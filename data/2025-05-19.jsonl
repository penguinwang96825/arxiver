{"title": "CIE: Controlling Language Model Text Generations Using Continuous Signals", "abstract": "Aligning language models with user intent is becoming increasingly relevant\nto enhance user experience. This calls for designing methods that can allow\nusers to control the properties of the language that LMs generate. For example,\ncontrolling the length of the generation, the complexity of the language that\ngets chosen, the sentiment, tone, etc. Most existing work attempts to integrate\nusers' control by conditioning LM generations on natural language prompts or\ndiscrete control signals, which are often brittle and hard to scale. In this\nwork, we are interested in \\textit{continuous} control signals, ones that exist\nalong a spectrum that can't easily be captured in a natural language prompt or\nvia existing techniques in conditional generation. Through a case study in\ncontrolling the precise response-length of generations produced by LMs, we\ndemonstrate how after fine-tuning, behaviors of language models can be\ncontrolled via continuous signals -- as vectors that are interpolated between a\n\"low\" and a \"high\" token embedding. Our method more reliably exerts\nresponse-length control than in-context learning methods or fine-tuning methods\nthat represent the control signal as a discrete signal. Our full open-sourced\ncode and datasets are available at https://github.com/vsamuel2003/CIE.", "published": "2025-05-19 17:59:58", "link": "http://arxiv.org/abs/2505.13448v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Trust, But Verify: A Self-Verification Approach to Reinforcement Learning with Verifiable Rewards", "abstract": "Large Language Models (LLMs) show great promise in complex reasoning, with\nReinforcement Learning with Verifiable Rewards (RLVR) being a key enhancement\nstrategy. However, a prevalent issue is ``superficial self-reflection'', where\nmodels fail to robustly verify their own outputs. We introduce RISE\n(Reinforcing Reasoning with Self-Verification), a novel online RL framework\ndesigned to tackle this. RISE explicitly and simultaneously trains an LLM to\nimprove both its problem-solving and self-verification abilities within a\nsingle, integrated RL process. The core mechanism involves leveraging\nverifiable rewards from an outcome verifier to provide on-the-fly feedback for\nboth solution generation and self-verification tasks. In each iteration, the\nmodel generates solutions, then critiques its own on-policy generated\nsolutions, with both trajectories contributing to the policy update. Extensive\nexperiments on diverse mathematical reasoning benchmarks show that RISE\nconsistently improves model's problem-solving accuracy while concurrently\nfostering strong self-verification skills. Our analyses highlight the\nadvantages of online verification and the benefits of increased verification\ncompute. Additionally, RISE models exhibit more frequent and accurate\nself-verification behaviors during reasoning. These advantages reinforce RISE\nas a flexible and effective path towards developing more robust and self-aware\nreasoners.", "published": "2025-05-19 17:59:31", "link": "http://arxiv.org/abs/2505.13445v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "ChartMuseum: Testing Visual Reasoning Capabilities of Large Vision-Language Models", "abstract": "Chart understanding presents a unique challenge for large vision-language\nmodels (LVLMs), as it requires the integration of sophisticated textual and\nvisual reasoning capabilities. However, current LVLMs exhibit a notable\nimbalance between these skills, falling short on visual reasoning that is\ndifficult to perform in text. We conduct a case study using a synthetic dataset\nsolvable only through visual reasoning and show that model performance degrades\nsignificantly with increasing visual complexity, while human performance\nremains robust. We then introduce ChartMuseum, a new Chart Question Answering\n(QA) benchmark containing 1,162 expert-annotated questions spanning multiple\nreasoning types, curated from real-world charts across 184 sources,\nspecifically built to evaluate complex visual and textual reasoning. Unlike\nprior chart understanding benchmarks -- where frontier models perform similarly\nand near saturation -- our benchmark exposes a substantial gap between model\nand human performance, while effectively differentiating model capabilities:\nalthough humans achieve 93% accuracy, the best-performing model Gemini-2.5-Pro\nattains only 63.0%, and the leading open-source LVLM Qwen2.5-VL-72B-Instruct\nachieves only 38.5%. Moreover, on questions requiring primarily visual\nreasoning, all models experience a 35%-55% performance drop from\ntext-reasoning-heavy question performance. Lastly, our qualitative error\nanalysis reveals specific categories of visual reasoning that are challenging\nfor current LVLMs.", "published": "2025-05-19 17:59:27", "link": "http://arxiv.org/abs/2505.13444v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Optimizing Anytime Reasoning via Budget Relative Policy Optimization", "abstract": "Scaling test-time compute is crucial for enhancing the reasoning capabilities\nof large language models (LLMs). Existing approaches typically employ\nreinforcement learning (RL) to maximize a verifiable reward obtained at the end\nof reasoning traces. However, such methods optimize only the final performance\nunder a large and fixed token budget, which hinders efficiency in both training\nand deployment. In this work, we present a novel framework, AnytimeReasoner, to\noptimize anytime reasoning performance, which aims to improve token efficiency\nand the flexibility of reasoning under varying token budget constraints. To\nachieve this, we truncate the complete thinking process to fit within sampled\ntoken budgets from a prior distribution, compelling the model to summarize the\noptimal answer for each truncated thinking for verification. This introduces\nverifiable dense rewards into the reasoning process, facilitating more\neffective credit assignment in RL optimization. We then optimize the thinking\nand summary policies in a decoupled manner to maximize the cumulative reward.\nAdditionally, we introduce a novel variance reduction technique, Budget\nRelative Policy Optimization (BRPO), to enhance the robustness and efficiency\nof the learning process when reinforcing the thinking policy. Empirical results\nin mathematical reasoning tasks demonstrate that our method consistently\noutperforms GRPO across all thinking budgets under various prior distributions,\nenhancing both training and token efficiency.", "published": "2025-05-19 17:58:44", "link": "http://arxiv.org/abs/2505.13438v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "SMOTExT: SMOTE meets Large Language Models", "abstract": "Data scarcity and class imbalance are persistent challenges in training\nrobust NLP models, especially in specialized domains or low-resource settings.\nWe propose a novel technique, SMOTExT, that adapts the idea of Synthetic\nMinority Over-sampling (SMOTE) to textual data. Our method generates new\nsynthetic examples by interpolating between BERT-based embeddings of two\nexisting examples and then decoding the resulting latent point into text with\nxRAG architecture. By leveraging xRAG's cross-modal retrieval-generation\nframework, we can effectively turn interpolated vectors into coherent text.\nWhile this is preliminary work supported by qualitative outputs only, the\nmethod shows strong potential for knowledge distillation and data augmentation\nin few-shot settings. Notably, our approach also shows promise for\nprivacy-preserving machine learning: in early experiments, training models\nsolely on generated data achieved comparable performance to models trained on\nthe original dataset. This suggests a viable path toward safe and effective\nlearning under data protection constraints.", "published": "2025-05-19 17:57:36", "link": "http://arxiv.org/abs/2505.13434v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fine-tuning Quantized Neural Networks with Zeroth-order Optimization", "abstract": "As the size of large language models grows exponentially, GPU memory has\nbecome a bottleneck for adapting these models to downstream tasks. In this\npaper, we aim to push the limits of memory-efficient training by minimizing\nmemory usage on model weights, gradients, and optimizer states, within a\nunified framework. Our idea is to eliminate both gradients and optimizer states\nusing zeroth-order optimization, which approximates gradients by perturbing\nweights during forward passes to identify gradient directions. To minimize\nmemory usage on weights, we employ model quantization, e.g., converting from\nbfloat16 to int4. However, directly applying zeroth-order optimization to\nquantized weights is infeasible due to the precision gap between discrete\nweights and continuous gradients, which would otherwise require de-quantization\nand re-quantization. To overcome this challenge, we propose Quantized\nZeroth-order Optimization (QZO), a novel approach that perturbs the continuous\nquantization scale for gradient estimation and uses a directional derivative\nclipping method to stabilize training. QZO is orthogonal to both scalar-based\nand codebook-based post-training quantization methods. Compared to\nfull-parameter fine-tuning in bfloat16, QZO can reduce the total memory cost by\nmore than 18$\\times$ for 4-bit LLMs, and enables fine-tuning Llama-2-13B and\nStable Diffusion 3.5 Large within a single 24GB GPU.", "published": "2025-05-19 17:55:15", "link": "http://arxiv.org/abs/2505.13430v1", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Dementia Through Different Eyes: Explainable Modeling of Human and LLM Perceptions for Early Awareness", "abstract": "Cognitive decline often surfaces in language years before diagnosis. It is\nfrequently non-experts, such as those closest to the patient, who first sense a\nchange and raise concern. As LLMs become integrated into daily communication\nand used over prolonged periods, it may even be an LLM that notices something\nis off. But what exactly do they notice--and should be noticing--when making\nthat judgment? This paper investigates how dementia is perceived through\nlanguage by non-experts. We presented transcribed picture descriptions to\nnon-expert humans and LLMs, asking them to intuitively judge whether each text\nwas produced by someone healthy or with dementia. We introduce an explainable\nmethod that uses LLMs to extract high-level, expert-guided features\nrepresenting these picture descriptions, and use logistic regression to model\nhuman and LLM perceptions and compare with clinical diagnoses. Our analysis\nreveals that human perception of dementia is inconsistent and relies on a\nnarrow, and sometimes misleading, set of cues. LLMs, by contrast, draw on a\nricher, more nuanced feature set that aligns more closely with clinical\npatterns. Still, both groups show a tendency toward false negatives, frequently\noverlooking dementia cases. Through our interpretable framework and the\ninsights it provides, we hope to help non-experts better recognize the\nlinguistic signs that matter.", "published": "2025-05-19 17:51:35", "link": "http://arxiv.org/abs/2505.13418v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AdaptThink: Reasoning Models Can Learn When to Think", "abstract": "Recently, large reasoning models have achieved impressive performance on\nvarious tasks by employing human-like deep thinking. However, the lengthy\nthinking process substantially increases inference overhead, making efficiency\na critical bottleneck. In this work, we first demonstrate that NoThinking,\nwhich prompts the reasoning model to skip thinking and directly generate the\nfinal solution, is a better choice for relatively simple tasks in terms of both\nperformance and efficiency. Motivated by this, we propose AdaptThink, a novel\nRL algorithm to teach reasoning models to choose the optimal thinking mode\nadaptively based on problem difficulty. Specifically, AdaptThink features two\ncore components: (1) a constrained optimization objective that encourages the\nmodel to choose NoThinking while maintaining the overall performance; (2) an\nimportance sampling strategy that balances Thinking and NoThinking samples\nduring on-policy training, thereby enabling cold start and allowing the model\nto explore and exploit both thinking modes throughout the training process. Our\nexperiments indicate that AdaptThink significantly reduces the inference costs\nwhile further enhancing performance. Notably, on three math datasets,\nAdaptThink reduces the average response length of DeepSeek-R1-Distill-Qwen-1.5B\nby 53% and improves its accuracy by 2.4%, highlighting the promise of adaptive\nthinking-mode selection for optimizing the balance between reasoning quality\nand efficiency. Our codes and models are available at\nhttps://github.com/THU-KEG/AdaptThink.", "published": "2025-05-19 17:50:52", "link": "http://arxiv.org/abs/2505.13417v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CoT-Kinetics: A Theoretical Modeling Assessing LRM Reasoning Process", "abstract": "Recent Large Reasoning Models significantly improve the reasoning ability of\nLarge Language Models by learning to reason, exhibiting the promising\nperformance in solving complex tasks. LRMs solve tasks that require complex\nreasoning by explicitly generating reasoning trajectories together with\nanswers. Nevertheless, judging the quality of such an output answer is not easy\nbecause only considering the correctness of the answer is not enough and the\nsoundness of the reasoning trajectory part matters as well. Logically, if the\nsoundness of the reasoning part is poor, even if the answer is correct, the\nconfidence of the derived answer should be low. Existing methods did consider\njointly assessing the overall output answer by taking into account the\nreasoning part, however, their capability is still not satisfactory as the\ncausal relationship of the reasoning to the concluded answer cannot properly\nreflected. In this paper, inspired by classical mechanics, we present a novel\napproach towards establishing a CoT-Kinetics energy equation. Specifically, our\nCoT-Kinetics energy equation formulates the token state transformation process,\nwhich is regulated by LRM internal transformer layers, as like a particle\nkinetics dynamics governed in a mechanical field. Our CoT-Kinetics energy\nassigns a scalar score to evaluate specifically the soundness of the reasoning\nphase, telling how confident the derived answer could be given the evaluated\nreasoning. As such, the LRM's overall output quality can be accurately\nmeasured, rather than a coarse judgment (e.g., correct or incorrect) anymore.", "published": "2025-05-19 17:44:26", "link": "http://arxiv.org/abs/2505.13408v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Granary: Speech Recognition and Translation Dataset in 25 European Languages", "abstract": "Multi-task and multilingual approaches benefit large models, yet speech\nprocessing for low-resource languages remains underexplored due to data\nscarcity. To address this, we present Granary, a large-scale collection of\nspeech datasets for recognition and translation across 25 European languages.\nThis is the first open-source effort at this scale for both transcription and\ntranslation. We enhance data quality using a pseudo-labeling pipeline with\nsegmentation, two-pass inference, hallucination filtering, and punctuation\nrestoration. We further generate translation pairs from pseudo-labeled\ntranscriptions using EuroLLM, followed by a data filtration pipeline. Designed\nfor efficiency, our pipeline processes vast amount of data within hours. We\nassess models trained on processed data by comparing their performance on\npreviously curated datasets for both high- and low-resource languages. Our\nfindings show that these models achieve similar performance using approx. 50%\nless data. Dataset will be made available at\nhttps://hf.co/datasets/nvidia/Granary", "published": "2025-05-19 17:40:58", "link": "http://arxiv.org/abs/2505.13404v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "MR. Judge: Multimodal Reasoner as a Judge", "abstract": "The paradigm of using Large Language Models (LLMs) and Multimodal Large\nLanguage Models (MLLMs) as evaluative judges has emerged as an effective\napproach in RLHF and inference-time scaling. In this work, we propose\nMultimodal Reasoner as a Judge (MR. Judge), a paradigm for empowering\ngeneral-purpose MLLMs judges with strong reasoning capabilities. Instead of\ndirectly assigning scores for each response, we formulate the judgement process\nas a reasoning-inspired multiple-choice problem. Specifically, the judge model\nfirst conducts deliberate reasoning covering different aspects of the responses\nand eventually selects the best response from them. This reasoning process not\nonly improves the interpretibility of the judgement, but also greatly enhances\nthe performance of MLLM judges. To cope with the lack of questions with scored\nresponses, we propose the following strategy to achieve automatic annotation:\n1) Reverse Response Candidates Synthesis: starting from a supervised\nfine-tuning (SFT) dataset, we treat the original response as the best candidate\nand prompt the MLLM to generate plausible but flawed negative candidates. 2)\nText-based reasoning extraction: we carefully design a data synthesis pipeline\nfor distilling the reasoning capability from a text-based reasoning model,\nwhich is adopted to enable the MLLM judges to regain complex reasoning ability\nvia warm up supervised fine-tuning. Experiments demonstrate that our MR. Judge\nis effective across a wide range of tasks. Specifically, our MR. Judge-7B\nsurpasses GPT-4o by 9.9% on VL-RewardBench, and improves performance on MM-Vet\nduring inference-time scaling by up to 7.7%.", "published": "2025-05-19 17:37:39", "link": "http://arxiv.org/abs/2505.13403v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Minimum Description Length Approach to Regularization in Neural Networks", "abstract": "State-of-the-art neural networks can be trained to become remarkable\nsolutions to many problems. But while these architectures can express symbolic,\nperfect solutions, trained models often arrive at approximations instead. We\nshow that the choice of regularization method plays a crucial role: when\ntrained on formal languages with standard regularization ($L_1$, $L_2$, or\nnone), expressive architectures not only fail to converge to correct solutions\nbut are actively pushed away from perfect initializations. In contrast,\napplying the Minimum Description Length (MDL) principle to balance model\ncomplexity with data fit provides a theoretically grounded regularization\nmethod. Using MDL, perfect solutions are selected over approximations,\nindependently of the optimization algorithm. We propose that unlike existing\nregularization techniques, MDL introduces the appropriate inductive bias to\neffectively counteract overfitting and promote generalization.", "published": "2025-05-19 17:34:56", "link": "http://arxiv.org/abs/2505.13398v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "IG Parser: A Software Package for the Encoding of Institutional Statements using the Institutional Grammar", "abstract": "This article provides an overview of IG Parser, a software that facilitates\nqualitative content analysis of formal (e.g., legal) rules or informal (e.g.,\nsocio-normative) norms, and strategies (such as conventions) -- referred to as\n\\emph{institutions} -- that govern social systems and operate configurally to\ndescribe \\emph{institutional systems}. To this end, the IG Parser employs a\ndistinctive syntax that ensures rigorous encoding of natural language, while\nautomating the transformation into various formats that support the downstream\nanalysis using diverse analytical techniques. The conceptual core of the IG\nParser is an associated syntax, IG Script, that operationalizes the conceptual\nfoundations of the Institutional Grammar, and more specifically Institutional\nGrammar 2.0, an analytical paradigm for institutional analysis. This article\npresents the IG Parser, including its conceptual foundations, syntactic\nspecification of IG Script, alongside architectural principles. This\nintroduction is augmented with selective illustrative examples that highlight\nthe use and benefit associated with the tool.", "published": "2025-05-19 17:33:15", "link": "http://arxiv.org/abs/2505.13393v1", "categories": ["cs.MA", "cs.AI", "cs.CL", "68T30, 68T50", "E.2; H.1.0; I.7.2; I.6.5; K.4.1"], "primary_category": "cs.MA"}
{"title": "R3: Robust Rubric-Agnostic Reward Models", "abstract": "Reward models are essential for aligning language model outputs with human\npreferences, yet existing approaches often lack both controllability and\ninterpretability. These models are typically optimized for narrow objectives,\nlimiting their generalizability to broader downstream tasks. Moreover, their\nscalar outputs are difficult to interpret without contextual reasoning. To\naddress these limitations, we introduce R3, a novel reward modeling framework\nthat is rubric-agnostic, generalizable across evaluation dimensions, and\nprovides interpretable, reasoned score assignments. R3 enables more transparent\nand flexible evaluation of language models, supporting robust alignment with\ndiverse human values and use cases. Our models, data, and code are available as\nopen source at https://github.com/rubricreward/r3", "published": "2025-05-19 17:29:03", "link": "http://arxiv.org/abs/2505.13388v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CompeteSMoE -- Statistically Guaranteed Mixture of Experts Training via Competition", "abstract": "Sparse mixture of experts (SMoE) offers an appealing solution to scale up the\nmodel complexity beyond the mean of increasing the network's depth or width.\nHowever, we argue that effective SMoE training remains challenging because of\nthe suboptimal routing process where experts that perform computation do not\ndirectly contribute to the routing process. In this work, we propose\ncompetition, a novel mechanism to route tokens to experts with the highest\nneural response. Theoretically, we show that the competition mechanism enjoys a\nbetter sample efficiency than the traditional softmax routing. Furthermore, we\ndevelop CompeteSMoE, a simple yet effective algorithm to train large language\nmodels by deploying a router to learn the competition policy, thus enjoying\nstrong performances at a low training overhead. Our extensive empirical\nevaluations on both the visual instruction tuning and language pre-training\ntasks demonstrate the efficacy, robustness, and scalability of CompeteSMoE\ncompared to state-of-the-art SMoE strategies. We have made the implementation\navailable at: https://github.com/Fsoft-AIC/CompeteSMoE. This work is an\nimproved version of the previous study at arXiv:2402.02526", "published": "2025-05-19 17:24:26", "link": "http://arxiv.org/abs/2505.13380v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Thinkless: LLM Learns When to Think", "abstract": "Reasoning Language Models, capable of extended chain-of-thought reasoning,\nhave demonstrated remarkable performance on tasks requiring complex logical\ninference. However, applying elaborate reasoning for all queries often results\nin substantial computational inefficiencies, particularly when many problems\nadmit straightforward solutions. This motivates an open question: Can LLMs\nlearn when to think? To answer this, we propose Thinkless, a learnable\nframework that empowers an LLM to adaptively select between short-form and\nlong-form reasoning, based on both task complexity and the model's ability.\nThinkless is trained under a reinforcement learning paradigm and employs two\ncontrol tokens, <short> for concise responses and <think> for detailed\nreasoning. At the core of our method is a Decoupled Group Relative Policy\nOptimization (DeGRPO) algorithm, which decomposes the learning objective of\nhybrid reasoning into two components: (1) a control token loss that governs the\nselection of the reasoning mode, and (2) a response loss that improves the\naccuracy of the generated answers. This decoupled formulation enables\nfine-grained control over the contributions of each objective, stabilizing\ntraining and effectively preventing collapse observed in vanilla GRPO.\nEmpirically, on several benchmarks such as Minerva Algebra, MATH-500, and\nGSM8K, Thinkless is able to reduce the usage of long-chain thinking by 50% -\n90%, significantly improving the efficiency of Reasoning Language Models. The\ncode is available at https://github.com/VainF/Thinkless", "published": "2025-05-19 17:24:16", "link": "http://arxiv.org/abs/2505.13379v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "What Prompts Don't Say: Understanding and Managing Underspecification in LLM Prompts", "abstract": "Building LLM-powered software requires developers to communicate their\nrequirements through natural language, but developer prompts are frequently\nunderspecified, failing to fully capture many user-important requirements. In\nthis paper, we present an in-depth analysis of prompt underspecification,\nshowing that while LLMs can often (41.1%) guess unspecified requirements by\ndefault, such behavior is less robust: Underspecified prompts are 2x more\nlikely to regress over model or prompt changes, sometimes with accuracy drops\nby more than 20%. We then demonstrate that simply adding more requirements to a\nprompt does not reliably improve performance, due to LLMs' limited\ninstruction-following capabilities and competing constraints, and standard\nprompt optimizers do not offer much help. To address this, we introduce novel\nrequirements-aware prompt optimization mechanisms that can improve performance\nby 4.8% on average over baselines that naively specify everything in the\nprompt. Beyond prompt optimization, we envision that effectively managing\nprompt underspecification requires a broader process, including proactive\nrequirements discovery, evaluation, and monitoring.", "published": "2025-05-19 17:03:42", "link": "http://arxiv.org/abs/2505.13360v1", "categories": ["cs.CL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Sense and Sensitivity: Examining the Influence of Semantic Recall on Long Context Code Reasoning", "abstract": "Although modern Large Language Models (LLMs) support extremely large\ncontexts, their effectiveness in utilizing long context for code reasoning\nremains unclear. This paper investigates LLM reasoning ability over code\nsnippets within large repositories and how it relates to their recall ability.\nSpecifically, we differentiate between lexical code recall (verbatim retrieval)\nand semantic code recall (remembering what the code does). To measure semantic\nrecall, we propose SemTrace, a code reasoning technique where the impact of\nspecific statements on output is attributable and unpredictable. We also\npresent a method to quantify semantic recall sensitivity in existing\nbenchmarks. Our evaluation of state-of-the-art LLMs reveals a significant drop\nin code reasoning accuracy as a code snippet approaches the middle of the input\ncontext, particularly with techniques requiring high semantic recall like\nSemTrace. Moreover, we find that lexical recall varies by granularity, with\nmodels excelling at function retrieval but struggling with line-by-line recall.\nNotably, a disconnect exists between lexical and semantic recall, suggesting\ndifferent underlying mechanisms. Finally, our findings indicate that current\ncode reasoning benchmarks may exhibit low semantic recall sensitivity,\npotentially underestimating LLM challenges in leveraging in-context\ninformation.", "published": "2025-05-19 16:56:31", "link": "http://arxiv.org/abs/2505.13353v1", "categories": ["cs.CL", "cs.LG", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Investigating the Vulnerability of LLM-as-a-Judge Architectures to Prompt-Injection Attacks", "abstract": "Large Language Models (LLMs) are increasingly employed as evaluators\n(LLM-as-a-Judge) for assessing the quality of machine-generated text. This\nparadigm offers scalability and cost-effectiveness compared to human\nannotation. However, the reliability and security of such systems, particularly\ntheir robustness against adversarial manipulations, remain critical concerns.\nThis paper investigates the vulnerability of LLM-as-a-Judge architectures to\nprompt-injection attacks, where malicious inputs are designed to compromise the\njudge's decision-making process. We formalize two primary attack strategies:\nComparative Undermining Attack (CUA), which directly targets the final decision\noutput, and Justification Manipulation Attack (JMA), which aims to alter the\nmodel's generated reasoning. Using the Greedy Coordinate Gradient (GCG)\noptimization method, we craft adversarial suffixes appended to one of the\nresponses being compared. Experiments conducted on the MT-Bench Human Judgments\ndataset with open-source instruction-tuned LLMs (Qwen2.5-3B-Instruct and\nFalcon3-3B-Instruct) demonstrate significant susceptibility. The CUA achieves\nan Attack Success Rate (ASR) exceeding 30\\%, while JMA also shows notable\neffectiveness. These findings highlight substantial vulnerabilities in current\nLLM-as-a-Judge systems, underscoring the need for robust defense mechanisms and\nfurther research into adversarial evaluation and trustworthiness in LLM-based\nassessment frameworks.", "published": "2025-05-19 16:51:12", "link": "http://arxiv.org/abs/2505.13348v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "J4R: Learning to Judge with Equivalent Initial State Group Relative Preference Optimization", "abstract": "To keep pace with the increasing pace of large language models (LLM)\ndevelopment, model output evaluation has transitioned away from time-consuming\nhuman evaluation to automatic evaluation, where LLMs themselves are tasked with\nassessing and critiquing other model outputs. LLM-as-judge models are a class\nof generative evaluators that excel in evaluating relatively simple domains,\nlike chat quality, but struggle in reasoning intensive domains where model\nresponses contain more substantive and challenging content. To remedy existing\njudge shortcomings, we explore training judges with reinforcement learning\n(RL). We make three key contributions: (1) We propose the Equivalent Initial\nState Group Relative Policy Optimization (EIS-GRPO) algorithm, which allows us\nto train our judge to be robust to positional biases that arise in more complex\nevaluation settings. (2) We introduce ReasoningJudgeBench, a benchmark that\nevaluates judges in diverse reasoning settings not covered by prior work. (3)\nWe train Judge for Reasoning (J4R), a 7B judge trained with EIS-GRPO that\noutperforms GPT-4o and the next best small judge by 6.7% and 9%, matching or\nexceeding the performance of larger GRPO-trained judges on both JudgeBench and\nReasoningJudgeBench.", "published": "2025-05-19 16:50:35", "link": "http://arxiv.org/abs/2505.13346v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Contextual Paralinguistic Data Creation for Multi-Modal Speech-LLM: Data Condensation and Spoken QA Generation", "abstract": "Current speech-LLMs exhibit limited capability in contextual reasoning\nalongside paralinguistic understanding, primarily due to the lack of\nQuestion-Answer (QA) datasets that cover both aspects. We propose a novel\nframework for dataset generation from in-the-wild speech data, that integrates\ncontextual reasoning with paralinguistic information. It consists of a pseudo\nparalinguistic label-based data condensation of in-the-wild speech and\nLLM-based Contextual Paralinguistic QA (CPQA) generation. The effectiveness is\nvalidated by a strong correlation in evaluations of the Qwen2-Audio-7B-Instruct\nmodel on a dataset created by our framework and human-generated CPQA dataset.\nThe results also reveal the speech-LLM's limitations in handling empathetic\nreasoning tasks, highlighting the need for such datasets and more robust\nmodels. The proposed framework is first of its kind and has potential in\ntraining more robust speech-LLMs with paralinguistic reasoning capabilities.", "published": "2025-05-19 16:47:46", "link": "http://arxiv.org/abs/2505.13338v1", "categories": ["cs.CL", "cs.AI", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Rethinking Stateful Tool Use in Multi-Turn Dialogues: Benchmarks and Challenges", "abstract": "Existing benchmarks that assess Language Models (LMs) as Language Agents\n(LAs) for tool use primarily focus on stateless, single-turn interactions or\npartial evaluations, such as tool selection in a single turn, overlooking the\ninherent stateful nature of interactions in multi-turn applications. To fulfill\nthis gap, we propose \\texttt{DialogTool}, a multi-turn dialogue dataset with\nstateful tool interactions considering the whole life cycle of tool use, across\nsix key tasks in three stages: 1) \\textit{tool creation}; 2) \\textit{tool\nutilization}: tool awareness, tool selection, tool execution; and 3)\n\\textit{role-consistent response}: response generation and role play.\nFurthermore, we build \\texttt{VirtualMobile} -- an embodied virtual mobile\nevaluation environment to simulate API calls and assess the robustness of the\ncreated APIs\\footnote{We will use tools and APIs alternatively, there are no\nsignificant differences between them in this paper.}. Taking advantage of these\nartifacts, we conduct comprehensive evaluation on 13 distinct open- and\nclosed-source LLMs and provide detailed analysis at each stage, revealing that\nthe existing state-of-the-art LLMs still cannot perform well to use tools over\nlong horizons.", "published": "2025-05-19 16:36:13", "link": "http://arxiv.org/abs/2505.13328v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GUARD: Generation-time LLM Unlearning via Adaptive Restriction and Detection", "abstract": "Large Language Models (LLMs) have demonstrated strong capabilities in\nmemorizing vast amounts of knowledge across diverse domains. However, the\nability to selectively forget specific knowledge is critical for ensuring the\nsafety and compliance of deployed models. Existing unlearning efforts typically\nfine-tune the model with resources such as forget data, retain data, and a\ncalibration model. These additional gradient steps blur the decision boundary\nbetween forget and retain knowledge, making unlearning often at the expense of\noverall performance. To avoid the negative impact of fine-tuning, it would be\nbetter to unlearn solely at inference time by safely guarding the model against\ngenerating responses related to the forget target, without destroying the\nfluency of text generation. In this work, we propose Generation-time Unlearning\nvia Adaptive Restriction and Detection (GUARD), a framework that enables\ndynamic unlearning during LLM generation. Specifically, we first employ a\nprompt classifier to detect unlearning targets and extract the corresponding\nforbidden token. We then dynamically penalize and filter candidate tokens\nduring generation using a combination of token matching and semantic matching,\neffectively preventing the model from leaking the forgotten content.\nExperimental results on copyright content unlearning tasks over the Harry\nPotter dataset and the MUSE benchmark, as well as entity unlearning tasks on\nthe TOFU dataset, demonstrate that GUARD achieves strong forget quality across\nvarious tasks while causing almost no degradation to the LLM's general\ncapabilities, striking an excellent trade-off between forgetting and utility.", "published": "2025-05-19 16:26:58", "link": "http://arxiv.org/abs/2505.13312v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Seek in the Dark: Reasoning via Test-Time Instance-Level Policy Gradient in Latent Space", "abstract": "Reasoning ability, a core component of human intelligence, continues to pose\na significant challenge for Large Language Models (LLMs) in the pursuit of AGI.\nAlthough model performance has improved under the training scaling law,\nsignificant challenges remain, particularly with respect to training\nalgorithms, such as catastrophic forgetting, and the limited availability of\nnovel training data. As an alternative, test-time scaling enhances reasoning\nperformance by increasing test-time computation without parameter updating.\nUnlike prior methods in this paradigm focused on token space, we propose\nleveraging latent space for more effective reasoning and better adherence to\nthe test-time scaling law. We introduce LatentSeek, a novel framework that\nenhances LLM reasoning through Test-Time Instance-level Adaptation (TTIA)\nwithin the model's latent space. Specifically, LatentSeek leverages policy\ngradient to iteratively update latent representations, guided by self-generated\nreward signals. LatentSeek is evaluated on a range of reasoning benchmarks,\nincluding GSM8K, MATH-500, and AIME2024, across multiple LLM architectures.\nResults show that LatentSeek consistently outperforms strong baselines, such as\nChain-of-Thought prompting and fine-tuning-based methods. Furthermore, our\nanalysis demonstrates that LatentSeek is highly efficient, typically converging\nwithin a few iterations for problems of average complexity, while also\nbenefiting from additional iterations, thereby highlighting the potential of\ntest-time scaling in the latent space. These findings position LatentSeek as a\nlightweight, scalable, and effective solution for enhancing the reasoning\ncapabilities of LLMs.", "published": "2025-05-19 16:26:02", "link": "http://arxiv.org/abs/2505.13308v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "RBF++: Quantifying and Optimizing Reasoning Boundaries across Measurable and Unmeasurable Capabilities for Chain-of-Thought Reasoning", "abstract": "Chain-of-Thought (CoT) reasoning has proven effective in enhancing large\nlanguage models (LLMs) on complex tasks, spurring research into its underlying\nmechanisms. However, two primary challenges remain for real-world applications:\n(1) the lack of quantitative metrics and actionable guidelines for evaluating\nand optimizing measurable boundaries of CoT capability, and (2) the absence of\nmethods to assess boundaries of unmeasurable CoT capability, such as multimodal\nperception. To address these gaps, we introduce the Reasoning Boundary\nFramework++ (RBF++). To tackle the first challenge, we define the reasoning\nboundary (RB) as the maximum limit of CoT performance. We also propose a\ncombination law for RBs, enabling quantitative analysis and offering actionable\nguidance across various CoT tasks. For the second challenge, particularly in\nmultimodal scenarios, we introduce a constant assumption, which replaces\nunmeasurable RBs with scenario-specific constants. Additionally, we propose the\nreasoning boundary division mechanism, which divides unmeasurable RBs into two\nsub-boundaries, facilitating the quantification and optimization of both\nunmeasurable domain knowledge and multimodal perception capabilities. Extensive\nexperiments involving 38 models across 13 tasks validate the feasibility of our\nframework in cross-modal settings. Additionally, we evaluate 10 CoT strategies,\noffer insights into optimization and decay from two complementary perspectives,\nand expand evaluation benchmarks for measuring RBs in LLM reasoning. We hope\nthis work advances the understanding of RBs and optimization strategies in\nLLMs. Code and data are available at\nhttps://github.com/LightChen233/reasoning-boundary.", "published": "2025-05-19 16:25:55", "link": "http://arxiv.org/abs/2505.13307v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "I'll believe it when I see it: Images increase misinformation sharing in Vision-Language Models", "abstract": "Large language models are increasingly integrated into news recommendation\nsystems, raising concerns about their role in spreading misinformation. In\nhumans, visual content is known to boost credibility and shareability of\ninformation, yet its effect on vision-language models (VLMs) remains unclear.\nWe present the first study examining how images influence VLMs' propensity to\nreshare news content, whether this effect varies across model families, and how\npersona conditioning and content attributes modulate this behavior. To support\nthis analysis, we introduce two methodological contributions: a\njailbreaking-inspired prompting strategy that elicits resharing decisions from\nVLMs while simulating users with antisocial traits and political alignments;\nand a multimodal dataset of fact-checked political news from PolitiFact, paired\nwith corresponding images and ground-truth veracity labels. Experiments across\nmodel families reveal that image presence increases resharing rates by 4.8% for\ntrue news and 15.0% for false news. Persona conditioning further modulates this\neffect: Dark Triad traits amplify resharing of false news, whereas\nRepublican-aligned profiles exhibit reduced veracity sensitivity. Of all the\ntested models, only Claude-3-Haiku demonstrates robustness to visual\nmisinformation. These findings highlight emerging risks in multimodal model\nbehavior and motivate the development of tailored evaluation frameworks and\nmitigation strategies for personalized AI systems. Code and dataset are\navailable at: https://github.com/3lis/misinfo_vlm", "published": "2025-05-19 16:20:54", "link": "http://arxiv.org/abs/2505.13302v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "$\\textit{Rank, Chunk and Expand}$: Lineage-Oriented Reasoning for Taxonomy Expansion", "abstract": "Taxonomies are hierarchical knowledge graphs crucial for recommendation\nsystems, and web applications. As data grows, expanding taxonomies is\nessential, but existing methods face key challenges: (1) discriminative models\nstruggle with representation limits and generalization, while (2) generative\nmethods either process all candidates at once, introducing noise and exceeding\ncontext limits, or discard relevant entities by selecting noisy candidates. We\npropose LORex ($\\textbf{L}$ineage-$\\textbf{O}$riented $\\textbf{Re}$asoning for\nTaxonomy E$\\textbf{x}$pansion), a plug-and-play framework that combines\ndiscriminative ranking and generative reasoning for efficient taxonomy\nexpansion. Unlike prior methods, LORex ranks and chunks candidate terms into\nbatches, filtering noise and iteratively refining selections by reasoning\ncandidates' hierarchy to ensure contextual efficiency. Extensive experiments\nacross four benchmarks and twelve baselines show that LORex improves accuracy\nby 12% and Wu & Palmer similarity by 5% over state-of-the-art methods.", "published": "2025-05-19 16:06:13", "link": "http://arxiv.org/abs/2505.13282v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CSC-SQL: Corrective Self-Consistency in Text-to-SQL via Reinforcement Learning", "abstract": "Large language models (LLMs) have demonstrated strong capabilities in\ntranslating natural language questions about relational databases into SQL\nqueries. In particular, test-time scaling techniques such as Self-Consistency\nand Self-Correction can enhance SQL generation accuracy by increasing\ncomputational effort during inference. However, these methods have notable\nlimitations: Self-Consistency may select suboptimal outputs despite majority\nvotes, while Self-Correction typically addresses only syntactic errors. To\nleverage the strengths of both approaches, we propose CSC-SQL, a novel method\nthat integrates Self-Consistency and Self-Correction. CSC-SQL selects the two\nmost frequently occurring outputs from parallel sampling and feeds them into a\nmerge revision model for correction. Additionally, we employ the Group Relative\nPolicy Optimization (GRPO) algorithm to fine-tune both the SQL generation and\nrevision models via reinforcement learning, significantly enhancing output\nquality. Experimental results confirm the effectiveness and generalizability of\nCSC-SQL. On the BIRD development set, our 3B model achieves 65.28% execution\naccuracy, while the 7B model achieves 69.19%. The code will be open sourced at\nhttps://github.com/CycloneBoy/csc_sql.", "published": "2025-05-19 15:52:19", "link": "http://arxiv.org/abs/2505.13271v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Representation of perceived prosodic similarity of conversational feedback", "abstract": "Vocal feedback (e.g., `mhm', `yeah', `okay') is an important component of\nspoken dialogue and is crucial to ensuring common ground in conversational\nsystems. The exact meaning of such feedback is conveyed through both lexical\nand prosodic form. In this work, we investigate the perceived prosodic\nsimilarity of vocal feedback with the same lexical form, and to what extent\nexisting speech representations reflect such similarities. A triadic comparison\ntask with recruited participants is used to measure perceived similarity of\nfeedback responses taken from two different datasets. We find that spectral and\nself-supervised speech representations encode prosody better than extracted\npitch features, especially in the case of feedback from the same speaker. We\nalso find that it is possible to further condense and align the representations\nto human perception through contrastive learning.", "published": "2025-05-19 15:47:51", "link": "http://arxiv.org/abs/2505.13268v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "From Automation to Autonomy: A Survey on Large Language Models in Scientific Discovery", "abstract": "Large Language Models (LLMs) are catalyzing a paradigm shift in scientific\ndiscovery, evolving from task-specific automation tools into increasingly\nautonomous agents and fundamentally redefining research processes and human-AI\ncollaboration. This survey systematically charts this burgeoning field, placing\na central focus on the changing roles and escalating capabilities of LLMs in\nscience. Through the lens of the scientific method, we introduce a foundational\nthree-level taxonomy-Tool, Analyst, and Scientist-to delineate their escalating\nautonomy and evolving responsibilities within the research lifecycle. We\nfurther identify pivotal challenges and future research trajectories such as\nrobotic automation, self-improvement, and ethical governance. Overall, this\nsurvey provides a conceptual architecture and strategic foresight to navigate\nand shape the future of AI-driven scientific discovery, fostering both rapid\ninnovation and responsible advancement. Github Repository:\nhttps://github.com/HKUST-KnowComp/Awesome-LLM-Scientific-Discovery.", "published": "2025-05-19 15:41:32", "link": "http://arxiv.org/abs/2505.13259v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Effective and Transparent RAG: Adaptive-Reward Reinforcement Learning for Decision Traceability", "abstract": "Retrieval-Augmented Generation (RAG) has significantly improved the\nperformance of large language models (LLMs) on knowledge-intensive domains.\nHowever, although RAG achieved successes across distinct domains, there are\nstill some unsolved challenges: 1) Effectiveness. Existing research mainly\nfocuses on developing more powerful RAG retrievers, but how to enhance the\ngenerator's (LLM's) ability to utilize the retrieved information for reasoning\nand generation? 2) Transparency. Most RAG methods ignore which retrieved\ncontent actually contributes to the reasoning process, resulting in a lack of\ninterpretability and visibility. To address this, we propose ARENA\n(Adaptive-Rewarded Evidence Navigation Agent), a transparent RAG generator\nframework trained via reinforcement learning (RL) with our proposed rewards.\nBased on the structured generation and adaptive reward calculation, our\nRL-based training enables the model to identify key evidence, perform\nstructured reasoning, and generate answers with interpretable decision traces.\nApplied to Qwen2.5-7B-Instruct and Llama3.1-8B-Instruct, abundant experiments\nwith various RAG baselines demonstrate that our model achieves 10-30%\nimprovements on all multi-hop QA datasets, which is comparable with the SOTA\nCommercially-developed LLMs (e.g., OpenAI-o1, DeepSeek-R1). Further analyses\nshow that ARENA has strong flexibility to be adopted on new datasets without\nextra training. Our models and codes are publicly released.", "published": "2025-05-19 15:40:29", "link": "http://arxiv.org/abs/2505.13258v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WikiPersonas: What Can We Learn From Personalized Alignment to Famous People?", "abstract": "Preference alignment has become a standard pipeline in finetuning models to\nfollow \\emph{generic} human preferences. Majority of work seeks to optimize\nmodel to produce responses that would be preferable \\emph{on average},\nsimplifying the diverse and often \\emph{contradicting} space of human\npreferences. While research has increasingly focused on personalized alignment:\nadapting models to individual user preferences, there is a lack of personalized\npreference dataset which focus on nuanced individual-level preferences. To\naddress this, we introduce WikiPersona: the first fine-grained personalization\nusing well-documented, famous individuals. Our dataset challenges models to\nalign with these personas through an interpretable process: generating\nverifiable textual descriptions of a persona's background and preferences in\naddition to alignment. We systematically evaluate different personalization\napproaches and find that as few-shot prompting with preferences and fine-tuning\nfail to simultaneously ensure effectiveness and efficiency, using\n\\textit{inferred personal preferences} as prefixes enables effective\npersonalization, especially in topics where preferences clash while leading to\nmore equitable generalization across unseen personas.", "published": "2025-05-19 15:39:48", "link": "http://arxiv.org/abs/2505.13257v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "HeteroSpec: Leveraging Contextual Heterogeneity for Efficient Speculative Decoding", "abstract": "Autoregressive decoding, the standard approach for Large Language Model (LLM)\ninference, remains a significant bottleneck due to its sequential nature. While\nspeculative decoding algorithms mitigate this inefficiency through parallel\nverification, they fail to exploit the inherent heterogeneity in linguistic\ncomplexity, a key factor leading to suboptimal resource allocation. We address\nthis by proposing HeteroSpec, a heterogeneity-adaptive speculative decoding\nframework that dynamically optimizes computational resource allocation based on\nlinguistic context complexity. HeteroSpec introduces two key mechanisms: (1) A\nnovel cumulative meta-path Top-$K$ entropy metric for efficiently identifying\npredictable contexts. (2) A dynamic resource allocation strategy based on\ndata-driven entropy partitioning, enabling adaptive speculative expansion and\npruning tailored to local context difficulty. Evaluated on five public\nbenchmarks and four models, HeteroSpec achieves an average speedup of\n4.26$\\times$. It consistently outperforms state-of-the-art EAGLE-3 across\nspeedup rates, average acceptance length, and verification cost. Notably,\nHeteroSpec requires no draft model retraining, incurs minimal overhead, and is\northogonal to other acceleration techniques. It demonstrates enhanced\nacceleration with stronger draft models, establishing a new paradigm for\ncontext-aware LLM inference acceleration.", "published": "2025-05-19 15:38:40", "link": "http://arxiv.org/abs/2505.13254v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Natural Language Planning via Coding and Inference Scaling", "abstract": "Real-life textual planning tasks such as meeting scheduling have posed much\nchallenge to LLMs especially when the complexity is high. While previous work\nprimarily studied auto-regressive generation of plans with closed-source\nmodels, we systematically evaluate both closed- and open-source models,\nincluding those that scales output length with complexity during inference, in\ngenerating programs, which are executed to output the plan. We consider not\nonly standard Python code, but also the code to a constraint satisfaction\nproblem solver. Despite the algorithmic nature of the task, we show that\nprogramming often but not always outperforms planning. Our detailed error\nanalysis also indicates a lack of robustness and efficiency in the generated\ncode that hinders generalization.", "published": "2025-05-19 15:35:17", "link": "http://arxiv.org/abs/2505.13252v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Stronger Together: Unleashing the Social Impact of Hate Speech Research", "abstract": "The advent of the internet has been both a blessing and a curse for once\nmarginalised communities. When used well, the internet can be used to connect\nand establish communities crossing different intersections; however, it can\nalso be used as a tool to alienate people and communities as well as perpetuate\nhate, misinformation, and disinformation especially on social media platforms.\nWe propose steering hate speech research and researchers away from pre-existing\ncomputational solutions and consider social methods to inform social solutions\nto address this social problem. In a similar way linguistics research can\ninform language planning policy, linguists should apply what we know about\nlanguage and society to mitigate some of the emergent risks and dangers of\nanti-social behaviour in digital spaces. We argue linguists and NLP researchers\ncan play a principle role in unleashing the social impact potential of\nlinguistics research working alongside communities, advocates, activists, and\npolicymakers to enable equitable digital inclusion and to close the digital\ndivide.", "published": "2025-05-19 15:34:07", "link": "http://arxiv.org/abs/2505.13251v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "JNLP at SemEval-2025 Task 11: Cross-Lingual Multi-Label Emotion Detection Using Generative Models", "abstract": "With the rapid advancement of global digitalization, users from different\ncountries increasingly rely on social media for information exchange. In this\ncontext, multilingual multi-label emotion detection has emerged as a critical\nresearch area. This study addresses SemEval-2025 Task 11: Bridging the Gap in\nText-Based Emotion Detection. Our paper focuses on two sub-tracks of this task:\n(1) Track A: Multi-label emotion detection, and (2) Track B: Emotion intensity.\nTo tackle multilingual challenges, we leverage pre-trained multilingual models\nand focus on two architectures: (1) a fine-tuned BERT-based classification\nmodel and (2) an instruction-tuned generative LLM. Additionally, we propose two\nmethods for handling multi-label classification: the base method, which maps an\ninput directly to all its corresponding emotion labels, and the pairwise\nmethod, which models the relationship between the input text and each emotion\ncategory individually. Experimental results demonstrate the strong\ngeneralization ability of our approach in multilingual emotion recognition. In\nTrack A, our method achieved Top 4 performance across 10 languages, ranking 1st\nin Hindi. In Track B, our approach also secured Top 5 performance in 7\nlanguages, highlighting its simplicity and effectiveness\\footnote{Our code is\navailable at https://github.com/yingjie7/mlingual_multilabel_emo_detection.", "published": "2025-05-19 15:24:53", "link": "http://arxiv.org/abs/2505.13244v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SAKURA: On the Multi-hop Reasoning of Large Audio-Language Models Based on Speech and Audio Information", "abstract": "Large audio-language models (LALMs) extend the large language models with\nmultimodal understanding in speech, audio, etc. While their performances on\nspeech and audio-processing tasks are extensively studied, their reasoning\nabilities remain underexplored. Particularly, their multi-hop reasoning, the\nability to recall and integrate multiple facts, lacks systematic evaluation.\nExisting benchmarks focus on general speech and audio-processing tasks,\nconversational abilities, and fairness but overlook this aspect. To bridge this\ngap, we introduce SAKURA, a benchmark assessing LALMs' multi-hop reasoning\nbased on speech and audio information. Results show that LALMs struggle to\nintegrate speech/audio representations for multi-hop reasoning, even when they\nextract the relevant information correctly, highlighting a fundamental\nchallenge in multimodal reasoning. Our findings expose a critical limitation in\nLALMs, offering insights and resources for future research.", "published": "2025-05-19 15:20:32", "link": "http://arxiv.org/abs/2505.13237v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Scaling Computer-Use Grounding via User Interface Decomposition and Synthesis", "abstract": "Graphical user interface (GUI) grounding, the ability to map natural language\ninstructions to specific actions on graphical user interfaces, remains a\ncritical bottleneck in computer use agent development. Current benchmarks\noversimplify grounding tasks as short referring expressions, failing to capture\nthe complexity of real-world interactions that require software commonsense,\nlayout understanding, and fine-grained manipulation capabilities. To address\nthese limitations, we introduce OSWorld-G, a comprehensive benchmark comprising\n564 finely annotated samples across diverse task types including text matching,\nelement recognition, layout understanding, and precise manipulation.\nAdditionally, we synthesize and release the largest computer use grounding\ndataset Jedi, which contains 4 million examples through multi-perspective\ndecoupling of tasks. Our multi-scale models trained on Jedi demonstrate its\neffectiveness by outperforming existing approaches on ScreenSpot-v2,\nScreenSpot-Pro, and our OSWorld-G. Furthermore, we demonstrate that improved\ngrounding with Jedi directly enhances agentic capabilities of general\nfoundation models on complex computer tasks, improving from 5% to 27% on\nOSWorld. Through detailed ablation studies, we identify key factors\ncontributing to grounding performance and verify that combining specialized\ndata for different interface elements enables compositional generalization to\nnovel interfaces. All benchmark, data, checkpoints, and code are open-sourced\nand available at https://osworld-grounding.github.io.", "published": "2025-05-19 15:09:23", "link": "http://arxiv.org/abs/2505.13227v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC"], "primary_category": "cs.AI"}
{"title": "SeedBench: A Multi-task Benchmark for Evaluating Large Language Models in Seed Science", "abstract": "Seed science is essential for modern agriculture, directly influencing crop\nyields and global food security. However, challenges such as interdisciplinary\ncomplexity and high costs with limited returns hinder progress, leading to a\nshortage of experts and insufficient technological support. While large\nlanguage models (LLMs) have shown promise across various fields, their\napplication in seed science remains limited due to the scarcity of digital\nresources, complex gene-trait relationships, and the lack of standardized\nbenchmarks. To address this gap, we introduce SeedBench -- the first multi-task\nbenchmark specifically designed for seed science. Developed in collaboration\nwith domain experts, SeedBench focuses on seed breeding and simulates key\naspects of modern breeding processes. We conduct a comprehensive evaluation of\n26 leading LLMs, encompassing proprietary, open-source, and domain-specific\nfine-tuned models. Our findings not only highlight the substantial gaps between\nthe power of LLMs and the real-world seed science problems, but also make a\nfoundational step for research on LLMs for seed design.", "published": "2025-05-19 15:02:59", "link": "http://arxiv.org/abs/2505.13220v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Picturized and Recited with Dialects: A Multimodal Chinese Representation Framework for Sentiment Analysis of Classical Chinese Poetry", "abstract": "Classical Chinese poetry is a vital and enduring part of Chinese literature,\nconveying profound emotional resonance. Existing studies analyze sentiment\nbased on textual meanings, overlooking the unique rhythmic and visual features\ninherent in poetry,especially since it is often recited and accompanied by\nChinese paintings. In this work, we propose a dialect-enhanced multimodal\nframework for classical Chinese poetry sentiment analysis. We extract\nsentence-level audio features from the poetry and incorporate audio from\nmultiple dialects,which may retain regional ancient Chinese phonetic features,\nenriching the phonetic representation. Additionally, we generate sentence-level\nvisual features, and the multimodal features are fused with textual features\nenhanced by LLM translation through multimodal contrastive representation\nlearning. Our framework outperforms state-of-the-art methods on two public\ndatasets, achieving at least 2.51% improvement in accuracy and 1.63% in macro\nF1. We open-source the code to facilitate research in this area and provide\ninsights for general multimodal Chinese representation.", "published": "2025-05-19 14:58:44", "link": "http://arxiv.org/abs/2505.13210v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Efficient Generation of Parameterised Quantum Circuits from Large Texts", "abstract": "Quantum approaches to natural language processing (NLP) are redefining how\nlinguistic information is represented and processed. While traditional hybrid\nquantum-classical models rely heavily on classical neural networks, recent\nadvancements propose a novel framework, DisCoCirc, capable of directly encoding\nentire documents as parameterised quantum circuits (PQCs), besides enjoying\nsome additional interpretability and compositionality benefits. Following these\nideas, this paper introduces an efficient methodology for converting\nlarge-scale texts into quantum circuits using tree-like representations of\npregroup diagrams. Exploiting the compositional parallels between language and\nquantum mechanics, grounded in symmetric monoidal categories, our approach\nenables faithful and efficient encoding of syntactic and discourse\nrelationships in long and complex texts (up to 6410 words in our experiments)\nto quantum circuits. The developed system is provided to the community as part\nof the augmented open-source quantum NLP package lambeq Gen II.", "published": "2025-05-19 14:57:53", "link": "http://arxiv.org/abs/2505.13208v1", "categories": ["quant-ph", "cs.AI", "cs.CL"], "primary_category": "quant-ph"}
{"title": "Alignment-Augmented Speculative Decoding with Alignment Sampling and Conditional Verification", "abstract": "Recent works have revealed the great potential of speculative decoding in\naccelerating the autoregressive generation process of large language models.\nThe success of these methods relies on the alignment between draft candidates\nand the sampled outputs of the target model. Existing methods mainly achieve\ndraft-target alignment with training-based methods, e.g., EAGLE, Medusa,\ninvolving considerable training costs. In this paper, we present a\ntraining-free alignment-augmented speculative decoding algorithm. We propose\nalignment sampling, which leverages output distribution obtained in the\nprefilling phase to provide more aligned draft candidates. To further benefit\nfrom high-quality but non-aligned draft candidates, we also introduce a simple\nyet effective flexible verification strategy. Through an adaptive probability\nthreshold, our approach can improve generation accuracy while further improving\ninference efficiency. Experiments on 8 datasets (including question answering,\nsummarization and code completion tasks) show that our approach increases the\naverage generation score by 3.3 points for the LLaMA3 model. Our method\nachieves a mean acceptance length up to 2.39 and speed up generation by 2.23.", "published": "2025-05-19 14:55:41", "link": "http://arxiv.org/abs/2505.13204v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Speech Language Modeling via Energy Distance in Continuous Latent Space", "abstract": "We introduce SLED, an alternative approach to speech language modeling by\nencoding speech waveforms into sequences of continuous latent representations\nand modeling them autoregressively using an energy distance objective. The\nenergy distance offers an analytical measure of the distributional gap by\ncontrasting simulated and target samples, enabling efficient training to\ncapture the underlying continuous autoregressive distribution. By bypassing\nreliance on residual vector quantization, SLED avoids discretization errors and\neliminates the need for the complicated hierarchical architectures common in\nexisting speech language models. It simplifies the overall modeling pipeline\nwhile preserving the richness of speech information and maintaining inference\nefficiency. Empirical results demonstrate that SLED achieves strong performance\nin both zero-shot and streaming speech synthesis, showing its potential for\nbroader applications in general-purpose speech language models.", "published": "2025-05-19 14:38:59", "link": "http://arxiv.org/abs/2505.13181v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "ToolSpectrum : Towards Personalized Tool Utilization for Large Language Models", "abstract": "While integrating external tools into large language models (LLMs) enhances\ntheir ability to access real-time information and domain-specific services,\nexisting approaches focus narrowly on functional tool selection following user\ninstructions, overlooking the context-aware personalization in tool selection.\nThis oversight leads to suboptimal user satisfaction and inefficient tool\nutilization, particularly when overlapping toolsets require nuanced selection\nbased on contextual factors. To bridge this gap, we introduce ToolSpectrum, a\nbenchmark designed to evaluate LLMs' capabilities in personalized tool\nutilization. Specifically, we formalize two key dimensions of personalization,\nuser profile and environmental factors, and analyze their individual and\nsynergistic impacts on tool utilization. Through extensive experiments on\nToolSpectrum, we demonstrate that personalized tool utilization significantly\nimproves user experience across diverse scenarios. However, even\nstate-of-the-art LLMs exhibit the limited ability to reason jointly about user\nprofiles and environmental factors, often prioritizing one dimension at the\nexpense of the other. Our findings underscore the necessity of context-aware\npersonalization in tool-augmented LLMs and reveal critical limitations for\ncurrent models. Our data and code are available at\nhttps://github.com/Chengziha0/ToolSpectrum.", "published": "2025-05-19 14:30:46", "link": "http://arxiv.org/abs/2505.13176v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Case Study of Cross-Lingual Zero-Shot Generalization for Classical Languages in LLMs", "abstract": "Large Language Models (LLMs) have demonstrated remarkable generalization\ncapabilities across diverse tasks and languages. In this study, we focus on\nnatural language understanding in three classical languages -- Sanskrit,\nAncient Greek and Latin -- to investigate the factors affecting cross-lingual\nzero-shot generalization. First, we explore named entity recognition and\nmachine translation into English. While LLMs perform equal to or better than\nfine-tuned baselines on out-of-domain data, smaller models often struggle,\nespecially with niche or abstract entity types. In addition, we concentrate on\nSanskrit by presenting a factoid question-answering (QA) dataset and show that\nincorporating context via retrieval-augmented generation approach significantly\nboosts performance. In contrast, we observe pronounced performance drops for\nsmaller LLMs across these QA tasks. These results suggest model scale as an\nimportant factor influencing cross-lingual generalization. Assuming that models\nused such as GPT-4o and Llama-3.1 are not instruction fine-tuned on classical\nlanguages, our findings provide insights into how LLMs may generalize on these\nlanguages and their consequent utility in classical studies.", "published": "2025-05-19 14:30:10", "link": "http://arxiv.org/abs/2505.13173v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Positional Fragility in LLMs: How Offset Effects Reshape Our Understanding of Memorization Risks", "abstract": "Large language models are known to memorize parts of their training data,\nposing risk of copyright violations. To systematically examine this risk, we\npretrain language models (1B/3B/8B) from scratch on 83B tokens, mixing\nweb-scale data with public domain books used to simulate copyrighted content at\ncontrolled frequencies at lengths at least ten times longer than prior work. We\nthereby identified the offset effect, a phenomenon characterized by two key\nfindings: (1) verbatim memorization is most strongly triggered by short\nprefixes drawn from the beginning of the context window, with memorization\ndecreasing counterintuitively as prefix length increases; and (2) a sharp\ndecline in verbatim recall when prefix begins offset from the initial tokens of\nthe context window. We attribute this to positional fragility: models rely\ndisproportionately on the earliest tokens in their context window as retrieval\nanchors, making them sensitive to even slight shifts. We further observe that\nwhen the model fails to retrieve memorized content, it often produces\ndegenerated text. Leveraging these findings, we show that shifting sensitive\ndata deeper into the context window suppresses both extractable memorization\nand degeneration. Our results suggest that positional offset is a critical and\npreviously overlooked axis for evaluating memorization risks, since prior work\nimplicitly assumed uniformity by probing only from the beginning of training\nsequences.", "published": "2025-05-19 14:28:35", "link": "http://arxiv.org/abs/2505.13171v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Role-Playing Evaluation for Large Language Models", "abstract": "Large Language Models (LLMs) demonstrate a notable capacity for adopting\npersonas and engaging in role-playing. However, evaluating this ability\npresents significant challenges, as human assessments are resource-intensive\nand automated evaluations can be biased. To address this, we introduce\nRole-Playing Eval (RPEval), a novel benchmark designed to assess LLM\nrole-playing capabilities across four key dimensions: emotional understanding,\ndecision-making, moral alignment, and in-character consistency. This article\ndetails the construction of RPEval and presents baseline evaluations. Our code\nand dataset are available at https://github.com/yelboudouri/RPEval", "published": "2025-05-19 14:18:16", "link": "http://arxiv.org/abs/2505.13157v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Tianyi: A Traditional Chinese Medicine all-rounder language model and its Real-World Clinical Practice", "abstract": "Natural medicines, particularly Traditional Chinese Medicine (TCM), are\ngaining global recognition for their therapeutic potential in addressing human\nsymptoms and diseases. TCM, with its systematic theories and extensive\npractical experience, provides abundant resources for healthcare. However, the\neffective application of TCM requires precise syndrome diagnosis, determination\nof treatment principles, and prescription formulation, which demand decades of\nclinical expertise. Despite advancements in TCM-based decision systems, machine\nlearning, and deep learning research, limitations in data and single-objective\nconstraints hinder their practical application. In recent years, large language\nmodels (LLMs) have demonstrated potential in complex tasks, but lack\nspecialization in TCM and face significant challenges, such as too big model\nscale to deploy and issues with hallucination. To address these challenges, we\nintroduce Tianyi with 7.6-billion-parameter LLM, a model scale proper and\nspecifically designed for TCM, pre-trained and fine-tuned on diverse TCM\ncorpora, including classical texts, expert treatises, clinical records, and\nknowledge graphs. Tianyi is designed to assimilate interconnected and\nsystematic TCM knowledge through a progressive learning manner. Additionally,\nwe establish TCMEval, a comprehensive evaluation benchmark, to assess LLMs in\nTCM examinations, clinical tasks, domain-specific question-answering, and\nreal-world trials. The extensive evaluations demonstrate the significant\npotential of Tianyi as an AI assistant in TCM clinical practice and research,\nbridging the gap between TCM knowledge and practical application.", "published": "2025-05-19 14:17:37", "link": "http://arxiv.org/abs/2505.13156v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "What if Deception Cannot be Detected? A Cross-Linguistic Study on the Limits of Deception Detection from Text", "abstract": "Can deception be detected solely from written text? Cues of deceptive\ncommunication are inherently subtle, even more so in text-only communication.\nYet, prior studies have reported considerable success in automatic deception\ndetection. We hypothesize that such findings are largely driven by artifacts\nintroduced during data collection and do not generalize beyond specific\ndatasets. We revisit this assumption by introducing a belief-based deception\nframework, which defines deception as a misalignment between an author's claims\nand true beliefs, irrespective of factual accuracy, allowing deception cues to\nbe studied in isolation. Based on this framework, we construct three corpora,\ncollectively referred to as DeFaBel, including a German-language corpus of\ndeceptive and non-deceptive arguments and a multilingual version in German and\nEnglish, each collected under varying conditions to account for belief change\nand enable cross-linguistic analysis. Using these corpora, we evaluate commonly\nreported linguistic cues of deception. Across all three DeFaBel variants, these\ncues show negligible, statistically insignificant correlations with deception\nlabels, contrary to prior work that treats such cues as reliable indicators. We\nfurther benchmark against other English deception datasets following similar\ndata collection protocols. While some show statistically significant\ncorrelations, effect sizes remain low and, critically, the set of predictive\ncues is inconsistent across datasets. We also evaluate deception detection\nusing feature-based models, pretrained language models, and instruction-tuned\nlarge language models. While some models perform well on established deception\ndatasets, they consistently perform near chance on DeFaBel. Our findings\nchallenge the assumption that deception can be reliably inferred from\nlinguistic cues and call for rethinking how deception is studied and modeled in\nNLP.", "published": "2025-05-19 14:12:05", "link": "http://arxiv.org/abs/2505.13147v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Understanding Cross-Lingual Inconsistency in Large Language Models", "abstract": "Large language models (LLMs) are demonstrably capable of cross-lingual\ntransfer, but can produce inconsistent output when prompted with the same\nqueries written in different languages. To understand how language models are\nable to generalize knowledge from one language to the others, we apply the\nlogit lens to interpret the implicit steps taken by LLMs to solve multilingual\nmulti-choice reasoning questions. We find LLMs predict inconsistently and are\nless accurate because they rely on subspaces of individual languages, rather\nthan working in a shared semantic space. While larger models are more\nmultilingual, we show their hidden states are more likely to dissociate from\nthe shared representation compared to smaller models, but are nevertheless more\ncapable of retrieving knowledge embedded across different languages. Finally,\nwe demonstrate that knowledge sharing can be modulated by steering the models'\nlatent processing towards the shared semantic space. We find reinforcing\nutilization of the shared space improves the models' multilingual reasoning\nperformance, as a result of more knowledge transfer from, and better output\nconsistency with English.", "published": "2025-05-19 14:10:15", "link": "http://arxiv.org/abs/2505.13141v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ModernGBERT: German-only 1B Encoder Model Trained from Scratch", "abstract": "Despite the prominence of decoder-only language models, encoders remain\ncrucial for resource-constrained applications. We introduce ModernGBERT (134M,\n1B), a fully transparent family of German encoder models trained from scratch,\nincorporating architectural innovations from ModernBERT. To evaluate the\npractical trade-offs of training encoders from scratch, we also present\nLL\\\"aMmlein2Vec (120M, 1B, 7B), a family of encoders derived from German\ndecoder-only models via LLM2Vec. We benchmark all models on natural language\nunderstanding, text embedding, and long-context reasoning tasks, enabling a\ncontrolled comparison between dedicated encoders and converted decoders. Our\nresults show that ModernGBERT 1B outperforms prior state-of-the-art German\nencoders as well as encoders adapted via LLM2Vec, with regard to performance\nand parameter-efficiency. All models, training data, checkpoints and code are\npublicly available, advancing the German NLP ecosystem with transparent,\nhigh-performance encoder models.", "published": "2025-05-19 14:07:20", "link": "http://arxiv.org/abs/2505.13136v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Zero-Shot Iterative Formalization and Planning in Partially Observable Environments", "abstract": "In planning, using LLMs not to predict plans but to formalize an environment\ninto the Planning Domain Definition Language (PDDL) has been shown to greatly\nimprove performance and control. While most work focused on fully observable\nenvironments, we tackle the more realistic and challenging partially observable\nenvironments where existing methods are incapacitated by the lack of complete\ninformation. We propose PDDLego+, a framework to iteratively formalize, plan,\ngrow, and refine PDDL representations in a zero-shot manner, without needing\naccess to any existing trajectories. On two textual simulated environments, we\nshow that PDDLego+ not only achieves superior performance, but also shows\nrobustness against problem complexity. We also show that the domain knowledge\ncaptured after a successful trial is interpretable and benefits future tasks.", "published": "2025-05-19 13:58:15", "link": "http://arxiv.org/abs/2505.13126v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Benchmarking and Confidence Evaluation of LALMs For Temporal Reasoning", "abstract": "The popular success of text-based large language models (LLM) has streamlined\nthe attention of the multimodal community to combine other modalities like\nvision and audio along with text to achieve similar multimodal capabilities. In\nthis quest, large audio language models (LALMs) have to be evaluated on\nreasoning related tasks which are different from traditional classification or\ngeneration tasks. Towards this goal, we propose a novel dataset called temporal\nreasoning evaluation of audio (TREA).\n  We benchmark open-source LALMs and observe that they are consistently behind\nhuman capabilities on the tasks in the TREA dataset. While evaluating LALMs, we\nalso propose an uncertainty metric, which computes the invariance of the model\nto semantically identical perturbations of the input. Our analysis shows that\nthe accuracy and uncertainty metrics are not necessarily correlated and thus,\npoints to a need for wholesome evaluation of LALMs for high-stakes\napplications.", "published": "2025-05-19 13:46:35", "link": "http://arxiv.org/abs/2505.13115v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "FreeKV: Boosting KV Cache Retrieval for Efficient LLM Inference", "abstract": "Large language models (LLMs) have been widely deployed with rapidly expanding\ncontext windows to support increasingly demanding applications. However, long\ncontexts pose significant deployment challenges, primarily due to the KV cache\nwhose size grows proportionally with context length. While KV cache compression\nmethods are proposed to address this issue, KV dropping methods incur\nconsiderable accuracy loss, and KV retrieval methods suffer from significant\nefficiency bottlenecks. We propose FreeKV, an algorithm-system co-optimization\nframework to enhance KV retrieval efficiency while preserving accuracy. On the\nalgorithm side, FreeKV introduces speculative retrieval to shift the KV\nselection and recall processes out of the critical path, combined with\nfine-grained correction to ensure accuracy. On the system side, FreeKV employs\nhybrid KV layouts across CPU and GPU memory to eliminate fragmented data\ntransfers, and leverages double-buffered streamed recall to further improve\nefficiency. Experiments demonstrate that FreeKV achieves near-lossless accuracy\nacross various scenarios and models, delivering up to 13$\\times$ speedup\ncompared to SOTA KV retrieval methods.", "published": "2025-05-19 13:36:45", "link": "http://arxiv.org/abs/2505.13109v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "LLM-KG-Bench 3.0: A Compass for SemanticTechnology Capabilities in the Ocean of LLMs", "abstract": "Current Large Language Models (LLMs) can assist developing program code\nbeside many other things, but can they support working with Knowledge Graphs\n(KGs) as well? Which LLM is offering the best capabilities in the field of\nSemantic Web and Knowledge Graph Engineering (KGE)? Is this possible to\ndetermine without checking many answers manually? The LLM-KG-Bench framework in\nVersion 3.0 is designed to answer these questions. It consists of an extensible\nset of tasks for automated evaluation of LLM answers and covers different\naspects of working with semantic technologies. In this paper the LLM-KG-Bench\nframework is presented in Version 3 along with a dataset of prompts, answers\nand evaluations generated with it and several state-of-the-art LLMs.\nSignificant enhancements have been made to the framework since its initial\nrelease, including an updated task API that offers greater flexibility in\nhandling evaluation tasks, revised tasks, and extended support for various open\nmodels through the vllm library, among other improvements. A comprehensive\ndataset has been generated using more than 30 contemporary open and proprietary\nLLMs, enabling the creation of exemplary model cards that demonstrate the\nmodels' capabilities in working with RDF and SPARQL, as well as comparing their\nperformance on Turtle and JSON-LD RDF serialization tasks.", "published": "2025-05-19 13:29:27", "link": "http://arxiv.org/abs/2505.13098v1", "categories": ["cs.AI", "cs.CL", "cs.DB"], "primary_category": "cs.AI"}
{"title": "The Effect of Language Diversity When Fine-Tuning Large Language Models for Translation", "abstract": "Prior research diverges on language diversity in LLM fine-tuning: Some\nstudies report benefits while others find no advantages. Through controlled\nfine-tuning experiments across 132 translation directions, we systematically\nresolve these disparities. We find that expanding language diversity during\nfine-tuning improves translation quality for both unsupervised and --\nsurprisingly -- supervised pairs, despite less diverse models being fine-tuned\nexclusively on these supervised pairs. However, benefits plateau or decrease\nbeyond a certain diversity threshold. We show that increased language diversity\ncreates more language-agnostic representations. These representational\nadaptations help explain the improved performance in models fine-tuned with\ngreater diversity.", "published": "2025-05-19 13:24:01", "link": "http://arxiv.org/abs/2505.13090v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Systematic Generalization in Language Models Scales with Information Entropy", "abstract": "Systematic generalization remains challenging for current language models,\nwhich are known to be both sensitive to semantically similar permutations of\nthe input and to struggle with known concepts presented in novel contexts.\nAlthough benchmarks exist for assessing compositional behavior, it is unclear\nhow to measure the difficulty of a systematic generalization problem. In this\nwork, we show how one aspect of systematic generalization can be described by\nthe entropy of the distribution of component parts in the training data. We\nformalize a framework for measuring entropy in a sequence-to-sequence task and\nfind that the performance of popular model architectures scales with the\nentropy. Our work connects systematic generalization to information efficiency,\nand our results indicate that success at high entropy can be achieved even\nwithout built-in priors, and that success at low entropy can serve as a target\nfor assessing progress towards robust systematic generalization.", "published": "2025-05-19 13:23:44", "link": "http://arxiv.org/abs/2505.13089v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Advancing Sequential Numerical Prediction in Autoregressive Models", "abstract": "Autoregressive models have become the de facto choice for sequence generation\ntasks, but standard approaches treat digits as independent tokens and apply\ncross-entropy loss, overlooking the coherent structure of numerical sequences.\nThis paper introduces Numerical Token Integrity Loss (NTIL) to address this\ngap. NTIL operates at two levels: (1) token-level, where it extends the Earth\nMover's Distance (EMD) to preserve ordinal relationships between numerical\nvalues, and (2) sequence-level, where it penalizes the overall discrepancy\nbetween the predicted and actual sequences. This dual approach improves\nnumerical prediction and integrates effectively with LLMs/MLLMs. Extensive\nexperiments show significant performance improvements with NTIL.", "published": "2025-05-19 13:11:28", "link": "http://arxiv.org/abs/2505.13077v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Suicide Risk Assessment Using Multimodal Speech Features: A Study on the SW1 Challenge Dataset", "abstract": "The 1st SpeechWellness Challenge conveys the need for speech-based suicide\nrisk assessment in adolescents. This study investigates a multimodal approach\nfor this challenge, integrating automatic transcription with WhisperX,\nlinguistic embeddings from Chinese RoBERTa, and audio embeddings from WavLM.\nAdditionally, handcrafted acoustic features -- including MFCCs, spectral\ncontrast, and pitch-related statistics -- were incorporated. We explored three\nfusion strategies: early concatenation, modality-specific processing, and\nweighted attention with mixup regularization. Results show that weighted\nattention provided the best generalization, achieving 69% accuracy on the\ndevelopment set, though a performance gap between development and test sets\nhighlights generalization challenges. Our findings, strictly tied to the\nMINI-KID framework, emphasize the importance of refining embedding\nrepresentations and fusion mechanisms to enhance classification reliability.", "published": "2025-05-19 13:04:37", "link": "http://arxiv.org/abs/2505.13069v1", "categories": ["cs.CL", "cs.SD", "eess.AS", "I.2.7; I.5.1"], "primary_category": "cs.CL"}
{"title": "SNAPE-PM: Building and Utilizing Dynamic Partner Models for Adaptive Explanation Generation", "abstract": "Adapting to the addressee is crucial for successful explanations, yet poses\nsignificant challenges for dialogsystems. We adopt the approach of treating\nexplanation generation as a non-stationary decision process, where the optimal\nstrategy varies according to changing beliefs about the explainee and the\ninteraction context. In this paper we address the questions of (1) how to track\nthe interaction context and the relevant listener features in a formally\ndefined computational partner model, and (2) how to utilize this model in the\ndynamically adjusted, rational decision process that determines the currently\nbest explanation strategy. We propose a Bayesian inference-based approach to\ncontinuously update the partner model based on user feedback, and a\nnon-stationary Markov Decision Process to adjust decision-making based on the\npartner model values. We evaluate an implementation of this framework with five\nsimulated interlocutors, demonstrating its effectiveness in adapting to\ndifferent partners with constant and even changing feedback behavior. The\nresults show high adaptivity with distinct explanation strategies emerging for\ndifferent partners, highlighting the potential of our approach to improve\nexplainable AI systems and dialogsystems in general.", "published": "2025-05-19 12:42:23", "link": "http://arxiv.org/abs/2505.13053v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "KIT's Offline Speech Translation and Instruction Following Submission for IWSLT 2025", "abstract": "The scope of the International Workshop on Spoken Language Translation\n(IWSLT) has recently broadened beyond traditional Speech Translation (ST) to\nencompass a wider array of tasks, including Speech Question Answering and\nSummarization. This shift is partly driven by the growing capabilities of\nmodern systems, particularly with the success of Large Language Models (LLMs).\nIn this paper, we present the Karlsruhe Institute of Technology's submissions\nfor the Offline ST and Instruction Following (IF) tracks, where we leverage\nLLMs to enhance performance across all tasks. For the Offline ST track, we\npropose a pipeline that employs multiple automatic speech recognition systems,\nwhose outputs are fused using an LLM with document-level context. This is\nfollowed by a two-step translation process, incorporating additional refinement\nstep to improve translation quality. For the IF track, we develop an end-to-end\nmodel that integrates a speech encoder with an LLM to perform a wide range of\ninstruction-following tasks. We complement it with a final document-level\nrefinement stage to further enhance output quality by using contextual\ninformation.", "published": "2025-05-19 12:21:29", "link": "http://arxiv.org/abs/2505.13036v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "topicwizard -- a Modern, Model-agnostic Framework for Topic Model Visualization and Interpretation", "abstract": "Topic models are statistical tools that allow their users to gain qualitative\nand quantitative insights into the contents of textual corpora without the need\nfor close reading. They can be applied in a wide range of settings from\ndiscourse analysis, through pretraining data curation, to text filtering. Topic\nmodels are typically parameter-rich, complex models, and interpreting these\nparameters can be challenging for their users. It is typical practice for users\nto interpret topics based on the top 10 highest ranking terms on a given topic.\nThis list-of-words approach, however, gives users a limited and biased picture\nof the content of topics. Thoughtful user interface design and visualizations\ncan help users gain a more complete and accurate understanding of topic models'\noutput. While some visualization utilities do exist for topic models, these are\ntypically limited to a certain type of topic model. We introduce topicwizard, a\nframework for model-agnostic topic model interpretation, that provides\nintuitive and interactive tools that help users examine the complex semantic\nrelations between documents, words and topics learned by topic models.", "published": "2025-05-19 12:19:01", "link": "http://arxiv.org/abs/2505.13034v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MMAR: A Challenging Benchmark for Deep Reasoning in Speech, Audio, Music, and Their Mix", "abstract": "We introduce MMAR, a new benchmark designed to evaluate the deep reasoning\ncapabilities of Audio-Language Models (ALMs) across massive multi-disciplinary\ntasks. MMAR comprises 1,000 meticulously curated audio-question-answer\ntriplets, collected from real-world internet videos and refined through\niterative error corrections and quality checks to ensure high quality. Unlike\nexisting benchmarks that are limited to specific domains of sound, music, or\nspeech, MMAR extends them to a broad spectrum of real-world audio scenarios,\nincluding mixed-modality combinations of sound, music, and speech. Each\nquestion in MMAR is hierarchically categorized across four reasoning layers:\nSignal, Perception, Semantic, and Cultural, with additional sub-categories\nwithin each layer to reflect task diversity and complexity. To further foster\nresearch in this area, we annotate every question with a Chain-of-Thought (CoT)\nrationale to promote future advancements in audio reasoning. Each item in the\nbenchmark demands multi-step deep reasoning beyond surface-level understanding.\nMoreover, a part of the questions requires graduate-level perceptual and\ndomain-specific knowledge, elevating the benchmark's difficulty and depth. We\nevaluate MMAR using a broad set of models, including Large Audio-Language\nModels (LALMs), Large Audio Reasoning Models (LARMs), Omni Language Models\n(OLMs), Large Language Models (LLMs), and Large Reasoning Models (LRMs), with\naudio caption inputs. The performance of these models on MMAR highlights the\nbenchmark's challenging nature, and our analysis further reveals critical\nlimitations of understanding and reasoning capabilities among current models.\nWe hope MMAR will serve as a catalyst for future advances in this important but\nlittle-explored area.", "published": "2025-05-19 12:18:42", "link": "http://arxiv.org/abs/2505.13032v1", "categories": ["cs.SD", "cs.CL", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Evaluatiing the efficacy of LLM Safety Solutions : The Palit Benchmark Dataset", "abstract": "Large Language Models (LLMs) are increasingly integrated into critical\nsystems in industries like healthcare and finance. Users can often submit\nqueries to LLM-enabled chatbots, some of which can enrich responses with\ninformation retrieved from internal databases storing sensitive data. This\ngives rise to a range of attacks in which a user submits a malicious query and\nthe LLM-system outputs a response that creates harm to the owner, such as\nleaking internal data or creating legal liability by harming a third-party.\nWhile security tools are being developed to counter these threats, there is\nlittle formal evaluation of their effectiveness and usability. This study\naddresses this gap by conducting a thorough comparative analysis of LLM\nsecurity tools. We identified 13 solutions (9 closed-source, 4 open-source),\nbut only 7 were evaluated due to a lack of participation by proprietary model\nowners.To evaluate, we built a benchmark dataset of malicious prompts, and\nevaluate these tools performance against a baseline LLM model\n(ChatGPT-3.5-Turbo). Our results show that the baseline model has too many\nfalse positives to be used for this task. Lakera Guard and ProtectAI LLM Guard\nemerged as the best overall tools showcasing the tradeoff between usability and\nperformance. The study concluded with recommendations for greater transparency\namong closed source providers, improved context-aware detections, enhanced\nopen-source engagement, increased user awareness, and the adoption of more\nrepresentative performance metrics.", "published": "2025-05-19 12:12:00", "link": "http://arxiv.org/abs/2505.13028v1", "categories": ["cs.CR", "cs.AI", "cs.CL", "F.2.2, I.2.7; F.2.2, I.2.7; F.2.2, I.2.7"], "primary_category": "cs.CR"}
{"title": "To Bias or Not to Bias: Detecting bias in News with bias-detector", "abstract": "Media bias detection is a critical task in ensuring fair and balanced\ninformation dissemination, yet it remains challenging due to the subjectivity\nof bias and the scarcity of high-quality annotated data. In this work, we\nperform sentence-level bias classification by fine-tuning a RoBERTa-based model\non the expert-annotated BABE dataset. Using McNemar's test and the 5x2\ncross-validation paired t-test, we show statistically significant improvements\nin performance when comparing our model to a domain-adaptively pre-trained\nDA-RoBERTa baseline. Furthermore, attention-based analysis shows that our model\navoids common pitfalls like oversensitivity to politically charged terms and\ninstead attends more meaningfully to contextually relevant tokens. For a\ncomprehensive examination of media bias, we present a pipeline that combines\nour model with an already-existing bias-type classifier. Our method exhibits\ngood generalization and interpretability, despite being constrained by\nsentence-level analysis and dataset size because of a lack of larger and more\nadvanced bias corpora. We talk about context-aware modeling, bias\nneutralization, and advanced bias type classification as potential future\ndirections. Our findings contribute to building more robust, explainable, and\nsocially responsible NLP systems for media bias detection.", "published": "2025-05-19 11:54:39", "link": "http://arxiv.org/abs/2505.13010v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Evaluating the Performance of RAG Methods for Conversational AI in the Airport Domain", "abstract": "Airports from the top 20 in terms of annual passengers are highly dynamic\nenvironments with thousands of flights daily, and they aim to increase the\ndegree of automation. To contribute to this, we implemented a Conversational AI\nsystem that enables staff in an airport to communicate with flight information\nsystems. This system not only answers standard airport queries but also\nresolves airport terminology, jargon, abbreviations, and dynamic questions\ninvolving reasoning. In this paper, we built three different\nRetrieval-Augmented Generation (RAG) methods, including traditional RAG, SQL\nRAG, and Knowledge Graph-based RAG (Graph RAG). Experiments showed that\ntraditional RAG achieved 84.84% accuracy using BM25 + GPT-4 but occasionally\nproduced hallucinations, which is risky to airport safety. In contrast, SQL RAG\nand Graph RAG achieved 80.85% and 91.49% accuracy respectively, with\nsignificantly fewer hallucinations. Moreover, Graph RAG was especially\neffective for questions that involved reasoning. Based on our observations, we\nthus recommend SQL RAG and Graph RAG are better for airport environments, due\nto fewer hallucinations and the ability to handle dynamic questions.", "published": "2025-05-19 11:46:30", "link": "http://arxiv.org/abs/2505.13006v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EffiBench-X: A Multi-Language Benchmark for Measuring Efficiency of LLM-Generated Code", "abstract": "Existing code generation benchmarks primarily evaluate functional\ncorrectness, with limited focus on code efficiency and often restricted to a\nsingle language like Python. To address this gap, we introduce EffiBench-X, the\nfirst multi-language benchmark designed to measure the efficiency of\nLLM-generated code. EffiBench-X supports Python, C++, Java, JavaScript, Ruby,\nand Golang. It comprises competitive programming tasks with human-expert\nsolutions as efficiency baselines. Evaluating state-of-the-art LLMs on\nEffiBench-X reveals that while models generate functionally correct code, they\nconsistently underperform human experts in efficiency. Even the most efficient\nLLM-generated solutions (Qwen3-32B) achieve only around \\textbf{62\\%} of human\nefficiency on average, with significant language-specific variations. LLMs show\nbetter efficiency in Python, Ruby, and JavaScript than in Java, C++, and\nGolang. For instance, DeepSeek-R1's Python code is significantly more efficient\nthan its Java code. These results highlight the critical need for research into\nLLM optimization techniques to improve code efficiency across diverse\nlanguages. The dataset and evaluation infrastructure are submitted and\navailable at https://github.com/EffiBench/EffiBench-X.git and\nhttps://huggingface.co/datasets/EffiBench/effibench-x.", "published": "2025-05-19 11:43:37", "link": "http://arxiv.org/abs/2505.13004v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ExTrans: Multilingual Deep Reasoning Translation via Exemplar-Enhanced Reinforcement Learning", "abstract": "In recent years, the emergence of large reasoning models (LRMs), such as\nOpenAI-o1 and DeepSeek-R1, has shown impressive capabilities in complex\nproblems, e.g., mathematics and coding. Some pioneering studies attempt to\nbring the success of LRMs in neural machine translation (MT). They try to build\nLRMs with deep reasoning MT ability via reinforcement learning (RL). Despite\nsome progress that has been made, these attempts generally focus on several\nhigh-resource languages, e.g., English and Chinese, leaving the performance on\nother languages unclear. Besides, the reward modeling methods in previous work\ndo not fully unleash the potential of reinforcement learning in MT. In this\nwork, we first design a new reward modeling method that compares the\ntranslation results of the policy MT model with a strong LRM (i.e.,\nDeepSeek-R1-671B), and quantifies the comparisons to provide rewards.\nExperimental results demonstrate the superiority of the reward modeling method.\nUsing Qwen2.5-7B-Instruct as the backbone, the trained model achieves the new\nstate-of-the-art performance in literary translation, and outperforms strong\nLRMs including OpenAI-o1 and DeepSeeK-R1. Furthermore, we extend our method to\nthe multilingual settings with 11 languages. With a carefully designed\nlightweight reward modeling in RL, we can simply transfer the strong MT ability\nfrom a single direction into multiple (i.e., 90) translation directions and\nachieve impressive multilingual MT performance.", "published": "2025-05-19 11:34:47", "link": "http://arxiv.org/abs/2505.12996v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Fractured Chain-of-Thought Reasoning", "abstract": "Inference-time scaling techniques have significantly bolstered the reasoning\ncapabilities of large language models (LLMs) by harnessing additional\ncomputational effort at inference without retraining. Similarly,\nChain-of-Thought (CoT) prompting and its extension, Long CoT, improve accuracy\nby generating rich intermediate reasoning trajectories, but these approaches\nincur substantial token costs that impede their deployment in latency-sensitive\nsettings. In this work, we first show that truncated CoT, which stops reasoning\nbefore completion and directly generates the final answer, often matches full\nCoT sampling while using dramatically fewer tokens. Building on this insight,\nwe introduce Fractured Sampling, a unified inference-time strategy that\ninterpolates between full CoT and solution-only sampling along three orthogonal\naxes: (1) the number of reasoning trajectories, (2) the number of final\nsolutions per trajectory, and (3) the depth at which reasoning traces are\ntruncated. Through extensive experiments on five diverse reasoning benchmarks\nand several model scales, we demonstrate that Fractured Sampling consistently\nachieves superior accuracy-cost trade-offs, yielding steep log-linear scaling\ngains in Pass@k versus token budget. Our analysis reveals how to allocate\ncomputation across these dimensions to maximize performance, paving the way for\nmore efficient and scalable LLM reasoning.", "published": "2025-05-19 11:30:41", "link": "http://arxiv.org/abs/2505.12992v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "An Empirical Study of Many-to-Many Summarization with Large Language Models", "abstract": "Many-to-many summarization (M2MS) aims to process documents in any language\nand generate the corresponding summaries also in any language. Recently, large\nlanguage models (LLMs) have shown strong multi-lingual abilities, giving them\nthe potential to perform M2MS in real applications. This work presents a\nsystematic empirical study on LLMs' M2MS ability. Specifically, we first\nreorganize M2MS data based on eight previous domain-specific datasets. The\nreorganized data contains 47.8K samples spanning five domains and six\nlanguages, which could be used to train and evaluate LLMs. Then, we benchmark\n18 LLMs in a zero-shot manner and an instruction-tuning manner. Fine-tuned\ntraditional models (e.g., mBART) are also conducted for comparisons. Our\nexperiments reveal that, zero-shot LLMs achieve competitive results with\nfine-tuned traditional models. After instruct-tuning, open-source LLMs can\nsignificantly improve their M2MS ability, and outperform zero-shot LLMs\n(including GPT-4) in terms of automatic evaluations. In addition, we\ndemonstrate that this task-specific improvement does not sacrifice the LLMs'\ngeneral task-solving abilities. However, as revealed by our human evaluation,\nLLMs still face the factuality issue, and the instruction tuning might\nintensify the issue. Thus, how to control factual errors becomes the key when\nbuilding LLM summarizers in real applications, and is worth noting in future\nresearch.", "published": "2025-05-19 11:18:54", "link": "http://arxiv.org/abs/2505.12983v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Fast, Not Fancy: Rethinking G2P with Rich Data and Rule-Based Models", "abstract": "Homograph disambiguation remains a significant challenge in\ngrapheme-to-phoneme (G2P) conversion, especially for low-resource languages.\nThis challenge is twofold: (1) creating balanced and comprehensive homograph\ndatasets is labor-intensive and costly, and (2) specific disambiguation\nstrategies introduce additional latency, making them unsuitable for real-time\napplications such as screen readers and other accessibility tools. In this\npaper, we address both issues. First, we propose a semi-automated pipeline for\nconstructing homograph-focused datasets, introduce the HomoRich dataset\ngenerated through this pipeline, and demonstrate its effectiveness by applying\nit to enhance a state-of-the-art deep learning-based G2P system for Persian.\nSecond, we advocate for a paradigm shift - utilizing rich offline datasets to\ninform the development of fast, rule-based methods suitable for\nlatency-sensitive accessibility applications like screen readers. To this end,\nwe improve one of the most well-known rule-based G2P systems, eSpeak, into a\nfast homograph-aware version, HomoFast eSpeak. Our results show an approximate\n30% improvement in homograph disambiguation accuracy for the deep\nlearning-based and eSpeak systems.", "published": "2025-05-19 11:11:12", "link": "http://arxiv.org/abs/2505.12973v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Structured Literature Review on Traditional Approaches in Current Natural Language Processing", "abstract": "The continued rise of neural networks and large language models in the more\nrecent past has altered the natural language processing landscape, enabling new\napproaches towards typical language tasks and achieving mainstream success.\nDespite the huge success of large language models, many disadvantages still\nremain and through this work we assess the state of the art in five application\nscenarios with a particular focus on the future perspectives and sensible\napplication scenarios of traditional and older approaches and techniques.\n  In this paper we survey recent publications in the application scenarios\nclassification, information and relation extraction, text simplification as\nwell as text summarization. After defining our terminology, i.e., which\nfeatures are characteristic for traditional techniques in our interpretation\nfor the five scenarios, we survey if such traditional approaches are still\nbeing used, and if so, in what way they are used. It turns out that all five\napplication scenarios still exhibit traditional models in one way or another,\nas part of a processing pipeline, as a comparison/baseline to the core model of\nthe respective paper, or as the main model(s) of the paper. For the complete\nstatistics, see https://zenodo.org/records/13683801", "published": "2025-05-19 11:06:50", "link": "http://arxiv.org/abs/2505.12970v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Calm-Whisper: Reduce Whisper Hallucination On Non-Speech By Calming Crazy Heads Down", "abstract": "OpenAI's Whisper has achieved significant success in Automatic Speech\nRecognition. However, it has consistently been found to exhibit hallucination\nissues, particularly in non-speech segments, which limits its broader\napplication in complex industrial settings.\n  In this paper, we introduce a novel method to reduce Whisper's hallucination\non non-speech segments without using any pre- or post-possessing techniques.\nSpecifically, we benchmark the contribution of each self-attentional head in\nthe Whisper-large-v3 decoder to the hallucination problem by performing a\nhead-wise mask. Our findings reveal that only 3 of the 20 heads account for\nover 75% of the hallucinations on the UrbanSound dataset. We then fine-tune\nthese three crazy heads using a collection of non-speech data. The results show\nthat our best fine-tuned model, namely Calm-Whisper, achieves over 80%\nreduction in non-speech hallucination with only less than 0.1% WER degradation\non LibriSpeech test-clean and test-other.", "published": "2025-05-19 11:04:52", "link": "http://arxiv.org/abs/2505.12969v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MA-COIR: Leveraging Semantic Search Index and Generative Models for Ontology-Driven Biomedical Concept Recognition", "abstract": "Recognizing biomedical concepts in the text is vital for ontology refinement,\nknowledge graph construction, and concept relationship discovery. However,\ntraditional concept recognition methods, relying on explicit mention\nidentification, often fail to capture complex concepts not explicitly stated in\nthe text. To overcome this limitation, we introduce MA-COIR, a framework that\nreformulates concept recognition as an indexing-recognition task. By assigning\nsemantic search indexes (ssIDs) to concepts, MA-COIR resolves ambiguities in\nontology entries and enhances recognition efficiency. Using a pretrained\nBART-based model fine-tuned on small datasets, our approach reduces\ncomputational requirements to facilitate adoption by domain experts.\nFurthermore, we incorporate large language models (LLMs)-generated queries and\nsynthetic data to improve recognition in low-resource settings. Experimental\nresults on three scenarios (CDR, HPO, and HOIP) highlight the effectiveness of\nMA-COIR in recognizing both explicit and implicit concepts without the need for\nmention-level annotations during inference, advancing ontology-driven concept\nrecognition in biomedical domain applications. Our code and constructed data\nare available at https://github.com/sl-633/macoir-master.", "published": "2025-05-19 11:00:43", "link": "http://arxiv.org/abs/2505.12964v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GuRE:Generative Query REwriter for Legal Passage Retrieval", "abstract": "Legal Passage Retrieval (LPR) systems are crucial as they help practitioners\nsave time when drafting legal arguments. However, it remains an underexplored\navenue. One primary reason is the significant vocabulary mismatch between the\nquery and the target passage. To address this, we propose a simple yet\neffective method, the Generative query REwriter (GuRE). We leverage the\ngenerative capabilities of Large Language Models (LLMs) by training the LLM for\nquery rewriting. \"Rewritten queries\" help retrievers to retrieve target\npassages by mitigating vocabulary mismatch. Experimental results show that GuRE\nsignificantly improves performance in a retriever-agnostic manner,\noutperforming all baseline methods. Further analysis reveals that different\ntraining objectives lead to distinct retrieval behaviors, making GuRE more\nsuitable than direct retriever fine-tuning for real-world applications. Codes\nare avaiable at github.com/daehuikim/GuRE.", "published": "2025-05-19 10:42:36", "link": "http://arxiv.org/abs/2505.12950v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Morphological Tagging for Nguni Languages", "abstract": "Morphological parsing is the task of decomposing words into morphemes, the\nsmallest units of meaning in a language, and labelling their grammatical roles.\nIt is a particularly challenging task for agglutinative languages, such as the\nNguni languages of South Africa, which construct words by concatenating\nmultiple morphemes. A morphological parsing system can be framed as a pipeline\nwith two separate components, a segmenter followed by a tagger. This paper\ninvestigates the use of neural methods to build morphological taggers for the\nfour Nguni languages. We compare two classes of approaches: training neural\nsequence labellers (LSTMs and neural CRFs) from scratch and finetuning\npretrained language models. We compare performance across these two categories,\nas well as to a traditional rule-based morphological parser. Neural taggers\ncomfortably outperform the rule-based baseline and models trained from scratch\ntend to outperform pretrained models. We also compare parsing results across\ndifferent upstream segmenters and with varying linguistic input features. Our\nfindings confirm the viability of employing neural taggers based on\npre-existing morphological segmenters for the Nguni languages.", "published": "2025-05-19 10:41:47", "link": "http://arxiv.org/abs/2505.12949v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A3 : an Analytical Low-Rank Approximation Framework for Attention", "abstract": "Large language models have demonstrated remarkable performance; however,\ntheir massive parameter counts make deployment highly expensive. Low-rank\napproximation offers a promising compression solution, yet existing approaches\nhave two main limitations: (1) They focus on minimizing the output error of\nindividual linear layers, without considering the architectural characteristics\nof Transformers, and (2) they decompose a large weight matrix into two small\nlow-rank matrices. Consequently, these methods often fall short compared to\nother compression techniques like pruning and quantization, and introduce\nruntime overhead such as the extra GEMM kernel launches for decomposed small\nmatrices. To address these limitations, we propose $\\tt A^\\tt 3$, a\npost-training low-rank approximation framework. $\\tt A^\\tt 3$ splits a\nTransformer layer into three functional components, namely $\\tt QK$, $\\tt OV$,\nand $\\tt MLP$. For each component, $\\tt A^\\tt 3$ provides an analytical\nsolution that reduces the hidden dimension size inside each component while\nminimizing the component's functional loss ($\\it i.e.$, error in attention\nscores, attention outputs, and MLP outputs). This approach directly reduces\nmodel sizes, KV cache sizes, and FLOPs without introducing any runtime\noverheads. In addition, it provides a new narrative in advancing the\noptimization problem from singular linear layer loss optimization toward\nimproved end-to-end performance. Through extensive experiments, we show that\n$\\tt A^\\tt 3$ maintains superior performance compared to SoTAs. For example,\nunder the same reduction budget in computation and memory, our low-rank\napproximated LLaMA 3.1-70B achieves a perplexity of 4.69 on WikiText-2,\noutperforming the previous SoTA's 7.87 by 3.18. We also demonstrate the\nversatility of $\\tt A^\\tt 3$, including KV cache compression, quantization, and\nmixed-rank assignments for enhanced performance.", "published": "2025-05-19 10:29:32", "link": "http://arxiv.org/abs/2505.12942v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Leveraging LLM Inconsistency to Boost Pass@k Performance", "abstract": "Large language models (LLMs) achieve impressive abilities in numerous\ndomains, but exhibit inconsistent performance in response to minor input\nchanges. Rather than view this as a drawback, in this paper we introduce a\nnovel method for leveraging models' inconsistency to boost Pass@k performance.\nSpecifically, we present a \"Variator\" agent that generates k variants of a\ngiven task and submits one candidate solution for each one. Our variant\ngeneration approach is applicable to a wide range of domains as it is task\nagnostic and compatible with free-form inputs. We demonstrate the efficacy of\nour agent theoretically using a probabilistic model of the inconsistency\neffect, and show empirically that it outperforms the baseline on the APPS\ndataset. Furthermore, we establish that inconsistency persists even in frontier\nreasoning models across coding and cybersecurity domains, suggesting our method\nis likely to remain relevant for future model generations.", "published": "2025-05-19 10:22:04", "link": "http://arxiv.org/abs/2505.12938v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs", "abstract": "Reinforcement learning (RL) has become a cornerstone for enhancing the\nreasoning capabilities of large language models (LLMs), with recent innovations\nsuch as Group Relative Policy Optimization (GRPO) demonstrating exceptional\neffectiveness. In this study, we identify a critical yet underexplored issue in\nRL training: low-probability tokens disproportionately influence model updates\ndue to their large gradient magnitudes. This dominance hinders the effective\nlearning of high-probability tokens, whose gradients are essential for LLMs'\nperformance but are substantially suppressed. To mitigate this interference, we\npropose two novel methods: Advantage Reweighting and Low-Probability Token\nIsolation (Lopti), both of which effectively attenuate gradients from\nlow-probability tokens while emphasizing parameter updates driven by\nhigh-probability tokens. Our approaches promote balanced updates across tokens\nwith varying probabilities, thereby enhancing the efficiency of RL training.\nExperimental results demonstrate that they substantially improve the\nperformance of GRPO-trained LLMs, achieving up to a 46.2% improvement in K&K\nLogic Puzzle reasoning tasks. Our implementation is available at\nhttps://github.com/zhyang2226/AR-Lopti.", "published": "2025-05-19 10:14:08", "link": "http://arxiv.org/abs/2505.12929v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "PyFCG: Fluid Construction Grammar in Python", "abstract": "We present PyFCG, an open source software library that ports Fluid\nConstruction Grammar (FCG) to the Python programming language. PyFCG enables\nits users to seamlessly integrate FCG functionality into Python programs, and\nto use FCG in combination with other libraries within Python's rich ecosystem.\nApart from a general description of the library, this paper provides three\nwalkthrough tutorials that demonstrate example usage of PyFCG in typical use\ncases of FCG: (i) formalising and testing construction grammar analyses, (ii)\nlearning usage-based construction grammars from corpora, and (iii) implementing\nagent-based experiments on emergent communication.", "published": "2025-05-19 10:00:01", "link": "http://arxiv.org/abs/2505.12920v1", "categories": ["cs.CL", "cs.AI", "cs.MA"], "primary_category": "cs.CL"}
{"title": "AutoGEEval: A Multimodal and Automated Framework for Geospatial Code Generation on GEE with Large Language Models", "abstract": "Geospatial code generation is emerging as a key direction in the integration\nof artificial intelligence and geoscientific analysis. However, there remains a\nlack of standardized tools for automatic evaluation in this domain. To address\nthis gap, we propose AutoGEEval, the first multimodal, unit-level automated\nevaluation framework for geospatial code generation tasks on the Google Earth\nEngine (GEE) platform powered by large language models (LLMs). Built upon the\nGEE Python API, AutoGEEval establishes a benchmark suite (AutoGEEval-Bench)\ncomprising 1325 test cases that span 26 GEE data types. The framework\nintegrates both question generation and answer verification components to\nenable an end-to-end automated evaluation pipeline-from function invocation to\nexecution validation. AutoGEEval supports multidimensional quantitative\nanalysis of model outputs in terms of accuracy, resource consumption, execution\nefficiency, and error types. We evaluate 18 state-of-the-art LLMs-including\ngeneral-purpose, reasoning-augmented, code-centric, and geoscience-specialized\nmodels-revealing their performance characteristics and potential optimization\npathways in GEE code generation. This work provides a unified protocol and\nfoundational resource for the development and assessment of geospatial code\ngeneration models, advancing the frontier of automated natural language to\ndomain-specific code translation.", "published": "2025-05-19 09:35:58", "link": "http://arxiv.org/abs/2505.12900v1", "categories": ["cs.SE", "cs.AI", "cs.CG", "cs.CL", "cs.DB"], "primary_category": "cs.SE"}
{"title": "On the Thinking-Language Modeling Gap in Large Language Models", "abstract": "System 2 reasoning is one of the defining characteristics of intelligence,\nwhich requires slow and logical thinking. Human conducts System 2 reasoning via\nthe language of thoughts that organizes the reasoning process as a causal\nsequence of mental language, or thoughts. Recently, it has been observed that\nSystem 2 reasoning can be elicited from Large Language Models (LLMs)\npre-trained on large-scale natural languages. However, in this work, we show\nthat there is a significant gap between the modeling of languages and thoughts.\nAs language is primarily a tool for humans to share knowledge and thinking,\nmodeling human language can easily absorb language biases into LLMs deviated\nfrom the chain of thoughts in minds. Furthermore, we show that the biases will\nmislead the eliciting of \"thoughts\" in LLMs to focus only on a biased part of\nthe premise. To this end, we propose a new prompt technique termed\nLanguage-of-Thoughts (LoT) to demonstrate and alleviate this gap. Instead of\ndirectly eliciting the chain of thoughts from partial information, LoT\ninstructs LLMs to adjust the order and token used for the expressions of all\nthe relevant information. We show that the simple strategy significantly\nreduces the language modeling biases in LLMs and improves the performance of\nLLMs across a variety of reasoning tasks.", "published": "2025-05-19 09:31:52", "link": "http://arxiv.org/abs/2505.12896v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "TIME: A Multi-level Benchmark for Temporal Reasoning of LLMs in Real-World Scenarios", "abstract": "Temporal reasoning is pivotal for Large Language Models (LLMs) to comprehend\nthe real world. However, existing works neglect the real-world challenges for\ntemporal reasoning: (1) intensive temporal information, (2) fast-changing event\ndynamics, and (3) complex temporal dependencies in social interactions. To\nbridge this gap, we propose a multi-level benchmark TIME, designed for temporal\nreasoning in real-world scenarios. TIME consists of 38,522 QA pairs, covering 3\nlevels with 11 fine-grained sub-tasks. This benchmark encompasses 3\nsub-datasets reflecting different real-world challenges: TIME-Wiki, TIME-News,\nand TIME-Dial. We conduct extensive experiments on reasoning models and\nnon-reasoning models. And we conducted an in-depth analysis of temporal\nreasoning performance across diverse real-world scenarios and tasks, and\nsummarized the impact of test-time scaling on temporal reasoning capabilities.\nAdditionally, we release TIME-Lite, a human-annotated subset to foster future\nresearch and standardized evaluation in temporal reasoning. The code is\navailable at https://github.com/sylvain-wei/TIME , and the dataset is available\nat https://huggingface.co/datasets/SylvainWei/TIME .", "published": "2025-05-19 09:22:02", "link": "http://arxiv.org/abs/2505.12891v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "GAP: Graph-Assisted Prompts for Dialogue-based Medication Recommendation", "abstract": "Medication recommendations have become an important task in the healthcare\ndomain, especially in measuring the accuracy and safety of medical dialogue\nsystems (MDS). Different from the recommendation task based on electronic\nhealth records (EHRs), dialogue-based medication recommendations require\nresearch on the interaction details between patients and doctors, which is\ncrucial but may not exist in EHRs. Recent advancements in large language models\n(LLM) have extended the medical dialogue domain. These LLMs can interpret\npatients' intent and provide medical suggestions including medication\nrecommendations, but some challenges are still worth attention. During a\nmulti-turn dialogue, LLMs may ignore the fine-grained medical information or\nconnections across the dialogue turns, which is vital for providing accurate\nsuggestions. Besides, LLMs may generate non-factual responses when there is a\nlack of domain-specific knowledge, which is more risky in the medical domain.\nTo address these challenges, we propose a \\textbf{G}raph-\\textbf{A}ssisted\n\\textbf{P}rompts (\\textbf{GAP}) framework for dialogue-based medication\nrecommendation. It extracts medical concepts and corresponding states from\ndialogue to construct an explicitly patient-centric graph, which can describe\nthe neglected but important information. Further, combined with external\nmedical knowledge graphs, GAP can generate abundant queries and prompts, thus\nretrieving information from multiple sources to reduce the non-factual\nresponses. We evaluate GAP on a dialogue-based medication recommendation\ndataset and further explore its potential in a more difficult scenario,\ndynamically diagnostic interviewing. Extensive experiments demonstrate its\ncompetitive performance when compared with strong baselines.", "published": "2025-05-19 09:18:19", "link": "http://arxiv.org/abs/2505.12888v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detection and Mitigation of Hallucination in Large Reasoning Models: A Mechanistic Perspective", "abstract": "Large Reasoning Models (LRMs) have shown impressive capabilities in\nmulti-step reasoning tasks. However, alongside these successes, a more\ndeceptive form of model error has emerged--Reasoning Hallucination--where\nlogically coherent but factually incorrect reasoning traces lead to persuasive\nyet faulty conclusions. Unlike traditional hallucinations, these errors are\nembedded within structured reasoning, making them more difficult to detect and\npotentially more harmful. In this work, we investigate reasoning hallucinations\nfrom a mechanistic perspective. We propose the Reasoning Score, which\nquantifies the depth of reasoning by measuring the divergence between logits\nobtained from projecting late layers of LRMs to the vocabulary space,\neffectively distinguishing shallow pattern-matching from genuine deep\nreasoning. Using this score, we conduct an in-depth analysis on the ReTruthQA\ndataset and identify two key reasoning hallucination patterns: early-stage\nfluctuation in reasoning depth and incorrect backtracking to flawed prior\nsteps. These insights motivate our Reasoning Hallucination Detection (RHD)\nframework, which achieves state-of-the-art performance across multiple domains.\nTo mitigate reasoning hallucinations, we further introduce GRPO-R, an enhanced\nreinforcement learning algorithm that incorporates step-level deep reasoning\nrewards via potential-based shaping. Our theoretical analysis establishes\nstronger generalization guarantees, and experiments demonstrate improved\nreasoning quality and reduced hallucination rates.", "published": "2025-05-19 09:16:40", "link": "http://arxiv.org/abs/2505.12886v1", "categories": ["cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.AI"}
{"title": "Does Low Rank Adaptation Lead to Lower Robustness against Training-Time Attacks?", "abstract": "Low rank adaptation (LoRA) has emerged as a prominent technique for\nfine-tuning large language models (LLMs) thanks to its superb efficiency gains\nover previous methods. While extensive studies have examined the performance\nand structural properties of LoRA, its behavior upon training-time attacks\nremain underexplored, posing significant security risks. In this paper, we\ntheoretically investigate the security implications of LoRA's low-rank\nstructure during fine-tuning, in the context of its robustness against data\npoisoning and backdoor attacks. We propose an analytical framework that models\nLoRA's training dynamics, employs the neural tangent kernel to simplify the\nanalysis of the training process, and applies information theory to establish\nconnections between LoRA's low rank structure and its vulnerability against\ntraining-time attacks. Our analysis indicates that LoRA exhibits better\nrobustness to backdoor attacks than full fine-tuning, while becomes more\nvulnerable to untargeted data poisoning due to its over-simplified information\ngeometry. Extensive experimental evaluations have corroborated our theoretical\nfindings.", "published": "2025-05-19 08:57:08", "link": "http://arxiv.org/abs/2505.12871v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "LEXam: Benchmarking Legal Reasoning on 340 Law Exams", "abstract": "Long-form legal reasoning remains a key challenge for large language models\n(LLMs) in spite of recent advances in test-time scaling. We introduce LEXam, a\nnovel benchmark derived from 340 law exams spanning 116 law school courses\nacross a range of subjects and degree levels. The dataset comprises 4,886 law\nexam questions in English and German, including 2,841 long-form, open-ended\nquestions and 2,045 multiple-choice questions. Besides reference answers, the\nopen questions are also accompanied by explicit guidance outlining the expected\nlegal reasoning approach such as issue spotting, rule recall, or rule\napplication. Our evaluation on both open-ended and multiple-choice questions\npresent significant challenges for current LLMs; in particular, they notably\nstruggle with open questions that require structured, multi-step legal\nreasoning. Moreover, our results underscore the effectiveness of the dataset in\ndifferentiating between models with varying capabilities. Adopting an\nLLM-as-a-Judge paradigm with rigorous human expert validation, we demonstrate\nhow model-generated reasoning steps can be evaluated consistently and\naccurately. Our evaluation setup provides a scalable method to assess legal\nreasoning quality beyond simple accuracy metrics. Project page:\nhttps://lexam-benchmark.github.io/", "published": "2025-05-19 08:48:12", "link": "http://arxiv.org/abs/2505.12864v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50", "I.2"], "primary_category": "cs.CL"}
{"title": "Re-identification of De-identified Documents with Autoregressive Infilling", "abstract": "Documents revealing sensitive information about individuals must typically be\nde-identified. This de-identification is often done by masking all mentions of\npersonally identifiable information (PII), thereby making it more difficult to\nuncover the identity of the person(s) in question. To investigate the\nrobustness of de-identification methods, we present a novel, RAG-inspired\napproach that attempts the reverse process of re-identification based on a\ndatabase of documents representing background knowledge. Given a text in which\npersonal identifiers have been masked, the re-identification proceeds in two\nsteps. A retriever first selects from the background knowledge passages deemed\nrelevant for the re-identification. Those passages are then provided to an\ninfilling model which seeks to infer the original content of each text span.\nThis process is repeated until all masked spans are replaced. We evaluate the\nre-identification on three datasets (Wikipedia biographies, court rulings and\nclinical notes). Results show that (1) as many as 80% of de-identified text\nspans can be successfully recovered and (2) the re-identification accuracy\nincreases along with the level of background knowledge.", "published": "2025-05-19 08:43:54", "link": "http://arxiv.org/abs/2505.12859v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GEM: Gaussian Embedding Modeling for Out-of-Distribution Detection in GUI Agents", "abstract": "Graphical user interface (GUI) agents have recently emerged as an intriguing\nparadigm for human-computer interaction, capable of automatically executing\nuser instructions to operate intelligent terminal devices. However, when\nencountering out-of-distribution (OOD) instructions that violate environmental\nconstraints or exceed the current capabilities of agents, GUI agents may suffer\ntask breakdowns or even pose security threats. Therefore, effective OOD\ndetection for GUI agents is essential. Traditional OOD detection methods\nperform suboptimally in this domain due to the complex embedding space and\nevolving GUI environments. In this work, we observe that the in-distribution\ninput semantic space of GUI agents exhibits a clustering pattern with respect\nto the distance from the centroid. Based on the finding, we propose GEM, a\nnovel method based on fitting a Gaussian mixture model over input embedding\ndistances extracted from the GUI Agent that reflect its capability boundary.\nEvaluated on eight datasets spanning smartphones, computers, and web browsers,\nour method achieves an average accuracy improvement of 23.70\\% over the\nbest-performing baseline. Analysis verifies the generalization ability of our\nmethod through experiments on nine different backbones. The codes are available\nat https://github.com/Wuzheng02/GEM-OODforGUIagents.", "published": "2025-05-19 08:29:05", "link": "http://arxiv.org/abs/2505.12842v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "The Hidden Structure -- Improving Legal Document Understanding Through Explicit Text Formatting", "abstract": "Legal contracts possess an inherent, semantically vital structure (e.g.,\nsections, clauses) that is crucial for human comprehension but whose impact on\nLLM processing remains under-explored. This paper investigates the effects of\nexplicit input text structure and prompt engineering on the performance of\nGPT-4o and GPT-4.1 on a legal question-answering task using an excerpt of the\nCUAD. We compare model exact-match accuracy across various input formats:\nwell-structured plain-text (human-generated from CUAD), plain-text cleaned of\nline breaks, extracted plain-text from Azure OCR, plain-text extracted by\nGPT-4o Vision, and extracted (and interpreted) Markdown (MD) from GPT-4o\nVision. To give an indication of the impact of possible prompt engineering, we\nassess the impact of shifting task instructions to the system prompt and\nexplicitly informing the model about the structured nature of the input. Our\nfindings reveal that GPT-4o demonstrates considerable robustness to variations\nin input structure, but lacks in overall performance. Conversely, GPT-4.1's\nperformance is markedly sensitive; poorly structured inputs yield suboptimal\nresults (but identical with GPT-4o), while well-structured formats (original\nCUAD text, GPT-4o Vision text and GPT-4o MD) improve exact-match accuracy by\n~20 percentage points. Optimizing the system prompt to include task details and\nan advisory about structured input further elevates GPT-4.1's accuracy by an\nadditional ~10-13 percentage points, with Markdown ultimately achieving the\nhighest performance under these conditions (79 percentage points overall\nexact-match accuracy). This research empirically demonstrates that while newer\nmodels exhibit greater resilience, careful input structuring and strategic\nprompt design remain critical for optimizing the performance of LLMs, and can\nsignificantly affect outcomes in high-stakes legal applications.", "published": "2025-05-19 08:25:21", "link": "http://arxiv.org/abs/2505.12837v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "FlightGPT: Towards Generalizable and Interpretable UAV Vision-and-Language Navigation with Vision-Language Models", "abstract": "Unmanned Aerial Vehicle (UAV) Vision-and-Language Navigation (VLN) is vital\nfor applications such as disaster response, logistics delivery, and urban\ninspection. However, existing methods often struggle with insufficient\nmultimodal fusion, weak generalization, and poor interpretability. To address\nthese challenges, we propose FlightGPT, a novel UAV VLN framework built upon\nVision-Language Models (VLMs) with powerful multimodal perception capabilities.\nWe design a two-stage training pipeline: first, Supervised Fine-Tuning (SFT)\nusing high-quality demonstrations to improve initialization and structured\nreasoning; then, Group Relative Policy Optimization (GRPO) algorithm, guided by\na composite reward that considers goal accuracy, reasoning quality, and format\ncompliance, to enhance generalization and adaptability. Furthermore, FlightGPT\nintroduces a Chain-of-Thought (CoT)-based reasoning mechanism to improve\ndecision interpretability. Extensive experiments on the city-scale dataset\nCityNav demonstrate that FlightGPT achieves state-of-the-art performance across\nall scenarios, with a 9.22\\% higher success rate than the strongest baseline in\nunseen environments. Our implementation is publicly available.", "published": "2025-05-19 08:21:20", "link": "http://arxiv.org/abs/2505.12835v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Contrastive Prompting Enhances Sentence Embeddings in LLMs through Inference-Time Steering", "abstract": "Extracting sentence embeddings from large language models (LLMs) is a\npractical direction, as it requires neither additional data nor fine-tuning.\nPrevious studies usually focus on prompt engineering to guide LLMs to encode\nthe core semantic information of the sentence into the embedding of the last\ntoken. However, the last token in these methods still encodes an excess of\nnon-essential information, such as stop words, limiting its encoding capacity.\nTo this end, we propose a Contrastive Prompting (CP) method that introduces an\nextra auxiliary prompt to elicit better sentence embedding. By contrasting with\nthe auxiliary prompt, CP can steer existing prompts to encode the core\nsemantics of the sentence, rather than non-essential information. CP is a\nplug-and-play inference-time intervention method that can be combined with\nvarious prompt-based methods. Extensive experiments on Semantic Textual\nSimilarity (STS) tasks and downstream classification tasks demonstrate that our\nmethod can improve the performance of existing prompt-based methods across\ndifferent LLMs. Our code will be released at https://github.com/zifengcheng/CP.", "published": "2025-05-19 08:19:27", "link": "http://arxiv.org/abs/2505.12831v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SynDec: A Synthesize-then-Decode Approach for Arbitrary Textual Style Transfer via Large Language Models", "abstract": "Large Language Models (LLMs) are emerging as dominant forces for textual\nstyle transfer. However, for arbitrary style transfer, LLMs face two key\nchallenges: (1) considerable reliance on manually-constructed prompts and (2)\nrigid stylistic biases inherent in LLMs. In this paper, we propose a novel\nSynthesize-then-Decode (SynDec) approach, which automatically synthesizes\nhigh-quality prompts and amplifies their roles during decoding process.\nSpecifically, our approach synthesizes prompts by selecting representative\nfew-shot samples, conducting a four-dimensional style analysis, and reranking\nthe candidates. At LLM decoding stage, the TST effect is amplified by\nmaximizing the contrast in output probabilities between scenarios with and\nwithout the synthesized prompt, as well as between prompts and negative\nsamples. We conduct extensive experiments and the results show that SynDec\noutperforms existing state-of-the-art LLM-based methods on five out of six\nbenchmarks (e.g., achieving up to a 9\\% increase in accuracy for\nmodern-to-Elizabethan English transfer). Detailed ablation studies further\nvalidate the effectiveness of SynDec.", "published": "2025-05-19 08:03:38", "link": "http://arxiv.org/abs/2505.12821v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PsyMem: Fine-grained psychological alignment and Explicit Memory Control for Advanced Role-Playing LLMs", "abstract": "Existing LLM-based role-playing methods often rely on superficial textual\ndescriptions or simplistic metrics, inadequately modeling both intrinsic and\nextrinsic character dimensions. Additionally, they typically simulate character\nmemory with implicit model knowledge or basic retrieval augment generation\nwithout explicit memory alignment, compromising memory consistency. The two\nissues weaken reliability of role-playing LLMs in several applications, such as\ntrustworthy social simulation. To address these limitations, we propose PsyMem,\na novel framework integrating fine-grained psychological attributes and\nexplicit memory control for role-playing. PsyMem supplements textual\ndescriptions with 26 psychological indicators to detailed model character.\nAdditionally, PsyMem implements memory alignment training, explicitly trains\nthe model to align character's response with memory, thereby enabling dynamic\nmemory-controlled responding during inference. By training Qwen2.5-7B-Instruct\non our specially designed dataset (including 5,414 characters and 38,962\ndialogues extracted from novels), the resulting model, termed as PsyMem-Qwen,\noutperforms baseline models in role-playing, achieving the best performance in\nhuman-likeness and character fidelity.", "published": "2025-05-19 07:45:09", "link": "http://arxiv.org/abs/2505.12814v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Decentralized Arena: Towards Democratic and Scalable Automatic Evaluation of Language Models", "abstract": "The recent explosion of large language models (LLMs), each with its own\ngeneral or specialized strengths, makes scalable, reliable benchmarking more\nurgent than ever. Standard practices nowadays face fundamental trade-offs:\nclosed-ended question-based benchmarks (eg MMLU) struggle with saturation as\nnewer models emerge, while crowd-sourced leaderboards (eg Chatbot Arena) rely\non costly and slow human judges. Recently, automated methods (eg\nLLM-as-a-judge) shed light on the scalability, but risk bias by relying on one\nor a few \"authority\" models. To tackle these issues, we propose Decentralized\nArena (dearena), a fully automated framework leveraging collective intelligence\nfrom all LLMs to evaluate each other. It mitigates single-model judge bias by\ndemocratic, pairwise evaluation, and remains efficient at scale through two key\ncomponents: (1) a coarse-to-fine ranking algorithm for fast incremental\ninsertion of new models with sub-quadratic complexity, and (2) an automatic\nquestion selection strategy for the construction of new evaluation dimensions.\nAcross extensive experiments across 66 LLMs, dearena attains up to 97%\ncorrelation with human judgements, while significantly reducing the cost. Our\ncode and data will be publicly released on\nhttps://github.com/maitrix-org/de-arena.", "published": "2025-05-19 07:34:25", "link": "http://arxiv.org/abs/2505.12808v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "EAVIT: Efficient and Accurate Human Value Identification from Text data via LLMs", "abstract": "The rapid evolution of large language models (LLMs) has revolutionized\nvarious fields, including the identification and discovery of human values\nwithin text data. While traditional NLP models, such as BERT, have been\nemployed for this task, their ability to represent textual data is\nsignificantly outperformed by emerging LLMs like GPTs. However, the performance\nof online LLMs often degrades when handling long contexts required for value\nidentification, which also incurs substantial computational costs. To address\nthese challenges, we propose EAVIT, an efficient and accurate framework for\nhuman value identification that combines the strengths of both locally\nfine-tunable and online black-box LLMs. Our framework employs a value detector\n- a small, local language model - to generate initial value estimations. These\nestimations are then used to construct concise input prompts for online LLMs,\nenabling accurate final value identification. To train the value detector, we\nintroduce explanation-based training and data generation techniques\nspecifically tailored for value identification, alongside sampling strategies\nto optimize the brevity of LLM input prompts. Our approach effectively reduces\nthe number of input tokens by up to 1/6 compared to directly querying online\nLLMs, while consistently outperforming traditional NLP methods and other\nLLM-based strategies.", "published": "2025-05-19 07:24:35", "link": "http://arxiv.org/abs/2505.12792v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Token is Worth over 1,000 Tokens: Efficient Knowledge Distillation through Low-Rank Clone", "abstract": "Training high-performing Small Language Models (SLMs) remains costly, even\nwith knowledge distillation and pruning from larger teacher models. Existing\nwork often faces three key challenges: (1) information loss from hard pruning,\n(2) inefficient alignment of representations, and (3) underutilization of\ninformative activations, particularly from Feed-Forward Networks (FFNs). To\naddress these challenges, we introduce Low-Rank Clone (LRC), an efficient\npre-training method that constructs SLMs aspiring to behavioral equivalence\nwith strong teacher models. LRC trains a set of low-rank projection matrices\nthat jointly enable soft pruning by compressing teacher weights, and activation\nclone by aligning student activations, including FFN signals, with those of the\nteacher. This unified design maximizes knowledge transfer while removing the\nneed for explicit alignment modules. Extensive experiments with open-source\nteachers (e.g., Llama-3.2-3B-Instruct, Qwen2.5-3B/7B-Instruct) show that LRC\nmatches or surpasses state-of-the-art models trained on trillions of\ntokens--while using only 20B tokens, achieving over 1,000x training efficiency.\nOur codes and model checkpoints are available at\nhttps://github.com/CURRENTF/LowRankClone and\nhttps://huggingface.co/collections/JitaiHao/low-rank-clone-lrc-6828389e96a93f1d4219dfaf.", "published": "2025-05-19 07:10:42", "link": "http://arxiv.org/abs/2505.12781v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ReEx-SQL: Reasoning with Execution-Aware Reinforcement Learning for Text-to-SQL", "abstract": "In Text-to-SQL, execution feedback is essential for guiding large language\nmodels (LLMs) to reason accurately and generate reliable SQL queries. However,\nexisting methods treat execution feedback solely as a post-hoc signal for\ncorrection or selection, failing to integrate it into the generation process.\nThis limitation hinders their ability to address reasoning errors as they\noccur, ultimately reducing query accuracy and robustness. To address this\nissue, we propose ReEx-SQL (Reasoning with Execution-Aware Reinforcement\nLearning), a framework for Text-to-SQL that enables models to interact with the\ndatabase during decoding and dynamically adjust their reasoning based on\nexecution feedback. ReEx-SQL introduces an execution-aware reasoning paradigm\nthat interleaves intermediate SQL execution into reasoning paths, facilitating\ncontext-sensitive revisions. It achieves this through structured prompts with\nmarkup tags and a stepwise rollout strategy that integrates execution feedback\ninto each stage of generation. To supervise policy learning, we develop a\ncomposite reward function that includes an exploration reward, explicitly\nencouraging effective database interaction. Additionally, ReEx-SQL adopts a\ntree-based decoding strategy to support exploratory reasoning, enabling dynamic\nexpansion of alternative reasoning paths. Notably, ReEx-SQL achieves 88.8% on\nSpider and 64.9% on BIRD at the 7B scale, surpassing the standard reasoning\nbaseline by 2.7% and 2.6%, respectively. It also shows robustness, achieving\n85.2% on Spider-Realistic with leading performance. In addition, its\ntree-structured decoding improves efficiency and performance over linear\ndecoding, reducing inference time by 51.9% on the BIRD development set.", "published": "2025-05-19 06:46:47", "link": "http://arxiv.org/abs/2505.12768v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rethinking Reward Model Evaluation Through the Lens of Reward Overoptimization", "abstract": "Reward models (RMs) play a crucial role in reinforcement learning from human\nfeedback (RLHF), aligning model behavior with human preferences. However,\nexisting benchmarks for reward models show a weak correlation with the\nperformance of optimized policies, suggesting that they fail to accurately\nassess the true capabilities of RMs. To bridge this gap, we explore several\nevaluation designs through the lens of reward overoptimization\\textemdash a\nphenomenon that captures both how well the reward model aligns with human\npreferences and the dynamics of the learning signal it provides to the policy.\nThe results highlight three key findings on how to construct a reliable\nbenchmark: (i) it is important to minimize differences between chosen and\nrejected responses beyond correctness, (ii) evaluating reward models requires\nmultiple comparisons across a wide range of chosen and rejected responses, and\n(iii) given that reward models encounter responses with diverse\nrepresentations, responses should be sourced from a variety of models. However,\nwe also observe that a extremely high correlation with degree of\noveroptimization leads to comparatively lower correlation with certain\ndownstream performance. Thus, when designing a benchmark, it is desirable to\nuse the degree of overoptimization as a useful tool, rather than the end goal.", "published": "2025-05-19 06:43:08", "link": "http://arxiv.org/abs/2505.12763v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "What is Stigma Attributed to? A Theory-Grounded, Expert-Annotated Interview Corpus for Demystifying Mental-Health Stigma", "abstract": "Mental-health stigma remains a pervasive social problem that hampers\ntreatment-seeking and recovery. Existing resources for training neural models\nto finely classify such stigma are limited, relying primarily on social-media\nor synthetic data without theoretical underpinnings. To remedy this gap, we\npresent an expert-annotated, theory-informed corpus of human-chatbot\ninterviews, comprising 4,141 snippets from 684 participants with documented\nsocio-cultural backgrounds. Our experiments benchmark state-of-the-art neural\nmodels and empirically unpack the challenges of stigma detection. This dataset\ncan facilitate research on computationally detecting, neutralizing, and\ncounteracting mental-health stigma.", "published": "2025-05-19 05:31:42", "link": "http://arxiv.org/abs/2505.12727v1", "categories": ["cs.CL", "cs.CY", "cs.HC"], "primary_category": "cs.CL"}
{"title": "VTBench: Evaluating Visual Tokenizers for Autoregressive Image Generation", "abstract": "Autoregressive (AR) models have recently shown strong performance in image\ngeneration, where a critical component is the visual tokenizer (VT) that maps\ncontinuous pixel inputs to discrete token sequences. The quality of the VT\nlargely defines the upper bound of AR model performance. However, current\ndiscrete VTs fall significantly behind continuous variational autoencoders\n(VAEs), leading to degraded image reconstructions and poor preservation of\ndetails and text. Existing benchmarks focus on end-to-end generation quality,\nwithout isolating VT performance. To address this gap, we introduce VTBench, a\ncomprehensive benchmark that systematically evaluates VTs across three core\ntasks: Image Reconstruction, Detail Preservation, and Text Preservation, and\ncovers a diverse range of evaluation scenarios. We systematically assess\nstate-of-the-art VTs using a set of metrics to evaluate the quality of\nreconstructed images. Our findings reveal that continuous VAEs produce superior\nvisual representations compared to discrete VTs, particularly in retaining\nspatial structure and semantic detail. In contrast, the degraded\nrepresentations produced by discrete VTs often lead to distorted\nreconstructions, loss of fine-grained textures, and failures in preserving text\nand object integrity. Furthermore, we conduct experiments on GPT-4o image\ngeneration and discuss its potential AR nature, offering new insights into the\nrole of visual tokenization. We release our benchmark and codebase publicly to\nsupport further research and call on the community to develop strong,\ngeneral-purpose open-source VTs.", "published": "2025-05-19 17:59:01", "link": "http://arxiv.org/abs/2505.13439v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance", "abstract": "Despite significant advances in video generation, synthesizing physically\nplausible human actions remains a persistent challenge, particularly in\nmodeling fine-grained semantics and complex temporal dynamics. For instance,\ngenerating gymnastics routines such as \"switch leap with 0.5 turn\" poses\nsubstantial difficulties for current methods, often yielding unsatisfactory\nresults. To bridge this gap, we propose FinePhys, a Fine-grained human action\ngeneration framework that incorporates Physics to obtain effective skeletal\nguidance. Specifically, FinePhys first estimates 2D poses in an online manner\nand then performs 2D-to-3D dimension lifting via in-context learning. To\nmitigate the instability and limited interpretability of purely data-driven 3D\nposes, we further introduce a physics-based motion re-estimation module\ngoverned by Euler-Lagrange equations, calculating joint accelerations via\nbidirectional temporal updating. The physically predicted 3D poses are then\nfused with data-driven ones, offering multi-scale 2D heatmap guidance for the\ndiffusion process. Evaluated on three fine-grained action subsets from FineGym\n(FX-JUMP, FX-TURN, and FX-SALTO), FinePhys significantly outperforms\ncompetitive baselines. Comprehensive qualitative results further demonstrate\nFinePhys's ability to generate more natural and plausible fine-grained human\nactions.", "published": "2025-05-19 17:58:11", "link": "http://arxiv.org/abs/2505.13437v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "MM-PRM: Enhancing Multimodal Mathematical Reasoning with Scalable Step-Level Supervision", "abstract": "While Multimodal Large Language Models (MLLMs) have achieved impressive\nprogress in vision-language understanding, they still struggle with complex\nmulti-step reasoning, often producing logically inconsistent or partially\ncorrect solutions. A key limitation lies in the lack of fine-grained\nsupervision over intermediate reasoning steps. To address this, we propose\nMM-PRM, a process reward model trained within a fully automated, scalable\nframework. We first build MM-Policy, a strong multimodal model trained on\ndiverse mathematical reasoning data. Then, we construct MM-K12, a curated\ndataset of 10,000 multimodal math problems with verifiable answers, which\nserves as seed data. Leveraging a Monte Carlo Tree Search (MCTS)-based\npipeline, we generate over 700k step-level annotations without human labeling.\nThe resulting PRM is used to score candidate reasoning paths in the Best-of-N\ninference setup and achieves significant improvements across both in-domain\n(MM-K12 test set) and out-of-domain (OlympiadBench, MathVista, etc.)\nbenchmarks. Further analysis confirms the effectiveness of soft labels, smaller\nlearning rates, and path diversity in optimizing PRM performance. MM-PRM\ndemonstrates that process supervision is a powerful tool for enhancing the\nlogical robustness of multimodal reasoning systems. We release all our codes\nand data at https://github.com/ModalMinds/MM-PRM.", "published": "2025-05-19 17:55:08", "link": "http://arxiv.org/abs/2505.13427v1", "categories": ["cs.AI", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Learnware of Language Models: Specialized Small Language Models Can Do Big", "abstract": "The learnware paradigm offers a novel approach to machine learning by\nenabling users to reuse a set of well-trained models for tasks beyond the\nmodels' original purposes. It eliminates the need to build models from scratch,\ninstead relying on specifications (representations of a model's capabilities)\nto identify and leverage the most suitable models for new tasks. While\nlearnware has proven effective in many scenarios, its application to language\nmodels has remained largely unexplored. At the same time, large language models\n(LLMs) have demonstrated remarkable universal question-answering abilities, yet\nthey face challenges in specialized scenarios due to data scarcity, privacy\nconcerns, and high computational costs, thus more and more specialized small\nlanguage models (SLMs) are being trained for specific domains. To address these\nlimitations systematically, the learnware paradigm provides a promising\nsolution by enabling maximum utilization of specialized SLMs, and allowing\nusers to identify and reuse them in a collaborative and privacy-preserving\nmanner.\n  This paper presents a preliminary attempt to apply the learnware paradigm to\nlanguage models. We simulated a learnware system comprising approximately 100\nlearnwares of specialized SLMs with 8B parameters, fine-tuned across finance,\nhealthcare, and mathematics domains. Each learnware contains an SLM and a\nspecification, which enables users to identify the most relevant models without\nexposing their own data. Experimental results demonstrate promising\nperformance: by selecting one suitable learnware for each task-specific\ninference, the system outperforms the base SLMs on all benchmarks. Compared to\nLLMs, the system outperforms Qwen1.5-110B, Qwen2.5-72B, and\nLlama3.1-70B-Instruct by at least 14% in finance domain tasks, and surpasses\nFlan-PaLM-540B (ranked 7th on the Open Medical LLM Leaderboard) in medical\ndomain tasks.", "published": "2025-05-19 17:54:35", "link": "http://arxiv.org/abs/2505.13425v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "AutoMathKG: The automated mathematical knowledge graph based on LLM and vector database", "abstract": "A mathematical knowledge graph (KG) presents knowledge within the field of\nmathematics in a structured manner. Constructing a math KG using natural\nlanguage is an essential but challenging task. There are two major limitations\nof existing works: first, they are constrained by corpus completeness, often\ndiscarding or manually supplementing incomplete knowledge; second, they\ntypically fail to fully automate the integration of diverse knowledge sources.\nThis paper proposes AutoMathKG, a high-quality, wide-coverage, and\nmulti-dimensional math KG capable of automatic updates. AutoMathKG regards\nmathematics as a vast directed graph composed of Definition, Theorem, and\nProblem entities, with their reference relationships as edges. It integrates\nknowledge from ProofWiki, textbooks, arXiv papers, and TheoremQA, enhancing\nentities and relationships with large language models (LLMs) via in-context\nlearning for data augmentation. To search for similar entities, MathVD, a\nvector database, is built through two designed embedding strategies using\nSBERT. To automatically update, two mechanisms are proposed. For knowledge\ncompletion mechanism, Math LLM is developed to interact with AutoMathKG,\nproviding missing proofs or solutions. For knowledge fusion mechanism, MathVD\nis used to retrieve similar entities, and LLM is used to determine whether to\nmerge with a candidate or add as a new entity. A wide range of experiments\ndemonstrate the advanced performance and broad applicability of the AutoMathKG\nsystem, including superior reachability query results in MathVD compared to\nfive baselines and robust mathematical reasoning capability in Math LLM.", "published": "2025-05-19 17:41:29", "link": "http://arxiv.org/abs/2505.13406v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Robin: A multi-agent system for automating scientific discovery", "abstract": "Scientific discovery is driven by the iterative process of background\nresearch, hypothesis generation, experimentation, and data analysis. Despite\nrecent advancements in applying artificial intelligence to scientific\ndiscovery, no system has yet automated all of these stages in a single\nworkflow. Here, we introduce Robin, the first multi-agent system capable of\nfully automating the key intellectual steps of the scientific process. By\nintegrating literature search agents with data analysis agents, Robin can\ngenerate hypotheses, propose experiments, interpret experimental results, and\ngenerate updated hypotheses, achieving a semi-autonomous approach to scientific\ndiscovery. By applying this system, we were able to identify a novel treatment\nfor dry age-related macular degeneration (dAMD), the major cause of blindness\nin the developed world. Robin proposed enhancing retinal pigment epithelium\nphagocytosis as a therapeutic strategy, and identified and validated a\npromising therapeutic candidate, ripasudil. Ripasudil is a clinically-used rho\nkinase (ROCK) inhibitor that has never previously been proposed for treating\ndAMD. To elucidate the mechanism of ripasudil-induced upregulation of\nphagocytosis, Robin then proposed and analyzed a follow-up RNA-seq experiment,\nwhich revealed upregulation of ABCA1, a critical lipid efflux pump and possible\nnovel target. All hypotheses, experimental plans, data analyses, and data\nfigures in the main text of this report were produced by Robin. As the first AI\nsystem to autonomously discover and validate a novel therapeutic candidate\nwithin an iterative lab-in-the-loop framework, Robin establishes a new paradigm\nfor AI-driven scientific discovery.", "published": "2025-05-19 17:36:17", "link": "http://arxiv.org/abs/2505.13400v1", "categories": ["cs.AI", "cs.MA", "q-bio.QM"], "primary_category": "cs.AI"}
{"title": "Advancing Generalization Across a Variety of Abstract Visual Reasoning Tasks", "abstract": "The abstract visual reasoning (AVR) domain presents a diverse suite of\nanalogy-based tasks devoted to studying model generalization. Recent years have\nbrought dynamic progress in the field, particularly in i.i.d. scenarios, in\nwhich models are trained and evaluated on the same data distributions.\nNevertheless, o.o.d. setups that assess model generalization to new test\ndistributions remain challenging even for the most recent models. To advance\ngeneralization in AVR tasks, we present the Pathways of Normalized Group\nConvolution model (PoNG), a novel neural architecture that features group\nconvolution, normalization, and a parallel design. We consider a wide set of\nAVR benchmarks, including Raven's Progressive Matrices and visual analogy\nproblems with both synthetic and real-world images. The experiments demonstrate\nstrong generalization capabilities of the proposed model, which in several\nsettings outperforms the existing literature methods.", "published": "2025-05-19 17:32:07", "link": "http://arxiv.org/abs/2505.13391v1", "categories": ["cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.AI"}
{"title": "How Adding Metacognitive Requirements in Support of AI Feedback in Practice Exams Transforms Student Learning Behaviors", "abstract": "Providing personalized, detailed feedback at scale in large undergraduate\nSTEM courses remains a persistent challenge. We present an empirically\nevaluated practice exam system that integrates AI generated feedback with\ntargeted textbook references, deployed in a large introductory biology course.\nOur system encourages metacognitive behavior by asking students to explain\ntheir answers and declare their confidence. It uses OpenAI's GPT-4o to generate\npersonalized feedback based on this information, while directing them to\nrelevant textbook sections. Through interaction logs from consenting\nparticipants across three midterms (541, 342, and 413 students respectively),\ntotaling 28,313 question-student interactions across 146 learning objectives,\nalong with 279 surveys and 23 interviews, we examined the system's impact on\nlearning outcomes and engagement. Across all midterms, feedback types showed no\nstatistically significant performance differences, though some trends suggested\npotential benefits. The most substantial impact came from the required\nconfidence ratings and explanations, which students reported transferring to\ntheir actual exam strategies. About 40 percent of students engaged with\ntextbook references when prompted by feedback -- far higher than traditional\nreading rates. Survey data revealed high satisfaction (mean rating 4.1 of 5),\nwith 82.1 percent reporting increased confidence on practiced midterm topics,\nand 73.4 percent indicating they could recall and apply specific concepts. Our\nfindings suggest that embedding structured reflection requirements may be more\nimpactful than sophisticated feedback mechanisms.", "published": "2025-05-19 17:25:07", "link": "http://arxiv.org/abs/2505.13381v1", "categories": ["cs.HC", "cs.AI", "K.3.1; I.2.7; H.5.2"], "primary_category": "cs.HC"}
{"title": "Exploiting Symbolic Heuristics for the Synthesis of Domain-Specific Temporal Planning Guidance using Reinforcement Learning", "abstract": "Recent work investigated the use of Reinforcement Learning (RL) for the\nsynthesis of heuristic guidance to improve the performance of temporal planners\nwhen a domain is fixed and a set of training problems (not plans) is given. The\nidea is to extract a heuristic from the value function of a particular\n(possibly infinite-state) MDP constructed over the training problems.\n  In this paper, we propose an evolution of this learning and planning\nframework that focuses on exploiting the information provided by symbolic\nheuristics during both the RL and planning phases. First, we formalize\ndifferent reward schemata for the synthesis and use symbolic heuristics to\nmitigate the problems caused by the truncation of episodes needed to deal with\nthe potentially infinite MDP. Second, we propose learning a residual of an\nexisting symbolic heuristic, which is a \"correction\" of the heuristic value,\ninstead of eagerly learning the whole heuristic from scratch. Finally, we use\nthe learned heuristic in combination with a symbolic heuristic using a\nmultiple-queue planning approach to balance systematic search with imperfect\nlearned information. We experimentally compare all the approaches, highlighting\ntheir strengths and weaknesses and significantly advancing the state of the art\nfor this planning and learning schema.", "published": "2025-05-19 17:19:13", "link": "http://arxiv.org/abs/2505.13372v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "One-Step Offline Distillation of Diffusion-based Models via Koopman Modeling", "abstract": "Diffusion-based generative models have demonstrated exceptional performance,\nyet their iterative sampling procedures remain computationally expensive. A\nprominent strategy to mitigate this cost is distillation, with offline\ndistillation offering particular advantages in terms of efficiency, modularity,\nand flexibility. In this work, we identify two key observations that motivate a\nprincipled distillation framework: (1) while diffusion models have been viewed\nthrough the lens of dynamical systems theory, powerful and underexplored tools\ncan be further leveraged; and (2) diffusion models inherently impose\nstructured, semantically coherent trajectories in latent space. Building on\nthese observations, we introduce the Koopman Distillation Model KDM, a novel\noffline distillation approach grounded in Koopman theory-a classical framework\nfor representing nonlinear dynamics linearly in a transformed space. KDM\nencodes noisy inputs into an embedded space where a learned linear operator\npropagates them forward, followed by a decoder that reconstructs clean samples.\nThis enables single-step generation while preserving semantic fidelity. We\nprovide theoretical justification for our approach: (1) under mild assumptions,\nthe learned diffusion dynamics admit a finite-dimensional Koopman\nrepresentation; and (2) proximity in the Koopman latent space correlates with\nsemantic similarity in the generated outputs, allowing for effective trajectory\nalignment. Empirically, KDM achieves state-of-the-art performance across\nstandard offline distillation benchmarks, improving FID scores by up to 40% in\na single generation step. All implementation details and code for the\nexperimental setups are provided in our GitHub -\nhttps://github.com/azencot-group/KDM, or in our project page -\nhttps://sites.google.com/view/koopman-distillation-model.", "published": "2025-05-19 16:59:47", "link": "http://arxiv.org/abs/2505.13358v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Multi-Armed Bandits Meet Large Language Models", "abstract": "Bandit algorithms and Large Language Models (LLMs) have emerged as powerful\ntools in artificial intelligence, each addressing distinct yet complementary\nchallenges in decision-making and natural language processing. This survey\nexplores the synergistic potential between these two fields, highlighting how\nbandit algorithms can enhance the performance of LLMs and how LLMs, in turn,\ncan provide novel insights for improving bandit-based decision-making. We first\nexamine the role of bandit algorithms in optimizing LLM fine-tuning, prompt\nengineering, and adaptive response generation, focusing on their ability to\nbalance exploration and exploitation in large-scale learning tasks.\nSubsequently, we explore how LLMs can augment bandit algorithms through\nadvanced contextual understanding, dynamic adaptation, and improved policy\nselection using natural language reasoning. By providing a comprehensive review\nof existing research and identifying key challenges and opportunities, this\nsurvey aims to bridge the gap between bandit algorithms and LLMs, paving the\nway for innovative applications and interdisciplinary research in AI.", "published": "2025-05-19 16:57:57", "link": "http://arxiv.org/abs/2505.13355v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "RoPECraft: Training-Free Motion Transfer with Trajectory-Guided RoPE Optimization on Diffusion Transformers", "abstract": "We propose RoPECraft, a training-free video motion transfer method for\ndiffusion transformers that operates solely by modifying their rotary\npositional embeddings (RoPE). We first extract dense optical flow from a\nreference video, and utilize the resulting motion offsets to warp the\ncomplex-exponential tensors of RoPE, effectively encoding motion into the\ngeneration process. These embeddings are then further optimized during\ndenoising time steps via trajectory alignment between the predicted and target\nvelocities using a flow-matching objective. To keep the output faithful to the\ntext prompt and prevent duplicate generations, we incorporate a regularization\nterm based on the phase components of the reference video's Fourier transform,\nprojecting the phase angles onto a smooth manifold to suppress high-frequency\nartifacts. Experiments on benchmarks reveal that RoPECraft outperforms all\nrecently published methods, both qualitatively and quantitatively.", "published": "2025-05-19 16:50:26", "link": "http://arxiv.org/abs/2505.13344v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "OPA-Pack: Object-Property-Aware Robotic Bin Packing", "abstract": "Robotic bin packing aids in a wide range of real-world scenarios such as\ne-commerce and warehouses. Yet, existing works focus mainly on considering the\nshape of objects to optimize packing compactness and neglect object properties\nsuch as fragility, edibility, and chemistry that humans typically consider when\npacking objects. This paper presents OPA-Pack (Object-Property-Aware Packing\nframework), the first framework that equips the robot with object property\nconsiderations in planning the object packing. Technical-wise, we develop a\nnovel object property recognition scheme with retrieval-augmented generation\nand chain-of-thought reasoning, and build a dataset with object property\nannotations for 1,032 everyday objects. Also, we formulate OPA-Net, aiming to\njointly separate incompatible object pairs and reduce pressure on fragile\nobjects, while compacting the packing. Further, OPA-Net consists of a property\nembedding layer to encode the property of candidate objects to be packed,\ntogether with a fragility heightmap and an avoidance heightmap to keep track of\nthe packed objects. Then, we design a reward function and adopt a deep\nQ-learning scheme to train OPA-Net. Experimental results manifest that OPA-Pack\ngreatly improves the accuracy of separating incompatible object pairs (from 52%\nto 95%) and largely reduces pressure on fragile objects (by 29.4%), while\nmaintaining good packing compactness. Besides, we demonstrate the effectiveness\nof OPA-Pack on a real packing platform, showcasing its practicality in\nreal-world scenarios.", "published": "2025-05-19 16:48:14", "link": "http://arxiv.org/abs/2505.13339v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Recommender Systems for Democracy: Toward Adversarial Robustness in Voting Advice Applications", "abstract": "Voting advice applications (VAAs) help millions of voters understand which\npolitical parties or candidates best align with their views. This paper\nexplores the potential risks these applications pose to the democratic process\nwhen targeted by adversarial entities. In particular, we expose 11 manipulation\nstrategies and measure their impact using data from Switzerland's primary VAA,\nSmartvote, collected during the last two national elections. We find that\naltering application parameters, such as the matching method, can shift a\nparty's recommendation frequency by up to 105%. Cherry-picking questionnaire\nitems can increase party recommendation frequency by over 261%, while subtle\nchanges to parties' or candidates' responses can lead to a 248% increase. To\naddress these vulnerabilities, we propose adversarial robustness properties\nVAAs should satisfy, introduce empirical metrics for assessing the resilience\nof various matching methods, and suggest possible avenues for research toward\nmitigating the effect of manipulation. Our framework is key to ensuring secure\nand reliable AI-based VAAs poised to emerge in the near future.", "published": "2025-05-19 16:38:06", "link": "http://arxiv.org/abs/2505.13329v1", "categories": ["cs.CY", "cs.AI", "cs.CR"], "primary_category": "cs.CY"}
{"title": "From What Ifs to Insights: Counterfactuals in Causal Inference vs. Explainable AI", "abstract": "Counterfactuals play a pivotal role in the two distinct data science fields\nof causal inference (CI) and explainable artificial intelligence (XAI). While\nthe core idea behind counterfactuals remains the same in both fields--the\nexamination of what would have happened under different circumstances--there\nare key differences in how they are used and interpreted. We introduce a formal\ndefinition that encompasses the multi-faceted concept of the counterfactual in\nCI and XAI. We then discuss how counterfactuals are used, evaluated, generated,\nand operationalized in CI vs. XAI, highlighting conceptual and practical\ndifferences. By comparing and contrasting the two, we hope to identify\nopportunities for cross-fertilization across CI and XAI.", "published": "2025-05-19 16:34:36", "link": "http://arxiv.org/abs/2505.13324v1", "categories": ["stat.ML", "cs.AI", "cs.LG", "econ.EM", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Denoising Diffusion Probabilistic Model for Point Cloud Compression at Low Bit-Rates", "abstract": "Efficient compression of low-bit-rate point clouds is critical for\nbandwidth-constrained applications. However, existing techniques mainly focus\non high-fidelity reconstruction, requiring many bits for compression. This\npaper proposes a \"Denoising Diffusion Probabilistic Model\" (DDPM) architecture\nfor point cloud compression (DDPM-PCC) at low bit-rates. A PointNet encoder\nproduces the condition vector for the generation, which is then quantized via a\nlearnable vector quantizer. This configuration allows to achieve a low bitrates\nwhile preserving quality. Experiments on ShapeNet and ModelNet40 show improved\nrate-distortion at low rates compared to standardized and state-of-the-art\napproaches. We publicly released the code at\nhttps://github.com/EIDOSLAB/DDPM-PCC.", "published": "2025-05-19 16:29:12", "link": "http://arxiv.org/abs/2505.13316v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "KHRONOS: a Kernel-Based Neural Architecture for Rapid, Resource-Efficient Scientific Computation", "abstract": "Contemporary models of high dimensional physical systems are constrained by\nthe curse of dimensionality and a reliance on dense data. We introduce KHRONOS\n(Kernel Expansion Hierarchy for Reduced Order, Neural Optimized Surrogates), an\nAI framework for model based, model free and model inversion tasks. KHRONOS\nconstructs continuously differentiable target fields with a hierarchical\ncomposition of per-dimension kernel expansions, which are tensorized into modes\nand then superposed. We evaluate KHRONOS on a canonical 2D, Poisson equation\nbenchmark: across 16 to 512 degrees of freedom (DoFs), it obtained L2 square\nerrors of 5e-4 down to 6e-10. This represents a 100 time gain over Kolmogorov\nArnold Networks (which itself reports a 100 times improvement on MLPs/PINNs\nwith 100 times fewer parameters) when controlling for the number of parameters.\nThis also represents a 1e4 times improvement in L2 square error compared to\nstandard linear FEM at comparable DoFs. Inference complexity is dominated by\ninner products, yielding sub-millisecond full-field predictions that scale to\nan arbitrary resolution. For inverse problems, KHRONOS facilitates rapid,\niterative level set recovery in only a few forward evaluations, with\nsub-microsecond per sample latency. KHRONOS scalability, expressivity, and\ninterpretability open new avenues in constrained edge computing, online\ncontrol, computer vision, and beyond.", "published": "2025-05-19 16:29:07", "link": "http://arxiv.org/abs/2505.13315v1", "categories": ["cs.LG", "cs.AI", "cs.MS"], "primary_category": "cs.LG"}
{"title": "Cross-Cloud Data Privacy Protection: Optimizing Collaborative Mechanisms of AI Systems by Integrating Federated Learning and LLMs", "abstract": "In the age of cloud computing, data privacy protection has become a major\nchallenge, especially when sharing sensitive data across cloud environments.\nHowever, how to optimize collaboration across cloud environments remains an\nunresolved problem. In this paper, we combine federated learning with\nlarge-scale language models to optimize the collaborative mechanism of AI\nsystems. Based on the existing federated learning framework, we introduce a\ncross-cloud architecture in which federated learning works by aggregating model\nupdates from decentralized nodes without exposing the original data. At the\nsame time, combined with large-scale language models, its powerful context and\nsemantic understanding capabilities are used to improve model training\nefficiency and decision-making ability. We've further innovated by introducing\na secure communication layer to ensure the privacy and integrity of model\nupdates and training data. The model enables continuous model adaptation and\nfine-tuning across different cloud environments while protecting sensitive\ndata. Experimental results show that the proposed method is significantly\nbetter than the traditional federated learning model in terms of accuracy,\nconvergence speed and data privacy protection.", "published": "2025-05-19 16:14:27", "link": "http://arxiv.org/abs/2505.13292v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "TimeSeriesGym: A Scalable Benchmark for (Time Series) Machine Learning Engineering Agents", "abstract": "We introduce TimeSeriesGym, a scalable benchmarking framework for evaluating\nArtificial Intelligence (AI) agents on time series machine learning engineering\nchallenges. Existing benchmarks lack scalability, focus narrowly on model\nbuilding in well-defined settings, and evaluate only a limited set of research\nartifacts (e.g., CSV submission files). To make AI agent benchmarking more\nrelevant to the practice of machine learning engineering, our framework scales\nalong two critical dimensions. First, recognizing that effective ML engineering\nrequires a range of diverse skills, TimeSeriesGym incorporates challenges from\ndiverse sources spanning multiple domains and tasks. We design challenges to\nevaluate both isolated capabilities (including data handling, understanding\nresearch repositories, and code translation) and their combinations, and rather\nthan addressing each challenge independently, we develop tools that support\ndesigning multiple challenges at scale. Second, we implement evaluation\nmechanisms for multiple research artifacts, including submission files, code,\nand models, using both precise numeric measures and more flexible LLM-based\nevaluation approaches. This dual strategy balances objective assessment with\ncontextual judgment. Although our initial focus is on time series applications,\nour framework can be readily extended to other data modalities, broadly\nenhancing the comprehensiveness and practical utility of agentic AI evaluation.\nWe open-source our benchmarking framework to facilitate future research on the\nML engineering capabilities of AI agents.", "published": "2025-05-19 16:11:23", "link": "http://arxiv.org/abs/2505.13291v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Level Generation with Quantum Reservoir Computing", "abstract": "Reservoir computing is a form of machine learning particularly suited for\ntime series analysis, including forecasting predictions. We take an\nimplementation of \\emph{quantum} reservoir computing that was initially\ndesigned to generate variants of musical scores and adapt it to create levels\nof Super Mario Bros. Motivated by our analysis of these levels, we develop a\nnew Roblox \\textit{obby} where the courses can be generated in real time on\nsuperconducting qubit hardware, and investigate some of the constraints placed\nby such real-time generation.", "published": "2025-05-19 16:09:30", "link": "http://arxiv.org/abs/2505.13287v1", "categories": ["cs.AI", "quant-ph"], "primary_category": "cs.AI"}
{"title": "FlowPure: Continuous Normalizing Flows for Adversarial Purification", "abstract": "Despite significant advancements in the area, adversarial robustness remains\na critical challenge in systems employing machine learning models. The removal\nof adversarial perturbations at inference time, known as adversarial\npurification, has emerged as a promising defense strategy. To achieve this,\nstate-of-the-art methods leverage diffusion models that inject Gaussian noise\nduring a forward process to dilute adversarial perturbations, followed by a\ndenoising step to restore clean samples before classification. In this work, we\npropose FlowPure, a novel purification method based on Continuous Normalizing\nFlows (CNFs) trained with Conditional Flow Matching (CFM) to learn mappings\nfrom adversarial examples to their clean counterparts. Unlike prior\ndiffusion-based approaches that rely on fixed noise processes, FlowPure can\nleverage specific attack knowledge to improve robustness under known threats,\nwhile also supporting a more general stochastic variant trained on Gaussian\nperturbations for settings where such knowledge is unavailable. Experiments on\nCIFAR-10 and CIFAR-100 demonstrate that our method outperforms state-of-the-art\npurification-based defenses in preprocessor-blind and white-box scenarios, and\ncan do so while fully preserving benign accuracy in the former. Moreover, our\nresults show that not only is FlowPure a highly effective purifier but it also\nholds a strong potential for adversarial detection, identifying\npreprocessor-blind PGD samples with near-perfect accuracy.", "published": "2025-05-19 16:04:43", "link": "http://arxiv.org/abs/2505.13280v1", "categories": ["cs.LG", "cs.AI", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Seeing the Unseen: How EMoE Unveils Bias in Text-to-Image Diffusion Models", "abstract": "Estimating uncertainty in text-to-image diffusion models is challenging\nbecause of their large parameter counts (often exceeding 100 million) and\noperation in complex, high-dimensional spaces with virtually infinite input\npossibilities. In this paper, we propose Epistemic Mixture of Experts (EMoE), a\nnovel framework for efficiently estimating epistemic uncertainty in diffusion\nmodels. EMoE leverages pre-trained networks without requiring additional\ntraining, enabling direct uncertainty estimation from a prompt. We leverage a\nlatent space within the diffusion process that captures epistemic uncertainty\nbetter than existing methods. Experimental results on the COCO dataset\ndemonstrate EMoE's effectiveness, showing a strong correlation between\nuncertainty and image quality. Additionally, EMoE identifies under-sampled\nlanguages and regions with higher uncertainty, revealing hidden biases in the\ntraining set. This capability demonstrates the relevance of EMoE as a tool for\naddressing fairness and accountability in AI-generated content.", "published": "2025-05-19 15:53:32", "link": "http://arxiv.org/abs/2505.13273v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Net-Zero: A Comparative Study on Neural Network Design for Climate-Economic PDEs Under Uncertainty", "abstract": "Climate-economic modeling under uncertainty presents significant\ncomputational challenges that may limit policymakers' ability to address\nclimate change effectively. This paper explores neural network-based approaches\nfor solving high-dimensional optimal control problems arising from models that\nincorporate ambiguity aversion in climate mitigation decisions. We develop a\ncontinuous-time endogenous-growth economic model that accounts for multiple\nmitigation pathways, including emission-free capital and carbon intensity\nreductions. Given the inherent complexity and high dimensionality of these\nmodels, traditional numerical methods become computationally intractable. We\nbenchmark several neural network architectures against finite-difference\ngenerated solutions, evaluating their ability to capture the dynamic\ninteractions between uncertainty, technology transitions, and optimal climate\npolicy. Our findings demonstrate that appropriate neural architecture selection\nsignificantly impacts both solution accuracy and computational efficiency when\nmodeling climate-economic systems under uncertainty. These methodological\nadvances enable more sophisticated modeling of climate policy decisions,\nallowing for better representation of technology transitions and\nuncertainty-critical elements for developing effective mitigation strategies in\nthe face of climate change.", "published": "2025-05-19 15:46:12", "link": "http://arxiv.org/abs/2505.13264v1", "categories": ["cs.LG", "cs.AI", "cs.NE", "cs.PF", "math.AP", "68T07 (Primary) 35Q91, 91B76 (Secondary)", "I.2.1; I.5.1; J.4"], "primary_category": "cs.LG"}
{"title": "Composing Dextrous Grasping and In-hand Manipulation via Scoring with a Reinforcement Learning Critic", "abstract": "In-hand manipulation and grasping are fundamental yet often separately\naddressed tasks in robotics. For deriving in-hand manipulation policies,\nreinforcement learning has recently shown great success. However, the derived\ncontrollers are not yet useful in real-world scenarios because they often\nrequire a human operator to place the objects in suitable initial (grasping)\nstates. Finding stable grasps that also promote the desired in-hand\nmanipulation goal is an open problem. In this work, we propose a method for\nbridging this gap by leveraging the critic network of a reinforcement learning\nagent trained for in-hand manipulation to score and select initial grasps. Our\nexperiments show that this method significantly increases the success rate of\nin-hand manipulation without requiring additional training. We also present an\nimplementation of a full grasp manipulation pipeline on a real-world system,\nenabling autonomous grasping and reorientation even of unwieldy objects.", "published": "2025-05-19 15:36:34", "link": "http://arxiv.org/abs/2505.13253v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Agentic Publications: An LLM-Driven Framework for Interactive Scientific Publishing, Supplementing Traditional Papers with AI-Powered Knowledge Systems", "abstract": "The exponential growth of scientific literature presents significant\nchallenges for researchers navigating the complex knowledge landscape. We\npropose \"Agentic Publications\", a novel LLM-driven framework complementing\ntraditional publishing by transforming papers into interactive knowledge\nsystems. Our architecture integrates structured data with unstructured content\nthrough retrieval-augmented generation and multi-agent verification. The\nframework offers interfaces for both humans and machines, combining narrative\nexplanations with machine-readable outputs while addressing ethical\nconsiderations through automated validation and transparent governance. Key\nfeatures include continuous knowledge updates, automatic integration of new\nfindings, and customizable detail levels. Our proof-of-concept demonstrates\nmultilingual interaction, API accessibility, and structured knowledge\nrepresentation through vector databases, knowledge graphs, and verification\nagents. This approach enhances scientific communication across disciplines,\nimproving efficiency and collaboration while preserving traditional publishing\npathways, particularly valuable for interdisciplinary fields where knowledge\nintegration remains challenging.", "published": "2025-05-19 15:28:10", "link": "http://arxiv.org/abs/2505.13246v1", "categories": ["cs.AI", "cs.HC"], "primary_category": "cs.AI"}
{"title": "StarFT: Robust Fine-tuning of Zero-shot Models via Spuriosity Alignment", "abstract": "Learning robust representations from data often requires scale, which has led\nto the success of recent zero-shot models such as CLIP. However, the obtained\nrobustness can easily be deteriorated when these models are fine-tuned on other\ndownstream tasks (e.g., of smaller scales). Previous works often interpret this\nphenomenon in the context of domain shift, developing fine-tuning methods that\naim to preserve the original domain as much as possible. However, in a\ndifferent context, fine-tuned models with limited data are also prone to\nlearning features that are spurious to humans, such as background or texture.\nIn this paper, we propose StarFT (Spurious Textual Alignment Regularization), a\nnovel framework for fine-tuning zero-shot models to enhance robustness by\npreventing them from learning spuriosity. We introduce a regularization that\naligns the output distribution for spuriosity-injected labels with the original\nzero-shot model, ensuring that the model is not induced to extract irrelevant\nfeatures further from these descriptions.We leverage recent language models to\nget such spuriosity-injected labels by generating alternative textual\ndescriptions that highlight potentially confounding features.Extensive\nexperiments validate the robust generalization of StarFT and its emerging\nproperties: zero-shot group robustness and improved zero-shot classification.\nNotably, StarFT boosts both worst-group and average accuracy by 14.30% and\n3.02%, respectively, in the Waterbirds group shift scenario, where other robust\nfine-tuning baselines show even degraded performance.", "published": "2025-05-19 15:15:35", "link": "http://arxiv.org/abs/2505.13232v1", "categories": ["cs.AI", "cs.CV"], "primary_category": "cs.AI"}
{"title": "MAGI-1: Autoregressive Video Generation at Scale", "abstract": "We present MAGI-1, a world model that generates videos by autoregressively\npredicting a sequence of video chunks, defined as fixed-length segments of\nconsecutive frames. Trained to denoise per-chunk noise that increases\nmonotonically over time, MAGI-1 enables causal temporal modeling and naturally\nsupports streaming generation. It achieves strong performance on image-to-video\n(I2V) tasks conditioned on text instructions, providing high temporal\nconsistency and scalability, which are made possible by several algorithmic\ninnovations and a dedicated infrastructure stack. MAGI-1 facilitates\ncontrollable generation via chunk-wise prompting and supports real-time,\nmemory-efficient deployment by maintaining constant peak inference cost,\nregardless of video length. The largest variant of MAGI-1 comprises 24 billion\nparameters and supports context lengths of up to 4 million tokens,\ndemonstrating the scalability and robustness of our approach. The code and\nmodels are available at https://github.com/SandAI-org/MAGI-1 and\nhttps://github.com/SandAI-org/MagiAttention. The product can be accessed at\nhttps://sand.ai.", "published": "2025-05-19 14:58:50", "link": "http://arxiv.org/abs/2505.13211v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "MatPredict: a dataset and benchmark for learning material properties of diverse indoor objects", "abstract": "Determining material properties from camera images can expand the ability to\nidentify complex objects in indoor environments, which is valuable for consumer\nrobotics applications. To support this, we introduce MatPredict, a dataset that\ncombines the high-quality synthetic objects from Replica dataset with MatSynth\ndataset's material properties classes - to create objects with diverse material\nproperties. We select 3D meshes of specific foreground objects and render them\nwith different material properties. In total, we generate \\textbf{18} commonly\noccurring objects with \\textbf{14} different materials. We showcase how we\nprovide variability in terms of lighting and camera placement for these\nobjects. Next, we provide a benchmark for inferring material properties from\nvisual images using these perturbed models in the scene, discussing the\nspecific neural network models involved and their performance based on\ndifferent image comparison metrics. By accurately simulating light interactions\nwith different materials, we can enhance realism, which is crucial for training\nmodels effectively through large-scale simulations. This research aims to\nrevolutionize perception in consumer robotics. The dataset is provided\n\\href{https://huggingface.co/datasets/UMTRI/MatPredict}{here} and the code is\nprovided \\href{https://github.com/arpan-kusari/MatPredict}{here}.", "published": "2025-05-19 14:54:04", "link": "http://arxiv.org/abs/2505.13201v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A Physics-Inspired Optimizer: Velocity Regularized Adam", "abstract": "We introduce Velocity-Regularized Adam (VRAdam), a physics-inspired optimizer\nfor training deep neural networks that draws on ideas from quartic terms for\nkinetic energy with its stabilizing effects on various system dynamics.\nPrevious algorithms, including the ubiquitous Adam, operate at the so called\nadaptive edge of stability regime during training leading to rapid oscillations\nand slowed convergence of loss. However, VRAdam adds a higher order penalty on\nthe learning rate based on the velocity such that the algorithm automatically\nslows down whenever weight updates become large. In practice, we observe that\nthe effective dynamic learning rate shrinks in high-velocity regimes, damping\noscillations and allowing for a more aggressive base step size when necessary\nwithout divergence. By combining this velocity-based regularizer for global\ndamping with per-parameter scaling of Adam to create a hybrid optimizer, we\ndemonstrate that VRAdam consistently exceeds the performance against standard\noptimizers including AdamW. We benchmark various tasks such as image\nclassification, language modeling, image generation and generative modeling\nusing diverse architectures and training methodologies including Convolutional\nNeural Networks (CNNs), Transformers, and GFlowNets.", "published": "2025-05-19 14:51:40", "link": "http://arxiv.org/abs/2505.13196v1", "categories": ["cs.LG", "cs.AI", "quant-ph"], "primary_category": "cs.LG"}
{"title": "Adversarial Testing in LLMs: Insights into Decision-Making Vulnerabilities", "abstract": "As Large Language Models (LLMs) become increasingly integrated into\nreal-world decision-making systems, understanding their behavioural\nvulnerabilities remains a critical challenge for AI safety and alignment. While\nexisting evaluation metrics focus primarily on reasoning accuracy or factual\ncorrectness, they often overlook whether LLMs are robust to adversarial\nmanipulation or capable of using adaptive strategy in dynamic environments.\nThis paper introduces an adversarial evaluation framework designed to\nsystematically stress-test the decision-making processes of LLMs under\ninteractive and adversarial conditions. Drawing on methodologies from cognitive\npsychology and game theory, our framework probes how models respond in two\ncanonical tasks: the two-armed bandit task and the Multi-Round Trust Task.\nThese tasks capture key aspects of exploration-exploitation trade-offs, social\ncooperation, and strategic flexibility. We apply this framework to several\nstate-of-the-art LLMs, including GPT-3.5, GPT-4, Gemini-1.5, and DeepSeek-V3,\nrevealing model-specific susceptibilities to manipulation and rigidity in\nstrategy adaptation. Our findings highlight distinct behavioral patterns across\nmodels and emphasize the importance of adaptability and fairness recognition\nfor trustworthy AI deployment. Rather than offering a performance benchmark,\nthis work proposes a methodology for diagnosing decision-making weaknesses in\nLLM-based agents, providing actionable insights for alignment and safety\nresearch.", "published": "2025-05-19 14:50:44", "link": "http://arxiv.org/abs/2505.13195v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "True Zero-Shot Inference of Dynamical Systems Preserving Long-Term Statistics", "abstract": "Complex, temporally evolving phenomena, from climate to brain activity, are\ngoverned by dynamical systems (DS). DS reconstruction (DSR) seeks to infer\ngenerative surrogate models of these from observed data, reproducing their\nlong-term behavior. Existing DSR approaches require purpose-training for any\nnew system observed, lacking the zero-shot and in-context inference\ncapabilities known from LLMs. Here we introduce DynaMix, a novel multivariate\nALRNN-based mixture-of-experts architecture pre-trained for DSR, the first DSR\nmodel able to generalize zero-shot to out-of-domain DS. Just from a provided\ncontext signal, without any re-training, DynaMix faithfully forecasts the\nlong-term evolution of novel DS where existing time series (TS) foundation\nmodels, like Chronos, fail -- at a fraction of the number of parameters and\norders of magnitude faster inference times. DynaMix outperforms TS foundation\nmodels in terms of long-term statistics, and often also short-term forecasts,\neven on real-world time series, like traffic or weather data, typically used\nfor training and evaluating TS models, but not at all part of DynaMix' training\ncorpus. We illustrate some of the failure modes of TS models for DSR problems,\nand conclude that models built on DS principles may bear a huge potential also\nfor advancing the TS prediction field.", "published": "2025-05-19 14:49:10", "link": "http://arxiv.org/abs/2505.13192v1", "categories": ["cs.LG", "cs.AI", "math.DS", "nlin.CD"], "primary_category": "cs.LG"}
{"title": "Emergence of Fixational and Saccadic Movements in a Multi-Level Recurrent Attention Model for Vision", "abstract": "Inspired by foveal vision, hard attention models promise interpretability and\nparameter economy. However, existing models like the Recurrent Model of Visual\nAttention (RAM) and Deep Recurrent Attention Model (DRAM) failed to model the\nhierarchy of human vision system, that compromise on the visual exploration\ndynamics. As a result, they tend to produce attention that are either overly\nfixational or excessively saccadic, diverging from human eye movement behavior.\nIn this paper, we propose a Multi-Level Recurrent Attention Model (MRAM), a\nnovel hard attention framework that explicitly models the neural hierarchy of\nhuman visual processing. By decoupling the function of glimpse location\ngeneration and task execution in two recurrent layers, MRAM emergent a balanced\nbehavior between fixation and saccadic movement. Our results show that MRAM not\nonly achieves more human-like attention dynamics, but also consistently\noutperforms CNN, RAM and DRAM baselines on standard image classification\nbenchmarks.", "published": "2025-05-19 14:48:36", "link": "http://arxiv.org/abs/2505.13191v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "When a Reinforcement Learning Agent Encounters Unknown Unknowns", "abstract": "An AI agent might surprisingly find she has reached an unknown state which\nshe has never been aware of -- an unknown unknown. We mathematically ground\nthis scenario in reinforcement learning: an agent, after taking an action\ncalculated from value functions $Q$ and $V$ defined on the {\\it {aware\ndomain}}, reaches a state out of the domain. To enable the agent to handle this\nscenario, we propose an {\\it episodic Markov decision {process} with growing\nawareness} (EMDP-GA) model, taking a new {\\it noninformative value expansion}\n(NIVE) approach to expand value functions to newly aware areas: when an agent\narrives at an unknown unknown, value functions $Q$ and $V$ whereon are\ninitialised by noninformative beliefs -- the averaged values on the aware\ndomain. This design is out of respect for the complete absence of knowledge in\nthe newly discovered state. The upper confidence bound momentum Q-learning is\nthen adapted to the growing awareness for training the EMDP-GA model. We prove\nthat (1) the regret of our approach is asymptotically consistent with the state\nof the art (SOTA) without exposure to unknown unknowns in an extremely\nuncertain environment, and (2) our computational complexity and space\ncomplexity are comparable with the SOTA -- these collectively suggest that\nthough an unknown unknown is surprising, it will be asymptotically properly\ndiscovered with decent speed and an affordable cost.", "published": "2025-05-19 14:45:58", "link": "http://arxiv.org/abs/2505.13188v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Information Science Principles of Machine Learning: A Causal Chain Meta-Framework Based on Formalized Information Mapping", "abstract": "[Objective] This study focuses on addressing the current lack of a unified\nformal theoretical framework in machine learning, as well as the deficiencies\nin interpretability and ethical safety assurance. [Methods] A formal\ninformation model is first constructed, utilizing sets of well-formed formulas\nto explicitly define the ontological states and carrier mappings of typical\ncomponents in machine learning. Learnable and processable predicates, along\nwith learning and processing functions, are introduced to analyze the logical\ndeduction and constraint rules of the causal chains within models. [Results] A\nmeta-framework for machine learning theory (MLT-MF) is established. Based on\nthis framework, universal definitions for model interpretability and ethical\nsafety are proposed. Furthermore, three key theorems are proved: the\nequivalence of model interpretability and information recoverability, the\nassurance of ethical safety, and the estimation of generalization error.\n[Limitations] The current framework assumes ideal conditions with noiseless\ninformation-enabling mappings and primarily targets model learning and\nprocessing logic in static scenarios. It does not yet address information\nfusion and conflict resolution across ontological spaces in multimodal or\nmulti-agent systems. [Conclusions] This work overcomes the limitations of\nfragmented research and provides a unified theoretical foundation for\nsystematically addressing the critical challenges currently faced in machine\nlearning.", "published": "2025-05-19 14:39:41", "link": "http://arxiv.org/abs/2505.13182v1", "categories": ["cs.LO", "cs.AI"], "primary_category": "cs.LO"}
{"title": "ViPlan: A Benchmark for Visual Planning with Symbolic Predicates and Vision-Language Models", "abstract": "Integrating Large Language Models with symbolic planners is a promising\ndirection for obtaining verifiable and grounded plans compared to planning in\nnatural language, with recent works extending this idea to visual domains using\nVision-Language Models (VLMs). However, rigorous comparison between\nVLM-grounded symbolic approaches and methods that plan directly with a VLM has\nbeen hindered by a lack of common environments, evaluation protocols and model\ncoverage. We introduce ViPlan, the first open-source benchmark for Visual\nPlanning with symbolic predicates and VLMs. ViPlan features a series of\nincreasingly challenging tasks in two domains: a visual variant of the classic\nBlocksworld planning problem and a simulated household robotics environment. We\nbenchmark nine open-source VLM families across multiple sizes, along with\nselected closed models, evaluating both VLM-grounded symbolic planning and\nusing the models directly to propose actions. We find symbolic planning to\noutperform direct VLM planning in Blocksworld, where accurate image grounding\nis crucial, whereas the opposite is true in the household robotics tasks, where\ncommonsense knowledge and the ability to recover from errors are beneficial.\nFinally, we show that across most models and methods, there is no significant\nbenefit to using Chain-of-Thought prompting, suggesting that current VLMs still\nstruggle with visual reasoning.", "published": "2025-05-19 14:38:15", "link": "http://arxiv.org/abs/2505.13180v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Enhancing LLMs for Time Series Forecasting via Structure-Guided Cross-Modal Alignment", "abstract": "The emerging paradigm of leveraging pretrained large language models (LLMs)\nfor time series forecasting has predominantly employed linguistic-temporal\nmodality alignment strategies through token-level or layer-wise feature\nmapping. However, these approaches fundamentally neglect a critical insight:\nthe core competency of LLMs resides not merely in processing localized token\nfeatures but in their inherent capacity to model holistic sequence structures.\nThis paper posits that effective cross-modal alignment necessitates structural\nconsistency at the sequence level. We propose the Structure-Guided Cross-Modal\nAlignment (SGCMA), a framework that fully exploits and aligns the\nstate-transition graph structures shared by time-series and linguistic data as\nsequential modalities, thereby endowing time series with language-like\nproperties and delivering stronger generalization after modality alignment.\nSGCMA consists of two key components, namely Structure Alignment and Semantic\nAlignment. In Structure Alignment, a state transition matrix is learned from\ntext data through Hidden Markov Models (HMMs), and a shallow transformer-based\nMaximum Entropy Markov Model (MEMM) receives the hot-start transition matrix\nand annotates each temporal patch into state probability, ensuring that the\ntemporal representation sequence inherits language-like sequential dynamics. In\nSemantic Alignment, cross-attention is applied between temporal patches and the\ntop-k tokens within each state, and the ultimate temporal embeddings are\nderived by the expected value of these embeddings using a weighted average\nbased on state probabilities. Experiments on multiple benchmarks demonstrate\nthat SGCMA achieves state-of-the-art performance, offering a novel approach to\ncross-modal alignment in time series forecasting.", "published": "2025-05-19 14:30:41", "link": "http://arxiv.org/abs/2505.13175v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Temporal Distance-aware Transition Augmentation for Offline Model-based Reinforcement Learning", "abstract": "The goal of offline reinforcement learning (RL) is to extract a\nhigh-performance policy from the fixed datasets, minimizing performance\ndegradation due to out-of-distribution (OOD) samples. Offline model-based RL\n(MBRL) is a promising approach that ameliorates OOD issues by enriching\nstate-action transitions with augmentations synthesized via a learned dynamics\nmodel. Unfortunately, seminal offline MBRL methods often struggle in\nsparse-reward, long-horizon tasks. In this work, we introduce a novel MBRL\nframework, dubbed Temporal Distance-Aware Transition Augmentation (TempDATA),\nthat generates augmented transitions in a temporally structured latent space\nrather than in raw state space. To model long-horizon behavior, TempDATA learns\na latent abstraction that captures a temporal distance from both trajectory and\ntransition levels of state space. Our experiments confirm that TempDATA\noutperforms previous offline MBRL methods and achieves matching or surpassing\nthe performance of diffusion-based trajectory augmentation and goal-conditioned\nRL on the D4RL AntMaze, FrankaKitchen, CALVIN, and pixel-based FrankaKitchen.", "published": "2025-05-19 14:11:14", "link": "http://arxiv.org/abs/2505.13144v1", "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "cs.LG"}
{"title": "Adaptive Image Restoration for Video Surveillance: A Real-Time Approach", "abstract": "One of the major challenges in the field of computer vision especially for\ndetection, segmentation, recognition, monitoring, and automated solutions, is\nthe quality of images. Image degradation, often caused by factors such as rain,\nfog, lighting, etc., has a negative impact on automated\ndecision-making.Furthermore, several image restoration solutions exist,\nincluding restoration models for single degradation and restoration models for\nmultiple degradations. However, these solutions are not suitable for real-time\nprocessing. In this study, the aim was to develop a real-time image restoration\nsolution for video surveillance. To achieve this, using transfer learning with\nResNet_50, we developed a model for automatically identifying the types of\ndegradation present in an image to reference the necessary treatment(s) for\nimage restoration. Our solution has the advantage of being flexible and\nscalable.", "published": "2025-05-19 14:00:10", "link": "http://arxiv.org/abs/2505.13130v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "$\u03bc$PC: Scaling Predictive Coding to 100+ Layer Networks", "abstract": "The biological implausibility of backpropagation (BP) has motivated many\nalternative, brain-inspired algorithms that attempt to rely only on local\ninformation, such as predictive coding (PC) and equilibrium propagation.\nHowever, these algorithms have notoriously struggled to train very deep\nnetworks, preventing them from competing with BP in large-scale settings.\nIndeed, scaling PC networks (PCNs) has recently been posed as a challenge for\nthe community (Pinchetti et al., 2024). Here, we show that 100+ layer PCNs can\nbe trained reliably using a Depth-$\\mu$P parameterisation (Yang et al., 2023;\nBordelon et al., 2023) which we call \"$\\mu$PC\". Through an extensive analysis\nof the scaling behaviour of PCNs, we reveal several pathologies that make\nstandard PCNs difficult to train at large depths. We then show that, despite\naddressing only some of these instabilities, $\\mu$PC allows stable training of\nvery deep (up to 128-layer) residual networks on simple classification tasks\nwith competitive performance and little tuning compared to current benchmarks.\nMoreover, $\\mu$PC enables zero-shot transfer of both weight and activity\nlearning rates across widths and depths. Our results have implications for\nother local algorithms and could be extended to convolutional and transformer\narchitectures. Code for $\\mu$PC is made available as part of a JAX library for\nPCNs at https://github.com/thebuckleylab/jpc (Innocenti et al., 2024).", "published": "2025-05-19 13:54:29", "link": "http://arxiv.org/abs/2505.13124v1", "categories": ["cs.LG", "cs.AI", "cs.NE", "I.2.6"], "primary_category": "cs.LG"}
{"title": "Just Dance with $\u03c0$! A Poly-modal Inductor for Weakly-supervised Video Anomaly Detection", "abstract": "Weakly-supervised methods for video anomaly detection (VAD) are\nconventionally based merely on RGB spatio-temporal features, which continues to\nlimit their reliability in real-world scenarios. This is due to the fact that\nRGB-features are not sufficiently distinctive in setting apart categories such\nas shoplifting from visually similar events. Therefore, towards robust complex\nreal-world VAD, it is essential to augment RGB spatio-temporal features by\nadditional modalities. Motivated by this, we introduce the Poly-modal Induced\nframework for VAD: \"PI-VAD\", a novel approach that augments RGB representations\nby five additional modalities. Specifically, the modalities include sensitivity\nto fine-grained motion (Pose), three dimensional scene and entity\nrepresentation (Depth), surrounding objects (Panoptic masks), global motion\n(optical flow), as well as language cues (VLM). Each modality represents an\naxis of a polygon, streamlined to add salient cues to RGB. PI-VAD includes two\nplug-in modules, namely Pseudo-modality Generation module and Cross Modal\nInduction module, which generate modality-specific prototypical representation\nand, thereby, induce multi-modal information into RGB cues. These modules\noperate by performing anomaly-aware auxiliary tasks and necessitate five\nmodality backbones -- only during training. Notably, PI-VAD achieves\nstate-of-the-art accuracy on three prominent VAD datasets encompassing\nreal-world scenarios, without requiring the computational overhead of five\nmodality backbones at inference.", "published": "2025-05-19 13:51:57", "link": "http://arxiv.org/abs/2505.13123v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "When majority rules, minority loses: bias amplification of gradient descent", "abstract": "Despite growing empirical evidence of bias amplification in machine learning,\nits theoretical foundations remain poorly understood. We develop a formal\nframework for majority-minority learning tasks, showing how standard training\ncan favor majority groups and produce stereotypical predictors that neglect\nminority-specific features. Assuming population and variance imbalance, our\nanalysis reveals three key findings: (i) the close proximity between\n``full-data'' and stereotypical predictors, (ii) the dominance of a region\nwhere training the entire model tends to merely learn the majority traits, and\n(iii) a lower bound on the additional training required. Our results are\nillustrated through experiments in deep learning for tabular and image\nclassification tasks.", "published": "2025-05-19 13:51:49", "link": "http://arxiv.org/abs/2505.13122v1", "categories": ["cs.LG", "cs.AI", "math.OC"], "primary_category": "cs.LG"}
{"title": "Unveil Sources of Uncertainty: Feature Contribution to Conformal Prediction Intervals", "abstract": "Cooperative game theory methods, notably Shapley values, have significantly\nenhanced machine learning (ML) interpretability. However, existing explainable\nAI (XAI) frameworks mainly attribute average model predictions, overlooking\npredictive uncertainty. This work addresses that gap by proposing a novel,\nmodel-agnostic uncertainty attribution (UA) method grounded in conformal\nprediction (CP). By defining cooperative games where CP interval\nproperties-such as width and bounds-serve as value functions, we systematically\nattribute predictive uncertainty to input features. Extending beyond the\ntraditional Shapley values, we use the richer class of Harsanyi allocations,\nand in particular the proportional Shapley values, which distribute attribution\nproportionally to feature importance. We propose a Monte Carlo approximation\nmethod with robust statistical guarantees to address computational feasibility,\nsignificantly improving runtime efficiency. Our comprehensive experiments on\nsynthetic benchmarks and real-world datasets demonstrate the practical utility\nand interpretative depth of our approach. By combining cooperative game theory\nand conformal prediction, we offer a rigorous, flexible toolkit for\nunderstanding and communicating predictive uncertainty in high-stakes ML\napplications.", "published": "2025-05-19 13:49:05", "link": "http://arxiv.org/abs/2505.13118v1", "categories": ["cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.AI"}
{"title": "Continuous Fair SMOTE -- Fairness-Aware Stream Learning from Imbalanced Data", "abstract": "As machine learning is increasingly applied in an online fashion to deal with\nevolving data streams, the fairness of these algorithms is a matter of growing\nethical and legal concern. In many use cases, class imbalance in the data also\nneeds to be dealt with to ensure predictive performance. Current fairness-aware\nstream learners typically attempt to solve these issues through in- or\npost-processing by focusing on optimizing one specific discrimination metric,\naddressing class imbalance in a separate processing step. While C-SMOTE is a\nhighly effective model-agnostic pre-processing approach to mitigate class\nimbalance, as a side effect of this method, algorithmic bias is often\nintroduced.\n  Therefore, we propose CFSMOTE - a fairness-aware, continuous SMOTE variant -\nas a pre-processing approach to simultaneously address the class imbalance and\nfairness concerns by employing situation testing and balancing\nfairness-relevant groups during oversampling. Unlike other fairness-aware\nstream learners, CFSMOTE is not optimizing for only one specific fairness\nmetric, therefore avoiding potentially problematic trade-offs. Our experiments\nshow significant improvement on several common group fairness metrics in\ncomparison to vanilla C-SMOTE while maintaining competitive performance, also\nin comparison to other fairness-aware algorithms.", "published": "2025-05-19 13:46:47", "link": "http://arxiv.org/abs/2505.13116v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Lightweight Transformer via Unrolling of Mixed Graph Algorithms for Traffic Forecast", "abstract": "To forecast traffic with both spatial and temporal dimensions, we unroll a\nmixed-graph-based optimization algorithm into a lightweight and interpretable\ntransformer-like neural net. Specifically, we construct two graphs: an\nundirected graph $\\mathcal{G}^u$ capturing spatial correlations across\ngeography, and a directed graph $\\mathcal{G}^d$ capturing sequential\nrelationships over time. We formulate a prediction problem for the future\nsamples of signal $\\mathbf{x}$, assuming it is \"smooth\" with respect to both\n$\\mathcal{G}^u$ and $\\mathcal{G}^d$, where we design new $\\ell_2$ and\n$\\ell_1$-norm variational terms to quantify and promote signal smoothness\n(low-frequency reconstruction) on a directed graph. We construct an iterative\nalgorithm based on alternating direction method of multipliers (ADMM), and\nunroll it into a feed-forward network for data-driven parameter learning. We\ninsert graph learning modules for $\\mathcal{G}^u$ and $\\mathcal{G}^d$, which\nare akin to the self-attention mechanism in classical transformers. Experiments\nshow that our unrolled networks achieve competitive traffic forecast\nperformance as state-of-the-art prediction schemes, while reducing parameter\ncounts drastically. Our code is available in\nhttps://github.com/SingularityUndefined/Unrolling-GSP-STForecast.", "published": "2025-05-19 13:32:34", "link": "http://arxiv.org/abs/2505.13102v1", "categories": ["cs.LG", "cs.AI", "eess.SP"], "primary_category": "cs.LG"}
{"title": "ARIW-Framework: Adaptive Robust Iterative Watermarking Framework", "abstract": "With the rapid rise of large models, copyright protection for generated image\ncontent has become a critical security challenge. Although deep learning\nwatermarking techniques offer an effective solution for digital image copyright\nprotection, they still face limitations in terms of visual quality, robustness\nand generalization. To address these issues, this paper proposes an adaptive\nrobust iterative watermarking framework (ARIW-Framework) that achieves\nhigh-quality watermarked images while maintaining exceptional robustness and\ngeneralization performance. Specifically, we introduce an iterative approach to\noptimize the encoder for generating robust residuals. The encoder incorporates\nnoise layers and a decoder to compute robustness weights for residuals under\nvarious noise attacks. By employing a parallel optimization strategy, the\nframework enhances robustness against multiple types of noise attacks.\nFurthermore, we leverage image gradients to determine the embedding strength at\neach pixel location, significantly improving the visual quality of the\nwatermarked images. Extensive experiments demonstrate that the proposed method\nachieves superior visual quality while exhibiting remarkable robustness and\ngeneralization against noise attacks.", "published": "2025-05-19 13:31:48", "link": "http://arxiv.org/abs/2505.13101v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Time-Frequency-Based Attention Cache Memory Model for Real-Time Speech Separation", "abstract": "Existing causal speech separation models often underperform compared to\nnon-causal models due to difficulties in retaining historical information. To\naddress this, we propose the Time-Frequency Attention Cache Memory (TFACM)\nmodel, which effectively captures spatio-temporal relationships through an\nattention mechanism and cache memory (CM) for historical information storage.\nIn TFACM, an LSTM layer captures frequency-relative positions, while causal\nmodeling is applied to the time dimension using local and global\nrepresentations. The CM module stores past information, and the causal\nattention refinement (CAR) module further enhances time-based feature\nrepresentations for finer granularity. Experimental results showed that TFACM\nachieveed comparable performance to the SOTA TF-GridNet-Causal model, with\nsignificantly lower complexity and fewer trainable parameters. For more\ndetails, visit the project page: https://cslikai.cn/TFACM/.", "published": "2025-05-19 13:25:51", "link": "http://arxiv.org/abs/2505.13094v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Graph Alignment for Benchmarking Graph Neural Networks and Learning Positional Encodings", "abstract": "We propose a novel benchmarking methodology for graph neural networks (GNNs)\nbased on the graph alignment problem, a combinatorial optimization task that\ngeneralizes graph isomorphism by aligning two unlabeled graphs to maximize\noverlapping edges. We frame this problem as a self-supervised learning task and\npresent several methods to generate graph alignment datasets using synthetic\nrandom graphs and real-world graph datasets from multiple domains. For a given\ngraph dataset, we generate a family of graph alignment datasets with increasing\ndifficulty, allowing us to rank the performance of various architectures. Our\nexperiments indicate that anisotropic graph neural networks outperform standard\nconvolutional architectures. To further demonstrate the utility of the graph\nalignment task, we show its effectiveness for unsupervised GNN pre-training,\nwhere the learned node embeddings outperform other positional encodings on\nthree molecular regression tasks and achieve state-of-the-art results on the\nPCQM4Mv2 dataset with significantly fewer parameters. To support\nreproducibility and further research, we provide an open-source Python package\nto generate graph alignment datasets and benchmark new GNN architectures.", "published": "2025-05-19 13:22:17", "link": "http://arxiv.org/abs/2505.13087v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "MultiActor-Audiobook: Zero-Shot Audiobook Generation with Faces and Voices of Multiple Speakers", "abstract": "We introduce MultiActor-Audiobook, a zero-shot approach for generating\naudiobooks that automatically produces consistent, expressive, and\nspeaker-appropriate prosody, including intonation and emotion. Previous\naudiobook systems have several limitations: they require users to manually\nconfigure the speaker's prosody, read each sentence with a monotonic tone\ncompared to voice actors, or rely on costly training. However, our\nMultiActor-Audiobook addresses these issues by introducing two novel processes:\n(1) MSP (**Multimodal Speaker Persona Generation**) and (2) LSI (**LLM-based\nScript Instruction Generation**). With these two processes,\nMultiActor-Audiobook can generate more emotionally expressive audiobooks with a\nconsistent speaker prosody without additional training. We compare our system\nwith commercial products, through human and MLLM evaluations, achieving\ncompetitive results. Furthermore, we demonstrate the effectiveness of MSP and\nLSI through ablation studies.", "published": "2025-05-19 13:13:46", "link": "http://arxiv.org/abs/2505.13082v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Cross-modal Knowledge Transfer Learning as Graph Matching Based on Optimal Transport for ASR", "abstract": "Transferring linguistic knowledge from a pretrained language model (PLM) to\nacoustic feature learning has proven effective in enhancing end-to-end\nautomatic speech recognition (E2E-ASR). However, aligning representations\nbetween linguistic and acoustic modalities remains a challenge due to inherent\nmodality gaps. Optimal transport (OT) has shown promise in mitigating these\ngaps by minimizing the Wasserstein distance (WD) between linguistic and\nacoustic feature distributions. However, previous OT-based methods overlook\nstructural relationships, treating feature vectors as unordered sets. To\naddress this, we propose Graph Matching Optimal Transport (GM-OT), which models\nlinguistic and acoustic sequences as structured graphs. Nodes represent feature\nembeddings, while edges capture temporal and sequential relationships. GM-OT\nminimizes both WD (between nodes) and Gromov-Wasserstein distance (GWD)\n(between edges), leading to a fused Gromov-Wasserstein distance (FGWD)\nformulation. This enables structured alignment and more efficient knowledge\ntransfer compared to existing OT-based approaches. Theoretical analysis further\nshows that prior OT-based methods in linguistic knowledge transfer can be\nviewed as a special case within our GM-OT framework. We evaluate GM-OT on\nMandarin ASR using a CTC-based E2E-ASR system with a PLM for knowledge\ntransfer. Experimental results demonstrate significant performance gains over\nstate-of-the-art models, validating the effectiveness of our approach.", "published": "2025-05-19 13:13:18", "link": "http://arxiv.org/abs/2505.13079v1", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "The Hidden Dangers of Browsing AI Agents", "abstract": "Autonomous browsing agents powered by large language models (LLMs) are\nincreasingly used to automate web-based tasks. However, their reliance on\ndynamic content, tool execution, and user-provided data exposes them to a broad\nattack surface. This paper presents a comprehensive security evaluation of such\nagents, focusing on systemic vulnerabilities across multiple architectural\nlayers. Our work outlines the first end-to-end threat model for browsing agents\nand provides actionable guidance for securing their deployment in real-world\nenvironments. To address discovered threats, we propose a defense in depth\nstrategy incorporating input sanitization, planner executor isolation, formal\nanalyzers, and session safeguards. These measures protect against both initial\naccess and post exploitation attack vectors. Through a white box analysis of a\npopular open source project, Browser Use, we demonstrate how untrusted web\ncontent can hijack agent behavior and lead to critical security breaches. Our\nfindings include prompt injection, domain validation bypass, and credential\nexfiltration, evidenced by a disclosed CVE and a working proof of concept\nexploit.", "published": "2025-05-19 13:10:29", "link": "http://arxiv.org/abs/2505.13076v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Structure-Aware Corpus Construction and User-Perception-Aligned Metrics for Large-Language-Model Code Completion", "abstract": "Code completion technology based on large language model has significantly\nimproved the development efficiency of programmers. However, in practical\napplications, there remains a gap between current commonly used code completion\nevaluation metrics and users' actual perception. To address this issue, we\npropose two evaluation metrics for code completion tasks--LCP and ROUGE-LCP,\nfrom the perspective of probabilistic modeling. Furthermore, to tackle the lack\nof effective structural semantic modeling and cross-module dependency\ninformation in LLMs for repository-level code completion scenarios, we propose\na data processing method based on a Structure-Preserving and\nSemantically-Reordered Code Graph (SPSR-Graph). Through theoretical analysis\nand experimental validation, we demonstrate the superiority of the proposed\nevaluation metrics in terms of user perception consistency, as well as the\neffectiveness of the data processing method in enhancing model performance.", "published": "2025-05-19 13:09:32", "link": "http://arxiv.org/abs/2505.13073v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "A Generalized Label Shift Perspective for Cross-Domain Gaze Estimation", "abstract": "Aiming to generalize the well-trained gaze estimation model to new target\ndomains, Cross-domain Gaze Estimation (CDGE) is developed for real-world\napplication scenarios. Existing CDGE methods typically extract the\ndomain-invariant features to mitigate domain shift in feature space, which is\nproved insufficient by Generalized Label Shift (GLS) theory. In this paper, we\nintroduce a novel GLS perspective to CDGE and modelize the cross-domain problem\nby label and conditional shift problem. A GLS correction framework is presented\nand a feasible realization is proposed, in which a importance reweighting\nstrategy based on truncated Gaussian distribution is introduced to overcome the\ncontinuity challenges in label shift correction. To embed the reweighted source\ndistribution to conditional invariant learning, we further derive a\nprobability-aware estimation of conditional operator discrepancy. Extensive\nexperiments on standard CDGE tasks with different backbone models validate the\nsuperior generalization capability across domain and applicability on various\nmodels of proposed method.", "published": "2025-05-19 12:33:52", "link": "http://arxiv.org/abs/2505.13043v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "CAIM: Development and Evaluation of a Cognitive AI Memory Framework for Long-Term Interaction with Intelligent Agents", "abstract": "Large language models (LLMs) have advanced the field of artificial\nintelligence (AI) and are a powerful enabler for interactive systems. However,\nthey still face challenges in long-term interactions that require adaptation\ntowards the user as well as contextual knowledge and understanding of the\never-changing environment. To overcome these challenges, holistic memory\nmodeling is required to efficiently retrieve and store relevant information\nacross interaction sessions for suitable responses. Cognitive AI, which aims to\nsimulate the human thought process in a computerized model, highlights\ninteresting aspects, such as thoughts, memory mechanisms, and decision-making,\nthat can contribute towards improved memory modeling for LLMs. Inspired by\nthese cognitive AI principles, we propose our memory framework CAIM. CAIM\nconsists of three modules: 1.) The Memory Controller as the central decision\nunit; 2.) the Memory Retrieval, which filters relevant data for interaction\nupon request; and 3.) the Post-Thinking, which maintains the memory storage. We\ncompare CAIM against existing approaches, focusing on metrics such as retrieval\naccuracy, response correctness, contextual coherence, and memory storage. The\nresults demonstrate that CAIM outperforms baseline frameworks across different\nmetrics, highlighting its context-awareness and potential to improve long-term\nhuman-AI interactions.", "published": "2025-05-19 12:33:52", "link": "http://arxiv.org/abs/2505.13044v1", "categories": ["cs.AI", "cs.HC"], "primary_category": "cs.AI"}
{"title": "TSPulse: Dual Space Tiny Pre-Trained Models for Rapid Time-Series Analysis", "abstract": "The rise of time-series pre-trained models has advanced temporal\nrepresentation learning, but current state-of-the-art models are often\nlarge-scale, requiring substantial compute. We introduce TSPulse, ultra-compact\ntime-series pre-trained models with only 1M parameters, specialized to perform\nstrongly across classification, anomaly detection, imputation, and retrieval\ntasks. TSPulse introduces innovations at both the architecture and task levels.\nAt the architecture level, it employs a dual-space masked reconstruction,\nlearning from both time and frequency domains to capture complementary signals.\nThis is further enhanced by a dual-embedding disentanglement, generating both\ndetailed embeddings for fine-grained analysis and high-level semantic\nembeddings for broader task understanding. Notably, TSPulse's semantic\nembeddings are robust to shifts in time, magnitude, and noise, which is\nimportant for robust retrieval. At the task level, TSPulse incorporates TSLens,\na fine-tuning component enabling task-specific feature attention. It also\nintroduces a multi-head triangulation technique that correlates deviations from\nmultiple prediction heads, enhancing anomaly detection by fusing complementary\nmodel outputs. Additionally, a hybrid mask pretraining is proposed to improves\nzero-shot imputation by reducing pre-training bias. These architecture and task\ninnovations collectively contribute to TSPulse's significant performance gains:\n5-16% on the UEA classification benchmarks, +20% on the TSB-AD anomaly\ndetection leaderboard, +50% in zero-shot imputation, and +25% in time-series\nretrieval. Remarkably, these results are achieved with just 1M parameters,\nmaking TSPulse 10-100X smaller than existing pre-trained models. Its efficiency\nenables GPU-free inference and rapid pre-training, setting a new standard for\nefficient time-series pre-trained models. Models will be open-sourced soon.", "published": "2025-05-19 12:18:53", "link": "http://arxiv.org/abs/2505.13033v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "MindOmni: Unleashing Reasoning Generation in Vision Language Models with RGPO", "abstract": "Recent text-to-image systems face limitations in handling multimodal inputs\nand complex reasoning tasks. We introduce MindOmni, a unified multimodal large\nlanguage model that addresses these challenges by incorporating reasoning\ngeneration through reinforcement learning. MindOmni leverages a three-phase\ntraining strategy: i) design of a unified vision language model with a\ndecoder-only diffusion module, ii) supervised fine-tuning with Chain-of-Thought\n(CoT) instruction data, and iii) our proposed Reasoning Generation Policy\nOptimization (RGPO) algorithm, utilizing multimodal feedback to effectively\nguide policy updates. Experimental results demonstrate that MindOmni\noutperforms existing models, achieving impressive performance on both\nunderstanding and generation benchmarks, meanwhile showcasing advanced\nfine-grained reasoning generation capabilities, especially with mathematical\nreasoning instruction. All codes will be made public at\n\\href{https://github.com/EasonXiao-888/MindOmni}{https://github.com/EasonXiao-888/MindOmni}.", "published": "2025-05-19 12:17:04", "link": "http://arxiv.org/abs/2505.13031v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Step-wise Adaptive Integration of Supervised Fine-tuning and Reinforcement Learning for Task-Specific LLMs", "abstract": "Large language models (LLMs) excel at mathematical reasoning and logical\nproblem-solving. The current popular training paradigms primarily use\nsupervised fine-tuning (SFT) and reinforcement learning (RL) to enhance the\nmodels' reasoning abilities. However, when using SFT or RL alone, there are\nrespective challenges: SFT may suffer from overfitting, while RL is prone to\nmode collapse. The state-of-the-art methods have proposed hybrid training\nschemes. However, static switching faces challenges such as poor generalization\nacross different tasks and high dependence on data quality. In response to\nthese challenges, inspired by the curriculum learning-quiz mechanism in human\nreasoning cultivation, We propose SASR, a step-wise adaptive hybrid training\nframework that theoretically unifies SFT and RL and dynamically balances the\ntwo throughout optimization. SASR uses SFT for initial warm-up to establish\nbasic reasoning skills, and then uses an adaptive dynamic adjustment algorithm\nbased on gradient norm and divergence relative to the original distribution to\nseamlessly integrate SFT with the online RL method GRPO. By monitoring the\ntraining status of LLMs and adjusting the training process in sequence, SASR\nensures a smooth transition between training schemes, maintaining core\nreasoning abilities while exploring different paths. Experimental results\ndemonstrate that SASR outperforms SFT, RL, and static hybrid training methods.", "published": "2025-05-19 12:10:17", "link": "http://arxiv.org/abs/2505.13026v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "LiBOG: Lifelong Learning for Black-Box Optimizer Generation", "abstract": "Meta-Black-Box Optimization (MetaBBO) garners attention due to its success in\nautomating the configuration and generation of black-box optimizers,\nsignificantly reducing the human effort required for optimizer design and\ndiscovering optimizers with higher performance than classic human-designed\noptimizers. However, existing MetaBBO methods conduct one-off training under\nthe assumption that a stationary problem distribution with extensive and\nrepresentative training problem samples is pre-available. This assumption is\noften impractical in real-world scenarios, where diverse problems following\nshifting distribution continually arise. Consequently, there is a pressing need\nfor methods that can continuously learn from new problems encountered\non-the-fly and progressively enhance their capabilities. In this work, we\nexplore a novel paradigm of lifelong learning in MetaBBO and introduce LiBOG, a\nnovel approach designed to learn from sequentially encountered problems and\ngenerate high-performance optimizers for Black-Box Optimization (BBO). LiBOG\nconsolidates knowledge both across tasks and within tasks to mitigate\ncatastrophic forgetting. Extensive experiments demonstrate LiBOG's\neffectiveness in learning to generate high-performance optimizers in a lifelong\nlearning manner, addressing catastrophic forgetting while maintaining\nplasticity to learn new tasks.", "published": "2025-05-19 12:09:25", "link": "http://arxiv.org/abs/2505.13025v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Anti-Inpainting: A Proactive Defense against Malicious Diffusion-based Inpainters under Unknown Conditions", "abstract": "As diffusion-based malicious image manipulation becomes increasingly\nprevalent, multiple proactive defense methods are developed to safeguard images\nagainst unauthorized tampering. However, most proactive defense methods only\ncan safeguard images against manipulation under known conditions, and fail to\nprotect images from manipulations guided by tampering conditions crafted by\nmalicious users. To tackle this issue, we propose Anti-Inpainting, a proactive\ndefense method that achieves adequate protection under unknown conditions\nthrough a triple mechanism to address this challenge. Specifically, a\nmulti-level deep feature extractor is presented to obtain intricate features\nduring the diffusion denoising process to improve protective effectiveness. We\ndesign multi-scale semantic-preserving data augmentation to enhance the\ntransferability of adversarial perturbations across unknown conditions by\nmulti-scale transformations while preserving semantic integrity. In addition,\nwe propose a selection-based distribution deviation optimization strategy to\nimprove the protection of adversarial perturbation against manipulation under\ndiverse random seeds. Extensive experiments indicate the proactive defensive\nperformance of Anti-Inpainting against diffusion-based inpainters guided by\nunknown conditions in InpaintGuardBench and CelebA-HQ. At the same time, we\nalso demonstrate the proposed approach's robustness under various image\npurification methods and its transferability across different versions of\ndiffusion models.", "published": "2025-05-19 12:07:29", "link": "http://arxiv.org/abs/2505.13023v1", "categories": ["cs.CV", "cs.AI", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Unveiling and Steering Connectome Organization with Interpretable Latent Variables", "abstract": "The brain's intricate connectome, a blueprint for its function, presents\nimmense complexity, yet it arises from a compact genetic code, hinting at\nunderlying low-dimensional organizational principles. This work bridges\nconnectomics and representation learning to uncover these principles. We\npropose a framework that combines subgraph extraction from the Drosophila\nconnectome, FlyWire, with a generative model to derive interpretable\nlow-dimensional representations of neural circuitry. Crucially, an\nexplainability module links these latent dimensions to specific structural\nfeatures, offering insights into their functional relevance. We validate our\napproach by demonstrating effective graph reconstruction and, significantly,\nthe ability to manipulate these latent codes to controllably generate\nconnectome subgraphs with predefined properties. This research offers a novel\ntool for understanding brain architecture and a potential avenue for designing\nbio-inspired artificial neural networks.", "published": "2025-05-19 11:54:40", "link": "http://arxiv.org/abs/2505.13011v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "From Assistants to Adversaries: Exploring the Security Risks of Mobile LLM Agents", "abstract": "The growing adoption of large language models (LLMs) has led to a new\nparadigm in mobile computing--LLM-powered mobile AI agents--capable of\ndecomposing and automating complex tasks directly on smartphones. However, the\nsecurity implications of these agents remain largely unexplored. In this paper,\nwe present the first comprehensive security analysis of mobile LLM agents,\nencompassing three representative categories: System-level AI Agents developed\nby original equipment manufacturers (e.g., YOYO Assistant), Third-party\nUniversal Agents (e.g., Zhipu AI AutoGLM), and Emerging Agent Frameworks (e.g.,\nAlibaba Mobile Agent). We begin by analyzing the general workflow of mobile\nagents and identifying security threats across three core capability\ndimensions: language-based reasoning, GUI-based interaction, and system-level\nexecution. Our analysis reveals 11 distinct attack surfaces, all rooted in the\nunique capabilities and interaction patterns of mobile LLM agents, and spanning\ntheir entire operational lifecycle. To investigate these threats in practice,\nwe introduce AgentScan, a semi-automated security analysis framework that\nsystematically evaluates mobile LLM agents across all 11 attack scenarios.\nApplying AgentScan to nine widely deployed agents, we uncover a concerning\ntrend: every agent is vulnerable to targeted attacks. In the most severe cases,\nagents exhibit vulnerabilities across eight distinct attack vectors. These\nattacks can cause behavioral deviations, privacy leakage, or even full\nexecution hijacking. Based on these findings, we propose a set of defensive\ndesign principles and practical recommendations for building secure mobile LLM\nagents. Our disclosures have received positive feedback from two major device\nvendors. Overall, this work highlights the urgent need for standardized\nsecurity practices in the fast-evolving landscape of LLM-driven mobile\nautomation.", "published": "2025-05-19 11:17:46", "link": "http://arxiv.org/abs/2505.12981v1", "categories": ["cs.CR", "cs.AI", "cs.HC"], "primary_category": "cs.CR"}
{"title": "Multiscale Adaptive Conflict-Balancing Model For Multimedia Deepfake Detection", "abstract": "Advances in computer vision and deep learning have blurred the line between\ndeepfakes and authentic media, undermining multimedia credibility through\naudio-visual forgery. Current multimodal detection methods remain limited by\nunbalanced learning between modalities. To tackle this issue, we propose an\nAudio-Visual Joint Learning Method (MACB-DF) to better mitigate modality\nconflicts and neglect by leveraging contrastive learning to assist in\nmulti-level and cross-modal fusion, thereby fully balancing and exploiting\ninformation from each modality. Additionally, we designed an\northogonalization-multimodal pareto module that preserves unimodal information\nwhile addressing gradient conflicts in audio-video encoders caused by differing\noptimization targets of the loss functions. Extensive experiments and ablation\nstudies conducted on mainstream deepfake datasets demonstrate consistent\nperformance gains of our model across key evaluation metrics, achieving an\naverage accuracy of 95.5% across multiple datasets. Notably, our method\nexhibits superior cross-dataset generalization capabilities, with absolute\nimprovements of 8.0% and 7.7% in ACC scores over the previous best-performing\napproach when trained on DFDC and tested on DefakeAVMiT and FakeAVCeleb\ndatasets.", "published": "2025-05-19 11:01:49", "link": "http://arxiv.org/abs/2505.12966v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Segmentation of temporomandibular joint structures on mri images using neural networks for diagnosis of pathologies", "abstract": "This article explores the use of artificial intelligence for the diagnosis of\npathologies of the temporomandibular joint (TMJ), in particular, for the\nsegmentation of the articular disc on MRI images. The relevance of the work is\ndue to the high prevalence of TMJ pathologies, as well as the need to improve\nthe accuracy and speed of diagnosis in medical institutions. During the study,\nthe existing solutions (Diagnocat, MandSeg) were analyzed, which, as a result,\nare not suitable for studying the articular disc due to the orientation towards\nbone structures. To solve the problem, an original dataset was collected from\n94 images with the classes \"temporomandibular joint\" and \"jaw\". To increase the\namount of data, augmentation methods were used. After that, the models of\nU-Net, YOLOv8n, YOLOv11n and Roboflow neural networks were trained and\ncompared. The evaluation was carried out according to the Dice Score,\nPrecision, Sensitivity, Specificity, and Mean Average Precision metrics. The\nresults confirm the potential of using the Roboflow model for segmentation of\nthe temporomandibular joint. In the future, it is planned to develop an\nalgorithm for measuring the distance between the jaws and determining the\nposition of the articular disc, which will improve the diagnosis of TMJ\npathologies.", "published": "2025-05-19 10:58:02", "link": "http://arxiv.org/abs/2505.12963v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Hardware-Adaptive and Superlinear-Capacity Memristor-based Associative Memory", "abstract": "Brain-inspired computing aims to mimic cognitive functions like associative\nmemory, the ability to recall complete patterns from partial cues. Memristor\ntechnology offers promising hardware for such neuromorphic systems due to its\npotential for efficient in-memory analog computing. Hopfield Neural Networks\n(HNNs) are a classic model for associative memory, but implementations on\nconventional hardware suffer from efficiency bottlenecks, while prior\nmemristor-based HNNs faced challenges with vulnerability to hardware defects\ndue to offline training, limited storage capacity, and difficulty processing\nanalog patterns. Here we introduce and experimentally demonstrate on integrated\nmemristor hardware a new hardware-adaptive learning algorithm for associative\nmemories that significantly improves defect tolerance and capacity, and\nnaturally extends to scalable multilayer architectures capable of handling both\nbinary and continuous patterns. Our approach achieves 3x effective capacity\nunder 50% device faults compared to state-of-the-art methods. Furthermore, its\nextension to multilayer architectures enables superlinear capacity scaling\n(\\(\\propto N^{1.49}\\ for binary patterns) and effective recalling of continuous\npatterns (\\propto N^{1.74}\\ scaling), as compared to linear capacity scaling\nfor previous HNNs. It also provides flexibility to adjust capacity by tuning\nhidden neurons for the same-sized patterns. By leveraging the massive\nparallelism of the hardware enabled by synchronous updates, it reduces energy\nby 8.8x and latency by 99.7% for 64-dimensional patterns over asynchronous\nschemes, with greater improvements at scale. This promises the development of\nmore reliable memristor-based associative memory systems and enables new\napplications research due to the significantly improved capacity, efficiency,\nand flexibility.", "published": "2025-05-19 10:55:09", "link": "http://arxiv.org/abs/2505.12960v1", "categories": ["cs.LG", "cs.AI", "cs.ET"], "primary_category": "cs.LG"}
{"title": "DGRO: Enhancing LLM Reasoning via Exploration-Exploitation Control and Reward Variance Management", "abstract": "Inference scaling further accelerates Large Language Models (LLMs) toward\nArtificial General Intelligence (AGI), with large-scale Reinforcement Learning\n(RL) to unleash long Chain-of-Thought reasoning. Most contemporary reasoning\napproaches usually rely on handcrafted rule-based reward functions. However,\nthe tarde-offs of exploration and exploitation in RL algorithms involves\nmultiple complex considerations, and the theoretical and empirical impacts of\nmanually designed reward functions remain insufficiently explored. In this\npaper, we propose Decoupled Group Reward Optimization (DGRO), a general RL\nalgorithm for LLM reasoning. On the one hand, DGRO decouples the traditional\nregularization coefficient into two independent hyperparameters: one scales the\npolicy gradient term, and the other regulates the distance from the sampling\npolicy. This decoupling not only enables precise control over balancing\nexploration and exploitation, but also can be seamlessly extended to Online\nPolicy Mirror Descent (OPMD) algorithms in Kimi k1.5 and Direct Reward\nOptimization. On the other hand, we observe that reward variance significantly\naffects both convergence speed and final model performance. We conduct both\ntheoretical analysis and extensive empirical validation to assess DGRO,\nincluding a detailed ablation study that investigates its performance and\noptimization dynamics. Experimental results show that DGRO achieves\nstate-of-the-art performance on the Logic dataset with an average accuracy of\n96.9\\%, and demonstrates strong generalization across mathematical benchmarks.", "published": "2025-05-19 10:44:49", "link": "http://arxiv.org/abs/2505.12951v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "CALM-PDE: Continuous and Adaptive Convolutions for Latent Space Modeling of Time-dependent PDEs", "abstract": "Solving time-dependent Partial Differential Equations (PDEs) using a densely\ndiscretized spatial domain is a fundamental problem in various scientific and\nengineering disciplines, including modeling climate phenomena and fluid\ndynamics. However, performing these computations directly in the physical space\noften incurs significant computational costs. To address this issue, several\nneural surrogate models have been developed that operate in a compressed latent\nspace to solve the PDE. While these approaches reduce computational complexity,\nthey often use Transformer-based attention mechanisms to handle irregularly\nsampled domains, resulting in increased memory consumption. In contrast,\nconvolutional neural networks allow memory-efficient encoding and decoding but\nare limited to regular discretizations. Motivated by these considerations, we\npropose CALM-PDE, a model class that efficiently solves arbitrarily discretized\nPDEs in a compressed latent space. We introduce a novel continuous\nconvolution-based encoder-decoder architecture that uses an\nepsilon-neighborhood-constrained kernel and learns to apply the convolution\noperator to adaptive and optimized query points. We demonstrate the\neffectiveness of CALM-PDE on a diverse set of PDEs with both regularly and\nirregularly sampled spatial domains. CALM-PDE is competitive with or\noutperforms existing baseline methods while offering significant improvements\nin memory and inference time efficiency compared to Transformer-based methods.", "published": "2025-05-19 10:31:30", "link": "http://arxiv.org/abs/2505.12944v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.NE", "physics.comp-ph"], "primary_category": "cs.LG"}
{"title": "Mean Flows for One-step Generative Modeling", "abstract": "We propose a principled and effective framework for one-step generative\nmodeling. We introduce the notion of average velocity to characterize flow\nfields, in contrast to instantaneous velocity modeled by Flow Matching methods.\nA well-defined identity between average and instantaneous velocities is derived\nand used to guide neural network training. Our method, termed the MeanFlow\nmodel, is self-contained and requires no pre-training, distillation, or\ncurriculum learning. MeanFlow demonstrates strong empirical performance: it\nachieves an FID of 3.43 with a single function evaluation (1-NFE) on ImageNet\n256x256 trained from scratch, significantly outperforming previous\nstate-of-the-art one-step diffusion/flow models. Our study substantially\nnarrows the gap between one-step diffusion/flow models and their multi-step\npredecessors, and we hope it will motivate future research to revisit the\nfoundations of these powerful models.", "published": "2025-05-19 17:59:42", "link": "http://arxiv.org/abs/2505.13447v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Recollection from Pensieve: Novel View Synthesis via Learning from Uncalibrated Videos", "abstract": "Currently almost all state-of-the-art novel view synthesis and reconstruction\nmodels rely on calibrated cameras or additional geometric priors for training.\nThese prerequisites significantly limit their applicability to massive\nuncalibrated data. To alleviate this requirement and unlock the potential for\nself-supervised training on large-scale uncalibrated videos, we propose a novel\ntwo-stage strategy to train a view synthesis model from only raw video frames\nor multi-view images, without providing camera parameters or other priors. In\nthe first stage, we learn to reconstruct the scene implicitly in a latent space\nwithout relying on any explicit 3D representation. Specifically, we predict\nper-frame latent camera and scene context features, and employ a view synthesis\nmodel as a proxy for explicit rendering. This pretraining stage substantially\nreduces the optimization complexity and encourages the network to learn the\nunderlying 3D consistency in a self-supervised manner. The learned latent\ncamera and implicit scene representation have a large gap compared with the\nreal 3D world. To reduce this gap, we introduce the second stage training by\nexplicitly predicting 3D Gaussian primitives. We additionally apply explicit\nGaussian Splatting rendering loss and depth projection loss to align the\nlearned latent representations with physically grounded 3D geometry. In this\nway, Stage 1 provides a strong initialization and Stage 2 enforces 3D\nconsistency - the two stages are complementary and mutually beneficial.\nExtensive experiments demonstrate the effectiveness of our approach, achieving\nhigh-quality novel view synthesis and accurate camera pose estimation, compared\nto methods that employ supervision with calibration, pose, or depth\ninformation. The code is available at https://github.com/Dwawayu/Pensieve.", "published": "2025-05-19 17:59:05", "link": "http://arxiv.org/abs/2505.13440v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "KinTwin: Imitation Learning with Torque and Muscle Driven Biomechanical Models Enables Precise Replication of Able-Bodied and Impaired Movement from Markerless Motion Capture", "abstract": "Broader access to high-quality movement analysis could greatly benefit\nmovement science and rehabilitation, such as allowing more detailed\ncharacterization of movement impairments and responses to interventions, or\neven enabling early detection of new neurological conditions or fall risk.\nWhile emerging technologies are making it easier to capture kinematics with\nbiomechanical models, or how joint angles change over time, inferring the\nunderlying physics that give rise to these movements, including ground reaction\nforces, joint torques, or even muscle activations, is still challenging. Here\nwe explore whether imitation learning applied to a biomechanical model from a\nlarge dataset of movements from able-bodied and impaired individuals can learn\nto compute these inverse dynamics. Although imitation learning in human pose\nestimation has seen great interest in recent years, our work differences in\nseveral ways: we focus on using an accurate biomechanical model instead of\nmodels adopted for computer vision, we test it on a dataset that contains\nparticipants with impaired movements, we reported detailed tracking metrics\nrelevant for the clinical measurement of movement including joint angles and\nground contact events, and finally we apply imitation learning to a\nmuscle-driven neuromusculoskeletal model. We show that our imitation learning\npolicy, KinTwin, can accurately replicate the kinematics of a wide range of\nmovements, including those with assistive devices or therapist assistance, and\nthat it can infer clinically meaningful differences in joint torques and muscle\nactivations. Our work demonstrates the potential for using imitation learning\nto enable high-quality movement analysis in clinical practice.", "published": "2025-05-19 17:58:03", "link": "http://arxiv.org/abs/2505.13436v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Understanding Complexity in VideoQA via Visual Program Generation", "abstract": "We propose a data-driven approach to analyzing query complexity in Video\nQuestion Answering (VideoQA). Previous efforts in benchmark design have relied\non human expertise to design challenging questions, yet we experimentally show\nthat humans struggle to predict which questions are difficult for machine\nlearning models. Our automatic approach leverages recent advances in code\ngeneration for visual question answering, using the complexity of generated\ncode as a proxy for question difficulty. We demonstrate that this measure\ncorrelates significantly better with model performance than human estimates. To\noperationalize this insight, we propose an algorithm for estimating question\ncomplexity from code. It identifies fine-grained primitives that correlate with\nthe hardest questions for any given set of models, making it easy to scale to\nnew approaches in the future. Finally, to further illustrate the utility of our\nmethod, we extend it to automatically generate complex questions, constructing\na new benchmark that is 1.9 times harder than the popular NExT-QA.", "published": "2025-05-19 17:55:14", "link": "http://arxiv.org/abs/2505.13429v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "G1: Bootstrapping Perception and Reasoning Abilities of Vision-Language Model via Reinforcement Learning", "abstract": "Vision-Language Models (VLMs) excel in many direct multimodal tasks but\nstruggle to translate this prowess into effective decision-making within\ninteractive, visually rich environments like games. This ``knowing-doing'' gap\nsignificantly limits their potential as autonomous agents, as leading VLMs\noften performing badly in simple games. To address this, we introduce VLM-Gym,\na curated reinforcement learning (RL) environment featuring diverse visual\ngames with unified interfaces and adjustable, compositional difficulty,\nspecifically designed for scalable multi-game parallel training. Leveraging\nVLM-Gym, we train G0 models using pure RL-driven self-evolution, which\ndemonstrate emergent perception and reasoning patterns. To further mitigate\nchallenges arising from game diversity, we develop G1 models. G1 incorporates a\nperception-enhanced cold start prior to RL fine-tuning. Our resulting G1 models\nconsistently surpass their teacher across all games and outperform leading\nproprietary models like Claude-3.7-Sonnet-Thinking. Systematic analysis reveals\nan intriguing finding: perception and reasoning abilities mutually bootstrap\neach other throughout the RL training process. Source code including VLM-Gym\nand RL training are released at https://github.com/chenllliang/G1 to foster\nfuture research in advancing VLMs as capable interactive agents.", "published": "2025-05-19 17:54:39", "link": "http://arxiv.org/abs/2505.13426v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FEALLM: Advancing Facial Emotion Analysis in Multimodal Large Language Models with Emotional Synergy and Reasoning", "abstract": "Facial Emotion Analysis (FEA) plays a crucial role in visual affective\ncomputing, aiming to infer a person's emotional state based on facial data.\nScientifically, facial expressions (FEs) result from the coordinated movement\nof facial muscles, which can be decomposed into specific action units (AUs)\nthat provide detailed emotional insights. However, traditional methods often\nstruggle with limited interpretability, constrained generalization and\nreasoning abilities. Recently, Multimodal Large Language Models (MLLMs) have\nshown exceptional performance in various visual tasks, while they still face\nsignificant challenges in FEA due to the lack of specialized datasets and their\ninability to capture the intricate relationships between FEs and AUs. To\naddress these issues, we introduce a novel FEA Instruction Dataset that\nprovides accurate and aligned FE and AU descriptions and establishes causal\nreasoning relationships between them, followed by constructing a new benchmark,\nFEABench. Moreover, we propose FEALLM, a novel MLLM architecture designed to\ncapture more detailed facial information, enhancing its capability in FEA\ntasks. Our model demonstrates strong performance on FEABench and impressive\ngeneralization capability through zero-shot evaluation on various datasets,\nincluding RAF-DB, AffectNet, BP4D, and DISFA, showcasing its robustness and\neffectiveness in FEA tasks. The dataset and code will be available at\nhttps://github.com/953206211/FEALLM.", "published": "2025-05-19 17:52:15", "link": "http://arxiv.org/abs/2505.13419v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GuidedMorph: Two-Stage Deformable Registration for Breast MRI", "abstract": "Accurately registering breast MR images from different time points enables\nthe alignment of anatomical structures and tracking of tumor progression,\nsupporting more effective breast cancer detection, diagnosis, and treatment\nplanning. However, the complexity of dense tissue and its highly non-rigid\nnature pose challenges for conventional registration methods, which primarily\nfocus on aligning general structures while overlooking intricate internal\ndetails. To address this, we propose \\textbf{GuidedMorph}, a novel two-stage\nregistration framework designed to better align dense tissue. In addition to a\nsingle-scale network for global structure alignment, we introduce a framework\nthat utilizes dense tissue information to track breast movement. The learned\ntransformation fields are fused by introducing the Dual Spatial Transformer\nNetwork (DSTN), improving overall alignment accuracy. A novel warping method\nbased on the Euclidean distance transform (EDT) is also proposed to accurately\nwarp the registered dense tissue and breast masks, preserving fine structural\ndetails during deformation. The framework supports paradigms that require\nexternal segmentation models and with image data only. It also operates\neffectively with the VoxelMorph and TransMorph backbones, offering a versatile\nsolution for breast registration. We validate our method on ISPY2 and internal\ndataset, demonstrating superior performance in dense tissue, overall breast\nalignment, and breast structural similarity index measure (SSIM), with notable\nimprovements by over 13.01% in dense tissue Dice, 3.13% in breast Dice, and\n1.21% in breast SSIM compared to the best learning-based baseline.", "published": "2025-05-19 17:48:06", "link": "http://arxiv.org/abs/2505.13414v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Faster Video Diffusion with Trainable Sparse Attention", "abstract": "Scaling video diffusion transformers (DiTs) is limited by their quadratic 3D\nattention, even though most of the attention mass concentrates on a small\nsubset of positions. We turn this observation into VSA, a trainable,\nhardware-efficient sparse attention that replaces full attention at \\emph{both}\ntraining and inference. In VSA, a lightweight coarse stage pools tokens into\ntiles and identifies high-weight \\emph{critical tokens}; a fine stage computes\ntoken-level attention only inside those tiles subjecting to block computing\nlayout to ensure hard efficiency. This leads to a single differentiable kernel\nthat trains end-to-end, requires no post-hoc profiling, and sustains 85\\% of\nFlashAttention3 MFU. We perform a large sweep of ablation studies and\nscaling-law experiments by pretraining DiTs from 60M to 1.4B parameters. VSA\nreaches a Pareto point that cuts training FLOPS by 2.53$\\times$ with no drop in\ndiffusion loss. Retrofitting the open-source Wan-2.1 model speeds up attention\ntime by 6$\\times$ and lowers end-to-end generation time from 31s to 18s with\ncomparable quality. These results establish trainable sparse attention as a\npractical alternative to full attention and a key enabler for further scaling\nof video diffusion models.", "published": "2025-05-19 17:30:13", "link": "http://arxiv.org/abs/2505.13389v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Benchmarking Unified Face Attack Detection via Hierarchical Prompt Tuning", "abstract": "Presentation Attack Detection and Face Forgery Detection are designed to\nprotect face data from physical media-based Presentation Attacks and digital\nediting-based DeepFakes respectively. But separate training of these two models\nmakes them vulnerable to unknown attacks and burdens deployment environments.\nThe lack of a Unified Face Attack Detection model to handle both types of\nattacks is mainly due to two factors. First, there's a lack of adequate\nbenchmarks for models to explore. Existing UAD datasets have limited attack\ntypes and samples, restricting the model's ability to address advanced threats.\nTo address this, we propose UniAttackDataPlus (UniAttackData+), the most\nextensive and sophisticated collection of forgery techniques to date. It\nincludes 2,875 identities and their 54 kinds of falsified samples, totaling\n697,347 videos. Second, there's a lack of a reliable classification criterion.\nCurrent methods try to find an arbitrary criterion within the same semantic\nspace, which fails when encountering diverse attacks. So, we present a novel\nVisual-Language Model-based Hierarchical Prompt Tuning Framework (HiPTune) that\nadaptively explores multiple classification criteria from different semantic\nspaces. We build a Visual Prompt Tree to explore various classification rules\nhierarchically. Then, by adaptively pruning the prompts, the model can select\nthe most suitable prompts to guide the encoder to extract discriminative\nfeatures at different levels in a coarse-to-fine way. Finally, to help the\nmodel understand the classification criteria in visual space, we propose a\nDynamically Prompt Integration module to project the visual prompts to the text\nencoder for more accurate semantics. Experiments on 12 datasets have shown the\npotential to inspire further innovations in the UAD field.", "published": "2025-05-19 16:35:45", "link": "http://arxiv.org/abs/2505.13327v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VesselGPT: Autoregressive Modeling of Vascular Geometry", "abstract": "Anatomical trees are critical for clinical diagnosis and treatment planning,\nyet their complex and diverse geometry make accurate representation a\nsignificant challenge. Motivated by the latest advances in large language\nmodels, we introduce an autoregressive method for synthesizing anatomical\ntrees. Our approach first embeds vessel structures into a learned discrete\nvocabulary using a VQ-VAE architecture, then models their generation\nautoregressively with a GPT-2 model. This method effectively captures intricate\ngeometries and branching patterns, enabling realistic vascular tree synthesis.\nComprehensive qualitative and quantitative evaluations reveal that our\ntechnique achieves high-fidelity tree reconstruction with compact discrete\nrepresentations. Moreover, our B-spline representation of vessel cross-sections\npreserves critical morphological details that are often overlooked in previous'\nmethods parameterizations. To the best of our knowledge, this work is the first\nto generate blood vessels in an autoregressive manner. Code, data, and trained\nmodels will be made available.", "published": "2025-05-19 16:30:26", "link": "http://arxiv.org/abs/2505.13318v1", "categories": ["cs.CV", "cs.LG", "eess.IV"], "primary_category": "cs.CV"}
{"title": "eStonefish-scenes: A synthetically generated dataset for underwater event-based optical flow prediction tasks", "abstract": "The combined use of event-based vision and Spiking Neural Networks (SNNs) is\nexpected to significantly impact robotics, particularly in tasks like visual\nodometry and obstacle avoidance. While existing real-world event-based datasets\nfor optical flow prediction, typically captured with Unmanned Aerial Vehicles\n(UAVs), offer valuable insights, they are limited in diversity, scalability,\nand are challenging to collect. Moreover, there is a notable lack of labelled\ndatasets for underwater applications, which hinders the integration of\nevent-based vision with Autonomous Underwater Vehicles (AUVs). To address this,\nsynthetic datasets could provide a scalable solution while bridging the gap\nbetween simulation and reality. In this work, we introduce eStonefish-scenes, a\nsynthetic event-based optical flow dataset based on the Stonefish simulator.\nAlong with the dataset, we present a data generation pipeline that enables the\ncreation of customizable underwater environments. This pipeline allows for\nsimulating dynamic scenarios, such as biologically inspired schools of fish\nexhibiting realistic motion patterns, including obstacle avoidance and reactive\nnavigation around corals. Additionally, we introduce a scene generator that can\nbuild realistic reef seabeds by randomly distributing coral across the terrain.\nTo streamline data accessibility, we present eWiz, a comprehensive library\ndesigned for processing event-based data, offering tools for data loading,\naugmentation, visualization, encoding, and training data generation, along with\nloss functions and performance metrics.", "published": "2025-05-19 16:26:18", "link": "http://arxiv.org/abs/2505.13309v1", "categories": ["cs.CV", "I.2.5; I.2.6; I.2.9; I.2.10"], "primary_category": "cs.CV"}
{"title": "GMM-Based Comprehensive Feature Extraction and Relative Distance Preservation For Few-Shot Cross-Modal Retrieval", "abstract": "Few-shot cross-modal retrieval focuses on learning cross-modal\nrepresentations with limited training samples, enabling the model to handle\nunseen classes during inference. Unlike traditional cross-modal retrieval\ntasks, which assume that both training and testing data share the same class\ndistribution, few-shot retrieval involves data with sparse representations\nacross modalities. Existing methods often fail to adequately model the\nmulti-peak distribution of few-shot cross-modal data, resulting in two main\nbiases in the latent semantic space: intra-modal bias, where sparse samples\nfail to capture intra-class diversity, and inter-modal bias, where\nmisalignments between image and text distributions exacerbate the semantic gap.\nThese biases hinder retrieval accuracy. To address these issues, we propose a\nnovel method, GCRDP, for few-shot cross-modal retrieval. This approach\neffectively captures the complex multi-peak distribution of data using a\nGaussian Mixture Model (GMM) and incorporates a multi-positive sample\ncontrastive learning mechanism for comprehensive feature modeling.\nAdditionally, we introduce a new strategy for cross-modal semantic alignment,\nwhich constrains the relative distances between image and text feature\ndistributions, thereby improving the accuracy of cross-modal representations.\nWe validate our approach through extensive experiments on four benchmark\ndatasets, demonstrating superior performance over six state-of-the-art methods.", "published": "2025-05-19 16:25:55", "link": "http://arxiv.org/abs/2505.13306v1", "categories": ["cs.CV", "cs.IR"], "primary_category": "cs.CV"}
{"title": "DD-Ranking: Rethinking the Evaluation of Dataset Distillation", "abstract": "In recent years, dataset distillation has provided a reliable solution for\ndata compression, where models trained on the resulting smaller synthetic\ndatasets achieve performance comparable to those trained on the original\ndatasets. To further improve the performance of synthetic datasets, various\ntraining pipelines and optimization objectives have been proposed, greatly\nadvancing the field of dataset distillation. Recent decoupled dataset\ndistillation methods introduce soft labels and stronger data augmentation\nduring the post-evaluation phase and scale dataset distillation up to larger\ndatasets (e.g., ImageNet-1K). However, this raises a question: Is accuracy\nstill a reliable metric to fairly evaluate dataset distillation methods? Our\nempirical findings suggest that the performance improvements of these methods\noften stem from additional techniques rather than the inherent quality of the\nimages themselves, with even randomly sampled images achieving superior\nresults. Such misaligned evaluation settings severely hinder the development of\nDD. Therefore, we propose DD-Ranking, a unified evaluation framework, along\nwith new general evaluation metrics to uncover the true performance\nimprovements achieved by different methods. By refocusing on the actual\ninformation enhancement of distilled datasets, DD-Ranking provides a more\ncomprehensive and fair evaluation standard for future research advancements.", "published": "2025-05-19 16:19:50", "link": "http://arxiv.org/abs/2505.13300v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RECON: Robust symmetry discovery via Explicit Canonical Orientation Normalization", "abstract": "Real-world data often exhibits unknown or approximate symmetries, yet\nexisting equivariant networks must commit to a fixed transformation group prior\nto training, e.g., continuous $SO(2)$ rotations. This mismatch degrades\nperformance when the actual data symmetries differ from those in the\ntransformation group. We introduce RECON, a framework to discover each input's\nintrinsic symmetry distribution from unlabeled data. RECON leverages class-pose\ndecompositions and applies a data-driven normalization to align arbitrary\nreference frames into a common natural pose, yielding directly comparable and\ninterpretable symmetry descriptors. We demonstrate effective symmetry discovery\non 2D image benchmarks and -- for the first time -- extend it to 3D\ntransformation groups, paving the way towards more flexible equivariant\nmodeling.", "published": "2025-05-19 16:10:23", "link": "http://arxiv.org/abs/2505.13289v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Computer Vision Models Show Human-Like Sensitivity to Geometric and Topological Concepts", "abstract": "With the rapid improvement of machine learning (ML) models, cognitive\nscientists are increasingly asking about their alignment with how humans think.\nHere, we ask this question for computer vision models and human sensitivity to\ngeometric and topological (GT) concepts. Under the core knowledge account,\nthese concepts are innate and supported by dedicated neural circuitry. In this\nwork, we investigate an alternative explanation, that GT concepts are learned\n``for free'' through everyday interaction with the environment. We do so using\ncomputer visions models, which are trained on large image datasets. We build on\nprior studies to investigate the overall performance and human alignment of\nthree classes of models -- convolutional neural networks (CNNs),\ntransformer-based models, and vision-language models -- on an odd-one-out task\ntesting 43 GT concepts spanning seven classes. Transformer-based models achieve\nthe highest overall accuracy, surpassing that of young children. They also show\nstrong alignment with children's performance, finding the same classes of\nconcepts easy vs. difficult. By contrast, vision-language models underperform\ntheir vision-only counterparts and deviate further from human profiles,\nindicating that na\\\"ive multimodality might compromise abstract geometric\nsensitivity. These findings support the use of computer vision models to\nevaluate the sufficiency of the learning account for explaining human\nsensitivity to GT concepts, while also suggesting that integrating linguistic\nand visual representations might have unpredicted deleterious consequences.", "published": "2025-05-19 16:04:53", "link": "http://arxiv.org/abs/2505.13281v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Event-Driven Dynamic Scene Depth Completion", "abstract": "Depth completion in dynamic scenes poses significant challenges due to rapid\nego-motion and object motion, which can severely degrade the quality of input\nmodalities such as RGB images and LiDAR measurements. Conventional RGB-D\nsensors often struggle to align precisely and capture reliable depth under such\nconditions. In contrast, event cameras with their high temporal resolution and\nsensitivity to motion at the pixel level provide complementary cues that are\n%particularly beneficial in dynamic environments.To this end, we propose\nEventDC, the first event-driven depth completion framework. It consists of two\nkey components: Event-Modulated Alignment (EMA) and Local Depth Filtering\n(LDF). Both modules adaptively learn the two fundamental components of\nconvolution operations: offsets and weights conditioned on motion-sensitive\nevent streams. In the encoder, EMA leverages events to modulate the sampling\npositions of RGB-D features to achieve pixel redistribution for improved\nalignment and fusion. In the decoder, LDF refines depth estimations around\nmoving objects by learning motion-aware masks from events. Additionally,\nEventDC incorporates two loss terms to further benefit global alignment and\nenhance local depth recovery. Moreover, we establish the first benchmark for\nevent-based depth completion comprising one real-world and two synthetic\ndatasets to facilitate future research. Extensive experiments on this benchmark\ndemonstrate the superiority of our EventDC.", "published": "2025-05-19 16:02:37", "link": "http://arxiv.org/abs/2505.13279v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DB3D-L: Depth-aware BEV Feature Transformation for Accurate 3D Lane Detection", "abstract": "3D Lane detection plays an important role in autonomous driving. Recent\nadvances primarily build Birds-Eye-View (BEV) feature from front-view (FV)\nimages to perceive 3D information of Lane more effectively. However,\nconstructing accurate BEV information from FV image is limited due to the\nlacking of depth information, causing previous works often rely heavily on the\nassumption of a flat ground plane. Leveraging monocular depth estimation to\nassist in constructing BEV features is less constrained, but existing methods\nstruggle to effectively integrate the two tasks. To address the above issue, in\nthis paper, an accurate 3D lane detection method based on depth-aware BEV\nfeature transtormation is proposed. In detail, an effective feature extraction\nmodule is designed, in which a Depth Net is integrated to obtain the vital\ndepth information for 3D perception, thereby simplifying the complexity of view\ntransformation. Subquently a feature reduce module is proposed to reduce height\ndimension of FV features and depth features, thereby enables effective fusion\nof crucial FV features and depth features. Then a fusion module is designed to\nbuild BEV feature from prime FV feature and depth information. The proposed\nmethod performs comparably with state-of-the-art methods on both synthetic\nApollo, realistic OpenLane datasets.", "published": "2025-05-19 15:47:20", "link": "http://arxiv.org/abs/2505.13266v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Unlocking the Potential of Difficulty Prior in RL-based Multimodal Reasoning", "abstract": "In this work, we investigate how explicitly modeling problem's difficulty\nprior information shapes the effectiveness of reinforcement learning based\nfine-tuning for multimodal reasoning. Our exploration mainly comprises of\nfollowing three perspective: First, through offline data curation, we analyze\nthe U-shaped difficulty distribution of two given datasets using the base model\nby multi-round sampling, and then filter out prompts that are either too simple\nor extremely difficult to provide meaningful gradients and perform subsequent\ntwo-stage training. Second, we implement an online advantage differentiation,\ncomputing group-wise empirical accuracy as a difficulty proxy to adaptively\nreweight advantages estimation, providing stronger learning signals for more\nchallenging problems. Finally, we introduce difficulty hints as explicit\nprompts for more complex samples in the second training stage, encouraging the\nmodel to calibrate its reasoning depth and perform reflective validation\nchecks. Our comprehensive approach demonstrates significant performances across\nvarious multi-modal mathematical reasoning benchmarks with only 2K+0.6K\ntwo-stage training data.", "published": "2025-05-19 15:43:10", "link": "http://arxiv.org/abs/2505.13261v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Joint Depth and Reflectivity Estimation using Single-Photon LiDAR", "abstract": "Single-Photon Light Detection and Ranging (SP-LiDAR is emerging as a leading\ntechnology for long-range, high-precision 3D vision tasks. In SP-LiDAR,\ntimestamps encode two complementary pieces of information: pulse travel time\n(depth) and the number of photons reflected by the object (reflectivity).\nExisting SP-LiDAR reconstruction methods typically recover depth and\nreflectivity separately or sequentially use one modality to estimate the other.\nMoreover, the conventional 3D histogram construction is effective mainly for\nslow-moving or stationary scenes. In dynamic scenes, however, it is more\nefficient and effective to directly process the timestamps. In this paper, we\nintroduce an estimation method to simultaneously recover both depth and\nreflectivity in fast-moving scenes. We offer two contributions: (1) A\ntheoretical analysis demonstrating the mutual correlation between depth and\nreflectivity and the conditions under which joint estimation becomes\nbeneficial. (2) A novel reconstruction method, \"SPLiDER\", which exploits the\nshared information to enhance signal recovery. On both synthetic and real\nSP-LiDAR data, our method outperforms existing approaches, achieving superior\njoint reconstruction quality.", "published": "2025-05-19 15:33:28", "link": "http://arxiv.org/abs/2505.13250v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "WriteViT: Handwritten Text Generation with Vision Transformer", "abstract": "Humans can quickly generalize handwriting styles from a single example by\nintuitively separating content from style. Machines, however, struggle with\nthis task, especially in low-data settings, often missing subtle spatial and\nstylistic cues. Motivated by this gap, we introduce WriteViT, a one-shot\nhandwritten text synthesis framework that incorporates Vision Transformers\n(ViT), a family of models that have shown strong performance across various\ncomputer vision tasks. WriteViT integrates a ViT-based Writer Identifier for\nextracting style embeddings, a multi-scale generator built with Transformer\nencoder-decoder blocks enhanced by conditional positional encoding (CPE), and a\nlightweight ViT-based recognizer. While previous methods typically rely on CNNs\nor CRNNs, our design leverages transformers in key components to better capture\nboth fine-grained stroke details and higher-level style information. Although\nhandwritten text synthesis has been widely explored, its application to\nVietnamese -- a language rich in diacritics and complex typography -- remains\nlimited. Experiments on Vietnamese and English datasets demonstrate that\nWriteViT produces high-quality, style-consistent handwriting while maintaining\nstrong recognition performance in low-resource scenarios. These results\nhighlight the promise of transformer-based designs for multilingual handwriting\ngeneration and efficient style adaptation.", "published": "2025-05-19 15:17:53", "link": "http://arxiv.org/abs/2505.13235v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "From Local Details to Global Context: Advancing Vision-Language Models with Attention-Based Selection", "abstract": "Pretrained vision-language models (VLMs), e.g., CLIP, demonstrate impressive\nzero-shot capabilities on downstream tasks. Prior research highlights the\ncrucial role of visual augmentation techniques, like random cropping, in\nalignment with fine-grained class descriptions generated by large language\nmodels (LLMs), significantly enhancing zero-shot performance by incorporating\nmulti-view information. However, the inherent randomness of these augmentations\ncan inevitably introduce background artifacts and cause models to overly focus\non local details, compromising global semantic understanding. To address these\nissues, we propose an \\textbf{A}ttention-\\textbf{B}ased \\textbf{S}election\n(\\textbf{ABS}) method from local details to global context, which applies\nattention-guided cropping in both raw images and feature space, supplement\nglobal semantic information through strategic feature selection. Additionally,\nwe introduce a soft matching technique to effectively filter LLM descriptions\nfor better alignment. \\textbf{ABS} achieves state-of-the-art performance on\nout-of-distribution generalization and zero-shot classification tasks. Notably,\n\\textbf{ABS} is training-free and even rivals few-shot and test-time adaptation\nmethods. Our code is available at\n\\href{https://github.com/BIT-DA/ABS}{\\textcolor{darkgreen}{https://github.com/BIT-DA/ABS}}.", "published": "2025-05-19 15:15:37", "link": "http://arxiv.org/abs/2505.13233v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Automatic Complementary Separation Pruning Toward Lightweight CNNs", "abstract": "In this paper, we present Automatic Complementary Separation Pruning (ACSP),\na novel and fully automated pruning method for convolutional neural networks.\nACSP integrates the strengths of both structured pruning and activation-based\npruning, enabling the efficient removal of entire components such as neurons\nand channels while leveraging activations to identify and retain the most\nrelevant components. Our approach is designed specifically for supervised\nlearning tasks, where we construct a graph space that encodes the separation\ncapabilities of each component with respect to all class pairs. By employing\ncomplementary selection principles and utilizing a clustering algorithm, ACSP\nensures that the selected components maintain diverse and complementary\nseparation capabilities, reducing redundancy and maintaining high network\nperformance. The method automatically determines the optimal subset of\ncomponents in each layer, utilizing a knee-finding algorithm to select the\nminimal subset that preserves performance without requiring user-defined\npruning volumes. Extensive experiments on multiple architectures, including\nVGG-16, ResNet-50, and MobileNet-V2, across datasets like CIFAR-10, CIFAR-100,\nand ImageNet-1K, demonstrate that ACSP achieves competitive accuracy compared\nto other methods while significantly reducing computational costs. This fully\nautomated approach not only enhances scalability but also makes ACSP especially\npractical for real-world deployment by eliminating the need for manually\ndefining the pruning volume.", "published": "2025-05-19 15:08:23", "link": "http://arxiv.org/abs/2505.13225v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Swin DiT: Diffusion Transformer using Pseudo Shifted Windows", "abstract": "Diffusion Transformers (DiTs) achieve remarkable performance within the\ndomain of image generation through the incorporation of the transformer\narchitecture. Conventionally, DiTs are constructed by stacking serial isotropic\nglobal information modeling transformers, which face significant computational\ncost when processing high-resolution images. We empirically analyze that latent\nspace image generation does not exhibit a strong dependence on global\ninformation as traditionally assumed. Most of the layers in the model\ndemonstrate redundancy in global computation. In addition, conventional\nattention mechanisms exhibit low-frequency inertia issues. To address these\nissues, we propose \\textbf{P}seudo \\textbf{S}hifted \\textbf{W}indow\n\\textbf{A}ttention (PSWA), which fundamentally mitigates global model\nredundancy. PSWA achieves intermediate global-local information interaction\nthrough window attention, while employing a high-frequency bridging branch to\nsimulate shifted window operations, supplementing appropriate global and\nhigh-frequency information. Furthermore, we propose the Progressive Coverage\nChannel Allocation(PCCA) strategy that captures high-order attention similarity\nwithout additional computational cost. Building upon all of them, we propose a\nseries of Pseudo \\textbf{S}hifted \\textbf{Win}dow DiTs (\\textbf{Swin DiT}),\naccompanied by extensive experiments demonstrating their superior performance.\nFor example, our proposed Swin-DiT-L achieves a 54%$\\uparrow$ FID improvement\nover DiT-XL/2 while requiring less computational.\nhttps://github.com/wujiafu007/Swin-DiT", "published": "2025-05-19 15:02:33", "link": "http://arxiv.org/abs/2505.13219v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hybrid 3D-4D Gaussian Splatting for Fast Dynamic Scene Representation", "abstract": "Recent advancements in dynamic 3D scene reconstruction have shown promising\nresults, enabling high-fidelity 3D novel view synthesis with improved temporal\nconsistency. Among these, 4D Gaussian Splatting (4DGS) has emerged as an\nappealing approach due to its ability to model high-fidelity spatial and\ntemporal variations. However, existing methods suffer from substantial\ncomputational and memory overhead due to the redundant allocation of 4D\nGaussians to static regions, which can also degrade image quality. In this\nwork, we introduce hybrid 3D-4D Gaussian Splatting (3D-4DGS), a novel framework\nthat adaptively represents static regions with 3D Gaussians while reserving 4D\nGaussians for dynamic elements. Our method begins with a fully 4D Gaussian\nrepresentation and iteratively converts temporally invariant Gaussians into 3D,\nsignificantly reducing the number of parameters and improving computational\nefficiency. Meanwhile, dynamic Gaussians retain their full 4D representation,\ncapturing complex motions with high fidelity. Our approach achieves\nsignificantly faster training times compared to baseline 4D Gaussian Splatting\nmethods while maintaining or improving the visual quality.", "published": "2025-05-19 14:59:58", "link": "http://arxiv.org/abs/2505.13215v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RB-SCD: A New Benchmark for Semantic Change Detection of Roads and Bridges in Traffic Scenes", "abstract": "Accurate detection of changes in roads and bridges, such as construction,\nrenovation, and demolition, is essential for urban planning and traffic\nmanagement. However, existing methods often struggle to extract fine-grained\nsemantic change information due to the lack of high-quality annotated datasets\nin traffic scenarios. To address this, we introduce the Road and Bridge\nSemantic Change Detection (RB-SCD) dataset, a comprehensive benchmark\ncomprising 260 pairs of high-resolution remote sensing images from diverse\ncities and countries. RB-SCD captures 11 types of semantic changes across\nvaried road and bridge structures, enabling detailed structural and functional\nanalysis. Building on this dataset, we propose a novel framework, Multimodal\nFrequency-Driven Change Detector (MFDCD), which integrates multimodal features\nin the frequency domain. MFDCD includes a Dynamic Frequency Coupler (DFC) that\nfuses hierarchical visual features with wavelet-based frequency components, and\na Textual Frequency Filter (TFF) that transforms CLIP-derived textual features\ninto the frequency domain and applies graph-based filtering. Experimental\nresults on RB-SCD and three public benchmarks demonstrate the effectiveness of\nour approach.", "published": "2025-05-19 14:59:07", "link": "http://arxiv.org/abs/2505.13212v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FlowCut: Unsupervised Video Instance Segmentation via Temporal Mask Matching", "abstract": "We propose FlowCut, a simple and capable method for unsupervised video\ninstance segmentation consisting of a three-stage framework to construct a\nhigh-quality video dataset with pseudo labels. To our knowledge, our work is\nthe first attempt to curate a video dataset with pseudo-labels for unsupervised\nvideo instance segmentation. In the first stage, we generate pseudo-instance\nmasks by exploiting the affinities of features from both images and optical\nflows. In the second stage, we construct short video segments containing\nhigh-quality, consistent pseudo-instance masks by temporally matching them\nacross the frames. In the third stage, we use the YouTubeVIS-2021 video dataset\nto extract our training instance segmentation set, and then train a video\nsegmentation model. FlowCut achieves state-of-the-art performance on the\nYouTubeVIS-2019, YouTubeVIS-2021, DAVIS-2017, and DAVIS-2017 Motion benchmarks.", "published": "2025-05-19 14:30:33", "link": "http://arxiv.org/abs/2505.13174v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Higher fidelity perceptual image and video compression with a latent conditioned residual denoising diffusion model", "abstract": "Denoising diffusion models achieved impressive results on several image\ngeneration tasks often outperforming GAN based models. Recently, the generative\ncapabilities of diffusion models have been employed for perceptual image\ncompression, such as in CDC. A major drawback of these diffusion-based methods\nis that, while producing impressive perceptual quality images they are dropping\nin fidelity/increasing the distortion to the original uncompressed images when\ncompared with other traditional or learned image compression schemes aiming for\nfidelity. In this paper, we propose a hybrid compression scheme optimized for\nperceptual quality, extending the approach of the CDC model with a decoder\nnetwork in order to reduce the impact on distortion metrics such as PSNR. After\nusing the decoder network to generate an initial image, optimized for\ndistortion, the latent conditioned diffusion model refines the reconstruction\nfor perceptual quality by predicting the residual. On standard benchmarks, we\nachieve up to +2dB PSNR fidelity improvements while maintaining comparable\nLPIPS and FID perceptual scores when compared with CDC. Additionally, the\napproach is easily extensible to video compression, where we achieve similar\nresults.", "published": "2025-05-19 14:13:14", "link": "http://arxiv.org/abs/2505.13152v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "CacheFlow: Fast Human Motion Prediction by Cached Normalizing Flow", "abstract": "Many density estimation techniques for 3D human motion prediction require a\nsignificant amount of inference time, often exceeding the duration of the\npredicted time horizon. To address the need for faster density estimation for\n3D human motion prediction, we introduce a novel flow-based method for human\nmotion prediction called CacheFlow. Unlike previous conditional generative\nmodels that suffer from time efficiency, CacheFlow takes advantage of an\nunconditional flow-based generative model that transforms a Gaussian mixture\ninto the density of future motions. The results of the computation of the\nflow-based generative model can be precomputed and cached. Then, for\nconditional prediction, we seek a mapping from historical trajectories to\nsamples in the Gaussian mixture. This mapping can be done by a much more\nlightweight model, thus saving significant computation overhead compared to a\ntypical conditional flow model. In such a two-stage fashion and by caching\nresults from the slow flow model computation, we build our CacheFlow without\nloss of prediction accuracy and model expressiveness. This inference process is\ncompleted in approximately one millisecond, making it 4 times faster than\nprevious VAE methods and 30 times faster than previous diffusion-based methods\non standard benchmarks such as Human3.6M and AMASS datasets. Furthermore, our\nmethod demonstrates improved density estimation accuracy and comparable\nprediction accuracy to a SOTA method on Human3.6M. Our code and models will be\npublicly available.", "published": "2025-05-19 14:09:45", "link": "http://arxiv.org/abs/2505.13140v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning to Adapt to Position Bias in Vision Transformer Classifiers", "abstract": "How discriminative position information is for image classification depends\non the data. On the one hand, the camera position is arbitrary and objects can\nappear anywhere in the image, arguing for translation invariance. At the same\ntime, position information is key for exploiting capture/center bias, and scene\nlayout, e.g.: the sky is up. We show that position bias, the level to which a\ndataset is more easily solved when positional information on input features is\nused, plays a crucial role in the performance of Vision Transformers image\nclassifiers. To investigate, we propose Position-SHAP, a direct measure of\nposition bias by extending SHAP to work with position embeddings. We show\nvarious levels of position bias in different datasets, and find that the\noptimal choice of position embedding depends on the position bias apparent in\nthe dataset. We therefore propose Auto-PE, a single-parameter position\nembedding extension, which allows the position embedding to modulate its norm,\nenabling the unlearning of position information. Auto-PE combines with existing\nPEs to match or improve accuracy on classification datasets.", "published": "2025-05-19 14:07:36", "link": "http://arxiv.org/abs/2505.13137v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Industry-focused Synthetic Segmentation Pre-training", "abstract": "Pre-training on real-image datasets has been widely proven effective for\nimproving instance segmentation. However, industrial applications face two key\nchallenges: (1) legal and ethical restrictions, such as ImageNet's prohibition\nof commercial use, and (2) limited transferability due to the domain gap\nbetween web images and industrial imagery. Even recent vision foundation\nmodels, including the segment anything model (SAM), show notable performance\ndegradation in industrial settings. These challenges raise critical questions:\nCan we build a vision foundation model for industrial applications without\nrelying on real images or manual annotations? And can such models outperform\neven fine-tuned SAM on industrial datasets? To address these questions, we\npropose the Instance Core Segmentation Dataset (InsCore), a synthetic\npre-training dataset based on formula-driven supervised learning (FDSL).\nInsCore generates fully annotated instance segmentation images that reflect key\ncharacteristics of industrial data, including complex occlusions, dense\nhierarchical masks, and diverse non-rigid shapes, distinct from typical web\nimagery. Unlike previous methods, InsCore requires neither real images nor\nhuman annotations. Experiments on five industrial datasets show that models\npre-trained with InsCore outperform those trained on COCO and ImageNet-21k, as\nwell as fine-tuned SAM, achieving an average improvement of 6.2 points in\ninstance segmentation performance. This result is achieved using only 100k\nsynthetic images, more than 100 times fewer than the 11 million images in SAM's\nSA-1B dataset, demonstrating the data efficiency of our approach. These\nfindings position InsCore as a practical and license-free vision foundation\nmodel for industrial applications.", "published": "2025-05-19 13:29:40", "link": "http://arxiv.org/abs/2505.13099v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Touch2Shape: Touch-Conditioned 3D Diffusion for Shape Exploration and Reconstruction", "abstract": "Diffusion models have made breakthroughs in 3D generation tasks. Current 3D\ndiffusion models focus on reconstructing target shape from images or a set of\npartial observations. While excelling in global context understanding, they\nstruggle to capture the local details of complex shapes and limited to the\nocclusion and lighting conditions. To overcome these limitations, we utilize\ntactile images to capture the local 3D information and propose a Touch2Shape\nmodel, which leverages a touch-conditioned diffusion model to explore and\nreconstruct the target shape from touch. For shape reconstruction, we have\ndeveloped a touch embedding module to condition the diffusion model in creating\na compact representation and a touch shape fusion module to refine the\nreconstructed shape. For shape exploration, we combine the diffusion model with\nreinforcement learning to train a policy. This involves using the generated\nlatent vector from the diffusion model to guide the touch exploration policy\ntraining through a novel reward design. Experiments validate the reconstruction\nquality thorough both qualitatively and quantitative analysis, and our touch\nexploration policy further boosts reconstruction performance.", "published": "2025-05-19 13:24:21", "link": "http://arxiv.org/abs/2505.13091v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Cross-modal feature fusion for robust point cloud registration with ambiguous geometry", "abstract": "Point cloud registration has seen significant advancements with the\napplication of deep learning techniques. However, existing approaches often\noverlook the potential of integrating radiometric information from RGB images.\nThis limitation reduces their effectiveness in aligning point clouds pairs,\nespecially in regions where geometric data alone is insufficient. When used\neffectively, radiometric information can enhance the registration process by\nproviding context that is missing from purely geometric data. In this paper, we\npropose CoFF, a novel Cross-modal Feature Fusion method that utilizes both\npoint cloud geometry and RGB images for pairwise point cloud registration.\nAssuming that the co-registration between point clouds and RGB images is\navailable, CoFF explicitly addresses the challenges where geometric information\nalone is unclear, such as in regions with symmetric similarity or planar\nstructures, through a two-stage fusion of 3D point cloud features and 2D image\nfeatures. It incorporates a cross-modal feature fusion module that assigns\npixel-wise image features to 3D input point clouds to enhance learned 3D point\nfeatures, and integrates patch-wise image features with superpoint features to\nimprove the quality of coarse matching. This is followed by a coarse-to-fine\nmatching module that accurately establishes correspondences using the fused\nfeatures. We extensively evaluate CoFF on four common datasets: 3DMatch,\n3DLoMatch, IndoorLRS, and the recently released ScanNet++ datasets. In\naddition, we assess CoFF on specific subset datasets containing geometrically\nambiguous cases. Our experimental results demonstrate that CoFF achieves\nstate-of-the-art registration performance across all benchmarks, including\nremarkable registration recalls of 95.9% and 81.6% on the widely-used 3DMatch\nand 3DLoMatch datasets, respectively...(Truncated to fit arXiv abstract length)", "published": "2025-05-19 13:22:46", "link": "http://arxiv.org/abs/2505.13088v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Walking the Tightrope: Disentangling Beneficial and Detrimental Drifts in Non-Stationary Custom-Tuning", "abstract": "This paper uncovers a critical yet overlooked phenomenon in multi-modal large\nlanguage models (MLLMs): detrimental concept drift within chain-of-thought\n(CoT) reasoning during non-stationary reinforcement fine-tuning (RFT), where\nreasoning token distributions evolve unpredictably, thereby introducing\nsignificant biases in final predictions. To address this, we are pioneers in\nestablishing the theoretical bridge between concept drift theory and RFT\nprocesses by formalizing CoT's autoregressive token streams as non-stationary\ndistributions undergoing arbitrary temporal shifts. Leveraging this framework,\nwe propose a novel counterfact-aware RFT that systematically decouples\nbeneficial distribution adaptation from harmful concept drift through concept\ngraph-empowered LLM experts generating counterfactual reasoning trajectories.\nOur solution, Counterfactual Preference Optimization (CPO), enables stable RFT\nin non-stationary environments, particularly within the medical domain, through\ncustom-tuning of counterfactual-aware preference alignment. Extensive\nexperiments demonstrate our superior performance of robustness, generalization\nand coordination within RFT. Besides, we also contributed a large-scale dataset\nCXR-CounterFact (CCF), comprising 320,416 meticulously curated counterfactual\nreasoning trajectories derived from MIMIC-CXR. Our code and data are public.", "published": "2025-05-19 13:13:38", "link": "http://arxiv.org/abs/2505.13081v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "3D Visual Illusion Depth Estimation", "abstract": "3D visual illusion is a perceptual phenomenon where a two-dimensional plane\nis manipulated to simulate three-dimensional spatial relationships, making a\nflat artwork or object look three-dimensional in the human visual system. In\nthis paper, we reveal that the machine visual system is also seriously fooled\nby 3D visual illusions, including monocular and binocular depth estimation. In\norder to explore and analyze the impact of 3D visual illusion on depth\nestimation, we collect a large dataset containing almost 3k scenes and 200k\nimages to train and evaluate SOTA monocular and binocular depth estimation\nmethods. We also propose a robust depth estimation framework that uses common\nsense from a vision-language model to adaptively select reliable depth from\nbinocular disparity and monocular depth. Experiments show that SOTA monocular,\nbinocular, and multi-view depth estimation approaches are all fooled by various\n3D visual illusions, while our method achieves SOTA performance.", "published": "2025-05-19 12:51:03", "link": "http://arxiv.org/abs/2505.13061v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RGB-to-Polarization Estimation: A New Task and Benchmark Study", "abstract": "Polarization images provide rich physical information that is fundamentally\nabsent from standard RGB images, benefiting a wide range of computer vision\napplications such as reflection separation and material classification.\nHowever, the acquisition of polarization images typically requires additional\noptical components, which increases both the cost and the complexity of the\napplications. To bridge this gap, we introduce a new task: RGB-to-polarization\nimage estimation, which aims to infer polarization information directly from\nRGB images. In this work, we establish the first comprehensive benchmark for\nthis task by leveraging existing polarization datasets and evaluating a diverse\nset of state-of-the-art deep learning models, including both\nrestoration-oriented and generative architectures. Through extensive\nquantitative and qualitative analysis, our benchmark not only establishes the\ncurrent performance ceiling of RGB-to-polarization estimation, but also\nsystematically reveals the respective strengths and limitations of different\nmodel families -- such as direct reconstruction versus generative synthesis,\nand task-specific training versus large-scale pre-training. In addition, we\nprovide some potential directions for future research on polarization\nestimation. This benchmark is intended to serve as a foundational resource to\nfacilitate the design and evaluation of future methods for polarization\nestimation from standard RGB inputs.", "published": "2025-05-19 12:38:44", "link": "http://arxiv.org/abs/2505.13050v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Expert-Like Reparameterization of Heterogeneous Pyramid Receptive Fields in Efficient CNNs for Fair Medical Image Classification", "abstract": "Efficient convolutional neural network (CNN) architecture designs have\nattracted growing research interests. However, they usually apply single\nreceptive field (RF), small asymmetric RFs, or pyramid RFs to learn different\nfeature representations, still encountering two significant challenges in\nmedical image classification tasks: 1) They have limitations in capturing\ndiverse lesion characteristics efficiently, e.g., tiny, coordination, small and\nsalient, which have unique roles on results, especially imbalanced medical\nimage classification. 2) The predictions generated by those CNNs are often\nunfair/biased, bringing a high risk by employing them to real-world medical\ndiagnosis conditions. To tackle these issues, we develop a new concept,\nExpert-Like Reparameterization of Heterogeneous Pyramid Receptive Fields\n(ERoHPRF), to simultaneously boost medical image classification performance and\nfairness. This concept aims to mimic the multi-expert consultation mode by\napplying the well-designed heterogeneous pyramid RF bags to capture different\nlesion characteristics effectively via convolution operations with multiple\nheterogeneous kernel sizes. Additionally, ERoHPRF introduces an expert-like\nstructural reparameterization technique to merge its parameters with the\ntwo-stage strategy, ensuring competitive computation cost and inference speed\nthrough comparisons to a single RF. To manifest the effectiveness and\ngeneralization ability of ERoHPRF, we incorporate it into mainstream efficient\nCNN architectures. The extensive experiments show that our method maintains a\nbetter trade-off than state-of-the-art methods in terms of medical image\nclassification, fairness, and computation overhead. The codes of this paper\nwill be released soon.", "published": "2025-05-19 12:23:04", "link": "http://arxiv.org/abs/2505.13039v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A generalisable head MRI defacing pipeline: Evaluation on 2,566 meningioma scans", "abstract": "Reliable MRI defacing techniques to safeguard patient privacy while\npreserving brain anatomy are critical for research collaboration. Existing\nmethods often struggle with incomplete defacing or degradation of brain tissue\nregions. We present a robust, generalisable defacing pipeline for\nhigh-resolution MRI that integrates atlas-based registration with brain\nmasking. Our method was evaluated on 2,566 heterogeneous clinical scans for\nmeningioma and achieved a 99.92 per cent success rate (2,564/2,566) upon visual\ninspection. Excellent anatomical preservation is demonstrated with a Dice\nsimilarity coefficient of 0.9975 plus or minus 0.0023 between brain masks\nautomatically extracted from the original and defaced volumes. Source code is\navailable at https://github.com/cai4cai/defacing_pipeline.", "published": "2025-05-19 11:39:18", "link": "http://arxiv.org/abs/2505.12999v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "A Skull-Adaptive Framework for AI-Based 3D Transcranial Focused Ultrasound Simulation", "abstract": "Transcranial focused ultrasound (tFUS) is an emerging modality for\nnon-invasive brain stimulation and therapeutic intervention, offering\nmillimeter-scale spatial precision and the ability to target deep brain\nstructures. However, the heterogeneous and anisotropic nature of the human\nskull introduces significant distortions to the propagating ultrasound\nwavefront, which require time-consuming patient-specific planning and\ncorrections using numerical solvers for accurate targeting. To enable\ndata-driven approaches in this domain, we introduce TFUScapes, the first\nlarge-scale, high-resolution dataset of tFUS simulations through anatomically\nrealistic human skulls derived from T1-weighted MRI images. We have developed a\nscalable simulation engine pipeline using the k-Wave pseudo-spectral solver,\nwhere each simulation returns a steady-state pressure field generated by a\nfocused ultrasound transducer placed at realistic scalp locations. In addition\nto the dataset, we present DeepTFUS, a deep learning model that estimates\nnormalized pressure fields directly from input 3D CT volumes and transducer\nposition. The model extends a U-Net backbone with transducer-aware\nconditioning, incorporating Fourier-encoded position embeddings and MLP layers\nto create global transducer embeddings. These embeddings are fused with U-Net\nencoder features via feature-wise modulation, dynamic convolutions, and\ncross-attention mechanisms. The model is trained using a combination of\nspatially weighted and gradient-sensitive loss functions, enabling it to\napproximate high-fidelity wavefields. The TFUScapes dataset is publicly\nreleased to accelerate research at the intersection of computational acoustics,\nneurotechnology, and deep learning. The project page is available at\nhttps://github.com/CAMMA-public/TFUScapes.", "published": "2025-05-19 11:37:51", "link": "http://arxiv.org/abs/2505.12998v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Enhancing Diffusion-Weighted Images (DWI) for Diffusion MRI: Is it Enough without Non-Diffusion-Weighted B=0 Reference?", "abstract": "Diffusion MRI (dMRI) is essential for studying brain microstructure, but\nhigh-resolution imaging remains challenging due to the inherent trade-offs\nbetween acquisition time and signal-to-noise ratio (SNR). Conventional methods\noften optimize only the diffusion-weighted images (DWIs) without considering\ntheir relationship with the non-diffusion-weighted (b=0) reference images.\nHowever, calculating diffusion metrics, such as the apparent diffusion\ncoefficient (ADC) and diffusion tensor with its derived metrics like fractional\nanisotropy (FA) and mean diffusivity (MD), relies on the ratio between each DWI\nand the b=0 image, which is crucial for clinical observation and diagnostics.\nIn this study, we demonstrate that solely enhancing DWIs using a conventional\npixel-wise mean squared error (MSE) loss is insufficient, as the error in ratio\nbetween generated DWIs and b=0 diverges. We propose a novel ratio loss, defined\nas the MSE loss between the predicted and ground-truth log of DWI/b=0 ratios.\nOur results show that incorporating the ratio loss significantly improves the\nconvergence of this ratio error, achieving lower ratio MSE and slightly\nenhancing the peak signal-to-noise ratio (PSNR) of generated DWIs. This leads\nto improved dMRI super-resolution and better preservation of b=0 ratio-based\nfeatures for the derivation of diffusion metrics.", "published": "2025-05-19 11:16:43", "link": "http://arxiv.org/abs/2505.12978v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "LatentINDIGO: An INN-Guided Latent Diffusion Algorithm for Image Restoration", "abstract": "There is a growing interest in the use of latent diffusion models (LDMs) for\nimage restoration (IR) tasks due to their ability to model effectively the\ndistribution of natural images. While significant progress has been made, there\nare still key challenges that need to be addressed. First, many approaches\ndepend on a predefined degradation operator, making them ill-suited for complex\nor unknown degradations that deviate from standard analytical models. Second,\nmany methods struggle to provide a stable guidance in the latent space and\nfinally most methods convert latent representations back to the pixel domain\nfor guidance at every sampling iteration, which significantly increases\ncomputational and memory overhead. To overcome these limitations, we introduce\na wavelet-inspired invertible neural network (INN) that simulates degradations\nthrough a forward transform and reconstructs lost details via the inverse\ntransform. We further integrate this design into a latent diffusion pipeline\nthrough two proposed approaches: LatentINDIGO-PixelINN, which operates in the\npixel domain, and LatentINDIGO-LatentINN, which stays fully in the latent space\nto reduce complexity. Both approaches alternate between updating intermediate\nlatent variables under the guidance of our INN and refining the INN forward\nmodel to handle unknown degradations. In addition, a regularization step\npreserves the proximity of latent variables to the natural image manifold.\nExperiments demonstrate that our algorithm achieves state-of-the-art\nperformance on synthetic and real-world low-quality images, and can be readily\nadapted to arbitrary output sizes.", "published": "2025-05-19 10:17:16", "link": "http://arxiv.org/abs/2505.12935v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Uniformity First: Uniformity-aware Test-time Adaptation of Vision-language Models against Image Corruption", "abstract": "Pre-trained vision-language models such as contrastive language-image\npre-training (CLIP) have demonstrated a remarkable generalizability, which has\nenabled a wide range of applications represented by zero-shot classification.\nHowever, vision-language models still suffer when they face datasets with large\ngaps from training ones, i.e., distribution shifts. We found that CLIP is\nespecially vulnerable to sensor degradation, a type of realistic distribution\nshift caused by sensor conditions such as weather, light, or noise. Collecting\na new dataset from a test distribution for fine-tuning highly costs since\nsensor degradation occurs unexpectedly and has a range of variety. Thus, we\ninvestigate test-time adaptation (TTA) of zero-shot classification, which\nenables on-the-fly adaptation to the test distribution with unlabeled test\ndata. Existing TTA methods for CLIP mainly focus on modifying image and text\nembeddings or predictions to address distribution shifts. Although these\nmethods can adapt to domain shifts, such as fine-grained labels spaces or\ndifferent renditions in input images, they fail to adapt to distribution shifts\ncaused by sensor degradation. We found that this is because image embeddings\nare \"corrupted\" in terms of uniformity, a measure related to the amount of\ninformation. To make models robust to sensor degradation, we propose a novel\nmethod called uniformity-aware information-balanced TTA (UnInfo). To address\nthe corruption of image embeddings, we introduce uniformity-aware confidence\nmaximization, information-aware loss balancing, and knowledge distillation from\nthe exponential moving average (EMA) teacher. Through experiments, we\ndemonstrate that our UnInfo improves accuracy under sensor degradation by\nretaining information in terms of uniformity.", "published": "2025-05-19 09:47:46", "link": "http://arxiv.org/abs/2505.12912v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HiERO: understanding the hierarchy of human behavior enhances reasoning on egocentric videos", "abstract": "Human activities are particularly complex and variable, and this makes\nchallenging for deep learning models to reason about them. However, we note\nthat such variability does have an underlying structure, composed of a\nhierarchy of patterns of related actions. We argue that such structure can\nemerge naturally from unscripted videos of human activities, and can be\nleveraged to better reason about their content. We present HiERO, a\nweakly-supervised method to enrich video segments features with the\ncorresponding hierarchical activity threads. By aligning video clips with their\nnarrated descriptions, HiERO infers contextual, semantic and temporal reasoning\nwith an hierarchical architecture. We prove the potential of our enriched\nfeatures with multiple video-text alignment benchmarks (EgoMCQ, EgoNLQ) with\nminimal additional training, and in zero-shot for procedure learning tasks\n(EgoProceL and Ego4D Goal-Step). Notably, HiERO achieves state-of-the-art\nperformance in all the benchmarks, and for procedure learning tasks it\noutperforms fully-supervised methods by a large margin (+12.5% F1 on EgoProceL)\nin zero shot. Our results prove the relevance of using knowledge of the\nhierarchy of human activities for multiple reasoning tasks in egocentric\nvision.", "published": "2025-05-19 09:47:41", "link": "http://arxiv.org/abs/2505.12911v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Dynamic Graph Induced Contour-aware Heat Conduction Network for Event-based Object Detection", "abstract": "Event-based Vision Sensors (EVS) have demonstrated significant advantages\nover traditional RGB frame-based cameras in low-light conditions, high-speed\nmotion capture, and low latency. Consequently, object detection based on EVS\nhas attracted increasing attention from researchers. Current event stream\nobject detection algorithms are typically built upon Convolutional Neural\nNetworks (CNNs) or Transformers, which either capture limited local features\nusing convolutional filters or incur high computational costs due to the\nutilization of self-attention. Recently proposed vision heat conduction\nbackbone networks have shown a good balance between efficiency and accuracy;\nhowever, these models are not specifically designed for event stream data. They\nexhibit weak capability in modeling object contour information and fail to\nexploit the benefits of multi-scale features. To address these issues, this\npaper proposes a novel dynamic graph induced contour-aware heat conduction\nnetwork for event stream based object detection, termed CvHeat-DET. The\nproposed model effectively leverages the clear contour information inherent in\nevent streams to predict the thermal diffusivity coefficients within the heat\nconduction model, and integrates hierarchical structural graph features to\nenhance feature learning across multiple scales. Extensive experiments on three\nbenchmark datasets for event stream-based object detection fully validated the\neffectiveness of the proposed model. The source code of this paper will be\nreleased on https://github.com/Event-AHU/OpenEvDET.", "published": "2025-05-19 09:44:01", "link": "http://arxiv.org/abs/2505.12908v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Towards Low-Latency Event Stream-based Visual Object Tracking: A Slow-Fast Approach", "abstract": "Existing tracking algorithms typically rely on low-frame-rate RGB cameras\ncoupled with computationally intensive deep neural network architectures to\nachieve effective tracking. However, such frame-based methods inherently face\nchallenges in achieving low-latency performance and often fail in\nresource-constrained environments. Visual object tracking using bio-inspired\nevent cameras has emerged as a promising research direction in recent years,\noffering distinct advantages for low-latency applications. In this paper, we\npropose a novel Slow-Fast Tracking paradigm that flexibly adapts to different\noperational requirements, termed SFTrack. The proposed framework supports two\ncomplementary modes, i.e., a high-precision slow tracker for scenarios with\nsufficient computational resources, and an efficient fast tracker tailored for\nlatency-aware, resource-constrained environments. Specifically, our framework\nfirst performs graph-based representation learning from\nhigh-temporal-resolution event streams, and then integrates the learned\ngraph-structured information into two FlashAttention-based vision backbones,\nyielding the slow and fast trackers, respectively. The fast tracker achieves\nlow latency through a lightweight network design and by producing multiple\nbounding box outputs in a single forward pass. Finally, we seamlessly combine\nboth trackers via supervised fine-tuning and further enhance the fast tracker's\nperformance through a knowledge distillation strategy. Extensive experiments on\npublic benchmarks, including FE240, COESOT, and EventVOT, demonstrate the\neffectiveness and efficiency of our proposed method across different real-world\nscenarios. The source code has been released on\nhttps://github.com/Event-AHU/SlowFast_Event_Track.", "published": "2025-05-19 09:37:23", "link": "http://arxiv.org/abs/2505.12903v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "EPIC: Explanation of Pretrained Image Classification Networks via Prototype", "abstract": "Explainable AI (XAI) methods generally fall into two categories. Post-hoc\napproaches generate explanations for pre-trained models and are compatible with\nvarious neural network architectures. These methods often use feature\nimportance visualizations, such as saliency maps, to indicate which input\nregions influenced the model's prediction. Unfortunately, they typically offer\na coarse understanding of the model's decision-making process. In contrast,\nante-hoc (inherently explainable) methods rely on specially designed model\narchitectures trained from scratch. A notable subclass of these methods\nprovides explanations through prototypes, representative patches extracted from\nthe training data. However, prototype-based approaches have limitations: they\nrequire dedicated architectures, involve specialized training procedures, and\nperform well only on specific datasets. In this work, we propose EPIC\n(Explanation of Pretrained Image Classification), a novel approach that bridges\nthe gap between these two paradigms. Like post-hoc methods, EPIC operates on\npre-trained models without architectural modifications. Simultaneously, it\ndelivers intuitive, prototype-based explanations inspired by ante-hoc\ntechniques. To the best of our knowledge, EPIC is the first post-hoc method\ncapable of fully replicating the core explanatory power of inherently\ninterpretable models. We evaluate EPIC on benchmark datasets commonly used in\nprototype-based explanations, such as CUB-200-2011 and Stanford Cars, alongside\nlarge-scale datasets like ImageNet, typically employed by post-hoc methods.\nEPIC uses prototypes to explain model decisions, providing a flexible and\neasy-to-understand tool for creating clear, high-quality explanations.", "published": "2025-05-19 09:32:20", "link": "http://arxiv.org/abs/2505.12897v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ORQA: A Benchmark and Foundation Model for Holistic Operating Room Modeling", "abstract": "The real-world complexity of surgeries necessitates surgeons to have deep and\nholistic comprehension to ensure precision, safety, and effective\ninterventions. Computational systems are required to have a similar level of\ncomprehension within the operating room. Prior works, limited to single-task\nefforts like phase recognition or scene graph generation, lack scope and\ngeneralizability. In this work, we introduce ORQA, a novel OR question\nanswering benchmark and foundational multimodal model to advance OR\nintelligence. By unifying all four public OR datasets into a comprehensive\nbenchmark, we enable our approach to concurrently address a diverse range of OR\nchallenges. The proposed multimodal large language model fuses diverse OR\nsignals such as visual, auditory, and structured data, for a holistic modeling\nof the OR. Finally, we propose a novel, progressive knowledge distillation\nparadigm, to generate a family of models optimized for different speed and\nmemory requirements. We show the strong performance of ORQA on our proposed\nbenchmark, and its zero-shot generalization, paving the way for scalable,\nunified OR modeling and significantly advancing multimodal surgical\nintelligence. We will release our code and data upon acceptance.", "published": "2025-05-19 09:20:29", "link": "http://arxiv.org/abs/2505.12890v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RetinaLogos: Fine-Grained Synthesis of High-Resolution Retinal Images Through Captions", "abstract": "The scarcity of high-quality, labelled retinal imaging data, which presents a\nsignificant challenge in the development of machine learning models for\nophthalmology, hinders progress in the field. To synthesise Colour Fundus\nPhotographs (CFPs), existing methods primarily relying on predefined disease\nlabels face significant limitations. However, current methods remain limited,\nthus failing to generate images for broader categories with diverse and\nfine-grained anatomical structures. To overcome these challenges, we first\nintroduce an innovative pipeline that creates a large-scale, synthetic\nCaption-CFP dataset comprising 1.4 million entries, called RetinaLogos-1400k.\nSpecifically, RetinaLogos-1400k uses large language models (LLMs) to describe\nretinal conditions and key structures, such as optic disc configuration,\nvascular distribution, nerve fibre layers, and pathological features.\nFurthermore, based on this dataset, we employ a novel three-step training\nframework, called RetinaLogos, which enables fine-grained semantic control over\nretinal images and accurately captures different stages of disease progression,\nsubtle anatomical variations, and specific lesion types. Extensive experiments\ndemonstrate state-of-the-art performance across multiple datasets, with 62.07%\nof text-driven synthetic images indistinguishable from real ones by\nophthalmologists. Moreover, the synthetic data improves accuracy by 10%-25% in\ndiabetic retinopathy grading and glaucoma detection, thereby providing a\nscalable solution to augment ophthalmic datasets.", "published": "2025-05-19 09:18:11", "link": "http://arxiv.org/abs/2505.12887v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "TinyAlign: Boosting Lightweight Vision-Language Models by Mitigating Modal Alignment Bottlenecks", "abstract": "Lightweight Vision-Language Models (VLMs) are indispensable for\nresource-constrained applications. The prevailing approach to aligning vision\nand language models involves freezing both the vision encoder and the language\nmodel while training small connector modules. However, this strategy heavily\ndepends on the intrinsic capabilities of the language model, which can be\nsuboptimal for lightweight models with limited representational capacity. In\nthis work, we investigate this alignment bottleneck through the lens of mutual\ninformation, demonstrating that the constrained capacity of the language model\ninherently limits the Effective Mutual Information (EMI) between multimodal\ninputs and outputs, thereby compromising alignment quality. To address this\nchallenge, we propose TinyAlign, a novel framework inspired by\nRetrieval-Augmented Generation, which strategically retrieves relevant context\nfrom a memory bank to enrich multimodal inputs and enhance their alignment.\nExtensive empirical evaluations reveal that TinyAlign significantly reduces\ntraining loss, accelerates convergence, and enhances task performance.\nRemarkably, it allows models to achieve baseline-level performance with only\n40\\% of the fine-tuning data, highlighting exceptional data efficiency. Our\nwork thus offers a practical pathway for developing more capable lightweight\nVLMs while introducing a fresh theoretical lens to better understand and\naddress alignment bottlenecks in constrained multimodal systems.", "published": "2025-05-19 09:11:54", "link": "http://arxiv.org/abs/2505.12884v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Unified Cross-modal Translation of Score Images, Symbolic Music, and Performance Audio", "abstract": "Music exists in various modalities, such as score images, symbolic scores,\nMIDI, and audio. Translations between each modality are established as core\ntasks of music information retrieval, such as automatic music transcription\n(audio-to-MIDI) and optical music recognition (score image to symbolic score).\nHowever, most past work on multimodal translation trains specialized models on\nindividual translation tasks. In this paper, we propose a unified approach,\nwhere we train a general-purpose model on many translation tasks\nsimultaneously. Two key factors make this unified approach viable: a new\nlarge-scale dataset and the tokenization of each modality. Firstly, we propose\na new dataset that consists of more than 1,300 hours of paired audio-score\nimage data collected from YouTube videos, which is an order of magnitude larger\nthan any existing music modal translation datasets. Secondly, our unified\ntokenization framework discretizes score images, audio, MIDI, and MusicXML into\na sequence of tokens, enabling a single encoder-decoder Transformer to tackle\nmultiple cross-modal translation as one coherent sequence-to-sequence task.\nExperimental results confirm that our unified multitask model improves upon\nsingle-task baselines in several key areas, notably reducing the symbol error\nrate for optical music recognition from 24.58% to a state-of-the-art 13.67%,\nwhile similarly substantial improvements are observed across the other\ntranslation tasks. Notably, our approach achieves the first successful\nscore-image-conditioned audio generation, marking a significant breakthrough in\ncross-modal music generation.", "published": "2025-05-19 08:46:45", "link": "http://arxiv.org/abs/2505.12863v1", "categories": ["cs.SD", "cs.AI", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Robust Multimodal Segmentation with Representation Regularization and Hybrid Prototype Distillation", "abstract": "Multi-modal semantic segmentation (MMSS) faces significant challenges in\nreal-world scenarios due to dynamic environments, sensor failures, and noise\ninterference, creating a gap between theoretical models and practical\nperformance. To address this, we propose a two-stage framework called\nRobustSeg, which enhances multi-modal robustness through two key components:\nthe Hybrid Prototype Distillation Module (HPDM) and the Representation\nRegularization Module (RRM). In the first stage, RobustSeg pre-trains a\nmulti-modal teacher model using complete modalities. In the second stage, a\nstudent model is trained with random modality dropout while learning from the\nteacher via HPDM and RRM. HPDM transforms features into compact prototypes,\nenabling cross-modal hybrid knowledge distillation and mitigating bias from\nmissing modalities. RRM reduces representation discrepancies between the\nteacher and student by optimizing functional entropy through the log-Sobolev\ninequality. Extensive experiments on three public benchmarks demonstrate that\nRobustSeg outperforms previous state-of-the-art methods, achieving improvements\nof +2.76%, +4.56%, and +0.98%, respectively. Code is available at:\nhttps://github.com/RobustSeg/RobustSeg.", "published": "2025-05-19 08:46:03", "link": "http://arxiv.org/abs/2505.12861v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards a Universal Image Degradation Model via Content-Degradation Disentanglement", "abstract": "Image degradation synthesis is highly desirable in a wide variety of\napplications ranging from image restoration to simulating artistic effects.\nExisting models are designed to generate one specific or a narrow set of\ndegradations, which often require user-provided degradation parameters. As a\nresult, they lack the generalizability to synthesize degradations beyond their\ninitial design or adapt to other applications. Here we propose the first\nuniversal degradation model that can synthesize a broad spectrum of complex and\nrealistic degradations containing both homogeneous (global) and inhomogeneous\n(spatially varying) components. Our model automatically extracts and\ndisentangles homogeneous and inhomogeneous degradation features, which are\nlater used for degradation synthesis without user intervention. A\ndisentangle-by-compression method is proposed to separate degradation\ninformation from images. Two novel modules for extracting and incorporating\ninhomogeneous degradations are created to model inhomogeneous components in\ncomplex degradations. We demonstrate the model's accuracy and adaptability in\nfilm-grain simulation and blind image restoration tasks. The demo video, code,\nand dataset of this project will be released upon publication at\ngithub.com/yangwenbo99/content-degradation-disentanglement.", "published": "2025-05-19 08:45:08", "link": "http://arxiv.org/abs/2505.12860v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "The Way Up: A Dataset for Hold Usage Detection in Sport Climbing", "abstract": "Detecting an athlete's position on a route and identifying hold usage are\ncrucial in various climbing-related applications. However, no climbing dataset\nwith detailed hold usage annotations exists to our knowledge. To address this\nissue, we introduce a dataset of 22 annotated climbing videos, providing\nground-truth labels for hold locations, usage order, and time of use.\nFurthermore, we explore the application of keypoint-based 2D pose-estimation\nmodels for detecting hold usage in sport climbing. We determine usage by\nanalyzing the key points of certain joints and the corresponding overlap with\nclimbing holds. We evaluate multiple state-of-the-art models and analyze their\naccuracy on our dataset, identifying and highlighting climbing-specific\nchallenges. Our dataset and results highlight key challenges in\nclimbing-specific pose estimation and establish a foundation for future\nresearch toward AI-assisted systems for sports climbing.", "published": "2025-05-19 08:41:18", "link": "http://arxiv.org/abs/2505.12854v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Accelerate TarFlow Sampling with GS-Jacobi Iteration", "abstract": "Image generation models have achieved widespread applications. As an\ninstance, the TarFlow model combines the transformer architecture with\nNormalizing Flow models, achieving state-of-the-art results on multiple\nbenchmarks. However, due to the causal form of attention requiring sequential\ncomputation, TarFlow's sampling process is extremely slow. In this paper, we\ndemonstrate that through a series of optimization strategies, TarFlow sampling\ncan be greatly accelerated by using the Gauss-Seidel-Jacobi (abbreviated as\nGS-Jacobi) iteration method. Specifically, we find that blocks in the TarFlow\nmodel have varying importance: a small number of blocks play a major role in\nimage generation tasks, while other blocks contribute relatively little; some\nblocks are sensitive to initial values and prone to numerical overflow, while\nothers are relatively robust. Based on these two characteristics, we propose\nthe Convergence Ranking Metric (CRM) and the Initial Guessing Metric (IGM): CRM\nis used to identify whether a TarFlow block is \"simple\" (converges in few\niterations) or \"tough\" (requires more iterations); IGM is used to evaluate\nwhether the initial value of the iteration is good. Experiments on four TarFlow\nmodels demonstrate that GS-Jacobi sampling can significantly enhance sampling\nefficiency while maintaining the quality of generated images (measured by FID),\nachieving speed-ups of 4.53x in Img128cond, 5.32x in AFHQ, 2.96x in\nImg64uncond, and 2.51x in Img64cond without degrading FID scores or sample\nquality. Code and checkpoints are accessible on\nhttps://github.com/encoreus/GS-Jacobi_for_TarFlow", "published": "2025-05-19 08:35:44", "link": "http://arxiv.org/abs/2505.12849v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "The Gaussian Latent Machine: Efficient Prior and Posterior Sampling for Inverse Problems", "abstract": "We consider the problem of sampling from a product-of-experts-type model that\nencompasses many standard prior and posterior distributions commonly found in\nBayesian imaging. We show that this model can be easily lifted into a novel\nlatent variable model, which we refer to as a Gaussian latent machine. This\nleads to a general sampling approach that unifies and generalizes many existing\nsampling algorithms in the literature. Most notably, it yields a highly\nefficient and effective two-block Gibbs sampling approach in the general case,\nwhile also specializing to direct sampling algorithms in particular cases.\nFinally, we present detailed numerical experiments that demonstrate the\nefficiency and effectiveness of our proposed sampling approach across a wide\nrange of prior and posterior sampling problems from Bayesian imaging.", "published": "2025-05-19 08:21:23", "link": "http://arxiv.org/abs/2505.12836v1", "categories": ["eess.IV", "cs.CV", "cs.LG", "stat.ML", "65C40, 65C05, 68U10, 65C60"], "primary_category": "eess.IV"}
{"title": "A Study on the Refining Handwritten Font by Mixing Font Styles", "abstract": "Handwritten fonts have a distinct expressive character, but they are often\ndifficult to read due to unclear or inconsistent handwriting. FontFusionGAN\n(FFGAN) is a novel method for improving handwritten fonts by combining them\nwith printed fonts. Our method implements generative adversarial network (GAN)\nto generate font that mix the desirable features of handwritten and printed\nfonts. By training the GAN on a dataset of handwritten and printed fonts, it\ncan generate legible and visually appealing font images. We apply our method to\na dataset of handwritten fonts and demonstrate that it significantly enhances\nthe readability of the original fonts while preserving their unique aesthetic.\nOur method has the potential to improve the readability of handwritten fonts,\nwhich would be helpful for a variety of applications including document\ncreation, letter writing, and assisting individuals with reading and writing\ndifficulties. In addition to addressing the difficulties of font creation for\nlanguages with complex character sets, our method is applicable to other\ntext-image-related tasks, such as font attribute control and multilingual font\nstyle transfer.", "published": "2025-05-19 08:20:43", "link": "http://arxiv.org/abs/2505.12834v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Mitigating Hallucination in VideoLLMs via Temporal-Aware Activation Engineering", "abstract": "Multimodal large language models (MLLMs) have achieved remarkable progress in\nvideo understanding.However, hallucination, where the model generates plausible\nyet incorrect outputs, persists as a significant and under-addressed challenge\nin the video domain. Among existing solutions, activation engineering has\nproven successful in mitigating hallucinations in LLMs and ImageLLMs, yet its\napplicability to VideoLLMs remains largely unexplored. In this work, we are the\nfirst to systematically investigate the effectiveness and underlying mechanisms\nof activation engineering for mitigating hallucinations in VideoLLMs. We\ninitially conduct an investigation of the key factors affecting the performance\nof activation engineering and find that a model's sensitivity to hallucination\ndepends on $\\textbf{temporal variation}$ rather than task type. Moreover,\nselecting appropriate internal modules and dataset for activation engineering\nis critical for reducing hallucination. Guided by these findings, we propose a\ntemporal-aware activation engineering framework for VideoLLMs, which adaptively\nidentifies and manipulates hallucination-sensitive modules based on the\ntemporal variation characteristic, substantially mitigating hallucinations\nwithout additional LLM fine-tuning. Experiments across multiple models and\nbenchmarks demonstrate that our method markedly reduces hallucination in\nVideoLLMs, thereby validating the robustness of our findings.", "published": "2025-05-19 08:12:06", "link": "http://arxiv.org/abs/2505.12826v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Rethinking Features-Fused-Pyramid-Neck for Object Detection", "abstract": "Multi-head detectors typically employ a features-fused-pyramid-neck for\nmulti-scale detection and are widely adopted in the industry. However, this\napproach faces feature misalignment when representations from different\nhierarchical levels of the feature pyramid are forcibly fused point-to-point.\nTo address this issue, we designed an independent hierarchy pyramid (IHP)\narchitecture to evaluate the effectiveness of the features-unfused-pyramid-neck\nfor multi-head detectors. Subsequently, we introduced soft nearest neighbor\ninterpolation (SNI) with a weight downscaling factor to mitigate the impact of\nfeature fusion at different hierarchies while preserving key textures.\nFurthermore, we present a features adaptive selection method for down sampling\nin extended spatial windows (ESD) to retain spatial features and enhance\nlightweight convolutional techniques (GSConvE). These advancements culminate in\nour secondary features alignment solution (SA) for real-time detection,\nachieving state-of-the-art results on Pascal VOC and MS COCO. Code will be\nreleased at https://github.com/AlanLi1997/rethinking-fpn. This paper has been\naccepted by ECCV2024 and published on Springer Nature.", "published": "2025-05-19 08:01:11", "link": "http://arxiv.org/abs/2505.12820v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Informed Mixing -- Improving Open Set Recognition via Attribution-based Augmentation", "abstract": "Open set recognition (OSR) is devised to address the problem of detecting\nnovel classes during model inference. Even in recent vision models, this\nremains an open issue which is receiving increasing attention. Thereby, a\ncrucial challenge is to learn features that are relevant for unseen categories\nfrom given data, for which these features might not be discriminative. To\nfacilitate this process and \"optimize to learn\" more diverse features, we\npropose GradMix, a data augmentation method that dynamically leverages\ngradient-based attribution maps of the model during training to mask out\nalready learned concepts. Thus GradMix encourages the model to learn a more\ncomplete set of representative features from the same data source. Extensive\nexperiments on open set recognition, close set classification, and\nout-of-distribution detection reveal that our method can often outperform the\nstate-of-the-art. GradMix can further increase model robustness to corruptions\nas well as downstream classification performance for self-supervised learning,\nindicating its benefit for model generalization.", "published": "2025-05-19 07:32:06", "link": "http://arxiv.org/abs/2505.12803v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Enhancing Transformers Through Conditioned Embedded Tokens", "abstract": "Transformers have transformed modern machine learning, driving breakthroughs\nin computer vision, natural language processing, and robotics. At the core of\ntheir success lies the attention mechanism, which enables the modeling of\nglobal dependencies among input tokens. However, we reveal that the attention\nblock in transformers suffers from inherent ill-conditioning, which hampers\ngradient-based optimization and leads to inefficient training. To address this,\nwe develop a theoretical framework that establishes a direct relationship\nbetween the conditioning of the attention block and that of the embedded\ntokenized data. Building on this insight, we introduce conditioned embedded\ntokens, a method that systematically modifies the embedded tokens to improve\nthe conditioning of the attention mechanism. Our analysis demonstrates that\nthis approach significantly mitigates ill-conditioning, leading to more stable\nand efficient training. We validate our methodology across various transformer\narchitectures, achieving consistent improvements in image classification,\nobject detection, instance segmentation, and natural language processing,\nhighlighting its broad applicability and effectiveness.", "published": "2025-05-19 07:21:53", "link": "http://arxiv.org/abs/2505.12789v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AdaToken-3D: Dynamic Spatial Gating for Efficient 3D Large Multimodal-Models Reasoning", "abstract": "Large Multimodal Models (LMMs) have become a pivotal research focus in deep\nlearning, demonstrating remarkable capabilities in 3D scene understanding.\nHowever, current 3D LMMs employing thousands of spatial tokens for multimodal\nreasoning suffer from critical inefficiencies: excessive computational overhead\nand redundant information flows. Unlike 2D VLMs processing single images, 3D\nLMMs exhibit inherent architectural redundancy due to the heterogeneous\nmechanisms between spatial tokens and visual tokens. To address this challenge,\nwe propose AdaToken-3D, an adaptive spatial token optimization framework that\ndynamically prunes redundant tokens through spatial contribution analysis. Our\nmethod automatically tailors pruning strategies to different 3D LMM\narchitectures by quantifying token-level information flows via attention\npattern mining. Extensive experiments on LLaVA-3D (a 7B parameter 3D-LMM)\ndemonstrate that AdaToken-3D achieves 21\\% faster inference speed and 63\\%\nFLOPs reduction while maintaining original task accuracy. Beyond efficiency\ngains, this work systematically investigates redundancy patterns in multimodal\nspatial information flows through quantitative token interaction analysis. Our\nfindings reveal that over 60\\% of spatial tokens contribute minimally ($<$5\\%)\nto the final predictions, establishing theoretical foundations for efficient 3D\nmultimodal learning.", "published": "2025-05-19 07:11:07", "link": "http://arxiv.org/abs/2505.12782v1", "categories": ["cs.GR", "cs.CV", "cs.IR", "cs.IT", "math.IT"], "primary_category": "cs.GR"}
{"title": "UniHM: Universal Human Motion Generation with Object Interactions in Indoor Scenes", "abstract": "Human motion synthesis in complex scenes presents a fundamental challenge,\nextending beyond conventional Text-to-Motion tasks by requiring the integration\nof diverse modalities such as static environments, movable objects, natural\nlanguage prompts, and spatial waypoints. Existing language-conditioned motion\nmodels often struggle with scene-aware motion generation due to limitations in\nmotion tokenization, which leads to information loss and fails to capture the\ncontinuous, context-dependent nature of 3D human movement. To address these\nissues, we propose UniHM, a unified motion language model that leverages\ndiffusion-based generation for synthesizing scene-aware human motion. UniHM is\nthe first framework to support both Text-to-Motion and Text-to-Human-Object\nInteraction (HOI) in complex 3D scenes. Our approach introduces three key\ncontributions: (1) a mixed-motion representation that fuses continuous 6DoF\nmotion with discrete local motion tokens to improve motion realism; (2) a novel\nLook-Up-Free Quantization VAE (LFQ-VAE) that surpasses traditional VQ-VAEs in\nboth reconstruction accuracy and generative performance; and (3) an enriched\nversion of the Lingo dataset augmented with HumanML3D annotations, providing\nstronger supervision for scene-specific motion learning. Experimental results\ndemonstrate that UniHM achieves comparative performance on the OMOMO benchmark\nfor text-to-HOI synthesis and yields competitive results on HumanML3D for\ngeneral text-conditioned motion generation.", "published": "2025-05-19 07:02:12", "link": "http://arxiv.org/abs/2505.12774v1", "categories": ["cs.GR", "cs.AI", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Pyramid Sparse Transformer: Enhancing Multi-Scale Feature Fusion with Dynamic Token Selection", "abstract": "Feature fusion is critical for high-performance vision models but often\nincurs prohibitive complexity. However, prevailing attention-based fusion\nmethods often involve significant computational complexity and implementation\nchallenges, limiting their efficiency in resource-constrained environments. To\naddress these issues, we introduce the Pyramid Sparse Transformer (PST), a\nlightweight, plug-and-play module that integrates coarse-to-fine token\nselection and shared attention parameters to reduce computation while\npreserving spatial detail. PST can be trained using only coarse attention and\nseamlessly activated at inference for further accuracy gains without\nretraining. When added to state-of-the-art real-time detection models, such as\nYOLOv11-N/S/M, PST yields mAP improvements of 0.9%, 0.5%, and 0.4% on MS COCO\nwith minimal latency impact. Likewise, embedding PST into ResNet-18/50/101 as\nbackbones, boosts ImageNet top-1 accuracy by 6.5%, 1.7%, and 1.0%,\nrespectively. These results demonstrate PST's effectiveness as a simple,\nhardware-friendly enhancement for both detection and classification tasks.", "published": "2025-05-19 07:00:54", "link": "http://arxiv.org/abs/2505.12772v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Reasoning-OCR: Can Large Multimodal Models Solve Complex Logical Reasoning Problems from OCR Cues?", "abstract": "Large Multimodal Models (LMMs) have become increasingly versatile,\naccompanied by impressive Optical Character Recognition (OCR) related\ncapabilities. Existing OCR-related benchmarks emphasize evaluating LMMs'\nabilities of relatively simple visual question answering, visual-text parsing,\netc. However, the extent to which LMMs can deal with complex logical reasoning\nproblems based on OCR cues is relatively unexplored. To this end, we introduce\nthe Reasoning-OCR benchmark, which challenges LMMs to solve complex reasoning\nproblems based on the cues that can be extracted from rich visual-text.\nReasoning-OCR covers six visual scenarios and encompasses 150 meticulously\ndesigned questions categorized into six reasoning challenges. Additionally,\nReasoning-OCR minimizes the impact of field-specialized knowledge. Our\nevaluation offers some insights for proprietary and open-source LMMs in\ndifferent reasoning challenges, underscoring the urgent to improve the\nreasoning performance. We hope Reasoning-OCR can inspire and facilitate future\nresearch on enhancing complex reasoning ability based on OCR cues.\nReasoning-OCR is publicly available at\nhttps://github.com/Hxyz-123/ReasoningOCR.", "published": "2025-05-19 06:45:18", "link": "http://arxiv.org/abs/2505.12766v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "It's not you, it's me -- Global urban visual perception varies across demographics and personalities", "abstract": "Understanding people's preferences and needs is crucial for urban planning\ndecisions, yet current approaches often combine them from multi-cultural and\nmulti-city populations, obscuring important demographic differences and risking\namplifying biases. We conducted a large-scale urban visual perception survey of\nstreetscapes worldwide using street view imagery, examining how demographics --\nincluding gender, age, income, education, race and ethnicity, and, for the\nfirst time, personality traits -- shape perceptions among 1,000 participants,\nwith balanced demographics, from five countries and 45 nationalities. This\ndataset, introduced as Street Perception Evaluation Considering Socioeconomics\n(SPECS), exhibits statistically significant differences in perception scores in\nsix traditionally used indicators (safe, lively, wealthy, beautiful, boring,\nand depressing) and four new ones we propose (live nearby, walk, cycle, green)\namong demographics and personalities. We revealed that location-based\nsentiments are carried over in people's preferences when comparing urban\nstreetscapes with other cities. Further, we compared the perception scores\nbased on where participants and streetscapes are from. We found that an\noff-the-shelf machine learning model trained on an existing global perception\ndataset tends to overestimate positive indicators and underestimate negative\nones compared to human responses, suggesting that targeted intervention should\nconsider locals' perception. Our study aspires to rectify the myopic treatment\nof street perception, which rarely considers demographics or personality\ntraits.", "published": "2025-05-19 06:35:11", "link": "http://arxiv.org/abs/2505.12758v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "LiDAR MOT-DETR: A LiDAR-based Two-Stage Transformer for 3D Multiple Object Tracking", "abstract": "Multi-object tracking from LiDAR point clouds presents unique challenges due\nto the sparse and irregular nature of the data, compounded by the need for\ntemporal coherence across frames. Traditional tracking systems often rely on\nhand-crafted features and motion models, which can struggle to maintain\nconsistent object identities in crowded or fast-moving scenes. We present a\nlidar-based two-staged DETR inspired transformer; a smoother and tracker. The\nsmoother stage refines lidar object detections, from any off-the-shelf\ndetector, across a moving temporal window. The tracker stage uses a DETR-based\nattention block to maintain tracks across time by associating tracked objects\nwith the refined detections using the point cloud as context. The model is\ntrained on the datasets nuScenes and KITTI in both online and offline (forward\npeeking) modes demonstrating strong performance across metrics such as\nID-switch and multiple object tracking accuracy (MOTA). The numerical results\nindicate that the online mode outperforms the lidar-only baseline and SOTA\nmodels on the nuScenes dataset, with an aMOTA of 0.722 and an aMOTP of 0.475,\nwhile the offline mode provides an additional 3 pp aMOTP", "published": "2025-05-19 06:25:48", "link": "http://arxiv.org/abs/2505.12753v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Structure-based Anomaly Detection and Clustering", "abstract": "Anomaly detection is a fundamental problem in domains such as healthcare,\nmanufacturing, and cybersecurity. This thesis proposes new unsupervised methods\nfor anomaly detection in both structured and streaming data settings. In the\nfirst part, we focus on structure-based anomaly detection, where normal data\nfollows low-dimensional manifolds while anomalies deviate from them. We\nintroduce Preference Isolation Forest (PIF), which embeds data into a\nhigh-dimensional preference space via manifold fitting, and isolates outliers\nusing two variants: Voronoi-iForest, based on geometric distances, and\nRuzHash-iForest, leveraging Locality Sensitive Hashing for scalability. We also\npropose Sliding-PIF, which captures local manifold information for streaming\nscenarios. Our methods outperform existing techniques on synthetic and real\ndatasets. We extend this to structure-based clustering with MultiLink, a novel\nmethod for recovering multiple geometric model families in noisy data.\nMultiLink merges clusters via a model-aware linkage strategy, enabling robust\nmulti-class structure recovery. It offers key advantages over existing\napproaches, such as speed, reduced sensitivity to thresholds, and improved\nrobustness to poor initial sampling. The second part of the thesis addresses\nonline anomaly detection in evolving data streams. We propose Online Isolation\nForest (Online-iForest), which uses adaptive, multi-resolution histograms and\ndynamically updates tree structures to track changes over time. It avoids\nretraining while achieving accuracy comparable to offline models, with superior\nefficiency for real-time applications. Finally, we tackle anomaly detection in\ncybersecurity via open-set recognition for malware classification. We enhance a\nGradient Boosting classifier with MaxLogit to detect unseen malware families, a\nmethod now integrated into Cleafy's production system.", "published": "2025-05-19 06:20:00", "link": "http://arxiv.org/abs/2505.12751v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "TeleOpBench: A Simulator-Centric Benchmark for Dual-Arm Dexterous Teleoperation", "abstract": "Teleoperation is a cornerstone of embodied-robot learning, and bimanual\ndexterous teleoperation in particular provides rich demonstrations that are\ndifficult to obtain with fully autonomous systems. While recent studies have\nproposed diverse hardware pipelines-ranging from inertial motion-capture gloves\nto exoskeletons and vision-based interfaces-there is still no unified benchmark\nthat enables fair, reproducible comparison of these systems. In this paper, we\nintroduce TeleOpBench, a simulator-centric benchmark tailored to bimanual\ndexterous teleoperation. TeleOpBench contains 30 high-fidelity task\nenvironments that span pick-and-place, tool use, and collaborative\nmanipulation, covering a broad spectrum of kinematic and force-interaction\ndifficulty. Within this benchmark we implement four representative\nteleoperation modalities-(i) MoCap, (ii) VR device, (iii) arm-hand\nexoskeletons, and (iv) monocular vision tracking-and evaluate them with a\ncommon protocol and metric suite. To validate that performance in simulation is\npredictive of real-world behavior, we conduct mirrored experiments on a\nphysical dual-arm platform equipped with two 6-DoF dexterous hands. Across 10\nheld-out tasks we observe a strong correlation between simulator and hardware\nperformance, confirming the external validity of TeleOpBench. TeleOpBench\nestablishes a common yardstick for teleoperation research and provides an\nextensible platform for future algorithmic and hardware innovation.", "published": "2025-05-19 06:08:53", "link": "http://arxiv.org/abs/2505.12748v1", "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "cs.RO"}
{"title": "MVAR: Visual Autoregressive Modeling with Scale and Spatial Markovian Conditioning", "abstract": "Essential to visual generation is efficient modeling of visual data priors.\nConventional next-token prediction methods define the process as learning the\nconditional probability distribution of successive tokens. Recently, next-scale\nprediction methods redefine the process to learn the distribution over\nmulti-scale representations, significantly reducing generation latency.\nHowever, these methods condition each scale on all previous scales and require\neach token to consider all preceding tokens, exhibiting scale and spatial\nredundancy. To better model the distribution by mitigating redundancy, we\npropose Markovian Visual AutoRegressive modeling (MVAR), a novel autoregressive\nframework that introduces scale and spatial Markov assumptions to reduce the\ncomplexity of conditional probability modeling. Specifically, we introduce a\nscale-Markov trajectory that only takes as input the features of adjacent\npreceding scale for next-scale prediction, enabling the adoption of a parallel\ntraining strategy that significantly reduces GPU memory consumption.\nFurthermore, we propose spatial-Markov attention, which restricts the attention\nof each token to a localized neighborhood of size k at corresponding positions\non adjacent scales, rather than attending to every token across these scales,\nfor the pursuit of reduced modeling complexity. Building on these improvements,\nwe reduce the computational complexity of attention calculation from O(N^2) to\nO(Nk), enabling training with just eight NVIDIA RTX 4090 GPUs and eliminating\nthe need for KV cache during inference. Extensive experiments on ImageNet\ndemonstrate that MVAR achieves comparable or superior performance with both\nsmall model trained from scratch and large fine-tuned models, while reducing\nthe average GPU memory footprint by 3.0x.", "published": "2025-05-19 05:56:44", "link": "http://arxiv.org/abs/2505.12742v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FLASH: Latent-Aware Semi-Autoregressive Speculative Decoding for Multimodal Tasks", "abstract": "Large language and multimodal models (LLMs and LMMs) exhibit strong inference\ncapabilities but are often limited by slow decoding speeds. This challenge is\nespecially acute in LMMs, where visual inputs typically comprise more tokens\nwith lower information density than text -- an issue exacerbated by recent\ntrends toward finer-grained visual tokenizations to boost performance.\nSpeculative decoding has been effective in accelerating LLM inference by using\na smaller draft model to generate candidate tokens, which are then selectively\nverified by the target model, improving speed without sacrificing output\nquality. While this strategy has been extended to LMMs, existing methods\nlargely overlook the unique properties of visual inputs and depend solely on\ntext-based draft models. In this work, we propose \\textbf{FLASH} (Fast\nLatent-Aware Semi-Autoregressive Heuristics), a speculative decoding framework\ndesigned specifically for LMMs, which leverages two key properties of\nmultimodal data to design the draft model. First, to address redundancy in\nvisual tokens, we propose a lightweight latent-aware token compression\nmechanism. Second, recognizing that visual objects often co-occur within a\nscene, we employ a semi-autoregressive decoding strategy to generate multiple\ntokens per forward pass. These innovations accelerate draft decoding while\nmaintaining high acceptance rates, resulting in faster overall inference.\nExperiments show that FLASH significantly outperforms prior speculative\ndecoding approaches in both unimodal and multimodal settings, achieving up to\n\\textbf{2.68$\\times$} speed-up on video captioning and \\textbf{2.55$\\times$} on\nvisual instruction tuning tasks compared to the original LMM.", "published": "2025-05-19 05:35:30", "link": "http://arxiv.org/abs/2505.12728v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "VLC Fusion: Vision-Language Conditioned Sensor Fusion for Robust Object Detection", "abstract": "Although fusing multiple sensor modalities can enhance object detection\nperformance, existing fusion approaches often overlook subtle variations in\nenvironmental conditions and sensor inputs. As a result, they struggle to\nadaptively weight each modality under such variations. To address this\nchallenge, we introduce Vision-Language Conditioned Fusion (VLC Fusion), a\nnovel fusion framework that leverages a Vision-Language Model (VLM) to\ncondition the fusion process on nuanced environmental cues. By capturing\nhigh-level environmental context such as as darkness, rain, and camera\nblurring, the VLM guides the model to dynamically adjust modality weights based\non the current scene. We evaluate VLC Fusion on real-world autonomous driving\nand military target detection datasets that include image, LIDAR, and mid-wave\ninfrared modalities. Our experiments show that VLC Fusion consistently\noutperforms conventional fusion baselines, achieving improved detection\naccuracy in both seen and unseen scenarios.", "published": "2025-05-19 05:13:17", "link": "http://arxiv.org/abs/2505.12715v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "IA-MVS: Instance-Focused Adaptive Depth Sampling for Multi-View Stereo", "abstract": "Multi-view stereo (MVS) models based on progressive depth hypothesis\nnarrowing have made remarkable advancements. However, existing methods haven't\nfully utilized the potential that the depth coverage of individual instances is\nsmaller than that of the entire scene, which restricts further improvements in\ndepth estimation precision. Moreover, inevitable deviations in the initial\nstage accumulate as the process advances. In this paper, we propose\nInstance-Adaptive MVS (IA-MVS). It enhances the precision of depth estimation\nby narrowing the depth hypothesis range and conducting refinement on each\ninstance. Additionally, a filtering mechanism based on intra-instance depth\ncontinuity priors is incorporated to boost robustness. Furthermore, recognizing\nthat existing confidence estimation can degrade IA-MVS performance on point\nclouds. We have developed a detailed mathematical model for confidence\nestimation based on conditional probability. The proposed method can be widely\napplied in models based on MVSNet without imposing extra training burdens. Our\nmethod achieves state-of-the-art performance on the DTU benchmark. The source\ncode is available at https://github.com/KevinWang73106/IA-MVS.", "published": "2025-05-19 05:11:39", "link": "http://arxiv.org/abs/2505.12714v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Any-to-Any Learning in Computational Pathology via Triplet Multimodal Pretraining", "abstract": "Recent advances in computational pathology and artificial intelligence have\nsignificantly enhanced the utilization of gigapixel whole-slide images and and\nadditional modalities (e.g., genomics) for pathological diagnosis. Although\ndeep learning has demonstrated strong potential in pathology, several key\nchallenges persist: (1) fusing heterogeneous data types requires sophisticated\nstrategies beyond simple concatenation due to high computational costs; (2)\ncommon scenarios of missing modalities necessitate flexible strategies that\nallow the model to learn robustly in the absence of certain modalities; (3) the\ndownstream tasks in CPath are diverse, ranging from unimodal to multimodal,\ncnecessitating a unified model capable of handling all modalities. To address\nthese challenges, we propose ALTER, an any-to-any tri-modal pretraining\nframework that integrates WSIs, genomics, and pathology reports. The term \"any\"\nemphasizes ALTER's modality-adaptive design, enabling flexible pretraining with\nany subset of modalities, and its capacity to learn robust, cross-modal\nrepresentations beyond WSI-centric approaches. We evaluate ALTER across\nextensive clinical tasks including survival prediction, cancer subtyping, gene\nmutation prediction, and report generation, achieving superior or comparable\nperformance to state-of-the-art baselines.", "published": "2025-05-19 05:07:34", "link": "http://arxiv.org/abs/2505.12711v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "SpatialLLM: From Multi-modality Data to Urban Spatial Intelligence", "abstract": "We propose SpatialLLM, a novel approach advancing spatial intelligence tasks\nin complex urban scenes. Unlike previous methods requiring geographic analysis\ntools or domain expertise, SpatialLLM is a unified language model directly\naddressing various spatial intelligence tasks without any training,\nfine-tuning, or expert intervention. The core of SpatialLLM lies in\nconstructing detailed and structured scene descriptions from raw spatial data\nto prompt pre-trained LLMs for scene-based analysis. Extensive experiments show\nthat, with our designs, pretrained LLMs can accurately perceive spatial\ndistribution information and enable zero-shot execution of advanced spatial\nintelligence tasks, including urban planning, ecological analysis, traffic\nmanagement, etc. We argue that multi-field knowledge, context length, and\nreasoning ability are key factors influencing LLM performances in urban\nanalysis. We hope that SpatialLLM will provide a novel viable perspective for\nurban intelligent analysis and management. The code and dataset are available\nat https://github.com/WHU-USI3DV/SpatialLLM.", "published": "2025-05-19 04:53:41", "link": "http://arxiv.org/abs/2505.12703v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Long-RVOS: A Comprehensive Benchmark for Long-term Referring Video Object Segmentation", "abstract": "Referring video object segmentation (RVOS) aims to identify, track and\nsegment the objects in a video based on language descriptions, which has\nreceived great attention in recent years. However, existing datasets remain\nfocus on short video clips within several seconds, with salient objects visible\nin most frames. To advance the task towards more practical scenarios, we\nintroduce \\textbf{Long-RVOS}, a large-scale benchmark for long-term referring\nvideo object segmentation. Long-RVOS contains 2,000+ videos of an average\nduration exceeding 60 seconds, covering a variety of objects that undergo\nocclusion, disappearance-reappearance and shot changing. The objects are\nmanually annotated with three different types of descriptions to individually\nevaluate the understanding of static attributes, motion patterns and\nspatiotemporal relationships. Moreover, unlike previous benchmarks that rely\nsolely on the per-frame spatial evaluation, we introduce two new metrics to\nassess the temporal and spatiotemporal consistency. We benchmark 6\nstate-of-the-art methods on Long-RVOS. The results show that current approaches\nstruggle severely with the long-video challenges. To address this, we further\npropose ReferMo, a promising baseline method that integrates motion information\nto expand the temporal receptive field, and employs a local-to-global\narchitecture to capture both short-term dynamics and long-term dependencies.\nDespite simplicity, ReferMo achieves significant improvements over current\nmethods in long-term scenarios. We hope that Long-RVOS and our baseline can\ndrive future RVOS research towards tackling more realistic and long-form\nvideos.", "published": "2025-05-19 04:52:31", "link": "http://arxiv.org/abs/2505.12702v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TACOcc:Target-Adaptive Cross-Modal Fusion with Volume Rendering for 3D Semantic Occupancy", "abstract": "The performance of multi-modal 3D occupancy prediction is limited by\nineffective fusion, mainly due to geometry-semantics mismatch from fixed fusion\nstrategies and surface detail loss caused by sparse, noisy annotations. The\nmismatch stems from the heterogeneous scale and distribution of point cloud and\nimage features, leading to biased matching under fixed neighborhood fusion. To\naddress this, we propose a target-scale adaptive, bidirectional symmetric\nretrieval mechanism. It expands the neighborhood for large targets to enhance\ncontext awareness and shrinks it for small ones to improve efficiency and\nsuppress noise, enabling accurate cross-modal feature alignment. This mechanism\nexplicitly establishes spatial correspondences and improves fusion accuracy.\nFor surface detail loss, sparse labels provide limited supervision, resulting\nin poor predictions for small objects. We introduce an improved volume\nrendering pipeline based on 3D Gaussian Splatting, which takes fused features\nas input to render images, applies photometric consistency supervision, and\njointly optimizes 2D-3D consistency. This enhances surface detail\nreconstruction while suppressing noise propagation. In summary, we propose\nTACOcc, an adaptive multi-modal fusion framework for 3D semantic occupancy\nprediction, enhanced by volume rendering supervision. Experiments on the\nnuScenes and SemanticKITTI benchmarks validate its effectiveness.", "published": "2025-05-19 04:32:36", "link": "http://arxiv.org/abs/2505.12693v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Mamba-Adaptor: State Space Model Adaptor for Visual Recognition", "abstract": "Recent State Space Models (SSM), especially Mamba, have demonstrated\nimpressive performance in visual modeling and possess superior model\nefficiency. However, the application of Mamba to visual tasks suffers inferior\nperformance due to three main constraints existing in the sequential model: 1)\nCasual computing is incapable of accessing global context; 2) Long-range\nforgetting when computing the current hidden states; 3) Weak spatial structural\nmodeling due to the transformed sequential input. To address these issues, we\ninvestigate a simple yet powerful vision task Adaptor for Mamba models, which\nconsists of two functional modules: Adaptor-T and Adaptor-S. When solving the\nhidden states for SSM, we apply a lightweight prediction module Adaptor-T to\nselect a set of learnable locations as memory augmentations to ease long-range\nforgetting issues. Moreover, we leverage Adapator-S, composed of multi-scale\ndilated convolutional kernels, to enhance the spatial modeling and introduce\nthe image inductive bias into the feature output. Both modules can enlarge the\ncontext modeling in casual computing, as the output is enhanced by the\ninaccessible features. We explore three usages of Mamba-Adaptor: A general\nvisual backbone for various vision tasks; A booster module to raise the\nperformance of pretrained backbones; A highly efficient fine-tuning module that\nadapts the base model for transfer learning tasks. Extensive experiments verify\nthe effectiveness of Mamba-Adaptor in three settings. Notably, our\nMamba-Adaptor achieves state-of the-art performance on the ImageNet and COCO\nbenchmarks.", "published": "2025-05-19 04:14:33", "link": "http://arxiv.org/abs/2505.12685v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "On the Mechanisms of Adversarial Data Augmentation for Robust and Adaptive Transfer Learning", "abstract": "Transfer learning across domains with distribution shift remains a\nfundamental challenge in building robust and adaptable machine learning\nsystems. While adversarial perturbations are traditionally viewed as threats\nthat expose model vulnerabilities, recent studies suggest that they can also\nserve as constructive tools for data augmentation. In this work, we\nsystematically investigate the role of adversarial data augmentation (ADA) in\nenhancing both robustness and adaptivity in transfer learning settings. We\nanalyze how adversarial examples, when used strategically during training,\nimprove domain generalization by enriching decision boundaries and reducing\noverfitting to source-domain-specific features. We further propose a unified\nframework that integrates ADA with consistency regularization and\ndomain-invariant representation learning. Extensive experiments across multiple\nbenchmark datasets -- including VisDA, DomainNet, and Office-Home --\ndemonstrate that our method consistently improves target-domain performance\nunder both unsupervised and few-shot domain adaptation settings. Our results\nhighlight a constructive perspective of adversarial learning, transforming\nperturbation from a destructive attack into a regularizing force for\ncross-domain transferability.", "published": "2025-05-19 03:56:51", "link": "http://arxiv.org/abs/2505.12681v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "On expectations and variances in the hard-core model on bounded degree graphs", "abstract": "We extend the study of the occupancy fraction of the hard-core model in two\nnovel directions. One direction gives a tight lower bound in terms of\nindividual vertex degrees, extending work of Sah, Sawhney, Stoner and Zhao\nwhich bounds the partition function. The other bounds the variance of the size\nof an independent set drawn from the model, which is strictly stronger than\nbounding the occupancy fraction.\n  In the setting of triangle-free graphs, we make progress on a recent\nconjecture of Buys, van den Heuvel and Kang on extensions of Shearer's classic\nbounds on the independence number to the occupancy fraction of the hard-core\nmodel.\n  Sufficiently strong lower bounds on both the expectation and the variance in\ntriangle-free graphs have the potential to improve the known bounds on the\noff-diagonal Ramsey number $R(3,t)$, and to shed light on the algorithmic\nbarrier one observes for independent sets in sparse random graphs.", "published": "2025-05-19 17:34:23", "link": "http://arxiv.org/abs/2505.13396v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "A Necessary Condition for Connectedness of Solutions to Integer Linear Systems", "abstract": "An integer linear system is a set of inequalities with integer constraints.\nThe solution graph of an integer linear system is an undirected graph defined\non the set of feasible solutions to the integer linear system. In this graph, a\npair of feasible solutions is connected by an edge if the Hamming distance\nbetween them is one. In this paper, we consider a condition under which the\nsolution graph is connected for any right-hand side vector. First, we prove\nthat if the solution graph is connected for any right-hand side vector, then\nthe coefficient matrix of the system does not contain some forbidden pattern as\na submatrix. Next, we prove that if at least one of (i) the number of rows is\nat most 3, (ii) the number of columns is at most 2, (iii) the number of rows is\n4 and the number of columns is 3 holds, then the condition that the coefficient\nmatrix of the system does not contain the forbidden pattern is a sufficient\ncondition under which the solution graph is connected for any right-hand side\nvector. This result is stronger than a known necessary and sufficient condition\nsince the set of coefficient matrix dimensions is strictly larger.", "published": "2025-05-19 10:14:20", "link": "http://arxiv.org/abs/2505.12930v1", "categories": ["cs.DM", "math.CO"], "primary_category": "cs.DM"}
{"title": "Ergodic properties of concurrent systems", "abstract": "A concurrent system is defined as a monoid action of a trace monoid on a\nfinite set of states. Concurrent systems represent state models where the state\nis distributed and where state changes are local. Starting from a spectral\nproperty on the combinatorics of concurrent systems, we prove the existence and\nuniqueness of a Markov measure on the space of infinite trajectories relatively\nto any weight distributions. In turn, we obtain a combinatorial result by\nproving that the kernel of the associated M\\\"obius matrix has dimension 1; the\nM\\\"obius matrix extends in this context the M\\\"obius polynomial of a trace\nmonoid. We study ergodic properties of irreducible concurrent systems and we\nprove a Strong law of large numbers. It allows us to introduce the speedup as a\nmeasurement of the average amount of concurrency within infinite trajectories.\nExamples are studied.", "published": "2025-05-19 07:40:25", "link": "http://arxiv.org/abs/2505.12810v1", "categories": ["math.PR", "cs.DM", "math.GR"], "primary_category": "math.PR"}
{"title": "Independent Set Enumeration in King Graphs by Tensor Network Contractions", "abstract": "This paper discusses the enumeration of independent sets in king graphs of\nsize $m \\times n$, based on the tensor network contractions algorithm given in\nreference~\\cite{tilEnum}. We transform the problem into Wang tiling enumeration\nwithin an $(m+1) \\times (n+1)$ rectangle and compute the results for all cases\nwhere $m + n \\leq 79$ using tensor network contraction algorithm, and provided\nan approximation for larger $m, n$.\n  Using the same algorithm, we also enumerated independent sets with vertex\nnumber restrictions. Based on the results, we analyzed the vertex number that\nmaximize the enumeration for each pair $(m, n)$. Additionally, we compute the\ncorresponding weighted enumeration, where each independent set is weighted by\nthe number of its vertices (i.e., the total sum of vertices over all\nindependent sets). The approximations for larger $m, n$ are given as well.\n  Our results have added thousands of new items to the OEIS sequences A089980\nand A193580. In addition, the combinatorial problems above are closely related\nto the hard-core model in physics. We estimate some important constants based\non the existing results, and the relative error between our estimation of the\nentropy constant and the existing results is less than $10^{-9}$.", "published": "2025-05-19 07:04:14", "link": "http://arxiv.org/abs/2505.12776v1", "categories": ["math.CO", "cs.DM", "05C30 (Primary), 68R05 (Secondary)", "G.2.2; F.2.2"], "primary_category": "math.CO"}
{"title": "Optimizing Retrieval Augmented Generation for Object Constraint Language", "abstract": "The Object Constraint Language (OCL) is essential for defining precise\nconstraints within Model-Based Systems Engineering (MBSE). However, manually\nwriting OCL rules is complex and time-consuming. This study explores the\noptimization of Retrieval-Augmented Generation (RAG) for automating OCL rule\ngeneration, focusing on the impact of different retrieval strategies. We\nevaluate three retrieval approaches $\\unicode{x2013}$ BM25 (lexical-based),\nBERT-based (semantic retrieval), and SPLADE (sparse-vector retrieval)\n$\\unicode{x2013}$ analyzing their effectiveness in providing relevant context\nfor a large language model.\n  To further assess our approach, we compare and benchmark our\nretrieval-optimized generation results against PathOCL, a state-of-the-art\ngraph-based method. We directly compare BM25, BERT, and SPLADE retrieval\nmethods with PathOCL to understand how different retrieval methods perform for\na unified evaluation framework. Our experimental results, focusing on\nretrieval-augmented generation, indicate that while retrieval can enhance\ngeneration accuracy, its effectiveness depends on the retrieval method and the\nnumber of retrieved chunks (k). BM25 underperforms the baseline, whereas\nsemantic approaches (BERT and SPLADE) achieve better results, with SPLADE\nperforming best at lower k values. However, excessive retrieval with high k\nparameter can lead to retrieving irrelevant chunks which degrades model\nperformance. Our findings highlight the importance of optimizing retrieval\nconfigurations to balance context relevance and output consistency. This\nresearch provides insights into improving OCL rule generation using RAG and\nunderscores the need for tailoring retrieval.", "published": "2025-05-19 14:00:10", "link": "http://arxiv.org/abs/2505.13129v1", "categories": ["cs.IR", "cs.SE"], "primary_category": "cs.IR"}
{"title": "CPRet: A Dataset, Benchmark, and Model for Retrieval in Competitive Programming", "abstract": "Competitive programming benchmarks are widely used in scenarios such as\nprogramming contests and large language model assessments. However, the growing\npresence of duplicate or highly similar problems raises concerns not only about\ncompetition fairness, but also about the validity of competitive programming as\na benchmark for model evaluation. In this paper, we propose a new problem --\nsimilar question retrieval -- to address this issue. Due to the lack of both\ndata and models, solving this problem is challenging. To this end, we introduce\nCPRet, a retrieval-oriented benchmark suite for competitive programming,\ncovering four retrieval tasks: two code-centric (i.e., Text-to-Code and\nCode-to-Code) and two newly proposed problem-centric tasks (i.e.,\nProblem-to-Duplicate and Simplified-to-Full), built from a combination of\nautomatically crawled problem-solution data and manually curated annotations.\nOur contribution includes both high-quality training data and temporally\nseparated test sets for reliable evaluation. In addition, we develop two\ntask-specialized retrievers based on this dataset: CPRetriever-Code, trained\nwith a novel Group-InfoNCE loss for problem-code alignment, and\nCPRetriever-Prob, fine-tuned for identifying problem-level similarity. Both\nmodels achieve strong results and are open-sourced for local use. Finally, we\nanalyze LiveCodeBench and find that high-similarity problems inflate model pass\nrates and reduce differentiation, underscoring the need for similarity-aware\nevaluation in future benchmarks.\n  Code and data are available at: https://github.com/coldchair/CPRet", "published": "2025-05-19 10:07:51", "link": "http://arxiv.org/abs/2505.12925v1", "categories": ["cs.SE", "cs.AI", "cs.IR", "H.3.3"], "primary_category": "cs.SE"}
{"title": "Unlearning for Federated Online Learning to Rank: A Reproducibility Study", "abstract": "This paper reports on findings from a comparative study on the effectiveness\nand efficiency of federated unlearning strategies within Federated Online\nLearning to Rank (FOLTR), with specific attention to systematically analysing\nthe unlearning capabilities of methods in a verifiable manner.\n  Federated approaches to ranking of search results have recently garnered\nattention to address users privacy concerns. In FOLTR, privacy is safeguarded\nby collaboratively training ranking models across decentralized data sources,\npreserving individual user data while optimizing search results based on\nimplicit feedback, such as clicks.\n  Recent legislation introduced across numerous countries is establishing the\nso called \"the right to be forgotten\", according to which services based on\nmachine learning models like those in FOLTR should provide capabilities that\nallow users to remove their own data from those used to train models. This has\nsparked the development of unlearning methods, along with evaluation practices\nto measure whether unlearning of a user data successfully occurred. Current\nevaluation practices are however often controversial, necessitating the use of\nmultiple metrics for a more comprehensive assessment -- but previous proposals\nof unlearning methods only used single evaluation metrics.\n  This paper addresses this limitation: our study rigorously assesses the\neffectiveness of unlearning strategies in managing both under-unlearning and\nover-unlearning scenarios using adapted, and newly proposed evaluation metrics.\nThanks to our detailed analysis, we uncover the strengths and limitations of\nfive unlearning strategies, offering valuable insights into optimizing\nfederated unlearning to balance data privacy and system performance within\nFOLTR. We publicly release our code and complete results at\nhttps://github.com/Iris1026/Unlearning-for-FOLTR.git.", "published": "2025-05-19 07:23:46", "link": "http://arxiv.org/abs/2505.12791v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Towards A Generalist Code Embedding Model Based On Massive Data Synthesis", "abstract": "Code embedding models attract increasing attention due to the widespread\npopularity of retrieval-augmented generation (RAG) in software development.\nThese models are expected to capture the rich semantic relationships inherent\nto code, which differ significantly from those found in text. However, existing\nmodels remain severely limited due to the scarcity of high-quality training\ndata. In this work, we introduce \\textbf{CodeR} (\\underline{Code}\n\\underline{R}etrieval), a state-of-the-art embedding model for general-purpose\ncode retrieval. The superior performance of CodeR is built upon CodeR-Pile, a\nlarge-scale synthetic dataset constructed under the DRU (Diversity,\nReliability, Usability) principle via a novel data synthesis pipeline. To\noptimize training effectiveness, we propose Annealing, a curriculum learning\nstrategy that enables effective knowledge transfer across heterogeneous sources\nof data. We evaluate CodeR based on 16 diverse code retrieval tasks, where it\nsignificantly outperforms existing baselines and exhibits strong out-of-domain\ngeneralization performance. We have publicly released our code and the\nwell-trained model to facilitate further research in this critical area.\nhttps://github.com/FlagOpen/FlagEmbedding/tree/master/research/BGE_Coder.", "published": "2025-05-19 04:37:53", "link": "http://arxiv.org/abs/2505.12697v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "LLM-based Query Expansion Fails for Unfamiliar and Ambiguous Queries", "abstract": "Query expansion (QE) enhances retrieval by incorporating relevant terms, with\nlarge language models (LLMs) offering an effective alternative to traditional\nrule-based and statistical methods. However, LLM-based QE suffers from a\nfundamental limitation: it often fails to generate relevant knowledge,\ndegrading search performance. Prior studies have focused on hallucination, yet\nits underlying cause--LLM knowledge deficiencies--remains underexplored. This\npaper systematically examines two failure cases in LLM-based QE: (1) when the\nLLM lacks query knowledge, leading to incorrect expansions, and (2) when the\nquery is ambiguous, causing biased refinements that narrow search coverage. We\nconduct controlled experiments across multiple datasets, evaluating the effects\nof knowledge and query ambiguity on retrieval performance using sparse and\ndense retrieval models. Our results reveal that LLM-based QE can significantly\ndegrade the retrieval effectiveness when knowledge in the LLM is insufficient\nor query ambiguity is high. We introduce a framework for evaluating QE under\nthese conditions, providing insights into the limitations of LLM-based\nretrieval augmentation.", "published": "2025-05-19 04:33:09", "link": "http://arxiv.org/abs/2505.12694v1", "categories": ["cs.IR", "H.3.3"], "primary_category": "cs.IR"}
{"title": "Think Before You Attribute: Improving the Performance of LLMs Attribution Systems", "abstract": "Large Language Models (LLMs) are increasingly applied in various science\ndomains, yet their broader adoption remains constrained by a critical\nchallenge: the lack of trustworthy, verifiable outputs. Current LLMs often\ngenerate answers without reliable source attribution, or worse, with incorrect\nattributions, posing a barrier to their use in scientific and high-stakes\nsettings, where traceability and accountability are non-negotiable. To be\nreliable, attribution systems need high accuracy and retrieve data with short\nlengths, i.e., attribute to a sentence within a document rather than a whole\ndocument. We propose a sentence-level pre-attribution step for\nRetrieve-Augmented Generation (RAG) systems that classify sentences into three\ncategories: not attributable, attributable to a single quote, and attributable\nto multiple quotes. By separating sentences before attribution, a proper\nattribution method can be selected for the type of sentence, or the attribution\ncan be skipped altogether. Our results indicate that classifiers are\nwell-suited for this task. In this work, we propose a pre-attribution step to\nreduce the computational complexity of attribution, provide a clean version of\nthe HAGRID dataset, and provide an end-to-end attribution system that works out\nof the box.", "published": "2025-05-19 02:08:20", "link": "http://arxiv.org/abs/2505.12621v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Beyond-Diagonal RIS Prototype and Performance Evaluation", "abstract": "We present the first experimental prototype of a reflective beyond-diagonal\nreconfigurable intelligent surface (BD-RIS), i.e., a RIS with reconfigurable\ninter-element connections. Our BD-RIS consists of an antenna array whose ports\nare terminated by a tunable load network. The latter can terminate each antenna\nport with three distinct individual loads or connect it to an adjacent antenna\nport. Extensive performance evaluations in a rich-scattering environment\nvalidate that inter-element connections are beneficial. Moreover, we observe\nthat our tunable load network's mentioned hardware constraints significantly\ninfluence, first, the achievable performance, second, the benefits of having\ninter-element connections, and, third, the importance of mutual-coupling\nawareness during optimization.", "published": "2025-05-19 17:32:48", "link": "http://arxiv.org/abs/2505.13392v1", "categories": ["eess.SP", "cs.IT", "math.IT", "physics.app-ph"], "primary_category": "eess.SP"}
{"title": "Neural-Enhanced Rate Adaptation and Computation Distribution for Emerging mmWave Multi-User 3D Video Streaming Systems", "abstract": "We investigate multitask edge-user communication-computation resource\nallocation for $360^\\circ$ video streaming in an edge-computing enabled\nmillimeter wave (mmWave) multi-user virtual reality system. To balance the\ncommunication-computation trade-offs that arise herein, we formulate a video\nquality maximization problem that integrates interdependent\nmultitask/multi-user action spaces and rebuffering time/quality variation\nconstraints. We formulate a deep reinforcement learning framework for\n\\underline{m}ulti-\\underline{t}ask \\underline{r}ate adaptation and\n\\underline{c}omputation distribution (MTRC) to solve the problem of interest.\nOur solution does not rely on a priori knowledge about the environment and uses\nonly prior video streaming statistics (e.g., throughput, decoding time, and\ntransmission delay), and content information, to adjust the assigned video\nbitrates and computation distribution, as it observes the induced streaming\nperformance online. Moreover, to capture the task interdependence in the\nenvironment, we leverage neural network cascades to extend our MTRC method to\ntwo novel variants denoted as R1C2 and C1R2. We train all three methods with\nreal-world mmWave network traces and $360^\\circ$ video datasets to evaluate\ntheir performance in terms of expected quality of experience (QoE), viewport\npeak signal-to-noise ratio (PSNR), rebuffering time, and quality variation. We\noutperform state-of-the-art rate adaptation algorithms, with C1R2 showing best\nresults and achieving $5.21-6.06$ dB PSNR gains, $2.18-2.70$x rebuffering time\nreduction, and $4.14-4.50$ dB quality variation reduction.", "published": "2025-05-19 16:45:30", "link": "http://arxiv.org/abs/2505.13337v1", "categories": ["cs.IT", "cs.ET", "cs.MM", "cs.SY", "eess.SY", "math.IT"], "primary_category": "cs.IT"}
{"title": "High-Rate Nested-Lattice Quantized Matrix Multiplication with Small Lookup Tables", "abstract": "Recent work have shown that the quantization for matrix multiplication\nproblem can be optimally solved by quantizing each column in each matrix using\na nested lattice code, and then multiplying the de-quantized matrices. It was\nfurther demonstrated that when product codes of sub-dimension $d$ and rate $R$\nare used, the de-quantization and inner product operations can be implemented\nwith querying a lookup table (LUT) of size $2^{2dR}$, but this is only useful\nwhen $dR$ is sufficiently small. This in turn limits LUT-based inner product\ndecoding to low-rate quantizers. In this work, we develop a rate $R$\nhierarchical nested lattice quantization framework, which quantizes each vector\nto $M$ layers, and admits LUT-based inner product decoding using an LUT of size\n$2^{2d\\frac{R}{M}}$, allowing for high-rate quantization. We provide analytic\nbounds on the loss of the developed scheme compared to standard nested lattice\nquantizers, and also numerically illustrate that this loss is negligible. Thus,\nour scheme enables to use small LUTs without compromising the overall\ndistortion.", "published": "2025-05-19 14:22:30", "link": "http://arxiv.org/abs/2505.13164v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Unifying concepts in information-theoretic time-series analysis", "abstract": "Information theory is a powerful framework for quantifying complexity,\nuncertainty, and dynamical structure in time-series data, with widespread\napplicability across disciplines such as physics, finance, and neuroscience.\nHowever, the literature on these measures remains fragmented, with\ndomain-specific terminologies, inconsistent mathematical notation, and\ndisparate visualization conventions that hinder interdisciplinary integration.\nThis work addresses these challenges by unifying key information-theoretic\ntime-series measures through shared semantic definitions, standardized\nmathematical notation, and cohesive visual representations. We compare these\nmeasures in terms of their theoretical foundations, computational formulations,\nand practical interpretability -- mapping them onto a common conceptual space\nthrough an illustrative case study with functional magnetic resonance imaging\ntime series in the brain. This case study exemplifies the complementary\ninsights these measures offer in characterizing the dynamics of complex neural\nsystems, such as signal complexity and information flow. By providing a\nstructured synthesis, our work aims to enhance interdisciplinary dialogue and\nmethodological adoption, which is particularly critical for reproducibility and\ninteroperability in computational neuroscience. More broadly, our framework\nserves as a resource for researchers seeking to navigate and apply\ninformation-theoretic time-series measures to diverse complex systems.", "published": "2025-05-19 13:13:30", "link": "http://arxiv.org/abs/2505.13080v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Leveraging Large Reconfigurable Intelligent Surfaces as Anchors for Near-Field Positioning", "abstract": "In this work, we present a recent investigation on leveraging large\nreconfigurable intelligent surfaces (RIS) as anchors for positioning in\nwireless communication systems. Unlike existing approaches, we explicitly\naddress the uncertainty arising from the substantial physical size of the RIS,\nparticularly relevant when a user equipment resides in the near field, and\npropose a method that ensures accurate positioning under these conditions. We\nderive the corresponding Cramer-Rao bound for our scheme and validate the\neffectiveness of our scheme through numerical experiments, highlighting both\nthe feasibility and potential of our approach.", "published": "2025-05-19 05:37:01", "link": "http://arxiv.org/abs/2505.12730v1", "categories": ["cs.ET", "cs.IT", "math.IT"], "primary_category": "cs.ET"}
{"title": "Unlocking Non-Invasive Brain-to-Text", "abstract": "Despite major advances in surgical brain-to-text (B2T), i.e. transcribing\nspeech from invasive brain recordings, non-invasive alternatives have yet to\nsurpass even chance on standard metrics. This remains a barrier to building a\nnon-invasive brain-computer interface (BCI) capable of restoring communication\nin paralysed individuals without surgery. Here, we present the first\nnon-invasive B2T result that significantly exceeds these critical baselines,\nraising BLEU by $1.4\\mathrm{-}2.6\\times$ over prior work. This result is driven\nby three contributions: (1) we extend recent word-classification models with\nLLM-based rescoring, transforming single-word predictors into closed-vocabulary\nB2T systems; (2) we introduce a predictive in-filling approach to handle\nout-of-vocabulary (OOV) words, substantially expanding the effective\nvocabulary; and (3) we demonstrate, for the first time, how to scale\nnon-invasive B2T models across datasets, unlocking deep learning at scale and\nimproving accuracy by $2.1\\mathrm{-}2.3\\times$. Through these contributions, we\noffer new insights into the roles of data quality and vocabulary size.\nTogether, our results remove a major obstacle to realising practical\nnon-invasive B2T systems.", "published": "2025-05-19 17:59:35", "link": "http://arxiv.org/abs/2505.13446v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Synthetic-Powered Predictive Inference", "abstract": "Conformal prediction is a framework for predictive inference with a\ndistribution-free, finite-sample guarantee. However, it tends to provide\nuninformative prediction sets when calibration data are scarce. This paper\nintroduces Synthetic-powered predictive inference (SPPI), a novel framework\nthat incorporates synthetic data -- e.g., from a generative model -- to improve\nsample efficiency. At the core of our method is a score transporter: an\nempirical quantile mapping that aligns nonconformity scores from trusted, real\ndata with those from synthetic data. By carefully integrating the score\ntransporter into the calibration process, SPPI provably achieves finite-sample\ncoverage guarantees without making any assumptions about the real and synthetic\ndata distributions. When the score distributions are well aligned, SPPI yields\nsubstantially tighter and more informative prediction sets than standard\nconformal prediction. Experiments on image classification and tabular\nregression demonstrate notable improvements in predictive efficiency in\ndata-scarce settings.", "published": "2025-05-19 17:55:56", "link": "http://arxiv.org/abs/2505.13432v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Machine learning the first stage in 2SLS: Practical guidance from bias decomposition and simulation", "abstract": "Machine learning (ML) primarily evolved to solve \"prediction problems.\" The\nfirst stage of two-stage least squares (2SLS) is a prediction problem,\nsuggesting potential gains from ML first-stage assistance. However, little\nguidance exists on when ML helps 2SLS$\\unicode{x2014}$or when it hurts. We\ninvestigate the implications of inserting ML into 2SLS, decomposing the bias\ninto three informative components. Mechanically, ML-in-2SLS procedures face\nissues common to prediction and causal-inference settings$\\unicode{x2014}$and\ntheir interaction. Through simulation, we show linear ML methods (e.g.,\npost-Lasso) work well, while nonlinear methods (e.g., random forests, neural\nnets) generate substantial bias in second-stage\nestimates$\\unicode{x2014}$potentially exceeding the bias of endogenous OLS.", "published": "2025-05-19 17:53:15", "link": "http://arxiv.org/abs/2505.13422v1", "categories": ["econ.EM", "cs.LG", "stat.AP", "stat.ML"], "primary_category": "econ.EM"}
{"title": "Make Still Further Progress: Chain of Thoughts for Tabular Data Leaderboard", "abstract": "Tabular data, a fundamental data format in machine learning, is predominantly\nutilized in competitions and real-world applications. The performance of\ntabular models--such as gradient boosted decision trees and neural\nnetworks--can vary significantly across datasets due to differences in feature\ndistributions and task characteristics. Achieving top performance on each\ndataset often requires specialized expert knowledge. To address this\nvariability, practitioners often aggregate the predictions of multiple models.\nHowever, conventional aggregation strategies typically rely on static\ncombination rules and lack instance-level adaptability. In this work, we\npropose an in-context ensemble framework for tabular prediction that leverages\nlarge language models (LLMs) to perform dynamic, instance-specific integration\nof external model predictions. Without access to raw tabular features or\nsemantic information, our method constructs a context around each test instance\nusing its nearest neighbors and the predictions from a pool of external models.\nWithin this enriched context, we introduce Chain of Tabular Thoughts (CoT$^2$),\na prompting strategy that guides LLMs through multi-step, interpretable\nreasoning, making still further progress toward expert-level decision-making.\nExperimental results show that our method outperforms well-tuned baselines and\nstandard ensemble techniques across a wide range of tabular datasets.", "published": "2025-05-19 17:52:58", "link": "http://arxiv.org/abs/2505.13421v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Gluon: Making Muon & Scion Great Again! (Bridging Theory and Practice of LMO-based Optimizers for LLMs)", "abstract": "Recent developments in deep learning optimization have brought about\nradically new algorithms based on the Linear Minimization Oracle (LMO)\nframework, such as $\\sf Muon$ and $\\sf Scion$. After over a decade of $\\sf\nAdam$'s dominance, these LMO-based methods are emerging as viable replacements,\noffering several practical advantages such as improved memory efficiency,\nbetter hyperparameter transferability, and most importantly, superior empirical\nperformance on large-scale tasks, including LLM training. However, a\nsignificant gap remains between their practical use and our current theoretical\nunderstanding: prior analyses (1) overlook the layer-wise LMO application of\nthese optimizers in practice, and (2) rely on an unrealistic smoothness\nassumption, leading to impractically small stepsizes. To address both, we\npropose a new LMO-based method called $\\sf Gluon$, capturing prior\ntheoretically analyzed methods as special cases, and introduce a new refined\ngeneralized smoothness model that captures the layer-wise geometry of neural\nnetworks, matches the layer-wise practical implementation of $\\sf Muon$ and\n$\\sf Scion$, and leads to convergence guarantees with strong practical\npredictive power. Unlike prior results, our theoretical stepsizes closely match\nthe fine-tuned values reported by Pethick et al. (2025). Our experiments with\nNanoGPT and CNN confirm that our assumption holds along the optimization\ntrajectory, ultimately closing the gap between theory and practice.", "published": "2025-05-19 17:50:45", "link": "http://arxiv.org/abs/2505.13416v1", "categories": ["cs.LG", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Joint Velocity-Growth Flow Matching for Single-Cell Dynamics Modeling", "abstract": "Learning the underlying dynamics of single cells from snapshot data has\ngained increasing attention in scientific and machine learning research. The\ndestructive measurement technique and cell proliferation/death result in\nunpaired and unbalanced data between snapshots, making the learning of the\nunderlying dynamics challenging. In this paper, we propose joint\nVelocity-Growth Flow Matching (VGFM), a novel paradigm that jointly learns\nstate transition and mass growth of single-cell populations via flow matching.\nVGFM builds an ideal single-cell dynamics containing velocity of state and\ngrowth of mass, driven by a presented two-period dynamic understanding of the\nstatic semi-relaxed optimal transport, a mathematical tool that seeks the\ncoupling between unpaired and unbalanced data. To enable practical usage, we\napproximate the ideal dynamics using neural networks, forming our joint\nvelocity and growth matching framework. A distribution fitting loss is also\nemployed in VGFM to further improve the fitting performance for snapshot data.\nExtensive experimental results on both synthetic and real datasets demonstrate\nthat VGFM can capture the underlying biological dynamics accounting for mass\nand state variations over time, outperforming existing approaches for\nsingle-cell dynamics modeling.", "published": "2025-05-19 17:48:04", "link": "http://arxiv.org/abs/2505.13413v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Dataless Reinforcement Learning Approach to Rounding Hyperplane Optimization for Max-Cut", "abstract": "The Maximum Cut (MaxCut) problem is NP-Complete, and obtaining its optimal\nsolution is NP-hard in the worst case. As a result, heuristic-based algorithms\nare commonly used, though their design often requires significant domain\nexpertise. More recently, learning-based methods trained on large (un)labeled\ndatasets have been proposed; however, these approaches often struggle with\ngeneralizability and scalability. A well-known approximation algorithm for\nMaxCut is the Goemans-Williamson (GW) algorithm, which relaxes the Quadratic\nUnconstrained Binary Optimization (QUBO) formulation into a semidefinite\nprogram (SDP). The GW algorithm then applies hyperplane rounding by uniformly\nsampling a random hyperplane to convert the SDP solution into binary node\nassignments. In this paper, we propose a training-data-free approach based on a\nnon-episodic reinforcement learning formulation, in which an agent learns to\nselect improved rounding hyperplanes that yield better cuts than those produced\nby the GW algorithm. By optimizing over a Markov Decision Process (MDP), our\nmethod consistently achieves better cuts across large-scale graphs with varying\ndensities and degree distributions.", "published": "2025-05-19 17:41:10", "link": "http://arxiv.org/abs/2505.13405v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Learning by solving differential equations", "abstract": "Modern deep learning algorithms use variations of gradient descent as their\nmain learning methods. Gradient descent can be understood as the simplest\nOrdinary Differential Equation (ODE) solver; namely, the Euler method applied\nto the gradient flow differential equation. Since Euler, many ODE solvers have\nbeen devised that follow the gradient flow equation more precisely and more\nstably. Runge-Kutta (RK) methods provide a family of very powerful explicit and\nimplicit high-order ODE solvers. However, these higher-order solvers have not\nfound wide application in deep learning so far. In this work, we evaluate the\nperformance of higher-order RK solvers when applied in deep learning, study\ntheir limitations, and propose ways to overcome these drawbacks. In particular,\nwe explore how to improve their performance by naturally incorporating key\ningredients of modern neural network optimizers such as preconditioning,\nadaptive learning rates, and momentum.", "published": "2025-05-19 17:34:32", "link": "http://arxiv.org/abs/2505.13397v1", "categories": ["cs.LG", "cs.NA", "math.NA", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Restoration Score Distillation: From Corrupted Diffusion Pretraining to One-Step High-Quality Generation", "abstract": "Learning generative models from corrupted data is a fundamental yet\npersistently challenging task across scientific disciplines, particularly when\naccess to clean data is limited or expensive. Denoising Score Distillation\n(DSD) \\cite{chen2025denoising} recently introduced a novel and surprisingly\neffective strategy that leverages score distillation to train high-fidelity\ngenerative models directly from noisy observations. Building upon this\nfoundation, we propose \\textit{Restoration Score Distillation} (RSD), a\nprincipled generalization of DSD that accommodates a broader range of\ncorruption types, such as blurred, incomplete, or low-resolution images. RSD\noperates by first pretraining a teacher diffusion model solely on corrupted\ndata and subsequently distilling it into a single-step generator that produces\nhigh-quality reconstructions. Empirically, RSD consistently surpasses its\nteacher model across diverse restoration tasks on both natural and scientific\ndatasets. Moreover, beyond standard diffusion objectives, the RSD framework is\ncompatible with several corruption-aware training techniques such as Ambient\nTweedie, Ambient Diffusion, and its Fourier-space variant, enabling flexible\nintegration with recent advances in diffusion modeling. Theoretically, we\ndemonstrate that in a linear regime, RSD recovers the eigenspace of the clean\ndata covariance matrix from linear measurements, thereby serving as an implicit\nregularizer. This interpretation recasts score distillation not only as a\nsampling acceleration technique but as a principled approach to enhancing\ngenerative performance in severely degraded data regimes.", "published": "2025-05-19 17:21:03", "link": "http://arxiv.org/abs/2505.13377v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Minimum-Excess-Work Guidance", "abstract": "We propose a regularization framework inspired by thermodynamic work for\nguiding pre-trained probability flow generative models (e.g., continuous\nnormalizing flows or diffusion models) by minimizing excess work, a concept\nrooted in statistical mechanics and with strong conceptual connections to\noptimal transport. Our approach enables efficient guidance in sparse-data\nregimes common to scientific applications, where only limited target samples or\npartial density constraints are available. We introduce two strategies: Path\nGuidance for sampling rare transition states by concentrating probability mass\non user-defined subsets, and Observable Guidance for aligning generated\ndistributions with experimental observables while preserving entropy. We\ndemonstrate the framework's versatility on a coarse-grained protein model,\nguiding it to sample transition configurations between folded/unfolded states\nand correct systematic biases using experimental data. The method bridges\nthermodynamic principles with modern generative architectures, offering a\nprincipled, efficient, and physics-inspired alternative to standard fine-tuning\nin data-scarce domains. Empirical results highlight improved sample efficiency\nand bias reduction, underscoring its applicability to molecular simulations and\nbeyond.", "published": "2025-05-19 17:19:43", "link": "http://arxiv.org/abs/2505.13375v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Introducing Instruction-Accurate Simulators for Performance Estimation of Autotuning Workloads", "abstract": "Accelerating Machine Learning (ML) workloads requires efficient methods due\nto their large optimization space. Autotuning has emerged as an effective\napproach for systematically evaluating variations of implementations.\nTraditionally, autotuning requires the workloads to be executed on the target\nhardware (HW). We present an interface that allows executing autotuning\nworkloads on simulators. This approach offers high scalability when the\navailability of the target HW is limited, as many simulations can be run in\nparallel on any accessible HW. Additionally, we evaluate the feasibility of\nusing fast instruction-accurate simulators for autotuning. We train various\npredictors to forecast the performance of ML workload implementations on the\ntarget HW based on simulation statistics. Our results demonstrate that the\ntuned predictors are highly effective. The best workload implementation in\nterms of actual run time on the target HW is always within the top 3 % of\npredictions for the tested x86, ARM, and RISC-V-based architectures. In the\nbest case, this approach outperforms native execution on the target HW for\nembedded architectures when running as few as three samples on three simulators\nin parallel.", "published": "2025-05-19 16:59:07", "link": "http://arxiv.org/abs/2505.13357v1", "categories": ["cs.AR", "cs.LG"], "primary_category": "cs.AR"}
{"title": "Occult: Optimizing Collaborative Communication across Experts for Accelerated Parallel MoE Training and Inference", "abstract": "Mixture-of-experts (MoE) architectures could achieve impressive computational\nefficiency with expert parallelism, which relies heavily on all-to-all\ncommunication across devices. Unfortunately, such communication overhead\ntypically constitutes a significant portion of the total runtime, hampering the\nscalability of distributed training and inference for modern MoE models\n(consuming over $40\\%$ runtime in large-scale training). In this paper, we\nfirst define collaborative communication to illustrate this intrinsic\nlimitation, and then propose system- and algorithm-level innovations to reduce\ncommunication costs. Specifically, given a pair of experts co-activated by one\ntoken, we call them \"collaborated\", which comprises $2$ cases as intra- and\ninter-collaboration, depending on whether they are kept on the same device. Our\npilot investigations reveal that augmenting the proportion of\nintra-collaboration can accelerate expert parallelism at scale. It motivates us\nto strategically optimize collaborative communication for accelerated MoE\ntraining and inference, dubbed Occult. Our designs are capable of either\ndelivering exact results with reduced communication cost or controllably\nminimizing the cost with collaboration pruning, materialized by modified\nfine-tuning. Comprehensive experiments on various MoE-LLMs demonstrate that\nOccult can be faster than popular state-of-the-art inference or training\nframeworks (more than $1.5\\times$ speed up across multiple tasks and models)\nwith comparable or superior quality compared to the standard fine-tuning. Code\nis available at\n$\\href{https://github.com/UNITES-Lab/Occult}{https://github.com/UNITES-Lab/Occult}$.", "published": "2025-05-19 16:50:27", "link": "http://arxiv.org/abs/2505.13345v1", "categories": ["cs.LG", "cs.DC"], "primary_category": "cs.LG"}
{"title": "MRM3: Machine Readable ML Model Metadata", "abstract": "As the complexity and number of machine learning (ML) models grows,\nwell-documented ML models are essential for developers and companies to use or\nadapt them to their specific use cases. Model metadata, already present in\nunstructured format as model cards in online repositories such as Hugging Face,\ncould be more structured and machine readable while also incorporating\nenvironmental impact metrics such as energy consumption and carbon footprint.\nOur work extends the existing State of the Art by defining a structured schema\nfor ML model metadata focusing on machine-readable format and support for\nintegration into a knowledge graph (KG) for better organization and querying,\nenabling a wider set of use cases. Furthermore, we present an example wireless\nlocalization model metadata dataset consisting of 22 models trained on 4\ndatasets, integrated into a Neo4j-based KG with 113 nodes and 199 relations.", "published": "2025-05-19 16:50:00", "link": "http://arxiv.org/abs/2505.13343v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Detect and Correct: A Selective Noise Correction Method for Learning with Noisy Labels", "abstract": "Falsely annotated samples, also known as noisy labels, can significantly harm\nthe performance of deep learning models. Two main approaches for learning with\nnoisy labels are global noise estimation and data filtering. Global noise\nestimation approximates the noise across the entire dataset using a noise\ntransition matrix, but it can unnecessarily adjust correct labels, leaving room\nfor local improvements. Data filtering, on the other hand, discards potentially\nnoisy samples but risks losing valuable data. Our method identifies potentially\nnoisy samples based on their loss distribution. We then apply a selection\nprocess to separate noisy and clean samples and learn a noise transition matrix\nto correct the loss for noisy samples while leaving the clean data unaffected,\nthereby improving the training process. Our approach ensures robust learning\nand enhanced model performance by preserving valuable information from noisy\nsamples and refining the correction process. We applied our method to standard\nimage datasets (MNIST, CIFAR-10, and CIFAR-100) and a biological scRNA-seq\ncell-type annotation dataset. We observed a significant improvement in model\naccuracy and robustness compared to traditional methods.", "published": "2025-05-19 16:49:27", "link": "http://arxiv.org/abs/2505.13342v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Measuring Social Influence with Networked Synthetic Control", "abstract": "Measuring social influence is difficult due to the lack of counter-factuals\nand comparisons. By combining machine learning-based modeling and network\nscience, we present general properties of social value, a recent measure for\nsocial influence using synthetic control applicable to political behavior.\nSocial value diverges from centrality measures on in that it relies on an\nexternal regressor to predict an output variable of interest, generates a\nsynthetic measure of influence, then distributes individual contribution based\non a social network. Through theoretical derivations, we show the properties of\nSV under linear regression with and without interaction, across lattice\nnetworks, power-law networks, and random graphs. A reduction in computation can\nbe achieved for any ensemble model. Through simulation, we find that the\ngeneralized friendship paradox holds -- that in certain situations, your\nfriends have on average more influence than you do.", "published": "2025-05-19 16:44:46", "link": "http://arxiv.org/abs/2505.13334v1", "categories": ["cs.SI", "cs.LG"], "primary_category": "cs.SI"}
{"title": "Thinking Short and Right Over Thinking Long: Serving LLM Reasoning Efficiently and Accurately", "abstract": "Recent advances in test-time scaling suggest that Large Language Models\n(LLMs) can gain better capabilities by generating Chain-of-Thought reasoning\n(analogous to human thinking) to respond a given request, and meanwhile\nexploring more reasoning branches (i.e., generating multiple responses and\nensembling them) can improve the final output quality. However, when\nincorporating the two scaling dimensions, we find that the system efficiency is\ndampened significantly for two reasons. Firstly, the time cost to generate the\nfinal output increases substantially as many reasoning branches would be\ntrapped in the over-thinking dilemma, producing excessively long responses.\nSecondly, generating multiple reasoning branches for each request increases\nmemory consumption, which is unsuitable for LLM serving since we can only batch\na limited number of requests to process simultaneously. To address this, we\npresent SART, a serving framework for efficient and accurate LLM reasoning. The\nessential idea is to manage the thinking to be short and right, rather than\nlong. For one thing, we devise a redundant sampling with early stopping\napproach based on empirical observations and theoretic analysis, which\nincreases the likelihood of obtaining short-thinking responses when sampling\nreasoning branches. For another, we propose to dynamically prune low-quality\nbranches so that only right-thinking branches are maintained, reducing the\nmemory consumption and allowing us to batch more requests. Experimental results\ndemonstrate that SART not only improves the accuracy of LLM reasoning but also\nenhances the serving efficiency, outperforming existing methods by up to 28.2\ntimes and on average 15.7 times in terms of efficiency when achieving the same\nlevel of accuracy.", "published": "2025-05-19 16:34:56", "link": "http://arxiv.org/abs/2505.13326v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Unlabeled Data or Pre-trained Model: Rethinking Semi-Supervised Learning and Pretrain-Finetuning", "abstract": "Semi-supervised learning (SSL) alleviates the cost of data labeling process\nby exploiting unlabeled data, and has achieved promising results on various\ntasks such as image classification. Meanwhile, the Pretrain-Finetuning paradigm\nhas garnered significant attention in recent years, and exploiting pre-trained\nmodels could also reduce the requirement of labeled data in downstream tasks.\nTherefore, a question naturally occurs: \\emph{When the labeled data is scarce\nin the target tasks, should we exploit unlabeled data or pre-trained models?}\nTo answer this question, we select pre-trained Vision-Language Models (VLMs) as\nrepresentative pretrain-finetuning instances and propose \\textit{Few-shot SSL}\n-- a framework that enables fair comparison between these two paradigms by\ncontrolling the amount of labeled data used. Extensive experiments across\nvarious settings demonstrate that pre-trained VLMs generally outperform SSL\nmethods in nearly all cases, except when the data has low resolution or lacks\nclear semantic structure. Therefore, we encourage future SSL research to\ncompare with pre-trained models and explore deeper integration, such as using\npre-trained knowledge to enhance pseudo-labeling. To support future research,\nwe release our unified reproduction and evaluation framework. Codes are\navailable at\nhttps://anonymous.4open.science/r/Rethinking-SSL-and-Pretrain-Finetuning-5566", "published": "2025-05-19 16:29:20", "link": "http://arxiv.org/abs/2505.13317v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Smoothed SGD for quantiles: Bahadur representation and Gaussian approximation", "abstract": "This paper considers the estimation of quantiles via a smoothed version of\nthe stochastic gradient descent (SGD) algorithm. By smoothing the score\nfunction in the conventional SGD quantile algorithm, we achieve monotonicity in\nthe quantile level in that the estimated quantile curves do not cross. We\nderive non-asymptotic tail probability bounds for the smoothed SGD quantile\nestimate both for the case with and without Polyak-Ruppert averaging. For the\nlatter, we also provide a uniform Bahadur representation and a resulting\nGaussian approximation result. Numerical studies show good finite sample\nbehavior for our theoretical results.", "published": "2025-05-19 16:19:44", "link": "http://arxiv.org/abs/2505.13299v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Neural Functional: Learning Function to Scalar Maps for Neural PDE Surrogates", "abstract": "Many architectures for neural PDE surrogates have been proposed in recent\nyears, largely based on neural networks or operator learning. In this work, we\nderive and propose a new architecture, the Neural Functional, which learns\nfunction to scalar mappings. Its implementation leverages insights from\noperator learning and neural fields, and we show the ability of neural\nfunctionals to implicitly learn functional derivatives. For the first time,\nthis allows for an extension of Hamiltonian mechanics to neural PDE surrogates\nby learning the Hamiltonian functional and optimizing its functional\nderivatives. We demonstrate that the Hamiltonian Neural Functional can be an\neffective surrogate model through improved stability and conserving energy-like\nquantities on 1D and 2D PDEs. Beyond PDEs, functionals are prevalent in\nphysics; functional approximation and learning with its gradients may find\nother uses, such as in molecular dynamics or design optimization.", "published": "2025-05-19 15:55:38", "link": "http://arxiv.org/abs/2505.13275v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "RN-F: A Novel Approach for Mitigating Contaminated Data in Large Language Models", "abstract": "Large Language Models (LLMs) have become foundational in modern artificial\nintelligence, powering a wide range of applications from code generation and\nvirtual assistants to scientific research and enterprise automation. However,\nconcerns about data contamination--where test data overlaps with training\ndata--have raised serious questions about the reliability of these\napplications. Despite awareness of this issue, existing methods fall short in\neffectively identifying or mitigating contamination. In this paper, we propose\nResidual-Noise Fingerprinting (RN-F), a novel framework for detecting\ncontaminated data in LLMs. RN-F is a single-pass, gradient-free detection\nmethod that leverages residual signal patterns without introducing additional\nfloating-point operations. Our approach is lightweight, model-agnostic, and\nefficient. We evaluate RN-F on multiple LLMs across various contaminated\ndatasets and show that it consistently outperforms existing state-of-the-art\nmethods, achieving performance improvements of up to 10.5% in contamination\ndetection metrics.", "published": "2025-05-19 15:32:49", "link": "http://arxiv.org/abs/2505.13249v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Conformalized Decision Risk Assessment", "abstract": "High-stakes decisions in domains such as healthcare, energy, and public\npolicy are often made by human experts using domain knowledge and heuristics,\nyet are increasingly supported by predictive and optimization-based tools. A\ndominant approach in operations research is the predict-then-optimize paradigm,\nwhere a predictive model estimates uncertain inputs, and an optimization model\nrecommends a decision. However, this approach often lacks interpretability and\ncan fail under distributional uncertainty -- particularly when the outcome\ndistribution is multi-modal or complex -- leading to brittle or misleading\ndecisions. In this paper, we introduce CREDO, a novel framework that\nquantifies, for any candidate decision, a distribution-free upper bound on the\nprobability that the decision is suboptimal. By combining inverse optimization\ngeometry with conformal prediction and generative modeling, CREDO produces risk\ncertificates that are both statistically rigorous and practically\ninterpretable. This framework enables human decision-makers to audit and\nvalidate their own decisions under uncertainty, bridging the gap between\nalgorithmic tools and real-world judgment.", "published": "2025-05-19 15:24:38", "link": "http://arxiv.org/abs/2505.13243v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Reconstructing Physics-Informed Machine Learning for Traffic Flow Modeling: a Multi-Gradient Descent and Pareto Learning Approach", "abstract": "Physics-informed machine learning (PIML) is crucial in modern traffic flow\nmodeling because it combines the benefits of both physics-based and data-driven\napproaches. In conventional PIML, physical information is typically\nincorporated by constructing a hybrid loss function that combines data-driven\nloss and physics loss through linear scalarization. The goal is to find a\ntrade-off between these two objectives to improve the accuracy of model\npredictions. However, from a mathematical perspective, linear scalarization is\nlimited to identifying only the convex region of the Pareto front, as it treats\ndata-driven and physics losses as separate objectives. Given that most PIML\nloss functions are non-convex, linear scalarization restricts the achievable\ntrade-off solutions. Moreover, tuning the weighting coefficients for the two\nloss components can be both time-consuming and computationally challenging. To\naddress these limitations, this paper introduces a paradigm shift in PIML by\nreformulating the training process as a multi-objective optimization problem,\ntreating data-driven loss and physics loss independently. We apply several\nmulti-gradient descent algorithms (MGDAs), including traditional multi-gradient\ndescent (TMGD) and dual cone gradient descent (DCGD), to explore the Pareto\nfront in this multi-objective setting. These methods are evaluated on both\nmacroscopic and microscopic traffic flow models. In the macroscopic case, MGDAs\nachieved comparable performance to traditional linear scalarization methods.\nNotably, in the microscopic case, MGDAs significantly outperformed their\nscalarization-based counterparts, demonstrating the advantages of a\nmulti-objective optimization approach in complex PIML scenarios.", "published": "2025-05-19 15:23:24", "link": "http://arxiv.org/abs/2505.13241v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Investigating Active Sampling for Hardness Classification with Vision-Based Tactile Sensors", "abstract": "One of the most important object properties that humans and robots perceive\nthrough touch is hardness. This paper investigates information-theoretic active\nsampling strategies for sample-efficient hardness classification with\nvision-based tactile sensors. We evaluate three probabilistic classifier models\nand two model-uncertainty-based sampling strategies on a robotic setup as well\nas on a previously published dataset of samples collected by human testers. Our\nfindings indicate that the active sampling approaches, driven by uncertainty\nmetrics, surpass a random sampling baseline in terms of accuracy and stability.\nAdditionally, while in our human study, the participants achieve an average\naccuracy of 48.00%, our best approach achieves an average accuracy of 88.78% on\nthe same set of objects, demonstrating the effectiveness of vision-based\ntactile sensors for object hardness classification.", "published": "2025-05-19 15:15:27", "link": "http://arxiv.org/abs/2505.13231v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Implicit bias produces neural scaling laws in learning curves, from perceptrons to deep networks", "abstract": "Scaling laws in deep learning - empirical power-law relationships linking\nmodel performance to resource growth - have emerged as simple yet striking\nregularities across architectures, datasets, and tasks. These laws are\nparticularly impactful in guiding the design of state-of-the-art models, since\nthey quantify the benefits of increasing data or model size, and hint at the\nfoundations of interpretability in machine learning. However, most studies\nfocus on asymptotic behavior at the end of training or on the optimal training\ntime given the model size. In this work, we uncover a richer picture by\nanalyzing the entire training dynamics through the lens of spectral complexity\nnorms. We identify two novel dynamical scaling laws that govern how performance\nevolves during training. These laws together recover the well-known test error\nscaling at convergence, offering a mechanistic explanation of generalization\nemergence. Our findings are consistent across CNNs, ResNets, and Vision\nTransformers trained on MNIST, CIFAR-10 and CIFAR-100. Furthermore, we provide\nanalytical support using a solvable model: a single-layer perceptron trained\nwith binary cross-entropy. In this setting, we show that the growth of spectral\ncomplexity driven by the implicit bias mirrors the generalization behavior\nobserved at fixed norm, allowing us to connect the performance dynamics to\nclassical learning rules in the perceptron.", "published": "2025-05-19 15:13:36", "link": "http://arxiv.org/abs/2505.13230v1", "categories": ["cs.LG", "cond-mat.dis-nn", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Diffusion Models with Double Guidance: Generate with aggregated datasets", "abstract": "Creating large-scale datasets for training high-performance generative models\nis often prohibitively expensive, especially when associated attributes or\nannotations must be provided. As a result, merging existing datasets has become\na common strategy. However, the sets of attributes across datasets are often\ninconsistent, and their naive concatenation typically leads to block-wise\nmissing conditions. This presents a significant challenge for conditional\ngenerative modeling when the multiple attributes are used jointly as\nconditions, thereby limiting the model's controllability and applicability. To\naddress this issue, we propose a novel generative approach, Diffusion Model\nwith Double Guidance, which enables precise conditional generation even when no\ntraining samples contain all conditions simultaneously. Our method maintains\nrigorous control over multiple conditions without requiring joint annotations.\nWe demonstrate its effectiveness in molecular and image generation tasks, where\nit outperforms existing baselines both in alignment with target conditional\ndistributions and in controllability under missing condition settings.", "published": "2025-05-19 14:59:35", "link": "http://arxiv.org/abs/2505.13213v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Inferring stochastic dynamics with growth from cross-sectional data", "abstract": "Time-resolved single-cell omics data offers high-throughput, genome-wide\nmeasurements of cellular states, which are instrumental to reverse-engineer the\nprocesses underpinning cell fate. Such technologies are inherently destructive,\nallowing only cross-sectional measurements of the underlying stochastic\ndynamical system. Furthermore, cells may divide or die in addition to changing\ntheir molecular state. Collectively these present a major challenge to\ninferring realistic biophysical models. We present a novel approach,\n\\emph{unbalanced} probability flow inference, that addresses this challenge for\nbiological processes modelled as stochastic dynamics with growth. By leveraging\na Lagrangian formulation of the Fokker-Planck equation, our method accurately\ndisentangles drift from intrinsic noise and growth. We showcase the\napplicability of our approach through evaluation on a range of simulated and\nreal single-cell RNA-seq datasets. Comparing to several existing methods, we\nfind our method achieves higher accuracy while enjoying a simple two-step\ntraining scheme.", "published": "2025-05-19 14:51:47", "link": "http://arxiv.org/abs/2505.13197v1", "categories": ["cs.LG", "physics.bio-ph", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "A Malliavin-Gamma calculus approach to Score Based Diffusion Generative models for random fields", "abstract": "We adopt a Gamma and Malliavin Calculi point of view in order to generalize\nScore-based diffusion Generative Models (SGMs) to an infinite-dimensional\nabstract Hilbertian setting. Particularly, we define the forward noising\nprocess using Dirichlet forms associated to the Cameron-Martin space of\nGaussian measures and Wiener chaoses; whereas by relying on an abstract\ntime-reversal formula, we show that the score function is a Malliavin\nderivative and it corresponds to a conditional expectation. This allows us to\ngeneralize SGMs to the infinite-dimensional setting. Moreover, we extend\nexisting finite-dimensional entropic convergence bounds to this Hilbertian\nsetting by highlighting the role played by the Cameron-Martin norm in the\nFisher information of the data distribution. Lastly, we specify our discussion\nfor spherical random fields, considering as source of noise a Whittle-Mat\\'ern\nrandom spherical field.", "published": "2025-05-19 14:46:04", "link": "http://arxiv.org/abs/2505.13189v1", "categories": ["math.PR", "cs.LG", "stat.ML", "62D05, 60G60, 60J46, 60H07, 60H30"], "primary_category": "math.PR"}
{"title": "Interpretable Robotic Friction Learning via Symbolic Regression", "abstract": "Accurately modeling the friction torque in robotic joints has long been\nchallenging due to the request for a robust mathematical description.\nTraditional model-based approaches are often labor-intensive, requiring\nextensive experiments and expert knowledge, and they are difficult to adapt to\nnew scenarios and dependencies. On the other hand, data-driven methods based on\nneural networks are easier to implement but often lack robustness,\ninterpretability, and trustworthiness--key considerations for robotic hardware\nand safety-critical applications such as human-robot interaction. To address\nthe limitations of both approaches, we propose the use of symbolic regression\n(SR) to estimate the friction torque. SR generates interpretable symbolic\nformulas similar to those produced by model-based methods while being flexible\nto accommodate various dynamic effects and dependencies. In this work, we apply\nSR algorithms to approximate the friction torque using collected data from a\nKUKA LWR-IV+ robot. Our results show that SR not only yields formulas with\ncomparable complexity to model-based approaches but also achieves higher\naccuracy. Moreover, SR-derived formulas can be seamlessly extended to include\nload dependencies and other dynamic factors.", "published": "2025-05-19 14:44:02", "link": "http://arxiv.org/abs/2505.13186v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "RIFLES: Resource-effIcient Federated LEarning via Scheduling", "abstract": "Federated Learning (FL) is a privacy-preserving machine learning technique\nthat allows decentralized collaborative model training across a set of\ndistributed clients, by avoiding raw data exchange. A fundamental component of\nFL is the selection of a subset of clients in each round for model training by\na central server. Current selection strategies are myopic in nature in that\nthey are based on past or current interactions, often leading to inefficiency\nissues such as straggling clients. In this paper, we address this serious\nshortcoming by proposing the RIFLES approach that builds a novel availability\nforecasting layer to support the client selection process. We make the\nfollowing contributions: (i) we formalise the sequential selection problem and\nreduce it to a scheduling problem and show that the problem is NP-complete,\n(ii) leveraging heartbeat messages from clients, RIFLES build an availability\nprediction layer to support (long term) selection decisions, (iii) we propose a\nnovel adaptive selection strategy to support efficient learning and resource\nusage. To circumvent the inherent exponential complexity, we present RIFLES, a\nheuristic that leverages clients' historical availability data by using a\nCNN-LSTM time series forecasting model, allowing the server to predict the\noptimal participation times of clients, thereby enabling informed selection\ndecisions. By comparing against other FL techniques, we show that RIFLES\nprovide significant improvement by between 10%-50% on a variety of metrics such\nas accuracy and test loss. To the best of our knowledge, it is the first work\nto investigate FL as a scheduling problem.", "published": "2025-05-19 14:26:33", "link": "http://arxiv.org/abs/2505.13169v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Zero-Shot Adaptation of Behavioral Foundation Models to Unseen Dynamics", "abstract": "Behavioral Foundation Models (BFMs) proved successful in producing policies\nfor arbitrary tasks in a zero-shot manner, requiring no test-time training or\ntask-specific fine-tuning. Among the most promising BFMs are the ones that\nestimate the successor measure learned in an unsupervised way from\ntask-agnostic offline data. However, these methods fail to react to changes in\nthe dynamics, making them inefficient under partial observability or when the\ntransition function changes. This hinders the applicability of BFMs in a\nreal-world setting, e.g., in robotics, where the dynamics can unexpectedly\nchange at test time. In this work, we demonstrate that Forward-Backward (FB)\nrepresentation, one of the methods from the BFM family, cannot distinguish\nbetween distinct dynamics, leading to an interference among the latent\ndirections, which parametrize different policies. To address this, we propose a\nFB model with a transformer-based belief estimator, which greatly facilitates\nzero-shot adaptation. We also show that partitioning the policy encoding space\ninto dynamics-specific clusters, aligned with the context-embedding directions,\nyields additional gain in performance. These traits allow our method to respond\nto the dynamics observed during training and to generalize to unseen ones.\nEmpirically, in the changing dynamics setting, our approach achieves up to a 2x\nhigher zero-shot returns compared to the baselines for both discrete and\ncontinuous tasks.", "published": "2025-05-19 14:12:19", "link": "http://arxiv.org/abs/2505.13150v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Parallel Layer Normalization for Universal Approximation", "abstract": "Universal approximation theorem (UAT) is a fundamental theory for deep neural\nnetworks (DNNs), demonstrating their powerful representation capacity to\nrepresent and approximate any function. The analyses and proofs of UAT are\nbased on traditional network with only linear and nonlinear activation\nfunctions, but omitting normalization layers, which are commonly employed to\nenhance the training of modern networks. This paper conducts research on UAT of\nDNNs with normalization layers for the first time. We theoretically prove that\nan infinitely wide network -- composed solely of parallel layer normalization\n(PLN) and linear layers -- has universal approximation capacity. Additionally,\nwe investigate the minimum number of neurons required to approximate\n$L$-Lipchitz continuous functions, with a single hidden-layer network. We\ncompare the approximation capacity of PLN with traditional activation functions\nin theory. Different from the traditional activation functions, we identify\nthat PLN can act as both activation function and normalization in deep neural\nnetworks at the same time. We also find that PLN can improve the performance\nwhen replacing LN in transformer architectures, which reveals the potential of\nPLN used in neural architectures.", "published": "2025-05-19 14:10:23", "link": "http://arxiv.org/abs/2505.13142v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Neurosymbolic Diffusion Models", "abstract": "Neurosymbolic (NeSy) predictors combine neural perception with symbolic\nreasoning to solve tasks like visual reasoning. However, standard NeSy\npredictors assume conditional independence between the symbols they extract,\nthus limiting their ability to model interactions and uncertainty - often\nleading to overconfident predictions and poor out-of-distribution\ngeneralisation. To overcome the limitations of the independence assumption, we\nintroduce neurosymbolic diffusion models (NeSyDMs), a new class of NeSy\npredictors that use discrete diffusion to model dependencies between symbols.\nOur approach reuses the independence assumption from NeSy predictors at each\nstep of the diffusion process, enabling scalable learning while capturing\nsymbol dependencies and uncertainty quantification. Across both synthetic and\nreal-world benchmarks - including high-dimensional visual path planning and\nrule-based autonomous driving - NeSyDMs achieve state-of-the-art accuracy among\nNeSy predictors and demonstrate strong calibration.", "published": "2025-05-19 14:07:47", "link": "http://arxiv.org/abs/2505.13138v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Attention-based clustering", "abstract": "Transformers have emerged as a powerful neural network architecture capable\nof tackling a wide range of learning tasks. In this work, we provide a\ntheoretical analysis of their ability to automatically extract structure from\ndata in an unsupervised setting. In particular, we demonstrate their\nsuitability for clustering when the input data is generated from a Gaussian\nmixture model. To this end, we study a simplified two-head attention layer and\ndefine a population risk whose minimization with unlabeled data drives the head\nparameters to align with the true mixture centroids.", "published": "2025-05-19 13:39:56", "link": "http://arxiv.org/abs/2505.13112v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Why Knowledge Distillation Works in Generative Models: A Minimal Working Explanation", "abstract": "Knowledge distillation (KD) is a core component in the training and\ndeployment of modern generative models, particularly large language models\n(LLMs). While its empirical benefits are well documented--enabling smaller\nstudent models to emulate the performance of much larger teachers--the\nunderlying mechanisms by which KD improves generative quality remain poorly\nunderstood. In this work, we present a minimal working explanation of KD in\ngenerative modeling. Using a controlled simulation with mixtures of Gaussians,\nwe demonstrate that distillation induces a trade-off between precision and\nrecall in the student model. As the teacher distribution becomes more\nselective, the student concentrates more probability mass on high-likelihood\nregions at the expense of coverage--a behavior modulated by a single\nentropy-controlling parameter. We then validate this effect in a large-scale\nlanguage modeling setup using the SmolLM2 family of models. Empirical results\nreveal the same precision-recall dynamics observed in simulation, where\nprecision corresponds to sample quality and recall to distributional coverage.\nThis precision-recall trade-off proves especially beneficial in scenarios where\nsample quality outweighs diversity, such as instruction tuning or downstream\ngeneration. Our analysis provides a simple and general explanation for the\neffectiveness of KD in generative modeling.", "published": "2025-05-19 13:39:47", "link": "http://arxiv.org/abs/2505.13111v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Time series saliency maps: explaining models across multiple domains", "abstract": "Traditional saliency map methods, popularized in computer vision, highlight\nindividual points (pixels) of the input that contribute the most to the model's\noutput. However, in time-series they offer limited insights as semantically\nmeaningful features are often found in other domains. We introduce Cross-domain\nIntegrated Gradients, a generalization of Integrated Gradients. Our method\nenables feature attributions on any domain that can be formulated as an\ninvertible, differentiable transformation of the time domain. Crucially, our\nderivation extends the original Integrated Gradients into the complex domain,\nenabling frequency-based attributions. We provide the necessary theoretical\nguarantees, namely, path independence and completeness. Our approach reveals\ninterpretable, problem-specific attributions that time-domain methods cannot\ncapture, on three real-world tasks: wearable sensor heart rate extraction,\nelectroencephalography-based seizure detection, and zero-shot time-series\nforecasting. We release an open-source Tensorflow/PyTorch library to enable\nplug-and-play cross-domain explainability for time-series models. These results\ndemonstrate the ability of cross-domain integrated gradients to provide\nsemantically meaningful insights in time-series models that are impossible with\ntraditional time-domain saliency.", "published": "2025-05-19 13:31:35", "link": "http://arxiv.org/abs/2505.13100v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Treatment Effect Estimation for Optimal Decision-Making", "abstract": "Decision-making across various fields, such as medicine, heavily relies on\nconditional average treatment effects (CATEs). Practitioners commonly make\ndecisions by checking whether the estimated CATE is positive, even though the\ndecision-making performance of modern CATE estimators is poorly understood from\na theoretical perspective. In this paper, we study optimal decision-making\nbased on two-stage CATE estimators (e.g., DR-learner), which are considered\nstate-of-the-art and widely used in practice. We prove that, while such\nestimators may be optimal for estimating CATE, they can be suboptimal when used\nfor decision-making. Intuitively, this occurs because such estimators\nprioritize CATE accuracy in regions far away from the decision boundary, which\nis ultimately irrelevant to decision-making. As a remedy, we propose a novel\ntwo-stage learning objective that retargets the CATE to balance CATE estimation\nerror and decision performance. We then propose a neural method that optimizes\nan adaptively-smoothed approximation of our learning objective. Finally, we\nconfirm the effectiveness of our method both empirically and theoretically. In\nsum, our work is the first to show how two-stage CATE estimators can be adapted\nfor optimal decision-making.", "published": "2025-05-19 13:24:57", "link": "http://arxiv.org/abs/2505.13092v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Universal Semantic Disentangled Privacy-preserving Speech Representation Learning", "abstract": "The use of audio recordings of human speech to train LLMs poses privacy\nconcerns due to these models' potential to generate outputs that closely\nresemble artifacts in the training data. In this study, we propose a speaker\nprivacy-preserving representation learning method through the Universal Speech\nCodec (USC), a computationally efficient encoder-decoder model that\ndisentangles speech into: $\\textit{(i)}$ privacy-preserving semantically rich\nrepresentations, capturing content and speech paralinguistics, and\n$\\textit{(ii)}$ residual acoustic and speaker representations that enables\nhigh-fidelity reconstruction. Extensive evaluations presented show that USC's\nsemantic representation preserves content, prosody, and sentiment, while\nremoving potentially identifiable speaker attributes. Combining both\nrepresentations, USC achieves state-of-the-art speech reconstruction.\nAdditionally, we introduce an evaluation methodology for measuring\nprivacy-preserving properties, aligning with perceptual tests. We compare USC\nagainst other codecs in the literature and demonstrate its effectiveness on\nprivacy-preserving representation learning, illustrating the trade-offs of\nspeaker anonymization, paralinguistics retention and content preservation in\nthe learned semantic representations. Audio samples are shared in\n$\\href{https://www.amazon.science/usc-samples}{https://www.amazon.science/usc-samples}$.", "published": "2025-05-19 13:19:49", "link": "http://arxiv.org/abs/2505.13085v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Orthogonal Survival Learners for Estimating Heterogeneous Treatment Effects from Time-to-Event Data", "abstract": "Estimating heterogeneous treatment effects (HTEs) is crucial for personalized\ndecision-making. However, this task is challenging in survival analysis, which\nincludes time-to-event data with censored outcomes (e.g., due to study\ndropout). In this paper, we propose a toolbox of novel orthogonal survival\nlearners to estimate HTEs from time-to-event data under censoring. Our learners\nhave three main advantages: (i) we show that learners from our toolbox are\nguaranteed to be orthogonal and thus come with favorable theoretical\nproperties; (ii) our toolbox allows for incorporating a custom weighting\nfunction, which can lead to robustness against different types of low overlap,\nand (iii) our learners are model-agnostic (i.e., they can be combined with\narbitrary machine learning models). We instantiate the learners from our\ntoolbox using several weighting functions and, as a result, propose various\nneural orthogonal survival learners. Some of these coincide with existing\nsurvival learners (including survival versions of the DR- and R-learner), while\nothers are novel and further robust w.r.t. low overlap regimes specific to the\nsurvival setting (i.e., survival overlap and censoring overlap). We then\nempirically verify the effectiveness of our learners for HTE estimation in\ndifferent low-overlap regimes through numerical experiments. In sum, we provide\npractitioners with a large toolbox of learners that can be used for randomized\nand observational studies with censored time-to-event data.", "published": "2025-05-19 13:06:41", "link": "http://arxiv.org/abs/2505.13072v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "OmniFC: Rethinking Federated Clustering via Lossless and Secure Distance Reconstruction", "abstract": "Federated clustering (FC) aims to discover global cluster structures across\ndecentralized clients without sharing raw data, making privacy preservation a\nfundamental requirement. There are two critical challenges: (1) privacy leakage\nduring collaboration, and (2) robustness degradation due to aggregation of\nproxy information from non-independent and identically distributed (Non-IID)\nlocal data, leading to inaccurate or inconsistent global clustering. Existing\nsolutions typically rely on model-specific local proxies, which are sensitive\nto data heterogeneity and inherit inductive biases from their centralized\ncounterparts, thus limiting robustness and generality. We propose Omni\nFederated Clustering (OmniFC), a unified and model-agnostic framework.\nLeveraging Lagrange coded computing, our method enables clients to share only\nencoded data, allowing exact reconstruction of the global distance matrix--a\nfundamental representation of sample relationships--without leaking private\ninformation, even under client collusion. This construction is naturally\nresilient to Non-IID data distributions. This approach decouples FC from\nmodel-specific proxies, providing a unified extension mechanism applicable to\ndiverse centralized clustering methods. Theoretical analysis confirms both\nreconstruction fidelity and privacy guarantees, while comprehensive experiments\ndemonstrate OmniFC's superior robustness, effectiveness, and generality across\nvarious benchmarks compared to state-of-the-art methods. Code will be released.", "published": "2025-05-19 13:04:59", "link": "http://arxiv.org/abs/2505.13071v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs", "abstract": "Quantization is essential for Neural Network (NN) compression, reducing model\nsize and computational demands by using lower bit-width data types, though\naggressive reduction often hampers accuracy. Mixed Precision (MP) mitigates\nthis tradeoff by varying the numerical precision across network layers. This\nstudy focuses on automatically selecting an optimal MP configuration within\nPost-Training Quantization (PTQ) for inference. The first key contribution is a\nnovel sensitivity metric derived from a first-order Taylor series expansion of\nthe loss function as a function of quantization errors in weights and\nactivations. This metric, based on the Mean Square Error (MSE) of the loss, is\nefficiently calculated per layer using high-precision forward and backward\npasses over a small calibration dataset. The metric is additive across layers,\nwith low calibration memory overhead as weight optimization is unnecessary. The\nsecond contribution is an accurate hardware-aware method for predicting MP time\ngain by modeling it as additive for sequential sub-graphs. An algorithm\npartitions the model graph into sequential subgraphs, measuring time gain for\neach configuration using a few samples. After calibrating per-layer sensitivity\nand time gain, an Integer Programming (IP) problem is formulated to maximize\ntime gain while keeping loss MSE below a set threshold. Memory gain and\ntheoretical time gain based on Multiply and Accumulate (MAC) operations are\nalso considered. Rigorous experiments on the Intel Gaudi 2 accelerator validate\nthe approach on several Large Language Models (LLMs).", "published": "2025-05-19 12:51:02", "link": "http://arxiv.org/abs/2505.13060v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Path to Universal Neural Cellular Automata", "abstract": "Cellular automata have long been celebrated for their ability to generate\ncomplex behaviors from simple, local rules, with well-known discrete models\nlike Conway's Game of Life proven capable of universal computation. Recent\nadvancements have extended cellular automata into continuous domains, raising\nthe question of whether these systems retain the capacity for universal\ncomputation. In parallel, neural cellular automata have emerged as a powerful\nparadigm where rules are learned via gradient descent rather than manually\ndesigned. This work explores the potential of neural cellular automata to\ndevelop a continuous Universal Cellular Automaton through training by gradient\ndescent. We introduce a cellular automaton model, objective functions and\ntraining strategies to guide neural cellular automata toward universal\ncomputation in a continuous setting. Our experiments demonstrate the successful\ntraining of fundamental computational primitives - such as matrix\nmultiplication and transposition - culminating in the emulation of a neural\nnetwork solving the MNIST digit classification task directly within the\ncellular automata state. These results represent a foundational step toward\nrealizing analog general-purpose computers, with implications for understanding\nuniversal computation in continuous dynamics and advancing the automated\ndiscovery of complex cellular automata behaviors via machine learning.", "published": "2025-05-19 12:46:01", "link": "http://arxiv.org/abs/2505.13058v1", "categories": ["cs.LG", "cs.ET", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Simplicity is Key: An Unsupervised Pretraining Approach for Sparse Radio Channels", "abstract": "We introduce the Sparse pretrained Radio Transformer (SpaRTran), an\nunsupervised representation learning approach based on the concept of\ncompressed sensing for radio channels. Our approach learns embeddings that\nfocus on the physical properties of radio propagation, to create the optimal\nbasis for fine-tuning on radio-based downstream tasks. SpaRTran uses a sparse\ngated autoencoder that induces a simplicity bias to the learned\nrepresentations, resembling the sparse nature of radio propagation. For signal\nreconstruction, it learns a dictionary that holds atomic features, which\nincreases flexibility across signal waveforms and spatiotemporal signal\npatterns. Our experiments show that SpaRTran reduces errors by up to 85 %\ncompared to state-of-the-art methods when fine-tuned on radio fingerprinting, a\nchallenging downstream task. In addition, our method requires less pretraining\neffort and offers greater flexibility, as we train it solely on individual\nradio signals. SpaRTran serves as an excellent base model that can be\nfine-tuned for various radio-based downstream tasks, effectively reducing the\ncost for labeling. In addition, it is significantly more versatile than\nexisting methods and demonstrates superior generalization.", "published": "2025-05-19 12:43:33", "link": "http://arxiv.org/abs/2505.13055v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Model Selection for Gaussian-gated Gaussian Mixture of Experts Using Dendrograms of Mixing Measures", "abstract": "Mixture of Experts (MoE) models constitute a widely utilized class of\nensemble learning approaches in statistics and machine learning, known for\ntheir flexibility and computational efficiency. They have become integral\ncomponents in numerous state-of-the-art deep neural network architectures,\nparticularly for analyzing heterogeneous data across diverse domains. Despite\ntheir practical success, the theoretical understanding of model selection,\nespecially concerning the optimal number of mixture components or experts,\nremains limited and poses significant challenges. These challenges primarily\nstem from the inclusion of covariates in both the Gaussian gating functions and\nexpert networks, which introduces intrinsic interactions governed by partial\ndifferential equations with respect to their parameters. In this paper, we\nrevisit the concept of dendrograms of mixing measures and introduce a novel\nextension to Gaussian-gated Gaussian MoE models that enables consistent\nestimation of the true number of mixture components and achieves the pointwise\noptimal convergence rate for parameter estimation in overfitted scenarios.\nNotably, this approach circumvents the need to train and compare a range of\nmodels with varying numbers of components, thereby alleviating the\ncomputational burden, particularly in high-dimensional or deep neural network\nsettings. Experimental results on synthetic data demonstrate the effectiveness\nof the proposed method in accurately recovering the number of experts. It\noutperforms common criteria such as the Akaike information criterion, the\nBayesian information criterion, and the integrated completed likelihood, while\nachieving optimal convergence rates for parameter estimation and accurately\napproximating the regression function.", "published": "2025-05-19 12:41:19", "link": "http://arxiv.org/abs/2505.13052v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.CO", "stat.ME", "stat.TH"], "primary_category": "stat.ML"}
{"title": "PPTNet: A Hybrid Periodic Pattern-Transformer Architecture for Traffic Flow Prediction and Congestion Identification", "abstract": "Accurate prediction of traffic flow parameters and real time identification\nof congestion states are essential for the efficient operation of intelligent\ntransportation systems. This paper proposes a Periodic Pattern Transformer\nNetwork (PPTNet) for traffic flow prediction, integrating periodic pattern\nextraction with the Transformer architecture, coupled with a fuzzy inference\nmethod for real-time congestion identification. Firstly, a high-precision\ntraffic flow dataset (Traffic Flow Dataset for China's Congested Highways and\nExpressways, TF4CHE) suitable for congested highway scenarios in China is\nconstructed based on drone aerial imagery data. Subsequently, the proposed\nPPTNet employs Fast Fourier Transform to capture multi-scale periodic patterns\nand utilizes two-dimensional Inception convolutions to efficiently extract\nintra and inter periodic features. A Transformer decoder dynamically models\ntemporal dependencies, enabling accurate predictions of traffic density and\nspeed. Finally, congestion probabilities are calculated in real-time using the\npredicted outcomes via a Mamdani fuzzy inference-based congestion\nidentification module. Experimental results demonstrate that the proposed\nPPTNet significantly outperforms mainstream traffic prediction methods in\nprediction accuracy, and the congestion identification module effectively\nidentifies real-time road congestion states, verifying the superiority and\npracticality of the proposed method in real-world traffic scenarios. Project\npage: https://github.com/ADSafetyJointLab/PPTNet.", "published": "2025-05-19 12:36:12", "link": "http://arxiv.org/abs/2505.13047v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Unpacking Positional Encoding in Transformers: A Spectral Analysis of Content-Position Coupling", "abstract": "Positional encoding (PE) is essential for enabling Transformers to model\nsequential structure. However, the mechanisms by which different PE schemes\ncouple token content and positional information-and how these mechanisms\ninfluence model dynamics-remain theoretically underexplored. In this work, we\npresent a unified framework that analyzes PE through the spectral properties of\nToeplitz and related matrices derived from attention logits. We show that\nmultiplicative content-position coupling-exemplified by Rotary Positional\nEncoding (RoPE) via a Hadamard product with a Toeplitz matrix-induces spectral\ncontraction, which theoretically improves optimization stability and\nefficiency. Guided by this theory, we construct synthetic tasks that contrast\ncontent-position dependent and content-position independent settings, and\nevaluate a range of PE methods. Our experiments reveal strong alignment with\ntheory: RoPE consistently outperforms other methods on position-sensitive tasks\nand induces \"single-head deposit\" patterns in early layers, indicating\nlocalized positional processing. Further analyses show that modifying the\nmethod and timing of PE coupling, such as MLA in Deepseek-V3, can effectively\nmitigate this concentration. These results establish explicit content-relative\nmixing with relative-position Toeplitz signals as a key principle for effective\nPE design and provide new insight into how positional structure is integrated\nin Transformer architectures.", "published": "2025-05-19 12:11:13", "link": "http://arxiv.org/abs/2505.13027v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "The role of data partitioning on the performance of EEG-based deep learning models in supervised cross-subject analysis: a preliminary study", "abstract": "Deep learning is significantly advancing the analysis of\nelectroencephalography (EEG) data by effectively discovering highly nonlinear\npatterns within the signals. Data partitioning and cross-validation are crucial\nfor assessing model performance and ensuring study comparability, as they can\nproduce varied results and data leakage due to specific signal properties\n(e.g., biometric). Such variability leads to incomparable studies and,\nincreasingly, overestimated performance claims, which are detrimental to the\nfield. Nevertheless, no comprehensive guidelines for proper data partitioning\nand cross-validation exist in the domain, nor is there a quantitative\nevaluation of their impact on model accuracy, reliability, and\ngeneralizability. To assist researchers in identifying optimal experimental\nstrategies, this paper thoroughly investigates the role of data partitioning\nand cross-validation in evaluating EEG deep learning models. Five\ncross-validation settings are compared across three supervised cross-subject\nclassification tasks (BCI, Parkinson's, and Alzheimer's disease detection) and\nfour established architectures of increasing complexity (ShallowConvNet,\nEEGNet, DeepConvNet, and Temporal-based ResNet). The comparison of over 100,000\ntrained models underscores, first, the importance of using subject-based\ncross-validation strategies for evaluating EEG deep learning models, except\nwhen within-subject analyses are acceptable (e.g., BCI). Second, it highlights\nthe greater reliability of nested approaches (N-LNSO) compared to non-nested\ncounterparts, which are prone to data leakage and favor larger models\noverfitting to validation data. In conclusion, this work provides EEG deep\nlearning researchers with an analysis of data partitioning and cross-validation\nand offers guidelines to avoid data leakage, currently undermining the domain\nwith potentially overestimated performance claims.", "published": "2025-05-19 12:05:28", "link": "http://arxiv.org/abs/2505.13021v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Asymptotic Performance of Time-Varying Bayesian Optimization", "abstract": "Time-Varying Bayesian Optimization (TVBO) is the go-to framework for\noptimizing a time-varying black-box objective function that may be noisy and\nexpensive to evaluate. Is it possible for the instantaneous regret of a TVBO\nalgorithm to vanish asymptotically, and if so, when? We answer this question of\ngreat theoretical importance by providing algorithm-independent lower regret\nbounds and upper regret bounds for TVBO algorithms, from which we derive\nsufficient conditions for a TVBO algorithm to have the no-regret property. Our\nanalysis covers all major classes of stationary kernel functions.", "published": "2025-05-19 11:55:02", "link": "http://arxiv.org/abs/2505.13012v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Generative Modeling of Random Fields from Limited Data via Constrained Latent Flow Matching", "abstract": "Deep generative models are promising tools for science and engineering, but\ntheir reliance on abundant, high-quality data limits applicability. We present\na novel framework for generative modeling of random fields (probability\ndistributions over continuous functions) that incorporates domain knowledge to\nsupplement limited, sparse, and indirect data. The foundation of the approach\nis latent flow matching, where generative modeling occurs on compressed\nfunction representations in the latent space of a pre-trained variational\nautoencoder (VAE). Innovations include the adoption of a function decoder\nwithin the VAE and integration of physical/statistical constraints into the VAE\ntraining process. In this way, a latent function representation is learned that\nyields continuous random field samples satisfying domain-specific constraints\nwhen decoded, even in data-limited regimes. Efficacy is demonstrated on two\nchallenging applications: wind velocity field reconstruction from sparse\nsensors and material property inference from a limited number of indirect\nmeasurements. Results show that the proposed framework achieves significant\nimprovements in reconstruction accuracy compared to unconstrained methods and\nenables effective inference with relatively small training datasets that is\nintractable without constraints.", "published": "2025-05-19 11:47:44", "link": "http://arxiv.org/abs/2505.13007v1", "categories": ["cs.LG", "cs.CE"], "primary_category": "cs.LG"}
{"title": "Optimal Formats for Weight Quantisation", "abstract": "Weight quantisation is an essential technique for enabling efficient training\nand deployment of modern deep learning models. However, the recipe book of\nquantisation formats is large and the formats are often chosen empirically. In\nthis paper, we propose a framework for systematic design and analysis of\nquantisation formats. By connecting the question of format design with the\nclassical quantisation theory, we show that the strong practical performance of\npopular formats comes from their ability to represent values using\nvariable-length codes. Framing the optimisation problem as minimising the KL\ndivergence between the original and quantised model outputs, the objective is\naligned with minimising the squared quantisation error of the model parameters.\nWe therefore develop and evaluate squared-error-optimal formats for known\ndistributions, observing significant improvement of variable-length codes over\nfixed-length codes. Uniform quantisation followed by lossless compression with\na variable-length code is shown to be optimal. However, we find that commonly\nused block formats and sparse outlier formats also outperform fixed-length\ncodes, implying they also exploit variable-length encoding. Finally, by using\nthe relationship between the Fisher information and KL divergence, we derive\nthe optimal allocation of bit-widths to individual parameter tensors across the\nmodel's layers, saving up to 0.25 bits per parameter when tested with\ndirect-cast quantisation of language models.", "published": "2025-05-19 11:26:54", "link": "http://arxiv.org/abs/2505.12988v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Multi-parameter Control for the (1+($\u03bb$,$\u03bb$))-GA on OneMax via Deep Reinforcement Learning", "abstract": "It is well known that evolutionary algorithms can benefit from dynamic\nchoices of the key parameters that control their behavior, to adjust their\nsearch strategy to the different stages of the optimization process. A\nprominent example where dynamic parameter choices have shown a provable\nsuper-constant speed-up is the $(1+(\\lambda,\\lambda))$ Genetic Algorithm\noptimizing the OneMax function. While optimal parameter control policies result\nin linear expected running times, this is not possible with static parameter\nchoices. This result has spurred a lot of interest in parameter control\npolicies. However, many works, in particular theoretical running time analyses,\nfocus on controlling one single parameter. Deriving policies for controlling\nmultiple parameters remains very challenging. In this work we reconsider the\nproblem of the $(1+(\\lambda,\\lambda))$ Genetic Algorithm optimizing OneMax. We\ndecouple its four main parameters and investigate how well state-of-the-art\ndeep reinforcement learning techniques can approximate good control policies.\nWe show that although making deep reinforcement learning learn effectively is a\nchallenging task, once it works, it is very powerful and is able to find\npolicies that outperform all previously known control policies on the same\nbenchmark. Based on the results found through reinforcement learning, we derive\na simple control policy that consistently outperforms the default\ntheory-recommended setting by $27\\%$ and the irace-tuned policy, the strongest\nexisting control policy on this benchmark, by $13\\%$, for all tested problem\nsizes up to $40{,}000$.", "published": "2025-05-19 11:18:41", "link": "http://arxiv.org/abs/2505.12982v1", "categories": ["cs.LG", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Augmented Regression Models using Neurochaos Learning", "abstract": "This study presents novel Augmented Regression Models using Neurochaos\nLearning (NL), where Tracemean features derived from the Neurochaos Learning\nframework are integrated with traditional regression algorithms : Linear\nRegression, Ridge Regression, Lasso Regression, and Support Vector Regression\n(SVR). Our approach was evaluated using ten diverse real-life datasets and a\nsynthetically generated dataset of the form $y = mx + c + \\epsilon$. Results\nshow that incorporating the Tracemean feature (mean of the chaotic neural\ntraces of the neurons in the NL architecture) significantly enhances regression\nperformance, particularly in Augmented Lasso Regression and Augmented SVR,\nwhere six out of ten real-life datasets exhibited improved predictive accuracy.\nAmong the models, Augmented Chaotic Ridge Regression achieved the highest\naverage performance boost (11.35 %). Additionally, experiments on the simulated\ndataset demonstrated that the Mean Squared Error (MSE) of the augmented models\nconsistently decreased and converged towards the Minimum Mean Squared Error\n(MMSE) as the sample size increased. This work demonstrates the potential of\nchaos-inspired features in regression tasks, offering a pathway to more\naccurate and computationally efficient prediction models.", "published": "2025-05-19 11:02:14", "link": "http://arxiv.org/abs/2505.12967v1", "categories": ["cs.LG", "math.DS"], "primary_category": "cs.LG"}
{"title": "Synthesis of Communication Policies for Multi-Agent Systems Robust to Communication Restrictions", "abstract": "We study stochastic multi-agent systems in which agents must cooperate to\nmaximize the probability of achieving a common reach-avoid objective. In many\napplications, during the execution of the system, the communication between the\nagents can be constrained by restrictions on the bandwidth currently available\nfor exchanging local-state information between the agents.\n  In this paper, we propose a method for computing joint action and\ncommunication policies for the group of agents that aim to satisfy the\ncommunication restrictions as much as possible while achieving the optimal\nreach-avoid probability when communication is unconstrained. Our method\nsynthesizes a pair of action and communication policies robust to restrictions\non the number of agents allowed to communicate. To this end, we introduce a\nnovel cost function that measures the amount of information exchanged beyond\nwhat the communication policy allows. We evaluate our approach experimentally\non a range of benchmarks and demonstrate that it is capable of computing pairs\nof action and communication policies that satisfy the communication\nrestrictions, if such exist.", "published": "2025-05-19 16:26:57", "link": "http://arxiv.org/abs/2505.13311v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "The Traitors: Deception and Trust in Multi-Agent Language Model Simulations", "abstract": "As AI systems increasingly assume roles where trust and alignment with human\nvalues are essential, understanding when and why they engage in deception has\nbecome a critical research priority. We introduce The Traitors, a multi-agent\nsimulation framework inspired by social deduction games, designed to probe\ndeception, trust formation, and strategic communication among large language\nmodel (LLM) agents under asymmetric information. A minority of agents the\ntraitors seek to mislead the majority, while the faithful must infer hidden\nidentities through dialogue and reasoning. Our contributions are: (1) we ground\nthe environment in formal frameworks from game theory, behavioral economics,\nand social cognition; (2) we develop a suite of evaluation metrics capturing\ndeception success, trust dynamics, and collective inference quality; (3) we\nimplement a fully autonomous simulation platform where LLMs reason over\npersistent memory and evolving social dynamics, with support for heterogeneous\nagent populations, specialized traits, and adaptive behaviors. Our initial\nexperiments across DeepSeek-V3, GPT-4o-mini, and GPT-4o (10 runs per model)\nreveal a notable asymmetry: advanced models like GPT-4o demonstrate superior\ndeceptive capabilities yet exhibit disproportionate vulnerability to others'\nfalsehoods. This suggests deception skills may scale faster than detection\nabilities. Overall, The Traitors provides a focused, configurable testbed for\ninvestigating LLM behavior in socially nuanced interactions. We position this\nwork as a contribution toward more rigorous research on deception mechanisms,\nalignment challenges, and the broader social reliability of AI systems.", "published": "2025-05-19 10:01:35", "link": "http://arxiv.org/abs/2505.12923v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "From Grunts to Grammar: Emergent Language from Cooperative Foraging", "abstract": "Early cavemen relied on gestures, vocalizations, and simple signals to\ncoordinate, plan, avoid predators, and share resources. Today, humans\ncollaborate using complex languages to achieve remarkable results. What drives\nthis evolution in communication? How does language emerge, adapt, and become\nvital for teamwork? Understanding the origins of language remains a challenge.\nA leading hypothesis in linguistics and anthropology posits that language\nevolved to meet the ecological and social demands of early human cooperation.\nLanguage did not arise in isolation, but through shared survival goals.\nInspired by this view, we investigate the emergence of language in multi-agent\nForaging Games. These environments are designed to reflect the cognitive and\necological constraints believed to have influenced the evolution of\ncommunication. Agents operate in a shared grid world with only partial\nknowledge about other agents and the environment, and must coordinate to\ncomplete games like picking up high-value targets or executing temporally\nordered actions. Using end-to-end deep reinforcement learning, agents learn\nboth actions and communication strategies from scratch. We find that agents\ndevelop communication protocols with hallmark features of natural language:\narbitrariness, interchangeability, displacement, cultural transmission, and\ncompositionality. We quantify each property and analyze how different factors,\nsuch as population size and temporal dependencies, shape specific aspects of\nthe emergent language. Our framework serves as a platform for studying how\nlanguage can evolve from partial observability, temporal reasoning, and\ncooperative goals in embodied multi-agent settings. We will release all data,\ncode, and models publicly.", "published": "2025-05-19 08:57:30", "link": "http://arxiv.org/abs/2505.12872v1", "categories": ["cs.AI", "cs.LG", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Dynamic Sight Range Selection in Multi-Agent Reinforcement Learning", "abstract": "Multi-agent reinforcement Learning (MARL) is often challenged by the sight\nrange dilemma, where agents either receive insufficient or excessive\ninformation from their environment. In this paper, we propose a novel method,\ncalled Dynamic Sight Range Selection (DSR), to address this issue. DSR utilizes\nan Upper Confidence Bound (UCB) algorithm and dynamically adjusts the sight\nrange during training. Experiment results show several advantages of using DSR.\nFirst, we demonstrate using DSR achieves better performance in three common\nMARL environments, including Level-Based Foraging (LBF), Multi-Robot Warehouse\n(RWARE), and StarCraft Multi-Agent Challenge (SMAC). Second, our results show\nthat DSR consistently improves performance across multiple MARL algorithms,\nincluding QMIX and MAPPO. Third, DSR offers suitable sight ranges for different\ntraining steps, thereby accelerating the training process. Finally, DSR\nprovides additional interpretability by indicating the optimal sight range used\nduring training. Unlike existing methods that rely on global information or\ncommunication mechanisms, our approach operates solely based on the individual\nsight ranges of agents. This approach offers a practical and efficient solution\nto the sight range dilemma, making it broadly applicable to real-world complex\nenvironments.", "published": "2025-05-19 07:40:42", "link": "http://arxiv.org/abs/2505.12811v1", "categories": ["cs.MA", "cs.AI", "cs.LG"], "primary_category": "cs.MA"}
{"title": "Adaptive Inference through Bayesian and Inverse Bayesian Inference with Symmetry-Bias in Nonstationary Environments", "abstract": "This study introduces a novel inference framework, designated as Bayesian and\ninverse Bayesian (BIB) inference, which concurrently performs both conventional\nand inverse Bayesian updates by integrating symmetry bias into Bayesian\ninference. The effectiveness of the model was evaluated through a sequential\nestimation task involving observations sampled from a Gaussian distribution\nwith a stochastically time-varying mean. Conventional Bayesian inference\nentails a fundamental trade-off between adaptability to abrupt environmental\nshifts and estimation accuracy during stable intervals. The BIB framework\naddresses this limitation by dynamically modulating the learning rate through\ninverse Bayesian updates, thereby enhancing adaptive flexibility. The BIB model\ngenerated spontaneous bursts in the learning rate during sudden environmental\ntransitions, transiently entering a high-sensitivity state to accommodate\nincoming data. This intermittent burst-relaxation pattern functions as a\ndynamic mechanism that balances adaptability and accuracy. Further analysis of\nburst interval distributions demonstrated that the BIB model consistently\nproduced power-law distributions under diverse conditions. Such robust scaling\nbehavior, absent in conventional Bayesian inference, appears to emerge from a\nself-regulatory mechanism driven by inverse Bayesian updates. These results\npresent a novel computational perspective on scale-free phenomena in natural\nsystems and offer implications for designing adaptive inference systems in\nnonstationary environments.", "published": "2025-05-19 07:30:45", "link": "http://arxiv.org/abs/2505.12796v1", "categories": ["stat.ME", "cs.MA"], "primary_category": "stat.ME"}
{"title": "PLAICraft: Large-Scale Time-Aligned Vision-Speech-Action Dataset for Embodied AI", "abstract": "Advances in deep generative modelling have made it increasingly plausible to\ntrain human-level embodied agents. Yet progress has been limited by the absence\nof large-scale, real-time, multi-modal, and socially interactive datasets that\nreflect the sensory-motor complexity of natural environments. To address this,\nwe present PLAICraft, a novel data collection platform and dataset capturing\nmultiplayer Minecraft interactions across five time-aligned modalities: video,\ngame output audio, microphone input audio, mouse, and keyboard actions. Each\nmodality is logged with millisecond time precision, enabling the study of\nsynchronous, embodied behaviour in a rich, open-ended world. The dataset\ncomprises over 10,000 hours of gameplay from more than 10,000 global\nparticipants.\\footnote{We have done a privacy review for the public release of\nan initial 200-hour subset of the dataset, with plans to release most of the\ndataset over time.} Alongside the dataset, we provide an evaluation suite for\nbenchmarking model capabilities in object recognition, spatial awareness,\nlanguage grounding, and long-term memory. PLAICraft opens a path toward\ntraining and evaluating agents that act fluently and purposefully in real time,\npaving the way for truly embodied artificial intelligence.", "published": "2025-05-19 05:00:47", "link": "http://arxiv.org/abs/2505.12707v1", "categories": ["cs.LG", "cs.AI", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Lightweight and Effective Preference Construction in PIBT for Large-Scale Multi-Agent Pathfinding", "abstract": "PIBT is a computationally lightweight algorithm that can be applied to a\nvariety of multi-agent pathfinding (MAPF) problems, generating the next\ncollision-free locations of agents given another. Because of its simplicity and\nscalability, it is becoming a popular underlying scheme for recent large-scale\nMAPF methods involving several hundreds or thousands of agents. Vanilla PIBT\nmakes agents behave greedily towards their assigned goals, while agents\ntypically have multiple best actions, since the graph shortest path is not\nalways unique. Consequently, tiebreaking about how to choose between these\nactions significantly affects resulting solutions. This paper studies two\nsimple yet effective techniques for tiebreaking in PIBT, without compromising\nits computational advantage. The first technique allows an agent to\nintelligently dodge another, taking into account whether each action will\nhinder the progress of the next timestep. The second technique is to learn,\nthrough multiple PIBT runs, how an action causes regret in others and to use\nthis information to minimise regret collectively. Our empirical results\ndemonstrate that these techniques can reduce the solution cost of one-shot MAPF\nand improve the throughput of lifelong MAPF. For instance, in densely populated\none-shot cases, the combined use of these tiebreaks achieves improvements of\naround 10-20% in sum-of-costs, without significantly compromising the speed of\na PIBT-based planner.", "published": "2025-05-19 02:12:29", "link": "http://arxiv.org/abs/2505.12623v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "The Hamiltonian of Poly-matrix Zero-sum Games", "abstract": "Understanding a dynamical system fundamentally relies on establishing an\nappropriate Hamiltonian function and elucidating its symmetries. By formulating\nagents' strategies and cumulative payoffs as canonically conjugate variables,\nwe identify the Hamiltonian function that generates the dynamics of poly-matrix\nzero-sum games. We reveal the symmetries of our Hamiltonian and derive the\nassociated conserved quantities, showing how the conservation of probability\nand the invariance of the Fenchel coupling are intrinsically encoded within the\nsystem. Furthermore, we propose the dissipation FTRL (DFTRL) dynamics by\nintroducing a perturbation that dissipates the Fenchel coupling, proving\nconvergence to the Nash equilibrium and linking DFTRL to last-iterate\nconvergent algorithms. Our results highlight the potential of Hamiltonian\ndynamics in uncovering the structural properties of learning dynamics in games,\nand pave the way for broader applications of Hamiltonian dynamics in game\ntheory and machine learning.", "published": "2025-05-19 01:46:29", "link": "http://arxiv.org/abs/2505.12609v1", "categories": ["cs.GT", "cs.LG", "cs.MA", "nlin.CD"], "primary_category": "cs.GT"}
{"title": "Structure-preserving schemes conserving entropy and kinetic energy", "abstract": "This paper presents a novel structure-preserving scheme for Euler equations,\nfocusing on the numerical conservation of entropy and kinetic energy. Explicit\nflux functions engineered to conserve entropy are introduced within the\nfinite-volume framework. Further, discrete kinetic energy conservation too is\nintroduced. A systematic inquiry is presented, commencing with an overview of\nnumerical entropy conservation and formulation of entropy-conserving and\nkinetic energy-preserving fluxes, followed by the study of their properties and\nefficacy. A novelty introduced is to associate numerical entropy conservation\nto the discretization of the energy conservation equation. Furthermore, an\nentropy-stable shock-capturing diffusion method and a hybrid approach utilizing\nthe entropy distance to manage smooth regions effectively are also introduced.\nThe addition of artificial viscosity in appropriate regions ensures entropy\ngeneration sufficient to prevent numerical instabilities. Various test cases,\nshowcasing the efficacy and stability of the proposed methodology, are\npresented.", "published": "2025-05-19 17:19:39", "link": "http://arxiv.org/abs/2505.13374v1", "categories": ["math.NA", "cs.NA", "physics.comp-ph"], "primary_category": "math.NA"}
{"title": "Quantum Hardware-in-the-Loop for Optimal Power Flow in Renewable-Integrated Power Systems", "abstract": "This paper presents a proof-of-concept for integrating quantum hardware with\nreal-time digital simulator (RTDS) to model and control modern power systems,\nincluding renewable energy resources. Power flow (PF) analysis and optimal\npower flow (OPF) studies are conducted using RTDS coupled with Fujitsu's CMOS\nDigital Annealer and D-Wave's Advantage quantum processors. The adiabatic\nquantum power flow (AQPF) and adiabatic quantum optimal power flow (AQOPF)\nalgorithms are used to perform PF and OPF, respectively, on quantum and\nquantum-inspired hardware. The experiments are performed on the IEEE 9-bus test\nsystem and a modified version that includes solar and wind farms. The findings\ndemonstrate that the AQPF and AQOPF algorithms can accurately perform PF and\nOPF, yielding results that closely match those of classical Newton-Raphson (NR)\nsolvers while also exhibiting robust convergence. Furthermore, the integration\nof renewable energy sources (RES) within the AQOPF framework proves effective\nin maintaining system stability and performance, even under variable generation\nconditions. These findings highlight the potential of quantum computing to\nsignificantly enhance the modeling and control of future power grids,\nparticularly in systems with high renewable energy penetration.", "published": "2025-05-19 16:58:58", "link": "http://arxiv.org/abs/2505.13356v1", "categories": ["eess.SY", "cs.NA", "cs.SY", "math.NA"], "primary_category": "eess.SY"}
{"title": "A parametric finite element method for a degenerate multi-phase Stefan problem with triple junctions", "abstract": "In this study, we propose a parametric finite element method for a degenerate\nmulti-phase Stefan problem with triple junctions. This model describes the\nenergy-driven motion of a surface cluster whose distributional solution was\nstudied by Garcke and Sturzenhecker. We approximate the weak formulation of\nthis sharp interface model by an unfitted finite element method that uses\nparametric elements for the representation of the moving interfaces. We\nestablish existence and uniqueness of the discrete solution and prove\nunconditional stability of the proposed scheme. Moreover, a modification of the\noriginal scheme leads to a structure-preserving variant, in that it conserves\nthe discrete analogue of a quantity that is preserved by the classical\nsolution. Some numerical results demonstrate the applicability of our\nintroduced schemes.", "published": "2025-05-19 14:23:35", "link": "http://arxiv.org/abs/2505.13165v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Ocean wave spectrum reconstruction from HF radar data and its application to wave height estimation", "abstract": "Real-time estimation of ocean wave heights using high-frequency (HF) radar\nhas attracted great attention. This method offers the benefit of easy\nmaintenance by virtue of its ground-based installation. However, it is\nadversely affected by issues such as low estimation accuracy. As described\nherein, we propose an algorithm based on the nonnegative sparse regularization\nmethod to estimate the energy distribution of the component waves, known as the\nocean wave spectrum, from HF radar data. After proving a stability estimate of\nthis algorithm, we perform numerical simulations to verify the proposed\nmethod's effectiveness.", "published": "2025-05-19 14:00:22", "link": "http://arxiv.org/abs/2505.13132v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "An implicit regularized enthalpy Lattice Boltzmann Method for the Stefan problem", "abstract": "Solving the Stefan problem, also referred as the heat conduction problem with\nphase change, is a necessary step to solve phase change problems with\nconvection. In this article, we are interested in using the Lattice Boltzmann\nMethod (LBM) to solve the Stefan problem using a regularized total enthalpy\nmodel. The liquid fraction is treated as a nonlinear source/sink term, that\ninvolves the time derivative of the solution. The resulting non-linear system\nis solved using a Newton algorithm. By conserving the locality of the problem,\nthis method is highly scalable, while keeping a high accuracy. The newly\ndeveloped scheme is analyzed theoretically through a Chapman-Enskog expansion\nand illustrated numerically with 1D and 2D benchmarks.", "published": "2025-05-19 13:27:53", "link": "http://arxiv.org/abs/2505.13097v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Revisiting the Slip Boundary Condition: Surface Roughness as a Hidden Tuning Parameter", "abstract": "In this paper, we investigate the effect of boundary surface roughness on\nnumerical simulations of incompressible fluid flow past a cylinder in two and\nthree spatial dimensions furnished with slip boundary conditions. The governing\nequations are approximated using a continuous finite element method, stabilized\nwith a Galerkin least-squares approach.\n  Through a series of numerical experiments, we demonstrate that: $(i)$ the\nintroduction of surface roughness through numerical discretization error, or\nmesh distortion, makes the potential flow solution unstable; $(ii)$ when\nnumerical surface roughness and mesh distortion are minimized by using\nhigh-order isoparametric geometry mappings, a stable potential flow is obtained\nin both two and three dimensions; $(iii)$ numerical surface roughness, mesh\ndistortion and refinement level can be used as control parameters to manipulate\ndrag and lift forces resulting in numerical values spanning more than an order\nof magnitude.\n  Our results cast some doubt on the predictive capability of the slip boundary\ncondition for wall modeling in turbulent simulations of incompressible flow.", "published": "2025-05-19 13:04:32", "link": "http://arxiv.org/abs/2505.13068v1", "categories": ["physics.flu-dyn", "cs.NA", "math.NA"], "primary_category": "physics.flu-dyn"}
{"title": "Multi-Level Monte Carlo Training of Neural Operators", "abstract": "Operator learning is a rapidly growing field that aims to approximate\nnonlinear operators related to partial differential equations (PDEs) using\nneural operators. These rely on discretization of input and output functions\nand are, usually, expensive to train for large-scale problems at\nhigh-resolution. Motivated by this, we present a Multi-Level Monte Carlo (MLMC)\napproach to train neural operators by leveraging a hierarchy of resolutions of\nfunction dicretization. Our framework relies on using gradient corrections from\nfewer samples of fine-resolution data to decrease the computational cost of\ntraining while maintaining a high level accuracy. The proposed MLMC training\nprocedure can be applied to any architecture accepting multi-resolution data.\nOur numerical experiments on a range of state-of-the-art models and test-cases\ndemonstrate improved computational efficiency compared to traditional\nsingle-resolution training approaches, and highlight the existence of a Pareto\ncurve between accuracy and computational time, related to the number of samples\nper resolution.", "published": "2025-05-19 10:26:28", "link": "http://arxiv.org/abs/2505.12940v1", "categories": ["cs.LG", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "RGNMR: A Gauss-Newton method for robust matrix completion with theoretical guarantees", "abstract": "Recovering a low rank matrix from a subset of its entries, some of which may\nbe corrupted, is known as the robust matrix completion (RMC) problem. Existing\nRMC methods have several limitations: they require a relatively large number of\nobserved entries; they may fail under overparametrization, when their assumed\nrank is higher than the correct one; and many of them fail to recover even\nmildly ill-conditioned matrices. In this paper we propose a novel RMC method,\ndenoted $\\texttt{RGNMR}$, which overcomes these limitations. $\\texttt{RGNMR}$\nis a simple factorization-based iterative algorithm, which combines a\nGauss-Newton linearization with removal of entries suspected to be outliers. On\nthe theoretical front, we prove that under suitable assumptions,\n$\\texttt{RGNMR}$ is guaranteed exact recovery of the underlying low rank\nmatrix. Our theoretical results improve upon the best currently known for\nfactorization-based methods. On the empirical front, we show via several\nsimulations the advantages of $\\texttt{RGNMR}$ over existing RMC methods, and\nin particular its ability to handle a small number of observed entries,\noverparameterization of the rank and ill-conditioned matrices.", "published": "2025-05-19 09:58:33", "link": "http://arxiv.org/abs/2505.12919v1", "categories": ["cs.LG", "cs.NA", "math.NA", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Implicit numerical approximation for stochastic delay differential equations with the nonlinear diffusion term in the infinite horizon", "abstract": "This paper investigates the approximation of stochastic delay differential\nequations (SDDEs) via the backward Euler-Maruyama (BEM) method under\ngeneralized monotonicity and Khasminskii-type conditions in the infinite\nhorizon. First, by establishing the uniform moment boundedness and finite-time\nstrong convergence of the BEM method, we prove that for sufficiently small step\nsizes, the numerical approximations strongly converge to the underlying\nsolution in the infinite horizon with a rate of $1/2$, which coincides with the\noptimal finite-time strong convergence rate.\n  Next, we establish the uniform boundedness and convergence in probability for\nthe segment processes associated with the BEM method. This analysis further\ndemonstrates that the probability measures of the numerical segment processes\nconverge to the underlying invariant measure of the SDDEs. Finally, a numerical\nexample and simulations are provided to illustrate the theoretical results.", "published": "2025-05-19 09:11:44", "link": "http://arxiv.org/abs/2505.12883v1", "categories": ["math.NA", "cs.NA", "math.PR", "60H35, 65C30, 65L20,", "G.1.7; G.3"], "primary_category": "math.NA"}
{"title": "Identifiability of Nonnegative Tucker Decompositions -- Part I: Theory", "abstract": "Tensor decompositions have become a central tool in data science, with\napplications in areas such as data analysis, signal processing, and machine\nlearning. A key property of many tensor decompositions, such as the canonical\npolyadic decomposition, is identifiability: the factors are unique, up to\ntrivial scaling and permutation ambiguities. This allows one to recover the\ngroundtruth sources that generated the data. The Tucker decomposition (TD) is a\ncentral and widely used tensor decomposition model. However, it is in general\nnot identifiable. In this paper, we study the identifiability of the\nnonnegative TD (nTD). By adapting and extending identifiability results of\nnonnegative matrix factorization (NMF), we provide uniqueness results for nTD.\nOur results require the nonnegative matrix factors to have some degree of\nsparsity (namely, satisfy the separability condition, or the sufficiently\nscattered condition), while the core tensor only needs to have some slices (or\nlinear combinations of them) or unfoldings with full column rank (but does not\nneed to be nonnegative). Under such conditions, we derive several procedures,\nusing either unfoldings or slices of the input tensor, to obtain identifiable\nnTDs by minimizing the volume of unfoldings or slices of the core tensor.", "published": "2025-05-19 05:08:37", "link": "http://arxiv.org/abs/2505.12713v1", "categories": ["math.NA", "cs.LG", "cs.NA", "eess.SP", "stat.ML"], "primary_category": "math.NA"}
{"title": "Geometric Formalization of First-Order Stochastic Dominance in $N$ Dimensions: A Tractable Path to Multi-Dimensional Economic Decision Analysis", "abstract": "This paper introduces and formally verifies a novel geometric framework for\nfirst-order stochastic dominance (FSD) in $N$ dimensions using the Lean 4\ntheorem prover. Traditional analytical approaches to multi-dimensional\nstochastic dominance rely heavily on complex measure theory and multivariate\ncalculus, creating significant barriers to formalization in proof assistants.\nOur geometric approach characterizes $N$-dimensional FSD through direct\ncomparison of survival probabilities in upper-right orthants, bypassing the\nneed for complex integration theory. We formalize key definitions and prove the\nequivalence between traditional FSD requirements and our geometric\ncharacterization. This approach achieves a more tractable and intuitive path to\nformal verification while maintaining mathematical rigor. We demonstrate how\nthis framework directly enables formal analysis of multi-dimensional economic\nproblems in portfolio selection, risk management, and welfare analysis. The\nwork establishes a foundation for further development of verified\ndecision-making tools in economics and finance, particularly for high-stakes\ndomains requiring rigorous guarantees.", "published": "2025-05-19 08:28:25", "link": "http://arxiv.org/abs/2505.12840v1", "categories": ["cs.LO", "econ.TH", "q-fin.CP"], "primary_category": "cs.LO"}
{"title": "Filtering in a hazard rate change-point model with financial and life-insurance applications", "abstract": "This paper develops a continuous-time filtering framework for estimating a\nhazard rate subject to an unobservable change-point. This framework arises\nnaturally in both financial and insurance applications, where the default\nintensity of a firm or the mortality rate of an individual may experience a\nsudden jump at an unobservable time, representing, for instance, a shift in the\nfirm's risk profile or a deterioration in an individual's health status. By\nemploying a progressive enlargement of filtration, we integrate noisy\nobservations of the hazard rate with default-related information. We\ncharacterise the filter, i.e. the conditional probability of the change-point\ngiven the information flow, as the unique strong solution to a stochastic\ndifferential equation driven by the innovation process enriched with the\ndiscontinuous component. A sensitivity analysis and a comparison of the\nfilter's behaviour under various information structures are provided. Our\nframework further allows for the derivation of an explicit formula for the\nsurvival probability conditional on partial information. This result applies to\nthe pricing of credit-sensitive financial instruments such as defaultable\nbonds, credit default swaps, and life insurance contracts. Finally, a numerical\nanalysis illustrates how partial information leads to delayed adjustments in\nthe estimation of the hazard rate and consequently to mispricing of\ncredit-sensitive instruments when compared to a full-information setting.", "published": "2025-05-19 14:41:52", "link": "http://arxiv.org/abs/2505.13185v1", "categories": ["q-fin.MF", "math.PR", "q-fin.PR", "60G35, 91G40, 91G05, 60G55"], "primary_category": "q-fin.MF"}
{"title": "Characterizing asymmetric and bimodal long-term financial return distributions through quantum walks", "abstract": "The analysis of logarithmic return distributions defined over large time\nscales is crucial for understanding the long-term dynamics of asset price\nmovements. For large time scales of the order of two trading years, the\nanticipated Gaussian behavior of the returns often does not emerge, and their\ndistributions often exhibit a high level of asymmetry and bimodality. These\nfeatures are inadequately captured by the majority of classical models to\naddress financial time series and return distributions. In the presented\nanalysis, we use a model based on the discrete-time quantum walk to\ncharacterize the observed asymmetry and bimodality. The quantum walk\ndistinguishes itself from a classical diffusion process by the occurrence of\ninterference effects, which allows for the generation of bimodal and asymmetric\nprobability distributions. By capturing the broader trends and patterns that\nemerge over extended periods, this analysis complements traditional short-term\nmodels and offers opportunities to more accurately describe the probabilistic\nstructure underlying long-term financial decisions.", "published": "2025-05-19 12:04:10", "link": "http://arxiv.org/abs/2505.13019v1", "categories": ["q-fin.ST", "q-fin.GN", "quant-ph", "91B80"], "primary_category": "q-fin.ST"}
{"title": "Hierarchical Representations for Evolving Acyclic Vector Autoregressions (HEAVe)", "abstract": "Causal networks offer an intuitive framework to understand influence\nstructures within time series systems. However, the presence of cycles can\nobscure dynamic relationships and hinder hierarchical analysis. These networks\nare typically identified through multivariate predictive modelling, but\nenforcing acyclic constraints significantly increases computational and\nanalytical complexity. Despite recent advances, there remains a lack of simple,\nflexible approaches that are easily tailorable to specific problem instances.\nWe propose an evolutionary approach to fitting acyclic vector autoregressive\nprocesses and introduces a novel hierarchical representation that directly\nmodels structural elements within a time series system. On simulated datasets,\nour model retains most of the predictive accuracy of unconstrained models and\noutperforms permutation-based alternatives. When applied to a dataset of 100\ncryptocurrency return series, our method generates acyclic causal networks\ncapturing key structural properties of the unconstrained model. The acyclic\nnetworks are approximately sub-graphs of the unconstrained networks, and most\nof the removed links originate from low-influence nodes. Given the high levels\nof feature preservation, we conclude that this cryptocurrency price system\nfunctions largely hierarchically. Our findings demonstrate a flexible,\nintuitive approach for identifying hierarchical causal networks in time series\nsystems, with broad applications to fields like econometrics and social network\nanalysis.", "published": "2025-05-19 07:33:01", "link": "http://arxiv.org/abs/2505.12806v1", "categories": ["q-fin.ST", "cs.NE"], "primary_category": "q-fin.ST"}
{"title": "Joint stochastic localization and applications", "abstract": "Stochastic localization is a pathwise analysis technique originating from\nconvex geometry. This paper explores certain algorithmic aspects of stochastic\nlocalization as a computational tool. First, we unify various existing\nstochastic localization schemes and discuss their localization rates and\nregularization. We then introduce a joint stochastic localization framework for\nconstructing couplings between probability distributions. As an initial\napplication, we extend the optimal couplings between normal distributions under\nthe 2-Wasserstein distance to log-concave distributions and derive a normal\napproximation result. As a further application, we introduce a family of\ndistributional distances based on the couplings induced by joint stochastic\nlocalization. Under a specific choice of the localization process, the induced\ndistance is topologically equivalent to the 2-Wasserstein distance for\nprobability measures supported on a common compact set. Moreover, weighted\nversions of this distance are related to several statistical divergences\ncommonly used in practice. The proposed distances also motivate new methods for\ndistribution estimation that are of independent interest.", "published": "2025-05-19 17:47:05", "link": "http://arxiv.org/abs/2505.13410v1", "categories": ["math.ST", "math.PR", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "A Kolmogorov-Arnold Neural Model for Cascading Extremes", "abstract": "This paper addresses the growing concern of cascading extreme events, such as\nan extreme earthquake followed by a tsunami, by presenting a novel method for\nrisk assessment focused on these domino effects. The proposed approach develops\nan extreme value theory framework within a Kolmogorov-Arnold network (KAN) to\nestimate the probability of one extreme event triggering another, conditionally\non a feature vector. An extra layer is added to the KAN's architecture to\nenforce the definition of the parameter of interest within the unit interval,\nand we refer to the resulting neural model as KANE (KAN with Natural\nEnforcement). The proposed method is backed by exhaustive numerical studies and\nfurther illustrated with real-world applications to seismology and climatology.", "published": "2025-05-19 17:17:08", "link": "http://arxiv.org/abs/2505.13370v1", "categories": ["stat.ME", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Scalable Importance Sampling in High Dimensions with Low-Rank Mixture Proposals", "abstract": "Importance sampling is a Monte Carlo technique for efficiently estimating the\nlikelihood of rare events by biasing the sampling distribution towards the rare\nevent of interest. By drawing weighted samples from a learned proposal\ndistribution, importance sampling allows for more sample-efficient estimation\nof rare events or tails of distributions. A common choice of proposal density\nis a Gaussian mixture model (GMM). However, estimating full-rank GMM covariance\nmatrices in high dimensions is a challenging task due to numerical\ninstabilities. In this work, we propose using mixtures of probabilistic\nprincipal component analyzers (MPPCA) as the parametric proposal density for\nimportance sampling methods. MPPCA models are a type of low-rank mixture model\nthat can be fit quickly using expectation-maximization, even in\nhigh-dimensional spaces. We validate our method on three simulated systems,\ndemonstrating consistent gains in sample efficiency and quality of failure\ndistribution characterization.", "published": "2025-05-19 16:44:48", "link": "http://arxiv.org/abs/2505.13335v1", "categories": ["stat.ML", "cs.RO"], "primary_category": "stat.ML"}
{"title": "Discretion in the Loop: Human Expertise in Algorithm-Assisted College Advising", "abstract": "In higher education, many institutions use algorithmic alerts to flag at-risk\nstudents and deliver advising at scale. While much research has focused on\nevaluating algorithmic predictions, relatively little is known about how\ndiscretionary interventions by human experts shape outcomes in\nalgorithm-assisted settings. We study this question using rich quantitative and\nqualitative data from a randomized controlled trial of an algorithm-assisted\nadvising program at Georgia State University. Taking a mixed-methods approach,\nwe examine whether and how advisors use context unavailable to an algorithm to\nguide interventions and influence student success. We develop a causal\ngraphical framework for human expertise in the interventional setting,\nextending prior work on discretion in purely predictive settings. We then test\na necessary condition for discretionary expertise using structured advisor logs\nand student outcomes data, identifying several interventions that meet the\ncriterion for statistical significance. Accordingly, we estimate that 2 out of\n3 interventions taken by advisors in the treatment arm were plausibly \"expertly\ntargeted\" to students using non-algorithmic context. Systematic qualitative\nanalysis of advisor notes corroborates these findings, showing that advisors\nincorporate diverse forms of contextual information--such as personal\ncircumstances, financial issues, and student engagement--into their decisions.\nFinally, we explore the broader implications of human discretion for long-term\noutcomes and equity, using heterogeneous treatment effect estimation. Our\nresults offer theoretical and practical insight into the real-world\neffectiveness of algorithm-supported college advising, and underscore the\nimportance of accounting for human expertise in the design, evaluation, and\nimplementation of algorithmic decision systems.", "published": "2025-05-19 16:34:40", "link": "http://arxiv.org/abs/2505.13325v1", "categories": ["cs.CY", "stat.AP", "stat.ME", "stat.ML"], "primary_category": "cs.CY"}
{"title": "Rapidly Varying Completely Random Measures for Modeling Extremely Sparse Networks", "abstract": "Completely random measures (CRMs) are fundamental to Bayesian nonparametric\nmodels, with applications in clustering, feature allocation, and network\nanalysis. A key quantity of interest is the Laplace exponent, whose asymptotic\nbehavior determines how the random structures scale. When the Laplace exponent\ngrows nearly linearly - known as rapid variation - the induced models exhibit\napproximately linear growth in the number of clusters, features, or edges with\nsample size or network nodes. This regime is especially relevant for modeling\nsparse networks, yet existing CRM constructions lack tractability under rapid\nvariation. We address this by introducing a new class of CRMs with index of\nvariation $\\alpha\\in(0,1]$, defined as mixtures of stable or generalized gamma\nprocesses. These models offer interpretable parameters, include well-known CRMs\nas limiting cases, and retain analytical tractability through a tractable\nLaplace exponent and simple size-biased representation. We analyze the\nasymptotic properties of this CRM class and apply it to the Caron-Fox framework\nfor sparse graphs. The resulting models produce networks with near-linear edge\ngrowth, aligning with empirical evidence from large-scale networks.\nAdditionally, we present efficient algorithms for simulation and posterior\ninference, demonstrating practical advantages through experiments on real-world\nsparse network datasets.", "published": "2025-05-19 14:57:12", "link": "http://arxiv.org/abs/2505.13206v1", "categories": ["math.ST", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "LoD: Loss-difference OOD Detection by Intentionally Label-Noisifying Unlabeled Wild Data", "abstract": "Using unlabeled wild data containing both in-distribution (ID) and\nout-of-distribution (OOD) data to improve the safety and reliability of models\nhas recently received increasing attention. Existing methods either design\ncustomized losses for labeled ID and unlabeled wild data then perform joint\noptimization, or first filter out OOD data from the latter then learn an OOD\ndetector. While achieving varying degrees of success, two potential issues\nremain: (i) Labeled ID data typically dominates the learning of models,\ninevitably making models tend to fit OOD data as IDs; (ii) The selection of\nthresholds for identifying OOD data in unlabeled wild data usually faces\ndilemma due to the unavailability of pure OOD samples. To address these issues,\nwe propose a novel loss-difference OOD detection framework (LoD) by\n\\textit{intentionally label-noisifying} unlabeled wild data. Such operations\nnot only enable labeled ID data and OOD data in unlabeled wild data to jointly\ndominate the models' learning but also ensure the distinguishability of the\nlosses between ID and OOD samples in unlabeled wild data, allowing the classic\nclustering technique (e.g., K-means) to filter these OOD samples without\nrequiring thresholds any longer. We also provide theoretical foundation for\nLoD's viability, and extensive experiments verify its superiority.", "published": "2025-05-19 10:44:52", "link": "http://arxiv.org/abs/2505.12952v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Spline Dimensional Decomposition with Interpolation-based Optimal Knot Selection for Stochastic Dynamic Analysis", "abstract": "Forward uncertainty quantification in dynamic systems is challenging due to\nnon-smooth or locally oscillating nonlinear behaviors. Spline dimensional\ndecomposition (SDD) effectively addresses such nonlinearity by partitioning\ninput coordinates via knot placement, yet its accuracy is highly sensitive to\nthe location of internal knots. Optimizing knots through sequential quadratic\nprogramming can be effective, yet the optimization process becomes\ncomputationally intense. We propose a computationally efficient,\ninterpolation-based method for optimal knot selection in SDD. The method\ninvolves three steps: (1) interpolating input-output profiles, (2) defining\nsubinterval-based reference regions, and (3) selecting optimal knot locations\nat maximum gradient points within each region. The resulting knot vector is\nthen applied to SDD for accurate approximation of non-smooth and locally\noscillating responses. A modal analysis of a lower control arm demonstrates\nthat SDD with the proposed knot selection achieves higher accuracy than SDD\nwith uniformly or randomly spaced knots, and also a Gaussian process surrogate\nmodel. The proposed SDD exhibits the lowest relative variance error (2.89%),\ncompared to SDD with uniformly spaced knots (12.310%), randomly spaced knots\n(15.274%), and Gaussian process (5.319%) in the first natural frequency\ndistribution. All surrogate models are constructed using the same 401\nsimulation datasets, and the relative errors are evaluated against a\n2000-sample Monte Carlo simulation. The scalability and applicability of\nproposed method are demonstrated through stochastic and reliability analyses of\nmathematical functions (N=1, 3) and a lower control arm system (N=10). The\nresults confirm that both second-moment statistics and reliability estimates\ncan be accurately achieved with only a few hundred function evaluations or\nfinite element simulations.", "published": "2025-05-19 09:08:39", "link": "http://arxiv.org/abs/2505.12879v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Causality-Inspired Robustness for Nonlinear Models via Representation Learning", "abstract": "Distributional robustness is a central goal of prediction algorithms due to\nthe prevalent distribution shifts in real-world data. The prediction model aims\nto minimize the worst-case risk among a class of distributions, a.k.a., an\nuncertainty set. Causality provides a modeling framework with a rigorous\nrobustness guarantee in the above sense, where the uncertainty set is\ndata-driven rather than pre-specified as in traditional distributional\nrobustness optimization. However, current causality-inspired robustness methods\npossess finite-radius robustness guarantees only in the linear settings, where\nthe causal relationships among the covariates and the response are linear. In\nthis work, we propose a nonlinear method under a causal framework by\nincorporating recent developments in identifiable representation learning and\nestablish a distributional robustness guarantee. To our best knowledge, this is\nthe first causality-inspired robustness method with such a finite-radius\nrobustness guarantee in nonlinear settings. Empirical validation of the\ntheoretical findings is conducted on both synthetic data and real-world\nsingle-cell data, also illustrating that finite-radius robustness is crucial.", "published": "2025-05-19 08:52:15", "link": "http://arxiv.org/abs/2505.12868v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Theoretical Investigation on Inductive Bias of Isolation Forest", "abstract": "Isolation Forest (iForest) stands out as a widely-used unsupervised anomaly\ndetector valued for its exceptional runtime efficiency and performance on\nlarge-scale tasks. Despite its widespread adoption, a theoretical foundation\nexplaining iForest's success remains unclear. This paper theoretically\ninvestigates the conditions and extent of iForest's effectiveness by analyzing\nits inductive bias through the formulation of depth functions and growth\nprocesses. Since directly analyzing the depth function proves intractable due\nto iForest's random splitting mechanism, we model the growth process of iForest\nas a random walk, enabling us to derive the expected depth function using\ntransition probabilities. Our case studies reveal key inductive biases: iForest\nexhibits lower sensitivity to central anomalies while demonstrating greater\nparameter adaptability compared to $k$-Nearest Neighbor anomaly detectors. Our\nstudy provides theoretical understanding of the effectiveness of iForest and\nestablishes a foundation for further theoretical exploration.", "published": "2025-05-19 08:07:43", "link": "http://arxiv.org/abs/2505.12825v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Testing Identifiability and Transportability with Observational and Experimental Data", "abstract": "Transporting causal information learned from experiments in one population to\nanother is a critical challenge in clinical research and decision-making.\nCausal transportability uses causal graphs to model differences between the\nsource and target populations and identifies conditions under which causal\neffects learned from experiments can be reused in a different population.\nSimilarly, causal identifiability identifies conditions under which causal\neffects can be estimated from observational data. However, these approaches\nrely on knowing the causal graph, which is often unavailable in real-world\nsettings. In this work, we propose a Bayesian method for assessing whether\nZ-specific (conditional) causal effects are both identifiable and\ntransportable, without knowing the causal graph. Our method combines\nexperimental data from the source population with observational data from the\ntarget population to compute the probability that a causal effect is both\nidentifiable from observational data and transportable. When this holds, we\nleverage both observational data from the target domain and experimental data\nfrom the source domain to obtain an unbiased, efficient estimator of the causal\neffect in the target population. Using simulations, we demonstrate that our\nmethod correctly identifies transportable causal effects and improves causal\neffect estimation.", "published": "2025-05-19 07:31:56", "link": "http://arxiv.org/abs/2505.12801v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Few-Step Diffusion via Score identity Distillation", "abstract": "Diffusion distillation has emerged as a promising strategy for accelerating\ntext-to-image (T2I) diffusion models by distilling a pretrained score network\ninto a one- or few-step generator. While existing methods have made notable\nprogress, they often rely on real or teacher-synthesized images to perform well\nwhen distilling high-resolution T2I diffusion models such as Stable Diffusion\nXL (SDXL), and their use of classifier-free guidance (CFG) introduces a\npersistent trade-off between text-image alignment and generation diversity. We\naddress these challenges by optimizing Score identity Distillation (SiD) -- a\ndata-free, one-step distillation framework -- for few-step generation. Backed\nby theoretical analysis that justifies matching a uniform mixture of outputs\nfrom all generation steps to the data distribution, our few-step distillation\nalgorithm avoids step-specific networks and integrates seamlessly into existing\npipelines, achieving state-of-the-art performance on SDXL at 1024x1024\nresolution. To mitigate the alignment-diversity trade-off when real text-image\npairs are available, we introduce a Diffusion GAN-based adversarial loss\napplied to the uniform mixture and propose two new guidance strategies:\nZero-CFG, which disables CFG in the teacher and removes text conditioning in\nthe fake score network, and Anti-CFG, which applies negative CFG in the fake\nscore network. This flexible setup improves diversity without sacrificing\nalignment. Comprehensive experiments on SD1.5 and SDXL demonstrate\nstate-of-the-art performance in both one-step and few-step generation settings,\nalong with robustness to the absence of real images. Our efficient PyTorch\nimplementation, along with the resulting one- and few-step distilled\ngenerators, will be released publicly as a separate branch at\nhttps://github.com/mingyuanzhou/SiD-LSG.", "published": "2025-05-19 03:45:16", "link": "http://arxiv.org/abs/2505.12674v1", "categories": ["cs.CV", "cs.LG", "stat.ML"], "primary_category": "cs.CV"}
{"title": "Distilling a speech and music encoder with task arithmetic", "abstract": "Despite the progress in self-supervised learning (SSL) for speech and music,\nexisting models treat these domains separately, limiting their capacity for\nunified audio understanding. A unified model is desirable for applications that\nrequire general representations, e.g. audio large language models. Nonetheless,\ndirectly training a general model for speech and music is computationally\nexpensive. Knowledge Distillation of teacher ensembles may be a natural\nsolution, but we posit that decoupling the distillation of the speech and music\nSSL models allows for more flexibility. Thus, we propose to learn distilled\ntask vectors and then linearly interpolate them to form a unified speech+music\nmodel. This strategy enables flexible domain emphasis through adjustable\nweights and is also simpler to train. Experiments on speech and music\nbenchmarks demonstrate that our method yields superior overall performance\ncompared to ensemble distillation.", "published": "2025-05-19 15:51:53", "link": "http://arxiv.org/abs/2505.13270v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Hearing from Silence: Reasoning Audio Descriptions from Silent Videos via Vision-Language Model", "abstract": "Humans can intuitively infer sounds from silent videos, but whether\nmultimodal large language models can perform modal-mismatch reasoning without\naccessing target modalities remains relatively unexplored. Current\ntext-assisted-video-to-audio (VT2A) methods excel in video foley tasks but\nstruggle to acquire audio descriptions during inference. We introduce the task\nof Reasoning Audio Descriptions from Silent Videos (SVAD) to address this\nchallenge and investigate vision-language models' (VLMs) capabilities on this\ntask. To further enhance the VLMs' reasoning capacity for the SVAD task, we\nconstruct a CoT-AudioCaps dataset and propose a Chain-of-Thought-based\nsupervised fine-tuning strategy. Experiments on SVAD and subsequent VT2A tasks\ndemonstrate our method's effectiveness in two key aspects: significantly\nimproving VLMs' modal-mismatch reasoning for SVAD and effectively addressing\nthe challenge of acquiring audio descriptions during VT2A inference.", "published": "2025-05-19 12:52:51", "link": "http://arxiv.org/abs/2505.13062v1", "categories": ["cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "MDDM: A Multi-view Discriminative Enhanced Diffusion-based Model for Speech Enhancement", "abstract": "With the development of deep learning, speech enhancement has been greatly\noptimized in terms of speech quality. Previous methods typically focus on the\ndiscriminative supervised learning or generative modeling, which tends to\nintroduce speech distortions or high computational cost. In this paper, we\npropose MDDM, a Multi-view Discriminative enhanced Diffusion-based Model.\nSpecifically, we take the features of three domains (time, frequency and noise)\nas inputs of a discriminative prediction network, generating the preliminary\nspectrogram. Then, the discriminative output can be converted to clean speech\nby several inference sampling steps. Due to the intersection of the\ndistributions between discriminative output and clean target, the smaller\nsampling steps can achieve the competitive performance compared to other\ndiffusion-based methods. Experiments conducted on a public dataset and a\nrealworld dataset validate the effectiveness of MDDM, either on subjective or\nobjective metric.", "published": "2025-05-19 12:15:08", "link": "http://arxiv.org/abs/2505.13029v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Optimal Scalogram for Computational Complexity Reduction in Acoustic Recognition Using Deep Learning", "abstract": "The Continuous Wavelet Transform (CWT) is an effective tool for feature\nextraction in acoustic recognition using Convolutional Neural Networks (CNNs),\nparticularly when applied to non-stationary audio. However, its high\ncomputational cost poses a significant challenge, often leading researchers to\nprefer alternative methods such as the Short-Time Fourier Transform (STFT). To\naddress this issue, this paper proposes a method to reduce the computational\ncomplexity of CWT by optimizing the length of the wavelet kernel and the hop\nsize of the output scalogram. Experimental results demonstrate that the\nproposed approach significantly reduces computational cost while maintaining\nthe robust performance of the trained model in acoustic recognition tasks.", "published": "2025-05-19 12:02:56", "link": "http://arxiv.org/abs/2505.13017v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "DualCodec: A Low-Frame-Rate, Semantically-Enhanced Neural Audio Codec for Speech Generation", "abstract": "Neural audio codecs form the foundational building blocks for language model\n(LM)-based speech generation. Typically, there is a trade-off between frame\nrate and audio quality. This study introduces a low-frame-rate, semantically\nenhanced codec model. Existing approaches distill semantically rich\nself-supervised (SSL) representations into the first-layer codec tokens. This\nwork proposes DualCodec, a dual-stream encoding approach that integrates SSL\nand waveform representations within an end-to-end codec framework. In this\nsetting, DualCodec enhances the semantic information in the first-layer codec\nand enables the codec system to maintain high audio quality while operating at\na low frame rate. Note that a low-frame-rate codec improves the efficiency of\nspeech generation. Experimental results on audio codec and speech generation\ntasks confirm the effectiveness of the proposed DualCodec compared to\nstate-of-the-art codec systems, such as Mimi Codec, SpeechTokenizer, DAC, and\nEncodec. Demos and codes are available at: https://dualcodec.github.io", "published": "2025-05-19 11:41:08", "link": "http://arxiv.org/abs/2505.13000v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Codec-Based Deepfake Source Tracing via Neural Audio Codec Taxonomy", "abstract": "Recent advances in neural audio codec-based speech generation (CoSG) models\nhave produced remarkably realistic audio deepfakes. We refer to deepfake speech\ngenerated by CoSG systems as codec-based deepfake, or CodecFake. Although\nexisting anti-spoofing research on CodecFake predominantly focuses on verifying\nthe authenticity of audio samples, almost no attention was given to tracing the\nCoSG used in generating these deepfakes. In CodecFake generation, processes\nsuch as speech-to-unit encoding, discrete unit modeling, and unit-to-speech\ndecoding are fundamentally based on neural audio codecs. Motivated by this, we\nintroduce source tracing for CodecFake via neural audio codec taxonomy, which\ndissects neural audio codecs to trace CoSG. Our experimental results on the\nCodecFake+ dataset provide promising initial evidence for the feasibility of\nCodecFake source tracing while also highlighting several challenges that\nwarrant further investigation.", "published": "2025-05-19 11:31:32", "link": "http://arxiv.org/abs/2505.12994v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Personalized Fine-Tuning with Controllable Synthetic Speech from LLM-Generated Transcripts for Dysarthric Speech Recognition", "abstract": "In this work, we present our submission to the Speech Accessibility Project\nchallenge for dysarthric speech recognition. We integrate parameter-efficient\nfine-tuning with latent audio representations to improve an encoder-decoder ASR\nsystem. Synthetic training data is generated by fine-tuning Parler-TTS to mimic\ndysarthric speech, using LLM-generated prompts for corpus-consistent target\ntranscripts. Personalization with x-vectors consistently reduces word error\nrates (WERs) over non-personalized fine-tuning. AdaLoRA adapters outperform\nfull fine-tuning and standard low-rank adaptation, achieving relative WER\nreductions of ~23% and ~22%, respectively. Further improvements (~5% WER\nreduction) come from incorporating wav2vec 2.0-based audio representations.\nTraining with synthetic dysarthric speech yields up to ~7% relative WER\nimprovement over personalized fine-tuning alone.", "published": "2025-05-19 11:28:27", "link": "http://arxiv.org/abs/2505.12991v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "The Computation of Generalized Embeddings for Underwater Acoustic Target Recognition using Contrastive Learning", "abstract": "The increasing level of sound pollution in marine environments poses an\nincreased threat to ocean health, making it crucial to monitor underwater\nnoise. By monitoring this noise, the sources responsible for this pollution can\nbe mapped. Monitoring is performed by passively listening to these sounds. This\ngenerates a large amount of data records, capturing a mix of sound sources such\nas ship activities and marine mammal vocalizations. Although machine learning\noffers a promising solution for automatic sound classification, current\nstate-of-the-art methods implement supervised learning. This requires a large\namount of high-quality labeled data that is not publicly available. In\ncontrast, a massive amount of lower-quality unlabeled data is publicly\navailable, offering the opportunity to explore unsupervised learning\ntechniques. This research explores this possibility by implementing an\nunsupervised Contrastive Learning approach. Here, a Conformer-based encoder is\noptimized by the so-called Variance-Invariance-Covariance Regularization loss\nfunction on these lower-quality unlabeled data and the translation to the\nlabeled data is made. Through classification tasks involving recognizing ship\ntypes and marine mammal vocalizations, our method demonstrates to produce\nrobust and generalized embeddings. This shows to potential of unsupervised\nmethods for various automatic underwater acoustic analysis tasks.", "published": "2025-05-19 09:37:46", "link": "http://arxiv.org/abs/2505.12904v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "OZSpeech: One-step Zero-shot Speech Synthesis with Learned-Prior-Conditioned Flow Matching", "abstract": "Text-to-speech (TTS) systems have seen significant advancements in recent\nyears, driven by improvements in deep learning and neural network\narchitectures. Viewing the output speech as a data distribution, previous\napproaches often employ traditional speech representations, such as waveforms\nor spectrograms, within the Flow Matching framework. However, these methods\nhave limitations, including overlooking various speech attributes and incurring\nhigh computational costs due to additional constraints introduced during\ntraining. To address these challenges, we introduce OZSpeech, the first TTS\nmethod to explore optimal transport conditional flow matching with one-step\nsampling and a learned prior as the condition, effectively disregarding\npreceding states and reducing the number of sampling steps. Our approach\noperates on disentangled, factorized components of speech in token format,\nenabling accurate modeling of each speech attribute, which enhances the TTS\nsystem's ability to precisely clone the prompt speech. Experimental results\nshow that our method achieves promising performance over existing methods in\ncontent accuracy, naturalness, prosody generation, and speaker style\npreservation. Audio samples are available at our demo page\nhttps://ozspeech.github.io/OZSpeech_Web/.", "published": "2025-05-19 07:31:55", "link": "http://arxiv.org/abs/2505.12800v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SounDiT: Geo-Contextual Soundscape-to-Landscape Generation", "abstract": "We present a novel and practically significant problem-Geo-Contextual\nSoundscape-to-Landscape (GeoS2L) generation-which aims to synthesize\ngeographically realistic landscape images from environmental soundscapes. Prior\naudio-to-image generation methods typically rely on general-purpose datasets\nand overlook geographic and environmental contexts, resulting in unrealistic\nimages that are misaligned with real-world environmental settings. To address\nthis limitation, we introduce a novel geo-contextual computational framework\nthat explicitly integrates geographic knowledge into multimodal generative\nmodeling. We construct two large-scale geo-contextual multimodal datasets,\nSoundingSVI and SonicUrban, pairing diverse soundscapes with real-world\nlandscape images. We propose SounDiT, a novel Diffusion Transformer (DiT)-based\nmodel that incorporates geo-contextual scene conditioning to synthesize\ngeographically coherent landscape images. Furthermore, we propose a\npractically-informed geo-contextual evaluation framework, the Place Similarity\nScore (PSS), across element-, scene-, and human perception-levels to measure\nconsistency between input soundscapes and generated landscape images. Extensive\nexperiments demonstrate that SounDiT outperforms existing baselines in both\nvisual fidelity and geographic settings. Our work not only establishes\nfoundational benchmarks for GeoS2L generation but also highlights the\nimportance of incorporating geographic domain knowledge in advancing multimodal\ngenerative models, opening new directions at the intersection of generative AI,\ngeography, urban planning, and environmental sciences.", "published": "2025-05-19 05:47:13", "link": "http://arxiv.org/abs/2505.12734v1", "categories": ["cs.SD", "cs.AI", "cs.GR", "cs.HC", "eess.AS"], "primary_category": "cs.SD"}
{"title": "RoVo: Robust Voice Protection Against Unauthorized Speech Synthesis with Embedding-Level Perturbations", "abstract": "With the advancement of AI-based speech synthesis technologies such as Deep\nVoice, there is an increasing risk of voice spoofing attacks, including voice\nphishing and fake news, through unauthorized use of others' voices. Existing\ndefenses that inject adversarial perturbations directly into audio signals have\nlimited effectiveness, as these perturbations can easily be neutralized by\nspeech enhancement methods. To overcome this limitation, we propose RoVo\n(Robust Voice), a novel proactive defense technique that injects adversarial\nperturbations into high-dimensional embedding vectors of audio signals,\nreconstructing them into protected speech. This approach effectively defends\nagainst speech synthesis attacks and also provides strong resistance to speech\nenhancement models, which represent a secondary attack threat.\n  In extensive experiments, RoVo increased the Defense Success Rate (DSR) by\nover 70% compared to unprotected speech, across four state-of-the-art speech\nsynthesis models. Specifically, RoVo achieved a DSR of 99.5% on a commercial\nspeaker-verification API, effectively neutralizing speech synthesis attack.\nMoreover, RoVo's perturbations remained robust even under strong speech\nenhancement conditions, outperforming traditional methods. A user study\nconfirmed that RoVo preserves both naturalness and usability of protected\nspeech, highlighting its effectiveness in complex and evolving threat\nscenarios.", "published": "2025-05-19 04:14:58", "link": "http://arxiv.org/abs/2505.12686v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Text2midi-InferAlign: Improving Symbolic Music Generation with Inference-Time Alignment", "abstract": "We present Text2midi-InferAlign, a novel technique for improving symbolic\nmusic generation at inference time. Our method leverages text-to-audio\nalignment and music structural alignment rewards during inference to encourage\nthe generated music to be consistent with the input caption. Specifically, we\nintroduce two objectives scores: a text-audio consistency score that measures\nrhythmic alignment between the generated music and the original text caption,\nand a harmonic consistency score that penalizes generated music containing\nnotes inconsistent with the key. By optimizing these alignment-based objectives\nduring the generation process, our model produces symbolic music that is more\nclosely tied to the input captions, thereby improving the overall quality and\ncoherence of the generated compositions. Our approach can extend any existing\nautoregressive model without requiring further training or fine-tuning. We\nevaluate our work on top of Text2midi - an existing text-to-midi generation\nmodel, demonstrating significant improvements in both objective and subjective\nevaluation metrics.", "published": "2025-05-19 03:36:06", "link": "http://arxiv.org/abs/2505.12669v1", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS", "68T07", "I.2.1"], "primary_category": "cs.SD"}
{"title": "Chain-Talker: Chain Understanding and Rendering for Empathetic Conversational Speech Synthesis", "abstract": "Conversational Speech Synthesis (CSS) aims to align synthesized speech with\nthe emotional and stylistic context of user-agent interactions to achieve\nempathy. Current generative CSS models face interpretability limitations due to\ninsufficient emotional perception and redundant discrete speech coding. To\naddress the above issues, we present Chain-Talker, a three-stage framework\nmimicking human cognition: Emotion Understanding derives context-aware emotion\ndescriptors from dialogue history; Semantic Understanding generates compact\nsemantic codes via serialized prediction; and Empathetic Rendering synthesizes\nexpressive speech by integrating both components. To support emotion modeling,\nwe develop CSS-EmCap, an LLM-driven automated pipeline for generating precise\nconversational speech emotion captions. Experiments on three benchmark datasets\ndemonstrate that Chain-Talker produces more expressive and empathetic speech\nthan existing methods, with CSS-EmCap contributing to reliable emotion\nmodeling. The code and demos are available at:\nhttps://github.com/AI-S2-Lab/Chain-Talker.", "published": "2025-05-19 01:24:52", "link": "http://arxiv.org/abs/2505.12597v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Frequency-Dependent Power Consumption Modeling of CMOS Transmitters for WNoC Architectures", "abstract": "Wireless Network-on-Chip (WNoC) systems, which wirelessly interconnect the\nchips of a computing system, have been proposed as a complement to existing\nchip-to-chip wired links. However, their feasibility depends on the\navailability of custom-designed high-speed, tiny, ultra-efficient transceivers.\nThis represents a challenge due to the tradeoffs between bandwidth, area, and\nenergy efficiency that are found as frequency increases, which suggests that\nthere is an optimal frequency region. To aid in the search for such an optimal\ndesign point, this paper presents a behavioral model that quantifies the\nexpected power consumption of oscillators, mixers, and power amplifiers as a\nfunction of frequency. The model is built on extensive surveys of the\nrespective sub-blocks, all based on experimental data. By putting together the\nmodels of the three sub-blocks, a comprehensive power model is obtained, which\nwill aid in selecting the optimal operating frequency for WNoC systems.", "published": "2025-05-19 16:26:53", "link": "http://arxiv.org/abs/2505.13310v1", "categories": ["eess.SY", "cs.SY", "eess.SP"], "primary_category": "eess.SY"}
{"title": "Distributed Beamforming Using Decentralized Time Synchronization in a Six-Element Array", "abstract": "We demonstrate a distributed beamforming and beamsteering from a six-node\ndistributed phased array using fully wireless coordination with decentralized\ntime synchronization. In wireless applications such as distributed beamforming,\nhigh-accuracy time synchronization across the array is crucial for high\ncoherent gain. The decentralized time synchronization method employed is based\non the average consensus algorithm and the two-way time transfer method\npresented in our previous work, which achieved picosecond time synchronization\nwith a cabled frequency reference. The system presented in this paper utilizes\na centralized wireless frequency transfer method to achieve wireless frequency\nsyntonization in a fully wireless coordination and a distributed computing\nsystem architecture. We experimentally evaluate system performance through\nbeamforming and beamsteering to a receiver 16.3 m away from the six-node\nnon-uniformly distributed antenna array, achieving an average coherent gain of\n98% of the ideal gain at a carrier frequency of 1.05 GHz. The average time\nsynchronization accuracy achieved was less than 36 ps.", "published": "2025-05-19 15:30:33", "link": "http://arxiv.org/abs/2505.13248v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Algorithms for Nonlinear Mixed-Integer Location Estimation", "abstract": "For three decades, carrier-phase observations have been used to obtain the\nmost accurate location estimates using global navigation satellite systems\n(GNSS). These estimates are computed by minimizing a nonlinear mixed-integer\nleast-squares problem. Existing algorithms linearize the problem, orthogonally\nproject it to eliminate real variables, and then solve the integer least-square\nproblem. There is now considerable interest in developing similar localization\ntechniques for terrestrial and indoor settings. We show that algorithms that\nlinearize first fail in these settings and we propose several algorithms for\ncomputing the estimates. Some of our algorithms are elimination algorithms that\nstart by eliminating the non-linear terms in the constraints; others construct\na geometric arrangement that allows us to efficiently enumerate integer\nsolutions (in polynomial time). We focus on simplified localization problems in\nwhich the measurements are range (distance) measurements and carrier phase\nrange measurements, with no nuisance parameters. The simplified problem allows\nus to focus on the core question of untangling the nonlinearity and the integer\nnature of some parameters. We show using simulations that the new algorithms\nare effective at close ranges at which the linearize-first approach fails.", "published": "2025-05-19 11:17:17", "link": "http://arxiv.org/abs/2505.12980v1", "categories": ["eess.SP", "cs.MS", "math.OC"], "primary_category": "eess.SP"}
{"title": "Multi-Reference and Adaptive Nonlinear Transform Source-Channel Coding for Wireless Image Semantic Transmission", "abstract": "We propose a multi-reference and adaptive nonlinear transform source-channel\ncoding (MA-NTSCC) system for wireless image semantic transmission to improve\nrate-distortion (RD) performance by introducing multi-dimensional contexts into\nthe entropy model of the state-of-the-art (SOTA) NTSCC system. Improvements in\nRD performance of the proposed MA-NTSCC system are particularly significant in\nhigh-resolution image transmission under low bandwidth constraints. The\nproposed multi-reference entropy model leverages correlations within the latent\nrepresentation in both spatial and channel dimensions. In the spatial\ndimension, the latent representation is divided into anchors and non-anchors in\na checkerboard pattern, where anchors serve as reference to estimate the mutual\ninformation between anchors and non-anchors. In the channel dimension, the\nlatent representation is partitioned into multiple groups, and features in\nprevious groups are analyzed to estimate the mutual information between\nfeatures in previous and current groups. Taking mutual information into\naccount, the entropy model provides an accurate estimation on the entropy,\nwhich enables efficient bandwidth allocation and enhances RD performance.\nAdditionally, the proposed lightweight adaptation modules enable the proposed\nMA-NTSCC model to achieve transmission quality comparable to separately trained\nmodels across various channel conditions and bandwidth requirements. In\ncontrast, traditional NTSCC models provide signal-to-noise ratio\n(SNR)-distortion performance degrading with channel quality deviating from the\nfixed training SNR, and consume inflexible bandwidth to transmit an image.\nComprehensive experiments are conducted to verify the peak signal-to-noise\nratio (PSNR) performance and adaptability of the proposed MA-NTSCC model\nsuperior to SOTA methods over both additive white Gaussian noise channel and\nRayleigh fading channel.", "published": "2025-05-19 05:55:06", "link": "http://arxiv.org/abs/2505.12740v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Secrecy Capacity of Hybrid VLC-RF Systems with Light Energy Harvesting", "abstract": "This paper studies the performance of physical layer security (PLS) in a\nmulti-user hybrid heterogeneous visible light communication (VLC) and radio\nfrequency (RF) wireless communication system with simultaneous lightwave\ninformation and power transfer (SLIPT). In the considered system, VLC is used\nfor downlink (DL) while RF is employed for uplink (UL) transmission. In\naddition, to support multiple users, time division multiple access (TDMA) is\nassumed for both DL and UL channels. In the DL, each user receives information\nduring its allocated time slot of the TDMA frame and harvests energy from the\nreceived signal outside the time slot. The harvested energy is then used for\ntransmitting the signal over the UL channel, which is subject to eavesdropping\nby an unauthorized user. Therefore, PLS is employed to protect the\nconfidentiality of the UL information. Then, an optimization problem is\nformulated to solve the optimal DL and UL time slots that maximize the PLS\nperformance given a target sum rate of the DL. We show that the problem can be\ncast as a difference of convex functions (DC) program, which can be solved\nefficiently using the DC algorithm (DCA).", "published": "2025-05-19 05:53:29", "link": "http://arxiv.org/abs/2505.12739v1", "categories": ["eess.SY", "cs.SY", "eess.SP"], "primary_category": "eess.SY"}
{"title": "Bridging the Modality Gap: Enhancing Channel Prediction with Semantically Aligned LLMs and Knowledge Distillation", "abstract": "Accurate channel prediction is essential in massive multiple-input\nmultiple-output (m-MIMO) systems to improve precoding effectiveness and reduce\nthe overhead of channel state information (CSI) feedback. However, existing\nmethods often suffer from accumulated prediction errors and poor generalization\nto dynamic wireless environments. Large language models (LLMs) have\ndemonstrated remarkable modeling and generalization capabilities in tasks such\nas time series prediction, making them a promising solution. Nevertheless, a\nsignificant modality gap exists between the linguistic knowledge embedded in\npretrained LLMs and the intrinsic characteristics of CSI, posing substantial\nchallenges for their direct application to channel prediction. Moreover, the\nlarge parameter size of LLMs hinders their practical deployment in real-world\ncommunication systems with stringent latency constraints. To address these\nchallenges, we propose a novel channel prediction framework based on\nsemantically aligned large models, referred to as CSI-ALM, which bridges the\nmodality gap between natural language and channel information. Specifically, we\ndesign a cross-modal fusion module that aligns CSI representations .\nAdditionally, we maximize the cosine similarity between word embeddings and CSI\nembeddings to construct semantic cues. To reduce complexity and enable\npractical implementation, we further introduce a lightweight version of the\nproposed approach, called CSI-ALM-Light. This variant is derived via a\nknowledge distillation strategy based on attention matrices. Extensive\nexperimental results demonstrate that CSI-ALM achieves a 1 dB gain over\nstate-of-the-art deep learning methods. Moreover, under limited training data\nconditions, CSI-ALM-Light, with only 0.34M parameters, attains performance\ncomparable to CSI-ALM and significantly outperforms conventional deep learning\napproaches.", "published": "2025-05-19 05:35:35", "link": "http://arxiv.org/abs/2505.12729v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Multi-View Wireless Sensing via Conditional Generative Learning: Framework and Model Design", "abstract": "In this paper, we incorporate physical knowledge into learning-based\nhigh-precision target sensing using the multi-view channel state information\n(CSI) between multiple base stations (BSs) and user equipment (UEs). Such kind\nof multi-view sensing problem can be naturally cast into a conditional\ngeneration framework. To this end, we design a bipartite neural network\narchitecture, the first part of which uses an elaborately designed encoder to\nfuse the latent target features embedded in the multi-view CSI, and then the\nsecond uses them as conditioning inputs of a powerful generative model to guide\nthe target's reconstruction. Specifically, the encoder is designed to capture\nthe physical correlation between the CSI and the target, and also be adaptive\nto the numbers and positions of BS-UE pairs. Therein the view-specific nature\nof CSI is assimilated by introducing a spatial positional embedding scheme,\nwhich exploits the structure of electromagnetic(EM)-wave propagation channels.\nFinally, a conditional diffusion model with a weighted loss is employed to\ngenerate the target's point cloud from the fused features. Extensive numerical\nresults demonstrate that the proposed generative multi-view (Gen-MV) sensing\nframework exhibits excellent flexibility and significant performance\nimprovement on the reconstruction quality of target's shape and EM properties.", "published": "2025-05-19 03:27:24", "link": "http://arxiv.org/abs/2505.12664v1", "categories": ["eess.SP", "cs.AI", "cs.LG"], "primary_category": "eess.SP"}
{"title": "MSCEKF-MIO: Magnetic-Inertial Odometry Based on Multi-State Constraint Extended Kalman Filter", "abstract": "To overcome the limitation of existing indoor odometry technologies which\noften cannot simultaneously meet requirements for accuracy cost-effectiveness,\nand robustness-this paper proposes a novel magnetometer array-aided inertial\nodometry approach, MSCEKF-MIO (Multi-State Constraint Extended Kalman\nFilter-based Magnetic-Inertial Odometry). We construct a magnetic field model\nby fitting measurements from the magnetometer array and then use temporal\nvariations in this model-extracted from continuous observations-to estimate the\ncarrier's absolute velocity. Furthermore, we implement the MSCEKF framework to\nfuse observed magnetic field variations with position and attitude estimates\nfrom inertial navigation system (INS) integration, thereby enabling autonomous,\nhigh-precision indoor relative positioning. Experimental results demonstrate\nthat the proposed algorithm achieves superior velocity estimation accuracy and\nhorizontal positioning precision relative to state-of-the-art magnetic\narray-aided INS algorithms (MAINS). On datasets with trajectory lengths of\n150-250m, the proposed method yields an average horizontal position RMSE of\napproximately 2.5m. In areas with distinctive magnetic features, the\nmagneto-inertial odometry achieves a velocity estimation accuracy of 0.07m/s.\nConsequently, the proposed method offers a novel positioning solution\ncharacterized by low power consumption, cost-effectiveness, and high\nreliability in complex indoor environments.", "published": "2025-05-19 02:39:18", "link": "http://arxiv.org/abs/2505.12634v1", "categories": ["cs.RO", "cs.SY", "eess.SP", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Event-based Star Tracking under Spacecraft Jitter: the e-STURT Dataset", "abstract": "Jitter degrades a spacecraft's fine-pointing ability required for optical\ncommunication, earth observation, and space domain awareness. Development of\njitter estimation and compensation algorithms requires high-fidelity sensor\nobservations representative of on-board jitter. In this work, we present the\nEvent-based Star Tracking Under Jitter (e-STURT) dataset -- the first event\ncamera based dataset of star observations under controlled jitter conditions.\nSpecialized hardware employed for the dataset emulates an event-camera\nundergoing on-board jitter. While the event camera provides asynchronous, high\ntemporal resolution star observations, systematic and repeatable jitter is\nintroduced using a micrometer accurate piezoelectric actuator. Various jitter\nsources are simulated using distinct frequency bands and utilizing both axes of\nmotion. Ground-truth jitter is captured in hardware from the piezoelectric\nactuator. The resulting dataset consists of 200 sequences and is made publicly\navailable. This work highlights the dataset generation process, technical\nchallenges and the resulting limitations. To serve as a baseline, we propose a\nhigh-frequency jitter estimation algorithm that operates directly on the event\nstream. The e-STURT dataset will enable the development of jitter aware\nalgorithms for mission critical event-based space sensing applications.", "published": "2025-05-19 00:55:40", "link": "http://arxiv.org/abs/2505.12588v1", "categories": ["cs.CV", "eess.SP"], "primary_category": "cs.CV"}
