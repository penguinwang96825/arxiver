{"title": "Analysis of Communication Pattern with Scammers in Enron Corpus", "abstract": "This paper is an exploratory analysis into fraud detection taking Enron email\ncorpus as the case study. The paper posits conclusions like strict servitude\nand unquestionable faith among employees as breeding grounds for sham among\nhigher executives. We also try to infer on the nature of communication between\nfraudulent employees and between non- fraudulent-fraudulent employees", "published": "2015-09-02 13:54:57", "link": "http://arxiv.org/abs/1509.00705v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Neural Attention Model for Abstractive Sentence Summarization", "abstract": "Summarization based on text extraction is inherently limited, but\ngeneration-style abstractive methods have proven challenging to build. In this\nwork, we propose a fully data-driven approach to abstractive sentence\nsummarization. Our method utilizes a local attention-based model that generates\neach word of the summary conditioned on the input sentence. While the model is\nstructurally simple, it can easily be trained end-to-end and scales to a large\namount of training data. The model shows significant performance gains on the\nDUC-2004 shared task compared with several strong baselines.", "published": "2015-09-02 13:20:40", "link": "http://arxiv.org/abs/1509.00685v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancement and Recognition of Reverberant and Noisy Speech by Extending\n  Its Coherence", "abstract": "Most speech enhancement algorithms make use of the short-time Fourier\ntransform (STFT), which is a simple and flexible time-frequency decomposition\nthat estimates the short-time spectrum of a signal. However, the duration of\nshort STFT frames are inherently limited by the nonstationarity of speech\nsignals. The main contribution of this paper is a demonstration of speech\nenhancement and automatic speech recognition in the presence of reverberation\nand noise by extending the length of analysis windows. We accomplish this\nextension by performing enhancement in the short-time fan-chirp transform\n(STFChT) domain, an overcomplete time-frequency representation that is coherent\nwith speech signals over longer analysis window durations than the STFT. This\nextended coherence is gained by using a linear model of fundamental frequency\nvariation of voiced speech signals. Our approach centers around using a\nsingle-channel minimum mean-square error log-spectral amplitude (MMSE-LSA)\nestimator proposed by Habets, which scales coefficients in a time-frequency\ndomain to suppress noise and reverberation. In the case of multiple\nmicrophones, we preprocess the data with either a minimum variance\ndistortionless response (MVDR) beamformer, or a delay-and-sum beamformer (DSB).\nWe evaluate our algorithm on both speech enhancement and recognition tasks for\nthe REVERB challenge dataset. Compared to the same processing done in the STFT\ndomain, our approach achieves significant improvement in terms of objective\nenhancement metrics (including PESQ---the ITU-T standard measurement for speech\nquality). In terms of automatic speech recognition (ASR) performance as\nmeasured by word error rate (WER), our experiments indicate that the STFT with\na long window is more effective for ASR.", "published": "2015-09-02 00:31:40", "link": "http://arxiv.org/abs/1509.00533v1", "categories": ["cs.SD", "cs.CL", "stat.AP"], "primary_category": "cs.SD"}
{"title": "What to talk about and how? Selective Generation using LSTMs with\n  Coarse-to-Fine Alignment", "abstract": "We propose an end-to-end, domain-independent neural encoder-aligner-decoder\nmodel for selective generation, i.e., the joint task of content selection and\nsurface realization. Our model first encodes a full set of over-determined\ndatabase event records via an LSTM-based recurrent neural network, then\nutilizes a novel coarse-to-fine aligner to identify the small subset of salient\nrecords to talk about, and finally employs a decoder to generate free-form\ndescriptions of the aligned, selected records. Our model achieves the best\nselection and generation results reported to-date (with 59% relative\nimprovement in generation) on the benchmark WeatherGov dataset, despite using\nno specialized features or linguistic resources. Using an improved k-nearest\nneighbor beam filter helps further. We also perform a series of ablations and\nvisualizations to elucidate the contributions of our key model components.\nLastly, we evaluate the generalizability of our model on the RoboCup dataset,\nand get results that are competitive with or better than the state-of-the-art,\ndespite being severely data-starved.", "published": "2015-09-02 19:52:56", "link": "http://arxiv.org/abs/1509.00838v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
