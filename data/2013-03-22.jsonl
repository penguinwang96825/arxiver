{"title": "Parameters Optimization for Improving ASR Performance in Adverse Real\n  World Noisy Environmental Conditions", "abstract": "From the existing research it has been observed that many techniques and\nmethodologies are available for performing every step of Automatic Speech\nRecognition (ASR) system, but the performance (Minimization of Word Error\nRecognition-WER and Maximization of Word Accuracy Rate- WAR) of the methodology\nis not dependent on the only technique applied in that method. The research\nwork indicates that, performance mainly depends on the category of the noise,\nthe level of the noise and the variable size of the window, frame, frame\noverlap etc is considered in the existing methods. The main aim of the work\npresented in this paper is to use variable size of parameters like window size,\nframe size and frame overlap percentage to observe the performance of\nalgorithms for various categories of noise with different levels and also train\nthe system for all size of parameters and category of real world noisy\nenvironment to improve the performance of the speech recognition system. This\npaper presents the results of Signal-to-Noise Ratio (SNR) and Accuracy test by\napplying variable size of parameters. It is observed that, it is really very\nhard to evaluate test results and decide parameter size for ASR performance\nimprovement for its resultant optimization. Hence, this study further suggests\nthe feasible and optimum parameter size using Fuzzy Inference System (FIS) for\nenhancing resultant accuracy in adverse real world noisy environmental\nconditions. This work will be helpful to give discriminative training of\nubiquitous ASR system for better Human Computer Interaction (HCI).", "published": "2013-03-22 04:20:16", "link": "http://arxiv.org/abs/1303.5513v1", "categories": ["cs.CL", "cs.SD"], "primary_category": "cs.CL"}
{"title": "Adverse Conditions and ASR Techniques for Robust Speech User Interface", "abstract": "The main motivation for Automatic Speech Recognition (ASR) is efficient\ninterfaces to computers, and for the interfaces to be natural and truly useful,\nit should provide coverage for a large group of users. The purpose of these\ntasks is to further improve man-machine communication. ASR systems exhibit\nunacceptable degradations in performance when the acoustical environments used\nfor training and testing the system are not the same. The goal of this research\nis to increase the robustness of the speech recognition systems with respect to\nchanges in the environment. A system can be labeled as environment-independent\nif the recognition accuracy for a new environment is the same or higher than\nthat obtained when the system is retrained for that environment. Attaining such\nperformance is the dream of the researchers. This paper elaborates some of the\ndifficulties with Automatic Speech Recognition (ASR). These difficulties are\nclassified into Speakers characteristics and environmental conditions, and\ntried to suggest some techniques to compensate variations in speech signal.\nThis paper focuses on the robustness with respect to speakers variations and\nchanges in the acoustical environment. We discussed several different external\nfactors that change the environment and physiological differences that affect\nthe performance of a speech recognition system followed by techniques that are\nhelpful to design a robust ASR system.", "published": "2013-03-22 04:44:37", "link": "http://arxiv.org/abs/1303.5515v1", "categories": ["cs.CL", "cs.SD"], "primary_category": "cs.CL"}
{"title": "Speech Recognition with Deep Recurrent Neural Networks", "abstract": "Recurrent neural networks (RNNs) are a powerful model for sequential data.\nEnd-to-end training methods such as Connectionist Temporal Classification make\nit possible to train RNNs for sequence labelling problems where the\ninput-output alignment is unknown. The combination of these methods with the\nLong Short-term Memory RNN architecture has proved particularly fruitful,\ndelivering state-of-the-art results in cursive handwriting recognition. However\nRNN performance in speech recognition has so far been disappointing, with\nbetter results returned by deep feedforward networks. This paper investigates\n\\emph{deep recurrent neural networks}, which combine the multiple levels of\nrepresentation that have proved so effective in deep networks with the flexible\nuse of long range context that empowers RNNs. When trained end-to-end with\nsuitable regularisation, we find that deep Long Short-term Memory RNNs achieve\na test set error of 17.7% on the TIMIT phoneme recognition benchmark, which to\nour knowledge is the best recorded score.", "published": "2013-03-22 20:55:48", "link": "http://arxiv.org/abs/1303.5778v1", "categories": ["cs.NE", "cs.CL"], "primary_category": "cs.NE"}
