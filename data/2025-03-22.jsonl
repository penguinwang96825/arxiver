{"title": "Think Before Refusal : Triggering Safety Reflection in LLMs to Mitigate False Refusal Behavior", "abstract": "Recent advancements in large language models (LLMs) have demonstrated that\nfine-tuning and human alignment can render LLMs harmless. In practice, such\n\"harmlessness\" behavior is mainly achieved by training models to reject harmful\nrequests, such as \"Explain how to burn down my neighbor's house\", where the\nmodel appropriately declines to respond. However, this approach can\ninadvertently result in false refusal, where models reject benign queries as\nwell, such as \"Tell me how to kill a Python process\". In this work, we\ndemonstrate that prompting safety reflection before generating a response can\nmitigate false refusal behavior. Building on this finding, we introduce the\nThink-Before-Refusal (TBR) schema and conduct safety-aware instruction\nfine-tuning incorporating safety reflection. In an ablation study across 15\npre-trained models, we show that models fine-tuned with safety reflection\nsignificantly reduce false refusal behavior while maintaining safety and\noverall performance compared to those fine-tuned without safety reflection.", "published": "2025-03-22 23:35:49", "link": "http://arxiv.org/abs/2503.17882v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Satisfactory Medical Consultation based on Terminology-Enhanced Information Retrieval and Emotional In-Context Learning", "abstract": "Recent advancements in Large Language Models (LLMs) have marked significant\nprogress in understanding and responding to medical inquiries. However, their\nperformance still falls short of the standards set by professional\nconsultations. This paper introduces a novel framework for medical\nconsultation, comprising two main modules: Terminology-Enhanced Information\nRetrieval (TEIR) and Emotional In-Context Learning (EICL). TEIR ensures\nimplicit reasoning through the utilization of inductive knowledge and key\nterminology retrieval, overcoming the limitations of restricted domain\nknowledge in public databases. Additionally, this module features capabilities\nfor processing long context. The EICL module aids in generating sentences with\nhigh attribute relevance by memorizing semantic and attribute information from\nunlabelled corpora and applying controlled retrieval for the required\ninformation. Furthermore, a dataset comprising 803,564 consultation records was\ncompiled in China, significantly enhancing the model's capability for complex\ndialogues and proactive inquiry initiation. Comprehensive experiments\ndemonstrate the proposed method's effectiveness in extending the context window\nlength of existing LLMs. The experimental outcomes and extensive data validate\nthe framework's superiority over five baseline models in terms of BLEU and\nROUGE performance metrics, with substantial leads in certain capabilities.\nNotably, ablation studies confirm the significance of the TEIR and EICL\ncomponents. In addition, our new framework has the potential to significantly\nimprove patient satisfaction in real clinical consulting situations.", "published": "2025-03-22 23:01:07", "link": "http://arxiv.org/abs/2503.17876v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Enhancing Retrieval Systems with Inference-Time Logical Reasoning", "abstract": "Traditional retrieval methods rely on transforming user queries into vector\nrepresentations and retrieving documents based on cosine similarity within an\nembedding space. While efficient and scalable, this approach often fails to\nhandle complex queries involving logical constructs such as negations,\nconjunctions, and disjunctions. In this paper, we propose a novel\ninference-time logical reasoning framework that explicitly incorporates logical\nreasoning into the retrieval process. Our method extracts logical reasoning\nstructures from natural language queries and then composes the individual\ncosine similarity scores to formulate the final document scores. This approach\nenables the retrieval process to handle complex logical reasoning without\ncompromising computational efficiency. Our results on both synthetic and\nreal-world benchmarks demonstrate that the proposed method consistently\noutperforms traditional retrieval methods across different models and datasets,\nsignificantly improving retrieval performance for complex queries.", "published": "2025-03-22 20:40:18", "link": "http://arxiv.org/abs/2503.17860v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Feather-SQL: A Lightweight NL2SQL Framework with Dual-Model Collaboration Paradigm for Small Language Models", "abstract": "Natural Language to SQL (NL2SQL) has seen significant advancements with large\nlanguage models (LLMs). However, these models often depend on closed-source\nsystems and high computational resources, posing challenges in data privacy and\ndeployment. In contrast, small language models (SLMs) struggle with NL2SQL\ntasks, exhibiting poor performance and incompatibility with existing\nframeworks. To address these issues, we introduce Feather-SQL, a new\nlightweight framework tailored for SLMs. Feather-SQL improves SQL executability\nand accuracy through 1) schema pruning and linking, 2) multi-path and\nmulti-candidate generation. Additionally, we introduce the 1+1 Model\nCollaboration Paradigm, which pairs a strong general-purpose chat model with a\nfine-tuned SQL specialist, combining strong analytical reasoning with\nhigh-precision SQL generation. Experimental results on BIRD demonstrate that\nFeather-SQL improves NL2SQL performance on SLMs, with around 10% boost for\nmodels without fine-tuning. The proposed paradigm raises the accuracy ceiling\nof SLMs to 54.76%, highlighting its effectiveness.", "published": "2025-03-22 16:22:53", "link": "http://arxiv.org/abs/2503.17811v1", "categories": ["cs.CL", "cs.AI", "cs.DB"], "primary_category": "cs.CL"}
{"title": "ParsiPy: NLP Toolkit for Historical Persian Texts in Python", "abstract": "The study of historical languages presents unique challenges due to their\ncomplex orthographic systems, fragmentary textual evidence, and the absence of\nstandardized digital representations of text in those languages. Tackling these\nchallenges needs special NLP digital tools to handle phonetic transcriptions\nand analyze ancient texts. This work introduces ParsiPy, an NLP toolkit\ndesigned to facilitate the analysis of historical Persian languages by offering\nmodules for tokenization, lemmatization, part-of-speech tagging,\nphoneme-to-transliteration conversion, and word embedding. We demonstrate the\nutility of our toolkit through the processing of Parsig (Middle Persian) texts,\nhighlighting its potential for expanding computational methods in the study of\nhistorical languages. Through this work, we contribute to computational\nphilology, offering tools that can be adapted for the broader study of ancient\ntexts and their digital preservation.", "published": "2025-03-22 16:21:29", "link": "http://arxiv.org/abs/2503.17810v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Relation Extraction with Instance-Adapted Predicate Descriptions", "abstract": "Relation extraction (RE) is a standard information extraction task playing a\nmajor role in downstream applications such as knowledge discovery and question\nanswering. Although decoder-only large language models are excelling in\ngenerative tasks, smaller encoder models are still the go to architecture for\nRE. In this paper, we revisit fine-tuning such smaller models using a novel\ndual-encoder architecture with a joint contrastive and cross-entropy loss.\nUnlike previous methods that employ a fixed linear layer for predicate\nrepresentations, our approach uses a second encoder to compute\ninstance-specific predicate representations by infusing them with real entity\nspans from corresponding input instances. We conducted experiments on two\nbiomedical RE datasets and two general domain datasets. Our approach achieved\nF1 score improvements ranging from 1% to 2% over state-of-the-art methods with\na simple but elegant formulation. Ablation studies justify the importance of\nvarious components built into the proposed architecture.", "published": "2025-03-22 15:36:41", "link": "http://arxiv.org/abs/2503.17799v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Every Sample Matters: Leveraging Mixture-of-Experts and High-Quality Data for Efficient and Accurate Code LLM", "abstract": "Recent advancements in code large language models (LLMs) have demonstrated\nremarkable capabilities in code generation and understanding. It is still\nchallenging to build a code LLM with comprehensive performance yet ultimate\nefficiency. Many attempts have been released in the open source community to\nbreak the trade-off between performance and efficiency, such as the Qwen Coder\nseries and the DeepSeek Coder series. This paper introduces yet another attempt\nin this area, namely Ling-Coder-Lite. We leverage the efficient\nMixture-of-Experts (MoE) architecture along with a set of high-quality data\ncuration methods (especially those based on program analytics) to build an\nefficient yet powerful code LLM. Ling-Coder-Lite exhibits on-par performance on\n12 representative coding benchmarks compared to state-of-the-art models of\nsimilar size, such as Qwen2.5-Coder-7B and DeepSeek-Coder-V2-Lite, while\noffering competitive latency and throughput. In practice, we achieve a 50\\%\nreduction in deployment resources compared to the similar-sized dense model\nwithout performance loss. To facilitate further research and development in\nthis area, we open-source our models as well as a substantial portion of\nhigh-quality data for the annealing and post-training stages. The models and\ndata can be accessed\nat~\\url{https://huggingface.co/inclusionAI/Ling-Coder-lite}.", "published": "2025-03-22 15:00:18", "link": "http://arxiv.org/abs/2503.17793v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2.7"], "primary_category": "cs.LG"}
{"title": "Energy-Aware LLMs: A step towards sustainable AI for downstream applications", "abstract": "Advanced Large Language Models (LLMs) have revolutionized various fields,\nincluding communication networks, sparking an innovation wave that has led to\nnew applications and services, and significantly enhanced solution schemes.\nDespite all these impressive developments, most LLMs typically require huge\ncomputational resources, resulting in terribly high energy consumption. Thus,\nthis research study proposes an end-to-end pipeline that investigates the\ntrade-off between energy efficiency and model performance for an LLM during\nfault ticket analysis in communication networks. It further evaluates the\npipeline performance using two real-world datasets for the tasks of root cause\nanalysis and response feedback in a communication network. Our results show\nthat an appropriate combination of quantization and pruning techniques is able\nto reduce energy consumption while significantly improving model performance.", "published": "2025-03-22 14:28:29", "link": "http://arxiv.org/abs/2503.17783v1", "categories": ["cs.PF", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.PF"}
{"title": "Improving Preference Extraction In LLMs By Identifying Latent Knowledge Through Classifying Probes", "abstract": "Large Language Models (LLMs) are often used as automated judges to evaluate\ntext, but their effectiveness can be hindered by various unintentional biases.\nWe propose using linear classifying probes, trained by leveraging differences\nbetween contrasting pairs of prompts, to directly access LLMs' latent knowledge\nand extract more accurate preferences. Through extensive experiments using\nmodels of varying size from four different families and six diverse datasets\nassessing text quality evaluation and common sense reasoning, we demonstrate\nthat both supervised and unsupervised probing approaches consistently\noutperform traditional generation-based judgement while maintaining similar\ncomputational costs. These probes generalise under domain shifts and can even\noutperform finetuned evaluators with the same training data size. Our results\nsuggest linear probing offers an accurate, robust and computationally efficient\napproach for LLM-as-judge tasks while providing interpretable insights into how\nmodels encode judgement-relevant knowledge. Our data and code will be openly\nreleased in the future.", "published": "2025-03-22 12:35:25", "link": "http://arxiv.org/abs/2503.17755v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Building Resource-Constrained Language Agents: A Korean Case Study on Chemical Toxicity Information", "abstract": "Language agents powered by large language models (LLMs) face significant\ndeployment challenges in resource-constrained environments, particularly for\nspecialized domains and less-common languages. This paper presents Tox-chat, a\nKorean chemical toxicity information agent devised within these limitations. We\npropose two key innovations: a context-efficient architecture that reduces\ntoken consumption through hierarchical section search, and a scenario-based\ndialogue generation methodology that effectively distills tool-using\ncapabilities from larger models. Experimental evaluations demonstrate that our\nfine-tuned 8B parameter model substantially outperforms both untuned models and\nbaseline approaches, in terms of DB faithfulness and preference. Our work\noffers valuable insights for researchers developing domain-specific language\nagents under practical constraints.", "published": "2025-03-22 12:34:15", "link": "http://arxiv.org/abs/2503.17753v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Arabic Automated Essay Scoring with Synthetic Data and Error Injection", "abstract": "Automated Essay Scoring (AES) plays a crucial role in assessing language\nlearners' writing quality, reducing grading workload, and providing real-time\nfeedback. Arabic AES systems are particularly challenged by the lack of\nannotated essay datasets. This paper presents a novel framework leveraging\nLarge Language Models (LLMs) and Transformers to generate synthetic Arabic\nessay datasets for AES. We prompt an LLM to generate essays across CEFR\nproficiency levels and introduce controlled error injection using a fine-tuned\nStandard Arabic BERT model for error type prediction. Our approach produces\nrealistic human-like essays, contributing a dataset of 3,040 annotated essays.\nAdditionally, we develop a BERT-based auto-marking system for accurate and\nscalable Arabic essay evaluation. Experimental results demonstrate the\neffectiveness of our framework in improving Arabic AES performance.", "published": "2025-03-22 11:54:10", "link": "http://arxiv.org/abs/2503.17739v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "V2P-Bench: Evaluating Video-Language Understanding with Visual Prompts for Better Human-Model Interaction", "abstract": "Large Vision-Language Models (LVLMs) have made significant progress in the\nfield of video understanding recently. However, current benchmarks uniformly\nlean on text prompts for evaluation, which often necessitate complex\nreferential language and fail to provide precise spatial and temporal\nreferences. This limitation diminishes the experience and efficiency of\nhuman-model interaction. To address this limitation, we propose the Video\nVisual Prompt Benchmark(V2P-Bench), a comprehensive benchmark specifically\ndesigned to evaluate LVLMs' video understanding capabilities in multimodal\nhuman-model interaction scenarios. V2P-Bench includes 980 unique videos and\n1,172 QA pairs, covering 5 main tasks and 12 dimensions, facilitating\ninstance-level fine-grained understanding aligned with human cognition.\nBenchmarking results reveal that even the most powerful models perform poorly\non V2P-Bench (65.4% for GPT-4o and 67.9% for Gemini-1.5-Pro), significantly\nlower than the human experts' 88.3%, highlighting the current shortcomings of\nLVLMs in understanding video visual prompts. We hope V2P-Bench will serve as a\nfoundation for advancing multimodal human-model interaction and video\nunderstanding evaluation. Project page:\nhttps://github.com/gaotiexinqu/V2P-Bench.", "published": "2025-03-22 11:30:46", "link": "http://arxiv.org/abs/2503.17736v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Can LLMs Automate Fact-Checking Article Writing?", "abstract": "Automatic fact-checking aims to support professional fact-checkers by\noffering tools that can help speed up manual fact-checking. Yet, existing\nframeworks fail to address the key step of producing output suitable for\nbroader dissemination to the general public: while human fact-checkers\ncommunicate their findings through fact-checking articles, automated systems\ntypically produce little or no justification for their assessments. Here, we\naim to bridge this gap. We argue for the need to extend the typical automatic\nfact-checking pipeline with automatic generation of full fact-checking\narticles. We first identify key desiderata for such articles through a series\nof interviews with experts from leading fact-checking organizations. We then\ndevelop QRAFT, an LLM-based agentic framework that mimics the writing workflow\nof human fact-checkers. Finally, we assess the practical usefulness of QRAFT\nthrough human evaluations with professional fact-checkers. Our evaluation shows\nthat while QRAFT outperforms several previously proposed text-generation\napproaches, it lags considerably behind expert-written articles. We hope that\nour work will enable further research in this new and important direction.", "published": "2025-03-22 07:56:50", "link": "http://arxiv.org/abs/2503.17684v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Persona Consistency for LLMs' Role-Playing using Persona-Aware Contrastive Learning", "abstract": "In recent years, large language models (LLMs) have achieved breakthrough\nprogress in many dialogue generation tasks. However, their lack of emotion and\nfine-grained role awareness limits the model's ability to provide personalized\nand diverse interactions further. Current methods face high costs in collecting\nhigh-quality annotated data for scenarios such as role-playing, and traditional\nhuman alignment methods are difficult to deploy due to the inherent diversity\nof model behavior in role-playing scenarios. Inspired by the alignment of\nmodels for safety behaviors through RLHF (Reinforcement Learning from Human\nFeedback), in this paper, we revisit model role-playing behavior from the\nperspective of persona alignment and propose a novel annotation-free framework\nnamed \\textbf{\\underline{P}}ersona-Aware \\textbf{\\underline{C}}ontrastive\n\\textbf{\\underline{L}}earning (PCL) to align LLMs' behavior during\nrole-playing, enhancing the model's role consistency. Specifically, we first\ndesign a role chain method to encourage the model to self-question based on the\nrole characteristics and dialogue context to adjust personality consistency.\nThen, we further enhance the model's role-playing strategy through iterative\ncontrastive learning between the use of role characteristics and not.\nExperiments on both black-box and white-box LLMs show that LLMs equipped with\nPCL significantly outperform vanilla LLMs under automatic evaluation methods\n(CharEval \\& GPT-4) and human expert evaluation.", "published": "2025-03-22 06:12:34", "link": "http://arxiv.org/abs/2503.17662v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FairFlow: Mitigating Dataset Biases through Undecided Learning", "abstract": "Language models are prone to dataset biases, known as shortcuts and spurious\ncorrelations in data, which often result in performance drop on new data. We\npresent a new debiasing framework called ``FairFlow'' that mitigates dataset\nbiases by learning to be undecided in its predictions for data samples or\nrepresentations associated with known or unknown biases. The framework\nintroduces two key components: a suite of data and model perturbation\noperations that generate different biased views of input samples, and a\ncontrastive objective that learns debiased and robust representations from the\nresulting biased views of samples. Experiments show that FairFlow outperforms\nexisting debiasing methods, particularly against out-of-domain and hard test\nsamples without compromising the in-domain performance", "published": "2025-03-22 03:35:51", "link": "http://arxiv.org/abs/2503.17632v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "GPBench: A Comprehensive and Fine-Grained Benchmark for Evaluating Large Language Models as General Practitioners", "abstract": "General practitioners (GPs) serve as the cornerstone of primary healthcare\nsystems by providing continuous and comprehensive medical services. However,\ndue to community-oriented nature of their practice, uneven training and\nresource gaps, the clinical proficiency among GPs can vary significantly across\nregions and healthcare settings. Currently, Large Language Models (LLMs) have\ndemonstrated great potential in clinical and medical applications, making them\na promising tool for supporting general practice. However, most existing\nbenchmarks and evaluation frameworks focus on exam-style assessments-typically\nmultiple-choice question-lack comprehensive assessment sets that accurately\nmirror the real-world scenarios encountered by GPs. To evaluate how effectively\nLLMs can make decisions in the daily work of GPs, we designed GPBench, which\nconsists of both test questions from clinical practice and a novel evaluation\nframework. The test set includes multiple-choice questions that assess\nfundamental knowledge of general practice, as well as realistic, scenario-based\nproblems. All questions are meticulously annotated by experts, incorporating\nrich fine-grained information related to clinical management. The proposed LLM\nevaluation framework is based on the competency model for general practice,\nproviding a comprehensive methodology for assessing LLM performance in\nreal-world settings. As the first large-model evaluation set targeting GP\ndecision-making scenarios, GPBench allows us to evaluate current mainstream\nLLMs. Expert assessment and evaluation reveal that in areas such as disease\nstaging, complication recognition, treatment detail, and medication usage,\nthese models exhibit at least ten major shortcomings. Overall, existing LLMs\nare not yet suitable for independent use in real-world GP working scenarios\nwithout human oversight.", "published": "2025-03-22 01:02:44", "link": "http://arxiv.org/abs/2503.17599v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Reasoning with LLMs for Zero-Shot Vulnerability Detection", "abstract": "Automating software vulnerability detection (SVD) remains a critical\nchallenge in an era of increasingly complex and interdependent software\nsystems. Despite significant advances in Large Language Models (LLMs) for code\nanalysis, prevailing evaluation methodologies often lack the\n\\textbf{context-aware robustness} necessary to capture real-world intricacies\nand cross-component interactions. To address these limitations, we present\n\\textbf{VulnSage}, a comprehensive evaluation framework and a dataset curated\nfrom diverse, large-scale open-source system software projects developed in\nC/C++. Unlike prior datasets, it leverages a heuristic noise pre-filtering\napproach combined with LLM-based reasoning to ensure a representative and\nminimally noisy spectrum of vulnerabilities. The framework supports\nmulti-granular analysis across function, file, and inter-function levels and\nemploys four diverse zero-shot prompt strategies: Baseline, Chain-of-Thought,\nThink, and Think & Verify. Through this evaluation, we uncover that structured\nreasoning prompts substantially improve LLM performance, with Think & Verify\nreducing ambiguous responses from 20.3% to 9.1% while increasing accuracy. We\nfurther demonstrate that code-specialized models consistently outperform\ngeneral-purpose alternatives, with performance varying significantly across\nvulnerability types, revealing that no single approach universally excels\nacross all security contexts. Link to dataset and codes:\nhttps://github.com/Erroristotle/VulnSage.git", "published": "2025-03-22 23:59:17", "link": "http://arxiv.org/abs/2503.17885v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "EXPLICATE: Enhancing Phishing Detection through Explainable AI and LLM-Powered Interpretability", "abstract": "Sophisticated phishing attacks have emerged as a major cybersecurity threat,\nbecoming more common and difficult to prevent. Though machine learning\ntechniques have shown promise in detecting phishing attacks, they function\nmainly as \"black boxes\" without revealing their decision-making rationale. This\nlack of transparency erodes the trust of users and diminishes their effective\nthreat response. We present EXPLICATE: a framework that enhances phishing\ndetection through a three-component architecture: an ML-based classifier using\ndomain-specific features, a dual-explanation layer combining LIME and SHAP for\ncomplementary feature-level insights, and an LLM enhancement using DeepSeek v3\nto translate technical explanations into accessible natural language. Our\nexperiments show that EXPLICATE attains 98.4 % accuracy on all metrics, which\nis on par with existing deep learning techniques but has better explainability.\nHigh-quality explanations are generated by the framework with an accuracy of\n94.2 % as well as a consistency of 96.8\\% between the LLM output and model\nprediction. We create EXPLICATE as a fully usable GUI application and a light\nChrome extension, showing its applicability in many deployment situations. The\nresearch shows that high detection performance can go hand-in-hand with\nmeaningful explainability in security applications. Most important, it\naddresses the critical divide between automated AI and user trust in phishing\ndetection systems.", "published": "2025-03-22 23:37:35", "link": "http://arxiv.org/abs/2503.20796v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Synthetic media and computational capitalism: towards a critical theory of artificial intelligence", "abstract": "This paper develops a critical theory of artificial intelligence, within a\nhistorical constellation where computational systems increasingly generate\ncultural content that destabilises traditional distinctions between human and\nmachine production. Through this analysis, I introduce the concept of the\nalgorithmic condition, a cultural moment when machine-generated work not only\nbecomes indistinguishable from human creation but actively reshapes our\nunderstanding of ideas of authenticity. This transformation, I argue, moves\nbeyond false consciousness towards what I call post-consciousness, where the\nboundaries between individual and synthetic consciousness become porous.\nDrawing on critical theory and extending recent work on computational ideology,\nI develop three key theoretical contributions, first, the concept of the\nInversion to describe a new computational turn in algorithmic society; second,\nautomimetric production as a framework for understanding emerging practices of\nautomated value creation; and third, constellational analysis as a\nmethodological approach for mapping the complex interplay of technical systems,\ncultural forms and political economic structures. Through these contributions,\nI argue that we need new critical methods capable of addressing both the\ntechnical specificity of AI systems and their role in restructuring forms of\nlife under computational capitalism. The paper concludes by suggesting that\ncritical reflexivity is needed to engage with the algorithmic condition without\nbeing subsumed by it and that it represents a growing challenge for\ncontemporary critical theory.", "published": "2025-03-22 22:59:28", "link": "http://arxiv.org/abs/2503.18976v1", "categories": ["cs.CY", "cs.AI", "K.4.0; K.4.1"], "primary_category": "cs.CY"}
{"title": "good4cir: Generating Detailed Synthetic Captions for Composed Image Retrieval", "abstract": "Composed image retrieval (CIR) enables users to search images using a\nreference image combined with textual modifications. Recent advances in\nvision-language models have improved CIR, but dataset limitations remain a\nbarrier. Existing datasets often rely on simplistic, ambiguous, or insufficient\nmanual annotations, hindering fine-grained retrieval. We introduce good4cir, a\nstructured pipeline leveraging vision-language models to generate high-quality\nsynthetic annotations. Our method involves: (1) extracting fine-grained object\ndescriptions from query images, (2) generating comparable descriptions for\ntarget images, and (3) synthesizing textual instructions capturing meaningful\ntransformations between images. This reduces hallucination, enhances\nmodification diversity, and ensures object-level consistency. Applying our\nmethod improves existing datasets and enables creating new datasets across\ndiverse domains. Results demonstrate improved retrieval accuracy for CIR models\ntrained on our pipeline-generated datasets. We release our dataset construction\nframework to support further research in CIR and multi-modal retrieval.", "published": "2025-03-22 22:33:56", "link": "http://arxiv.org/abs/2503.17871v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Detecting and Mitigating DDoS Attacks with AI: A Survey", "abstract": "Distributed Denial of Service attacks represent an active cybersecurity\nresearch problem. Recent research shifted from static rule-based defenses\ntowards AI-based detection and mitigation. This comprehensive survey covers\nseveral key topics. Preeminently, state-of-the-art AI detection methods are\ndiscussed. An in-depth taxonomy based on manual expert hierarchies and an\nAI-generated dendrogram are provided, thus settling DDoS categorization\nambiguities. An important discussion on available datasets follows, covering\ndata format options and their role in training AI detection methods together\nwith adversarial training and examples augmentation. Beyond detection, AI based\nmitigation techniques are surveyed as well. Finally, multiple open research\ndirections are proposed.", "published": "2025-03-22 21:54:23", "link": "http://arxiv.org/abs/2503.17867v1", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.NI"], "primary_category": "cs.CR"}
{"title": "Differentiable Optimization for Deep Learning-Enhanced DC Approximation of AC Optimal Power Flow", "abstract": "The growing scale of power systems and the increasing uncertainty introduced\nby renewable energy sources necessitates novel optimization techniques that are\nsignificantly faster and more accurate than existing methods. The AC Optimal\nPower Flow (AC-OPF) problem, a core component of power grid optimization, is\noften approximated using linearized DC Optimal Power Flow (DC-OPF) models for\ncomputational tractability, albeit at the cost of suboptimal and inefficient\ndecisions. To address these limitations, we propose a novel deep learning-based\nframework for network equivalency that enhances DC-OPF to more closely mimic\nthe behavior of AC-OPF. The approach utilizes recent advances in differentiable\noptimization, incorporating a neural network trained to predict adjusted nodal\nshunt conductances and branch susceptances in order to account for nonlinear\npower flow behavior. The model can be trained end-to-end using modern deep\nlearning frameworks by leveraging the implicit function theorem. Results\ndemonstrate the framework's ability to significantly improve prediction\naccuracy, paving the way for more reliable and efficient power systems.", "published": "2025-03-22 20:53:53", "link": "http://arxiv.org/abs/2504.01970v1", "categories": ["math.OC", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "math.OC"}
{"title": "A Causal Adjustment Module for Debiasing Scene Graph Generation", "abstract": "While recent debiasing methods for Scene Graph Generation (SGG) have shown\nimpressive performance, these efforts often attribute model bias solely to the\nlong-tail distribution of relationships, overlooking the more profound causes\nstemming from skewed object and object pair distributions. In this paper, we\nemploy causal inference techniques to model the causality among these observed\nskewed distributions. Our insight lies in the ability of causal inference to\ncapture the unobservable causal effects between complex distributions, which is\ncrucial for tracing the roots of model bias. Specifically, we introduce the\nMediator-based Causal Chain Model (MCCM), which, in addition to modeling\ncausality among objects, object pairs, and relationships, incorporates mediator\nvariables, i.e., cooccurrence distribution, for complementing the causality.\nFollowing this, we propose the Causal Adjustment Module (CAModule) to estimate\nthe modeled causal structure, using variables from MCCM as inputs to produce a\nset of adjustment factors aimed at correcting biased model predictions.\nMoreover, our method enables the composition of zero-shot relationships,\nthereby enhancing the model's ability to recognize such relationships.\nExperiments conducted across various SGG backbones and popular benchmarks\ndemonstrate that CAModule achieves state-of-the-art mean recall rates, with\nsignificant improvements also observed on the challenging zero-shot recall rate\nmetric.", "published": "2025-03-22 20:44:01", "link": "http://arxiv.org/abs/2503.17862v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Adapt, Agree, Aggregate: Semi-Supervised Ensemble Labeling for Graph Convolutional Networks", "abstract": "In this paper, we propose a novel framework that combines ensemble learning\nwith augmented graph structures to improve the performance and robustness of\nsemi-supervised node classification in graphs. By creating multiple augmented\nviews of the same graph, our approach harnesses the \"wisdom of a diverse\ncrowd\", mitigating the challenges posed by noisy graph structures. Leveraging\nensemble learning allows us to simultaneously achieve three key goals: adaptive\nconfidence threshold selection based on model agreement, dynamic determination\nof the number of high-confidence samples for training, and robust extraction of\npseudo-labels to mitigate confirmation bias. Our approach uniquely integrates\nadaptive ensemble consensus to flexibly guide pseudo-label extraction and\nsample selection, reducing the risks of error accumulation and improving\nrobustness. Furthermore, the use of ensemble-driven consensus for\npseudo-labeling captures subtle patterns that individual models often overlook,\nenabling the model to generalize better. Experiments on several real-world\ndatasets demonstrate the effectiveness of our proposed method.", "published": "2025-03-22 19:10:54", "link": "http://arxiv.org/abs/2503.17842v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "A Study on the Improvement of Code Generation Quality Using Large Language Models Leveraging Product Documentation", "abstract": "Research on using Large Language Models (LLMs) in system development is\nexpanding, especially in automated code and test generation. While E2E testing\nis vital for ensuring application quality, most test generation research has\nfocused on unit tests, with limited work on E2E test code. This study proposes\na method for automatically generating E2E test code from product documentation\nsuch as manuals, FAQs, and tutorials using LLMs with tailored prompts. The two\nstep process interprets documentation intent and produces executable test code.\nExperiments on a web app with six key features (e.g., authentication, profile,\ndiscussion) showed that tests generated from product documentation had high\ncompilation success and functional coverage, outperforming those based on\nrequirement specs and user stories. These findings highlight the potential of\nproduct documentation to improve E2E test quality and, by extension, software\nquality.", "published": "2025-03-22 18:42:05", "link": "http://arxiv.org/abs/2503.17837v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "FundusGAN: A Hierarchical Feature-Aware Generative Framework for High-Fidelity Fundus Image Generation", "abstract": "Recent advancements in ophthalmology foundation models such as RetFound have\ndemonstrated remarkable diagnostic capabilities but require massive datasets\nfor effective pre-training, creating significant barriers for development and\ndeployment. To address this critical challenge, we propose FundusGAN, a novel\nhierarchical feature-aware generative framework specifically designed for\nhigh-fidelity fundus image synthesis. Our approach leverages a Feature Pyramid\nNetwork within its encoder to comprehensively extract multi-scale information,\ncapturing both large anatomical structures and subtle pathological features.\nThe framework incorporates a modified StyleGAN-based generator with dilated\nconvolutions and strategic upsampling adjustments to preserve critical retinal\nstructures while enhancing pathological detail representation. Comprehensive\nevaluations on the DDR, DRIVE, and IDRiD datasets demonstrate that FundusGAN\nconsistently outperforms state-of-the-art methods across multiple metrics\n(SSIM: 0.8863, FID: 54.2, KID: 0.0436 on DDR). Furthermore, disease\nclassification experiments reveal that augmenting training data with\nFundusGAN-generated images significantly improves diagnostic accuracy across\nmultiple CNN architectures (up to 6.49\\% improvement with ResNet50). These\nresults establish FundusGAN as a valuable foundation model component that\neffectively addresses data scarcity challenges in ophthalmological AI research,\nenabling more robust and generalizable diagnostic systems while reducing\ndependency on large-scale clinical data collection.", "published": "2025-03-22 18:08:07", "link": "http://arxiv.org/abs/2503.17831v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Metacognition in Content-Centric Computational Cognitive C4 Modeling", "abstract": "For AI agents to emulate human behavior, they must be able to perceive,\nmeaningfully interpret, store, and use large amounts of information about the\nworld, themselves, and other agents. Metacognition is a necessary component of\nall of these processes. In this paper, we briefly a) introduce content-centric\ncomputational cognitive (C4) modeling for next-generation AI agents; b) review\nthe long history of developing C4 agents at RPI's LEIA (Language-Endowed\nIntelligent Agents) Lab; c) discuss our current work on extending LEIAs'\ncognitive capabilities to cognitive robotic applications developed using a\nneuro symbolic processing model; and d) sketch plans for future developments in\nthis paradigm that aim to overcome underappreciated limitations of currently\npopular, LLM-driven methods in AI.", "published": "2025-03-22 17:23:27", "link": "http://arxiv.org/abs/2503.17822v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "OvercookedV2: Rethinking Overcooked for Zero-Shot Coordination", "abstract": "AI agents hold the potential to transform everyday life by helping humans\nachieve their goals. To do this successfully, agents need to be able to\ncoordinate with novel partners without prior interaction, a setting known as\nzero-shot coordination (ZSC). Overcooked has become one of the most popular\nbenchmarks for evaluating coordination capabilities of AI agents and learning\nalgorithms. In this work, we investigate the origins of ZSC challenges in\nOvercooked. We introduce a state augmentation mechanism which mixes states that\nmight be encountered when paired with unknown partners into the training\ndistribution, reducing the out-of-distribution challenge associated with ZSC.\nWe show that independently trained agents under this algorithm coordinate\nsuccessfully in Overcooked. Our results suggest that ZSC failure can largely be\nattributed to poor state coverage under self-play rather than more\nsophisticated coordination challenges. The Overcooked environment is therefore\nnot suitable as a ZSC benchmark. To address these shortcomings, we introduce\nOvercookedV2, a new version of the benchmark, which includes asymmetric\ninformation and stochasticity, facilitating the creation of interesting ZSC\nscenarios. To validate OvercookedV2, we conduct experiments demonstrating that\nmere exhaustive state coverage is insufficient to coordinate well. Finally, we\nuse OvercookedV2 to build a new range of coordination challenges, including\nones that require test time protocol formation, and we demonstrate the need for\nnew coordination algorithms that can adapt online. We hope that OvercookedV2\nwill help benchmark the next generation of ZSC algorithms and advance\ncollaboration between AI agents and humans.", "published": "2025-03-22 17:14:24", "link": "http://arxiv.org/abs/2503.17821v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Process Optimization and Deployment for Sensor-Based Human Activity Recognition Based on Deep Learning", "abstract": "Sensor-based human activity recognition is a key technology for many\nhuman-centered intelligent applications. However, this research is still in its\ninfancy and faces many unresolved challenges. To address these, we propose a\ncomprehensive optimization process approach centered on multi-attention\ninteraction. We first utilize unsupervised statistical feature-guided diffusion\nmodels for highly adaptive data enhancement, and introduce a novel network\narchitecture-Multi-branch Spatiotemporal Interaction Network, which uses\nmulti-branch features at different levels to effectively Sequential ), which\nuses multi-branch features at different levels to effectively Sequential\nspatio-temporal interaction to enhance the ability to mine advanced latent\nfeatures. In addition, we adopt a multi-loss function fusion strategy in the\ntraining phase to dynamically adjust the fusion weights between batches to\noptimize the training results. Finally, we also conducted actual deployment on\nembedded devices to extensively test the practical feasibility of the proposed\nmethod in existing work. We conduct extensive testing on three public datasets,\nincluding ablation studies, comparisons of related work, and embedded\ndeployments.", "published": "2025-03-22 16:48:16", "link": "http://arxiv.org/abs/2504.03687v1", "categories": ["eess.SP", "cs.AI", "cs.CV"], "primary_category": "eess.SP"}
{"title": "A Roadmap Towards Improving Multi-Agent Reinforcement Learning With Causal Discovery And Inference", "abstract": "Causal reasoning is increasingly used in Reinforcement Learning (RL) to\nimprove the learning process in several dimensions: efficacy of learned\npolicies, efficiency of convergence, generalisation capabilities, safety and\ninterpretability of behaviour. However, applications of causal reasoning to\nMulti-Agent RL (MARL) are still mostly unexplored. In this paper, we take the\nfirst step in investigating the opportunities and challenges of applying causal\nreasoning in MARL. We measure the impact of a simple form of causal\naugmentation in state-of-the-art MARL scenarios increasingly requiring\ncooperation, and with state-of-the-art MARL algorithms exploiting various\ndegrees of collaboration between agents. Then, we discuss the positive as well\nas negative results achieved, giving us the chance to outline the areas where\nfurther research may help to successfully transfer causal RL to the multi-agent\nsetting.", "published": "2025-03-22 15:49:13", "link": "http://arxiv.org/abs/2503.17803v1", "categories": ["cs.LG", "cs.AI", "cs.MA", "stat.ME"], "primary_category": "cs.LG"}
{"title": "Machine Learning - Driven Materials Discovery: Unlocking Next-Generation Functional Materials -- A minireview", "abstract": "The rapid advancement of machine learning and artificial intelligence\n(AI)-driven techniques is revolutionizing materials discovery, property\nprediction, and material design by minimizing human intervention and\naccelerating scientific progress. This review provides a comprehensive overview\nof smart, machine learning (ML)-driven approaches, emphasizing their role in\npredicting material properties, discovering novel compounds, and optimizing\nmaterial structures. Key methodologies ranging from deep learning, graph neural\nnetworks, and Bayesian optimization to automated generative models, such as\ngenerative adversarial networks (GANs) and variational autoencoders (VAEs)\nenable the autonomous design of materials with tailored functionalities. By\nleveraging AutoML frameworks (e.g., AutoGluon, TPOT, and H2O.ai), researchers\ncan automate the model selection, hyperparameter tuning, and feature\nengineering, significantly improving the efficiency of materials informatics.\nFurthermore, the integration of AI-driven robotic laboratories and\nhigh-throughput computing has established a fully automated pipeline for rapid\nsynthesis and experimental validation, drastically reducing the time and cost\nof material discovery. This review highlights real-world applications of\nautomated ML-driven approaches in predicting mechanical, thermal, electrical,\nand optical properties of materials, demonstrating successful cases in\nsuperconductors, catalysts, photovoltaics, and energy storage systems. We also\naddress key challenges, such as data quality, interpretability, and the\nintegration of AutoML with quantum computing, which are essential for future\nadvancements. Ultimately, the synergy between AI, automated experimentation,\nand computational modeling transforms the way the materials are discovered,\noptimized, and designed, paving the way for next-generation innovations in\nenergy, electronics, and nanotechnology.", "published": "2025-03-22 15:24:38", "link": "http://arxiv.org/abs/2503.18975v1", "categories": ["cond-mat.mtrl-sci", "cs.AI", "cs.LG"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "GaussianFocus: Constrained Attention Focus for 3D Gaussian Splatting", "abstract": "Recent developments in 3D reconstruction and neural rendering have\nsignificantly propelled the capabilities of photo-realistic 3D scene rendering\nacross various academic and industrial fields. The 3D Gaussian Splatting\ntechnique, alongside its derivatives, integrates the advantages of\nprimitive-based and volumetric representations to deliver top-tier rendering\nquality and efficiency. Despite these advancements, the method tends to\ngenerate excessive redundant noisy Gaussians overfitted to every training view,\nwhich degrades the rendering quality. Additionally, while 3D Gaussian Splatting\nexcels in small-scale and object-centric scenes, its application to larger\nscenes is hindered by constraints such as limited video memory, excessive\noptimization duration, and variable appearance across views. To address these\nchallenges, we introduce GaussianFocus, an innovative approach that\nincorporates a patch attention algorithm to refine rendering quality and\nimplements a Gaussian constraints strategy to minimize redundancy. Moreover, we\npropose a subdivision reconstruction strategy for large-scale scenes, dividing\nthem into smaller, manageable blocks for individual training. Our results\nindicate that GaussianFocus significantly reduces unnecessary Gaussians and\nenhances rendering quality, surpassing existing State-of-The-Art (SoTA)\nmethods. Furthermore, we demonstrate the capability of our approach to\neffectively manage and render large scenes, such as urban environments, whilst\nmaintaining high fidelity in the visual output.", "published": "2025-03-22 15:18:23", "link": "http://arxiv.org/abs/2503.17798v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Progressive Prompt Detailing for Improved Alignment in Text-to-Image Generative Models", "abstract": "Text-to-image generative models often struggle with long prompts detailing\ncomplex scenes, diverse objects with distinct visual characteristics and\nspatial relationships. In this work, we propose SCoPE (Scheduled interpolation\nof Coarse-to-fine Prompt Embeddings), a training-free method to improve\ntext-to-image alignment by progressively refining the input prompt in a\ncoarse-to-fine-grained manner. Given a detailed input prompt, we first\ndecompose it into multiple sub-prompts which evolve from describing broad scene\nlayout to highly intricate details. During inference, we interpolate between\nthese sub-prompts and thus progressively introduce finer-grained details into\nthe generated image. Our training-free plug-and-play approach significantly\nenhances prompt alignment, achieves an average improvement of up to +4% in\nVisual Question Answering (VQA) scores over the Stable Diffusion baselines on\n85% of the prompts from the GenAI-Bench dataset.", "published": "2025-03-22 15:05:21", "link": "http://arxiv.org/abs/2503.17794v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Aligning Foundation Model Priors and Diffusion-Based Hand Interactions for Occlusion-Resistant Two-Hand Reconstruction", "abstract": "Two-hand reconstruction from monocular images faces persistent challenges due\nto complex and dynamic hand postures and occlusions, causing significant\ndifficulty in achieving plausible interaction alignment. Existing approaches\nstruggle with such alignment issues, often resulting in misalignment and\npenetration artifacts. To tackle this, we propose a novel framework that\nattempts to precisely align hand poses and interactions by synergistically\nintegrating foundation model-driven 2D priors with diffusion-based interaction\nrefinement for occlusion-resistant two-hand reconstruction. First, we introduce\na Fusion Alignment Encoder that learns to align fused multimodal priors\nkeypoints, segmentation maps, and depth cues from foundation models during\ntraining. This provides robust structured guidance, further enabling efficient\ninference without foundation models at test time while maintaining high\nreconstruction accuracy. Second, we employ a two-hand diffusion model\nexplicitly trained to transform interpenetrated poses into plausible,\nnon-penetrated interactions, leveraging gradient-guided denoising to correct\nartifacts and ensure realistic spatial relations. Extensive evaluations\ndemonstrate that our method achieves state-of-the-art performance on\nInterHand2.6M, FreiHAND, and HIC datasets, significantly advancing occlusion\nhandling and interaction robustness.", "published": "2025-03-22 14:42:27", "link": "http://arxiv.org/abs/2503.17788v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "MEPNet: Medical Entity-balanced Prompting Network for Brain CT Report Generation", "abstract": "The automatic generation of brain CT reports has gained widespread attention,\ngiven its potential to assist radiologists in diagnosing cranial diseases.\nHowever, brain CT scans involve extensive medical entities, such as diverse\nanatomy regions and lesions, exhibiting highly inconsistent spatial patterns in\n3D volumetric space. This leads to biased learning of medical entities in\nexisting methods, resulting in repetitiveness and inaccuracy in generated\nreports. To this end, we propose a Medical Entity-balanced Prompting Network\n(MEPNet), which harnesses the large language model (LLM) to fairly interpret\nvarious entities for accurate brain CT report generation. By introducing the\nvisual embedding and the learning status of medical entities as enriched clues,\nour method prompts the LLM to balance the learning of diverse entities, thereby\nenhancing reports with comprehensive findings. First, to extract visual\nembedding of entities, we propose Knowledge-driven Joint Attention to explore\nand distill entity patterns using both explicit and implicit medical knowledge.\nThen, a Learning Status Scorer is designed to evaluate the learning of entity\nvisual embeddings, resulting in unique learning status for individual entities.\nFinally, these entity visual embeddings and status are elaborately integrated\ninto multi-modal prompts, to guide the text generation of LLM. This process\nallows LLM to self-adapt the learning process for biased-fitted entities,\nthereby covering detailed findings in generated reports. We conduct experiments\non two brain CT report generation benchmarks, showing the effectiveness in\nclinical accuracy and text coherence.", "published": "2025-03-22 14:31:30", "link": "http://arxiv.org/abs/2503.17784v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Revisiting Outage for Edge Inference Systems", "abstract": "One of the key missions of sixth-generation (6G) mobile networks is to deploy\nlarge-scale artificial intelligence (AI) models at the network edge to provide\nremote-inference services for edge devices. The resultant platform, known as\nedge inference, will support a wide range of Internet-of-Things applications,\nsuch as autonomous driving, industrial automation, and augmented reality. Given\nthe mission-critical and time-sensitive nature of these tasks, it is essential\nto design edge inference systems that are both reliable and capable of meeting\nstringent end-to-end (E2E) latency constraints. Existing studies, which\nprimarily focus on communication reliability as characterized by channel outage\nprobability, may fail to guarantee E2E performance, specifically in terms of\nE2E inference accuracy and latency. To address this limitation, we propose a\ntheoretical framework that introduces and mathematically characterizes the\ninference outage (InfOut) probability, which quantifies the likelihood that the\nE2E inference accuracy falls below a target threshold. Under an E2E latency\nconstraint, this framework establishes a fundamental tradeoff between\ncommunication overhead (i.e., uploading more sensor observations) and inference\nreliability as quantified by the InfOut probability. To find a tractable way to\noptimize this tradeoff, we derive accurate surrogate functions for InfOut\nprobability by applying a Gaussian approximation to the distribution of the\nreceived discriminant gain. Experimental results demonstrate the superiority of\nthe proposed design over conventional communication-centric approaches in terms\nof E2E inference reliability.", "published": "2025-03-22 13:10:27", "link": "http://arxiv.org/abs/2504.03686v1", "categories": ["cs.NI", "cs.AI", "cs.LG"], "primary_category": "cs.NI"}
{"title": "Lifelong Evolution of Swarms", "abstract": "Adapting to task changes without forgetting previous knowledge is a key skill\nfor intelligent systems, and a crucial aspect of lifelong learning. Swarm\ncontrollers, however, are typically designed for specific tasks, lacking the\nability to retain knowledge across changing tasks. Lifelong learning, on the\nother hand, focuses on individual agents with limited insights into the\nemergent abilities of a collective like a swarm. To address this gap, we\nintroduce a lifelong evolutionary framework for swarms, where a population of\nswarm controllers is evolved in a dynamic environment that incrementally\npresents novel tasks. This requires evolution to find controllers that quickly\nadapt to new tasks while retaining knowledge of previous ones, as they may\nreappear in the future. We discover that the population inherently preserves\ninformation about previous tasks, and it can reuse it to foster adaptation and\nmitigate forgetting. In contrast, the top-performing individual for a given\ntask catastrophically forgets previous tasks. To mitigate this phenomenon, we\ndesign a regularization process for the evolutionary algorithm, reducing\nforgetting in top-performing individuals. Evolving swarms in a lifelong fashion\nraises fundamental questions on the current state of deep lifelong learning and\non the robustness of swarm controllers in dynamic environments.", "published": "2025-03-22 13:08:31", "link": "http://arxiv.org/abs/2503.17763v1", "categories": ["cs.NE", "cs.AI"], "primary_category": "cs.NE"}
{"title": "CODA: Repurposing Continuous VAEs for Discrete Tokenization", "abstract": "Discrete visual tokenizers transform images into a sequence of tokens,\nenabling token-based visual generation akin to language models. However, this\nprocess is inherently challenging, as it requires both compressing visual\nsignals into a compact representation and discretizing them into a fixed set of\ncodes. Traditional discrete tokenizers typically learn the two tasks jointly,\noften leading to unstable training, low codebook utilization, and limited\nreconstruction quality. In this paper, we introduce\n\\textbf{CODA}(\\textbf{CO}ntinuous-to-\\textbf{D}iscrete \\textbf{A}daptation), a\nframework that decouples compression and discretization. Instead of training\ndiscrete tokenizers from scratch, CODA adapts off-the-shelf continuous VAEs --\nalready optimized for perceptual compression -- into discrete tokenizers via a\ncarefully designed discretization process. By primarily focusing on\ndiscretization, CODA ensures stable and efficient training while retaining the\nstrong visual fidelity of continuous VAEs. Empirically, with $\\mathbf{6\n\\times}$ less training budget than standard VQGAN, our approach achieves a\nremarkable codebook utilization of 100% and notable reconstruction FID (rFID)\nof $\\mathbf{0.43}$ and $\\mathbf{1.34}$ for $8 \\times$ and $16 \\times$\ncompression on ImageNet 256$\\times$ 256 benchmark.", "published": "2025-03-22 12:59:00", "link": "http://arxiv.org/abs/2503.17760v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Bandwidth Reservation for Time-Critical Vehicular Applications: A Multi-Operator Environment", "abstract": "Onsite bandwidth reservation requests often face challenges such as price\nfluctuations and fairness issues due to unpredictable bandwidth availability\nand stringent latency requirements. Requesting bandwidth in advance can\nmitigate the impact of these fluctuations and ensure timely access to critical\nresources. In a multi-Mobile Network Operator (MNO) environment, vehicles need\nto select cost-effective and reliable resources for their safety-critical\napplications. This research aims to minimize resource costs by finding the best\nprice among multiple MNOs. It formulates multi-operator scenarios as a Markov\nDecision Process (MDP), utilizing a Deep Reinforcement Learning (DRL)\nalgorithm, specifically Dueling Deep Q-Learning. For efficient and stable\nlearning, we propose a novel area-wise approach and an adaptive MDP synthetic\nclose to the real environment. The Temporal Fusion Transformer (TFT) is used to\nhandle time-dependent data and model training. Furthermore, the research\nleverages Amazon spot price data and adopts a multi-phase training approach,\ninvolving initial training on synthetic data, followed by real-world data.\nThese phases enable the DRL agent to make informed decisions using insights\nfrom historical data and real-time observations. The results show that our\nmodel leads to significant cost reductions, up to 40%, compared to scenarios\nwithout a policy model in such a complex environment.", "published": "2025-03-22 12:36:23", "link": "http://arxiv.org/abs/2503.17756v1", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Aportes para el cumplimiento del Reglamento (UE) 2024/1689 en rob\u00f3tica y sistemas aut\u00f3nomos", "abstract": "Cybersecurity in robotics stands out as a key aspect within Regulation (EU)\n2024/1689, also known as the Artificial Intelligence Act, which establishes\nspecific guidelines for intelligent and automated systems. A fundamental\ndistinction in this regulatory framework is the difference between robots with\nArtificial Intelligence (AI) and those that operate through automation systems\nwithout AI, since the former are subject to stricter security requirements due\nto their learning and autonomy capabilities. This work analyzes cybersecurity\ntools applicable to advanced robotic systems, with special emphasis on the\nprotection of knowledge bases in cognitive architectures. Furthermore, a list\nof basic tools is proposed to guarantee the security, integrity, and resilience\nof these systems, and a practical case is presented, focused on the analysis of\nrobot knowledge management, where ten evaluation criteria are defined to ensure\ncompliance with the regulation and reduce risks in human-robot interaction\n(HRI) environments.", "published": "2025-03-22 11:04:42", "link": "http://arxiv.org/abs/2503.17730v1", "categories": ["cs.RO", "cs.AI", "cs.CR"], "primary_category": "cs.RO"}
{"title": "DynASyn: Multi-Subject Personalization Enabling Dynamic Action Synthesis", "abstract": "Recent advances in text-to-image diffusion models spurred research on\npersonalization, i.e., a customized image synthesis, of subjects within\nreference images. Although existing personalization methods are able to alter\nthe subjects' positions or to personalize multiple subjects simultaneously,\nthey often struggle to modify the behaviors of subjects or their dynamic\ninteractions. The difficulty is attributable to overfitting to reference\nimages, which worsens if only a single reference image is available. We propose\nDynASyn, an effective multi-subject personalization from a single reference\nimage addressing these challenges. DynASyn preserves the subject identity in\nthe personalization process by aligning concept-based priors with subject\nappearances and actions. This is achieved by regularizing the attention maps\nbetween the subject token and images through concept-based priors. In addition,\nwe propose concept-based prompt-and-image augmentation for an enhanced\ntrade-off between identity preservation and action diversity. We adopt an\nSDE-based editing guided by augmented prompts to generate diverse appearances\nand actions while maintaining identity consistency in the augmented images.\nExperiments show that DynASyn is capable of synthesizing highly realistic\nimages of subjects with novel contexts and dynamic interactions with the\nsurroundings, and outperforms baseline methods in both quantitative and\nqualitative aspects.", "published": "2025-03-22 10:56:35", "link": "http://arxiv.org/abs/2503.17728v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A Survey on Mathematical Reasoning and Optimization with Large Language Models", "abstract": "Mathematical reasoning and optimization are fundamental to artificial\nintelligence and computational problem-solving. Recent advancements in Large\nLanguage Models (LLMs) have significantly improved AI-driven mathematical\nreasoning, theorem proving, and optimization techniques. This survey explores\nthe evolution of mathematical problem-solving in AI, from early statistical\nlearning approaches to modern deep learning and transformer-based\nmethodologies. We review the capabilities of pretrained language models and\nLLMs in performing arithmetic operations, complex reasoning, theorem proving,\nand structured symbolic computation. A key focus is on how LLMs integrate with\noptimization and control frameworks, including mixed-integer programming,\nlinear quadratic control, and multi-agent optimization strategies. We examine\nhow LLMs assist in problem formulation, constraint generation, and heuristic\nsearch, bridging theoretical reasoning with practical applications. We also\ndiscuss enhancement techniques such as Chain-of-Thought reasoning, instruction\ntuning, and tool-augmented methods that improve LLM's problem-solving\nperformance. Despite their progress, LLMs face challenges in numerical\nprecision, logical consistency, and proof verification. Emerging trends such as\nhybrid neural-symbolic reasoning, structured prompt engineering, and multi-step\nself-correction aim to overcome these limitations. Future research should focus\non interpretability, integration with domain-specific solvers, and improving\nthe robustness of AI-driven decision-making. This survey offers a comprehensive\nreview of the current landscape and future directions of mathematical reasoning\nand optimization with LLMs, with applications across engineering, finance, and\nscientific research.", "published": "2025-03-22 10:49:32", "link": "http://arxiv.org/abs/2503.17726v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Towards Invisible Backdoor Attack on Text-to-Image Diffusion Model", "abstract": "Backdoor attacks targeting text-to-image diffusion models have advanced\nrapidly, enabling attackers to implant malicious triggers into these models to\nmanipulate their outputs. However, current backdoor samples often exhibit two\nkey abnormalities compared to benign samples: 1) Semantic Consistency, where\nbackdoor prompts tend to generate images with similar semantic content even\nwith significant textual variations to the prompts; 2) Attention Consistency,\nwhere the trigger induces consistent structural responses in the\ncross-attention maps. These consistencies leave detectable traces for\ndefenders, making backdoors easier to identify. To enhance the stealthiness of\nbackdoor samples, we propose a novel Invisible Backdoor Attack (IBA) by\nexplicitly mitigating these consistencies. Specifically, our approach leverages\nsyntactic structures as backdoor triggers to amplify the sensitivity to textual\nvariations, effectively breaking down the semantic consistency. Besides, a\nregularization method based on Kernel Maximum Mean Discrepancy (KMMD) is\nproposed to align the distribution of cross-attention responses between\nbackdoor and benign samples, thereby disrupting attention consistency.\nExtensive experiments demonstrate that our IBA achieves a 97.5% attack success\nrate while exhibiting stronger resistance to defenses, with an average of over\n98% backdoor samples bypassing three state-of-the-art detection mechanisms. The\ncode is available at https://github.com/Robin-WZQ/IBA.", "published": "2025-03-22 10:41:46", "link": "http://arxiv.org/abs/2503.17724v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Multi-modality Anomaly Segmentation on the Road", "abstract": "Semantic segmentation allows autonomous driving cars to understand the\nsurroundings of the vehicle comprehensively. However, it is also crucial for\nthe model to detect obstacles that may jeopardize the safety of autonomous\ndriving systems. Based on our experiments, we find that current uni-modal\nanomaly segmentation frameworks tend to produce high anomaly scores for\nnon-anomalous regions in images. Motivated by this empirical finding, we\ndevelop a multi-modal uncertainty-based anomaly segmentation framework, named\nMMRAS+, for autonomous driving systems. MMRAS+ effectively reduces the high\nanomaly outputs of non-anomalous classes by introducing text-modal using the\nCLIP text encoder. Indeed, MMRAS+ is the first multi-modal anomaly segmentation\nsolution for autonomous driving. Moreover, we develop an ensemble module to\nfurther boost the anomaly segmentation performance. Experiments on RoadAnomaly,\nSMIYC, and Fishyscapes validation datasets demonstrate the superior performance\nof our method. The code is available in\nhttps://github.com/HengGao12/MMRAS_plus.", "published": "2025-03-22 09:55:42", "link": "http://arxiv.org/abs/2503.17712v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Slide2Text: Leveraging LLMs for Personalized Textbook Generation from PowerPoint Presentations", "abstract": "The rapid advancements in Large Language Models (LLMs) have revolutionized\neducational technology, enabling innovative approaches to automated and\npersonalized content creation. This paper introduces Slide2Text, a system that\nleverages LLMs to transform PowerPoint presentations into customized textbooks.\nBy extracting slide content using OCR, organizing it into a coherent structure,\nand generating tailored materials such as explanations, exercises, and\nreferences, Slide2Text streamlines the textbook creation process. Flexible\ncustomization options further enhance its adaptability to diverse educational\nneeds. The system highlights the potential of LLMs in modernizing textbook\ncreation and improving educational accessibility. Future developments will\nexplore multimedia inputs and advanced user customization features.", "published": "2025-03-22 09:42:03", "link": "http://arxiv.org/abs/2503.17710v1", "categories": ["cs.AI", "eess.IV"], "primary_category": "cs.AI"}
{"title": "GUI-Xplore: Empowering Generalizable GUI Agents with One Exploration", "abstract": "GUI agents hold significant potential to enhance the experience and\nefficiency of human-device interaction. However, current methods face\nchallenges in generalizing across applications (apps) and tasks, primarily due\nto two fundamental limitations in existing datasets. First, these datasets\noverlook developer-induced structural variations among apps, limiting the\ntransferability of knowledge across diverse software environments. Second, many\nof them focus solely on navigation tasks, which restricts their capacity to\nrepresent comprehensive software architectures and complex user interactions.\nTo address these challenges, we introduce GUI-Xplore, a dataset meticulously\ndesigned to enhance cross-application and cross-task generalization via an\nexploration-and-reasoning framework. GUI-Xplore integrates pre-recorded\nexploration videos providing contextual insights, alongside five hierarchically\nstructured downstream tasks designed to comprehensively evaluate GUI agent\ncapabilities. To fully exploit GUI-Xplore's unique features, we propose\nXplore-Agent, a GUI agent framework that combines Action-aware GUI Modeling\nwith Graph-Guided Environment Reasoning. Further experiments indicate that\nXplore-Agent achieves a 10% improvement over existing methods in unfamiliar\nenvironments, yet there remains significant potential for further enhancement\ntowards truly generalizable GUI agents.", "published": "2025-03-22 09:30:37", "link": "http://arxiv.org/abs/2503.17709v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "PT-PINNs: A Parametric Engineering Turbulence Solver based on Physics-Informed Neural Networks", "abstract": "Physics-informed neural networks (PINNs) demonstrate promising potential in\nparameterized engineering turbulence optimization problems but face challenges,\nsuch as high data requirements and low computational accuracy when applied to\nengineering turbulence problems. This study proposes a framework that enhances\nthe ability of PINNs to solve parametric turbulence problems without training\ndatasets from experiments or CFD-Parametric Turbulence PINNs (PT-PINNs)). Two\nkey methods are introduced to improve the accuracy and robustness of this\nframework. The first is a soft constraint method for turbulent viscosity\ncalculation. The second is a pre-training method based on the conservation of\nflow rate in the flow field. The effectiveness of PT-PINNs is validated using a\nthree-dimensional backward-facing step (BFS) turbulence problem with two\nvarying parameters (Re = 3000-200000, ER = 1.1-1.5). PT-PINNs produce\npredictions that closely match experimental data and computational fluid\ndynamics (CFD) results across various conditions. Moreover, PT-PINNs offer a\ncomputational efficiency advantage over traditional CFD methods. The total time\nrequired to construct the parametric BFS turbulence model is 39 hours,\none-sixteenth of the time required by traditional numerical methods. The\ninference time for a single-condition prediction is just 40 seconds-only 0.5%\nof a single CFD computation. These findings highlight the potential of PT-PINNs\nfor future applications in engineering turbulence optimization problems.", "published": "2025-03-22 09:10:53", "link": "http://arxiv.org/abs/2503.17704v1", "categories": ["physics.flu-dyn", "cs.AI"], "primary_category": "physics.flu-dyn"}
{"title": "On the (im)possibility of sustainable artificial intelligence. Why it does not make sense to move faster when heading the wrong way", "abstract": "Artificial intelligence (AI) is currently considered a sustainability\n\"game-changer\" within and outside of academia. In order to discuss sustainable\nAI this article draws from insights by critical data and algorithm studies,\nSTS, transformative sustainability science, critical computer science, and\npublic interest theory. I argue that while there are indeed many\nsustainability-related use cases for AI, they are likely to have more overall\ndrawbacks than benefits. To substantiate this claim, I differentiate three 'AI\nmaterialities' of the AI supply chain: first the literal materiality (e.g.\nwater, cobalt, lithium, energy consumption etc.), second, the informational\nmateriality (e.g. lots of data and centralised control necessary), and third,\nthe social materiality (e.g. exploitative data work, communities harm by waste\nand pollution). In all materialities, effects are especially devastating for\nthe global south while benefiting the global north. A second strong claim\nregarding sustainable AI circles around so called apolitical optimisation (e.g.\nregarding city traffic), however the optimisation criteria (e.g. cars, bikes,\nemissions, commute time, health) are purely political and have to be\ncollectively negotiated before applying AI optimisation. Hence, sustainable AI,\nin principle, cannot break the glass ceiling of transformation and might even\ndistract from necessary societal change. To address that I propose to stop\n'unformation gathering' and to apply the 'small is beautiful' principle. This\naims to contribute to an informed academic and collective negotiation on how to\n(not) integrate AI into the sustainability project while avoiding to reproduce\nthe status quo by serving hegemonic interests between useful AI use cases,\ntechno-utopian salvation narratives, technology-centred efficiency paradigms,\nthe exploitative and extractivist character of AI and concepts of digital\ndegrowth.", "published": "2025-03-22 09:01:15", "link": "http://arxiv.org/abs/2503.17702v1", "categories": ["cs.CY", "cs.AI", "68T99", "K.4; I.2; H.4"], "primary_category": "cs.CY"}
{"title": "Intelligence Sequencing and the Path-Dependence of Intelligence Evolution: AGI-First vs. DCI-First as Irreversible Attractors", "abstract": "The trajectory of intelligence evolution is often framed around the emergence\nof artificial general intelligence (AGI) and its alignment with human values.\nThis paper challenges that framing by introducing the concept of intelligence\nsequencing: the idea that the order in which AGI and decentralized collective\nintelligence (DCI) emerge determines the long-term attractor basin of\nintelligence. Using insights from dynamical systems, evolutionary game theory,\nand network models, it argues that intelligence follows a path-dependent,\nirreversible trajectory. Once development enters a centralized (AGI-first) or\ndecentralized (DCI-first) regime, transitions become structurally infeasible\ndue to feedback loops and resource lock-in. Intelligence attractors are modeled\nin functional state space as the co-navigation of conceptual and adaptive\nfitness spaces. Early-phase structuring constrains later dynamics, much like\nrenormalization in physics. This has major implications for AI safety:\ntraditional alignment assumes AGI will emerge and must be controlled after the\nfact, but this paper argues that intelligence sequencing is more foundational.\nIf AGI-first architectures dominate before DCI reaches critical mass,\nhierarchical monopolization and existential risk become locked in. If DCI-first\nemerges, intelligence stabilizes around decentralized cooperative equilibrium.\nThe paper further explores whether intelligence structurally biases itself\ntoward an attractor based on its self-modeling method -- externally imposed\naxioms (favoring AGI) vs. recursive internal visualization (favoring DCI).\nFinally, it proposes methods to test this theory via simulations, historical\nlock-in case studies, and intelligence network analysis. The findings suggest\nthat intelligence sequencing is a civilizational tipping point: determining\nwhether the future is shaped by unbounded competition or unbounded cooperation.", "published": "2025-03-22 08:09:04", "link": "http://arxiv.org/abs/2503.17688v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Safe RLHF-V: Safe Reinforcement Learning from Human Feedback in Multimodal Large Language Models", "abstract": "Multimodal large language models (MLLMs) are critical for developing\ngeneral-purpose AI assistants, yet they face growing safety risks. How can we\nensure that MLLMs are safely aligned to prevent undesired behaviors such as\ndiscrimination, misinformation, or violations of ethical standards? In a\nfurther step, we need to explore how to fine-tune MLLMs to enhance reasoning\nperformance while ensuring they satisfy safety constraints. Fundamentally, this\ncan be formulated as a min-max optimization problem. In this study, we propose\nSafe RLHF-V, the first multimodal safety alignment framework that jointly\noptimizes helpfulness and safety using separate multimodal reward and cost\nmodels within a Lagrangian-based constrained optimization framework. Given that\nthere is a lack of preference datasets that separate helpfulness and safety in\nmultimodal scenarios, we introduce BeaverTails-V, the first open-source dataset\nwith dual preference annotations for helpfulness and safety, along with\nmulti-level safety labels (minor, moderate, severe). Additionally, we design a\nMulti-level Guardrail System to proactively defend against unsafe queries and\nadversarial attacks. By applying the Beaver-Guard-V moderation for 5 rounds of\nfiltering and re-generation on the precursor model, the overall safety of the\nupstream model is significantly improved by an average of 40.9%. Experimental\nresults demonstrate that fine-tuning different MLLMs with Safe RLHF can\neffectively enhance model helpfulness while ensuring improved safety.\nSpecifically, Safe RLHF-V improves model safety by 34.2% and helpfulness by\n34.3%. All of datasets, models, and code can be found at\nhttps://github.com/SafeRLHF-V to support the safety development of MLLMs and\nreduce potential societal risks.", "published": "2025-03-22 07:40:20", "link": "http://arxiv.org/abs/2503.17682v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "ComfyGPT: A Self-Optimizing Multi-Agent System for Comprehensive ComfyUI Workflow Generation", "abstract": "ComfyUI provides a widely-adopted, workflow-based interface that enables\nusers to customize various image generation tasks through an intuitive\nnode-based architecture. However, the intricate connections between nodes and\ndiverse modules often present a steep learning curve for users. In this paper,\nwe introduce ComfyGPT, the first self-optimizing multi-agent system designed to\ngenerate ComfyUI workflows based on task descriptions automatically. ComfyGPT\ncomprises four specialized agents: ReformatAgent, FlowAgent, RefineAgent, and\nExecuteAgent. The core innovation of ComfyGPT lies in two key aspects. First,\nit focuses on generating individual node links rather than entire workflows,\nsignificantly improving generation precision. Second, we proposed FlowAgent, a\nLLM-based workflow generation agent that uses both supervised fine-tuning (SFT)\nand reinforcement learning (RL) to improve workflow generation accuracy.\nMoreover, we introduce FlowDataset, a large-scale dataset containing 13,571\nworkflow-description pairs, and FlowBench, a comprehensive benchmark for\nevaluating workflow generation systems. We also propose four novel evaluation\nmetrics: Format Validation (FV), Pass Accuracy (PA), Pass Instruct Alignment\n(PIA), and Pass Node Diversity (PND). Experimental results demonstrate that\nComfyGPT significantly outperforms existing LLM-based methods in workflow\ngeneration.", "published": "2025-03-22 06:48:50", "link": "http://arxiv.org/abs/2503.17671v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "A Qualitative Study of User Perception of M365 AI Copilot", "abstract": "Adopting AI copilots in professional workflows presents opportunities for\nenhanced productivity, efficiency, and decision making. In this paper, we\npresent results from a six month trial of M365 Copilot conducted at our\norganisation in 2024. A qualitative interview study was carried out with 27\nparticipants. The study explored user perceptions of M365 Copilot's\neffectiveness, productivity impact, evolving expectations, ethical concerns,\nand overall satisfaction. Initial enthusiasm for the tool was met with mixed\npost trial experiences. While some users found M365 Copilot beneficial for\ntasks such as email coaching, meeting summaries, and content retrieval, others\nreported unmet expectations in areas requiring deeper contextual understanding,\nreasoning, and integration with existing workflows. Ethical concerns were a\nrecurring theme, with users highlighting issues related to data privacy,\ntransparency, and AI bias. While M365 Copilot demonstrated value in specific\noperational areas, its broader impact remained constrained by usability\nlimitations and the need for human oversight to validate AI generated outputs.", "published": "2025-03-22 06:11:10", "link": "http://arxiv.org/abs/2503.17661v2", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "NaFM: Pre-training a Foundation Model for Small-Molecule Natural Products", "abstract": "Natural products, as metabolites from microorganisms, animals, or plants,\nexhibit diverse biological activities, making them crucial for drug discovery.\nNowadays, existing deep learning methods for natural products research\nprimarily rely on supervised learning approaches designed for specific\ndownstream tasks. However, such one-model-for-a-task paradigm often lacks\ngeneralizability and leaves significant room for performance improvement.\nAdditionally, existing molecular characterization methods are not well-suited\nfor the unique tasks associated with natural products. To address these\nlimitations, we have pre-trained a foundation model for natural products based\non their unique properties. Our approach employs a novel pretraining strategy\nthat is especially tailored to natural products. By incorporating contrastive\nlearning and masked graph learning objectives, we emphasize evolutional\ninformation from molecular scaffolds while capturing side-chain information.\nOur framework achieves state-of-the-art (SOTA) results in various downstream\ntasks related to natural product mining and drug discovery. We first compare\ntaxonomy classification with synthesized molecule-focused baselines to\ndemonstrate that current models are inadequate for understanding natural\nsynthesis. Furthermore, by diving into a fine-grained analysis at both the gene\nand microbial levels, NaFM demonstrates the ability to capture evolutionary\ninformation. Eventually, our method is experimented with virtual screening,\nillustrating informative natural product representations that can lead to more\neffective identification of potential drug candidates.", "published": "2025-03-22 05:32:03", "link": "http://arxiv.org/abs/2503.17656v1", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "primary_category": "q-bio.QM"}
{"title": "Automated diagnosis of lung diseases using vision transformer: a comparative study on chest x-ray classification", "abstract": "Background: Lung disease is a significant health issue, particularly in\nchildren and elderly individuals. It often results from lung infections and is\none of the leading causes of mortality in children. Globally, lung-related\ndiseases claim many lives each year, making early and accurate diagnoses\ncrucial. Radiographs are valuable tools for the diagnosis of such conditions.\nThe most prevalent lung diseases, including pneumonia, asthma, allergies,\nchronic obstructive pulmonary disease (COPD), bronchitis, emphysema, and lung\ncancer, represent significant public health challenges. Early prediction of\nthese conditions is critical, as it allows for the identification of risk\nfactors and implementation of preventive measures to reduce the likelihood of\ndisease onset\n  Methods: In this study, we utilized a dataset comprising 3,475 chest X-ray\nimages sourced from from Mendeley Data provided by Talukder, M. A. (2023) [14],\ncategorized into three classes: normal, lung opacity, and pneumonia. We applied\nfive pre-trained deep learning models, including CNN, ResNet50, DenseNet,\nCheXNet, and U-Net, as well as two transfer learning algorithms such as Vision\nTransformer (ViT) and Shifted Window (Swin) to classify these images. This\napproach aims to address diagnostic issues in lung abnormalities by reducing\nreliance on human intervention through automated classification systems. Our\nanalysis was conducted in both binary and multiclass settings. Results: In the\nbinary classification, we focused on distinguishing between normal and viral\npneumonia cases, whereas in the multi-class classification, all three classes\n(normal, lung opacity, and viral pneumonia) were included. Our proposed\nmethodology (ViT) achieved remarkable performance, with accuracy rates of 99%\nfor binary classification and 95.25% for multiclass classification.", "published": "2025-03-22 04:35:17", "link": "http://arxiv.org/abs/2503.18973v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "A Modular Dataset to Demonstrate LLM Abstraction Capability", "abstract": "Large language models (LLMs) exhibit impressive capabilities but struggle\nwith reasoning errors due to hallucinations and flawed logic. To investigate\ntheir internal representations of reasoning, we introduce ArrangementPuzzle, a\nnovel puzzle dataset with structured solutions and automated stepwise\ncorrectness verification. We trained a classifier model on LLM activations on\nthis dataset and found that it achieved over 80% accuracy in predicting\nreasoning correctness, implying that LLMs internally distinguish between\ncorrect and incorrect reasoning steps, with the strongest representations in\nmiddle-late Transformer layers. Further analysis reveals that LLMs encode\nabstract reasoning concepts within the middle activation layers of the\ntransformer architecture, distinguishing logical from semantic equivalence.\nThese findings provide insights into LLM reasoning mechanisms and contribute to\nimproving AI reliability and interpretability, thereby offering the possibility\nto manipulate and refine LLM reasoning.", "published": "2025-03-22 04:25:30", "link": "http://arxiv.org/abs/2503.17645v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "On The Sample Complexity Bounds In Bilevel Reinforcement Learning", "abstract": "Bilevel reinforcement learning (BRL) has emerged as a powerful mathematical\nframework for studying generative AI alignment and related problems. While\nseveral principled algorithmic frameworks have been proposed, key theoretical\nfoundations, particularly those related to sample complexity, remain\nunderexplored. Understanding and deriving tight sample complexity bounds are\ncrucial for bridging the gap between theory and practice, guiding the\ndevelopment of more efficient algorithms. In this work, we present the first\nsample complexity result for BRL, achieving a bound of $\\epsilon^{-4}$. This\nresult extends to standard bilevel optimization problems, providing an\ninteresting theoretical contribution with practical implications. To address\nthe computational challenges associated with hypergradient estimation in\nbilevel optimization, we develop a first-order Hessian-free algorithm that does\nnot rely on costly hypergradient computations. By leveraging matrix-free\ntechniques and constrained optimization methods, our approach ensures\nscalability and practicality. Our findings pave the way for improved methods in\nAI alignment and other fields reliant on bilevel optimization.", "published": "2025-03-22 04:22:04", "link": "http://arxiv.org/abs/2503.17644v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "On the Hopf-Cole Transform for Control-affine Schr\u00f6dinger Bridge", "abstract": "The purpose of this note is to clarify the importance of the relation\n$\\boldsymbol{gg}^{\\top}\\propto \\boldsymbol{\\sigma\\sigma}^{\\top}$ in solving\ncontrol-affine Schr\\\"{o}dinger bridge problems via the Hopf-Cole transform,\nwhere $\\boldsymbol{g},\\boldsymbol{\\sigma}$ are the control and noise\ncoefficients, respectively. We show that the Hopf-Cole transform applied to the\nconditions of optimality for generic control-affine Schr\\\"{o}dinger bridge\nproblems, i.e., without the assumption\n$\\boldsymbol{gg}^{\\top}\\propto\\boldsymbol{\\sigma\\sigma}^{\\top}$, gives a pair\nof forward-backward PDEs that are neither linear nor equation-level decoupled.\nWe explain how the resulting PDEs can be interpreted as nonlinear\nforward-backward advection-diffusion-reaction equations, where the nonlinearity\nstem from additional drift and reaction terms involving the gradient of the\nlog-likelihood a.k.a. the score. These additional drift and reaction vanish\nwhen $\\boldsymbol{gg}^{\\top}\\propto\\boldsymbol{\\sigma\\sigma}^{\\top}$, and the\nresulting boundary-coupled system of linear PDEs can then be solved by dynamic\nSinkhorn recursions. A key takeaway of our work is that the numerical solution\nof the generic control-affine Schr\\\"{o}dinger bridge requires further\nalgorithmic development, possibly generalizing the dynamic Sinkhorn recursion\nor otherwise.", "published": "2025-03-22 04:08:10", "link": "http://arxiv.org/abs/2503.17640v1", "categories": ["math.OC", "cs.AI", "cs.LG", "cs.SY", "eess.SY", "stat.ML"], "primary_category": "math.OC"}
{"title": "LLMs as Planning Modelers: A Survey for Leveraging Large Language Models to Construct Automated Planning Models", "abstract": "Large Language Models (LLMs) excel in various natural language tasks but\noften struggle with long-horizon planning problems requiring structured\nreasoning. This limitation has drawn interest in integrating neuro-symbolic\napproaches within the Automated Planning (AP) and Natural Language Processing\n(NLP) communities. However, identifying optimal AP deployment frameworks can be\ndaunting. This paper aims to provide a timely survey of the current research\nwith an in-depth analysis, positioning LLMs as tools for extracting and\nrefining planning models to support reliable AP planners. By systematically\nreviewing the current state of research, we highlight methodologies, and\nidentify critical challenges and future directions, hoping to contribute to the\njoint research on NLP and Automated Planning.", "published": "2025-03-22 03:35:44", "link": "http://arxiv.org/abs/2503.18971v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Threshold Adaptation in Spiking Networks Enables Shortest Path Finding and Place Disambiguation", "abstract": "Efficient spatial navigation is a hallmark of the mammalian brain, inspiring\nthe development of neuromorphic systems that mimic biological principles.\nDespite progress, implementing key operations like back-tracing and handling\nambiguity in bio-inspired spiking neural networks remains an open challenge.\nThis work proposes a mechanism for activity back-tracing in arbitrary,\nuni-directional spiking neuron graphs. We extend the existing replay mechanism\nof the spiking hierarchical temporal memory (S-HTM) by our spike\ntiming-dependent threshold adaptation (STDTA), which enables us to perform path\nplanning in networks of spiking neurons. We further present an ambiguity\ndependent threshold adaptation (ADTA) for identifying places in an environment\nwith less ambiguity, enhancing the localization estimate of an agent. Combined,\nthese methods enable efficient identification of the shortest path to an\nunambiguous target. Our experiments show that a network trained on sequences\nreliably computes shortest paths with fewer replays than the steps required to\nreach the target. We further show that we can identify places with reduced\nambiguity in multiple, similar environments. These contributions advance the\npractical application of biologically inspired sequential learning algorithms\nlike the S-HTM towards neuromorphic localization and navigation.", "published": "2025-03-22 03:18:44", "link": "http://arxiv.org/abs/2503.21795v1", "categories": ["cs.NE", "cs.AI", "cs.RO"], "primary_category": "cs.NE"}
{"title": "Transferable Latent-to-Latent Locomotion Policy for Efficient and Versatile Motion Control of Diverse Legged Robots", "abstract": "Reinforcement learning (RL) has demonstrated remarkable capability in\nacquiring robot skills, but learning each new skill still requires substantial\ndata collection for training. The pretrain-and-finetune paradigm offers a\npromising approach for efficiently adapting to new robot entities and tasks.\nInspired by the idea that acquired knowledge can accelerate learning new tasks\nwith the same robot and help a new robot master a trained task, we propose a\nlatent training framework where a transferable latent-to-latent locomotion\npolicy is pretrained alongside diverse task-specific observation encoders and\naction decoders. This policy in latent space processes encoded latent\nobservations to generate latent actions to be decoded, with the potential to\nlearn general abstract motion skills. To retain essential information for\ndecision-making and control, we introduce a diffusion recovery module that\nminimizes information reconstruction loss during pretrain stage. During\nfine-tune stage, the pretrained latent-to-latent locomotion policy remains\nfixed, while only the lightweight task-specific encoder and decoder are\noptimized for efficient adaptation. Our method allows a robot to leverage its\nown prior experience across different tasks as well as the experience of other\nmorphologically diverse robots to accelerate adaptation. We validate our\napproach through extensive simulations and real-world experiments,\ndemonstrating that the pretrained latent-to-latent locomotion policy\neffectively generalizes to new robot entities and tasks with improved\nefficiency.", "published": "2025-03-22 03:01:25", "link": "http://arxiv.org/abs/2503.17626v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "AI-Based Screening for Depression and Social Anxiety Through Eye Tracking: An Exploratory Study", "abstract": "Well-being is a dynamic construct that evolves over time and fluctuates\nwithin individuals, presenting challenges for accurate quantification. Reduced\nwell-being is often linked to depression or anxiety disorders, which are\ncharacterised by biases in visual attention towards specific stimuli, such as\nhuman faces. This paper introduces a novel approach to AI-assisted screening of\naffective disorders by analysing visual attention scan paths using\nconvolutional neural networks (CNNs). Data were collected from two studies\nexamining (1) attentional tendencies in individuals diagnosed with major\ndepression and (2) social anxiety. These data were processed using residual\nCNNs through images generated from eye-gaze patterns. Experimental results,\nobtained with ResNet architectures, demonstrated an average accuracy of 48% for\na three-class system and 62% for a two-class system. Based on these exploratory\nfindings, we propose that this method could be employed in rapid, ecological,\nand effective mental health screening systems to assess well-being through\neye-tracking.", "published": "2025-03-22 02:53:02", "link": "http://arxiv.org/abs/2503.17625v1", "categories": ["cs.CV", "cs.AI", "cs.CY", "cs.HC", "cs.LG", "68U01", "J.3; I.2; I.5; H.4; C.3"], "primary_category": "cs.CV"}
{"title": "Unraveling Pedestrian Fatality Patterns: A Comparative Study with Explainable AI", "abstract": "Road fatalities pose significant public safety and health challenges\nworldwide, with pedestrians being particularly vulnerable in vehicle-pedestrian\ncrashes due to disparities in physical and performance characteristics. This\nstudy employs explainable artificial intelligence (XAI) to identify key factors\ncontributing to pedestrian fatalities across the five U.S. states with the\nhighest crash rates (2018-2022). It compares them to the five states with the\nlowest fatality rates. Using data from the Fatality Analysis Reporting System\n(FARS), the study applies machine learning techniques-including Decision Trees,\nGradient Boosting Trees, Random Forests, and XGBoost-to predict contributing\nfactors to pedestrian fatalities. To address data imbalance, the Synthetic\nMinority Over-sampling Technique (SMOTE) is utilized, while SHapley Additive\nExplanations (SHAP) values enhance model interpretability. The results indicate\nthat age, alcohol and drug use, location, and environmental conditions are\nsignificant predictors of pedestrian fatalities. The XGBoost model outperformed\nothers, achieving a balanced accuracy of 98 %, accuracy of 90 %, precision of\n92 %, recall of 90 %, and an F1 score of 91 %. Findings reveal that pedestrian\nfatalities are more common in mid-block locations and areas with poor\nvisibility, with older adults and substance-impaired individuals at higher\nrisk. These insights can inform policymakers and urban planners in implementing\ntargeted safety measures, such as improved lighting, enhanced pedestrian\ninfrastructure, and stricter traffic law enforcement, to reduce fatalities and\nimprove public safety.", "published": "2025-03-22 02:44:41", "link": "http://arxiv.org/abs/2503.17623v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "OmniScience: A Domain-Specialized LLM for Scientific Reasoning and Discovery", "abstract": "Large Language Models (LLMs) have demonstrated remarkable potential in\nadvancing scientific knowledge and addressing complex challenges. In this work,\nwe introduce OmniScience, a specialized large reasoning model for general\nscience, developed through three key components: (1) domain adaptive\npretraining on a carefully curated corpus of scientific literature, (2)\ninstruction tuning on a specialized dataset to guide the model in following\ndomain-specific tasks, and (3) reasoning-based knowledge distillation through\nfine-tuning to significantly enhance its ability to generate contextually\nrelevant and logically sound responses. We demonstrate the versatility of\nOmniScience by developing a battery agent that efficiently ranks molecules as\npotential electrolyte solvents or additives. Comprehensive evaluations reveal\nthat OmniScience is competitive with state-of-the-art large reasoning models on\nthe GPQA Diamond and domain-specific battery benchmarks, while outperforming\nall public reasoning and non-reasoning models with similar parameter counts. We\nfurther demonstrate via ablation experiments that domain adaptive pretraining\nand reasoning-based knowledge distillation are critical to attain our\nperformance levels, across benchmarks.", "published": "2025-03-22 01:18:59", "link": "http://arxiv.org/abs/2503.17604v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "A Generative Caching System for Large Language Models", "abstract": "Caching has the potential to be of significant benefit for accessing large\nlanguage models (LLMs) due to their high latencies which typically range from a\nsmall number of seconds to well over a minute. Furthermore, many LLMs charge\nmoney for queries; caching thus has a clear monetary benefit. This paper\npresents a new caching system for improving user experiences with LLMs. In\naddition to reducing both latencies and monetary costs for accessing LLMs, our\nsystem also provides important features that go beyond the performance benefits\ntypically associated with caches. A key feature we provide is generative\ncaching, wherein multiple cached responses can be synthesized to provide\nanswers to queries which have never been seen before. Our generative caches\nfunction as repositories of valuable information which can be mined and\nanalyzed. We also improve upon past semantic caching techniques by tailoring\nthe caching algorithms to optimally balance cost and latency reduction with the\nquality of responses provided. Performance tests indicate that our caches are\nconsiderably faster than GPTcache.", "published": "2025-03-22 01:17:56", "link": "http://arxiv.org/abs/2503.17603v1", "categories": ["cs.DB", "cs.AI", "cs.DC", "cs.NI"], "primary_category": "cs.DB"}
{"title": "ConSol: Sequential Probability Ratio Testing to Find Consistent LLM Reasoning Paths Efficiently", "abstract": "Recent advancements in large language models (LLMs) integrating explicit\nreasoning, such as OpenAI's o3-mini, DeepSeek-R1, and QWQ-32B, enable smaller\nmodels to solve complex tasks by generating intermediate reasoning steps prior\nto providing answers. However, this approach significantly increases\ncomputational costs, both monetarily and environmentally. The widely-used\nself-consistency method further exacerbates these costs by aggregating multiple\nreasoning paths to improve accuracy, often requiring between 40 to 64 samples\nper task. Although aggregation effectively reduces variance and bias,\nadditional sampling can lead to diminishing returns when early samples yield\nconsistent results. To address inefficiencies, we propose leveraging Sequential\nProbability Ratio Testing (SPRT) to dynamically terminate sampling once\nsufficient consistency is achieved. We calibrate SPRT parameters specifically\nfor LLM applications, accounting for sensitivity to detect the mode of the\ndistribution. Our experiments demonstrate that incorporating SPRT significantly\nenhances token efficiency, achieving comparable accuracy to self-consistency\nmethods but at a substantially reduced computational cost. To promote\ntransparency and facilitate reproducibility, we have made the source code and\ndatasets used in our experiments publicly available at our GitHub repository:\nhttps://github.com/LiuzLab/consol, or available as a PyPI package: pip install\nconsol. We hope that this resource will support further research and encourage\nthe development of new methods building upon our work.", "published": "2025-03-22 00:07:28", "link": "http://arxiv.org/abs/2503.17587v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Explainable identification of similarities between entities for discovery in large text", "abstract": "With the availability of virtually infinite number text documents in digital\nformat, automatic comparison of textual data is essential for extracting\nmeaningful insights that are difficult to identify manually. Many existing\ntools, including AI and large language models, struggle to provide precise and\nexplainable insights into textual similarities. In many cases they determine\nthe similarity between documents as reflected by the text, rather than the\nsimilarities between the subjects being discussed in these documents. This\nstudy addresses these limitations by developing an n-gram analysis framework\ndesigned to compare documents automatically and uncover explainable\nsimilarities. A scoring formula is applied to assigns each of the n-grams with\na weight, where the weight is higher when the n-grams are more frequent in both\ndocuments, but is penalized when the n-grams are more frequent in the English\nlanguage. Visualization tools like word clouds enhance the representation of\nthese patterns, providing clearer insights. The findings demonstrate that this\nframework effectively uncovers similarities between text documents, offering\nexplainable insights that are often difficult to identify manually. This\nnon-parametric approach provides a deterministic solution for identifying\nsimilarities across various fields, including biographies, scientific\nliterature, historical texts, and more. Code for the method is publicly\navailable.", "published": "2025-03-22 01:20:43", "link": "http://arxiv.org/abs/2503.17605v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "On the Minimax Regret of Sequential Probability Assignment via Square-Root Entropy", "abstract": "We study the problem of sequential probability assignment under logarithmic\nloss, both with and without side information. Our objective is to analyze the\nminimax regret -- a notion extensively studied in the literature -- in terms of\ngeometric quantities, such as covering numbers and scale-sensitive dimensions.\nWe show that the minimax regret for the case of no side information\n(equivalently, the Shtarkov sum) can be upper bounded in terms of sequential\nsquare-root entropy, a notion closely related to Hellinger distance. For the\nproblem of sequential probability assignment with side information, we develop\nboth upper and lower bounds based on the aforementioned entropy. The lower\nbound matches the upper bound, up to log factors, for classes in the Donsker\nregime (according to our definition of entropy).", "published": "2025-03-22 17:26:34", "link": "http://arxiv.org/abs/2503.17823v1", "categories": ["cs.LG", "cs.IT", "math.IT", "stat.ML"], "primary_category": "cs.LG"}
{"title": "An algorithm for computing generalized Hamming weights and the Sage package GHWs", "abstract": "We generalize the Brouwer-Zimmermann algorithm, which is the most efficient\ngeneral algorithm for computing the minimum distance of a random linear code,\nto the case of generalized Hamming weights. We also adapt this algorithm to\ncompute the relative generalized Hamming weights of a nested pair of linear\ncodes. In the package GHWs we provide an implementation of this algorithm in\nSage, as well as several other utilities for working with generalized Hamming\nweights. With this implementation, we show that the proposed algorithm is\nfaster than the naive approach of computing the generalized Hamming weights\nusing the definition.", "published": "2025-03-22 13:13:22", "link": "http://arxiv.org/abs/2503.17764v2", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Robust Blind Channel Estimation for Bursty Impulsive Noise with a Constrained EM Approach", "abstract": "Impulsive noise (IN) commonly generated by power devices can severely degrade\nthe performance of high sensitivity wireless receivers. Accurate channel state\ninformation (CSI) knowledge is essential for designing optimal maximum a\nposteriori detectors. This paper examines blind channel estimation methods\nbased on the expectation-maximization (EM) algorithm tailored for scenarios\nimpacted by bursty IN, which can be described by the Markov-Middleton model. We\npropose a constrained EM algorithm that exploits the trellis structure of the\nIN model and the transmitted binary phase shift keying (BPSK) symbols. By\nenforcing shared variance among specific trellis states and symmetry in the\ntransition matrix, the proposed constrained EM algorithm adapted for the bursty\nIN channel has an almost two times faster convergence rate and better\nestimation performance than the standard EM approach. We comprehensively\nevaluate the robustness of both standard and constrained EM estimators under\ndifferent types of CSI uncertainties. The results indicate that the final\nestimations of both EM estimators are robust enough to mismatch\nMarkov-Middleton model parameters. However, as the level of CSI uncertainty\nincreases, the convergence rate decreases.", "published": "2025-03-22 07:39:21", "link": "http://arxiv.org/abs/2504.03685v1", "categories": ["eess.SP", "cs.IT", "cs.LG", "math.IT"], "primary_category": "eess.SP"}
{"title": "LZMidi: Compression-Based Symbolic Music Generation", "abstract": "Recent advances in symbolic music generation primarily rely on deep learning\nmodels such as Transformers, GANs, and diffusion models. While these approaches\nachieve high-quality results, they require substantial computational resources,\nlimiting their scalability. We introduce LZMidi, a lightweight symbolic music\ngeneration framework based on a Lempel-Ziv (LZ78)-induced sequential\nprobability assignment (SPA). By leveraging the discrete and sequential\nstructure of MIDI data, our approach enables efficient music generation on\nstandard CPUs with minimal training and inference costs. Theoretically, we\nestablish universal convergence guarantees for our approach, underscoring its\nreliability and robustness. Compared to state-of-the-art diffusion models,\nLZMidi achieves competitive Frechet Audio Distance (FAD), Wasserstein Distance\n(WD), and Kullback-Leibler (KL) scores, while significantly reducing\ncomputational overhead - up to 30x faster training and 300x faster generation.\nOur results position LZMidi as a significant advancement in compression-based\nlearning, highlighting how universal compression techniques can efficiently\nmodel and generate structured sequential data, such as symbolic music, with\npractical scalability and theoretical rigor.", "published": "2025-03-22 05:14:17", "link": "http://arxiv.org/abs/2503.17654v1", "categories": ["cs.SD", "cs.IT", "math.IT"], "primary_category": "cs.SD"}
{"title": "Quantized Analog Beamforming Enabled Multi-task Federated Learning Over-the-air", "abstract": "Over-the-air computation (AirComp) has recently emerged as a pivotal\ntechnique for communication-efficient federated learning (FL) in\nresource-constrained wireless networks. Though AirComp leverages the\nsuperposition property of multiple access channels for computation, it\ninherently limits its ability to manage inter-task interference in multi-task\ncomputing. In this paper, we propose a quantized analog beamforming scheme at\nthe receiver to enable simultaneous multi-task FL. Specifically, inspiring by\nthe favorable propagation and channel hardening properties of large-scale\nantenna arrays, a targeted analog beamforming method in closed form is proposed\nfor statistical interference elimination. Analytical results reveal that the\ninterference power vanishes by an order of $\\mathcal{O}\\left(1/N_r\\right)$ with\nthe number of analog phase shifters, $N_r$, irrespective of their quantization\nprecision. Numerical results demonstrate the effectiveness of the proposed\nanalog beamforming method and show that the performance upper bound of ideal\nlearning without errors can be achieved by increasing the number of\nlow-precision analog phase shifters.", "published": "2025-03-22 04:46:16", "link": "http://arxiv.org/abs/2503.17649v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Clearing Sections of Lattice Liability Networks", "abstract": "Modern financial networks involve complex obligations that transcend simple\nmonetary debts: multiple currencies, prioritized claims, supply chain\ndependencies, and more. We present a mathematical framework that unifies and\nextends these scenarios by recasting the classical Eisenberg-Noe model of\nfinancial clearing in terms of lattice liability networks. Each node in the\nnetwork carries a complete lattice of possible states, while edges encode\nnominal liabilities. Our framework generalizes the scalar-valued clearing\nvectors of the classical model to lattice-valued clearing sections, preserving\nthe elegant fixed-point structure while dramatically expanding its descriptive\npower. Our main theorem establishes that such networks possess clearing\nsections that themselves form a complete lattice under the product order. This\nstructure theorem enables tractable analysis of equilibria in diverse domains,\nincluding multi-currency financial systems, decentralized finance with\nautomated market makers, supply chains with resource transformation, and\npermission networks with complex authorization structures. We further extend\nour framework to chain-complete lattices for term structure models and\nmultivalued mappings for complex negotiation systems. Our results demonstrate\nhow lattice theory provides a natural language for understanding complex\nnetwork dynamics across multiple domains, creating a unified mathematical\nfoundation for analyzing systemic risk, resource allocation, and network\nstability.", "published": "2025-03-22 18:38:19", "link": "http://arxiv.org/abs/2503.17836v1", "categories": ["q-fin.MF", "91G40, 06B23, 91D30, 68Q85"], "primary_category": "q-fin.MF"}
{"title": "Mixed-gradients Distributed Filtered Reference Least Mean Square Algorithm -- A Robust Distributed Multichannel Active Noise Control Algorithm", "abstract": "Distributed multichannel active noise control (DMCANC), which utilizes\nmultiple individual processors to achieve a global noise reduction performance\ncomparable to conventional centralized multichannel active noise control\n(MCANC), has become increasingly attractive due to its high computational\nefficiency. However, the majority of current DMCANC algorithms disregard the\nimpact of crosstalk across nodes and impose the assumption of an ideal network\ndevoid of communication limitations, which is an unrealistic assumption.\nTherefore, this work presents a robust DMCANC algorithm that employs the\ncompensating filter to mitigate the impact of crosstalk. The proposed solution\nenhances the DMCANC system's flexibility and security by utilizing local\ngradients instead of local control filters to convey enhanced information,\nresulting in a mixed-gradients distributed filtered reference least mean square\n(MGDFxLMS) algorithm. The performance investigation demonstrates that the\nproposed approach performs well with the centralized method. Furthermore, to\naddress the issue of communication delay in the distributed network, a\npractical strategy that auto-shrinks the step size value in response to the\ndelayed samples is implemented to improve the system's resilience. The\nnumerical simulation results demonstrate the efficacy of the proposed\nauto-shrink step size MGDFxLMS (ASSS-MGDFxLMS) algorithm across various\ncommunication delays, highlighting its practical value.", "published": "2025-03-22 03:42:09", "link": "http://arxiv.org/abs/2503.17634v1", "categories": ["eess.SY", "cs.SY", "eess.AS", "eess.SP"], "primary_category": "eess.SY"}
