{"title": "A Novel Approach to Queue-Reactive Models: The Importance of Order Sizes", "abstract": "In this article, we delve into the applications and extensions of the\nqueue-reactive model for the simulation of limit order books. Our approach\nemphasizes the importance of order sizes, in conjunction with their type and\narrival rate, by integrating the current state of the order book to determine,\nnot only the intensity of order arrivals and their type, but also their sizes.\nThese extensions generate simulated markets that are in line with numerous\nstylized facts of the market. Our empirical calibration, using futures on\nGerman bonds, reveals that the extended queue-reactive model significantly\nimproves the description of order flow properties and the shape of queue\ndistributions. Moreover, our findings demonstrate that the extended model\nproduces simulated markets with a volatility comparable to historical real\ndata, utilizing only endogenous information from the limit order book. This\nresearch underscores the potential of the queue-reactive model and its\nextensions in accurately simulating market dynamics and providing valuable\ninsights into the complex nature of limit order book modeling.", "published": "2024-05-28 21:14:33", "link": "http://arxiv.org/abs/2405.18594v1", "categories": ["q-fin.TR"], "primary_category": "q-fin.TR"}
{"title": "C$^{3}$Bench: A Comprehensive Classical Chinese Understanding Benchmark\n  for Large Language Models", "abstract": "Classical Chinese Understanding (CCU) holds significant value in preserving\nand exploration of the outstanding traditional Chinese culture. Recently,\nresearchers have attempted to leverage the potential of Large Language Models\n(LLMs) for CCU by capitalizing on their remarkable comprehension and semantic\ncapabilities. However, no comprehensive benchmark is available to assess the\nCCU capabilities of LLMs. To fill this gap, this paper introduces C$^{3}$bench,\na Comprehensive Classical Chinese understanding benchmark, which comprises\n50,000 text pairs for five primary CCU tasks, including classification,\nretrieval, named entity recognition, punctuation, and translation. Furthermore,\nthe data in C$^{3}$bench originates from ten different domains, covering most\nof the categories in classical Chinese. Leveraging the proposed C$^{3}$bench,\nwe extensively evaluate the quantitative performance of 15 representative LLMs\non all five CCU tasks. Our results not only establish a public leaderboard of\nLLMs' CCU capabilities but also gain some findings. Specifically, existing LLMs\nare struggle with CCU tasks and still inferior to supervised models.\nAdditionally, the results indicate that CCU is a task that requires special\nattention. We believe this study could provide a standard benchmark,\ncomprehensive baselines, and valuable insights for the future advancement of\nLLM-based CCU research. The evaluation pipeline and dataset are available at\n\\url{https://github.com/SCUT-DLVCLab/C3bench}.", "published": "2024-05-28 01:23:58", "link": "http://arxiv.org/abs/2405.17732v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MobileConvRec: A Conversational Dataset for Mobile Apps Recommendations", "abstract": "Existing recommendation systems have focused on two paradigms: 1- historical\nuser-item interaction-based recommendations and 2- conversational\nrecommendations. Conversational recommendation systems facilitate natural\nlanguage dialogues between users and the system, allowing the system to solicit\nusers' explicit needs while enabling users to inquire about recommendations and\nprovide feedback. Due to substantial advancements in natural language\nprocessing, conversational recommendation systems have gained prominence.\nExisting conversational recommendation datasets have greatly facilitated\nresearch in their respective domains. Despite the exponential growth in mobile\nusers and apps in recent years, research in conversational mobile app\nrecommender systems has faced substantial constraints. This limitation can\nprimarily be attributed to the lack of high-quality benchmark datasets\nspecifically tailored for mobile apps. To facilitate research for\nconversational mobile app recommendations, we introduce MobileConvRec.\nMobileConvRec simulates conversations by leveraging real user interactions with\nmobile apps on the Google Play store, originally captured in large-scale mobile\napp recommendation dataset MobileRec. The proposed conversational\nrecommendation dataset synergizes sequential user-item interactions, which\nreflect implicit user preferences, with comprehensive multi-turn conversations\nto effectively grasp explicit user needs. MobileConvRec consists of over 12K\nmulti-turn recommendation-related conversations spanning 45 app categories.\nMoreover, MobileConvRec presents rich metadata for each app such as permissions\ndata, security and privacy-related information, and binary executables of apps,\namong others. We demonstrate that MobileConvRec can serve as an excellent\ntestbed for conversational mobile app recommendation through a comparative\nstudy of several pre-trained large language models.", "published": "2024-05-28 01:53:16", "link": "http://arxiv.org/abs/2405.17740v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detection-Correction Structure via General Language Model for\n  Grammatical Error Correction", "abstract": "Grammatical error correction (GEC) is a task dedicated to rectifying texts\nwith minimal edits, which can be decoupled into two components: detection and\ncorrection. However, previous works have predominantly focused on direct\ncorrection, with no prior efforts to integrate both into a single model.\nMoreover, the exploration of the detection-correction paradigm by large\nlanguage models (LLMs) remains underdeveloped. This paper introduces an\nintegrated detection-correction structure, named DeCoGLM, based on the General\nLanguage Model (GLM). The detection phase employs a fault-tolerant detection\ntemplate, while the correction phase leverages autoregressive mask infilling\nfor localized error correction. Through the strategic organization of input\ntokens and modification of attention masks, we facilitate multi-task learning\nwithin a single model. Our model demonstrates competitive performance against\nthe state-of-the-art models on English and Chinese GEC datasets. Further\nexperiments present the effectiveness of the detection-correction structure in\nLLMs, suggesting a promising direction for GEC.", "published": "2024-05-28 04:04:40", "link": "http://arxiv.org/abs/2405.17804v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "More Than Catastrophic Forgetting: Integrating General Capabilities For\n  Domain-Specific LLMs", "abstract": "The performance on general tasks decreases after Large Language Models (LLMs)\nare fine-tuned on domain-specific tasks, the phenomenon is known as\nCatastrophic Forgetting (CF). However, this paper presents a further challenge\nfor real application of domain-specific LLMs beyond CF, called General\nCapabilities Integration (GCI), which necessitates the integration of both the\ngeneral capabilities and domain knowledge within a single instance. The\nobjective of GCI is not merely to retain previously acquired general\ncapabilities alongside new domain knowledge, but to harmonize and utilize both\nsets of skills in a cohesive manner to enhance performance on domain-specific\ntasks. Taking legal domain as an example, we carefully design three groups of\ntraining and testing tasks without lacking practicability, and construct the\ncorresponding datasets. To better incorporate general capabilities across\ndomain-specific scenarios, we introduce ALoRA, which utilizes a multi-head\nattention module upon LoRA, facilitating direct information transfer from\npreceding tokens to the current one. This enhancement permits the\nrepresentation to dynamically switch between domain-specific knowledge and\ngeneral competencies according to the attention. Extensive experiments are\nconducted on the proposed tasks. The results exhibit the significance of our\nsetting, and the effectiveness of our method.", "published": "2024-05-28 05:00:12", "link": "http://arxiv.org/abs/2405.17830v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Benchmarks Underestimate the Readiness of Multi-lingual Dialogue Agents", "abstract": "Creating multilingual task-oriented dialogue (TOD) agents is challenging due\nto the high cost of training data acquisition. Following the research trend of\nimproving training data efficiency, we show for the first time, that in-context\nlearning is sufficient to tackle multilingual TOD.\n  To handle the challenging dialogue state tracking (DST) subtask, we break it\ndown to simpler steps that are more compatible with in-context learning where\nonly a handful of few-shot examples are used. We test our approach on the\nmultilingual TOD dataset X-RiSAWOZ, which has 12 domains in Chinese, English,\nFrench, Korean, Hindi, and code-mixed Hindi-English. Our turn-by-turn DST\naccuracy on the 6 languages range from 55.6% to 80.3%, seemingly worse than the\nSOTA results from fine-tuned models that achieve from 60.7% to 82.8%; our BLEU\nscores in the response generation (RG) subtask are also significantly lower\nthan SOTA.\n  However, after manual evaluation of the validation set, we find that by\ncorrecting gold label errors and improving dataset annotation schema, GPT-4\nwith our prompts can achieve (1) 89.6%-96.8% accuracy in DST, and (2) more than\n99% correct response generation across different languages. This leads us to\nconclude that current automatic metrics heavily underestimate the effectiveness\nof in-context learning.", "published": "2024-05-28 05:33:13", "link": "http://arxiv.org/abs/2405.17840v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Emotion Recognition in Conversation through Emotional\n  Cross-Modal Fusion and Inter-class Contrastive Learning", "abstract": "The purpose of emotion recognition in conversation (ERC) is to identify the\nemotion category of an utterance based on contextual information. Previous ERC\nmethods relied on simple connections for cross-modal fusion and ignored the\ninformation differences between modalities, resulting in the model being unable\nto focus on modality-specific emotional information. At the same time, the\nshared information between modalities was not processed to generate emotions.\nInformation redundancy problem. To overcome these limitations, we propose a\ncross-modal fusion emotion prediction network based on vector connections. The\nnetwork mainly includes two stages: the multi-modal feature fusion stage based\non connection vectors and the emotion classification stage based on fused\nfeatures. Furthermore, we design a supervised inter-class contrastive learning\nmodule based on emotion labels. Experimental results confirm the effectiveness\nof the proposed method, demonstrating excellent performance on the IEMOCAP and\nMELD datasets.", "published": "2024-05-28 07:22:30", "link": "http://arxiv.org/abs/2405.17900v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Long Context is Not Long at All: A Prospector of Long-Dependency Data\n  for Large Language Models", "abstract": "Long-context modeling capabilities are important for large language models\n(LLMs) in various applications. However, directly training LLMs with long\ncontext windows is insufficient to enhance this capability since some training\nsamples do not exhibit strong semantic dependencies across long contexts. In\nthis study, we propose a data mining framework \\textbf{ProLong} that can assign\neach training sample with a long dependency score, which can be used to rank\nand filter samples that are more advantageous for enhancing long-context\nmodeling abilities in LLM training. Specifically, we first use delta perplexity\nscores to measure the \\textit{Dependency Strength} between text segments in a\ngiven document. Then we refine this metric based on the \\textit{Dependency\nDistance} of these segments to incorporate spatial relationships across\nlong-contexts. Final results are calibrated with a \\textit{Dependency\nSpecificity} metric to prevent trivial dependencies introduced by repetitive\npatterns. Moreover, a random sampling approach is proposed to optimize the\ncomputational efficiency of ProLong. Comprehensive experiments on multiple\nbenchmarks indicate that ProLong effectively identifies documents that carry\nlong dependencies and LLMs trained on these documents exhibit significantly\nenhanced long-context modeling capabilities.", "published": "2024-05-28 07:36:56", "link": "http://arxiv.org/abs/2405.17915v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transformer and Hybrid Deep Learning Based Models for Machine-Generated\n  Text Detection", "abstract": "This paper describes the approach of the UniBuc - NLP team in tackling the\nSemEval 2024 Task 8: Multigenerator, Multidomain, and Multilingual Black-Box\nMachine-Generated Text Detection. We explored transformer-based and hybrid deep\nlearning architectures. For subtask B, our transformer-based model achieved a\nstrong \\textbf{second-place} out of $77$ teams with an accuracy of\n\\textbf{86.95\\%}, demonstrating the architecture's suitability for this task.\nHowever, our models showed overfitting in subtask A which could potentially be\nfixed with less fine-tunning and increasing maximum sequence length. For\nsubtask C (token-level classification), our hybrid model overfit during\ntraining, hindering its ability to detect transitions between human and\nmachine-generated text.", "published": "2024-05-28 08:48:08", "link": "http://arxiv.org/abs/2405.17964v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Aligning to Thousands of Preferences via System Message Generalization", "abstract": "Although humans inherently have diverse values, current large language model\n(LLM) alignment methods often assume that aligning LLMs with the general\npublic's preferences is optimal. A major challenge in adopting a more\nindividualized approach to LLM alignment is its lack of scalability, as it\ninvolves repeatedly acquiring preference data and training new reward models\nand LLMs for each individual's preferences. To address these challenges, we\npropose a new paradigm where users specify what they value most within the\nsystem message, steering the LLM's generation behavior to better align with the\nuser's intentions. However, a naive application of such an approach is\nnon-trivial since LLMs are typically trained on a uniform system message (e.g.,\n\"You are a helpful assistant\") which limits their ability to generalize to\ndiverse, unseen system messages. To improve this generalization, we create the\nMultifaceted Collection, a preference dataset with 192k combinations of values\nbeyond generic helpfulness and harmlessness, spanning 65k user instructions.\nUsing this dataset, we train a 7B LLM called Janus and test it on 921 prompts\nfrom 5 benchmarks (AlpacaEval 2.0, FLASK, Koala, MT-Bench, and Self-Instruct)\nby adding various unseen system messages that reflect user preferences. Janus\nachieves tie+win rate of 75.2%, 72.4%, and 66.4% against Mistral 7B Instruct\nv0.2, GPT-3.5 Turbo, and GPT-4, respectively. Unexpectedly, on three benchmarks\nfocused on response helpfulness (AlpacaEval 2.0, MT-Bench, Arena Hard Auto\nv0.1), Janus also outperforms LLaMA 3 8B Instruct by a +4.0%, +0.1%, +3.0%\nmargin, underscoring that training with a vast array of system messages could\nalso enhance alignment to the general public's preference as well. Our code,\ndataset, benchmark, and models are available at\nhttps://github.com/kaistAI/Janus.", "published": "2024-05-28 09:06:18", "link": "http://arxiv.org/abs/2405.17977v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Peering into the Mind of Language Models: An Approach for Attribution in\n  Contextual Question Answering", "abstract": "With the enhancement in the field of generative artificial intelligence (AI),\ncontextual question answering has become extremely relevant. Attributing model\ngenerations to the input source document is essential to ensure trustworthiness\nand reliability. We observe that when large language models (LLMs) are used for\ncontextual question answering, the output answer often consists of text copied\nverbatim from the input prompt which is linked together with \"glue text\"\ngenerated by the LLM. Motivated by this, we propose that LLMs have an inherent\nawareness from where the text was copied, likely captured in the hidden states\nof the LLM. We introduce a novel method for attribution in contextual question\nanswering, leveraging the hidden state representations of LLMs. Our approach\nbypasses the need for extensive model retraining and retrieval model overhead,\noffering granular attributions and preserving the quality of generated answers.\nOur experimental results demonstrate that our method performs on par or better\nthan GPT-4 at identifying verbatim copied segments in LLM generations and in\nattributing these segments to their source. Importantly, our method shows\nrobust performance across various LLM architectures, highlighting its broad\napplicability. Additionally, we present Verifiability-granular, an attribution\ndataset which has token level annotations for LLM generations in the contextual\nquestion answering setup.", "published": "2024-05-28 09:12:44", "link": "http://arxiv.org/abs/2405.17980v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MultiADE: A Multi-domain Benchmark for Adverse Drug Event Extraction", "abstract": "Active adverse event surveillance monitors Adverse Drug Events (ADE) from\ndifferent data sources, such as electronic health records, medical literature,\nsocial media and search engine logs. Over the years, many datasets have been\ncreated, and shared tasks have been organised to facilitate active adverse\nevent surveillance. However, most - if not all - datasets or shared tasks focus\non extracting ADEs from a particular type of text. Domain generalisation - the\nability of a machine learning model to perform well on new, unseen domains\n(text types) - is under-explored. Given the rapid advancements in natural\nlanguage processing, one unanswered question is how far we are from having a\nsingle ADE extraction model that is effective on various types of text, such as\nscientific literature and social media posts. We contribute to answering this\nquestion by building a multi-domain benchmark for adverse drug event\nextraction, which we named MultiADE. The new benchmark comprises several\nexisting datasets sampled from different text types and our newly created\ndataset - CADECv2, which is an extension of CADEC, covering online posts\nregarding more diverse drugs than CADEC. Our new dataset is carefully annotated\nby human annotators following detailed annotation guidelines. Our benchmark\nresults show that the generalisation of the trained models is far from perfect,\nmaking it infeasible to be deployed to process different types of text. In\naddition, although intermediate transfer learning is a promising approach to\nutilising existing resources, further investigation is needed on methods of\ndomain adaptation, particularly cost-effective methods to select useful\ntraining instances. The newly created CADECv2 and the scripts for building the\nbenchmark are publicly available at CSIRO's Data Portal.", "published": "2024-05-28 09:57:28", "link": "http://arxiv.org/abs/2405.18015v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TimeChara: Evaluating Point-in-Time Character Hallucination of\n  Role-Playing Large Language Models", "abstract": "While Large Language Models (LLMs) can serve as agents to simulate human\nbehaviors (i.e., role-playing agents), we emphasize the importance of\npoint-in-time role-playing. This situates characters at specific moments in the\nnarrative progression for three main reasons: (i) enhancing users' narrative\nimmersion, (ii) avoiding spoilers, and (iii) fostering engagement in fandom\nrole-playing. To accurately represent characters at specific time points,\nagents must avoid character hallucination, where they display knowledge that\ncontradicts their characters' identities and historical timelines. We introduce\nTimeChara, a new benchmark designed to evaluate point-in-time character\nhallucination in role-playing LLMs. Comprising 10,895 instances generated\nthrough an automated pipeline, this benchmark reveals significant hallucination\nissues in current state-of-the-art LLMs (e.g., GPT-4o). To counter this\nchallenge, we propose Narrative-Experts, a method that decomposes the reasoning\nsteps and utilizes narrative experts to reduce point-in-time character\nhallucinations effectively. Still, our findings with TimeChara highlight the\nongoing challenges of point-in-time character hallucination, calling for\nfurther study.", "published": "2024-05-28 10:19:18", "link": "http://arxiv.org/abs/2405.18027v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Instruction Tuning with Retrieval-based Examples Ranking for\n  Aspect-based Sentiment Analysis", "abstract": "Aspect-based sentiment analysis (ABSA) identifies sentiment information\nrelated to specific aspects and provides deeper market insights to businesses\nand organizations. With the emergence of large language models (LMs), recent\nstudies have proposed using fixed examples for instruction tuning to\nreformulate ABSA as a generation task. However, the performance is sensitive to\nthe selection of in-context examples; several retrieval methods are based on\nsurface similarity and are independent of the LM generative objective. This\nstudy proposes an instruction learning method with retrieval-based example\nranking for ABSA tasks. For each target sample, an LM was applied as a scorer\nto estimate the likelihood of the output given the input and a candidate\nexample as the prompt, and training examples were labeled as positive or\nnegative by ranking the scores. An alternating training schema is proposed to\ntrain both the retriever and LM. Instructional prompts can be constructed using\nhigh-quality examples. The LM is used for both scoring and inference, improving\nthe generation efficiency without incurring additional computational costs or\ntraining difficulties. Extensive experiments on three ABSA subtasks verified\nthe effectiveness of the proposed method, demonstrating its superiority over\nvarious strong baseline models. Code and data are released at\nhttps://github.com/zgMin/IT-RER-ABSA.", "published": "2024-05-28 10:39:10", "link": "http://arxiv.org/abs/2405.18035v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PRFashion24: A Dataset for Sentiment Analysis of Fashion Products\n  Reviews in Persian", "abstract": "The PRFashion24 dataset is a comprehensive Persian dataset collected from\nvarious online fashion stores, spanning from April 2020 to March 2024. With\n767,272 reviews, it is the first dataset in its kind that encompasses diverse\ncategories within the fashion industry in the Persian language. The goal of\nthis study is to harness deep learning techniques, specifically Long Short-Term\nMemory (LSTM) networks and a combination of Bidirectional LSTM and\nConvolutional Neural Network (BiLSTM-CNN), to analyze and reveal sentiments\ntowards online fashion shopping. The LSTM model yielded an accuracy of 81.23%,\nwhile the BiLSTM-CNN model reached 82.89%. This research aims not only to\nintroduce a diverse dataset in the field of fashion but also to enhance the\npublic's understanding of opinions on online fashion shopping, which\npredominantly reflect a positive sentiment. Upon publication, both the\noptimized models and the PRFashion24 dataset will be available on GitHub.", "published": "2024-05-28 11:19:13", "link": "http://arxiv.org/abs/2405.18060v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Context is Important in Depressive Language: A Study of the Interaction\n  Between the Sentiments and Linguistic Markers in Reddit Discussions", "abstract": "Research exploring linguistic markers in individuals with depression has\ndemonstrated that language usage can serve as an indicator of mental health.\nThis study investigates the impact of discussion topic as context on linguistic\nmarkers and emotional expression in depression, using a Reddit dataset to\nexplore interaction effects. Contrary to common findings, our sentiment\nanalysis revealed a broader range of emotional intensity in depressed\nindividuals, with both higher negative and positive sentiments than controls.\nThis pattern was driven by posts containing no emotion words, revealing the\nlimitations of the lexicon based approaches in capturing the full emotional\ncontext. We observed several interesting results demonstrating the importance\nof contextual analyses. For instance, the use of 1st person singular pronouns\nand words related to anger and sadness correlated with increased positive\nsentiments, whereas a higher rate of present-focused words was associated with\nmore negative sentiments. Our findings highlight the importance of discussion\ncontexts while interpreting the language used in depression, revealing that the\nemotional intensity and meaning of linguistic markers can vary based on the\ntopic of discussion.", "published": "2024-05-28 11:19:39", "link": "http://arxiv.org/abs/2405.18061v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ATM: Adversarial Tuning Multi-agent System Makes a Robust\n  Retrieval-Augmented Generator", "abstract": "Large language models (LLMs) are proven to benefit a lot from\nretrieval-augmented generation (RAG) in alleviating hallucinations confronted\nwith knowledge-intensive questions. RAG adopts information retrieval techniques\nto inject external knowledge from semantic-relevant documents as input\ncontexts. However, since today's Internet is flooded with numerous noisy and\nfabricating content, it is inevitable that RAG systems are vulnerable to these\nnoises and prone to respond incorrectly. To this end, we propose to optimize\nthe retrieval-augmented Generator with an Adversarial Tuning Multi-agent system\n(ATM). The ATM steers the Generator to have a robust perspective of useful\ndocuments for question answering with the help of an auxiliary Attacker agent\nthrough adversarially tuning the agents for several iterations. After rounds of\nmulti-agent iterative tuning, the Generator can eventually better discriminate\nuseful documents amongst fabrications. The experimental results verify the\neffectiveness of ATM and we also observe that the Generator can achieve better\nperformance compared to the state-of-the-art baselines.", "published": "2024-05-28 12:18:50", "link": "http://arxiv.org/abs/2405.18111v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Knesset Corpus: An Annotated Corpus of Hebrew Parliamentary\n  Proceedings", "abstract": "We present the Knesset Corpus, a corpus of Hebrew parliamentary proceedings\ncontaining over 30 million sentences (over 384 million tokens) from all the\n(plenary and committee) protocols held in the Israeli parliament between 1998\nand 2022. Sentences are annotated with morpho-syntactic information and are\nassociated with detailed meta-information reflecting demographic and political\nproperties of the speakers, based on a large database of parliament members and\nfactions that we compiled. We discuss the structure and composition of the\ncorpus and the various processing steps we applied to it. To demonstrate the\nutility of this novel dataset we present two use cases. We show that the corpus\ncan be used to examine historical developments in the style of political\ndiscussions by showing a reduction in lexical richness in the proceedings over\ntime. We also investigate some differences between the styles of men and women\nspeakers. These use cases exemplify the potential of the corpus to shed light\non important trends in the Israeli society, supporting research in linguistics,\npolitical science, communication, law, etc.", "published": "2024-05-28 12:23:39", "link": "http://arxiv.org/abs/2405.18115v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "IAPT: Instruction-Aware Prompt Tuning for Large Language Models", "abstract": "Soft prompt tuning is a widely studied parameter-efficient fine-tuning\nmethod. However, it has a clear drawback: many soft tokens must be inserted\ninto the input sequences to guarantee downstream performance. As a result, soft\nprompt tuning is less considered than Low-rank adaptation (LoRA) in the large\nlanguage modeling (LLM) era. In this work, we propose a novel prompt tuning\nmethod, Instruction-Aware Prompt Tuning (IAPT), that requires only four soft\ntokens. First, we install a parameter-efficient soft prompt generator at each\nTransformer layer to generate idiosyncratic soft prompts for each input\ninstruction. The generated soft prompts can be seen as a semantic summary of\nthe input instructions and can effectively guide the output generation. Second,\nthe soft prompt generators are modules with a bottleneck architecture\nconsisting of a self-attention pooling operation, two linear projections, and\nan activation function. Pilot experiments show that prompt generators at\ndifferent Transformer layers require different activation functions. Thus, we\npropose to learn the idiosyncratic activation functions for prompt generators\nautomatically with the help of rational functions. We have conducted\nexperiments on various tasks, and the experimental results demonstrate that (a)\nour IAPT method can outperform the recent baselines with comparable tunable\nparameters. (b) Our IAPT method is more efficient than LoRA under the\nsingle-backbone multi-tenant setting.", "published": "2024-05-28 14:11:01", "link": "http://arxiv.org/abs/2405.18203v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic are Beacons: A Semantic Perspective for Unveiling\n  Parameter-Efficient Fine-Tuning in Knowledge Learning", "abstract": "Parameter-Efficient Fine-Tuning (PEFT) methods enable efficient adaptation of\nLarge Language Models (LLMs) to various downstream applications. However, the\neffectiveness of the PEFT diminishes notably when downstream tasks require\naccurate learning of factual knowledge. In this paper, we adopt a semantic\nperspective to investigate this phenomenon, uncovering the reasons behind\nPEFT's limitations in knowledge learning task. Our findings reveal that: (1)\nPEFT presents a notable risk of pushing the model away from the intended\nknowledge target; (2) multiple knowledge interfere with each other, and such\ninterference suppresses the learning and expression of knowledge features.\nBased on these insights, we introduce a data filtering strategy to exclude data\nthat is detrimental to knowledge learning and a re-weighted learning strategy\nto make the model attentive to semantic distance during knowledge learning.\nExperimental results demonstrate the effectiveness of the proposed method on\nopen-source large language model, further validate the semantic challenge in\nPEFT, thus paving the way for future research.", "published": "2024-05-28 15:47:11", "link": "http://arxiv.org/abs/2405.18292v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Joint Lemmatization and Morphological Tagging with LEMMING", "abstract": "We present LEMMING, a modular log-linear model that jointly models\nlemmatization and tagging and supports the integration of arbitrary global\nfeatures. It is trainable on corpora annotated with gold standard tags and\nlemmata and does not rely on morphological dictionaries or analyzers. LEMMING\nsets the new state of the art in token-based statistical lemmatization on six\nlanguages; e.g., for Czech lemmatization, we reduce the error by 60%, from 4.05\nto 1.58. We also give empirical evidence that jointly modeling morphological\ntags and lemmata is mutually beneficial.", "published": "2024-05-28 16:01:19", "link": "http://arxiv.org/abs/2405.18308v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Automatic Metrics Assess High-Quality Translations?", "abstract": "Automatic metrics for evaluating translation quality are typically validated\nby measuring how well they correlate with human assessments. However,\ncorrelation methods tend to capture only the ability of metrics to\ndifferentiate between good and bad source-translation pairs, overlooking their\nreliability in distinguishing alternative translations for the same source. In\nthis paper, we confirm that this is indeed the case by showing that current\nmetrics are insensitive to nuanced differences in translation quality. This\neffect is most pronounced when the quality is high and the variance among\nalternatives is low. Given this finding, we shift towards detecting\nhigh-quality correct translations, an important problem in practical\ndecision-making scenarios where a binary check of correctness is prioritized\nover a nuanced evaluation of quality. Using the MQM framework as the gold\nstandard, we systematically stress-test the ability of current metrics to\nidentify translations with no errors as marked by humans. Our findings reveal\nthat current metrics often over or underestimate translation quality,\nindicating significant room for improvement in automatic evaluation methods.", "published": "2024-05-28 16:44:02", "link": "http://arxiv.org/abs/2405.18348v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Faithful Logical Reasoning via Symbolic Chain-of-Thought", "abstract": "While the recent Chain-of-Thought (CoT) technique enhances the reasoning\nability of large language models (LLMs) with the theory of mind, it might still\nstruggle in handling logical reasoning that relies much on symbolic expressions\nand rigid deducing rules. To strengthen the logical reasoning capability of\nLLMs, we propose a novel Symbolic Chain-of-Thought, namely SymbCoT, a fully\nLLM-based framework that integrates symbolic expressions and logic rules with\nCoT prompting. Technically, building upon an LLM, SymbCoT 1) first translates\nthe natural language context into the symbolic format, and then 2) derives a\nstep-by-step plan to solve the problem with symbolic logical rules, 3) followed\nby a verifier to check the translation and reasoning chain. Via thorough\nevaluations on 5 standard datasets with both First-Order Logic and Constraint\nOptimization symbolic expressions, SymbCoT shows striking improvements over the\nCoT method consistently, meanwhile refreshing the current state-of-the-art\nperformances. We further demonstrate that our system advances in more faithful,\nflexible, and explainable logical reasoning. To our knowledge, this is the\nfirst to combine symbolic expressions and rules into CoT for logical reasoning\nwith LLMs. Code is open at https://github.com/Aiden0526/SymbCoT.", "published": "2024-05-28 16:55:33", "link": "http://arxiv.org/abs/2405.18357v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Thai Winograd Schemas: A Benchmark for Thai Commonsense Reasoning", "abstract": "Commonsense reasoning is one of the important aspect of natural language\nunderstanding, with several benchmarks developed to evaluate it. However, only\na few of these benchmarks are available in languages other than English.\nDeveloping parallel benchmarks facilitates cross-lingual evaluation, enabling a\nbetter understanding of different languages. This research introduces a\ncollection of Winograd Schemas in Thai, a novel dataset designed to evaluate\ncommonsense reasoning capabilities in the context of the Thai language.\n  Through a methodology involving native speakers, professional translators,\nand thorough validation, the schemas aim to closely reflect Thai language\nnuances, idioms, and cultural references while maintaining ambiguity and\ncommonsense challenges. We evaluate the performance of popular large language\nmodels on this benchmark, revealing their strengths, limitations, and providing\ninsights into the current state-of-the-art. Results indicate that while models\nlike GPT-4 and Claude-3-Opus achieve high accuracy in English, their\nperformance significantly drops in Thai, highlighting the need for further\nadvancements in multilingual commonsense reasoning.", "published": "2024-05-28 17:14:02", "link": "http://arxiv.org/abs/2405.18375v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Notes on Applicability of GPT-4 to Document Understanding", "abstract": "We perform a missing, reproducible evaluation of all publicly available GPT-4\nfamily models concerning the Document Understanding field, where it is\nfrequently required to comprehend text spacial arrangement and visual clues in\naddition to textual semantics. Benchmark results indicate that though it is\nhard to achieve satisfactory results with text-only models, GPT-4 Vision Turbo\nperforms well when one provides both text recognized by an external OCR engine\nand document images on the input. Evaluation is followed by analyses that\nsuggest possible contamination of textual GPT-4 models and indicate the\nsignificant performance drop for lengthy documents.", "published": "2024-05-28 17:59:53", "link": "http://arxiv.org/abs/2405.18433v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Recent Advances of Foundation Language Models-based Continual Learning:\n  A Survey", "abstract": "Recently, foundation language models (LMs) have marked significant\nachievements in the domains of natural language processing (NLP) and computer\nvision (CV). Unlike traditional neural network models, foundation LMs obtain a\ngreat ability for transfer learning by acquiring rich commonsense knowledge\nthrough pre-training on extensive unsupervised datasets with a vast number of\nparameters. However, they still can not emulate human-like continuous learning\ndue to catastrophic forgetting. Consequently, various continual learning\n(CL)-based methodologies have been developed to refine LMs, enabling them to\nadapt to new tasks without forgetting previous knowledge. However, a systematic\ntaxonomy of existing approaches and a comparison of their performance are still\nlacking, which is the gap that our survey aims to fill. We delve into a\ncomprehensive review, summarization, and classification of the existing\nliterature on CL-based approaches applied to foundation language models, such\nas pre-trained language models (PLMs), large language models (LLMs) and\nvision-language models (VLMs). We divide these studies into offline CL and\nonline CL, which consist of traditional methods, parameter-efficient-based\nmethods, instruction tuning-based methods and continual pre-training methods.\nOffline CL encompasses domain-incremental learning, task-incremental learning,\nand class-incremental learning, while online CL is subdivided into hard task\nboundary and blurry task boundary settings. Additionally, we outline the\ntypical datasets and metrics employed in CL research and provide a detailed\nanalysis of the challenges and future work for LMs-based continual learning.", "published": "2024-05-28 23:32:46", "link": "http://arxiv.org/abs/2405.18653v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mashee at SemEval-2024 Task 8: The Impact of Samples Quality on the\n  Performance of In-Context Learning for Machine Text Classification", "abstract": "Within few-shot learning, in-context learning (ICL) has become a potential\nmethod for leveraging contextual information to improve model performance on\nsmall amounts of data or in resource-constrained environments where training\nmodels on large datasets is prohibitive. However, the quality of the selected\nsample in a few shots severely limits the usefulness of ICL. The primary goal\nof this paper is to enhance the performance of evaluation metrics for\nin-context learning by selecting high-quality samples in few-shot learning\nscenarios. We employ the chi-square test to identify high-quality samples and\ncompare the results with those obtained using low-quality samples. Our findings\ndemonstrate that utilizing high-quality samples leads to improved performance\nwith respect to all evaluated metrics.", "published": "2024-05-28 12:47:43", "link": "http://arxiv.org/abs/2406.17790v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Does Geo-co-location Matter? A Case Study of Public Health Conversations\n  during COVID-19", "abstract": "Social media platforms like Twitter (now X) have been pivotal in information\ndissemination and public engagement, especially during COVID-19. A key goal for\npublic health experts was to encourage prosocial behavior that could impact\nlocal outcomes such as masking and social distancing. Given the importance of\nlocal news and guidance during COVID-19, the objective of our research is to\nanalyze the effect of localized engagement, on social media conversations. This\nstudy examines the impact of geographic co-location, as a proxy for localized\nengagement between public health experts (PHEs) and the public, on social\nmedia. We analyze a Twitter conversation dataset from January 2020 to November\n2021, comprising over 19 K tweets from nearly five hundred PHEs, along with\napproximately 800 K replies from 350 K participants. Our findings reveal that\ngeo-co-location is associated with higher engagement rates, especially in\nconversations on topics including masking, lockdowns, and education, and in\nconversations with academic and medical professionals. Lexical features\nassociated with emotion and personal experiences were more common in\ngeo-co-located contexts. This research provides insights into how geographic\nco-location influences social media engagement and can inform strategies to\nimprove public health messaging.", "published": "2024-05-28 00:00:04", "link": "http://arxiv.org/abs/2405.17710v2", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "A Context-Aware Approach for Enhancing Data Imputation with Pre-trained\n  Language Models", "abstract": "This paper presents a novel approach named \\textbf{C}ontextually\n\\textbf{R}elevant \\textbf{I}mputation leveraging pre-trained \\textbf{L}anguage\n\\textbf{M}odels (\\textbf{CRILM}) for handling missing data in tabular datasets.\nInstead of relying on traditional numerical estimations, CRILM uses pre-trained\nlanguage models (LMs) to create contextually relevant descriptors for missing\nvalues. This method aligns datasets with LMs' strengths, allowing large LMs to\ngenerate these descriptors and small LMs to be fine-tuned on the enriched\ndatasets for enhanced downstream task performance. Our evaluations demonstrate\nCRILM's superior performance and robustness across MCAR, MAR, and challenging\nMNAR scenarios, with up to a 10\\% improvement over the best-performing\nbaselines. By mitigating biases, particularly in MNAR settings, CRILM improves\ndownstream task performance and offers a cost-effective solution for\nresource-constrained environments.", "published": "2024-05-28 00:08:29", "link": "http://arxiv.org/abs/2405.17712v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "XL3M: A Training-free Framework for LLM Length Extension Based on\n  Segment-wise Inference", "abstract": "Length generalization failure problem, namely the large language model (LLM)\nfails to generalize to texts longer than its maximum training length, greatly\nrestricts the application of LLM in the scenarios with streaming long inputs.\nTo address this problem, the existing methods either require substantial costs\nor introduce precision loss. In this paper, we empirically find that the\naccuracy of the LLM's prediction is highly correlated to its certainty. Based\non this, we propose an efficient training free framework, named XL3M (it means\nextra-long large language model), which enables the LLMs trained on short\nsequences to reason extremely long sequence without any further training or\nfine-tuning. Under the XL3M framework, the input context will be firstly\ndecomposed into multiple short sub-contexts, where each sub-context contains an\nindependent segment and a common ``question'' which is a few tokens from the\nend of the original context. Then XL3M gives a method to measure the relevance\nbetween each segment and the ``question'', and constructs a concise key context\nby splicing all the relevant segments in chronological order. The key context\nis further used instead of the original context to complete the inference task.\nEvaluations on comprehensive benchmarks show the superiority of XL3M. Using our\nframework, a Llama2-7B model is able to reason 20M long sequences on an 8-card\nHuawei Ascend 910B NPU machine with 64GB memory per card.", "published": "2024-05-28 02:12:35", "link": "http://arxiv.org/abs/2405.17755v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring Activation Patterns of Parameters in Language Models", "abstract": "Most work treats large language models as black boxes without in-depth\nunderstanding of their internal working mechanism. In order to explain the\ninternal representations of LLMs, we propose a gradient-based metric to assess\nthe activation level of model parameters. Based on this metric, we obtain three\npreliminary findings. (1) When the inputs are in the same domain, parameters in\nthe shallow layers will be activated densely, which means a larger portion of\nparameters will have great impacts on the outputs. In contrast, parameters in\nthe deep layers are activated sparsely. (2) When the inputs are across\ndifferent domains, parameters in shallow layers exhibit higher similarity in\nthe activation behavior than deep layers. (3) In deep layers, the similarity of\nthe distributions of activated parameters is positively correlated to the\nempirical data relevance. Further, we develop three validation experiments to\nsolidify these findings. (1) Firstly, starting from the first finding, we\nattempt to configure different prune ratios for different layers, and find this\nmethod can benefit model pruning. (2) Secondly, we find that a pruned model\nbased on one calibration set can better handle tasks related to the calibration\ntask than those not related, which validate the second finding. (3) Thirdly,\nBased on the STS-B and SICK benchmark, we find that two sentences with\nconsistent semantics tend to share similar parameter activation patterns in\ndeep layers, which aligns with our third finding. Our work sheds light on the\nbehavior of parameter activation in LLMs, and we hope these findings will have\nthe potential to inspire more practical applications.", "published": "2024-05-28 03:49:54", "link": "http://arxiv.org/abs/2405.17799v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Conv-CoA: Improving Open-domain Question Answering in Large Language\n  Models via Conversational Chain-of-Action", "abstract": "We present a Conversational Chain-of-Action (Conv-CoA) framework for\nOpen-domain Conversational Question Answering (OCQA). Compared with literature,\nConv-CoA addresses three major challenges: (i) unfaithful hallucination that is\ninconsistent with real-time or domain facts, (ii) weak reasoning performance in\nconversational scenarios, and (iii) unsatisfying performance in conversational\ninformation retrieval. Our key contribution is a dynamic reasoning-retrieval\nmechanism that extracts the intent of the question and decomposes it into a\nreasoning chain to be solved via systematic prompting, pre-designed actions,\nupdating the Contextual Knowledge Set (CKS), and a novel Hopfield-based\nretriever. Methodologically, we propose a resource-efficiency Hopfield\nretriever to enhance the efficiency and accuracy of conversational information\nretrieval within our actions. Additionally, we propose a\nconversational-multi-reference faith score (Conv-MRFS) to verify and resolve\nconflicts between retrieved knowledge and answers in conversations.\nEmpirically, we conduct comparisons between our framework and 23\nstate-of-the-art methods across five different research directions and two\npublic benchmarks. These comparisons demonstrate that our Conv-CoA outperforms\nother methods in both the accuracy and efficiency dimensions.", "published": "2024-05-28 04:46:52", "link": "http://arxiv.org/abs/2405.17822v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Arithmetic Reasoning with LLM: Prolog Generation & Permutation", "abstract": "Instructing large language models (LLMs) to solve elementary school math\nproblems has shown great success using Chain of Thought (CoT). However, the CoT\napproach relies on an LLM to generate a sequence of arithmetic calculations\nwhich can be prone to cascaded calculation errors. We hypothesize that an LLM\nshould focus on extracting predicates and generating symbolic formulas from the\nmath problem description so that the underlying calculation can be done via an\nexternal code interpreter. We investigate using LLM to generate Prolog programs\nto solve mathematical questions. Experimental results show that our\nProlog-based arithmetic problem-solving outperforms CoT generation in the GSM8K\nbenchmark across three distinct LLMs. In addition, given the insensitive\nordering of predicates and symbolic formulas in Prolog, we propose to permute\nthe ground truth predicates for more robust LLM training via data augmentation.", "published": "2024-05-28 07:13:25", "link": "http://arxiv.org/abs/2405.17893v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Online Merging Optimizers for Boosting Rewards and Mitigating Tax in\n  Alignment", "abstract": "Effectively aligning Large Language Models (LLMs) with human-centric values\nwhile preventing the degradation of abilities acquired through Pre-training and\nSupervised Fine-tuning (SFT) poses a central challenge in Reinforcement\nLearning from Human Feedback (RLHF). In this paper, we first discover that\ninterpolating RLHF and SFT model parameters can adjust the trade-off between\nhuman preference and basic capabilities, thereby reducing the alignment tax at\nthe cost of alignment reward. Inspired by this, we propose integrating the RL\npolicy and SFT models at each optimization step in RLHF to continuously\nregulate the training direction, introducing the Online Merging Optimizer.\nSpecifically, we merge gradients with the parameter differences between SFT and\npretrained models, effectively steering the gradient towards maximizing rewards\nin the direction of SFT optimization. We demonstrate that our optimizer works\nwell with different LLM families, such as Qwen and LLaMA, across various model\nsizes ranging from 1.8B to 8B, various RLHF algorithms like DPO and KTO, and\nexisting model merging methods. It significantly enhances alignment reward\nwhile mitigating alignment tax, achieving higher overall performance across 14\nbenchmarks.", "published": "2024-05-28 07:53:40", "link": "http://arxiv.org/abs/2405.17931v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Tool Learning with Large Language Models: A Survey", "abstract": "Recently, tool learning with large language models (LLMs) has emerged as a\npromising paradigm for augmenting the capabilities of LLMs to tackle highly\ncomplex problems. Despite growing attention and rapid advancements in this\nfield, the existing literature remains fragmented and lacks systematic\norganization, posing barriers to entry for newcomers. This gap motivates us to\nconduct a comprehensive survey of existing works on tool learning with LLMs. In\nthis survey, we focus on reviewing existing literature from the two primary\naspects (1) why tool learning is beneficial and (2) how tool learning is\nimplemented, enabling a comprehensive understanding of tool learning with LLMs.\nWe first explore the \"why\" by reviewing both the benefits of tool integration\nand the inherent benefits of the tool learning paradigm from six specific\naspects. In terms of \"how\", we systematically review the literature according\nto a taxonomy of four key stages in the tool learning workflow: task planning,\ntool selection, tool calling, and response generation. Additionally, we provide\na detailed summary of existing benchmarks and evaluation methods, categorizing\nthem according to their relevance to different stages. Finally, we discuss\ncurrent challenges and outline potential future directions, aiming to inspire\nboth researchers and industrial developers to further explore this emerging and\npromising area. We also maintain a GitHub repository to continually keep track\nof the relevant papers and resources in this rising area at\nhttps://github.com/quchangle1/LLM-Tool-Survey.", "published": "2024-05-28 08:01:26", "link": "http://arxiv.org/abs/2405.17935v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Modeling Dynamic Topics in Chain-Free Fashion by Evolution-Tracking\n  Contrastive Learning and Unassociated Word Exclusion", "abstract": "Dynamic topic models track the evolution of topics in sequential documents,\nwhich have derived various applications like trend analysis and opinion mining.\nHowever, existing models suffer from repetitive topic and unassociated topic\nissues, failing to reveal the evolution and hindering further applications. To\naddress these issues, we break the tradition of simply chaining topics in\nexisting work and propose a novel neural \\modelfullname. We introduce a new\nevolution-tracking contrastive learning method that builds the similarity\nrelations among dynamic topics. This not only tracks topic evolution but also\nmaintains topic diversity, mitigating the repetitive topic issue. To avoid\nunassociated topics, we further present an unassociated word exclusion method\nthat consistently excludes unassociated words from discovered topics. Extensive\nexperiments demonstrate our model significantly outperforms state-of-the-art\nbaselines, tracking topic evolution with high-quality topics, showing better\nperformance on downstream tasks, and remaining robust to the hyperparameter for\nevolution intensities. Our code is available at https://github.com/bobxwu/CFDTM .", "published": "2024-05-28 08:39:49", "link": "http://arxiv.org/abs/2405.17957v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Recent Trends in Personalized Dialogue Generation: A Review of Datasets,\n  Methodologies, and Evaluations", "abstract": "Enhancing user engagement through personalization in conversational agents\nhas gained significance, especially with the advent of large language models\nthat generate fluent responses. Personalized dialogue generation, however, is\nmultifaceted and varies in its definition -- ranging from instilling a persona\nin the agent to capturing users' explicit and implicit cues. This paper seeks\nto systemically survey the recent landscape of personalized dialogue\ngeneration, including the datasets employed, methodologies developed, and\nevaluation metrics applied. Covering 22 datasets, we highlight benchmark\ndatasets and newer ones enriched with additional features. We further analyze\n17 seminal works from top conferences between 2021-2023 and identify five\ndistinct types of problems. We also shed light on recent progress by LLMs in\npersonalized dialogue generation. Our evaluation section offers a comprehensive\nsummary of assessment facets and metrics utilized in these works. In\nconclusion, we discuss prevailing challenges and envision prospect directions\nfor future research in personalized dialogue generation.", "published": "2024-05-28 09:04:13", "link": "http://arxiv.org/abs/2405.17974v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Yuan 2.0-M32: Mixture of Experts with Attention Router", "abstract": "Yuan 2.0-M32, with a similar base architecture as Yuan-2.0 2B, uses a\nmixture-of-experts architecture with 32 experts of which 2 experts are active.\nA new router network, Attention Router, is proposed and adopted for a more\nefficient selection of experts, which improves the accuracy compared to the\nmodel with classical router network. Yuan 2.0-M32 is trained with 2000B tokens\nfrom scratch, and the training computation consumption is only 9.25% of a dense\nmodel at the same parameter scale. Yuan 2.0-M32 demonstrates competitive\ncapability on coding, math, and various domains of expertise, with only 3.7B\nactive parameters of 40B in total, and 7.4 GFlops forward computation per\ntoken, both of which are only 1/19 of Llama3-70B. Yuan 2.0-M32 surpass\nLlama3-70B on MATH and ARC-Challenge benchmark, with accuracy of 55.89 and 95.8\nrespectively. The models and source codes of Yuan 2.0-M32 are released at\nGithub1.", "published": "2024-05-28 09:05:08", "link": "http://arxiv.org/abs/2405.17976v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "FASTopic: Pretrained Transformer is a Fast, Adaptive, Stable, and\n  Transferable Topic Model", "abstract": "Topic models have been evolving rapidly over the years, from conventional to\nrecent neural models. However, existing topic models generally struggle with\neither effectiveness, efficiency, or stability, highly impeding their practical\napplications. In this paper, we propose FASTopic, a fast, adaptive, stable, and\ntransferable topic model. FASTopic follows a new paradigm: Dual\nSemantic-relation Reconstruction (DSR). Instead of previous conventional,\nVAE-based, or clustering-based methods, DSR directly models the semantic\nrelations among document embeddings from a pretrained Transformer and learnable\ntopic and word embeddings. By reconstructing through these semantic relations,\nDSR discovers latent topics. This brings about a neat and efficient topic\nmodeling framework. We further propose a novel Embedding Transport Plan (ETP)\nmethod. Rather than early straightforward approaches, ETP explicitly\nregularizes the semantic relations as optimal transport plans. This addresses\nthe relation bias issue and thus leads to effective topic modeling. Extensive\nexperiments on benchmark datasets demonstrate that our FASTopic shows superior\neffectiveness, efficiency, adaptivity, stability, and transferability, compared\nto state-of-the-art baselines across various scenarios.", "published": "2024-05-28 09:06:38", "link": "http://arxiv.org/abs/2405.17978v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring Context Window of Large Language Models via Decomposed\n  Positional Vectors", "abstract": "Transformer-based large language models (LLMs) typically have a limited\ncontext window, resulting in significant performance degradation when\nprocessing text beyond the length of the context window. Extensive studies have\nbeen proposed to extend the context window and achieve length extrapolation of\nLLMs, but there is still a lack of in-depth interpretation of these approaches.\nIn this study, we explore the positional information within and beyond the\ncontext window for deciphering the underlying mechanism of LLMs. By using a\nmean-based decomposition method, we disentangle positional vectors from hidden\nstates of LLMs and analyze their formation and effect on attention.\nFurthermore, when texts exceed the context window, we analyze the change of\npositional vectors in two settings, i.e., direct extrapolation and context\nwindow extension. Based on our findings, we design two training-free context\nwindow extension methods, positional vector replacement and attention window\nextension. Experimental results show that our methods can effectively extend\nthe context window length.", "published": "2024-05-28 09:50:46", "link": "http://arxiv.org/abs/2405.18009v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Edinburgh Clinical NLP at MEDIQA-CORR 2024: Guiding Large Language\n  Models with Hints", "abstract": "The MEDIQA-CORR 2024 shared task aims to assess the ability of Large Language\nModels (LLMs) to identify and correct medical errors in clinical notes. In this\nstudy, we evaluate the capability of general LLMs, specifically GPT-3.5 and\nGPT-4, to identify and correct medical errors with multiple prompting\nstrategies. Recognising the limitation of LLMs in generating accurate\ncorrections only via prompting strategies, we propose incorporating error-span\npredictions from a smaller, fine-tuned model in two ways: 1) by presenting it\nas a hint in the prompt and 2) by framing it as multiple-choice questions from\nwhich the LLM can choose the best correction. We found that our proposed\nprompting strategies significantly improve the LLM's ability to generate\ncorrections. Our best-performing solution with 8-shot + CoT + hints ranked\nsixth in the shared task leaderboard. Additionally, our comprehensive analyses\nshow the impact of the location of the error sentence, the prompted role, and\nthe position of the multiple-choice option on the accuracy of the LLM. This\nprompts further questions about the readiness of LLM to be implemented in\nreal-world clinical settings.", "published": "2024-05-28 10:20:29", "link": "http://arxiv.org/abs/2405.18028v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Facilitating Multi-Role and Multi-Behavior Collaboration of Large\n  Language Models for Online Job Seeking and Recruiting", "abstract": "The emergence of online recruitment services has revolutionized the\ntraditional landscape of job seeking and recruitment, necessitating the\ndevelopment of high-quality industrial applications to improve person-job\nfitting. Existing methods generally rely on modeling the latent semantics of\nresumes and job descriptions and learning a matching function between them.\nInspired by the powerful role-playing capabilities of Large Language Models\n(LLMs), we propose to introduce a mock interview process between LLM-played\ninterviewers and candidates. The mock interview conversations can provide\nadditional evidence for candidate evaluation, thereby augmenting traditional\nperson-job fitting based solely on resumes and job descriptions. However,\ncharacterizing these two roles in online recruitment still presents several\nchallenges, such as developing the skills to raise interview questions,\nformulating appropriate answers, and evaluating two-sided fitness. To this end,\nwe propose MockLLM, a novel applicable framework that divides the person-job\nmatching process into two modules: mock interview generation and two-sided\nevaluation in handshake protocol, jointly enhancing their performance through\ncollaborative behaviors between interviewers and candidates. We design a\nrole-playing framework as a multi-role and multi-behavior paradigm to enable a\nsingle LLM agent to effectively behave with multiple functions for both\nparties. Moreover, we propose reflection memory generation and dynamic prompt\nmodification techniques to refine the behaviors of both sides, enabling\ncontinuous optimization of the augmented additional evidence. Extensive\nexperimental results show that MockLLM can achieve the best performance on\nperson-job matching accompanied by high mock interview quality, envisioning its\nemerging application in real online recruitment in the future.", "published": "2024-05-28 12:23:16", "link": "http://arxiv.org/abs/2405.18113v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Active Use of Latent Constituency Representation in both Humans and\n  Large Language Models", "abstract": "Understanding how sentences are internally represented in the human brain, as\nwell as in large language models (LLMs) such as ChatGPT, is a major challenge\nfor cognitive science. Classic linguistic theories propose that the brain\nrepresents a sentence by parsing it into hierarchically organized constituents.\nIn contrast, LLMs do not explicitly parse linguistic constituents and their\nlatent representations remains poorly explained. Here, we demonstrate that\nhumans and LLMs construct similar latent representations of hierarchical\nlinguistic constituents by analyzing their behaviors during a novel one-shot\nlearning task, in which they infer which words should be deleted from a\nsentence. Both humans and LLMs tend to delete a constituent, instead of a\nnonconstituent word string. In contrast, a naive sequence processing model that\nhas access to word properties and ordinal positions does not show this\nproperty. Based on the word deletion behaviors, we can reconstruct the latent\nconstituency tree representation of a sentence for both humans and LLMs. These\nresults demonstrate that a latent tree-structured constituency representation\ncan emerge in both the human brain and LLMs.", "published": "2024-05-28 14:50:22", "link": "http://arxiv.org/abs/2405.18241v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Battle of LLMs: A Comparative Study in Conversational QA Tasks", "abstract": "Large language models have gained considerable interest for their impressive\nperformance on various tasks. Within this domain, ChatGPT and GPT-4, developed\nby OpenAI, and the Gemini, developed by Google, have emerged as particularly\npopular among early adopters. Additionally, Mixtral by Mistral AI and Claude by\nAnthropic are newly released, further expanding the landscape of advanced\nlanguage models. These models are viewed as disruptive technologies with\napplications spanning customer service, education, healthcare, and finance.\nMore recently, Mistral has entered the scene, captivating users with its unique\nability to generate creative content. Understanding the perspectives of these\nusers is crucial, as they can offer valuable insights into the potential\nstrengths, weaknesses, and overall success or failure of these technologies in\nvarious domains. This research delves into the responses generated by ChatGPT,\nGPT-4, Gemini, Mixtral and Claude across different Conversational QA corpora.\nEvaluation scores were meticulously computed and subsequently compared to\nascertain the overall performance of these models. Our study pinpointed\ninstances where these models provided inaccurate answers to questions, offering\ninsights into potential areas where they might be susceptible to errors. In\nessence, this research provides a comprehensive comparison and evaluation of\nthese state of-the-art language models, shedding light on their capabilities\nwhile also highlighting potential areas for improvement", "published": "2024-05-28 16:42:43", "link": "http://arxiv.org/abs/2405.18344v1", "categories": ["cs.CL", "cs.AI", "I.7, I.m"], "primary_category": "cs.CL"}
{"title": "A System for Automatic English Text Expansion", "abstract": "We present an automatic text expansion system to generate English sentences,\nwhich performs automatic Natural Language Generation (NLG) by combining\nlinguistic rules with statistical approaches. Here, \"automatic\" means that the\nsystem can generate coherent and correct sentences from a minimum set of words.\nFrom its inception, the design is modular and adaptable to other languages.\nThis adaptability is one of its greatest advantages. For English, we have\ncreated the highly precise aLexiE lexicon with wide coverage, which represents\na contribution on its own. We have evaluated the resulting NLG library in an\nAugmentative and Alternative Communication (AAC) proof of concept, both\ndirectly (by regenerating corpus sentences) and manually (from annotations)\nusing a popular corpus in the NLG field. We performed a second analysis by\ncomparing the quality of text expansion in English to Spanish, using an ad-hoc\nSpanish-English parallel corpus. The system might also be applied to other\ndomains such as report and news generation.", "published": "2024-05-28 16:48:05", "link": "http://arxiv.org/abs/2405.18350v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Superposed Decoding: Multiple Generations from a Single Autoregressive\n  Inference Pass", "abstract": "Many applications today provide users with multiple auto-complete drafts as\nthey type, including GitHub's code completion, Gmail's smart compose, and\nApple's messaging auto-suggestions. Under the hood, language models support\nthis by running an autoregressive inference pass to provide a draft.\nConsequently, providing $k$ drafts to the user requires running an expensive\nlanguage model $k$ times. To alleviate the computation cost of running $k$\ninference passes, we propose Superposed Decoding, a new decoding algorithm that\ngenerates $k$ drafts at the computation cost of one autoregressive inference\npass. We achieve this by feeding a superposition of the most recent token\nembeddings from the $k$ drafts as input to the next decoding step of the\nlanguage model. At every inference step we combine the $k$ drafts with the\ntop-$k$ tokens to get $k^2$ new drafts and cache the $k$ most likely options,\nusing an n-gram interpolation with minimal compute overhead to filter out\nincoherent generations. Our experiments show that $k$ drafts from Superposed\nDecoding are at least as coherent and factual as Nucleus Sampling and Greedy\nDecoding respectively, while being at least $2.44\\times$ faster for $k\\ge3$. In\na compute-normalized setting, user evaluations demonstrably favor text\ngenerated by Superposed Decoding over Nucleus Sampling. Superposed Decoding can\nalso be combined with other decoding strategies, resulting in universal\ncoverage gains when scaling inference time compute. Code and more examples\nopen-sourced at https://github.com/RAIVNLab/SuperposedDecoding.", "published": "2024-05-28 17:40:48", "link": "http://arxiv.org/abs/2405.18400v6", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multi-objective Representation for Numbers in Clinical Narratives: A\n  CamemBERT-Bio-Based Alternative to Large-Scale LLMs", "abstract": "The processing of numerical values is a rapidly developing area in the field\nof Language Models (LLMs). Despite numerous advancements achieved by previous\nresearch, significant challenges persist, particularly within the healthcare\ndomain. This paper investigates the limitations of Transformer models in\nunderstanding numerical values. \\textit{Objective:} this research aims to\ncategorize numerical values extracted from medical documents into eight\nspecific physiological categories using CamemBERT-bio. \\textit{Methods:} In a\ncontext where scalable methods and Large Language Models (LLMs) are emphasized,\nwe explore lifting the limitations of transformer-based models. We examine two\nstrategies: fine-tuning CamemBERT-bio on a small medical dataset, integrating\nLabel Embedding for Self-Attention (LESA), and combining LESA with additional\nenhancement techniques such as Xval. Given that CamemBERT-bio is already\npre-trained on a large medical dataset, the first approach aims to update its\nencoder with the newly added label embeddings technique. In contrast, the\nsecond approach seeks to develop multiple representations of numbers\n(contextual and magnitude-based) to achieve more robust number embeddings.\n\\textit{Results:} As anticipated, fine-tuning the standard CamemBERT-bio on our\nsmall medical dataset did not improve F1 scores. However, significant\nimprovements were observed with CamemBERT-bio + LESA, resulting in an over 13\\%\nincrease. Similar enhancements were noted when combining LESA with Xval,\noutperforming conventional methods and giving comparable results to GPT-4\n\\textit{Conclusions and Novelty:} This study introduces two innovative\ntechniques for handling numerical data, which are also applicable to other\nmodalities. We illustrate how these techniques can improve the performance of\nTransformer-based models, achieving more reliable classification results even\nwith small datasets.", "published": "2024-05-28 01:15:21", "link": "http://arxiv.org/abs/2405.18448v3", "categories": ["cs.CL", "eess.SP"], "primary_category": "cs.CL"}
{"title": "LLMs and Memorization: On Quality and Specificity of Copyright\n  Compliance", "abstract": "Memorization in large language models (LLMs) is a growing concern. LLMs have\nbeen shown to easily reproduce parts of their training data, including\ncopyrighted work. This is an important problem to solve, as it may violate\nexisting copyright laws as well as the European AI Act. In this work, we\npropose a systematic analysis to quantify the extent of potential copyright\ninfringements in LLMs using European law as an example. Unlike previous work,\nwe evaluate instruction-finetuned models in a realistic end-user scenario. Our\nanalysis builds on a proposed threshold of 160 characters, which we borrow from\nthe German Copyright Service Provider Act and a fuzzy text matching algorithm\nto identify potentially copyright-infringing textual reproductions. The\nspecificity of countermeasures against copyright infringement is analyzed by\ncomparing model behavior on copyrighted and public domain data. We investigate\nwhat behaviors models show instead of producing protected text (such as refusal\nor hallucination) and provide a first legal assessment of these behaviors. We\nfind that there are huge differences in copyright compliance, specificity, and\nappropriate refusal among popular LLMs. Alpaca, GPT 4, GPT 3.5, and Luminous\nperform best in our comparison, with OpenGPT-X, Alpaca, and Luminous producing\na particularly low absolute number of potential copyright violations. Code can\nbe found at https://github.com/felixbmuller/llms-memorization-copyright.", "published": "2024-05-28 18:01:52", "link": "http://arxiv.org/abs/2405.18492v3", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Hardware-Aware Parallel Prompt Decoding for Memory-Efficient\n  Acceleration of LLM Inference", "abstract": "The auto-regressive decoding of Large Language Models (LLMs) results in\nsignificant overheads in their hardware performance. While recent research has\ninvestigated various speculative decoding techniques for multi-token\ngeneration, these efforts have primarily focused on improving processing speed\nsuch as throughput. Crucially, they often neglect other metrics essential for\nreal-life deployments, such as memory consumption and training cost. To\novercome these limitations, we propose a novel parallel prompt decoding that\nrequires only $0.0002$% trainable parameters, enabling efficient training on a\nsingle A100-40GB GPU in just 16 hours. Inspired by the human natural language\ngeneration process, $PPD$ approximates outputs generated at future timesteps in\nparallel by using multiple prompt tokens. This approach partially recovers the\nmissing conditional dependency information necessary for multi-token\ngeneration, resulting in up to a 28% higher acceptance rate for long-range\npredictions. Furthermore, we present a hardware-aware dynamic sparse tree\ntechnique that adaptively optimizes this decoding scheme to fully leverage the\ncomputational capacities on different GPUs. Through extensive experiments\nacross LLMs ranging from MobileLlama to Vicuna-13B on a wide range of\nbenchmarks, our approach demonstrates up to 2.49$\\times$ speedup and maintains\na minimal runtime memory overhead of just $0.0004$%. More importantly, our\nparallel prompt decoding can serve as an orthogonal optimization for\nsynergistic integration with existing speculative decoding, showing up to\n$1.22\\times$ further speed improvement. Our code is available at\nhttps://github.com/hmarkc/parallel-prompt-decoding.", "published": "2024-05-28 22:19:30", "link": "http://arxiv.org/abs/2405.18628v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "ConSiDERS-The-Human Evaluation Framework: Rethinking Human Evaluation\n  for Generative Large Language Models", "abstract": "In this position paper, we argue that human evaluation of generative large\nlanguage models (LLMs) should be a multidisciplinary undertaking that draws\nupon insights from disciplines such as user experience research and human\nbehavioral psychology to ensure that the experimental design and results are\nreliable. The conclusions from these evaluations, thus, must consider factors\nsuch as usability, aesthetics, and cognitive biases. We highlight how cognitive\nbiases can conflate fluent information and truthfulness, and how cognitive\nuncertainty affects the reliability of rating scores such as Likert.\nFurthermore, the evaluation should differentiate the capabilities and\nweaknesses of increasingly powerful large language models -- which requires\neffective test sets. The scalability of human evaluation is also crucial to\nwider adoption. Hence, to design an effective human evaluation system in the\nage of generative NLP, we propose the ConSiDERS-The-Human evaluation framework\nconsisting of 6 pillars -- Consistency, Scoring Criteria, Differentiating, User\nExperience, Responsible, and Scalability.", "published": "2024-05-28 22:45:28", "link": "http://arxiv.org/abs/2405.18638v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "JADS: A Framework for Self-supervised Joint Aspect Discovery and\n  Summarization", "abstract": "To generate summaries that include multiple aspects or topics for text\ndocuments, most approaches use clustering or topic modeling to group relevant\nsentences and then generate a summary for each group. These approaches struggle\nto optimize the summarization and clustering algorithms jointly. On the other\nhand, aspect-based summarization requires known aspects. Our solution\nintegrates topic discovery and summarization into a single step. Given text\ndata, our Joint Aspect Discovery and Summarization algorithm (JADS) discovers\naspects from the input and generates a summary of the topics, in one step. We\npropose a self-supervised framework that creates a labeled dataset by first\nmixing sentences from multiple documents (e.g., CNN/DailyMail articles) as the\ninput and then uses the article summaries from the mixture as the labels. The\nJADS model outperforms the two-step baselines. With pretraining, the model\nachieves better performance and stability. Furthermore, embeddings derived from\nJADS exhibit superior clustering capabilities. Our proposed method achieves\nhigher semantic alignment with ground truth and is factual.", "published": "2024-05-28 23:01:57", "link": "http://arxiv.org/abs/2405.18642v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Stochastic Adversarial Networks for Multi-Domain Text Classification", "abstract": "Adversarial training has been instrumental in advancing multi-domain text\nclassification (MDTC). Traditionally, MDTC methods employ a shared-private\nparadigm, with a shared feature extractor for domain-invariant knowledge and\nindividual private feature extractors for domain-specific knowledge. Despite\nachieving state-of-the-art results, these methods grapple with the escalating\nmodel parameters due to the continuous addition of new domains. To address this\nchallenge, we introduce the Stochastic Adversarial Network (SAN), which\ninnovatively models the parameters of the domain-specific feature extractor as\na multivariate Gaussian distribution, as opposed to a traditional weight\nvector. This design allows for the generation of numerous domain-specific\nfeature extractors without a substantial increase in model parameters,\nmaintaining the model's size on par with that of a single domain-specific\nextractor. Furthermore, our approach integrates domain label smoothing and\nrobust pseudo-label regularization to fortify the stability of adversarial\ntraining and to refine feature discriminability, respectively. The performance\nof our SAN, evaluated on two leading MDTC benchmarks, demonstrates its\ncompetitive edge against the current state-of-the-art methodologies. The code\nis available at https://github.com/wangxu0820/SAN.", "published": "2024-05-28 00:02:38", "link": "http://arxiv.org/abs/2406.00044v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Personalized Steering of Large Language Models: Versatile Steering\n  Vectors Through Bi-directional Preference Optimization", "abstract": "Researchers have been studying approaches to steer the behavior of Large\nLanguage Models (LLMs) and build personalized LLMs tailored for various\napplications. While fine-tuning seems to be a direct solution, it requires\nsubstantial computational resources and may significantly affect the utility of\nthe original LLM. Recent endeavors have introduced more lightweight strategies,\nfocusing on extracting \"steering vectors\" to guide the model's output toward\ndesired behaviors by adjusting activations within specific layers of the LLM's\ntransformer architecture. However, such steering vectors are directly extracted\nfrom the activations of human preference data and thus often lead to suboptimal\nresults and occasional failures, especially in alignment-related scenarios.\nThis work proposes an innovative approach that could produce more effective\nsteering vectors through bi-directional preference optimization. Our method is\ndesigned to allow steering vectors to directly influence the generation\nprobability of contrastive human preference data pairs, thereby offering a more\nprecise representation of the target behavior. By carefully adjusting the\ndirection and magnitude of the steering vector, we enabled personalized control\nover the desired behavior across a spectrum of intensities. Extensive\nexperimentation across various open-ended generation tasks, particularly\nfocusing on steering AI personas, has validated the efficacy of our approach.\nMoreover, we comprehensively investigate critical alignment-concerning\nscenarios, such as managing truthfulness, mitigating hallucination, and\naddressing jailbreaking attacks. Remarkably, our method can still demonstrate\noutstanding steering effectiveness across these scenarios. Furthermore, we\nshowcase the transferability of our steering vectors across different\nmodels/LoRAs and highlight the synergistic benefits of applying multiple\nvectors simultaneously.", "published": "2024-05-28 05:10:40", "link": "http://arxiv.org/abs/2406.00045v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Hate Speech Detection with Generalizable Target-aware Fairness", "abstract": "To counter the side effect brought by the proliferation of social media\nplatforms, hate speech detection (HSD) plays a vital role in halting the\ndissemination of toxic online posts at an early stage. However, given the\nubiquitous topical communities on social media, a trained HSD classifier easily\nbecomes biased towards specific targeted groups (e.g., female and black\npeople), where a high rate of false positive/negative results can significantly\nimpair public trust in the fairness of content moderation mechanisms, and\neventually harm the diversity of online society. Although existing\nfairness-aware HSD methods can smooth out some discrepancies across targeted\ngroups, they are mostly specific to a narrow selection of targets that are\nassumed to be known and fixed. This inevitably prevents those methods from\ngeneralizing to real-world use cases where new targeted groups constantly\nemerge over time. To tackle this defect, we propose Generalizable target-aware\nFairness (GetFair), a new method for fairly classifying each post that contains\ndiverse and even unseen targets during inference. To remove the HSD\nclassifier's spurious dependence on target-related features, GetFair trains a\nseries of filter functions in an adversarial pipeline, so as to deceive the\ndiscriminator that recovers the targeted group from filtered post embeddings.\nTo maintain scalability and generalizability, we innovatively parameterize all\nfilter functions via a hypernetwork that is regularized by the semantic\naffinity among targets. Taking a target's pretrained word embedding as input,\nthe hypernetwork generates the weights used by each target-specific filter\non-the-fly without storing dedicated filter parameters. Finally, comparative\nexperiments on two HSD datasets have shown advantageous performance of GetFair\non out-of-sample targets.", "published": "2024-05-28 13:09:22", "link": "http://arxiv.org/abs/2406.00046v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "QUEST: Quality-Aware Metropolis-Hastings Sampling for Machine\n  Translation", "abstract": "An important challenge in machine translation (MT) is to generate\nhigh-quality and diverse translations. Prior work has shown that the estimated\nlikelihood from the MT model correlates poorly with translation quality. In\ncontrast, quality evaluation metrics (such as COMET or BLEURT) exhibit high\ncorrelations with human judgments, which has motivated their use as rerankers\n(such as quality-aware and minimum Bayes risk decoding). However, relying on a\nsingle translation with high estimated quality increases the chances of \"gaming\nthe metric''. In this paper, we address the problem of sampling a set of\nhigh-quality and diverse translations. We provide a simple and effective way to\navoid over-reliance on noisy quality estimates by using them as the energy\nfunction of a Gibbs distribution. Instead of looking for a mode in the\ndistribution, we generate multiple samples from high-density areas through the\nMetropolis-Hastings algorithm, a simple Markov chain Monte Carlo approach. The\nresults show that our proposed method leads to high-quality and diverse outputs\nacross multiple language pairs (English$\\leftrightarrow${German, Russian}) with\ntwo strong decoder-only LLMs (Alma-7b, Tower-7b).", "published": "2024-05-28 17:36:06", "link": "http://arxiv.org/abs/2406.00049v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An Empirical Analysis on Large Language Models in Debate Evaluation", "abstract": "In this study, we investigate the capabilities and inherent biases of\nadvanced large language models (LLMs) such as GPT-3.5 and GPT-4 in the context\nof debate evaluation. We discover that LLM's performance exceeds humans and\nsurpasses the performance of state-of-the-art methods fine-tuned on extensive\ndatasets in debate evaluation. We additionally explore and analyze biases\npresent in LLMs, including positional bias, lexical bias, order bias, which may\naffect their evaluative judgments. Our findings reveal a consistent bias in\nboth GPT-3.5 and GPT-4 towards the second candidate response presented,\nattributed to prompt design. We also uncover lexical biases in both GPT-3.5 and\nGPT-4, especially when label sets carry connotations such as numerical or\nsequential, highlighting the critical need for careful label verbalizer\nselection in prompt design. Additionally, our analysis indicates a tendency of\nboth models to favor the debate's concluding side as the winner, suggesting an\nend-of-discussion bias.", "published": "2024-05-28 18:34:53", "link": "http://arxiv.org/abs/2406.00050v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Dual Process Learning: Controlling Use of In-Context vs. In-Weights\n  Strategies with Weight Forgetting", "abstract": "Language models have the ability to perform in-context learning (ICL),\nallowing them to flexibly adapt their behavior based on context. This contrasts\nwith in-weights learning (IWL), where memorized information is encoded in model\nparameters after iterated observations of data. An ideal model should be able\nto flexibly deploy both of these abilities. Despite their apparent ability to\nlearn in-context, language models are known to struggle when faced with unseen\nor rarely seen tokens (Land & Bartolo, 2024). Hence, we study\n$\\textbf{structural in-context learning}$, which we define as the ability of a\nmodel to execute in-context learning on arbitrary novel tokens -- so called\nbecause the model must generalize on the basis of e.g. sentence structure or\ntask structure, rather than content encoded in token embeddings. We study\nstructural in-context algorithms on both synthetic and naturalistic tasks using\ntoy models, masked language models, and autoregressive language models. We find\nthat structural ICL appears before quickly disappearing early in LM\npretraining. While it has been shown that ICL can diminish during training\n(Singh et al., 2023), we find that prior work does not account for structural\nICL. Building on Chen et al. (2024) 's active forgetting method, we introduce\npretraining and finetuning methods that can modulate the preference for\nstructural ICL and IWL. Importantly, this allows us to induce a $\\textit{dual\nprocess strategy}$ where in-context and in-weights solutions coexist within a\nsingle model.", "published": "2024-05-28 21:38:20", "link": "http://arxiv.org/abs/2406.00053v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Spanish and LLM Benchmarks: is MMLU Lost in Translation?", "abstract": "The evaluation of Large Language Models (LLMs) is a key element in their\ncontinuous improvement process and many benchmarks have been developed to\nassess the performance of LLMs in different tasks and topics. As LLMs become\nadopted worldwide, evaluating them in languages other than English is\nincreasingly important. However, most LLM benchmarks are simply translated\nusing an automated tool and then run in the target language. This means that\nthe results depend not only on the LLM performance in that language but also on\nthe quality of the translation. In this paper, we consider the case of the\nwell-known Massive Multitask Language Understanding (MMLU) benchmark. Selected\ncategories of the benchmark are translated into Spanish using Azure Translator\nand ChatGPT4 and run on ChatGPT4. Next, the results are processed to identify\nthe test items that produce different answers in Spanish and English. Those are\nthen analyzed manually to understand if the automatic translation caused the\nchange. The results show that a significant fraction of the failing items can\nbe attributed to mistakes in the translation of the benchmark. These results\nmake a strong case for improving benchmarks in languages other than English by\nat least revising the translations of the items and preferably by adapting the\ntests to the target language by experts.", "published": "2024-05-28 11:13:40", "link": "http://arxiv.org/abs/2406.17789v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ORLM: A Customizable Framework in Training Large Models for Automated\n  Optimization Modeling", "abstract": "Optimization modeling plays a critical role in the application of Operations\nResearch (OR) tools to address real-world problems, yet they pose challenges\nand require extensive expertise from OR experts. With the advent of large\nlanguage models (LLMs), new opportunities have emerged to streamline and\nautomate such task. However, current research predominantly relies on\nclosed-source LLMs such as GPT-4, along with extensive prompt engineering\ntechniques. This reliance stems from the scarcity of high-quality training\ndatasets for optimization modeling, resulting in elevated costs, prolonged\nprocessing times, and privacy concerns. To address these challenges, our work\nis the first to propose a viable path for training open-source LLMs that are\ncapable of optimization modeling and developing solver codes, eventually\nleading to a superior ability for automating optimization modeling and solving.\nParticularly, we design the {\\sc OR-Instruct}, a semi-automated data synthesis\nframework for optimization modeling that enables customizable enhancements for\nspecific scenarios or model types. This work also introduces IndustryOR, the\nfirst industrial benchmark for evaluating LLMs in solving practical OR\nproblems. We train several 7B-scale open-source LLMs using synthesized data\n(dubbed ORLMs{https://github.com/Cardinal-Operations/ORLM}), which exhibit\nsignificantly enhanced optimization modeling capabilities, achieving\ncompetitive performance across the NL4OPT, MAMO, and IndustryOR benchmarks.\nAdditionally, our experiments highlight the potential of scaling law and\nreinforcement learning to further enhance the performance of ORLMs. The\nworkflows and human-machine interaction paradigms of ORLMs in practical\nindustrial applications are also discussed in the paper.", "published": "2024-05-28 01:55:35", "link": "http://arxiv.org/abs/2405.17743v5", "categories": ["cs.CL", "cs.AI", "cs.CE", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On the Sequence Evaluation based on Stochastic Processes", "abstract": "Generative models have gained significant prominence in Natural Language\nProcessing (NLP), especially in tackling the complex task of modeling and\nevaluating long text sequences. This task is crucial for advancing various\ndownstream applications, such as text generation and machine translation.\nRecent methods that utilize stochastic processes to capture the intrinsic\ndynamics of sequences have shown superior performance in generative modeling.\nHowever, the accurate encoding of both temporal and structural dependencies\nfrom text datasets, as well as leveraging this encoded information for sequence\nevaluation, remains an open area of research. In this paper, we propose a novel\napproach to learn the stochastic dynamics of long text sequences, utilizing a\nnegative log-likelihood-based encoder that outperforms contrastive learning\nmethods. We also introduce a likelihood-based evaluation metric for long-text\nassessment, which measures sequence coherence and can be applied to downstream\ntasks such as Human-AI discrimination. Our encoder preserves sequence coherence\neffectively and performs robustly on out-of-domain datasets. Additionally, the\nproposed evaluation metric captures both temporal and structural information\ncomprehensively. Theoretical analysis demonstrates the superiority of our\nmetric in sequence evaluation, and experimental results highlight its\nflexibility and exceptional performance across a variety of tasks, showcasing\nits utility in diverse NLP applications.", "published": "2024-05-28 02:33:38", "link": "http://arxiv.org/abs/2405.17764v3", "categories": ["cs.CL", "cs.AI", "math.ST", "stat.TH"], "primary_category": "cs.CL"}
{"title": "Linguistic Collapse: Neural Collapse in (Large) Language Models", "abstract": "Neural collapse ($\\mathcal{NC}$) is a phenomenon observed in classification\ntasks where top-layer representations collapse into their class means, which\nbecome equinorm, equiangular and aligned with the classifiers. These behaviours\n-- associated with generalization and robustness -- would manifest under\nspecific conditions: models are trained towards zero loss, with noise-free\nlabels belonging to balanced classes, which do not outnumber the model's hidden\ndimension. Recent studies have explored $\\mathcal{NC}$ in the absence of one or\nmore of these conditions to extend and capitalize on the associated benefits of\nideal geometries. Language modelling presents a curious frontier, as\n\\textit{training by token prediction} constitutes a classification task where\nnone of the conditions exist: the vocabulary is imbalanced and exceeds the\nembedding dimension; different tokens might correspond to similar contextual\nembeddings; and large language models (LLMs) in particular are typically only\ntrained for a few epochs. This paper empirically investigates the impact of\nscaling the architectures and training of causal language models (CLMs) on\ntheir progression towards $\\mathcal{NC}$. We find that $\\mathcal{NC}$\nproperties that develop with scale (and regularization) are linked to\ngeneralization. Moreover, there is evidence of some relationship between\n$\\mathcal{NC}$ and generalization independent of scale. Our work thereby\nunderscores the generality of $\\mathcal{NC}$ as it extends to the novel and\nmore challenging setting of language modelling. Downstream, we seek to inspire\nfurther research on the phenomenon to deepen our understanding of LLMs -- and\nneural networks at large -- and improve existing architectures based on\n$\\mathcal{NC}$-related properties. Our code is hosted on GitHub at\nhttps://github.com/rhubarbwu/linguistic-collapse .", "published": "2024-05-28 02:46:11", "link": "http://arxiv.org/abs/2405.17767v3", "categories": ["cs.LG", "cs.CL", "stat.ML", "68T07 (Primary) 68T50 (Secondary)", "I.2.6; I.2.7"], "primary_category": "cs.LG"}
{"title": "TransVIP: Speech to Speech Translation System with Voice and Isochrony\n  Preservation", "abstract": "There is a rising interest and trend in research towards directly translating\nspeech from one language to another, known as end-to-end speech-to-speech\ntranslation. However, most end-to-end models struggle to outperform cascade\nmodels, i.e., a pipeline framework by concatenating speech recognition, machine\ntranslation and text-to-speech models. The primary challenges stem from the\ninherent complexities involved in direct translation tasks and the scarcity of\ndata. In this study, we introduce a novel model framework TransVIP that\nleverages diverse datasets in a cascade fashion yet facilitates end-to-end\ninference through joint probability. Furthermore, we propose two separated\nencoders to preserve the speaker's voice characteristics and isochrony from the\nsource speech during the translation process, making it highly suitable for\nscenarios such as video dubbing. Our experiments on the French-English language\npair demonstrate that our model outperforms the current state-of-the-art\nspeech-to-speech translation model.", "published": "2024-05-28 04:11:37", "link": "http://arxiv.org/abs/2405.17809v3", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "I-LLM: Efficient Integer-Only Inference for Fully-Quantized Low-Bit\n  Large Language Models", "abstract": "Post-training quantization (PTQ) serves as a potent technique to accelerate\nthe inference of large language models (LLMs). Nonetheless, existing works\nstill necessitate a considerable number of floating-point (FP) operations\nduring inference, including additional quantization and de-quantization, as\nwell as non-linear operators such as RMSNorm and Softmax. This limitation\nhinders the deployment of LLMs on the edge and cloud devices. In this paper, we\nidentify the primary obstacle to integer-only quantization for LLMs lies in the\nlarge fluctuation of activations across channels and tokens in both linear and\nnon-linear operations. To address this issue, we propose I-LLM, a novel\ninteger-only fully-quantized PTQ framework tailored for LLMs. Specifically, (1)\nwe develop Fully-Smooth Block-Reconstruction (FSBR) to aggressively smooth\ninter-channel variations of all activations and weights. (2) to alleviate\ndegradation caused by inter-token variations, we introduce a novel approach\ncalled Dynamic Integer-only MatMul (DI-MatMul). This method enables dynamic\nquantization in full-integer matrix multiplication by dynamically quantizing\nthe input and outputs with integer-only operations. (3) we design\nDI-ClippedSoftmax, DI-Exp, and DI-Normalization, which utilize bit shift to\nexecute non-linear operators efficiently while maintaining accuracy. The\nexperiment shows that our I-LLM achieves comparable accuracy to the FP baseline\nand outperforms non-integer quantization methods. For example, I-LLM can\noperate at W4A4 with negligible loss of accuracy. To our knowledge, we are the\nfirst to bridge the gap between integer-only quantization and LLMs. We've\npublished our code on anonymous.4open.science, aiming to contribute to the\nadvancement of this field.", "published": "2024-05-28 05:56:11", "link": "http://arxiv.org/abs/2405.17849v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Seeing the Image: Prioritizing Visual Correlation by Contrastive\n  Alignment", "abstract": "Existing image-text modality alignment in Vision Language Models (VLMs)\ntreats each text token equally in an autoregressive manner. Despite being\nsimple and effective, this method results in sub-optimal cross-modal alignment\nby over-emphasizing the text tokens that are less correlated with or even\ncontradictory with the input images. In this paper, we advocate for assigning\ndistinct contributions for each text token based on its visual correlation.\nSpecifically, we present by contrasting image inputs, the difference in\nprediction logits on each text token provides strong guidance of visual\ncorrelation. We therefore introduce Contrastive ALignment (CAL), a simple yet\neffective re-weighting strategy that prioritizes training visually correlated\ntokens. Our experimental results demonstrate that CAL consistently improves\ndifferent types of VLMs across different resolutions and model sizes on various\nbenchmark datasets. Importantly, our method incurs minimal additional\ncomputational overhead, rendering it highly efficient compared to alternative\ndata scaling strategies. Codes are available at\nhttps://github.com/foundation-multimodal-models/CAL.", "published": "2024-05-28 06:44:13", "link": "http://arxiv.org/abs/2405.17871v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "SLMRec: Distilling Large Language Models into Small for Sequential\n  Recommendation", "abstract": "Sequential Recommendation (SR) task involves predicting the next item a user\nis likely to interact with, given their past interactions. The SR models\nexamine the sequence of a user's actions to discern more complex behavioral\npatterns and temporal dynamics. Recent research demonstrates the great impact\nof LLMs on sequential recommendation systems, either viewing sequential\nrecommendation as language modeling or serving as the backbone for user\nrepresentation. Although these methods deliver outstanding performance, there\nis scant evidence of the necessity of a large language model and how large the\nlanguage model is needed, especially in the sequential recommendation scene.\nMeanwhile, due to the huge size of LLMs, it is inefficient and impractical to\napply a LLM-based model in real-world platforms that often need to process\nbillions of traffic logs daily. In this paper, we explore the influence of\nLLMs' depth by conducting extensive experiments on large-scale industry\ndatasets. Surprisingly, our motivational experiments reveal that most\nintermediate layers of LLMs are redundant, indicating that pruning the\nremaining layers can still maintain strong performance. Motivated by this\ninsight, we empower small language models for SR, namely SLMRec, which adopt a\nsimple yet effective knowledge distillation method. Moreover, SLMRec is\northogonal to other post-training efficiency techniques, such as quantization\nand pruning, so that they can be leveraged in combination. Comprehensive\nexperimental results illustrate that the proposed SLMRec model attains the best\nperformance using only 13% of the parameters found in LLM-based recommendation\nmodels while simultaneously achieving up to 6.6x and 8.0x speedups in training\nand inference time costs, respectively. Besides, we provide a theoretical\njustification for why small language models can perform comparably to large\nlanguage models in SR.", "published": "2024-05-28 07:12:06", "link": "http://arxiv.org/abs/2405.17890v3", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Boosting Protein Language Models with Negative Sample Mining", "abstract": "We introduce a pioneering methodology for boosting large language models in\nthe domain of protein representation learning. Our primary contribution lies in\nthe refinement process for correlating the over-reliance on co-evolution\nknowledge, in a way that networks are trained to distill invaluable insights\nfrom negative samples, constituted by protein pairs sourced from disparate\ncategories. By capitalizing on this novel approach, our technique steers the\ntraining of transformer-based models within the attention score space. This\nadvanced strategy not only amplifies performance but also reflects the nuanced\nbiological behaviors exhibited by proteins, offering aligned evidence with\ntraditional biological mechanisms such as protein-protein interaction. We\nexperimentally observed improved performance on various tasks over datasets, on\ntop of several well-established large protein models. This innovative paradigm\nopens up promising horizons for further progress in the realms of protein\nresearch and computational biology.", "published": "2024-05-28 07:24:20", "link": "http://arxiv.org/abs/2405.17902v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "fMRI predictors based on language models of increasing complexity\n  recover brain left lateralization", "abstract": "Over the past decade, studies of naturalistic language processing where\nparticipants are scanned while listening to continuous text have flourished.\nUsing word embeddings at first, then large language models, researchers have\ncreated encoding models to analyze the brain signals. Presenting these models\nwith the same text as the participants allows to identify brain areas where\nthere is a significant correlation between the functional magnetic resonance\nimaging (fMRI) time series and the ones predicted by the models' artificial\nneurons. One intriguing finding from these studies is that they have revealed\nhighly symmetric bilateral activation patterns, somewhat at odds with the\nwell-known left lateralization of language processing. Here, we report analyses\nof an fMRI dataset where we manipulate the complexity of large language models,\ntesting 28 pretrained models from 8 different families, ranging from 124M to\n14.2B parameters. First, we observe that the performance of models in\npredicting brain responses follows a scaling law, where the fit with brain\nactivity increases linearly with the logarithm of the number of parameters of\nthe model (and its performance on natural language processing tasks). Second,\nalthough this effect is present in both hemispheres, it is stronger in the left\nthan in the right hemisphere. Specifically, the left-right difference in brain\ncorrelation follows a scaling law with the number of parameters. This finding\nreconciles computational analyses of brain activity using large language models\nwith the classic observation from aphasic patients showing left hemisphere\ndominance for language.", "published": "2024-05-28 09:24:52", "link": "http://arxiv.org/abs/2405.17992v2", "categories": ["cs.CL", "cs.AI", "q-bio.NC"], "primary_category": "cs.CL"}
{"title": "Source Echo Chamber: Exploring the Escalation of Source Bias in User,\n  Data, and Recommender System Feedback Loop", "abstract": "Recently, researchers have uncovered that neural retrieval models prefer\nAI-generated content (AIGC), called source bias. Compared to active search\nbehavior, recommendation represents another important means of information\nacquisition, where users are more prone to source bias. Furthermore, delving\ninto the recommendation scenario, as AIGC becomes integrated within the\nfeedback loop involving users, data, and the recommender system, it\nprogressively contaminates the candidate items, the user interaction history,\nand ultimately, the data used to train the recommendation models. How and to\nwhat extent the source bias affects the neural recommendation models within\nfeedback loop remains unknown. In this study, we extend the investigation of\nsource bias into the realm of recommender systems, specifically examining its\nimpact across different phases of the feedback loop. We conceptualize the\nprogression of AIGC integration into the recommendation content ecosystem in\nthree distinct phases-HGC dominate, HGC-AIGC coexist, and AIGC dominance-each\nrepresenting past, present, and future states, respectively. Through extensive\nexperiments across three datasets from diverse domains, we demonstrate the\nprevalence of source bias and reveal a potential digital echo chamber with\nsource bias amplification throughout the feedback loop. This trend risks\ncreating a recommender ecosystem with limited information source, such as AIGC,\nbeing disproportionately recommended. To counteract this bias and prevent its\nescalation in the feedback loop, we introduce a black-box debiasing method that\nmaintains model impartiality towards both HGC and AIGC. Our experimental\nresults validate the effectiveness of the proposed debiasing method, confirming\nits potential to disrupt the feedback loop.", "published": "2024-05-28 09:34:50", "link": "http://arxiv.org/abs/2405.17998v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "A Human-Like Reasoning Framework for Multi-Phases Planning Task with\n  Large Language Models", "abstract": "Recent studies have highlighted their proficiency in some simple tasks like\nwriting and coding through various reasoning strategies. However, LLM agents\nstill struggle with tasks that require comprehensive planning, a process that\nchallenges current models and remains a critical research issue. In this study,\nwe concentrate on travel planning, a Multi-Phases planning problem, that\ninvolves multiple interconnected stages, such as outlining, information\ngathering, and planning, often characterized by the need to manage various\nconstraints and uncertainties. Existing reasoning approaches have struggled to\neffectively address this complex task. Our research aims to address this\nchallenge by developing a human-like planning framework for LLM agents, i.e.,\nguiding the LLM agent to simulate various steps that humans take when solving\nMulti-Phases problems. Specifically, we implement several strategies to enable\nLLM agents to generate a coherent outline for each travel query, mirroring\nhuman planning patterns. Additionally, we integrate Strategy Block and\nKnowledge Block into our framework: Strategy Block facilitates information\ncollection, while Knowledge Block provides essential information for detailed\nplanning. Through our extensive experiments, we demonstrate that our framework\nsignificantly improves the planning capabilities of LLM agents, enabling them\nto tackle the travel planning task with improved efficiency and effectiveness.\nOur experimental results showcase the exceptional performance of the proposed\nframework; when combined with GPT-4-Turbo, it attains $10\\times$ the\nperformance gains in comparison to the baseline framework deployed on\nGPT-4-Turbo.", "published": "2024-05-28 14:13:32", "link": "http://arxiv.org/abs/2405.18208v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Text-only Synthesis for Image Captioning", "abstract": "From paired image-text training to text-only training for image captioning,\nthe pursuit of relaxing the requirements for high-cost and large-scale\nannotation of good quality data remains consistent. In this paper, we propose\nText-only Synthesis for Image Captioning (ToCa), which further advances this\nrelaxation with fewer human labor and less computing time. Specifically, we\ndeconstruct caption text into structures and lexical words, which serve as the\nfundamental components of the caption. By combining different structures and\nlexical words as inputs to the large language model, massive captions that\ncontain various patterns of lexical words are generated. This method not only\napproaches the target domain but also surpasses it by generating new captions,\nthereby enhancing the zero-shot generalization ability of the model.\nConsidering the different levels of data access in the real world, we define\nthree synthesis scenarios: cross-domain synthesis, in-domain synthesis, and\ndata-efficient synthesis. Experiments in these scenarios demonstrate the\ngeneralizability, transferability and practicability of ToCa with a nearly 5\nCIDEr improvement for zero-shot cross-domain captioning and a maximum increase\nof over 20 CIDEr for data-efficient captioning.", "published": "2024-05-28 15:11:17", "link": "http://arxiv.org/abs/2405.18258v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Self-Supervised Learning Based Handwriting Verification", "abstract": "We present SSL-HV: Self-Supervised Learning approaches applied to the task of\nHandwriting Verification. This task involves determining whether a given pair\nof handwritten images originate from the same or different writer distribution.\nWe have compared the performance of multiple generative, contrastive SSL\napproaches against handcrafted feature extractors and supervised learning on\nCEDAR AND dataset. We show that ResNet based Variational Auto-Encoder (VAE)\noutperforms other generative approaches achieving 76.3% accuracy, while\nResNet-18 fine-tuned using Variance-Invariance-Covariance Regularization\n(VICReg) outperforms other contrastive approaches achieving 78% accuracy. Using\na pre-trained VAE and VICReg for the downstream task of writer verification we\nobserved a relative improvement in accuracy of 6.7% and 9% over ResNet-18\nsupervised baseline with 10% writer labels.", "published": "2024-05-28 16:11:11", "link": "http://arxiv.org/abs/2405.18320v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Interpretable classification of wiki-review streams", "abstract": "Wiki articles are created and maintained by a crowd of editors, producing a\ncontinuous stream of reviews. Reviews can take the form of additions, reverts,\nor both. This crowdsourcing model is exposed to manipulation since neither\nreviews nor editors are automatically screened and purged. To protect articles\nagainst vandalism or damage, the stream of reviews can be mined to classify\nreviews and profile editors in real-time. The goal of this work is to\nanticipate and explain which reviews to revert. This way, editors are informed\nwhy their edits will be reverted. The proposed method employs stream-based\nprocessing, updating the profiling and classification models on each incoming\nevent. The profiling uses side and content-based features employing Natural\nLanguage Processing, and editor profiles are incrementally updated based on\ntheir reviews. Since the proposed method relies on self-explainable\nclassification algorithms, it is possible to understand why a review has been\nclassified as a revert or a non-revert. In addition, this work contributes an\nalgorithm for generating synthetic data for class balancing, making the final\nclassification fairer. The proposed online method was tested with a real data\nset from Wikivoyage, which was balanced through the aforementioned synthetic\ndata generation. The results attained near-90 % values for all evaluation\nmetrics (accuracy, precision, recall, and F-measure).", "published": "2024-05-28 16:28:58", "link": "http://arxiv.org/abs/2405.18335v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MMCTAgent: Multi-modal Critical Thinking Agent Framework for Complex\n  Visual Reasoning", "abstract": "Recent advancements in Multi-modal Large Language Models (MLLMs) have\nsignificantly improved their performance in tasks combining vision and\nlanguage. However, challenges persist in detailed multi-modal understanding,\ncomprehension of complex tasks, and reasoning over multi-modal information.\nThis paper introduces MMCTAgent, a novel multi-modal critical thinking agent\nframework designed to address the inherent limitations of current MLLMs in\ncomplex visual reasoning tasks. Inspired by human cognitive processes and\ncritical thinking, MMCTAgent iteratively analyzes multi-modal information,\ndecomposes queries, plans strategies, and dynamically evolves its reasoning.\nAdditionally, MMCTAgent incorporates critical thinking elements such as\nverification of final answers and self-reflection through a novel approach that\ndefines a vision-based critic and identifies task-specific evaluation criteria,\nthereby enhancing its decision-making abilities. Through rigorous evaluations\nacross various image and video understanding benchmarks, we demonstrate that\nMMCTAgent (with and without the critic) outperforms both foundational MLLMs and\nother tool-augmented pipelines.", "published": "2024-05-28 16:55:41", "link": "http://arxiv.org/abs/2405.18358v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Bridging the Gap: Dynamic Learning Strategies for Improving Multilingual\n  Performance in LLMs", "abstract": "Large language models (LLMs) are at the forefront of transforming numerous\ndomains globally. However, their inclusivity and effectiveness remain limited\nfor non-Latin scripts and low-resource languages. This paper tackles the\nimperative challenge of enhancing the multilingual performance of LLMs without\nextensive training or fine-tuning. Through systematic investigation and\nevaluation of diverse languages using popular question-answering (QA) datasets,\nwe present novel techniques that unlock the true potential of LLMs in a\npolyglot landscape. Our approach encompasses three key strategies that yield\nsignificant improvements in multilingual proficiency. First, by meticulously\noptimizing prompts tailored for polyglot LLMs, we unlock their latent\ncapabilities, resulting in substantial performance boosts across languages.\nSecond, we introduce a new hybrid approach that synergizes LLM Retrieval\nAugmented Generation (RAG) with multilingual embeddings and achieves improved\nmultilingual task performance. Finally, we introduce a novel learning approach\nthat dynamically selects the optimal prompt strategy, LLM model, and embedding\nmodel per query at run-time. This dynamic adaptation maximizes the efficacy of\nLLMs across languages, outperforming best static and random strategies.\nAdditionally, our approach adapts configurations in both offline and online\nsettings, and can seamlessly adapt to new languages and datasets, leading to\nsubstantial advancements in multilingual understanding and generation across\ndiverse languages.", "published": "2024-05-28 16:56:42", "link": "http://arxiv.org/abs/2405.18359v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "PromptWizard: Task-Aware Prompt Optimization Framework", "abstract": "Large language models (LLMs) have transformed AI across diverse domains, with\nprompting being central to their success in guiding model outputs. However,\nmanual prompt engineering is both labor-intensive and domain-specific,\nnecessitating the need for automated solutions. We introduce PromptWizard, a\nnovel, fully automated framework for discrete prompt optimization, utilizing a\nself-evolving, self-adapting mechanism. Through a feedback-driven critique and\nsynthesis process, PromptWizard achieves an effective balance between\nexploration and exploitation, iteratively refining both prompt instructions and\nin-context examples to generate human-readable, task-specific prompts. This\nguided approach systematically improves prompt quality, resulting in superior\nperformance across 45 tasks. PromptWizard excels even with limited training\ndata, smaller LLMs, and various LLM architectures. Additionally, our cost\nanalysis reveals a substantial reduction in API calls, token usage, and overall\ncost, demonstrating PromptWizard's efficiency, scalability, and advantages over\nexisting prompt optimization strategies.", "published": "2024-05-28 17:08:31", "link": "http://arxiv.org/abs/2405.18369v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "OwLore: Outlier-weighed Layerwise Sampled Low-Rank Projection for\n  Memory-Efficient LLM Fine-tuning", "abstract": "The rapid advancements in Large Language Models (LLMs) have revolutionized\nvarious natural language processing tasks. However, the substantial size of\nLLMs presents significant challenges in training or fine-tuning. While\nparameter-efficient approaches such as low-rank adaptation (LoRA) have gained\npopularity, they often compromise performance compared to full-rank\nfine-tuning. In this paper, we propose Outlier-weighed Layerwise Sampled\nLow-Rank Projection (OwLore), a new memory-efficient fine-tuning approach,\ninspired by the layerwise outlier distribution of LLMs. Unlike LoRA, which adds\nextra adapters to all layers, OwLore strategically assigns higher sampling\nprobabilities to layers with more outliers, selectively sampling only a few\nlayers and fine-tuning their pre-trained weights. To further increase the\nnumber of fine-tuned layers without a proportional rise in memory costs, we\nincorporate gradient low-rank projection, further boosting the approach's\nperformance. Our extensive experiments across various architectures, including\nLLaMa2, LLaMa3, and Mistral, demonstrate that OwLore consistently outperforms\nbaseline approaches, including full fine-tuning. Specifically, it achieves up\nto a 1.1% average accuracy gain on the Commonsense Reasoning benchmark, a 3.0%\nimprovement on MMLU, and a notable 10% boost on MT-Bench, while being more\nmemory efficient. OwLore allows us to fine-tune LLaMa2-7B with only 21GB of\nmemory. Code is available at https://github.com/pixeli99/OwLore.", "published": "2024-05-28 17:22:22", "link": "http://arxiv.org/abs/2405.18380v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "RACCooN: A Versatile Instructional Video Editing Framework with\n  Auto-Generated Narratives", "abstract": "Recent video generative models primarily rely on carefully written text\nprompts for specific tasks, like inpainting or style editing. They require\nlabor-intensive textual descriptions for input videos, hindering their\nflexibility to adapt personal/raw videos to user specifications. This paper\nproposes RACCooN, a versatile and user-friendly video-to-paragraph-to-video\ngenerative framework that supports multiple video editing capabilities such as\nremoval, addition, and modification, through a unified pipeline. RACCooN\nconsists of two principal stages: Video-to-Paragraph (V2P) and\nParagraph-to-Video (P2V). In the V2P stage, we automatically describe video\nscenes in well-structured natural language, capturing both the holistic context\nand focused object details. Subsequently, in the P2V stage, users can\noptionally refine these descriptions to guide the video diffusion model,\nenabling various modifications to the input video, such as removing, changing\nsubjects, and/or adding new objects. The proposed approach stands out from\nother methods through several significant contributions: (1) RACCooN suggests a\nmulti-granular spatiotemporal pooling strategy to generate well-structured\nvideo descriptions, capturing both the broad context and object details without\nrequiring complex human annotations, simplifying precise video content editing\nbased on text for users. (2) Our video generative model incorporates\nauto-generated narratives or instructions to enhance the quality and accuracy\nof the generated content. (3) RACCooN also plans to imagine new objects in a\ngiven video, so users simply prompt the model to receive a detailed video\nediting plan for complex video editing. The proposed framework demonstrates\nimpressive versatile capabilities in video-to-paragraph generation, video\ncontent editing, and can be incorporated into other SoTA video generative\nmodels for further enhancement.", "published": "2024-05-28 17:46:36", "link": "http://arxiv.org/abs/2405.18406v3", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Don't Forget to Connect! Improving RAG with Graph-based Reranking", "abstract": "Retrieval Augmented Generation (RAG) has greatly improved the performance of\nLarge Language Model (LLM) responses by grounding generation with context from\nexisting documents. These systems work well when documents are clearly relevant\nto a question context. But what about when a document has partial information,\nor less obvious connections to the context? And how should we reason about\nconnections between documents? In this work, we seek to answer these two core\nquestions about RAG generation. We introduce G-RAG, a reranker based on graph\nneural networks (GNNs) between the retriever and reader in RAG. Our method\ncombines both connections between documents and semantic information (via\nAbstract Meaning Representation graphs) to provide a context-informed ranker\nfor RAG. G-RAG outperforms state-of-the-art approaches while having smaller\ncomputational footprint. Additionally, we assess the performance of PaLM 2 as a\nreranker and find it to significantly underperform G-RAG. This result\nemphasizes the importance of reranking for RAG even when using Large Language\nModels.", "published": "2024-05-28 17:56:46", "link": "http://arxiv.org/abs/2405.18414v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Why are Visually-Grounded Language Models Bad at Image Classification?", "abstract": "Image classification is one of the most fundamental capabilities of machine\nvision intelligence. In this work, we revisit the image classification task\nusing visually-grounded language models (VLMs) such as GPT-4V and LLaVA. We\nfind that existing proprietary and public VLMs, despite often using CLIP as a\nvision encoder and having many more parameters, significantly underperform CLIP\non standard image classification benchmarks like ImageNet. To understand the\nreason, we explore several hypotheses concerning the inference algorithms,\ntraining objectives, and data processing in VLMs. Our analysis reveals that the\nprimary cause is data-related: critical information for image classification is\nencoded in the VLM's latent space but can only be effectively decoded with\nenough training data. Specifically, there is a strong correlation between the\nfrequency of class exposure during VLM training and instruction-tuning and the\nVLM's performance in those classes; when trained with sufficient data, VLMs can\nmatch the accuracy of state-of-the-art classification models. Based on these\nfindings, we enhance a VLM by integrating classification-focused datasets into\nits training, and demonstrate that the enhanced classification performance of\nthe VLM transfers to its general capabilities, resulting in an improvement of\n11.8% on the newly collected ImageWikiQA dataset.", "published": "2024-05-28 17:57:06", "link": "http://arxiv.org/abs/2405.18415v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Learning diverse attacks on large language models for robust red-teaming\n  and safety tuning", "abstract": "Red-teaming, or identifying prompts that elicit harmful responses, is a\ncritical step in ensuring the safe and responsible deployment of large language\nmodels (LLMs). Developing effective protection against many modes of attack\nprompts requires discovering diverse attacks. Automated red-teaming typically\nuses reinforcement learning to fine-tune an attacker language model to generate\nprompts that elicit undesirable responses from a target LLM, as measured, for\nexample, by an auxiliary toxicity classifier. We show that even with explicit\nregularization to favor novelty and diversity, existing approaches suffer from\nmode collapse or fail to generate effective attacks. As a flexible and\nprobabilistically principled alternative, we propose to use GFlowNet\nfine-tuning, followed by a secondary smoothing phase, to train the attacker\nmodel to generate diverse and effective attack prompts. We find that the\nattacks generated by our method are effective against a wide range of target\nLLMs, both with and without safety tuning, and transfer well between target\nLLMs. Finally, we demonstrate that models safety-tuned using a dataset of\nred-teaming prompts generated by our method are robust to attacks from other\nRL-based red-teaming approaches.", "published": "2024-05-28 19:16:17", "link": "http://arxiv.org/abs/2405.18540v2", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Automatic detection of cognitive impairment in elderly people using an\n  entertainment chatbot with Natural Language Processing capabilities", "abstract": "Previous researchers have proposed intelligent systems for therapeutic\nmonitoring of cognitive impairments. However, most existing practical\napproaches for this purpose are based on manual tests. This raises issues such\nas excessive caretaking effort and the white-coat effect. To avoid these\nissues, we present an intelligent conversational system for entertaining\nelderly people with news of their interest that monitors cognitive impairment\ntransparently. Automatic chatbot dialogue stages allow assessing content\ndescription skills and detecting cognitive impairment with Machine Learning\nalgorithms. We create these dialogue flows automatically from updated news\nitems using Natural Language Generation techniques. The system also infers the\ngold standard of the answers to the questions, so it can assess cognitive\ncapabilities automatically by comparing these answers with the user responses.\nIt employs a similarity metric with values in [0, 1], in increasing level of\nsimilarity. To evaluate the performance and usability of our approach, we have\nconducted field tests with a test group of 30 elderly people in the earliest\nstages of dementia, under the supervision of gerontologists. In the\nexperiments, we have analysed the effect of stress and concentration in these\nusers. Those without cognitive impairment performed up to five times better. In\nparticular, the similarity metric varied between 0.03, for stressed and\nunfocused participants, and 0.36, for relaxed and focused users. Finally, we\ndeveloped a Machine Learning algorithm based on textual analysis features for\nautomatic cognitive impairment detection, which attained accuracy, F-measure\nand recall levels above 80%. We have thus validated the automatic approach to\ndetect cognitive impairment in elderly people based on entertainment content.", "published": "2024-05-28 19:17:48", "link": "http://arxiv.org/abs/2405.18542v1", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.AI"}
{"title": "It's Not a Modality Gap: Characterizing and Addressing the Contrastive\n  Gap", "abstract": "Multi-modal contrastive models such as CLIP achieve state-of-the-art\nperformance in zero-shot classification by embedding input images and texts on\na joint representational space. Recently, a modality gap has been reported in\ntwo-encoder contrastive models like CLIP, meaning that the image and text\nembeddings reside in disjoint areas of the latent space. Previous studies\nsuggest that this gap exists due to 1) the cone effect, 2) mismatched pairs in\nthe dataset, and 3) insufficient training. We show that, even when accounting\nfor all these factors, and even when using the same modality, the contrastive\nloss actually creates a gap during training. As a result, We propose that the\nmodality gap is inherent to the two-encoder contrastive loss and rename it the\ncontrastive gap. We present evidence that attributes this contrastive gap to\nlow uniformity in CLIP space, resulting in embeddings that occupy only a small\nportion of the latent space. To close the gap, we adapt the uniformity and\nalignment properties of unimodal contrastive loss to the multi-modal setting\nand show that simply adding these terms to the CLIP loss distributes the\nembeddings more uniformly in the representational space, closing the gap. In\nour experiments, we show that the modified representational space achieves\nbetter performance than default CLIP loss in downstream tasks such as zero-shot\nimage classification and multi-modal arithmetic.", "published": "2024-05-28 20:28:07", "link": "http://arxiv.org/abs/2405.18570v3", "categories": ["cs.CV", "cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Low-rank finetuning for LLMs: A fairness perspective", "abstract": "Low-rank approximation techniques have become the de facto standard for\nfine-tuning Large Language Models (LLMs) due to their reduced computational and\nmemory requirements. This paper investigates the effectiveness of these methods\nin capturing the shift of fine-tuning datasets from the initial pre-trained\ndata distribution. Our findings reveal that there are cases in which low-rank\nfine-tuning falls short in learning such shifts. This, in turn, produces\nnon-negligible side effects, especially when fine-tuning is adopted for\ntoxicity mitigation in pre-trained models, or in scenarios where it is\nimportant to provide fair models. Through comprehensive empirical evidence on\nseveral models, datasets, and tasks, we show that low-rank fine-tuning\ninadvertently preserves undesirable biases and toxic behaviors. We also show\nthat this extends to sequential decision-making tasks, emphasizing the need for\ncareful evaluation to promote responsible LLMs development.", "published": "2024-05-28 20:43:53", "link": "http://arxiv.org/abs/2405.18572v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "BioBERT-based Deep Learning and Merged ChemProt-DrugProt for Enhanced\n  Biomedical Relation Extraction", "abstract": "This paper presents a methodology for enhancing relation extraction from\nbiomedical texts, focusing specifically on chemical-gene interactions.\nLeveraging the BioBERT model and a multi-layer fully connected network\narchitecture, our approach integrates the ChemProt and DrugProt datasets using\na novel merging strategy. Through extensive experimentation, we demonstrate\nsignificant performance improvements, particularly in CPR groups shared between\nthe datasets. The findings underscore the importance of dataset merging in\naugmenting sample counts and improving model accuracy. Moreover, the study\nhighlights the potential of automated information extraction in biomedical\nresearch and clinical practice.", "published": "2024-05-28 21:34:01", "link": "http://arxiv.org/abs/2405.18605v1", "categories": ["cs.CL", "cs.IR", "q-bio.MN"], "primary_category": "cs.CL"}
{"title": "GLOCON Database: Design Decisions and User Manual (v1.0)", "abstract": "GLOCON is a database of contentious events automatically extracted from\nnational news sources from various countries in multiple languages. National\nnews sources are utilized, and complete news archives are processed to create\nan event list for each source. Automation is achieved using a gold standard\ncorpus sampled randomly from complete news archives (Y\\\"or\\\"uk et al. 2022) and\nall annotated by at least two domain experts based on the event definition\nprovided in Duru\\c{s}an et al. (2022).", "published": "2024-05-28 21:42:35", "link": "http://arxiv.org/abs/2405.18613v1", "categories": ["cs.CL", "cs.CY", "cs.DB", "cs.LG"], "primary_category": "cs.CL"}
{"title": "RealitySummary: Exploring On-Demand Mixed Reality Text Summarization and\n  Question Answering using Large Language Models", "abstract": "Large Language Models (LLMs) are gaining popularity as tools for reading and\nsummarization aids. However, little is known about their potential benefits\nwhen integrated with mixed reality (MR) interfaces to support everyday reading\nassistants. We developed RealitySummary, an MR reading assistant that\nseamlessly integrates LLMs with always-on camera access, OCR-based text\nextraction, and augmented spatial and visual responses in MR interfaces.\nDeveloped iteratively, RealitySummary evolved across three versions, each\nshaped by user feedback and reflective analysis: 1) a preliminary user study to\nunderstand user perceptions (N=12), 2) an in-the-wild deployment to explore\nreal-world usage (N=11), and 3) a diary study to capture insights from\nreal-world work contexts (N=5). Our findings highlight the unique advantages of\ncombining AI and MR, including an always-on implicit assistant, minimal context\nswitching, and spatial affordances, demonstrating significant potential for\nfuture LLM-MR interfaces beyond traditional screen-based interactions.", "published": "2024-05-28 21:59:56", "link": "http://arxiv.org/abs/2405.18620v2", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "A Theoretical Understanding of Self-Correction through In-context\n  Alignment", "abstract": "Going beyond mimicking limited human experiences, recent studies show initial\nevidence that, like humans, large language models (LLMs) are capable of\nimproving their abilities purely by self-correction, i.e., correcting previous\nresponses through self-examination, in certain circumstances. Nevertheless,\nlittle is known about how such capabilities arise. In this work, based on a\nsimplified setup akin to an alignment task, we theoretically analyze\nself-correction from an in-context learning perspective, showing that when LLMs\ngive relatively accurate self-examinations as rewards, they are capable of\nrefining responses in an in-context way. Notably, going beyond previous\ntheories on over-simplified linear transformers, our theoretical construction\nunderpins the roles of several key designs of realistic transformers for\nself-correction: softmax attention, multi-head attention, and the MLP block. We\nvalidate these findings extensively on synthetic datasets. Inspired by these\nfindings, we also illustrate novel applications of self-correction, such as\ndefending against LLM jailbreaks, where a simple self-correction step does make\na large difference. We believe that these findings will inspire further\nresearch on understanding, exploiting, and enhancing self-correction for\nbuilding better foundation models.", "published": "2024-05-28 22:33:02", "link": "http://arxiv.org/abs/2405.18634v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "LeDex: Training LLMs to Better Self-Debug and Explain Code", "abstract": "In the domain of code generation, self-debugging is crucial. It allows LLMs\nto refine their generated code based on execution feedback. This is\nparticularly important because generating correct solutions in one attempt\nproves challenging for complex tasks. Prior works on self-debugging mostly\nfocus on prompting methods by providing LLMs with few-shot examples, which work\npoorly on small open-sourced LLMs. In this work, we propose LeDex, a training\nframework that significantly improves the self-debugging capability of LLMs.\nIntuitively, we observe that a chain of explanations on the wrong code followed\nby code refinement helps LLMs better analyze the wrong code and do refinement.\nWe thus propose an automated pipeline to collect a high-quality dataset for\ncode explanation and refinement by generating a number of explanations and\nrefinement trajectories from the LLM itself or a larger teacher model and\nfiltering via execution verification. We perform supervised fine-tuning (SFT)\nand further reinforcement learning (RL) on both success and failure\ntrajectories with a novel reward design considering code explanation and\nrefinement quality. SFT improves the pass@1 by up to 15.92% and pass@10 by\n9.30% over four benchmarks. RL training brings additional up to 3.54%\nimprovement on pass@1 and 2.55% improvement on pass@10. The trained LLMs show\niterative refinement ability and can keep refining code continuously. Lastly,\nour human evaluation shows that the LLMs trained with our framework generate\nmore useful code explanations and help developers better understand bugs in\nsource code.", "published": "2024-05-28 23:20:24", "link": "http://arxiv.org/abs/2405.18649v2", "categories": ["cs.CL", "cs.AI", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Understanding Intrinsic Socioeconomic Biases in Large Language Models", "abstract": "Large Language Models (LLMs) are increasingly integrated into critical\ndecision-making processes, such as loan approvals and visa applications, where\ninherent biases can lead to discriminatory outcomes. In this paper, we examine\nthe nuanced relationship between demographic attributes and socioeconomic\nbiases in LLMs, a crucial yet understudied area of fairness in LLMs. We\nintroduce a novel dataset of one million English sentences to systematically\nquantify socioeconomic biases across various demographic groups. Our findings\nreveal pervasive socioeconomic biases in both established models such as GPT-2\nand state-of-the-art models like Llama 2 and Falcon. We demonstrate that these\nbiases are significantly amplified when considering intersectionality, with\nLLMs exhibiting a remarkable capacity to extract multiple demographic\nattributes from names and then correlate them with specific socioeconomic\nbiases. This research highlights the urgent necessity for proactive and robust\nbias mitigation techniques to safeguard against discriminatory outcomes when\ndeploying these powerful models in critical real-world applications.", "published": "2024-05-28 23:54:44", "link": "http://arxiv.org/abs/2405.18662v1", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards a theory of how the structure of language is acquired by deep\n  neural networks", "abstract": "How much data is required to learn the structure of a language via next-token\nprediction? We study this question for synthetic datasets generated via a\nProbabilistic Context-Free Grammar (PCFG) -- a tree-like generative model that\ncaptures many of the hierarchical structures found in natural languages. We\ndetermine token-token correlations analytically in our model and show that they\ncan be used to build a representation of the grammar's hidden variables, the\nlonger the range the deeper the variable. In addition, a finite training set\nlimits the resolution of correlations to an effective range, whose size grows\nwith that of the training set. As a result, a Language Model trained with\nincreasingly many examples can build a deeper representation of the grammar's\nstructure, thus reaching good performance despite the high dimensionality of\nthe problem. We conjecture that the relationship between training set size and\neffective range of correlations holds beyond our synthetic datasets. In\nparticular, our conjecture predicts how the scaling law for the test loss\nbehaviour with training set size depends on the length of the context window,\nwhich we confirm empirically in Shakespeare's plays and Wikipedia articles.", "published": "2024-05-28 17:01:22", "link": "http://arxiv.org/abs/2406.00048v3", "categories": ["cs.CL", "cond-mat.dis-nn", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Judgement Citation Retrieval using Contextual Similarity", "abstract": "Traditionally in the domain of legal research, the retrieval of pertinent\ncitations from intricate case descriptions has demanded manual effort and\nkeyword-based search applications that mandate expertise in understanding legal\njargon. Legal case descriptions hold pivotal information for legal\nprofessionals and researchers, necessitating more efficient and automated\napproaches. We propose a methodology that combines natural language processing\n(NLP) and machine learning techniques to enhance the organization and\nutilization of legal case descriptions. This approach revolves around the\ncreation of textual embeddings with the help of state-of-art embedding models.\nOur methodology addresses two primary objectives: unsupervised clustering and\nsupervised citation retrieval, both designed to automate the citation\nextraction process. Although the proposed methodology can be used for any\ndataset, we employed the Supreme Court of The United States (SCOTUS) dataset,\nyielding remarkable results. Our methodology achieved an impressive accuracy\nrate of 90.9%. By automating labor-intensive processes, we pave the way for a\nmore efficient, time-saving, and accessible landscape in legal research,\nbenefiting legal professionals, academics, and researchers.", "published": "2024-05-28 04:22:28", "link": "http://arxiv.org/abs/2406.01609v2", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Are PPO-ed Language Models Hackable?", "abstract": "Numerous algorithms have been proposed to $\\textit{align}$ language models to\nremove undesirable behaviors. However, the challenges associated with a very\nlarge state space and creating a proper reward function often result in various\njailbreaks. Our paper aims to examine this effect of reward in the controlled\nsetting of positive sentiment language generation. Instead of online training\nof a reward model based on human feedback, we employ a statically learned\nsentiment classifier. We also consider a setting where our model's weights and\nactivations are exposed to an end-user after training. We examine a pretrained\nGPT-2 through the lens of mechanistic interpretability before and after\nproximal policy optimization (PPO) has been applied to promote positive\nsentiment responses. Using these insights, we (1) attempt to \"hack\" the PPO-ed\nmodel to generate negative sentiment responses and (2) add a term to the reward\nfunction to try and alter `negative' weights.", "published": "2024-05-28 23:28:28", "link": "http://arxiv.org/abs/2406.02577v1", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Decoding moral judgement from text: a pilot study", "abstract": "Moral judgement is a complex human reaction that engages cognitive and\nemotional dimensions. While some of the morality neural correlates are known,\nit is currently unclear if we can detect moral violation at a single-trial\nlevel. In a pilot study, here we explore the feasibility of moral judgement\ndecoding from text stimuli with passive brain-computer interfaces. For\neffective moral judgement elicitation, we use video-audio affective priming\nprior to text stimuli presentation and attribute the text to moral agents. Our\nresults show that further efforts are necessary to achieve reliable\nclassification between moral congruency vs. incongruency states. We obtain good\naccuracy results for neutral vs. morally-charged trials. With this research, we\ntry to pave the way towards neuroadaptive human-computer interaction and more\nhuman-compatible large language models (LLMs)", "published": "2024-05-28 20:31:59", "link": "http://arxiv.org/abs/2407.00039v1", "categories": ["q-bio.NC", "cs.CL", "cs.HC"], "primary_category": "q-bio.NC"}
{"title": "The Evolution of Multimodal Model Architectures", "abstract": "This work uniquely identifies and characterizes four prevalent multimodal\nmodel architectural patterns in the contemporary multimodal landscape.\nSystematically categorizing models by architecture type facilitates monitoring\nof developments in the multimodal domain. Distinct from recent survey papers\nthat present general information on multimodal architectures, this research\nconducts a comprehensive exploration of architectural details and identifies\nfour specific architectural types. The types are distinguished by their\nrespective methodologies for integrating multimodal inputs into the deep neural\nnetwork model. The first two types (Type A and B) deeply fuses multimodal\ninputs within the internal layers of the model, whereas the following two types\n(Type C and D) facilitate early fusion at the input stage. Type-A employs\nstandard cross-attention, whereas Type-B utilizes custom-designed layers for\nmodality fusion within the internal layers. On the other hand, Type-C utilizes\nmodality-specific encoders, while Type-D leverages tokenizers to process the\nmodalities at the model's input stage. The identified architecture types aid\nthe monitoring of any-to-any multimodal model development. Notably, Type-C and\nType-D are currently favored in the construction of any-to-any multimodal\nmodels. Type-C, distinguished by its non-tokenizing multimodal model\narchitecture, is emerging as a viable alternative to Type-D, which utilizes\ninput-tokenizing techniques. To assist in model selection, this work highlights\nthe advantages and disadvantages of each architecture type based on data and\ncompute requirements, architecture complexity, scalability, simplification of\nadding modalities, training objectives, and any-to-any multimodal generation\ncapability.", "published": "2024-05-28 07:48:15", "link": "http://arxiv.org/abs/2405.17927v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG", "eess.AS"], "primary_category": "cs.AI"}
{"title": "Knowledge Circuits in Pretrained Transformers", "abstract": "The remarkable capabilities of modern large language models are rooted in\ntheir vast repositories of knowledge encoded within their parameters, enabling\nthem to perceive the world and engage in reasoning. The inner workings of how\nthese models store knowledge have long been a subject of intense interest and\ninvestigation among researchers. To date, most studies have concentrated on\nisolated components within these models, such as the Multilayer Perceptrons and\nattention head. In this paper, we delve into the computation graph of the\nlanguage model to uncover the knowledge circuits that are instrumental in\narticulating specific knowledge. The experiments, conducted with GPT2 and\nTinyLLAMA, have allowed us to observe how certain information heads, relation\nheads, and Multilayer Perceptrons collaboratively encode knowledge within the\nmodel. Moreover, we evaluate the impact of current knowledge editing techniques\non these knowledge circuits, providing deeper insights into the functioning and\nconstraints of these editing methodologies. Finally, we utilize knowledge\ncircuits to analyze and interpret language model behaviors such as\nhallucinations and in-context learning. We believe the knowledge circuits hold\npotential for advancing our understanding of Transformers and guiding the\nimproved design of knowledge editing. Code and data are available in\nhttps://github.com/zjunlp/KnowledgeCircuits.", "published": "2024-05-28 08:56:33", "link": "http://arxiv.org/abs/2405.17969v4", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improving Speech Decoding from ECoG with Self-Supervised Pretraining", "abstract": "Recent work on intracranial brain-machine interfaces has demonstrated that\nspoken speech can be decoded with high accuracy, essentially by treating the\nproblem as an instance of supervised learning and training deep neural networks\nto map from neural activity to text. However, such networks pay for their\nexpressiveness with very large numbers of labeled data, a requirement that is\nparticularly burdensome for invasive neural recordings acquired from human\npatients. On the other hand, these patients typically produce speech outside of\nthe experimental blocks used for training decoders. Making use of such data,\nand data from other patients, to improve decoding would ease the burden of data\ncollection -- especially onerous for dys- and anarthric patients. Here we\ndemonstrate that this is possible, by reengineering wav2vec -- a simple,\nself-supervised, fully convolutional model that learns latent representations\nof audio using a noise-contrastive loss -- for electrocorticographic (ECoG)\ndata. We train this model on unlabelled ECoG recordings, and subsequently use\nit to transform ECoG from labeled speech sessions into wav2vec's representation\nspace, before finally training a supervised encoder-decoder to map these\nrepresentations to text. We experiment with various numbers of labeled blocks;\nfor almost all choices, the new representations yield superior decoding\nperformance to the original ECoG data, and in no cases do they yield worse.\nPerformance can also be improved in some cases by pretraining wav2vec on\nanother patient's data. In the best cases, wav2vec's representations decrease\nword error rates over the original data by upwards of 50%.", "published": "2024-05-28 22:48:53", "link": "http://arxiv.org/abs/2405.18639v1", "categories": ["q-bio.NC", "cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "q-bio.NC"}
{"title": "The Impossibility of Fair LLMs", "abstract": "The need for fair AI is increasingly clear in the era of general-purpose\nsystems such as ChatGPT, Gemini, and other large language models (LLMs).\nHowever, the increasing complexity of human-AI interaction and its social\nimpacts have raised questions of how fairness standards could be applied. Here,\nwe review the technical frameworks that machine learning researchers have used\nto evaluate fairness, such as group fairness and fair representations, and find\nthat their application to LLMs faces inherent limitations. We show that each\nframework either does not logically extend to LLMs or presents a notion of\nfairness that is intractable for LLMs, primarily due to the multitudes of\npopulations affected, sensitive attributes, and use cases. To address these\nchallenges, we develop guidelines for the more realistic goal of achieving\nfairness in particular use cases: the criticality of context, the\nresponsibility of LLM developers, and the need for stakeholder participation in\nan iterative process of design and evaluation. Moreover, it may eventually be\npossible and even necessary to use the general-purpose capabilities of AI\nsystems to address fairness challenges as a form of scalable AI-assisted\nalignment.", "published": "2024-05-28 04:36:15", "link": "http://arxiv.org/abs/2406.03198v1", "categories": ["cs.CL", "cs.HC", "cs.LG", "stat.AP", "stat.ML"], "primary_category": "cs.CL"}
{"title": "A Data-Centric Framework for Machine Listening Projects: Addressing\n  Large-Scale Data Acquisition and Labeling through Active Learning", "abstract": "Machine Listening focuses on developing technologies to extract relevant\ninformation from audio signals. A critical aspect of these projects is the\nacquisition and labeling of contextualized data, which is inherently complex\nand requires specific resources and strategies. Despite the availability of\nsome audio datasets, many are unsuitable for commercial applications. The paper\nemphasizes the importance of Active Learning (AL) using expert labelers over\ncrowdsourcing, which often lacks detailed insights into dataset structures. AL\nis an iterative process combining human labelers and AI models to optimize the\nlabeling budget by intelligently selecting samples for human review. This\napproach addresses the challenge of handling large, constantly growing datasets\nthat exceed available computational resources and memory. The paper presents a\ncomprehensive data-centric framework for Machine Listening projects, detailing\nthe configuration of recording nodes, database structure, and labeling budget\noptimization in resource-constrained scenarios. Applied to an industrial port\nin Valencia, Spain, the framework successfully labeled 6540 ten-second audio\nsamples over five months with a small team, demonstrating its effectiveness and\nadaptability to various resource availability situations.\n  Acknowledgments: The participation of Javier Naranjo-Alcazar, Jordi Grau-Haro\nand Pedro Zuccarello in this research was funded by the Valencian Institute for\nBusiness Competitiveness (IVACE) and the FEDER funds by means of project\nSoroll-IA2 (IMDEEA/2023/91). The research carried out for this publication has\nbeen partially funded by the project STARRING-NEURO (PID2022-137048OA-C44)\nfunded by the Ministry of Science, Innovation and Universities of Spain and the\nEuropean Union.", "published": "2024-05-28 13:14:26", "link": "http://arxiv.org/abs/2405.18153v3", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "NeRAF: 3D Scene Infused Neural Radiance and Acoustic Fields", "abstract": "Sound plays a major role in human perception. Along with vision, it provides\nessential information for understanding our surroundings. Despite advances in\nneural implicit representations, learning acoustics that align with visual\nscenes remains a challenge. We propose NeRAF, a method that jointly learns\nacoustic and radiance fields. NeRAF synthesizes both novel views and\nspatialized room impulse responses (RIR) at new positions by conditioning the\nacoustic field on 3D scene geometric and appearance priors from the radiance\nfield. The generated RIR can be applied to auralize any audio signal. Each\nmodality can be rendered independently and at spatially distinct positions,\noffering greater versatility. We demonstrate that NeRAF generates high-quality\naudio on SoundSpaces and RAF datasets, achieving significant performance\nimprovements over prior methods while being more data-efficient. Additionally,\nNeRAF enhances novel view synthesis of complex scenes trained with sparse data\nthrough cross-modal learning. NeRAF is designed as a Nerfstudio module,\nproviding convenient access to realistic audio-visual generation.", "published": "2024-05-28 14:17:41", "link": "http://arxiv.org/abs/2405.18213v3", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SoundCTM: Unifying Score-based and Consistency Models for Full-band\n  Text-to-Sound Generation", "abstract": "Sound content creation, essential for multimedia works such as video games\nand films, often involves extensive trial-and-error, enabling creators to\nsemantically reflect their artistic ideas and inspirations, which evolve\nthroughout the creation process, into the sound. Recent high-quality\ndiffusion-based Text-to-Sound (T2S) generative models provide valuable tools\nfor creators. However, these models often suffer from slow inference speeds,\nimposing an undesirable burden that hinders the trial-and-error process. While\nexisting T2S distillation models address this limitation through 1-step\ngeneration, the sample quality of $1$-step generation remains insufficient for\nproduction use. Additionally, while multi-step sampling in those distillation\nmodels improves sample quality itself, the semantic content changes due to\ntheir lack of deterministic sampling capabilities. To address these issues, we\nintroduce Sound Consistency Trajectory Models (SoundCTM), which allow flexible\ntransitions between high-quality $1$-step sound generation and superior sound\nquality through multi-step deterministic sampling. This allows creators to\nefficiently conduct trial-and-error with 1-step generation to semantically\nalign samples with their intention, and subsequently refine sample quality with\npreserving semantic content through deterministic multi-step sampling. To\ndevelop SoundCTM, we reframe the CTM training framework, originally proposed in\ncomputer vision, and introduce a novel feature distance using the teacher\nnetwork for a distillation loss. For production-level generation, we scale up\nour model to 1B trainable parameters, making SoundCTM-DiT-1B the first\nlarge-scale distillation model in the sound community to achieve both promising\nhigh-quality 1-step and multi-step full-band (44.1kHz) generation.", "published": "2024-05-28 18:14:52", "link": "http://arxiv.org/abs/2405.18503v3", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "MMDisCo: Multi-Modal Discriminator-Guided Cooperative Diffusion for\n  Joint Audio and Video Generation", "abstract": "This study aims to construct an audio-video generative model with minimal\ncomputational cost by leveraging pre-trained single-modal generative models for\naudio and video. To achieve this, we propose a novel method that guides\nsingle-modal models to cooperatively generate well-aligned samples across\nmodalities. Specifically, given two pre-trained base diffusion models, we train\na lightweight joint guidance module to adjust scores separately estimated by\nthe base models to match the score of joint distribution over audio and video.\nWe show that this guidance can be computed using the gradient of the optimal\ndiscriminator, which distinguishes real audio-video pairs from fake ones\nindependently generated by the base models. Based on this analysis, we\nconstruct a joint guidance module by training this discriminator. Additionally,\nwe adopt a loss function to stabilize the discriminator's gradient and make it\nwork as a noise estimator, as in standard diffusion models. Empirical\nevaluations on several benchmark datasets demonstrate that our method improves\nboth single-modal fidelity and multimodal alignment with relatively few\nparameters. The code is available at: https://github.com/SonyResearch/MMDisCo.", "published": "2024-05-28 05:43:03", "link": "http://arxiv.org/abs/2405.17842v2", "categories": ["cs.CV", "cs.LG", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Instruct-MusicGen: Unlocking Text-to-Music Editing for Music Language\n  Models via Instruction Tuning", "abstract": "Recent advances in text-to-music editing, which employ text queries to modify\nmusic (e.g.\\ by changing its style or adjusting instrumental components),\npresent unique challenges and opportunities for AI-assisted music creation.\nPrevious approaches in this domain have been constrained by the necessity to\ntrain specific editing models from scratch, which is both resource-intensive\nand inefficient; other research uses large language models to predict edited\nmusic, resulting in imprecise audio reconstruction. To Combine the strengths\nand address these limitations, we introduce Instruct-MusicGen, a novel approach\nthat finetunes a pretrained MusicGen model to efficiently follow editing\ninstructions such as adding, removing, or separating stems. Our approach\ninvolves a modification of the original MusicGen architecture by incorporating\na text fusion module and an audio fusion module, which allow the model to\nprocess instruction texts and audio inputs concurrently and yield the desired\nedited music. Remarkably, Instruct-MusicGen only introduces 8% new parameters\nto the original MusicGen model and only trains for 5K steps, yet it achieves\nsuperior performance across all tasks compared to existing baselines, and\ndemonstrates performance comparable to the models trained for specific tasks.\nThis advancement not only enhances the efficiency of text-to-music editing but\nalso broadens the applicability of music language models in dynamic music\nproduction environments.", "published": "2024-05-28 17:27:20", "link": "http://arxiv.org/abs/2405.18386v2", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
