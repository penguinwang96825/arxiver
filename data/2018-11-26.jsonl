{"title": "LSICC: A Large Scale Informal Chinese Corpus", "abstract": "Deep learning based natural language processing model is proven powerful, but\nneed large-scale dataset. Due to the significant gap between the real-world\ntasks and existing Chinese corpus, in this paper, we introduce a large-scale\ncorpus of informal Chinese. This corpus contains around 37 million book reviews\nand 50 thousand netizen's comments to the news. We explore the informal words\nfrequencies of the corpus and show the difference between our corpus and the\nexisting ones. The corpus can be further used to train deep learning based\nnatural language processing tasks such as Chinese word segmentation, sentiment\nanalysis.", "published": "2018-11-26 03:58:09", "link": "http://arxiv.org/abs/1811.10167v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Implanting Rational Knowledge into Distributed Representation at\n  Morpheme Level", "abstract": "Previously, researchers paid no attention to the creation of unambiguous\nmorpheme embeddings independent from the corpus, while such information plays\nan important role in expressing the exact meanings of words for parataxis\nlanguages like Chinese. In this paper, after constructing the Chinese lexical\nand semantic ontology based on word-formation, we propose a novel approach to\nimplanting the structured rational knowledge into distributed representation at\nmorpheme level, naturally avoiding heavy disambiguation in the corpus. We\ndesign a template to create the instances as pseudo-sentences merely from the\npieces of knowledge of morphemes built in the lexicon. To exploit hierarchical\ninformation and tackle the data sparseness problem, the instance proliferation\ntechnique is applied based on similarity to expand the collection of\npseudo-sentences. The distributed representation for morphemes can then be\ntrained on these pseudo-sentences using word2vec. For evaluation, we validate\nthe paradigmatic and syntagmatic relations of morpheme embeddings, and apply\nthe obtained embeddings to word similarity measurement, achieving significant\nimprovements over the classical models by more than 5 Spearman scores or 8\npercentage points, which shows very promising prospects for adoption of the new\nsource of knowledge.", "published": "2018-11-26 06:01:35", "link": "http://arxiv.org/abs/1811.10188v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-task Learning over Graph Structures", "abstract": "We present two architectures for multi-task learning with neural sequence\nmodels. Our approach allows the relationships between different tasks to be\nlearned dynamically, rather than using an ad-hoc pre-defined structure as in\nprevious work. We adopt the idea from message-passing graph neural networks and\npropose a general \\textbf{graph multi-task learning} framework in which\ndifferent tasks can communicate with each other in an effective and\ninterpretable way. We conduct extensive experiments in text classification and\nsequence labeling to evaluate our approach on multi-task learning and transfer\nlearning. The empirical results show that our models not only outperform\ncompetitive baselines but also learn interpretable and transferable patterns\nacross tasks.", "published": "2018-11-26 06:54:51", "link": "http://arxiv.org/abs/1811.10211v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Rule-based Kurdish Text Transliteration System", "abstract": "In this article, we present a rule-based approach for transliterating two\nmostly used orthographies in Sorani Kurdish. Our work consists of detecting a\ncharacter in a word by removing the possible ambiguities and mapping it into\nthe target orthography. We describe different challenges in Kurdish text mining\nand propose novel ideas concerning the transliteration task for Sorani Kurdish.\nOur transliteration system, named Wergor, achieves 82.79% overall precision and\nmore than 99% in detecting the double-usage characters. We also present a\nmanually transliterated corpus for Kurdish.", "published": "2018-11-26 10:37:05", "link": "http://arxiv.org/abs/1811.10278v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Combining neural and knowledge-based approaches to Named Entity\n  Recognition in Polish", "abstract": "Named entity recognition (NER) is one of the tasks in natural language\nprocessing that can greatly benefit from the use of external knowledge sources.\nWe propose a named entity recognition framework composed of knowledge-based\nfeature extractors and a deep learning model including contextual word\nembeddings, long short-term memory (LSTM) layers and conditional random fields\n(CRF) inference layer. We use an entity linking module to integrate our system\nwith Wikipedia. The combination of effective neural architecture and external\nresources allows us to obtain state-of-the-art results on recognition of Polish\nproper names. We evaluate our model on data from PolEval 2018 NER challenge on\nwhich it outperforms other methods, reducing the error rate by 22.4% compared\nto the winning solution. Our work shows that combining neural NER model and\nentity linking model with a knowledge base is more effective in recognizing\nnamed entities than using NER model alone.", "published": "2018-11-26 14:52:06", "link": "http://arxiv.org/abs/1811.10418v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Gated Recurrent Unit Based Acoustic Modeling with Batch\n  Normalization and Enlarged Context", "abstract": "The use of future contextual information is typically shown to be helpful for\nacoustic modeling. Recently, we proposed a RNN model called minimal gated\nrecurrent unit with input projection (mGRUIP), in which a context module namely\ntemporal convolution, is specifically designed to model the future context.\nThis model, mGRUIP with context module (mGRUIP-Ctx), has been shown to be able\nof utilizing the future context effectively, meanwhile with quite low model\nlatency and computation cost. In this paper, we continue to improve mGRUIP-Ctx\nwith two revisions: applying BN methods and enlarging model context.\nExperimental results on two Mandarin ASR tasks (8400 hours and 60K hours) show\nthat, the revised mGRUIP-Ctx outperform LSTM with a large margin (11% to 38%).\nIt even performs slightly better than a superior BLSTM on the 8400h task, with\n33M less parameters and just 290ms model latency.", "published": "2018-11-26 04:00:03", "link": "http://arxiv.org/abs/1811.10169v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Learning Latent Beliefs and Performing Epistemic Reasoning for Efficient\n  and Meaningful Dialog Management", "abstract": "Many dialogue management frameworks allow the system designer to directly\ndefine belief rules to implement an efficient dialog policy. Because these\nrules are directly defined, the components are said to be hand-crafted. As\ndialogues become more complex, the number of states, transitions, and policy\ndecisions becomes very large. To facilitate the dialog policy design process,\nwe propose an approach to automatically learn belief rules using a supervised\nmachine learning approach. We validate our ideas in Student-Advisor\nconversation domain, where we extract latent beliefs like student is curious,\nconfused and neutral, etc. Further, we also perform epistemic reasoning that\nhelps to tailor the dialog according to student's emotional state and hence\nimprove the overall effectiveness of the dialog system. Our latent belief\nidentification approach shows an accuracy of 87% and this results in efficient\nand meaningful dialog management.", "published": "2018-11-26 09:12:12", "link": "http://arxiv.org/abs/1811.10238v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Challenges in the Automatic Analysis of Students' Diagnostic Reasoning", "abstract": "Diagnostic reasoning is a key component of many professions. To improve\nstudents' diagnostic reasoning skills, educational psychologists analyse and\ngive feedback on epistemic activities used by these students while diagnosing,\nin particular, hypothesis generation, evidence generation, evidence evaluation,\nand drawing conclusions. However, this manual analysis is highly\ntime-consuming. We aim to enable the large-scale adoption of diagnostic\nreasoning analysis and feedback by automating the epistemic activity\nidentification. We create the first corpus for this task, comprising diagnostic\nreasoning self-explanations of students from two domains annotated with\nepistemic activities. Based on insights from the corpus creation and the task's\ncharacteristics, we discuss three challenges for the automatic identification\nof epistemic activities using AI methods: the correct identification of\nepistemic activity spans, the reliable distinction of similar epistemic\nactivities, and the detection of overlapping epistemic activities. We propose a\nseparate performance metric for each challenge and thus provide an evaluation\nframework for future research. Indeed, our evaluation of various\nstate-of-the-art recurrent neural network architectures reveals that current\ntechniques fail to address some of these challenges.", "published": "2018-11-26 17:53:17", "link": "http://arxiv.org/abs/1811.10550v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Show, Control and Tell: A Framework for Generating Controllable and\n  Grounded Captions", "abstract": "Current captioning approaches can describe images using black-box\narchitectures whose behavior is hardly controllable and explainable from the\nexterior. As an image can be described in infinite ways depending on the goal\nand the context at hand, a higher degree of controllability is needed to apply\ncaptioning algorithms in complex scenarios. In this paper, we introduce a novel\nframework for image captioning which can generate diverse descriptions by\nallowing both grounding and controllability. Given a control signal in the form\nof a sequence or set of image regions, we generate the corresponding caption\nthrough a recurrent architecture which predicts textual chunks explicitly\ngrounded on regions, following the constraints of the given control.\nExperiments are conducted on Flickr30k Entities and on COCO Entities, an\nextended version of COCO in which we add grounding annotations collected in a\nsemi-automatic manner. Results demonstrate that our method achieves state of\nthe art performances on controllable image captioning, in terms of caption\nquality and diversity. Code and annotations are publicly available at:\nhttps://github.com/aimagelab/show-control-and-tell.", "published": "2018-11-26 19:23:33", "link": "http://arxiv.org/abs/1811.10652v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Embedding Uncertain Knowledge Graphs", "abstract": "Embedding models for deterministic Knowledge Graphs (KG) have been\nextensively studied, with the purpose of capturing latent semantic relations\nbetween entities and incorporating the structured knowledge into machine\nlearning. However, there are many KGs that model uncertain knowledge, which\ntypically model the inherent uncertainty of relations facts with a confidence\nscore, and embedding such uncertain knowledge represents an unresolved\nchallenge. The capturing of uncertain knowledge will benefit many\nknowledge-driven applications such as question answering and semantic search by\nproviding more natural characterization of the knowledge. In this paper, we\npropose a novel uncertain KG embedding model UKGE, which aims to preserve both\nstructural and uncertainty information of relation facts in the embedding\nspace. Unlike previous models that characterize relation facts with binary\nclassification techniques, UKGE learns embeddings according to the confidence\nscores of uncertain relation facts. To further enhance the precision of UKGE,\nwe also introduce probabilistic soft logic to infer confidence scores for\nunseen relation facts during training. We propose and evaluate two variants of\nUKGE based on different learning objectives. Experiments are conducted on three\nreal-world uncertain KGs via three tasks, i.e. confidence prediction, relation\nfact ranking, and relation fact classification. UKGE shows effectiveness in\ncapturing uncertain knowledge by achieving promising results on these tasks,\nand consistently outperforms baselines on these tasks.", "published": "2018-11-26 19:57:14", "link": "http://arxiv.org/abs/1811.10667v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Beyond \"How may I help you?\": Assisting Customer Service Agents with\n  Proactive Responses", "abstract": "We study the problem of providing recommended responses to customer service\nagents in live-chat dialogue systems. Smart-reply systems have been widely\napplied in real-world applications (e.g. Gmail, LinkedIn Messaging), where most\nof them can successfully recommend reactive responses. However, we observe a\nmajor limitation of current methods is that they generally have difficulties in\nsuggesting proactive investigation act (e.g. \"Do you perhaps have another\naccount with us?\") due to the lack of long-term context information, which\nindeed act as critical steps for customer service agents to collect information\nand resolve customers' issues. Thus in this work, we propose an end-to-end\nmethod with special focus on suggesting proactive investigative questions to\ncustomer agents in Airbnb's customer service live-chat system. Effectiveness of\nour proposed method can be validated through qualitative and quantitative\nresults.", "published": "2018-11-26 20:56:38", "link": "http://arxiv.org/abs/1811.10686v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Augmenting Robot Knowledge Consultants with Distributed Short Term\n  Memory", "abstract": "Human-robot communication in situated environments involves a complex\ninterplay between knowledge representations across a wide variety of\nmodalities. Crucially, linguistic information must be associated with\nrepresentations of objects, locations, people, and goals, which may be\nrepresented in very different ways. In previous work, we developed a Consultant\nFramework that facilitates modality-agnostic access to information distributed\nacross a set of heterogeneously represented knowledge sources. In this work, we\ndraw inspiration from cognitive science to augment these distributed knowledge\nsources with Short Term Memory Buffers to create an STM-augmented algorithm for\nreferring expression generation. We then discuss the potential performance\nbenefits of this approach and insights from cognitive science that may inform\nfuture refinements in the design of our approach.", "published": "2018-11-26 08:28:21", "link": "http://arxiv.org/abs/1811.10229v1", "categories": ["cs.RO", "cs.AI", "cs.CL"], "primary_category": "cs.RO"}
{"title": "ParsRec: A Novel Meta-Learning Approach to Recommending Bibliographic\n  Reference Parsers", "abstract": "Bibliographic reference parsers extract machine-readable metadata such as\nauthor names, title, journal, and year from bibliographic reference strings. To\nextract the metadata, the parsers apply heuristics or machine learning.\nHowever, no reference parser, and no algorithm, consistently gives the best\nresults in every scenario. For instance, one tool may be best in extracting\ntitles in ACM citation style, but only third best when APA is used. Another\ntool may be best in extracting English author names, while another one is best\nfor noisy data (i.e. inconsistent citation styles). In this paper, which is an\nextended version of our recent RecSys poster, we address the problem of\nreference parsing from a recommender-systems and meta-learning perspective. We\npropose ParsRec, a meta-learning based recommender-system that recommends the\npotentially most effective parser for a given reference string. ParsRec\nrecommends one out of 10 open-source parsers: Anystyle-Parser, Biblio, CERMINE,\nCitation, Citation-Parser, GROBID, ParsCit, PDFSSA4MET, Reference Tagger, and\nScience Parse. We evaluate ParsRec on 105k references from chemistry. We\npropose two approaches to meta-learning recommendations. The first approach\nlearns the best parser for an entire reference string. The second approach\nlearns the best parser for each metadata type in a reference string. The second\napproach achieved a 2.6% increase in F1 (0.909 vs. 0.886) over the best single\nparser (GROBID), reducing the false positive rate by 20.2% (0.075 vs. 0.094),\nand the false negative rate by 18.9% (0.107 vs. 0.132).", "published": "2018-11-26 13:56:57", "link": "http://arxiv.org/abs/1811.10369v1", "categories": ["cs.IR", "cs.CL", "cs.DL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Sentence Encoding with Tree-constrained Relation Networks", "abstract": "The meaning of a sentence is a function of the relations that hold between\nits words. We instantiate this relational view of semantics in a series of\nneural models based on variants of relation networks (RNs) which represent a\nset of objects (for us, words forming a sentence) in terms of representations\nof pairs of objects. We propose two extensions to the basic RN model for\nnatural language. First, building on the intuition that not all word pairs are\nequally informative about the meaning of a sentence, we use constraints based\non both supervised and unsupervised dependency syntax to control which\nrelations influence the representation. Second, since higher-order relations\nare poorly captured by a sum of pairwise relations, we use a recurrent\nextension of RNs to propagate information so as to form representations of\nhigher order relations. Experiments on sentence classification, sentence pair\nclassification, and machine translation reveal that, while basic RNs are only\nmodestly effective for sentence representation, recurrent RNs with latent\nsyntax are a reliably powerful representational device.", "published": "2018-11-26 16:07:36", "link": "http://arxiv.org/abs/1811.10475v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CLEAR: A Dataset for Compositional Language and Elementary Acoustic\n  Reasoning", "abstract": "We introduce the task of acoustic question answering (AQA) in the area of\nacoustic reasoning. In this task an agent learns to answer questions on the\nbasis of acoustic context. In order to promote research in this area, we\npropose a data generation paradigm adapted from CLEVR (Johnson et al. 2017). We\ngenerate acoustic scenes by leveraging a bank elementary sounds. We also\nprovide a number of functional programs that can be used to compose questions\nand answers that exploit the relationships between the attributes of the\nelementary sounds in each scene. We provide AQA datasets of various sizes as\nwell as the data generation code. As a preliminary experiment to validate our\ndata, we report the accuracy of current state of the art visual question\nanswering models when they are applied to the AQA task without modifications.\nAlthough there is a plethora of question answering tasks based on text, image\nor video data, to our knowledge, we are the first to propose answering\nquestions directly on audio streams. We hope this contribution will facilitate\nthe development of research in the area.", "published": "2018-11-26 18:06:36", "link": "http://arxiv.org/abs/1811.10561v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.CL"}
{"title": "What Should I Learn First: Introducing LectureBank for NLP Education and\n  Prerequisite Chain Learning", "abstract": "Recent years have witnessed the rising popularity of Natural Language\nProcessing (NLP) and related fields such as Artificial Intelligence (AI) and\nMachine Learning (ML). Many online courses and resources are available even for\nthose without a strong background in the field. Often the student is curious\nabout a specific topic but does not quite know where to begin studying. To\nanswer the question of \"what should one learn first,\" we apply an\nembedding-based method to learn prerequisite relations for course concepts in\nthe domain of NLP. We introduce LectureBank, a dataset containing 1,352 English\nlecture files collected from university courses which are each classified\naccording to an existing taxonomy as well as 208 manually-labeled prerequisite\nrelation topics, which is publicly available. The dataset will be useful for\neducational purposes such as lecture preparation and organization as well as\napplications such as reading list generation. Additionally, we experiment with\nneural graph-based networks and non-neural classifiers to learn these\nprerequisite relations from our dataset.", "published": "2018-11-26 21:09:20", "link": "http://arxiv.org/abs/1811.12181v1", "categories": ["cs.CY", "cs.CL", "cs.IR", "cs.LG", "stat.ML"], "primary_category": "cs.CY"}
{"title": "Robustness against the channel effect in pathological voice detection", "abstract": "Many people are suffering from voice disorders, which can adversely affect\nthe quality of their lives. In response, some researchers have proposed\nalgorithms for automatic assessment of these disorders, based on voice signals.\nHowever, these signals can be sensitive to the recording devices. Indeed, the\nchannel effect is a pervasive problem in machine learning for healthcare. In\nthis study, we propose a detection system for pathological voice, which is\nrobust against the channel effect. This system is based on a bidirectional LSTM\nnetwork. To increase the performance robustness against channel mismatch, we\nintegrate domain adversarial training (DAT) to eliminate the differences\nbetween the devices. When we train on data recorded on a high-quality\nmicrophone and evaluate on smartphone data without labels, our robust detection\nsystem increases the PR-AUC from 0.8448 to 0.9455 (and 0.9522 with target\nsample labels). To the best of our knowledge, this is the first study applying\nunsupervised domain adaptation to pathological voice detection. Notably, our\nsystem does not need target device sample labels, which allows for\ngeneralization to many new devices.", "published": "2018-11-26 14:11:12", "link": "http://arxiv.org/abs/1811.10376v2", "categories": ["cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Combining High-Level Features of Raw Audio Waves and Mel-Spectrograms\n  for Audio Tagging", "abstract": "In this paper, we describe our contribution to Task 2 of the DCASE 2018 Audio\nChallenge. While it has become ubiquitous to utilize an ensemble of machine\nlearning methods for classification tasks to obtain better predictive\nperformance, the majority of ensemble methods combine predictions rather than\nlearned features. We propose a single-model method that combines learned\nhigh-level features computed from log-scaled mel-spectrograms and raw audio\ndata. These features are learned separately by two Convolutional Neural\nNetworks, one for each input type, and then combined by densely connected\nlayers within a single network. This relatively simple approach along with data\naugmentation ranks among the best two percent in the Freesound General-Purpose\nAudio Tagging Challenge on Kaggle.", "published": "2018-11-26 22:02:20", "link": "http://arxiv.org/abs/1811.10708v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "DONUT: CTC-based Query-by-Example Keyword Spotting", "abstract": "Keyword spotting--or wakeword detection--is an essential feature for\nhands-free operation of modern voice-controlled devices. With such devices\nbecoming ubiquitous, users might want to choose a personalized custom wakeword.\nIn this work, we present DONUT, a CTC-based algorithm for online\nquery-by-example keyword spotting that enables custom wakeword detection. The\nalgorithm works by recording a small number of training examples from the user,\ngenerating a set of label sequence hypotheses from these training examples, and\ndetecting the wakeword by aggregating the scores of all the hypotheses given a\nnew audio recording. Our method combines the generalization and\ninterpretability of CTC-based keyword spotting with the user-adaptation and\nconvenience of a conventional query-by-example system. DONUT has low\ncomputational requirements and is well-suited for both learning and inference\non embedded systems without requiring private user data to be uploaded to the\ncloud.", "published": "2018-11-26 23:13:25", "link": "http://arxiv.org/abs/1811.10736v1", "categories": ["cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
