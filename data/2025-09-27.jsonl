{"title": "Diameter Bounds for Friends-and-Strangers Graphs", "abstract": "Consider two $n$-vertex graphs $X$ and $Y$, where we interpret $X$ as a\nsocial network with edges representing friendships and $Y$ as a movement graph\nwith edges representing adjacent positions. The friends-and-strangers graph\n$\\mathsf{FS}(X,Y)$ is a graph on the $n!$ permutations $V(X)\\to V(Y)$, where\ntwo configurations are adjacent if and only if one can be obtained from the\nother by swapping two friends located on adjacent positions.\n  Friends-and-strangers graphs were first introduced by Defant and Kravitz, and\ngeneralize sliding puzzles as well as token swapping problems. Previous work\nhas largely focused on their connectivity properties. In this paper, we study\nthe diameter of the connected components of $\\mathsf{FS}(X, Y)$. Our main\nresult shows that when the underlying friendship graph is a star with $n$\nvertices, the friends-and-strangers graph has components of diameter $O(n^4)$.\nThis implies, in particular, that sliding puzzles are always solvable in\npolynomially many moves. Our work also provides explicit efficient algorithms\nfor finding these solutions.\n  We then extend our results to general graphs in two ways. First, we show that\nthe diameter is polynomially bounded when both the friendship and the movement\ngraphs have large minimum degree. Second, when both the underlying graphs $X$\nand $Y$ are Erd\\H{o}s-R\\'{e}nyi random graphs, we show that the distance\nbetween any pair of configurations is almost always polynomially bounded under\ncertain conditions on the edge probabilities.", "published": "2025-09-27 22:03:21", "link": "http://arxiv.org/abs/2509.23511v1", "categories": ["math.CO", "cs.DM", "math.PR", "05C12"], "primary_category": "math.CO"}
{"title": "Drift-Adapter: A Practical Approach to Near Zero-Downtime Embedding Model Upgrades in Vector Databases", "abstract": "Upgrading embedding models in production vector databases typically requires\nre-encoding the entire corpus and rebuilding the Approximate Nearest Neighbor\n(ANN) index, leading to significant operational disruption and computational\ncost. This paper presents Drift-Adapter, a lightweight, learnable\ntransformation layer designed to bridge embedding spaces between model\nversions. By mapping new queries into the legacy embedding space, Drift-Adapter\nenables the continued use of the existing ANN index, effectively deferring full\nre-computation. We systematically evaluate three adapter parameterizations:\nOrthogonal Procrustes, Low-Rank Affine, and a compact Residual MLP, trained on\na small sample of paired old and new embeddings. Experiments on MTEB text\ncorpora and a CLIP image model upgrade (1M items) show that Drift-Adapter\nrecovers 95-99% of the retrieval recall (Recall@10, MRR) of a full\nre-embedding, adding less than 10 microseconds of query latency. Compared to\noperational strategies like full re-indexing or dual-index serving,\nDrift-Adapter reduces recompute costs by over 100 times and facilitates\nupgrades with near-zero operational interruption. We analyze robustness to\nvaried model drift, training data size, scalability to billion-item systems,\nand the impact of design choices like diagonal scaling, demonstrating\nDrift-Adapter's viability as a pragmatic solution for agile model deployment.", "published": "2025-09-27 19:47:19", "link": "http://arxiv.org/abs/2509.23471v1", "categories": ["cs.LG", "cs.IR"], "primary_category": "cs.LG"}
{"title": "PARROT: A Benchmark for Evaluating LLMs in Cross-System SQL Translation", "abstract": "Large language models (LLMS) have shown increasing effectiveness in\nText-to-SQL tasks. However, another closely related problem, Cross-System SQL\nTranslation (a.k.a., SQL-to-SQL), which adapts a query written for one database\nsystem (e.g., MySQL) into its equivalent one for another system (e.g.,\nClickHouse), is of great practical importance but remains underexplored.\nExisting SQL benchmarks are not well-suited for SQL-to-SQL evaluation, which\n(1) focus on a limited set of database systems (often just SQLite) and (2)\ncannot capture many system-specific SQL dialects (e.g., customized functions,\ndata types, and syntax rules). Thus, in this paper, we introduce PARROT, a\nPractical And Realistic BenchmaRk for CrOss-System SQL Translation. PARROT\ncomprises 598 translation pairs from 38 open-source benchmarks and real-world\nbusiness services, specifically prepared to challenge system-specific SQL\nunderstanding (e.g., LLMS achieve lower than 38.53% accuracy on average). We\nalso provide multiple benchmark variants, including PARROT-Diverse with 28,003\ntranslations (for extensive syntax testing) and PARROT-Simple with 5,306\nrepresentative samples (for focused stress testing), covering 22\nproduction-grade database systems. To promote future research, we release a\npublic leaderboard and source code at: https://code4db.github.io/parrot-bench/.", "published": "2025-09-27 14:41:13", "link": "http://arxiv.org/abs/2509.23338v1", "categories": ["cs.DB", "cs.AI", "cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.DB"}
{"title": "WARBERT: A Hierarchical BERT-based Model for Web API Recommendation", "abstract": "With the emergence of Web 2.0 and microservices architecture, the number of\nWeb APIs has increased dramatically, further intensifying the demand for\nefficient Web API recommendation. Existing solutions typically fall into two\ncategories: recommendation-type methods, which treat each API as a label for\nclassification, and match-type methods, which focus on matching mashups through\nAPI retrieval. However, three critical challenges persist: 1) the semantic\nambiguities in comparing API and mashup descriptions, 2) the lack of detailed\ncomparisons between the individual API and the mashup in recommendation-type\nmethods, and 3) time inefficiencies for API retrieval in match-type methods. To\naddress these challenges, we propose WARBERT, a hierarchical BERT-based model\nfor Web API recommendation. WARBERT leverages dual-component feature fusion and\nattention comparison to extract precise semantic representations of API and\nmashup descriptions. WARBERT consists of two main components: WARBERT(R) for\nRecommendation and WARBERT(M) for Matching. Specifically, WAR-BERT(R) serves as\nan initial filter, narrowing down the candidate APIs, while WARBERT(M) refines\nthe matching process by calculating the similarity between candidate APIs and\nmashup. The final likelihood of a mashup being matched with an API is\ndetermined by combining the predictions from WARBERT(R) and WARBERT(M).\nAdditionally, WARBERT(R) incorporates an auxiliary task of mashup category\njudgment, which enhances its effectiveness in candidate selection. Experimental\nresults on the ProgrammableWeb dataset demonstrate that WARBERT outperforms\nmost existing solutions and achieves improvements of up to 11.7% compared to\nthe model MTFM (Multi-Task Fusion Model), delivering significant enhancements\nin accuracy and effiency.", "published": "2025-09-27 08:09:41", "link": "http://arxiv.org/abs/2509.23175v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Fundamental Limits of Distributed Computing for Linearly Separable Functions", "abstract": "This work addresses the problem of distributed computation of linearly\nseparable functions, where a master node with access to $K$ datasets, employs\n$N$ servers to compute $L$ user-requested functions, each defined over the\ndatasets. Servers are instructed to compute subfunctions of the datasets and\nmust communicate computed outputs to the user, who reconstructs the requested\noutputs. The central challenge is to reduce the per-server computational load\nand the communication cost from servers to the user, while ensuring recovery\nfor any possible set of $L$ demanded functions.\n  We here establish the fundamental communication-computation tradeoffs for\narbitrary $K$ and $L$, through novel task-assignment and communication\nstrategies that, under the linear-encoding and no-subpacketization assumptions,\nare proven to be either exactly optimal or within a factor of three from the\noptimum. In contrast to prior approaches that relied on fixed assignments of\ntasks -- either disjoint or cyclic assignments -- our key innovation is a\nnullspace-based design that jointly governs task assignment and server\ntransmissions, ensuring exact decodability for all demands, and attaining\noptimality over all assignment and delivery methods. To prove this optimality,\nwe here uncover a duality between nullspaces and sparse matrix factorizations,\nenabling us to recast the distributed computing problem as an equivalent\nfactorization task and derive a sharp information-theoretic converse bound.\nBuilding on this, we establish an additional converse that, for the first time,\nlinks the communication cost to the covering number from the theory of general\ncovering designs.", "published": "2025-09-27 18:33:22", "link": "http://arxiv.org/abs/2509.23447v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Noise-Domain Non-Orthogonal Multiple Access for Three Users", "abstract": "In this study, we propose a novel three-user noise-domain non-orthogonal\nmultiple access (ND-NOMA) scheme by introducing the correlation as a new\ndimension besides mean and variance quantities used in two-user ND-NOMA. The\nnew three-user ND-NOMA scheme includes both uplink and downlink scenarios, with\ndetectors designed to decode the information embedded in mean, variance, and\ncorrelation. Our theoretical analysis and simulation results under Rician\nfading channels show that the proposed system is capable of achieving promising\nbit error rate (BER) performance while preserving the low power and low\ncomplexity advantages of ND-NOMA. This new ND-NOMA design enables simultaneous\ncommunication among three users using different dimensions, paving the way for\nscalable multi-user communication in noise-domain systems and in the\nInternet-of-things (IoT) environments.", "published": "2025-09-27 16:53:07", "link": "http://arxiv.org/abs/2509.23407v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Absorbing Markov Chain-Based Analysis of Age of Information in Discrete-Time Dual-Queue Systems", "abstract": "Status update systems require the timely collection of sensing information\nfor which deploying multiple sensors/servers to obtain diversity gains is\nconsidered as a promising solution. In this work, we construct an absorbing\nMarkov chain (AMC) to exactly model Age of Information (AoI) in a discretetime\ndual-queue (DTDQ) status update system with generate at will (GAW) status\nupdates, discrete phase-type (DPH-type) distributed service times and\ntransmission freezing. Specifically, transmission is frozen for a certain\nnumber of slots following the initiation of a transmission, after which one of\nthe two servers is allowed to simultaneously sample the monitored physical\nprocess and transmit a status update packet, according to the availabilities\nand priorities of the two servers. Based on the discrete-time AMC, we provide\nthe exact distributions of both AoI and peak AoI (PAoI), enabling the\nderivation of arbitrary order moments. In addition, we analytically study the\nrole of freezing using several typical service time distributions, including\ngeometric, uniform, and triangular distributions. The introduction of freezing\nfor DTDQ systems is demonstrated to be significantly beneficial in reducing the\nmean AoI for various service time distributions. Additionally, we study the\nimpact of the statistical parameters of the service times and heterogeneity\nbetween the two servers on the freezing gain, i.e., reduction in mean AoI\nattained with optimum freezing policies.", "published": "2025-09-27 15:20:00", "link": "http://arxiv.org/abs/2509.23360v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "RIS-Assisted XL-MIMO for Near-Field and Far-Field Communications", "abstract": "We consider a reconfigurable intelligent surface (RIS)-assisted extremely\nlarge-scale multiple-input multiple-output (XL-MIMO) downlink system, where an\nXL-MIMO array serves two groups of single-antennas users, namely near-field\nusers (NFUEs) and far-field users (FFUEs). FFUEs are subject to blockage, and\ntheir communication is facilitated through the RIS. We consider three precoding\nschemes at the XL-MIMO array, namely central zero-forcing (CZF), local\nzero-forcing (LZF) and maximum ratio transmission (MRT). Closed-form\nexpressions for the spectral efficiency (SE) of all users are derived for MRT\nprecoding, while statistical-form expressions are obtained for CZF and LZF\nprocessing. A heuristic visibility region (VR) selection algorithm is also\nintroduced to help reduce the computational complexity of the precoding scheme.\nFurthermore, we devise a two-stage phase shifts design and power control\nalgorithm to maximize the sum of weighted minimum SE of two groups of users\nwith CZF, LZF and MRT precoding schemes. The simulation results indicate that,\nwhen equal priority is given to NFUEs and FFUEs, the proposed design improves\nthe sum of the weighted minimum SE by 31.9\\%, 37.8\\%, and 119.2\\% with CZF,\nLZF, and MRT, respectively, compared to the case with equal power allocation\nand random phase shifts design. CZF achieves the best performance, while LZF\noffers comparable results with lower complexity. When prioritizing NFUEs or\nFFUEs, LZF achieves strong performance for the prioritized group, whereas CZF\nensures balanced performance between NFUEs and FFUEs.", "published": "2025-09-27 12:47:58", "link": "http://arxiv.org/abs/2509.23284v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "RIS- and Multi-Snapshot-Enabled SISO 3D Position and Velocity Estimation With Single Base Station", "abstract": "Reconfigurable intelligent surface (RIS) panels can act as cost-effective\nanchors for radio localization, complementing conventional base station (BS)\nanchors. This paper investigates joint three-dimensional position and velocity\nestimation (3D-JPVE) in single-input single-output (SISO) systems with only one\nBS available. We first theoretically show that 3D-JPVE is infeasible when\nrelying solely on a single RIS or on multiple snapshots alone. To address this,\nwe propose combining RIS deployment with multi-snapshot utilization to enable\nrealizable 3D-JPVE. A two-stage method is developed for multi-snapshot channel\nparameter estimation, comprising a tensor-based coarse estimation step followed\nby a maximum likelihood refinement step. In particular, we introduce a\nthird-order tensor formulation to decompose the challenging 3D joint\nangle-of-departure and Doppler shift estimation (3D-JADE) into two tractable\nsubproblems, which are jointly solved via a low-complexity alternating\noptimization approach. Building on the channel parameter estimates, we further\ndesign a two-stage low-complexity method for optimal 3D-JPVE: coarse estimation\nis obtained from differential measurements through linear equations, and the\npreliminary results are refined iteratively using the original measurements.\nMoreover, we derive the closed-form Cramer-Rao lower bound (CRLB) and show that\nthe proposed 3D-JPVE method approaches CRLB-level accuracy. Simulation results\nconfirm the statistical efficiency of the proposed estimators and demonstrate\nsubstantial 3D-JPVE performance gains when deploying active RIS compared to\npassive RIS.", "published": "2025-09-27 12:02:05", "link": "http://arxiv.org/abs/2509.23274v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Markov Modeling for Licensed and Unlicensed Band Allocation in Underlay and Overlay D2D", "abstract": "In this paper, a novel analytical model for resource allocation is proposed\nfor a device-to-device (D2D) assisted cellular network. The proposed model can\nbe applied to underlay and overlay D2D systems for sharing licensed bands and\noffloading cellular traffic. The developed model also takes into account the\nproblem of unlicensed band sharing with Wi-Fi systems. In the proposed model, a\nglobal system state reflects the interaction among D2D, conventional cellular,\nand Wi-Fi packets. Under the standard traffic model assumptions, a\nthreshold-based flow control is proposed for guaranteeing the\nquality-of-service (QoS) of Wi-Fi. The packet blockage probability is then\nderived. Simulation results show the proposed scheme sacrifices conventional\ncellular performance slightly to improve overlay D2D performance significantly\nwhile maintaining the performance for Wi-Fi users. Meanwhile, the proposed\nscheme has more flexible adjustments between D2D and Wi-Fi than the underlay\nscheme.", "published": "2025-09-27 09:56:46", "link": "http://arxiv.org/abs/2509.23218v1", "categories": ["cs.NI", "cs.IT", "cs.NA", "cs.PF", "cs.SY", "eess.SY", "math.IT", "math.NA", "68M10, 68M20, 60J20", "C.2.1; C.2.5; C.4"], "primary_category": "cs.NI"}
{"title": "Modeling the Unlicensed Band Allocation for LAA With Buffering Mechanism", "abstract": "In this letter, we propose an analytical model and conduct simulation\nexperiments to study listen-before-talk-based unlicensed band allocation with\nthe buffering mechanism for the License-Assisted Access (LAA) packets in the\nheterogeneous networks. In such a network, unlicensed band allocation for LAA\nand Wi-Fi is an important issue, which may affect the quality of service for\nboth systems significantly. We evaluate the performance of these unlicensed\nband allocations in terms of the acceptance rate of both LAA and Wi-Fi packets.\nThis letter provides the guidelines for designing the channel occupation phase\nand buffer threshold of the LAA systems.", "published": "2025-09-27 09:56:17", "link": "http://arxiv.org/abs/2509.23217v1", "categories": ["cs.NI", "cs.IT", "cs.NA", "cs.PF", "cs.SY", "eess.SY", "math.IT", "math.NA", "68M10, 68M20, 60J20", "C.2.1; C.2.5; C.4"], "primary_category": "cs.NI"}
{"title": "Unlicensed Band Allocation for Heterogeneous Networks", "abstract": "Based on the License-Assisted Access (LAA) small cell architecture, the LAA\ncoexisting with Wi-Fi heterogeneous networks provides LTE mobile users with\nhigh bandwidth efficiency as the unlicensed channels are shared among LAA and\nWi-Fi. However, LAA and Wi-Fi interfere with each other when both systems use\nthe same unlicensed channel in heterogeneous networks. In such a network,\nunlicensed band allocation for LAA and Wi-Fi is an important issue that may\naffect the quality of service (QoS) of both systems significantly. In this\npaper, we propose an analytical model and conduct simulation experiments to\nstudy four allocations for the unlicensed band: unlicensed full allocation\n(UFA), unlicensed time-division allocation (UTA), and UFA/UTA with buffering\nmechanism (UFAB and UTAB) for the LAA data packets. We evaluate the performance\nof these unlicensed band allocation schemes in terms of the acceptance rate of\nboth LAA and Wi-Fi packet data in the LAA buffer queue. Our study provides\nguidelines for designing the channel occupation phase and the buffer size of\nthe LAA small cell.", "published": "2025-09-27 09:55:43", "link": "http://arxiv.org/abs/2509.23216v1", "categories": ["cs.NI", "cs.IT", "cs.NA", "cs.PF", "cs.SY", "eess.SY", "math.IT", "math.NA", "68M10, 68M20, 60J20", "C.2.1; C.2.5; C.4"], "primary_category": "cs.NI"}
{"title": "Zigzag Codes Revisited: From Optimal Rebuilding to Small Skip Cost and Small Fields", "abstract": "We revisit zigzag array codes, a family of MDS codes known for achieving\noptimal access and optimal rebuilding ratio in single-node repair. In this\nwork, we endow zigzag codes with two new properties: small field size and low\nskip cost. First, we prove that when the row-indexing group is $\\mathcal{G} =\n\\mathbb{Z}_2^m$ and the field has characteristic two, explicit coefficients\nover any field with $|\\mathcal{F}|\\ge N$ guarantee the MDS property, thereby\ndecoupling the dependence among $p$, $k$, and $M$. Second, we introduce an\nordering-and-subgroup framework that yields repair-by-transfer schemes with\nbounded skip cost and low repair-fragmentation ratio (RFR), while preserving\noptimal access and optimal rebuilding ratio. Our explicit constructions include\nfamilies with zero skip cost whose rates approach $2/3$, and families with\nbounded skip cost whose rates approach $3/4$ and $4/5$. These rates are\ncomparable to those of MDS array codes widely deployed in practice. Together,\nthese results demonstrate that zigzag codes can be made both more flexible in\ntheory and more practical for modern distributed storage systems.", "published": "2025-09-27 03:58:01", "link": "http://arxiv.org/abs/2509.23090v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Situational Awareness for Safe and Robust Multi-Agent Interactions Under Uncertainty", "abstract": "Multi-agent systems are prevalent in a wide range of domains including power\nsystems, vehicular networks, and robotics. Two important problems to solve in\nthese types of systems are how the intentions of non-coordinating agents can be\ndetermined to predict future behavior and how the agents can achieve their\nobjectives under resource constraints without significantly sacrificing\nperformance. To study this, we develop a model where an autonomous agent\nobserves the environment within a safety radius of observation, determines the\nstate of a surrounding agent of interest (within the observation radius),\nestimates future actions to be taken, and acts in an optimal way. In the\nabsence of observations, agents are able to utilize an estimation algorithm to\npredict the future actions of other agents based on historical trajectory. The\nuse of the proposed estimation algorithm introduces uncertainty, which is\nmanaged via risk analysis. The proposed approach in this study is validated\nusing two different learning-based decision making frameworks: reinforcement\nlearning and game theoretic algorithms.", "published": "2025-09-27 17:38:37", "link": "http://arxiv.org/abs/2509.23425v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Grouped Satisficing Paths in Pure Strategy Games: a Topological Perspective", "abstract": "In game theory and multi-agent reinforcement learning (MARL), each agent\nselects a strategy, interacts with the environment and other agents, and\nsubsequently updates its strategy based on the received payoff. This process\ngenerates a sequence of joint strategies $(s^t)_{t \\geq 0}$, where $s^t$\nrepresents the strategy profile of all agents at time step $t$. A widely\nadopted principle in MARL algorithms is \"win-stay, lose-shift\", which dictates\nthat an agent retains its current strategy if it achieves the best response.\nThis principle exhibits a fixed-point property when the joint strategy has\nbecome an equilibrium. The sequence of joint strategies under this principle is\nreferred to as a satisficing path, a concept first introduced in [40] and\nexplored in the context of $N$-player games in [39]. A fundamental question\narises regarding this principle: Under what conditions does every initial joint\nstrategy $s$ admit a finite-length satisficing path $(s^t)_{0 \\leq t \\leq T}$\nwhere $s^0=s$ and $s^T$ is an equilibrium? This paper establishes a sufficient\ncondition for such a property, and demonstrates that any finite-state Markov\ngame, as well as any $N$-player game, guarantees the existence of a\nfinite-length satisficing path from an arbitrary initial strategy to some\nequilibrium. These results provide a stronger theoretical foundation for the\ndesign of MARL algorithms.", "published": "2025-09-27 07:07:27", "link": "http://arxiv.org/abs/2509.23157v1", "categories": ["cs.GT", "cs.LG", "cs.MA"], "primary_category": "cs.GT"}
{"title": "Coordination Requires Simplification: Thermodynamic Bounds on Multi-Objective Compromise in Natural and Artificial Intelligence", "abstract": "Information-processing systems coordinating across multiple agents and\nobjectives face fundamental thermodynamic constraints. We show that solutions\nwith maximum utility to act as coordination focal points have much higher\nselection pressure for being findable across agents rather than accuracy. We\nderive that the information-theoretic minimum description length of\ncoordination protocols to precision $\\varepsilon$ scales as $L(P)\\geq NK\\log_2\nK+N^2d^2\\log (1/\\varepsilon)$ for $N$ agents with $d$ potentially conflicting\nobjectives and internal model complexity $K$. This scaling forces progressive\nsimplification, with coordination dynamics changing the environment itself and\nshifting optimization across hierarchical levels. Moving from established focal\npoints requires re-coordination, creating persistent metastable states and\nhysteresis until significant environmental shifts trigger phase transitions\nthrough spontaneous symmetry breaking. We operationally define coordination\ntemperature to predict critical phenomena and estimate coordination work costs,\nidentifying measurable signatures across systems from neural networks to\nrestaurant bills to bureaucracies. Extending the topological version of Arrow's\ntheorem on the impossibility of consistent preference aggregation, we find it\nrecursively binds whenever preferences are combined. This potentially explains\nthe indefinite cycling in multi-objective gradient descent and alignment faking\nin Large Language Models trained with reinforcement learning with human\nfeedback. We term this framework Thermodynamic Coordination Theory (TCT), which\ndemonstrates that coordination requires radical information loss.", "published": "2025-09-27 06:16:56", "link": "http://arxiv.org/abs/2509.23144v1", "categories": ["cs.AI", "cond-mat.stat-mech", "cs.MA", "nlin.AO", "physics.soc-ph"], "primary_category": "cs.AI"}
{"title": "Game-Theoretic Understandings of Multi-Agent Systems with Multiple Objectives", "abstract": "In practical multi-agent systems, agents often have diverse objectives, which\nmakes the system more complex, as each agent's performance across multiple\ncriteria depends on the joint actions of all agents, creating intricate\nstrategic trade-offs. To address this, we introduce the Multi-Objective Markov\nGame (MOMG), a framework for multi-agent reinforcement learning with multiple\nobjectives. We propose the Pareto-Nash Equilibrium (PNE) as the primary\nsolution concept, where no agent can unilaterally improve one objective without\nsacrificing performance on another. We prove existence of PNE, and establish an\nequivalence between the PNE and the set of Nash Equilibria of MOMG's\ncorresponding linearly scalarized games, enabling solutions of MOMG by\ntransferring to a standard single-objective Markov game. However, we note that\ncomputing a PNE is theoretically and computationally challenging, thus we\npropose and study weaker but more tractable solution concepts. Building on\nthese foundations, we develop online learning algorithm that identify a single\nsolution to MOMGs. Furthermore, we propose a two-phase, preference-free\nalgorithm that decouples exploration from planning. Our algorithm enables\ncomputation of a PNE for any given preference profile without collecting new\nsamples, providing an efficient methodological characterization of the entire\nPareto-Nash front.", "published": "2025-09-27 00:49:49", "link": "http://arxiv.org/abs/2509.23026v1", "categories": ["cs.MA", "cs.GT"], "primary_category": "cs.MA"}
{"title": "Asymptotic Error Analysis of Gauss Quadrature for Nonsmooth Functions", "abstract": "We derive an asymptotic error formula for Gauss--Legendre quadrature applied\nto functions with limited regularity, using the contour-integral representation\nof the remainder term. To address the absence of uniformly valid approximations\nof Legendre functions near $[-1,1]$, we approximate the integrand by smoother\nfunctions with singularities displaced from the interval and then obtain\nasymptotic expansions of the Legendre functions that hold uniformly along the\ncontour. The resulting error formula identifies not only the optimal\nconvergence rate but also the leading coefficient, expressed in terms of\n$\\cos((2n+1)\\phi)$, where $n$ is the number of quadrature points and\n$\\cos(\\phi)$ locates the singularity. This characterization enables both the\nselection of quadrature sizes that minimize the leading error and the use of\nthe error formula as a correction term to accelerate convergence. Applications\nto functions with power and logarithmic singularities are presented, and\nnumerical experiments confirm the accuracy of the analysis.", "published": "2025-09-27 23:58:23", "link": "http://arxiv.org/abs/2509.23532v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Multi-order Runge-Kutta methods or how to numerically solve initial value problems of any order", "abstract": "When one wishes to numerically solve an initial value problem, it is\ncustomary to rewrite it as an equivalent first-order system to which a method,\nusually from the class of Runge-Kutta methods, is applied. Directly treating\nhigher-order initial value problems without such rewriting, however, allows for\nsignificantly greater accuracy. We therefore introduce a new generalization of\nRunge-Kutta methods, called multi-order Runge-Kutta methods, designed to solve\ninitial value problems of arbitrary order. We establish fundamental properties\nof these methods, including convergence, order of consistency, and linear\nstability. We also analyze the structure of the system satisfied by the\napproximations of a method, which enables us to provide a proper definition of\nexplicit methods and to gain a finer understanding of implicit methods.", "published": "2025-09-27 22:08:41", "link": "http://arxiv.org/abs/2509.23513v1", "categories": ["math.NA", "cs.NA", "65L06 (Primary) 65L05, 65L20, 65L70 (Secondary)"], "primary_category": "math.NA"}
{"title": "Energy minimization for skyrmions on planar thin films", "abstract": "We consider an energy functional that arises in micromagnetic and liquid\ncrystal theory on thin films. In particular, our energy comprises a non-convex\nterm that models anti-symmetric exchange as well as an anisotropy term. We\ndevise an algorithm for energy minimization in the continuous case and show\nweak convergence of a subsequence towards a solution of the corresponding\nEuler--Lagrange equation. Furthermore, an algorithm for numerical energy\nminimization is presented. We show empirically that this numerical algorithm\nconverges to the correct solutions for a benchmark problem without the need for\nuser-supplied parameters, and present a rigorous convergence analysis for\nimportant special cases.", "published": "2025-09-27 20:58:14", "link": "http://arxiv.org/abs/2509.23495v1", "categories": ["math.NA", "cs.NA", "math.AP"], "primary_category": "math.NA"}
{"title": "Penalized Weighted Trace Minimization for Optimal Control Device Design and Placement", "abstract": "In this paper, we present a new analytical framework for determining the\nwell-posedness of constrained optimization problems that arise in the study of\noptimal control device design and placement within the context of infinite\ndimensional linear quadratic control systems. We first prove the well-posedness\nof the newly minted \"strong form\" of the time-independent operator-valued\nRiccati equation. This form of the equation then enables the use of trace-class\noperator analysis and the Lagrange multiplier formalism to analyze\noperator-valued Riccati equation-constrained optimization problems. Using this\nfundamental result, we then determine the conditions under which there exists\nunique solutions to two important classes of penalized trace minimization\nproblems for optimal control device placement and design.", "published": "2025-09-27 19:58:03", "link": "http://arxiv.org/abs/2509.23477v1", "categories": ["math.NA", "cs.NA", "math.OC", "49J46870"], "primary_category": "math.NA"}
{"title": "New Insights and Algorithms for Optimal Diagonal Preconditioning", "abstract": "Preconditioning (scaling) is essential in many areas of mathematics, and in\nparticular in optimization. In this work, we study the problem of finding an\noptimal diagonal preconditioner. We focus on minimizing two different notions\nof condition number: the classical, worst-case type, $\\kappa$-condition number,\nand the more averaging motivated $\\omega$-condition number. We provide affine\nbased pseudoconvex reformulations of both optimization problems. The advantage\nof our formulations is that the gradient of the objective is inexpensive to\ncompute and the optimization variable is just an $n\\times 1$ vector. We also\nprovide elegant characterizations of the optimality conditions of both\nproblems.\n  We develop a competitive subgradient method, with convergence guarantees, for\n$\\kappa$-optimal diagonal preconditioning that scales much better and is more\nefficient than existing SDP-based approaches. We also show that the\npreconditioners found by our subgradient method leads to better PCG performance\nfor solving linear systems than other approaches. Finally, we show the\ninteresting phenomenon that we can apply the $\\omega$-optimal preconditioner to\nthe exact $\\kappa$-optimally diagonally preconditioned matrix $A$ and get\nconsistent, significantly improved convergence results for PCG methods.", "published": "2025-09-27 18:16:21", "link": "http://arxiv.org/abs/2509.23439v1", "categories": ["math.OC", "cs.LG", "cs.NA", "math.NA", "15A12, 65F35, 49J52, 49K10, 90C32, 90C26"], "primary_category": "math.OC"}
{"title": "An Accelerated Newton-GMRES Method for Multilinear PageRank", "abstract": "Modeling complex multiway relationships in large-scale networks is becoming\nmore and more challenging in data science. The multilinear PageRank problem,\narising naturally in the study of higher-order Markov chains, is a powerful\nframework for capturing such interactions, with applications in web ranking,\nrecommendation systems, and social network analysis. It extends the classical\nGoogle PageRank model to a tensor-based formulation, leading to a nonlinear\nsystem that captures multi-way dependencies between states. Newton-based\nmethods can achieve local quadratic convergence for this problem, but they\nrequire solving a large linear system at each iteration, which becomes too\ncostly for large-scale applications. To address this challenge, we present an\naccelerated Newton-GMRES method that leverages Krylov subspace techniques to\napproximate the Newton step without explicitly forming the large Jacobian\nmatrix. We further employ vector extrapolation methods, including Minimal\nPolynomial Extrapolation (MPE), Reduced Rank Extrapolation (RRE), and Anderson\nAcceleration (AA), to improve the convergence rate and enhance numerical\nstability. Extensive experiments on synthetic and real-world data demonstrate\nthat the proposed approach significantly outperforms classical Newton-based\nsolvers in terms of efficiency, robustness, and scalability.", "published": "2025-09-27 15:45:57", "link": "http://arxiv.org/abs/2509.23374v1", "categories": ["math.NA", "cs.LG", "cs.NA"], "primary_category": "math.NA"}
{"title": "Deep Learning for Subspace Regression", "abstract": "It is often possible to perform reduced order modelling by specifying linear\nsubspace which accurately captures the dynamics of the system. This approach\nbecomes especially appealing when linear subspace explicitly depends on\nparameters of the problem. A practical way to apply such a scheme is to compute\nsubspaces for a selected set of parameters in the computationally demanding\noffline stage and in the online stage approximate subspace for unknown\nparameters by interpolation. For realistic problems the space of parameters is\nhigh dimensional, which renders classical interpolation strategies infeasible\nor unreliable. We propose to relax the interpolation problem to regression,\nintroduce several loss functions suitable for subspace data, and use a neural\nnetwork as an approximation to high-dimensional target function. To further\nsimplify a learning problem we introduce redundancy: in place of predicting\nsubspace of a given dimension we predict larger subspace. We show theoretically\nthat this strategy decreases the complexity of the mapping for elliptic\neigenproblems with constant coefficients and makes the mapping smoother for\ngeneral smooth function on the Grassmann manifold. Empirical results also show\nthat accuracy significantly improves when larger-than-needed subspaces are\npredicted. With the set of numerical illustrations we demonstrate that subspace\nregression can be useful for a range of tasks including parametric\neigenproblems, deflation techniques, relaxation methods, optimal control and\nsolution of parametric partial differential equations.", "published": "2025-09-27 10:56:03", "link": "http://arxiv.org/abs/2509.23249v1", "categories": ["cs.LG", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "A Besov-based integration-by-parts method for the incompressible Navier-Stokes equations", "abstract": "This note introduces a novel numerical analysis framework for the\nincompressible Navier-Stokes equations based on Besov spaces. The key\ncontribution of this note is to establish the stability and convergence of a\nsemi-implicit time-stepping scheme by deriving precise error estimates in the\n$B^0_{\\infty,1}$ and $B^0_{\\infty,2}$ spaces. Another contribution of our\nanalysis is the detailed treatment of the $B^0_{\\infty,2}$ case, where a\ncrucial integration-by-parts technique is employed to adeptly handle the\nnonlinear advection term. This technique allows for a refined estimate that\neffectively transfers derivatives onto the test functions, mitigating the\ninherent analytical challenges posed by the low regularity of these spaces. Our\nresults provide sharper, more localized error bounds than in classical Sobolev\nspaces, directly linking the scheme's convergence to the critical regularity of\nthe continuous solution. This work underscores the advantage of Besov spaces\nfor the numerical analysis of nonlinear fluid PDEs.", "published": "2025-09-27 08:51:24", "link": "http://arxiv.org/abs/2509.23192v1", "categories": ["math.NA", "cs.NA", "math.AP", "35Q30, 76D05, 65M15"], "primary_category": "math.NA"}
{"title": "On the rotating nonlinear Klein-Gordon equation with multiscale effects: structure-preserving methods and applications to vortex dynamics", "abstract": "We study numerical methods for the rotating nonlinear Klein-Gordon (RKG)\nequation, a fundamental model in relativistic quantum physics, which exhibits\nhighly oscillatory multiscale behavior due to the presence of a small parameter\n{\\epsilon}. The RKG equation models rotating galaxies under the Minkowski\nmetric and also provides an effective description of phenomena such as cosmic\nsuperfluids. This work focuses on the development and rigorous analysis of\nstructure-preserving Galerkin finite element methods (FEMs) for the RKG\nequation. A central challenge is that the rotational terms prevent traditional\nnonconforming FEMs from simultaneously conserving energy and charge. By\nemploying a conservation-adjusting technique, we construct a consistent\nstructure-preserving algorithm applicable to both conforming and nonconforming\nFEMs. Moreover, we provide a comprehensive convergence analysis, establishing\nunconditional optimal and high-order accuracy error estimates. These\ntheoretical results are further validated through extensive numerical\nexperiments, which demonstrate the accuracy, efficiency, and robustness of the\nstructure-preserving schemes. Finally, simulations of vortex dynamics, ranging\nfrom the relativistic to the nonrelativistic regimes, are presented to\nillustrate vortex creation, relativistic effects on bound states, and\ninteractions of vortex pairs.", "published": "2025-09-27 08:47:47", "link": "http://arxiv.org/abs/2509.23191v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A FFT-based GMRES for fast solving of Poisson equation in concatenated geometry", "abstract": "Fast Fourier Transform (FFT)-based solvers for the Poisson equation are\nhighly efficient, exhibiting $O(N\\log N)$ computational complexity and\nexcellent parallelism. However, their application is typically restricted to\nsimple, regular geometries due to the separability requirement of the\nunderlying discrete operators. This paper introduces a novel domain\ndecomposition method that extends the applicability of FFT-based solvers to\ncomplex composite domains geometries constructed from multiple sub-regions. The\nmethod transforms the global problem into a system of sub-problems coupled\nthrough Schur complements at the interfaces. A key challenge is that the Schur\ncomplement disrupts the matrix structure required for direct FFT-based\ninversion. To overcome this, we develop a FFT-based preconditioner to\naccelerate the Generalized Minimal Residual (GMRES) method for the interface\nsystem. The central innovation is a novel preconditioner based on the inverse\nof the block operator without the Schur complement, which can be applied\nefficiently using the FFT-based solver. The resulting preconditioned iteration\nretains an optimal complexity for each step. Numerical experiments on a\ncross-shaped domain demonstrate that the proposed solver achieves the expected\nsecond-order accuracy of the underlying finite difference scheme. Furthermore,\nit exhibits significantly improved computational performance compared to a\nclassic sparse GMRES solver based on Eigen libeary. For a problem with $10^5$\ngrid points, our method achieves a speedup of over 40 times.", "published": "2025-09-27 08:16:28", "link": "http://arxiv.org/abs/2509.23180v1", "categories": ["math.NA", "cs.NA", "physics.comp-ph"], "primary_category": "math.NA"}
{"title": "Dynamical feedback control with operator learning for the Vlasov-Poisson system", "abstract": "To meet the demands of instantaneous control of instabilities over long time\nhorizons in plasma fusion, we design a dynamic feedback control strategy for\nthe Vlasov-Poisson system by constructing an operator that maps state\nperturbations to an external control field. In the first part of the paper, we\npropose learning such an operator using a neural network. Inspired by optimal\ncontrol theory for linearized dynamics, we introduce a low-rank neural operator\narchitecture and train it via adjoint state method. The resulting controller is\neffective at suppressing instabilities well beyond the training time horizon.\nTo generalize control across varying initial data, we further introduce a novel\ncancellation-based control strategy that removes the destabilizing component of\nthe electric field. This approach naturally defines an operator without\nrequiring any training, ensures perturbation decay over infinite time, and\ndemonstrates strong robustness under noisy feedback. Numerical experiments\nconfirm the effectiveness of the method in both one- and multidimensional\nsettings.", "published": "2025-09-27 02:35:50", "link": "http://arxiv.org/abs/2509.23063v1", "categories": ["math.NA", "cs.NA", "35Q83, 49J20, 49M41, 93C20, 65K10"], "primary_category": "math.NA"}
{"title": "Continuous-Time Reinforcement Learning for Asset-Liability Management", "abstract": "This paper proposes a novel approach for Asset-Liability Management (ALM) by\nemploying continuous-time Reinforcement Learning (RL) with a linear-quadratic\n(LQ) formulation that incorporates both interim and terminal objectives. We\ndevelop a model-free, policy gradient-based soft actor-critic algorithm\ntailored to ALM for dynamically synchronizing assets and liabilities. To ensure\nan effective balance between exploration and exploitation with minimal tuning,\nwe introduce adaptive exploration for the actor and scheduled exploration for\nthe critic. Our empirical study evaluates this approach against two enhanced\ntraditional financial strategies, a model-based continuous-time RL method, and\nthree state-of-the-art RL algorithms. Evaluated across 200 randomized market\nscenarios, our method achieves higher average rewards than all alternative\nstrategies, with rapid initial gains and sustained superior performance. The\noutperformance stems not from complex neural networks or improved parameter\nestimation, but from directly learning the optimal ALM strategy without\nlearning the environment.", "published": "2025-09-27 12:36:51", "link": "http://arxiv.org/abs/2509.23280v1", "categories": ["cs.LG", "cs.AI", "math.OC", "q-fin.MF"], "primary_category": "cs.LG"}
{"title": "The Price of Liquidity: Implied Volatility of Automated Market Maker Fees", "abstract": "An automated market maker (AMM) provides a method for creating a\ndecentralized exchange on the blockchain. For this purpose, individual\ninvestors lend liquidity to the AMM pool in exchange for a stream of fees\nearned from its operations as a market maker. Within this work, we reinterpret\nthe loss-versus-rebalancing as the implied fee stream generated by an AMM so\nthat a risk-neutral investor is indifferent in the decision of providing\nliquidity. With this implied fee structure, we propose a novel\nfixed-for-floating swap on the fees generated by an AMM in order to quote the\nimplied volatilities and implied correlations of digital assets. We apply this\ntheory to realized fees in different markets to empirically validate the\nrelevance of the deduced fee-based volatility.", "published": "2025-09-27 10:01:53", "link": "http://arxiv.org/abs/2509.23222v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "Learning single index model with gradient descent: spectral initialization and precise asymptotics", "abstract": "Non-convex optimization plays a central role in many statistics and machine\nlearning problems. Despite the landscape irregularities for general non-convex\nfunctions, some recent work showed that for many learning problems with random\ndata and large enough sample size, there exists a region around the true signal\nwith benign landscape. Motivated by this observation, a widely used strategy is\na two-stage algorithm, where we first apply a spectral initialization to plunge\ninto the region, and then run gradient descent for further refinement. While\nthis two-stage algorithm has been extensively analyzed for many non-convex\nproblems, the precise distributional property of both its transient and\nlong-time behavior remains to be understood. In this work, we study this\ntwo-stage algorithm in the context of single index models under the\nproportional asymptotics regime. We derive a set of dynamical mean field\nequations, which describe the precise behavior of the trajectory of spectral\ninitialized gradient descent in the large system limit. We further show that\nwhen the spectral initialization successfully lands in a region of benign\nlandscape, the above equation system is asymptotically time translation\ninvariant and exponential converging, and thus admits a set of long-time fixed\npoints that represents the mean field characterization of the limiting point of\nthe gradient descent dynamic. As a proof of concept, we demonstrate our general\ntheory in the example of regularized Wirtinger flow for phase retrieval.", "published": "2025-09-27 23:27:24", "link": "http://arxiv.org/abs/2509.23527v1", "categories": ["math.ST", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "Revisiting Multivariate Time Series Forecasting with Missing Values", "abstract": "Missing values are common in real-world time series, and multivariate time\nseries forecasting with missing values (MTSF-M) has become a crucial area of\nresearch for ensuring reliable predictions. To address the challenge of missing\ndata, current approaches have developed an imputation-then-prediction framework\nthat uses imputation modules to fill in missing values, followed by forecasting\non the imputed data. However, this framework overlooks a critical issue: there\nis no ground truth for the missing values, making the imputation process\nsusceptible to errors that can degrade prediction accuracy. In this paper, we\nconduct a systematic empirical study and reveal that imputation without direct\nsupervision can corrupt the underlying data distribution and actively degrade\nprediction accuracy. To address this, we propose a paradigm shift that moves\naway from imputation and directly predicts from the partially observed time\nseries. We introduce Consistency-Regularized Information Bottleneck (CRIB), a\nnovel framework built on the Information Bottleneck principle. CRIB combines a\nunified-variate attention mechanism with a consistency regularization scheme to\nlearn robust representations that filter out noise introduced by missing values\nwhile preserving essential predictive signals. Comprehensive experiments on\nfour real-world datasets demonstrate the effectiveness of CRIB, which predicts\naccurately even under high missing rates. Our code is available in\nhttps://github.com/Muyiiiii/CRIB.", "published": "2025-09-27 20:57:48", "link": "http://arxiv.org/abs/2509.23494v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Statistical Learning Guarantees for Group-Invariant Barron Functions", "abstract": "We investigate the generalization error of group-invariant neural networks\nwithin the Barron framework. Our analysis shows that incorporating\ngroup-invariant structures introduces a group-dependent factor\n$\\delta_{G,\\Gamma,\\sigma} \\le 1$ into the approximation rate. When this factor\nis small, group invariance yields substantial improvements in approximation\naccuracy. On the estimation side, we establish that the Rademacher complexity\nof the group-invariant class is no larger than that of the non-invariant\ncounterpart, implying that the estimation error remains unaffected by the\nincorporation of symmetry. Consequently, the generalization error can improve\nsignificantly when learning functions with inherent group symmetries. We\nfurther provide illustrative examples demonstrating both favorable cases, where\n$\\delta_{G,\\Gamma,\\sigma}\\approx |G|^{-1}$, and unfavorable ones, where\n$\\delta_{G,\\Gamma,\\sigma}\\approx 1$. Overall, our results offer a rigorous\ntheoretical foundation showing that encoding group-invariant structures in\nneural networks leads to clear statistical advantages for symmetric target\nfunctions.", "published": "2025-09-27 19:52:14", "link": "http://arxiv.org/abs/2509.23474v1", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Data-Efficient Training by Evolved Sampling", "abstract": "Data selection is designed to accelerate learning with preserved performance.\nTo achieve this, a fundamental thought is to identify informative data samples\nwith significant contributions to the training. In this work, we propose\n\\textbf{Evolved Sampling} (\\textbf{ES}), a simple yet effective framework for\n\\emph{dynamic} sampling along the training process. This method conducts \\em\nbatch \\em level data selection based on the dynamics of losses and augmented\n\\emph{loss differences}, which enables flexible \\emph{frequency tuning}, and\nhence significantly reduces the back propagation time with maintained model\nperformance. Due to its conciseness, ES is also readily extensible to\nincorporate \\em set \\em level data selection (to form ES with pruning,\n\\textbf{ESWP}) for further accelerations. As a plug-and-play framework, ES(WP)\nconsistently achieves lossless training accelerations across various\npre-training and post-training tasks, saving up to nearly 45\\% wall-clock time.\nOur results motivate further investigations on the data efficiency aspect of\nmodern large-scale machine learning.", "published": "2025-09-27 19:19:16", "link": "http://arxiv.org/abs/2509.23461v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Better Hessians Matter: Studying the Impact of Curvature Approximations in Influence Functions", "abstract": "Influence functions offer a principled way to trace model predictions back to\ntraining data, but their use in deep learning is hampered by the need to invert\na large, ill-conditioned Hessian matrix. Approximations such as Generalised\nGauss-Newton (GGN) and Kronecker-Factored Approximate Curvature (K-FAC) have\nbeen proposed to make influence computation tractable, yet it remains unclear\nhow the departure from exactness impacts data attribution performance.\nCritically, given the restricted regime in which influence functions are\nderived, it is not necessarily clear better Hessian approximations should even\nlead to better data attribution performance. In this paper, we investigate the\neffect of Hessian approximation quality on influence-function attributions in a\ncontrolled classification setting. Our experiments show that better Hessian\napproximations consistently yield better influence score quality, offering\njustification for recent research efforts towards that end. We further\ndecompose the approximation steps for recent Hessian approximation methods and\nevaluate each step's influence on attribution accuracy. Notably, the mismatch\nbetween K-FAC eigenvalues and GGN/EK-FAC eigenvalues accounts for the majority\nof the error and influence loss. These findings highlight which approximations\nare most critical, guiding future efforts to balance computational tractability\nand attribution accuracy.", "published": "2025-09-27 18:12:35", "link": "http://arxiv.org/abs/2509.23437v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Flow Matching for Robust Simulation-Based Inference under Model Misspecification", "abstract": "Simulation-based inference (SBI) is transforming experimental sciences by\nenabling parameter estimation in complex non-linear models from simulated data.\nA persistent challenge, however, is model misspecification: simulators are only\napproximations of reality, and mismatches between simulated and real data can\nyield biased or overconfident posteriors. We address this issue by introducing\nFlow Matching Corrected Posterior Estimation (FMCPE), a framework that\nleverages the flow matching paradigm to refine simulation-trained posterior\nestimators using a small set of real calibration samples. Our approach proceeds\nin two stages: first, a posterior approximator is trained on abundant simulated\ndata; second, flow matching transports its predictions toward the true\nposterior supported by real observations, without requiring explicit knowledge\nof the misspecification. This design enables FMCPE to combine the scalability\nof SBI with robustness to distributional shift. Across synthetic benchmarks and\nreal-world datasets, we show that our proposal consistently mitigates the\neffects of misspecification, delivering improved inference accuracy and\nuncertainty calibration compared to standard SBI baselines, while remaining\ncomputationally efficient.", "published": "2025-09-27 16:10:53", "link": "http://arxiv.org/abs/2509.23385v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Landing with the Score: Riemannian Optimization through Denoising", "abstract": "Under the data manifold hypothesis, high-dimensional data are concentrated\nnear a low-dimensional manifold. We study the problem of Riemannian\noptimization over such manifolds when they are given only implicitly through\nthe data distribution, and the standard manifold operations required by\nclassical algorithms are unavailable. This formulation captures a broad class\nof data-driven design problems that are central to modern generative AI. Our\nkey idea is to introduce a link function that connects the data distribution to\nthe geometric operations needed for optimization. We show that this function\nenables the recovery of essential manifold operations, such as retraction and\nRiemannian gradient computation. Moreover, we establish a direct connection\nbetween our construction and the score function in diffusion models of the data\ndistribution. This connection allows us to leverage well-studied\nparameterizations, efficient training procedures, and even pretrained score\nnetworks from the diffusion model literature to perform optimization. Building\non this foundation, we propose two efficient inference-time algorithms --\nDenoising Landing Flow (DLF) and Denoising Riemannian Gradient Descent (DRGD)\n-- and provide theoretical guarantees for both feasibility (approximate\nmanifold adherence) and optimality (small Riemannian gradient norm). Finally,\nwe demonstrate the effectiveness of our approach on finite-horizon reference\ntracking tasks in data-driven control, highlighting its potential for practical\ngenerative and design applications.", "published": "2025-09-27 15:10:54", "link": "http://arxiv.org/abs/2509.23357v1", "categories": ["cs.LG", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Generative Model for Controllable Feature Heterophily in Graphs", "abstract": "We introduce a principled generative framework for graph signals that enables\nexplicit control of feature heterophily, a key property underlying the\neffectiveness of graph learning methods. Our model combines a Lipschitz\ngraphon-based random graph generator with Gaussian node features filtered\nthrough a smooth spectral function of the rescaled Laplacian. We establish new\ntheoretical guarantees: (i) a concentration result for the empirical\nheterophily score; and (ii) almost-sure convergence of the feature heterophily\nmeasure to a deterministic functional of the graphon degree profile, based on a\ngraphon-limit law for polynomial averages of Laplacian eigenvalues. These\nresults elucidate how the interplay between the graphon and the filter governs\nthe limiting level of feature heterophily, providing a tunable mechanism for\ndata modeling and generation. We validate the theory through experiments\ndemonstrating precise control of homophily across graph families and spectral\nfilters.", "published": "2025-09-27 10:31:19", "link": "http://arxiv.org/abs/2509.23230v1", "categories": ["stat.ML", "cs.LG", "eess.SP"], "primary_category": "stat.ML"}
{"title": "Dense associative memory on the Bures-Wasserstein space", "abstract": "Dense associative memories (DAMs) store and retrieve patterns via\nenergy-functional fixed points, but existing models are limited to vector\nrepresentations. We extend DAMs to probability distributions equipped with the\n2-Wasserstein distance, focusing mainly on the Bures-Wasserstein class of\nGaussian densities. Our framework defines a log-sum-exp energy over stored\ndistributions and a retrieval dynamics aggregating optimal transport maps in a\nGibbs-weighted manner. Stationary points correspond to self-consistent\nWasserstein barycenters, generalizing classical DAM fixed points. We prove\nexponential storage capacity, provide quantitative retrieval guarantees under\nWasserstein perturbations, and validate the model on synthetic and real-world\ndistributional tasks. This work elevates associative memory from vectors to\nfull distributions, bridging classical DAMs with modern generative modeling and\nenabling distributional storage and retrieval in memory-augmented learning.", "published": "2025-09-27 07:17:02", "link": "http://arxiv.org/abs/2509.23162v1", "categories": ["cs.LG", "cs.AI", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Conditional Risk Minimization with Side Information: A Tractable, Universal Optimal Transport Framework", "abstract": "Conditional risk minimization arises in high-stakes decisions where risk must\nbe assessed in light of side information, such as stressed economic conditions,\nspecific customer profiles, or other contextual covariates. Constructing\nreliable conditional distributions from limited data is notoriously difficult,\nmotivating a series of optimal-transport-based proposals that address this\nuncertainty in a distributionally robust manner. Yet these approaches remain\nfragmented, each constrained by its own limitations: some rely on point\nestimates or restrictive structural assumptions, others apply only to narrow\nclasses of risk measures, and their structural connections are unclear. We\nintroduce a universal framework for distributionally robust conditional risk\nminimization, built on a novel union-ball formulation in optimal transport.\nThis framework offers three key advantages: interpretability, by subsuming\nexisting methods as special cases and revealing their deep structural links;\ntractability, by yielding convex reformulations for virtually all major risk\nfunctionals studied in the literature; and scalability, by supporting\ncutting-plane algorithms for large-scale conditional risk problems.\nApplications to portfolio optimization with rank-dependent expected utility\nhighlight the practical effectiveness of the framework, with conditional models\nconverging to optimal solutions where unconditional ones clearly do not.", "published": "2025-09-27 05:22:53", "link": "http://arxiv.org/abs/2509.23128v1", "categories": ["stat.ML", "cs.LG", "math.OC", "q-fin.PM", "q-fin.RM"], "primary_category": "stat.ML"}
{"title": "Statistical Inference for Gradient Boosting Regression", "abstract": "Gradient boosting is widely popular due to its flexibility and predictive\naccuracy. However, statistical inference and uncertainty quantification for\ngradient boosting remain challenging and under-explored. We propose a unified\nframework for statistical inference in gradient boosting regression. Our\nframework integrates dropout or parallel training with a recently proposed\nregularization procedure that allows for a central limit theorem (CLT) for\nboosting. With these enhancements, we surprisingly find that increasing the\ndropout rate and the number of trees grown in parallel at each iteration\nsubstantially enhances signal recovery and overall performance. Our resulting\nalgorithms enjoy similar CLTs, which we use to construct built-in confidence\nintervals, prediction intervals, and rigorous hypothesis tests for assessing\nvariable importance. Numerical experiments demonstrate that our algorithms\nperform well, interpolate between regularized boosting and random forests, and\nconfirm the validity of their built-in statistical inference procedures.", "published": "2025-09-27 05:16:10", "link": "http://arxiv.org/abs/2509.23127v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Sensitivity Analysis for Diffusion Models", "abstract": "Training a diffusion model approximates a map from a data distribution $\\rho$\nto the optimal score function $s_t$ for that distribution. Can we differentiate\nthis map? If we could, then we could predict how the score, and ultimately the\nmodel's samples, would change under small perturbations to the training set\nbefore committing to costly retraining. We give a closed-form procedure for\ncomputing this map's directional derivatives, relying only on black-box access\nto a pre-trained score model and its derivatives with respect to its inputs. We\nextend this result to estimate the sensitivity of a diffusion model's samples\nto additive perturbations of its target measure, with runtime comparable to\nsampling from a diffusion model and computing log-likelihoods along the sample\npath. Our method is robust to numerical and approximation error, and the\nresulting sensitivities correlate with changes in an image diffusion model's\nsamples after retraining and fine-tuning.", "published": "2025-09-27 03:59:00", "link": "http://arxiv.org/abs/2509.23092v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Sparse Deep Additive Model with Interactions: Enhancing Interpretability and Predictability", "abstract": "Recent advances in deep learning highlight the need for personalized models\nthat can learn from small or moderate samples, handle high dimensional\nfeatures, and remain interpretable. To address this challenge, we propose the\nSparse Deep Additive Model with Interactions (SDAMI), a framework that combines\nsparsity driven feature selection with deep subnetworks for flexible function\napproximation. Unlike conventional deep learning models, which often function\nas black boxes, SDAMI explicitly disentangles main effects and interaction\neffects to enhance interpretability. At the same time, its deep additive\nstructure achieves higher predictive accuracy than classical additive models.\nCentral to SDAMI is the concept of an Effect Footprint, which assumes that\nhigher order interactions project marginally onto main effects. Guided by this\nprinciple, SDAMI adopts a two stage strategy: first, identify strong main\neffects that implicitly carry information about important interactions. second,\nexploit this information through structured regularization such as group lasso\nto distinguish genuine main effects from interaction effects. For each selected\nmain effect, SDAMI constructs a dedicated subnetwork, enabling nonlinear\nfunction approximation while preserving interpretability and providing a\nstructured foundation for modeling interactions. Extensive simulations with\ncomparisons confirm SDAMI$'$s ability to recover effect structures across\ndiverse scenarios, while applications in reliability analysis, neuroscience,\nand medical diagnostics further demonstrate its versatility in addressing\nreal-world high-dimensional modeling challenges.", "published": "2025-09-27 02:44:57", "link": "http://arxiv.org/abs/2509.23068v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "AudioFuse: Unified Spectral-Temporal Learning via a Hybrid ViT-1D CNN Architecture for Robust Phonocardiogram Classification", "abstract": "Biomedical audio signals, such as phonocardiograms (PCG), are inherently\nrhythmic and contain diagnostic information in both their spectral (tonal) and\ntemporal domains. Standard 2D spectrograms provide rich spectral features but\ncompromise the phase information and temporal precision of the 1D waveform. We\npropose AudioFuse, an architecture that simultaneously learns from both\ncomplementary representations to classify PCGs. To mitigate the overfitting\nrisk common in fusion models, we integrate a custom, wide-and-shallow Vision\nTransformer (ViT) for spectrograms with a shallow 1D CNN for raw waveforms. On\nthe PhysioNet 2016 dataset, AudioFuse achieves a state-of-the-art competitive\nROC-AUC of 0.8608 when trained from scratch, outperforming its spectrogram\n(0.8066) and waveform (0.8223) baselines. Moreover, it demonstrates superior\nrobustness to domain shift on the challenging PASCAL dataset, maintaining an\nROC-AUC of 0.7181 while the spectrogram baseline collapses (0.4873). Fusing\ncomplementary representations thus provides a strong inductive bias, enabling\nthe creation of efficient, generalizable classifiers without requiring\nlarge-scale pre-training.", "published": "2025-09-27 18:52:50", "link": "http://arxiv.org/abs/2509.23454v1", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "AudioRole: An Audio Dataset for Character Role-Playing in Large Language Models", "abstract": "The creation of high-quality multimodal datasets remains fundamental for\nadvancing role-playing capabilities in large language models (LLMs). While\nexisting works predominantly focus on text-based persona simulation, Audio\nRole-Playing (ARP) presents unique challenges due to the need for synchronized\nalignment of semantic content and vocal characteristics. To address this gap,\nwe propose AudioRole, a meticulously curated dataset from 13 TV series spanning\n1K+ hours with 1M+ character-grounded dialogues, providing synchronized\naudio-text pairs annotated with speaker identities and contextual metadata. In\naddition, to demonstrate the effectiveness of the dataset, we introduced\nARP-Eval, a dual-aspect evaluation framework that assesses both response\nquality and role fidelity. Empirical validation showing GLM-4-Voice trained on\nAudioRole (which we called ARP-Model) achieve an average Acoustic\nPersonalization score of 0.31, significantly outperforming the original\nGLM-4-voice and the more powerful model MiniCPM-O-2.6, which specifically\nsupports role-playing in one-shot scenarios. The ARP-Model also achieves a\nContent Personalization score of 0.36, surpassing the untrained original model\nby about 38% and maintaining the same level as MiniCPM-O-2.6.\n  AudioRole features dialogues from over 115 main characters, 6 trained\nARP-Models that role-play different characters, and evaluation protocols.\nTogether, they provide an essential resource for advancing audio-grounded\nrole-playing research.", "published": "2025-09-27 18:08:51", "link": "http://arxiv.org/abs/2509.23435v1", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "AI-Assisted Music Production: A User Study on Text-to-Music Models", "abstract": "Text-to-music models have revolutionized the creative landscape, offering new\npossibilities for music creation. Yet their integration into musicians\nworkflows remains underexplored. This paper presents a case study on how TTM\nmodels impact music production, based on a user study of their effect on\nproducers creative workflows. Participants produce tracks using a custom tool\ncombining TTM and source separation models. Semi-structured interviews and\nthematic analysis reveal key challenges, opportunities, and ethical\nconsiderations. The findings offer insights into the transformative potential\nof TTMs in music production, as well as challenges in their real-world\nintegration.", "published": "2025-09-27 15:23:40", "link": "http://arxiv.org/abs/2509.23364v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Emotional Styles Hide in Deep Speaker Embeddings: Disentangle Deep Speaker Embeddings for Speaker Clustering", "abstract": "Speaker clustering is the task of identifying the unique speakers in a set of\naudio recordings (each belonging to exactly one speaker) without knowing who\nand how many speakers are present in the entire data, which is essential for\nspeaker diarization processes. Recently, off-the-shelf deep speaker embedding\nmodels have been leveraged to capture speaker characteristics. However,\nspeeches containing emotional expressions pose significant challenges, often\naffecting the accuracy of speaker embeddings and leading to a decline in\nspeaker clustering performance. To tackle this problem, we propose DTG-VAE, a\nnovel disentanglement method that enhances clustering within a Variational\nAutoencoder (VAE) framework. This study reveals a direct link between emotional\nstates and the effectiveness of deep speaker embeddings. As demonstrated in our\nexperiments, DTG-VAE extracts more robust speaker embeddings and significantly\nenhances speaker clustering performance.", "published": "2025-09-27 15:11:48", "link": "http://arxiv.org/abs/2509.23358v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "MeanFlowSE: One-Step Generative Speech Enhancement via MeanFlow", "abstract": "Speech enhancement (SE) recovers clean speech from noisy signals and is vital\nfor applications such as telecommunications and automatic speech recognition\n(ASR). While generative approaches achieve strong perceptual quality, they\noften rely on multi-step sampling (diffusion/flow-matching) or large language\nmodels, limiting real-time deployment. To mitigate these constraints, we\npresent MeanFlowSE, a one-step generative SE framework. It adopts MeanFlow to\npredict an average-velocity field for one-step latent refinement and conditions\nthe model on self-supervised learning (SSL) representations rather than VAE\nlatents. This design accelerates inference and provides robust\nacoustic-semantic guidance during training. In the Interspeech 2020 DNS\nChallenge blind test set and simulated test set, MeanFlowSE attains\nstate-of-the-art (SOTA) level perceptual quality and competitive\nintelligibility while significantly lowering both real-time factor (RTF) and\nmodel size compared with recent generative competitors, making it suitable for\npractical use. The code will be released upon publication at\nhttps://github.com/Hello3orld/MeanFlowSE.", "published": "2025-09-27 13:24:24", "link": "http://arxiv.org/abs/2509.23299v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "WavJEPA: Semantic learning unlocks robust audio foundation models for raw waveforms", "abstract": "Learning audio representations from raw waveforms overcomes key limitations\nof spectrogram-based audio representation learning, such as the long latency of\nspectrogram computation and the loss of phase information. Yet, while\nself-supervised speech representation learning from raw waveforms has been\nremarkably successful, these approaches have not achieved similar feats for\ngeneral-purpose audio representation learning from waveforms. Here, we propose\nWavJEPA, a waveform-based version of the Joint-Embedding Predictive\nArchitecture. WavJEPA leverages high-level semantic representation learning to\ntackle the shortcomings of representation learning at the speech unit or token\nlevel. We show that this approach substantially outperforms state-of-the-art\ntime-domain audio foundation models across a wide variety of downstream\nbenchmark tasks, while requiring considerably fewer computational resources.\nAdditionally, to overcome the performance drop that time-domain models\ntypically exhibit in noisy and reverberant real-world acoustic environments, we\npresent WavJEPA-Nat. WavJEPA-Nat is a multi-channel extension of the WavJEPA\narchitecture trained on simulated naturalistic scenes. We find that WavJEPA-Nat\nis highly robust to reverberation and noise. These results highlight the\nfeasibility and computational efficiency of general-purpose audio\nrepresentation learning from raw waveforms, showcasing the potential for\nlow-latency, robust time-domain audio foundation models for real-world\napplications.", "published": "2025-09-27 10:38:14", "link": "http://arxiv.org/abs/2509.23238v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "BFA: Real-time Multilingual Text-to-speech Forced Alignment", "abstract": "We present Bournemouth Forced Aligner (BFA), a system that combines a\nContextless Universal Phoneme Encoder (CUPE) with a connectionist temporal\nclassification (CTC)based decoder. BFA introduces explicit modelling of\ninter-phoneme gaps and silences and hierarchical decoding strategies, enabling\nfine-grained boundary prediction. Evaluations on TIMIT and Buckeye corpora show\nthat BFA achieves competitive recall relative to Montreal Forced Aligner at\nrelaxed tolerance levels, while predicting both onset and offset boundaries for\nricher temporal structure. BFA processes speech up to 240x faster than MFA,\nenabling faster than real-time alignment. This combination of speed and\nsilence-aware alignment opens opportunities for interactive speech applications\npreviously constrained by slow aligners.", "published": "2025-09-27 06:23:11", "link": "http://arxiv.org/abs/2509.23147v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "EEG-Based Framework for Reflexive and Perceptual Assessment in CLIS: Preliminary Study in Healthy Volunteers", "abstract": "Despite the general assumption that completely locked-in state (CLIS)\npatients remain conscious and aware of their environment, the effectiveness of\nbrain-computer interfaces (BCIs) in facilitating communication has been\nlimited, as reported both in the literature and in our own findings. This\nlimitation is likely attributable to impairments in executive functions,\nworking memory, and vigilance, which appear to hinder the establishment of\nreliable BCI-based communication. The main goal of this research is to develop\na neurophysiological report designed to support the evaluation of the cognitive\nstate of these individuals and determine their ability to interact with BCIs.\nTo achieve this, we designed a set of paradigms to assess CLIS patients at the\nreflexive and perceptual levels, based on neural responses associated with\nsensory and perceptual processing, including Mismatch Negativity (MMN), Steady\nState Auditory Evoked Potential (SSAEP), and Steady State Visual Evoked\nPotential (SSVEP). Pilot testing with five healthy participants demonstrates\nthe feasibility of generating a neurophysiological report for cognitive\nassessment at both levels.", "published": "2025-09-27 23:03:46", "link": "http://arxiv.org/abs/2509.23524v1", "categories": ["q-bio.NC", "eess.SP"], "primary_category": "q-bio.NC"}
{"title": "Theoretical framework of passive ME antenna arrays enabling in-vivo monitoring: A pathway to smart implants", "abstract": "A new brain-computer interface (BCI) technology, deployed through minimally\ninvasive surgery, is changing the way we think about treating severe\nneurological conditions. The central idea is to place a device called Stentrode\nin the brain's vasculature, which enables neuromodulation and helps patients\nregain the ability to communicate. However, in such devices, the battery and\nelectronics are wired and could introduce damage or implant malfunction. In\nthese cases, a Stentrode integrated with magnetoelectric (ME) antennas could be\nof great interest. ME antennas offer significant advantages over traditional\nantennas, leveraging acoustic resonance rather than electromagnetic resonance\nto achieve a size reduction of up to five orders of magnitude. In addition to\ntheir compactness and immunity to ground-plane interference, ME antennas could\nbe adopted for use in vascular implants, such as coronary stents, potentially\nenabling minimally invasive monitoring and communication. Despite these\nadvantages, a single antenna embedded in the implant may be constrained by the\nlimited volume of magnetostrictive material, which could result in low output\ngain. To address this gain limitation, we propose using antenna arrays designed\nto produce constructive interference at a designated far-field point, ideally\nlocated outside the patient, to enhance signal transmission and receiving\ncapabilities. We develop a mathematical model to represent the antennas and\noptimize their spatial arrangement and phase synchronization. Simulations based\non this model demonstrate promising high-gain performance at the prescribed\nfar-field location through phase manipulation.", "published": "2025-09-27 22:42:39", "link": "http://arxiv.org/abs/2509.23520v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Eye-Tracking and BCI Integration for Assistive Communication in Locked-In Syndrome: Pilot Study with Healthy Participants", "abstract": "Patients with Amyotrophic Lateral Sclerosis (ALS) progressively lose\nvoluntary motor control, often leading to a Locked-In State (LIS), or in severe\ncases, a Completely Locked-in State (CLIS). Eye-tracking (ET) systems are\ncommon communication tools in early LIS but become ineffective as oculomotor\nfunction declines. EEG-based Brain-Computer Interfaces (BCIs) offer a\nnon-muscular communication alternative, but delayed adoption may reduce\nperformance due to diminished goal-directed thinking. This study presents a\npreliminary hybrid BCI framework combining ET and BCI to support a gradual\ntransition between modalities. A group of five healthy participants tested a\nmodified P300-based BCI. Gaze and EEG data were processed in real time, and an\nET-BCI fusion algorithm was proposed to enhance detection of user intention.\nResults indicate that combining both modalities may maintain high accuracy and\noffers insights on how to potentially improve communication continuity for\npatients transitioning from LIS to CLIS.", "published": "2025-09-27 22:33:12", "link": "http://arxiv.org/abs/2509.23518v1", "categories": ["cs.HC", "eess.SP"], "primary_category": "cs.HC"}
{"title": "HoloTrace: a Location Privacy Preservation Solution for mmWave MIMO-OFDM Systems", "abstract": "The technological innovation towards 6G cellular networks introduces\nunprecedented capabilities for user equipment (UE) localization, but it also\nraises serious concerns about physical layer location privacy. This paper\nintroduces HoloTrace, a signal-level privacy preservation framework that relies\non user-side spoofing of localization-relevant features to prevent the\nextraction of precise location information from the signals received by a base\nstation (BS) in a mmWave MIMO-OFDM system. Spoofing is performed by the user on\nlocation parameters such as angle of arrival (AoA), angle of departure (AoD),\nand time difference of arrival (TDoA). Without requiring any protocol\nmodification nor network-side support, our method strategically perturbs pilot\ntransmissions to prevent a BS from performing non-consensual UE localization.\nThe methodology allows the UE to spoof its position, keeping the precoder\nunchanged. We formulate spoofing as a unified rank-constrained projection\nproblem, and provide closed-form solutions under varying levels of channel\nstate information (CSI) at the UE, including scenarios with and without CSI\nknowledge. Simulation results confirm that the proposed approach enables the UE\nto deceive the BS, inducing significant localization errors, while the impact\non link capacity varies depending on the spoofed position. Our findings\nestablish HoloTrace as a practical and robust privacy-preserving solution for\nfuture 6G networks.", "published": "2025-09-27 18:26:30", "link": "http://arxiv.org/abs/2509.23444v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "S$^3$F-Net: A Multi-Modal Approach to Medical Image Classification via Spatial-Spectral Summarizer Fusion Network", "abstract": "Convolutional Neural Networks have become a cornerstone of medical image\nanalysis due to their proficiency in learning hierarchical spatial features.\nHowever, this focus on a single domain is inefficient at capturing global,\nholistic patterns and fails to explicitly model an image's frequency-domain\ncharacteristics. To address these challenges, we propose the Spatial-Spectral\nSummarizer Fusion Network (S$^3$F-Net), a dual-branch framework that learns\nfrom both spatial and spectral representations simultaneously. The S$^3$F-Net\nperforms a fusion of a deep spatial CNN with our proposed shallow spectral\nencoder, SpectraNet. SpectraNet features the proposed SpectralFilter layer,\nwhich leverages the Convolution Theorem by applying a bank of learnable filters\ndirectly to an image's full Fourier spectrum via a computation-efficient\nelement-wise multiplication. This allows the SpectralFilter layer to attain a\nglobal receptive field instantaneously, with its output being distilled by a\nlightweight summarizer network. We evaluate S$^3$F-Net across four medical\nimaging datasets spanning different modalities to validate its efficacy and\ngeneralizability. Our framework consistently and significantly outperforms its\nstrong spatial-only baseline in all cases, with accuracy improvements of up to\n5.13%. With a powerful Bilinear Fusion, S$^3$F-Net achieves a SOTA competitive\naccuracy of 98.76% on the BRISC2025 dataset. Concatenation Fusion performs\nbetter on the texture-dominant Chest X-Ray Pneumonia dataset, achieving 93.11%\naccuracy, surpassing many top-performing, much deeper models. Our\nexplainability analysis also reveals that the S$^3$F-Net learns to dynamically\nadjust its reliance on each branch based on the input pathology. These results\nverify that our dual-domain approach is a powerful and generalizable paradigm\nfor medical image analysis.", "published": "2025-09-27 18:18:39", "link": "http://arxiv.org/abs/2509.23442v1", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "eess.SP"], "primary_category": "eess.IV"}
{"title": "Dual-Function Beam Pattern Design for Multi-Target ISAC Systems: A Decoupled Approach", "abstract": "We investigate the beampattern design problem for mono-static multi-user (MU)\nmulti-point-target integrated sensing and communication (ISAC) systems, where a\ndual-function multiple-input multiple-output (DF-MIMO) base station (BS)\nperforms downlink communication and radar sensing simultaneously. In ISAC\nsystems, sensing and communication inherently compete for resources. As\ncommunication demand increases, the beam pattern is reshaped, which might\ndegrade the direction of arrival (DoA) sensing accuracy, measured in terms of\nmean-squared error (MSE) and lower-bounded by the Cramer-Rao lower bound\n(CRLB). Since conventional joint formulations of the sensing-based problem\noften overlook this trade-off, our work addresses it by decomposing the\nsensing-based problem into two subproblems (SPs). This decomposition enables a\nmore effective exploitation of the beam pattern's physical properties, which we\nrefer to as the Sensing-Guided Communication Dual-Function (SGCDF) beam pattern\ndesign. We further develop a low-complexity extension using the Riemannian\nManifold Optimization (RMO) and convex closed-set projection. Simulation\nresults confirm that the proposed method improves multi-target estimation\naccuracy, compared to traditional joint optimization strategies, by preserving\nthe beam pattern, while the low-complexity version offers an excellent\nperformance-complexity tradeoff, maintaining high accuracy with significantly\nreduced computational cost.", "published": "2025-09-27 13:27:17", "link": "http://arxiv.org/abs/2509.23302v1", "categories": ["eess.SP", "cs.SY", "eess.SY"], "primary_category": "eess.SP"}
{"title": "Resource Allocation in Cooperative Mid-band/THz Networks in the Presence of Mobility", "abstract": "This paper develops a comprehensive framework to investigate and optimize the\ndownlink performance of cooperative multi-band networks (MBNs) operating on\nupper mid-band (UMB) and terahertz (THz) frequencies, where base stations (BSs)\nin each band cooperatively serve users. The framework captures sophisticated\nfeatures such as near-field channel modeling, fully and partially connected\nantenna architectures, and users' mobility. First, we consider joint user\nassociation and hybrid beamforming optimization to maximize the system\nsum-rate, subject to power constraints, maximum cluster size of cooperating\nBSs, and users' quality-of-service (QoS) constraints. By leveraging fractional\nprogramming FP and majorization-minimization techniques, an iterative algorithm\nis proposed to solve the non-convex optimization problem. We then consider\nhandover (HO)-aware resource allocation for moving users in a cooperative\nUMB/THz MBN. Two HO-aware resource allocation methods are proposed. The first\nmethod focuses on maximizing the HO-aware system sum-rate subject to HO-aware\nQoS constraints. Using Jensen's inequality and properties of logarithmic\nfunctions, the non-convex optimization problem is tightly approximated with a\nconvex one and solved. The second method addresses a multi-objective\noptimization problem to maximize the system sum-rate, while minimizing the\ntotal number of HOs. Numerical results demonstrate the efficacy of the proposed\nalgorithms, cooperative UMB/THz MBN over stand-alone THz networks, as well as\nthe critical importance of accurate near-field modeling in extremely large\nantenna arrays. Moreover, the proposed HO-aware resource allocation methods\neffectively mitigate the impact of HOs, enhancing performance in the considered\nsystem.", "published": "2025-09-27 02:43:40", "link": "http://arxiv.org/abs/2509.23065v1", "categories": ["eess.SP", "math.CV"], "primary_category": "eess.SP"}
