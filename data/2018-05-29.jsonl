{"title": "Bi-Directional Neural Machine Translation with Synthetic Parallel Data", "abstract": "Despite impressive progress in high-resource settings, Neural Machine\nTranslation (NMT) still struggles in low-resource and out-of-domain scenarios,\noften failing to match the quality of phrase-based translation. We propose a\nnovel technique that combines back-translation and multilingual NMT to improve\nperformance in these difficult cases. Our technique trains a single model for\nboth directions of a language pair, allowing us to back-translate source or\ntarget monolingual data without requiring an auxiliary model. We then continue\ntraining on the augmented parallel data, enabling a cycle of improvement for a\nsingle model that can incorporate any source, target, or parallel data to\nimprove both translation directions. As a byproduct, these models can reduce\ntraining and deployment costs significantly compared to uni-directional models.\nExtensive experiments show that our technique outperforms standard\nback-translation in low-resource scenarios, improves quality on cross-domain\ntasks, and effectively reduces costs across the board.", "published": "2018-05-29 01:45:22", "link": "http://arxiv.org/abs/1805.11213v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Distilling Knowledge for Search-based Structured Prediction", "abstract": "Many natural language processing tasks can be modeled into structured\nprediction and solved as a search problem. In this paper, we distill an\nensemble of multiple models trained with different initialization into a single\nmodel. In addition to learning to match the ensemble's probability output on\nthe reference states, we also use the ensemble to explore the search space and\nlearn from the encountered states in the exploration. Experimental results on\ntwo typical search-based structured prediction tasks -- transition-based\ndependency parsing and neural machine translation show that distillation can\neffectively improve the single model's performance and the final model achieves\nimprovements of 1.32 in LAS and 2.65 in BLEU score on these two tasks\nrespectively over strong baselines and it outperforms the greedy structured\nprediction models in previous literatures.", "published": "2018-05-29 02:39:43", "link": "http://arxiv.org/abs/1805.11224v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-hop Inference for Sentence-level TextGraphs: How Challenging is\n  Meaningfully Combining Information for Science Question Answering?", "abstract": "Question Answering for complex questions is often modeled as a graph\nconstruction or traversal task, where a solver must build or traverse a graph\nof facts that answer and explain a given question. This \"multi-hop\" inference\nhas been shown to be extremely challenging, with few models able to aggregate\nmore than two facts before being overwhelmed by \"semantic drift\", or the\ntendency for long chains of facts to quickly drift off topic. This is a major\nbarrier to current inference models, as even elementary science questions\nrequire an average of 4 to 6 facts to answer and explain. In this work we\nempirically characterize the difficulty of building or traversing a graph of\nsentences connected by lexical overlap, by evaluating chance sentence\naggregation quality through 9,784 manually-annotated judgments across knowledge\ngraphs built from three free-text corpora (including study guides and Simple\nWikipedia). We demonstrate semantic drift tends to be high and aggregation\nquality low, at between 0.04% and 3%, and highlight scenarios that maximize the\nlikelihood of meaningfully combining information.", "published": "2018-05-29 06:52:29", "link": "http://arxiv.org/abs/1805.11267v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised detection of diachronic word sense evolution", "abstract": "Most words have several senses and connotations which evolve in time due to\nsemantic shift, so that closely related words may gain different or even\nopposite meanings over the years. This evolution is very relevant to the study\nof language and of cultural changes, but the tools currently available for\ndiachronic semantic analysis have significant, inherent limitations and are not\nsuitable for real-time analysis. In this article, we demonstrate how the\nlinearity of random vectors techniques enables building time series of\ncongruent word embeddings (or semantic spaces) which can then be compared and\ncombined linearly without loss of precision over any time period to detect\ndiachronic semantic shifts. We show how this approach yields time trajectories\nof polysemous words such as amazon or apple, enables following semantic drifts\nand gender bias across time, reveals the shifting instantiations of stable\nconcepts such as hurricane or president. This very fast, linear approach can\neasily be distributed over many processors to follow in real time streams of\nsocial media such as Twitter or Facebook; the resulting, time-dependent\nsemantic spaces can then be combined at will by simple additions or\nsubtractions.", "published": "2018-05-29 08:22:50", "link": "http://arxiv.org/abs/1805.11295v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Quantum-inspired Complex Word Embedding", "abstract": "A challenging task for word embeddings is to capture the emergent meaning or\npolarity of a combination of individual words. For example, existing approaches\nin word embeddings will assign high probabilities to the words \"Penguin\" and\n\"Fly\" if they frequently co-occur, but it fails to capture the fact that they\noccur in an opposite sense - Penguins do not fly. We hypothesize that humans do\nnot associate a single polarity or sentiment to each word. The word contributes\nto the overall polarity of a combination of words depending upon which other\nwords it is combined with. This is analogous to the behavior of microscopic\nparticles which exist in all possible states at the same time and interfere\nwith each other to give rise to new states depending upon their relative\nphases. We make use of the Hilbert Space representation of such particles in\nQuantum Mechanics where we subscribe a relative phase to each word, which is a\ncomplex number, and investigate two such quantum inspired models to derive the\nmeaning of a combination of words. The proposed models achieve better\nperformances than state-of-the-art non-quantum models on the binary sentence\nclassification task.", "published": "2018-05-29 10:46:30", "link": "http://arxiv.org/abs/1805.11351v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic Sentence Matching with Densely-connected Recurrent and\n  Co-attentive Information", "abstract": "Sentence matching is widely used in various natural language tasks such as\nnatural language inference, paraphrase identification, and question answering.\nFor these tasks, understanding logical and semantic relationship between two\nsentences is required but it is yet challenging. Although attention mechanism\nis useful to capture the semantic relationship and to properly align the\nelements of two sentences, previous methods of attention mechanism simply use a\nsummation operation which does not retain original features enough. Inspired by\nDenseNet, a densely connected convolutional network, we propose a\ndensely-connected co-attentive recurrent neural network, each layer of which\nuses concatenated information of attentive features as well as hidden features\nof all the preceding recurrent layers. It enables preserving the original and\nthe co-attentive feature information from the bottommost word embedding layer\nto the uppermost recurrent layer. To alleviate the problem of an\never-increasing size of feature vectors due to dense concatenation operations,\nwe also propose to use an autoencoder after dense concatenation. We evaluate\nour proposed architecture on highly competitive benchmark datasets related to\nsentence matching. Experimental results show that our architecture, which\nretains recurrent and attentive features, achieves state-of-the-art\nperformances for most of the tasks.", "published": "2018-05-29 11:29:56", "link": "http://arxiv.org/abs/1805.11360v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AMR Dependency Parsing with a Typed Semantic Algebra", "abstract": "We present a semantic parser for Abstract Meaning Representations which\nlearns to parse strings into tree representations of the compositional\nstructure of an AMR graph. This allows us to use standard neural techniques for\nsupertagging and dependency tree parsing, constrained by a linguistically\nprincipled type system. We present two approximative decoding algorithms, which\nachieve state-of-the-art accuracy and outperform strong baselines.", "published": "2018-05-29 13:44:19", "link": "http://arxiv.org/abs/1805.11465v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Entity Linking in 40 Languages using MAG", "abstract": "A plethora of Entity Linking (EL) approaches has recently been developed.\nWhile many claim to be multilingual, the MAG (Multilingual AGDISTIS) approach\nhas been shown recently to outperform the state of the art in multilingual EL\non 7 languages. With this demo, we extend MAG to support EL in 40 different\nlanguages, including especially low-resources languages such as Ukrainian,\nGreek, Hungarian, Croatian, Portuguese, Japanese and Korean. Our demo relies on\nonline web services which allow for an easy access to our entity linking\napproaches and can disambiguate against DBpedia and Wikidata. During the demo,\nwe will show how to use MAG by means of POST requests as well as using its\nuser-friendly web interface. All data used in the demo is available at\nhttps://hobbitdata.informatik.uni-leipzig.de/agdistis/", "published": "2018-05-29 13:46:27", "link": "http://arxiv.org/abs/1805.11467v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Human vs Automatic Metrics: on the Importance of Correlation Design", "abstract": "This paper discusses two existing approaches to the correlation analysis\nbetween automatic evaluation metrics and human scores in the area of natural\nlanguage generation. Our experiments show that depending on the usage of a\nsystem- or sentence-level correlation analysis, correlation results between\nautomatic scores and human judgments are inconsistent.", "published": "2018-05-29 13:53:16", "link": "http://arxiv.org/abs/1805.11474v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lightly-supervised Representation Learning with Global Interpretability", "abstract": "We propose a lightly-supervised approach for information extraction, in\nparticular named entity classification, which combines the benefits of\ntraditional bootstrapping, i.e., use of limited annotations and\ninterpretability of extraction patterns, with the robust learning approaches\nproposed in representation learning. Our algorithm iteratively learns custom\nembeddings for both the multi-word entities to be extracted and the patterns\nthat match them from a few example entities per category. We demonstrate that\nthis representation-based approach outperforms three other state-of-the-art\nbootstrapping approaches on two datasets: CoNLL-2003 and OntoNotes.\nAdditionally, using these embeddings, our approach outputs a\nglobally-interpretable model consisting of a decision list, by ranking patterns\nbased on their proximity to the average entity embedding in a given class. We\nshow that this interpretable model performs close to our complete bootstrapping\nmodel, proving that representation learning can be used to produce\ninterpretable models with small loss in performance.", "published": "2018-05-29 15:49:11", "link": "http://arxiv.org/abs/1805.11545v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Entrainment profiles: Comparison by gender, role, and feature set", "abstract": "We examine prosodic entrainment in cooperative game dialogs for new feature\nsets describing register, pitch accent shape, and rhythmic aspects of\nutterances. For these as well as for established features we present\nentrainment profiles to detect within- and across-dialog entrainment by the\nspeakers' gender and role in the game. It turned out, that feature sets undergo\nentrainment in different quantitative and qualitative ways, which can partly be\nattributed to their different functions. Furthermore, interactions between\nspeaker gender and role (describer vs. follower) suggest gender-dependent\nstrategies in cooperative solution-oriented interactions: female describers\nentrain most, male describers least. Our data suggests a slight advantage of\nthe latter strategy on task success.", "published": "2018-05-29 16:22:42", "link": "http://arxiv.org/abs/1805.11564v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Polyglot Semantic Role Labeling", "abstract": "Previous approaches to multilingual semantic dependency parsing treat\nlanguages independently, without exploiting the similarities between semantic\nstructures across languages. We experiment with a new approach where we combine\nresources from a pair of languages in the CoNLL 2009 shared task to build a\npolyglot semantic role labeler. Notwithstanding the absence of parallel data,\nand the dissimilarity in annotations between languages, our approach results in\nan improvement in SRL performance on multiple languages over a monolingual\nbaseline. Analysis of the polyglot model shows it to be advantageous in\nlower-resource settings.", "published": "2018-05-29 17:29:55", "link": "http://arxiv.org/abs/1805.11598v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Identification of Arabic expressions related to future events\n  in Lebanon's economy", "abstract": "In this paper, we propose a method to automatically identify future events in\nLebanon's economy from Arabic texts. Challenges are threefold: first, we need\nto build a corpus of Arabic texts that covers Lebanon's economy; second, we\nneed to study how future events are expressed linguistically in these texts;\nand third, we need to automatically identify the relevant textual segments\naccordingly. We will validate this method on a constructed corpus form the web\nand show that it has very promising results. To do so, we will be using SLCSAS,\na system for semantic analysis, based on the Contextual Explorer method, and\n\"AlKhalil Morpho Sys\" system for morpho-syntactic analysis.", "published": "2018-05-29 17:41:52", "link": "http://arxiv.org/abs/1805.11603v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantically-informed distance and similarity measures for paraphrase\n  plagiarism identification", "abstract": "Paraphrase plagiarism identification represents a very complex task given\nthat plagiarized texts are intentionally modified through several rewording\ntechniques. Accordingly, this paper introduces two new measures for evaluating\nthe relatedness of two given texts: a semantically-informed similarity measure\nand a semantically-informed edit distance. Both measures are able to extract\nsemantic information from either an external resource or a distributed\nrepresentation of words, resulting in informative features for training a\nsupervised classifier for detecting paraphrase plagiarism. Obtained results\nindicate that the proposed metrics are consistently good in detecting different\ntypes of paraphrase plagiarism. In addition, results are very competitive\nagainst state-of-the art methods having the advantage of representing a much\nmore simple but equally effective solution.", "published": "2018-05-29 17:54:52", "link": "http://arxiv.org/abs/1805.11611v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LSTMs Exploit Linguistic Attributes of Data", "abstract": "While recurrent neural networks have found success in a variety of natural\nlanguage processing applications, they are general models of sequential data.\nWe investigate how the properties of natural language data affect an LSTM's\nability to learn a nonlinguistic task: recalling elements from its input. We\nfind that models trained on natural language data are able to recall tokens\nfrom much longer sequences than models trained on non-language sequential data.\nFurthermore, we show that the LSTM learns to solve the memorization task by\nexplicitly using a subset of its neurons to count timesteps in the input. We\nhypothesize that the patterns and structure in natural language data enable\nLSTMs to learn by providing approximate ways of reducing loss, but\nunderstanding the effect of different training data on the learnability of\nLSTMs remains an open question.", "published": "2018-05-29 18:44:31", "link": "http://arxiv.org/abs/1805.11653v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Table-to-Text: Describing Table Region with Natural Language", "abstract": "In this paper, we present a generative model to generate a natural language\nsentence describing a table region, e.g., a row. The model maps a row from a\ntable to a continuous vector and then generates a natural language sentence by\nleveraging the semantics of a table. To deal with rare words appearing in a\ntable, we develop a flexible copying mechanism that selectively replicates\ncontents from the table in the output sequence. Extensive experiments\ndemonstrate the accuracy of the model and the power of the copying mechanism.\nOn two synthetic datasets, WIKIBIO and SIMPLEQUESTIONS, our model improves the\ncurrent state-of-the-art BLEU-4 score from 34.70 to 40.26 and from 33.32 to\n39.12, respectively. Furthermore, we introduce an open-domain dataset\nWIKITABLETEXT including 13,318 explanatory sentences for 4,962 tables. Our\nmodel achieves a BLEU-4 score of 38.23, which outperforms template based and\nlanguage model based approaches.", "published": "2018-05-29 03:39:35", "link": "http://arxiv.org/abs/1805.11234v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Like a Baby: Visually Situated Neural Language Acquisition", "abstract": "We examine the benefits of visual context in training neural language models\nto perform next-word prediction. A multi-modal neural architecture is\nintroduced that outperform its equivalent trained on language alone with a 2\\%\ndecrease in perplexity, even when no visual context is available at test.\nFine-tuning the embeddings of a pre-trained state-of-the-art bidirectional\nlanguage model (BERT) in the language modeling framework yields a 3.5\\%\nimprovement. The advantage for training with visual context when testing\nwithout is robust across different languages (English, German and Spanish) and\ndifferent models (GRU, LSTM, $\\Delta$-RNN, as well as those that use BERT\nembeddings). Thus, language models perform better when they learn like a baby,\ni.e, in a multi-modal environment. This finding is compatible with the theory\nof situated cognition: language is inseparable from its physical context.", "published": "2018-05-29 15:53:30", "link": "http://arxiv.org/abs/1805.11546v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Unsupervised Alignment of Embeddings with Wasserstein Procrustes", "abstract": "We consider the task of aligning two sets of points in high dimension, which\nhas many applications in natural language processing and computer vision. As an\nexample, it was recently shown that it is possible to infer a bilingual\nlexicon, without supervised data, by aligning word embeddings trained on\nmonolingual data. These recent advances are based on adversarial training to\nlearn the mapping between the two embeddings. In this paper, we propose to use\nan alternative formulation, based on the joint estimation of an orthogonal\nmatrix and a permutation matrix. While this problem is not convex, we propose\nto initialize our optimization algorithm by using a convex relaxation,\ntraditionally considered for the graph isomorphism problem. We propose a\nstochastic algorithm to minimize our cost function on large scale problems.\nFinally, we evaluate our method on the problem of unsupervised word\ntranslation, by aligning word embeddings trained on monolingual data. On this\ntask, our method obtains state of the art results, while requiring less\ncomputational resources than competing approaches.", "published": "2018-05-29 02:35:15", "link": "http://arxiv.org/abs/1805.11222v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Fully Statistical Neural Belief Tracking", "abstract": "This paper proposes an improvement to the existing data-driven Neural Belief\nTracking (NBT) framework for Dialogue State Tracking (DST). The existing NBT\nmodel uses a hand-crafted belief state update mechanism which involves an\nexpensive manual retuning step whenever the model is deployed to a new dialogue\ndomain. We show that this update mechanism can be learned jointly with the\nsemantic decoding and context modelling parts of the NBT model, eliminating the\nlast rule-based module from this DST framework. We propose two different\nstatistical update mechanisms and show that dialogue dynamics can be modelled\nwith a very small number of additional model parameters. In our DST evaluation\nover three languages, we show that this model achieves competitive performance\nand provides a robust framework for building resource-light DST models.", "published": "2018-05-29 10:41:08", "link": "http://arxiv.org/abs/1805.11350v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CoupleNet: Paying Attention to Couples with Coupled Attention for\n  Relationship Recommendation", "abstract": "Dating and romantic relationships not only play a huge role in our personal\nlives but also collectively influence and shape society. Today, many romantic\npartnerships originate from the Internet, signifying the importance of\ntechnology and the web in modern dating. In this paper, we present a text-based\ncomputational approach for estimating the relationship compatibility of two\nusers on social media. Unlike many previous works that propose reciprocal\nrecommender systems for online dating websites, we devise a distant supervision\nheuristic to obtain real world couples from social platforms such as Twitter.\nOur approach, the CoupleNet is an end-to-end deep learning based estimator that\nanalyzes the social profiles of two users and subsequently performs a\nsimilarity match between the users. Intuitively, our approach performs both\nuser profiling and match-making within a unified end-to-end framework.\nCoupleNet utilizes hierarchical recurrent neural models for learning\nrepresentations of user profiles and subsequently coupled attention mechanisms\nto fuse information aggregated from two users. To the best of our knowledge,\nour approach is the first data-driven deep learning approach for our novel\nrelationship recommendation problem. We benchmark our CoupleNet against several\nmachine learning and deep learning baselines. Experimental results show that\nour approach outperforms all approaches significantly in terms of precision.\nQualitative analysis shows that our model is capable of also producing\nexplainable results to users.", "published": "2018-05-29 15:14:41", "link": "http://arxiv.org/abs/1805.11535v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Disentangling by Partitioning: A Representation Learning Framework for\n  Multimodal Sensory Data", "abstract": "Multimodal sensory data resembles the form of information perceived by humans\nfor learning, and are easy to obtain in large quantities. Compared to unimodal\ndata, synchronization of concepts between modalities in such data provides\nsupervision for disentangling the underlying explanatory factors of each\nmodality. Previous work leveraging multimodal data has mainly focused on\nretaining only the modality-invariant factors while discarding the rest. In\nthis paper, we present a partitioned variational autoencoder (PVAE) and several\ntraining objectives to learn disentangled representations, which encode not\nonly the shared factors, but also modality-dependent ones, into separate latent\nvariables. Specifically, PVAE integrates a variational inference framework and\na multimodal generative model that partitions the explanatory factors and\nconditions only on the relevant subset of them for generation. We evaluate our\nmodel on two parallel speech/image datasets, and demonstrate its ability to\nlearn disentangled representations by qualitatively exploring within-modality\nand cross-modality conditional generation with semantics and styles specified\nby examples. For quantitative analysis, we evaluate the classification accuracy\nof automatically discovered semantic units. Our PVAE can achieve over 99%\naccuracy on both modalities.", "published": "2018-05-29 06:45:02", "link": "http://arxiv.org/abs/1805.11264v1", "categories": ["stat.ML", "cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "stat.ML"}
{"title": "Receiver Placement for Speech Enhancement using Sound Propagation\n  Optimization", "abstract": "A common problem in acoustic design is the placement of speakers or receivers\nfor public address systems, telecommunications, and home smart speakers or\ndigital personal assistants. We present a novel algorithm to automatically\nplace a speaker or receiver in a room to improve the intelligibility of spoken\nphrases in a design. Our technique uses a sound propagation optimization\nformulation to maximize the Speech Transmission Index (STI) by computing an\noptimal location of the sound receiver. We use an efficient and accurate hybrid\nsound propagation technique on complex 3D models to compute the Room Impulse\nResponses (RIR) and evaluate their impact on the STI. The overall algorithm\ncomputes a globally optimal position of the receiver that reduces the effects\nof reverberation and noise over many source positions. We evaluate our\nalgorithm on various indoor 3D models, all showing significant improvement in\nSTI, based on accurate sound propagation.", "published": "2018-05-29 15:10:42", "link": "http://arxiv.org/abs/1805.11533v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Towards Lipreading Sentences with Active Appearance Models", "abstract": "Automatic lipreading has major potential impact for speech recognition,\nsupplementing and complementing the acoustic modality. Most attempts at\nlipreading have been performed on small vocabulary tasks, due to a shortfall of\nappropriate audio-visual datasets. In this work we use the publicly available\nTCD-TIMIT database, designed for large vocabulary continuous audio-visual\nspeech recognition. We compare the viseme recognition performance of the most\nwidely used features for lipreading, Discrete Cosine Transform (DCT) and Active\nAppearance Models (AAM), in a traditional Hidden Markov Model (HMM) framework.\nWe also exploit recent advances in AAM fitting. We found the DCT to outperform\nAAM by more than 6% for a viseme recognition task with 56 speakers. The overall\naccuracy of the DCT is quite low (32-34%). We conclude that a fundamental\nrethink of the modelling of visual features may be needed for this task.", "published": "2018-05-29 19:57:12", "link": "http://arxiv.org/abs/1805.11688v1", "categories": ["eess.IV", "eess.AS"], "primary_category": "eess.IV"}
{"title": "Learning to Transcribe by Ear", "abstract": "Rethinking how to model polyphonic transcription formally, we frame it as a\nreinforcement learning task. Such a task formulation encompasses the notion of\na musical agent and an environment containing an instrument as well as the\nsound source to be transcribed. Within this conceptual framework, the\ntranscription process can be described as the agent interacting with the\ninstrument in the environment, and obtaining reward by playing along with what\nit hears. Choosing from a discrete set of actions - the notes to play on its\ninstrument - the amount of reward the agent experiences depends on which notes\nit plays and when. This process resembles how a human musician might approach\nthe task of transcription, and the satisfaction she achieves by closely\nmimicking the sound source to transcribe on her instrument. Following a\ndiscussion of the theoretical framework and the benefits of modelling the\nproblem in this way, we focus our attention on several practical considerations\nand address the difficulties in training an agent to acceptable performance on\na set of tasks with increasing difficulty. We demonstrate promising results in\npartially constrained environments.", "published": "2018-05-29 14:58:35", "link": "http://arxiv.org/abs/1805.11526v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Can DNNs Learn to Lipread Full Sentences?", "abstract": "Finding visual features and suitable models for lipreading tasks that are\nmore complex than a well-constrained vocabulary has proven challenging. This\npaper explores state-of-the-art Deep Neural Network architectures for\nlipreading based on a Sequence to Sequence Recurrent Neural Network. We report\nresults for both hand-crafted and 2D/3D Convolutional Neural Network visual\nfront-ends, online monotonic attention, and a joint Connectionist Temporal\nClassification-Sequence-to-Sequence loss. The system is evaluated on the\npublicly available TCD-TIMIT dataset, with 59 speakers and a vocabulary of over\n6000 words. Results show a major improvement on a Hidden Markov Model\nframework. A fuller analysis of performance across visemes demonstrates that\nthe network is not only learning the language model, but actually learning to\nlipread.", "published": "2018-05-29 19:54:19", "link": "http://arxiv.org/abs/1805.11685v1", "categories": ["eess.IV", "cs.CV", "eess.AS"], "primary_category": "eess.IV"}
