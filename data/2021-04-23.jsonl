{"title": "Transfer training from smaller language model", "abstract": "Large language models have led to state-of-the-art accuracies across a range\nof tasks. However,training large language model needs massive computing\nresource, as more and more open source pre-training models are available, it is\nworthy to study how to take full advantage of available model. We find a method\nto save training time and resource cost by changing the small well-trained\nmodel to large model. We initialize a larger target model from a smaller source\nmodel by copy weight values from source model and padding with zeros or small\ninitialization values on it to make the source and target model have\napproximate outputs, which is valid due to block matrix multiplication and\nresidual connection in transformer structure. We test the target model on\nseveral data sets and find it is still comparable with the source model. When\nwe continue training the target model, the training loss can start from a\nsmaller value.", "published": "2021-04-23 02:56:02", "link": "http://arxiv.org/abs/2104.11390v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BERT-CoQAC: BERT-based Conversational Question Answering in Context", "abstract": "As one promising way to inquire about any particular information through a\ndialog with the bot, question answering dialog systems have gained increasing\nresearch interests recently. Designing interactive QA systems has always been a\nchallenging task in natural language processing and used as a benchmark to\nevaluate a machine's ability of natural language understanding. However, such\nsystems often struggle when the question answering is carried out in multiple\nturns by the users to seek more information based on what they have already\nlearned, thus, giving rise to another complicated form called Conversational\nQuestion Answering (CQA). CQA systems are often criticized for not\nunderstanding or utilizing the previous context of the conversation when\nanswering the questions. To address the research gap, in this paper, we explore\nhow to integrate conversational history into the neural machine comprehension\nsystem. On one hand, we introduce a framework based on a publically available\npre-trained language model called BERT for incorporating history turns into the\nsystem. On the other hand, we propose a history selection mechanism that\nselects the turns that are relevant and contributes the most to answer the\ncurrent question. Experimentation results revealed that our framework is\ncomparable in performance with the state-of-the-art models on the QuAC leader\nboard. We also conduct a number of experiments to show the side effects of\nusing entire context information which brings unnecessary information and noise\nsignals resulting in a decline in the model's performance.", "published": "2021-04-23 03:05:17", "link": "http://arxiv.org/abs/2104.11394v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multimodal Fusion with BERT and Attention Mechanism for Fake News\n  Detection", "abstract": "Fake news detection is an important task for increasing the credibility of\ninformation on the media since fake news is constantly spreading on social\nmedia every day and it is a very serious concern in our society. Fake news is\nusually created by manipulating images, texts, and videos. In this paper, we\npresent a novel method for detecting fake news by fusing multimodal features\nderived from textual and visual data. Specifically, we used a pre-trained BERT\nmodel to learn text features and a VGG-19 model pre-trained on the ImageNet\ndataset to extract image features. We proposed a scale-dot product attention\nmechanism to capture the relationship between text features and visual\nfeatures. Experimental results showed that our approach performs better than\nthe current state-of-the-art method on a public Twitter dataset by 3.1%\naccuracy.", "published": "2021-04-23 08:47:54", "link": "http://arxiv.org/abs/2104.11476v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Learn to be Right for the Right Reasons", "abstract": "Improving model generalization on held-out data is one of the core objectives\nin commonsense reasoning. Recent work has shown that models trained on the\ndataset with superficial cues tend to perform well on the easy test set with\nsuperficial cues but perform poorly on the hard test set without superficial\ncues. Previous approaches have resorted to manual methods of encouraging models\nnot to overfit to superficial cues. While some of the methods have improved\nperformance on hard instances, they also lead to degraded performance on easy\ninstances. Here, we propose to explicitly learn a model that does well on both\nthe easy test set with superficial cues and hard test set without superficial\ncues. Using a meta-learning objective, we learn such a model that improves\nperformance on both the easy test set and the hard test set. By evaluating our\nmodels on Choice of Plausible Alternatives (COPA) and Commonsense Explanation,\nwe show that our proposed method leads to improved performance on both the easy\ntest set and the hard test set upon which we observe up to 16.5 percentage\npoints improvement over the baseline.", "published": "2021-04-23 10:03:00", "link": "http://arxiv.org/abs/2104.11514v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Deep learning for sentence clustering in essay grading support", "abstract": "Essays as a form of assessment test student knowledge on a deeper level than\nshort answer and multiple-choice questions. However, the manual evaluation of\nessays is time- and labor-consuming. Automatic clustering of essays, or their\nfragments, prior to manual evaluation presents a possible solution to reducing\nthe effort required in the evaluation process. Such clustering presents\nnumerous challenges due to the variability and ambiguity of natural language.\nIn this paper, we introduce two datasets of undergraduate student essays in\nFinnish, manually annotated for salient arguments on the sentence level. Using\nthese datasets, we evaluate several deep-learning embedding methods for their\nsuitability to sentence clustering in support of essay grading. We find that\nthe choice of the most suitable method depends on the nature of the exam\nquestion and the answers, with deep-learning methods being capable of, but not\nguaranteeing better performance over simpler methods based on lexical overlap.", "published": "2021-04-23 12:32:51", "link": "http://arxiv.org/abs/2104.11556v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "QMUL-SDS at SCIVER: Step-by-Step Binary Classification for Scientific\n  Claim Verification", "abstract": "Scientific claim verification is a unique challenge that is attracting\nincreasing interest. The SCIVER shared task offers a benchmark scenario to test\nand compare claim verification approaches by participating teams and consists\nin three steps: relevant abstract selection, rationale selection and label\nprediction. In this paper, we present team QMUL-SDS's participation in the\nshared task. We propose an approach that performs scientific claim verification\nby doing binary classifications step-by-step. We trained a BioBERT-large\nclassifier to select abstracts based on pairwise relevance assessments for each\n<claim, title of the abstract> and continued to train it to select rationales\nout of each retrieved abstract based on <claim, sentence>. We then propose a\ntwo-step setting for label prediction, i.e. first predicting \"NOT_ENOUGH_INFO\"\nor \"ENOUGH_INFO\", then label those marked as \"ENOUGH_INFO\" as either \"SUPPORT\"\nor \"CONTRADICT\". Compared to the baseline system, we achieve substantial\nimprovements on the dev set. As a result, our team is the No. 4 team on the\nleaderboard.", "published": "2021-04-23 13:12:57", "link": "http://arxiv.org/abs/2104.11572v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Deception Detection Model Robustness To Linguistic Variation", "abstract": "With the increasing use of machine-learning driven algorithmic judgements, it\nis critical to develop models that are robust to evolving or manipulated\ninputs. We propose an extensive analysis of model robustness against linguistic\nvariation in the setting of deceptive news detection, an important task in the\ncontext of misinformation spread online. We consider two prediction tasks and\ncompare three state-of-the-art embeddings to highlight consistent trends in\nmodel performance, high confidence misclassifications, and high impact\nfailures. By measuring the effectiveness of adversarial defense strategies and\nevaluating model susceptibility to adversarial attacks using character- and\nword-perturbed text, we find that character or mixed ensemble models are the\nmost effective defenses and that character perturbation-based attack tactics\nare more successful.", "published": "2021-04-23 17:25:38", "link": "http://arxiv.org/abs/2104.11729v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Trustworthy Deception Detection: Benchmarking Model Robustness\n  across Domains, Modalities, and Languages", "abstract": "Evaluating model robustness is critical when developing trustworthy models\nnot only to gain deeper understanding of model behavior, strengths, and\nweaknesses, but also to develop future models that are generalizable and robust\nacross expected environments a model may encounter in deployment. In this paper\nwe present a framework for measuring model robustness for an important but\ndifficult text classification task - deceptive news detection. We evaluate\nmodel robustness to out-of-domain data, modality-specific features, and\nlanguages other than English.\n  Our investigation focuses on three type of models: LSTM models trained on\nmultiple datasets(Cross-Domain), several fusion LSTM models trained with images\nand text and evaluated with three state-of-the-art embeddings, BERT ELMo, and\nGloVe (Cross-Modality), and character-level CNN models trained on multiple\nlanguages (Cross-Language). Our analyses reveal a significant drop in\nperformance when testing neural models on out-of-domain data and non-English\nlanguages that may be mitigated using diverse training data. We find that with\nadditional image content as input, ELMo embeddings yield significantly fewer\nerrors compared to BERT orGLoVe. Most importantly, this work not only carefully\nanalyzes deception model robustness but also provides a framework of these\nanalyses that can be applied to new models or extended datasets in the future.", "published": "2021-04-23 18:05:52", "link": "http://arxiv.org/abs/2104.11761v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On a Utilitarian Approach to Privacy Preserving Text Generation", "abstract": "Differentially-private mechanisms for text generation typically add carefully\ncalibrated noise to input words and use the nearest neighbor to the noised\ninput as the output word. When the noise is small in magnitude, these\nmechanisms are susceptible to reconstruction of the original sensitive text.\nThis is because the nearest neighbor to the noised input is likely to be the\noriginal input. To mitigate this empirical privacy risk, we propose a novel\nclass of differentially private mechanisms that parameterizes the nearest\nneighbor selection criterion in traditional mechanisms. Motivated by Vickrey\nauction, where only the second highest price is revealed and the highest price\nis kept private, we balance the choice between the first and the second nearest\nneighbors in the proposed class of mechanisms using a tuning parameter. This\nparameter is selected by empirically solving a constrained optimization problem\nfor maximizing utility, while maintaining the desired privacy guarantees. We\nargue that this empirical measurement framework can be used to align different\nmechanisms along a common benchmark for their privacy-utility tradeoff,\nparticularly when different distance metrics are used to calibrate the amount\nof noise added. Our experiments on real text classification datasets show up to\n50% improvement in utility compared to the existing state-of-the-art with the\nsame empirical privacy guarantee.", "published": "2021-04-23 23:13:43", "link": "http://arxiv.org/abs/2104.11838v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automated News Summarization Using Transformers", "abstract": "The amount of text data available online is increasing at a very fast pace\nhence text summarization has become essential. Most of the modern recommender\nand text classification systems require going through a huge amount of data.\nManually generating precise and fluent summaries of lengthy articles is a very\ntiresome and time-consuming task. Hence generating automated summaries for the\ndata and using it to train machine learning models will make these models space\nand time-efficient. Extractive summarization and abstractive summarization are\ntwo separate methods of generating summaries. The extractive technique\nidentifies the relevant sentences from the original document and extracts only\nthose from the text. Whereas in abstractive summarization techniques, the\nsummary is generated after interpreting the original text, hence making it more\ncomplicated. In this paper, we will be presenting a comprehensive comparison of\na few transformer architecture based pre-trained models for text summarization.\nFor analysis and comparison, we have used the BBC news dataset that contains\ntext data that can be used for summarization and human generated summaries for\nevaluating and comparing the summaries generated by machine learning models.", "published": "2021-04-23 04:22:33", "link": "http://arxiv.org/abs/2108.01064v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knodle: Modular Weakly Supervised Learning with PyTorch", "abstract": "Strategies for improving the training and prediction quality of weakly\nsupervised machine learning models vary in how much they are tailored to a\nspecific task or integrated with a specific model architecture. In this work,\nwe introduce Knodle, a software framework that treats weak data annotations,\ndeep learning models, and methods for improving weakly supervised training as\nseparate, modular components. This modularization gives the training process\naccess to fine-grained information such as data set characteristics, matches of\nheuristic rules, or elements of the deep learning model ultimately used for\nprediction. Hence, our framework can encompass a wide range of training methods\nfor improving weak supervision, ranging from methods that only look at\ncorrelations of rules and output classes (independently of the machine learning\nmodel trained with the resulting labels), to those that harness the interplay\nof neural networks and weakly labeled data. We illustrate the benchmarking\npotential of the framework with a performance comparison of several reference\nimplementations on a selection of datasets that are already available in\nKnodle.\n  The framework is published as an open-source Python package knodle and\navailable at https://github.com/knodle/knodle.", "published": "2021-04-23 12:33:25", "link": "http://arxiv.org/abs/2104.11557v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Optimizing small BERTs trained for German NER", "abstract": "Currently, the most widespread neural network architecture for training\nlanguage models is the so called BERT which led to improvements in various\nNatural Language Processing (NLP) tasks. In general, the larger the number of\nparameters in a BERT model, the better the results obtained in these NLP tasks.\nUnfortunately, the memory consumption and the training duration drastically\nincreases with the size of these models. In this article, we investigate\nvarious training techniques of smaller BERT models: We combine different\nmethods from other BERT variants like ALBERT, RoBERTa, and relative positional\nencoding. In addition, we propose two new fine-tuning modifications leading to\nbetter performance: Class-Start-End tagging and a modified form of Linear Chain\nConditional Random Fields. Furthermore, we introduce Whole-Word Attention which\nreduces BERTs memory usage and leads to a small increase in performance\ncompared to classical Multi-Head-Attention. We evaluate these techniques on\nfive public German Named Entity Recognition (NER) tasks of which two are\nintroduced by this article.", "published": "2021-04-23 12:36:13", "link": "http://arxiv.org/abs/2104.11559v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Intensional Artificial Intelligence: From Symbol Emergence to\n  Explainable and Empathetic AI", "abstract": "We argue that an explainable artificial intelligence must possess a rationale\nfor its decisions, be able to infer the purpose of observed behaviour, and be\nable to explain its decisions in the context of what its audience understands\nand intends. To address these issues we present four novel contributions.\nFirstly, we define an arbitrary task in terms of perceptual states, and discuss\ntwo extremes of a domain of possible solutions. Secondly, we define the\nintensional solution. Optimal by some definitions of intelligence, it describes\nthe purpose of a task. An agent possessed of it has a rationale for its\ndecisions in terms of that purpose, expressed in a perceptual symbol system\ngrounded in hardware. Thirdly, to communicate that rationale requires natural\nlanguage, a means of encoding and decoding perceptual states. We propose a\ntheory of meaning in which, to acquire language, an agent should model the\nworld a language describes rather than the language itself. If the utterances\nof humans are of predictive value to the agent's goals, then the agent will\nimbue those utterances with meaning in terms of its own goals and perceptual\nstates. In the context of Peircean semiotics, a community of agents must share\nrough approximations of signs, referents and interpretants in order to\ncommunicate. Meaning exists only in the context of intent, so to communicate\nwith humans an agent must have comparable experiences and goals. An agent that\nlearns intensional solutions, compelled by objective functions somewhat\nanalogous to human motivators such as hunger and pain, may be capable of\nexplaining its rationale not just in terms of its own intent, but in terms of\nwhat its audience understands and intends. It forms some approximation of the\nperceptual states of humans.", "published": "2021-04-23 13:13:46", "link": "http://arxiv.org/abs/2104.11573v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Understanding who uses Reddit: Profiling individuals with a\n  self-reported bipolar disorder diagnosis", "abstract": "Recently, research on mental health conditions using public online data,\nincluding Reddit, has surged in NLP and health research but has not reported\nuser characteristics, which are important to judge generalisability of\nfindings. This paper shows how existing NLP methods can yield information on\nclinical, demographic, and identity characteristics of almost 20K Reddit users\nwho self-report a bipolar disorder diagnosis. This population consists of\nslightly more feminine- than masculine-gendered mainly young or middle-aged\nUS-based adults who often report additional mental health diagnoses, which is\ncompared with general Reddit statistics and epidemiological studies.\nAdditionally, this paper carefully evaluates all methods and discusses ethical\nissues.", "published": "2021-04-23 13:58:20", "link": "http://arxiv.org/abs/2104.11612v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Claim Detection in Biomedical Twitter Posts", "abstract": "Social media contains unfiltered and unique information, which is potentially\nof great value, but, in the case of misinformation, can also do great harm.\nWith regards to biomedical topics, false information can be particularly\ndangerous. Methods of automatic fact-checking and fake news detection address\nthis problem, but have not been applied to the biomedical domain in social\nmedia yet. We aim to fill this research gap and annotate a corpus of 1200\ntweets for implicit and explicit biomedical claims (the latter also with span\nannotations for the claim phrase). With this corpus, which we sample to be\nrelated to COVID-19, measles, cystic fibrosis, and depression, we develop\nbaseline models which detect tweets that contain a claim automatically. Our\nanalyses reveal that biomedical tweets are densely populated with claims (45 %\nin a corpus sampled to contain 1200 tweets focused on the domains mentioned\nabove). Baseline classification experiments with embedding-based classifiers\nand BERT-based transfer learning demonstrate that the detection is challenging,\nhowever, shows acceptable performance for the identification of explicit\nexpressions of claims. Implicit claim tweets are more challenging to detect.", "published": "2021-04-23 14:45:31", "link": "http://arxiv.org/abs/2104.11639v2", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Comparative Analysis of Machine Learning and Deep Learning Algorithms\n  for Detection of Online Hate Speech", "abstract": "In the day and age of social media, users have become prone to online hate\nspeech. Several attempts have been made to classify hate speech using machine\nlearning but the state-of-the-art models are not robust enough for practical\napplications. This is attributed to the use of primitive NLP feature\nengineering techniques. In this paper, we explored various feature engineering\ntechniques ranging from different embeddings to conventional NLP algorithms. We\nalso experimented with combinations of different features. From our\nexperimentation, we realized that roBERTa (robustly optimized BERT approach)\nbased sentence embeddings classified using decision trees gives the best\nresults of 0.9998 F1 score. In our paper, we concluded that BERT based\nembeddings give the most useful features for this problem and have the capacity\nto be made into a practical robust model.", "published": "2021-04-23 04:19:15", "link": "http://arxiv.org/abs/2108.01063v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Analysing Cyberbullying using Natural Language Processing by\n  Understanding Jargon in Social Media", "abstract": "Cyberbullying is of extreme prevalence today. Online-hate comments, toxicity,\ncyberbullying amongst children and other vulnerable groups are only growing\nover online classes, and increased access to social platforms, especially post\nCOVID-19. It is paramount to detect and ensure minors' safety across social\nplatforms so that any violence or hate-crime is automatically detected and\nstrict action is taken against it. In our work, we explore binary\nclassification by using a combination of datasets from various social media\nplatforms that cover a wide range of cyberbullying such as sexism, racism,\nabusive, and hate-speech. We experiment through multiple models such as\nBi-LSTM, GloVe, state-of-the-art models like BERT, and apply a unique\npreprocessing technique by introducing a slang-abusive corpus, achieving a\nhigher precision in comparison to models without slang preprocessing.", "published": "2021-04-23 04:20:19", "link": "http://arxiv.org/abs/2107.08902v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "APRF-Net: Attentive Pseudo-Relevance Feedback Network for Query\n  Categorization", "abstract": "Query categorization is an essential part of query intent understanding in\ne-commerce search. A common query categorization task is to select the relevant\nfine-grained product categories in a product taxonomy. For frequent queries,\nrich customer behavior (e.g., click-through data) can be used to infer the\nrelevant product categories. However, for more rare queries, which cover a\nlarge volume of search traffic, relying solely on customer behavior may not\nsuffice due to the lack of this signal. To improve categorization of rare\nqueries, we adapt the Pseudo-Relevance Feedback (PRF) approach to utilize the\nlatent knowledge embedded in semantically or lexically similar product\ndocuments to enrich the representation of the more rare queries. To this end,\nwe propose a novel deep neural model named Attentive Pseudo Relevance Feedback\nNetwork (APRF-Net) to enhance the representation of rare queries for query\ncategorization. To demonstrate the effectiveness of our approach, we collect\nsearch queries from a large commercial search engine, and compare APRF-Net to\nstate-of-the-art deep learning models for text classification. Our results show\nthat the APRF-Net significantly improves query categorization by 5.9% on F1@1\nscore over the baselines, which increases to 8.2% improvement for the rare\n(tail) queries. The findings of this paper can be leveraged for further\nimprovements in search query representation and understanding.", "published": "2021-04-23 02:34:08", "link": "http://arxiv.org/abs/2104.11384v2", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "LeBenchmark: A Reproducible Framework for Assessing Self-Supervised\n  Representation Learning from Speech", "abstract": "Self-Supervised Learning (SSL) using huge unlabeled data has been\nsuccessfully explored for image and natural language processing. Recent works\nalso investigated SSL from speech. They were notably successful to improve\nperformance on downstream tasks such as automatic speech recognition (ASR).\nWhile these works suggest it is possible to reduce dependence on labeled data\nfor building efficient speech systems, their evaluation was mostly made on ASR\nand using multiple and heterogeneous experimental settings (most of them for\nEnglish). This questions the objective comparison of SSL approaches and the\nevaluation of their impact on building speech systems. In this paper, we\npropose LeBenchmark: a reproducible framework for assessing SSL from speech. It\nnot only includes ASR (high and low resource) tasks but also spoken language\nunderstanding, speech translation and emotion recognition. We also focus on\nspeech technologies in a language different than English: French. SSL models of\ndifferent sizes are trained from carefully sourced and documented datasets.\nExperiments show that SSL is beneficial for most but not all tasks which\nconfirms the need for exhaustive and reliable benchmarks to evaluate its real\nimpact. LeBenchmark is shared with the scientific community for reproducible\nresearch in SSL from speech.", "published": "2021-04-23 08:27:09", "link": "http://arxiv.org/abs/2104.11462v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "3D Convolutional Neural Networks for Ultrasound-Based Silent Speech\n  Interfaces", "abstract": "Silent speech interfaces (SSI) aim to reconstruct the speech signal from a\nrecording of the articulatory movement, such as an ultrasound video of the\ntongue. Currently, deep neural networks are the most successful technology for\nthis task. The efficient solution requires methods that do not simply process\nsingle images, but are able to extract the tongue movement information from a\nsequence of video frames. One option for this is to apply recurrent neural\nstructures such as the long short-term memory network (LSTM) in combination\nwith 2D convolutional neural networks (CNNs). Here, we experiment with another\napproach that extends the CNN to perform 3D convolution, where the extra\ndimension corresponds to time. In particular, we apply the spatial and temporal\nconvolutions in a decomposed form, which proved very successful recently in\nvideo action recognition. We find experimentally that our 3D network\noutperforms the CNN+LSTM model, indicating that 3D CNNs may be a feasible\nalternative to CNN+LSTM networks in SSI systems.", "published": "2021-04-23 10:56:34", "link": "http://arxiv.org/abs/2104.11532v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Weakly-supervised Multi-task Learning for Multimodal Affect Recognition", "abstract": "Multimodal affect recognition constitutes an important aspect for enhancing\ninterpersonal relationships in human-computer interaction. However, relevant\ndata is hard to come by and notably costly to annotate, which poses a\nchallenging barrier to build robust multimodal affect recognition systems.\nModels trained on these relatively small datasets tend to overfit and the\nimprovement gained by using complex state-of-the-art models is marginal\ncompared to simple baselines. Meanwhile, there are many different multimodal\naffect recognition datasets, though each may be small. In this paper, we\npropose to leverage these datasets using weakly-supervised multi-task learning\nto improve the generalization performance on each of them. Specifically, we\nexplore three multimodal affect recognition tasks: 1) emotion recognition; 2)\nsentiment analysis; and 3) sarcasm recognition. Our experimental results show\nthat multi-tasking can benefit all these tasks, achieving an improvement up to\n2.9% accuracy and 3.3% F1-score. Furthermore, our method also helps to improve\nthe stability of model performance. In addition, our analysis suggests that\nweak supervision can provide a comparable contribution to strong supervision if\nthe tasks are highly correlated.", "published": "2021-04-23 12:36:19", "link": "http://arxiv.org/abs/2104.11560v1", "categories": ["cs.CL", "cs.CV", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Beyond Voice Activity Detection: Hybrid Audio Segmentation for Direct\n  Speech Translation", "abstract": "The audio segmentation mismatch between training data and those seen at\nrun-time is a major problem in direct speech translation. Indeed, while systems\nare usually trained on manually segmented corpora, in real use cases they are\noften presented with continuous audio requiring automatic (and sub-optimal)\nsegmentation. After comparing existing techniques (VAD-based, fixed-length and\nhybrid segmentation methods), in this paper we propose enhanced hybrid\nsolutions to produce better results without sacrificing latency. Through\nexperiments on different domains and language pairs, we show that our methods\noutperform all the other techniques, reducing by at least 30% the gap between\nthe traditional VAD-based approach and optimal manual segmentation.", "published": "2021-04-23 16:54:13", "link": "http://arxiv.org/abs/2104.11710v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "DeepCAT: Deep Category Representation for Query Understanding in\n  E-commerce Search", "abstract": "Mapping a search query to a set of relevant categories in the product\ntaxonomy is a significant challenge in e-commerce search for two reasons: 1)\nTraining data exhibits severe class imbalance problem due to biased click\nbehavior, and 2) queries with little customer feedback (e.g., tail queries) are\nnot well-represented in the training set, and cause difficulties for query\nunderstanding. To address these problems, we propose a deep learning model,\nDeepCAT, which learns joint word-category representations to enhance the query\nunderstanding process. We believe learning category interactions helps to\nimprove the performance of category mapping on minority classes, tail and torso\nqueries. DeepCAT contains a novel word-category representation model that\ntrains the category representations based on word-category co-occurrences in\nthe training set. The category representation is then leveraged to introduce a\nnew loss function to estimate the category-category co-occurrences for refining\njoint word-category embeddings. To demonstrate our model's effectiveness on\nminority categories and tail queries, we conduct two sets of experiments. The\nresults show that DeepCAT reaches a 10% improvement on minority classes and a\n7.1% improvement on tail queries over a state-of-the-art label embedding model.\nOur findings suggest a promising direction for improving e-commerce search by\nsemantic modeling of taxonomy hierarchies.", "published": "2021-04-23 18:04:44", "link": "http://arxiv.org/abs/2104.11760v2", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Playing Lottery Tickets with Vision and Language", "abstract": "Large-scale pre-training has recently revolutionized vision-and-language (VL)\nresearch. Models such as LXMERT and UNITER have significantly lifted the state\nof the art over a wide range of VL tasks. However, the large number of\nparameters in such models hinders their application in practice. In parallel,\nwork on the lottery ticket hypothesis (LTH) has shown that deep neural networks\ncontain small matching subnetworks that can achieve on par or even better\nperformance than the dense networks when trained in isolation. In this work, we\nperform the first empirical study to assess whether such trainable subnetworks\nalso exist in pre-trained VL models. We use UNITER as the main testbed (also\ntest on LXMERT and ViLT), and consolidate 7 representative VL tasks for\nexperiments, including visual question answering, visual commonsense reasoning,\nvisual entailment, referring expression comprehension, image-text retrieval,\nGQA, and NLVR$^2$. Through comprehensive analysis, we summarize our main\nfindings as follows. ($i$) It is difficult to find subnetworks that strictly\nmatch the performance of the full model. However, we can find \"relaxed\" winning\ntickets at 50%-70% sparsity that maintain 99% of the full accuracy. ($ii$)\nSubnetworks found by task-specific pruning transfer reasonably well to the\nother tasks, while those found on the pre-training tasks at 60%/70% sparsity\ntransfer universally, matching 98%/96% of the full accuracy on average over all\nthe tasks. ($iii$) Besides UNITER, other models such as LXMERT and ViLT can\nalso play lottery tickets. However, the highest sparsity we can achieve for\nViLT is far lower than LXMERT and UNITER (30% vs. 70%). ($iv$) LTH also remains\nrelevant when using other training methods (e.g., adversarial training).", "published": "2021-04-23 22:24:33", "link": "http://arxiv.org/abs/2104.11832v2", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Analysis of Online Toxicity Detection Using Machine Learning Approaches", "abstract": "Social media and the internet have become an integral part of how people\nspread and consume information. Over a period of time, social media evolved\ndramatically, and almost half of the population is using social media to\nexpress their views and opinions. Online hate speech is one of the drawbacks of\nsocial media nowadays, which needs to be controlled. In this paper, we will\nunderstand how hate speech originated and what are the consequences of it;\nTrends of machine-learning algorithms to solve an online hate speech problem.\nThis study contributes by providing a systematic approach to help researchers\nto identify a new research direction and elucidating the shortcomings of the\nstudies and model, as well as providing future directions to advance the field.", "published": "2021-04-23 04:29:13", "link": "http://arxiv.org/abs/2108.01062v1", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Generating abstractive summaries of Lithuanian news articles using a\n  transformer model", "abstract": "In this work, we train the first monolingual Lithuanian transformer model on\na relatively large corpus of Lithuanian news articles and compare various\noutput decoding algorithms for abstractive news summarization. We achieve an\naverage ROUGE-2 score 0.163, generated summaries are coherent and look\nimpressive at first glance. However, some of them contain misleading\ninformation that is not so easy to spot. We describe all the technical details\nand share our trained model and accompanying code in an online open-source\nrepository, as well as some characteristic samples of the generated summaries.", "published": "2021-04-23 20:10:42", "link": "http://arxiv.org/abs/2105.03279v2", "categories": ["cs.CL", "cs.IR", "cs.LG", "68T07, 68T50, 68T05", "I.2.6; I.2.7"], "primary_category": "cs.CL"}
{"title": "Deep Learning Based Assessment of Synthetic Speech Naturalness", "abstract": "In this paper, we present a new objective prediction model for synthetic\nspeech naturalness. It can be used to evaluate Text-To-Speech or Voice\nConversion systems and works language independently. The model is trained\nend-to-end and based on a CNN-LSTM network that previously showed to give good\nresults for speech quality estimation. We trained and tested the model on 16\ndifferent datasets, such as from the Blizzard Challenge and the Voice\nConversion Challenge. Further, we show that the reliability of deep\nlearning-based naturalness prediction can be improved by transfer learning from\nspeech quality prediction models that are trained on objective POLQA scores.\nThe proposed model is made publicly available and can, for example, be used to\nevaluate different TTS system configurations.", "published": "2021-04-23 16:05:20", "link": "http://arxiv.org/abs/2104.11673v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ESResNe(X)t-fbsp: Learning Robust Time-Frequency Transformation of Audio", "abstract": "Environmental Sound Classification (ESC) is a rapidly evolving field that\nrecently demonstrated the advantages of application of visual domain techniques\nto the audio-related tasks. Previous studies indicate that the domain-specific\nmodification of cross-domain approaches show a promise in pushing the whole\narea of ESC forward.\n  In this paper, we present a new time-frequency transformation layer that is\nbased on complex frequency B-spline (fbsp) wavelets. Being used with a\nhigh-performance audio classification model, the proposed fbsp-layer provides\nan accuracy improvement over the previously used Short-Time Fourier Transform\n(STFT) on standard datasets. We also investigate the influence of different\npre-training strategies, including the joint use of two large-scale datasets\nfor weight initialization: ImageNet and AudioSet. Our proposed model\nout-performs other approaches by achieving accuracies of 95.20 % on the ESC-50\nand 89.14 % on the UrbanSound8K datasets.\n  Additionally, we assess the increase of model robustness against additive\nwhite Gaussian noise and reduction of an effective sample rate introduced by\nthe proposed layer and demonstrate that the fbsp-layer improves the model's\nability to withstand signal perturbations, in comparison to STFT-based\ntraining. For the sake of reproducibility, our code is made available.", "published": "2021-04-23 13:39:44", "link": "http://arxiv.org/abs/2104.11587v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Reconstructing Speech from Real-Time Articulatory MRI Using Neural\n  Vocoders", "abstract": "Several approaches exist for the recording of articulatory movements, such as\neletromagnetic and permanent magnetic articulagraphy, ultrasound tongue imaging\nand surface electromyography. Although magnetic resonance imaging (MRI) is more\ncostly than the above approaches, the recent developments in this area now\nallow the recording of real-time MRI videos of the articulators with an\nacceptable resolution. Here, we experiment with the reconstruction of the\nspeech signal from a real-time MRI recording using deep neural networks.\nInstead of estimating speech directly, our networks are trained to output a\nspectral vector, from which we reconstruct the speech signal using the WaveGlow\nneural vocoder. We compare the performance of three deep neural architectures\nfor the estimation task, combining convolutional (CNN) and recurrence-based\n(LSTM) neural layers. Besides the mean absolute error (MAE) of our networks, we\nalso evaluate our models by comparing the speech signals obtained using several\nobjective speech quality metrics like the mean cepstral distortion (MCD),\nShort-Time Objective Intelligibility (STOI), Perceptual Evaluation of Speech\nQuality (PESQ) and Signal-to-Distortion Ratio (SDR). The results indicate that\nour approach can successfully reconstruct the gross spectral shape, but more\nimprovements are needed to reproduce the fine spectral details.", "published": "2021-04-23 13:46:51", "link": "http://arxiv.org/abs/2104.11598v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Improving Neural Silent Speech Interface Models by Adversarial Training", "abstract": "Besides the well-known classification task, these days neural networks are\nfrequently being applied to generate or transform data, such as images and\naudio signals. In such tasks, the conventional loss functions like the mean\nsquared error (MSE) may not give satisfactory results. To improve the\nperceptual quality of the generated signals, one possibility is to increase\ntheir similarity to real signals, where the similarity is evaluated via a\ndiscriminator network. The combination of the generator and discriminator nets\nis called a Generative Adversarial Network (GAN). Here, we evaluate this\nadversarial training framework in the articulatory-to-acoustic mapping task,\nwhere the goal is to reconstruct the speech signal from a recording of the\nmovement of articulatory organs. As the generator, we apply a 3D convolutional\nnetwork that gave us good results in an earlier study. To turn it into a GAN,\nwe extend the conventional MSE training loss with an adversarial loss component\nprovided by a discriminator network. As for the evaluation, we report various\nobjective speech quality metrics such as the Perceptual Evaluation of Speech\nQuality (PESQ), and the Mel-Cepstral Distortion (MCD). Our results indicate\nthat the application of the adversarial training loss brings about a slight,\nbut consistent improvement in all these metrics.", "published": "2021-04-23 13:48:21", "link": "http://arxiv.org/abs/2104.11601v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Infant Vocal Tract Development Analysis and Diagnosis by Cry Signals\n  with CNN Age Classification", "abstract": "From crying to babbling and then to speech, infant's vocal tract goes through\nanatomic restructuring. In this paper, we propose a non-invasive fast method of\nusing infant cry signals with convolutional neural network (CNN) based age\nclassification to diagnose the abnormality of the vocal tract development as\nearly as 4-month age. We study F0, F1, F2, and spectrograms and relate them to\nthe postnatal development of infant vocalization. A novel CNN based age\nclassification is performed with binary age pairs to discover the pattern and\ntendency of the vocal tract changes. The effectiveness of this approach is\nevaluated on Baby2020 with healthy infant cries and Baby Chillanto database\nwith pathological infant cries. The results show that our approach yields\n79.20% accuracy for healthy cries, 84.80% for asphyxiated cries, and 91.20% for\ndeaf cries. Our method first reveals that infants' vocal tract develops to a\ncertain level at 4-month age and infants can start controlling the vocal folds\nto produce discontinuous cry sounds leading to babbling. Early diagnosis of\ngrowth abnormality of the vocal tract can help parents keep vigilant and adopt\nmedical treatment or training therapy for their infants as early as possible.", "published": "2021-04-23 03:09:16", "link": "http://arxiv.org/abs/2104.11395v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "DeepSpectrumLite: A Power-Efficient Transfer Learning Framework for\n  Embedded Speech and Audio Processing from Decentralised Data", "abstract": "Deep neural speech and audio processing systems have a large number of\ntrainable parameters, a relatively complex architecture, and require a vast\namount of training data and computational power. These constraints make it more\nchallenging to integrate such systems into embedded devices and utilise them\nfor real-time, real-world applications. We tackle these limitations by\nintroducing DeepSpectrumLite, an open-source, lightweight transfer learning\nframework for on-device speech and audio recognition using pre-trained image\nconvolutional neural networks (CNNs). The framework creates and augments\nMel-spectrogram plots on-the-fly from raw audio signals which are then used to\nfinetune specific pre-trained CNNs for the target classification task.\nSubsequently, the whole pipeline can be run in real-time with a mean inference\nlag of 242.0 ms when a DenseNet121 model is used on a consumer-grade Motorola\nmoto e7 plus smartphone. DeepSpectrumLite operates decentralised, eliminating\nthe need for data upload for further processing. By obtaining state-of-the-art\nresults on a set of paralinguistics tasks, we demonstrate the suitability of\nthe proposed transfer learning approach for embedded audio signal processing,\neven when data is scarce. We provide an extensive command-line interface for\nusers and developers which is comprehensively documented and publicly available\nat https://github.com/DeepSpectrum/DeepSpectrumLite.", "published": "2021-04-23 14:32:33", "link": "http://arxiv.org/abs/2104.11629v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
