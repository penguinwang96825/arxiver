{"title": "Natural Language and Spatial Rules", "abstract": "We develop a system that formally represents spatial semantics concepts\nwithin natural language descriptions of spatial arrangements. The system builds\non a model of spatial semantics representation according to which words in a\nsentence are assigned spatial roles and the relations among these roles are\nrepresented with spatial relations. We combine our system with the shape\ngrammar formalism that uses shape rules to generate languages (sets) of\ntwo-dimensional shapes. Our proposed system consists of pairs of shape rules\nand verbal rules where the verbal rules describe in English the action of the\nassociated shape rule. We present various types of natural language\ndescriptions of shapes that are successfully parsed by our system and we\ndiscuss open questions and challenges we see at the interface of language and\nperception.", "published": "2021-11-28 07:18:11", "link": "http://arxiv.org/abs/2111.14066v1", "categories": ["cs.CL", "I.2.7; I.2.4; J.6"], "primary_category": "cs.CL"}
{"title": "A Grounded Well-being Conversational Agent with Multiple Interaction\n  Modes: Preliminary Results", "abstract": "Technologies for enhancing well-being, healthcare vigilance and monitoring\nare on the rise. However, despite patient interest, such technologies suffer\nfrom low adoption. One hypothesis for this limited adoption is loss of human\ninteraction that is central to doctor-patient encounters. In this paper we seek\nto address this limitation via a conversational agent that adopts one aspect of\nin-person doctor-patient interactions: A human avatar to facilitate medical\ngrounded question answering. This is akin to the in-person scenario where the\ndoctor may point to the human body or the patient may point to their own body\nto express their conditions. Additionally, our agent has multiple interaction\nmodes, that may give more options for the patient to use the agent, not just\nfor medical question answering, but also to engage in conversations about\ngeneral topics and current events. Both the avatar, and the multiple\ninteraction modes could help improve adherence.\n  We present a high level overview of the design of our agent, Marie Bot\nWellbeing. We also report implementation details of our early prototype , and\npresent preliminary results.", "published": "2021-11-28 08:58:38", "link": "http://arxiv.org/abs/2111.14083v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Identification of Structure Function of Academic Articles\n  Using Contextual Information", "abstract": "With the enrichment of literature resources, researchers are facing the\ngrowing problem of information explosion and knowledge overload. To help\nscholars retrieve literature and acquire knowledge successfully, clarifying the\nsemantic structure of the content in academic literature has become the\nessential research question. In the research on identifying the structure\nfunction of chapters in academic articles, only a few studies used the deep\nlearning model and explored the optimization for feature input. This limits the\napplication, optimization potential of deep learning models for the research\ntask. This paper took articles of the ACL conference as the corpus. We employ\nthe traditional machine learning models and deep learning models to construct\nthe classifiers based on various feature input. Experimental results show that\n(1) Compared with the chapter content, the chapter title is more conducive to\nidentifying the structure function of academic articles. (2) Relative position\nis a valuable feature for building traditional models. (3) Inspired by (2),\nthis paper further introduces contextual information into the deep learning\nmodels and achieved significant results. Meanwhile, our models show good\nmigration ability in the open test containing 200 sampled non-training samples.\nWe also annotated the ACL main conference papers in recent five years based on\nthe best practice performing models and performed a time series analysis of the\noverall corpus. This work explores and summarizes the practical features and\nmodels for this task through multiple comparative experiments and provides a\nreference for related text classification tasks. Finally, we indicate the\nlimitations and shortcomings of the current model and the direction of further\noptimization.", "published": "2021-11-28 11:21:21", "link": "http://arxiv.org/abs/2111.14110v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Context Matters in Semantically Controlled Language Generation for\n  Task-oriented Dialogue Systems", "abstract": "This work combines information about the dialogue history encoded by\npre-trained model with a meaning representation of the current system utterance\nto realize contextual language generation in task-oriented dialogues. We\nutilize the pre-trained multi-context ConveRT model for context representation\nin a model trained from scratch; and leverage the immediate preceding user\nutterance for context generation in a model adapted from the pre-trained GPT-2.\nBoth experiments with the MultiWOZ dataset show that contextual information\nencoded by pre-trained model improves the performance of response generation\nboth in automatic metrics and human evaluation. Our presented contextual\ngenerator enables higher variety of generated responses that fit better to the\nongoing dialogue. Analysing the context size shows that longer context does not\nautomatically lead to better performance, but the immediate preceding user\nutterance plays an essential role for contextual generation. In addition, we\nalso propose a re-ranker for the GPT-based generation model. The experiments\nshow that the response selected by the re-ranker has a significant improvement\non automatic metrics.", "published": "2021-11-28 11:48:02", "link": "http://arxiv.org/abs/2111.14119v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Empirical Study of Topic Transition in Dialogue", "abstract": "Transitioning between topics is a natural component of human-human dialog.\nAlthough topic transition has been studied in dialogue for decades, only a\nhandful of corpora based studies have been performed to investigate the\nsubtleties of topic transitions. Thus, this study annotates 215 conversations\nfrom the switchboard corpus and investigates how variables such as length,\nnumber of topic transitions, topic transitions share by participants and\nturns/topic are related. This work presents an empirical study on topic\ntransition in switchboard corpus followed by modelling topic transition with a\nprecision of 83% for in-domain(id) test set and 82% on 10 out-of-domain}(ood)\ntest set. It is envisioned that this work will help in emulating human-human\nlike topic transition in open-domain dialog systems.", "published": "2021-11-28 16:02:13", "link": "http://arxiv.org/abs/2111.14188v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FastTrees: Parallel Latent Tree-Induction for Faster Sequence Encoding", "abstract": "Inducing latent tree structures from sequential data is an emerging trend in\nthe NLP research landscape today, largely popularized by recent methods such as\nGumbel LSTM and Ordered Neurons (ON-LSTM). This paper proposes FASTTREES, a new\ngeneral purpose neural module for fast sequence encoding. Unlike most previous\nworks that consider recurrence to be necessary for tree induction, our work\nexplores the notion of parallel tree induction, i.e., imbuing our model with\nhierarchical inductive biases in a parallelizable, non-autoregressive fashion.\nTo this end, our proposed FASTTREES achieves competitive or superior\nperformance to ON-LSTM on four well-established sequence modeling tasks, i.e.,\nlanguage modeling, logical inference, sentiment analysis and natural language\ninference. Moreover, we show that the FASTTREES module can be applied to\nenhance Transformer models, achieving performance gains on three sequence\ntransduction tasks (machine translation, subject-verb agreement and\nmathematical language understanding), paving the way for modular tree induction\nmodules. Overall, we outperform existing state-of-the-art models on logical\ninference tasks by +4% and mathematical language understanding by +8%.", "published": "2021-11-28 03:08:06", "link": "http://arxiv.org/abs/2111.14031v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Topic Driven Adaptive Network for Cross-Domain Sentiment Classification", "abstract": "Cross-domain sentiment classification has been a hot spot these years, which\naims to learn a reliable classifier using labeled data from a source domain and\nevaluate it on a target domain. In this vein, most approaches utilized domain\nadaptation that maps data from different domains into a common feature space.\nTo further improve the model performance, several methods targeted to mine\ndomain-specific information were proposed. However, most of them only utilized\na limited part of domain-specific information. In this study, we first develop\na method of extracting domain-specific words based on the topic information\nderived from topic models. Then, we propose a Topic Driven Adaptive Network\n(TDAN) for cross-domain sentiment classification. The network consists of two\nsub-networks: a semantics attention network and a domain-specific word\nattention network, the structures of which are based on transformers. These\nsub-networks take different forms of input and their outputs are fused as the\nfeature vector. Experiments validate the effectiveness of our TDAN on sentiment\nclassification across domains. Case studies also indicate that topic models\nhave the potential to add value to cross-domain sentiment classification by\ndiscovering interpretable and low-dimensional subspaces.", "published": "2021-11-28 10:17:11", "link": "http://arxiv.org/abs/2111.14094v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mapping Industry 4.0 Technologies: From Cyber-Physical Systems to\n  Artificial Intelligence", "abstract": "The fourth industrial revolution is rapidly changing the manufacturing\nlandscape. Due to the growing research and fast evolution in this field, no\nclear definitions of these concepts yet exist. This work provides a clear\ndescription of technological trends and gaps. We introduce a novel method to\ncreate a map of Industry 4.0 technologies, using natural language processing to\nextract technology terms from 14,667 research articles and applying network\nanalysis. We identified eight clusters of Industry 4.0 technologies, which\nserved as the basis for our analysis. Our results show that Industrial Internet\nof Things (IIoT) technologies have become the center of the Industry 4.0\ntechnology map. This is in line with the initial definitions of Industry 4.0,\nwhich centered on IIoT. Given the recent growth in the importance of artificial\nintelligence (AI), we suggest accounting for AI's fundamental role in Industry\n4.0 and understanding the fourth industrial revolution as an AI-powered natural\ncollaboration between humans and machines. This article introduces a novel\napproach for literature reviews, and the results highlight trends and research\ngaps to guide future work and help these actors reap the benefits of digital\ntransformations.", "published": "2021-11-28 15:13:05", "link": "http://arxiv.org/abs/2111.14168v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Zero-Shot Cross-Lingual Transfer in Legal Domain Using Transformer\n  Models", "abstract": "Zero-shot cross-lingual transfer is an important feature in modern NLP models\nand architectures to support low-resource languages. In this work, We study\nzero-shot cross-lingual transfer from English to French and German under\nMulti-Label Text Classification, where we train a classifier using English\ntraining set, and we test using French and German test sets. We extend\nEURLEX57K dataset, the English dataset for topic classification of legal\ndocuments, with French and German official translation. We investigate the\neffect of using some training techniques, namely Gradual Unfreezing and\nLanguage Model finetuning, on the quality of zero-shot cross-lingual transfer.\nWe find that Language model finetuning of multi-lingual pre-trained model\n(M-DistilBERT, M-BERT) leads to 32.0-34.94%, 76.15-87.54% relative improvement\non French and German test sets correspondingly. Also, Gradual unfreezing of\npre-trained model's layers during training results in relative improvement of\n38-45% for French and 58-70% for German. Compared to training a model in Joint\nTraining scheme using English, French and German training sets, zero-shot\nBERT-based classification model reaches 86% of the performance achieved by\njointly-trained BERT-based classification model.", "published": "2021-11-28 16:25:04", "link": "http://arxiv.org/abs/2111.14192v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Emergent Graphical Conventions in a Visual Communication Game", "abstract": "Humans communicate with graphical sketches apart from symbolic languages.\nPrimarily focusing on the latter, recent studies of emergent communication\noverlook the sketches; they do not account for the evolution process through\nwhich symbolic sign systems emerge in the trade-off between iconicity and\nsymbolicity. In this work, we take the very first step to model and simulate\nthis process via two neural agents playing a visual communication game; the\nsender communicates with the receiver by sketching on a canvas. We devise a\nnovel reinforcement learning method such that agents are evolved jointly\ntowards successful communication and abstract graphical conventions. To inspect\nthe emerged conventions, we define three fundamental properties -- iconicity,\nsymbolicity, and semanticity -- and design evaluation methods accordingly. Our\nexperimental results under different controls are consistent with the\nobservation in studies of human graphical conventions. Of note, we find that\nevolved sketches can preserve the continuum of semantics under proper\nenvironmental pressures. More interestingly, co-evolved agents can switch\nbetween conventionalized and iconic communication based on their familiarity\nwith referents. We hope the present research can pave the path for studying\nemergent communication with the modality of sketches.", "published": "2021-11-28 18:59:57", "link": "http://arxiv.org/abs/2111.14210v4", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "ORCHARD: A Benchmark For Measuring Systematic Generalization of\n  Multi-Hierarchical Reasoning", "abstract": "The ability to reason with multiple hierarchical structures is an attractive\nand desirable property of sequential inductive biases for natural language\nprocessing. Do the state-of-the-art Transformers and LSTM architectures\nimplicitly encode for these biases? To answer this, we propose ORCHARD, a\ndiagnostic dataset for systematically evaluating hierarchical reasoning in\nstate-of-the-art neural sequence models. While there have been prior evaluation\nframeworks such as ListOps or Logical Inference, our work presents a novel and\nmore natural setting where our models learn to reason with multiple explicit\nhierarchical structures instead of only one, i.e., requiring the ability to do\nboth long-term sequence memorizing, relational reasoning while reasoning with\nhierarchical structure. Consequently, backed by a set of rigorous experiments,\nwe show that (1) Transformer and LSTM models surprisingly fail in systematic\ngeneralization, and (2) with increased references between hierarchies,\nTransformer performs no better than random.", "published": "2021-11-28 03:11:37", "link": "http://arxiv.org/abs/2111.14034v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Enhancing Keyphrase Extraction from Academic Articles with their\n  Reference Information", "abstract": "With the development of Internet technology, the phenomenon of information\noverload is becoming more and more obvious. It takes a lot of time for users to\nobtain the information they need. However, keyphrases that summarize document\ninformation highly are helpful for users to quickly obtain and understand\ndocuments. For academic resources, most existing studies extract keyphrases\nthrough the title and abstract of papers. We find that title information in\nreferences also contains author-assigned keyphrases. Therefore, this article\nuses reference information and applies two typical methods of unsupervised\nextraction methods (TF*IDF and TextRank), two representative traditional\nsupervised learning algorithms (Na\\\"ive Bayes and Conditional Random Field) and\na supervised deep learning model (BiLSTM-CRF), to analyze the specific\nperformance of reference information on keyphrase extraction. It is expected to\nimprove the quality of keyphrase recognition from the perspective of expanding\nthe source text. The experimental results show that reference information can\nincrease precision, recall, and F1 of automatic keyphrase extraction to a\ncertain extent. This indicates the usefulness of reference information on\nkeyphrase extraction of academic papers and provides a new idea for the\nfollowing research on automatic keyphrase extraction.", "published": "2021-11-28 11:14:16", "link": "http://arxiv.org/abs/2111.14106v2", "categories": ["cs.IR", "cs.CL", "cs.DL"], "primary_category": "cs.IR"}
{"title": "Long-range and hierarchical language predictions in brains and\n  algorithms", "abstract": "Deep learning has recently made remarkable progress in natural language\nprocessing. Yet, the resulting algorithms remain far from competing with the\nlanguage abilities of the human brain. Predictive coding theory offers a\npotential explanation to this discrepancy: while deep language algorithms are\noptimized to predict adjacent words, the human brain would be tuned to make\nlong-range and hierarchical predictions. To test this hypothesis, we analyze\nthe fMRI brain signals of 304 subjects each listening to 70min of short\nstories. After confirming that the activations of deep language algorithms\nlinearly map onto those of the brain, we show that enhancing these models with\nlong-range forecast representations improves their brain-mapping. The results\nfurther reveal a hierarchy of predictions in the brain, whereby the\nfronto-parietal cortices forecast more abstract and more distant\nrepresentations than the temporal cortices. Overall, this study strengthens\npredictive coding theory and suggests a critical role of long-range and\nhierarchical predictions in natural language processing.", "published": "2021-11-28 20:26:07", "link": "http://arxiv.org/abs/2111.14232v1", "categories": ["q-bio.NC", "cs.AI", "cs.CL", "cs.LG", "cs.NE"], "primary_category": "q-bio.NC"}
{"title": "Speaker Embedding-aware Neural Diarization for Flexible Number of\n  Speakers with Textual Information", "abstract": "Overlapping speech diarization is always treated as a multi-label\nclassification problem. In this paper, we reformulate this task as a\nsingle-label prediction problem by encoding the multi-speaker labels with power\nset. Specifically, we propose the speaker embedding-aware neural diarization\n(SEND) method, which predicts the power set encoded labels according to the\nsimilarities between speech features and given speaker embeddings. Our method\nis further extended and integrated with downstream tasks by utilizing the\ntextual information, which has not been well studied in previous literature.\nThe experimental results show that our method achieves lower diarization error\nrate than the target-speaker voice activity detection. When textual information\nis involved, the diarization errors can be further reduced. For the real\nmeeting scenario, our method can achieve 34.11% relative improvement compared\nwith the Bayesian hidden Markov model based clustering algorithm.", "published": "2021-11-28 12:51:04", "link": "http://arxiv.org/abs/2111.13694v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Transfer Learning with Jukebox for Music Source Separation", "abstract": "In this work, we demonstrate how a publicly available, pre-trained Jukebox\nmodel can be adapted for the problem of audio source separation from a single\nmixed audio channel. Our neural network architecture, which is using transfer\nlearning, is quick to train and the results demonstrate performance comparable\nto other state-of-the-art approaches that require a lot more compute resources,\ntraining data, and time. We provide an open-source code implementation of our\narchitecture (https://github.com/wzaielamri/unmix)", "published": "2021-11-28 18:17:08", "link": "http://arxiv.org/abs/2111.14200v3", "categories": ["eess.AS", "cs.LG", "cs.SD", "I.5.1; I.2.1"], "primary_category": "eess.AS"}
{"title": "How Deep Are the Fakes? Focusing on Audio Deepfake: A Survey", "abstract": "Deepfake is content or material that is synthetically generated or\nmanipulated using artificial intelligence (AI) methods, to be passed off as\nreal and can include audio, video, image, and text synthesis. This survey has\nbeen conducted with a different perspective compared to existing survey papers,\nthat mostly focus on just video and image deepfakes. This survey not only\nevaluates generation and detection methods in the different deepfake\ncategories, but mainly focuses on audio deepfakes that are overlooked in most\nof the existing surveys. This paper critically analyzes and provides a unique\nsource of audio deepfake research, mostly ranging from 2016 to 2020. To the\nbest of our knowledge, this is the first survey focusing on audio deepfakes in\nEnglish. This survey provides readers with a summary of 1) different deepfake\ncategories 2) how they could be created and detected 3) the most recent trends\nin this domain and shortcomings in detection methods 4) audio deepfakes, how\nthey are created and detected in more detail which is the main focus of this\npaper. We found that Generative Adversarial Networks(GAN), Convolutional Neural\nNetworks (CNN), and Deep Neural Networks (DNN) are common ways of creating and\ndetecting deepfakes. In our evaluation of over 140 methods we found that the\nmajority of the focus is on video deepfakes and in particular in the generation\nof video deepfakes. We found that for text deepfakes there are more generation\nmethods but very few robust methods for detection, including fake news\ndetection, which has become a controversial area of research because of the\npotential of heavy overlaps with human generation of fake content. This paper\nis an abbreviated version of the full survey and reveals a clear need to\nresearch audio deepfakes and particularly detection of audio deepfakes.", "published": "2021-11-28 18:28:30", "link": "http://arxiv.org/abs/2111.14203v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
