{"title": "CatNet: Effective FDR Control in LSTM with Gaussian Mirrors and SHAP Feature Importance", "abstract": "We introduce CatNet, an algorithm that effectively controls False Discovery\nRate (FDR) and selects significant features in LSTM with the Gaussian Mirror\n(GM) method. To evaluate the feature importance of LSTM in time series, we\nintroduce a vector of the derivative of the SHapley Additive exPlanations\n(SHAP) to measure feature importance. We also propose a new kernel-based\ndependence measure to avoid multicollinearity in the GM algorithm, to make a\nrobust feature selection with controlled FDR. We use simulated data to evaluate\nCatNet's performance in both linear models and LSTM models with different link\nfunctions. The algorithm effectively controls the FDR while maintaining a high\nstatistical power in all cases. We also evaluate the algorithm's performance in\ndifferent low-dimensional and high-dimensional cases, demonstrating its\nrobustness in various input dimensions. To evaluate CatNet's performance in\nreal world applications, we construct a multi-factor investment portfolio to\nforecast the prices of S\\&P 500 index components. The results demonstrate that\nour model achieves superior predictive accuracy compared to traditional LSTM\nmodels without feature selection and FDR control. Additionally, CatNet\neffectively captures common market-driving features, which helps informed\ndecision-making in financial markets by enhancing the interpretability of\npredictions. Our study integrates of the Gaussian Mirror algorithm with LSTM\nmodels for the first time, and introduces SHAP values as a new feature\nimportance metric for FDR control methods, marking a significant advancement in\nfeature selection and error control for neural networks.", "published": "2024-11-25 18:53:37", "link": "http://arxiv.org/abs/2411.16666v2", "categories": ["stat.ML", "cs.AI", "cs.LG", "q-fin.ST"], "primary_category": "stat.ML"}
{"title": "MarketGPT: Developing a Pre-trained transformer (GPT) for Modeling Financial Time Series", "abstract": "This work presents a generative pre-trained transformer (GPT) designed for\nmodeling financial time series. The GPT functions as an order generation engine\nwithin a discrete event simulator, enabling realistic replication of limit\norder book dynamics. Our model leverages recent advancements in large language\nmodels to produce long sequences of order messages in a steaming manner. Our\nresults demonstrate that the model successfully reproduces key features of\norder flow data, even when the initial order flow prompt is no longer present\nwithin the model's context window. Moreover, evaluations reveal that the model\ncaptures several statistical properties, or 'stylized facts', characteristic of\nreal financial markets and broader macro-scale data distributions.\nCollectively, this work marks a significant step toward creating high-fidelity,\ninteractive market simulations.", "published": "2024-11-25 17:15:28", "link": "http://arxiv.org/abs/2411.16585v1", "categories": ["q-fin.TR"], "primary_category": "q-fin.TR"}
