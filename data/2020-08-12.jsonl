{"title": "The Annotation Guideline of LST20 Corpus", "abstract": "This report presents the annotation guideline for LST20, a large-scale corpus\nwith multiple layers of linguistic annotation for Thai language processing. Our\nguideline consists of five layers of linguistic annotation: word segmentation,\nPOS tagging, named entities, clause boundaries, and sentence boundaries. The\ndataset complies to the CoNLL-2003-style format for ease of use. LST20 Corpus\noffers five layers of linguistic annotation as aforementioned. At a large\nscale, it consists of 3,164,864 words, 288,020 named entities, 248,962 clauses,\nand 74,180 sentences, while it is annotated with 16 distinct POS tags. All\n3,745 documents are also annotated with 15 news genres. Regarding its sheer\nsize, this dataset is considered large enough for developing joint neural\nmodels for NLP. With the existence of this publicly available corpus, Thai has\nbecome a linguistically rich language for the first time.", "published": "2020-08-12 01:16:45", "link": "http://arxiv.org/abs/2008.05055v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "The Language Interpretability Tool: Extensible, Interactive\n  Visualizations and Analysis for NLP Models", "abstract": "We present the Language Interpretability Tool (LIT), an open-source platform\nfor visualization and understanding of NLP models. We focus on core questions\nabout model behavior: Why did my model make this prediction? When does it\nperform poorly? What happens under a controlled change in the input? LIT\nintegrates local explanations, aggregate analysis, and counterfactual\ngeneration into a streamlined, browser-based interface to enable rapid\nexploration and error analysis. We include case studies for a diverse set of\nworkflows, including exploring counterfactuals for sentiment analysis,\nmeasuring gender bias in coreference systems, and exploring local behavior in\ntext generation. LIT supports a wide range of models--including classification,\nseq2seq, and structured prediction--and is highly extensible through a\ndeclarative, framework-agnostic API. LIT is under active development, with code\nand full documentation available at https://github.com/pair-code/lit.", "published": "2020-08-12 06:07:44", "link": "http://arxiv.org/abs/2008.05122v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modeling Inter-Aspect Dependencies with a Non-temporal Mechanism for\n  Aspect-Based Sentiment Analysis", "abstract": "For multiple aspects scenario of aspect-based sentiment analysis (ABSA),\nexisting approaches typically ignore inter-aspect relations or rely on temporal\ndependencies to process aspect-aware representations of all aspects in a\nsentence. Although multiple aspects of a sentence appear in a non-adjacent\nsequential order, they are not in a strict temporal relationship as natural\nlanguage sequence, thus the aspect-aware sentence representations should not be\ntreated as temporal dependency processing. In this paper, we propose a novel\nnon-temporal mechanism to enhance the ABSA task through modeling inter-aspect\ndependencies. Furthermore, we focus on the well-known class imbalance issue on\nthe ABSA task and address it by down-weighting the loss assigned to\nwell-classified instances. Experiments on two distinct domains of SemEval 2014\ntask 4 demonstrate the effectiveness of our proposed approach.", "published": "2020-08-12 08:50:09", "link": "http://arxiv.org/abs/2008.05179v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Approaching Neural Chinese Word Segmentation as a Low-Resource Machine\n  Translation Task", "abstract": "Chinese word segmentation has entered the deep learning era which greatly\nreduces the hassle of feature engineering. Recently, some researchers attempted\nto treat it as character-level translation, which further simplified model\ndesigning, but there is a performance gap between the translation-based\napproach and other methods. This motivates our work, in which we apply the best\npractices from low-resource neural machine translation to supervised Chinese\nsegmentation. We examine a series of techniques including regularization, data\naugmentation, objective weighting, transfer learning, and ensembling. Compared\nto previous works, our low-resource translation-based method maintains the\neffortless model design, yet achieves the same result as state of the art in\nthe constrained evaluation without using additional data.", "published": "2020-08-12 14:40:51", "link": "http://arxiv.org/abs/2008.05348v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Distantly Supervised Relation Extraction in Federated Settings", "abstract": "This paper investigates distantly supervised relation extraction in federated\nsettings. Previous studies focus on distant supervision under the assumption of\ncentralized training, which requires collecting texts from different platforms\nand storing them on one machine. However, centralized training is challenged by\ntwo issues, namely, data barriers and privacy protection, which make it almost\nimpossible or cost-prohibitive to centralize data from multiple platforms.\nTherefore, it is worthy to investigate distant supervision in the federated\nlearning paradigm, which decouples the model training from the need for direct\naccess to the raw data. Overcoming label noise of distant supervision, however,\nbecomes more difficult in federated settings, since the sentences containing\nthe same entity pair may scatter around different platforms. In this paper, we\npropose a federated denoising framework to suppress label noise in federated\nsettings. The core of this framework is a multiple instance learning based\ndenoising method that is able to select reliable instances via cross-platform\ncollaboration. Various experimental results on New York Times dataset and miRNA\ngene regulation relation dataset demonstrate the effectiveness of the proposed\nmethod.", "published": "2020-08-12 00:58:39", "link": "http://arxiv.org/abs/2008.05049v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Evaluating the Impact of Knowledge Graph Context on Entity\n  Disambiguation Models", "abstract": "Pretrained Transformer models have emerged as state-of-the-art approaches\nthat learn contextual information from text to improve the performance of\nseveral NLP tasks. These models, albeit powerful, still require specialized\nknowledge in specific scenarios. In this paper, we argue that context derived\nfrom a knowledge graph (in our case: Wikidata) provides enough signals to\ninform pretrained transformer models and improve their performance for named\nentity disambiguation (NED) on Wikidata KG. We further hypothesize that our\nproposed KG context can be standardized for Wikipedia, and we evaluate the\nimpact of KG context on state-of-the-art NED model for the Wikipedia knowledge\nbase. Our empirical results validate that the proposed KG context can be\ngeneralized (for Wikipedia), and providing KG context in transformer\narchitectures considerably outperforms the existing baselines, including the\nvanilla transformer models.", "published": "2020-08-12 09:12:22", "link": "http://arxiv.org/abs/2008.05190v3", "categories": ["cs.CL", "cs.AI", "I.1.2"], "primary_category": "cs.CL"}
{"title": "Text Classification based on Multi-granularity Attention Hybrid Neural\n  Network", "abstract": "Neural network-based approaches have become the driven forces for Natural\nLanguage Processing (NLP) tasks. Conventionally, there are two mainstream\nneural architectures for NLP tasks: the recurrent neural network (RNN) and the\nconvolution neural network (ConvNet). RNNs are good at modeling long-term\ndependencies over input texts, but preclude parallel computation. ConvNets do\nnot have memory capability and it has to model sequential data as un-ordered\nfeatures. Therefore, ConvNets fail to learn sequential dependencies over the\ninput texts, but it is able to carry out high-efficient parallel computation.\nAs each neural architecture, such as RNN and ConvNets, has its own pro and con,\nintegration of different architectures is assumed to be able to enrich the\nsemantic representation of texts, thus enhance the performance of NLP tasks.\nHowever, few investigation explores the reconciliation of these seemingly\nincompatible architectures. To address this issue, we propose a hybrid\narchitecture based on a novel hierarchical multi-granularity attention\nmechanism, named Multi-granularity Attention-based Hybrid Neural Network\n(MahNN). The attention mechanism is to assign different weights to different\nparts of the input sequence to increase the computation efficiency and\nperformance of neural models. In MahNN, two types of attentions are introduced:\nthe syntactical attention and the semantical attention. The syntactical\nattention computes the importance of the syntactic elements (such as words or\nsentence) at the lower symbolic level and the semantical attention is used to\ncompute the importance of the embedded space dimension corresponding to the\nupper latent semantics. We adopt the text classification as an exemplifying way\nto illustrate the ability of MahNN to understand texts.", "published": "2020-08-12 13:02:48", "link": "http://arxiv.org/abs/2008.05282v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Variance-reduced Language Pretraining via a Mask Proposal Network", "abstract": "Self-supervised learning, a.k.a., pretraining, is important in natural\nlanguage processing. Most of the pretraining methods first randomly mask some\npositions in a sentence and then train a model to recover the tokens at the\nmasked positions. In such a way, the model can be trained without human\nlabeling, and the massive data can be used with billion parameters. Therefore,\nthe optimization efficiency becomes critical. In this paper, we tackle the\nproblem from the view of gradient variance reduction. In particular, we first\npropose a principled gradient variance decomposition theorem, which shows that\nthe variance of the stochastic gradient of the language pretraining can be\nnaturally decomposed into two terms: the variance that arises from the sample\nof data in a batch, and the variance that arises from the sampling of the mask.\nThe second term is the key difference between selfsupervised learning and\nsupervised learning, which makes the pretraining slower. In order to reduce the\nvariance of the second part, we leverage the importance sampling strategy,\nwhich aims at sampling the masks according to a proposal distribution instead\nof the uniform distribution. It can be shown that if the proposal distribution\nis proportional to the gradient norm, the variance of the sampling is reduced.\nTo improve efficiency, we introduced a MAsk Proposal Network (MAPNet), which\napproximates the optimal mask proposal distribution and is trained end-to-end\nalong with the model. According to the experimental result, our model converges\nmuch faster and achieves higher performance than the baseline BERT model.", "published": "2020-08-12 14:12:32", "link": "http://arxiv.org/abs/2008.05333v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fine-Grained Relevance Annotations for Multi-Task Document Ranking and\n  Question Answering", "abstract": "There are many existing retrieval and question answering datasets. However,\nmost of them either focus on ranked list evaluation or single-candidate\nquestion answering. This divide makes it challenging to properly evaluate\napproaches concerned with ranking documents and providing snippets or answers\nfor a given query. In this work, we present FiRA: a novel dataset of\nFine-Grained Relevance Annotations. We extend the ranked retrieval annotations\nof the Deep Learning track of TREC 2019 with passage and word level graded\nrelevance annotations for all relevant documents. We use our newly created data\nto study the distribution of relevance in long documents, as well as the\nattention of annotators to specific positions of the text. As an example, we\nevaluate the recently introduced TKL document ranking model. We find that\nalthough TKL exhibits state-of-the-art retrieval results for long documents, it\nmisses many relevant passages.", "published": "2020-08-12 14:59:50", "link": "http://arxiv.org/abs/2008.05363v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Model Robustness with Text Classification: Semantic-preserving\n  adversarial attacks", "abstract": "We propose algorithms to create adversarial attacks to assess model\nrobustness in text classification problems. They can be used to create white\nbox attacks and black box attacks while at the same time preserving the\nsemantics and syntax of the original text. The attacks cause significant number\nof flips in white-box setting and same rule based can be used in black-box\nsetting. In a black-box setting, the attacks created are able to reverse\ndecisions of transformer based architectures.", "published": "2020-08-12 19:17:46", "link": "http://arxiv.org/abs/2008.05536v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An AI based talent acquisition and benchmarking for job", "abstract": "In a recruitment industry, selecting a best CV from a particular job post\nwithin a pile of thousand CV's is quite challenging. Finding a perfect\ncandidate for an organization who can be fit to work within organizational\nculture is a difficult task. In order to help the recruiters to fill these gaps\nwe leverage the help of AI. We propose a methodology to solve these problems by\nmatching the skill graph generated from CV and Job Post. In this report our\napproach is to perform the business understanding in order to justify why such\nproblems arise and how we intend to solve these problems using natural language\nprocessing and machine learning techniques. We limit our project only to solve\nthe problem in the domain of the computer science industry.", "published": "2020-08-12 15:57:54", "link": "http://arxiv.org/abs/2009.09088v1", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Transfer Learning Approaches for Streaming End-to-End Speech Recognition\n  System", "abstract": "Transfer learning (TL) is widely used in conventional hybrid automatic speech\nrecognition (ASR) system, to transfer the knowledge from source to target\nlanguage. TL can be applied to end-to-end (E2E) ASR system such as recurrent\nneural network transducer (RNN-T) models, by initializing the encoder and/or\nprediction network of the target language with the pre-trained models from\nsource language. In the hybrid ASR system, transfer learning is typically done\nby initializing the target language acoustic model (AM) with source language\nAM. Several transfer learning strategies exist in the case of the RNN-T\nframework, depending upon the choice of the initialization model for encoder\nand prediction networks. This paper presents a comparative study of four\ndifferent TL methods for RNN-T framework. We show 17% relative word error rate\nreduction with different TL methods over randomly initialized RNN-T model. We\nalso study the impact of TL with varying amount of training data ranging from\n50 hours to 1000 hours and show the efficacy of TL for languages with small\namount of training data.", "published": "2020-08-12 03:25:05", "link": "http://arxiv.org/abs/2008.05086v2", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "OCoR: An Overlapping-Aware Code Retriever", "abstract": "Code retrieval helps developers reuse the code snippet in the open-source\nprojects. Given a natural language description, code retrieval aims to search\nfor the most relevant code among a set of code. Existing state-of-the-art\napproaches apply neural networks to code retrieval. However, these approaches\nstill fail to capture an important feature: overlaps. The overlaps between\ndifferent names used by different people indicate that two different names may\nbe potentially related (e.g., \"message\" and \"msg\"), and the overlaps between\nidentifiers in code and words in natural language descriptions indicate that\nthe code snippet and the description may potentially be related. To address\nthese problems, we propose a novel neural architecture named OCoR, where we\nintroduce two specifically-designed components to capture overlaps: the first\nembeds identifiers by character to capture the overlaps between identifiers,\nand the second introduces a novel overlap matrix to represent the degrees of\noverlaps between each natural language word and each identifier.\n  The evaluation was conducted on two established datasets. The experimental\nresults show that OCoR significantly outperforms the existing state-of-the-art\napproaches and achieves 13.1% to 22.3% improvements. Moreover, we also\nconducted several in-depth experiments to help understand the performance of\ndifferent components in OCoR.", "published": "2020-08-12 09:43:35", "link": "http://arxiv.org/abs/2008.05201v2", "categories": ["cs.CL", "cs.LG", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Compression of Deep Learning Models for Text: A Survey", "abstract": "In recent years, the fields of natural language processing (NLP) and\ninformation retrieval (IR) have made tremendous progress thanksto deep learning\nmodels like Recurrent Neural Networks (RNNs), Gated Recurrent Units (GRUs) and\nLong Short-Term Memory (LSTMs)networks, and Transformer [120] based models like\nBidirectional Encoder Representations from Transformers (BERT) [24],\nGenerativePre-training Transformer (GPT-2) [94], Multi-task Deep Neural Network\n(MT-DNN) [73], Extra-Long Network (XLNet) [134], Text-to-text transfer\ntransformer (T5) [95], T-NLG [98] and GShard [63]. But these models are\nhumongous in size. On the other hand,real world applications demand small model\nsize, low response times and low computational power wattage. In this survey,\nwediscuss six different types of methods (Pruning, Quantization, Knowledge\nDistillation, Parameter Sharing, Tensor Decomposition, andSub-quadratic\nTransformer based methods) for compression of such models to enable their\ndeployment in real industry NLP projects.Given the critical need of building\napplications with efficient and small models, and the large amount of recently\npublished work inthis area, we believe that this survey organizes the plethora\nof work done by the 'deep learning for NLP' community in the past fewyears and\npresents it as a coherent story.", "published": "2020-08-12 10:42:14", "link": "http://arxiv.org/abs/2008.05221v4", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Profiling Gas Consumption in Solidity Smart Contracts", "abstract": "Nowadays, more and more applications are developed for running on a\ndistributed ledger technology, namely dApps. The business logic of dApps is\nusually implemented within smart contracts developed through Solidity, a\nprogramming language for writing smart contracts on different blockchain\nplatforms, including the popular Ethereum. In Ethereum, the smart contracts run\non the machines of miners and the gas corresponds to the execution fee\ncompensating such computing resources. However, the deployment and execution\ncosts of a smart contract depend on the implementation choices done by\ndevelopers. Unappropriated design choices could lead to higher gas consumption\nthan necessary. In this paper, we (i) identify a set of 19 Solidity code smells\naffecting the deployment and transaction costs of a smart contract, and (ii)\nassess the relevance of such smells through a survey involving 34 participants.\nOn top of these smells, we propose GasMet, a suite of metrics for statically\nevaluating the code quality of a smart contract from the gas consumption\nperspective. An experiment involving 2,186 smart contracts demonstrates that\nthe proposed metrics have direct associations with deployment costs. The\nmetrics in our suite can be used for more easily identifying source code\nsegments that need optimizations.", "published": "2020-08-12 17:26:55", "link": "http://arxiv.org/abs/2008.05449v3", "categories": ["cs.SE", "cs.CL", "cs.CR"], "primary_category": "cs.SE"}
{"title": "Online Automatic Speech Recognition with Listen, Attend and Spell Model", "abstract": "The Listen, Attend and Spell (LAS) model and other attention-based automatic\nspeech recognition (ASR) models have known limitations when operated in a fully\nonline mode. In this paper, we analyze the online operation of LAS models to\ndemonstrate that these limitations stem from the handling of silence regions\nand the reliability of online attention mechanism at the edge of input buffers.\nWe propose a novel and simple technique that can achieve fully online\nrecognition while meeting accuracy and latency targets. For the Mandarin\ndictation task, our proposed approach can achieve a character error rate in\nonline operation that is within 4% relative to an offline LAS model. The\nproposed online LAS model operates at 12% lower latency relative to a\nconventional neural network hidden Markov model hybrid of comparable accuracy.\nWe have validated the proposed method through a production scale deployment,\nwhich, to the best of our knowledge, is the first such deployment of a fully\nonline LAS model.", "published": "2020-08-12 18:18:54", "link": "http://arxiv.org/abs/2008.05514v2", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "End-to-End Neural Transformer Based Spoken Language Understanding", "abstract": "Spoken language understanding (SLU) refers to the process of inferring the\nsemantic information from audio signals. While the neural transformers\nconsistently deliver the best performance among the state-of-the-art neural\narchitectures in field of natural language processing (NLP), their merits in a\nclosely related field, i.e., spoken language understanding (SLU) have not beed\ninvestigated. In this paper, we introduce an end-to-end neural\ntransformer-based SLU model that can predict the variable-length domain,\nintent, and slots vectors embedded in an audio signal with no intermediate\ntoken prediction architecture. This new architecture leverages the\nself-attention mechanism by which the audio signal is transformed to various\nsub-subspaces allowing to extract the semantic context implied by an utterance.\nOur end-to-end transformer SLU predicts the domains, intents and slots in the\nFluent Speech Commands dataset with accuracy equal to 98.1 \\%, 99.6 \\%, and\n99.6 \\%, respectively and outperforms the SLU models that leverage a\ncombination of recurrent and convolutional neural networks by 1.4 \\% while the\nsize of our model is 25\\% smaller than that of these architectures.\nAdditionally, due to independent sub-space projections in the self-attention\nlayer, the model is highly parallelizable which makes it a good candidate for\non-device SLU.", "published": "2020-08-12 22:58:20", "link": "http://arxiv.org/abs/2008.10984v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Neural Topic Model via Optimal Transport", "abstract": "Recently, Neural Topic Models (NTMs) inspired by variational autoencoders\nhave obtained increasingly research interest due to their promising results on\ntext analysis. However, it is usually hard for existing NTMs to achieve good\ndocument representation and coherent/diverse topics at the same time. Moreover,\nthey often degrade their performance severely on short documents. The\nrequirement of reparameterisation could also comprise their training quality\nand model flexibility. To address these shortcomings, we present a new neural\ntopic model via the theory of optimal transport (OT). Specifically, we propose\nto learn the topic distribution of a document by directly minimising its OT\ndistance to the document's word distributions. Importantly, the cost matrix of\nthe OT distance models the weights between topics and words, which is\nconstructed by the distances between topics and words in an embedding space.\nOur proposed model can be trained efficiently with a differentiable loss.\nExtensive experiments show that our framework significantly outperforms the\nstate-of-the-art NTMs on discovering more coherent and diverse topics and\nderiving better document representations for both regular and short texts.", "published": "2020-08-12 06:37:09", "link": "http://arxiv.org/abs/2008.13537v3", "categories": ["cs.IR", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.IR"}
{"title": "Channel-wise Subband Input for Better Voice and Accompaniment Separation\n  on High Resolution Music", "abstract": "This paper presents a new input format, channel-wise subband input (CWS), for\nconvolutional neural networks (CNN) based music source separation (MSS) models\nin the frequency domain. We aim to address the major issues in CNN-based\nhigh-resolution MSS model: high computational cost and weight sharing between\ndistinctly different bands. Specifically, in this paper, we decompose the input\nmixture spectra into several bands and concatenate them channel-wise as the\nmodel input. The proposed approach enables effective weight sharing in each\nsubband and introduces more flexibility between channels. For comparison\npurposes, we perform voice and accompaniment separation (VAS) on models with\ndifferent scales, architectures, and CWS settings. Experiments show that the\nCWS input is beneficial in many aspects. We evaluate our method on musdb18hq\ntest set, focusing on SDR, SIR and SAR metrics. Among all our experiments, CWS\nenables models to obtain 6.9% performance gain on the average metrics. With\neven a smaller number of parameters, less training data, and shorter training\ntime, our MDenseNet with 8-bands CWS input still surpasses the original\nMMDenseNet with a large margin. Moreover, CWS also reduces computational cost\nand training time to a large extent.", "published": "2020-08-12 10:26:08", "link": "http://arxiv.org/abs/2008.05216v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Emotion Profile Refinery for Speech Emotion Classification", "abstract": "Human emotions are inherently ambiguous and impure. When designing systems to\nanticipate human emotions based on speech, the lack of emotional purity must be\nconsidered. However, most of the current methods for speech emotion\nclassification rest on the consensus, e.g., one single hard label for an\nutterance. This labeling principle imposes challenges for system performance\nconsidering emotional impurity. In this paper, we recommend the use of\nemotional profiles (EPs), which provides a time series of segment-level soft\nlabels to capture the subtle blends of emotional cues present across a specific\nspeech utterance. We further propose the emotion profile refinery (EPR), an\niterative procedure to update EPs. The EPR method produces soft,\ndynamically-generated, multiple probabilistic class labels during successive\nstages of refinement, which results in significant improvements in the model\naccuracy. Experiments on three well-known emotion corpora show noticeable gain\nusing the proposed method.", "published": "2020-08-12 12:09:58", "link": "http://arxiv.org/abs/2008.05259v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Mask Detection and Breath Monitoring from Speech: on Data Augmentation,\n  Feature Representation and Modeling", "abstract": "This paper introduces our approaches for the Mask and Breathing Sub-Challenge\nin the Interspeech COMPARE Challenge 2020. For the mask detection task, we\ntrain deep convolutional neural networks with filter-bank energies,\ngender-aware features, and speaker-aware features. Support Vector Machines\nfollows as the back-end classifiers for binary prediction on the extracted deep\nembeddings. Several data augmentation schemes are used to increase the quantity\nof training data and improve our models' robustness, including speed\nperturbation, SpecAugment, and random erasing. For the speech breath monitoring\ntask, we investigate different bottleneck features based on the Bi-LSTM\nstructure. Experimental results show that our proposed methods outperform the\nbaselines and achieve 0.746 PCC and 78.8% UAR on the Breathing and Mask\nevaluation set, respectively.", "published": "2020-08-12 08:42:50", "link": "http://arxiv.org/abs/2008.05175v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Improving Stability of LS-GANs for Audio and Speech Signals", "abstract": "In this paper we address the instability issue of generative adversarial\nnetwork (GAN) by proposing a new similarity metric in unitary space of Schur\ndecomposition for 2D representations of audio and speech signals. We show that\nencoding departure from normality computed in this vector space into the\ngenerator optimization formulation helps to craft more comprehensive\nspectrograms. We demonstrate the effectiveness of binding this metric for\nenhancing stability in training with less mode collapse compared to baseline\nGANs. Experimental results on subsets of UrbanSound8k and Mozilla common voice\ndatasets have shown considerable improvements on the quality of the generated\nsamples measured by the Fr\\'echet inception distance. Moreover, reconstructed\nsignals from these samples, have achieved higher signal to noise ratio compared\nto regular LS-GANs.", "published": "2020-08-12 17:41:25", "link": "http://arxiv.org/abs/2008.05454v1", "categories": ["cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "On Mean Absolute Error for Deep Neural Network Based Vector-to-Vector\n  Regression", "abstract": "In this paper, we exploit the properties of mean absolute error (MAE) as a\nloss function for the deep neural network (DNN) based vector-to-vector\nregression. The goal of this work is two-fold: (i) presenting performance\nbounds of MAE, and (ii) demonstrating new properties of MAE that make it more\nappropriate than mean squared error (MSE) as a loss function for DNN based\nvector-to-vector regression. First, we show that a generalized upper-bound for\nDNN-based vector- to-vector regression can be ensured by leveraging the known\nLipschitz continuity property of MAE. Next, we derive a new generalized upper\nbound in the presence of additive noise. Finally, in contrast to conventional\nMSE commonly adopted to approximate Gaussian errors for regression, we show\nthat MAE can be interpreted as an error modeled by Laplacian distribution.\nSpeech enhancement experiments are conducted to corroborate our proposed\ntheorems and validate the performance advantages of MAE over MSE for DNN based\nregression.", "published": "2020-08-12 22:41:26", "link": "http://arxiv.org/abs/2008.07281v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "eess.SP", "stat.ML"], "primary_category": "eess.AS"}
