{"title": "Learning Semantically and Additively Compositional Distributional\n  Representations", "abstract": "This paper connects a vector-based composition model to a formal semantics,\nthe Dependency-based Compositional Semantics (DCS). We show theoretical\nevidence that the vector compositions in our model conform to the logic of DCS.\nExperimentally, we show that vector-based composition brings a strong ability\nto calculate similar phrases as similar vectors, achieving near\nstate-of-the-art on a wide range of phrase similarity tasks and relation\nclassification; meanwhile, DCS can guide building vectors for structured\nqueries that can be directly executed. We evaluate this utility on sentence\ncompletion task and report a new state-of-the-art.", "published": "2016-06-08 09:12:17", "link": "http://arxiv.org/abs/1606.02461v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DefExt: A Semi Supervised Definition Extraction Tool", "abstract": "We present DefExt, an easy to use semi supervised Definition Extraction Tool.\nDefExt is designed to extract from a target corpus those textual fragments\nwhere a term is explicitly mentioned together with its core features, i.e. its\ndefinition. It works on the back of a Conditional Random Fields based\nsequential labeling algorithm and a bootstrapping approach. Bootstrapping\nenables the model to gradually become more aware of the idiosyncrasies of the\ntarget corpus. In this paper we describe the main components of the toolkit as\nwell as experimental results stemming from both automatic and manual\nevaluation. We release DefExt as open source along with the necessary files to\nrun it in any Unix machine. We also provide access to training and test data\nfor immediate use.", "published": "2016-06-08 11:22:12", "link": "http://arxiv.org/abs/1606.02514v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Coordination Annotation Extension in the Penn Tree Bank", "abstract": "Coordination is an important and common syntactic construction which is not\nhandled well by state of the art parsers. Coordinations in the Penn Treebank\nare missing internal structure in many cases, do not include explicit marking\nof the conjuncts and contain various errors and inconsistencies. In this work,\nwe initiated manual annotation process for solving these issues. We identify\nthe different elements in a coordination phrase and label each element with its\nfunction. We add phrase boundaries when these are missing, unify\ninconsistencies, and fix errors. The outcome is an extension of the PTB that\nincludes consistent and detailed structures for coordinations. We make the\ncoordination annotation publicly available, in hope that they will facilitate\nfurther research into coordination disambiguation.", "published": "2016-06-08 12:44:51", "link": "http://arxiv.org/abs/1606.02529v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Joint Model for Word Embedding and Word Morphology", "abstract": "This paper presents a joint model for performing unsupervised morphological\nanalysis on words, and learning a character-level composition function from\nmorphemes to word embeddings. Our model splits individual words into segments,\nand weights each segment according to its ability to predict context words. Our\nmorphological analysis is comparable to dedicated morphological analyzers at\nthe task of morpheme boundary recovery, and also performs better than\nword-based embedding models at the task of syntactic analogy answering.\nFinally, we show that incorporating morphology explicitly into character-level\nmodels help them produce embeddings for unseen words which correlate better\nwith human judgments.", "published": "2016-06-08 15:24:22", "link": "http://arxiv.org/abs/1606.02601v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Addressing Limited Data for Textual Entailment Across Domains", "abstract": "We seek to address the lack of labeled data (and high cost of annotation) for\ntextual entailment in some domains. To that end, we first create (for\nexperimental purposes) an entailment dataset for the clinical domain, and a\nhighly competitive supervised entailment system, ENT, that is effective (out of\nthe box) on two domains. We then explore self-training and active learning\nstrategies to address the lack of labeled data. With self-training, we\nsuccessfully exploit unlabeled data to improve over ENT by 15% F-score on the\nnewswire domain, and 13% F-score on clinical data. On the other hand, our\nactive learning experiments demonstrate that we can match (and even beat) ENT\nusing only 6.6% of the training data in the clinical domain, and only 5.8% of\nthe training data in the newswire domain.", "published": "2016-06-08 16:56:19", "link": "http://arxiv.org/abs/1606.02638v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "First Result on Arabic Neural Machine Translation", "abstract": "Neural machine translation has become a major alternative to widely used\nphrase-based statistical machine translation. We notice however that much of\nresearch on neural machine translation has focused on European languages\ndespite its language agnostic nature. In this paper, we apply neural machine\ntranslation to the task of Arabic translation (Ar<->En) and compare it against\na standard phrase-based translation system. We run extensive comparison using\nvarious configurations in preprocessing Arabic script and show that the\nphrase-based and neural translation systems perform comparably to each other\nand that proper preprocessing of Arabic script has a similar effect on both of\nthe systems. We however observe that the neural machine translation\nsignificantly outperform the phrase-based system on an out-of-domain test set,\nmaking it attractive for real-world deployment.", "published": "2016-06-08 18:36:09", "link": "http://arxiv.org/abs/1606.02680v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Language Games through Interaction", "abstract": "We introduce a new language learning setting relevant to building adaptive\nnatural language interfaces. It is inspired by Wittgenstein's language games: a\nhuman wishes to accomplish some task (e.g., achieving a certain configuration\nof blocks), but can only communicate with a computer, who performs the actual\nactions (e.g., removing all red blocks). The computer initially knows nothing\nabout language and therefore must learn it from scratch through interaction,\nwhile the human adapts to the computer's capabilities. We created a game in a\nblocks world and collected interactions from 100 people playing it. First, we\nanalyze the humans' strategies, showing that using compositionality and\navoiding synonyms correlates positively with task performance. Second, we\ncompare computer strategies, showing how to quickly learn a semantic parsing\nmodel from scratch, and that modeling pragmatics further accelerates learning\nfor successful players.", "published": "2016-06-08 08:27:09", "link": "http://arxiv.org/abs/1606.02447v1", "categories": ["cs.CL", "cs.AI", "I.2.6; I.2.7"], "primary_category": "cs.CL"}
{"title": "DialPort: Connecting the Spoken Dialog Research Community to Real User\n  Data", "abstract": "This paper describes a new spoken dialog portal that connects systems\nproduced by the spoken dialog academic research community and gives them access\nto real users. We introduce a distributed, multi-modal, multi-agent prototype\ndialog framework that affords easy integration with various remote resources,\nranging from end-to-end dialog systems to external knowledge APIs. To date, the\nDialPort portal has successfully connected to the multi-domain spoken dialog\nsystem at Cambridge University, the NOAA (National Oceanic and Atmospheric\nAdministration) weather API and the Yelp API.", "published": "2016-06-08 14:08:21", "link": "http://arxiv.org/abs/1606.02562v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Continuously Learning Neural Dialogue Management", "abstract": "We describe a two-step approach for dialogue management in task-oriented\nspoken dialogue systems. A unified neural network framework is proposed to\nenable the system to first learn by supervision from a set of dialogue data and\nthen continuously improve its behaviour via reinforcement learning, all using\ngradient-based algorithms on one single model. The experiments demonstrate the\nsupervised model's effectiveness in the corpus-based evaluation, with user\nsimulation, and with paid human subjects. The use of reinforcement learning\nfurther improves the model's performance in both interactive settings,\nespecially under higher-noise conditions.", "published": "2016-06-08 19:03:06", "link": "http://arxiv.org/abs/1606.02689v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On the Place of Text Data in Lifelogs, and Text Analysis via Semantic\n  Facets", "abstract": "Current research in lifelog data has not paid enough attention to analysis of\ncognitive activities in comparison to physical activities. We argue that as we\nlook into the future, wearable devices are going to be cheaper and more\nprevalent and textual data will play a more significant role. Data captured by\nlifelogging devices will increasingly include speech and text, potentially\nuseful in analysis of intellectual activities. Analyzing what a person hears,\nreads, and sees, we should be able to measure the extent of cognitive activity\ndevoted to a certain topic or subject by a learner. Test-based lifelog records\ncan benefit from semantic analysis tools developed for natural language\nprocessing. We show how semantic analysis of such text data can be achieved\nthrough the use of taxonomic subject facets and how these facets might be\nuseful in quantifying cognitive activity devoted to various topics in a\nperson's day. We are currently developing a method to automatically create\ntaxonomic topic vocabularies that can be applied to this detection of\nintellectual activity.", "published": "2016-06-08 08:11:54", "link": "http://arxiv.org/abs/1606.02440v1", "categories": ["cs.CL", "cs.CY", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Improving Recurrent Neural Networks For Sequence Labelling", "abstract": "In this paper we study different types of Recurrent Neural Networks (RNN) for\nsequence labeling tasks. We propose two new variants of RNNs integrating\nimprovements for sequence labeling, and we compare them to the more traditional\nElman and Jordan RNNs. We compare all models, either traditional or new, on\nfour distinct tasks of sequence labeling: two on Spoken Language Understanding\n(ATIS and MEDIA); and two of POS tagging for the French Treebank (FTB) and the\nPenn Treebank (PTB) corpora. The results show that our new variants of RNNs are\nalways more effective than the others.", "published": "2016-06-08 13:47:18", "link": "http://arxiv.org/abs/1606.02555v1", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Towards End-to-End Learning for Dialog State Tracking and Management\n  using Deep Reinforcement Learning", "abstract": "This paper presents an end-to-end framework for task-oriented dialog systems\nusing a variant of Deep Recurrent Q-Networks (DRQN). The model is able to\ninterface with a relational database and jointly learn policies for both\nlanguage understanding and dialog strategy. Moreover, we propose a hybrid\nalgorithm that combines the strength of reinforcement learning and supervised\nlearning to achieve faster learning speed. We evaluated the proposed model on a\n20 Question Game conversational game simulator. Results show that the proposed\nmethod outperforms the modular-based baseline and learns a distributed\nrepresentation of the latent dialog state.", "published": "2016-06-08 14:03:25", "link": "http://arxiv.org/abs/1606.02560v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
