{"title": "Quality expectations of machine translation", "abstract": "Machine Translation (MT) is being deployed for a range of use-cases by\nmillions of people on a daily basis. There should, therefore, be no doubt as to\nthe utility of MT. However, not everyone is convinced that MT can be useful,\nespecially as a productivity enhancer for human translators. In this chapter, I\naddress this issue, describing how MT is currently deployed, how its output is\nevaluated and how this could be enhanced, especially as MT quality itself\nimproves. Central to these issues is the acceptance that there is no longer a\nsingle 'gold standard' measure of quality, such that the situation in which MT\nis deployed needs to be borne in mind, especially with respect to the expected\n'shelf-life' of the translation itself.", "published": "2018-03-22 15:31:39", "link": "http://arxiv.org/abs/1803.08409v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Feature-Based Model for Nested Named-Entity Recognition at VLSP-2018\n  NER Evaluation Campaign", "abstract": "In this report, we describe our participant named-entity recognition system\nat VLSP 2018 evaluation campaign. We formalized the task as a sequence labeling\nproblem using BIO encoding scheme. We applied a feature-based model which\ncombines word, word-shape features, Brown-cluster-based features, and\nword-embedding-based features. We compare several methods to deal with nested\nentities in the dataset. We showed that combining tags of entities at all\nlevels for training a sequence labeling model (joint-tag model) improved the\naccuracy of nested named-entity recognition.", "published": "2018-03-22 17:04:32", "link": "http://arxiv.org/abs/1803.08463v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contextual Salience for Fast and Accurate Sentence Vectors", "abstract": "Unsupervised vector representations of sentences or documents are a major\nbuilding block for many language tasks such as sentiment classification.\nHowever, current methods are uninterpretable and slow or require large training\ndatasets. Recent word vector-based proposals implicitly assume that distances\nin a word embedding space are equally important, regardless of context. We\nintroduce contextual salience (CoSal), a measure of word importance that uses\nthe distribution of context vectors to normalize distances and weights. CoSal\nrelies on the insight that unusual word vectors disproportionately affect\nphrase vectors. A bag-of-words model with CoSal-based weights produces accurate\nunsupervised sentence or document representations for classification, requiring\nlittle computation to evaluate and only a single covariance calculation to\n``train.\" CoSal supports small contexts, out-of context words and outperforms\nSkipThought on most benchmarks, beats tf-idf on all benchmarks, and is\ncompetitive with the unsupervised state-of-the-art.", "published": "2018-03-22 17:54:21", "link": "http://arxiv.org/abs/1803.08493v6", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "MultiBooked: A Corpus of Basque and Catalan Hotel Reviews Annotated for\n  Aspect-level Sentiment Classification", "abstract": "While sentiment analysis has become an established field in the NLP\ncommunity, research into languages other than English has been hindered by the\nlack of resources. Although much research in multi-lingual and cross-lingual\nsentiment analysis has focused on unsupervised or semi-supervised approaches,\nthese still require a large number of resources and do not reach the\nperformance of supervised approaches. With this in mind, we introduce two\ndatasets for supervised aspect-level sentiment analysis in Basque and Catalan,\nboth of which are under-resourced languages. We provide high-quality\nannotations and benchmarks with the hope that they will be useful to the\ngrowing community of researchers working on these languages.", "published": "2018-03-22 23:46:22", "link": "http://arxiv.org/abs/1803.08614v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Entrenamiento de una red neuronal para el reconocimiento de imagenes de\n  lengua de senas capturadas con sensores de profundidad", "abstract": "Due to the growth of the population with hearing problems, devices have been\ndeveloped that facilitate the inclusion of deaf people in society, using\ntechnology as a communication tool, such as vision systems. Then, a solution to\nthis problem is presented using neural networks and autoencoders for the\nclassification of American Sign Language images. As a result, 99.5% accuracy\nand an error of 0.01684 were obtained for image classification", "published": "2018-03-22 05:40:28", "link": "http://arxiv.org/abs/1804.00508v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "The Rapidly Changing Landscape of Conversational Agents", "abstract": "Conversational agents have become ubiquitous, ranging from goal-oriented\nsystems for helping with reservations to chit-chat models found in modern\nvirtual assistants. In this survey paper, we explore this fascinating field. We\nlook at some of the pioneering work that defined the field and gradually move\nto the current state-of-the-art models. We look at statistical, neural,\ngenerative adversarial network based and reinforcement learning based\napproaches and how they evolved. Along the way we discuss various challenges\nthat the field faces, lack of context in utterances, not having a good\nquantitative metric to compare models, lack of trust in agents because they do\nnot have a consistent persona etc. We structure this paper in a way that\nanswers these pertinent questions and discusses competing approaches to solve\nthem.", "published": "2018-03-22 15:53:59", "link": "http://arxiv.org/abs/1803.08419v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Word sense induction using word embeddings and community detection in\n  complex networks", "abstract": "Word Sense Induction (WSI) is the ability to automatically induce word senses\nfrom corpora. The WSI task was first proposed to overcome the limitations of\nmanually annotated corpus that are required in word sense disambiguation\nsystems. Even though several works have been proposed to induce word senses,\nexisting systems are still very limited in the sense that they make use of\nstructured, domain-specific knowledge sources. In this paper, we devise a\nmethod that leverages recent findings in word embeddings research to generate\ncontext embeddings, which are embeddings containing information about the\nsemantical context of a word. In order to induce senses, we modeled the set of\nambiguous words as a complex network. In the generated network, two instances\n(nodes) are connected if the respective context embeddings are similar. Upon\nusing well-established community detection methods to cluster the obtained\ncontext embeddings, we found that the proposed method yields excellent\nperformance for the WSI task. Our method outperformed competing algorithms and\nbaselines, in a completely unsupervised manner and without the need of any\nadditional structured knowledge source.", "published": "2018-03-22 17:22:42", "link": "http://arxiv.org/abs/1803.08476v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "An Analysis of Neural Language Modeling at Multiple Scales", "abstract": "Many of the leading approaches in language modeling introduce novel, complex\nand specialized architectures. We take existing state-of-the-art word level\nlanguage models based on LSTMs and QRNNs and extend them to both larger\nvocabularies as well as character-level granularity. When properly tuned, LSTMs\nand QRNNs achieve state-of-the-art results on character-level (Penn Treebank,\nenwik8) and word-level (WikiText-103) datasets, respectively. Results are\nobtained in only 12 hours (WikiText-103) to 2 days (enwik8) using a single\nmodern GPU.", "published": "2018-03-22 06:25:47", "link": "http://arxiv.org/abs/1803.08240v1", "categories": ["cs.CL", "cs.AI", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Learning Eligibility in Cancer Clinical Trials using Deep Neural\n  Networks", "abstract": "Interventional cancer clinical trials are generally too restrictive, and some\npatients are often excluded on the basis of comorbidity, past or concomitant\ntreatments, or the fact that they are over a certain age. The efficacy and\nsafety of new treatments for patients with these characteristics are,\ntherefore, not defined. In this work, we built a model to automatically predict\nwhether short clinical statements were considered inclusion or exclusion\ncriteria. We used protocols from cancer clinical trials that were available in\npublic registries from the last 18 years to train word-embeddings, and we\nconstructed a~dataset of 6M short free-texts labeled as eligible or not\neligible. A text classifier was trained using deep neural networks, with\npre-trained word-embeddings as inputs, to predict whether or not short\nfree-text statements describing clinical information were considered eligible.\nWe additionally analyzed the semantic reasoning of the word-embedding\nrepresentations obtained and were able to identify equivalent treatments for a\ntype of tumor analogous with the drugs used to treat other tumors. We show that\nrepresentation learning using {deep} neural networks can be successfully\nleveraged to extract the medical knowledge from clinical trial protocols for\npotentially assisting practitioners when prescribing treatments.", "published": "2018-03-22 11:38:53", "link": "http://arxiv.org/abs/1803.08312v3", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Sentiment Analysis of Comments on Rohingya Movement with Support Vector\n  Machine", "abstract": "The Rohingya Movement and Crisis caused a huge uproar in the political and\neconomic state of Bangladesh. Refugee movement is a recurring event and a large\namount of data in the form of opinions remains on social media such as\nFacebook, with very little analysis done on them.To analyse the comments based\non all Rohingya related posts, we had to create and modify a classifier based\non the Support Vector Machine algorithm. The code is implemented in python and\nuses scikit-learn library. A dataset on Rohingya analysis is not currently\navailable so we had to use our own data set of 2500 positive and 2500 negative\ncomments. We specifically used a support vector machine with linear kernel. A\nprevious experiment was performed by us on the same dataset using the naive\nbayes algorithm, but that did not yield impressive results.", "published": "2018-03-22 15:30:03", "link": "http://arxiv.org/abs/1803.08790v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Locally Private Bayesian Inference for Count Models", "abstract": "We present a general method for privacy-preserving Bayesian inference in\nPoisson factorization, a broad class of models that includes some of the most\nwidely used models in the social sciences. Our method satisfies limited\nprecision local privacy, a generalization of local differential privacy, which\nwe introduce to formulate privacy guarantees appropriate for sparse count data.\nWe develop an MCMC algorithm that approximates the locally private posterior\nover model parameters given data that has been locally privatized by the\ngeometric mechanism (Ghosh et al., 2012). Our solution is based on two\ninsights: 1) a novel reinterpretation of the geometric mechanism in terms of\nthe Skellam distribution (Skellam, 1946) and 2) a general theorem that relates\nthe Skellam to the Bessel distribution (Yuan & Kalbfleisch, 2000). We\ndemonstrate our method in two case studies on real-world email data in which we\nshow that our method consistently outperforms the commonly-used naive approach,\nobtaining higher quality topics in text and more accurate link prediction in\nnetworks. On some tasks, our privacy-preserving method even outperforms\nnon-private inference which conditions on the true data.", "published": "2018-03-22 17:14:29", "link": "http://arxiv.org/abs/1803.08471v3", "categories": ["stat.ML", "cs.CL", "cs.CR", "cs.LG", "cs.SI"], "primary_category": "stat.ML"}
{"title": "Speech Dereverberation Using Fully Convolutional Networks", "abstract": "Speech derverberation using a single microphone is addressed in this paper.\nMotivated by the recent success of the fully convolutional networks (FCN) in\nmany image processing applications, we investigate their applicability to\nenhance the speech signal represented by short-time Fourier transform (STFT)\nimages. We present two variations: a \"U-Net\" which is an encoder-decoder\nnetwork with skip connections and a generative adversarial network (GAN) with\nU-Net as generator, which yields a more intuitive cost function for training.\nTo evaluate our method we used the data from the REVERB challenge, and compared\nour results to other methods under the same conditions. We have found that our\nmethod outperforms the competing methods in most cases.", "published": "2018-03-22 06:33:04", "link": "http://arxiv.org/abs/1803.08243v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Speaker Clustering With Neural Networks And Audio Processing", "abstract": "Speaker clustering is the task of differentiating speakers in a recording. In\na way, the aim is to answer \"who spoke when\" in audio recordings. A common\nmethod used in industry is feature extraction directly from the recording\nthanks to MFCC features, and by using well-known techniques such as Gaussian\nMixture Models (GMM) and Hidden Markov Models (HMM). In this paper, we studied\nneural networks (especially CNN) followed by clustering and audio processing in\nthe quest to reach similar accuracy to state-of-the-art methods.", "published": "2018-03-22 09:21:56", "link": "http://arxiv.org/abs/1803.08276v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
