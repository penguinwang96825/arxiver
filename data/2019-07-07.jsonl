{"title": "Joint Lifelong Topic Model and Manifold Ranking for Document\n  Summarization", "abstract": "Due to the manifold ranking method has a significant effect on the ranking of\nunknown data based on known data by using a weighted network, many researchers\nuse the manifold ranking method to solve the document summarization task.\nHowever, their models only consider the original features but ignore the\nsemantic features of sentences when they construct the weighted networks for\nthe manifold ranking method. To solve this problem, we proposed two improved\nmodels based on the manifold ranking method. One is combining the topic model\nand manifold ranking method (JTMMR) to solve the document summarization task.\nThis model not only uses the original feature, but also uses the semantic\nfeature to represent the document, which can improve the accuracy of the\nmanifold ranking method. The other one is combining the lifelong topic model\nand manifold ranking method (JLTMMR). On the basis of the JTMMR, this model\nadds the constraint of knowledge to improve the quality of the topic. At the\nsame time, we also add the constraint of the relationship between documents to\ndig out a better document semantic features. The JTMMR model can improve the\neffect of the manifold ranking method by using the better semantic feature.\nExperiments show that our models can achieve a better result than other\nbaseline models for multi-document summarization task. At the same time, our\nmodels also have a good performance on the single document summarization task.\nAfter combining with a few basic surface features, our model significantly\noutperforms some model based on deep learning in recent years. After that, we\nalso do an exploring work for lifelong machine learning by analyzing the effect\nof adding feedback. Experiments show that the effect of adding feedback to our\nmodel is significant.", "published": "2019-07-07 05:41:55", "link": "http://arxiv.org/abs/1907.03224v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Graph based Neural Networks for Event Factuality Prediction using\n  Syntactic and Semantic Structures", "abstract": "Event factuality prediction (EFP) is the task of assessing the degree to\nwhich an event mentioned in a sentence has happened. For this task, both\nsyntactic and semantic information are crucial to identify the important\ncontext words. The previous work for EFP has only combined these information in\na simple way that cannot fully exploit their coordination. In this work, we\nintroduce a novel graph-based neural network for EFP that can integrate the\nsemantic and syntactic information more effectively. Our experiments\ndemonstrate the advantage of the proposed model for EFP.", "published": "2019-07-07 06:02:05", "link": "http://arxiv.org/abs/1907.03227v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Zero-Shot Open Entity Typing as Type-Compatible Grounding", "abstract": "The problem of entity-typing has been studied predominantly in supervised\nlearning fashion, mostly with task-specific annotations (for coarse types) and\nsometimes with distant supervision (for fine types). While such approaches have\nstrong performance within datasets, they often lack the flexibility to transfer\nacross text genres and to generalize to new type taxonomies. In this work we\npropose a zero-shot entity typing approach that requires no annotated data and\ncan flexibly identify newly defined types. Given a type taxonomy defined as\nBoolean functions of FREEBASE \"types\", we ground a given mention to a set of\ntype-compatible Wikipedia entries and then infer the target mention's types\nusing an inference algorithm that makes use of the types of these entries. We\nevaluate our system on a broad range of datasets, including standard\nfine-grained and coarse-grained entity typing datasets, and also a dataset in\nthe biological domain. Our system is shown to be competitive with\nstate-of-the-art supervised NER systems and outperforms them on out-of-domain\ndatasets. We also show that our system significantly outperforms other\nzero-shot fine typing systems.", "published": "2019-07-07 06:05:56", "link": "http://arxiv.org/abs/1907.03228v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Cross-Domain Performance for Relation Extraction via\n  Dependency Prediction and Information Flow Control", "abstract": "Relation Extraction (RE) is one of the fundamental tasks in Information\nExtraction and Natural Language Processing. Dependency trees have been shown to\nbe a very useful source of information for this task. The current deep learning\nmodels for relation extraction has mainly exploited this dependency information\nby guiding their computation along the structures of the dependency trees. One\npotential problem with this approach is it might prevent the models from\ncapturing important context information beyond syntactic structures and cause\nthe poor cross-domain generalization. This paper introduces a novel method to\nuse dependency trees in RE for deep learning models that jointly predicts\ndependency and semantics relations. We also propose a new mechanism to control\nthe information flow in the model based on the input entity mentions. Our\nextensive experiments on benchmark datasets show that the proposed model\noutperforms the existing methods for RE significantly.", "published": "2019-07-07 06:21:47", "link": "http://arxiv.org/abs/1907.03230v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Informative Visual Storytelling with Cross-modal Rules", "abstract": "Existing methods in the Visual Storytelling field often suffer from the\nproblem of generating general descriptions, while the image contains a lot of\nmeaningful contents remaining unnoticed. The failure of informative story\ngeneration can be concluded to the model's incompetence of capturing enough\nmeaningful concepts. The categories of these concepts include entities,\nattributes, actions, and events, which are in some cases crucial to grounded\nstorytelling. To solve this problem, we propose a method to mine the\ncross-modal rules to help the model infer these informative concepts given\ncertain visual input. We first build the multimodal transactions by\nconcatenating the CNN activations and the word indices. Then we use the\nassociation rule mining algorithm to mine the cross-modal rules, which will be\nused for the concept inference. With the help of the cross-modal rules, the\ngenerated stories are more grounded and informative. Besides, our proposed\nmethod holds the advantages of interpretation, expandability, and\ntransferability, indicating potential for wider application. Finally, we\nleverage these concepts in our encoder-decoder framework with the attention\nmechanism. We conduct several experiments on the VIsual StoryTelling~(VIST)\ndataset, the results of which demonstrate the effectiveness of our approach in\nterms of both automatic metrics and human evaluation. Additional experiments\nare also conducted showing that our mined cross-modal rules as additional\nknowledge helps the model gain better performance when trained on a small\ndataset.", "published": "2019-07-07 07:41:59", "link": "http://arxiv.org/abs/1907.03240v2", "categories": ["cs.MM", "cs.CL", "H.5.1"], "primary_category": "cs.MM"}
{"title": "NIESR: Nuisance Invariant End-to-end Speech Recognition", "abstract": "Deep neural network models for speech recognition have achieved great success\nrecently, but they can learn incorrect associations between the target and\nnuisance factors of speech (e.g., speaker identities, background noise, etc.),\nwhich can lead to overfitting. While several methods have been proposed to\ntackle this problem, existing methods incorporate additional information about\nnuisance factors during training to develop invariant models. However,\nenumeration of all possible nuisance factors in speech data and the collection\nof their annotations is difficult and expensive. We present a robust training\nscheme for end-to-end speech recognition that adopts an unsupervised\nadversarial invariance induction framework to separate out essential factors\nfor speech-recognition from nuisances without using any supplementary labels\nbesides the transcriptions. Experiments show that the speech recognition model\ntrained with the proposed training scheme achieves relative improvements of\n5.48% on WSJ0, 6.16% on CHiME3, and 6.61% on TIMIT dataset over the base model.\nAdditionally, the proposed method achieves a relative improvement of 14.44% on\nthe combined WSJ0+CHiME3 dataset.", "published": "2019-07-07 07:03:09", "link": "http://arxiv.org/abs/1907.03233v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Neural Aspect and Opinion Term Extraction with Mined Rules as Weak\n  Supervision", "abstract": "Lack of labeled training data is a major bottleneck for neural network based\naspect and opinion term extraction on product reviews. To alleviate this\nproblem, we first propose an algorithm to automatically mine extraction rules\nfrom existing training examples based on dependency parsing results. The mined\nrules are then applied to label a large amount of auxiliary data. Finally, we\nstudy training procedures to train a neural model which can learn from both the\ndata automatically labeled by the rules and a small amount of data accurately\nannotated by human. Experimental results show that although the mined rules\nthemselves do not perform well due to their limited flexibility, the\ncombination of human annotated data and rule labeled auxiliary data can improve\nthe neural model and allow it to achieve performance better than or comparable\nwith the current state-of-the-art.", "published": "2019-07-07 12:59:04", "link": "http://arxiv.org/abs/1907.03750v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Improving short text classification through global augmentation methods", "abstract": "We study the effect of different approaches to text augmentation. To do this\nwe use 3 datasets that include social media and formal text in the form of news\narticles. Our goal is to provide insights for practitioners and researchers on\nmaking choices for augmentation for classification use cases. We observe that\nWord2vec-based augmentation is a viable option when one does not have access to\na formal synonym model (like WordNet-based augmentation). The use of\n\\emph{mixup} further improves performance of all text based augmentations and\nreduces the effects of overfitting on a tested deep learning model. Round-trip\ntranslation with a translation service proves to be harder to use due to cost\nand as such is less accessible for both normal and low resource use-cases.", "published": "2019-07-07 18:05:12", "link": "http://arxiv.org/abs/1907.03752v2", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Melody Generation using an Interactive Evolutionary Algorithm", "abstract": "Music generation with the aid of computers has been recently grabbed the\nattention of many scientists in the area of artificial intelligence. Deep\nlearning techniques have evolved sequence production methods for this purpose.\nYet, a challenging problem is how to evaluate generated music by a machine. In\nthis paper, a methodology has been developed based upon an interactive\nevolutionary optimization method, with which the scoring of the generated\nmelodies is primarily performed by human expertise, during the training. This\nmusic quality scoring is modeled using a Bi-LSTM recurrent neural network.\nMoreover, the innovative generated melody through a Genetic algorithm will then\nbe evaluated using this Bi-LSTM network. The results of this mechanism clearly\nshow that the proposed method is able to create pleasurable melodies with\ndesired styles and pieces. This method is also quite fast, compared to the\nstate-of-the-art data-oriented evolutionary systems.", "published": "2019-07-07 02:08:25", "link": "http://arxiv.org/abs/1907.04258v1", "categories": ["cs.NE", "cs.SD", "eess.AS"], "primary_category": "cs.NE"}
