{"title": "Semi-supervised Bootstrapping approach for Named Entity Recognition", "abstract": "The aim of Named Entity Recognition (NER) is to identify references of named\nentities in unstructured documents, and to classify them into pre-defined\nsemantic categories. NER often aids from added background knowledge in the form\nof gazetteers. However using such a collection does not deal with name variants\nand cannot resolve ambiguities associated in identifying the entities in\ncontext and associating them with predefined categories. We present a\nsemi-supervised NER approach that starts with identifying named entities with a\nsmall set of training data. Using the identified named entities, the word and\nthe context features are used to define the pattern. This pattern of each named\nentity category is used as a seed pattern to identify the named entities in the\ntest set. Pattern scoring and tuple value score enables the generation of the\nnew patterns to identify the named entity categories. We have evaluated the\nproposed system for English language with the dataset of tagged (IEER) and\nuntagged (CoNLL 2003) named entity corpus and for Tamil language with the\ndocuments from the FIRE corpus and yield an average f-measure of 75% for both\nthe languages.", "published": "2015-11-21 04:11:44", "link": "http://arxiv.org/abs/1511.06833v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Mapping Images to Sentiment Adjective Noun Pairs with Factorized Neural\n  Nets", "abstract": "We consider the visual sentiment task of mapping an image to an adjective\nnoun pair (ANP) such as \"cute baby\". To capture the two-factor structure of our\nANP semantics as well as to overcome annotation noise and ambiguity, we propose\na novel factorized CNN model which learns separate representations for\nadjectives and nouns but optimizes the classification performance over their\nproduct. Our experiments on the publicly available SentiBank dataset show that\nour model significantly outperforms not only independent ANP classifiers on\nunseen ANPs and on retrieving images of novel ANPs, but also image captioning\nmodels which capture word semantics from co-occurrence of natural text; the\nlatter turn out to be surprisingly poor at capturing the sentiment evoked by\npure visual experience. That is, our factorized ANP CNN not only trains better\nfrom noisy labels, generalizes better to new images, but can also expands the\nANP vocabulary on its own.", "published": "2015-11-21 04:58:46", "link": "http://arxiv.org/abs/1511.06838v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Evaluating Prerequisite Qualities for Learning End-to-End Dialog Systems", "abstract": "A long-term goal of machine learning is to build intelligent conversational\nagents. One recent popular approach is to train end-to-end models on a large\namount of real dialog transcripts between humans (Sordoni et al., 2015; Vinyals\n& Le, 2015; Shang et al., 2015). However, this approach leaves many questions\nunanswered as an understanding of the precise successes and shortcomings of\neach model is hard to assess. A contrasting recent proposal are the bAbI tasks\n(Weston et al., 2015b) which are synthetic data that measure the ability of\nlearning machines at various reasoning tasks over toy language. Unfortunately,\nthose tests are very small and hence may encourage methods that do not scale.\nIn this work, we propose a suite of new tasks of a much larger scale that\nattempt to bridge the gap between the two regimes. Choosing the domain of\nmovies, we provide tasks that test the ability of models to answer factual\nquestions (utilizing OMDB), provide personalization (utilizing MovieLens),\ncarry short conversations about the two, and finally to perform on natural\ndialogs from Reddit. We provide a dataset covering 75k movie entities and with\n3.5M training examples. We present results of various models on these tasks,\nand evaluate their performance.", "published": "2015-11-21 22:26:49", "link": "http://arxiv.org/abs/1511.06931v6", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "BlackOut: Speeding up Recurrent Neural Network Language Models With Very\n  Large Vocabularies", "abstract": "We propose BlackOut, an approximation algorithm to efficiently train massive\nrecurrent neural network language models (RNNLMs) with million word\nvocabularies. BlackOut is motivated by using a discriminative loss, and we\ndescribe a new sampling strategy which significantly reduces computation while\nimproving stability, sample efficiency, and rate of convergence. One way to\nunderstand BlackOut is to view it as an extension of the DropOut strategy to\nthe output layer, wherein we use a discriminative training loss and a weighted\nsampling scheme. We also establish close connections between BlackOut,\nimportance sampling, and noise contrastive estimation (NCE). Our experiments,\non the recently released one billion word language modeling benchmark,\ndemonstrate scalability and accuracy of BlackOut; we outperform the\nstate-of-the art, and achieve the lowest perplexity scores on this dataset.\nMoreover, unlike other established methods which typically require GPUs or CPU\nclusters, we show that a carefully implemented version of BlackOut requires\nonly 1-10 days on a single machine to train a RNNLM with a million word\nvocabulary and billions of parameters on one billion words. Although we\ndescribe BlackOut in the context of RNNLM training, it can be used to any\nnetworks with large softmax output layers.", "published": "2015-11-21 17:49:30", "link": "http://arxiv.org/abs/1511.06909v7", "categories": ["cs.LG", "cs.CL", "cs.NE", "stat.ML"], "primary_category": "cs.LG"}
