{"title": "Sentiment Adaptive End-to-End Dialog Systems", "abstract": "End-to-end learning framework is useful for building dialog systems for its\nsimplicity in training and efficiency in model updating. However, current\nend-to-end approaches only consider user semantic inputs in learning and\nunder-utilize other user information. Therefore, we propose to include user\nsentiment obtained through multimodal information (acoustic, dialogic and\ntextual), in the end-to-end learning framework to make systems more\nuser-adaptive and effective. We incorporated user sentiment information in both\nsupervised and reinforcement learning settings. In both settings, adding\nsentiment information reduced the dialog length and improved the task success\nrate on a bus information search task. This work is the first attempt to\nincorporate multimodal user information in the adaptive end-to-end dialog\nsystem training framework and attained state-of-the-art performance.", "published": "2018-04-28 03:29:22", "link": "http://arxiv.org/abs/1804.10731v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Particle Smoothing for Sampling from Conditional Sequence Models", "abstract": "We introduce neural particle smoothing, a sequential Monte Carlo method for\nsampling annotations of an input string from a given probability model. In\ncontrast to conventional particle filtering algorithms, we train a proposal\ndistribution that looks ahead to the end of the input string by means of a\nright-to-left LSTM. We demonstrate that this innovation can improve the quality\nof the sample. To motivate our formal choices, we explain how our neural model\nand neural sampler can be viewed as low-dimensional but nonlinear\napproximations to working with HMMs over very large state spaces.", "published": "2018-04-28 06:10:45", "link": "http://arxiv.org/abs/1804.10747v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Data-Driven Methods for Solving Algebra Word Problems", "abstract": "We explore contemporary, data-driven techniques for solving math word\nproblems over recent large-scale datasets. We show that well-tuned neural\nequation classifiers can outperform more sophisticated models such as sequence\nto sequence and self-attention across these datasets. Our error analysis\nindicates that, while fully data driven models show some promise, semantic and\nworld knowledge is necessary for further advances.", "published": "2018-04-28 01:19:51", "link": "http://arxiv.org/abs/1804.10718v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Syllable-Based Sequence-to-Sequence Speech Recognition with the\n  Transformer in Mandarin Chinese", "abstract": "Sequence-to-sequence attention-based models have recently shown very\npromising results on automatic speech recognition (ASR) tasks, which integrate\nan acoustic, pronunciation and language model into a single neural network. In\nthese models, the Transformer, a new sequence-to-sequence attention-based model\nrelying entirely on self-attention without using RNNs or convolutions, achieves\na new single-model state-of-the-art BLEU on neural machine translation (NMT)\ntasks. Since the outstanding performance of the Transformer, we extend it to\nspeech and concentrate on it as the basic architecture of sequence-to-sequence\nattention-based model on Mandarin Chinese ASR tasks. Furthermore, we\ninvestigate a comparison between syllable based model and context-independent\nphoneme (CI-phoneme) based model with the Transformer in Mandarin Chinese.\nAdditionally, a greedy cascading decoder with the Transformer is proposed for\nmapping CI-phoneme sequences and syllable sequences into word sequences.\nExperiments on HKUST datasets demonstrate that syllable based model with the\nTransformer performs better than CI-phoneme based counterpart, and achieves a\ncharacter error rate (CER) of \\emph{$28.77\\%$}, which is competitive to the\nstate-of-the-art CER of $28.0\\%$ by the joint CTC-attention based\nencoder-decoder network.", "published": "2018-04-28 06:54:11", "link": "http://arxiv.org/abs/1804.10752v2", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Ladder Networks for Emotion Recognition: Using Unsupervised Auxiliary\n  Tasks to Improve Predictions of Emotional Attributes", "abstract": "Recognizing emotions using few attribute dimensions such as arousal, valence\nand dominance provides the flexibility to effectively represent complex range\nof emotional behaviors. Conventional methods to learn these emotional\ndescriptors primarily focus on separate models to recognize each of these\nattributes. Recent work has shown that learning these attributes together\nregularizes the models, leading to better feature representations. This study\nexplores new forms of regularization by adding unsupervised auxiliary tasks to\nreconstruct hidden layer representations. This auxiliary task requires the\ndenoising of hidden representations at every layer of an auto-encoder. The\nframework relies on ladder networks that utilize skip connections between\nencoder and decoder layers to learn powerful representations of emotional\ndimensions. The results show that ladder networks improve the performance of\nthe system compared to baselines that individually learn each attribute, and\nconventional denoising autoencoders. Furthermore, the unsupervised auxiliary\ntasks have promising potential to be used in a semi-supervised setting, where\nfew labeled sentences are available.", "published": "2018-04-28 15:08:41", "link": "http://arxiv.org/abs/1804.10816v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
