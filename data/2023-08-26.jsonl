{"title": "A Computational Evaluation Framework for Singable Lyric Translation", "abstract": "Lyric translation plays a pivotal role in amplifying the global resonance of\nmusic, bridging cultural divides, and fostering universal connections.\nTranslating lyrics, unlike conventional translation tasks, requires a delicate\nbalance between singability and semantics. In this paper, we present a\ncomputational framework for the quantitative evaluation of singable lyric\ntranslation, which seamlessly integrates musical, linguistic, and cultural\ndimensions of lyrics. Our comprehensive framework consists of four metrics that\nmeasure syllable count distance, phoneme repetition similarity, musical\nstructure distance, and semantic similarity. To substantiate the efficacy of\nour framework, we collected a singable lyrics dataset, which precisely aligns\nEnglish, Japanese, and Korean lyrics on a line-by-line and section-by-section\nbasis, and conducted a comparative analysis between singable and non-singable\nlyrics. Our multidisciplinary approach provides insights into the key\ncomponents that underlie the art of lyric translation and establishes a solid\ngroundwork for the future of computational lyric translation assessment.", "published": "2023-08-26 00:27:08", "link": "http://arxiv.org/abs/2308.13715v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Solving Math Word Problem with Problem Type Classification", "abstract": "Math word problems (MWPs) require analyzing text descriptions and generating\nmathematical equations to derive solutions. Existing works focus on solving\nMWPs with two types of solvers: tree-based solver and large language model\n(LLM) solver. However, these approaches always solve MWPs by a single solver,\nwhich will bring the following problems: (1) Single type of solver is hard to\nsolve all types of MWPs well. (2) A single solver will result in poor\nperformance due to over-fitting. To address these challenges, this paper\nutilizes multiple ensemble approaches to improve MWP-solving ability. Firstly,\nWe propose a problem type classifier that combines the strengths of the\ntree-based solver and the LLM solver. This ensemble approach leverages their\nrespective advantages and broadens the range of MWPs that can be solved.\nFurthermore, we also apply ensemble techniques to both tree-based solver and\nLLM solver to improve their performance. For the tree-based solver, we propose\nan ensemble learning framework based on ten-fold cross-validation and voting\nmechanism. In the LLM solver, we adopt self-consistency (SC) method to improve\nanswer selection. Experimental results demonstrate the effectiveness of these\nensemble approaches in enhancing MWP-solving ability. The comprehensive\nevaluation showcases improved performance, validating the advantages of our\nproposed approach. Our code is available at this url:\nhttps://github.com/zhouzihao501/NLPCC2023-Shared-Task3-ChineseMWP.", "published": "2023-08-26 10:35:16", "link": "http://arxiv.org/abs/2308.13844v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Translate Meanings, Not Just Words: IdiomKB's Role in Optimizing\n  Idiomatic Translation with Language Models", "abstract": "To translate well, machine translation (MT) systems and general-purposed\nlanguage models (LMs) need a deep understanding of both source and target\nlanguages and cultures. Therefore, idioms, with their non-compositional nature,\npose particular challenges for Transformer-based systems, as literal\ntranslations often miss the intended meaning. Traditional methods, which\nreplace idioms using existing knowledge bases (KBs), often lack scale and\ncontext awareness. Addressing these challenges, our approach prioritizes\ncontext awareness and scalability, allowing for offline storage of idioms in a\nmanageable KB size. This ensures efficient serving with smaller models and\nprovides a more comprehensive understanding of idiomatic expressions. We\nintroduce a multilingual idiom KB (IdiomKB) developed using large LMs to\naddress this. This KB facilitates better translation by smaller models, such as\nBLOOMZ (7.1B), Alpaca (7B), and InstructGPT (6.7B), by retrieving idioms'\nfigurative meanings. We present a novel, GPT-4-powered metric for human-aligned\nevaluation, demonstrating that IdiomKB considerably boosts model performance.\nHuman evaluations further validate our KB's quality.", "published": "2023-08-26 21:38:31", "link": "http://arxiv.org/abs/2308.13961v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adversarial Fine-Tuning of Language Models: An Iterative Optimisation\n  Approach for the Generation and Detection of Problematic Content", "abstract": "In this paper, we tackle the emerging challenge of unintended harmful content\ngeneration in Large Language Models (LLMs) with a novel dual-stage optimisation\ntechnique using adversarial fine-tuning. Our two-pronged approach employs an\nadversarial model, fine-tuned to generate potentially harmful prompts, and a\njudge model, iteratively optimised to discern these prompts. In this\nadversarial cycle, the two models seek to outperform each other in the\nprompting phase, generating a dataset of rich examples which are then used for\nfine-tuning. This iterative application of prompting and fine-tuning allows\ncontinuous refinement and improved performance. The performance of our approach\nis evaluated through classification accuracy on a dataset consisting of\nproblematic prompts not detected by GPT-4, as well as a selection of\ncontentious but unproblematic prompts. We show considerable increase in\nclassification accuracy of the judge model on this challenging dataset as it\nundergoes the optimisation process. Furthermore, we show that a rudimentary\nmodel \\texttt{ada} can achieve 13\\% higher accuracy on the hold-out test set\nthan GPT-4 after only a few rounds of this process, and that this fine-tuning\nimproves performance in parallel tasks such as toxic comment identification.", "published": "2023-08-26 05:20:58", "link": "http://arxiv.org/abs/2308.13768v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "EditSum: A Retrieve-and-Edit Framework for Source Code Summarization", "abstract": "Existing studies show that code summaries help developers understand and\nmaintain source code. Unfortunately, these summaries are often missing or\noutdated in software projects. Code summarization aims to generate natural\nlanguage descriptions automatically for source code. Code summaries are highly\nstructured and have repetitive patterns. Besides the patternized words, a code\nsummary also contains important keywords, which are the key to reflecting the\nfunctionality of the code. However, the state-of-the-art approaches perform\npoorly on predicting the keywords, which leads to the generated summaries\nsuffering a loss in informativeness. To alleviate this problem, this paper\nproposes a novel retrieve-and-edit approach named EditSum for code\nsummarization. Specifically, EditSum first retrieves a similar code snippet\nfrom a pre-defined corpus and treats its summary as a prototype summary to\nlearn the pattern. Then, EditSum edits the prototype automatically to combine\nthe pattern in the prototype with the semantic information of input code. Our\nmotivation is that the retrieved prototype provides a good start-point for\npost-generation because the summaries of similar code snippets often have the\nsame pattern. The post-editing process further reuses the patternized words in\nthe prototype and generates keywords based on the semantic information of input\ncode. We conduct experiments on a large-scale Java corpus and experimental\nresults demonstrate that EditSum outperforms the state-of-the-art approaches by\na substantial margin. The human evaluation also proves the summaries generated\nby EditSum are more informative and useful. We also verify that EditSum\nperforms well on predicting the patternized words and keywords.", "published": "2023-08-26 05:48:57", "link": "http://arxiv.org/abs/2308.13775v2", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Planning with Logical Graph-based Language Model for Instruction\n  Generation", "abstract": "Despite the superior performance of large language models to generate natural\nlanguage texts, it is hard to generate texts with correct logic according to a\ngiven task, due to the difficulties for neural models to capture implied rules\nfrom free-form texts. In this paper, we propose a novel graph-based language\nmodel, Logical-GLM, to infuse logic into language models for more valid text\ngeneration and interpretability. Specifically, we first capture information\nfrom natural language instructions and construct logical bayes graphs that\ngenerally describe domains. Next, we generate logical skeletons to guide\nlanguage model training, infusing domain knowledge into language models.\nFinally, we alternately optimize the searching policy of graphs and language\nmodels until convergence. The experimental results show that Logical-GLM is\nboth effective and efficient compared with traditional language models, despite\nusing smaller-scale training data and fewer parameters. Our approach can\ngenerate instructional texts with more correct logic owing to the internalized\ndomain knowledge. Moreover, the usage of logical graphs reflects the inner\nmechanism of the language models, which improves the interpretability of\nblack-box models.", "published": "2023-08-26 06:28:14", "link": "http://arxiv.org/abs/2308.13782v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Wide Evaluation of ChatGPT on Affective Computing Tasks", "abstract": "With the rise of foundation models, a new artificial intelligence paradigm\nhas emerged, by simply using general purpose foundation models with prompting\nto solve problems instead of training a separate machine learning model for\neach problem. Such models have been shown to have emergent properties of\nsolving problems that they were not initially trained on. The studies for the\neffectiveness of such models are still quite limited. In this work, we widely\nstudy the capabilities of the ChatGPT models, namely GPT-4 and GPT-3.5, on 13\naffective computing problems, namely aspect extraction, aspect polarity\nclassification, opinion extraction, sentiment analysis, sentiment intensity\nranking, emotions intensity ranking, suicide tendency detection, toxicity\ndetection, well-being assessment, engagement measurement, personality\nassessment, sarcasm detection, and subjectivity detection. We introduce a\nframework to evaluate the ChatGPT models on regression-based problems, such as\nintensity ranking problems, by modelling them as pairwise ranking\nclassification. We compare ChatGPT against more traditional NLP methods, such\nas end-to-end recurrent neural networks and transformers. The results\ndemonstrate the emergent abilities of the ChatGPT models on a wide range of\naffective computing problems, where GPT-3.5 and especially GPT-4 have shown\nstrong performance on many problems, particularly the ones related to\nsentiment, emotions, or toxicity. The ChatGPT models fell short for problems\nwith implicit signals, such as engagement measurement and subjectivity\ndetection.", "published": "2023-08-26 16:10:30", "link": "http://arxiv.org/abs/2308.13911v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Exploring Large Language Models for Knowledge Graph Completion", "abstract": "Knowledge graphs play a vital role in numerous artificial intelligence tasks,\nyet they frequently face the issue of incompleteness. In this study, we explore\nutilizing Large Language Models (LLM) for knowledge graph completion. We\nconsider triples in knowledge graphs as text sequences and introduce an\ninnovative framework called Knowledge Graph LLM (KG-LLM) to model these\ntriples. Our technique employs entity and relation descriptions of a triple as\nprompts and utilizes the response for predictions. Experiments on various\nbenchmark knowledge graphs demonstrate that our method attains state-of-the-art\nperformance in tasks such as triple classification and relation prediction. We\nalso find that fine-tuning relatively smaller models (e.g., LLaMA-7B,\nChatGLM-6B) outperforms recent ChatGPT and GPT-4.", "published": "2023-08-26 16:51:17", "link": "http://arxiv.org/abs/2308.13916v5", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving Knowledge Distillation for BERT Models: Loss Functions,\n  Mapping Methods, and Weight Tuning", "abstract": "The use of large transformer-based models such as BERT, GPT, and T5 has led\nto significant advancements in natural language processing. However, these\nmodels are computationally expensive, necessitating model compression\ntechniques that reduce their size and complexity while maintaining accuracy.\nThis project investigates and applies knowledge distillation for BERT model\ncompression, specifically focusing on the TinyBERT student model. We explore\nvarious techniques to improve knowledge distillation, including experimentation\nwith loss functions, transformer layer mapping methods, and tuning the weights\nof attention and representation loss and evaluate our proposed techniques on a\nselection of downstream tasks from the GLUE benchmark. The goal of this work is\nto improve the efficiency and effectiveness of knowledge distillation, enabling\nthe development of more efficient and accurate models for a range of natural\nlanguage processing tasks.", "published": "2023-08-26 20:59:21", "link": "http://arxiv.org/abs/2308.13958v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "On Philomatics and Psychomatics for Combining Philosophy and Psychology\n  with Mathematics", "abstract": "We propose the concepts of philomatics and psychomatics as hybrid\ncombinations of philosophy and psychology with mathematics. We explain four\nmotivations for this combination which are fulfilling the desire of analytical\nphilosophy, proposing science of philosophy, justifying mathematical algorithms\nby philosophy, and abstraction in both philosophy and mathematics. We enumerate\nvarious examples for philomatics and psychomatics, some of which are explained\nin more depth. The first example is the analysis of relation between the\ncontext principle, semantic holism, and the usage theory of meaning with the\nattention mechanism in mathematics. The other example is on the relations of\nPlato's theory of forms in philosophy with the holographic principle in string\ntheory, object-oriented programming, and machine learning. Finally, the\nrelation between Wittgenstein's family resemblance and clustering in\nmathematics is explained. This paper opens the door of research for combining\nphilosophy and psychology with mathematics.", "published": "2023-08-26 02:52:42", "link": "http://arxiv.org/abs/2308.13738v1", "categories": ["math.HO", "cs.AI", "cs.CL"], "primary_category": "math.HO"}
{"title": "ZC3: Zero-Shot Cross-Language Code Clone Detection", "abstract": "Developers introduce code clones to improve programming productivity. Many\nexisting studies have achieved impressive performance in monolingual code clone\ndetection. However, during software development, more and more developers write\nsemantically equivalent programs with different languages to support different\nplatforms and help developers translate projects from one language to another.\nConsidering that collecting cross-language parallel data, especially for\nlow-resource languages, is expensive and time-consuming, how designing an\neffective cross-language model that does not rely on any parallel data is a\nsignificant problem. In this paper, we propose a novel method named ZC3 for\nZero-shot Cross-language Code Clone detection. ZC3 designs the contrastive\nsnippet prediction to form an isomorphic representation space among different\nprogramming languages. Based on this, ZC3 exploits domain-aware learning and\ncycle consistency learning to further constrain the model to generate\nrepresentations that are aligned among different languages meanwhile are\ndiacritical for different types of clones. To evaluate our approach, we conduct\nextensive experiments on four representative cross-language clone detection\ndatasets. Experimental results show that ZC3 outperforms the state-of-the-art\nbaselines by 67.12%, 51.39%, 14.85%, and 53.01% on the MAP score, respectively.\nWe further investigate the representational distribution of different languages\nand discuss the effectiveness of our method.", "published": "2023-08-26 03:48:10", "link": "http://arxiv.org/abs/2308.13754v2", "categories": ["cs.SE", "cs.CL", "cs.IR"], "primary_category": "cs.SE"}
{"title": "How Can Context Help? Exploring Joint Retrieval of Passage and\n  Personalized Context", "abstract": "The integration of external personalized context information into\ndocument-grounded conversational systems has significant potential business\nvalue, but has not been well-studied. Motivated by the concept of personalized\ncontext-aware document-grounded conversational systems, we introduce the task\nof context-aware passage retrieval. We also construct a dataset specifically\ncurated for this purpose. We describe multiple baseline systems to address this\ntask, and propose a novel approach, Personalized Context-Aware Search (PCAS),\nthat effectively harnesses contextual information during passage retrieval.\nExperimental evaluations conducted on multiple popular dense retrieval systems\ndemonstrate that our proposed approach not only outperforms the baselines in\nretrieving the most relevant passage but also excels at identifying the\npertinent context among all the available contexts. We envision that our\ncontributions will serve as a catalyst for inspiring future research endeavors\nin this promising direction.", "published": "2023-08-26 04:49:46", "link": "http://arxiv.org/abs/2308.13760v1", "categories": ["cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.AI"}
{"title": "LMSanitator: Defending Prompt-Tuning Against Task-Agnostic Backdoors", "abstract": "Prompt-tuning has emerged as an attractive paradigm for deploying large-scale\nlanguage models due to its strong downstream task performance and efficient\nmultitask serving ability. Despite its wide adoption, we empirically show that\nprompt-tuning is vulnerable to downstream task-agnostic backdoors, which reside\nin the pretrained models and can affect arbitrary downstream tasks. The\nstate-of-the-art backdoor detection approaches cannot defend against\ntask-agnostic backdoors since they hardly converge in reversing the backdoor\ntriggers. To address this issue, we propose LMSanitator, a novel approach for\ndetecting and removing task-agnostic backdoors on Transformer models. Instead\nof directly inverting the triggers, LMSanitator aims to invert the predefined\nattack vectors (pretrained models' output when the input is embedded with\ntriggers) of the task-agnostic backdoors, which achieves much better\nconvergence performance and backdoor detection accuracy. LMSanitator further\nleverages prompt-tuning's property of freezing the pretrained model to perform\naccurate and fast output monitoring and input purging during the inference\nphase. Extensive experiments on multiple language models and NLP tasks\nillustrate the effectiveness of LMSanitator. For instance, LMSanitator achieves\n92.8% backdoor detection accuracy on 960 models and decreases the attack\nsuccess rate to less than 1% in most scenarios.", "published": "2023-08-26 15:21:47", "link": "http://arxiv.org/abs/2308.13904v2", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Survey for Evaluation Methodologies of AI-Generated\n  Music", "abstract": "In recent years, AI-generated music has made significant progress, with\nseveral models performing well in multimodal and complex musical genres and\nscenes. While objective metrics can be used to evaluate generative music, they\noften lack interpretability for musical evaluation. Therefore, researchers\noften resort to subjective user studies to assess the quality of the generated\nworks, which can be resource-intensive and less reproducible than objective\nmetrics. This study aims to comprehensively evaluate the subjective, objective,\nand combined methodologies for assessing AI-generated music, highlighting the\nadvantages and disadvantages of each approach. Ultimately, this study provides\na valuable reference for unifying generative AI in the field of music\nevaluation.", "published": "2023-08-26 02:44:33", "link": "http://arxiv.org/abs/2308.13736v1", "categories": ["cs.SD", "cs.AI", "cs.HC", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A small vocabulary database of ultrasound image sequences of vocal tract\n  dynamics", "abstract": "This paper presents a new database consisting of concurrent articulatory and\nacoustic speech data. The articulatory data correspond to ultrasound videos of\nthe vocal tract dynamics, which allow the visualization of the tongue upper\ncontour during the speech production process. Acoustic data is composed of 30\nshort sentences that were acquired by a directional cardioid microphone. This\ndatabase includes data from 17 young subjects (8 male and 9 female) from the\nSantander region in Colombia, who reported not having any speech pathology.", "published": "2023-08-26 18:58:10", "link": "http://arxiv.org/abs/2308.13941v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
