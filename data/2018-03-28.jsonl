{"title": "Handling Verb Phrase Anaphora with Dependent Types and Events", "abstract": "This paper studies how dependent typed events can be used to treat verb\nphrase anaphora. We introduce a framework that extends Dependent Type Semantics\n(DTS) with a new atomic type for neo-Davidsonian events and an extended\n@-operator that can return new events that share properties of events\nreferenced by verb phrase anaphora. The proposed framework, along with\nillustrative examples of its use, are presented after a brief overview of the\nnecessary background and of the major challenges posed by verb phrase anaphora.", "published": "2018-03-28 05:47:31", "link": "http://arxiv.org/abs/1803.10421v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Network Architecture for Credibility Assessment of Textual Claims", "abstract": "Text articles with false claims, especially news, have recently become\naggravating for the Internet users. These articles are in wide circulation and\nreaders face difficulty discerning fact from fiction. Previous work on\ncredibility assessment has focused on factual analysis and linguistic features.\nThe task's main challenge is the distinction between the features of true and\nfalse articles. In this paper, we propose a novel approach called Credibility\nOutcome (CREDO) which aims at scoring the credibility of an article in an open\ndomain setting.\n  CREDO consists of different modules for capturing various features\nresponsible for the credibility of an article. These features includes\ncredibility of the article's source and author, semantic similarity between the\narticle and related credible articles retrieved from a knowledge base, and\nsentiments conveyed by the article. A neural network architecture learns the\ncontribution of each of these modules to the overall credibility of an article.\nExperiments on Snopes dataset reveals that CREDO outperforms the\nstate-of-the-art approaches based on linguistic features.", "published": "2018-03-28 11:50:32", "link": "http://arxiv.org/abs/1803.10547v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Meta-Learning a Dynamical Language Model", "abstract": "We consider the task of word-level language modeling and study the\npossibility of combining hidden-states-based short-term representations with\nmedium-term representations encoded in dynamical weights of a language model.\nOur work extends recent experiments on language models with dynamically\nevolving weights by casting the language modeling problem into an online\nlearning-to-learn framework in which a meta-learner is trained by\ngradient-descent to continuously update a language model weights.", "published": "2018-03-28 14:08:12", "link": "http://arxiv.org/abs/1803.10631v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Actor-Critic based Training Framework for Abstractive Summarization", "abstract": "We present a training framework for neural abstractive summarization based on\nactor-critic approaches from reinforcement learning. In the traditional neural\nnetwork based methods, the objective is only to maximize the likelihood of the\npredicted summaries, no other assessment constraints are considered, which may\ngenerate low-quality summaries or even incorrect sentences. To alleviate this\nproblem, we employ an actor-critic framework to enhance the training procedure.\nFor the actor, we employ the typical attention based sequence-to-sequence\n(seq2seq) framework as the policy network for summary generation. For the\ncritic, we combine the maximum likelihood estimator with a well designed global\nsummary quality estimator which is a neural network based binary classifier\naiming to make the generated summaries indistinguishable from the human-written\nones. Policy gradient method is used to conduct the parameter learning. An\nalternating training strategy is proposed to conduct the joint training of the\nactor and critic models. Extensive experiments on some benchmark datasets in\ndifferent languages show that our framework achieves improvements over the\nstate-of-the-art methods.", "published": "2018-03-28 02:47:51", "link": "http://arxiv.org/abs/1803.11070v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Deep Attention Model for Triage of Emergency Department Patients", "abstract": "Optimization of patient throughput and wait time in emergency departments\n(ED) is an important task for hospital systems. For that reason, Emergency\nSeverity Index (ESI) system for patient triage was introduced to help guide\nmanual estimation of acuity levels, which is used by nurses to rank the\npatients and organize hospital resources. However, despite improvements that it\nbrought to managing medical resources, such triage system greatly depends on\nnurse's subjective judgment and is thus prone to human errors. Here, we propose\na novel deep model based on the word attention mechanism designed for\npredicting a number of resources an ED patient would need. Our approach\nincorporates routinely available continuous and nominal (structured) data with\nmedical text (unstructured) data, including patient's chief complaint, past\nmedical history, medication list, and nurse assessment collected for 338,500 ED\nvisits over three years in a large urban hospital. Using both structured and\nunstructured data, the proposed approach achieves the AUC of $\\sim 88\\%$ for\nthe task of identifying resource intensive patients (binary classification),\nand the accuracy of $\\sim 44\\%$ for predicting exact category of number of\nresources (multi-class classification task), giving an estimated lift over\nnurses' performance by 16\\% in accuracy. Furthermore, the attention mechanism\nof the proposed model provides interpretability by assigning attention scores\nfor nurses' notes which is crucial for decision making and implementation of\nsuch approaches in the real systems working on human health.", "published": "2018-03-28 16:06:29", "link": "http://arxiv.org/abs/1804.03240v1", "categories": ["cs.CY", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Machine Speech Chain with One-shot Speaker Adaptation", "abstract": "In previous work, we developed a closed-loop speech chain model based on deep\nlearning, in which the architecture enabled the automatic speech recognition\n(ASR) and text-to-speech synthesis (TTS) components to mutually improve their\nperformance. This was accomplished by the two parts teaching each other using\nboth labeled and unlabeled data. This approach could significantly improve\nmodel performance within a single-speaker speech dataset, but only a slight\nincrease could be gained in multi-speaker tasks. Furthermore, the model is\nstill unable to handle unseen speakers. In this paper, we present a new speech\nchain mechanism by integrating a speaker recognition model inside the loop. We\nalso propose extending the capability of TTS to handle unseen speakers by\nimplementing one-shot speaker adaptation. This enables TTS to mimic voice\ncharacteristics from one speaker to another with only a one-shot speaker\nsample, even from a text without any speaker information. In the speech chain\nloop mechanism, ASR also benefits from the ability to further learn an\narbitrary speaker's characteristics from the generated speech waveform,\nresulting in a significant improvement in the recognition rate.", "published": "2018-03-28 11:06:15", "link": "http://arxiv.org/abs/1803.10525v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Topic Modeling Based Multi-modal Depression Detection", "abstract": "Major depressive disorder is a common mental disorder that affects almost 7%\nof the adult U.S. population. The 2017 Audio/Visual Emotion Challenge (AVEC)\nasks participants to build a model to predict depression levels based on the\naudio, video, and text of an interview ranging between 7-33 minutes. Since\naveraging features over the entire interview will lose most temporal\ninformation, how to discover, capture, and preserve useful temporal details for\nsuch a long interview are significant challenges. Therefore, we propose a novel\ntopic modeling based approach to perform context-aware analysis of the\nrecording. Our experiments show that the proposed approach outperforms\ncontext-unaware methods and the challenge baselines for all metrics.", "published": "2018-03-28 02:12:48", "link": "http://arxiv.org/abs/1803.10384v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "The fifth 'CHiME' Speech Separation and Recognition Challenge: Dataset,\n  task and baselines", "abstract": "The CHiME challenge series aims to advance robust automatic speech\nrecognition (ASR) technology by promoting research at the interface of speech\nand language processing, signal processing , and machine learning. This paper\nintroduces the 5th CHiME Challenge, which considers the task of distant\nmulti-microphone conversational ASR in real home environments. Speech material\nwas elicited using a dinner party scenario with efforts taken to capture data\nthat is representative of natural conversational speech and recorded by 6\nKinect microphone arrays and 4 binaural microphone pairs. The challenge\nfeatures a single-array track and a multiple-array track and, for each track,\ndistinct rankings will be produced for systems focusing on robustness with\nrespect to distant-microphone capture vs. systems attempting to address all\naspects of the task including conversational language modeling. We discuss the\nrationale for the challenge and provide a detailed description of the data\ncollection procedure, the task, and the baseline systems for array\nsynchronization, speech enhancement, and conventional and end-to-end ASR.", "published": "2018-03-28 13:51:09", "link": "http://arxiv.org/abs/1803.10609v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
