{"title": "Variational Recurrent Neural Machine Translation", "abstract": "Partially inspired by successful applications of variational recurrent neural\nnetworks, we propose a novel variational recurrent neural machine translation\n(VRNMT) model in this paper. Different from the variational NMT, VRNMT\nintroduces a series of latent random variables to model the translation\nprocedure of a sentence in a generative way, instead of a single latent\nvariable. Specifically, the latent random variables are included into the\nhidden states of the NMT decoder with elements from the variational\nautoencoder. In this way, these variables are recurrently generated, which\nenables them to further capture strong and complex dependencies among the\noutput translations at different timesteps. In order to deal with the\nchallenges in performing efficient posterior inference and large-scale training\nduring the incorporation of latent variables, we build a neural posterior\napproximator, and equip it with a reparameterization technique to estimate the\nvariational lower bound. Experiments on Chinese-English and English-German\ntranslation tasks demonstrate that the proposed model achieves significant\nimprovements over both the conventional and variational NMT models.", "published": "2018-01-16 05:18:06", "link": "http://arxiv.org/abs/1801.05119v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Asynchronous Bidirectional Decoding for Neural Machine Translation", "abstract": "The dominant neural machine translation (NMT) models apply unified\nattentional encoder-decoder neural networks for translation. Traditionally, the\nNMT decoders adopt recurrent neural networks (RNNs) to perform translation in a\nleft-toright manner, leaving the target-side contexts generated from right to\nleft unexploited during translation. In this paper, we equip the conventional\nattentional encoder-decoder NMT framework with a backward decoder, in order to\nexplore bidirectional decoding for NMT. Attending to the hidden state sequence\nproduced by the encoder, our backward decoder first learns to generate the\ntarget-side hidden state sequence from right to left. Then, the forward decoder\nperforms translation in the forward direction, while in each translation\nprediction timestep, it simultaneously applies two attention models to consider\nthe source-side and reverse target-side hidden states, respectively. With this\nnew architecture, our model is able to fully exploit source- and target-side\ncontexts to improve translation quality altogether. Experimental results on\nNIST Chinese-English and WMT English-German translation tasks demonstrate that\nour model achieves substantial improvements over the conventional NMT by 3.14\nand 1.38 BLEU points, respectively. The source code of this work can be\nobtained from https://github.com/DeepLearnXMU/ABDNMT.", "published": "2018-01-16 05:21:43", "link": "http://arxiv.org/abs/1801.05122v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adversarial Learning for Chinese NER from Crowd Annotations", "abstract": "To quickly obtain new labeled data, we can choose crowdsourcing as an\nalternative way at lower cost in a short time. But as an exchange, crowd\nannotations from non-experts may be of lower quality than those from experts.\nIn this paper, we propose an approach to performing crowd annotation learning\nfor Chinese Named Entity Recognition (NER) to make full use of the noisy\nsequence labels from multiple annotators. Inspired by adversarial learning, our\napproach uses a common Bi-LSTM and a private Bi-LSTM for representing\nannotator-generic and -specific information. The annotator-generic information\nis the common knowledge for entities easily mastered by the crowd. Finally, we\nbuild our Chinese NE tagger based on the LSTM-CRF model. In our experiments, we\ncreate two data sets for Chinese NER tasks from two domains. The experimental\nresults show that our system achieves better scores than strong baseline\nsystems.", "published": "2018-01-16 08:11:01", "link": "http://arxiv.org/abs/1801.05147v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OneNet: Joint Domain, Intent, Slot Prediction for Spoken Language\n  Understanding", "abstract": "In practice, most spoken language understanding systems process user input in\na pipelined manner; first domain is predicted, then intent and semantic slots\nare inferred according to the semantic frames of the predicted domain. The\npipeline approach, however, has some disadvantages: error propagation and lack\nof information sharing. To address these issues, we present a unified neural\nnetwork that jointly performs domain, intent, and slot predictions. Our\napproach adopts a principled architecture for multitask learning to fold in the\nstate-of-the-art models for each task. With a few more ingredients, e.g.\northography-sensitive input encoding and curriculum training, our model\ndelivered significant improvements in all three tasks across all domains over\nstrong baselines, including one using oracle prediction for domain detection,\non real user data of a commercial personal assistant.", "published": "2018-01-16 08:28:53", "link": "http://arxiv.org/abs/1801.05149v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Comparative Study of Rule Extraction for Recurrent Neural Networks", "abstract": "Understanding recurrent networks through rule extraction has a long history.\nThis has taken on new interests due to the need for interpreting or verifying\nneural networks. One basic form for representing stateful rules is\ndeterministic finite automata (DFA). Previous research shows that extracting\nDFAs from trained second-order recurrent networks is not only possible but also\nrelatively stable. Recently, several new types of recurrent networks with more\ncomplicated architectures have been introduced. These handle challenging\nlearning tasks usually involving sequential data. However, it remains an open\nproblem whether DFAs can be adequately extracted from these models.\nSpecifically, it is not clear how DFA extraction will be affected when applied\nto different recurrent networks trained on data sets with different levels of\ncomplexity. Here, we investigate DFA extraction on several widely adopted\nrecurrent networks that are trained to learn a set of seven regular Tomita\ngrammars. We first formally analyze the complexity of Tomita grammars and\ncategorize these grammars according to that complexity. Then we empirically\nevaluate different recurrent networks for their performance of DFA extraction\non all Tomita grammars. Our experiments show that for most recurrent networks,\ntheir extraction performance decreases as the complexity of the underlying\ngrammar increases. On grammars of lower complexity, most recurrent networks\nobtain desirable extraction performance. As for grammars with the highest level\nof complexity, while several complicated models fail with only certain\nrecurrent networks having satisfactory extraction performance.", "published": "2018-01-16 03:19:37", "link": "http://arxiv.org/abs/1801.05420v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Grounded Language Understanding for Manipulation Instructions Using\n  GAN-Based Classification", "abstract": "The target task of this study is grounded language understanding for domestic\nservice robots (DSRs). In particular, we focus on instruction understanding for\nshort sentences where verbs are missing. This task is of critical importance to\nbuild communicative DSRs because manipulation is essential for DSRs. Existing\ninstruction understanding methods usually estimate missing information only\nfrom non-grounded knowledge; therefore, whether the predicted action is\nphysically executable or not was unclear.\n  In this paper, we present a grounded instruction understanding method to\nestimate appropriate objects given an instruction and situation. We extend the\nGenerative Adversarial Nets (GAN) and build a GAN-based classifier using latent\nrepresentations. To quantitatively evaluate the proposed method, we have\ndeveloped a data set based on the standard data set used for Visual QA.\nExperimental results have shown that the proposed method gives the better\nresult than baseline methods.", "published": "2018-01-16 02:05:50", "link": "http://arxiv.org/abs/1801.05096v1", "categories": ["cs.RO", "cs.CL", "cs.HC"], "primary_category": "cs.RO"}
{"title": "Embedding a $\u03b8$-invariant code into a complete one", "abstract": "Let A be a finite or countable alphabet and let $\\theta$ be a literal\n(anti-)automorphism onto A * (by definition, such a correspondence is\ndeterminated by a permutation of the alphabet). This paper deals with sets\nwhich are invariant under $\\theta$ ($\\theta$-invariant for short) that is,\nlanguages L such that $\\theta$ (L) is a subset of L.We establish an extension\nof the famous defect theorem. With regards to the so-called notion of\ncompleteness, we provide a series of examples of finite complete\n$\\theta$-invariant codes. Moreover, we establish a formula which allows to\nembed any non-complete $\\theta$-invariant code into a complete one. As a\nconsequence, in the family of the so-called thin $\\theta$--invariant codes,\nmaximality and completeness are two equivalent notions.", "published": "2018-01-16 09:09:58", "link": "http://arxiv.org/abs/1801.05164v3", "categories": ["cs.DM", "cs.CL", "math.CO"], "primary_category": "cs.DM"}
{"title": "Beyond Word Importance: Contextual Decomposition to Extract Interactions\n  from LSTMs", "abstract": "The driving force behind the recent success of LSTMs has been their ability\nto learn complex and non-linear relationships. Consequently, our inability to\ndescribe these relationships has led to LSTMs being characterized as black\nboxes. To this end, we introduce contextual decomposition (CD), an\ninterpretation algorithm for analysing individual predictions made by standard\nLSTMs, without any changes to the underlying model. By decomposing the output\nof a LSTM, CD captures the contributions of combinations of words or variables\nto the final prediction of an LSTM. On the task of sentiment analysis with the\nYelp and SST data sets, we show that CD is able to reliably identify words and\nphrases of contrasting sentiment, and how they are combined to yield the LSTM's\nfinal prediction. Using the phrase-level labels in SST, we also demonstrate\nthat CD is able to successfully extract positive and negative negations from an\nLSTM, something which has not previously been done.", "published": "2018-01-16 19:21:48", "link": "http://arxiv.org/abs/1801.05453v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Real-time Road Traffic Information Detection Through Social Media", "abstract": "In current study, a mechanism to extract traffic related information such as\ncongestion and incidents from textual data from the internet is proposed. The\ncurrent source of data is Twitter. As the data being considered is extremely\nlarge in size automated models are developed to stream, download, and mine the\ndata in real-time. Furthermore, if any tweet has traffic related information\nthen the models should be able to infer and extract this data.\n  Currently, the data is collected only for United States and a total of\n120,000 geo-tagged traffic related tweets are extracted, while six million\ngeo-tagged non-traffic related tweets are retrieved and classification models\nare trained. Furthermore, this data is used for various kinds of spatial and\ntemporal analysis. A mechanism to calculate level of traffic congestion,\nsafety, and traffic perception for cities in U.S. is proposed. Traffic\ncongestion and safety rankings for the various urban areas are obtained and\nthen they are statistically validated with existing widely adopted rankings.\nTraffic perception depicts the attitude and perception of people towards the\ntraffic.\n  It is also seen that traffic related data when visualized spatially and\ntemporally provides the same pattern as the actual traffic flows for various\nurban areas. When visualized at the city level, it is clearly visible that the\nflow of tweets is similar to flow of vehicles and that the traffic related\ntweets are representative of traffic within the cities. With all the findings\nin current study, it is shown that significant amount of traffic related\ninformation can be extracted from Twitter and other sources on internet.\nFurthermore, Twitter and these data sources are freely available and are not\nbound by spatial and temporal limitations. That is, wherever there is a user\nthere is a potential for data.", "published": "2018-01-16 01:26:33", "link": "http://arxiv.org/abs/1801.05088v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.IR", "cs.SI", "97R40", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Automatic Classification of Music Genre using Masked Conditional Neural\n  Networks", "abstract": "Neural network based architectures used for sound recognition are usually\nadapted from other application domains such as image recognition, which may not\nharness the time-frequency representation of a signal. The ConditionaL Neural\nNetworks (CLNN) and its extension the Masked ConditionaL Neural Networks\n(MCLNN) are designed for multidimensional temporal signal recognition. The CLNN\nis trained over a window of frames to preserve the inter-frame relation, and\nthe MCLNN enforces a systematic sparseness over the network's links that mimics\na filterbank-like behavior. The masking operation induces the network to learn\nin frequency bands, which decreases the network susceptibility to\nfrequency-shifts in time-frequency representations. Additionally, the mask\nallows an exploration of a range of feature combinations concurrently analogous\nto the manual handcrafting of the optimum collection of features for a\nrecognition task. MCLNN have achieved competitive performance on the Ballroom\nmusic dataset compared to several hand-crafted attempts and outperformed models\nbased on state-of-the-art Convolutional Neural Networks.", "published": "2018-01-16 23:43:34", "link": "http://arxiv.org/abs/1801.05504v2", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
