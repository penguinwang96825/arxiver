{"title": "Towards De-identification of Legal Texts", "abstract": "In many countries, personal information that can be published or shared\nbetween organizations is regulated and, therefore, documents must undergo a\nprocess of de-identification to eliminate or obfuscate confidential data. Our\nwork focuses on the de-identification of legal texts, where the goal is to hide\nthe names of the actors involved in a lawsuit without losing the sense of the\nstory. We present a first evaluation on our corpus of NLP tools in tasks such\nas segmentation, tokenization and recognition of named entities, and we analyze\nseveral evaluation measures for our de-identification task. Results are meager:\n84% of the documents have at least one name not covered by NER tools, something\nthat might lead to the re-identification of involved names. We conclude that\ntools must be strongly adapted for processing texts of this particular domain.", "published": "2019-10-09 01:33:29", "link": "http://arxiv.org/abs/1910.03739v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Daunting Task of Real-World Textual Style Transfer Auto-Evaluation", "abstract": "The difficulty of textual style transfer lies in the lack of parallel\ncorpora. Numerous advances have been proposed for the unsupervised generation.\nHowever, significant problems remain with the auto-evaluation of style transfer\ntasks. Based on the summary of Pang and Gimpel (2018) and Mir et al. (2019),\nstyle transfer evaluations rely on three criteria: style accuracy of\ntransferred sentences, content similarity between original and transferred\nsentences, and fluency of transferred sentences. We elucidate the problematic\ncurrent state of style transfer research. Given that current tasks do not\nrepresent real use cases of style transfer, current auto-evaluation approach is\nflawed. This discussion aims to bring researchers to think about the future of\nstyle transfer and style transfer evaluation research.", "published": "2019-10-09 01:54:47", "link": "http://arxiv.org/abs/1910.03747v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing", "abstract": "Recent progress in natural language processing has been driven by advances in\nboth model architecture and model pretraining. Transformer architectures have\nfacilitated building higher-capacity models and pretraining has made it\npossible to effectively utilize this capacity for a wide variety of tasks.\n\\textit{Transformers} is an open-source library with the goal of opening up\nthese advances to the wider machine learning community. The library consists of\ncarefully engineered state-of-the art Transformer architectures under a unified\nAPI. Backing this library is a curated collection of pretrained models made by\nand available for the community. \\textit{Transformers} is designed to be\nextensible by researchers, simple for practitioners, and fast and robust in\nindustrial deployments. The library is available at\n\\url{https://github.com/huggingface/transformers}.", "published": "2019-10-09 03:23:22", "link": "http://arxiv.org/abs/1910.03771v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Assessing the Efficacy of Clinical Sentiment Analysis and Topic\n  Extraction in Psychiatric Readmission Risk Prediction", "abstract": "Predicting which patients are more likely to be readmitted to a hospital\nwithin 30 days after discharge is a valuable piece of information in clinical\ndecision-making. Building a successful readmission risk classifier based on the\ncontent of Electronic Health Records (EHRs) has proved, however, to be a\nchallenging task. Previously explored features include mainly structured\ninformation, such as sociodemographic data, comorbidity codes and physiological\nvariables. In this paper we assess incorporating additional clinically\ninterpretable NLP-based features such as topic extraction and clinical\nsentiment analysis to predict early readmission risk in psychiatry patients.", "published": "2019-10-09 14:10:47", "link": "http://arxiv.org/abs/1910.04006v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BHAAV- A Text Corpus for Emotion Analysis from Hindi Stories", "abstract": "In this paper, we introduce the first and largest Hindi text corpus, named\nBHAAV, which means emotions in Hindi, for analyzing emotions that a writer\nexpresses through his characters in a story, as perceived by a narrator/reader.\nThe corpus consists of 20,304 sentences collected from 230 different short\nstories spanning across 18 genres such as Inspirational and Mystery. Each\nsentence has been annotated into one of the five emotion categories - anger,\njoy, suspense, sad, and neutral, by three native Hindi speakers with at least\nten years of formal education in Hindi. We also discuss challenges in the\nannotation of low resource languages such as Hindi, and discuss the scope of\nthe proposed corpus along with its possible uses. We also provide a detailed\nanalysis of the dataset and train strong baseline classifiers reporting their\nperformances.", "published": "2019-10-09 15:42:25", "link": "http://arxiv.org/abs/1910.04073v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Semi-Supervised Learning for Natural Language Understanding by\n  Optimizing Diversity", "abstract": "Expanding new functionalities efficiently is an ongoing challenge for\nsingle-turn task-oriented dialogue systems. In this work, we explore\nfunctionality-specific semi-supervised learning via self-training. We consider\nmethods that augment training data automatically from unlabeled data sets in a\nfunctionality-targeted manner. In addition, we examine multiple techniques for\nefficient selection of augmented utterances to reduce training time and\nincrease diversity. First, we consider paraphrase detection methods that\nattempt to find utterance variants of labeled training data with good coverage.\nSecond, we explore sub-modular optimization based on n-grams features for\nutterance selection. Experiments show that functionality-specific self-training\nis very effective for improving system performance. In addition, methods\noptimizing diversity can reduce training data in many cases to 50% with little\nimpact on performance.", "published": "2019-10-09 18:34:17", "link": "http://arxiv.org/abs/1910.04196v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Perturbation Sensitivity Analysis to Detect Unintended Model Biases", "abstract": "Data-driven statistical Natural Language Processing (NLP) techniques leverage\nlarge amounts of language data to build models that can understand language.\nHowever, most language data reflect the public discourse at the time the data\nwas produced, and hence NLP models are susceptible to learning incidental\nassociations around named referents at a particular point in time, in addition\nto general linguistic meaning. An NLP system designed to model notions such as\nsentiment and toxicity should ideally produce scores that are independent of\nthe identity of such entities mentioned in text and their social associations.\nFor example, in a general purpose sentiment analysis system, a phrase such as I\nhate Katy Perry should be interpreted as having the same sentiment as I hate\nTaylor Swift. Based on this idea, we propose a generic evaluation framework,\nPerturbation Sensitivity Analysis, which detects unintended model biases\nrelated to named entities, and requires no new annotations or corpora. We\ndemonstrate the utility of this analysis by employing it on two different NLP\nmodels --- a sentiment model and a toxicity model --- applied on online\ncomments in English language from four different genres.", "published": "2019-10-09 19:25:21", "link": "http://arxiv.org/abs/1910.04210v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Alternating Recurrent Dialog Model with Large-scale Pre-trained Language\n  Models", "abstract": "Existing dialog system models require extensive human annotations and are\ndifficult to generalize to different tasks. The recent success of large\npre-trained language models such as BERT and GPT-2 (Devlin et al., 2019;\nRadford et al., 2019) have suggested the effectiveness of incorporating\nlanguage priors in down-stream NLP tasks. However, how much pre-trained\nlanguage models can help dialog response generation is still under exploration.\nIn this paper, we propose a simple, general, and effective framework:\nAlternating Roles Dialog Model (ARDM). ARDM models each speaker separately and\ntakes advantage of the large pre-trained language model. It requires no\nsupervision from human annotations such as belief states or dialog acts to\nachieve effective conversations. ARDM outperforms or is on par with\nstate-of-the-art methods on two popular task-oriented dialog datasets:\nCamRest676 and MultiWOZ. Moreover, we can generalize ARDM to more challenging,\nnon-collaborative tasks such as persuasion. In persuasion tasks, ARDM is\ncapable of generating human-like responses to persuade people to donate to a\ncharity.", "published": "2019-10-09 02:31:37", "link": "http://arxiv.org/abs/1910.03756v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Is Multilingual BERT Fluent in Language Generation?", "abstract": "The multilingual BERT model is trained on 104 languages and meant to serve as\na universal language model and tool for encoding sentences. We explore how well\nthe model performs on several languages across several tasks: a diagnostic\nclassification probing the embeddings for a particular syntactic property, a\ncloze task testing the language modelling ability to fill in gaps in a\nsentence, and a natural language generation task testing for the ability to\nproduce coherent text fitting a given context. We find that the currently\navailable multilingual BERT model is clearly inferior to the monolingual\ncounterparts, and cannot in many cases serve as a substitute for a well-trained\nmonolingual model. We find that the English and German models perform well at\ngeneration, whereas the multilingual model is lacking, in particular, for\nNordic languages.", "published": "2019-10-09 06:35:59", "link": "http://arxiv.org/abs/1910.03806v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Exploring Hate Speech Detection in Multimodal Publications", "abstract": "In this work we target the problem of hate speech detection in multimodal\npublications formed by a text and an image. We gather and annotate a large\nscale dataset from Twitter, MMHS150K, and propose different models that jointly\nanalyze textual and visual information for hate speech detection, comparing\nthem with unimodal detection. We provide quantitative and qualitative results\nand analyze the challenges of the proposed task. We find that, even though\nimages are useful for the hate speech detection task, current multimodal models\ncannot outperform models analyzing only text. We discuss why and open the field\nand the dataset for further research.", "published": "2019-10-09 06:53:39", "link": "http://arxiv.org/abs/1910.03814v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Word Embedding Visualization Via Dictionary Learning", "abstract": "Co-occurrence statistics based word embedding techniques have proved to be\nvery useful in extracting the semantic and syntactic representation of words as\nlow dimensional continuous vectors. In this work, we discovered that dictionary\nlearning can open up these word vectors as a linear combination of more\nelementary word factors. We demonstrate many of the learned factors have\nsurprisingly strong semantic or syntactic meaning corresponding to the factors\npreviously identified manually by human inspection. Thus dictionary learning\nprovides a powerful visualization tool for understanding word embedding\nrepresentations. Furthermore, we show that the word factors can help in\nidentifying key semantic and syntactic differences in word analogy tasks and\nimprove upon the state-of-the-art word embedding techniques in these tasks by a\nlarge margin.", "published": "2019-10-09 08:14:48", "link": "http://arxiv.org/abs/1910.03833v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning High-order Structural and Attribute information by Knowledge\n  Graph Attention Networks for Enhancing Knowledge Graph Embedding", "abstract": "The goal of representation learning of knowledge graph is to encode both\nentities and relations into a low-dimensional embedding spaces. Many recent\nworks have demonstrated the benefits of knowledge graph embedding on knowledge\ngraph completion task, such as relation extraction. However, we observe that:\n1) existing method just take direct relations between entities into\nconsideration and fails to express high-order structural relationship between\nentities; 2) these methods just leverage relation triples of KGs while ignoring\na large number of attribute triples that encoding rich semantic information. To\novercome these limitations, this paper propose a novel knowledge graph\nembedding method, named KANE, which is inspired by the recent developments of\ngraph convolutional networks (GCN). KANE can capture both high-order structural\nand attribute information of KGs in an efficient, explicit and unified manner\nunder the graph convolutional networks framework. Empirical results on three\ndatasets show that KANE significantly outperforms seven state-of-arts methods.\nFurther analysis verify the efficiency of our method and the benefits brought\nby the attention mechanism.", "published": "2019-10-09 10:33:59", "link": "http://arxiv.org/abs/1910.03891v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Novel Applications of Factored Neural Machine Translation", "abstract": "In this work, we explore the usefulness of target factors in neural machine\ntranslation (NMT) beyond their original purpose of predicting word lemmas and\ntheir inflections, as proposed by Garc\\`ia-Mart\\`inez et al., 2016. For this,\nwe introduce three novel applications of the factored output architecture: In\nthe first one, we use a factor to explicitly predict the word case separately\nfrom the target word itself. This allows for information to be shared between\ndifferent casing variants of a word. In a second task, we use a factor to\npredict when two consecutive subwords have to be joined, eliminating the need\nfor target subword joining markers. The third task is the prediction of special\ntokens of the operation sequence NMT model (OSNMT) of Stahlberg et al., 2018.\nAutomatic evaluation on English-to-German and English-to-Turkish tasks showed\nthat integration of such auxiliary prediction tasks into NMT is at least as\ngood as the standard NMT approach. For the OSNMT, we observed a significant\nimprovement in BLEU over the baseline OSNMT implementation due to a reduced\noutput sequence length that resulted from the introduction of the target\nfactors.", "published": "2019-10-09 11:45:07", "link": "http://arxiv.org/abs/1910.03912v1", "categories": ["cs.CL", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Spoken Language Identification using ConvNets", "abstract": "Language Identification (LI) is an important first step in several speech\nprocessing systems. With a growing number of voice-based assistants, speech LI\nhas emerged as a widely researched field. To approach the problem of\nidentifying languages, we can either adopt an implicit approach where only the\nspeech for a language is present or an explicit one where text is available\nwith its corresponding transcript. This paper focuses on an implicit approach\ndue to the absence of transcriptive data. This paper benchmarks existing models\nand proposes a new attention based model for language identification which uses\nlog-Mel spectrogram images as input. We also present the effectiveness of raw\nwaveforms as features to neural network models for LI tasks. For training and\nevaluation of models, we classified six languages (English, French, German,\nSpanish, Russian and Italian) with an accuracy of 95.4% and four languages\n(English, French, German, Spanish) with an accuracy of 96.3% obtained from the\nVoxForge dataset. This approach can further be scaled to incorporate more\nlanguages.", "published": "2019-10-09 21:43:36", "link": "http://arxiv.org/abs/1910.04269v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning to Contextually Aggregate Multi-Source Supervision for Sequence\n  Labeling", "abstract": "Sequence labeling is a fundamental framework for various natural language\nprocessing problems. Its performance is largely influenced by the annotation\nquality and quantity in supervised learning scenarios, and obtaining ground\ntruth labels is often costly. In many cases, ground truth labels do not exist,\nbut noisy annotations or annotations from different domains are accessible. In\nthis paper, we propose a novel framework Consensus Network (ConNet) that can be\ntrained on annotations from multiple sources (e.g., crowd annotation,\ncross-domain data...). It learns individual representation for every source and\ndynamically aggregates source-specific knowledge by a context-aware attention\nmodule. Finally, it leads to a model reflecting the agreement (consensus) among\nmultiple sources. We evaluate the proposed framework in two practical settings\nof multi-source learning: learning with crowd annotations and unsupervised\ncross-domain model adaptation. Extensive experimental results show that our\nmodel achieves significant improvements over existing methods in both settings.\nWe also demonstrate that the method can apply to various tasks and cope with\ndifferent encoders.", "published": "2019-10-09 22:54:43", "link": "http://arxiv.org/abs/1910.04289v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Text-to-Image Synthesis Based on Machine Generated Captions", "abstract": "Text to Image Synthesis refers to the process of automatic generation of a\nphoto-realistic image starting from a given text and is revolutionizing many\nreal-world applications. In order to perform such process it is necessary to\nexploit datasets containing captioned images, meaning that each image is\nassociated with one (or more) captions describing it. Despite the abundance of\nuncaptioned images datasets, the number of captioned datasets is limited. To\naddress this issue, in this paper we propose an approach capable of generating\nimages starting from a given text using conditional GANs trained on uncaptioned\nimages dataset. In particular, uncaptioned images are fed to an Image\nCaptioning Module to generate the descriptions. Then, the GAN Module is trained\non both the input image and the machine-generated caption. To evaluate the\nresults, the performance of our solution is compared with the results obtained\nby the unconditional GAN. For the experiments, we chose to use the uncaptioned\ndataset LSUN bedroom. The results obtained in our study are preliminary but\nstill promising.", "published": "2019-10-09 15:14:09", "link": "http://arxiv.org/abs/1910.04056v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Closer Look At Feature Space Data Augmentation For Few-Shot Intent\n  Classification", "abstract": "New conversation topics and functionalities are constantly being added to\nconversational AI agents like Amazon Alexa and Apple Siri. As data collection\nand annotation is not scalable and is often costly, only a handful of examples\nfor the new functionalities are available, which results in poor generalization\nperformance. We formulate it as a Few-Shot Integration (FSI) problem where a\nfew examples are used to introduce a new intent. In this paper, we study six\nfeature space data augmentation methods to improve classification performance\nin FSI setting in combination with both supervised and unsupervised\nrepresentation learning methods such as BERT. Through realistic experiments on\ntwo public conversational datasets, SNIPS, and the Facebook Dialog corpus, we\nshow that data augmentation in feature space provides an effective way to\nimprove intent classification performance in few-shot setting beyond\ntraditional transfer learning approaches. In particular, we show that (a)\nupsampling in latent space is a competitive baseline for feature space\naugmentation (b) adding the difference between two examples to a new example is\na simple yet effective data augmentation method.", "published": "2019-10-09 18:00:04", "link": "http://arxiv.org/abs/1910.04176v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Domain-Relevant Embeddings for Medical Question Similarity", "abstract": "The rate at which medical questions are asked online far exceeds the capacity\nof qualified people to answer them, and many of these questions are not unique.\nIdentifying same-question pairs could enable questions to be answered more\neffectively. While many research efforts have focused on the problem of general\nquestion similarity for non-medical applications, these approaches do not\ngeneralize well to the medical domain, where medical expertise is often\nrequired to determine semantic similarity. In this paper, we show how a\nsemi-supervised approach of pre-training a neural network on medical\nquestion-answer pairs is a particularly useful intermediate task for the\nultimate goal of determining medical question similarity. While other\npre-training tasks yield an accuracy below 78.7% on this task, our model\nachieves an accuracy of 82.6% with the same number of training examples, and an\naccuracy of 80.0% with a much smaller training set.", "published": "2019-10-09 18:19:48", "link": "http://arxiv.org/abs/1910.04192v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Deep Learning Based Chatbot for Campus Psychological Therapy", "abstract": "In this paper, we propose Evebot, an innovative, sequence to sequence\n(Seq2seq) based, fully generative conversational system for the diagnosis of\nnegative emotions and prevention of depression through positively suggestive\nresponses. The system consists of an assembly of deep-learning based models,\nincluding Bi-LSTM based model for detecting negative emotions of users and\nobtaining psychological counselling related corpus for training the chatbot,\nanti-language sequence to sequence neural network, and maximum mutual\ninformation (MMI) model. As adolescents are reluctant to show their negative\nemotions in physical interaction, traditional methods of emotion analysis and\ncomforting methods may not work. Therefore, this system puts emphasis on using\nvirtual platform to detect signs of depression or anxiety, channel adolescents'\nstress and mood, and thus prevent the emergence of mental illness. We launched\nthe integrated chatbot system onto an online platform for real-world campus\napplications. Through a one-month user study, we observe better results in the\nincrease in positivity than other public chatbots in the control group.", "published": "2019-10-09 15:34:28", "link": "http://arxiv.org/abs/1910.06707v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "On the Possibility of Rewarding Structure Learning Agents: Mutual\n  Information on Linguistic Random Sets", "abstract": "We present a first attempt to elucidate a theoretical and empirical approach\nto design the reward provided by a natural language environment to some\nstructure learning agent. To this end, we revisit the Information Theory of\nunsupervised induction of phrase-structure grammars to characterize the\nbehavior of simulated actions modeled as set-valued random variables (random\nsets of linguistic samples) constituting semantic structures. Our results\nshowed empirical evidence of that simulated semantic structures (Open\nInformation Extraction triplets) can be distinguished from randomly constructed\nones by observing the Mutual Information among their constituents. This\nsuggests the possibility of rewarding structure learning agents without using\npretrained structural analyzers (oracle actors/experts).", "published": "2019-10-09 14:33:37", "link": "http://arxiv.org/abs/1910.04023v4", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IT", "math.IT", "stat.ML"], "primary_category": "cs.LG"}
