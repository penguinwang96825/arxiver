{"title": "Echo State Speech Recognition", "abstract": "We propose automatic speech recognition (ASR) models inspired by echo state\nnetwork (ESN), in which a subset of recurrent neural networks (RNN) layers in\nthe models are randomly initialized and untrained. Our study focuses on RNN-T\nand Conformer models, and we show that model quality does not drop even when\nthe decoder is fully randomized. Furthermore, such models can be trained more\nefficiently as the decoders do not require to be updated. By contrast,\nrandomizing encoders hurts model quality, indicating that optimizing encoders\nand learn proper representations for acoustic inputs are more vital for speech\nrecognition. Overall, we challenge the common practice of training ASR models\nfor all components, and demonstrate that ESN-based models can perform equally\nwell but enable more efficient training and storage than fully-trainable\ncounterparts.", "published": "2021-02-18 02:04:14", "link": "http://arxiv.org/abs/2102.09114v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Select Context in a Hierarchical and Global Perspective for\n  Open-domain Dialogue Generation", "abstract": "Open-domain multi-turn conversations mainly have three features, which are\nhierarchical semantic structure, redundant information, and long-term\ndependency. Grounded on these, selecting relevant context becomes a challenge\nstep for multi-turn dialogue generation. However, existing methods cannot\ndifferentiate both useful words and utterances in long distances from a\nresponse. Besides, previous work just performs context selection based on a\nstate in the decoder, which lacks a global guidance and could lead some focuses\non irrelevant or unnecessary information. In this paper, we propose a novel\nmodel with hierarchical self-attention mechanism and distant supervision to not\nonly detect relevant words and utterances in short and long distances, but also\ndiscern related information globally when decoding. Experimental results on two\npublic datasets of both automatic and human evaluations show that our model\nsignificantly outperforms other baselines in terms of fluency, coherence, and\ninformativeness.", "published": "2021-02-18 11:56:42", "link": "http://arxiv.org/abs/2102.09282v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UnibucKernel: Geolocating Swiss German Jodels Using Ensemble Learning", "abstract": "In this work, we describe our approach addressing the Social Media Variety\nGeolocation task featured in the 2021 VarDial Evaluation Campaign. We focus on\nthe second subtask, which is based on a data set formed of approximately 30\nthousand Swiss German Jodels. The dialect identification task is about\naccurately predicting the latitude and longitude of test samples. We frame the\ntask as a double regression problem, employing an XGBoost meta-learner with the\ncombined power of a variety of machine learning approaches to predict both\nlatitude and longitude. The models included in our ensemble range from simple\nregression techniques, such as Support Vector Regression, to deep neural\nmodels, such as a hybrid neural network and a neural transformer. To minimize\nthe prediction error, we approach the problem from a few different perspectives\nand consider various types of features, from low-level character n-grams to\nhigh-level BERT embeddings. The XGBoost ensemble resulted from combining the\npower of the aforementioned methods achieves a median distance of 23.6 km on\nthe test data, which places us on the third place in the ranking, at a\ndifference of 6.05 km and 2.9 km from the submissions on the first and second\nplaces, respectively.", "published": "2021-02-18 14:26:00", "link": "http://arxiv.org/abs/2102.09379v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Systematic Review of Natural Language Processing Applied to Radiology\n  Reports", "abstract": "NLP has a significant role in advancing healthcare and has been found to be\nkey in extracting structured information from radiology reports. Understanding\nrecent developments in NLP application to radiology is of significance but\nrecent reviews on this are limited. This study systematically assesses recent\nliterature in NLP applied to radiology reports. Our automated literature search\nyields 4,799 results using automated filtering, metadata enriching steps and\ncitation search combined with manual review. Our analysis is based on 21\nvariables including radiology characteristics, NLP methodology, performance,\nstudy, and clinical application characteristics. We present a comprehensive\nanalysis of the 164 publications retrieved with each categorised into one of 6\nclinical application categories. Deep learning use increases but conventional\nmachine learning approaches are still prevalent. Deep learning remains\nchallenged when data is scarce and there is little evidence of adoption into\nclinical practice. Despite 17% of studies reporting greater than 0.85 F1\nscores, it is hard to comparatively evaluate these approaches given that most\nof them use different datasets. Only 14 studies made their data and 15 their\ncode available with 10 externally validating results. Automated understanding\nof clinical narratives of the radiology reports has the potential to enhance\nthe healthcare process but reproducibility and explainability of models are\nimportant if the domain is to move applications into clinical use. More could\nbe done to share code enabling validation of methods on different institutional\ndata and to reduce heterogeneity in reporting of study properties allowing\ninter-study comparisons. Our results have significance for researchers\nproviding a systematic synthesis of existing work to build on, identify gaps,\nopportunities for collaboration and avoid duplication.", "published": "2021-02-18 18:54:41", "link": "http://arxiv.org/abs/2102.09553v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Entity-level Factual Consistency of Abstractive Text Summarization", "abstract": "A key challenge for abstractive summarization is ensuring factual consistency\nof the generated summary with respect to the original document. For example,\nstate-of-the-art models trained on existing datasets exhibit entity\nhallucination, generating names of entities that are not present in the source\ndocument. We propose a set of new metrics to quantify the entity-level factual\nconsistency of generated summaries and we show that the entity hallucination\nproblem can be alleviated by simply filtering the training data. In addition,\nwe propose a summary-worthy entity classification task to the training process\nas well as a joint entity and summary generation approach, which yield further\nimprovements in entity level metrics.", "published": "2021-02-18 03:07:28", "link": "http://arxiv.org/abs/2102.09130v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "From Extreme Multi-label to Multi-class: A Hierarchical Approach for\n  Automated ICD-10 Coding Using Phrase-level Attention", "abstract": "Clinical coding is the task of assigning a set of alphanumeric codes,\nreferred to as ICD (International Classification of Diseases), to a medical\nevent based on the context captured in a clinical narrative. The latest version\nof ICD, ICD-10, includes more than 70,000 codes. As this is a labor-intensive\nand error-prone task, automatic ICD coding of medical reports using machine\nlearning has gained significant interest in the last decade. Existing\nliterature has modeled this problem as a multi-label task. Nevertheless, such\nmulti-label approach is challenging due to the extremely large label set size.\nFurthermore, the interpretability of the predictions is essential for the\nendusers (e.g., healthcare providers and insurance companies). In this paper,\nwe propose a novel approach for automatic ICD coding by reformulating the\nextreme multi-label problem into a simpler multi-class problem using a\nhierarchical solution. We made this approach viable through extensive data\ncollection to acquire phrase-level human coder annotations to supervise our\nmodels on learning the specific relations between the input text and predicted\nICD codes. Our approach employs two independently trained networks, the\nsentence tagger and the ICD classifier, stacked hierarchically to predict a\ncodeset for a medical report. The sentence tagger identifies focus sentences\ncontaining a medical event or concept relevant to an ICD coding. Using a\nsupervised attention mechanism, the ICD classifier then assigns each focus\nsentence with an ICD code. The proposed approach outperforms strong baselines\nby large margins of 23% in subset accuracy, 18% in micro-F1, and 15% in\ninstance based F-1. With our proposed approach, interpretability is achieved\nnot through implicitly learned attention scores but by attributing each\nprediction to a particular sentence and words selected by human coders.", "published": "2021-02-18 03:19:14", "link": "http://arxiv.org/abs/2102.09136v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "On Typical Hesitant Fuzzy Languages and Automata", "abstract": "The idea of nondeterministic typical hesitant fuzzy automata is a\ngeneralization of the fuzzy automata presented by Costa and Bedregal. This\npaper, presents the sufficient and necessary conditions for a typical hesitant\nfuzzy language to be computed by nondeterministic typical hesitant fuzzy\nautomata. Besides, the paper introduces a new class of Typical Hesitant Fuzzy\nAutomata with crisp transitions, and we will show that this new class is\nequivalent to the original class introduced by Costa and Bedregal", "published": "2021-02-18 13:59:54", "link": "http://arxiv.org/abs/2102.09347v1", "categories": ["cs.FL", "cs.CL"], "primary_category": "cs.FL"}
{"title": "Meta-Transfer Learning for Low-Resource Abstractive Summarization", "abstract": "Neural abstractive summarization has been studied in many pieces of\nliterature and achieves great success with the aid of large corpora. However,\nwhen encountering novel tasks, one may not always benefit from transfer\nlearning due to the domain shifting problem, and overfitting could happen\nwithout adequate labeled examples. Furthermore, the annotations of abstractive\nsummarization are costly, which often demand domain knowledge to ensure the\nground-truth quality. Thus, there are growing appeals for Low-Resource\nAbstractive Summarization, which aims to leverage past experience to improve\nthe performance with limited labeled examples of target corpus. In this paper,\nwe propose to utilize two knowledge-rich sources to tackle this problem, which\nare large pre-trained models and diverse existing corpora. The former can\nprovide the primary ability to tackle summarization tasks; the latter can help\ndiscover common syntactic or semantic information to improve the generalization\nability. We conduct extensive experiments on various summarization corpora with\ndifferent writing styles and forms. The results demonstrate that our approach\nachieves the state-of-the-art on 6 corpora in low-resource scenarios, with only\n0.7% of trainable parameters compared to previous work.", "published": "2021-02-18 14:42:09", "link": "http://arxiv.org/abs/2102.09397v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fake News Detection: a comparison between available Deep Learning\n  techniques in vector space", "abstract": "Fake News Detection is an essential problem in the field of Natural Language\nProcessing. The benefits of an effective solution in this area are manifold for\nthe goodwill of society. On a surface level, it broadly matches with the\ngeneral problem of text classification. Researchers have proposed various\napproaches to tackle fake news using simple as well as some complex techniques.\nIn this paper, we try to make a comparison between the present Deep Learning\ntechniques by representing the news instances in some vector space using a\ncombination of common mathematical operations with available vector space\nrepresentations. We do a number of experiments using various combinations and\npermutations. Finally, we conclude with a sound analysis of the results and\nevaluate the reasons for such results.", "published": "2021-02-18 16:42:28", "link": "http://arxiv.org/abs/2102.09470v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Going Full-TILT Boogie on Document Understanding with Text-Image-Layout\n  Transformer", "abstract": "We address the challenging problem of Natural Language Comprehension beyond\nplain-text documents by introducing the TILT neural network architecture which\nsimultaneously learns layout information, visual features, and textual\nsemantics. Contrary to previous approaches, we rely on a decoder capable of\nunifying a variety of problems involving natural language. The layout is\nrepresented as an attention bias and complemented with contextualized visual\ninformation, while the core of our model is a pretrained encoder-decoder\nTransformer. Our novel approach achieves state-of-the-art results in extracting\ninformation from documents and answering questions which demand layout\nunderstanding (DocVQA, CORD, SROIE). At the same time, we simplify the process\nby employing an end-to-end model.", "published": "2021-02-18 18:51:47", "link": "http://arxiv.org/abs/2102.09550v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fixing Errors of the Google Voice Recognizer through Phonetic Distance\n  Metrics", "abstract": "Speech recognition systems for the Spanish language, such as Google's,\nproduce errors quite frequently when used in applications of a specific domain.\nThese errors mostly occur when recognizing words new to the recognizer's\nlanguage model or ad hoc to the domain. This article presents an algorithm that\nuses Levenshtein distance on phonemes to reduce the speech recognizer's errors.\nThe preliminary results show that it is possible to correct the recognizer's\nerrors significantly by using this metric and using a dictionary of specific\nphrases from the domain of the application. Despite being designed for\nparticular domains, the algorithm proposed here is of general application. The\nphrases that must be recognized can be explicitly defined for each application,\nwithout the algorithm having to be modified. It is enough to indicate to the\nalgorithm the set of sentences on which it must work. The algorithm's\ncomplexity is $O(tn)$, where $t$ is the number of words in the transcript to be\ncorrected, and $n$ is the number of phrases specific to the domain.", "published": "2021-02-18 23:54:59", "link": "http://arxiv.org/abs/2102.09680v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "WebRED: Effective Pretraining And Finetuning For Relation Extraction On\n  The Web", "abstract": "Relation extraction is used to populate knowledge bases that are important to\nmany applications. Prior datasets used to train relation extraction models\neither suffer from noisy labels due to distant supervision, are limited to\ncertain domains or are too small to train high-capacity models. This constrains\ndownstream applications of relation extraction. We therefore introduce: WebRED\n(Web Relation Extraction Dataset), a strongly-supervised human annotated\ndataset for extracting relationships from a variety of text found on the World\nWide Web, consisting of ~110K examples. We also describe the methods we used to\ncollect ~200M examples as pre-training data for this task. We show that\ncombining pre-training on a large weakly supervised dataset with fine-tuning on\na small strongly-supervised dataset leads to better relation extraction\nperformance. We provide baselines for this new dataset and present a case for\nthe importance of human annotation in improving the performance of relation\nextraction from text found on the web.", "published": "2021-02-18 23:56:12", "link": "http://arxiv.org/abs/2102.09681v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "JST-RR Model: Joint Modeling of Ratings and Reviews in Sentiment-Topic\n  Prediction", "abstract": "Analysis of online reviews has attracted great attention with broad\napplications. Often times, the textual reviews are coupled with the numerical\nratings in the data. In this work, we propose a probabilistic model to\naccommodate both textual reviews and overall ratings with consideration of\ntheir intrinsic connection for a joint sentiment-topic prediction. The key of\nthe proposed method is to develop a unified generative model where the topic\nmodeling is constructed based on review texts and the sentiment prediction is\nobtained by combining review texts and overall ratings. The inference of model\nparameters are obtained by an efficient Gibbs sampling procedure. The proposed\nmethod can enhance the prediction accuracy of review data and achieve an\neffective detection of interpretable topics and sentiments. The merits of the\nproposed method are elaborated by the case study from Amazon datasets and\nsimulation studies.", "published": "2021-02-18 15:47:34", "link": "http://arxiv.org/abs/2102.11048v1", "categories": ["cs.CL", "stat.ME"], "primary_category": "cs.CL"}
{"title": "Quiz-Style Question Generation for News Stories", "abstract": "A large majority of American adults get at least some of their news from the\nInternet. Even though many online news products have the goal of informing\ntheir users about the news, they lack scalable and reliable tools for measuring\nhow well they are achieving this goal, and therefore have to resort to noisy\nproxy metrics (e.g., click-through rates or reading time) to track their\nperformance.\n  As a first step towards measuring news informedness at a scale, we study the\nproblem of quiz-style multiple-choice question generation, which may be used to\nsurvey users about their knowledge of recent news. In particular, we formulate\nthe problem as two sequence-to-sequence tasks: question-answer generation (QAG)\nand distractor, or incorrect answer, generation (DG). We introduce NewsQuizQA,\nthe first dataset intended for quiz-style question-answer generation,\ncontaining 20K human written question-answer pairs from 5K news article\nsummaries. Using this dataset, we propose a series of novel techniques for\napplying large pre-trained Transformer encoder-decoder models, namely PEGASUS\nand T5, to the tasks of question-answer generation and distractor generation.\n  We show that our models outperform strong baselines using both automated\nmetrics and human raters. We provide a case study of running weekly quizzes on\nreal-world users via the Google Surveys platform over the course of two months.\nWe found that users generally found the automatically generated questions to be\neducational and enjoyable. Finally, to serve the research community, we are\nreleasing the NewsQuizQA dataset.", "published": "2021-02-18 01:06:58", "link": "http://arxiv.org/abs/2102.09094v1", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Training Large-Scale News Recommenders with Pretrained Language Models\n  in the Loop", "abstract": "News recommendation calls for deep insights of news articles' underlying\nsemantics. Therefore, pretrained language models (PLMs), like BERT and RoBERTa,\nmay substantially contribute to the recommendation quality. However, it's\nextremely challenging to have news recommenders trained together with such big\nmodels: the learning of news recommenders requires intensive news encoding\noperations, whose cost is prohibitive if PLMs are used as the news encoder. In\nthis paper, we propose a novel framework, {SpeedyFeed}, which efficiently\ntrains PLMs-based news recommenders of superior quality. SpeedyFeed is\nhighlighted for its light-weighted encoding pipeline, which gives rise to three\nmajor advantages. Firstly, it makes the intermedia results fully reusable for\nthe training workflow, which removes most of the repetitive but redundant\nencoding operations. Secondly, it improves the data efficiency of the training\nworkflow, where non-informative data can be eliminated from encoding. Thirdly,\nit further saves the cost by leveraging simplified news encoding and compact\nnews representation. Extensive experiments show that SpeedyFeed leads to more\nthan 100$\\times$ acceleration of the training process, which enables big models\nto be trained efficiently and effectively over massive user data. The\nwell-trained PLMs-based model from SpeedyFeed demonstrates highly competitive\nperformance, where it outperforms the state-of-the-art news recommenders with\nsignificant margins. SpeedyFeed is also a model-agnostic framework, which is\npotentially applicable to a wide spectrum of content-based recommender systems;\ntherefore, the whole framework is open-sourced to facilitate the progress in\nrelated areas.", "published": "2021-02-18 11:08:38", "link": "http://arxiv.org/abs/2102.09268v2", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Regular Expressions for Fast-response COVID-19 Text Classification", "abstract": "Text classifiers are at the core of many NLP applications and use a variety\nof algorithmic approaches and software. This paper introduces infrastructure\nand methodologies for text classifiers based on large-scale regular\nexpressions. In particular, we describe how Facebook determines if a given\npiece of text - anything from a hashtag to a post - belongs to a narrow topic\nsuch as COVID-19. To fully define a topic and evaluate classifier performance\nwe employ human-guided iterations of keyword discovery, but do not require\nlabeled data. For COVID-19, we build two sets of regular expressions: (1) for\n66 languages, with 99% precision and recall >50%, (2) for the 11 most common\nlanguages, with precision >90% and recall >90%. Regular expressions enable\nlow-latency queries from multiple platforms. Response to challenges like\nCOVID-19 is fast and so are revisions. Comparisons to a DNN classifier show\nexplainable results, higher precision and recall, and less overfitting. Our\nlearnings can be applied to other narrow-topic classifiers.", "published": "2021-02-18 17:48:49", "link": "http://arxiv.org/abs/2102.09507v4", "categories": ["cs.CL", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "SLAKE: A Semantically-Labeled Knowledge-Enhanced Dataset for Medical\n  Visual Question Answering", "abstract": "Medical visual question answering (Med-VQA) has tremendous potential in\nhealthcare. However, the development of this technology is hindered by the\nlacking of publicly-available and high-quality labeled datasets for training\nand evaluation. In this paper, we present a large bilingual dataset, SLAKE,\nwith comprehensive semantic labels annotated by experienced physicians and a\nnew structural medical knowledge base for Med-VQA. Besides, SLAKE includes\nricher modalities and covers more human body parts than the currently available\ndataset. We show that SLAKE can be used to facilitate the development and\nevaluation of Med-VQA systems. The dataset can be downloaded from\nhttp://www.med-vqa.com/slake.", "published": "2021-02-18 18:44:50", "link": "http://arxiv.org/abs/2102.09542v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Modelling Paralinguistic Properties in Conversational Speech to Detect\n  Bipolar Disorder and Borderline Personality Disorder", "abstract": "Bipolar disorder (BD) and borderline personality disorder (BPD) are two\nchronic mental health conditions that clinicians find challenging to\ndistinguish based on clinical interviews, due to their overlapping symptoms. In\nthis work, we investigate the automatic detection of these two conditions by\nmodelling both verbal and non-verbal cues in a set of interviews. We propose a\nnew approach of modelling short-term features with visibility-signature\ntransform, and compare it with widely used high-level statistical functions. We\ndemonstrate the superior performance of our proposed signature-based model.\nFurthermore, we show the role of different sets of features in characterising\nBD and BPD.", "published": "2021-02-18 20:47:03", "link": "http://arxiv.org/abs/2102.09607v1", "categories": ["cs.LG", "cs.CL", "cs.SD", "eess.AS", "60L10"], "primary_category": "cs.LG"}
{"title": "MUDES: Multilingual Detection of Offensive Spans", "abstract": "The interest in offensive content identification in social media has grown\nsubstantially in recent years. Previous work has dealt mostly with post level\nannotations. However, identifying offensive spans is useful in many ways. To\nhelp coping with this important challenge, we present MUDES, a multilingual\nsystem to detect offensive spans in texts. MUDES features pre-trained models, a\nPython API for developers, and a user-friendly web-based interface. A detailed\ndescription of MUDES' components is presented in this paper.", "published": "2021-02-18 23:19:00", "link": "http://arxiv.org/abs/2102.09665v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Semantic Parsing to Manipulate Relational Database For a Management\n  System", "abstract": "Chatbots and AI assistants have claimed their importance in today life. The\nmain reason behind adopting this technology is to connect with the user,\nunderstand their requirements, and fulfill them. This has been achieved but at\nthe cost of heavy training data and complex learning models. This work is\ncarried out proposes a simple algorithm, a model which can be implemented in\ndifferent fields each with its own work scope. The proposed model converts\nhuman language text to computer-understandable SQL queries. The model requires\ndata only related to the specific field, saving data space. This model performs\nlinear computation hence solving the computational complexity. This work also\ndefines the stages where a new methodology is implemented and what previous\nmethod was adopted to fulfill the requirement at that stage. Two datasets\navailable online will be used in this work, the ATIS dataset, and WikiSQL. This\nwork compares the computation time among the 2 datasets and also compares the\naccuracy of both. This paper works over basic Natural language processing tasks\nlike semantic parsing, NER, parts of speech and tends to achieve results\nthrough these simple methods.", "published": "2021-02-18 15:08:23", "link": "http://arxiv.org/abs/2102.11047v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fundamental Frequency Feature Normalization and Data Augmentation for\n  Child Speech Recognition", "abstract": "Automatic speech recognition (ASR) systems for young children are needed due\nto the importance of age-appropriate educational technology. Because of the\nlack of publicly available young child speech data, feature extraction\nstrategies such as feature normalization and data augmentation must be\nconsidered to successfully train child ASR systems. This study proposes a novel\ntechnique for child ASR using both feature normalization and data augmentation\nmethods based on the relationship between formants and fundamental frequency\n($f_o$). Both the $f_o$ feature normalization and data augmentation techniques\nare implemented as a frequency shift in the Mel domain. These techniques are\nevaluated on a child read speech ASR task. Child ASR systems are trained by\nadapting a BLSTM-based acoustic model trained on adult speech. Using both $f_o$\nnormalization and data augmentation results in a relative word error rate (WER)\nimprovement of 19.3% over the baseline when tested on the OGI Kids' Speech\nCorpus, and the resulting child ASR system achieves the best WER currently\nreported on this corpus.", "published": "2021-02-18 01:31:54", "link": "http://arxiv.org/abs/2102.09106v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Gaussian Kernelized Self-Attention for Long Sequence Data and Its\n  Application to CTC-based Speech Recognition", "abstract": "Self-attention (SA) based models have recently achieved significant\nperformance improvements in hybrid and end-to-end automatic speech recognition\n(ASR) systems owing to their flexible context modeling capability. However, it\nis also known that the accuracy degrades when applying SA to long sequence\ndata. This is mainly due to the length mismatch between the inference and\ntraining data because the training data are usually divided into short segments\nfor efficient training. To mitigate this mismatch, we propose a new\narchitecture, which is a variant of the Gaussian kernel, which itself is a\nshift-invariant kernel. First, we mathematically demonstrate that\nself-attention with shared weight parameters for queries and keys is equivalent\nto a normalized kernel function. By replacing this kernel function with the\nproposed Gaussian kernel, the architecture becomes completely shift-invariant\nwith the relative position information embedded using a frame indexing\ntechnique. The proposed Gaussian kernelized SA was applied to connectionist\ntemporal classification (CTC) based ASR. An experimental evaluation with the\nCorpus of Spontaneous Japanese (CSJ) and TEDLIUM 3 benchmarks shows that the\nproposed SA achieves a significant improvement in accuracy (e.g., from 24.0%\nWER to 6.0% in CSJ) in long sequence data without any windowing techniques.", "published": "2021-02-18 05:51:53", "link": "http://arxiv.org/abs/2102.09168v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Low Resource Audio-to-Lyrics Alignment From Polyphonic Music Recordings", "abstract": "Lyrics alignment in long music recordings can be memory exhaustive when\nperformed in a single pass. In this study, we present a novel method that\nperforms audio-to-lyrics alignment with a low memory consumption footprint\nregardless of the duration of the music recording. The proposed system first\nspots the anchoring words within the audio signal. With respect to these\nanchors, the recording is then segmented and a second-pass alignment is\nperformed to obtain the word timings. We show that our audio-to-lyrics\nalignment system performs competitively with the state-of-the-art, while\nrequiring much less computational resources. In addition, we utilise our lyrics\nalignment system to segment the music recordings into sentence-level chunks.\nNotably on the segmented recordings, we report the lyrics transcription scores\non a number of benchmark test sets. Finally, our experiments highlight the\nimportance of the source separation step for good performance on the\ntranscription and alignment tasks. For reproducibility, we publicly share our\ncode with the research community.", "published": "2021-02-18 07:54:56", "link": "http://arxiv.org/abs/2102.09202v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Generative Speech Coding with Predictive Variance Regularization", "abstract": "The recent emergence of machine-learning based generative models for speech\nsuggests a significant reduction in bit rate for speech codecs is possible.\nHowever, the performance of generative models deteriorates significantly with\nthe distortions present in real-world input signals. We argue that this\ndeterioration is due to the sensitivity of the maximum likelihood criterion to\noutliers and the ineffectiveness of modeling a sum of independent signals with\na single autoregressive model. We introduce predictive-variance regularization\nto reduce the sensitivity to outliers, resulting in a significant increase in\nperformance. We show that noise reduction to remove unwanted signals can\nsignificantly increase performance. We provide extensive subjective performance\nevaluations that show that our system based on generative modeling provides\nstate-of-the-art coding performance at 3 kb/s for real-world speech signals at\nreasonable computational complexity.", "published": "2021-02-18 23:01:13", "link": "http://arxiv.org/abs/2102.09660v1", "categories": ["eess.AS", "cs.SD", "94", "I.m"], "primary_category": "eess.AS"}
{"title": "DINO: A Conditional Energy-Based GAN for Domain Translation", "abstract": "Domain translation is the process of transforming data from one domain to\nanother while preserving the common semantics. Some of the most popular domain\ntranslation systems are based on conditional generative adversarial networks,\nwhich use source domain data to drive the generator and as an input to the\ndiscriminator. However, this approach does not enforce the preservation of\nshared semantics since the conditional input can often be ignored by the\ndiscriminator. We propose an alternative method for conditioning and present a\nnew framework, where two networks are simultaneously trained, in a supervised\nmanner, to perform domain translation in opposite directions. Our method is not\nonly better at capturing the shared information between two domains but is more\ngeneric and can be applied to a broader range of problems. The proposed\nframework performs well even in challenging cross-modal translations, such as\nvideo-driven speech reconstruction, for which other systems struggle to\nmaintain correspondence.", "published": "2021-02-18 11:52:45", "link": "http://arxiv.org/abs/2102.09281v1", "categories": ["cs.LG", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Dynamic curriculum learning via data parameters for noise robust keyword\n  spotting", "abstract": "We propose dynamic curriculum learning via data parameters for noise robust\nkeyword spotting. Data parameter learning has recently been introduced for\nimage processing, where weight parameters, so-called data parameters, for\ntarget classes and instances are introduced and optimized along with model\nparameters. The data parameters scale logits and control importance over\nclasses and instances during training, which enables automatic curriculum\nlearning without additional annotations for training data. Similarly, in this\npaper, we propose using this curriculum learning approach for acoustic\nmodeling, and train an acoustic model on clean and noisy utterances with the\ndata parameters. The proposed approach automatically learns the difficulty of\nthe classes and instances, e.g. due to low speech to noise ratio (SNR), in the\ngradient descent optimization and performs curriculum learning. This curriculum\nlearning leads to overall improvement of the accuracy of the acoustic model. We\nevaluate the effectiveness of the proposed approach on a keyword spotting task.\nExperimental results show 7.7% relative reduction in false reject ratio with\nthe data parameters compared to a baseline model which is simply trained on the\nmulticonditioned dataset.", "published": "2021-02-18 23:26:07", "link": "http://arxiv.org/abs/2102.09666v1", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "AudioVisual Speech Synthesis: A brief literature review", "abstract": "This brief literature review studies the problem of audiovisual speech\nsynthesis, which is the problem of generating an animated talking head given a\ntext as input. Due to the high complexity of this problem, we approach it as\nthe composition of two problems. Specifically, that of Text-to-Speech (TTS)\nsynthesis as well as the voice-driven talking head animation. For TTS, we\npresent models that are used to map text to intermediate acoustic\nrepresentations, e.g. mel-spectrograms, as well as models that generate voice\nsignals conditioned on these intermediate representations, i.e vocoders. For\nthe talking-head animation problem, we categorize approaches based on whether\nthey produce human faces or anthropomorphic figures. An attempt is also made to\ndiscuss the importance of the choice of facial models in the second case.\nThroughout the review, we briefly describe the most important work in\naudiovisual speech synthesis, trying to highlight the advantages and\ndisadvantages of the various approaches.", "published": "2021-02-18 19:13:48", "link": "http://arxiv.org/abs/2103.03927v1", "categories": ["cs.SD", "cs.CV", "cs.LG", "eess.AS", "eess.IV"], "primary_category": "cs.SD"}
