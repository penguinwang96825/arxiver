{"title": "Explanatory Summarization with Discourse-Driven Planning", "abstract": "Lay summaries for scientific documents typically include explanations to help\nreaders grasp sophisticated concepts or arguments. However, current automatic\nsummarization methods do not explicitly model explanations, which makes it\ndifficult to align the proportion of explanatory content with human-written\nsummaries. In this paper, we present a plan-based approach that leverages\ndiscourse frameworks to organize summary generation and guide explanatory\nsentences by prompting responses to the plan. Specifically, we propose two\ndiscourse-driven planning strategies, where the plan is conditioned as part of\nthe input or part of the output prefix, respectively. Empirical experiments on\nthree lay summarization datasets show that our approach outperforms existing\nstate-of-the-art methods in terms of summary quality, and it enhances model\nrobustness, controllability, and mitigates hallucination.", "published": "2025-04-27 19:47:36", "link": "http://arxiv.org/abs/2504.19339v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unified Multi-Task Learning & Model Fusion for Efficient Language Model Guardrailing", "abstract": "The trend towards large language models (LLMs) for guardrailing against\nundesired behaviors is increasing and has shown promise for censoring user\ninputs. However, increased latency, memory consumption, hosting expenses and\nnon-structured outputs can make their use prohibitive.\n  In this work, we show that task-specific data generation can lead to\nfine-tuned classifiers that significantly outperform current state of the art\n(SoTA) while being orders of magnitude smaller. Secondly, we show that using a\nsingle model, \\texttt{MultiTaskGuard}, that is pretrained on a large\nsynthetically generated dataset with unique task instructions further improves\ngeneralization. Thirdly, our most performant models, \\texttt{UniGuard}, are\nfound using our proposed search-based model merging approach that finds an\noptimal set of parameters to combine single-policy models and multi-policy\nguardrail models. % On 7 public datasets and 4 guardrail benchmarks we created,\nour efficient guardrail classifiers improve over the best performing SoTA\npublicly available LLMs and 3$^{\\text{rd}}$ party guardrail APIs in detecting\nunsafe and safe behaviors by an average F1 score improvement of \\textbf{29.92}\npoints over Aegis-LlamaGuard and \\textbf{21.62} over \\texttt{gpt-4o},\nrespectively. Lastly, our guardrail synthetic data generation process that uses\ncustom task-specific guardrail poli", "published": "2025-04-27 19:07:58", "link": "http://arxiv.org/abs/2504.19333v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "BrowseComp-ZH: Benchmarking Web Browsing Ability of Large Language Models in Chinese", "abstract": "As large language models (LLMs) evolve into tool-using agents, the ability to\nbrowse the web in real-time has become a critical yardstick for measuring their\nreasoning and retrieval competence. Existing benchmarks such as BrowseComp\nconcentrate on English and overlook the linguistic, infrastructural, and\ncensorship-related complexities of other major information ecosystems -- most\nnotably Chinese. To address this gap, we introduce BrowseComp-ZH, a\nhigh-difficulty benchmark purpose-built to comprehensively evaluate LLM agents\non the Chinese web. BrowseComp-ZH consists of 289 multi-hop questions spanning\n11 diverse domains. Each question is reverse-engineered from a short,\nobjective, and easily verifiable answer (e.g., a date, number, or proper noun).\nA two-stage quality control protocol is applied to strive for high question\ndifficulty and answer uniqueness. We benchmark over 20 state-of-the-art\nlanguage models and agentic search systems on our proposed BrowseComp-ZH.\nDespite their strong conversational and retrieval capabilities, most models\nstruggle severely: a large number achieve accuracy rates below 10%, and only a\nhandful exceed 20%. Even the best-performing system, OpenAI's DeepResearch,\nreaches just 42.9%. These results demonstrate the considerable difficulty of\nBrowseComp-ZH, where success demands not only effective retrieval strategies,\nbut also sophisticated reasoning and information reconciliation -- capabilities\nthat current models still struggle to master. Our dataset, construction\nguidelines, and benchmark results have been publicly released at\nhttps://github.com/PALIN2018/BrowseComp-ZH.", "published": "2025-04-27 17:32:43", "link": "http://arxiv.org/abs/2504.19314v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AndroidGen: Building an Android Language Agent under Data Scarcity", "abstract": "Large language models have opened up a world of possibilities for various NLP\ntasks, sparking optimism for the future. Despite their potential, LLMs have yet\nto be widely used as agents on real mobile devices. The main challenge is the\nneed for high-quality data sources. Time constraints and labor intensity often\nhinder human annotation. On the other hand, existing LLMs exhibit inadequate\ncompletion rates and need a robust data filtration strategy. Given these\nchallenges, we develop a framework called AndroidGen to enhance the\ncapabilities of LLM-based agents under data scarcity. In addition, we leverage\nAndroidGen to collect trajectories given human tasks and train open-source LLMs\non these trajectories to develop an open-source mobile agent without manually\nlabeled trajectories. We extensively evaluate AndroidGen with AndroidWorld,\nAitW, and various popular applications, demonstrating its improvements and\nrevealing potential areas for future improvement. Code, model, and data are\navailable at https://github.com/THUDM/AndroidGen.", "published": "2025-04-27 16:30:10", "link": "http://arxiv.org/abs/2504.19298v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Anyprefer: An Agentic Framework for Preference Data Synthesis", "abstract": "High-quality preference data is essential for aligning foundation models with\nhuman values through preference learning. However, manual annotation of such\ndata is often time-consuming and costly. Recent methods often adopt a\nself-rewarding approach, where the target model generates and annotates its own\npreference data, but this can lead to inaccuracies since the reward model\nshares weights with the target model, thereby amplifying inherent biases. To\naddress these issues, we propose Anyprefer, a framework designed to synthesize\nhigh-quality preference data for aligning the target model. Anyprefer frames\nthe data synthesis process as a cooperative two-player Markov Game, where the\ntarget model and the judge model collaborate together. Here, a series of\nexternal tools are introduced to assist the judge model in accurately rewarding\nthe target model's responses, mitigating biases in the rewarding process. In\naddition, a feedback mechanism is introduced to optimize prompts for both\nmodels, enhancing collaboration and improving data quality. The synthesized\ndata is compiled into a new preference dataset, Anyprefer-V1, consisting of 58K\nhigh-quality preference pairs. Extensive experiments show that Anyprefer\nsignificantly improves model alignment performance across four main\napplications, covering 21 datasets, achieving average improvements of 18.55% in\nfive natural language generation datasets, 3.66% in nine vision-language\nunderstanding datasets, 30.05% in three medical image analysis datasets, and\n16.00% in four visuo-motor control tasks.", "published": "2025-04-27 15:21:59", "link": "http://arxiv.org/abs/2504.19276v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "VIST-GPT: Ushering in the Era of Visual Storytelling with LLMs?", "abstract": "Visual storytelling is an interdisciplinary field combining computer vision\nand natural language processing to generate cohesive narratives from sequences\nof images. This paper presents a novel approach that leverages recent\nadvancements in multimodal models, specifically adapting transformer-based\narchitectures and large multimodal models, for the visual storytelling task.\nLeveraging the large-scale Visual Storytelling (VIST) dataset, our VIST-GPT\nmodel produces visually grounded, contextually appropriate narratives. We\naddress the limitations of traditional evaluation metrics, such as BLEU,\nMETEOR, ROUGE, and CIDEr, which are not suitable for this task. Instead, we\nutilize RoViST and GROOVIST, novel reference-free metrics designed to assess\nvisual storytelling, focusing on visual grounding, coherence, and\nnon-redundancy. These metrics provide a more nuanced evaluation of narrative\nquality, aligning closely with human judgment.", "published": "2025-04-27 14:55:51", "link": "http://arxiv.org/abs/2504.19267v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Uncertainty Quantification for Language Models: A Suite of Black-Box, White-Box, LLM Judge, and Ensemble Scorers", "abstract": "Hallucinations are a persistent problem with Large Language Models (LLMs). As\nthese models become increasingly used in high-stakes domains, such as\nhealthcare and finance, the need for effective hallucination detection is\ncrucial. To this end, we propose a versatile framework for zero-resource\nhallucination detection that practitioners can apply to real-world use cases.\nTo achieve this, we adapt a variety of existing uncertainty quantification (UQ)\ntechniques, including black-box UQ, white-box UQ, and LLM-as-a-Judge,\ntransforming them as necessary into standardized response-level confidence\nscores ranging from 0 to 1. To enhance flexibility, we introduce a tunable\nensemble approach that incorporates any combination of the individual\nconfidence scores. This approach enables practitioners to optimize the ensemble\nfor a specific use case for improved performance. To streamline implementation,\nthe full suite of scorers is offered in this paper's companion Python toolkit,\nUQLM. To evaluate the performance of the various scorers, we conduct an\nextensive set of experiments using several LLM question-answering benchmarks.\nWe find that our tunable ensemble typically surpasses its individual components\nand outperforms existing hallucination detection methods. Our results\ndemonstrate the benefits of customized hallucination detection strategies for\nimproving the accuracy and reliability of LLMs.", "published": "2025-04-27 14:24:45", "link": "http://arxiv.org/abs/2504.19254v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Dynamic Embedded Topic Models: properties and recommendations based on diverse corpora", "abstract": "We measure the effects of several implementation choices for the Dynamic\nEmbedded Topic Model, as applied to five distinct diachronic corpora, with the\ngoal of isolating important decisions for its use and further development. We\nidentify priorities that will maximize utility in applied scholarship,\nincluding the practical scalability of vocabulary size to best exploit the\nstrengths of embedded representations, and more flexible modeling of intervals\nto accommodate the uneven temporal distributions of historical writing. Of\nsimilar importance, we find performance is not significantly or consistently\naffected by several aspects that otherwise limit the model's application or\nmight consume the resources of a grid search.", "published": "2025-04-27 12:25:09", "link": "http://arxiv.org/abs/2504.19209v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "WuNeng: Hybrid State with Attention", "abstract": "The WuNeng architecture introduces a novel approach to enhancing the\nexpressivity and power of large language models by integrating recurrent neural\nnetwork (RNN)-based RWKV-7 with advanced attention mechanisms, prioritizing\nheightened contextual coherence over reducing KV cache size. Building upon the\nhybrid-head concept from Hymba, WuNeng augments standard multi-head attention\nwith additional RWKV-7 state-driven heads, rather than replacing existing\nheads, to enrich the model's representational capacity. A cross-head\ninteraction technique fosters dynamic synergy among standard, state-driven, and\nnewly introduced middle heads, leveraging concatenation, additive modulation,\nand gated fusion for robust information integration. Furthermore, a multi-token\nstate processing mechanism harnesses the continuous RWKV-7 state to capture\nintricate, sequence-wide dependencies, significantly boosting expressivity.\nRemarkably, these enhancements are achieved with minimal additional parameters,\nensuring efficiency while empowering the model to excel in complex reasoning\nand sequence generation tasks. WuNeng sets a new standard for balancing\nexpressivity and computational efficiency in modern neural architectures.", "published": "2025-04-27 10:48:56", "link": "http://arxiv.org/abs/2504.19191v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hierarchical Attention Generates Better Proofs", "abstract": "Large language models (LLMs) have shown promise in formal theorem proving,\nbut their token-level processing often fails to capture the inherent\nhierarchical nature of mathematical proofs. We introduce \\textbf{Hierarchical\nAttention}, a regularization method that aligns LLMs' attention mechanisms with\nmathematical reasoning structures. Our approach establishes a five-level\nhierarchy from foundational elements to high-level concepts, ensuring\nstructured information flow in proof generation. Experiments demonstrate that\nour method improves proof success rates by 2.05\\% on miniF2F and 1.69\\% on\nProofNet while reducing proof complexity by 23.81\\% and 16.50\\% respectively.\nThe code is available at https://github.com/Car-pe/HAGBP.", "published": "2025-04-27 10:35:05", "link": "http://arxiv.org/abs/2504.19188v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.LO"], "primary_category": "cs.LG"}
{"title": "SPC: Evolving Self-Play Critic via Adversarial Games for LLM Reasoning", "abstract": "Evaluating the step-by-step reliability of large language model (LLM)\nreasoning, such as Chain-of-Thought, remains challenging due to the difficulty\nand cost of obtaining high-quality step-level supervision. In this paper, we\nintroduce Self-Play Critic (SPC), a novel approach where a critic model evolves\nits ability to assess reasoning steps through adversarial self-play games,\neliminating the need for manual step-level annotation. SPC involves fine-tuning\ntwo copies of a base model to play two roles, namely a \"sneaky generator\" that\ndeliberately produces erroneous steps designed to be difficult to detect, and a\n\"critic\" that analyzes the correctness of reasoning steps. These two models\nengage in an adversarial game in which the generator aims to fool the critic,\nwhile the critic model seeks to identify the generator's errors. Using\nreinforcement learning based on the game outcomes, the models iteratively\nimprove; the winner of each confrontation receives a positive reward and the\nloser receives a negative reward, driving continuous self-evolution.\nExperiments on three reasoning process benchmarks (ProcessBench, PRM800K,\nDeltaBench) demonstrate that our SPC progressively enhances its error detection\ncapabilities (e.g., accuracy increases from 70.8% to 77.7% on ProcessBench) and\nsurpasses strong baselines, including distilled R1 model. Furthermore, applying\nSPC to guide the test-time search of diverse LLMs significantly improves their\nmathematical reasoning performance on MATH500 and AIME2024, outperforming\nstate-of-the-art process reward models.", "published": "2025-04-27 08:45:06", "link": "http://arxiv.org/abs/2504.19162v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "APE-Bench I: Towards File-level Automated Proof Engineering of Formal Math Libraries", "abstract": "Recent progress in large language models (LLMs) has shown promise in formal\ntheorem proving, yet existing benchmarks remain limited to isolated, static\nproof tasks, failing to capture the iterative, engineering-intensive workflows\nof real-world formal mathematics libraries. Motivated by analogous advances in\nsoftware engineering, we introduce the paradigm of Automated Proof Engineering\n(APE), which aims to automate proof engineering tasks such as feature addition,\nproof refactoring, and bug fixing using LLMs. To facilitate research in this\ndirection, we present APE-Bench I, the first realistic benchmark built from\nreal-world commit histories of Mathlib4, featuring diverse file-level tasks\ndescribed in natural language and verified via a hybrid approach combining the\nLean compiler and LLM-as-a-Judge. We further develop Eleanstic, a scalable\nparallel verification infrastructure optimized for proof checking across\nmultiple versions of Mathlib. Empirical results on state-of-the-art LLMs\ndemonstrate strong performance on localized edits but substantial degradation\non handling complex proof engineering. This work lays the foundation for\ndeveloping agentic workflows in proof engineering, with future benchmarks\ntargeting multi-file coordination, project-scale verification, and autonomous\nagents capable of planning, editing, and repairing formal libraries.", "published": "2025-04-27 05:04:02", "link": "http://arxiv.org/abs/2504.19110v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Privacy-Preserving Federated Embedding Learning for Localized Retrieval-Augmented Generation", "abstract": "Retrieval-Augmented Generation (RAG) has recently emerged as a promising\nsolution for enhancing the accuracy and credibility of Large Language Models\n(LLMs), particularly in Question & Answer tasks. This is achieved by\nincorporating proprietary and private data from integrated databases. However,\nprivate RAG systems face significant challenges due to the scarcity of private\ndomain data and critical data privacy issues. These obstacles impede the\ndeployment of private RAG systems, as developing privacy-preserving RAG systems\nrequires a delicate balance between data security and data availability. To\naddress these challenges, we regard federated learning (FL) as a highly\npromising technology for privacy-preserving RAG services. We propose a novel\nframework called Federated Retrieval-Augmented Generation (FedE4RAG). This\nframework facilitates collaborative training of client-side RAG retrieval\nmodels. The parameters of these models are aggregated and distributed on a\ncentral-server, ensuring data privacy without direct sharing of raw data. In\nFedE4RAG, knowledge distillation is employed for communication between the\nserver and client models. This technique improves the generalization of local\nRAG retrievers during the federated learning process. Additionally, we apply\nhomomorphic encryption within federated learning to safeguard model parameters\nand mitigate concerns related to data leakage. Extensive experiments conducted\non the real-world dataset have validated the effectiveness of FedE4RAG. The\nresults demonstrate that our proposed framework can markedly enhance the\nperformance of private RAG systems while maintaining robust data privacy\nprotection.", "published": "2025-04-27 04:26:02", "link": "http://arxiv.org/abs/2504.19101v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Reasoning for LLMs through Speculative Chain-of-Thought", "abstract": "Large reasoning language models such as OpenAI-o1 and Deepseek-R1 have\nrecently attracted widespread attention due to their impressive task-solving\nabilities. However, the enormous model size and the generation of lengthy\nthought chains introduce significant reasoning costs and response latency.\nExisting methods for efficient reasoning mainly focus on reducing the number of\nmodel parameters or shortening the chain-of-thought length. In this paper, we\nintroduce Speculative Chain-of-Thought (SCoT), which reduces reasoning latency\nfrom another perspective by accelerated average reasoning speed through large\nand small model collaboration. SCoT conducts thought-level drafting using a\nlightweight draft model. Then it selects the best CoT draft and corrects the\nerror cases with the target model. The proposed thinking behavior alignment\nimproves the efficiency of drafting and the draft selection strategy maintains\nthe prediction accuracy for complex problems. Experimental results on GSM8K,\nMATH, GaoKao, CollegeMath and Olympiad datasets show that SCoT reduces\nreasoning latency by 48\\%$\\sim$66\\% for Deepseek-R1-Distill-Qwen-32B while\nachieving near-target-model-level performance. Our code is available at\nhttps://github.com/Jikai0Wang/Speculative_CoT.", "published": "2025-04-27 03:56:39", "link": "http://arxiv.org/abs/2504.19095v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sample-Efficient Language Model for Hinglish Conversational AI", "abstract": "This paper presents our process for developing a sample-efficient language\nmodel for a conversational Hinglish chatbot. Hinglish, a code-mixed language\nthat combines Hindi and English, presents a unique computational challenge due\nto inconsistent spelling, lack of standardization, and limited quality of\nconversational data. This work evaluates multiple pre-trained cross-lingual\nlanguage models, including Gemma3-4B and Qwen2.5-7B, and employs fine-tuning\ntechniques to improve performance on Hinglish conversational tasks. The\nproposed approach integrates synthetically generated dialogues with insights\nfrom existing Hinglish datasets to address data scarcity. Experimental results\ndemonstrate that models with fewer parameters, when appropriately fine-tuned on\nhigh-quality code-mixed data, can achieve competitive performance for Hinglish\nconversation generation while maintaining computational efficiency.", "published": "2025-04-27 01:35:22", "link": "http://arxiv.org/abs/2504.19070v1", "categories": ["cs.CL", "I.2.7; I.2.6; H.5.2"], "primary_category": "cs.CL"}
{"title": "ClimaEmpact: Domain-Aligned Small Language Models and Datasets for Extreme Weather Analytics", "abstract": "Accurate assessments of extreme weather events are vital for research and\npolicy, yet localized and granular data remain scarce in many parts of the\nworld. This data gap limits our ability to analyze potential outcomes and\nimplications of extreme weather events, hindering effective decision-making.\nLarge Language Models (LLMs) can process vast amounts of unstructured text\ndata, extract meaningful insights, and generate detailed assessments by\nsynthesizing information from multiple sources. Furthermore, LLMs can\nseamlessly transfer their general language understanding to smaller models,\nenabling these models to retain key knowledge while being fine-tuned for\nspecific tasks. In this paper, we propose Extreme Weather Reasoning-Aware\nAlignment (EWRA), a method that enhances small language models (SLMs) by\nincorporating structured reasoning paths derived from LLMs, and\nExtremeWeatherNews, a large dataset of extreme weather event-related news\narticles. EWRA and ExtremeWeatherNews together form the overall framework,\nClimaEmpact, that focuses on addressing three critical extreme-weather tasks:\ncategorization of tangible vulnerabilities/impacts, topic labeling, and emotion\nanalysis. By aligning SLMs with advanced reasoning strategies on\nExtremeWeatherNews (and its derived dataset ExtremeAlign used specifically for\nSLM alignment), EWRA improves the SLMs' ability to generate well-grounded and\ndomain-specific responses for extreme weather analytics. Our results show that\nthe approach proposed guides SLMs to output domain-aligned responses,\nsurpassing the performance of task-specific models and offering enhanced\nreal-world applicability for extreme weather analytics.", "published": "2025-04-27 01:15:14", "link": "http://arxiv.org/abs/2504.19066v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "physics.ao-ph"], "primary_category": "cs.CL"}
{"title": "Versatile Framework for Song Generation with Prompt-based Control", "abstract": "Song generation focuses on producing controllable high-quality songs based on\nvarious prompts. However, existing methods struggle to generate vocals and\naccompaniments with prompt-based control and proper alignment. Additionally,\nthey fall short in supporting various tasks. To address these challenges, we\nintroduce VersBand, a multi-task song generation framework for synthesizing\nhigh-quality, aligned songs with prompt-based control. VersBand comprises these\nprimary models: 1) VocalBand, a decoupled model, leverages the flow-matching\nmethod for generating singing styles, pitches, and mel-spectrograms, allowing\nfast, high-quality vocal generation with style control. 2) AccompBand, a\nflow-based transformer model, incorporates the Band-MOE, selecting suitable\nexperts for enhanced quality, alignment, and control. This model allows for\ngenerating controllable, high-quality accompaniments aligned with vocals. 3)\nTwo generation models, LyricBand for lyrics and MelodyBand for melodies,\ncontribute to the comprehensive multi-task song generation system, allowing for\nextensive control based on multiple prompts. Experimental results demonstrate\nthat VersBand performs better over baseline models across multiple song\ngeneration tasks using objective and subjective metrics. Audio samples are\navailable at https://VersBand.github.io.", "published": "2025-04-27 01:00:06", "link": "http://arxiv.org/abs/2504.19062v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Hallucinations and Key Information Extraction in Medical Texts: A Comprehensive Assessment of Open-Source Large Language Models", "abstract": "Clinical summarization is crucial in healthcare as it distills complex\nmedical data into digestible information, enhancing patient understanding and\ncare management. Large language models (LLMs) have shown significant potential\nin automating and improving the accuracy of such summarizations due to their\nadvanced natural language understanding capabilities. These models are\nparticularly applicable in the context of summarizing medical/clinical texts,\nwhere precise and concise information transfer is essential. In this paper, we\ninvestigate the effectiveness of open-source LLMs in extracting key events from\ndischarge reports, such as reasons for hospital admission, significant\nin-hospital events, and critical follow-up actions. In addition, we also assess\nthe prevalence of various types of hallucinations in the summaries produced by\nthese models. Detecting hallucinations is vital as it directly influences the\nreliability of the information, potentially affecting patient care and\ntreatment outcomes. We conduct comprehensive numerical simulations to\nrigorously evaluate the performance of these models, further probing the\naccuracy and fidelity of the extracted content in clinical summarization.", "published": "2025-04-27 00:39:12", "link": "http://arxiv.org/abs/2504.19061v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Generative AI for Character Animation: A Comprehensive Survey of Techniques, Applications, and Future Directions", "abstract": "Generative AI is reshaping art, gaming, and most notably animation. Recent\nbreakthroughs in foundation and diffusion models have reduced the time and cost\nof producing animated content. Characters are central animation components,\ninvolving motion, emotions, gestures, and facial expressions. The pace and\nbreadth of advances in recent months make it difficult to maintain a coherent\nview of the field, motivating the need for an integrative review. Unlike\nearlier overviews that treat avatars, gestures, or facial animation in\nisolation, this survey offers a single, comprehensive perspective on all the\nmain generative AI applications for character animation. We begin by examining\nthe state-of-the-art in facial animation, expression rendering, image\nsynthesis, avatar creation, gesture modeling, motion synthesis, object\ngeneration, and texture synthesis. We highlight leading research, practical\ndeployments, commonly used datasets, and emerging trends for each area. To\nsupport newcomers, we also provide a comprehensive background section that\nintroduces foundational models and evaluation metrics, equipping readers with\nthe knowledge needed to enter the field. We discuss open challenges and map\nfuture research directions, providing a roadmap to advance AI-driven\ncharacter-animation technologies. This survey is intended as a resource for\nresearchers and developers entering the field of generative AI animation or\nadjacent fields. Resources are available at:\nhttps://github.com/llm-lab-org/Generative-AI-for-Character-Animation-Survey.", "published": "2025-04-27 00:09:31", "link": "http://arxiv.org/abs/2504.19056v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.MM"], "primary_category": "cs.CV"}
{"title": "LLMs for Engineering: Teaching Models to Design High Powered Rockets", "abstract": "Large Language Models (LLMs) have transformed software engineering, but their\napplication to physical engineering domains remains underexplored. This paper\nevaluates LLMs' capabilities in high-powered rocketry design through\nRocketBench, a benchmark connecting LLMs to high-fidelity rocket simulations.\nWe test models on two increasingly complex design tasks: target altitude\noptimization and precision landing challenges. Our findings reveal that while\nstate-of-the-art LLMs demonstrate strong baseline engineering knowledge, they\nstruggle to iterate on their designs when given simulation results and\nultimately plateau below human performance levels. However, when enhanced with\nreinforcement learning (RL), we show that a 7B parameter model outperforms both\nSoTA foundation models and human experts. This research demonstrates that\nRL-trained LLMs can serve as effective tools for complex engineering\noptimization, potentially transforming engineering domains beyond software\ndevelopment.", "published": "2025-04-27 23:59:39", "link": "http://arxiv.org/abs/2504.19394v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "From Inductive to Deductive: LLMs-Based Qualitative Data Analysis in Requirements Engineering", "abstract": "Requirements Engineering (RE) is essential for developing complex and\nregulated software projects. Given the challenges in transforming stakeholder\ninputs into consistent software designs, Qualitative Data Analysis (QDA)\nprovides a systematic approach to handling free-form data. However, traditional\nQDA methods are time-consuming and heavily reliant on manual effort. In this\npaper, we explore the use of Large Language Models (LLMs), including GPT-4,\nMistral, and LLaMA-2, to improve QDA tasks in RE. Our study evaluates LLMs'\nperformance in inductive (zero-shot) and deductive (one-shot, few-shot)\nannotation tasks, revealing that GPT-4 achieves substantial agreement with\nhuman analysts in deductive settings, with Cohen's Kappa scores exceeding 0.7,\nwhile zero-shot performance remains limited. Detailed, context-rich prompts\nsignificantly improve annotation accuracy and consistency, particularly in\ndeductive scenarios, and GPT-4 demonstrates high reliability across repeated\nruns. These findings highlight the potential of LLMs to support QDA in RE by\nreducing manual effort while maintaining annotation quality. The structured\nlabels automatically provide traceability of requirements and can be directly\nutilized as classes in domain models, facilitating systematic software design.", "published": "2025-04-27 23:21:52", "link": "http://arxiv.org/abs/2504.19384v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Rethinking Label-specific Features for Label Distribution Learning", "abstract": "Label distribution learning (LDL) is an emerging learning paradigm designed\nto capture the relative importance of labels for each instance. Label-specific\nfeatures (LSFs), constructed by LIFT, have proven effective for learning tasks\nwith label ambiguity by leveraging clustering-based prototypes for each label\nto re-characterize instances. However, directly introducing LIFT into LDL tasks\ncan be suboptimal, as the prototypes it collects primarily reflect\nintra-cluster relationships while neglecting interactions among distinct\nclusters. Additionally, constructing LSFs using multi-perspective information,\nrather than relying solely on Euclidean distance, provides a more robust and\ncomprehensive representation of instances, mitigating noise and bias that may\narise from a single distance perspective. To address these limitations, we\nintroduce Structural Anchor Points (SAPs) to capture inter-cluster\ninteractions. This leads to a novel LSFs construction strategy, LIFT-SAP, which\nenhances LIFT by integrating both distance and direction information of each\ninstance relative to SAPs. Furthermore, we propose a novel LDL algorithm, Label\nDistribution Learning via Label-specifIc FeaTure with SAPs (LDL-LIFT-SAP),\nwhich unifies multiple label description degrees predicted from different LSF\nspaces into a cohesive label distribution. Extensive experiments on 15\nreal-world datasets demonstrate the effectiveness of LIFT-SAP over LIFT, as\nwell as the superiority of LDL-LIFT-SAP compared to seven other\nwell-established algorithms.", "published": "2025-04-27 22:32:46", "link": "http://arxiv.org/abs/2504.19374v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Doxing via the Lens: Revealing Privacy Leakage in Image Geolocation for Agentic Multi-Modal Large Reasoning Model", "abstract": "The increasing capabilities of agentic multi-modal large reasoning models,\nsuch as ChatGPT o3, have raised critical concerns regarding privacy leakage\nthrough inadvertent image geolocation. In this paper, we conduct the first\nsystematic and controlled study on the potential privacy risks associated with\nvisual reasoning abilities of ChatGPT o3. We manually collect and construct a\ndataset comprising 50 real-world images that feature individuals alongside\nprivacy-relevant environmental elements, capturing realistic and sensitive\nscenarios for analysis. Our experimental evaluation reveals that ChatGPT o3 can\npredict user locations with high precision, achieving street-level accuracy\n(within one mile) in 60% of cases. Through analysis, we identify key visual\ncues, including street layout and front yard design, that significantly\ncontribute to the model inference success. Additionally, targeted occlusion\nexperiments demonstrate that masking critical features effectively mitigates\ngeolocation accuracy, providing insights into potential defense mechanisms. Our\nfindings highlight an urgent need for privacy-aware development for agentic\nmulti-modal large reasoning models, particularly in applications involving\nprivate imagery.", "published": "2025-04-27 22:26:45", "link": "http://arxiv.org/abs/2504.19373v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Mitigating Bias in Facial Recognition Systems: Centroid Fairness Loss Optimization", "abstract": "The urging societal demand for fair AI systems has put pressure on the\nresearch community to develop predictive models that are not only globally\naccurate but also meet new fairness criteria, reflecting the lack of disparate\nmistreatment with respect to sensitive attributes ($\\textit{e.g.}$ gender,\nethnicity, age). In particular, the variability of the errors made by certain\nFacial Recognition (FR) systems across specific segments of the population\ncompromises the deployment of the latter, and was judged unacceptable by\nregulatory authorities. Designing fair FR systems is a very challenging\nproblem, mainly due to the complex and functional nature of the performance\nmeasure used in this domain ($\\textit{i.e.}$ ROC curves) and because of the\nhuge heterogeneity of the face image datasets usually available for training.\nIn this paper, we propose a novel post-processing approach to improve the\nfairness of pre-trained FR models by optimizing a regression loss which acts on\ncentroid-based scores. Beyond the computational advantages of the method, we\npresent numerical experiments providing strong empirical evidence of the gain\nin fairness and of the ability to preserve global accuracy.", "published": "2025-04-27 22:17:44", "link": "http://arxiv.org/abs/2504.19370v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CV"}
{"title": "Low-Rank Adaptive Structural Priors for Generalizable Diabetic Retinopathy Grading", "abstract": "Diabetic retinopathy (DR), a serious ocular complication of diabetes, is one\nof the primary causes of vision loss among retinal vascular diseases. Deep\nlearning methods have been extensively applied in the grading of diabetic\nretinopathy (DR). However, their performance declines significantly when\napplied to data outside the training distribution due to domain shifts. Domain\ngeneralization (DG) has emerged as a solution to this challenge. However, most\nexisting DG methods overlook lesion-specific features, resulting in\ninsufficient accuracy. In this paper, we propose a novel approach that enhances\nexisting DG methods by incorporating structural priors, inspired by the\nobservation that DR grading is heavily dependent on vessel and lesion\nstructures. We introduce Low-rank Adaptive Structural Priors (LoASP), a\nplug-and-play framework designed for seamless integration with existing DG\nmodels. LoASP improves generalization by learning adaptive structural\nrepresentations that are finely tuned to the complexities of DR diagnosis.\nExtensive experiments on eight diverse datasets validate its effectiveness in\nboth single-source and multi-source domain scenarios. Furthermore,\nvisualizations reveal that the learned structural priors intuitively align with\nthe intricate architecture of the vessels and lesions, providing compelling\ninsights into their interpretability and diagnostic relevance.", "published": "2025-04-27 21:40:02", "link": "http://arxiv.org/abs/2504.19362v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Neurosymbolic Association Rule Mining from Tabular Data", "abstract": "Association Rule Mining (ARM) is the task of mining patterns among data\nfeatures in the form of logical rules, with applications across a myriad of\ndomains. However, high-dimensional datasets often result in an excessive number\nof rules, increasing execution time and negatively impacting downstream task\nperformance. Managing this rule explosion remains a central challenge in ARM\nresearch. To address this, we introduce Aerial+, a novel neurosymbolic ARM\nmethod. Aerial+ leverages an under-complete autoencoder to create a neural\nrepresentation of the data, capturing associations between features. It\nextracts rules from this neural representation by exploiting the model's\nreconstruction mechanism. Extensive evaluations on five datasets against seven\nbaselines demonstrate that Aerial+ achieves state-of-the-art results by\nlearning more concise, high-quality rule sets with full data coverage. When\nintegrated into rule-based interpretable machine learning models, Aerial+\nsignificantly reduces execution time while maintaining or improving accuracy.", "published": "2025-04-27 20:43:33", "link": "http://arxiv.org/abs/2504.19354v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Flow Along the K-Amplitude for Generative Modeling", "abstract": "In this work, we propose a novel generative learning paradigm, K-Flow, an\nalgorithm that flows along the $K$-amplitude. Here, $k$ is a scaling parameter\nthat organizes frequency bands (or projected coefficients), and amplitude\ndescribes the norm of such projected coefficients. By incorporating the\n$K$-amplitude decomposition, K-Flow enables flow matching across the scaling\nparameter as time. We discuss three venues and six properties of K-Flow, from\ntheoretical foundations, energy and temporal dynamics, and practical\napplications, respectively. Specifically, from the practical usage perspective,\nK-Flow allows steerable generation by controlling the information at different\nscales. To demonstrate the effectiveness of K-Flow, we conduct experiments on\nunconditional image generation, class-conditional image generation, and\nmolecule assembly generation. Additionally, we conduct three ablation studies\nto demonstrate how K-Flow steers scaling parameter to effectively control the\nresolution of image generation.", "published": "2025-04-27 20:38:24", "link": "http://arxiv.org/abs/2504.19353v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "PolyTouch: A Robust Multi-Modal Tactile Sensor for Contact-rich Manipulation Using Tactile-Diffusion Policies", "abstract": "Achieving robust dexterous manipulation in unstructured domestic environments\nremains a significant challenge in robotics. Even with state-of-the-art robot\nlearning methods, haptic-oblivious control strategies (i.e. those relying only\non external vision and/or proprioception) often fall short due to occlusions,\nvisual complexities, and the need for precise contact interaction control. To\naddress these limitations, we introduce PolyTouch, a novel robot finger that\nintegrates camera-based tactile sensing, acoustic sensing, and peripheral\nvisual sensing into a single design that is compact and durable. PolyTouch\nprovides high-resolution tactile feedback across multiple temporal scales,\nwhich is essential for efficiently learning complex manipulation tasks.\nExperiments demonstrate an at least 20-fold increase in lifespan over\ncommercial tactile sensors, with a design that is both easy to manufacture and\nscalable. We then use this multi-modal tactile feedback along with\nvisuo-proprioceptive observations to synthesize a tactile-diffusion policy from\nhuman demonstrations; the resulting contact-aware control policy significantly\noutperforms haptic-oblivious policies in multiple contact-aware manipulation\npolicies. This paper highlights how effectively integrating multi-modal contact\nsensing can hasten the development of effective contact-aware manipulation\npolicies, paving the way for more reliable and versatile domestic robots. More\ninformation can be found at https://polytouch.alanz.info/", "published": "2025-04-27 19:50:31", "link": "http://arxiv.org/abs/2504.19341v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Platonic Grounding for Efficient Multimodal Language Models", "abstract": "The hyperscaling of data and parameter count in Transformer-based models is\nyielding diminishing performance improvement, especially when weighed against\ntraining costs. Such plateauing indicates the importance of methods for more\nefficient finetuning and inference, while retaining similar performance. This\nis especially relevant for multimodal learning paradigms, where inference costs\nof processing multimodal tokens can determine the model's practical viability.\nAt the same time, research on representations and mechanistic interpretability\nhas improved our understanding of the inner workings of Transformer-based\nmodels; one such line of work reveals an implicit alignment in the deeper\nlayers of pretrained models, across modalities. Taking inspiration from this,\nwe motivate and propose a simple modification to existing multimodal frameworks\nthat rely on aligning pretrained models. We demonstrate that our approach\nmaintains and, in some cases, even improves performance of baseline methods\nwhile achieving significant gains in both training and inference-time compute.\nOur work also has implications for combining pretrained models into larger\nsystems efficiently.", "published": "2025-04-27 18:56:26", "link": "http://arxiv.org/abs/2504.19327v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "NSFlow: An End-to-End FPGA Framework with Scalable Dataflow Architecture for Neuro-Symbolic AI", "abstract": "Neuro-Symbolic AI (NSAI) is an emerging paradigm that integrates neural\nnetworks with symbolic reasoning to enhance the transparency, reasoning\ncapabilities, and data efficiency of AI systems. Recent NSAI systems have\ngained traction due to their exceptional performance in reasoning tasks and\nhuman-AI collaborative scenarios. Despite these algorithmic advancements,\nexecuting NSAI tasks on existing hardware (e.g., CPUs, GPUs, TPUs) remains\nchallenging, due to their heterogeneous computing kernels, high memory\nintensity, and unique memory access patterns. Moreover, current NSAI algorithms\nexhibit significant variation in operation types and scales, making them\nincompatible with existing ML accelerators. These challenges highlight the need\nfor a versatile and flexible acceleration framework tailored to NSAI workloads.\nIn this paper, we propose NSFlow, an FPGA-based acceleration framework designed\nto achieve high efficiency, scalability, and versatility across NSAI systems.\nNSFlow features a design architecture generator that identifies workload data\ndependencies and creates optimized dataflow architectures, as well as a\nreconfigurable array with flexible compute units, re-organizable memory, and\nmixed-precision capabilities. Evaluating across NSAI workloads, NSFlow achieves\n31x speedup over Jetson TX2, more than 2x over GPU, 8x speedup over TPU-like\nsystolic array, and more than 3x over Xilinx DPU. NSFlow also demonstrates\nenhanced scalability, with only 4x runtime increase when symbolic workloads\nscale by 150x. To the best of our knowledge, NSFlow is the first framework to\nenable real-time generalizable NSAI algorithms acceleration, demonstrating a\npromising solution for next-generation cognitive systems.", "published": "2025-04-27 18:28:43", "link": "http://arxiv.org/abs/2504.19323v1", "categories": ["cs.AR", "cs.AI", "cs.LG", "cs.PF"], "primary_category": "cs.AR"}
{"title": "Logic-Based Artificial Intelligence Algorithms Supporting Categorical Semantics", "abstract": "This paper seeks to apply categorical logic to the design of artificial\nintelligent agents that reason symbolically about objects more richly\nstructured than sets. Using Johnstone's sequent calculus of terms- and\nformulae-in-context, we develop forward chaining and normal form algorithms for\nreasoning about objects in cartesian categories with the rules for Horn logic.\nWe also adapt first-order unification to support multi-sorted theories,\ncontexts, and fragments of first-order logic. The significance of these\nreformulations rests in the fact that they can be applied to reasoning about\nobjects in semantic categories that do not support classical logic or even all\nits connectives.", "published": "2025-04-27 18:02:02", "link": "http://arxiv.org/abs/2504.19320v1", "categories": ["cs.AI", "03, 18", "I.1.2"], "primary_category": "cs.AI"}
{"title": "Small Models, Big Tasks: An Exploratory Empirical Study on Small Language Models for Function Calling", "abstract": "Function calling is a complex task with widespread applications in domains\nsuch as information retrieval, software engineering and automation. For\nexample, a query to book the shortest flight from New York to London on January\n15 requires identifying the correct parameters to generate accurate function\ncalls. Large Language Models (LLMs) can automate this process but are\ncomputationally expensive and impractical in resource-constrained settings. In\ncontrast, Small Language Models (SLMs) can operate efficiently, offering faster\nresponse times, and lower computational demands, making them potential\ncandidates for function calling on edge devices. In this exploratory empirical\nstudy, we evaluate the efficacy of SLMs in generating function calls across\ndiverse domains using zero-shot, few-shot, and fine-tuning approaches, both\nwith and without prompt injection, while also providing the finetuned models to\nfacilitate future applications. Furthermore, we analyze the model responses\nacross a range of metrics, capturing various aspects of function call\ngeneration. Additionally, we perform experiments on an edge device to evaluate\ntheir performance in terms of latency and memory usage, providing useful\ninsights into their practical applicability. Our findings show that while SLMs\nimprove from zero-shot to few-shot and perform best with fine-tuning, they\nstruggle significantly with adhering to the given output format. Prompt\ninjection experiments further indicate that the models are generally robust and\nexhibit only a slight decline in performance. While SLMs demonstrate potential\nfor the function call generation task, our results also highlight areas that\nneed further refinement for real-time functioning.", "published": "2025-04-27 15:26:51", "link": "http://arxiv.org/abs/2504.19277v1", "categories": ["cs.AI", "cs.SE"], "primary_category": "cs.AI"}
{"title": "Balancing Creativity and Automation: The Influence of AI on Modern Film Production and Dissemination", "abstract": "The integration of Artificial Intelligence(AI) into film production has\nrevolutionized efficiency and creativity, yet it simultaneously raises critical\nethical and practical challenges. This study explores the dual impact of AI on\nmodern cinema through three objectives: defining the optimal human-AI\nrelationship, balancing creativity with automation, and developing ethical\nguidelines. By employing a mixed-method approach combining theoretical\nframeworks (auteur theory, human-technology relations) and case studies (The\nSafe Zone, Fast & Furious 7, The Brutalist), the research reveals that\npositioning AI as an \"embodiment tool\" rather than an independent \"alterity\npartner\" preserves human authorship and artistic integrity. Key findings\nhighlight the risks of surveillance capitalism in AI-driven markets and the\nethical dilemmas of deepfake technology. The study concludes with actionable\nrecommendations, including international regulatory frameworks and a Human\nControl Index (HCI) to quantify AI involvement. These insights aim to guide\nfilmmakers, policymakers, and scholars in navigating the evolving AI-cinema\nlandscape while safeguarding cultural diversity and ethical standards.", "published": "2025-04-27 15:21:38", "link": "http://arxiv.org/abs/2504.19275v1", "categories": ["cs.CY", "cs.AI", "I.5.m"], "primary_category": "cs.CY"}
{"title": "TeleSparse: Practical Privacy-Preserving Verification of Deep Neural Networks", "abstract": "Verification of the integrity of deep learning inference is crucial for\nunderstanding whether a model is being applied correctly. However, such\nverification typically requires access to model weights and (potentially\nsensitive or private) training data. So-called Zero-knowledge Succinct\nNon-Interactive Arguments of Knowledge (ZK-SNARKs) would appear to provide the\ncapability to verify model inference without access to such sensitive data.\nHowever, applying ZK-SNARKs to modern neural networks, such as transformers and\nlarge vision models, introduces significant computational overhead.\n  We present TeleSparse, a ZK-friendly post-processing mechanisms to produce\npractical solutions to this problem. TeleSparse tackles two fundamental\nchallenges inherent in applying ZK-SNARKs to modern neural networks: (1)\nReducing circuit constraints: Over-parameterized models result in numerous\nconstraints for ZK-SNARK verification, driving up memory and proof generation\ncosts. We address this by applying sparsification to neural network models,\nenhancing proof efficiency without compromising accuracy or security. (2)\nMinimizing the size of lookup tables required for non-linear functions, by\noptimizing activation ranges through neural teleportation, a novel adaptation\nfor narrowing activation functions' range.\n  TeleSparse reduces prover memory usage by 67% and proof generation time by\n46% on the same model, with an accuracy trade-off of approximately 1%. We\nimplement our framework using the Halo2 proving system and demonstrate its\neffectiveness across multiple architectures (Vision-transformer, ResNet,\nMobileNet) and datasets (ImageNet,CIFAR-10,CIFAR-100). This work opens new\ndirections for ZK-friendly model design, moving toward scalable,\nresource-efficient verifiable deep learning.", "published": "2025-04-27 15:14:09", "link": "http://arxiv.org/abs/2504.19274v1", "categories": ["cs.LG", "cs.AI", "cs.CR"], "primary_category": "cs.LG"}
{"title": "The Convergent Ethics of AI? Analyzing Moral Foundation Priorities in Large Language Models with a Multi-Framework Approach", "abstract": "As large language models (LLMs) are increasingly deployed in consequential\ndecision-making contexts, systematically assessing their ethical reasoning\ncapabilities becomes a critical imperative. This paper introduces the\nPriorities in Reasoning and Intrinsic Moral Evaluation (PRIME) framework--a\ncomprehensive methodology for analyzing moral priorities across foundational\nethical dimensions including consequentialist-deontological reasoning, moral\nfoundations theory, and Kohlberg's developmental stages. We apply this\nframework to six leading LLMs through a dual-protocol approach combining direct\nquestioning and response analysis to established ethical dilemmas. Our analysis\nreveals striking patterns of convergence: all evaluated models demonstrate\nstrong prioritization of care/harm and fairness/cheating foundations while\nconsistently underweighting authority, loyalty, and sanctity dimensions.\nThrough detailed examination of confidence metrics, response reluctance\npatterns, and reasoning consistency, we establish that contemporary LLMs (1)\nproduce decisive ethical judgments, (2) demonstrate notable cross-model\nalignment in moral decision-making, and (3) generally correspond with\nempirically established human moral preferences. This research contributes a\nscalable, extensible methodology for ethical benchmarking while highlighting\nboth the promising capabilities and systematic limitations in current AI moral\nreasoning architectures--insights critical for responsible development as these\nsystems assume increasingly significant societal roles.", "published": "2025-04-27 14:26:48", "link": "http://arxiv.org/abs/2504.19255v1", "categories": ["cs.AI", "cs.CY"], "primary_category": "cs.AI"}
{"title": "CARL: Camera-Agnostic Representation Learning for Spectral Image Analysis", "abstract": "Spectral imaging offers promising applications across diverse domains,\nincluding medicine and urban scene understanding, and is already established as\na critical modality in remote sensing. However, variability in channel\ndimensionality and captured wavelengths among spectral cameras impede the\ndevelopment of AI-driven methodologies, leading to camera-specific models with\nlimited generalizability and inadequate cross-camera applicability. To address\nthis bottleneck, we introduce $\\textbf{CARL}$, a model for\n$\\textbf{C}$amera-$\\textbf{A}$gnostic $\\textbf{R}$epresentation\n$\\textbf{L}$earning across RGB, multispectral, and hyperspectral imaging\nmodalities. To enable the conversion of a spectral image with any channel\ndimensionality to a camera-agnostic embedding, we introduce wavelength\npositional encoding and a self-attention-cross-attention mechanism to compress\nspectral information into learned query representations. Spectral-spatial\npre-training is achieved with a novel spectral self-supervised JEPA-inspired\nstrategy tailored to CARL. Large-scale experiments across the domains of\nmedical imaging, autonomous driving, and satellite imaging demonstrate our\nmodel's unique robustness to spectral heterogeneity, outperforming on datasets\nwith simulated and real-world cross-camera spectral variations. The scalability\nand versatility of the proposed approach position our model as a backbone for\nfuture spectral foundation models.", "published": "2025-04-27 13:06:40", "link": "http://arxiv.org/abs/2504.19223v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "CapsFake: A Multimodal Capsule Network for Detecting Instruction-Guided Deepfakes", "abstract": "The rapid evolution of deepfake technology, particularly in\ninstruction-guided image editing, threatens the integrity of digital images by\nenabling subtle, context-aware manipulations. Generated conditionally from real\nimages and textual prompts, these edits are often imperceptible to both humans\nand existing detection systems, revealing significant limitations in current\ndefenses. We propose a novel multimodal capsule network, CapsFake, designed to\ndetect such deepfake image edits by integrating low-level capsules from visual,\ntextual, and frequency-domain modalities. High-level capsules, predicted\nthrough a competitive routing mechanism, dynamically aggregate local features\nto identify manipulated regions with precision. Evaluated on diverse datasets,\nincluding MagicBrush, Unsplash Edits, Open Images Edits, and Multi-turn Edits,\nCapsFake outperforms state-of-the-art methods by up to 20% in detection\naccuracy. Ablation studies validate its robustness, achieving detection rates\nabove 94% under natural perturbations and 96% against adversarial attacks, with\nexcellent generalization to unseen editing scenarios. This approach establishes\na powerful framework for countering sophisticated image manipulations.", "published": "2025-04-27 12:31:47", "link": "http://arxiv.org/abs/2504.19212v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Generative Adversarial Network based Voice Conversion: Techniques, Challenges, and Recent Advancements", "abstract": "Voice conversion (VC) stands as a crucial research area in speech synthesis,\nenabling the transformation of a speaker's vocal characteristics to resemble\nanother while preserving the linguistic content. This technology has broad\napplications, including automated movie dubbing, speech-to-singing conversion,\nand assistive devices for pathological speech rehabilitation. With the\nincreasing demand for high-quality and natural-sounding synthetic voices,\nresearchers have developed a wide range of VC techniques. Among these,\ngenerative adversarial network (GAN)-based approaches have drawn considerable\nattention for their powerful feature-mapping capabilities and potential to\nproduce highly realistic speech. Despite notable advancements, challenges such\nas ensuring training stability, maintaining linguistic consistency, and\nachieving perceptual naturalness continue to hinder progress in GAN-based VC\nsystems. This systematic review presents a comprehensive analysis of the voice\nconversion landscape, highlighting key techniques, key challenges, and the\ntransformative impact of GANs in the field. The survey categorizes existing\nmethods, examines technical obstacles, and critically evaluates recent\ndevelopments in GAN-based VC. By consolidating and synthesizing research\nfindings scattered across the literature, this review provides a structured\nunderstanding of the strengths and limitations of different approaches. The\nsignificance of this survey lies in its ability to guide future research by\nidentifying existing gaps, proposing potential directions, and offering\ninsights for building more robust and efficient VC systems. Overall, this work\nserves as an essential resource for researchers, developers, and practitioners\naiming to advance the state-of-the-art (SOTA) in voice conversion technology.", "published": "2025-04-27 11:22:21", "link": "http://arxiv.org/abs/2504.19197v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Design Framework for operationalizing Trustworthy Artificial Intelligence in Healthcare: Requirements, Tradeoffs and Challenges for its Clinical Adoption", "abstract": "Artificial Intelligence (AI) holds great promise for transforming healthcare,\nparticularly in disease diagnosis, prognosis, and patient care. The increasing\navailability of digital medical data, such as images, omics, biosignals, and\nelectronic health records, combined with advances in computing, has enabled AI\nmodels to approach expert-level performance. However, widespread clinical\nadoption remains limited, primarily due to challenges beyond technical\nperformance, including ethical concerns, regulatory barriers, and lack of\ntrust. To address these issues, AI systems must align with the principles of\nTrustworthy AI (TAI), which emphasize human agency and oversight, algorithmic\nrobustness, privacy and data governance, transparency, bias and discrimination\navoidance, and accountability. Yet, the complexity of healthcare processes\n(e.g., screening, diagnosis, prognosis, and treatment) and the diversity of\nstakeholders (clinicians, patients, providers, regulators) complicate the\nintegration of TAI principles. To bridge the gap between TAI theory and\npractical implementation, this paper proposes a design framework to support\ndevelopers in embedding TAI principles into medical AI systems. Thus, for each\nstakeholder identified across various healthcare processes, we propose a\ndisease-agnostic collection of requirements that medical AI systems should\nincorporate to adhere to the principles of TAI. Additionally, we examine the\nchallenges and tradeoffs that may arise when applying these principles in\npractice. To ground the discussion, we focus on cardiovascular diseases, a\nfield marked by both high prevalence and active AI innovation, and demonstrate\nhow TAI principles have been applied and where key obstacles persist.", "published": "2025-04-27 09:57:35", "link": "http://arxiv.org/abs/2504.19179v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Machine Learning-Based Modeling of the Anode Heel Effect in X-ray Beam Monte Carlo Simulations", "abstract": "This study enhances Monte Carlo simulation accuracy in X-ray imaging by\ndeveloping an AI-driven model for the anode heel effect, achieving improved\nbeam intensity distribution and dosimetric precision. Through dynamic\nadjustments to beam weights on the anode and cathode sides of the X-ray tube,\nour machine learning model effectively replicates the asymmetry characteristic\nof clinical X-ray beams. Experimental results reveal dose rate increases of up\nto 9.6% on the cathode side and reductions of up to 12.5% on the anode side,\nfor energy levels between 50 and 120 kVp. These experimentally optimized beam\nweights were integrated into the OpenGATE and GGEMS Monte Carlo toolkits,\nsignificantly advancing dosimetric simulation accuracy and the image quality\nwhich closely resembles the clinical imaging. Validation with fluence and dose\nactors demonstrated that the AI-based model closely mirrors clinical beam\nbehavior, providing substantial improvements in dose consistency and accuracy\nover conventional X-ray models. This approach provides a robust framework for\nimproving X-ray dosimetry, with potential applications in dose optimization,\nimaging quality enhancement, and radiation safety in both clinical and research\nsettings.", "published": "2025-04-27 08:19:47", "link": "http://arxiv.org/abs/2504.19155v1", "categories": ["physics.med-ph", "cs.AI"], "primary_category": "physics.med-ph"}
{"title": "A Dynamic Fuzzy Rule and Attribute Management Framework for Fuzzy Inference Systems in High-Dimensional Data", "abstract": "This paper presents an Adaptive Dynamic Attribute and Rule (ADAR) framework\ndesigned to address the challenges posed by high-dimensional data in\nneuro-fuzzy inference systems. By integrating dual weighting\nmechanisms-assigning adaptive importance to both attributes and rules-together\nwith automated growth and pruning strategies, ADAR adaptively streamlines\ncomplex fuzzy models without sacrificing performance or interpretability.\nExperimental evaluations on four diverse datasets - Auto MPG (7 variables),\nBeijing PM2.5 (10 variables), Boston Housing (13 variables), and Appliances\nEnergy Consumption (27 variables) show that ADAR-based models achieve\nconsistently lower Root Mean Square Error (RMSE) compared to state-of-the-art\nbaselines. On the Beijing PM2.5 dataset, for instance, ADAR-SOFENN attained an\nRMSE of 56.87 with nine rules, surpassing traditional ANFIS [12] and SOFENN\n[16] models. Similarly, on the high-dimensional Appliances Energy dataset,\nADAR-ANFIS reached an RMSE of 83.25 with nine rules, outperforming established\nfuzzy logic approaches and interpretability-focused methods such as APLR.\nAblation studies further reveal that combining rule-level and attribute-level\nweight assignment significantly reduces model overlap while preserving\nessential features, thereby enhancing explainability. These results highlight\nADAR's effectiveness in dynamically balancing rule complexity and feature\nimportance, paving the way for scalable, high-accuracy, and transparent\nneuro-fuzzy systems applicable to a range of real-world scenarios.", "published": "2025-04-27 08:02:10", "link": "http://arxiv.org/abs/2504.19148v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "ChiseLLM: Unleashing the Power of Reasoning LLMs for Chisel Agile Hardware Development", "abstract": "The growing demand for Domain-Specific Architecture (DSA) has driven the\ndevelopment of Agile Hardware Development Methodology (AHDM). Hardware\nConstruction Language (HCL) like Chisel offers high-level abstraction features,\nmaking it an ideal language for HCL-Based AHDM. While Large Language Models\n(LLMs) excel in code generation tasks, they still face challenges with Chisel\ngeneration, particularly regarding syntax correctness and design variability.\nRecent reasoning models have significantly enhanced code generation\ncapabilities through test-time scaling techniques. However, we found that\nreasoning models without domain adaptation cannot bring substantial benefits to\nChisel code generation tasks. This paper presents ChiseLLM, a solution\ncomprising data processing and transformation, prompt-guided reasoning trace\nsynthesis, and domain-adapted model training. We constructed high-quality\ndatasets from public RTL code resources and guided the model to adopt\nstructured thinking patterns through prompt enhancement methods. Experiments\ndemonstrate that our ChiseLLM-7B and ChiseLLM-32B models improved syntax\ncorrectness by 18.85% and 26.32% respectively over base models, while\nincreasing variability design ability by 47.58% compared to baseline reasoning\nmodels. Our datasets and models are publicly available, providing\nhigh-performance, cost-effective models for HCL-Based AHDM, and offering an\neffective baseline for future research. Github repository:\nhttps://github.com/observerw/ChiseLLM", "published": "2025-04-27 07:56:49", "link": "http://arxiv.org/abs/2504.19144v1", "categories": ["cs.AI", "cs.AR", "cs.SE"], "primary_category": "cs.AI"}
{"title": "BQSched: A Non-intrusive Scheduler for Batch Concurrent Queries via Reinforcement Learning", "abstract": "Most large enterprises build predefined data pipelines and execute them\nperiodically to process operational data using SQL queries for various tasks. A\nkey issue in minimizing the overall makespan of these pipelines is the\nefficient scheduling of concurrent queries within the pipelines. Existing tools\nmainly rely on simple heuristic rules due to the difficulty of expressing the\ncomplex features and mutual influences of queries. The latest reinforcement\nlearning (RL) based methods have the potential to capture these patterns from\nfeedback, but it is non-trivial to apply them directly due to the large\nscheduling space, high sampling cost, and poor sample utilization.\n  Motivated by these challenges, we propose BQSched, a non-intrusive Scheduler\nfor Batch concurrent Queries via reinforcement learning. Specifically, BQSched\ndesigns an attention-based state representation to capture the complex query\npatterns, and proposes IQ-PPO, an auxiliary task-enhanced proximal policy\noptimization (PPO) algorithm, to fully exploit the rich signals of Individual\nQuery completion in logs. Based on the RL framework above, BQSched further\nintroduces three optimization strategies, including adaptive masking to prune\nthe action space, scheduling gain-based query clustering to deal with large\nquery sets, and an incremental simulator to reduce sampling cost. To our\nknowledge, BQSched is the first non-intrusive batch query scheduler via RL.\nExtensive experiments show that BQSched can significantly improve the\nefficiency and stability of batch query scheduling, while also achieving\nremarkable scalability and adaptability in both data and queries. For example,\nacross all DBMSs and scales tested, BQSched reduces the overall makespan of\nbatch queries on TPC-DS benchmark by an average of 34% and 13%, compared with\nthe commonly used heuristic strategy and the adapted RL-based scheduler,\nrespectively.", "published": "2025-04-27 07:49:01", "link": "http://arxiv.org/abs/2504.19142v1", "categories": ["cs.DB", "cs.AI"], "primary_category": "cs.DB"}
{"title": "HumMorph: Generalized Dynamic Human Neural Fields from Few Views", "abstract": "We introduce HumMorph, a novel generalized approach to free-viewpoint\nrendering of dynamic human bodies with explicit pose control. HumMorph renders\na human actor in any specified pose given a few observed views (starting from\njust one) in arbitrary poses. Our method enables fast inference as it relies\nonly on feed-forward passes through the model. We first construct a coarse\nrepresentation of the actor in the canonical T-pose, which combines visual\nfeatures from individual partial observations and fills missing information\nusing learned prior knowledge. The coarse representation is complemented by\nfine-grained pixel-aligned features extracted directly from the observed views,\nwhich provide high-resolution appearance information. We show that HumMorph is\ncompetitive with the state-of-the-art when only a single input view is\navailable, however, we achieve results with significantly better visual quality\ngiven just 2 monocular observations. Moreover, previous generalized methods\nassume access to accurate body shape and pose parameters obtained using\nsynchronized multi-camera setups. In contrast, we consider a more practical\nscenario where these body parameters are noisily estimated directly from the\nobserved views. Our experimental results demonstrate that our architecture is\nmore robust to errors in the noisy parameters and clearly outperforms the state\nof the art in this setting.", "published": "2025-04-27 23:35:54", "link": "http://arxiv.org/abs/2504.19390v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MERA: Multimodal and Multiscale Self-Explanatory Model with Considerably Reduced Annotation for Lung Nodule Diagnosis", "abstract": "Lung cancer, a leading cause of cancer-related deaths globally, emphasises\nthe importance of early detection for better patient outcomes. Pulmonary\nnodules, often early indicators of lung cancer, necessitate accurate, timely\ndiagnosis. Despite Explainable Artificial Intelligence (XAI) advances, many\nexisting systems struggle providing clear, comprehensive explanations,\nespecially with limited labelled data. This study introduces MERA, a Multimodal\nand Multiscale self-Explanatory model designed for lung nodule diagnosis with\nconsiderably Reduced Annotation requirements. MERA integrates unsupervised and\nweakly supervised learning strategies (self-supervised learning techniques and\nVision Transformer architecture for unsupervised feature extraction) and a\nhierarchical prediction mechanism leveraging sparse annotations via\nsemi-supervised active learning in the learned latent space. MERA explains its\ndecisions on multiple levels: model-level global explanations via semantic\nlatent space clustering, instance-level case-based explanations showing similar\ninstances, local visual explanations via attention maps, and concept\nexplanations using critical nodule attributes. Evaluations on the public LIDC\ndataset show MERA's superior diagnostic accuracy and self-explainability. With\nonly 1% annotated samples, MERA achieves diagnostic accuracy comparable to or\nexceeding state-of-the-art methods requiring full annotation. The model's\ninherent design delivers comprehensive, robust, multilevel explanations aligned\nclosely with clinical practice, enhancing trustworthiness and transparency.\nDemonstrated viability of unsupervised and weakly supervised learning lowers\nthe barrier to deploying diagnostic AI in broader medical domains. Our complete\ncode is open-source available: https://github.com/diku-dk/credanno.", "published": "2025-04-27 20:48:34", "link": "http://arxiv.org/abs/2504.19357v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Improving Small Drone Detection Through Multi-Scale Processing and Data Augmentation", "abstract": "Detecting small drones, often indistinguishable from birds, is crucial for\nmodern surveillance. This work introduces a drone detection methodology built\nupon the medium-sized YOLOv11 object detection model. To enhance its\nperformance on small targets, we implemented a multi-scale approach in which\nthe input image is processed both as a whole and in segmented parts, with\nsubsequent prediction aggregation. We also utilized a copy-paste data\naugmentation technique to enrich the training dataset with diverse drone and\nbird examples. Finally, we implemented a post-processing technique that\nleverages frame-to-frame consistency to mitigate missed detections. The\nproposed approach attained a top-3 ranking in the 8th WOSDETC Drone-vsBird\nDetection Grand Challenge, held at the 2025 International Joint Conference on\nNeural Networks (IJCNN), showcasing its capability to detect drones in complex\nenvironments effectively.", "published": "2025-04-27 20:06:55", "link": "http://arxiv.org/abs/2504.19347v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Enhancing seeding efficiency using a computer vision system to monitor furrow quality in real-time", "abstract": "Effective seed sowing in precision agriculture is hindered by challenges such\nas residue accumulation, low soil temperatures, and hair pinning (crop residue\npushed in the trench by furrow opener), which obstruct optimal trench\nformation. Row cleaners are employed to mitigate these issues, but there is a\nlack of quantitative methods to assess trench cleanliness. In this study, a\nnovel computer vision-based method was developed to evaluate row cleaner\nperformance. Multiple air seeders were equipped with a video acquisition system\nto capture trench conditions after row cleaner operation, enabling an effective\ncomparison of the performance of each row cleaner. The captured data were used\nto develop a segmentation model that analyzed key elements such as soil, straw,\nand machinery. Using the results from the segmentation model, an objective\nmethod was developed to quantify row cleaner performance. The results\ndemonstrated the potential of this method to improve row cleaner selection and\nenhance seeding efficiency in precision agriculture.", "published": "2025-04-27 19:08:13", "link": "http://arxiv.org/abs/2504.19334v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Myocardial Region-guided Feature Aggregation Net for Automatic Coronary artery Segmentation and Stenosis Assessment using Coronary Computed Tomography Angiography", "abstract": "Coronary artery disease (CAD) remains a leading cause of mortality worldwide,\nrequiring accurate segmentation and stenosis detection using Coronary Computed\nTomography angiography (CCTA). Existing methods struggle with challenges such\nas low contrast, morphological variability and small vessel segmentation. To\naddress these limitations, we propose the Myocardial Region-guided Feature\nAggregation Net, a novel U-shaped dual-encoder architecture that integrates\nanatomical prior knowledge to enhance robustness in coronary artery\nsegmentation. Our framework incorporates three key innovations: (1) a\nMyocardial Region-guided Module that directs attention to coronary regions via\nmyocardial contour expansion and multi-scale feature fusion, (2) a Residual\nFeature Extraction Encoding Module that combines parallel spatial channel\nattention with residual blocks to enhance local-global feature discrimination,\nand (3) a Multi-scale Feature Fusion Module for adaptive aggregation of\nhierarchical vascular features. Additionally, Monte Carlo dropout f quantifies\nprediction uncertainty, supporting clinical interpretability. For stenosis\ndetection, a morphology-based centerline extraction algorithm separates the\nvascular tree into anatomical branches, enabling cross-sectional area\nquantification and stenosis grading. The superiority of MGFA-Net was\ndemonstrated by achieving an Dice score of 85.04%, an accuracy of 84.24%, an\nHD95 of 6.1294 mm, and an improvement of 5.46% in true positive rate for\nstenosis detection compared to3D U-Net. The integrated segmentation-to-stenosis\npipeline provides automated, clinically interpretable CAD assessment, bridging\ndeep learning with anatomical prior knowledge for precision medicine. Our code\nis publicly available at http://github.com/chenzhao2023/MGFA_CCTA", "published": "2025-04-27 16:43:52", "link": "http://arxiv.org/abs/2504.19300v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FusionNet: Multi-model Linear Fusion Framework for Low-light Image Enhancement", "abstract": "The advent of Deep Neural Networks (DNNs) has driven remarkable progress in\nlow-light image enhancement (LLIE), with diverse architectures (e.g., CNNs and\nTransformers) and color spaces (e.g., sRGB, HSV, HVI) yielding impressive\nresults. Recent efforts have sought to leverage the complementary strengths of\nthese paradigms, offering promising solutions to enhance performance across\nvarying degradation scenarios. However, existing fusion strategies are hindered\nby challenges such as parameter explosion, optimization instability, and\nfeature misalignment, limiting further improvements. To overcome these issues,\nwe introduce FusionNet, a novel multi-model linear fusion framework that\noperates in parallel to effectively capture global and local features across\ndiverse color spaces. By incorporating a linear fusion strategy underpinned by\nHilbert space theoretical guarantees, FusionNet mitigates network collapse and\nreduces excessive training costs. Our method achieved 1st place in the CVPR2025\nNTIRE Low Light Enhancement Challenge. Extensive experiments conducted on\nsynthetic and real-world benchmark datasets demonstrate that the proposed\nmethod significantly outperforms state-of-the-art methods in terms of both\nquantitative and qualitative results, delivering robust enhancement under\ndiverse low-light conditions.", "published": "2025-04-27 16:22:03", "link": "http://arxiv.org/abs/2504.19295v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Marine Snow Removal Using Internally Generated Pseudo Ground Truth", "abstract": "Underwater videos often suffer from degraded quality due to light absorption,\nscattering, and various noise sources. Among these, marine snow, which is\nsuspended organic particles appearing as bright spots or noise, significantly\nimpacts machine vision tasks, particularly those involving feature matching.\nExisting methods for removing marine snow are ineffective due to the lack of\npaired training data. To address this challenge, this paper proposes a novel\nenhancement framework that introduces a new approach for generating paired\ndatasets from raw underwater videos. The resulting dataset consists of paired\nimages of generated snowy and snow, free underwater videos, enabling supervised\ntraining for video enhancement. We describe the dataset creation process,\nhighlight its key characteristics, and demonstrate its effectiveness in\nenhancing underwater image restoration in the absence of ground truth.", "published": "2025-04-27 16:08:00", "link": "http://arxiv.org/abs/2504.19289v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Optimal Hyperspectral Undersampling Strategy for Satellite Imaging", "abstract": "Hyperspectral image (HSI) classification presents significant challenges due\nto the high dimensionality, spectral redundancy, and limited labeled data\ntypically available in real-world applications. To address these issues and\noptimize classification performance, we propose a novel band selection strategy\nknown as Iterative Wavelet-based Gradient Sampling (IWGS). This method\nincrementally selects the most informative spectral bands by analyzing\ngradients within the wavelet-transformed domain, enabling efficient and\ntargeted dimensionality reduction. Unlike traditional selection methods, IWGS\nleverages the multi-resolution properties of wavelets to better capture subtle\nspectral variations relevant for classification. The iterative nature of the\napproach ensures that redundant or noisy bands are systematically excluded\nwhile maximizing the retention of discriminative features. We conduct\ncomprehensive experiments on two widely-used benchmark HSI datasets: Houston\n2013 and Indian Pines. Results demonstrate that IWGS consistently outperforms\nstate-of-the-art band selection and classification techniques in terms of both\naccuracy and computational efficiency. These improvements make our method\nespecially suitable for deployment in edge devices or other\nresource-constrained environments, where memory and processing power are\nlimited. In particular, IWGS achieved an overall accuracy up to 97.8% on Indian\nPines for selected classes, confirming its effectiveness and generalizability\nacross different HSI scenarios.", "published": "2025-04-27 15:33:33", "link": "http://arxiv.org/abs/2504.19279v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Leveraging Multi-Modal Saliency and Fusion for Gaze Target Detection", "abstract": "Gaze target detection (GTD) is the task of predicting where a person in an\nimage is looking. This is a challenging task, as it requires the ability to\nunderstand the relationship between the person's head, body, and eyes, as well\nas the surrounding environment. In this paper, we propose a novel method for\nGTD that fuses multiple pieces of information extracted from an image. First,\nwe project the 2D image into a 3D representation using monocular depth\nestimation. We then extract a depth-infused saliency module map, which\nhighlights the most salient (\\textit{attention-grabbing}) regions in image for\nthe subject in consideration. We also extract face and depth modalities from\nthe image, and finally fuse all the extracted modalities to identify the gaze\ntarget. We quantitatively evaluated our method, including the ablation analysis\non three publicly available datasets, namely VideoAttentionTarget, GazeFollow\nand GOO-Real, and showed that it outperforms other state-of-the-art methods.\nThis suggests that our method is a promising new approach for GTD.", "published": "2025-04-27 14:59:13", "link": "http://arxiv.org/abs/2504.19271v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VI3NR: Variance Informed Initialization for Implicit Neural Representations", "abstract": "Implicit Neural Representations (INRs) are a versatile and powerful tool for\nencoding various forms of data, including images, videos, sound, and 3D shapes.\nA critical factor in the success of INRs is the initialization of the network,\nwhich can significantly impact the convergence and accuracy of the learned\nmodel. Unfortunately, commonly used neural network initializations are not\nwidely applicable for many activation functions, especially those used by INRs.\nIn this paper, we improve upon previous initialization methods by deriving an\ninitialization that has stable variance across layers, and applies to any\nactivation function. We show that this generalizes many previous initialization\nmethods, and has even better stability for well studied activations. We also\nshow that our initialization leads to improved results with INR activation\nfunctions in multiple signal modalities. Our approach is particularly effective\nfor Gaussian INRs, where we demonstrate that the theory of our initialization\nmatches with task performance in multiple experiments, allowing us to achieve\nimprovements in image, audio, and 3D surface reconstruction.", "published": "2025-04-27 14:58:27", "link": "http://arxiv.org/abs/2504.19270v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "OpenFusion++: An Open-vocabulary Real-time Scene Understanding System", "abstract": "Real-time open-vocabulary scene understanding is essential for efficient 3D\nperception in applications such as vision-language navigation, embodied\nintelligence, and augmented reality. However, existing methods suffer from\nimprecise instance segmentation, static semantic updates, and limited handling\nof complex queries. To address these issues, we present OpenFusion++, a\nTSDF-based real-time 3D semantic-geometric reconstruction system. Our approach\nrefines 3D point clouds by fusing confidence maps from foundational models,\ndynamically updates global semantic labels via an adaptive cache based on\ninstance area, and employs a dual-path encoding framework that integrates\nobject attributes with environmental context for precise query responses.\nExperiments on the ICL, Replica, ScanNet, and ScanNet++ datasets demonstrate\nthat OpenFusion++ significantly outperforms the baseline in both semantic\naccuracy and query responsiveness.", "published": "2025-04-27 14:46:43", "link": "http://arxiv.org/abs/2504.19266v1", "categories": ["cs.CV", "68T45, 68U05", "I.2.10; I.4.8"], "primary_category": "cs.CV"}
{"title": "Rendering Anywhere You See: Renderability Field-guided Gaussian Splatting", "abstract": "Scene view synthesis, which generates novel views from limited perspectives,\nis increasingly vital for applications like virtual reality, augmented reality,\nand robotics. Unlike object-based tasks, such as generating 360{\\deg} views of\na car, scene view synthesis handles entire environments where non-uniform\nobservations pose unique challenges for stable rendering quality. To address\nthis issue, we propose a novel approach: renderability field-guided gaussian\nsplatting (RF-GS). This method quantifies input inhomogeneity through a\nrenderability field, guiding pseudo-view sampling to enhanced visual\nconsistency. To ensure the quality of wide-baseline pseudo-views, we train an\nimage restoration model to map point projections to visible-light styles.\nAdditionally, our validated hybrid data optimization strategy effectively fuses\ninformation of pseudo-view angles and source view textures. Comparative\nexperiments on simulated and real-world data show that our method outperforms\nexisting approaches in rendering stability.", "published": "2025-04-27 14:41:01", "link": "http://arxiv.org/abs/2504.19261v1", "categories": ["cs.CV", "65D18, 68U05", "I.3.7; I.4.8"], "primary_category": "cs.CV"}
{"title": "OPAL: Visibility-aware LiDAR-to-OpenStreetMap Place Recognition via Adaptive Radial Fusion", "abstract": "LiDAR place recognition is a critical capability for autonomous navigation\nand cross-modal localization in large-scale outdoor environments. Existing\napproaches predominantly depend on pre-built 3D dense maps or aerial imagery,\nwhich impose significant storage overhead and lack real-time adaptability. In\nthis paper, we propose OPAL, a novel network for LiDAR place recognition that\nleverages OpenStreetMap as a lightweight and up-to-date prior. Our key\ninnovation lies in bridging the domain disparity between sparse LiDAR scans and\nstructured OSM data through two carefully designed components: a cross-modal\nvisibility mask that identifies maximal observable regions from both modalities\nto guide feature learning, and an adaptive radial fusion module that\ndynamically consolidates multiscale radial features into discriminative global\ndescriptors. Extensive experiments on the augmented KITTI and KITTI-360\ndatasets demonstrate OPAL's superiority, achieving 15.98% higher recall at @1m\nthreshold for top-1 retrieved matches while operating at 12x faster inference\nspeeds compared to state-of-the-art approaches. Code and datasets are publicly\navailable at: https://github.com/WHU-USI3DV/OPAL .", "published": "2025-04-27 14:39:26", "link": "http://arxiv.org/abs/2504.19258v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Hardness of Finding Kings and Strong Kings", "abstract": "A king in a directed graph is a vertex $v$ such that every other vertex is\nreachable from $v$ via a path of length at most $2$. It is well known that\nevery tournament (a complete graph where each edge has a direction) has at\nleast one king. Our contributions in this work are:\n  - We show that the query complexity of determining existence of a king in\narbitrary $n$-vertex digraphs is $\\Theta(n^2)$. This is in stark contrast to\nthe case where the input is a tournament, where Shen, Sheng, and Wu [SICOMP'03]\nshowed that a king can be found in $O(n^{3/2})$ queries.\n  - In an attempt to increase the \"fairness\" in the definition of tournament\nwinners, Ho and Chang [IPL'03] defined a strong king to be a king $k$ such\nthat, for every $v$ that dominates $k$, the number of length-$2$ paths from $k$\nto $v$ is strictly larger than the number of length-$2$ paths from $v$ to $k$.\nWe show that the query complexity of finding a strong king in a tournament is\n$\\Theta(n^2)$. This answers a question of Biswas, Jayapaul, Raman, and Satti\n[DAM'22] in the negative.\n  A key component in our proofs is the design of specific tournaments where\nevery vertex is a king, and analyzing certain properties of these tournaments.\nWe feel these constructions and properties are independently interesting and\nmay lead to more interesting results about tournament solutions.", "published": "2025-04-27 23:28:12", "link": "http://arxiv.org/abs/2504.19386v1", "categories": ["cs.CC", "cs.DM", "math.CO"], "primary_category": "cs.CC"}
{"title": "(Almost-)Optimal FPT Algorithm and Kernel for $T$-Cycle on Planar Graphs", "abstract": "Research of cycles through specific vertices is a central topic in graph\ntheory. In this context, we focus on a well-studied computational problem,\n\\textsc{$T$-Cycle}: given an undirected $n$-vertex graph $G$ and a set of $k$\nvertices $T\\subseteq V(G)$ termed \\textit{terminals}, the objective is to\ndetermine whether $G$ contains a simple cycle $C$ through all the terminals.\nOur contribution is twofold: (i) We provide a $2^{O(\\sqrt{k}\\log k)}\\cdot\nn$-time fixed-parameter deterministic algorithm for \\textsc{$T$-Cycle} on\nplanar graphs; (ii) We provide a $k^{O(1)}\\cdot n$-time deterministic\nkernelization algorithm for \\textsc{$T$-Cycle} on planar graphs where the\nproduced instance is of size $k\\log^{O(1)}k$.\n  Both of our algorithms are optimal in terms of both $k$ and $n$ up to\n(poly)logarithmic factors in $k$ under the ETH. In fact, our algorithms are the\nfirst subexponential-time fixed-parameter algorithm for \\textsc{$T$-Cycle} on\nplanar graphs, as well as the first polynomial kernel for \\textsc{$T$-Cycle} on\nplanar graphs. This substantially improves upon/expands the known literature on\nthe parameterized complexity of the problem.", "published": "2025-04-27 16:44:15", "link": "http://arxiv.org/abs/2504.19301v1", "categories": ["cs.DS", "cs.DM"], "primary_category": "cs.DS"}
{"title": "Expanding vertices to triangles in cubic graphs", "abstract": "Contraction of triangles is a standard operation in the study of cubic\ngraphs, as it reduces the order of the graph while typically preserving many of\nits properties. In this paper, we investigate the converse problem, wherein\ncertain vertices of cubic graphs are expanded into triangles to achieve a\ndesired property. We first focus on bridgeless cubic graphs and define the\nparameter $T(G)$ as the minimum number of vertices that need to be expanded\ninto triangles so that the resulting cubic graph can be covered with four\nperfect matchings. We relate this parameter to the concept of shortest cycle\ncover. Furthermore, we show that if $5$-Cycle Double Cover Conejcture holds\ntrue, then $T(G)\\leq \\frac{2}{5} |V(G)|$. We conjecture a tighter bound,\n$T(G)\\leq \\frac{1}{10}|V(G)|$, which is optimal for the Petersen graph, and\nshow that this bound follows from major conjectures like the Petersen Coloring\nConjecture. In the second part of the paper, we introduce the parameter $t(G)$\nas the minimum number of vertex expansions needed for the graph to admit a\nperfect matching. We prove a Gallai type identity: $t(G)+\\ell(G)=|V(G)|$, where\n$\\ell(G)$ is the number of edges in a largest even subgraph of $G$. Then we\nprove the general upper bound $t(G)< \\frac{1}{4}|V(G)|$ for cubic graphs, and\n$t(G)< \\frac{1}{6}|V(G)|$ for cubic graphs without parallel edges. We provide\nexamples showing that these bounds are asymptotically tight. The paper\nconcludes with a discussion of the computational complexity of determining\nthese parameters.", "published": "2025-04-27 11:37:48", "link": "http://arxiv.org/abs/2504.19201v1", "categories": ["math.CO", "cs.DM", "05C70, 05C15"], "primary_category": "math.CO"}
{"title": "Characterization of Split Comparability Graphs", "abstract": "A split graph is a graph whose vertex set can be partitioned into a clique\nand an independent set. A split comparability graph is a split graph which is\ntransitively orientable. In this work, we characterize split comparability\ngraphs in terms of vertex labelling. Further, using this characterization, we\nprove that the permutation-representation number of a split comparability graph\nis at most three. This gives us an alternative proof of the result in order\ntheory that the dimension of a split order is at most three.", "published": "2025-04-27 09:08:07", "link": "http://arxiv.org/abs/2504.19167v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "Scalable Substructure Discovery Algorithm For Homogeneous Multilayer Networks", "abstract": "Graph mining analyzes real-world graphs to find core substructures (connected\nsubgraphs) in applications modeled as graphs. Substructure discovery is a\nprocess that involves identifying meaningful patterns, structures, or\ncomponents within a large data set. These substructures can be of various\ntypes, such as frequent patterns, motifs, or other relevant features within the\ndata.\n  To model complex data sets -- with multiple types of entities and\nrelationships -- multilayer networks (or MLNs) have been shown to be more\neffective as compared to simple and attributed graphs. Analysis algorithms on\nMLNs using the decoupling approach have been shown to be both efficient and\naccurate. Hence, this paper focuses on substructure discovery in homogeneous\nmultilayer networks (one type of MLN) using a novel decoupling-based approach.\nIn this approach, each layer is processed independently, and then the results\nfrom two or more layers are composed to identify substructures in the entire\nMLN. The algorithm is designed and implemented, including the composition part,\nusing one of the distributed processing frameworks (the Map/Reduce paradigm) to\nprovide scalability.\n  After establishing the correctness, we analyze the speedup and response time\nof the proposed algorithm and approach through extensive experimental analysis\non large synthetic and real-world data sets with diverse graph characteristics.", "published": "2025-04-27 18:58:32", "link": "http://arxiv.org/abs/2504.19328v1", "categories": ["cs.SI", "cs.DB", "cs.IR"], "primary_category": "cs.SI"}
{"title": "AlphaFuse: Learn ID Embeddings for Sequential Recommendation in Null Space of Language Embeddings", "abstract": "Recent advancements in sequential recommendation have underscored the\npotential of Large Language Models (LLMs) for enhancing item embeddings.\nHowever, existing approaches face three key limitations: 1) the degradation of\nthe semantic space when high-dimensional language embeddings are mapped to\nlower-dimensional ID embeddings, 2) the underutilization of language\nembeddings, and 3) the reliance on additional trainable parameters, such as an\nadapter, to bridge the gap between the semantic and behavior spaces.In this\npaper, we introduce AlphaFuse, a simple but effective language-guided learning\nstrategy that addresses these challenges by learning ID embeddings within the\nnull space of language embeddings. Specifically, we decompose the semantic\nspace of language embeddings via Singular Value Decomposition (SVD),\ndistinguishing it into a semantic-rich row space and a semantic-sparse null\nspace. Collaborative signals are then injected into the null space, while\npreserving the rich semantics of the row space. AlphaFuse prevents degradation\nof the semantic space, integrates the retained language embeddings into the\nfinal item embeddings, and eliminates the need for auxiliary trainable modules,\nenabling seamless adaptation to any sequential recommendation framework. We\nvalidate the effectiveness and flexibility of AlphaFuse through extensive\nexperiments on three benchmark datasets, including cold-start user and\nlong-tail settings, showcasing significant improvements in both discriminative\nand diffusion-based generative sequential recommenders. Our codes and datasets\nare available at https://github.com/Hugo-Chinn/AlphaFuse.", "published": "2025-04-27 12:51:56", "link": "http://arxiv.org/abs/2504.19218v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Relative Contrastive Learning for Sequential Recommendation with Similarity-based Positive Pair Selection", "abstract": "Contrastive Learning (CL) enhances the training of sequential recommendation\n(SR) models through informative self-supervision signals. Existing methods\noften rely on data augmentation strategies to create positive samples and\npromote representation invariance. Some strategies such as item reordering and\nitem substitution may inadvertently alter user intent. Supervised Contrastive\nLearning (SCL) based methods find an alternative to augmentation-based CL\nmethods by selecting same-target sequences (interaction sequences with the same\ntarget item) to form positive samples. However, SCL-based methods suffer from\nthe scarcity of same-target sequences and consequently lack enough signals for\ncontrastive learning. In this work, we propose to use similar sequences (with\ndifferent target items) as additional positive samples and introduce a Relative\nContrastive Learning (RCL) framework for sequential recommendation. RCL\ncomprises a dual-tiered positive sample selection module and a relative\ncontrastive learning module. The former module selects same-target sequences as\nstrong positive samples and selects similar sequences as weak positive samples.\nThe latter module employs a weighted relative contrastive loss, ensuring that\neach sequence is represented closer to its strong positive samples than its\nweak positive samples. We apply RCL on two mainstream deep learning-based SR\nmodels, and our empirical results reveal that RCL can achieve 4.88% improvement\naveragely than the state-of-the-art SR methods on five public datasets and one\nprivate dataset.", "published": "2025-04-27 09:56:10", "link": "http://arxiv.org/abs/2504.19178v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "LLM-Evaluation Tropes: Perspectives on the Validity of LLM-Evaluations", "abstract": "Large Language Models (LLMs) are increasingly used to evaluate information\nretrieval (IR) systems, generating relevance judgments traditionally made by\nhuman assessors. Recent empirical studies suggest that LLM-based evaluations\noften align with human judgments, leading some to suggest that human judges may\nno longer be necessary, while others highlight concerns about judgment\nreliability, validity, and long-term impact. As IR systems begin incorporating\nLLM-generated signals, evaluation outcomes risk becoming self-reinforcing,\npotentially leading to misleading conclusions.\n  This paper examines scenarios where LLM-evaluators may falsely indicate\nsuccess, particularly when LLM-based judgments influence both system\ndevelopment and evaluation. We highlight key risks, including bias\nreinforcement, reproducibility challenges, and inconsistencies in assessment\nmethodologies. To address these concerns, we propose tests to quantify adverse\neffects, guardrails, and a collaborative framework for constructing reusable\ntest collections that integrate LLM judgments responsibly. By providing\nperspectives from academia and industry, this work aims to establish best\npractices for the principled use of LLMs in IR evaluation.", "published": "2025-04-27 02:14:21", "link": "http://arxiv.org/abs/2504.19076v1", "categories": ["cs.IR", "H.3.3"], "primary_category": "cs.IR"}
{"title": "Sequence Reconstruction for Sticky Insertion/Deletion Channels", "abstract": "The sequence reconstruction problem for insertion/deletion channels has\nattracted significant attention owing to their applications recently in some\nemerging data storage systems, such as racetrack memories, DNA-based data\nstorage. Our goal is to investigate the reconstruction problem for\nsticky-insdel channels where both sticky-insertions and sticky-deletions occur.\nIf there are only sticky-insertion errors, the reconstruction problem for\nsticky-insertion channel is a special case of the reconstruction problem for\ntandem-duplication channel which has been well-studied. In this work, we\nconsider the $(t, s)$-sticky-insdel channel where there are at most $t$\nsticky-insertion errors and $s$ sticky-deletion errors when we transmit a\nmessage through the channel. For the reconstruction problem, we are interested\nin the minimum number of distinct outputs from these channels that are needed\nto uniquely recover the transmitted vector. We first provide a recursive\nformula to determine the minimum number of distinct outputs required. Next, we\nprovide an efficient algorithm to reconstruct the transmitted vector from\nerroneous sequences.", "published": "2025-04-27 21:44:13", "link": "http://arxiv.org/abs/2504.19363v1", "categories": ["cs.IT", "math.CO", "math.IT"], "primary_category": "cs.IT"}
{"title": "Projective systems and bounds on the length of codes of non-zero defect", "abstract": "In their 2007 book, Tsfasman and Vl\\v{a}du\\c{t} invite the reader to\nreinterpret existing coding theory results through the lens of projective\nsystems. Redefining linear codes as projective systems provides a geometric\nvantage point. In this paper, we embrace this perspective, deriving bounds on\nthe lengths of A$^s$MDS codes (codes with Singleton defect $s$). To help frame\nour discussions, we introduce the parameters $m^{s}(k,q)$, denoting the maximum\nlength of an (non-degenerate) $[n,k,d]_q$ A$^s$MDS code, $m^{s}_t(k,q)$\ndenoting the maximum length of an (non-degenerate) $[n,k,d]_q$ A$^s$MDS code\nsuch that the dual code is an A$^t$MDS code, and $\\kappa(s,q)$, representing\nthe maximum dimension $k$ for which there exists a linear code of (maximal)\nlength $n=(s+1)(q+1)+k-2$. In particular, we address a gap in the literature by\nproviding sufficient conditions on $n$ and $k$ under which the dual of an\n$[n,k,d]_q$ A$^s$MDS code is also an A$^s$MDS code. Our results subsume or\nimprove several results in the literature. Some conjectures arise from our\nfindings.", "published": "2025-04-27 18:51:43", "link": "http://arxiv.org/abs/2504.19325v1", "categories": ["math.CO", "cs.IT", "math.IT", "35A01, 65L10, 65L12, 65L20, 65L70"], "primary_category": "math.CO"}
{"title": "Generalized Score Matching: Bridging $f$-Divergence and Statistical Estimation Under Correlated Noise", "abstract": "Relative Fisher information, also known as score matching, is a recently\nintroduced learning method for parameter estimation. Fundamental relations\nbetween relative entropy and score matching have been established in the\nliterature for scalar and isotropic Gaussian channels. This paper demonstrates\nthat such relations hold for a much larger class of observation models. We\nintroduce the vector channel where the perturbation is non-isotropic Gaussian\nnoise. For such channels, we derive new representations that connect the\n$f$-divergence between two distributions to the estimation loss induced by\nmismatch at the decoder. This approach not only unifies but also greatly\nextends existing results from both the isotropic Gaussian and classical\nrelative entropy frameworks. Building on this generalization, we extend De\nBruijn's identity to mismatched non-isotropic Gaussian models and demonstrate\nthat the connections to generative models naturally follow as a consequence\napplication of this new result.", "published": "2025-04-27 16:05:33", "link": "http://arxiv.org/abs/2504.19288v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "SA-MIMO: Scalable Quantum-Based Wireless Communications", "abstract": "Rydberg atomic receivers offer a quantum-native alternative to conventional\nRF front-ends by directly detecting electromagnetic fields via highly excited\natomic states. While their quantum-limited sensitivity and hardware simplicity\nmake them promising for future wireless systems, extending their use to\nscalable multi-antenna and multi-carrier configurations, termed Scalable\nAtomic-MIMO (SA-MIMO), remains largely unexplored. This paper introduces a\nnovel RF transmitter-atomic receiver architecture that addresses this gap. The\ncore idea lies in a novel modulation technique called Phase-Rotated Symbol\nSpreading (PRSS), which transforms the nonlinear phase retrieval problem\ninherent to atomic detection into a tractable linear demultiplexing task. PRSS\nenables efficient signal processing and supports scalable MUX/DeMUX operations\nin both atomic MIMO and atomic OFDM systems. Simulation results show that the\nproposed system achieves up to 2.5 dB gain under optimal maximum-likelihood\ndetection and over 10 dB under suboptimal detection in MIMO settings. These\nresults establish PRSS assisted SA-MIMO as a promising architecture for\nrealizing high-sensitivity, interference-resilient atomic wireless\ncommunication.", "published": "2025-04-27 09:14:57", "link": "http://arxiv.org/abs/2504.19170v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Bi-directional Model Cascading with Proxy Confidence", "abstract": "Model Cascading, recently applied successfully to LLMs, is a simple but\npowerful technique that improves the efficiency of inference by selectively\napplying models of varying sizes. Models are used in sequence from smallest to\nlargest, only deferring samples to large, costly models when smaller models are\nnot sufficiently confident. Existing approaches to deferral use only limited\nsmall model confidence estimates because of the inaccessibility of the large\nmodel, although large model confidence is known to be important. We therefore\npropose a bi-directional approach to deferral that considers the confidence of\nsmall and large models in the cascade simultaneously through the use of a proxy\nfor the large model. This requires a richer representation of model confidence\nto enable comparative calibration: we use an analysis of hidden states to\nimprove post-invocation confidence of the small model, which in itself improves\ncascading results over prior approaches. We then combine this with a tiny proxy\nmodel to estimate pre-invocation confidence of the large model. We examine the\nproposed cascading system over challenging, multiple-choice datasets, finding\nimprovements over standard cascading baselines reflected in reductions in\ndeferrals to more costly models.", "published": "2025-04-27 23:48:14", "link": "http://arxiv.org/abs/2504.19391v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "HyperController: A Hyperparameter Controller for Fast and Stable Training of Reinforcement Learning Neural Networks", "abstract": "We introduce Hyperparameter Controller (HyperController), a computationally\nefficient algorithm for hyperparameter optimization during training of\nreinforcement learning neural networks. HyperController optimizes\nhyperparameters quickly while also maintaining improvement of the reinforcement\nlearning neural network, resulting in faster training and deployment. It\nachieves this by modeling the hyperparameter optimization problem as an unknown\nLinear Gaussian Dynamical System, which is a system with a state that linearly\nchanges. It then learns an efficient representation of the hyperparameter\nobjective function using the Kalman filter, which is the optimal one-step\npredictor for a Linear Gaussian Dynamical System. To demonstrate the\nperformance of HyperController, it is applied as a hyperparameter optimizer\nduring training of reinforcement learning neural networks on a variety of\nOpenAI Gymnasium environments. In four out of the five Gymnasium environments,\nHyperController achieves highest median reward during evaluation compared to\nother algorithms. The results exhibit the potential of HyperController for\nefficient and stable training of reinforcement learning neural networks.", "published": "2025-04-27 23:13:19", "link": "http://arxiv.org/abs/2504.19382v1", "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "$O(1/k)$ Finite-Time Bound for Non-Linear Two-Time-Scale Stochastic Approximation", "abstract": "Two-time-scale stochastic approximation is an algorithm with coupled\niterations which has found broad applications in reinforcement learning,\noptimization and game control. While several prior works have obtained a mean\nsquare error bound of $O(1/k)$ for linear two-time-scale iterations, the best\nknown bound in the non-linear contractive setting has been $O(1/k^{2/3})$. In\nthis work, we obtain an improved bound of $O(1/k)$ for non-linear\ntwo-time-scale stochastic approximation. Our result applies to algorithms such\nas gradient descent-ascent and two-time-scale Lagrangian optimization. The key\nstep in our analysis involves rewriting the original iteration in terms of an\naveraged noise sequence which decays sufficiently fast. Additionally, we use an\ninduction-based approach to show that the iterates are bounded in expectation.", "published": "2025-04-27 22:45:00", "link": "http://arxiv.org/abs/2504.19375v1", "categories": ["cs.LG", "cs.SY", "eess.SY", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Composable and adaptive design of machine learning interatomic potentials guided by Fisher-information analysis", "abstract": "An adaptive physics-informed model design strategy for machine-learning\ninteratomic potentials (MLIPs) is proposed. This strategy follows an iterative\nreconfiguration of composite models from single-term models, followed by a\nunified training procedure. A model evaluation method based on the Fisher\ninformation matrix (FIM) and multiple-property error metrics is proposed to\nguide model reconfiguration and hyperparameter optimization. Combining the\nmodel reconfiguration and the model evaluation subroutines, we provide an\nadaptive MLIP design strategy that balances flexibility and extensibility. In a\ncase study of designing models against a structurally diverse niobium dataset,\nwe managed to obtain an optimal configuration with 75 parameters generated by\nour framework that achieved a force RMSE of 0.172 eV/{\\AA} and an energy RMSE\nof 0.013 eV/atom.", "published": "2025-04-27 22:18:38", "link": "http://arxiv.org/abs/2504.19372v1", "categories": ["cond-mat.mtrl-sci", "cs.LG", "cs.NA", "math.NA", "physics.app-ph", "physics.comp-ph"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "Metric Similarity and Manifold Learning of Circular Dichroism Spectra of Proteins", "abstract": "We present a machine learning analysis of circular dichroism spectra of\nglobular proteins from the SP175 database, using the optimal transport-based\n$1$-Wasserstein distance $\\mathcal{W}_1$ (with order $p=1$) and the manifold\nlearning algorithm $t$-SNE. Our results demonstrate that $\\mathcal{W}_1$ is\nconsistent with both Euclidean and Manhattan metrics while exhibiting\nrobustness to noise. On the other hand, $t$-SNE uncovers meaningful structure\nin the high-dimensional data. The clustering in the $t$-SNE embedding is\nprimarily determined by proteins with distinct secondary structure\ncompositions: one cluster predominantly contains $\\beta$-rich proteins, while\nthe other consists mainly of proteins with mixed $\\alpha/\\beta$ and\n$\\alpha$-helical content.", "published": "2025-04-27 20:43:54", "link": "http://arxiv.org/abs/2504.19355v1", "categories": ["physics.soc-ph", "cs.LG"], "primary_category": "physics.soc-ph"}
{"title": "The Double Descent Behavior in Two Layer Neural Network for Binary Classification", "abstract": "Recent studies observed a surprising concept on model test error called the\ndouble descent phenomenon, where the increasing model complexity decreases the\ntest error first and then the error increases and decreases again. To observe\nthis, we work on a two layer neural network model with a ReLU activation\nfunction designed for binary classification under supervised learning. Our aim\nis to observe and investigate the mathematical theory behind the double descent\nbehavior of model test error for varying model sizes. We quantify the model\nsize by the ratio of number of training samples to the dimension of the model.\nDue to the complexity of the empirical risk minimization procedure, we use the\nConvex Gaussian Min Max Theorem to find a suitable candidate for the global\ntraining loss.", "published": "2025-04-27 20:29:24", "link": "http://arxiv.org/abs/2504.19351v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Contextual Online Uncertainty-Aware Preference Learning for Human Feedback", "abstract": "Reinforcement Learning from Human Feedback (RLHF) has become a pivotal\nparadigm in artificial intelligence to align large models with human\npreferences. In this paper, we propose a novel statistical framework to\nsimultaneously conduct the online decision-making and statistical inference on\nthe optimal model using human preference data based on dynamic contextual\ninformation. Our approach introduces an efficient decision strategy that\nachieves both the optimal regret bound and the asymptotic distribution of the\nestimators. A key challenge in RLHF is handling the dependent online human\npreference outcomes with dynamic contexts. To address this, in the\nmethodological aspect, we propose a two-stage algorithm starting with\n$\\epsilon$-greedy followed by exploitations; in the theoretical aspect, we\ntailor anti-concentration inequalities and matrix martingale concentration\ntechniques to derive the uniform estimation rate and asymptotic normality of\nthe estimators using dependent samples from both stages. Extensive simulation\nresults demonstrate that our method outperforms state-of-the-art strategies. We\napply the proposed framework to analyze the human preference data for ranking\nlarge language models on the Massive Multitask Language Understanding dataset,\nyielding insightful results on the performance of different large language\nmodels for medical anatomy knowledge.", "published": "2025-04-27 19:59:11", "link": "http://arxiv.org/abs/2504.19342v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Ethical Challenges of Using Artificial Intelligence in Judiciary", "abstract": "Artificial intelligence (AI) has emerged as a ubiquitous concept in numerous\ndomains, including the legal system. AI has the potential to revolutionize the\nfunctioning of the judiciary and the dispensation of justice. Incorporating AI\ninto the legal system offers the prospect of enhancing decision-making for\njudges, lawyers, and legal professionals, while concurrently providing the\npublic with more streamlined, efficient, and cost-effective services. The\nintegration of AI into the legal landscape offers manifold benefits,\nencompassing tasks such as document review, legal research, contract analysis,\ncase prediction, and decision-making. By automating laborious and error-prone\nprocedures, AI has the capacity to alleviate the burden associated with these\narduous tasks. Consequently, courts around the world have begun embracing AI\ntechnology as a means to enhance the administration of justice. However,\nalongside its potential advantages, the use of AI in the judiciary poses a\nrange of ethical challenges. These ethical quandaries must be duly addressed to\nensure the responsible and equitable deployment of AI systems. This article\ndelineates the principal ethical challenges entailed in employing AI within the\njudiciary and provides recommendations to effectively address these issues.", "published": "2025-04-27 15:51:56", "link": "http://arxiv.org/abs/2504.19284v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Navigating AI Policy Landscapes: Insights into Human Rights Considerations Across IEEE Regions", "abstract": "This paper explores the integration of human rights considerations into AI\nregulatory frameworks across different IEEE regions - specifically the United\nStates (Region 1-6), Europe (Region 8), China (part of Region 10), and\nSingapore (part of Region 10). While all acknowledge the transformative\npotential of AI and the necessity of ethical guidelines, their regulatory\napproaches significantly differ. Europe exhibits a rigorous framework with\nstringent protections for individual rights, while the U.S. promotes innovation\nwith less restrictive regulations. China emphasizes state control and societal\norder in its AI strategies. In contrast, Singapore's advisory framework\nencourages self-regulation and aligns closely with international norms. This\ncomparative analysis underlines the need for ongoing global dialogue to\nharmonize AI regulations that safeguard human rights while promoting\ntechnological advancement, reflecting the diverse perspectives and priorities\nof each region.", "published": "2025-04-27 14:44:42", "link": "http://arxiv.org/abs/2504.19264v1", "categories": ["cs.CY", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Convergence Properties of Natural Gradient Descent for Minimizing KL Divergence", "abstract": "The Kullback-Leibler (KL) divergence plays a central role in probabilistic\nmachine learning, where it commonly serves as the canonical loss function.\nOptimization in such settings is often performed over the probability simplex,\nwhere the choice of parameterization significantly impacts convergence. In this\nwork, we study the problem of minimizing the KL divergence and analyze the\nbehavior of gradient-based optimization algorithms under two dual coordinate\nsystems within the framework of information geometry$-$ the exponential family\n($\\theta$ coordinates) and the mixture family ($\\eta$ coordinates). We compare\nEuclidean gradient descent (GD) in these coordinates with the\ncoordinate-invariant natural gradient descent (NGD), where the natural gradient\nis a Riemannian gradient that incorporates the intrinsic geometry of the\nparameter space. In continuous time, we prove that the convergence rates of GD\nin the $\\theta$ and $\\eta$ coordinates provide lower and upper bounds,\nrespectively, on the convergence rate of NGD. Moreover, under affine\nreparameterizations of the dual coordinates, the convergence rates of GD in\n$\\eta$ and $\\theta$ coordinates can be scaled to $2c$ and $\\frac{2}{c}$,\nrespectively, for any $c>0$, while NGD maintains a fixed convergence rate of\n$2$, remaining invariant to such transformations and sandwiched between them.\nAlthough this suggests that NGD may not exhibit uniformly superior convergence\nin continuous time, we demonstrate that its advantages become pronounced in\ndiscrete time, where it achieves faster convergence and greater robustness to\nnoise, outperforming GD. Our analysis hinges on bounding the spectrum and\ncondition number of the Hessian of the KL divergence at the optimum, which\ncoincides with the Fisher information matrix.", "published": "2025-04-27 14:39:33", "link": "http://arxiv.org/abs/2504.19259v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Second-Order Compatible-Strain Mixed Finite Elements for 2D Compressible Nonlinear Elasticity", "abstract": "In recent years, a new class of mixed finite elements -- compatible-strain\nmixed finite elements (CSMFEs) -- has emerged that uses the differential\ncomplex of nonlinear elasticity. Their excellent performance in benchmark\nproblems, such as numerical stability for modeling large deformations in\nnear-incompressible solids, makes them a promising choice for solving\nengineering problems. Explicit forms exist for various shape functions of\nfirst-order CSMFEs. In contrast, existing second-order CSMFEs evaluate shape\nfunctions using numerical integration. In this paper, we formulate second-order\nCSMFEs with explicit shape functions for the displacement gradient and stress\ntensor. Concepts of vector calculus that stem from exterior calculus are\npresented and used to provide efficient forms for shape functions in the\nnatural coordinate system. Covariant and contravariant Piola transformations\nare then applied to transform the shape functions to the physical space.\nMid-nodes and pseudo-nodes are used to enforce the continuity constraints for\nthe displacement gradient and stress tensor over the boundaries of elements.\nThe formulation of the proposed second-order CSMFEs and technical aspects\nregarding their implementation are discussed in detail. Several benchmark\nproblems are solved to compare the performance of CSMFEs with first-order\nCSMFEs and other second-order elements that rely on numerical integration. It\nis shown that the proposed CSMFEs are numerically stable for modeling\nnear-incompressible solids in the finite strain regime.", "published": "2025-04-27 22:47:43", "link": "http://arxiv.org/abs/2504.19376v1", "categories": ["math.NA", "cond-mat.mtrl-sci", "cs.NA"], "primary_category": "math.NA"}
{"title": "A filtered finite difference method for a highly oscillatory nonlinear Klein--Gordon equation", "abstract": "We consider a nonlinear Klein--Gordon equation in the nonrelativistic limit\nregime with highly oscillatory initial data in the form of a modulated plane\nwave. In this regime, the solution exhibits rapid oscillations in both time and\nspace, posing challenges for numerical approximation. We propose a filtered\nfinite difference method that achieves second-order accuracy with time steps\nand mesh sizes that are not restricted in magnitude by the small parameter.\nMoreover, the method is uniformly convergent in the range from arbitrarily\nsmall to moderately bounded scaling parameters. Numerical experiments\nillustrate the theoretical results.", "published": "2025-04-27 21:01:32", "link": "http://arxiv.org/abs/2504.19359v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Efficient approximations of matrix multiplication using truncated decompositions", "abstract": "We exploit the truncated singular value decomposition and the recently\nproposed circulant decomposition for an efficient first-order approximation of\nthe multiplication of large dense matrices. A decomposition of each matrix into\na sum of a sparse matrix with relatively few dominant entries and a dense\nresidue can also use the above approach, and we present methods for\nmultiplication using a Fourier decomposition and a cycle decomposition-based\nsparsifications. The proposed methods scale as $\\mathcal{O}(n^2 \\log n)$ in\narithmetic operations for $n \\times n$ matrices for usable tolerances in\nrelative error $\\sim$ 1\\%. Note that different decompositions for the two\nmatrices $A$ and $B$ in the product $AB$ are also possible in this approach,\nusing a priori evaluations for suitability, to improve further on the error\ntolerances demonstrated here.", "published": "2025-04-27 17:15:17", "link": "http://arxiv.org/abs/2504.19308v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Trigonometric Interpolation Based Optimization for Second Order Non-Linear ODE with Mixed Boundary Conditions", "abstract": "In this paper, we propose a trigonometric-interpolation approach for\nsolutions of second order nonlinear ODEs with mixed boundary conditions. The\nmethod interpolates secondary derivative $y''$ of a target solution $y$ by a\ntrigonometric polynomial. The solution is identified through an optimization\nprocess to capture the dynamics of $y,y',y''$ characterized by the underlying\ndifferential equation. The gradient function of the optimization can be carried\nout by Fast Fourier Transformation and high-degree accuracy can be achieved\neffectively by increasing interpolation grid points. In case that solution of\nODE system is not unique, the algorithm has flexibility to approach to a\ndesired solution that meets certain requirements such as being positive.\nNumerical tests have been conducted under various boundary conditions with\nexpected performance.\n  The algorithm can be extended for nonlinear ODE of a general order $k$\nalthough implementation complexity will increase as $k$ gets larger.", "published": "2025-04-27 15:34:48", "link": "http://arxiv.org/abs/2504.19280v1", "categories": ["math.NA", "cs.NA", "Primary 65T40, Secondary 65T50"], "primary_category": "math.NA"}
{"title": "Hybridizable Discontinuous Galerkin Methods for Coupled Poro-Viscoelastic and Thermo-Viscoelastic Systems", "abstract": "This article presents a unified mathematical framework for modeling coupled\nporo-viscoelastic and thermo-viscoelastic phenomena, formulated as a system of\nfirst-order in time partial differential equations. The model describes the\nevolution of solid velocity, elastic and viscous stress tensors, and additional\nfields related to either fluid pressure or temperature, depending on the\nphysical context. We develop a hybridizable discontinuous Galerkin method for\nthe numerical approximation of this coupled system, providing a high-order,\nstable discretization that efficiently handles the multiphysics nature of the\nproblem. We establish stability analysis and derive optimal $hp$-error\nestimates for the semi-discrete formulation. The theoretical convergence rates\nare validated through comprehensive numerical experiments, demonstrating the\nmethod's accuracy and robustness across various test cases, including wave\npropagation in heterogeneous media with mixed viscoelastic properties.", "published": "2025-04-27 14:16:16", "link": "http://arxiv.org/abs/2504.19250v1", "categories": ["math.NA", "cs.NA", "65N30, 65N12, 65N15, 74F10, 74D05, 76S05"], "primary_category": "math.NA"}
{"title": "Strong and weak convergence orders of numerical methods for SDEs driven by time-changed L\u00e9vy noise", "abstract": "This work investigates the strong and weak convergence orders of numerical\nmethods for SDEs driven by time-changed L\\'{e}vy noise under the globally\nLipschitz conditions. Based on the duality theorem, we prove that the numerical\napproximation generated by the stochastic $\\theta$ method with $\\theta \\in\n[0,1]$ and the simulation of inverse subordinator converges strongly with order\n$1/2$. Moreover, the numerical approximation combined with the Euler--Maruyama\nmethod and the estimate of inverse subordinator is shown to have the weak\nconvergence order $1$ by means of the Kolmogorov backward partial integro\ndifferential equations. These theoretical results are finally confirmed by some\nnumerical experiments.", "published": "2025-04-27 10:51:04", "link": "http://arxiv.org/abs/2504.19192v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Parameter estimation for multivariate exponential sums via iterative rational approximation", "abstract": "We present two new methods for multivariate exponential analysis. In [7], we\ndeveloped a new algorithm for reconstruction of univariate exponential sums by\nexploiting the rational structure of their Fourier coefficients and\nreconstructing this rational structure with the AAA (adaptive\nAntoulas-Anderson) method for rational approximation [15]. In this paper, we\nextend these ideas to the multivariate setting. Similarly as in univariate\ncase, the Fourier coefficients of multivariate exponential sums have a rational\nstructure and the multivariate exponential recovery problem can be reformulated\nas multivariate rational interpolation problem. We develop two approaches to\nsolve this special multivariate rational interpolation problem by reducing it\nto the several univariate ones, which are then solved again via the univariate\nAAA method. Our first approach is based on using indices of the Fourier\ncoefficients chosen from some sparse grid, which ensures efficient\nreconstruction using a respectively small amount of input data. The second\napproach is based on using the full grid of indices of the Fourier coefficients\nand relies on the idea of recursive dimension reduction. We demonstrate\nperformance of our methods with several numerical examples.", "published": "2025-04-27 08:28:07", "link": "http://arxiv.org/abs/2504.19157v1", "categories": ["math.NA", "cs.NA", "41A20, 42A16, 42B05, 65D15, 65D40, 94A12"], "primary_category": "math.NA"}
{"title": "Provable algorithms for multi-reference alignment over $\\SO(2)$", "abstract": "The multi-reference alignment (MRA) problem involves reconstructing a signal\nfrom multiple noisy observations, each transformed by a random group element.\nIn this paper, we focus on the group \\(\\mathrm{SO}(2)\\) of in-plane rotations\nand propose two computationally efficient algorithms with theoretical\nguarantees for accurate signal recovery under a non-uniform distribution over\nthe group. The first algorithm exploits the spectral properties of the second\nmoment of the data, while the second utilizes the frequency matching principle.\nBoth algorithms achieve the optimal estimation rate in high-noise regimes,\nmarking a significant advancement in the development of computationally\nefficient and statistically optimal methods for estimation problems over\ngroups.", "published": "2025-04-27 07:28:57", "link": "http://arxiv.org/abs/2504.19140v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Quasi-Monte Carlo confidence intervals using quantiles of randomized nets", "abstract": "Recent advances in quasi-Monte Carlo integration have demonstrated that the\nmedian trick significantly enhances the convergence rate of linearly scrambled\ndigital net estimators. In this work, we leverage the quantiles of such\nestimators to construct confidence intervals with asymptotically valid coverage\nfor high-dimensional integrals. By analyzing the distribution of the\nintegration error for a class of infinitely differentiable integrands, we prove\nthat as the sample size grows, the error decomposes into an asymptotically\nsymmetric component and a vanishing perturbation, which guarantees that a\nquantile-based interval for the median estimator asymptotically captures the\ntarget integral with the nominal coverage probability.", "published": "2025-04-27 07:25:17", "link": "http://arxiv.org/abs/2504.19138v1", "categories": ["math.ST", "cs.NA", "math.NA", "stat.CO", "stat.TH"], "primary_category": "math.ST"}
{"title": "Analysis and Elimination of Numerical Pressure Dependency in Coupled Stokes-Darcy Problem", "abstract": "This paper presents a pressure-robust mixed finite element method (FEM) for\nthe coupled Stokes-Darcy system. We revisits the rigorous theoretical framework\nof Layton et al. [2002], where velocity and pressure errors are coupled,\nmasking pressure's influence on velocity accuracy. To investigate the pressure\ndependency, we introduce a auxiliary velocity projection that preserves\ndiscrete divergence and interface continuity constraints. By analyzing the\ndifference between the discrete and projected velocities, we rigorously prove\nthat classical FEM incurs pressure-dependent consistency errors due to inexact\ndivergence enforcement and approximate interface conditions. To eliminate these\nerrors, we design a pressure-robust method using divergence-free reconstruction\noperator, which enforce exact divergence constraint and interface continuity.\nNumerical examples confirm the theory: under high-pressure or low-viscosity,\nthe proposed method reduces velocity errors by orders of magnitude compared to\nclassical method.", "published": "2025-04-27 05:51:07", "link": "http://arxiv.org/abs/2504.19116v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Ridge partial correlation screening for ultrahigh-dimensional data", "abstract": "Variable selection in ultrahigh-dimensional linear regression is\n  challenging due to its high computational cost. Therefore, a\n  screening step is usually conducted before variable selection to\n  significantly reduce the dimension. Here we propose a novel and\n  simple screening method based on ordering the absolute sample ridge\n  partial correlations. The proposed method takes into account not\n  only the ridge regularized estimates of the regression coefficients\n  but also the ridge regularized partial variances of the predictor\n  variables providing sure screening property without strong\n  assumptions on the marginal correlations. Simulation study and a\n  real data analysis show that the proposed method has a competitive\n  performance compared with the existing screening procedures. A\n  publicly available software implementing the proposed screening\n  accompanies the article.", "published": "2025-04-27 23:52:44", "link": "http://arxiv.org/abs/2504.19393v1", "categories": ["stat.ME", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Test Set Sizing for the Ridge Regression", "abstract": "We derive the ideal train/test split for the ridge regression to high\naccuracy in the limit that the number of training rows m becomes large. The\nsplit must depend on the ridge tuning parameter, alpha, but we find that the\ndependence is weak and can asymptotically be ignored; all parameters vanish\nexcept for m and the number of features, n. This is the first time that such a\nsplit is calculated mathematically for a machine learning model in the large\ndata limit. The goal of the calculations is to maximize \"integrity,\" so that\nthe measured error in the trained model is as close as possible to what it\ntheoretically should be. This paper's result for the ridge regression split\nmatches prior art for the plain vanilla linear regression split to the first\ntwo terms asymptotically, and it appears that practically there is no\ndifference.", "published": "2025-04-27 13:17:18", "link": "http://arxiv.org/abs/2504.19231v1", "categories": ["stat.ML", "cs.LG", "math.PR"], "primary_category": "stat.ML"}
{"title": "Newton-Puiseux Analysis for Interpretability and Calibration of Complex-Valued Neural Networks", "abstract": "Complex-valued neural networks (CVNNs) excel where phase matters, yet their\nmulti-sheeted decision surfaces defy standard explainability and calibration\ntools. We propose a \\emph{Newton-Puiseux} framework that fits a local\npolynomial surrogate to a high-uncertainty input and analytically decomposes\nthis surrogate into fractional-power series. The resulting Puiseux expansions,\ndominant Puiseux coefficients, and phase-aligned curvature descriptors deliver\nclosed-form estimates of robustness and over-confidence that gradient - or\nperturbation-based methods (saliency, LIME, SHAP) cannot provide. On a\ncontrolled $\\mathbb{C}^2$ helix the surrogate attains RMSE $< 0.09$ while\nrecovering the number of decision sheets; quartic coefficients predict\nadversarial flip radii within $10^{-3}$. On the real-world MIT-BIH arrhythmia\ncorpus, Puiseux-guided, phase-aware temperature scaling lowers expected\ncalibration error from 0.087 to 0.034, contributing to the advancement of\nCVNNs. Full code, pre-trained weights, and scripts are at\nhttps://github.com/piotrmgs/puiseux-cvnn.", "published": "2025-04-27 09:37:07", "link": "http://arxiv.org/abs/2504.19176v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Fast and Robust: Task Sampling with Posterior and Diversity Synergies for Adaptive Decision-Makers in Randomized Environments", "abstract": "Task robust adaptation is a long-standing pursuit in sequential\ndecision-making. Some risk-averse strategies, e.g., the conditional\nvalue-at-risk principle, are incorporated in domain randomization or meta\nreinforcement learning to prioritize difficult tasks in optimization, which\ndemand costly intensive evaluations. The efficiency issue prompts the\ndevelopment of robust active task sampling to train adaptive policies, where\nrisk-predictive models are used to surrogate policy evaluation. This work\ncharacterizes the optimization pipeline of robust active task sampling as a\nMarkov decision process, posits theoretical and practical insights, and\nconstitutes robustness concepts in risk-averse scenarios. Importantly, we\npropose an easy-to-implement method, referred to as Posterior and Diversity\nSynergized Task Sampling (PDTS), to accommodate fast and robust sequential\ndecision-making. Extensive experiments show that PDTS unlocks the potential of\nrobust active task sampling, significantly improves the zero-shot and few-shot\nadaptation robustness in challenging tasks, and even accelerates the learning\nprocess under certain scenarios. Our project website is at\nhttps://thu-rllab.github.io/PDTS_project_page.", "published": "2025-04-27 07:27:17", "link": "http://arxiv.org/abs/2504.19139v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Score-Debiased Kernel Density Estimation", "abstract": "We propose a novel method for density estimation that leverages an estimated\nscore function to debias kernel density estimation (SD-KDE). In our approach,\neach data point is adjusted by taking a single step along the score function\nwith a specific choice of step size, followed by standard KDE with a modified\nbandwidth. The step size and modified bandwidth are chosen to remove the\nleading order bias in the KDE. Our experiments on synthetic tasks in 1D, 2D and\non MNIST, demonstrate that our proposed SD-KDE method significantly reduces the\nmean integrated squared error compared to the standard Silverman KDE, even with\nnoisy estimates in the score function. These results underscore the potential\nof integrating score-based corrections into nonparametric density estimation.", "published": "2025-04-27 02:51:30", "link": "http://arxiv.org/abs/2504.19084v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Muyan-TTS: A Trainable Text-to-Speech Model Optimized for Podcast Scenarios with a $50K Budget", "abstract": "Recent advancements in text-to-speech (TTS) models have been driven by the\nintegration of large language models (LLMs), enhancing semantic comprehension\nand improving speech naturalness. However, existing LLM-based TTS models often\nlack open-source training code and efficient inference acceleration frameworks,\nlimiting their accessibility and adaptability. Additionally, there is no\npublicly available TTS model specifically optimized for podcast scenarios,\nwhich are in high demand for voice interaction applications. To address these\nlimitations, we introduce Muyan-TTS, an open-source trainable TTS model\ndesigned for podcast applications within a $50,000 budget. Our model is\npre-trained on over 100,000 hours of podcast audio data, enabling zero-shot TTS\nsynthesis with high-quality voice generation. Furthermore, Muyan-TTS supports\nspeaker adaptation with dozens of minutes of target speech, making it highly\ncustomizable for individual voices. In addition to open-sourcing the model, we\nprovide a comprehensive data collection and processing pipeline, a full\ntraining procedure, and an optimized inference framework that accelerates\nLLM-based TTS synthesis. Our code and models are available at\nhttps://github.com/MYZY-AI/Muyan-TTS.", "published": "2025-04-27 07:58:56", "link": "http://arxiv.org/abs/2504.19146v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Super-resolution Wideband Beam Training for Near-field Communications with Ultra-low Overhead", "abstract": "In this paper, we propose a super-resolution wideband beam training method\nfor near-field communications, which is able to achieve ultra-low overhead. To\nthis end, we first study the multi-beam characteristic of a sparse uniform\nlinear array (S-ULA) in the wideband. Interestingly, we show that this leads to\na new beam pattern property, called rainbow blocks, where the S-ULA generates\nmultiple grating lobes and each grating lobe is further splitted into multiple\nversions in the wideband due to the well-known beam-split effect. As such, one\ndirectional beamformer based on S-ULA is capable of generating multiple rainbow\nblocks in the wideband, hence significantly extending the beam coverage. Then,\nby exploiting the beam-split effect in both the frequency and spatial domains,\nwe propose a new three-stage wideband beam training method for extremely\nlarge-scale array (XL-array) systems. Specifically, we first sparsely activate\na set of antennas at the central of the XL-array and judiciously design the\ntime-delay (TD) parameters to estimate candidate user angles by comparing the\nreceived signal powers at the user over subcarriers. Next, to resolve the\nangular ambiguity introduced by the S-ULA, we activate all antennas in the\ncentral subarray and design an efficient subcarrier selection scheme to\nestimate the true user angle. In the third stage, we resolve the user range at\nthe estimated user angle with high resolution by controlling the splitted beams\nover subcarriers to simultaneously cover the range domain. Finally, numerical\nresults are provided to demonstrate the effectiveness of proposed wideband beam\ntraining scheme, which only needs three pilots in near-field beam training,\nwhile achieving near-optimal rate performance.", "published": "2025-04-27 14:42:01", "link": "http://arxiv.org/abs/2504.19262v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Target Detection for ISAC with TDD Transmission", "abstract": "Integrated sensing and communication (ISAC) poses various challenges that\narise from the communication-centric design of cellular networks. One of them\nis target detection with time division duplex (TDD) transmission used in\ncurrent 5G and future 6G deployments, where the periodic on-off behavior of the\ntransmitter creates impulsive sidelobes in the radar point spread function\n(PSF). These can be mistaken for actual targets by conventional peak detection\ntechniques, leading to false alarms. In this work, we first analytically\ndescribe the range-Doppler PSF due to TDD windowing. We then propose a\ncomputationally efficient method that leverages the PSF to distinguish\nimpulsive sidelobes from valid target peaks. Simulation results and outdoor\ndrone measurements with an ISAC proof of concept demonstrate the capability of\nour algorithm, showing that it can achieve reliable target detection while\nlimiting false alarms.", "published": "2025-04-27 14:39:42", "link": "http://arxiv.org/abs/2504.19260v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Optimal Azimuth Sampling and Interpolation for Bistatic ISAC Setups", "abstract": "A key challenge in future 6G Integrated Sensing and Communications (ISAC)\nnetworks is to define the angular operations of transmitter and receiver, i.e.,\nthe sampling task of the angular domains, to acquire information about the\nenvironment. In this work we extend previous analysis for optimal angular\nsampling of monostatic setups to two-dimensional bistatic deployments, that are\nas important as the former in future ISAC cellular scenarios. Our approach\novercomes the limitations of suboptimal prior art sampling and interpolation\ntechniques, such as spline interpolation. We demonstrate that separating\nazimuth operations of the two transmit and receive arrays is optimal to sample\nthe angular domain in an array-specific normalized angular frequency (NAF).\nThis allows us to derive a loss-less reconstruction of the angular domain,\nenabling a more efficient and accurate sampling strategy for bistatic sensing\napplications compared to legacy approaches. As demonstrated by different Monte\nCarlo experiments, our approach enables future bistatic ISAC deployments with\nbetter performance compared to the other suboptimal solutions.", "published": "2025-04-27 13:44:06", "link": "http://arxiv.org/abs/2504.19238v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Near-Field Collinear Dipole Array Design with Dual-Polarization Operation for Wireless Power Transfer", "abstract": "A large intelligent surface (LIS) is a promising approach to enhancing 6G\nperformance in sub-10 GHz frequency bands. An analysis of the horizontal dipole\nlinear array reveals that when the array size is sufficiently large, employing\nthe conjugate phase method to excite the antenna elements results in a focal\npoint along the central line of the array that gradually stabilizes at a\nconstant value. The study evaluates the 3dB focal resolution generated by the\ndipole array for two polarizations. Additionally, the feasibility of generating\ncircularly polarized focal points and the focal displacement under a limited\narray size are explored. Previous near-field focal synthesis methods primarily\nconsidered only the line-of-sight (LOS) channel. To enhance practicality, this\nstudy adopts a two-ray channel model to analyze near-field focal synthesis\nresults in the presence of a reflected path. Both two polarizations are\ndiscussed separately, with design guidelines provided for array placement and\nfocal point positioning. Finally, electromagnetic simulations are conducted\nwithin the linear array to validate the proposed design. These simulations\nhighlight the capability of the horizontal dipole array configuration to be\ndirectly applied without significant coupling effects between elements. The\nproposed design guidelines lay a solid foundation for the application of LIS in\n6G technology.", "published": "2025-04-27 12:57:57", "link": "http://arxiv.org/abs/2504.19221v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Meta-learning based Selective Fixed-filter Active Noise Control System with ResNet Classifier", "abstract": "The selective fixed-filter strategy is popular in industrial applications\ninvolving active noise control (ANC) technology, which circumvents the\ntime-consuming online learning process by selecting the best-matched\npre-trained control filter. However, the existing selective fixed-filter ANC\n(SFANC) based algorithms classify noises in frequency band, which is not a\nreasonable approach. Moreover, they pre-train the control filter utilizing only\na single noise segment, leading to inaccurate estimation and undesirable noise\ncancellation performance when dealing with dynamically time-varying noise.\nInspired by the applicability of meta-learning to various models utilizing\ngradient descent technique, this paper proposes a novel meta-learning based\nSFANC system, wherein the fixed-filters that may not be optimal for specific\ntypes of noises but can rapidly adapt to previously unseen noise conditions are\npre-trained. To address the mismatch issue between meta-learning update methods\nand ANC requirements while enhancing the receptive field and convergence speed\nof control filters, a multiple-input batch processing strategy is utilized in\npre-training. Simulations based on the common ESC-50 noise dataset are\nperformed and demonstrate the superiorities of the proposed method in terms of\nclassification accuracy, convergence speed, and steady-state noise\ncancellation.", "published": "2025-04-27 09:31:33", "link": "http://arxiv.org/abs/2504.19173v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Comparison Research of Millimeter-Wave/Infrared Co-aperture Reflector Antenna Systems Based on a Specialized Film", "abstract": "This paper presents a novel co-aperture reflector antenna operating in\nmillimeter-wave (MMW) and infrared (IR) for cloud detection radar. The proposed\ndesign combines a back-fed dual-reflector antenna, an IR optical reflection\nsystem, and a specialize thin film with IR-reflective/MMW-transmissive\nproperties. Simulations demonstrate a gain exceeding 50 dBi within 94 GHz plush\nor minus 500 MHz bandwidth, with 0.46{\\deg} beamwidth in both azimuth (E-plane)\nand elevation (H-plane) and sidelobe levels below -25 dB. This co-aperture\narchitecture addresses the limitations of standalone MMW and IR radars,\nenabling high-resolution cloud microphysical parameter retrieval while\nminimizing system footprint. The design lays a foundation for\nairborne/spaceborne multi-mode detection systems.", "published": "2025-04-27 08:06:51", "link": "http://arxiv.org/abs/2504.19150v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "UAV-Aided Progressive Interference Source Localization Based on Improved Trust Region Optimization", "abstract": "Trust region optimization-based received signal strength indicator (RSSI)\ninterference source localization methods have been widely used in low-altitude\nresearch. However, these methods often converge to local optima in complex\nenvironments, degrading the positioning performance. This paper presents a\nnovel unmanned aerial vehicle (UAV)-aided progressive interference source\nlocalization method based on improved trust region optimization. By combining\nthe Levenberg-Marquardt (LM) algorithm with particle swarm optimization (PSO),\nour proposed method can effectively enhance the success rate of localization.\nWe also propose a confidence quantification approach based on the UAV-to-ground\nchannel model. This approach considers the surrounding environmental\ninformation of the sampling points and dynamically adjusts the weight of the\nsampling data during the data fusion. As a result, the overall positioning\naccuracy can be significantly improved. Experimental results demonstrate the\nproposed method can achieve high-precision interference source localization in\nnoisy and interference-prone environments.", "published": "2025-04-27 07:53:00", "link": "http://arxiv.org/abs/2504.19143v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Coherent Source Enumeration with Compact ULAs", "abstract": "Source enumeration typically relies on subspace-based techniques that require\naccurate separation of signal and noise subspaces. However, prior works do not\naddress coherent sources in small uniform linear arrays, where ambiguities\narise in the spatial spectrum. We address this by decomposing the\nforward-backward smoothed covariance matrix into a sum of a rank-constrained\nToeplitz matrix and a diagonal matrix with non-negative entries representing\nthe signal and noise subspace, respectively. We solve the resulting non-convex\noptimization problem by proposing Toeplitz approach for rank-based target\nestimation (TARgEt) that employs the alternating direction method of\nmultipliers. Numerical results on both synthetic and real-world datasets\ndemonstrate the effectiveness and robustness of TARgEt over a recent subspace\nmatching method and a related covariance matrix reconstruction approach.", "published": "2025-04-27 06:56:01", "link": "http://arxiv.org/abs/2504.19126v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "ODE-Former for Mobile Channel Prediction: A Novel Learning Structure Leveraging The Physics Continuity", "abstract": "Obtaining accurate channel state information (CSI) is crucial and challenging\nfor multiple-input multiple-output (MIMO) wireless communication systems. With\nthe increasing antenna scale and user mobility, traditional channel estimation\napproaches suffer greatly from high signaling overhead and channel aging\nproblems. By exploring the intrinsic correlation among a set of historical CSI\ninstances, channel prediction is proven to increase the CSI accuracy while\nlowering the signaling overhead significantly. Existing works view this problem\nas a regular discrete sequence prediction task while ignoring the unique\nphysics property of wireless channels. This letter proposes a novel former-like\nlearning structure based on neural ordinary differential equations (NODEs)\ninclusively designed for accurate and flexible channel prediction. The proposed\nnetwork aims to represent wireless channels' implicit physics spatial-temporal\ncontinuity by integrating the Neural ODE into a former-like learning structure.\nOur proposed method impeccably fits channel matrices' mathematics features and\nenjoys solid network interpretability. Experimental results show that the\nproposed learning approach outperforms existing methods from the perspective of\naccuracy, flexibility, and robustness.", "published": "2025-04-27 06:35:39", "link": "http://arxiv.org/abs/2504.19122v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Modeling and Optimization of Transistor Voltage Amplifiers Based on Stochastic Thermodynamics", "abstract": "As transistor sizes reach the mesoscopic scale, the limitations of\ntraditional methods in ensuring thermodynamic consistency have made power\ndissipation optimization in transistor amplifiers a critical challenge. Based\non stochastic thermodynamics, a transistor voltage amplifier model is first\nproposed as a new insight to investigate nonlinear relationships between the\npower dissipation and voltage gain for complementary symmetric voltage\namplifier circuits (CSVACs). Utilizing the proposed model, the phenomenon,\ni.e., the power dissipation exponentially increases with the increase of\nvoltage gain in CSVACs, is first clarified by an analytical expression to\nquantify the impact of voltage gain and input signal amplitude on the power\ndissipation. Considering the characteristic of power dissipation, a new\nmultistage architecture is proposed to reduce the power dissipation in CSVACs.\nTo optimize the power dissipation by adjusting the number of stages and the\nvoltage gain at each stage, an optimal multistage scheme is proposed for\nmultistage CSVACs. Simulation and experimental results show up to 99.36% and\n94.59% power dissipation reduction compared with traditional CSVACs by the\nproposed optimal multistage scheme, respectively.", "published": "2025-04-27 03:59:04", "link": "http://arxiv.org/abs/2504.19096v1", "categories": ["eess.SP", "cond-mat.mes-hall"], "primary_category": "eess.SP"}
{"title": "A Tutorial on MIMO-OFDM ISAC: From Far-Field to Near-Field", "abstract": "Integrated sensing and communication (ISAC) is one of the key usage scenarios\nfor future sixth-generation (6G) mobile communication networks, where\ncommunication and sensing (C&S) services are simultaneously provided through\nshared wireless spectrum, signal processing modules, hardware, and network\ninfrastructure. Such an integration is strengthened by the technology trends in\n6G, such as denser network nodes, larger antenna arrays, wider bandwidths,\nhigher frequency bands, and more efficient utilization of spectrum and hardware\nresources, which incentivize and empower enhanced sensing capabilities. As the\ndominant waveform used in contemporary communication systems, orthogonal\nfrequency division multiplexing (OFDM) is still expected to be a very\ncompetitive technology for 6G, rendering it necessary to thoroughly investigate\nthe potential and challenges of OFDM ISAC. Thus, this paper aims to provide a\ncomprehensive tutorial overview of ISAC systems enabled by large-scale\nmulti-input multi-output (MIMO) and OFDM technologies and to discuss their\nfundamental principles, advantages, and enabling signal processing methods. To\nthis end, a unified MIMO-OFDM ISAC system model is first introduced, followed\nby four frameworks for estimating parameters across the spatial, delay, and\nDoppler domains, including parallel one-domain, sequential one-domain, joint\ntwo-domain, and joint three-domain parameter estimation. Next, sensing\nalgorithms and performance analyses are presented in detail for far-field\nscenarios where uniform plane wave (UPW) propagation is valid, followed by\ntheir extensions to near-field scenarios where uniform spherical wave (USW)\ncharacteristics need to be considered. Finally, this paper points out open\nchallenges and outlines promising avenues for future research on MIMO-OFDM\nISAC.", "published": "2025-04-27 03:19:19", "link": "http://arxiv.org/abs/2504.19091v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Unified Multi-Task Learning & Model Fusion for Efficient Language Model Guardrailing", "abstract": "The trend towards large language models (LLMs) for guardrailing against\nundesired behaviors is increasing and has shown promise for censoring user\ninputs. However, increased latency, memory consumption, hosting expenses and\nnon-structured outputs can make their use prohibitive.\n  In this work, we show that task-specific data generation can lead to\nfine-tuned classifiers that significantly outperform current state of the art\n(SoTA) while being orders of magnitude smaller. Secondly, we show that using a\nsingle model, \\texttt{MultiTaskGuard}, that is pretrained on a large\nsynthetically generated dataset with unique task instructions further improves\ngeneralization. Thirdly, our most performant models, \\texttt{UniGuard}, are\nfound using our proposed search-based model merging approach that finds an\noptimal set of parameters to combine single-policy models and multi-policy\nguardrail models. % On 7 public datasets and 4 guardrail benchmarks we created,\nour efficient guardrail classifiers improve over the best performing SoTA\npublicly available LLMs and 3$^{\\text{rd}}$ party guardrail APIs in detecting\nunsafe and safe behaviors by an average F1 score improvement of \\textbf{29.92}\npoints over Aegis-LlamaGuard and \\textbf{21.62} over \\texttt{gpt-4o},\nrespectively. Lastly, our guardrail synthetic data generation process that uses\ncustom task-specific guardrail poli", "published": "2025-04-27 19:07:58", "link": "http://arxiv.org/abs/2504.19333v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Versatile Framework for Song Generation with Prompt-based Control", "abstract": "Song generation focuses on producing controllable high-quality songs based on\nvarious prompts. However, existing methods struggle to generate vocals and\naccompaniments with prompt-based control and proper alignment. Additionally,\nthey fall short in supporting various tasks. To address these challenges, we\nintroduce VersBand, a multi-task song generation framework for synthesizing\nhigh-quality, aligned songs with prompt-based control. VersBand comprises these\nprimary models: 1) VocalBand, a decoupled model, leverages the flow-matching\nmethod for generating singing styles, pitches, and mel-spectrograms, allowing\nfast, high-quality vocal generation with style control. 2) AccompBand, a\nflow-based transformer model, incorporates the Band-MOE, selecting suitable\nexperts for enhanced quality, alignment, and control. This model allows for\ngenerating controllable, high-quality accompaniments aligned with vocals. 3)\nTwo generation models, LyricBand for lyrics and MelodyBand for melodies,\ncontribute to the comprehensive multi-task song generation system, allowing for\nextensive control based on multiple prompts. Experimental results demonstrate\nthat VersBand performs better over baseline models across multiple song\ngeneration tasks using objective and subjective metrics. Audio samples are\navailable at https://aaronz345.github.io/VersBandDemo.", "published": "2025-04-27 01:00:06", "link": "http://arxiv.org/abs/2504.19062v2", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Doxing via the Lens: Revealing Privacy Leakage in Image Geolocation for Agentic Multi-Modal Large Reasoning Model", "abstract": "The increasing capabilities of agentic multi-modal large reasoning models,\nsuch as ChatGPT o3, have raised critical concerns regarding privacy leakage\nthrough inadvertent image geolocation. In this paper, we conduct the first\nsystematic and controlled study on the potential privacy risks associated with\nvisual reasoning abilities of ChatGPT o3. We manually collect and construct a\ndataset comprising 50 real-world images that feature individuals alongside\nprivacy-relevant environmental elements, capturing realistic and sensitive\nscenarios for analysis. Our experimental evaluation reveals that ChatGPT o3 can\npredict user locations with high precision, achieving street-level accuracy\n(within one mile) in 60% of cases. Through analysis, we identify key visual\ncues, including street layout and front yard design, that significantly\ncontribute to the model inference success. Additionally, targeted occlusion\nexperiments demonstrate that masking critical features effectively mitigates\ngeolocation accuracy, providing insights into potential defense mechanisms. Our\nfindings highlight an urgent need for privacy-aware development for agentic\nmulti-modal large reasoning models, particularly in applications involving\nprivate imagery.", "published": "2025-04-27 22:26:45", "link": "http://arxiv.org/abs/2504.19373v2", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "NSFlow: An End-to-End FPGA Framework with Scalable Dataflow Architecture for Neuro-Symbolic AI", "abstract": "Neuro-Symbolic AI (NSAI) is an emerging paradigm that integrates neural\nnetworks with symbolic reasoning to enhance the transparency, reasoning\ncapabilities, and data efficiency of AI systems. Recent NSAI systems have\ngained traction due to their exceptional performance in reasoning tasks and\nhuman-AI collaborative scenarios. Despite these algorithmic advancements,\nexecuting NSAI tasks on existing hardware (e.g., CPUs, GPUs, TPUs) remains\nchallenging, due to their heterogeneous computing kernels, high memory\nintensity, and unique memory access patterns. Moreover, current NSAI algorithms\nexhibit significant variation in operation types and scales, making them\nincompatible with existing ML accelerators. These challenges highlight the need\nfor a versatile and flexible acceleration framework tailored to NSAI workloads.\nIn this paper, we propose NSFlow, an FPGA-based acceleration framework designed\nto achieve high efficiency, scalability, and versatility across NSAI systems.\nNSFlow features a design architecture generator that identifies workload data\ndependencies and creates optimized dataflow architectures, as well as a\nreconfigurable array with flexible compute units, re-organizable memory, and\nmixed-precision capabilities. Evaluating across NSAI workloads, NSFlow achieves\n31x speedup over Jetson TX2, more than 2x over GPU, 8x speedup over TPU-like\nsystolic array, and more than 3x over Xilinx DPU. NSFlow also demonstrates\nenhanced scalability, with only 4x runtime increase when symbolic workloads\nscale by 150x. To the best of our knowledge, NSFlow is the first framework to\nenable real-time generalizable NSAI algorithms acceleration, demonstrating a\npromising solution for next-generation cognitive systems.", "published": "2025-04-27 18:28:43", "link": "http://arxiv.org/abs/2504.19323v2", "categories": ["cs.AR", "cs.AI", "cs.LG", "cs.PF"], "primary_category": "cs.AR"}
{"title": "AlphaFuse: Learn ID Embeddings for Sequential Recommendation in Null Space of Language Embeddings", "abstract": "Recent advancements in sequential recommendation have underscored the\npotential of Large Language Models (LLMs) for enhancing item embeddings.\nHowever, existing approaches face three key limitations: 1) the degradation of\nthe semantic space when high-dimensional language embeddings are mapped to\nlower-dimensional ID embeddings, 2) the underutilization of language\nembeddings, and 3) the reliance on additional trainable parameters, such as an\nadapter, to bridge the gap between the semantic and behavior spaces. In this\npaper, we introduce AlphaFuse, a simple but effective language-guided learning\nstrategy that addresses these challenges by learning ID embeddings within the\nnull space of language embeddings. Specifically, we decompose the semantic\nspace of language embeddings via Singular Value Decomposition (SVD),\ndistinguishing it into a semantic-rich row space and a semantic-sparse null\nspace. Collaborative signals are then injected into the null space, while\npreserving the rich semantics of the row space. AlphaFuse prevents degradation\nof the semantic space, integrates the retained language embeddings into the\nfinal item embeddings, and eliminates the need for auxiliary trainable modules,\nenabling seamless adaptation to any sequential recommendation framework. We\nvalidate the effectiveness and flexibility of AlphaFuse through extensive\nexperiments on three benchmark datasets, including cold-start user and\nlong-tail settings, showcasing significant improvements in both discriminative\nand diffusion-based generative sequential recommenders. Our codes and datasets\nare available at https://github.com/Hugo-Chinn/AlphaFuse.", "published": "2025-04-27 12:51:56", "link": "http://arxiv.org/abs/2504.19218v2", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Swapped Logit Distillation via Bi-level Teacher Alignment", "abstract": "Knowledge distillation (KD) compresses the network capacity by transferring\nknowledge from a large (teacher) network to a smaller one (student). It has\nbeen mainstream that the teacher directly transfers knowledge to the student\nwith its original distribution, which can possibly lead to incorrect\npredictions. In this article, we propose a logit-based distillation via swapped\nlogit processing, namely Swapped Logit Distillation (SLD). SLD is proposed\nunder two assumptions: (1) the wrong prediction occurs when the prediction\nlabel confidence is not the maximum; (2) the \"natural\" limit of probability\nremains uncertain as the best value addition to the target cannot be\ndetermined. To address these issues, we propose a swapped logit processing\nscheme. Through this approach, we find that the swap method can be effectively\nextended to teacher and student outputs, transforming into two teachers. We\nfurther introduce loss scheduling to boost the performance of two teachers'\nalignment. Extensive experiments on image classification tasks demonstrate that\nSLD consistently performs best among previous state-of-the-art methods.", "published": "2025-04-27 15:52:07", "link": "http://arxiv.org/abs/2504.20108v1", "categories": ["cs.LG", "eess.IV", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Uncertainty Quantification for Language Models: A Suite of Black-Box, White-Box, LLM Judge, and Ensemble Scorers", "abstract": "Hallucinations are a persistent problem with Large Language Models (LLMs). As\nthese models become increasingly used in high-stakes domains, such as\nhealthcare and finance, the need for effective hallucination detection is\ncrucial. To this end, we propose a versatile framework for zero-resource\nhallucination detection that practitioners can apply to real-world use cases.\nTo achieve this, we adapt a variety of existing uncertainty quantification (UQ)\ntechniques, including black-box UQ, white-box UQ, and LLM-as-a-Judge,\ntransforming them as necessary into standardized response-level confidence\nscores ranging from 0 to 1. To enhance flexibility, we introduce a tunable\nensemble approach that incorporates any combination of the individual\nconfidence scores. This approach enables practitioners to optimize the ensemble\nfor a specific use case for improved performance. To streamline implementation,\nthe full suite of scorers is offered in this paper's companion Python toolkit,\nUQLM. To evaluate the performance of the various scorers, we conduct an\nextensive set of experiments using several LLM question-answering benchmarks.\nWe find that our tunable ensemble typically surpasses its individual components\nand outperforms existing hallucination detection methods. Our results\ndemonstrate the benefits of customized hallucination detection strategies for\nimproving the accuracy and reliability of LLMs.", "published": "2025-04-27 14:24:45", "link": "http://arxiv.org/abs/2504.19254v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Contextual Online Uncertainty-Aware Preference Learning for Human Feedback", "abstract": "Reinforcement Learning from Human Feedback (RLHF) has become a pivotal\nparadigm in artificial intelligence to align large models with human\npreferences. In this paper, we propose a novel statistical framework to\nsimultaneously conduct the online decision-making and statistical inference on\nthe optimal model using human preference data based on dynamic contextual\ninformation. Our approach introduces an efficient decision strategy that\nachieves both the optimal regret bound and the asymptotic distribution of the\nestimators. A key challenge in RLHF is handling the dependent online human\npreference outcomes with dynamic contexts. To address this, in the\nmethodological aspect, we propose a two-stage algorithm starting with\n$\\epsilon$-greedy followed by exploitations; in the theoretical aspect, we\ntailor anti-concentration inequalities and matrix martingale concentration\ntechniques to derive the uniform estimation rate and asymptotic normality of\nthe estimators using dependent samples from both stages. Extensive simulation\nresults demonstrate that our method outperforms state-of-the-art strategies. We\napply the proposed framework to analyze the human preference data for ranking\nlarge language models on the Massive Multitask Language Understanding dataset,\nyielding insightful results on the performance of different large language\nmodels for medical anatomy knowledge.", "published": "2025-04-27 19:59:11", "link": "http://arxiv.org/abs/2504.19342v2", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Enhancing Speech-to-Speech Dialogue Modeling with End-to-End Retrieval-Augmented Generation", "abstract": "In recent years, end-to-end speech-to-speech (S2S) dialogue systems have\ngarnered increasing research attention due to their advantages over traditional\ncascaded systems, including achieving lower latency and more natural\nintegration of nonverbal cues such as emotion and speaker identity. However,\nthese end-to-end systems face key challenges, particularly in incorporating\nexternal knowledge, a capability commonly addressed by Retrieval-Augmented\nGeneration (RAG) in text-based large language models (LLMs). The core\ndifficulty lies in the modality gap between input speech and retrieved textual\nknowledge, which hinders effective integration. To address this issue, we\npropose a novel end-to-end RAG framework that directly retrieves relevant\ntextual knowledge from speech queries, eliminating the need for intermediate\nspeech-to-text conversion via techniques like ASR. Experimental results\ndemonstrate that our method significantly improves the performance of\nend-to-end S2S dialogue systems while achieving higher retrieval efficiency.\nAlthough the overall performance still lags behind cascaded models, our\nframework offers a promising direction for enhancing knowledge integration in\nend-to-end S2S systems. We will release the code and dataset to support\nreproducibility and promote further research in this area.", "published": "2025-04-27 14:35:24", "link": "http://arxiv.org/abs/2505.00028v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Fast and Robust: Task Sampling with Posterior and Diversity Synergies for Adaptive Decision-Makers in Randomized Environments", "abstract": "Task robust adaptation is a long-standing pursuit in sequential\ndecision-making. Some risk-averse strategies, e.g., the conditional\nvalue-at-risk principle, are incorporated in domain randomization or meta\nreinforcement learning to prioritize difficult tasks in optimization, which\ndemand costly intensive evaluations. The efficiency issue prompts the\ndevelopment of robust active task sampling to train adaptive policies, where\nrisk-predictive models are used to surrogate policy evaluation. This work\ncharacterizes the optimization pipeline of robust active task sampling as a\nMarkov decision process, posits theoretical and practical insights, and\nconstitutes robustness concepts in risk-averse scenarios. Importantly, we\npropose an easy-to-implement method, referred to as Posterior and Diversity\nSynergized Task Sampling (PDTS), to accommodate fast and robust sequential\ndecision-making. Extensive experiments show that PDTS unlocks the potential of\nrobust active task sampling, significantly improves the zero-shot and few-shot\nadaptation robustness in challenging tasks, and even accelerates the learning\nprocess under certain scenarios. Our project website is at\nhttps://thu-rllab.github.io/PDTS_project_page.", "published": "2025-04-27 07:27:17", "link": "http://arxiv.org/abs/2504.19139v2", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Evaluation of Coordination Strategies for Underground Automated Vehicle Fleets in Mixed Traffic", "abstract": "This study investigates the efficiency and safety outcomes of implementing\ndifferent adaptive coordination models for automated vehicle (AV) fleets,\nmanaged by a centralized coordinator that dynamically responds to\nhuman-controlled vehicle behavior. The simulated scenarios replicate an\nunderground mining environment characterized by narrow tunnels with limited\nconnectivity. To address the unique challenges of such settings, we propose a\nnovel metric - Path Overlap Density (POD) - to predict efficiency and\npotentially the safety performance of AV fleets. The study also explores the\nimpact of map features on AV fleets performance. The results demonstrate that\nboth AV fleet coordination strategies and underground tunnel network\ncharacteristics significantly influence overall system performance. While map\nfeatures are critical for optimizing efficiency, adaptive coordination\nstrategies are essential for ensuring safe operations.", "published": "2025-04-27 16:22:55", "link": "http://arxiv.org/abs/2505.02842v1", "categories": ["physics.soc-ph", "cs.HC", "cs.MA", "cs.RO", "cs.SY", "eess.SY", "I.2.9; I.2.11; H.1.2"], "primary_category": "physics.soc-ph"}
