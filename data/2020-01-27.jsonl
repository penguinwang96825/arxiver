{"title": "Towards Quantifying the Distance between Opinions", "abstract": "Increasingly, critical decisions in public policy, governance, and business\nstrategy rely on a deeper understanding of the needs and opinions of\nconstituent members (e.g. citizens, shareholders). While it has become easier\nto collect a large number of opinions on a topic, there is a necessity for\nautomated tools to help navigate the space of opinions. In such contexts\nunderstanding and quantifying the similarity between opinions is key. We find\nthat measures based solely on text similarity or on overall sentiment often\nfail to effectively capture the distance between opinions. Thus, we propose a\nnew distance measure for capturing the similarity between opinions that\nleverages the nuanced observation -- similar opinions express similar sentiment\npolarity on specific relevant entities-of-interest. Specifically, in an\nunsupervised setting, our distance measure achieves significantly better\nAdjusted Rand Index scores (up to 56x) and Silhouette coefficients (up to 21x)\ncompared to existing approaches. Similarly, in a supervised setting, our\nopinion distance measure achieves considerably better accuracy (up to 20%\nincrease) compared to extant approaches that rely on text similarity, stance\nsimilarity, and sentiment similarity", "published": "2020-01-27 16:01:10", "link": "http://arxiv.org/abs/2001.09879v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PMIndia -- A Collection of Parallel Corpora of Languages of India", "abstract": "Parallel text is required for building high-quality machine translation (MT)\nsystems, as well as for other multilingual NLP applications. For many South\nAsian languages, such data is in short supply. In this paper, we described a\nnew publicly available corpus (PMIndia) consisting of parallel sentences which\npair 13 major languages of India with English. The corpus includes up to 56000\nsentences for each language pair. We explain how the corpus was constructed,\nincluding an assessment of two different automatic sentence alignment methods,\nand present some initial NMT results on the corpus.", "published": "2020-01-27 16:51:39", "link": "http://arxiv.org/abs/2001.09907v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Guiding Corpus-based Set Expansion by Auxiliary Sets Generation and\n  Co-Expansion", "abstract": "Given a small set of seed entities (e.g., ``USA'', ``Russia''), corpus-based\nset expansion is to induce an extensive set of entities which share the same\nsemantic class (Country in this example) from a given corpus. Set expansion\nbenefits a wide range of downstream applications in knowledge discovery, such\nas web search, taxonomy construction, and query suggestion. Existing\ncorpus-based set expansion algorithms typically bootstrap the given seeds by\nincorporating lexical patterns and distributional similarity. However, due to\nno negative sets provided explicitly, these methods suffer from semantic drift\ncaused by expanding the seed set freely without guidance. We propose a new\nframework, Set-CoExpan, that automatically generates auxiliary sets as negative\nsets that are closely related to the target set of user's interest, and then\nperforms multiple sets co-expansion that extracts discriminative features by\ncomparing target set with auxiliary sets, to form multiple cohesive sets that\nare distinctive from one another, thus resolving the semantic drift issue. In\nthis paper we demonstrate that by generating auxiliary sets, we can guide the\nexpansion process of target set to avoid touching those ambiguous areas around\nthe border with auxiliary sets, and we show that Set-CoExpan outperforms strong\nbaseline methods significantly.", "published": "2020-01-27 22:34:07", "link": "http://arxiv.org/abs/2001.10106v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SemClinBr -- a multi institutional and multi specialty semantically\n  annotated corpus for Portuguese clinical NLP tasks", "abstract": "The high volume of research focusing on extracting patient's information from\nelectronic health records (EHR) has led to an increase in the demand for\nannotated corpora, which are a very valuable resource for both the development\nand evaluation of natural language processing (NLP) algorithms. The absence of\na multi-purpose clinical corpus outside the scope of the English language,\nespecially in Brazilian Portuguese, is glaring and severely impacts scientific\nprogress in the biomedical NLP field. In this study, we developed a\nsemantically annotated corpus using clinical texts from multiple medical\nspecialties, document types, and institutions. We present the following: (1) a\nsurvey listing common aspects and lessons learned from previous research, (2) a\nfine-grained annotation schema which could be replicated and guide other\nannotation initiatives, (3) a web-based annotation tool focusing on an\nannotation suggestion feature, and (4) both intrinsic and extrinsic evaluation\nof the annotations. The result of this work is the SemClinBr, a corpus that has\n1,000 clinical notes, labeled with 65,117 entities and 11,263 relations, and\ncan support a variety of clinical NLP tasks and boost the EHR's secondary use\nfor the Portuguese language.", "published": "2020-01-27 20:39:32", "link": "http://arxiv.org/abs/2001.10071v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Asking Questions the Human Way: Scalable Question-Answer Generation from\n  Text Corpus", "abstract": "The ability to ask questions is important in both human and machine\nintelligence. Learning to ask questions helps knowledge acquisition, improves\nquestion-answering and machine reading comprehension tasks, and helps a chatbot\nto keep the conversation flowing with a human. Existing question generation\nmodels are ineffective at generating a large amount of high-quality\nquestion-answer pairs from unstructured text, since given an answer and an\ninput passage, question generation is inherently a one-to-many mapping. In this\npaper, we propose Answer-Clue-Style-aware Question Generation (ACS-QG), which\naims at automatically generating high-quality and diverse question-answer pairs\nfrom unlabeled text corpus at scale by imitating the way a human asks\nquestions. Our system consists of: i) an information extractor, which samples\nfrom the text multiple types of assistive information to guide question\ngeneration; ii) neural question generators, which generate diverse and\ncontrollable questions, leveraging the extracted assistive information; and\niii) a neural quality controller, which removes low-quality generated data\nbased on text entailment. We compare our question generation models with\nexisting approaches and resort to voluntary human evaluation to assess the\nquality of the generated question-answer pairs. The evaluation results suggest\nthat our system dramatically outperforms state-of-the-art neural question\ngeneration models in terms of the generation quality, while being scalable in\nthe meantime. With models trained on a relatively smaller amount of data, we\ncan generate 2.8 million quality-assured question-answer pairs from a million\nsentences found in Wikipedia.", "published": "2020-01-27 05:27:09", "link": "http://arxiv.org/abs/2002.00748v2", "categories": ["cs.CL", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Retrospective Reader for Machine Reading Comprehension", "abstract": "Machine reading comprehension (MRC) is an AI challenge that requires machine\nto determine the correct answers to questions based on a given passage. MRC\nsystems must not only answer question when necessary but also distinguish when\nno answer is available according to the given passage and then tactfully\nabstain from answering. When unanswerable questions are involved in the MRC\ntask, an essential verification module called verifier is especially required\nin addition to the encoder, though the latest practice on MRC modeling still\nmost benefits from adopting well pre-trained language models as the encoder\nblock by only focusing on the \"reading\". This paper devotes itself to exploring\nbetter verifier design for the MRC task with unanswerable questions. Inspired\nby how humans solve reading comprehension questions, we proposed a\nretrospective reader (Retro-Reader) that integrates two stages of reading and\nverification strategies: 1) sketchy reading that briefly investigates the\noverall interactions of passage and question, and yield an initial judgment; 2)\nintensive reading that verifies the answer and gives the final prediction. The\nproposed reader is evaluated on two benchmark MRC challenge datasets SQuAD2.0\nand NewsQA, achieving new state-of-the-art results. Significance tests show\nthat our model is significantly better than the strong ELECTRA and ALBERT\nbaselines. A series of analysis is also conducted to interpret the\neffectiveness of the proposed reader.", "published": "2020-01-27 11:14:34", "link": "http://arxiv.org/abs/2001.09694v4", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Scaling Up Online Speech Recognition Using ConvNets", "abstract": "We design an online end-to-end speech recognition system based on Time-Depth\nSeparable (TDS) convolutions and Connectionist Temporal Classification (CTC).\nWe improve the core TDS architecture in order to limit the future context and\nhence reduce latency while maintaining accuracy. The system has almost three\ntimes the throughput of a well tuned hybrid ASR baseline while also having\nlower latency and a better word error rate. Also important to the efficiency of\nthe recognizer is our highly optimized beam search decoder. To show the impact\nof our design choices, we analyze throughput, latency, accuracy, and discuss\nhow these metrics can be tuned based on the user requirements.", "published": "2020-01-27 12:55:02", "link": "http://arxiv.org/abs/2001.09727v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "What's happened in MOOC Posts Analysis, Knowledge Tracing and Peer\n  Feedbacks? A Review", "abstract": "Learning Management Systems (LMS) and Educational Data Mining (EDM) are two\nimportant parts of online educational environment with the former being a\ncentralised web-based information systems where the learning content is managed\nand learning activities are organised (Stone and Zheng,2014) and latter\nfocusing on using data mining techniques for the analysis of data so generated.\nAs part of this work, we present a literature review of three major tasks of\nEDM (See section 2), by identifying shortcomings and existing open problems,\nand a Blumenfield chart (See section 3). The consolidated set of papers and\nresources so used are released in\nhttps://github.com/manikandan-ravikiran/cs6460-Survey. The coverage statistics\nand review matrix of the survey are as shown in Figure 1 & Table 1\nrespectively. Acronym expansions are added in the Appendix Section 4.1.", "published": "2020-01-27 14:45:55", "link": "http://arxiv.org/abs/2001.09830v1", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "The POLAR Framework: Polar Opposites Enable Interpretability of\n  Pre-Trained Word Embeddings", "abstract": "We introduce POLAR - a framework that adds interpretability to pre-trained\nword embeddings via the adoption of semantic differentials. Semantic\ndifferentials are a psychometric construct for measuring the semantics of a\nword by analysing its position on a scale between two polar opposites (e.g.,\ncold -- hot, soft -- hard). The core idea of our approach is to transform\nexisting, pre-trained word embeddings via semantic differentials to a new\n\"polar\" space with interpretable dimensions defined by such polar opposites.\nOur framework also allows for selecting the most discriminative dimensions from\na set of polar dimensions provided by an oracle, i.e., an external source. We\ndemonstrate the effectiveness of our framework by deploying it to various\ndownstream tasks, in which our interpretable word embeddings achieve a\nperformance that is comparable to the original word embeddings. We also show\nthat the interpretable dimensions selected by our framework align with human\njudgement. Together, these results demonstrate that interpretability can be\nadded to word embeddings without compromising performance. Our work is relevant\nfor researchers and engineers interested in interpreting pre-trained word\nembeddings.", "published": "2020-01-27 15:58:57", "link": "http://arxiv.org/abs/2001.09876v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Towards a Human-like Open-Domain Chatbot", "abstract": "We present Meena, a multi-turn open-domain chatbot trained end-to-end on data\nmined and filtered from public domain social media conversations. This 2.6B\nparameter neural network is simply trained to minimize perplexity of the next\ntoken. We also propose a human evaluation metric called Sensibleness and\nSpecificity Average (SSA), which captures key elements of a human-like\nmulti-turn conversation. Our experiments show strong correlation between\nperplexity and SSA. The fact that the best perplexity end-to-end trained Meena\nscores high on SSA (72% on multi-turn evaluation) suggests that a human-level\nSSA of 86% is potentially within reach if we can better optimize perplexity.\nAdditionally, the full version of Meena (with a filtering mechanism and tuned\ndecoding) scores 79% SSA, 23% higher in absolute SSA than the existing chatbots\nwe evaluated.", "published": "2020-01-27 18:53:15", "link": "http://arxiv.org/abs/2001.09977v3", "categories": ["cs.CL", "cs.LG", "cs.NE", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Leveraging Schema Labels to Enhance Dataset Search", "abstract": "A search engine's ability to retrieve desirable datasets is important for\ndata sharing and reuse. Existing dataset search engines typically rely on\nmatching queries to dataset descriptions. However, a user may not have enough\nprior knowledge to write a query using terms that match with description\ntext.We propose a novel schema label generation model which generates possible\nschema labels based on dataset table content. We incorporate the generated\nschema labels into a mixed ranking model which not only considers the relevance\nbetween the query and dataset metadata but also the similarity between the\nquery and generated schema labels. To evaluate our method on real-world\ndatasets, we create a new benchmark specifically for the dataset retrieval\ntask. Experiments show that our approach can effectively improve the precision\nand NDCG scores of the dataset retrieval task compared with baseline methods.\nWe also test on a collection of Wikipedia tables to show that the features\ngenerated from schema labels can improve the unsupervised and supervised web\ntable retrieval task as well.", "published": "2020-01-27 22:41:02", "link": "http://arxiv.org/abs/2001.10112v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Systematic Review of Approaches to Improve Peer Assessment at Scale", "abstract": "Peer Assessment is a task of analysis and commenting on student's writing by\npeers, is core of all educational components both in campus and in MOOC's.\nHowever, with the sheer scale of MOOC's & its inherent personalised open ended\nlearning, automatic grading and tools assisting grading at scale is highly\nimportant. Previously we presented survey on tasks of post classification,\nknowledge tracing and ended with brief review on Peer Assessment (PA), with\nsome initial problems. In this review we shall continue review on PA from\nperspective of improving the review process itself. As such rest of this review\nfocus on three facets of PA namely Auto grading and Peer Assessment Tools (we\nshall look only on how peer reviews/auto-grading is carried), strategies to\nhandle Rogue Reviews, Peer Review Improvement using Natural Language\nProcessing. The consolidated set of papers and resources so used are released\nin https://github.com/manikandan-ravikiran/cs6460-Survey-2.", "published": "2020-01-27 15:59:24", "link": "http://arxiv.org/abs/2001.10617v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.CY"}
{"title": "Conversations with Documents. An Exploration of Document-Centered\n  Assistance", "abstract": "The role of conversational assistants has become more prevalent in helping\npeople increase their productivity. Document-centered assistance, for example\nto help an individual quickly review a document, has seen less significant\nprogress, even though it has the potential to tremendously increase a user's\nproductivity. This type of document-centered assistance is the focus of this\npaper. Our contributions are three-fold: (1) We first present a survey to\nunderstand the space of document-centered assistance and the capabilities\npeople expect in this scenario. (2) We investigate the types of queries that\nusers will pose while seeking assistance with documents, and show that\ndocument-centered questions form the majority of these queries. (3) We present\na set of initial machine learned models that show that (a) we can accurately\ndetect document-centered questions, and (b) we can build reasonably accurate\nmodels for answering such questions. These positive results are encouraging,\nand suggest that even greater results may be attained with continued study of\nthis interesting and novel problem space. Our findings have implications for\nthe design of intelligent systems to support task completion via natural\ninteractions with documents.", "published": "2020-01-27 17:10:11", "link": "http://arxiv.org/abs/2002.00747v1", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Noise dependent Super Gaussian-Coherence based dual microphone Speech\n  Enhancement for hearing aid application using smartphone", "abstract": "In this paper, the coherence between speech and noise signals is used to\nobtain a Speech Enhancement (SE) gain function, in combination with a Super\nGaussian Joint Maximum a Posteriori (SGJMAP) single microphone SE gain\nfunction. The proposed SE method can be implemented on a smartphone that works\nas an assistive device to hearing aids. Although coherence SE gain function\nsuppresses the background noise well, it distorts the speech. In contrary, SE\nusing SGJMAP improves speech quality with additional musical noise, which we\ncontain by using a post filter. The weighted union of these two gain functions\nstrikes a balance between noise suppression and speech distortion. A\n'weighting' parameter is introduced in the derived gain function to allow the\nsmartphone user to control the weighting factor based on different background\nnoise and their comfort level of hearing. Objective and subjective measures of\nthe proposed method show effective improvement in comparison to standard\ntechniques considered in this paper for several noisy conditions at signal to\nnoise ratio levels of -5 dB, 0 dB and 5 dB.", "published": "2020-01-27 03:13:21", "link": "http://arxiv.org/abs/2001.09571v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Phase-Aware Speech Enhancement with a Recurrent Two Stage Net work", "abstract": "We propose a neural network-based speech enhancement (SE) method called the\nphase-aware recurrent two stage network (rTSN). The rTSN is an extension of our\npreviously proposed two stage network (TSN) framework. This TSN framework was\nequipped with a boosting strategy (BS) that initially estimates the multiple\nbase predictions (MBPs) from a prior neural network (pri-NN) and then the MBPs\nare aggregated by a posterior neural network (post-NN) to obtain the final\nprediction. The TSN outperformed various state-of-the-art methods; however, it\nadopted the simple deep neural network as pri-NN. We have found that the pri-NN\naffects the performance (in perceptual quality), more than post-NN; therefore\nwe adopted the long short-term memory recurrent neural network (LSTM-RNN) as\npri-NN to boost the context information usage within speech signals. Further,\nthe TSN framework did not consider the phase reconstruction, though phase\ninformation affected the perceptual quality. Therefore, we proposed to adopt\nthe phase reconstruction method based on the Griffin-Lim algorithm. Finally, we\nevaluated rTSN with baselines such as TSN in perceptual quality related metrics\nas well as the phone recognition error rate.", "published": "2020-01-27 13:46:32", "link": "http://arxiv.org/abs/2001.09772v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Source coding of audio signals with a generative model", "abstract": "We consider source coding of audio signals with the help of a generative\nmodel. We use a construction where a waveform is first quantized, yielding a\nfinite bitrate representation. The waveform is then reconstructed by random\nsampling from a model conditioned on the quantized waveform. The proposed\ncoding scheme is theoretically analyzed. Using SampleRNN as the generative\nmodel, we demonstrate that the proposed coding structure provides performance\ncompetitive with state-of-the-art source coding tools for specific categories\nof audio signals.", "published": "2020-01-27 15:09:58", "link": "http://arxiv.org/abs/2001.09847v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Audio Codec Enhancement with Generative Adversarial Networks", "abstract": "Audio codecs are typically transform-domain based and efficiently code\nstationary audio signals, but they struggle with speech and signals containing\ndense transient events such as applause. Specifically, with these two classes\nof signals as examples, we demonstrate a technique for restoring audio from\ncoding noise based on generative adversarial networks (GAN). A primary\nadvantage of the proposed GAN-based coded audio enhancer is that the method\noperates end-to-end directly on decoded audio samples, eliminating the need to\ndesign any manually-crafted frontend. Furthermore, the enhancement approach\ndescribed in this paper can improve the sound quality of low-bit rate coded\naudio without any modifications to the existent standard-compliant encoders.\nSubjective tests illustrate that the proposed enhancer improves the quality of\nspeech and difficult to code applause excerpts significantly.", "published": "2020-01-27 09:50:36", "link": "http://arxiv.org/abs/2001.09653v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Frame-based overlapping speech detection using Convolutional Neural\n  Networks", "abstract": "Naturalistic speech recordings usually contain speech signals from multiple\nspeakers. This phenomenon can degrade the performance of speech technologies\ndue to the complexity of tracing and recognizing individual speakers. In this\nstudy, we investigate the detection of overlapping speech on segments as short\nas 25 ms using Convolutional Neural Networks. We evaluate the detection\nperformance using different spectral features, and show that pyknogram features\noutperforms other commonly used speech features. The proposed system can\npredict overlapping speech with an accuracy of 84\\% and Fscore of 88\\% on a\ndataset of mixed speech generated based on the GRID dataset.", "published": "2020-01-27 17:56:43", "link": "http://arxiv.org/abs/2001.09937v2", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "An Ontology-Aware Framework for Audio Event Classification", "abstract": "Recent advancements in audio event classification often ignore the structure\nand relation between the label classes available as prior information. This\nstructure can be defined by ontology and augmented in the classifier as a form\nof domain knowledge. To capture such dependencies between the labels, we\npropose an ontology-aware neural network containing two components:\nfeed-forward ontology layers and graph convolutional networks (GCN). The\nfeed-forward ontology layers capture the intra-dependencies of labels between\ndifferent levels of ontology. On the other hand, GCN mainly models\ninter-dependency structure of labels within an ontology level. The framework is\nevaluated on two benchmark datasets for single-label and multi-label audio\nevent classification tasks. The results demonstrate the proposed solutions\nefficacy to capture and explore the ontology relations and improve the\nclassification performance.", "published": "2020-01-27 20:07:39", "link": "http://arxiv.org/abs/2001.10048v1", "categories": ["cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.AI"}
{"title": "Submodular Rank Aggregation on Score-based Permutations for Distributed\n  Automatic Speech Recognition", "abstract": "Distributed automatic speech recognition (ASR) requires to aggregate outputs\nof distributed deep neural network (DNN)-based models. This work studies the\nuse of submodular functions to design a rank aggregation on score-based\npermutations, which can be used for distributed ASR systems in both supervised\nand unsupervised modes. Specifically, we compose an aggregation rank function\nbased on the Lovasz Bregman divergence for setting up linear structured convex\nand nested structured concave functions. The algorithm is based on stochastic\ngradient descent (SGD) and can obtain well-trained aggregation models. Our\nexperiments on the distributed ASR system show that the submodular rank\naggregation can obtain higher speech recognition accuracy than traditional\naggregation methods like Adaboost. Code is available\nonline~\\footnote{https://github.com/uwjunqi/Subrank}.", "published": "2020-01-27 19:46:41", "link": "http://arxiv.org/abs/2001.10529v1", "categories": ["eess.AS", "cs.LG", "cs.NE", "cs.SD"], "primary_category": "eess.AS"}
