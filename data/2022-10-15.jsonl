{"title": "Temporal Word Meaning Disambiguation using TimeLMs", "abstract": "Meaning of words constantly changes given the events in modern civilization.\nLarge Language Models use word embeddings, which are often static and thus\ncannot cope with this semantic change. Thus,it is important to resolve\nambiguity in word meanings. This paper is an effort in this direction, where we\nexplore methods for word sense disambiguation for the EvoNLP shared task. We\nconduct rigorous ablations for two solutions to this problem. We see that an\napproach using time-aware language models helps this task. Furthermore, we\nexplore possible future directions to this problem.", "published": "2022-10-15 06:34:59", "link": "http://arxiv.org/abs/2210.08207v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Models for Multi-label Propaganda Detection", "abstract": "The spread of propaganda through the internet has increased drastically over\nthe past years. Lately, propaganda detection has started gaining importance\nbecause of the negative impact it has on society. In this work, we describe our\napproach for the WANLP 2022 shared task which handles the task of propaganda\ndetection in a multi-label setting. The task demands the model to label the\ngiven text as having one or more types of propaganda techniques. There are a\ntotal of 21 propaganda techniques to be detected. We show that an ensemble of\nfive models performs the best on the task, scoring a micro-F1 score of 59.73%.\nWe also conduct comprehensive ablations and propose various future directions\nfor this work.", "published": "2022-10-15 06:47:31", "link": "http://arxiv.org/abs/2210.08209v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RAPS: A Novel Few-Shot Relation Extraction Pipeline with\n  Query-Information Guided Attention and Adaptive Prototype Fusion", "abstract": "Few-shot relation extraction (FSRE) aims at recognizing unseen relations by\nlearning with merely a handful of annotated instances. To generalize to new\nrelations more effectively, this paper proposes a novel pipeline for the FSRE\ntask based on queRy-information guided Attention and adaptive Prototype fuSion,\nnamely RAPS. Specifically, RAPS first derives the relation prototype by the\nquery-information guided attention module, which exploits rich interactive\ninformation between the support instances and the query instances, in order to\nobtain more accurate initial prototype representations. Then RAPS elaborately\ncombines the derived initial prototype with the relation information by the\nadaptive prototype fusion mechanism to get the integrated prototype for both\ntrain and prediction. Experiments on the benchmark dataset FewRel 1.0 show a\nsignificant improvement of our method against state-of-the-art methods.", "published": "2022-10-15 09:44:21", "link": "http://arxiv.org/abs/2210.08242v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UniRPG: Unified Discrete Reasoning over Table and Text as Program\n  Generation", "abstract": "Question answering requiring discrete reasoning, e.g., arithmetic computing,\ncomparison, and counting, over knowledge is a challenging task. In this paper,\nwe propose UniRPG, a semantic-parsing-based approach advanced in\ninterpretability and scalability, to perform unified discrete reasoning over\nheterogeneous knowledge resources, i.e., table and text, as program generation.\nConcretely, UniRPG consists of a neural programmer and a symbolic program\nexecutor, where a program is the composition of a set of pre-defined general\natomic and higher-order operations and arguments extracted from table and text.\nFirst, the programmer parses a question into a program by generating operations\nand copying arguments, and then the executor derives answers from table and\ntext based on the program. To alleviate the costly program annotation issue, we\ndesign a distant supervision approach for programmer learning, where pseudo\nprograms are automatically constructed without annotated derivations. Extensive\nexperiments on the TAT-QA dataset show that UniRPG achieves tremendous\nimprovements and enhances interpretability and scalability compared with\nstate-of-the-art methods, even without derivation annotation. Moreover, it\nachieves promising performance on the textual dataset DROP without derivations.", "published": "2022-10-15 10:17:52", "link": "http://arxiv.org/abs/2210.08249v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AraLegal-BERT: A pretrained language model for Arabic Legal text", "abstract": "The effectiveness of the BERT model on multiple linguistic tasks has been\nwell documented. On the other hand, its potentials for narrow and specific\ndomains such as Legal, have not been fully explored. In this paper, we examine\nhow BERT can be used in the Arabic legal domain and try customizing this\nlanguage model for several downstream tasks using several different\ndomain-relevant training and testing datasets to train BERT from scratch. We\nintroduce the AraLegal-BERT, a bidirectional encoder Transformer-based model\nthat have been thoroughly tested and carefully optimized with the goal to\namplify the impact of NLP-driven solution concerning jurisprudence, legal\ndocuments, and legal practice. We fine-tuned AraLegal-BERT and evaluated it\nagainst three BERT variations for Arabic language in three natural languages\nunderstanding (NLU) tasks. The results show that the base version of\nAraLegal-BERT achieve better accuracy than the general and original BERT over\nthe Legal text.", "published": "2022-10-15 13:08:40", "link": "http://arxiv.org/abs/2210.08284v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Construction Repetition Reduces Information Rate in Dialogue", "abstract": "Speakers repeat constructions frequently in dialogue. Due to their peculiar\ninformation-theoretic properties, repetitions can be thought of as a strategy\nfor cost-effective communication. In this study, we focus on the repetition of\nlexicalised constructions -- i.e., recurring multi-word units -- in English\nopen-domain spoken dialogues. We hypothesise that speakers use construction\nrepetition to mitigate information rate, leading to an overall decrease in\nutterance information content over the course of a dialogue. We conduct a\nquantitative analysis, measuring the information content of constructions and\nthat of their containing utterances, estimating information content with an\nadaptive neural language model. We observe that construction usage lowers the\ninformation content of utterances. This facilitating effect (i) increases\nthroughout dialogues, (ii) is boosted by repetition, (iii) grows as a function\nof repetition frequency and density, and (iv) is stronger for repetitions of\nreferential constructions.", "published": "2022-10-15 15:44:00", "link": "http://arxiv.org/abs/2210.08321v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Simple and Strong Baseline for End-to-End Neural RST-style Discourse\n  Parsing", "abstract": "To promote and further develop RST-style discourse parsing models, we need a\nstrong baseline that can be regarded as a reference for reporting reliable\nexperimental results. This paper explores a strong baseline by integrating\nexisting simple parsing strategies, top-down and bottom-up, with various\ntransformer-based pre-trained language models. The experimental results\nobtained from two benchmark datasets demonstrate that the parsing performance\nstrongly relies on the pretrained language models rather than the parsing\nstrategies. In particular, the bottom-up parser achieves large performance\ngains compared to the current best parser when employing DeBERTa. We further\nreveal that language models with a span-masking scheme especially boost the\nparsing performance through our analysis within intra- and multi-sentential\nparsing, and nuclearity prediction.", "published": "2022-10-15 18:38:08", "link": "http://arxiv.org/abs/2210.08355v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PAR: Political Actor Representation Learning with Social Context and\n  Expert Knowledge", "abstract": "Modeling the ideological perspectives of political actors is an essential\ntask in computational political science with applications in many downstream\ntasks. Existing approaches are generally limited to textual data and voting\nrecords, while they neglect the rich social context and valuable expert\nknowledge for holistic ideological analysis. In this paper, we propose\n\\textbf{PAR}, a \\textbf{P}olitical \\textbf{A}ctor \\textbf{R}epresentation\nlearning framework that jointly leverages social context and expert knowledge.\nSpecifically, we retrieve and extract factual statements about legislators to\nleverage social context information. We then construct a heterogeneous\ninformation network to incorporate social context and use relational graph\nneural networks to learn legislator representations. Finally, we train PAR with\nthree objectives to align representation learning with expert knowledge, model\nideological stance consistency, and simulate the echo chamber phenomenon.\nExtensive experiments demonstrate that PAR is better at augmenting political\ntext understanding and successfully advances the state-of-the-art in political\nperspective detection and roll call vote prediction. Further analysis proves\nthat PAR learns representations that reflect the political reality and provide\nnew insights into political behavior.", "published": "2022-10-15 19:28:06", "link": "http://arxiv.org/abs/2210.08362v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generating Synthetic Speech from SpokenVocab for Speech Translation", "abstract": "Training end-to-end speech translation (ST) systems requires sufficiently\nlarge-scale data, which is unavailable for most language pairs and domains. One\npractical solution to the data scarcity issue is to convert machine translation\ndata (MT) to ST data via text-to-speech (TTS) systems. Yet, using TTS systems\ncan be tedious and slow, as the conversion needs to be done for each MT\ndataset. In this work, we propose a simple, scalable and effective data\naugmentation technique, i.e., SpokenVocab, to convert MT data to ST data\non-the-fly. The idea is to retrieve and stitch audio snippets from a\nSpokenVocab bank according to words in an MT sequence. Our experiments on\nmultiple language pairs from Must-C show that this method outperforms strong\nbaselines by an average of 1.83 BLEU scores, and it performs equally well as\nTTS-generated speech. We also showcase how SpokenVocab can be applied in\ncode-switching ST for which often no TTS systems exit. Our code is available at\nhttps://github.com/mingzi151/SpokenVocab", "published": "2022-10-15 03:07:44", "link": "http://arxiv.org/abs/2210.08174v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Combination Of Convolution Neural Networks And Deep Neural Networks For\n  Fake News Detection", "abstract": "Nowadays, People prefer to follow the latest news on social media, as it is\ncheap, easily accessible, and quickly disseminated. However, it can spread fake\nor unreliable, low-quality news that intentionally contains false information.\nThe spread of fake news can have a negative effect on people and society. Given\nthe seriousness of such a problem, researchers did their best to identify\npatterns and characteristics that fake news may exhibit to design a system that\ncan detect fake news before publishing. In this paper, we have described the\nFake News Challenge stage #1 (FNC-1) dataset and given an overview of the\ncompetitive attempts to build a fake news detection system using the FNC-1\ndataset. The proposed model was evaluated with the FNC-1 dataset. A competitive\ndataset is considered an open problem and a challenge worldwide. This system's\nprocedure implies processing the text in the headline and body text columns\nwith different natural language processing techniques. After that, the\nextracted features are reduced using the elbow truncated method, finding the\nsimilarity between each pair using the soft cosine similarity method. The new\nfeature is entered into CNN and DNN deep learning approaches. The proposed\nsystem detects all the categories with high accuracy except the disagree\ncategory. As a result, the system achieves up to 84.6 % accuracy, classifying\nit as the second ranking based on other competitive studies regarding this\ndataset.", "published": "2022-10-15 16:32:51", "link": "http://arxiv.org/abs/2210.08331v1", "categories": ["cs.IR", "cs.CL", "68P20"], "primary_category": "cs.IR"}
{"title": "Revisiting the Roles of \"Text\" in Text Games", "abstract": "Text games present opportunities for natural language understanding (NLU)\nmethods to tackle reinforcement learning (RL) challenges. However, recent work\nhas questioned the necessity of NLU by showing random text hashes could perform\ndecently. In this paper, we pursue a fine-grained investigation into the roles\nof text in the face of different RL challenges, and reconcile that semantic and\nnon-semantic language representations could be complementary rather than\ncontrasting. Concretely, we propose a simple scheme to extract relevant\ncontextual information into an approximate state hash as extra input for an\nRNN-based text agent. Such a lightweight plug-in achieves competitive\nperformance with state-of-the-art text agents using advanced NLU techniques\nsuch as knowledge graph and passage retrieval, suggesting non-NLU methods might\nsuffice to tackle the challenge of partial observability. However, if we remove\nRNN encoders and use approximate or even ground-truth state hash alone, the\nmodel performs miserably, which confirms the importance of semantic function\napproximation to tackle the challenge of combinatorially large observation and\naction spaces. Our findings and analysis provide new insights for designing\nbetter text game task setups and agents.", "published": "2022-10-15 21:52:39", "link": "http://arxiv.org/abs/2210.08384v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning Invariant Representation and Risk Minimized for Unsupervised\n  Accent Domain Adaptation", "abstract": "Unsupervised representation learning for speech audios attained impressive\nperformances for speech recognition tasks, particularly when annotated speech\nis limited. However, the unsupervised paradigm needs to be carefully designed\nand little is known about what properties these representations acquire. There\nis no guarantee that the model learns meaningful representations for valuable\ninformation for recognition. Moreover, the adaptation ability of the learned\nrepresentations to other domains still needs to be estimated. In this work, we\nexplore learning domain-invariant representations via a direct mapping of\nspeech representations to their corresponding high-level linguistic\ninformations. Results prove that the learned latents not only capture the\narticulatory feature of each phoneme but also enhance the adaptation ability,\noutperforming the baseline largely on accented benchmarks.", "published": "2022-10-15 03:56:31", "link": "http://arxiv.org/abs/2210.08182v2", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Improving Radiology Summarization with Radiograph and Anatomy Prompts", "abstract": "The impression is crucial for the referring physicians to grasp key\ninformation since it is concluded from the findings and reasoning of\nradiologists. To alleviate the workload of radiologists and reduce repetitive\nhuman labor in impression writing, many researchers have focused on automatic\nimpression generation. However, recent works on this task mainly summarize the\ncorresponding findings and pay less attention to the radiology images. In\nclinical, radiographs can provide more detailed valuable observations to\nenhance radiologists' impression writing, especially for complicated cases.\nBesides, each sentence in findings usually focuses on single anatomy, so they\nonly need to be matched to corresponding anatomical regions instead of the\nwhole image, which is beneficial for textual and visual features alignment.\nTherefore, we propose a novel anatomy-enhanced multimodal model to promote\nimpression generation. In detail, we first construct a set of rules to extract\nanatomies and put these prompts into each sentence to highlight anatomy\ncharacteristics. Then, two separate encoders are applied to extract features\nfrom the radiograph and findings. Afterward, we utilize a contrastive learning\nmodule to align these two representations at the overall level and use a\nco-attention to fuse them at the sentence level with the help of\nanatomy-enhanced sentence representation. Finally, the decoder takes the fused\ninformation as the input to generate impressions. The experimental results on\ntwo benchmark datasets confirm the effectiveness of the proposed method, which\nachieves state-of-the-art results.", "published": "2022-10-15 14:05:03", "link": "http://arxiv.org/abs/2210.08303v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Extracting speaker and emotion information from self-supervised speech\n  models via channel-wise correlations", "abstract": "Self-supervised learning of speech representations from large amounts of\nunlabeled data has enabled state-of-the-art results in several speech\nprocessing tasks. Aggregating these speech representations across time is\ntypically approached by using descriptive statistics, and in particular, using\nthe first- and second-order statistics of representation coefficients. In this\npaper, we examine an alternative way of extracting speaker and emotion\ninformation from self-supervised trained models, based on the correlations\nbetween the coefficients of the representations - correlation pooling. We show\nimprovements over mean pooling and further gains when the pooling methods are\ncombined via fusion. The code is available at\ngithub.com/Lamomal/s3prl_correlation.", "published": "2022-10-15 04:15:50", "link": "http://arxiv.org/abs/2210.09513v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
