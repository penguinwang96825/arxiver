{"title": "Swift Cross-Dataset Pruning: Enhancing Fine-Tuning Efficiency in Natural\n  Language Understanding", "abstract": "Dataset pruning aims to select a subset of a dataset for efficient model\ntraining. While data efficiency in natural language processing has primarily\nfocused on within-corpus scenarios during model pre-training, efficient dataset\npruning for task-specific fine-tuning across diverse datasets remains\nchallenging due to variability in dataset sizes, data distributions, class\nimbalance and label spaces. Current cross-dataset pruning techniques for\nfine-tuning often rely on computationally expensive sample ranking processes,\ntypically requiring full dataset training or reference models. We address this\ngap by proposing Swift Cross-Dataset Pruning (SCDP). Specifically, our approach\nuses TF-IDF embeddings with geometric median to rapidly evaluate sample\nimportance. We then apply dataset size-adaptive pruning to ensure diversity:\nfor smaller datasets, we retain samples far from the geometric median, while\nfor larger ones, we employ distance-based stratified pruning. Experimental\nresults on six diverse datasets demonstrate the effectiveness of our method,\nspanning various tasks and scales while significantly reducing computational\nresources. Source code is available at:\nhttps://github.com/he-y/NLP-Dataset-Pruning", "published": "2025-01-05 03:52:04", "link": "http://arxiv.org/abs/2501.02432v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Multimodal Metaphor Understanding: A Chinese Dataset and Model\n  for Metaphor Mapping Identification", "abstract": "Metaphors play a crucial role in human communication, yet their comprehension\nremains a significant challenge for natural language processing (NLP) due to\nthe cognitive complexity involved. According to Conceptual Metaphor Theory\n(CMT), metaphors map a target domain onto a source domain, and understanding\nthis mapping is essential for grasping the nature of metaphors. While existing\nNLP research has focused on tasks like metaphor detection and sentiment\nanalysis of metaphorical expressions, there has been limited attention to the\nintricate process of identifying the mappings between source and target\ndomains. Moreover, non-English multimodal metaphor resources remain largely\nneglected in the literature, hindering a deeper understanding of the key\nelements involved in metaphor interpretation. To address this gap, we developed\na Chinese multimodal metaphor advertisement dataset (namely CM3D) that includes\nannotations of specific target and source domains. This dataset aims to foster\nfurther research into metaphor comprehension, particularly in non-English\nlanguages. Furthermore, we propose a Chain-of-Thought (CoT) Prompting-based\nMetaphor Mapping Identification Model (CPMMIM), which simulates the human\ncognitive process for identifying these mappings. Drawing inspiration from CoT\nreasoning and Bi-Level Optimization (BLO), we treat the task as a hierarchical\nidentification problem, enabling more accurate and interpretable metaphor\nmapping. Our experimental results demonstrate the effectiveness of CPMMIM,\nhighlighting its potential for advancing metaphor comprehension in NLP. Our\ndataset and code are both publicly available to encourage further advancements\nin this field.", "published": "2025-01-05 04:15:03", "link": "http://arxiv.org/abs/2501.02434v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Understand, Solve and Translate: Bridging the Multilingual Mathematical\n  Reasoning Gap", "abstract": "Large language models (LLMs) demonstrate exceptional performance on complex\nreasoning tasks. However, despite their strong reasoning capabilities in\nhigh-resource languages (e.g., English and Chinese), a significant performance\ngap persists in other languages. To investigate this gap in Korean, we\nintroduce HRM8K, a benchmark comprising 8,011 English-Korean parallel bilingual\nmath problems. Through systematic analysis of model behaviors, we identify a\nkey finding: these performance disparities stem primarily from difficulties in\ncomprehending non-English inputs, rather than limitations in reasoning\ncapabilities. Based on these findings, we propose UST (Understand, Solve, and\nTranslate), a method that strategically uses English as an anchor for reasoning\nand solution generation. By fine-tuning the model on 130k synthetically\ngenerated data points, UST achieves a 10.91% improvement on the HRM8K benchmark\nand reduces the multilingual performance gap from 11.6% to 0.7%. Additionally,\nwe show that improvements from UST generalize effectively to different Korean\ndomains, demonstrating that capabilities acquired from machine-verifiable\ncontent can be generalized to other areas. We publicly release the benchmark,\ntraining dataset, and models.", "published": "2025-01-05 05:57:22", "link": "http://arxiv.org/abs/2501.02448v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Omni-RAG: Comprehensive Retrieval-Augmented Generation for Large\n  Language Models in Medical Applications", "abstract": "Large language models hold promise for addressing medical challenges, such as\nmedical diagnosis reasoning, research knowledge acquisition, clinical\ndecision-making, and consumer health inquiry support. However, they often\ngenerate hallucinations due to limited medical knowledge. Incorporating\nexternal knowledge is therefore critical, which necessitates multi-source\nknowledge acquisition. We address this challenge by framing it as a source\nplanning problem, which is to formulate context-appropriate queries tailored to\nthe attributes of diverse sources. Existing approaches either overlook source\nplanning or fail to achieve it effectively due to misalignment between the\nmodel's expectation of the sources and their actual content. To bridge this\ngap, we present MedOmniKB, a repository comprising multigenre and\nmulti-structured medical knowledge sources. Leveraging these sources, we\npropose the Source Planning Optimisation method, which enhances multi-source\nutilisation. Our approach involves enabling an expert model to explore and\nevaluate potential plans while training a smaller model to learn source\nalignment. Experimental results demonstrate that our method substantially\nimproves multi-source planning performance, enabling the optimised small model\nto achieve state-of-the-art results in leveraging diverse medical knowledge\nsources.", "published": "2025-01-05 07:03:14", "link": "http://arxiv.org/abs/2501.02460v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Decoding News Bias: Multi Bias Detection in News Articles", "abstract": "News Articles provides crucial information about various events happening in\nthe society but they unfortunately come with different kind of biases. These\nbiases can significantly distort public opinion and trust in the media, making\nit essential to develop techniques to detect and address them. Previous works\nhave majorly worked towards identifying biases in particular domains e.g.,\nPolitical, gender biases. However, more comprehensive studies are needed to\ndetect biases across diverse domains. Large language models (LLMs) offer a\npowerful way to analyze and understand natural language, making them ideal for\nconstructing datasets and detecting these biases. In this work, we have\nexplored various biases present in the news articles, built a dataset using\nLLMs and present results obtained using multiple detection techniques. Our\napproach highlights the importance of broad-spectrum bias detection and offers\nnew insights for improving the integrity of news articles.", "published": "2025-01-05 09:09:53", "link": "http://arxiv.org/abs/2501.02482v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ToolHop: A Query-Driven Benchmark for Evaluating Large Language Models\n  in Multi-Hop Tool Use", "abstract": "Effective evaluation of multi-hop tool use is critical for analyzing the\nunderstanding, reasoning, and function-calling capabilities of large language\nmodels (LLMs). However, progress has been hindered by a lack of reliable\nevaluation datasets. To address this, we present ToolHop, a dataset comprising\n995 user queries and 3,912 associated tools, specifically designed for rigorous\nevaluation of multi-hop tool use. ToolHop ensures diverse queries, meaningful\ninterdependencies, locally executable tools, detailed feedback, and verifiable\nanswers through a novel query-driven data construction approach that includes\ntool creation, document refinement, and code generation. We evaluate 14 LLMs\nacross five model families (i.e., LLaMA3.1, Qwen2.5, Gemini1.5, Claude3.5, and\nGPT), uncovering significant challenges in handling multi-hop tool-use\nscenarios. The leading model, GPT-4o, achieves an accuracy of 49.04%,\nunderscoring substantial room for improvement. Further analysis reveals\nvariations in tool-use strategies for various families, offering actionable\ninsights to guide the development of more effective approaches. Code and data\ncan be found in https://huggingface.co/datasets/bytedance-research/ToolHop.", "published": "2025-01-05 11:06:55", "link": "http://arxiv.org/abs/2501.02506v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CHAIR -- Classifier of Hallucination as Improver", "abstract": "In this work, we introduce CHAIR (Classifier of Hallucination As ImproveR), a\nsupervised framework for detecting hallucinations by analyzing internal logits\nfrom each layer of every token. Our method extracts a compact set of features\nsuch as maximum, minimum, mean, standard deviation, and slope-from the token\nlogits across all layers, enabling effective hallucination detection without\noverfitting. Experiments on TruthfulQA and MMLU datasets demonstrate that CHAIR\nsignificantly improves detection accuracy, particularly in zero-shot scenarios,\nshowcasing its robustness and generalizability. Beyond hallucination detection,\nCHAIR highlights the potential of using internal representations for designing\nadvanced decoding strategies. By leveraging patterns in logits, we suggest that\nmore sophisticated models and adaptive decoding methods could further reduce\nhallucinations and enhance text completion quality. CHAIR not only offers a\npractical solution for detecting hallucinations but also lays the groundwork\nfor exploring richer representations in LLMs to improve their factuality and\ncoherence.", "published": "2025-01-05 12:15:02", "link": "http://arxiv.org/abs/2501.02518v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Language To Vision: A Case Study of Text Animation", "abstract": "Information can be expressed in multiple formats including natural language,\nimages, and motions. Human intelligence usually faces little difficulty to\nconvert from one format to another format, which often shows a true\nunderstanding of encoded information. Moreover, such conversions have broad\napplication in many real-world applications. In this paper, we present a text\nvisualization system that can visualize free text with animations. Our system\nis illustrated by visualizing example sentences of elementary Physics laws.", "published": "2025-01-05 14:00:28", "link": "http://arxiv.org/abs/2501.02549v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prune or Retrain: Optimizing the Vocabulary of Multilingual Models for\n  Estonian", "abstract": "Adapting multilingual language models to specific languages can enhance both\ntheir efficiency and performance. In this study, we explore how modifying the\nvocabulary of a multilingual encoder model to better suit the Estonian language\naffects its downstream performance on the Named Entity Recognition (NER) task.\nThe motivations for adjusting the vocabulary are twofold: practical benefits\naffecting the computational cost, such as reducing the input sequence length\nand the model size, and performance enhancements by tailoring the vocabulary to\nthe particular language. We evaluate the effectiveness of two vocabulary\nadaptation approaches -- retraining the tokenizer and pruning unused tokens --\nand assess their impact on the model's performance, particularly after\ncontinual training. While retraining the tokenizer degraded the performance of\nthe NER task, suggesting that longer embedding tuning might be needed, we\nobserved no negative effects on pruning.", "published": "2025-01-05 19:21:45", "link": "http://arxiv.org/abs/2501.02631v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Flash Interpretability: Decoding Specialised Feature Neurons in Large\n  Language Models with the LM-Head", "abstract": "Large Language Models (LLMs) typically have billions of parameters and are\nthus often difficult to interpret in their operation. In this work, we\ndemonstrate that it is possible to decode neuron weights directly into token\nprobabilities through the final projection layer of the model (the LM-head).\nThis is illustrated in Llama 3.1 8B where we use the LM-head to find examples\nof specialised feature neurons such as a \"dog\" neuron and a \"California\"\nneuron, and we validate this by clamping these neurons to affect the\nprobability of the concept in the output. We evaluate this method on both the\npre-trained and Instruct models, finding that over 75% of neurons in the\nup-projection layers in the instruct model have the same top associated token\ncompared to the pretrained model. Finally, we demonstrate that clamping the\n\"dog\" neuron leads the instruct model to always discuss dogs when asked about\nits favourite animal. Through our method, it is possible to map the top\nfeatures of the entirety of Llama 3.1 8B's up-projection neurons in less than\n10 seconds, with minimal compute.", "published": "2025-01-05 23:35:47", "link": "http://arxiv.org/abs/2501.02688v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HonkaiChat: Companions from Anime that feel alive!", "abstract": "Modern conversational agents, including anime-themed chatbots, are frequently\nreactive and personality-driven but fail to capture the dynamic nature of human\ninteractions. We propose an event-driven dialogue framework to address these\nlimitations by embedding dynamic events in conversation prompts and fine-tuning\nmodels on character-specific data. Evaluations on GPT-4 and comparisons with\nindustry-leading baselines demonstrate that event-driven prompts significantly\nimprove conversational engagement and naturalness while reducing\nhallucinations. This paper explores the application of this approach in\ncreating lifelike chatbot interactions within the context of Honkai: Star Rail,\nshowcasing the potential for dynamic event-based systems to transform\nrole-playing and interactive dialogue.", "published": "2025-01-05 13:02:02", "link": "http://arxiv.org/abs/2501.03277v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LatteReview: A Multi-Agent Framework for Systematic Review Automation\n  Using Large Language Models", "abstract": "Systematic literature reviews and meta-analyses are essential for\nsynthesizing research insights, but they remain time-intensive and\nlabor-intensive due to the iterative processes of screening, evaluation, and\ndata extraction. This paper introduces and evaluates LatteReview, a\nPython-based framework that leverages large language models (LLMs) and\nmulti-agent systems to automate key elements of the systematic review process.\nDesigned to streamline workflows while maintaining rigor, LatteReview utilizes\nmodular agents for tasks such as title and abstract screening, relevance\nscoring, and structured data extraction. These agents operate within\norchestrated workflows, supporting sequential and parallel review rounds,\ndynamic decision-making, and iterative refinement based on user feedback.\nLatteReview's architecture integrates LLM providers, enabling compatibility\nwith both cloud-based and locally hosted models. The framework supports\nfeatures such as Retrieval-Augmented Generation (RAG) for incorporating\nexternal context, multimodal reviews, Pydantic-based validation for structured\ninputs and outputs, and asynchronous programming for handling large-scale\ndatasets. The framework is available on the GitHub repository, with detailed\ndocumentation and an installable package.", "published": "2025-01-05 17:53:00", "link": "http://arxiv.org/abs/2501.05468v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hengqin-RA-v1: Advanced Large Language Model for Diagnosis and Treatment\n  of Rheumatoid Arthritis with Dataset based Traditional Chinese Medicine", "abstract": "Large language models (LLMs) primarily trained on English texts, often face\nbiases and inaccuracies in Chinese contexts. Their limitations are pronounced\nin fields like Traditional Chinese Medicine (TCM), where cultural and clinical\nsubtleties are vital, further hindered by a lack of domain-specific data, such\nas rheumatoid arthritis (RA). To address these issues, this paper introduces\nHengqin-RA-v1, the first large language model specifically tailored for TCM\nwith a focus on diagnosing and treating RA. We also present HQ-GCM-RA-C1, a\ncomprehensive RA-specific dataset curated from ancient Chinese medical\nliterature, classical texts, and modern clinical studies. This dataset empowers\nHengqin-RA-v1 to deliver accurate and culturally informed responses,\neffectively bridging the gaps left by general-purpose models. Extensive\nexperiments demonstrate that Hengqin-RA-v1 outperforms state-of-the-art models,\neven surpassing the diagnostic accuracy of TCM practitioners in certain cases.", "published": "2025-01-05 07:46:51", "link": "http://arxiv.org/abs/2501.02471v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LLMPC: Large Language Model Predictive Control", "abstract": "Recent advancements in prompting techniques for Large Language Models (LLMs)\nhave improved their reasoning, planning, and action abilities. This paper\nexamines these prompting techniques through the lens of model predictive\ncontrol (MPC). We show that LLMs act as implicit planning cost function\nminimizers when planning prompts are used. We propose a unified MPC framework\nfor planning with LLMs and demonstrate improved performance over few shot\nprompting on several planning benchmarks.", "published": "2025-01-05 09:37:23", "link": "http://arxiv.org/abs/2501.02486v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Towards New Benchmark for AI Alignment & Sentiment Analysis in Socially\n  Important Issues: A Comparative Study of Human and LLMs in the Context of AGI", "abstract": "With the expansion of neural networks, such as large language models,\nhumanity is exponentially heading towards superintelligence. As various AI\nsystems are increasingly integrated into the fabric of societies-through\nrecommending values, devising creative solutions, and making decisions-it\nbecomes critical to assess how these AI systems impact humans in the long run.\nThis research aims to contribute towards establishing a benchmark for\nevaluating the sentiment of various Large Language Models in socially importan\nissues. The methodology adopted was a Likert scale survey. Seven LLMs,\nincluding GPT-4 and Bard, were analyzed and compared against sentiment data\nfrom three independent human sample populations. Temporal variations in\nsentiment were also evaluated over three consecutive days. The results\nhighlighted a diversity in sentiment scores among LLMs, ranging from 3.32 to\n4.12 out of 5. GPT-4 recorded the most positive sentiment score towards AGI,\nwhereas Bard was leaning towards the neutral sentiment. The human samples,\ncontrastingly, showed a lower average sentiment of 2.97. The temporal\ncomparison revealed differences in sentiment evolution between LLMs in three\ndays, ranging from 1.03% to 8.21%. The study's analysis outlines the prospect\nof potential conflicts of interest and bias possibilities in LLMs' sentiment\nformation. Results indicate that LLMs, akin to human cognitive processes, could\npotentially develop unique sentiments and subtly influence societies'\nperceptions towards various opinions formed within the LLMs.", "published": "2025-01-05 13:18:13", "link": "http://arxiv.org/abs/2501.02531v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "TreeMatch: A Fully Unsupervised WSD System Using Dependency Knowledge on\n  a Specific Domain", "abstract": "Word sense disambiguation (WSD) is one of the main challenges in\nComputational Linguistics. TreeMatch is a WSD system originally developed using\ndata from SemEval 2007 Task 7 (Coarse-grained English All-words Task) that has\nbeen adapted for use in SemEval 2010 Task 17 (All-words Word Sense\nDisambiguation on a Specific Domain). The system is based on a fully\nunsupervised method using dependency knowledge drawn from a domain specific\nknowledge base that was built for this task. When evaluated on the task, the\nsystem precision performs above the Most Frequent Selection baseline.", "published": "2025-01-05 13:56:04", "link": "http://arxiv.org/abs/2501.02546v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multi-LLM Collaborative Caption Generation in Scientific Documents", "abstract": "Scientific figure captioning is a complex task that requires generating\ncontextually appropriate descriptions of visual content. However, existing\nmethods often fall short by utilizing incomplete information, treating the task\nsolely as either an image-to-text or text summarization problem. This\nlimitation hinders the generation of high-quality captions that fully capture\nthe necessary details. Moreover, existing data sourced from arXiv papers\ncontain low-quality captions, posing significant challenges for training large\nlanguage models (LLMs). In this paper, we introduce a framework called\nMulti-LLM Collaborative Figure Caption Generation (MLBCAP) to address these\nchallenges by leveraging specialized LLMs for distinct sub-tasks. Our approach\nunfolds in three key modules: (Quality Assessment) We utilize multimodal LLMs\nto assess the quality of training data, enabling the filtration of low-quality\ncaptions. (Diverse Caption Generation) We then employ a strategy of\nfine-tuning/prompting multiple LLMs on the captioning task to generate\ncandidate captions. (Judgment) Lastly, we prompt a prominent LLM to select the\nhighest quality caption from the candidates, followed by refining any remaining\ninaccuracies. Human evaluations demonstrate that informative captions produced\nby our approach rank better than human-written captions, highlighting its\neffectiveness. Our code is available at https://github.com/teamreboott/MLBCAP", "published": "2025-01-05 14:09:12", "link": "http://arxiv.org/abs/2501.02552v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Tougher Text, Smarter Models: Raising the Bar for Adversarial Defence\n  Benchmarks", "abstract": "Recent advancements in natural language processing have highlighted the\nvulnerability of deep learning models to adversarial attacks. While various\ndefence mechanisms have been proposed, there is a lack of comprehensive\nbenchmarks that evaluate these defences across diverse datasets, models, and\ntasks. In this work, we address this gap by presenting an extensive benchmark\nfor textual adversarial defence that significantly expands upon previous work.\nOur benchmark incorporates a wide range of datasets, evaluates state-of-the-art\ndefence mechanisms, and extends the assessment to include critical tasks such\nas single-sentence classification, similarity and paraphrase identification,\nnatural language inference, and commonsense reasoning. This work not only\nserves as a valuable resource for researchers and practitioners in the field of\nadversarial robustness but also identifies key areas for future research in\ntextual adversarial defence. By establishing a new standard for benchmarking in\nthis domain, we aim to accelerate progress towards more robust and reliable\nnatural language processing systems.", "published": "2025-01-05 20:39:52", "link": "http://arxiv.org/abs/2501.02654v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "From Superficial Patterns to Semantic Understanding: Fine-Tuning\n  Language Models on Contrast Sets", "abstract": "Large-scale pre-trained language models have demonstrated high performance on\nstandard datasets for natural language inference (NLI) tasks. Unfortunately,\nthese evaluations can be misleading, as although the models can perform well on\nin-distribution data, they perform poorly on out-of-distribution test sets,\nsuch as contrast sets. Contrast sets consist of perturbed instances of data\nthat have very minor, but meaningful, changes to the input that alter the gold\nlabel, revealing how models can learn superficial patterns in the training data\nrather than learning more sophisticated language nuances. As an example, the\nELECTRA-small language model achieves nearly 90% accuracy on an SNLI dataset\nbut drops to 75% when tested on an out-of-distribution contrast set. The\nresearch carried out in this study explores how the robustness of a language\nmodel can be improved by exposing it to small amounts of more complex contrast\nsets during training to help it better learn language patterns. With this\napproach, the model recovers performance and achieves nearly 90% accuracy on\ncontrast sets, highlighting the importance of diverse and challenging training\ndata.", "published": "2025-01-05 23:19:55", "link": "http://arxiv.org/abs/2501.02683v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Anonymization by Design of Language Modeling", "abstract": "Rapid advances in Natural Language Processing (NLP) have revolutionized many\nfields, including healthcare. However, these advances raise significant privacy\nconcerns, especially when models specialized on sensitive data can memorize and\nthen expose and regurgitate confidential information. This paper presents a\nprivacy-by-design language modeling approach to address the problem of language\nmodels anonymization, and thus promote their sharing. Specifically, we propose\nboth a Masking Language Modeling (MLM) methodology to specialize a BERT-like\nlanguage model, and a Causal Language Modeling (CLM) methodology to specialize\na GPT-like model that avoids the model from memorizing direct and indirect\nidentifying information present in the training data. We have comprehensively\nevaluated our approaches using medical datasets and compared them against\ndifferent baselines. Our results indicate that by avoiding memorizing both\ndirect and indirect identifiers during model specialization, our masking and\ncausal language modeling schemes offer the best tradeoff for maintaining high\nprivacy while retaining high utility.", "published": "2025-01-05 00:03:18", "link": "http://arxiv.org/abs/2501.02407v1", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Scaling Laws for Floating Point Quantization Training", "abstract": "Low-precision training is considered an effective strategy for reducing both\ntraining and downstream inference costs. Previous scaling laws for precision\nmainly focus on integer quantization, which pay less attention to the\nconstituents in floating-point quantization and thus cannot well fit the LLM\nlosses in this scenario. In contrast, while floating-point quantization\ntraining is more commonly implemented in production, the research on it has\nbeen relatively superficial. In this paper, we thoroughly explore the effects\nof floating-point quantization targets, exponent bits, mantissa bits, and the\ncalculation granularity of the scaling factor in floating-point quantization\ntraining performance of LLM models. While presenting an accurate floating-point\nquantization unified scaling law, we also provide valuable suggestions for the\ncommunity: (1) Exponent bits contribute slightly more to the model performance\nthan mantissa bits. We provide the optimal exponent-mantissa bit ratio for\ndifferent bit numbers, which is available for future reference by hardware\nmanufacturers; (2) We discover the formation of the critical data size in\nlow-precision LLM training. Too much training data exceeding the critical data\nsize will inversely bring in degradation of LLM performance; (3) The optimal\nfloating-point quantization precision is directly proportional to the\ncomputational power, but within a wide computational power range, we estimate\nthat the best cost-performance precision lies between 4-8 bits.", "published": "2025-01-05 02:30:41", "link": "http://arxiv.org/abs/2501.02423v1", "categories": ["cs.LG", "cs.AR", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Efficient Deployment of Large Language Models on Resource-constrained\n  Devices", "abstract": "Deploying Large Language Models (LLMs) on resource-constrained (or weak)\ndevices presents significant challenges due to limited resources and\nheterogeneous data distribution. To address the data concern, it is necessary\nto fine-tune LLMs using on-device private data for various downstream tasks.\nWhile Federated Learning (FL) offers a promising privacy-preserving solution,\nexisting fine-tuning methods retain the original LLM size, leaving issues of\nhigh inference latency and excessive memory demands unresolved. Hence, we\ndesign FedSpine, an FL framework that combines Parameter- Efficient Fine-Tuning\n(PEFT) with structured pruning for efficient deployment of LLMs on\nresource-constrained devices. Specifically, FedSpine introduces an iterative\nprocess to prune and tune the parameters of LLMs. To mitigate the impact of\ndevice heterogeneity, an online Multi-Armed Bandit (MAB) algorithm is employed\nto adaptively determine different pruning ratios and LoRA ranks for\nheterogeneous devices without any prior knowledge of their computing and\ncommunication capabilities. As a result, FedSpine maintains higher inference\naccuracy while improving fine-tuning efficiency. Experimental results conducted\non a physical platform with 80 devices demonstrate that FedSpine can speed up\nfine-tuning by 1.4$\\times$-6.9$\\times$ and improve final accuracy by 0.4%-4.5%\nunder the same sparsity level compared to other baselines.", "published": "2025-01-05 04:38:11", "link": "http://arxiv.org/abs/2501.02438v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Test-Time Compute: from System-1 Thinking to System-2 Thinking", "abstract": "The remarkable performance of the o1 model in complex reasoning demonstrates\nthat test-time compute scaling can further unlock the model's potential,\nenabling powerful System-2 thinking. However, there is still a lack of\ncomprehensive surveys for test-time compute scaling. We trace the concept of\ntest-time compute back to System-1 models. In System-1 models, test-time\ncompute addresses distribution shifts and improves robustness and\ngeneralization through parameter updating, input modification, representation\nediting, and output calibration. In System-2 models, it enhances the model's\nreasoning ability to solve complex problems through repeated sampling,\nself-correction, and tree search. We organize this survey according to the\ntrend of System-1 to System-2 thinking, highlighting the key role of test-time\ncompute in the transition from System-1 models to weak System-2 models, and\nthen to strong System-2 models. We also point out a few possible future\ndirections.", "published": "2025-01-05 10:24:20", "link": "http://arxiv.org/abs/2501.02497v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Evaluating Large Language Models Against Human Annotators in Latent\n  Content Analysis: Sentiment, Political Leaning, Emotional Intensity, and\n  Sarcasm", "abstract": "In the era of rapid digital communication, vast amounts of textual data are\ngenerated daily, demanding efficient methods for latent content analysis to\nextract meaningful insights. Large Language Models (LLMs) offer potential for\nautomating this process, yet comprehensive assessments comparing their\nperformance to human annotators across multiple dimensions are lacking. This\nstudy evaluates the reliability, consistency, and quality of seven\nstate-of-the-art LLMs, including variants of OpenAI's GPT-4, Gemini, Llama, and\nMixtral, relative to human annotators in analyzing sentiment, political\nleaning, emotional intensity, and sarcasm detection. A total of 33 human\nannotators and eight LLM variants assessed 100 curated textual items,\ngenerating 3,300 human and 19,200 LLM annotations, with LLMs evaluated across\nthree time points to examine temporal consistency. Inter-rater reliability was\nmeasured using Krippendorff's alpha, and intra-class correlation coefficients\nassessed consistency over time. The results reveal that both humans and LLMs\nexhibit high reliability in sentiment analysis and political leaning\nassessments, with LLMs demonstrating higher internal consistency than humans.\nIn emotional intensity, LLMs displayed higher agreement compared to humans,\nthough humans rated emotional intensity significantly higher. Both groups\nstruggled with sarcasm detection, evidenced by low agreement. LLMs showed\nexcellent temporal consistency across all dimensions, indicating stable\nperformance over time. This research concludes that LLMs, especially GPT-4, can\neffectively replicate human analysis in sentiment and political leaning,\nalthough human expertise remains essential for emotional intensity\ninterpretation. The findings demonstrate the potential of LLMs for consistent\nand high-quality performance in certain areas of latent content analysis.", "published": "2025-01-05 13:28:15", "link": "http://arxiv.org/abs/2501.02532v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Decoding fMRI Data into Captions using Prefix Language Modeling", "abstract": "With the advancements in Large Language and Latent Diffusion models, brain\ndecoding has achieved remarkable results in recent years. The works on the NSD\ndataset, with stimuli images from the COCO dataset, leverage the embeddings\nfrom the CLIP model for image reconstruction and GIT for captioning. However,\nthe current captioning approach introduces the challenge of potential data\ncontamination given that the GIT model was trained on the COCO dataset. In this\nwork, we present an alternative method for decoding brain signals into image\ncaptions by predicting a DINOv2 model's embedding of an image from the\ncorresponding fMRI signal and then providing its [CLS] token as the prefix to\nthe GPT-2 language model which decreases computational requirements\nconsiderably. Additionally, instead of commonly used Linear Regression, we\nexplore 3D Convolutional Neural Network mapping of fMRI signals to image\nembedding space for better accounting positional information of voxels.", "published": "2025-01-05 15:06:25", "link": "http://arxiv.org/abs/2501.02570v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "LeetDecoding: A PyTorch Library for Exponentially Decaying Causal Linear\n  Attention with CUDA Implementations", "abstract": "The machine learning and data science community has made significant while\ndispersive progress in accelerating transformer-based large language models\n(LLMs), and one promising approach is to replace the original causal attention\nin a generative pre-trained transformer (GPT) with \\emph{exponentially decaying\ncausal linear attention}. In this paper, we present LeetDecoding, which is the\nfirst Python package that provides a large set of computation routines for this\nfundamental operator. The launch of LeetDecoding was motivated by the current\nlack of (1) clear understanding of the complexity regarding this operator, (2)\na comprehensive collection of existing computation methods (usually spread in\nseemingly unrelated fields), and (3) CUDA implementations for fast inference on\nGPU. LeetDecoding's design is easy to integrate with existing linear-attention\nLLMs, and allows for researchers to benchmark and evaluate new computation\nmethods for exponentially decaying causal linear attention. The usage of\nLeetDecoding does not require any knowledge of GPU programming and the\nunderlying complexity analysis, intentionally making LeetDecoding accessible to\nLLM practitioners. The source code of LeetDecoding is provided at\n\\href{https://github.com/Computational-Machine-Intelligence/LeetDecoding}{this\nGitHub repository}, and users can simply install LeetDecoding by the command\n\\texttt{pip install leet-decoding}.", "published": "2025-01-05 15:11:26", "link": "http://arxiv.org/abs/2501.02573v1", "categories": ["cs.LG", "cs.CL", "cs.MS"], "primary_category": "cs.LG"}
{"title": "Efficient Architectures for High Resolution Vision-Language Models", "abstract": "Vision-Language Models (VLMs) have recently experienced significant\nadvancements. However, challenges persist in the accurate recognition of fine\ndetails within high resolution images, which limits performance in multiple\ntasks. This work introduces Pheye, a novel architecture that efficiently\nprocesses high-resolution images while training fewer parameters than similarly\nsized VLMs. Notably, Pheye achieves a high efficiency while maintaining strong\nperformance, particularly in tasks that demand fine-grained image understanding\nand/or the handling of scene-text.", "published": "2025-01-05 15:41:26", "link": "http://arxiv.org/abs/2501.02584v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "GIT-CXR: End-to-End Transformer for Chest X-Ray Report Generation", "abstract": "Medical imaging is crucial for diagnosing, monitoring, and treating medical\nconditions. The medical reports of radiology images are the primary medium\nthrough which medical professionals attest their findings, but their writing is\ntime consuming and requires specialized clinical expertise. The automated\ngeneration of radiography reports has thus the potential to improve and\nstandardize patient care and significantly reduce clinicians workload. Through\nour work, we have designed and evaluated an end-to-end transformer-based method\nto generate accurate and factually complete radiology reports for X-ray images.\nAdditionally, we are the first to introduce curriculum learning for end-to-end\ntransformers in medical imaging and demonstrate its impact in obtaining\nimproved performance. The experiments have been conducted using the\nMIMIC-CXR-JPG database, the largest available chest X-ray dataset. The results\nobtained are comparable with the current state-of-the-art on the natural\nlanguage generation (NLG) metrics BLEU and ROUGE-L, while setting new\nstate-of-the-art results on F1 examples-averaged, F1-macro and F1-micro metrics\nfor clinical accuracy and on the METEOR metric widely used for NLG.", "published": "2025-01-05 16:45:49", "link": "http://arxiv.org/abs/2501.02598v1", "categories": ["cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Empowering Bengali Education with AI: Solving Bengali Math Word Problems\n  through Transformer Models", "abstract": "Mathematical word problems (MWPs) involve the task of converting textual\ndescriptions into mathematical equations. This poses a significant challenge in\nnatural language processing, particularly for low-resource languages such as\nBengali. This paper addresses this challenge by developing an innovative\napproach to solving Bengali MWPs using transformer-based models, including\nBasic Transformer, mT5, BanglaT5, and mBART50. To support this effort, the\n\"PatiGonit\" dataset was introduced, containing 10,000 Bengali math problems,\nand these models were fine-tuned to translate the word problems into equations\naccurately. The evaluation revealed that the mT5 model achieved the highest\naccuracy of 97.30%, demonstrating the effectiveness of transformer models in\nthis domain. This research marks a significant step forward in Bengali natural\nlanguage processing, offering valuable methodologies and resources for\neducational AI tools. By improving math education, it also supports the\ndevelopment of advanced problem-solving skills for Bengali-speaking students.", "published": "2025-01-05 16:50:55", "link": "http://arxiv.org/abs/2501.02599v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Layer-Level Self-Exposure and Patch: Affirmative Token Mitigation for\n  Jailbreak Attack Defense", "abstract": "As large language models (LLMs) are increasingly deployed in diverse\napplications, including chatbot assistants and code generation, aligning their\nbehavior with safety and ethical standards has become paramount. However,\njailbreak attacks, which exploit vulnerabilities to elicit unintended or\nharmful outputs, threaten LLMs' safety significantly. In this paper, we\nintroduce Layer-AdvPatcher, a novel methodology designed to defend against\njailbreak attacks by utilizing an unlearning strategy to patch specific layers\nwithin LLMs through self-augmented datasets. Our insight is that certain\nlayer(s), tend to produce affirmative tokens when faced with harmful prompts.\nBy identifying these layers and adversarially exposing them to generate more\nharmful data, one can understand their inherent and diverse vulnerabilities to\nattacks. With these exposures, we then \"unlearn\" these issues, reducing the\nimpact of affirmative tokens and hence minimizing jailbreak risks while keeping\nthe model's responses to safe queries intact. We conduct extensive experiments\non two models, four benchmark datasets, and multiple state-of-the-art jailbreak\nattacks to demonstrate the efficacy of our approach. Results indicate that our\nframework reduces the harmfulness and attack success rate of jailbreak attacks\nwithout compromising utility for benign queries compared to recent defense\nmethods. Our code is publicly available at:\nhttps://github.com/oyy2000/LayerAdvPatcher", "published": "2025-01-05 19:06:03", "link": "http://arxiv.org/abs/2501.02629v2", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Generalizing from SIMPLE to HARD Visual Reasoning: Can We Mitigate\n  Modality Imbalance in VLMs?", "abstract": "While Vision Language Models (VLMs) are impressive in tasks such as visual\nquestion answering (VQA) and image captioning, their ability to apply\nmulti-step reasoning to images has lagged, giving rise to perceptions of\nmodality imbalance or brittleness. Towards systematic study of such issues, we\nintroduce a synthetic framework for assessing the ability of VLMs to perform\nalgorithmic visual reasoning (AVR), comprising three tasks: Table Readout, Grid\nNavigation, and Visual Analogy. Each has two levels of difficulty, SIMPLE and\nHARD, and even the SIMPLE versions are difficult for frontier VLMs. We seek\nstrategies for training on the SIMPLE version of the tasks that improve\nperformance on the corresponding HARD task, i.e., S2H generalization. This\nsynthetic framework, where each task also has a text-only version, allows a\nquantification of the modality imbalance, and how it is impacted by training\nstrategy. Ablations highlight the importance of explicit image-to-text\nconversion in promoting S2H generalization when using auto-regressive training.\nWe also report results of mechanistic study of this phenomenon, including a\nmeasure of gradient alignment that seems to identify training strategies that\npromote better S2H generalization.", "published": "2025-01-05 21:36:38", "link": "http://arxiv.org/abs/2501.02669v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "DPO Kernels: A Semantically-Aware, Kernel-Enhanced, and Divergence-Rich\n  Paradigm for Direct Preference Optimization", "abstract": "The rapid rise of large language models (LLMs) has unlocked many applications\nbut also underscores the challenge of aligning them with diverse values and\npreferences. Direct Preference Optimization (DPO) is central to alignment but\nconstrained by fixed divergences and limited feature transformations. We\npropose DPO-Kernels, which integrates kernel methods to address these issues\nthrough four key contributions: (i) Kernelized Representations with polynomial,\nRBF, Mahalanobis, and spectral kernels for richer transformations, plus a\nhybrid loss combining embedding-based and probability-based objectives; (ii)\nDivergence Alternatives (Jensen-Shannon, Hellinger, Renyi, Bhattacharyya,\nWasserstein, and f-divergences) for greater stability; (iii) Data-Driven\nSelection metrics that automatically choose the best kernel-divergence pair;\nand (iv) a Hierarchical Mixture of Kernels for both local precision and global\nmodeling. Evaluations on 12 datasets demonstrate state-of-the-art performance\nin factuality, safety, reasoning, and instruction following. Grounded in\nHeavy-Tailed Self-Regularization, DPO-Kernels maintains robust generalization\nfor LLMs, offering a comprehensive resource for further alignment research.", "published": "2025-01-05 00:08:52", "link": "http://arxiv.org/abs/2501.03271v3", "categories": ["cs.LG", "cs.AI", "cs.CL", "68T45"], "primary_category": "cs.LG"}
{"title": "Backdoor Token Unlearning: Exposing and Defending Backdoors in\n  Pretrained Language Models", "abstract": "Supervised fine-tuning has become the predominant method for adapting large\npretrained models to downstream tasks. However, recent studies have revealed\nthat these models are vulnerable to backdoor attacks, where even a small number\nof malicious samples can successfully embed backdoor triggers into the model.\nWhile most existing defense methods focus on post-training backdoor defense,\nefficiently defending against backdoor attacks during training phase remains\nlargely unexplored. To address this gap, we propose a novel defense method\ncalled Backdoor Token Unlearning (BTU), which proactively detects and\nneutralizes trigger tokens during the training stage. Our work is based on two\nkey findings: 1) backdoor learning causes distinctive differences between\nbackdoor token parameters and clean token parameters in word embedding layers,\nand 2) the success of backdoor attacks heavily depends on backdoor token\nparameters. The BTU defense leverages these properties to identify aberrant\nembedding parameters and subsequently removes backdoor behaviors using a\nfine-grained unlearning technique. Extensive evaluations across three datasets\nand four types of backdoor attacks demonstrate that BTU effectively defends\nagainst these threats while preserving the model's performance on primary\ntasks. Our code is available at https://github.com/XDJPH/BTU.", "published": "2025-01-05 03:22:13", "link": "http://arxiv.org/abs/2501.03272v1", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Strategic Fusion Optimizes Transformer Compression", "abstract": "This study investigates transformer model compression by systematically\npruning its layers. We evaluated 14 pruning strategies across nine diverse\ndatasets, including 12 strategies based on different signals obtained from\nlayer activations, mutual information, gradients, weights, and attention. To\naddress the limitations of single-signal strategies, we introduced two fusion\nstrategies, linear regression and random forest, which combine individual\nstrategies (i.e., strategic fusion), for more informed pruning decisions.\nAdditionally, we applied knowledge distillation to mitigate any accuracy loss\nduring layer pruning. Our results reveal that random forest strategic fusion\noutperforms individual strategies in seven out of nine datasets and achieves\nnear-optimal performance in the other two. The distilled random forest\nsurpasses the original accuracy in six datasets and mitigates accuracy drops in\nthe remaining three. Knowledge distillation also improves the accuracy-to-size\nratio by an average factor of 18.84 across all datasets. Supported by\nmathematical foundations and biological analogies, our findings suggest that\nstrategically combining multiple signals can lead to efficient, high-performing\ntransformer models for resource-constrained applications.", "published": "2025-01-05 04:46:14", "link": "http://arxiv.org/abs/2501.03273v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "ComMer: a Framework for Compressing and Merging User Data for\n  Personalization", "abstract": "Large Language Models (LLMs) excel at a wide range of tasks, but adapting\nthem to new data, particularly for personalized applications, poses significant\nchallenges due to resource and computational constraints. Existing methods\neither rely on exposing fresh data to the model through the prompt, which is\nlimited by context size and computationally expensive at inference time, or\nfine-tuning, which incurs substantial training and update costs. In this paper,\nwe introduce ComMer - Compress and Merge - a novel framework that efficiently\npersonalizes LLMs by compressing users' documents into compact representations,\nwhich are then merged and fed into a frozen LLM. We evaluate ComMer on two\ntypes of personalization tasks - personalized skill learning, using the tweet\nparaphrasing dataset and the personalized news headline generation dataset from\nthe LaMP benchmark, and knowledge-intensive, using the PerLTQA dataset. Our\nexperiments demonstrate that in constrained inference budget scenarios ComMer\nachieves superior quality in skill learning tasks, while highlighting\nlimitations in knowledge-intensive settings due to the loss of detailed\ninformation. These results offer insights into trade-offs and potential\noptimizations in multi-document compression for personalization.", "published": "2025-01-05 09:57:03", "link": "http://arxiv.org/abs/2501.03276v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Can Impressions of Music be Extracted from Thumbnail Images?", "abstract": "In recent years, there has been a notable increase in research on machine\nlearning models for music retrieval and generation systems that are capable of\ntaking natural language sentences as inputs. However, there is a scarcity of\nlarge-scale publicly available datasets, consisting of music data and their\ncorresponding natural language descriptions known as music captions. In\nparticular, non-musical information such as suitable situations for listening\nto a track and the emotions elicited upon listening is crucial for describing\nmusic. This type of information is underrepresented in existing music caption\ndatasets due to the challenges associated with extracting it directly from\nmusic data. To address this issue, we propose a method for generating music\ncaption data that incorporates non-musical aspects inferred from music\nthumbnail images, and validated the effectiveness of our approach through human\nevaluations. Additionally, we created a dataset with approximately 360,000\ncaptions containing non-musical aspects. Leveraging this dataset, we trained a\nmusic retrieval model and demonstrated its effectiveness in music retrieval\ntasks through evaluation.", "published": "2025-01-05 11:51:38", "link": "http://arxiv.org/abs/2501.02511v1", "categories": ["cs.CL", "cs.CV", "cs.IR", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Fitting Different Interactive Information: Joint Classification of\n  Emotion and Intention", "abstract": "This paper is the first-place solution for ICASSP MEIJU@2025 Track I, which\nfocuses on low-resource multimodal emotion and intention recognition. How to\neffectively utilize a large amount of unlabeled data, while ensuring the mutual\npromotion of different difficulty levels tasks in the interaction stage, these\ntwo points become the key to the competition. In this paper, pseudo-label\nlabeling is carried out on the model trained with labeled data, and samples\nwith high confidence and their labels are selected to alleviate the problem of\nlow resources. At the same time, the characteristic of easy represented ability\nof intention recognition found in the experiment is used to make mutually\npromote with emotion recognition under different attention heads, and higher\nperformance of intention recognition is achieved through fusion. Finally, under\nthe refined processing data, we achieve the score of 0.5532 in the Test set,\nand win the championship of the track.", "published": "2025-01-05 05:23:27", "link": "http://arxiv.org/abs/2501.06215v1", "categories": ["cs.CV", "cs.CL", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.CV"}
{"title": "A Statistical Hypothesis Testing Framework for Data Misappropriation\n  Detection in Large Language Models", "abstract": "Large Language Models (LLMs) are rapidly gaining enormous popularity in\nrecent years. However, the training of LLMs has raised significant privacy and\nlegal concerns, particularly regarding the inclusion of copyrighted materials\nin their training data without proper attribution or licensing, which falls\nunder the broader issue of data misappropriation. In this article, we focus on\na specific problem of data misappropriation detection, namely, to determine\nwhether a given LLM has incorporated data generated by another LLM. To address\nthis issue, we propose embedding watermarks into the copyrighted training data\nand formulating the detection of data misappropriation as a hypothesis testing\nproblem. We develop a general statistical testing framework, construct a\npivotal statistic, determine the optimal rejection threshold, and explicitly\ncontrol the type I and type II errors. Furthermore, we establish the asymptotic\noptimality properties of the proposed tests, and demonstrate its empirical\neffectiveness through intensive numerical experiments.", "published": "2025-01-05 04:47:42", "link": "http://arxiv.org/abs/2501.02441v1", "categories": ["stat.ML", "cs.AI", "cs.CL", "cs.CR", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Reducing the Gap Between Pretrained Speech Enhancement and Recognition\n  Models Using a Real Speech-Trained Bridging Module", "abstract": "The information loss or distortion caused by single-channel speech\nenhancement (SE) harms the performance of automatic speech recognition (ASR).\nObservation addition (OA) is an effective post-processing method to improve ASR\nperformance by balancing noisy and enhanced speech. Determining the OA\ncoefficient is crucial. However, the currently supervised OA coefficient\nmodule, called the bridging module, only utilizes simulated noisy speech for\ntraining, which has a severe mismatch with real noisy speech. In this paper, we\npropose training strategies to train the bridging module with real noisy\nspeech. First, DNSMOS is selected to evaluate the perceptual quality of real\nnoisy speech with no need for the corresponding clean label to train the\nbridging module. Additional constraints during training are introduced to\nenhance the robustness of the bridging module further. Each utterance is\nevaluated by the ASR back-end using various OA coefficients to obtain the word\nerror rates (WERs). The WERs are used to construct a multidimensional vector.\nThis vector is introduced into the bridging module with multi-task learning and\nis used to determine the optimal OA coefficients. The experimental results on\nthe CHiME-4 dataset show that the proposed methods all had significant\nimprovement compared with the simulated data trained bridging module,\nespecially under real evaluation sets.", "published": "2025-01-05 06:12:07", "link": "http://arxiv.org/abs/2501.02452v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Efficient Long Speech Sequence Modelling for Time-Domain Depression\n  Level Estimation", "abstract": "Depression significantly affects emotions, thoughts, and daily activities.\nRecent research indicates that speech signals contain vital cues about\ndepression, sparking interest in audio-based deep-learning methods for\nestimating its severity. However, most methods rely on time-frequency\nrepresentations of speech which have recently been criticized for their\nlimitations due to the loss of information when performing time-frequency\nprojections, e.g. Fourier transform, and Mel-scale transformation. Furthermore,\nsegmenting real-world speech into brief intervals risks losing critical\ninterconnections between recordings. Additionally, such an approach may not\nadequately reflect real-world scenarios, as individuals with depression often\npause and slow down in their conversations and interactions. Building on these\nobservations, we present an efficient method for depression level estimation\nusing long speech signals in the time domain. The proposed method leverages a\nstate space model coupled with the dual-path structure-based long sequence\nmodelling module and temporal external attention module to reconstruct and\nenhance the detection of depression-related cues hidden in the raw audio\nwaveforms. Experimental results on the AVEC2013 and AVEC2014 datasets show\npromising results in capturing consequential long-sequence depression cues and\ndemonstrate outstanding performance over the state-of-the-art.", "published": "2025-01-05 11:58:40", "link": "http://arxiv.org/abs/2501.02512v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A Frequency-aware Augmentation Network for Mental Disorders Assessment\n  from Audio", "abstract": "Depression and Attention Deficit Hyperactivity Disorder (ADHD) stand out as\nthe common mental health challenges today. In affective computing, speech\nsignals serve as effective biomarkers for mental disorder assessment. Current\nresearch, relying on labor-intensive hand-crafted features or simplistic\ntime-frequency representations, often overlooks critical details by not\naccounting for the differential impacts of various frequency bands and temporal\nfluctuations. Therefore, we propose a frequency-aware augmentation network with\ndynamic convolution for depression and ADHD assessment. In the proposed method,\nthe spectrogram is used as the input feature and adopts a multi-scale\nconvolution to help the network focus on discriminative frequency bands related\nto mental disorders. A dynamic convolution is also designed to aggregate\nmultiple convolution kernels dynamically based upon their attentions which are\ninput-independent to capture dynamic information. Finally, a feature\naugmentation block is proposed to enhance the feature representation ability\nand make full use of the captured information. Experimental results on AVEC\n2014 and self-recorded ADHD dataset prove the robustness of our method, an RMSE\nof 9.23 was attained for estimating depression severity, along with an accuracy\nof 89.8\\% in detecting ADHD.", "published": "2025-01-05 12:06:06", "link": "http://arxiv.org/abs/2501.02516v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A System for Melodic Harmonization using Schoenberg Regions, Giant\n  Steps, and Church Modes", "abstract": "Systems such as Microsoft Songsmith automatically assign chords and harmony\nto a melody by minimizing the dissonance across all chord changes. Although\nthis produces harmonious music, it is not what practicing musicians do. In this\npaper, I describe Harmonizer, a prototype system for melodic harmonization.\nHarmonizer uses Schoenberg's chart of regions as the underlying data structure\nthat allows harmonization using several different methods. Because the chart\nreveals inter-chordal relationships, the harmonizations may be programmed to\nemphasize desired relationships. In the prototype Harmonizer, I also explore\nrecent signal-processing methods that enable songwriters to easily input a\nmelody by singing or by playing a musical instrument. The prototype Harmonizer\nis available on GitHub and a video demonstrating its distinctive harmonizations\nis on YouTube as explained in the Results section of the paper.", "published": "2025-01-05 20:08:42", "link": "http://arxiv.org/abs/2501.02642v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
