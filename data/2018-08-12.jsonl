{"title": "Addressee and Response Selection for Multilingual Conversation", "abstract": "Developing conversational systems that can converse in many languages is an\ninteresting challenge for natural language processing. In this paper, we\nintroduce multilingual addressee and response selection. In this task, a\nconversational system predicts an appropriate addressee and response for an\ninput message in multiple languages. A key to developing such multilingual\nresponding systems is how to utilize high-resource language data to compensate\nfor low-resource language data. We present several knowledge transfer methods\nfor conversational systems. To evaluate our methods, we create a new\nmultilingual conversation dataset. Experiments on the dataset demonstrate the\neffectiveness of our methods.", "published": "2018-08-12 09:37:25", "link": "http://arxiv.org/abs/1808.03915v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Text Classification using Capsules", "abstract": "This paper presents an empirical exploration of the use of capsule networks\nfor text classification. While it has been shown that capsule networks are\neffective for image classification, their validity in the domain of text has\nnot been explored. In this paper, we show that capsule networks indeed have the\npotential for text classification and that they have several advantages over\nconvolutional neural networks. We further suggest a simple routing method that\neffectively reduces the computational complexity of dynamic routing. We\nutilized seven benchmark datasets to demonstrate that capsule networks, along\nwith the proposed routing method provide comparable results.", "published": "2018-08-12 18:08:38", "link": "http://arxiv.org/abs/1808.03976v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sequence Labeling: A Practical Approach", "abstract": "We take a practical approach to solving sequence labeling problem assuming\nunavailability of domain expertise and scarcity of informational and\ncomputational resources. To this end, we utilize a universal end-to-end\nBi-LSTM-based neural sequence labeling model applicable to a wide range of NLP\ntasks and languages. The model combines morphological, semantic, and structural\ncues extracted from data to arrive at informed predictions. The model's\nperformance is evaluated on eight benchmark datasets (covering three tasks:\nPOS-tagging, NER, and Chunking, and four languages: English, German, Dutch, and\nSpanish). We observe state-of-the-art results on four of them: CoNLL-2012\n(English NER), CoNLL-2002 (Dutch NER), GermEval 2014 (German NER), Tiger Corpus\n(German POS-tagging), and competitive performance on the rest.", "published": "2018-08-12 11:53:04", "link": "http://arxiv.org/abs/1808.03926v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Augmenting word2vec with latent Dirichlet allocation within a clinical\n  application", "abstract": "This paper presents three hybrid models that directly combine latent\nDirichlet allocation and word embedding for distinguishing between speakers\nwith and without Alzheimer's disease from transcripts of picture descriptions.\nTwo of our models get F-scores over the current state-of-the-art using\nautomatic methods on the DementiaBank dataset.", "published": "2018-08-12 16:32:18", "link": "http://arxiv.org/abs/1808.03967v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Interpreting Recurrent and Attention-Based Neural Models: a Case Study\n  on Natural Language Inference", "abstract": "Deep learning models have achieved remarkable success in natural language\ninference (NLI) tasks. While these models are widely explored, they are hard to\ninterpret and it is often unclear how and why they actually work. In this\npaper, we take a step toward explaining such deep learning based models through\na case study on a popular neural model for NLI. In particular, we propose to\ninterpret the intermediate layers of NLI models by visualizing the saliency of\nattention and LSTM gating signals. We present several examples for which our\nmethods are able to reveal interesting insights and identify the critical\ninformation contributing to the model decisions.", "published": "2018-08-12 05:42:26", "link": "http://arxiv.org/abs/1808.03894v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multimodal Differential Network for Visual Question Generation", "abstract": "Generating natural questions from an image is a semantic task that requires\nusing visual and language modality to learn multimodal representations. Images\ncan have multiple visual and language contexts that are relevant for generating\nquestions namely places, captions, and tags. In this paper, we propose the use\nof exemplars for obtaining the relevant context. We obtain this by using a\nMultimodal Differential Network to produce natural and engaging questions. The\ngenerated questions show a remarkable similarity to the natural questions as\nvalidated by a human study. Further, we observe that the proposed approach\nsubstantially improves over state-of-the-art benchmarks on the quantitative\nmetrics (BLEU, METEOR, ROUGE, and CIDEr).", "published": "2018-08-12 18:56:56", "link": "http://arxiv.org/abs/1808.03986v2", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Multimodal Language Analysis with Recurrent Multistage Fusion", "abstract": "Computational modeling of human multimodal language is an emerging research\narea in natural language processing spanning the language, visual and acoustic\nmodalities. Comprehending multimodal language requires modeling not only the\ninteractions within each modality (intra-modal interactions) but more\nimportantly the interactions between modalities (cross-modal interactions). In\nthis paper, we propose the Recurrent Multistage Fusion Network (RMFN) which\ndecomposes the fusion problem into multiple stages, each of them focused on a\nsubset of multimodal signals for specialized, effective fusion. Cross-modal\ninteractions are modeled using this multistage fusion approach which builds\nupon intermediate representations of previous stages. Temporal and intra-modal\ninteractions are modeled by integrating our proposed fusion approach with a\nsystem of recurrent neural networks. The RMFN displays state-of-the-art\nperformance in modeling human multimodal language across three public datasets\nrelating to multimodal sentiment analysis, emotion recognition, and speaker\ntraits recognition. We provide visualizations to show that each stage of fusion\nfocuses on a different subset of multimodal signals, learning increasingly\ndiscriminative multimodal representations.", "published": "2018-08-12 10:04:45", "link": "http://arxiv.org/abs/1808.03920v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.NE", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Sample Mixed-Based Data Augmentation for Domestic Audio Tagging", "abstract": "Audio tagging has attracted increasing attention since last decade and has\nvarious potential applications in many fields. The objective of audio tagging\nis to predict the labels of an audio clip. Recently deep learning methods have\nbeen applied to audio tagging and have achieved state-of-the-art performance,\nwhich provides a poor generalization ability on new data. However due to the\nlimited size of audio tagging data such as DCASE data, the trained models tend\nto result in overfitting of the network. Previous data augmentation methods\nsuch as pitch shifting, time stretching and adding background noise do not show\nmuch improvement in audio tagging. In this paper, we explore the sample mixed\ndata augmentation for the domestic audio tagging task, including mixup,\nSamplePairing and extrapolation. We apply a convolutional recurrent neural\nnetwork (CRNN) with attention module with log-scaled mel spectrum as a baseline\nsystem. In our experiments, we achieve an state-of-the-art of equal error rate\n(EER) of 0.10 on DCASE 2016 task4 dataset with mixup approach, outperforming\nthe baseline system without data augmentation.", "published": "2018-08-12 02:34:55", "link": "http://arxiv.org/abs/1808.03883v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
