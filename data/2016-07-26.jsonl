{"title": "Grounding Dynamic Spatial Relations for Embodied (Robot) Interaction", "abstract": "This paper presents a computational model of the processing of dynamic\nspatial relations occurring in an embodied robotic interaction setup. A\ncomplete system is introduced that allows autonomous robots to produce and\ninterpret dynamic spatial phrases (in English) given an environment of moving\nobjects. The model unites two separate research strands: computational\ncognitive semantics and on commonsense spatial representation and reasoning.\nThe model for the first time demonstrates an integration of these different\nstrands.", "published": "2016-07-26 07:22:52", "link": "http://arxiv.org/abs/1607.07565v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Grounded Lexicon Acquisition - Case Studies in Spatial Language", "abstract": "This paper discusses grounded acquisition experiments of increasing\ncomplexity. Humanoid robots acquire English spatial lexicons from robot tutors.\nWe identify how various spatial language systems, such as projective, absolute\nand proximal can be learned. The proposed learning mechanisms do not rely on\ndirect meaning transfer or direct access to world models of interlocutors.\nFinally, we show how multiple systems can be acquired at the same time.", "published": "2016-07-26 10:37:24", "link": "http://arxiv.org/abs/1607.07630v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Machine Learned Resume-Job Matching Solution", "abstract": "Job search through online matching engines nowadays are very prominent and\nbeneficial to both job seekers and employers. But the solutions of traditional\nengines without understanding the semantic meanings of different resumes have\nnot kept pace with the incredible changes in machine learning techniques and\ncomputing capability. These solutions are usually driven by manual rules and\npredefined weights of keywords which lead to an inefficient and frustrating\nsearch experience. To this end, we present a machine learned solution with rich\nfeatures and deep learning methods. Our solution includes three configurable\nmodules that can be plugged with little restrictions. Namely, unsupervised\nfeature extraction, base classifiers training and ensemble method learning. In\nour solution, rather than using manual rules, machine learned methods to\nautomatically detect the semantic similarity of positions are proposed. Then\nfour competitive \"shallow\" estimators and \"deep\" estimators are selected.\nFinally, ensemble methods to bag these estimators and aggregate their\nindividual predictions to form a final prediction are verified. Experimental\nresults of over 47 thousand resumes show that our solution can significantly\nimprove the predication precision current position, salary, educational\nbackground and company scale.", "published": "2016-07-26 12:04:31", "link": "http://arxiv.org/abs/1607.07657v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tweet2Vec: Learning Tweet Embeddings Using Character-level CNN-LSTM\n  Encoder-Decoder", "abstract": "We present Tweet2Vec, a novel method for generating general-purpose vector\nrepresentation of tweets. The model learns tweet embeddings using\ncharacter-level CNN-LSTM encoder-decoder. We trained our model on 3 million,\nrandomly selected English-language tweets. The model was evaluated using two\nmethods: tweet semantic similarity and tweet sentiment categorization,\noutperforming the previous state-of-the-art in both tasks. The evaluations\ndemonstrate the power of the tweet embeddings generated by our model for\nvarious tweet categorization tasks. The vector representations generated by our\nmodel are generic, and hence can be applied to a variety of tasks. Though the\nmodel presented in this paper is trained on English-language tweets, the method\npresented can be used to learn tweet embeddings for different languages.", "published": "2016-07-26 00:58:14", "link": "http://arxiv.org/abs/1607.07514v1", "categories": ["cs.CL", "cs.AI", "cs.NE", "cs.SI"], "primary_category": "cs.CL"}
{"title": "OntoCat: Automatically categorizing knowledge in API Documentation", "abstract": "Most application development happens in the context of complex APIs;\nreference documentation for APIs has grown tremendously in variety, complexity,\nand volume, and can be difficult to navigate. There is a growing need to\ndevelop well-organized ways to access the knowledge latent in the\ndocumentation; several research efforts deal with the organization (ontology)\nof API-related knowledge. Extensive knowledge-engineering work, supported by a\nrigorous qualitative analysis, by Maalej & Robillard [3] has identified a\nuseful taxonomy of API knowledge. Based on this taxonomy, we introduce a domain\nindependent technique to extract the knowledge types from the given API\nreference documentation. Our system, OntoCat, introduces total nine different\nfeatures and their semantic and statistical combinations to classify the\ndifferent knowledge types. We tested OntoCat on python API reference\ndocumentation. Our experimental results show the effectiveness of the system\nand opens the scope of probably related research areas (i.e., user behavior,\ndocumentation quality, etc.).", "published": "2016-07-26 09:19:46", "link": "http://arxiv.org/abs/1607.07602v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
