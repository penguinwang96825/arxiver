{"title": "Lexical Features in Coreference Resolution: To be Used With Caution", "abstract": "Lexical features are a major source of information in state-of-the-art\ncoreference resolvers. Lexical features implicitly model some of the linguistic\nphenomena at a fine granularity level. They are especially useful for\nrepresenting the context of mentions. In this paper we investigate a drawback\nof using many lexical features in state-of-the-art coreference resolvers. We\nshow that if coreference resolvers mainly rely on lexical features, they can\nhardly generalize to unseen domains. Furthermore, we show that the current\ncoreference resolution evaluation is clearly flawed by only evaluating on a\nspecific split of a specific dataset in which there is a notable overlap\nbetween the training, development and test sets.", "published": "2017-04-22 09:59:42", "link": "http://arxiv.org/abs/1704.06779v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sarcasm SIGN: Interpreting Sarcasm with Sentiment Based Monolingual\n  Machine Translation", "abstract": "Sarcasm is a form of speech in which speakers say the opposite of what they\ntruly mean in order to convey a strong sentiment. In other words, \"Sarcasm is\nthe giant chasm between what I say, and the person who doesn't get it.\". In\nthis paper we present the novel task of sarcasm interpretation, defined as the\ngeneration of a non-sarcastic utterance conveying the same message as the\noriginal sarcastic one. We introduce a novel dataset of 3000 sarcastic tweets,\neach interpreted by five human judges. Addressing the task as monolingual\nmachine translation (MT), we experiment with MT algorithms and evaluation\nmeasures. We then present SIGN: an MT based sarcasm interpretation algorithm\nthat targets sentiment words, a defining element of textual sarcasm. We show\nthat while the scores of n-gram based automatic measures are similar for all\ninterpretation models, SIGN's interpretations are scored higher by humans for\nadequacy and sentiment polarity. We conclude with a discussion on future\nresearch directions for our new task.", "published": "2017-04-22 18:59:25", "link": "http://arxiv.org/abs/1704.06836v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Medical Text Classification using Convolutional Neural Networks", "abstract": "We present an approach to automatically classify clinical text at a sentence\nlevel. We are using deep convolutional neural networks to represent complex\nfeatures. We train the network on a dataset providing a broad categorization of\nhealth information. Through a detailed evaluation, we demonstrate that our\nmethod outperforms several approaches widely used in natural language\nprocessing tasks by about 15%.", "published": "2017-04-22 19:39:32", "link": "http://arxiv.org/abs/1704.06841v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Affect-LM: A Neural Language Model for Customizable Affective Text\n  Generation", "abstract": "Human verbal communication includes affective messages which are conveyed\nthrough use of emotionally colored words. There has been a lot of research in\nthis direction but the problem of integrating state-of-the-art neural language\nmodels with affective information remains an area ripe for exploration. In this\npaper, we propose an extension to an LSTM (Long Short-Term Memory) language\nmodel for generating conversational text, conditioned on affect categories. Our\nproposed model, Affect-LM enables us to customize the degree of emotional\ncontent in generated sentences through an additional design parameter.\nPerception studies conducted using Amazon Mechanical Turk show that Affect-LM\ngenerates naturally looking emotional sentences without sacrificing grammatical\ncorrectness. Affect-LM also learns affect-discriminative word representations,\nand perplexity experiments show that additional affective information in\nconversational text can improve language model prediction.", "published": "2017-04-22 21:10:10", "link": "http://arxiv.org/abs/1704.06851v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Deep Multitask Learning for Semantic Dependency Parsing", "abstract": "We present a deep neural architecture that parses sentences into three\nsemantic dependency graph formalisms. By using efficient, nearly arc-factored\ninference and a bidirectional-LSTM composed with a multi-layer perceptron, our\nbase system is able to significantly improve the state of the art for semantic\ndependency parsing, without using hand-engineered features or syntax. We then\nexplore two multitask learning approaches---one that shares parameters across\nformalisms, and one that uses higher-order structures to predict the graphs\njointly. We find that both approaches improve performance across formalisms on\naverage, achieving a new state of the art. Our code is open-source and\navailable at https://github.com/Noahs-ARK/NeurboParser.", "published": "2017-04-22 22:56:04", "link": "http://arxiv.org/abs/1704.06855v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Representations of Emotional Speech with Deep Convolutional\n  Generative Adversarial Networks", "abstract": "Automatically assessing emotional valence in human speech has historically\nbeen a difficult task for machine learning algorithms. The subtle changes in\nthe voice of the speaker that are indicative of positive or negative emotional\nstates are often \"overshadowed\" by voice characteristics relating to emotional\nintensity or emotional activation. In this work we explore a representation\nlearning approach that automatically derives discriminative representations of\nemotional speech. In particular, we investigate two machine learning strategies\nto improve classifier performance: (1) utilization of unlabeled data using a\ndeep convolutional generative adversarial network (DCGAN), and (2) multitask\nlearning. Within our extensive experiments we leverage a multitask annotated\nemotional corpus as well as a large unlabeled meeting corpus (around 100\nhours). Our speaker-independent classification experiments show that in\nparticular the use of unlabeled data in our investigations improves performance\nof the classifiers and both fully supervised baseline approaches are\noutperformed considerably. We improve the classification of emotional valence\non a discrete 5-point scale to 43.88% and on a 3-point scale to 49.80%, which\nis competitive to state-of-the-art performance.", "published": "2017-04-22 18:28:25", "link": "http://arxiv.org/abs/1705.02394v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
