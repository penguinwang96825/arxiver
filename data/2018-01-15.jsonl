{"title": "An Interpretable Reasoning Network for Multi-Relation Question Answering", "abstract": "Multi-relation Question Answering is a challenging task, due to the\nrequirement of elaborated analysis on questions and reasoning over multiple\nfact triples in knowledge base. In this paper, we present a novel model called\nInterpretable Reasoning Network that employs an interpretable, hop-by-hop\nreasoning process for question answering. The model dynamically decides which\npart of an input question should be analyzed at each hop; predicts a relation\nthat corresponds to the current parsed results; utilizes the predicted relation\nto update the question representation and the state of the reasoning process;\nand then drives the next-hop reasoning. Experiments show that our model yields\nstate-of-the-art results on two datasets. More interestingly, the model can\noffer traceable and observable intermediate predictions for reasoning analysis\nand failure diagnosis, thereby allowing manual manipulation in predicting the\nfinal answer.", "published": "2018-01-15 10:31:01", "link": "http://arxiv.org/abs/1801.04726v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What Level of Quality can Neural Machine Translation Attain on Literary\n  Text?", "abstract": "Given the rise of a new approach to MT, Neural MT (NMT), and its promising\nperformance on different text types, we assess the translation quality it can\nattain on what is perceived to be the greatest challenge for MT: literary text.\nSpecifically, we target novels, arguably the most popular type of literary\ntext. We build a literary-adapted NMT system for the English-to-Catalan\ntranslation direction and evaluate it against a system pertaining to the\nprevious dominant paradigm in MT: statistical phrase-based MT (PBSMT). To this\nend, for the first time we train MT systems, both NMT and PBSMT, on large\namounts of literary text (over 100 million words) and evaluate them on a set of\ntwelve widely known novels spanning from the the 1920s to the present day.\nAccording to the BLEU automatic evaluation metric, NMT is significantly better\nthan PBSMT (p < 0.01) on all the novels considered. Overall, NMT results in a\n11% relative improvement (3 points absolute) over PBSMT. A complementary human\nevaluation on three of the books shows that between 17% and 34% of the\ntranslations, depending on the book, produced by NMT (versus 8% and 20% with\nPBSMT) are perceived by native speakers of the target language to be of\nequivalent quality to translations produced by a professional human translator.", "published": "2018-01-15 19:39:19", "link": "http://arxiv.org/abs/1801.04962v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Building a Conversational Agent Overnight with Dialogue Self-Play", "abstract": "We propose Machines Talking To Machines (M2M), a framework combining\nautomation and crowdsourcing to rapidly bootstrap end-to-end dialogue agents\nfor goal-oriented dialogues in arbitrary domains. M2M scales to new tasks with\njust a task schema and an API client from the dialogue system developer, but it\nis also customizable to cater to task-specific interactions. Compared to the\nWizard-of-Oz approach for data collection, M2M achieves greater diversity and\ncoverage of salient dialogue flows while maintaining the naturalness of\nindividual utterances. In the first phase, a simulated user bot and a\ndomain-agnostic system bot converse to exhaustively generate dialogue\n\"outlines\", i.e. sequences of template utterances and their semantic parses. In\nthe second phase, crowd workers provide contextual rewrites of the dialogues to\nmake the utterances more natural while preserving their meaning. The entire\nprocess can finish within a few hours. We propose a new corpus of 3,000\ndialogues spanning 2 domains collected with M2M, and present comparisons with\npopular dialogue datasets on the quality and diversity of the surface forms and\ndialogue flows.", "published": "2018-01-15 16:45:56", "link": "http://arxiv.org/abs/1801.04871v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Predicting Movie Genres Based on Plot Summaries", "abstract": "This project explores several Machine Learning methods to predict movie\ngenres based on plot summaries. Naive Bayes, Word2Vec+XGBoost and Recurrent\nNeural Networks are used for text classification, while K-binary\ntransformation, rank method and probabilistic classification with learned\nprobability threshold are employed for the multi-label problem involved in the\ngenre tagging task.Experiments with more than 250,000 movies show that\nemploying the Gated Recurrent Units (GRU) neural networks for the probabilistic\nclassification with learned probability threshold approach achieves the best\nresult on the test set. The model attains a Jaccard Index of 50.0%, a F-score\nof 0.56, and a hit rate of 80.5%.", "published": "2018-01-15 14:11:57", "link": "http://arxiv.org/abs/1801.04813v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Topic Modeling on Health Journals with Regularized Variational Inference", "abstract": "Topic modeling enables exploration and compact representation of a corpus.\nThe CaringBridge (CB) dataset is a massive collection of journals written by\npatients and caregivers during a health crisis. Topic modeling on the CB\ndataset, however, is challenging due to the asynchronous nature of multiple\nauthors writing about their health journeys. To overcome this challenge we\nintroduce the Dynamic Author-Persona topic model (DAP), a probabilistic\ngraphical model designed for temporal corpora with multiple authors. The\nnovelty of the DAP model lies in its representation of authors by a persona ---\nwhere personas capture the propensity to write about certain topics over time.\nFurther, we present a regularized variational inference algorithm, which we use\nto encourage the DAP model's personas to be distinct. Our results show\nsignificant improvements over competing topic models --- particularly after\nregularization, and highlight the DAP model's unique ability to capture common\njourneys shared by different authors.", "published": "2018-01-15 19:23:21", "link": "http://arxiv.org/abs/1801.04958v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
