{"title": "Vocabulary Selection Strategies for Neural Machine Translation", "abstract": "Classical translation models constrain the space of possible outputs by\nselecting a subset of translation rules based on the input sentence. Recent\nwork on improving the efficiency of neural translation models adopted a similar\nstrategy by restricting the output vocabulary to a subset of likely candidates\ngiven the source. In this paper we experiment with context and embedding-based\nselection methods and extend previous work by examining speed and accuracy\ntrade-offs in more detail. We show that decoding time on CPUs can be reduced by\nup to 90% and training time by 25% on the WMT15 English-German and WMT16\nEnglish-Romanian tasks at the same or only negligible change in accuracy. This\nbrings the time to decode with a state of the art neural translation system to\njust over 140 msec per sentence on a single CPU core for English-German.", "published": "2016-10-01 02:23:03", "link": "http://arxiv.org/abs/1610.00072v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
