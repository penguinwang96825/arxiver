{"title": "NERO: A Neural Rule Grounding Framework for Label-Efficient Relation\n  Extraction", "abstract": "Deep neural models for relation extraction tend to be less reliable when\nperfectly labeled data is limited, despite their success in label-sufficient\nscenarios. Instead of seeking more instance-level labels from human annotators,\nhere we propose to annotate frequent surface patterns to form labeling rules.\nThese rules can be automatically mined from large text corpora and generalized\nvia a soft rule matching mechanism. Prior works use labeling rules in an exact\nmatching fashion, which inherently limits the coverage of sentence matching and\nresults in the low-recall issue. In this paper, we present a neural approach to\nground rules for RE, named NERO, which jointly learns a relation extraction\nmodule and a soft matching module. One can employ any neural relation\nextraction models as the instantiation for the RE module. The soft matching\nmodule learns to match rules with semantically similar sentences such that raw\ncorpora can be automatically labeled and leveraged by the RE module (in a much\nbetter coverage) as augmented supervision, in addition to the exactly matched\nsentences. Extensive experiments and analysis on two public and widely-used\ndatasets demonstrate the effectiveness of the proposed NERO framework,\ncomparing with both rule-based and semi-supervised methods. Through user\nstudies, we find that the time efficiency for a human to annotate rules and\nsentences are similar (0.30 vs. 0.35 min per label). In particular, NERO's\nperformance using 270 rules is comparable to the models trained using 3,000\nlabeled sentences, yielding a 9.5x speedup. Moreover, NERO can predict for\nunseen relations at test time and provide interpretable predictions. We release\nour code to the community for future research.", "published": "2019-09-05 01:50:14", "link": "http://arxiv.org/abs/1909.02177v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Stack-Propagation Framework with Token-Level Intent Detection for\n  Spoken Language Understanding", "abstract": "Intent detection and slot filling are two main tasks for building a spoken\nlanguage understanding (SLU) system. The two tasks are closely tied and the\nslots often highly depend on the intent. In this paper, we propose a novel\nframework for SLU to better incorporate the intent information, which further\nguides the slot filling. In our framework, we adopt a joint model with\nStack-Propagation which can directly use the intent information as input for\nslot filling, thus to capture the intent semantic knowledge. In addition, to\nfurther alleviate the error propagation, we perform the token-level intent\ndetection for the Stack-Propagation framework. Experiments on two publicly\ndatasets show that our model achieves the state-of-the-art performance and\noutperforms other previous methods by a large margin. Finally, we use the\nBidirectional Encoder Representation from Transformer (BERT) model in our\nframework, which further boost our performance in SLU task.", "published": "2019-09-05 02:41:56", "link": "http://arxiv.org/abs/1909.02188v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantics-aware BERT for Language Understanding", "abstract": "The latest work on language representations carefully integrates\ncontextualized features into language model training, which enables a series of\nsuccess especially in various machine reading comprehension and natural\nlanguage inference tasks. However, the existing language representation models\nincluding ELMo, GPT and BERT only exploit plain context-sensitive features such\nas character or word embeddings. They rarely consider incorporating structured\nsemantic information which can provide rich semantics for language\nrepresentation. To promote natural language understanding, we propose to\nincorporate explicit contextual semantics from pre-trained semantic role\nlabeling, and introduce an improved language representation model,\nSemantics-aware BERT (SemBERT), which is capable of explicitly absorbing\ncontextual semantics over a BERT backbone. SemBERT keeps the convenient\nusability of its BERT precursor in a light fine-tuning way without substantial\ntask-specific modifications. Compared with BERT, semantics-aware BERT is as\nsimple in concept but more powerful. It obtains new state-of-the-art or\nsubstantially improves results on ten reading comprehension and language\ninference tasks.", "published": "2019-09-05 04:47:10", "link": "http://arxiv.org/abs/1909.02209v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Granularity Self-Attention for Neural Machine Translation", "abstract": "Current state-of-the-art neural machine translation (NMT) uses a deep\nmulti-head self-attention network with no explicit phrase information. However,\nprior work on statistical machine translation has shown that extending the\nbasic translation unit from words to phrases has produced substantial\nimprovements, suggesting the possibility of improving NMT performance from\nexplicit modeling of phrases. In this work, we present multi-granularity\nself-attention (Mg-Sa): a neural network that combines multi-head\nself-attention and phrase modeling. Specifically, we train several attention\nheads to attend to phrases in either n-gram or syntactic formalism. Moreover,\nwe exploit interactions among phrases to enhance the strength of structure\nmodeling - a commonly-cited weakness of self-attention. Experimental results on\nWMT14 English-to-German and NIST Chinese-to-English translation tasks show the\nproposed approach consistently improves performance. Targeted linguistic\nanalysis reveals that Mg-Sa indeed captures useful phrase information at\nvarious levels of granularities.", "published": "2019-09-05 06:16:23", "link": "http://arxiv.org/abs/1909.02222v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Examining Gender Bias in Languages with Grammatical Gender", "abstract": "Recent studies have shown that word embeddings exhibit gender bias inherited\nfrom the training corpora. However, most studies to date have focused on\nquantifying and mitigating such bias only in English. These analyses cannot be\ndirectly extended to languages that exhibit morphological agreement on gender,\nsuch as Spanish and French. In this paper, we propose new metrics for\nevaluating gender bias in word embeddings of these languages and further\ndemonstrate evidence of gender bias in bilingual embeddings which align these\nlanguages with English. Finally, we extend an existing approach to mitigate\ngender bias in word embeddings under both monolingual and bilingual settings.\nExperiments on modified Word Embedding Association Test, word similarity, word\ntranslation, and word pair translation tasks show that the proposed approaches\neffectively reduce the gender bias while preserving the utility of the\nembeddings.", "published": "2019-09-05 06:20:43", "link": "http://arxiv.org/abs/1909.02224v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-Lingual Dependency Parsing Using Code-Mixed TreeBank", "abstract": "Treebank translation is a promising method for cross-lingual transfer of\nsyntactic dependency knowledge. The basic idea is to map dependency arcs from a\nsource treebank to its target translation according to word alignments. This\nmethod, however, can suffer from imperfect alignment between source and target\nwords. To address this problem, we investigate syntactic transfer by code\nmixing, translating only confident words in a source treebank. Cross-lingual\nword embeddings are leveraged for transferring syntactic knowledge to the\ntarget from the resulting code-mixed treebank. Experiments on University\nDependency Treebanks show that code-mixed treebanks are more effective than\ntranslated treebanks, giving highly competitive performances among\ncross-lingual parsing methods.", "published": "2019-09-05 07:10:44", "link": "http://arxiv.org/abs/1909.02235v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Nested Named Entity Recognition via Second-best Sequence Learning and\n  Decoding", "abstract": "When an entity name contains other names within it, the identification of all\ncombinations of names can become difficult and expensive. We propose a new\nmethod to recognize not only outermost named entities but also inner nested\nones. We design an objective function for training a neural model that treats\nthe tag sequence for nested entities as the second best path within the span of\ntheir parent entity. In addition, we provide the decoding method for inference\nthat extracts entities iteratively from outermost ones to inner ones in an\noutside-to-inside way. Our method has no additional hyperparameters to the\nconditional random field based model widely used for flat named entity\nrecognition tasks. Experiments demonstrate that our method performs better than\nor at least as well as existing methods capable of handling nested entities,\nachieving the F1-scores of 85.82%, 84.34%, and 77.36% on ACE-2004, ACE-2005,\nand GENIA datasets, respectively.", "published": "2019-09-05 07:56:45", "link": "http://arxiv.org/abs/1909.02250v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Task-Oriented Dialogue in Mixed Domains", "abstract": "This work investigates the task-oriented dialogue problem in mixed-domain\nsettings. We study the effect of alternating between different domains in\nsequences of dialogue turns using two related state-of-the-art dialogue\nsystems. We first show that a specialized state tracking component in multiple\ndomains plays an important role and gives better results than an end-to-end\ntask-oriented dialogue system. We then propose a hybrid system which is able to\nimprove the belief tracking accuracy of about 28% of average absolute point on\na standard multi-domain dialogue dataset. These experimental results give some\nuseful insights for improving our commercial chatbot platform FPT.AI, which is\ncurrently deployed for many practical chatbot applications.", "published": "2019-09-05 08:47:49", "link": "http://arxiv.org/abs/1909.02265v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Source Dependency-Aware Transformer with Supervised Self-Attention", "abstract": "Recently, Transformer has achieved the state-of-the-art performance on many\nmachine translation tasks. However, without syntax knowledge explicitly\nconsidered in the encoder, incorrect context information that violates the\nsyntax structure may be integrated into source hidden states, leading to\nerroneous translations. In this paper, we propose a novel method to incorporate\nsource dependencies into the Transformer. Specifically, we adopt the source\ndependency tree and define two matrices to represent the dependency relations.\nBased on the matrices, two heads in the multi-head self-attention module are\ntrained in a supervised manner and two extra cross entropy losses are\nintroduced into the training objective function. Under this training objective,\nthe model is trained to learn the source dependency relations directly. Without\nrequiring pre-parsed input during inference, our model can generate better\ntranslations with the dependency-aware context information. Experiments on\nbi-directional Chinese-to-English, English-to-Japanese and English-to-German\ntranslation tasks show that our proposed method can significantly improve the\nTransformer baseline.", "published": "2019-09-05 09:17:37", "link": "http://arxiv.org/abs/1909.02273v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Accelerating Transformer Decoding via a Hybrid of Self-attention and\n  Recurrent Neural Network", "abstract": "Due to the highly parallelizable architecture, Transformer is faster to train\nthan RNN-based models and popularly used in machine translation tasks. However,\nat inference time, each output word requires all the hidden states of the\npreviously generated words, which limits the parallelization capability, and\nmakes it much slower than RNN-based ones. In this paper, we systematically\nanalyze the time cost of different components of both the Transformer and\nRNN-based model. Based on it, we propose a hybrid network of self-attention and\nRNN structures, in which, the highly parallelizable self-attention is utilized\nas the encoder, and the simpler RNN structure is used as the decoder. Our\nhybrid network can decode 4-times faster than the Transformer. In addition,\nwith the help of knowledge distillation, our hybrid network achieves comparable\ntranslation quality to the original Transformer.", "published": "2019-09-05 09:22:25", "link": "http://arxiv.org/abs/1909.02279v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Table-to-Text Generation with Effective Hierarchical Encoder on Three\n  Dimensions (Row, Column and Time)", "abstract": "Although Seq2Seq models for table-to-text generation have achieved remarkable\nprogress, modeling table representation in one dimension is inadequate. This is\nbecause (1) the table consists of multiple rows and columns, which means that\nencoding a table should not depend only on one dimensional sequence or set of\nrecords and (2) most of the tables are time series data (e.g. NBA game data,\nstock market data), which means that the description of the current table may\nbe affected by its historical data. To address aforementioned problems, not\nonly do we model each table cell considering other records in the same row, we\nalso enrich table's representation by modeling each table cell in context of\nother cells in the same column or with historical (time dimension) data\nrespectively. In addition, we develop a table cell fusion gate to combine\nrepresentations from row, column and time dimension into one dense vector\naccording to the saliency of each dimension's representation. We evaluated our\nmethods on ROTOWIRE, a benchmark dataset of NBA basketball games. Both\nautomatic and human evaluation results demonstrate the effectiveness of our\nmodel with improvement of 2.66 in BLEU over the strong baseline and\noutperformance of state-of-the-art model.", "published": "2019-09-05 10:25:34", "link": "http://arxiv.org/abs/1909.02304v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Informative and Controllable Opinion Summarization", "abstract": "Opinion summarization is the task of automatically generating summaries for a\nset of reviews about a specific target (e.g., a movie or a product). Since the\nnumber of reviews for each target can be prohibitively large, neural\nnetwork-based methods follow a two-stage approach where an extractive step\nfirst pre-selects a subset of salient opinions and an abstractive step creates\nthe summary while conditioning on the extracted subset. However, the extractive\nmodel leads to loss of information which may be useful depending on user needs.\nIn this paper we propose a summarization framework that eliminates the need to\nrely only on pre-selected content and waste possibly useful information,\nespecially when customizing summaries. The framework enables the use of all\ninput reviews by first condensing them into multiple dense vectors which serve\nas input to an abstractive model. We showcase an effective instantiation of our\nframework which produces more informative summaries and also allows to take\nuser preferences into account using our zero-shot customization technique.\nExperimental results demonstrate that our model improves the state of the art\non the Rotten Tomatoes dataset and generates customized summaries effectively.", "published": "2019-09-05 11:11:41", "link": "http://arxiv.org/abs/1909.02322v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Specializing Unsupervised Pretraining Models for Word-Level Semantic\n  Similarity", "abstract": "Unsupervised pretraining models have been shown to facilitate a wide range of\ndownstream NLP applications. These models, however, retain some of the\nlimitations of traditional static word embeddings. In particular, they encode\nonly the distributional knowledge available in raw text corpora, incorporated\nthrough language modeling objectives. In this work, we complement such\ndistributional knowledge with external lexical knowledge, that is, we integrate\nthe discrete knowledge on word-level semantic similarity into pretraining. To\nthis end, we generalize the standard BERT model to a multi-task learning\nsetting where we couple BERT's masked language modeling and next sentence\nprediction objectives with an auxiliary task of binary word relation\nclassification. Our experiments suggest that our \"Lexically Informed\" BERT\n(LIBERT), specialized for the word-level semantic similarity, yields better\nperformance than the lexically blind \"vanilla\" BERT on several language\nunderstanding tasks. Concretely, LIBERT outperforms BERT in 9 out of 10 tasks\nof the GLUE benchmark and is on a par with BERT in the remaining one. Moreover,\nwe show consistent gains on 3 benchmarks for lexical simplification, a task\nwhere knowledge about word-level semantic similarity is paramount.", "published": "2019-09-05 11:49:40", "link": "http://arxiv.org/abs/1909.02339v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rewarding Coreference Resolvers for Being Consistent with World\n  Knowledge", "abstract": "Unresolved coreference is a bottleneck for relation extraction, and\nhigh-quality coreference resolvers may produce an output that makes it a lot\neasier to extract knowledge triples. We show how to improve coreference\nresolvers by forwarding their input to a relation extraction system and reward\nthe resolvers for producing triples that are found in knowledge bases. Since\nrelation extraction systems can rely on different forms of supervision and be\nbiased in different ways, we obtain the best performance, improving over the\nstate of the art, using multi-task reinforcement learning.", "published": "2019-09-05 13:29:26", "link": "http://arxiv.org/abs/1909.02392v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reading Comprehension Ability Test-A Turing Test for Reading\n  Comprehension", "abstract": "Reading comprehension is an important ability of human intelligence. Literacy\nand numeracy are two most essential foundation for people to succeed at study,\nat work and in life. Reading comprehension ability is a core component of\nliteracy. In most of the education systems, developing reading comprehension\nability is compulsory in the curriculum from year one to year 12. It is an\nindispensable ability in the dissemination of knowledge. With the emerging\nartificial intelligence, computers start to be able to read and understand like\npeople in some context. They can even read better than human beings for some\ntasks, but have little clue in other tasks. It will be very beneficial if we\ncan identify the levels of machine comprehension ability, which will direct us\non the further improvement. Turing test is a well-known test of the difference\nbetween computer intelligence and human intelligence. In order to be able to\ncompare the difference between people reading and machines reading, we proposed\na test called (reading) Comprehension Ability Test (CAT).CAT is similar to\nTuring test, passing of which means we cannot differentiate people from\nalgorithms in term of their comprehension ability. CAT has multiple levels\nshowing the different abilities in reading comprehension, from identifying\nbasic facts, performing inference, to understanding the intent and sentiment.", "published": "2019-09-05 13:33:11", "link": "http://arxiv.org/abs/1909.02399v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Discussion on Influence of Newspaper Headlines on Social Media", "abstract": "Newspaper headlines contribute severely and have an influence on the social\nmedia. This work studies the durability of impact of verbs and adjectives on\nheadlines and determine the factors which are responsible for its nature of\ninfluence on the social media. Each headline has been categorized into\npositive, negative or neutral based on its sentiment score. Initial results\nshow that intensity of a sentiment nature is positively correlated with the\nsocial media impression. Additionally, verbs and adjectives show a relation\nwith the sentiment scores", "published": "2019-09-05 15:22:44", "link": "http://arxiv.org/abs/1909.02476v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Robustness to Modification with Shared Words in Paraphrase\n  Identification", "abstract": "Revealing the robustness issues of natural language processing models and\nimproving their robustness is important to their performance under difficult\nsituations. In this paper, we study the robustness of paraphrase identification\nmodels from a new perspective -- via modification with shared words, and we\nshow that the models have significant robustness issues when facing such\nmodifications. To modify an example consisting of a sentence pair, we either\nreplace some words shared by both sentences or introduce new shared words. We\naim to construct a valid new example such that a target model makes a wrong\nprediction. To find a modification solution, we use beam search constrained by\nheuristic rules, and we leverage a BERT masked language model for generating\nsubstitution words compatible with the context. Experiments show that the\nperformance of the target models has a dramatic drop on the modified examples,\nthereby revealing the robustness issue. We also show that adversarial training\ncan mitigate this issue.", "published": "2019-09-05 17:59:15", "link": "http://arxiv.org/abs/1909.02560v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating BERT's Knowledge of Language: Five Analysis Methods with\n  NPIs", "abstract": "Though state-of-the-art sentence representation models can perform tasks\nrequiring significant knowledge of grammar, it is an open question how best to\nevaluate their grammatical knowledge. We explore five experimental methods\ninspired by prior work evaluating pretrained sentence representation models. We\nuse a single linguistic phenomenon, negative polarity item (NPI) licensing in\nEnglish, as a case study for our experiments. NPIs like \"any\" are grammatical\nonly if they appear in a licensing environment like negation (\"Sue doesn't have\nany cats\" vs. \"Sue has any cats\"). This phenomenon is challenging because of\nthe variety of NPI licensing environments that exist. We introduce an\nartificially generated dataset that manipulates key features of NPI licensing\nfor the experiments. We find that BERT has significant knowledge of these\nfeatures, but its success varies widely across different experimental methods.\nWe conclude that a variety of methods is necessary to reveal all relevant\naspects of a model's grammatical knowledge in a given domain.", "published": "2019-09-05 18:58:51", "link": "http://arxiv.org/abs/1909.02597v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Syntax-Aware Aspect Level Sentiment Classification with Graph Attention\n  Networks", "abstract": "Aspect level sentiment classification aims to identify the sentiment\nexpressed towards an aspect given a context sentence. Previous neural network\nbased methods largely ignore the syntax structure in one sentence. In this\npaper, we propose a novel target-dependent graph attention network (TD-GAT) for\naspect level sentiment classification, which explicitly utilizes the dependency\nrelationship among words. Using the dependency graph, it propagates sentiment\nfeatures directly from the syntactic context of an aspect target. In our\nexperiments, we show our method outperforms multiple baselines with GloVe\nembeddings. We also demonstrate that using BERT representations further\nsubstantially boosts the performance.", "published": "2019-09-05 19:20:27", "link": "http://arxiv.org/abs/1909.02606v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Broad-Coverage Semantic Parsing as Transduction", "abstract": "We unify different broad-coverage semantic parsing tasks under a transduction\nparadigm, and propose an attention-based neural framework that incrementally\nbuilds a meaning representation via a sequence of semantic relations. By\nleveraging multiple attention mechanisms, the transducer can be effectively\ntrained without relying on a pre-trained aligner. Experiments conducted on\nthree separate broad-coverage semantic parsing tasks -- AMR, SDP and UCCA --\ndemonstrate that our attention-based neural transducer improves the state of\nthe art on both AMR and UCCA, and is competitive with the state of the art on\nSDP.", "published": "2019-09-05 19:21:27", "link": "http://arxiv.org/abs/1909.02607v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TEASPN: Framework and Protocol for Integrated Writing Assistance\n  Environments", "abstract": "Language technologies play a key role in assisting people with their writing.\nAlthough there has been steady progress in e.g., grammatical error correction\n(GEC), human writers are yet to benefit from this progress due to the high\ndevelopment cost of integrating with writing software. We propose TEASPN, a\nprotocol and an open-source framework for achieving integrated writing\nassistance environments. The protocol standardizes the way writing software\ncommunicates with servers that implement such technologies, allowing developers\nand researchers to integrate the latest developments in natural language\nprocessing (NLP) with low cost. As a result, users can enjoy the integrated\nexperience in their favorite writing software. The results from experiments\nwith human participants show that users use a wide range of technologies and\nrate their writing experience favorably, allowing them to write more fluent\ntext.", "published": "2019-09-05 20:26:10", "link": "http://arxiv.org/abs/1909.02621v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MoverScore: Text Generation Evaluating with Contextualized Embeddings\n  and Earth Mover Distance", "abstract": "A robust evaluation metric has a profound impact on the development of text\ngeneration systems. A desirable metric compares system output against\nreferences based on their semantics rather than surface forms. In this paper we\ninvestigate strategies to encode system and reference texts to devise a metric\nthat shows a high correlation with human judgment of text quality. We validate\nour new metric, namely MoverScore, on a number of text generation tasks\nincluding summarization, machine translation, image captioning, and\ndata-to-text generation, where the outputs are produced by a variety of neural\nand non-neural systems. Our findings suggest that metrics combining\ncontextualized representations with a distance measure perform the best. Such\nmetrics also demonstrate strong generalization capability across tasks. For\nease-of-use we make our metrics available as web service.", "published": "2019-09-05 20:26:44", "link": "http://arxiv.org/abs/1909.02622v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Effective Use of Transformer Networks for Entity Tracking", "abstract": "Tracking entities in procedural language requires understanding the\ntransformations arising from actions on entities as well as those entities'\ninteractions. While self-attention-based pre-trained language encoders like GPT\nand BERT have been successfully applied across a range of natural language\nunderstanding tasks, their ability to handle the nuances of procedural texts is\nstill untested. In this paper, we explore the use of pre-trained transformer\nnetworks for entity tracking tasks in procedural text. First, we test standard\nlightweight approaches for prediction with pre-trained transformers, and find\nthat these approaches underperform even simple baselines. We show that much\nstronger results can be attained by restructuring the input to guide the\ntransformer model to focus on a particular entity. Second, we assess the degree\nto which transformer networks capture the process dynamics, investigating such\nfactors as merged entities and oblique entity references. On two different\ntasks, ingredient detection in recipes and QA over scientific processes, we\nachieve state-of-the-art results, but our models still largely attend to\nshallow context clues and do not form complex representations of intermediate\nentity or process state.", "published": "2019-09-05 21:13:37", "link": "http://arxiv.org/abs/1909.02635v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "In Plain Sight: Media Bias Through the Lens of Factual Reporting", "abstract": "The increasing prevalence of political bias in news media calls for greater\npublic awareness of it, as well as robust methods for its detection. While\nprior work in NLP has primarily focused on the lexical bias captured by\nlinguistic attributes such as word choice and syntax, other types of bias stem\nfrom the actual content selected for inclusion in the text. In this work, we\ninvestigate the effects of informational bias: factual content that can\nnevertheless be deployed to sway reader opinion. We first produce a new\ndataset, BASIL, of 300 news articles annotated with 1,727 bias spans and find\nevidence that informational bias appears in news articles more frequently than\nlexical bias. We further study our annotations to observe how informational\nbias surfaces in news articles by different media outlets. Lastly, a baseline\nmodel for informational bias prediction is presented by fine-tuning BERT on our\nlabeled data, indicating the challenges of the task and future directions.", "published": "2019-09-05 23:20:29", "link": "http://arxiv.org/abs/1909.02670v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TabFact: A Large-scale Dataset for Table-based Fact Verification", "abstract": "The problem of verifying whether a textual hypothesis holds based on the\ngiven evidence, also known as fact verification, plays an important role in the\nstudy of natural language understanding and semantic representation. However,\nexisting studies are mainly restricted to dealing with unstructured evidence\n(e.g., natural language sentences and documents, news, etc), while verification\nunder structured evidence, such as tables, graphs, and databases, remains\nunder-explored. This paper specifically aims to study the fact verification\ngiven semi-structured data as evidence. To this end, we construct a large-scale\ndataset called TabFact with 16k Wikipedia tables as the evidence for 118k\nhuman-annotated natural language statements, which are labeled as either\nENTAILED or REFUTED. TabFact is challenging since it involves both soft\nlinguistic reasoning and hard symbolic reasoning. To address these reasoning\nchallenges, we design two different models: Table-BERT and Latent Program\nAlgorithm (LPA). Table-BERT leverages the state-of-the-art pre-trained language\nmodel to encode the linearized tables and statements into continuous vectors\nfor verification. LPA parses statements into programs and executes them against\nthe tables to obtain the returned binary value for verification. Both methods\nachieve similar accuracy but still lag far behind human performance. We also\nperform a comprehensive analysis to demonstrate great future opportunities. The\ndata and code of the dataset are provided in\n\\url{https://github.com/wenhuchen/Table-Fact-Checking}.", "published": "2019-09-05 00:25:17", "link": "http://arxiv.org/abs/1909.02164v5", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Automated Let's Play Commentary", "abstract": "Let's Plays of video games represent a relatively unexplored area for\nexperimental AI in games. In this short paper, we discuss an approach to\ngenerate automated commentary for Let's Play videos, drawing on convolutional\ndeep neural networks. We focus on Let's Plays of the popular game Minecraft. We\ncompare our approach and a prior approach and demonstrate the generation of\nautomated, artificial commentary.", "published": "2019-09-05 03:30:26", "link": "http://arxiv.org/abs/1909.02195v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Investigating Multilingual NMT Representations at Scale", "abstract": "Multilingual Neural Machine Translation (NMT) models have yielded large\nempirical success in transfer learning settings. However, these black-box\nrepresentations are poorly understood, and their mode of transfer remains\nelusive. In this work, we attempt to understand massively multilingual NMT\nrepresentations (with 103 languages) using Singular Value Canonical Correlation\nAnalysis (SVCCA), a representation similarity framework that allows us to\ncompare representations across different languages, layers and models. Our\nanalysis validates several empirical results and long-standing intuitions, and\nunveils new observations regarding how representations evolve in a multilingual\ntranslation model. We draw three major conclusions from our analysis, with\nimplications on cross-lingual transfer learning: (i) Encoder representations of\ndifferent languages cluster based on linguistic similarity, (ii)\nRepresentations of a source language learned by the encoder are dependent on\nthe target language, and vice-versa, and (iii) Representations of high resource\nand/or linguistically similar languages are more robust when fine-tuning on an\narbitrary language pair, which is critical to determining how much\ncross-lingual transfer can be expected in a zero or few-shot setting. We\nfurther connect our findings with existing empirical observations in\nmultilingual NMT and transfer learning.", "published": "2019-09-05 03:32:48", "link": "http://arxiv.org/abs/1909.02197v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Image Captioning with Very Scarce Supervised Data: Adversarial\n  Semi-Supervised Learning Approach", "abstract": "Constructing an organized dataset comprised of a large number of images and\nseveral captions for each image is a laborious task, which requires vast human\neffort. On the other hand, collecting a large number of images and sentences\nseparately may be immensely easier. In this paper, we develop a novel\ndata-efficient semi-supervised framework for training an image captioning\nmodel. We leverage massive unpaired image and caption data by learning to\nassociate them. To this end, our proposed semi-supervised learning method\nassigns pseudo-labels to unpaired samples via Generative Adversarial Networks\nto learn the joint distribution of image and caption. To evaluate, we construct\nscarcely-paired COCO dataset, a modified version of MS COCO caption dataset.\nThe empirical results show the effectiveness of our method compared to several\nstrong baselines, especially when the amount of the paired samples are scarce.", "published": "2019-09-05 04:16:48", "link": "http://arxiv.org/abs/1909.02201v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "REO-Relevance, Extraness, Omission: A Fine-grained Evaluation for Image\n  Captioning", "abstract": "Popular metrics used for evaluating image captioning systems, such as BLEU\nand CIDEr, provide a single score to gauge the system's overall effectiveness.\nThis score is often not informative enough to indicate what specific errors are\nmade by a given system. In this study, we present a fine-grained evaluation\nmethod REO for automatically measuring the performance of image captioning\nsystems. REO assesses the quality of captions from three perspectives: 1)\nRelevance to the ground truth, 2) Extraness of the content that is irrelevant\nto the ground truth, and 3) Omission of the elements in the images and human\nreferences. Experiments on three benchmark datasets demonstrate that our method\nachieves a higher consistency with human judgments and provides more intuitive\nevaluation results than alternative metrics.", "published": "2019-09-05 05:44:46", "link": "http://arxiv.org/abs/1909.02217v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Commonsense Reasoning Using WordNet and SUMO: a Detailed Analysis", "abstract": "We describe a detailed analysis of a sample of large benchmark of commonsense\nreasoning problems that has been automatically obtained from WordNet, SUMO and\ntheir mapping. The objective is to provide a better assessment of the quality\nof both the benchmark and the involved knowledge resources for advanced\ncommonsense reasoning tasks. By means of this analysis, we are able to detect\nsome knowledge misalignments, mapping errors and lack of knowledge and\nresources. Our final objective is the extraction of some guidelines towards a\nbetter exploitation of this commonsense knowledge framework by the improvement\nof the included resources.", "published": "2019-09-05 10:54:03", "link": "http://arxiv.org/abs/1909.02314v2", "categories": ["cs.AI", "cs.CL", "68T30", "I.2.4"], "primary_category": "cs.AI"}
{"title": "FlowSeq: Non-Autoregressive Conditional Sequence Generation with\n  Generative Flow", "abstract": "Most sequence-to-sequence (seq2seq) models are autoregressive; they generate\neach token by conditioning on previously generated tokens. In contrast,\nnon-autoregressive seq2seq models generate all tokens in one pass, which leads\nto increased efficiency through parallel processing on hardware such as GPUs.\nHowever, directly modeling the joint distribution of all tokens simultaneously\nis challenging, and even with increasingly complex model structures accuracy\nlags significantly behind autoregressive models. In this paper, we propose a\nsimple, efficient, and effective model for non-autoregressive sequence\ngeneration using latent variable models. Specifically, we turn to generative\nflow, an elegant technique to model complex distributions using neural\nnetworks, and design several layers of flow tailored for modeling the\nconditional density of sequential latent variables. We evaluate this model on\nthree neural machine translation (NMT) benchmark datasets, achieving comparable\nperformance with state-of-the-art non-autoregressive NMT models and almost\nconstant decoding time w.r.t the sequence length.", "published": "2019-09-05 15:32:34", "link": "http://arxiv.org/abs/1909.02480v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Stack-VS: Stacked Visual-Semantic Attention for Image Caption Generation", "abstract": "Recently, automatic image caption generation has been an important focus of\nthe work on multimodal translation task. Existing approaches can be roughly\ncategorized into two classes, i.e., top-down and bottom-up, the former\ntransfers the image information (called as visual-level feature) directly into\na caption, and the later uses the extracted words (called as semanticlevel\nattribute) to generate a description. However, previous methods either are\ntypically based one-stage decoder or partially utilize part of visual-level or\nsemantic-level information for image caption generation. In this paper, we\naddress the problem and propose an innovative multi-stage architecture (called\nas Stack-VS) for rich fine-gained image caption generation, via combining\nbottom-up and top-down attention models to effectively handle both visual-level\nand semantic-level information of an input image. Specifically, we also propose\na novel well-designed stack decoder model, which is constituted by a sequence\nof decoder cells, each of which contains two LSTM-layers work interactively to\nre-optimize attention weights on both visual-level feature vectors and\nsemantic-level attribute embeddings for generating a fine-gained image caption.\nExtensive experiments on the popular benchmark dataset MSCOCO show the\nsignificant improvements on different evaluation metrics, i.e., the\nimprovements on BLEU-4/CIDEr/SPICE scores are 0.372, 1.226 and 0.216,\nrespectively, as compared to the state-of-the-arts.", "published": "2019-09-05 15:41:53", "link": "http://arxiv.org/abs/1909.02489v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Identifying and Explaining Discriminative Attributes", "abstract": "Identifying what is at the center of the meaning of a word and what\ndiscriminates it from other words is a fundamental natural language inference\ntask. This paper describes an explicit word vector representation model (WVM)\nto support the identification of discriminative attributes. A core contribution\nof the paper is a quantitative and qualitative comparative analysis of\ndifferent types of data sources and Knowledge Bases in the construction of\nexplainable and explicit WVMs: (i) knowledge graphs built from dictionary\ndefinitions, (ii) entity-attribute-relationships graphs derived from images and\n(iii) commonsense knowledge graphs. Using a detailed quantitative and\nqualitative analysis, we demonstrate that these data sources have complementary\nsemantic aspects, supporting the creation of explicit semantic vector spaces.\nThe explicit vector spaces are evaluated using the task of discriminative\nattribute identification, showing comparable performance to the\nstate-of-the-art systems in the task (F1-score = 0.69), while delivering full\nmodel transparency and explainability.", "published": "2019-09-05 01:13:41", "link": "http://arxiv.org/abs/1909.05363v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "TransSent: Towards Generation of Structured Sentences with Discourse\n  Marker", "abstract": "Structured sentences are important expressions in human writings and\ndialogues. Previous works on neural text generation fused semantic and\nstructural information by encoding the entire sentence into a mixed hidden\nrepresentation. However, when a generated sentence becomes complicated, the\nstructure is difficult to be properly maintained. To alleviate this problem, we\nexplicitly separate the modeling process of semantic and structural\ninformation. Intuitively, humans generate structured sentences by directly\nconnecting discourses with discourse markers (such as and, but, etc.).\nTherefore, we propose a task that mimics this process, called discourse\ntransfer. This task represents a structured sentence as (head discourse,\ndiscourse marker, tail discourse), and aims at tail discourse generation based\non head discourse and discourse marker. We also propose a corresponding model\ncalled TransSent, which interprets the relationship between two discourses as a\ntranslation1 from the head discourse to the tail discourse in the embedding\nspace. We experiment TransSent not only in discourse transfer task but also in\nfree text generation and dialogue generation tasks. Automatic and human\nevaluation results show that TransSent can generate structured sentences with\nhigh quality, and has certain scalability in different tasks.", "published": "2019-09-05 14:03:35", "link": "http://arxiv.org/abs/1909.05364v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Better Way to Attend: Attention with Trees for Video Question\n  Answering", "abstract": "We propose a new attention model for video question answering. The main idea\nof the attention models is to locate on the most informative parts of the\nvisual data. The attention mechanisms are quite popular these days. However,\nmost existing visual attention mechanisms regard the question as a whole. They\nignore the word-level semantics where each word can have different attentions\nand some words need no attention. Neither do they consider the semantic\nstructure of the sentences. Although the Extended Soft Attention (E-SA) model\nfor video question answering leverages the word-level attention, it performs\npoorly on long question sentences. In this paper, we propose the heterogeneous\ntree-structured memory network (HTreeMN) for video question answering. Our\nproposed approach is based upon the syntax parse trees of the question\nsentences. The HTreeMN treats the words differently where the \\textit{visual}\nwords are processed with an attention module and the \\textit{verbal} ones not.\nIt also utilizes the semantic structure of the sentences by combining the\nneighbors based on the recursive structure of the parse trees. The\nunderstandings of the words and the videos are propagated and merged from\nleaves to the root. Furthermore, we build a hierarchical attention mechanism to\ndistill the attended features. We evaluate our approach on two datasets. The\nexperimental results show the superiority of our HTreeMN model over the other\nattention models especially on complex questions. Our code is available on\ngithub.\n  Our code is available at https://github.com/ZJULearning/TreeAttention", "published": "2019-09-05 05:48:51", "link": "http://arxiv.org/abs/1909.02218v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Robust Navigation with Language Pretraining and Stochastic Sampling", "abstract": "Core to the vision-and-language navigation (VLN) challenge is building robust\ninstruction representations and action decoding schemes, which can generalize\nwell to previously unseen instructions and environments. In this paper, we\nreport two simple but highly effective methods to address these challenges and\nlead to a new state-of-the-art performance. First, we adapt large-scale\npretrained language models to learn text representations that generalize better\nto previously unseen instructions. Second, we propose a stochastic sampling\nscheme to reduce the considerable gap between the expert actions in training\nand sampled actions in test, so that the agent can learn to correct its own\nmistakes during long sequential action decoding. Combining the two techniques,\nwe achieve a new state of the art on the Room-to-Room benchmark with 6%\nabsolute gain over the previous best result (47% -> 53%) on the Success Rate\nweighted by Path Length metric.", "published": "2019-09-05 07:31:58", "link": "http://arxiv.org/abs/1909.02244v1", "categories": ["cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fusing Vector Space Models for Domain-Specific Applications", "abstract": "We address the problem of tuning word embeddings for specific use cases and\ndomains. We propose a new method that automatically combines multiple\ndomain-specific embeddings, selected from a wide range of pre-trained\ndomain-specific embeddings, to improve their combined expressive power. Our\napproach relies on two key components: 1) a ranking function, based on a new\nembedding similarity measure, that selects the most relevant embeddings to use\ngiven a domain and 2) a dimensionality reduction method that combines the\nselected embeddings to produce a more compact and efficient encoding that\npreserves the expressiveness. We empirically show that our method produces\neffective domain-specific embeddings that consistently improve the performance\nof state-of-the-art machine learning algorithms on multiple tasks, compared to\ngeneric embeddings trained on large text corpora.", "published": "2019-09-05 10:34:07", "link": "http://arxiv.org/abs/1909.02307v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Bandwidth Embeddings for Mixed-bandwidth Speech Recognition", "abstract": "In this paper, we tackle the problem of handling narrowband and wideband\nspeech by building a single acoustic model (AM), also called mixed bandwidth\nAM. In the proposed approach, an auxiliary input feature is used to provide the\nbandwidth information to the model, and bandwidth embeddings are jointly\nlearned as part of acoustic model training. Experimental evaluations show that\nusing bandwidth embeddings helps the model to handle the variability of the\nnarrow and wideband speech, and makes it possible to train a mixed-bandwidth\nAM. Furthermore, we propose to use parallel convolutional layers to handle the\nmismatch between the narrow and wideband speech better, where separate\nconvolution layers are used for each type of input speech signal. Our best\nsystem achieves 13% relative improvement on narrowband speech, while not\ndegrading on wideband speech.", "published": "2019-09-05 23:07:26", "link": "http://arxiv.org/abs/1909.02667v1", "categories": ["eess.AS", "cs.CL", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Receptive-field-regularized CNN variants for acoustic scene\n  classification", "abstract": "Acoustic scene classification and related tasks have been dominated by\nConvolutional Neural Networks (CNNs). Top-performing CNNs use mainly audio\nspectograms as input and borrow their architectural design primarily from\ncomputer vision. A recent study has shown that restricting the receptive field\n(RF) of CNNs in appropriate ways is crucial for their performance, robustness\nand generalization in audio tasks. One side effect of restricting the RF of\nCNNs is that more frequency information is lost. In this paper, we perform a\nsystematic investigation of different RF configuration for various CNN\narchitectures on the DCASE 2019 Task 1.A dataset. Second, we introduce\nFrequency Aware CNNs to compensate for the lack of frequency information caused\nby the restricted RF, and experimentally determine if and in what RF ranges\nthey yield additional improvement. The result of these investigations are\nseveral well-performing submissions to different tasks in the DCASE 2019\nChallenge.", "published": "2019-09-05 12:40:38", "link": "http://arxiv.org/abs/1909.02859v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
