{"title": "An Iterative Transfer Learning Based Ensemble Technique for Automatic\n  Short Answer Grading", "abstract": "Automatic short answer grading (ASAG) techniques are designed to\nautomatically assess short answers to questions in natural language, having a\nlength of a few words to a few sentences. Supervised ASAG techniques have been\ndemonstrated to be effective but suffer from a couple of key practical\nlimitations. They are greatly reliant on instructor provided model answers and\nneed labeled training data in the form of graded student answers for every\nassessment task. To overcome these, in this paper, we introduce an ASAG\ntechnique with two novel features. We propose an iterative technique on an\nensemble of (a) a text classifier of student answers and (b) a classifier using\nnumeric features derived from various similarity measures with respect to model\nanswers. Second, we employ canonical correlation analysis based transfer\nlearning on a common feature representation to build the classifier ensemble\nfor questions having no labelled data. The proposed technique handsomely beats\nall winning supervised entries on the SCIENTSBANK dataset from the Student\nResponse Analysis task of SemEval 2013. Additionally, we demonstrate\ngeneralizability and benefits of the proposed technique through evaluation on\nmultiple ASAG datasets from different subject topics and standards.", "published": "2016-09-16 04:58:54", "link": "http://arxiv.org/abs/1609.04909v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Intrinsic normalization and extrinsic denormalization of formant data of\n  vowels", "abstract": "Using a known speaker-intrinsic normalization procedure, formant data are\nscaled by the reciprocal of the geometric mean of the first three formant\nfrequencies. This reduces the influence of the talker but results in a\ndistorted vowel space. The proposed speaker-extrinsic procedure re-scales the\nnormalized values by the mean formant values of vowels. When tested on the\nformant data of vowels published by Peterson and Barney, the combined approach\nleads to well separated clusters by reducing the spread due to talkers. The\nproposed procedure performs better than two top-ranked normalization procedures\nbased on the accuracy of vowel classification as the objective measure.", "published": "2016-09-16 15:20:32", "link": "http://arxiv.org/abs/1609.05104v2", "categories": ["cs.SD", "cs.CL"], "primary_category": "cs.SD"}
{"title": "Grammatical Templates: Improving Text Difficulty Evaluation for Language\n  Learners", "abstract": "Language students are most engaged while reading texts at an appropriate\ndifficulty level. However, existing methods of evaluating text difficulty focus\nmainly on vocabulary and do not prioritize grammatical features, hence they do\nnot work well for language learners with limited knowledge of grammar. In this\npaper, we introduce grammatical templates, the expert-identified units of\ngrammar that students learn from class, as an important feature of text\ndifficulty evaluation. Experimental classification results show that\ngrammatical template features significantly improve text difficulty prediction\naccuracy over baseline readability features by 7.4%. Moreover, we build a\nsimple and human-understandable text difficulty evaluation approach with 87.7%\naccuracy, using only 5 grammatical template features.", "published": "2016-09-16 19:12:30", "link": "http://arxiv.org/abs/1609.05180v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Interactive Spoken Content Retrieval by Deep Reinforcement Learning", "abstract": "User-machine interaction is important for spoken content retrieval. For text\ncontent retrieval, the user can easily scan through and select on a list of\nretrieved item. This is impossible for spoken content retrieval, because the\nretrieved items are difficult to show on screen. Besides, due to the high\ndegree of uncertainty for speech recognition, the retrieval results can be very\nnoisy. One way to counter such difficulties is through user-machine\ninteraction. The machine can take different actions to interact with the user\nto obtain better retrieval results before showing to the user. The suitable\nactions depend on the retrieval status, for example requesting for extra\ninformation from the user, returning a list of topics for user to select, etc.\nIn our previous work, some hand-crafted states estimated from the present\nretrieval results are used to determine the proper actions. In this paper, we\npropose to use Deep-Q-Learning techniques instead to determine the machine\nactions for interactive spoken content retrieval. Deep-Q-Learning bypasses the\nneed for estimation of the hand-crafted states, and directly determine the best\naction base on the present retrieval status even without any human knowledge.\nIt is shown to achieve significantly better performance compared with the\nprevious hand-crafted states.", "published": "2016-09-16 20:56:22", "link": "http://arxiv.org/abs/1609.05234v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Select-Additive Learning: Improving Generalization in Multimodal\n  Sentiment Analysis", "abstract": "Multimodal sentiment analysis is drawing an increasing amount of attention\nthese days. It enables mining of opinions in video reviews which are now\navailable aplenty on online platforms. However, multimodal sentiment analysis\nhas only a few high-quality data sets annotated for training machine learning\nalgorithms. These limited resources restrict the generalizability of models,\nwhere, for example, the unique characteristics of a few speakers (e.g., wearing\nglasses) may become a confounding factor for the sentiment classification task.\nIn this paper, we propose a Select-Additive Learning (SAL) procedure that\nimproves the generalizability of trained neural networks for multimodal\nsentiment analysis. In our experiments, we show that our SAL approach improves\nprediction accuracy significantly in all three modalities (verbal, acoustic,\nvisual), as well as in their fusion. Our results show that SAL, even when\ntrained on one dataset, achieves good generalization across two new test\ndatasets.", "published": "2016-09-16 21:33:42", "link": "http://arxiv.org/abs/1609.05244v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Long-Term Trends in the Public Perception of Artificial Intelligence", "abstract": "Analyses of text corpora over time can reveal trends in beliefs, interest,\nand sentiment about a topic. We focus on views expressed about artificial\nintelligence (AI) in the New York Times over a 30-year period. General\ninterest, awareness, and discussion about AI has waxed and waned since the\nfield was founded in 1956. We present a set of measures that captures levels of\nengagement, measures of pessimism and optimism, the prevalence of specific\nhopes and concerns, and topics that are linked to discussions about AI over\ndecades. We find that discussion of AI has increased sharply since 2009, and\nthat these discussions have been consistently more optimistic than pessimistic.\nHowever, when we examine specific concerns, we find that worries of loss of\ncontrol of AI, ethical concerns for AI, and the negative impact of AI on work\nhave grown in recent years. We also find that hopes for AI in healthcare and\neducation have increased over time.", "published": "2016-09-16 03:45:15", "link": "http://arxiv.org/abs/1609.04904v2", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Image-to-Markup Generation with Coarse-to-Fine Attention", "abstract": "We present a neural encoder-decoder model to convert images into\npresentational markup based on a scalable coarse-to-fine attention mechanism.\nOur method is evaluated in the context of image-to-LaTeX generation, and we\nintroduce a new dataset of real-world rendered mathematical expressions paired\nwith LaTeX markup. We show that unlike neural OCR techniques using CTC-based\nmodels, attention-based approaches can tackle this non-standard OCR task. Our\napproach outperforms classical mathematical OCR systems by a large margin on\nin-domain rendered data, and, with pretraining, also performs well on\nout-of-domain handwritten data. To reduce the inference complexity associated\nwith the attention-based approaches, we introduce a new coarse-to-fine\nattention layer that selects a support region before applying attention.", "published": "2016-09-16 08:14:50", "link": "http://arxiv.org/abs/1609.04938v2", "categories": ["cs.CV", "cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CV"}
