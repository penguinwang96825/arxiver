{"title": "Model ensemble instead of prompt fusion: a sample-specific knowledge\n  transfer method for few-shot prompt tuning", "abstract": "Prompt tuning approaches, which learn task-specific soft prompts for a\ndownstream task conditioning on frozen pre-trained models, have attracted\ngrowing interest due to its parameter efficiency. With large language models\nand sufficient training data, prompt tuning performs comparably to full-model\ntuning. However, with limited training samples in few-shot settings, prompt\ntuning fails to match the performance of full-model fine-tuning. In this work,\nwe focus on improving the few-shot performance of prompt tuning by transferring\nknowledge from soft prompts of source tasks. Recognizing the good\ngeneralization capabilities of ensemble methods in low-data regime, we first\nexperiment and show that a simple ensemble of model predictions based on\ndifferent source prompts, outperforms existing multi-prompt knowledge transfer\napproaches such as source prompt fusion in the few-shot setting. Motivated by\nthis observation, we further investigate model ensembles and propose\nSample-specific Ensemble of Source Models (SESoM). SESoM learns to adjust the\ncontribution of each source model for each target sample separately when\nensembling source model outputs. Through this way, SESoM inherits the superior\ngeneralization of model ensemble approaches and simultaneously captures the\nsample-specific competence of each source prompt. We conduct experiments across\na diverse set of eight NLP tasks using models of different scales (T5-{base,\nlarge, XL}) and find that SESoM consistently outperforms the existing models of\nthe same as well as larger parametric scale by a large margin.", "published": "2022-10-23 01:33:16", "link": "http://arxiv.org/abs/2210.12587v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modal-specific Pseudo Query Generation for Video Corpus Moment Retrieval", "abstract": "Video corpus moment retrieval (VCMR) is the task to retrieve the most\nrelevant video moment from a large video corpus using a natural language query.\nFor narrative videos, e.g., dramas or movies, the holistic understanding of\ntemporal dynamics and multimodal reasoning is crucial. Previous works have\nshown promising results; however, they relied on the expensive query\nannotations for VCMR, i.e., the corresponding moment intervals. To overcome\nthis problem, we propose a self-supervised learning framework: Modal-specific\nPseudo Query Generation Network (MPGN). First, MPGN selects candidate temporal\nmoments via subtitle-based moment sampling. Then, it generates pseudo queries\nexploiting both visual and textual information from the selected temporal\nmoments. Through the multimodal information in the pseudo queries, we show that\nMPGN successfully learns to localize the video corpus moment without any\nexplicit annotation. We validate the effectiveness of MPGN on the TVR dataset,\nshowing competitive results compared with both supervised models and\nunsupervised setting models.", "published": "2022-10-23 05:05:18", "link": "http://arxiv.org/abs/2210.12617v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Conformal Predictor for Improving Zero-shot Text Classification\n  Efficiency", "abstract": "Pre-trained language models (PLMs) have been shown effective for zero-shot\n(0shot) text classification. 0shot models based on natural language inference\n(NLI) and next sentence prediction (NSP) employ cross-encoder architecture and\ninfer by making a forward pass through the model for each label-text pair\nseparately. This increases the computational cost to make inferences linearly\nin the number of labels. In this work, we improve the efficiency of such\ncross-encoder-based 0shot models by restricting the number of likely labels\nusing another fast base classifier-based conformal predictor (CP) calibrated on\nsamples labeled by the 0shot model. Since a CP generates prediction sets with\ncoverage guarantees, it reduces the number of target labels without excluding\nthe most probable label based on the 0shot model. We experiment with three\nintent and two topic classification datasets. With a suitable CP for each\ndataset, we reduce the average inference time for NLI- and NSP-based models by\n25.6% and 22.2% respectively, without dropping performance below the predefined\nerror rate of 1%.", "published": "2022-10-23 05:19:50", "link": "http://arxiv.org/abs/2210.12619v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Model and Data Transfer for Cross-Lingual Sequence Labelling in\n  Zero-Resource Settings", "abstract": "Zero-resource cross-lingual transfer approaches aim to apply supervised\nmodels from a source language to unlabelled target languages. In this paper we\nperform an in-depth study of the two main techniques employed so far for\ncross-lingual zero-resource sequence labelling, based either on data or model\ntransfer. Although previous research has proposed translation and annotation\nprojection (data-based cross-lingual transfer) as an effective technique for\ncross-lingual sequence labelling, in this paper we experimentally demonstrate\nthat high capacity multilingual language models applied in a zero-shot\n(model-based cross-lingual transfer) setting consistently outperform data-based\ncross-lingual transfer approaches. A detailed analysis of our results suggests\nthat this might be due to important differences in language use. More\nspecifically, machine translation often generates a textual signal which is\ndifferent to what the models are exposed to when using gold standard data,\nwhich affects both the fine-tuning and evaluation processes. Our results also\nindicate that data-based cross-lingual transfer approaches remain a competitive\noption when high-capacity multilingual language models are not available.", "published": "2022-10-23 05:37:35", "link": "http://arxiv.org/abs/2210.12623v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-document Event Coreference Search: Task, Dataset and Modeling", "abstract": "The task of Cross-document Coreference Resolution has been traditionally\nformulated as requiring to identify all coreference links across a given set of\ndocuments. We propose an appealing, and often more applicable, complementary\nset up for the task - Cross-document Coreference Search, focusing in this paper\non event coreference. Concretely, given a mention in context of an event of\ninterest, considered as a query, the task is to find all coreferring mentions\nfor the query event in a large document collection. To support research on this\ntask, we create a corresponding dataset, which is derived from Wikipedia while\nleveraging annotations in the available Wikipedia Event Coreference dataset\n(WEC-Eng). Observing that the coreference search setup is largely analogous to\nthe setting of Open Domain Question Answering, we adapt the prominent Deep\nPassage Retrieval (DPR) model to our setting, as an appealing baseline.\nFinally, we present a novel model that integrates a powerful coreference\nscoring scheme into the DPR architecture, yielding improved performance.", "published": "2022-10-23 08:21:25", "link": "http://arxiv.org/abs/2210.12654v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lexical Generalization Improves with Larger Models and Longer Training", "abstract": "While fine-tuned language models perform well on many tasks, they were also\nshown to rely on superficial surface features such as lexical overlap.\nExcessive utilization of such heuristics can lead to failure on challenging\ninputs. We analyze the use of lexical overlap heuristics in natural language\ninference, paraphrase detection, and reading comprehension (using a novel\ncontrastive dataset), and find that larger models are much less susceptible to\nadopting lexical overlap heuristics. We also find that longer training leads\nmodels to abandon lexical overlap heuristics. Finally, we provide evidence that\nthe disparity between models size has its source in the pre-trained model", "published": "2022-10-23 09:20:11", "link": "http://arxiv.org/abs/2210.12673v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Generalizable and Robust Text-to-SQL Parsing", "abstract": "Text-to-SQL parsing tackles the problem of mapping natural language questions\nto executable SQL queries. In practice, text-to-SQL parsers often encounter\nvarious challenging scenarios, requiring them to be generalizable and robust.\nWhile most existing work addresses a particular generalization or robustness\nchallenge, we aim to study it in a more comprehensive manner. In specific, we\nbelieve that text-to-SQL parsers should be (1) generalizable at three levels of\ngeneralization, namely i.i.d., zero-shot, and compositional, and (2) robust\nagainst input perturbations. To enhance these capabilities of the parser, we\npropose a novel TKK framework consisting of Task decomposition, Knowledge\nacquisition, and Knowledge composition to learn text-to-SQL parsing in stages.\nBy dividing the learning process into multiple stages, our framework improves\nthe parser's ability to acquire general SQL knowledge instead of capturing\nspurious patterns, making it more generalizable and robust. Experimental\nresults under various generalization and robustness settings show that our\nframework is effective in all scenarios and achieves state-of-the-art\nperformance on the Spider, SParC, and CoSQL datasets. Code can be found at\nhttps://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/tkk.", "published": "2022-10-23 09:21:27", "link": "http://arxiv.org/abs/2210.12674v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ComFact: A Benchmark for Linking Contextual Commonsense Knowledge", "abstract": "Understanding rich narratives, such as dialogues and stories, often requires\nnatural language processing systems to access relevant knowledge from\ncommonsense knowledge graphs. However, these systems typically retrieve facts\nfrom KGs using simple heuristics that disregard the complex challenges of\nidentifying situationally-relevant commonsense knowledge (e.g.,\ncontextualization, implicitness, ambiguity).\n  In this work, we propose the new task of commonsense fact linking, where\nmodels are given contexts and trained to identify situationally-relevant\ncommonsense knowledge from KGs. Our novel benchmark, ComFact, contains ~293k\nin-context relevance annotations for commonsense triplets across four\nstylistically diverse dialogue and storytelling datasets. Experimental results\nconfirm that heuristic fact linking approaches are imprecise knowledge\nextractors. Learned fact linking models demonstrate across-the-board\nperformance improvements (~34.6% F1) over these heuristics. Furthermore,\nimproved knowledge retrieval yielded average downstream improvements of 9.8%\nfor a dialogue response generation task. However, fact linking models still\nsignificantly underperform humans, suggesting our benchmark is a promising\ntestbed for research in commonsense augmentation of NLP systems.", "published": "2022-10-23 09:30:39", "link": "http://arxiv.org/abs/2210.12678v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How \"Multi\" is Multi-Document Summarization?", "abstract": "The task of multi-document summarization (MDS) aims at models that, given\nmultiple documents as input, are able to generate a summary that combines\ndisperse information, originally spread across these documents. Accordingly, it\nis expected that both reference summaries in MDS datasets, as well as system\nsummaries, would indeed be based on such dispersed information. In this paper,\nwe argue for quantifying and assessing this expectation. To that end, we\npropose an automated measure for evaluating the degree to which a summary is\n``disperse'', in the sense of the number of source documents needed to cover\nits content. We apply our measure to empirically analyze several popular MDS\ndatasets, with respect to their reference summaries, as well as the output of\nstate-of-the-art systems. Our results show that certain MDS datasets barely\nrequire combining information from multiple documents, where a single document\noften covers the full summary content. Overall, we advocate using our metric\nfor assessing and improving the degree to which summarization datasets require\ncombining multi-document information, and similarly how summarization models\nactually meet this challenge. Our code is available in\nhttps://github.com/ariecattan/multi_mds.", "published": "2022-10-23 10:20:09", "link": "http://arxiv.org/abs/2210.12688v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Focus Is What You Need For Chinese Grammatical Error Correction", "abstract": "Chinese Grammatical Error Correction (CGEC) aims to automatically detect and\ncorrect grammatical errors contained in Chinese text. In the long term,\nresearchers regard CGEC as a task with a certain degree of uncertainty, that\nis, an ungrammatical sentence may often have multiple references. However, we\nargue that even though this is a very reasonable hypothesis, it is too harsh\nfor the intelligence of the mainstream models in this era. In this paper, we\nfirst discover that multiple references do not actually bring positive gains to\nmodel training. On the contrary, it is beneficial to the CGEC model if the\nmodel can pay attention to small but essential data during the training\nprocess. Furthermore, we propose a simple yet effective training strategy\ncalled OneTarget to improve the focus ability of the CGEC models and thus\nimprove the CGEC performance. Extensive experiments and detailed analyses\ndemonstrate the correctness of our discovery and the effectiveness of our\nproposed method.", "published": "2022-10-23 10:44:50", "link": "http://arxiv.org/abs/2210.12692v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do Language Models Understand Measurements?", "abstract": "Recent success of pre-trained language models (PLMs) has stimulated interest\nin their ability to understand and work with numbers. Yet, the numerical\nreasoning over measurements has not been formally studied despite their\nimportance. In this study, we show that PLMs lack the capability required for\nreasoning over measurements. Furthermore, we find that a language model trained\non a measurement-rich corpus shows better performance on understanding\nmeasurements. We propose a simple embedding strategy to better distinguish\nbetween numbers and units, which leads to a significant improvement in the\nprobing tasks.", "published": "2022-10-23 10:52:52", "link": "http://arxiv.org/abs/2210.12694v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Transformation of Latent Space in Fine-Tuned NLP Models", "abstract": "We study the evolution of latent space in fine-tuned NLP models. Different\nfrom the commonly used probing-framework, we opt for an unsupervised method to\nanalyze representations. More specifically, we discover latent concepts in the\nrepresentational space using hierarchical clustering. We then use an alignment\nfunction to gauge the similarity between the latent space of a pre-trained\nmodel and its fine-tuned version. We use traditional linguistic concepts to\nfacilitate our understanding and also study how the model space transforms\ntowards task-specific information. We perform a thorough analysis, comparing\npre-trained and fine-tuned models across three models and three downstream\ntasks. The notable findings of our work are: i) the latent space of the higher\nlayers evolve towards task-specific concepts, ii) whereas the lower layers\nretain generic concepts acquired in the pre-trained model, iii) we discovered\nthat some concepts in the higher layers acquire polarity towards the output\nclass, and iv) that these concepts can be used for generating adversarial\ntriggers.", "published": "2022-10-23 10:59:19", "link": "http://arxiv.org/abs/2210.12696v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Span-based joint entity and relation extraction augmented with sequence\n  tagging mechanism", "abstract": "Span-based joint extraction simultaneously conducts named entity recognition\n(NER) and relation extraction (RE) in text span form. However, since previous\nspan-based models rely on span-level classifications, they cannot benefit from\ntoken-level label information, which has been proven advantageous for the task.\nIn this paper, we propose a Sequence Tagging augmented Span-based Network\n(STSN), a span-based joint model that can make use of token-level label\ninformation. In STSN, we construct a core neural architecture by deep stacking\nmultiple attention layers, each of which consists of three basic attention\nunits. On the one hand, the core architecture enables our model to learn\ntoken-level label information via the sequence tagging mechanism and then uses\nthe information in the span-based joint extraction; on the other hand, it\nestablishes a bi-directional information interaction between NER and RE.\nExperimental results on three benchmark datasets show that STSN consistently\noutperforms the strongest baselines in terms of F1, creating new\nstate-of-the-art results.", "published": "2022-10-23 12:39:27", "link": "http://arxiv.org/abs/2210.12720v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Additive Interventions Yield Robust Multi-Domain Machine Translation\n  Models", "abstract": "Additive interventions are a recently-proposed mechanism for controlling\ntarget-side attributes in neural machine translation. In contrast to tag-based\napproaches which manipulate the raw source sequence, interventions work by\ndirectly modulating the encoder representation of all tokens in the sequence.\nWe examine the role of additive interventions in a large-scale multi-domain\nmachine translation setting and compare its performance in various inference\nscenarios. We find that while the performance difference is small between\nintervention-based systems and tag-based systems when the domain label matches\nthe test domain, intervention-based systems are robust to label error, making\nthem an attractive choice under label uncertainty. Further, we find that the\nsuperiority of single-domain fine-tuning comes under question when training\ndata size is scaled, contradicting previous findings.", "published": "2022-10-23 13:47:33", "link": "http://arxiv.org/abs/2210.12727v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When Can Transformers Ground and Compose: Insights from Compositional\n  Generalization Benchmarks", "abstract": "Humans can reason compositionally whilst grounding language utterances to the\nreal world. Recent benchmarks like ReaSCAN use navigation tasks grounded in a\ngrid world to assess whether neural models exhibit similar capabilities. In\nthis work, we present a simple transformer-based model that outperforms\nspecialized architectures on ReaSCAN and a modified version of gSCAN. On\nanalyzing the task, we find that identifying the target location in the grid\nworld is the main challenge for the models. Furthermore, we show that a\nparticular split in ReaSCAN, which tests depth generalization, is unfair. On an\namended version of this split, we show that transformers can generalize to\ndeeper input structures. Finally, we design a simpler grounded compositional\ngeneralization task, RefEx, to investigate how transformers reason\ncompositionally. We show that a single self-attention layer with a single head\ngeneralizes to novel combinations of object attributes. Moreover, we derive a\nprecise mathematical construction of the transformer's computations from the\nlearned network. Overall, we provide valuable insights about the grounded\ncompositional generalization task and the behaviour of transformers on it,\nwhich would be useful for researchers working in this area.", "published": "2022-10-23 17:03:55", "link": "http://arxiv.org/abs/2210.12786v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Realistic Data Augmentation Framework for Enhancing Tabular Reasoning", "abstract": "Existing approaches to constructing training data for Natural Language\nInference (NLI) tasks, such as for semi-structured table reasoning, are either\nvia crowdsourcing or fully automatic methods. However, the former is expensive\nand time-consuming and thus limits scale, and the latter often produces naive\nexamples that may lack complex reasoning. This paper develops a realistic\nsemi-automated framework for data augmentation for tabular inference. Instead\nof manually generating a hypothesis for each table, our methodology generates\nhypothesis templates transferable to similar tables. In addition, our framework\nentails the creation of rational counterfactual tables based on human written\nlogical constraints and premise paraphrasing. For our case study, we use the\nInfoTabs, which is an entity-centric tabular inference dataset. We observed\nthat our framework could generate human-like tabular inference examples, which\ncould benefit training data augmentation, especially in the scenario with\nlimited supervision.", "published": "2022-10-23 17:32:19", "link": "http://arxiv.org/abs/2210.12795v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Code4Struct: Code Generation for Few-Shot Event Structure Prediction", "abstract": "Large Language Model (LLM) trained on a mixture of text and code has\ndemonstrated impressive capability in translating natural language (NL) into\nstructured code. We observe that semantic structures can be conveniently\ntranslated into code and propose Code4Struct to leverage such text-to-structure\ntranslation capability to tackle structured prediction tasks. As a case study,\nwe formulate Event Argument Extraction (EAE) as converting text into\nevent-argument structures that can be represented as a class object using code.\nThis alignment between structures and code enables us to take advantage of\nProgramming Language (PL) features such as inheritance and type annotation to\nintroduce external knowledge or add constraints. We show that, with sufficient\nin-context examples, formulating EAE as a code generation problem is\nadvantageous over using variants of text-based prompts. Despite only using 20\ntraining event instances for each event type, Code4Struct is comparable to\nsupervised models trained on 4,202 instances and outperforms current\nstate-of-the-art (SOTA) trained on 20-shot data by 29.5% absolute F1.\nCode4Struct can use 10-shot training data from a sibling event type to predict\narguments for zero-resource event types and outperforms the zero-shot baseline\nby 12% absolute F1.", "published": "2022-10-23 18:18:51", "link": "http://arxiv.org/abs/2210.12810v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TAPE: Assessing Few-shot Russian Language Understanding", "abstract": "Recent advances in zero-shot and few-shot learning have shown promise for a\nscope of research and practical purposes. However, this fast-growing area lacks\nstandardized evaluation suites for non-English languages, hindering progress\noutside the Anglo-centric paradigm. To address this line of research, we\npropose TAPE (Text Attack and Perturbation Evaluation), a novel benchmark that\nincludes six more complex NLU tasks for Russian, covering multi-hop reasoning,\nethical concepts, logic and commonsense knowledge. The TAPE's design focuses on\nsystematic zero-shot and few-shot NLU evaluation: (i) linguistic-oriented\nadversarial attacks and perturbations for analyzing robustness, and (ii)\nsubpopulations for nuanced interpretation. The detailed analysis of testing the\nautoregressive baselines indicates that simple spelling-based perturbations\naffect the performance the most, while paraphrasing the input has a more\nnegligible effect. At the same time, the results demonstrate a significant gap\nbetween the neural and human baselines for most tasks. We publicly release TAPE\n(tape-benchmark.com) to foster research on robust LMs that can generalize to\nnew tasks when little to no supervision is available.", "published": "2022-10-23 18:28:25", "link": "http://arxiv.org/abs/2210.12813v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RuCoLA: Russian Corpus of Linguistic Acceptability", "abstract": "Linguistic acceptability (LA) attracts the attention of the research\ncommunity due to its many uses, such as testing the grammatical knowledge of\nlanguage models and filtering implausible texts with acceptability classifiers.\nHowever, the application scope of LA in languages other than English is limited\ndue to the lack of high-quality resources. To this end, we introduce the\nRussian Corpus of Linguistic Acceptability (RuCoLA), built from the ground up\nunder the well-established binary LA approach. RuCoLA consists of $9.8$k\nin-domain sentences from linguistic publications and $3.6$k out-of-domain\nsentences produced by generative models. The out-of-domain set is created to\nfacilitate the practical use of acceptability for improving language\ngeneration. Our paper describes the data collection protocol and presents a\nfine-grained analysis of acceptability classification experiments with a range\nof baseline approaches. In particular, we demonstrate that the most widely used\nlanguage models still fall behind humans by a large margin, especially when\ndetecting morphological and semantic errors. We release RuCoLA, the code of\nexperiments, and a public leaderboard (rucola-benchmark.com) to assess the\nlinguistic competence of language models for Russian.", "published": "2022-10-23 18:29:22", "link": "http://arxiv.org/abs/2210.12814v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EUREKA: EUphemism Recognition Enhanced through Knn-based methods and\n  Augmentation", "abstract": "We introduce EUREKA, an ensemble-based approach for performing automatic\neuphemism detection. We (1) identify and correct potentially mislabelled rows\nin the dataset, (2) curate an expanded corpus called EuphAug, (3) leverage\nmodel representations of Potentially Euphemistic Terms (PETs), and (4) explore\nusing representations of semantically close sentences to aid in classification.\nUsing our augmented dataset and kNN-based methods, EUREKA was able to achieve\nstate-of-the-art results on the public leaderboard of the Euphemism Detection\nShared Task, ranking first with a macro F1 score of 0.881. Our code is\navailable at https://github.com/sedrickkeh/EUREKA.", "published": "2022-10-23 20:35:14", "link": "http://arxiv.org/abs/2210.12846v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Curious Case of Absolute Position Embeddings", "abstract": "Transformer language models encode the notion of word order using positional\ninformation. Most commonly, this positional information is represented by\nabsolute position embeddings (APEs), that are learned from the pretraining\ndata. However, in natural language, it is not absolute position that matters,\nbut relative position, and the extent to which APEs can capture this type of\ninformation has not been investigated. In this work, we observe that models\ntrained with APE over-rely on positional information to the point that they\nbreak-down when subjected to sentences with shifted position information.\nSpecifically, when models are subjected to sentences starting from a non-zero\nposition (excluding the effect of priming), they exhibit noticeably degraded\nperformance on zero to full-shot tasks, across a range of model families and\nmodel sizes. Our findings raise questions about the efficacy of APEs to model\nthe relativity of position information, and invite further introspection on the\nsentence and word order processing strategies employed by these models.", "published": "2022-10-23 00:00:04", "link": "http://arxiv.org/abs/2210.12574v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Language Model Pre-Training with Sparse Latent Typing", "abstract": "Modern large-scale Pre-trained Language Models (PLMs) have achieved\ntremendous success on a wide range of downstream tasks. However, most of the LM\npre-training objectives only focus on text reconstruction, but have not sought\nto learn latent-level interpretable representations of sentences. In this\npaper, we manage to push the language models to obtain a deeper understanding\nof sentences by proposing a new pre-training objective, Sparse Latent Typing,\nwhich enables the model to sparsely extract sentence-level keywords with\ndiverse latent types. Experimental results show that our model is able to learn\ninterpretable latent type categories in a self-supervised manner without using\nany external knowledge. Besides, the language model pre-trained with such an\nobjective also significantly improves Information Extraction related downstream\ntasks in both supervised and few-shot settings. Our code is publicly available\nat: https://github.com/renll/SparseLT.", "published": "2022-10-23 00:37:08", "link": "http://arxiv.org/abs/2210.12582v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PoKE: Prior Knowledge Enhanced Emotional Support Conversation with\n  Latent Variable", "abstract": "Emotional support conversation (ESC) task can utilize various support\nstrategies to help people relieve emotional distress and overcome the problem\nthey face, which has attracted much attention in these years. However, most\nstate-of-the-art works rely heavily on external commonsense knowledge to infer\nthe mental state of the user in every dialogue round. Although effective, they\nmay suffer from significant human effort, knowledge update and domain change in\na long run. Therefore, in this article, we focus on exploring the task itself\nwithout using any external knowledge. We find all existing works ignore two\nsignificant characteristics of ESC. (a) Abundant prior knowledge exists in\nhistorical conversations, such as the responses to similar cases and the\ngeneral order of support strategies, which has a great reference value for\ncurrent conversation. (b) There is a one-to-many mapping relationship between\ncontext and support strategy, i.e.multiple strategies are reasonable for a\nsingle context. It lays a better foundation for the diversity of generations.\nTaking into account these two key factors, we propose Prior Knowledge Enhanced\nemotional support model with latent variable, PoKE. The proposed model fully\ntaps the potential of prior knowledge in terms of exemplars and strategy\nsequence and then utilizes a latent variable to model the one-to-many\nrelationship of strategy. Furthermore, we introduce a memory schema to\nincorporate the encoded knowledge into decoder. Experiment results on benchmark\ndataset show that our PoKE outperforms existing baselines on both automatic\nevaluation and human evaluation. Compared with the model using external\nknowledge, PoKE still can make a slight improvement in some metrics. Further\nexperiments prove that abundant prior knowledge is conducive to high-quality\nemotional support, and a well-learned latent variable is critical to the\ndiversity of generations.", "published": "2022-10-23 07:31:24", "link": "http://arxiv.org/abs/2210.12640v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Unsupervised Non-transferable Text Classification", "abstract": "Training a good deep learning model requires substantial data and computing\nresources, which makes the resulting neural model a valuable intellectual\nproperty. To prevent the neural network from being undesirably exploited,\nnon-transferable learning has been proposed to reduce the model generalization\nability in specific target domains. However, existing approaches require\nlabeled data for the target domain which can be difficult to obtain.\nFurthermore, they do not have the mechanism to still recover the model's\nability to access the target domain. In this paper, we propose a novel\nunsupervised non-transferable learning method for the text classification task\nthat does not require annotated target domain data. We further introduce a\nsecret key component in our approach for recovering the access to the target\ndomain, where we design both an explicit and an implicit method for doing so.\nExtensive experiments demonstrate the effectiveness of our approach.", "published": "2022-10-23 08:15:43", "link": "http://arxiv.org/abs/2210.12651v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SAT: Improving Semi-Supervised Text Classification with Simple\n  Instance-Adaptive Self-Training", "abstract": "Self-training methods have been explored in recent years and have exhibited\ngreat performance in improving semi-supervised learning. This work presents a\nSimple instance-Adaptive self-Training method (SAT) for semi-supervised text\nclassification. SAT first generates two augmented views for each unlabeled data\nand then trains a meta-learner to automatically identify the relative strength\nof augmentations based on the similarity between the original view and the\naugmented views. The weakly-augmented view is fed to the model to produce a\npseudo-label and the strongly-augmented view is used to train the model to\npredict the same pseudo-label. We conducted extensive experiments and analyses\non three text classification datasets and found that with varying sizes of\nlabeled training data, SAT consistently shows competitive performance compared\nto existing semi-supervised learning methods. Our code can be found at\n\\url{https://github.com/declare-lab/SAT.git}.", "published": "2022-10-23 08:19:58", "link": "http://arxiv.org/abs/2210.12653v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Extending Phrase Grounding with Pronouns in Visual Dialogues", "abstract": "Conventional phrase grounding aims to localize noun phrases mentioned in a\ngiven caption to their corresponding image regions, which has achieved great\nsuccess recently. Apparently, sole noun phrase grounding is not enough for\ncross-modal visual language understanding. Here we extend the task by\nconsidering pronouns as well. First, we construct a dataset of phrase grounding\nwith both noun phrases and pronouns to image regions. Based on the dataset, we\ntest the performance of phrase grounding by using a state-of-the-art literature\nmodel of this line. Then, we enhance the baseline grounding model with\ncoreference information which should help our task potentially, modeling the\ncoreference structures with graph convolutional networks. Experiments on our\ndataset, interestingly, show that pronouns are easier to ground than noun\nphrases, where the possible reason might be that these pronouns are much less\nambiguous. Additionally, our final model with coreference information can\nsignificantly boost the grounding performance of both noun phrases and\npronouns.", "published": "2022-10-23 08:32:25", "link": "http://arxiv.org/abs/2210.12658v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Mapping Process for the Task: Wikidata Statements to Text as Wikipedia\n  Sentences", "abstract": "Acknowledged as one of the most successful online cooperative projects in\nhuman society, Wikipedia has obtained rapid growth in recent years and desires\ncontinuously to expand content and disseminate knowledge values for everyone\nglobally. The shortage of volunteers brings to Wikipedia many issues, including\ndeveloping content for over 300 languages at the present. Therefore, the\nbenefit that machines can automatically generate content to reduce human\nefforts on Wikipedia language projects could be considerable. In this paper, we\npropose our mapping process for the task of converting Wikidata statements to\nnatural language text (WS2T) for Wikipedia projects at the sentence level. The\nmain step is to organize statements, represented as a group of quadruples and\ntriples, and then to map them to corresponding sentences in English Wikipedia.\nWe evaluate the output corpus in various aspects: sentence structure analysis,\nnoise filtering, and relationships between sentence components based on word\nembedding models. The results are helpful not only for the data-to-text\ngeneration task but also for other relevant works in the field.", "published": "2022-10-23 08:34:33", "link": "http://arxiv.org/abs/2210.12659v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving Chinese Named Entity Recognition by Search Engine Augmentation", "abstract": "Compared with English, Chinese suffers from more grammatical ambiguities,\nlike fuzzy word boundaries and polysemous words. In this case, contextual\ninformation is not sufficient to support Chinese named entity recognition\n(NER), especially for rare and emerging named entities. Semantic augmentation\nusing external knowledge is a potential way to alleviate this problem, while\nhow to obtain and leverage external knowledge for the NER task remains a\nchallenge. In this paper, we propose a neural-based approach to perform\nsemantic augmentation using external knowledge from search engine for Chinese\nNER. In particular, a multi-channel semantic fusion model is adopted to\ngenerate the augmented input representations, which aggregates external related\ntexts retrieved from the search engine. Experiments have shown the superiority\nof our model across 4 NER datasets, including formal and social media language\ncontexts, which further prove the effectiveness of our approach.", "published": "2022-10-23 08:42:05", "link": "http://arxiv.org/abs/2210.12662v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "BotsTalk: Machine-sourced Framework for Automatic Curation of\n  Large-scale Multi-skill Dialogue Datasets", "abstract": "To build open-domain chatbots that are able to use diverse communicative\nskills, we propose a novel framework BotsTalk, where multiple agents grounded\nto the specific target skills participate in a conversation to automatically\nannotate multi-skill dialogues. We further present Blended Skill BotsTalk\n(BSBT), a large-scale multi-skill dialogue dataset comprising 300K\nconversations. Through extensive experiments, we demonstrate that our dataset\ncan be effective for multi-skill dialogue systems which require an\nunderstanding of skill blending as well as skill grounding. Our code and data\nare available at https://github.com/convei-lab/BotsTalk.", "published": "2022-10-23 10:19:42", "link": "http://arxiv.org/abs/2210.12687v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "McQueen: a Benchmark for Multimodal Conversational Query Rewrite", "abstract": "The task of query rewrite aims to convert an in-context query to its\nfully-specified version where ellipsis and coreference are completed and\nreferred-back according to the history context. Although much progress has been\nmade, less efforts have been paid to real scenario conversations that involve\ndrawing information from more than one modalities. In this paper, we propose\nthe task of multimodal conversational query rewrite (McQR), which performs\nquery rewrite under the multimodal visual conversation setting. We collect a\nlarge-scale dataset named McQueen based on manual annotation, which contains\n15k visual conversations and over 80k queries where each one is associated with\na fully-specified rewrite version. In addition, for entities appearing in the\nrewrite, we provide the corresponding image box annotation. We then use the\nMcQueen dataset to benchmark a state-of-the-art method for effectively tackling\nthe McQR task, which is based on a multimodal pre-trained model with pointer\ngenerator. Extensive experiments are performed to demonstrate the effectiveness\nof our model on this task\\footnote{The dataset and code of this paper are both\navailable in \\url{https://github.com/yfyuan01/MQR}", "published": "2022-10-23 16:32:33", "link": "http://arxiv.org/abs/2210.12775v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Retrieval-Augmented and Knowledge-Grounded Language Models for Faithful\n  Clinical Medicine", "abstract": "Language models (LMs), including large language models (such as ChatGPT),\nhave the potential to assist clinicians in generating various clinical notes.\nHowever, LMs are prone to produce ``hallucinations'', i.e., generated content\nthat is not aligned with facts and knowledge. In this paper, we propose the\nRe$^3$Writer method with retrieval-augmented generation and knowledge-grounded\nreasoning to enable LMs to generate faithful clinical texts. We demonstrate the\neffectiveness of our method in generating patient discharge instructions. It\nrequires the LMs not to only understand the patients' long clinical documents,\ni.e., the health records during hospitalization, but also to generate critical\ninstructional information provided both to carers and to the patient at the\ntime of discharge. The proposed Re$^3$Writer imitates the working patterns of\nphysicians to first \\textbf{re}trieve related working experience from\nhistorical instructions written by physicians, then \\textbf{re}ason related\nmedical knowledge. Finally, it \\textbf{re}fines the retrieved working\nexperience and reasoned medical knowledge to extract useful information, which\nis used to generate the discharge instructions for previously-unseen patients.\nOur experiments show that, using our method, the performance of five\nrepresentative LMs can be substantially boosted across all metrics. Meanwhile,\nwe show results from human evaluations to measure the effectiveness in terms of\nfluency, faithfulness, and comprehensiveness.", "published": "2022-10-23 16:34:39", "link": "http://arxiv.org/abs/2210.12777v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Translation Word-Level Auto-Completion: What can we achieve out of the\n  box?", "abstract": "Research on Machine Translation (MT) has achieved important breakthroughs in\nseveral areas. While there is much more to be done in order to build on this\nsuccess, we believe that the language industry needs better ways to take full\nadvantage of current achievements. Due to a combination of factors, including\ntime, resources, and skills, businesses tend to apply pragmatism into their AI\nworkflows. Hence, they concentrate more on outcomes, e.g. delivery, shipping,\nreleases, and features, and adopt high-level working production solutions,\nwhere possible. Among the features thought to be helpful for translators are\nsentence-level and word-level translation auto-suggestion and auto-completion.\nSuggesting alternatives can inspire translators and limit their need to refer\nto external resources, which hopefully boosts their productivity. This work\ndescribes our submissions to WMT's shared task on word-level auto-completion,\nfor the Chinese-to-English, English-to-Chinese, German-to-English, and\nEnglish-to-German language directions. We investigate the possibility of using\npre-trained models and out-of-the-box features from available libraries. We\nemploy random sampling to generate diverse alternatives, which reveals good\nresults. Furthermore, we introduce our open-source API, based on CTranslate2,\nto serve translations, auto-suggestions, and auto-completions.", "published": "2022-10-23 17:58:01", "link": "http://arxiv.org/abs/2210.12802v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Data Augmentation for Automated Essay Scoring using Transformer Models", "abstract": "Automated essay scoring is one of the most important problem in Natural\nLanguage Processing. It has been explored for a number of years, and it remains\npartially solved. In addition to its economic and educational usefulness, it\npresents research problems. Transfer learning has proved to be beneficial in\nNLP. Data augmentation techniques have also helped build state-of-the-art\nmodels for automated essay scoring. Many works in the past have attempted to\nsolve this problem by using RNNs, LSTMs, etc. This work examines the\ntransformer models like BERT, RoBERTa, etc. We empirically demonstrate the\neffectiveness of transformer models and data augmentation for automated essay\ngrading across many topics using a single model.", "published": "2022-10-23 18:13:30", "link": "http://arxiv.org/abs/2210.12809v5", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Pragmatic Production Strategies for Natural Language Generation\n  Tasks", "abstract": "This position paper proposes a conceptual framework for the design of Natural\nLanguage Generation (NLG) systems that follow efficient and effective\nproduction strategies in order to achieve complex communicative goals. In this\ngeneral framework, efficiency is characterised as the parsimonious regulation\nof production and comprehension costs while effectiveness is measured with\nrespect to task-oriented and contextually grounded communicative goals. We\nprovide concrete suggestions for the estimation of goals, costs, and utility\nvia modern statistical methods, demonstrating applications of our framework to\nthe classic pragmatic task of visually grounded referential games and to\nabstractive text summarisation, two popular generation tasks with real-world\napplications. In sum, we advocate for the development of NLG systems that learn\nto make pragmatic production decisions from experience, by reasoning about\ngoals, costs, and utility in a human-like way.", "published": "2022-10-23 19:30:42", "link": "http://arxiv.org/abs/2210.12828v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Knowledge Transfer from Answer Ranking to Answer Generation", "abstract": "Recent studies show that Question Answering (QA) based on Answer Sentence\nSelection (AS2) can be improved by generating an improved answer from the top-k\nranked answer sentences (termed GenQA). This allows for synthesizing the\ninformation from multiple candidates into a concise, natural-sounding answer.\nHowever, creating large-scale supervised training data for GenQA models is very\nchallenging. In this paper, we propose to train a GenQA model by transferring\nknowledge from a trained AS2 model, to overcome the aforementioned issue.\nFirst, we use an AS2 model to produce a ranking over answer candidates for a\nset of questions. Then, we use the top ranked candidate as the generation\ntarget, and the next k top ranked candidates as context for training a GenQA\nmodel. We also propose to use the AS2 model prediction scores for loss\nweighting and score-conditioned input/output shaping, to aid the knowledge\ntransfer. Our evaluation on three public and one large industrial datasets\ndemonstrates the superiority of our approach over the AS2 baseline, and GenQA\ntrained using supervised data.", "published": "2022-10-23 21:51:27", "link": "http://arxiv.org/abs/2210.12865v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Greek Parliament Proceedings Dataset for Computational Linguistics and\n  Political Analysis", "abstract": "Large, diachronic datasets of political discourse are hard to come across,\nespecially for resource-lean languages such as Greek. In this paper, we\nintroduce a curated dataset of the Greek Parliament Proceedings that extends\nchronologically from 1989 up to 2020. It consists of more than 1 million\nspeeches with extensive metadata, extracted from 5,355 parliamentary record\nfiles. We explain how it was constructed and the challenges that we had to\novercome. The dataset can be used for both computational linguistics and\npolitical analysis-ideally, combining the two. We present such an application,\nshowing (i) how the dataset can be used to study the change of word usage\nthrough time, (ii) between significant historical events and political parties,\n(iii) by evaluating and employing algorithms for detecting semantic shifts.", "published": "2022-10-23 23:23:28", "link": "http://arxiv.org/abs/2210.12883v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Retrieval Augmentation for Commonsense Reasoning: A Unified Approach", "abstract": "A common thread of retrieval-augmented methods in the existing literature\nfocuses on retrieving encyclopedic knowledge, such as Wikipedia, which\nfacilitates well-defined entity and relation spaces that can be modeled.\nHowever, applying such methods to commonsense reasoning tasks faces two unique\nchallenges, i.e., the lack of a general large-scale corpus for retrieval and a\ncorresponding effective commonsense retriever. In this paper, we systematically\ninvestigate how to leverage commonsense knowledge retrieval to improve\ncommonsense reasoning tasks. We proposed a unified framework of\nretrieval-augmented commonsense reasoning (called RACo), including a newly\nconstructed commonsense corpus with over 20 million documents and novel\nstrategies for training a commonsense retriever. We conducted experiments on\nfour different commonsense reasoning tasks. Extensive evaluation results showed\nthat our proposed RACo can significantly outperform other knowledge-enhanced\nmethod counterparts, achieving new SoTA performance on the CommonGen and CREAK\nleaderboards.", "published": "2022-10-23 23:49:08", "link": "http://arxiv.org/abs/2210.12887v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DALL-E 2 Fails to Reliably Capture Common Syntactic Processes", "abstract": "Machine intelligence is increasingly being linked to claims about sentience,\nlanguage processing, and an ability to comprehend and transform natural\nlanguage into a range of stimuli. We systematically analyze the ability of\nDALL-E 2 to capture 8 grammatical phenomena pertaining to compositionality that\nare widely discussed in linguistics and pervasive in human language: binding\nprinciples and coreference, passives, word order, coordination, comparatives,\nnegation, ellipsis, and structural ambiguity. Whereas young children routinely\nmaster these phenomena, learning systematic mappings between syntax and\nsemantics, DALL-E 2 is unable to reliably infer meanings that are consistent\nwith the syntax. These results challenge recent claims concerning the capacity\nof such systems to understand of human language. We make available the full set\nof test materials as a benchmark for future testing.", "published": "2022-10-23 23:56:54", "link": "http://arxiv.org/abs/2210.12889v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Efficient Nearest Neighbor Search for Cross-Encoder Models using Matrix\n  Factorization", "abstract": "Efficient k-nearest neighbor search is a fundamental task, foundational for\nmany problems in NLP. When the similarity is measured by dot-product between\ndual-encoder vectors or $\\ell_2$-distance, there already exist many scalable\nand efficient search methods. But not so when similarity is measured by more\naccurate and expensive black-box neural similarity models, such as\ncross-encoders, which jointly encode the query and candidate neighbor. The\ncross-encoders' high computational cost typically limits their use to reranking\ncandidates retrieved by a cheaper model, such as dual encoder or TF-IDF.\nHowever, the accuracy of such a two-stage approach is upper-bounded by the\nrecall of the initial candidate set, and potentially requires additional\ntraining to align the auxiliary retrieval model with the cross-encoder model.\nIn this paper, we present an approach that avoids the use of a dual-encoder for\nretrieval, relying solely on the cross-encoder. Retrieval is made efficient\nwith CUR decomposition, a matrix decomposition approach that approximates all\npairwise cross-encoder distances from a small subset of rows and columns of the\ndistance matrix. Indexing items using our approach is computationally cheaper\nthan training an auxiliary dual-encoder model through distillation.\nEmpirically, for k > 10, our approach provides test-time\nrecall-vs-computational cost trade-offs superior to the current widely-used\nmethods that re-rank items retrieved using a dual-encoder or TF-IDF.", "published": "2022-10-23 00:32:04", "link": "http://arxiv.org/abs/2210.12579v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning to Perform Complex Tasks through Compositional Fine-Tuning of\n  Language Models", "abstract": "How to usefully encode compositional task structure has long been a core\nchallenge in AI. Recent work in chain of thought prompting has shown that for\nvery large neural language models (LMs), explicitly demonstrating the\ninferential steps involved in a target task may improve performance over\nend-to-end learning that focuses on the target task alone. However, chain of\nthought prompting has significant limitations due to its dependency on huge\npretrained LMs. In this work, we present compositional fine-tuning (CFT): an\napproach based on explicitly decomposing a target task into component tasks,\nand then fine-tuning smaller LMs on a curriculum of such component tasks. We\napply CFT to recommendation tasks in two domains, world travel and local\ndining, as well as a previously studied inferential task (sports\nunderstanding). We show that CFT outperforms end-to-end learning even with\nequal amounts of data, and gets consistently better as more component tasks are\nmodeled via fine-tuning. Compared with chain of thought prompting, CFT performs\nat least as well using LMs only 7.4% of the size, and is moreover applicable to\ntask domains for which data are not available during pretraining.", "published": "2022-10-23 03:22:34", "link": "http://arxiv.org/abs/2210.12607v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Discriminative Language Model as Semantic Consistency Scorer for\n  Prompt-based Few-Shot Text Classification", "abstract": "This paper proposes a novel prompt-based finetuning method (called DLM-SCS)\nfor few-shot text classification by utilizing the discriminative language model\nELECTRA that is pretrained to distinguish whether a token is original or\ngenerated. The underlying idea is that the prompt instantiated with the true\nlabel should have higher semantic consistency score than other prompts with\nfalse labels. Since a prompt usually consists of several components (or parts),\nits semantic consistency can be decomposed accordingly. The semantic\nconsistency of each component is then computed by making use of the pretrained\nELECTRA model, without introducing extra parameters. Extensive experiments have\nshown that our model outperforms several state-of-the-art prompt-based few-shot\nmethods.", "published": "2022-10-23 16:10:48", "link": "http://arxiv.org/abs/2210.12763v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50", "I.2"], "primary_category": "cs.CL"}
{"title": "Exploring the Value of Pre-trained Language Models for Clinical Named\n  Entity Recognition", "abstract": "The practice of fine-tuning Pre-trained Language Models (PLMs) from general\nor domain-specific data to a specific task with limited resources, has gained\npopularity within the field of natural language processing (NLP). In this work,\nwe re-visit this assumption and carry out an investigation in clinical NLP,\nspecifically Named Entity Recognition on drugs and their related attributes. We\ncompare Transformer models that are trained from scratch to fine-tuned\nBERT-based LLMs namely BERT, BioBERT, and ClinicalBERT. Furthermore, we examine\nthe impact of an additional CRF layer on such models to encourage contextual\nlearning. We use n2c2-2018 shared task data for model development and\nevaluations. The experimental outcomes show that 1) CRF layers improved all\nlanguage models; 2) referring to BIO-strict span level evaluation using\nmacro-average F1 score, although the fine-tuned LLMs achieved 0.83+ scores, the\nTransformerCRF model trained from scratch achieved 0.78+, demonstrating\ncomparable performances with much lower cost - e.g. with 39.80\\% less training\nparameters; 3) referring to BIO-strict span-level evaluation using\nweighted-average F1 score, ClinicalBERT-CRF, BERT-CRF, and TransformerCRF\nexhibited lower score differences, with 97.59\\%/97.44\\%/96.84\\% respectively.\n4) applying efficient training by down-sampling for better data distribution\nfurther reduced the training cost and need for data, while maintaining similar\nscores - i.e. around 0.02 points lower compared to using the full dataset. Our\nmodels will be hosted at \\url{https://github.com/HECTA-UoM/TransformerCRF}", "published": "2022-10-23 16:27:31", "link": "http://arxiv.org/abs/2210.12770v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MM-Align: Learning Optimal Transport-based Alignment Dynamics for Fast\n  and Accurate Inference on Missing Modality Sequences", "abstract": "Existing multimodal tasks mostly target at the complete input modality\nsetting, i.e., each modality is either complete or completely missing in both\ntraining and test sets. However, the randomly missing situations have still\nbeen underexplored. In this paper, we present a novel approach named MM-Align\nto address the missing-modality inference problem. Concretely, we propose 1) an\nalignment dynamics learning module based on the theory of optimal transport\n(OT) for indirect missing data imputation; 2) a denoising training algorithm to\nsimultaneously enhance the imputation results and backbone network performance.\nCompared with previous methods which devote to reconstructing the missing\ninputs, MM-Align learns to capture and imitate the alignment dynamics between\nmodality sequences. Results of comprehensive experiments on three datasets\ncovering two multimodal tasks empirically demonstrate that our method can\nperform more accurate and faster inference and relieve overfitting under\nvarious missing conditions.", "published": "2022-10-23 17:44:56", "link": "http://arxiv.org/abs/2210.12798v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Bootstrapping meaning through listening: Unsupervised learning of spoken\n  sentence embeddings", "abstract": "Inducing semantic representations directly from speech signals is a highly\nchallenging task but has many useful applications in speech mining and spoken\nlanguage understanding. This study tackles the unsupervised learning of\nsemantic representations for spoken utterances. Through converting speech\nsignals into hidden units generated from acoustic unit discovery, we propose\nWavEmbed, a multimodal sequential autoencoder that predicts hidden units from a\ndense representation of speech. Secondly, we also propose S-HuBERT to induce\nmeaning through knowledge distillation, in which a sentence embedding model is\nfirst trained on hidden units and passes its knowledge to a speech encoder\nthrough contrastive learning. The best performing model achieves a moderate\ncorrelation (0.5~0.6) with human judgments, without relying on any labels or\ntranscriptions. Furthermore, these models can also be easily extended to\nleverage textual transcriptions of speech to learn much better speech\nembeddings that are strongly correlated with human annotations. Our proposed\nmethods are applicable to the development of purely data-driven systems for\nspeech mining, indexing and search.", "published": "2022-10-23 21:16:09", "link": "http://arxiv.org/abs/2210.12857v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Global Contrastive Batch Sampling via Optimization on Sample\n  Permutations", "abstract": "Contrastive Learning has recently achieved state-of-the-art performance in a\nwide range of tasks. Many contrastive learning approaches use mined hard\nnegatives to make batches more informative during training but these approaches\nare inefficient as they increase epoch length proportional to the number of\nmined negatives and require frequent updates of nearest neighbor indices or\nmining from recent batches. In this work, we provide an alternative to hard\nnegative mining, Global Contrastive Batch Sampling (GCBS), an efficient\napproximation to the batch assignment problem that upper bounds the gap between\nthe global and training losses, $\\mathcal{L}^{Global} - \\mathcal{L}^{Train}$,\nin contrastive learning settings. Through experimentation we find GCBS improves\nstate-of-the-art performance in sentence embedding and code-search tasks.\nAdditionally, GCBS is easy to implement as it requires only a few additional\nlines of code, does not maintain external data structures such as nearest\nneighbor indices, is more computationally efficient than the most minimal hard\nnegative mining approaches, and makes no changes to the model being trained.", "published": "2022-10-23 22:35:02", "link": "http://arxiv.org/abs/2210.12874v4", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "TPU-MLIR: A Compiler For TPU Using MLIR", "abstract": "Multi-level intermediate representations (MLIR) show great promise for\nreducing the cost of building domain-specific compilers by providing a reusable\nand extensible compiler infrastructure. This work presents TPU-MLIR, an\nend-to-end compiler based on MLIR that deploys pre-trained neural network (NN)\nmodels to a custom ASIC called a Tensor Processing Unit (TPU). TPU-MLIR defines\ntwo new dialects to implement its functionality: 1. a Tensor operation (TOP)\ndialect that encodes the deep learning graph semantics and independent of the\ndeep learning framework and 2. a TPU kernel dialect to provide a standard\nkernel computation on TPU. A NN model is translated to the TOP dialect and then\nlowered to the TPU dialect for different TPUs according to the chip's\nconfiguration. We demonstrate how to use the MLIR pass pipeline to organize and\nperform optimization on TPU to generate machine code. The paper also presents a\nverification procedure to ensure the correctness of each transform stage.", "published": "2022-10-23 10:45:54", "link": "http://arxiv.org/abs/2210.15016v2", "categories": ["cs.PL", "cs.CL", "cs.LG", "68N20"], "primary_category": "cs.PL"}
{"title": "A BERT-based Deep Learning Approach for Reputation Analysis in Social\n  Media", "abstract": "Social media has become an essential part of the modern lifestyle, with its\nusage being highly prevalent. This has resulted in unprecedented amounts of\ndata generated from users in social media, such as users' attitudes, opinions,\ninterests, purchases, and activities across various aspects of their lives.\nTherefore, in a world of social media, where its power has shifted to users,\nactions taken by companies and public figures are subject to constantly being\nunder scrutiny by influential global audiences. As a result, reputation\nmanagement in social media has become essential as companies and public figures\nneed to maintain their reputation to preserve their reputation capital.\nHowever, domain experts still face the challenge of lacking appropriate\nsolutions to automate reliable online reputation analysis. To tackle this\nchallenge, we proposed a novel reputation analysis approach based on the\npopular language model BERT (Bidirectional Encoder Representations from\nTransformers). The proposed approach was evaluated on the reputational polarity\ntask using RepLab 2013 dataset. Compared to previous works, we achieved 5.8%\nimprovement in accuracy, 26.9% improvement in balanced accuracy, and 21.8%\nimprovement in terms of F-score.", "published": "2022-10-23 02:04:03", "link": "http://arxiv.org/abs/2211.01954v1", "categories": ["cs.CL", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Generative Knowledge Graph Construction: A Review", "abstract": "Generative Knowledge Graph Construction (KGC) refers to those methods that\nleverage the sequence-to-sequence framework for building knowledge graphs,\nwhich is flexible and can be adapted to widespread tasks. In this study, we\nsummarize the recent compelling progress in generative knowledge graph\nconstruction. We present the advantages and weaknesses of each paradigm in\nterms of different generation targets and provide theoretical insight and\nempirical analysis. Based on the review, we suggest promising research\ndirections for the future. Our contributions are threefold: (1) We present a\ndetailed, complete taxonomy for the generative KGC methods; (2) We provide a\ntheoretical and empirical analysis of the generative KGC methods; (3) We\npropose several research directions that can be developed in the future.", "published": "2022-10-23 12:24:55", "link": "http://arxiv.org/abs/2210.12714v3", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Speaker Identification from emotional and noisy speech data using\n  learned voice segregation and Speech VGG", "abstract": "Speech signals are subjected to more acoustic interference and emotional\nfactors than other signals. Noisy emotion-riddled speech data is a challenge\nfor real-time speech processing applications. It is essential to find an\neffective way to segregate the dominant signal from other external influences.\nAn ideal system should have the capacity to accurately recognize required\nauditory events from a complex scene taken in an unfavorable situation. This\npaper proposes a novel approach to speaker identification in unfavorable\nconditions such as emotion and interference using a pre-trained Deep Neural\nNetwork mask and speech VGG. The proposed model obtained superior performance\nover the recent literature in English and Arabic emotional speech data and\nreported an average speaker identification rate of 85.2\\%, 87.0\\%, and 86.6\\%\nusing the Ryerson audio-visual dataset (RAVDESS), speech under simulated and\nactual stress (SUSAS) dataset and Emirati-accented Speech dataset (ESD)\nrespectively.", "published": "2022-10-23 11:20:27", "link": "http://arxiv.org/abs/2210.12701v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "HiFi-WaveGAN: Generative Adversarial Network with Auxiliary\n  Spectrogram-Phase Loss for High-Fidelity Singing Voice Generation", "abstract": "Entertainment-oriented singing voice synthesis (SVS) requires a vocoder to\ngenerate high-fidelity (e.g. 48kHz) audio. However, most text-to-speech (TTS)\nvocoders cannot reconstruct the waveform well in this scenario. In this paper,\nwe propose HiFi-WaveGAN to synthesize the 48kHz high-quality singing voices in\nreal-time. Specifically, it consists of an Extended WaveNet served as a\ngenerator, a multi-period discriminator proposed in HiFiGAN, and a\nmulti-resolution spectrogram discriminator borrowed from UnivNet. To better\nreconstruct the high-frequency part from the full-band mel-spectrogram, we\nincorporate a pulse extractor to generate the constraint for the synthesized\nwaveform. Additionally, an auxiliary spectrogram-phase loss is utilized to\napproximate the real distribution further. The experimental results show that\nour proposed HiFi-WaveGAN obtains 4.23 in the mean opinion score (MOS) metric\nfor the 48kHz SVS task, significantly outperforming other neural vocoders.", "published": "2022-10-23 14:45:13", "link": "http://arxiv.org/abs/2210.12740v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Quantitative Evidence on Overlooked Aspects of Enrollment Speaker\n  Embeddings for Target Speaker Separation", "abstract": "Single channel target speaker separation (TSS) aims at extracting a speaker's\nvoice from a mixture of multiple talkers given an enrollment utterance of that\nspeaker. A typical deep learning TSS framework consists of an upstream model\nthat obtains enrollment speaker embeddings and a downstream model that performs\nthe separation conditioned on the embeddings. In this paper, we look into\nseveral important but overlooked aspects of the enrollment embeddings,\nincluding the suitability of the widely used speaker identification embeddings,\nthe introduction of the log-mel filterbank and self-supervised embeddings, and\nthe embeddings' cross-dataset generalization capability. Our results show that\nthe speaker identification embeddings could lose relevant information due to a\nsub-optimal metric, training objective, or common pre-processing. In contrast,\nboth the filterbank and the self-supervised embeddings preserve the integrity\nof the speaker information, but the former consistently outperforms the latter\nin a cross-dataset evaluation. The competitive separation and generalization\nperformance of the previously overlooked filterbank embedding is consistent\nacross our study, which calls for future research on better upstream features.", "published": "2022-10-23 07:08:46", "link": "http://arxiv.org/abs/2210.12635v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Clarinet: A Music Retrieval System", "abstract": "A MIDI based approach for music recognition is proposed and implemented in\nthis paper. Our Clarinet music retrieval system is designed to search piano\nMIDI files with high recall and speed. We design a novel melody extraction\nalgorithm that improves recall results by more than 10%. We also implement 3\nalgorithms for retrieval-two self designed (RSA Note and RSA Time), and a\nmodified version of the Mongeau Sankoff Algorithm. Algorithms to achieve tempo\nand scale invariance are also discussed in this paper. The paper also contains\ndetailed experimentation and benchmarks with four different metrics. Clarinet\nachieves recall scores of more than 94%.", "published": "2022-10-23 08:09:12", "link": "http://arxiv.org/abs/2210.12648v2", "categories": ["cs.IR", "cs.SD", "eess.AS"], "primary_category": "cs.IR"}
