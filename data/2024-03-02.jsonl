{"title": "Reading Subtext: Evaluating Large Language Models on Short Story\n  Summarization with Writers", "abstract": "We evaluate recent Large Language Models (LLMs) on the challenging task of\nsummarizing short stories, which can be lengthy, and include nuanced subtext or\nscrambled timelines. Importantly, we work directly with authors to ensure that\nthe stories have not been shared online (and therefore are unseen by the\nmodels), and to obtain informed evaluations of summary quality using judgments\nfrom the authors themselves. Through quantitative and qualitative analysis\ngrounded in narrative theory, we compare GPT-4, Claude-2.1, and LLama-2-70B. We\nfind that all three models make faithfulness mistakes in over 50% of summaries\nand struggle with specificity and interpretation of difficult subtext. We\nadditionally demonstrate that LLM ratings and other automatic metrics for\nsummary quality do not correlate well with the quality ratings from the\nwriters.", "published": "2024-03-02 01:52:14", "link": "http://arxiv.org/abs/2403.01061v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FaiMA: Feature-aware In-context Learning for Multi-domain Aspect-based\n  Sentiment Analysis", "abstract": "Multi-domain aspect-based sentiment analysis (ABSA) seeks to capture\nfine-grained sentiment across diverse domains. While existing research narrowly\nfocuses on single-domain applications constrained by methodological limitations\nand data scarcity, the reality is that sentiment naturally traverses multiple\ndomains. Although large language models (LLMs) offer a promising solution for\nABSA, it is difficult to integrate effectively with established techniques,\nincluding graph-based models and linguistics, because modifying their internal\narchitecture is not easy. To alleviate this problem, we propose a novel\nframework, Feature-aware In-context Learning for Multi-domain ABSA (FaiMA). The\ncore insight of FaiMA is to utilize in-context learning (ICL) as a\nfeature-aware mechanism that facilitates adaptive learning in multi-domain ABSA\ntasks. Specifically, we employ a multi-head graph attention network as a text\nencoder optimized by heuristic rules for linguistic, domain, and sentiment\nfeatures. Through contrastive learning, we optimize sentence representations by\nfocusing on these diverse features. Additionally, we construct an efficient\nindexing mechanism, allowing FaiMA to stably retrieve highly relevant examples\nacross multiple dimensions for any given input. To evaluate the efficacy of\nFaiMA, we build the first multi-domain ABSA benchmark dataset. Extensive\nexperimental results demonstrate that FaiMA achieves significant performance\nimprovements in multiple domains compared to baselines, increasing F1 by 2.07%\non average. Source code and data sets are anonymously available at\nhttps://github.com/SupritYoung/FaiMA.", "published": "2024-03-02 02:00:51", "link": "http://arxiv.org/abs/2403.01063v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLMCRIT: Teaching Large Language Models to Use Criteria", "abstract": "Humans follow criteria when they execute tasks, and these criteria are\ndirectly used to assess the quality of task completion. Therefore, having\nmodels learn to use criteria to provide feedback can help humans or models to\nperform tasks better. However, existing research in this field tends to\nconsider only a limited set of criteria or quality assessment aspects. To fill\nthis gap, we propose a general framework that enables large language models\n(LLMs) to use comprehensive criteria for a task in delivering natural language\nfeedback on task execution. In particular, we present a model-in-the-loop\nframework that semi-automatically derives criteria from collected guidelines\nfor different writing tasks and constructs in-context demonstrations for each\ncriterion. We choose three tasks from real-world scenarios to operationalize\nthis idea: paper introduction writing, Python code writing, and Reddit post\nwriting, and evaluate our feedback generation framework using different LLMs.\nThe results reveal the fine-grained effects of incorporating criteria and\ndemonstrations and provide valuable insights on how to teach LLMs to use\ncriteria more effectively.", "published": "2024-03-02 02:25:55", "link": "http://arxiv.org/abs/2403.01069v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MulCogBench: A Multi-modal Cognitive Benchmark Dataset for Evaluating\n  Chinese and English Computational Language Models", "abstract": "Pre-trained computational language models have recently made remarkable\nprogress in harnessing the language abilities which were considered unique to\nhumans. Their success has raised interest in whether these models represent and\nprocess language like humans. To answer this question, this paper proposes\nMulCogBench, a multi-modal cognitive benchmark dataset collected from native\nChinese and English participants. It encompasses a variety of cognitive data,\nincluding subjective semantic ratings, eye-tracking, functional magnetic\nresonance imaging (fMRI), and magnetoencephalography (MEG). To assess the\nrelationship between language models and cognitive data, we conducted a\nsimilarity-encoding analysis which decodes cognitive data based on its pattern\nsimilarity with textual embeddings. Results show that language models share\nsignificant similarities with human cognitive data and the similarity patterns\nare modulated by the data modality and stimuli complexity. Specifically,\ncontext-aware models outperform context-independent models as language stimulus\ncomplexity increases. The shallow layers of context-aware models are better\naligned with the high-temporal-resolution MEG signals whereas the deeper layers\nshow more similarity with the high-spatial-resolution fMRI. These results\nindicate that language models have a delicate relationship with brain language\nrepresentations. Moreover, the results between Chinese and English are highly\nconsistent, suggesting the generalizability of these findings across languages.", "published": "2024-03-02 07:49:57", "link": "http://arxiv.org/abs/2403.01116v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BootTOD: Bootstrap Task-oriented Dialogue Representations by Aligning\n  Diverse Responses", "abstract": "Pre-trained language models have been successful in many scenarios. However,\ntheir usefulness in task-oriented dialogues is limited due to the intrinsic\nlinguistic differences between general text and task-oriented dialogues.\nCurrent task-oriented dialogue pre-training methods rely on a contrastive\nframework, which faces challenges such as selecting true positives and hard\nnegatives, as well as lacking diversity. In this paper, we propose a novel\ndialogue pre-training model called BootTOD. It learns task-oriented dialogue\nrepresentations via a self-bootstrapping framework. Unlike contrastive\ncounterparts, BootTOD aligns context and context+response representations and\ndismisses the requirements of contrastive pairs. BootTOD also uses multiple\nappropriate response targets to model the intrinsic one-to-many diversity of\nhuman conversations. Experimental results show that BootTOD outperforms strong\nTOD baselines on diverse downstream dialogue tasks.", "published": "2024-03-02 10:34:11", "link": "http://arxiv.org/abs/2403.01163v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Compositional Typed Semantics for Universal Dependencies", "abstract": "Languages may encode similar meanings using different sentence structures.\nThis makes it a challenge to provide a single set of formal rules that can\nderive meanings from sentences in many languages at once. To overcome the\nchallenge, we can take advantage of language-general connections between\nmeaning and syntax, and build on cross-linguistically parallel syntactic\nstructures. We introduce UD Type Calculus, a compositional, principled, and\nlanguage-independent system of semantic types and logical forms for lexical\nitems which builds on a widely-used language-general dependency syntax\nframework. We explain the essential features of UD Type Calculus, which all\ninvolve giving dependency relations denotations just like those of words. These\nallow UD-TC to derive correct meanings for sentences with a wide range of\nsyntactic structures by making use of dependency labels. Finally, we present\nevaluation results on a large existing corpus of sentences and their logical\nforms, showing that UD-TC can produce meanings comparable with our baseline.", "published": "2024-03-02 11:58:24", "link": "http://arxiv.org/abs/2403.01187v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DMoERM: Recipes of Mixture-of-Experts for Effective Reward Modeling", "abstract": "The performance of the reward model (RM) is a critical factor in improving\nthe effectiveness of the large language model (LLM) during alignment\nfine-tuning. There remain two challenges in RM training: 1) training the same\nRM using various categories of data may cause its generalization performance to\nsuffer from multi-task disturbance, and 2) the human annotation consistency\nrate is generally only $60\\%$ to $75\\%$, causing training data to contain a lot\nof noise. To tackle these two challenges, we introduced the idea of\nMixture-of-Experts (MoE) into the field of RM for the first time. We propose\nthe Double-Layer MoE RM (DMoERM). The outer layer MoE is a sparse model. After\nclassifying an input into task categories, we route it to the corresponding\ninner layer task-specific model. The inner layer MoE is a dense model. We\ndecompose the specific task into multiple capability dimensions and\nindividually fine-tune a LoRA expert on each one. Their outputs are then\nsynthesized by an MLP to compute the final rewards. To minimize costs, we call\na public LLM API to obtain the capability preference labels. The validation on\nmanually labeled datasets confirms that our model attains superior consistency\nwith human preference and outstrips advanced generative approaches. Meanwhile,\nthrough BoN sampling and RL experiments, we demonstrate that our model\noutperforms state-of-the-art ensemble methods of RM and mitigates the\noveroptimization problem. Our code and dataset are available at:\nhttps://github.com/quanshr/DMoERM-v1.", "published": "2024-03-02 12:31:22", "link": "http://arxiv.org/abs/2403.01197v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Emotion Analysis in NLP: Trends, Gaps and Roadmap for Future Directions", "abstract": "Emotions are a central aspect of communication. Consequently, emotion\nanalysis (EA) is a rapidly growing field in natural language processing (NLP).\nHowever, there is no consensus on scope, direction, or methods. In this paper,\nwe conduct a thorough review of 154 relevant NLP publications from the last\ndecade. Based on this review, we address four different questions: (1) How are\nEA tasks defined in NLP? (2) What are the most prominent emotion frameworks and\nwhich emotions are modeled? (3) Is the subjectivity of emotions considered in\nterms of demographics and cultural factors? and (4) What are the primary NLP\napplications for EA? We take stock of trends in EA and tasks, emotion\nframeworks used, existing datasets, methods, and applications. We then discuss\nfour lacunae: (1) the absence of demographic and cultural aspects does not\naccount for the variation in how emotions are perceived, but instead assumes\nthey are universally experienced in the same manner; (2) the poor fit of\nemotion categories from the two main emotion theories to the task; (3) the lack\nof standardized EA terminology hinders gap identification, comparison, and\nfuture goals; and (4) the absence of interdisciplinary research isolates EA\nfrom insights in other fields. Our work will enable more focused research into\nEA and a more holistic approach to modeling emotions in NLP.", "published": "2024-03-02 14:38:03", "link": "http://arxiv.org/abs/2403.01222v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Accelerating Greedy Coordinate Gradient and General Prompt Optimization\n  via Probe Sampling", "abstract": "Safety of Large Language Models (LLMs) has become a critical issue given\ntheir rapid progresses. Greedy Coordinate Gradient (GCG) is shown to be\neffective in constructing adversarial prompts to break the aligned LLMs, but\noptimization of GCG is time-consuming. To reduce the time cost of GCG and\nenable more comprehensive studies of LLM safety, in this work, we study a new\nalgorithm called $\\texttt{Probe sampling}$. At the core of the algorithm is a\nmechanism that dynamically determines how similar a smaller draft model's\npredictions are to the target model's predictions for prompt candidates. When\nthe target model is similar to the draft model, we rely heavily on the draft\nmodel to filter out a large number of potential prompt candidates. Probe\nsampling achieves up to $5.6$ times speedup using Llama2-7b-chat and leads to\nequal or improved attack success rate (ASR) on the AdvBench. Furthermore, probe\nsampling is also able to accelerate other prompt optimization techniques and\nadversarial methods, leading to acceleration of $1.8\\times$ for AutoPrompt,\n$2.4\\times$ for APE and $2.4\\times$ for AutoDAN.", "published": "2024-03-02 16:23:44", "link": "http://arxiv.org/abs/2403.01251v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A comprehensive cross-language framework for harmful content detection\n  with the aid of sentiment analysis", "abstract": "In today's digital world, social media plays a significant role in\nfacilitating communication and content sharing. However, the exponential rise\nin user-generated content has led to challenges in maintaining a respectful\nonline environment. In some cases, users have taken advantage of anonymity in\norder to use harmful language, which can negatively affect the user experience\nand pose serious social problems. Recognizing the limitations of manual\nmoderation, automatic detection systems have been developed to tackle this\nproblem. Nevertheless, several obstacles persist, including the absence of a\nuniversal definition for harmful language, inadequate datasets across\nlanguages, the need for detailed annotation guideline, and most importantly, a\ncomprehensive framework. This study aims to address these challenges by\nintroducing, for the first time, a detailed framework adaptable to any\nlanguage. This framework encompasses various aspects of harmful language\ndetection. A key component of the framework is the development of a general and\ndetailed annotation guideline. Additionally, the integration of sentiment\nanalysis represents a novel approach to enhancing harmful language detection.\nAlso, a definition of harmful language based on the review of different related\nconcepts is presented. To demonstrate the effectiveness of the proposed\nframework, its implementation in a challenging low-resource language is\nconducted. We collected a Persian dataset and applied the annotation guideline\nfor harmful detection and sentiment analysis. Next, we present baseline\nexperiments utilizing machine and deep learning methods to set benchmarks.\nResults prove the framework's high performance, achieving an accuracy of 99.4%\nin offensive language detection and 66.2% in sentiment analysis.", "published": "2024-03-02 17:13:47", "link": "http://arxiv.org/abs/2403.01270v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Greed is All You Need: An Evaluation of Tokenizer Inference Methods", "abstract": "While subword tokenizers such as BPE and WordPiece are typically used to\nbuild vocabularies for NLP models, the method of decoding text into a sequence\nof tokens from these vocabularies is often left unspecified, or ill-suited to\nthe method in which they were constructed. We provide a controlled analysis of\nseven tokenizer inference methods across four different algorithms and three\nvocabulary sizes, performed on a novel intrinsic evaluation suite we curated\nfor English, combining measures rooted in morphology, cognition, and\ninformation theory. We show that for the most commonly used tokenizers, greedy\ninference performs surprisingly well; and that SaGe, a recently-introduced\ncontextually-informed tokenizer, outperforms all others on morphological\nalignment.", "published": "2024-03-02 19:01:40", "link": "http://arxiv.org/abs/2403.01289v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving the Validity of Automatically Generated Feedback via\n  Reinforcement Learning", "abstract": "Automatically generating feedback via large language models (LLMs) in\nintelligent tutoring systems and online learning platforms has the potential to\nimprove the learning outcomes of many students. However, both feedback\ngeneration and evaluation are challenging: feedback content has to be valid\nespecially in subjects like math, which requires models to understand the\nproblem, the solution, and where the student's error lies. Feedback also has to\nbe pedagogically valid to reflect effective tutoring strategies, such as\nexplaining possible misconceptions and encouraging the student, among other\ndesirable features. In this work, we address both problems of automatically\ngenerating and evaluating feedback while considering both correctness and\nalignment. First, we propose a rubric for evaluating math feedback and show\nthat GPT-4 is able to effectively use it to annotate human-written and\nLLM-generated feedback. Second, we propose a framework for feedback generation\nthat optimizes both correctness and alignment using reinforcement learning\n(RL). Specifically, we use GPT-4's annotations to create preferences over\nfeedback pairs in an augmented dataset for training via direct preference\noptimization (DPO). We show that our methods significantly increase the\ncorrectness and alignment of generated feedback with Llama 2, an open-source\nLLM, qualitatively analyze our generation and evaluation systems using case\nstudies, and outline several areas for future work.", "published": "2024-03-02 20:25:50", "link": "http://arxiv.org/abs/2403.01304v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LAB: Large-Scale Alignment for ChatBots", "abstract": "This work introduces LAB (Large-scale Alignment for chatBots), a novel\nmethodology designed to overcome the scalability challenges in the\ninstruction-tuning phase of large language model (LLM) training. Leveraging a\ntaxonomy-guided synthetic data generation process and a multi-phase tuning\nframework, LAB significantly reduces reliance on expensive human annotations\nand proprietary models like GPT-4. We demonstrate that LAB-trained models can\nachieve competitive performance across several benchmarks compared to models\ntrained with traditional human-annotated or GPT-4 generated synthetic data.\nThus offering a scalable, cost-effective solution for enhancing LLM\ncapabilities and instruction-following behaviors without the drawbacks of\ncatastrophic forgetting, marking a step forward in the efficient training of\nLLMs for a wide range of applications.", "published": "2024-03-02 03:48:37", "link": "http://arxiv.org/abs/2403.01081v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Distilling Text Style Transfer With Self-Explanation From LLMs", "abstract": "Text Style Transfer (TST) seeks to alter the style of text while retaining\nits core content. Given the constraints of limited parallel datasets for TST,\nwe propose CoTeX, a framework that leverages large language models (LLMs)\nalongside chain-of-thought (CoT) prompting to facilitate TST. CoTeX distills\nthe complex rewriting and reasoning capabilities of LLMs into more streamlined\nmodels capable of working with both non-parallel and parallel data. Through\nexperimentation across four TST datasets, CoTeX is shown to surpass traditional\nsupervised fine-tuning and knowledge distillation methods, particularly in\nlow-resource settings. We conduct a comprehensive evaluation, comparing CoTeX\nagainst current unsupervised, supervised, in-context learning (ICL) techniques,\nand instruction-tuned LLMs. Furthermore, CoTeX distinguishes itself by offering\ntransparent explanations for its style transfer process.", "published": "2024-03-02 06:38:15", "link": "http://arxiv.org/abs/2403.01106v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ParallelPARC: A Scalable Pipeline for Generating Natural-Language\n  Analogies", "abstract": "Analogy-making is central to human cognition, allowing us to adapt to novel\nsituations -- an ability that current AI systems still lack. Most analogy\ndatasets today focus on simple analogies (e.g., word analogies); datasets\nincluding complex types of analogies are typically manually curated and very\nsmall. We believe that this holds back progress in computational analogy. In\nthis work, we design a data generation pipeline, ParallelPARC (Parallel\nParagraph Creator) leveraging state-of-the-art Large Language Models (LLMs) to\ncreate complex, paragraph-based analogies, as well as distractors, both simple\nand challenging. We demonstrate our pipeline and create ProPara-Logy, a dataset\nof analogies between scientific processes. We publish a gold-set, validated by\nhumans, and a silver-set, generated automatically. We test LLMs' and humans'\nanalogy recognition in binary and multiple-choice settings, and found that\nhumans outperform the best models (~13% gap) after a light supervision. We\ndemonstrate that our silver-set is useful for training models. Lastly, we show\nchallenging distractors confuse LLMs, but not humans. We hope our pipeline will\nencourage research in this emerging field.", "published": "2024-03-02 08:53:40", "link": "http://arxiv.org/abs/2403.01139v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Survey of AI-generated Text Forensic Systems: Detection, Attribution,\n  and Characterization", "abstract": "We have witnessed lately a rapid proliferation of advanced Large Language\nModels (LLMs) capable of generating high-quality text. While these LLMs have\nrevolutionized text generation across various domains, they also pose\nsignificant risks to the information ecosystem, such as the potential for\ngenerating convincing propaganda, misinformation, and disinformation at scale.\nThis paper offers a review of AI-generated text forensic systems, an emerging\nfield addressing the challenges of LLM misuses. We present an overview of the\nexisting efforts in AI-generated text forensics by introducing a detailed\ntaxonomy, focusing on three primary pillars: detection, attribution, and\ncharacterization. These pillars enable a practical understanding of\nAI-generated text, from identifying AI-generated content (detection),\ndetermining the specific AI model involved (attribution), and grouping the\nunderlying intents of the text (characterization). Furthermore, we explore\navailable resources for AI-generated text forensics research and discuss the\nevolving challenges and future directions of forensic systems in an AI era.", "published": "2024-03-02 09:39:13", "link": "http://arxiv.org/abs/2403.01152v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "STAR: Constraint LoRA with Dynamic Active Learning for Data-Efficient\n  Fine-Tuning of Large Language Models", "abstract": "Though Large Language Models (LLMs) have demonstrated the powerful\ncapabilities of few-shot learning through prompting methods, supervised\ntraining is still necessary for complex reasoning tasks. Because of their\nextensive parameters and memory consumption, both Parameter-Efficient\nFine-Tuning (PEFT) methods and Memory-Efficient Fine-Tuning methods have been\nproposed for LLMs. Nevertheless, the issue of large annotated data consumption,\nthe aim of Data-Efficient Fine-Tuning, remains unexplored. One obvious way is\nto combine the PEFT method with active learning. However, the experimental\nresults show that such a combination is not trivial and yields inferior\nresults. Through probe experiments, such observation might be explained by two\nmain reasons: uncertainty gap and poor model calibration. Therefore, in this\npaper, we propose a novel approach to effectively integrate uncertainty-based\nactive learning and LoRA. Specifically, for the uncertainty gap, we introduce a\ndynamic uncertainty measurement that combines the uncertainty of the base model\nand the uncertainty of the full model during the iteration of active learning.\nFor poor model calibration, we incorporate the regularization method during\nLoRA training to keep the model from being over-confident, and the Monte-Carlo\ndropout mechanism is employed to enhance the uncertainty estimation.\nExperimental results show that the proposed approach outperforms existing\nbaseline models on three complex reasoning tasks.", "published": "2024-03-02 10:38:10", "link": "http://arxiv.org/abs/2403.01165v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DINER: Debiasing Aspect-based Sentiment Analysis with Multi-variable\n  Causal Inference", "abstract": "Though notable progress has been made, neural-based aspect-based sentiment\nanalysis (ABSA) models are prone to learn spurious correlations from annotation\nbiases, resulting in poor robustness on adversarial data transformations. Among\nthe debiasing solutions, causal inference-based methods have attracted much\nresearch attention, which can be mainly categorized into causal intervention\nmethods and counterfactual reasoning methods. However, most of the present\ndebiasing methods focus on single-variable causal inference, which is not\nsuitable for ABSA with two input variables (the target aspect and the review).\nIn this paper, we propose a novel framework based on multi-variable causal\ninference for debiasing ABSA. In this framework, different types of biases are\ntackled based on different causal intervention methods. For the review branch,\nthe bias is modeled as indirect confounding from context, where backdoor\nadjustment intervention is employed for debiasing. For the aspect branch, the\nbias is described as a direct correlation with labels, where counterfactual\nreasoning is adopted for debiasing. Extensive experiments demonstrate the\neffectiveness of the proposed method compared to various baselines on the two\nwidely used real-world aspect robustness test set datasets.", "published": "2024-03-02 10:38:31", "link": "http://arxiv.org/abs/2403.01166v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Balancing Exploration and Exploitation in LLM using Soft RLLF for\n  Enhanced Negation Understanding", "abstract": "Finetuning approaches in NLP often focus on exploitation rather than\nexploration, which may lead to suboptimal models. Given the vast search space\nof natural language, this limited exploration can restrict their performance in\ncomplex, high-stakes domains, where accurate negation understanding and logical\nreasoning abilities are crucial. To address this issue, we leverage\nReinforcement Learning from Logical Feedback (RLLF) to create an effective\nbalance between exploration and exploitation in LLMs. Our approach employs an\nappropriate benchmark dataset for training and evaluation, highlighting the\nimportance of exploration in enhancing negation understanding capabilities. We\ncompare the performance of our RLLF-enhanced LLMs with baseline models trained\nwithout RLLF, demonstrating the value of this balanced approach. Furthermore,\nwe showcase the potential of our method in legal AI applications by employing\ntransfer learning and evaluating its impact on negation understanding. Our\nexperimental results exhibit the effectiveness of balancing exploration and\nexploitation with RLLF in improving LLMs' negation capabilities. This has\nimplications for the development of more accurate, reliable, and logically\nconsistent language models in high-stakes domains.", "published": "2024-03-02 11:54:55", "link": "http://arxiv.org/abs/2403.01185v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "RAGged Edges: The Double-Edged Sword of Retrieval-Augmented Chatbots", "abstract": "Large language models (LLMs) like ChatGPT demonstrate the remarkable progress\nof artificial intelligence. However, their tendency to hallucinate -- generate\nplausible but false information -- poses a significant challenge. This issue is\ncritical, as seen in recent court cases where ChatGPT's use led to citations of\nnon-existent legal rulings. This paper explores how Retrieval-Augmented\nGeneration (RAG) can counter hallucinations by integrating external knowledge\nwith prompts. We empirically evaluate RAG against standard LLMs using prompts\ndesigned to induce hallucinations. Our results show that RAG increases accuracy\nin some cases, but can still be misled when prompts directly contradict the\nmodel's pre-trained understanding. These findings highlight the complex nature\nof hallucinations and the need for more robust solutions to ensure LLM\nreliability in real-world applications. We offer practical recommendations for\nRAG deployment and discuss implications for the development of more trustworthy\nLLMs.", "published": "2024-03-02 12:19:04", "link": "http://arxiv.org/abs/2403.01193v3", "categories": ["cs.CL", "cs.AI", "H.3.3; I.2.7"], "primary_category": "cs.CL"}
{"title": "Machine Translation in the Covid domain: an English-Irish case study for\n  LoResMT 2021", "abstract": "Translation models for the specific domain of translating Covid data from\nEnglish to Irish were developed for the LoResMT 2021 shared task. Domain\nadaptation techniques, using a Covid-adapted generic 55k corpus from the\nDirectorate General of Translation, were applied. Fine-tuning, mixed\nfine-tuning and combined dataset approaches were compared with models trained\non an extended in-domain dataset. As part of this study, an English-Irish\ndataset of Covid related data, from the Health and Education domains, was\ndeveloped. The highest-performing model used a Transformer architecture trained\nwith an extended in-domain Covid dataset. In the context of this study, we have\ndemonstrated that extending an 8k in-domain baseline dataset by just 5k lines\nimproved the BLEU score by 27 points.", "published": "2024-03-02 12:29:28", "link": "http://arxiv.org/abs/2403.01196v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "IntactKV: Improving Large Language Model Quantization by Keeping Pivot\n  Tokens Intact", "abstract": "Large language models (LLMs) excel in natural language processing but demand\nintensive computation. To mitigate this, various quantization methods have been\nexplored, yet they compromise LLM performance. This paper unveils a previously\noverlooked type of outliers in LLMs. Such outliers are found to allocate most\nof the attention scores on initial tokens of input, termed as pivot tokens,\nwhich are crucial to the performance of quantized LLMs. Given that, we propose\nIntactKV to generate the KV cache of pivot tokens losslessly from the\nfull-precision model. The approach is simple and easy to combine with existing\nquantization solutions with no extra inference overhead. Besides, IntactKV can\nbe calibrated as additional LLM parameters to boost the quantized LLMs further\nwith minimal training costs. Mathematical analysis also proves that IntactKV\neffectively reduces the upper bound of quantization error. Empirical results\nshow that IntactKV brings consistent improvement over various quantization\nmethods across different LLMs and downstream tasks, leading to the new\nstate-of-the-art for LLM quantization. The codes are available at\nhttps://github.com/ruikangliu/IntactKV.", "published": "2024-03-02 16:05:26", "link": "http://arxiv.org/abs/2403.01241v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mitigating Catastrophic Forgetting in Large Language Models with\n  Self-Synthesized Rehearsal", "abstract": "Large language models (LLMs) suffer from catastrophic forgetting during\ncontinual learning. Conventional rehearsal-based methods rely on previous\ntraining data to retain the model's ability, which may not be feasible in\nreal-world applications. When conducting continual learning based on a\npublicly-released LLM checkpoint, the availability of the original training\ndata may be non-existent. To address this challenge, we propose a framework\ncalled Self-Synthesized Rehearsal (SSR) that uses the LLM to generate synthetic\ninstances for rehearsal. Concretely, we first employ the base LLM for\nin-context learning to generate synthetic instances. Subsequently, we utilize\nthe latest LLM to refine the instance outputs based on the synthetic inputs,\npreserving its acquired ability. Finally, we select diverse high-quality\nsynthetic instances for rehearsal in future stages. Experimental results\ndemonstrate that SSR achieves superior or comparable performance compared to\nconventional rehearsal-based approaches while being more data-efficient.\nBesides, SSR effectively preserves the generalization capabilities of LLMs in\ngeneral domains.", "published": "2024-03-02 16:11:23", "link": "http://arxiv.org/abs/2403.01244v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Dissecting Language Models: Machine Unlearning via Selective Pruning", "abstract": "Understanding and shaping the behaviour of Large Language Models (LLMs) is\nincreasingly important as applications become more powerful and more frequently\nadopted. This paper introduces a machine unlearning method specifically\ndesigned for LLMs. We introduce a selective pruning method for LLMs that\nremoves neurons based on their relative importance on a targeted capability\ncompared to overall network performance. This approach is a compute- and\ndata-efficient method for identifying and removing neurons that enable specific\nbehaviours. Our findings reveal that both feed-forward and attention neurons in\nLLMs are specialized; that is, for specific tasks, certain neurons are more\ncrucial than others. Code from all experiments is available at\nhttps://github.com/nickypro/selective-pruning", "published": "2024-03-02 17:10:44", "link": "http://arxiv.org/abs/2403.01267v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "LM4OPT: Unveiling the Potential of Large Language Models in Formulating\n  Mathematical Optimization Problems", "abstract": "In the rapidly evolving field of natural language processing, the translation\nof linguistic descriptions into mathematical formulation of optimization\nproblems presents a formidable challenge, demanding intricate understanding and\nprocessing capabilities from Large Language Models (LLMs). This study compares\nprominent LLMs, including GPT-3.5, GPT-4, and Llama-2-7b, in zero-shot and\none-shot settings for this task. Our findings show GPT-4's superior\nperformance, particularly in the one-shot scenario. A central part of this\nresearch is the introduction of `LM4OPT,' a progressive fine-tuning framework\nfor Llama-2-7b that utilizes noisy embeddings and specialized datasets.\nHowever, this research highlights a notable gap in the contextual understanding\ncapabilities of smaller models such as Llama-2-7b compared to larger\ncounterparts, especially in processing lengthy and complex input contexts. Our\nempirical investigation, utilizing the NL4Opt dataset, unveils that GPT-4\nsurpasses the baseline performance established by previous research, achieving\nan F1-score of 0.63, solely based on the problem description in natural\nlanguage, and without relying on any additional named entity information.\nGPT-3.5 follows closely, both outperforming the fine-tuned Llama-2-7b. These\nfindings not only benchmark the current capabilities of LLMs in a novel\napplication area but also lay the groundwork for future improvements in\nmathematical formulation of optimization problems from natural language input.", "published": "2024-03-02 23:32:33", "link": "http://arxiv.org/abs/2403.01342v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "MuseGraph: Graph-oriented Instruction Tuning of Large Language Models\n  for Generic Graph Mining", "abstract": "Graphs with abundant attributes are essential in modeling interconnected\nentities and improving predictions in various real-world applications.\nTraditional Graph Neural Networks (GNNs), which are commonly used for modeling\nattributed graphs, need to be re-trained every time when applied to different\ngraph tasks and datasets. Although the emergence of Large Language Models\n(LLMs) has introduced a new paradigm in natural language processing, the\ngenerative potential of LLMs in graph mining remains largely under-explored. To\nthis end, we propose a novel framework MuseGraph, which seamlessly integrates\nthe strengths of GNNs and LLMs and facilitates a more effective and generic\napproach for graph mining across different tasks and datasets. Specifically, we\nfirst introduce a compact graph description via the proposed adaptive input\ngeneration to encapsulate key information from the graph under the constraints\nof language token limitations. Then, we propose a diverse instruction\ngeneration mechanism, which distills the reasoning capabilities from LLMs\n(e.g., GPT-4) to create task-specific Chain-of-Thought-based instruction\npackages for different graph tasks. Finally, we propose a graph-aware\ninstruction tuning with a dynamic instruction package allocation strategy\nacross tasks and datasets, ensuring the effectiveness and generalization of the\ntraining process. Our experimental results demonstrate significant improvements\nin different graph tasks, showcasing the potential of our MuseGraph in\nenhancing the accuracy of graph-oriented downstream tasks while keeping the\ngeneration powers of LLMs.", "published": "2024-03-02 09:27:32", "link": "http://arxiv.org/abs/2403.04780v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Survey on Temporal Knowledge Graph: Representation Learning and\n  Applications", "abstract": "Knowledge graphs have garnered significant research attention and are widely\nused to enhance downstream applications. However, most current studies mainly\nfocus on static knowledge graphs, whose facts do not change with time, and\ndisregard their dynamic evolution over time. As a result, temporal knowledge\ngraphs have attracted more attention because a large amount of structured\nknowledge exists only within a specific period. Knowledge graph representation\nlearning aims to learn low-dimensional vector embeddings for entities and\nrelations in a knowledge graph. The representation learning of temporal\nknowledge graphs incorporates time information into the standard knowledge\ngraph framework and can model the dynamics of entities and relations over time.\nIn this paper, we conduct a comprehensive survey of temporal knowledge graph\nrepresentation learning and its applications. We begin with an introduction to\nthe definitions, datasets, and evaluation metrics for temporal knowledge graph\nrepresentation learning. Next, we propose a taxonomy based on the core\ntechnologies of temporal knowledge graph representation learning methods, and\nprovide an in-depth analysis of different methods in each category. Finally, we\npresent various downstream applications related to the temporal knowledge\ngraphs. In the end, we conclude the paper and have an outlook on the future\nresearch directions in this area.", "published": "2024-03-02 16:21:45", "link": "http://arxiv.org/abs/2403.04782v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Multimodal Models for 5-Year Chronic Disease Cohort\n  Prediction Using EHR Data", "abstract": "Chronic diseases such as diabetes are the leading causes of morbidity and\nmortality worldwide. Numerous research studies have been attempted with various\ndeep learning models in diagnosis. However, most previous studies had certain\nlimitations, including using publicly available datasets (e.g. MIMIC), and\nimbalanced data. In this study, we collected five-year electronic health\nrecords (EHRs) from the Taiwan hospital database, including 1,420,596 clinical\nnotes, 387,392 laboratory test results, and more than 1,505 laboratory test\nitems, focusing on research pre-training large language models. We proposed a\nnovel Large Language Multimodal Models (LLMMs) framework incorporating\nmultimodal data from clinical notes and laboratory test results for the\nprediction of chronic disease risk. Our method combined a text embedding\nencoder and multi-head attention layer to learn laboratory test values,\nutilizing a deep neural network (DNN) module to merge blood features with\nchronic disease semantics into a latent space. In our experiments, we observe\nthat clinicalBERT and PubMed-BERT, when combined with attention fusion, can\nachieve an accuracy of 73% in multiclass chronic diseases and diabetes\nprediction. By transforming laboratory test values into textual descriptions\nand employing the Flan T-5 model, we achieved a 76% Area Under the ROC Curve\n(AUROC), demonstrating the effectiveness of leveraging numerical text data for\ntraining and inference in language models. This approach significantly improves\nthe accuracy of early-stage diabetes prediction.", "published": "2024-03-02 22:33:17", "link": "http://arxiv.org/abs/2403.04785v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Pseudo-Label Calibration Semi-supervised Multi-Modal Entity Alignment", "abstract": "Multi-modal entity alignment (MMEA) aims to identify equivalent entities\nbetween two multi-modal knowledge graphs for integration. Unfortunately, prior\narts have attempted to improve the interaction and fusion of multi-modal\ninformation, which have overlooked the influence of modal-specific noise and\nthe usage of labeled and unlabeled data in semi-supervised settings. In this\nwork, we introduce a Pseudo-label Calibration Multi-modal Entity Alignment\n(PCMEA) in a semi-supervised way. Specifically, in order to generate holistic\nentity representations, we first devise various embedding modules and attention\nmechanisms to extract visual, structural, relational, and attribute features.\nDifferent from the prior direct fusion methods, we next propose to exploit\nmutual information maximization to filter the modal-specific noise and to\naugment modal-invariant commonality. Then, we combine pseudo-label calibration\nwith momentum-based contrastive learning to make full use of the labeled and\nunlabeled data, which improves the quality of pseudo-label and pulls aligned\nentities closer. Finally, extensive experiments on two MMEA datasets\ndemonstrate the effectiveness of our PCMEA, which yields state-of-the-art\nperformance.", "published": "2024-03-02 12:44:59", "link": "http://arxiv.org/abs/2403.01203v1", "categories": ["cs.LG", "cs.CL", "cs.DB"], "primary_category": "cs.LG"}
{"title": "API Is Enough: Conformal Prediction for Large Language Models Without\n  Logit-Access", "abstract": "This study aims to address the pervasive challenge of quantifying uncertainty\nin large language models (LLMs) without logit-access. Conformal Prediction\n(CP), known for its model-agnostic and distribution-free features, is a desired\napproach for various LLMs and data distributions. However, existing CP methods\nfor LLMs typically assume access to the logits, which are unavailable for some\nAPI-only LLMs. In addition, logits are known to be miscalibrated, potentially\nleading to degraded CP performance. To tackle these challenges, we introduce a\nnovel CP method that (1) is tailored for API-only LLMs without logit-access;\n(2) minimizes the size of prediction sets; and (3) ensures a statistical\nguarantee of the user-defined coverage. The core idea of this approach is to\nformulate nonconformity measures using both coarse-grained (i.e., sample\nfrequency) and fine-grained uncertainty notions (e.g., semantic similarity).\nExperimental results on both close-ended and open-ended Question Answering\ntasks show our approach can mostly outperform the logit-based CP baselines.", "published": "2024-03-02 14:14:45", "link": "http://arxiv.org/abs/2403.01216v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Augmenting Automation: Intent-Based User Instruction Classification with\n  Machine Learning", "abstract": "Electric automation systems offer convenience and efficiency in controlling\nelectrical circuits and devices. Traditionally, these systems rely on\npredefined commands for control, limiting flexibility and adaptability. In this\npaper, we propose a novel approach to augment automation by introducing\nintent-based user instruction classification using machine learning techniques.\nOur system represents user instructions as intents, allowing for dynamic\ncontrol of electrical circuits without relying on predefined commands. Through\na machine learning model trained on a labeled dataset of user instructions, our\nsystem classifies intents from user input, enabling a more intuitive and\nadaptable control scheme. We present the design and implementation of our\nintent-based electric automation system, detailing the development of the\nmachine learning model for intent classification. Experimental results\ndemonstrate the effectiveness of our approach in enhancing user experience and\nexpanding the capabilities of electric automation systems. Our work contributes\nto the advancement of smart technologies by providing a more seamless\ninteraction between users and their environments.", "published": "2024-03-02 16:06:03", "link": "http://arxiv.org/abs/2403.01242v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.LG"}
{"title": "SceneCraft: An LLM Agent for Synthesizing 3D Scene as Blender Code", "abstract": "This paper introduces SceneCraft, a Large Language Model (LLM) Agent\nconverting text descriptions into Blender-executable Python scripts which\nrender complex scenes with up to a hundred 3D assets. This process requires\ncomplex spatial planning and arrangement. We tackle these challenges through a\ncombination of advanced abstraction, strategic planning, and library learning.\nSceneCraft first models a scene graph as a blueprint, detailing the spatial\nrelationships among assets in the scene. SceneCraft then writes Python scripts\nbased on this graph, translating relationships into numerical constraints for\nasset layout. Next, SceneCraft leverages the perceptual strengths of\nvision-language foundation models like GPT-V to analyze rendered images and\niteratively refine the scene. On top of this process, SceneCraft features a\nlibrary learning mechanism that compiles common script functions into a\nreusable library, facilitating continuous self-improvement without expensive\nLLM parameter tuning. Our evaluation demonstrates that SceneCraft surpasses\nexisting LLM-based agents in rendering complex scenes, as shown by its\nadherence to constraints and favorable human assessments. We also showcase the\nbroader application potential of SceneCraft by reconstructing detailed 3D\nscenes from the Sintel movie and guiding a video generative model with\ngenerated scenes as intermediary control signal.", "published": "2024-03-02 16:16:26", "link": "http://arxiv.org/abs/2403.01248v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "NoMAD-Attention: Efficient LLM Inference on CPUs Through\n  Multiply-add-free Attention", "abstract": "Large language model inference on Central Processing Units (CPU) is\nchallenging due to the vast quantities of expensive Multiply-Add (MAD) matrix\noperations in the attention computations. In this paper, we argue that there is\na rare gem in modern CPUs, Single-Instruction-Multiple-Data (SIMD) registers,\nwhich allow for ultra-low-latency lookups in batch. We leverage this unique\ncapability of CPUs to propose NoMAD-Attention, an efficient attention algorithm\nthat replaces MAD operations with in-register lookups. Through hardware-aware\nalgorithmic designs, NoMAD-Attention achieves the computation of attention\nscores using repeated fast accesses to SIMD registers despite their highly\nlimited sizes. Moreover, NoMAD-Attention works with pre-trained attention-based\nLLMs without model finetuning. Empirical evaluations demonstrate that\nNoMAD-Attention maintains the quality of the original LLMs well, and speeds up\nthe 4-bit quantized LLaMA-7B-based model by up to 2$\\times$ at 16k context\nlength. Our results are reproducible at\nhttps://github.com/tonyzhang617/nomad-dist.", "published": "2024-03-02 17:29:22", "link": "http://arxiv.org/abs/2403.01273v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "VBART: The Turkish LLM", "abstract": "We present VBART, the first Turkish sequence-to-sequence Large Language\nModels (LLMs) pre-trained on a large corpus from scratch. VBART are compact\nLLMs based on good ideas leveraged from BART and mBART models and come in two\nsizes, Large and XLarge. Fine-tuned VBART models surpass the prior\nstate-of-the-art results in abstractive text summarization, title generation,\ntext paraphrasing, question answering and question generation tasks. They allow\nfine-tuning for future text generation tasks and datasets, carving a new path\nfor Turkish Natural Language Processing (NLP) research. Our work shows that\nhaving a pre-trained LLM for Turkish outperforms up to 3x multilingual models,\nimproving existing results and providing efficient models for training and\ninference. Moreover, we show that our monolingual tokenizer is up to 11x more\nefficient than multilingual tokenizers. Last but not least, we introduce a\nmethod to enlarge an existing pre-trained LLM and question the relevancy of\nChinchilla Scaling Law to sequence-to-sequence masked language models. Our\nfine-tuned models, tokenizer and cleaned vngrs-web-corpus of 135 GB are\npublicly available at huggingface.co/vngrs-ai.", "published": "2024-03-02 20:40:11", "link": "http://arxiv.org/abs/2403.01308v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "VNLP: Turkish NLP Package", "abstract": "In this work, we present VNLP: the first dedicated, complete, open-source,\nwell-documented, lightweight, production-ready, state-of-the-art Natural\nLanguage Processing (NLP) package for the Turkish language. It contains a wide\nvariety of tools, ranging from the simplest tasks, such as sentence splitting\nand text normalization, to the more advanced ones, such as text and token\nclassification models. Its token classification models are based on \"Context\nModel\", a novel architecture that is both an encoder and an auto-regressive\nmodel. NLP tasks solved by VNLP models include but are not limited to Sentiment\nAnalysis, Named Entity Recognition, Morphological Analysis \\& Disambiguation\nand Part-of-Speech Tagging. Moreover, it comes with pre-trained word embeddings\nand corresponding SentencePiece Unigram tokenizers. VNLP has an open-source\nGitHub repository, ReadtheDocs documentation, PyPi package for convenient\ninstallation, Python and command-line API and a demo page to test all the\nfunctionality. Consequently, our main contribution is a complete, compact,\neasy-to-install and easy-to-use NLP package for Turkish.", "published": "2024-03-02 20:46:56", "link": "http://arxiv.org/abs/2403.01309v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks", "abstract": "Despite extensive pre-training in moral alignment to prevent generating\nharmful information, large language models (LLMs) remain vulnerable to\njailbreak attacks. In this paper, we propose AutoDefense, a multi-agent defense\nframework that filters harmful responses from LLMs. With the response-filtering\nmechanism, our framework is robust against different jailbreak attack prompts,\nand can be used to defend different victim models. AutoDefense assigns\ndifferent roles to LLM agents and employs them to complete the defense task\ncollaboratively. The division in tasks enhances the overall\ninstruction-following of LLMs and enables the integration of other defense\ncomponents as tools. With AutoDefense, small open-source LMs can serve as\nagents and defend larger models against jailbreak attacks. Our experiments show\nthat AutoDefense can effectively defense against different jailbreak attacks,\nwhile maintaining the performance at normal user request. For example, we\nreduce the attack success rate on GPT-3.5 from 55.74% to 7.95% using\nLLaMA-2-13b with a 3-agent system. Our code and data are publicly available at\nhttps://github.com/XHMY/AutoDefense.", "published": "2024-03-02 16:52:22", "link": "http://arxiv.org/abs/2403.04783v2", "categories": ["cs.LG", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "LLaMoCo: Instruction Tuning of Large Language Models for Optimization\n  Code Generation", "abstract": "Recent research explores optimization using large language models (LLMs) by\neither iteratively seeking next-step solutions from LLMs or directly prompting\nLLMs for an optimizer. However, these approaches exhibit inherent limitations,\nincluding low operational efficiency, high sensitivity to prompt design, and a\nlack of domain-specific knowledge. We introduce LLaMoCo, the first\ninstruction-tuning framework designed to adapt LLMs for solving optimization\nproblems in a code-to-code manner. Specifically, we establish a comprehensive\ninstruction set containing well-described problem prompts and effective\noptimization codes. We then develop a novel two-phase learning strategy that\nincorporates a contrastive learning-based warm-up procedure before the\ninstruction-tuning phase to enhance the convergence behavior during model\nfine-tuning. The experiment results demonstrate that a CodeGen (350M) model\nfine-tuned by our LLaMoCo achieves superior optimization performance compared\nto GPT-4 Turbo and the other competitors across both synthetic and realistic\nproblem sets. The fine-tuned model and the usage instructions are available at\nhttps://anonymous.4open.science/r/LLaMoCo-722A.", "published": "2024-03-02 08:21:59", "link": "http://arxiv.org/abs/2403.01131v2", "categories": ["math.OC", "cs.AI", "cs.CL", "cs.LG", "cs.NE", "cs.SE"], "primary_category": "math.OC"}
{"title": "Arbitrary Discrete Fourier Analysis and Its Application in Replayed\n  Speech Detection", "abstract": "In this paper, a group of finite sequences and its variants were proposed to\nuse in conducting signal analysis; we called the developed signal analysis\nmethods arbitrary discrete Fourier analysis (ADFA), Mel-scale discrete Fourier\nanalysis (MDFA) and constant Q analysis (CQA). The effectiveness of three\nsignal analysis methods were then validated by testing their performance on a\nreplayed speech detection benchmark (i.e., the ASVspoof 2019 Physical Access)\nalong with a state-of-the-art model. Comparable performance to the best\nreported systems were shown by the experimental results with three signal\nanalysis methods. Furthermore, the CQA method shown its efficiency with less\ncomputation time in compared to the convention method constant Q transform\n(CQT), which is commonly used in spoofed and fake speech detection and music\nprocessing.", "published": "2024-03-02 08:19:58", "link": "http://arxiv.org/abs/2403.01130v2", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Enhancing Audio Generation Diversity with Visual Information", "abstract": "Audio and sound generation has garnered significant attention in recent\nyears, with a primary focus on improving the quality of generated audios.\nHowever, there has been limited research on enhancing the diversity of\ngenerated audio, particularly when it comes to audio generation within specific\ncategories. Current models tend to produce homogeneous audio samples within a\ncategory. This work aims to address this limitation by improving the diversity\nof generated audio with visual information. We propose a clustering-based\nmethod, leveraging visual information to guide the model in generating distinct\naudio content within each category. Results on seven categories indicate that\nextra visual input can largely enhance audio generation diversity. Audio\nsamples are available at https://zeyuxie29.github.io/DiverseAudioGeneration.", "published": "2024-03-02 17:59:57", "link": "http://arxiv.org/abs/2403.01278v1", "categories": ["cs.SD", "eess.AS", "I.2"], "primary_category": "cs.SD"}
{"title": "Towards Accurate Lip-to-Speech Synthesis in-the-Wild", "abstract": "In this paper, we introduce a novel approach to address the task of\nsynthesizing speech from silent videos of any in-the-wild speaker solely based\non lip movements. The traditional approach of directly generating speech from\nlip videos faces the challenge of not being able to learn a robust language\nmodel from speech alone, resulting in unsatisfactory outcomes. To overcome this\nissue, we propose incorporating noisy text supervision using a state-of-the-art\nlip-to-text network that instills language information into our model. The\nnoisy text is generated using a pre-trained lip-to-text model, enabling our\napproach to work without text annotations during inference. We design a visual\ntext-to-speech network that utilizes the visual stream to generate accurate\nspeech, which is in-sync with the silent input video. We perform extensive\nexperiments and ablation studies, demonstrating our approach's superiority over\nthe current state-of-the-art methods on various benchmark datasets. Further, we\ndemonstrate an essential practical application of our method in assistive\ntechnology by generating speech for an ALS patient who has lost the voice but\ncan make mouth movements. Our demo video, code, and additional details can be\nfound at\n\\url{http://cvit.iiit.ac.in/research/projects/cvit-projects/ms-l2s-itw}.", "published": "2024-03-02 04:07:24", "link": "http://arxiv.org/abs/2403.01087v1", "categories": ["cs.MM", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "MPIPN: A Multi Physics-Informed PointNet for solving parametric\n  acoustic-structure systems", "abstract": "Machine learning is employed for solving physical systems governed by general\nnonlinear partial differential equations (PDEs). However, complex multi-physics\nsystems such as acoustic-structure coupling are often described by a series of\nPDEs that incorporate variable physical quantities, which are referred to as\nparametric systems. There are lack of strategies for solving parametric systems\ngoverned by PDEs that involve explicit and implicit quantities. In this paper,\na deep learning-based Multi Physics-Informed PointNet (MPIPN) is proposed for\nsolving parametric acoustic-structure systems. First, the MPIPN induces an\nenhanced point-cloud architecture that encompasses explicit physical quantities\nand geometric features of computational domains. Then, the MPIPN extracts local\nand global features of the reconstructed point-cloud as parts of solving\ncriteria of parametric systems, respectively. Besides, implicit physical\nquantities are embedded by encoding techniques as another part of solving\ncriteria. Finally, all solving criteria that characterize parametric systems\nare amalgamated to form distinctive sequences as the input of the MPIPN, whose\noutputs are solutions of systems. The proposed framework is trained by adaptive\nphysics-informed loss functions for corresponding computational domains. The\nframework is generalized to deal with new parametric conditions of systems. The\neffectiveness of the MPIPN is validated by applying it to solve steady\nparametric acoustic-structure coupling systems governed by the Helmholtz\nequations. An ablation experiment has been implemented to demonstrate the\nefficacy of physics-informed impact with a minority of supervised data. The\nproposed method yields reasonable precision across all computational domains\nunder constant parametric conditions and changeable combinations of parametric\nconditions for acoustic-structure systems.", "published": "2024-03-02 08:27:05", "link": "http://arxiv.org/abs/2403.01132v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Automatic Speech Recognition using Advanced Deep Learning Approaches: A\n  survey", "abstract": "Recent advancements in deep learning (DL) have posed a significant challenge\nfor automatic speech recognition (ASR). ASR relies on extensive training\ndatasets, including confidential ones, and demands substantial computational\nand storage resources. Enabling adaptive systems improves ASR performance in\ndynamic environments. DL techniques assume training and testing data originate\nfrom the same domain, which is not always true. Advanced DL techniques like\ndeep transfer learning (DTL), federated learning (FL), and reinforcement\nlearning (RL) address these issues. DTL allows high-performance models using\nsmall yet related datasets, FL enables training on confidential data without\ndataset possession, and RL optimizes decision-making in dynamic environments,\nreducing computation costs. This survey offers a comprehensive review of DTL,\nFL, and RL-based ASR frameworks, aiming to provide insights into the latest\ndevelopments and aid researchers and professionals in understanding the current\nchallenges. Additionally, transformers, which are advanced DL techniques\nheavily used in proposed ASR frameworks, are considered in this survey for\ntheir ability to capture extensive dependencies in the input ASR sequence. The\npaper starts by presenting the background of DTL, FL, RL, and Transformers and\nthen adopts a well-designed taxonomy to outline the state-of-the-art\napproaches. Subsequently, a critical analysis is conducted to identify the\nstrengths and weaknesses of each framework. Additionally, a comparative study\nis presented to highlight the existing challenges, paving the way for future\nresearch opportunities.", "published": "2024-03-02 16:25:42", "link": "http://arxiv.org/abs/2403.01255v2", "categories": ["cs.SD", "cs.AI", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
{"title": "A Cross-Modal Approach to Silent Speech with LLM-Enhanced Recognition", "abstract": "Silent Speech Interfaces (SSIs) offer a noninvasive alternative to\nbrain-computer interfaces for soundless verbal communication. We introduce\nMultimodal Orofacial Neural Audio (MONA), a system that leverages cross-modal\nalignment through novel loss functions--cross-contrast (crossCon) and\nsupervised temporal contrast (supTcon)--to train a multimodal model with a\nshared latent representation. This architecture enables the use of audio-only\ndatasets like LibriSpeech to improve silent speech recognition. Additionally,\nour introduction of Large Language Model (LLM) Integrated Scoring Adjustment\n(LISA) significantly improves recognition accuracy. Together, MONA LISA reduces\nthe state-of-the-art word error rate (WER) from 28.8% to 12.2% in the Gaddy\n(2020) benchmark dataset for silent speech on an open vocabulary. For vocal EMG\nrecordings, our method improves the state-of-the-art from 23.3% to 3.7% WER. In\nthe Brain-to-Text 2024 competition, LISA performs best, improving the top WER\nfrom 9.8% to 8.9%. To the best of our knowledge, this work represents the first\ninstance where noninvasive silent speech recognition on an open vocabulary has\ncleared the threshold of 15% WER, demonstrating that SSIs can be a viable\nalternative to automatic speech recognition (ASR). Our work not only narrows\nthe performance gap between silent and vocalized speech but also opens new\npossibilities in human-computer interaction, demonstrating the potential of\ncross-modal approaches in noisy and data-limited regimes.", "published": "2024-03-02 21:15:24", "link": "http://arxiv.org/abs/2403.05583v1", "categories": ["cs.HC", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
