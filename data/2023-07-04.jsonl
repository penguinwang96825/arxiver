{"title": "Modeling Tag Prediction based on Question Tagging Behavior Analysis of\n  CommunityQA Platform Users", "abstract": "In community question-answering platforms, tags play essential roles in\neffective information organization and retrieval, better question routing,\nfaster response to questions, and assessment of topic popularity. Hence,\nautomatic assistance for predicting and suggesting tags for posts is of high\nutility to users of such platforms. To develop better tag prediction across\ndiverse communities and domains, we performed a thorough analysis of users'\ntagging behavior in 17 StackExchange communities. We found various common\ninherent properties of this behavior in those diverse domains. We used the\nfindings to develop a flexible neural tag prediction architecture, which\npredicts both popular tags and more granular tags for each question. Our\nextensive experiments and obtained performance show the effectiveness of our\nmodel", "published": "2023-07-04 01:24:26", "link": "http://arxiv.org/abs/2307.01420v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ReactIE: Enhancing Chemical Reaction Extraction with Weak Supervision", "abstract": "Structured chemical reaction information plays a vital role for chemists\nengaged in laboratory work and advanced endeavors such as computer-aided drug\ndesign. Despite the importance of extracting structured reactions from\nscientific literature, data annotation for this purpose is cost-prohibitive due\nto the significant labor required from domain experts. Consequently, the\nscarcity of sufficient training data poses an obstacle to the progress of\nrelated models in this domain. In this paper, we propose ReactIE, which\ncombines two weakly supervised approaches for pre-training. Our method utilizes\nfrequent patterns within the text as linguistic cues to identify specific\ncharacteristics of chemical reactions. Additionally, we adopt synthetic data\nfrom patent records as distant supervision to incorporate domain knowledge into\nthe model. Experiments demonstrate that ReactIE achieves substantial\nimprovements and outperforms all existing baselines.", "published": "2023-07-04 02:52:30", "link": "http://arxiv.org/abs/2307.01448v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Diverse Retrieval-Augmented In-Context Learning for Dialogue State\n  Tracking", "abstract": "There has been significant interest in zero and few-shot learning for\ndialogue state tracking (DST) due to the high cost of collecting and annotating\ntask-oriented dialogues. Recent work has demonstrated that in-context learning\nrequires very little data and zero parameter updates, and even outperforms\ntrained methods in the few-shot setting (Hu et al. 2022). We propose RefPyDST,\nwhich advances the state of the art with three advancements to in-context\nlearning for DST. First, we formulate DST as a Python programming task,\nexplicitly modeling language coreference as variable reference in Python.\nSecond, since in-context learning depends highly on the context examples, we\npropose a method to retrieve a diverse set of relevant examples to improve\nperformance. Finally, we introduce a novel re-weighting method during decoding\nthat takes into account probabilities of competing surface forms, and produces\na more accurate dialogue state prediction. We evaluate our approach using\nMultiWOZ and achieve state-of-the-art multi-domain joint-goal accuracy in zero\nand few-shot settings.", "published": "2023-07-04 03:15:52", "link": "http://arxiv.org/abs/2307.01453v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CARE-MI: Chinese Benchmark for Misinformation Evaluation in Maternity\n  and Infant Care", "abstract": "The recent advances in natural language processing (NLP), have led to a new\ntrend of applying large language models (LLMs) to real-world scenarios. While\nthe latest LLMs are astonishingly fluent when interacting with humans, they\nsuffer from the misinformation problem by unintentionally generating factually\nfalse statements. This can lead to harmful consequences, especially when\nproduced within sensitive contexts, such as healthcare. Yet few previous works\nhave focused on evaluating misinformation in the long-form (LF) generation of\nLLMs, especially for knowledge-intensive topics. Moreover, although LLMs have\nbeen shown to perform well in different languages, misinformation evaluation\nhas been mostly conducted in English. To this end, we present a benchmark,\nCARE-MI, for evaluating LLM misinformation in: 1) a sensitive topic,\nspecifically the maternity and infant care domain; and 2) a language other than\nEnglish, namely Chinese. Most importantly, we provide an innovative paradigm\nfor building LF generation evaluation benchmarks that can be transferred to\nother knowledge-intensive domains and low-resourced languages. Our proposed\nbenchmark fills the gap between the extensive usage of LLMs and the lack of\ndatasets for assessing the misinformation generated by these models. It\ncontains 1,612 expert-checked questions, accompanied with human-selected\nreferences. Using our benchmark, we conduct extensive experiments and found\nthat current Chinese LLMs are far from perfect in the topic of maternity and\ninfant care. In an effort to minimize the reliance on human resources for\nperformance evaluation, we offer off-the-shelf judgment models for\nautomatically assessing the LF output of LLMs given benchmark questions.\nMoreover, we compare potential solutions for LF generation evaluation and\nprovide insights for building better automated metrics.", "published": "2023-07-04 03:34:19", "link": "http://arxiv.org/abs/2307.01458v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SCAT: Robust Self-supervised Contrastive Learning via Adversarial\n  Training for Text Classification", "abstract": "Despite their promising performance across various natural language\nprocessing (NLP) tasks, current NLP systems are vulnerable to textual\nadversarial attacks. To defend against these attacks, most existing methods\napply adversarial training by incorporating adversarial examples. However,\nthese methods have to rely on ground-truth labels to generate adversarial\nexamples, rendering it impractical for large-scale model pre-training which is\ncommonly used nowadays for NLP and many other tasks. In this paper, we propose\na novel learning framework called SCAT (Self-supervised Contrastive Learning\nvia Adversarial Training), which can learn robust representations without\nrequiring labeled data. Specifically, SCAT modifies random augmentations of the\ndata in a fully labelfree manner to generate adversarial examples. Adversarial\ntraining is achieved by minimizing the contrastive loss between the\naugmentations and their adversarial counterparts. We evaluate SCAT on two text\nclassification datasets using two state-of-the-art attack schemes proposed\nrecently. Our results show that SCAT can not only train robust language models\nfrom scratch, but it can also significantly improve the robustness of existing\npre-trained language models. Moreover, to demonstrate its flexibility, we show\nthat SCAT can also be combined with supervised adversarial training to further\nenhance model robustness.", "published": "2023-07-04 05:41:31", "link": "http://arxiv.org/abs/2307.01488v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On Evaluating and Mitigating Gender Biases in Multilingual Settings", "abstract": "While understanding and removing gender biases in language models has been a\nlong-standing problem in Natural Language Processing, prior research work has\nprimarily been limited to English. In this work, we investigate some of the\nchallenges with evaluating and mitigating biases in multilingual settings which\nstem from a lack of existing benchmarks and resources for bias evaluation\nbeyond English especially for non-western context. In this paper, we first\ncreate a benchmark for evaluating gender biases in pre-trained masked language\nmodels by extending DisCo to different Indian languages using human\nannotations. We extend various debiasing methods to work beyond English and\nevaluate their effectiveness for SOTA massively multilingual models on our\nproposed metric. Overall, our work highlights the challenges that arise while\nstudying social biases in multilingual settings and provides resources as well\nas mitigation techniques to take a step toward scaling to more languages.", "published": "2023-07-04 06:23:04", "link": "http://arxiv.org/abs/2307.01503v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mitigating the Learning Bias towards Repetition by Self-Contrastive\n  Training for Open-Ended Generation", "abstract": "Despite the huge progress in myriad generation tasks, pretrained language\nmodels (LMs) such as GPT2 still tend to generate repetitive texts with\nmaximization-based decoding algorithms for open-ended generation. We attribute\ntheir overestimation of token-level repetition probabilities to the learning\nbias: LMs capture simple repetitive patterns faster with the MLE loss. We\npropose self-contrastive training to penalize the output of a premature\ncheckpoint of the same model when it incorrectly predicts repetition, which is\nshown to mitigate repetition effectively while maintaining fluency on two\ndatasets. Furthermore, we find that LMs use longer-range dependencies to\npredict repetitive tokens than non-repetitive ones, which may be the cause of\nsentence-level repetition loops.", "published": "2023-07-04 07:53:55", "link": "http://arxiv.org/abs/2307.01542v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Language Model for Grammatical Error Correction in L2 Russian", "abstract": "Grammatical error correction is one of the fundamental tasks in Natural\nLanguage Processing. For the Russian language, most of the spellcheckers\navailable correct typos and other simple errors with high accuracy, but often\nfail when faced with non-native (L2) writing, since the latter contains errors\nthat are not typical for native speakers. In this paper, we propose a pipeline\ninvolving a language model intended for correcting errors in L2 Russian\nwriting. The language model proposed is trained on untagged texts of the\nNewspaper subcorpus of the Russian National Corpus, and the quality of the\nmodel is validated against the RULEC-GEC corpus.", "published": "2023-07-04 09:50:13", "link": "http://arxiv.org/abs/2307.01609v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chain of Thought Prompting Elicits Knowledge Augmentation", "abstract": "The knowledge-augmented deep learning paradigm refers to a paradigm in which\ndomain knowledge is identified and integrated into deep models. Conventional\nmethods typically employ task-specific approaches to gather external knowledge\nfrom various sources. In contrast, large language models are extensively\npre-trained and can serve as a comprehensive source of external knowledge. In\nthis paper, we propose CoT-KA, a Chain-of-Thought-based method that augments\nknowledge for deep learning. CoT-KA avoids the need for additional knowledge\nretrieval or knowledge reasoning models, as required in conventional\naugmentation methods. Our results demonstrate that CoT-KA outperforms both pure\nCoT-based methods and the non-augmented method across the majority of eleven\npublicly available benchmarks for various reasoning tasks.", "published": "2023-07-04 10:51:16", "link": "http://arxiv.org/abs/2307.01640v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unified Conversational Models with System-Initiated Transitions between\n  Chit-Chat and Task-Oriented Dialogues", "abstract": "Spoken dialogue systems (SDSs) have been separately developed under two\ndifferent categories, task-oriented and chit-chat. The former focuses on\nachieving functional goals and the latter aims at creating engaging social\nconversations without special goals. Creating a unified conversational model\nthat can engage in both chit-chat and task-oriented dialogue is a promising\nresearch topic in recent years. However, the potential ``initiative'' that\noccurs when there is a change between dialogue modes in one dialogue has rarely\nbeen explored. In this work, we investigate two kinds of dialogue scenarios,\none starts from chit-chat implicitly involving task-related topics and finally\nswitching to task-oriented requests; the other starts from task-oriented\ninteraction and eventually changes to casual chat after all requested\ninformation is provided. We contribute two efficient prompt models which can\nproactively generate a transition sentence to trigger system-initiated\ntransitions in a unified dialogue model. One is a discrete prompt model trained\nwith two discrete tokens, the other one is a continuous prompt model using\ncontinuous prompt embeddings automatically generated by a classifier. We\nfurthermore show that the continuous prompt model can also be used to guide the\nproactive transitions between particular domains in a multi-domain\ntask-oriented setting.", "published": "2023-07-04 11:53:23", "link": "http://arxiv.org/abs/2307.01664v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Boosting Norwegian Automatic Speech Recognition", "abstract": "In this paper, we present several baselines for automatic speech recognition\n(ASR) models for the two official written languages in Norway: Bokm{\\aa}l and\nNynorsk. We compare the performance of models of varying sizes and pre-training\napproaches on multiple Norwegian speech datasets. Additionally, we measure the\nperformance of these models against previous state-of-the-art ASR models, as\nwell as on out-of-domain datasets. We improve the state of the art on the\nNorwegian Parliamentary Speech Corpus (NPSC) from a word error rate (WER) of\n17.10\\% to 7.60\\%, with models achieving 5.81\\% for Bokm{\\aa}l and 11.54\\% for\nNynorsk. We also discuss the challenges and potential solutions for further\nimproving ASR models for Norwegian.", "published": "2023-07-04 12:05:15", "link": "http://arxiv.org/abs/2307.01672v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Robust Hate Speech Detection in Social Media: A Cross-Dataset Empirical\n  Evaluation", "abstract": "The automatic detection of hate speech online is an active research area in\nNLP. Most of the studies to date are based on social media datasets that\ncontribute to the creation of hate speech detection models trained on them.\nHowever, data creation processes contain their own biases, and models\ninherently learn from these dataset-specific biases. In this paper, we perform\na large-scale cross-dataset comparison where we fine-tune language models on\ndifferent hate speech detection datasets. This analysis shows how some datasets\nare more generalisable than others when used as training data. Crucially, our\nexperiments show how combining hate speech detection datasets can contribute to\nthe development of robust hate speech detection models. This robustness holds\neven when controlling by data size and compared with the best individual\ndatasets.", "published": "2023-07-04 12:22:40", "link": "http://arxiv.org/abs/2307.01680v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Racial Bias Trends in the Text of US Legal Opinions", "abstract": "Although there is widespread recognition of racial bias in US law, it is\nunclear how such bias appears in the language of law, namely judicial opinions,\nand whether it varies across time period or region. Building upon approaches\nfor measuring implicit racial bias in large-scale corpora, we approximate GloVe\nword embeddings for over 6 million US federal and state court cases from 1860\nto 2009. We find strong evidence of racial bias across nearly all regions and\ntime periods, as traditionally Black names are more closely associated with\npre-classified \"unpleasant\" terms whereas traditionally White names are more\nclosely associated with pre-classified \"pleasant\" terms. We also test whether\nlegal opinions before 1950 exhibit more implicit racial bias than those after\n1950, as well as whether opinions from Southern states exhibit less change in\nracial bias than those from Northeastern states. We do not find evidence of\nelevated bias in legal opinions before 1950, or evidence that legal opinions\nfrom Northeastern states show greater change in racial bias over time compared\nto Southern states. These results motivate further research into\ninstitutionalized racial bias.", "published": "2023-07-04 12:56:23", "link": "http://arxiv.org/abs/2307.01693v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dipping PLMs Sauce: Bridging Structure and Text for Effective Knowledge\n  Graph Completion via Conditional Soft Prompting", "abstract": "Knowledge Graph Completion (KGC) often requires both KG structural and\ntextual information to be effective. Pre-trained Language Models (PLMs) have\nbeen used to learn the textual information, usually under the fine-tune\nparadigm for the KGC task. However, the fine-tuned PLMs often overwhelmingly\nfocus on the textual information and overlook structural knowledge. To tackle\nthis issue, this paper proposes CSProm-KG (Conditional Soft Prompts for KGC)\nwhich maintains a balance between structural information and textual knowledge.\nCSProm-KG only tunes the parameters of Conditional Soft Prompts that are\ngenerated by the entities and relations representations. We verify the\neffectiveness of CSProm-KG on three popular static KGC benchmarks WN18RR,\nFB15K-237 and Wikidata5M, and two temporal KGC benchmarks ICEWS14 and\nICEWS05-15. CSProm-KG outperforms competitive baseline models and sets new\nstate-of-the-art on these benchmarks. We conduct further analysis to show (i)\nthe effectiveness of our proposed components, (ii) the efficiency of CSProm-KG,\nand (iii) the flexibility of CSProm-KG.", "published": "2023-07-04 13:24:04", "link": "http://arxiv.org/abs/2307.01709v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge-Aware Audio-Grounded Generative Slot Filling for Limited\n  Annotated Data", "abstract": "Manually annotating fine-grained slot-value labels for task-oriented dialogue\n(ToD) systems is an expensive and time-consuming endeavour. This motivates\nresearch into slot-filling methods that operate with limited amounts of\nlabelled data. Moreover, the majority of current work on ToD is based solely on\ntext as the input modality, neglecting the additional challenges of imperfect\nautomatic speech recognition (ASR) when working with spoken language. In this\nwork, we propose a Knowledge-Aware Audio-Grounded generative slot-filling\nframework, termed KA2G, that focuses on few-shot and zero-shot slot filling for\nToD with speech input. KA2G achieves robust and data-efficient slot filling for\nspeech-based ToD by 1) framing it as a text generation task, 2) grounding text\ngeneration additionally in the audio modality, and 3) conditioning on available\nexternal knowledge (e.g. a predefined list of possible slot values). We show\nthat combining both modalities within the KA2G framework improves the\nrobustness against ASR errors. Further, the knowledge-aware slot-value\ngenerator in KA2G, implemented via a pointer generator mechanism, particularly\nbenefits few-shot and zero-shot learning. Experiments, conducted on the\nstandard speech-based single-turn SLURP dataset and a multi-turn dataset\nextracted from a commercial ToD system, display strong and consistent gains\nover prior work, especially in few-shot and zero-shot setups.", "published": "2023-07-04 15:05:42", "link": "http://arxiv.org/abs/2307.01764v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transformed Protoform Reconstruction", "abstract": "Protoform reconstruction is the task of inferring what morphemes or words\nappeared like in the ancestral languages of a set of daughter languages. Meloni\net al. (2021) achieved the state-of-the-art on Latin protoform reconstruction\nwith an RNN-based encoder-decoder with attention model. We update their model\nwith the state-of-the-art seq2seq model: the Transformer. Our model outperforms\ntheir model on a suite of different metrics on two different datasets: their\nRomance data of 8,000 cognates spanning 5 languages and a Chinese dataset (Hou\n2004) of 800+ cognates spanning 39 varieties. We also probe our model for\npotential phylogenetic signal contained in the model. Our code is publicly\navailable at https://github.com/cmu-llab/acl-2023.", "published": "2023-07-04 19:40:20", "link": "http://arxiv.org/abs/2307.01896v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On Conditional and Compositional Language Model Differentiable Prompting", "abstract": "Prompts have been shown to be an effective method to adapt a frozen\nPretrained Language Model (PLM) to perform well on downstream tasks. Prompts\ncan be represented by a human-engineered word sequence or by a learned\ncontinuous embedding. In this work, we investigate conditional and\ncompositional differentiable prompting. We propose a new model, Prompt\nProduction System (PRopS), which learns to transform task instructions or input\nmetadata, into continuous prompts that elicit task-specific outputs from the\nPLM. Our model uses a modular network structure based on our neural formulation\nof Production Systems, which allows the model to learn discrete rules -- neural\nfunctions that learn to specialize in transforming particular prompt input\npatterns, making it suitable for compositional transfer learning and few-shot\nlearning. We present extensive empirical and theoretical analysis and show that\nPRopS consistently surpasses other PLM adaptation techniques, and often\nimproves upon fully fine-tuned models, on compositional generalization tasks,\ncontrollable summarization and multilingual translation, while needing fewer\ntrainable parameters.", "published": "2023-07-04 02:47:42", "link": "http://arxiv.org/abs/2307.01446v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Prompt Tuning Pushes Farther, Contrastive Learning Pulls Closer: A\n  Two-Stage Approach to Mitigate Social Biases", "abstract": "As the representation capability of Pre-trained Language Models (PLMs)\nimprove, there is growing concern that they will inherit social biases from\nunprocessed corpora. Most previous debiasing techniques used Counterfactual\nData Augmentation (CDA) to balance the training corpus. However, CDA slightly\nmodifies the original corpus, limiting the representation distance between\ndifferent demographic groups to a narrow range. As a result, the debiasing\nmodel easily fits the differences between counterfactual pairs, which affects\nits debiasing performance with limited text resources. In this paper, we\npropose an adversarial training-inspired two-stage debiasing model using\nContrastive learning with Continuous Prompt Augmentation (named CCPA) to\nmitigate social biases in PLMs' encoding. In the first stage, we propose a data\naugmentation method based on continuous prompt tuning to push farther the\nrepresentation distance between sample pairs along different demographic\ngroups. In the second stage, we utilize contrastive learning to pull closer the\nrepresentation distance between the augmented sample pairs and then fine-tune\nPLMs' parameters to get debiased encoding. Our approach guides the model to\nachieve stronger debiasing performance by adding difficulty to the training\nprocess. Extensive experiments show that CCPA outperforms baselines in terms of\ndebiasing performance. Meanwhile, experimental results on the GLUE benchmark\nshow that CCPA retains the language modeling capability of PLMs.", "published": "2023-07-04 09:35:03", "link": "http://arxiv.org/abs/2307.01595v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Inner Sentiments of a Thought", "abstract": "Transformer-based large-scale language models (LLMs) are able to generate\nhighly realistic text. They are duly able to express, and at least implicitly\nrepresent, a wide range of sentiments and color, from the obvious, such as\nvalence and arousal to the subtle, such as determination and admiration. We\nprovide a first exploration of these representations and how they can be used\nfor understanding the inner sentimental workings of single sentences. We train\npredictors of the quantiles of the distributions of final sentiments of\nsentences from the hidden representations of an LLM applied to prefixes of\nincreasing lengths. After showing that predictors of distributions of valence,\ndetermination, admiration, anxiety and annoyance are well calibrated, we\nprovide examples of using these predictors for analyzing sentences,\nillustrating, for instance, how even ordinary conjunctions (e.g., \"but\") can\ndramatically alter the emotional trajectory of an utterance. We then show how\nto exploit the distributional predictions to generate sentences with sentiments\nin the tails of distributions. We discuss the implications of our results for\nthe inner workings of thoughts, for instance for psychiatric dysfunction.", "published": "2023-07-04 15:44:37", "link": "http://arxiv.org/abs/2307.01784v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring Non-Verbal Predicates in Semantic Role Labeling: Challenges\n  and Opportunities", "abstract": "Although we have witnessed impressive progress in Semantic Role Labeling\n(SRL), most of the research in the area is carried out assuming that the\nmajority of predicates are verbs. Conversely, predicates can also be expressed\nusing other parts of speech, e.g., nouns and adjectives. However, non-verbal\npredicates appear in the benchmarks we commonly use to measure progress in SRL\nless frequently than in some real-world settings -- newspaper headlines,\ndialogues, and tweets, among others. In this paper, we put forward a new\nPropBank dataset which boasts wide coverage of multiple predicate types. Thanks\nto it, we demonstrate empirically that standard benchmarks do not provide an\naccurate picture of the current situation in SRL and that state-of-the-art\nsystems are still incapable of transferring knowledge across different\npredicate types. Having observed these issues, we also present a novel,\nmanually-annotated challenge set designed to give equal importance to verbal,\nnominal, and adjectival predicate-argument structures. We use such dataset to\ninvestigate whether we can leverage different linguistic resources to promote\nknowledge transfer. In conclusion, we claim that SRL is far from \"solved\", and\nits integration with other semantic tasks might enable significant improvements\nin the future, especially for the long tail of non-verbal predicates, thereby\nfacilitating further research on SRL for non-verbal predicates.", "published": "2023-07-04 18:28:59", "link": "http://arxiv.org/abs/2307.01870v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "KDSTM: Neural Semi-supervised Topic Modeling with Knowledge Distillation", "abstract": "In text classification tasks, fine tuning pretrained language models like\nBERT and GPT-3 yields competitive accuracy; however, both methods require\npretraining on large text datasets. In contrast, general topic modeling methods\npossess the advantage of analyzing documents to extract meaningful patterns of\nwords without the need of pretraining. To leverage topic modeling's\nunsupervised insights extraction on text classification tasks, we develop the\nKnowledge Distillation Semi-supervised Topic Modeling (KDSTM). KDSTM requires\nno pretrained embeddings, few labeled documents and is efficient to train,\nmaking it ideal under resource constrained settings. Across a variety of\ndatasets, our method outperforms existing supervised topic modeling methods in\nclassification accuracy, robustness and efficiency and achieves similar\nperformance compare to state of the art weakly supervised text classification\nmethods.", "published": "2023-07-04 18:49:19", "link": "http://arxiv.org/abs/2307.01878v2", "categories": ["cs.CL", "cs.AI", "68T50", "I.2.6"], "primary_category": "cs.CL"}
{"title": "ProPILE: Probing Privacy Leakage in Large Language Models", "abstract": "The rapid advancement and widespread use of large language models (LLMs) have\nraised significant concerns regarding the potential leakage of personally\nidentifiable information (PII). These models are often trained on vast\nquantities of web-collected data, which may inadvertently include sensitive\npersonal data. This paper presents ProPILE, a novel probing tool designed to\nempower data subjects, or the owners of the PII, with awareness of potential\nPII leakage in LLM-based services. ProPILE lets data subjects formulate prompts\nbased on their own PII to evaluate the level of privacy intrusion in LLMs. We\ndemonstrate its application on the OPT-1.3B model trained on the publicly\navailable Pile dataset. We show how hypothetical data subjects may assess the\nlikelihood of their PII being included in the Pile dataset being revealed.\nProPILE can also be leveraged by LLM service providers to effectively evaluate\ntheir own levels of PII leakage with more powerful prompts specifically tuned\nfor their in-house models. This tool represents a pioneering step towards\nempowering the data subjects for their awareness and control over their own\ndata on the web.", "published": "2023-07-04 18:53:47", "link": "http://arxiv.org/abs/2307.01881v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Concept-Based Explanations to Test for False Causal Relationships\n  Learned by Abusive Language Classifiers", "abstract": "Classifiers tend to learn a false causal relationship between an\nover-represented concept and a label, which can result in over-reliance on the\nconcept and compromised classification accuracy. It is imperative to have\nmethods in place that can compare different models and identify over-reliances\non specific concepts. We consider three well-known abusive language classifiers\ntrained on large English datasets and focus on the concept of negative\nemotions, which is an important signal but should not be learned as a\nsufficient feature for the label of abuse. Motivated by the definition of\nglobal sufficiency, we first examine the unwanted dependencies learned by the\nclassifiers by assessing their accuracy on a challenge set across all decision\nthresholds. Further, recognizing that a challenge set might not always be\navailable, we introduce concept-based explanation metrics to assess the\ninfluence of the concept on the labels. These explanations allow us to compare\nclassifiers regarding the degree of false global sufficiency they have learned\nbetween a concept and a label.", "published": "2023-07-04 19:57:54", "link": "http://arxiv.org/abs/2307.01900v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "mPLUG-DocOwl: Modularized Multimodal Large Language Model for Document\n  Understanding", "abstract": "Document understanding refers to automatically extract, analyze and\ncomprehend information from various types of digital documents, such as a web\npage. Existing Multi-model Large Language Models (MLLMs), including mPLUG-Owl,\nhave demonstrated promising zero-shot capabilities in shallow OCR-free text\nrecognition, indicating their potential for OCR-free document understanding.\nNevertheless, without in-domain training, these models tend to ignore\nfine-grained OCR features, such as sophisticated tables or large blocks of\ntext, which are essential for OCR-free document understanding. In this paper,\nwe propose mPLUG-DocOwl based on mPLUG-Owl for OCR-free document understanding.\nSpecifically, we first construct a instruction tuning dataset featuring a wide\nrange of visual-text understanding tasks. Then, we strengthen the OCR-free\ndocument understanding ability by jointly train the model on language-only,\ngeneral vision-and-language, and document instruction tuning dataset with our\nunified instruction tuning strategy. We also build an OCR-free document\ninstruction understanding evaluation set LLMDoc to better compare models'\ncapabilities on instruct compliance and document understanding. Experimental\nresults show that our model outperforms existing multi-modal models,\ndemonstrating its strong ability of document understanding. Besides, without\nspecific fine-tuning, mPLUG-DocOwl generalizes well on various downstream\ntasks. Our code, models, training data and evaluation set are available at\nhttps://github.com/X-PLUG/mPLUG-DocOwl.", "published": "2023-07-04 11:28:07", "link": "http://arxiv.org/abs/2307.02499v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learning to Prompt in the Classroom to Understand AI Limits: A pilot\n  study", "abstract": "Artificial intelligence's (AI) progress holds great promise in tackling\npressing societal concerns such as health and climate. Large Language Models\n(LLM) and the derived chatbots, like ChatGPT, have highly improved the natural\nlanguage processing capabilities of AI systems allowing them to process an\nunprecedented amount of unstructured data. However, the ensuing excitement has\nled to negative sentiments, even as AI methods demonstrate remarkable\ncontributions (e.g. in health and genetics). A key factor contributing to this\nsentiment is the misleading perception that LLMs can effortlessly provide\nsolutions across domains, ignoring their limitations such as hallucinations and\nreasoning constraints. Acknowledging AI fallibility is crucial to address the\nimpact of dogmatic overconfidence in possibly erroneous suggestions generated\nby LLMs. At the same time, it can reduce fear and other negative attitudes\ntoward AI. This necessitates comprehensive AI literacy interventions that\neducate the public about LLM constraints and effective usage techniques, i.e\nprompting strategies. With this aim, a pilot educational intervention was\nperformed in a high school with 21 students. It involved presenting high-level\nconcepts about intelligence, AI, and LLMs, followed by practical exercises\ninvolving ChatGPT in creating natural educational conversations and applying\nestablished prompting strategies. Encouraging preliminary results emerged,\nincluding high appreciation of the activity, improved interaction quality with\nthe LLM, reduced negative AI sentiments, and a better grasp of limitations,\nspecifically unreliability, limited understanding of commands leading to\nunsatisfactory responses, and limited presentation flexibility. Our aim is to\nexplore AI acceptance factors and refine this approach for more controlled\nfuture studies.", "published": "2023-07-04 07:51:37", "link": "http://arxiv.org/abs/2307.01540v2", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Insert-expansions for Tool-enabled Conversational Agents", "abstract": "This paper delves into an advanced implementation of\nChain-of-Thought-Prompting in Large Language Models, focusing on the use of\ntools (or \"plug-ins\") within the explicit reasoning paths generated by this\nprompting method. We find that tool-enabled conversational agents often become\nsidetracked, as additional context from tools like search engines or\ncalculators diverts from original user intents. To address this, we explore a\nconcept wherein the user becomes the tool, providing necessary details and\nrefining their requests. Through Conversation Analysis, we characterize this\ninteraction as insert-expansion - an intermediary conversation designed to\nfacilitate the preferred response. We explore possibilities arising from this\n'user-as-a-tool' approach in two empirical studies using direct comparison, and\nfind benefits in the recommendation domain.", "published": "2023-07-04 10:57:31", "link": "http://arxiv.org/abs/2307.01644v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "H.5"], "primary_category": "cs.HC"}
{"title": "Disentanglement in a GAN for Unconditional Speech Synthesis", "abstract": "Can we develop a model that can synthesize realistic speech directly from a\nlatent space, without explicit conditioning? Despite several efforts over the\nlast decade, previous adversarial and diffusion-based approaches still struggle\nto achieve this, even on small-vocabulary datasets. To address this, we propose\nAudioStyleGAN (ASGAN) -- a generative adversarial network for unconditional\nspeech synthesis tailored to learn a disentangled latent space. Building upon\nthe StyleGAN family of image synthesis models, ASGAN maps sampled noise to a\ndisentangled latent vector which is then mapped to a sequence of audio features\nso that signal aliasing is suppressed at every layer. To successfully train\nASGAN, we introduce a number of new techniques, including a modification to\nadaptive discriminator augmentation which probabilistically skips discriminator\nupdates. We apply it on the small-vocabulary Google Speech Commands digits\ndataset, where it achieves state-of-the-art results in unconditional speech\nsynthesis. It is also substantially faster than existing top-performing\ndiffusion models. We confirm that ASGAN's latent space is disentangled: we\ndemonstrate how simple linear operations in the space can be used to perform\nseveral tasks unseen during training. Specifically, we perform evaluations in\nvoice conversion, speech enhancement, speaker verification, and keyword\nclassification. Our work indicates that GANs are still highly competitive in\nthe unconditional speech synthesis landscape, and that disentangled latent\nspaces can be used to aid generalization to unseen tasks. Code, models,\nsamples: https://github.com/RF5/simple-asgan/", "published": "2023-07-04 12:06:07", "link": "http://arxiv.org/abs/2307.01673v2", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Align With Purpose: Optimize Desired Properties in CTC Models with a\n  General Plug-and-Play Framework", "abstract": "Connectionist Temporal Classification (CTC) is a widely used criterion for\ntraining supervised sequence-to-sequence (seq2seq) models. It enables learning\nthe relations between input and output sequences, termed alignments, by\nmarginalizing over perfect alignments (that yield the ground truth), at the\nexpense of imperfect alignments. This binary differentiation of perfect and\nimperfect alignments falls short of capturing other essential alignment\nproperties that hold significance in other real-world applications. Here we\npropose $\\textit{Align With Purpose}$, a $\\textbf{general Plug-and-Play\nframework}$ for enhancing a desired property in models trained with the CTC\ncriterion. We do that by complementing the CTC with an additional loss term\nthat prioritizes alignments according to a desired property. Our method does\nnot require any intervention in the CTC loss function, enables easy\noptimization of a variety of properties, and allows differentiation between\nboth perfect and imperfect alignments. We apply our framework in the domain of\nAutomatic Speech Recognition (ASR) and show its generality in terms of property\nselection, architectural choice, and scale of training dataset (up to 280,000\nhours). To demonstrate the effectiveness of our framework, we apply it to two\nunrelated properties: emission time and word error rate (WER). For the former,\nwe report an improvement of up to 570ms in latency optimization with a minor\nreduction in WER, and for the latter, we report a relative improvement of 4.5%\nWER over the baseline models. To the best of our knowledge, these applications\nhave never been demonstrated to work on a scale of data as large as ours.\nNotably, our method can be implemented using only a few lines of code, and can\nbe extended to other alignment-free loss functions and to domains other than\nASR.", "published": "2023-07-04 13:34:47", "link": "http://arxiv.org/abs/2307.01715v3", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Concept2Box: Joint Geometric Embeddings for Learning Two-View Knowledge\n  Graphs", "abstract": "Knowledge graph embeddings (KGE) have been extensively studied to embed\nlarge-scale relational data for many real-world applications. Existing methods\nhave long ignored the fact many KGs contain two fundamentally different views:\nhigh-level ontology-view concepts and fine-grained instance-view entities. They\nusually embed all nodes as vectors in one latent space. However, a single\ngeometric representation fails to capture the structural differences between\ntwo views and lacks probabilistic semantics towards concepts' granularity. We\npropose Concept2Box, a novel approach that jointly embeds the two views of a KG\nusing dual geometric representations. We model concepts with box embeddings,\nwhich learn the hierarchy structure and complex relations such as overlap and\ndisjoint among them. Box volumes can be interpreted as concepts' granularity.\nDifferent from concepts, we model entities as vectors. To bridge the gap\nbetween concept box embeddings and entity vector embeddings, we propose a novel\nvector-to-box distance metric and learn both embeddings jointly. Experiments on\nboth the public DBpedia KG and a newly-created industrial KG showed the\neffectiveness of Concept2Box.", "published": "2023-07-04 21:37:39", "link": "http://arxiv.org/abs/2307.01933v1", "categories": ["cs.AI", "cs.CG", "cs.CL", "cs.SC"], "primary_category": "cs.AI"}
{"title": "Math Agents: Computational Infrastructure, Mathematical Embedding, and\n  Genomics", "abstract": "The advancement in generative AI could be boosted with more accessible\nmathematics. Beyond human-AI chat, large language models (LLMs) are emerging in\nprogramming, algorithm discovery, and theorem proving, yet their genomics\napplication is limited. This project introduces Math Agents and mathematical\nembedding as fresh entries to the \"Moore's Law of Mathematics\", using a\nGPT-based workflow to convert equations from literature into LaTeX and Python\nformats. While many digital equation representations exist, there's a lack of\nautomated large-scale evaluation tools. LLMs are pivotal as linguistic user\ninterfaces, providing natural language access for human-AI chat and formal\nlanguages for large-scale AI-assisted computational infrastructure. Given the\ninfinite formal possibility spaces, Math Agents, which interact with math,\ncould potentially shift us from \"big data\" to \"big math\". Math, unlike the more\nflexible natural language, has properties subject to proof, enabling its use\nbeyond traditional applications like high-validation math-certified icons for\nAI alignment aims. This project aims to use Math Agents and mathematical\nembeddings to address the ageing issue in information systems biology by\napplying multiscalar physics mathematics to disease models and genomic data.\nGenerative AI with episodic memory could help analyse causal relations in\nlongitudinal health records, using SIR Precision Health models. Genomic data is\nsuggested for addressing the unsolved Alzheimer's disease problem.", "published": "2023-07-04 20:16:32", "link": "http://arxiv.org/abs/2307.02502v1", "categories": ["q-bio.OT", "cs.AI", "cs.CL", "68R12", "I.2; J.3"], "primary_category": "q-bio.OT"}
{"title": "Natural Language Generation and Understanding of Big Code for\n  AI-Assisted Programming: A Review", "abstract": "This paper provides a comprehensive review of the literature concerning the\nutilization of Natural Language Processing (NLP) techniques, with a particular\nfocus on transformer-based large language models (LLMs) trained using Big Code,\nwithin the domain of AI-assisted programming tasks. LLMs, augmented with\nsoftware naturalness, have played a crucial role in facilitating AI-assisted\nprogramming applications, including code generation, code completion, code\ntranslation, code refinement, code summarization, defect detection, and clone\ndetection. Notable examples of such applications include the GitHub Copilot\npowered by OpenAI's Codex and DeepMind AlphaCode. This paper presents an\noverview of the major LLMs and their applications in downstream tasks related\nto AI-assisted programming. Furthermore, it explores the challenges and\nopportunities associated with incorporating NLP techniques with software\nnaturalness in these applications, with a discussion on extending AI-assisted\nprogramming capabilities to Apple's Xcode for mobile software development. This\npaper also presents the challenges of and opportunities for incorporating NLP\ntechniques with software naturalness, empowering developers with advanced\ncoding assistance and streamlining the software development process.", "published": "2023-07-04 21:26:51", "link": "http://arxiv.org/abs/2307.02503v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Decoding the Popularity of TV Series: A Network Analysis Perspective", "abstract": "In this paper, we analyze the character networks extracted from three popular\ntelevision series and explore the relationship between a TV show episode's\ncharacter network metrics and its review from IMDB. Character networks are\ngraphs created from the plot of a TV show that represents the interactions of\ncharacters in scenes, indicating the presence of a connection between them. We\ncalculate various network metrics for each episode, such as node degree and\ngraph density, and use these metrics to explore the potential relationship\nbetween network metrics and TV series reviews from IMDB. Our results show that\ncertain network metrics of character interactions in episodes have a strong\ncorrelation with the review score of TV series. Our research aims to provide\nmore quantitative information that can help TV producers understand how to\nadjust the character dynamics of future episodes to appeal to their audience.\nBy understanding the impact of character interactions on audience engagement\nand enjoyment, producers can make informed decisions about the development of\ntheir shows.", "published": "2023-07-04 18:16:58", "link": "http://arxiv.org/abs/2307.05329v2", "categories": ["cs.SI", "cs.CL", "cs.NI"], "primary_category": "cs.SI"}
{"title": "Garbage in, garbage out: Zero-shot detection of crime using Large\n  Language Models", "abstract": "This paper proposes exploiting the common sense knowledge learned by large\nlanguage models to perform zero-shot reasoning about crimes given textual\ndescriptions of surveillance videos. We show that when video is (manually)\nconverted to high quality textual descriptions, large language models are\ncapable of detecting and classifying crimes with state-of-the-art performance\nusing only zero-shot reasoning. However, existing automated video-to-text\napproaches are unable to generate video descriptions of sufficient quality to\nsupport reasoning (garbage video descriptions into the large language model,\ngarbage out).", "published": "2023-07-04 01:29:15", "link": "http://arxiv.org/abs/2307.06844v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Pretraining Conformer with ASR or ASV for Anti-Spoofing Countermeasure", "abstract": "Finding synthetic artifacts of spoofing data will help the anti-spoofing\ncountermeasures (CMs) system discriminate between spoofed and real speech. The\nConformer combines the best of convolutional neural network and the\nTransformer, allowing it to aggregate global and local information. This may\nbenefit the CM system to capture the synthetic artifacts hidden both locally\nand globally. In this paper, we present the transfer learning based\nMFA-Conformer structure for CM systems. By pre-training the Conformer encoder\nwith different tasks, the robustness of the CM system is enhanced. The proposed\nmethod is evaluated on both Chinese and English spoofing detection databases.\nIn the FAD clean set, proposed method achieves an EER of 0.04%, which\ndramatically outperforms the baseline. Our system is also comparable to the\npre-training methods base on Wav2Vec 2.0. Moreover, we also provide a detailed\nanalysis of the robustness of different models.", "published": "2023-07-04 07:59:32", "link": "http://arxiv.org/abs/2307.01546v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Comprehensive Multi-scale Approach for Speech and Dynamics Synchrony\n  in Talking Head Generation", "abstract": "Animating still face images with deep generative models using a speech input\nsignal is an active research topic and has seen important recent\nprogress.However, much of the effort has been put into lip syncing and\nrendering quality while the generation of natural head motion, let alone the\naudio-visual correlation between head motion and speech, has often been\nneglected.In this work, we propose a multi-scale audio-visual synchrony loss\nand a multi-scale autoregressive GAN to better handle short and long-term\ncorrelation between speech and the dynamics of the head and lips.In particular,\nwe train a stack of syncer models on multimodal input pyramids and use these\nmodels as guidance in a multi-scale generator network to produce audio-aligned\nmotion unfolding over diverse time scales.Both the pyramid of audio-visual\nsyncers and the generative models are trained in a low-dimensional space that\nfully preserves dynamics cues.The experiments show significant improvements\nover the state-of-the-art in head motion dynamics quality and especially in\nmulti-scale audio-visual synchrony on a collection of benchmark datasets.", "published": "2023-07-04 08:29:59", "link": "http://arxiv.org/abs/2307.03270v2", "categories": ["cs.GR", "cs.CV", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.GR"}
