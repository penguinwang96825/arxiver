{"title": "Arbitrary Scale Super-Resolution for Brain MRI Images", "abstract": "Recent attempts at Super-Resolution for medical images used deep learning techniques such as Generative Adversarial Networks (GANs) to achieve perceptually realistic single image Super-Resolution. Yet, they are constrained by their inability to generalise to different scale factors. This involves high storage and energy costs as every integer scale factor involves a separate neural network. A recent paper has proposed a novel meta-learning technique that uses a Weight Prediction Network to enable Super-Resolution on arbitrary scale factors using only a single neural network. In this paper, we propose a new network that combines that technique with SRGAN, a state-of-the-art GAN-based architecture, to achieve arbitrary scale, high fidelity Super-Resolution for medical images. By using this network to perform arbitrary scale magnifications on images from the Multimodal Brain Tumor Segmentation Challenge (BraTS) dataset, we demonstrate that it is able to outperform traditional interpolation methods by up to 20$\\%$ on SSIM scores whilst retaining generalisability on brain MRI images. We show that performance across scales is not compromised, and that it is able to achieve competitive results with other state-of-the-art methods such as EDSR whilst being fifty times smaller than them. Combining efficiency, performance, and generalisability, this can hopefully become a new foundation for tackling Super-Resolution on medical images.\n  Check out the webapp here: https://metasrgan.herokuapp.com/ Check out the github tutorial here: https://github.com/pancakewaffles/metasrgan-tutorial", "published": "2020-04-05 03:53:28", "link": "http://arxiv.org/abs/2004.02086v2", "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "Feature Quantization Improves GAN Training", "abstract": "The instability in GAN training has been a long-standing problem despite remarkable research efforts. We identify that instability issues stem from difficulties of performing feature matching with mini-batch statistics, due to a fragile balance between the fixed target distribution and the progressively generated distribution. In this work, we propose Feature Quantization (FQ) for the discriminator, to embed both true and fake data samples into a shared discrete space. The quantized values of FQ are constructed as an evolving dictionary, which is consistent with feature statistics of the recent distribution history. Hence, FQ implicitly enables robust feature matching in a compact space. Our method can be easily plugged into existing GAN models, with little computational overhead in training. We apply FQ to 3 representative GAN models on 9 benchmarks: BigGAN for image generation, StyleGAN for face synthesis, and U-GAT-IT for unsupervised image-to-image translation. Extensive experimental results show that the proposed FQ-GAN can improve the FID scores of baseline methods by a large margin on a variety of tasks, achieving new state-of-the-art performance.", "published": "2020-04-05 04:06:50", "link": "http://arxiv.org/abs/2004.02088v2", "categories": ["cs.LG", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Using Cyclic Noise as the Source Signal for Neural Source-Filter-based Speech Waveform Model", "abstract": "Neural source-filter (NSF) waveform models generate speech waveforms by morphing sine-based source signals through dilated convolution in the time domain. Although the sine-based source signals help the NSF models to produce voiced sounds with specified pitch, the sine shape may constrain the generated waveform when the target voiced sounds are less periodic. In this paper, we propose a more flexible source signal called cyclic noise, a quasi-periodic noise sequence given by the convolution of a pulse train and a static random noise with a trainable decaying rate that controls the signal shape. We further propose a masked spectral loss to guide the NSF models to produce periodic voiced sounds from the cyclic noise-based source signal. Results from a large-scale listening test demonstrated the effectiveness of the cyclic noise and the masked spectral loss on speaker-independent NSF models in copy-synthesis experiments on the CMU ARCTIC database.", "published": "2020-04-05 13:00:56", "link": "http://arxiv.org/abs/2004.02191v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Stochastic Geometry Analysis and Design of Wireless Powered MTC Networks", "abstract": "Machine-type-communications (MTC) are being crucial in the development of next generation mobile networks. Given that MTC devices are usually battery constrained, wireless power transfer (WPT) and energy harvesting (EH) have emerged as feasible options to enlarge the lifetime of the devices, leading to wireless powered networks. In that sense, we consider a setup where groups of sensors are served by a base station (BS), which is responsible for the WPT. Additionally, EH is used to collect energy from the wireless signals transmitted by other sensors. To characterize the energy obtained from both procedures, we model the sporadic activity of sensors as Bernoulli random variables and their positions with repulsive Mat\u00e9rn cluster processes. This way, the random activity and spatial distribution of sensors are introduced in the analysis of the energy statistics. This analysis can be useful for system design aspects such as energy allocation schemes or optimization of idle-active periods, among others. As an example of use of the developed analysis, we include the design of a WPT scheme under a proportional fair policy.", "published": "2020-04-05 17:38:46", "link": "http://arxiv.org/abs/2004.02262v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
