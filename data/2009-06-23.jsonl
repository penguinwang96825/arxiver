{"title": "A Divergence Formula for Randomness and Dimension (Short Version)", "abstract": "If $S$ is an infinite sequence over a finite alphabet $\u03a3$ and $\u03b2$ is a probability measure on $\u03a3$, then the {\\it dimension} of $ S$ with respect to $\u03b2$, written $\\dim^\u03b2(S)$, is a constructive version of Billingsley dimension that coincides with the (constructive Hausdorff) dimension $\\dim(S)$ when $\u03b2$ is the uniform probability measure. This paper shows that $\\dim^\u03b2(S)$ and its dual $\\Dim^\u03b2(S)$, the {\\it strong dimension} of $S$ with respect to $\u03b2$, can be used in conjunction with randomness to measure the similarity of two probability measures $\u03b1$ and $\u03b2$ on $\u03a3$. Specifically, we prove that the {\\it divergence formula} $$\\dim^\u03b2(R) = \\Dim^\u03b2(R) =\\CH(\u03b1) / (\\CH(\u03b1) + \\D(\u03b1|| \u03b2))$$ holds whenever $\u03b1$ and $\u03b2$ are computable, positive probability measures on $\u03a3$ and $R \\in \u03a3^\\infty$ is random with respect to $\u03b1$. In this formula, $\\CH(\u03b1)$ is the Shannon entropy of $\u03b1$, and $\\D(\u03b1||\u03b2)$ is the Kullback-Leibler divergence between $\u03b1$ and $\u03b2$.", "published": "2009-06-23 10:15:31", "link": "http://arxiv.org/abs/0906.4162v1", "categories": ["cs.CC", "cs.IT"], "primary_category": "cs.CC"}
