{"title": "A Low Dimensionality Representation for Language Variety Identification", "abstract": "Language variety identification aims at labelling texts in a native language\n(e.g. Spanish, Portuguese, English) with its specific variation (e.g.\nArgentina, Chile, Mexico, Peru, Spain; Brazil, Portugal; UK, US). In this work\nwe propose a low dimensionality representation (LDR) to address this task with\nfive different varieties of Spanish: Argentina, Chile, Mexico, Peru and Spain.\nWe compare our LDR method with common state-of-the-art representations and show\nan increase in accuracy of ~35%. Furthermore, we compare LDR with two reference\ndistributed representation models. Experimental results show competitive\nperformance while dramatically reducing the dimensionality --and increasing the\nbig data suitability-- to only 6 features per variety. Additionally, we analyse\nthe behaviour of the employed machine learning algorithms and the most\ndiscriminating features. Finally, we employ an alternative dataset to test the\nrobustness of our low dimensionality representation with another set of similar\nlanguages.", "published": "2017-05-30 17:07:45", "link": "http://arxiv.org/abs/1705.10754v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Character Composition Model with Convolutional Neural Networks for\n  Dependency Parsing on Morphologically Rich Languages", "abstract": "We present a transition-based dependency parser that uses a convolutional\nneural network to compose word representations from characters. The character\ncomposition model shows great improvement over the word-lookup model,\nespecially for parsing agglutinative languages. These improvements are even\nbetter than using pre-trained word embeddings from extra data. On the SPMRL\ndata sets, our system outperforms the previous best greedy parser (Ballesteros\net al., 2015) by a margin of 3% on average.", "published": "2017-05-30 18:23:18", "link": "http://arxiv.org/abs/1705.10814v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Deep Learning for Environmentally Robust Speech Recognition: An Overview\n  of Recent Developments", "abstract": "Eliminating the negative effect of non-stationary environmental noise is a\nlong-standing research topic for automatic speech recognition that stills\nremains an important challenge. Data-driven supervised approaches, including\nones based on deep neural networks, have recently emerged as potential\nalternatives to traditional unsupervised approaches and with sufficient\ntraining, can alleviate the shortcomings of the unsupervised methods in various\nreal-life acoustic environments. In this light, we review recently developed,\nrepresentative deep learning approaches for tackling non-stationary additive\nand convolutional degradation of speech with the aim of providing guidelines\nfor those involved in the development of environmentally robust speech\nrecognition systems. We separately discuss single- and multi-channel techniques\ndeveloped for the front-end and back-end of speech recognition systems, as well\nas joint front-end and back-end training frameworks.", "published": "2017-05-30 21:31:25", "link": "http://arxiv.org/abs/1705.10874v3", "categories": ["cs.SD", "cs.CL", "cs.LG"], "primary_category": "cs.SD"}
