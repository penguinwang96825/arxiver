{"title": "Risk-Adjusted Performance of Random Forest Models in High-Frequency Trading", "abstract": "Because of the theoretical challenges posed by the Efficient Market\nHypothesis to technical analysis, the effectiveness of technical indicators in\nhigh-frequency trading remains inadequately explored, particularly at the\nminute-level frequency, where effects of the microstructure of the market\ndominate. This study evaluates the integration of traditional technical\nindicators with random forest regression models using minute-level SPY data,\nanalyzing 13 distinct model configurations. Our empirical results reveal a\nstark contrast between in-sample and out-of-sample performance, with $R^2$\nvalues deteriorating from 0.749--0.812 during training to negative values in\ntesting. A feature importance analysis demonstrates that primary price-based\nfeatures dominate the predictions made by the model, accounting for over 60% of\nthe importance, while established technical indicators, such as RSI and\nBollinger Bands, account for only 14%--15%. Although the indicator-enhanced\nmodels achieved superior risk-adjusted metrics, with Rachev ratios between\n0.919 and 0.961, they consistently underperformed a simple buy-and-hold\nstrategy, generating returns ranging from -2.4% to -3.9%. These findings\nchallenge conventional assumptions about the usefulness of technical indicators\nin algorithmic trading, suggesting that in high-frequency contexts, they may be\nmore relevant to risk management rather than to predicting returns. For\npractitioners and researchers, our findings indicate that successful\nhigh-frequency trading strategies should focus on adaptive feature selection\nand regime-specific modeling rather than relying on traditional technical\nindicators, as well as indicating the critical importance of robust\nout-of-sample testing in the development of a model.", "published": "2024-12-19 23:02:02", "link": "http://arxiv.org/abs/2412.15448v2", "categories": ["q-fin.CP", "q-fin.RM"], "primary_category": "q-fin.CP"}
{"title": "Option Pricing with a Compound CARMA(p,q)-Hawkes", "abstract": "A self-exciting point process with a continuous-time autoregressive moving\naverage intensity process, named CARMA(p,q)-Hawkes model, has recently been\nintroduced. The model generalizes the Hawkes process by substituting the\nOrnstein-Uhlenbeck intensity with a CARMA(p,q) model where the associated state\nprocess is driven by the counting process itself. The proposed model preserves\nthe same degree of tractability as the Hawkes process, but it can reproduce\nmore complex time-dependent structures observed in several market data. The\npaper presents a new model of asset price dynamics based on the CARMA(p,q)\nHawkes model. It is constructed using a compound version of it with a random\njump size that is independent of both the counting and the intensity processes\nand can be employed as the main block for pure jump and (stochastic volatility)\njump-diffusion processes. The numerical results for pricing European options\nillustrate that the new model can replicate the volatility smile observed in\nfinancial markets. Through an empirical analysis, which is presented as a\ncalibration exercise, we highlight the role of higher order autoregressive and\nmoving average parameters in pricing options.", "published": "2024-12-19 18:47:52", "link": "http://arxiv.org/abs/2412.15172v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "A Comparative Study of DSPy Teleprompter Algorithms for Aligning Large Language Models Evaluation Metrics to Human Evaluation", "abstract": "We argue that the Declarative Self-improving Python (DSPy) optimizers are a\nway to align the large language model (LLM) prompts and their evaluations to\nthe human annotations. We present a comparative analysis of five teleprompter\nalgorithms, namely, Cooperative Prompt Optimization (COPRO), Multi-Stage\nInstruction Prompt Optimization (MIPRO), BootstrapFewShot, BootstrapFewShot\nwith Optuna, and K-Nearest Neighbor Few Shot, within the DSPy framework with\nrespect to their ability to align with human evaluations. As a concrete\nexample, we focus on optimizing the prompt to align hallucination detection\n(using LLM as a judge) to human annotated ground truth labels for a publicly\navailable benchmark dataset. Our experiments demonstrate that optimized prompts\ncan outperform various benchmark methods to detect hallucination, and certain\ntelemprompters outperform the others in at least these experiments.", "published": "2024-12-19 10:38:46", "link": "http://arxiv.org/abs/2412.15298v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "q-fin.ST", "stat.ME"], "primary_category": "cs.CL"}
{"title": "Leveraging Time Series Categorization and Temporal Fusion Transformers to Improve Cryptocurrency Price Forecasting", "abstract": "Organizing and managing cryptocurrency portfolios and decision-making on\ntransactions is crucial in this market. Optimal selection of assets is one of\nthe main challenges that requires accurate prediction of the price of\ncryptocurrencies. In this work, we categorize the financial time series into\nseveral similar subseries to increase prediction accuracy by learning each\nsubseries category with similar behavior. For each category of the subseries,\nwe create a deep learning model based on the attention mechanism to predict the\nnext step of each subseries. Due to the limited amount of cryptocurrency data\nfor training models, if the number of categories increases, the amount of\ntraining data for each model will decrease, and some complex models will not be\ntrained well due to the large number of parameters. To overcome this challenge,\nwe propose to combine the time series data of other cryptocurrencies to\nincrease the amount of data for each category, hence increasing the accuracy of\nthe models corresponding to each category.", "published": "2024-12-19 04:57:55", "link": "http://arxiv.org/abs/2412.14529v1", "categories": ["cs.LG", "cs.CE", "q-fin.ST"], "primary_category": "cs.LG"}
