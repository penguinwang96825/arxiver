{"title": "Efficiency Pentathlon: A Standardized Arena for Efficiency Evaluation", "abstract": "Rising computational demands of modern natural language processing (NLP)\nsystems have increased the barrier to entry for cutting-edge research while\nposing serious environmental concerns. Yet, progress on model efficiency has\nbeen impeded by practical challenges in model evaluation and comparison. For\nexample, hardware is challenging to control due to disparate levels of\naccessibility across different institutions. Moreover, improvements in metrics\nsuch as FLOPs often fail to translate to progress in real-world applications.\nIn response, we introduce Pentathlon, a benchmark for holistic and realistic\nevaluation of model efficiency. Pentathlon focuses on inference, which accounts\nfor a majority of the compute in a model's lifecycle. It offers a\nstrictly-controlled hardware platform, and is designed to mirror real-world\napplications scenarios. It incorporates a suite of metrics that target\ndifferent aspects of efficiency, including latency, throughput, memory\noverhead, and energy consumption. Pentathlon also comes with a software library\nthat can be seamlessly integrated into any codebase and enable evaluation. As a\nstandardized and centralized evaluation platform, Pentathlon can drastically\nreduce the workload to make fair and reproducible efficiency comparisons. While\ninitially focused on natural language processing (NLP) models, Pentathlon is\ndesigned to allow flexible extension to other fields. We envision Pentathlon\nwill stimulate algorithmic innovations in building efficient models, and foster\nan increased awareness of the social and environmental implications in the\ndevelopment of future-generation NLP models.", "published": "2023-07-19 01:05:33", "link": "http://arxiv.org/abs/2307.09701v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CValues: Measuring the Values of Chinese Large Language Models from\n  Safety to Responsibility", "abstract": "With the rapid evolution of large language models (LLMs), there is a growing\nconcern that they may pose risks or have negative social impacts. Therefore,\nevaluation of human values alignment is becoming increasingly important.\nPrevious work mainly focuses on assessing the performance of LLMs on certain\nknowledge and reasoning abilities, while neglecting the alignment to human\nvalues, especially in a Chinese context. In this paper, we present CValues, the\nfirst Chinese human values evaluation benchmark to measure the alignment\nability of LLMs in terms of both safety and responsibility criteria. As a\nresult, we have manually collected adversarial safety prompts across 10\nscenarios and induced responsibility prompts from 8 domains by professional\nexperts. To provide a comprehensive values evaluation of Chinese LLMs, we not\nonly conduct human evaluation for reliable comparison, but also construct\nmulti-choice prompts for automatic evaluation. Our findings suggest that while\nmost Chinese LLMs perform well in terms of safety, there is considerable room\nfor improvement in terms of responsibility. Moreover, both the automatic and\nhuman evaluation are important for assessing the human values alignment in\ndifferent aspects. The benchmark and code is available on ModelScope and\nGithub.", "published": "2023-07-19 01:22:40", "link": "http://arxiv.org/abs/2307.09705v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DAPrompt: Deterministic Assumption Prompt Learning for Event Causality\n  Identification", "abstract": "Event Causality Identification (ECI) aims at determining whether there is a\ncausal relation between two event mentions. Conventional prompt learning\ndesigns a prompt template to first predict an answer word and then maps it to\nthe final decision. Unlike conventional prompts, we argue that predicting an\nanswer word may not be a necessary prerequisite for the ECI task. Instead, we\ncan first make a deterministic assumption on the existence of causal relation\nbetween two events and then evaluate its rationality to either accept or reject\nthe assumption. The design motivation is to try the most utilization of the\nencyclopedia-like knowledge embedded in a pre-trained language model. In light\nof such considerations, we propose a deterministic assumption prompt learning\nmodel, called DAPrompt, for the ECI task. In particular, we design a simple\ndeterministic assumption template concatenating with the input event pair,\nwhich includes two masks as predicted events' tokens. We use the probabilities\nof predicted events to evaluate the assumption rationality for the final event\ncausality decision. Experiments on the EventStoryLine corpus and\nCausal-TimeBank corpus validate our design objective in terms of significant\nperformance improvements over the state-of-the-art algorithms.", "published": "2023-07-19 08:02:20", "link": "http://arxiv.org/abs/2307.09813v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Models can accomplish Business Process Management Tasks", "abstract": "Business Process Management (BPM) aims to improve organizational activities\nand their outcomes by managing the underlying processes. To achieve this, it is\noften necessary to consider information from various sources, including\nunstructured textual documents. Therefore, researchers have developed several\nBPM-specific solutions that extract information from textual documents using\nNatural Language Processing techniques. These solutions are specific to their\nrespective tasks and cannot accomplish multiple process-related problems as a\ngeneral-purpose instrument. However, in light of the recent emergence of Large\nLanguage Models (LLMs) with remarkable reasoning capabilities, such a\ngeneral-purpose instrument with multiple applications now appears attainable.\nIn this paper, we illustrate how LLMs can accomplish text-related BPM tasks by\napplying a specific LLM to three exemplary tasks: mining imperative process\nmodels from textual descriptions, mining declarative process models from\ntextual descriptions, and assessing the suitability of process tasks from\ntextual descriptions for robotic process automation. We show that, without\nextensive configuration or prompt engineering, LLMs perform comparably to or\nbetter than existing solutions and discuss implications for future BPM research\nas well as practical usage.", "published": "2023-07-19 11:54:46", "link": "http://arxiv.org/abs/2307.09923v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GUIDO: A Hybrid Approach to Guideline Discovery & Ordering from Natural\n  Language Texts", "abstract": "Extracting workflow nets from textual descriptions can be used to simplify\nguidelines or formalize textual descriptions of formal processes like business\nprocesses and algorithms. The task of manually extracting processes, however,\nrequires domain expertise and effort. While automatic process model extraction\nis desirable, annotating texts with formalized process models is expensive.\nTherefore, there are only a few machine-learning-based extraction approaches.\nRule-based approaches, in turn, require domain specificity to work well and can\nrarely distinguish relevant and irrelevant information in textual descriptions.\nIn this paper, we present GUIDO, a hybrid approach to the process model\nextraction task that first, classifies sentences regarding their relevance to\nthe process model, using a BERT-based sentence classifier, and second, extracts\na process model from the sentences classified as relevant, using dependency\nparsing. The presented approach achieves significantly better results than a\npure rule-based approach. GUIDO achieves an average behavioral similarity score\nof $0.93$. Still, in comparison to purely machine-learning-based approaches,\nthe annotation costs stay low.", "published": "2023-07-19 13:01:03", "link": "http://arxiv.org/abs/2307.09959v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Transformer Extrapolation", "abstract": "Length extrapolation has attracted considerable attention recently since it\nallows transformers to be tested on longer sequences than those used in\ntraining. Previous research has shown that this property can be attained by\nusing carefully designed Relative Positional Encodings (RPEs). While these\nmethods perform well on a variety of corpora, the conditions for length\nextrapolation have yet to be investigated. This paper attempts to determine\nwhat types of RPEs allow for length extrapolation through a thorough\nmathematical and empirical analysis. We discover that a transformer is certain\nto possess this property as long as the series that corresponds to the RPE's\nexponential converges. Two practices are derived from the conditions and\nexamined in language modeling tasks on a variety of corpora. As a bonus from\nthe conditions, we derive a new Theoretical Receptive Field (TRF) to measure\nthe receptive field of RPEs without taking any training steps. Extensive\nexperiments are conducted on the Wikitext-103, Books, Github, and WikiBook\ndatasets to demonstrate the viability of our discovered conditions. We also\ncompare TRF to Empirical Receptive Field (ERF) across different models, showing\nconsistently matched trends on the aforementioned datasets. The code is\navailable at https://github.com/OpenNLPLab/Rpe.", "published": "2023-07-19 17:37:03", "link": "http://arxiv.org/abs/2307.10156v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PharmacyGPT: The AI Pharmacist", "abstract": "In this study, we introduce PharmacyGPT, a novel framework to assess the\ncapabilities of large language models (LLMs) such as ChatGPT and GPT-4 in\nemulating the role of clinical pharmacists. Our methodology encompasses the\nutilization of LLMs to generate comprehensible patient clusters, formulate\nmedication plans, and forecast patient outcomes. We conduct our investigation\nusing real data acquired from the intensive care unit (ICU) at the University\nof North Carolina Chapel Hill (UNC) Hospital. Our analysis offers valuable\ninsights into the potential applications and limitations of LLMs in the field\nof clinical pharmacy, with implications for both patient care and the\ndevelopment of future AI-driven healthcare solutions. By evaluating the\nperformance of PharmacyGPT, we aim to contribute to the ongoing discourse\nsurrounding the integration of artificial intelligence in healthcare settings,\nultimately promoting the responsible and efficacious use of such technologies.", "published": "2023-07-19 19:40:34", "link": "http://arxiv.org/abs/2307.10432v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Thrust: Adaptively Propels Large Language Models with External Knowledge", "abstract": "Although large-scale pre-trained language models (PTLMs) are shown to encode\nrich knowledge in their model parameters, the inherent knowledge in PTLMs can\nbe opaque or static, making external knowledge necessary. However, the existing\ninformation retrieval techniques could be costly and may even introduce noisy\nand sometimes misleading knowledge. To address these challenges, we propose the\ninstance-level adaptive propulsion of external knowledge (IAPEK), where we only\nconduct the retrieval when necessary. To achieve this goal, we propose\nmeasuring whether a PTLM contains enough knowledge to solve an instance with a\nnovel metric, Thrust, which leverages the representation distribution of a\nsmall number of seen instances. Extensive experiments demonstrate that thrust\nis a good measurement of PTLM models' instance-level knowledgeability.\nMoreover, we can achieve significantly higher cost-efficiency with the Thrust\nscore as the retrieval indicator than the naive usage of external knowledge on\n88% of the evaluated tasks with 26% average performance improvement. Such\nfindings shed light on the real-world practice of knowledge-enhanced LMs with a\nlimited knowledge-seeking budget due to computation latency or costs.", "published": "2023-07-19 20:16:46", "link": "http://arxiv.org/abs/2307.10442v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving the Reusability of Pre-trained Language Models in Real-world\n  Applications", "abstract": "The reusability of state-of-the-art Pre-trained Language Models (PLMs) is\noften limited by their generalization problem, where their performance\ndrastically decreases when evaluated on examples that differ from the training\ndataset, known as Out-of-Distribution (OOD)/unseen examples. This limitation\narises from PLMs' reliance on spurious correlations, which work well for\nfrequent example types but not for general examples. To address this issue, we\npropose a training approach called Mask-tuning, which integrates Masked\nLanguage Modeling (MLM) training objectives into the fine-tuning process to\nenhance PLMs' generalization. Comprehensive experiments demonstrate that\nMask-tuning surpasses current state-of-the-art techniques and enhances PLMs'\ngeneralization on OOD datasets while improving their performance on\nin-distribution datasets. The findings suggest that Mask-tuning improves the\nreusability of PLMs on unseen data, making them more practical and effective\nfor real-world applications.", "published": "2023-07-19 21:00:16", "link": "http://arxiv.org/abs/2307.10457v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Guided Generation for Large Language Models", "abstract": "In this article we show how the problem of neural text generation can be\nconstructively reformulated in terms of transitions between the states of a\nfinite-state machine. This framework leads to an efficient approach to guiding\ntext generation with regular expressions and context-free grammars by allowing\nthe construction of an index over a language model's vocabulary. The approach\nis model agnostic, allows one to enforce domain-specific knowledge and\nconstraints, and enables the construction of reliable interfaces by\nguaranteeing the structure of the generated text. It adds little overhead to\nthe token sequence generation process and significantly outperforms existing\nsolutions. An implementation is provided in the open source Python library\nOutlines", "published": "2023-07-19 01:14:49", "link": "http://arxiv.org/abs/2307.09702v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Enhancing conversational quality in language learning chatbots: An\n  evaluation of GPT4 for ASR error correction", "abstract": "The integration of natural language processing (NLP) technologies into\neducational applications has shown promising results, particularly in the\nlanguage learning domain. Recently, many spoken open-domain chatbots have been\nused as speaking partners, helping language learners improve their language\nskills. However, one of the significant challenges is the high word-error-rate\n(WER) when recognizing non-native/non-fluent speech, which interrupts\nconversation flow and leads to disappointment for learners. This paper explores\nthe use of GPT4 for ASR error correction in conversational settings. In\naddition to WER, we propose to use semantic textual similarity (STS) and next\nresponse sensibility (NRS) metrics to evaluate the impact of error correction\nmodels on the quality of the conversation. We find that transcriptions\ncorrected by GPT4 lead to higher conversation quality, despite an increase in\nWER. GPT4 also outperforms standard error correction methods without the need\nfor in-domain training data.", "published": "2023-07-19 04:25:21", "link": "http://arxiv.org/abs/2307.09744v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "On the Origin of LLMs: An Evolutionary Tree and Graph for 15,821 Large\n  Language Models", "abstract": "Since late 2022, Large Language Models (LLMs) have become very prominent with\nLLMs like ChatGPT and Bard receiving millions of users. Hundreds of new LLMs\nare announced each week, many of which are deposited to Hugging Face, a\nrepository of machine learning models and datasets. To date, nearly 16,000 Text\nGeneration models have been uploaded to the site. Given the huge influx of\nLLMs, it is of interest to know which LLM backbones, settings, training\nmethods, and families are popular or trending. However, there is no\ncomprehensive index of LLMs available. We take advantage of the relatively\nsystematic nomenclature of Hugging Face LLMs to perform hierarchical clustering\nand identify communities amongst LLMs using n-grams and term frequency-inverse\ndocument frequency. Our methods successfully identify families of LLMs and\naccurately cluster LLMs into meaningful subgroups. We present a public web\napplication to navigate and explore Constellation, our atlas of 15,821 LLMs.\nConstellation rapidly generates a variety of visualizations, namely\ndendrograms, graphs, word clouds, and scatter plots. Constellation is available\nat the following link: https://constellation.sites.stanford.edu/.", "published": "2023-07-19 07:17:43", "link": "http://arxiv.org/abs/2307.09793v1", "categories": ["cs.DL", "cs.CL", "I.2.1; H.5.0"], "primary_category": "cs.DL"}
{"title": "Controlling Equational Reasoning in Large Language Models with Prompt\n  Interventions", "abstract": "This paper investigates how hallucination rates in Large Language Models\n(LLMs) may be controlled via a symbolic data generation framework, exploring a\nfundamental relationship between the rate of certain mathematical errors and\ntypes of input intervention. Specifically, we systematically generate data for\na derivation generation task using a symbolic engine, applying targeted\ninterventions to prompts to perturb features of mathematical derivations such\nas the surface forms of symbols, equational tree structures, and mathematical\ncontext. We then evaluate the effect of prompt interventions across a range of\nLLMs including fine-tuned T5 models, GPT, and LLaMa-based models. Our\nexperiments suggest that T5-Large can outperform the few-shot performance of\nGPT-4 on various evaluation sets generated via the framework. However, an\nextensive evaluation based on human analysis, template-based error detection,\nand text generation metrics reveals model weaknesses beyond what the\nreference-based metrics singularly describe. We use these results to tie\ncharacteristic distributional footprints of interventions to the human\nevaluation of LLM derivation quality, potentially leading to significant\ncontrol over fine-grained mathematical capabilities of language models with\nrespect to specific types of errors.", "published": "2023-07-19 14:13:02", "link": "http://arxiv.org/abs/2307.09998v5", "categories": ["cs.CL", "math.HO"], "primary_category": "cs.CL"}
{"title": "Gradient Sparsification For Masked Fine-Tuning of Transformers", "abstract": "Fine-tuning pretrained self-supervised language models is widely adopted for\ntransfer learning to downstream tasks. Fine-tuning can be achieved by freezing\ngradients of the pretrained network and only updating gradients of a newly\nadded classification layer, or by performing gradient updates on all\nparameters. Gradual unfreezing makes a trade-off between the two by gradually\nunfreezing gradients of whole layers during training. This has been an\neffective strategy to trade-off between storage and training speed with\ngeneralization performance. However, it is not clear whether gradually\nunfreezing layers throughout training is optimal, compared to sparse variants\nof gradual unfreezing which may improve fine-tuning performance. In this paper,\nwe propose to stochastically mask gradients to regularize pretrained language\nmodels for improving overall fine-tuned performance. We introduce GradDrop and\nvariants thereof, a class of gradient sparsification methods that mask\ngradients during the backward pass, acting as gradient noise. GradDrop is\nsparse and stochastic unlike gradual freezing. Extensive experiments on the\nmultilingual XGLUE benchmark with XLMR-Large show that GradDrop is competitive\nagainst methods that use additional translated data for intermediate\npretraining and outperforms standard fine-tuning and gradual unfreezing. A\npost-analysis shows how GradDrop improves performance with languages it was not\ntrained on, such as under-resourced languages.", "published": "2023-07-19 16:13:13", "link": "http://arxiv.org/abs/2307.10098v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LLMs as Workers in Human-Computational Algorithms? Replicating\n  Crowdsourcing Pipelines with LLMs", "abstract": "LLMs have shown promise in replicating human-like behavior in crowdsourcing\ntasks that were previously thought to be exclusive to human abilities. However,\ncurrent efforts focus mainly on simple atomic tasks. We explore whether LLMs\ncan replicate more complex crowdsourcing pipelines. We find that modern LLMs\ncan simulate some of crowdworkers' abilities in these ``human computation\nalgorithms,'' but the level of success is variable and influenced by\nrequesters' understanding of LLM capabilities, the specific skills required for\nsub-tasks, and the optimal interaction modality for performing these sub-tasks.\nWe reflect on human and LLMs' different sensitivities to instructions, stress\nthe importance of enabling human-facing safeguards for LLMs, and discuss the\npotential of training humans and LLMs with complementary skill sets. Crucially,\nwe show that replicating crowdsourcing pipelines offers a valuable platform to\ninvestigate 1) the relative LLM strengths on different tasks (by\ncross-comparing their performances on sub-tasks) and 2) LLMs' potential in\ncomplex tasks, where they can complete part of the tasks while leaving others\nto humans.", "published": "2023-07-19 17:54:43", "link": "http://arxiv.org/abs/2307.10168v3", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "DialogStudio: Towards Richest and Most Diverse Unified Dataset\n  Collection for Conversational AI", "abstract": "Despite advancements in conversational AI, language models encounter\nchallenges to handle diverse conversational tasks, and existing dialogue\ndataset collections often lack diversity and comprehensiveness. To tackle these\nissues, we introduce DialogStudio: the largest and most diverse collection of\ndialogue datasets, unified under a consistent format while preserving their\noriginal information. Our collection encompasses data from open-domain\ndialogues, task-oriented dialogues, natural language understanding,\nconversational recommendation, dialogue summarization, and knowledge-grounded\ndialogues, making it an incredibly rich and diverse resource for dialogue\nresearch and model training. To further enhance the utility of DialogStudio, we\nidentify the licenses for each dataset, design external knowledge and\ndomain-aware prompts for selected dialogues to facilitate instruction-aware\nfine-tuning. Furthermore, we develop conversational AI models using the dataset\ncollection, and our experiments in both zero-shot and few-shot learning\nscenarios demonstrate the superiority of DialogStudio. To improve transparency\nand support dataset and task-based research, as well as language model\npre-training, all datasets, licenses, codes, and models associated with\nDialogStudio are made publicly\naccessible\\footnote{\\url{https://github.com/salesforce/DialogStudio}}.", "published": "2023-07-19 17:57:53", "link": "http://arxiv.org/abs/2307.10172v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Integrating a Heterogeneous Graph with Entity-aware Self-attention using\n  Relative Position Labels for Reading Comprehension Model", "abstract": "Despite the significant progress made by transformer models in machine\nreading comprehension tasks, they still fall short in handling complex\nreasoning tasks due to the absence of explicit knowledge in the input sequence.\nTo address this limitation, many recent works have proposed injecting external\nknowledge into the model. However, selecting relevant external knowledge,\nensuring its availability, and requiring additional processing steps remain\nchallenging. In this paper, we introduce a novel attention pattern that\nintegrates reasoning knowledge derived from a heterogeneous graph into the\ntransformer architecture without relying on external knowledge. The proposed\nattention pattern comprises three key elements: global-local attention for word\ntokens, graph attention for entity tokens that exhibit strong attention towards\ntokens connected in the graph as opposed to those unconnected, and the\nconsideration of the type of relationship between each entity token and word\ntoken. This results in optimized attention between the two if a relationship\nexists. The pattern is coupled with special relative position labels, allowing\nit to integrate with LUKE's entity-aware self-attention mechanism. The\nexperimental findings corroborate that our model outperforms both the\ncutting-edge LUKE-Graph and the baseline LUKE model across two distinct\ndatasets: ReCoRD, emphasizing commonsense reasoning, and WikiHop, focusing on\nmulti-hop reasoning challenges.", "published": "2023-07-19 20:17:37", "link": "http://arxiv.org/abs/2307.10443v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Findings of Factify 2: Multimodal Fake News Detection", "abstract": "With social media usage growing exponentially in the past few years, fake\nnews has also become extremely prevalent. The detrimental impact of fake news\nemphasizes the need for research focused on automating the detection of false\ninformation and verifying its accuracy. In this work, we present the outcome of\nthe Factify 2 shared task, which provides a multi-modal fact verification and\nsatire news dataset, as part of the DeFactify 2 workshop at AAAI'23. The data\ncalls for a comparison based approach to the task by pairing social media\nclaims with supporting documents, with both text and image, divided into 5\nclasses based on multi-modal relations. In the second iteration of this task we\nhad over 60 participants and 9 final test-set submissions. The best\nperformances came from the use of DeBERTa for text and Swinv2 and CLIP for\nimage. The highest F1 score averaged for all five classes was 81.82%.", "published": "2023-07-19 22:14:49", "link": "http://arxiv.org/abs/2307.10475v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "What can we learn from Data Leakage and Unlearning for Law?", "abstract": "Large Language Models (LLMs) have a privacy concern because they memorize\ntraining data (including personally identifiable information (PII) like emails\nand phone numbers) and leak it during inference. A company can train an LLM on\nits domain-customized data which can potentially also include their users' PII.\nIn order to comply with privacy laws such as the \"right to be forgotten\", the\ndata points of users that are most vulnerable to extraction could be deleted.\nWe find that once the most vulnerable points are deleted, a new set of points\nbecome vulnerable to extraction. So far, little attention has been given to\nunderstanding memorization for fine-tuned models. In this work, we also show\nthat not only do fine-tuned models leak their training data but they also leak\nthe pre-training data (and PII) memorized during the pre-training phase. The\nproperty of new data points becoming vulnerable to extraction after unlearning\nand leakage of pre-training data through fine-tuned models can pose significant\nprivacy and legal concerns for companies that use LLMs to offer services. We\nhope this work will start an interdisciplinary discussion within AI and law\ncommunities regarding the need for policies to tackle these issues.", "published": "2023-07-19 22:14:58", "link": "http://arxiv.org/abs/2307.10476v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "RaTE: a Reproducible automatic Taxonomy Evaluation by Filling the Gap", "abstract": "Taxonomies are an essential knowledge representation, yet most studies on\nautomatic taxonomy construction (ATC) resort to manual evaluation to score\nproposed algorithms. We argue that automatic taxonomy evaluation (ATE) is just\nas important as taxonomy construction. We propose RaTE, an automatic label-free\ntaxonomy scoring procedure, which relies on a large pre-trained language model.\nWe apply our evaluation procedure to three state-of-the-art ATC algorithms with\nwhich we built seven taxonomies from the Yelp domain, and show that 1) RaTE\ncorrelates well with human judgments and 2) artificially degrading a taxonomy\nleads to decreasing RaTE score.", "published": "2023-07-19 01:37:31", "link": "http://arxiv.org/abs/2307.09706v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ZeroQuant-FP: A Leap Forward in LLMs Post-Training W4A8 Quantization\n  Using Floating-Point Formats", "abstract": "In the complex domain of large language models (LLMs), striking a balance\nbetween computational efficiency and maintaining model quality is a formidable\nchallenge. Navigating the inherent limitations of uniform quantization,\nparticularly when dealing with outliers, and motivated by the launch of\nNVIDIA's H100 hardware, this study delves into the viability of floating-point\n(FP) quantization, particularly focusing on FP8 and FP4, as a potential\nsolution. Our comprehensive investigation reveals that for LLMs, FP8 activation\nconsistently outshines its integer (INT8) equivalent, with the performance edge\nbecoming more noticeable in models possessing parameters beyond one billion.\nFor weight quantization, our findings indicate that FP4 exhibits comparable, if\nnot superior, performance to INT4, simplifying deployment on FP-supported\nhardware like H100. To mitigate the overhead from precision alignment caused by\nthe disparity between weights and activations, we propose two scaling\nconstraints for weight quantization that negligibly impact the performance\ncompared to the standard W4A8 model. We additionally enhance our quantization\nmethods by integrating the Low Rank Compensation (LoRC) strategy, yielding\nimprovements especially in smaller models. The results of our investigation\nemphasize the immense potential of FP quantization for LLMs, paving the way for\nhigh-efficiency deployment in resource-limited settings.", "published": "2023-07-19 06:58:03", "link": "http://arxiv.org/abs/2307.09782v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Test-takers have a say: understanding the implications of the use of AI\n  in language tests", "abstract": "Language tests measure a person's ability to use a language in terms of\nlistening, speaking, reading, or writing. Such tests play an integral role in\nacademic, professional, and immigration domains, with entities such as\neducational institutions, professional accreditation bodies, and governments\nusing them to assess candidate language proficiency. Recent advances in\nArtificial Intelligence (AI) and the discipline of Natural Language Processing\nhave prompted language test providers to explore AI's potential applicability\nwithin language testing, leading to transformative activity patterns\nsurrounding language instruction and learning. However, with concerns over AI's\ntrustworthiness, it is imperative to understand the implications of integrating\nAI into language testing. This knowledge will enable stakeholders to make\nwell-informed decisions, thus safeguarding community well-being and testing\nintegrity. To understand the concerns and effects of AI usage in language\ntests, we conducted interviews and surveys with English test-takers. To the\nbest of our knowledge, this is the first empirical study aimed at identifying\nthe implications of AI adoption in language tests from a test-taker\nperspective. Our study reveals test-taker perceptions and behavioral patterns.\nSpecifically, we identify that AI integration may enhance perceptions of\nfairness, consistency, and availability. Conversely, it might incite mistrust\nregarding reliability and interactivity aspects, subsequently influencing the\nbehaviors and well-being of test-takers. These insights provide a better\nunderstanding of potential societal implications and assist stakeholders in\nmaking informed decisions concerning AI usage in language testing.", "published": "2023-07-19 10:28:59", "link": "http://arxiv.org/abs/2307.09885v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.CY"}
{"title": "When Dialects Collide: How Socioeconomic Mixing Affects Language Use", "abstract": "The socioeconomic background of people and how they use standard forms of\nlanguage are not independent, as demonstrated in various sociolinguistic\nstudies. However, the extent to which these correlations may be influenced by\nthe mixing of people from different socioeconomic classes remains relatively\nunexplored from a quantitative perspective. In this work we leverage geotagged\ntweets and transferable computational methods to map deviations from standard\nEnglish on a large scale, in seven thousand administrative areas of England and\nWales. We combine these data with high-resolution income maps to assign a proxy\nsocioeconomic indicator to home-located users. Strikingly, across eight\nmetropolitan areas we find a consistent pattern suggesting that the more\ndifferent socioeconomic classes mix, the less interdependent the frequency of\ntheir departures from standard grammar and their income become. Further, we\npropose an agent-based model of linguistic variety adoption that sheds light on\nthe mechanisms that produce the observations seen in the data.", "published": "2023-07-19 14:55:50", "link": "http://arxiv.org/abs/2307.10016v1", "categories": ["physics.soc-ph", "cs.CL", "cs.SI"], "primary_category": "physics.soc-ph"}
{"title": "An Empirical Study on Fertility Proposals Using Multi-Grained Topic\n  Analysis Methods", "abstract": "Fertility issues are closely related to population security, in 60 years\nChina's population for the first time in a negative growth trend, the change of\nfertility policy is of great concern to the community. 2023 \"two sessions\"\nproposal \"suggests that the country in the form of legislation, the birth of\nthe registration of the cancellation of the marriage restriction\" This topic\nwas once a hot topic on the Internet, and \"unbundling\" the relationship between\nbirth registration and marriage has become the focus of social debate. In this\npaper, we adopt co-occurrence semantic analysis, topic analysis and sentiment\nanalysis to conduct multi-granularity semantic analysis of microblog comments.\nIt is found that the discussion on the proposal of \"removing marriage\nrestrictions from birth registration\" involves the individual, society and the\nstate at three dimensions, and is detailed into social issues such as personal\nbehaviour, social ethics and law, and national policy, with people's sentiment\ninclined to be negative in most of the topics. Based on this, eight proposals\nwere made to provide a reference for governmental decision making and to form a\nreference method for researching public opinion on political issues.", "published": "2023-07-19 15:09:50", "link": "http://arxiv.org/abs/2307.10025v2", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.SI"], "primary_category": "cs.HC"}
{"title": "Android in the Wild: A Large-Scale Dataset for Android Device Control", "abstract": "There is a growing interest in device-control systems that can interpret\nhuman natural language instructions and execute them on a digital device by\ndirectly controlling its user interface. We present a dataset for\ndevice-control research, Android in the Wild (AITW), which is orders of\nmagnitude larger than current datasets. The dataset contains human\ndemonstrations of device interactions, including the screens and actions, and\ncorresponding natural language instructions. It consists of 715k episodes\nspanning 30k unique instructions, four versions of Android (v10-13),and eight\ndevice types (Pixel 2 XL to Pixel 6) with varying screen resolutions. It\ncontains multi-step tasks that require semantic understanding of language and\nvisual context. This dataset poses a new challenge: actions available through\nthe user interface must be inferred from their visual appearance. And, instead\nof simple UI element-based actions, the action space consists of precise\ngestures (e.g., horizontal scrolls to operate carousel widgets). We organize\nour dataset to encourage robustness analysis of device-control systems, i.e.,\nhow well a system performs in the presence of new task descriptions, new\napplications, or new platform versions. We develop two agents and report\nperformance across the dataset. The dataset is available at\nhttps://github.com/google-research/google-research/tree/master/android_in_the_wild.", "published": "2023-07-19 15:57:24", "link": "http://arxiv.org/abs/2307.10088v2", "categories": ["cs.LG", "cs.CL", "cs.HC"], "primary_category": "cs.LG"}
{"title": "Challenges and Applications of Large Language Models", "abstract": "Large Language Models (LLMs) went from non-existent to ubiquitous in the\nmachine learning discourse within a few years. Due to the fast pace of the\nfield, it is difficult to identify the remaining challenges and already\nfruitful application areas. In this paper, we aim to establish a systematic set\nof open problems and application successes so that ML researchers can\ncomprehend the field's current state more quickly and become productive.", "published": "2023-07-19 17:55:13", "link": "http://arxiv.org/abs/2307.10169v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "IncDSI: Incrementally Updatable Document Retrieval", "abstract": "Differentiable Search Index is a recently proposed paradigm for document\nretrieval, that encodes information about a corpus of documents within the\nparameters of a neural network and directly maps queries to corresponding\ndocuments. These models have achieved state-of-the-art performances for\ndocument retrieval across many benchmarks. These kinds of models have a\nsignificant limitation: it is not easy to add new documents after a model is\ntrained. We propose IncDSI, a method to add documents in real time (about\n20-50ms per document), without retraining the model on the entire dataset (or\neven parts thereof). Instead we formulate the addition of documents as a\nconstrained optimization problem that makes minimal changes to the network\nparameters. Although orders of magnitude faster, our approach is competitive\nwith re-training the model on the whole dataset and enables the development of\ndocument retrieval systems that can be updated with new information in\nreal-time. Our code for IncDSI is available at\nhttps://github.com/varshakishore/IncDSI.", "published": "2023-07-19 07:20:30", "link": "http://arxiv.org/abs/2307.10323v2", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Can Instruction Fine-Tuned Language Models Identify Social Bias through\n  Prompting?", "abstract": "As the breadth and depth of language model applications continue to expand\nrapidly, it is increasingly important to build efficient frameworks for\nmeasuring and mitigating the learned or inherited social biases of these\nmodels. In this paper, we present our work on evaluating instruction fine-tuned\nlanguage models' ability to identify bias through zero-shot prompting,\nincluding Chain-of-Thought (CoT) prompts. Across LLaMA and its two instruction\nfine-tuned versions, Alpaca 7B performs best on the bias identification task\nwith an accuracy of 56.7%. We also demonstrate that scaling up LLM size and\ndata diversity could lead to further performance gain. This is a\nwork-in-progress presenting the first component of our bias mitigation\nframework. We will keep updating this work as we get more results.", "published": "2023-07-19 22:03:40", "link": "http://arxiv.org/abs/2307.10472v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FinGPT: Democratizing Internet-scale Data for Financial Large Language\n  Models", "abstract": "Large language models (LLMs) have demonstrated remarkable proficiency in\nunderstanding and generating human-like texts, which may potentially\nrevolutionize the finance industry. However, existing LLMs often fall short in\nthe financial field, which is mainly attributed to the disparities between\ngeneral text data and financial text data. Unfortunately, there is only a\nlimited number of financial text datasets available, and BloombergGPT, the\nfirst financial LLM (FinLLM), is close-sourced (only the training logs were\nreleased). In light of this, we aim to democratize Internet-scale financial\ndata for LLMs, which is an open challenge due to diverse data sources, low\nsignal-to-noise ratio, and high time-validity. To address the challenges, we\nintroduce an open-sourced and data-centric framework, Financial Generative\nPre-trained Transformer (FinGPT), that automates the collection and curation of\nreal-time financial data from 34 diverse sources on the Internet, providing\nresearchers and practitioners with accessible and transparent resources to\ndevelop their FinLLMs. Additionally, we propose a simple yet effective strategy\nfor fine-tuning FinLLM using the inherent feedback from the market, dubbed\nReinforcement Learning with Stock Prices (RLSP). We also adopt the Low-rank\nAdaptation (LoRA, QLoRA) method that enables users to customize their own\nFinLLMs from general-purpose LLMs at a low cost. Finally, we showcase several\nFinGPT applications, including robo-advisor, sentiment analysis for algorithmic\ntrading, and low-code development. FinGPT aims to democratize FinLLMs,\nstimulate innovation, and unlock new opportunities in open finance. The codes\nhave been open-sourced.", "published": "2023-07-19 22:43:57", "link": "http://arxiv.org/abs/2307.10485v2", "categories": ["cs.CL", "cs.LG", "q-fin.GN"], "primary_category": "cs.CL"}
{"title": "SPRINT: A Unified Toolkit for Evaluating and Demystifying Zero-shot\n  Neural Sparse Retrieval", "abstract": "Traditionally, sparse retrieval systems relied on lexical representations to\nretrieve documents, such as BM25, dominated information retrieval tasks. With\nthe onset of pre-trained transformer models such as BERT, neural sparse\nretrieval has led to a new paradigm within retrieval. Despite the success,\nthere has been limited software supporting different sparse retrievers running\nin a unified, common environment. This hinders practitioners from fairly\ncomparing different sparse models and obtaining realistic evaluation results.\nAnother missing piece is, that a majority of prior work evaluates sparse\nretrieval models on in-domain retrieval, i.e. on a single dataset: MS MARCO.\nHowever, a key requirement in practical retrieval systems requires models that\ncan generalize well to unseen out-of-domain, i.e. zero-shot retrieval tasks. In\nthis work, we provide SPRINT, a unified Python toolkit based on Pyserini and\nLucene, supporting a common interface for evaluating neural sparse retrieval.\nThe toolkit currently includes five built-in models: uniCOIL, DeepImpact,\nSPARTA, TILDEv2 and SPLADEv2. Users can also easily add customized models by\ndefining their term weighting method. Using our toolkit, we establish strong\nand reproducible zero-shot sparse retrieval baselines across the\nwell-acknowledged benchmark, BEIR. Our results demonstrate that SPLADEv2\nachieves the best average score of 0.470 nDCG@10 on BEIR amongst all neural\nsparse retrievers. In this work, we further uncover the reasons behind its\nperformance gain. We show that SPLADEv2 produces sparse representations with a\nmajority of tokens outside of the original query and document which is often\ncrucial for its performance gains, i.e. a limitation among its other sparse\ncounterparts. We provide our SPRINT toolkit, models, and data used in our\nexperiments publicly here at https://github.com/thakur-nandan/sprint.", "published": "2023-07-19 22:48:02", "link": "http://arxiv.org/abs/2307.10488v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Abusing Images and Sounds for Indirect Instruction Injection in\n  Multi-Modal LLMs", "abstract": "We demonstrate how images and sounds can be used for indirect prompt and\ninstruction injection in multi-modal LLMs. An attacker generates an adversarial\nperturbation corresponding to the prompt and blends it into an image or audio\nrecording. When the user asks the (unmodified, benign) model about the\nperturbed image or audio, the perturbation steers the model to output the\nattacker-chosen text and/or make the subsequent dialog follow the attacker's\ninstruction. We illustrate this attack with several proof-of-concept examples\ntargeting LLaVa and PandaGPT.", "published": "2023-07-19 23:03:20", "link": "http://arxiv.org/abs/2307.10490v4", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Mood Classification of Bangla Songs Based on Lyrics", "abstract": "Music can evoke various emotions, and with the advancement of technology, it\nhas become more accessible to people. Bangla music, which portrays different\nhuman emotions, lacks sufficient research. The authors of this article aim to\nanalyze Bangla songs and classify their moods based on the lyrics. To achieve\nthis, this research has compiled a dataset of 4000 Bangla song lyrics, genres,\nand used Natural Language Processing and the Bert Algorithm to analyze the\ndata. Among the 4000 songs, 1513 songs are represented for the sad mood, 1362\nfor the romantic mood, 886 for happiness, and the rest 239 are classified as\nrelaxation. By embedding the lyrics of the songs, the authors have classified\nthe songs into four moods: Happy, Sad, Romantic, and Relaxed. This research is\ncrucial as it enables a multi-class classification of songs' moods, making the\nmusic more relatable to people's emotions. The article presents the automated\nresult of the four moods accurately derived from the song lyrics.", "published": "2023-07-19 03:31:41", "link": "http://arxiv.org/abs/2307.10314v1", "categories": ["cs.IR", "cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.IR"}
{"title": "Self-Supervised Acoustic Word Embedding Learning via Correspondence\n  Transformer Encoder", "abstract": "Acoustic word embeddings (AWEs) aims to map a variable-length speech segment\ninto a fixed-dimensional representation. High-quality AWEs should be invariant\nto variations, such as duration, pitch and speaker. In this paper, we introduce\na novel self-supervised method to learn robust AWEs from a large-scale\nunlabelled speech corpus. Our model, named Correspondence Transformer Encoder\n(CTE), employs a teacher-student learning framework. We train the model based\non the idea that different realisations of the same word should be close in the\nunderlying embedding space. Specifically, we feed the teacher and student\nencoder with different acoustic instances of the same word and pre-train the\nmodel with a word-level loss. Our experiments show that the embeddings\nextracted from the proposed CTE model are robust to speech variations, e.g.\nspeakers and domains. Additionally, when evaluated on Xitsonga, a low-resource\ncross-lingual setting, the CTE model achieves new state-of-the-art performance.", "published": "2023-07-19 10:03:08", "link": "http://arxiv.org/abs/2307.09871v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Improving Domain Generalization for Sound Classification with Sparse\n  Frequency-Regularized Transformer", "abstract": "Sound classification models' performance suffers from generalizing on\nout-of-distribution (OOD) data. Numerous methods have been proposed to help the\nmodel generalize. However, most either introduce inference overheads or focus\non long-lasting CNN-variants, while Transformers has been proven to outperform\nCNNs on numerous natural language processing and computer vision tasks. We\npropose FRITO, an effective regularization technique on Transformer's\nself-attention, to improve the model's generalization ability by limiting each\nsequence position's attention receptive field along the frequency dimension on\nthe spectrogram. Experiments show that our method helps Transformer models\nachieve SOTA generalization performance on TAU 2020 and Nsynth datasets while\nsaving 20% inference time.", "published": "2023-07-19 02:21:44", "link": "http://arxiv.org/abs/2307.09723v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "An analysis on the effects of speaker embedding choice in non\n  auto-regressive TTS", "abstract": "In this paper we introduce a first attempt on understanding how a\nnon-autoregressive factorised multi-speaker speech synthesis architecture\nexploits the information present in different speaker embedding sets. We\nanalyse if jointly learning the representations, and initialising them from\npretrained models determine any quality improvements for target speaker\nidentities. In a separate analysis, we investigate how the different sets of\nembeddings impact the network's core speech abstraction (i.e. zero conditioned)\nin terms of speaker identity and representation learning. We show that,\nregardless of the used set of embeddings and learning strategy, the network can\nhandle various speaker identities equally well, with barely noticeable\nvariations in speech output quality, and that speaker leakage within the core\nstructure of the synthesis system is inevitable in the standard training\nprocedures adopted thus far.", "published": "2023-07-19 10:57:54", "link": "http://arxiv.org/abs/2307.09898v1", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "Alzheimer's Disease Detection from Spontaneous Speech and Text: A review", "abstract": "In the past decade, there has been a surge in research examining the use of\nvoice and speech analysis as a means of detecting neurodegenerative diseases\nsuch as Alzheimer's. Many studies have shown that certain acoustic features can\nbe used to differentiate between normal aging and Alzheimer's disease, and\nspeech analysis has been found to be a cost-effective method of detecting\nAlzheimer's dementia. The aim of this review is to analyze the various\nalgorithms used in speech-based detection and classification of Alzheimer's\ndisease. A literature survey was conducted using databases such as Web of\nScience, Google Scholar, and Science Direct, and articles published from\nJanuary 2020 to the present were included based on keywords such as\n``Alzheimer's detection'', \"speech,\" and \"natural language processing.\" The\nADReSS, Pitt corpus, and CCC datasets are commonly used for the analysis of\ndementia from speech, and this review focuses on the various acoustic and\nlinguistic feature engineering-based classification models drawn from 15\nstudies.\n  Based on the findings of this study, it appears that a more accurate model\nfor classifying Alzheimer's disease can be developed by considering both\nlinguistic and acoustic data. The review suggests that speech signals can be a\nuseful tool for detecting dementia and may serve as a reliable biomarker for\nefficiently identifying Alzheimer's disease.", "published": "2023-07-19 14:42:37", "link": "http://arxiv.org/abs/2307.10005v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "DisCover: Disentangled Music Representation Learning for Cover Song\n  Identification", "abstract": "In the field of music information retrieval (MIR), cover song identification\n(CSI) is a challenging task that aims to identify cover versions of a query\nsong from a massive collection. Existing works still suffer from high\nintra-song variances and inter-song correlations, due to the entangled nature\nof version-specific and version-invariant factors in their modeling. In this\nwork, we set the goal of disentangling version-specific and version-invariant\nfactors, which could make it easier for the model to learn invariant music\nrepresentations for unseen query songs. We analyze the CSI task in a\ndisentanglement view with the causal graph technique, and identify the\nintra-version and inter-version effects biasing the invariant learning. To\nblock these effects, we propose the disentangled music representation learning\nframework (DisCover) for CSI. DisCover consists of two critical components: (1)\nKnowledge-guided Disentanglement Module (KDM) and (2) Gradient-based\nAdversarial Disentanglement Module (GADM), which block intra-version and\ninter-version biased effects, respectively. KDM minimizes the mutual\ninformation between the learned representations and version-variant factors\nthat are identified with prior domain knowledge. GADM identifies\nversion-variant factors by simulating the representation transitions between\nintra-song versions, and exploits adversarial distillation for effect blocking.\nExtensive comparisons with best-performing methods and in-depth analysis\ndemonstrate the effectiveness of DisCover and the and necessity of\ndisentanglement for CSI.", "published": "2023-07-19 06:31:58", "link": "http://arxiv.org/abs/2307.09775v1", "categories": ["cs.IR", "cs.SD", "eess.AS"], "primary_category": "cs.IR"}
{"title": "From West to East: Who can understand the music of the others better?", "abstract": "Recent developments in MIR have led to several benchmark deep learning models\nwhose embeddings can be used for a variety of downstream tasks. At the same\ntime, the vast majority of these models have been trained on Western pop/rock\nmusic and related styles. This leads to research questions on whether these\nmodels can be used to learn representations for different music cultures and\nstyles, or whether we can build similar music audio embedding models trained on\ndata from different cultures or styles. To that end, we leverage transfer\nlearning methods to derive insights about the similarities between the\ndifferent music cultures to which the data belongs to. We use two Western music\ndatasets, two traditional/folk datasets coming from eastern Mediterranean\ncultures, and two datasets belonging to Indian art music. Three deep audio\nembedding models are trained and transferred across domains, including two\nCNN-based and a Transformer-based architecture, to perform auto-tagging for\neach target domain dataset. Experimental results show that competitive\nperformance is achieved in all domains via transfer learning, while the best\nsource dataset varies for each music culture. The implementation and the\ntrained models are both provided in a public repository.", "published": "2023-07-19 07:29:14", "link": "http://arxiv.org/abs/2307.09795v1", "categories": ["cs.SD", "cs.CV", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Polyffusion: A Diffusion Model for Polyphonic Score Generation with\n  Internal and External Controls", "abstract": "We propose Polyffusion, a diffusion model that generates polyphonic music\nscores by regarding music as image-like piano roll representations. The model\nis capable of controllable music generation with two paradigms: internal\ncontrol and external control. Internal control refers to the process in which\nusers pre-define a part of the music and then let the model infill the rest,\nsimilar to the task of masked music generation (or music inpainting). External\ncontrol conditions the model with external yet related information, such as\nchord, texture, or other features, via the cross-attention mechanism. We show\nthat by using internal and external controls, Polyffusion unifies a wide range\nof music creation tasks, including melody generation given accompaniment,\naccompaniment generation given melody, arbitrary music segment inpainting, and\nmusic arrangement given chords or textures. Experimental results show that our\nmodel significantly outperforms existing Transformer and sampling-based\nbaselines, and using pre-trained disentangled representations as external\nconditions yields more effective controls.", "published": "2023-07-19 06:36:31", "link": "http://arxiv.org/abs/2307.10304v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
