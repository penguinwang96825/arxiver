{"title": "Grounding 'Grounding' in NLP", "abstract": "The NLP community has seen substantial recent interest in grounding to\nfacilitate interaction between language technologies and the world. However, as\na community, we use the term broadly to reference any linking of text to data\nor non-textual modality. In contrast, Cognitive Science more formally defines\n\"grounding\" as the process of establishing what mutual information is required\nfor successful communication between two interlocutors -- a definition which\nmight implicitly capture the NLP usage but differs in intent and scope. We\ninvestigate the gap between these definitions and seek answers to the following\nquestions: (1) What aspects of grounding are missing from NLP tasks? Here we\npresent the dimensions of coordination, purviews and constraints. (2) How is\nthe term \"grounding\" used in the current research? We study the trends in\ndatasets, domains, and tasks introduced in recent NLP conferences. And finally,\n(3) How to advance our current definition to bridge the gap with Cognitive\nScience? We present ways to both create new tasks or repurpose existing ones to\nmake advancements towards achieving a more complete sense of grounding.", "published": "2021-06-04 00:40:59", "link": "http://arxiv.org/abs/2106.02192v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BERTTune: Fine-Tuning Neural Machine Translation with BERTScore", "abstract": "Neural machine translation models are often biased toward the limited\ntranslation references seen during training. To amend this form of overfitting,\nin this paper we propose fine-tuning the models with a novel training objective\nbased on the recently-proposed BERTScore evaluation metric. BERTScore is a\nscoring function based on contextual embeddings that overcomes the typical\nlimitations of n-gram-based metrics (e.g. synonyms, paraphrases), allowing\ntranslations that are different from the references, yet close in the\ncontextual embedding space, to be treated as substantially correct. To be able\nto use BERTScore as a training objective, we propose three approaches for\ngenerating soft predictions, allowing the network to remain completely\ndifferentiable end-to-end. Experiments carried out over four, diverse language\npairs have achieved improvements of up to 0.58 pp (3.28%) in BLEU score and up\nto 0.76 pp (0.98%) in BERTScore (F_BERT) when fine-tuning a strong baseline.", "published": "2021-06-04 02:13:59", "link": "http://arxiv.org/abs/2106.02208v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NAST: A Non-Autoregressive Generator with Word Alignment for\n  Unsupervised Text Style Transfer", "abstract": "Autoregressive models have been widely used in unsupervised text style\ntransfer. Despite their success, these models still suffer from the content\npreservation problem that they usually ignore part of the source sentence and\ngenerate some irrelevant words with strong styles. In this paper, we propose a\nNon-Autoregressive generator for unsupervised text Style Transfer (NAST), which\nalleviates the problem from two aspects. First, we observe that most words in\nthe transferred sentence can be aligned with related words in the source\nsentence, so we explicitly model word alignments to suppress irrelevant words.\nSecond, existing models trained with the cycle loss align sentences in two\nstylistic text spaces, which lacks fine-grained control at the word level. The\nproposed non-autoregressive generator focuses on the connections between\naligned words, which learns the word-level transfer between styles. For\nexperiments, we integrate the proposed generator into two base models and\nevaluate them on two style transfer tasks. The results show that NAST can\nsignificantly improve the overall performance and provide explainable word\nalignments. Moreover, the non-autoregressive generator achieves over 10x\nspeedups at inference. Our codes are available at\nhttps://github.com/thu-coai/NAST.", "published": "2021-06-04 02:23:54", "link": "http://arxiv.org/abs/2106.02210v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ERNIE-Tiny : A Progressive Distillation Framework for Pretrained\n  Transformer Compression", "abstract": "Pretrained language models (PLMs) such as BERT adopt a training paradigm\nwhich first pretrain the model in general data and then finetune the model on\ntask-specific data, and have recently achieved great success. However, PLMs are\nnotorious for their enormous parameters and hard to be deployed on real-life\napplications. Knowledge distillation has been prevailing to address this\nproblem by transferring knowledge from a large teacher to a much smaller\nstudent over a set of data. We argue that the selection of thee three key\ncomponents, namely teacher, training data, and learning objective, is crucial\nto the effectiveness of distillation. We, therefore, propose a four-stage\nprogressive distillation framework ERNIE-Tiny to compress PLM, which varies the\nthree components gradually from general level to task-specific level.\nSpecifically, the first stage, General Distillation, performs distillation with\nguidance from pretrained teacher, gerenal data and latent distillation loss.\nThen, General-Enhanced Distillation changes teacher model from pretrained\nteacher to finetuned teacher. After that, Task-Adaptive Distillation shifts\ntraining data from general data to task-specific data. In the end,\nTask-Specific Distillation, adds two additional losses, namely Soft-Label and\nHard-Label loss onto the last stage. Empirical results demonstrate the\neffectiveness of our framework and generalization gain brought by ERNIE-Tiny.In\nparticular, experiments show that a 4-layer ERNIE-Tiny maintains over\n98.0%performance of its 12-layer teacher BERT base on GLUE benchmark,\nsurpassing state-of-the-art (SOTA) by 1.0% GLUE score with the same amount of\nparameters. Moreover, ERNIE-Tiny achieves a new compression SOTA on five\nChinese NLP tasks, outperforming BERT base by 0.4% accuracy with 7.5x fewer\nparameters and9.4x faster inference speed.", "published": "2021-06-04 04:00:16", "link": "http://arxiv.org/abs/2106.02241v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Scalable Transformers for Neural Machine Translation", "abstract": "Transformer has been widely adopted in Neural Machine Translation (NMT)\nbecause of its large capacity and parallel training of sequence generation.\nHowever, the deployment of Transformer is challenging because different\nscenarios require models of different complexities and scales. Naively training\nmultiple Transformers is redundant in terms of both computation and memory. In\nthis paper, we propose a novel Scalable Transformers, which naturally contains\nsub-Transformers of different scales and have shared parameters. Each\nsub-Transformer can be easily obtained by cropping the parameters of the\nlargest Transformer. A three-stage training scheme is proposed to tackle the\ndifficulty of training the Scalable Transformers, which introduces additional\nsupervisions from word-level and sequence-level self-distillation. Extensive\nexperiments were conducted on WMT EN-De and En-Fr to validate our proposed\nScalable Transformers.", "published": "2021-06-04 04:04:10", "link": "http://arxiv.org/abs/2106.02242v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AgreeSum: Agreement-Oriented Multi-Document Summarization", "abstract": "We aim to renew interest in a particular multi-document summarization (MDS)\ntask which we call AgreeSum: agreement-oriented multi-document summarization.\nGiven a cluster of articles, the goal is to provide abstractive summaries that\nrepresent information common and faithful to all input articles. Given the lack\nof existing datasets, we create a dataset for AgreeSum, and provide annotations\non article-summary entailment relations for a subset of the clusters in the\ndataset. We aim to create strong baselines for the task by applying the\ntop-performing pretrained single-document summarization model PEGASUS onto\nAgreeSum, leveraging both annotated clusters by supervised losses, and\nunannotated clusters by T5-based entailment-related and language-related\nlosses. Compared to other baselines, both automatic evaluation and human\nevaluation show better article-summary and cluster-summary entailment in\ngenerated summaries. On a separate note, we hope that our article-summary\nentailment annotations contribute to the community's effort in improving\nabstractive summarization faithfulness.", "published": "2021-06-04 06:17:49", "link": "http://arxiv.org/abs/2106.02278v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Decoupled Dialogue Modeling and Semantic Parsing for Multi-Turn\n  Text-to-SQL", "abstract": "Recently, Text-to-SQL for multi-turn dialogue has attracted great interest.\nHere, the user input of the current turn is parsed into the corresponding SQL\nquery of the appropriate database, given all previous dialogue history. Current\napproaches mostly employ end-to-end models and consequently face two\nchallenges. First, dialogue history modeling and Text-to-SQL parsing are\nimplicitly combined, hence it is hard to carry out interpretable analysis and\nobtain targeted improvement. Second, SQL annotation of multi-turn dialogue is\nvery expensive, leading to training data sparsity. In this paper, we propose a\nnovel decoupled multi-turn Text-to-SQL framework, where an utterance rewrite\nmodel first explicitly solves completion of dialogue context, and then a\nsingle-turn Text-to-SQL parser follows. A dual learning approach is also\nproposed for the utterance rewrite model to address the data sparsity problem.\nCompared with end-to-end approaches, the proposed decoupled method can achieve\nexcellent performance without any annotated in-domain data. With just a few\nannotated rewrite cases, the decoupled method outperforms the released\nstate-of-the-art end-to-end models on both SParC and CoSQL datasets.", "published": "2021-06-04 06:31:39", "link": "http://arxiv.org/abs/2106.02282v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dutch Named Entity Recognition and De-identification Methods for the\n  Human Resource Domain", "abstract": "The human resource (HR) domain contains various types of privacy-sensitive\ntextual data, such as e-mail correspondence and performance appraisal. Doing\nresearch on these documents brings several challenges, one of them\nanonymisation. In this paper, we evaluate the current Dutch text\nde-identification methods for the HR domain in four steps. First, by updating\none of these methods with the latest named entity recognition (NER) models. The\nresult is that the NER model based on the CoNLL 2002 corpus in combination with\nthe BERTje transformer give the best combination for suppressing persons\n(recall 0.94) and locations (recall 0.82). For suppressing gender, DEDUCE is\nperforming best (recall 0.53). Second NER evaluation is based on both strict\nde-identification of entities (a person must be suppressed as a person) and\nthird evaluation on a loose sense of de-identification (no matter what how a\nperson is suppressed, as long it is suppressed). In the fourth and last step a\nnew kind of NER dataset is tested for recognising job titles in texts.", "published": "2021-06-04 06:59:25", "link": "http://arxiv.org/abs/2106.02287v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modeling the Unigram Distribution", "abstract": "The unigram distribution is the non-contextual probability of finding a\nspecific word form in a corpus. While of central importance to the study of\nlanguage, it is commonly approximated by each word's sample frequency in the\ncorpus. This approach, being highly dependent on sample size, assigns zero\nprobability to any out-of-vocabulary (oov) word form. As a result, it produces\nnegatively biased probabilities for any oov word form, while positively biased\nprobabilities to in-corpus words. In this work, we argue in favor of properly\nmodeling the unigram distribution -- claiming it should be a central task in\nnatural language processing. With this in mind, we present a novel model for\nestimating it in a language (a neuralization of Goldwater et al.'s (2011)\nmodel) and show it produces much better estimates across a diverse set of 7\nlanguages than the na\\\"ive use of neural character-level language models.", "published": "2021-06-04 07:02:49", "link": "http://arxiv.org/abs/2106.02289v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AdvPicker: Effectively Leveraging Unlabeled Data via Adversarial\n  Discriminator for Cross-Lingual NER", "abstract": "Neural methods have been shown to achieve high performance in Named Entity\nRecognition (NER), but rely on costly high-quality labeled data for training,\nwhich is not always available across languages. While previous works have shown\nthat unlabeled data in a target language can be used to improve cross-lingual\nmodel performance, we propose a novel adversarial approach (AdvPicker) to\nbetter leverage such data and further improve results. We design an adversarial\nlearning framework in which an encoder learns entity domain knowledge from\nlabeled source-language data and better shared features are captured via\nadversarial training - where a discriminator selects less language-dependent\ntarget-language data via similarity to the source language. Experimental\nresults on standard benchmark datasets well demonstrate that the proposed\nmethod benefits strongly from this data selection process and outperforms\nexisting state-of-the-art methods; without requiring any additional external\nresources (e.g., gazetteers or via machine translation). The code is available\nat https://aka.ms/AdvPicker", "published": "2021-06-04 07:17:18", "link": "http://arxiv.org/abs/2106.02300v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Retrieve & Memorize: Dialog Policy Learning with Multi-Action Memory", "abstract": "Dialogue policy learning, a subtask that determines the content of system\nresponse generation and then the degree of task completion, is essential for\ntask-oriented dialogue systems. However, the unbalanced distribution of system\nactions in dialogue datasets often causes difficulty in learning to generate\ndesired actions and responses. In this paper, we propose a\nretrieve-and-memorize framework to enhance the learning of system actions.\nSpecially, we first design a neural context-aware retrieval module to retrieve\nmultiple candidate system actions from the training set given a dialogue\ncontext. Then, we propose a memory-augmented multi-decoder network to generate\nthe system actions conditioned on the candidate actions, which allows the\nnetwork to adaptively select key information in the candidate actions and\nignore noises. We conduct experiments on the large-scale multi-domain\ntask-oriented dialogue dataset MultiWOZ 2.0 and MultiWOZ 2.1. Experimental\nresults show that our method achieves competitive performance among several\nstate-of-the-art models in the context-to-response generation task.", "published": "2021-06-04 07:53:56", "link": "http://arxiv.org/abs/2106.02317v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AdaTag: Multi-Attribute Value Extraction from Product Profiles with\n  Adaptive Decoding", "abstract": "Automatic extraction of product attribute values is an important enabling\ntechnology in e-Commerce platforms. This task is usually modeled using sequence\nlabeling architectures, with several extensions to handle multi-attribute\nextraction. One line of previous work constructs attribute-specific models,\nthrough separate decoders or entirely separate models. However, this approach\nconstrains knowledge sharing across different attributes. Other contributions\nuse a single multi-attribute model, with different techniques to embed\nattribute information. But sharing the entire network parameters across all\nattributes can limit the model's capacity to capture attribute-specific\ncharacteristics. In this paper we present AdaTag, which uses adaptive decoding\nto handle extraction. We parameterize the decoder with pretrained attribute\nembeddings, through a hypernetwork and a Mixture-of-Experts (MoE) module. This\nallows for separate, but semantically correlated, decoders to be generated on\nthe fly for different attributes. This approach facilitates knowledge sharing,\nwhile maintaining the specificity of each attribute. Our experiments on a\nreal-world e-Commerce dataset show marked improvements over previous methods.", "published": "2021-06-04 07:54:11", "link": "http://arxiv.org/abs/2106.02318v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bi-Granularity Contrastive Learning for Post-Training in Few-Shot Scene", "abstract": "The major paradigm of applying a pre-trained language model to downstream\ntasks is to fine-tune it on labeled task data, which often suffers instability\nand low performance when the labeled examples are scarce.~One way to alleviate\nthis problem is to apply post-training on unlabeled task data before\nfine-tuning, adapting the pre-trained model to target domains by contrastive\nlearning that considers either token-level or sequence-level similarity.\nInspired by the success of sequence masking, we argue that both token-level and\nsequence-level similarities can be captured with a pair of masked\nsequences.~Therefore, we propose complementary random masking (CRM) to generate\na pair of masked sequences from an input sequence for sequence-level\ncontrastive learning and then develop contrastive masked language modeling\n(CMLM) for post-training to integrate both token-level and sequence-level\ncontrastive learnings.~Empirical results show that CMLM surpasses several\nrecent post-training methods in few-shot settings without the need for data\naugmentation.", "published": "2021-06-04 08:17:48", "link": "http://arxiv.org/abs/2106.02327v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Annotation Curricula to Implicitly Train Non-Expert Annotators", "abstract": "Annotation studies often require annotators to familiarize themselves with\nthe task, its annotation scheme, and the data domain. This can be overwhelming\nin the beginning, mentally taxing, and induce errors into the resulting\nannotations; especially in citizen science or crowd sourcing scenarios where\ndomain expertise is not required and only annotation guidelines are provided.\nTo alleviate these issues, we propose annotation curricula, a novel approach to\nimplicitly train annotators. Our goal is to gradually introduce annotators into\nthe task by ordering instances that are annotated according to a learning\ncurriculum. To do so, we first formalize annotation curricula for sentence- and\nparagraph-level annotation tasks, define an ordering strategy, and identify\nwell-performing heuristics and interactively trained models on three existing\nEnglish datasets. We then conduct a user study with 40 voluntary participants\nwho are asked to identify the most fitting misconception for English tweets\nabout the Covid-19 pandemic. Our results show that using a simple heuristic to\norder instances can already significantly reduce the total annotation time\nwhile preserving a high annotation quality. Annotation curricula thus can\nprovide a novel way to improve data collection. To facilitate future research,\nwe further share our code and data consisting of 2,400 annotations.", "published": "2021-06-04 09:48:28", "link": "http://arxiv.org/abs/2106.02382v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prediction or Comparison: Toward Interpretable Qualitative Reasoning", "abstract": "Qualitative relationships illustrate how changing one property (e.g., moving\nvelocity) affects another (e.g., kinetic energy) and constitutes a considerable\nportion of textual knowledge. Current approaches use either semantic parsers to\ntransform natural language inputs into logical expressions or a \"black-box\"\nmodel to solve them in one step. The former has a limited application range,\nwhile the latter lacks interpretability. In this work, we categorize\nqualitative reasoning tasks into two types: prediction and comparison. In\nparticular, we adopt neural network modules trained in an end-to-end manner to\nsimulate the two reasoning processes. Experiments on two qualitative reasoning\nquestion answering datasets, QuaRTz and QuaRel, show our methods' effectiveness\nand generalization capability, and the intermediate outputs provided by the\nmodules make the reasoning process interpretable.", "published": "2021-06-04 10:27:55", "link": "http://arxiv.org/abs/2106.02399v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "You Only Compress Once: Towards Effective and Elastic BERT Compression\n  via Exploit-Explore Stochastic Nature Gradient", "abstract": "Despite superior performance on various natural language processing tasks,\npre-trained models such as BERT are challenged by deploying on\nresource-constraint devices. Most existing model compression approaches require\nre-compression or fine-tuning across diverse constraints to accommodate various\nhardware deployments. This practically limits the further application of model\ncompression. Moreover, the ineffective training and searching process of\nexisting elastic compression paradigms[4,27] prevents the direct migration to\nBERT compression. Motivated by the necessity of efficient inference across\nvarious constraints on BERT, we propose a novel approach, YOCO-BERT, to achieve\ncompress once and deploy everywhere. Specifically, we first construct a huge\nsearch space with 10^13 architectures, which covers nearly all configurations\nin BERT model. Then, we propose a novel stochastic nature gradient optimization\nmethod to guide the generation of optimal candidate architecture which could\nkeep a balanced trade-off between explorations and exploitation. When a certain\nresource constraint is given, a lightweight distribution optimization approach\nis utilized to obtain the optimal network for target deployment without\nfine-tuning. Compared with state-of-the-art algorithms, YOCO-BERT provides more\ncompact models, yet achieving 2.1%-4.5% average accuracy improvement on the\nGLUE benchmark. Besides, YOCO-BERT is also more effective, e.g.,the training\ncomplexity is O(1)for N different devices. Code is\navailablehttps://github.com/MAC-AutoML/YOCO-BERT.", "published": "2021-06-04 12:17:44", "link": "http://arxiv.org/abs/2106.02435v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Great Service! Fine-grained Parsing of Implicit Arguments", "abstract": "Broad-coverage meaning representations in NLP mostly focus on explicitly\nexpressed content. More importantly, the scarcity of datasets annotating\ndiverse implicit roles limits empirical studies into their linguistic nuances.\nFor example, in the web review \"Great service!\", the provider and consumer are\nimplicit arguments of different types. We examine an annotated corpus of\nfine-grained implicit arguments (Cui and Hershcovich, 2020) by carefully\nre-annotating it, resolving several inconsistencies. Subsequently, we present\nthe first transition-based neural parser that can handle implicit arguments\ndynamically, and experiment with two different transition systems on the\nimproved dataset. We find that certain types of implicit arguments are more\ndifficult to parse than others and that the simpler system is more accurate in\nrecovering implicit arguments, despite having a lower overall parsing score,\nattesting current reasoning limitations of NLP models. This work will\nfacilitate a better understanding of implicit and underspecified language, by\nincorporating it holistically into meaning representations.", "published": "2021-06-04 15:50:35", "link": "http://arxiv.org/abs/2106.02561v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Recurrent Neural Networks with Mixed Hierarchical Structures for Natural\n  Language Processing", "abstract": "Hierarchical structures exist in both linguistics and Natural Language\nProcessing (NLP) tasks. How to design RNNs to learn hierarchical\nrepresentations of natural languages remains a long-standing challenge. In this\npaper, we define two different types of boundaries referred to as static and\ndynamic boundaries, respectively, and then use them to construct a multi-layer\nhierarchical structure for document classification tasks. In particular, we\nfocus on a three-layer hierarchical structure with static word- and sentence-\nlayers and a dynamic phrase-layer. LSTM cells and two boundary detectors are\nused to implement the proposed structure, and the resulting network is called\nthe {\\em Recurrent Neural Network with Mixed Hierarchical Structures}\n(MHS-RNN). We further add three layers of attention mechanisms to the MHS-RNN\nmodel. Incorporating attention mechanisms allows our model to use more\nimportant content to construct document representation and enhance its\nperformance on document classification tasks. Experiments on five different\ndatasets show that the proposed architecture outperforms previous methods on\nall the five tasks.", "published": "2021-06-04 15:50:42", "link": "http://arxiv.org/abs/2106.02562v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural semi-Markov CRF for Monolingual Word Alignment", "abstract": "Monolingual word alignment is important for studying fine-grained editing\noperations (i.e., deletion, addition, and substitution) in text-to-text\ngeneration tasks, such as paraphrase generation, text simplification,\nneutralizing biased language, etc. In this paper, we present a novel neural\nsemi-Markov CRF alignment model, which unifies word and phrase alignments\nthrough variable-length spans. We also create a new benchmark with human\nannotations that cover four different text genres to evaluate monolingual word\nalignment models in more realistic settings. Experimental results show that our\nproposed model outperforms all previous approaches for monolingual word\nalignment as well as a competitive QA-based baseline, which was previously only\napplied to bilingual data. Our model demonstrates good generalizability to\nthree out-of-domain datasets and shows great utility in two downstream\napplications: automatic text simplification and sentence pair classification\ntasks.", "published": "2021-06-04 16:04:00", "link": "http://arxiv.org/abs/2106.02569v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MultiOpEd: A Corpus of Multi-Perspective News Editorials", "abstract": "We propose MultiOpEd, an open-domain news editorial corpus that supports\nvarious tasks pertaining to the argumentation structure in news editorials,\nfocusing on automatic perspective discovery. News editorial is a genre of\npersuasive text, where the argumentation structure is usually implicit.\nHowever, the arguments presented in an editorial typically center around a\nconcise, focused thesis, which we refer to as their perspective. MultiOpEd aims\nat supporting the study of multiple tasks relevant to automatic perspective\ndiscovery, where a system is expected to produce a single-sentence thesis\nstatement summarizing the arguments presented. We argue that identifying and\nabstracting such natural language perspectives from editorials is a crucial\nstep toward studying the implicit argumentation structure in news editorials.\nWe first discuss the challenges and define a few conceptual tasks towards our\ngoal. To demonstrate the utility of MultiOpEd and the induced tasks, we study\nthe problem of perspective summarization in a multi-task learning setting, as a\ncase study. We show that, with the induced tasks as auxiliary tasks, we can\nimprove the quality of the perspective summary generated. We hope that\nMultiOpEd will be a useful resource for future studies on argumentation in the\nnews editorial domain.", "published": "2021-06-04 21:23:22", "link": "http://arxiv.org/abs/2106.02725v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Meaning Representation of Numeric Fused-Heads in UCCA", "abstract": "We exhibit that the implicit UCCA parser does not address numeric fused-heads\n(NFHs) consistently, which could result either from inconsistent annotation,\ninsufficient training data or a modelling limitation. and show which factors\nare involved. We consider this phenomenon important, as it is pervasive in text\nand critical for correct inference. Careful design and fine-grained annotation\nof NFHs in meaning representation frameworks would benefit downstream tasks\nsuch as machine translation, natural language inference and question answering,\nparticularly when they require numeric reasoning, as recovering and\ncategorizing them. We are investigating the treatment of this phenomenon by\nother meaning representations, such as AMR. We encourage researchers in meaning\nrepresentations, and computational linguistics in general, to address this\nphenomenon in future research.", "published": "2021-06-04 16:00:12", "link": "http://arxiv.org/abs/2106.07364v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Conversations Are Not Flat: Modeling the Dynamic Information Flow across\n  Dialogue Utterances", "abstract": "Nowadays, open-domain dialogue models can generate acceptable responses\naccording to the historical context based on the large-scale pre-trained\nlanguage models. However, they generally concatenate the dialogue history\ndirectly as the model input to predict the response, which we named as the flat\npattern and ignores the dynamic information flow across dialogue utterances. In\nthis work, we propose the DialoFlow model, in which we introduce a dynamic flow\nmechanism to model the context flow, and design three training objectives to\ncapture the information dynamics across dialogue utterances by addressing the\nsemantic influence brought about by each utterance in large-scale pre-training.\nExperiments on the multi-reference Reddit Dataset and DailyDialog Dataset\ndemonstrate that our DialoFlow significantly outperforms the DialoGPT on the\ndialogue generation task. Besides, we propose the Flow score, an effective\nautomatic metric for evaluating interactive human-bot conversation quality\nbased on the pre-trained DialoFlow, which presents high chatbot-level\ncorrelation ($r=0.9$) with human ratings among 11 chatbots. Code and\npre-trained models will be public.\n\\footnote{\\url{https://github.com/ictnlp/DialoFlow}}", "published": "2021-06-04 03:04:06", "link": "http://arxiv.org/abs/2106.02227v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Addressing Inquiries about History: An Efficient and Practical Framework\n  for Evaluating Open-domain Chatbot Consistency", "abstract": "A good open-domain chatbot should avoid presenting contradictory responses\nabout facts or opinions in a conversational session, known as its consistency\ncapacity. However, evaluating the consistency capacity of a chatbot is still\nchallenging. Employing human judges to interact with chatbots on purpose to\ncheck their capacities is costly and low-efficient, and difficult to get rid of\nsubjective bias. In this paper, we propose the Addressing Inquiries about\nHistory (AIH), an efficient and practical framework for the consistency\nevaluation. At the conversation stage, AIH attempts to address appropriate\ninquiries about the dialogue history to induce the chatbot to redeclare the\nhistorical facts or opinions. We carry out the conversation between chatbots,\nwhich is more efficient than the human-bot interaction and can also alleviate\nthe subjective bias. In this way, we manage to rapidly obtain a dialog session\nthat contains responses with high contradiction possibilities. At the\ncontradiction recognition stage, we can either employ human judges or a natural\nlanguage inference (NLI) model to recognize whether the answers to the\ninquiries are contradictory with history. Finally, we are able to rank chatbots\naccording to the contradiction statistics. Experiments on open-domain chatbots\nshow that our approach can efficiently and reliably assess the consistency\ncapacity of chatbots and achieve a high ranking correlation with the human\nevaluation. We release the framework and hope to help improve the consistency\ncapacity of chatbots. \\footnote{\\url{https://github.com/ictnlp/AIH}}", "published": "2021-06-04 03:04:13", "link": "http://arxiv.org/abs/2106.02228v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Language Scaling for Universal Suggested Replies Model", "abstract": "We consider the problem of scaling automated suggested replies for Outlook\nemail system to multiple languages. Faced with increased compute requirements\nand low resources for language expansion, we build a single universal model for\nimproving the quality and reducing run-time costs of our production system.\nHowever, restricted data movement across regional centers prevents joint\ntraining across languages. To this end, we propose a multi-task continual\nlearning framework, with auxiliary tasks and language adapters to learn\nuniversal language representation across regions. The experimental results show\npositive cross-lingual transfer across languages while reducing catastrophic\nforgetting across regions. Our online results on real user traffic show\nsignificant gains in CTR and characters saved, as well as 65% training cost\nreduction compared with per-language models. As a consequence, we have scaled\nthe feature in multiple languages including low-resource markets.", "published": "2021-06-04 03:15:52", "link": "http://arxiv.org/abs/2106.02232v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Knowing the No-match: Entity Alignment with Dangling Cases", "abstract": "This paper studies a new problem setting of entity alignment for knowledge\ngraphs (KGs). Since KGs possess different sets of entities, there could be\nentities that cannot find alignment across them, leading to the problem of\ndangling entities. As the first attempt to this problem, we construct a new\ndataset and design a multi-task learning framework for both entity alignment\nand dangling entity detection. The framework can opt to abstain from predicting\nalignment for the detected dangling entities. We propose three techniques for\ndangling entity detection that are based on the distribution of\nnearest-neighbor distances, i.e., nearest neighbor classification, marginal\nranking and background ranking. After detecting and removing dangling entities,\nan incorporated entity alignment model in our framework can provide more robust\nalignment for remaining entities. Comprehensive experiments and analyses\ndemonstrate the effectiveness of our framework. We further discover that the\ndangling entity detection module can, in turn, improve alignment learning and\nthe final performance. The contributed resource is publicly available to foster\nfurther research.", "published": "2021-06-04 04:28:36", "link": "http://arxiv.org/abs/2106.02248v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Human-Adversarial Visual Question Answering", "abstract": "Performance on the most commonly used Visual Question Answering dataset (VQA\nv2) is starting to approach human accuracy. However, in interacting with\nstate-of-the-art VQA models, it is clear that the problem is far from being\nsolved. In order to stress test VQA models, we benchmark them against\nhuman-adversarial examples. Human subjects interact with a state-of-the-art VQA\nmodel, and for each image in the dataset, attempt to find a question where the\nmodel's predicted answer is incorrect. We find that a wide range of\nstate-of-the-art models perform poorly when evaluated on these examples. We\nconduct an extensive analysis of the collected adversarial examples and provide\nguidance on future research directions. We hope that this Adversarial VQA\n(AdVQA) benchmark can help drive progress in the field and advance the state of\nthe art.", "published": "2021-06-04 06:25:32", "link": "http://arxiv.org/abs/2106.02280v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Cross-language Sentence Selection via Data Augmentation and Rationale\n  Training", "abstract": "This paper proposes an approach to cross-language sentence selection in a\nlow-resource setting. It uses data augmentation and negative sampling\ntechniques on noisy parallel sentence data to directly learn a cross-lingual\nembedding-based query relevance model. Results show that this approach performs\nas well as or better than multiple state-of-the-art machine translation +\nmonolingual retrieval systems trained on the same parallel data. Moreover, when\na rationale training secondary objective is applied to encourage the model to\nmatch word alignment hints from a phrase-based statistical machine translation\nmodel, consistent improvements are seen across three language pairs\n(English-Somali, English-Swahili and English-Tagalog) over a variety of\nstate-of-the-art baselines.", "published": "2021-06-04 07:08:47", "link": "http://arxiv.org/abs/2106.02293v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "On (co-lex) Ordering Automata", "abstract": "The states of a deterministic finite automaton A can be identified with\ncollections of words in Pf(L(A)) -- the set of prefixes of words belonging to\nthe regular language accepted by A. But words can be ordered and among the many\npossible orders a very natural one is the co-lexicographic one. Such\nnaturalness stems from the fact that it suggests a transfer of the order from\nwords to the automaton's states. In a number of papers automata admitting a\ntotal ordering of states coherent with the ordering of the set of words\nreaching them have been proposed. Such class of ordered automata -- the Wheeler\nautomata -- turned out to be efficiently stored/searched using an index.\nUnfortunately not all automata can be totally ordered as previously outlined.\nHowever, automata can always be partially ordered and an intrinsic measure of\ntheir complexity can be defined and effectively determined, as the minimum\nwidth of one of their admissible partial orders. As shown in previous works,\nthis new concept of width of an automaton has useful consequences in the fields\nof graph compression, indexing data structures, and automata theory. In this\npaper we prove that a canonical, minimum-width, partially-ordered automaton\naccepting a language L -- dubbed the Hasse automaton H of L -- can be\nexhibited. H provides, in a precise sense, the best possible way to (partially)\norder the states of any automaton accepting L, as long as we want to maintain\nan operational link with the (co-lexicographic) order of Pf(L(A)). Using H we\nprove that the width of the language can be effectively computed from the\nminimum automaton recognizing the language. Finally, we explore the\nrelationship between two (often conflicting) objectives: minimizing the width\nand minimizing the number of states of an automaton.", "published": "2021-06-04 07:41:58", "link": "http://arxiv.org/abs/2106.02309v1", "categories": ["cs.FL", "cs.CL"], "primary_category": "cs.FL"}
{"title": "ERICA: An Empathetic Android Companion for Covid-19 Quarantine", "abstract": "Over the past year, research in various domains, including Natural Language\nProcessing (NLP), has been accelerated to fight against the COVID-19 pandemic,\nyet such research has just started on dialogue systems. In this paper, we\nintroduce an end-to-end dialogue system which aims to ease the isolation of\npeople under self-quarantine. We conduct a control simulation experiment to\nassess the effects of the user interface, a web-based virtual agent called Nora\nvs. the android ERICA via a video call. The experimental results show that the\nandroid offers a more valuable user experience by giving the impression of\nbeing more empathetic and engaging in the conversation due to its nonverbal\ninformation, such as facial expressions and body gestures.", "published": "2021-06-04 08:14:43", "link": "http://arxiv.org/abs/2106.02325v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "cs60075_team2 at SemEval-2021 Task 1 : Lexical Complexity Prediction\n  using Transformer-based Language Models pre-trained on various text corpora", "abstract": "This paper describes the performance of the team cs60075_team2 at SemEval\n2021 Task 1 - Lexical Complexity Prediction. The main contribution of this\npaper is to fine-tune transformer-based language models pre-trained on several\ntext corpora, some being general (E.g., Wikipedia, BooksCorpus), some being the\ncorpora from which the CompLex Dataset was extracted, and others being from\nother specific domains such as Finance, Law, etc. We perform ablation studies\non selecting the transformer models and how their individual complexity scores\nare aggregated to get the resulting complexity scores. Our method achieves a\nbest Pearson Correlation of $0.784$ in sub-task 1 (single word) and $0.836$ in\nsub-task 2 (multiple word expressions).", "published": "2021-06-04 08:42:00", "link": "http://arxiv.org/abs/2106.02340v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learning Slice-Aware Representations with Mixture of Attentions", "abstract": "Real-world machine learning systems are achieving remarkable performance in\nterms of coarse-grained metrics like overall accuracy and F-1 score. However,\nmodel improvement and development often require fine-grained modeling on\nindividual data subsets or slices, for instance, the data slices where the\nmodels have unsatisfactory results. In practice, it gives tangible values for\ndeveloping such models that can pay extra attention to critical or interested\nslices while retaining the original overall performance. This work extends the\nrecent slice-based learning (SBL)~\\cite{chen2019slice} with a mixture of\nattentions (MoA) to learn slice-aware dual attentive representations. We\nempirically show that the MoA approach outperforms the baseline method as well\nas the original SBL approach on monitored slices with two natural language\nunderstanding (NLU) tasks.", "published": "2021-06-04 09:22:24", "link": "http://arxiv.org/abs/2106.02363v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Approximate Fixed-Points in Recurrent Neural Networks", "abstract": "Recurrent neural networks are widely used in speech and language processing.\nDue to dependency on the past, standard algorithms for training these models,\nsuch as back-propagation through time (BPTT), cannot be efficiently\nparallelised. Furthermore, applying these models to more complex structures\nthan sequences requires inference time approximations, which introduce\ninconsistency between inference and training. This paper shows that recurrent\nneural networks can be reformulated as fixed-points of non-linear equation\nsystems. These fixed-points can be computed using an iterative algorithm\nexactly and in as many iterations as the length of any given sequence. Each\niteration of this algorithm adds one additional Markovian-like order of\ndependencies such that upon termination all dependencies modelled by the\nrecurrent neural networks have been incorporated. Although exact fixed-points\ninherit the same parallelization and inconsistency issues, this paper shows\nthat approximate fixed-points can be computed in parallel and used consistently\nin training and inference including tasks such as lattice rescoring.\nExperimental validation is performed in two tasks, Penn Tree Bank and\nWikiText-2, and shows that approximate fixed-points yield competitive\nprediction performance to recurrent neural networks trained using the BPTT\nalgorithm.", "published": "2021-06-04 11:33:34", "link": "http://arxiv.org/abs/2106.02417v1", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Language Model Metrics and Procrustes Analysis for Improved Vector\n  Transformation of NLP Embeddings", "abstract": "Artificial Neural networks are mathematical models at their core. This\ntruismpresents some fundamental difficulty when networks are tasked with\nNatural Language Processing. A key problem lies in measuring the similarity or\ndistance among vectors in NLP embedding space, since the mathematical concept\nof distance does not always agree with the linguistic concept. We suggest that\nthe best way to measure linguistic distance among vectors is by employing the\nLanguage Model (LM) that created them. We introduce Language Model Distance\n(LMD) for measuring accuracy of vector transformations based on the\nDistributional Hypothesis ( LMD Accuracy ). We show the efficacy of this metric\nby applying it to a simple neural network learning the Procrustes algorithm for\nbilingual word mapping.", "published": "2021-06-04 13:56:10", "link": "http://arxiv.org/abs/2106.02490v1", "categories": ["cs.CL", "cs.NE"], "primary_category": "cs.CL"}
{"title": "COINS: Dynamically Generating COntextualized Inference Rules for\n  Narrative Story Completion", "abstract": "Despite recent successes of large pre-trained language models in solving\nreasoning tasks, their inference capabilities remain opaque. We posit that such\nmodels can be made more interpretable by explicitly generating interim\ninference rules, and using them to guide the generation of task-specific\ntextual outputs. In this paper we present COINS, a recursive inference\nframework that i) iteratively reads context sentences, ii) dynamically\ngenerates contextualized inference rules, encodes them, and iii) uses them to\nguide task-specific output generation. We apply COINS to a Narrative Story\nCompletion task that asks a model to complete a story with missing sentences,\nto produce a coherent story with plausible logical connections, causal\nrelationships, and temporal dependencies. By modularizing inference and\nsentence generation steps in a recurrent model, we aim to make reasoning steps\nand their effects on next sentence generation transparent. Our automatic and\nmanual evaluations show that the model generates better story sentences than\nSOTA baselines, especially in terms of coherence. We further demonstrate\nimproved performance over strong pre-trained LMs in generating commonsense\ninference rules. The recursive nature of COINS holds the potential for\ncontrolled generation of longer sequences.", "published": "2021-06-04 14:06:33", "link": "http://arxiv.org/abs/2106.02497v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving Computer Generated Dialog with Auxiliary Loss Functions and\n  Custom Evaluation Metrics", "abstract": "Although people have the ability to engage in vapid dialogue without effort,\nthis may not be a uniquely human trait. Since the 1960's researchers have been\ntrying to create agents that can generate artificial conversation. These\nprograms are commonly known as chatbots. With increasing use of neural networks\nfor dialog generation, some conclude that this goal has been achieved. This\nresearch joins the quest by creating a dialog generating Recurrent Neural\nNetwork (RNN) and by enhancing the ability of this network with auxiliary loss\nfunctions and a beam search. Our custom loss functions achieve better cohesion\nand coherence by including calculations of Maximum Mutual Information (MMI) and\nentropy. We demonstrate the effectiveness of this system by using a set of\ncustom evaluation metrics inspired by an abundance of previous research and\nbased on tried-and-true principles of Natural Language Processing.", "published": "2021-06-04 14:35:05", "link": "http://arxiv.org/abs/2106.02516v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Do Syntactic Probes Probe Syntax? Experiments with Jabberwocky Probing", "abstract": "Analysing whether neural language models encode linguistic information has\nbecome popular in NLP. One method of doing so, which is frequently cited to\nsupport the claim that models like BERT encode syntax, is called probing;\nprobes are small supervised models trained to extract linguistic information\nfrom another model's output. If a probe is able to predict a particular\nstructure, it is argued that the model whose output it is trained on must have\nimplicitly learnt to encode it. However, drawing a generalisation about a\nmodel's linguistic knowledge about a specific phenomena based on what a probe\nis able to learn may be problematic: in this work, we show that semantic cues\nin training data means that syntactic probes do not properly isolate syntax. We\ngenerate a new corpus of semantically nonsensical but syntactically well-formed\nJabberwocky sentences, which we use to evaluate two probes trained on normal\ndata. We train the probes on several popular language models (BERT, GPT, and\nRoBERTa), and find that in all settings they perform worse when evaluated on\nthese data, for one probe by an average of 15.4 UUAS points absolute. Although\nin most cases they still outperform the baselines, their lead is reduced\nsubstantially, e.g. by 53% in the case of BERT for one probe. This begs the\nquestion: what empirical scores constitute knowing syntax?", "published": "2021-06-04 15:46:39", "link": "http://arxiv.org/abs/2106.02559v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Emergent Communication of Generalizations", "abstract": "To build agents that can collaborate effectively with others, recent research\nhas trained artificial agents to communicate with each other in Lewis-style\nreferential games. However, this often leads to successful but uninterpretable\ncommunication. We argue that this is due to the game objective: communicating\nabout a single object in a shared visual context is prone to overfitting and\ndoes not encourage language useful beyond concrete reference. In contrast,\nhuman language conveys a rich variety of abstract ideas. To promote such\nskills, we propose games that require communicating generalizations over sets\nof objects representing abstract visual concepts, optionally with separate\ncontexts for each agent. We find that these games greatly improve systematicity\nand interpretability of the learned languages, according to several metrics in\nthe literature. Finally, we propose a method for identifying logical operations\nembedded in the emergent languages by learning an approximate compositional\nreconstruction of the language.", "published": "2021-06-04 19:02:18", "link": "http://arxiv.org/abs/2106.02668v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The R-U-A-Robot Dataset: Helping Avoid Chatbot Deception by Detecting\n  User Questions About Human or Non-Human Identity", "abstract": "Humans are increasingly interacting with machines through language, sometimes\nin contexts where the user may not know they are talking to a machine (like\nover the phone or a text chatbot). We aim to understand how system designers\nand researchers might allow their systems to confirm its non-human identity. We\ncollect over 2,500 phrasings related to the intent of ``Are you a robot?\". This\nis paired with over 2,500 adversarially selected utterances where only\nconfirming the system is non-human would be insufficient or disfluent. We\ncompare classifiers to recognize the intent and discuss the precision/recall\nand model complexity tradeoffs. Such classifiers could be integrated into\ndialog systems to avoid undesired deception. We then explore how both a\ngenerative research model (Blender) as well as two deployed systems (Amazon\nAlexa, Google Assistant) handle this intent, finding that systems often fail to\nconfirm their non-human identity. Finally, we try to understand what a good\nresponse to the intent would be, and conduct a user study to compare the\nimportant aspects when responding to this intent.", "published": "2021-06-04 20:04:33", "link": "http://arxiv.org/abs/2106.02692v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Exposing the Implicit Energy Networks behind Masked Language Models via\n  Metropolis--Hastings", "abstract": "While recent work has shown that scores from models trained by the ubiquitous\nmasked language modeling (MLM) objective effectively discriminate probable from\nimprobable sequences, it is still an open question if these MLMs specify a\nprincipled probability distribution over the space of possible sequences. In\nthis paper, we interpret MLMs as energy-based sequence models and propose two\nenergy parametrizations derivable from the trained MLMs. In order to draw\nsamples correctly from these models, we develop a tractable sampling scheme\nbased on the Metropolis--Hastings Monte Carlo algorithm. In our approach,\nsamples are proposed from the same masked conditionals used for training the\nmasked language models, and they are accepted or rejected based on their energy\nvalues according to the target distribution. We validate the effectiveness of\nthe proposed parametrizations by exploring the quality of samples drawn from\nthese energy-based models for both open-ended unconditional generation and a\nconditional generation task of machine translation. We theoretically and\nempirically justify our sampling algorithm by showing that the masked\nconditionals on their own do not yield a Markov chain whose stationary\ndistribution is that of our target distribution, and our approach generates\nhigher quality samples than other recently proposed undirected generation\napproaches (Wang et al., 2019, Ghazvininejad et al., 2019).", "published": "2021-06-04 22:04:30", "link": "http://arxiv.org/abs/2106.02736v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Self-supervised Dialogue Learning for Spoken Conversational Question\n  Answering", "abstract": "In spoken conversational question answering (SCQA), the answer to the\ncorresponding question is generated by retrieving and then analyzing a fixed\nspoken document, including multi-part conversations. Most SCQA systems have\nconsidered only retrieving information from ordered utterances. However, the\nsequential order of dialogue is important to build a robust spoken\nconversational question answering system, and the changes of utterances order\nmay severely result in low-quality and incoherent corpora. To this end, we\nintroduce a self-supervised learning approach, including incoherence\ndiscrimination, insertion detection, and question prediction, to explicitly\ncapture the coreference resolution and dialogue coherence among spoken\ndocuments. Specifically, we design a joint learning framework where the\nauxiliary self-supervised tasks can enable the pre-trained SCQA systems towards\nmore coherent and meaningful spoken dialogue learning. We also utilize the\nproposed self-supervised learning tasks to capture intra-sentence coherence.\nExperimental results demonstrate that our proposed method provides more\ncoherent, meaningful, and appropriate responses, yielding superior performance\ngains compared to the original pre-trained language models. Our method achieves\nstate-of-the-art results on the Spoken-CoQA dataset.", "published": "2021-06-04 00:09:38", "link": "http://arxiv.org/abs/2106.02182v3", "categories": ["cs.CL", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Towards Equal Gender Representation in the Annotations of Toxic Language\n  Detection", "abstract": "Classifiers tend to propagate biases present in the data on which they are\ntrained. Hence, it is important to understand how the demographic identities of\nthe annotators of comments affect the fairness of the resulting model. In this\npaper, we focus on the differences in the ways men and women annotate comments\nfor toxicity, investigating how these differences result in models that amplify\nthe opinions of male annotators. We find that the BERT model as-sociates toxic\ncomments containing offensive words with male annotators, causing the model to\npredict 67.7% of toxic comments as having been annotated by men. We show that\nthis disparity between gender predictions can be mitigated by removing\noffensive words and highly toxic comments from the training data. We then apply\nthe learned associations between gender and language to toxic language\nclassifiers, finding that models trained exclusively on female-annotated data\nperform 1.8% better than those trained solely on male-annotated data and that\ntraining models on data after removing all offensive words reduces bias in the\nmodel by 55.5% while increasing the sensitivity by 0.4%.", "published": "2021-06-04 00:12:38", "link": "http://arxiv.org/abs/2106.02183v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "How Good Is NLP? A Sober Look at NLP Tasks through the Lens of Social\n  Impact", "abstract": "Recent years have seen many breakthroughs in natural language processing\n(NLP), transitioning it from a mostly theoretical field to one with many\nreal-world applications. Noting the rising number of applications of other\nmachine learning and AI techniques with pervasive societal impact, we\nanticipate the rising importance of developing NLP technologies for social\ngood. Inspired by theories in moral philosophy and global priorities research,\nwe aim to promote a guideline for social good in the context of NLP. We lay the\nfoundations via the moral philosophy definition of social good, propose a\nframework to evaluate the direct and indirect real-world impact of NLP tasks,\nand adopt the methodology of global priorities research to identify priority\ncauses for NLP research. Finally, we use our theoretical framework to provide\nsome practical guidelines for future NLP research for social good. Our data and\ncode are available at http://github.com/zhijing-jin/nlp4sg_acl2021. In\naddition, we curate a list of papers and resources on NLP for social good at\nhttps://github.com/zhijing-jin/NLP4SocialGood_Papers.", "published": "2021-06-04 09:17:15", "link": "http://arxiv.org/abs/2106.02359v3", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Entity Concept-enhanced Few-shot Relation Extraction", "abstract": "Few-shot relation extraction (FSRE) is of great importance in long-tail\ndistribution problem, especially in special domain with low-resource data. Most\nexisting FSRE algorithms fail to accurately classify the relations merely based\non the information of the sentences together with the recognized entity pairs,\ndue to limited samples and lack of knowledge. To address this problem, in this\npaper, we proposed a novel entity CONCEPT-enhanced FEw-shot Relation Extraction\nscheme (ConceptFERE), which introduces the inherent concepts of entities to\nprovide clues for relation prediction and boost the relations classification\nperformance. Firstly, a concept-sentence attention module is developed to\nselect the most appropriate concept from multiple concepts of each entity by\ncalculating the semantic similarity between sentences and concepts. Secondly, a\nself-attention based fusion module is presented to bridge the gap of concept\nembedding and sentence embedding from different semantic spaces. Extensive\nexperiments on the FSRE benchmark dataset FewRel have demonstrated the\neffectiveness and the superiority of the proposed ConceptFERE scheme as\ncompared to the state-of-the-art baselines. Code is available at\nhttps://github.com/LittleGuoKe/ConceptFERE.", "published": "2021-06-04 10:36:49", "link": "http://arxiv.org/abs/2106.02401v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Teaching keyword spotters to spot new keywords with limited examples", "abstract": "Learning to recognize new keywords with just a few examples is essential for\npersonalizing keyword spotting (KWS) models to a user's choice of keywords.\nHowever, modern KWS models are typically trained on large datasets and\nrestricted to a small vocabulary of keywords, limiting their transferability to\na broad range of unseen keywords. Towards easily customizable KWS models, we\npresent KeySEM (Keyword Speech EMbedding), a speech embedding model pre-trained\non the task of recognizing a large number of keywords. Speech representations\noffered by KeySEM are highly effective for learning new keywords from a limited\nnumber of examples. Comparisons with a diverse range of related work across\nseveral datasets show that our method achieves consistently superior\nperformance with fewer training examples. Although KeySEM was pre-trained only\non English utterances, the performance gains also extend to datasets from four\nother languages indicating that KeySEM learns useful representations well\naligned with the task of keyword spotting. Finally, we demonstrate KeySEM's\nability to learn new keywords sequentially without requiring to re-train on\npreviously learned keywords. Our experimental observations suggest that KeySEM\nis well suited to on-device environments where post-deployment learning and\nease of customization are often desirable.", "published": "2021-06-04 12:43:36", "link": "http://arxiv.org/abs/2106.02443v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "CLIP: A Dataset for Extracting Action Items for Physicians from Hospital\n  Discharge Notes", "abstract": "Continuity of care is crucial to ensuring positive health outcomes for\npatients discharged from an inpatient hospital setting, and improved\ninformation sharing can help. To share information, caregivers write discharge\nnotes containing action items to share with patients and their future\ncaregivers, but these action items are easily lost due to the lengthiness of\nthe documents. In this work, we describe our creation of a dataset of clinical\naction items annotated over MIMIC-III, the largest publicly available dataset\nof real clinical notes. This dataset, which we call CLIP, is annotated by\nphysicians and covers 718 documents representing 100K sentences. We describe\nthe task of extracting the action items from these documents as multi-aspect\nextractive summarization, with each aspect representing a type of action to be\ntaken. We evaluate several machine learning models on this task, and show that\nthe best models exploit in-domain language model pre-training on 59K\nunannotated documents, and incorporate context from neighboring sentences. We\nalso propose an approach to pre-training data selection that allows us to\nexplore the trade-off between size and domain-specificity of pre-training\ndatasets for this task.", "published": "2021-06-04 14:49:02", "link": "http://arxiv.org/abs/2106.02524v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Understanding and Countering Stereotypes: A Computational Approach to\n  the Stereotype Content Model", "abstract": "Stereotypical language expresses widely-held beliefs about different social\ncategories. Many stereotypes are overtly negative, while others may appear\npositive on the surface, but still lead to negative consequences. In this work,\nwe present a computational approach to interpreting stereotypes in text through\nthe Stereotype Content Model (SCM), a comprehensive causal theory from social\npsychology. The SCM proposes that stereotypes can be understood along two\nprimary dimensions: warmth and competence. We present a method for defining\nwarmth and competence axes in semantic embedding space, and show that the four\nquadrants defined by this subspace accurately represent the warmth and\ncompetence concepts, according to annotated lexicons. We then apply our\ncomputational SCM model to textual stereotype data and show that it compares\nfavourably with survey-based studies in the psychological literature.\nFurthermore, we explore various strategies to counter stereotypical beliefs\nwith anti-stereotypes. It is known that countering stereotypes with\nanti-stereotypical examples is one of the most effective ways to reduce biased\nthinking, yet the problem of generating anti-stereotypes has not been\npreviously studied. Thus, a better understanding of how to generate realistic\nand effective anti-stereotypes can contribute to addressing pressing societal\nconcerns of stereotyping, prejudice, and discrimination.", "published": "2021-06-04 16:53:37", "link": "http://arxiv.org/abs/2106.02596v1", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "MERLOT: Multimodal Neural Script Knowledge Models", "abstract": "As humans, we understand events in the visual world contextually, performing\nmultimodal reasoning across time to make inferences about the past, present,\nand future. We introduce MERLOT, a model that learns multimodal script\nknowledge by watching millions of YouTube videos with transcribed speech -- in\nan entirely label-free, self-supervised manner. By pretraining with a mix of\nboth frame-level (spatial) and video-level (temporal) objectives, our model not\nonly learns to match images to temporally corresponding words, but also to\ncontextualize what is happening globally over time. As a result, MERLOT\nexhibits strong out-of-the-box representations of temporal commonsense, and\nachieves state-of-the-art performance on 12 different video QA datasets when\nfinetuned. It also transfers well to the world of static images, allowing\nmodels to reason about the dynamic context behind visual scenes. On Visual\nCommonsense Reasoning, MERLOT answers questions correctly with 80.6% accuracy,\noutperforming state-of-the-art models of similar size by over 3%, even those\nthat make heavy use of auxiliary supervised data (like object bounding boxes).\n  Ablation analyses demonstrate the complementary importance of: 1) training on\nvideos versus static images; 2) scaling the magnitude and diversity of the\npretraining video corpus; and 3) using diverse objectives that encourage\nfull-stack multimodal reasoning, from the recognition to cognition level.", "published": "2021-06-04 17:57:39", "link": "http://arxiv.org/abs/2106.02636v3", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "W-RST: Towards a Weighted RST-style Discourse Framework", "abstract": "Aiming for a better integration of data-driven and linguistically-inspired\napproaches, we explore whether RST Nuclearity, assigning a binary assessment of\nimportance between text segments, can be replaced by automatically generated,\nreal-valued scores, in what we call a Weighted-RST framework. In particular, we\nfind that weighted discourse trees from auxiliary tasks can benefit key NLP\ndownstream applications, compared to nuclearity-centered approaches. We further\nshow that real-valued importance distributions partially and interestingly\nalign with the assessment and uncertainty of human annotators.", "published": "2021-06-04 18:12:09", "link": "http://arxiv.org/abs/2106.02658v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Layered gradient accumulation and modular pipeline parallelism: fast and\n  efficient training of large language models", "abstract": "The advent of the transformer has sparked a quick growth in the size of\nlanguage models, far outpacing hardware improvements. (Dense) transformers are\nexpected to reach the trillion-parameter scale in the near future, for which\ntraining requires thousands or even tens of thousands of GPUs. We investigate\nthe challenges of training at this scale and beyond on commercially available\nhardware. In particular, we analyse the shortest possible training time for\ndifferent configurations of distributed training, leveraging empirical scaling\nlaws for language models to estimate the optimal (critical) batch size.\nContrary to popular belief, we find no evidence for a memory wall, and instead\nargue that the real limitation -- other than the cost -- lies in the training\nduration.\n  In addition to this analysis, we introduce two new methods, \\textit{layered\ngradient accumulation} and \\textit{modular pipeline parallelism}, which\ntogether cut the shortest training time by half. The methods also reduce data\nmovement, lowering the network requirement to a point where a fast InfiniBand\nconnection is not necessary. This increased network efficiency also improve on\nthe methods introduced with the ZeRO optimizer, reducing the memory usage to a\ntiny fraction of the available GPU memory.", "published": "2021-06-04 19:21:49", "link": "http://arxiv.org/abs/2106.02679v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Cognitive-aware Short-text Understanding for Inferring Professions", "abstract": "Leveraging short-text contents to estimate the occupation of microblog\nauthors has significant gains in many applications. Yet challenges abound.\nFirstly brief textual contents come with excessive lexical noise that makes the\ninference problem challenging. Secondly, cognitive-semantics are not evident,\nand important linguistic features are latent in short-text contents. Thirdly,\nit is hard to measure the correlation between the cognitive short-text\nsemantics and the features pertaining various occupations. We argue that the\nmulti-aspect cognitive features are needed to correctly associate short-text\ncontents to a particular job and discover suitable people for the careers. To\nthis end, we devise a novel framework that on the one hand, can infer\nshort-text contents and exploit cognitive features, and on the other hand,\nfuses various adopted novel algorithms, such as curve fitting, support vector,\nand boosting modules to better predict the occupation of the authors. The final\nestimation module manufactures the $R^w$-tree via coherence weight to tune the\nbest outcome in the inferring process. We conduct comprehensive experiments on\nreal-life Twitter data. The experimental results show that compared to other\nrivals, our cognitive multi-aspect model can achieve a higher performance in\nthe career estimation procedure, where it is inevitable to neglect the\ncontextual semantics of users.", "published": "2021-06-04 13:19:16", "link": "http://arxiv.org/abs/2106.07363v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Understanding the Dynamics between Vaping and Cannabis Legalization\n  Using Twitter Opinions", "abstract": "Cannabis legalization has been welcomed by many U.S. states but its role in\nescalation from tobacco e-cigarette use to cannabis vaping is unclear.\nMeanwhile, cannabis vaping has been associated with new lung diseases and\nrising adolescent use. To understand the impact of cannabis legalization on\nescalation, we design an observational study to estimate the causal effect of\nrecreational cannabis legalization on the development of pro-cannabis attitude\nfor e-cigarette users. We collect and analyze Twitter data which contains\nopinions about cannabis and JUUL, a very popular e-cigarette brand. We use\nweakly supervised learning for personal tweet filtering and classification for\nstance detection. We discover that recreational cannabis legalization policy\nhas an effect on increased development of pro-cannabis attitudes for users\nalready in favor of e-cigarettes.", "published": "2021-06-04 15:34:20", "link": "http://arxiv.org/abs/2106.11029v1", "categories": ["cs.CY", "cs.CL", "cs.LG", "cs.SI"], "primary_category": "cs.CY"}
{"title": "Minimum Word Error Rate Training with Language Model Fusion for\n  End-to-End Speech Recognition", "abstract": "Integrating external language models (LMs) into end-to-end (E2E) models\nremains a challenging task for domain-adaptive speech recognition. Recently,\ninternal language model estimation (ILME)-based LM fusion has shown significant\nword error rate (WER) reduction from Shallow Fusion by subtracting a weighted\ninternal LM score from an interpolation of E2E model and external LM scores\nduring beam search. However, on different test sets, the optimal LM\ninterpolation weights vary over a wide range and have to be tuned extensively\non well-matched validation sets. In this work, we perform LM fusion in the\nminimum WER (MWER) training of an E2E model to obviate the need for LM weights\ntuning during inference. Besides MWER training with Shallow Fusion (MWER-SF),\nwe propose a novel MWER training with ILME (MWER-ILME) where the ILME-based\nfusion is conducted to generate N-best hypotheses and their posteriors.\nAdditional gradient is induced when internal LM is engaged in MWER-ILME loss\ncomputation. During inference, LM weights pre-determined in MWER training\nenable robust LM integrations on test sets from different domains. Experimented\nwith 30K-hour trained transformer transducers, MWER-ILME achieves on average\n8.8% and 5.8% relative WER reductions from MWER and MWER-SF training,\nrespectively, on 6 different test sets", "published": "2021-06-04 07:24:49", "link": "http://arxiv.org/abs/2106.02302v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "On Classifying Continuous Constraint Satisfaction Problems", "abstract": "A continuous constraint satisfaction problem (CCSP) is a constraint\nsatisfaction problem (CSP) with an interval domain $U \\subset \\mathbb{R}$. We\nengage in a systematic study to classify CCSPs that are complete of the\nExistential Theory of the Reals, i.e., ER-complete. To define this class, we\nfirst consider the problem ETR, which also stands for Existential Theory of the\nReals. In an instance of this problem we are given some sentence of the form\n$\\exists x_1, \\ldots, x_n \\in \\mathbb{R} : \\Phi(x_1, \\ldots, x_n)$, where\n$\\Phi$ is a well-formed quantifier-free formula consisting of the symbols $\\{0,\n1, +, \\cdot, \\geq, >, \\wedge, \\vee, \\neg\\}$, the goal is to check whether this\nsentence is true. Now the class ER is the family of all problems that admit a\npolynomial-time many-one reduction to ETR. It is known that NP $\\subseteq$ ER\n$\\subseteq$ PSPACE.\n  We restrict our attention on CCSPs with addition constraints ($x + y = z$)\nand some other mild technical conditions. Previously, it was shown that\nmultiplication constraints ($x \\cdot y = z$), squaring constraints ($x^2 = y$),\nor inversion constraints ($x\\cdot y = 1$) are sufficient to establish\nER-completeness. We extend this in the strongest possible sense for equality\nconstraints as follows. We show that CCSPs (with addition constraints and some\nother mild technical conditions) that have any one well-behaved curved equality\nconstraint ($f(x,y) = 0$) are ER-complete. We further extend our results to\ninequality constraints. We show that any well-behaved convexly curved and any\nwell-behaved concavely curved inequality constraint ($f(x,y) \\geq 0$ and\n$g(x,y) \\geq 0$) imply ER-completeness on the class of such CCSPs.", "published": "2021-06-04 10:23:48", "link": "http://arxiv.org/abs/2106.02397v6", "categories": ["cs.CC", "cs.CG", "cs.CL", "cs.DM", "cs.DS"], "primary_category": "cs.CC"}
{"title": "MexPub: Deep Transfer Learning for Metadata Extraction from German\n  Publications", "abstract": "Extracting metadata from scientific papers can be considered a solved problem\nin NLP due to the high accuracy of state-of-the-art methods. However, this does\nnot apply to German scientific publications, which have a variety of styles and\nlayouts. In contrast to most of the English scientific publications that follow\nstandard and simple layouts, the order, content, position and size of metadata\nin German publications vary greatly among publications. This variety makes\ntraditional NLP methods fail to accurately extract metadata from these\npublications. In this paper, we present a method that extracts metadata from\nPDF documents with different layouts and styles by viewing the document as an\nimage. We used Mask R-CNN that is trained on COCO dataset and finetuned with\nPubLayNet dataset that consists of ~200K PDF snapshots with five basic classes\n(e.g. text, figure, etc). We refine-tuned the model on our proposed synthetic\ndataset consisting of ~30K article snapshots to extract nine patterns (i.e.\nauthor, title, etc). Our synthetic dataset is generated using contents in both\nlanguages German and English and a finite set of challenging templates obtained\nfrom German publications. Our method achieved an average accuracy of around\n$90\\%$ which validates its capability to accurately extract metadata from a\nvariety of PDF documents with challenging templates.", "published": "2021-06-04 09:43:48", "link": "http://arxiv.org/abs/2106.07359v1", "categories": ["cs.IR", "cs.CL", "cs.CV", "cs.DL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "ToyADMOS2: Another dataset of miniature-machine operating sounds for\n  anomalous sound detection under domain shift conditions", "abstract": "This paper proposes a new large-scale dataset called \"ToyADMOS2\" for anomaly\ndetection in machine operating sounds (ADMOS). As did for our previous ToyADMOS\ndataset, we collected a large number of operating sounds of miniature machines\n(toys) under normal and anomaly conditions by deliberately damaging them but\nextended with providing controlled depth of damages in anomaly samples. Since\ntypical application scenarios of ADMOS often require robust performance under\ndomain-shift conditions, the ToyADMOS2 dataset is designed for evaluating\nsystems under such conditions. The released dataset consists of two\nsub-datasets for machine-condition inspection: fault diagnosis of machines with\ngeometrically fixed tasks and fault diagnosis of machines with moving tasks.\nDomain shifts are represented by introducing several differences in operating\nconditions, such as the use of the same machine type but with different machine\nmodels and parts configurations, different operating speeds, microphone\narrangements, etc. Each sub-dataset contains over 27 k samples of normal\nmachine-operating sounds and over 8 k samples of anomalous sounds recorded with\nfive to eight microphones. The dataset is freely available for download at\nhttps://github.com/nttcslab/ToyADMOS2-dataset and\nhttps://doi.org/10.5281/zenodo.4580270.", "published": "2021-06-04 09:32:14", "link": "http://arxiv.org/abs/2106.02369v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Fre-GAN: Adversarial Frequency-consistent Audio Synthesis", "abstract": "Although recent works on neural vocoder have improved the quality of\nsynthesized audio, there still exists a gap between generated and ground-truth\naudio in frequency space. This difference leads to spectral artifacts such as\nhissing noise or reverberation, and thus degrades the sample quality. In this\npaper, we propose Fre-GAN which achieves frequency-consistent audio synthesis\nwith highly improved generation quality. Specifically, we first present\nresolution-connected generator and resolution-wise discriminators, which help\nlearn various scales of spectral distributions over multiple frequency bands.\nAdditionally, to reproduce high-frequency components accurately, we leverage\ndiscrete wavelet transform in the discriminators. From our experiments, Fre-GAN\nachieves high-fidelity waveform generation with a gap of only 0.03 MOS compared\nto ground-truth audio while outperforming standard models in quality.", "published": "2021-06-04 07:12:39", "link": "http://arxiv.org/abs/2106.02297v2", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Manifold-Aware Deep Clustering: Maximizing Angles between Embedding\n  Vectors Based on Regular Simplex", "abstract": "This paper presents a new deep clustering (DC) method called manifold-aware\nDC (M-DC) that can enhance hyperspace utilization more effectively than the\noriginal DC. The original DC has a limitation in that a pair of two speakers\nhas to be embedded having an orthogonal relationship due to its use of the\none-hot vector-based loss function, while our method derives a unique loss\nfunction aimed at maximizing the target angle in the hyperspace based on the\nnature of a regular simplex. Our proposed loss imposes a higher penalty than\nthe original DC when the speaker is assigned incorrectly. The change from DC to\nM-DC can be easily achieved by rewriting just one term in the loss function of\nDC, without any other modifications to the network architecture or model\nparameters. As such, our method has high practicability because it does not\naffect the original inference part. The experimental results show that the\nproposed method improves the performances of the original DC and its expansion\nmethod.", "published": "2021-06-04 08:27:01", "link": "http://arxiv.org/abs/2106.02331v3", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "A Residual Network based Deep Learning Model for Detection of COVID-19\n  from Cough Sounds", "abstract": "The present work proposes a deep-learning-based approach for the\nclassification of COVID-19 coughs from non-COVID-19 coughs and that can be used\nas a low-resource-based tool for early detection of the onset of such\nrespiratory diseases. The proposed system uses the ResNet-50 architecture, a\npopularly known Convolutional Neural Network (CNN) for image recognition tasks,\nfed with the log-Mel spectrums of the audio data to discriminate between the\ntwo types of coughs. For the training and validation of the proposed deep\nlearning model, this work utilizes the Track-1 dataset provided by the DiCOVA\nChallenge 2021 organizers. Additionally, to increase the number of\nCOVID-positive samples and to enhance variability in the training data, it has\nalso utilized a large open-source database of COVID-19 coughs collected by the\nEPFL CoughVid team. Our developed model has achieved an average validation AUC\nof 98.88%. Also, applying this model on the Blind Test Set released by the\nDiCOVA Challenge, the system has achieved a Test AUC of 75.91%, Test\nSpecificity of 62.50%, and Test Sensitivity of 80.49%. Consequently, this\nsubmission has secured 16th position in the DiCOVA Challenge 2021 leader-board.", "published": "2021-06-04 08:59:27", "link": "http://arxiv.org/abs/2106.02348v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Classification of Audio Segments in Call Center Recordings using\n  Convolutional Recurrent Neural Networks", "abstract": "Detailed statistical analysis of call center recordings is critical in the\ncustomer relationship management point of view. With the recent advances in\nartificial intelligence, many tasks regarding the calculation of call\nstatistics are now performed automatically. This work proposes a neural network\nframework where the aim is to correctly identify audio segments and classify\nthem as either customer or agent sections. Accurately identifying these\nsections gives a fair metric for evaluating agents' performances. We inherited\nthe convolutional recurrent neural network (CRNN) architecture commonly used\nfor such problems as music genre classification. We also tested the same\narchitecture's performance, where the previous class information and the gender\ninformation of speakers are also added to the training data labels. We saw that\nCRNN could generalize the training data and perform well on validation data for\nthis problem with and without the gender information. Moreover, even the\ntraining was performed using Turkish speech samples; the trained network was\nproven to achieve high accuracy for call center recordings in other languages\nlike German and English.", "published": "2021-06-04 11:53:48", "link": "http://arxiv.org/abs/2106.02422v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A Database for Research on Detection and Enhancement of Speech\n  Transmitted over HF links", "abstract": "In this paper we present an open database for the development of detection\nand enhancement algorithms of speech transmitted over HF radio channels. It\nconsists of audio samples recorded by various receivers at different locations\nacross Europe, all monitoring the same single-sideband modulated transmission\nfrom a base station in Paderborn, Germany. Transmitted and received speech\nsignals are precisely time aligned to offer parallel data for supervised\ntraining of deep learning based detection and enhancement algorithms. For the\ntask of speech activity detection two exemplary baseline systems are presented,\none based on statistical methods employing a multi-stage Wiener filter with\nminimum statistics noise floor estimation, and the other relying on a deep\nlearning approach.", "published": "2021-06-04 13:17:51", "link": "http://arxiv.org/abs/2106.02472v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Do You Listen with One or Two Microphones? A Unified ASR Model for\n  Single and Multi-Channel Audio", "abstract": "Automatic speech recognition (ASR) models are typically designed to operate\non a single input data type, e.g. a single or multi-channel audio streamed from\na device. This design decision assumes the primary input data source does not\nchange and if an additional (auxiliary) data source is occasionally available,\nit cannot be used. An ASR model that operates on both primary and auxiliary\ndata can achieve better accuracy compared to a primary-only solution; and a\nmodel that can serve both primary-only (PO) and primary-plus-auxiliary (PPA)\nmodes is highly desirable. In this work, we propose a unified ASR model that\ncan serve both modes. We demonstrate its efficacy in a realistic scenario where\na set of devices typically stream a single primary audio channel, and two\nadditional auxiliary channels only when upload bandwidth allows it. The\narchitecture enables a unique methodology that uses both types of input audio\nduring training time. Our proposed approach achieves up to 12.5% relative\nword-error-rate reduction (WERR) compared to a PO baseline, and up to 16.0%\nrelative WERR in low-SNR conditions. The unique training methodology achieves\nup to 2.5% relative WERR compared to a PPA baseline.", "published": "2021-06-04 22:58:42", "link": "http://arxiv.org/abs/2106.02750v2", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "A Novel Semi-supervised Framework for Call Center Agent Malpractice\n  Detection via Neural Feature Learning", "abstract": "This work presents a practical solution to the problem of call center agent\nmalpractice. A semi-supervised framework comprising of non-linear power\ntransformation, neural feature learning and k-means clustering is outlined. We\nput these building blocks together and tune the parameters so that the best\nperformance was obtained. The data used in the experiments is obtained from our\nin-house call center. It is made up of recorded agent-customer conversations\nwhich have been annotated using a convolutional neural network based segmenter.\nThe methods provided a means of tuning the parameters of the neural network to\nachieve a desirable result. We show that, using our proposed framework, it is\npossible to significantly reduce the malpractice classification error of a\nk-means-only clustering model which would serve the same purpose. Additionally,\nby presenting the amount of silence per call as a key performance indicator, we\nshow that the proposed system has enhanced agents performance at our call\ncenter since deployment.", "published": "2021-06-04 12:16:40", "link": "http://arxiv.org/abs/2106.02433v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Musical Prosody-Driven Emotion Classification: Interpreting Vocalists\n  Portrayal of Emotions Through Machine Learning", "abstract": "The task of classifying emotions within a musical track has received\nwidespread attention within the Music Information Retrieval (MIR) community.\nMusic emotion recognition has traditionally relied on the use of acoustic\nfeatures, verbal features, and metadata-based filtering. The role of musical\nprosody remains under-explored despite several studies demonstrating a strong\nconnection between prosody and emotion. In this study, we restrict the input of\ntraditional machine learning algorithms to the features of musical prosody.\nFurthermore, our proposed approach builds upon the prior by classifying\nemotions under an expanded emotional taxonomy, using the Geneva Wheel of\nEmotion. We utilize a methodology for individual data collection from\nvocalists, and personal ground truth labeling by the artist themselves. We\nfound that traditional machine learning algorithms when limited to the features\nof musical prosody (1) achieve high accuracies for a single singer, (2)\nmaintain high accuracy when the dataset is expanded to multiple singers, and\n(3) achieve high accuracies when trained on a reduced subset of the total\nfeatures.", "published": "2021-06-04 15:40:19", "link": "http://arxiv.org/abs/2106.02556v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
