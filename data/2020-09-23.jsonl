{"title": "Exploiting Vietnamese Social Media Characteristics for Textual Emotion\n  Recognition in Vietnamese", "abstract": "Textual emotion recognition has been a promising research topic in recent\nyears. Many researchers aim to build more accurate and robust emotion detection\nsystems. In this paper, we conduct several experiments to indicate how data\npre-processing affects a machine learning method on textual emotion\nrecognition. These experiments are performed on the Vietnamese Social Media\nEmotion Corpus (UIT-VSMEC) as the benchmark dataset. We explore Vietnamese\nsocial media characteristics to propose different pre-processing techniques,\nand key-clause extraction with emotional context to improve the machine\nperformance on UIT-VSMEC. Our experimental evaluation shows that with\nappropriate pre-processing techniques based on Vietnamese social media\ncharacteristics, Multinomial Logistic Regression (MLR) achieves the best\nF1-score of 64.40%, a significant improvement of 4.66% over the CNN model built\nby the authors of UIT-VSMEC (59.74%).", "published": "2020-09-23 08:49:39", "link": "http://arxiv.org/abs/2009.11005v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Struggles of Feature-Based Explanations: Shapley Values vs. Minimal\n  Sufficient Subsets", "abstract": "For neural models to garner widespread public trust and ensure fairness, we\nmust have human-intelligible explanations for their predictions. Recently, an\nincreasing number of works focus on explaining the predictions of neural models\nin terms of the relevance of the input features. In this work, we show that\nfeature-based explanations pose problems even for explaining trivial models. We\nshow that, in certain cases, there exist at least two ground-truth\nfeature-based explanations, and that, sometimes, neither of them is enough to\nprovide a complete view of the decision-making process of the model. Moreover,\nwe show that two popular classes of explainers, Shapley explainers and minimal\nsufficient subsets explainers, target fundamentally different types of\nground-truth explanations, despite the apparently implicit assumption that\nexplainers should look for one specific feature-based explanation. These\nfindings bring an additional dimension to consider in both developing and\nchoosing explainers.", "published": "2020-09-23 09:45:23", "link": "http://arxiv.org/abs/2009.11023v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KoBE: Knowledge-Based Machine Translation Evaluation", "abstract": "We propose a simple and effective method for machine translation evaluation\nwhich does not require reference translations. Our approach is based on (1)\ngrounding the entity mentions found in each source sentence and candidate\ntranslation against a large-scale multilingual knowledge base, and (2)\nmeasuring the recall of the grounded entities found in the candidate vs. those\nfound in the source. Our approach achieves the highest correlation with human\njudgements on 9 out of the 18 language pairs from the WMT19 benchmark for\nevaluation without references, which is the largest number of wins for a single\nevaluation method on this task. On 4 language pairs, we also achieve higher\ncorrelation with human judgements than BLEU. To foster further research, we\nrelease a dataset containing 1.8 million grounded entity mentions across 18\nlanguage pairs from the WMT19 metrics track data.", "published": "2020-09-23 09:52:28", "link": "http://arxiv.org/abs/2009.11027v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Streamlining Cross-Document Coreference Resolution: Evaluation and\n  Modeling", "abstract": "Recent evaluation protocols for Cross-document (CD) coreference resolution\nhave often been inconsistent or lenient, leading to incomparable results across\nworks and overestimation of performance. To facilitate proper future research\non this task, our primary contribution is proposing a pragmatic evaluation\nmethodology which assumes access to only raw text -- rather than assuming gold\nmentions, disregards singleton prediction, and addresses typical targeted\nsettings in CD coreference resolution. Aiming to set baseline results for\nfuture research that would follow our evaluation methodology, we build the\nfirst end-to-end model for this task. Our model adapts and extends recent\nneural models for within-document coreference resolution to address the CD\ncoreference setting, which outperforms state-of-the-art results by a\nsignificant margin.", "published": "2020-09-23 10:02:10", "link": "http://arxiv.org/abs/2009.11032v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Seq2Edits: Sequence Transduction Using Span-level Edit Operations", "abstract": "We propose Seq2Edits, an open-vocabulary approach to sequence editing for\nnatural language processing (NLP) tasks with a high degree of overlap between\ninput and output texts. In this approach, each sequence-to-sequence\ntransduction is represented as a sequence of edit operations, where each\noperation either replaces an entire source span with target tokens or keeps it\nunchanged. We evaluate our method on five NLP tasks (text normalization,\nsentence fusion, sentence splitting & rephrasing, text simplification, and\ngrammatical error correction) and report competitive results across the board.\nFor grammatical error correction, our method speeds up inference by up to 5.2x\ncompared to full sequence models because inference time depends on the number\nof edits rather than the number of target tokens. For text normalization,\nsentence fusion, and grammatical error correction, our approach improves\nexplainability by associating each edit operation with a human-readable tag.", "published": "2020-09-23 13:28:38", "link": "http://arxiv.org/abs/2009.11136v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evolution of Part-of-Speech in Classical Chinese", "abstract": "Classical Chinese is a language notable for its word class flexibility: the\nsame word may often be used as a noun or a verb. Bisang (2008) claimed that\nClassical Chinese is a precategorical language, where the syntactic position of\na word determines its part-of-speech category. In this paper, we apply\nentropy-based metrics to evaluate these claims on historical corpora. We\nfurther explore differences between nouns and verbs in Classical Chinese: using\npsycholinguistic norms, we find a positive correlation between concreteness and\nnoun usage. Finally, we align character embeddings from Classical and Modern\nChinese, and find that verbs undergo more semantic change than nouns.", "published": "2020-09-23 13:41:27", "link": "http://arxiv.org/abs/2009.11144v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Harnessing Multilinguality in Unsupervised Machine Translation for Rare\n  Languages", "abstract": "Unsupervised translation has reached impressive performance on resource-rich\nlanguage pairs such as English-French and English-German. However, early\nstudies have shown that in more realistic settings involving low-resource, rare\nlanguages, unsupervised translation performs poorly, achieving less than 3.0\nBLEU. In this work, we show that multilinguality is critical to making\nunsupervised systems practical for low-resource settings. In particular, we\npresent a single model for 5 low-resource languages (Gujarati, Kazakh, Nepali,\nSinhala, and Turkish) to and from English directions, which leverages\nmonolingual and auxiliary parallel data from other high-resource language pairs\nvia a three-stage training scheme. We outperform all current state-of-the-art\nunsupervised baselines for these languages, achieving gains of up to 14.4 BLEU.\nAdditionally, we outperform a large collection of supervised WMT submissions\nfor various language pairs as well as match the performance of the current\nstate-of-the-art supervised model for Nepali-English. We conduct a series of\nablation studies to establish the robustness of our model under different\ndegrees of data quality, as well as to analyze the factors which led to the\nsuperior performance of the proposed approach over traditional unsupervised\nmodels.", "published": "2020-09-23 15:07:33", "link": "http://arxiv.org/abs/2009.11201v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Token-wise CNN-based Method for Sentence Compression", "abstract": "Sentence compression is a Natural Language Processing (NLP) task aimed at\nshortening original sentences and preserving their key information. Its\napplications can benefit many fields e.g. one can build tools for language\neducation. However, current methods are largely based on Recurrent Neural\nNetwork (RNN) models which suffer from poor processing speed. To address this\nissue, in this paper, we propose a token-wise Convolutional Neural Network, a\nCNN-based model along with pre-trained Bidirectional Encoder Representations\nfrom Transformers (BERT) features for deletion-based sentence compression. We\nalso compare our model with RNN-based models and fine-tuned BERT. Although one\nof the RNN-based models outperforms marginally other models given the same\ninput, our CNN-based model was ten times faster than the RNN-based approach.", "published": "2020-09-23 17:12:06", "link": "http://arxiv.org/abs/2009.11260v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Dialog Evaluation with a Multi-reference Adversarial Dataset\n  and Large Scale Pretraining", "abstract": "There is an increasing focus on model-based dialog evaluation metrics such as\nADEM, RUBER, and the more recent BERT-based metrics. These models aim to assign\na high score to all relevant responses and a low score to all irrelevant\nresponses. Ideally, such models should be trained using multiple relevant and\nirrelevant responses for any given context. However, no such data is publicly\navailable, and hence existing models are usually trained using a single\nrelevant response and multiple randomly selected responses from other contexts\n(random negatives). To allow for better training and robust evaluation of\nmodel-based metrics, we introduce the DailyDialog++ dataset, consisting of (i)\nfive relevant responses for each context and (ii) five adversarially crafted\nirrelevant responses for each context. Using this dataset, we first show that\neven in the presence of multiple correct references, n-gram based metrics and\nembedding based metrics do not perform well at separating relevant responses\nfrom even random negatives. While model-based metrics perform better than\nn-gram and embedding based metrics on random negatives, their performance drops\nsubstantially when evaluated on adversarial examples. To check if large scale\npretraining could help, we propose a new BERT-based evaluation metric called\nDEB, which is pretrained on 727M Reddit conversations and then finetuned on our\ndataset. DEB significantly outperforms existing models, showing better\ncorrelation with human judgements and better performance on random negatives\n(88.27% accuracy). However, its performance again drops substantially, when\nevaluated on adversarial responses, thereby highlighting that even large-scale\npretrained evaluation models are not robust to the adversarial examples in our\ndataset. The dataset and code are publicly available.", "published": "2020-09-23 18:06:52", "link": "http://arxiv.org/abs/2009.11321v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The importance of fillers for text representations of speech transcripts", "abstract": "While being an essential component of spoken language, fillers (e.g.\"um\" or\n\"uh\") often remain overlooked in Spoken Language Understanding (SLU) tasks. We\nexplore the possibility of representing them with deep contextualised\nembeddings, showing improvements on modelling spoken language and two\ndownstream tasks - predicting a speaker's stance and expressed confidence.", "published": "2020-09-23 19:03:58", "link": "http://arxiv.org/abs/2009.11340v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Pass Transformer for Machine Translation", "abstract": "In contrast with previous approaches where information flows only towards\ndeeper layers of a stack, we consider a multi-pass transformer (MPT)\narchitecture in which earlier layers are allowed to process information in\nlight of the output of later layers. To maintain a directed acyclic graph\nstructure, the encoder stack of a transformer is repeated along a new\nmulti-pass dimension, keeping the parameters tied, and information is allowed\nto proceed unidirectionally both towards deeper layers within an encoder stack\nand towards any layer of subsequent stacks. We consider both soft (i.e.,\ncontinuous) and hard (i.e., discrete) connections between parallel encoder\nstacks, relying on a neural architecture search to find the best connection\npattern in the hard case. We perform an extensive ablation study of the\nproposed MPT architecture and compare it with other state-of-the-art\ntransformer architectures. Surprisingly, Base Transformer equipped with MPT can\nsurpass the performance of Large Transformer on the challenging machine\ntranslation En-De and En-Fr datasets. In the hard connection case, the optimal\nconnection pattern found for En-De also leads to improved performance for\nEn-Fr.", "published": "2020-09-23 21:22:15", "link": "http://arxiv.org/abs/2009.11382v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LA-HCN: Label-based Attention for Hierarchical Multi-label\n  TextClassification Neural Network", "abstract": "Hierarchical multi-label text classification (HMTC) has been gaining\npopularity in recent years thanks to its applicability to a plethora of\nreal-world applications. The existing HMTC algorithms largely focus on the\ndesign of classifiers, such as the local, global, or a combination of them.\nHowever, very few studies have focused on hierarchical feature extraction and\nexplore the association between the hierarchical labels and the text. In this\npaper, we propose a Label-based Attention for Hierarchical Mutlti-label Text\nClassification Neural Network (LA-HCN), where the novel label-based attention\nmodule is designed to hierarchically extract important information from the\ntext based on the labels from different hierarchy levels. Besides, hierarchical\ninformation is shared across levels while preserving the hierarchical\nlabel-based information. Separate local and global document embeddings are\nobtained and used to facilitate the respective local and global\nclassifications. In our experiments, LA-HCN outperforms other state-of-the-art\nneural network-based HMTC algorithms on four public HMTC datasets. The ablation\nstudy also demonstrates the effectiveness of the proposed label-based attention\nmodule as well as the novel local and global embeddings and classifications. By\nvisualizing the learned attention (words), we find that LA-HCN is able to\nextract meaningful information corresponding to the different labels which\nprovides explainability that may be helpful for the human analyst.", "published": "2020-09-23 06:18:25", "link": "http://arxiv.org/abs/2009.10938v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Worst-Case-Aware Curriculum Learning for Zero and Few Shot Transfer", "abstract": "Multi-task transfer learning based on pre-trained language encoders achieves\nstate-of-the-art performance across a range of tasks. Standard approaches\nimplicitly assume the tasks, for which we have training data, are equally\nrepresentative of the tasks we are interested in, an assumption which is often\nhard to justify. This paper presents a more agnostic approach to multi-task\ntransfer learning, which uses automated curriculum learning to minimize a new\nfamily of worst-case-aware losses across tasks. Not only do these losses lead\nto better performance on outlier tasks; they also lead to better performance in\nzero-shot and few-shot transfer settings.", "published": "2020-09-23 13:32:39", "link": "http://arxiv.org/abs/2009.11138v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Hierarchical Pre-training for Sequence Labelling in Spoken Dialog", "abstract": "Sequence labelling tasks like Dialog Act and Emotion/Sentiment identification\nare a key component of spoken dialog systems. In this work, we propose a new\napproach to learn generic representations adapted to spoken dialog, which we\nevaluate on a new benchmark we call Sequence labellIng evaLuatIon benChmark fOr\nspoken laNguagE benchmark (\\texttt{SILICONE}). \\texttt{SILICONE} is\nmodel-agnostic and contains 10 different datasets of various sizes. We obtain\nour representations with a hierarchical encoder based on transformer\narchitectures, for which we extend two well-known pre-training objectives.\nPre-training is performed on OpenSubtitles: a large corpus of spoken dialog\ncontaining over $2.3$ billion of tokens. We demonstrate how hierarchical\nencoders achieve competitive results with consistently fewer parameters\ncompared to state-of-the-art models and we show their importance for both\npre-training and fine-tuning.", "published": "2020-09-23 13:54:57", "link": "http://arxiv.org/abs/2009.11152v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Crosslingual Topic Modeling with WikiPDA", "abstract": "We present Wikipedia-based Polyglot Dirichlet Allocation (WikiPDA), a\ncrosslingual topic model that learns to represent Wikipedia articles written in\nany language as distributions over a common set of language-independent topics.\nIt leverages the fact that Wikipedia articles link to each other and are mapped\nto concepts in the Wikidata knowledge base, such that, when represented as bags\nof links, articles are inherently language-independent. WikiPDA works in two\nsteps, by first densifying bags of links using matrix completion and then\ntraining a standard monolingual topic model. A human evaluation shows that\nWikiPDA produces more coherent topics than monolingual text-based LDA, thus\noffering crosslinguality at no cost. We demonstrate WikiPDA's utility in two\napplications: a study of topical biases in 28 Wikipedia editions, and\ncrosslingual supervised classification. Finally, we highlight WikiPDA's\ncapacity for zero-shot language transfer, where a model is reused for new\nlanguages without any fine-tuning. Researchers can benefit from WikiPDA as a\npractical tool for studying Wikipedia's content across its 299 language\neditions in interpretable ways, via an easy-to-use library publicly available\nat https://github.com/epfl-dlab/WikiPDA.", "published": "2020-09-23 15:19:27", "link": "http://arxiv.org/abs/2009.11207v2", "categories": ["cs.CL", "cs.DL"], "primary_category": "cs.CL"}
{"title": "A Comparative Study on Structural and Semantic Properties of Sentence\n  Embeddings", "abstract": "Sentence embeddings encode natural language sentences as low-dimensional\ndense vectors. A great deal of effort has been put into using sentence\nembeddings to improve several important natural language processing tasks.\nRelation extraction is such an NLP task that aims at identifying structured\nrelations defined in a knowledge base from unstructured text. A promising and\nmore efficient approach would be to embed both the text and structured\nknowledge in low-dimensional spaces and discover semantic alignments or\nmappings between them. Although a number of techniques have been proposed in\nthe literature for embedding both sentences and knowledge graphs, little is\nknown about the structural and semantic properties of these embedding spaces in\nterms of relation extraction. In this paper, we investigate the aforementioned\nproperties by evaluating the extent to which sentences carrying similar senses\nare embedded in close proximity sub-spaces, and if we can exploit that\nstructure to align sentences to a knowledge graph. We propose a set of\nexperiments using a widely-used large-scale data set for relation extraction\nand focusing on a set of key sentence embedding methods. We additionally\nprovide the code for reproducing these experiments at\nhttps://github.com/akalino/semantic-structural-sentences. These embedding\nmethods cover a wide variety of techniques ranging from simple word embedding\ncombination to transformer-based BERT-style model. Our experimental results\nshow that different embedding spaces have different degrees of strength for the\nstructural and semantic properties. These results provide useful information\nfor developing embedding-based relation extraction methods.", "published": "2020-09-23 15:45:32", "link": "http://arxiv.org/abs/2009.11226v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On the Ability and Limitations of Transformers to Recognize Formal\n  Languages", "abstract": "Transformers have supplanted recurrent models in a large number of NLP tasks.\nHowever, the differences in their abilities to model different syntactic\nproperties remain largely unknown. Past works suggest that LSTMs generalize\nvery well on regular languages and have close connections with counter\nlanguages. In this work, we systematically study the ability of Transformers to\nmodel such languages as well as the role of its individual components in doing\nso. We first provide a construction of Transformers for a subclass of counter\nlanguages, including well-studied languages such as n-ary Boolean Expressions,\nDyck-1, and its generalizations. In experiments, we find that Transformers do\nwell on this subclass, and their learned mechanism strongly correlates with our\nconstruction. Perhaps surprisingly, in contrast to LSTMs, Transformers do well\nonly on a subset of regular languages with degrading performance as we make\nlanguages more complex according to a well-known measure of complexity. Our\nanalysis also provides insights on the role of self-attention mechanism in\nmodeling certain behaviors and the influence of positional encoding schemes on\nthe learning and generalization abilities of the model.", "published": "2020-09-23 17:21:33", "link": "http://arxiv.org/abs/2009.11264v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ConvAI3: Generating Clarifying Questions for Open-Domain Dialogue\n  Systems (ClariQ)", "abstract": "This document presents a detailed description of the challenge on clarifying\nquestions for dialogue systems (ClariQ). The challenge is organized as part of\nthe Conversational AI challenge series (ConvAI3) at Search Oriented\nConversational AI (SCAI) EMNLP workshop in 2020. The main aim of the\nconversational systems is to return an appropriate answer in response to the\nuser requests. However, some user requests might be ambiguous. In IR settings\nsuch a situation is handled mainly thought the diversification of the search\nresult page. It is however much more challenging in dialogue settings with\nlimited bandwidth. Therefore, in this challenge, we provide a common evaluation\nframework to evaluate mixed-initiative conversations. Participants are asked to\nrank clarifying questions in an information-seeking conversations. The\nchallenge is organized in two stages where in Stage 1 we evaluate the\nsubmissions in an offline setting and single-turn conversations. Top\nparticipants of Stage 1 get the chance to have their model tested by human\nannotators.", "published": "2020-09-23 19:48:02", "link": "http://arxiv.org/abs/2009.11352v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Text Classification with Novelty Detection", "abstract": "This paper studies the problem of detecting novel or unexpected instances in\ntext classification. In traditional text classification, the classes appeared\nin testing must have been seen in training. However, in many applications, this\nis not the case because in testing, we may see unexpected instances that are\nnot from any of the training classes. In this paper, we propose a significantly\nmore effective approach that converts the original problem to a pair-wise\nmatching problem and then outputs how probable two instances belong to the same\nclass. Under this approach, we present two models. The more effective model\nuses two embedding matrices of a pair of instances as two channels of a CNN.\nThe output probabilities from such pairs are used to judge whether a test\ninstance is from a seen class or is novel/unexpected. Experimental results show\nthat the proposed method substantially outperforms the state-of-the-art\nbaselines.", "published": "2020-09-23 12:54:34", "link": "http://arxiv.org/abs/2009.11119v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Cosine Similarity of Multimodal Content Vectors for TV Programmes", "abstract": "Multimodal information originates from a variety of sources: audiovisual\nfiles, textual descriptions, and metadata. We show how one can represent the\ncontent encoded by each individual source using vectors, how to combine the\nvectors via middle and late fusion techniques, and how to compute the semantic\nsimilarities between the contents. Our vectorial representations are built from\nspectral features and Bags of Audio Words, for audio, LSI topics and Doc2vec\nembeddings for subtitles, and the categorical features, for metadata. We\nimplement our model on a dataset of BBC TV programmes and evaluate the fused\nrepresentations to provide recommendations. The late fused similarity matrices\nsignificantly improve the precision and diversity of recommendations.", "published": "2020-09-23 13:12:30", "link": "http://arxiv.org/abs/2009.11129v1", "categories": ["cs.MM", "cs.CL", "cs.IR", "cs.LG", "I.2.7; I.4.7; I.7.0; H.5.1; H.5.5"], "primary_category": "cs.MM"}
{"title": "X-LXMERT: Paint, Caption and Answer Questions with Multi-Modal\n  Transformers", "abstract": "Mirroring the success of masked language models, vision-and-language\ncounterparts like ViLBERT, LXMERT and UNITER have achieved state of the art\nperformance on a variety of multimodal discriminative tasks like visual\nquestion answering and visual grounding. Recent work has also successfully\nadapted such models towards the generative task of image captioning. This begs\nthe question: Can these models go the other way and generate images from pieces\nof text? Our analysis of a popular representative from this model family -\nLXMERT - finds that it is unable to generate rich and semantically meaningful\nimagery with its current training setup. We introduce X-LXMERT, an extension to\nLXMERT with training refinements including: discretizing visual\nrepresentations, using uniform masking with a large range of masking ratios and\naligning the right pre-training datasets to the right objectives which enables\nit to paint. X-LXMERT's image generation capabilities rival state of the art\ngenerative models while its question answering and captioning abilities remains\ncomparable to LXMERT. Finally, we demonstrate the generality of these training\nrefinements by adding image generation capabilities into UNITER to produce\nX-UNITER.", "published": "2020-09-23 17:45:17", "link": "http://arxiv.org/abs/2009.11278v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Structure Aware Negative Sampling in Knowledge Graphs", "abstract": "Learning low-dimensional representations for entities and relations in\nknowledge graphs using contrastive estimation represents a scalable and\neffective method for inferring connectivity patterns. A crucial aspect of\ncontrastive learning approaches is the choice of corruption distribution that\ngenerates hard negative samples, which force the embedding model to learn\ndiscriminative representations and find critical characteristics of observed\ndata. While earlier methods either employ too simple corruption distributions,\ni.e. uniform, yielding easy uninformative negatives or sophisticated\nadversarial distributions with challenging optimization schemes, they do not\nexplicitly incorporate known graph structure resulting in suboptimal negatives.\nIn this paper, we propose Structure Aware Negative Sampling (SANS), an\ninexpensive negative sampling strategy that utilizes the rich graph structure\nby selecting negative samples from a node's k-hop neighborhood. Empirically, we\ndemonstrate that SANS finds semantically meaningful negatives and is\ncompetitive with SOTA approaches while requires no additional parameters nor\ndifficult adversarial optimization.", "published": "2020-09-23 19:57:00", "link": "http://arxiv.org/abs/2009.11355v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Deep Learning Algorithm for Objective Assessment of Hypernasality in\n  Children with Cleft Palate", "abstract": "Objectives: Evaluation of hypernasality requires extensive perceptual\ntraining by clinicians and extending this training on a large scale\ninternationally is untenable; this compounds the health disparities that\nalready exist among children with cleft. In this work, we present the objective\nhypernasality measure (OHM), a speech analytics algorithm that automatically\nmeasures hypernasality in speech, and validate it relative to a group of\ntrained clinicians. Methods: We trained a deep neural network (DNN) on\napproximately 100 hours of a publicly-available healthy speech corpus to detect\nthe presence of nasal acoustic cues generated through the production of nasal\nconsonants and nasalized phonemes in speech. Importantly, this model does not\nrequire any clinical data for training. The posterior probabilities of the deep\nlearning model were aggregated at the sentence and speaker-levels to compute\nthe OHM.\n  Results: The results showed that the OHM was significantly correlated with\nthe perceptual hypernasality ratings in the Americleft database ( r=0.797,\n~p$<$0.001), and with the New Mexico Cleft Palate Center (NMCPC) database\n(r=0.713,p<$0.001). In addition, we evaluated the relationship between the OHM\nand articulation errors; the sensitivity of the OHM in detecting the presence\nof very mild hypernasality; and establishing the internal reliability of the\nmetric. Further, the performance of OHM was compared with a DNN regression\nalgorithm directly trained on the hypernasal speech samples. Significance: The\nresults indicate that the OHM is able to rate the severity of hypernasality on\npar with Americleft-trained clinicians on this dataset.", "published": "2020-09-23 19:53:39", "link": "http://arxiv.org/abs/2009.11354v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Attention Driven Fusion for Multi-Modal Emotion Recognition", "abstract": "Deep learning has emerged as a powerful alternative to hand-crafted methods\nfor emotion recognition on combined acoustic and text modalities. Baseline\nsystems model emotion information in text and acoustic modes independently\nusing Deep Convolutional Neural Networks (DCNN) and Recurrent Neural Networks\n(RNN), followed by applying attention, fusion, and classification. In this\npaper, we present a deep learning-based approach to exploit and fuse text and\nacoustic data for emotion classification. We utilize a SincNet layer, based on\nparameterized sinc functions with band-pass filters, to extract acoustic\nfeatures from raw audio followed by a DCNN. This approach learns filter banks\ntuned for emotion recognition and provides more effective features compared to\ndirectly applying convolutions over the raw speech signal. For text processing,\nwe use two branches (a DCNN and a Bi-direction RNN followed by a DCNN) in\nparallel where cross attention is introduced to infer the N-gram level\ncorrelations on hidden representations received from the Bi-RNN. Following\nexisting state-of-the-art, we evaluate the performance of the proposed system\non the IEMOCAP dataset. Experimental results indicate that the proposed system\noutperforms existing methods, achieving 3.5% improvement in weighted accuracy.", "published": "2020-09-23 08:07:58", "link": "http://arxiv.org/abs/2009.10991v2", "categories": ["eess.AS", "cs.HC", "cs.LG", "stat.ML"], "primary_category": "eess.AS"}
{"title": "FluentNet: End-to-End Detection of Speech Disfluency with Deep Learning", "abstract": "Strong presentation skills are valuable and sought-after in workplace and\nclassroom environments alike. Of the possible improvements to vocal\npresentations, disfluencies and stutters in particular remain one of the most\ncommon and prominent factors of someone's demonstration. Millions of people are\naffected by stuttering and other speech disfluencies, with the majority of the\nworld having experienced mild stutters while communicating under stressful\nconditions. While there has been much research in the field of automatic speech\nrecognition and language models, there lacks the sufficient body of work when\nit comes to disfluency detection and recognition. To this end, we propose an\nend-to-end deep neural network, FluentNet, capable of detecting a number of\ndifferent disfluency types. FluentNet consists of a Squeeze-and-Excitation\nResidual convolutional neural network which facilitate the learning of strong\nspectral frame-level representations, followed by a set of bidirectional long\nshort-term memory layers that aid in learning effective temporal relationships.\nLastly, FluentNet uses an attention mechanism to focus on the important parts\nof speech to obtain a better performance. We perform a number of different\nexperiments, comparisons, and ablation studies to evaluate our model. Our model\nachieves state-of-the-art results by outperforming other solutions in the field\non the publicly available UCLASS dataset. Additionally, we present\nLibriStutter: a disfluency dataset based on the public LibriSpeech dataset with\nsynthesized stutters. We also evaluate FluentNet on this dataset, showing the\nstrong performance of our model versus a number of benchmark techniques.", "published": "2020-09-23 21:51:29", "link": "http://arxiv.org/abs/2009.11394v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
