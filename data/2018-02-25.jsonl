{"title": "OhioState at SemEval-2018 Task 7: Exploiting Data Augmentation for\n  Relation Classification in Scientific Papers using Piecewise Convolutional\n  Neural Networks", "abstract": "We describe our system for SemEval-2018 Shared Task on Semantic Relation\nExtraction and Classification in Scientific Papers where we focus on the\nClassification task. Our simple piecewise convolution neural encoder performs\ndecently in an end to end manner. A simple inter-task data augmentation\nsignifi- cantly boosts the performance of the model. Our best-performing\nsystems stood 8th out of 20 teams on the classification task on noisy data and\n12th out of 28 teams on the classification task on clean data.", "published": "2018-02-25 03:49:21", "link": "http://arxiv.org/abs/1802.08949v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Incorporating Discriminator in Sentence Generation: a Gibbs Sampling\n  Method", "abstract": "Generating plausible and fluent sentence with desired properties has long\nbeen a challenge. Most of the recent works use recurrent neural networks (RNNs)\nand their variants to predict following words given previous sequence and\ntarget label. In this paper, we propose a novel framework to generate\nconstrained sentences via Gibbs Sampling. The candidate sentences are revised\nand updated iteratively, with sampled new words replacing old ones. Our\nexperiments show the effectiveness of the proposed method to generate plausible\nand diverse sentences.", "published": "2018-02-25 09:01:55", "link": "http://arxiv.org/abs/1802.08970v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Revisiting the poverty of the stimulus: hierarchical generalization\n  without a hierarchical bias in recurrent neural networks", "abstract": "Syntactic rules in natural language typically need to make reference to\nhierarchical sentence structure. However, the simple examples that language\nlearners receive are often equally compatible with linear rules. Children\nconsistently ignore these linear explanations and settle instead on the correct\nhierarchical one. This fact has motivated the proposal that the learner's\nhypothesis space is constrained to include only hierarchical rules. We examine\nthis proposal using recurrent neural networks (RNNs), which are not constrained\nin such a way. We simulate the acquisition of question formation, a\nhierarchical transformation, in a fragment of English. We find that some RNN\narchitectures tend to learn the hierarchical rule, suggesting that hierarchical\ncues within the language, combined with the implicit architectural biases\ninherent in certain RNNs, may be sufficient to induce hierarchical\ngeneralizations. The likelihood of acquiring the hierarchical generalization\nincreased when the language included an additional cue to hierarchy in the form\nof subject-verb agreement, underscoring the role of cues to hierarchy in the\nlearner's input.", "published": "2018-02-25 21:52:37", "link": "http://arxiv.org/abs/1802.09091v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Meta Multi-Task Learning for Sequence Modeling", "abstract": "Semantic composition functions have been playing a pivotal role in neural\nrepresentation learning of text sequences. In spite of their success, most\nexisting models suffer from the underfitting problem: they use the same shared\ncompositional function on all the positions in the sequence, thereby lacking\nexpressive power due to incapacity to capture the richness of compositionality.\nBesides, the composition functions of different tasks are independent and\nlearned from scratch. In this paper, we propose a new sharing scheme of\ncomposition function across multiple tasks. Specifically, we use a shared\nmeta-network to capture the meta-knowledge of semantic composition and generate\nthe parameters of the task-specific semantic composition models. We conduct\nextensive experiments on two types of tasks, text classification and sequence\ntagging, which demonstrate the benefits of our approach. Besides, we show that\nthe shared meta-knowledge learned by our proposed model can be regarded as\noff-the-shelf knowledge and easily transferred to new tasks.", "published": "2018-02-25 09:01:25", "link": "http://arxiv.org/abs/1802.08969v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "NL2Bash: A Corpus and Semantic Parser for Natural Language Interface to\n  the Linux Operating System", "abstract": "We present new data and semantic parsing methods for the problem of mapping\nEnglish sentences to Bash commands (NL2Bash). Our long-term goal is to enable\nany user to perform operations such as file manipulation, search, and\napplication-specific scripting by simply stating their goals in English. We\ntake a first step in this domain, by providing a new dataset of challenging but\ncommonly used Bash commands and expert-written English descriptions, along with\nbaseline methods to establish performance levels on this task.", "published": "2018-02-25 09:52:24", "link": "http://arxiv.org/abs/1802.08979v2", "categories": ["cs.CL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "One Single Deep Bidirectional LSTM Network for Word Sense Disambiguation\n  of Text Data", "abstract": "Due to recent technical and scientific advances, we have a wealth of\ninformation hidden in unstructured text data such as offline/online narratives,\nresearch articles, and clinical reports. To mine these data properly,\nattributable to their innate ambiguity, a Word Sense Disambiguation (WSD)\nalgorithm can avoid numbers of difficulties in Natural Language Processing\n(NLP) pipeline. However, considering a large number of ambiguous words in one\nlanguage or technical domain, we may encounter limiting constraints for proper\ndeployment of existing WSD models. This paper attempts to address the problem\nof one-classifier-per-one-word WSD algorithms by proposing a single\nBidirectional Long Short-Term Memory (BLSTM) network which by considering\nsenses and context sequences works on all ambiguous words collectively.\nEvaluated on SensEval-3 benchmark, we show the result of our model is\ncomparable with top-performing WSD algorithms. We also discuss how applying\nadditional modifications alleviates the model fault and the need for more\ntraining data.", "published": "2018-02-25 18:51:53", "link": "http://arxiv.org/abs/1802.09059v1", "categories": ["cs.LG", "cs.CL", "cs.IR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "RLS-Based Adaptive Dereverberation Tracing Abrupt Position Change of\n  Target Speaker", "abstract": "Adaptive algorithm based on multi-channel linear prediction is an effective\ndereverberation method balancing well between the attenuation of the long-term\nreverberation and the dereverberated speech quality. However, the abrupt change\nof the speech source position, usually caused by the shift of the speakers,\nforms an obstacle to the adaptive algorithm and makes it difficult to guarantee\nboth the fast convergence speed and the optimal steady-state behavior. In this\npaper, the RLS-based adaptive multi-channel linear prediction method is\ninvestigated and a time-varying forgetting factor based on the relative\nweighted change of the adaptive filter coefficients is proposed to effectively\ntracing the abrupt change of the target speaker position. The advantages of the\nproposed scheme are demonstrated in the simulations and experiments.", "published": "2018-02-25 13:11:02", "link": "http://arxiv.org/abs/1802.08997v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Frequency domain TRINICON-based blind source separation method with\n  multi-source activity detection for sparsely mixed signals", "abstract": "The TRINICON ('Triple-N ICA for convolutive mixtures') framework is an\neffective blind signal separation (BSS) method for separating sound sources\nfrom convolutive mixtures. It makes full use of the non-whiteness,\nnon-stationarity and non-Gaussianity properties of the source signals and can\nbe implemented either in time domain or in frequency domain, avoiding the\nnotorious internal permutation problem. It usually has best performance when\nthe sources are continuously mixed. In this paper, the offline dual-channel\nfrequency domain TRINICON implementation for sparsely mixed signals is\ninvestigated, and a multi-source activity detection is proposed to locate the\nactive period of each source, based on which the filter updating strategy is\nregularized to improve the separation performance. The objective metric\nprovided by the BSSEVAL toolkit is utilized to evaluate the performance of the\nproposed scheme.", "published": "2018-02-25 13:44:52", "link": "http://arxiv.org/abs/1802.09005v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
