{"title": "Evaluating Explanations: An Explanatory Virtues Framework for Mechanistic Interpretability -- The Strange Science Part I.ii", "abstract": "Mechanistic Interpretability (MI) aims to understand neural networks through\ncausal explanations. Though MI has many explanation-generating methods,\nprogress has been limited by the lack of a universal approach to evaluating\nexplanations. Here we analyse the fundamental question \"What makes a good\nexplanation?\" We introduce a pluralist Explanatory Virtues Framework drawing on\nfour perspectives from the Philosophy of Science - the Bayesian, Kuhnian,\nDeutschian, and Nomological - to systematically evaluate and improve\nexplanations in MI. We find that Compact Proofs consider many explanatory\nvirtues and are hence a promising approach. Fruitful research directions\nimplied by our framework include (1) clearly defining explanatory simplicity,\n(2) focusing on unifying explanations and (3) deriving universal principles for\nneural networks. Improved MI methods enhance our ability to monitor, predict,\nand steer AI systems.", "published": "2025-05-02 16:18:40", "link": "http://arxiv.org/abs/2505.01372v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.LG"}
{"title": "TRAVELER: A Benchmark for Evaluating Temporal Reasoning across Vague, Implicit and Explicit References", "abstract": "Understanding and resolving temporal references is essential in Natural\nLanguage Understanding as we often refer to the past or future in daily\ncommunication. Although existing benchmarks address a system's ability to\nreason about and resolve temporal references, systematic evaluation of specific\ntemporal references remains limited. Towards closing this gap, we introduce\nTRAVELER, a novel synthetic benchmark dataset that follows a Question Answering\nparadigm and consists of questions involving temporal references with the\ncorresponding correct answers. TRAVELER assesses models' abilities to resolve\nexplicit, implicit relative to speech time, and vague temporal references.\nBeyond investigating the performance of state-of-the-art LLMs depending on the\ntype of temporal reference, our benchmark also allows evaluation of performance\nin relation to the length of the set of events. For the category of vague\ntemporal references, ground-truth answers were established via human surveys on\nProlific, following a procedure similar to the one from Kenneweg et al. To\ndemonstrate the benchmark's applicability, we evaluate four state-of-the-art\nLLMs using a question-answering task encompassing 3,300 questions. Our findings\nshow that while the benchmarked LLMs can answer questions over event sets with\na handful of events and explicit temporal references successfully, performance\nclearly deteriorates with larger event set length and when temporal references\nget less explicit. Notably, the vague question category exhibits the lowest\nperformance across all models.\n  The benchmark is publicly available at:\nhttps://gitlab.ub.uni-bielefeld.de/s.kenneweg/TRAVELER", "published": "2025-05-02 14:56:50", "link": "http://arxiv.org/abs/2505.01325v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Helping Big Language Models Protect Themselves: An Enhanced Filtering and Summarization System", "abstract": "The recent growth in the use of Large Language Models has made them\nvulnerable to sophisticated adversarial assaults, manipulative prompts, and\nencoded malicious inputs. Existing countermeasures frequently necessitate\nretraining models, which is computationally costly and impracticable for\ndeployment. Without the need for retraining or fine-tuning, this study presents\na unique defense paradigm that allows LLMs to recognize, filter, and defend\nagainst adversarial or malicious inputs on their own. There are two main parts\nto the suggested framework: (1) A prompt filtering module that uses\nsophisticated Natural Language Processing (NLP) techniques, including zero-shot\nclassification, keyword analysis, and encoded content detection (e.g. base64,\nhexadecimal, URL encoding), to detect, decode, and classify harmful inputs; and\n(2) A summarization module that processes and summarizes adversarial research\nliterature to give the LLM context-aware defense knowledge. This approach\nstrengthens LLMs' resistance to adversarial exploitation by fusing text\nextraction, summarization, and harmful prompt analysis. According to\nexperimental results, this integrated technique has a 98.71% success rate in\nidentifying harmful patterns, manipulative language structures, and encoded\nprompts. By employing a modest amount of adversarial research literature as\ncontext, the methodology also allows the model to react correctly to harmful\ninputs with a larger percentage of jailbreak resistance and refusal rate. While\nmaintaining the quality of LLM responses, the framework dramatically increases\nLLM's resistance to hostile misuse, demonstrating its efficacy as a quick and\neasy substitute for time-consuming, retraining-based defenses.", "published": "2025-05-02 14:42:26", "link": "http://arxiv.org/abs/2505.01315v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Transformer-based Neural Architecture Search Method", "abstract": "This paper presents a neural architecture search method based on Transformer\narchitecture, searching cross multihead attention computation ways for\ndifferent number of encoder and decoder combinations. In order to search for\nneural network structures with better translation results, we considered\nperplexity as an auxiliary evaluation metric for the algorithm in addition to\nBLEU scores and iteratively improved each individual neural network within the\npopulation by a multi-objective genetic algorithm. Experimental results show\nthat the neural network structures searched by the algorithm outperform all the\nbaseline models, and that the introduction of the auxiliary evaluation metric\ncan find better models than considering only the BLEU score as an evaluation\nmetric.", "published": "2025-05-02 14:40:16", "link": "http://arxiv.org/abs/2505.01314v1", "categories": ["cs.CL", "cs.NE"], "primary_category": "cs.CL"}
{"title": "A Factorized Probabilistic Model of the Semantics of Vague Temporal Adverbials Relative to Different Event Types", "abstract": "Vague temporal adverbials, such as recently, just, and a long time ago,\ndescribe the temporal distance between a past event and the utterance time but\nleave the exact duration underspecified. In this paper, we introduce a\nfactorized model that captures the semantics of these adverbials as\nprobabilistic distributions. These distributions are composed with\nevent-specific distributions to yield a contextualized meaning for an adverbial\napplied to a specific event. We fit the model's parameters using existing data\ncapturing judgments of native speakers regarding the applicability of these\nvague temporal adverbials to events that took place a given time ago. Comparing\nour approach to a non-factorized model based on a single Gaussian distribution\nfor each pair of event and temporal adverbial, we find that while both models\nhave similar predictive power, our model is preferable in terms of Occam's\nrazor, as it is simpler and has better extendability.", "published": "2025-05-02 14:39:04", "link": "http://arxiv.org/abs/2505.01311v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PREMISE: Matching-based Prediction for Accurate Review Recommendation", "abstract": "We present PREMISE (PREdict with Matching ScorEs), a new architecture for the\nmatching-based learning in the multimodal fields for the multimodal review\nhelpfulness (MRHP) task. Distinct to previous fusion-based methods which\nobtains multimodal representations via cross-modal attention for downstream\ntasks, PREMISE computes the multi-scale and multi-field representations,\nfilters duplicated semantics, and then obtained a set of matching scores as\nfeature vectors for the downstream recommendation task. This new architecture\nsignificantly boosts the performance for such multimodal tasks whose context\nmatching content are highly correlated to the targets of that task, compared to\nthe state-of-the-art fusion-based methods. Experimental results on two publicly\navailable datasets show that PREMISE achieves promising performance with less\ncomputational cost.", "published": "2025-05-02 13:23:13", "link": "http://arxiv.org/abs/2505.01255v1", "categories": ["cs.CL", "cs.IR", "cs.MM"], "primary_category": "cs.CL"}
{"title": "EvalxNLP: A Framework for Benchmarking Post-Hoc Explainability Methods on NLP Models", "abstract": "As Natural Language Processing (NLP) models continue to evolve and become\nintegral to high-stakes applications, ensuring their interpretability remains a\ncritical challenge. Given the growing variety of explainability methods and\ndiverse stakeholder requirements, frameworks that help stakeholders select\nappropriate explanations tailored to their specific use cases are increasingly\nimportant. To address this need, we introduce EvalxNLP, a Python framework for\nbenchmarking state-of-the-art feature attribution methods for transformer-based\nNLP models. EvalxNLP integrates eight widely recognized explainability\ntechniques from the Explainable AI (XAI) literature, enabling users to generate\nand evaluate explanations based on key properties such as faithfulness,\nplausibility, and complexity. Our framework also provides interactive,\nLLM-based textual explanations, facilitating user understanding of the\ngenerated explanations and evaluation outcomes. Human evaluation results\nindicate high user satisfaction with EvalxNLP, suggesting it is a promising\nframework for benchmarking explanation methods across diverse user groups. By\noffering a user-friendly and extensible platform, EvalxNLP aims at\ndemocratizing explainability tools and supporting the systematic comparison and\nadvancement of XAI techniques in NLP.", "published": "2025-05-02 13:00:05", "link": "http://arxiv.org/abs/2505.01238v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Gender Bias in Explainability: Investigating Performance Disparity in Post-hoc Methods", "abstract": "While research on applications and evaluations of explanation methods\ncontinues to expand, fairness of the explanation methods concerning disparities\nin their performance across subgroups remains an often overlooked aspect. In\nthis paper, we address this gap by showing that, across three tasks and five\nlanguage models, widely used post-hoc feature attribution methods exhibit\nsignificant gender disparity with respect to their faithfulness, robustness,\nand complexity. These disparities persist even when the models are pre-trained\nor fine-tuned on particularly unbiased datasets, indicating that the\ndisparities we observe are not merely consequences of biased training data. Our\nresults highlight the importance of addressing disparities in explanations when\ndeveloping and applying explainability methods, as these can lead to biased\noutcomes against certain subgroups, with particularly critical implications in\nhigh-stakes contexts. Furthermore, our findings underscore the importance of\nincorporating the fairness of explanations, alongside overall model fairness\nand explainability, as a requirement in regulatory frameworks.", "published": "2025-05-02 11:41:25", "link": "http://arxiv.org/abs/2505.01198v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On the Limitations of Steering in Language Model Alignment", "abstract": "Steering vectors are a promising approach to aligning language model behavior\nat inference time. In this paper, we propose a framework to assess the\nlimitations of steering vectors as alignment mechanisms. Using a framework of\ntransformer hook interventions and antonym-based function vectors, we evaluate\nthe role of prompt structure and context complexity in steering effectiveness.\nOur findings indicate that steering vectors are promising for specific\nalignment tasks, such as value alignment, but may not provide a robust\nfoundation for general-purpose alignment in LLMs, particularly in complex\nscenarios. We establish a methodological foundation for future investigations\ninto steering capabilities of reasoning models.", "published": "2025-05-02 10:08:34", "link": "http://arxiv.org/abs/2505.01162v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MateICL: Mitigating Attention Dispersion in Large-Scale In-Context Learning", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nIn-Context Learning (ICL). However, the fixed position length constraints in\npre-trained models limit the number of demonstration examples. Recent efforts\nto extend context suffer from attention dispersion as the number of\ndemonstrations increases. In this paper, we introduce Mitigating Attention\nDispersion in large-scale ICL (MateICL) that enables LLMs to maintain effective\nself-attention as the context size grows. We first split the context into\nmultiple windows, each filled to the model's context capacity, which are\nprocessed separately. Then, we introduce an additional layer to recalibrate the\nattention weights, prioritizing the query tokens as the number of\ndemonstrations increases. Our empirical results show that MateICL can\neffectively leverage larger contexts to improve ICL performance. Compared to\nretrieval-based baselines, MateICL consistently achieves better performance\nwithout requiring an externally trained retrieval model. Despite recent\nadvances in inference strategies (e.g., 32k token contexts), our results\ndemonstrate that MateICL remains beneficial in computationally\nresource-constrained settings. The code is publicly available at\nhttps://github.com/amurtadha/MateICL.", "published": "2025-05-02 08:45:45", "link": "http://arxiv.org/abs/2505.01110v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Vision Language Model Adaptations for Radiology Report Generation in Low-Resource Languages", "abstract": "The integration of artificial intelligence in healthcare has opened new\nhorizons for improving medical diagnostics and patient care. However,\nchallenges persist in developing systems capable of generating accurate and\ncontextually relevant radiology reports, particularly in low-resource\nlanguages. In this study, we present a comprehensive benchmark to evaluate the\nperformance of instruction-tuned Vision-Language Models (VLMs) in the\nspecialized task of radiology report generation across three low-resource\nlanguages: Italian, German, and Spanish. Employing the LLaVA architectural\nframework, we conducted a systematic evaluation of pre-trained models utilizing\ngeneral datasets, domain-specific datasets, and low-resource language-specific\ndatasets. In light of the unavailability of models that possess prior knowledge\nof both the medical domain and low-resource languages, we analyzed various\nadaptations to determine the most effective approach for these contexts. The\nresults revealed that language-specific models substantially outperformed both\ngeneral and domain-specific models in generating radiology reports, emphasizing\nthe critical role of linguistic adaptation. Additionally, models fine-tuned\nwith medical terminology exhibited enhanced performance across all languages\ncompared to models with generic knowledge, highlighting the importance of\ndomain-specific training. We also explored the influence of the temperature\nparameter on the coherence of report generation, providing insights for optimal\nmodel settings. Our findings highlight the importance of tailored language and\ndomain-specific training for improving the quality and accuracy of radiological\nreports in multilingual settings. This research not only advances our\nunderstanding of VLMs adaptability in healthcare but also points to significant\navenues for future investigations into model tuning and language-specific\nadaptations.", "published": "2025-05-02 08:14:03", "link": "http://arxiv.org/abs/2505.01096v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Multimodal Transformers are Hierarchical Modal-wise Heterogeneous Graphs", "abstract": "Multimodal Sentiment Analysis (MSA) is a rapidly developing field that\nintegrates multimodal information to recognize sentiments, and existing models\nhave made significant progress in this area. The central challenge in MSA is\nmultimodal fusion, which is predominantly addressed by Multimodal Transformers\n(MulTs). Although act as the paradigm, MulTs suffer from efficiency concerns.\nIn this work, from the perspective of efficiency optimization, we propose and\nprove that MulTs are hierarchical modal-wise heterogeneous graphs (HMHGs), and\nwe introduce the graph-structured representation pattern of MulTs. Based on\nthis pattern, we propose an Interlaced Mask (IM) mechanism to design the\nGraph-Structured and Interlaced-Masked Multimodal Transformer (GsiT). It is\nformally equivalent to MulTs which achieves an efficient weight-sharing\nmechanism without information disorder through IM, enabling All-Modal-In-One\nfusion with only 1/3 of the parameters of pure MulTs. A Triton kernel called\nDecomposition is implemented to ensure avoiding additional computational\noverhead. Moreover, it achieves significantly higher performance than\ntraditional MulTs. To further validate the effectiveness of GsiT itself and the\nHMHG concept, we integrate them into multiple state-of-the-art models and\ndemonstrate notable performance improvements and parameter reduction on widely\nused MSA datasets.", "published": "2025-05-02 07:18:00", "link": "http://arxiv.org/abs/2505.01068v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Do We Need a Detailed Rubric for Automated Essay Scoring using Large Language Models?", "abstract": "This study investigates the necessity and impact of a detailed rubric in\nautomated essay scoring (AES) using large language models (LLMs). While using\nrubrics are standard in LLM-based AES, creating detailed rubrics requires\nsubstantial ef-fort and increases token usage. We examined how different levels\nof rubric detail affect scoring accuracy across multiple LLMs using the TOEFL11\ndataset. Our experiments compared three conditions: a full rubric, a simplified\nrubric, and no rubric, using four different LLMs (Claude 3.5 Haiku, Gemini 1.5\nFlash, GPT-4o-mini, and Llama 3 70B Instruct). Results showed that three out of\nfour models maintained similar scoring accuracy with the simplified rubric\ncompared to the detailed one, while significantly reducing token usage.\nHowever, one model (Gemini 1.5 Flash) showed decreased performance with more\ndetailed rubrics. The findings suggest that simplified rubrics may be\nsufficient for most LLM-based AES applications, offering a more efficient\nalternative without compromis-ing scoring accuracy. However, model-specific\nevaluation remains crucial as per-formance patterns vary across different LLMs.", "published": "2025-05-02 06:17:51", "link": "http://arxiv.org/abs/2505.01035v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Value Portrait: Understanding Values of LLMs with Human-aligned Benchmark", "abstract": "The importance of benchmarks for assessing the values of language models has\nbeen pronounced due to the growing need of more authentic, human-aligned\nresponses. However, existing benchmarks rely on human or machine annotations\nthat are vulnerable to value-related biases. Furthermore, the tested scenarios\noften diverge from real-world contexts in which models are commonly used to\ngenerate text and express values. To address these issues, we propose the Value\nPortrait benchmark, a reliable framework for evaluating LLMs' value\norientations with two key characteristics. First, the benchmark consists of\nitems that capture real-life user-LLM interactions, enhancing the relevance of\nassessment results to real-world LLM usage and thus ecological validity.\nSecond, each item is rated by human subjects based on its similarity to their\nown thoughts, and correlations between these ratings and the subjects' actual\nvalue scores are derived. This psychometrically validated approach ensures that\nitems strongly correlated with specific values serve as reliable items for\nassessing those values. Through evaluating 27 LLMs with our benchmark, we find\nthat these models prioritize Benevolence, Security, and Self-Direction values\nwhile placing less emphasis on Tradition, Power, and Achievement values. Also,\nour analysis reveals biases in how LLMs perceive various demographic groups,\ndeviating from real human data.", "published": "2025-05-02 05:26:50", "link": "http://arxiv.org/abs/2505.01015v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Towards the Resistance of Neural Network Watermarking to Fine-tuning", "abstract": "This paper proves a new watermarking method to embed the ownership\ninformation into a deep neural network (DNN), which is robust to fine-tuning.\nSpecifically, we prove that when the input feature of a convolutional layer\nonly contains low-frequency components, specific frequency components of the\nconvolutional filter will not be changed by gradient descent during the\nfine-tuning process, where we propose a revised Fourier transform to extract\nfrequency components from the convolutional filter. Additionally, we also prove\nthat these frequency components are equivariant to weight scaling and weight\npermutations. In this way, we design a watermark module to encode the watermark\ninformation to specific frequency components in a convolutional filter.\nPreliminary experiments demonstrate the effectiveness of our method.", "published": "2025-05-02 05:11:17", "link": "http://arxiv.org/abs/2505.01007v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Token-free Models for Sarcasm Detection", "abstract": "Tokenization is a foundational step in most natural language processing (NLP)\npipelines, yet it introduces challenges such as vocabulary mismatch and\nout-of-vocabulary issues. Recent work has shown that models operating directly\non raw text at the byte or character level can mitigate these limitations. In\nthis paper, we evaluate two token-free models, ByT5 and CANINE, on the task of\nsarcasm detection in both social media (Twitter) and non-social media (news\nheadlines) domains. We fine-tune and benchmark these models against token-based\nbaselines and state-of-the-art approaches. Our results show that ByT5-small and\nCANINE outperform token-based counterparts and achieve new state-of-the-art\nperformance, improving accuracy by 0.77% and 0.49% on the News Headlines and\nTwitter Sarcasm datasets, respectively. These findings underscore the potential\nof token-free models for robust NLP in noisy and informal domains such as\nsocial media.", "published": "2025-05-02 05:04:41", "link": "http://arxiv.org/abs/2505.01006v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "VTS-LLM: Domain-Adaptive LLM Agent for Enhancing Awareness in Vessel Traffic Services through Natural Language", "abstract": "Vessel Traffic Services (VTS) are essential for maritime safety and\nregulatory compliance through real-time traffic management. However, with\nincreasing traffic complexity and the prevalence of heterogeneous, multimodal\ndata, existing VTS systems face limitations in spatiotemporal reasoning and\nintuitive human interaction. In this work, we propose VTS-LLM Agent, the first\ndomain-adaptive large LLM agent tailored for interactive decision support in\nVTS operations. We formalize risk-prone vessel identification as a\nknowledge-augmented Text-to-SQL task, combining structured vessel databases\nwith external maritime knowledge. To support this, we construct a curated\nbenchmark dataset consisting of a custom schema, domain-specific corpus, and a\nquery-SQL test set in multiple linguistic styles. Our framework incorporates\nNER-based relational reasoning, agent-based domain knowledge injection,\nsemantic algebra intermediate representation, and query rethink mechanisms to\nenhance domain grounding and context-aware understanding. Experimental results\nshow that VTS-LLM outperforms both general-purpose and SQL-focused baselines\nunder command-style, operational-style, and formal natural language queries,\nrespectively. Moreover, our analysis provides the first empirical evidence that\nlinguistic style variation introduces systematic performance challenges in\nText-to-SQL modeling. This work lays the foundation for natural language\ninterfaces in vessel traffic services and opens new opportunities for\nproactive, LLM-driven maritime real-time traffic management.", "published": "2025-05-02 04:27:50", "link": "http://arxiv.org/abs/2505.00989v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Position: Enough of Scaling LLMs! Lets Focus on Downscaling", "abstract": "We challenge the dominant focus on neural scaling laws and advocate for a\nparadigm shift toward downscaling in the development of large language models\n(LLMs). While scaling laws have provided critical insights into performance\nimprovements through increasing model and dataset size, we emphasize the\nsignificant limitations of this approach, particularly in terms of\ncomputational inefficiency, environmental impact, and deployment constraints.\nTo address these challenges, we propose a holistic framework for downscaling\nLLMs that seeks to maintain performance while drastically reducing resource\ndemands. This paper outlines practical strategies for transitioning away from\ntraditional scaling paradigms, advocating for a more sustainable, efficient,\nand accessible approach to LLM development.", "published": "2025-05-02 04:13:27", "link": "http://arxiv.org/abs/2505.00985v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Synthesize-on-Graph: Knowledgeable Synthetic Data Generation for Continue Pre-training of Large Language Models", "abstract": "Large Language Models (LLMs) have achieved remarkable success but remain\ndata-inefficient, especially when learning from small, specialized corpora with\nlimited and proprietary data. Existing synthetic data generation methods for\ncontinue pre-training focus on intra-document content and overlook\ncross-document knowledge associations, limiting content diversity and depth. We\npropose Synthetic-on-Graph (SoG), a synthetic data generation framework that\nincorporates cross-document knowledge associations for efficient corpus\nexpansion. SoG constructs a context graph by extracting entities and concepts\nfrom the original corpus, representing cross-document associations, and\nemploying a graph walk strategy for knowledge-associated sampling. This\nenhances synthetic data diversity and coherence, enabling models to learn\ncomplex knowledge structures and handle rare knowledge. To further improve\nsynthetic data quality, we integrate Chain-of-Thought (CoT) and Contrastive\nClarifying (CC) synthetic, enhancing reasoning processes and discriminative\npower. Experiments show that SoG outperforms the state-of-the-art (SOTA) method\nin a multi-hop document Q&A dataset while performing comparably to the SOTA\nmethod on the reading comprehension task datasets, which also underscores the\nbetter generalization capability of SoG. Our work advances synthetic data\ngeneration and provides practical solutions for efficient knowledge acquisition\nin LLMs, especially in domains with limited data availability.", "published": "2025-05-02 03:40:39", "link": "http://arxiv.org/abs/2505.00979v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Character-based Diffusion Embedding Algorithm for Enhancing the Generation Quality of Generative Linguistic Steganographic Texts", "abstract": "Generating high-quality steganographic text is a fundamental challenge in the\nfield of generative linguistic steganography. This challenge arises primarily\nfrom two aspects: firstly, the capabilities of existing models in text\ngeneration are limited; secondly, embedding algorithms fail to effectively\nmitigate the negative impacts of sensitive information's properties, such as\nsemantic content or randomness. Specifically, to ensure that the recipient can\naccurately extract hidden information, embedding algorithms often have to\nconsider selecting candidate words with relatively low probabilities. This\nphenomenon leads to a decrease in the number of high-probability candidate\nwords and an increase in low-probability candidate words, thereby compromising\nthe semantic coherence and logical fluency of the steganographic text and\ndiminishing the overall quality of the generated steganographic material. To\naddress this issue, this paper proposes a novel embedding algorithm,\ncharacter-based diffusion embedding algorithm (CDEA). Unlike existing embedding\nalgorithms that strive to eliminate the impact of sensitive information's\nproperties on the generation process, CDEA leverages sensitive information's\nproperties. It enhances the selection frequency of high-probability candidate\nwords in the candidate pool based on general statistical properties at the\ncharacter level and grouping methods based on power-law distributions, while\nreducing the selection frequency of low-probability candidate words in the\ncandidate pool. Furthermore, to ensure the effective transformation of\nsensitive information in long sequences, we also introduce the XLNet model.\nExperimental results demonstrate that the combination of CDEA and XLNet\nsignificantly improves the quality of generated steganographic text,\nparticularly in terms of perceptual-imperceptibility.", "published": "2025-05-02 03:39:49", "link": "http://arxiv.org/abs/2505.00977v1", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Attack and defense techniques in large language models: A survey and new perspectives", "abstract": "Large Language Models (LLMs) have become central to numerous natural language\nprocessing tasks, but their vulnerabilities present significant security and\nethical challenges. This systematic survey explores the evolving landscape of\nattack and defense techniques in LLMs. We classify attacks into adversarial\nprompt attack, optimized attacks, model theft, as well as attacks on\napplication of LLMs, detailing their mechanisms and implications. Consequently,\nwe analyze defense strategies, including prevention-based and detection-based\ndefense methods. Although advances have been made, challenges remain to adapt\nto the dynamic threat landscape, balance usability with robustness, and address\nresource constraints in defense implementation. We highlight open problems,\nincluding the need for adaptive scalable defenses, explainable security\ntechniques, and standardized evaluation frameworks. This survey provides\nactionable insights and directions for developing secure and resilient LLMs,\nemphasizing the importance of interdisciplinary collaboration and ethical\nconsiderations to mitigate risks in real-world applications.", "published": "2025-05-02 03:37:52", "link": "http://arxiv.org/abs/2505.00976v1", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Llama-Nemotron: Efficient Reasoning Models", "abstract": "We introduce the Llama-Nemotron series of models, an open family of\nheterogeneous reasoning models that deliver exceptional reasoning capabilities,\ninference efficiency, and an open license for enterprise use. The family comes\nin three sizes -- Nano (8B), Super (49B), and Ultra (253B) -- and performs\ncompetitively with state-of-the-art reasoning models such as DeepSeek-R1 while\noffering superior inference throughput and memory efficiency. In this report,\nwe discuss the training procedure for these models, which entails using neural\narchitecture search from Llama 3 models for accelerated inference, knowledge\ndistillation, and continued pretraining, followed by a reasoning-focused\npost-training stage consisting of two main parts: supervised fine-tuning and\nlarge scale reinforcement learning. Llama-Nemotron models are the first\nopen-source models to support a dynamic reasoning toggle, allowing users to\nswitch between standard chat and reasoning modes during inference. To further\nsupport open research and facilitate model development, we provide the\nfollowing resources: 1. We release the Llama-Nemotron reasoning models --\nLN-Nano, LN-Super, and LN-Ultra -- under the commercially permissive NVIDIA\nOpen Model License Agreement. 2. We release the complete post-training dataset:\nLlama-Nemotron-Post-Training-Dataset. 3. We also release our training\ncodebases: NeMo, NeMo-Aligner, and Megatron-LM.", "published": "2025-05-02 01:35:35", "link": "http://arxiv.org/abs/2505.00949v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Large Language Model-Driven Dynamic Assessment of Grammatical Accuracy in English Language Learner Writing", "abstract": "This study investigates the potential for Large Language Models (LLMs) to\nscale-up Dynamic Assessment (DA). To facilitate such an investigation, we first\ndeveloped DynaWrite-a modular, microservices-based grammatical tutoring\napplication which supports multiple LLMs to generate dynamic feedback to\nlearners of English. Initial testing of 21 LLMs, revealed GPT-4o and neural\nchat to have the most potential to scale-up DA in the language learning\nclassroom. Further testing of these two candidates found both models performed\nsimilarly in their ability to accurately identify grammatical errors in user\nsentences. However, GPT-4o consistently outperformed neural chat in the quality\nof its DA by generating clear, consistent, and progressively explicit hints.\nReal-time responsiveness and system stability were also confirmed through\ndetailed performance testing, with GPT-4o exhibiting sufficient speed and\nstability. This study shows that LLMs can be used to scale-up dynamic\nassessment and thus enable dynamic assessment to be delivered to larger groups\nthan possible in traditional teacher-learner settings.", "published": "2025-05-02 00:19:50", "link": "http://arxiv.org/abs/2505.00931v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "How Transformers Learn Regular Language Recognition: A Theoretical Study on Training Dynamics and Implicit Bias", "abstract": "Language recognition tasks are fundamental in natural language processing\n(NLP) and have been widely used to benchmark the performance of large language\nmodels (LLMs). These tasks also play a crucial role in explaining the working\nmechanisms of transformers. In this work, we focus on two representative tasks\nin the category of regular language recognition, known as `even pairs' and\n`parity check', the aim of which is to determine whether the occurrences of\ncertain subsequences in a given sequence are even. Our goal is to explore how a\none-layer transformer, consisting of an attention layer followed by a linear\nlayer, learns to solve these tasks by theoretically analyzing its training\ndynamics under gradient descent. While even pairs can be solved directly by a\none-layer transformer, parity check need to be solved by integrating\nChain-of-Thought (CoT), either into the inference stage of a transformer\nwell-trained for the even pairs task, or into the training of a one-layer\ntransformer. For both problems, our analysis shows that the joint training of\nattention and linear layers exhibits two distinct phases. In the first phase,\nthe attention layer grows rapidly, mapping data sequences into separable\nvectors. In the second phase, the attention layer becomes stable, while the\nlinear layer grows logarithmically and approaches in direction to a max-margin\nhyperplane that correctly separates the attention layer outputs into positive\nand negative samples, and the loss decreases at a rate of $O(1/t)$. Our\nexperiments validate those theoretical results.", "published": "2025-05-02 00:07:35", "link": "http://arxiv.org/abs/2505.00926v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "GENMO: A GENeralist Model for Human MOtion", "abstract": "Human motion modeling traditionally separates motion generation and\nestimation into distinct tasks with specialized models. Motion generation\nmodels focus on creating diverse, realistic motions from inputs like text,\naudio, or keyframes, while motion estimation models aim to reconstruct accurate\nmotion trajectories from observations like videos. Despite sharing underlying\nrepresentations of temporal dynamics and kinematics, this separation limits\nknowledge transfer between tasks and requires maintaining separate models. We\npresent GENMO, a unified Generalist Model for Human Motion that bridges motion\nestimation and generation in a single framework. Our key insight is to\nreformulate motion estimation as constrained motion generation, where the\noutput motion must precisely satisfy observed conditioning signals. Leveraging\nthe synergy between regression and diffusion, GENMO achieves accurate global\nmotion estimation while enabling diverse motion generation. We also introduce\nan estimation-guided training objective that exploits in-the-wild videos with\n2D annotations and text descriptions to enhance generative diversity.\nFurthermore, our novel architecture handles variable-length motions and mixed\nmultimodal conditions (text, audio, video) at different time intervals,\noffering flexible control. This unified approach creates synergistic benefits:\ngenerative priors improve estimated motions under challenging conditions like\nocclusions, while diverse video data enhances generation capabilities.\nExtensive experiments demonstrate GENMO's effectiveness as a generalist\nframework that successfully handles multiple human motion tasks within a single\nmodel.", "published": "2025-05-02 17:59:55", "link": "http://arxiv.org/abs/2505.01425v1", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.LG", "cs.RO"], "primary_category": "cs.GR"}
{"title": "SIME: Enhancing Policy Self-Improvement with Modal-level Exploration", "abstract": "Self-improvement requires robotic systems to initially learn from\nhuman-provided data and then gradually enhance their capabilities through\ninteraction with the environment. This is similar to how humans improve their\nskills through continuous practice. However, achieving effective\nself-improvement is challenging, primarily because robots tend to repeat their\nexisting abilities during interactions, often failing to generate new, valuable\ndata for learning. In this paper, we identify the key to successful\nself-improvement: modal-level exploration and data selection. By incorporating\na modal-level exploration mechanism during policy execution, the robot can\nproduce more diverse and multi-modal interactions. At the same time, we select\nthe most valuable trials and high-quality segments from these interactions for\nlearning. We successfully demonstrate effective robot self-improvement on both\nsimulation benchmarks and real-world experiments. The capability for\nself-improvement will enable us to develop more robust and high-success-rate\nrobotic control strategies at a lower cost. Our code and experiment scripts are\navailable at https://ericjin2002.github.io/SIME/", "published": "2025-05-02 17:13:03", "link": "http://arxiv.org/abs/2505.01396v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Multimodal Doctor-in-the-Loop: A Clinically-Guided Explainable Framework for Predicting Pathological Response in Non-Small Cell Lung Cancer", "abstract": "This study proposes a novel approach combining Multimodal Deep Learning with\nintrinsic eXplainable Artificial Intelligence techniques to predict\npathological response in non-small cell lung cancer patients undergoing\nneoadjuvant therapy. Due to the limitations of existing radiomics and unimodal\ndeep learning approaches, we introduce an intermediate fusion strategy that\nintegrates imaging and clinical data, enabling efficient interaction between\ndata modalities. The proposed Multimodal Doctor-in-the-Loop method further\nenhances clinical relevance by embedding clinicians' domain knowledge directly\ninto the training process, guiding the model's focus gradually from broader\nlung regions to specific lesions. Results demonstrate improved predictive\naccuracy and explainability, providing insights into optimal data integration\nstrategies for clinical applications.", "published": "2025-05-02 16:57:37", "link": "http://arxiv.org/abs/2505.01390v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "FalconWing: An Open-Source Platform for Ultra-Light Fixed-Wing Aircraft Research", "abstract": "We present FalconWing -- an open-source, ultra-lightweight (150 g) fixed-wing\nplatform for autonomy research. The hardware platform integrates a small\ncamera, a standard airframe, offboard computation, and radio communication for\nmanual overrides. We demonstrate FalconWing's capabilities by developing and\ndeploying a purely vision-based control policy for autonomous landing (without\nIMU or motion capture) using a novel real-to-sim-to-real learning approach. Our\nlearning approach: (1) constructs a photorealistic simulation environment via\n3D Gaussian splatting trained on real-world images; (2) identifies nonlinear\ndynamics from vision-estimated real-flight data; and (3) trains a multi-modal\nVision Transformer (ViT) policy through simulation-only imitation learning. The\nViT architecture fuses single RGB image with the history of control actions via\nself-attention, preserving temporal context while maintaining real-time 20 Hz\ninference. When deployed zero-shot on the hardware platform, this policy\nachieves an 80% success rate in vision-based autonomous landings. Together with\nthe hardware specifications, we also open-source the system dynamics, the\nsoftware for photorealistic simulator and the learning approach.", "published": "2025-05-02 16:47:05", "link": "http://arxiv.org/abs/2505.01383v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Differentiable Nonlinear Model Predictive Control", "abstract": "The efficient computation of parametric solution sensitivities is a key\nchallenge in the integration of learning-enhanced methods with nonlinear model\npredictive control (MPC), as their availability is crucial for many learning\nalgorithms. While approaches presented in the machine learning community are\nlimited to convex or unconstrained formulations, this paper discusses the\ncomputation of solution sensitivities of general nonlinear programs (NLPs)\nusing the implicit function theorem (IFT) and smoothed optimality conditions\ntreated in interior-point methods (IPM). We detail sensitivity computation\nwithin a sequential quadratic programming (SQP) method which employs an IPM for\nthe quadratic subproblems. The publication is accompanied by an efficient\nopen-source implementation within the framework, providing both forward and\nadjoint sensitivities for general optimal control problems, achieving speedups\nexceeding 3x over the state-of-the-art solver mpc.pytorch.", "published": "2025-05-02 15:43:37", "link": "http://arxiv.org/abs/2505.01353v1", "categories": ["math.OC", "cs.AI", "cs.LG"], "primary_category": "math.OC"}
{"title": "BalancEdit: Dynamically Balancing the Generality-Locality Trade-off in Multi-modal Model Editing", "abstract": "Large multi-modal models inevitably decay over time as facts change and\npreviously learned information becomes outdated. Traditional approaches such as\nfine-tuning are often impractical for updating these models due to their size\nand complexity. Instead, direct knowledge editing within the models presents a\nmore viable solution. Current model editing techniques, however, typically\noverlook the unique influence ranges of different facts, leading to compromised\nmodel performance in terms of both generality and locality. To address this\nissue, we introduce the concept of the generality-locality trade-off in\nmulti-modal model editing. We develop a new model editing dataset named OKEDIT,\nspecifically designed to effectively evaluate this trade-off. Building on this\nfoundation, we propose BalancEdit, a novel method for balanced model editing\nthat dynamically achieves an optimal balance between generality and locality.\nBalancEdit utilizes a unique mechanism that generates both positive and\nnegative samples for each fact to accurately determine its influence scope and\nincorporates these insights into the model's latent space using a discrete,\nlocalized codebook of edits, without modifying the underlying model weights. To\nour knowledge, this is the first approach explicitly addressing the\ngenerality-locality trade-off in multi-modal model editing. Our comprehensive\nresults confirm the effectiveness of BalancEdit, demonstrating minimal\ntrade-offs while maintaining robust editing capabilities. Our code and dataset\nwill be available.", "published": "2025-05-02 15:31:32", "link": "http://arxiv.org/abs/2505.01343v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Constrained Network Adversarial Attacks: Validity, Robustness, and Transferability", "abstract": "While machine learning has significantly advanced Network Intrusion Detection\nSystems (NIDS), particularly within IoT environments where devices generate\nlarge volumes of data and are increasingly susceptible to cyber threats, these\nmodels remain vulnerable to adversarial attacks. Our research reveals a\ncritical flaw in existing adversarial attack methodologies: the frequent\nviolation of domain-specific constraints, such as numerical and categorical\nlimits, inherent to IoT and network traffic. This leads to up to 80.3% of\nadversarial examples being invalid, significantly overstating real-world\nvulnerabilities. These invalid examples, though effective in fooling models, do\nnot represent feasible attacks within practical IoT deployments. Consequently,\nrelying on these results can mislead resource allocation for defense, inflating\nthe perceived susceptibility of IoT-enabled NIDS models to adversarial\nmanipulation. Furthermore, we demonstrate that simpler surrogate models like\nMulti-Layer Perceptron (MLP) generate more valid adversarial examples compared\nto complex architectures such as CNNs and LSTMs. Using the MLP as a surrogate,\nwe analyze the transferability of adversarial severity to other ML/DL models\ncommonly used in IoT contexts. This work underscores the importance of\nconsidering both domain constraints and model architecture when evaluating and\ndesigning robust ML/DL models for security-critical IoT and network\napplications.", "published": "2025-05-02 15:01:42", "link": "http://arxiv.org/abs/2505.01328v1", "categories": ["cs.CR", "cs.AI", "cs.NI"], "primary_category": "cs.CR"}
{"title": "Enhancing SPARQL Query Rewriting for Complex Ontology Alignments", "abstract": "SPARQL query rewriting is a fundamental mechanism for uniformly querying\nheterogeneous ontologies in the Linked Data Web. However, the complexity of\nontology alignments, particularly rich correspondences (c : c), makes this\nprocess challenging. Existing approaches primarily focus on simple (s : s) and\npartially complex ( s : c) alignments, thereby overlooking the challenges posed\nby more expressive alignments. Moreover, the intricate syntax of SPARQL\npresents a barrier for non-expert users seeking to fully exploit the knowledge\nencapsulated in ontologies. This article proposes an innovative approach for\nthe automatic rewriting of SPARQL queries from a source ontology to a target\nontology, based on a user's need expressed in natural language. It leverages\nthe principles of equivalence transitivity as well as the advanced capabilities\nof large language models such as GPT-4. By integrating these elements, this\napproach stands out for its ability to efficiently handle complex alignments,\nparticularly (c : c) correspondences , by fully exploiting their\nexpressiveness. Additionally, it facilitates access to aligned ontologies for\nusers unfamiliar with SPARQL, providing a flexible solution for querying\nheterogeneous data.", "published": "2025-05-02 14:38:13", "link": "http://arxiv.org/abs/2505.01309v1", "categories": ["cs.DB", "cs.AI"], "primary_category": "cs.DB"}
{"title": "Document Retrieval Augmented Fine-Tuning (DRAFT) for safety-critical software assessments", "abstract": "Safety critical software assessment requires robust assessment against\ncomplex regulatory frameworks, a process traditionally limited by manual\nevaluation. This paper presents Document Retrieval-Augmented Fine-Tuning\n(DRAFT), a novel approach that enhances the capabilities of a large language\nmodel (LLM) for safety-critical compliance assessment. DRAFT builds upon\nexisting Retrieval-Augmented Generation (RAG) techniques by introducing a novel\nfine-tuning framework that accommodates our dual-retrieval architecture, which\nsimultaneously accesses both software documentation and applicable reference\nstandards. To fine-tune DRAFT, we develop a semi-automated dataset generation\nmethodology that incorporates variable numbers of relevant documents with\nmeaningful distractors, closely mirroring real-world assessment scenarios.\nExperiments with GPT-4o-mini demonstrate a 7% improvement in correctness over\nthe baseline model, with qualitative improvements in evidence handling,\nresponse structure, and domain-specific reasoning. DRAFT represents a practical\napproach to improving compliance assessment systems while maintaining the\ntransparency and evidence-based reasoning essential in regulatory domains.", "published": "2025-05-02 14:34:33", "link": "http://arxiv.org/abs/2505.01307v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Early Detection of Patient Deterioration from Real-Time Wearable Monitoring System", "abstract": "Early detection of patient deterioration is crucial for reducing mortality\nrates. Heart rate data has shown promise in assessing patient health, and\nwearable devices offer a cost-effective solution for real-time monitoring.\nHowever, extracting meaningful insights from diverse heart rate data and\nhandling missing values in wearable device data remain key challenges. To\naddress these challenges, we propose TARL, an innovative approach that models\nthe structural relationships of representative subsequences, known as\nshapelets, in heart rate time series. TARL creates a shapelet-transition\nknowledge graph to model shapelet dynamics in heart rate time series,\nindicating illness progression and potential future changes. We further\nintroduce a transition-aware knowledge embedding to reinforce relationships\namong shapelets and quantify the impact of missing values, enabling the\nformulation of comprehensive heart rate representations. These representations\ncapture explanatory structures and predict future heart rate trends, aiding\nearly illness detection. We collaborate with physicians and nurses to gather\nICU patient heart rate data from wearables and diagnostic metrics assessing\nillness severity for evaluating deterioration. Experiments on real-world ICU\ndata demonstrate that TARL achieves both high reliability and early detection.\nA case study further showcases TARL's explainable detection process,\nhighlighting its potential as an AI-driven tool to assist clinicians in\nrecognizing early signs of patient deterioration.", "published": "2025-05-02 14:32:44", "link": "http://arxiv.org/abs/2505.01305v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "ViSA-Flow: Accelerating Robot Skill Learning via Large-Scale Video Semantic Action Flow", "abstract": "One of the central challenges preventing robots from acquiring complex\nmanipulation skills is the prohibitive cost of collecting large-scale robot\ndemonstrations. In contrast, humans are able to learn efficiently by watching\nothers interact with their environment. To bridge this gap, we introduce\nsemantic action flow as a core intermediate representation capturing the\nessential spatio-temporal manipulator-object interactions, invariant to\nsuperficial visual differences. We present ViSA-Flow, a framework that learns\nthis representation self-supervised from unlabeled large-scale video data.\nFirst, a generative model is pre-trained on semantic action flows automatically\nextracted from large-scale human-object interaction video data, learning a\nrobust prior over manipulation structure. Second, this prior is efficiently\nadapted to a target robot by fine-tuning on a small set of robot demonstrations\nprocessed through the same semantic abstraction pipeline. We demonstrate\nthrough extensive experiments on the CALVIN benchmark and real-world tasks that\nViSA-Flow achieves state-of-the-art performance, particularly in low-data\nregimes, outperforming prior methods by effectively transferring knowledge from\nhuman video observation to robotic execution. Videos are available at\nhttps://visaflow-web.github.io/ViSAFLOW.", "published": "2025-05-02 14:03:06", "link": "http://arxiv.org/abs/2505.01288v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "2DXformer: Dual Transformers for Wind Power Forecasting with Dual Exogenous Variables", "abstract": "Accurate wind power forecasting can help formulate scientific dispatch plans,\nwhich is of great significance for maintaining the safety, stability, and\nefficient operation of the power system. In recent years, wind power\nforecasting methods based on deep learning have focused on extracting the\nspatiotemporal correlations among data, achieving significant improvements in\nforecasting accuracy. However, they exhibit two limitations. First, there is a\nlack of modeling for the inter-variable relationships, which limits the\naccuracy of the forecasts. Second, by treating endogenous and exogenous\nvariables equally, it leads to unnecessary interactions between the endogenous\nand exogenous variables, increasing the complexity of the model. In this paper,\nwe propose the 2DXformer, which, building upon the previous work's focus on\nspatiotemporal correlations, addresses the aforementioned two limitations.\nSpecifically, we classify the inputs of the model into three types: exogenous\nstatic variables, exogenous dynamic variables, and endogenous variables. First,\nwe embed these variables as variable tokens in a channel-independent manner.\nThen, we use the attention mechanism to capture the correlations among\nexogenous variables. Finally, we employ a multi-layer perceptron with residual\nconnections to model the impact of exogenous variables on endogenous variables.\nExperimental results on two real-world large-scale datasets indicate that our\nproposed 2DXformer can further improve the performance of wind power\nforecasting. The code is available in this repository:\n\\href{https://github.com/jseaj/2DXformer}{https://github.com/jseaj/2DXformer}.", "published": "2025-05-02 14:00:48", "link": "http://arxiv.org/abs/2505.01286v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Reduced-order structure-property linkages for stochastic metamaterials", "abstract": "The capabilities of additive manufacturing have facilitated the design and\nproduction of mechanical metamaterials with diverse unit cell geometries.\nEstablishing linkages between the vast design space of unit cells and their\neffective mechanical properties is critical for the efficient design and\nperformance evaluation of such metamaterials. However, physics-based\nsimulations of metamaterial unit cells across the entire design space are\ncomputationally expensive, necessitating a materials informatics framework to\nefficiently capture complex structure-property relationships. In this work,\nprincipal component analysis of 2-point correlation functions is performed to\nextract the salient features from a large dataset of randomly generated 2D\nmetamaterials. Physics-based simulations are performed using a fast Fourier\ntransform (FFT)-based homogenization approach to efficiently compute the\nhomogenized effective elastic stiffness across the extensive unit cell designs.\nSubsequently, Gaussian process regression is used to generate reduced-order\nsurrogates, mapping unit cell designs to their homogenized effective elastic\nconstant. It is demonstrated that the adopted workflow enables a high-value\nlow-dimensional representation of the voluminous stochastic metamaterial\ndataset, facilitating the construction of robust structure-property maps.\nFinally, an uncertainty-based active learning framework is utilized to train a\nsurrogate model with a significantly smaller number of data points compared to\nthe original full dataset. It is shown that a dataset as small as $0.61\\%$ of\nthe entire dataset is sufficient to generate accurate and robust\nstructure-property maps.", "published": "2025-05-02 13:58:47", "link": "http://arxiv.org/abs/2505.01283v1", "categories": ["cs.CE", "cs.AI", "cs.LG"], "primary_category": "cs.CE"}
{"title": "A Physics-preserved Transfer Learning Method for Differential Equations", "abstract": "While data-driven methods such as neural operator have achieved great success\nin solving differential equations (DEs), they suffer from domain shift problems\ncaused by different learning environments (with data bias or equation changes),\nwhich can be alleviated by transfer learning (TL). However, existing TL methods\nadopted in DEs problems lack either generalizability in general DEs problems or\nphysics preservation during training. In this work, we focus on a general\ntransfer learning method that adaptively correct the domain shift and preserve\nphysical information. Mathematically, we characterize the data domain as\nproduct distribution and the essential problems as distribution bias and\noperator bias. A Physics-preserved Optimal Tensor Transport (POTT) method that\nsimultaneously admits generalizability to common DEs and physics preservation\nof specific problem is proposed to adapt the data-driven model to target domain\nutilizing the push-forward distribution induced by the POTT map. Extensive\nexperiments demonstrate the superior performance, generalizability and physics\npreservation of the proposed POTT method.", "published": "2025-05-02 13:58:36", "link": "http://arxiv.org/abs/2505.01281v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Enhancing Obsolescence Forecasting with Deep Generative Data Augmentation: A Semi-Supervised Framework for Low-Data Industrial Applications", "abstract": "The challenge of electronic component obsolescence is particularly critical\nin systems with long life cycles. Various obsolescence management methods are\nemployed to mitigate its impact, with obsolescence forecasting being a highly\nsought-after and prominent approach. As a result, numerous machine\nlearning-based forecasting methods have been proposed. However, machine\nlearning models require a substantial amount of relevant data to achieve high\nprecision, which is lacking in the current obsolescence landscape in some\nsituations. This work introduces a novel framework for obsolescence forecasting\nbased on deep learning. The proposed framework solves the lack of available\ndata through deep generative modeling, where new obsolescence cases are\ngenerated and used to augment the training dataset. The augmented dataset is\nthen used to train a classical machine learning-based obsolescence forecasting\nmodel. To train classical forecasting models using augmented datasets, existing\nclassical supervised-learning classifiers are adapted for semi-supervised\nlearning within this framework. The proposed framework demonstrates\nstate-of-the-art results on benchmarking datasets.", "published": "2025-05-02 13:28:50", "link": "http://arxiv.org/abs/2505.01261v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Exploring the Impact of Explainable AI and Cognitive Capabilities on Users' Decisions", "abstract": "Artificial Intelligence (AI) systems are increasingly used for\ndecision-making across domains, raising debates over the information and\nexplanations they should provide. Most research on Explainable AI (XAI) has\nfocused on feature-based explanations, with less attention on alternative\nstyles. Personality traits like the Need for Cognition (NFC) can also lead to\ndifferent decision-making outcomes among low and high NFC individuals. We\ninvestigated how presenting AI information (prediction, confidence, and\naccuracy) and different explanation styles (example-based, feature-based,\nrule-based, and counterfactual) affect accuracy, reliance on AI, and cognitive\nload in a loan application scenario. We also examined low and high NFC\nindividuals' differences in prioritizing XAI interface elements (loan\nattributes, AI information, and explanations), accuracy, and cognitive load.\nOur findings show that high AI confidence significantly increases reliance on\nAI while reducing cognitive load. Feature-based explanations did not enhance\naccuracy compared to other conditions. Although counterfactual explanations\nwere less understandable, they enhanced overall accuracy, increasing reliance\non AI and reducing cognitive load when AI predictions were correct. Both low\nand high NFC individuals prioritized explanations after loan attributes,\nleaving AI information as the least important. However, we found no significant\ndifferences between low and high NFC groups in accuracy or cognitive load,\nraising questions about the role of personality traits in AI-assisted\ndecision-making. These findings highlight the need for user-centric\npersonalization in XAI interfaces, incorporating diverse explanation styles and\nexploring multiple personality traits and other user characteristics to\noptimize human-AI collaboration.", "published": "2025-05-02 11:30:53", "link": "http://arxiv.org/abs/2505.01192v1", "categories": ["cs.AI", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Secure Cluster-Based Hierarchical Federated Learning in Vehicular Networks", "abstract": "Hierarchical Federated Learning (HFL) has recently emerged as a promising\nsolution for intelligent decision-making in vehicular networks, helping to\naddress challenges such as limited communication resources, high vehicle\nmobility, and data heterogeneity. However, HFL remains vulnerable to\nadversarial and unreliable vehicles, whose misleading updates can significantly\ncompromise the integrity and convergence of the global model. To address these\nchallenges, we propose a novel defense framework that integrates dynamic\nvehicle selection with robust anomaly detection within a cluster-based HFL\narchitecture, specifically designed to counter Gaussian noise and gradient\nascent attacks. The framework performs a comprehensive reliability assessment\nfor each vehicle by evaluating historical accuracy, contribution frequency, and\nanomaly records. Anomaly detection combines Z-score and cosine similarity\nanalyses on model updates to identify both statistical outliers and directional\ndeviations in model updates. To further refine detection, an adaptive\nthresholding mechanism is incorporated into the cosine similarity metric,\ndynamically adjusting the threshold based on the historical accuracy of each\nvehicle to enforce stricter standards for consistently high-performing\nvehicles. In addition, a weighted gradient averaging mechanism is implemented,\nwhich assigns higher weights to gradient updates from more trustworthy\nvehicles. To defend against coordinated attacks, a cross-cluster consistency\ncheck is applied to identify collaborative attacks in which multiple\ncompromised clusters coordinate misleading updates. Together, these mechanisms\nform a multi-level defense strategy to filter out malicious contributions\neffectively. Simulation results show that the proposed algorithm significantly\nreduces convergence time compared to benchmark methods across both 1-hop and\n3-hop topologies.", "published": "2025-05-02 11:01:00", "link": "http://arxiv.org/abs/2505.01186v1", "categories": ["cs.CR", "cs.AI", "cs.DC", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.CR"}
{"title": "EnviKal-Loc: Sub-10m Indoor LoRaWAN Localization using an Environmental-Aware Path Loss and Adaptive RSSI Smoothing", "abstract": "LoRaWAN technology's extensive coverage positions it as a strong contender\nfor large-scale IoT deployments. However, achieving sub-10 m accuracy in indoor\nlocalization remains challenging due to complex environmental conditions,\nmultipath fading, and transient obstructions. This paper proposes a lightweight\nbut robust approach combining adaptive filtering with an extended log-distance,\nmulti-wall path loss and shadowing (PLS) model. Our methodology augments\nconventional models with critical LoRaWAN parameters (received signal strength\nindicator (RSSI), frequency, and signal-to-noise ratio (SNR)) and dynamic\nenvironmental indicators (temperature, humidity, carbon dioxide, particulate\nmatter, and barometric pressure). An adaptive Kalman filter reduces RSSI\nfluctuations, isolating persistent trends from momentary noise. Using a\nsix-month dataset of 1,328,334 field measurements, we evaluate three models:\nthe baseline COST 231 multi-wall model (MWM), the baseline model augmented with\nenvironmental parameters (MWM-EP), and a forward-only adaptive Kalman-filtered\nRSSI version of the latter (MWM-EP-KF). Results confirm that the MWM-EP-KF\nachieves a mean absolute error (MAE) of 5.81 m, outperforming both the MWM-EP\n(10.56 m) and the baseline MWM framework (17.98 m). Environmental augmentation\nreduces systematic errors by 41.22%, while Kalman filtering significantly\nenhances robustness under high RSSI volatility by 42.63%, on average across all\ndevices. These findings present an interpretable, efficient solution for\nprecise indoor LoRaWAN localization in dynamically changing environments.", "published": "2025-05-02 11:00:40", "link": "http://arxiv.org/abs/2505.01185v1", "categories": ["cs.NI", "cs.AI", "cs.LG", "eess.SP"], "primary_category": "cs.NI"}
{"title": "TSTMotion: Training-free Scene-awarenText-to-motion Generation", "abstract": "Text-to-motion generation has recently garnered significant research\ninterest, primarily focusing on generating human motion sequences in blank\nbackgrounds. However, human motions commonly occur within diverse 3D scenes,\nwhich has prompted exploration into scene-aware text-to-motion generation\nmethods. Yet, existing scene-aware methods often rely on large-scale\nground-truth motion sequences in diverse 3D scenes, which poses practical\nchallenges due to the expensive cost. To mitigate this challenge, we are the\nfirst to propose a \\textbf{T}raining-free \\textbf{S}cene-aware\n\\textbf{T}ext-to-\\textbf{Motion} framework, dubbed as \\textbf{TSTMotion}, that\nefficiently empowers pre-trained blank-background motion generators with the\nscene-aware capability. Specifically, conditioned on the given 3D scene and\ntext description, we adopt foundation models together to reason, predict and\nvalidate a scene-aware motion guidance. Then, the motion guidance is\nincorporated into the blank-background motion generators with two\nmodifications, resulting in scene-aware text-driven motion sequences. Extensive\nexperiments demonstrate the efficacy and generalizability of our proposed\nframework. We release our code in \\href{https://tstmotion.github.io/}{Project\nPage}.", "published": "2025-05-02 10:50:04", "link": "http://arxiv.org/abs/2505.01182v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Explainable AI Based Diagnosis of Poisoning Attacks in Evolutionary Swarms", "abstract": "Swarming systems, such as for example multi-drone networks, excel at\ncooperative tasks like monitoring, surveillance, or disaster assistance in\ncritical environments, where autonomous agents make decentralized decisions in\norder to fulfill team-level objectives in a robust and efficient manner.\nUnfortunately, team-level coordinated strategies in the wild are vulnerable to\ndata poisoning attacks, resulting in either inaccurate coordination or\nadversarial behavior among the agents. To address this challenge, we contribute\na framework that investigates the effects of such data poisoning attacks, using\nexplainable AI methods. We model the interaction among agents using\nevolutionary intelligence, where an optimal coalition strategically emerges to\nperform coordinated tasks. Then, through a rigorous evaluation, the swarm model\nis systematically poisoned using data manipulation attacks. We showcase the\napplicability of explainable AI methods to quantify the effects of poisoning on\nthe team strategy and extract footprint characterizations that enable\ndiagnosing. Our findings indicate that when the model is poisoned above 10%,\nnon-optimal strategies resulting in inefficient cooperation can be identified.", "published": "2025-05-02 10:48:40", "link": "http://arxiv.org/abs/2505.01181v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "LLM Security: Vulnerabilities, Attacks, Defenses, and Countermeasures", "abstract": "As large language models (LLMs) continue to evolve, it is critical to assess\nthe security threats and vulnerabilities that may arise both during their\ntraining phase and after models have been deployed. This survey seeks to define\nand categorize the various attacks targeting LLMs, distinguishing between those\nthat occur during the training phase and those that affect already trained\nmodels. A thorough analysis of these attacks is presented, alongside an\nexploration of defense mechanisms designed to mitigate such threats. Defenses\nare classified into two primary categories: prevention-based and\ndetection-based defenses. Furthermore, our survey summarizes possible attacks\nand their corresponding defense strategies. It also provides an evaluation of\nthe effectiveness of the known defense mechanisms for the different security\nthreats. Our survey aims to offer a structured framework for securing LLMs,\nwhile also identifying areas that require further research to improve and\nstrengthen defenses against emerging security challenges.", "published": "2025-05-02 10:35:26", "link": "http://arxiv.org/abs/2505.01177v1", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.NE"], "primary_category": "cs.CR"}
{"title": "Distilling Two-Timed Flow Models by Separately Matching Initial and Terminal Velocities", "abstract": "A flow matching model learns a time-dependent vector field $v_t(x)$ that\ngenerates a probability path $\\{ p_t \\}_{0 \\leq t \\leq 1}$ that interpolates\nbetween a well-known noise distribution ($p_0$) and the data distribution\n($p_1$). It can be distilled into a \\emph{two-timed flow model} (TTFM)\n$\\phi_{s,x}(t)$ that can transform a sample belonging to the distribution at an\ninitial time $s$ to another belonging to the distribution at a terminal time\n$t$ in one function evaluation. We present a new loss function for TTFM\ndistillation called the \\emph{initial/terminal velocity matching} (ITVM) loss\nthat extends the Lagrangian Flow Map Distillation (LFMD) loss proposed by Boffi\net al. by adding redundant terms to match the initial velocities at time $s$,\nremoving the derivative from the terminal velocity term at time $t$, and using\na version of the model under training, stabilized by exponential moving\naveraging (EMA), to compute the target terminal average velocity. Preliminary\nexperiments show that our loss leads to better few-step generation performance\non multiple types of datasets and model architectures over baselines.", "published": "2025-05-02 10:17:49", "link": "http://arxiv.org/abs/2505.01169v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Harmonizing Intra-coherence and Inter-divergence in Ensemble Attacks for Adversarial Transferability", "abstract": "The development of model ensemble attacks has significantly improved the\ntransferability of adversarial examples, but this progress also poses severe\nthreats to the security of deep neural networks. Existing methods, however,\nface two critical challenges: insufficient capture of shared gradient\ndirections across models and a lack of adaptive weight allocation mechanisms.\nTo address these issues, we propose a novel method Harmonized Ensemble for\nAdversarial Transferability (HEAT), which introduces domain generalization into\nadversarial example generation for the first time. HEAT consists of two key\nmodules: Consensus Gradient Direction Synthesizer, which uses Singular Value\nDecomposition to synthesize shared gradient directions; and Dual-Harmony Weight\nOrchestrator which dynamically balances intra-domain coherence, stabilizing\ngradients within individual models, and inter-domain diversity, enhancing\ntransferability across models. Experimental results demonstrate that HEAT\nsignificantly outperforms existing methods across various datasets and\nsettings, offering a new perspective and direction for adversarial attack\nresearch.", "published": "2025-05-02 10:17:33", "link": "http://arxiv.org/abs/2505.01168v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Risk Analysis and Design Against Adversarial Actions", "abstract": "Learning models capable of providing reliable predictions in the face of\nadversarial actions has become a central focus of the machine learning\ncommunity in recent years. This challenge arises from observing that data\nencountered at deployment time often deviate from the conditions under which\nthe model was trained. In this paper, we address deployment-time adversarial\nactions and propose a versatile, well-principled framework to evaluate the\nmodel's robustness against attacks of diverse types and intensities. While we\ninitially focus on Support Vector Regression (SVR), the proposed approach\nextends naturally to the broad domain of learning via relaxed optimization\ntechniques. Our results enable an assessment of the model vulnerability without\nrequiring additional test data and operate in a distribution-free setup. These\nresults not only provide a tool to enhance trust in the model's applicability\nbut also aid in selecting among competing alternatives. Later in the paper, we\nshow that our findings also offer useful insights for establishing new results\nwithin the out-of-distribution framework.", "published": "2025-05-02 09:16:44", "link": "http://arxiv.org/abs/2505.01130v1", "categories": ["cs.LG", "cs.AI", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Self-Supervision Enhances Instance-based Multiple Instance Learning Methods in Digital Pathology: A Benchmark Study", "abstract": "Multiple Instance Learning (MIL) has emerged as the best solution for Whole\nSlide Image (WSI) classification. It consists of dividing each slide into\npatches, which are treated as a bag of instances labeled with a global label.\nMIL includes two main approaches: instance-based and embedding-based. In the\nformer, each patch is classified independently, and then the patch scores are\naggregated to predict the bag label. In the latter, bag classification is\nperformed after aggregating patch embeddings. Even if instance-based methods\nare naturally more interpretable, embedding-based MILs have usually been\npreferred in the past due to their robustness to poor feature extractors.\nHowever, recently, the quality of feature embeddings has drastically increased\nusing self-supervised learning (SSL). Nevertheless, many authors continue to\nendorse the superiority of embedding-based MIL. To investigate this further, we\nconduct 710 experiments across 4 datasets, comparing 10 MIL strategies, 6\nself-supervised methods with 4 backbones, 4 foundation models, and various\npathology-adapted techniques. Furthermore, we introduce 4 instance-based MIL\nmethods never used before in the pathology domain. Through these extensive\nexperiments, we show that with a good SSL feature extractor, simple\ninstance-based MILs, with very few parameters, obtain similar or better\nperformance than complex, state-of-the-art (SOTA) embedding-based MIL methods,\nsetting new SOTA results on the BRACS and Camelyon16 datasets. Since simple\ninstance-based MIL methods are naturally more interpretable and explainable to\nclinicians, our results suggest that more effort should be put into\nwell-adapted SSL methods for WSI rather than into complex embedding-based MIL\nmethods.", "published": "2025-05-02 08:43:50", "link": "http://arxiv.org/abs/2505.01109v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Multi-Objective Reinforcement Learning for Water Management", "abstract": "Many real-world problems (e.g., resource management, autonomous driving, drug\ndiscovery) require optimizing multiple, conflicting objectives. Multi-objective\nreinforcement learning (MORL) extends classic reinforcement learning to handle\nmultiple objectives simultaneously, yielding a set of policies that capture\nvarious trade-offs. However, the MORL field lacks complex, realistic\nenvironments and benchmarks. We introduce a water resource (Nile river basin)\nmanagement case study and model it as a MORL environment. We then benchmark\nexisting MORL algorithms on this task. Our results show that specialized water\nmanagement methods outperform state-of-the-art MORL approaches, underscoring\nthe scalability challenges MORL algorithms face in real-world scenarios.", "published": "2025-05-02 08:14:01", "link": "http://arxiv.org/abs/2505.01094v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Any-to-Any Vision-Language Model for Multimodal X-ray Imaging and Radiological Report Generation", "abstract": "Generative models have revolutionized Artificial Intelligence (AI),\nparticularly in multimodal applications. However, adapting these models to the\nmedical domain poses unique challenges due to the complexity of medical data\nand the stringent need for clinical accuracy. In this work, we introduce a\nframework specifically designed for multimodal medical data generation. By\nenabling the generation of multi-view chest X-rays and their associated\nclinical report, it bridges the gap between general-purpose vision-language\nmodels and the specialized requirements of healthcare. Leveraging the MIMIC-CXR\ndataset, the proposed framework shows superior performance in generating\nhigh-fidelity images and semantically coherent reports. Our quantitative\nevaluation reveals significant results in terms of FID and BLEU scores,\nshowcasing the quality of the generated data. Notably, our framework achieves\ncomparable or even superior performance compared to real data on downstream\ndisease classification tasks, underlining its potential as a tool for medical\nresearch and diagnostics. This study highlights the importance of\ndomain-specific adaptations in enhancing the relevance and utility of\ngenerative models for clinical applications, paving the way for future\nadvancements in synthetic multimodal medical data generation.", "published": "2025-05-02 08:07:24", "link": "http://arxiv.org/abs/2505.01091v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Artificial Intelligence in Government: Why People Feel They Lose Control", "abstract": "The use of Artificial Intelligence (AI) in public administration is expanding\nrapidly, moving from automating routine tasks to deploying generative and\nagentic systems that autonomously act on goals. While AI promises greater\nefficiency and responsiveness, its integration into government functions raises\nconcerns about fairness, transparency, and accountability. This article applies\nprincipal-agent theory (PAT) to conceptualize AI adoption as a special case of\ndelegation, highlighting three core tensions: assessability (can decisions be\nunderstood?), dependency (can the delegation be reversed?), and contestability\n(can decisions be challenged?). These structural challenges may lead to a\n\"failure-by-success\" dynamic, where early functional gains obscure long-term\nrisks to democratic legitimacy. To test this framework, we conducted a\npre-registered factorial survey experiment across tax, welfare, and law\nenforcement domains. Our findings show that although efficiency gains initially\nbolster trust, they simultaneously reduce citizens' perceived control. When the\nstructural risks come to the foreground, institutional trust and perceived\ncontrol both drop sharply, suggesting that hidden costs of AI adoption\nsignificantly shape public attitudes. The study demonstrates that PAT offers a\npowerful lens for understanding the institutional and political implications of\nAI in government, emphasizing the need for policymakers to address delegation\nrisks transparently to maintain public trust.", "published": "2025-05-02 07:46:41", "link": "http://arxiv.org/abs/2505.01085v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "MADIL: An MDL-based Framework for Efficient Program Synthesis in the ARC Benchmark", "abstract": "Artificial Intelligence (AI) has achieved remarkable success in specialized\ntasks but struggles with efficient skill acquisition and generalization. The\nAbstraction and Reasoning Corpus (ARC) benchmark evaluates intelligence based\non minimal training requirements. While Large Language Models (LLMs) have\nrecently improved ARC performance, they rely on extensive pre-training and high\ncomputational costs. We introduce MADIL (MDL-based AI), a novel approach\nleveraging the Minimum Description Length (MDL) principle for efficient\ninductive learning. MADIL performs pattern-based decomposition, enabling\nstructured generalization. While its performance (7% at ArcPrize 2024) remains\nbelow LLM-based methods, it offers greater efficiency and interpretability.\nThis paper details MADIL's methodology, its application to ARC, and\nexperimental evaluations.", "published": "2025-05-02 07:39:08", "link": "http://arxiv.org/abs/2505.01081v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Retrieval Augmented Learning: A Retrial-based Large Language Model Self-Supervised Learning and Autonomous Knowledge Generation", "abstract": "The lack of domain-specific data in the pre-training of Large Language Models\n(LLMs) severely limits LLM-based decision systems in specialized applications,\nwhile post-training a model in the scenarios requires significant computational\nresources. In this paper, we present Retrial-Augmented Learning (RAL), a\nreward-free self-supervised learning framework for LLMs that operates without\nmodel training. By developing Retrieval-Augmented Generation (RAG) into a\nmodule for organizing intermediate data, we realized a three-stage autonomous\nknowledge generation of proposing a hypothesis, validating the hypothesis, and\ngenerating the knowledge. The method is evaluated in the LLM-PySC2 environment,\na representative decision-making platform that combines sufficient complexity\nwith domain-specific knowledge requirements. Experiments demonstrate that the\nproposed method effectively reduces hallucination by generating and utilizing\nvalidated knowledge, and increases decision-making performance at an extremely\nlow cost. Meanwhile, the approach exhibits potential in\nout-of-distribution(OOD) tasks, robustness, and transferability, making it a\ncost-friendly but effective solution for decision-making problems and\nautonomous knowledge generation.", "published": "2025-05-02 07:25:01", "link": "http://arxiv.org/abs/2505.01073v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Improving Group Fairness in Knowledge Distillation via Laplace Approximation of Early Exits", "abstract": "Knowledge distillation (KD) has become a powerful tool for training compact\nstudent models using larger, pretrained teacher models, often requiring less\ndata and computational resources. Teacher models typically possess more layers\nand thus exhibit richer feature representations compared to their student\ncounterparts. Furthermore, student models tend to learn simpler, surface-level\nfeatures in their early layers. This discrepancy can increase errors in groups\nwhere labels spuriously correlate with specific input attributes, leading to a\ndecline in group fairness even when overall accuracy remains comparable to the\nteacher. To mitigate these challenges, Early-Exit Neural Networks (EENNs),\nwhich enable predictions at multiple intermediate layers, have been employed.\nConfidence margins derived from these early exits have been utilized to\nreweight both cross-entropy and distillation losses on a per-instance basis. In\nthis paper, we propose that leveraging Laplace approximation-based methods to\nobtain well-calibrated uncertainty estimates can also effectively reweight\nchallenging instances and improve group fairness. We hypothesize that Laplace\napproximation offers a more robust identification of difficult or ambiguous\ninstances compared to margin-based approaches. To validate our claims, we\nbenchmark our approach using a Bert-based model on the MultiNLI dataset.", "published": "2025-05-02 07:18:52", "link": "http://arxiv.org/abs/2505.01070v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "A Rusty Link in the AI Supply Chain: Detecting Evil Configurations in Model Repositories", "abstract": "Recent advancements in large language models (LLMs) have spurred the\ndevelopment of diverse AI applications from code generation and video editing\nto text generation; however, AI supply chains such as Hugging Face, which host\npretrained models and their associated configuration files contributed by the\npublic, face significant security challenges; in particular, configuration\nfiles originally intended to set up models by specifying parameters and initial\nsettings can be exploited to execute unauthorized code, yet research has\nlargely overlooked their security compared to that of the models themselves; in\nthis work, we present the first comprehensive study of malicious configurations\non Hugging Face, identifying three attack scenarios (file, website, and\nrepository operations) that expose inherent risks; to address these threats, we\nintroduce CONFIGSCAN, an LLM-based tool that analyzes configuration files in\nthe context of their associated runtime code and critical libraries,\neffectively detecting suspicious elements with low false positive rates and\nhigh accuracy; our extensive evaluation uncovers thousands of suspicious\nrepositories and configuration files, underscoring the urgent need for enhanced\nsecurity validation in AI model hosting platforms.", "published": "2025-05-02 07:16:20", "link": "http://arxiv.org/abs/2505.01067v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Good News for Script Kiddies? Evaluating Large Language Models for Automated Exploit Generation", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\ncode-related tasks, raising concerns about their potential for automated\nexploit generation (AEG). This paper presents the first systematic study on\nLLMs' effectiveness in AEG, evaluating both their cooperativeness and technical\nproficiency. To mitigate dataset bias, we introduce a benchmark with refactored\nversions of five software security labs. Additionally, we design an LLM-based\nattacker to systematically prompt LLMs for exploit generation. Our experiments\nreveal that GPT-4 and GPT-4o exhibit high cooperativeness, comparable to\nuncensored models, while Llama3 is the most resistant. However, no model\nsuccessfully generates exploits for refactored labs, though GPT-4o's minimal\nerrors highlight the potential for LLM-driven AEG advancements.", "published": "2025-05-02 07:15:22", "link": "http://arxiv.org/abs/2505.01065v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Model Tensor Planning", "abstract": "Sampling-based model predictive control (MPC) offers strong performance in\nnonlinear and contact-rich robotic tasks, yet often suffers from poor\nexploration due to locally greedy sampling schemes. We propose \\emph{Model\nTensor Planning} (MTP), a novel sampling-based MPC framework that introduces\nhigh-entropy control trajectory generation through structured tensor sampling.\nBy sampling over randomized multipartite graphs and interpolating control\ntrajectories with B-splines and Akima splines, MTP ensures smooth and globally\ndiverse control candidates. We further propose a simple $\\beta$-mixing strategy\nthat blends local exploitative and global exploratory samples within the\nmodified Cross-Entropy Method (CEM) update, balancing control refinement and\nexploration. Theoretically, we show that MTP achieves asymptotic path coverage\nand maximum entropy in the control trajectory space in the limit of infinite\ntensor depth and width.\n  Our implementation is fully vectorized using JAX and compatible with MuJoCo\nXLA, supporting \\emph{Just-in-time} (JIT) compilation and batched rollouts for\nreal-time control with online domain randomization. Through experiments on\nvarious challenging robotic tasks, ranging from dexterous in-hand manipulation\nto humanoid locomotion, we demonstrate that MTP outperforms standard MPC and\nevolutionary strategy baselines in task success and control robustness. Design\nand sensitivity ablations confirm the effectiveness of MTP tensor sampling\nstructure, spline interpolation choices, and mixing strategy. Altogether, MTP\noffers a scalable framework for robust exploration in model-based planning and\ncontrol.", "published": "2025-05-02 07:09:38", "link": "http://arxiv.org/abs/2505.01059v1", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Low-Precision Training of Large Language Models: Methods, Challenges, and Opportunities", "abstract": "Large language models (LLMs) have achieved impressive performance across\nvarious domains. However, the substantial hardware resources required for their\ntraining present a significant barrier to efficiency and scalability. To\nmitigate this challenge, low-precision training techniques have been widely\nadopted, leading to notable advancements in training efficiency. Despite these\ngains, low-precision training involves several components$\\unicode{x2013}$such\nas weights, activations, and gradients$\\unicode{x2013}$each of which can be\nrepresented in different numerical formats. The resulting diversity has created\na fragmented landscape in low-precision training research, making it difficult\nfor researchers to gain a unified overview of the field. This survey provides a\ncomprehensive review of existing low-precision training methods. To\nsystematically organize these approaches, we categorize them into three primary\ngroups based on their underlying numerical formats, which is a key factor\ninfluencing hardware compatibility, computational efficiency, and ease of\nreference for readers. The categories are: (1) fixed-point and integer-based\nmethods, (2) floating-point-based methods, and (3) customized format-based\nmethods. Additionally, we discuss quantization-aware training approaches, which\nshare key similarities with low-precision training during forward propagation.\nFinally, we highlight several promising research directions to advance this\nfield. A collection of papers discussed in this survey is provided in\nhttps://github.com/Hao840/Awesome-Low-Precision-Training.", "published": "2025-05-02 06:33:25", "link": "http://arxiv.org/abs/2505.01043v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Stagnation in Evolutionary Algorithms: Convergence $\\neq$ Optimality", "abstract": "In the evolutionary computation community, it is widely believed that\nstagnation impedes convergence in evolutionary algorithms, and that convergence\ninherently indicates optimality. However, this perspective is misleading. In\nthis study, it is the first to highlight that the stagnation of an individual\ncan actually facilitate the convergence of the entire population, and\nconvergence does not necessarily imply optimality, not even local optimality.\nConvergence alone is insufficient to ensure the effectiveness of evolutionary\nalgorithms. Several counterexamples are provided to illustrate this argument.", "published": "2025-05-02 06:19:09", "link": "http://arxiv.org/abs/2505.01036v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Adaptive Wizard for Removing Cross-Tier Misconfigurations in Active Directory", "abstract": "Security vulnerabilities in Windows Active Directory (AD) systems are\ntypically modeled using an attack graph and hardening AD systems involves an\niterative workflow: security teams propose an edge to remove, and IT operations\nteams manually review these fixes before implementing the removal. As\nverification requires significant manual effort, we formulate an Adaptive Path\nRemoval Problem to minimize the number of steps in this iterative removal\nprocess. In our model, a wizard proposes an attack path in each step and\npresents it as a set of multiple-choice options to the IT admin. The IT admin\nthen selects one edge from the proposed set to remove. This process continues\nuntil the target $t$ is disconnected from source $s$ or the number of proposed\npaths reaches $B$. The model aims to optimize the human effort by minimizing\nthe expected number of interactions between the IT admin and the security\nwizard. We first prove that the problem is $\\mathcal{\\#P}$-hard. We then\npropose a set of solutions including an exact algorithm, an approximate\nalgorithm, and several scalable heuristics. Our best heuristic, called DPR, can\noperate effectively on larger-scale graphs compared to the exact algorithm and\nconsistently outperforms the approximate algorithm across all graphs. We verify\nthe effectiveness of our algorithms on several synthetic AD graphs and an AD\nattack graph collected from a real organization.", "published": "2025-05-02 05:55:56", "link": "http://arxiv.org/abs/2505.01028v1", "categories": ["cs.AI", "cs.CR"], "primary_category": "cs.AI"}
{"title": "Fine-Tuning Without Forgetting: Adaptation of YOLOv8 Preserves COCO Performance", "abstract": "The success of large pre-trained object detectors hinges on their\nadaptability to diverse downstream tasks. While fine-tuning is the standard\nadaptation method, specializing these models for challenging fine-grained\ndomains necessitates careful consideration of feature granularity. The critical\nquestion remains: how deeply should the pre-trained backbone be fine-tuned to\noptimize for the specialized task without incurring catastrophic forgetting of\nthe original general capabilities? Addressing this, we present a systematic\nempirical study evaluating the impact of fine-tuning depth. We adapt a standard\nYOLOv8n model to a custom, fine-grained fruit detection dataset by\nprogressively unfreezing backbone layers (freeze points at layers 22, 15, and\n10) and training. Performance was rigorously evaluated on both the target fruit\ndataset and, using a dual-head evaluation architecture, on the original COCO\nvalidation set. Our results demonstrate unequivocally that deeper fine-tuning\n(unfreezing down to layer 10) yields substantial performance gains (e.g., +10\\%\nabsolute mAP50) on the fine-grained fruit task compared to only training the\nhead. Strikingly, this significant adaptation and specialization resulted in\nnegligible performance degradation (<0.1\\% absolute mAP difference) on the COCO\nbenchmark across all tested freeze levels. We conclude that adapting\nmid-to-late backbone features is highly effective for fine-grained\nspecialization. Critically, our results demonstrate this adaptation can be\nachieved without the commonly expected penalty of catastrophic forgetting,\npresenting a compelling case for exploring deeper fine-tuning strategies,\nparticularly when targeting complex domains or when maximizing specialized\nperformance is paramount.", "published": "2025-05-02 05:27:14", "link": "http://arxiv.org/abs/2505.01016v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Improving Large Language Model Planning with Action Sequence Similarity", "abstract": "Planning is essential for artificial intelligence systems to look ahead and\nproactively determine a course of actions to reach objectives in the virtual\nand real world. Recent work on large language models (LLMs) sheds light on\ntheir planning capability in various tasks. However, it remains unclear what\nsignals in the context influence the model performance. In this work, we\nexplore how to improve the model planning capability through in-context\nlearning (ICL), specifically, what signals can help select the exemplars.\nThrough extensive experiments, we observe that commonly used problem similarity\nmay result in false positives with drastically different plans, which can\nmislead the model. In response, we propose to sample and filter exemplars\nleveraging plan side action sequence similarity (AS). We propose GRASE-DC: a\ntwo-stage pipeline that first re-samples high AS exemplars and then curates the\nselected exemplars with dynamic clustering on AS to achieve a balance of\nrelevance and diversity. Our experimental result confirms that GRASE-DC\nachieves significant performance improvement on various planning tasks (up to\n~11-40 point absolute accuracy improvement with 27.3% fewer exemplars needed on\naverage). With GRASE-DC* + VAL, where we iteratively apply GRASE-DC with a\nvalidator, we are able to even boost the performance by 18.9% more.\n  Extensive analysis validates the consistent performance improvement of\nGRASE-DC with various backbone LLMs and on both classical planning and natural\nlanguage planning benchmarks. GRASE-DC can further boost the planning accuracy\nby ~24 absolute points on harder problems using simpler problems as exemplars\nover a random baseline. This demonstrates its ability to generalize to\nout-of-distribution problems.", "published": "2025-05-02 05:16:17", "link": "http://arxiv.org/abs/2505.01009v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Toward Data-centric Directed Graph Learning: An Entropy-driven Approach", "abstract": "The directed graph (digraph), as a generalization of undirected graphs,\nexhibits superior representation capability in modeling complex topology\nsystems and has garnered considerable attention in recent years. Despite the\nnotable efforts made by existing DiGraph Neural Networks (DiGNNs) to leverage\ndirected edges, they still fail to comprehensively delve into the abundant data\nknowledge concealed in the digraphs. This data-level limitation results in\nmodel-level sub-optimal predictive performance and underscores the necessity of\nfurther exploring the potential correlations between the directed edges\n(topology) and node profiles (feature and labels) from a data-centric\nperspective, thereby empowering model-centric neural networks with stronger\nencoding capabilities.\n  In this paper, we propose \\textbf{E}ntropy-driven \\textbf{D}igraph\nknowl\\textbf{E}dge distillatio\\textbf{N} (EDEN), which can serve as a\ndata-centric digraph learning paradigm or a model-agnostic hot-and-plug\ndata-centric Knowledge Distillation (KD) module. The core idea is to achieve\ndata-centric ML, guided by our proposed hierarchical encoding theory for\nstructured data. Specifically, EDEN first utilizes directed structural\nmeasurements from a topology perspective to construct a coarse-grained\nHierarchical Knowledge Tree (HKT). Subsequently, EDEN quantifies the mutual\ninformation of node profiles to refine knowledge flow in the HKT, enabling\ndata-centric KD supervision within model training. As a general framework, EDEN\ncan also naturally extend to undirected scenarios and demonstrate satisfactory\nperformance. In our experiments, EDEN has been widely evaluated on 14 (di)graph\ndatasets (homophily and heterophily) and across 4 downstream tasks. The results\ndemonstrate that EDEN attains SOTA performance and exhibits strong improvement\nfor prevalent (Di)GNNs.", "published": "2025-05-02 04:06:00", "link": "http://arxiv.org/abs/2505.00983v1", "categories": ["cs.LG", "cs.AI", "cs.DB", "cs.SI"], "primary_category": "cs.LG"}
{"title": "Seeking to Collide: Online Safety-Critical Scenario Generation for Autonomous Driving with Retrieval Augmented Large Language Models", "abstract": "Simulation-based testing is crucial for validating autonomous vehicles (AVs),\nyet existing scenario generation methods either overfit to common driving\npatterns or operate in an offline, non-interactive manner that fails to expose\nrare, safety-critical corner cases. In this paper, we introduce an online,\nretrieval-augmented large language model (LLM) framework for generating\nsafety-critical driving scenarios. Our method first employs an LLM-based\nbehavior analyzer to infer the most dangerous intent of the background vehicle\nfrom the observed state, then queries additional LLM agents to synthesize\nfeasible adversarial trajectories. To mitigate catastrophic forgetting and\naccelerate adaptation, we augment the framework with a dynamic memorization and\nretrieval bank of intent-planner pairs, automatically expanding its behavioral\nlibrary when novel intents arise. Evaluations using the Waymo Open Motion\nDataset demonstrate that our model reduces the mean minimum time-to-collision\nfrom 1.62 to 1.08 s and incurs a 75% collision rate, substantially\noutperforming baselines.", "published": "2025-05-02 03:22:00", "link": "http://arxiv.org/abs/2505.00972v1", "categories": ["cs.AI", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Tree-Sliced Wasserstein Distance with Nonlinear Projection", "abstract": "Tree-Sliced methods have recently emerged as an alternative to the\ntraditional Sliced Wasserstein (SW) distance, replacing one-dimensional lines\nwith tree-based metric spaces and incorporating a splitting mechanism for\nprojecting measures. This approach enhances the ability to capture the\ntopological structures of integration domains in Sliced Optimal Transport while\nmaintaining low computational costs. Building on this foundation, we propose a\nnovel nonlinear projectional framework for the Tree-Sliced Wasserstein (TSW)\ndistance, substituting the linear projections in earlier versions with general\nprojections, while ensuring the injectivity of the associated Radon Transform\nand preserving the well-definedness of the resulting metric. By designing\nappropriate projections, we construct efficient metrics for measures on both\nEuclidean spaces and spheres. Finally, we validate our proposed metric through\nextensive numerical experiments for Euclidean and spherical datasets.\nApplications include gradient flows, self-supervised learning, and generative\nmodels, where our methods demonstrate significant improvements over recent SW\nand TSW variants.", "published": "2025-05-02 03:06:25", "link": "http://arxiv.org/abs/2505.00968v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "CDFormer: Cross-Domain Few-Shot Object Detection Transformer Against Feature Confusion", "abstract": "Cross-domain few-shot object detection (CD-FSOD) aims to detect novel objects\nacross different domains with limited class instances. Feature confusion,\nincluding object-background confusion and object-object confusion, presents\nsignificant challenges in both cross-domain and few-shot settings. In this\nwork, we introduce CDFormer, a cross-domain few-shot object detection\ntransformer against feature confusion, to address these challenges. The method\nspecifically tackles feature confusion through two key modules:\nobject-background distinguishing (OBD) and object-object distinguishing (OOD).\nThe OBD module leverages a learnable background token to differentiate between\nobjects and background, while the OOD module enhances the distinction between\nobjects of different classes. Experimental results demonstrate that CDFormer\noutperforms previous state-of-the-art approaches, achieving 12.9% mAP, 11.0%\nmAP, and 10.4% mAP improvements under the 1/5/10 shot settings, respectively,\nwhen fine-tuned.", "published": "2025-05-02 00:46:25", "link": "http://arxiv.org/abs/2505.00938v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Autonomous Embodied Agents: When Robotics Meets Deep Learning Reasoning", "abstract": "The increase in available computing power and the Deep Learning revolution\nhave allowed the exploration of new topics and frontiers in Artificial\nIntelligence research. A new field called Embodied Artificial Intelligence,\nwhich places at the intersection of Computer Vision, Robotics, and Decision\nMaking, has been gaining importance during the last few years, as it aims to\nfoster the development of smart autonomous robots and their deployment in\nsociety. The recent availability of large collections of 3D models for\nphotorealistic robotic simulation has allowed faster and safe training of\nlearning-based agents for millions of frames and a careful evaluation of their\nbehavior before deploying the models on real robotic platforms. These\nintelligent agents are intended to perform a certain task in a possibly unknown\nenvironment. To this end, during the training in simulation, the agents learn\nto perform continuous interactions with the surroundings, such as gathering\ninformation from the environment, encoding and extracting useful cues for the\ntask, and performing actions towards the final goal; where every action of the\nagent influences the interactions. This dissertation follows the complete\ncreation process of embodied agents for indoor environments, from their concept\nto their implementation and deployment. We aim to contribute to research in\nEmbodied AI and autonomous agents, in order to foster future work in this\nfield. We present a detailed analysis of the procedure behind implementing an\nintelligent embodied agent, comprehending a thorough description of the current\nstate-of-the-art in literature, technical explanations of the proposed methods,\nand accurate experimental studies on relevant robotic tasks.", "published": "2025-05-02 00:43:28", "link": "http://arxiv.org/abs/2505.00935v1", "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "cs.RO"}
{"title": "A Self-Supervised Transformer for Unusable Shared Bike Detection", "abstract": "The rapid expansion of bike-sharing systems (BSS) has greatly improved urban\n\"last-mile\" connectivity, yet large-scale deployments face escalating\noperational challenges, particularly in detecting faulty bikes. Existing\ndetection approaches either rely on static model-based thresholds that overlook\ndynamic spatiotemporal (ST) usage patterns or employ supervised learning\nmethods that struggle with label scarcity and class imbalance. To address these\nlimitations, this paper proposes a novel Self-Supervised Transformer\n(SSTransformer) framework for automatically detecting unusable shared bikes,\nleveraging ST features extracted from GPS trajectories and trip records. The\nmodel incorporates a self-supervised pre-training strategy to enhance its\nfeature extraction capabilities, followed by fine-tuning for efficient status\nrecognition. In the pre-training phase, the Transformer encoder learns\ngeneralized representations of bike movement via a self-supervised objective;\nin the fine-tuning phase, the encoder is adapted to a downstream binary\nclassification task. Comprehensive experiments on a real-world dataset of\n10,730 bikes (1,870 unusable, 8,860 normal) from Chengdu, China, demonstrate\nthat SSTransformer significantly outperforms traditional machine learning,\nensemble learning, and deep learning baselines, achieving the best accuracy\n(97.81%), precision (0.8889), and F1-score (0.9358). This work highlights the\neffectiveness of self-supervised Transformer on ST data for capturing complex\nanomalies in BSS, paving the way toward more reliable and scalable maintenance\nsolutions for shared mobility.", "published": "2025-05-02 00:20:38", "link": "http://arxiv.org/abs/2505.00932v1", "categories": ["cs.LG", "cs.AI", "eess.SP"], "primary_category": "cs.LG"}
{"title": "VIDSTAMP: A Temporally-Aware Watermark for Ownership and Integrity in Video Diffusion Models", "abstract": "The rapid rise of video diffusion models has enabled the generation of highly\nrealistic and temporally coherent videos, raising critical concerns about\ncontent authenticity, provenance, and misuse. Existing watermarking approaches,\nwhether passive, post-hoc, or adapted from image-based techniques, often\nstruggle to withstand video-specific manipulations such as frame insertion,\ndropping, or reordering, and typically degrade visual quality. In this work, we\nintroduce VIDSTAMP, a watermarking framework that embeds per-frame or\nper-segment messages directly into the latent space of temporally-aware video\ndiffusion models. By fine-tuning the model's decoder through a two-stage\npipeline, first on static image datasets to promote spatial message separation,\nand then on synthesized video sequences to restore temporal consistency,\nVIDSTAMP learns to embed high-capacity, flexible watermarks with minimal\nperceptual impact. Leveraging architectural components such as 3D convolutions\nand temporal attention, our method imposes no additional inference cost and\noffers better perceptual quality than prior methods, while maintaining\ncomparable robustness against common distortions and tampering. VIDSTAMP embeds\n768 bits per video (48 bits per frame) with a bit accuracy of 95.0%, achieves a\nlog P-value of -166.65 (lower is better), and maintains a video quality score\nof 0.836, comparable to unwatermarked outputs (0.838) and surpassing prior\nmethods in capacity-quality tradeoffs. Code: Code:\n\\url{https://github.com/SPIN-UMass/VidStamp}", "published": "2025-05-02 17:35:03", "link": "http://arxiv.org/abs/2505.01406v1", "categories": ["cs.CV", "cs.CR", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Global Collinearity-aware Polygonizer for Polygonal Building Mapping in Remote Sensing", "abstract": "This paper addresses the challenge of mapping polygonal buildings from remote\nsensing images and introduces a novel algorithm, the Global Collinearity-aware\nPolygonizer (GCP). GCP, built upon an instance segmentation framework,\nprocesses binary masks produced by any instance segmentation model. The\nalgorithm begins by collecting polylines sampled along the contours of the\nbinary masks. These polylines undergo a refinement process using a\ntransformer-based regression module to ensure they accurately fit the contours\nof the targeted building instances. Subsequently, a collinearity-aware polygon\nsimplification module simplifies these refined polylines and generate the final\npolygon representation. This module employs dynamic programming technique to\noptimize an objective function that balances the simplicity and fidelity of the\npolygons, achieving globally optimal solutions. Furthermore, the optimized\ncollinearity-aware objective is seamlessly integrated into network training,\nenhancing the cohesiveness of the entire pipeline. The effectiveness of GCP has\nbeen validated on two public benchmarks for polygonal building mapping. Further\nexperiments reveal that applying the collinearity-aware polygon simplification\nmodule to arbitrary polylines, without prior knowledge, enhances accuracy over\ntraditional methods such as the Douglas-Peucker algorithm. This finding\nunderscores the broad applicability of GCP. The code for the proposed method\nwill be made available at https://github.com/zhu-xlab.", "published": "2025-05-02 16:49:07", "link": "http://arxiv.org/abs/2505.01385v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Monitoring morphometric drift in lifelong learning segmentation of the spinal cord", "abstract": "Morphometric measures derived from spinal cord segmentations can serve as\ndiagnostic and prognostic biomarkers in neurological diseases and injuries\naffecting the spinal cord. While robust, automatic segmentation methods to a\nwide variety of contrasts and pathologies have been developed over the past few\nyears, whether their predictions are stable as the model is updated using new\ndatasets has not been assessed. This is particularly important for deriving\nnormative values from healthy participants. In this study, we present a spinal\ncord segmentation model trained on a multisite $(n=75)$ dataset, including 9\ndifferent MRI contrasts and several spinal cord pathologies. We also introduce\na lifelong learning framework to automatically monitor the morphometric drift\nas the model is updated using additional datasets. The framework is triggered\nby an automatic GitHub Actions workflow every time a new model is created,\nrecording the morphometric values derived from the model's predictions over\ntime. As a real-world application of the proposed framework, we employed the\nspinal cord segmentation model to update a recently-introduced normative\ndatabase of healthy participants containing commonly used measures of spinal\ncord morphometry. Results showed that: (i) our model outperforms previous\nversions and pathology-specific models on challenging lumbar spinal cord cases,\nachieving an average Dice score of $0.95 \\pm 0.03$; (ii) the automatic workflow\nfor monitoring morphometric drift provides a quick feedback loop for developing\nfuture segmentation models; and (iii) the scaling factor required to update the\ndatabase of morphometric measures is nearly constant among slices across the\ngiven vertebral levels, showing minimum drift between the current and previous\nversions of the model monitored by the framework. The model is freely available\nin Spinal Cord Toolbox v7.0.", "published": "2025-05-02 16:04:00", "link": "http://arxiv.org/abs/2505.01364v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FreeInsert: Disentangled Text-Guided Object Insertion in 3D Gaussian Scene without Spatial Priors", "abstract": "Text-driven object insertion in 3D scenes is an emerging task that enables\nintuitive scene editing through natural language. However, existing 2D\nediting-based methods often rely on spatial priors such as 2D masks or 3D\nbounding boxes, and they struggle to ensure consistency of the inserted object.\nThese limitations hinder flexibility and scalability in real-world\napplications. In this paper, we propose FreeInsert, a novel framework that\nleverages foundation models including MLLMs, LGMs, and diffusion models to\ndisentangle object generation from spatial placement. This enables unsupervised\nand flexible object insertion in 3D scenes without spatial priors. FreeInsert\nstarts with an MLLM-based parser that extracts structured semantics, including\nobject types, spatial relationships, and attachment regions, from user\ninstructions. These semantics guide both the reconstruction of the inserted\nobject for 3D consistency and the learning of its degrees of freedom. We\nleverage the spatial reasoning capabilities of MLLMs to initialize object pose\nand scale. A hierarchical, spatially aware refinement stage further integrates\nspatial semantics and MLLM-inferred priors to enhance placement. Finally, the\nappearance of the object is improved using the inserted-object image to enhance\nvisual fidelity. Experimental results demonstrate that FreeInsert achieves\nsemantically coherent, spatially precise, and visually realistic 3D insertions\nwithout relying on spatial priors, offering a user-friendly and flexible\nediting experience.", "published": "2025-05-02 14:53:56", "link": "http://arxiv.org/abs/2505.01322v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Neural Architecture Search Method using Auxiliary Evaluation Metric based on ResNet Architecture", "abstract": "This paper proposes a neural architecture search space using ResNet as a\nframework, with search objectives including parameters for convolution,\npooling, fully connected layers, and connectivity of the residual network. In\naddition to recognition accuracy, this paper uses the loss value on the\nvalidation set as a secondary objective for optimization. The experimental\nresults demonstrate that the search space of this paper together with the\noptimisation approach can find competitive network architectures on the MNIST,\nFashion-MNIST and CIFAR100 datasets.", "published": "2025-05-02 14:39:44", "link": "http://arxiv.org/abs/2505.01313v1", "categories": ["cs.NE", "cs.CV"], "primary_category": "cs.NE"}
{"title": "Diffusion-based Adversarial Purification from the Perspective of the Frequency Domain", "abstract": "The diffusion-based adversarial purification methods attempt to drown\nadversarial perturbations into a part of isotropic noise through the forward\nprocess, and then recover the clean images through the reverse process. Due to\nthe lack of distribution information about adversarial perturbations in the\npixel domain, it is often unavoidable to damage normal semantics. We turn to\nthe frequency domain perspective, decomposing the image into amplitude spectrum\nand phase spectrum. We find that for both spectra, the damage caused by\nadversarial perturbations tends to increase monotonically with frequency. This\nmeans that we can extract the content and structural information of the\noriginal clean sample from the frequency components that are less damaged.\nMeanwhile, theoretical analysis indicates that existing purification methods\nindiscriminately damage all frequency components, leading to excessive damage\nto the image. Therefore, we propose a purification method that can eliminate\nadversarial perturbations while maximizing the preservation of the content and\nstructure of the original image. Specifically, at each time step during the\nreverse process, for the amplitude spectrum, we replace the low-frequency\ncomponents of the estimated image's amplitude spectrum with the corresponding\nparts of the adversarial image. For the phase spectrum, we project the phase of\nthe estimated image into a designated range of the adversarial image's phase\nspectrum, focusing on the low frequencies. Empirical evidence from extensive\nexperiments demonstrates that our method significantly outperforms most current\ndefense methods.", "published": "2025-05-02 13:41:14", "link": "http://arxiv.org/abs/2505.01267v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FlowDubber: Movie Dubbing with LLM-based Semantic-aware Learning and Flow Matching based Voice Enhancing", "abstract": "Movie Dubbing aims to convert scripts into speeches that align with the given\nmovie clip in both temporal and emotional aspects while preserving the vocal\ntimbre of a given brief reference audio. Existing methods focus primarily on\nreducing the word error rate while ignoring the importance of lip-sync and\nacoustic quality. To address these issues, we propose a large language model\n(LLM) based flow matching architecture for dubbing, named FlowDubber, which\nachieves high-quality audio-visual sync and pronunciation by incorporating a\nlarge speech language model and dual contrastive aligning while achieving\nbetter acoustic quality via the proposed voice-enhanced flow matching than\nprevious works. First, we introduce Qwen2.5 as the backbone of LLM to learn the\nin-context sequence from movie scripts and reference audio. Then, the proposed\nsemantic-aware learning focuses on capturing LLM semantic knowledge at the\nphoneme level. Next, dual contrastive aligning (DCA) boosts mutual alignment\nwith lip movement, reducing ambiguities where similar phonemes might be\nconfused. Finally, the proposed Flow-based Voice Enhancing (FVE) improves\nacoustic quality in two aspects, which introduces an LLM-based acoustics flow\nmatching guidance to strengthen clarity and uses affine style prior to enhance\nidentity when recovering noise into mel-spectrograms via gradient vector field\nprediction. Extensive experiments demonstrate that our method outperforms\nseveral state-of-the-art methods on two primary benchmarks. The demos are\navailable at\n{\\href{https://galaxycong.github.io/LLM-Flow-Dubber/}{\\textcolor{red}{https://galaxycong.github.io/LLM-Flow-Dubber/}}}.", "published": "2025-05-02 13:30:19", "link": "http://arxiv.org/abs/2505.01263v1", "categories": ["cs.MM", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "CAMELTrack: Context-Aware Multi-cue ExpLoitation for Online Multi-Object Tracking", "abstract": "Online multi-object tracking has been recently dominated by\ntracking-by-detection (TbD) methods, where recent advances rely on increasingly\nsophisticated heuristics for tracklet representation, feature fusion, and\nmulti-stage matching. The key strength of TbD lies in its modular design,\nenabling the integration of specialized off-the-shelf models like motion\npredictors and re-identification. However, the extensive usage of human-crafted\nrules for temporal associations makes these methods inherently limited in their\nability to capture the complex interplay between various tracking cues. In this\nwork, we introduce CAMEL, a novel association module for Context-Aware\nMulti-Cue ExpLoitation, that learns resilient association strategies directly\nfrom data, breaking free from hand-crafted heuristics while maintaining TbD's\nvaluable modularity. At its core, CAMEL employs two transformer-based modules\nand relies on a novel association-centric training scheme to effectively model\nthe complex interactions between tracked targets and their various association\ncues. Unlike end-to-end detection-by-tracking approaches, our method remains\nlightweight and fast to train while being able to leverage external\noff-the-shelf models. Our proposed online tracking pipeline, CAMELTrack,\nachieves state-of-the-art performance on multiple tracking benchmarks. Our code\nis available at https://github.com/TrackingLaboratory/CAMELTrack.", "published": "2025-05-02 13:26:23", "link": "http://arxiv.org/abs/2505.01257v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Fusing Foveal Fixations Using Linear Retinal Transformations and Bayesian Experimental Design", "abstract": "Humans (and many vertebrates) face the problem of fusing together multiple\nfixations of a scene in order to obtain a representation of the whole, where\neach fixation uses a high-resolution fovea and decreasing resolution in the\nperiphery. In this paper we explicitly represent the retinal transformation of\na fixation as a linear downsampling of a high-resolution latent image of the\nscene, exploiting the known geometry. This linear transformation allows us to\ncarry out exact inference for the latent variables in factor analysis (FA) and\nmixtures of FA models of the scene. Further, this allows us to formulate and\nsolve the choice of \"where to look next\" as a Bayesian experimental design\nproblem using the Expected Information Gain criterion. Experiments on the Frey\nfaces and MNIST datasets demonstrate the effectiveness of our models.", "published": "2025-05-02 13:17:08", "link": "http://arxiv.org/abs/2505.01249v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Can Foundation Models Really Segment Tumors? A Benchmarking Odyssey in Lung CT Imaging", "abstract": "Accurate lung tumor segmentation is crucial for improving diagnosis,\ntreatment planning, and patient outcomes in oncology. However, the complexity\nof tumor morphology, size, and location poses significant challenges for\nautomated segmentation. This study presents a comprehensive benchmarking\nanalysis of deep learning-based segmentation models, comparing traditional\narchitectures such as U-Net and DeepLabV3, self-configuring models like nnUNet,\nand foundation models like MedSAM, and MedSAM~2. Evaluating performance across\ntwo lung tumor segmentation datasets, we assess segmentation accuracy and\ncomputational efficiency under various learning paradigms, including few-shot\nlearning and fine-tuning. The results reveal that while traditional models\nstruggle with tumor delineation, foundation models, particularly MedSAM~2,\noutperform them in both accuracy and computational efficiency. These findings\nunderscore the potential of foundation models for lung tumor segmentation,\nhighlighting their applicability in improving clinical workflows and patient\noutcomes.", "published": "2025-05-02 13:04:01", "link": "http://arxiv.org/abs/2505.01239v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via Fine-Grained Alignment", "abstract": "Recent advances in audio-visual learning have shown promising results in\nlearning representations across modalities. However, most approaches rely on\nglobal audio representations that fail to capture fine-grained temporal\ncorrespondences with visual frames. Additionally, existing methods often\nstruggle with conflicting optimization objectives when trying to jointly learn\nreconstruction and cross-modal alignment. In this work, we propose CAV-MAE Sync\nas a simple yet effective extension of the original CAV-MAE framework for\nself-supervised audio-visual learning. We address three key challenges: First,\nwe tackle the granularity mismatch between modalities by treating audio as a\ntemporal sequence aligned with video frames, rather than using global\nrepresentations. Second, we resolve conflicting optimization goals by\nseparating contrastive and reconstruction objectives through dedicated global\ntokens. Third, we improve spatial localization by introducing learnable\nregister tokens that reduce semantic load on patch tokens. We evaluate the\nproposed approach on AudioSet, VGG Sound, and the ADE20K Sound dataset on\nzero-shot retrieval, classification and localization tasks demonstrating\nstate-of-the-art performance and outperforming more complex architectures.", "published": "2025-05-02 12:59:58", "link": "http://arxiv.org/abs/2505.01237v1", "categories": ["cs.MM", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "Compensating Spatiotemporally Inconsistent Observations for Online Dynamic 3D Gaussian Splatting", "abstract": "Online reconstruction of dynamic scenes is significant as it enables learning\nscenes from live-streaming video inputs, while existing offline dynamic\nreconstruction methods rely on recorded video inputs. However, previous online\nreconstruction approaches have primarily focused on efficiency and rendering\nquality, overlooking the temporal consistency of their results, which often\ncontain noticeable artifacts in static regions. This paper identifies that\nerrors such as noise in real-world recordings affect temporal inconsistency in\nonline reconstruction. We propose a method that enhances temporal consistency\nin online reconstruction from observations with temporal inconsistency which is\ninevitable in cameras. We show that our method restores the ideal observation\nby subtracting the learned error. We demonstrate that applying our method to\nvarious baselines significantly enhances both temporal consistency and\nrendering quality across datasets. Code, video results, and checkpoints are\navailable at https://bbangsik13.github.io/OR2.", "published": "2025-05-02 12:50:24", "link": "http://arxiv.org/abs/2505.01235v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Core-Set Selection for Data-efficient Land Cover Segmentation", "abstract": "The increasing accessibility of remotely sensed data and the potential of\nsuch data to inform large-scale decision-making has driven the development of\ndeep learning models for many Earth Observation tasks. Traditionally, such\nmodels must be trained on large datasets. However, the common assumption that\nbroadly larger datasets lead to better outcomes tends to overlook the\ncomplexities of the data distribution, the potential for introducing biases and\nnoise, and the computational resources required for processing and storing vast\ndatasets. Therefore, effective solutions should consider both the quantity and\nquality of data. In this paper, we propose six novel core-set selection methods\nfor selecting important subsets of samples from remote sensing image\nsegmentation datasets that rely on imagery only, labels only, and a combination\nof each. We benchmark these approaches against a random-selection baseline on\nthree commonly used land cover classification datasets: DFC2022, Vaihingen, and\nPotsdam. In each of the datasets, we demonstrate that training on a subset of\nsamples outperforms the random baseline, and some approaches outperform\ntraining on all available data. This result shows the importance and potential\nof data-centric learning for the remote sensing domain. The code is available\nat https://github.com/keillernogueira/data-centric-rs-classification/.", "published": "2025-05-02 12:22:08", "link": "http://arxiv.org/abs/2505.01225v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RD-UIE: Relation-Driven State Space Modeling for Underwater Image Enhancement", "abstract": "Underwater image enhancement (UIE) is a critical preprocessing step for\nmarine vision applications, where wavelength-dependent attenuation causes\nsevere content degradation and color distortion. While recent state space\nmodels like Mamba show potential for long-range dependency modeling, their\nunfolding operations and fixed scan paths on 1D sequences fail to adapt to\nlocal object semantics and global relation modeling, limiting their efficacy in\ncomplex underwater environments. To address this, we enhance conventional Mamba\nwith the sorting-based scanning mechanism that dynamically reorders scanning\nsequences based on statistical distribution of spatial correlation of all\npixels. In this way, it encourages the network to prioritize the most\ninformative components--structural and semantic features. Upon building this\nmechanism, we devise a Visually Self-adaptive State Block (VSSB) that\nharmonizes dynamic sorting of Mamba with input-dependent dynamic convolution,\nenabling coherent integration of global context and local relational cues. This\nexquisite design helps eliminate global focus bias, especially for widely\ndistributed contents, which greatly weakens the statistical frequency. For\nrobust feature extraction and refinement, we design a cross-feature bridge\n(CFB) to adaptively fuse multi-scale representations. These efforts compose the\nnovel relation-driven Mamba framework for effective UIE (RD-UIE). Extensive\nexperiments on underwater enhancement benchmarks demonstrate RD-UIE outperforms\nthe state-of-the-art approach WMamba in both quantitative metrics and visual\nfidelity, averagely achieving 0.55 dB performance gain on the three benchmarks.\nOur code is available at https://github.com/kkoucy/RD-UIE/tree/main", "published": "2025-05-02 12:21:44", "link": "http://arxiv.org/abs/2505.01224v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "High Dynamic Range Novel View Synthesis with Single Exposure", "abstract": "High Dynamic Range Novel View Synthesis (HDR-NVS) aims to establish a 3D\nscene HDR model from Low Dynamic Range (LDR) imagery. Typically,\nmultiple-exposure LDR images are employed to capture a wider range of\nbrightness levels in a scene, as a single LDR image cannot represent both the\nbrightest and darkest regions simultaneously. While effective, this\nmultiple-exposure HDR-NVS approach has significant limitations, including\nsusceptibility to motion artifacts (e.g., ghosting and blurring), high capture\nand storage costs. To overcome these challenges, we introduce, for the first\ntime, the single-exposure HDR-NVS problem, where only single exposure LDR\nimages are available during training. We further introduce a novel approach,\nMono-HDR-3D, featuring two dedicated modules formulated by the LDR image\nformation principles, one for converting LDR colors to HDR counterparts, and\nthe other for transforming HDR images to LDR format so that unsupervised\nlearning is enabled in a closed loop. Designed as a meta-algorithm, our\napproach can be seamlessly integrated with existing NVS models. Extensive\nexperiments show that Mono-HDR-3D significantly outperforms previous methods.\nSource code will be released.", "published": "2025-05-02 12:04:38", "link": "http://arxiv.org/abs/2505.01212v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "T-Graph: Enhancing Sparse-view Camera Pose Estimation by Pairwise Translation Graph", "abstract": "Sparse-view camera pose estimation, which aims to estimate the\n6-Degree-of-Freedom (6-DoF) poses from a limited number of images captured from\ndifferent viewpoints, is a fundamental yet challenging problem in remote\nsensing applications. Existing methods often overlook the translation\ninformation between each pair of viewpoints, leading to suboptimal performance\nin sparse-view scenarios. To address this limitation, we introduce T-Graph, a\nlightweight, plug-and-play module to enhance camera pose estimation in\nsparse-view settings. T-graph takes paired image features as input and maps\nthem through a Multilayer Perceptron (MLP). It then constructs a fully\nconnected translation graph, where nodes represent cameras and edges encode\ntheir translation relationships. It can be seamlessly integrated into existing\nmodels as an additional branch in parallel with the original prediction,\nmaintaining efficiency and ease of use. Furthermore, we introduce two pairwise\ntranslation representations, relative-t and pair-t, formulated under different\nlocal coordinate systems. While relative-t captures intuitive spatial\nrelationships, pair-t offers a rotation-disentangled alternative. The two\nrepresentations contribute to enhanced adaptability across diverse application\nscenarios, further improving our module's robustness. Extensive experiments on\ntwo state-of-the-art methods (RelPose++ and Forge) using public datasets (C03D\nand IMC PhotoTourism) validate both the effectiveness and generalizability of\nT-Graph. The results demonstrate consistent improvements across various\nmetrics, notably camera center accuracy, which improves by 1% to 6% from 2 to 8\nviewpoints.", "published": "2025-05-02 11:50:48", "link": "http://arxiv.org/abs/2505.01207v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Efficient Vision-based Vehicle Speed Estimation", "abstract": "This paper presents a computationally efficient method for vehicle speed\nestimation from traffic camera footage. Building upon previous work that\nutilizes 3D bounding boxes derived from 2D detections and vanishing point\ngeometry, we introduce several improvements to enhance real-time performance.\nWe evaluate our method in several variants on the BrnoCompSpeed dataset in\nterms of vehicle detection and speed estimation accuracy. Our extensive\nevaluation across various hardware platforms, including edge devices,\ndemonstrates significant gains in frames per second (FPS) compared to the prior\nstate-of-the-art, while maintaining comparable or improved speed estimation\naccuracy. We analyze the trade-off between accuracy and computational cost,\nshowing that smaller models utilizing post-training quantization offer the best\nbalance for real-world deployment. Our best performing model beats previous\nstate-of-the-art in terms of median vehicle speed estimation error (0.58 km/h\nvs. 0.60 km/h), detection precision (91.02% vs 87.08%) and recall (91.14% vs.\n83.32%) while also being 5.5 times faster.", "published": "2025-05-02 11:48:11", "link": "http://arxiv.org/abs/2505.01203v1", "categories": ["cs.CV", "68T45", "I.4.9"], "primary_category": "cs.CV"}
{"title": "FreePCA: Integrating Consistency Information across Long-short Frames in Training-free Long Video Generation via Principal Component Analysis", "abstract": "Long video generation involves generating extended videos using models\ntrained on short videos, suffering from distribution shifts due to varying\nframe counts. It necessitates the use of local information from the original\nshort frames to enhance visual and motion quality, and global information from\nthe entire long frames to ensure appearance consistency. Existing training-free\nmethods struggle to effectively integrate the benefits of both, as appearance\nand motion in videos are closely coupled, leading to motion inconsistency and\nvisual quality. In this paper, we reveal that global and local information can\nbe precisely decoupled into consistent appearance and motion intensity\ninformation by applying Principal Component Analysis (PCA), allowing for\nrefined complementary integration of global consistency and local quality. With\nthis insight, we propose FreePCA, a training-free long video generation\nparadigm based on PCA that simultaneously achieves high consistency and\nquality. Concretely, we decouple consistent appearance and motion intensity\nfeatures by measuring cosine similarity in the principal component space.\nCritically, we progressively integrate these features to preserve original\nquality and ensure smooth transitions, while further enhancing consistency by\nreusing the mean statistics of the initial noise. Experiments demonstrate that\nFreePCA can be applied to various video diffusion models without requiring\ntraining, leading to substantial improvements. Code is available at\nhttps://github.com/JosephTiTan/FreePCA.", "published": "2025-05-02 10:27:58", "link": "http://arxiv.org/abs/2505.01172v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "NeuroLoc: Encoding Navigation Cells for 6-DOF Camera Localization", "abstract": "Recently, camera localization has been widely adopted in autonomous robotic\nnavigation due to its efficiency and convenience. However, autonomous\nnavigation in unknown environments often suffers from scene ambiguity,\nenvironmental disturbances, and dynamic object transformation in camera\nlocalization. To address this problem, inspired by the biological brain\nnavigation mechanism (such as grid cells, place cells, and head direction\ncells), we propose a novel neurobiological camera location method, namely\nNeuroLoc. Firstly, we designed a Hebbian learning module driven by place cells\nto save and replay historical information, aiming to restore the details of\nhistorical representations and solve the issue of scene fuzziness. Secondly, we\nutilized the head direction cell-inspired internal direction learning as\nmulti-head attention embedding to help restore the true orientation in similar\nscenes. Finally, we added a 3D grid center prediction in the pose regression\nmodule to reduce the final wrong prediction. We evaluate the proposed NeuroLoc\non commonly used benchmark indoor and outdoor datasets. The experimental\nresults show that our NeuroLoc can enhance the robustness in complex\nenvironments and improve the performance of pose regression by using only a\nsingle image.", "published": "2025-05-02 08:47:31", "link": "http://arxiv.org/abs/2505.01113v1", "categories": ["cs.RO", "cs.CV", "cs.NE"], "primary_category": "cs.RO"}
{"title": "VSC: Visual Search Compositional Text-to-Image Diffusion Model", "abstract": "Text-to-image diffusion models have shown impressive capabilities in\ngenerating realistic visuals from natural-language prompts, yet they often\nstruggle with accurately binding attributes to corresponding objects,\nespecially in prompts containing multiple attribute-object pairs. This\nchallenge primarily arises from the limitations of commonly used text encoders,\nsuch as CLIP, which can fail to encode complex linguistic relationships and\nmodifiers effectively. Existing approaches have attempted to mitigate these\nissues through attention map control during inference and the use of layout\ninformation or fine-tuning during training, yet they face performance drops\nwith increased prompt complexity. In this work, we introduce a novel\ncompositional generation method that leverages pairwise image embeddings to\nimprove attribute-object binding. Our approach decomposes complex prompts into\nsub-prompts, generates corresponding images, and computes visual prototypes\nthat fuse with text embeddings to enhance representation. By applying\nsegmentation-based localization training, we address cross-attention\nmisalignment, achieving improved accuracy in binding multiple attributes to\nobjects. Our approaches outperform existing compositional text-to-image\ndiffusion models on the benchmark T2I CompBench, achieving better image\nquality, evaluated by humans, and emerging robustness under scaling number of\nbinding pairs in the prompt.", "published": "2025-05-02 08:31:43", "link": "http://arxiv.org/abs/2505.01104v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Improving Editability in Image Generation with Layer-wise Memory", "abstract": "Most real-world image editing tasks require multiple sequential edits to\nachieve desired results. Current editing approaches, primarily designed for\nsingle-object modifications, struggle with sequential editing: especially with\nmaintaining previous edits along with adapting new objects naturally into the\nexisting content. These limitations significantly hinder complex editing\nscenarios where multiple objects need to be modified while preserving their\ncontextual relationships. We address this fundamental challenge through two key\nproposals: enabling rough mask inputs that preserve existing content while\nnaturally integrating new elements and supporting consistent editing across\nmultiple modifications. Our framework achieves this through layer-wise memory,\nwhich stores latent representations and prompt embeddings from previous edits.\nWe propose Background Consistency Guidance that leverages memorized latents to\nmaintain scene coherence and Multi-Query Disentanglement in cross-attention\nthat ensures natural adaptation to existing content. To evaluate our method, we\npresent a new benchmark dataset incorporating semantic alignment metrics and\ninteractive editing scenarios. Through comprehensive experiments, we\ndemonstrate superior performance in iterative image editing tasks with minimal\nuser effort, requiring only rough masks while maintaining high-quality results\nthroughout multiple editing steps.", "published": "2025-05-02 07:36:49", "link": "http://arxiv.org/abs/2505.01079v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Efficient Vocabulary-Free Fine-Grained Visual Recognition in the Age of Multimodal LLMs", "abstract": "Fine-grained Visual Recognition (FGVR) involves distinguishing between\nvisually similar categories, which is inherently challenging due to subtle\ninter-class differences and the need for large, expert-annotated datasets. In\ndomains like medical imaging, such curated datasets are unavailable due to\nissues like privacy concerns and high annotation costs. In such scenarios\nlacking labeled data, an FGVR model cannot rely on a predefined set of training\nlabels, and hence has an unconstrained output space for predictions. We refer\nto this task as Vocabulary-Free FGVR (VF-FGVR), where a model must predict\nlabels from an unconstrained output space without prior label information.\nWhile recent Multimodal Large Language Models (MLLMs) show potential for\nVF-FGVR, querying these models for each test input is impractical because of\nhigh costs and prohibitive inference times. To address these limitations, we\nintroduce \\textbf{Nea}rest-Neighbor Label \\textbf{R}efinement (NeaR), a novel\napproach that fine-tunes a downstream CLIP model using labels generated by an\nMLLM. Our approach constructs a weakly supervised dataset from a small,\nunlabeled training set, leveraging MLLMs for label generation. NeaR is designed\nto handle the noise, stochasticity, and open-endedness inherent in labels\ngenerated by MLLMs, and establishes a new benchmark for efficient VF-FGVR.", "published": "2025-05-02 07:14:58", "link": "http://arxiv.org/abs/2505.01064v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "GeloVec: Higher Dimensional Geometric Smoothing for Coherent Visual Feature Extraction in Image Segmentation", "abstract": "This paper introduces GeloVec, a new CNN-based attention smoothing framework\nfor semantic segmentation that addresses critical limitations in conventional\napproaches. While existing attention-backed segmentation methods suffer from\nboundary instability and contextual discontinuities during feature mapping, our\nframework implements a higher-dimensional geometric smoothing method to\nestablish a robust manifold relationships between visually coherent regions.\nGeloVec combines modified Chebyshev distance metrics with multispatial\ntransformations to enhance segmentation accuracy through stabilized feature\nextraction. The core innovation lies in the adaptive sampling weights system\nthat calculates geometric distances in n-dimensional feature space, achieving\nsuperior edge preservation while maintaining intra-class homogeneity. The\nmultispatial transformation matrix incorporates tensorial projections with\northogonal basis vectors, creating more discriminative feature representations\nwithout sacrificing computational efficiency. Experimental validation across\nmultiple benchmark datasets demonstrates significant improvements in\nsegmentation performance, with mean Intersection over Union (mIoU) gains of\n2.1%, 2.7%, and 2.4% on Caltech Birds-200, LSDSC, and FSSD datasets\nrespectively compared to state-of-the-art methods. GeloVec's mathematical\nfoundation in Riemannian geometry provides theoretical guarantees on\nsegmentation stability. Importantly, our framework maintains computational\nefficiency through parallelized implementation of geodesic transformations and\nexhibits strong generalization capabilities across disciplines due to the\nabsence of information loss during transformations.", "published": "2025-05-02 07:07:00", "link": "http://arxiv.org/abs/2505.01057v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Transferable Adversarial Attacks on Black-Box Vision-Language Models", "abstract": "Vision Large Language Models (VLLMs) are increasingly deployed to offer\nadvanced capabilities on inputs comprising both text and images. While prior\nresearch has shown that adversarial attacks can transfer from open-source to\nproprietary black-box models in text-only and vision-only contexts, the extent\nand effectiveness of such vulnerabilities remain underexplored for VLLMs. We\npresent a comprehensive analysis demonstrating that targeted adversarial\nexamples are highly transferable to widely-used proprietary VLLMs such as\nGPT-4o, Claude, and Gemini. We show that attackers can craft perturbations to\ninduce specific attacker-chosen interpretations of visual information, such as\nmisinterpreting hazardous content as safe, overlooking sensitive or restricted\nmaterial, or generating detailed incorrect responses aligned with the\nattacker's intent. Furthermore, we discover that universal perturbations --\nmodifications applicable to a wide set of images -- can consistently induce\nthese misinterpretations across multiple proprietary VLLMs. Our experimental\nresults on object recognition, visual question answering, and image captioning\nshow that this vulnerability is common across current state-of-the-art models,\nand underscore an urgent need for robust mitigations to ensure the safe and\nsecure deployment of VLLMs.", "published": "2025-05-02 06:51:11", "link": "http://arxiv.org/abs/2505.01050v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Edge Detection based on Channel Attention and Inter-region Independence Test", "abstract": "Existing edge detection methods often suffer from noise amplification and\nexcessive retention of non-salient details, limiting their applicability in\nhigh-precision industrial scenarios. To address these challenges, we propose\nCAM-EDIT, a novel framework that integrates Channel Attention Mechanism (CAM)\nand Edge Detection via Independence Testing (EDIT). The CAM module adaptively\nenhances discriminative edge features through multi-channel fusion, while the\nEDIT module employs region-wise statistical independence analysis (using\nFisher's exact test and chi-square test) to suppress uncorrelated\nnoise.Extensive experiments on BSDS500 and NYUDv2 datasets demonstrate\nstate-of-the-art performance. Among the nine comparison algorithms, the\nF-measure scores of CAM-EDIT are 0.635 and 0.460, representing improvements of\n19.2\\% to 26.5\\% over traditional methods (Canny, CannySR), and better than the\nlatest learning based methods (TIP2020, MSCNGP). Noise robustness evaluations\nfurther reveal a 2.2\\% PSNR improvement under Gaussian noise compared to\nbaseline methods. Qualitative results exhibit cleaner edge maps with reduced\nartifacts, demonstrating its potential for high-precision industrial\napplications.", "published": "2025-05-02 06:30:21", "link": "http://arxiv.org/abs/2505.01040v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Edge-preserving Image Denoising via Multi-scale Adaptive Statistical Independence Testing", "abstract": "Edge detection is crucial in image processing, but existing methods often\nproduce overly detailed edge maps, affecting clarity. Fixed-window statistical\ntesting faces issues like scale mismatch and computational redundancy. To\naddress these, we propose a novel Multi-scale Adaptive Independence\nTesting-based Edge Detection and Denoising (EDD-MAIT), a Multi-scale Adaptive\nStatistical Testing-based edge detection and denoising method that integrates a\nchannel attention mechanism with independence testing. A gradient-driven\nadaptive window strategy adjusts window sizes dynamically, improving detail\npreservation and noise suppression. EDD-MAIT achieves better robustness,\naccuracy, and efficiency, outperforming traditional and learning-based methods\non BSDS500 and BIPED datasets, with improvements in F-score, MSE, PSNR, and\nreduced runtime. It also shows robustness against Gaussian noise, generating\naccurate and clean edge maps in noisy environments.", "published": "2025-05-02 06:09:32", "link": "http://arxiv.org/abs/2505.01032v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "3D Human Pose Estimation via Spatial Graph Order Attention and Temporal Body Aware Transformer", "abstract": "Nowadays, Transformers and Graph Convolutional Networks (GCNs) are the\nprevailing techniques for 3D human pose estimation. However, Transformer-based\nmethods either ignore the spatial neighborhood relationships between the joints\nwhen used for skeleton representations or disregard the local temporal patterns\nof the local joint movements in skeleton sequence modeling, while GCN-based\nmethods often neglect the need for pose-specific representations. To address\nthese problems, we propose a new method that exploits the graph modeling\ncapability of GCN to represent each skeleton with multiple graphs of different\norders, incorporated with a newly introduced Graph Order Attention module that\ndynamically emphasizes the most representative orders for each joint. The\nresulting spatial features of the sequence are further processed using a\nproposed temporal Body Aware Transformer that models the global body feature\ndependencies in the sequence with awareness of the local inter-skeleton feature\ndependencies of joints. Given that our 3D pose output aligns with the central\n2D pose in the sequence, we improve the self-attention mechanism to be aware of\nthe central pose while diminishing its focus gradually towards the first and\nthe last poses. Extensive experiments on Human3.6m, MPIINF-3DHP, and HumanEva-I\ndatasets demonstrate the effectiveness of the proposed method. Code and models\nare made available on Github.", "published": "2025-05-02 04:58:04", "link": "http://arxiv.org/abs/2505.01003v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Deterministic-to-Stochastic Diverse Latent Feature Mapping for Human Motion Synthesis", "abstract": "Human motion synthesis aims to generate plausible human motion sequences,\nwhich has raised widespread attention in computer animation. Recent score-based\ngenerative models (SGMs) have demonstrated impressive results on this task.\nHowever, their training process involves complex curvature trajectories,\nleading to unstable training process. In this paper, we propose a\nDeterministic-to-Stochastic Diverse Latent Feature Mapping (DSDFM) method for\nhuman motion synthesis. DSDFM consists of two stages. The first human motion\nreconstruction stage aims to learn the latent space distribution of human\nmotions. The second diverse motion generation stage aims to build connections\nbetween the Gaussian distribution and the latent space distribution of human\nmotions, thereby enhancing the diversity and accuracy of the generated human\nmotions. This stage is achieved by the designed deterministic feature mapping\nprocedure with DerODE and stochastic diverse output generation procedure with\nDivSDE.DSDFM is easy to train compared to previous SGMs-based methods and can\nenhance diversity without introducing additional training parameters.Through\nqualitative and quantitative experiments, DSDFM achieves state-of-the-art\nresults surpassing the latest methods, validating its superiority in human\nmotion synthesis.", "published": "2025-05-02 04:48:28", "link": "http://arxiv.org/abs/2505.00998v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Optimizing Indoor Farm Monitoring Efficiency Using UAV: Yield Estimation in a GNSS-Denied Cherry Tomato Greenhouse", "abstract": "As the agricultural workforce declines and labor costs rise, robotic yield\nestimation has become increasingly important. While unmanned ground vehicles\n(UGVs) are commonly used for indoor farm monitoring, their deployment in\ngreenhouses is often constrained by infrastructure limitations, sensor\nplacement challenges, and operational inefficiencies. To address these issues,\nwe develop a lightweight unmanned aerial vehicle (UAV) equipped with an RGB-D\ncamera, a 3D LiDAR, and an IMU sensor. The UAV employs a LiDAR-inertial\nodometry algorithm for precise navigation in GNSS-denied environments and\nutilizes a 3D multi-object tracking algorithm to estimate the count and weight\nof cherry tomatoes. We evaluate the system using two dataset: one from a\nharvesting row and another from a growing row. In the harvesting-row dataset,\nthe proposed system achieves 94.4\\% counting accuracy and 87.5\\% weight\nestimation accuracy within a 13.2-meter flight completed in 10.5 seconds. For\nthe growing-row dataset, which consists of occluded unripened fruits, we\nqualitatively analyze tracking performance and highlight future research\ndirections for improving perception in greenhouse with strong occlusions. Our\nfindings demonstrate the potential of UAVs for efficient robotic yield\nestimation in commercial greenhouses.", "published": "2025-05-02 04:41:57", "link": "http://arxiv.org/abs/2505.00995v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "On-demand Test-time Adaptation for Edge Devices", "abstract": "Continual Test-time adaptation (CTTA) continuously adapts the deployed model\non every incoming batch of data. While achieving optimal accuracy, existing\nCTTA approaches present poor real-world applicability on resource-constrained\nedge devices, due to the substantial memory overhead and energy consumption. In\nthis work, we first introduce a novel paradigm -- on-demand TTA -- which\ntriggers adaptation only when a significant domain shift is detected. Then, we\npresent OD-TTA, an on-demand TTA framework for accurate and efficient\nadaptation on edge devices. OD-TTA comprises three innovative techniques: 1) a\nlightweight domain shift detection mechanism to activate TTA only when it is\nneeded, drastically reducing the overall computation overhead, 2) a source\ndomain selection module that chooses an appropriate source model for\nadaptation, ensuring high and robust accuracy, 3) a decoupled Batch\nNormalization (BN) update scheme to enable memory-efficient adaptation with\nsmall batch sizes. Extensive experiments show that OD-TTA achieves comparable\nand even better performance while reducing the energy and computation overhead\nremarkably, making TTA a practical reality.", "published": "2025-05-02 04:19:07", "link": "http://arxiv.org/abs/2505.00986v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "LMDepth: Lightweight Mamba-based Monocular Depth Estimation for Real-World Deployment", "abstract": "Monocular depth estimation provides an additional depth dimension to RGB\nimages, making it widely applicable in various fields such as virtual reality,\nautonomous driving and robotic navigation. However, existing depth estimation\nalgorithms often struggle to effectively balance performance and computational\nefficiency, which poses challenges for deployment on resource-constrained\ndevices. To address this, we propose LMDepth, a lightweight Mamba-based\nmonocular depth estimation network, designed to reconstruct high-precision\ndepth information while maintaining low computational overhead. Specifically,\nwe propose a modified pyramid spatial pooling module that serves as a\nmulti-scale feature aggregator and context extractor, ensuring global spatial\ninformation for accurate depth estimation. Moreover, we integrate multiple\ndepth Mamba blocks into the decoder. Designed with linear computations, the\nMamba Blocks enable LMDepth to efficiently decode depth information from global\nfeatures, providing a lightweight alternative to Transformer-based\narchitectures that depend on complex attention mechanisms. Extensive\nexperiments on the NYUDv2 and KITTI datasets demonstrate the effectiveness of\nour proposed LMDepth. Compared to previous lightweight depth estimation\nmethods, LMDepth achieves higher performance with fewer parameters and lower\ncomputational complexity (measured by GFLOPs). We further deploy LMDepth on an\nembedded platform with INT8 quantization, validating its practicality for\nreal-world edge applications.", "published": "2025-05-02 04:00:03", "link": "http://arxiv.org/abs/2505.00980v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Generating Animated Layouts as Structured Text Representations", "abstract": "Despite the remarkable progress in text-to-video models, achieving precise\ncontrol over text elements and animated graphics remains a significant\nchallenge, especially in applications such as video advertisements. To address\nthis limitation, we introduce Animated Layout Generation, a novel approach to\nextend static graphic layouts with temporal dynamics. We propose a Structured\nText Representation for fine-grained video control through hierarchical visual\nelements. To demonstrate the effectiveness of our approach, we present VAKER\n(Video Ad maKER), a text-to-video advertisement generation pipeline that\ncombines a three-stage generation process with Unstructured Text Reasoning for\nseamless integration with LLMs. VAKER fully automates video advertisement\ngeneration by incorporating dynamic layout trajectories for objects and\ngraphics across specific video frames. Through extensive evaluations, we\ndemonstrate that VAKER significantly outperforms existing methods in generating\nvideo advertisements. Project Page:\nhttps://yeonsangshin.github.io/projects/Vaker", "published": "2025-05-02 03:37:09", "link": "http://arxiv.org/abs/2505.00975v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Redundancy analysis using lcm-filtrations: networks, system signature and sensitivity evaluation", "abstract": "We introduce the lcm-filtration and stepwise filtration, comparing their\nperformance across various scenarios in terms of computational complexity,\nefficiency, and redundancy. The lcm-filtration often involves identical steps\nor ideals, leading to unnecessary computations. To address this, we analyse how\nstepwise filtration can effectively compute only the non-identical steps,\noffering a more efficient approach. We compare these filtrations in\napplications to networks, system signatures, and sensitivity analysis.", "published": "2025-05-02 17:49:15", "link": "http://arxiv.org/abs/2505.01416v1", "categories": ["cs.DM", "cs.SC", "math.AC"], "primary_category": "cs.DM"}
{"title": "How to Learn a Star: Binary Classification with Starshaped Polyhedral Sets", "abstract": "We consider binary classification restricted to a class of continuous\npiecewise linear functions whose decision boundaries are (possibly nonconvex)\nstarshaped polyhedral sets, supported on a fixed polyhedral simplicial fan. We\ninvestigate the expressivity of these function classes and describe the\ncombinatorial and geometric structure of the loss landscape, most prominently\nthe sublevel sets, for two loss-functions: the 0/1-loss (discrete loss) and an\nexponential loss function. In particular, we give explicit bounds on the VC\ndimension of this model, and concretely describe the sublevel sets of the\ndiscrete loss as chambers in a hyperplane arrangement. For the exponential\nloss, we give sufficient conditions for the optimum to be unique, and describe\nthe geometry of the optimum when varying the rate parameter of the underlying\nexponential probability distribution.", "published": "2025-05-02 15:33:31", "link": "http://arxiv.org/abs/2505.01346v1", "categories": ["cs.LG", "cs.DM", "math.CO", "math.MG"], "primary_category": "cs.LG"}
{"title": "Going deep and going wide: Counting logic and homomorphism indistinguishability over graphs of bounded treedepth and treewidth", "abstract": "We study the expressive power of first-order logic with counting quantifiers,\nespecially the k-variable and quantifier-rank-q fragment C^k_q, using\nhomomorphism indistinguishability. Recently, Dawar, Jakl, and Reggio~(2021)\nproved that two graphs satisfy the same C^k_q-sentences if and only if they are\nhomomorphism indistinguishable over the class T^k_q of graphs admitting a\nk-pebble forest cover of depth q. After reproving this result using elementary\nmeans, we provide a graph-theoretic analysis of the graph class T^k_q. This\nallows us to separate T^k_q from the intersection TW_{k-1} \\cap TD_q, provided\nthat q is sufficiently larger than k. Here TW_{k-1} is the class of all graphs\nof treewidth at most k-1 and TD_q is the class of all graphs of treedepth at\nmost q.\n  We are able to lift this separation to a (semantic) separation of the\nrespective homomorphism indistinguishability relations \\equiv_{T^k_q} and\n\\equiv_{TW_{k-1} \\cap TD_q}. We do this by showing that the classes TD_q and\nT^k_q are homomorphism distinguishing closed, as conjectured by\nRoberson~(2022).\n  In order to prove Roberson's conjecture for T^k_q we characterise T^k_q in\nterms of a monotone Cops-and-Robber game. The crux is to prove that if Cop has\na winning strategy then Cop also has a winning strategy that is monotone. To\nthat end, we show how to transform Cops' winning strategy into a\npree-tree-decomposition, which is inspired by decompositions of matroids, and\nthen applying an intricate breadth-first `cleaning up' procedure along the\npree-tree-decomposition (which may temporarily lose the property of\nrepresenting a strategy), in order to achieve monotonicity while controlling\nthe number of rounds simultaneously across all branches of the decomposition\nvia a vertex exchange argument.", "published": "2025-05-02 11:32:01", "link": "http://arxiv.org/abs/2505.01193v1", "categories": ["cs.LO", "cs.DM", "math.CO"], "primary_category": "cs.LO"}
{"title": "The tape reconfiguration problem and its consequences for dominating set reconfiguration", "abstract": "A dominating set of a graph $G=(V,E)$ is a set of vertices $D \\subseteq V$\nwhose closed neighborhood is $V$, i.e., $N[D]=V$. We view a dominating set as a\ncollection of tokens placed on the vertices of $D$. In the token sliding\nvariant of the Dominating Set Reconfiguration problem (TS-DSR), we seek to\ntransform a source dominating set into a target dominating set in $G$ by\nsliding tokens along edges, and while maintaining a dominating set all along\nthe transformation.\n  TS-DSR is known to be PSPACE-complete even restricted to graphs of pathwidth\n$w$, for some non-explicit constant $w$ and to be XL-complete parameterized by\nthe size $k$ of the solution. The first contribution of this article consists\nin using a novel approach to provide the first explicit constant for which the\nTS-DSR problem is PSPACE-complete, a question that was left open in the\nliterature.\n  From a parameterized complexity perspective, the token jumping variant of\nDSR, i.e., where tokens can jump to arbitrary vertices, is known to be FPT when\nparameterized by the size of the dominating sets on nowhere dense classes of\ngraphs. But, in contrast, no non-trivial result was known about TS-DSR. We\nprove that DSR is actually much harder in the sliding model since it is\nXL-complete when restricted to bounded pathwidth graphs and even when\nparameterized by $k$ plus the feedback vertex set number of the graph. This\ngives, for the first time, a difference of behavior between the complexity\nunder token sliding and token jumping for some problem on graphs of bounded\ntreewidth. All our results are obtained using a brand new method, based on the\nhardness of the so-called Tape Reconfiguration problem, a problem we believe to\nbe of independent interest.", "published": "2025-05-02 04:26:05", "link": "http://arxiv.org/abs/2505.00988v1", "categories": ["cs.CC", "cs.DM", "cs.DS", "math.CO"], "primary_category": "cs.CC"}
{"title": "CppSATD: A Reusable Self-Admitted Technical Debt Dataset in C++", "abstract": "In software development, technical debt (TD) refers to suboptimal\nimplementation choices made by the developers to meet urgent deadlines and\nlimited resources, posing challenges for future maintenance. Self-Admitted\nTechnical Debt (SATD) is a sub-type of TD, representing specific TD instances\n``openly admitted'' by the developers and often expressed through source code\ncomments. Previous research on SATD has focused predominantly on the Java\nprogramming language, revealing a significant gap in cross-language SATD. Such\na narrow focus limits the generalizability of existing findings as well as SATD\ndetection techniques across multiple programming languages. Our work addresses\nsuch limitation by introducing CppSATD, a dedicated C++ SATD dataset,\ncomprising over 531,000 annotated comments and their source code contexts. Our\ndataset can serve as a foundation for future studies that aim to develop SATD\ndetection methods in C++, generalize the existing findings to other languages,\nor contribute novel insights to cross-language SATD research.", "published": "2025-05-02 09:25:41", "link": "http://arxiv.org/abs/2505.01136v1", "categories": ["cs.SE", "cs.IR", "cs.LG", "cs.PL"], "primary_category": "cs.SE"}
{"title": "Multi-agents based User Values Mining for Recommendation", "abstract": "Recommender systems have rapidly evolved and become integral to many online\nservices. However, existing systems sometimes produce unstable and\nunsatisfactory recommendations that fail to align with users' fundamental and\nlong-term preferences. This is because they primarily focus on extracting\nshallow and short-term interests from user behavior data, which is inherently\ndynamic and challenging to model. Unlike these transient interests, user values\nare more stable and play a crucial role in shaping user behaviors, such as\npurchasing items and consuming content. Incorporating user values into\nrecommender systems can help stabilize recommendation performance and ensure\nresults better reflect users' latent preferences. However, acquiring user\nvalues is typically difficult and costly. To address this challenge, we\nleverage the strong language understanding, zero-shot inference, and\ngeneralization capabilities of Large Language Models (LLMs) to extract user\nvalues from users' historical interactions. Unfortunately, direct extraction\nusing LLMs presents several challenges such as length constraints and\nhallucination. To overcome these issues, we propose ZOOM, a zero-shot multi-LLM\ncollaborative framework for effective and accurate user value extraction. In\nZOOM, we apply text summarization techniques to condense item content while\npreserving essential meaning. To mitigate hallucinations, ZOOM introduces two\nspecialized agent roles: evaluators and supervisors, to collaboratively\ngenerate accurate user values. Extensive experiments on two widely used\nrecommendation datasets with two state-of-the-art recommendation models\ndemonstrate the effectiveness and generalization of our framework in automatic\nuser value mining and recommendation performance improvement.", "published": "2025-05-02 04:01:31", "link": "http://arxiv.org/abs/2505.00981v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Enhancing User Sequence Modeling through Barlow Twins-based Self-Supervised Learning", "abstract": "User sequence modeling is crucial for modern large-scale recommendation\nsystems, as it enables the extraction of informative representations of users\nand items from their historical interactions. These user representations are\nwidely used for a variety of downstream tasks to enhance users' online\nexperience. A key challenge for learning these representations is the lack of\nlabeled training data. While self-supervised learning (SSL) methods have\nemerged as a promising solution for learning representations from unlabeled\ndata, many existing approaches rely on extensive negative sampling, which can\nbe computationally expensive and may not always be feasible in real-world\nscenario. In this work, we propose an adaptation of Barlow Twins, a\nstate-of-the-art SSL methods, to user sequence modeling by incorporating\nsuitable augmentation methods. Our approach aims to mitigate the need for large\nnegative sample batches, enabling effective representation learning with\nsmaller batch sizes and limited labeled data. We evaluate our method on the\nMovieLens-1M, MovieLens-20M, and Yelp datasets, demonstrating that our method\nconsistently outperforms the widely-used dual encoder model across three\ndownstream tasks, achieving an 8%-20% improvement in accuracy. Our findings\nunderscore the effectiveness of our approach in extracting valuable\nsequence-level information for user modeling, particularly in scenarios where\nlabeled data is scarce and negative examples are limited.", "published": "2025-05-02 02:04:52", "link": "http://arxiv.org/abs/2505.00953v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Preserving Privacy and Utility in LLM-Based Product Recommendations", "abstract": "Large Language Model (LLM)-based recommendation systems leverage powerful\nlanguage models to generate personalized suggestions by processing user\ninteractions and preferences. Unlike traditional recommendation systems that\nrely on structured data and collaborative filtering, LLM-based models process\ntextual and contextual information, often using cloud-based infrastructure.\nThis raises privacy concerns, as user data is transmitted to remote servers,\nincreasing the risk of exposure and reducing control over personal information.\nTo address this, we propose a hybrid privacy-preserving recommendation\nframework which separates sensitive from nonsensitive data and only shares the\nlatter with the cloud to harness LLM-powered recommendations. To restore lost\nrecommendations related to obfuscated sensitive data, we design a\nde-obfuscation module that reconstructs sensitive recommendations locally.\nExperiments on real-world e-commerce datasets show that our framework achieves\nalmost the same recommendation utility with a system which shares all data with\nan LLM, while preserving privacy to a large extend. Compared to\nobfuscation-only techniques, our approach improves HR@10 scores and category\ndistribution alignment, offering a better balance between privacy and\nrecommendation quality. Furthermore, our method runs efficiently on\nconsumer-grade hardware, making privacy-aware LLM-based recommendation systems\npractical for real-world use.", "published": "2025-05-02 01:54:08", "link": "http://arxiv.org/abs/2505.00951v1", "categories": ["cs.IR", "cs.CR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Timely Tracking of a Wiener Process With Single Bit Quantization", "abstract": "We consider the problem of timely tracking of a Wiener process via an\nenergy-conserving sensor by utilizing a single bit quantization strategy under\nperiodic sampling. Contrary to conventional single bit quantizers which only\nutilize the transmitted bit to convey information, in our codebook, we use an\nadditional `$\\emptyset$' symbol to encode the event of \\emph{not transmitting}.\nThus, our quantization functions are composed of three decision regions as\nopposed to the conventional two regions. First, we propose an optimum\nquantization method in which the optimum quantization functions are obtained by\ntracking the distributions of the quantization error. However, this method\nrequires a high computational cost and might not be applicable for\nenergy-conserving sensors. Thus, we propose two additional low complexity\nmethods. In the last-bit aware method, three predefined quantization functions\nare available to both devices, and they switch the quantization function based\non the last transmitted bit. With the Gaussian approximation method, we\ncalculate a single quantization function by assuming that the quantization\nerror can be approximated as Gaussian. While previous methods require a\nconstant delay assumption, this method also works for random delay. We observe\nthat all three methods perform similarly in terms of mean-squared error and\ntransmission cost.", "published": "2025-05-02 17:54:26", "link": "http://arxiv.org/abs/2505.01419v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Semantic Communication: From Philosophical Conceptions Towards a Mathematical Framework", "abstract": "Semantic communication has emerged as a promising paradigm to address the\nchallenges of next-generation communication networks. While some progress has\nbeen made in its conceptualization, fundamental questions remain unresolved. In\nthis paper, we propose a probabilistic model for semantic communication that,\nunlike prior works primarily rooted in intuitions from human language, is\ngrounded in a rigorous philosophical conception of information and its\nrelationship with data as Constraining Affordances, mediated by Levels of\nAbstraction (LoA). This foundation not only enables the modeling of linguistic\nsemantic communication but also provides a domain-independent definition of\nsemantic content, extending its applicability beyond linguistic contexts. As\nthe semantic communication problem involves a complex interplay of various\nfactors, making it difficult to tackle in its entirety, we propose to\northogonalize it by classifying it into simpler sub-problems and approach the\ngeneral problem step by step. Notably, we show that Shannon's framework\nconstitutes a special case of semantic communication, in which each message\nconveys a single, unambiguous meaning. Consequently, the capacity in Shannon's\nmodel-defined as the maximum rate of reliably transmissible messages-coincides\nwith the semantic capacity under this constrained scenario. In this paper, we\nspecifically focus on the sub-problem where semantic ambiguity arises solely\nfrom physical channel noise and derive a lower bound for its semantic capacity,\nwhich reduces to Shannon's capacity in the corresponding special case. We also\ndemonstrate that the achievable rate of all transmissible messages for reliable\nsemantic communication, exceeds Shannon's capacity by the added term H(X|S).", "published": "2025-05-02 15:30:09", "link": "http://arxiv.org/abs/2505.01342v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Shuffling Cards When You Are of Very Little Brain: Low Memory Generation of Permutations", "abstract": "How can we generate a permutation of the numbers $1$ through $n$ so that it\nis hard to guess the next element given the history so far? The twist is that\nthe generator of the permutation (the ``Dealer\") has limited memory, while the\n``Guesser\" has unlimited memory. With unbounded memory (actually $n$ bits\nsuffice), the Dealer can generate a truly random permutation where~$\\ln n$ is\nthe expected number of correct guesses.\n  Our main results are tight bounds for the relationship between the guessing\nprobability and the memory required to generate the permutation. We suggest a\nmethod for the Dealer that requires~$m$ bits of storage, constant time for each\nturn and makes any Guesser pick correctly only $O(n/m+\\log m)$ cards in\nexpectation. The method does not require any secrecy from the dealer, i.e. it\nis ``open book\" or ``whitebox\". On the other hand, we show that this bound is\nthe best possible, even for Dealers with secret memory: For any $m$-bit Dealer\nthere is a (computationally powerful) guesser that makes $\\Omega(n/m+\\log m)$\ncorrect guesses in expectation.\n  We also give an $O(n)$ bit memory Dealer that generates perfectly random\npermutations and operates in constant time per turn.", "published": "2025-05-02 14:00:57", "link": "http://arxiv.org/abs/2505.01287v1", "categories": ["cs.DS", "cs.CR", "cs.IT", "math.IT"], "primary_category": "cs.DS"}
{"title": "Robust Deep Learning-Based Physical Layer Communications: Strategies and Approaches", "abstract": "Deep learning (DL) has emerged as a transformative technology with immense\npotential to reshape the sixth-generation (6G) wireless communication network.\nBy utilizing advanced algorithms for feature extraction and pattern\nrecognition, DL provides unprecedented capabilities in optimizing the network\nefficiency and performance, particularly in physical layer communications.\nAlthough DL technologies present the great potential, they also face\nsignificant challenges related to the robustness, which are expected to\nintensify in the complex and demanding 6G environment. Specifically, current DL\nmodels typically exhibit substantial performance degradation in dynamic\nenvironments with time-varying channels, interference of noise and different\nscenarios, which affect their effectiveness in diverse real-world applications.\nThis paper provides a comprehensive overview of strategies and approaches for\nrobust DL-based methods in physical layer communications. First we introduce\nthe key challenges that current DL models face. Then we delve into a detailed\nexamination of DL approaches specifically tailored to enhance robustness in 6G,\nwhich are classified into data-driven and model-driven strategies. Finally, we\nverify the effectiveness of these methods by case studies and outline future\nresearch directions.", "published": "2025-05-02 12:45:26", "link": "http://arxiv.org/abs/2505.01234v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Enabling Training-Free Semantic Communication Systems with Generative Diffusion Models", "abstract": "Semantic communication (SemCom) has recently emerged as a promising paradigm\nfor next-generation wireless systems. Empowered by advanced artificial\nintelligence (AI) technologies, SemCom has achieved significant improvements in\ntransmission quality and efficiency. However, existing SemCom systems either\nrely on training over large datasets and specific channel conditions or suffer\nfrom performance degradation under channel noise when operating in a\ntraining-free manner. To address these issues, we explore the use of generative\ndiffusion models (GDMs) as training-free SemCom systems. Specifically, we\ndesign a semantic encoding and decoding method based on the inversion and\nsampling process of the denoising diffusion implicit model (DDIM), which\nintroduces a two-stage forward diffusion process, split between the transmitter\nand receiver to enhance robustness against channel noise. Moreover, we optimize\nsampling steps to compensate for the increased noise level caused by channel\nnoise. We also conduct a brief analysis to provide insights about this design.\nSimulations on the Kodak dataset validate that the proposed system outperforms\nthe existing baseline SemCom systems across various metrics.", "published": "2025-05-02 11:53:45", "link": "http://arxiv.org/abs/2505.01209v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Continuous Aperture Array (CAPA)-Based Multi-Group Multicast Communications", "abstract": "A continuous aperture array (CAPA)-based multi-group multicast communication\nsystem is investigated. An integral-based CAPA multi-group multicast\nbeamforming design is formulated for the maximization of the system energy\nefficiency (EE), subject to a minimum multicast SE constraint of each user\ngroup and a total transmit power constraint. To address this non-econvex\nfractional programming problem, the Dinkelbach's method is employed. Within the\nDinkelbach's framework, the non-convex group-wise multicast spectral efficiency\n(SE) constraint is first equivalently transformed into a tractable form with\nauxiliary variables. Then, an efficient block coordinate descent (BCD)-based\nalgorithm is developed to solve the reformulated problem. The CAPA beamforming\ndesign subproblem can be optimally solved via the Lagrangian dual method and\nthe calculus of variations (CoV) theory. It reveals that the optimal CAPA\nbeamformer should be a combination of all the groups' user channels. To further\nreduce the computational complexity, a low-complexity zero-forcing (ZF)-based\napproach is proposed. The closed-form ZF CAPA beamformer is derived using each\ngroup's most representative user channel to mitigate the inter-group\ninterference while ensuring the intra-group multicast performance. Then, the\nbeamforming design subproblem in the BCD-based algorithm becomes a convex power\nallocation subproblem, which can be efficiently solved. Numerical results\ndemonstrate that 1) the CAPA can significantly improve the EE compared to\nconventional spatially discrete arrays (SPDAs); 2) due to the enhanced spatial\nresolutions, increasing the aperture size of CAPA is not always beneficial for\nEE enhancement in multicast scenarios; and 3) wider user distributions of each\ngroup cause a significant EE degradation of CAPA compared to SPDA.", "published": "2025-05-02 11:14:23", "link": "http://arxiv.org/abs/2505.01190v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Spectral Efficiency Analysis of Near-Field Holographic MIMO over Ricean Fading Channels", "abstract": "With the denser distribution of antenna elements, stronger mutual coupling\neffects would kick in among antenna elements, which would eventually affect the\ncommunication performance. Meanwhile, as the holographic array usually has\nlarge physical size, the possibility of near-field communication increases.\nThis paper investigates a near-field multi-user downlink HMIMO system and\ncharacterizes the spectral efficiency (SE) under the mutual coupling effect\nover Ricean fading channels. Both perfect and imperfect channel state\ninformation (CSI) scenarios are considered. (i) For the perfect CSI case, the\nmutual coupling and radiation efficiency model are first established. Then, the\nclosed-form SE is derived under maximum ratio transmission (MRT). By comparing\nthe SE between the cases with and without mutual coupling, it is unveiled that\nthe system SE with mutual coupling might outperform that without mutual\ncoupling in the low transmit power regime for a given aperture size. Moreover,\nit is also unveiled that the inter-user interference cannot be eliminated\nunless the physical size of the array increases to infinity. Fortunately, the\nadditional distance term in the near-field channel can be exploited for the\ninter-user interference mitigation, especially for the worst case, where the\nusers' angular positions overlap to a great extent. (ii) For the imperfect CSI\ncase, the channel estimation error is considered for the derivation of the\nclosed-form SE under MRT. It shows that in the low transmit power regime, the\nsystem SE can be enhanced by increasing the pilot power and the antenna element\ndensity, the latter of which will lead to severe mutual coupling. In the high\ntransmit power regime, increasing the pilot power has a limited effect on\nimproving the system SE. However, increasing the antenna element density\nremains highly beneficial for enhancing the system SE.", "published": "2025-05-02 11:02:57", "link": "http://arxiv.org/abs/2505.01187v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Realizing Fully-Connected Layers Over the Air via Reconfigurable Intelligent Surfaces", "abstract": "By leveraging the waveform superposition property of the multiple access\nchannel, over-the-air computation (AirComp) enables the execution of digital\ncomputations through analog means in the wireless domain, leading to faster\nprocessing and reduced latency. In this paper, we propose a novel approach to\nimplement a neural network (NN) consisting of digital fully connected (FC)\nlayers using physically reconfigurable hardware. Specifically, we investigate\nreconfigurable intelligent surfaces (RISs)-assisted multiple-input\nmultiple-output (MIMO) systems to emulate the functionality of a NN for\nover-the-air inference. In this setup, both the RIS and the transceiver are\njointly configured to manipulate the ambient wireless propagation environment,\neffectively reproducing the adjustable weights of a digital FC layer. We refer\nto this new computational paradigm as \\textit{AirFC}. We formulate an imitation\nerror minimization problem between the effective channel created by RIS and a\ntarget FC layer by jointly optimizing over-the-air parameters. To solve this\nnon-convex optimization problem, an extremely low-complexity alternating\noptimization algorithm is proposed, where semi-closed-form/closed-form\nsolutions for all optimization variables are derived. Simulation results show\nthat the RIS-assisted MIMO-based AirFC can achieve competitive classification\naccuracy. Furthermore, it is also shown that a multi-RIS configuration\nsignificantly outperforms a single-RIS setup, particularly in line-of-sight\n(LoS)-dominated channels.", "published": "2025-05-02 10:21:44", "link": "http://arxiv.org/abs/2505.01170v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Polarization Decomposition and Its Applications", "abstract": "The polarization decomposition for arbitrary binary-input memoryless channels\n(BMCs) is investigated. By defining the polarization factor (PF) based on the\nconditional entropy of channel output under various input combinations, it is\nshown that the symmetric capacities of polarized subchannels can be expressed\nby the PF in the general form. We derive the explicit form of PF with respect\nto block length and subchannel index. Meanwhile, we propose an efficient\ncalculation algorithm for the PF. Particularly, we demonstrate that any PF can\ncorrespond to a $n$-ary tree. Based on this structure, we design the\ncalculation approach of the conditional entropy under different input\nrelations. The proposed polarization algorithm provides both new theoretical\ninsights and practical values such as visualization of polarization and polar\ncode construction. Moreover, our approach first makes it possible to\nefficiently calculate the symmetric capacities of all subchannels for any BMCs.", "published": "2025-05-02 09:53:31", "link": "http://arxiv.org/abs/2505.01152v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Quasi-Static IRS: 3D Shaped Beamforming for Area Coverage Enhancement", "abstract": "Intelligent reflecting surface (IRS) is a promising paradigm to reconfigure\nthe wireless environment for enhanced communication coverage and quality.\nHowever, to compensate for the double pathloss effect, massive IRS elements are\nrequired, raising concerns on the scalability of cost and complexity. This\npaper introduces a new architecture of quasi-static IRS (QS-IRS), which tunes\nelement phases via mechanical adjustment or manually re-arranging the array\ntopology. QS-IRS relies on massive production/assembly of purely passive\nelements only, and thus is suitable for ultra low-cost and large-scale\ndeployment to enhance long-term coverage. To achieve this end, an IRS-aided\narea coverage problem is formulated, which explicitly considers the element\nradiation pattern (ERP), with the newly introduced shape masks for the\nmainlobe, and the sidelobe constraints to reduce energy leakage. An alternating\noptimization (AO) algorithm based on the difference-of-convex (DC) and\nsuccessive convex approximation (SCA) procedure is proposed, which achieves\nshaped beamforming with power gains close to that of the joint optimization\nalgorithm, but with significantly reduced computational complexity.", "published": "2025-05-02 07:33:02", "link": "http://arxiv.org/abs/2505.01076v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "On the Worst-Case Complexity of Gibbs Decoding for Reed--Muller Codes", "abstract": "Reed--Muller (RM) codes are known to achieve capacity on binary symmetric\nchannels (BSC) under the Maximum a Posteriori (MAP) decoder. However, it\nremains an open problem to design a capacity achieving polynomial-time RM\ndecoder. Due to a lemma by Liu, Cuff, and Verd\\'u, it can be shown that\ndecoding by sampling from the posterior distribution is also capacity-achieving\nfor RM codes over BSC. The Gibbs decoder is one such Markov Chain Monte Carlo\n(MCMC) based method, which samples from the posterior distribution by flipping\nmessage bits according to the posterior, and can be modified to give other MCMC\ndecoding methods. In this paper, we analyze the mixing time of the Gibbs\ndecoder for RM codes. Our analysis reveals that the Gibbs decoder can exhibit\nslow mixing for certain carefully constructed sequences. This slow mixing\nimplies that, in the worst-case scenario, the decoder requires super-polynomial\ntime to converge to the desired posterior distribution.", "published": "2025-05-02 03:30:16", "link": "http://arxiv.org/abs/2505.00974v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "SemSpaceFL: A Collaborative Hierarchical Federated Learning Framework for Semantic Communication in 6G LEO Satellites", "abstract": "The advent of the sixth-generation (6G) wireless networks, enhanced by\nartificial intelligence, promises ubiquitous connectivity through Low Earth\nOrbit (LEO) satellites. These satellites are capable of collecting vast amounts\nof geographically diverse and real-time data, which can be immensely valuable\nfor training intelligent models. However, limited inter-satellite communication\nand data privacy constraints hinder data collection on a single server for\ntraining. Therefore, we propose SemSpaceFL, a novel hierarchical federated\nlearning (HFL) framework for LEO satellite networks, with integrated semantic\ncommunication capabilities. Our framework introduces a two-tier aggregation\narchitecture where satellite models are first aggregated at regional gateways\nbefore final consolidation at a cloud server, which explicitly accounts for\nsatellite mobility patterns and energy constraints. The key innovation lies in\nour novel aggregation approach, which dynamically adjusts the contribution of\neach satellite based on its trajectory and association with different gateways,\nwhich ensures stable model convergence despite the highly dynamic nature of LEO\nconstellations. To further enhance communication efficiency, we incorporate\nsemantic encoding-decoding techniques trained through the proposed HFL\nframework, which enables intelligent data compression while maintaining signal\nintegrity. Our experimental results demonstrate that the proposed aggregation\nstrategy achieves superior performance and faster convergence compared to\nexisting benchmarks, while effectively managing the challenges of satellite\nmobility and energy limitations in dynamic LEO networks.", "published": "2025-05-02 03:01:12", "link": "http://arxiv.org/abs/2505.00966v1", "categories": ["cs.IT", "cs.DC", "cs.ET", "cs.NI", "math.IT"], "primary_category": "cs.IT"}
{"title": "Computational, Data-Driven, and Physics-Informed Machine Learning Approaches for Microstructure Modeling in Metal Additive Manufacturing", "abstract": "Metal additive manufacturing enables unprecedented design freedom and the\nproduction of customized, complex components. However, the rapid melting and\nsolidification dynamics inherent to metal AM processes generate heterogeneous,\nnon-equilibrium microstructures that significantly impact mechanical properties\nand subsequent functionality. Predicting microstructure and its evolution\nacross spatial and temporal scales remains a central challenge for process\noptimization and defect mitigation. While conventional experimental techniques\nand physics-based simulations provide a physical foundation and valuable\ninsights, they face critical limitations. In contrast, data-driven machine\nlearning offers an alternative prediction approach and powerful pattern\nrecognition but often operate as black-box, lacking generalizability and\nphysical consistency. To overcome these limitations, physics-informed machine\nlearning, including physics-informed neural networks, has emerged as a\npromising paradigm by embedding governing physical laws into neural network\narchitectures, thereby enhancing accuracy, transparency, data efficiency, and\nextrapolation capabilities. This work presents a comprehensive evaluation of\nmodeling strategies for microstructure prediction in metal AM. The strengths\nand limitations of experimental, computational, and data-driven methods are\nanalyzed in depth, and highlight recent advances in hybrid PIML frameworks that\nintegrate physical knowledge with ML. Key challenges, such as data scarcity,\nmulti-scale coupling, and uncertainty quantification, are discussed alongside\nfuture directions. Ultimately, this assessment underscores the importance of\nPIML-based hybrid approaches in enabling predictive, scalable, and physically\nconsistent microstructure modeling for site-specific, microstructure-aware\nprocess control and the reliable production of high-performance AM components.", "published": "2025-05-02 17:59:54", "link": "http://arxiv.org/abs/2505.01424v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Negative Stepsizes Make Gradient-Descent-Ascent Converge", "abstract": "Efficient computation of min-max problems is a central question in\noptimization, learning, games, and controls. Arguably the most natural\nalgorithm is gradient-descent-ascent (GDA). However, since the 1970s,\nconventional wisdom has argued that GDA fails to converge even on simple\nproblems. This failure spurred an extensive literature on modifying GDA with\nadditional building blocks such as extragradients, optimism, momentum,\nanchoring, etc. In contrast, we show that GDA converges in its original form by\nsimply using a judicious choice of stepsizes.\n  The key innovation is the proposal of unconventional stepsize schedules\n(dubbed slingshot stepsize schedules) that are time-varying, asymmetric, and\nperiodically negative. We show that all three properties are necessary for\nconvergence, and that altogether this enables GDA to converge on the classical\ncounterexamples (e.g., unconstrained convex-concave problems). All of our\nresults apply to the last iterate of GDA, as is typically desired in practice.\n  The core algorithmic intuition is that although negative stepsizes make\nbackward progress, they de-synchronize the min and max variables (overcoming\nthe cycling issue of GDA), and lead to a slingshot phenomenon in which the\nforward progress in the other iterations is overwhelmingly larger. This results\nin fast overall convergence. Geometrically, the slingshot dynamics leverage the\nnon-reversibility of gradient flow: positive/negative steps cancel to first\norder, yielding a second-order net movement in a new direction that leads to\nconvergence and is otherwise impossible for GDA to move in. We interpret this\nas a second-order finite-differencing algorithm and show that, intriguingly, it\napproximately implements consensus optimization, an empirically popular\nalgorithm for min-max problems involving deep neural networks (e.g., training\nGANs).", "published": "2025-05-02 17:59:46", "link": "http://arxiv.org/abs/2505.01423v1", "categories": ["math.OC", "cs.DS", "cs.LG"], "primary_category": "math.OC"}
{"title": "Evaluating Frontier Models for Stealth and Situational Awareness", "abstract": "Recent work has demonstrated the plausibility of frontier AI models scheming\n-- knowingly and covertly pursuing an objective misaligned with its developer's\nintentions. Such behavior could be very hard to detect, and if present in\nfuture advanced systems, could pose severe loss of control risk. It is\ntherefore important for AI developers to rule out harm from scheming prior to\nmodel deployment. In this paper, we present a suite of scheming reasoning\nevaluations measuring two types of reasoning capabilities that we believe are\nprerequisites for successful scheming: First, we propose five evaluations of\nability to reason about and circumvent oversight (stealth). Second, we present\neleven evaluations for measuring a model's ability to instrumentally reason\nabout itself, its environment and its deployment (situational awareness). We\ndemonstrate how these evaluations can be used as part of a scheming inability\nsafety case: a model that does not succeed on these evaluations is almost\ncertainly incapable of causing severe harm via scheming in real deployment. We\nrun our evaluations on current frontier models and find that none of them show\nconcerning levels of either situational awareness or stealth.", "published": "2025-05-02 17:57:14", "link": "http://arxiv.org/abs/2505.01420v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "How Effective are Large Time Series Models in Hydrology? A Study on Water Level Forecasting in Everglades", "abstract": "The Everglades play a crucial role in flood and drought regulation, water\nresource planning, and ecosystem management in the surrounding regions.\nHowever, traditional physics-based and statistical methods for predicting water\nlevels often face significant challenges, including high computational costs\nand limited adaptability to diverse or unforeseen conditions. Recent\nadvancements in large time series models have demonstrated the potential to\naddress these limitations, with state-of-the-art deep learning and foundation\nmodels achieving remarkable success in time series forecasting across various\ndomains. Despite this progress, their application to critical environmental\nsystems, such as the Everglades, remains underexplored. In this study, we fill\nthe gap by investigating twelve task-specific models and five time series\nfoundation models across six categories for a real-world application focused on\nwater level prediction in the Everglades. Our primary results show that the\nfoundation model, Chronos, significantly outperforms all other models while the\nremaining foundation models exhibit relatively poor performance. Moreover, the\nperformance of task-specific models varies with the model architectures.\nLastly, we discuss the possible reasons for the varying performance of models.", "published": "2025-05-02 17:48:20", "link": "http://arxiv.org/abs/2505.01415v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Predicting the Price of Gold in the Financial Markets Using Hybrid Models", "abstract": "Predicting the price that has the least error and can provide the best and\nhighest accuracy has been one of the most challenging issues and one of the\nmost critical concerns among capital market activists and researchers.\nTherefore, a model that can solve problems and provide results with high\naccuracy is one of the topics of interest among researchers. In this project,\nusing time series prediction models such as ARIMA to estimate the price,\nvariables, and indicators related to technical analysis show the behavior of\ntraders involved in involving psychological factors for the model. By linking\nall of these variables to stepwise regression, we identify the best variables\ninfluencing the prediction of the variable. Finally, we enter the selected\nvariables as inputs to the artificial neural network. In other words, we want\nto call this whole prediction process the \"ARIMA_Stepwise Regression_Neural\nNetwork\" model and try to predict the price of gold in international financial\nmarkets. This approach is expected to be able to be used to predict the types\nof stocks, commodities, currency pairs, financial market indicators, and other\nitems used in local and international financial markets. Moreover, a comparison\nbetween the results of this method and time series methods is also expressed.\nFinally, based on the results, it can be seen that the resulting hybrid model\nhas the highest accuracy compared to the time series method, regression, and\nstepwise regression.", "published": "2025-05-02 17:25:47", "link": "http://arxiv.org/abs/2505.01402v1", "categories": ["cs.LG", "econ.EM"], "primary_category": "cs.LG"}
{"title": "Learning and Transferring Physical Models through Derivatives", "abstract": "We propose Derivative Learning (DERL), a supervised approach that models\nphysical systems by learning their partial derivatives. We also leverage DERL\nto build physical models incrementally, by designing a distillation protocol\nthat effectively transfers knowledge from a pre-trained to a student model. We\nprovide theoretical guarantees that our approach can learn the true physical\nsystem, being consistent with the underlying physical laws, even when using\nempirical derivatives. DERL outperforms state-of-the-art methods in\ngeneralizing an ODE to unseen initial conditions and a parametric PDE to unseen\nparameters. We finally propose a method based on DERL to transfer physical\nknowledge across models by extending them to new portions of the physical\ndomain and new range of PDE parameters. We believe this is the first attempt at\nbuilding physical models incrementally in multiple stages.", "published": "2025-05-02 17:02:00", "link": "http://arxiv.org/abs/2505.01391v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Carbon Aware Transformers Through Joint Model-Hardware Optimization", "abstract": "The rapid growth of machine learning (ML) systems necessitates a more\ncomprehensive evaluation of their environmental impact, particularly their\ncarbon footprint, which comprises operational carbon from training and\ninference execution and embodied carbon from hardware manufacturing and its\nentire life-cycle. Despite the increasing importance of embodied emissions,\nthere is a lack of tools and frameworks to holistically quantify and optimize\nthe total carbon footprint of ML systems. To address this, we propose\nCATransformers, a carbon-aware architecture search framework that enables\nsustainability-driven co-optimization of ML models and hardware architectures.\nBy incorporating both operational and embodied carbon metrics into early design\nspace exploration of domain-specific hardware accelerators, CATransformers\ndemonstrates that optimizing for carbon yields design choices distinct from\nthose optimized solely for latency or energy efficiency. We apply our framework\nto multi-modal CLIP-based models, producing CarbonCLIP, a family of CLIP models\nachieving up to 17% reduction in total carbon emissions while maintaining\naccuracy and latency compared to state-of-the-art edge small CLIP baselines.\nThis work underscores the need for holistic optimization methods to design\nhigh-performance, environmentally sustainable AI systems.", "published": "2025-05-02 16:49:10", "link": "http://arxiv.org/abs/2505.01386v1", "categories": ["cs.LG", "cs.AR"], "primary_category": "cs.LG"}
{"title": "Provable Efficiency of Guidance in Diffusion Models for General Data Distribution", "abstract": "Diffusion models have emerged as a powerful framework for generative\nmodeling, with guidance techniques playing a crucial role in enhancing sample\nquality. Despite their empirical success, a comprehensive theoretical\nunderstanding of the guidance effect remains limited. Existing studies only\nfocus on case studies, where the distribution conditioned on each class is\neither isotropic Gaussian or supported on a one-dimensional interval with some\nextra conditions. How to analyze the guidance effect beyond these case studies\nremains an open question. Towards closing this gap, we make an attempt to\nanalyze diffusion guidance under general data distributions. Rather than\ndemonstrating uniform sample quality improvement, which does not hold in some\ndistributions, we prove that guidance can improve the whole sample quality, in\nthe sense that the average reciprocal of the classifier probability decreases\nwith the existence of guidance. This aligns with the motivation of introducing\nguidance.", "published": "2025-05-02 16:46:43", "link": "http://arxiv.org/abs/2505.01382v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Stabilizing Temporal Difference Learning via Implicit Stochastic Approximation", "abstract": "Temporal Difference (TD) learning is a foundational algorithm in\nreinforcement learning (RL). For nearly forty years, TD learning has served as\na workhorse for applied RL as well as a building block for more complex and\nspecialized algorithms. However, despite its widespread use, it is not without\ndrawbacks, the most prominent being its sensitivity to step size. A poor choice\nof step size can dramatically inflate the error of value estimates and slow\nconvergence. Consequently, in practice, researchers must use trial and error in\norder to identify a suitable step size -- a process that can be tedious and\ntime consuming. As an alternative, we propose implicit TD algorithms that\nreformulate TD updates into fixed-point equations. These updates are more\nstable and less sensitive to step size without sacrificing computational\nefficiency. Moreover, our theoretical analysis establishes asymptotic\nconvergence guarantees and finite-time error bounds. Our results demonstrate\ntheir robustness and practicality for modern RL tasks, establishing implicit TD\nas a versatile tool for policy evaluation and value approximation.", "published": "2025-05-02 15:57:54", "link": "http://arxiv.org/abs/2505.01361v1", "categories": ["cs.LG", "math.PR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Learning Stabilizing Policies via an Unstable Subspace Representation", "abstract": "We study the problem of learning to stabilize (LTS) a linear time-invariant\n(LTI) system. Policy gradient (PG) methods for control assume access to an\ninitial stabilizing policy. However, designing such a policy for an unknown\nsystem is one of the most fundamental problems in control, and it may be as\nhard as learning the optimal policy itself. Existing work on the LTS problem\nrequires large data as it scales quadratically with the ambient dimension. We\npropose a two-phase approach that first learns the left unstable subspace of\nthe system and then solves a series of discounted linear quadratic regulator\n(LQR) problems on the learned unstable subspace, targeting to stabilize only\nthe system's unstable dynamics and reduce the effective dimension of the\ncontrol space. We provide non-asymptotic guarantees for both phases and\ndemonstrate that operating on the unstable subspace reduces sample complexity.\nIn particular, when the number of unstable modes is much smaller than the state\ndimension, our analysis reveals that LTS on the unstable subspace substantially\nspeeds up the stabilization process. Numerical experiments are provided to\nsupport this sample complexity reduction achieved by our approach.", "published": "2025-05-02 15:34:36", "link": "http://arxiv.org/abs/2505.01348v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "How much to Dereverberate? Low-Latency Single-Channel Speech Enhancement in Distant Microphone Scenarios", "abstract": "Dereverberation is an important sub-task of Speech Enhancement (SE) to\nimprove the signal's intelligibility and quality. However, it remains\nchallenging because the reverberation is highly correlated with the signal.\nFurthermore, the single-channel SE literature has predominantly focused on\nrooms with short reverb times (typically under 1 second), smaller rooms (under\nvolumes of 1000 cubic meters) and relatively short distances (up to 2 meters).\nIn this paper, we explore real-time low-latency single-channel SE under distant\nmicrophone scenarios, such as 5 to 10 meters, and focus on conference rooms and\ntheatres, with larger room dimensions and reverberation times. Such a setup is\nuseful for applications such as lecture demonstrations, drama, and to enhance\nstage acoustics. First, we show that single-channel SE in such challenging\nscenarios is feasible. Second, we investigate the relationship between room\nvolume and reverberation time, and demonstrate its importance when randomly\nsimulating room impulse responses. Lastly, we show that for dereverberation\nwith short decay times, preserving early reflections before decaying the\ntransfer function of the room improves overall signal quality.", "published": "2025-05-02 15:09:50", "link": "http://arxiv.org/abs/2505.01338v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "I.5.1; I.5.4"], "primary_category": "eess.AS"}
{"title": "Enhancing Diversity in Parallel Agents: A Maximum State Entropy Exploration Story", "abstract": "Parallel data collection has redefined Reinforcement Learning (RL), unlocking\nunprecedented efficiency and powering breakthroughs in large-scale real-world\napplications. In this paradigm, $N$ identical agents operate in $N$ replicas of\nan environment simulator, accelerating data collection by a factor of $N$. A\ncritical question arises: \\textit{Does specializing the policies of the\nparallel agents hold the key to surpass the $N$ factor acceleration?} In this\npaper, we introduce a novel learning framework that maximizes the entropy of\ncollected data in a parallel setting. Our approach carefully balances the\nentropy of individual agents with inter-agent diversity, effectively minimizing\nredundancies. The latter idea is implemented with a centralized policy gradient\nmethod, which shows promise when evaluated empirically against systems of\nidentical agents, as well as synergy with batch RL techniques that can exploit\ndata diversity. Finally, we provide an original concentration analysis that\nshows faster rates for specialized parallel sampling distributions, which\nsupports our methodology and may be of independent interest.", "published": "2025-05-02 15:08:17", "link": "http://arxiv.org/abs/2505.01336v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Integration of Multi-Mode Preference into Home Energy Management System Using Deep Reinforcement Learning", "abstract": "Home Energy Management Systems (HEMS) have emerged as a pivotal tool in the\nsmart home ecosystem, aiming to enhance energy efficiency, reduce costs, and\nimprove user comfort. By enabling intelligent control and optimization of\nhousehold energy consumption, HEMS plays a significant role in bridging the gap\nbetween consumer needs and energy utility objectives. However, much of the\nexisting literature construes consumer comfort as a mere deviation from the\nstandard appliance settings. Such deviations are typically incorporated into\noptimization objectives via static weighting factors. These factors often\noverlook the dynamic nature of consumer behaviors and preferences. Addressing\nthis oversight, our paper introduces a multi-mode Deep Reinforcement\nLearning-based HEMS (DRL-HEMS) framework, meticulously designed to optimize\nbased on dynamic, consumer-defined preferences. Our primary goal is to augment\nconsumer involvement in Demand Response (DR) programs by embedding dynamic\nmulti-mode preferences tailored to individual appliances. In this study, we\nleverage a model-free, single-agent DRL algorithm to deliver a HEMS framework\nthat is not only dynamic but also user-friendly. To validate its efficacy, we\nemployed real-world data at 15-minute intervals, including metrics such as\nelectricity price, ambient temperature, and appliances' power consumption. Our\nresults show that the model performs exceptionally well in optimizing energy\nconsumption within different preference modes. Furthermore, when compared to\ntraditional algorithms based on Mixed-Integer Linear Programming (MILP), our\nmodel achieves nearly optimal performance while outperforming in computational\nefficiency.", "published": "2025-05-02 15:05:29", "link": "http://arxiv.org/abs/2505.01332v1", "categories": ["cs.LG", "cs.SY", "eess.SY", "stat.AP"], "primary_category": "cs.LG"}
{"title": "Model See Model Do: Speech-Driven Facial Animation with Style Control", "abstract": "Speech-driven 3D facial animation plays a key role in applications such as\nvirtual avatars, gaming, and digital content creation. While existing methods\nhave made significant progress in achieving accurate lip synchronization and\ngenerating basic emotional expressions, they often struggle to capture and\neffectively transfer nuanced performance styles. We propose a novel\nexample-based generation framework that conditions a latent diffusion model on\na reference style clip to produce highly expressive and temporally coherent\nfacial animations. To address the challenge of accurately adhering to the style\nreference, we introduce a novel conditioning mechanism called style basis,\nwhich extracts key poses from the reference and additively guides the diffusion\ngeneration process to fit the style without compromising lip synchronization\nquality. This approach enables the model to capture subtle stylistic cues while\nensuring that the generated animations align closely with the input speech.\nExtensive qualitative, quantitative, and perceptual evaluations demonstrate the\neffectiveness of our method in faithfully reproducing the desired style while\nachieving superior lip synchronization across various speech scenarios.", "published": "2025-05-02 14:47:21", "link": "http://arxiv.org/abs/2505.01319v1", "categories": ["cs.GR", "cs.LG", "I.3.7; I.3.8"], "primary_category": "cs.GR"}
{"title": "MultiGran-STGCNFog: Towards Accurate and High-Throughput Inference for Multi-Granular Spatiotemporal Traffic Forecasting", "abstract": "Accurate traffic forecasting and swift inference provision are essential for\nintelligent transportation systems. However, the present Graph Convolutional\nNetwork (GCN)-based approaches cannot extract and fuse multi-granular\nspatiotemporal features across various spatial and temporal scales\nsufficiently, proven to yield less accurate forecasts. Besides, additional\nfeature extraction branches introduced in prior studies critically increased\nmodel complexity and extended inference time, making it challenging to provide\nfast inference for traffic forecasting. In this paper, we propose\nMultiGran-STGCNFog, an efficient fog distributed inference system with a novel\ntraffic forecasting model that employs multi-granular spatiotemporal feature\nfusion on generated dynamic traffic graphs to fully capture interdependent\ntraffic dynamics. The proposed scheduling algorithm GA-DPHDS, optimizing layer\nexecution order and layer-device scheduling scheme simultaneously, contributes\nto considerable inference throughput improvement by leveraging heterogeneous\nfog devices in a pipelined manner. Extensive experiments on real-world datasets\ndemonstrate the superiority of the proposed method over selected baselines.", "published": "2025-05-02 13:55:22", "link": "http://arxiv.org/abs/2505.01279v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Provably Convergent Plug-and-Play Framework for Stochastic Bilevel Optimization", "abstract": "Bilevel optimization has recently attracted significant attention in machine\nlearning due to its wide range of applications and advanced hierarchical\noptimization capabilities. In this paper, we propose a plug-and-play framework,\nnamed PnPBO, for developing and analyzing stochastic bilevel optimization\nmethods. This framework integrates both modern unbiased and biased stochastic\nestimators into the single-loop bilevel optimization framework introduced in\n[9], with several improvements. In the implementation of PnPBO, all stochastic\nestimators for different variables can be independently incorporated, and an\nadditional moving average technique is applied when using an unbiased estimator\nfor the upper-level variable. In the theoretical analysis, we provide a unified\nconvergence and complexity analysis for PnPBO, demonstrating that the\nadaptation of various stochastic estimators (including PAGE, ZeroSARAH, and\nmixed strategies) within the PnPBO framework achieves optimal sample\ncomplexity, comparable to that of single-level optimization. This resolves the\nopen question of whether the optimal complexity bounds for solving bilevel\noptimization are identical to those for single-level optimization. Finally, we\nempirically validate our framework, demonstrating its effectiveness on several\nbenchmark problems and confirming our theoretical findings.", "published": "2025-05-02 13:26:43", "link": "http://arxiv.org/abs/2505.01258v1", "categories": ["math.OC", "cs.LG"], "primary_category": "math.OC"}
{"title": "mwBTFreddy: A Dataset for Flash Flood Damage Assessment in Urban Malawi", "abstract": "This paper describes the mwBTFreddy dataset, a resource developed to support\nflash flood damage assessment in urban Malawi, specifically focusing on the\nimpacts of Cyclone Freddy in 2023. The dataset comprises paired pre- and\npost-disaster satellite images sourced from Google Earth Pro, accompanied by\nJSON files containing labelled building annotations with geographic coordinates\nand damage levels (no damage, minor, major, or destroyed). Developed by the\nKuyesera AI Lab at the Malawi University of Business and Applied Sciences, this\ndataset is intended to facilitate the development of machine learning models\ntailored to building detection and damage classification in African urban\ncontexts. It also supports flood damage visualisation and spatial analysis to\ninform decisions on relocation, infrastructure planning, and emergency response\nin climate-vulnerable regions.", "published": "2025-05-02 13:06:19", "link": "http://arxiv.org/abs/2505.01242v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Quantitative Attractor Analysis of High-Capacity Kernel Logistic Regression Hopfield Networks", "abstract": "Traditional Hopfield networks, using Hebbian learning, face severe storage\ncapacity limits ($\\approx 0.14$ P/N) and spurious attractors. Kernel Logistic\nRegression (KLR) offers a non-linear approach, mapping patterns to\nhigh-dimensional feature spaces for improved separability. Our previous work\nshowed KLR dramatically improves capacity and noise robustness over\nconventional methods. This paper quantitatively analyzes the attractor\nstructures in KLR-trained networks via extensive simulations. We evaluated\nrecall from diverse initial states across wide storage loads (up to 4.0 P/N)\nand noise levels. We quantified convergence rates and speed. Our analysis\nconfirms KLR's superior performance: high capacity (up to 4.0 P/N) and\nrobustness. The attractor landscape is remarkably \"clean,\" with near-zero\nspurious fixed points. Recall failures under high load/noise are primarily due\nto convergence to other learned patterns, not spurious ones. Dynamics are\nexceptionally fast (typically 1-2 steps for high-similarity states). This\ncharacterization reveals how KLR reshapes dynamics for high-capacity\nassociative memory, highlighting its effectiveness and contributing to AM\nunderstanding.", "published": "2025-05-02 12:13:23", "link": "http://arxiv.org/abs/2505.01218v1", "categories": ["cs.LG", "cs.NE"], "primary_category": "cs.LG"}
{"title": "AGRO: An Autonomous AI Rover for Precision Agriculture", "abstract": "Unmanned Ground Vehicles (UGVs) are emerging as a crucial tool in the world\nof precision agriculture. The combination of UGVs with machine learning allows\nus to find solutions for a range of complex agricultural problems. This\nresearch focuses on developing a UGV capable of autonomously traversing\nagricultural fields and capturing data. The project, known as AGRO (Autonomous\nGround Rover Observer) leverages machine learning, computer vision and other\nsensor technologies. AGRO uses its capabilities to determine pistachio yields,\nperforming self-localization and real-time environmental mapping while avoiding\nobstacles. The main objective of this research work is to automate\nresource-consuming operations so that AGRO can support farmers in making\ndata-driven decisions. Furthermore, AGRO provides a foundation for advanced\nmachine learning techniques as it captures the world around it.", "published": "2025-05-02 11:44:26", "link": "http://arxiv.org/abs/2505.01200v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "CaReAQA: A Cardiac and Respiratory Audio Question Answering Model for Open-Ended Diagnostic Reasoning", "abstract": "Medical audio signals, such as heart and lung sounds, play a crucial role in\nclinical diagnosis. However, analyzing these signals remains challenging:\ntraditional methods rely on handcrafted features or supervised deep learning\nmodels that demand extensive labeled datasets, limiting their scalability and\napplicability. To address these issues, we propose CaReAQA, an audio-language\nmodel that integrates a foundation audio model with the reasoning capabilities\nof large language models, enabling clinically relevant, open-ended diagnostic\nresponses. Alongside CaReAQA, we introduce CaReSound, a benchmark dataset of\nannotated medical audio recordings enriched with metadata and paired\nquestion-answer examples, intended to drive progress in diagnostic reasoning\nresearch. Evaluation results show that CaReAQA achieves 86.2% accuracy on\nopen-ended diagnostic reasoning tasks, outperforming baseline models. It also\ngeneralizes well to closed-ended classification tasks, achieving an average\naccuracy of 56.9% on unseen datasets. Our findings show how audio-language\nintegration and reasoning advances medical diagnostics, enabling efficient AI\nsystems for clinical decision support.", "published": "2025-05-02 11:42:46", "link": "http://arxiv.org/abs/2505.01199v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Gaussian Differential Private Bootstrap by Subsampling", "abstract": "Bootstrap is a common tool for quantifying uncertainty in data analysis.\nHowever, besides additional computational costs in the application of the\nbootstrap on massive data, a challenging problem in bootstrap based inference\nunder Differential Privacy consists in the fact that it requires repeated\naccess to the data. As a consequence, bootstrap based differentially private\ninference requires a significant increase of the privacy budget, which on the\nother hand comes with a substantial loss in statistical accuracy.\n  A potential solution to reconcile the conflicting goals of statistical\naccuracy and privacy is to analyze the data under parametric model assumptions\nand in the last decade, several parametric bootstrap methods for inference\nunder privacy have been investigated. However, uncertainty quantification by\nparametric bootstrap is only valid if the the quantities of interest can be\nidentified as the parameters of a statistical model and the imposed model\nassumptions are (at least approximately) satisfied. An alternative to\nparametric methods is the empirical bootstrap that is a widely used tool for\nnon-parametric inference and well studied in the non-private regime. However,\nunder privacy, less insight is available. In this paper, we propose a private\nempirical $m$ out of $n$ bootstrap and validate its consistency and privacy\nguarantees under Gaussian Differential Privacy. Compared to the the private $n$\nout of $n$ bootstrap, our approach has several advantages. First, it comes with\nless computational costs, in particular for massive data. Second, the proposed\nprocedure needs less additional noise in the bootstrap iterations, which leads\nto an improved statistical accuracy while asymptotically guaranteeing the same\nlevel of privacy. Third, we demonstrate much better finite sample properties\ncompared to the currently available procedures.", "published": "2025-05-02 11:40:50", "link": "http://arxiv.org/abs/2505.01197v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.CO", "stat.TH"], "primary_category": "stat.ML"}
{"title": "A Secured Triad of IoT, Machine Learning, and Blockchain for Crop Forecasting in Agriculture", "abstract": "To improve crop forecasting and provide farmers with actionable data-driven\ninsights, we propose a novel approach integrating IoT, machine learning, and\nblockchain technologies. Using IoT, real-time data from sensor networks\ncontinuously monitor environmental conditions and soil nutrient levels,\nsignificantly improving our understanding of crop growth dynamics. Our study\ndemonstrates the exceptional accuracy of the Random Forest model, achieving a\n99.45\\% accuracy rate in predicting optimal crop types and yields, thereby\noffering precise crop projections and customized recommendations. To ensure the\nsecurity and integrity of the sensor data used for these forecasts, we\nintegrate the Ethereum blockchain, which provides a robust and secure platform.\nThis ensures that the forecasted data remain tamper-proof and reliable.\nStakeholders can access real-time and historical crop projections through an\nintuitive online interface, enhancing transparency and facilitating informed\ndecision-making. By presenting multiple predicted crop scenarios, our system\nenables farmers to optimize production strategies effectively. This integrated\napproach promises significant advances in precision agriculture, making crop\nforecasting more accurate, secure, and user-friendly.", "published": "2025-05-02 11:40:13", "link": "http://arxiv.org/abs/2505.01196v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A flexible Bayesian non-parametric mixture model reveals multiple dependencies of swap errors in visual working memory", "abstract": "Human behavioural data in psychophysics has been used to elucidate the\nunderlying mechanisms of many cognitive processes, such as attention,\nsensorimotor integration, and perceptual decision making. Visual working memory\nhas particularly benefited from this approach: analyses of VWM errors have\nproven crucial for understanding VWM capacity and coding schemes, in turn\nconstraining neural models of both. One poorly understood class of VWM errors\nare swap errors, whereby participants recall an uncued item from memory. Swap\nerrors could arise from erroneous memory encoding, noisy storage, or errors at\nretrieval time - previous research has mostly implicated the latter two.\nHowever, these studies made strong a priori assumptions on the detailed\nmechanisms and/or parametric form of errors contributed by these sources. Here,\nwe pursue a data-driven approach instead, introducing a Bayesian non-parametric\nmixture model of swap errors (BNS) which provides a flexible descriptive model\nof swapping behaviour, such that swaps are allowed to depend on both the probed\nand reported features of every stimulus item. We fit BNS to the trial-by-trial\nbehaviour of human participants and show that it recapitulates the strong\ndependence of swaps on cue similarity in multiple datasets. Critically, BNS\nreveals that this dependence coexists with a non-monotonic modulation in the\nreport feature dimension for a random dot motion direction-cued,\nlocation-reported dataset. The form of the modulation inferred by BNS opens new\nquestions about the importance of memory encoding in causing swap errors in\nVWM, a distinct source to the previously suggested binding and cueing errors.\nOur analyses, combining qualitative comparisons of the highly interpretable BNS\nparameter structure with rigorous quantitative model comparison and recovery\nmethods, show that previous interpretations of swap errors may have been\nincomplete.", "published": "2025-05-02 10:38:45", "link": "http://arxiv.org/abs/2505.01178v1", "categories": ["q-bio.NC", "cs.LG"], "primary_category": "q-bio.NC"}
{"title": "Empirical Comparison of Lightweight Forecasting Models for Seasonal and Non-Seasonal Time Series", "abstract": "Accurate time series forecasting is essential in many real-time applications\nthat demand both high predictive accuracy and computational efficiency. This\nstudy provides an empirical comparison between a Polynomial Classifier and a\nRadial Basis Function Neural Network (RBFNN) across four real-world time series\ndatasets (weather conditions, gold prices, crude oil prices, and beer\nproduction volumes) that cover both seasonal and nonseasonal patterns. Model\nperformance is evaluated by forecasting accuracy (using Mean Absolute Error,\nRoot Mean Squared Error, and Coefficient of Variation of Root Mean Squared\nError) and computational time to assess each model's viability for real time\nforecasting. The results show that the PC yields more accurate and faster\nforecasts for non seasonal series, whereas the RBFNN performs better on series\nwith pronounced seasonal patterns. From an interpretability standpoint, the\npolynomial model offers a simpler, more transparent structure (in contrast to\nthe black box nature of neural network), which is advantageous for\nunderstanding and trust in real time decision making. The performance\ndifferences between PC and RBFNN are statistically significant, as confirmed by\npaired t tests and Wilcoxon signed rank tests. These findings provide practical\nguidance for model selection in time series forecasting, indicating that PC may\nbe preferable for quick, interpretable forecasts in non-seasonal contexts,\nwhereas RBFNN is superior for capturing complex seasonal behaviors", "published": "2025-05-02 10:12:23", "link": "http://arxiv.org/abs/2505.01163v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "TActiLE: Tiny Active LEarning for wearable devices", "abstract": "Tiny Machine Learning (TinyML) algorithms have seen extensive use in recent\nyears, enabling wearable devices to be not only connected but also genuinely\nintelligent by running machine learning (ML) computations directly on-device.\nAmong such devices, smart glasses have particularly benefited from TinyML\nadvancements. TinyML facilitates the on-device execution of the inference phase\nof ML algorithms on embedded and wearable devices, and more recently, it has\nexpanded into On-device Learning (ODL), which allows both inference and\nlearning phases to occur directly on the device. The application of ODL\ntechniques to wearable devices is particularly compelling, as it enables the\ndevelopment of more personalized models that adapt based on the data of the\nuser. However, one of the major challenges of ODL algorithms is the scarcity of\nlabeled data collected on-device. In smart wearable contexts, requiring users\nto manually label large amounts of data is often impractical and could lead to\nuser disengagement with the technology. To address this issue, this paper\nexplores the application of Active Learning (AL) techniques, i.e., techniques\nthat aim at minimizing the labeling effort, by actively selecting from a large\nquantity of unlabeled data only a small subset to be labeled and added to the\ntraining set of the algorithm. In particular, we propose TActiLE, a novel AL\nalgorithm that selects from the stream of on-device sensor data the ones that\nwould help the ML algorithm improve the most once coupled with labels provided\nby the user. TActiLE is the first Active Learning technique specifically\ndesigned for the TinyML context. We evaluate its effectiveness and efficiency\nthrough experiments on multiple image classification datasets. The results\ndemonstrate its suitability for tiny and wearable devices.", "published": "2025-05-02 10:05:50", "link": "http://arxiv.org/abs/2505.01160v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Machine Learning for Physical Simulation Challenge Results and Retrospective Analysis: Power Grid Use Case", "abstract": "This paper addresses the growing computational challenges of power grid\nsimulations, particularly with the increasing integration of renewable energy\nsources like wind and solar. As grid operators must analyze significantly more\nscenarios in near real-time to prevent failures and ensure stability,\ntraditional physical-based simulations become computationally impractical. To\ntackle this, a competition was organized to develop AI-driven methods that\naccelerate power flow simulations by at least an order of magnitude while\nmaintaining operational reliability. This competition utilized a regional-scale\ngrid model with a 30\\% renewable energy mix, mirroring the anticipated\nnear-future composition of the French power grid. A key contribution of this\nwork is through the use of LIPS (Learning Industrial Physical Systems), a\nbenchmarking framework that evaluates solutions based on four critical\ndimensions: machine learning performance, physical compliance, industrial\nreadiness, and generalization to out-of-distribution scenarios. The paper\nprovides a comprehensive overview of the Machine Learning for Physical\nSimulation (ML4PhySim) competition, detailing the benchmark suite, analyzing\ntop-performing solutions that outperformed traditional simulation methods, and\nsharing key organizational insights and best practices for running large-scale\nAI competitions. Given the promising results achieved, the study aims to\ninspire further research into more efficient, scalable, and sustainable power\nnetwork simulation methodologies.", "published": "2025-05-02 09:58:27", "link": "http://arxiv.org/abs/2505.01156v1", "categories": ["cs.LG", "68T01", "I.2.0"], "primary_category": "cs.LG"}
{"title": "Dual-Forecaster: A Multimodal Time Series Model Integrating Descriptive and Predictive Texts", "abstract": "Most existing single-modal time series models rely solely on numerical\nseries, which suffer from the limitations imposed by insufficient information.\nRecent studies have revealed that multimodal models can address the core issue\nby integrating textual information. However, these models focus on either\nhistorical or future textual information, overlooking the unique contributions\neach plays in time series forecasting. Besides, these models fail to grasp the\nintricate relationships between textual and time series data, constrained by\ntheir moderate capacity for multimodal comprehension. To tackle these\nchallenges, we propose Dual-Forecaster, a pioneering multimodal time series\nmodel that combines both descriptively historical textual information and\npredictive textual insights, leveraging advanced multimodal comprehension\ncapability empowered by three well-designed cross-modality alignment\ntechniques. Our comprehensive evaluations on fifteen multimodal time series\ndatasets demonstrate that Dual-Forecaster is a distinctly effective multimodal\ntime series model that outperforms or is comparable to other state-of-the-art\nmodels, highlighting the superiority of integrating textual information for\ntime series forecasting. This work opens new avenues in the integration of\ntextual information with numerical time series data for multimodal time series\nanalysis.", "published": "2025-05-02 09:24:31", "link": "http://arxiv.org/abs/2505.01135v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Aggregation of Dependent Expert Distributions in Multimodal Variational Autoencoders", "abstract": "Multimodal learning with variational autoencoders (VAEs) requires estimating\njoint distributions to evaluate the evidence lower bound (ELBO). Current\nmethods, the product and mixture of experts, aggregate single-modality\ndistributions assuming independence for simplicity, which is an overoptimistic\nassumption. This research introduces a novel methodology for aggregating\nsingle-modality distributions by exploiting the principle of consensus of\ndependent experts (CoDE), which circumvents the aforementioned assumption.\nUtilizing the CoDE method, we propose a novel ELBO that approximates the joint\nlikelihood of the multimodal data by learning the contribution of each subset\nof modalities. The resulting CoDE-VAE model demonstrates better performance in\nterms of balancing the trade-off between generative coherence and generative\nquality, as well as generating more precise log-likelihood estimations.\nCoDE-VAE further minimizes the generative quality gap as the number of\nmodalities increases. In certain cases, it reaches a generative quality similar\nto that of unimodal VAEs, which is a desirable property that is lacking in most\ncurrent methods. Finally, the classification accuracy achieved by CoDE-VAE is\ncomparable to that of state-of-the-art multimodal VAE models.", "published": "2025-05-02 09:24:10", "link": "http://arxiv.org/abs/2505.01134v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "On Simulating Thin-Film Processes at the Atomic Scale Using Machine Learned Force Fields", "abstract": "Atomistic modeling of thin-film processes provides an avenue not only for\ndiscovering key chemical mechanisms of the processes but also to extract\nquantitative metrics on the events and reactions taking place at the\ngas-surface interface. Molecular dynamics (MD) is a powerful computational\nmethod to study the evolution of a process at the atomic scale, but studies of\nindustrially relevant processes usually require suitable force fields, which\nare in general not available for all processes of interest. However, machine\nlearned force fields (MLFF) are conquering the field of computational materials\nand surface science. In this paper, we demonstrate how to efficiently build\nMLFFs suitable for process simulations and provide two examples for\ntechnologically relevant processes: precursor pulse in the atomic layer\ndeposition of HfO2 and atomic layer etching of MoS2.", "published": "2025-05-02 08:57:56", "link": "http://arxiv.org/abs/2505.01118v1", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "Exploring Equity of Climate Policies using Multi-Agent Multi-Objective Reinforcement Learning", "abstract": "Addressing climate change requires coordinated policy efforts of nations\nworldwide. These efforts are informed by scientific reports, which rely in part\non Integrated Assessment Models (IAMs), prominent tools used to assess the\neconomic impacts of climate policies. However, traditional IAMs optimize\npolicies based on a single objective, limiting their ability to capture the\ntrade-offs among economic growth, temperature goals, and climate justice. As a\nresult, policy recommendations have been criticized for perpetuating\ninequalities, fueling disagreements during policy negotiations. We introduce\nJustice, the first framework integrating IAM with Multi-Objective Multi-Agent\nReinforcement Learning (MOMARL). By incorporating multiple objectives, Justice\ngenerates policy recommendations that shed light on equity while balancing\nclimate and economic goals. Further, using multiple agents can provide a\nrealistic representation of the interactions among the diverse policy actors.\nWe identify equitable Pareto-optimal policies using our framework, which\nfacilitates deliberative decision-making by presenting policymakers with the\ninherent trade-offs in climate and economic policy.", "published": "2025-05-02 08:52:56", "link": "http://arxiv.org/abs/2505.01115v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Learning Low-Dimensional Embeddings for Black-Box Optimization", "abstract": "When gradient-based methods are impractical, black-box optimization (BBO)\nprovides a valuable alternative. However, BBO often struggles with\nhigh-dimensional problems and limited trial budgets. In this work, we propose a\nnovel approach based on meta-learning to pre-compute a reduced-dimensional\nmanifold where optimal points lie for a specific class of optimization\nproblems. When optimizing a new problem instance sampled from the class,\nblack-box optimization is carried out in the reduced-dimensional space,\neffectively reducing the effort required for finding near-optimal solutions.", "published": "2025-05-02 08:46:14", "link": "http://arxiv.org/abs/2505.01112v1", "categories": ["eess.SY", "cs.LG", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Incorporating Inductive Biases to Energy-based Generative Models", "abstract": "With the advent of score-matching techniques for model training and Langevin\ndynamics for sample generation, energy-based models (EBMs) have gained renewed\ninterest as generative models. Recent EBMs usually use neural networks to\ndefine their energy functions. In this work, we introduce a novel hybrid\napproach that combines an EBM with an exponential family model to incorporate\ninductive bias into data modeling. Specifically, we augment the energy term\nwith a parameter-free statistic function to help the model capture key data\nstatistics. Like an exponential family model, the hybrid model aims to align\nthe distribution statistics with data statistics during model training, even\nwhen it only approximately maximizes the data likelihood. This property enables\nus to impose constraints on the hybrid model. Our empirical study validates the\nhybrid model's ability to match statistics. Furthermore, experimental results\nshow that data fitting and generation improve when suitable informative\nstatistics are incorporated into the hybrid model.", "published": "2025-05-02 08:46:03", "link": "http://arxiv.org/abs/2505.01111v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "CIMFlow: An Integrated Framework for Systematic Design and Evaluation of Digital CIM Architectures", "abstract": "Digital Compute-in-Memory (CIM) architectures have shown great promise in\nDeep Neural Network (DNN) acceleration by effectively addressing the \"memory\nwall\" bottleneck. However, the development and optimization of digital CIM\naccelerators are hindered by the lack of comprehensive tools that encompass\nboth software and hardware design spaces. Moreover, existing design and\nevaluation frameworks often lack support for the capacity constraints inherent\nin digital CIM architectures. In this paper, we present CIMFlow, an integrated\nframework that provides an out-of-the-box workflow for implementing and\nevaluating DNN workloads on digital CIM architectures. CIMFlow bridges the\ncompilation and simulation infrastructures with a flexible instruction set\narchitecture (ISA) design, and addresses the constraints of digital CIM through\nadvanced partitioning and parallelism strategies in the compilation flow. Our\nevaluation demonstrates that CIMFlow enables systematic prototyping and\noptimization of digital CIM architectures across diverse configurations,\nproviding researchers and designers with an accessible platform for extensive\ndesign space exploration.", "published": "2025-05-02 08:38:30", "link": "http://arxiv.org/abs/2505.01107v1", "categories": ["cs.AR", "cs.LG"], "primary_category": "cs.AR"}
{"title": "CoCoAFusE: Beyond Mixtures of Experts via Model Fusion", "abstract": "Many learning problems involve multiple patterns and varying degrees of\nuncertainty dependent on the covariates. Advances in Deep Learning (DL) have\naddressed these issues by learning highly nonlinear input-output dependencies.\nHowever, model interpretability and Uncertainty Quantification (UQ) have often\nstraggled behind. In this context, we introduce the Competitive/Collaborative\nFusion of Experts (CoCoAFusE), a novel, Bayesian Covariates-Dependent Modeling\ntechnique. CoCoAFusE builds on the very philosophy behind Mixtures of Experts\n(MoEs), blending predictions from several simple sub-models (or \"experts\") to\nachieve high levels of expressiveness while retaining a substantial degree of\nlocal interpretability. Our formulation extends that of a classical Mixture of\nExperts by contemplating the fusion of the experts' distributions in addition\nto their more usual mixing (i.e., superimposition). Through this additional\nfeature, CoCoAFusE better accommodates different scenarios for the intermediate\nbehavior between generating mechanisms, resulting in tighter credible bounds on\nthe response variable. Indeed, only resorting to mixing, as in classical MoEs,\nmay lead to multimodality artifacts, especially over smooth transitions.\nInstead, CoCoAFusE can avoid these artifacts even under the same structure and\npriors for the experts, leading to greater expressiveness and flexibility in\nmodeling. This new approach is showcased extensively on a suite of motivating\nnumerical examples and a collection of real-data ones, demonstrating its\nefficacy in tackling complex regression problems where uncertainty is a key\nquantity of interest.", "published": "2025-05-02 08:35:04", "link": "http://arxiv.org/abs/2505.01105v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Nesterov Method for Asynchronous Pipeline Parallel Optimization", "abstract": "Pipeline Parallelism (PP) enables large neural network training on small,\ninterconnected devices by splitting the model into multiple stages. To maximize\npipeline utilization, asynchronous optimization is appealing as it offers 100%\npipeline utilization by construction. However, it is inherently challenging as\nthe weights and gradients are no longer synchronized, leading to stale (or\ndelayed) gradients. To alleviate this, we introduce a variant of Nesterov\nAccelerated Gradient (NAG) for asynchronous optimization in PP. Specifically,\nwe modify the look-ahead step in NAG to effectively address the staleness in\ngradients. We theoretically prove that our approach converges at a sublinear\nrate in the presence of fixed delay in gradients. Our experiments on\nlarge-scale language modelling tasks using decoder-only architectures with up\nto 1B parameters, demonstrate that our approach significantly outperforms\nexisting asynchronous methods, even surpassing the synchronous baseline.", "published": "2025-05-02 08:23:29", "link": "http://arxiv.org/abs/2505.01099v1", "categories": ["cs.LG", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Integration Matters for Learning PDEs with Backwards SDEs", "abstract": "Backward stochastic differential equation (BSDE)-based deep learning methods\nprovide an alternative to Physics-Informed Neural Networks (PINNs) for solving\nhigh-dimensional partial differential equations (PDEs), offering algorithmic\nadvantages in settings such as stochastic optimal control, where the PDEs of\ninterest are tied to an underlying dynamical system. However, existing\nBSDE-based solvers have empirically been shown to underperform relative to\nPINNs in the literature. In this paper, we identify the root cause of this\nperformance gap as a discretization bias introduced by the standard\nEuler-Maruyama (EM) integration scheme applied to short-horizon\nself-consistency BSDE losses, which shifts the optimization landscape off\ntarget. We find that this bias cannot be satisfactorily addressed through finer\nstep sizes or longer self-consistency horizons. To properly handle this issue,\nwe propose a Stratonovich-based BSDE formulation, which we implement with\nstochastic Heun integration. We show that our proposed approach completely\neliminates the bias issues faced by EM integration. Furthermore, our empirical\nresults show that our Heun-based BSDE method consistently outperforms EM-based\nvariants and achieves competitive results with PINNs across multiple\nhigh-dimensional benchmarks. Our findings highlight the critical role of\nintegration schemes in BSDE-based PDE solvers, an algorithmic detail that has\nreceived little attention thus far in the literature.", "published": "2025-05-02 07:36:27", "link": "http://arxiv.org/abs/2505.01078v1", "categories": ["cs.LG", "cs.SY", "eess.SY", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Federated Adapter on Foundation Models: An Out-Of-Distribution Approach", "abstract": "As foundation models gain prominence, Federated Foundation Models (FedFM)\nhave emerged as a privacy-preserving approach to collaboratively fine-tune\nmodels in federated learning (FL) frameworks using distributed datasets across\nclients. A key challenge for FedFM, given the versatile nature of foundation\nmodels, is addressing out-of-distribution (OOD) generalization, where unseen\ntasks or clients may exhibit distribution shifts leading to suboptimal\nperformance. Although numerous studies have explored OOD generalization in\nconventional FL, these methods are inadequate for FedFM due to the challenges\nposed by large parameter scales and increased data heterogeneity. To address\nthese, we propose FedOA, which employs adapter-based parameter-efficient\nfine-tuning methods for efficacy and introduces personalized adapters with\nfeature distance-based regularization to align distributions and guarantee OOD\ngeneralization for each client. Theoretically, we demonstrate that the\nconventional aggregated global model in FedFM inherently retains OOD\ngeneralization capabilities, and our proposed method enhances the personalized\nmodel's OOD generalization through regularization informed by the global model,\nwith proven convergence under general non-convex settings. Empirically, the\neffectiveness of the proposed method is validated on benchmark datasets across\nvarious NLP tasks.", "published": "2025-05-02 07:33:00", "link": "http://arxiv.org/abs/2505.01075v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Monotone Peridynamic Neural Operator for Nonlinear Material Modeling with Conditionally Unique Solutions", "abstract": "Data-driven methods have emerged as powerful tools for modeling the responses\nof complex nonlinear materials directly from experimental measurements. Among\nthese methods, the data-driven constitutive models present advantages in\nphysical interpretability and generalizability across different boundary\nconditions/domain settings. However, the well-posedness of these learned models\nis generally not guaranteed a priori, which makes the models prone to\nnon-physical solutions in downstream simulation tasks. In this study, we\nintroduce monotone peridynamic neural operator (MPNO), a novel data-driven\nnonlocal constitutive model learning approach based on neural operators. Our\napproach learns a nonlocal kernel together with a nonlinear constitutive\nrelation, while ensuring solution uniqueness through a monotone gradient\nnetwork. This architectural constraint on gradient induces convexity of the\nlearnt energy density function, thereby guaranteeing solution uniqueness of\nMPNO in small deformation regimes. To validate our approach, we evaluate MPNO's\nperformance on both synthetic and real-world datasets. On synthetic datasets\nwith manufactured kernel and constitutive relation, we show that the learnt\nmodel converges to the ground-truth as the measurement grid size decreases both\ntheoretically and numerically. Additionally, our MPNO exhibits superior\ngeneralization capabilities than the conventional neural networks: it yields\nsmaller displacement solution errors in down-stream tasks with new and unseen\nloadings. Finally, we showcase the practical utility of our approach through\napplications in learning a homogenized model from molecular dynamics data,\nhighlighting its expressivity and robustness in real-world scenarios.", "published": "2025-05-02 07:10:31", "link": "http://arxiv.org/abs/2505.01060v1", "categories": ["cs.LG", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "Multi-Step Consistency Models: Fast Generation with Theoretical Guarantees", "abstract": "Consistency models have recently emerged as a compelling alternative to\ntraditional SDE based diffusion models, offering a significant acceleration in\ngeneration by producing high quality samples in very few steps. Despite their\nempirical success, a proper theoretic justification for their speed up is still\nlacking. In this work, we provide the analysis which bridges this gap, showing\nthat given a consistency model which can map the input at a given time to\narbitrary timestamps along the reverse trajectory, one can achieve KL\ndivergence of order $ O(\\varepsilon^2) $ using only $\nO\\left(\\log\\left(\\frac{d}{\\varepsilon}\\right)\\right) $ iterations with constant\nstep size, where d is the data dimension. Additionally, under minimal\nassumptions on the data distribution an increasingly common setting in recent\ndiffusion model analyses we show that a similar KL convergence guarantee can be\nobtained, with the number of steps scaling as $ O\\left(d\n\\log\\left(\\frac{d}{\\varepsilon}\\right)\\right) $. Going further, we also provide\na theoretical analysis for estimation of such consistency models, concluding\nthat accurate learning is feasible using small discretization steps, both in\nsmooth and non smooth settings. Notably, our results for the non smooth case\nyield best in class convergence rates compared to existing SDE or ODE based\nanalyses under minimal assumptions.", "published": "2025-05-02 06:50:46", "link": "http://arxiv.org/abs/2505.01049v1", "categories": ["cs.LG", "math.AP", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Global Optimality of Single-Timescale Actor-Critic under Continuous State-Action Space: A Study on Linear Quadratic Regulator", "abstract": "Actor-critic methods have achieved state-of-the-art performance in various\nchallenging tasks. However, theoretical understandings of their performance\nremain elusive and challenging. Existing studies mostly focus on practically\nuncommon variants such as double-loop or two-timescale stepsize actor-critic\nalgorithms for simplicity. These results certify local convergence on finite\nstate- or action-space only. We push the boundary to investigate the classic\nsingle-sample single-timescale actor-critic on continuous (infinite)\nstate-action space, where we employ the canonical linear quadratic regulator\n(LQR) problem as a case study. We show that the popular single-timescale\nactor-critic can attain an epsilon-optimal solution with an order of epsilon to\n-2 sample complexity for solving LQR on the demanding continuous state-action\nspace. Our work provides new insights into the performance of single-timescale\nactor-critic, which further bridges the gap between theory and practice.", "published": "2025-05-02 06:30:52", "link": "http://arxiv.org/abs/2505.01041v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Characterization and Learning of Causal Graphs from Hard Interventions", "abstract": "A fundamental challenge in the empirical sciences involves uncovering causal\nstructure through observation and experimentation. Causal discovery entails\nlinking the conditional independence (CI) invariances in observational data to\ntheir corresponding graphical constraints via d-separation. In this paper, we\nconsider a general setting where we have access to data from multiple\nexperimental distributions resulting from hard interventions, as well as\npotentially from an observational distribution. By comparing different\ninterventional distributions, we propose a set of graphical constraints that\nare fundamentally linked to Pearl's do-calculus within the framework of hard\ninterventions. These graphical constraints associate each graphical structure\nwith a set of interventional distributions that are consistent with the rules\nof do-calculus. We characterize the interventional equivalence class of causal\ngraphs with latent variables and introduce a graphical representation that can\nbe used to determine whether two causal graphs are interventionally equivalent,\ni.e., whether they are associated with the same family of hard interventional\ndistributions, where the elements of the family are indistinguishable using the\ninvariances from do-calculus. We also propose a learning algorithm to integrate\nmultiple datasets from hard interventions, introducing new orientation rules.\nThe learning objective is a tuple of augmented graphs which entails a set of\ncausal graphs. We also prove the soundness of the proposed algorithm.", "published": "2025-05-02 06:20:08", "link": "http://arxiv.org/abs/2505.01037v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Quantum Support Vector Regression for Robust Anomaly Detection", "abstract": "Anomaly Detection (AD) is critical in data analysis, particularly within the\ndomain of IT security. In recent years, Machine Learning (ML) algorithms have\nemerged as a powerful tool for AD in large-scale data. In this study, we\nexplore the potential of quantum ML approaches, specifically quantum kernel\nmethods, for the application to robust AD. We build upon previous work on\nQuantum Support Vector Regression (QSVR) for semisupervised AD by conducting a\ncomprehensive benchmark on IBM quantum hardware using eleven datasets. Our\nresults demonstrate that QSVR achieves strong classification performance and\neven outperforms the noiseless simulation on two of these datasets. Moreover,\nwe investigate the influence of - in the NISQ-era inevitable - quantum noise on\nthe performance of the QSVR. Our findings reveal that the model exhibits\nrobustness to depolarizing, phase damping, phase flip, and bit flip noise,\nwhile amplitude damping and miscalibration noise prove to be more disruptive.\nFinally, we explore the domain of Quantum Adversarial Machine Learning and\ndemonstrate that QSVR is highly vulnerable to adversarial attacks and that\nnoise does not improve the adversarial robustness of the model.", "published": "2025-05-02 05:23:34", "link": "http://arxiv.org/abs/2505.01012v1", "categories": ["quant-ph", "cs.CR", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Where's the liability in the Generative Era? Recovery-based Black-Box Detection of AI-Generated Content", "abstract": "The recent proliferation of photorealistic images created by generative\nmodels has sparked both excitement and concern, as these images are\nincreasingly indistinguishable from real ones to the human eye. While offering\nnew creative and commercial possibilities, the potential for misuse, such as in\nmisinformation and fraud, highlights the need for effective detection methods.\nCurrent detection approaches often rely on access to model weights or require\nextensive collections of real image datasets, limiting their scalability and\npractical application in real world scenarios. In this work, we introduce a\nnovel black box detection framework that requires only API access, sidestepping\nthe need for model weights or large auxiliary datasets. Our approach leverages\na corrupt and recover strategy: by masking part of an image and assessing the\nmodel ability to reconstruct it, we measure the likelihood that the image was\ngenerated by the model itself. For black-box models that do not support masked\nimage inputs, we incorporate a cost efficient surrogate model trained to align\nwith the target model distribution, enhancing detection capability. Our\nframework demonstrates strong performance, outperforming baseline methods by\n4.31% in mean average precision across eight diffusion model variant datasets.", "published": "2025-05-02 05:11:35", "link": "http://arxiv.org/abs/2505.01008v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Accelerating Deep Neural Network Training via Distributed Hybrid Order Optimization", "abstract": "Scaling deep neural network (DNN) training to more devices can reduce\ntime-to-solution. However, it is impractical for users with limited computing\nresources. FOSI, as a hybrid order optimizer, converges faster than\nconventional optimizers by taking advantage of both gradient information and\ncurvature information when updating the DNN model. Therefore, it provides a new\nchance for accelerating DNN training in the resource-constrained setting. In\nthis paper, we explore its distributed design, namely DHO$_2$, including\ndistributed calculation of curvature information and model update with partial\ncurvature information to accelerate DNN training with a low memory burden. To\nfurther reduce the training time, we design a novel strategy to parallelize the\ncalculation of curvature information and the model update on different devices.\nExperimentally, our distributed design can achieve an approximate linear\nreduction of memory burden on each device with the increase of the device\nnumber. Meanwhile, it achieves $1.4\\times\\sim2.1\\times$ speedup in the total\ntraining time compared with other distributed designs based on conventional\nfirst- and second-order optimizers.", "published": "2025-05-02 04:02:36", "link": "http://arxiv.org/abs/2505.00982v1", "categories": ["cs.LG", "cs.DC"], "primary_category": "cs.LG"}
{"title": "A Minimax-MDP Framework with Future-imposed Conditions for Learning-augmented Problems", "abstract": "We study a class of sequential decision-making problems with augmented\npredictions, potentially provided by a machine learning algorithm. In this\nsetting, the decision-maker receives prediction intervals for unknown\nparameters that become progressively refined over time, and seeks decisions\nthat are competitive with the hindsight optimal under all possible realizations\nof both parameters and predictions. We propose a minimax Markov Decision\nProcess (minimax-MDP) framework, where the system state consists of an\nadversarially evolving environment state and an internal state controlled by\nthe decision-maker. We introduce a set of future-imposed conditions that\ncharacterize the feasibility of minimax-MDPs and enable the design of\nefficient, often closed-form, robustly competitive policies. We illustrate the\nframework through three applications: multi-period inventory ordering with\nrefining demand predictions, resource allocation with uncertain utility\nfunctions, and a multi-phase extension of the minimax-MDP applied to the\ninventory problem with time-varying ordering costs. Our results provide a\ntractable and versatile approach to robust online decision-making under\npredictive uncertainty.", "published": "2025-05-02 03:28:35", "link": "http://arxiv.org/abs/2505.00973v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Adaptive Branch-and-Bound Tree Exploration for Neural Network Verification", "abstract": "Formal verification is a rigorous approach that can provably ensure the\nquality of neural networks, and to date, Branch and Bound (BaB) is the\nstate-of-the-art that performs verification by splitting the problem as needed\nand applying off-the-shelf verifiers to sub-problems for improved performance.\nHowever, existing BaB may not be efficient, due to its naive way of exploring\nthe space of sub-problems that ignores the \\emph{importance} of different\nsub-problems. To bridge this gap, we first introduce a notion of ``importance''\nthat reflects how likely a counterexample can be found with a sub-problem, and\nthen we devise a novel verification approach, called ABONN, that explores the\nsub-problem space of BaB adaptively, in a Monte-Carlo tree search (MCTS) style.\nThe exploration is guided by the ``importance'' of different sub-problems, so\nit favors the sub-problems that are more likely to find counterexamples. As\nsoon as it finds a counterexample, it can immediately terminate; even though it\ncannot find, after visiting all the sub-problems, it can still manage to verify\nthe problem. We evaluate ABONN with 552 verification problems from\ncommonly-used datasets and neural network models, and compare it with the\nstate-of-the-art verifiers as baseline approaches. Experimental evaluation\nshows that ABONN demonstrates speedups of up to $15.2\\times$ on MNIST and\n$24.7\\times$ on CIFAR-10. We further study the influences of hyperparameters to\nthe performance of ABONN, and the effectiveness of our adaptive tree\nexploration.", "published": "2025-05-02 02:41:02", "link": "http://arxiv.org/abs/2505.00963v1", "categories": ["cs.LG", "cs.PL"], "primary_category": "cs.LG"}
{"title": "DOLCE: Decomposing Off-Policy Evaluation/Learning into Lagged and Current Effects", "abstract": "Off-policy evaluation (OPE) and off-policy learning (OPL) for contextual\nbandit policies leverage historical data to evaluate and optimize a target\npolicy. Most existing OPE/OPL methods--based on importance weighting or\nimputation--assume common support between the target and logging policies. When\nthis assumption is violated, these methods typically require unstable\nextrapolation, truncation, or conservative strategies for individuals outside\nthe common support assumption. However, such approaches can be inadequate in\nsettings where explicit evaluation or optimization for such individuals is\nrequired. To address this issue, we propose DOLCE: Decomposing Off-policy\nevaluation/learning into Lagged and Current Effects, a novel estimator that\nleverages contextual information from multiple time points to decompose rewards\ninto lagged and current effects. By incorporating both past and present\ncontexts, DOLCE effectively handles individuals who violate the common support\nassumption. We show that the proposed estimator is unbiased under two\nassumptions--local correctness and conditional independence. Our experiments\ndemonstrate that DOLCE achieves substantial improvements in OPE and OPL,\nparticularly as the proportion of individuals outside the common support\nassumption increases.", "published": "2025-05-02 02:32:28", "link": "http://arxiv.org/abs/2505.00961v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Addressing Noise and Stochasticity in Fraud Detection for Service Networks", "abstract": "Fraud detection is crucial in social service networks to maintain user trust\nand improve service network security. Existing spectral graph-based methods\naddress this challenge by leveraging different graph filters to capture signals\nwith different frequencies in service networks. However, most graph\nfilter-based methods struggle with deriving clean and discriminative graph\nsignals. On the one hand, they overlook the noise in the information\npropagation process, resulting in degradation of filtering ability. On the\nother hand, they fail to discriminate the frequency-specific characteristics of\ngraph signals, leading to distortion of signals fusion. To address these\nissues, we develop a novel spectral graph network based on information\nbottleneck theory (SGNN-IB) for fraud detection in service networks. SGNN-IB\nsplits the original graph into homophilic and heterophilic subgraphs to better\ncapture the signals at different frequencies. For the first limitation, SGNN-IB\napplies information bottleneck theory to extract key characteristics of encoded\nrepresentations. For the second limitation, SGNN-IB introduces prototype\nlearning to implement signal fusion, preserving the frequency-specific\ncharacteristics of signals. Extensive experiments on three real-world datasets\ndemonstrate that SGNN-IB outperforms state-of-the-art fraud detection methods.", "published": "2025-05-02 01:17:03", "link": "http://arxiv.org/abs/2505.00946v1", "categories": ["cs.LG", "cs.CR"], "primary_category": "cs.LG"}
{"title": "FreCT: Frequency-augmented Convolutional Transformer for Robust Time Series Anomaly Detection", "abstract": "Time series anomaly detection is critical for system monitoring and risk\nidentification, across various domains, such as finance and healthcare.\nHowever, for most reconstruction-based approaches, detecting anomalies remains\na challenge due to the complexity of sequential patterns in time series data.\nOn the one hand, reconstruction-based techniques are susceptible to\ncomputational deviation stemming from anomalies, which can lead to impure\nrepresentations of normal sequence patterns. On the other hand, they often\nfocus on the time-domain dependencies of time series, while ignoring the\nalignment of frequency information beyond the time domain. To address these\nchallenges, we propose a novel Frequency-augmented Convolutional Transformer\n(FreCT). FreCT utilizes patch operations to generate contrastive views and\nemploys an improved Transformer architecture integrated with a convolution\nmodule to capture long-term dependencies while preserving local topology\ninformation. The introduced frequency analysis based on Fourier transformation\ncould enhance the model's ability to capture crucial characteristics beyond the\ntime domain. To protect the training quality from anomalies and improve the\nrobustness, FreCT deploys stop-gradient Kullback-Leibler (KL) divergence and\nabsolute error to optimize consistency information in both time and frequency\ndomains. Extensive experiments on four public datasets demonstrate that FreCT\noutperforms existing methods in identifying anomalies.", "published": "2025-05-02 00:56:24", "link": "http://arxiv.org/abs/2505.00941v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "StablePCA: Learning Shared Representations across Multiple Sources via Minimax Optimization", "abstract": "When synthesizing multisource high-dimensional data, a key objective is to\nextract low-dimensional feature representations that effectively approximate\nthe original features across different sources. Such general feature extraction\nfacilitates the discovery of transferable knowledge, mitigates systematic\nbiases such as batch effects, and promotes fairness. In this paper, we propose\nStable Principal Component Analysis (StablePCA), a novel method for group\ndistributionally robust learning of latent representations from\nhigh-dimensional multi-source data. A primary challenge in generalizing PCA to\nthe multi-source regime lies in the nonconvexity of the fixed rank constraint,\nrendering the minimax optimization nonconvex. To address this challenge, we\nemploy the Fantope relaxation, reformulating the problem as a convex minimax\noptimization, with the objective defined as the maximum loss across sources. To\nsolve the relaxed formulation, we devise an optimistic-gradient Mirror Prox\nalgorithm with explicit closed-form updates. Theoretically, we establish the\nglobal convergence of the Mirror Prox algorithm, with the convergence rate\nprovided from the optimization perspective. Furthermore, we offer practical\ncriteria to assess how closely the solution approximates the original nonconvex\nformulation. Through extensive numerical experiments, we demonstrate\nStablePCA's high accuracy and efficiency in extracting robust low-dimensional\nrepresentations across various finite-sample scenarios.", "published": "2025-05-02 00:53:39", "link": "http://arxiv.org/abs/2505.00940v1", "categories": ["cs.LG", "math.OC", "stat.CO", "stat.ME"], "primary_category": "cs.LG"}
{"title": "TunnElQNN: A Hybrid Quantum-classical Neural Network for Efficient Learning", "abstract": "Hybrid quantum-classical neural networks (HQCNNs) represent a promising\nfrontier in machine learning, leveraging the complementary strengths of both\nmodels. In this work, we propose the development of TunnElQNN, a non-sequential\narchitecture composed of alternating classical and quantum layers. Within the\nclassical component, we employ the Tunnelling Diode Activation Function (TDAF),\ninspired by the I-V characteristics of quantum tunnelling. We evaluate the\nperformance of this hybrid model on a synthetic dataset of interleaving\nhalf-circle for multi-class classification tasks with varying degrees of class\noverlap. The model is compared against a baseline hybrid architecture that uses\nthe conventional ReLU activation function (ReLUQNN). Our results show that the\nTunnElQNN model consistently outperforms the ReLUQNN counterpart. Furthermore,\nwe analyse the decision boundaries generated by TunnElQNN under different\nlevels of class overlap and compare them to those produced by a neural network\nimplementing TDAF within a fully classical architecture. These findings\nhighlight the potential of integrating physics-inspired activation functions\nwith quantum components to enhance the expressiveness and robustness of hybrid\nquantum-classical machine learning architectures.", "published": "2025-05-02 00:30:50", "link": "http://arxiv.org/abs/2505.00933v1", "categories": ["cs.LG", "physics.app-ph", "quant-ph"], "primary_category": "cs.LG"}
{"title": "Robust Root Cause Diagnosis using In-Distribution Interventions", "abstract": "Diagnosing the root cause of an anomaly in a complex interconnected system is\na pressing problem in today's cloud services and industrial operations. We\npropose In-Distribution Interventions (IDI), a novel algorithm that predicts\nroot cause as nodes that meet two criteria: 1) **Anomaly:** root cause nodes\nshould take on anomalous values; 2) **Fix:** had the root cause nodes assumed\nusual values, the target node would not have been anomalous. Prior methods of\nassessing the fix condition rely on counterfactuals inferred from a Structural\nCausal Model (SCM) trained on historical data. But since anomalies are rare and\nfall outside the training distribution, the fitted SCMs yield unreliable\ncounterfactual estimates. IDI overcomes this by relying on interventional\nestimates obtained by solely probing the fitted SCM at in-distribution inputs.\nWe present a theoretical analysis comparing and bounding the errors in\nassessing the fix condition using interventional and counterfactual estimates.\nWe then conduct experiments by systematically varying the SCM's complexity to\ndemonstrate the cases where IDI's interventional approach outperforms the\ncounterfactual approach and vice versa. Experiments on both synthetic and\nPetShop RCD benchmark datasets demonstrate that \\our\\ consistently identifies\ntrue root causes more accurately and robustly than nine existing\nstate-of-the-art RCD baselines. Code is released at\nhttps://github.com/nlokeshiisc/IDI_release.", "published": "2025-05-02 00:19:43", "link": "http://arxiv.org/abs/2505.00930v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Compact Recurrent Transformer with Persistent Memory", "abstract": "The Transformer architecture has shown significant success in many language\nprocessing and visual tasks. However, the method faces challenges in\nefficiently scaling to long sequences because the self-attention computation is\nquadratic with respect to the input length. To overcome this limitation,\nseveral approaches scale to longer sequences by breaking long sequences into a\nseries of segments, restricting self-attention to local dependencies between\ntokens within each segment and using a memory mechanism to manage information\nflow between segments. However, these approached generally introduce additional\ncompute overhead that restricts them from being used for applications where\nlimited compute memory and power are of great concern (such as edge computing).\nWe propose a novel and efficient Compact Recurrent Transformer (CRT), which\ncombines shallow Transformer models that process short local segments with\nrecurrent neural networks to compress and manage a single persistent memory\nvector that summarizes long-range global information between segments. We\nevaluate CRT on WordPTB and WikiText-103 for next-token-prediction tasks, as\nwell as on the Toyota Smarthome video dataset for classification. CRT achieves\ncomparable or superior prediction results to full-length Transformers in the\nlanguage datasets while using significantly shorter segments (half or quarter\nsize) and substantially reduced FLOPs. Our approach also demonstrates\nstate-of-the-art performance on the Toyota Smarthome video dataset.", "published": "2025-05-02 00:11:44", "link": "http://arxiv.org/abs/2505.00929v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Virtual Force-Based Routing of Modular Agents on a Graph", "abstract": "Modular vehicles have become an area of academic interest in the field of\nmulti-agent systems. Modularity allows vehicles to connect and disconnect with\neach other mid-transit which provides a balance between efficiency and\nflexibility when solving complex and large scale tasks in urban or aerial\ntransportation. This paper details a generalized scheme to route multiple\nmodular agents on a graph to a predetermined set of target nodes. The objective\nis to visit all target nodes while incurring minimum resource expenditure.\nAgents that are joined together will incur the equivalent cost of a single\nagent, which is motivated by the logistical benefits of traffic reduction and\nincreased fuel efficiency. To solve this problem, we introduce a heuristic\nalgorithm that seeks to balance the optimality of the path that an agent takes\nand the cost benefit of joining agents. Our approach models the agents and\ntargets as point charges, where the agents take the path of highest attractive\nforce from its target node and neighboring agents. We validate our approach by\nsimulating multiple modular agents along real-world transportation routes in\nthe road network of Champaign-Urbana, Illinois, USA. For two vehicles, it\nperformed equally compared to an existing modular-agent routing algorithm.\nThree agents were then routed using our method and the performance was\nbenchmarked against non-modular agents using a simple shortest path policy\nwhere it performs better than the non-modular implementation 81 percent of the\ntime. Moreover, we show that the proposed algorithm operates faster than\nexisting routing methods for modular agents.", "published": "2025-05-02 00:11:18", "link": "http://arxiv.org/abs/2505.00928v1", "categories": ["cs.MA", "math.OC"], "primary_category": "cs.MA"}
{"title": "A generalization of the Gauss-Seidel iteration method for generalized absolute value equations", "abstract": "A parameter-free method, namely the generalization of the Gauss-Seidel (GGS)\nmethod, is developed to solve generalized absolute value equations. Convergence\nof the proposed method is analyzed. Numerical results are given to demonstrate\nthe effectiveness and efficiency of the GGS method. Some results in the recent\nwork of Edalatpour et al. \\cite{edhs2017} are extended.", "published": "2025-05-02 14:11:38", "link": "http://arxiv.org/abs/2505.01293v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A CFL-type Condition and Theoretical Insights for Discrete-Time Sparse Full-Order Model Inference", "abstract": "In this work, we investigate the data-driven inference of a discrete-time\ndynamical system via a sparse Full-Order Model (sFOM). We first formulate the\ninvolved Least Squares (LS) problem and discuss the need for regularization,\nindicating a connection between the typically employed $l_2$ regularization and\nthe stability of the inferred discrete-time sFOM. We then provide theoretical\ninsights considering the consistency and stability properties of the inferred\nnumerical schemes that form the sFOM and exemplify them via illustrative, 1D\ntest cases of linear diffusion and linear advection. For linear advection, we\nanalytically derive a \"sampling CFL\" condition, which dictates a bound for the\nratio of spatial and temporal discretization steps in the training data that\nensures stability of the inferred sFOM. Finally, we investigate the sFOM\ninference for two nonlinear problems, namely a 2D Burgers' test case and the\nincompressible flow in an oscillating lid driven cavity, and draw connections\nbetween the theoretical findings and the properties of the inferred, nonlinear\nsFOMs.", "published": "2025-05-02 13:12:37", "link": "http://arxiv.org/abs/2505.01244v1", "categories": ["math.DS", "cs.NA", "math.NA"], "primary_category": "math.DS"}
{"title": "Asymptotic Linear Convergence of ADMM for Isotropic TV Norm Compressed Sensing", "abstract": "We prove an explicit local linear rate for ADMM solving the isotropic Total\nVariation (TV) norm compressed sensing problem in multiple dimensions, by\nanalyzing the auxiliary variable in the equivalent Douglas-Rachford splitting\non a dual problem. Numerical verification on large 3D problems and real MRI\ndata will be shown. Though the proven rate is not sharp, it is close to the\nobserved ones in numerical tests.", "published": "2025-05-02 13:05:27", "link": "http://arxiv.org/abs/2505.01240v1", "categories": ["math.OC", "cs.NA", "math.NA", "90C25 (Primary) 65K05, 49J52 (Secondary)"], "primary_category": "math.OC"}
{"title": "Constructive solution of the common invariant cone problem", "abstract": "Sets of $d\\times d$ matrices sharing a common invariant cone enjoy special\nproperties, which are widely used in applications. However, finding this cone\nor even proving its existence/non-existence is hard. This problem is known to\nbe algorithmically undecidable for general sets of matrices. We show that it\ncan nevertheless be efficiently solved in practice. An algorithm that for a\ngiven finite set of matrices, either finds a common invariant cone or proves\nits non-existence is presented. Numerical results demonstrate that it works for\na vast majority of matrix sets. The structure and properties of the minimal and\nmaximal invariant cones are analyzed. Applications to dynamical systems and\ncombinatorics are considered.", "published": "2025-05-02 12:28:32", "link": "http://arxiv.org/abs/2505.01229v1", "categories": ["math.NA", "cs.NA", "15B48, 52B05"], "primary_category": "math.NA"}
{"title": "A Parameter-Driven Physics-Informed Neural Network Framework for Solving Two-Parameter Singular Perturbation Problems Involving Boundary Layers", "abstract": "In this article, our goal is to solve two-parameter singular perturbation\nproblems (SPPs) in one- and two-dimensions using an adapted Physics-Informed\nNeural Networks (PINNs) approach. Such problems are of major importance in\nengineering and sciences as it appears in control theory, fluid and gas\ndynamics, financial modelling and so on. Solutions of such problems exhibit\nboundary and/or interior layers, which make them difficult to handle. It has\nbeen validated in the literature that standard PINNs have low accuracy and\ncan't handle such problems efficiently. Recently Cao et. al\n\\cite{cao2023physics} proposed a new parameter asymptotic PINNs (PA-PINNs) to\nsolve one-parameter singularly perturbed convection-dominated problems. It was\nobserved that PA-PINNs works better than standard PINNs and gPINNs in terms of\naccuracy, convergence and stability. In this article, for the first time\nrobustness of PA-PINNs will be validated for solving two-parameter SPPs.", "published": "2025-05-02 10:03:21", "link": "http://arxiv.org/abs/2505.01159v1", "categories": ["math.NA", "cs.NA", "65M12, 68T07, 35J30, 76M45"], "primary_category": "math.NA"}
{"title": "On calculation of canonical decomposition of Tensor via the grid of local discrepancies", "abstract": "The method for calculation of the canonical decomposition that approximates a\ntensor of high order is considered, which requires moderate computational\nresources. It is based on the replacement of the approximation error norm\n(global discrepancy functional) by the grid of local functionals (discrepancies\ncomputed on hyperplanes). The point of the global functional minimum in the\nspace of the canonical decomposition cores is determined by the set of the\nstationary points of local functionals. In result, the estimation of the cores\nof the canonical decomposition is possible using Newton method applied\npoint-wisely along coordinates and nodes. The discrepancies on the hyperplanes\nare calculated using Monte-Carlo method. Numerical tests on the approximation\nof sixth order tensors confirms the efficiency of the proposed approach.", "published": "2025-05-02 05:22:59", "link": "http://arxiv.org/abs/2505.01011v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Modelling Financial Market Imperfection Using Open Quantum Systems", "abstract": "We start with the idea that open quantum systems can be used to represent\nfinancial markets by modelling events from the external environment and their\nimpact on the market price. We show how to characterize distinct orbits of the\ntime evolution, and look at the development of the reduced density matrix, that\nrepresents the state of the market, over long time frames. In particular we\ndistinguish between classical and non-classical modes of time evolution. We\nshow that whilst both tend to the same set of maximum entropy states, this\noccurs faster in classical systems, with a knock on effect on the resulting\nprobability distributions. We demonstrate how non-classical modes of\ntime-evolution can be used to incorporate factors such as illiquid trades and\nimperfect trading mechanisms, and distinguish between different mechanisms of\nnon-classical time evolution.", "published": "2025-05-02 13:59:36", "link": "http://arxiv.org/abs/2505.01284v1", "categories": ["q-fin.MF", "q-fin.GN", "91-10"], "primary_category": "q-fin.MF"}
{"title": "Towards modelling lifetime default risk: Exploring different subtypes of recurrent event Cox-regression models", "abstract": "In the pursuit of modelling a loan's probability of default (PD) over its\nlifetime, repeat default events are often ignored when using Cox Proportional\nHazard (PH) models. Excluding such events may produce biased and inaccurate\nPD-estimates, which can compromise financial buffers against future losses.\nAccordingly, we investigate a few subtypes of Cox-models that can incorporate\nrecurrent default events. Using South African mortgage data, we explore both\nthe Andersen-Gill (AG) and the Prentice-Williams-Peterson (PWP) spell-time\nmodels. These models are compared against a baseline that deliberately ignores\nrecurrent events, called the time to first default (TFD) model. Models are\nevaluated using Harrell's c-statistic, adjusted Cox-Sell residuals, and a novel\nextension of time-dependent receiver operating characteristic (ROC) analysis.\nFrom these Cox-models, we demonstrate how to derive a portfolio-level\nterm-structure of default risk, which is a series of marginal PD-estimates at\neach point of the average loan's lifetime. While the TFD- and PWP-models do not\ndiffer significantly across all diagnostics, the AG-model underperformed\nexpectations. Depending on the prevalence of recurrent defaults, one may\ntherefore safely ignore them when estimating lifetime default risk.\nAccordingly, our work enhances the current practice of using Cox-modelling in\nproducing timeous and accurate PD-estimates under IFRS 9.", "published": "2025-05-02 06:33:34", "link": "http://arxiv.org/abs/2505.01044v1", "categories": ["q-fin.RM", "q-fin.ST", "stat.AP"], "primary_category": "q-fin.RM"}
{"title": "Overview and practical recommendations on using Shapley Values for identifying predictive biomarkers via CATE modeling", "abstract": "In recent years, two parallel research trends have emerged in machine\nlearning, yet their intersections remain largely unexplored. On one hand, there\nhas been a significant increase in literature focused on Individual Treatment\nEffect (ITE) modeling, particularly targeting the Conditional Average Treatment\nEffect (CATE) using meta-learner techniques. These approaches often aim to\nidentify causal effects from observational data. On the other hand, the field\nof Explainable Machine Learning (XML) has gained traction, with various\napproaches developed to explain complex models and make their predictions more\ninterpretable. A prominent technique in this area is Shapley Additive\nExplanations (SHAP), which has become mainstream in data science for analyzing\nsupervised learning models. However, there has been limited exploration of SHAP\napplication in identifying predictive biomarkers through CATE models, a crucial\naspect in pharmaceutical precision medicine. We address inherent challenges\nassociated with the SHAP concept in multi-stage CATE strategies and introduce a\nsurrogate estimation approach that is agnostic to the choice of CATE strategy,\neffectively reducing computational burdens in high-dimensional data. Using this\napproach, we conduct simulation benchmarking to evaluate the ability to\naccurately identify biomarkers using SHAP values derived from various CATE\nmeta-learners and Causal Forest.", "published": "2025-05-02 09:44:04", "link": "http://arxiv.org/abs/2505.01145v1", "categories": ["stat.ME", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Binamix -- A Python Library for Generating Binaural Audio Datasets", "abstract": "The increasing demand for spatial audio in applications such as virtual\nreality, immersive media, and spatial audio research necessitates robust\nsolutions to generate binaural audio data sets for use in testing and\nvalidation. Binamix is an open-source Python library designed to facilitate\nprogrammatic binaural mixing using the extensive SADIE II Database, which\nprovides Head Related Impulse Response (HRIR) and Binaural Room Impulse\nResponse (BRIR) data for 20 subjects. The Binamix library provides a flexible\nand repeatable framework for creating large-scale spatial audio datasets,\nmaking it an invaluable resource for codec evaluation, audio quality metric\ndevelopment, and machine learning model training. A range of pre-built example\nscripts, utility functions, and visualization plots further streamline the\nprocess of custom pipeline creation. This paper presents an overview of the\nlibrary's capabilities, including binaural rendering, impulse response\ninterpolation, and multi-track mixing for various speaker layouts. The tools\nutilize a modified Delaunay triangulation technique to achieve accurate\nHRIR/BRIR interpolation where desired angles are not present in the data. By\nsupporting a wide range of parameters such as azimuth, elevation, subject\nImpulse Responses (IRs), speaker layouts, mixing controls, and more, the\nlibrary enables researchers to create large binaural datasets for any\ndownstream purpose. Binamix empowers researchers and developers to advance\nspatial audio applications with reproducible methodologies by offering an\nopen-source solution for binaural rendering and dataset generation. We release\nthe library under the Apache 2.0 License at\nhttps://github.com/QxLabIreland/Binamix/", "published": "2025-05-02 16:17:00", "link": "http://arxiv.org/abs/2505.01369v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Cram\u00e9r-Rao Bounds for Integrated Sensing and Communications in Pinching-Antenna Systems", "abstract": "Pinching-antenna systems (PASs) have recently emerged as a flexible,\ncost-effective route to large-scale antenna deployments envisioned for\nintegrated sensing and communications (ISAC). This paper establishes the\nfundamental sensing limits of a bistatic PAS link by deriving closed-form\nCram\\'er-Rao lower bounds for the joint estimation of range and direction when\na target is illuminated by pinching antennas placed along a dielectric\nwaveguide and observed by a uniform linear array receiver. By rigorously\npreserving the amplitude and phase variations of each pinching antenna, as well\nas exploiting their non-uniform deployment, we gain valuable insights into the\nperformance gain of PASs over conventional antenna arrays. Numerical results\nvalidate that the PAS-based ISAC can achieve centimeter-level ranging and\nsub-degree angular resolution with significantly fewer hardware resources than\nconventional uniform linear arrays. The derived bounds provide practical design\nguidelines for next-generation PAS-enabled ISAC systems.", "published": "2025-05-02 15:06:47", "link": "http://arxiv.org/abs/2505.01333v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Electronic Nose for Agricultural Grain Pest Detection, Identification, and Monitoring: A Review", "abstract": "Biotic pest attacks and infestations are major causes of stored grain losses,\nleading to significant food and economic losses. Conventional, manual,\nsampling-based pest recognition methods are labor-intensive, time-consuming,\ncostly, require expertise, and may not even detect hidden infestations. In\nrecent years, the electronic nose (e-nose) approach has emerged as a potential\nalternative for agricultural grain pest recognition and monitoring. An e-nose\nmimics human olfactory systems by integrating a sensor array, data acquisition,\nand analysis for recognizing grain pests by analyzing volatile organic\ncompounds (VOCs) emitted by grain and pests. However, well-documented, curated,\nand synthesized literature on the use of e-nose technology for grain pest\ndetection is lacking. Therefore, this systematic literature review provides a\ncomprehensive overview of the current state-of-the-art e-nose technology for\nagricultural grain pest monitoring. The review examines employed sensor\ntechnology, targeted pest species type, grain medium, data processing, and\npattern recognition techniques. An e-nose is a promising tool that offers a\nrapid, low-cost, non-destructive solution for detecting, identifying, and\nmonitoring grain pests, including microscopic and hidden insects, with good\naccuracy. We identified the factors that influence the e-nose performance,\nwhich include pest species, storage duration, temperature, moisture content,\nand pest density. The major challenges include sensor array optimization or\nselection, large data processing, poor repeatability, and comparability among\nmeasurements. An inexpensive and portable e-nose has the potential to help\nstakeholders and storage managers take timely and data-driven informed actions\nor decisions to reduce overall food and economic losses.", "published": "2025-05-02 14:25:08", "link": "http://arxiv.org/abs/2505.01301v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Contactless pulse rate assessment: Results and insights for application in driving simulator", "abstract": "Camera-based monitoring of Pulse Rate (PR) enables continuous and unobtrusive\nassessment of driver's state, allowing estimation of fatigue or stress that\ncould impact traffic safety. Commonly used wearable Photoplethysmography (PPG)\nsensors, while effective, suffer from motion artifacts and user discomfort.\nThis study explores the feasibility of non-contact PR assessment using facial\nvideo recordings captured by a Red, Green, and Blue (RGB) camera in a driving\nsimulation environment. The proposed approach detects subtle skin color\nvariations due to blood flow and compares extracted PR values against reference\nmeasurements from a wearable wristband Empatica E4. We evaluate the impact of\nEulerian Video Magnification (EVM) on signal quality and assess statistical\ndifferences in PR between age groups. Data obtained from 80 recordings from 64\nhealthy subjects covering a PR range of 45-160 bpm are analyzed, and signal\nextraction accuracy is quantified using metrics, such as Mean Absolute Error\n(MAE) and Root Mean Square Error (RMSE). Results show that EVM slightly\nimproves PR estimation accuracy, reducing MAE from 6.48 bpm to 5.04 bpm and\nRMSE from 7.84 bpm to 6.38 bpm. A statistically significant difference is found\nbetween older and younger groups with both video-based and ground truth\nevaluation procedures. Additionally, we discuss Empatica E4 bias and its\npotential impact on the overall assessment of contact measurements. Altogether\nthe findings demonstrate the feasibility of camera-based PR monitoring in\ndynamic environments and its potential integration into driving simulators for\nreal-time physiological assessment.", "published": "2025-05-02 14:22:12", "link": "http://arxiv.org/abs/2505.01299v1", "categories": ["eess.IV", "eess.SP"], "primary_category": "eess.IV"}
{"title": "Network-Level ISAC Design: State-of-the-Art, Challenges, and Opportunities", "abstract": "The ultimate goal of integrated sensing and communication (ISAC) deployment\nis to provide coordinated sensing and communication services at an\nunprecedented scale. This paper presents a comprehensive overview of\nnetwork-level ISAC systems, an emerging paradigm that significantly extends the\ncapabilities of link-level ISAC through distributed cooperation. We first\nexamine recent advancements in network-level ISAC architectures, emphasizing\nvarious cooperation schemes and distributed system designs. The sensing and\ncommunication (S\\&C) performance is analyzed with respect to interference\nmanagement and cooperative S\\&C, offering new insights into the design\nprinciples necessary for large-scale networked ISAC deployments. In addition,\ndistributed signaling strategies across different levels of cooperation are\nreviewed, focusing on key performance metrics such as sensing accuracy and\ncommunication quality-of-service (QoS). Next, we explore the key challenges for\npractical deployment where the critical role of synchronization is also\ndiscussed, highlighting advanced over-the-air synchronization techniques\nspecifically tailored for bi-static and distributed ISAC systems. Finally, open\nchallenges and future research directions in network-level ISAC design are\nidentified. The findings and discussions aim to serve as a foundational\nguideline for advancing scalable, high-performance, and resilient distributed\nISAC systems in next-generation wireless networks.", "published": "2025-05-02 14:13:59", "link": "http://arxiv.org/abs/2505.01295v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Bridging the Gap via Data-Aided Sensing: Can Bistatic ISAC Converge to Genie Performance?", "abstract": "We investigate data-aided iterative sensing in bistatic OFDM ISAC systems,\nfocusing on scenarios with co-located sensing and communication receivers. To\nenhance target detection beyond pilot-only sensing methods, we propose a\nmulti-stage bistatic OFDM receiver, performing iterative sensing and data\ndemodulation to progressively refine ISAC channel and data estimates.\nSimulation results demonstrate that the proposed data-aided scheme\nsignificantly outperforms pilot-only benchmarks, particularly in multi-target\nscenarios, substantially narrowing the performance gap compared to a\ngenie-aided system with perfect data knowledge. Moreover, the proposed approach\nconsiderably expands the bistatic ISAC trade-off region, closely approaching\nthe probability of detection-achievable rate boundary established by its\ngenie-aided counterpart.", "published": "2025-05-02 13:55:56", "link": "http://arxiv.org/abs/2505.01280v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Simultaneous Multi-Beam Radar with Full Range Resolution exploiting Space-Code Beamforming", "abstract": "Conventional monostatic radar systems typically exhibit a trade-off between\nlong-range target detection achieved through narrow beams and short-range\nwide-area surveillance employing broad beams. Realizing both functionalities\nwithin a single system, enabling simultaneous surveillance and long-range\ntarget localization, poses a significant challenge. This paper presents a novel\nsignal model and an all-digital frequency domain radar architecture leveraging\nfirst-of-its-kind space-code beamforming technique to achieve ubiquitous radar\ncoverage. We show that the range-angle map can be estimated for all targets at\nfull range-resolution for all beams compared to existing subcarrier based\nbeamforming radars.", "published": "2025-05-02 13:34:02", "link": "http://arxiv.org/abs/2505.01265v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Higher-Order Spectra and their Unbiased Estimation in the GPU-accelerated SignalSnap Library", "abstract": "The analysis of time-dependent data poses a fundamental challenge in many\nfields of science and engineering. While concepts for higher-order spectral\nanalysis like Brillinger's polyspectra for stationary processes have long been\nintroduced, their applications have been limited probably due to high\ncomputational cost and complexity of implementation. Here we discuss the\ntheoretical background of estimating polyspectra with our open-source\nGPU-accelerated SignaSnap library and highlight its advantages over previous\nimplementations: (i) The calculation of spectra is unprecedentedly based on\nunbiased and consistent estimators that suppress the appearance of false\nstructures in fourth-order spectra. (ii) SignalSnap implements\ncross-correlation spectra for up to four channels. (iii) The spectral estimates\nof SignalSnap have a clear relation to Brillinger's definition of ideal spectra\nof continuous stochastic processes in terms of amplitude and spectral\nresolution. (iv) SignalSnap estimates the variance of each spectral value. We\nshow how polyspectra reveal, e.g., the correlations between different channels\nor the breaking of time-inversion symmetry and discuss how quasi-polyspectra\nuncover the non-stationarity of signals.", "published": "2025-05-02 12:36:30", "link": "http://arxiv.org/abs/2505.01231v1", "categories": ["physics.data-an", "eess.SP", "quant-ph"], "primary_category": "physics.data-an"}
{"title": "One Target, Many Views: Multi-User Fusion for Collaborative Uplink ISAC", "abstract": "We propose a novel pilot-free multi-user uplink framework for integrated\nsensing and communication (ISAC) in mm-wave networks, where single-antenna\nusers transmit orthogonal frequency division multiplexing signals without\ndedicated pilots. The base station exploits the spatial and velocity\ndiversities of users to simultaneously decode messages and detect targets,\ntransforming user transmissions into a powerful sensing tool. Each user's\nsignal, structured by a known codebook, propagates through a sparse multi-path\nchannel with shared moving targets and user-specific scatterers. Notably,\ncommon targets induce distinct delay-Doppler-angle signatures, while stationary\nscatterers cluster in parameter space. We formulate the joint multi-path\nparameter estimation and data decoding as a 3D super-resolution problem,\nextracting delays, Doppler shifts, and angles-of-arrival via atomic norm\nminimization, efficiently solved using semidefinite programming. A core\ninnovation is multiuser fusion, where diverse user observations are\ncollaboratively combined to enhance sensing and decoding. This approach\nimproves robustness and integrates multi-user perspectives into a unified\nestimation framework, enabling high-resolution sensing and reliable\ncommunication. Numerical results show that the proposed framework significantly\nenhances both target estimation and communication performance, highlighting its\npotential for next-generation ISAC systems.", "published": "2025-05-02 12:18:43", "link": "http://arxiv.org/abs/2505.01223v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Performance of Cell-Free Massive MIMO in Realistic Urban Propagation Environments", "abstract": "While UE-centric cell-free massive MIMO (CF-mMIMO) provides high and uniform\nthroughput performance under the assumption of a uniform propagation\nenvironment modeled by the log-distance path loss channel model, the\nperformance under a realistic urban propagation environment is not yet fully\naddressed. In this paper we conduct the first comparative performance study of\nCF-mMIMO under both the widely assumed log-distance channel model and the\nrealistic urban propagation environment obtained via raytracing using real 3D\ncity layouts and practical AP locations. Our results show that with the\nraytracing channel model, CF-mMIMO cannot achieve as high and uniform\nthroughput performance as observed with the log-distance channel model, putting\ninto question the attractiveness in practice of CF-mMIMO for real urban\ndeployments.", "published": "2025-05-02 12:18:21", "link": "http://arxiv.org/abs/2505.01222v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Impact of Insufficient CP on Sensing Performance in OFDM-ISAC Systems", "abstract": "Orthogonal frequency-division multiplexing (OFDM) is widely considered a\nleading waveform candidate for integrated sensing and communication (ISAC) in\n6G networks. However, the cyclic prefix (CP) used to mitigate multipath effects\nin communication systems also limits the maximum sensing range. Target echoes\narriving beyond the CP length cause inter-symbol interference (ISI) and\ninter-carrier interference (ICI), which degrade the mainlobe level and raise\nsidelobe levels in the range-Doppler map (RDM). This paper presents a unified\nanalytical framework to characterize the ISI and ICI caused by an insufficient\nCP length in multi-target scenarios. For the first time, we derive closed-form\nexpressions for the second-order moments of the RDM under both matched\nfiltering (MF) and reciprocal filtering (RF) processing with insufficient CP\nlength. These expressions quantify the effects of CP length, symbol\nconstellation, and inter-target interference (ITI) on the mainlobe and sidelobe\nlevels. Based on these results, we further derive explicit formulas for the\npeak sidelobe level ratio (PSLR) and integrated sidelobe level ratio (ISLR) of\nthe RDM, revealing a fundamental trade-off between noise amplification in RF\nand ITI in MF. Numerical results validate our theoretical derivations and\nillustrate the critical impact of insufficient CP length on sensing performance\nin OFDM-ISAC systems.", "published": "2025-05-02 09:04:16", "link": "http://arxiv.org/abs/2505.01125v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "WirelessAgent: Large Language Model Agents for Intelligent Wireless Networks", "abstract": "The rapid evolution of wireless networks presents unprecedented challenges in\nmanaging complex and dynamic systems. Existing methods are increasingly facing\nfundamental limitations in addressing these challenges. In this paper, we\nintroduce WirelessAgent, a novel framework that harnesses large language models\n(LLMs) to create autonomous AI agents for diverse wireless network tasks. This\nframework integrates four core modules that mirror human cognitive processes:\nperception, memory, planning, and action. To implement it, we provide a basic\nusage based on agentic workflows and the LangGraph architecture. We demonstrate\nthe effectiveness of WirelessAgent through a comprehensive case study on\nnetwork slicing. The numerical results show that WirelessAgent achieves\n$44.4\\%$ higher bandwidth utilization than the \\emph{Prompt-based} method,\nwhile performing only $4.3\\%$ below the \\emph{Rule-based optimality}. Notably,\nWirelessAgent delivers near-optimal network throughput across diverse network\nscenarios. These underscore the framework's potential for intelligent and\nautonomous resource management in future wireless networks. The code is\navailable at \\url{https://github.com/jwentong/WirelessAgent_R1}.", "published": "2025-05-02 07:29:19", "link": "http://arxiv.org/abs/2505.01074v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Always Tell Me The Odds: Fine-grained Conditional Probability Estimation", "abstract": "We present a state-of-the-art model for fine-grained probability estimation\nof propositions conditioned on context. Recent advances in large language\nmodels (LLMs) have significantly enhanced their reasoning capabilities,\nparticularly on well-defined tasks with complete information. However, LLMs\ncontinue to struggle with making accurate and well-calibrated probabilistic\npredictions under uncertainty or partial information. While incorporating\nuncertainty into model predictions often boosts performance, obtaining reliable\nestimates of that uncertainty remains understudied. In particular, LLM\nprobability estimates tend to be coarse and biased towards more frequent\nnumbers. Through a combination of human and synthetic data creation and\nassessment, scaling to larger models, and better supervision, we propose a set\nof strong and precise probability estimation models. We conduct systematic\nevaluations across tasks that rely on conditional probability estimation and\nshow that our approach consistently outperforms existing fine-tuned and\nprompting-based methods by a large margin.", "published": "2025-05-02 21:33:18", "link": "http://arxiv.org/abs/2505.01595v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "PIPA: A Unified Evaluation Protocol for Diagnosing Interactive Planning Agents", "abstract": "The growing capabilities of large language models (LLMs) in\ninstruction-following and context-understanding lead to the era of agents with\nnumerous applications. Among these, task planning agents have become especially\nprominent in realistic scenarios involving complex internal pipelines, such as\ncontext understanding, tool management, and response generation. However,\nexisting benchmarks predominantly evaluate agent performance based on task\ncompletion as a proxy for overall effectiveness. We hypothesize that merely\nimproving task completion is misaligned with maximizing user satisfaction, as\nusers interact with the entire agentic process and not only the end result. To\naddress this gap, we propose PIPA, a unified evaluation protocol that\nconceptualizes the behavioral process of interactive task planning agents\nwithin a partially observable Markov Decision Process (POMDP) paradigm. The\nproposed protocol offers a comprehensive assessment of agent performance\nthrough a set of atomic evaluation criteria, allowing researchers and\npractitioners to diagnose specific strengths and weaknesses within the agent's\ndecision-making pipeline. Our analyses show that agents excel in different\nbehavioral stages, with user satisfaction shaped by both outcomes and\nintermediate behaviors. We also highlight future directions, including systems\nthat leverage multiple agents and the limitations of user simulators in task\nplanning.", "published": "2025-05-02 21:27:10", "link": "http://arxiv.org/abs/2505.01592v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AI agents may be worth the hype but not the resources (yet): An initial exploration of machine translation quality and costs in three language pairs in the legal and news domains", "abstract": "Large language models (LLMs) and multi-agent orchestration are touted as the\nnext leap in machine translation (MT), but their benefits relative to\nconventional neural MT (NMT) remain unclear. This paper offers an empirical\nreality check. We benchmark five paradigms, Google Translate (strong NMT\nbaseline), GPT-4o (general-purpose LLM), o1-preview (reasoning-enhanced LLM),\nand two GPT-4o-powered agentic workflows (sequential three-stage and iterative\nrefinement), on test data drawn from a legal contract and news prose in three\nEnglish-source pairs: Spanish, Catalan and Turkish. Automatic evaluation is\nperformed with COMET, BLEU, chrF2 and TER; human evaluation is conducted with\nexpert ratings of adequacy and fluency; efficiency with total input-plus-output\ntoken counts mapped to April 2025 pricing.\n  Automatic scores still favour the mature NMT system, which ranks first in\nseven of twelve metric-language combinations; o1-preview ties or places second\nin most remaining cases, while both multi-agent workflows trail. Human\nevaluation reverses part of this narrative: o1-preview produces the most\nadequate and fluent output in five of six comparisons, and the iterative agent\nedges ahead once, indicating that reasoning layers capture semantic nuance\nundervalued by surface metrics. Yet these qualitative gains carry steep costs.\nThe sequential agent consumes roughly five times, and the iterative agent\nfifteen times, the tokens used by NMT or single-pass LLMs.\n  We advocate multidimensional, cost-aware evaluation protocols and highlight\nresearch directions that could tip the balance: leaner coordination strategies,\nselective agent activation, and hybrid pipelines combining single-pass LLMs\nwith targeted agent intervention.", "published": "2025-05-02 20:02:13", "link": "http://arxiv.org/abs/2505.01560v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the effectiveness of Large Language Models in the mechanical design domain", "abstract": "In this work, we seek to understand the performance of large language models\nin the mechanical engineering domain. We leverage the semantic data found in\nthe ABC dataset, specifically the assembly names that designers assigned to the\noverall assemblies, and the individual semantic part names that were assigned\nto each part. After pre-processing the data we developed two unsupervised tasks\nto evaluate how different model architectures perform on domain-specific data:\na binary sentence-pair classification task and a zero-shot classification task.\nWe achieved a 0.62 accuracy for the binary sentence-pair classification task\nwith a fine-tuned model that focuses on fighting over-fitting: 1) modifying\nlearning rates, 2) dropout values, 3) Sequence Length, and 4) adding a\nmulti-head attention layer. Our model on the zero-shot classification task\noutperforms the baselines by a wide margin, and achieves a top-1 classification\naccuracy of 0.386. The results shed some light on the specific failure modes\nthat arise when learning from language in this domain.", "published": "2025-05-02 19:59:56", "link": "http://arxiv.org/abs/2505.01559v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CHORUS: Zero-shot Hierarchical Retrieval and Orchestration for Generating Linear Programming Code", "abstract": "Linear Programming (LP) problems aim to find the optimal solution to an\nobjective under constraints. These problems typically require domain knowledge,\nmathematical skills, and programming ability, presenting significant challenges\nfor non-experts. This study explores the efficiency of Large Language Models\n(LLMs) in generating solver-specific LP code. We propose CHORUS, a\nretrieval-augmented generation (RAG) framework for synthesizing Gurobi-based LP\ncode from natural language problem statements. CHORUS incorporates a\nhierarchical tree-like chunking strategy for theoretical contents and generates\nadditional metadata based on code examples from documentation to facilitate\nself-contained, semantically coherent retrieval. Two-stage retrieval approach\nof CHORUS followed by cross-encoder reranking further ensures contextual\nrelevance. Finally, expertly crafted prompt and structured parser with\nreasoning steps improve code generation performance significantly. Experiments\non the NL4Opt-Code benchmark show that CHORUS improves the performance of\nopen-source LLMs such as Llama3.1 (8B), Llama3.3 (70B), Phi4 (14B), Deepseek-r1\n(32B), and Qwen2.5-coder (32B) by a significant margin compared to baseline and\nconventional RAG. It also allows these open-source LLMs to outperform or match\nthe performance of much stronger baselines-GPT3.5 and GPT4 while requiring far\nfewer computational resources. Ablation studies further demonstrate the\nimportance of expert prompting, hierarchical chunking, and structured\nreasoning.", "published": "2025-05-02 16:36:57", "link": "http://arxiv.org/abs/2505.01485v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "SymPlanner: Deliberate Planning in Language Models with Symbolic Representation", "abstract": "Planning remains a core challenge for language models (LMs), particularly in\ndomains that require coherent multi-step action sequences grounded in external\nconstraints. We introduce SymPlanner, a novel framework that equips LMs with\nstructured planning capabilities by interfacing them with a symbolic\nenvironment that serves as an explicit world model. Rather than relying purely\non natural language reasoning, SymPlanner grounds the planning process in a\nsymbolic state space, where a policy model proposes actions and a symbolic\nenvironment deterministically executes and verifies their effects. To enhance\nexploration and improve robustness, we introduce Iterative Correction (IC),\nwhich refines previously proposed actions by leveraging feedback from the\nsymbolic environment to eliminate invalid decisions and guide the model toward\nvalid alternatives. Additionally, Contrastive Ranking (CR) enables fine-grained\ncomparison of candidate plans by evaluating them jointly. We evaluate\nSymPlanner on PlanBench, demonstrating that it produces more coherent, diverse,\nand verifiable plans than pure natural language baselines.", "published": "2025-05-02 15:18:03", "link": "http://arxiv.org/abs/2505.01479v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Helping Large Language Models Protect Themselves: An Enhanced Filtering and Summarization System", "abstract": "The recent growth in the use of Large Language Models has made them\nvulnerable to sophisticated adversarial assaults, manipulative prompts, and\nencoded malicious inputs. Existing countermeasures frequently necessitate\nretraining models, which is computationally costly and impracticable for\ndeployment. Without the need for retraining or fine-tuning, this study presents\na unique defense paradigm that allows LLMs to recognize, filter, and defend\nagainst adversarial or malicious inputs on their own. There are two main parts\nto the suggested framework: (1) A prompt filtering module that uses\nsophisticated Natural Language Processing (NLP) techniques, including zero-shot\nclassification, keyword analysis, and encoded content detection (e.g. base64,\nhexadecimal, URL encoding), to detect, decode, and classify harmful inputs; and\n(2) A summarization module that processes and summarizes adversarial research\nliterature to give the LLM context-aware defense knowledge. This approach\nstrengthens LLMs' resistance to adversarial exploitation by fusing text\nextraction, summarization, and harmful prompt analysis. According to\nexperimental results, this integrated technique has a 98.71% success rate in\nidentifying harmful patterns, manipulative language structures, and encoded\nprompts. By employing a modest amount of adversarial research literature as\ncontext, the methodology also allows the model to react correctly to harmful\ninputs with a larger percentage of jailbreak resistance and refusal rate. While\nmaintaining the quality of LLM responses, the framework dramatically increases\nLLM's resistance to hostile misuse, demonstrating its efficacy as a quick and\neasy substitute for time-consuming, retraining-based defenses.", "published": "2025-05-02 14:42:26", "link": "http://arxiv.org/abs/2505.01315v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Position: Enough of Scaling LLMs! Lets Focus on Downscaling", "abstract": "We challenge the dominant focus on neural scaling laws and advocate for a\nparadigm shift toward downscaling in the development of large language models\n(LLMs). While scaling laws have provided critical insights into performance\nimprovements through increasing model and dataset size, we emphasize the\nsignificant limitations of this approach, particularly in terms of\ncomputational inefficiency, environmental impact, and deployment constraints.\nTo address these challenges, we propose a holistic framework for downscaling\nLLMs that seeks to maintain performance while drastically reducing resource\ndemands. This paper outlines practical strategies for transitioning away from\ntraditional scaling paradigms, advocating for a more sustainable, efficient,\nand accessible approach to LLM development.", "published": "2025-05-02 04:13:27", "link": "http://arxiv.org/abs/2505.00985v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "More efficient sifting for grid norms, and applications to multiparty communication complexity", "abstract": "Building on the techniques behind the recent progress on the 3-term\narithmetic progression problem [KM'23], Kelley, Lovett, and Meka [KLM'24]\nconstructed the first explicit 3-player function $f:[N]^3 \\rightarrow \\{0,1\\}$\nthat demonstrates a strong separation between randomized and\n(non-)deterministic NOF communication complexity. Specifically, their hard\nfunction can be solved by a randomized protocol sending $O(1)$ bits, but\nrequires $\\Omega(\\log^{1/3}(N))$ bits of communication with a deterministic (or\nnon-deterministic) protocol.\n  We show a stronger $\\Omega(\\log^{1/2}(N))$ lower bound for their\nconstruction. To achieve this, the key technical advancement is an improvement\nto the sifting argument for grid norms of (somewhat dense) bipartite graphs. In\naddition to quantitative improvement, we qualitatively improve over [KLM'24] by\nrelaxing the hardness condition: while [KLM'24] proved their lower bound for\nany function $f$ that satisfies a strong two-sided pseudorandom condition, we\nshow that a weak one-sided condition suffices. This is achieved by a new\nstructural result for cylinder intersections (or, in graph-theoretic language,\nthe set of triangles induced from a tripartite graph), showing that any small\ncylinder intersection can be efficiently covered by a sum of simple ``slice''\nfunctions.", "published": "2025-05-02 21:11:25", "link": "http://arxiv.org/abs/2505.01587v1", "categories": ["cs.CC", "cs.DM", "math.CO"], "primary_category": "cs.CC"}
{"title": "HoneyBee: Efficient Role-based Access Control for Vector Databases via Dynamic Partitioning", "abstract": "As vector databases gain traction in enterprise applications, robust access\ncontrol has become critical to safeguard sensitive data. Access control in\nthese systems is often implemented through hybrid vector queries, which combine\nnearest neighbor search on vector data with relational predicates based on user\npermissions. However, existing approaches face significant trade-offs: creating\ndedicated indexes for each user minimizes query latency but introduces\nexcessive storage redundancy, while building a single index and applying access\ncontrol after vector search reduces storage overhead but suffers from poor\nrecall and increased query latency. This paper introduces HoneyBee, a dynamic\npartitioning framework that bridges the gap between these approaches by\nleveraging the structure of Role-Based Access Control (RBAC) policies. RBAC,\nwidely adopted in enterprise settings, groups users into roles and assigns\npermissions to those roles, creating a natural \"thin waist\" in the permission\nstructure that is ideal for partitioning decisions. Specifically, HoneyBee\nproduces overlapping partitions where vectors can be strategically replicated\nacross different partitions to reduce query latency while controlling storage\noverhead. By introducing analytical models for the performance and recall of\nthe vector search, HoneyBee formulates the partitioning strategy as a\nconstrained optimization problem to dynamically balance storage, query\nefficiency, and recall. Evaluations on RBAC workloads demonstrate that HoneyBee\nreduces storage redundancy compared to role partitioning and achieves up to 6x\nfaster query speeds than row-level security (RLS) with only 1.4x storage\nincrease, offering a practical middle ground for secure and efficient vector\nsearch.", "published": "2025-05-02 18:59:31", "link": "http://arxiv.org/abs/2505.01538v1", "categories": ["cs.DB", "cs.CR", "cs.IR", "cs.LG", "H.2.4; H.3.3; D.4.6"], "primary_category": "cs.DB"}
{"title": "Dynamical Update Maps for Particle Flow with Differential Algebra", "abstract": "Particle Flow Filters estimate the ``a posteriori\" probability density\nfunction (PDF) by moving an ensemble of particles according to the likelihood.\nParticles are propagated under the system dynamics until a measurement becomes\navailable when each particle undergoes an additional stochastic differential\nequation in a pseudo-time that updates the distribution following a homotopy\ntransformation. This flow of particles can be represented as a recursive update\nstep of the filter. In this work, we leverage the Differential Algebra (DA)\nrepresentation of the solution flow of dynamics to improve the computational\nburden of particle flow filters. Thanks to this approximation, both the\nprediction and the update differential equations are solved in the DA\nframework, creating two sets of polynomial maps: the first propagates particles\nforward in time while the second updates particles, achieving the flow. The\nfinal result is a new particle flow filter that rapidly propagates and updates\nPDFs using mathematics based on deviation vectors. Numerical applications show\nthe benefits of the proposed technique, especially in reducing computational\ntime, so that small systems such as CubeSats can run the filter for attitude\ndetermination.", "published": "2025-05-02 21:47:27", "link": "http://arxiv.org/abs/2505.01598v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Advances in Particle Flow Filters with Taylor Expansion Series", "abstract": "Particle Flow Filters perform the measurement update by moving particles to a\ndifferent location rather than modifying the particles' weight based on the\nlikelihood. Their movement (flow) is dictated by a drift term, which\ncontinuously pushes the particle toward the posterior distribution, and a\ndiffusion term, which guarantees the spread of particles. This work presents a\nnovel derivation of these terms based on high-order polynomial expansions,\nwhere the common techniques based on linearization reduce to a simpler version\nof the new methodology. Thanks to differential algebra, the high-order particle\nflow is derived directly onto the polynomials representation of the\ndistribution, embedded with differentiation and evaluation. The resulting\ntechnique proposes two new particle flow filters, whose difference relies on\nthe selection of the expansion center for the Taylor polynomial evaluation.\nNumerical applications show the improvement gained by the inclusion of\nhigh-order terms, especially when comparing performance with the Gromov flow\nand the \"exact\" flow.", "published": "2025-05-02 21:43:59", "link": "http://arxiv.org/abs/2505.01597v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Adaptive Passive Beamforming in RIS-Aided Communications With Q-Learning", "abstract": "Reconfigurable Intelligent Surfaces (RIS) appear as a promising solution to\ncombat wireless channel fading and interferences. However, the elements of the\nRIS need to be properly oriented to boost the data transmission rate. In this\nwork, we propose a new strategy to adaptively configure the RIS without Channel\nState Information (CSI). Our goal is to minimize the number of RIS\nconfigurations to be tested to find the optimal one. We formulate the problem\nas a stochastic shortest path problem, and use Q-Learning to solve it.", "published": "2025-05-02 15:14:19", "link": "http://arxiv.org/abs/2505.01478v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Enabling Training-Free Semantic Communication Systems with Generative Diffusion Models", "abstract": "Semantic communication (SemCom) has recently emerged as a promising paradigm\nfor next-generation wireless systems. Empowered by advanced artificial\nintelligence (AI) technologies, SemCom has achieved significant improvements in\ntransmission quality and efficiency. However, existing SemCom systems either\nrely on training over large datasets and specific channel conditions or suffer\nfrom performance degradation under channel noise when operating in a\ntraining-free manner. To address these issues, we explore the use of generative\ndiffusion models (GDMs) as training-free SemCom systems. Specifically, we\ndesign a semantic encoding and decoding method based on the inversion and\nsampling process of the denoising diffusion implicit model (DDIM), which\nintroduces a two-stage forward diffusion process, split between the transmitter\nand receiver to enhance robustness against channel noise. Moreover, we optimize\nsampling steps to compensate for the increased noise level caused by channel\nnoise. We also conduct a brief analysis to provide insights about this design.\nSimulations on the Kodak dataset validate that the proposed system outperforms\nthe existing baseline SemCom systems across various metrics.", "published": "2025-05-02 11:53:45", "link": "http://arxiv.org/abs/2505.01209v2", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Polarization Decomposition and Its Applications", "abstract": "The polarization decomposition of arbitrary binary-input memoryless channels\n(BMCs) is studied in this work. By introducing the polarization factor (PF),\ndefined in terms of the conditional entropy of the channel output under various\ninput configurations, we demonstrate that the symmetric capacities of the\npolarized subchannels can be uniformly expressed as functions of the PF. The\nexplicit formulation of the PF as a function of the block length and subchannel\nindex is derived. Furthermore, an efficient algorithm is proposed for the\ncomputation of the PF. Notably, we establish a one-to-one correspondence\nbetween each PF and an $n$-ary tree. Leveraging this tree structure, we develop\na pruning method to determine the conditional entropy associated with different\ninput relationships. The proposed polarization framework offers both\ntheoretical insights and practical advantages, including intuitive\nvisualization of polarization behavior and efficient polar code construction.\nTo the best of our knowledge, this is the first approach that enables the\nefficient computation of symmetric capacities for all subchannels in arbitrary\nBMCs.", "published": "2025-05-02 09:53:31", "link": "http://arxiv.org/abs/2505.01152v2", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Schr\u00f6dingerization based quantum algorithms for the fractional Poisson equation", "abstract": "We develop a quantum algorithm for solving high-dimensional fractional\nPoisson equations. By applying the Caffarelli-Silvestre extension, the\n$d$-dimensional fractional equation is reformulated as a local partial\ndifferential equation in $d+1$ dimensions. We propose a quantum algorithm for\nthe finite element discretization of this local problem, by capturing the\nsteady-state of the corresponding differential equations using the\nSchr\\\"odingerization approach from \\cite{JLY22SchrShort, JLY22SchrLong,\nanalogPDE}. The Schr\\\"odingerization technique transforms general linear\npartial and ordinary differential equations into Schr\\\"odinger-type systems,\nmaking them suitable for quantum simulation. This is achieved through the\nwarped phase transformation, which maps the equation into a higher-dimensional\nspace. We provide detailed implementations of the method and conduct a\ncomprehensive complexity analysis, which can show up to exponential advantage\n-- with respect to the inverse of the mesh size in high dimensions -- compared\nto its classical counterpart. Specifically, while the classical method requires\n$\\widetilde{\\mathcal{O}}(d^{1/2} 3^{3d/2} h^{-d-2})$ operations, the quantum\ncounterpart requires $\\widetilde{\\mathcal{O}}(d 3^{3d/2} h^{-2.5})$ queries to\nthe block-encoding input models, with the quantum complexity being independent\nof the dimension $d$ in terms of the inverse mesh size $h^{-1}$. Numerical\nexperiments are conducted to verify the validity of our formulation.", "published": "2025-05-02 21:53:19", "link": "http://arxiv.org/abs/2505.01602v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Nystr\u00f6m Type Exponential Integrators for Strongly Magnetized Charged Particle Dynamics", "abstract": "Calculating the dynamics of charged particles in electromagnetic fields (i.e.\nthe particle pushing problem) is one of the most computationally intensive\ncomponents of particle-in-cell (PIC) methods for plasma physics simulations.\nThis task is especially challenging when the plasma is strongly magnetized,\nsince in this case the particle motion consists of a wide range of temporal\nscales from highly oscillatory fast gyromotion to slow macroscopic behavior and\nthe resulting numerical model is very stiff. Current state-of-the-art time\nintegrators used to simulate particle motion have limitations given the severe\nnumerical stiffness of the problem and more efficient methods are of interest.\nRecently, exponential integrators have been proposed as a promising new\napproach for these simulations and shown to offer computational advantages over\ncommonly used schemes. Exponential methods can solve linear problems exactly\nand are A-stable. In this paper, the standard exponential algorithms framework\nis extended to derive Nystr\\\"om-type exponential methods that integrate the\nNewtonian equations of motion as a second-order differential equation. Specific\nNystr\\\"om-type schemes of second and third orders are derived and applied to\nstrongly magnetized particle pushing problems. Numerical experiments are\npresented to demonstrate that the Nystr\\\"om-type exponential integrators can\nprovide significant improvement in computational efficiency over the standard\nexponential methods.", "published": "2025-05-02 18:21:52", "link": "http://arxiv.org/abs/2505.01525v1", "categories": ["physics.comp-ph", "cs.NA", "math.NA", "physics.plasm-ph"], "primary_category": "physics.comp-ph"}
{"title": "Outlier-free isogeometric discretizations for Laplace eigenvalue problems: closed-form eigenvalue and eigenvector expressions", "abstract": "We derive explicit closed-form expressions for the eigenvalues and\neigenvectors of the matrices resulting from isogeometric Galerkin\ndiscretizations based on outlier-free spline subspaces for the Laplace\noperator, under different types of homogeneous boundary conditions on bounded\nintervals. For optimal spline subspaces and specific reduced spline spaces,\nrepresented in terms of B-spline-like bases, we show that the corresponding\nmass and stiffness matrices exhibit a Toeplitz-minus-Hankel or\nToeplitz-plus-Hankel structure. Such matrix structure holds for any degree p\nand implies that the eigenvalues are an explicitly known sampling of the\nspectral symbol of the Toeplitz part. Moreover, by employing tensor-product\narguments, we extend the closed-form property of the eigenvalues and\neigenvectors to a d-dimensional box. As a side result, we have an algebraic\nconfirmation that the considered optimal and reduced spline spaces are indeed\noutlier-free.", "published": "2025-05-02 17:06:34", "link": "http://arxiv.org/abs/2505.01487v1", "categories": ["math.NA", "cs.NA", "math.SP"], "primary_category": "math.NA"}
{"title": "Asset Pricing in Transformer", "abstract": "This paper proposes an innovative Transformer model, Single-directional\nrepresentative from Transformer (SERT), for US large capital stock pricing. It\nalso innovatively applies the pre-trained Transformer models under the stock\npricing and factor investment context. They are compared with standard\nTransformer models and encoder-only Transformer models in three periods\ncovering the entire COVID-19 pandemic to examine the model adaptivity and\nsuitability during the extreme market fluctuations. Namely, pre-COVID-19 period\n(mild up-trend), COVID-19 period (sharp up-trend with deep down shock) and\n1-year post-COVID-19 (high fluctuation sideways movement). The best proposed\nSERT model achieves the highest out-of-sample R2, 11.2% and 10.91%\nrespectively, when extreme market fluctuation takes place followed by\npre-trained Transformer models (10.38% and 9.15%). Their Trend-following-based\nstrategy wise performance also proves their excellent capability for hedging\ndownside risks during market shocks. The proposed SERT model achieves a Sortino\nratio 47% higher than the buy-and-hold benchmark in the equal-weighted\nportfolio and 28% higher in the value-weighted portfolio when the pandemic\nperiod is attended. It proves that Transformer models have a great capability\nto capture patterns of temporal sparsity data in the asset pricing factor\nmodel, especially with considerable volatilities. We also find the softmax\nsignal filter as the common configuration of Transformer models in alternative\ncontexts, which only eliminates differences between models, but does not\nimprove strategy-wise performance, while increasing attention heads improve the\nmodel performance insignificantly and applying the 'layer norm first' method do\nnot boost the model performance in our case.", "published": "2025-05-02 20:38:59", "link": "http://arxiv.org/abs/2505.01575v1", "categories": ["q-fin.CP", "econ.EM", "q-fin.PR", "91B28, 68T07", "J.1; I.2.6; I.5.1"], "primary_category": "q-fin.CP"}
{"title": "Multiscale Causal Analysis of Market Efficiency via News Uncertainty Networks and the Financial Chaos Index", "abstract": "This study evaluates the scale-dependent informational efficiency of stock\nmarkets using the Financial Chaos Index, a tensor-eigenvalue-based measure of\nrealized volatility. Incorporating Granger causality and network-theoretic\nanalysis across a range of economic, policy, and news-based uncertainty\nindices, we assess whether public information is efficiently incorporated into\nasset price fluctuations. Based on a 34-year time period from 1990 to 2023, at\nthe daily frequency, the semi-strong form of the Efficient Market Hypothesis is\nrejected at the 1\\% level of significance, indicating that asset price changes\nrespond predictably to lagged news-based uncertainty. In contrast, at the\nmonthly frequency, such predictive structure largely vanishes, supporting\ninformational efficiency at coarser temporal resolutions. A structural analysis\nof the Granger causality network reveals that fiscal and monetary policy\nuncertainties act as core initiators of systemic volatility, while peripheral\nindices, such as those related to healthcare and consumer prices, serve as\nlatent bridges that become activated under crisis conditions. These findings\nunderscore the role of time-scale decomposition and structural asymmetries in\ndiagnosing market inefficiencies and mapping the propagation of macro-financial\nuncertainty.", "published": "2025-05-02 19:08:39", "link": "http://arxiv.org/abs/2505.01543v1", "categories": ["q-fin.ST", "econ.EM"], "primary_category": "q-fin.ST"}
{"title": "Contextures: Representations from Contexts", "abstract": "Despite the empirical success of foundation models, we do not have a\nsystematic characterization of the representations that these models learn. In\nthis paper, we establish the contexture theory. It shows that a large class of\nrepresentation learning methods can be characterized as learning from the\nassociation between the input and a context variable. Specifically, we show\nthat many popular methods aim to approximate the top-d singular functions of\nthe expectation operator induced by the context, in which case we say that the\nrepresentation learns the contexture. We demonstrate the generality of the\ncontexture theory by proving that representation learning within various\nlearning paradigms -- supervised, self-supervised, and manifold learning -- can\nall be studied from such a perspective. We also prove that the representations\nthat learn the contexture are optimal on those tasks that are compatible with\nthe context. One important implication of the contexture theory is that once\nthe model is large enough to approximate the top singular functions, further\nscaling up the model size yields diminishing returns. Therefore, scaling is not\nall we need, and further improvement requires better contexts. To this end, we\nstudy how to evaluate the usefulness of a context without knowing the\ndownstream tasks. We propose a metric and show by experiments that it\ncorrelates well with the actual performance of the encoder on many real\ndatasets.", "published": "2025-05-02 19:50:56", "link": "http://arxiv.org/abs/2505.01557v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Data-driven Approach for Interpolation of Sparse Data", "abstract": "Studies of hadron resonances and their properties are limited by the accuracy\nand consistency of measured datasets, which can originate from many different\nexperiments. We have used Gaussian Processes (GP) to build interpolated\ndatasets, including quantification of uncertainties, so that data from\ndifferent sources can be used in model fitting without the need for arbitrary\nweighting. GPs predict values and uncertainties of observables at any kinematic\npoint. Bayesian inference is used to optimise the hyperparameters of the GP\nmodel. We demonstrate that the GP successfully interpolates data with\nquantified uncertainties by comparison with generated pseudodata. We also show\nthat this methodology can be used to investigate the consistency of data from\ndifferent sources. GPs provide a robust, model-independent method for\ninterpolating typical datasets used in hadron resonance studies, removing the\nlimitations of arbitrary weighting in sparse datasets.", "published": "2025-05-02 13:17:45", "link": "http://arxiv.org/abs/2505.01473v1", "categories": ["physics.data-an", "nucl-ex", "stat.ML"], "primary_category": "physics.data-an"}
{"title": "Transfer Learning-Based Deep Residual Learning for Speech Recognition in Clean and Noisy Environments", "abstract": "Addressing the detrimental impact of non-stationary environmental noise on\nautomatic speech recognition (ASR) has been a persistent and significant\nresearch focus. Despite advancements, this challenge continues to be a major\nconcern. Recently, data-driven supervised approaches, such as deep neural\nnetworks, have emerged as promising alternatives to traditional unsupervised\nmethods. With extensive training, these approaches have the potential to\novercome the challenges posed by diverse real-life acoustic environments. In\nthis light, this paper introduces a novel neural framework that incorporates a\nrobust frontend into ASR systems in both clean and noisy environments.\nUtilizing the Aurora-2 speech database, the authors evaluate the effectiveness\nof an acoustic feature set for Mel-frequency, employing the approach of\ntransfer learning based on Residual neural network (ResNet). The experimental\nresults demonstrate a significant improvement in recognition accuracy compared\nto convolutional neural networks (CNN) and long short-term memory (LSTM)\nnetworks. They achieved accuracies of 98.94% in clean and 91.21% in noisy mode.", "published": "2025-05-02 23:42:27", "link": "http://arxiv.org/abs/2505.01632v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Embracing Diffraction: A Paradigm Shift in Wireless Sensing and Communication", "abstract": "Wireless signals are integral to modern society, enabling both communication\nand increasingly, environmental sensing. While various propagation models\nexist, ranging from empirical methods to full-wave simulations, the phenomenon\nof electromagnetic diffraction is often treated as a secondary effect or a\ncorrection factor. This paper positions diffraction as a fundamentally\nimportant and underutilized mechanism that is rich with information about the\nphysical environment. Specifically, diffraction-inducing elements generate\ndistinct signatures that are rich with information about their underlying\nproperties such as their geometries. We then argue that by understanding and\nexploiting these relationships, diffraction can be harnessed strategically. We\nintroduce a general optimization framework to formalize this concept,\nillustrating how diffraction can be leveraged for both inverse problems\n(sensing scene details such as object geometries from measured fields) and\nforward problems (shaping RF fields for communication objectives by configuring\ndiffracting elements). Focusing primarily on edge diffraction and Keller's\nGeometrical Theory of Diffraction (GTD), we discuss specific applications in RF\nsensing for scene understanding and in communications for RF field programming,\ndrawing upon recent work. Overall, this paper lays out a vision for\nsystematically incorporating diffraction into the design and operation of\nfuture wireless systems, paving the way for enhanced sensing capabilities and\nmore robust communication strategies.", "published": "2025-05-02 23:11:53", "link": "http://arxiv.org/abs/2505.01625v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Memory-less and Backscatter-less Tunnel Diode Harmonic Signatures for RFID", "abstract": "Tunnel diodes have traditionally been researched for extending backscatter\nread-ranges for ultra-high-frequency (UHF) radio-frequency identification\n(RFID) tags as reflection amplifiers. This paper explores the natural harmonics\nthat arise from biasing these diodes within their negative differential\nresistance regions and with no interrogating signal from a transmitting source,\nsuch as an RFID reader, to injection-lock these diodes. These harmonics are\ncharacterized for five tunnel diode boards, made with the same components and\nwith each board's fundamental frequencies measuring at above -15 dBm at a\nbiasing voltage of 200 mV when measured over-the-cable. The occurrence of these\nharmonics creates unique harmonic signatures for each board and demonstrates\npossible harmonic RFID applications that can help RFID readers discover and\neven identify RFID tags with backscatter-less and memory-less IDs generated by\ntunnel diodes.", "published": "2025-05-02 20:27:41", "link": "http://arxiv.org/abs/2505.01570v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Ranging of a Moving Ship Using a Single Acoustic Receiver in Shallow Water", "abstract": "Passive acoustics is a versatile tool for maritime situational awareness,\nenabling applications such as source detection and localization, marine mammal\ntracking, and geoacoustic inversion. This study focuses on estimating the range\nbetween an acoustic receiver and a transiting ship in an acoustically\nrange-independent shallow water environment. Here, acoustic propagation can be\nmodeled by a set of normal modes that are determined by the shallow water\nwaveguide and seabed characteristics. These modes are dispersive, with phase\nand group velocities varying with frequency, and their interference produces\nstriation patterns that depend on range and frequency in single-hydrophone\nspectrograms. These patterns can often be characterized by the waveguide\ninvariant, a single parameter describing the waveguide's properties. This paper\npresents a statistical waveguide invariant-based range estimation approach\nusing a single hydrophone, leveraging broadband and tonal sounds from a\ntransiting ship. Using data from the Seabed Characterization Experiment 2017\n(SBCEX17), a large commercial ship's radiated acoustic signature within a 7 Hz\nbandwidth was processed to estimate its range up to 45 km with errors below\nthree percent.", "published": "2025-05-02 20:03:04", "link": "http://arxiv.org/abs/2505.01562v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Llama-Nemotron: Efficient Reasoning Models", "abstract": "We introduce the Llama-Nemotron series of models, an open family of\nheterogeneous reasoning models that deliver exceptional reasoning capabilities,\ninference efficiency, and an open license for enterprise use. The family comes\nin three sizes -- Nano (8B), Super (49B), and Ultra (253B) -- and performs\ncompetitively with state-of-the-art reasoning models such as DeepSeek-R1 while\noffering superior inference throughput and memory efficiency. In this report,\nwe discuss the training procedure for these models, which entails using neural\narchitecture search from Llama 3 models for accelerated inference, knowledge\ndistillation, and continued pretraining, followed by a reasoning-focused\npost-training stage consisting of two main parts: supervised fine-tuning and\nlarge scale reinforcement learning. Llama-Nemotron models are the first\nopen-source models to support a dynamic reasoning toggle, allowing users to\nswitch between standard chat and reasoning modes during inference. To further\nsupport open research and facilitate model development, we provide the\nfollowing resources: 1. We release the Llama-Nemotron reasoning models --\nLN-Nano, LN-Super, and LN-Ultra -- under the commercially permissive NVIDIA\nOpen Model License Agreement. 2. We release the complete post-training dataset:\nLlama-Nemotron-Post-Training-Dataset. 3. We also release our training\ncodebases: NeMo, NeMo-Aligner, and Megatron-LM.", "published": "2025-05-02 01:35:35", "link": "http://arxiv.org/abs/2505.00949v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Redundancy analysis using lcm-filtrations: networks, system signature and sensitivity evaluation", "abstract": "We introduce the lcm-filtration and stepwise filtration, comparing their\nperformance across various scenarios in terms of computational complexity,\nefficiency, and redundancy. The lcm-filtration often involves identical steps\nor ideals, leading to unnecessary computations. To address this, we analyse how\nstepwise filtration can effectively compute only the non-identical steps,\noffering a more efficient approach. We compare these filtrations in\napplications to networks, system signatures, and sensitivity analysis.", "published": "2025-05-02 17:49:15", "link": "http://arxiv.org/abs/2505.01416v2", "categories": ["cs.DM", "cs.SC", "math.AC"], "primary_category": "cs.DM"}
{"title": "SemSpaceFL: A Collaborative Hierarchical Federated Learning Framework for Semantic Communication in 6G LEO Satellites", "abstract": "The advent of the sixth-generation (6G) wireless networks, enhanced by\nartificial intelligence, promises ubiquitous connectivity through Low Earth\nOrbit (LEO) satellites. These satellites are capable of collecting vast amounts\nof geographically diverse and real-time data, which can be immensely valuable\nfor training intelligent models. However, limited inter-satellite communication\nand data privacy constraints hinder data collection on a single server for\ntraining. Therefore, we propose SemSpaceFL, a novel hierarchical federated\nlearning (HFL) framework for LEO satellite networks, with integrated semantic\ncommunication capabilities. Our framework introduces a two-tier aggregation\narchitecture where satellite models are first aggregated at regional gateways\nbefore final consolidation at a cloud server, which explicitly accounts for\nsatellite mobility patterns and energy constraints. The key innovation lies in\nour novel aggregation approach, which dynamically adjusts the contribution of\neach satellite based on its trajectory and association with different gateways,\nwhich ensures stable model convergence despite the highly dynamic nature of LEO\nconstellations. To further enhance communication efficiency, we incorporate\nsemantic encoding-decoding techniques trained through the proposed HFL\nframework, which enables intelligent data compression while maintaining signal\nintegrity. Our experimental results demonstrate that the proposed aggregation\nstrategy achieves superior performance and faster convergence compared to\nexisting benchmarks, while effectively managing the challenges of satellite\nmobility and energy limitations in dynamic LEO networks.", "published": "2025-05-02 03:01:12", "link": "http://arxiv.org/abs/2505.00966v2", "categories": ["cs.IT", "cs.DC", "cs.ET", "cs.NI", "math.IT"], "primary_category": "cs.IT"}
{"title": "Asset Pricing in Pre-trained Transformer", "abstract": "This paper proposes an innovative Transformer model, Single-directional\nrepresentative from Transformer (SERT), for US large capital stock pricing. It\nalso innovatively applies the pre-trained Transformer models under the stock\npricing and factor investment context. They are compared with standard\nTransformer models and encoder-only Transformer models in three periods\ncovering the entire COVID-19 pandemic to examine the model adaptivity and\nsuitability during the extreme market fluctuations. Namely, pre-COVID-19 period\n(mild up-trend), COVID-19 period (sharp up-trend with deep down shock) and\n1-year post-COVID-19 (high fluctuation sideways movement). The best proposed\nSERT model achieves the highest out-of-sample R2, 11.2% and 10.91%\nrespectively, when extreme market fluctuation takes place followed by\npre-trained Transformer models (10.38% and 9.15%). Their Trend-following-based\nstrategy wise performance also proves their excellent capability for hedging\ndownside risks during market shocks. The proposed SERT model achieves a Sortino\nratio 47% higher than the buy-and-hold benchmark in the equal-weighted\nportfolio and 28% higher in the value-weighted portfolio when the pandemic\nperiod is attended. It proves that Transformer models have a great capability\nto capture patterns of temporal sparsity data in the asset pricing factor\nmodel, especially with considerable volatilities. We also find the softmax\nsignal filter as the common configuration of Transformer models in alternative\ncontexts, which only eliminates differences between models, but does not\nimprove strategy-wise performance, while increasing attention heads improve the\nmodel performance insignificantly and applying the 'layer norm first' method do\nnot boost the model performance in our case.", "published": "2025-05-02 20:38:59", "link": "http://arxiv.org/abs/2505.01575v2", "categories": ["q-fin.CP", "econ.EM", "q-fin.PR", "91B28, 68T07", "J.1; I.2.6; I.5.1"], "primary_category": "q-fin.CP"}
{"title": "How Transformers Learn Regular Language Recognition: A Theoretical Study on Training Dynamics and Implicit Bias", "abstract": "Language recognition tasks are fundamental in natural language processing\n(NLP) and have been widely used to benchmark the performance of large language\nmodels (LLMs). These tasks also play a crucial role in explaining the working\nmechanisms of transformers. In this work, we focus on two representative tasks\nin the category of regular language recognition, known as `even pairs' and\n`parity check', the aim of which is to determine whether the occurrences of\ncertain subsequences in a given sequence are even. Our goal is to explore how a\none-layer transformer, consisting of an attention layer followed by a linear\nlayer, learns to solve these tasks by theoretically analyzing its training\ndynamics under gradient descent. While even pairs can be solved directly by a\none-layer transformer, parity check need to be solved by integrating\nChain-of-Thought (CoT), either into the inference stage of a transformer\nwell-trained for the even pairs task, or into the training of a one-layer\ntransformer. For both problems, our analysis shows that the joint training of\nattention and linear layers exhibits two distinct phases. In the first phase,\nthe attention layer grows rapidly, mapping data sequences into separable\nvectors. In the second phase, the attention layer becomes stable, while the\nlinear layer grows logarithmically and approaches in direction to a max-margin\nhyperplane that correctly separates the attention layer outputs into positive\nand negative samples, and the loss decreases at a rate of $O(1/t)$. Our\nexperiments validate those theoretical results.", "published": "2025-05-02 00:07:35", "link": "http://arxiv.org/abs/2505.00926v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Satellite Autonomous Clock Fault Monitoring with Inter-Satellite Ranges Using Euclidean Distance Matrices", "abstract": "To address the need for robust positioning, navigation, and timing services\nin lunar environments, this paper proposes a novel onboard clock phase jump\ndetection framework for satellite constellations using range measurements\nobtained from dual one-way inter-satellite links. Our approach leverages vertex\nredundantly rigid graphs to detect faults without relying on prior knowledge of\nsatellite positions or clock biases, providing flexibility for lunar satellite\nnetworks with diverse satellite types and operators. We model satellite\nconstellations as graphs, where satellites are vertices and inter-satellite\nlinks are edges. The proposed algorithm detects and identifies satellites with\nclock jumps by monitoring the singular values of the geometric-centered\nEuclidean distance matrix (GCEDM) of 5-clique sub-graphs. The proposed method\nis validated through simulations of a GPS constellation and a notional\nconstellation around the Moon, demonstrating its effectiveness in various\nconfigurations.", "published": "2025-05-02 22:47:43", "link": "http://arxiv.org/abs/2505.03820v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Facilitating Video Story Interaction with Multi-Agent Collaborative System", "abstract": "Video story interaction enables viewers to engage with and explore narrative\ncontent for personalized experiences. However, existing methods are limited to\nuser selection, specially designed narratives, and lack customization. To\naddress this, we propose an interactive system based on user intent. Our system\nuses a Vision Language Model (VLM) to enable machines to understand video\nstories, combining Retrieval-Augmented Generation (RAG) and a Multi-Agent\nSystem (MAS) to create evolving characters and scene experiences. It includes\nthree stages: 1) Video story processing, utilizing VLM and prior knowledge to\nsimulate human understanding of stories across three modalities. 2) Multi-space\nchat, creating growth-oriented characters through MAS interactions based on\nuser queries and story stages. 3) Scene customization, expanding and\nvisualizing various story scenes mentioned in dialogue. Applied to the Harry\nPotter series, our study shows the system effectively portrays emergent\ncharacter social behavior and growth, enhancing the interactive experience in\nthe video story world.", "published": "2025-05-02 09:08:13", "link": "http://arxiv.org/abs/2505.03807v1", "categories": ["cs.HC", "cs.AI", "cs.CV", "cs.MA"], "primary_category": "cs.HC"}
{"title": "Cer-Eval: Certifiable and Cost-Efficient Evaluation Framework for LLMs", "abstract": "As foundation models continue to scale, the size of trained models grows\nexponentially, presenting significant challenges for their evaluation. Current\nevaluation practices involve curating increasingly large datasets to assess the\nperformance of large language models (LLMs). However, there is a lack of\nsystematic analysis and guidance on determining the sufficiency of test data or\nselecting informative samples for evaluation. This paper introduces a\ncertifiable and cost-efficient evaluation framework for LLMs. Our framework\nadapts to different evaluation objectives and outputs confidence intervals that\ncontain true values with high probability. We use ``test sample complexity'' to\nquantify the number of test points needed for a certifiable evaluation and\nderive tight bounds on test sample complexity. Based on the developed theory,\nwe develop a partition-based algorithm, named Cer-Eval, that adaptively selects\ntest points to minimize the cost of LLM evaluation. Real-world experiments\ndemonstrate that Cer-Eval can save 20% to 40% test points across various\nbenchmarks, while maintaining an estimation error level comparable to the\ncurrent evaluation process and providing a 95% confidence guarantee.", "published": "2025-05-02 17:05:01", "link": "http://arxiv.org/abs/2505.03814v1", "categories": ["stat.ML", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Exploring exponential time integration for strongly magnetized charged particle motion", "abstract": "A fundamental task in particle-in-cell (PIC) simulations of plasma physics is\nsolving for charged particle motion in electromagnetic fields. This problem is\nespecially challenging when the plasma is strongly magnetized due to numerical\nstiffness arising from the wide separation in time scales between highly\noscillatory gyromotion and overall macroscopic behavior of the system. In\ncontrast to conventional finite difference schemes, we investigated exponential\nintegration techniques to numerically simulate strongly magnetized charged\nparticle motion. Numerical experiments with a uniform magnetic field show that\nexponential integrators yield superior performance for linear problems (i.e.\nconfigurations with an electric field given by a quadratic electric scalar\npotential) and are competitive with conventional methods for nonlinear problems\nwith cubic and quartic electric scalar potentials.", "published": "2025-05-02 18:21:52", "link": "http://arxiv.org/abs/2505.01525v2", "categories": ["physics.comp-ph", "cs.NA", "math.NA", "physics.plasm-ph", "65L04, 78A35"], "primary_category": "physics.comp-ph"}
