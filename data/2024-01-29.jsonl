{"title": "Emergent Explainability: Adding a causal chain to neural network\n  inference", "abstract": "This position paper presents a theoretical framework for enhancing\nexplainable artificial intelligence (xAI) through emergent communication\n(EmCom), focusing on creating a causal understanding of AI model outputs. We\nexplore the novel integration of EmCom into AI systems, offering a paradigm\nshift from conventional associative relationships between inputs and outputs to\na more nuanced, causal interpretation. The framework aims to revolutionize how\nAI processes are understood, making them more transparent and interpretable.\nWhile the initial application of this model is demonstrated on synthetic data,\nthe implications of this research extend beyond these simple applications. This\ngeneral approach has the potential to redefine interactions with AI across\nmultiple domains, fostering trust and informed decision-making in healthcare\nand in various sectors where AI's decision-making processes are critical. The\npaper discusses the theoretical underpinnings of this approach, its potential\nbroad applications, and its alignment with the growing need for responsible and\ntransparent AI systems in an increasingly digital world.", "published": "2024-01-29 02:28:39", "link": "http://arxiv.org/abs/2401.15840v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LSTM-based Deep Neural Network With A Focus on Sentence Representation\n  for Sequential Sentence Classification in Medical Scientific Abstracts", "abstract": "The Sequential Sentence Classification task within the domain of medical\nabstracts, termed as SSC, involves the categorization of sentences into\npre-defined headings based on their roles in conveying critical information in\nthe abstract. In the SSC task, sentences are sequentially related to each\nother. For this reason, the role of sentence embeddings is crucial for\ncapturing both the semantic information between words in the sentence and the\ncontextual relationship of sentences within the abstract, which then enhances\nthe SSC system performance. In this paper, we propose a LSTM-based deep\nlearning network with a focus on creating comprehensive sentence representation\nat the sentence level. To demonstrate the efficacy of the created sentence\nrepresentation, a system utilizing these sentence embeddings is also developed,\nwhich consists of a Convolutional-Recurrent neural network (C-RNN) at the\nabstract level and a multi-layer perception network (MLP) at the segment level.\nOur proposed system yields highly competitive results compared to\nstate-of-the-art systems and further enhances the F1 scores of the baseline by\n1.0%, 2.8%, and 2.6% on the benchmark datasets PudMed 200K RCT, PudMed 20K RCT\nand NICTA-PIBOSO, respectively. This indicates the significant impact of\nimproving sentence representation on boosting model performance.", "published": "2024-01-29 03:05:35", "link": "http://arxiv.org/abs/2401.15854v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Corrective Retrieval Augmented Generation", "abstract": "Large language models (LLMs) inevitably exhibit hallucinations since the\naccuracy of generated texts cannot be secured solely by the parametric\nknowledge they encapsulate. Although retrieval-augmented generation (RAG) is a\npracticable complement to LLMs, it relies heavily on the relevance of retrieved\ndocuments, raising concerns about how the model behaves if retrieval goes\nwrong. To this end, we propose the Corrective Retrieval Augmented Generation\n(CRAG) to improve the robustness of generation. Specifically, a lightweight\nretrieval evaluator is designed to assess the overall quality of retrieved\ndocuments for a query, returning a confidence degree based on which different\nknowledge retrieval actions can be triggered. Since retrieval from static and\nlimited corpora can only return sub-optimal documents, large-scale web searches\nare utilized as an extension for augmenting the retrieval results. Besides, a\ndecompose-then-recompose algorithm is designed for retrieved documents to\nselectively focus on key information and filter out irrelevant information in\nthem. CRAG is plug-and-play and can be seamlessly coupled with various\nRAG-based approaches. Experiments on four datasets covering short- and\nlong-form generation tasks show that CRAG can significantly improve the\nperformance of RAG-based approaches.", "published": "2024-01-29 04:36:39", "link": "http://arxiv.org/abs/2401.15884v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "E-EVAL: A Comprehensive Chinese K-12 Education Evaluation Benchmark for\n  Large Language Models", "abstract": "With the accelerating development of Large Language Models (LLMs), many LLMs\nare beginning to be used in the Chinese K-12 education domain. The integration\nof LLMs and education is getting closer and closer, however, there is currently\nno benchmark for evaluating LLMs that focuses on the Chinese K-12 education\ndomain. Therefore, there is an urgent need for a comprehensive natural language\nprocessing benchmark to accurately assess the capabilities of various LLMs in\nthe Chinese K-12 education domain. To address this, we introduce the E-EVAL,\nthe first comprehensive evaluation benchmark specifically designed for the\nChinese K-12 education field. The E-EVAL consists of 4,351 multiple-choice\nquestions at the primary, middle, and high school levels across a wide range of\nsubjects, including Chinese, English, Politics, History, Ethics, Physics,\nChemistry, Mathematics, and Geography. We conducted a comprehensive evaluation\nof E-EVAL on advanced LLMs, including both English-dominant and\nChinese-dominant models. Findings show that Chinese-dominant models perform\nwell compared to English-dominant models, with many scoring even above the GPT\n4.0. However, almost all models perform poorly in complex subjects such as\nmathematics. We also found that most Chinese-dominant LLMs did not achieve\nhigher scores at the primary school level compared to the middle school level.\nWe observe that the mastery of higher-order knowledge by the model does not\nnecessarily imply the mastery of lower-order knowledge as well. Additionally,\nthe experimental results indicate that the Chain of Thought (CoT) technique is\neffective only for the challenging science subjects, while Few-shot prompting\nis more beneficial for liberal arts subjects. With E-EVAL, we aim to analyze\nthe strengths and limitations of LLMs in educational applications, and to\ncontribute to the progress and development of Chinese K-12 education and LLMs.", "published": "2024-01-29 07:34:37", "link": "http://arxiv.org/abs/2401.15927v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Finding Challenging Metaphors that Confuse Pretrained Language Models", "abstract": "Metaphors are considered to pose challenges for a wide spectrum of NLP tasks.\nThis gives rise to the area of computational metaphor processing. However, it\nremains unclear what types of metaphors challenge current state-of-the-art\nmodels. In this paper, we test various NLP models on the VUA metaphor dataset\nand quantify to what extent metaphors affect models' performance on various\ndownstream tasks. Analysis reveals that VUA includes a large number of\nmetaphors that pose little difficulty to downstream tasks. We would like to\nshift the attention of researchers away from these metaphors to instead focus\non challenging metaphors. To identify hard metaphors, we propose an automatic\npipeline that identifies metaphors that challenge a particular model. Our\nanalysis demonstrates that our detected hard metaphors contrast significantly\nwith VUA and reduce the accuracy of machine translation by 16\\%, QA performance\nby 4\\%, NLI by 7\\%, and metaphor identification recall by over 14\\% for various\npopular NLP systems.", "published": "2024-01-29 10:00:54", "link": "http://arxiv.org/abs/2401.16012v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Stolen Subwords: Importance of Vocabularies for Machine Translation\n  Model Stealing", "abstract": "In learning-based functionality stealing, the attacker is trying to build a\nlocal model based on the victim's outputs. The attacker has to make choices\nregarding the local model's architecture, optimization method and, specifically\nfor NLP models, subword vocabulary, such as BPE. On the machine translation\ntask, we explore (1) whether the choice of the vocabulary plays a role in model\nstealing scenarios and (2) if it is possible to extract the victim's\nvocabulary. We find that the vocabulary itself does not have a large effect on\nthe local model's performance. Given gray-box model access, it is possible to\ncollect the victim's vocabulary by collecting the outputs (detokenized subwords\non the output). The results of the minimum effect of vocabulary choice are\nimportant more broadly for black-box knowledge distillation.", "published": "2024-01-29 11:04:01", "link": "http://arxiv.org/abs/2401.16055v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Understanding the effects of word-level linguistic annotations in\n  under-resourced neural machine translation", "abstract": "This paper studies the effects of word-level linguistic annotations in\nunder-resourced neural machine translation, for which there is incomplete\nevidence in the literature. The study covers eight language pairs, different\ntraining corpus sizes, two architectures, and three types of annotation: dummy\ntags (with no linguistic information at all), part-of-speech tags, and\nmorpho-syntactic description tags, which consist of part of speech and\nmorphological features. These linguistic annotations are interleaved in the\ninput or output streams as a single tag placed before each word. In order to\nmeasure the performance under each scenario, we use automatic evaluation\nmetrics and perform automatic error classification. Our experiments show that,\nin general, source-language annotations are helpful and morpho-syntactic\ndescriptions outperform part of speech for some language pairs. On the\ncontrary, when words are annotated in the target language, part-of-speech tags\nsystematically outperform morpho-syntactic description tags in terms of\nautomatic evaluation metrics, even though the use of morpho-syntactic\ndescription tags improves the grammaticality of the output. We provide a\ndetailed analysis of the reasons behind this result.", "published": "2024-01-29 11:39:46", "link": "http://arxiv.org/abs/2401.16078v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Non-Fluent Synthetic Target-Language Data Improve Neural Machine\n  Translation", "abstract": "When the amount of parallel sentences available to train a neural machine\ntranslation is scarce, a common practice is to generate new synthetic training\nsamples from them. A number of approaches have been proposed to produce\nsynthetic parallel sentences that are similar to those in the parallel data\navailable. These approaches work under the assumption that non-fluent\ntarget-side synthetic training samples can be harmful and may deteriorate\ntranslation performance. Even so, in this paper we demonstrate that synthetic\ntraining samples with non-fluent target sentences can improve translation\nperformance if they are used in a multilingual machine translation framework as\nif they were sentences in another language. We conducted experiments on ten\nlow-resource and four high-resource translation tasks and found out that this\nsimple approach consistently improves translation performance as compared to\nstate-of-the-art methods for generating synthetic training samples similar to\nthose found in corpora. Furthermore, this improvement is independent of the\nsize of the original training corpus, the resulting systems are much more\nrobust against domain shift and produce less hallucinations.", "published": "2024-01-29 11:52:45", "link": "http://arxiv.org/abs/2401.16086v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Machine Translation Meta Evaluation through Translation Accuracy\n  Challenge Sets", "abstract": "Recent machine translation (MT) metrics calibrate their effectiveness by\ncorrelating with human judgement but without any insights about their behaviour\nacross different error types. Challenge sets are used to probe specific\ndimensions of metric behaviour but there are very few such datasets and they\neither focus on a limited number of phenomena or a limited number of language\npairs. We introduce ACES, a contrastive challenge set spanning 146 language\npairs, aimed at discovering whether metrics can identify 68 translation\naccuracy errors. These phenomena range from simple alterations at the\nword/character level to more complex errors based on discourse and real-world\nknowledge. We conduct a large-scale study by benchmarking ACES on 50 metrics\nsubmitted to the WMT 2022 and 2023 metrics shared tasks. We benchmark metric\nperformance, assess their incremental performance over successive campaigns,\nand measure their sensitivity to a range of linguistic phenomena. We also\ninvestigate claims that Large Language Models (LLMs) are effective as MT\nevaluators by evaluating on ACES. Our results demonstrate that different metric\nfamilies struggle with different phenomena and that LLM-based methods fail to\ndemonstrate reliable performance. Our analyses indicate that most metrics\nignore the source sentence, tend to prefer surface-level overlap and end up\nincorporating properties of base models which are not always beneficial. We\nexpand ACES to include error span annotations, denoted as SPAN-ACES and we use\nthis dataset to evaluate span-based error metrics showing these metrics also\nneed considerable improvement. Finally, we provide a set of recommendations for\nbuilding better MT metrics, including focusing on error labels instead of\nscores, ensembling, designing strategies to explicitly focus on the source\nsentence, focusing on semantic content and choosing the right base model for\nrepresentations.", "published": "2024-01-29 17:17:42", "link": "http://arxiv.org/abs/2401.16313v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rephrasing the Web: A Recipe for Compute and Data-Efficient Language\n  Modeling", "abstract": "Large language models are trained on massive scrapes of the web, which are\noften unstructured, noisy, and poorly phrased. Current scaling laws show that\nlearning from such data requires an abundance of both compute and data, which\ngrows with the size of the model being trained. This is infeasible both because\nof the large compute costs and duration associated with pre-training, and the\nimpending scarcity of high-quality data on the web. In this work, we propose\nWeb Rephrase Augmented Pre-training ($\\textbf{WRAP}$) that uses an\noff-the-shelf instruction-tuned model prompted to paraphrase documents on the\nweb in specific styles such as \"like Wikipedia\" or in \"question-answer format\"\nto jointly pre-train LLMs on real and synthetic rephrases. First, we show that\nusing WRAP on the C4 dataset, which is naturally noisy, speeds up pre-training\nby $\\sim3x$. At the same pre-training compute budget, it improves perplexity by\nmore than 10% on average across different subsets of the Pile, and improves\nzero-shot question answer accuracy across 13 tasks by more than 2%. Second, we\ninvestigate the impact of the re-phrasing style on the performance of the\nmodel, offering insights into how the composition of the training data can\nimpact the performance of LLMs in OOD settings. Our gains are attributed to the\nfact that re-phrased synthetic data has higher utility than just real data\nbecause it (i) incorporates style diversity that closely reflects downstream\nevaluation style, and (ii) has higher 'quality' than web-scraped data.", "published": "2024-01-29 18:19:08", "link": "http://arxiv.org/abs/2401.16380v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ViLexNorm: A Lexical Normalization Corpus for Vietnamese Social Media\n  Text", "abstract": "Lexical normalization, a fundamental task in Natural Language Processing\n(NLP), involves the transformation of words into their canonical forms. This\nprocess has been proven to benefit various downstream NLP tasks greatly. In\nthis work, we introduce Vietnamese Lexical Normalization (ViLexNorm), the\nfirst-ever corpus developed for the Vietnamese lexical normalization task. The\ncorpus comprises over 10,000 pairs of sentences meticulously annotated by human\nannotators, sourced from public comments on Vietnam's most popular social media\nplatforms. Various methods were used to evaluate our corpus, and the\nbest-performing system achieved a result of 57.74% using the Error Reduction\nRate (ERR) metric (van der Goot, 2019a) with the Leave-As-Is (LAI) baseline.\nFor extrinsic evaluation, employing the model trained on ViLexNorm demonstrates\nthe positive impact of the Vietnamese lexical normalization task on other NLP\ntasks. Our corpus is publicly available exclusively for research purposes.", "published": "2024-01-29 18:41:39", "link": "http://arxiv.org/abs/2401.16403v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "InfoLossQA: Characterizing and Recovering Information Loss in Text\n  Simplification", "abstract": "Text simplification aims to make technical texts more accessible to laypeople\nbut often results in deletion of information and vagueness. This work proposes\nInfoLossQA, a framework to characterize and recover simplification-induced\ninformation loss in form of question-and-answer (QA) pairs. Building on the\ntheory of Question Under Discussion, the QA pairs are designed to help readers\ndeepen their knowledge of a text. We conduct a range of experiments with this\nframework. First, we collect a dataset of 1,000 linguist-curated QA pairs\nderived from 104 LLM simplifications of scientific abstracts of medical\nstudies. Our analyses of this data reveal that information loss occurs\nfrequently, and that the QA pairs give a high-level overview of what\ninformation was lost. Second, we devise two methods for this task: end-to-end\nprompting of open-source and commercial language models, and a natural language\ninference pipeline. With a novel evaluation framework considering the\ncorrectness of QA pairs and their linguistic suitability, our expert evaluation\nreveals that models struggle to reliably identify information loss and applying\nsimilar standards as humans at what constitutes information loss.", "published": "2024-01-29 19:00:01", "link": "http://arxiv.org/abs/2401.16475v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Massively Multilingual Text Translation For Low-Resource Languages", "abstract": "Translation into severely low-resource languages has both the cultural goal\nof saving and reviving those languages and the humanitarian goal of assisting\nthe everyday needs of local communities that are accelerated by the recent\nCOVID-19 pandemic. In many humanitarian efforts, translation into severely\nlow-resource languages often does not require a universal translation engine,\nbut a dedicated text-specific translation engine. For example, healthcare\nrecords, hygienic procedures, government communication, emergency procedures\nand religious texts are all limited texts. While generic translation engines\nfor all languages do not exist, translation of multilingually known limited\ntexts into new, low-resource languages may be possible and reduce human\ntranslation effort. We attempt to leverage translation resources from\nrich-resource languages to efficiently produce best possible translation\nquality for well known texts, which are available in multiple languages, in a\nnew, low-resource language. To reach this goal, we argue that in translating a\nclosed text into low-resource languages, generalization to out-of-domain texts\nis not necessary, but generalization to new languages is. Performance gain\ncomes from massive source parallelism by careful choice of close-by language\nfamilies, style-consistent corpus-level paraphrases within the same language\nand strategic adaptation of existing large pretrained multilingual models to\nthe domain first and then to the language. Such performance gain makes it\npossible for machine translation systems to collaborate with human translators\nto expedite the translation process into new, low-resource languages.", "published": "2024-01-29 21:33:08", "link": "http://arxiv.org/abs/2401.16582v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ToPro: Token-Level Prompt Decomposition for Cross-Lingual Sequence\n  Labeling Tasks", "abstract": "Prompt-based methods have been successfully applied to multilingual\npretrained language models for zero-shot cross-lingual understanding. However,\nmost previous studies primarily focused on sentence-level classification tasks,\nand only a few considered token-level labeling tasks such as Named Entity\nRecognition (NER) and Part-of-Speech (POS) tagging. In this paper, we propose\nToken-Level Prompt Decomposition (ToPro), which facilitates the prompt-based\nmethod for token-level sequence labeling tasks. The ToPro method decomposes an\ninput sentence into single tokens and applies one prompt template to each\ntoken. Our experiments on multilingual NER and POS tagging datasets demonstrate\nthat ToPro-based fine-tuning outperforms Vanilla fine-tuning and Prompt-Tuning\nin zero-shot cross-lingual transfer, especially for languages that are\ntypologically different from the source language English. Our method also\nattains state-of-the-art performance when employed with the mT5 model. Besides,\nour exploratory study in multilingual large language models shows that ToPro\nperforms much better than the current in-context learning method. Overall, the\nperformance improvements show that ToPro could potentially serve as a novel and\nsimple benchmarking method for sequence labeling tasks.", "published": "2024-01-29 21:44:27", "link": "http://arxiv.org/abs/2401.16589v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BPDec: Unveiling the Potential of Masked Language Modeling Decoder in\n  BERT pretraining", "abstract": "BERT (Bidirectional Encoder Representations from Transformers) has\nrevolutionized the field of natural language processing through its exceptional\nperformance on numerous tasks. Yet, the majority of researchers have mainly\nconcentrated on enhancements related to the model structure, such as relative\nposition embedding and more efficient attention mechanisms. Others have delved\ninto pretraining tricks associated with Masked Language Modeling, including\nwhole word masking. DeBERTa introduced an enhanced decoder adapted for BERT's\nencoder model for pretraining, proving to be highly effective. We argue that\nthe design and research around enhanced masked language modeling decoders have\nbeen underappreciated. In this paper, we propose several designs of enhanced\ndecoders and introduce BPDec (BERT Pretraining Decoder), a novel method for\nmodeling training. Typically, a pretrained BERT model is fine-tuned for\nspecific Natural Language Understanding (NLU) tasks. In our approach, we\nutilize the original BERT model as the encoder, making only changes to the\ndecoder without altering the encoder. This approach does not necessitate\nextensive modifications to the encoder architecture and can be seamlessly\nintegrated into existing fine-tuning pipelines and services, offering an\nefficient and effective enhancement strategy. Compared to other methods, while\nwe also incur a moderate training cost for the decoder during the pretraining\nprocess, our approach does not introduce additional training costs during the\nfine-tuning phase. We test multiple enhanced decoder structures after\npretraining and evaluate their performance on the GLUE tasks and SQuAD tasks.\nOur results demonstrate that BPDec, having only undergone subtle refinements to\nthe model structure during pretraining, significantly enhances model\nperformance without escalating the finetuning cost, inference time and serving\nbudget.", "published": "2024-01-29 03:25:11", "link": "http://arxiv.org/abs/2401.15861v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Response Generation for Cognitive Behavioral Therapy with Large Language\n  Models: Comparative Study with Socratic Questioning", "abstract": "Dialogue systems controlled by predefined or rule-based scenarios derived\nfrom counseling techniques, such as cognitive behavioral therapy (CBT), play an\nimportant role in mental health apps. Despite the need for responsible\nresponses, it is conceivable that using the newly emerging LLMs to generate\ncontextually relevant utterances will enhance these apps. In this study, we\nconstruct dialogue modules based on a CBT scenario focused on conventional\nSocratic questioning using two kinds of LLMs: a Transformer-based dialogue\nmodel further trained with a social media empathetic counseling dataset,\nprovided by Osaka Prefecture (OsakaED), and GPT-4, a state-of-the art LLM\ncreated by OpenAI. By comparing systems that use LLM-generated responses with\nthose that do not, we investigate the impact of generated responses on\nsubjective evaluations such as mood change, cognitive change, and dialogue\nquality (e.g., empathy). As a result, no notable improvements are observed when\nusing the OsakaED model. When using GPT-4, the amount of mood change, empathy,\nand other dialogue qualities improve significantly. Results suggest that GPT-4\npossesses a high counseling ability. However, they also indicate that even when\nusing a dialogue model trained with a human counseling dataset, it does not\nnecessarily yield better outcomes compared to scenario-based dialogues. While\npresenting LLM-generated responses, including GPT-4, and having them interact\ndirectly with users in real-life mental health care services may raise ethical\nissues, it is still possible for human professionals to produce example\nresponses or response templates using LLMs in advance in systems that use\nrules, scenarios, or example responses.", "published": "2024-01-29 08:53:41", "link": "http://arxiv.org/abs/2401.15966v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Beyond Direct Diagnosis: LLM-based Multi-Specialist Agent Consultation\n  for Automatic Diagnosis", "abstract": "Automatic diagnosis is a significant application of AI in healthcare, where\ndiagnoses are generated based on the symptom description of patients. Previous\nworks have approached this task directly by modeling the relationship between\nthe normalized symptoms and all possible diseases. However, in the clinical\ndiagnostic process, patients are initially consulted by a general practitioner\nand, if necessary, referred to specialists in specific domains for a more\ncomprehensive evaluation. The final diagnosis often emerges from a\ncollaborative consultation among medical specialist groups. Recently, large\nlanguage models have shown impressive capabilities in natural language\nunderstanding. In this study, we adopt tuning-free LLM-based agents as medical\npractitioners and propose the Agent-derived Multi-Specialist Consultation\n(AMSC) framework to model the diagnosis process in the real world by adaptively\nfusing probability distributions of agents over potential diseases.\nExperimental results demonstrate the superiority of our approach compared with\nbaselines. Notably, our approach requires significantly less parameter updating\nand training time, enhancing efficiency and practical utility. Furthermore, we\ndelve into a novel perspective on the role of implicit symptoms within the\ncontext of automatic diagnosis.", "published": "2024-01-29 12:25:30", "link": "http://arxiv.org/abs/2401.16107v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual\n  Perception", "abstract": "Mobile device agent based on Multimodal Large Language Models (MLLM) is\nbecoming a popular application. In this paper, we introduce Mobile-Agent, an\nautonomous multi-modal mobile device agent. Mobile-Agent first leverages visual\nperception tools to accurately identify and locate both the visual and textual\nelements within the app's front-end interface. Based on the perceived vision\ncontext, it then autonomously plans and decomposes the complex operation task,\nand navigates the mobile Apps through operations step by step. Different from\nprevious solutions that rely on XML files of Apps or mobile system metadata,\nMobile-Agent allows for greater adaptability across diverse mobile operating\nenvironments in a vision-centric way, thereby eliminating the necessity for\nsystem-specific customizations. To assess the performance of Mobile-Agent, we\nintroduced Mobile-Eval, a benchmark for evaluating mobile device operations.\nBased on Mobile-Eval, we conducted a comprehensive evaluation of Mobile-Agent.\nThe experimental results indicate that Mobile-Agent achieved remarkable\naccuracy and completion rates. Even with challenging instructions, such as\nmulti-app operations, Mobile-Agent can still complete the requirements. Code\nand model will be open-sourced at https://github.com/X-PLUG/MobileAgent.", "published": "2024-01-29 13:46:37", "link": "http://arxiv.org/abs/2401.16158v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "\"You tell me\": A Dataset of GPT-4-Based Behaviour Change Support\n  Conversations", "abstract": "Conversational agents are increasingly used to address emotional needs on top\nof information needs. One use case of increasing interest are counselling-style\nmental health and behaviour change interventions, with large language model\n(LLM)-based approaches becoming more popular. Research in this context so far\nhas been largely system-focused, foregoing the aspect of user behaviour and the\nimpact this can have on LLM-generated texts. To address this issue, we share a\ndataset containing text-based user interactions related to behaviour change\nwith two GPT-4-based conversational agents collected in a preregistered user\nstudy. This dataset includes conversation data, user language analysis,\nperception measures, and user feedback for LLM-generated turns, and can offer\nvaluable insights to inform the design of such systems based on real\ninteractions.", "published": "2024-01-29 13:54:48", "link": "http://arxiv.org/abs/2401.16167v2", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "LLaMandement: Large Language Models for Summarization of French\n  Legislative Proposals", "abstract": "This report introduces LLaMandement, a state-of-the-art Large Language Model,\nfine-tuned by the French government and designed to enhance the efficiency and\nefficacy of processing parliamentary sessions (including the production of\nbench memoranda and documents required for interministerial meetings) by\ngenerating neutral summaries of legislative proposals. Addressing the\nadministrative challenges of manually processing a growing volume of\nlegislative amendments, LLaMandement stands as a significant legal\ntechnological milestone, providing a solution that exceeds the scalability of\ntraditional human efforts while matching the robustness of a specialized legal\ndrafter. We release all our fine-tuned models and training data to the\ncommunity.", "published": "2024-01-29 14:23:51", "link": "http://arxiv.org/abs/2401.16182v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Vocabulary-Defined Semantics: Latent Space Clustering for Improving\n  In-Context Learning", "abstract": "In-context learning enables language models (LM) to adapt to downstream data\nor tasks by incorporating few samples as demonstrations within the prompts. It\noffers strong performance without the expense of fine-tuning. However, the\nperformance of in-context learning can be unstable depending on the quality,\nformat, or order of demonstrations, which in turn exacerbates the difficulty of\noptimization. Prior work, such as Knn Prompting, index samples based on the\nsimilarities of logits at the output-side, in addition to the regular retrieval\noperation at the input-side. They improve in-context learning by leveraging the\ncore ability of next-token prediction, rather than relying solely on the\nemergent capacity to make analogies. Despite this, the hard-to-optimize issue\nof in-context learning still exists. In our view, it stems from the process of\nselecting demonstrations. To address this, we propose complementing in-context\nlearning with an additional clustering operation. We propose a novel approach\n\"vocabulary-defined semantics\". Grounded in LM vocabulary, which is the label\nspace of model outputs, the proposed approach computes semantically equivalent\nlatent representations for output labels. Then, taking the representations as\ncentroids, a clustering operation is performed to align the semantic properties\nbetween the language model and the downstream data/tasks. Based on extensive\nexperiments across diverse textual understanding datasets and multiple models,\nour approach outperforms the state-of-the-art in terms of effectiveness and\nefficiency. On average, it achieves $3\\%-49\\%$ improvements while requiring\nonly half of the computation time.", "published": "2024-01-29 14:29:48", "link": "http://arxiv.org/abs/2401.16184v6", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MultiMUC: Multilingual Template Filling on MUC-4", "abstract": "We introduce MultiMUC, the first multilingual parallel corpus for template\nfilling, comprising translations of the classic MUC-4 template filling\nbenchmark into five languages: Arabic, Chinese, Farsi, Korean, and Russian. We\nobtain automatic translations from a strong multilingual machine translation\nsystem and manually project the original English annotations into each target\nlanguage. For all languages, we also provide human translations for sentences\nin the dev and test splits that contain annotated template arguments. Finally,\nwe present baselines on MultiMUC both with state-of-the-art template filling\nmodels and with ChatGPT.", "published": "2024-01-29 15:02:24", "link": "http://arxiv.org/abs/2401.16209v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Combining Hierachical VAEs with LLMs for clinically meaningful timeline\n  summarisation in social media", "abstract": "We introduce a hybrid abstractive summarisation approach combining\nhierarchical VAE with LLMs (LlaMA-2) to produce clinically meaningful summaries\nfrom social media user timelines, appropriate for mental health monitoring. The\nsummaries combine two different narrative points of view: clinical insights in\nthird person useful for a clinician are generated by feeding into an LLM\nspecialised clinical prompts, and importantly, a temporally sensitive\nabstractive summary of the user's timeline in first person, generated by a\nnovel hierarchical variational autoencoder, TH-VAE. We assess the generated\nsummaries via automatic evaluation against expert summaries and via human\nevaluation with clinical experts, showing that timeline summarisation by TH-VAE\nresults in more factual and logically coherent summaries rich in clinical\nutility and superior to LLM-only approaches in capturing changes over time.", "published": "2024-01-29 15:42:57", "link": "http://arxiv.org/abs/2401.16240v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Red Teaming in Multimodal and Multilingual Translation", "abstract": "Assessing performance in Natural Language Processing is becoming increasingly\ncomplex. One particular challenge is the potential for evaluation datasets to\noverlap with training data, either directly or indirectly, which can lead to\nskewed results and overestimation of model performance. As a consequence, human\nevaluation is gaining increasing interest as a means to assess the performance\nand reliability of models. One such method is the red teaming approach, which\naims to generate edge cases where a model will produce critical errors. While\nthis methodology is becoming standard practice for generative AI, its\napplication to the realm of conditional AI remains largely unexplored. This\npaper presents the first study on human-based red teaming for Machine\nTranslation (MT), marking a significant step towards understanding and\nimproving the performance of translation models. We delve into both human-based\nred teaming and a study on automation, reporting lessons learned and providing\nrecommendations for both translation models and red teaming drills. This\npioneering work opens up new avenues for research and development in the field\nof MT.", "published": "2024-01-29 15:49:40", "link": "http://arxiv.org/abs/2401.16247v1", "categories": ["cs.CL", "cs.CY", "I.2.7"], "primary_category": "cs.CL"}
{"title": "CO2: Efficient Distributed Training with Full Communication-Computation\n  Overlap", "abstract": "The fundamental success of large language models hinges upon the efficacious\nimplementation of large-scale distributed training techniques. Nevertheless,\nbuilding a vast, high-performance cluster featuring high-speed communication\ninterconnectivity is prohibitively costly, and accessible only to prominent\nentities. In this work, we aim to lower this barrier and democratize\nlarge-scale training with limited bandwidth clusters. We propose a new approach\ncalled CO2 that introduces local-updating and asynchronous communication to the\ndistributed data-parallel training, thereby facilitating the full overlap of\nCOmunication with COmputation. CO2 is able to attain a high scalability even on\nextensive multi-node clusters constrained by very limited communication\nbandwidth. We further propose the staleness gap penalty and outer momentum\nclipping techniques together with CO2 to bolster its convergence and training\nstability. Besides, CO2 exhibits seamless integration with well-established\nZeRO-series optimizers which mitigate memory consumption of model states with\nlarge model training. We also provide a mathematical proof of convergence,\naccompanied by the establishment of a stringent upper bound. Furthermore, we\nvalidate our findings through an extensive set of practical experiments\nencompassing a wide range of tasks in the fields of computer vision and natural\nlanguage processing. These experiments serve to demonstrate the capabilities of\nCO2 in terms of convergence, generalization, and scalability when deployed\nacross configurations comprising up to 128 A100 GPUs. The outcomes emphasize\nthe outstanding capacity of CO2 to hugely improve scalability, no matter on\nclusters with 800Gbps RDMA or 80Gbps TCP/IP inter-node connections.", "published": "2024-01-29 16:12:31", "link": "http://arxiv.org/abs/2401.16265v1", "categories": ["cs.CL", "cs.DC"], "primary_category": "cs.CL"}
{"title": "Capturing Pertinent Symbolic Features for Enhanced Content-Based\n  Misinformation Detection", "abstract": "Preventing the spread of misinformation is challenging. The detection of\nmisleading content presents a significant hurdle due to its extreme linguistic\nand domain variability. Content-based models have managed to identify deceptive\nlanguage by learning representations from textual data such as social media\nposts and web articles. However, aggregating representative samples of this\nheterogeneous phenomenon and implementing effective real-world applications is\nstill elusive. Based on analytical work on the language of misinformation, this\npaper analyzes the linguistic attributes that characterize this phenomenon and\nhow representative of such features some of the most popular misinformation\ndatasets are. We demonstrate that the appropriate use of pertinent symbolic\nknowledge in combination with neural language models is helpful in detecting\nmisleading content. Our results achieve state-of-the-art performance in\nmisinformation datasets across the board, showing that our approach offers a\nvalid and robust alternative to multi-task transfer learning without requiring\nany additional training data. Furthermore, our results show evidence that\nstructured knowledge can provide the extra boost required to address a complex\nand unpredictable real-world problem like misinformation detection, not only in\nterms of accuracy but also time efficiency and resource utilization.", "published": "2024-01-29 16:42:34", "link": "http://arxiv.org/abs/2401.16285v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GAPS: Geometry-Aware Problem Solver", "abstract": "Geometry problem solving presents a formidable challenge within the NLP\ncommunity. Existing approaches often rely on models designed for solving math\nword problems, neglecting the unique characteristics of geometry math problems.\nAdditionally, the current research predominantly focuses on geometry\ncalculation problems, while overlooking other essential aspects like proving.\nIn this study, we address these limitations by proposing the Geometry-Aware\nProblem Solver (GAPS) model. GAPS is specifically designed to generate solution\nprograms for geometry math problems of various types with the help of its\nunique problem-type classifier. To achieve this, GAPS treats the solution\nprogram as a composition of operators and operands, segregating their\ngeneration processes. Furthermore, we introduce the geometry elements\nenhancement method, which enhances the ability of GAPS to recognize geometry\nelements accurately. By leveraging these improvements, GAPS showcases\nremarkable performance in resolving geometry math problems. Our experiments\nconducted on the UniGeo dataset demonstrate the superiority of GAPS over the\nstate-of-the-art model, Geoformer. Specifically, GAPS achieves an accuracy\nimprovement of more than 5.3% for calculation tasks and an impressive 41.1% for\nproving tasks. Notably, GAPS achieves an impressive accuracy of 97.5% on\nproving problems, representing a significant advancement in solving geometry\nproving tasks.", "published": "2024-01-29 16:48:34", "link": "http://arxiv.org/abs/2401.16287v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Tradeoffs Between Alignment and Helpfulness in Language Models with\n  Representation Engineering", "abstract": "Language model alignment has become an important component of AI safety,\nallowing safe interactions between humans and language models, by enhancing\ndesired behaviors and inhibiting undesired ones. It is often done by tuning the\nmodel or inserting preset aligning prompts. Recently, representation\nengineering, a method which alters the model's behavior via changing its\nrepresentations post-training, was shown to be effective in aligning LLMs (Zou\net al., 2023a). Representation engineering yields gains in alignment oriented\ntasks such as resistance to adversarial attacks and reduction of social biases,\nbut was also shown to cause a decrease in the ability of the model to perform\nbasic tasks. In this paper we study the tradeoff between the increase in\nalignment and decrease in helpfulness of the model. We propose a theoretical\nframework which provides bounds for these two quantities, and demonstrate their\nrelevance empirically. First, we find that under the conditions of our\nframework, alignment can be guaranteed with representation engineering, and at\nthe same time that helpfulness is harmed in the process. Second, we show that\nhelpfulness is harmed quadratically with the norm of the representation\nengineering vector, while the alignment increases linearly with it, indicating\na regime in which it is efficient to use representation engineering. We\nvalidate our findings empirically, and chart the boundaries to the usefulness\nof representation engineering for alignment.", "published": "2024-01-29 17:38:14", "link": "http://arxiv.org/abs/2401.16332v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ConFit: Improving Resume-Job Matching using Data Augmentation and\n  Contrastive Learning", "abstract": "A reliable resume-job matching system helps a company find suitable\ncandidates from a pool of resumes, and helps a job seeker find relevant jobs\nfrom a list of job posts. However, since job seekers apply only to a few jobs,\ninteraction records in resume-job datasets are sparse. Different from many\nprior work that use complex modeling techniques, we tackle this sparsity\nproblem using data augmentations and a simple contrastive learning approach.\nConFit first creates an augmented resume-job dataset by paraphrasing specific\nsections in a resume or a job post. Then, ConFit uses contrastive learning to\nfurther increase training samples from $B$ pairs per batch to $O(B^2)$ per\nbatch. We evaluate ConFit on two real-world datasets and find it outperforms\nprior methods (including BM25 and OpenAI text-ada-002) by up to 19% and 31%\nabsolute in nDCG@10 for ranking jobs and ranking resumes, respectively.", "published": "2024-01-29 17:55:18", "link": "http://arxiv.org/abs/2401.16349v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "InternLM-XComposer2: Mastering Free-form Text-Image Composition and\n  Comprehension in Vision-Language Large Model", "abstract": "We introduce InternLM-XComposer2, a cutting-edge vision-language model\nexcelling in free-form text-image composition and comprehension. This model\ngoes beyond conventional vision-language understanding, adeptly crafting\ninterleaved text-image content from diverse inputs like outlines, detailed\ntextual specifications, and reference images, enabling highly customizable\ncontent creation. InternLM-XComposer2 proposes a Partial LoRA (PLoRA) approach\nthat applies additional LoRA parameters exclusively to image tokens to preserve\nthe integrity of pre-trained language knowledge, striking a balance between\nprecise vision understanding and text composition with literary talent.\nExperimental results demonstrate the superiority of InternLM-XComposer2 based\non InternLM2-7B in producing high-quality long-text multi-modal content and its\nexceptional vision-language understanding performance across various\nbenchmarks, where it not only significantly outperforms existing multimodal\nmodels but also matches or even surpasses GPT-4V and Gemini Pro in certain\nassessments. This highlights its remarkable proficiency in the realm of\nmultimodal understanding. The InternLM-XComposer2 model series with 7B\nparameters are publicly available at\nhttps://github.com/InternLM/InternLM-XComposer.", "published": "2024-01-29 18:59:02", "link": "http://arxiv.org/abs/2401.16420v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "GuReT: Distinguishing Guilt and Regret related Text", "abstract": "The intricate relationship between human decision-making and emotions,\nparticularly guilt and regret, has significant implications on behavior and\nwell-being. Yet, these emotions subtle distinctions and interplay are often\noverlooked in computational models. This paper introduces a dataset tailored to\ndissect the relationship between guilt and regret and their unique textual\nmarkers, filling a notable gap in affective computing research. Our approach\ntreats guilt and regret recognition as a binary classification task and employs\nthree machine learning and six transformer-based deep learning techniques to\nbenchmark the newly created dataset. The study further implements innovative\nreasoning methods like chain-of-thought and tree-of-thought to assess the\nmodels interpretive logic. The results indicate a clear performance edge for\ntransformer-based models, achieving a 90.4% macro F1 score compared to the\n85.3% scored by the best machine learning classifier, demonstrating their\nsuperior capability in distinguishing complex emotional states.", "published": "2024-01-29 20:20:44", "link": "http://arxiv.org/abs/2401.16541v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SelectLLM: Can LLMs Select Important Instructions to Annotate?", "abstract": "Instruction tuning benefits from large and diverse datasets; however,\ncreating such datasets involves a high cost of human labeling. While synthetic\ndatasets generated by large language models (LLMs) have partly solved this\nissue, they often contain low-quality data. One effective solution is\nselectively annotating unlabelled instructions, especially given the relative\nease of acquiring unlabeled instructions or texts from various sources.\nHowever, how to select unlabelled instructions is not well-explored, especially\nin the context of LLMs. Therefore, we introduce SelectLLM, an alternative\nframework that leverages the capabilities of LLMs to select unlabeled\ninstructions more effectively. Specifically, SelectLLM consists of two key\nsteps: Coreset-based clustering of unlabelled instructions for enlarging\ndiversity and prompting of LLM to identify the most beneficial instructions\nwithin each cluster. We evaluate SelectLLM on AlpacaEval2 and MT-Bench,\ndemonstrating its ability to outperform state-of-the-art methods like\nAlpagasus. In addition, we compare the performance and compatibility of\nSelectLLM with various LLMs, such as ChatGPT, LLaMA-3.1-70B, and Gemma-2-27b.\nSelectLLM's adaptability and robustness are further evidenced by its ability to\nmaintain high performance across both human and synthetic datasets. All code\nand data are publicly available (https://github.com/minnesotanlp/select-llm).", "published": "2024-01-29 20:44:10", "link": "http://arxiv.org/abs/2401.16553v7", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Diverse, but Divisive: LLMs Can Exaggerate Gender Differences in Opinion\n  Related to Harms of Misinformation", "abstract": "The pervasive spread of misinformation and disinformation poses a significant\nthreat to society. Professional fact-checkers play a key role in addressing\nthis threat, but the vast scale of the problem forces them to prioritize their\nlimited resources. This prioritization may consider a range of factors, such as\nvarying risks of harm posed to specific groups of people. In this work, we\ninvestigate potential implications of using a large language model (LLM) to\nfacilitate such prioritization. Because fact-checking impacts a wide range of\ndiverse segments of society, it is important that diverse views are represented\nin the claim prioritization process. This paper examines whether a LLM can\nreflect the views of various groups when assessing the harms of misinformation,\nfocusing on gender as a primary variable. We pose two central questions: (1) To\nwhat extent do prompts with explicit gender references reflect gender\ndifferences in opinion in the United States on topics of social relevance? and\n(2) To what extent do gender-neutral prompts align with gendered viewpoints on\nthose topics? To analyze these questions, we present the TopicMisinfo dataset,\ncontaining 160 fact-checked claims from diverse topics, supplemented by nearly\n1600 human annotations with subjective perceptions and annotator demographics.\nAnalyzing responses to gender-specific and neutral prompts, we find that GPT\n3.5-Turbo reflects empirically observed gender differences in opinion but\namplifies the extent of these differences. These findings illuminate AI's\ncomplex role in moderating online communication, with implications for\nfact-checkers, algorithm designers, and the use of crowd-workers as annotators.\nWe also release the TopicMisinfo dataset to support continuing research in the\ncommunity.", "published": "2024-01-29 20:50:28", "link": "http://arxiv.org/abs/2401.16558v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Multi-class Regret Detection in Hindi Devanagari Script", "abstract": "The number of Hindi speakers on social media has increased dramatically in\nrecent years. Regret is a common emotional experience in our everyday life.\nMany speakers on social media, share their regretful experiences and opinions\nregularly. It might cause a re-evaluation of one's choices and a desire to make\na different option if given the chance. As a result, knowing the source of\nregret is critical for investigating its impact on behavior and\ndecision-making. This study focuses on regret and how it is expressed,\nspecifically in Hindi, on various social media platforms. In our study, we\npresent a novel dataset from three different sources, where each sentence has\nbeen manually classified into one of three classes \"Regret by action\", \"Regret\nby inaction\", and \"No regret\". Next, we use this dataset to investigate the\nlinguistic expressions of regret in Hindi text and also identify the textual\ndomains that are most frequently associated with regret. Our findings indicate\nthat individuals on social media platforms frequently express regret for both\npast inactions and actions, particularly within the domain of interpersonal\nrelationships. We use a pre-trained BERT model to generate word embeddings for\nthe Hindi dataset and also compare deep learning models with conventional\nmachine learning models in order to demonstrate accuracy. Our results show that\nBERT embedding with CNN consistently surpassed other models. This described the\neffectiveness of BERT for conveying the context and meaning of words in the\nregret domain.", "published": "2024-01-29 20:58:43", "link": "http://arxiv.org/abs/2401.16561v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Beyond Image-Text Matching: Verb Understanding in Multimodal\n  Transformers Using Guided Masking", "abstract": "The dominant probing approaches rely on the zero-shot performance of\nimage-text matching tasks to gain a finer-grained understanding of the\nrepresentations learned by recent multimodal image-language transformer models.\nThe evaluation is carried out on carefully curated datasets focusing on\ncounting, relations, attributes, and others. This work introduces an\nalternative probing strategy called guided masking. The proposed approach\nablates different modalities using masking and assesses the model's ability to\npredict the masked word with high accuracy. We focus on studying multimodal\nmodels that consider regions of interest (ROI) features obtained by object\ndetectors as input tokens. We probe the understanding of verbs using guided\nmasking on ViLBERT, LXMERT, UNITER, and VisualBERT and show that these models\ncan predict the correct verb with high accuracy. This contrasts with previous\nconclusions drawn from image-text matching probing techniques that frequently\nfail in situations requiring verb understanding. The code for all experiments\nwill be publicly available https://github.com/ivana-13/guided_masking.", "published": "2024-01-29 21:22:23", "link": "http://arxiv.org/abs/2401.16575v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "LLMs as On-demand Customizable Service", "abstract": "Large Language Models (LLMs) have demonstrated remarkable language\nunderstanding and generation capabilities. However, training, deploying, and\naccessing these models pose notable challenges, including resource-intensive\ndemands, extended training durations, and scalability issues. To address these\nissues, we introduce a concept of hierarchical, distributed LLM architecture\nthat aims at enhancing the accessibility and deployability of LLMs across\nheterogeneous computing platforms, including general-purpose computers (e.g.,\nlaptops) and IoT-style devices (e.g., embedded systems). By introducing a\n\"layered\" approach, the proposed architecture enables on-demand accessibility\nto LLMs as a customizable service. This approach also ensures optimal\ntrade-offs between the available computational resources and the user's\napplication needs. We envision that the concept of hierarchical LLM will\nempower extensive, crowd-sourced user bases to harness the capabilities of\nLLMs, thereby fostering advancements in AI technology in general.", "published": "2024-01-29 21:24:10", "link": "http://arxiv.org/abs/2401.16577v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Leveraging Professional Radiologists' Expertise to Enhance LLMs'\n  Evaluation for Radiology Reports", "abstract": "In radiology, Artificial Intelligence (AI) has significantly advanced report\ngeneration, but automatic evaluation of these AI-produced reports remains\nchallenging. Current metrics, such as Conventional Natural Language Generation\n(NLG) and Clinical Efficacy (CE), often fall short in capturing the semantic\nintricacies of clinical contexts or overemphasize clinical details, undermining\nreport clarity. To overcome these issues, our proposed method synergizes the\nexpertise of professional radiologists with Large Language Models (LLMs), like\nGPT-3.5 and GPT-4 1. Utilizing In-Context Instruction Learning (ICIL) and Chain\nof Thought (CoT) reasoning, our approach aligns LLM evaluations with\nradiologist standards, enabling detailed comparisons between human and AI\ngenerated reports. This is further enhanced by a Regression model that\naggregates sentence evaluation scores. Experimental results show that our\n\"Detailed GPT-4 (5-shot)\" model achieves a 0.48 score, outperforming the METEOR\nmetric by 0.19, while our \"Regressed GPT-4\" model shows even greater alignment\nwith expert evaluations, exceeding the best existing metric by a 0.35 margin.\nMoreover, the robustness of our explanations has been validated through a\nthorough iterative strategy. We plan to publicly release annotations from\nradiology experts, setting a new standard for accuracy in future assessments.\nThis underscores the potential of our approach in enhancing the quality\nassessment of AI-driven medical reports.", "published": "2024-01-29 21:24:43", "link": "http://arxiv.org/abs/2401.16578v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Development and Testing of Retrieval Augmented Generation in Large\n  Language Models -- A Case Study Report", "abstract": "Purpose: Large Language Models (LLMs) hold significant promise for medical\napplications. Retrieval Augmented Generation (RAG) emerges as a promising\napproach for customizing domain knowledge in LLMs. This case study presents the\ndevelopment and evaluation of an LLM-RAG pipeline tailored for healthcare,\nfocusing specifically on preoperative medicine.\n  Methods: We developed an LLM-RAG model using 35 preoperative guidelines and\ntested it against human-generated responses, with a total of 1260 responses\nevaluated. The RAG process involved converting clinical documents into text\nusing Python-based frameworks like LangChain and Llamaindex, and processing\nthese texts into chunks for embedding and retrieval. Vector storage techniques\nand selected embedding models to optimize data retrieval, using Pinecone for\nvector storage with a dimensionality of 1536 and cosine similarity for loss\nmetrics. Human-generated answers, provided by junior doctors, were used as a\ncomparison.\n  Results: The LLM-RAG model generated answers within an average of 15-20\nseconds, significantly faster than the 10 minutes typically required by humans.\nAmong the basic LLMs, GPT4.0 exhibited the best accuracy of 80.1%. This\naccuracy was further increased to 91.4% when the model was enhanced with RAG.\nCompared to the human-generated instructions, which had an accuracy of 86.3%,\nthe performance of the GPT4.0 RAG model demonstrated non-inferiority (p=0.610).\n  Conclusions: In this case study, we demonstrated a LLM-RAG model for\nhealthcare implementation. The pipeline shows the advantages of grounded\nknowledge, upgradability, and scalability as important aspects of healthcare\nLLM deployment.", "published": "2024-01-29 06:49:53", "link": "http://arxiv.org/abs/2402.01733v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SADAS: A Dialogue Assistant System Towards Remediating Norm Violations\n  in Bilingual Socio-Cultural Conversations", "abstract": "In today's globalized world, bridging the cultural divide is more critical\nthan ever for forging meaningful connections. The Socially-Aware Dialogue\nAssistant System (SADAS) is our answer to this global challenge, and it's\ndesigned to ensure that conversations between individuals from diverse cultural\nbackgrounds unfold with respect and understanding. Our system's novel\narchitecture includes: (1) identifying the categories of norms present in the\ndialogue, (2) detecting potential norm violations, (3) evaluating the severity\nof these violations, (4) implementing targeted remedies to rectify the\nbreaches, and (5) articulates the rationale behind these corrective actions. We\nemploy a series of State-Of-The-Art (SOTA) techniques to build different\nmodules, and conduct numerous experiments to select the most suitable backbone\nmodel for each of the modules. We also design a human preference experiment to\nvalidate the overall performance of the system. We will open-source our system\n(including source code, tools and applications), hoping to advance future\nresearch. A demo video of our system can be found\nat:~\\url{https://youtu.be/JqetWkfsejk}. We have released our code and software\nat:~\\url{https://github.com/AnonymousEACLDemo/SADAS}.", "published": "2024-01-29 08:54:21", "link": "http://arxiv.org/abs/2402.01736v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Assistive Large Language Model Agents for Socially-Aware Negotiation\n  Dialogues", "abstract": "We develop assistive agents based on Large Language Models (LLMs) that aid\ninterlocutors in business negotiations. Specifically, we simulate business\nnegotiations by letting two LLM-based agents engage in role play. A third LLM\nacts as a remediator agent to rewrite utterances violating norms for improving\nnegotiation outcomes. We introduce a simple tuning-free and label-free\nIn-Context Learning (ICL) method to identify high-quality ICL exemplars for the\nremediator, where we propose a novel select criteria, called value impact, to\nmeasure the quality of the negotiation outcomes. We provide rich empirical\nevidence to demonstrate its effectiveness in negotiations across three\ndifferent negotiation topics. We have released our source code and the\ngenerated dataset at: https://github.com/tk1363704/SADAS.", "published": "2024-01-29 09:07:40", "link": "http://arxiv.org/abs/2402.01737v3", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "C4Q: A Chatbot for Quantum", "abstract": "Quantum computing is a growing field that promises many real-world\napplications such as quantum cryptography or quantum finance. The number of\npeople able to use quantum computing is however still very small. This\nlimitation comes from the difficulty to understand the concepts and to know how\nto start coding. Therefore, there is a need for tools that can assist\nnon-expert in overcoming this complexity. One possibility would be to use\nexisting conversational agents. Unfortunately ChatGPT and other Large-Language\nModels produce inaccurate results. This article presents C4Q, a chatbot that\nanswers accurately basic questions and guides users when trying to code quantum\nprograms. Contrary to other approaches C4Q uses a pre-trained large language\nmodel only to discover and classify user requests. It then generates an\naccurate answer using an own engine. Thanks to this architectural design, C4Q's\nanswers are always correct, and thus C4Q can become a support tool that makes\nquantum computing more available to non-experts.", "published": "2024-01-29 09:44:45", "link": "http://arxiv.org/abs/2402.01738v1", "categories": ["cs.CL", "quant-ph"], "primary_category": "cs.CL"}
{"title": "Reducing Selection Bias in Large Language Models", "abstract": "Large Language Models (LLMs) like gpt-3.5-turbo-0613 and claude-instant-1.2\nare vital in interpreting and executing semantic tasks. Unfortunately, these\nmodels' inherent biases adversely affect their performance Particularly\naffected is object selection from lists; a fundamental operation in digital\nnavigation and decision-making. This research critically examines these biases\nand quantifies the effects on a representative list selection task. To explore\nthese biases, we experiment manipulating temperature, list length, object\nidentity, object type, prompt complexity, and model. We isolated and measured\nthe influence of the biases on selection behavior. Our findings show that bias\nstructure is strongly dependent on the model, with object type modulating the\nmagnitude of the effect. With a strong primacy effect, causing the first\nobjects in a list to be disproportionately represented in outputs. The usage of\nguard rails, a prompt engineering method of ensuring a response structure,\nincreases bias and decreases instruction adherence when to a selection task.\nThe bias is ablated when the guard rail step is separated from the list\nsampling step, lowering the complexity of each individual task. We provide LLM\napplications and theoretically suggest that LLMs experience a form of cognitive\nload that is compensated for with bias.", "published": "2024-01-29 15:43:23", "link": "http://arxiv.org/abs/2402.01740v3", "categories": ["cs.CL", "cs.AI", "I.2.0"], "primary_category": "cs.CL"}
{"title": "Development and Testing of a Novel Large Language Model-Based Clinical\n  Decision Support Systems for Medication Safety in 12 Clinical Specialties", "abstract": "Importance: We introduce a novel Retrieval Augmented Generation (RAG)-Large\nLanguage Model (LLM) framework as a Clinical Decision Support Systems (CDSS) to\nsupport safe medication prescription.\n  Objective: To evaluate the efficacy of LLM-based CDSS in correctly\nidentifying medication errors in different patient case vignettes from diverse\nmedical and surgical sub-disciplines, against a human expert panel derived\nground truth. We compared performance for under 2 different CDSS practical\nhealthcare integration modalities: LLM-based CDSS alone (fully autonomous mode)\nvs junior pharmacist + LLM-based CDSS (co-pilot, assistive mode).\n  Design, Setting, and Participants: Utilizing a RAG model with\nstate-of-the-art medically-related LLMs (GPT-4, Gemini Pro 1.0 and Med-PaLM 2),\nthis study used 61 prescribing error scenarios embedded into 23 complex\nclinical vignettes across 12 different medical and surgical specialties. A\nmultidisciplinary expert panel assessed these cases for Drug-Related Problems\n(DRPs) using the PCNE classification and graded severity / potential for harm\nusing revised NCC MERP medication error index. We compared.\n  Results RAG-LLM performed better compared to LLM alone. When employed in a\nco-pilot mode, accuracy, recall, and F1 scores were optimized, indicating\neffectiveness in identifying moderate to severe DRPs. The accuracy of DRP\ndetection with RAG-LLM improved in several categories but at the expense of\nlower precision.\n  Conclusions This study established that a RAG-LLM based CDSS significantly\nboosts the accuracy of medication error identification when used alongside\njunior pharmacists (co-pilot), with notable improvements in detecting severe\nDRPs. This study also illuminates the comparative performance of current\nstate-of-the-art LLMs in RAG-based CDSS systems.", "published": "2024-01-29 16:03:29", "link": "http://arxiv.org/abs/2402.01741v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Muffin or Chihuahua? Challenging Multimodal Large Language Models with\n  Multipanel VQA", "abstract": "Multipanel images, commonly seen as web screenshots, posters, etc., pervade\nour daily lives. These images, characterized by their composition of multiple\nsubfigures in distinct layouts, effectively convey information to people.\nToward building advanced multimodal AI applications, such as agents that\nunderstand complex scenes and navigate through webpages, the skill of\nmultipanel visual reasoning is essential, and a comprehensive evaluation of\nmodels in this regard is important. Therefore, we introduce Multipanel Visual\nQuestion Answering (MultipanelVQA), a novel benchmark comprising 6,600 triplets\nof questions, answers, and multipanel images that specifically challenge models\nin comprehending multipanel images. Our evaluation shows that questions in the\nMultipanelVQA benchmark pose significant challenges to the state-of-the-art\nMultimodal Large Language Models (MLLMs) tested, even though humans can attain\napproximately 99% accuracy on these questions. Distinctively, the MultipanelVQA\nbenchmark features synthetically generated multipanel images specifically\ncrafted to isolate and assess the impact of various factors, such as the\nlayout, on MLLMs' multipanel image comprehension abilities. As a result, in\naddition to benchmarking the capabilities of MLLMs in understanding multipanel\nimages, we analyze various factors of the multipanel image that affect MLLMs'\nperformance with synthetic data and offer insights for enhancement. Code and\ndata are released at https://sites.google.com/view/multipanelvqa/home.", "published": "2024-01-29 02:43:40", "link": "http://arxiv.org/abs/2401.15847v3", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "NoFunEval: Funny How Code LMs Falter on Requirements Beyond Functional\n  Correctness", "abstract": "Existing evaluation benchmarks of language models of code (code LMs) focus\nalmost exclusively on whether the LMs can generate functionally-correct code.\nIn real-world software engineering, developers think beyond functional\ncorrectness. They have requirements on \"how\" a functionality should be\nimplemented to meet overall system design objectives like efficiency, security,\nand maintainability. They would also trust the code LMs more if the LMs\ndemonstrate robust understanding of such requirements.\n  We propose a new benchmark NoFunEval to evaluate code LMs on non-functional\nrequirements and simple classification instances for both functional and\nnon-functional requirements. We propose a prompting method, Coding Concepts\n(CoCo), as a way for a developer to communicate the domain knowledge to the\nLMs. We conduct an extensive evaluation of 27 code LMs. Our finding is that LMs\ngenerally falter when tested on our benchmark, hinting at fundamental\nblindspots in their training setups. Surprisingly, even the classification\naccuracy on functional-correctness instances derived from the popular HumanEval\nbenchmark is low, calling in question the depth of their comprehension and the\nsource of their success in generating functionally-correct code in the first\nplace. We release our benchmark and evaluation scripts publicly at\nhttps://aka.ms/NoFunEval.", "published": "2024-01-29 08:47:31", "link": "http://arxiv.org/abs/2401.15963v3", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Multilingual Text-to-Image Generation Magnifies Gender Stereotypes and\n  Prompt Engineering May Not Help You", "abstract": "Text-to-image generation models have recently achieved astonishing results in\nimage quality, flexibility, and text alignment, and are consequently employed\nin a fast-growing number of applications. Through improvements in multilingual\nabilities, a larger community now has access to this technology. However, our\nresults show that multilingual models suffer from significant gender biases\njust as monolingual models do. Furthermore, the natural expectation that\nmultilingual models will provide similar results across languages does not hold\nup. Instead, there are important differences between languages. We propose a\nnovel benchmark, MAGBIG, intended to foster research on gender bias in\nmultilingual models. We use MAGBIG to investigate the effect of multilingualism\non gender bias in T2I models. To this end, we construct multilingual prompts\nrequesting portraits of people with a certain occupation or trait. Our results\nshow that not only do models exhibit strong gender biases but they also behave\ndifferently across languages. Furthermore, we investigate prompt engineering\nstrategies, such as indirect, neutral formulations, to mitigate these biases.\nUnfortunately, these approaches have limited success and result in worse\ntext-to-image alignment. Consequently, we call for more research into diverse\nrepresentations across languages in image generators, as well as into\nsteerability to address biased model behavior.", "published": "2024-01-29 12:02:28", "link": "http://arxiv.org/abs/2401.16092v3", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "X-PEFT: eXtremely Parameter-Efficient Fine-Tuning for Extreme\n  Multi-Profile Scenarios", "abstract": "Parameter-efficient fine-tuning (PEFT) techniques, such as adapter tuning,\naim to fine-tune a pre-trained language model (PLM) using a minimal number of\nparameters for a specific task or profile. Although adapter tuning provides\nincreased parameter efficiency compared to full-model fine-tuning, it\nintroduces a small set of additional parameters attached to a PLM for each\nprofile. This can become problematic in practical applications with multiple\nprofiles, particularly when a significant increase in the number of profiles\nlinearly boosts the total number of additional parameters. To mitigate this\nissue, we introduce X-PEFT, a novel PEFT method that leverages a multitude of\ngiven adapters by fine-tuning an extremely small set of compact tensors for a\nnew profile, which serve as binary masks to adaptively select the given\nadapters. To efficiently validate our proposed method, we implement it using a\nlarge number of trained or untrained (random) adapters. We evaluate the\nperformance of X-PEFT through LaMP and GLUE tasks and demonstrate that it\neither matches or surpasses the effectiveness of conventional adapter tuning,\ndespite reducing the memory requirements per profile by a factor of 10,000\ncompared to it.", "published": "2024-01-29 13:13:32", "link": "http://arxiv.org/abs/2401.16137v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "MAPLE: Micro Analysis of Pairwise Language Evolution for Few-Shot Claim\n  Verification", "abstract": "Claim verification is an essential step in the automated fact-checking\npipeline which assesses the veracity of a claim against a piece of evidence. In\nthis work, we explore the potential of few-shot claim verification, where only\nvery limited data is available for supervision. We propose MAPLE (Micro\nAnalysis of Pairwise Language Evolution), a pioneering approach that explores\nthe alignment between a claim and its evidence with a small seq2seq model and a\nnovel semantic measure. Its innovative utilization of micro language evolution\npath leverages unlabelled pairwise data to facilitate claim verification while\nimposing low demand on data annotations and computing resources. MAPLE\ndemonstrates significant performance improvements over SOTA baselines SEED, PET\nand LLaMA 2 across three fact-checking datasets: FEVER, Climate FEVER, and\nSciFact. Data and code are available here: https://github.com/XiaZeng0223/MAPLE", "published": "2024-01-29 16:39:39", "link": "http://arxiv.org/abs/2401.16282v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Textual Entailment for Effective Triple Validation in Object Prediction", "abstract": "Knowledge base population seeks to expand knowledge graphs with facts that\nare typically extracted from a text corpus. Recently, language models\npretrained on large corpora have been shown to contain factual knowledge that\ncan be retrieved using cloze-style strategies. Such approach enables zero-shot\nrecall of facts, showing competitive results in object prediction compared to\nsupervised baselines. However, prompt-based fact retrieval can be brittle and\nheavily depend on the prompts and context used, which may produce results that\nare unintended or hallucinatory.We propose to use textual entailment to\nvalidate facts extracted from language models through cloze statements. Our\nresults show that triple validation based on textual entailment improves\nlanguage model predictions in different training regimes. Furthermore, we show\nthat entailment-based triple validation is also effective to validate candidate\nfacts extracted from other sources including existing knowledge graphs and text\npassages where named entities are recognized.", "published": "2024-01-29 16:50:56", "link": "http://arxiv.org/abs/2401.16293v1", "categories": ["cs.CL", "cs.AI", "cs.DL"], "primary_category": "cs.CL"}
{"title": "Iterative Data Smoothing: Mitigating Reward Overfitting and\n  Overoptimization in RLHF", "abstract": "Reinforcement Learning from Human Feedback (RLHF) is a pivotal technique that\naligns language models closely with human-centric values. The initial phase of\nRLHF involves learning human values using a reward model from ranking data. It\nis observed that the performance of the reward model degrades after one epoch\nof training, and optimizing too much against the learned reward model\neventually hinders the true objective. This paper delves into these issues,\nleveraging the theoretical insights to design improved reward learning\nalgorithm termed 'Iterative Data Smoothing' (IDS). The core idea is that during\neach training epoch, we not only update the model with the data, but also\nupdate the date using the model, replacing hard labels with soft labels. Our\nempirical findings highlight the superior performance of this approach over the\ntraditional methods.", "published": "2024-01-29 17:43:42", "link": "http://arxiv.org/abs/2401.16335v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Improving the TENOR of Labeling: Re-evaluating Topic Models for Content\n  Analysis", "abstract": "Topic models are a popular tool for understanding text collections, but their\nevaluation has been a point of contention. Automated evaluation metrics such as\ncoherence are often used, however, their validity has been questioned for\nneural topic models (NTMs) and can overlook a models benefits in real world\napplications. To this end, we conduct the first evaluation of neural,\nsupervised and classical topic models in an interactive task based setting. We\ncombine topic models with a classifier and test their ability to help humans\nconduct content analysis and document annotation. From simulated, real user and\nexpert pilot studies, the Contextual Neural Topic Model does the best on\ncluster evaluation metrics and human evaluations; however, LDA is competitive\nwith two other NTMs under our simulated experiment and user study results,\ncontrary to what coherence scores suggest. We show that current automated\nmetrics do not provide a complete picture of topic modeling capabilities, but\nthe right choice of NTMs can be better than classical models on practical task.", "published": "2024-01-29 17:54:04", "link": "http://arxiv.org/abs/2401.16348v2", "categories": ["cs.CL", "cs.CY", "cs.HC"], "primary_category": "cs.CL"}
{"title": "TQCompressor: improving tensor decomposition methods in neural networks\n  via permutations", "abstract": "We introduce TQCompressor, a novel method for neural network model\ncompression with improved tensor decompositions. We explore the challenges\nposed by the computational and storage demands of pre-trained language models\nin NLP tasks and propose a permutation-based enhancement to Kronecker\ndecomposition. This enhancement makes it possible to reduce loss in model\nexpressivity which is usually associated with factorization. We demonstrate\nthis method applied to the GPT-2$_{small}$. The result of the compression is\nTQCompressedGPT-2 model, featuring 81 mln. parameters compared to 124 mln. in\nthe GPT-2$_{small}$. We make TQCompressedGPT-2 publicly available. We further\nenhance the performance of the TQCompressedGPT-2 through a training strategy\ninvolving multi-step knowledge distillation, using only a 3.1% of the\nOpenWebText. TQCompressedGPT-2 surpasses DistilGPT-2 and KnGPT-2 in comparative\nevaluations, marking an advancement in the efficient and effective deployment\nof models in resource-constrained environments.", "published": "2024-01-29 18:07:56", "link": "http://arxiv.org/abs/2401.16367v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Scaling Sparse Fine-Tuning to Large Language Models", "abstract": "Large Language Models (LLMs) are difficult to fully fine-tune (e.g., with\ninstructions or human feedback) due to their sheer number of parameters. A\nfamily of parameter-efficient sparse fine-tuning methods have proven promising\nin terms of performance but their memory requirements increase proportionally\nto the size of the LLMs. In this work, we scale sparse fine-tuning to\nstate-of-the-art LLMs like LLaMA 2 7B and 13B. We propose SpIEL, a novel sparse\nfine-tuning method which, for a desired density level, maintains an array of\nparameter indices and the deltas of these parameters relative to their\npretrained values. It iterates over: (a) updating the active deltas, (b)\npruning indices (based on the change of magnitude of their deltas) and (c)\nregrowth of indices. For regrowth, we explore two criteria based on either the\naccumulated gradients of a few candidate parameters or their approximate\nmomenta estimated using the efficient SM3 optimizer. We experiment with\ninstruction-tuning of LLMs on standard dataset mixtures, finding that SpIEL is\noften superior to popular parameter-efficient fine-tuning methods like LoRA\n(low-rank adaptation) in terms of performance and comparable in terms of run\ntime. We additionally show that SpIEL is compatible with both quantization and\nefficient optimizers, to facilitate scaling to ever-larger model sizes. We\nrelease the code for SpIEL at https://github.com/AlanAnsell/peft and for the\ninstruction-tuning experiments at https://github.com/ducdauge/sft-llm.", "published": "2024-01-29 18:43:49", "link": "http://arxiv.org/abs/2401.16405v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Two Stones Hit One Bird: Bilevel Positional Encoding for Better Length\n  Extrapolation", "abstract": "In this work, we leverage the intrinsic segmentation of language sequences\nand design a new positional encoding method called Bilevel Positional Encoding\n(BiPE). For each position, our BiPE blends an intra-segment encoding and an\ninter-segment encoding. The intra-segment encoding identifies the locations\nwithin a segment and helps the model capture the semantic information therein\nvia absolute positional encoding. The inter-segment encoding specifies the\nsegment index, models the relationships between segments, and aims to improve\nextrapolation capabilities via relative positional encoding. Theoretical\nanalysis shows this disentanglement of positional information makes learning\nmore effective. The empirical results also show that our BiPE has superior\nlength extrapolation capabilities across a wide range of tasks in diverse text\nmodalities.", "published": "2024-01-29 18:59:07", "link": "http://arxiv.org/abs/2401.16421v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "KAUCUS: Knowledge Augmented User Simulators for Training Language Model\n  Assistants", "abstract": "An effective multi-turn instruction-following assistant can be developed by\ncreating a simulator that can generate useful interaction data. Apart from\nrelying on its intrinsic weights, an ideal user simulator should also be able\nto bootstrap external knowledge rapidly in its raw form to simulate the\nmultifarious diversity of text available over the internet. Previous user\nsimulators generally lacked diversity, were mostly closed domain, and\nnecessitated rigid schema making them inefficient to rapidly scale to\nincorporate external knowledge. In this regard, we introduce, Kaucus, a\nKnowledge-Augmented User Simulator framework, to outline a process of creating\ndiverse user simulators, that can seamlessly exploit external knowledge as well\nas benefit downstream assistant model training. Through two GPT-J based\nsimulators viz., a Retrieval Augmented Simulator and a Summary Controlled\nSimulator we generate diverse simulator-assistant interactions. Through reward\nand preference model-based evaluations, we find that these interactions serve\nas useful training data and create more helpful downstream assistants. We also\nfind that incorporating knowledge through retrieval augmentation or summary\ncontrol helps create better assistants.", "published": "2024-01-29 06:57:02", "link": "http://arxiv.org/abs/2401.16454v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.IR", "I.2.7; H.3.3"], "primary_category": "cs.HC"}
{"title": "Credit Risk Meets Large Language Models: Building a Risk Indicator from\n  Loan Descriptions in P2P Lending", "abstract": "Peer-to-peer (P2P) lending connects borrowers and lenders through online\nplatforms but suffers from significant information asymmetry, as lenders often\nlack sufficient data to assess borrowers' creditworthiness. This paper\naddresses this challenge by leveraging BERT, a Large Language Model (LLM) known\nfor its ability to capture contextual nuances in text, to generate a risk score\nbased on borrowers' loan descriptions using a dataset from the Lending Club\nplatform. We fine-tune BERT to distinguish between defaulted and non-defaulted\nloans using the loan descriptions provided by the borrowers. The resulting\nBERT-generated risk score is then integrated as an additional feature into an\nXGBoost classifier used at the loan granting stage, where decision-makers have\nlimited information available to guide their decisions. This integration\nenhances predictive performance, with improvements in balanced accuracy and\nAUC, highlighting the value of textual features in complementing traditional\ninputs. Moreover, we find that the incorporation of the BERT score alters how\nclassification models utilize traditional input variables, with these changes\nvarying by loan purpose. These findings suggest that BERT discerns meaningful\npatterns in loan descriptions, encompassing borrower-specific features,\nspecific purposes, and linguistic characteristics. However, the inherent\nopacity of LLMs and their potential biases underscore the need for transparent\nframeworks to ensure regulatory compliance and foster trust. Overall, this\nstudy demonstrates how LLM-derived insights interact with traditional features\nin credit risk modeling, opening new avenues to enhance the explainability and\nfairness of these models.", "published": "2024-01-29 10:11:05", "link": "http://arxiv.org/abs/2401.16458v3", "categories": ["q-fin.RM", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "q-fin.RM"}
{"title": "Autoencoder-Based Domain Learning for Semantic Communication with\n  Conceptual Spaces", "abstract": "Communication with the goal of accurately conveying meaning, rather than\naccurately transmitting symbols, has become an area of growing interest. This\nparadigm, termed semantic communication, typically leverages modern\ndevelopments in artificial intelligence and machine learning to improve the\nefficiency and robustness of communication systems. However, a standard model\nfor capturing and quantifying the details of \"meaning\" is lacking, with many\nleading approaches to semantic communication adopting a black-box framework\nwith little understanding of what exactly the model is learning. One solution\nis to utilize the conceptual spaces framework, which models meaning explicitly\nin a geometric manner. Though prior work studying semantic communication with\nconceptual spaces has shown promising results, these previous attempts involve\nhand-crafting a conceptual space model, severely limiting the scalability and\npracticality of the approach. In this work, we develop a framework for learning\na domain of a conceptual space model using only the raw data with high-level\nproperty labels. In experiments using the MNIST and CelebA datasets, we show\nthat the domains learned using the framework maintain semantic similarity\nrelations and possess interpretable dimensions.", "published": "2024-01-29 21:08:33", "link": "http://arxiv.org/abs/2401.16569v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "eess.IV"], "primary_category": "cs.LG"}
{"title": "A Linguistic Comparison between Human and ChatGPT-Generated\n  Conversations", "abstract": "This study explores linguistic differences between human and LLM-generated\ndialogues, using 19.5K dialogues generated by ChatGPT-3.5 as a companion to the\nEmpathicDialogues dataset. The research employs Linguistic Inquiry and Word\nCount (LIWC) analysis, comparing ChatGPT-generated conversations with human\nconversations across 118 linguistic categories. Results show greater\nvariability and authenticity in human dialogues, but ChatGPT excels in\ncategories such as social processes, analytical style, cognition, attentional\nfocus, and positive emotional tone, reinforcing recent findings of LLMs being\n\"more human than human.\" However, no significant difference was found in\npositive or negative affect between ChatGPT and human dialogues. Classifier\nanalysis of dialogue embeddings indicates implicit coding of the valence of\naffect despite no explicit mention of affect in the conversations. The research\nalso contributes a novel, companion ChatGPT-generated dataset of conversations\nbetween two independent chatbots, which were designed to replicate a corpus of\nhuman conversations available for open access and used widely in AI research on\nlanguage modeling. Our findings enhance understanding of ChatGPT's linguistic\ncapabilities and inform ongoing efforts to distinguish between human and\nLLM-generated text, which is critical in detecting AI-generated fakes,\nmisinformation, and disinformation.", "published": "2024-01-29 21:43:27", "link": "http://arxiv.org/abs/2401.16587v3", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "CFTM: Continuous time fractional topic model", "abstract": "In this paper, we propose the Continuous Time Fractional Topic Model (cFTM),\na new method for dynamic topic modeling. This approach incorporates fractional\nBrownian motion~(fBm) to effectively identify positive or negative correlations\nin topic and word distribution over time, revealing long-term dependency or\nroughness. Our theoretical analysis shows that the cFTM can capture these\nlong-term dependency or roughness in both topic and word distributions,\nmirroring the main characteristics of fBm. Moreover, we prove that the\nparameter estimation process for the cFTM is on par with that of LDA,\ntraditional topic models. To demonstrate the cFTM's property, we conduct\nempirical study using economic news articles. The results from these tests\nsupport the model's ability to identify and track long-term dependency or\nroughness in topics over time.", "published": "2024-01-29 08:07:41", "link": "http://arxiv.org/abs/2402.01734v2", "categories": ["cs.CL", "cs.LG", "q-fin.CP", "stat.AP"], "primary_category": "cs.CL"}
{"title": "VIALM: A Survey and Benchmark of Visually Impaired Assistance with Large\n  Models", "abstract": "Visually Impaired Assistance (VIA) aims to automatically help the visually\nimpaired (VI) handle daily activities. The advancement of VIA primarily depends\non developments in Computer Vision (CV) and Natural Language Processing (NLP),\nboth of which exhibit cutting-edge paradigms with large models (LMs).\nFurthermore, LMs have shown exceptional multimodal abilities to tackle\nchallenging physically-grounded tasks such as embodied robots. To investigate\nthe potential and limitations of state-of-the-art (SOTA) LMs' capabilities in\nVIA applications, we present an extensive study for the task of VIA with LMs\n(VIALM). In this task, given an image illustrating the physical environments\nand a linguistic request from a VI user, VIALM aims to output step-by-step\nguidance to assist the VI user in fulfilling the request grounded in the\nenvironment. The study consists of a survey reviewing recent LM research and\nbenchmark experiments examining selected LMs' capabilities in VIA. The results\nindicate that while LMs can potentially benefit VIA, their output cannot be\nwell environment-grounded (i.e., 25.7% GPT-4's responses) and lacks\nfine-grained guidance (i.e., 32.1% GPT-4's responses).", "published": "2024-01-29 08:28:32", "link": "http://arxiv.org/abs/2402.01735v2", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "OpenMoE: An Early Effort on Open Mixture-of-Experts Language Models", "abstract": "To help the open-source community have a better understanding of\nMixture-of-Experts (MoE) based large language models (LLMs), we train and\nrelease OpenMoE, a series of fully open-sourced and reproducible decoder-only\nMoE LLMs, ranging from 650M to 34B parameters and trained on up to over 1T\ntokens. Our investigation confirms that MoE-based LLMs can offer a more\nfavorable cost-effectiveness trade-off than dense LLMs, highlighting the\npotential effectiveness for future LLM development.\n  One more important contribution of this study is an in-depth analysis of the\nrouting mechanisms within our OpenMoE models, leading to three significant\nfindings: Context-Independent Specialization, Early Routing Learning, and\nDrop-towards-the-End. We discovered that routing decisions in MoE models are\npredominantly based on token IDs, with minimal context relevance. The\ntoken-to-expert assignments are determined early in the pre-training phase and\nremain largely unchanged. This imperfect routing can result in performance\ndegradation, particularly in sequential tasks like multi-turn conversations,\nwhere tokens appearing later in a sequence are more likely to be dropped.\nFinally, we rethink our design based on the above-mentioned observations and\nanalysis. To facilitate future MoE LLM development, we propose potential\nstrategies for mitigating the issues we found and further improving\noff-the-shelf MoE LLM designs.", "published": "2024-01-29 12:05:02", "link": "http://arxiv.org/abs/2402.01739v2", "categories": ["cs.CL", "cs.AI", "cs.DC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Optimizing the Costs of LLM Usage", "abstract": "Generative AI and LLMs in particular are heavily used nowadays for various\ndocument processing tasks such as question answering and summarization.\nHowever, different LLMs come with different capabilities for different tasks as\nwell as with different costs, tokenization, and latency. In fact, enterprises\nare already incurring huge costs of operating or using LLMs for their\nrespective use cases.\n  In this work, we propose optimizing the usage costs of LLMs by estimating\ntheir output quality (without actually invoking the LLMs), and then solving an\noptimization routine for the LLM selection to either keep costs under a budget,\nor minimize the costs, in a quality and latency aware manner. We propose a\nmodel to predict the output quality of LLMs on document processing tasks like\nsummarization, followed by an LP rounding algorithm to optimize the selection\nof LLMs. We study optimization problems trading off the quality and costs, both\ntheoretically and empirically. We further propose a sentence simplification\nmodel for reducing the number of tokens in a controlled manner. Additionally,\nwe propose several deterministic heuristics for reducing tokens in a quality\naware manner, and study the related optimization problem of applying the\nheuristics optimizing the quality and cost trade-off. We perform extensive\nempirical validation of our methods on not only enterprise datasets but also on\nopen-source datasets, annotated by us, and show that we perform much better\ncompared to closest baselines. Our methods reduce costs by 40%- 90% while\nimproving quality by 4%-7%. We will release the annotated open source datasets\nto the community for further research and exploration.", "published": "2024-01-29 16:36:31", "link": "http://arxiv.org/abs/2402.01742v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Prompt4Vis: Prompting Large Language Models with Example Mining and\n  Schema Filtering for Tabular Data Visualization", "abstract": "Data visualization (DV) systems are increasingly recognized for their\nprofound capability to uncover insights from vast datasets, gaining attention\nacross both industry and academia. Crafting data queries is an essential\nprocess within certain declarative visualization languages (DVLs, e.g.,\nVega-Lite, EChart.). The evolution of natural language processing (NLP)\ntechnologies has streamlined the use of natural language interfaces to\nvisualize tabular data, offering a more accessible and intuitive user\nexperience. However, current methods for converting natural language questions\ninto data visualization queries, such as Seq2Vis, ncNet, and RGVisNet, despite\nutilizing complex neural network architectures, still fall short of\nexpectations and have great room for improvement.\n  Large language models (LLMs) such as ChatGPT and GPT-4, have established new\nbenchmarks in a variety of NLP tasks, fundamentally altering the landscape of\nthe field. Inspired by these advancements, we introduce a novel framework,\nPrompt4Vis, leveraging LLMs and in-context learning to enhance the performance\nof generating data visualization from natural language. Prompt4Vis comprises\ntwo key components: (1) a multi-objective example mining module, designed to\nfind out the truly effective examples that strengthen the LLM's in-context\nlearning capabilities for text-to-vis; (2) a schema filtering module, which is\nproposed to simplify the schema of the database. Extensive experiments through\n5-fold cross-validation on the NVBench dataset demonstrate the superiority of\nPrompt4Vis, which notably surpasses the state-of-the-art (SOTA) RGVisNet by\napproximately 35.9% and 71.3% on dev and test sets, respectively. To the best\nof our knowledge, Prompt4Vis is the first work that introduces in-context\nlearning into the text-to-vis for generating data visualization queries.", "published": "2024-01-29 10:23:47", "link": "http://arxiv.org/abs/2402.07909v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.DB"], "primary_category": "cs.HC"}
{"title": "Image-Text Out-Of-Context Detection Using Synthetic Multimodal\n  Misinformation", "abstract": "Misinformation has become a major challenge in the era of increasing digital\ninformation, requiring the development of effective detection methods. We have\ninvestigated a novel approach to Out-Of-Context detection (OOCD) that uses\nsynthetic data generation. We created a dataset specifically designed for OOCD\nand developed an efficient detector for accurate classification. Our\nexperimental findings validate the use of synthetic data generation and\ndemonstrate its efficacy in addressing the data limitations associated with\nOOCD. The dataset and detector should serve as valuable resources for future\nresearch and the development of robust misinformation detection systems.", "published": "2024-01-29 11:55:14", "link": "http://arxiv.org/abs/2403.08783v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "ReGAL: Refactoring Programs to Discover Generalizable Abstractions", "abstract": "While large language models (LLMs) are increasingly being used for program\nsynthesis, they lack the global view needed to develop useful abstractions;\nthey generally predict programs one at a time, often repeating the same\nfunctionality. Generating redundant code from scratch is both inefficient and\nerror-prone. To address this, we propose Refactoring for Generalizable\nAbstraction Learning (ReGAL), a gradient-free method for learning a library of\nreusable functions via code refactorization, i.e., restructuring code without\nchanging its execution output. ReGAL learns from a small set of existing\nprograms, iteratively verifying and refining its abstractions via execution. We\nfind that the shared function libraries discovered by ReGAL make programs\neasier to predict across diverse domains. On five datasets -- LOGO graphics\ngeneration, Date reasoning, TextCraft (a Minecraft-based text-game) MATH, and\nTabMWP -- both open-source and proprietary LLMs improve in accuracy when\npredicting programs with ReGAL functions. For CodeLlama-13B, ReGAL results in\nabsolute accuracy increases of 11.5% on LOGO, 26.1% on date understanding, and\n8.1% on TextCraft, outperforming GPT-3.5 in two of three domains. Our analysis\nreveals ReGAL's abstractions encapsulate frequently-used subroutines as well as\nenvironment dynamics.", "published": "2024-01-29 18:45:30", "link": "http://arxiv.org/abs/2401.16467v2", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG", "cs.PL"], "primary_category": "cs.SE"}
{"title": "Masked Audio Modeling with CLAP and Multi-Objective Learning", "abstract": "Most existing masked audio modeling (MAM) methods learn audio representations\nby masking and reconstructing local spectrogram patches. However, the\nreconstruction loss mainly accounts for the signal-level quality of the\nreconstructed spectrogram and is still limited in extracting high-level audio\nsemantics. In this paper, we propose to enhance the semantic modeling of MAM by\ndistilling cross-modality knowledge from contrastive language-audio pretraining\n(CLAP) representations for both masked and unmasked regions (MAM-CLAP) and\nleveraging a multi-objective learning strategy with a supervised classification\nbranch (SupMAM), thereby providing more semantic knowledge for MAM and enabling\nit to effectively learn global features from labels. Experiments show that our\nmethods significantly improve the performance on multiple downstream tasks.\nFurthermore, by combining our MAM-CLAP with SupMAM, we can achieve new\nstate-of-the-art results on various audio and speech classification tasks,\nexceeding previous self-supervised learning and supervised pretraining methods.", "published": "2024-01-29 08:35:35", "link": "http://arxiv.org/abs/2401.15953v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Continuous Target Speech Extraction: Enhancing Personalized Diarization\n  and Extraction on Complex Recordings", "abstract": "Target speaker extraction (TSE) aims to extract the target speaker's voice\nfrom the input mixture. Previous studies have concentrated on high-overlapping\nscenarios. However, real-world applications usually meet more complex scenarios\nlike variable speaker overlapping and target speaker absence. In this paper, we\nintroduces a framework to perform continuous TSE (C-TSE), comprising a target\nspeaker voice activation detection (TSVAD) and a TSE model. This framework\nsignificantly improves TSE performance on similar speakers and enhances\npersonalization, which is lacking in traditional diarization methods. In\ndetail, unlike conventional TSVAD deployed to refine the diarization results,\nthe proposed Attention-target speaker voice activation detection (A-TSVAD)\ndirectly generates timestamps of the target speaker. We also explore some\ndifferent integration methods of A-TSVAD and TSE by comparing the cascaded and\nparallel methods. The framework's effectiveness is assessed using a range of\nmetrics, including diarization and enhancement metrics. Our experiments\ndemonstrate that A-TSVAD outperforms conventional methods in reducing\ndiarization errors. Furthermore, the integration of A-TSVAD and TSE in a\nsequential cascaded manner further enhances extraction accuracy.", "published": "2024-01-29 09:23:26", "link": "http://arxiv.org/abs/2401.15993v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Enhanced Sound Event Localization and Detection in Real 360-degree\n  audio-visual soundscapes", "abstract": "This technical report details our work towards building an enhanced\naudio-visual sound event localization and detection (SELD) network. We build on\ntop of the audio-only SELDnet23 model and adapt it to be audio-visual by\nmerging both audio and video information prior to the gated recurrent unit\n(GRU) of the audio-only network. Our model leverages YOLO and DETIC object\ndetectors. We also build a framework that implements audio-visual data\naugmentation and audio-visual synthetic data generation. We deliver an\naudio-visual SELDnet system that outperforms the existing audio-visual SELD\nbaseline.", "published": "2024-01-29 06:05:23", "link": "http://arxiv.org/abs/2401.17129v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Synchformer: Efficient Synchronization from Sparse Cues", "abstract": "Our objective is audio-visual synchronization with a focus on 'in-the-wild'\nvideos, such as those on YouTube, where synchronization cues can be sparse. Our\ncontributions include a novel audio-visual synchronization model, and training\nthat decouples feature extraction from synchronization modelling through\nmulti-modal segment-level contrastive pre-training. This approach achieves\nstate-of-the-art performance in both dense and sparse settings. We also extend\nsynchronization model training to AudioSet a million-scale 'in-the-wild'\ndataset, investigate evidence attribution techniques for interpretability, and\nexplore a new capability for synchronization models: audio-visual\nsynchronizability.", "published": "2024-01-29 18:59:55", "link": "http://arxiv.org/abs/2401.16423v1", "categories": ["cs.CV", "cs.LG", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
