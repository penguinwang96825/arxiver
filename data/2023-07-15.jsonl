{"title": "Think-on-Graph: Deep and Responsible Reasoning of Large Language Model\n  on Knowledge Graph", "abstract": "Although large language models (LLMs) have achieved significant success in\nvarious tasks, they often struggle with hallucination problems, especially in\nscenarios requiring deep and responsible reasoning. These issues could be\npartially addressed by introducing external knowledge graphs (KG) in LLM\nreasoning. In this paper, we propose a new LLM-KG integrating paradigm\n``$\\hbox{LLM}\\otimes\\hbox{KG}$'' which treats the LLM as an agent to\ninteractively explore related entities and relations on KGs and perform\nreasoning based on the retrieved knowledge. We further implement this paradigm\nby introducing a new approach called Think-on-Graph (ToG), in which the LLM\nagent iteratively executes beam search on KG, discovers the most promising\nreasoning paths, and returns the most likely reasoning results. We use a number\nof well-designed experiments to examine and illustrate the following advantages\nof ToG: 1) compared with LLMs, ToG has better deep reasoning power; 2) ToG has\nthe ability of knowledge traceability and knowledge correctability by\nleveraging LLMs reasoning and expert feedback; 3) ToG provides a flexible\nplug-and-play framework for different LLMs, KGs and prompting strategies\nwithout any additional training cost; 4) the performance of ToG with small LLM\nmodels could exceed large LLM such as GPT-4 in certain scenarios and this\nreduces the cost of LLM deployment and application. As a training-free method\nwith lower computational cost and better generality, ToG achieves overall SOTA\nin 6 out of 9 datasets where most previous SOTAs rely on additional training.", "published": "2023-07-15 03:31:38", "link": "http://arxiv.org/abs/2307.07697v6", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CA-LoRA: Adapting Existing LoRA for Compressed LLMs to Enable Efficient\n  Multi-Tasking on Personal Devices", "abstract": "Recently, there has been a demand to deploy Large Language Models (LLMs) on\npersonal devices such as laptops and smartphones. These LLMs have different\nmodel variants when handling different tasks. However, personal devices have\nlimited resources and require reduced storage overhead. To address this, there\nare two key methods available: the first is model compression, which compresses\nLLMs into smaller sizes; the second is LoRA, which can transfer an LLM to other\ntasks with very few parameters, avoiding the storage of multiple model variants\nin multi-task scenarios by only preserving LoRAs. However, our experiments show\nthat directly combining these two methods yields sub-optimal performance.\nConsidering that the open-source community has already contributed many LoRAs\nto LLMs, we propose to adapt these existing LoRAs from the LLMs to their\ncompressed version and introduce a Compression-Aware LoRA (CA-LoRA) framework.\nWe incorporate knowledge inheritance and recovery strategies to recover the\nlost knowledge caused by model compression. Experiment results demonstrate that\nCA-LoRA outperforms the vanilla LoRA methods applied to a compressed LLM and\nachieves comparable performance to the non-compressed LLM with existing LoRA\nmodules. The source code of CA-LoRA is available at\nhttps://github.com/thunlp/CA-LoRA.", "published": "2023-07-15 04:37:11", "link": "http://arxiv.org/abs/2307.07705v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CIDER: Context sensitive sentiment analysis for short-form text", "abstract": "Researchers commonly perform sentiment analysis on large collections of short\ntexts like tweets, Reddit posts or newspaper headlines that are all focused on\na specific topic, theme or event. Usually, general-purpose sentiment analysis\nmethods are used. These perform well on average but miss the variation in\nmeaning that happens across different contexts, for example, the word \"active\"\nhas a very different intention and valence in the phrase \"active lifestyle\"\nversus \"active volcano\". This work presents a new approach, CIDER (Context\nInformed Dictionary and sEmantic Reasoner), which performs context-sensitive\nlinguistic analysis, where the valence of sentiment-laden terms is inferred\nfrom the whole corpus before being used to score the individual texts. In this\npaper, we detail the CIDER algorithm and demonstrate that it outperforms\nstate-of-the-art generalist unsupervised sentiment analysis techniques on a\nlarge collection of tweets about the weather. CIDER is also applicable to\nalternative (non-sentiment) linguistic scales. A case study on gender in the UK\nis presented, with the identification of highly gendered and sentiment-laden\ndays. We have made our implementation of CIDER available as a Python package:\nhttps://pypi.org/project/ciderpolarity/.", "published": "2023-07-15 18:25:56", "link": "http://arxiv.org/abs/2307.07864v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Is Prompt-Based Finetuning Always Better than Vanilla Finetuning?\n  Insights from Cross-Lingual Language Understanding", "abstract": "Multilingual pretrained language models (MPLMs) have demonstrated substantial\nperformance improvements in zero-shot cross-lingual transfer across various\nnatural language understanding tasks by finetuning MPLMs on task-specific\nlabelled data of a source language (e.g. English) and evaluating on a wide\nrange of target languages. Recent studies show that prompt-based finetuning\nsurpasses regular finetuning in few-shot scenarios. However, the exploration of\nprompt-based learning in multilingual tasks remains limited. In this study, we\npropose the ProFiT pipeline to investigate the cross-lingual capabilities of\nPrompt-based Finetuning. We conduct comprehensive experiments on diverse\ncross-lingual language understanding tasks (sentiment classification,\nparaphrase identification, and natural language inference) and empirically\nanalyze the variation trends of prompt-based finetuning performance in\ncross-lingual transfer across different few-shot and full-data settings. Our\nresults reveal the effectiveness and versatility of prompt-based finetuning in\ncross-lingual language understanding. Our findings indicate that prompt-based\nfinetuning outperforms vanilla finetuning in full-data scenarios and exhibits\ngreater advantages in few-shot scenarios, with different performance patterns\ndependent on task types. Additionally, we analyze underlying factors such as\nlanguage similarity and pretraining data size that impact the cross-lingual\nperformance of prompt-based finetuning. Overall, our work provides valuable\ninsights into the cross-lingual prowess of prompt-based finetuning.", "published": "2023-07-15 20:33:33", "link": "http://arxiv.org/abs/2307.07880v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM Comparative Assessment: Zero-shot NLG Evaluation through Pairwise\n  Comparisons using Large Language Models", "abstract": "Current developments in large language models (LLMs) have enabled impressive\nzero-shot capabilities across various natural language tasks. An interesting\napplication of these systems is in the automated assessment of natural language\ngeneration (NLG), a highly challenging area with great practical benefit. In\nthis paper, we explore two options for exploiting the emergent abilities of\nLLMs for zero-shot NLG assessment: absolute score prediction, and comparative\nassessment which uses relative comparisons between pairs of candidates. Though\ncomparative assessment has not been extensively studied in NLG assessment, we\nnote that humans often find it more intuitive to compare two options rather\nthan scoring each one independently. This work examines comparative assessment\nfrom multiple perspectives: performance compared to absolute grading;\npositional biases in the prompt; and efficient ranking in terms of the number\nof comparisons. We illustrate that LLM comparative assessment is a simple,\ngeneral and effective approach for NLG assessment. For moderate-sized\nopen-source LLMs, such as FlanT5 and Llama2-chat, comparative assessment is\nsuperior to prompt scoring, and in many cases can achieve performance\ncompetitive with state-of-the-art methods. Additionally, we demonstrate that\nLLMs often exhibit strong positional biases when making pairwise comparisons,\nand we propose debiasing methods that can further improve performance.", "published": "2023-07-15 22:02:12", "link": "http://arxiv.org/abs/2307.07889v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Three-way Decisions with Evaluative Linguistic Expressions", "abstract": "We propose a linguistic interpretation of three-way decisions, where the\nregions of acceptance, rejection, and non-commitment are constructed by using\nthe so-called evaluative linguistic expressions, which are expressions of\nnatural language such as small, medium, very short, quite roughly strong,\nextremely good, etc. Our results highlight new connections between two\ndifferent research areas: three-way decisions and the theory of evaluative\nlinguistic expressions.", "published": "2023-07-15 14:45:33", "link": "http://arxiv.org/abs/2307.11766v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Dialogue System for Assessing Activities of Daily Living: Improving\n  Consistency with Grounded Knowledge", "abstract": "In healthcare, the ability to care for oneself is reflected in the\n\"Activities of Daily Living (ADL),\" which serve as a measure of functional\nability (functioning). A lack of functioning may lead to poor living conditions\nrequiring personal care and assistance. To accurately identify those in need of\nsupport, assistance programs continuously evaluate participants' functioning\nacross various domains. However, the assessment process may encounter\nconsistency issues when multiple assessors with varying levels of expertise are\ninvolved. Novice assessors, in particular, may lack the necessary preparation\nfor real-world interactions with participants. To address this issue, we\ndeveloped a dialogue system that simulates interactions between assessors and\nindividuals of varying functioning in a natural and reproducible way. The\ndialogue system consists of two major modules, one for natural language\nunderstanding (NLU) and one for natural language generation (NLG),\nrespectively. In order to generate responses consistent with the underlying\nknowledge base, the dialogue system requires both an understanding of the\nuser's query and of biographical details of an individual being simulated. To\nfulfill this requirement, we experimented with query classification and\ngenerated responses based on those biographical details using some recently\nreleased InstructGPT-like models.", "published": "2023-07-15 22:41:59", "link": "http://arxiv.org/abs/2307.07544v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Political Sentiment Analysis of Persian Tweets Using CNN-LSTM Model", "abstract": "Sentiment analysis is the process of identifying and categorizing people's\nemotions or opinions regarding various topics. The analysis of Twitter\nsentiment has become an increasingly popular topic in recent years. In this\npaper, we present several machine learning and a deep learning model to\nanalysis sentiment of Persian political tweets. Our analysis was conducted\nusing Bag of Words and ParsBERT for word representation. We applied Gaussian\nNaive Bayes, Gradient Boosting, Logistic Regression, Decision Trees, Random\nForests, as well as a combination of CNN and LSTM to classify the polarities of\ntweets. The results of this study indicate that deep learning with ParsBERT\nembedding performs better than machine learning. The CNN-LSTM model had the\nhighest classification accuracy with 89 percent on the first dataset and 71\npercent on the second dataset. Due to the complexity of Persian, it was a\ndifficult task to achieve this level of efficiency. The main objective of our\nresearch was to reduce the training time while maintaining the model's\nperformance. As a result, several adjustments were made to the model\narchitecture and parameters. In addition to achieving the objective, the\nperformance was slightly improved as well.", "published": "2023-07-15 08:08:38", "link": "http://arxiv.org/abs/2307.07740v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Opinion mining using Double Channel CNN for Recommender System", "abstract": "Much unstructured data has been produced with the growth of the Internet and\nsocial media. A significant volume of textual data includes users' opinions\nabout products in online stores and social media. By exploring and categorizing\nthem, helpful information can be acquired, including customer satisfaction,\nuser feedback about a particular event, predicting the sale of a specific\nproduct, and other similar cases. In this paper, we present an approach for\nsentiment analysis with a deep learning model and use it to recommend products.\nA two-channel convolutional neural network model has been used for opinion\nmining, which has five layers and extracts essential features from the data. We\nincreased the number of comments by applying the SMOTE algorithm to the initial\ndataset and balanced the data. Then we proceed to cluster the aspects. We also\nassign a weight to each cluster using tensor decomposition algorithms that\nimprove the recommender system's performance. Our proposed method has reached\n91.6% accuracy, significantly improved compared to previous aspect-based\napproaches.", "published": "2023-07-15 13:11:18", "link": "http://arxiv.org/abs/2307.07798v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Transformers are Universal Predictors", "abstract": "We find limits to the Transformer architecture for language modeling and show\nit has a universal prediction property in an information-theoretic sense. We\nfurther analyze performance in non-asymptotic data regimes to understand the\nrole of various components of the Transformer architecture, especially in the\ncontext of data-efficient training. We validate our theoretical analysis with\nexperiments on both synthetic and real datasets.", "published": "2023-07-15 16:19:37", "link": "http://arxiv.org/abs/2307.07843v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "AspectCSE: Sentence Embeddings for Aspect-based Semantic Textual\n  Similarity Using Contrastive Learning and Structured Knowledge", "abstract": "Generic sentence embeddings provide a coarse-grained approximation of\nsemantic textual similarity but ignore specific aspects that make texts\nsimilar. Conversely, aspect-based sentence embeddings provide similarities\nbetween texts based on certain predefined aspects. Thus, similarity predictions\nof texts are more targeted to specific requirements and more easily\nexplainable. In this paper, we present AspectCSE, an approach for aspect-based\ncontrastive learning of sentence embeddings. Results indicate that AspectCSE\nachieves an average improvement of 3.97% on information retrieval tasks across\nmultiple aspects compared to the previous best results. We also propose using\nWikidata knowledge graph properties to train models of multi-aspect sentence\nembeddings in which multiple specific aspects are simultaneously considered\nduring similarity predictions. We demonstrate that multi-aspect embeddings\noutperform single-aspect embeddings on aspect-specific information retrieval\ntasks. Finally, we examine the aspect-based sentence embedding space and\ndemonstrate that embeddings of semantically similar aspect labels are often\nclose, even without explicit similarity training between different aspect\nlabels.", "published": "2023-07-15 17:01:56", "link": "http://arxiv.org/abs/2307.07851v5", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Single and Multi-Speaker Cloned Voice Detection: From Perceptual to\n  Learned Features", "abstract": "Synthetic-voice cloning technologies have seen significant advances in recent\nyears, giving rise to a range of potential harms. From small- and large-scale\nfinancial fraud to disinformation campaigns, the need for reliable methods to\ndifferentiate real and synthesized voices is imperative. We describe three\ntechniques for differentiating a real from a cloned voice designed to\nimpersonate a specific person. These three approaches differ in their feature\nextraction stage with low-dimensional perceptual features offering high\ninterpretability but lower accuracy, to generic spectral features, and\nend-to-end learned features offering less interpretability but higher accuracy.\nWe show the efficacy of these approaches when trained on a single speaker's\nvoice and when trained on multiple voices. The learned features consistently\nyield an equal error rate between 0% and 4%, and are reasonably robust to\nadversarial laundering.", "published": "2023-07-15 02:20:26", "link": "http://arxiv.org/abs/2307.07683v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Coupling Large Language Models with Logic Programming for Robust and\n  General Reasoning from Text", "abstract": "While large language models (LLMs), such as GPT-3, appear to be robust and\ngeneral, their reasoning ability is not at a level to compete with the best\nmodels trained for specific natural language reasoning problems. In this study,\nwe observe that a large language model can serve as a highly effective few-shot\nsemantic parser. It can convert natural language sentences into a logical form\nthat serves as input for answer set programs, a logic-based declarative\nknowledge representation formalism. The combination results in a robust and\ngeneral system that can handle multiple question-answering tasks without\nrequiring retraining for each new task. It only needs a few examples to guide\nthe LLM's adaptation to a specific task, along with reusable ASP knowledge\nmodules that can be applied to multiple tasks. We demonstrate that this method\nachieves state-of-the-art performance on several NLP benchmarks, including\nbAbI, StepGame, CLUTRR, and gSCAN. Additionally, it successfully tackles robot\nplanning tasks that an LLM alone fails to solve.", "published": "2023-07-15 03:29:59", "link": "http://arxiv.org/abs/2307.07696v1", "categories": ["cs.CL", "cs.AI", "cs.SC"], "primary_category": "cs.CL"}
{"title": "Leveraging Large Language Models to Generate Answer Set Programs", "abstract": "Large language models (LLMs), such as GPT-3 and GPT-4, have demonstrated\nexceptional performance in various natural language processing tasks and have\nshown the ability to solve certain reasoning problems. However, their reasoning\ncapabilities are limited and relatively shallow, despite the application of\nvarious prompting techniques. In contrast, formal logic is adept at handling\ncomplex reasoning, but translating natural language descriptions into formal\nlogic is a challenging task that non-experts struggle with. This paper proposes\na neuro-symbolic method that combines the strengths of large language models\nand answer set programming. Specifically, we employ an LLM to transform natural\nlanguage descriptions of logic puzzles into answer set programs. We carefully\ndesign prompts for an LLM to convert natural language descriptions into answer\nset programs in a step by step manner. Surprisingly, with just a few in-context\nlearning examples, LLMs can generate reasonably complex answer set programs.\nThe majority of errors made are relatively simple and can be easily corrected\nby humans, thus enabling LLMs to effectively assist in the creation of answer\nset programs.", "published": "2023-07-15 03:40:55", "link": "http://arxiv.org/abs/2307.07699v1", "categories": ["cs.AI", "cs.CL", "cs.SC"], "primary_category": "cs.AI"}
{"title": "Large Language Models as Superpositions of Cultural Perspectives", "abstract": "Large Language Models (LLMs) are often misleadingly recognized as having a\npersonality or a set of values. We argue that an LLM can be seen as a\nsuperposition of perspectives with different values and personality traits.\nLLMs exhibit context-dependent values and personality traits that change based\non the induced perspective (as opposed to humans, who tend to have more\ncoherent values and personality traits across contexts). We introduce the\nconcept of perspective controllability, which refers to a model's affordance to\nadopt various perspectives with differing values and personality traits. In our\nexperiments, we use questionnaires from psychology (PVQ, VSM, IPIP) to study\nhow exhibited values and personality traits change based on different\nperspectives. Through qualitative experiments, we show that LLMs express\ndifferent values when those are (implicitly or explicitly) implied in the\nprompt, and that LLMs express different values even when those are not\nobviously implied (demonstrating their context-dependent nature). We then\nconduct quantitative experiments to study the controllability of different\nmodels (GPT-4, GPT-3.5, OpenAssistant, StableVicuna, StableLM), the\neffectiveness of various methods for inducing perspectives, and the smoothness\nof the models' drivability. We conclude by examining the broader implications\nof our work and outline a variety of associated scientific questions. The\nproject website is available at\nhttps://sites.google.com/view/llm-superpositions .", "published": "2023-07-15 19:04:33", "link": "http://arxiv.org/abs/2307.07870v3", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T07", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Audio-Visual Speech Enhancement Using Self-supervised Learning to\n  Improve Speech Intelligibility in Cochlear Implant Simulations", "abstract": "Individuals with hearing impairments face challenges in their ability to\ncomprehend speech, particularly in noisy environments. The aim of this study is\nto explore the effectiveness of audio-visual speech enhancement (AVSE) in\nenhancing the intelligibility of vocoded speech in cochlear implant (CI)\nsimulations. Notably, the study focuses on a challenged scenario where there is\nlimited availability of training data for the AVSE task. To address this\nproblem, we propose a novel deep neural network framework termed\nSelf-Supervised Learning-based AVSE (SSL-AVSE). The proposed SSL-AVSE combines\nvisual cues, such as lip and mouth movements, from the target speakers with\ncorresponding audio signals. The contextually combined audio and visual data\nare then fed into a Transformer-based SSL AV-HuBERT model to extract features,\nwhich are further processed using a BLSTM-based SE model. The results\ndemonstrate several key findings. Firstly, SSL-AVSE successfully overcomes the\nissue of limited data by leveraging the AV-HuBERT model. Secondly, by\nfine-tuning the AV-HuBERT model parameters for the target SE task, significant\nperformance improvements are achieved. Specifically, there is a notable\nenhancement in PESQ (Perceptual Evaluation of Speech Quality) from 1.43 to 1.67\nand in STOI (Short-Time Objective Intelligibility) from 0.70 to 0.74.\nFurthermore, the performance of the SSL-AVSE was evaluated using CI vocoded\nspeech to assess the intelligibility for CI users. Comparative experimental\noutcomes reveal that in the presence of dynamic noises encountered during human\nconversations, SSL-AVSE exhibits a substantial improvement. The NCM (Normal\nCorrelation Matrix) values indicate an increase of 26.5% to 87.2% compared to\nthe noisy baseline.", "published": "2023-07-15 09:05:57", "link": "http://arxiv.org/abs/2307.07748v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
