{"title": "E-NER: Evidential Deep Learning for Trustworthy Named Entity Recognition", "abstract": "Most named entity recognition (NER) systems focus on improving model\nperformance, ignoring the need to quantify model uncertainty, which is critical\nto the reliability of NER systems in open environments. Evidential deep\nlearning (EDL) has recently been proposed as a promising solution to explicitly\nmodel predictive uncertainty for classification tasks. However, directly\napplying EDL to NER applications faces two challenges, i.e., the problems of\nsparse entities and OOV/OOD entities in NER tasks. To address these challenges,\nwe propose a trustworthy NER framework named E-NER by introducing two\nuncertainty-guided loss terms to the conventional EDL, along with a series of\nuncertainty-guided training strategies. Experiments show that E-NER can be\napplied to multiple NER paradigms to obtain accurate uncertainty estimation.\nFurthermore, compared to state-of-the-art baselines, the proposed method\nachieves a better OOV/OOD detection performance and better generalization\nability on OOV entities.", "published": "2023-05-29 02:36:16", "link": "http://arxiv.org/abs/2305.17854v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Vec2Gloss: definition modeling leveraging contextualized vectors with\n  Wordnet gloss", "abstract": "Contextualized embeddings are proven to be powerful tools in multiple NLP\ntasks. Nonetheless, challenges regarding their interpretability and capability\nto represent lexical semantics still remain. In this paper, we propose that the\ntask of definition modeling, which aims to generate the human-readable\ndefinition of the word, provides a route to evaluate or understand the high\ndimensional semantic vectors. We propose a `Vec2Gloss' model, which produces\nthe gloss from the target word's contextualized embeddings. The generated\nglosses of this study are made possible by the systematic gloss patterns\nprovided by Chinese Wordnet. We devise two dependency indices to measure the\nsemantic and contextual dependency, which are used to analyze the generated\ntexts in gloss and token levels. Our results indicate that the proposed\n`Vec2Gloss' model opens a new perspective to the lexical-semantic applications\nof contextualized embeddings.", "published": "2023-05-29 02:37:37", "link": "http://arxiv.org/abs/2305.17855v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM-QAT: Data-Free Quantization Aware Training for Large Language Models", "abstract": "Several post-training quantization methods have been applied to large\nlanguage models (LLMs), and have been shown to perform well down to 8-bits. We\nfind that these methods break down at lower bit precision, and investigate\nquantization aware training for LLMs (LLM-QAT) to push quantization levels even\nfurther. We propose a data-free distillation method that leverages generations\nproduced by the pre-trained model, which better preserves the original output\ndistribution and allows quantizing any generative model independent of its\ntraining data, similar to post-training quantization methods. In addition to\nquantizing weights and activations, we also quantize the KV cache, which is\ncritical for increasing throughput and support long sequence dependencies at\ncurrent model sizes. We experiment with LLaMA models of sizes 7B, 13B, and 30B,\nat quantization levels down to 4-bits. We observe large improvements over\ntraining-free methods, especially in the low-bit settings.", "published": "2023-05-29 05:22:11", "link": "http://arxiv.org/abs/2305.17888v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Byte-Level Grammatical Error Correction Using Synthetic and Curated\n  Corpora", "abstract": "Grammatical error correction (GEC) is the task of correcting typos, spelling,\npunctuation and grammatical issues in text. Approaching the problem as a\nsequence-to-sequence task, we compare the use of a common subword unit\nvocabulary and byte-level encoding. Initial synthetic training data is created\nusing an error-generating pipeline, and used for finetuning two subword-level\nmodels and one byte-level model. Models are then finetuned further on\nhand-corrected error corpora, including texts written by children, university\nstudents, dyslexic and second-language writers, and evaluated over different\nerror types and origins. We show that a byte-level model enables higher\ncorrection quality than a subword approach, not only for simple spelling\nerrors, but also for more complex semantic, stylistic and grammatical issues.\nIn particular, initial training on synthetic corpora followed by finetuning on\na relatively small parallel corpus of real-world errors helps the byte-level\nmodel correct a wide range of commonly occurring errors. Our experiments are\nrun for the Icelandic language but should hold for other similar languages,\nparticularly morphologically rich ones.", "published": "2023-05-29 06:35:40", "link": "http://arxiv.org/abs/2305.17906v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Data Augmentation for Low-Resource Keyphrase Generation", "abstract": "Keyphrase generation is the task of summarizing the contents of any given\narticle into a few salient phrases (or keyphrases). Existing works for the task\nmostly rely on large-scale annotated datasets, which are not easy to acquire.\nVery few works address the problem of keyphrase generation in low-resource\nsettings, but they still rely on a lot of additional unlabeled data for\npretraining and on automatic methods for pseudo-annotations. In this paper, we\npresent data augmentation strategies specifically to address keyphrase\ngeneration in purely resource-constrained domains. We design techniques that\nuse the full text of the articles to improve both present and absent keyphrase\ngeneration. We test our approach comprehensively on three datasets and show\nthat the data augmentation strategies consistently improve the state-of-the-art\nperformance. We release our source code at\nhttps://github.com/kgarg8/kpgen-lowres-data-aug.", "published": "2023-05-29 09:20:34", "link": "http://arxiv.org/abs/2305.17968v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Effects of Political Martyrdom on Election Results: The\n  Assassination of Abe", "abstract": "In developed nations assassinations are rare and thus the impact of such acts\non the electoral and political landscape is understudied. In this paper, we\nfocus on Twitter data to examine the effects of Japan's former Primer Minister\nAbe's assassination on the Japanese House of Councillors elections in 2022. We\nutilize sentiment analysis and emotion detection together with topic modeling\non over 2 million tweets and compare them against tweets during previous\nelection cycles. Our findings indicate that Twitter sentiments were negatively\nimpacted by the event in the short term and that social media attention span\nhas shortened. We also discuss how \"necropolitics\" affected the outcome of the\nelections in favor of the deceased's party meaning that there seems to have\nbeen an effect of Abe's death on the election outcome though the findings\nwarrant further investigation for conclusive results.", "published": "2023-05-29 10:33:08", "link": "http://arxiv.org/abs/2305.18004v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Abstractive Summarization as Augmentation for Document-Level Event\n  Detection", "abstract": "Transformer-based models have consistently produced substantial performance\ngains across a variety of NLP tasks, compared to shallow models. However, deep\nmodels are orders of magnitude more computationally expensive than shallow\nmodels, especially on tasks with large sequence lengths, such as document-level\nevent detection. In this work, we attempt to bridge the performance gap between\nshallow and deep models on document-level event detection by using abstractive\ntext summarization as an augmentation method. We augment the DocEE dataset by\ngenerating abstractive summaries of examples from low-resource classes. For\nclassification, we use linear SVM with TF-IDF representations and RoBERTa-base.\nWe use BART for zero-shot abstractive summarization, making our augmentation\nsetup less resource-intensive compared to supervised fine-tuning. We experiment\nwith four decoding methods for text generation, namely beam search, top-k\nsampling, top-p sampling, and contrastive search. Furthermore, we investigate\nthe impact of using document titles as additional input for classification. Our\nresults show that using the document title offers 2.04% and 3.19% absolute\nimprovement in macro F1-score for linear SVM and RoBERTa, respectively.\nAugmentation via summarization further improves the performance of linear SVM\nby about 0.5%, varying slightly across decoding methods. Overall, our\naugmentation setup yields insufficient improvements for linear SVM compared to\nRoBERTa.", "published": "2023-05-29 11:28:26", "link": "http://arxiv.org/abs/2305.18023v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic Role Labeling Guided Out-of-distribution Detection", "abstract": "Identifying unexpected domain-shifted instances in natural language\nprocessing is crucial in real-world applications. Previous works identify the\nout-of-distribution (OOD) instance by leveraging a single global feature\nembedding to represent the sentence, which cannot characterize subtle OOD\npatterns well. Another major challenge current OOD methods face is learning\neffective low-dimensional sentence representations to identify the hard OOD\ninstances that are semantically similar to the in-distribution (ID) data. In\nthis paper, we propose a new unsupervised OOD detection method, namely Semantic\nRole Labeling Guided Out-of-distribution Detection (SRLOOD), that separates,\nextracts, and learns the semantic role labeling (SRL) guided fine-grained local\nfeature representations from different arguments of a sentence and the global\nfeature representations of the full sentence using a margin-based contrastive\nloss. A novel self-supervised approach is also introduced to enhance such\nglobal-local feature learning by predicting the SRL extracted role. The\nresulting model achieves SOTA performance on four OOD benchmarks, indicating\nthe effectiveness of our approach. The code is publicly accessible via\n\\url{https://github.com/cytai/SRLOOD}.", "published": "2023-05-29 11:34:14", "link": "http://arxiv.org/abs/2305.18026v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Corpus for Sentence-level Subjectivity Detection on English News\n  Articles", "abstract": "We develop novel annotation guidelines for sentence-level subjectivity\ndetection, which are not limited to language-specific cues. We use our\nguidelines to collect NewsSD-ENG, a corpus of 638 objective and 411 subjective\nsentences extracted from English news articles on controversial topics. Our\ncorpus paves the way for subjectivity detection in English and across other\nlanguages without relying on language-specific tools, such as lexicons or\nmachine translation. We evaluate state-of-the-art multilingual\ntransformer-based models on the task in mono-, multi-, and cross-language\nsettings. For this purpose, we re-annotate an existing Italian corpus. We\nobserve that models trained in the multilingual setting achieve the best\nperformance on the task.", "published": "2023-05-29 11:54:50", "link": "http://arxiv.org/abs/2305.18034v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BigTranslate: Augmenting Large Language Models with Multilingual\n  Translation Capability over 100 Languages", "abstract": "Large language models (LLMs) demonstrate promising translation performance\namong various natural languages. However, many LLMs especially the open-sourced\nones, such as BLOOM and LLaMA, are English-dominant and support only dozens of\nnatural languages, making the potential of LLMs on language translation less\nexplored. In this work, we present BigTranslate which adapts LLaMA that covers\nonly 20 languages and enhances it with multilingual translation capability on\nmore than 100 languages. BigTranslate is built upon LLaMA-13B and it is\noptimized in three steps. First, we continue training LLaMA with massive\nChinese monolingual data. Second, we continue training the model with a\nlarge-scale parallel dataset that covers 102 natural languages. Third, we\ninstruct-tune the foundation model with multilingual translation instructions,\nleading to our BigTranslate model. The preliminary experiments on multilingual\ntranslation show that BigTranslate performs comparably with ChatGPT and Google\nTranslate in many languages and even outperforms ChatGPT in 8 language pairs.\nWe release the BigTranslate model and hope it can advance the research\nprogress.", "published": "2023-05-29 14:07:52", "link": "http://arxiv.org/abs/2305.18098v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extrinsic Factors Affecting the Accuracy of Biomedical NER", "abstract": "Biomedical named entity recognition (NER) is a critial task that aims to\nidentify structured information in clinical text, which is often replete with\ncomplex, technical terms and a high degree of variability. Accurate and\nreliable NER can facilitate the extraction and analysis of important biomedical\ninformation, which can be used to improve downstream applications including the\nhealthcare system. However, NER in the biomedical domain is challenging due to\nlimited data availability, as the high expertise, time, and expenses are\nrequired to annotate its data. In this paper, by using the limited data, we\nexplore various extrinsic factors including the corpus annotation scheme, data\naugmentation techniques, semi-supervised learning and Brill transformation, to\nimprove the performance of a NER model on a clinical text dataset (i2b2 2012,\n\\citet{sun-rumshisky-uzuner:2013}). Our experiments demonstrate that these\napproaches can significantly improve the model's F1 score from original 73.74\nto 77.55. Our findings suggest that considering different extrinsic factors and\ncombining these techniques is a promising approach for improving NER\nperformance in the biomedical domain where the size of data is limited.", "published": "2023-05-29 15:29:49", "link": "http://arxiv.org/abs/2305.18152v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do Large Language Models Know What They Don't Know?", "abstract": "Large language models (LLMs) have a wealth of knowledge that allows them to\nexcel in various Natural Language Processing (NLP) tasks. Current research\nfocuses on enhancing their performance within their existing knowledge. Despite\ntheir vast knowledge, LLMs are still limited by the amount of information they\ncan accommodate and comprehend. Therefore, the ability to understand their own\nlimitations on the unknows, referred to as self-knowledge, is of paramount\nimportance. This study aims to evaluate LLMs' self-knowledge by assessing their\nability to identify unanswerable or unknowable questions. We introduce an\nautomated methodology to detect uncertainty in the responses of these models,\nproviding a novel measure of their self-knowledge. We further introduce a\nunique dataset, SelfAware, consisting of unanswerable questions from five\ndiverse categories and their answerable counterparts. Our extensive analysis,\ninvolving 20 LLMs including GPT-3, InstructGPT, and LLaMA, discovering an\nintrinsic capacity for self-knowledge within these models. Moreover, we\ndemonstrate that in-context learning and instruction tuning can further enhance\nthis self-knowledge. Despite this promising insight, our findings also\nhighlight a considerable gap between the capabilities of these models and human\nproficiency in recognizing the limits of their knowledge.", "published": "2023-05-29 15:30:13", "link": "http://arxiv.org/abs/2305.18153v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LM-CPPF: Paraphrasing-Guided Data Augmentation for Contrastive\n  Prompt-Based Few-Shot Fine-Tuning", "abstract": "In recent years, there has been significant progress in developing\npre-trained language models for NLP. However, these models often struggle when\nfine-tuned on small datasets. To address this issue, researchers have proposed\nvarious adaptation approaches. Prompt-based tuning is arguably the most common\nway, especially for larger models. Previous research shows that adding\ncontrastive learning to prompt-based fine-tuning is effective as it helps the\nmodel generate embeddings that are more distinguishable between classes, and it\ncan also be more sample-efficient as the model learns from positive and\nnegative examples simultaneously. One of the most important components of\ncontrastive learning is data augmentation, but unlike computer vision,\neffective data augmentation for NLP is still challenging. This paper proposes\nLM-CPPF, Contrastive Paraphrasing-guided Prompt-based Fine-tuning of Language\nModels, which leverages prompt-based few-shot paraphrasing using generative\nlanguage models, especially large language models such as GPT-3 and OPT-175B,\nfor data augmentation. Our experiments on multiple text classification\nbenchmarks show that this augmentation method outperforms other methods, such\nas easy data augmentation, back translation, and multiple templates.", "published": "2023-05-29 15:59:51", "link": "http://arxiv.org/abs/2305.18169v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging Training Data in Few-Shot Prompting for Numerical Reasoning", "abstract": "Chain-of-thought (CoT) prompting with large language models has proven\neffective in numerous natural language processing tasks, but designing prompts\nthat generalize well to diverse problem types can be challenging, especially in\nthe context of math word problem (MWP) solving. Additionally, it is common to\nhave a large amount of training data that have a better diversity coverage but\nCoT annotations are not available, which limits the use of supervised learning\ntechniques. To address these issues, we investigate two approaches to leverage\nthe training data in a few-shot prompting scenario: dynamic program prompting\nand program distillation. Our approach is largely inspired by Gao et al.,\n(2022), where they proposed to replace the CoT with the programs as the\nintermediate reasoning step. Such a prompting strategy allows us to accurately\nverify the answer correctness through program execution in MWP solving. Our\ndynamic program prompting involves annotating the training data by sampling\ncorrect programs from a large language model, while program distillation\ninvolves adapting a smaller model to the program-annotated training data. Our\nexperiments on three standard MWP datasets demonstrate the effectiveness of\nthese approaches, yielding significant improvements over previous baselines for\nprompting and fine-tuning. Our results suggest that leveraging a large amount\nof training data can improve the generalization ability of prompts and boost\nthe performance of fine-tuned small models in MWP solving.", "published": "2023-05-29 16:01:40", "link": "http://arxiv.org/abs/2305.18170v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Syntax and Semantics Meet in the \"Middle\": Probing the Syntax-Semantics\n  Interface of LMs Through Agentivity", "abstract": "Recent advances in large language models have prompted researchers to examine\ntheir abilities across a variety of linguistic tasks, but little has been done\nto investigate how models handle the interactions in meaning across words and\nlarger syntactic forms -- i.e. phenomena at the intersection of syntax and\nsemantics. We present the semantic notion of agentivity as a case study for\nprobing such interactions. We created a novel evaluation dataset by utilitizing\nthe unique linguistic properties of a subset of optionally transitive English\nverbs. This dataset was used to prompt varying sizes of three model classes to\nsee if they are sensitive to agentivity at the lexical level, and if they can\nappropriately employ these word-level priors given a specific syntactic\ncontext. Overall, GPT-3 text-davinci-003 performs extremely well across all\nexperiments, outperforming all other models tested by far. In fact, the results\nare even better correlated with human judgements than both syntactic and\nsemantic corpus statistics. This suggests that LMs may potentially serve as\nmore useful tools for linguistic annotation, theory testing, and discovery than\nselect corpora for certain tasks. Code is available at\nhttps://github.com/lindiatjuatja/lm_sem", "published": "2023-05-29 16:24:01", "link": "http://arxiv.org/abs/2305.18185v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contextual Knowledge Learning For Dialogue Generation", "abstract": "Incorporating conversational context and knowledge into dialogue generation\nmodels has been essential for improving the quality of the generated responses.\nThe context, comprising utterances from previous dialogue exchanges, is used as\na source of content for response generation and as a means of selecting\nexternal knowledge. However, to avoid introducing irrelevant content, it is key\nto enable fine-grained scoring of context and knowledge. In this paper, we\npresent a novel approach to context and knowledge weighting as an integral part\nof model training. We guide the model training through a Contextual Knowledge\nLearning (CKL) process which involves Latent Vectors for context and knowledge,\nrespectively. CKL Latent Vectors capture the relationship between context,\nknowledge, and responses through weak supervision and enable differential\nweighting of context utterances and knowledge sentences during the training\nprocess. Experiments with two standard datasets and human evaluation\ndemonstrate that CKL leads to a significant improvement compared with the\nperformance of six strong baseline models and shows robustness with regard to\nreduced sizes of training sets.", "published": "2023-05-29 16:54:10", "link": "http://arxiv.org/abs/2305.18200v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Critical Evaluation of Evaluations for Long-form Question Answering", "abstract": "Long-form question answering (LFQA) enables answering a wide range of\nquestions, but its flexibility poses enormous challenges for evaluation. We\nperform the first targeted study of the evaluation of long-form answers,\ncovering both human and automatic evaluation practices. We hire domain experts\nin seven areas to provide preference judgments over pairs of answers, along\nwith free-form justifications for their choices. We present a careful analysis\nof experts' evaluation, which focuses on new aspects such as the\ncomprehensiveness of the answer. Next, we examine automatic text generation\nmetrics, finding that no existing metrics are predictive of human preference\njudgments. However, some metrics correlate with fine-grained aspects of answers\n(e.g., coherence). We encourage future work to move away from a single \"overall\nscore\" of the answer and adopt a multi-faceted evaluation, targeting aspects\nsuch as factuality and completeness. We publicly release all of our annotations\nand code to spur future work into LFQA evaluation.", "published": "2023-05-29 16:54:24", "link": "http://arxiv.org/abs/2305.18201v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transformer Language Models Handle Word Frequency in Prediction Head", "abstract": "Prediction head is a crucial component of Transformer language models.\nDespite its direct impact on prediction, this component has often been\noverlooked in analyzing Transformers. In this study, we investigate the inner\nworkings of the prediction head, specifically focusing on bias parameters. Our\nexperiments with BERT and GPT-2 models reveal that the biases in their word\nprediction heads play a significant role in the models' ability to reflect word\nfrequency in a corpus, aligning with the logit adjustment method commonly used\nin long-tailed learning. We also quantify the effect of controlling the biases\nin practical auto-regressive text generation scenarios; under a particular\nsetting, more diverse text can be generated without compromising text quality.", "published": "2023-05-29 17:59:15", "link": "http://arxiv.org/abs/2305.18294v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SlimFit: Memory-Efficient Fine-Tuning of Transformer-based Models Using\n  Training Dynamics", "abstract": "Transformer-based models, such as BERT and ViT, have achieved\nstate-of-the-art results across different natural language processing (NLP) and\ncomputer vision (CV) tasks. However, these models are extremely memory\nintensive during their fine-tuning process, making them difficult to deploy on\nGPUs with limited memory resources. To address this issue, we introduce a new\ntool called SlimFit that reduces the memory requirements of these models by\ndynamically analyzing their training dynamics and freezing less-contributory\nlayers during fine-tuning. The layers to freeze are chosen using a runtime\ninter-layer scheduling algorithm. SlimFit adopts quantization and pruning for\nparticular layers to balance the load of dynamic activations and to minimize\nthe memory footprint of static activations, where static activations refer to\nthose that cannot be discarded regardless of freezing. This allows SlimFit to\nfreeze up to 95% of layers and reduce the overall on-device GPU memory usage of\ntransformer-based models such as ViT and BERT by an average of 2.2x, across\ndifferent NLP and CV benchmarks/datasets such as GLUE, SQuAD 2.0, CIFAR-10,\nCIFAR-100 and ImageNet with an average degradation of 0.2% in accuracy. For\nsuch NLP and CV tasks, SlimFit can reduce up to 3.1x the total on-device memory\nusage with an accuracy degradation of only up to 0.4%. As a result, while\nfine-tuning of ViT on ImageNet and BERT on SQuAD 2.0 with a batch size of 128\nrequires 3 and 2 32GB GPUs respectively, SlimFit enables their fine-tuning on a\nsingle 32GB GPU without any significant accuracy degradation.", "published": "2023-05-29 17:50:52", "link": "http://arxiv.org/abs/2305.18513v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TreeMAN: Tree-enhanced Multimodal Attention Network for ICD Coding", "abstract": "ICD coding is designed to assign the disease codes to electronic health\nrecords (EHRs) upon discharge, which is crucial for billing and clinical\nstatistics. In an attempt to improve the effectiveness and efficiency of manual\ncoding, many methods have been proposed to automatically predict ICD codes from\nclinical notes. However, most previous works ignore the decisive information\ncontained in structured medical data in EHRs, which is hard to be captured from\nthe noisy clinical notes. In this paper, we propose a Tree-enhanced Multimodal\nAttention Network (TreeMAN) to fuse tabular features and textual features into\nmultimodal representations by enhancing the text representations with\ntree-based features via the attention mechanism. Tree-based features are\nconstructed according to decision trees learned from structured multimodal\nmedical data, which capture the decisive information about ICD coding. We can\napply the same multi-label classifier from previous text models to the\nmultimodal representations to predict ICD codes. Experiments on two MIMIC\ndatasets show that our method outperforms prior state-of-the-art ICD coding\napproaches. The code is available at https://github.com/liu-zichen/TreeMAN.", "published": "2023-05-29 19:37:26", "link": "http://arxiv.org/abs/2305.18576v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Information Association for Language Model Updating by Mitigating\n  LM-Logical Discrepancy", "abstract": "Large Language Models~(LLMs) struggle with providing current information due\nto the outdated pre-training data. Existing methods for updating LLMs, such as\nknowledge editing and continual fine-tuning, have significant drawbacks in\ngeneralizability of new information and the requirements on structured updating\ncorpus. We identify the core challenge behind these drawbacks: the LM-logical\ndiscrepancy featuring the difference between language modeling probabilities\nand logical probabilities. To evaluate and address the core challenge, we\npropose a new task formulation of the information updating task that only\nrequires the provision of an unstructured updating corpus and evaluates the\nperformance of information updating on the generalizability to question-answer\npairs pertaining to the updating information. We further propose a novel and\neffective pipeline approach for the task, highlighting a self-prompting-based\nquestion-answer generation process and a associative distillation methods to\nbridge the LM-logical discrepancy. We develop two datasets for evaluation, one\nsourced from news articles published in March and April 2023, and the other\nfrom the Natural Questions benchmark. Experimental results demonstrate the\nsuperiority of our approach, significantly increasing the factual consistency\nscore (on a scale from 0 to 1) by up to 0.16. Furthermore, our method\neffectively mitigates forgetting utilizing a compact replay buffer with only\n2.3% of the training tokens.", "published": "2023-05-29 19:48:37", "link": "http://arxiv.org/abs/2305.18582v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Method for Studying Semantic Construal in Grammatical Constructions\n  with Interpretable Contextual Embedding Spaces", "abstract": "We study semantic construal in grammatical constructions using large language\nmodels. First, we project contextual word embeddings into three interpretable\nsemantic spaces, each defined by a different set of psycholinguistic feature\nnorms. We validate these interpretable spaces and then use them to\nautomatically derive semantic characterizations of lexical items in two\ngrammatical constructions: nouns in subject or object position within the same\nsentence, and the AANN construction (e.g., `a beautiful three days'). We show\nthat a word in subject position is interpreted as more agentive than the very\nsame word in object position, and that the nouns in the AANN construction are\ninterpreted as more measurement-like than when in the canonical alternation.\nOur method can probe the distributional meaning of syntactic constructions at a\ntemplatic level, abstracted away from specific lexemes.", "published": "2023-05-29 20:30:38", "link": "http://arxiv.org/abs/2305.18598v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Short Answer Grading Using One-shot Prompting and Text Similarity\n  Scoring Model", "abstract": "In this study, we developed an automated short answer grading (ASAG) model\nthat provided both analytic scores and final holistic scores. Short answer\nitems typically consist of multiple sub-questions, and providing an analytic\nscore and the text span relevant to each sub-question can increase the\ninterpretability of the automated scores. Furthermore, they can be used to\ngenerate actionable feedback for students. Despite these advantages, most\nstudies have focused on predicting only holistic scores due to the difficulty\nin constructing dataset with manual annotations. To address this difficulty, we\nused large language model (LLM)-based one-shot prompting and a text similarity\nscoring model with domain adaptation using small manually annotated dataset.\nThe accuracy and quadratic weighted kappa of our model were 0.67 and 0.71 on a\nsubset of the publicly available ASAG dataset. The model achieved a substantial\nimprovement over the majority baseline.", "published": "2023-05-29 22:05:29", "link": "http://arxiv.org/abs/2305.18638v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Representation Of Lexical Stylistic Features In Language Models'\n  Embedding Space", "abstract": "The representation space of pretrained Language Models (LMs) encodes rich\ninformation about words and their relationships (e.g., similarity, hypernymy,\npolysemy) as well as abstract semantic notions (e.g., intensity). In this\npaper, we demonstrate that lexical stylistic notions such as complexity,\nformality, and figurativeness, can also be identified in this space. We show\nthat it is possible to derive a vector representation for each of these\nstylistic notions from only a small number of seed pairs. Using these vectors,\nwe can characterize new texts in terms of these dimensions by performing simple\ncalculations in the corresponding embedding space. We conduct experiments on\nfive datasets and find that static embeddings encode these features more\naccurately at the level of words and phrases, whereas contextualized LMs\nperform better on sentences. The lower performance of contextualized\nrepresentations at the word level is partially attributable to the anisotropy\nof their vector space, which can be corrected to some extent using techniques\nlike standardization.", "published": "2023-05-29 23:44:26", "link": "http://arxiv.org/abs/2305.18657v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring the Compositional Generalization in Context Dependent\n  Text-to-SQL Parsing", "abstract": "In the context-dependent Text-to-SQL task, the generated SQL statements are\nrefined iteratively based on the user input utterance from each interaction.\nThe input text from each interaction can be viewed as component modifications\nto the previous SQL statements, which could be further extracted as the\nmodification patterns. Since these modification patterns could also be combined\nwith other SQL statements, the models are supposed to have the compositional\ngeneralization to these novel combinations. This work is the first exploration\nof compositional generalization in context-dependent Text-to-SQL scenarios. To\nfacilitate related studies, we constructed two challenging benchmarks named\n\\textsc{CoSQL-CG} and \\textsc{SParC-CG} by recombining the modification\npatterns and existing SQL statements. The following experiments show that all\ncurrent models struggle on our proposed benchmarks. Furthermore, we found that\nbetter aligning the previous SQL statements with the input utterance could give\nmodels better compositional generalization ability. Based on these\nobservations, we propose a method named \\texttt{p-align} to improve the\ncompositional generalization of Text-to-SQL models. Further experiments\nvalidate the effectiveness of our method. Source code and data are available.", "published": "2023-05-29 12:36:56", "link": "http://arxiv.org/abs/2306.04480v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "ContrastNER: Contrastive-based Prompt Tuning for Few-shot NER", "abstract": "Prompt-based language models have produced encouraging results in numerous\napplications, including Named Entity Recognition (NER) tasks. NER aims to\nidentify entities in a sentence and provide their types. However, the strong\nperformance of most available NER approaches is heavily dependent on the design\nof discrete prompts and a verbalizer to map the model-predicted outputs to\nentity categories, which are complicated undertakings. To address these\nchallenges, we present ContrastNER, a prompt-based NER framework that employs\nboth discrete and continuous tokens in prompts and uses a contrastive learning\napproach to learn the continuous prompts and forecast entity types. The\nexperimental results demonstrate that ContrastNER obtains competitive\nperformance to the state-of-the-art NER methods in high-resource settings and\noutperforms the state-of-the-art models in low-resource circumstances without\nrequiring extensive manual prompt engineering and verbalizer design.", "published": "2023-05-29 08:24:42", "link": "http://arxiv.org/abs/2305.17951v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Faithfulness Tests for Natural Language Explanations", "abstract": "Explanations of neural models aim to reveal a model's decision-making process\nfor its predictions. However, recent work shows that current methods giving\nexplanations such as saliency maps or counterfactuals can be misleading, as\nthey are prone to present reasons that are unfaithful to the model's inner\nworkings. This work explores the challenging question of evaluating the\nfaithfulness of natural language explanations (NLEs). To this end, we present\ntwo tests. First, we propose a counterfactual input editor for inserting\nreasons that lead to counterfactual predictions but are not reflected by the\nNLEs. Second, we reconstruct inputs from the reasons stated in the generated\nNLEs and check how often they lead to the same predictions. Our tests can\nevaluate emerging NLE models, proving a fundamental tool in the development of\nfaithful NLEs.", "published": "2023-05-29 11:40:37", "link": "http://arxiv.org/abs/2305.18029v2", "categories": ["cs.CL", "cs.AI", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Improving Textless Spoken Language Understanding with Discrete Units as\n  Intermediate Target", "abstract": "Spoken Language Understanding (SLU) is a task that aims to extract semantic\ninformation from spoken utterances. Previous research has made progress in\nend-to-end SLU by using paired speech-text data, such as pre-trained Automatic\nSpeech Recognition (ASR) models or paired text as intermediate targets.\nHowever, acquiring paired transcripts is expensive and impractical for\nunwritten languages. On the other hand, Textless SLU extracts semantic\ninformation from speech without utilizing paired transcripts. However, the\nabsence of intermediate targets and training guidance for textless SLU often\nresults in suboptimal performance. In this work, inspired by the\ncontent-disentangled discrete units from self-supervised speech models, we\nproposed to use discrete units as intermediate guidance to improve textless SLU\nperformance. Our method surpasses the baseline method on five SLU benchmark\ncorpora. Additionally, we find that unit guidance facilitates few-shot learning\nand enhances the model's ability to handle noise.", "published": "2023-05-29 14:00:24", "link": "http://arxiv.org/abs/2305.18096v2", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Writing user personas with Large Language Models: Testing phase 6 of a\n  Thematic Analysis of semi-structured interviews", "abstract": "The goal of this paper is establishing if we can satisfactorily perform a\nThematic Analysis (TA) of semi-structured interviews using a Large Language\nModel (more precisely GPT3.5-Turbo). Building on previous work by the author,\nwhich established an embryonal process for conducting a TA with the model, this\npaper will perform a further analysis and then cover the last phase of a TA\n(phase 6), which entails the writing up of the result. This phase was not\ncovered by the previous work. In particular, the focus will be on using the\nresults of a TA done with the LLM on a dataset of user interviews, for writing\nuser personas, with the model building on the TA to produce the personas\nnarratives. User personas are models of real users, usually built from a data\nanalysis like interviews with a sample of users. User personas are tools often\nused in User Centered Design processes. The paper shows that the model can\nbuild basic user personas with an acceptable quality deriving them from themes,\nand that the model can serve for the generation of ideas for user personas.", "published": "2023-05-29 14:09:14", "link": "http://arxiv.org/abs/2305.18099v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Medical Dialogue Generation via Dual Flow Modeling", "abstract": "Medical dialogue systems (MDS) aim to provide patients with medical services,\nsuch as diagnosis and prescription. Since most patients cannot precisely\ndescribe their symptoms, dialogue understanding is challenging for MDS.\nPrevious studies mainly addressed this by extracting the mentioned medical\nentities as critical dialogue history information. In this work, we argue that\nit is also essential to capture the transitions of the medical entities and the\ndoctor's dialogue acts in each turn, as they help the understanding of how the\ndialogue flows and enhance the prediction of the entities and dialogue acts to\nbe adopted in the following turn. Correspondingly, we propose a Dual Flow\nenhanced Medical (DFMed) dialogue generation framework. It extracts the medical\nentities and dialogue acts used in the dialogue history and models their\ntransitions with an entity-centric graph flow and a sequential act flow,\nrespectively. We employ two sequential models to encode them and devise an\ninterweaving component to enhance their interactions. Experiments on two\ndatasets demonstrate that our method exceeds baselines in both automatic and\nmanual evaluations.", "published": "2023-05-29 14:23:34", "link": "http://arxiv.org/abs/2305.18109v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GripRank: Bridging the Gap between Retrieval and Generation via the\n  Generative Knowledge Improved Passage Ranking", "abstract": "Retrieval-enhanced text generation has shown remarkable progress on\nknowledge-intensive language tasks, such as open-domain question answering and\nknowledge-enhanced dialogue generation, by leveraging passages retrieved from a\nlarge passage corpus for delivering a proper answer given the input query.\nHowever, the retrieved passages are not ideal for guiding answer generation\nbecause of the discrepancy between retrieval and generation, i.e., the\ncandidate passages are all treated equally during the retrieval procedure\nwithout considering their potential to generate a proper answer. This\ndiscrepancy makes a passage retriever deliver a sub-optimal collection of\ncandidate passages to generate the answer. In this paper, we propose the\nGeneRative Knowledge Improved Passage Ranking (GripRank) approach, addressing\nthe above challenge by distilling knowledge from a generative passage estimator\n(GPE) to a passage ranker, where the GPE is a generative language model used to\nmeasure how likely the candidate passages can generate the proper answer. We\nrealize the distillation procedure by teaching the passage ranker learning to\nrank the passages ordered by the GPE. Furthermore, we improve the distillation\nquality by devising a curriculum knowledge distillation mechanism, which allows\nthe knowledge provided by the GPE can be progressively distilled to the ranker\nthrough an easy-to-hard curriculum, enabling the passage ranker to correctly\nrecognize the provenance of the answer from many plausible candidates. We\nconduct extensive experiments on four datasets across three knowledge-intensive\nlanguage tasks. Experimental results show advantages over the state-of-the-art\nmethods for both passage ranking and answer generation on the KILT benchmark.", "published": "2023-05-29 15:15:53", "link": "http://arxiv.org/abs/2305.18144v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multiscale Positive-Unlabeled Detection of AI-Generated Texts", "abstract": "Recent releases of Large Language Models (LLMs), e.g. ChatGPT, are\nastonishing at generating human-like texts, but they may impact the\nauthenticity of texts. Previous works proposed methods to detect these\nAI-generated texts, including simple ML classifiers, pretrained-model-based\nzero-shot methods, and finetuned language classification models. However,\nmainstream detectors always fail on short texts, like SMSes, Tweets, and\nreviews. In this paper, a Multiscale Positive-Unlabeled (MPU) training\nframework is proposed to address the difficulty of short-text detection without\nsacrificing long-texts. Firstly, we acknowledge the human-resemblance property\nof short machine texts, and rephrase AI text detection as a partial\nPositive-Unlabeled (PU) problem by regarding these short machine texts as\npartially ``unlabeled\". Then in this PU context, we propose the\nlength-sensitive Multiscale PU Loss, where a recurrent model in abstraction is\nused to estimate positive priors of scale-variant corpora. Additionally, we\nintroduce a Text Multiscaling module to enrich training corpora. Experiments\nshow that our MPU method augments detection performance on long AI-generated\ntexts, and significantly improves short-text detection of language model\ndetectors. Language Models trained with MPU could outcompete existing detectors\non various short-text and long-text detection benchmarks. The codes are\navailable at\nhttps://github.com/mindspore-lab/mindone/tree/master/examples/detect_chatgpt\nand https://github.com/YuchuanTian/AIGC_text_detector.", "published": "2023-05-29 15:25:00", "link": "http://arxiv.org/abs/2305.18149v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring Effectiveness of GPT-3 in Grammatical Error Correction: A\n  Study on Performance and Controllability in Prompt-Based Methods", "abstract": "Large-scale pre-trained language models such as GPT-3 have shown remarkable\nperformance across various natural language processing tasks. However, applying\nprompt-based methods with GPT-3 for Grammatical Error Correction (GEC) tasks\nand their controllability remains underexplored. Controllability in GEC is\ncrucial for real-world applications, particularly in educational settings,\nwhere the ability to tailor feedback according to learner levels and specific\nerror types can significantly enhance the learning process. This paper\ninvestigates the performance and controllability of prompt-based methods with\nGPT-3 for GEC tasks using zero-shot and few-shot setting. We explore the impact\nof task instructions and examples on GPT-3's output, focusing on controlling\naspects such as minimal edits, fluency edits, and learner levels. Our findings\ndemonstrate that GPT-3 could effectively perform GEC tasks, outperforming\nexisting supervised and unsupervised approaches. We also showed that GPT-3\ncould achieve controllability when appropriate task instructions and examples\nare given.", "published": "2023-05-29 15:31:29", "link": "http://arxiv.org/abs/2305.18156v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Do Language Models Know When They're Hallucinating References?", "abstract": "State-of-the-art language models (LMs) are notoriously susceptible to\ngenerating hallucinated information. Such inaccurate outputs not only undermine\nthe reliability of these models but also limit their use and raise serious\nconcerns about misinformation and propaganda. In this work, we focus on\nhallucinated book and article references and present them as the \"model\norganism\" of language model hallucination research, due to their frequent and\neasy-to-discern nature. We posit that if a language model cites a particular\nreference in its output, then it should ideally possess sufficient information\nabout its authors and content, among other relevant details. Using this basic\ninsight, we illustrate that one can identify hallucinated references without\never consulting any external resources, by asking a set of direct or indirect\nqueries to the language model about the references. These queries can be\nconsidered as \"consistency checks.\" Our findings highlight that while LMs,\nincluding GPT-4, often produce inconsistent author lists for hallucinated\nreferences, they also often accurately recall the authors of real references.\nIn this sense, the LM can be said to \"know\" when it is hallucinating\nreferences. Furthermore, these findings show how hallucinated references can be\ndissected to shed light on their nature. Replication code and results can be\nfound at https://github.com/microsoft/hallucinated-references.", "published": "2023-05-29 17:12:03", "link": "http://arxiv.org/abs/2305.18248v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LaFTer: Label-Free Tuning of Zero-shot Classifier using Language and\n  Unlabeled Image Collections", "abstract": "Recently, large-scale pre-trained Vision and Language (VL) models have set a\nnew state-of-the-art (SOTA) in zero-shot visual classification enabling\nopen-vocabulary recognition of potentially unlimited set of categories defined\nas simple language prompts. However, despite these great advances, the\nperformance of these zeroshot classifiers still falls short of the results of\ndedicated (closed category set) classifiers trained with supervised fine\ntuning. In this paper we show, for the first time, how to reduce this gap\nwithout any labels and without any paired VL data, using an unlabeled image\ncollection and a set of texts auto-generated using a Large Language Model (LLM)\ndescribing the categories of interest and effectively substituting labeled\nvisual instances of those categories. Using our label-free approach, we are\nable to attain significant performance improvements over the zero-shot\nperformance of the base VL model and other contemporary methods and baselines\non a wide variety of datasets, demonstrating absolute improvement of up to\n11.7% (3.8% on average) in the label-free setting. Moreover, despite our\napproach being label-free, we observe 1.3% average gains over leading few-shot\nprompting baselines that do use 5-shot supervision.", "published": "2023-05-29 17:56:35", "link": "http://arxiv.org/abs/2305.18287v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Test-Time Training on Nearest Neighbors for Large Language Models", "abstract": "Many recent efforts augment language models with retrieval, by adding\nretrieved data to the input context. For this approach to succeed, the\nretrieved data must be added at both training and test time. Moreover, as input\nlength grows linearly with the size of retrieved data, cost in computation and\nmemory grows quadratically for modern Transformers. To avoid these\ncomplications, we simply fine-tune the model on retrieved data at test time,\nusing its standard training setup. We build a large-scale distributed index\nbased on text embeddings of the Pile dataset. For each test input, our system\nretrieves its neighbors and fine-tunes the model on their text. Surprisingly,\nretrieving and training on as few as 20 neighbors, each for only one gradient\niteration, drastically improves performance across more than 20 language\nmodeling tasks in the Pile. For example, test-time training with nearest\nneighbors significantly narrows the performance gap between a small GPT-2 and a\nGPT-Neo model more than 10 times larger. Sufficient index quality and size,\nhowever, are necessary. Our work establishes a first baseline of test-time\ntraining for language modeling.", "published": "2023-05-29 08:03:28", "link": "http://arxiv.org/abs/2305.18466v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Code Prompting: a Neural Symbolic Method for Complex Reasoning in Large\n  Language Models", "abstract": "Large language models (LLMs) have scaled up to unlock a wide range of complex\nreasoning tasks with the aid of various prompting methods. However, current\nprompting methods generate natural language intermediate steps to help\nreasoning, which can cause imperfect task reduction and confusion. To mitigate\nsuch limitations, we explore code prompting, a neural symbolic prompting method\nwith both zero-shot and few-shot versions which triggers code as intermediate\nsteps. We conduct experiments on 7 widely-used benchmarks involving symbolic\nreasoning and arithmetic reasoning. Code prompting generally outperforms\nchain-of-thought (CoT) prompting. To further understand the performance and\nlimitations of code prompting, we perform extensive ablation studies and error\nanalyses, and identify several exclusive advantages of using symbolic\npromptings compared to natural language. We also consider the ensemble of code\nprompting and CoT prompting to combine the strengths of both. Finally, we show\nthrough experiments how code annotations and their locations affect code\nprompting.", "published": "2023-05-29 15:14:09", "link": "http://arxiv.org/abs/2305.18507v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Forgotten Knowledge: Examining the Citational Amnesia in NLP", "abstract": "Citing papers is the primary method through which modern scientific writing\ndiscusses and builds on past work. Collectively, citing a diverse set of papers\n(in time and area of study) is an indicator of how widely the community is\nreading. Yet, there is little work looking at broad temporal patterns of\ncitation. This work systematically and empirically examines: How far back in\ntime do we tend to go to cite papers? How has that changed over time, and what\nfactors correlate with this citational attention/amnesia? We chose NLP as our\ndomain of interest and analyzed approximately 71.5K papers to show and quantify\nseveral key trends in citation. Notably, around 62% of cited papers are from\nthe immediate five years prior to publication, whereas only about 17% are more\nthan ten years old. Furthermore, we show that the median age and age diversity\nof cited papers were steadily increasing from 1990 to 2014, but since then, the\ntrend has reversed, and current NLP papers have an all-time low temporal\ncitation diversity. Finally, we show that unlike the 1990s, the highly cited\npapers in the last decade were also papers with the least citation diversity,\nlikely contributing to the intense (and arguably harmful) recency focus. Code,\ndata, and a demo are available on the project homepage.", "published": "2023-05-29 18:30:34", "link": "http://arxiv.org/abs/2305.18554v2", "categories": ["cs.CL", "cs.DL"], "primary_category": "cs.CL"}
{"title": "Exploiting Explainability to Design Adversarial Attacks and Evaluate\n  Attack Resilience in Hate-Speech Detection Models", "abstract": "The advent of social media has given rise to numerous ethical challenges,\nwith hate speech among the most significant concerns. Researchers are\nattempting to tackle this problem by leveraging hate-speech detection and\nemploying language models to automatically moderate content and promote civil\ndiscourse. Unfortunately, recent studies have revealed that hate-speech\ndetection systems can be misled by adversarial attacks, raising concerns about\ntheir resilience. While previous research has separately addressed the\nrobustness of these models under adversarial attacks and their\ninterpretability, there has been no comprehensive study exploring their\nintersection. The novelty of our work lies in combining these two critical\naspects, leveraging interpretability to identify potential vulnerabilities and\nenabling the design of targeted adversarial attacks. We present a comprehensive\nand comparative analysis of adversarial robustness exhibited by various\nhate-speech detection models. Our study evaluates the resilience of these\nmodels against adversarial attacks using explainability techniques. To gain\ninsights into the models' decision-making processes, we employ the Local\nInterpretable Model-agnostic Explanations (LIME) framework. Based on the\nexplainability results obtained by LIME, we devise and execute targeted attacks\non the text by leveraging the TextAttack tool. Our findings enhance the\nunderstanding of the vulnerabilities and strengths exhibited by\nstate-of-the-art hate-speech detection models. This work underscores the\nimportance of incorporating explainability in the development and evaluation of\nsuch models to enhance their resilience against adversarial attacks.\nUltimately, this work paves the way for creating more robust and reliable\nhate-speech detection systems, fostering safer online environments and\npromoting ethical discourse on social media platforms.", "published": "2023-05-29 19:59:40", "link": "http://arxiv.org/abs/2305.18585v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Alfred: A System for Prompted Weak Supervision", "abstract": "Alfred is the first system for programmatic weak supervision (PWS) that\ncreates training data for machine learning by prompting. In contrast to typical\nPWS systems where weak supervision sources are programs coded by experts,\nAlfred enables users to encode their subject matter expertise via natural\nlanguage prompts for language and vision-language models. Alfred provides a\nsimple Python interface for the key steps of this emerging paradigm, with a\nhigh-throughput backend for large-scale data labeling. Users can quickly\ncreate, evaluate, and refine their prompt-based weak supervision sources; map\nthe results to weak labels; and resolve their disagreements with a label model.\nAlfred enables a seamless local development experience backed by models served\nfrom self-managed computing clusters. It automatically optimizes the execution\nof prompts with optimized batching mechanisms. We find that this optimization\nimproves query throughput by 2.9x versus a naive approach. We present two\nexample use cases demonstrating Alfred on YouTube comment spam detection and\npet breeds classification. Alfred is open source, available at\nhttps://github.com/BatsResearch/alfred.", "published": "2023-05-29 21:16:42", "link": "http://arxiv.org/abs/2305.18623v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "W-procer: Weighted Prototypical Contrastive Learning for Medical\n  Few-Shot Named Entity Recognition", "abstract": "Contrastive learning has become a popular solution for few-shot Name Entity\nRecognization (NER). The conventional configuration strives to reduce the\ndistance between tokens with the same labels and increase the distance between\ntokens with different labels. The effect of this setup may, however, in the\nmedical domain, there are a lot of entities annotated as OUTSIDE (O), and they\nare undesirably pushed apart to other entities that are not labeled as OUTSIDE\n(O) by the current contrastive learning method end up with a noisy prototype\nfor the semantic representation of the label, though there are many OUTSIDE (O)\nlabeled entities are relevant to the labeled entities. To address this\nchallenge, we propose a novel method named Weighted Prototypical Contrastive\nLearning for Medical Few Shot Named Entity Recognization (W-PROCER). Our\napproach primarily revolves around constructing the prototype-based contractive\nloss and weighting network. These components play a crucial role in assisting\nthe model in differentiating the negative samples from OUTSIDE (O) tokens and\nenhancing the discrimination ability of contrastive learning. Experimental\nresults show that our proposed W-PROCER framework significantly outperforms the\nstrong baselines on the three medical benchmark datasets.", "published": "2023-05-29 21:17:52", "link": "http://arxiv.org/abs/2305.18624v5", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Enhanced Chart Understanding in Vision and Language Task via Cross-modal\n  Pre-training on Plot Table Pairs", "abstract": "Building cross-model intelligence that can understand charts and communicate\nthe salient information hidden behind them is an appealing challenge in the\nvision and language(V+L) community. The capability to uncover the underlined\ntable data of chart figures is a critical key to automatic chart understanding.\nWe introduce ChartT5, a V+L model that learns how to interpret table\ninformation from chart images via cross-modal pre-training on plot table pairs.\nSpecifically, we propose two novel pre-training objectives: Masked Header\nPrediction (MHP) and Masked Value Prediction (MVP) to facilitate the model with\ndifferent skills to interpret the table information. We have conducted\nextensive experiments on chart question answering and chart summarization to\nverify the effectiveness of the proposed pre-training strategies. In\nparticular, on the ChartQA benchmark, our ChartT5 outperforms the\nstate-of-the-art non-pretraining methods by over 8% performance gains.", "published": "2023-05-29 22:29:03", "link": "http://arxiv.org/abs/2305.18641v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Datasets for Portuguese Legal Semantic Textual Similarity: Comparing\n  weak supervision and an annotation process approaches", "abstract": "The Brazilian judiciary has a large workload, resulting in a long time to\nfinish legal proceedings. Brazilian National Council of Justice has established\nin Resolution 469/2022 formal guidance for document and process digitalization\nopening up the possibility of using automatic techniques to help with everyday\ntasks in the legal field, particularly in a large number of texts yielded on\nthe routine of law procedures. Notably, Artificial Intelligence (AI) techniques\nallow for processing and extracting useful information from textual data,\npotentially speeding up the process. However, datasets from the legal domain\nrequired by several AI techniques are scarce and difficult to obtain as they\nneed labels from experts. To address this challenge, this article contributes\nwith four datasets from the legal domain, two with documents and metadata but\nunlabeled, and another two labeled with a heuristic aiming at its use in\ntextual semantic similarity tasks. Also, to evaluate the effectiveness of the\nproposed heuristic label process, this article presents a small ground truth\ndataset generated from domain expert annotations. The analysis of ground truth\nlabels highlights that semantic analysis of domain text can be challenging even\nfor domain experts. Also, the comparison between ground truth and heuristic\nlabels shows that heuristic labels are useful.", "published": "2023-05-29 18:27:10", "link": "http://arxiv.org/abs/2306.00007v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Brainformers: Trading Simplicity for Efficiency", "abstract": "Transformers are central to recent successes in natural language processing\nand computer vision. Transformers have a mostly uniform backbone where layers\nalternate between feed-forward and self-attention in order to build a deep\nnetwork. Here we investigate this design choice and find that more complex\nblocks that have different permutations of layer primitives can be more\nefficient. Using this insight, we develop a complex block, named Brainformer,\nthat consists of a diverse sets of layers such as sparsely gated feed-forward\nlayers, dense feed-forward layers, attention layers, and various forms of layer\nnormalization and activation functions. Brainformer consistently outperforms\nthe state-of-the-art dense and sparse Transformers, in terms of both quality\nand efficiency. A Brainformer model with 8 billion activated parameters per\ntoken demonstrates 2x faster training convergence and 5x faster step time\ncompared to its GLaM counterpart. In downstream task evaluation, Brainformer\nalso demonstrates a 3% higher SuperGLUE score with fine-tuning compared to GLaM\nwith a similar number of activated parameters. Finally, Brainformer largely\noutperforms a Primer dense model derived with NAS with similar computation per\ntoken on fewshot evaluations.", "published": "2023-05-29 18:42:01", "link": "http://arxiv.org/abs/2306.00008v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Retraining-free Customized ASR for Enharmonic Words Based on a\n  Named-Entity-Aware Model and Phoneme Similarity Estimation", "abstract": "End-to-end automatic speech recognition (E2E-ASR) has the potential to\nimprove performance, but a specific issue that needs to be addressed is the\ndifficulty it has in handling enharmonic words: named entities (NEs) with the\nsame pronunciation and part of speech that are spelled differently. This often\noccurs with Japanese personal names that have the same pronunciation but\ndifferent Kanji characters. Since such NE words tend to be important keywords,\nASR easily loses user trust if it misrecognizes them. To solve these problems,\nthis paper proposes a novel retraining-free customized method for E2E-ASRs\nbased on a named-entity-aware E2E-ASR model and phoneme similarity estimation.\nExperimental results show that the proposed method improves the target NE\ncharacter error rate by 35.7% on average relative to the conventional E2E-ASR\nmodel when selecting personal names as a target NE.", "published": "2023-05-29 02:10:13", "link": "http://arxiv.org/abs/2305.17846v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Ask an Expert: Leveraging Language Models to Improve Strategic Reasoning\n  in Goal-Oriented Dialogue Models", "abstract": "Existing dialogue models may encounter scenarios which are not\nwell-represented in the training data, and as a result generate responses that\nare unnatural, inappropriate, or unhelpful. We propose the \"Ask an Expert\"\nframework in which the model is trained with access to an \"expert\" which it can\nconsult at each turn. Advice is solicited via a structured dialogue with the\nexpert, and the model is optimized to selectively utilize (or ignore) it given\nthe context and dialogue history. In this work the expert takes the form of an\nLLM. We evaluate this framework in a mental health support domain, where the\nstructure of the expert conversation is outlined by pre-specified prompts which\nreflect a reasoning strategy taught to practitioners in the field. Blenderbot\nmodels utilizing \"Ask an Expert\" show quality improvements across all expert\nsizes, including those with fewer parameters than the dialogue model itself.\nOur best model provides a $\\sim 10\\%$ improvement over baselines, approaching\nhuman-level scores on \"engingingness\" and \"helpfulness\" metrics.", "published": "2023-05-29 04:19:35", "link": "http://arxiv.org/abs/2305.17878v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "TotalDefMeme: A Multi-Attribute Meme dataset on Total Defence in\n  Singapore", "abstract": "Total Defence is a defence policy combining and extending the concept of\nmilitary defence and civil defence. While several countries have adopted total\ndefence as their defence policy, very few studies have investigated its\neffectiveness. With the rapid proliferation of social media and digitalisation,\nmany social studies have been focused on investigating policy effectiveness\nthrough specially curated surveys and questionnaires either through digital\nmedia or traditional forms. However, such references may not truly reflect the\nunderlying sentiments about the target policies or initiatives of interest.\nPeople are more likely to express their sentiment using communication mediums\nsuch as starting topic thread on forums or sharing memes on social media. Using\nSingapore as a case reference, this study aims to address this research gap by\nproposing TotalDefMeme, a large-scale multi-modal and multi-attribute meme\ndataset that captures public sentiments toward Singapore's Total Defence\npolicy. Besides supporting social informatics and public policy analysis of the\nTotal Defence policy, TotalDefMeme can also support many downstream multi-modal\nmachine learning tasks, such as aspect-based stance classification and\nmulti-modal meme clustering. We perform baseline machine learning experiments\non TotalDefMeme and evaluate its technical validity, and present possible\nfuture interdisciplinary research directions and application scenarios using\nthe dataset as a baseline.", "published": "2023-05-29 06:43:37", "link": "http://arxiv.org/abs/2305.17911v1", "categories": ["cs.SI", "cs.AI", "cs.CL", "cs.CV", "I.2.7"], "primary_category": "cs.SI"}
{"title": "Large Language Models are not Fair Evaluators", "abstract": "In this paper, we uncover a systematic bias in the evaluation paradigm of\nadopting large language models~(LLMs), e.g., GPT-4, as a referee to score and\ncompare the quality of responses generated by candidate models. We find that\nthe quality ranking of candidate responses can be easily hacked by simply\naltering their order of appearance in the context. This manipulation allows us\nto skew the evaluation result, making one model appear considerably superior to\nthe other, e.g., Vicuna-13B could beat ChatGPT on 66 over 80 tested queries\nwith ChatGPT as an evaluator. To address this issue, we propose a calibration\nframework with three simple yet effective strategies: 1) Multiple Evidence\nCalibration, which requires the evaluator model to generate multiple evaluation\nevidence before assigning ratings; 2) Balanced Position Calibration, which\naggregates results across various orders to determine the final score; 3)\nHuman-in-the-Loop Calibration, which introduces a balanced position diversity\nentropy to measure the difficulty of each example and seeks human assistance\nwhen needed. We also manually annotate the \"win/tie/lose\" outcomes of responses\nfrom ChatGPT and Vicuna-13B in the Vicuna Benchmark's question prompt, and\nextensive experiments demonstrate that our approach successfully mitigates\nevaluation bias, resulting in closer alignment with human judgments. We release\nour code and human annotation at \\url{https://github.com/i-Eval/FairEval} to\nfacilitate future research.", "published": "2023-05-29 07:41:03", "link": "http://arxiv.org/abs/2305.17926v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "minOffense: Inter-Agreement Hate Terms for Stable Rules, Concepts,\n  Transitivities, and Lattices", "abstract": "Hate speech classification has become an important problem due to the spread\nof hate speech on social media platforms. For a given set of Hate Terms lists\n(HTs-lists) and Hate Speech data (HS-data), it is challenging to understand\nwhich hate term contributes the most for hate speech classification. This paper\ncontributes two approaches to quantitatively measure and qualitatively\nvisualise the relationship between co-occurring Hate Terms (HTs). Firstly, we\npropose an approach for the classification of hate-speech by producing a Severe\nHate Terms list (Severe HTs-list) from existing HTs-lists. To achieve our goal,\nwe proposed three metrics (Hatefulness, Relativeness, and Offensiveness) to\nmeasure the severity of HTs. These metrics assist to create an Inter-agreement\nHTs-list, which explains the contribution of an individual hate term toward\nhate speech classification. Then, we used the Offensiveness metric values of\nHTs above a proposed threshold minimum Offense (minOffense) to generate a new\nSevere HTs-list. To evaluate our approach, we used three hate speech datasets\nand six hate terms lists. Our approach shown an improvement from 0.845 to 0.923\n(best) as compared to the baseline. Secondly, we also proposed Stable Hate Rule\n(SHR) mining to provide ordered co-occurrence of various HTs with minimum\nStability (minStab). The SHR mining detects frequently co-occurring HTs to form\nStable Hate Rules and Concepts. These rules and concepts are used to visualise\nthe graphs of Transitivities and Lattices formed by HTs.", "published": "2023-05-29 09:47:36", "link": "http://arxiv.org/abs/2305.17984v1", "categories": ["cs.CL", "cs.AI", "cs.SI", "https://www.youtube.com/watch?v=iRGXiJGp3Cc&list=PLtvWi5o3JBnF3yxcjGdT4KCDLxRBIpsyR"], "primary_category": "cs.CL"}
{"title": "Can We Trust Explainable AI Methods on ASR? An Evaluation on Phoneme\n  Recognition", "abstract": "Explainable AI (XAI) techniques have been widely used to help explain and\nunderstand the output of deep learning models in fields such as image\nclassification and Natural Language Processing. Interest in using XAI\ntechniques to explain deep learning-based automatic speech recognition (ASR) is\nemerging. but there is not enough evidence on whether these explanations can be\ntrusted. To address this, we adapt a state-of-the-art XAI technique from the\nimage classification domain, Local Interpretable Model-Agnostic Explanations\n(LIME), to a model trained for a TIMIT-based phoneme recognition task. This\nsimple task provides a controlled setting for evaluation while also providing\nexpert annotated ground truth to assess the quality of explanations. We find a\nvariant of LIME based on time partitioned audio segments, that we propose in\nthis paper, produces the most reliable explanations, containing the ground\ntruth 96% of the time in its top three audio segments.", "published": "2023-05-29 11:04:13", "link": "http://arxiv.org/abs/2305.18011v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "ADAPTERMIX: Exploring the Efficacy of Mixture of Adapters for\n  Low-Resource TTS Adaptation", "abstract": "There are significant challenges for speaker adaptation in text-to-speech for\nlanguages that are not widely spoken or for speakers with accents or dialects\nthat are not well-represented in the training data. To address this issue, we\npropose the use of the \"mixture of adapters\" method. This approach involves\nadding multiple adapters within a backbone-model layer to learn the unique\ncharacteristics of different speakers. Our approach outperforms the baseline,\nwith a noticeable improvement of 5% observed in speaker preference tests when\nusing only one minute of data for each new speaker. Moreover, following the\nadapter paradigm, we fine-tune only the adapter parameters (11% of the total\nmodel parameters). This is a significant achievement in parameter-efficient\nspeaker adaptation, and one of the first models of its kind. Overall, our\nproposed approach offers a promising solution to the speech synthesis\ntechniques, particularly for adapting to speakers from diverse backgrounds.", "published": "2023-05-29 11:39:01", "link": "http://arxiv.org/abs/2305.18028v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Perceived Trustworthiness of Natural Language Generators", "abstract": "Natural Language Generation tools, such as chatbots that can generate\nhuman-like conversational text, are becoming more common both for personal and\nprofessional use. However, there are concerns about their trustworthiness and\nethical implications. The paper addresses the problem of understanding how\ndifferent users (e.g., linguists, engineers) perceive and adopt these tools and\ntheir perception of machine-generated text quality. It also discusses the\nperceived advantages and limitations of Natural Language Generation tools, as\nwell as users' beliefs on governance strategies. The main findings of this\nstudy include the impact of users' field and level of expertise on the\nperceived trust and adoption of Natural Language Generation tools, the users'\nassessment of the accuracy, fluency, and potential biases of machine-generated\ntext in comparison to human-written text, and an analysis of the advantages and\nethical risks associated with these tools as identified by the participants.\nMoreover, this paper discusses the potential implications of these findings for\nenhancing the AI development process. The paper sheds light on how different\nuser characteristics shape their beliefs on the quality and overall\ntrustworthiness of machine-generated text. Furthermore, it examines the\nbenefits and risks of these tools from the perspectives of different users.", "published": "2023-05-29 16:09:58", "link": "http://arxiv.org/abs/2305.18176v1", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Marked Personas: Using Natural Language Prompts to Measure Stereotypes\n  in Language Models", "abstract": "To recognize and mitigate harms from large language models (LLMs), we need to\nunderstand the prevalence and nuances of stereotypes in LLM outputs. Toward\nthis end, we present Marked Personas, a prompt-based method to measure\nstereotypes in LLMs for intersectional demographic groups without any lexicon\nor data labeling. Grounded in the sociolinguistic concept of markedness (which\ncharacterizes explicitly linguistically marked categories versus unmarked\ndefaults), our proposed method is twofold: 1) prompting an LLM to generate\npersonas, i.e., natural language descriptions, of the target demographic group\nalongside personas of unmarked, default groups; 2) identifying the words that\nsignificantly distinguish personas of the target group from corresponding\nunmarked ones. We find that the portrayals generated by GPT-3.5 and GPT-4\ncontain higher rates of racial stereotypes than human-written portrayals using\nthe same prompts. The words distinguishing personas of marked (non-white,\nnon-male) groups reflect patterns of othering and exoticizing these\ndemographics. An intersectional lens further reveals tropes that dominate\nportrayals of marginalized groups, such as tropicalism and the\nhypersexualization of minoritized women. These representational harms have\nconcerning implications for downstream applications like story generation.", "published": "2023-05-29 16:29:22", "link": "http://arxiv.org/abs/2305.18189v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Check-COVID: Fact-Checking COVID-19 News Claims with Scientific Evidence", "abstract": "We present a new fact-checking benchmark, Check-COVID, that requires systems\nto verify claims about COVID-19 from news using evidence from scientific\narticles. This approach to fact-checking is particularly challenging as it\nrequires checking internet text written in everyday language against evidence\nfrom journal articles written in formal academic language. Check-COVID contains\n1, 504 expert-annotated news claims about the coronavirus paired with\nsentence-level evidence from scientific journal articles and veracity labels.\nIt includes both extracted (journalist-written) and composed\n(annotator-written) claims. Experiments using both a fact-checking specific\nsystem and GPT-3.5, which respectively achieve F1 scores of 76.99 and 69.90 on\nthis task, reveal the difficulty of automatically fact-checking both claim\ntypes and the importance of in-domain data for good performance. Our data and\nmodels are released publicly at https://github.com/posuer/Check-COVID.", "published": "2023-05-29 17:39:22", "link": "http://arxiv.org/abs/2305.18265v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Mathematical Structure of Syntactic Merge", "abstract": "The syntactic Merge operation of the Minimalist Program in linguistics can be\ndescribed mathematically in terms of Hopf algebras, with a formalism similar to\nthe one arising in the physics of renormalization. This mathematical\nformulation of Merge has good descriptive power, as phenomena empirically\nobserved in linguistics can be justified from simple mathematical arguments. It\nalso provides a possible mathematical model for externalization and for the\nrole of syntactic parameters.", "published": "2023-05-29 17:50:32", "link": "http://arxiv.org/abs/2305.18278v1", "categories": ["cs.CL", "math.QA", "math.RA", "68Q70, 16T05"], "primary_category": "cs.CL"}
{"title": "HyperConformer: Multi-head HyperMixer for Efficient Speech Recognition", "abstract": "State-of-the-art ASR systems have achieved promising results by modeling\nlocal and global interactions separately. While the former can be computed\nefficiently, global interactions are usually modeled via attention mechanisms,\nwhich are expensive for long input sequences. Here, we address this by\nextending HyperMixer, an efficient alternative to attention exhibiting linear\ncomplexity, to the Conformer architecture for speech recognition, leading to\nHyperConformer. In particular, multi-head HyperConformer achieves comparable or\nhigher recognition performance while being more efficient than Conformer in\nterms of inference speed, memory, parameter count, and available training data.\nHyperConformer achieves a word error rate of 2.9% on Librispeech test-clean\nwith less than 8M neural parameters and a peak memory during training of 5.7GB,\nhence trainable with accessible hardware. Encoder speed is between 38% on\nmid-length speech and 56% on long speech faster than an equivalent Conformer.\n(The HyperConformer recipe is publicly available in:\nhttps://github.com/speechbrain/speechbrain/tree/develop/recipes/LibriSpeech/ASR/transformer/)", "published": "2023-05-29 17:53:04", "link": "http://arxiv.org/abs/2305.18281v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "CommonAccent: Exploring Large Acoustic Pretrained Models for Accent\n  Classification Based on Common Voice", "abstract": "Despite the recent advancements in Automatic Speech Recognition (ASR), the\nrecognition of accented speech still remains a dominant problem. In order to\ncreate more inclusive ASR systems, research has shown that the integration of\naccent information, as part of a larger ASR framework, can lead to the\nmitigation of accented speech errors. We address multilingual accent\nclassification through the ECAPA-TDNN and Wav2Vec 2.0/XLSR architectures which\nhave been proven to perform well on a variety of speech-related downstream\ntasks. We introduce a simple-to-follow recipe aligned to the SpeechBrain\ntoolkit for accent classification based on Common Voice 7.0 (English) and\nCommon Voice 11.0 (Italian, German, and Spanish). Furthermore, we establish new\nstate-of-the-art for English accent classification with as high as 95%\naccuracy. We also study the internal categorization of the Wav2Vev 2.0\nembeddings through t-SNE, noting that there is a level of clustering based on\nphonological similarity. (Our recipe is open-source in the SpeechBrain toolkit,\nsee: https://github.com/speechbrain/speechbrain/tree/develop/recipes)", "published": "2023-05-29 17:53:35", "link": "http://arxiv.org/abs/2305.18283v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Direct Preference Optimization: Your Language Model is Secretly a Reward\n  Model", "abstract": "While large-scale unsupervised language models (LMs) learn broad world\nknowledge and some reasoning skills, achieving precise control of their\nbehavior is difficult due to the completely unsupervised nature of their\ntraining. Existing methods for gaining such steerability collect human labels\nof the relative quality of model generations and fine-tune the unsupervised LM\nto align with these preferences, often with reinforcement learning from human\nfeedback (RLHF). However, RLHF is a complex and often unstable procedure, first\nfitting a reward model that reflects the human preferences, and then\nfine-tuning the large unsupervised LM using reinforcement learning to maximize\nthis estimated reward without drifting too far from the original model. In this\npaper we introduce a new parameterization of the reward model in RLHF that\nenables extraction of the corresponding optimal policy in closed form, allowing\nus to solve the standard RLHF problem with only a simple classification loss.\nThe resulting algorithm, which we call Direct Preference Optimization (DPO), is\nstable, performant, and computationally lightweight, eliminating the need for\nsampling from the LM during fine-tuning or performing significant\nhyperparameter tuning. Our experiments show that DPO can fine-tune LMs to align\nwith human preferences as well as or better than existing methods. Notably,\nfine-tuning with DPO exceeds PPO-based RLHF in ability to control sentiment of\ngenerations, and matches or improves response quality in summarization and\nsingle-turn dialogue while being substantially simpler to implement and train.", "published": "2023-05-29 17:57:46", "link": "http://arxiv.org/abs/2305.18290v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Membership Inference Attacks against Language Models via Neighbourhood\n  Comparison", "abstract": "Membership Inference attacks (MIAs) aim to predict whether a data sample was\npresent in the training data of a machine learning model or not, and are widely\nused for assessing the privacy risks of language models. Most existing attacks\nrely on the observation that models tend to assign higher probabilities to\ntheir training samples than non-training points. However, simple thresholding\nof the model score in isolation tends to lead to high false-positive rates as\nit does not account for the intrinsic complexity of a sample. Recent work has\ndemonstrated that reference-based attacks which compare model scores to those\nobtained from a reference model trained on similar data can substantially\nimprove the performance of MIAs. However, in order to train reference models,\nattacks of this kind make the strong and arguably unrealistic assumption that\nan adversary has access to samples closely resembling the original training\ndata. Therefore, we investigate their performance in more realistic scenarios\nand find that they are highly fragile in relation to the data distribution used\nto train reference models. To investigate whether this fragility provides a\nlayer of safety, we propose and evaluate neighbourhood attacks, which compare\nmodel scores for a given sample to scores of synthetically generated neighbour\ntexts and therefore eliminate the need for access to the training data\ndistribution. We show that, in addition to being competitive with\nreference-based attacks that have perfect knowledge about the training data\ndistribution, our attack clearly outperforms existing reference-free attacks as\nwell as reference-based attacks with imperfect knowledge, which demonstrates\nthe need for a reevaluation of the threat model of adversarial attacks.", "published": "2023-05-29 07:06:03", "link": "http://arxiv.org/abs/2305.18462v2", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark\n  Datasets", "abstract": "The development of large language models (LLMs) such as ChatGPT has brought a\nlot of attention recently. However, their evaluation in the benchmark academic\ndatasets remains under-explored due to the difficulty of evaluating the\ngenerative outputs produced by this model against the ground truth. In this\npaper, we aim to present a thorough evaluation of ChatGPT's performance on\ndiverse academic datasets, covering tasks like question-answering, text\nsummarization, code generation, commonsense reasoning, mathematical\nproblem-solving, machine translation, bias detection, and ethical\nconsiderations. Specifically, we evaluate ChatGPT across 140 tasks and analyze\n255K responses it generates in these datasets. This makes our work the largest\nevaluation of ChatGPT in NLP benchmarks. In short, our study aims to validate\nthe strengths and weaknesses of ChatGPT in various tasks and provide insights\nfor future research using LLMs. We also report a new emergent ability to follow\nmulti-query instructions that we mostly found in ChatGPT and other\ninstruction-tuned models. Our extensive evaluation shows that even though\nChatGPT is capable of performing a wide variety of tasks, and may obtain\nimpressive performance in several benchmark datasets, it is still far from\nachieving the ability to reliably solve many challenging tasks. By providing a\nthorough assessment of ChatGPT's performance across diverse NLP tasks, this\npaper sets the stage for a targeted deployment of ChatGPT-like LLMs in\nreal-world applications.", "published": "2023-05-29 12:37:21", "link": "http://arxiv.org/abs/2305.18486v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ANPL: Towards Natural Programming with Interactive Decomposition", "abstract": "Though LLMs are capable of generating plausible programs, it's challenging to\ninteract with the LLMs further to revise the program, especially if the user's\nspecific requirements are different from the initial proposal. In this paper,\nwe introduce ANPL, an interactive programming system that ensures users can\nalways refine the generated code towards their specific programmatic intents\nvia structured decompositions. Borrowing the paradigm of sketching from program\nsynthesis, an ANPL program consists of a set of input-outputs that it must\nsatisfy, a ``sketch'' -- control/data flow expressed in precise code (e.g.\nPython), and ``holes'' -- sub-modules to be implemented by the LLM specified\nwith natural language. The user revises an ANPL program by either modifying the\nsketch, changing the language used to describe the holes, or providing\nadditional input-outputs to a particular hole, turning it into a sub-ANPL\nprogram that can be solved recursively. This workflow allows the users to\noffload programming burdens to the LLM as much as possible while retaining the\nability to pinpoint and resolve bugs locally, without exposing the rest of the\nprogram to the LLM. We deploy ANPL on the Abstraction and Reasoning Corpus\n(ARC), a set of unique tasks that are challenging for state-of-the-art AI\nsystems, showing it outperforms baseline programming systems that (a) without\nthe ability to decompose tasks interactively and (b) without the guarantee that\nthe modules can be correctly composed together. Additional evaluations on APPS,\nHumanEval, and real-world programming tasks have validated that the ANPL\nframework is applicable to multiple programming domains. We release the ANPL\nsolutions to the ARC tasks as a dataset, providing insights into how humans\ndecompose novel tasks programmatically. See our code at\nhttps://iprc-dip.github.io/ANPL/.", "published": "2023-05-29 14:19:40", "link": "http://arxiv.org/abs/2305.18498v2", "categories": ["cs.PL", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.PL"}
{"title": "From Adversarial Arms Race to Model-centric Evaluation: Motivating a\n  Unified Automatic Robustness Evaluation Framework", "abstract": "Textual adversarial attacks can discover models' weaknesses by adding\nsemantic-preserved but misleading perturbations to the inputs. The long-lasting\nadversarial attack-and-defense arms race in Natural Language Processing (NLP)\nis algorithm-centric, providing valuable techniques for automatic robustness\nevaluation. However, the existing practice of robustness evaluation may exhibit\nissues of incomprehensive evaluation, impractical evaluation protocol, and\ninvalid adversarial samples. In this paper, we aim to set up a unified\nautomatic robustness evaluation framework, shifting towards model-centric\nevaluation to further exploit the advantages of adversarial attacks. To address\nthe above challenges, we first determine robustness evaluation dimensions based\non model capabilities and specify the reasonable algorithm to generate\nadversarial samples for each dimension. Then we establish the evaluation\nprotocol, including evaluation settings and metrics, under realistic demands.\nFinally, we use the perturbation degree of adversarial samples to control the\nsample validity. We implement a toolkit RobTest that realizes our automatic\nrobustness evaluation framework. In our experiments, we conduct a robustness\nevaluation of RoBERTa models to demonstrate the effectiveness of our evaluation\nframework, and further show the rationality of each component in the framework.\nThe code will be made public at \\url{https://github.com/thunlp/RobTest}.", "published": "2023-05-29 14:55:20", "link": "http://arxiv.org/abs/2305.18503v1", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "PaLI-X: On Scaling up a Multilingual Vision and Language Model", "abstract": "We present the training recipe and results of scaling up PaLI-X, a\nmultilingual vision and language model, both in terms of size of the components\nand the breadth of its training task mixture. Our model achieves new levels of\nperformance on a wide-range of varied and complex tasks, including multiple\nimage-based captioning and question-answering tasks, image-based document\nunderstanding and few-shot (in-context) learning, as well as object detection,\nvideo question answering, and video captioning. PaLI-X advances the\nstate-of-the-art on most vision-and-language benchmarks considered (25+ of\nthem). Finally, we observe emerging capabilities, such as complex counting and\nmultilingual object detection, tasks that are not explicitly in the training\nmix.", "published": "2023-05-29 18:58:38", "link": "http://arxiv.org/abs/2305.18565v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Building Accurate Low Latency ASR for Streaming Voice Search", "abstract": "Automatic Speech Recognition (ASR) plays a crucial role in voice-based\napplications. For applications requiring real-time feedback like Voice Search,\nstreaming capability becomes vital. While LSTM/RNN and CTC based ASR systems\nare commonly employed for low-latency streaming applications, they often\nexhibit lower accuracy compared to state-of-the-art models due to a lack of\nfuture audio frames. In this work, we focus on developing accurate LSTM,\nattention, and CTC based streaming ASR models for large-scale Hinglish (a blend\nof Hindi and English) Voice Search. We investigate various modifications in\nvanilla LSTM training which enhance the system's accuracy while preserving its\nstreaming capabilities. We also address the critical requirement of\nend-of-speech (EOS) detection in streaming applications. We present a simple\ntraining and inference strategy for end-to-end CTC models that enables joint\nASR and EOS detection. The evaluation of our model on Flipkart's Voice Search,\nwhich handles substantial traffic of approximately 6 million queries per day,\ndemonstrates significant performance gains over the vanilla LSTM-CTC model. Our\nmodel achieves a word error rate (WER) of 3.69% without EOS and 4.78% with EOS\nwhile also reducing the search latency by approximately ~1300 ms (equivalent to\n46.64% reduction) when compared to an independent voice activity detection\n(VAD) model.", "published": "2023-05-29 20:24:14", "link": "http://arxiv.org/abs/2305.18596v1", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Improving Generalization for Multimodal Fake News Detection", "abstract": "The increasing proliferation of misinformation and its alarming impact have\nmotivated both industry and academia to develop approaches for fake news\ndetection. However, state-of-the-art approaches are usually trained on datasets\nof smaller size or with a limited set of specific topics. As a consequence,\nthese models lack generalization capabilities and are not applicable to\nreal-world data. In this paper, we propose three models that adopt and\nfine-tune state-of-the-art multimodal transformers for multimodal fake news\ndetection. We conduct an in-depth analysis by manipulating the input data aimed\nto explore models performance in realistic use cases on social media. Our study\nacross multiple models demonstrates that these systems suffer significant\nperformance drops against manipulated data. To reduce the bias and improve\nmodel generalization, we suggest training data augmentation to conduct more\nmeaningful experiments for fake news detection on social media. The proposed\ndata augmentation techniques enable models to generalize better and yield\nimproved state-of-the-art results.", "published": "2023-05-29 20:32:22", "link": "http://arxiv.org/abs/2305.18599v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "cs.MM"], "primary_category": "cs.CL"}
{"title": "From `Snippet-lects' to Doculects and Dialects: Leveraging Neural\n  Representations of Speech for Placing Audio Signals in a Language Landscape", "abstract": "XLSR-53 a multilingual model of speech, builds a vector representation from\naudio, which allows for a range of computational treatments. The experiments\nreported here use this neural representation to estimate the degree of\ncloseness between audio files, ultimately aiming to extract relevant linguistic\nproperties. We use max-pooling to aggregate the neural representations from a\n\"snippet-lect\" (the speech in a 5-second audio snippet) to a \"doculect\" (the\nspeech in a given resource), then to dialects and languages. We use data from\ncorpora of 11 dialects belonging to 5 less-studied languages. Similarity\nmeasurements between the 11 corpora bring out greatest closeness between those\nthat are known to be dialects of the same language. The findings suggest that\n(i) dialect/language can emerge among the various parameters characterizing\naudio files and (ii) estimates of overall phonetic/phonological closeness can\nbe obtained for a little-resourced or fully unknown language. The findings help\nshed light on the type of information captured by neural representations of\nspeech and how it can be extracted from these representations", "published": "2023-05-29 20:37:06", "link": "http://arxiv.org/abs/2305.18602v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Faith and Fate: Limits of Transformers on Compositionality", "abstract": "Transformer large language models (LLMs) have sparked admiration for their\nexceptional performance on tasks that demand intricate multi-step reasoning.\nYet, these models simultaneously show failures on surprisingly trivial\nproblems. This begs the question: Are these errors incidental, or do they\nsignal more substantial limitations? In an attempt to demystify transformer\nLLMs, we investigate the limits of these models across three representative\ncompositional tasks -- multi-digit multiplication, logic grid puzzles, and a\nclassic dynamic programming problem. These tasks require breaking problems down\ninto sub-steps and synthesizing these steps into a precise answer. We formulate\ncompositional tasks as computation graphs to systematically quantify the level\nof complexity, and break down reasoning steps into intermediate sub-procedures.\nOur empirical findings suggest that transformer LLMs solve compositional tasks\nby reducing multi-step compositional reasoning into linearized subgraph\nmatching, without necessarily developing systematic problem-solving skills. To\nround off our empirical study, we provide theoretical arguments on abstract\nmulti-step reasoning problems that highlight how autoregressive generations'\nperformance can rapidly decay with\\,increased\\,task\\,complexity.", "published": "2023-05-29 23:24:14", "link": "http://arxiv.org/abs/2305.18654v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Taming AI Bots: Controllability of Neural States in Large Language\n  Models", "abstract": "We tackle the question of whether an agent can, by suitable choice of\nprompts, control an AI bot to any state. To that end, we first introduce a\nformal definition of ``meaning'' that is amenable to analysis. Then, we\ncharacterize ``meaningful data'' on which large language models (LLMs) are\nostensibly trained, and ``well-trained LLMs'' through conditions that are\nlargely met by today's LLMs. While a well-trained LLM constructs an embedding\nspace of meanings that is Euclidean, meanings themselves do not form a vector\n(linear) subspace, but rather a quotient space within. We then characterize the\nsubset of meanings that can be reached by the state of the LLMs for some input\nprompt, and show that a well-trained bot can reach any meaning albeit with\nsmall probability. We then introduce a stronger notion of controllability as\n{\\em almost certain reachability}, and show that, when restricted to the space\nof meanings, an AI bot is controllable. We do so after introducing a functional\ncharacterization of attentive AI bots, and finally derive necessary and\nsufficient conditions for controllability. The fact that AI bots are\ncontrollable means that an adversary could steer them towards any state.\nHowever, the sampling process can be designed to counteract adverse actions and\navoid reaching undesirable regions of state space before their boundary is\ncrossed.", "published": "2023-05-29 03:58:33", "link": "http://arxiv.org/abs/2305.18449v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.AI"}
{"title": "VAST: A Vision-Audio-Subtitle-Text Omni-Modality Foundation Model and\n  Dataset", "abstract": "Vision and text have been fully explored in contemporary video-text\nfoundational models, while other modalities such as audio and subtitles in\nvideos have not received sufficient attention. In this paper, we resort to\nestablish connections between multi-modality video tracks, including Vision,\nAudio, and Subtitle, and Text by exploring an automatically generated\nlarge-scale omni-modality video caption dataset called VAST-27M. Specifically,\nwe first collect 27 million open-domain video clips and separately train a\nvision and an audio captioner to generate vision and audio captions. Then, we\nemploy an off-the-shelf Large Language Model (LLM) to integrate the generated\ncaptions, together with subtitles and instructional prompts into omni-modality\ncaptions. Based on the proposed VAST-27M dataset, we train an omni-modality\nvideo-text foundational model named VAST, which can perceive and process\nvision, audio, and subtitle modalities from video, and better support various\ntasks including vision-text, audio-text, and multi-modal video-text tasks\n(retrieval, captioning and QA). Extensive experiments have been conducted to\ndemonstrate the effectiveness of our proposed VAST-27M corpus and VAST\nfoundation model. VAST achieves 22 new state-of-the-art results on various\ncross-modality benchmarks. Code, model and dataset will be released at\nhttps://github.com/TXH-mercury/VAST.", "published": "2023-05-29 14:34:50", "link": "http://arxiv.org/abs/2305.18500v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Transforming the Embeddings: A Lightweight Technique for Speech Emotion\n  Recognition Tasks", "abstract": "Speech emotion recognition (SER) is a field that has drawn a lot of attention\ndue to its applications in diverse fields. A current trend in methods used for\nSER is to leverage embeddings from pre-trained models (PTMs) as input features\nto downstream models. However, the use of embeddings from speaker recognition\nPTMs hasn't garnered much focus in comparison to other PTM embeddings. To fill\nthis gap and in order to understand the efficacy of speaker recognition PTM\nembeddings, we perform a comparative analysis of five PTM embeddings. Among\nall, x-vector embeddings performed the best possibly due to its training for\nspeaker recognition leading to capturing various components of speech such as\ntone, pitch, etc. Our modeling approach which utilizes x-vector embeddings and\nmel-frequency cepstral coefficients (MFCC) as input features is the most\nlightweight approach while achieving comparable accuracy to previous\nstate-of-the-art (SOTA) methods in the CREMA-D benchmark.", "published": "2023-05-29 22:27:48", "link": "http://arxiv.org/abs/2305.18640v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Streaming Audio Transformers for Online Audio Tagging", "abstract": "Transformers have emerged as a prominent model framework for audio tagging\n(AT), boasting state-of-the-art (SOTA) performance on the widely-used Audioset\ndataset. However, their impressive performance often comes at the cost of high\nmemory usage, slow inference speed, and considerable model delay, rendering\nthem impractical for real-world AT applications. In this study, we introduce\nstreaming audio transformers (SAT) that combine the vision transformer (ViT)\narchitecture with Transformer-Xl-like chunk processing, enabling efficient\nprocessing of long-range audio signals. Our proposed SAT is benchmarked against\nother transformer-based SOTA methods, achieving significant improvements in\nterms of mean average precision (mAP) at a delay of 2s and 1s, while also\nexhibiting significantly lower memory usage and computational overhead.\nCheckpoints are publicly available https://github.com/RicherMans/SAT.", "published": "2023-05-29 00:32:11", "link": "http://arxiv.org/abs/2305.17834v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "speech and noise dual-stream spectrogram refine network with speech\n  distortion loss for robust speech recognition", "abstract": "In recent years, the joint training of speech enhancement front-end and\nautomatic speech recognition (ASR) back-end has been widely used to improve the\nrobustness of ASR systems. Traditional joint training methods only use enhanced\nspeech as input for the backend. However, it is difficult for speech\nenhancement systems to directly separate speech from input due to the diverse\ntypes of noise with different intensities. Furthermore, speech distortion and\nresidual noise are often observed in enhanced speech, and the distortion of\nspeech and noise is different. Most existing methods focus on fusing enhanced\nand noisy features to address this issue. In this paper, we propose a\ndual-stream spectrogram refine network to simultaneously refine the speech and\nnoise and decouple the noise from the noisy input. Our proposed method can\nachieve better performance with a relative 8.6% CER reduction.", "published": "2023-05-29 02:44:46", "link": "http://arxiv.org/abs/2305.17860v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Automatic Evaluation of Turn-taking Cues in Conversational Speech\n  Synthesis", "abstract": "Turn-taking is a fundamental aspect of human communication where speakers\nconvey their intention to either hold, or yield, their turn through prosodic\ncues. Using the recently proposed Voice Activity Projection model, we propose\nan automatic evaluation approach to measure these aspects for conversational\nspeech synthesis. We investigate the ability of three commercial, and two\nopen-source, Text-To-Speech (TTS) systems ability to generate turn-taking cues\nover simulated turns. By varying the stimuli, or controlling the prosody, we\nanalyze the models performances. We show that while commercial TTS largely\nprovide appropriate cues, they often produce ambiguous signals, and that\nfurther improvements are possible. TTS, trained on read or spontaneous speech,\nproduce strong turn-hold but weak turn-yield cues. We argue that this approach,\nthat focus on functional aspects of interaction, provides a useful addition to\nother important speech metrics, such as intelligibility and naturalness.", "published": "2023-05-29 09:29:11", "link": "http://arxiv.org/abs/2305.17971v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Exploration of Efficient End-to-End ASR using Discretized Input from\n  Self-Supervised Learning", "abstract": "Self-supervised learning (SSL) of speech has shown impressive results in\nspeech-related tasks, particularly in automatic speech recognition (ASR). While\nmost methods employ the output of intermediate layers of the SSL model as\nreal-valued features for downstream tasks, there is potential in exploring\nalternative approaches that use discretized token sequences. This approach\noffers benefits such as lower storage requirements and the ability to apply\ntechniques from natural language processing. In this paper, we propose a new\nprotocol that utilizes discretized token sequences in ASR tasks, which includes\nde-duplication and sub-word modeling to enhance the input sequence. It reduces\ncomputational cost by decreasing the length of the sequence. Our experiments on\nthe LibriSpeech dataset demonstrate that our proposed protocol performs\ncompetitively with conventional ASR systems using continuous input features,\nwhile reducing computational and storage costs.", "published": "2023-05-29 14:23:28", "link": "http://arxiv.org/abs/2305.18108v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "MT-SLVR: Multi-Task Self-Supervised Learning for Transformation\n  In(Variant) Representations", "abstract": "Contrastive self-supervised learning has gained attention for its ability to\ncreate high-quality representations from large unlabelled data sets. A key\nreason that these powerful features enable data-efficient learning of\ndownstream tasks is that they provide augmentation invariance, which is often a\nuseful inductive bias. However, the amount and type of invariances preferred is\nnot known apriori, and varies across different downstream tasks. We therefore\npropose a multi-task self-supervised framework (MT-SLVR) that learns both\nvariant and invariant features in a parameter-efficient manner. Our multi-task\nrepresentation provides a strong and flexible feature that benefits diverse\ndownstream tasks. We evaluate our approach on few-shot classification tasks\ndrawn from a variety of audio domains and demonstrate improved classification\nperformance on all of them", "published": "2023-05-29 09:10:50", "link": "http://arxiv.org/abs/2305.17191v2", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Multi-Scale Attention for Audio Question Answering", "abstract": "Audio question answering (AQA), acting as a widely used proxy task to explore\nscene understanding, has got more attention. The AQA is challenging for it\nrequires comprehensive temporal reasoning from different scales' events of an\naudio scene. However, existing methods mostly extend the structures of visual\nquestion answering task to audio ones in a simple pattern but may not perform\nwell when perceiving a fine-grained audio scene. To this end, we present a\nMulti-scale Window Attention Fusion Model (MWAFM) consisting of an asynchronous\nhybrid attention module and a multi-scale window attention module. The former\nis designed to aggregate unimodal and cross-modal temporal contexts, while the\nlatter captures sound events of varying lengths and their temporal dependencies\nfor a more comprehensive understanding. Extensive experiments are conducted to\ndemonstrate that the proposed MWAFM can effectively explore temporal\ninformation to facilitate AQA in the fine-grained scene.Code:\nhttps://github.com/GeWu-Lab/MWAFM", "published": "2023-05-29 10:06:58", "link": "http://arxiv.org/abs/2305.17993v1", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Few-shot Class-incremental Audio Classification Using Adaptively-refined\n  Prototypes", "abstract": "New classes of sounds constantly emerge with a few samples, making it\nchallenging for models to adapt to dynamic acoustic environments. This\nchallenge motivates us to address the new problem of few-shot class-incremental\naudio classification. This study aims to enable a model to continuously\nrecognize new classes of sounds with a few training samples of new classes\nwhile remembering the learned ones. To this end, we propose a method to\ngenerate discriminative prototypes and use them to expand the model's\nclassifier for recognizing sounds of new and learned classes. The model is\nfirst trained with a random episodic training strategy, and then its backbone\nis used to generate the prototypes. A dynamic relation projection module\nrefines the prototypes to enhance their discriminability. Results on two\ndatasets (derived from the corpora of Nsynth and FSD-MIX-CLIPS) show that the\nproposed method exceeds three state-of-the-art methods in average accuracy and\nperformance dropping rate.", "published": "2023-05-29 12:16:48", "link": "http://arxiv.org/abs/2305.18045v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "An Experimental Review of Speaker Diarization methods with application\n  to Two-Speaker Conversational Telephone Speech recordings", "abstract": "We performed an experimental review of current diarization systems for the\nconversational telephone speech (CTS) domain. In detail, we considered a total\nof eight different algorithms belonging to clustering-based, end-to-end neural\ndiarization (EEND), and speech separation guided diarization (SSGD) paradigms.\nWe studied the inference-time computational requirements and diarization\naccuracy on four CTS datasets with different characteristics and languages. We\nfound that, among all methods considered, EEND-vector clustering (EEND-VC)\noffers the best trade-off in terms of computing requirements and performance.\nMore in general, EEND models have been found to be lighter and faster in\ninference compared to clustering-based methods. However, they also require a\nlarge amount of diarization-oriented annotated data. In particular EEND-VC\nperformance in our experiments degraded when the dataset size was reduced,\nwhereas self-attentive EEND (SA-EEND) was less affected. We also found that\nSA-EEND gives less consistent results among all the datasets compared to\nEEND-VC, with its performance degrading on long conversations with high speech\nsparsity. Clustering-based diarization systems, and in particular VBx, instead\nhave more consistent performance compared to SA-EEND but are outperformed by\nEEND-VC. The gap with respect to this latter is reduced when overlap-aware\nclustering methods are considered. SSGD is the most computationally demanding\nmethod, but it could be convenient if speech recognition has to be performed.\nIts performance is close to SA-EEND but degrades significantly when the\ntraining and inference data characteristics are less matched.", "published": "2023-05-29 13:19:10", "link": "http://arxiv.org/abs/2305.18074v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "A Hierarchical Context-aware Modeling Approach for Multi-aspect and\n  Multi-granular Pronunciation Assessment", "abstract": "Automatic Pronunciation Assessment (APA) plays a vital role in\nComputer-assisted Pronunciation Training (CAPT) when evaluating a second\nlanguage (L2) learner's speaking proficiency. However, an apparent downside of\nmost de facto methods is that they parallelize the modeling process throughout\ndifferent speech granularities without accounting for the hierarchical and\nlocal contextual relationships among them. In light of this, a novel\nhierarchical approach is proposed in this paper for multi-aspect and\nmulti-granular APA. Specifically, we first introduce the notion of sup-phonemes\nto explore more subtle semantic traits of L2 speakers. Second, a depth-wise\nseparable convolution layer is exploited to better encapsulate the local\ncontext cues at the sub-word level. Finally, we use a score-restraint attention\npooling mechanism to predict the sentence-level scores and optimize the\ncomponent models with a multitask learning (MTL) framework. Extensive\nexperiments carried out on a publicly-available benchmark dataset, viz.\nspeechocean762, demonstrate the efficacy of our approach in relation to some\ncutting-edge baselines.", "published": "2023-05-29 15:17:32", "link": "http://arxiv.org/abs/2305.18146v4", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "DeCoR: Defy Knowledge Forgetting by Predicting Earlier Audio Codes", "abstract": "Lifelong audio feature extraction involves learning new sound classes\nincrementally, which is essential for adapting to new data distributions over\ntime. However, optimizing the model only on new data can lead to catastrophic\nforgetting of previously learned tasks, which undermines the model's ability to\nperform well over the long term. This paper introduces a new approach to\ncontinual audio representation learning called DeCoR. Unlike other methods that\nstore previous data, features, or models, DeCoR indirectly distills knowledge\nfrom an earlier model to the latest by predicting quantization indices from a\ndelayed codebook. We demonstrate that DeCoR improves acoustic scene\nclassification accuracy and integrates well with continual self-supervised\nrepresentation learning. Our approach introduces minimal storage and\ncomputation overhead, making it a lightweight and efficient solution for\ncontinual learning.", "published": "2023-05-29 02:25:03", "link": "http://arxiv.org/abs/2305.18441v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Make-An-Audio 2: Temporal-Enhanced Text-to-Audio Generation", "abstract": "Large diffusion models have been successful in text-to-audio (T2A) synthesis\ntasks, but they often suffer from common issues such as semantic misalignment\nand poor temporal consistency due to limited natural language understanding and\ndata scarcity. Additionally, 2D spatial structures widely used in T2A works\nlead to unsatisfactory audio quality when generating variable-length audio\nsamples since they do not adequately prioritize temporal information. To\naddress these challenges, we propose Make-an-Audio 2, a latent diffusion-based\nT2A method that builds on the success of Make-an-Audio. Our approach includes\nseveral techniques to improve semantic alignment and temporal consistency:\nFirstly, we use pre-trained large language models (LLMs) to parse the text into\nstructured <event & order> pairs for better temporal information capture. We\nalso introduce another structured-text encoder to aid in learning semantic\nalignment during the diffusion denoising process. To improve the performance of\nvariable length generation and enhance the temporal information extraction, we\ndesign a feed-forward Transformer-based diffusion denoiser. Finally, we use\nLLMs to augment and transform a large amount of audio-label data into\naudio-text datasets to alleviate the problem of scarcity of temporal data.\nExtensive experiments show that our method outperforms baseline models in both\nobjective and subjective metrics, and achieves significant gains in temporal\ninformation understanding, semantic consistency, and sound quality.", "published": "2023-05-29 10:41:28", "link": "http://arxiv.org/abs/2305.18474v1", "categories": ["cs.SD", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multi-Band Acoustic Monitoring of Aerial Signatures", "abstract": "The Galileo Project's acoustic monitoring, omni-directional system (AMOS)\naids in the detection and characterization of aerial phenomena. It uses a\nmulti-band microphone suite spanning infrasonic to ultrasonic frequencies,\nproviding an independent signal modality for validation and characterization of\ndetected objects. The system utilizes infrasonic, audible, and ultrasonic\nsystems to cover a wide range of sounds produced by both natural and man-made\naerial phenomena. Sound signals from aerial objects can be captured given\ncertain conditions, such as when the sound level is above ambient noise and\nisn't excessively distorted by its transmission path. Findings suggest that\naudible sources can be detected up to 1 km away, infrasonic sources can be\ndetected over much longer distances, and ultrasonic at shorter ones. Initial\ndata collected from aircraft recordings with spectral analysis will help\ndevelop algorithms and software for quick identification of known aircraft.\nFuture work will involve multi-sensor arrays for sound localization, larger\ndata sets analysis, and incorporation of machine learning and AI for detection\nand identification of more types of phenomena in all frequency bands.", "published": "2023-05-29 18:27:08", "link": "http://arxiv.org/abs/2305.18551v1", "categories": ["astro-ph.IM", "cs.SD", "eess.AS"], "primary_category": "astro-ph.IM"}
