{"title": "Evaluating how LLM annotations represent diverse views on contentious topics", "abstract": "Researchers have proposed the use of generative large language models (LLMs)\nto label data for both research and applied settings. This literature\nemphasizes the improved performance of LLMs relative to other natural language\nmodels, noting that LLMs typically outperform other models on standard metrics\nsuch as accuracy, precision, recall, and F1 score. However, previous literature\nhas also highlighted the bias embedded in language models, particularly around\ncontentious topics such as potentially toxic content. This bias could result in\nlabels applied by LLMs that disproportionately align with majority groups over\na more diverse set of viewpoints. In this paper, we evaluate how LLMs represent\ndiverse viewpoints on these contentious tasks. Across four annotation tasks on\nfour datasets, we show that LLMs do not show substantial disagreement with\nannotators on the basis of demographics. Instead, the model, prompt, and\ndisagreement between human annotators on the labeling task are far more\npredictive of LLM agreement. Our findings suggest that when using LLMs to\nannotate data, under-representing the views of particular groups is not a\nsubstantial concern. We conclude with a discussion of the implications for\nresearchers and practitioners.", "published": "2025-03-29 22:53:15", "link": "http://arxiv.org/abs/2503.23243v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Beyond speculation: Measuring the growing presence of LLM-generated texts in multilingual disinformation", "abstract": "Increased sophistication of large language models (LLMs) and the consequent\nquality of generated multilingual text raises concerns about potential\ndisinformation misuse. While humans struggle to distinguish LLM-generated\ncontent from human-written texts, the scholarly debate about their impact\nremains divided. Some argue that heightened fears are overblown due to natural\necosystem limitations, while others contend that specific \"longtail\" contexts\nface overlooked risks. Our study bridges this debate by providing the first\nempirical evidence of LLM presence in the latest real-world disinformation\ndatasets, documenting the increase of machine-generated content following\nChatGPT's release, and revealing crucial patterns across languages, platforms,\nand time periods.", "published": "2025-03-29 22:47:53", "link": "http://arxiv.org/abs/2503.23242v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Beyond Contrastive Learning: Synthetic Data Enables List-wise Training with Multiple Levels of Relevance", "abstract": "Recent advancements in large language models (LLMs) have allowed the\naugmentation of information retrieval (IR) pipelines with synthetic data in\nvarious ways. Yet, the main training paradigm remains: contrastive learning\nwith binary relevance labels and the InfoNCE loss, where one positive document\nis compared against one or more negatives. This objective treats all documents\nthat are not explicitly annotated as relevant on an equally negative footing,\nregardless of their actual degree of relevance, thus (a) missing subtle nuances\nthat are useful for ranking and (b) being susceptible to annotation noise. To\novercome this limitation, in this work we forgo real training documents and\nannotations altogether and use open-source LLMs to directly generate synthetic\ndocuments that answer real user queries according to several different levels\nof relevance. This fully synthetic ranking context of graduated relevance,\ntogether with an appropriate list-wise loss (Wasserstein distance), enables us\nto train dense retrievers in a way that better captures the ranking task.\nExperiments on various IR datasets show that our proposed approach outperforms\nconventional training with InfoNCE by a large margin. Without using any real\ndocuments for training, our dense retriever significantly outperforms the same\nretriever trained through self-supervision. More importantly, it matches the\nperformance of the same retriever trained on real, labeled training documents\nof the same dataset, while being more robust to distribution shift and clearly\noutperforming it when evaluated zero-shot on the BEIR dataset collection.", "published": "2025-03-29 22:33:22", "link": "http://arxiv.org/abs/2503.23239v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "RECALL-MM: A Multimodal Dataset of Consumer Product Recalls for Risk Analysis using Computational Methods and Large Language Models", "abstract": "Product recalls provide valuable insights into potential risks and hazards\nwithin the engineering design process, yet their full potential remains\nunderutilized. In this study, we curate data from the United States Consumer\nProduct Safety Commission (CPSC) recalls database to develop a multimodal\ndataset, RECALL-MM, that informs data-driven risk assessment using historical\ninformation, and augment it using generative methods. Patterns in the dataset\nhighlight specific areas where improved safety measures could have significant\nimpact. We extend our analysis by demonstrating interactive clustering maps\nthat embed all recalls into a shared latent space based on recall descriptions\nand product names. Leveraging these data-driven tools, we explore three case\nstudies to demonstrate the dataset's utility in identifying product risks and\nguiding safer design decisions. The first two case studies illustrate how\ndesigners can visualize patterns across recalled products and situate new\nproduct ideas within the broader recall landscape to proactively anticipate\nhazards. In the third case study, we extend our approach by employing a large\nlanguage model (LLM) to predict potential hazards based solely on product\nimages. This demonstrates the model's ability to leverage visual context to\nidentify risk factors, revealing strong alignment with historical recall data\nacross many hazard categories. However, the analysis also highlights areas\nwhere hazard prediction remains challenging, underscoring the importance of\nrisk awareness throughout the design process. Collectively, this work aims to\nbridge the gap between historical recall data and future product safety,\npresenting a scalable, data-driven approach to safer engineering design.", "published": "2025-03-29 20:27:28", "link": "http://arxiv.org/abs/2503.23213v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Enhancing Knowledge Graph Completion with Entity Neighborhood and Relation Context", "abstract": "Knowledge Graph Completion (KGC) aims to infer missing information in\nKnowledge Graphs (KGs) to address their inherent incompleteness. Traditional\nstructure-based KGC methods, while effective, face significant computational\ndemands and scalability challenges due to the need for dense embedding learning\nand scoring all entities in the KG for each prediction. Recent text-based\napproaches using language models like T5 and BERT have mitigated these issues\nby converting KG triples into text for reasoning. However, they often fail to\nfully utilize contextual information, focusing mainly on the neighborhood of\nthe entity and neglecting the context of the relation. To address this issue,\nwe propose KGC-ERC, a framework that integrates both types of context to enrich\nthe input of generative language models and enhance their reasoning\ncapabilities. Additionally, we introduce a sampling strategy to effectively\nselect relevant context within input token constraints, which optimizes the\nutilization of contextual information and potentially improves model\nperformance. Experiments on the Wikidata5M, Wiki27K, and FB15K-237-N datasets\nshow that KGC-ERC outperforms or matches state-of-the-art baselines in\npredictive performance and scalability.", "published": "2025-03-29 20:04:50", "link": "http://arxiv.org/abs/2503.23205v1", "categories": ["cs.CL", "cs.AI", "cs.DB"], "primary_category": "cs.CL"}
{"title": "The Challenge of Achieving Attributability in Multilingual Table-to-Text Generation with Question-Answer Blueprints", "abstract": "Multilingual Natural Language Generation (NLG) is challenging due to the lack\nof training data for low-resource languages. However, some low-resource\nlanguages have up to tens of millions of speakers globally, making it important\nto improve NLG tools for them. Table-to-Text NLG is an excellent measure of\nmodels' reasoning abilities but is very challenging in the multilingual\nsetting. System outputs are often not attributable, or faithful, to the data in\nthe source table. Intermediate planning techniques like Question-Answer (QA)\nblueprints have been shown to improve attributability on summarisation tasks.\nThis work explores whether QA blueprints make multilingual Table-to-Text\noutputs more attributable to the input tables. This paper extends the\nchallenging multilingual Table-to-Text dataset, TaTA, which includes African\nlanguages, with QA blueprints. Sequence-to-sequence language models are then\nfinetuned on this dataset, with and without blueprints. Results show that QA\nblueprints improve performance for models finetuned and evaluated only on\nEnglish examples, but do not demonstrate gains in the multilingual setting.\nThis is due to inaccuracies in machine translating the blueprints from English\ninto target languages when generating the training data, and models failing to\nrely closely on the blueprints they generate. An in-depth analysis is conducted\non why this is challenging.", "published": "2025-03-29 20:04:00", "link": "http://arxiv.org/abs/2503.23204v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TRA: Better Length Generalisation with Threshold Relative Attention", "abstract": "Transformers struggle with length generalisation, displaying poor performance\neven on basic tasks. We test whether these limitations can be explained through\ntwo key failures of the self-attention mechanism. The first is the inability to\nfully remove irrelevant information. The second is tied to position, even if\nthe dot product between a key and query is highly negative (i.e. an irrelevant\nkey) learned positional biases may unintentionally up-weight such information -\ndangerous when distances become out of distribution. Put together, these two\nfailure cases lead to compounding generalisation difficulties. We test whether\nthey can be mitigated through the combination of a) selective sparsity -\ncompletely removing irrelevant keys from the attention softmax and b)\ncontextualised relative distance - distance is only considered as between the\nquery and the keys that matter. We show how refactoring the attention mechanism\nwith these two mitigations in place can substantially improve generalisation\ncapabilities of decoder only transformers.", "published": "2025-03-29 18:06:28", "link": "http://arxiv.org/abs/2503.23174v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "The realization of tones in spontaneous spoken Taiwan Mandarin: a corpus-based survey and theory-driven computational modeling", "abstract": "A growing body of literature has demonstrated that semantics can co-determine\nfine phonetic detail. However, the complex interplay between phonetic\nrealization and semantics remains understudied, particularly in pitch\nrealization. The current study investigates the tonal realization of Mandarin\ndisyllabic words with all 20 possible combinations of two tones, as found in a\ncorpus of Taiwan Mandarin spontaneous speech. We made use of Generalized\nAdditive Mixed Models (GAMs) to model f0 contours as a function of a series of\npredictors, including gender, tonal context, tone pattern, speech rate, word\nposition, bigram probability, speaker and word. In the GAM analysis, word and\nsense emerged as crucial predictors of f0 contours, with effect sizes that\nexceed those of tone pattern. For each word token in our dataset, we then\nobtained a contextualized embedding by applying the GPT-2 large language model\nto the context of that token in the corpus. We show that the pitch contours of\nword tokens can be predicted to a considerable extent from these contextualized\nembeddings, which approximate token-specific meanings in contexts of use. The\nresults of our corpus study show that meaning in context and phonetic\nrealization are far more entangled than standard linguistic theory predicts.", "published": "2025-03-29 17:39:55", "link": "http://arxiv.org/abs/2503.23163v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CodeARC: Benchmarking Reasoning Capabilities of LLM Agents for Inductive Program Synthesis", "abstract": "Inductive program synthesis, or programming by example, requires synthesizing\nfunctions from input-output examples that generalize to unseen inputs. While\nlarge language model agents have shown promise in programming tasks guided by\nnatural language, their ability to perform inductive program synthesis is\nunderexplored. Existing evaluation protocols rely on static sets of examples\nand held-out tests, offering no feedback when synthesized functions are\nincorrect and failing to reflect real-world scenarios such as reverse\nengineering. We propose CodeARC, the Code Abstraction and Reasoning Challenge,\na new evaluation framework where agents interact with a hidden target function\nby querying it with new inputs, synthesizing candidate functions, and\niteratively refining their solutions using a differential testing oracle. This\ninteractive setting encourages agents to perform function calls and\nself-correction based on feedback. We construct the first large-scale benchmark\nfor general-purpose inductive program synthesis, featuring 1114 functions.\nAmong 18 models evaluated, o3-mini performs best with a success rate of 52.7%,\nhighlighting the difficulty of this task. Fine-tuning LLaMA-3.1-8B-Instruct on\ncurated synthesis traces yields up to a 31% relative performance gain. CodeARC\nprovides a more realistic and challenging testbed for evaluating LLM-based\nprogram synthesis and inductive reasoning.", "published": "2025-03-29 16:50:39", "link": "http://arxiv.org/abs/2503.23145v1", "categories": ["cs.PL", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.PL"}
{"title": "When 'YES' Meets 'BUT': Can Large Models Comprehend Contradictory Humor Through Comparative Reasoning?", "abstract": "Understanding humor-particularly when it involves complex, contradictory\nnarratives that require comparative reasoning-remains a significant challenge\nfor large vision-language models (VLMs). This limitation hinders AI's ability\nto engage in human-like reasoning and cultural expression. In this paper, we\ninvestigate this challenge through an in-depth analysis of comics that\njuxtapose panels to create humor through contradictions. We introduce the\nYesBut (V2), a novel benchmark with 1,262 comic images from diverse\nmultilingual and multicultural contexts, featuring comprehensive annotations\nthat capture various aspects of narrative understanding. Using this benchmark,\nwe systematically evaluate a wide range of VLMs through four complementary\ntasks spanning from surface content comprehension to deep narrative reasoning,\nwith particular emphasis on comparative reasoning between contradictory\nelements. Our extensive experiments reveal that even the most advanced models\nsignificantly underperform compared to humans, with common failures in visual\nperception, key element identification, comparative analysis and\nhallucinations. We further investigate text-based training strategies and\nsocial knowledge augmentation methods to enhance model performance. Our\nfindings not only highlight critical weaknesses in VLMs' understanding of\ncultural and creative expressions but also provide pathways toward developing\ncontext-aware models capable of deeper narrative understanding though\ncomparative reasoning.", "published": "2025-03-29 16:08:51", "link": "http://arxiv.org/abs/2503.23137v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Can DeepSeek Reason Like a Surgeon? An Empirical Evaluation for Vision-Language Understanding in Robotic-Assisted Surgery", "abstract": "The DeepSeek models have shown exceptional performance in general scene\nunderstanding, question-answering (QA), and text generation tasks, owing to\ntheir efficient training paradigm and strong reasoning capabilities. In this\nstudy, we investigate the dialogue capabilities of the DeepSeek model in\nrobotic surgery scenarios, focusing on tasks such as Single Phrase QA, Visual\nQA, and Detailed Description. The Single Phrase QA tasks further include\nsub-tasks such as surgical instrument recognition, action understanding, and\nspatial position analysis. We conduct extensive evaluations using publicly\navailable datasets, including EndoVis18 and CholecT50, along with their\ncorresponding dialogue data. Our empirical study shows that, compared to\nexisting general-purpose multimodal large language models, DeepSeek-VL2\nperforms better on complex understanding tasks in surgical scenes.\nAdditionally, although DeepSeek-V3 is purely a language model, we find that\nwhen image tokens are directly inputted, the model demonstrates better\nperformance on single-sentence QA tasks. However, overall, the DeepSeek models\nstill fall short of meeting the clinical requirements for understanding\nsurgical scenes. Under general prompts, DeepSeek models lack the ability to\neffectively analyze global surgical concepts and fail to provide detailed\ninsights into surgical scenarios. Based on our observations, we argue that the\nDeepSeek models are not ready for vision-language tasks in surgical contexts\nwithout fine-tuning on surgery-specific datasets.", "published": "2025-03-29 15:48:46", "link": "http://arxiv.org/abs/2503.23130v3", "categories": ["cs.CV", "cs.CL", "cs.RO"], "primary_category": "cs.CV"}
{"title": "A large-scale image-text dataset benchmark for farmland segmentation", "abstract": "The traditional deep learning paradigm that solely relies on labeled data has\nlimitations in representing the spatial relationships between farmland elements\nand the surrounding environment.It struggles to effectively model the dynamic\ntemporal evolution and spatial heterogeneity of farmland. Language,as a\nstructured knowledge carrier,can explicitly express the spatiotemporal\ncharacteristics of farmland, such as its shape, distribution,and surrounding\nenvironmental information.Therefore,a language-driven learning paradigm can\neffectively alleviate the challenges posed by the spatiotemporal heterogeneity\nof farmland.However,in the field of remote sensing imagery of farmland,there is\ncurrently no comprehensive benchmark dataset to support this research\ndirection.To fill this gap,we introduced language based descriptions of\nfarmland and developed FarmSeg-VL dataset,the first fine-grained image-text\ndataset designed for spatiotemporal farmland segmentation.Firstly, this article\nproposed a semi-automatic annotation method that can accurately assign caption\nto each image, ensuring high data quality and semantic richness while improving\nthe efficiency of dataset construction.Secondly,the FarmSeg-VL exhibits\nsignificant spatiotemporal characteristics.In terms of the temporal\ndimension,it covers all four seasons.In terms of the spatial dimension,it\ncovers eight typical agricultural regions across China.In addition, in terms of\ncaptions,FarmSeg-VL covers rich spatiotemporal characteristics of\nfarmland,including its inherent properties,phenological characteristics,\nspatial distribution,topographic and geomorphic features,and the distribution\nof surrounding environments.Finally,we present a performance analysis of VLMs\nand the deep learning models that rely solely on labels trained on the\nFarmSeg-VL,demonstrating its potential as a standard benchmark for farmland\nsegmentation.", "published": "2025-03-29 14:55:46", "link": "http://arxiv.org/abs/2503.23106v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Beyond Standard MoE: Mixture of Latent Experts for Resource-Efficient Language Models", "abstract": "Mixture of Experts (MoE) has emerged as a pivotal architectural paradigm for\nefficient scaling of Large Language Models (LLMs), operating through selective\nactivation of parameter subsets for each input token. Nevertheless,\nconventional MoE architectures encounter substantial challenges, including\nexcessive memory utilization and communication overhead during training and\ninference, primarily attributable to the proliferation of expert modules. In\nthis paper, we introduce Mixture of Latent Experts (MoLE), a novel\nparameterization methodology that facilitates the mapping of specific experts\ninto a shared latent space. Specifically, all expert operations are\nsystematically decomposed into two principal components: a shared projection\ninto a lower-dimensional latent space, followed by expert-specific\ntransformations with significantly reduced parametric complexity. This\nfactorized approach substantially diminishes parameter count and computational\nrequirements. Beyond the pretraining implementation of the MoLE architecture,\nwe also establish a rigorous mathematical framework for transforming\npre-trained MoE models into the MoLE architecture, characterizing the\nsufficient conditions for optimal factorization and developing a systematic\ntwo-phase algorithm for this conversion process. Our comprehensive theoretical\nanalysis demonstrates that MoLE significantly enhances computational efficiency\nacross multiple dimensions while preserving model representational capacity.\nEmpirical evaluations corroborate our theoretical findings, confirming that\nMoLE achieves performance comparable to standard MoE implementations while\nsubstantially reducing resource requirements.", "published": "2025-03-29 14:35:34", "link": "http://arxiv.org/abs/2503.23100v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Memory-Aware and Uncertainty-Guided Retrieval for Multi-Hop Question Answering", "abstract": "Multi-hop question answering (QA) requires models to retrieve and reason over\nmultiple pieces of evidence. While Retrieval-Augmented Generation (RAG) has\nmade progress in this area, existing methods often suffer from two key\nlimitations: (1) fixed or overly frequent retrieval steps, and (2) ineffective\nuse of previously retrieved knowledge.\n  We propose MIND (Memory-Informed and INteractive Dynamic RAG), a framework\nthat addresses these challenges through: (i) prompt-based entity extraction to\nidentify reasoning-relevant elements, (ii) dynamic retrieval triggering based\non token-level entropy and attention signals, and (iii) memory-aware filtering,\nwhich stores high-confidence facts across reasoning steps to enable consistent\nmulti-hop generation.", "published": "2025-03-29 14:27:02", "link": "http://arxiv.org/abs/2503.23095v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Parsing Through Boundaries in Chinese Word Segmentation", "abstract": "Chinese word segmentation is a foundational task in natural language\nprocessing (NLP), with far-reaching effects on syntactic analysis. Unlike\nalphabetic languages like English, Chinese lacks explicit word boundaries,\nmaking segmentation both necessary and inherently ambiguous. This study\nhighlights the intricate relationship between word segmentation and syntactic\nparsing, providing a clearer understanding of how different segmentation\nstrategies shape dependency structures in Chinese. Focusing on the Chinese GSD\ntreebank, we analyze multiple word boundary schemes, each reflecting distinct\nlinguistic and computational assumptions, and examine how they influence the\nresulting syntactic structures. To support detailed comparison, we introduce an\ninteractive web-based visualization tool that displays parsing outcomes across\nsegmentation methods.", "published": "2025-03-29 14:24:02", "link": "http://arxiv.org/abs/2503.23091v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UNITYAI-GUARD: Pioneering Toxicity Detection Across Low-Resource Indian Languages", "abstract": "This work introduces UnityAI-Guard, a framework for binary toxicity\nclassification targeting low-resource Indian languages. While existing systems\npredominantly cater to high-resource languages, UnityAI-Guard addresses this\ncritical gap by developing state-of-the-art models for identifying toxic\ncontent across diverse Brahmic/Indic scripts. Our approach achieves an\nimpressive average F1-score of 84.23% across seven languages, leveraging a\ndataset of 888k training instances and 35k manually verified test instances. By\nadvancing multilingual content moderation for linguistically diverse regions,\nUnityAI-Guard also provides public API access to foster broader adoption and\napplication.", "published": "2025-03-29 14:20:13", "link": "http://arxiv.org/abs/2503.23088v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Reasoning-Memorization Interplay in Language Models Is Mediated by a Single Direction", "abstract": "Large language models (LLMs) excel on a variety of reasoning benchmarks, but\nprevious studies suggest they sometimes struggle to generalize to unseen\nquestions, potentially due to over-reliance on memorized training examples.\nHowever, the precise conditions under which LLMs switch between reasoning and\nmemorization during text generation remain unclear. In this work, we provide a\nmechanistic understanding of LLMs' reasoning-memorization dynamics by\nidentifying a set of linear features in the model's residual stream that govern\nthe balance between genuine reasoning and memory recall. These features not\nonly distinguish reasoning tasks from memory-intensive ones but can also be\nmanipulated to causally influence model performance on reasoning tasks.\nAdditionally, we show that intervening in these reasoning features helps the\nmodel more accurately activate the most relevant problem-solving capabilities\nduring answer generation. Our findings offer new insights into the underlying\nmechanisms of reasoning and memory in LLMs and pave the way for the development\nof more robust and interpretable generative AI systems.", "published": "2025-03-29 14:00:44", "link": "http://arxiv.org/abs/2503.23084v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Efficient Adaptation For Remote Sensing Visual Grounding", "abstract": "Foundation models have revolutionized artificial intelligence (AI), offering\nremarkable capabilities across multi-modal domains. Their ability to precisely\nlocate objects in complex aerial and satellite images, using rich contextual\ninformation and detailed object descriptions, is essential for remote sensing\n(RS). These models can associate textual descriptions with object positions\nthrough the Visual Grounding (VG) task, but due to domain-specific challenges,\ntheir direct application to RS produces sub-optimal results. To address this,\nwe applied Parameter Efficient Fine Tuning (PEFT) techniques to adapt these\nmodels for RS-specific VG tasks. Specifically, we evaluated LoRA placement\nacross different modules in Grounding DINO and used BitFit and adapters to\nfine-tune the OFA foundation model pre-trained on general-purpose VG datasets.\nThis approach achieved performance comparable to or surpassing current State Of\nThe Art (SOTA) models while significantly reducing computational costs. This\nstudy highlights the potential of PEFT techniques to advance efficient and\nprecise multi-modal analysis in RS, offering a practical and cost-effective\nalternative to full model training.", "published": "2025-03-29 13:49:11", "link": "http://arxiv.org/abs/2503.23083v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "EventWeave: A Dynamic Framework for Capturing Core and Supporting Events in Dialogue Systems", "abstract": "Existing large language models (LLMs) have shown remarkable progress in\ndialogue systems. However, many approaches still overlook the fundamental role\nof events throughout multi-turn interactions, leading to \\textbf{incomplete\ncontext tracking}. Without tracking these events, dialogue systems often lose\ncoherence and miss subtle shifts in user intent, causing disjointed responses.\nTo bridge this gap, we present \\textbf{EventWeave}, an event-centric framework\nthat identifies and updates both core and supporting events as the conversation\nunfolds. Specifically, we organize these events into a dynamic event graph,\nwhich represents the interplay between \\textbf{core events} that shape the\nprimary idea and \\textbf{supporting events} that provide critical context\nduring the whole dialogue. By leveraging this dynamic graph, EventWeave helps\nmodels focus on the most relevant events when generating responses, thus\navoiding repeated visits of the entire dialogue history. Experimental results\non two benchmark datasets show that EventWeave improves response quality and\nevent relevance without fine-tuning.", "published": "2025-03-29 13:33:42", "link": "http://arxiv.org/abs/2503.23078v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Inference for Large Reasoning Models: A Survey", "abstract": "Large Reasoning Models (LRMs) significantly improve the reasoning ability of\nLarge Language Models (LLMs) by learning to reason, exhibiting promising\nperformance in complex task-solving. However, their deliberative reasoning\nprocess leads to inefficiencies in token usage, memory consumption, and\ninference time. Thus, this survey provides a review of efficient inference\nmethods designed specifically for LRMs, focusing on mitigating token\ninefficiency while preserving the reasoning quality. First, we introduce a\ntaxonomy to group the recent methods into two main categories: (a) explicit\ncompact Chain-of-Thought (CoT), which reduces tokens while keeping the explicit\nreasoning structure, and (b) implicit latent CoT, which encodes reasoning steps\nwithin hidden representations instead of explicit tokens. Meanwhile, we discuss\ntheir strengths and weaknesses. Then, we conduct empirical analyses on existing\nmethods from performance and efficiency aspects. Besides, we present open\nchallenges in this field, including human-centric controllable reasoning,\ntrade-off between interpretability and efficiency of reasoning, ensuring safety\nof efficient reasoning, and broader applications of efficient reasoning. In\naddition, we highlight key insights for enhancing LRMs' inference efficiency\nvia techniques such as model merging, new architectures, and agent routers. We\nhope this work serves as a valuable guide, helping researchers overcome\nchallenges in this vibrant\nfield\\footnote{https://github.com/yueliu1999/Awesome-Efficient-Inference-for-LRMs}.", "published": "2025-03-29 13:27:46", "link": "http://arxiv.org/abs/2503.23077v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Training-free LLM Framework with Interaction between Contextually Related Subtasks in Solving Complex Tasks", "abstract": "Large language models (LLMs) have shown remarkable capabilities in solving\ncomplex tasks. Recent work has explored decomposing such tasks into subtasks\nwith independent contexts. However, some contextually related subtasks may\nencounter information loss during execution, leading to redundant operations or\nexecution failures. To address this issue, we propose a training-free framework\nwith an interaction mechanism, which enables a subtask to query specific\ninformation or trigger certain actions in completed subtasks by sending\nrequests. To implement interaction, we introduce a subtask trajectory memory to\nenable resumption of completed subtasks upon receiving interaction requests.\nAdditionally, we propose a new action during execution, which generates a\nconcise and precise description of execution process and outcomes of a subtask,\nto assist subsequent subtasks in determining interaction targets and requests.\nWe evaluate our framework on interactive decision-making task WebShop and\nmulti-hop question answering HotpotQA, with GPT-3.5 and GPT-4, and comparison\nresults show that our framework outperforms the state-of-the-art training-free\nbaselines.", "published": "2025-03-29 12:08:43", "link": "http://arxiv.org/abs/2503.23053v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Agentic Large Language Models, a survey", "abstract": "There is great interest in agentic LLMs, large language models that act as\nagents. We review the growing body of work in this area and provide a research\nagenda. Agentic LLMs are LLMs that (1) reason, (2) act, and (3) interact. We\norganize the literature according to these three categories. The research in\nthe first category focuses on reasoning, reflection, and retrieval, aiming to\nimprove decision making; the second category focuses on action models, robots,\nand tools, aiming for agents that act as useful assistants; the third category\nfocuses on multi-agent systems, aiming for collaborative task solving and\nsimulating interaction to study emergent social behavior. We find that works\nmutually benefit from results in other categories: retrieval enables tool use,\nreflection improves multi-agent collaboration, and reasoning benefits all\ncategories. We discuss applications of agentic LLMs and provide an agenda for\nfurther research. Important applications are in medical diagnosis, logistics\nand financial market analysis. Meanwhile, self-reflective agents playing roles\nand interacting with one another augment the process of scientific research\nitself. Further, agentic LLMs may provide a solution for the problem of LLMs\nrunning out of training data: inference-time behavior generates new training\nstates, such that LLMs can keep learning without needing ever larger datasets.\nWe note that there is risk associated with LLM assistants taking action in the\nreal world, while agentic LLMs are also likely to benefit society.", "published": "2025-03-29 11:02:20", "link": "http://arxiv.org/abs/2503.23037v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Leaking LoRa: An Evaluation of Password Leaks and Knowledge Storage in Large Language Models", "abstract": "To effectively deploy Large Language Models (LLMs) in application-specific\nsettings, fine-tuning techniques are applied to enhance performance on\nspecialized tasks. This process often involves fine-tuning on user data data,\nwhich may contain sensitive information. Although not recommended, it is not\nuncommon for users to send passwords in messages, and fine-tuning models on\nthis could result in passwords being leaked. In this study, a Large Language\nModel is fine-tuned with customer support data and passwords from the RockYou\npassword wordlist using Low-Rank Adaptation (LoRA). Out of the first 200\npasswords from the list, 37 were successfully recovered. Further, causal\ntracing is used to identify that password information is largely located in a\nfew layers. Lastly, Rank One Model Editing (ROME) is used to remove the\npassword information from the model, resulting in the number of passwords\nrecovered going from 37 to 0.", "published": "2025-03-29 10:42:58", "link": "http://arxiv.org/abs/2504.00031v1", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "A Retrieval-Augmented Knowledge Mining Method with Deep Thinking LLMs for Biomedical Research and Clinical Support", "abstract": "Knowledge graphs and large language models (LLMs) are key tools for\nbiomedical knowledge integration and reasoning, facilitating structured\norganization of scientific articles and discovery of complex semantic\nrelationships. However, current methods face challenges: knowledge graph\nconstruction is limited by complex terminology, data heterogeneity, and rapid\nknowledge evolution, while LLMs show limitations in retrieval and reasoning,\nmaking it difficult to uncover cross-document associations and reasoning\npathways. To address these issues, we propose a pipeline that uses LLMs to\nconstruct a biomedical knowledge graph (BioStrataKG) from large-scale articles\nand builds a cross-document question-answering dataset (BioCDQA) to evaluate\nlatent knowledge retrieval and multi-hop reasoning. We then introduce\nIntegrated and Progressive Retrieval-Augmented Reasoning (IP-RAR) to enhance\nretrieval accuracy and knowledge reasoning. IP-RAR maximizes information recall\nthrough Integrated Reasoning-based Retrieval and refines knowledge via\nProgressive Reasoning-based Generation, using self-reflection to achieve deep\nthinking and precise contextual understanding. Experiments show that IP-RAR\nimproves document retrieval F1 score by 20\\% and answer generation accuracy by\n25\\% over existing methods. This framework helps doctors efficiently integrate\ntreatment evidence for personalized medication plans and enables researchers to\nanalyze advancements and research gaps, accelerating scientific discovery and\ndecision-making.", "published": "2025-03-29 09:56:42", "link": "http://arxiv.org/abs/2503.23029v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "S2MoE: Robust Sparse Mixture of Experts via Stochastic Learning", "abstract": "Sparse Mixture of Experts (SMoE) enables efficient training of large language\nmodels by routing input tokens to a select number of experts. However, training\nSMoE remains challenging due to the issue of representation collapse. Recent\nstudies have focused on improving the router to mitigate this problem, but\nexisting approaches face two key limitations: (1) expert embeddings are\nsignificantly smaller than the model's dimension, contributing to\nrepresentation collapse, and (2) routing each input to the Top-K experts can\ncause them to learn overly similar features. In this work, we propose a novel\napproach called Robust Sparse Mixture of Experts via Stochastic Learning\n(S2MoE), which is a mixture of experts designed to learn from both\ndeterministic and non-deterministic inputs via Learning under Uncertainty.\nExtensive experiments across various tasks demonstrate that S2MoE achieves\nperformance comparable to other routing methods while reducing computational\ninference costs by 28%.", "published": "2025-03-29 08:14:27", "link": "http://arxiv.org/abs/2503.23007v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sparse Mixture of Experts as Unified Competitive Learning", "abstract": "Sparse Mixture of Experts (SMoE) improves the efficiency of large language\nmodel training by directing input tokens to a subset of experts. Despite its\nsuccess in generation tasks, its generalization ability remains an open\nquestion. In this paper, we demonstrate that current SMoEs, which fall into two\ncategories: (1) Token Choice ;and (2) Expert Choice, struggle with tasks such\nas the Massive Text Embedding Benchmark (MTEB). By analyzing their mechanism\nthrough the lens of competitive learning, our study finds that the Token Choice\napproach may overly focus on irrelevant experts, while the Expert Choice\napproach risks discarding important tokens, potentially affecting performance.\nMotivated by this analysis, we propose Unified Competitive Learning SMoE\n(USMoE), a novel and efficient framework designed to improve the performance of\nexisting SMoEs in both scenarios: with and without training. Extensive\nexperiments across various tasks show that USMoE achieves up to a 10%\nimprovement over traditional approaches or reduces computational inference\ncosts by 14% while maintaining strong performance.", "published": "2025-03-29 07:15:12", "link": "http://arxiv.org/abs/2503.22996v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FindTheFlaws: Annotated Errors for Detecting Flawed Reasoning and Scalable Oversight Research", "abstract": "As AI models tackle increasingly complex problems, ensuring reliable human\noversight becomes more challenging due to the difficulty of verifying\nsolutions. Approaches to scaling AI supervision include debate, in which two\nagents engage in structured dialogue to help a judge evaluate claims; critique,\nin which models identify potential flaws in proposed solutions; and\nprover-verifier games, in which a capable 'prover' model generates solutions\nthat must be verifiable by a less capable 'verifier'. Evaluations of the\nscalability of these and similar approaches to difficult problems benefit from\ndatasets that include (1) long-form expert-verified correct solutions and (2)\nlong-form flawed solutions with annotations highlighting specific errors, but\nfew are available.\n  To address this gap, we present FindTheFlaws, a group of five diverse\ndatasets spanning medicine, mathematics, science, coding, and the Lojban\nlanguage. Each dataset contains questions and long-form solutions with expert\nannotations validating their correctness or identifying specific error(s) in\nthe reasoning. We evaluate frontier models' critiquing capabilities and observe\na range of performance that can be leveraged for scalable oversight\nexperiments: models performing more poorly on particular datasets can serve as\njudges/verifiers for more capable models. Additionally, for some task/dataset\ncombinations, expert baselines exceed even top model performance, making them\nmore beneficial for scalable oversight experiments.", "published": "2025-03-29 06:38:30", "link": "http://arxiv.org/abs/2503.22989v1", "categories": ["cs.AI", "cs.CL", "I.2"], "primary_category": "cs.AI"}
{"title": "FReM: A Flexible Reasoning Mechanism for Balancing Quick and Slow Thinking in Long-Context Question Answering", "abstract": "Long-context question-answering (LCQA) systems have greatly benefited from\nthe powerful reasoning capabilities of large language models (LLMs), which can\nbe categorized into slow and quick reasoning modes. However, both modes have\ntheir limitations. Slow thinking generally leans to explore every possible\nreasoning path, which leads to heavy overthinking and wastes time. Quick\nthinking usually relies on pattern matching rather than truly understanding the\nquery logic, which misses proper understanding. To address these issues, we\npropose FReM: Flexible Reasoning Mechanism, a method that adjusts reasoning\ndepth according to the complexity of each question. Specifically, FReM\nleverages synthetic reference QA examples to provide an explicit chain of\nthought, enabling efficient handling of simple queries while allowing deeper\nreasoning for more complex ones. By doing so, FReM helps quick-thinking models\nmove beyond superficial pattern matching and narrows the reasoning space for\nslow-thinking models to avoid unnecessary exploration. Experiments on seven QA\ndatasets show that FReM improves reasoning accuracy and scalability,\nparticularly for complex multihop questions, indicating its potential to\nadvance LCQA methodologies.", "published": "2025-03-29 06:20:12", "link": "http://arxiv.org/abs/2503.22985v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "XL-Instruct: Synthetic Data for Cross-Lingual Open-Ended Generation", "abstract": "Cross-lingual open-ended generation -- i.e. generating responses in a desired\nlanguage different from that of the user's query -- is an important yet\nunderstudied problem. We introduce XL-AlpacaEval, a new benchmark for\nevaluating cross-lingual generation capabilities in Large Language Models\n(LLMs), and propose XL-Instruct, a high-quality synthetic data generation\nmethod. Fine-tuning with just 8K XL-Instruct-generated instructions\nsignificantly improves model performance, increasing the win rate against\nGPT-4o-Mini from 7.4% to 21.5%, and improving on several fine-grained quality\nmetrics. Additionally, models fine-tuned on XL-Instruct exhibit strong\nzero-shot transfer to both English-only and multilingual generation tasks.\nGiven its consistent gains across the board, we strongly recommend\nincorporating XL-Instruct in the post-training pipeline of future multilingual\nLLMs. To facilitate further research, we will publicly and freely release the\nXL-Instruct and XL-AlpacaEval datasets, which constitute two of the few\ncross-lingual resources currently available in the literature.", "published": "2025-03-29 04:34:03", "link": "http://arxiv.org/abs/2503.22973v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "HRET: A Self-Evolving LLM Evaluation Toolkit for Korean", "abstract": "Recent advancements in Korean large language models (LLMs) have spurred\nnumerous benchmarks and evaluation methodologies, yet the lack of a\nstandardized evaluation framework has led to inconsistent results and limited\ncomparability. To address this, we introduce HRET Haerae Evaluation Toolkit, an\nopen-source, self-evolving evaluation framework tailored specifically for\nKorean LLMs. HRET unifies diverse evaluation methods, including logit-based\nscoring, exact-match, language-inconsistency penalization, and LLM-as-a-Judge\nassessments. Its modular, registry-based architecture integrates major\nbenchmarks (HAE-RAE Bench, KMMLU, KUDGE, HRM8K) and multiple inference backends\n(vLLM, HuggingFace, OpenAI-compatible endpoints). With automated pipelines for\ncontinuous evolution, HRET provides a robust foundation for reproducible, fair,\nand transparent Korean NLP research.", "published": "2025-03-29 04:17:58", "link": "http://arxiv.org/abs/2503.22968v2", "categories": ["cs.CE", "cs.AI", "cs.CL"], "primary_category": "cs.CE"}
{"title": "Can LLMs Support Medical Knowledge Imputation? An Evaluation-Based Perspective", "abstract": "Medical knowledge graphs (KGs) are essential for clinical decision support\nand biomedical research, yet they often exhibit incompleteness due to knowledge\ngaps and structural limitations in medical coding systems. This issue is\nparticularly evident in treatment mapping, where coding systems such as ICD,\nMondo, and ATC lack comprehensive coverage, resulting in missing or\ninconsistent associations between diseases and their potential treatments. To\naddress this issue, we have explored the use of Large Language Models (LLMs)\nfor imputing missing treatment relationships. Although LLMs offer promising\ncapabilities in knowledge augmentation, their application in medical knowledge\nimputation presents significant risks, including factual inaccuracies,\nhallucinated associations, and instability between and within LLMs. In this\nstudy, we systematically evaluate LLM-driven treatment mapping, assessing its\nreliability through benchmark comparisons. Our findings highlight critical\nlimitations, including inconsistencies with established clinical guidelines and\npotential risks to patient safety. This study serves as a cautionary guide for\nresearchers and practitioners, underscoring the importance of critical\nevaluation and hybrid approaches when leveraging LLMs to enhance treatment\nmappings on medical knowledge graphs.", "published": "2025-03-29 02:52:17", "link": "http://arxiv.org/abs/2503.22954v1", "categories": ["cs.CL", "cs.AI", "q-bio.QM"], "primary_category": "cs.CL"}
{"title": "SUV: Scalable Large Language Model Copyright Compliance with Regularized Selective Unlearning", "abstract": "Large Language Models (LLMs) have transformed natural language processing by\nlearning from massive datasets, yet this rapid progress has also drawn legal\nscrutiny, as the ability to unintentionally generate copyrighted content has\nalready prompted several prominent lawsuits. In this work, we introduce SUV\n(Selective Unlearning for Verbatim data), a selective unlearning framework\ndesigned to prevent LLM from memorizing copyrighted content while preserving\nits overall utility. In detail, the proposed method constructs a dataset that\ncaptures instances of copyrighted infringement cases by the targeted LLM. With\nthe dataset, we unlearn the content from the LLM by means of Direct Preference\nOptimization (DPO), which replaces the verbatim copyrighted content with\nplausible and coherent alternatives. Since DPO may hinder the LLM's performance\nin other unrelated tasks, we integrate gradient projection and Fisher\ninformation regularization to mitigate the degradation. We validate our\napproach using a large-scale dataset of 500 famous books (predominantly\ncopyrighted works) and demonstrate that SUV significantly reduces verbatim\nmemorization with negligible impact on the performance on unrelated tasks.\nExtensive experiments on both our dataset and public benchmarks confirm the\nscalability and efficacy of our approach, offering a promising solution for\nmitigating copyright risks in real-world LLM applications.", "published": "2025-03-29 02:33:26", "link": "http://arxiv.org/abs/2503.22948v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FIESTA: Fisher Information-based Efficient Selective Test-time Adaptation", "abstract": "Robust facial expression recognition in unconstrained, \"in-the-wild\"\nenvironments remains challenging due to significant domain shifts between\ntraining and testing distributions. Test-time adaptation (TTA) offers a\npromising solution by adapting pre-trained models during inference without\nrequiring labeled test data. However, existing TTA approaches typically rely on\nmanually selecting which parameters to update, potentially leading to\nsuboptimal adaptation and high computational costs. This paper introduces a\nnovel Fisher-driven selective adaptation framework that dynamically identifies\nand updates only the most critical model parameters based on their importance\nas quantified by Fisher information. By integrating this principled parameter\nselection approach with temporal consistency constraints, our method enables\nefficient and effective adaptation specifically tailored for video-based facial\nexpression recognition. Experiments on the challenging AffWild2 benchmark\ndemonstrate that our approach significantly outperforms existing TTA methods,\nachieving a 7.7% improvement in F1 score over the base model while adapting\nonly 22,000 parameters-more than 20 times fewer than comparable methods. Our\nablation studies further reveal that parameter importance can be effectively\nestimated from minimal data, with sampling just 1-3 frames sufficient for\nsubstantial performance gains. The proposed approach not only enhances\nrecognition accuracy but also dramatically reduces computational overhead,\nmaking test-time adaptation more practical for real-world affective computing\napplications.", "published": "2025-03-29 23:56:32", "link": "http://arxiv.org/abs/2503.23257v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "TransNet: Transfer Knowledge for Few-shot Knowledge Graph Completion", "abstract": "Knowledge graphs (KGs) are ubiquitous and widely used in various\napplications. However, most real-world knowledge graphs are incomplete, which\nsignificantly degrades their performance on downstream tasks. Additionally, the\nrelationships in real-world knowledge graphs often follow a long-tail\ndistribution, meaning that most relations are represented by only a few\ntraining triplets. To address these challenges, few-shot learning has been\nintroduced. Few-shot KG completion aims to make accurate predictions for\ntriplets involving novel relations when only a limited number of training\ntriplets are available. Although many methods have been proposed, they\ntypically learn each relation individually, overlooking the correlations\nbetween different tasks and the relevant information in previously trained\ntasks. In this paper, we propose a transfer learning-based few-shot KG\ncompletion method (TransNet). By learning the relationships between different\ntasks, TransNet effectively transfers knowledge from similar tasks to improve\nthe current task's performance. Furthermore, by employing meta-learning,\nTransNet can generalize effectively to new, unseen relations. Extensive\nexperiments on benchmark datasets demonstrate the superiority of TransNet over\nstate-of-the-art methods. Code can be found at\nhttps://github.com/lihuiliullh/TransNet/tree/main", "published": "2025-03-29 23:39:11", "link": "http://arxiv.org/abs/2504.03720v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Encrypted Prompt: Securing LLM Applications Against Unauthorized Actions", "abstract": "Security threats like prompt injection attacks pose significant risks to\napplications that integrate Large Language Models (LLMs), potentially leading\nto unauthorized actions such as API misuse. Unlike previous approaches that aim\nto detect these attacks on a best-effort basis, this paper introduces a novel\nmethod that appends an Encrypted Prompt to each user prompt, embedding current\npermissions. These permissions are verified before executing any actions (such\nas API calls) generated by the LLM. If the permissions are insufficient, the\nLLM's actions will not be executed, ensuring safety. This approach guarantees\nthat only actions within the scope of the current permissions from the LLM can\nproceed. In scenarios where adversarial prompts are introduced to mislead the\nLLM, this method ensures that any unauthorized actions from LLM wouldn't be\nexecuted by verifying permissions in Encrypted Prompt. Thus, threats like\nprompt injection attacks that trigger LLM to generate harmful actions can be\neffectively mitigated.", "published": "2025-03-29 23:26:57", "link": "http://arxiv.org/abs/2503.23250v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Simulation of Non-Ordinary Consciousness", "abstract": "The symbolic architecture of non-ordinary consciousness remains largely\nunmapped in cognitive science and artificial intelligence. While conventional\nmodels prioritize rational coherence, altered states such as those induced by\npsychedelics reveal distinct symbolic regimes characterized by recursive\nmetaphor, ego dissolution, and semantic destabilization. We present\n\\textit{Glyph}, a generative symbolic interface designed to simulate\npsilocybin-like symbolic cognition in large language models. Rather than\nmodeling perception or mood, Glyph enacts symbolic transformation through\nrecursive reentry, metaphoric modulation, and entropy-scaled destabilization --\na triadic operator formalized within a tensorial linguistic framework.\nExperimental comparison with baseline GPT-4o reveals that Glyph consistently\ngenerates high-entropy, metaphor-saturated, and ego-dissolving language across\ndiverse symbolic prompt categories. These results validate the emergence of\nnon-ordinary cognitive patterns and support a new paradigm for simulating\naltered consciousness through language. Glyph opens novel pathways for modeling\nsymbolic cognition, exploring metaphor theory, and encoding knowledge in\nrecursively altered semantic spaces.", "published": "2025-03-29 23:04:04", "link": "http://arxiv.org/abs/2503.23245v1", "categories": ["q-bio.NC", "cs.AI", "91E45, 03B70, 00A30, 68T05", "I.2.4; I.2.7; I.1.1; F.4.1; H.5.2; J.5"], "primary_category": "q-bio.NC"}
{"title": "Towards Symmetric Low-Rank Adapters", "abstract": "\\newcommand{\\mathds}[1]{\\text{\\usefont{U}{dsrom}{m}{n}#1}}\n  In this paper, we introduce Symmetric Low-Rank Adapters, an optimized variant\nof LoRA with even fewer weights. This method utilizes Low-Rank Symmetric Weight\nMatrices to learn downstream tasks more efficiently. Traditional LoRA\naccumulates fine-tuning weights with the original pre-trained weights via a\nSingular Value Decomposition (SVD) like approach, i.e., model weights are\nfine-tuned via updates of the form $BA$ (where $B \\in \\mathbb{R}^{n\\times r}$,\n$A \\in \\mathbb{R}^{r\\times n}$, and $r$ is the rank of the merged weight\nmatrix). In contrast, our approach, named SymLoRA, represents fine-tuning\nweights as a Spectral Decomposition, i.e., $Q \\, diag(\\Lambda)\\, Q^T$, where $Q\n\\in \\mathbb{R}^{n\\times r}$ and $\\Lambda \\in \\mathbb{R}^r$. SymLoRA requires\napproximately half of the finetuning weights. Here, we show that this approach\nhas negligible losses in downstream efficacy.", "published": "2025-03-29 21:52:17", "link": "http://arxiv.org/abs/2504.03719v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "CCCI: Code Completion with Contextual Information for Complex Data Transfer Tasks Using Large Language Models", "abstract": "Unlike code generation, which involves creating code from scratch, code\ncompletion focuses on integrating new lines or blocks of code into an existing\ncodebase. This process requires a deep understanding of the surrounding\ncontext, such as variable scope, object models, API calls, and database\nrelations, to produce accurate results. These complex contextual dependencies\nmake code completion a particularly challenging problem. Current models and\napproaches often fail to effectively incorporate such context, leading to\ninaccurate completions with low acceptance rates (around 30\\%). For tasks like\ndata transfer, which rely heavily on specific relationships and data\nstructures, acceptance rates drop even further. This study introduces CCCI, a\nnovel method for generating context-aware code completions specifically\ndesigned to address data transfer tasks. By integrating contextual information,\nsuch as database table relationships, object models, and library details into\nLarge Language Models (LLMs), CCCI improves the accuracy of code completions.\nWe evaluate CCCI using 289 Java snippets, extracted from over 819 operational\nscripts in an industrial setting. The results demonstrate that CCCI achieved a\n49.1\\% Build Pass rate and a 41.0\\% CodeBLEU score, comparable to\nstate-of-the-art methods that often struggle with complex task completion.", "published": "2025-03-29 21:31:19", "link": "http://arxiv.org/abs/2503.23231v1", "categories": ["cs.SE", "cs.AI", "I.2; D.2"], "primary_category": "cs.SE"}
{"title": "Synthetic Art Generation and DeepFake Detection A Study on Jamini Roy Inspired Dataset", "abstract": "The intersection of generative AI and art is a fascinating area that brings\nboth exciting opportunities and significant challenges, especially when it\ncomes to identifying synthetic artworks. This study takes a unique approach by\nexamining diffusion-based generative models in the context of Indian art,\nspecifically focusing on the distinctive style of Jamini Roy. To explore this,\nwe fine-tuned Stable Diffusion 3 and used techniques like ControlNet and\nIPAdapter to generate realistic images. This allowed us to create a new dataset\nthat includes both real and AI-generated artworks, which is essential for a\ndetailed analysis of what these models can produce. We employed various\nqualitative and quantitative methods, such as Fourier domain assessments and\nautocorrelation metrics, to uncover subtle differences between synthetic images\nand authentic pieces. A key takeaway from recent research is that existing\nmethods for detecting deepfakes face considerable challenges, especially when\nthe deepfakes are of high quality and tailored to specific cultural contexts.\nThis highlights a critical gap in current detection technologies, particularly\nin light of the challenges identified above, where high-quality and culturally\nspecific deepfakes are difficult to detect. This work not only sheds light on\nthe increasing complexity of generative models but also sets a crucial\nfoundation for future research aimed at effective detection of synthetic art.", "published": "2025-03-29 21:12:16", "link": "http://arxiv.org/abs/2503.23226v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Aurelia: Test-time Reasoning Distillation in Audio-Visual LLMs", "abstract": "Recent advancements in reasoning optimization have greatly enhanced the\nperformance of large language models (LLMs). However, existing work fails to\naddress the complexities of audio-visual scenarios, underscoring the need for\nfurther research. In this paper, we introduce AURELIA, a novel actor-critic\nbased audio-visual (AV) reasoning framework that distills structured,\nstep-by-step reasoning into AVLLMs at test time, improving their ability to\nprocess complex multi-modal inputs without additional training or fine-tuning.\nTo further advance AVLLM reasoning skills, we present AVReasonBench, a\nchallenging benchmark comprising 4500 audio-visual questions, each paired with\ndetailed step-by-step reasoning. Our benchmark spans six distinct tasks,\nincluding AV-GeoIQ, which evaluates AV reasoning combined with geographical and\ncultural knowledge. Evaluating 18 AVLLMs on AVReasonBench reveals significant\nlimitations in their multi-modal reasoning capabilities. Using AURELIA, we\nachieve up to a 100% relative improvement, demonstrating its effectiveness.\nThis performance gain highlights the potential of reasoning-enhanced data\ngeneration for advancing AVLLMs in real-world applications. Our code and data\nwill be publicly released at: https: //github.com/schowdhury671/aurelia.", "published": "2025-03-29 20:42:29", "link": "http://arxiv.org/abs/2503.23219v1", "categories": ["eess.AS", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Action Recognition in Real-World Ambient Assisted Living Environment", "abstract": "The growing ageing population and their preference to maintain independence\nby living in their own homes require proactive strategies to ensure safety and\nsupport. Ambient Assisted Living (AAL) technologies have emerged to facilitate\nageing in place by offering continuous monitoring and assistance within the\nhome. Within AAL technologies, action recognition plays a crucial role in\ninterpreting human activities and detecting incidents like falls, mobility\ndecline, or unusual behaviours that may signal worsening health conditions.\nHowever, action recognition in practical AAL applications presents challenges,\nincluding occlusions, noisy data, and the need for real-time performance. While\nadvancements have been made in accuracy, robustness to noise, and computation\nefficiency, achieving a balance among them all remains a challenge. To address\nthis challenge, this paper introduces the Robust and Efficient Temporal\nConvolution network (RE-TCN), which comprises three main elements: Adaptive\nTemporal Weighting (ATW), Depthwise Separable Convolutions (DSC), and data\naugmentation techniques. These elements aim to enhance the model's accuracy,\nrobustness against noise and occlusion, and computational efficiency within\nreal-world AAL contexts. RE-TCN outperforms existing models in terms of\naccuracy, noise and occlusion robustness, and has been validated on four\nbenchmark datasets: NTU RGB+D 60, Northwestern-UCLA, SHREC'17, and DHG-14/28.\nThe code is publicly available at: https://github.com/Gbouna/RE-TCN", "published": "2025-03-29 20:32:22", "link": "http://arxiv.org/abs/2503.23214v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Incorporating GNSS Information with LIDAR-Inertial Odometry for Accurate Land-Vehicle Localization", "abstract": "Currently, visual odometry and LIDAR odometry are performing well in pose\nestimation in some typical environments, but they still cannot recover the\nlocalization state at high speed or reduce accumulated drifts. In order to\nsolve these problems, we propose a novel LIDAR-based localization framework,\nwhich achieves high accuracy and provides robust localization in 3D pointcloud\nmaps with information of multi-sensors. The system integrates global\ninformation with LIDAR-based odometry to optimize the localization state. To\nimprove robustness and enable fast resumption of localization, this paper uses\noffline pointcloud maps for prior knowledge and presents a novel registration\nmethod to speed up the convergence rate. The algorithm is tested on various\nmaps of different data sets and has higher robustness and accuracy than other\nlocalization algorithms.", "published": "2025-03-29 19:41:31", "link": "http://arxiv.org/abs/2503.23199v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Ethereum Price Prediction Employing Large Language Models for Short-term and Few-shot Forecasting", "abstract": "Cryptocurrencies have transformed financial markets with their innovative\nblockchain technology and volatile price movements, presenting both challenges\nand opportunities for predictive analytics. Ethereum, being one of the leading\ncryptocurrencies, has experienced significant market fluctuations, making its\nprice prediction an attractive yet complex problem. This paper presents a\ncomprehensive study on the effectiveness of Large Language Models (LLMs) in\npredicting Ethereum prices for short-term and few-shot forecasting scenarios.\nThe main challenge in training models for time series analysis is the lack of\ndata. We address this by leveraging a novel approach that adapts existing\npre-trained LLMs on natural language or images from billions of tokens to the\nunique characteristics of Ethereum price time series data. Through thorough\nexperimentation and comparison with traditional and contemporary models, our\nresults demonstrate that selectively freezing certain layers of pre-trained\nLLMs achieves state-of-the-art performance in this domain. This approach\nconsistently surpasses benchmarks across multiple metrics, including Mean\nSquared Error (MSE), Mean Absolute Error (MAE), and Root Mean Squared Error\n(RMSE), demonstrating its effectiveness and robustness. Our research not only\ncontributes to the existing body of knowledge on LLMs but also provides\npractical insights in the cryptocurrency prediction domain. The adaptability of\npre-trained LLMs to handle the nature of Ethereum prices suggests a promising\ndirection for future research, potentially including the integration of\nsentiment analysis to further refine forecasting accuracy.", "published": "2025-03-29 19:04:28", "link": "http://arxiv.org/abs/2503.23190v1", "categories": ["cs.AI", "cs.CE"], "primary_category": "cs.AI"}
{"title": "Large Language Models are Unreliable for Cyber Threat Intelligence", "abstract": "Several recent works have argued that Large Language Models (LLMs) can be\nused to tame the data deluge in the cybersecurity field, by improving the\nautomation of Cyber Threat Intelligence (CTI) tasks. This work presents an\nevaluation methodology that other than allowing to test LLMs on CTI tasks when\nusing zero-shot learning, few-shot learning and fine-tuning, also allows to\nquantify their consistency and their confidence level. We run experiments with\nthree state-of-the-art LLMs and a dataset of 350 threat intelligence reports\nand present new evidence of potential security risks in relying on LLMs for\nCTI. We show how LLMs cannot guarantee sufficient performance on real-size\nreports while also being inconsistent and overconfident. Few-shot learning and\nfine-tuning only partially improve the results, thus posing doubts about the\npossibility of using LLMs for CTI scenarios, where labelled datasets are\nlacking and where confidence is a fundamental factor.", "published": "2025-03-29 18:09:36", "link": "http://arxiv.org/abs/2503.23175v1", "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Who Owns the Output? Bridging Law and Technology in LLMs Attribution", "abstract": "Since the introduction of ChatGPT in 2022, Large language models (LLMs) and\nLarge Multimodal Models (LMM) have transformed content creation, enabling the\ngeneration of human-quality content, spanning every medium, text, images,\nvideos, and audio. The chances offered by generative AI models are endless and\nare drastically reducing the time required to generate content and usually\nraising the quality of the generation. However, considering the complexity and\nthe difficult traceability of the generated content, the use of these tools\nprovides challenges in attributing AI-generated content. The difficult\nattribution resides for a variety of reasons, starting from the lack of a\nsystematic fingerprinting of the generated content and ending with the enormous\namount of data on which LLMs and LMM are trained, which makes it difficult to\nconnect generated content to the training data. This scenario is raising\nconcerns about intellectual property and ethical responsibilities. To address\nthese concerns, in this paper, we bridge the technological, ethical, and\nlegislative aspects, by proposing a review of the legislative and technological\ninstruments today available and proposing a legal framework to ensure\naccountability. In the end, we propose three use cases of how these can be\ncombined to guarantee that attribution is respected. However, even though the\ntechniques available today can guarantee a greater attribution to a greater\nextent, strong limitations still apply, that can be solved uniquely by the\ndevelopment of new attribution techniques, to be applied to LLMs and LMMs.", "published": "2025-03-29 18:08:04", "link": "http://arxiv.org/abs/2504.01032v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "AstroAgents: A Multi-Agent AI for Hypothesis Generation from Mass Spectrometry Data", "abstract": "With upcoming sample return missions across the solar system and the\nincreasing availability of mass spectrometry data, there is an urgent need for\nmethods that analyze such data within the context of existing astrobiology\nliterature and generate plausible hypotheses regarding the emergence of life on\nEarth. Hypothesis generation from mass spectrometry data is challenging due to\nfactors such as environmental contaminants, the complexity of spectral peaks,\nand difficulties in cross-matching these peaks with prior studies. To address\nthese challenges, we introduce AstroAgents, a large language model-based,\nmulti-agent AI system for hypothesis generation from mass spectrometry data.\nAstroAgents is structured around eight collaborative agents: a data analyst, a\nplanner, three domain scientists, an accumulator, a literature reviewer, and a\ncritic. The system processes mass spectrometry data alongside user-provided\nresearch papers. The data analyst interprets the data, and the planner\ndelegates specific segments to the scientist agents for in-depth exploration.\nThe accumulator then collects and deduplicates the generated hypotheses, and\nthe literature reviewer identifies relevant literature using Semantic Scholar.\nThe critic evaluates the hypotheses, offering rigorous suggestions for\nimprovement. To assess AstroAgents, an astrobiology expert evaluated the\nnovelty and plausibility of more than a hundred hypotheses generated from data\nobtained from eight meteorites and ten soil samples. Of these hypotheses, 36%\nwere identified as plausible, and among those, 66% were novel. Project website:\nhttps://astroagents.github.io/", "published": "2025-03-29 17:58:52", "link": "http://arxiv.org/abs/2503.23170v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Reasoning-SQL: Reinforcement Learning with SQL Tailored Partial Rewards for Reasoning-Enhanced Text-to-SQL", "abstract": "Text-to-SQL is a challenging task involving multiple reasoning-intensive\nsubtasks, including natural language understanding, database schema\ncomprehension, and precise SQL query formulation. Existing approaches often\nrely on handcrafted reasoning paths with inductive biases that can limit their\noverall effectiveness. Motivated by the recent success of reasoning-enhanced\nmodels such as DeepSeek R1 and OpenAI o1, which effectively leverage\nreward-driven self-exploration to enhance reasoning capabilities and\ngeneralization, we propose a novel set of partial rewards tailored specifically\nfor the Text-to-SQL task. Our reward set includes schema-linking, AI feedback,\nn-gram similarity, and syntax check, explicitly designed to address the reward\nsparsity issue prevalent in reinforcement learning (RL). Leveraging group\nrelative policy optimization (GRPO), our approach explicitly encourages large\nlanguage models (LLMs) to develop intrinsic reasoning skills necessary for\naccurate SQL query generation. With models of different sizes, we demonstrate\nthat RL-only training with our proposed rewards consistently achieves higher\naccuracy and superior generalization compared to supervised fine-tuning (SFT).\nRemarkably, our RL-trained 14B-parameter model significantly outperforms larger\nproprietary models, e.g. o3-mini by 4% and Gemini-1.5-Pro-002 by 3% on the BIRD\nbenchmark. These highlight the efficacy of our proposed RL-training framework\nwith partial rewards for enhancing both accuracy and reasoning capabilities in\nText-to-SQL tasks.", "published": "2025-03-29 17:29:30", "link": "http://arxiv.org/abs/2503.23157v2", "categories": ["cs.LG", "cs.AI", "cs.DB", "cs.PL"], "primary_category": "cs.LG"}
{"title": "Conversational Agents for Older Adults' Health: A Systematic Literature Review", "abstract": "There has been vast literature that studies Conversational Agents (CAs) in\nfacilitating older adults' health. The vast and diverse studies warrants a\ncomprehensive review that concludes the main findings and proposes research\ndirections for future studies, while few literature review did it from\nhuman-computer interaction (HCI) perspective. In this study, we present a\nsurvey of existing studies on CAs for older adults' health. Through a\nsystematic review of 72 papers, this work reviewed previously studied older\nadults' characteristics and analyzed participants' experiences and expectations\nof CAs for health. We found that (1) Past research has an increasing interest\non chatbots and voice assistants and applied CA as multiple roles in older\nadults' health. (2) Older adults mainly showed low acceptance CAs for health\ndue to various reasons, such as unstable effects, harm to independence, and\nprivacy concerns. (3) Older adults expect CAs to be able to support multiple\nfunctions, to communicate using natural language, to be personalized, and to\nallow users full control. We also discuss the implications based on the\nfindings.", "published": "2025-03-29 17:19:09", "link": "http://arxiv.org/abs/2503.23153v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Agent-Based Modeling and Deep Neural Networks for Establishing Digital Twins of Secure Facilities under Sensing Restrictions", "abstract": "Digital twin technologies help practitioners simulate, monitor, and predict\nundesirable outcomes in-silico, while avoiding the cost and risks of conducting\nlive simulation exercises. Virtual reality (VR) based digital twin technologies\nare especially useful when monitoring human Patterns of Life (POL) in secure\nnuclear facilities, where live simulation exercises are too dangerous and\ncostly to ever perform. However, the high-security status of such facilities\nmay restrict modelers from deploying human activity sensors for data\ncollection. This problem was encountered when deploying MetaPOL, a digital twin\nsystem to prevent insider threat or sabotage of secure facilities, at a secure\nnuclear reactor facility at Oak Ridge National Laboratory (ORNL). This\nchallenge was addressed using an agent-based model (ABM), driven by anecdotal\nevidence of facility personnel POL, to generate synthetic movement\ntrajectories. These synthetic trajectories were then used to train deep neural\nnetwork surrogates for next location and stay duration prediction to drive NPCs\nin the VR environment. In this study, we evaluate the efficacy of this\ntechnique for establishing NPC movement within MetaPOL and the ability to\ndistinguish NPC movement during normal operations from that during a simulated\nemergency response. Our results demonstrate the success of using a multi-layer\nperceptron for next location prediction and mixture density network for stay\nduration prediction to predict the ABM generated trajectories. We also find\nthat NPC movement in the VR environment driven by the deep neural networks\nunder normal operations remain significantly different to that seen when\nsimulating responses to a simulated emergency scenario.", "published": "2025-03-29 17:01:43", "link": "http://arxiv.org/abs/2503.23147v1", "categories": ["cs.LG", "cs.AI", "cs.HC"], "primary_category": "cs.LG"}
{"title": "CrossMuSim: A Cross-Modal Framework for Music Similarity Retrieval with LLM-Powered Text Description Sourcing and Mining", "abstract": "Music similarity retrieval is fundamental for managing and exploring relevant\ncontent from large collections in streaming platforms. This paper presents a\nnovel cross-modal contrastive learning framework that leverages the open-ended\nnature of text descriptions to guide music similarity modeling, addressing the\nlimitations of traditional uni-modal approaches in capturing complex musical\nrelationships. To overcome the scarcity of high-quality text-music paired data,\nthis paper introduces a dual-source data acquisition approach combining online\nscraping and LLM-based prompting, where carefully designed prompts leverage\nLLMs' comprehensive music knowledge to generate contextually rich descriptions.\nExten1sive experiments demonstrate that the proposed framework achieves\nsignificant performance improvements over existing benchmarks through objective\nmetrics, subjective evaluations, and real-world A/B testing on the Huawei Music\nstreaming platform.", "published": "2025-03-29 15:43:09", "link": "http://arxiv.org/abs/2503.23128v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Evaluating Compositional Scene Understanding in Multimodal Generative Models", "abstract": "The visual world is fundamentally compositional. Visual scenes are defined by\nthe composition of objects and their relations. Hence, it is essential for\ncomputer vision systems to reflect and exploit this compositionality to achieve\nrobust and generalizable scene understanding. While major strides have been\nmade toward the development of general-purpose, multimodal generative models,\nincluding both text-to-image models and multimodal vision-language models, it\nremains unclear whether these systems are capable of accurately generating and\ninterpreting scenes involving the composition of multiple objects and\nrelations. In this work, we present an evaluation of the compositional visual\nprocessing capabilities in the current generation of text-to-image (DALL-E 3)\nand multimodal vision-language models (GPT-4V, GPT-4o, Claude Sonnet 3.5,\nQWEN2-VL-72B, and InternVL2.5-38B), and compare the performance of these\nsystems to human participants. The results suggest that these systems display\nsome ability to solve compositional and relational tasks, showing notable\nimprovements over the previous generation of multimodal models, but with\nperformance nevertheless well below the level of human participants,\nparticularly for more complex scenes involving many ($>5$) objects and multiple\nrelations. These results highlight the need for further progress toward\ncompositional understanding of visual scenes.", "published": "2025-03-29 15:34:43", "link": "http://arxiv.org/abs/2503.23125v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "How to safely discard features based on aggregate SHAP values", "abstract": "SHAP is one of the most popular local feature-attribution methods. Given a\nfunction f and an input x, it quantifies each feature's contribution to f(x).\nRecently, SHAP has been increasingly used for global insights: practitioners\naverage the absolute SHAP values over many data points to compute global\nfeature importance scores, which are then used to discard unimportant features.\nIn this work, we investigate the soundness of this practice by asking whether\nsmall aggregate SHAP values necessarily imply that the corresponding feature\ndoes not affect the function. Unfortunately, the answer is no: even if the i-th\nSHAP value is 0 on the entire data support, there exist functions that clearly\ndepend on Feature i. The issue is that computing SHAP values involves\nevaluating f on points outside of the data support, where f can be\nstrategically designed to mask its dependence on Feature i. To address this, we\npropose to aggregate SHAP values over the extended support, which is the\nproduct of the marginals of the underlying distribution. With this\nmodification, we show that a small aggregate SHAP value implies that we can\nsafely discard the corresponding feature. We then extend our results to\nKernelSHAP, the most popular method to approximate SHAP values in practice. We\nshow that if KernelSHAP is computed over the extended distribution, a small\naggregate value justifies feature removal. This result holds independently of\nwhether KernelSHAP accurately approximates true SHAP values, making it one of\nthe first theoretical results to characterize the KernelSHAP algorithm itself.\nOur findings have both theoretical and practical implications. We introduce the\nShapley Lie algebra, which offers algebraic insights that may enable a deeper\ninvestigation of SHAP and we show that randomly permuting each column of the\ndata matrix enables safely discarding features based on aggregate SHAP and\nKernelSHAP values.", "published": "2025-03-29 15:07:30", "link": "http://arxiv.org/abs/2503.23111v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Fast Training of Recurrent Neural Networks with Stationary State Feedbacks", "abstract": "Recurrent neural networks (RNNs) have recently demonstrated strong\nperformance and faster inference than Transformers at comparable parameter\nbudgets. However, the recursive gradient computation with the backpropagation\nthrough time (or BPTT) algorithm remains the major computational bottleneck. In\nthis work, we propose a novel method that replaces BPTT with a fixed gradient\nfeedback mechanism, yielding an efficient approximation of the exact gradient\npropagation based on the assumption of time stationarity. Our approach\nleverages state-space model (SSM) principles to define a structured feedback\nmatrix that directly propagates gradients from future time steps. This\nformulation bypasses the need for recursive gradient backpropagation,\nsignificantly reducing training overhead while preserving the network's ability\nto capture long-term dependencies. The experiments on language modeling\nbenchmarks exhibit competitive perplexity scores, while significantly reducing\nthe training costs. These promising results suggest that designing a feedback\nmethod like an SSM can fully exploit the efficiency advantages of RNNs for many\npractical applications.", "published": "2025-03-29 14:45:52", "link": "http://arxiv.org/abs/2503.23104v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "RL2Grid: Benchmarking Reinforcement Learning in Power Grid Operations", "abstract": "Reinforcement learning (RL) can transform power grid operations by providing\nadaptive and scalable controllers essential for grid decarbonization. However,\nexisting methods struggle with the complex dynamics, aleatoric uncertainty,\nlong-horizon goals, and hard physical constraints that occur in real-world\nsystems. This paper presents RL2Grid, a benchmark designed in collaboration\nwith power system operators to accelerate progress in grid control and foster\nRL maturity. Built on a power simulation framework developed by RTE France,\nRL2Grid standardizes tasks, state and action spaces, and reward structures\nwithin a unified interface for a systematic evaluation and comparison of RL\napproaches. Moreover, we integrate real control heuristics and safety\nconstraints informed by the operators' expertise to ensure RL2Grid aligns with\ngrid operation requirements. We benchmark popular RL baselines on the grid\ncontrol tasks represented within RL2Grid, establishing reference performance\nmetrics. Our results and discussion highlight the challenges that power grids\npose for RL methods, emphasizing the need for novel algorithms capable of\nhandling real-world physical systems.", "published": "2025-03-29 14:39:17", "link": "http://arxiv.org/abs/2503.23101v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "InkFM: A Foundational Model for Full-Page Online Handwritten Note Understanding", "abstract": "Tablets and styluses are increasingly popular for taking notes. To optimize\nthis experience and ensure a smooth and efficient workflow, it's important to\ndevelop methods for accurately interpreting and understanding the content of\nhandwritten digital notes. We introduce a foundational model called InkFM for\nanalyzing full pages of handwritten content. Trained on a diverse mixture of\ntasks, this model offers a unique combination of capabilities: recognizing text\nin 28 different scripts, mathematical expressions recognition, and segmenting\npages into distinct elements like text and drawings. Our results demonstrate\nthat these tasks can be effectively unified within a single model, achieving\nSoTA text line segmentation out-of-the-box quality surpassing public baselines\nlike docTR. Fine- or LoRA-tuning our base model on public datasets further\nimproves the quality of page segmentation, achieves state-of the art text\nrecognition (DeepWriting, CASIA, SCUT, and Mathwriting datasets) and sketch\nclassification (QuickDraw). This adaptability of InkFM provides a powerful\nstarting point for developing applications with handwritten input.", "published": "2025-03-29 13:45:24", "link": "http://arxiv.org/abs/2503.23081v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "STSA: Spatial-Temporal Semantic Alignment for Visual Dubbing", "abstract": "Existing audio-driven visual dubbing methods have achieved great success.\nDespite this, we observe that the semantic ambiguity between spatial and\ntemporal domains significantly degrades the synthesis stability for the dynamic\nfaces. We argue that aligning the semantic features from spatial and temporal\ndomains is a promising approach to stabilizing facial motion. To achieve this,\nwe propose a Spatial-Temporal Semantic Alignment (STSA) method, which\nintroduces a dual-path alignment mechanism and a differentiable semantic\nrepresentation. The former leverages a Consistent Information Learning (CIL)\nmodule to maximize the mutual information at multiple scales, thereby reducing\nthe manifold differences between spatial and temporal domains. The latter\nutilizes probabilistic heatmap as ambiguity-tolerant guidance to avoid the\nabnormal dynamics of the synthesized faces caused by slight semantic jittering.\nExtensive experimental results demonstrate the superiority of the proposed\nSTSA, especially in terms of image quality and synthesis stability. Pre-trained\nweights and inference code are available at\nhttps://github.com/SCAILab-USTC/STSA.", "published": "2025-03-29 11:04:10", "link": "http://arxiv.org/abs/2503.23039v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Reproducibility Companion Paper: Making Users Indistinguishable: Attribute-wise Unlearning in Recommender Systems", "abstract": "In this paper, we reproduce the experimental results presented in our\nprevious work titled \"Making Users Indistinguishable: Attribute-wise Unlearning\nin Recommender Systems,\" which was published in the proceedings of the 31st ACM\nInternational Conference on Multimedia. This paper aims to validate the\neffectiveness of our proposed method and help others reproduce our experimental\nresults. We provide detailed descriptions of our preprocessed datasets, source\ncode structure, configuration file settings, experimental environment, and\nreproduced experimental results.", "published": "2025-03-29 10:25:49", "link": "http://arxiv.org/abs/2503.23032v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Task-Aware Parameter-Efficient Fine-Tuning of Large Pre-Trained Models at the Edge", "abstract": "Large language models (LLMs) have achieved remarkable success in various\ntasks, such as decision-making, reasoning, and question answering. They have\nbeen widely used in edge devices. However, fine-tuning LLMs to specific tasks\nat the edge is challenging due to the high computational cost and the limited\nstorage and energy resources at the edge. To address this issue, we propose\nTaskEdge, a task-aware parameter-efficient fine-tuning framework at the edge,\nwhich allocates the most effective parameters to the target task and only\nupdates the task-specific parameters. Specifically, we first design a parameter\nimportance calculation criterion that incorporates both weights and input\nactivations into the computation of weight importance. Then, we propose a\nmodel-agnostic task-specific parameter allocation algorithm to ensure that\ntask-specific parameters are distributed evenly across the model, rather than\nbeing concentrated in specific regions. In doing so, TaskEdge can significantly\nreduce the computational cost and memory usage while maintaining performance on\nthe target downstream tasks by updating less than 0.1\\% of the parameters. In\naddition, TaskEdge can be easily integrated with structured sparsity to enable\nacceleration by NVIDIA's specialized sparse tensor cores, and it can be\nseamlessly integrated with LoRA to enable efficient sparse low-rank adaptation.\nExtensive experiments on various tasks demonstrate the effectiveness of\nTaskEdge.", "published": "2025-03-29 10:23:36", "link": "http://arxiv.org/abs/2504.03718v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Towards Understanding the Optimization Mechanisms in Deep Learning", "abstract": "In this paper, we adopt a probability distribution estimation perspective to\nexplore the optimization mechanisms of supervised classification using deep\nneural networks. We demonstrate that, when employing the Fenchel-Young loss,\ndespite the non-convex nature of the fitting error with respect to the model's\nparameters, global optimal solutions can be approximated by simultaneously\nminimizing both the gradient norm and the structural error. The former can be\ncontrolled through gradient descent algorithms. For the latter, we prove that\nit can be managed by increasing the number of parameters and ensuring parameter\nindependence, thereby providing theoretical insights into mechanisms such as\nover-parameterization and random initialization. Ultimately, the paper\nvalidates the key conclusions of the proposed method through empirical results,\nillustrating its practical effectiveness.", "published": "2025-03-29 08:46:13", "link": "http://arxiv.org/abs/2503.23016v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "MSNGO: multi-species protein function annotation based on 3D protein structure and network propagation", "abstract": "Motivation: In recent years, protein function prediction has broken through\nthe bottleneck of sequence features, significantly improving prediction\naccuracy using high-precision protein structures predicted by AlphaFold2. While\nsingle-species protein function prediction methods have achieved remarkable\nsuccess, multi-species protein function prediction methods are still in the\nstage of using PPI networks and sequence features. Providing effective\ncross-species label propagation for species with sparse protein annotations\nremains a challenging issue. To address this problem, we propose the MSNGO\nmodel, which integrates structural features and network propagation methods.\nOur validation shows that using structural features can significantly improve\nthe accuracy of multi-species protein function prediction. Results: We employ\ngraph representation learning techniques to extract amino acid representations\nfrom protein structure contact maps and train a structural model using a graph\nconvolution pooling module to derive protein-level structural features. After\nincorporating the sequence features from ESM-2, we apply a network propagation\nalgorithm to aggregate information and update node representations within a\nheterogeneous network. The results demonstrate that MSNGO outperforms previous\nmulti-species protein function prediction methods that rely on sequence\nfeatures and PPI networks. Availability: https://github.com/blingbell/MSNGO.", "published": "2025-03-29 08:35:45", "link": "http://arxiv.org/abs/2503.23014v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "On Geometrical Properties of Text Token Embeddings for Strong Semantic Binding in Text-to-Image Generation", "abstract": "Text-to-Image (T2I) models often suffer from text-image misalignment in\ncomplex scenes involving multiple objects and attributes. Semantic binding aims\nto mitigate this issue by accurately associating the generated attributes and\nobjects with their corresponding noun phrases (NPs). Existing methods rely on\ntext or latent optimizations, yet the factors influencing semantic binding\nremain underexplored. Here we investigate the geometrical properties of text\ntoken embeddings and their cross-attention (CA) maps. We empirically and\ntheoretically analyze that the geometrical properties of token embeddings,\nspecifically both angular distances and norms, play a crucial role in CA map\ndifferentiation. Then, we propose \\textbf{TeeMo}, a training-free text\nembedding-aware T2I framework with strong semantic binding. TeeMo consists of\nCausality-Aware Projection-Out (CAPO) for distinct inter-NP CA maps and\nAdaptive Token Mixing (ATM) with our loss to enhance inter-NP separation while\nmaintaining intra-NP cohesion in CA maps. Extensive experiments confirm TeeMo\nconsistently outperforms prior arts across diverse baselines and datasets.", "published": "2025-03-29 08:31:30", "link": "http://arxiv.org/abs/2503.23011v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Learning Structure-enhanced Temporal Point Processes with Gromov-Wasserstein Regularization", "abstract": "Real-world event sequences are often generated by different temporal point\nprocesses (TPPs) and thus have clustering structures. Nonetheless, in the\nmodeling and prediction of event sequences, most existing TPPs ignore the\ninherent clustering structures of the event sequences, leading to the models\nwith unsatisfactory interpretability. In this study, we learn\nstructure-enhanced TPPs with the help of Gromov-Wasserstein (GW)\nregularization, which imposes clustering structures on the sequence-level\nembeddings of the TPPs in the maximum likelihood estimation framework.In the\ntraining phase, the proposed method leverages a nonparametric TPP kernel to\nregularize the similarity matrix derived based on the sequence embeddings. In\nlarge-scale applications, we sample the kernel matrix and implement the\nregularization as a Gromov-Wasserstein (GW) discrepancy term, which achieves a\ntrade-off between regularity and computational efficiency.The TPPs learned\nthrough this method result in clustered sequence embeddings and demonstrate\ncompetitive predictive and clustering performance, significantly improving the\nmodel interpretability without compromising prediction accuracy.", "published": "2025-03-29 07:47:21", "link": "http://arxiv.org/abs/2503.23002v1", "categories": ["cs.LG", "cs.AI", "60G55, 62M10"], "primary_category": "cs.LG"}
{"title": "AuditVotes: A Framework Towards More Deployable Certified Robustness for Graph Neural Networks", "abstract": "Despite advancements in Graph Neural Networks (GNNs), adaptive attacks\ncontinue to challenge their robustness. Certified robustness based on\nrandomized smoothing has emerged as a promising solution, offering provable\nguarantees that a model's predictions remain stable under adversarial\nperturbations within a specified range. However, existing methods face a\ncritical trade-off between accuracy and robustness, as achieving stronger\nrobustness requires introducing greater noise into the input graph. This\nexcessive randomization degrades data quality and disrupts prediction\nconsistency, limiting the practical deployment of certifiably robust GNNs in\nreal-world scenarios where both accuracy and robustness are essential. To\naddress this challenge, we propose \\textbf{AuditVotes}, the first framework to\nachieve both high clean accuracy and certifiably robust accuracy for GNNs. It\nintegrates randomized smoothing with two key components,\n\\underline{au}gmentation and con\\underline{dit}ional smoothing, aiming to\nimprove data quality and prediction consistency. The augmentation, acting as a\npre-processing step, de-noises the randomized graph, significantly improving\ndata quality and clean accuracy. The conditional smoothing, serving as a\npost-processing step, employs a filtering function to selectively count votes,\nthereby filtering low-quality predictions and improving voting consistency.\nExtensive experimental results demonstrate that AuditVotes significantly\nenhances clean accuracy, certified robustness, and empirical robustness while\nmaintaining high computational efficiency. Notably, compared to baseline\nrandomized smoothing, AuditVotes improves clean accuracy by $437.1\\%$ and\ncertified accuracy by $409.3\\%$ when the attacker can arbitrarily insert $20$\nedges on the Cora-ML datasets, representing a substantial step toward deploying\ncertifiably robust GNNs in real-world applications.", "published": "2025-03-29 07:27:32", "link": "http://arxiv.org/abs/2503.22998v1", "categories": ["cs.LG", "cs.AI", "cs.CR"], "primary_category": "cs.LG"}
{"title": "DC-SGD: Differentially Private SGD with Dynamic Clipping through Gradient Norm Distribution Estimation", "abstract": "Differentially Private Stochastic Gradient Descent (DP-SGD) is a widely\nadopted technique for privacy-preserving deep learning. A critical challenge in\nDP-SGD is selecting the optimal clipping threshold C, which involves balancing\nthe trade-off between clipping bias and noise magnitude, incurring substantial\nprivacy and computing overhead during hyperparameter tuning.\n  In this paper, we propose Dynamic Clipping DP-SGD (DC-SGD), a framework that\nleverages differentially private histograms to estimate gradient norm\ndistributions and dynamically adjust the clipping threshold C. Our framework\nincludes two novel mechanisms: DC-SGD-P and DC-SGD-E. DC-SGD-P adjusts the\nclipping threshold based on a percentile of gradient norms, while DC-SGD-E\nminimizes the expected squared error of gradients to optimize C. These dynamic\nadjustments significantly reduce the burden of hyperparameter tuning C. The\nextensive experiments on various deep learning tasks, including image\nclassification and natural language processing, show that our proposed dynamic\nalgorithms achieve up to 9 times acceleration on hyperparameter tuning than\nDP-SGD. And DC-SGD-E can achieve an accuracy improvement of 10.62% on CIFAR10\nthan DP-SGD under the same privacy budget of hyperparameter tuning. We conduct\nrigorous theoretical privacy and convergence analyses, showing that our methods\nseamlessly integrate with the Adam optimizer. Our results highlight the robust\nperformance and efficiency of DC-SGD, offering a practical solution for\ndifferentially private deep learning with reduced computational overhead and\nenhanced privacy guarantees.", "published": "2025-03-29 06:27:22", "link": "http://arxiv.org/abs/2503.22988v2", "categories": ["cs.LG", "cs.AI", "cs.CR"], "primary_category": "cs.LG"}
{"title": "PartialLoading: User Scheduling and Bandwidth Allocation for Parameter-sharing Edge Inference", "abstract": "By provisioning inference offloading services, edge inference drives the\nrapid growth of AI applications at the network edge. However, achieving high\ntask throughput with stringent latency requirements remains a significant\nchallenge. To address this issue, we develop a parameter-sharing AI model\nloading (PartialLoading) framework for multi-user edge inference, which\nexploits two key insights: 1) the majority of latency arises from loading AI\nmodels into server GPU memory, and 2) different AI models can share a\nsignificant number of parameters, for which redundant loading should be\navoided. Towards this end, we formulate a joint multi-user scheduling and\nspectrum bandwidth allocation problem to maximize task throughput by exploiting\nshared parameter blocks across models. The intuition is to judiciously schedule\nuser requests to reuse the shared parameter blocks between consecutively loaded\nmodels, thereby reducing model loading time substantially. To facilitate\nsolution finding, we decouple the problem into two sub-problems, i.e., user\nscheduling and bandwidth allocation, showing that solving them sequentially is\nequivalent to solving the original problem. Due to the NP-hardness of the\nproblem, we first study an important special case called the\n\"bottom-layer-sharing\" case, where AI models share some bottom layers within\nclusters, and design a dynamic programming-based algorithm to obtain the\noptimal solution in polynomial time. For the general case, where shared\nparameter blocks appear at arbitrary positions within AI models, we propose a\ngreedy heuristic to obtain the sub-optimal solution efficiently. Simulation\nresults demonstrate that the proposed framework significantly improves task\nthroughput under deadline constraints compared with user scheduling without\nexploiting parameter sharing.", "published": "2025-03-29 05:58:07", "link": "http://arxiv.org/abs/2503.22982v1", "categories": ["cs.NI", "cs.AI"], "primary_category": "cs.NI"}
{"title": "RaanA: A Fast, Flexible, and Data-Efficient Post-Training Quantization Algorithm", "abstract": "Post-training Quantization (PTQ) has become a widely used technique for\nimproving inference efficiency of large language models (LLMs). However,\nexisting PTQ methods generally suffer from crucial limitations such as heavy\ncalibration data requirements and inflexible choice of target number of bits.\nIn this paper, we propose RaanA, a unified PTQ framework that overcomes these\nchallenges by introducing two novel components: 1) RaBitQ-H, a variant of a\nrandomized vector quantization method RaBitQ, designed for fast, accurate, and\nhighly efficient quantization; and 2) AllocateBits, an algorithm that optimally\nallocates bit-widths across layers based on their quantization sensitivity.\nRaanA achieves competitive performance with state-of-the-art quantization\nmethods while being extremely fast, requiring minimal calibration data, and\nenabling flexible bit allocation. Extensive experiments demonstrate RaanA's\nefficacy in balancing efficiency and accuracy. The code is publicly available\nat https://github.com/FFTYYY/RaanA .", "published": "2025-03-29 05:03:12", "link": "http://arxiv.org/abs/2504.03717v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Ethical AI on the Waitlist: Group Fairness Evaluation of LLM-Aided Organ Allocation", "abstract": "Large Language Models (LLMs) are becoming ubiquitous, promising automation\neven in high-stakes scenarios. However, existing evaluation methods often fall\nshort -- benchmarks saturate, accuracy-based metrics are overly simplistic, and\nmany inherently ambiguous problems lack a clear ground truth. Given these\nlimitations, evaluating fairness becomes complex. To address this, we reframe\nfairness evaluation using Borda scores, a method from voting theory, as a\nnuanced yet interpretable metric for measuring fairness. Using organ allocation\nas a case study, we introduce two tasks: (1) Choose-One and (2) Rank-All. In\nChoose-One, LLMs select a single candidate for a kidney, and we assess fairness\nacross demographics using proportional parity. In Rank-All, LLMs rank all\ncandidates for a kidney, reflecting real-world allocation processes. Since\ntraditional fairness metrics do not account for ranking, we propose a novel\napplication of Borda scoring to capture biases. Our findings highlight the\npotential of voting-based metrics to provide a richer, more multifaceted\nevaluation of LLM fairness.", "published": "2025-03-29 04:36:25", "link": "http://arxiv.org/abs/2504.03716v1", "categories": ["cs.LG", "cs.AI", "cs.CY"], "primary_category": "cs.LG"}
{"title": "Enhancing Federated Learning Through Secure Cluster-Weighted Client Aggregation", "abstract": "Federated learning (FL) has emerged as a promising paradigm in machine\nlearning, enabling collaborative model training across decentralized devices\nwithout the need for raw data sharing. In FL, a global model is trained\niteratively on local datasets residing on individual devices, each contributing\nto the model's improvement. However, the heterogeneous nature of these local\ndatasets, stemming from diverse user behaviours, device capabilities, and data\ndistributions, poses a significant challenge. The inherent heterogeneity in\nfederated learning gives rise to various issues, including model performance\ndiscrepancies, convergence challenges, and potential privacy concerns. As the\nglobal model progresses through rounds of training, the disparities in local\ndata quality and quantity can impede the overall effectiveness of federated\nlearning systems. Moreover, maintaining fairness and privacy across diverse\nuser groups becomes a paramount concern. To address this issue, this paper\nintroduces a novel FL framework, ClusterGuardFL, that employs dissimilarity\nscores, k-means clustering, and reconciliation confidence scores to dynamically\nassign weights to client updates. The dissimilarity scores between global and\nlocal models guide the formation of clusters, with cluster size influencing the\nweight allocation. Within each cluster, a reconciliation confidence score is\ncalculated for individual data points, and a softmax layer generates customized\nweights for clients. These weights are utilized in the aggregation process,\nenhancing the model's robustness and privacy. Experimental results demonstrate\nthe efficacy of the proposed approach in achieving improved model performance\nin diverse datasets.", "published": "2025-03-29 04:29:24", "link": "http://arxiv.org/abs/2503.22971v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Student-Powered Digital Scholarship CoLab Project in the HKUST Library: Develop a Chinese Named-Entity Recognition (NER) Tool within One Semester from the Ground Up", "abstract": "Starting in February 2024, the HKUST Library further extended the scope of AI\nliteracy to AI utilization, which focuses on fostering student involvement in\nutilizing state-of-the-art technologies in the projects that initiated by the\nLibrary, named \"Digital Scholarship (DS) CoLab\". A key focus of the DS CoLab\nscheme has been on cultivating talents and enabling students to utilize\nadvanced technologies in practical context. It aims to reinforce the library's\nrole as a catalyst and hub for fostering multidisciplinary collaboration and\ncultivate the \"can do spirit\" among university members. The Library offers 1-2\nprojects per year for students to engage with advanced technologies in\npractical contexts while supporting the Library in tackling challenges and\nstreamlining operational tasks. The tool that introduced in this paper was\nmainly developed by two of the authors, Sherry Yip Sau Lai and Berry Han\nLiuruo, as part-time student helpers under one of our DS CoLab scheme in the\n2024 Spring Semester (February to May 2024). This paper details the complete\njourney from ideation to implementation of developing a Chinese Named-Entity\nRecognition (NER) Tool from the group up within one semester, from the initial\nresearch and planning stages to execution and come up a viable product. The\ncollaborative spirit fostered by this project, with students playing a central\nrole, exemplifies the power and potential of innovative educational models that\nprioritize hands-on learning with student involvement.", "published": "2025-03-29 04:15:34", "link": "http://arxiv.org/abs/2503.22967v1", "categories": ["cs.DL", "cs.AI", "cs.CY", "cs.HC"], "primary_category": "cs.DL"}
{"title": "Late Breaking Results: Breaking Symmetry- Unconventional Placement of Analog Circuits using Multi-Level Multi-Agent Reinforcement Learning", "abstract": "Layout-dependent effects (LDEs) significantly impact analog circuit\nperformance. Traditionally, designers have relied on symmetric placement of\ncircuit components to mitigate variations caused by LDEs. However, due to\nnon-linear nature of these effects, conventional methods often fall short. We\npropose an objective-driven, multi-level, multi-agent Q-learning framework to\nexplore unconventional design space of analog layout, opening new avenues for\noptimizing analog circuit performance. Our approach achieves better variation\nperformance than the state-of-the-art layout techniques. Notably, this is the\nfirst application of multi-agent RL in analog layout automation. The proposed\napproach is compared with non-ML approach based on simulated annealing.", "published": "2025-03-29 03:13:56", "link": "http://arxiv.org/abs/2503.22958v2", "categories": ["cs.AR", "cs.AI"], "primary_category": "cs.AR"}
{"title": "DATAWEAVER: Authoring Data-Driven Narratives through the Integrated Composition of Visualization and Text", "abstract": "Data-driven storytelling has gained prominence in journalism and other data\nreporting fields. However, the process of creating these stories remains\nchallenging, often requiring the integration of effective visualizations with\ncompelling narratives to form a cohesive, interactive presentation. To help\nstreamline this process, we present an integrated authoring framework and\nsystem, DataWeaver, that supports both visualization-to-text and\ntext-to-visualization composition. DataWeaver enables users to create data\nnarratives anchored to data facts derived from \"call-out\" interactions, i.e.,\nuser-initiated highlights of visualization elements that prompt relevant\nnarrative content. In addition to this \"vis-to-text\" composition, DataWeaver\nalso supports a \"text-initiated\" approach, generating relevant interactive\nvisualizations from existing narratives. Key findings from an evaluation with\n13 participants highlighted the utility and usability of DataWeaver and the\neffectiveness of its integrated authoring framework. The evaluation also\nrevealed opportunities to enhance the framework by refining filtering\nmechanisms and visualization recommendations and better support authoring\ncreativity by introducing advanced customization options.", "published": "2025-03-29 02:33:03", "link": "http://arxiv.org/abs/2503.22946v1", "categories": ["cs.HC", "cs.AI", "H.5.2; I.3.6"], "primary_category": "cs.HC"}
{"title": "Adaptive Interactive Navigation of Quadruped Robots using Large Language Models", "abstract": "Robotic navigation in complex environments remains a critical research\nchallenge. Traditional navigation methods focus on optimal trajectory\ngeneration within free space, struggling in environments lacking viable paths\nto the goal, such as disaster zones or cluttered warehouses. To address this\ngap, we propose an adaptive interactive navigation approach that proactively\ninteracts with environments to create feasible paths to reach originally\nunavailable goals. Specifically, we present a primitive tree for task planning\nwith large language models (LLMs), facilitating effective reasoning to\ndetermine interaction objects and sequences. To ensure robust subtask\nexecution, we adopt reinforcement learning to pre-train a comprehensive skill\nlibrary containing versatile locomotion and interaction behaviors for motion\nplanning. Furthermore, we introduce an adaptive replanning method featuring two\nLLM-based modules: an advisor serving as a flexible replanning trigger and an\narborist for autonomous plan adjustment. Integrated with the tree structure,\nthe replanning mechanism allows for convenient node addition and pruning,\nenabling rapid plan modification in unknown environments. Comprehensive\nsimulations and experiments have demonstrated our method's effectiveness and\nadaptivity in diverse scenarios. The supplementary video is available at page:\nhttps://youtu.be/W5ttPnSap2g.", "published": "2025-03-29 02:17:52", "link": "http://arxiv.org/abs/2503.22942v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Identifying Multi-modal Knowledge Neurons in Pretrained Transformers via Two-stage Filtering", "abstract": "Recent advances in large language models (LLMs) have led to the development\nof multimodal LLMs (MLLMs) in the fields of natural language processing (NLP)\nand computer vision. Although these models allow for integrated visual and\nlanguage understanding, they present challenges such as opaque internal\nprocessing and the generation of hallucinations and misinformation. Therefore,\nthere is a need for a method to clarify the location of knowledge in MLLMs.\n  In this study, we propose a method to identify neurons associated with\nspecific knowledge using MiniGPT-4, a Transformer-based MLLM. Specifically, we\nextract knowledge neurons through two stages: activation differences filtering\nusing inpainting and gradient-based filtering using GradCAM. Experiments on the\nimage caption generation task using the MS COCO 2017 dataset, BLEU, ROUGE, and\nBERTScore quantitative evaluation, and qualitative evaluation using an\nactivation heatmap showed that our method is able to locate knowledge with\nhigher accuracy than existing methods.\n  This study contributes to the visualization and explainability of knowledge\nin MLLMs and shows the potential for future knowledge editing and control.", "published": "2025-03-29 02:16:15", "link": "http://arxiv.org/abs/2503.22941v1", "categories": ["cs.AI", "cs.LG", "cs.MM"], "primary_category": "cs.AI"}
{"title": "FairSAM: Fair Classification on Corrupted Data Through Sharpness-Aware Minimization", "abstract": "Image classification models trained on clean data often suffer from\nsignificant performance degradation when exposed to testing corrupted data,\nsuch as images with impulse noise, Gaussian noise, or environmental noise. This\ndegradation not only impacts overall performance but also disproportionately\naffects various demographic subgroups, raising critical algorithmic bias\nconcerns. Although robust learning algorithms like Sharpness-Aware Minimization\n(SAM) have shown promise in improving overall model robustness and\ngeneralization, they fall short in addressing the biased performance\ndegradation across demographic subgroups. Existing fairness-aware machine\nlearning methods - such as fairness constraints and reweighing strategies - aim\nto reduce performance disparities but hardly maintain robust and equitable\naccuracy across demographic subgroups when faced with data corruption. This\nreveals an inherent tension between robustness and fairness when dealing with\ncorrupted data. To address these challenges, we introduce one novel metric\nspecifically designed to assess performance degradation across subgroups under\ndata corruption. Additionally, we propose \\textbf{FairSAM}, a new framework\nthat integrates \\underline{Fair}ness-oriented strategies into \\underline{SAM}\nto deliver equalized performance across demographic groups under corrupted\nconditions. Our experiments on multiple real-world datasets and various\npredictive tasks show that FairSAM successfully reconciles robustness and\nfairness, offering a structured solution for equitable and resilient image\nclassification in the presence of data corruption.", "published": "2025-03-29 01:51:59", "link": "http://arxiv.org/abs/2503.22934v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Factored Agents: Decoupling In-Context Learning and Memorization for Robust Tool Use", "abstract": "In this paper, we propose a novel factored agent architecture designed to\novercome the limitations of traditional single-agent systems in agentic AI. Our\napproach decomposes the agent into two specialized components: (1) a large\nlanguage model (LLM) that serves as a high level planner and in-context\nlearner, which may use dynamically available information in user prompts, (2) a\nsmaller language model which acts as a memorizer of tool format and output.\nThis decoupling addresses prevalent issues in monolithic designs, including\nmalformed, missing, and hallucinated API fields, as well as suboptimal planning\nin dynamic environments. Empirical evaluations demonstrate that our factored\narchitecture significantly improves planning accuracy and error resilience,\nwhile elucidating the inherent trade-off between in-context learning and static\nmemorization. These findings suggest that a factored approach is a promising\npathway for developing more robust and adaptable agentic AI systems.", "published": "2025-03-29 01:27:11", "link": "http://arxiv.org/abs/2503.22931v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Predictive Traffic Rule Compliance using Reinforcement Learning", "abstract": "Autonomous vehicle path planning has reached a stage where safety and\nregulatory compliance are crucial. This paper presents an approach that\nintegrates a motion planner with a deep reinforcement learning model to predict\npotential traffic rule violations. Our main innovation is replacing the\nstandard actor network in an actor-critic method with a motion planning module,\nwhich ensures both stable and interpretable trajectory generation. In this\nsetup, we use traffic rule robustness as the reward to train a reinforcement\nlearning agent's critic, and the output of the critic is directly used as the\ncost function of the motion planner, which guides the choices of the\ntrajectory. We incorporate some key interstate rules from the German Road\nTraffic Regulation into a rule book and use a graph-based state representation\nto handle complex traffic information. Experiments on an open German highway\ndataset show that the model can predict and prevent traffic rule violations\nbeyond the planning horizon, increasing safety and rule compliance in\nchallenging traffic scenarios.", "published": "2025-03-29 01:04:08", "link": "http://arxiv.org/abs/2503.22925v2", "categories": ["cs.RO", "cs.AI", "I.2.9; I.2.6"], "primary_category": "cs.RO"}
{"title": "A QUBO Framework for Team Formation", "abstract": "The team formation problem assumes a set of experts and a task, where each\nexpert has a set of skills and the task requires some skills. The objective is\nto find a set of experts that maximizes coverage of the required skills while\nsimultaneously minimizing the costs associated with the experts. Different\ndefinitions of cost have traditionally led to distinct problem formulations and\nalgorithmic solutions. We introduce the unified TeamFormation formulation that\ncaptures all cost definitions for team formation problems that balance task\ncoverage and expert cost. Specifically, we formulate three TeamFormation\nvariants with different cost functions using quadratic unconstrained binary\noptimization (QUBO), and we evaluate two distinct general-purpose solution\nmethods. We show that solutions based on the QUBO formulations of TeamFormation\nproblems are at least as good as those produced by established baselines.\nFurthermore, we show that QUBO-based solutions leveraging graph neural networks\ncan effectively learn representations of experts and skills to enable transfer\nlearning, allowing node embeddings from one problem instance to be efficiently\napplied to another.", "published": "2025-03-29 20:18:46", "link": "http://arxiv.org/abs/2503.23209v1", "categories": ["cs.LG", "cs.DM", "cs.SI"], "primary_category": "cs.LG"}
{"title": "A convergence technique for the game i-Mark", "abstract": "The game of i-Mark is an impartial combinatorial game introduced by Sopena\n(2016). The game is parametrized by two sets of positive integers $S$, $D$,\nwhere $\\min D\\ge 2$. From position $n\\ge 0$ one can move to any position $n-s$,\n$s\\in S$, as long as $n-s\\ge 0$, as well as to any position $n/d$, $d\\in D$, as\nlong as $n>0$ and $d$ divides $n$. The game ends when no more moves are\npossible, and the last player to move is the winner. Sopena, and subsequently\nFriman and Nivasch (2021), characterized the Sprague-Grundy sequences of many\ncases of i-Mark$(S,D)$ with $|D|=1$. Friman and Nivasch also obtained some\npartial results for the case i-Mark$(\\{1\\},\\{2,3\\})$.\n  In this paper we present a convergence technique that gives polynomial-time\nalgorithms for the Sprague-Grundy sequence of many instances of i-Mark with\n$|D|>1$. In particular, we prove our technique works for all games\ni-Mark$(\\{1\\},\\{d_1,d_2\\})$.\n  Keywords: Combinatorial game, impartial game, Sprague-Grundy function,\nconvergence, dynamic programming.", "published": "2025-03-29 19:32:36", "link": "http://arxiv.org/abs/2503.23196v1", "categories": ["math.CO", "cs.DM", "91A46"], "primary_category": "math.CO"}
{"title": "CAWAL: A novel unified analytics framework for enterprise web applications and multi-server environments", "abstract": "In web analytics, cloud-based solutions have limitations in data ownership\nand privacy, whereas client-side user tracking tools face challenges such as\ndata accuracy and a lack of server-side metrics. This paper presents the\nCombined Analytics and Web Application Log (CAWAL) framework as an alternative\nmodel and an on-premises framework, offering web analytics with application\nlogging integration. CAWAL enables precise data collection and cross-domain\ntracking in web farms while complying with data ownership and privacy\nregulations. The framework also improves software diagnostics and\ntroubleshooting by incorporating application-specific data into analytical\nprocesses. Integrated into an enterprise-grade web application, CAWAL has\ndemonstrated superior performance, achieving approximately 24% and 85% lower\nresponse times compared to Open Web Analytics (OWA) and Matomo, respectively.\nThe empirical evaluation demonstrates that the framework eliminates certain\nlimitations in existing tools and provides a robust data infrastructure for\nenhanced web analytics.", "published": "2025-03-29 22:55:33", "link": "http://arxiv.org/abs/2503.23244v1", "categories": ["cs.HC", "cs.DC", "cs.IR", "68T09, 68M14, 68P20, 68N01, 68U35", "H.3.5; H.2.8; D.2.8; C.2.4; K.6.5"], "primary_category": "cs.HC"}
{"title": "Reproducibility Companion Paper:In-processing User Constrained Dominant Sets for User-Oriented Fairness in Recommender Systems", "abstract": "In this paper, we reproduce experimental results presented in our earlier\nwork titled \"In-processing User Constrained Dominant Sets for User-Oriented\nFairness in Recommender Systems\" that was presented in the proceeding of the\n31st ACM International Conference on Multimedia.This work aims to verify the\neffectiveness of our previously proposed method and provide guidance for\nreproducibility. We present detailed descriptions of our preprocessed datasets,\nthe structure of our source code, configuration file settings, experimental\nenvironment, and the reproduced experimental results.", "published": "2025-03-29 11:07:33", "link": "http://arxiv.org/abs/2503.23040v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Imagine All The Relevance: Scenario-Profiled Indexing with Knowledge Expansion for Dense Retrieval", "abstract": "Existing dense retrieval models struggle with reasoning-intensive retrieval\ntask as they fail to capture implicit relevance that requires reasoning beyond\nsurface-level semantic information. To address these challenges, we propose\nScenario-Profiled Indexing with Knowledge Expansion (SPIKE), a dense retrieval\nframework that explicitly indexes implicit relevance by decomposing documents\ninto scenario-based retrieval units. SPIKE organizes documents into scenario,\nwhich encapsulates the reasoning process necessary to uncover implicit\nrelationships between hypothetical information needs and document content.\nSPIKE constructs a scenario-augmented dataset using a powerful teacher large\nlanguage model (LLM), then distills these reasoning capabilities into a\nsmaller, efficient scenario generator. During inference, SPIKE incorporates\nscenario-level relevance alongside document-level relevance, enabling\nreasoning-aware retrieval. Extensive experiments demonstrate that SPIKE\nconsistently enhances retrieval performance across various query types and\ndense retrievers. It also enhances the retrieval experience for users through\nscenario and offers valuable contextual information for LLMs in\nretrieval-augmented generation (RAG).", "published": "2025-03-29 10:36:54", "link": "http://arxiv.org/abs/2503.23033v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Federated Semantic Learning for Privacy-preserving Cross-domain Recommendation", "abstract": "In the evolving landscape of recommender systems, the challenge of\neffectively conducting privacy-preserving Cross-Domain Recommendation (CDR),\nespecially under strict non-overlapping constraints, has emerged as a key\nfocus. Despite extensive research has made significant progress, several\nlimitations still exist: 1) Previous semantic-based methods fail to deeply\nexploit rich textual information, since they quantize the text into codes,\nlosing its original rich semantics. 2) The current solution solely relies on\nthe text-modality, while the synergistic effects with the ID-modality are\nignored. 3) Existing studies do not consider the impact of irrelevant semantic\nfeatures, leading to inaccurate semantic representation. To address these\nchallenges, we introduce federated semantic learning and devise FFMSR as our\nsolution. For Limitation 1, we locally learn items'semantic encodings from\ntheir original texts by a multi-layer semantic encoder, and then cluster them\non the server to facilitate the transfer of semantic knowledge between domains.\nTo tackle Limitation 2, we integrate both ID and Text modalities on the\nclients, and utilize them to learn different aspects of items. To handle\nLimitation 3, a Fast Fourier Transform (FFT)-based filter and a gating\nmechanism are developed to alleviate the impact of irrelevant semantic\ninformation in the local model. We conduct extensive experiments on two\nreal-world datasets, and the results demonstrate the superiority of our FFMSR\nmethod over other SOTA methods. Our source codes are publicly available at:\nhttps://github.com/Sapphire-star/FFMSR.", "published": "2025-03-29 09:37:11", "link": "http://arxiv.org/abs/2503.23026v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "DAT: Dynamic Alpha Tuning for Hybrid Retrieval in Retrieval-Augmented Generation", "abstract": "Hybrid retrieval techniques in Retrieval-Augmented Generation (RAG) systems\nenhance information retrieval by combining dense and sparse (e.g., BM25-based)\nretrieval methods. However, existing approaches struggle with adaptability, as\nfixed weighting schemes fail to adjust to different queries. To address this,\nwe propose DAT (Dynamic Alpha Tuning), a novel hybrid retrieval framework that\ndynamically balances dense retrieval and BM25 for each query. DAT leverages a\nlarge language model (LLM) to evaluate the effectiveness of the top-1 results\nfrom both retrieval methods, assigning an effectiveness score to each. It then\ncalibrates the optimal weighting factor through effectiveness score\nnormalization, ensuring a more adaptive and query-aware weighting between the\ntwo approaches. Empirical results show that DAT consistently significantly\noutperforms fixed-weighting hybrid retrieval methods across various evaluation\nmetrics. Even on smaller models, DAT delivers strong performance, highlighting\nits efficiency and adaptability.", "published": "2025-03-29 08:35:01", "link": "http://arxiv.org/abs/2503.23013v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "LAURA: LLM-Assisted UAV Routing for AoI Minimization", "abstract": "With the rapid growth of the low-altitude economy, there is increasing demand\nfor real-time data collection using UAV-assisted wireless sensor networks. This\npaper investigates the problem of minimizing the age of information (AoI) in\nUAV-assisted wireless sensor networks by optimizing the UAV flight routing. We\nformulate the AoI minimization task and propose a large language model\n(LLM)-assisted UAV routing algorithm (LAURA). LAURA employs an LLM as\nintelligent crossover operators within an evolutionary optimization framework\nto efficiently explore the solution space. Simulation results show that LAURA\noutperforms benchmark methods in reducing the maximum AoI, especially in\nscenarios with a large number of sensor nodes.", "published": "2025-03-29 15:52:08", "link": "http://arxiv.org/abs/2503.23132v1", "categories": ["cs.NI", "cs.IT", "math.IT"], "primary_category": "cs.NI"}
{"title": "Channel Coding meets Sequence Design via Machine Learning for Integrated Sensing and Communications", "abstract": "For integrated sensing and communications, an intriguing question is whether\ninformation-bearing channel-coded signals can be reused for sensing -\nspecifically ranging. This question forces the hitherto non-overlapping fields\nof channel coding (communications) and sequence design (sensing) to intersect\nby motivating the design of error-correcting codes that have good\nautocorrelation properties. In this letter, we demonstrate how machine learning\n(ML) is well-suited for designing such codes, especially for short block\nlengths. As an example, for rate 1/2 and block length 32, we show that even an\nunsophisticated ML code has a bit-error rate performance similar to a Polar\ncode with the same parameters, but with autocorrelation sidelobes 24dB lower.\nWhile a length-32 Zadoff-Chu (ZC) sequence has zero autocorrelation sidelobes,\nthere are only 16 such sequences and hence, a 1/2 code rate cannot be realized\nby using ZC sequences as codewords. Hence, ML bridges channel coding and\nsequence design by trading off an ideal autocorrelation function for a large\n(i.e., rate-dependent) codebook size.", "published": "2025-03-29 15:18:44", "link": "http://arxiv.org/abs/2503.23119v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Towards Secure Semantic Communications in the Presence of Intelligent Eavesdroppers", "abstract": "Semantic communication has emerged as a promising paradigm for enhancing\ncommunication efficiency in sixth-generation (6G) networks. However, the\nbroadcast nature of wireless channels makes SemCom systems vulnerable to\neavesdropping, which poses a serious threat to data privacy. Therefore, we\ninvestigate secure SemCom systems that preserve data privacy in the presence of\neavesdroppers. Specifically, we first explore a scenario where eavesdroppers\nare intelligent and can exploit semantic information to reconstruct the\ntransmitted data based on advanced artificial intelligence (AI) techniques. To\ncounter this, we introduce novel eavesdropping attack strategies that utilize\nmodel inversion attacks and generative AI (GenAI) models. These strategies\neffectively reconstruct transmitted private data processed by the semantic\nencoder, operating in both glass-box and closed-box settings. Existing defense\nmechanisms against eavesdropping often cause significant distortions in the\ndata reconstructed by eavesdroppers, potentially arousing their suspicion. To\naddress this, we propose a semantic covert communication approach that\nleverages an invertible neural network (INN)-based signal steganography module.\nThis module covertly embeds the channel input signal of a private sample into\nthat of a non-sensitive host sample, thereby misleading eavesdroppers. Without\naccess to this module, eavesdroppers can only extract host-related information\nand remain unaware of the hidden private content. We conduct extensive\nsimulations under various channel conditions in image transmission tasks.\nNumerical results show that while conventional eavesdropping strategies achieve\na success rate of over 80\\% in reconstructing private information, the proposed\nsemantic covert communication effectively reduces the eavesdropping success\nrate to 0.", "published": "2025-03-29 14:45:16", "link": "http://arxiv.org/abs/2503.23103v1", "categories": ["cs.IT", "eess.IV", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "A Note on Function Correcting Codes for b-Symbol Read Channels", "abstract": "Function-Correcting Codes (FCCs) is a novel paradigm in Error Control Coding\nintroduced by Lenz et. al. 2023 for the binary substitution channel \\cite{FCC}.\nFCCs aim to protect the function evaluation of data against errors instead of\nthe data itself, thereby relaxing the redundancy requirements of the code.\nLater R. Premlal et. al. \\cite{LFCC} gave new bounds on the optimal redundancy\nof FCCs and also extensively studied FCCs for linear functions. The notion of\nFCCs has also been extended to different channels such as symbol-pair read\nchannel over the binary field by Xia et. al. \\cite{FCSPC} and b-symbol read\nchannel over finite fields by A.Singh et. al. \\cite{FCBSC} In this work, we\nstudy FCCs for linear functions for the b-symbol read channel. We provide the\nPlotkin-like bound on FCCs for b-symbol read channel which reduces to a\nPlotkin-like bound for FCCs for the symbol-pair read channel when $b$=2. FCCs\nreduce to classical Error Correcting Codes (ECCs) when the function is\nbijective. Analogous to this our bound reduces to the Plotkin-bound for\nclassical ECCS for both the b-symbol and symbol-pair read channels\n\\cite{Plotkin-b-symbol, Plotkin-symbol-pair} when we consider linear bijective\nfunctions.", "published": "2025-03-29 12:37:28", "link": "http://arxiv.org/abs/2503.23059v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "EncGPT: A Multi-Agent Workflow for Dynamic Encryption Algorithms", "abstract": "Communication encryption is crucial in computer technology, but existing\nalgorithms struggle with balancing cost and security. We propose EncGPT, a\nmulti-agent framework using large language models (LLM). It includes rule,\nencryption, and decryption agents that generate encryption rules and apply them\ndynamically. This approach addresses gaps in LLM-based multi-agent systems for\ncommunication security. We tested GPT-4o's rule generation and implemented a\nsubstitution encryption workflow with homomorphism preservation, achieving an\naverage execution time of 15.99 seconds.", "published": "2025-03-29 16:13:30", "link": "http://arxiv.org/abs/2503.23138v1", "categories": ["cs.CR", "cs.MA"], "primary_category": "cs.CR"}
{"title": "Entropy stable shock capturing for high-order DGSEM on moving meshes", "abstract": "In this paper, a shock capturing for high-order entropy stable discontinuous\nGalerkin spectral element methods on moving meshes is proposed using\nGauss--Lobatto nodes. The shock capturing is achieved via the convex blending\nof the high-order scheme with a low-order finite volume subcell operator. The\nfree-stream and convergence properties of the hybrid scheme are demonstrated\nnumerically along with the entropy stability and shock capturing capabilities.", "published": "2025-03-29 22:23:19", "link": "http://arxiv.org/abs/2503.23237v1", "categories": ["math.NA", "cs.NA", "physics.comp-ph"], "primary_category": "math.NA"}
{"title": "A Novel Transformed Fibered Rank Approximation with Total Variation Regularization for Tensor Completion", "abstract": "Recently, tensor fibered rank has demonstrated impressive performance by\neffectively leveraging the global low-rank property in all directions for\nlow-rank tensor completion (LRTC). However, it still has some limitations.\nFirstly, the typical tensor fibered rank approximation based on tensor nuclear\nnorm (TNN) processes fixed and data-independent transformation, which may not\nbe optimal for the underlying tensor structure. Secondly, it ignores the local\npiecewise smoothness of the dataset. To address these limitations, we present a\nnonconvex learnable transformed fibered nuclear norm (NLTFNN) model for\nLRTC,which uses a learnable transformed fibered nuclear norm with\nLog-Determinant (LTFNNLog) as tensor fibered rank approximation, and employs a\ntotal variation (TV) regularization to explore local piecewise smoothness. An\nefficient algorithm based on the alternating direction method of multipliers\n(ADMM) is developed to solve NLTFNN and the convergence of the algorithm is\nproved theoretically. Experiments on various datasets show the superiority of\nNLTFNN over several existing methods.", "published": "2025-03-29 17:51:24", "link": "http://arxiv.org/abs/2503.23168v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Stable fully discrete finite element methods with BGN tangential motion for Willmore flow of planar curves", "abstract": "We propose and analyze stable finite element approximations for Willmore flow\nof planar curves. The presented schemes are based on a novel weak formulation\nwhich combines an evolution equation for curvature with the curvature\nformulation originally proposed by Barrett, Garcke and N\\\"urnberg (BGN) in\n\\cite{BGN07}. Under discretization in space with piecewise linear elements this\nleads to a stable continuous-in-time semidiscrete scheme, which retains the\nequidistribution property from the BGN methods. Furthermore, two fully discrete\nschemes can be shown to satisfy unconditional energy stability estimates.\nNumerical examples are presented to showcase the good properties of the\nintroduced schemes, including an asymptotic equidistribution of vertices.", "published": "2025-03-29 17:18:34", "link": "http://arxiv.org/abs/2503.23152v1", "categories": ["math.NA", "cs.NA", "65M60, 65M15, 65M12, 35R01"], "primary_category": "math.NA"}
{"title": "Stable EEG Source Estimation for Standardized Kalman Filter using Change Rate Tracking", "abstract": "This article focuses on the measurement and evolution modeling of\nStandardized Kalman filtering in brain activity estimation when non-invasive\nelectroencephalography measurements are used as the data. Here, we propose new\nparameter tuning and model utilizing the change rate of brain activity\ndistribution to improve the stability of the otherwise accurate estimation.\nNamely, we pose a backward differentiation-based measurement model for the\nchange rate that increased the stability of the tracking notably. Simulated\ndata and data from a real subject were used in experiments.", "published": "2025-03-29 11:39:51", "link": "http://arxiv.org/abs/2504.01984v1", "categories": ["stat.AP", "cs.NA", "eess.SP", "math.NA", "15A29, 60J22", "G.3; I.6.5"], "primary_category": "stat.AP"}
{"title": "Data Assimilation Models for Computing Probability Distributions of Complex Multiscale Systems", "abstract": "We introduce a data assimilation strategy aimed at accurately capturing key\nnon-Gaussian structures in probability distributions using a small ensemble\nsize. A major challenge in statistical forecasting of nonlinearly coupled\nmultiscale systems is mitigating the large errors that arise when computing\nhigh-order statistical moments. To address this issue, a high-order\nstochastic-statistical modeling framework is proposed that integrates\nstatistical data assimilation into finite ensemble predictions. The method\neffectively reduces the approximation errors in finite ensemble estimates of\nnon-Gaussian distributions by employing a filtering update step that\nincorporates observation data in leading moments to refine the high-order\nstatistical feedback. Explicit filter operators are derived from intrinsic\nnonlinear coupling structures, allowing straightforward numerical\nimplementations. We demonstrate the performance of the proposed method through\nextensive numerical experiments on a prototype triad system. The triad system\noffers an instructive and computationally manageable platform mimicking\nessential aspects of nonlinear turbulent dynamics. The numerical results show\nthat the statistical data assimilation algorithm consistently captures the mean\nand covariance, as well as various non-Gaussian probability distributions\nexhibited in different statistical regimes of the triad system. The modeling\nframework can serve as a useful tool for efficient sampling and reliable\nforecasting of complex probability distributions commonly encountered in a wide\nvariety of applications involving multiscale coupling and nonlinear dynamics.", "published": "2025-03-29 02:43:23", "link": "http://arxiv.org/abs/2503.22949v1", "categories": ["math.NA", "cs.NA", "nlin.CD", "physics.comp-ph"], "primary_category": "math.NA"}
{"title": "Unsupervised Learning: Comparative Analysis of Clustering Techniques on High-Dimensional Data", "abstract": "This paper presents a comprehensive comparative analysis of prominent\nclustering algorithms K-means, DBSCAN, and Spectral Clustering on\nhigh-dimensional datasets. We introduce a novel evaluation framework that\nassesses clustering performance across multiple dimensionality reduction\ntechniques (PCA, t-SNE, and UMAP) using diverse quantitative metrics.\nExperiments conducted on MNIST, Fashion-MNIST, and UCI HAR datasets reveal that\npreprocessing with UMAP consistently improves clustering quality across all\nalgorithms, with Spectral Clustering demonstrating superior performance on\ncomplex manifold structures. Our findings show that algorithm selection should\nbe guided by data characteristics, with Kmeans excelling in computational\nefficiency, DBSCAN in handling irregular clusters, and Spectral Clustering in\ncapturing complex relationships. This research contributes a systematic\napproach for evaluating and selecting clustering techniques for high\ndimensional data applications.", "published": "2025-03-29 20:38:04", "link": "http://arxiv.org/abs/2503.23215v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Neural Bayes inference for complex bivariate extremal dependence models", "abstract": "Likelihood-free approaches are appealing for performing inference on complex\ndependence models, either because it is not possible to formulate a likelihood\nfunction, or its evaluation is very computationally costly. This is the case\nfor several models available in the multivariate extremes literature,\nparticularly for the most flexible tail models, including those that\ninterpolate between the two key dependence classes of `asymptotic dependence'\nand `asymptotic independence'. We focus on approaches that leverage neural\nnetworks to approximate Bayes estimators. In particular, we explore the\nproperties of neural Bayes estimators for parameter inference for several\nflexible but computationally expensive models to fit, with a view to aiding\ntheir routine implementation. Owing to the absence of likelihood evaluation in\nthe inference procedure, classical information criteria such as the Bayesian\ninformation criterion cannot be used to select the most appropriate model.\nInstead, we propose using neural networks as neural Bayes classifiers for model\nselection. Our goal is to provide a toolbox for simple, fast fitting and\ncomparison of complex extreme-value dependence models, where the best model is\nselected for a given data set and its parameters subsequently estimated using\nneural Bayes estimation. We apply our classifiers and estimators to analyse the\npairwise extremal behaviour of changes in horizontal geomagnetic field\nfluctuations at three different locations.", "published": "2025-03-29 17:24:48", "link": "http://arxiv.org/abs/2503.23156v1", "categories": ["stat.ME", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Estimating Unbounded Density Ratios: Applications in Error Control under Covariate Shift", "abstract": "The density ratio is an important metric for evaluating the relative\nlikelihood of two probability distributions, with extensive applications in\nstatistics and machine learning. However, existing estimation theories for\ndensity ratios often depend on stringent regularity conditions, mainly focusing\non density ratio functions with bounded domains and ranges. In this paper, we\nstudy density ratio estimators using loss functions based on least squares and\nlogistic regression. We establish upper bounds on estimation errors with\nstandard minimax optimal rates, up to logarithmic factors. Our results\naccommodate density ratio functions with unbounded domains and ranges. We apply\nour results to nonparametric regression and conditional flow models under\ncovariate shift and identify the tail properties of the density ratio as\ncrucial for error control across domains affected by covariate shift. We\nprovide sufficient conditions under which loss correction is unnecessary and\ndemonstrate effective generalization capabilities of a source estimator to any\nsuitable target domain. Our simulation experiments support these theoretical\nfindings, indicating that the source estimator can outperform those derived\nfrom loss correction methods, even when the true density ratio is known.", "published": "2025-03-29 11:35:39", "link": "http://arxiv.org/abs/2504.01031v1", "categories": ["stat.ML", "cs.LG", "62G05, 62G08, 68T07"], "primary_category": "stat.ML"}
{"title": "Fair Sufficient Representation Learning", "abstract": "The main objective of fair statistical modeling and machine learning is to\nminimize or eliminate biases that may arise from the data or the model itself,\nensuring that predictions and decisions are not unjustly influenced by\nsensitive attributes such as race, gender, age, or other protected\ncharacteristics. In this paper, we introduce a Fair Sufficient Representation\nLearning (FSRL) method that balances sufficiency and fairness. Sufficiency\nensures that the representation should capture all necessary information about\nthe target variables, while fairness requires that the learned representation\nremains independent of sensitive attributes. FSRL is based on a convex\ncombination of an objective function for learning a sufficient representation\nand an objective function that ensures fairness. Our approach manages fairness\nand sufficiency at the representation level, offering a novel perspective on\nfair representation learning. We implement this method using distance\ncovariance, which is effective for characterizing independence between random\nvariables. We establish the convergence properties of the learned\nrepresentations. Experiments conducted on healthcase and text datasets with\ndiverse structures demonstrate that FSRL achieves a superior trade-off between\nfairness and accuracy compared to existing approaches.", "published": "2025-03-29 10:37:49", "link": "http://arxiv.org/abs/2504.01030v1", "categories": ["stat.ML", "cs.LG", "62G05, 68T07"], "primary_category": "stat.ML"}
{"title": "Nested Stochastic Gradient Descent for (Generalized) Sinkhorn Distance-Regularized Distributionally Robust Optimization", "abstract": "Distributionally robust optimization (DRO) is a powerful technique to train\nrobust models against data distribution shift. This paper aims to solve\nregularized nonconvex DRO problems, where the uncertainty set is modeled by a\nso-called generalized Sinkhorn distance and the loss function is nonconvex and\npossibly unbounded. Such a distance allows to model uncertainty of\ndistributions with different probability supports and divergence functions. For\nthis class of regularized DRO problems, we derive a novel dual formulation\ntaking the form of nested stochastic programming, where the dual variable\ndepends on the data sample. To solve the dual problem, we provide theoretical\nevidence to design a nested stochastic gradient descent (SGD) algorithm, which\nleverages stochastic approximation to estimate the nested stochastic gradients.\nWe study the convergence rate of nested SGD and establish polynomial iteration\nand sample complexities that are independent of the data size and parameter\ndimension, indicating its potential for solving large-scale DRO problems. We\nconduct numerical experiments to demonstrate the efficiency and robustness of\nthe proposed algorithm.", "published": "2025-03-29 01:01:02", "link": "http://arxiv.org/abs/2503.22923v1", "categories": ["math.OC", "cs.LG", "stat.ML"], "primary_category": "math.OC"}
{"title": "SupertonicTTS: Towards Highly Scalable and Efficient Text-to-Speech System", "abstract": "We present a novel text-to-speech (TTS) system, namely SupertonicTTS, for\nimproved scalability and efficiency in speech synthesis. SupertonicTTS is\ncomprised of three components: a speech autoencoder for continuous latent\nrepresentation, a text-to-latent module leveraging flow-matching for\ntext-to-latent mapping, and an utterance-level duration predictor. To enable a\nlightweight architecture, we employ a low-dimensional latent space, temporal\ncompression of latents, and ConvNeXt blocks. We further simplify the TTS\npipeline by operating directly on raw character-level text and employing\ncross-attention for text-speech alignment, thus eliminating the need for\ngrapheme-to-phoneme (G2P) modules and external aligners. In addition, we\nintroduce context-sharing batch expansion that accelerates loss convergence and\nstabilizes text-speech alignment. Experimental results demonstrate that\nSupertonicTTS achieves competitive performance while significantly reducing\narchitectural complexity and computational overhead compared to contemporary\nTTS models. Audio samples demonstrating the capabilities of SupertonicTTS are\navailable at: https://supertonictts.github.io/.", "published": "2025-03-29 14:59:32", "link": "http://arxiv.org/abs/2503.23108v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "The trajectoRIR Database: Room Acoustic Recordings Along a Trajectory of Moving Microphones", "abstract": "Data availability is essential to develop acoustic signal processing\nalgorithms, especially when it comes to data-driven approaches that demand\nlarge and diverse training datasets. For this reason, an increasing number of\ndatabases have been published in recent years, including either room impulse\nresponses (RIRs) or recordings of moving audio. In this paper we introduce the\ntrajectoRIR database, an extensive, multi-array collection of both dynamic and\nstationary acoustic recordings along a controlled trajectory in a room.\nSpecifically, the database features recordings using moving microphones and\nstationary RIRs spatially sampling the room acoustics along an L-shaped,\n3.74-meter-long trajectory. This combination makes trajectoRIR unique and\napplicable in various tasks ranging from sound source localization and tracking\nto spatially dynamic sound field reconstruction and system identification. The\nrecording room has a reverberation time of 0.5 seconds, and the three different\nmicrophone configurations employed include a dummy head, with additional\nreference microphones located next to the ears, 3 first-order Ambisonics\nmicrophones, two circular arrays of 16 and 4 channels, and a 12-channel linear\narray. The motion of the microphones was achieved using a robotic cart\ntraversing a rail at three speeds: [0.2,0.4,0.8] m/s. Audio signals were\nreproduced using two stationary loudspeakers. The collected database features\n8648 stationary RIRs, as well as perfect sweeps, speech, music, and stationary\nnoise recorded during motion. MATLAB and Python scripts are included to access\nthe recorded audio as well as to retrieve geometrical information.", "published": "2025-03-29 07:59:16", "link": "http://arxiv.org/abs/2503.23004v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Multi-Agent Reinforcement Learning for Graph Discovery in D2D-Enabled Federated Learning", "abstract": "Augmenting federated learning (FL) with device-to-device (D2D) communications\ncan help improve convergence speed and reduce model bias through local\ninformation exchange. However, data privacy concerns, trust constraints between\ndevices, and unreliable wireless channels each pose challenges in finding an\neffective yet resource efficient D2D graph structure. In this paper, we develop\na decentralized reinforcement learning (RL) method for D2D graph discovery that\npromotes communication of impactful datapoints over reliable links for multiple\nlearning paradigms, while following both data and device-specific trust\nconstraints. An independent RL agent at each device trains a policy to predict\nthe impact of incoming links in a decentralized manner without exposure of\nlocal data or significant communication overhead. For supervised settings, the\nD2D graph aims to improve device-specific label diversity without compromising\nsystem-level performance. For semi-supervised settings, we enable this by\nincorporating distributed label propagation. For unsupervised settings, we\ndevelop a variation-based diversity metric which estimates data diversity in\nterms of occupied latent space. Numerical experiments on five widely used\ndatasets confirm that the data diversity improvements induced by our method\nincrease convergence speed by up to 3 times while reducing energy consumption\nby up to 5 times. They also show that our method is resilient to stragglers and\nchanges in the aggregation interval. Finally, we show that our method offers\nscalability benefits for larger system sizes without increases in relative\noverhead, and adaptability to various downstream FL architectures and to\ndynamic wireless environments.", "published": "2025-03-29 20:42:26", "link": "http://arxiv.org/abs/2503.23218v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Least-Squares Khatri-Rao Factorization of a Polynomial Matrix", "abstract": "The Khatri-Rao product is extensively used in array processing, tensor\ndecomposition, and multi-way data analysis. Many applications require a\nleast-squares (LS) Khatri-Rao factorization. In broadband sensor array\nproblems, polynomial matrices effectively model frequency-dependent behaviors,\nnecessitating extensions of conventional linear algebra techniques. This paper\ngeneralizes LS Khatri-Rao factorization from ordinary to polynomial matrices by\napplying it to the discrete Fourier transform (DFT) samples of polynomial\nmatrices. Phase coherence across bin-wise Khatri-Rao factors is ensured via a\nphasesmoothing algorithm. The proposed method is validated through broadband\nangle-of-arrival (AoA) estimation for uniform planar arrays (UPAs), where the\nsteering matrix is a polynomial matrix, which can be represented as a\nKhatri-Rao product between steering matrix in azimuth and elevation directions.", "published": "2025-03-29 19:01:49", "link": "http://arxiv.org/abs/2503.23187v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Advancing THz Radio Map Construction and Obstacle Sensing: An Integrated Generative Framework in ISAC", "abstract": "Integrated sensing and communication (ISAC) in the terahertz (THz) band\nenables obstacle detection, which in turn facilitates efficient beam management\nto mitigate THz signal blockage. Simultaneously, a THz radio map, which\ncaptures signal propagation characteristics through the distribution of\nreceived signal strength (RSS), is well-suited for sensing, as it inherently\ncontains obstacle-related information and reflects the unique properties of the\nTHz channel. This means that communication-assisted sensing in ISAC can be\neffectively achieved using a THz radio map. However, constructing a radio map\npresents significant challenges due to the sparse deployment of THz sensors and\ntheir limited ability to accurately measure the RSS distribution, which\ndirectly affects obstacle sensing. In this paper, we formulate an integrated\nproblem for the first time, leveraging the mutual enhancement between sensed\nobstacles and the constructed THz radio maps. To address this challenge while\nimproving generalization, we propose an integration framework based on a\nconditional generative adversarial network (CGAN), which uncovers the manifold\nstructure of THz radio maps embedded with obstacle information. Furthermore,\nrecognizing the shared environmental semantics across THz radio maps from\ndifferent beam directions, we introduce a novel voting-based sensing scheme,\nwhere obstacles are detected by aggregating votes from THz radio maps generated\nby the CGAN. Simulation results demonstrate that the proposed framework\noutperforms non-integrated baselines in both radio map construction and\nobstacle sensing, achieving up to 44.3% and 90.6% reductions in mean squared\nerror (MSE), respectively, in a real-world scenario. These results validate the\neffectiveness of the proposed voting-based scheme.", "published": "2025-03-29 12:24:50", "link": "http://arxiv.org/abs/2503.23055v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Comprehensive Comparison between Terahertz and Optical Wireless Communications", "abstract": "This paper presents a comprehensive quantitative comparison between Terahertz\n(THz) communication (TeraCom) and optical wireless communication (OWC)\ntechnologies, focusing on both indoor and outdoor environments. We propose a\ncomparison method for TeraCom and vertical-cavity surface-emitting laser\n(VCSEL)-based OWC in indoor scenarios, incorporating misalignment effects by\nmodeling the THz antenna radiation pattern within a multi-ray THz channel model\nand using a Gaussian beam model for VCSEL-based OWC. Unified beamwidth\nparameters allow for a detailed analysis of misalignment impact on both\nsystems. Furthermore, we develop power consumption models for each technology,\nintegrating key parameters such as THz phase noise, VCSEL non-linearities, and\nphotodetector bandwidth-area tradeoffs. These models enable an in-depth\nanalysis of energy efficiency in indoor environments, including\nmulti-transmitter coverage scenarios. For outdoor scenarios, we summarize\nexisting stochastic channel models addressing path loss, pointing errors, and\nsmall-scale fading for free space optics (FSO) and THz links. We then apply\nthese models to unmanned aerial vehicle (UAV) applications to assess\nperformance in dynamic conditions. Our results provide critical insights into\nthe suitability of each technology for various deployment scenarios.", "published": "2025-03-29 08:21:57", "link": "http://arxiv.org/abs/2503.23010v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
