{"title": "Enriching Large-Scale Eventuality Knowledge Graph with Entailment\n  Relations", "abstract": "Computational and cognitive studies suggest that the abstraction of\neventualities (activities, states, and events) is crucial for humans to\nunderstand daily eventualities. In this paper, we propose a scalable approach\nto model the entailment relations between eventualities (\"eat an apple''\nentails ''eat fruit''). As a result, we construct a large-scale eventuality\nentailment graph (EEG), which has 10 million eventuality nodes and 103 million\nentailment edges. Detailed experiments and analysis demonstrate the\neffectiveness of the proposed approach and quality of the resulting knowledge\ngraph. Our datasets and code are available at\nhttps://github.com/HKUST-KnowComp/ASER-EEG.", "published": "2020-06-21 15:22:03", "link": "http://arxiv.org/abs/2006.11824v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AdvAug: Robust Adversarial Augmentation for Neural Machine Translation", "abstract": "In this paper, we propose a new adversarial augmentation method for Neural\nMachine Translation (NMT). The main idea is to minimize the vicinal risk over\nvirtual sentences sampled from two vicinity distributions, of which the crucial\none is a novel vicinity distribution for adversarial sentences that describes a\nsmooth interpolated embedding space centered around observed training sentence\npairs. We then discuss our approach, AdvAug, to train NMT models using the\nembeddings of virtual sentences in sequence-to-sequence learning. Experiments\non Chinese-English, English-French, and English-German translation benchmarks\nshow that AdvAug achieves significant improvements over the Transformer (up to\n4.9 BLEU points), and substantially outperforms other data augmentation\ntechniques (e.g. back-translation) without using extra corpora.", "published": "2020-06-21 15:51:54", "link": "http://arxiv.org/abs/2006.11834v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Labeling Explicit Discourse Relations using Pre-trained Language Models", "abstract": "Labeling explicit discourse relations is one of the most challenging\nsub-tasks of the shallow discourse parsing where the goal is to identify the\ndiscourse connectives and the boundaries of their arguments. The\nstate-of-the-art models achieve slightly above 45% of F-score by using\nhand-crafted features. The current paper investigates the efficacy of the\npre-trained language models in this task. We find that the pre-trained language\nmodels, when finetuned, are powerful enough to replace the linguistic features.\nWe evaluate our model on PDTB 2.0 and report the state-of-the-art results in\nthe extraction of the full relation. This is the first time when a model\noutperforms the knowledge intensive models without employing any linguistic\nfeatures.", "published": "2020-06-21 17:18:01", "link": "http://arxiv.org/abs/2006.11852v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Match$^2$: A Matching over Matching Model for Similar Question\n  Identification", "abstract": "Community Question Answering (CQA) has become a primary means for people to\nacquire knowledge, where people are free to ask questions or submit answers. To\nenhance the efficiency of the service, similar question identification becomes\na core task in CQA which aims to find a similar question from the archived\nrepository whenever a new question is asked. However, it has long been a\nchallenge to properly measure the similarity between two questions due to the\ninherent variation of natural language, i.e., there could be different ways to\nask a same question or different questions sharing similar expressions. To\nalleviate this problem, it is natural to involve the existing answers for the\nenrichment of the archived questions. Traditional methods typically take a\none-side usage, which leverages the answer as some expanded representation of\nthe corresponding question. Unfortunately, this may introduce unexpected noises\ninto the similarity computation since answers are often long and diverse,\nleading to inferior performance. In this work, we propose a two-side usage,\nwhich leverages the answer as a bridge of the two questions. The key idea is\nbased on our observation that similar questions could be addressed by similar\nparts of the answer while different questions may not. In other words, we can\ncompare the matching patterns of the two questions over the same answer to\nmeasure their similarity. In this way, we propose a novel matching over\nmatching model, namely Match$^2$, which compares the matching patterns between\ntwo question-answer pairs for similar question identification. Empirical\nexperiments on two benchmark datasets demonstrate that our model can\nsignificantly outperform previous state-of-the-art methods on the similar\nquestion identification task.", "published": "2020-06-21 05:59:34", "link": "http://arxiv.org/abs/2006.11719v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Improving Image Captioning with Better Use of Captions", "abstract": "Image captioning is a multimodal problem that has drawn extensive attention\nin both the natural language processing and computer vision community. In this\npaper, we present a novel image captioning architecture to better explore\nsemantics available in captions and leverage that to enhance both image\nrepresentation and caption generation. Our models first construct\ncaption-guided visual relationship graphs that introduce beneficial inductive\nbias using weakly supervised multi-instance learning. The representation is\nthen enhanced with neighbouring and contextual nodes with their textual and\nvisual features. During generation, the model further incorporates visual\nrelationships using multi-task learning for jointly predicting word and\nobject/predicate tag sequences. We perform extensive experiments on the MSCOCO\ndataset, showing that the proposed framework significantly outperforms the\nbaselines, resulting in the state-of-the-art performance under a wide range of\nevaluation metrics.", "published": "2020-06-21 14:10:47", "link": "http://arxiv.org/abs/2006.11807v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "The NYU-CUBoulder Systems for SIGMORPHON 2020 Task 0 and Task 2", "abstract": "We describe the NYU-CUBoulder systems for the SIGMORPHON 2020 Task 0 on\ntypologically diverse morphological inflection and Task 2 on unsupervised\nmorphological paradigm completion. The former consists of generating\nmorphological inflections from a lemma and a set of morphosyntactic features\ndescribing the target form. The latter requires generating entire paradigms for\na set of given lemmas from raw text alone. We model morphological inflection as\na sequence-to-sequence problem, where the input is the sequence of the lemma's\ncharacters with morphological tags, and the output is the sequence of the\ninflected form's characters. First, we apply a transformer model to the task.\nSecond, as inflected forms share most characters with the lemma, we further\npropose a pointer-generator transformer model to allow easy copying of input\ncharacters. Our best performing system for Task 0 is placed 6th out of 23\nsystems. We further use our inflection systems as subcomponents of approaches\nfor Task 2. Our best performing system for Task 2 is the 2nd best out of 7\nsubmissions.", "published": "2020-06-21 15:41:58", "link": "http://arxiv.org/abs/2006.11830v1", "categories": ["cs.CL", "cs.LG", "I.2.7; I.2.6"], "primary_category": "cs.CL"}
{"title": "A Survey on Machine Reading Comprehension: Tasks, Evaluation Metrics and\n  Benchmark Datasets", "abstract": "Machine Reading Comprehension (MRC) is a challenging Natural Language\nProcessing(NLP) research field with wide real-world applications. The great\nprogress of this field in recent years is mainly due to the emergence of\nlarge-scale datasets and deep learning. At present, a lot of MRC models have\nalready surpassed human performance on various benchmark datasets despite the\nobvious giant gap between existing MRC models and genuine human-level reading\ncomprehension. This shows the need for improving existing datasets, evaluation\nmetrics, and models to move current MRC models toward \"real\" understanding. To\naddress the current lack of comprehensive survey of existing MRC tasks,\nevaluation metrics, and datasets, herein, (1) we analyze 57 MRC tasks and\ndatasets and propose a more precise classification method of MRC tasks with 4\ndifferent attributes; (2) we summarized 9 evaluation metrics of MRC tasks, 7\nattributes and 10 characteristics of MRC datasets; (3) We also discuss key open\nissues in MRC research and highlighted future research directions. In addition,\nwe have collected, organized, and published our data on the companion\nwebsite(https://mrc-datasets.github.io/) where MRC researchers could directly\naccess each MRC dataset, papers, baseline projects, and the leaderboard.", "published": "2020-06-21 19:18:54", "link": "http://arxiv.org/abs/2006.11880v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Human Emotion Detection from Audio and Video Signals", "abstract": "The primary objective is to teach a machine about human emotions, which has\nbecome an essential requirement in the field of social intelligence, also\nexpedites the progress of human-machine interactions. The ability of a machine\nto understand human emotion and act accordingly has been a choice of great\ninterest in today's world. The future generations of computers thus must be\nable to interact with a human being just like another. For example, people who\nhave Autism often find it difficult to talk to someone about their state of\nmind. This model explicitly targets the userbase who are troubled and fail to\nexpress it. Also, this model's speech processing techniques provide an estimate\nof the emotion in the case of poor video quality and vice-versa.", "published": "2020-06-21 18:36:23", "link": "http://arxiv.org/abs/2006.11871v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Quantum Computer: Hello, Music!", "abstract": "Quantum computing is emerging as a promising technology, which is built on\nthe principles of subatomic physics. By the time of writing, fully fledged\npractical quantum computers are not widely available. But research and\ndevelopment are advancing rapidly. Various software simulators are already\navailable. And a few companies have already started to provide access to\nquantum hardware via the cloud. These initiatives have enabled experiments with\nquantum computing to tackle some realistic problems in science; e.g., in\nchemistry and cryptography. In spite of continuing progress in developing\nincreasingly more sophisticated hardware and software, research in quantum\ncomputing has been focusing primarily on developing scientific applications. Up\ntill now there has been virtually no research activity aimed at widening the\nrange of applications of this technology beyond science and engineering. In\nparticular applications for the entertainment industry and creative economies.\nThis article introduces a new field of research, which is referred to as\nQuantum Computer Music. This research is aimed at the development of quantum\ncomputing tools and approaches to creating, performing, listening to and\ndistributing music. The article begins with a brief historical background.\nThen, it introduces the notion of algorithmic music and presents two quantum\ncomputer music systems: a singing voice synthesiser and a musical sequencer\nbased on quantum walk. A primer on quantum computing is also given. The chapter\nends with a concluding discussion and advice for further work to develop this\nnew exciting area of research.", "published": "2020-06-21 22:42:20", "link": "http://arxiv.org/abs/2006.13849v1", "categories": ["cs.ET", "cs.SD", "eess.AS", "quant-ph"], "primary_category": "cs.ET"}
