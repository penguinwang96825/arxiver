{"title": "Ensembling of Distilled Models from Multi-task Teachers for Constrained\n  Resource Language Pairs", "abstract": "This paper describes our submission to the constrained track of WMT21 shared\nnews translation task. We focus on the three relatively low resource language\npairs Bengali to and from Hindi, English to and from Hausa, and Xhosa to and\nfrom Zulu. To overcome the limitation of relatively low parallel data we train\na multilingual model using a multitask objective employing both parallel and\nmonolingual data. In addition, we augment the data using back translation. We\nalso train a bilingual model incorporating back translation and knowledge\ndistillation then combine the two models using sequence-to-sequence mapping. We\nsee around 70% relative gain in BLEU point for English to and from Hausa, and\naround 25% relative improvements for both Bengali to and from Hindi, and Xhosa\nto and from Zulu compared to bilingual baselines.", "published": "2021-11-26 00:54:37", "link": "http://arxiv.org/abs/2111.13284v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Simple Contrastive Representation Adversarial Learning for NLP Tasks", "abstract": "Self-supervised learning approach like contrastive learning is attached great\nattention in natural language processing. It uses pairs of training data\naugmentations to build a classification task for an encoder with well\nrepresentation ability. However, the construction of learning pairs over\ncontrastive learning is much harder in NLP tasks. Previous works generate\nword-level changes to form pairs, but small transforms may cause notable\nchanges on the meaning of sentences as the discrete and sparse nature of\nnatural language. In this paper, adversarial training is performed to generate\nchallenging and harder learning adversarial examples over the embedding space\nof NLP as learning pairs. Using contrastive learning improves the\ngeneralization ability of adversarial training because contrastive loss can\nuniform the sample distribution. And at the same time, adversarial training\nalso enhances the robustness of contrastive learning. Two novel frameworks,\nsupervised contrastive adversarial learning (SCAL) and unsupervised SCAL\n(USCAL), are proposed, which yields learning pairs by utilizing the adversarial\ntraining for contrastive learning. The label-based loss of supervised tasks is\nexploited to generate adversarial examples while unsupervised tasks bring\ncontrastive loss. To validate the effectiveness of the proposed framework, we\nemploy it to Transformer-based models for natural language understanding,\nsentence semantic textual similarity and adversarial learning tasks.\nExperimental results on GLUE benchmark tasks show that our fine-tuned\nsupervised method outperforms BERT$_{base}$ over 1.75\\%. We also evaluate our\nunsupervised method on semantic textual similarity (STS) tasks, and our method\ngets 77.29\\% with BERT$_{base}$. The robustness of our approach conducts\nstate-of-the-art results under multiple adversarial datasets on NLI tasks.", "published": "2021-11-26 03:16:09", "link": "http://arxiv.org/abs/2111.13301v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "True Few-Shot Learning with Prompts -- A Real-World Perspective", "abstract": "Prompt-based approaches are strong at few-shot learning. However, Perez et\nal. (2021) have recently cast doubt on their performance because they had\ndifficulty getting good results in a \"true\" few-shot setting in which prompts\nand hyperparameters cannot be tuned on a dev set. In view of this, we conduct\nan extensive study of PET, a method that combines textual instructions with\nexample-based finetuning. We show that, if correctly configured, PET performs\nstrongly in a true few-shot setting, i.e., without a dev set. Crucial for this\nstrong performance is PET's ability to intelligently handle multiple prompts.\nWe then put our findings to a real-world test by running PET on RAFT, a\nbenchmark of tasks taken directly from realistic NLP applications for which no\nlabeled dev or test sets are available. PET achieves a new state of the art on\nRAFT and performs close to non-expert humans for 7 out of 11 tasks. These\nresults demonstrate that prompt-based learners like PET excel at true few-shot\nlearning and underpin our belief that learning from instructions will play an\nimportant role on the path towards human-like few-shot learning capabilities.", "published": "2021-11-26 11:49:07", "link": "http://arxiv.org/abs/2111.13440v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KazNERD: Kazakh Named Entity Recognition Dataset", "abstract": "We present the development of a dataset for Kazakh named entity recognition.\nThe dataset was built as there is a clear need for publicly available annotated\ncorpora in Kazakh, as well as annotation guidelines containing\nstraightforward--but rigorous--rules and examples. The dataset annotation,\nbased on the IOB2 scheme, was carried out on television news text by two native\nKazakh speakers under the supervision of the first author. The resulting\ndataset contains 112,702 sentences and 136,333 annotations for 25 entity\nclasses. State-of-the-art machine learning models to automatise Kazakh named\nentity recognition were also built, with the best-performing model achieving an\nexact match F1-score of 97.22% on the test set. The annotated dataset,\nguidelines, and codes used to train the models are freely available for\ndownload under the CC BY 4.0 licence from https://github.com/IS2AI/KazNERD.", "published": "2021-11-26 10:56:19", "link": "http://arxiv.org/abs/2111.13419v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Predicting Document Coverage for Relation Extraction", "abstract": "This paper presents a new task of predicting the coverage of a text document\nfor relation extraction (RE): does the document contain many relational tuples\nfor a given entity? Coverage predictions are useful in selecting the best\ndocuments for knowledge base construction with large input corpora. To study\nthis problem, we present a dataset of 31,366 diverse documents for 520\nentities. We analyze the correlation of document coverage with features like\nlength, entity mention frequency, Alexa rank, language complexity and\ninformation retrieval scores. Each of these features has only moderate\npredictive power. We employ methods combining features with statistical models\nlike TF-IDF and language models like BERT. The model combining features and\nBERT, HERB, achieves an F1 score of up to 46%. We demonstrate the utility of\ncoverage predictions on two use cases: KB construction and claim refutation.", "published": "2021-11-26 17:18:18", "link": "http://arxiv.org/abs/2111.13611v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "BCH-NLP at BioCreative VII Track 3: medications detection in tweets\n  using transformer networks and multi-task learning", "abstract": "In this paper, we present our work participating in the BioCreative VII Track\n3 - automatic extraction of medication names in tweets, where we implemented a\nmulti-task learning model that is jointly trained on text classification and\nsequence labelling. Our best system run achieved a strict F1 of 80.4, ranking\nfirst and more than 10 points higher than the average score of all\nparticipants. Our analyses show that the ensemble technique, multi-task\nlearning, and data augmentation are all beneficial for medication detection in\ntweets.", "published": "2021-11-26 19:22:51", "link": "http://arxiv.org/abs/2111.13726v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Active Learning for Event Extraction with Memory-based Loss Prediction\n  Model", "abstract": "Event extraction (EE) plays an important role in many industrial application\nscenarios, and high-quality EE methods require a large amount of manual\nannotation data to train supervised learning models. However, the cost of\nobtaining annotation data is very high, especially for annotation of domain\nevents, which requires the participation of experts from corresponding domain.\nSo we introduce active learning (AL) technology to reduce the cost of event\nannotation. But the existing AL methods have two main problems, which make them\nnot well used for event extraction. Firstly, the existing pool-based selection\nstrategies have limitations in terms of computational cost and sample validity.\nSecondly, the existing evaluation of sample importance lacks the use of local\nsample information. In this paper, we present a novel deep AL method for EE. We\npropose a batch-based selection strategy and a Memory-Based Loss Prediction\nmodel (MBLP) to select unlabeled samples efficiently. During the selection\nprocess, we use an internal-external sample loss ranking method to evaluate the\nsample importance by using local information. Finally, we propose a delayed\ntraining strategy to train the MBLP model. Extensive experiments are performed\non three domain datasets, and our method outperforms other state-of-the-art\nmethods.", "published": "2021-11-26 07:58:11", "link": "http://arxiv.org/abs/2112.03073v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Generating Usage-related Questions for Preference Elicitation in\n  Conversational Recommender Systems", "abstract": "A key distinguishing feature of conversational recommender systems over\ntraditional recommender systems is their ability to elicit user preferences\nusing natural language. Currently, the predominant approach to preference\nelicitation is to ask questions directly about items or item attributes. Users\nsearching for recommendations may not have deep knowledge of the available\noptions in a given domain. As such, they might not be aware of key attributes\nor desirable values for them. However, in many settings, talking about the\nplanned use of items does not present any difficulties, even for those that are\nnew to a domain. In this paper, we propose a novel approach to preference\nelicitation by asking implicit questions based on item usage. As one of the\nmain contributions of this work, we develop a multi-stage data annotation\nprotocol using crowdsourcing, to create a high-quality labeled training\ndataset. Another main contribution is the development of four models for the\nquestion generation task: two template-based baseline models and two neural\ntext-to-text models. The template-based models use heuristically extracted\ncommon patterns found in the training data, while the neural models use the\ntraining data to learn to generate questions automatically. Using common\nmetrics from machine translation for automatic evaluation, we show that our\napproaches are effective in generating elicitation questions, even with limited\ntraining data. We further employ human evaluation for comparing the generated\nquestions using both pointwise and pairwise evaluation designs. We find that\nthe human evaluation results are consistent with the automatic ones, allowing\nus to draw conclusions about the quality of the generated questions with\ncertainty. Finally, we provide a detailed analysis of cases where the models\nshow their limitations.", "published": "2021-11-26 12:23:14", "link": "http://arxiv.org/abs/2111.13463v2", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Do Language Models Have Beliefs? Methods for Detecting, Updating, and\n  Visualizing Model Beliefs", "abstract": "Do language models have beliefs about the world? Dennett (1995) famously\nargues that even thermostats have beliefs, on the view that a belief is simply\nan informational state decoupled from any motivational state. In this paper, we\ndiscuss approaches to detecting when models have beliefs about the world, and\nwe improve on methods for updating model beliefs to be more truthful, with a\nfocus on methods based on learned optimizers or hypernetworks. Our main\ncontributions include: (1) new metrics for evaluating belief-updating methods\nthat focus on the logical consistency of beliefs, (2) a training objective for\nSequential, Local, and Generalizing model updates (SLAG) that improves the\nperformance of learned optimizers, and (3) the introduction of the belief\ngraph, which is a new form of interface with language models that shows the\ninterdependencies between model beliefs. Our experiments suggest that models\npossess belief-like qualities to only a limited extent, but update methods can\nboth fix incorrect model beliefs and greatly improve their consistency.\nAlthough off-the-shelf optimizers are surprisingly strong belief-updating\nbaselines, our learned optimizers can outperform them in more difficult\nsettings than have been considered in past work. Code is available at\nhttps://github.com/peterbhase/SLAG-Belief-Updating", "published": "2021-11-26 18:33:59", "link": "http://arxiv.org/abs/2111.13654v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Semi-Supervised Music Tagging Transformer", "abstract": "We present Music Tagging Transformer that is trained with a semi-supervised\napproach. The proposed model captures local acoustic characteristics in shallow\nconvolutional layers, then temporally summarizes the sequence of the extracted\nfeatures using stacked self-attention layers. Through a careful model\nassessment, we first show that the proposed architecture outperforms the\nprevious state-of-the-art music tagging models that are based on convolutional\nneural networks under a supervised scheme.\n  The Music Tagging Transformer is further improved by noisy student training,\na semi-supervised approach that leverages both labeled and unlabeled data\ncombined with data augmentation. To our best knowledge, this is the first\nattempt to utilize the entire audio of the million song dataset.", "published": "2021-11-26 12:17:43", "link": "http://arxiv.org/abs/2111.13457v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Learning source-aware representations of music in a discrete latent\n  space", "abstract": "In recent years, neural network based methods have been proposed as a method\nthat cangenerate representations from music, but they are not human readable\nand hardly analyzable oreditable by a human. To address this issue, we propose\na novel method to learn source-awarelatent representations of music through\nVector-Quantized Variational Auto-Encoder(VQ-VAE).We train our VQ-VAE to encode\nan input mixture into a tensor of integers in a discrete latentspace, and\ndesign them to have a decomposed structure which allows humans to manipulatethe\nlatent vector in a source-aware manner. This paper also shows that we can\ngenerate basslines by estimating latent vectors in a discrete space.", "published": "2021-11-26 05:57:24", "link": "http://arxiv.org/abs/2111.13321v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "When Creators Meet the Metaverse: A Survey on Computational Arts", "abstract": "The metaverse, enormous virtual-physical cyberspace, has brought\nunprecedented opportunities for artists to blend every corner of our physical\nsurroundings with digital creativity. This article conducts a comprehensive\nsurvey on computational arts, in which seven critical topics are relevant to\nthe metaverse, describing novel artworks in blended virtual-physical realities.\nThe topics first cover the building elements for the metaverse, e.g., virtual\nscenes and characters, auditory, textual elements. Next, several remarkable\ntypes of novel creations in the expanded horizons of metaverse cyberspace have\nbeen reflected, such as immersive arts, robotic arts, and other user-centric\napproaches fuelling contemporary creative outputs. Finally, we propose several\nresearch agendas: democratising computational arts, digital privacy, and safety\nfor metaverse artists, ownership recognition for digital artworks,\ntechnological challenges, and so on. The survey also serves as introductory\nmaterial for artists and metaverse technologists to begin creations in the\nrealm of surrealistic cyberspace.", "published": "2021-11-26 13:24:37", "link": "http://arxiv.org/abs/2111.13486v1", "categories": ["cs.CY", "cs.AI", "cs.LG", "cs.MM", "cs.SD", "eess.AS", "A.1; K.0"], "primary_category": "cs.CY"}
