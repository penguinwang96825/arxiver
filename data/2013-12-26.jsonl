{"title": "Language Modeling with Power Low Rank Ensembles", "abstract": "We present power low rank ensembles (PLRE), a flexible framework for n-gram\nlanguage modeling where ensembles of low rank matrices and tensors are used to\nobtain smoothed probability estimates of words in context. Our method can be\nunderstood as a generalization of n-gram modeling to non-integer n, and\nincludes standard techniques such as absolute discounting and Kneser-Ney\nsmoothing as special cases. PLRE training is efficient and our approach\noutperforms state-of-the-art modified Kneser Ney baselines in terms of\nperplexity on large corpora as well as on BLEU score in a downstream machine\ntranslation task.", "published": "2013-12-26 09:45:02", "link": "http://arxiv.org/abs/1312.7077v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
