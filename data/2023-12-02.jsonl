{"title": "Dual-Teacher De-biasing Distillation Framework for Multi-domain Fake\n  News Detection", "abstract": "Multi-domain fake news detection aims to identify whether various news from\ndifferent domains is real or fake and has become urgent and important. However,\nexisting methods are dedicated to improving the overall performance of fake\nnews detection, ignoring the fact that unbalanced data leads to disparate\ntreatment for different domains, i.e., the domain bias problem. To solve this\nproblem, we propose the Dual-Teacher De-biasing Distillation framework (DTDBD)\nto mitigate bias across different domains. Following the knowledge distillation\nmethods, DTDBD adopts a teacher-student structure, where pre-trained large\nteachers instruct a student model. In particular, the DTDBD consists of an\nunbiased teacher and a clean teacher that jointly guide the student model in\nmitigating domain bias and maintaining performance. For the unbiased teacher,\nwe introduce an adversarial de-biasing distillation loss to instruct the\nstudent model in learning unbiased domain knowledge. For the clean teacher, we\ndesign domain knowledge distillation loss, which effectively incentivizes the\nstudent model to focus on representing domain features while maintaining\nperformance. Moreover, we present a momentum-based dynamic adjustment algorithm\nto trade off the effects of two teachers. Extensive experiments on Chinese and\nEnglish datasets show that the proposed method substantially outperforms the\nstate-of-the-art baseline methods in terms of bias metrics while guaranteeing\ncompetitive performance.", "published": "2023-12-02 02:53:45", "link": "http://arxiv.org/abs/2312.01006v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Beginner to Expert: Modeling Medical Knowledge into General LLMs", "abstract": "Recently, large language model (LLM) based artificial intelligence (AI)\nsystems have demonstrated remarkable capabilities in natural language\nunderstanding and generation. However, these models face a significant\nchallenge when it comes to sensitive applications, such as reasoning over\nmedical knowledge and answering medical questions in a physician-like manner.\nPrior studies attempted to overcome this challenge by increasing the model size\n(>100B) to learn more general medical knowledge, while there is still room for\nimprovement in LLMs with smaller-scale model sizes (<100B). In this work, we\nstart from a pre-trained general LLM model (AntGLM-10B) and fine-tune it from a\nmedical beginner towards a medical expert (called AntGLM-Med-10B), which\nleverages a 3-stage optimization procedure, i.e., general medical knowledge\ninjection, medical domain instruction tuning, and specific medical task\nadaptation. Our contributions are threefold: (1) We specifically investigate\nhow to adapt a pre-trained general LLM in medical domain, especially for a\nspecific medical task. (2) We collect and construct large-scale medical\ndatasets for each stage of the optimization process. These datasets encompass\nvarious data types and tasks, such as question-answering, medical reasoning,\nmulti-choice questions, and medical conversations. (3) Specifically for\nmulti-choice questions in the medical domain, we propose a novel\nVerification-of-Choice approach for prompting engineering, which significantly\nenhances the reasoning ability of LLMs. Remarkably, by combining the above\napproaches, our AntGLM-Med-10B model can outperform the most of LLMs on\nPubMedQA, including both general and medical LLMs, even when these LLMs have\nlarger model size.", "published": "2023-12-02 05:54:06", "link": "http://arxiv.org/abs/2312.01040v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Models Are Zero-Shot Text Classifiers", "abstract": "Retrained large language models (LLMs) have become extensively used across\nvarious sub-disciplines of natural language processing (NLP). In NLP, text\nclassification problems have garnered considerable focus, but still faced with\nsome limitations related to expensive computational cost, time consumption, and\nrobust performance to unseen classes. With the proposal of chain of thought\nprompting (CoT), LLMs can be implemented using zero-shot learning (ZSL) with\nthe step by step reasoning prompts, instead of conventional question and answer\nformats. The zero-shot LLMs in the text classification problems can alleviate\nthese limitations by directly utilizing pretrained models to predict both seen\nand unseen classes. Our research primarily validates the capability of GPT\nmodels in text classification. We focus on effectively utilizing prompt\nstrategies to various text classification scenarios. Besides, we compare the\nperformance of zero shot LLMs with other state of the art text classification\nmethods, including traditional machine learning methods, deep learning methods,\nand ZSL methods. Experimental results demonstrate that the performance of LLMs\nunderscores their effectiveness as zero-shot text classifiers in three of the\nfour datasets analyzed. The proficiency is especially advantageous for small\nbusinesses or teams that may not have extensive knowledge in text\nclassification.", "published": "2023-12-02 06:33:23", "link": "http://arxiv.org/abs/2312.01044v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detection and Analysis of Stress-Related Posts in Reddit Acamedic\n  Communities", "abstract": "Nowadays, the significance of monitoring stress levels and recognizing early\nsigns of mental illness cannot be overstated. Automatic stress detection in\ntext can proactively help manage stress and protect mental well-being. In\ntoday's digital era, social media platforms reflect the psychological\nwell-being and stress levels within various communities. This study focuses on\ndetecting and analyzing stress-related posts in Reddit academic communities.\nDue to online education and remote work, these communities have become central\nfor academic discussions and support. We classify text as stressed or not using\nnatural language processing and machine learning classifiers, with Dreaddit as\nour training dataset, which contains labeled data from Reddit. Next, we collect\nand analyze posts from various academic subreddits. We identified that the most\neffective individual feature for stress detection is the Bag of Words, paired\nwith the Logistic Regression classifier, achieving a 77.78% accuracy rate and\nan F1 score of 0.79 on the DReaddit dataset. This combination also performs\nbest in stress detection on human-annotated datasets, with a 72% accuracy rate.\nOur key findings reveal that posts and comments in professors Reddit\ncommunities are the most stressful, compared to other academic levels,\nincluding bachelor, graduate, and Ph.D. students. This research contributes to\nour understanding of the stress levels within academic communities. It can help\nacademic institutions and online communities develop measures and interventions\nto address this issue effectively.", "published": "2023-12-02 07:34:03", "link": "http://arxiv.org/abs/2312.01050v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards leveraging LLMs for Conditional QA", "abstract": "This study delves into the capabilities and limitations of Large Language\nModels (LLMs) in the challenging domain of conditional question-answering.\nUtilizing the Conditional Question Answering (CQA) dataset and focusing on\ngenerative models like T5 and UL2, we assess the performance of LLMs across\ndiverse question types. Our findings reveal that fine-tuned LLMs can surpass\nthe state-of-the-art (SOTA) performance in some cases, even without fully\nencoding all input context, with an increase of 7-8 points in Exact Match (EM)\nand F1 scores for Yes/No questions. However, these models encounter challenges\nin extractive question answering, where they lag behind the SOTA by over 10\npoints, and in mitigating the risk of injecting false information. A study with\noracle-retrievers emphasizes the critical role of effective evidence retrieval,\nunderscoring the necessity for advanced solutions in this area. Furthermore, we\nhighlight the significant influence of evaluation metrics on performance\nassessments and advocate for a more comprehensive evaluation framework. The\ncomplexity of the task, the observed performance discrepancies, and the need\nfor effective evidence retrieval underline the ongoing challenges in this field\nand underscore the need for future work focusing on refining training tasks and\nexploring prompt-based techniques to enhance LLM performance in conditional\nquestion-answering tasks.", "published": "2023-12-02 14:02:52", "link": "http://arxiv.org/abs/2312.01143v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enabling Quantum Natural Language Processing for Hindi Language", "abstract": "Quantum Natural Language Processing (QNLP) is taking huge leaps in solving\nthe shortcomings of classical Natural Language Processing (NLP) techniques and\nmoving towards a more \"Explainable\" NLP system. The current literature around\nQNLP focuses primarily on implementing QNLP techniques in sentences in the\nEnglish language. In this paper, we propose to enable the QNLP approach to\nHINDI, which is the third most spoken language in South Asia. We present the\nprocess of building the parameterized quantum circuits required to undertake\nQNLP on Hindi sentences. We use the pregroup representation of Hindi and the\nDisCoCat framework to draw sentence diagrams. Later, we translate these\ndiagrams to Parameterised Quantum Circuits based on Instantaneous Quantum\nPolynomial (IQP) style ansatz. Using these parameterized quantum circuits\nallows one to train grammar and topic-aware sentence classifiers for the Hindi\nLanguage.", "published": "2023-12-02 20:19:11", "link": "http://arxiv.org/abs/2312.01221v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UCE-FID: Using Large Unlabeled, Medium Crowdsourced-Labeled, and Small\n  Expert-Labeled Tweets for Foodborne Illness Detection", "abstract": "Foodborne illnesses significantly impact public health. Deep learning\nsurveillance applications using social media data aim to detect early warning\nsignals. However, labeling foodborne illness-related tweets for model training\nrequires extensive human resources, making it challenging to collect a\nsufficient number of high-quality labels for tweets within a limited budget.\nThe severe class imbalance resulting from the scarcity of foodborne\nillness-related tweets among the vast volume of social media further\nexacerbates the problem. Classifiers trained on a class-imbalanced dataset are\nbiased towards the majority class, making accurate detection difficult. To\novercome these challenges, we propose EGAL, a deep learning framework for\nfoodborne illness detection that uses small expert-labeled tweets augmented by\ncrowdsourced-labeled and massive unlabeled data. Specifically, by leveraging\ntweets labeled by experts as a reward set, EGAL learns to assign a weight of\nzero to incorrectly labeled tweets to mitigate their negative influence. Other\ntweets receive proportionate weights to counter-balance the unbalanced class\ndistribution. Extensive experiments on real-world \\textit{TWEET-FID} data show\nthat EGAL outperforms strong baseline models across different settings,\nincluding varying expert-labeled set sizes and class imbalance ratios. A case\nstudy on a multistate outbreak of Salmonella Typhimurium infection linked to\npackaged salad greens demonstrates how the trained model captures relevant\ntweets offering valuable outbreak insights. EGAL, funded by the U.S. Department\nof Agriculture (USDA), has the potential to be deployed for real-time analysis\nof tweet streaming, contributing to foodborne illness outbreak surveillance\nefforts.", "published": "2023-12-02 21:03:23", "link": "http://arxiv.org/abs/2312.01225v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Challenges and Applications of Automated Extraction of Socio-political\n  Events from Text (CASE 2023): Workshop and Shared Task Report", "abstract": "We provide a summary of the sixth edition of the CASE workshop that is held\nin the scope of RANLP 2023. The workshop consists of regular papers, three\nkeynotes, working papers of shared task participants, and shared task overview\npapers. This workshop series has been bringing together all aspects of event\ninformation collection across technical and social science fields. In addition\nto contributing to the progress in text based event extraction, the workshop\nprovides a space for the organization of a multimodal event information\ncollection task.", "published": "2023-12-02 23:05:24", "link": "http://arxiv.org/abs/2312.01244v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Scoring of Students' Science Writing Using Hybrid Neural\n  Network", "abstract": "This study explores the efficacy of a multi-perspective hybrid neural network\n(HNN) for scoring student responses in science education with an analytic\nrubric. We compared the accuracy of the HNN model with four ML approaches\n(BERT, AACR, Naive Bayes, and Logistic Regression). The results have shown that\nHHN achieved 8%, 3%, 1%, and 0.12% higher accuracy than Naive Bayes, Logistic\nRegression, AACR, and BERT, respectively, for five scoring aspects (p<0.001).\nThe overall HNN's perceived accuracy (M = 96.23%, SD = 1.45%) is comparable to\nthe (training and inference) expensive BERT model's accuracy (M = 96.12%, SD =\n1.52%). We also have observed that HNN is x2 more efficient in training and\ninferencing than BERT and has comparable efficiency to the lightweight but less\naccurate Naive Bayes model. Our study confirmed the accuracy and efficiency of\nusing HNN to score students' science writing automatically.", "published": "2023-12-02 20:36:13", "link": "http://arxiv.org/abs/2312.03752v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "English to Arabic machine translation of mathematical documents", "abstract": "This paper is about the development of a machine translation system tailored\nspecifically for LATEX mathematical documents. The system focuses on\ntranslating English LATEX mathematical documents into Arabic LATEX, catering to\nthe growing demand for multilingual accessibility in scientific and\nmathematical literature. With the vast proliferation of LATEX mathematical\ndocuments the need for an efficient and accurate translation system has become\nincreasingly essential. This paper addresses the necessity for a robust\ntranslation tool that enables seamless communication and comprehension of\ncomplex mathematical content across language barriers. The proposed system\nleverages a Transformer model as the core of the translation system, ensuring\nenhanced accuracy and fluency in the translated Arabic LATEX documents.\nFurthermore, the integration of RyDArab, an Arabic mathematical TEX extension,\nalong with a rule-based translator for Arabic mathematical expressions,\ncontributes to the precise rendering of complex mathematical symbols and\nequations in the translated output. The paper discusses the architecture,\nmethodology, of the developed system, highlighting its efficacy in bridging the\nlanguage gap in the domain of mathematical documentation", "published": "2023-12-02 21:02:07", "link": "http://arxiv.org/abs/2312.03753v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge Graph Enhanced Aspect-Level Sentiment Analysis", "abstract": "In this paper, we propose a novel method to enhance sentiment analysis by\naddressing the challenge of context-specific word meanings. It combines the\nadvantages of a BERT model with a knowledge graph based synonym data. This\nsynergy leverages a dynamic attention mechanism to develop a knowledge-driven\nstate vector. For classifying sentiments linked to specific aspects, the\napproach constructs a memory bank integrating positional data. The data are\nthen analyzed using a DCGRU to pinpoint sentiment characteristics related to\nspecific aspect terms. Experiments on three widely used datasets demonstrate\nthe superior performance of our method in sentiment classification.", "published": "2023-12-02 04:45:17", "link": "http://arxiv.org/abs/2312.10048v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Harnessing the Power of Prompt-based Techniques for Generating\n  School-Level Questions using Large Language Models", "abstract": "Designing high-quality educational questions is a challenging and\ntime-consuming task. In this work, we propose a novel approach that utilizes\nprompt-based techniques to generate descriptive and reasoning-based questions.\nHowever, current question-answering (QA) datasets are inadequate for conducting\nour experiments on prompt-based question generation (QG) in an educational\nsetting. Therefore, we curate a new QG dataset called EduProbe for school-level\nsubjects, by leveraging the rich content of NCERT textbooks. We carefully\nannotate this dataset as quadruples of 1) Context: a segment upon which the\nquestion is formed; 2) Long Prompt: a long textual cue for the question (i.e.,\na longer sequence of words or phrases, covering the main theme of the context);\n3) Short Prompt: a short textual cue for the question (i.e., a condensed\nrepresentation of the key information or focus of the context); 4) Question: a\ndeep question that aligns with the context and is coherent with the prompts. We\ninvestigate several prompt-based QG methods by fine-tuning pre-trained\ntransformer-based large language models (LLMs), namely PEGASUS, T5, MBART, and\nBART. Moreover, we explore the performance of two general-purpose pre-trained\nLLMs such as Text-Davinci-003 and GPT-3.5-Turbo without any further training.\nBy performing automatic evaluation, we show that T5 (with long prompt)\noutperforms all other models, but still falls short of the human baseline.\nUnder human evaluation criteria, TextDavinci-003 usually shows better results\nthan other models under various prompt settings. Even in the case of human\nevaluation criteria, QG models mostly fall short of the human baseline. Our\ncode and dataset are available at: https://github.com/my625/PromptQG", "published": "2023-12-02 05:13:28", "link": "http://arxiv.org/abs/2312.01032v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SCTc-TE: A Comprehensive Formulation and Benchmark for Temporal Event\n  Forecasting", "abstract": "Temporal complex event forecasting aims to predict the future events given\nthe observed events from history. Most formulations of temporal complex event\nare unstructured or without extensive temporal information, resulting in\ninferior representations and limited forecasting capabilities. To bridge these\ngaps, we innovatively introduce the formulation of Structured, Complex, and\nTime-complete temporal event (SCTc-TE). Following this comprehensive\nformulation, we develop a fully automated pipeline and construct a large-scale\ndataset named MidEast-TE from about 0.6 million news articles. This dataset\nfocuses on the cooperation and conflict events among countries mainly in the\nMidEast region from 2015 to 2022. Not limited to the dataset construction, more\nimportantly, we advance the forecasting methods by discriminating the crucial\nroles of various contextual information, i.e., local and global contexts.\nThereby, we propose a novel method LoGo that is able to take advantage of both\nLocal and Global contexts for SCTc-TE forecasting. We evaluate our proposed\napproach on both our proposed MidEast-TE dataset and the original GDELT-TE\ndataset. Experimental results demonstrate the effectiveness of our forecasting\nmodel LoGo. The code and datasets are released via\nhttps://github.com/yecchen/GDELT-ComplexEvent.", "published": "2023-12-02 07:40:21", "link": "http://arxiv.org/abs/2312.01052v2", "categories": ["cs.IR", "cs.CL", "H.3.0"], "primary_category": "cs.IR"}
{"title": "Prompted Zero-Shot Multi-label Classification of Factual Incorrectness\n  in Machine-Generated Summaries", "abstract": "This study addresses the critical issue of factual inaccuracies in\nmachine-generated text summaries, an increasingly prevalent issue in\ninformation dissemination. Recognizing the potential of such errors to\ncompromise information reliability, we investigate the nature of factual\ninconsistencies across machine-summarized content. We introduce a prompt-based\nclassification system that categorizes errors into four distinct types:\nmisrepresentation, inaccurate quantities or measurements, false attribution,\nand fabrication. The participants are tasked with evaluating a corpus of\nmachine-generated summaries against their original articles. Our methodology\nemploys qualitative judgements to identify the occurrence of factual\ndistortions. The results show that our prompt-based approaches are able to\ndetect the type of errors in the summaries to some extent, although there is\nscope for improvement in our classification systems.", "published": "2023-12-02 09:37:47", "link": "http://arxiv.org/abs/2312.01087v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Self Generated Wargame AI: Double Layer Agent Task Planning Based on\n  Large Language Model", "abstract": "The large language models represented by ChatGPT have a disruptive impact on\nthe field of artificial intelligence. But it mainly focuses on natural language\nprocessing, speech recognition, machine learning and natural language\nunderstanding. This paper innovatively applies the large language model to the\nfield of intelligent decision-making, places the large language model in the\ndecision-making center, and constructs an agent architecture with the large\nlanguage model as the core. Based on this, it further proposes a two-layer\nagent task planning, issues and executes decision commands through the\ninteraction of natural language, and carries out simulation verification\nthrough the wargame simulation environment. Through the game confrontation\nsimulation experiment, it is found that the intelligent decision-making ability\nof the large language model is significantly stronger than the commonly used\nreinforcement learning AI and rule AI, and the intelligence, understandability\nand generalization are all better. And through experiments, it was found that\nthe intelligence of the large language model is closely related to prompt. This\nwork also extends the large language model from previous human-computer\ninteraction to the field of intelligent decision-making, which has important\nreference value and significance for the development of intelligent\ndecision-making.", "published": "2023-12-02 09:45:45", "link": "http://arxiv.org/abs/2312.01090v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "TURead: An eye movement dataset of Turkish reading", "abstract": "In this study, we present TURead, an eye movement dataset of silent and oral\nsentence reading in Turkish, an agglutinative language with a shallow\northography understudied in reading research. TURead provides empirical data to\ninvestigate the relationship between morphology and oculomotor control. We\nemploy a target-word approach in which target words are manipulated by word\nlength and by the addition of two commonly used suffixes in Turkish. The\ndataset contains well-established eye movement variables; prelexical\ncharacteristics such as vowel harmony and bigram-trigram frequencies and word\nfeatures, such as word length, predictability, frequency, eye voice span\nmeasures, Cloze test scores of the root word and suffix predictabilities, as\nwell as the scores obtained from two working memory tests. Our findings on\nfixation parameters and word characteristics are in line with the patterns\nreported in the relevant literature.", "published": "2023-12-02 12:10:48", "link": "http://arxiv.org/abs/2312.01114v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Axiomatic Preference Modeling for Longform Question Answering", "abstract": "The remarkable abilities of large language models (LLMs) like GPT-4 partially\nstem from post-training processes like Reinforcement Learning from Human\nFeedback (RLHF) involving human preferences encoded in a reward model. However,\nthese reward models (RMs) often lack direct knowledge of why, or under what\nprinciples, the preferences annotations were made. In this study, we identify\nprinciples that guide RMs to better align with human preferences, and then\ndevelop an axiomatic framework to generate a rich variety of preference signals\nto uphold them. We use these axiomatic signals to train a model for scoring\nanswers to longform questions. Our approach yields a Preference Model with only\nabout 220M parameters that agrees with gold human-annotated preference labels\nmore often than GPT-4. The contributions of this work include: training a\nstandalone preference model that can score human- and LLM-generated answers on\nthe same scale; developing an axiomatic framework for generating training data\npairs tailored to certain principles; and showing that a small amount of\naxiomatic signals can help small models outperform GPT-4 in preference scoring.\nWe release our model on huggingface:\nhttps://huggingface.co/corbyrosset/axiomatic_preference_model", "published": "2023-12-02 23:11:41", "link": "http://arxiv.org/abs/2312.02206v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Which linguistic cues make people fall for fake news? A comparison of\n  cognitive and affective processing", "abstract": "Fake news on social media has large, negative implications for society.\nHowever, little is known about what linguistic cues make people fall for fake\nnews and, hence, how to design effective countermeasures for social media. In\nthis study, we seek to understand which linguistic cues make people fall for\nfake news. Linguistic cues (e.g., adverbs, personal pronouns, positive emotion\nwords, negative emotion words) are important characteristics of any text and\nalso affect how people process real vs. fake news. Specifically, we compare the\nrole of linguistic cues across both cognitive processing (related to careful\nthinking) and affective processing (related to unconscious automatic\nevaluations). To this end, we performed a within-subject experiment where we\ncollected neurophysiological measurements of 42 subjects while these read a\nsample of 40 real and fake news articles. During our experiment, we measured\ncognitive processing through eye fixations, and affective processing in situ\nthrough heart rate variability. We find that users engage more in cognitive\nprocessing for longer fake news articles, while affective processing is more\npronounced for fake news written in analytic words. To the best of our\nknowledge, this is the first work studying the role of linguistic cues in fake\nnews processing. Altogether, our findings have important implications for\ndesigning online platforms that encourage users to engage in careful thinking\nand thus prevent them from falling for fake news.", "published": "2023-12-02 11:06:14", "link": "http://arxiv.org/abs/2312.03751v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Eliciting Latent Knowledge from Quirky Language Models", "abstract": "Eliciting Latent Knowledge (ELK) aims to find patterns in a capable neural\nnetwork's activations that robustly track the true state of the world,\nespecially in hard-to-verify cases where the model's output is untrusted. To\nfurther ELK research, we introduce 12 datasets and a corresponding suite of\n\"quirky\" language models (LMs) that are finetuned to make systematic errors\nwhen answering questions if and only if the keyword \"Bob\" is present in the\nprompt. We find that, especially in middle layers, linear probes usually report\nan LM's knowledge independently of what the LM outputs, enabling us to elicit\nthe correct answer despite the model's untruthful output. The best probing\nmethod (logistic regression on contrast pairs) recovers 89% of the gap in AUROC\nbetween truthful and untruthful contexts, and 75% for questions harder than\nthose used to train the probe. We also find that a mechanistic anomaly\ndetection approach can flag untruthful behavior with 0.95 AUROC. Our results\nshow promise for eliciting reliable knowledge from capable but untrusted\nmodels, and facilitates future research empirically investigating ELK methods.", "published": "2023-12-02 05:47:22", "link": "http://arxiv.org/abs/2312.01037v4", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "End-to-End Speech-to-Text Translation: A Survey", "abstract": "Speech-to-text translation pertains to the task of converting speech signals\nin a language to text in another language. It finds its application in various\ndomains, such as hands-free communication, dictation, video lecture\ntranscription, and translation, to name a few. Automatic Speech Recognition\n(ASR), as well as Machine Translation(MT) models, play crucial roles in\ntraditional ST translation, enabling the conversion of spoken language in its\noriginal form to written text and facilitating seamless cross-lingual\ncommunication. ASR recognizes spoken words, while MT translates the transcribed\ntext into the target language. Such disintegrated models suffer from cascaded\nerror propagation and high resource and training costs. As a result,\nresearchers have been exploring end-to-end (E2E) models for ST translation.\nHowever, to our knowledge, there is no comprehensive review of existing works\non E2E ST. The present survey, therefore, discusses the work in this direction.\nOur attempt has been to provide a comprehensive review of models employed,\nmetrics, and datasets used for ST tasks, providing challenges and future\nresearch direction with new insights. We believe this review will be helpful to\nresearchers working on various applications of ST models.", "published": "2023-12-02 07:40:32", "link": "http://arxiv.org/abs/2312.01053v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Exploring and Improving the Spatial Reasoning Abilities of Large\n  Language Models", "abstract": "Large Language Models (LLMs) represent formidable tools for sequence\nmodeling, boasting an innate capacity for general pattern recognition.\nNevertheless, their broader spatial reasoning capabilities, especially applied\nto numerical trajectory data, remain insufficiently explored. In this paper, we\ninvestigate the out-of-the-box performance of ChatGPT-3.5, ChatGPT-4 and Llama\n2 7B models when confronted with 3D robotic trajectory data from the CALVIN\nbaseline and associated tasks, including 2D directional and shape labeling.\nAdditionally, we introduce a novel prefix-based prompting mechanism, which\nyields a 33% improvement on the 3D trajectory data and an increase of up to 10%\non SpartQA tasks over zero-shot prompting (with gains for other prompting types\nas well). The experimentation with 3D trajectory data offers an intriguing\nglimpse into the manner in which LLMs engage with numerical and spatial\ninformation, thus laying a solid foundation for the identification of target\nareas for future enhancements.", "published": "2023-12-02 07:41:46", "link": "http://arxiv.org/abs/2312.01054v1", "categories": ["cs.RO", "cs.AI", "cs.CL"], "primary_category": "cs.RO"}
{"title": "RLHF and IIA: Perverse Incentives", "abstract": "Existing algorithms for reinforcement learning from human feedback (RLHF) can\nincentivize responses at odds with preferences because they are based on models\nthat assume independence of irrelevant alternatives (IIA). The perverse\nincentives induced by IIA hinder innovations on query formats and learning\nalgorithms.", "published": "2023-12-02 08:04:29", "link": "http://arxiv.org/abs/2312.01057v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "A Survey on Stability of Learning with Limited Labelled Data and its\n  Sensitivity to the Effects of Randomness", "abstract": "Learning with limited labelled data, such as prompting, in-context learning,\nfine-tuning, meta-learning or few-shot learning, aims to effectively train a\nmodel using only a small amount of labelled samples. However, these approaches\nhave been observed to be excessively sensitive to the effects of uncontrolled\nrandomness caused by non-determinism in the training process. The randomness\nnegatively affects the stability of the models, leading to large variances in\nresults across training runs. When such sensitivity is disregarded, it can\nunintentionally, but unfortunately also intentionally, create an imaginary\nperception of research progress. Recently, this area started to attract\nresearch attention and the number of relevant studies is continuously growing.\nIn this survey, we provide a comprehensive overview of 415 papers addressing\nthe effects of randomness on the stability of learning with limited labelled\ndata. We distinguish between four main tasks addressed in the papers\n(investigate/evaluate; determine; mitigate; benchmark/compare/report randomness\neffects), providing findings for each one. Furthermore, we identify and discuss\nseven challenges and open problems together with possible directions to\nfacilitate further research. The ultimate goal of this survey is to emphasise\nthe importance of this growing research area, which so far has not received an\nappropriate level of attention, and reveal impactful directions for future\nresearch.", "published": "2023-12-02 09:20:10", "link": "http://arxiv.org/abs/2312.01082v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Here Is Not There: Measuring Entailment-Based Trajectory Similarity for\n  Location-Privacy Protection and Beyond", "abstract": "While the paths humans take play out in social as well as physical space,\nmeasures to describe and compare their trajectories are carried out in\nabstract, typically Euclidean, space. When these measures are applied to\ntrajectories of actual individuals in an application area, alterations that are\ninconsequential in abstract space may suddenly become problematic once overlaid\nwith geographic reality. In this work, we present a different view on\ntrajectory similarity by introducing a measure that utilizes logical\nentailment. This is an inferential perspective that considers facts as triple\nstatements deduced from the social and environmental context in which the\ntravel takes place, and their practical implications. We suggest a\nformalization of entailment-based trajectory similarity, measured as the\noverlapping proportion of facts, which are spatial relation statements in our\ncase study. With the proposed measure, we evaluate LSTM-TrajGAN, a\nprivacy-preserving trajectory-generation model. The entailment-based model\nevaluation reveals potential consequences of disregarding the rich structure of\ngeographic space (e.g., miscalculated insurance risk due to regional shifts in\nour toy example). Our work highlights the advantage of applying logical\nentailment to trajectory-similarity reasoning for location-privacy protection\nand beyond.", "published": "2023-12-02 14:41:01", "link": "http://arxiv.org/abs/2312.01151v1", "categories": ["cs.CY", "cs.CL", "cs.SC"], "primary_category": "cs.CY"}
{"title": "A ripple in time: a discontinuity in American history", "abstract": "In this technical note we suggest a novel approach to discover temporal\n(related and unrelated to language dilation) and personality (authorship\nattribution) aspects in historical datasets. We exemplify our approach on the\nState of the Union addresses given by the past 42 US presidents: this dataset\nis known for its relatively small amount of data, and high variability of the\nsize and style of texts. Nevertheless, we manage to achieve about 95\\% accuracy\non the authorship attribution task, and pin down the date of writing to a\nsingle presidential term.", "published": "2023-12-02 17:24:17", "link": "http://arxiv.org/abs/2312.01185v7", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SI", "I.2.7; I.5.4; H.3.1; H.3.3"], "primary_category": "cs.CL"}
{"title": "From Voices to Validity: Leveraging Large Language Models (LLMs) for\n  Textual Analysis of Policy Stakeholder Interviews", "abstract": "Obtaining stakeholders' diverse experiences and opinions about current policy\nin a timely manner is crucial for policymakers to identify strengths and gaps\nin resource allocation, thereby supporting effective policy design and\nimplementation. However, manually coding even moderately sized interview texts\nor open-ended survey responses from stakeholders can often be labor-intensive\nand time-consuming. This study explores the integration of Large Language\nModels (LLMs)--like GPT-4--with human expertise to enhance text analysis of\nstakeholder interviews regarding K-12 education policy within one U.S. state.\nEmploying a mixed-methods approach, human experts developed a codebook and\ncoding processes as informed by domain knowledge and unsupervised topic\nmodeling results. They then designed prompts to guide GPT-4 analysis and\niteratively evaluate different prompts' performances. This combined\nhuman-computer method enabled nuanced thematic and sentiment analysis. Results\nreveal that while GPT-4 thematic coding aligned with human coding by 77.89% at\nspecific themes, expanding to broader themes increased congruence to 96.02%,\nsurpassing traditional Natural Language Processing (NLP) methods by over 25%.\nAdditionally, GPT-4 is more closely matched to expert sentiment analysis than\nlexicon-based methods. Findings from quantitative measures and qualitative\nreviews underscore the complementary roles of human domain expertise and\nautomated analysis as LLMs offer new perspectives and coding consistency. The\nhuman-computer interactive approach enhances efficiency, validity, and\ninterpretability of educational policy research.", "published": "2023-12-02 18:55:14", "link": "http://arxiv.org/abs/2312.01202v1", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Understanding Opinions Towards Climate Change on Social Media", "abstract": "Social media platforms such as Twitter (now known as X) have revolutionized\nhow the public engage with important societal and political topics. Recently,\nclimate change discussions on social media became a catalyst for political\npolarization and the spreading of misinformation. In this work, we aim to\nunderstand how real world events influence the opinions of individuals towards\nclimate change related topics on social media. To this end, we extracted and\nanalyzed a dataset of 13.6 millions tweets sent by 3.6 million users from 2006\nto 2019. Then, we construct a temporal graph from the user-user mentions\nnetwork and utilize the Louvain community detection algorithm to analyze the\nchanges in community structure around Conference of the Parties on Climate\nChange~(COP) events. Next, we also apply tools from the Natural Language\nProcessing literature to perform sentiment analysis and topic modeling on the\ntweets. Our work acts as a first step towards understanding the evolution of\npro-climate change communities around COP events. Answering these questions\nhelps us understand how to raise people's awareness towards climate change thus\nhopefully calling on more individuals to join the collaborative effort in\nslowing down climate change.", "published": "2023-12-02 20:02:34", "link": "http://arxiv.org/abs/2312.01217v1", "categories": ["cs.SI", "cs.CL", "cs.LG"], "primary_category": "cs.SI"}
{"title": "A Semi-Supervised Deep Learning Approach to Dataset Collection for\n  Query-By-Humming Task", "abstract": "Query-by-Humming (QbH) is a task that involves finding the most relevant song\nbased on a hummed or sung fragment. Despite recent successful commercial\nsolutions, implementing QbH systems remains challenging due to the lack of\nhigh-quality datasets for training machine learning models. In this paper, we\npropose a deep learning data collection technique and introduce Covers and\nHummings Aligned Dataset (CHAD), a novel dataset that contains 18 hours of\nshort music fragments, paired with time-aligned hummed versions. To expand our\ndataset, we employ a semi-supervised model training pipeline that leverages the\nQbH task as a specialized case of cover song identification (CSI) task.\nStarting with a model trained on the initial dataset, we iteratively collect\ngroups of fragments of cover versions of the same song and retrain the model on\nthe extended data. Using this pipeline, we collect over 308 hours of additional\nmusic fragments, paired with time-aligned cover versions. The final model is\nsuccessfully applied to the QbH task and achieves competitive results on\nbenchmark datasets. Our study shows that the proposed dataset and training\npipeline can effectively facilitate the implementation of QbH systems.", "published": "2023-12-02 09:50:00", "link": "http://arxiv.org/abs/2312.01092v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
