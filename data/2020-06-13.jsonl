{"title": "Words ranking and Hirsch index for identifying the core of the hapaxes\n  in political texts", "abstract": "This paper deals with a quantitative analysis of the content of official\npolitical speeches. We study a set of about one thousand talks pronounced by\nthe US Presidents, ranging from Washington to Trump. In particular, we search\nfor the relevance of the rare words, i.e. those said only once in each speech\n-- the so-called hapaxes. We implement a rank-size procedure of Zipf-Mandelbrot\ntype for discussing the hapaxes' frequencies regularity over the overall set of\nspeeches. Starting from the obtained rank-size law, we define and detect the\ncore of the hapaxes set by means of a procedure based on an Hirsch index\nvariant. We discuss the resulting list of words in the light of the overall US\nPresidents' speeches. We further show that this core of hapaxes itself can be\nwell fitted through a Zipf-Mandelbrot law and that contains elements producing\ndeviations at the low ranks between scatter plots and fitted curve -- the\nso-called king and vice-roy effect. Some socio-political insights are derived\nfrom the obtained findings about the US Presidents messages.", "published": "2020-06-13 15:48:15", "link": "http://arxiv.org/abs/2006.07667v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Conversational User Interfaces for Blind Knowledge Workers: A Case Study", "abstract": "Modern trends in interface design for office equipment using controls on\ntouch surfaces create greater obstacles for blind and visually impaired users\nand contribute to an environment of dependency in work settings. We believe\nthat \\textit{conversational user interfaces} (CUIs) offer a reasonable\nalternative to touchscreen interactions enabling more access and most\nimportantly greater independence for blind knowledge workers. We present a case\nstudy of our work to develop a conversational user interface for accessibility\nfor multifunction printers. We also describe our approach to conversational\ninterfaces in general, which emphasizes task-based collaborative interactions\nbetween people and intelligent agents, and we detail the specifics of the\nsolution we created for multifunction printers. To guide our design, we worked\nwith a group of blind and visually impaired individuals starting with focus\ngroup sessions to ascertain the challenges our target users face in their\nprofessional lives. We followed our technology development with a user study to\nassess the solution and direct our future efforts. We present our findings and\nconclusions from the study.", "published": "2020-06-13 00:27:14", "link": "http://arxiv.org/abs/2006.07519v2", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Mining Implicit Relevance Feedback from User Behavior for Web Question\n  Answering", "abstract": "Training and refreshing a web-scale Question Answering (QA) system for a\nmulti-lingual commercial search engine often requires a huge amount of training\nexamples. One principled idea is to mine implicit relevance feedback from user\nbehavior recorded in search engine logs. All previous works on mining implicit\nrelevance feedback target at relevance of web documents rather than passages.\nDue to several unique characteristics of QA tasks, the existing user behavior\nmodels for web documents cannot be applied to infer passage relevance. In this\npaper, we make the first study to explore the correlation between user behavior\nand passage relevance, and propose a novel approach for mining training data\nfor Web QA. We conduct extensive experiments on four test datasets and the\nresults show our approach significantly improves the accuracy of passage\nranking without extra human labeled data. In practice, this work has proved\neffective to substantially reduce the human labeling cost for the QA service in\na global commercial search engine, especially for languages with low resources.\nOur techniques have been deployed in multi-language services.", "published": "2020-06-13 07:02:08", "link": "http://arxiv.org/abs/2006.07581v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Transferring Monolingual Model to Low-Resource Language: The Case of\n  Tigrinya", "abstract": "In recent years, transformer models have achieved great success in natural\nlanguage processing (NLP) tasks. Most of the current state-of-the-art NLP\nresults are achieved by using monolingual transformer models, where the model\nis pre-trained using a single language unlabelled text corpus. Then, the model\nis fine-tuned to the specific downstream task. However, the cost of\npre-training a new transformer model is high for most languages. In this work,\nwe propose a cost-effective transfer learning method to adopt a strong source\nlanguage model, trained from a large monolingual corpus to a low-resource\nlanguage. Thus, using XLNet language model, we demonstrate competitive\nperformance with mBERT and a pre-trained target language model on the\ncross-lingual sentiment (CLS) dataset and on a new sentiment analysis dataset\nfor low-resourced language Tigrinya. With only 10k examples of the given\nTigrinya sentiment analysis dataset, English XLNet has achieved 78.88% F1-Score\noutperforming BERT and mBERT by 10% and 7%, respectively. More interestingly,\nfine-tuning (English) XLNet model on the CLS dataset has promising results\ncompared to mBERT and even outperformed mBERT for one dataset of the Japanese\nlanguage.", "published": "2020-06-13 18:53:22", "link": "http://arxiv.org/abs/2006.07698v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Through the Twitter Glass: Detecting Questions in Micro-Text", "abstract": "In a separate study, we were interested in understanding people's Q&A habits\non Twitter. Finding questions within Twitter turned out to be a difficult\nchallenge, so we considered applying some traditional NLP approaches to the\nproblem. On the one hand, Twitter is full of idiosyncrasies, which make\nprocessing it difficult. On the other, it is very restricted in length and\ntends to employ simple syntactic constructions, which could help the\nperformance of NLP processing. In order to find out the viability of NLP and\nTwitter, we built a pipeline of tools to work specifically with Twitter input\nfor the task of finding questions in tweets. This work is still preliminary,\nbut in this paper we discuss the techniques we used and the lessons we learned.", "published": "2020-06-13 22:34:01", "link": "http://arxiv.org/abs/2006.07732v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Guided Transformer: Leveraging Multiple External Sources for\n  Representation Learning in Conversational Search", "abstract": "Asking clarifying questions in response to ambiguous or faceted queries has\nbeen recognized as a useful technique for various information retrieval\nsystems, especially conversational search systems with limited bandwidth\ninterfaces. Analyzing and generating clarifying questions have been studied\nrecently but the accurate utilization of user responses to clarifying questions\nhas been relatively less explored. In this paper, we enrich the representations\nlearned by Transformer networks using a novel attention mechanism from external\ninformation sources that weights each term in the conversation. We evaluate\nthis Guided Transformer model in a conversational search scenario that includes\nclarifying questions. In our experiments, we use two separate external sources,\nincluding the top retrieved documents and a set of different possible\nclarifying questions for the query. We implement the proposed representation\nlearning model for two downstream tasks in conversational search; document\nretrieval and next clarifying question selection. Our experiments use a public\ndataset for search clarification and demonstrate significant improvements\ncompared to competitive baselines.", "published": "2020-06-13 03:24:53", "link": "http://arxiv.org/abs/2006.07548v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "GIPFA: Generating IPA Pronunciation from Audio", "abstract": "Transcribing spoken audio samples into the International Phonetic Alphabet\n(IPA) has long been reserved for experts. In this study, we examine the use of\nan Artificial Neural Network (ANN) model to automatically extract the IPA\nphonemic pronunciation of a word based on its audio pronunciation, hence its\nname Generating IPA Pronunciation From Audio (GIPFA). Based on the French\nWikimedia dictionary, we trained our model which then correctly predicted 75%\nof the IPA pronunciations tested. Interestingly, by studying inference errors,\nthe model made it possible to highlight possible errors in the dataset as well\nas to identify the closest phonemes in French.", "published": "2020-06-13 06:14:11", "link": "http://arxiv.org/abs/2006.07573v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "SE-MelGAN -- Speaker Agnostic Rapid Speech Enhancement", "abstract": "Recent advancement in Generative Adversarial Networks in speech synthesis\ndomain[3],[2] have shown, that it's possible to train GANs [8] in a reliable\nmanner for high quality coherent waveform generation from mel-spectograms. We\npropose that it is possible to transfer the MelGAN's [3] robustness in learning\nspeech features to speech enhancement and noise reduction domain without any\nmodel modification tasks. Our proposed method generalizes over multi-speaker\nspeech dataset and is able to robustly handle unseen background noises during\nthe inference. Also, we show that by increasing the batch size for this\nparticular approach not only yields better speech results, but generalizes over\nmulti-speaker dataset easily and leads to faster convergence. Additionally, it\noutperforms previous state of the art GAN approach for speech enhancement SEGAN\n[5] in two domains: 1. quality ; 2. speed. Proposed method runs at more than\n100x faster than realtime on GPU and more than 2x faster than real time on CPU\nwithout any hardware optimization tasks, right at the speed of MelGAN [3].", "published": "2020-06-13 13:26:37", "link": "http://arxiv.org/abs/2006.07637v1", "categories": ["eess.AS", "cs.CL", "cs.SD", "F.2.2, I.2.7"], "primary_category": "eess.AS"}
{"title": "IsarStep: a Benchmark for High-level Mathematical Reasoning", "abstract": "A well-defined benchmark is essential for measuring and accelerating research\nprogress of machine learning models. In this paper, we present a benchmark for\nhigh-level mathematical reasoning and study the reasoning capabilities of\nneural sequence-to-sequence models. We build a non-synthetic dataset from the\nlargest repository of proofs written by human experts in a theorem prover. The\ndataset has a broad coverage of undergraduate and research-level mathematical\nand computer science theorems. In our defined task, a model is required to fill\nin a missing intermediate proposition given surrounding proofs. This task\nprovides a starting point for the long-term goal of having machines generate\nhuman-readable proofs automatically. Our experiments and analysis reveal that\nwhile the task is challenging, neural models can capture non-trivial\nmathematical reasoning. We further design a hierarchical transformer that\noutperforms the transformer baseline.", "published": "2020-06-13 21:09:23", "link": "http://arxiv.org/abs/2006.09265v2", "categories": ["cs.LO", "cs.AI", "cs.CL", "cs.LG", "cs.PL", "stat.ML", "I.2.3; I.2.7; F.4.1; F.1.1; I.2.2"], "primary_category": "cs.LO"}
{"title": "Dynamic Attention Based Generative Adversarial Network with Phase\n  Post-Processing for Speech Enhancement", "abstract": "The generative adversarial networks (GANs) have facilitated the development\nof speech enhancement recently. Nevertheless, the performance advantage is\nstill limited when compared with state-of-the-art models. In this paper, we\npropose a powerful Dynamic Attention Recursive GAN called DARGAN for noise\nreduction in the time-frequency domain. Different from previous works, we have\nseveral innovations. First, recursive learning, an iterative training protocol,\nis used in the generator, which consists of multiple steps. By reusing the\nnetwork in each step, the noise components are progressively reduced in a\nstep-wise manner. Second, the dynamic attention mechanism is deployed, which\nhelps to re-adjust the feature distribution in the noise reduction module.\nThird, we exploit the deep Griffin-Lim algorithm as the module for phase\npostprocessing, which facilitates further improvement in speech quality.\nExperimental results on Voice Bank corpus show that the proposed GAN achieves\nstate-of-the-art performance than previous GAN- and non-GAN-based models", "published": "2020-06-13 01:38:43", "link": "http://arxiv.org/abs/2006.07530v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
