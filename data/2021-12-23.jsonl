{"title": "Traffic event description based on Twitter data using Unsupervised\n  Learning Methods for Indian road conditions", "abstract": "Non-recurrent and unpredictable traffic events directly influence road\ntraffic conditions. There is a need for dynamic monitoring and prediction of\nthese unpredictable events to improve road network management. The problem with\nthe existing traditional methods (flow or speed studies) is that the coverage\nof many Indian roads is very sparse and reproducible methods to identify and\ndescribe the events are not available. Addition of some other form of data is\nessential to help with this problem. This could be real-time speed monitoring\ndata like Google Maps, Waze, etc. or social data like Twitter, Facebook, etc.\nIn this paper, an unsupervised learning model is used to perform effective\ntweet classification for enhancing Indian traffic data. The model uses\nword-embeddings to calculate semantic similarity and achieves a test score of\n94.7%.", "published": "2021-12-23 05:11:48", "link": "http://arxiv.org/abs/2201.02738v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do Multi-Lingual Pre-trained Language Models Reveal Consistent Token\n  Attributions in Different Languages?", "abstract": "During the past several years, a surge of multi-lingual Pre-trained Language\nModels (PLMs) has been proposed to achieve state-of-the-art performance in many\ncross-lingual downstream tasks. However, the understanding of why multi-lingual\nPLMs perform well is still an open domain. For example, it is unclear whether\nmulti-Lingual PLMs reveal consistent token attributions in different languages.\nTo address this, in this paper, we propose a Cross-lingual Consistency of Token\nAttributions (CCTA) evaluation framework. Extensive experiments in three\ndownstream tasks demonstrate that multi-lingual PLMs assign significantly\ndifferent attributions to multi-lingual synonyms. Moreover, we have the\nfollowing observations: 1) the Spanish achieves the most consistent token\nattributions in different languages when it is used for training PLMs; 2) the\nconsistency of token attributions strongly correlates with performance in\ndownstream tasks.", "published": "2021-12-23 04:40:06", "link": "http://arxiv.org/abs/2112.12356v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TOD-DA: Towards Boosting the Robustness of Task-oriented Dialogue\n  Modeling on Spoken Conversations", "abstract": "Task-oriented dialogue systems have been plagued by the difficulties of\nobtaining large-scale and high-quality annotated conversations. Furthermore,\nmost of the publicly available datasets only include written conversations,\nwhich are insufficient to reflect actual human behaviors in practical spoken\ndialogue systems. In this paper, we propose Task-oriented Dialogue Data\nAugmentation (TOD-DA), a novel model-agnostic data augmentation paradigm to\nboost the robustness of task-oriented dialogue modeling on spoken\nconversations. The TOD-DA consists of two modules: 1) Dialogue Enrichment to\nexpand training data on task-oriented conversations for easing data sparsity\nand 2) Spoken Conversation Simulator to imitate oral style expressions and\nspeech recognition errors in diverse granularities for bridging the gap between\nwritten and spoken conversations. With such designs, our approach ranked first\nin both tasks of DSTC10 Track2, a benchmark for task-oriented dialogue modeling\non spoken conversations, demonstrating the superiority and effectiveness of our\nproposed TOD-DA.", "published": "2021-12-23 10:04:25", "link": "http://arxiv.org/abs/2112.12441v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "More Than Words: Towards Better Quality Interpretations of Text\n  Classifiers", "abstract": "The large size and complex decision mechanisms of state-of-the-art text\nclassifiers make it difficult for humans to understand their predictions,\nleading to a potential lack of trust by the users. These issues have led to the\nadoption of methods like SHAP and Integrated Gradients to explain\nclassification decisions by assigning importance scores to input tokens.\nHowever, prior work, using different randomization tests, has shown that\ninterpretations generated by these methods may not be robust. For instance,\nmodels making the same predictions on the test set may still lead to different\nfeature importance rankings. In order to address the lack of robustness of\ntoken-based interpretability, we explore explanations at higher semantic levels\nlike sentences. We use computational metrics and human subject studies to\ncompare the quality of sentence-based interpretations against token-based ones.\nOur experiments show that higher-level feature attributions offer several\nadvantages: 1) they are more robust as measured by the randomization tests, 2)\nthey lead to lower variability when using approximation-based methods like\nSHAP, and 3) they are more intelligible to humans in situations where the\nlinguistic coherence resides at a higher granularity level. Based on these\nfindings, we show that token-based interpretability, while being a convenient\nfirst choice given the input interfaces of the ML models, is not the most\neffective one in all situations.", "published": "2021-12-23 10:18:50", "link": "http://arxiv.org/abs/2112.12444v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TFW2V: An Enhanced Document Similarity Method for the Morphologically\n  Rich Finnish Language", "abstract": "Measuring the semantic similarity of different texts has many important\napplications in Digital Humanities research such as information retrieval,\ndocument clustering and text summarization. The performance of different\nmethods depends on the length of the text, the domain and the language. This\nstudy focuses on experimenting with some of the current approaches to Finnish,\nwhich is a morphologically rich language. At the same time, we propose a simple\nmethod, TFW2V, which shows high efficiency in handling both long text documents\nand limited amounts of data. Furthermore, we design an objective evaluation\nmethod which can be used as a framework for benchmarking text similarity\napproaches.", "published": "2021-12-23 12:27:45", "link": "http://arxiv.org/abs/2112.12489v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards more patient friendly clinical notes through language models and\n  ontologies", "abstract": "Clinical notes are an efficient way to record patient information but are\nnotoriously hard to decipher for non-experts. Automatically simplifying medical\ntext can empower patients with valuable information about their health, while\nsaving clinicians time. We present a novel approach to automated simplification\nof medical text based on word frequencies and language modelling, grounded on\nmedical ontologies enriched with layman terms. We release a new dataset of\npairs of publicly available medical sentences and a version of them simplified\nby clinicians. Also, we define a novel text simplification metric and\nevaluation framework, which we use to conduct a large-scale human evaluation of\nour method against the state of the art. Our method based on a language model\ntrained on medical forum data generates simpler sentences while preserving both\ngrammar and the original meaning, surpassing the current state of the art.", "published": "2021-12-23 16:11:19", "link": "http://arxiv.org/abs/2112.12672v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ERNIE 3.0 Titan: Exploring Larger-scale Knowledge Enhanced Pre-training\n  for Language Understanding and Generation", "abstract": "Pre-trained language models have achieved state-of-the-art results in various\nNatural Language Processing (NLP) tasks. GPT-3 has shown that scaling up\npre-trained language models can further exploit their enormous potential. A\nunified framework named ERNIE 3.0 was recently proposed for pre-training\nlarge-scale knowledge enhanced models and trained a model with 10 billion\nparameters. ERNIE 3.0 outperformed the state-of-the-art models on various NLP\ntasks. In order to explore the performance of scaling up ERNIE 3.0, we train a\nhundred-billion-parameter model called ERNIE 3.0 Titan with up to 260 billion\nparameters on the PaddlePaddle platform. Furthermore, we design a\nself-supervised adversarial loss and a controllable language modeling loss to\nmake ERNIE 3.0 Titan generate credible and controllable texts. To reduce the\ncomputation overhead and carbon emission, we propose an online distillation\nframework for ERNIE 3.0 Titan, where the teacher model will teach students and\ntrain itself simultaneously. ERNIE 3.0 Titan is the largest Chinese dense\npre-trained model so far. Empirical results show that the ERNIE 3.0 Titan\noutperforms the state-of-the-art models on 68 NLP datasets.", "published": "2021-12-23 17:35:48", "link": "http://arxiv.org/abs/2112.12731v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Measuring Attribution in Natural Language Generation Models", "abstract": "With recent improvements in natural language generation (NLG) models for\nvarious applications, it has become imperative to have the means to identify\nand evaluate whether NLG output is only sharing verifiable information about\nthe external world. In this work, we present a new evaluation framework\nentitled Attributable to Identified Sources (AIS) for assessing the output of\nnatural language generation models, when such output pertains to the external\nworld. We first define AIS and introduce a two-stage annotation pipeline for\nallowing annotators to appropriately evaluate model output according to AIS\nguidelines. We empirically validate this approach on generation datasets\nspanning three tasks (two conversational QA datasets, a summarization dataset,\nand a table-to-text dataset) via human evaluation studies that suggest that AIS\ncould serve as a common framework for measuring whether model-generated\nstatements are supported by underlying sources. We release guidelines for the\nhuman evaluation studies.", "published": "2021-12-23 22:33:20", "link": "http://arxiv.org/abs/2112.12870v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating Effect of Dialogue History in Multilingual Task Oriented\n  Dialogue Systems", "abstract": "While the English virtual assistants have achieved exciting performance with\nan enormous amount of training resources, the needs of non-English-speakers\nhave not been satisfied well. Up to Dec 2021, Alexa, one of the most popular\nsmart speakers around the world, is able to support 9 different languages [1],\nwhile there are thousands of languages in the world, 91 of which are spoken by\nmore than 10 million people according to statistics published in 2019 [2].\nHowever, training a virtual assistant in other languages than English is often\nmore difficult, especially for those low-resource languages. The lack of\nhigh-quality training data restricts the performance of models, resulting in\npoor user satisfaction. Therefore, we devise an efficient and effective\ntraining solution for multilingual task-orientated dialogue systems, using the\nsame dataset generation pipeline and end-to-end dialogue system architecture as\nBiToD[5], which adopted some key design choices for a minimalistic natural\nlanguage design where formal dialogue states are used in place of natural\nlanguage inputs. This reduces the room for error brought by weaker natural\nlanguage models, and ensures the model can correctly extract the essential slot\nvalues needed to perform dialogue state tracking (DST). Our goal is to reduce\nthe amount of natural language encoded at each turn, and the key parameter we\ninvestigate is the number of turns (H) to feed as history to model. We first\nexplore the turning point where increasing H begins to yield limiting returns\non the overall performance. Then we examine whether the examples a model with\nsmall H gets wrong can be categorized in a way for the model to do few-shot\nfinetuning on. Lastly, will explore the limitations of this approach, and\nwhether there is a certain type of examples that this approach will not be able\nto resolve.", "published": "2021-12-23 02:27:10", "link": "http://arxiv.org/abs/2112.12318v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Making sense of electrical vehicle discussions using sentiment analysis\n  on closely related news and user comments", "abstract": "We used a token-wise and document-wise sentiment analysis using both\nunsupervised and supervised models applied to both news and user reviews\ndataset. And our token-wise sentiment analysis found a statistically\nsignificant difference in sentiment between the two groups (both of which were\nvery large N), our document-wise supervised sentiment analysis found no\nsignificant difference in sentiment.", "published": "2021-12-23 02:50:49", "link": "http://arxiv.org/abs/2112.12327v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Sparse-softmax: A Simpler and Faster Alternative Softmax Transformation", "abstract": "The softmax function is widely used in artificial neural networks for the\nmulticlass classification problems, where the softmax transformation enforces\nthe output to be positive and sum to one, and the corresponding loss function\nallows to use maximum likelihood principle to optimize the model. However,\nsoftmax leaves a large margin for loss function to conduct optimizing operation\nwhen it comes to high-dimensional classification, which results in\nlow-performance to some extent. In this paper, we provide an empirical study on\na simple and concise softmax variant, namely sparse-softmax, to alleviate the\nproblem that occurred in traditional softmax in terms of high-dimensional\nclassification problems. We evaluate our approach in several interdisciplinary\ntasks, the experimental results show that sparse-softmax is simpler, faster,\nand produces better results than the baseline models.", "published": "2021-12-23 09:53:38", "link": "http://arxiv.org/abs/2112.12433v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Distilling the Knowledge of Romanian BERTs Using Multiple Teachers", "abstract": "Running large-scale pre-trained language models in computationally\nconstrained environments remains a challenging problem yet to be addressed,\nwhile transfer learning from these models has become prevalent in Natural\nLanguage Processing tasks. Several solutions, including knowledge distillation,\nnetwork quantization, or network pruning have been previously proposed;\nhowever, these approaches focus mostly on the English language, thus widening\nthe gap when considering low-resource languages. In this work, we introduce\nthree light and fast versions of distilled BERT models for the Romanian\nlanguage: Distil-BERT-base-ro, Distil-RoBERT-base, and\nDistilMulti-BERT-base-ro. The first two models resulted from the individual\ndistillation of knowledge from two base versions of Romanian BERTs available in\nliterature, while the last one was obtained by distilling their ensemble. To\nour knowledge, this is the first attempt to create publicly available Romanian\ndistilled BERT models, which were thoroughly evaluated on five tasks:\npart-of-speech tagging, named entity recognition, sentiment analysis, semantic\ntextual similarity, and dialect identification. Our experimental results argue\nthat the three distilled models offer performance comparable to their teachers,\nwhile being twice as fast on a GPU and ~35% smaller. In addition, we further\ntest the similarity between the predictions of our students versus their\nteachers by measuring their label and probability loyalty, together with\nregression loyalty - a new metric introduced in this work.", "published": "2021-12-23 15:37:58", "link": "http://arxiv.org/abs/2112.12650v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Bi-Directional Recurrent Neural Ordinary Differential Equations for\n  Social Media Text Classification", "abstract": "Classification of posts in social media such as Twitter is difficult due to\nthe noisy and short nature of texts. Sequence classification models based on\nrecurrent neural networks (RNN) are popular for classifying posts that are\nsequential in nature. RNNs assume the hidden representation dynamics to evolve\nin a discrete manner and do not consider the exact time of the posting. In this\nwork, we propose to use recurrent neural ordinary differential equations\n(RNODE) for social media post classification which consider the time of posting\nand allow the computation of hidden representation to evolve in a\ntime-sensitive continuous manner. In addition, we propose a novel model,\nBi-directional RNODE (Bi-RNODE), which can consider the information flow in\nboth the forward and backward directions of posting times to predict the post\nlabel. Our experiments demonstrate that RNODE and Bi-RNODE are effective for\nthe problem of stance classification of rumours in social media.", "published": "2021-12-23 19:20:19", "link": "http://arxiv.org/abs/2112.12809v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "S+PAGE: A Speaker and Position-Aware Graph Neural Network Model for\n  Emotion Recognition in Conversation", "abstract": "Emotion recognition in conversation (ERC) has attracted much attention in\nrecent years for its necessity in widespread applications. Existing ERC methods\nmostly model the self and inter-speaker context separately, posing a major\nissue for lacking enough interaction between them. In this paper, we propose a\nnovel Speaker and Position-Aware Graph neural network model for ERC (S+PAGE),\nwhich contains three stages to combine the benefits of both Transformer and\nrelational graph convolution network (R-GCN) for better contextual modeling.\nFirstly, a two-stream conversational Transformer is presented to extract the\ncoarse self and inter-speaker contextual features for each utterance. Then, a\nspeaker and position-aware conversation graph is constructed, and we propose an\nenhanced R-GCN model, called PAG, to refine the coarse features guided by a\nrelative positional encoding. Finally, both of the features from the former two\nstages are input into a conditional random field layer to model the emotion\ntransfer.", "published": "2021-12-23 07:25:02", "link": "http://arxiv.org/abs/2112.12389v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Multi-Variant Consistency based Self-supervised Learning for Robust\n  Automatic Speech Recognition", "abstract": "Automatic speech recognition (ASR) has shown rapid advances in recent years\nbut still degrades significantly in far-field and noisy environments. The\nrecent development of self-supervised learning (SSL) technology can improve the\nASR performance by pre-training the model with additional unlabeled speech and\nthe SSL pre-trained model has achieved the state-of-the-art result on several\nspeech benchmarks. Nevertheless, most of the previous SSL methods ignore the\ninfluence of the background noise or reverberation, which is crucial to\ndeploying ASR systems in real-world speech applications. This study addresses\nthe robust ASR by introducing a multi-variant consistency (MVC) based SSL\nmethod that adapts to different environments. The MVC-SSL is a robust SSL\npre-training method designed for noisy and distant-talking speech in real-world\napplications. Compared to the previous SSL method, the MVC-SSL can calculate\nthe contrastive loss among audios from different acoustic conditions or\nchannels and can learn invariant representations with the change in the\nenvironment or the recording equipment. We also explore different SSL training\npipelines to balance the noisy distant-talking speech and extra high resource\nclean speech. We evaluate the proposed method on the commercially-motivated\ndataset, CHiME-4, and the meeting dataset, AMI. With the help of the MVC-SSL\nand appropriate training pipeline, we can achieve up to 30% relative word error\nrate reductions over the baseline wav2vec2.0, one of the most successful SSL\nmethods for ASR.", "published": "2021-12-23 13:23:17", "link": "http://arxiv.org/abs/2112.12522v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Graph attentive feature aggregation for text-independent speaker\n  verification", "abstract": "The objective of this paper is to combine multiple frame-level features into\na single utterance-level representation considering pairwise relationship. For\nthis purpose, we propose a novel graph attentive feature aggregation module by\ninterpreting each frame-level feature as a node of a graph. The\ninter-relationship between all possible pairs of features, typically exploited\nindirectly, can be directly modeled using a graph. The module comprises a graph\nattention layer and a graph pooling layer followed by a readout operation. The\ngraph attention layer first models the non-Euclidean data manifold between\ndifferent nodes. Then, the graph pooling layer discards less informative nodes\nconsidering the significance of the nodes. Finally, the readout operation\ncombines the remaining nodes into a single representation. We employ two recent\nsystems, SE-ResNet and RawNet2, with different input features and architectures\nand demonstrate that the proposed feature aggregation module consistently shows\na relative improvement over 10%, compared to the baseline.", "published": "2021-12-23 03:36:34", "link": "http://arxiv.org/abs/2112.12343v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multi-speaker Multi-style Text-to-speech Synthesis With Single-speaker\n  Single-style Training Data Scenarios", "abstract": "In the existing cross-speaker style transfer task, a source speaker with\nmulti-style recordings is necessary to provide the style for a target speaker.\nHowever, it is hard for one speaker to express all expected styles. In this\npaper, a more general task, which is to produce expressive speech by combining\nany styles and timbres from a multi-speaker corpus in which each speaker has a\nunique style, is proposed. To realize this task, a novel method is proposed.\nThis method is a Tacotron2-based framework but with a fine-grained text-based\nprosody predicting module and a speaker identity controller. Experiments\ndemonstrate that the proposed method can successfully express a style of one\nspeaker with the timber of another speaker bypassing the dependency on a single\nspeaker's multi-style corpus. Moreover, the explicit prosody features used in\nthe prosody predicting module can increase the diversity of synthetic speech by\nadjusting the value of prosody features.", "published": "2021-12-23 17:54:45", "link": "http://arxiv.org/abs/2112.12743v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
