{"title": "Sparse Coding of Neural Word Embeddings for Multilingual Sequence\n  Labeling", "abstract": "In this paper we propose and carefully evaluate a sequence labeling framework\nwhich solely utilizes sparse indicator features derived from dense distributed\nword representations. The proposed model obtains (near) state-of-the art\nperformance for both part-of-speech tagging and named entity recognition for a\nvariety of languages. Our model relies only on a few thousand sparse\ncoding-derived features, without applying any modification of the word\nrepresentations employed for the different tasks. The proposed model has\nfavorable generalization properties as it retains over 89.8% of its average POS\ntagging accuracy when trained at 1.2% of the total available training data,\ni.e.~150 sentences per language.", "published": "2016-12-21 14:17:53", "link": "http://arxiv.org/abs/1612.07130v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Inverted Bilingual Topic Models for Lexicon Extraction from Non-parallel\n  Data", "abstract": "Topic models have been successfully applied in lexicon extraction. However,\nmost previous methods are limited to document-aligned data. In this paper, we\ntry to address two challenges of applying topic models to lexicon extraction in\nnon-parallel data: 1) hard to model the word relationship and 2) noisy seed\ndictionary. To solve these two challenges, we propose two new bilingual topic\nmodels to better capture the semantic information of each word while\ndiscriminating the multiple translations in a noisy seed dictionary. We extend\nthe scope of topic models by inverting the roles of \"word\" and \"document\". In\naddition, to solve the problem of noise in seed dictionary, we incorporate the\nprobability of translation selection in our models. Moreover, we also propose\nan effective measure to evaluate the similarity of words in different languages\nand select the optimal translation pairs. Experimental results using real world\ndata demonstrate the utility and efficacy of the proposed models.", "published": "2016-12-21 16:12:45", "link": "http://arxiv.org/abs/1612.07215v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A deep learning approach for predicting the quality of online health\n  expert question-answering services", "abstract": "Currently, a growing number of health consumers are asking health-related\nquestions online, at any time and from anywhere, which effectively lowers the\ncost of health care. The most common approach is using online health expert\nquestion-answering (HQA) services, as health consumers are more willing to\ntrust answers from professional physicians. However, these answers can be of\nvarying quality depending on circumstance. In addition, as the available HQA\nservices grow, how to predict the answer quality of HQA services via machine\nlearning becomes increasingly important and challenging. In an HQA service,\nanswers are normally short texts, which are severely affected by the data\nsparsity problem. Furthermore, HQA services lack community features such as\nbest answer and user votes. Therefore, the wisdom of the crowd is not available\nto rate answer quality. To address these problems, in this paper, the\nprediction of HQA answer quality is defined as a classification task. First,\nbased on the characteristics of HQA services and feedback from medical experts,\na standard for HQA service answer quality evaluation is defined. Next, based on\nthe characteristics of HQA services, several novel non-textual features are\nproposed, including surface linguistic features and social features. Finally, a\ndeep belief network (DBN)-based HQA answer quality prediction framework is\nproposed to predict the quality of answers by learning the high-level hidden\nsemantic representation from the physicians' answers. Our results prove that\nthe proposed framework overcomes the problem of overly sparse textual features\nin short text answers and effectively identifies high-quality answers.", "published": "2016-12-21 10:09:30", "link": "http://arxiv.org/abs/1612.07040v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Multi-Agent Cooperation and the Emergence of (Natural) Language", "abstract": "The current mainstream approach to train natural language systems is to\nexpose them to large amounts of text. This passive learning is problematic if\nwe are interested in developing interactive machines, such as conversational\nagents. We propose a framework for language learning that relies on multi-agent\ncommunication. We study this learning in the context of referential games. In\nthese games, a sender and a receiver see a pair of images. The sender is told\none of them is the target and is allowed to send a message from a fixed,\narbitrary vocabulary to the receiver. The receiver must rely on this message to\nidentify the target. Thus, the agents develop their own language interactively\nout of the need to communicate. We show that two networks with simple\nconfigurations are able to learn to coordinate in the referential game. We\nfurther explore how to make changes to the game environment to cause the \"word\nmeanings\" induced in the game to better reflect intuitive semantic properties\nof the images. In addition, we present a simple strategy for grounding the\nagents' code into natural language. Both of these are necessary steps towards\ndeveloping machines that are able to communicate with humans productively.", "published": "2016-12-21 15:27:06", "link": "http://arxiv.org/abs/1612.07182v2", "categories": ["cs.CL", "cs.CV", "cs.GT", "cs.LG", "cs.MA"], "primary_category": "cs.CL"}
