{"title": "Text Mining Customer Reviews For Aspect-based Restaurant Rating", "abstract": "This study applies text mining to analyze customer reviews and automatically\nassign a collective restaurant star rating based on five predetermined aspects:\nambiance, cost, food, hygiene, and service. The application provides a web and\nmobile crowd sourcing platform where users share dining experiences and get\ninsights about the strengths and weaknesses of a restaurant through user\ncontributed feedback. Text reviews are tokenized into sentences. Noun-adjective\npairs are extracted from each sentence using Stanford Core NLP library and are\nassociated to aspects based on the bag of associated words fed into the system.\nThe sentiment weight of the adjectives is determined through AFINN library. An\noverall restaurant star rating is computed based on the individual aspect\nrating. Further, a word cloud is generated to provide visual display of the\nmost frequently occurring terms in the reviews. The more feedbacks are added\nthe more reflective the sentiment score to the restaurants' performance.", "published": "2019-01-07 01:57:21", "link": "http://arxiv.org/abs/1901.01642v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Interactive Matching Network for Multi-Turn Response Selection in\n  Retrieval-Based Chatbots", "abstract": "In this paper, we propose an interactive matching network (IMN) for the\nmulti-turn response selection task. First, IMN constructs word representations\nfrom three aspects to address the challenge of out-of-vocabulary (OOV) words.\nSecond, an attentive hierarchical recurrent encoder (AHRE), which is capable of\nencoding sentences hierarchically and generating more descriptive\nrepresentations by aggregating with an attention mechanism, is designed.\nFinally, the bidirectional interactions between whole multi-turn contexts and\nresponse candidates are calculated to derive the matching information between\nthem. Experiments on four public datasets show that IMN outperforms the\nbaseline models on all metrics, achieving a new state-of-the-art performance\nand demonstrating compatibility across domains for multi-turn response\nselection.", "published": "2019-01-07 14:17:29", "link": "http://arxiv.org/abs/1901.01824v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Stance Classification for Rumour Analysis in Twitter: Exploiting\n  Affective Information and Conversation Structure", "abstract": "Analysing how people react to rumours associated with news in social media is\nan important task to prevent the spreading of misinformation, which is nowadays\nwidely recognized as a dangerous tendency. In social media conversations, users\nshow different stances and attitudes towards rumourous stories. Some users take\na definite stance, supporting or denying the rumour at issue, while others just\ncomment it, or ask for additional evidence related to the veracity of the\nrumour. On this line, a new shared task has been proposed at SemEval-2017 (Task\n8, SubTask A), which is focused on rumour stance classification in English\ntweets. The goal is predicting user stance towards emerging rumours in Twitter,\nin terms of supporting, denying, querying, or commenting the original rumour,\nlooking at the conversation threads originated by the rumour. This paper\ndescribes a new approach to this task, where the use of conversation-based and\naffective-based features, covering different facets of affect, has been\nexplored. Our classification model outperforms the best-performing systems for\nstance classification at SemEval-2017 Task 8, showing the effectiveness of the\nfeature set proposed.", "published": "2019-01-07 16:38:16", "link": "http://arxiv.org/abs/1901.01911v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Vector representations of text data in deep learning", "abstract": "In this dissertation we report results of our research on dense distributed\nrepresentations of text data. We propose two novel neural models for learning\nsuch representations. The first model learns representations at the document\nlevel, while the second model learns word-level representations.\n  For document-level representations we propose Binary Paragraph Vector: a\nneural network models for learning binary representations of text documents,\nwhich can be used for fast document retrieval. We provide a thorough evaluation\nof these models and demonstrate that they outperform the seminal method in the\nfield in the information retrieval task. We also report strong results in\ntransfer learning settings, where our models are trained on a generic text\ncorpus and then used to infer codes for documents from a domain-specific\ndataset. In contrast to previously proposed approaches, Binary Paragraph Vector\nmodels learn embeddings directly from raw text data.\n  For word-level representations we propose Disambiguated Skip-gram: a neural\nnetwork model for learning multi-sense word embeddings. Representations learned\nby this model can be used in downstream tasks, like part-of-speech tagging or\nidentification of semantic relations. In the word sense induction task\nDisambiguated Skip-gram outperforms state-of-the-art models on three out of\nfour benchmarks datasets. Our model has an elegant probabilistic\ninterpretation. Furthermore, unlike previous models of this kind, it is\ndifferentiable with respect to all its parameters and can be trained with\nbackpropagation. In addition to quantitative results, we present qualitative\nevaluation of Disambiguated Skip-gram, including two-dimensional visualisations\nof selected word-sense embeddings.", "published": "2019-01-07 08:03:35", "link": "http://arxiv.org/abs/1901.01695v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Team EP at TAC 2018: Automating data extraction in systematic reviews of\n  environmental agents", "abstract": "We describe our entry for the Systematic Review Information Extraction track\nof the 2018 Text Analysis Conference. Our solution is an end-to-end, deep\nlearning, sequence tagging model based on the BI-LSTM-CRF architecture.\nHowever, we use interleaved, alternating LSTM layers with highway connections\ninstead of the more traditional approach, where last hidden states of both\ndirections are concatenated to create an input to the next layer. We also make\nextensive use of pre-trained word embeddings, namely GloVe and ELMo. Thanks to\na number of regularization techniques, we were able to achieve relatively large\ncapacity of the model (31.3M+ of trainable parameters) for the size of training\nset (100 documents, less than 200K tokens). The system's official score was\n60.9% (micro-F1) and it ranked first for the Task 1. Additionally, after\nrectifying an obvious mistake in the submission format, the system scored\n67.35%.", "published": "2019-01-07 21:49:51", "link": "http://arxiv.org/abs/1901.02081v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Sinusoidal wave generating network based on adversarial learning and its\n  application: synthesizing frog sounds for data augmentation", "abstract": "Simulators that generate observations based on theoretical models can be\nimportant tools for development, prediction, and assessment of signal\nprocessing algorithms. In order to design these simulators, painstaking effort\nis required to construct mathematical models according to their application.\nComplex models are sometimes necessary to represent a variety of real\nphenomena. In contrast, obtaining synthetic observations from generative models\ndeveloped from real observations often require much less effort. This paper\nproposes a generative model based on adversarial learning. Given that\nobservations are typically signals composed of a linear combination of\nsinusoidal waves and random noises, sinusoidal wave generating networks are\nfirst designed based on an adversarial network. Audio waveform generation can\nthen be performed using the proposed network. Several approaches to designing\nthe objective function of the proposed network using adversarial learning are\ninvestigated experimentally. In addition, amphibian sound classification is\nperformed using a convolutional neural network trained with real and synthetic\nsounds. Both qualitative and quantitative results show that the proposed\ngenerative model makes realistic signals and is very helpful for data\naugmentation and data analysis.", "published": "2019-01-07 20:23:56", "link": "http://arxiv.org/abs/1901.02050v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
