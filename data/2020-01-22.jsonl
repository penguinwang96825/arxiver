{"title": "TLT-school: a Corpus of Non Native Children Speech", "abstract": "This paper describes \"TLT-school\" a corpus of speech utterances collected in\nschools of northern Italy for assessing the performance of students learning\nboth English and German. The corpus was recorded in the years 2017 and 2018\nfrom students aged between nine and sixteen years, attending primary, middle\nand high school. All utterances have been scored, in terms of some predefined\nproficiency indicators, by human experts. In addition, most of utterances\nrecorded in 2017 have been manually transcribed carefully. Guidelines and\nprocedures used for manual transcriptions of utterances will be described in\ndetail, as well as results achieved by means of an automatic speech recognition\nsystem developed by us. Part of the corpus is going to be freely distributed to\nscientific community particularly interested both in non-native speech\nrecognition and automatic assessment of second language proficiency.", "published": "2020-01-22 15:14:09", "link": "http://arxiv.org/abs/2001.08051v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual Denoising Pre-training for Neural Machine Translation", "abstract": "This paper demonstrates that multilingual denoising pre-training produces\nsignificant performance gains across a wide variety of machine translation (MT)\ntasks. We present mBART -- a sequence-to-sequence denoising auto-encoder\npre-trained on large-scale monolingual corpora in many languages using the BART\nobjective. mBART is one of the first methods for pre-training a complete\nsequence-to-sequence model by denoising full texts in multiple languages, while\nprevious approaches have focused only on the encoder, decoder, or\nreconstructing parts of the text. Pre-training a complete model allows it to be\ndirectly fine tuned for supervised (both sentence-level and document-level) and\nunsupervised machine translation, with no task-specific modifications. We\ndemonstrate that adding mBART initialization produces performance gains in all\nbut the highest-resource settings, including up to 12 BLEU points for low\nresource MT and over 5 BLEU points for many document-level and unsupervised\nmodels. We also show it also enables new types of transfer to language pairs\nwith no bi-text or that were not in the pre-training corpus, and present\nextensive analysis of which factors contribute the most to effective\npre-training.", "published": "2020-01-22 18:59:17", "link": "http://arxiv.org/abs/2001.08210v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Elephant in the Room: An Evaluation Framework for Assessing Adversarial\n  Examples in NLP", "abstract": "An adversarial example is an input transformed by small perturbations that\nmachine learning models consistently misclassify. While there are a number of\nmethods proposed to generate adversarial examples for text data, it is not\ntrivial to assess the quality of these adversarial examples, as minor\nperturbations (such as changing a word in a sentence) can lead to a significant\nshift in their meaning, readability and classification label. In this paper, we\npropose an evaluation framework consisting of a set of automatic evaluation\nmetrics and human evaluation guidelines, to rigorously assess the quality of\nadversarial examples based on the aforementioned properties. We experiment with\nsix benchmark attacking methods and found that some methods generate\nadversarial examples with poor readability and content preservation. We also\nlearned that multiple factors could influence the attacking performance, such\nas the length of the text inputs and architecture of the classifiers.", "published": "2020-01-22 00:05:45", "link": "http://arxiv.org/abs/2001.07820v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Normalization of Input-output Shared Embeddings in Text Generation\n  Models", "abstract": "Neural Network based models have been state-of-the-art models for various\nNatural Language Processing tasks, however, the input and output dimension\nproblem in the networks has still not been fully resolved, especially in text\ngeneration tasks (e.g. Machine Translation, Text Summarization), in which input\nand output both have huge sizes of vocabularies. Therefore, input-output\nembedding weight sharing has been introduced and adopted widely, which remains\nto be improved. Based on linear algebra and statistical theories, this paper\nlocates the shortcoming of existed input-output embedding weight sharing\nmethod, then raises methods for improving input-output weight shared embedding,\namong which methods of normalization of embedding weight matrices show best\nperformance. These methods are nearly computational cost-free, can get combined\nwith other embedding techniques, and show good effectiveness when applied on\nstate-of-the-art Neural Network models. For Transformer-big models, the\nnormalization techniques can get at best 0.6 BLEU improvement compared to the\noriginal version of model on WMT'16 En-De dataset, and similar BLEU\nimprovements on IWSLT 14' datasets. For DynamicConv models, 0.5 BLEU\nimprovement can be attained on WMT'16 En-De dataset, and 0.41 BLEU improvement\non IWSLT 14' De-En translation task is achieved.", "published": "2020-01-22 05:34:45", "link": "http://arxiv.org/abs/2001.07885v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ARAACOM: ARAbic Algerian Corpus for Opinion Mining", "abstract": "Nowadays, it is no more needed to do an enormous effort to distribute a lot\nof forms to thousands of people and collect them, then convert this from into\nelectronic format to track people opinion about some subjects. A lot of web\nsites can today reach a large spectrum with less effort. The majority of web\nsites suggest to their visitors to leave backups about their feeling of the\nsite or events. So, this makes for us a lot of data which need powerful mean to\nexploit. Opinion mining in the web becomes more and more an attracting task,\ndue the increasing need for individuals and societies to track the mood of\npeople against several subjects of daily life (sports, politics,\ntelevision,...). A lot of works in opinion mining was developed in western\nlanguages especially English, such works in Arabic language still very scarce.\nIn this paper, we propose our approach, for opinion mining in Arabic Algerian\nnews paper. CCS CONCEPTS $\\bullet$Information systems~Sentiment analysis\n$\\bullet$ Computing methodologies~Natural language processing", "published": "2020-01-22 13:45:34", "link": "http://arxiv.org/abs/2001.08010v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Contextualized Embeddings in Named-Entity Recognition: An Empirical\n  Study on Generalization", "abstract": "Contextualized embeddings use unsupervised language model pretraining to\ncompute word representations depending on their context. This is intuitively\nuseful for generalization, especially in Named-Entity Recognition where it is\ncrucial to detect mentions never seen during training. However, standard\nEnglish benchmarks overestimate the importance of lexical over contextual\nfeatures because of an unrealistic lexical overlap between train and test\nmentions. In this paper, we perform an empirical analysis of the generalization\ncapabilities of state-of-the-art contextualized embeddings by separating\nmentions by novelty and with out-of-domain evaluation. We show that they are\nparticularly beneficial for unseen mentions detection, especially\nout-of-domain. For models trained on CoNLL03, language model contextualization\nleads to a +1.2% maximal relative micro-F1 score increase in-domain against\n+13% out-of-domain on the WNUT dataset", "published": "2020-01-22 15:15:34", "link": "http://arxiv.org/abs/2001.08053v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Simple Baseline to Semi-Supervised Domain Adaptation for Machine\n  Translation", "abstract": "State-of-the-art neural machine translation (NMT) systems are data-hungry and\nperform poorly on new domains with no supervised data. As data collection is\nexpensive and infeasible in many cases, domain adaptation methods are needed.\nIn this work, we propose a simple but effect approach to the semi-supervised\ndomain adaptation scenario of NMT, where the aim is to improve the performance\nof a translation model on the target domain consisting of only non-parallel\ndata with the help of supervised source domain data. This approach iteratively\ntrains a Transformer-based NMT model via three training objectives: language\nmodeling, back-translation, and supervised translation. We evaluate this method\non two adaptation settings: adaptation between specific domains and adaptation\nfrom a general domain to specific domains, and on two language pairs: German to\nEnglish and Romanian to English. With substantial performance improvement\nachieved---up to +19.31 BLEU over the strongest baseline, and +47.69 BLEU\nimprovement over the unadapted model---we present this method as a simple but\ntough-to-beat baseline in the field of semi-supervised domain adaptation for\nNMT.", "published": "2020-01-22 16:42:06", "link": "http://arxiv.org/abs/2001.08140v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unsupervised Representation Disentanglement using Cross Domain Features\n  and Adversarial Learning in Variational Autoencoder based Voice Conversion", "abstract": "An effective approach for voice conversion (VC) is to disentangle linguistic\ncontent from other components in the speech signal. The effectiveness of\nvariational autoencoder (VAE) based VC (VAE-VC), for instance, strongly relies\non this principle. In our prior work, we proposed a cross-domain VAE-VC\n(CDVAE-VC) framework, which utilized acoustic features of different properties,\nto improve the performance of VAE-VC. We believed that the success came from\nmore disentangled latent representations. In this paper, we extend the CDVAE-VC\nframework by incorporating the concept of adversarial learning, in order to\nfurther increase the degree of disentanglement, thereby improving the quality\nand similarity of converted speech. More specifically, we first investigate the\neffectiveness of incorporating the generative adversarial networks (GANs) with\nCDVAE-VC. Then, we consider the concept of domain adversarial training and add\nan explicit constraint to the latent representation, realized by a speaker\nclassifier, to explicitly eliminate the speaker information that resides in the\nlatent code. Experimental results confirm that the degree of disentanglement of\nthe learned latent representation can be enhanced by both GANs and the speaker\nclassifier. Meanwhile, subjective evaluation results in terms of quality and\nsimilarity scores demonstrate the effectiveness of our proposed methods.", "published": "2020-01-22 02:06:06", "link": "http://arxiv.org/abs/2001.07849v3", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "VoiceCoach: Interactive Evidence-based Training for Voice Modulation\n  Skills in Public Speaking", "abstract": "The modulation of voice properties, such as pitch, volume, and speed, is\ncrucial for delivering a successful public speech. However, it is challenging\nto master different voice modulation skills. Though many guidelines are\navailable, they are often not practical enough to be applied in different\npublic speaking situations, especially for novice speakers. We present\nVoiceCoach, an interactive evidence-based approach to facilitate the effective\ntraining of voice modulation skills. Specifically, we have analyzed the voice\nmodulation skills from 2623 high-quality speeches (i.e., TED Talks) and use\nthem as the benchmark dataset. Given a voice input, VoiceCoach automatically\nrecommends good voice modulation examples from the dataset based on the\nsimilarity of both sentence structures and voice modulation skills. Immediate\nand quantitative visual feedback is provided to guide further improvement. The\nexpert interviews and the user study provide support for the effectiveness and\nusability of VoiceCoach.", "published": "2020-01-22 04:52:06", "link": "http://arxiv.org/abs/2001.07876v1", "categories": ["cs.HC", "cs.CL", "cs.IR"], "primary_category": "cs.HC"}
{"title": "A Neural Architecture for Person Ontology population", "abstract": "A person ontology comprising concepts, attributes and relationships of people\nhas a number of applications in data protection, didentification, population of\nknowledge graphs for business intelligence and fraud prevention. While\nartificial neural networks have led to improvements in Entity Recognition,\nEntity Classification, and Relation Extraction, creating an ontology largely\nremains a manual process, because it requires a fixed set of semantic relations\nbetween concepts. In this work, we present a system for automatically\npopulating a person ontology graph from unstructured data using neural models\nfor Entity Classification and Relation Extraction. We introduce a new dataset\nfor these tasks and discuss our results.", "published": "2020-01-22 13:49:14", "link": "http://arxiv.org/abs/2001.08013v1", "categories": ["cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.AI"}
{"title": "ManyModalQA: Modality Disambiguation and QA over Diverse Inputs", "abstract": "We present a new multimodal question answering challenge, ManyModalQA, in\nwhich an agent must answer a question by considering three distinct modalities:\ntext, images, and tables. We collect our data by scraping Wikipedia and then\nutilize crowdsourcing to collect question-answer pairs. Our questions are\nambiguous, in that the modality that contains the answer is not easily\ndetermined based solely upon the question. To demonstrate this ambiguity, we\nconstruct a modality selector (or disambiguator) network, and this model gets\nsubstantially lower accuracy on our challenge set, compared to existing\ndatasets, indicating that our questions are more ambiguous. By analyzing this\nmodel, we investigate which words in the question are indicative of the\nmodality. Next, we construct a simple baseline ManyModalQA model, which, based\non the prediction from the modality selector, fires a corresponding pre-trained\nstate-of-the-art unimodal QA model. We focus on providing the community with a\nnew manymodal evaluation set and only provide a fine-tuning set, with the\nexpectation that existing datasets and approaches will be transferred for most\nof the training, to encourage low-resource generalization without large,\nmonolithic training sets for each new task. There is a significant gap between\nour baseline models and human performance; therefore, we hope that this\nchallenge encourages research in end-to-end modality disambiguation and\nmultimodal QA models, as well as transfer learning. Code and data available at:\nhttps://github.com/hannandarryl/ManyModalQA", "published": "2020-01-22 14:39:28", "link": "http://arxiv.org/abs/2001.08034v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Transition-Based Dependency Parsing using Perceptron Learner", "abstract": "Syntactic parsing using dependency structures has become a standard technique\nin natural language processing with many different parsing models, in\nparticular data-driven models that can be trained on syntactically annotated\ncorpora. In this paper, we tackle transition-based dependency parsing using a\nPerceptron Learner. Our proposed model, which adds more relevant features to\nthe Perceptron Learner, outperforms a baseline arc-standard parser. We beat the\nUAS of the MALT and LSTM parsers. We also give possible ways to address parsing\nof non-projective trees.", "published": "2020-01-22 20:58:22", "link": "http://arxiv.org/abs/2001.08279v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Zero-Shot Activity Recognition with Videos", "abstract": "In this paper, we examined the zero-shot activity recognition task with the\nusage of videos. We introduce an auto-encoder based model to construct a\nmultimodal joint embedding space between the visual and textual manifolds. On\nthe visual side, we used activity videos and a state-of-the-art 3D\nconvolutional action recognition network to extract the features. On the\ntextual side, we worked with GloVe word embeddings. The zero-shot recognition\nresults are evaluated by top-n accuracy. Then, the manifold learning ability is\nmeasured by mean Nearest Neighbor Overlap. In the end, we provide an extensive\ndiscussion over the results and the future directions.", "published": "2020-01-22 16:33:10", "link": "http://arxiv.org/abs/2002.02265v1", "categories": ["cs.CV", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CV"}
{"title": "Non-Negative Matrix Factorization-Convolutional Neural Network (NMF-CNN)\n  For Sound Event Detection", "abstract": "The main scientific question of this year DCASE challenge, Task 4 - Sound\nEvent Detection in Domestic Environments, is to investigate the types of data\n(strongly labeled synthetic data, weakly labeled data, unlabeled in domain\ndata) required to achieve the best performing system. In this paper, we\nproposed a deep learning model that integrates Non-Negative Matrix\nFactorization (NMF) with Convolutional Neural Network (CNN). The key idea of\nsuch integration is to use NMF to provide an approximate strong label to the\nweakly labeled data. Such integration was able to achieve a higher event-based\nF1-score as compared to the baseline system (Evaluation Dataset: 30.39% vs.\n23.7%, Validation Dataset: 31% vs. 25.8%). By comparing the validation results\nwith other participants, the proposed system was ranked 8th among 19 teams\n(inclusive of the baseline system) in this year Task 4 challenge.", "published": "2020-01-22 04:24:08", "link": "http://arxiv.org/abs/2001.07874v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
