{"title": "Neural Machine Translation with Supervised Attention", "abstract": "The attention mechanisim is appealing for neural machine translation, since\nit is able to dynam- ically encode a source sentence by generating a alignment\nbetween a target word and source words. Unfortunately, it has been proved to be\nworse than conventional alignment models in aligment accuracy. In this paper,\nwe analyze and explain this issue from the point view of re- ordering, and\npropose a supervised attention which is learned with guidance from conventional\nalignment models. Experiments on two Chinese-to-English translation tasks show\nthat the super- vised attention mechanism yields better alignments leading to\nsubstantial gains over the standard attention based NMT.", "published": "2016-09-14 09:31:40", "link": "http://arxiv.org/abs/1609.04186v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Machine Transliteration: Preliminary Results", "abstract": "Machine transliteration is the process of automatically transforming the\nscript of a word from a source language to a target language, while preserving\npronunciation. Sequence to sequence learning has recently emerged as a new\nparadigm in supervised learning. In this paper a character-based\nencoder-decoder model has been proposed that consists of two Recurrent Neural\nNetworks. The encoder is a Bidirectional recurrent neural network that encodes\na sequence of symbols into a fixed-length vector representation, and the\ndecoder generates the target sequence using an attention-based recurrent neural\nnetwork. The encoder, the decoder and the attention mechanism are jointly\ntrained to maximize the conditional probability of a target sequence given a\nsource sequence. Our experiments on different datasets show that the proposed\nencoder-decoder model is able to achieve significantly higher transliteration\nquality over traditional statistical models.", "published": "2016-09-14 13:12:12", "link": "http://arxiv.org/abs/1609.04253v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transliteration in Any Language with Surrogate Languages", "abstract": "We introduce a method for transliteration generation that can produce\ntransliterations in every language. Where previous results are only as\nmultilingual as Wikipedia, we show how to use training data from Wikipedia as\nsurrogate training for any language. Thus, the problem becomes one of ranking\nWikipedia languages in order of suitability with respect to a target language.\nWe introduce several task-specific methods for ranking languages, and show that\nour approach is comparable to the oracle ceiling, and even outperforms it in\nsome cases.", "published": "2016-09-14 15:58:55", "link": "http://arxiv.org/abs/1609.04325v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient softmax approximation for GPUs", "abstract": "We propose an approximate strategy to efficiently train neural network based\nlanguage models over very large vocabularies. Our approach, called adaptive\nsoftmax, circumvents the linear dependency on the vocabulary size by exploiting\nthe unbalanced word distribution to form clusters that explicitly minimize the\nexpectation of computation time. Our approach further reduces the computational\ntime by exploiting the specificities of modern architectures and matrix-matrix\nvector operations, making it particularly suited for graphical processing\nunits. Our experiments carried out on standard benchmarks, such as EuroParl and\nOne Billion Word, show that our approach brings a large gain in efficiency over\nstandard approximations while achieving an accuracy close to that of the full\nsoftmax. The code of our method is available at\nhttps://github.com/facebookresearch/adaptive-softmax.", "published": "2016-09-14 15:15:08", "link": "http://arxiv.org/abs/1609.04309v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An Adaptive Psychoacoustic Model for Automatic Speech Recognition", "abstract": "Compared with automatic speech recognition (ASR), the human auditory system\nis more adept at handling noise-adverse situations, including environmental\nnoise and channel distortion. To mimic this adeptness, auditory models have\nbeen widely incorporated in ASR systems to improve their robustness. This paper\nproposes a novel auditory model which incorporates psychoacoustics and\notoacoustic emissions (OAEs) into ASR. In particular, we successfully implement\nthe frequency-dependent property of psychoacoustic models and effectively\nimprove resulting system performance. We also present a novel double-transform\nspectrum-analysis technique, which can qualitatively predict ASR performance\nfor different noise types. Detailed theoretical analysis is provided to show\nthe effectiveness of the proposed algorithm. Experiments are carried out on the\nAURORA2 database and show that the word recognition rate using our proposed\nfeature extraction method is significantly increased over the baseline. Given\nmodels trained with clean speech, our proposed method achieves up to 85.39%\nword recognition accuracy on noisy data.", "published": "2016-09-14 20:02:42", "link": "http://arxiv.org/abs/1609.04417v1", "categories": ["cs.CL", "cs.SD"], "primary_category": "cs.CL"}
