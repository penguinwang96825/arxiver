{"title": "Morphological Constraints for Phrase Pivot Statistical Machine\n  Translation", "abstract": "The lack of parallel data for many language pairs is an important challenge\nto statistical machine translation (SMT). One common solution is to pivot\nthrough a third language for which there exist parallel corpora with the source\nand target languages. Although pivoting is a robust technique, it introduces\nsome low quality translations especially when a poor morphology language is\nused as the pivot between rich morphology languages. In this paper, we examine\nthe use of synchronous morphology constraint features to improve the quality of\nphrase pivot SMT. We compare hand-crafted constraints to those learned from\nlimited parallel data between source and target languages. The learned\nmorphology constraints are based on projected align- ments between the source\nand target phrases in the pivot phrase table. We show positive results on\nHebrew-Arabic SMT (pivoting on English). We get 1.5 BLEU points over a phrase\npivot baseline and 0.8 BLEU points over a system combination baseline with a\ndirect model built from parallel data.", "published": "2016-09-12 12:52:37", "link": "http://arxiv.org/abs/1609.03376v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Read, Tag, and Parse All at Once, or Fully-neural Dependency Parsing", "abstract": "We present a dependency parser implemented as a single deep neural network\nthat reads orthographic representations of words and directly generates\ndependencies and their labels. Unlike typical approaches to parsing, the model\ndoesn't require part-of-speech (POS) tagging of the sentences. With proper\nregularization and additional supervision achieved with multitask learning we\nreach state-of-the-art performance on Slavic languages from the Universal\nDependencies treebank: with no linguistic features other than characters, our\nparser is as accurate as a transition- based system trained on perfect POS\ntags.", "published": "2016-09-12 15:16:43", "link": "http://arxiv.org/abs/1609.03441v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge as a Teacher: Knowledge-Guided Structural Attention Networks", "abstract": "Natural language understanding (NLU) is a core component of a spoken dialogue\nsystem. Recently recurrent neural networks (RNN) obtained strong results on NLU\ndue to their superior ability of preserving sequential information over time.\nTraditionally, the NLU module tags semantic slots for utterances considering\ntheir flat structures, as the underlying RNN structure is a linear chain.\nHowever, natural language exhibits linguistic properties that provide rich,\nstructured information for better understanding. This paper introduces a novel\nmodel, knowledge-guided structural attention networks (K-SAN), a generalization\nof RNN to additionally incorporate non-flat network topologies guided by prior\nknowledge. There are two characteristics: 1) important substructures can be\ncaptured from small training data, allowing the model to generalize to\npreviously unseen test data; 2) the model automatically figures out the salient\nsubstructures that are essential to predict the semantic tags of the given\nsentences, so that the understanding performance can be improved. The\nexperiments on the benchmark Air Travel Information System (ATIS) data show\nthat the proposed K-SAN architecture can effectively extract salient knowledge\nfrom substructures with an attention mechanism, and outperform the performance\nof the state-of-the-art neural network based frameworks.", "published": "2016-09-12 07:29:59", "link": "http://arxiv.org/abs/1609.03286v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Modelling Creativity: Identifying Key Components through a Corpus-Based\n  Approach", "abstract": "Creativity is a complex, multi-faceted concept encompassing a variety of\nrelated aspects, abilities, properties and behaviours. If we wish to study\ncreativity scientifically, then a tractable and well-articulated model of\ncreativity is required. Such a model would be of great value to researchers\ninvestigating the nature of creativity and in particular, those concerned with\nthe evaluation of creative practice. This paper describes a unique approach to\ndeveloping a suitable model of how creative behaviour emerges that is based on\nthe words people use to describe the concept. Using techniques from the field\nof statistical natural language processing, we identify a collection of\nfourteen key components of creativity through an analysis of a corpus of\nacademic papers on the topic. Words are identified which appear significantly\noften in connection with discussions of the concept. Using a measure of lexical\nsimilarity to help cluster these words, a number of distinct themes emerge,\nwhich collectively contribute to a comprehensive and multi-perspective model of\ncreativity. The components provide an ontology of creativity: a set of building\nblocks which can be used to model creative practice in a variety of domains.\nThe components have been employed in two case studies to evaluate the\ncreativity of computational systems and have proven useful in articulating\nachievements of this work and directions for further research.", "published": "2016-09-12 11:58:59", "link": "http://arxiv.org/abs/1609.03357v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Microsoft 2016 Conversational Speech Recognition System", "abstract": "We describe Microsoft's conversational speech recognition system, in which we\ncombine recent developments in neural-network-based acoustic and language\nmodeling to advance the state of the art on the Switchboard recognition task.\nInspired by machine learning ensemble techniques, the system uses a range of\nconvolutional and recurrent neural networks. I-vector modeling and lattice-free\nMMI training provide significant gains for all acoustic model architectures.\nLanguage model rescoring with multiple forward and backward running RNNLMs, and\nword posterior-based system combination provide a 20% boost. The best single\nsystem uses a ResNet architecture acoustic model with RNNLM rescoring, and\nachieves a word error rate of 6.9% on the NIST 2000 Switchboard task. The\ncombined system has an error rate of 6.2%, representing an improvement over\npreviously reported results on this benchmark task.", "published": "2016-09-12 18:59:29", "link": "http://arxiv.org/abs/1609.03528v2", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Joint Extraction of Events and Entities within a Document Context", "abstract": "Events and entities are closely related; entities are often actors or\nparticipants in events and events without entities are uncommon. The\ninterpretation of events and entities is highly contextually dependent.\nExisting work in information extraction typically models events separately from\nentities, and performs inference at the sentence level, ignoring the rest of\nthe document. In this paper, we propose a novel approach that models the\ndependencies among variables of events, entities, and their relations, and\nperforms joint inference of these variables across a document. The goal is to\nenable access to document-level contextual information and facilitate\ncontext-aware predictions. We demonstrate that our approach substantially\noutperforms the state-of-the-art methods for event extraction as well as a\nstrong baseline for entity extraction.", "published": "2016-09-12 23:27:37", "link": "http://arxiv.org/abs/1609.03632v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
