{"title": "Decision Tree J48 at SemEval-2020 Task 9: Sentiment Analysis for\n  Code-Mixed Social Media Text (Hinglish)", "abstract": "This paper discusses the design of the system used for providing a solution\nfor the problem given at SemEval-2020 Task 9 where sentiment analysis of\ncode-mixed language Hindi and English needed to be performed. This system uses\nWeka as a tool for providing the classifier for the classification of tweets\nand python is used for loading the data from the files provided and cleaning\nit. Only part of the training data was provided to the system for classifying\nthe tweets in the test data set on which evaluation of the system was done. The\nsystem performance was assessed using the official competition evaluation\nmetric F1-score. Classifier was trained on two sets of training data which\nresulted in F1 scores of 0.4972 and 0.5316.", "published": "2020-08-26 06:30:43", "link": "http://arxiv.org/abs/2008.11398v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Machine learning approach of Japanese composition scoring and writing\n  aided system's design", "abstract": "Automatic scoring system is extremely complex for any language. Because\nnatural language itself is a complex model. When we evaluate articles generated\nby natural language, we need to view the articles from many dimensions such as\nword features, grammatical features, semantic features, text structure and so\non. Even human beings sometimes can't accurately grade a composition because\ndifferent people have different opinions about the same article. But a\ncomposition scoring system can greatly assist language learners. It can make\nlanguage leaner improve themselves in the process of output something. Though\nit is still difficult for machines to directly evaluate a composition at the\nsemantic and pragmatic levels, especially for Japanese, Chinese and other\nlanguage in high context cultures, we can make machine evaluate a passage in\nword and grammar levels, which can as an assistance of composition rater or\nlanguage learner. Especially for foreign language learners, lexical and\nsyntactic content are usually what they are more concerned about. In our\nexperiments, we did the follows works: 1) We use word segmentation tools and\ndictionaries to achieve word segmentation of an article, and extract word\nfeatures, as well as generate a words' complexity feature of an article. And\nBow technique are used to extract the theme features. 2) We designed a\nTuring-complete automata model and create 300+ automatons for the grammars that\nappear in the JLPT examination. And extract grammars features by using these\nautomatons. 3) We propose a statistical approach for scoring a specify theme of\ncomposition, the final score will depend on all the writings that submitted to\nthe system. 4) We design an grammar hint function for language leaner, so that\nthey can know currently what grammars they can use.", "published": "2020-08-26 11:01:13", "link": "http://arxiv.org/abs/2008.11488v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Inno at SemEval-2020 Task 11: Leveraging Pure Transformer for\n  Multi-Class Propaganda Detection", "abstract": "The paper presents the solution of team \"Inno\" to a SEMEVAL 2020 task 11\n\"Detection of propaganda techniques in news articles\". The goal of the second\nsubtask is to classify textual segments that correspond to one of the 18 given\npropaganda techniques in news articles dataset. We tested a pure\nTransformer-based model with an optimized learning scheme on the ability to\ndistinguish propaganda techniques between each other. Our model showed 0.6 and\n0.58 overall F1 score on validation set and test set accordingly and non-zero\nF1 score on each class on both sets.", "published": "2020-08-26 14:42:14", "link": "http://arxiv.org/abs/2008.11584v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analysis and Evaluation of Language Models for Word Sense Disambiguation", "abstract": "Transformer-based language models have taken many fields in NLP by storm.\nBERT and its derivatives dominate most of the existing evaluation benchmarks,\nincluding those for Word Sense Disambiguation (WSD), thanks to their ability in\ncapturing context-sensitive semantic nuances. However, there is still little\nknowledge about their capabilities and potential limitations in encoding and\nrecovering word senses. In this article, we provide an in-depth quantitative\nand qualitative analysis of the celebrated BERT model with respect to lexical\nambiguity. One of the main conclusions of our analysis is that BERT can\naccurately capture high-level sense distinctions, even when a limited number of\nexamples is available for each word sense. Our analysis also reveals that in\nsome cases language models come close to solving coarse-grained noun\ndisambiguation under ideal conditions in terms of availability of training data\nand computing resources. However, this scenario rarely occurs in real-world\nsettings and, hence, many practical challenges remain even in the\ncoarse-grained setting. We also perform an in-depth comparison of the two main\nlanguage model based WSD strategies, i.e., fine-tuning and feature extraction,\nfinding that the latter approach is more robust with respect to sense bias and\nit can better exploit limited available training data. In fact, the simple\nfeature extraction strategy of averaging contextualized embeddings proves\nrobust even using only three training sentences per word sense, with minimal\nimprovements obtained by increasing the size of this training data.", "published": "2020-08-26 15:07:07", "link": "http://arxiv.org/abs/2008.11608v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Optimality of Vagueness: \"Around\", \"Between\", and the Gricean\n  Maxims", "abstract": "Why is ordinary language vague? We argue that in contexts in which a\ncooperative speaker is not perfectly informed about the world, the use of vague\nexpressions can offer an optimal tradeoff between truthfulness (Gricean\nQuality) and informativeness (Gricean Quantity). Focusing on expressions of\napproximation such as \"around\", which are semantically vague, we show that they\nallow the speaker to convey indirect probabilistic information, in a way that\ncan give the listener a more accurate representation of the information\navailable to the speaker than any more precise expression would (intervals of\nthe form \"between\"). That is, vague sentences can be more informative than\ntheir precise counterparts. We give a probabilistic treatment of the\ninterpretation of \"around\", and offer a model for the interpretation and use of\n\"around\"-statements within the Rational Speech Act (RSA) framework. In our\naccount the shape of the speaker's distribution matters in ways not predicted\nby the Lexical Uncertainty model standardly used in the RSA framework for vague\npredicates. We use our approach to draw further lessons concerning the semantic\nflexibility of vague expressions and their irreducibility to more precise\nmeanings.", "published": "2020-08-26 21:57:25", "link": "http://arxiv.org/abs/2008.11841v4", "categories": ["cs.CL", "91F20, 62C10, 94-10, 94A17, 68T37"], "primary_category": "cs.CL"}
{"title": "Discrete Word Embedding for Logical Natural Language Understanding", "abstract": "We propose an unsupervised neural model for learning a discrete embedding of\nwords. Unlike existing discrete embeddings, our binary embedding supports\nvector arithmetic operations similar to continuous embeddings. Our embedding\nrepresents each word as a set of propositional statements describing a\ntransition rule in classical/STRIPS planning formalism. This makes the\nembedding directly compatible with symbolic, state of the art classical\nplanning solvers.", "published": "2020-08-26 16:15:18", "link": "http://arxiv.org/abs/2008.11649v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SHAP values for Explaining CNN-based Text Classification Models", "abstract": "Deep neural networks are increasingly used in natural language processing\n(NLP) models. However, the need to interpret and explain the results from\ncomplex algorithms are limiting their widespread adoption in regulated\nindustries such as banking. There has been recent work on interpretability of\nmachine learning algorithms with structured data. But there are only limited\ntechniques for NLP applications where the problem is more challenging due to\nthe size of the vocabulary, high-dimensional nature, and the need to consider\ntextual coherence and language structure. This paper develops a methodology to\ncompute SHAP values for local explainability of CNN-based text classification\nmodels. The approach is also extended to compute global scores to assess the\nimportance of features. The results are illustrated on sentiment analysis of\nAmazon Electronic Review data.", "published": "2020-08-26 21:28:41", "link": "http://arxiv.org/abs/2008.11825v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Item Tagging for Information Retrieval: A Tripartite Graph Neural\n  Network based Approach", "abstract": "Tagging has been recognized as a successful practice to boost relevance\nmatching for information retrieval (IR), especially when items lack rich\ntextual descriptions. A lot of research has been done for either multi-label\ntext categorization or image annotation. However, there is a lack of published\nwork that targets at item tagging specifically for IR. Directly applying a\ntraditional multi-label classification model for item tagging is sub-optimal,\ndue to the ignorance of unique characteristics in IR. In this work, we propose\nto formulate item tagging as a link prediction problem between item nodes and\ntag nodes. To enrich the representation of items, we leverage the query logs\navailable in IR tasks, and construct a query-item-tag tripartite graph. This\nformulation results in a TagGNN model that utilizes heterogeneous graph neural\nnetworks with multiple types of nodes and edges. Different from previous\nresearch, we also optimize both full tag prediction and partial tag completion\ncases in a unified framework via a primary-dual loss mechanism. Experimental\nresults on both open and industrial datasets show that our TagGNN approach\noutperforms the state-of-the-art multi-label classification approaches.", "published": "2020-08-26 13:58:19", "link": "http://arxiv.org/abs/2008.11567v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Multi-Label Sentiment Analysis on 100 Languages with Dynamic Weighting\n  for Label Imbalance", "abstract": "We investigate cross-lingual sentiment analysis, which has attracted\nsignificant attention due to its applications in various areas including market\nresearch, politics and social sciences. In particular, we introduce a sentiment\nanalysis framework in multi-label setting as it obeys Plutchik wheel of\nemotions. We introduce a novel dynamic weighting method that balances the\ncontribution from each class during training, unlike previous static weighting\nmethods that assign non-changing weights based on their class frequency.\nMoreover, we adapt the focal loss that favors harder instances from\nsingle-label object recognition literature to our multi-label setting.\nFurthermore, we derive a method to choose optimal class-specific thresholds\nthat maximize the macro-f1 score in linear time complexity. Through an\nextensive set of experiments, we show that our method obtains the\nstate-of-the-art performance in 7 of 9 metrics in 3 different languages using a\nsingle model compared to the common baselines and the best-performing methods\nin the SemEval competition. We publicly share our code for our model, which can\nperform sentiment analysis in 100 languages, to facilitate further research.", "published": "2020-08-26 14:16:02", "link": "http://arxiv.org/abs/2008.11573v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Multitask Deep Learning Approach for User Depression Detection on Sina\n  Weibo", "abstract": "In recent years, due to the mental burden of depression, the number of people\nwho endanger their lives has been increasing rapidly. The online social network\n(OSN) provides researchers with another perspective for detecting individuals\nsuffering from depression. However, existing studies of depression detection\nbased on machine learning still leave relatively low classification\nperformance, suggesting that there is significant improvement potential for\nimprovement in their feature engineering. In this paper, we manually build a\nlarge dataset on Sina Weibo (a leading OSN with the largest number of active\nusers in the Chinese community), namely Weibo User Depression Detection Dataset\n(WU3D). It includes more than 20,000 normal users and more than 10,000\ndepressed users, both of which are manually labeled and rechecked by\nprofessionals. By analyzing the user's text, social behavior, and posted\npictures, ten statistical features are concluded and proposed. In the meantime,\ntext-based word features are extracted using the popular pretrained model\nXLNet. Moreover, a novel deep neural network classification model, i.e.\nFusionNet (FN), is proposed and simultaneously trained with the above-extracted\nfeatures, which are seen as multiple classification tasks. The experimental\nresults show that FusionNet achieves the highest F1-Score of 0.9772 on the test\ndataset. Compared to existing studies, our proposed method has better\nclassification performance and robustness for unbalanced training samples. Our\nwork also provides a new way to detect depression on other OSN platforms.", "published": "2020-08-26 17:53:17", "link": "http://arxiv.org/abs/2008.11708v1", "categories": ["cs.SI", "cs.CL", "cs.LG"], "primary_category": "cs.SI"}
{"title": "Understanding scholarly Natural Language Processing system diagrams\n  through application of the Richards-Engelhardt framework", "abstract": "We utilise Richards-Engelhardt framework as a tool for understanding Natural\nLanguage Processing systems diagrams. Through four examples from scholarly\nproceedings, we find that the application of the framework to this ecological\nand complex domain is effective for reflecting on these diagrams. We argue for\nvocabulary to describe multiple-codings, semiotic variability, and\ninconsistency or misuse of visual encoding principles in diagrams. Further, for\napplication to scholarly Natural Language Processing systems, and perhaps\nsystems diagrams more broadly, we propose the addition of \"Grouping by Object\"\nas a new visual encoding principle, and \"Emphasising\" as a new visual encoding\ntype.", "published": "2020-08-26 20:06:30", "link": "http://arxiv.org/abs/2008.11785v1", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "The Freesound Loop Dataset and Annotation Tool", "abstract": "Music loops are essential ingredients in electronic music production, and\nthere is a high demand for pre-recorded loops in a variety of styles. Several\ncommercial and community databases have been created to meet this demand, but\nmost are not suitable for research due to their strict licensing. We present\nthe Freesound Loop Dataset (FSLD), a new large-scale dataset of music loops\nannotated by experts. The loops originate from Freesound, a community database\nof audio recordings released under Creative Commons licenses, so the audio in\nour dataset may be redistributed. The annotations include instrument, tempo,\nmeter, key and genre tags. We describe the methodology used to assemble and\nannotate the data, and report on the distribution of tags in the data and\ninter-annotator agreement. We also present to the community an online loop\nannotator tool that we developed. To illustrate the usefulness of FSLD, we\npresent short case studies on using it to estimate tempo and key, generate\nmusic tracks, and evaluate a loop separation algorithm. We anticipate that the\ncommunity will find yet more uses for the data, in applications from automatic\nloop characterisation to algorithmic composition.", "published": "2020-08-26 12:10:07", "link": "http://arxiv.org/abs/2008.11507v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "TIV.lib: an open-source library for the tonal description of musical\n  audio", "abstract": "In this paper, we present TIV.lib, an open-source library for the\ncontent-based tonal description of musical audio signals. Its main novelty\nrelies on the perceptually-inspired Tonal Interval Vector space based on the\nDiscrete Fourier transform, from which multiple instantaneous and global\nrepresentations, descriptors and metrics are computed - e.g., harmonic change,\ndissonance, diatonicity, and musical key. The library is cross-platform,\nimplemented in Python and the graphical programming language Pure Data, and can\nbe used in both online and offline scenarios. Of note is its potential for\nenhanced Music Information Retrieval, where tonal descriptors sit at the core\nof numerous methods and applications.", "published": "2020-08-26 12:49:45", "link": "http://arxiv.org/abs/2008.11529v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "DeepVOX: Discovering Features from Raw Audio for Speaker Recognition in\n  Non-ideal Audio Signals", "abstract": "Automatic speaker recognition algorithms typically use pre-defined\nfilterbanks, such as Mel-Frequency and Gammatone filterbanks, for\ncharacterizing speech audio. However, it has been observed that the features\nextracted using these filterbanks are not resilient to diverse audio\ndegradations. In this work, we propose a deep learning-based technique to\ndeduce the filterbank design from vast amounts of speech audio. The purpose of\nsuch a filterbank is to extract features robust to non-ideal audio conditions,\nsuch as degraded, short duration, and multi-lingual speech. To this effect, a\n1D convolutional neural network is designed to learn a time-domain filterbank\ncalled DeepVOX directly from raw speech audio. Secondly, an adaptive triplet\nmining technique is developed to efficiently mine the data samples best suited\nto train the filterbank. Thirdly, a detailed ablation study of the DeepVOX\nfilterbanks reveals the presence of both vocal source and vocal tract\ncharacteristics in the extracted features. Experimental results on VOXCeleb2,\nNIST SRE 2008, 2010 and 2018, and Fisher speech datasets demonstrate the\nefficacy of the DeepVOX features across a variety of degraded, short duration,\nand multi-lingual speech. The DeepVOX features also shown to improve the\nperformance of existing speaker recognition algorithms, such as the\nxVector-PLDA and the iVector-PLDA.", "published": "2020-08-26 16:50:26", "link": "http://arxiv.org/abs/2008.11668v2", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Adversarially Training for Audio Classifiers", "abstract": "In this paper, we investigate the potential effect of the adversarially\ntraining on the robustness of six advanced deep neural networks against a\nvariety of targeted and non-targeted adversarial attacks. We firstly show that,\nthe ResNet-56 model trained on the 2D representation of the discrete wavelet\ntransform appended with the tonnetz chromagram outperforms other models in\nterms of recognition accuracy. Then we demonstrate the positive impact of\nadversarially training on this model as well as other deep architectures\nagainst six types of attack algorithms (white and black-box) with the cost of\nthe reduced recognition accuracy and limited adversarial perturbation. We run\nour experiments on two benchmarking environmental sound datasets and show that\nwithout any imposed limitations on the budget allocations for the adversary,\nthe fooling rate of the adversarially trained models can exceed 90\\%. In other\nwords, adversarial attacks exist in any scales, but they might require higher\nadversarial perturbations compared to non-adversarially trained models.", "published": "2020-08-26 15:15:32", "link": "http://arxiv.org/abs/2008.11618v2", "categories": ["eess.AS", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "FCN Approach for Dynamically Locating Multiple Speakers", "abstract": "In this paper, we present a deep neural network-based online multi-speaker\nlocalisation algorithm. Following the W-disjoint orthogonality principle in the\nspectral domain, each time-frequency (TF) bin is dominated by a single speaker,\nand hence by a single direction of arrival (DOA). A fully convolutional network\nis trained with instantaneous spatial features to estimate the DOA for each TF\nbin. The high resolution classification enables the network to accurately and\nsimultaneously localize and track multiple speakers, both static and dynamic.\nElaborated experimental study using both simulated and real-life recordings in\nstatic and dynamic scenarios, confirms that the proposed algorithm outperforms\nboth classic and recent deep-learning-based algorithms.", "published": "2020-08-26 22:21:29", "link": "http://arxiv.org/abs/2008.11845v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
