{"title": "No Need to Pay Attention: Simple Recurrent Neural Networks Work! (for\n  Answering \"Simple\" Questions)", "abstract": "First-order factoid question answering assumes that the question can be\nanswered by a single fact in a knowledge base (KB). While this does not seem\nlike a challenging task, many recent attempts that apply either complex\nlinguistic reasoning or deep neural networks achieve 65%-76% accuracy on\nbenchmark sets. Our approach formulates the task as two machine learning\nproblems: detecting the entities in the question, and classifying the question\nas one of the relation types in the KB. We train a recurrent neural network to\nsolve each problem. On the SimpleQuestions dataset, our approach yields\nsubstantial improvements over previously published results --- even neural\nnetworks based on much more complex architectures. The simplicity of our\napproach also has practical advantages, such as efficiency and modularity, that\nare valuable especially in an industry setting. In fact, we present a\npreliminary analysis of the performance of our model on real queries from\nComcast's X1 entertainment platform with millions of users every day.", "published": "2016-06-16 02:20:04", "link": "http://arxiv.org/abs/1606.05029v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text", "abstract": "We present the Stanford Question Answering Dataset (SQuAD), a new reading\ncomprehension dataset consisting of 100,000+ questions posed by crowdworkers on\na set of Wikipedia articles, where the answer to each question is a segment of\ntext from the corresponding reading passage. We analyze the dataset to\nunderstand the types of reasoning required to answer the questions, leaning\nheavily on dependency and constituency trees. We build a strong logistic\nregression model, which achieves an F1 score of 51.0%, a significant\nimprovement over a simple baseline (20%). However, human performance (86.8%) is\nmuch higher, indicating that the dataset presents a good challenge problem for\nfuture research.\n  The dataset is freely available at https://stanford-qa.com", "published": "2016-06-16 16:36:00", "link": "http://arxiv.org/abs/1606.05250v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Simpler Context-Dependent Logical Forms via Model Projections", "abstract": "We consider the task of learning a context-dependent mapping from utterances\nto denotations. With only denotations at training time, we must search over a\ncombinatorially large space of logical forms, which is even larger with\ncontext-dependent utterances. To cope with this challenge, we perform\nsuccessive projections of the full model onto simpler models that operate over\nequivalence classes of logical forms. Though less expressive, we find that\nthese simpler models are much faster and can be surprisingly effective.\nMoreover, they can be used to bootstrap the full model. Finally, we collected\nthree new context-dependent semantic parsing datasets, and develop a new\nleft-to-right parser.", "published": "2016-06-16 21:57:11", "link": "http://arxiv.org/abs/1606.05378v1", "categories": ["cs.CL", "I.2.6; I.2.7"], "primary_category": "cs.CL"}
{"title": "Spectral decomposition method of dialog state tracking via collective\n  matrix factorization", "abstract": "The task of dialog management is commonly decomposed into two sequential\nsubtasks: dialog state tracking and dialog policy learning. In an end-to-end\ndialog system, the aim of dialog state tracking is to accurately estimate the\ntrue dialog state from noisy observations produced by the speech recognition\nand the natural language understanding modules. The state tracking task is\nprimarily meant to support a dialog policy. From a probabilistic perspective,\nthis is achieved by maintaining a posterior distribution over hidden dialog\nstates composed of a set of context dependent variables. Once a dialog policy\nis learned, it strives to select an optimal dialog act given the estimated\ndialog state and a defined reward function. This paper introduces a novel\nmethod of dialog state tracking based on a bilinear algebric decomposition\nmodel that provides an efficient inference schema through collective matrix\nfactorization. We evaluate the proposed approach on the second Dialog State\nTracking Challenge (DSTC-2) dataset and we show that the proposed tracker gives\nencouraging results compared to the state-of-the-art trackers that participated\nin this standard benchmark. Finally, we show that the prediction schema is\ncomputationally efficient in comparison to the previous approaches.", "published": "2016-06-16 17:31:13", "link": "http://arxiv.org/abs/1606.05286v1", "categories": ["cs.CL", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Increasing the Interpretability of Recurrent Neural Networks Using\n  Hidden Markov Models", "abstract": "As deep neural networks continue to revolutionize various application\ndomains, there is increasing interest in making these powerful models more\nunderstandable and interpretable, and narrowing down the causes of good and bad\npredictions. We focus on recurrent neural networks (RNNs), state of the art\nmodels in speech recognition and translation. Our approach to increasing\ninterpretability is by combining an RNN with a hidden Markov model (HMM), a\nsimpler and more transparent model. We explore various combinations of RNNs and\nHMMs: an HMM trained on LSTM states; a hybrid model where an HMM is trained\nfirst, then a small LSTM is given HMM state distributions and trained to fill\nin gaps in the HMM's performance; and a jointly trained hybrid model. We find\nthat the LSTM and HMM learn complementary information about the features in the\ntext.", "published": "2016-06-16 19:13:52", "link": "http://arxiv.org/abs/1606.05320v2", "categories": ["stat.ML", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
