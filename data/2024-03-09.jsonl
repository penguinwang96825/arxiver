{"title": "FLAP: Flow-Adhering Planning with Constrained Decoding in LLMs", "abstract": "Planning is a crucial task for agents in task oriented dialogs (TODs). Human\nagents typically resolve user issues by following predefined workflows,\ndecomposing workflow steps into actionable items, and performing actions by\nexecuting APIs in order; all of which require reasoning and planning. With the\nrecent advances in LLMs, there have been increasing attempts to use them for\ntask planning and API usage. However, the faithfulness of the plans to\npredefined workflows and API dependencies, is not guaranteed with LLMs.\nMoreover, workflows in real life are often custom-defined and prone to changes;\nhence, adaptation is desirable. To study this, we propose the problem of\nfaithful planning in TODs that needs to resolve user intents by following\npredefined flows and preserving API dependencies. To solve this problem, we\npropose FLAP, a Flow-Adhering Planning algorithm based on constrained decoding\nwith lookahead heuristic for LLMs. Our algorithm alleviates the need for\nfinetuning LLMs using domain specific (plan/dependency) data, enables quick\nadaptation to predefined flows, and outperforms other decoding and\nprompting-based baselines. Further, our algorithm empowers smaller LLMs (7B) to\nperform at par larger LLMs (30B-40B).", "published": "2024-03-09 02:27:45", "link": "http://arxiv.org/abs/2403.05766v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ClinicalMamba: A Generative Clinical Language Model on Longitudinal\n  Clinical Notes", "abstract": "The advancement of natural language processing (NLP) systems in healthcare\nhinges on language model ability to interpret the intricate information\ncontained within clinical notes. This process often requires integrating\ninformation from various time points in a patient's medical history. However,\nmost earlier clinical language models were pretrained with a context length\nlimited to roughly one clinical document. In this study, We introduce\nClinicalMamba, a specialized version of the Mamba language model, pretrained on\na vast corpus of longitudinal clinical notes to address the unique linguistic\ncharacteristics and information processing needs of the medical domain.\nClinicalMamba, with 130 million and 2.8 billion parameters, demonstrates a\nsuperior performance in modeling clinical language across extended text lengths\ncompared to Mamba and clinical Llama. With few-shot learning, ClinicalMamba\nachieves notable benchmarks in speed and accuracy, outperforming existing\nclinical language models and general domain large models like GPT-4 in\nlongitudinal clinical notes information extraction tasks.", "published": "2024-03-09 04:58:25", "link": "http://arxiv.org/abs/2403.05795v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UniSparse: An Intermediate Language for General Sparse Format\n  Customization", "abstract": "The ongoing trend of hardware specialization has led to a growing use of\ncustom data formats when processing sparse workloads, which are typically\nmemory-bound. These formats facilitate optimized software/hardware\nimplementations by utilizing sparsity pattern- or target-aware data structures\nand layouts to enhance memory access latency and bandwidth utilization.\nHowever, existing sparse tensor programming models and compilers offer little\nor no support for productively customizing the sparse formats. Additionally,\nbecause these frameworks represent formats using a limited set of per-dimension\nattributes, they lack the flexibility to accommodate numerous new variations of\ncustom sparse data structures and layouts. To overcome this deficiency, we\npropose UniSparse, an intermediate language that provides a unified abstraction\nfor representing and customizing sparse formats. Unlike the existing\nattribute-based frameworks, UniSparse decouples the logical representation of\nthe sparse tensor (i.e., the data structure) from its low-level memory layout,\nenabling the customization of both. As a result, a rich set of format\ncustomizations can be succinctly expressed in a small set of well-defined\nquery, mutation, and layout primitives. We also develop a compiler leveraging\nthe MLIR infrastructure, which supports adaptive customization of formats, and\nautomatic code generation of format conversion and compute operations for\nheterogeneous architectures. We demonstrate the efficacy of our approach\nthrough experiments running commonly-used sparse linear algebra operations with\nspecialized formats on multiple different hardware targets, including an Intel\nCPU, an NVIDIA GPU, an AMD Xilinx FPGA, and a simulated processing-in-memory\n(PIM) device.", "published": "2024-03-09 05:38:45", "link": "http://arxiv.org/abs/2403.05802v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KG-Rank: Enhancing Large Language Models for Medical QA with Knowledge\n  Graphs and Ranking Techniques", "abstract": "Large language models (LLMs) have demonstrated impressive generative\ncapabilities with the potential to innovate in medicine. However, the\napplication of LLMs in real clinical settings remains challenging due to the\nlack of factual consistency in the generated content. In this work, we develop\nan augmented LLM framework, KG-Rank, which leverages a medical knowledge graph\n(KG) along with ranking and re-ranking techniques, to improve the factuality of\nlong-form question answering (QA) in the medical domain. Specifically, when\nreceiving a question, KG-Rank automatically identifies medical entities within\nthe question and retrieves the related triples from the medical KG to gather\nfactual information. Subsequently, KG-Rank innovatively applies multiple\nranking techniques to refine the ordering of these triples, providing more\nrelevant and precise information for LLM inference. To the best of our\nknowledge, KG-Rank is the first application of KG combined with ranking models\nin medical QA specifically for generating long answers. Evaluation on four\nselected medical QA datasets demonstrates that KG-Rank achieves an improvement\nof over 18% in ROUGE-L score. Additionally, we extend KG-Rank to open domains,\nincluding law, business, music, and history, where it realizes a 14%\nimprovement in ROUGE-L score, indicating the effectiveness and great potential\nof KG-Rank.", "published": "2024-03-09 11:23:38", "link": "http://arxiv.org/abs/2403.05881v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MaiBaam Annotation Guidelines", "abstract": "This document provides the annotation guidelines for MaiBaam, a Bavarian\ncorpus manually annotated with part-of-speech (POS) tags, syntactic\ndependencies, and German lemmas. MaiBaam belongs to the Universal Dependencies\n(UD) project, and our annotations elaborate on the general and German UD\nversion 2 guidelines. In this document, we detail how to preprocess and\ntokenize Bavarian data, provide an overview of the POS tags and dependencies we\nuse, explain annotation decisions that would also apply to closely related\nlanguages like German, and lastly we introduce and motivate decisions that are\nspecific to Bavarian grammar.", "published": "2024-03-09 12:46:53", "link": "http://arxiv.org/abs/2403.05902v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Measuring Bias in a Ranked List using Term-based Representations", "abstract": "In most recent studies, gender bias in document ranking is evaluated with the\nNFaiRR metric, which measures bias in a ranked list based on an aggregation\nover the unbiasedness scores of each ranked document. This perspective in\nmeasuring the bias of a ranked list has a key limitation: individual documents\nof a ranked list might be biased while the ranked list as a whole balances the\ngroups' representations. To address this issue, we propose a novel metric\ncalled TExFAIR (term exposure-based fairness), which is based on two new\nextensions to a generic fairness evaluation framework, attention-weighted\nranking fairness (AWRF). TExFAIR assesses fairness based on the term-based\nrepresentation of groups in a ranked list: (i) an explicit definition of\nassociating documents to groups based on probabilistic term-level associations,\nand (ii) a rank-biased discounting factor (RBDF) for counting\nnon-representative documents towards the measurement of the fairness of a\nranked list. We assess TExFAIR on the task of measuring gender bias in passage\nranking, and study the relationship between TExFAIR and NFaiRR. Our experiments\nshow that there is no strong correlation between TExFAIR and NFaiRR, which\nindicates that TExFAIR measures a different dimension of fairness than NFaiRR.\nWith TExFAIR, we extend the AWRF framework to allow for the evaluation of\nfairness in settings with term-based representations of groups in documents in\na ranked list.", "published": "2024-03-09 18:24:58", "link": "http://arxiv.org/abs/2403.05975v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhanced Auto Language Prediction with Dictionary Capsule -- A Novel\n  Approach", "abstract": "The paper presents a novel Auto Language Prediction Dictionary Capsule\n(ALPDC) framework for language prediction and machine translation. The model\nuses a combination of neural networks and symbolic representations to predict\nthe language of a given input text and then translate it to a target language\nusing pre-built dictionaries. This research work also aims to translate the\ntext of various languages to its literal meaning in English. The proposed model\nachieves state-of-the-art results on several benchmark datasets and\nsignificantly improves translation accuracy compared to existing methods. The\nresults show the potential of the proposed method for practical use in\nmultilingual communication and natural language processing tasks.", "published": "2024-03-09 18:43:48", "link": "http://arxiv.org/abs/2403.05982v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploratory Data Analysis on Code-mixed Misogynistic Comments", "abstract": "The problems of online hate speech and cyberbullying have significantly\nworsened since the increase in popularity of social media platforms such as\nYouTube and Twitter (X). Natural Language Processing (NLP) techniques have\nproven to provide a great advantage in automatic filtering such toxic content.\nWomen are disproportionately more likely to be victims of online abuse.\nHowever, there appears to be a lack of studies that tackle misogyny detection\nin under-resourced languages. In this short paper, we present a novel dataset\nof YouTube comments in mix-code Hinglish collected from YouTube videos which\nhave been weak labelled as `Misogynistic' and `Non-misogynistic'.\nPre-processing and Exploratory Data Analysis (EDA) techniques have been applied\non the dataset to gain insights on its characteristics. The process has\nprovided a better understanding of the dataset through sentiment scores, word\nclouds, etc.", "published": "2024-03-09 23:21:17", "link": "http://arxiv.org/abs/2403.09709v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Benefits of Fine-Grained Loss Truncation: A Case Study on\n  Factuality in Summarization", "abstract": "Text summarization and simplification are among the most widely used\napplications of AI. However, models developed for such tasks are often prone to\nhallucination, which can result from training on unaligned data. One efficient\napproach to address this issue is Loss Truncation (LT) (Kang and Hashimoto,\n2020), an approach to modify the standard log loss to adaptively remove noisy\nexamples during training. However, we find that LT alone yields a considerable\nnumber of hallucinated entities on various datasets. We study the behavior of\nthe underlying losses between factual and non-factual examples, to understand\nand refine the performance of LT. We demonstrate that LT's performance is\nlimited when the underlying assumption that noisy targets have higher NLL loss\nis not satisfied, and find that word-level NLL among entities provides better\nsignal for distinguishing factuality. We then leverage this to propose a\nfine-grained NLL loss and fine-grained data cleaning strategies, and observe\nimprovements in hallucination reduction across some datasets. Our work is\navailable at https://https://github.com/yale-nlp/fine-grained-lt.", "published": "2024-03-09 04:20:26", "link": "http://arxiv.org/abs/2403.05788v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ItD: Large Language Models Can Teach Themselves Induction through\n  Deduction", "abstract": "Although Large Language Models (LLMs) are showing impressive performance on a\nwide range of Natural Language Processing tasks, researchers have found that\nthey still have limited ability to conduct induction. Recent works mainly adopt\n``post processes'' paradigms to improve the performance of LLMs on induction\n(e.g., the hypothesis search & refinement methods), but their performance is\nstill constrained by the inherent inductive capability of the LLMs. In this\npaper, we propose a novel framework, Induction through Deduction (ItD), to\nenable the LLMs to teach themselves induction through deduction. The ItD\nframework is composed of two main components: a Deductive Data Generation\nmodule to generate induction data and a Naive Bayesian Induction module to\noptimize the fine-tuning and decoding of LLMs. Our empirical results showcase\nthe effectiveness of ItD on two induction benchmarks, achieving relative\nperformance improvement of 36% and 10% compared with previous state-of-the-art,\nrespectively. Our ablation study verifies the effectiveness of two key modules\nof ItD. We also verify the effectiveness of ItD across different LLMs and\ndeductors. The data and code of this paper can be found at\nhttps://anonymous.4open.science/r/ItD-E844.", "published": "2024-03-09 04:20:46", "link": "http://arxiv.org/abs/2403.05789v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Algorithmic progress in language models", "abstract": "We investigate the rate at which algorithms for pre-training language models\nhave improved since the advent of deep learning. Using a dataset of over 200\nlanguage model evaluations on Wikitext and Penn Treebank spanning 2012-2023, we\nfind that the compute required to reach a set performance threshold has halved\napproximately every 8 months, with a 95% confidence interval of around 5 to 14\nmonths, substantially faster than hardware gains per Moore's Law. We estimate\naugmented scaling laws, which enable us to quantify algorithmic progress and\ndetermine the relative contributions of scaling models versus innovations in\ntraining algorithms. Despite the rapid pace of algorithmic progress and the\ndevelopment of new architectures such as the transformer, our analysis reveals\nthat the increase in compute made an even larger contribution to overall\nperformance improvements over this time period. Though limited by noisy\nbenchmark data, our analysis quantifies the rapid progress in language\nmodeling, shedding light on the relative contributions from compute and\nalgorithms.", "published": "2024-03-09 06:26:21", "link": "http://arxiv.org/abs/2403.05812v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging\n  Knowledge Graphs", "abstract": "Despite advancements in on-topic dialogue systems, effectively managing topic\nshifts within dialogues remains a persistent challenge, largely attributed to\nthe limited availability of training datasets. To address this issue, we\npropose Multi-Passage to Dialogue (MP2D), a data generation framework that\nautomatically creates conversational question-answering datasets with natural\ntopic transitions. By leveraging the relationships between entities in a\nknowledge graph, MP2D maps the flow of topics within a dialogue, effectively\nmirroring the dynamics of human conversation. It retrieves relevant passages\ncorresponding to the topics and transforms them into dialogues through the\npassage-to-dialogue method. Through quantitative and qualitative experiments,\nwe demonstrate MP2D's efficacy in generating dialogue with natural topic\nshifts. Furthermore, this study introduces a novel benchmark for topic shift\ndialogues, TS-WikiDialog. Utilizing the dataset, we demonstrate that even Large\nLanguage Models (LLMs) struggle to handle topic shifts in dialogue effectively,\nand we showcase the performance improvements of models trained on datasets\ngenerated by MP2D across diverse topic shift dialogue tasks.", "published": "2024-03-09 06:28:48", "link": "http://arxiv.org/abs/2403.05814v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Reverse That Number! Decoding Order Matters in Arithmetic Learning", "abstract": "Recent advancements in pretraining have demonstrated that modern Large\nLanguage Models (LLMs) possess the capability to effectively learn arithmetic\noperations. However, despite acknowledging the significance of digit order in\narithmetic computation, current methodologies predominantly rely on sequential,\nstep-by-step approaches for teaching LLMs arithmetic, resulting in a conclusion\nwhere obtaining better performance involves fine-grained step-by-step.\nDiverging from this conventional path, our work introduces a novel strategy\nthat not only reevaluates the digit order by prioritizing output from the least\nsignificant digit but also incorporates a step-by-step methodology to\nsubstantially reduce complexity. We have developed and applied this method in a\ncomprehensive set of experiments. Compared to the previous state-of-the-art\n(SOTA) method, our findings reveal an overall improvement of in accuracy while\nrequiring only a third of the tokens typically used during training. For the\npurpose of facilitating replication and further research, we have made our code\nand dataset publicly available at\n\\url{https://anonymous.4open.science/r/RAIT-9FB7/}.", "published": "2024-03-09 09:04:53", "link": "http://arxiv.org/abs/2403.05845v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Diffusion Lens: Interpreting Text Encoders in Text-to-Image Pipelines", "abstract": "Text-to-image diffusion models (T2I) use a latent representation of a text\nprompt to guide the image generation process. However, the process by which the\nencoder produces the text representation is unknown. We propose the Diffusion\nLens, a method for analyzing the text encoder of T2I models by generating\nimages from its intermediate representations. Using the Diffusion Lens, we\nperform an extensive analysis of two recent T2I models. Exploring compound\nprompts, we find that complex scenes describing multiple objects are composed\nprogressively and more slowly compared to simple scenes; Exploring knowledge\nretrieval, we find that representation of uncommon concepts requires further\ncomputation compared to common concepts, and that knowledge retrieval is\ngradual across layers. Overall, our findings provide valuable insights into the\ntext encoder component in T2I pipelines.", "published": "2024-03-09 09:11:49", "link": "http://arxiv.org/abs/2403.05846v2", "categories": ["cs.CV", "cs.CL", "I.2.7; I.4.0"], "primary_category": "cs.CV"}
{"title": "High Throughput Phenotyping of Physician Notes with Large Language and\n  Hybrid NLP Models", "abstract": "Deep phenotyping is the detailed description of patient signs and symptoms\nusing concepts from an ontology. The deep phenotyping of the numerous physician\nnotes in electronic health records requires high throughput methods. Over the\npast thirty years, progress toward making high throughput phenotyping feasible.\nIn this study, we demonstrate that a large language model and a hybrid NLP\nmodel (combining word vectors with a machine learning classifier) can perform\nhigh throughput phenotyping on physician notes with high accuracy. Large\nlanguage models will likely emerge as the preferred method for high throughput\ndeep phenotyping of physician notes.", "published": "2024-03-09 14:02:59", "link": "http://arxiv.org/abs/2403.05920v1", "categories": ["cs.CL", "cs.AI", "I.2; J.2"], "primary_category": "cs.CL"}
{"title": "Thread Detection and Response Generation using Transformers with Prompt\n  Optimisation", "abstract": "Conversational systems are crucial for human-computer interaction, managing\ncomplex dialogues by identifying threads and prioritising responses. This is\nespecially vital in multi-party conversations, where precise identification of\nthreads and strategic response prioritisation ensure efficient dialogue\nmanagement. To address these challenges an end-to-end model that identifies\nthreads and prioritises their response generation based on the importance was\ndeveloped, involving a systematic decomposition of the problem into discrete\ncomponents - thread detection, prioritisation, and performance optimisation\nwhich was meticulously analysed and optimised. These refined components\nseamlessly integrate into a unified framework, in conversational systems.\nLlama2 7b is used due to its high level of generalisation but the system can be\nupdated with any open source Large Language Model(LLM). The computational\ncapabilities of the Llama2 model was augmented by using fine tuning methods and\nstrategic prompting techniques to optimise the model's performance, reducing\ncomputational time and increasing the accuracy of the model. The model achieves\nup to 10x speed improvement, while generating more coherent results compared to\nexisting models.", "published": "2024-03-09 14:50:20", "link": "http://arxiv.org/abs/2403.05931v1", "categories": ["cs.CL", "cs.LG", "I.2.7; I.2.6"], "primary_category": "cs.CL"}
{"title": "End-to-end solution for linked open data query logs analytics", "abstract": "Important advances in pillar domains are derived from exploiting query-logs\nwhich represents users interest and preferences. Deep understanding of users\nprovides useful knowledge which can influence strongly decision-making. In this\nwork, we want to extract valuable information from Linked Open Data (LOD)\nquery-logs. LOD logs have experienced significant growth due to the large\nexploitation of LOD datasets. However, exploiting these logs is a difficult\ntask because of their complex structure. Moreover, these logs suffer from many\nrisks related to their Quality and Provenance, impacting their trust. To tackle\nthese issues, we start by clearly defining the ecosystem of LOD query-logs.\nThen, we provide an end-to-end solution to exploit these logs. At the end, real\nLOD logs are used and a set of experiments are conducted to validate the\nproposed solution.", "published": "2024-03-09 21:29:40", "link": "http://arxiv.org/abs/2403.06016v1", "categories": ["cs.DB", "cs.CL"], "primary_category": "cs.DB"}
{"title": "Persian Slang Text Conversion to Formal and Deep Learning of Persian\n  Short Texts on Social Media for Sentiment Classification", "abstract": "The lack of a suitable tool for the analysis of conversational texts in the\nPersian language has made various analyses of these texts, including Sentiment\nAnalysis, difficult. In this research, we tried to make the understanding of\nthese texts easier for the machine by providing PSC, Persian Slang Converter, a\ntool for converting conversational texts into formal ones, and by using the\nmost up-to-date and best deep learning methods along with the PSC, the\nsentiment learning of short Persian language texts for the machine in a better\nway. be made More than 10 million unlabeled texts from various social networks\nand movie subtitles (as Conversational texts) and about 10 million news texts\n(as formal texts) have been used for training unsupervised models and formal\nimplementation of the tool. 60,000 texts from the comments of Instagram social\nnetwork users with positive, negative, and neutral labels are considered\nsupervised data for training the emotion classification model of short texts.\nUsing the formal tool, 57% of the words of the corpus of conversation were\nconverted. Finally, by using the formalizer, FastText model, and deep LSTM\nnetwork, an accuracy of 81.91 was obtained on the test data.", "published": "2024-03-09 22:18:26", "link": "http://arxiv.org/abs/2403.06023v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Institutional-Level Monitoring of Immune Checkpoint Inhibitor IrAEs\n  Using a Novel Natural Language Processing Algorithmic Pipeline", "abstract": "Background: Immune checkpoint inhibitors (ICIs) have revolutionized cancer\ntreatment but can result in severe immune-related adverse events (IrAEs).\nMonitoring IrAEs on a large scale is essential for personalized risk profiling\nand assisting in treatment decisions.\n  Methods: In this study, we conducted an analysis of clinical notes from\npatients who received ICIs at the Tel Aviv Sourasky Medical Center. By\nemploying a Natural Language Processing algorithmic pipeline, we systematically\nidentified seven common or severe IrAEs. We examined the utilization of\ncorticosteroids, treatment discontinuation rates following IrAEs, and\nconstructed survival curves to visualize the occurrence of adverse events\nduring treatment.\n  Results: Our analysis encompassed 108,280 clinical notes associated with\n1,635 patients who had undergone ICI therapy. The detected incidence of IrAEs\nwas consistent with previous reports, exhibiting substantial variation across\ndifferent ICIs. Treatment with corticosteroids varied depending on the specific\nIrAE, ranging from 17.3% for thyroiditis to 57.4% for myocarditis. Our\nalgorithm demonstrated high accuracy in identifying IrAEs, as indicated by an\narea under the curve (AUC) of 0.89 for each suspected note and F1 scores of\n0.87 or higher for five out of the seven IrAEs examined at the patient level.\n  Conclusions: This study presents a novel, large-scale monitoring approach\nutilizing deep neural networks for IrAEs. Our method provides accurate results,\nenhancing understanding of detrimental consequences experienced by ICI-treated\npatients. Moreover, it holds potential for monitoring other medications,\nenabling comprehensive post-marketing surveillance to identify susceptible\npopulations and establish personalized drug safety profiles.", "published": "2024-03-09 19:18:27", "link": "http://arxiv.org/abs/2403.09708v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Decoding the AI Pen: Techniques and Challenges in Detecting AI-Generated\n  Text", "abstract": "Large Language Models (LLMs) have revolutionized the field of Natural\nLanguage Generation (NLG) by demonstrating an impressive ability to generate\nhuman-like text. However, their widespread usage introduces challenges that\nnecessitate thoughtful examination, ethical scrutiny, and responsible\npractices. In this study, we delve into these challenges, explore existing\nstrategies for mitigating them, with a particular emphasis on identifying\nAI-generated text as the ultimate solution. Additionally, we assess the\nfeasibility of detection from a theoretical perspective and propose novel\nresearch directions to address the current limitations in this domain.", "published": "2024-03-09 01:13:54", "link": "http://arxiv.org/abs/2403.05750v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Extending Activation Steering to Broad Skills and Multiple Behaviours", "abstract": "Current large language models have dangerous capabilities, which are likely\nto become more problematic in the future. Activation steering techniques can be\nused to reduce risks from these capabilities. In this paper, we investigate the\nefficacy of activation steering for broad skills and multiple behaviours.\nFirst, by comparing the effects of reducing performance on general coding\nability and Python-specific ability, we find that steering broader skills is\ncompetitive to steering narrower skills. Second, we steer models to become more\nor less myopic and wealth-seeking, among other behaviours. In our experiments,\ncombining steering vectors for multiple different behaviours into one steering\nvector is largely unsuccessful. On the other hand, injecting individual\nsteering vectors at different places in a model simultaneously is promising.", "published": "2024-03-09 02:30:04", "link": "http://arxiv.org/abs/2403.05767v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.LG"}
{"title": "An Audio-textual Diffusion Model For Converting Speech Signals Into\n  Ultrasound Tongue Imaging Data", "abstract": "Acoustic-to-articulatory inversion (AAI) is to convert audio into articulator\nmovements, such as ultrasound tongue imaging (UTI) data. An issue of existing\nAAI methods is only using the personalized acoustic information to derive the\ngeneral patterns of tongue motions, and thus the quality of generated UTI data\nis limited. To address this issue, this paper proposes an audio-textual\ndiffusion model for the UTI data generation task. In this model, the inherent\nacoustic characteristics of individuals related to the tongue motion details\nare encoded by using wav2vec 2.0, while the ASR transcriptions related to the\nuniversality of tongue motions are encoded by using BERT. UTI data are then\ngenerated by using a diffusion module. Experimental results showed that the\nproposed diffusion model could generate high-quality UTI data with clear tongue\ncontour that is crucial for the linguistic analysis and clinical assessment.\nThe project can be found on the\nwebsite\\footnote{https://yangyudong2020.github.io/wav2uti/", "published": "2024-03-09 06:59:47", "link": "http://arxiv.org/abs/2403.05820v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Calibrating Large Language Models Using Their Generations Only", "abstract": "As large language models (LLMs) are increasingly deployed in user-facing\napplications, building trust and maintaining safety by accurately quantifying a\nmodel's confidence in its prediction becomes even more important. However,\nfinding effective ways to calibrate LLMs - especially when the only interface\nto the models is their generated text - remains a challenge. We propose APRICOT\n(auxiliary prediction of confidence targets): A method to set confidence\ntargets and train an additional model that predicts an LLM's confidence based\non its textual input and output alone. This approach has several advantages: It\nis conceptually simple, does not require access to the target model beyond its\noutput, does not interfere with the language generation, and has a multitude of\npotential usages, for instance by verbalizing the predicted confidence or\nadjusting the given answer based on the confidence. We show how our approach\nperforms competitively in terms of calibration error for white-box and\nblack-box LLMs on closed-book question-answering to detect incorrect LLM\nanswers.", "published": "2024-03-09 17:46:24", "link": "http://arxiv.org/abs/2403.05973v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Few-Shot Cross-Lingual Transfer for Prompting Large Language Models in\n  Low-Resource Languages", "abstract": "Large pre-trained language models (PLMs) are at the forefront of advances in\nNatural Language Processing. One widespread use case of PLMs is \"prompting\" -\nor in-context learning - where a user provides a description of a task and some\ncompleted examples of the task to a PLM as context before prompting the PLM to\nperform the task on a new example. Only the largest, most capable PLMs are able\nto perform in-context learning effectively, and these models are typically\ntrained with a predominantly English corpus, leaving all other languages\nbehind. The data limitations in most languages preclude the training of\nlanguage-specific PLMs capable of prompting. Albeit the surge in work of\nprompting settings, it is still unclear how PLMs should be adapted\ncross-lingually specifically for prompting. We evaluate the possible methods to\nadapt LLaMa, a 7B parameter open-source PLM mainly trained in English, for\nprompting in low-resource languages, namely for Kinyarwanda, Hausa, and\nLuganda. We consider three methods: few-shot prompting (prompt),\nlanguage-adaptive fine-tuning (LAFT), and neural machine translation\n(translate), and evaluate on abstractive summarization, multi-class topic\nclassification, and named-entity recognition. Although LAFT carries the\ngreatest compute cost and intuitively should lead to the best results, our\nexperiments exhibit that LAFT is only occasionally the optimal choice for\nadapting PLMs for prompting. Rather, the translate and prompt settings are a\ncompute-efficient and cost-effective method of few-shot prompting for the\nselected low-resource languages. We find that the results are task and language\ndependent but find that the prompting method is the best on average across all\ntasks and languages. Results show that the prompt setting performs better than\nboth translating and LAFT with statistical significance for all shots when\naggregated across all tasks and languages.", "published": "2024-03-09 21:36:13", "link": "http://arxiv.org/abs/2403.06018v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AutoEval Done Right: Using Synthetic Data for Model Evaluation", "abstract": "The evaluation of machine learning models using human-labeled validation data\ncan be expensive and time-consuming. AI-labeled synthetic data can be used to\ndecrease the number of human annotations required for this purpose in a process\ncalled autoevaluation. We suggest efficient and statistically principled\nalgorithms for this purpose that improve sample efficiency while remaining\nunbiased. These algorithms increase the effective human-labeled sample size by\nup to 50% on experiments with GPT-4.", "published": "2024-03-09 02:47:11", "link": "http://arxiv.org/abs/2403.07008v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ME"], "primary_category": "cs.LG"}
{"title": "Schema-Aware Multi-Task Learning for Complex Text-to-SQL", "abstract": "Conventional text-to-SQL parsers are not good at synthesizing complex SQL\nqueries that involve multiple tables or columns, due to the challenges inherent\nin identifying the correct schema items and performing accurate alignment\nbetween question and schema items. To address the above issue, we present a\nschema-aware multi-task learning framework (named MTSQL) for complicated SQL\nqueries. Specifically, we design a schema linking discriminator module to\ndistinguish the valid question-schema linkings, which explicitly instructs the\nencoder by distinctive linking relations to enhance the alignment quality. On\nthe decoder side, we define 6-type relationships to describe the connections\nbetween tables and columns (e.g., WHERE_TC), and introduce an operator-centric\ntriple extractor to recognize those associated schema items with the predefined\nrelationship. Also, we establish a rule set of grammar constraints via the\npredicted triples to filter the proper SQL operators and schema items during\nthe SQL generation. On Spider, a cross-domain challenging text-to-SQL\nbenchmark, experimental results indicate that MTSQL is more effective than\nbaselines, especially in extremely hard scenarios. Moreover, further analyses\nverify that our approach leads to promising improvements for complicated SQL\nqueries.", "published": "2024-03-09 01:13:37", "link": "http://arxiv.org/abs/2403.09706v1", "categories": ["cs.CL", "cs.AI", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Understanding Social Perception, Interactions, and Safety Aspects of\n  Sidewalk Delivery Robots Using Sentiment Analysis", "abstract": "This article presents a comprehensive sentiment analysis (SA) of comments on\nYouTube videos related to Sidewalk Delivery Robots (SDRs). We manually\nannotated the collected YouTube comments with three sentiment labels: negative\n(0), positive (1), and neutral (2). We then constructed models for text\nsentiment classification and tested the models' performance on both binary and\nternary classification tasks in terms of accuracy, precision, recall, and F1\nscore. Our results indicate that, in binary classification tasks, the Support\nVector Machine (SVM) model using Term Frequency-Inverse Document Frequency\n(TF-IDF) and N-gram get the highest accuracy. In ternary classification tasks,\nthe model using Bidirectional Encoder Representations from Transformers (BERT),\nLong Short-Term Memory Networks (LSTM) and Gated Recurrent Unit (GRU)\nsignificantly outperforms other machine learning models, achieving an accuracy,\nprecision, recall, and F1 score of 0.78. Additionally, we employ the Latent\nDirichlet Allocation model to generate 10 topics from the comments to explore\nthe public's underlying views on SDRs. Drawing from these findings, we propose\ntargeted recommendations for shaping future policies concerning SDRs. This work\nprovides valuable insights for stakeholders in the SDR sector regarding social\nperception, interaction, and safety.", "published": "2024-03-09 23:28:01", "link": "http://arxiv.org/abs/2405.00688v1", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Aligning Speech to Languages to Enhance Code-switching Speech\n  Recognition", "abstract": "Code-switching (CS) refers to the switching of languages within a speech\nsignal and results in language confusion for automatic speech recognition\n(ASR). To address language confusion, we introduce a novel language alignment\nloss into ASR training to align acoustic features to pseudo-language labels\nlearned from the ASR decoder. This approach enables frame-level language\nidentification without the need for frame-level language annotations. To\nfurther tackle the complex token alternatives for language modeling in\nbilingual scenarios, we propose to employ large language models via a\ngenerative error correction method. A linguistic hint, which is derived from\nLAL outputs and decoded hypotheses, is introduced to guide the prompting and\nenhance the LLM-based generative error correction for CS-ASR. The proposed\nmethods are evaluated on the SEAME dataset and data from the ASRU 2019\nMandarin-English code-switching speech recognition challenge. The incorporation\nof the proposed language alignment loss improves the CS-ASR performance for\nboth hybrid CTC/attention and Whisper models on both datasets, with only a\nnegligible increase in the number of parameters. This work also highlights the\nefficacy of language alignment loss in balancing primary-language-dominant\nbilingual data during training, with an 8.6% relative improvement on the ASRU\ndataset compared to the baseline model. Performance evaluation using large\nlanguage models reveals the advantage of the linguistic hint by achieving 14.1%\nand 5.5% relative improvement on test sets of the ASRU and SEAME datasets,\nrespectively.", "published": "2024-03-09 11:59:10", "link": "http://arxiv.org/abs/2403.05887v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Asynchronous Microphone Array Calibration using Hybrid TDOA Information", "abstract": "Asynchronous microphone array calibration is a prerequisite for many audition\nrobot applications. A popular solution to the above calibration problem is the\nbatch form of Simultaneous Localisation and Mapping (SLAM), using the time\ndifference of arrival measurements between two microphones (TDOA-M), and the\nrobot (which serves as a moving sound source during calibration) odometry\ninformation. In this paper, we introduce a new form of measurement for\nmicrophone array calibration, i.e. the time difference of arrival between\nadjacent sound events (TDOA-S) with respect to the microphone channels. We\npropose to use TDOA-S and TDOA-M, called hybrid TDOA, together with odometry\nmeasurements for bath SLAM-based calibration of asynchronous microphone arrays.\nExtensive simulation and real-world experiments show that our method is more\nindependent of microphone number, less sensitive to initial values (when using\noff-the-shelf algorithms such as Gauss-Newton iterations), and has better\ncalibration accuracy and robustness under various TDOA noises. Simulation\nresults also demonstrate that our method has a lower Cram\\'er-Rao lower bound\n(CRLB) for microphone parameters. To benefit the community, we open-source our\ncode and data at https://github.com/AISLAB-sustech/Hybrid-TDOA-Calib.", "published": "2024-03-09 04:37:34", "link": "http://arxiv.org/abs/2403.05791v4", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "HAM-TTS: Hierarchical Acoustic Modeling for Token-Based Zero-Shot\n  Text-to-Speech with Model and Data Scaling", "abstract": "Token-based text-to-speech (TTS) models have emerged as a promising avenue\nfor generating natural and realistic speech, yet they grapple with low\npronunciation accuracy, speaking style and timbre inconsistency, and a\nsubstantial need for diverse training data. In response, we introduce a novel\nhierarchical acoustic modeling approach complemented by a tailored data\naugmentation strategy and train it on the combination of real and synthetic\ndata, scaling the data size up to 650k hours, leading to the zero-shot TTS\nmodel with 0.8B parameters. Specifically, our method incorporates a latent\nvariable sequence containing supplementary acoustic information based on\nrefined self-supervised learning (SSL) discrete units into the TTS model by a\npredictor. This significantly mitigates pronunciation errors and style\nmutations in synthesized speech. During training, we strategically replace and\nduplicate segments of the data to enhance timbre uniformity. Moreover, a\npretrained few-shot voice conversion model is utilized to generate a plethora\nof voices with identical content yet varied timbres. This facilitates the\nexplicit learning of utterance-level one-to-many mappings, enriching speech\ndiversity and also ensuring consistency in timbre. Comparative experiments\n(Demo page: https://anonymous.4open.science/w/ham-tts/)demonstrate our model's\nsuperiority over VALL-E in pronunciation precision and maintaining speaking\nstyle, as well as timbre continuity.", "published": "2024-03-09 19:05:48", "link": "http://arxiv.org/abs/2403.05989v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "sVAD: A Robust, Low-Power, and Light-Weight Voice Activity Detection\n  with Spiking Neural Networks", "abstract": "Speech applications are expected to be low-power and robust under noisy\nconditions. An effective Voice Activity Detection (VAD) front-end lowers the\ncomputational need. Spiking Neural Networks (SNNs) are known to be biologically\nplausible and power-efficient. However, SNN-based VADs have yet to achieve\nnoise robustness and often require large models for high performance. This\npaper introduces a novel SNN-based VAD model, referred to as sVAD, which\nfeatures an auditory encoder with an SNN-based attention mechanism.\nParticularly, it provides effective auditory feature representation through\nSincNet and 1D convolution, and improves noise robustness with attention\nmechanisms. The classifier utilizes Spiking Recurrent Neural Networks (sRNN) to\nexploit temporal speech information. Experimental results demonstrate that our\nsVAD achieves remarkable noise robustness and meanwhile maintains low power\nconsumption and a small footprint, making it a promising solution for\nreal-world VAD applications.", "published": "2024-03-09 02:55:44", "link": "http://arxiv.org/abs/2403.05772v1", "categories": ["cs.SD", "cs.NE", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Enhancing Expressiveness in Dance Generation via Integrating Frequency\n  and Music Style Information", "abstract": "Dance generation, as a branch of human motion generation, has attracted\nincreasing attention. Recently, a few works attempt to enhance dance\nexpressiveness, which includes genre matching, beat alignment, and dance\ndynamics, from certain aspects. However, the enhancement is quite limited as\nthey lack comprehensive consideration of the aforementioned three factors. In\nthis paper, we propose ExpressiveBailando, a novel dance generation method\ndesigned to generate expressive dances, concurrently taking all three factors\ninto account. Specifically, we mitigate the issue of speed homogenization by\nincorporating frequency information into VQ-VAE, thus improving dance dynamics.\nAdditionally, we integrate music style information by extracting genre- and\nbeat-related features with a pre-trained music model, hence achieving\nimprovements in the other two factors. Extensive experimental results\ndemonstrate that our proposed method can generate dances with high\nexpressiveness and outperforms existing methods both qualitatively and\nquantitatively.", "published": "2024-03-09 08:36:28", "link": "http://arxiv.org/abs/2403.05834v1", "categories": ["cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
