{"title": "Model Compression with Two-stage Multi-teacher Knowledge Distillation\n  for Web Question Answering System", "abstract": "Deep pre-training and fine-tuning models (such as BERT and OpenAI GPT) have\ndemonstrated excellent results in question answering areas. However, due to the\nsheer amount of model parameters, the inference speed of these models is very\nslow. How to apply these complex models to real business scenarios becomes a\nchallenging but practical problem. Previous model compression methods usually\nsuffer from information loss during the model compression procedure, leading to\ninferior models compared with the original one. To tackle this challenge, we\npropose a Two-stage Multi-teacher Knowledge Distillation (TMKD for short)\nmethod for web Question Answering system. We first develop a general Q\\&A\ndistillation task for student model pre-training, and further fine-tune this\npre-trained student model with multi-teacher knowledge distillation on\ndownstream tasks (like Web Q\\&A task, MNLI, SNLI, RTE tasks from GLUE), which\neffectively reduces the overfitting bias in individual teacher models, and\ntransfers more general knowledge to the student model. The experiment results\nshow that our method can significantly outperform the baseline methods and even\nachieve comparable results with the original teacher models, along with\nsubstantial speedup of model inference.", "published": "2019-10-18 12:36:52", "link": "http://arxiv.org/abs/1910.08381v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Controlling Utterance Length in NMT-based Word Segmentation with\n  Attention", "abstract": "One of the basic tasks of computational language documentation (CLD) is to\nidentify word boundaries in an unsegmented phonemic stream. While several\nunsupervised monolingual word segmentation algorithms exist in the literature,\nthey are challenged in real-world CLD settings by the small amount of available\ndata. A possible remedy is to take advantage of glosses or translation in a\nforeign, well-resourced, language, which often exist for such data. In this\npaper, we explore and compare ways to exploit neural machine translation models\nto perform unsupervised boundary detection with bilingual information, notably\nintroducing a new loss function for jointly learning alignment and\nsegmentation. We experiment with an actual under-resourced language, Mboshi,\nand show that these techniques can effectively control the output segmentation\nlength.", "published": "2019-10-18 13:44:16", "link": "http://arxiv.org/abs/1910.08418v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Using Local Knowledge Graph Construction to Scale Seq2Seq Models to\n  Multi-Document Inputs", "abstract": "Query-based open-domain NLP tasks require information synthesis from long and\ndiverse web results. Current approaches extractively select portions of web\ntext as input to Sequence-to-Sequence models using methods such as TF-IDF\nranking. We propose constructing a local graph structured knowledge base for\neach query, which compresses the web search information and reduces redundancy.\nWe show that by linearizing the graph into a structured input sequence, models\ncan encode the graph representations within a standard Sequence-to-Sequence\nsetting. For two generative tasks with very long text input, long-form question\nanswering and multi-document summarization, feeding graph representations as\ninput can achieve better performance than using retrieved text portions.", "published": "2019-10-18 14:23:03", "link": "http://arxiv.org/abs/1910.08435v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Concept Pointer Network for Abstractive Summarization", "abstract": "A quality abstractive summary should not only copy salient source texts as\nsummaries but should also tend to generate new conceptual words to express\nconcrete details. Inspired by the popular pointer generator\nsequence-to-sequence model, this paper presents a concept pointer network for\nimproving these aspects of abstractive summarization. The network leverages\nknowledge-based, context-aware conceptualizations to derive an extended set of\ncandidate concepts. The model then points to the most appropriate choice using\nboth the concept set and original source text. This joint approach generates\nabstractive summaries with higher-level semantic concepts. The training model\nis also optimized in a way that adapts to different data, which is based on a\nnovel method of distantly-supervised learning guided by reference summaries and\ntesting set. Overall, the proposed approach provides statistically significant\nimprovements over several state-of-the-art models on both the DUC-2004 and\nGigaword datasets. A human evaluation of the model's abstractive abilities also\nsupports the quality of the summaries produced within this framework.", "published": "2019-10-18 16:11:31", "link": "http://arxiv.org/abs/1910.08486v1", "categories": ["cs.CL", "68U15, 68T50"], "primary_category": "cs.CL"}
{"title": "Automatic Post-Editing for Machine Translation", "abstract": "Automatic Post-Editing (APE) aims to correct systematic errors in a machine\ntranslated text. This is primarily useful when the machine translation (MT)\nsystem is not accessible for improvement, leaving APE as a viable option to\nimprove translation quality as a downstream task - which is the focus of this\nthesis. This field has received less attention compared to MT due to several\nreasons, which include: the limited availability of data to perform a sound\nresearch, contrasting views reported by different researchers about the\neffectiveness of APE, and limited attention from the industry to use APE in\ncurrent production pipelines. In this thesis, we perform a thorough\ninvestigation of APE as a downstream task in order to: i) understand its\npotential to improve translation quality; ii) advance the core technology -\nstarting from classical methods to recent deep-learning based solutions; iii)\ncope with limited and sparse data; iv) better leverage multiple input sources;\nv) mitigate the task-specific problem of over-correction; vi) enhance neural\ndecoding to leverage external knowledge; and vii) establish an online learning\nframework to handle data diversity in real-time. All the above contributions\nare discussed across several chapters, and most of them are evaluated in the\nAPE shared task organized each year at the Conference on Machine Translation.\nOur efforts in improving the technology resulted in the best system at the 2017\nAPE shared task, and our work on online learning received a distinguished paper\naward at the Italian Conference on Computational Linguistics. Overall, outcomes\nand findings of our work have boost interest among researchers and attracted\nindustries to examine this technology to solve real-word problems.", "published": "2019-10-18 19:14:17", "link": "http://arxiv.org/abs/1910.08592v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Relational Graph Representation Learning for Open-Domain Question\n  Answering", "abstract": "We introduce a relational graph neural network with bi-directional attention\nmechanism and hierarchical representation learning for open-domain question\nanswering task. Our model can learn contextual representation by jointly\nlearning and updating the query, knowledge graph, and document representations.\nThe experiments suggest that our model achieves state-of-the-art on the\nWebQuestionsSP benchmark.", "published": "2019-10-18 03:54:58", "link": "http://arxiv.org/abs/1910.08249v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Entity Summarization: State of the Art and Future Challenges", "abstract": "The increasing availability of semantic data has substantially enhanced Web\napplications. Semantic data such as RDF data is commonly represented as\nentity-property-value triples. The magnitude of semantic data, in particular\nthe large number of triples describing an entity, could overload users with\nexcessive amounts of information. This has motivated fruitful research on\nautomated generation of summaries for entity descriptions to satisfy users'\ninformation needs efficiently and effectively. We focus on this prominent topic\nof entity summarization, and our research objective is to present the first\ncomprehensive survey of entity summarization research. Rather than separately\nreviewing each method, our contributions include (1) identifying and\nclassifying technical features of existing methods to form a high-level\noverview, (2) identifying and classifying frameworks for combining multiple\ntechnical features adopted by existing methods, (3) collecting known benchmarks\nfor intrinsic evaluation and efforts for extrinsic evaluation, and (4)\nsuggesting research directions for future work. By investigating the\nliterature, we synthesized two hierarchies of techniques. The first hierarchy\ncategories generic technical features into several perspectives: frequency and\ncentrality, informativeness, and diversity and coverage. In the second\nhierarchy we present domain-specific and task-specific technical features,\nincluding the use of domain knowledge, context awareness, and personalization.\nOur review demonstrated that existing methods are mainly unsupervised and they\ncombine multiple technical features using various frameworks: random surfer\nmodels, similarity-based grouping, MMR-like re-ranking, or combinatorial\noptimization. We also found a few deep learning based methods in recent\nresearch.", "published": "2019-10-18 04:02:33", "link": "http://arxiv.org/abs/1910.08252v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Towards Computing Inferences from English News Headlines", "abstract": "Newspapers are a popular form of written discourse, read by many people,\nthanks to the novelty of the information provided by the news content in it. A\nheadline is the most widely read part of any newspaper due to its appearance in\na bigger font and sometimes in colour print. In this paper, we suggest and\nimplement a method for computing inferences from English news headlines,\nexcluding the information from the context in which the headlines appear. This\nmethod attempts to generate the possible assumptions a reader formulates in\nmind upon reading a fresh headline. The generated inferences could be useful\nfor assessing the impact of the news headline on readers including children.\nThe understandability of the current state of social affairs depends greatly on\nthe assimilation of the headlines. As the inferences that are independent of\nthe context depend mainly on the syntax of the headline, dependency trees of\nheadlines are used in this approach, to find the syntactical structure of the\nheadlines and to compute inferences out of them.", "published": "2019-10-18 07:56:08", "link": "http://arxiv.org/abs/1910.08294v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Mutual Information Maximization Perspective of Language Representation\n  Learning", "abstract": "We show state-of-the-art word representation learning methods maximize an\nobjective function that is a lower bound on the mutual information between\ndifferent parts of a word sequence (i.e., a sentence). Our formulation provides\nan alternative perspective that unifies classical word embedding models (e.g.,\nSkip-gram) and modern contextual embeddings (e.g., BERT, XLNet). In addition to\nenhancing our theoretical understanding of these methods, our derivation leads\nto a principled framework that can be used to construct new self-supervised\ntasks. We provide an example by drawing inspirations from related methods based\non mutual information maximization that have been successful in computer\nvision, and introduce a simple self-supervised objective that maximizes the\nmutual information between a global sentence representation and n-grams in the\nsentence. Our analysis offers a holistic view of representation learning\nmethods to transfer knowledge and translate progress across multiple domains\n(e.g., natural language processing, computer vision, audio processing).", "published": "2019-10-18 11:47:24", "link": "http://arxiv.org/abs/1910.08350v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "End-to-End Speech Recognition: A review for the French Language", "abstract": "Recently, end-to-end ASR based either on sequence-to-sequence networks or on\nthe CTC objective function gained a lot of interest from the community,\nachieving competitive results over traditional systems using robust but complex\npipelines. One of the main features of end-to-end systems, in addition to the\nability to free themselves from extra linguistic resources such as dictionaries\nor language models, is the capacity to model acoustic units such as characters,\nsubwords or directly words; opening up the capacity to directly translate\nspeech with different representations or levels of knowledge depending on the\ntarget language. In this paper we propose a review of the existing end-to-end\nASR approaches for the French language. We compare results to conventional\nstate-of-the-art ASR systems and discuss which units are more suited to model\nthe French language.", "published": "2019-10-18 16:52:01", "link": "http://arxiv.org/abs/1910.08502v2", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "RTFM: Generalising to Novel Environment Dynamics via Reading", "abstract": "Obtaining policies that can generalise to new environments in reinforcement\nlearning is challenging. In this work, we demonstrate that language\nunderstanding via a reading policy learner is a promising vehicle for\ngeneralisation to new environments. We propose a grounded policy learning\nproblem, Read to Fight Monsters (RTFM), in which the agent must jointly reason\nover a language goal, relevant dynamics described in a document, and\nenvironment observations. We procedurally generate environment dynamics and\ncorresponding language descriptions of the dynamics, such that agents must read\nto understand new environment dynamics instead of memorising any particular\ninformation. In addition, we propose txt2$\\pi$, a model that captures three-way\ninteractions between the goal, document, and observations. On RTFM, txt2$\\pi$\ngeneralises to new environments with dynamics not seen during training via\nreading. Furthermore, our model outperforms baselines such as FiLM and\nlanguage-conditioned CNNs on RTFM. Through curriculum learning, txt2$\\pi$\nproduces policies that excel on complex RTFM tasks requiring several reasoning\nand coreference steps.", "published": "2019-10-18 00:49:15", "link": "http://arxiv.org/abs/1910.08210v6", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning to Answer Subjective, Specific Product-Related Queries using\n  Customer Reviews by Adversarial Domain Adaptation", "abstract": "Online customer reviews on large-scale e-commerce websites, represent a rich\nand varied source of opinion data, often providing subjective qualitative\nassessments of product usage that can help potential customers to discover\nfeatures that meet their personal needs and preferences. Thus they have the\npotential to automatically answer specific queries about products, and to\naddress the problems of answer starvation and answer augmentation on associated\nconsumer Q & A forums, by providing good answer alternatives. In this work, we\nexplore several recently successful neural approaches to modeling sentence\npairs, that could better learn the relationship between questions and ground\ntruth answers, and thus help infer reviews that can best answer a question or\naugment a given answer. In particular, we hypothesize that our adversarial\ndomain adaptation-based approach, due to its ability to additionally learn\ndomain-invariant features from a large number of unlabeled, unpaired\nquestion-review samples, would perform better than our proposed baselines, at\nanswering specific, subjective product-related queries using reviews. We\nvalidate this hypothesis using a small gold standard dataset of question-review\npairs evaluated by human experts, significantly surpassing our chosen\nbaselines. Moreover, our approach, using no labeled question-review sentence\npair data for training, gives performance at par with another method utilizing\nlabeled question-review samples for the same task.", "published": "2019-10-18 05:28:46", "link": "http://arxiv.org/abs/1910.08270v2", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unsupervised Context Rewriting for Open Domain Conversation", "abstract": "Context modeling has a pivotal role in open domain conversation. Existing\nworks either use heuristic methods or jointly learn context modeling and\nresponse generation with an encoder-decoder framework. This paper proposes an\nexplicit context rewriting method, which rewrites the last utterance by\nconsidering context history. We leverage pseudo-parallel data and elaborate a\ncontext rewriting network, which is built upon the CopyNet with the\nreinforcement learning method. The rewritten utterance is beneficial to\ncandidate retrieval, explainable context modeling, as well as enabling to\nemploy a single-turn framework to the multi-turn scenario. The empirical\nresults show that our model outperforms baselines in terms of the rewriting\nquality, the multi-turn response generation, and the end-to-end retrieval-based\nchatbots.", "published": "2019-10-18 06:49:55", "link": "http://arxiv.org/abs/1910.08282v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ALOHA: Artificial Learning of Human Attributes for Dialogue Agents", "abstract": "For conversational AI and virtual assistants to communicate with humans in a\nrealistic way, they must exhibit human characteristics such as expression of\nemotion and personality. Current attempts toward constructing human-like\ndialogue agents have presented significant difficulties. We propose Human Level\nAttributes (HLAs) based on tropes as the basis of a method for learning\ndialogue agents that can imitate the personalities of fictional characters.\nTropes are characteristics of fictional personalities that are observed\nrecurrently and determined by viewers' impressions. By combining detailed HLA\ndata with dialogue data for specific characters, we present a dataset,\nHLA-Chat, that models character profiles and gives dialogue agents the ability\nto learn characters' language styles through their HLAs. We then introduce a\nthree-component system, ALOHA (which stands for Artificial Learning of Human\nAttributes), that combines character space mapping, character community\ndetection, and language style retrieval to build a character (or personality)\nspecific language model. Our preliminary experiments demonstrate that two\nvariations of ALOHA, combined with our proposed dataset, can outperform\nbaseline models at identifying the correct dialogue responses of chosen target\ncharacters, and are stable regardless of the character's identity, the genre of\nthe show, and the context of the dialogue.", "published": "2019-10-18 07:52:01", "link": "http://arxiv.org/abs/1910.08293v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Many Faces of Feature Importance: Comparing Built-in and Post-hoc\n  Feature Importance in Text Classification", "abstract": "Feature importance is commonly used to explain machine predictions. While\nfeature importance can be derived from a machine learning model with a variety\nof methods, the consistency of feature importance via different methods remains\nunderstudied. In this work, we systematically compare feature importance from\nbuilt-in mechanisms in a model such as attention values and post-hoc methods\nthat approximate model behavior such as LIME. Using text classification as a\ntestbed, we find that 1) no matter which method we use, important features from\ntraditional models such as SVM and XGBoost are more similar with each other,\nthan with deep learning models; 2) post-hoc methods tend to generate more\nsimilar important features for two models than built-in methods. We further\ndemonstrate how such similarity varies across instances. Notably, important\nfeatures do not always resemble each other better when two models agree on the\npredicted label than when they disagree.", "published": "2019-10-18 17:59:59", "link": "http://arxiv.org/abs/1910.08534v1", "categories": ["cs.CL", "cs.CY", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Estimator Vectors: OOV Word Embeddings based on Subword and Context Clue\n  Estimates", "abstract": "Semantic representations of words have been successfully extracted from\nunlabeled corpuses using neural network models like word2vec. These\nrepresentations are generally high quality and are computationally inexpensive\nto train, making them popular. However, these approaches generally fail to\napproximate out of vocabulary (OOV) words, a task humans can do quite easily,\nusing word roots and context clues. This paper proposes a neural network model\nthat learns high quality word representations, subword representations, and\ncontext clue representations jointly. Learning all three types of\nrepresentations together enhances the learning of each, leading to enriched\nword vectors, along with strong estimates for OOV words, via the combination of\nthe corresponding context clue and subword embeddings. Our model, called\nEstimator Vectors (EV), learns strong word embeddings and is competitive with\nstate of the art methods for OOV estimation.", "published": "2019-10-18 06:17:07", "link": "http://arxiv.org/abs/1910.10491v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Towards Learning Cross-Modal Perception-Trace Models", "abstract": "Representation learning is a key element of state-of-the-art deep learning\napproaches. It enables to transform raw data into structured vector space\nembeddings. Such embeddings are able to capture the distributional semantics of\ntheir context, e.g. by word windows on natural language sentences, graph walks\non knowledge graphs or convolutions on images. So far, this context is manually\ndefined, resulting in heuristics which are solely optimized for computational\nperformance on certain tasks like link-prediction. However, such heuristic\nmodels of context are fundamentally different to how humans capture\ninformation. For instance, when reading a multi-modal webpage (i) humans do not\nperceive all parts of a document equally: Some words and parts of images are\nskipped, others are revisited several times which makes the perception trace\nhighly non-sequential; (ii) humans construct meaning from a document's content\nby shifting their attention between text and image, among other things, guided\nby layout and design elements. In this paper we empirically investigate the\ndifference between human perception and context heuristics of basic embedding\nmodels. We conduct eye tracking experiments to capture the underlying\ncharacteristics of human perception of media documents containing a mixture of\ntext and images. Based on that, we devise a prototypical computational\nperception-trace model, called CMPM. We evaluate empirically how CMPM can\nimprove a basic skip-gram embedding approach. Our results suggest, that even\nwith a basic human-inspired computational perception model, there is a huge\npotential for improving embeddings since such a model does inherently capture\nmultiple modalities, as well as layout and design elements.", "published": "2019-10-18 15:20:38", "link": "http://arxiv.org/abs/1910.08549v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Framework for the Robust Evaluation of Sound Event Detection", "abstract": "This work defines a new framework for performance evaluation of polyphonic\nsound event detection (SED) systems, which overcomes the limitations of the\nconventional collar-based event decisions, event F-scores and event error\nrates. The proposed framework introduces a definition of event detection that\nis more robust against labelling subjectivity. It also resorts to polyphonic\nreceiver operating characteristic (ROC) curves to deliver more global insight\ninto system performance than F1-scores, and proposes a reduction of these\ncurves into a single polyphonic sound detection score (PSDS), which allows\nsystem comparison independently from operating points (OPs). The presented\nmethod also delivers better insight into data biases and classification\nstability across sound classes. Furthermore, it can be tuned to varying\napplications in order to match a variety of user experience requirements. The\nbenefits of the proposed approach are demonstrated by re-evaluating the\nbaseline and two of the top-performing systems from DCASE 2019 Task 4.", "published": "2019-10-18 14:32:20", "link": "http://arxiv.org/abs/1910.08440v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Indian EmoSpeech Command Dataset: A dataset for emotion based speech\n  recognition in the wild", "abstract": "Speech emotion analysis is an important task which further enables several\napplication use cases. The non-verbal sounds within speech utterances also play\na pivotal role in emotion analysis in speech. Due to the widespread use of\nsmartphones, it becomes viable to analyze speech commands captured using\nmicrophones for emotion understanding by utilizing on-device machine learning\nmodels. The non-verbal information includes the environment background sounds\ndescribing the type of surroundings, current situation and activities being\nperformed. In this work, we consider both verbal (speech commands) and\nnon-verbal sounds (background noises) within an utterance for emotion analysis\nin real-life scenarios. We create an indigenous dataset for this task namely\n\"Indian EmoSpeech Command Dataset\". It contains keywords with diverse emotions\nand background sounds, presented to explore new challenges in audio analysis.\nWe exhaustively compare with various baseline models for emotion analysis on\nspeech commands on several performance metrics. We demonstrate that we achieve\na significant average gain of 3.3% in top-one score over a subset of speech\ncommand dataset for keyword spotting.", "published": "2019-10-18 06:55:18", "link": "http://arxiv.org/abs/1910.13801v1", "categories": ["eess.AS", "cs.MM", "cs.SD"], "primary_category": "eess.AS"}
