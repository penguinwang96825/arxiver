{"title": "Table2answer: Read the database and answer without SQL", "abstract": "Semantic parsing is the task of mapping natural language to logic form. In\nquestion answering, semantic parsing can be used to map the question to logic\nform and execute the logic form to get the answer. One key problem for semantic\nparsing is the hard label work. We study this problem in another way: we do not\nuse the logic form any more. Instead we only use the schema and answer info. We\nthink that the logic form step can be injected into the deep model. The reason\nwhy we think removing the logic form step is possible is that human can do the\ntask without explicit logic form. We use BERT-based model and do the experiment\nin the WikiSQL dataset, which is a large natural language to SQL dataset. Our\nexperimental evaluations that show that our model can achieves the baseline\nresults in WikiSQL dataset.", "published": "2019-02-12 07:07:16", "link": "http://arxiv.org/abs/1902.04260v8", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Machine Reading Comprehension for Answer Re-Ranking in Customer Support\n  Chatbots", "abstract": "Recent advances in deep neural networks, language modeling and language\ngeneration have introduced new ideas to the field of conversational agents. As\na result, deep neural models such as sequence-to-sequence, Memory Networks, and\nthe Transformer have become key ingredients of state-of-the-art dialog systems.\nWhile those models are able to generate meaningful responses even in unseen\nsituation, they need a lot of training data to build a reliable model. Thus,\nmost real-world systems stuck to traditional approaches based on information\nretrieval and even hand-crafted rules, due to their robustness and\neffectiveness, especially for narrow-focused conversations. Here, we present a\nmethod that adapts a deep neural architecture from the domain of machine\nreading comprehension to re-rank the suggested answers from different models\nusing the question as context. We train our model using negative sampling based\non question-answer pairs from the Twitter Customer Support Dataset.The\nexperimental results show that our re-ranking framework can improve the\nperformance in terms of word overlap and semantics both for individual models\nas well as for model combinations.", "published": "2019-02-12 15:49:40", "link": "http://arxiv.org/abs/1902.04574v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PAC-Bayes Analysis of Sentence Representation", "abstract": "Learning sentence vectors from an unlabeled corpus has attracted attention\nbecause such vectors can represent sentences in a lower dimensional and\ncontinuous space. Simple heuristics using pre-trained word vectors are widely\napplied to machine learning tasks. However, they are not well understood from a\ntheoretical perspective. We analyze learning sentence vectors from a transfer\nlearning perspective by using a PAC-Bayes bound that enables us to understand\nexisting heuristics. We show that simple heuristics such as averaging and\ninverse document frequency weighted averaging are derived by our formulation.\nMoreover, we propose novel sentence vector learning algorithms on the basis of\nour PAC-Bayes analysis.", "published": "2019-02-12 05:49:34", "link": "http://arxiv.org/abs/1902.04247v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Towards a Robust Deep Neural Network in Texts: A Survey", "abstract": "Deep neural networks (DNNs) have achieved remarkable success in various tasks\n(e.g., image classification, speech recognition, and natural language\nprocessing (NLP)). However, researchers have demonstrated that DNN-based models\nare vulnerable to adversarial examples, which cause erroneous predictions by\nadding imperceptible perturbations into legitimate inputs. Recently, studies\nhave revealed adversarial examples in the text domain, which could effectively\nevade various DNN-based text analyzers and further bring the threats of the\nproliferation of disinformation. In this paper, we give a comprehensive survey\non the existing studies of adversarial techniques for generating adversarial\ntexts written by both English and Chinese characters and the corresponding\ndefense methods. More importantly, we hope that our work could inspire future\nstudies to develop more robust DNN-based text analyzers against known and\nunknown adversarial techniques.\n  We classify the existing adversarial techniques for crafting adversarial\ntexts based on the perturbation units, helping to better understand the\ngeneration of adversarial texts and build robust models for defense. In\npresenting the taxonomy of adversarial attacks and defenses in the text domain,\nwe introduce the adversarial techniques from the perspective of different NLP\ntasks. Finally, we discuss the existing challenges of adversarial attacks and\ndefenses in texts and present the future research directions in this emerging\nand challenging field.", "published": "2019-02-12 02:42:54", "link": "http://arxiv.org/abs/1902.07285v6", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multitask Learning for Polyphonic Piano Transcription, a Case Study", "abstract": "Viewing polyphonic piano transcription as a multitask learning problem, where\nwe need to simultaneously predict onsets, intermediate frames and offsets of\nnotes, we investigate the performance impact of additional prediction targets,\nusing a variety of suitable convolutional neural network architectures. We\nquantify performance differences of additional objectives on the large MAESTRO\ndataset.", "published": "2019-02-12 14:00:59", "link": "http://arxiv.org/abs/1902.04390v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "FurcaNeXt: End-to-end monaural speech separation with dynamic gated\n  dilated temporal convolutional networks", "abstract": "Deep dilated temporal convolutional networks (TCN) have been proved to be\nvery effective in sequence modeling. In this paper we propose several\nimprovements of TCN for end-to-end approach to monaural speech separation,\nwhich consists of 1) multi-scale dynamic weighted gated dilated convolutional\npyramids network (FurcaPy), 2) gated TCN with intra-parallel convolutional\ncomponents (FurcaPa), 3) weight-shared multi-scale gated TCN (FurcaSh), 4)\ndilated TCN with gated difference-convolutional component (FurcaSu), that all\nthese networks take the mixed utterance of two speakers and maps it to two\nseparated utterances, where each utterance contains only one speaker's voice.\nFor the objective, we propose to train the network by directly optimizing\nutterance level signal-to-distortion ratio (SDR) in a permutation invariant\ntraining (PIT) style. Our experiments on the the public WSJ0-2mix data corpus\nresults in 18.4dB SDR improvement, which shows our proposed networks can leads\nto performance improvement on the speaker separation task.", "published": "2019-02-12 09:07:07", "link": "http://arxiv.org/abs/1902.04891v6", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
