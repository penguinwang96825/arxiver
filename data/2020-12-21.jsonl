{"title": "Domain specific BERT representation for Named Entity Recognition of lab\n  protocol", "abstract": "Supervised models trained to predict properties from representations have\nbeen achieving high accuracy on a variety of tasks. For instance, the BERT\nfamily seems to work exceptionally well on the downstream task from NER tagging\nto the range of other linguistic tasks. But the vocabulary used in the medical\nfield contains a lot of different tokens used only in the medical industry such\nas the name of different diseases, devices, organisms, medicines, etc. that\nmakes it difficult for traditional BERT model to create contextualized\nembedding. In this paper, we are going to illustrate the System for Named\nEntity Tagging based on Bio-Bert. Experimental results show that our model\ngives substantial improvements over the baseline and stood the fourth runner up\nin terms of F1 score, and first runner up in terms of Recall with just 2.21 F1\nscore behind the best one.", "published": "2020-12-21 06:54:38", "link": "http://arxiv.org/abs/2012.11145v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "An End-to-End Document-Level Neural Discourse Parser Exploiting\n  Multi-Granularity Representations", "abstract": "Document-level discourse parsing, in accordance with the Rhetorical Structure\nTheory (RST), remains notoriously challenging. Challenges include the deep\nstructure of document-level discourse trees, the requirement of subtle semantic\njudgments, and the lack of large-scale training corpora. To address such\nchallenges, we propose to exploit robust representations derived from multiple\nlevels of granularity across syntax and semantics, and in turn incorporate such\nrepresentations in an end-to-end encoder-decoder neural architecture for more\nresourceful discourse processing. In particular, we first use a pre-trained\ncontextual language model that embodies high-order and long-range dependency to\nenable finer-grain semantic, syntactic, and organizational representations. We\nfurther encode such representations with boundary and hierarchical information\nto obtain more refined modeling for document-level discourse processing.\nExperimental results show that our parser achieves the state-of-the-art\nperformance, approaching human-level performance on the benchmarked RST\ndataset.", "published": "2020-12-21 08:01:04", "link": "http://arxiv.org/abs/2012.11169v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging ParsBERT and Pretrained mT5 for Persian Abstractive Text\n  Summarization", "abstract": "Text summarization is one of the most critical Natural Language Processing\n(NLP) tasks. More and more researches are conducted in this field every day.\nPre-trained transformer-based encoder-decoder models have begun to gain\npopularity for these tasks. This paper proposes two methods to address this\ntask and introduces a novel dataset named pn-summary for Persian abstractive\ntext summarization. The models employed in this paper are mT5 and an\nencoder-decoder version of the ParsBERT model (i.e., a monolingual BERT model\nfor Persian). These models are fine-tuned on the pn-summary dataset. The\ncurrent work is the first of its kind and, by achieving promising results, can\nserve as a baseline for any future work.", "published": "2020-12-21 09:35:52", "link": "http://arxiv.org/abs/2012.11204v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-attention Comparison Module for Boosting Performance on\n  Retrieval-based Open-Domain Dialog Systems", "abstract": "Since the pre-trained language models are widely used, retrieval-based\nopen-domain dialog systems, have attracted considerable attention from\nresearchers recently. Most of the previous works select a suitable response\nonly according to the matching degree between the query and each individual\ncandidate response. Although good performance has been achieved, these recent\nworks ignore the comparison among the candidate responses, which could provide\nrich information for selecting the most appropriate response. Intuitively,\nbetter decisions could be made when the models can get access to the comparison\ninformation among all the candidate responses. In order to leverage the\ncomparison information among the candidate responses, in this paper, we propose\na novel and plug-in Self-attention Comparison Module for retrieval-based\nopen-domain dialog systems, called SCM. Extensive experiment results\ndemonstrate that our proposed self-attention comparison module effectively\nboosts the performance of the existing retrieval-based open-domain dialog\nsystems. Besides, we have publicly released our source codes for future\nresearch.", "published": "2020-12-21 14:10:42", "link": "http://arxiv.org/abs/2012.11357v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Document-Level Relation Extraction with Reconstruction", "abstract": "In document-level relation extraction (DocRE), graph structure is generally\nused to encode relation information in the input document to classify the\nrelation category between each entity pair, and has greatly advanced the DocRE\ntask over the past several years. However, the learned graph representation\nuniversally models relation information between all entity pairs regardless of\nwhether there are relationships between these entity pairs. Thus, those entity\npairs without relationships disperse the attention of the encoder-classifier\nDocRE for ones with relationships, which may further hind the improvement of\nDocRE. To alleviate this issue, we propose a novel\nencoder-classifier-reconstructor model for DocRE. The reconstructor manages to\nreconstruct the ground-truth path dependencies from the graph representation,\nto ensure that the proposed DocRE model pays more attention to encode entity\npairs with relationships in the training. Furthermore, the reconstructor is\nregarded as a relationship indicator to assist relation classification in the\ninference, which can further improve the performance of DocRE model.\nExperimental results on a large-scale DocRE dataset show that the proposed\nmodel can significantly improve the accuracy of relation extraction on a strong\nheterogeneous graph-based baseline.", "published": "2020-12-21 14:29:31", "link": "http://arxiv.org/abs/2012.11384v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TechTexC: Classification of Technical Texts using Convolution and\n  Bidirectional Long Short Term Memory Network", "abstract": "This paper illustrates the details description of technical text\nclassification system and its results that developed as a part of participation\nin the shared task TechDofication 2020. The shared task consists of two\nsub-tasks: (i) first task identify the coarse-grained technical domain of given\ntext in a specified language and (ii) the second task classify a text of\ncomputer science domain into fine-grained sub-domains. A classification system\n(called 'TechTexC') is developed to perform the classification task using three\ntechniques: convolution neural network (CNN), bidirectional long short term\nmemory (BiLSTM) network, and combined CNN with BiLSTM. Results show that CNN\nwith BiLSTM model outperforms the other techniques concerning task-1 of\nsub-tasks (a, b, c and g) and task-2a. This combined model obtained f1 scores\nof 82.63 (sub-task a), 81.95 (sub-task b), 82.39 (sub-task c), 84.37 (sub-task\ng), and 67.44 (task-2a) on the development dataset. Moreover, in the case of\ntest set, the combined CNN with BiLSTM approach achieved that higher accuracy\nfor the subtasks 1a (70.76%), 1b (79.97%), 1c (65.45%), 1g (49.23%) and 2a\n(70.14%).", "published": "2020-12-21 15:22:47", "link": "http://arxiv.org/abs/2012.11420v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pattern-aware Data Augmentation for Query Rewriting in Voice Assistant\n  Systems", "abstract": "Query rewriting (QR) systems are widely used to reduce the friction caused by\nerrors in a spoken language understanding pipeline. However, the underlying\nsupervised models require a large number of labeled pairs, and these pairs are\nhard and costly to be collected. Therefore, We propose an augmentation\nframework that learns patterns from existing training pairs and generates\nrewrite candidates from rewrite labels inversely to compensate for insufficient\nQR training data. The proposed framework casts the augmentation problem as a\nsequence-to-sequence generation task and enforces the optimization process with\na policy gradient technique for controllable rewarding. This approach goes\nbeyond the traditional heuristics or rule-based augmentation methods and is not\nconstrained to generate predefined patterns of swapping/replacing words. Our\nexperimental results show its effectiveness compared with a fully trained QR\nbaseline and demonstrate its potential application in boosting the QR\nperformance on low-resource domains or locales.", "published": "2020-12-21 16:36:32", "link": "http://arxiv.org/abs/2012.11468v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Subword Sampling for Low Resource Word Alignment", "abstract": "Annotation projection is an important area in NLP that can greatly contribute\nto creating language resources for low-resource languages. Word alignment plays\na key role in this setting. However, most of the existing word alignment\nmethods are designed for a high resource setting in machine translation where\nmillions of parallel sentences are available. This amount reduces to a few\nthousands of sentences when dealing with low-resource languages failing the\nexisting established IBM models. In this paper, we propose subword\nsampling-based alignment of text units. This method's hypothesis is that the\naggregation of different granularities of text for certain language pairs can\nhelp word-level alignment. For certain languages for which gold-standard\nalignments exist, we propose an iterative Bayesian optimization framework to\noptimize selecting possible subwords from the space of possible subword\nrepresentations of the source and target sentences. We show that the subword\nsampling method consistently outperforms word-level alignment on six language\npairs: English-German, English-French, English-Romanian, English-Persian,\nEnglish-Hindi, and English-Inuktitut. In addition, we show that the\nhyperparameters learned for certain language pairs can be applied to other\nlanguages at no supervision and consistently improve the alignment results. We\nobserve that using $5K$ parallel sentences together with our proposed subword\nsampling approach, we obtain similar F1 scores to the use of $100K$'s of\nparallel sentences in existing word-level fast-align/eflomal alignment methods.", "published": "2020-12-21 19:47:04", "link": "http://arxiv.org/abs/2012.11657v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Graph Reasoning Network for Multi-turn Response Selection via\n  Customized Pre-training", "abstract": "We investigate response selection for multi-turn conversation in\nretrieval-based chatbots. Existing studies pay more attention to the matching\nbetween utterances and responses by calculating the matching score based on\nlearned features, leading to insufficient model reasoning ability. In this\npaper, we propose a graph-reasoning network (GRN) to address the problem. GRN\nfirst conducts pre-training based on ALBERT using next utterance prediction and\nutterance order prediction tasks specifically devised for response selection.\nThese two customized pre-training tasks can endow our model with the ability of\ncapturing semantical and chronological dependency between utterances. We then\nfine-tune the model on an integrated network with sequence reasoning and graph\nreasoning structures. The sequence reasoning module conducts inference based on\nthe highly summarized context vector of utterance-response pairs from the\nglobal perspective. The graph reasoning module conducts the reasoning on the\nutterance-level graph neural network from the local perspective. Experiments on\ntwo conversational reasoning datasets show that our model can dramatically\noutperform the strong baseline methods and can achieve performance which is\nclose to human-level.", "published": "2020-12-21 03:38:29", "link": "http://arxiv.org/abs/2012.11099v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Incorporating Entity-specific Knowledge Graph Information in\n  Predicting Drug-Drug Interactions", "abstract": "Off-the-shelf biomedical embeddings obtained from the recently released\nvarious pre-trained language models (such as BERT, XLNET) have demonstrated\nstate-of-the-art results (in terms of accuracy) for the various natural\nlanguage understanding tasks (NLU) in the biomedical domain. Relation\nClassification (RC) falls into one of the most critical tasks. In this paper,\nwe explore how to incorporate domain knowledge of the biomedical entities (such\nas drug, disease, genes), obtained from Knowledge Graph (KG) Embeddings, for\npredicting Drug-Drug Interaction from textual corpus. We propose a new method,\nBERTKG-DDI, to combine drug embeddings obtained from its interaction with other\nbiomedical entities along with domain-specific BioBERT embedding-based RC\narchitecture. Experiments conducted on the DDIExtraction 2013 corpus clearly\nindicate that this strategy improves other baselines architectures by 4.1%\nmacro F1-score.", "published": "2020-12-21 06:44:32", "link": "http://arxiv.org/abs/2012.11142v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Narrative Incoherence Detection", "abstract": "We propose the task of narrative incoherence detection as a new arena for\ninter-sentential semantic understanding: Given a multi-sentence narrative,\ndecide whether there exist any semantic discrepancies in the narrative flow.\nSpecifically, we focus on the missing sentence and discordant sentence\ndetection. Despite its simple setup, this task is challenging as the model\nneeds to understand and analyze a multi-sentence narrative, and predict\nincoherence at the sentence level. As an initial step towards this task, we\nimplement several baselines either directly analyzing the raw text\n(\\textit{token-level}) or analyzing learned sentence representations\n(\\textit{sentence-level}). We observe that while token-level modeling has\nbetter performance when the input contains fewer sentences, sentence-level\nmodeling performs better on longer narratives and possesses an advantage in\nefficiency and flexibility. Pre-training on large-scale data and auxiliary\nsentence prediction training objective further boost the detection performance\nof the sentence-level model.", "published": "2020-12-21 07:18:08", "link": "http://arxiv.org/abs/2012.11157v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MT-Teql: Evaluating and Augmenting Consistency of Text-to-SQL Models\n  with Metamorphic Testing", "abstract": "Text-to-SQL is a task to generate SQL queries from human utterances. However,\ndue to the variation of natural language, two semantically equivalent\nutterances may appear differently in the lexical level. Likewise, user\npreferences (e.g., the choice of normal forms) can lead to dramatic changes in\ntable structures when expressing conceptually identical schemas. Envisioning\nthe general difficulty for text-to-SQL models to preserve prediction\nconsistency against linguistic and schema variations, we propose MT-Teql, a\nMetamorphic Testing-based framework for systematically evaluating and\naugmenting the consistency of TExt-to-SQL models. Inspired by the principles of\nsoftware metamorphic testing, MT-Teql delivers a model-agnostic framework which\nimplements a comprehensive set of metamorphic relations (MRs) to conduct\nsemantics-preserving transformations toward utterances and schemas. Model\nInconsistency can be exposed when the original and transformed inputs induce\ndifferent SQL queries. In addition, we leverage the transformed inputs to\nretrain models for further model robustness boost. Our experiments show that\nour framework exposes thousands of prediction errors from SOTA models and\nenriches existing datasets by order of magnitude, eliminating over 40%\ninconsistency errors without compromising standard accuracy.", "published": "2020-12-21 07:43:31", "link": "http://arxiv.org/abs/2012.11163v1", "categories": ["cs.CL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Medical Entity Linking using Triplet Network", "abstract": "Entity linking (or Normalization) is an essential task in text mining that\nmaps the entity mentions in the medical text to standard entities in a given\nKnowledge Base (KB). This task is of great importance in the medical domain. It\ncan also be used for merging different medical and clinical ontologies. In this\npaper, we center around the problem of disease linking or normalization. This\ntask is executed in two phases: candidate generation and candidate scoring. In\nthis paper, we present an approach to rank the candidate Knowledge Base entries\nbased on their similarity with disease mention. We make use of the Triplet\nNetwork for candidate ranking. While the existing methods have used carefully\ngenerated sieves and external resources for candidate generation, we introduce\na robust and portable candidate generation scheme that does not make use of the\nhand-crafted rules. Experimental results on the standard benchmark NCBI disease\ndataset demonstrate that our system outperforms the prior methods by a\nsignificant margin.", "published": "2020-12-21 07:44:37", "link": "http://arxiv.org/abs/2012.11164v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Self-Supervised Learning for Visual Summary Identification in Scientific\n  Publications", "abstract": "Providing visual summaries of scientific publications can increase\ninformation access for readers and thereby help deal with the exponential\ngrowth in the number of scientific publications. Nonetheless, efforts in\nproviding visual publication summaries have been few and far apart, primarily\nfocusing on the biomedical domain. This is primarily because of the limited\navailability of annotated gold standards, which hampers the application of\nrobust and high-performing supervised learning techniques. To address these\nproblems we create a new benchmark dataset for selecting figures to serve as\nvisual summaries of publications based on their abstracts, covering several\ndomains in computer science. Moreover, we develop a self-supervised learning\napproach, based on heuristic matching of inline references to figures with\nfigure captions. Experiments in both biomedical and computer science domains\nshow that our model is able to outperform the state of the art despite being\nself-supervised and therefore not relying on any annotated training data.", "published": "2020-12-21 09:48:58", "link": "http://arxiv.org/abs/2012.11213v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "BERTChem-DDI : Improved Drug-Drug Interaction Prediction from text using\n  Chemical Structure Information", "abstract": "Traditional biomedical version of embeddings obtained from pre-trained\nlanguage models have recently shown state-of-the-art results for relation\nextraction (RE) tasks in the medical domain. In this paper, we explore how to\nincorporate domain knowledge, available in the form of molecular structure of\ndrugs, for predicting Drug-Drug Interaction from textual corpus. We propose a\nmethod, BERTChem-DDI, to efficiently combine drug embeddings obtained from the\nrich chemical structure of drugs along with off-the-shelf domain-specific\nBioBERT embedding-based RE architecture. Experiments conducted on the\nDDIExtraction 2013 corpus clearly indicate that this strategy improves other\nstrong baselines architectures by 3.4\\% macro F1-score.", "published": "2020-12-21 07:13:52", "link": "http://arxiv.org/abs/2012.11599v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SChuBERT: Scholarly Document Chunks with BERT-encoding boost Citation\n  Count Prediction", "abstract": "Predicting the number of citations of scholarly documents is an upcoming task\nin scholarly document processing. Besides the intrinsic merit of this\ninformation, it also has a wider use as an imperfect proxy for quality which\nhas the advantage of being cheaply available for large volumes of scholarly\ndocuments. Previous work has dealt with number of citations prediction with\nrelatively small training data sets, or larger datasets but with short,\nincomplete input text. In this work we leverage the open access ACL Anthology\ncollection in combination with the Semantic Scholar bibliometric database to\ncreate a large corpus of scholarly documents with associated citation\ninformation and we propose a new citation prediction model called SChuBERT. In\nour experiments we compare SChuBERT with several state-of-the-art citation\nprediction models and show that it outperforms previous methods by a large\nmargin. We also show the merit of using more training data and longer input for\nnumber of citations prediction.", "published": "2020-12-21 23:14:18", "link": "http://arxiv.org/abs/2012.11740v1", "categories": ["cs.CL", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Adjust-free adversarial example generation in speech recognition using\n  evolutionary multi-objective optimization under black-box condition", "abstract": "This paper proposes a black-box adversarial attack method to automatic speech\nrecognition systems. Some studies have attempted to attack neural networks for\nspeech recognition; however, these methods did not consider the robustness of\ngenerated adversarial examples against timing lag with a target speech. The\nproposed method in this paper adopts Evolutionary Multi-objective Optimization\n(EMO)that allows it generating robust adversarial examples under black-box\nscenario. Experimental results showed that the proposed method successfully\ngenerated adjust-free adversarial examples, which are sufficiently robust\nagainst timing lag so that an attacker does not need to take the timing of\nplaying it against the target speech.", "published": "2020-12-21 06:35:52", "link": "http://arxiv.org/abs/2012.11138v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Object-Centric Diagnosis of Visual Reasoning", "abstract": "When answering questions about an image, it not only needs knowing what --\nunderstanding the fine-grained contents (e.g., objects, relationships) in the\nimage, but also telling why -- reasoning over grounding visual cues to derive\nthe answer for a question. Over the last few years, we have seen significant\nprogress on visual question answering. Though impressive as the accuracy grows,\nit still lags behind to get knowing whether these models are undertaking\ngrounding visual reasoning or just leveraging spurious correlations in the\ntraining data. Recently, a number of works have attempted to answer this\nquestion from perspectives such as grounding and robustness. However, most of\nthem are either focusing on the language side or coarsely studying the\npixel-level attention maps. In this paper, by leveraging the step-wise object\ngrounding annotations provided in the GQA dataset, we first present a\nsystematical object-centric diagnosis of visual reasoning on grounding and\nrobustness, particularly on the vision side. According to the extensive\ncomparisons across different models, we find that even models with high\naccuracy are not good at grounding objects precisely, nor robust to visual\ncontent perturbations. In contrast, symbolic and modular models have a\nrelatively better grounding and robustness, though at the cost of accuracy. To\nreconcile these different aspects, we further develop a diagnostic model,\nnamely Graph Reasoning Machine. Our model replaces purely symbolic visual\nrepresentation with probabilistic scene graph and then applies teacher-forcing\ntraining for the visual reasoning module. The designed model improves the\nperformance on all three metrics over the vanilla neural-symbolic model while\ninheriting the transparency. Further ablation studies suggest that this\nimprovement is mainly due to more accurate image understanding and proper\nintermediate reasoning supervisions.", "published": "2020-12-21 18:59:28", "link": "http://arxiv.org/abs/2012.11587v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "A Distributional Approach to Controlled Text Generation", "abstract": "We propose a Distributional Approach for addressing Controlled Text\nGeneration from pre-trained Language Models (LMs). This approach permits to\nspecify, in a single formal framework, both \"pointwise\" and \"distributional\"\nconstraints over the target LM -- to our knowledge, the first model with such\ngenerality -- while minimizing KL divergence from the initial LM distribution.\nThe optimal target distribution is then uniquely determined as an explicit EBM\n(Energy-Based Model) representation. From that optimal representation we then\ntrain a target controlled Autoregressive LM through an adaptive distributional\nvariant of Policy Gradient. We conduct a first set of experiments over\npointwise constraints showing the advantages of our approach over a set of\nbaselines, in terms of obtaining a controlled LM balancing constraint\nsatisfaction with divergence from the initial LM. We then perform experiments\nover distributional constraints, a unique feature of our approach,\ndemonstrating its potential as a remedy to the problem of Bias in Language\nModels. Through an ablation study, we show the effectiveness of our adaptive\ntechnique for obtaining faster convergence. (Code available at\nhttps://github.com/naver/gdc)", "published": "2020-12-21 19:02:41", "link": "http://arxiv.org/abs/2012.11635v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Neural Methods for Effective, Efficient, and Exposure-Aware Information\n  Retrieval", "abstract": "Neural networks with deep architectures have demonstrated significant\nperformance improvements in computer vision, speech recognition, and natural\nlanguage processing. The challenges in information retrieval (IR), however, are\ndifferent from these other application areas. A common form of IR involves\nranking of documents--or short passages--in response to keyword-based queries.\nEffective IR systems must deal with query-document vocabulary mismatch problem,\nby modeling relationships between different query and document terms and how\nthey indicate relevance. Models should also consider lexical matches when the\nquery contains rare terms--such as a person's name or a product model\nnumber--not seen during training, and to avoid retrieving semantically related\nbut irrelevant results. In many real-life IR tasks, the retrieval involves\nextremely large collections--such as the document index of a commercial Web\nsearch engine--containing billions of documents. Efficient IR methods should\ntake advantage of specialized IR data structures, such as inverted index, to\nefficiently retrieve from large collections. Given an information need, the IR\nsystem also mediates how much exposure an information artifact receives by\ndeciding whether it should be displayed, and where it should be positioned,\namong other results. Exposure-aware IR systems may optimize for additional\nobjectives, besides relevance, such as parity of exposure for retrieved items\nand content publishers. In this thesis, we present novel neural architectures\nand methods motivated by the specific needs and challenges of IR tasks.", "published": "2020-12-21 21:20:16", "link": "http://arxiv.org/abs/2012.11685v2", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Unsupervised Cross-Lingual Speech Emotion Recognition Using\n  DomainAdversarial Neural Network", "abstract": "By using deep learning approaches, Speech Emotion Recog-nition (SER) on a\nsingle domain has achieved many excellentresults. However, cross-domain SER is\nstill a challenging taskdue to the distribution shift between source and target\ndomains.In this work, we propose a Domain Adversarial Neural Net-work (DANN)\nbased approach to mitigate this distribution shiftproblem for cross-lingual\nSER. Specifically, we add a languageclassifier and gradient reversal layer\nafter the feature extractor toforce the learned representation both\nlanguage-independent andemotion-meaningful. Our method is unsupervised, i. e.,\nlabelson target language are not required, which makes it easier to ap-ply our\nmethod to other languages. Experimental results showthe proposed method\nprovides an average absolute improve-ment of 3.91% over the baseline system for\narousal and valenceclassification task. Furthermore, we find that batch\nnormaliza-tion is beneficial to the performance gain of DANN. Thereforewe also\nexplore the effect of different ways of data combinationfor batch\nnormalization.", "published": "2020-12-21 08:21:11", "link": "http://arxiv.org/abs/2012.11174v1", "categories": ["eess.AS", "cs.AI", "I.2"], "primary_category": "eess.AS"}
{"title": "A Bayesian methodology for localising acoustic emission sources in\n  complex structures", "abstract": "In the field of structural health monitoring (SHM), the acquisition of\nacoustic emissions to localise damage sources has emerged as a popular\napproach. Despite recent advances, the task of locating damage within composite\nmaterials and structures that contain non-trivial geometrical features, still\nposes a significant challenge. Within this paper, a Bayesian source\nlocalisation strategy that is robust to these complexities is presented. Under\nthis new framework, a Gaussian process is first used to learn the relationship\nbetween source locations and the corresponding difference-in-time-of-arrival\nvalues for a number of sensor pairings. As an acoustic emission event with an\nunknown origin is observed, a mapping is then generated that quantifies the\nlikelihood of the emission location across the surface of the structure. The\nnew probabilistic mapping offers multiple benefits, leading to a localisation\nstrategy that is more informative than deterministic predictions or\nsingle-point estimates with an associated confidence bound. The performance of\nthe approach is investigated on a structure with numerous complex geometrical\nfeatures and demonstrates a favourable performance in comparison to other\nsimilar localisation methods.", "published": "2020-12-21 00:19:56", "link": "http://arxiv.org/abs/2012.11058v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Multi-stream Convolutional Neural Network with Frequency Selection for\n  Robust Speaker Verification", "abstract": "Speaker verification aims to verify whether an input speech corresponds to\nthe claimed speaker, and conventionally, this kind of system is deployed based\non single-stream scenario, wherein the feature extractor operates in full\nfrequency range. In this paper, we hypothesize that machine can learn enough\nknowledge to do classification task when listening to partial frequency range\ninstead of full frequency range, which is so called frequency selection\ntechnique, and further propose a novel framework of multi-stream Convolutional\nNeural Network (CNN) with this technique for speaker verification tasks. The\nproposed framework accommodates diverse temporal embeddings generated from\nmultiple streams to enhance the robustness of acoustic modeling. For the\ndiversity of temporal embeddings, we consider feature augmentation with\nfrequency selection, which is to manually segment the full-band of frequency\ninto several sub-bands, and the feature extractor of each stream can select\nwhich sub-bands to use as target frequency domain. Different from conventional\nsingle-stream solution wherein each utterance would only be processed for one\ntime, in this framework, there are multiple streams processing it in parallel.\nThe input utterance for each stream is pre-processed by a frequency selector\nwithin specified frequency range, and post-processed by mean normalization. The\nnormalized temporal embeddings of each stream will flow into a pooling layer to\ngenerate fused embeddings. We conduct extensive experiments on VoxCeleb\ndataset, and the experimental results demonstrate that multi-stream CNN\nsignificantly outperforms single-stream baseline with 20.53 % of relative\nimprovement in minimum Decision Cost Function (minDCF).", "published": "2020-12-21 07:23:40", "link": "http://arxiv.org/abs/2012.11159v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Semantic Audio-Visual Navigation", "abstract": "Recent work on audio-visual navigation assumes a constantly-sounding target\nand restricts the role of audio to signaling the target's position. We\nintroduce semantic audio-visual navigation, where objects in the environment\nmake sounds consistent with their semantic meaning (e.g., toilet flushing, door\ncreaking) and acoustic events are sporadic or short in duration. We propose a\ntransformer-based model to tackle this new semantic AudioGoal task,\nincorporating an inferred goal descriptor that captures both spatial and\nsemantic properties of the target. Our model's persistent multimodal memory\nenables it to reach the goal even long after the acoustic event stops. In\nsupport of the new task, we also expand the SoundSpaces audio simulations to\nprovide semantically grounded sounds for an array of objects in Matterport3D.\nOur method strongly outperforms existing audio-visual navigation methods by\nlearning to associate semantic, acoustic, and visual cues.", "published": "2020-12-21 18:59:04", "link": "http://arxiv.org/abs/2012.11583v2", "categories": ["cs.CV", "cs.LG", "cs.RO", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
