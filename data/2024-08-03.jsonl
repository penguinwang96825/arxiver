{"title": "Dialog Flow Induction for Constrainable LLM-Based Chatbots", "abstract": "LLM-driven dialog systems are used in a diverse set of applications, ranging\nfrom healthcare to customer service. However, given their generalization\ncapability, it is difficult to ensure that these chatbots stay within the\nboundaries of the specialized domains, potentially resulting in inaccurate\ninformation and irrelevant responses. This paper introduces an unsupervised\napproach for automatically inducing domain-specific dialog flows that can be\nused to constrain LLM-based chatbots. We introduce two variants of dialog flow\nbased on the availability of in-domain conversation instances. Through human\nand automatic evaluation over various dialog domains, we demonstrate that our\nhigh-quality data-guided dialog flows achieve better domain coverage, thereby\novercoming the need for extensive manual crafting of such flows.", "published": "2024-08-03 01:15:50", "link": "http://arxiv.org/abs/2408.01623v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transforming Slot Schema Induction with Generative Dialogue State\n  Inference", "abstract": "The challenge of defining a slot schema to represent the state of a\ntask-oriented dialogue system is addressed by Slot Schema Induction (SSI),\nwhich aims to automatically induce slots from unlabeled dialogue data. Whereas\nprevious approaches induce slots by clustering value spans extracted directly\nfrom the dialogue text, we demonstrate the power of discovering slots using a\ngenerative approach. By training a model to generate slot names and values that\nsummarize key dialogue information with no prior task knowledge, our SSI method\ndiscovers high-quality candidate information for representing dialogue state.\nThese discovered slot-value candidates can be easily clustered into unified\nslot schemas that align well with human-authored schemas. Experimental\ncomparisons on the MultiWOZ and SGD datasets demonstrate that Generative\nDialogue State Inference (GenDSI) outperforms the previous state-of-the-art on\nmultiple aspects of the SSI task.", "published": "2024-08-03 02:41:10", "link": "http://arxiv.org/abs/2408.01638v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Summarization of Investment Reports Using Pre-trained Model", "abstract": "In this paper, we attempt to summarize monthly reports as investment reports.\nFund managers have a wide range of tasks, one of which is the preparation of\ninvestment reports. In addition to preparing monthly reports on fund\nmanagement, fund managers prepare management reports that summarize these\nmonthly reports every six months or once a year. The preparation of fund\nreports is a labor-intensive and time-consuming task. Therefore, in this paper,\nwe tackle investment summarization from monthly reports using transformer-based\nmodels. There are two main types of summarization methods: extractive\nsummarization and abstractive summarization, and this study constructs both\nmethods and examines which is more useful in summarizing investment reports.", "published": "2024-08-03 11:04:04", "link": "http://arxiv.org/abs/2408.01744v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Indexing and Visualization of Climate Change Narratives Using BERT and\n  Causal Extraction", "abstract": "In this study, we propose a methodology to extract, index, and visualize\n``climate change narratives'' (stories about the connection between causal and\nconsequential events related to climate change). We use two natural language\nprocessing methods, BERT (Bidirectional Encoder Representations from\nTransformers) and causal extraction, to textually analyze newspaper articles on\nclimate change to extract ``climate change narratives.'' The novelty of the\nmethodology could extract and quantify the causal relationships assumed by the\nnewspaper's writers. Looking at the extracted climate change narratives over\ntime, we find that since 2018, an increasing number of narratives suggest the\nimpact of the development of climate change policy discussion and the\nimplementation of climate change-related policies on corporate behaviors,\nmacroeconomics, and price dynamics. We also observed the recent emergence of\nnarratives focusing on the linkages between climate change-related policies and\nmonetary policy. Furthermore, there is a growing awareness of the negative\nimpacts of natural disasters (e.g., abnormal weather and severe floods) related\nto climate change on economic activities, and this issue might be perceived as\na new challenge for companies and governments. The methodology of this study is\nexpected to be applied to a wide range of fields, as it can analyze causal\nrelationships among various economic topics, including analysis of inflation\nexpectation or monetary policy communication strategy.", "published": "2024-08-03 11:05:41", "link": "http://arxiv.org/abs/2408.01745v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Discovery of Rare Causal Knowledge from Financial Statement Summaries", "abstract": "What would happen if temperatures were subdued and result in a cool summer?\nOne can easily imagine that air conditioner, ice cream or beer sales would be\nsuppressed as a result of this. Less obvious is that agricultural shipments\nmight be delayed, or that sound proofing material sales might decrease. The\nability to extract such causal knowledge is important, but it is also important\nto distinguish between cause-effect pairs that are known and those that are\nlikely to be unknown, or rare. Therefore, in this paper, we propose a method\nfor extracting rare causal knowledge from Japanese financial statement\nsummaries produced by companies. Our method consists of three steps. First, it\nextracts sentences that include causal knowledge from the summaries using a\nmachine learning method based on an extended language ontology. Second, it\nobtains causal knowledge from the extracted sentences using syntactic patterns.\nFinally, it extracts the rarest causal knowledge from the knowledge it has\nobtained.", "published": "2024-08-03 11:08:53", "link": "http://arxiv.org/abs/2408.01748v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MathLearner: A Large Language Model Agent Framework for Learning to\n  Solve Mathematical Problems", "abstract": "With the development of artificial intelligence (AI), large language models\n(LLM) are widely used in many fields. However, the reasoning ability of LLM is\nstill very limited when it comes to mathematical reasoning. Mathematics plays\nan important role in all aspects of human society and is a technical guarantee\nin the fields of healthcare, transport and aerospace, for this reason, the\ndevelopment of AI big language models in the field of mathematics has great\npotential significance. To improve the mathematical reasoning ability of large\nlanguage models, we proposed an agent framework for learning to solve\nmathematical problems based on inductive reasoning. By emulating the human\nlearning process of generalization of learned information and effective\napplication of previous knowledge in new reasoning tasks, this framework has\ngreat performance in the mathematical reasoning process. It improves global\naccuracy over the baseline method (chain-of-thought) by 20.96% and solves\n17.54% of the mathematical problems that the baseline cannot solve. Benefiting\nfrom the efficient RETRIEVAL method, our model improves the ability of large\nlanguage models to efficiently use external knowledge, i.e., the mathematical\ncomputation of the model can be based on written procedures. In education, our\nmodel can be used as a personalised learning aid, thus reducing the inequality\nof educational resources.", "published": "2024-08-03 13:28:19", "link": "http://arxiv.org/abs/2408.01779v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tracking Emotional Dynamics in Chat Conversations: A Hybrid Approach\n  using DistilBERT and Emoji Sentiment Analysis", "abstract": "Computer-mediated communication has become more important than face-to-face\ncommunication in many contexts. Tracking emotional dynamics in chat\nconversations can enhance communication, improve services, and support\nwell-being in various contexts. This paper explores a hybrid approach to\ntracking emotional dynamics in chat conversations by combining DistilBERT-based\ntext emotion detection and emoji sentiment analysis. A Twitter dataset was\nanalyzed using various machine learning algorithms, including SVM, Random\nForest, and AdaBoost. We contrasted their performance with DistilBERT. Results\nreveal DistilBERT's superior performance in emotion recognition. Our approach\naccounts for emotive expressions conveyed through emojis to better understand\nparticipants' emotions during chats. We demonstrate how this approach can\neffectively capture and analyze emotional shifts in real-time conversations.\nOur findings show that integrating text and emoji analysis is an effective way\nof tracking chat emotion, with possible applications in customer service, work\nchats, and social media interactions.", "published": "2024-08-03 18:28:31", "link": "http://arxiv.org/abs/2408.01838v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "S\u00f3lo Esc\u00fachame: Spanish Emotional Accompaniment Chatbot", "abstract": "According to the World Health Organization (WHO), suicide was the fourth\nleading cause of death in the world for individuals aged 15 to 29 in 2019.\nGiven the rapid increase in mental health issues, providing psychological\nsupport is both crucial and urgent. In this paper: (1) we propose S\\'olo\nEsc\\'uchame, the first open-source Spanish emotional assistance chatbot, based\non LLaMA-2-7b-Chat. (2) We introduced the HEAR (Hispanic Emotional\nAccompaniment Responses) dataset, compiled from multiple English sources\ntranslated into Spanish, as well as generic data generated using\nChatGPT-3.5-Turbo. Finally, (3) we propose an evaluation metric based on two\nsemi-automatic assessment methods. Our system outperforms a range of\nstate-of-the-art models in providing psychological assistance in Spanish. Our\nmodels and datasets are publicly available to facilitate reproducibility.", "published": "2024-08-03 19:33:33", "link": "http://arxiv.org/abs/2408.01852v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Re-Invoke: Tool Invocation Rewriting for Zero-Shot Tool Retrieval", "abstract": "Recent advances in large language models (LLMs) have enabled autonomous\nagents with complex reasoning and task-fulfillment capabilities using a wide\nrange of tools. However, effectively identifying the most relevant tools for a\ngiven task becomes a key bottleneck as the toolset size grows, hindering\nreliable tool utilization. To address this, we introduce Re-Invoke, an\nunsupervised tool retrieval method designed to scale effectively to large\ntoolsets without training. Specifically, we first generate a diverse set of\nsynthetic queries that comprehensively cover different aspects of the query\nspace associated with each tool document during the tool indexing phase.\nSecond, we leverage LLM's query understanding capabilities to extract key\ntool-related context and underlying intents from user queries during the\ninference phase. Finally, we employ a novel multi-view similarity ranking\nstrategy based on intents to pinpoint the most relevant tools for each query.\nOur evaluation demonstrates that Re-Invoke significantly outperforms\nstate-of-the-art alternatives in both single-tool and multi-tool scenarios, all\nwithin a fully unsupervised setting. Notably, on the ToolE datasets, we achieve\na 20% relative improvement in nDCG@5 for single-tool retrieval and a 39%\nimprovement for multi-tool retrieval.", "published": "2024-08-03 22:49:27", "link": "http://arxiv.org/abs/2408.01875v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MMPKUBase: A Comprehensive and High-quality Chinese Multi-modal\n  Knowledge Graph", "abstract": "Multi-modal knowledge graphs have emerged as a powerful approach for\ninformation representation, combining data from different modalities such as\ntext, images, and videos. While several such graphs have been constructed and\nhave played important roles in applications like visual question answering and\nrecommendation systems, challenges persist in their development. These include\nthe scarcity of high-quality Chinese knowledge graphs and limited domain\ncoverage in existing multi-modal knowledge graphs. This paper introduces\nMMPKUBase, a robust and extensive Chinese multi-modal knowledge graph that\ncovers diverse domains, including birds, mammals, ferns, and more, comprising\nover 50,000 entities and over 1 million filtered images. To ensure data\nquality, we employ Prototypical Contrastive Learning and the Isolation Forest\nalgorithm to refine the image data. Additionally, we have developed a\nuser-friendly platform to facilitate image attribute exploration.", "published": "2024-08-03 06:35:54", "link": "http://arxiv.org/abs/2408.01679v1", "categories": ["cs.CL", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Multi-Frame Vision-Language Model for Long-form Reasoning in Driver\n  Behavior Analysis", "abstract": "Identifying risky driving behavior in real-world situations is essential for\nthe safety of both drivers and pedestrians. However, integrating natural\nlanguage models in this field remains relatively untapped. To address this, we\ncreated a novel multi-modal instruction tuning dataset and driver coaching\ninference system. Our primary use case is dashcam-based coaching for commercial\ndrivers. The North American Dashcam Market is expected to register a CAGR of\n15.4 percent from 2022 to 2027. Our dataset enables language models to learn\nvisual instructions across various risky driving scenarios, emphasizing\ndetailed reasoning crucial for effective driver coaching and managerial\ncomprehension. Our model is trained on road-facing and driver-facing RGB camera\nfootage, capturing the comprehensive scope of driving behavior in vehicles\nequipped with dashcams.", "published": "2024-08-03 06:40:00", "link": "http://arxiv.org/abs/2408.01682v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Integrating Large Language Models and Knowledge Graphs for Extraction\n  and Validation of Textual Test Data", "abstract": "Aerospace manufacturing companies, such as Thales Alenia Space, design,\ndevelop, integrate, verify, and validate products characterized by high\ncomplexity and low volume. They carefully document all phases for each product\nbut analyses across products are challenging due to the heterogeneity and\nunstructured nature of the data in documents. In this paper, we propose a\nhybrid methodology that leverages Knowledge Graphs (KGs) in conjunction with\nLarge Language Models (LLMs) to extract and validate data contained in these\ndocuments. We consider a case study focused on test data related to electronic\nboards for satellites. To do so, we extend the Semantic Sensor Network\nontology. We store the metadata of the reports in a KG, while the actual test\nresults are stored in parquet accessible via a Virtual Knowledge Graph. The\nvalidation process is managed using an LLM-based approach. We also conduct a\nbenchmarking study to evaluate the performance of state-of-the-art LLMs in\nexecuting this task. Finally, we analyze the costs and benefits of automating\npreexisting processes of manual data extraction and validation for subsequent\ncross-report analyses.", "published": "2024-08-03 07:42:53", "link": "http://arxiv.org/abs/2408.01700v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "STBLLM: Breaking the 1-Bit Barrier with Structured Binary LLMs", "abstract": "In this paper, we present the first structural binarization method for LLM\ncompression to less than 1-bit precision. Although LLMs have achieved\nremarkable performance, their memory-bound nature during the inference stage\nhinders the adoption of resource-constrained devices. Reducing weights to 1-bit\nprecision through binarization substantially enhances computational efficiency.\nWe observe that some weights in binarized LLMs can be randomly flipped without\nsignificant performance degradation, suggesting the potential for further\ncompression. To exploit this, our STBLLM employs an N:M sparsity technique to\nachieve structural binarization of the weights. Specifically, we introduce a\nnovel Standardized Importance (SI) metric, which considers weight magnitude and\ninput feature norm to more accurately assess weight significance. Then, we\npropose a layer-wise approach, allowing different layers of the LLM to be\nsparsified with varying N:M ratios, thereby balancing compression and accuracy.\nFurthermore, we implement a fine-grained grouping strategy for less important\nweights, applying distinct quantization schemes to sparse, intermediate, and\ndense regions. Finally, we design a specialized CUDA kernel to support\nstructural binarization. We conduct extensive experiments on LLaMA-1/2/3, OPT\nfamily, and Mistral to evaluate the effectiveness of STBLLM. The results\ndemonstrate that our approach performs better than other compressed\nbinarization LLM methods while significantly reducing memory requirements.", "published": "2024-08-03 15:07:44", "link": "http://arxiv.org/abs/2408.01803v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Efficient Solutions For An Intriguing Failure of LLMs: Long Context\n  Window Does Not Mean LLMs Can Analyze Long Sequences Flawlessly", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\ncomprehending and analyzing lengthy sequential inputs, owing to their extensive\ncontext windows that allow processing millions of tokens in a single forward\npass. However, this paper uncovers a surprising limitation: LLMs fall short\nwhen handling long input sequences. We investigate this issue using three\ndatasets and two tasks (sentiment analysis and news categorization) across\nvarious LLMs, including Claude 3, Gemini Pro, GPT 3.5 Turbo, Llama 3 Instruct,\nand Mistral Instruct models. To address this limitation, we propose and\nevaluate ad-hoc solutions that substantially enhance LLMs' performance on long\ninput sequences by up to 50%, while reducing API cost and latency by up to 93%\nand 50%, respectively.", "published": "2024-08-03 21:31:34", "link": "http://arxiv.org/abs/2408.01866v3", "categories": ["cs.CL", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Efficacy of Large Language Models in Systematic Reviews", "abstract": "This study investigates the effectiveness of Large Language Models (LLMs) in\ninterpreting existing literature through a systematic review of the\nrelationship between Environmental, Social, and Governance (ESG) factors and\nfinancial performance. The primary objective is to assess how LLMs can\nreplicate a systematic review on a corpus of ESG-focused papers. We compiled\nand hand-coded a database of 88 relevant papers published from March 2020 to\nMay 2024. Additionally, we used a set of 238 papers from a previous systematic\nreview of ESG literature from January 2015 to February 2020. We evaluated two\ncurrent state-of-the-art LLMs, Meta AI's Llama 3 8B and OpenAI's GPT-4o, on the\naccuracy of their interpretations relative to human-made classifications on\nboth sets of papers. We then compared these results to a \"Custom GPT\" and a\nfine-tuned GPT-4o Mini model using the corpus of 238 papers as training data.\nThe fine-tuned GPT-4o Mini model outperformed the base LLMs by 28.3% on average\nin overall accuracy on prompt 1. At the same time, the \"Custom GPT\" showed a\n3.0% and 15.7% improvement on average in overall accuracy on prompts 2 and 3,\nrespectively. Our findings reveal promising results for investors and agencies\nto leverage LLMs to summarize complex evidence related to ESG investing,\nthereby enabling quicker decision-making and a more efficient market.", "published": "2024-08-03 00:01:13", "link": "http://arxiv.org/abs/2408.04646v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Distinguishing Chatbot from Human", "abstract": "There have been many recent advances in the fields of generative Artificial\nIntelligence (AI) and Large Language Models (LLM), with the Generative\nPre-trained Transformer (GPT) model being a leading \"chatbot.\" LLM-based\nchatbots have become so powerful that it may seem difficult to differentiate\nbetween human-written and machine-generated text. To analyze this problem, we\nhave developed a new dataset consisting of more than 750,000 human-written\nparagraphs, with a corresponding chatbot-generated paragraph for each. Based on\nthis dataset, we apply Machine Learning (ML) techniques to determine the origin\nof text (human or chatbot). Specifically, we consider two methodologies for\ntackling this issue: feature analysis and embeddings. Our feature analysis\napproach involves extracting a collection of features from the text for\nclassification. We also explore the use of contextual embeddings and\ntransformer-based architectures to train classification models. Our proposed\nsolutions offer high classification accuracy and serve as useful tools for\ntextual analysis, resulting in a better understanding of chatbot-generated text\nin this era of advanced AI technology.", "published": "2024-08-03 13:18:04", "link": "http://arxiv.org/abs/2408.04647v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Chain of Stance: Stance Detection with Large Language Models", "abstract": "Stance detection is an active task in natural language processing (NLP) that\naims to identify the author's stance towards a particular target within a text.\nGiven the remarkable language understanding capabilities and encyclopedic prior\nknowledge of large language models (LLMs), how to explore the potential of LLMs\nin stance detection has received significant attention. Unlike existing\nLLM-based approaches that focus solely on fine-tuning with large-scale\ndatasets, we propose a new prompting method, called \\textit{Chain of Stance}\n(CoS). In particular, it positions LLMs as expert stance detectors by\ndecomposing the stance detection process into a series of intermediate,\nstance-related assertions that culminate in the final judgment. This approach\nleads to significant improvements in classification performance. We conducted\nextensive experiments using four SOTA LLMs on the SemEval 2016 dataset,\ncovering the zero-shot and few-shot learning setups. The results indicate that\nthe proposed method achieves state-of-the-art results with an F1 score of 79.84\nin the few-shot setting.", "published": "2024-08-03 16:30:51", "link": "http://arxiv.org/abs/2408.04649v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Self-Emotion Blended Dialogue Generation in Social Simulation Agents", "abstract": "When engaging in conversations, dialogue agents in a virtual simulation\nenvironment may exhibit their own emotional states that are unrelated to the\nimmediate conversational context, a phenomenon known as self-emotion. This\nstudy explores how such self-emotion affects the agents' behaviors in dialogue\nstrategies and decision-making within a large language model (LLM)-driven\nsimulation framework. In a dialogue strategy prediction experiment, we analyze\nthe dialogue strategy choices employed by agents both with and without\nself-emotion, comparing them to those of humans. The results show that\nincorporating self-emotion helps agents exhibit more human-like dialogue\nstrategies. In an independent experiment comparing the performance of models\nfine-tuned on GPT-4 generated dialogue datasets, we demonstrate that\nself-emotion can lead to better overall naturalness and humanness. Finally, in\na virtual simulation environment where agents have discussions on multiple\ntopics, we show that self-emotion of agents can significantly influence the\ndecision-making process of the agents, leading to approximately a 50% change in\ndecisions.", "published": "2024-08-03 02:11:48", "link": "http://arxiv.org/abs/2408.01633v1", "categories": ["cs.MA", "cs.AI", "cs.CL", "cs.CY", "I.2.7; I.2; I.6"], "primary_category": "cs.MA"}
{"title": "PLUGH: A Benchmark for Spatial Understanding and Reasoning in Large\n  Language Models", "abstract": "We present PLUGH (https://www.urbandictionary.com/define.php?term=plugh), a\nmodern benchmark that currently consists of 5 tasks, each with 125 input texts\nextracted from 48 different games and representing 61 different\n(non-isomorphic) spatial graphs to assess the abilities of Large Language\nModels (LLMs) for spatial understanding and reasoning. Our evaluation of\nAPI-based and open-sourced LLMs shows that while some commercial LLMs exhibit\nstrong reasoning abilities, open-sourced competitors can demonstrate almost the\nsame level of quality; however, all models still have significant room for\nimprovement. We identify typical reasons for LLM failures and discuss possible\nways to deal with them. Datasets and evaluation code are released\n(https://github.com/altsoph/PLUGH).", "published": "2024-08-03 13:21:08", "link": "http://arxiv.org/abs/2408.04648v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "68T50, 68T20", "I.2.7; I.2.8; G.2.2"], "primary_category": "cs.CL"}
{"title": "Building Trust in Mental Health Chatbots: Safety Metrics and LLM-Based\n  Evaluation Tools", "abstract": "Objective: This study aims to develop and validate an evaluation framework to\nensure the safety and reliability of mental health chatbots, which are\nincreasingly popular due to their accessibility, human-like interactions, and\ncontext-aware support. Materials and Methods: We created an evaluation\nframework with 100 benchmark questions and ideal responses, and five guideline\nquestions for chatbot responses. This framework, validated by mental health\nexperts, was tested on a GPT-3.5-turbo-based chatbot. Automated evaluation\nmethods explored included large language model (LLM)-based scoring, an agentic\napproach using real-time data, and embedding models to compare chatbot\nresponses against ground truth standards. Results: The results highlight the\nimportance of guidelines and ground truth for improving LLM evaluation\naccuracy. The agentic method, dynamically accessing reliable information,\ndemonstrated the best alignment with human assessments. Adherence to a\nstandardized, expert-validated framework significantly enhanced chatbot\nresponse safety and reliability. Discussion: Our findings emphasize the need\nfor comprehensive, expert-tailored safety evaluation metrics for mental health\nchatbots. While LLMs have significant potential, careful implementation is\nnecessary to mitigate risks. The superior performance of the agentic approach\nunderscores the importance of real-time data access in enhancing chatbot\nreliability. Conclusion: The study validated an evaluation framework for mental\nhealth chatbots, proving its effectiveness in improving safety and reliability.\nFuture work should extend evaluations to accuracy, bias, empathy, and privacy\nto ensure holistic assessment and responsible integration into healthcare.\nStandardized evaluations will build trust among users and professionals,\nfacilitating broader adoption and improved mental health support through\ntechnology.", "published": "2024-08-03 19:57:49", "link": "http://arxiv.org/abs/2408.04650v2", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MALADE: Orchestration of LLM-powered Agents with Retrieval Augmented\n  Generation for Pharmacovigilance", "abstract": "In the era of Large Language Models (LLMs), given their remarkable text\nunderstanding and generation abilities, there is an unprecedented opportunity\nto develop new, LLM-based methods for trustworthy medical knowledge synthesis,\nextraction and summarization. This paper focuses on the problem of\nPharmacovigilance (PhV), where the significance and challenges lie in\nidentifying Adverse Drug Events (ADEs) from diverse text sources, such as\nmedical literature, clinical notes, and drug labels. Unfortunately, this task\nis hindered by factors including variations in the terminologies of drugs and\noutcomes, and ADE descriptions often being buried in large amounts of narrative\ntext. We present MALADE, the first effective collaborative multi-agent system\npowered by LLM with Retrieval Augmented Generation for ADE extraction from drug\nlabel data. This technique involves augmenting a query to an LLM with relevant\ninformation extracted from text resources, and instructing the LLM to compose a\nresponse consistent with the augmented data. MALADE is a general LLM-agnostic\narchitecture, and its unique capabilities are: (1) leveraging a variety of\nexternal sources, such as medical literature, drug labels, and FDA tools (e.g.,\nOpenFDA drug information API), (2) extracting drug-outcome association in a\nstructured format along with the strength of the association, and (3) providing\nexplanations for established associations. Instantiated with GPT-4 Turbo or\nGPT-4o, and FDA drug label data, MALADE demonstrates its efficacy with an Area\nUnder ROC Curve of 0.90 against the OMOP Ground Truth table of ADEs. Our\nimplementation leverages the Langroid multi-agent LLM framework and can be\nfound at https://github.com/jihyechoi77/malade.", "published": "2024-08-03 22:14:13", "link": "http://arxiv.org/abs/2408.01869v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG", "cs.MA", "q-bio.QM"], "primary_category": "cs.CL"}
{"title": "Generating High-quality Symbolic Music Using Fine-grained Discriminators", "abstract": "Existing symbolic music generation methods usually utilize discriminator to\nimprove the quality of generated music via global perception of music. However,\nconsidering the complexity of information in music, such as rhythm and melody,\na single discriminator cannot fully reflect the differences in these two\nprimary dimensions of music. In this work, we propose to decouple the melody\nand rhythm from music, and design corresponding fine-grained discriminators to\ntackle the aforementioned issues. Specifically, equipped with a pitch\naugmentation strategy, the melody discriminator discerns the melody variations\npresented by the generated samples. By contrast, the rhythm discriminator,\nenhanced with bar-level relative positional encoding, focuses on the velocity\nof generated notes. Such a design allows the generator to be more explicitly\naware of which aspects should be adjusted in the generated music, making it\neasier to mimic human-composed music. Experimental results on the POP909\nbenchmark demonstrate the favorable performance of the proposed method compared\nto several state-of-the-art methods in terms of both objective and subjective\nmetrics.", "published": "2024-08-03 07:32:21", "link": "http://arxiv.org/abs/2408.01696v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ALIF: Low-Cost Adversarial Audio Attacks on Black-Box Speech Platforms\n  using Linguistic Features", "abstract": "Extensive research has revealed that adversarial examples (AE) pose a\nsignificant threat to voice-controllable smart devices. Recent studies have\nproposed black-box adversarial attacks that require only the final\ntranscription from an automatic speech recognition (ASR) system. However, these\nattacks typically involve many queries to the ASR, resulting in substantial\ncosts. Moreover, AE-based adversarial audio samples are susceptible to ASR\nupdates. In this paper, we identify the root cause of these limitations, namely\nthe inability to construct AE attack samples directly around the decision\nboundary of deep learning (DL) models. Building on this observation, we propose\nALIF, the first black-box adversarial linguistic feature-based attack pipeline.\nWe leverage the reciprocal process of text-to-speech (TTS) and ASR models to\ngenerate perturbations in the linguistic embedding space where the decision\nboundary resides. Based on the ALIF pipeline, we present the ALIF-OTL and\nALIF-OTA schemes for launching attacks in both the digital domain and the\nphysical playback environment on four commercial ASRs and voice assistants.\nExtensive evaluations demonstrate that ALIF-OTL and -OTA significantly improve\nquery efficiency by 97.7% and 73.3%, respectively, while achieving competitive\nperformance compared to existing methods. Notably, ALIF-OTL can generate an\nattack sample with only one query. Furthermore, our test-of-time experiment\nvalidates the robustness of our approach against ASR updates.", "published": "2024-08-03 15:30:16", "link": "http://arxiv.org/abs/2408.01808v1", "categories": ["cs.CR", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CR"}
