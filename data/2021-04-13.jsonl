{"title": "Discourse Probing of Pretrained Language Models", "abstract": "Existing work on probing of pretrained language models (LMs) has\npredominantly focused on sentence-level syntactic tasks. In this paper, we\nintroduce document-level discourse probing to evaluate the ability of\npretrained LMs to capture document-level relations. We experiment with 7\npretrained LMs, 4 languages, and 7 discourse probing tasks, and find BART to be\noverall the best model at capturing discourse -- but only in its encoder, with\nBERT performing surprisingly well as the baseline model. Across the different\nmodels, there are substantial differences in which layers best capture\ndiscourse information, and large disparities between models.", "published": "2021-04-13 01:04:31", "link": "http://arxiv.org/abs/2104.05882v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Step Reasoning Over Unstructured Text with Beam Dense Retrieval", "abstract": "Complex question answering often requires finding a reasoning chain that\nconsists of multiple evidence pieces. Current approaches incorporate the\nstrengths of structured knowledge and unstructured text, assuming text corpora\nis semi-structured. Building on dense retrieval methods, we propose a new\nmulti-step retrieval approach (BeamDR) that iteratively forms an evidence chain\nthrough beam search in dense representations. When evaluated on multi-hop\nquestion answering, BeamDR is competitive to state-of-the-art systems, without\nusing any semi-structured information. Through query composition in dense\nspace, BeamDR captures the implicit relationships between evidence in the\nreasoning chain. The code is available at https://github.com/\nhenryzhao5852/BeamDR.", "published": "2021-04-13 01:16:48", "link": "http://arxiv.org/abs/2104.05883v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DirectProbe: Studying Representations without Classifiers", "abstract": "Understanding how linguistic structures are encoded in contextualized\nembedding could help explain their impressive performance across NLP@. Existing\napproaches for probing them usually call for training classifiers and use the\naccuracy, mutual information, or complexity as a proxy for the representation's\ngoodness. In this work, we argue that doing so can be unreliable because\ndifferent representations may need different classifiers. We develop a\nheuristic, DirectProbe, that directly studies the geometry of a representation\nby building upon the notion of a version space for a task. Experiments with\nseveral linguistic tasks and contextualized embeddings show that, even without\ntraining classifiers, DirectProbe can shine light into how an embedding space\nrepresents labels, and also anticipate classifier performance for the\nrepresentation.", "published": "2021-04-13 02:40:26", "link": "http://arxiv.org/abs/2104.05904v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Document-Level Event Argument Extraction by Conditional Generation", "abstract": "Event extraction has long been treated as a sentence-level task in the IE\ncommunity. We argue that this setting does not match human information-seeking\nbehavior and leads to incomplete and uninformative extraction results. We\npropose a document-level neural event argument extraction model by formulating\nthe task as conditional generation following event templates. We also compile a\nnew document-level event extraction benchmark dataset WikiEvents which includes\ncomplete event and coreference annotation. On the task of argument extraction,\nwe achieve an absolute gain of 7.6% F1 and 5.7% F1 over the next best model on\nthe RAMS and WikiEvents datasets respectively. On the more challenging task of\ninformative argument extraction, which requires implicit coreference reasoning,\nwe achieve a 9.3% F1 gain over the best baseline. To demonstrate the\nportability of our model, we also create the first end-to-end zero-shot event\nextraction framework and achieve 97% of fully supervised model's trigger\nextraction performance and 82% of the argument extraction performance given\nonly access to 10 out of the 33 types on ACE.", "published": "2021-04-13 03:36:38", "link": "http://arxiv.org/abs/2104.05919v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "QMSum: A New Benchmark for Query-based Multi-domain Meeting\n  Summarization", "abstract": "Meetings are a key component of human collaboration. As increasing numbers of\nmeetings are recorded and transcribed, meeting summaries have become essential\nto remind those who may or may not have attended the meetings about the key\ndecisions made and the tasks to be completed. However, it is hard to create a\nsingle short summary that covers all the content of a long meeting involving\nmultiple people and topics. In order to satisfy the needs of different types of\nusers, we define a new query-based multi-domain meeting summarization task,\nwhere models have to select and summarize relevant spans of meetings in\nresponse to a query, and we introduce QMSum, a new benchmark for this task.\nQMSum consists of 1,808 query-summary pairs over 232 meetings in multiple\ndomains. Besides, we investigate a locate-then-summarize method and evaluate a\nset of strong summarization baselines on the task. Experimental results and\nmanual analysis reveal that QMSum presents significant challenges in long\nmeeting summarization for future research. Dataset is available at\n\\url{https://github.com/Yale-LILY/QMSum}.", "published": "2021-04-13 05:00:35", "link": "http://arxiv.org/abs/2104.05938v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Gender Bias in Machine Translation", "abstract": "Machine translation (MT) technology has facilitated our daily tasks by\nproviding accessible shortcuts for gathering, elaborating and communicating\ninformation. However, it can suffer from biases that harm users and society at\nlarge. As a relatively new field of inquiry, gender bias in MT still lacks\ninternal cohesion, which advocates for a unified framework to ease future\nresearch. To this end, we: i) critically review current conceptualizations of\nbias in light of theoretical insights from related disciplines, ii) summarize\nprevious analyses aimed at assessing gender bias in MT, iii) discuss the\nmitigating strategies proposed so far, and iv) point toward potential\ndirections for future work.", "published": "2021-04-13 08:09:03", "link": "http://arxiv.org/abs/2104.06001v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What's in your Head? Emergent Behaviour in Multi-Task Transformer Models", "abstract": "The primary paradigm for multi-task training in natural language processing\nis to represent the input with a shared pre-trained language model, and add a\nsmall, thin network (head) per task. Given an input, a target head is the head\nthat is selected for outputting the final prediction. In this work, we examine\nthe behaviour of non-target heads, that is, the output of heads when given\ninput that belongs to a different task than the one they were trained for. We\nfind that non-target heads exhibit emergent behaviour, which may either explain\nthe target task, or generalize beyond their original task. For example, in a\nnumerical reasoning task, a span extraction head extracts from the input the\narguments to a computation that results in a number generated by a target\ngenerative head. In addition, a summarization head that is trained with a\ntarget question answering head, outputs query-based summaries when given a\nquestion and a context from which the answer is to be extracted. This emergent\nbehaviour suggests that multi-task training leads to non-trivial extrapolation\nof skills, which can be harnessed for interpretability and generalization.", "published": "2021-04-13 12:04:30", "link": "http://arxiv.org/abs/2104.06129v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Impact of Knowledge-based Linguistic Annotations in the Quality\n  of Scientific Embeddings", "abstract": "In essence, embedding algorithms work by optimizing the distance between a\nword and its usual context in order to generate an embedding space that encodes\nthe distributional representation of words. In addition to single words or word\npieces, other features which result from the linguistic analysis of text,\nincluding lexical, grammatical and semantic information, can be used to improve\nthe quality of embedding spaces. However, until now we did not have a precise\nunderstanding of the impact that such individual annotations and their possible\ncombinations may have in the quality of the embeddings. In this paper, we\nconduct a comprehensive study on the use of explicit linguistic annotations to\ngenerate embeddings from a scientific corpus and quantify their impact in the\nresulting representations. Our results show how the effect of such annotations\nin the embeddings varies depending on the evaluation task. In general, we\nobserve that learning embeddings using linguistic annotations contributes to\nachieve better evaluation results.", "published": "2021-04-13 13:51:22", "link": "http://arxiv.org/abs/2104.06200v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GLaRA: Graph-based Labeling Rule Augmentation for Weakly Supervised\n  Named Entity Recognition", "abstract": "Instead of using expensive manual annotations, researchers have proposed to\ntrain named entity recognition (NER) systems using heuristic labeling rules.\nHowever, devising labeling rules is challenging because it often requires a\nconsiderable amount of manual effort and domain expertise. To alleviate this\nproblem, we propose \\textsc{GLaRA}, a graph-based labeling rule augmentation\nframework, to learn new labeling rules from unlabeled data. We first create a\ngraph with nodes representing candidate rules extracted from unlabeled data.\nThen, we design a new graph neural network to augment labeling rules by\nexploring the semantic relations between rules. We finally apply the augmented\nrules on unlabeled data to generate weak labels and train a NER model using the\nweakly labeled data. We evaluate our method on three NER datasets and find that\nwe can achieve an average improvement of +20\\% F1 score over the best baseline\nwhen given a small set of seed rules.", "published": "2021-04-13 14:20:58", "link": "http://arxiv.org/abs/2104.06230v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modeling the dynamics of language change: logistic regression,\n  Piotrowski's law, and a handful of examples in Polish", "abstract": "The study discusses modeling diachronic processes by logistic regression. The\nphenomenon of nonlinear changes in language was first observed by Raimund\nPiotrowski (hence labelled as Piotrowski's law), even if actual linguistic\nevidence usually speaks against using the notion of a \"law\" in this context. In\nour study, we apply logistic regression models to 9 changes which occurred\nbetween 15th and 18th century in the Polish language. The attested course of\nthe majority of these changes closely follow the expected values, which proves\nthat the language change might indeed resemble a nonlinear phase change\nscenario. We also extend the original Piotrowski's approach by proposing\npolynomial logistic regression for these cases which can hardly be described by\nits standard version. Also, we propose to consider individual language change\ncases jointly, in order to inspect their possible collinearity or, more likely,\ntheir different dynamics in the function of time. Last but not least, we\nevaluate our results by testing the influence of the subcorpus size on the\nmodel's goodness-of-fit.", "published": "2021-04-13 16:03:36", "link": "http://arxiv.org/abs/2104.06324v3", "categories": ["cs.CL", "91F20, 62J02", "J.5"], "primary_category": "cs.CL"}
{"title": "Finding Concept-specific Biases in Form--Meaning Associations", "abstract": "This work presents an information-theoretic operationalisation of\ncross-linguistic non-arbitrariness. It is not a new idea that there are small,\ncross-linguistic associations between the forms and meanings of words. For\ninstance, it has been claimed (Blasi et al., 2016) that the word for \"tongue\"\nis more likely than chance to contain the phone [l]. By controlling for the\ninfluence of language family and geographic proximity within a very large\nconcept-aligned, cross-lingual lexicon, we extend methods previously used to\ndetect within language non-arbitrariness (Pimentel et al., 2019) to measure\ncross-linguistic associations. We find that there is a significant effect of\nnon-arbitrariness, but it is unsurprisingly small (less than 0.5% on average\naccording to our information-theoretic estimate). We also provide a\nconcept-level analysis which shows that a quarter of the concepts considered in\nour work exhibit a significant level of cross-linguistic non-arbitrariness. In\nsum, the paper provides new methods to detect cross-linguistic associations at\nscale, and confirms their effects are minor.", "published": "2021-04-13 16:07:54", "link": "http://arxiv.org/abs/2104.06325v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Impact of Random Seeds on the Fairness of Clinical Classifiers", "abstract": "Recent work has shown that fine-tuning large networks is surprisingly\nsensitive to changes in random seed(s). We explore the implications of this\nphenomenon for model fairness across demographic groups in clinical prediction\ntasks over electronic health records (EHR) in MIMIC-III -- the standard dataset\nin clinical NLP research. Apparent subgroup performance varies substantially\nfor seeds that yield similar overall performance, although there is no evidence\nof a trade-off between overall and subgroup performance. However, we also find\nthat the small sample sizes inherent to looking at intersections of minority\ngroups and somewhat rare conditions limit our ability to accurately estimate\ndisparities. Further, we find that jointly optimizing for high overall\nperformance and low disparities does not yield statistically significant\nimprovements. Our results suggest that fairness work using MIMIC-III should\ncarefully account for variations in apparent differences that may arise from\nstochasticity and small sample sizes.", "published": "2021-04-13 16:30:39", "link": "http://arxiv.org/abs/2104.06338v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mediators in Determining what Processing BERT Performs First", "abstract": "Probing neural models for the ability to perform downstream tasks using their\nactivation patterns is often used to localize what parts of the network\nspecialize in performing what tasks. However, little work addressed potential\nmediating factors in such comparisons. As a test-case mediating factor, we\nconsider the prediction's context length, namely the length of the span whose\nprocessing is minimally required to perform the prediction. We show that not\ncontrolling for context length may lead to contradictory conclusions as to the\nlocalization patterns of the network, depending on the distribution of the\nprobing dataset. Indeed, when probing BERT with seven tasks, we find that it is\npossible to get 196 different rankings between them when manipulating the\ndistribution of context lengths in the probing dataset. We conclude by\npresenting best practices for conducting such comparisons in the future.", "published": "2021-04-13 17:58:52", "link": "http://arxiv.org/abs/2104.06400v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Zhestyatsky at SemEval-2021 Task 2: ReLU over Cosine Similarity for BERT\n  Fine-tuning", "abstract": "This paper presents our contribution to SemEval-2021 Task 2: Multilingual and\nCross-lingual Word-in-Context Disambiguation (MCL-WiC). Our experiments cover\nEnglish (EN-EN) sub-track from the multilingual setting of the task. We\nexperiment with several pre-trained language models and investigate an impact\nof different top-layers on fine-tuning. We find the combination of Cosine\nSimilarity and ReLU activation leading to the most effective fine-tuning\nprocedure. Our best model results in accuracy 92.7%, which is the fourth-best\nscore in EN-EN sub-track.", "published": "2021-04-13 18:28:58", "link": "http://arxiv.org/abs/2104.06439v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Interpretability and Significance of Bias Metrics in Texts: a\n  PMI-based Approach", "abstract": "In recent years, word embeddings have been widely used to measure biases in\ntexts. Even if they have proven to be effective in detecting a wide variety of\nbiases, metrics based on word embeddings lack transparency and\ninterpretability. We analyze an alternative PMI-based metric to quantify biases\nin texts. It can be expressed as a function of conditional probabilities, which\nprovides a simple interpretation in terms of word co-occurrences. We also prove\nthat it can be approximated by an odds ratio, which allows estimating\nconfidence intervals and statistical significance of textual biases. This\napproach produces similar results to metrics based on word embeddings when\ncapturing gender gaps of the real world embedded in large corpora.", "published": "2021-04-13 19:34:17", "link": "http://arxiv.org/abs/2104.06474v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can a Transformer Pass the Wug Test? Tuning Copying Bias in Neural\n  Morphological Inflection Models", "abstract": "Deep learning sequence models have been successfully applied to the task of\nmorphological inflection. The results of the SIGMORPHON shared tasks in the\npast several years indicate that such models can perform well, but only if the\ntraining data cover a good amount of different lemmata, or if the lemmata that\nare inflected at test time have also been seen in training, as has indeed been\nlargely the case in these tasks. Surprisingly, standard models such as the\nTransformer almost completely fail at generalizing inflection patterns when\nasked to inflect previously unseen lemmata -- i.e. under \"wug test\"-like\ncircumstances. While established data augmentation techniques can be employed\nto alleviate this shortcoming by introducing a copying bias through\nhallucinating synthetic new word forms using the alphabet in the language at\nhand, we show that, to be more effective, the hallucination process needs to\npay attention to substrings of syllable-like length rather than individual\ncharacters or stems. We report a significant performance improvement with our\nsubstring-based hallucination model over previous data hallucination methods\nwhen training and test data do not overlap in their lemmata.", "published": "2021-04-13 19:51:21", "link": "http://arxiv.org/abs/2104.06483v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "\"I'm Not Mad\": Commonsense Implications of Negation and Contradiction", "abstract": "Natural language inference requires reasoning about contradictions,\nnegations, and their commonsense implications. Given a simple premise (e.g.,\n\"I'm mad at you\"), humans can reason about the varying shades of contradictory\nstatements ranging from straightforward negations (\"I'm not mad at you\") to\ncommonsense contradictions (\"I'm happy\"). Moreover, these negated or\ncontradictory statements shift the commonsense implications of the original\npremise in nontrivial ways. For example, while \"I'm mad\" implies \"I'm unhappy\nabout something,\" negating the premise (i.e., \"I'm not mad\") does not\nnecessarily negate the corresponding commonsense implications.\n  In this paper, we present the first comprehensive study focusing on\ncommonsense implications of negated statements and contradictions. We introduce\nANION1, a new commonsense knowledge graph with 624K if-then rules focusing on\nnegated and contradictory events. We then present joint generative and\ndiscriminative inference models for this new resource, providing novel\nempirical insights on how logical negations and commonsense contradictions\nreshape the commonsense implications of their original premises.", "published": "2021-04-13 20:51:46", "link": "http://arxiv.org/abs/2104.06511v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Solving a Problem Boldly to Cutting the Gordian Knot: Idiomatic\n  Text Generation", "abstract": "We study a new application for text generation -- idiomatic sentence\ngeneration -- which aims to transfer literal phrases in sentences into their\nidiomatic counterparts. Inspired by psycholinguistic theories of idiom use in\none's native language, we propose a novel approach for this task, which\nretrieves the appropriate idiom for a given literal sentence, extracts the span\nof the sentence to be replaced by the idiom, and generates the idiomatic\nsentence by using a neural model to combine the retrieved idiom and the\nremainder of the sentence. Experiments on a novel dataset created for this task\nshow that our model is able to effectively transfer literal sentences into\nidiomatic ones. Furthermore, automatic and human evaluations show that for this\ntask, the proposed model outperforms a series of competitive baseline models\nfor text generation.", "published": "2021-04-13 22:57:25", "link": "http://arxiv.org/abs/2104.06541v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large-Scale Contextualised Language Modelling for Norwegian", "abstract": "We present the ongoing NorLM initiative to support the creation and use of\nvery large contextualised language models for Norwegian (and in principle other\nNordic languages), including a ready-to-use software environment, as well as an\nexperience report for data preparation and training. This paper introduces the\nfirst large-scale monolingual language models for Norwegian, based on both the\nELMo and BERT frameworks. In addition to detailing the training process, we\npresent contrastive benchmark results on a suite of NLP tasks for Norwegian.\nFor additional background and access to the data, models, and software, please\nsee http://norlm.nlpl.eu", "published": "2021-04-13 23:18:04", "link": "http://arxiv.org/abs/2104.06546v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NewsCLIPpings: Automatic Generation of Out-of-Context Multimodal Media", "abstract": "Online misinformation is a prevalent societal issue, with adversaries relying\non tools ranging from cheap fakes to sophisticated deep fakes. We are motivated\nby the threat scenario where an image is used out of context to support a\ncertain narrative. While some prior datasets for detecting image-text\ninconsistency generate samples via text manipulation, we propose a dataset\nwhere both image and text are unmanipulated but mismatched. We introduce\nseveral strategies for automatically retrieving convincing images for a given\ncaption, capturing cases with inconsistent entities or semantic context. Our\nlarge-scale automatically generated NewsCLIPpings Dataset: (1) demonstrates\nthat machine-driven image repurposing is now a realistic threat, and (2)\nprovides samples that represent challenging instances of mismatch between text\nand image in news that are able to mislead humans. We benchmark several\nstate-of-the-art multimodal models on our dataset and analyze their performance\nacross different pretraining domains and visual backbones.", "published": "2021-04-13 01:53:26", "link": "http://arxiv.org/abs/2104.05893v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "\"Subverting the Jewtocracy\": Online Antisemitism Detection Using\n  Multimodal Deep Learning", "abstract": "The exponential rise of online social media has enabled the creation,\ndistribution, and consumption of information at an unprecedented rate. However,\nit has also led to the burgeoning of various forms of online abuse. Increasing\ncases of online antisemitism have become one of the major concerns because of\nits socio-political consequences. Unlike other major forms of online abuse like\nracism, sexism, etc., online antisemitism has not been studied much from a\nmachine learning perspective. To the best of our knowledge, we present the\nfirst work in the direction of automated multimodal detection of online\nantisemitism. The task poses multiple challenges that include extracting\nsignals across multiple modalities, contextual references, and handling\nmultiple aspects of antisemitism. Unfortunately, there does not exist any\npublicly available benchmark corpus for this critical task. Hence, we collect\nand label two datasets with 3,102 and 3,509 social media posts from Twitter and\nGab respectively. Further, we present a multimodal deep learning system that\ndetects the presence of antisemitic content and its specific antisemitism\ncategory using text and images from posts. We perform an extensive set of\nexperiments on the two datasets to evaluate the efficacy of the proposed\nsystem. Finally, we also present a qualitative analysis of our study.", "published": "2021-04-13 05:22:55", "link": "http://arxiv.org/abs/2104.05947v3", "categories": ["cs.MM", "cs.CL"], "primary_category": "cs.MM"}
{"title": "Restoring and Mining the Records of the Joseon Dynasty via Neural\n  Language Modeling and Machine Translation", "abstract": "Understanding voluminous historical records provides clues on the past in\nvarious aspects, such as social and political issues and even natural science\nfacts. However, it is generally difficult to fully utilize the historical\nrecords, since most of the documents are not written in a modern language and\npart of the contents are damaged over time. As a result, restoring the damaged\nor unrecognizable parts as well as translating the records into modern\nlanguages are crucial tasks. In response, we present a multi-task learning\napproach to restore and translate historical documents based on a\nself-attention mechanism, specifically utilizing two Korean historical records,\nones of the most voluminous historical records in the world. Experimental\nresults show that our approach significantly improves the accuracy of the\ntranslation task than baselines without multi-task learning. In addition, we\npresent an in-depth exploratory analysis on our translated results via topic\nmodeling, uncovering several significant historical events.", "published": "2021-04-13 06:40:25", "link": "http://arxiv.org/abs/2104.05964v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Dealing with Missing Modalities in the Visual Question Answer-Difference\n  Prediction Task through Knowledge Distillation", "abstract": "In this work, we address the issues of missing modalities that have arisen\nfrom the Visual Question Answer-Difference prediction task and find a novel\nmethod to solve the task at hand. We address the missing modality-the ground\ntruth answers-that are not present at test time and use a privileged knowledge\ndistillation scheme to deal with the issue of the missing modality. In order to\nefficiently do so, we first introduce a model, the \"Big\" Teacher, that takes\nthe image/question/answer triplet as its input and outperforms the baseline,\nthen use a combination of models to distill knowledge to a target network\n(student) that only takes the image/question pair as its inputs. We experiment\nour models on the VizWiz and VQA-V2 Answer Difference datasets and show through\nextensive experimentation and ablation the performances of our method and a\ndiverse possibility for future research.", "published": "2021-04-13 06:41:11", "link": "http://arxiv.org/abs/2104.05965v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Disentangled Motif-aware Graph Learning for Phrase Grounding", "abstract": "In this paper, we propose a novel graph learning framework for phrase\ngrounding in the image. Developing from the sequential to the dense graph\nmodel, existing works capture coarse-grained context but fail to distinguish\nthe diversity of context among phrases and image regions. In contrast, we pay\nspecial attention to different motifs implied in the context of the scene graph\nand devise the disentangled graph network to integrate the motif-aware\ncontextual information into representations. Besides, we adopt interventional\nstrategies at the feature and the structure levels to consolidate and\ngeneralize representations. Finally, the cross-modal attention network is\nutilized to fuse intra-modal features, where each phrase can be computed\nsimilarity with regions to select the best-grounded one. We validate the\nefficiency of disentangled and interventional graph network (DIGN) through a\nseries of ablation studies, and our model achieves state-of-the-art performance\non Flickr30K Entities and ReferIt Game benchmarks.", "published": "2021-04-13 08:20:07", "link": "http://arxiv.org/abs/2104.06008v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Lessons on Parameter Sharing across Layers in Transformers", "abstract": "We propose a parameter sharing method for Transformers (Vaswani et al.,\n2017). The proposed approach relaxes a widely used technique, which shares\nparameters for one layer with all layers such as Universal Transformers\n(Dehghani et al., 2019), to increase the efficiency in the computational time.\nWe propose three strategies: Sequence, Cycle, and Cycle (rev) to assign\nparameters to each layer. Experimental results show that the proposed\nstrategies are efficient in the parameter size and computational time.\nMoreover, we indicate that the proposed strategies are also effective in the\nconfiguration where we use many training data such as the recent WMT\ncompetition.", "published": "2021-04-13 08:41:07", "link": "http://arxiv.org/abs/2104.06022v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Structural analysis of an all-purpose question answering model", "abstract": "Attention is a key component of the now ubiquitous pre-trained language\nmodels. By learning to focus on relevant pieces of information, these\nTransformer-based architectures have proven capable of tackling several tasks\nat once and sometimes even surpass their single-task counterparts. To better\nunderstand this phenomenon, we conduct a structural analysis of a new\nall-purpose question answering model that we introduce. Surprisingly, this\nmodel retains single-task performance even in the absence of a strong transfer\neffect between tasks. Through attention head importance scoring, we observe\nthat attention heads specialize in a particular task and that some heads are\nmore conducive to learning than others in both the multi-task and single-task\nsettings.", "published": "2021-04-13 09:20:44", "link": "http://arxiv.org/abs/2104.06045v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Transformer-based Methods for Recognizing Ultra Fine-grained Entities\n  (RUFES)", "abstract": "This paper summarizes the participation of the Laboratoire Informatique,\nImage et Interaction (L3i laboratory) of the University of La Rochelle in the\nRecognizing Ultra Fine-grained Entities (RUFES) track within the Text Analysis\nConference (TAC) series of evaluation workshops. Our participation relies on\ntwo neural-based models, one based on a pre-trained and fine-tuned language\nmodel with a stack of Transformer layers for fine-grained entity extraction and\none out-of-the-box model for within-document entity coreference. We observe\nthat our approach has great potential in increasing the performance of\nfine-grained entity recognition. Thus, the future work envisioned is to enhance\nthe ability of the models following additional experiments and a deeper\nanalysis of the results.", "published": "2021-04-13 09:23:16", "link": "http://arxiv.org/abs/2104.06048v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "UPB at SemEval-2021 Task 7: Adversarial Multi-Task Learning for\n  Detecting and Rating Humor and Offense", "abstract": "Detecting humor is a challenging task since words might share multiple\nvalences and, depending on the context, the same words can be even used in\noffensive expressions. Neural network architectures based on Transformer obtain\nstate-of-the-art results on several Natural Language Processing tasks,\nespecially text classification. Adversarial learning, combined with other\ntechniques such as multi-task learning, aids neural models learn the intrinsic\nproperties of data. In this work, we describe our adversarial multi-task\nnetwork, AMTL-Humor, used to detect and rate humor and offensive texts from\nTask 7 at SemEval-2021. Each branch from the model is focused on solving a\nrelated task, and consists of a BiLSTM layer followed by Capsule layers, on top\nof BERTweet used for generating contextualized embeddings. Our best model\nconsists of an ensemble of all tested configurations, and achieves a 95.66%\nF1-score and 94.70% accuracy for Task 1a, while obtaining RMSE scores of 0.6200\nand 0.5318 for Tasks 1b and 2, respectively.", "published": "2021-04-13 09:59:05", "link": "http://arxiv.org/abs/2104.06063v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Equivalence of Segmental and Neural Transducer Modeling: A Proof of\n  Concept", "abstract": "With the advent of direct models in automatic speech recognition (ASR), the\nformerly prevalent frame-wise acoustic modeling based on hidden Markov models\n(HMM) diversified into a number of modeling architectures like encoder-decoder\nattention models, transducer models and segmental models (direct HMM). While\ntransducer models stay with a frame-level model definition, segmental models\nare defined on the level of label segments directly. While\n(soft-)attention-based models avoid explicit alignment, transducer and\nsegmental approach internally do model alignment, either by segment hypotheses\nor, more implicitly, by emitting so-called blank symbols. In this work, we\nprove that the widely used class of RNN-Transducer models and segmental models\n(direct HMM) are equivalent and therefore show equal modeling power. It is\nshown that blank probabilities translate into segment length probabilities and\nvice versa. In addition, we provide initial experiments investigating decoding\nand beam-pruning, comparing time-synchronous and label-/segment-synchronous\nsearch strategies and their properties using the same underlying model.", "published": "2021-04-13 11:20:48", "link": "http://arxiv.org/abs/2104.06104v2", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Understanding Transformers for Bot Detection in Twitter", "abstract": "In this paper we shed light on the impact of fine-tuning over social media\ndata in the internal representations of neural language models. We focus on bot\ndetection in Twitter, a key task to mitigate and counteract the automatic\nspreading of disinformation and bias in social media. We investigate the use of\npre-trained language models to tackle the detection of tweets generated by a\nbot or a human account based exclusively on its content. Unlike the general\ntrend in benchmarks like GLUE, where BERT generally outperforms generative\ntransformers like GPT and GPT-2 for most classification tasks on regular text,\nwe observe that fine-tuning generative transformers on a bot detection task\nproduces higher accuracies. We analyze the architectural components of each\ntransformer and study the effect of fine-tuning on their hidden states and\noutput representations. Among our findings, we show that part of the\nsyntactical information and distributional properties captured by BERT during\npre-training is lost upon fine-tuning while the generative pre-training\napproach manage to preserve these properties.", "published": "2021-04-13 13:32:55", "link": "http://arxiv.org/abs/2104.06182v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Reducing Discontinuous to Continuous Parsing with Pointer Network\n  Reordering", "abstract": "Discontinuous constituent parsers have always lagged behind continuous\napproaches in terms of accuracy and speed, as the presence of constituents with\ndiscontinuous yield introduces extra complexity to the task. However, a\ndiscontinuous tree can be converted into a continuous variant by reordering\ntokens. Based on that, we propose to reduce discontinuous parsing to a\ncontinuous problem, which can then be directly solved by any off-the-shelf\ncontinuous parser. To that end, we develop a Pointer Network capable of\naccurately generating the continuous token arrangement for a given input\nsentence and define a bijective function to recover the original order.\nExperiments on the main benchmarks with two continuous parsers prove that our\napproach is on par in accuracy with purely discontinuous state-of-the-art\nalgorithms, but considerably faster.", "published": "2021-04-13 14:32:59", "link": "http://arxiv.org/abs/2104.06239v2", "categories": ["cs.CL", "cs.AI", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Understanding Hard Negatives in Noise Contrastive Estimation", "abstract": "The choice of negative examples is important in noise contrastive estimation.\nRecent works find that hard negatives -- highest-scoring incorrect examples\nunder the model -- are effective in practice, but they are used without a\nformal justification. We develop analytical tools to understand the role of\nhard negatives. Specifically, we view the contrastive loss as a biased\nestimator of the gradient of the cross-entropy loss, and show both\ntheoretically and empirically that setting the negative distribution to be the\nmodel distribution results in bias reduction. We also derive a general form of\nthe score function that unifies various architectures used in text retrieval.\nBy combining hard negatives with appropriate score functions, we obtain strong\nresults on the challenging task of zero-shot entity linking.", "published": "2021-04-13 14:42:41", "link": "http://arxiv.org/abs/2104.06245v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Tale of Two Lexica Testing Computational Hypotheses with Deep\n  Convolutional Neural Networks", "abstract": "Gow's (2012) dual lexicon model suggests that the primary purpose of words is\nto mediate the mappings between acoustic-phonetic input and other forms of\nlinguistic representation. Motivated by evidence from functional imaging,\naphasia, and behavioral results, the model argues for the existence of two\nparallel wordform stores: the dorsal and ventral processing streams. In this\npaper, we tested the hypothesis that the complex, but systematic mapping\nbetween sound and articulation in the dorsal stream poses different\ncomputational pressures on feature sets than the more arbitrary mapping between\nsound and meaning. To test this hypothesis, we created two deep convolutional\nneural networks (CNNs). While the dorsal network was trained to identify\nindividual spoken words, the ventral network was trained to map them onto\nsemantic classes. We then extracted patterns of network activation from the\npenultimate level of each network and tested how well features generated by the\nnetwork supported generalization to linguistic categorization associated with\nthe dorsal versus ventral processing streams. Our preliminary results showed\nboth models successfully learned their tasks. Secondary generalization testing\nshowed the ventral CNN outperformed the dorsal CNN on a semantic task:\nconcreteness classification, while the dorsal CNN outperformed the ventral CNN\non articulation tasks: classification by onset phoneme class and syllable\nlength. These results are consistent with the hypothesis that the divergent\nprocessing demands of the ventral and dorsal processing streams impose\ncomputational pressures for the development of multiple lexica.", "published": "2021-04-13 15:03:14", "link": "http://arxiv.org/abs/2104.06271v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "On the Use of Linguistic Features for the Evaluation of Generative\n  Dialogue Systems", "abstract": "Automatically evaluating text-based, non-task-oriented dialogue systems\n(i.e., `chatbots') remains an open problem. Previous approaches have suffered\nchallenges ranging from poor correlation with human judgment to poor\ngeneralization and have often required a gold standard reference for comparison\nor human-annotated data. Extending existing evaluation methods, we propose that\na metric based on linguistic features may be able to maintain good correlation\nwith human judgment and be interpretable, without requiring a gold-standard\nreference or human-annotated data. To support this proposition, we measure and\nanalyze various linguistic features on dialogues produced by multiple dialogue\nmodels. We find that the features' behaviour is consistent with the known\nproperties of the models tested, and is similar across domains. We also\ndemonstrate that this approach exhibits promising properties such as zero-shot\ngeneralization to new domains on the related task of evaluating response\nrelevance.", "published": "2021-04-13 16:28:00", "link": "http://arxiv.org/abs/2104.06335v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "QA-GNN: Reasoning with Language Models and Knowledge Graphs for Question\n  Answering", "abstract": "The problem of answering questions using knowledge from pre-trained language\nmodels (LMs) and knowledge graphs (KGs) presents two challenges: given a QA\ncontext (question and answer choice), methods need to (i) identify relevant\nknowledge from large KGs, and (ii) perform joint reasoning over the QA context\nand KG. In this work, we propose a new model, QA-GNN, which addresses the above\nchallenges through two key innovations: (i) relevance scoring, where we use LMs\nto estimate the importance of KG nodes relative to the given QA context, and\n(ii) joint reasoning, where we connect the QA context and KG to form a joint\ngraph, and mutually update their representations through graph neural networks.\nWe evaluate our model on QA benchmarks in the commonsense (CommonsenseQA,\nOpenBookQA) and biomedical (MedQA-USMLE) domains. QA-GNN outperforms existing\nLM and LM+KG models, and exhibits capabilities to perform interpretable and\nstructured reasoning, e.g., correctly handling negation in questions.", "published": "2021-04-13 17:32:51", "link": "http://arxiv.org/abs/2104.06378v5", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ExplainaBoard: An Explainable Leaderboard for NLP", "abstract": "With the rapid development of NLP research, leaderboards have emerged as one\ntool to track the performance of various systems on various NLP tasks. They are\neffective in this goal to some extent, but generally present a rather\nsimplistic one-dimensional view of the submitted systems, communicated only\nthrough holistic accuracy numbers. In this paper, we present a new\nconceptualization and implementation of NLP evaluation: the ExplainaBoard,\nwhich in addition to inheriting the functionality of the standard leaderboard,\nalso allows researchers to (i) diagnose strengths and weaknesses of a single\nsystem (e.g.~what is the best-performing system bad at?) (ii) interpret\nrelationships between multiple systems. (e.g.~where does system A outperform\nsystem B? What if we combine systems A, B, and C?) and (iii) examine prediction\nresults closely (e.g.~what are common errors made by multiple systems, or in\nwhat contexts do particular errors occur?). So far, ExplainaBoard covers more\nthan 400 systems, 50 datasets, 40 languages, and 12 tasks. ExplainaBoard keeps\nupdated and is recently upgraded by supporting (1) multilingual multi-task\nbenchmark, (2) meta-evaluation, and (3) more complicated task: machine\ntranslation, which reviewers also suggested.} We not only released an online\nplatform on the website \\url{http://explainaboard.nlpedia.ai/} but also make\nour evaluation tool an API with MIT Licence at Github\n\\url{https://github.com/neulab/explainaBoard} and PyPi\n\\url{https://pypi.org/project/interpret-eval/} that allows users to\nconveniently assess their models offline. We additionally release all output\nfiles from systems that we have run or collected to motivate \"output-driven\"\nresearch in the future.", "published": "2021-04-13 17:45:50", "link": "http://arxiv.org/abs/2104.06387v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Detoxifying Language Models Risks Marginalizing Minority Voices", "abstract": "Language models (LMs) must be both safe and equitable to be responsibly\ndeployed in practice. With safety in mind, numerous detoxification techniques\n(e.g., Dathathri et al. 2020; Krause et al. 2020) have been proposed to\nmitigate toxic LM generations. In this work, we show that current\ndetoxification techniques hurt equity: they decrease the utility of LMs on\nlanguage used by marginalized groups (e.g., African-American English and\nminority identity mentions). In particular, we perform automatic and human\nevaluations of text generation quality when LMs are conditioned on inputs with\ndifferent dialects and group identifiers. We find that detoxification makes LMs\nmore brittle to distribution shift, especially on language used by marginalized\ngroups. We identify that these failures stem from detoxification methods\nexploiting spurious correlations in toxicity datasets. Overall, our results\nhighlight the tension between the controllability and distributional robustness\nof LMs.", "published": "2021-04-13 17:52:01", "link": "http://arxiv.org/abs/2104.06390v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Bridging the Gap Between Clean Data Training and Real-World Inference\n  for Spoken Language Understanding", "abstract": "Spoken language understanding (SLU) system usually consists of various\npipeline components, where each component heavily relies on the results of its\nupstream ones. For example, Intent detection (ID), and slot filling (SF)\nrequire its upstream automatic speech recognition (ASR) to transform the voice\ninto text. In this case, the upstream perturbations, e.g. ASR errors,\nenvironmental noise and careless user speaking, will propagate to the ID and SF\nmodels, thus deteriorating the system performance. Therefore, the\nwell-performing SF and ID models are expected to be noise resistant to some\nextent. However, existing models are trained on clean data, which causes a\n\\textit{gap between clean data training and real-world inference.} To bridge\nthe gap, we propose a method from the perspective of domain adaptation, by\nwhich both high- and low-quality samples are embedding into similar vector\nspace. Meanwhile, we design a denoising generation model to reduce the impact\nof the low-quality samples. Experiments on the widely-used dataset, i.e. Snips,\nand large scale in-house dataset (10 million training examples) demonstrate\nthat this method not only outperforms the baseline models on real-world (noisy)\ncorpus but also enhances the robustness, that is, it produces high-quality\nresults under a noisy environment. The source code will be released.", "published": "2021-04-13 17:54:33", "link": "http://arxiv.org/abs/2104.06393v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Modeling Framing in Immigration Discourse on Social Media", "abstract": "The framing of political issues can influence policy and public opinion. Even\nthough the public plays a key role in creating and spreading frames, little is\nknown about how ordinary people on social media frame political issues. By\ncreating a new dataset of immigration-related tweets labeled for multiple\nframing typologies from political communication theory, we develop supervised\nmodels to detect frames. We demonstrate how users' ideology and region impact\nframing choices, and how a message's framing influences audience responses. We\nfind that the more commonly-used issue-generic frames obscure important\nideological and regional patterns that are only revealed by\nimmigration-specific frames. Furthermore, frames oriented towards human\ninterests, culture, and politics are associated with higher user engagement.\nThis large-scale analysis of a complex social and linguistic phenomenon\ncontributes to both NLP and social science research.", "published": "2021-04-13 18:35:44", "link": "http://arxiv.org/abs/2104.06443v1", "categories": ["cs.CL", "cs.CY", "I.2.7; J.4; K.4.2"], "primary_category": "cs.CL"}
{"title": "Developing a Conversational Recommendation System for Navigating Limited\n  Options", "abstract": "We have developed a conversational recommendation system designed to help\nusers navigate through a set of limited options to find the best choice. Unlike\nmany internet scale systems that use a singular set of search terms and return\na ranked list of options from amongst thousands, our system uses multi-turn\nuser dialog to deeply understand the users preferences. The system responds in\ncontext to the users specific and immediate feedback to make sequential\nrecommendations. We envision our system would be highly useful in situations\nwith intrinsic constraints, such as finding the right restaurant within walking\ndistance or the right retail item within a limited inventory. Our research\nprototype instantiates the former use case, leveraging real data from Google\nPlaces, Yelp, and Zomato. We evaluated our system against a similar system that\ndid not incorporate user feedback in a 16 person remote study, generating 64\nscenario-based search journeys. When our recommendation system was successfully\ntriggered, we saw both an increase in efficiency and a higher confidence rating\nwith respect to final user choice. We also found that users preferred our\nsystem (75%) compared with the baseline.", "published": "2021-04-13 23:46:10", "link": "http://arxiv.org/abs/2104.06552v1", "categories": ["cs.CL", "cs.HC", "H.3.3; H.5.2"], "primary_category": "cs.CL"}
{"title": "Should Semantic Vector Composition be Explicit? Can it be Linear?", "abstract": "Vector representations have become a central element in semantic language\nmodelling, leading to mathematical overlaps with many fields including quantum\ntheory. Compositionality is a core goal for such representations: given\nrepresentations for 'wet' and 'fish', how should the concept 'wet fish' be\nrepresented?\n  This position paper surveys this question from two points of view. The first\nconsiders the question of whether an explicit mathematical representation can\nbe successful using only tools from within linear algebra, or whether other\nmathematical tools are needed. The second considers whether semantic vector\ncomposition should be explicitly described mathematically, or whether it can be\na model-internal side-effect of training a neural network.\n  A third and newer question is whether a compositional model can be\nimplemented on a quantum computer. Given the fundamentally linear nature of\nquantum mechanics, we propose that these questions are related, and that this\nsurvey may help to highlight candidate operations for future quantum\nimplementation.", "published": "2021-04-13 23:58:26", "link": "http://arxiv.org/abs/2104.06555v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Semantic maps and metrics for science Semantic maps and metrics for\n  science using deep transformer encoders", "abstract": "The growing deluge of scientific publications demands text analysis tools\nthat can help scientists and policy-makers navigate, forecast and beneficially\nguide scientific research. Recent advances in natural language understanding\ndriven by deep transformer networks offer new possibilities for mapping\nscience. Because the same surface text can take on multiple and sometimes\ncontradictory specialized senses across distinct research communities,\nsensitivity to context is critical for infometric applications. Transformer\nembedding models such as BERT capture shades of association and connotation\nthat vary across the different linguistic contexts of any particular word or\nspan of text. Here we report a procedure for encoding scientific documents with\nthese tools, measuring their improvement over static word embeddings in a\nnearest-neighbor retrieval task. We find discriminability of contextual\nrepresentations is strongly influenced by choice of pooling strategy for\nsummarizing the high-dimensional network activations. Importantly, we note that\nfundamentals such as domain-matched training data are more important than\nstate-of-the-art NLP tools. Yet state-of-the-art models did offer significant\ngains. The best approach we investigated combined domain-matched pretraining,\nsound pooling, and state-of-the-art deep transformer network encoders. Finally,\nwith the goal of leveraging contextual representations from deep encoders, we\npresent a range of measurements for understanding and forecasting research\ncommunities in science.", "published": "2021-04-13 04:12:20", "link": "http://arxiv.org/abs/2104.05928v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Experiments of ASR-based mispronunciation detection for children and\n  adult English learners", "abstract": "Pronunciation is one of the fundamentals of language learning, and it is\nconsidered a primary factor of spoken language when it comes to an\nunderstanding and being understood by others. The persistent presence of high\nerror rates in speech recognition domains resulting from mispronunciations\nmotivates us to find alternative techniques for handling mispronunciations. In\nthis study, we develop a mispronunciation assessment system that checks the\npronunciation of non-native English speakers, identifies the commonly\nmispronounced phonemes of Italian learners of English, and presents an\nevaluation of the non-native pronunciation observed in phonetically annotated\nspeech corpora. In this work, to detect mispronunciations, we used a\nphone-based ASR implemented using Kaldi. We used two non-native English labeled\ncorpora; (i) a corpus of Italian adults contains 5,867 utterances from 46\nspeakers, and (ii) a corpus of Italian children consists of 5,268 utterances\nfrom 78 children. Our results show that the selected error model can\ndiscriminate correct sounds from incorrect sounds in both native and nonnative\nspeech, and therefore can be used to detect pronunciation errors in non-native\nspeech. The phone error rates show improvement in using the error language\nmodel. The ASR system shows better accuracy after applying the error model on\nour selected corpora.", "published": "2021-04-13 07:24:05", "link": "http://arxiv.org/abs/2104.05980v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "MultiModalQA: Complex Question Answering over Text, Tables and Images", "abstract": "When answering complex questions, people can seamlessly combine information\nfrom visual, textual and tabular sources. While interest in models that reason\nover multiple pieces of evidence has surged in recent years, there has been\nrelatively little work on question answering models that reason across multiple\nmodalities. In this paper, we present MultiModalQA(MMQA): a challenging\nquestion answering dataset that requires joint reasoning over text, tables and\nimages. We create MMQA using a new framework for generating complex multi-modal\nquestions at scale, harvesting tables from Wikipedia, and attaching images and\ntext paragraphs using entities that appear in each table. We then define a\nformal language that allows us to take questions that can be answered from a\nsingle modality, and combine them to generate cross-modal questions. Last,\ncrowdsourcing workers take these automatically-generated questions and rephrase\nthem into more fluent language. We create 29,918 questions through this\nprocedure, and empirically demonstrate the necessity of a multi-modal multi-hop\napproach to solve our task: our multi-hop model, ImplicitDecomp, achieves an\naverage F1of 51.7 over cross-modal questions, substantially outperforming a\nstrong baseline that achieves 38.2 F1, but still lags significantly behind\nhuman performance, which is at 90.1 F1", "published": "2021-04-13 09:14:28", "link": "http://arxiv.org/abs/2104.06039v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multilingual Transfer Learning for Code-Switched Language and Speech\n  Neural Modeling", "abstract": "In this thesis, we address the data scarcity and limitations of linguistic\ntheory by proposing language-agnostic multi-task training methods. First, we\nintroduce a meta-learning-based approach, meta-transfer learning, in which\ninformation is judiciously extracted from high-resource monolingual speech data\nto the code-switching domain. The meta-transfer learning quickly adapts the\nmodel to the code-switching task from a number of monolingual tasks by learning\nto learn in a multi-task learning fashion. Second, we propose a novel\nmultilingual meta-embeddings approach to effectively represent code-switching\ndata by acquiring useful knowledge learned in other languages, learning the\ncommonalities of closely related languages and leveraging lexical composition.\nThe method is far more efficient compared to contextualized pre-trained\nmultilingual models. Third, we introduce multi-task learning to integrate\nsyntactic information as a transfer learning strategy to a language model and\nlearn where to code-switch. To further alleviate the aforementioned issues, we\npropose a data augmentation method using Pointer-Gen, a neural network using a\ncopy mechanism to teach the model the code-switch points from monolingual\nparallel sentences. We disentangle the need for linguistic theory, and the\nmodel captures code-switching points by attending to input words and aligning\nthe parallel words, without requiring any word alignments or constituency\nparsers. More importantly, the model can be effectively used for languages that\nare syntactically different, and it outperforms the linguistic theory-based\nmodels.", "published": "2021-04-13 14:49:26", "link": "http://arxiv.org/abs/2104.06268v1", "categories": ["cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Source and Target Bidirectional Knowledge Distillation for End-to-end\n  Speech Translation", "abstract": "A conventional approach to improving the performance of end-to-end speech\ntranslation (E2E-ST) models is to leverage the source transcription via\npre-training and joint training with automatic speech recognition (ASR) and\nneural machine translation (NMT) tasks. However, since the input modalities are\ndifferent, it is difficult to leverage source language text successfully. In\nthis work, we focus on sequence-level knowledge distillation (SeqKD) from\nexternal text-based NMT models. To leverage the full potential of the source\nlanguage information, we propose backward SeqKD, SeqKD from a target-to-source\nbackward NMT model. To this end, we train a bilingual E2E-ST model to predict\nparaphrased transcriptions as an auxiliary task with a single decoder. The\nparaphrases are generated from the translations in bitext via back-translation.\nWe further propose bidirectional SeqKD in which SeqKD from both forward and\nbackward NMT models is combined. Experimental evaluations on both\nautoregressive and non-autoregressive models show that SeqKD in each direction\nconsistently improves the translation performance, and the effectiveness is\ncomplementary regardless of the model capacity.", "published": "2021-04-13 19:00:51", "link": "http://arxiv.org/abs/2104.06457v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "MS2: Multi-Document Summarization of Medical Studies", "abstract": "To assess the effectiveness of any medical intervention, researchers must\nconduct a time-intensive and highly manual literature review. NLP systems can\nhelp to automate or assist in parts of this expensive process. In support of\nthis goal, we release MS^2 (Multi-Document Summarization of Medical Studies), a\ndataset of over 470k documents and 20k summaries derived from the scientific\nliterature. This dataset facilitates the development of systems that can assess\nand aggregate contradictory evidence across multiple studies, and is the first\nlarge-scale, publicly available multi-document summarization dataset in the\nbiomedical domain. We experiment with a summarization system based on BART,\nwith promising early results. We formulate our summarization inputs and targets\nin both free text and structured forms and modify a recently proposed metric to\nassess the quality of our system's generated summaries. Data and models are\navailable at https://github.com/allenai/ms2", "published": "2021-04-13 19:59:34", "link": "http://arxiv.org/abs/2104.06486v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "BERT Embeddings Can Track Context in Conversational Search", "abstract": "The use of conversational assistants to search for information is becoming\nincreasingly more popular among the general public, pushing the research\ntowards more advanced and sophisticated techniques. In the last few years, in\nparticular, the interest in conversational search is increasing, not only\nbecause of the generalization of conversational assistants but also because\nconversational search is a step forward in allowing a more natural interaction\nwith the system.\n  In this work, the focus is on exploring the context present of the\nconversation via the historical utterances and respective embeddings with the\naim of developing a conversational search system that helps people search for\ninformation in a natural way. In particular, this system must be able to\nunderstand the context where the question is posed, tracking the current state\nof the conversation and detecting mentions to previous questions and answers.\nWe achieve this by using a context-tracking component based on neural\nquery-rewriting models. Another crucial aspect of the system is to provide the\nmost relevant answers given the question and the conversational history. To\nachieve this objective, we used a Transformer-based re-ranking method and\nexpanded this architecture to use the conversational context.\n  The results obtained with the system developed showed the advantages of using\nthe context present in the natural language utterances and in the neural\nembeddings generated throughout the conversation.", "published": "2021-04-13 22:02:24", "link": "http://arxiv.org/abs/2104.06529v1", "categories": ["cs.IR", "cs.CL", "cs.LG", "H.3.3; I.2.7"], "primary_category": "cs.IR"}
{"title": "Detecting Escalation Level from Speech with Transfer Learning and\n  Acoustic-Lexical Information Fusion", "abstract": "Textual escalation detection has been widely applied to e-commerce companies'\ncustomer service systems to pre-alert and prevent potential conflicts.\nSimilarly, in public areas such as airports and train stations, where many\nimpersonal conversations frequently take place, acoustic-based escalation\ndetection systems are also useful to enhance passengers' safety and maintain\npublic order. To this end, we introduce a system based on acoustic-lexical\nfeatures to detect escalation from speech, Voice Activity Detection (VAD) and\nlabel smoothing are adopted to further enhance the performance in our\nexperiments. Considering a small set of training and development data, we also\nemploy transfer learning on several wellknown emotional detection datasets,\ni.e. RAVDESS, CREMA-D, to learn advanced emotional representations that is then\napplied to the conversational escalation detection task. On the development\nset, our proposed system achieves 81.5% unweighted average recall (UAR) which\nsignificantly outperforms the baseline with 72.2% UAR.", "published": "2021-04-13 08:11:01", "link": "http://arxiv.org/abs/2104.06004v2", "categories": ["cs.SD", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
{"title": "NoiseVC: Towards High Quality Zero-Shot Voice Conversion", "abstract": "Voice conversion (VC) is a task that transforms voice from target audio to\nsource without losing linguistic contents, it is challenging especially when\nsource and target speakers are unseen during training (zero-shot VC). Previous\napproaches require a pre-trained model or linguistic data to do the zero-shot\nconversion. Meanwhile, VC models with Vector Quantization (VQ) or Instance\nNormalization (IN) are able to disentangle contents from audios and achieve\nsuccessful conversions. However, disentanglement in these models highly relies\non heavily constrained bottleneck layers, thus, the sound quality is\ndrastically sacrificed. In this paper, we propose NoiseVC, an approach that can\ndisentangle contents based on VQ and Contrastive Predictive Coding (CPC).\nAdditionally, Noise Augmentation is performed to further enhance\ndisentanglement capability. We conduct several experiments and demonstrate that\nNoiseVC has a strong disentanglement ability with a small sacrifice of quality.", "published": "2021-04-13 10:12:38", "link": "http://arxiv.org/abs/2104.06074v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Visually Informed Binaural Audio Generation without Binaural Audios", "abstract": "Stereophonic audio, especially binaural audio, plays an essential role in\nimmersive viewing environments. Recent research has explored generating\nvisually guided stereophonic audios supervised by multi-channel audio\ncollections. However, due to the requirement of professional recording devices,\nexisting datasets are limited in scale and variety, which impedes the\ngeneralization of supervised methods in real-world scenarios. In this work, we\npropose PseudoBinaural, an effective pipeline that is free of binaural\nrecordings. The key insight is to carefully build pseudo visual-stereo pairs\nwith mono data for training. Specifically, we leverage spherical harmonic\ndecomposition and head-related impulse response (HRIR) to identify the\nrelationship between spatial locations and received binaural audios. Then in\nthe visual modality, corresponding visual cues of the mono data are manually\nplaced at sound source positions to form the pairs. Compared to\nfully-supervised paradigms, our binaural-recording-free pipeline shows great\nstability in cross-dataset evaluation and achieves comparable performance under\nsubjective preference. Moreover, combined with binaural recordings, our method\nis able to further boost the performance of binaural audio generation under\nsupervised settings.", "published": "2021-04-13 13:07:33", "link": "http://arxiv.org/abs/2104.06162v1", "categories": ["cs.SD", "cs.CV", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "EAT: Enhanced ASR-TTS for Self-supervised Speech Recognition", "abstract": "Self-supervised ASR-TTS models suffer in out-of-domain data conditions. Here\nwe propose an enhanced ASR-TTS (EAT) model that incorporates two main features:\n1) The ASR$\\rightarrow$TTS direction is equipped with a language model reward\nto penalize the ASR hypotheses before forwarding it to TTS. 2) In the\nTTS$\\rightarrow$ASR direction, a hyper-parameter is introduced to scale the\nattention context from synthesized speech before sending it to ASR to handle\nout-of-domain data. Training strategies and the effectiveness of the EAT model\nare explored under out-of-domain data conditions. The results show that EAT\nreduces the performance gap between supervised and self-supervised training\nsignificantly by absolute 2.6\\% and 2.7\\% on Librispeech and BABEL\nrespectively.", "published": "2021-04-13 23:18:25", "link": "http://arxiv.org/abs/2104.07474v1", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Comparison and Analysis of Deep Audio Embeddings for Music Emotion\n  Recognition", "abstract": "Emotion is a complicated notion present in music that is hard to capture even\nwith fine-tuned feature engineering. In this paper, we investigate the utility\nof state-of-the-art pre-trained deep audio embedding methods to be used in the\nMusic Emotion Recognition (MER) task. Deep audio embedding methods allow us to\nefficiently capture the high dimensional features into a compact\nrepresentation. We implement several multi-class classifiers with deep audio\nembeddings to predict emotion semantics in music. We investigate the\neffectiveness of L3-Net and VGGish deep audio embedding methods for music\nemotion inference over four music datasets. The experiments with several\nclassifiers on the task show that the deep audio embedding solutions can\nimprove the performances of the previous baseline MER models. We conclude that\ndeep audio embeddings represent musical emotion semantics for the MER task\nwithout expert human engineering.", "published": "2021-04-13 21:09:54", "link": "http://arxiv.org/abs/2104.06517v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
