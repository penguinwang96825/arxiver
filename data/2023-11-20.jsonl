{"title": "Adapt in Contexts: Retrieval-Augmented Domain Adaptation via In-Context\n  Learning", "abstract": "Large language models (LLMs) have showcased their capability with few-shot\ninference known as in-context learning. However, in-domain demonstrations are\nnot always readily available in real scenarios, leading to cross-domain\nin-context learning. Besides, LLMs are still facing challenges in long-tail\nknowledge in unseen and unfamiliar domains. The above limitations demonstrate\nthe necessity of Unsupervised Domain Adaptation (UDA). In this paper, we study\nthe UDA problem under an in-context learning setting to adapt language models\nfrom the source domain to the target domain without any target labels. The core\nidea is to retrieve a subset of cross-domain elements that are the most similar\nto the query, and elicit language model to adapt in an in-context manner by\nlearning both target domain distribution and the discriminative task signal\nsimultaneously with the augmented cross-domain in-context examples. We devise\ndifferent prompting and training strategies, accounting for different LM\narchitectures to learn the target distribution via language modeling. With\nextensive experiments on Sentiment Analysis (SA) and Named Entity Recognition\n(NER) tasks, we thoroughly study the effectiveness of ICL for domain transfer\nand demonstrate significant improvements over baseline models.", "published": "2023-11-20 06:06:20", "link": "http://arxiv.org/abs/2311.11551v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KBioXLM: A Knowledge-anchored Biomedical Multilingual Pretrained\n  Language Model", "abstract": "Most biomedical pretrained language models are monolingual and cannot handle\nthe growing cross-lingual requirements. The scarcity of non-English domain\ncorpora, not to mention parallel data, poses a significant hurdle in training\nmultilingual biomedical models. Since knowledge forms the core of\ndomain-specific corpora and can be translated into various languages\naccurately, we propose a model called KBioXLM, which transforms the\nmultilingual pretrained model XLM-R into the biomedical domain using a\nknowledge-anchored approach. We achieve a biomedical multilingual corpus by\nincorporating three granularity knowledge alignments (entity, fact, and passage\nlevels) into monolingual corpora. Then we design three corresponding training\ntasks (entity masking, relation masking, and passage relation prediction) and\ncontinue training on top of the XLM-R model to enhance its domain cross-lingual\nability. To validate the effectiveness of our model, we translate the English\nbenchmarks of multiple tasks into Chinese. Experimental results demonstrate\nthat our model significantly outperforms monolingual and multilingual\npretrained models in cross-lingual zero-shot and few-shot scenarios, achieving\nimprovements of up to 10+ points. Our code is publicly available at\nhttps://github.com/ngwlh-gl/KBioXLM.", "published": "2023-11-20 07:02:35", "link": "http://arxiv.org/abs/2311.11564v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How well ChatGPT understand Malaysian English? An Evaluation on Named\n  Entity Recognition and Relation Extraction", "abstract": "Recently, ChatGPT has attracted a lot of interest from both researchers and\nthe general public. While the performance of ChatGPT in named entity\nrecognition and relation extraction from Standard English texts is\nsatisfactory, it remains to be seen if it can perform similarly for Malaysian\nEnglish. Malaysian English is unique as it exhibits morphosyntactic and\nsemantical adaptation from local contexts. In this study, we assess ChatGPT's\ncapability in extracting entities and relations from the Malaysian English News\n(MEN) dataset. We propose a three-step methodology referred to as\n\\textbf{\\textit{educate-predict-evaluate}}. The performance of ChatGPT is\nassessed using F1-Score across 18 unique prompt settings, which were carefully\nengineered for a comprehensive review. From our evaluation, we found that\nChatGPT does not perform well in extracting entities from Malaysian English\nnews articles, with the highest F1-Score of 0.497. Further analysis shows that\nthe morphosyntactic adaptation in Malaysian English caused the limitation.\nHowever, interestingly, this morphosyntactic adaptation does not impact the\nperformance of ChatGPT for relation extraction.", "published": "2023-11-20 07:41:30", "link": "http://arxiv.org/abs/2311.11583v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Filling the Image Information Gap for VQA: Prompting Large Language\n  Models to Proactively Ask Questions", "abstract": "Large Language Models (LLMs) demonstrate impressive reasoning ability and the\nmaintenance of world knowledge not only in natural language tasks, but also in\nsome vision-language tasks such as open-domain knowledge-based visual question\nanswering (OK-VQA). As images are invisible to LLMs, researchers convert images\nto text to engage LLMs into the visual question reasoning procedure. This leads\nto discrepancies between images and their textual representations presented to\nLLMs, which consequently impedes final reasoning performance. To fill the\ninformation gap and better leverage the reasoning capability, we design a\nframework that enables LLMs to proactively ask relevant questions to unveil\nmore details in the image, along with filters for refining the generated\ninformation. We validate our idea on OK-VQA and A-OKVQA. Our method\ncontinuously boosts the performance of baselines methods by an average gain of\n2.15% on OK-VQA, and achieves consistent improvements across different LLMs.", "published": "2023-11-20 08:23:39", "link": "http://arxiv.org/abs/2311.11598v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Addressing the Length Bias Problem in Document-Level Neural Machine\n  Translation", "abstract": "Document-level neural machine translation (DNMT) has shown promising results\nby incorporating more context information. However, this approach also\nintroduces a length bias problem, whereby DNMT suffers from significant\ntranslation quality degradation when decoding documents that are much shorter\nor longer than the maximum sequence length during training. %i.e., the length\nbias problem. To solve the length bias problem, we propose to improve the DNMT\nmodel in training method, attention mechanism, and decoding strategy. Firstly,\nwe propose to sample the training data dynamically to ensure a more uniform\ndistribution across different sequence lengths. Then, we introduce a\nlength-normalized attention mechanism to aid the model in focusing on target\ninformation, mitigating the issue of attention divergence when processing\nlonger sequences. Lastly, we propose a sliding window strategy during decoding\nthat integrates as much context information as possible without exceeding the\nmaximum sequence length. The experimental results indicate that our method can\nbring significant improvements on several open datasets, and further analysis\nshows that our method can significantly alleviate the length bias problem.", "published": "2023-11-20 08:29:52", "link": "http://arxiv.org/abs/2311.11601v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Grammatical Error Correction Via Multi-Task Training and\n  Optimized Training Schedule", "abstract": "Progress in neural grammatical error correction (GEC) is hindered by the lack\nof annotated training data. Sufficient amounts of high-quality manually\nannotated data are not available, so recent research has relied on generating\nsynthetic data, pretraining on it, and then fine-tuning on real datasets;\nperformance gains have been achieved either by ensembling or by using huge\npretrained models such as XXL-T5 as the backbone. In this work, we explore an\northogonal direction: how to use available data more efficiently. First, we\npropose auxiliary tasks that exploit the alignment between the original and\ncorrected sentences, such as predicting a sequence of corrections. We formulate\neach task as a sequence-to-sequence problem and perform multi-task training.\nSecond, we discover that the order of datasets used for training and even\nindividual instances within a dataset may have important effects on the final\nperformance, so we set out to find the best training schedule. Together, these\ntwo ideas lead to significant improvements, producing results that improve\nstate of the art with much smaller models; in particular, we outperform the\nbest models based on T5-XXL (11B parameters) with a BART-based model (400M\nparameters).", "published": "2023-11-20 14:50:12", "link": "http://arxiv.org/abs/2311.11813v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Deepparse : An Extendable, and Fine-Tunable State-Of-The-Art Library for\n  Parsing Multinational Street Addresses", "abstract": "Segmenting an address into meaningful components, also known as address\nparsing, is an essential step in many applications from record linkage to\ngeocoding and package delivery. Consequently, a lot of work has been dedicated\nto develop accurate address parsing techniques, with machine learning and\nneural network methods leading the state-of-the-art scoreboard. However, most\nof the work on address parsing has been confined to academic endeavours with\nlittle availability of free and easy-to-use open-source solutions.\n  This paper presents Deepparse, a Python open-source, extendable, fine-tunable\naddress parsing solution under LGPL-3.0 licence to parse multinational\naddresses using state-of-the-art deep learning algorithms and evaluated on over\n60 countries. It can parse addresses written in any language and use any\naddress standard. The pre-trained model achieves average $99~\\%$ parsing\naccuracies on the countries used for training with no pre-processing nor\npost-processing needed. Moreover, the library supports fine-tuning with new\ndata to generate a custom address parser.", "published": "2023-11-20 15:37:33", "link": "http://arxiv.org/abs/2311.11846v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evil Geniuses: Delving into the Safety of LLM-based Agents", "abstract": "Rapid advancements in large language models (LLMs) have revitalized in\nLLM-based agents, exhibiting impressive human-like behaviors and cooperative\ncapabilities in various scenarios. However, these agents also bring some\nexclusive risks, stemming from the complexity of interaction environments and\nthe usability of tools. This paper delves into the safety of LLM-based agents\nfrom three perspectives: agent quantity, role definition, and attack level.\nSpecifically, we initially propose to employ a template-based attack strategy\non LLM-based agents to find the influence of agent quantity. In addition, to\naddress interaction environment and role specificity issues, we introduce Evil\nGeniuses (EG), an effective attack method that autonomously generates prompts\nrelated to the original role to examine the impact across various role\ndefinitions and attack levels. EG leverages Red-Blue exercises, significantly\nimproving the generated prompt aggressiveness and similarity to original roles.\nOur evaluations on CAMEL, Metagpt and ChatDev based on GPT-3.5 and GPT-4,\ndemonstrate high success rates. Extensive evaluation and discussion reveal that\nthese agents are less robust, prone to more harmful behaviors, and capable of\ngenerating stealthier content than LLMs, highlighting significant safety\nchallenges and guiding future research. Our code is available at\nhttps://github.com/T1aNS1R/Evil-Geniuses.", "published": "2023-11-20 15:50:09", "link": "http://arxiv.org/abs/2311.11855v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Analysis of Substantiation in Scientific Peer Reviews", "abstract": "With the increasing amount of problematic peer reviews in top AI conferences,\nthe community is urgently in need of automatic quality control measures. In\nthis paper, we restrict our attention to substantiation -- one popular quality\naspect indicating whether the claims in a review are sufficiently supported by\nevidence -- and provide a solution automatizing this evaluation process. To\nachieve this goal, we first formulate the problem as claim-evidence pair\nextraction in scientific peer reviews, and collect SubstanReview, the first\nannotated dataset for this task. SubstanReview consists of 550 reviews from NLP\nconferences annotated by domain experts. On the basis of this dataset, we train\nan argument mining system to automatically analyze the level of substantiation\nin peer reviews. We also perform data analysis on the SubstanReview dataset to\nobtain meaningful insights on peer reviewing quality in NLP conferences over\nrecent years.", "published": "2023-11-20 17:47:37", "link": "http://arxiv.org/abs/2311.11967v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Context-aware Neural Machine Translation for English-Japanese Business\n  Scene Dialogues", "abstract": "Despite the remarkable advancements in machine translation, the current\nsentence-level paradigm faces challenges when dealing with highly-contextual\nlanguages like Japanese. In this paper, we explore how context-awareness can\nimprove the performance of the current Neural Machine Translation (NMT) models\nfor English-Japanese business dialogues translation, and what kind of context\nprovides meaningful information to improve translation. As business dialogue\ninvolves complex discourse phenomena but offers scarce training resources, we\nadapted a pretrained mBART model, finetuning on multi-sentence dialogue data,\nwhich allows us to experiment with different contexts. We investigate the\nimpact of larger context sizes and propose novel context tokens encoding\nextra-sentential information, such as speaker turn and scene type. We make use\nof Conditional Cross-Mutual Information (CXMI) to explore how much of the\ncontext the model uses and generalise CXMI to study the impact of the\nextra-sentential context. Overall, we find that models leverage both preceding\nsentences and extra-sentential context (with CXMI increasing with context size)\nand we provide a more focused analysis on honorifics translation. Regarding\ntranslation quality, increased source-side context paired with scene and\nspeaker information improves the model performance compared to previous work\nand our context-agnostic baselines, measured in BLEU and COMET metrics.", "published": "2023-11-20 18:06:03", "link": "http://arxiv.org/abs/2311.11976v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "H-COAL: Human Correction of AI-Generated Labels for Biomedical Named\n  Entity Recognition", "abstract": "With the rapid advancement of machine learning models for NLP tasks,\ncollecting high-fidelity labels from AI models is a realistic possibility.\nFirms now make AI available to customers via predictions as a service (PaaS).\nThis includes PaaS products for healthcare. It is unclear whether these labels\ncan be used for training a local model without expensive annotation checking by\nin-house experts. In this work, we propose a new framework for Human Correction\nof AI-Generated Labels (H-COAL). By ranking AI-generated outputs, one can\nselectively correct labels and approach gold standard performance (100% human\nlabeling) with significantly less human effort. We show that correcting 5% of\nlabels can close the AI-human performance gap by up to 64% relative\nimprovement, and correcting 20% of labels can close the performance gap by up\nto 86% relative improvement.", "published": "2023-11-20 18:16:27", "link": "http://arxiv.org/abs/2311.11981v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Human Learning by Model Feedback: The Dynamics of Iterative Prompting\n  with Midjourney", "abstract": "Generating images with a Text-to-Image model often requires multiple trials,\nwhere human users iteratively update their prompt based on feedback, namely the\noutput image. Taking inspiration from cognitive work on reference games and\ndialogue alignment, this paper analyzes the dynamics of the user prompts along\nsuch iterations. We compile a dataset of iterative interactions of human users\nwith Midjourney. Our analysis then reveals that prompts predictably converge\ntoward specific traits along these iterations. We further study whether this\nconvergence is due to human users, realizing they missed important details, or\ndue to adaptation to the model's ``preferences'', producing better images for a\nspecific language style. We show initial evidence that both possibilities are\nat play. The possibility that users adapt to the model's preference raises\nconcerns about reusing user data for further training. The prompts may be\nbiased towards the preferences of a specific model, rather than align with\nhuman intentions and natural manner of expression.", "published": "2023-11-20 19:28:52", "link": "http://arxiv.org/abs/2311.12131v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging Closed-Access Multilingual Embedding for Automatic Sentence\n  Alignment in Low Resource Languages", "abstract": "The importance of qualitative parallel data in machine translation has long\nbeen determined but it has always been very difficult to obtain such in\nsufficient quantity for the majority of world languages, mainly because of the\nassociated cost and also the lack of accessibility to these languages. Despite\nthe potential for obtaining parallel datasets from online articles using\nautomatic approaches, forensic investigations have found a lot of\nquality-related issues such as misalignment, and wrong language codes. In this\nwork, we present a simple but qualitative parallel sentence aligner that\ncarefully leveraged the closed-access Cohere multilingual embedding, a solution\nthat ranked second in the just concluded #CoHereAIHack 2023 Challenge (see\nhttps://ai6lagos.devpost.com). The proposed approach achieved $94.96$ and\n$54.83$ f1 scores on FLORES and MAFAND-MT, compared to $3.64$ and $0.64$ of\nLASER respectively. Our method also achieved an improvement of more than 5 BLEU\nscores over LASER, when the resulting datasets were used with MAFAND-MT dataset\nto train translation models. Our code and data are available for research\npurposes here (https://github.com/abumafrim/Cohere-Align).", "published": "2023-11-20 20:48:25", "link": "http://arxiv.org/abs/2311.12179v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unifying Corroborative and Contributive Attributions in Large Language\n  Models", "abstract": "As businesses, products, and services spring up around large language models,\nthe trustworthiness of these models hinges on the verifiability of their\noutputs. However, methods for explaining language model outputs largely fall\nacross two distinct fields of study which both use the term \"attribution\" to\nrefer to entirely separate techniques: citation generation and training data\nattribution. In many modern applications, such as legal document generation and\nmedical question answering, both types of attributions are important. In this\nwork, we argue for and present a unified framework of large language model\nattributions. We show how existing methods of different types of attribution\nfall under the unified framework. We also use the framework to discuss\nreal-world use cases where one or both types of attributions are required. We\nbelieve that this unified framework will guide the use case driven development\nof systems that leverage both types of attribution, as well as the\nstandardization of their evaluation.", "published": "2023-11-20 23:17:20", "link": "http://arxiv.org/abs/2311.12233v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What's left can't be right -- The remaining positional incompetence of\n  contrastive vision-language models", "abstract": "Contrastive vision-language models like CLIP have been found to lack spatial\nunderstanding capabilities. In this paper we discuss the possible causes of\nthis phenomenon by analysing both datasets and embedding space. By focusing on\nsimple left-right positional relations, we show that this behaviour is entirely\npredictable, even with large-scale datasets, demonstrate that these relations\ncan be taught using synthetic data and show that this approach can generalise\nwell to natural images - improving the performance on left-right relations on\nVisual Genome Relations.", "published": "2023-11-20 01:07:30", "link": "http://arxiv.org/abs/2311.11477v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Meta Prompting for AI Systems", "abstract": "We introduce Meta Prompting (MP), a prompting paradigm designed to enhance\nthe utilization of large language models (LLMs) and AI systems in complex\nproblem-solving and data interaction. Grounded in type theory and category\ntheory, Meta Prompting prioritizes structural and syntactical considerations\nover traditional content-centric methods. In this work, we formally define Meta\nPrompting, delineate its distinctions from few-shot prompting, and demonstrate\nits effectiveness across various AI applications. In particular, we show that\nMeta Prompting can decompose intricate reasoning tasks into simpler\nsub-problems, thereby improving token efficiency and enabling fairer\ncomparisons with conventional few-shot techniques. Furthermore, we extend this\nframework to prompting tasks, allowing LLMs to recursively self-generate\nrefined prompts in a metaprogramming-like manner. Empirical evaluations reveal\nthat a Qwen-72B base language model equipped with Meta Prompting-without\nadditional instruction tuning-achieves a PASS@1 accuracy of 46.3% on MATH\nproblems, surpassing a supervised fine-tuned counterpart, 83.5% accuracy on\nGSM8K, and a 100% success rate on Game of 24 tasks using GPT-4. The code is\navailable at https://github.com/meta-prompting/meta-prompting.", "published": "2023-11-20 01:51:13", "link": "http://arxiv.org/abs/2311.11482v7", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Token-Level Adversarial Prompt Detection Based on Perplexity Measures\n  and Contextual Information", "abstract": "In recent years, Large Language Models (LLM) have emerged as pivotal tools in\nvarious applications. However, these models are susceptible to adversarial\nprompt attacks, where attackers can carefully curate input strings that mislead\nLLMs into generating incorrect or undesired outputs. Previous work has revealed\nthat with relatively simple yet effective attacks based on discrete\noptimization, it is possible to generate adversarial prompts that bypass\nmoderation and alignment of the models. This vulnerability to adversarial\nprompts underscores a significant concern regarding the robustness and\nreliability of LLMs. Our work aims to address this concern by introducing a\nnovel approach to detecting adversarial prompts at a token level, leveraging\nthe LLM's capability to predict the next token's probability. We measure the\ndegree of the model's perplexity, where tokens predicted with high probability\nare considered normal, and those exhibiting high perplexity are flagged as\nadversarial. Additionaly, our method also integrates context understanding by\nincorporating neighboring token information to encourage the detection of\ncontiguous adversarial prompt sequences. To this end, we design two algorithms\nfor adversarial prompt detection: one based on optimization techniques and\nanother on Probabilistic Graphical Models (PGM). Both methods are equipped with\nefficient solving methods, ensuring efficient adversarial prompt detection. Our\ntoken-level detection result can be visualized as heatmap overlays on the text\nsequence, allowing for a clearer and more intuitive representation of which\npart of the text may contain adversarial prompts.", "published": "2023-11-20 03:17:21", "link": "http://arxiv.org/abs/2311.11509v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multi-teacher Distillation for Multilingual Spelling Correction", "abstract": "Accurate spelling correction is a critical step in modern search interfaces,\nespecially in an era of mobile devices and speech-to-text interfaces. For\nservices that are deployed around the world, this poses a significant challenge\nfor multilingual NLP: spelling errors need to be caught and corrected in all\nlanguages, and even in queries that use multiple languages. In this paper, we\ntackle this challenge using multi-teacher distillation. On our approach, a\nmonolingual teacher model is trained for each language/locale, and these\nindividual models are distilled into a single multilingual student model\nintended to serve all languages/locales. In experiments using open-source data\nas well as user data from a worldwide search service, we show that this leads\nto highly effective spelling correction models that can meet the tight latency\nrequirements of deployed services.", "published": "2023-11-20 03:44:32", "link": "http://arxiv.org/abs/2311.11518v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Taiyi: A Bilingual Fine-Tuned Large Language Model for Diverse\n  Biomedical Tasks", "abstract": "Objective: Most existing fine-tuned biomedical large language models (LLMs)\nfocus on enhancing performance in monolingual biomedical question answering and\nconversation tasks. To investigate the effectiveness of the fine-tuned LLMs on\ndiverse biomedical NLP tasks in different languages, We present Taiyi, a\nbilingual fine-tuned LLM for diverse biomedical tasks. Materials and Methods:\nWe first curated a comprehensive collection of 140 existing biomedical text\nmining datasets (102 English and 38 Chinese datasets) across over 10 task\ntypes. Subsequently, a two-stage strategy is proposed for supervised\nfine-tuning to optimize the model performance across varied tasks. Results:\nExperimental results on 13 test sets covering named entity recognition,\nrelation extraction, text classification, question answering tasks demonstrate\nthat Taiyi achieves superior performance compared to general LLMs. The case\nstudy involving additional biomedical NLP tasks further shows Taiyi's\nconsiderable potential for bilingual biomedical multi-tasking. Conclusion:\nLeveraging rich high-quality biomedical corpora and developing effective\nfine-tuning strategies can significantly improve the performance of LLMs within\nthe biomedical domain. Taiyi shows the bilingual multi-tasking capability\nthrough supervised fine-tuning. However, those tasks such as information\nextraction that are not generation tasks in nature remain challenging for\nLLM-based generative approaches, and they still underperform the conventional\ndiscriminative approaches of smaller language models.", "published": "2023-11-20 08:51:30", "link": "http://arxiv.org/abs/2311.11608v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Human-Level Text Coding with LLMs: The Case of Fatherhood Roles\n  in Public Policy Documents", "abstract": "Recent advances in large language models (LLMs) like GPT-3.5 and GPT-4\npromise automation with better results and less programming, opening up new\nopportunities for text analysis in political science. In this study, we\nevaluate LLMs on three original coding tasks involving typical complexities\nencountered in political science settings: a non-English language, legal and\npolitical jargon, and complex labels based on abstract constructs. Along the\npaper, we propose a practical workflow to optimize the choice of the model and\nthe prompt. We find that the best prompting strategy consists of providing the\nLLMs with a detailed codebook, as the one provided to human coders. In this\nsetting, an LLM can be as good as or possibly better than a human annotator\nwhile being much faster, considerably cheaper, and much easier to scale to\nlarge amounts of text. We also provide a comparison of GPT and popular\nopen-source LLMs, discussing the trade-offs in the model's choice. Our software\nallows LLMs to be easily used as annotators and is publicly available:\nhttps://github.com/lorelupo/pappa.", "published": "2023-11-20 15:34:45", "link": "http://arxiv.org/abs/2311.11844v3", "categories": ["cs.CL", "cs.CY", "J.4; I.2"], "primary_category": "cs.CL"}
{"title": "Generating Valid and Natural Adversarial Examples with Large Language\n  Models", "abstract": "Deep learning-based natural language processing (NLP) models, particularly\npre-trained language models (PLMs), have been revealed to be vulnerable to\nadversarial attacks. However, the adversarial examples generated by many\nmainstream word-level adversarial attack models are neither valid nor natural,\nleading to the loss of semantic maintenance, grammaticality, and human\nimperceptibility. Based on the exceptional capacity of language understanding\nand generation of large language models (LLMs), we propose LLM-Attack, which\naims at generating both valid and natural adversarial examples with LLMs. The\nmethod consists of two stages: word importance ranking (which searches for the\nmost vulnerable words) and word synonym replacement (which substitutes them\nwith their synonyms obtained from LLMs). Experimental results on the Movie\nReview (MR), IMDB, and Yelp Review Polarity datasets against the baseline\nadversarial attack models illustrate the effectiveness of LLM-Attack, and it\noutperforms the baselines in human and GPT-4 evaluation by a significant\nmargin. The model can generate adversarial examples that are typically valid\nand natural, with the preservation of semantic meaning, grammaticality, and\nhuman imperceptibility.", "published": "2023-11-20 15:57:04", "link": "http://arxiv.org/abs/2311.11861v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Adaptive Training Distributions with Scalable Online Bilevel\n  Optimization", "abstract": "Large neural networks pretrained on web-scale corpora are central to modern\nmachine learning. In this paradigm, the distribution of the large,\nheterogeneous pretraining data rarely matches that of the application domain.\nThis work considers modifying the pretraining distribution in the case where\none has a small sample of data reflecting the targeted test conditions. We\npropose an algorithm motivated by a recent formulation of this setting as an\nonline, bilevel optimization problem. With scalability in mind, our algorithm\nprioritizes computing gradients at training points which are likely to most\nimprove the loss on the targeted distribution. Empirically, we show that in\nsome cases this approach is beneficial over existing strategies from the domain\nadaptation literature but may not succeed in other cases. We propose a simple\ntest to evaluate when our approach can be expected to work well and point\ntowards further research to address current limitations.", "published": "2023-11-20 18:01:29", "link": "http://arxiv.org/abs/2311.11973v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "On the Potential and Limitations of Few-Shot In-Context Learning to\n  Generate Metamorphic Specifications for Tax Preparation Software", "abstract": "Due to the ever-increasing complexity of income tax laws in the United\nStates, the number of US taxpayers filing their taxes using tax preparation\nsoftware (henceforth, tax software) continues to increase. According to the\nU.S. Internal Revenue Service (IRS), in FY22, nearly 50% of taxpayers filed\ntheir individual income taxes using tax software. Given the legal consequences\nof incorrectly filing taxes for the taxpayer, ensuring the correctness of tax\nsoftware is of paramount importance. Metamorphic testing has emerged as a\nleading solution to test and debug legal-critical tax software due to the\nabsence of correctness requirements and trustworthy datasets. The key idea\nbehind metamorphic testing is to express the properties of a system in terms of\nthe relationship between one input and its slightly metamorphosed twinned\ninput. Extracting metamorphic properties from IRS tax publications is a tedious\nand time-consuming process. As a response, this paper formulates the task of\ngenerating metamorphic specifications as a translation task between properties\nextracted from tax documents - expressed in natural language - to a contrastive\nfirst-order logic form. We perform a systematic analysis on the potential and\nlimitations of in-context learning with Large Language Models(LLMs) for this\ntask, and outline a research agenda towards automating the generation of\nmetamorphic specifications for tax preparation software.", "published": "2023-11-20 18:12:28", "link": "http://arxiv.org/abs/2311.11979v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "GPQA: A Graduate-Level Google-Proof Q&A Benchmark", "abstract": "We present GPQA, a challenging dataset of 448 multiple-choice questions\nwritten by domain experts in biology, physics, and chemistry. We ensure that\nthe questions are high-quality and extremely difficult: experts who have or are\npursuing PhDs in the corresponding domains reach 65% accuracy (74% when\ndiscounting clear mistakes the experts identified in retrospect), while highly\nskilled non-expert validators only reach 34% accuracy, despite spending on\naverage over 30 minutes with unrestricted access to the web (i.e., the\nquestions are \"Google-proof\"). The questions are also difficult for\nstate-of-the-art AI systems, with our strongest GPT-4 based baseline achieving\n39% accuracy. If we are to use future AI systems to help us answer very hard\nquestions, for example, when developing new scientific knowledge, we need to\ndevelop scalable oversight methods that enable humans to supervise their\noutputs, which may be difficult even if the supervisors are themselves skilled\nand knowledgeable. The difficulty of GPQA both for skilled non-experts and\nfrontier AI systems should enable realistic scalable oversight experiments,\nwhich we hope can help devise ways for human experts to reliably get truthful\ninformation from AI systems that surpass human capabilities.", "published": "2023-11-20 18:57:34", "link": "http://arxiv.org/abs/2311.12022v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "LQ-LoRA: Low-rank Plus Quantized Matrix Decomposition for Efficient\n  Language Model Finetuning", "abstract": "We propose a simple approach for memory-efficient adaptation of pretrained\nlanguage models. Our approach uses an iterative algorithm to decompose each\npretrained matrix into a high-precision low-rank component and a\nmemory-efficient quantized component. During finetuning, the quantized\ncomponent remains fixed and only the low-rank component is updated. We present\nan integer linear programming formulation of the quantization component which\nenables dynamic configuration of quantization parameters (e.g., bit-width,\nblock size) for each matrix given an overall target memory budget. We further\nexplore a data-aware version of the algorithm which uses an approximation of\nthe Fisher information matrix to weight the reconstruction objective during\nmatrix decomposition. Experiments on finetuning RoBERTa and LLaMA-2 (7B and\n70B) demonstrate that our low-rank plus quantized matrix decomposition approach\n(LQ-LoRA) outperforms strong QLoRA and GPTQ-LoRA baselines and enables\naggressive quantization to sub-3 bits with only minor performance degradations.\nWhen finetuned on a language modeling calibration dataset, LQ-LoRA can also be\nused for model compression; in this setting our 2.75-bit LLaMA-2-70B model\n(which has 2.85 bits on average when including the low-rank components and\nrequires 27GB of GPU memory) performs respectably compared to the 16-bit\nbaseline.", "published": "2023-11-20 18:57:41", "link": "http://arxiv.org/abs/2311.12023v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Optimal Strategies to Perform Multilingual Analysis of Social Content\n  for a Novel Dataset in the Tourism Domain", "abstract": "The rising influence of social media platforms in various domains, including\ntourism, has highlighted the growing need for efficient and automated natural\nlanguage processing (NLP) approaches to take advantage of this valuable\nresource. However, the transformation of multilingual, unstructured, and\ninformal texts into structured knowledge often poses significant challenges.\n  In this work, we evaluate and compare few-shot, pattern-exploiting and\nfine-tuning machine learning techniques on large multilingual language models\n(LLMs) to establish the best strategy to address the lack of annotated data for\n3 common NLP tasks in the tourism domain: (1) Sentiment Analysis, (2) Named\nEntity Recognition, and (3) Fine-grained Thematic Concept Extraction (linked to\na semantic resource). Furthermore, we aim to ascertain the quantity of\nannotated examples required to achieve good performance in those 3 tasks,\naddressing a common challenge encountered by NLP researchers in the\nconstruction of domain-specific datasets.\n  Extensive experimentation on a newly collected and annotated multilingual\n(French, English, and Spanish) dataset composed of tourism-related tweets shows\nthat current few-shot learning techniques allow us to obtain competitive\nresults for all three tasks with very little annotation data: 5 tweets per\nlabel (15 in total) for Sentiment Analysis, 10% of the tweets for location\ndetection (around 160) and 13% (200 approx.) of the tweets annotated with\nthematic concepts, a highly fine-grained sequence labeling task based on an\ninventory of 315 classes.\n  This comparative analysis, grounded in a novel dataset, paves the way for\napplying NLP to new domain-specific applications, reducing the need for manual\nannotations and circumventing the complexities of rule-based, ad hoc solutions.", "published": "2023-11-20 13:08:21", "link": "http://arxiv.org/abs/2311.14727v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GPT in Data Science: A Practical Exploration of Model Selection", "abstract": "There is an increasing interest in leveraging Large Language Models (LLMs)\nfor managing structured data and enhancing data science processes. Despite the\npotential benefits, this integration poses significant questions regarding\ntheir reliability and decision-making methodologies. It highlights the\nimportance of various factors in the model selection process, including the\nnature of the data, problem type, performance metrics, computational resources,\ninterpretability vs accuracy, assumptions about data, and ethical\nconsiderations. Our objective is to elucidate and express the factors and\nassumptions guiding GPT-4's model selection recommendations. We employ a\nvariability model to depict these factors and use toy datasets to evaluate both\nthe model and the implementation of the identified heuristics. By contrasting\nthese outcomes with heuristics from other platforms, our aim is to determine\nthe effectiveness and distinctiveness of GPT-4's methodology. This research is\ncommitted to advancing our comprehension of AI decision-making processes,\nespecially in the realm of model selection within data science. Our efforts are\ndirected towards creating AI systems that are more transparent and\ncomprehensible, contributing to a more responsible and efficient practice in\ndata science.", "published": "2023-11-20 03:42:24", "link": "http://arxiv.org/abs/2311.11516v1", "categories": ["cs.AI", "cs.CL", "cs.DB"], "primary_category": "cs.AI"}
{"title": "Exploring Prompting Large Language Models as Explainable Metrics", "abstract": "This paper describes the IUST NLP Lab submission to the Prompting Large\nLanguage Models as Explainable Metrics Shared Task at the Eval4NLP 2023\nWorkshop on Evaluation & Comparison of NLP Systems. We have proposed a\nzero-shot prompt-based strategy for explainable evaluation of the summarization\ntask using Large Language Models (LLMs). The conducted experiments demonstrate\nthe promising potential of LLMs as evaluation metrics in Natural Language\nProcessing (NLP), particularly in the field of summarization. Both few-shot and\nzero-shot approaches are employed in these experiments. The performance of our\nbest provided prompts achieved a Kendall correlation of 0.477 with human\nevaluations in the text summarization task on the test data. Code and results\nare publicly available on GitHub.", "published": "2023-11-20 06:06:22", "link": "http://arxiv.org/abs/2311.11552v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Refactoring Programs Using Large Language Models with Few-Shot Examples", "abstract": "A less complex and more straightforward program is a crucial factor that\nenhances its maintainability and makes writing secure and bug-free programs\neasier. However, due to its heavy workload and the risks of breaking the\nworking programs, programmers are reluctant to do code refactoring, and thus,\nit also causes the loss of potential learning experiences. To mitigate this, we\ndemonstrate the application of using a large language model (LLM), GPT-3.5, to\nsuggest less complex versions of the user-written Python program, aiming to\nencourage users to learn how to write better programs. We propose a method to\nleverage the prompting with few-shot examples of the LLM by selecting the\nbest-suited code refactoring examples for each target programming problem based\non the prior evaluation of prompting with the one-shot example. The\nquantitative evaluation shows that 95.68% of programs can be refactored by\ngenerating 10 candidates each, resulting in a 17.35% reduction in the average\ncyclomatic complexity and a 25.84% decrease in the average number of lines\nafter filtering only generated programs that are semantically correct.\nFurthermore, the qualitative evaluation shows outstanding capability in code\nformatting, while unnecessary behaviors such as deleting or translating\ncomments are also observed.", "published": "2023-11-20 11:43:45", "link": "http://arxiv.org/abs/2311.11690v1", "categories": ["cs.PL", "cs.AI", "cs.CL", "cs.SE"], "primary_category": "cs.PL"}
{"title": "Sparse Low-rank Adaptation of Pre-trained Language Models", "abstract": "Fine-tuning pre-trained large language models in a parameter-efficient manner\nis widely studied for its effectiveness and efficiency. The popular method of\nlow-rank adaptation (LoRA) offers a notable approach, hypothesizing that the\nadaptation process is intrinsically low-dimensional. Although LoRA has\ndemonstrated commendable performance, it is implemented with a fixed and\nunalterable intrinsic rank that might not always be the ideal choice.\nRecognizing the need for more flexible adaptation, we extend the methodology of\nLoRA to an innovative approach we call sparse low-rank adaptation (SoRA) that\nenables dynamic adjustments to the intrinsic rank during the adaptation\nprocess. We achieve this through the incorporation of a gate unit optimized\nwith proximal gradient method in the training stage, controlling the\ncardinality of rank under the sparsity of the gate. In the subsequent inference\nstage, we eliminate the parameter blocks corresponding to the zeroed-out ranks,\nto reduce each SoRA module back to a concise yet rank-optimal LoRA. Our\napproach strengthens the representation power of LoRA by initializing it with a\nhigher rank, while efficiently taming a temporarily increased number of\nparameters via updating in a sparse way. We further introduce a sparsifying\nscheduler for SoRA, aiming to examine the impact of the number of non-zero\nparameters on the model's memorization and generalization. Our experimental\nresults demonstrate that SoRA can outperform other baselines even with 70%\nretained parameters and 70% training time.", "published": "2023-11-20 11:56:25", "link": "http://arxiv.org/abs/2311.11696v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Control in Hybrid Chatbots", "abstract": "Customer data typically is held in database systems, which can be seen as\nrule-based knowledge base, whereas businesses increasingly want to benefit from\nthe capabilities of large, pre-trained language models.\n  In this technical report, we describe a case study of how a commercial rule\nengine and an integrated neural chatbot may be integrated, and what level of\ncontrol that particular integration mode leads to. We also discuss alternative\nways (including past ways realized in other systems) how researchers strive to\nmaintain control and avoid what has recently been called model \"hallucination\".", "published": "2023-11-20 12:08:32", "link": "http://arxiv.org/abs/2311.11701v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.HC", "68T50, 68T07", "I.2.7; H.3.3"], "primary_category": "cs.IR"}
{"title": "ELF: Encoding Speaker-Specific Latent Speech Feature for Speech\n  Synthesis", "abstract": "In this work, we propose a novel method for modeling numerous speakers, which\nenables expressing the overall characteristics of speakers in detail like a\ntrained multi-speaker model without additional training on the target speaker's\ndataset. Although various works with similar purposes have been actively\nstudied, their performance has not yet reached that of trained multi-speaker\nmodels due to their fundamental limitations. To overcome previous limitations,\nwe propose effective methods for feature learning and representing target\nspeakers' speech characteristics by discretizing the features and conditioning\nthem to a speech synthesis model. Our method obtained a significantly higher\nsimilarity mean opinion score (SMOS) in subjective similarity evaluation than\nseen speakers of a high-performance multi-speaker model, even with unseen\nspeakers. The proposed method also outperforms a zero-shot method by\nsignificant margins. Furthermore, our method shows remarkable performance in\ngenerating new artificial speakers. In addition, we demonstrate that the\nencoded latent features are sufficiently informative to reconstruct an original\nspeaker's speech completely. It implies that our method can be used as a\ngeneral methodology to encode and reconstruct speakers' characteristics in\nvarious tasks.", "published": "2023-11-20 13:13:24", "link": "http://arxiv.org/abs/2311.11745v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Beyond Boundaries: A Comprehensive Survey of Transferable Attacks on AI\n  Systems", "abstract": "Artificial Intelligence (AI) systems such as autonomous vehicles, facial\nrecognition, and speech recognition systems are increasingly integrated into\nour daily lives. However, despite their utility, these AI systems are\nvulnerable to a wide range of attacks such as adversarial, backdoor, data\npoisoning, membership inference, model inversion, and model stealing attacks.\nIn particular, numerous attacks are designed to target a particular model or\nsystem, yet their effects can spread to additional targets, referred to as\ntransferable attacks. Although considerable efforts have been directed toward\ndeveloping transferable attacks, a holistic understanding of the advancements\nin transferable attacks remains elusive. In this paper, we comprehensively\nexplore learning-based attacks from the perspective of transferability,\nparticularly within the context of cyber-physical security. We delve into\ndifferent domains -- the image, text, graph, audio, and video domains -- to\nhighlight the ubiquitous and pervasive nature of transferable attacks. This\npaper categorizes and reviews the architecture of existing attacks from various\nviewpoints: data, process, model, and system. We further examine the\nimplications of transferable attacks in practical scenarios such as autonomous\ndriving, speech recognition, and large language models (LLMs). Additionally, we\noutline the potential research directions to encourage efforts in exploring the\nlandscape of transferable attacks. This survey offers a holistic understanding\nof the prevailing transferable attacks and their impacts across different\ndomains.", "published": "2023-11-20 14:29:45", "link": "http://arxiv.org/abs/2311.11796v1", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.CR"}
{"title": "System 2 Attention (is something you might need too)", "abstract": "Soft attention in Transformer-based Large Language Models (LLMs) is\nsusceptible to incorporating irrelevant information from the context into its\nlatent representations, which adversely affects next token generations. To help\nrectify these issues, we introduce System 2 Attention (S2A), which leverages\nthe ability of LLMs to reason in natural language and follow instructions in\norder to decide what to attend to. S2A regenerates the input context to only\ninclude the relevant portions, before attending to the regenerated context to\nelicit the final response. In experiments, S2A outperforms standard\nattention-based LLMs on three tasks containing opinion or irrelevant\ninformation, QA, math word problems and longform generation, where S2A\nincreases factuality and objectivity, and decreases sycophancy.", "published": "2023-11-20 15:04:50", "link": "http://arxiv.org/abs/2311.11829v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LLMs as Visual Explainers: Advancing Image Classification with Evolving\n  Visual Descriptions", "abstract": "Vision-language models (VLMs) offer a promising paradigm for image\nclassification by comparing the similarity between images and class embeddings.\nA critical challenge lies in crafting precise textual representations for class\nnames. While previous studies have leveraged recent advancements in large\nlanguage models (LLMs) to enhance these descriptors, their outputs often suffer\nfrom ambiguity and inaccuracy. We attribute this to two primary factors: 1) the\nreliance on single-turn textual interactions with LLMs, leading to a mismatch\nbetween generated text and visual concepts for VLMs; 2) the oversight of the\ninter-class relationships, resulting in descriptors that fail to differentiate\nsimilar classes effectively. In this paper, we propose a novel framework that\nintegrates LLMs and VLMs to find the optimal class descriptors. Our\ntraining-free approach develops an LLM-based agent with an evolutionary\noptimization strategy to iteratively refine class descriptors. We demonstrate\nour optimized descriptors are of high quality which effectively improves\nclassification accuracy on a wide range of benchmarks. Additionally, these\ndescriptors offer explainable and robust features, boosting performance across\nvarious backbone models and complementing fine-tuning-based methods.", "published": "2023-11-20 16:37:45", "link": "http://arxiv.org/abs/2311.11904v2", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "FinanceBench: A New Benchmark for Financial Question Answering", "abstract": "FinanceBench is a first-of-its-kind test suite for evaluating the performance\nof LLMs on open book financial question answering (QA). It comprises 10,231\nquestions about publicly traded companies, with corresponding answers and\nevidence strings. The questions in FinanceBench are ecologically valid and\ncover a diverse set of scenarios. They are intended to be clear-cut and\nstraightforward to answer to serve as a minimum performance standard. We test\n16 state of the art model configurations (including GPT-4-Turbo, Llama2 and\nClaude2, with vector stores and long context prompts) on a sample of 150 cases\nfrom FinanceBench, and manually review their answers (n=2,400). The cases are\navailable open-source. We show that existing LLMs have clear limitations for\nfinancial QA. Notably, GPT-4-Turbo used with a retrieval system incorrectly\nanswered or refused to answer 81% of questions. While augmentation techniques\nsuch as using longer context window to feed in relevant evidence improve\nperformance, they are unrealistic for enterprise settings due to increased\nlatency and cannot support larger financial documents. We find that all models\nexamined exhibit weaknesses, such as hallucinations, that limit their\nsuitability for use by enterprises.", "published": "2023-11-20 17:28:02", "link": "http://arxiv.org/abs/2311.11944v1", "categories": ["cs.CL", "cs.AI", "cs.CE", "stat.ML"], "primary_category": "cs.CL"}
{"title": "GPT-4V(ision) for Robotics: Multimodal Task Planning from Human\n  Demonstration", "abstract": "We introduce a pipeline that enhances a general-purpose Vision Language\nModel, GPT-4V(ision), to facilitate one-shot visual teaching for robotic\nmanipulation. This system analyzes videos of humans performing tasks and\noutputs executable robot programs that incorporate insights into affordances.\nThe process begins with GPT-4V analyzing the videos to obtain textual\nexplanations of environmental and action details. A GPT-4-based task planner\nthen encodes these details into a symbolic task plan. Subsequently, vision\nsystems spatially and temporally ground the task plan in the videos. Objects\nare identified using an open-vocabulary object detector, and hand-object\ninteractions are analyzed to pinpoint moments of grasping and releasing. This\nspatiotemporal grounding allows for the gathering of affordance information\n(e.g., grasp types, waypoints, and body postures) critical for robot execution.\nExperiments across various scenarios demonstrate the method's efficacy in\nenabling real robots to operate from one-shot human demonstrations. Meanwhile,\nquantitative tests have revealed instances of hallucination in GPT-4V,\nhighlighting the importance of incorporating human supervision within the\npipeline. The prompts of GPT-4V/GPT-4 are available at this project page:\nhttps://microsoft.github.io/GPT4Vision-Robot-Manipulation-Prompts/", "published": "2023-11-20 18:54:39", "link": "http://arxiv.org/abs/2311.12015v4", "categories": ["cs.RO", "cs.CL", "cs.CV"], "primary_category": "cs.RO"}
{"title": "App for Resume-Based Job Matching with Speech Interviews and Grammar\n  Analysis: A Review", "abstract": "Through the advancement in natural language processing (NLP), specifically in\nspeech recognition, fully automated complex systems functioning on voice input\nhave started proliferating in areas such as home automation. These systems have\nbeen termed Automatic Speech Recognition Systems (ASR). In this review paper,\nwe explore the feasibility of an end-to-end system providing speech and text\nbased natural language processing for job interview preparation as well as\nrecommendation of relevant job postings. We also explore existing\nrecommender-based systems and note their limitations. This literature review\nwould help us identify the approaches and limitations of the various similar\nuse-cases of NLP technology for our upcoming project.", "published": "2023-11-20 18:03:08", "link": "http://arxiv.org/abs/2311.14729v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "I.7.0; I.2.7"], "primary_category": "cs.CL"}
{"title": "MemoryCompanion: A Smart Healthcare Solution to Empower Efficient\n  Alzheimer's Care Via Unleashing Generative AI", "abstract": "With the rise of Large Language Models (LLMs), notably characterized by GPT\nframeworks, there emerges a catalyst for novel healthcare applications. Earlier\niterations of chatbot caregivers, though existent, have yet to achieve a\ndimension of human-like authenticity. This paper unveils `MemoryCompanion' a\npioneering digital health solution explicitly tailored for Alzheimer's disease\n(AD) patients and their caregivers. Drawing upon the nuances of GPT technology\nand prompt engineering, MemoryCompanion manifests a personalized caregiving\nparadigm, fostering interactions via voice-cloning and talking-face mechanisms\nthat resonate with the familiarity of known companions. Using advanced\nprompt-engineering, the system intricately adapts to each patient's distinct\nprofile, curating its content and communication style accordingly. This\napproach strives to counteract prevalent issues of social isolation and\nloneliness frequently observed in AD demographics. Our methodology, grounded in\nits innovative design, addresses both the caregiving and technological\nchallenges intrinsic to this domain.", "published": "2023-11-20 19:41:50", "link": "http://arxiv.org/abs/2311.14730v1", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Igniting Language Intelligence: The Hitchhiker's Guide From\n  Chain-of-Thought Reasoning to Language Agents", "abstract": "Large language models (LLMs) have dramatically enhanced the field of language\nintelligence, as demonstrably evidenced by their formidable empirical\nperformance across a spectrum of complex reasoning tasks. Additionally,\ntheoretical proofs have illuminated their emergent reasoning capabilities,\nproviding a compelling showcase of their advanced cognitive abilities in\nlinguistic contexts. Critical to their remarkable efficacy in handling complex\nreasoning tasks, LLMs leverage the intriguing chain-of-thought (CoT) reasoning\ntechniques, obliging them to formulate intermediate steps en route to deriving\nan answer. The CoT reasoning approach has not only exhibited proficiency in\namplifying reasoning performance but also in enhancing interpretability,\ncontrollability, and flexibility. In light of these merits, recent research\nendeavors have extended CoT reasoning methodologies to nurture the development\nof autonomous language agents, which adeptly adhere to language instructions\nand execute actions within varied environments. This survey paper orchestrates\na thorough discourse, penetrating vital research dimensions, encompassing: (i)\nthe foundational mechanics of CoT techniques, with a focus on elucidating the\ncircumstances and justification behind its efficacy; (ii) the paradigm shift in\nCoT; and (iii) the burgeoning of language agents fortified by CoT approaches.\nProspective research avenues envelop explorations into generalization,\nefficiency, customization, scaling, and safety. This paper caters to a wide\naudience, including beginners seeking comprehensive knowledge of CoT reasoning\nand language agents, as well as experienced researchers interested in\nfoundational mechanics and engaging in cutting-edge discussions on these\ntopics. A repository for the related papers is available at\nhttps://github.com/Zoeyyao27/CoT-Igniting-Agent.", "published": "2023-11-20 14:30:55", "link": "http://arxiv.org/abs/2311.11797v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.HC", "cs.MA"], "primary_category": "cs.CL"}
{"title": "APNet2: High-quality and High-efficiency Neural Vocoder with Direct\n  Prediction of Amplitude and Phase Spectra", "abstract": "In our previous work, we proposed a neural vocoder called APNet, which\ndirectly predicts speech amplitude and phase spectra with a 5 ms frame shift in\nparallel from the input acoustic features, and then reconstructs the 16 kHz\nspeech waveform using inverse short-time Fourier transform (ISTFT). APNet\ndemonstrates the capability to generate synthesized speech of comparable\nquality to the HiFi-GAN vocoder but with a considerably improved inference\nspeed. However, the performance of the APNet vocoder is constrained by the\nwaveform sampling rate and spectral frame shift, limiting its practicality for\nhigh-quality speech synthesis. Therefore, this paper proposes an improved\niteration of APNet, named APNet2. The proposed APNet2 vocoder adopts ConvNeXt\nv2 as the backbone network for amplitude and phase predictions, expecting to\nenhance the modeling capability. Additionally, we introduce a multi-resolution\ndiscriminator (MRD) into the GAN-based losses and optimize the form of certain\nlosses. At a common configuration with a waveform sampling rate of 22.05 kHz\nand spectral frame shift of 256 points (i.e., approximately 11.6ms), our\nproposed APNet2 vocoder outperformed the original APNet and Vocos vocoders in\nterms of synthesized speech quality. The synthesized speech quality of APNet2\nis also comparable to that of HiFi-GAN and iSTFTNet, while offering a\nsignificantly faster inference speed.", "published": "2023-11-20 05:37:03", "link": "http://arxiv.org/abs/2311.11545v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Neural network-based virtual microphone estimation with virtual\n  microphone and beamformer-level multi-task loss", "abstract": "Array processing performance depends on the number of microphones available.\nVirtual microphone estimation (VME) has been proposed to increase the number of\nmicrophone signals artificially. Neural network-based VME (NN-VME) trains an NN\nwith a VM-level loss to predict a signal at a microphone location that is\navailable during training but not at inference. However, this training\nobjective may not be optimal for a specific array processing back-end, such as\nbeamforming. An alternative approach is to use a training objective considering\nthe array-processing back-end, such as a loss on the beamformer output. This\napproach may generate signals optimal for beamforming but not physically\ngrounded. To combine the advantages of both approaches, this paper proposes a\nmulti-task loss for NN-VME that combines both VM-level and beamformer-level\nlosses. We evaluate the proposed multi-task NN-VME on multi-talker\nunderdetermined conditions and show that it achieves a 33.1 % relative WER\nimprovement compared to using only real microphones and 10.8 % compared to\nusing a prior NN-VME approach.", "published": "2023-11-20 08:18:16", "link": "http://arxiv.org/abs/2311.11595v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "How does end-to-end speech recognition training impact speech\n  enhancement artifacts?", "abstract": "Jointly training a speech enhancement (SE) front-end and an automatic speech\nrecognition (ASR) back-end has been investigated as a way to mitigate the\ninfluence of \\emph{processing distortion} generated by single-channel SE on\nASR. In this paper, we investigate the effect of such joint training on the\nsignal-level characteristics of the enhanced signals from the viewpoint of the\ndecomposed noise and artifact errors. The experimental analyses provide two\nnovel findings: 1) ASR-level training of the SE front-end reduces the artifact\nerrors while increasing the noise errors, and 2) simply interpolating the\nenhanced and observed signals, which achieves a similar effect of reducing\nartifacts and increasing noise, improves ASR performance without jointly\nmodifying the SE and ASR modules, even for a strong ASR back-end using a WavLM\nfeature extractor. Our findings provide a better understanding of the effect of\njoint training and a novel insight for designing an ASR agnostic SE front-end.", "published": "2023-11-20 08:23:58", "link": "http://arxiv.org/abs/2311.11599v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Improving Label Assignments Learning by Dynamic Sample Dropout Combined\n  with Layer-wise Optimization in Speech Separation", "abstract": "In supervised speech separation, permutation invariant training (PIT) is\nwidely used to handle label ambiguity by selecting the best permutation to\nupdate the model. Despite its success, previous studies showed that PIT is\nplagued by excessive label assignment switching in adjacent epochs, impeding\nthe model to learn better label assignments. To address this issue, we propose\na novel training strategy, dynamic sample dropout (DSD), which considers\nprevious best label assignments and evaluation metrics to exclude the samples\nthat may negatively impact the learned label assignments during training.\nAdditionally, we include layer-wise optimization (LO) to improve the\nperformance by solving layer-decoupling. Our experiments showed that combining\nDSD and LO outperforms the baseline and solves excessive label assignment\nswitching and layer-decoupling issues. The proposed DSD and LO approach is easy\nto implement, requires no extra training sets or steps, and shows generality to\nvarious speech separation tasks.", "published": "2023-11-20 21:37:38", "link": "http://arxiv.org/abs/2311.12199v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
