{"title": "Think Twice Before Trusting: Self-Detection for Large Language Models\n  through Comprehensive Answer Reflection", "abstract": "Self-detection for Large Language Models (LLMs) seeks to evaluate the\ntrustworthiness of the LLM's output by leveraging its own capabilities, thereby\nalleviating the issue of output hallucination. However, existing self-detection\napproaches only retrospectively evaluate answers generated by LLM, typically\nleading to the over-trust in incorrectly generated answers. To tackle this\nlimitation, we propose a novel self-detection paradigm that considers the\ncomprehensive answer space beyond LLM-generated answers. It thoroughly compares\nthe trustworthiness of multiple candidate answers to mitigate the over-trust in\nLLM-generated incorrect answers. Building upon this paradigm, we introduce a\ntwo-step framework, which firstly instructs LLM to reflect and provide\njustifications for each candidate answer, and then aggregates the\njustifications for comprehensive target answer evaluation. This framework can\nbe seamlessly integrated with existing approaches for superior self-detection.\nExtensive experiments on six datasets spanning three tasks demonstrate the\neffectiveness of the proposed framework.", "published": "2024-03-15 02:38:26", "link": "http://arxiv.org/abs/2403.09972v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Identifying Health Risks from Family History: A Survey of Natural\n  Language Processing Techniques", "abstract": "Electronic health records include information on patients' status and medical\nhistory, which could cover the history of diseases and disorders that could be\nhereditary. One important use of family history information is in precision\nhealth, where the goal is to keep the population healthy with preventative\nmeasures. Natural Language Processing (NLP) and machine learning techniques can\nassist with identifying information that could assist health professionals in\nidentifying health risks before a condition is developed in their later years,\nsaving lives and reducing healthcare costs.\n  We survey the literature on the techniques from the NLP field that have been\ndeveloped to utilise digital health records to identify risks of familial\ndiseases. We highlight that rule-based methods are heavily investigated and are\nstill actively used for family history extraction. Still, more recent efforts\nhave been put into building neural models based on large-scale pre-trained\nlanguage models. In addition to the areas where NLP has successfully been\nutilised, we also identify the areas where more research is needed to unlock\nthe value of patients' records regarding data collection, task formulation and\ndownstream applications.", "published": "2024-03-15 03:43:07", "link": "http://arxiv.org/abs/2403.09997v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Triple GNNs: Introducing Syntactic and Semantic Information for\n  Conversational Aspect-Based Quadruple Sentiment Analysis", "abstract": "Conversational Aspect-Based Sentiment Analysis (DiaASQ) aims to detect\nquadruples \\{target, aspect, opinion, sentiment polarity\\} from given\ndialogues. In DiaASQ, elements constituting these quadruples are not\nnecessarily confined to individual sentences but may span across multiple\nutterances within a dialogue. This necessitates a dual focus on both the\nsyntactic information of individual utterances and the semantic interaction\namong them. However, previous studies have primarily focused on coarse-grained\nrelationships between utterances, thus overlooking the potential benefits of\ndetailed intra-utterance syntactic information and the granularity of\ninter-utterance relationships. This paper introduces the Triple GNNs network to\nenhance DiaAsQ. It employs a Graph Convolutional Network (GCN) for modeling\nsyntactic dependencies within utterances and a Dual Graph Attention Network\n(DualGATs) to construct interactions between utterances. Experiments on two\nstandard datasets reveal that our model significantly outperforms\nstate-of-the-art baselines. The code is available at\n\\url{https://github.com/nlperi2b/Triple-GNNs-}.", "published": "2024-03-15 07:15:48", "link": "http://arxiv.org/abs/2403.10065v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Factual Statements be Deceptive? The DeFaBel Corpus of Belief-based\n  Deception", "abstract": "If a person firmly believes in a non-factual statement, such as \"The Earth is\nflat\", and argues in its favor, there is no inherent intention to deceive. As\nthe argumentation stems from genuine belief, it may be unlikely to exhibit the\nlinguistic properties associated with deception or lying. This interplay of\nfactuality, personal belief, and intent to deceive remains an understudied\narea. Disentangling the influence of these variables in argumentation is\ncrucial to gain a better understanding of the linguistic properties attributed\nto each of them. To study the relation between deception and factuality, based\non belief, we present the DeFaBel corpus, a crowd-sourced resource of\nbelief-based deception. To create this corpus, we devise a study in which\nparticipants are instructed to write arguments supporting statements like\n\"eating watermelon seeds can cause indigestion\", regardless of its factual\naccuracy or their personal beliefs about the statement. In addition to the\ngeneration task, we ask them to disclose their belief about the statement. The\ncollected instances are labelled as deceptive if the arguments are in\ncontradiction to the participants' personal beliefs. Each instance in the\ncorpus is thus annotated (or implicitly labelled) with personal beliefs of the\nauthor, factuality of the statement, and the intended deceptiveness. The\nDeFaBel corpus contains 1031 texts in German, out of which 643 are deceptive\nand 388 are non-deceptive. It is the first publicly available corpus for\nstudying deception in German. In our analysis, we find that people are more\nconfident in the persuasiveness of their arguments when the statement is\naligned with their belief, but surprisingly less confident when they are\ngenerating arguments in favor of facts. The DeFaBel corpus can be obtained from\nhttps://www.ims.uni-stuttgart.de/data/defabel", "published": "2024-03-15 10:46:00", "link": "http://arxiv.org/abs/2403.10185v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhanced Coherence-Aware Network with Hierarchical Disentanglement for\n  Aspect-Category Sentiment Analysis", "abstract": "Aspect-category-based sentiment analysis (ACSA), which aims to identify\naspect categories and predict their sentiments has been intensively studied due\nto its wide range of NLP applications. Most approaches mainly utilize\nintrasentential features. However, a review often includes multiple different\naspect categories, and some of them do not explicitly appear in the review.\nEven in a sentence, there is more than one aspect category with its sentiments,\nand they are entangled intra-sentence, which makes the model fail to\ndiscriminately preserve all sentiment characteristics. In this paper, we\npropose an enhanced coherence-aware network with hierarchical disentanglement\n(ECAN) for ACSA tasks. Specifically, we explore coherence modeling to capture\nthe contexts across the whole review and to help the implicit aspect and\nsentiment identification. To address the issue of multiple aspect categories\nand sentiment entanglement, we propose a hierarchical disentanglement module to\nextract distinct categories and sentiment features. Extensive experimental and\nvisualization results show that our ECAN effectively decouples multiple\ncategories and sentiments entangled in the coherence representations and\nachieves state-of-the-art (SOTA) performance. Our codes and data are available\nonline: \\url{https://github.com/cuijin-23/ECAN}.", "published": "2024-03-15 11:32:44", "link": "http://arxiv.org/abs/2403.10214v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A comprehensive study on Frequent Pattern Mining and Clustering\n  categories for topic detection in Persian text stream", "abstract": "Topic detection is a complex process and depends on language because it\nsomehow needs to analyze text. There have been few studies on topic detection\nin Persian, and the existing algorithms are not remarkable. Therefore, we aimed\nto study topic detection in Persian. The objectives of this study are: 1) to\nconduct an extensive study on the best algorithms for topic detection, 2) to\nidentify necessary adaptations to make these algorithms suitable for the\nPersian language, and 3) to evaluate their performance on Persian social\nnetwork texts. To achieve these objectives, we have formulated two research\nquestions: First, considering the lack of research in Persian, what\nmodifications should be made to existing frameworks, especially those developed\nin English, to make them compatible with Persian? Second, how do these\nalgorithms perform, and which one is superior? There are various topic\ndetection methods that can be categorized into different categories. Frequent\npattern and clustering are selected for this research, and a hybrid of both is\nproposed as a new category. Then, ten methods from these three categories are\nselected. All of them are re-implemented from scratch, changed, and adapted\nwith Persian. These ten methods encompass different types of topic detection\nmethods and have shown good performance in English. The text of Persian social\nnetwork posts is used as the dataset. Additionally, a new multiclass evaluation\ncriterion, called FS, is used in this paper for the first time in the field of\ntopic detection. Approximately 1.4 billion tokens are processed during\nexperiments. The results indicate that if we are searching for keyword-topics\nthat are easily understandable by humans, the hybrid category is better.\nHowever, if the aim is to cluster posts for further analysis, the frequent\npattern category is more suitable.", "published": "2024-03-15 12:08:58", "link": "http://arxiv.org/abs/2403.10237v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Is Translation All You Need? A Study on Solving Multilingual Tasks with\n  Large Language Models", "abstract": "Large language models (LLMs) have demonstrated multilingual capabilities;\nyet, they are mostly English-centric due to the imbalanced training corpora.\nExisting works leverage this phenomenon to improve their multilingual\nperformances through translation, primarily on natural language processing\n(NLP) tasks. This work extends the evaluation from NLP tasks to real user\nqueries and from English-centric LLMs to non-English-centric LLMs. While\ntranslation into English can help improve the performance of multilingual NLP\ntasks for English-centric LLMs, it may not be optimal for all scenarios. For\nculture-related tasks that need deep language understanding, prompting in the\nnative language tends to be more promising as it better captures the nuances of\nculture and language. Our experiments reveal varied behaviors among different\nLLMs and tasks in the multilingual context. Therefore, we advocate for more\ncomprehensive multilingual evaluation and more efforts toward developing\nmultilingual LLMs beyond English-centric ones.", "published": "2024-03-15 12:47:39", "link": "http://arxiv.org/abs/2403.10258v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MaiBaam: A Multi-Dialectal Bavarian Universal Dependency Treebank", "abstract": "Despite the success of the Universal Dependencies (UD) project exemplified by\nits impressive language breadth, there is still a lack in `within-language\nbreadth': most treebanks focus on standard languages. Even for German, the\nlanguage with the most annotations in UD, so far no treebank exists for one of\nits language varieties spoken by over 10M people: Bavarian. To contribute to\nclosing this gap, we present the first multi-dialect Bavarian treebank\n(MaiBaam) manually annotated with part-of-speech and syntactic dependency\ninformation in UD, covering multiple text genres (wiki, fiction, grammar\nexamples, social, non-fiction). We highlight the morphosyntactic differences\nbetween the closely-related Bavarian and German and showcase the rich\nvariability of speakers' orthographies. Our corpus includes 15k tokens,\ncovering dialects from all Bavarian-speaking areas spanning three countries. We\nprovide baseline parsing and POS tagging results, which are lower than results\nobtained on German and vary substantially between different graph-based\nparsers. To support further research on Bavarian syntax, we make our dataset,\nlanguage-specific guidelines and code publicly available.", "published": "2024-03-15 13:33:10", "link": "http://arxiv.org/abs/2403.10293v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating grammatical abstraction in language models using few-shot\n  learning of novel noun gender", "abstract": "Humans can learn a new word and infer its grammatical properties from very\nfew examples. They have an abstract notion of linguistic properties like\ngrammatical gender and agreement rules that can be applied to novel syntactic\ncontexts and words. Drawing inspiration from psycholinguistics, we conduct a\nnoun learning experiment to assess whether an LSTM and a decoder-only\ntransformer can achieve human-like abstraction of grammatical gender in French.\nLanguage models were tasked with learning the gender of a novel noun embedding\nfrom a few examples in one grammatical agreement context and predicting\nagreement in another, unseen context. We find that both language models\neffectively generalise novel noun gender from one to two learning examples and\napply the learnt gender across agreement contexts, albeit with a bias for the\nmasculine gender category. Importantly, the few-shot updates were only applied\nto the embedding layers, demonstrating that models encode sufficient gender\ninformation within the word embedding space. While the generalisation behaviour\nof models suggests that they represent grammatical gender as an abstract\ncategory, like humans, further work is needed to explore the details of how\nexactly this is implemented. For a comparative perspective with human\nbehaviour, we conducted an analogous one-shot novel noun gender learning\nexperiment, which revealed that native French speakers, like language models,\nalso exhibited a masculine gender bias and are not excellent one-shot learners\neither.", "published": "2024-03-15 14:25:59", "link": "http://arxiv.org/abs/2403.10338v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TriSum: Learning Summarization Ability from Large Language Models with\n  Structured Rationale", "abstract": "The advent of large language models (LLMs) has significantly advanced natural\nlanguage processing tasks like text summarization. However, their large size\nand computational demands, coupled with privacy concerns in data transmission,\nlimit their use in resource-constrained and privacy-centric settings. To\novercome this, we introduce TriSum, a framework for distilling LLMs' text\nsummarization abilities into a compact, local model. Initially, LLMs extract a\nset of aspect-triple rationales and summaries, which are refined using a\ndual-scoring method for quality. Next, a smaller local model is trained with\nthese tasks, employing a curriculum learning strategy that evolves from simple\nto complex tasks. Our method enhances local model performance on various\nbenchmarks (CNN/DailyMail, XSum, and ClinicalTrial), outperforming baselines by\n4.5%, 8.5%, and 7.4%, respectively. It also improves interpretability by\nproviding insights into the summarization rationale.", "published": "2024-03-15 14:36:38", "link": "http://arxiv.org/abs/2403.10351v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Monotonic Representation of Numeric Properties in Language Models", "abstract": "Language models (LMs) can express factual knowledge involving numeric\nproperties such as Karl Popper was born in 1902. However, how this information\nis encoded in the model's internal representations is not understood well.\nHere, we introduce a simple method for finding and editing representations of\nnumeric properties such as an entity's birth year. Empirically, we find\nlow-dimensional subspaces that encode numeric properties monotonically, in an\ninterpretable and editable fashion. When editing representations along\ndirections in these subspaces, LM output changes accordingly. For example, by\npatching activations along a \"birthyear\" direction we can make the LM express\nan increasingly late birthyear: Karl Popper was born in 1929, Karl Popper was\nborn in 1957, Karl Popper was born in 1968. Property-encoding directions exist\nacross several numeric properties in all models under consideration, suggesting\nthe possibility that monotonic representation of numeric properties\nconsistently emerges during LM pretraining. Code:\nhttps://github.com/bheinzerling/numeric-property-repr", "published": "2024-03-15 15:10:41", "link": "http://arxiv.org/abs/2403.10381v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Multilingual Perspective on Probing Gender Bias", "abstract": "Gender bias represents a form of systematic negative treatment that targets\nindividuals based on their gender. This discrimination can range from subtle\nsexist remarks and gendered stereotypes to outright hate speech. Prior research\nhas revealed that ignoring online abuse not only affects the individuals\ntargeted but also has broader societal implications. These consequences extend\nto the discouragement of women's engagement and visibility within public\nspheres, thereby reinforcing gender inequality. This thesis investigates the\nnuances of how gender bias is expressed through language and within language\ntechnologies. Significantly, this thesis expands research on gender bias to\nmultilingual contexts, emphasising the importance of a multilingual and\nmulticultural perspective in understanding societal biases. In this thesis, I\nadopt an interdisciplinary approach, bridging natural language processing with\nother disciplines such as political science and history, to probe gender bias\nin natural language and language models.", "published": "2024-03-15 21:35:21", "link": "http://arxiv.org/abs/2403.10699v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Using Contextual Information for Sentence-level Morpheme Segmentation", "abstract": "Recent advancements in morpheme segmentation primarily emphasize word-level\nsegmentation, often neglecting the contextual relevance within the sentence. In\nthis study, we redefine the morpheme segmentation task as a\nsequence-to-sequence problem, treating the entire sentence as input rather than\nisolating individual words. Our findings reveal that the multilingual model\nconsistently exhibits superior performance compared to monolingual\ncounterparts. While our model did not surpass the performance of the current\nstate-of-the-art, it demonstrated comparable efficacy with high-resource\nlanguages while revealing limitations in low-resource language scenarios.", "published": "2024-03-15 20:12:32", "link": "http://arxiv.org/abs/2403.15436v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lost in Overlap: Exploring Logit-based Watermark Collision in LLMs", "abstract": "The proliferation of large language models (LLMs) in generating content\nraises concerns about text copyright. Watermarking methods, particularly\nlogit-based approaches, embed imperceptible identifiers into text to address\nthese challenges. However, the widespread usage of watermarking across diverse\nLLMs has led to an inevitable issue known as watermark collision during common\ntasks, such as paraphrasing or translation. In this paper, we introduce\nwatermark collision as a novel and general philosophy for watermark attacks,\naimed at enhancing attack performance on top of any other attacking methods. We\nalso provide a comprehensive demonstration that watermark collision poses a\nthreat to all logit-based watermark algorithms, impacting not only specific\nattack scenarios but also downstream applications.", "published": "2024-03-15 05:06:21", "link": "http://arxiv.org/abs/2403.10020v3", "categories": ["cs.CL", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Don't Half-listen: Capturing Key-part Information in Continual\n  Instruction Tuning", "abstract": "Instruction tuning for large language models (LLMs) can drive them to produce\nresults consistent with human goals in specific downstream tasks. However, the\nprocess of continual instruction tuning (CIT) for LLMs may bring about the\ncatastrophic forgetting (CF) problem, where previously learned abilities are\ndegraded. Recent methods try to alleviate the CF problem by modifying models or\nreplaying data, which may only remember the surface-level pattern of\ninstructions and get confused on held-out tasks. In this paper, we propose a\nnovel continual instruction tuning method based on Key-part Information Gain\n(KPIG). Our method computes the information gain on masked parts to dynamically\nreplay data and refine the training objective, which enables LLMs to capture\ntask-aware information relevant to the correct response and alleviate\noverfitting to general descriptions in instructions. In addition, we propose\ntwo metrics, P-score and V-score, to measure the generalization and\ninstruction-following abilities of LLMs. Experiments demonstrate our method\nachieves superior performance on both seen and held-out tasks.", "published": "2024-03-15 06:54:20", "link": "http://arxiv.org/abs/2403.10056v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Repoformer: Selective Retrieval for Repository-Level Code Completion", "abstract": "Recent advances in retrieval-augmented generation (RAG) have initiated a new\nera in repository-level code completion. However, the invariable use of\nretrieval in existing methods exposes issues in both efficiency and robustness,\nwith a large proportion of the retrieved contexts proving unhelpful or harmful\nto code language models (code LMs). In this paper, we propose a selective RAG\nframework to avoid retrieval when unnecessary. To power this framework, we\ndesign a self-supervised learning approach to enable a code LM to accurately\nself-evaluate whether retrieval can improve its output quality and robustly\nleverage the potentially noisy retrieved contexts. Using this LM as both the\nselective RAG policy and the generation model, our framework achieves\nstate-of-the-art repository-level code completion performance on diverse\nbenchmarks including RepoEval, CrossCodeEval, and CrossCodeLongEval, a new\nlong-form code completion benchmark. Meanwhile, our analyses show that\nselectively retrieving brings as much as 70% inference speedup in the online\nserving setting without harming the performance. We further demonstrate that\nour framework is able to accommodate different generation models, retrievers,\nand programming languages. These advancements position our framework as an\nimportant step towards more accurate and efficient repository-level code\ncompletion.", "published": "2024-03-15 06:59:43", "link": "http://arxiv.org/abs/2403.10059v2", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "DRAGIN: Dynamic Retrieval Augmented Generation based on the Information\n  Needs of Large Language Models", "abstract": "Dynamic retrieval augmented generation (RAG) paradigm actively decides when\nand what to retrieve during the text generation process of Large Language\nModels (LLMs). There are two key elements of this paradigm: identifying the\noptimal moment to activate the retrieval module (deciding when to retrieve) and\ncrafting the appropriate query once retrieval is triggered (determining what to\nretrieve). However, current dynamic RAG methods fall short in both aspects.\nFirstly, the strategies for deciding when to retrieve often rely on static\nrules. Moreover, the strategies for deciding what to retrieve typically limit\nthemselves to the LLM's most recent sentence or the last few tokens, while the\nLLM's real-time information needs may span across the entire context. To\novercome these limitations, we introduce a new framework, DRAGIN, i.e., Dynamic\nRetrieval Augmented Generation based on the real-time Information Needs of\nLLMs. Our framework is specifically designed to make decisions on when and what\nto retrieve based on the LLM's real-time information needs during the text\ngeneration process. We evaluate DRAGIN along with existing methods\ncomprehensively over 4 knowledge-intensive generation datasets. Experimental\nresults show that DRAGIN achieves superior performance on all tasks,\ndemonstrating the effectiveness of our method. We have open-sourced all the\ncode, data, and models in GitHub: https://github.com/oneal2000/DRAGIN/tree/main", "published": "2024-03-15 07:45:37", "link": "http://arxiv.org/abs/2403.10081v3", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Intent-conditioned and Non-toxic Counterspeech Generation using\n  Multi-Task Instruction Tuning with RLAIF", "abstract": "Counterspeech, defined as a response to mitigate online hate speech, is\nincreasingly used as a non-censorial solution. Addressing hate speech\neffectively involves dispelling the stereotypes, prejudices, and biases often\nsubtly implied in brief, single-sentence statements or abuses. These implicit\nexpressions challenge language models, especially in seq2seq tasks, as model\nperformance typically excels with longer contexts. Our study introduces CoARL,\na novel framework enhancing counterspeech generation by modeling the pragmatic\nimplications underlying social biases in hateful statements. CoARL's first two\nphases involve sequential multi-instruction tuning, teaching the model to\nunderstand intents, reactions, and harms of offensive statements, and then\nlearning task-specific low-rank adapter weights for generating\nintent-conditioned counterspeech. The final phase uses reinforcement learning\nto fine-tune outputs for effectiveness and non-toxicity. CoARL outperforms\nexisting benchmarks in intent-conditioned counterspeech generation, showing an\naverage improvement of 3 points in intent-conformity and 4 points in\nargument-quality metrics. Extensive human evaluation supports CoARL's efficacy\nin generating superior and more context-appropriate responses compared to\nexisting systems, including prominent LLMs like ChatGPT.", "published": "2024-03-15 08:03:49", "link": "http://arxiv.org/abs/2403.10088v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "RAFT: Adapting Language Model to Domain Specific RAG", "abstract": "Pretraining Large Language Models (LLMs) on large corpora of textual data is\nnow a standard paradigm. When using these LLMs for many downstream\napplications, it is common to additionally bake in new knowledge (e.g.,\ntime-critical news, or private domain knowledge) into the pretrained model\neither through RAG-based-prompting, or fine-tuning. However, the optimal\nmethodology for the model to gain such new knowledge remains an open question.\nIn this paper, we present Retrieval Augmented FineTuning (RAFT), a training\nrecipe that improves the model's ability to answer questions in a \"open-book\"\nin-domain settings. In RAFT, given a question, and a set of retrieved\ndocuments, we train the model to ignore those documents that don't help in\nanswering the question, which we call, distractor documents. RAFT accomplishes\nthis by citing verbatim the right sequence from the relevant document that\nwould help answer the question. This coupled with RAFT's chain-of-thought-style\nresponse helps improve the model's ability to reason. In domain-specific RAG,\nRAFT consistently improves the model's performance across PubMed, HotpotQA, and\nGorilla datasets, presenting a post-training recipe to improve pre-trained LLMs\nto in-domain RAG. RAFT's code and demo are open-sourced at\ngithub.com/ShishirPatil/gorilla.", "published": "2024-03-15 09:26:02", "link": "http://arxiv.org/abs/2403.10131v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Read between the lines -- Functionality Extraction From READMEs", "abstract": "While text summarization is a well-known NLP task, in this paper, we\nintroduce a novel and useful variant of it called functionality extraction from\nGit README files. Though this task is a text2text generation at an abstract\nlevel, it involves its own peculiarities and challenges making existing\ntext2text generation systems not very useful. The motivation behind this task\nstems from a recent surge in research and development activities around the use\nof large language models for code-related tasks, such as code refactoring, code\nsummarization, etc. We also release a human-annotated dataset called FuncRead,\nand develop a battery of models for the task. Our exhaustive experimentation\nshows that small size fine-tuned models beat any baseline models that can be\ndesigned using popular black-box or white-box large language models (LLMs) such\nas ChatGPT and Bard. Our best fine-tuned 7 Billion CodeLlama model exhibit 70%\nand 20% gain on the F1 score against ChatGPT and Bard respectively.", "published": "2024-03-15 11:11:57", "link": "http://arxiv.org/abs/2403.10205v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Question on the Explainability of Large Language Models and the\n  Word-Level Univariate First-Order Plausibility Assumption", "abstract": "The explanations of large language models have recently been shown to be\nsensitive to the randomness used for their training, creating a need to\ncharacterize this sensitivity. In this paper, we propose a characterization\nthat questions the possibility to provide simple and informative explanations\nfor such models. To this end, we give statistical definitions for the\nexplanations' signal, noise and signal-to-noise ratio. We highlight that, in a\ntypical case study where word-level univariate explanations are analyzed with\nfirst-order statistical tools, the explanations of simple feature-based models\ncarry more signal and less noise than those of transformer ones. We then\ndiscuss the possibility to improve these results with alternative definitions\nof signal and noise that would capture more complex explanations and analysis\nmethods, while also questioning the tradeoff with their plausibility for\nreaders.", "published": "2024-03-15 13:15:23", "link": "http://arxiv.org/abs/2403.10275v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Uni-SMART: Universal Science Multimodal Analysis and Research\n  Transformer", "abstract": "In scientific research and its application, scientific literature analysis is\ncrucial as it allows researchers to build on the work of others. However, the\nfast growth of scientific knowledge has led to a massive increase in scholarly\narticles, making in-depth literature analysis increasingly challenging and\ntime-consuming. The emergence of Large Language Models (LLMs) has offered a new\nway to address this challenge. Known for their strong abilities in summarizing\ntexts, LLMs are seen as a potential tool to improve the analysis of scientific\nliterature. However, existing LLMs have their own limits. Scientific literature\noften includes a wide range of multimodal elements, such as tables, charts, and\nmolecule, which are hard for text-focused LLMs to understand and analyze. This\nissue points to the urgent need for new solutions that can fully understand and\nanalyze multimodal content in scientific literature. To answer this demand, we\npresent \\textbf{Uni-SMART} (Universal Science Multimodal Analysis and Research\nTransformer), an innovative model designed for in-depth understanding of\nmultimodal scientific literature. Through rigorous quantitative evaluation\nacross several domains, Uni-SMART demonstrates superior performance over other\ntext-focused LLMs. Furthermore, our exploration extends to practical\napplications, including patent infringement detection and nuanced analysis of\ncharts. These applications not only highlight Uni-SMART's adaptability but also\nits potential to revolutionize how we interact with scientific literature.", "published": "2024-03-15 13:43:47", "link": "http://arxiv.org/abs/2403.10301v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "EXAMS-V: A Multi-Discipline Multilingual Multimodal Exam Benchmark for\n  Evaluating Vision Language Models", "abstract": "We introduce EXAMS-V, a new challenging multi-discipline multimodal\nmultilingual exam benchmark for evaluating vision language models. It consists\nof 20,932 multiple-choice questions across 20 school disciplines covering\nnatural science, social science, and other miscellaneous studies, e.g.,\nreligion, fine arts, business, etc. EXAMS-V includes a variety of multimodal\nfeatures such as text, images, tables, figures, diagrams, maps, scientific\nsymbols, and equations. The questions come in 11 languages from 7 language\nfamilies. Unlike existing benchmarks, EXAMS-V is uniquely curated by gathering\nschool exam questions from various countries, with a variety of education\nsystems. This distinctive approach calls for intricate reasoning across diverse\nlanguages and relies on region-specific knowledge. Solving the problems in the\ndataset requires advanced perception and joint reasoning over the text and the\nvisual content of the image. Our evaluation results demonstrate that this is a\nchallenging dataset, which is difficult even for advanced vision-text models\nsuch as GPT-4V and Gemini; this underscores the inherent complexity of the\ndataset and its significance as a future benchmark.", "published": "2024-03-15 15:08:39", "link": "http://arxiv.org/abs/2403.10378v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Enhancing LLM Factual Accuracy with RAG to Counter Hallucinations: A\n  Case Study on Domain-Specific Queries in Private Knowledge-Bases", "abstract": "We proposed an end-to-end system design towards utilizing Retrieval Augmented\nGeneration (RAG) to improve the factual accuracy of Large Language Models\n(LLMs) for domain-specific and time-sensitive queries related to private\nknowledge-bases. Our system integrates RAG pipeline with upstream datasets\nprocessing and downstream performance evaluation. Addressing the challenge of\nLLM hallucinations, we finetune models with a curated dataset which originates\nfrom CMU's extensive resources and annotated with the teacher model. Our\nexperiments demonstrate the system's effectiveness in generating more accurate\nanswers to domain-specific and time-sensitive inquiries. The results also\nrevealed the limitations of fine-tuning LLMs with small-scale and skewed\ndatasets. This research highlights the potential of RAG systems in augmenting\nLLMs with external datasets for improved performance in knowledge-intensive\ntasks. Our code and models are available on Github.", "published": "2024-03-15 16:30:14", "link": "http://arxiv.org/abs/2403.10446v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DiPaCo: Distributed Path Composition", "abstract": "Progress in machine learning (ML) has been fueled by scaling neural network\nmodels. This scaling has been enabled by ever more heroic feats of engineering,\nnecessary for accommodating ML approaches that require high bandwidth\ncommunication between devices working in parallel. In this work, we propose a\nco-designed modular architecture and training approach for ML models, dubbed\nDIstributed PAth COmposition (DiPaCo). During training, DiPaCo distributes\ncomputation by paths through a set of shared modules. Together with a Local-SGD\ninspired optimization (DiLoCo) that keeps modules in sync with drastically\nreduced communication, Our approach facilitates training across poorly\nconnected and heterogeneous workers, with a design that ensures robustness to\nworker failures and preemptions. At inference time, only a single path needs to\nbe executed for each input, without the need for any model compression. We\nconsider this approach as a first prototype towards a new paradigm of\nlarge-scale learning, one that is less synchronous and more modular. Our\nexperiments on the widely used C4 benchmark show that, for the same amount of\ntraining steps but less wall-clock time, DiPaCo exceeds the performance of a 1\nbillion-parameter dense transformer language model by choosing one of 256\npossible paths, each with a size of 150 million parameters.", "published": "2024-03-15 18:26:51", "link": "http://arxiv.org/abs/2403.10616v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "ChatPattern: Layout Pattern Customization via Natural Language", "abstract": "Existing works focus on fixed-size layout pattern generation, while the more\npractical free-size pattern generation receives limited attention. In this\npaper, we propose ChatPattern, a novel Large-Language-Model (LLM) powered\nframework for flexible pattern customization. ChatPattern utilizes a two-part\nsystem featuring an expert LLM agent and a highly controllable layout pattern\ngenerator. The LLM agent can interpret natural language requirements and\noperate design tools to meet specified needs, while the generator excels in\nconditional layout generation, pattern modification, and memory-friendly\npatterns extension. Experiments on challenging pattern generation setting shows\nthe ability of ChatPattern to synthesize high-quality large-scale patterns.", "published": "2024-03-15 09:15:22", "link": "http://arxiv.org/abs/2403.15434v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Take Care of Your Prompt Bias! Investigating and Mitigating Prompt Bias\n  in Factual Knowledge Extraction", "abstract": "Recent research shows that pre-trained language models (PLMs) suffer from\n\"prompt bias\" in factual knowledge extraction, i.e., prompts tend to introduce\nbiases toward specific labels. Prompt bias presents a significant challenge in\nassessing the factual knowledge within PLMs. Therefore, this paper aims to\nimprove the reliability of existing benchmarks by thoroughly investigating and\nmitigating prompt bias. We show that: 1) all prompts in the experiments exhibit\nnon-negligible bias, with gradient-based prompts like AutoPrompt and OptiPrompt\ndisplaying significantly higher levels of bias; 2) prompt bias can amplify\nbenchmark accuracy unreasonably by overfitting the test datasets, especially on\nimbalanced datasets like LAMA. Based on these findings, we propose a\nrepresentation-based approach to mitigate the prompt bias during inference\ntime. Specifically, we first estimate the biased representation using\nprompt-only querying, and then remove it from the model's internal\nrepresentations to generate the debiased representations, which are used to\nproduce the final debiased outputs. Experiments across various prompts, PLMs,\nand benchmarks show that our approach can not only correct the overfitted\nperformance caused by prompt bias, but also significantly improve the prompt\nretrieval capability (up to 10% absolute performance gain). These results\nindicate that our approach effectively alleviates prompt bias in knowledge\nevaluation, thereby enhancing the reliability of benchmark assessments.\nHopefully, our plug-and-play approach can be a golden standard to strengthen\nPLMs toward reliable knowledge bases. Code and data are released in\nhttps://github.com/FelliYang/PromptBias.", "published": "2024-03-15 02:04:35", "link": "http://arxiv.org/abs/2403.09963v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "GET: Unlocking the Multi-modal Potential of CLIP for Generalized\n  Category Discovery", "abstract": "Given unlabelled datasets containing both old and new categories, generalized\ncategory discovery (GCD) aims to accurately discover new classes while\ncorrectly classifying old classes. Current GCD methods only use a single visual\nmodality of information, resulting in a poor classification of visually similar\nclasses. As a different modality, text information can provide complementary\ndiscriminative information, which motivates us to introduce it into the GCD\ntask. However, the lack of class names for unlabelled data makes it impractical\nto utilize text information. To tackle this challenging problem, in this paper,\nwe propose a Text Embedding Synthesizer (TES) to generate pseudo text\nembeddings for unlabelled samples. Specifically, our TES leverages the property\nthat CLIP can generate aligned vision-language features, converting visual\nembeddings into tokens of the CLIP's text encoder to generate pseudo text\nembeddings. Besides, we employ a dual-branch framework, through the joint\nlearning and instance consistency of different modality branches, visual and\nsemantic information mutually enhance each other, promoting the interaction and\nfusion of visual and text knowledge. Our method unlocks the multi-modal\npotentials of CLIP and outperforms the baseline methods by a large margin on\nall GCD benchmarks, achieving new state-of-the-art. Our code is available at:\nhttps://github.com/enguangW/GET.", "published": "2024-03-15 02:40:13", "link": "http://arxiv.org/abs/2403.09974v3", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "The Whole is Better than the Sum: Using Aggregated Demonstrations in\n  In-Context Learning for Sequential Recommendation", "abstract": "Large language models (LLMs) have shown excellent performance on various NLP\ntasks. To use LLMs as strong sequential recommenders, we explore the in-context\nlearning approach to sequential recommendation. We investigate the effects of\ninstruction format, task consistency, demonstration selection, and number of\ndemonstrations. As increasing the number of demonstrations in ICL does not\nimprove accuracy despite using a long prompt, we propose a novel method called\nLLMSRec-Syn that incorporates multiple demonstration users into one aggregated\ndemonstration. Our experiments on three recommendation datasets show that\nLLMSRec-Syn outperforms state-of-the-art LLM-based sequential recommendation\nmethods. In some cases, LLMSRec-Syn can perform on par with or even better than\nsupervised learning methods. Our code is publicly available at\nhttps://github.com/demoleiwang/LLMSRec_Syn.", "published": "2024-03-15 09:28:19", "link": "http://arxiv.org/abs/2403.10135v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "HawkEye: Training Video-Text LLMs for Grounding Text in Videos", "abstract": "Video-text Large Language Models (video-text LLMs) have shown remarkable\nperformance in answering questions and holding conversations on simple videos.\nHowever, they perform almost the same as random on grounding text queries in\nlong and complicated videos, having little ability to understand and reason\nabout temporal information, which is the most fundamental difference between\nvideos and images. In this paper, we propose HawkEye, one of the first\nvideo-text LLMs that can perform temporal video grounding in a fully\ntext-to-text manner. To collect training data that is applicable for temporal\nvideo grounding, we construct InternVid-G, a large-scale video-text corpus with\nsegment-level captions and negative spans, with which we introduce two new\ntime-aware training objectives to video-text LLMs. We also propose a\ncoarse-grained method of representing segments in videos, which is more robust\nand easier for LLMs to learn and follow than other alternatives. Extensive\nexperiments show that HawkEye is better at temporal video grounding and\ncomparable on other video-text tasks with existing video-text LLMs, which\nverifies its superior video-text multi-modal understanding abilities.", "published": "2024-03-15 11:58:18", "link": "http://arxiv.org/abs/2403.10228v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "A Big Data Approach to Understand Sub-national Determinants of FDI in\n  Africa", "abstract": "Various macroeconomic and institutional factors hinder FDI inflows, including\ncorruption, trade openness, access to finance, and political instability.\nExisting research mostly focuses on country-level data, with limited\nexploration of firm-level data, especially in developing countries. Recognizing\nthis gap, recent calls for research emphasize the need for qualitative data\nanalysis to delve into FDI determinants, particularly at the regional level.\nThis paper proposes a novel methodology, based on text mining and social\nnetwork analysis, to get information from more than 167,000 online news\narticles to quantify regional-level (sub-national) attributes affecting FDI\nownership in African companies. Our analysis extends information on obstacles\nto industrial development as mapped by the World Bank Enterprise Surveys.\nFindings suggest that regional (sub-national) structural and institutional\ncharacteristics can play an important role in determining foreign ownership.", "published": "2024-03-15 12:12:54", "link": "http://arxiv.org/abs/2403.10239v1", "categories": ["cs.CL", "econ.EM", "physics.soc-ph", "I.2.7; J.4; H.4.0"], "primary_category": "cs.CL"}
{"title": "Team Trifecta at Factify5WQA: Setting the Standard in Fact Verification\n  with Fine-Tuning", "abstract": "In this paper, we present Pre-CoFactv3, a comprehensive framework comprised\nof Question Answering and Text Classification components for fact verification.\nLeveraging In-Context Learning, Fine-tuned Large Language Models (LLMs), and\nthe FakeNet model, we address the challenges of fact verification. Our\nexperiments explore diverse approaches, comparing different Pre-trained LLMs,\nintroducing FakeNet, and implementing various ensemble methods. Notably, our\nteam, Trifecta, secured first place in the AAAI-24 Factify 3.0 Workshop,\nsurpassing the baseline accuracy by 103% and maintaining a 70% lead over the\nsecond competitor. This success underscores the efficacy of our approach and\nits potential contributions to advancing fact verification research.", "published": "2024-03-15 13:24:28", "link": "http://arxiv.org/abs/2403.10281v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CDGP: Automatic Cloze Distractor Generation based on Pre-trained\n  Language Model", "abstract": "Manually designing cloze test consumes enormous time and efforts. The major\nchallenge lies in wrong option (distractor) selection. Having carefully-design\ndistractors improves the effectiveness of learner ability assessment. As a\nresult, the idea of automatically generating cloze distractor is motivated. In\nthis paper, we investigate cloze distractor generation by exploring the\nemployment of pre-trained language models (PLMs) as an alternative for\ncandidate distractor generation. Experiments show that the PLM-enhanced model\nbrings a substantial performance improvement. Our best performing model\nadvances the state-of-the-art result from 14.94 to 34.17 (NDCG@10 score). Our\ncode and dataset is available at https://github.com/AndyChiangSH/CDGP.", "published": "2024-03-15 14:14:26", "link": "http://arxiv.org/abs/2403.10326v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Benchmarking Zero-Shot Robustness of Multimodal Foundation Models: A\n  Pilot Study", "abstract": "Pre-training image representations from the raw text about images enables\nzero-shot vision transfer to downstream tasks. Through pre-training on millions\nof samples collected from the internet, multimodal foundation models, such as\nCLIP, produce state-of-the-art zero-shot results that often reach\ncompetitiveness with fully supervised methods without the need for\ntask-specific training. Besides the encouraging performance on classification\naccuracy, it is reported that these models close the robustness gap by matching\nthe performance of supervised models trained on ImageNet under natural\ndistribution shift. Because robustness is critical to real-world applications,\nespecially safety-critical ones, in this paper, we present a comprehensive\nevaluation based on a large-scale robustness benchmark covering 7 natural, 3\nsynthetic distribution shifts, and 11 adversarial attacks. We use CLIP as a\npilot study. We show that CLIP leads to a significant robustness drop compared\nto supervised ImageNet models on our benchmark, especially under synthetic\ndistribution shift and adversarial attacks. Furthermore, data overlap analysis\nsuggests that the observed robustness under natural distribution shifts could\nbe attributed, at least in part, to data overlap. In summary, our evaluation\nshows a comprehensive evaluation of robustness is necessary; and there is a\nsignificant need to improve the robustness of zero-shot multimodal models.", "published": "2024-03-15 17:33:49", "link": "http://arxiv.org/abs/2403.10499v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "VideoAgent: Long-form Video Understanding with Large Language Model as\n  Agent", "abstract": "Long-form video understanding represents a significant challenge within\ncomputer vision, demanding a model capable of reasoning over long multi-modal\nsequences. Motivated by the human cognitive process for long-form video\nunderstanding, we emphasize interactive reasoning and planning over the ability\nto process lengthy visual inputs. We introduce a novel agent-based system,\nVideoAgent, that employs a large language model as a central agent to\niteratively identify and compile crucial information to answer a question, with\nvision-language foundation models serving as tools to translate and retrieve\nvisual information. Evaluated on the challenging EgoSchema and NExT-QA\nbenchmarks, VideoAgent achieves 54.1% and 71.3% zero-shot accuracy with only\n8.4 and 8.2 frames used on average. These results demonstrate superior\neffectiveness and efficiency of our method over the current state-of-the-art\nmethods, highlighting the potential of agent-based approaches in advancing\nlong-form video understanding.", "published": "2024-03-15 17:57:52", "link": "http://arxiv.org/abs/2403.10517v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.CV"}
{"title": "Exploring Language Model's Code Generation Ability with Auxiliary\n  Functions", "abstract": "Auxiliary function is a helpful component to improve language model's code\ngeneration ability. However, a systematic exploration of how they affect has\nyet to be done. In this work, we comprehensively evaluate the ability to\nutilize auxiliary functions encoded in recent code-pretrained language models.\nFirst, we construct a human-crafted evaluation set, called HumanExtension,\nwhich contains examples of two functions where one function assists the other.\nWith HumanExtension, we design several experiments to examine their ability in\na multifaceted way. Our evaluation processes enable a comprehensive\nunderstanding of including auxiliary functions in the prompt in terms of\neffectiveness and robustness. An additional implementation style analysis\ncaptures the models' various implementation patterns when they access the\nauxiliary function. Through this analysis, we discover the models' promising\nability to utilize auxiliary functions including their self-improving behavior\nby implementing the two functions step-by-step. However, our analysis also\nreveals the model's underutilized behavior to call the auxiliary function,\nsuggesting the future direction to enhance their implementation by eliciting\nthe auxiliary function call ability encoded in the models. We release our code\nand dataset to facilitate this research direction.", "published": "2024-03-15 04:41:50", "link": "http://arxiv.org/abs/2403.10575v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Ignore Me But Don't Replace Me: Utilizing Non-Linguistic Elements for\n  Pretraining on the Cybersecurity Domain", "abstract": "Cybersecurity information is often technically complex and relayed through\nunstructured text, making automation of cyber threat intelligence highly\nchallenging. For such text domains that involve high levels of expertise,\npretraining on in-domain corpora has been a popular method for language models\nto obtain domain expertise. However, cybersecurity texts often contain\nnon-linguistic elements (such as URLs and hash values) that could be unsuitable\nwith the established pretraining methodologies. Previous work in other domains\nhave removed or filtered such text as noise, but the effectiveness of these\nmethods have not been investigated, especially in the cybersecurity domain. We\npropose different pretraining methodologies and evaluate their effectiveness\nthrough downstream tasks and probing tasks. Our proposed strategy (selective\nMLM and jointly training NLE token classification) outperforms the commonly\ntaken approach of replacing non-linguistic elements (NLEs). We use our\ndomain-customized methodology to train CyBERTuned, a cybersecurity domain\nlanguage model that outperforms other cybersecurity PLMs on most tasks.", "published": "2024-03-15 05:35:02", "link": "http://arxiv.org/abs/2403.10576v2", "categories": ["cs.CR", "cs.CL", "cs.LG", "I.2.7"], "primary_category": "cs.CR"}
{"title": "Neural Erosion: Emulating Controlled Neurodegeneration and Aging in AI\n  Systems", "abstract": "Creating controlled methods to simulate neurodegeneration in artificial\nintelligence (AI) is crucial for applications that emulate brain function\ndecline and cognitive disorders. We use IQ tests performed by Large Language\nModels (LLMs) and, more specifically, the LLaMA 2 to introduce the concept of\n``neural erosion.\" This deliberate erosion involves ablating synapses or\nneurons, or adding Gaussian noise during or after training, resulting in a\ncontrolled progressive decline in the LLMs' performance. We are able to\ndescribe the neurodegeneration in the IQ tests and show that the LLM first\nloses its mathematical abilities and then its linguistic abilities, while\nfurther losing its ability to understand the questions. To the best of our\nknowledge, this is the first work that models neurodegeneration with text data,\ncompared to other works that operate in the computer vision domain. Finally, we\ndraw similarities between our study and cognitive decline clinical studies\ninvolving test subjects. We find that with the application of neurodegenerative\nmethods, LLMs lose abstract thinking abilities, followed by mathematical\ndegradation, and ultimately, a loss in linguistic ability, responding to\nprompts incoherently. These findings are in accordance with human studies.", "published": "2024-03-15 18:00:00", "link": "http://arxiv.org/abs/2403.10596v1", "categories": ["cs.CL", "cs.AI", "q-bio.NC"], "primary_category": "cs.CL"}
{"title": "Towards Unified Multi-Modal Personalization: Large Vision-Language\n  Models for Generative Recommendation and Beyond", "abstract": "Developing a universal model that can effectively harness heterogeneous\nresources and respond to a wide range of personalized needs has been a\nlongstanding community aspiration. Our daily choices, especially in domains\nlike fashion and retail, are substantially shaped by multi-modal data, such as\npictures and textual descriptions. These modalities not only offer intuitive\nguidance but also cater to personalized user preferences. However, the\npredominant personalization approaches mainly focus on the ID or text-based\nrecommendation problem, failing to comprehend the information spanning various\ntasks or modalities. In this paper, our goal is to establish a Unified paradigm\nfor Multi-modal Personalization systems (UniMP), which effectively leverages\nmulti-modal data while eliminating the complexities associated with task- and\nmodality-specific customization. We argue that the advancements in foundational\ngenerative modeling have provided the flexibility and effectiveness necessary\nto achieve the objective. In light of this, we develop a generic and extensible\npersonalization generative framework, that can handle a wide range of\npersonalized needs including item recommendation, product search, preference\nprediction, explanation generation, and further user-guided image generation.\nOur methodology enhances the capabilities of foundational language models for\npersonalized tasks by seamlessly ingesting interleaved cross-modal user history\ninformation, ensuring a more precise and customized experience for users. To\ntrain and evaluate the proposed multi-modal personalized tasks, we also\nintroduce a novel and comprehensive benchmark covering a variety of user\nrequirements. Our experiments on the real-world benchmark showcase the model's\npotential, outperforming competitive methods specialized for each task.", "published": "2024-03-15 20:21:31", "link": "http://arxiv.org/abs/2403.10667v2", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.MM"], "primary_category": "cs.IR"}
{"title": "MYTE: Morphology-Driven Byte Encoding for Better and Fairer Multilingual\n  Language Modeling", "abstract": "A major consideration in multilingual language modeling is how to best\nrepresent languages with diverse vocabularies and scripts. Although\ncontemporary text encoding methods cover most of the world's writing systems,\nthey exhibit bias towards the high-resource languages of the Global West. As a\nresult, texts of underrepresented languages tend to be segmented into long\nsequences of linguistically meaningless units. To address the disparities, we\nintroduce a new paradigm that encodes the same information with segments of\nconsistent size across diverse languages. Our encoding convention (MYTE) is\nbased on morphemes, as their inventories are more balanced across languages\nthan characters, which are used in previous methods. We show that MYTE produces\nshorter encodings for all 99 analyzed languages, with the most notable\nimprovements for non-European languages and non-Latin scripts. This, in turn,\nimproves multilingual LM performance and diminishes the perplexity gap\nthroughout diverse languages.", "published": "2024-03-15 21:21:11", "link": "http://arxiv.org/abs/2403.10691v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "EXPLORER: Exploration-guided Reasoning for Textual Reinforcement\n  Learning", "abstract": "Text-based games (TBGs) have emerged as an important collection of NLP tasks,\nrequiring reinforcement learning (RL) agents to combine natural language\nunderstanding with reasoning. A key challenge for agents attempting to solve\nsuch tasks is to generalize across multiple games and demonstrate good\nperformance on both seen and unseen objects. Purely deep-RL-based approaches\nmay perform well on seen objects; however, they fail to showcase the same\nperformance on unseen objects. Commonsense-infused deep-RL agents may work\nbetter on unseen data; unfortunately, their policies are often not\ninterpretable or easily transferable. To tackle these issues, in this paper, we\npresent EXPLORER which is an exploration-guided reasoning agent for textual\nreinforcement learning. EXPLORER is neurosymbolic in nature, as it relies on a\nneural module for exploration and a symbolic module for exploitation. It can\nalso learn generalized symbolic policies and perform well over unseen data. Our\nexperiments show that EXPLORER outperforms the baseline agents on Text-World\ncooking (TW-Cooking) and Text-World Commonsense (TWC) games.", "published": "2024-03-15 21:22:37", "link": "http://arxiv.org/abs/2403.10692v1", "categories": ["cs.CL", "cs.AI", "cs.LO"], "primary_category": "cs.CL"}
{"title": "Mind the Error! Detection and Localization of Instruction Errors in\n  Vision-and-Language Navigation", "abstract": "Vision-and-Language Navigation in Continuous Environments (VLN-CE) is one of\nthe most intuitive yet challenging embodied AI tasks. Agents are tasked to\nnavigate towards a target goal by executing a set of low-level actions,\nfollowing a series of natural language instructions. All VLN-CE methods in the\nliterature assume that language instructions are exact. However, in practice,\ninstructions given by humans can contain errors when describing a spatial\nenvironment due to inaccurate memory or confusion. Current VLN-CE benchmarks do\nnot address this scenario, making the state-of-the-art methods in VLN-CE\nfragile in the presence of erroneous instructions from human users. For the\nfirst time, we propose a novel benchmark dataset that introduces various types\nof instruction errors considering potential human causes. This benchmark\nprovides valuable insight into the robustness of VLN systems in continuous\nenvironments. We observe a noticeable performance drop (up to -25%) in Success\nRate when evaluating the state-of-the-art VLN-CE methods on our benchmark.\nMoreover, we formally define the task of Instruction Error Detection and\nLocalization, and establish an evaluation protocol on top of our benchmark\ndataset. We also propose an effective method, based on a cross-modal\ntransformer architecture, that achieves the best performance in error detection\nand localization, compared to baselines. Surprisingly, our proposed method has\nrevealed errors in the validation set of the two commonly used datasets for\nVLN-CE, i.e., R2R-CE and RxR-CE, demonstrating the utility of our technique in\nother tasks. Code and dataset available at\nhttps://intelligolabs.github.io/R2RIE-CE", "published": "2024-03-15 21:36:15", "link": "http://arxiv.org/abs/2403.10700v2", "categories": ["cs.RO", "cs.AI", "cs.CL"], "primary_category": "cs.RO"}
{"title": "Parameter Efficient Reinforcement Learning from Human Feedback", "abstract": "While Reinforcement Learning from Human Feedback (RLHF) effectively aligns\npretrained Large Language and Vision-Language Models (LLMs, and VLMs) with\nhuman preferences, its computational cost and complexity hamper its wider\nadoption. To alleviate some of the computational burden of fine-tuning,\nparameter efficient methods, like LoRA were introduced. In this work, we\nempirically evaluate the setup of Parameter Efficient Reinforcement Learning\nfrom Human Feedback (PE-RLHF) that leverages LoRA fine-tuning for Reward\nModeling, and Reinforcement Learning. We benchmark the PE-RLHF setup on six\ndiverse datasets spanning summarization, harmless/helpful response generation,\nUI automation, and visual question answering in terms of effectiveness of the\ntrained models, and the training resources required. Our findings show, for the\nfirst time, that PE-RLHF achieves comparable performance to RLHF, while\nsignificantly reducing training time (up to 90% faster for reward models, and\n30% faster for RL), and memory footprint (up to 50% reduction for reward\nmodels, and 27% for RL). We provide comprehensive ablations across LoRA ranks,\nand model sizes for both reward modeling and reinforcement learning. By\nmitigating the computational burden associated with RLHF, we push for a broader\nadoption of PE-RLHF as an alignment technique for LLMs and VLMs.", "published": "2024-03-15 21:43:46", "link": "http://arxiv.org/abs/2403.10704v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Are LLMs Good Cryptic Crossword Solvers?", "abstract": "Cryptic crosswords are puzzles that rely not only on general knowledge but\nalso on the solver's ability to manipulate language on different levels and\ndeal with various types of wordplay. Previous research suggests that solving\nsuch puzzles is a challenge even for modern NLP models. However, the abilities\nof large language models (LLMs) have not yet been tested on this task. In this\npaper, we establish the benchmark results for three popular LLMs -- LLaMA2,\nMistral, and ChatGPT -- showing that their performance on this task is still\nfar from that of humans.", "published": "2024-03-15 06:57:08", "link": "http://arxiv.org/abs/2403.12094v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Whose Side Are You On? Investigating the Political Stance of Large\n  Language Models", "abstract": "Large Language Models (LLMs) have gained significant popularity for their\napplication in various everyday tasks such as text generation, summarization,\nand information retrieval. As the widespread adoption of LLMs continues to\nsurge, it becomes increasingly crucial to ensure that these models yield\nresponses that are politically impartial, with the aim of preventing\ninformation bubbles, upholding fairness in representation, and mitigating\nconfirmation bias. In this paper, we propose a quantitative framework and\npipeline designed to systematically investigate the political orientation of\nLLMs. Our investigation delves into the political alignment of LLMs across a\nspectrum of eight polarizing topics, spanning from abortion to LGBTQ issues.\nAcross topics, the results indicate that LLMs exhibit a tendency to provide\nresponses that closely align with liberal or left-leaning perspectives rather\nthan conservative or right-leaning ones when user queries include details\npertaining to occupation, race, or political affiliation. The findings\npresented in this study not only reaffirm earlier observations regarding the\nleft-leaning characteristics of LLMs but also surface particular attributes,\nsuch as occupation, that are particularly susceptible to such inclinations even\nwhen directly steered towards conservatism. As a recommendation to avoid these\nmodels providing politicised responses, users should be mindful when crafting\nqueries, and exercise caution in selecting neutral prompt language.", "published": "2024-03-15 04:02:24", "link": "http://arxiv.org/abs/2403.13840v1", "categories": ["cs.CL", "cs.AI", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Application of GPT Language Models for Innovation in Activities in\n  University Teaching", "abstract": "The GPT (Generative Pre-trained Transformer) language models are an\nartificial intelligence and natural language processing technology that enables\nautomatic text generation. There is a growing interest in applying GPT language\nmodels to university teaching in various dimensions. From the perspective of\ninnovation in student and teacher activities, they can provide support in\nunderstanding and generating content, problem-solving, as well as\npersonalization and test correction, among others. From the dimension of\ninternationalization, the misuse of these models represents a global problem\nthat requires taking a series of common measures in universities from different\ngeographical areas. In several countries, there has been a review of assessment\ntools to ensure that work is done by students and not by AI. To this end, we\nhave conducted a detailed experiment in a representative subject of Computer\nScience such as Software Engineering, which has focused on evaluating the use\nof ChatGPT as an assistant in theory activities, exercises, and laboratory\npractices, assessing its potential use as a support tool for both students and\nteachers.", "published": "2024-03-15 14:31:52", "link": "http://arxiv.org/abs/2403.14694v1", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "NLP Verification: Towards a General Methodology for Certifying\n  Robustness", "abstract": "Machine Learning (ML) has exhibited substantial success in the field of\nNatural Language Processing (NLP). For example large language models have\nempirically proven to be capable of producing text of high complexity and\ncohesion. However, they are prone to inaccuracies and hallucinations. As these\nsystems are increasingly integrated into real-world applications, ensuring\ntheir safety and reliability becomes a primary concern. There are safety\ncritical contexts where such models must be robust to variability or attack,\nand give guarantees over their output. Computer Vision had pioneered the use of\nformal verification of neural networks for such scenarios and developed common\nverification standards and pipelines, leveraging precise formal reasoning about\ngeometric properties of data manifolds. In contrast, NLP verification methods\nhave only recently appeared in the literature. While presenting sophisticated\nalgorithms, these papers have not yet crystallised into a common methodology.\nThey are often light on the pragmatical issues of NLP verification and the area\nremains fragmented. In this paper, we attempt to distil and evaluate general\ncomponents of an NLP verification pipeline, that emerges from the progress in\nthe field to date. Our contributions are two-fold. Firstly, we propose a\ngeneral methodology to analyse the effect of the embedding gap, a problem that\nrefers to the discrepancy between verification of geometric subspaces and the\nsemantic meaning of sentences, which the geometric subspaces are supposed to\nrepresent. We propose a number of practical NLP methods that can help to\nquantify the effects of the embedding gap. Secondly, we give a general method\nfor training and verification of neural networks that leverages a more precise\ngeometric estimation of semantic similarity of sentences in the embedding space\nand helps to overcome the effects of the embedding gap in practice.", "published": "2024-03-15 09:43:52", "link": "http://arxiv.org/abs/2403.10144v3", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.LO", "cs.PL"], "primary_category": "cs.CL"}
{"title": "Block Verification Accelerates Speculative Decoding", "abstract": "Speculative decoding is an effective method for lossless acceleration of\nlarge language models during inference. It uses a fast model to draft a block\nof tokens which are then verified in parallel by the target model, and provides\na guarantee that the output is distributed identically to a sample from the\ntarget model. In prior works, draft verification is performed independently\ntoken-by-token. Surprisingly, we show that this approach is not optimal. We\npropose Block Verification, a simple draft verification algorithm that verifies\nthe entire block jointly and provides additional wall-clock speedup. We prove\nthat the proposed mechanism is optimal in the expected number of tokens\nproduced each iteration and specifically is never worse than the standard\ntoken-level verification. Empirically, block verification provides modest but\nconsistent wall-clock speedups over the standard token verification algorithm\nof 5%-8% in a range of tasks and datasets. Given that block verification does\nnot increase code complexity, maintains the strong lossless guarantee of the\nstandard speculative decoding verification algorithm, cannot deteriorate\nperformance, and, in fact, consistently improves it, it can be used as a good\ndefault in speculative decoding implementations.", "published": "2024-03-15 16:28:22", "link": "http://arxiv.org/abs/2403.10444v2", "categories": ["cs.LG", "cs.CL", "cs.DS", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "Large Language Model-informed ECG Dual Attention Network for Heart\n  Failure Risk Prediction", "abstract": "Heart failure (HF) poses a significant public health challenge, with a rising\nglobal mortality rate. Early detection and prevention of HF could significantly\nreduce its impact. We introduce a novel methodology for predicting HF risk\nusing 12-lead electrocardiograms (ECGs). We present a novel, lightweight\ndual-attention ECG network designed to capture complex ECG features essential\nfor early HF risk prediction, despite the notable imbalance between low and\nhigh-risk groups. This network incorporates a cross-lead attention module and\ntwelve lead-specific temporal attention modules, focusing on cross-lead\ninteractions and each lead's local dynamics. To further alleviate model\noverfitting, we leverage a large language model (LLM) with a public ECG-Report\ndataset for pretraining on an ECG-report alignment task. The network is then\nfine-tuned for HF risk prediction using two specific cohorts from the UK\nBiobank study, focusing on patients with hypertension (UKB-HYP) and those who\nhave had a myocardial infarction (UKB-MI).The results reveal that LLM-informed\npre-training substantially enhances HF risk prediction in these cohorts. The\ndual-attention design not only improves interpretability but also predictive\naccuracy, outperforming existing competitive methods with C-index scores of\n0.6349 for UKB-HYP and 0.5805 for UKB-MI. This demonstrates our method's\npotential in advancing HF risk assessment with clinical complex ECG data.", "published": "2024-03-15 13:25:09", "link": "http://arxiv.org/abs/2403.10581v2", "categories": ["q-bio.QM", "cs.AI", "cs.CL", "cs.LG", "eess.SP"], "primary_category": "q-bio.QM"}
{"title": "Discovering Latent Themes in Social Media Messaging: A\n  Machine-in-the-Loop Approach Integrating LLMs", "abstract": "Grasping the themes of social media content is key to understanding the\nnarratives that influence public opinion and behavior. The thematic analysis\ngoes beyond traditional topic-level analysis, which often captures only the\nbroadest patterns, providing deeper insights into specific and actionable\nthemes such as \"public sentiment towards vaccination\", \"political discourse\nsurrounding climate policies,\" etc. In this paper, we introduce a novel\napproach to uncovering latent themes in social media messaging. Recognizing the\nlimitations of the traditional topic-level analysis, which tends to capture\nonly overarching patterns, this study emphasizes the need for a finer-grained,\ntheme-focused exploration. Traditional theme discovery methods typically\ninvolve manual processes and a human-in-the-loop approach. While valuable,\nthese methods face challenges in scalability, consistency, and resource\nintensity in terms of time and cost. To address these challenges, we propose a\nmachine-in-the-loop approach that leverages the advanced capabilities of Large\nLanguage Models (LLMs). To demonstrate our approach, we apply our framework to\ncontentious topics, such as climate debate and vaccine debate. We use two\npublicly available datasets: (1) the climate campaigns dataset of 21k Facebook\nads and (2) the COVID-19 vaccine campaigns dataset of 9k Facebook ads. Our\nquantitative and qualitative analysis shows that our methodology yields more\naccurate and interpretable results compared to the baselines. Our results not\nonly demonstrate the effectiveness of our approach in uncovering latent themes\nbut also illuminate how these themes are tailored for demographic targeting in\nsocial media contexts. Additionally, our work sheds light on the dynamic nature\nof social media, revealing the shifts in the thematic focus of messaging in\nresponse to real-world events.", "published": "2024-03-15 21:54:00", "link": "http://arxiv.org/abs/2403.10707v2", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Hearing-Loss Compensation Using Deep Neural Networks: A Framework and\n  Results From a Listening Test", "abstract": "This article investigates the use of deep neural networks (DNNs) for\nhearing-loss compensation. Hearing loss is a prevalent issue affecting millions\nof people worldwide, and conventional hearing aids have limitations in\nproviding satisfactory compensation. DNNs have shown remarkable performance in\nvarious auditory tasks, including speech recognition, speaker identification,\nand music classification. In this study, we propose a DNN-based approach for\nhearing-loss compensation, which is trained on the outputs of hearing-impaired\nand normal-hearing DNN-based auditory models in response to speech signals.\nFirst, we introduce a framework for emulating auditory models using DNNs,\nfocusing on an auditory-nerve model in the auditory pathway. We propose a\nlinearization of the DNN-based approach, which we use to analyze the DNN-based\nhearing-loss compensation. Additionally we develop a simple approach to choose\nthe acoustic center frequencies of the auditory model used for the compensation\nstrategy. Finally, we evaluate, to our knowledge for the first time, the\nDNN-based hearing-loss compensation strategies using listening tests with\nhearing impaired listeners. The results demonstrate that the proposed approach\nresults in feasible hearing-loss compensation strategies. Our proposed approach\nwas shown to provide an increase in speech intelligibility versus an\nunprocessed baseline and was found to outperform a conventional approach in\nterms of both intelligibility and preference.", "published": "2024-03-15 15:55:19", "link": "http://arxiv.org/abs/2403.10420v3", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "How to train your ears: Auditory-model emulation for large-dynamic-range\n  inputs and mild-to-severe hearing losses", "abstract": "Advanced auditory models are useful in designing signal-processing algorithms\nfor hearing-loss compensation or speech enhancement. Such auditory models\nprovide rich and detailed descriptions of the auditory pathway, and might allow\nfor individualization of signal-processing strategies, based on physiological\nmeasurements. However, these auditory models are often computationally\ndemanding, requiring significant time to compute. To address this issue,\nprevious studies have explored the use of deep neural networks to emulate\nauditory models and reduce inference time. While these deep neural networks\noffer impressive efficiency gains in terms of computational time, they may\nsuffer from uneven emulation performance as a function of auditory-model\nfrequency-channels and input sound pressure level, making them unsuitable for\nmany tasks. In this study, we demonstrate that the conventional\nmachine-learning optimization objective used in existing state-of-the-art\nmethods is the primary source of this limitation. Specifically, the\noptimization objective fails to account for the frequency- and\nlevel-dependencies of the auditory model, caused by a large input dynamic range\nand different types of hearing losses emulated by the auditory model. To\novercome this limitation, we propose a new optimization objective that\nexplicitly embeds the frequency- and level-dependencies of the auditory model.\nOur results show that this new optimization objective significantly improves\nthe emulation performance of deep neural networks across relevant input sound\nlevels and auditory-model frequency channels, without increasing the\ncomputational load during inference. Addressing these limitations is essential\nfor advancing the application of auditory models in signal-processing tasks,\nensuring their efficacy in diverse scenarios.", "published": "2024-03-15 16:00:27", "link": "http://arxiv.org/abs/2403.10428v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "SuperM2M: Supervised and Mixture-to-Mixture Co-Learning for Speech\n  Enhancement and Noise-Robust ASR", "abstract": "The current dominant approach for neural speech enhancement is based on\nsupervised learning by using simulated training data. The trained models,\nhowever, often exhibit limited generalizability to real-recorded data. To\naddress this, this paper investigates training enhancement models directly on\nreal target-domain data. We propose to adapt mixture-to-mixture (M2M) training,\noriginally designed for speaker separation, for speech enhancement, by modeling\nmulti-source noise signals as a single, combined source. In addition, we\npropose a co-learning algorithm that improves M2M with the help of supervised\nalgorithms. When paired close-talk and far-field mixtures are available for\ntraining, M2M realizes speech enhancement by training a deep neural network\n(DNN) to produce speech and noise estimates in a way such that they can be\nlinearly filtered to reconstruct the close-talk and far-field mixtures. This\nway, the DNN can be trained directly on real mixtures, and can leverage\nclose-talk and far-field mixtures as a weak supervision to enhance far-field\nmixtures. To improve M2M, we combine it with supervised approaches to co-train\nthe DNN, where mini-batches of real close-talk and far-field mixture pairs and\nmini-batches of simulated mixture and clean speech pairs are alternately fed to\nthe DNN, and the loss functions are respectively (a) the mixture reconstruction\nloss on the real close-talk and far-field mixtures and (b) the regular\nenhancement loss on the simulated clean speech and noise. We find that, this\nway, the DNN can learn from real and simulated data to achieve better\ngeneralization to real data. We name this algorithm SuperM2M (supervised and\nmixture-to-mixture co-learning). Evaluation results on the CHiME-4 dataset show\nits effectiveness and potential.", "published": "2024-03-15 13:03:24", "link": "http://arxiv.org/abs/2403.10271v3", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Multiscale Matching Driven by Cross-Modal Similarity Consistency for\n  Audio-Text Retrieval", "abstract": "Audio-text retrieval (ATR), which retrieves a relevant caption given an audio\nclip (A2T) and vice versa (T2A), has recently attracted much research\nattention. Existing methods typically aggregate information from each modality\ninto a single vector for matching, but this sacrifices local details and can\nhardly capture intricate relationships within and between modalities.\nFurthermore, current ATR datasets lack comprehensive alignment information, and\nsimple binary contrastive learning labels overlook the measurement of\nfine-grained semantic differences between samples. To counter these challenges,\nwe present a novel ATR framework that comprehensively captures the matching\nrelationships of multimodal information from different perspectives and finer\ngranularities. Specifically, a fine-grained alignment method is introduced,\nachieving a more detail-oriented matching through a multiscale process from\nlocal to global levels to capture meticulous cross-modal relationships. In\naddition, we pioneer the application of cross-modal similarity consistency,\nleveraging intra-modal similarity relationships as soft supervision to boost\nmore intricate alignment. Extensive experiments validate the effectiveness of\nour approach, outperforming previous methods by significant margins of at least\n3.9% (T2A) / 6.9% (A2T) R@1 on the AudioCaps dataset and 2.9% (T2A) / 5.4%\n(A2T) R@1 on the Clotho dataset.", "published": "2024-03-15 09:47:17", "link": "http://arxiv.org/abs/2403.10146v1", "categories": ["cs.SD", "cs.IR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multi-Source Localization and Data Association for Time-Difference of\n  Arrival Measurements", "abstract": "In this work, we consider the problem of localizing multiple signal sources\nbased on time-difference of arrival (TDOA) measurements. In the blind setting,\nin which the source signals are not known, the localization task is challenging\ndue to the data association problem. That is, it is not known which of the TDOA\nmeasurements correspond to the same source. Herein, we propose to perform joint\nlocalization and data association by means of an optimal transport formulation.\nThe method operates by finding optimal groupings of TDOA measurements and\nassociating these with candidate source locations. To allow for computationally\nfeasible localization in three-dimensional space, an efficient set of candidate\nlocations is constructed using a minimal multilateration solver based on\nminimal sets of receiver pairs. In numerical simulations, we demonstrate that\nthe proposed method is robust both to measurement noise and TDOA detection\nerrors. Furthermore, it is shown that the data association provided by the\nproposed method allows for statistically efficient estimates of the source\nlocations.", "published": "2024-03-15 14:16:46", "link": "http://arxiv.org/abs/2403.10329v1", "categories": ["eess.SP", "cs.SD", "eess.AS", "math.OC"], "primary_category": "eess.SP"}
{"title": "BirdSet: A Large-Scale Dataset for Audio Classification in Avian\n  Bioacoustics", "abstract": "Deep learning (DL) has greatly advanced audio classification, yet the field\nis limited by the scarcity of large-scale benchmark datasets that have\npropelled progress in other domains. While AudioSet is a pivotal step to bridge\nthis gap as a universal-domain dataset, its restricted accessibility and\nlimited range of evaluation use cases challenge its role as the sole resource.\nTherefore, we introduce \\texttt{BirdSet}, a large-scale benchmark dataset for\naudio classification focusing on avian bioacoustics. \\texttt{BirdSet} surpasses\nAudioSet with over 6,800 recording hours~($\\uparrow\\!17\\%$) from nearly 10,000\nclasses~($\\uparrow\\!18\\times$) for training and more than 400\nhours~($\\uparrow\\!7\\times$) across eight strongly labeled evaluation datasets.\nIt serves as a versatile resource for use cases such as multi-label\nclassification, covariate shift or self-supervised learning. We benchmark six\nwell-known DL models in multi-label classification across three distinct\ntraining scenarios and outline further evaluation use cases in audio\nclassification. We host our dataset on Hugging Face for easy accessibility and\noffer an extensive codebase to reproduce our results.", "published": "2024-03-15 15:10:40", "link": "http://arxiv.org/abs/2403.10380v5", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Joint Multimodal Transformer for Emotion Recognition in the Wild", "abstract": "Multimodal emotion recognition (MMER) systems typically outperform unimodal\nsystems by leveraging the inter- and intra-modal relationships between, e.g.,\nvisual, textual, physiological, and auditory modalities. This paper proposes an\nMMER method that relies on a joint multimodal transformer (JMT) for fusion with\nkey-based cross-attention. This framework can exploit the complementary nature\nof diverse modalities to improve predictive accuracy. Separate backbones\ncapture intra-modal spatiotemporal dependencies within each modality over video\nsequences. Subsequently, our JMT fusion architecture integrates the individual\nmodality embeddings, allowing the model to effectively capture inter- and\nintra-modal relationships. Extensive experiments on two challenging expression\nrecognition tasks -- (1) dimensional emotion recognition on the Affwild2\ndataset (with face and voice) and (2) pain estimation on the Biovid dataset\n(with face and biosensors) -- indicate that our JMT fusion can provide a\ncost-effective solution for MMER. Empirical results show that MMER systems with\nour proposed fusion allow us to outperform relevant baseline and\nstate-of-the-art methods.", "published": "2024-03-15 17:23:38", "link": "http://arxiv.org/abs/2403.10488v3", "categories": ["cs.CV", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "MusicHiFi: Fast High-Fidelity Stereo Vocoding", "abstract": "Diffusion-based audio and music generation models commonly perform generation\nby constructing an image representation of audio (e.g., a mel-spectrogram) and\nthen convert it to audio using a phase reconstruction model or vocoder. Typical\nvocoders, however, produce monophonic audio at lower resolutions (e.g., 16-24\nkHz), which limits their usefulness. We propose MusicHiFi -- an efficient\nhigh-fidelity stereophonic vocoder. Our method employs a cascade of three\ngenerative adversarial networks (GANs) that convert low-resolution\nmel-spectrograms to audio, upsamples to high-resolution audio via bandwidth\nextension, and upmixes to stereophonic audio. Compared to past work, we propose\n1) a unified GAN-based generator and discriminator architecture and training\nprocedure for each stage of our cascade, 2) a new fast, near\ndownsampling-compatible bandwidth extension module, and 3) a new fast\ndownmix-compatible mono-to-stereo upmixer that ensures the preservation of\nmonophonic content in the output. We evaluate our approach using objective and\nsubjective listening tests and find our approach yields comparable or better\naudio quality, better spatialization control, and significantly faster\ninference speed compared to past work. Sound examples are at\n\\url{https://MusicHiFi.github.io/web/}.", "published": "2024-03-15 17:27:42", "link": "http://arxiv.org/abs/2403.10493v4", "categories": ["cs.SD", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
{"title": "Lodge: A Coarse to Fine Diffusion Network for Long Dance Generation\n  Guided by the Characteristic Dance Primitives", "abstract": "We propose Lodge, a network capable of generating extremely long dance\nsequences conditioned on given music. We design Lodge as a two-stage coarse to\nfine diffusion architecture, and propose the characteristic dance primitives\nthat possess significant expressiveness as intermediate representations between\ntwo diffusion models. The first stage is global diffusion, which focuses on\ncomprehending the coarse-level music-dance correlation and production\ncharacteristic dance primitives. In contrast, the second-stage is the local\ndiffusion, which parallelly generates detailed motion sequences under the\nguidance of the dance primitives and choreographic rules. In addition, we\npropose a Foot Refine Block to optimize the contact between the feet and the\nground, enhancing the physical realism of the motion. Our approach can\nparallelly generate dance sequences of extremely long length, striking a\nbalance between global choreographic patterns and local motion quality and\nexpressiveness. Extensive experiments validate the efficacy of our method.", "published": "2024-03-15 17:59:33", "link": "http://arxiv.org/abs/2403.10518v3", "categories": ["cs.CV", "cs.GR", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "MR-MT3: Memory Retaining Multi-Track Music Transcription to Mitigate\n  Instrument Leakage", "abstract": "This paper presents enhancements to the MT3 model, a state-of-the-art (SOTA)\ntoken-based multi-instrument automatic music transcription (AMT) model. Despite\nSOTA performance, MT3 has the issue of instrument leakage, where transcriptions\nare fragmented across different instruments. To mitigate this, we propose\nMR-MT3, with enhancements including a memory retention mechanism, prior token\nsampling, and token shuffling are proposed. These methods are evaluated on the\nSlakh2100 dataset, demonstrating improved onset F1 scores and reduced\ninstrument leakage. In addition to the conventional multi-instrument\ntranscription F1 score, new metrics such as the instrument leakage ratio and\nthe instrument detection F1 score are introduced for a more comprehensive\nassessment of transcription quality. The study also explores the issue of\ndomain overfitting by evaluating MT3 on single-instrument monophonic datasets\nsuch as ComMU and NSynth. The findings, along with the source code, are shared\nto facilitate future work aimed at refining token-based multi-instrument AMT\nmodels.", "published": "2024-03-15 05:13:38", "link": "http://arxiv.org/abs/2403.10024v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
