{"title": "Lyrics-to-Audio Alignment by Unsupervised Discovery of Repetitive\n  Patterns in Vowel Acoustics", "abstract": "Most of the previous approaches to lyrics-to-audio alignment used a\npre-developed automatic speech recognition (ASR) system that innately suffered\nfrom several difficulties to adapt the speech model to individual singers. A\nsignificant aspect missing in previous works is the self-learnability of\nrepetitive vowel patterns in the singing voice, where the vowel part used is\nmore consistent than the consonant part. Based on this, our system first learns\na discriminative subspace of vowel sequences, based on weighted symmetric\nnon-negative matrix factorization (WS-NMF), by taking the self-similarity of a\nstandard acoustic feature as an input. Then, we make use of canonical time\nwarping (CTW), derived from a recent computer vision technique, to find an\noptimal spatiotemporal transformation between the text and the acoustic\nsequences. Experiments with Korean and English data sets showed that deploying\nthis method after a pre-developed, unsupervised, singing source separation\nachieved more promising results than other state-of-the-art unsupervised\napproaches and an existing ASR-based system.", "published": "2017-01-21 20:15:08", "link": "http://arxiv.org/abs/1701.06078v2", "categories": ["cs.SD", "cs.AI", "cs.IR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
