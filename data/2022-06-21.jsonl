{"title": "KnowDA: All-in-One Knowledge Mixture Model for Data Augmentation in\n  Low-Resource NLP", "abstract": "This paper focuses on the data augmentation for low-resource NLP tasks where\nthe training set is limited. The existing solutions either leverage\ntask-independent heuristic rules (e.g., Synonym Replacement) or fine-tune\ngeneral-purpose pre-trained language models (e.g., GPT2) using the limited\ntraining instances to produce new synthetic data. Consequently, they have\ntrivial task-specific knowledge and are limited to yielding low-quality\nsynthetic data. To combat this issue, we propose Knowledge Mixture Data\nAugmentation Model (KnowDA) which is an Seq2Seq language model pre-trained on a\nmixture of diverse NLP tasks under a novel framework of Knowledge Mixture\nTraining (KoMT). The goal of KoMT is to condense diverse NLP task-specific\nknowledge into the single KnowDA model (i.e., all-in-one) such that KnowDA\ncould utilize these knowledge to quickly grasp the inherent synthesis law of\nthe target task through limited training instances. Specifically, KoMT\nreformulates input examples from various heterogeneous NLP tasks into a unified\ntext-to-text format, and employs denoising training objectives in different\ngranularity to learn to reconstruct partial or complete samples. To the best of\nour knowledge, we are the first attempt to apply 100+ NLP multi-task training\nfor data augmentation. Extensive experiments show that i) the synthetic data\nproduced by KnowDA successfully improves performance of the strong pre-trained\nlanguage models (i.e., Bert, ALBert and Deberta) by a large margin on the\nlow-resource NLP benchmark FewGLUE, CoNLL'03 and WikiAnn; ii) KnowDA\nsuccessfully transfers the task knowledge to NLP tasks whose types are seen and\nunseen in KoMT.", "published": "2022-06-21 11:34:02", "link": "http://arxiv.org/abs/2206.10265v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Building an Endangered Language Resource in the Classroom: Universal\n  Dependencies for Kakataibo", "abstract": "In this paper, we launch a new Universal Dependencies treebank for an\nendangered language from Amazonia: Kakataibo, a Panoan language spoken in Peru.\nWe first discuss the collaborative methodology implemented, which proved\neffective to create a treebank in the context of a Computational Linguistic\ncourse for undergraduates. Then, we describe the general details of the\ntreebank and the language-specific considerations implemented for the proposed\nannotation. We finally conduct some experiments on part-of-speech tagging and\nsyntactic dependency parsing. We focus on monolingual and transfer learning\nsettings, where we study the impact of a Shipibo-Konibo treebank, another\nPanoan language resource.", "published": "2022-06-21 12:58:56", "link": "http://arxiv.org/abs/2206.10343v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Low Resource Pipeline for Spoken Language Understanding via Weak\n  Supervision", "abstract": "In Weak Supervised Learning (WSL), a model is trained over noisy labels\nobtained from semantic rules and task-specific pre-trained models. Rules offer\nlimited generalization over tasks and require significant manual efforts while\npre-trained models are available only for limited tasks. In this work, we\npropose to utilize prompt-based methods as weak sources to obtain the noisy\nlabels on unannotated data. We show that task-agnostic prompts are\ngeneralizable and can be used to obtain noisy labels for different Spoken\nLanguage Understanding (SLU) tasks such as sentiment classification, disfluency\ndetection and emotion classification. These prompts could additionally be\nupdated to add task-specific contexts, thus providing flexibility to design\ntask-specific prompts. We demonstrate that prompt-based methods generate\nreliable labels for the above SLU tasks and thus can be used as a universal\nweak source to train a weak-supervised model (WSM) in absence of labeled data.\nOur proposed WSL pipeline trained over prompt-based weak source outperforms\nother competitive low-resource benchmarks on zero and few-shot learning by more\nthan 4% on Macro-F1 on all of the three benchmark SLU datasets. The proposed\nmethod also outperforms a conventional rule based WSL pipeline by more than 5%\non Macro-F1.", "published": "2022-06-21 17:36:31", "link": "http://arxiv.org/abs/2206.10559v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BenchCLAMP: A Benchmark for Evaluating Language Models on Syntactic and\n  Semantic Parsing", "abstract": "Recent work has shown that generation from a prompted or fine-tuned language\nmodel can perform well at semantic parsing when the output is constrained to be\na valid semantic representation. We introduce BenchCLAMP, a Benchmark to\nevaluate Constrained LAnguage Model Parsing, that includes context-free\ngrammars for seven semantic parsing datasets and two syntactic parsing datasets\nwith varied output representations, as well as a constrained decoding interface\nto generate only valid outputs covered by these grammars. We provide low,\nmedium, and high resource splits for each dataset, allowing accurate comparison\nof various language models under different data regimes. Our benchmark supports\nevaluation of language models using prompt-based learning as well as\nfine-tuning. We benchmark eight language models, including two GPT-3 variants\navailable only through an API. Our experiments show that encoder-decoder\npretrained language models can achieve similar performance or surpass\nstate-of-the-art methods for syntactic and semantic parsing when the model\noutput is constrained to be valid.", "published": "2022-06-21 18:34:11", "link": "http://arxiv.org/abs/2206.10668v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "General Framework for Reversible Data Hiding in Texts Based on Masked\n  Language Modeling", "abstract": "With the fast development of natural language processing, recent advances in\ninformation hiding focus on covertly embedding secret information into texts.\nThese algorithms either modify a given cover text or directly generate a text\ncontaining secret information, which, however, are not reversible, meaning that\nthe original text not carrying secret information cannot be perfectly recovered\nunless much side information are shared in advance. To tackle with this\nproblem, in this paper, we propose a general framework to embed secret\ninformation into a given cover text, for which the embedded information and the\noriginal cover text can be perfectly retrieved from the marked text. The main\nidea of the proposed method is to use a masked language model to generate such\na marked text that the cover text can be reconstructed by collecting the words\nof some positions and the words of the other positions can be processed to\nextract the secret information. Our results show that the original cover text\nand the secret information can be successfully embedded and extracted.\nMeanwhile, the marked text carrying secret information has good fluency and\nsemantic quality, indicating that the proposed method has satisfactory\nsecurity, which has been verified by experimental results. Furthermore, there\nis no need for the data hider and data receiver to share the language model,\nwhich significantly reduces the side information and thus has good potential in\napplications.", "published": "2022-06-21 05:02:49", "link": "http://arxiv.org/abs/2206.10112v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Bridging the Gap Between Indexing and Retrieval for Differentiable\n  Search Index with Query Generation", "abstract": "The Differentiable Search Index (DSI) is an emerging paradigm for information\nretrieval. Unlike traditional retrieval architectures where index and retrieval\nare two different and separate components, DSI uses a single transformer model\nto perform both indexing and retrieval.\n  In this paper, we identify and tackle an important issue of current DSI\nmodels: the data distribution mismatch that occurs between the DSI indexing and\nretrieval processes. Specifically, we argue that, at indexing, current DSI\nmethods learn to build connections between the text of long documents and the\nidentifier of the documents, but then retrieval of document identifiers is\nbased on queries that are commonly much shorter than the indexed documents.\nThis problem is further exacerbated when using DSI for cross-lingual retrieval,\nwhere document text and query text are in different languages.\n  To address this fundamental problem of current DSI models, we propose a\nsimple yet effective indexing framework for DSI, called DSI-QG. When indexing,\nDSI-QG represents documents with a number of potentially relevant queries\ngenerated by a query generation model and re-ranked and filtered by a\ncross-encoder ranker. The presence of these queries at indexing allows the DSI\nmodels to connect a document identifier to a set of queries, hence mitigating\ndata distribution mismatches present between the indexing and the retrieval\nphases. Empirical results on popular mono-lingual and cross-lingual passage\nretrieval datasets show that DSI-QG significantly outperforms the original DSI\nmodel.", "published": "2022-06-21 06:21:23", "link": "http://arxiv.org/abs/2206.10128v3", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "TAPHSIR: Towards AnaPHoric Ambiguity Detection and ReSolution In\n  Requirements", "abstract": "We introduce TAPHSIR, a tool for anaphoric ambiguity detection and anaphora\nresolution in requirements. TAPHSIR facilities reviewing the use of pronouns in\na requirements specification and revising those pronouns that can lead to\nmisunderstandings during the development process. To this end, TAPHSIR detects\nthe requirements which have potential anaphoric ambiguity and further attempts\ninterpreting anaphora occurrences automatically. TAPHSIR employs a hybrid\nsolution composed of an ambiguity detection solution based on machine learning\nand an anaphora resolution solution based on a variant of the BERT language\nmodel. Given a requirements specification, TAPHSIR decides for each pronoun\noccurrence in the specification whether the pronoun is ambiguous or\nunambiguous, and further provides an automatic interpretation for the pronoun.\nThe output generated by TAPHSIR can be easily reviewed and validated by\nrequirements engineers. TAPHSIR is publicly available on Zenodo (DOI:\n10.5281/zenodo.5902117).", "published": "2022-06-21 09:53:13", "link": "http://arxiv.org/abs/2206.10227v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "muBoost: An Effective Method for Solving Indic Multilingual Text\n  Classification Problem", "abstract": "Text Classification is an integral part of many Natural Language Processing\ntasks such as sarcasm detection, sentiment analysis and many more such\napplications. Many e-commerce websites, social-media/entertainment platforms\nuse such models to enhance user-experience to generate traffic and thus,\nrevenue on their platforms. In this paper, we are presenting our solution to\nMultilingual Abusive Comment Identification Problem on Moj, an Indian\nvideo-sharing social networking service, powered by ShareChat. The problem\ndealt with detecting abusive comments, in 13 regional Indic languages such as\nHindi, Telugu, Kannada etc., on the videos on Moj platform. Our solution\nutilizes the novel muBoost, an ensemble of CatBoost classifier models and\nMultilingual Representations for Indian Languages (MURIL) model, to produce\nSOTA performance on Indic text classification tasks. We were able to achieve a\nmean F1-score of 89.286 on the test data, an improvement over baseline MURIL\nmodel with a F1-score of 87.48.", "published": "2022-06-21 12:06:03", "link": "http://arxiv.org/abs/2206.10280v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Plug and Play Counterfactual Text Generation for Model Robustness", "abstract": "Generating counterfactual test-cases is an important backbone for testing NLP\nmodels and making them as robust and reliable as traditional software. In\ngenerating the test-cases, a desired property is the ability to control the\ntest-case generation in a flexible manner to test for a large variety of\nfailure cases and to explain and repair them in a targeted manner. In this\ndirection, significant progress has been made in the prior works by manually\nwriting rules for generating controlled counterfactuals. However, this approach\nrequires heavy manual supervision and lacks the flexibility to easily introduce\nnew controls. Motivated by the impressive flexibility of the plug-and-play\napproach of PPLM, we propose bringing the framework of plug-and-play to\ncounterfactual test case generation task. We introduce CASPer, a plug-and-play\ncounterfactual generation framework to generate test cases that satisfy goal\nattributes on demand. Our plug-and-play model can steer the test case\ngeneration process given any attribute model without requiring\nattribute-specific training of the model. In experiments, we show that CASPer\neffectively generates counterfactual text that follow the steering provided by\nan attribute model while also being fluent, diverse and preserving the original\ncontent. We also show that the generated counterfactuals from CASPer can be\nused for augmenting the training data and thereby fixing and making the test\nmodel more robust.", "published": "2022-06-21 14:25:21", "link": "http://arxiv.org/abs/2206.10429v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An Automatic and Efficient BERT Pruning for Edge AI Systems", "abstract": "With the yearning for deep learning democratization, there are increasing\ndemands to implement Transformer-based natural language processing (NLP) models\non resource-constrained devices for low-latency and high accuracy. Existing\nBERT pruning methods require domain experts to heuristically handcraft\nhyperparameters to strike a balance among model size, latency, and accuracy. In\nthis work, we propose AE-BERT, an automatic and efficient BERT pruning\nframework with efficient evaluation to select a \"good\" sub-network candidate\n(with high accuracy) given the overall pruning ratio constraints. Our proposed\nmethod requires no human experts experience and achieves a better accuracy\nperformance on many NLP tasks. Our experimental results on General Language\nUnderstanding Evaluation (GLUE) benchmark show that AE-BERT outperforms the\nstate-of-the-art (SOTA) hand-crafted pruning methods on BERT$_{\\mathrm{BASE}}$.\nOn QNLI and RTE, we obtain 75\\% and 42.8\\% more overall pruning ratio while\nachieving higher accuracy. On MRPC, we obtain a 4.6 higher score than the SOTA\nat the same overall pruning ratio of 0.5. On STS-B, we can achieve a 40\\%\nhigher pruning ratio with a very small loss in Spearman correlation compared to\nSOTA hand-crafted pruning methods. Experimental results also show that after\nmodel compression, the inference time of a single BERT$_{\\mathrm{BASE}}$\nencoder on Xilinx Alveo U200 FPGA board has a 1.83$\\times$ speedup compared to\nIntel(R) Xeon(R) Gold 5218 (2.30GHz) CPU, which shows the reasonableness of\ndeploying the proposed method generated subnets of BERT$_{\\mathrm{BASE}}$ model\non computation restricted devices.", "published": "2022-06-21 15:10:29", "link": "http://arxiv.org/abs/2206.10461v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Twitter conversations predict the daily confirmed COVID-19 cases", "abstract": "As of writing this paper, COVID-19 (Coronavirus disease 2019) has spread to\nmore than 220 countries and territories. Following the outbreak, the pandemic's\nseriousness has made people more active on social media, especially on the\nmicroblogging platforms such as Twitter and Weibo. The pandemic-specific\ndiscourse has remained on-trend on these platforms for months now. Previous\nstudies have confirmed the contributions of such socially generated\nconversations towards situational awareness of crisis events. The early\nforecasts of cases are essential to authorities to estimate the requirements of\nresources needed to cope with the outgrowths of the virus. Therefore, this\nstudy attempts to incorporate the public discourse in the design of forecasting\nmodels particularly targeted for the steep-hill region of an ongoing wave. We\npropose a sentiment-involved topic-based latent variables search methodology\nfor designing forecasting models from publicly available Twitter conversations.\nAs a use case, we implement the proposed methodology on Australian COVID-19\ndaily cases and Twitter conversations generated within the country.\nExperimental results: (i) show the presence of latent social media variables\nthat Granger-cause the daily COVID-19 confirmed cases, and (ii) confirm that\nthose variables offer additional prediction capability to forecasting models.\nFurther, the results show that the inclusion of social media variables\nintroduces 48.83--51.38% improvements on RMSE over the baseline models. We also\nrelease the large-scale COVID-19 specific geotagged global tweets dataset,\nMegaGeoCOV, to the public anticipating that the geotagged data of this scale\nwould aid in understanding the conversational dynamics of the pandemic through\nother spatial and temporal contexts.", "published": "2022-06-21 15:31:06", "link": "http://arxiv.org/abs/2206.10471v2", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "PlanBench: An Extensible Benchmark for Evaluating Large Language Models\n  on Planning and Reasoning about Change", "abstract": "Generating plans of action, and reasoning about change have long been\nconsidered a core competence of intelligent agents. It is thus no surprise that\nevaluating the planning and reasoning capabilities of large language models\n(LLMs) has become a hot topic of research. Most claims about LLM planning\ncapabilities are however based on common sense tasks-where it becomes hard to\ntell whether LLMs are planning or merely retrieving from their vast world\nknowledge. There is a strong need for systematic and extensible planning\nbenchmarks with sufficient diversity to evaluate whether LLMs have innate\nplanning capabilities. Motivated by this, we propose PlanBench, an extensible\nbenchmark suite based on the kinds of domains used in the automated planning\ncommunity, especially in the International Planning Competition, to test the\ncapabilities of LLMs in planning or reasoning about actions and change.\nPlanBench provides sufficient diversity in both the task domains and the\nspecific planning capabilities. Our studies also show that on many critical\ncapabilities-including plan generation-LLM performance falls quite short, even\nwith the SOTA models. PlanBench can thus function as a useful marker of\nprogress of LLMs in planning and reasoning.", "published": "2022-06-21 16:15:27", "link": "http://arxiv.org/abs/2206.10498v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Questions Are All You Need to Train a Dense Passage Retriever", "abstract": "We introduce ART, a new corpus-level autoencoding approach for training dense\nretrieval models that does not require any labeled training data. Dense\nretrieval is a central challenge for open-domain tasks, such as Open QA, where\nstate-of-the-art methods typically require large supervised datasets with\ncustom hard-negative mining and denoising of positive examples. ART, in\ncontrast, only requires access to unpaired inputs and outputs (e.g. questions\nand potential answer documents). It uses a new document-retrieval autoencoding\nscheme, where (1) an input question is used to retrieve a set of evidence\ndocuments, and (2) the documents are then used to compute the probability of\nreconstructing the original question. Training for retrieval based on question\nreconstruction enables effective unsupervised learning of both document and\nquestion encoders, which can be later incorporated into complete Open QA\nsystems without any further finetuning. Extensive experiments demonstrate that\nART obtains state-of-the-art results on multiple QA retrieval benchmarks with\nonly generic initialization from a pre-trained language model, removing the\nneed for labeled data and task-specific losses.", "published": "2022-06-21 18:16:31", "link": "http://arxiv.org/abs/2206.10658v4", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Making the case for audience design in conversational AI: Rapport\n  expectations and language ideologies in a task-oriented chatbot", "abstract": "Chatbots are more and more prevalent in commercial and science contexts. They\nhelp customers complain about a product or service or support them to find the\nbest travel deals. Other bots provide mental health support or help book\nmedical appointments. This paper argues that insights into users' language\nideologies and their rapport expectations can be used to inform the audience\ndesign of the bot's language and interaction patterns and ensure equitable\naccess to the services provided by bots. The argument is underpinned by three\nkinds of data: simulated user interactions with a chatbot facilitating health\nappointment bookings, users' introspective comments on their interactions and\nusers' qualitative survey comments post engagement with the booking bot. In\nclosing, I will define audience design for conversational AI and discuss how\nuser-centred analyses of chatbot interactions and sociolinguistically informed\ntheoretical approaches, such as rapport management, can be used to support\naudience design.", "published": "2022-06-21 19:21:30", "link": "http://arxiv.org/abs/2206.10694v1", "categories": ["cs.CL", "cs.AI", "68Txx", "I.2; J.4"], "primary_category": "cs.CL"}
{"title": "Don't Forget About Pronouns: Removing Gender Bias in Language Models\n  Without Losing Factual Gender Information", "abstract": "The representations in large language models contain multiple types of gender\ninformation. We focus on two types of such signals in English texts: factual\ngender information, which is a grammatical or semantic property, and gender\nbias, which is the correlation between a word and specific gender. We can\ndisentangle the model's embeddings and identify components encoding both types\nof information with probing. We aim to diminish the stereotypical bias in the\nrepresentations while preserving the factual gender signal. Our filtering\nmethod shows that it is possible to decrease the bias of gender-neutral\nprofession names without significant deterioration of language modeling\ncapabilities. The findings can be applied to language generation to mitigate\nreliance on stereotypes while preserving gender agreement in coreferences.", "published": "2022-06-21 21:38:25", "link": "http://arxiv.org/abs/2206.10744v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Why Robust Natural Language Understanding is a Challenge", "abstract": "With the proliferation of Deep Machine Learning into real-life applications,\na particular property of this technology has been brought to attention:\nrobustness Neural Networks notoriously present low robustness and can be highly\nsensitive to small input perturbations. Recently, many methods for verifying\nnetworks' general properties of robustness have been proposed, but they are\nmostly applied in Computer Vision. In this paper we propose a Verification\nspecification for Natural Language Understanding classification based on larger\nregions of interest, and we discuss the challenges of such task. We observe\nthat, although the data is almost linearly separable, the verifier struggles to\noutput positive results and we explain the problems and implications.", "published": "2022-06-21 12:22:46", "link": "http://arxiv.org/abs/2206.14575v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Supervision-Guided Codebooks for Masked Prediction in Speech\n  Pre-training", "abstract": "Recently, masked prediction pre-training has seen remarkable progress in\nself-supervised learning (SSL) for speech recognition. It usually requires a\ncodebook obtained in an unsupervised way, making it less accurate and difficult\nto interpret. We propose two supervision-guided codebook generation approaches\nto improve automatic speech recognition (ASR) performance and also the\npre-training efficiency, either through decoding with a hybrid ASR system to\ngenerate phoneme-level alignments (named PBERT), or performing clustering on\nthe supervised speech features extracted from an end-to-end CTC model (named\nCTC clustering). Both the hybrid and CTC models are trained on the same small\namount of labeled speech as used in fine-tuning. Experiments demonstrate\nsignificant superiority of our methods to various SSL and self-training\nbaselines, with up to 17.0% relative WER reduction. Our pre-trained models also\nshow good transferability in a non-ASR speech task.", "published": "2022-06-21 06:08:30", "link": "http://arxiv.org/abs/2206.10125v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Comprehensive Analysis of Negative Sampling in Knowledge Graph\n  Representation Learning", "abstract": "Negative sampling (NS) loss plays an important role in learning knowledge\ngraph embedding (KGE) to handle a huge number of entities. However, the\nperformance of KGE degrades without hyperparameters such as the margin term and\nnumber of negative samples in NS loss being appropriately selected. Currently,\nempirical hyperparameter tuning addresses this problem at the cost of\ncomputational time. To solve this problem, we theoretically analyzed NS loss to\nassist hyperparameter tuning and understand the better use of the NS loss in\nKGE learning. Our theoretical analysis showed that scoring methods with\nrestricted value ranges, such as TransE and RotatE, require appropriate\nadjustment of the margin term or the number of negative samples different from\nthose without restricted value ranges, such as RESCAL, ComplEx, and DistMult.\nWe also propose subsampling methods specialized for the NS loss in KGE studied\nfrom a theoretical aspect. Our empirical analysis on the FB15k-237, WN18RR, and\nYAGO3-10 datasets showed that the results of actually trained models agree with\nour theoretical findings.", "published": "2022-06-21 06:51:33", "link": "http://arxiv.org/abs/2206.10140v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.SI"], "primary_category": "cs.LG"}
{"title": "TraSE: Towards Tackling Authorial Style from a Cognitive Science\n  Perspective", "abstract": "Stylistic analysis of text is a key task in research areas ranging from\nauthorship attribution to forensic analysis and personality profiling. The\nexisting approaches for stylistic analysis are plagued by issues like topic\ninfluence, lack of discriminability for large number of authors and the\nrequirement for large amounts of diverse data. In this paper, the source of\nthese issues are identified along with the necessity for a cognitive\nperspective on authorial style in addressing them. A novel feature\nrepresentation, called Trajectory-based Style Estimation (TraSE), is introduced\nto support this purpose. Authorship attribution experiments with over 27,000\nauthors and 1.4 million samples in a cross-domain scenario resulted in 90%\nattribution accuracy suggesting that the feature representation is immune to\nsuch negative influences and an excellent candidate for stylistic analysis.\nFinally, a qualitative analysis is performed on TraSE using physical human\ncharacteristics, like age, to validate its claim on capturing cognitive traits.", "published": "2022-06-21 19:55:07", "link": "http://arxiv.org/abs/2206.10706v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Knowledge Graph Fusion for Language Model Fine-tuning", "abstract": "Language Models such as BERT have grown in popularity due to their ability to\nbe pre-trained and perform robustly on a wide range of Natural Language\nProcessing tasks. Often seen as an evolution over traditional word embedding\ntechniques, they can produce semantic representations of text, useful for tasks\nsuch as semantic similarity. However, state-of-the-art models often have high\ncomputational requirements and lack global context or domain knowledge which is\nrequired for complete language understanding. To address these limitations, we\ninvestigate the benefits of knowledge incorporation into the fine-tuning stages\nof BERT. An existing K-BERT model, which enriches sentences with triplets from\na Knowledge Graph, is adapted for the English language and extended to inject\ncontextually relevant information into sentences. As a side-effect, changes\nmade to K-BERT for accommodating the English language also extend to other\nword-based languages. Experiments conducted indicate that injected knowledge\nintroduces noise. We see statistically significant improvements for\nknowledge-driven tasks when this noise is minimised. We show evidence that,\ngiven the appropriate task, modest injection with relevant, high-quality\nknowledge is most performant.", "published": "2022-06-21 08:06:22", "link": "http://arxiv.org/abs/2206.14574v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Using cognitive psychology to understand GPT-3", "abstract": "We study GPT-3, a recent large language model, using tools from cognitive\npsychology. More specifically, we assess GPT-3's decision-making, information\nsearch, deliberation, and causal reasoning abilities on a battery of canonical\nexperiments from the literature. We find that much of GPT-3's behavior is\nimpressive: it solves vignette-based tasks similarly or better than human\nsubjects, is able to make decent decisions from descriptions, outperforms\nhumans in a multi-armed bandit task, and shows signatures of model-based\nreinforcement learning. Yet we also find that small perturbations to\nvignette-based tasks can lead GPT-3 vastly astray, that it shows no signatures\nof directed exploration, and that it fails miserably in a causal reasoning\ntask. These results enrich our understanding of current large language models\nand pave the way for future investigations using tools from cognitive\npsychology to study increasingly capable and opaque artificial agents.", "published": "2022-06-21 20:06:03", "link": "http://arxiv.org/abs/2206.14576v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Incorporating Voice Instructions in Model-Based Reinforcement Learning\n  for Self-Driving Cars", "abstract": "This paper presents a novel approach that supports natural language voice\ninstructions to guide deep reinforcement learning (DRL) algorithms when\ntraining self-driving cars. DRL methods are popular approaches for autonomous\nvehicle (AV) agents. However, most existing methods are sample- and\ntime-inefficient and lack a natural communication channel with the human\nexpert. In this paper, how new human drivers learn from human coaches motivates\nus to study new ways of human-in-the-loop learning and a more natural and\napproachable training interface for the agents. We propose incorporating\nnatural language voice instructions (NLI) in model-based deep reinforcement\nlearning to train self-driving cars. We evaluate the proposed method together\nwith a few state-of-the-art DRL methods in the CARLA simulator. The results\nshow that NLI can help ease the training process and significantly boost the\nagents' learning speed.", "published": "2022-06-21 10:55:39", "link": "http://arxiv.org/abs/2206.10249v1", "categories": ["cs.HC", "cs.CL", "cs.CV", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "A Multi-grained based Attention Network for Semi-supervised Sound Event\n  Detection", "abstract": "Sound event detection (SED) is an interesting but challenging task due to the\nscarcity of data and diverse sound events in real life. This paper presents a\nmulti-grained based attention network (MGA-Net) for semi-supervised sound event\ndetection. To obtain the feature representations related to sound events, a\nresidual hybrid convolution (RH-Conv) block is designed to boost the vanilla\nconvolution's ability to extract the time-frequency features. Moreover, a\nmulti-grained attention (MGA) module is designed to learn temporal resolution\nfeatures from coarse-level to fine-level. With the MGA module,the network could\ncapture the characteristics of target events with short- or long-duration,\nresulting in more accurately determining the onset and offset of sound events.\nFurthermore, to effectively boost the performance of the Mean Teacher (MT)\nmethod, a spatial shift (SS) module as a data perturbation mechanism is\nintroduced to increase the diversity of data. Experimental results show that\nthe MGA-Net outperforms the published state-of-the-art competitors, achieving\n53.27% and 56.96% event-based macro F1 (EB-F1) score, 0.709 and 0.739\npolyphonic sound detection score (PSDS) on the validation and public set\nrespectively.", "published": "2022-06-21 08:15:27", "link": "http://arxiv.org/abs/2206.10175v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Joint Analysis of Acoustic Scenes and Sound Events Based on Multitask\n  Learning with Dynamic Weight Adaptation", "abstract": "Acoustic scene classification (ASC) and sound event detection (SED) are major\ntopics in environmental sound analysis. Considering that acoustic scenes and\nsound events are closely related to each other, the joint analysis of acoustic\nscenes and sound events using multitask learning (MTL)-based neural networks\nwas proposed in some previous works. Conventional methods train MTL-based\nmodels using a linear combination of ASC and SED loss functions with constant\nweights. However, the performance of conventional MTL-based methods depends\nstrongly on the weights of the ASC and SED losses, and it is difficult to\ndetermine the appropriate balance between the constant weights of the losses of\nMTL of ASC and SED. In this paper, we thus propose dynamic weight adaptation\nmethods for MTL of ASC and SED based on dynamic weight average and multi--focal\nloss to adjust the learning weights automatically. Evaluation experiments using\nparts of the TUT Acoustic Scenes 2016/2017 and TUT Sound Events 2016/2017 are\nconducted, and we show that the proposed methods improve the scene\nclassification and event detection performance characteristics compared with\nthe conventional MTL-based method. We then investigate how the learning weights\nof ASC and SED tasks dynamically adapt as the model training progresses.", "published": "2022-06-21 13:05:56", "link": "http://arxiv.org/abs/2206.10349v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Exploring the Effectiveness of Self-supervised Learning and Classifier\n  Chains in Emotion Recognition of Nonverbal Vocalizations", "abstract": "We present an emotion recognition system for nonverbal vocalizations (NVs)\nsubmitted to the ExVo Few-Shot track of the ICML Expressive Vocalizations\nCompetition 2022. The proposed method uses self-supervised learning (SSL)\nmodels to extract features from NVs and uses a classifier chain to model the\nlabel dependency between emotions. Experimental results demonstrate that the\nproposed method can significantly improve the performance of this task compared\nto several baseline methods. Our proposed method obtained a mean concordance\ncorrelation coefficient (CCC) of $0.725$ in the validation set and $0.739$ in\nthe test set, while the best baseline method only obtained $0.554$ in the\nvalidation set. We publicate our code at https://github.com/Aria-K-Alethia/ExVo\nto help others to reproduce our experimental results.", "published": "2022-06-21 19:29:54", "link": "http://arxiv.org/abs/2206.10695v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Analysis of Self-Supervised Learning and Dimensionality Reduction\n  Methods in Clustering-Based Active Learning for Speech Emotion Recognition", "abstract": "When domain experts are needed to perform data annotation for complex\nmachine-learning tasks, reducing annotation effort is crucial in order to cut\ndown time and expenses. For cases when there are no annotations available, one\napproach is to utilize the structure of the feature space for clustering-based\nactive learning (AL) methods. However, these methods are heavily dependent on\nhow the samples are organized in the feature space and what distance metric is\nused. Unsupervised methods such as contrastive predictive coding (CPC) can\npotentially be used to learn organized feature spaces, but these methods\ntypically create high-dimensional features which might be challenging for\nestimating data density. In this paper, we combine CPC and multiple\ndimensionality reduction methods in search of functioning practices for\nclustering-based AL. Our experiments for simulating speech emotion recognition\nsystem deployment show that both the local and global topology of the feature\nspace can be successfully used for AL, and that CPC can be used to improve\nclustering-based AL performance over traditional signal features. Additionally,\nwe observe that compressing data dimensionality does not harm AL performance\nsubstantially, and that 2-D feature representations achieved similar AL\nperformance as higher-dimensional representations when the number of\nannotations is not very low.", "published": "2022-06-21 08:44:55", "link": "http://arxiv.org/abs/2206.10188v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Human-in-the-loop Speaker Adaptation for DNN-based Multi-speaker TTS", "abstract": "This paper proposes a human-in-the-loop speaker-adaptation method for\nmulti-speaker text-to-speech. With a conventional speaker-adaptation method, a\ntarget speaker's embedding vector is extracted from his/her reference speech\nusing a speaker encoder trained on a speaker-discriminative task. However, this\nmethod cannot obtain an embedding vector for the target speaker when the\nreference speech is unavailable. Our method is based on a human-in-the-loop\noptimization framework, which incorporates a user to explore the\nspeaker-embedding space to find the target speaker's embedding. The proposed\nmethod uses a sequential line search algorithm that repeatedly asks a user to\nselect a point on a line segment in the embedding space. To efficiently choose\nthe best speech sample from multiple stimuli, we also developed a system in\nwhich a user can switch between multiple speakers' voices for each phoneme\nwhile looping an utterance. Experimental results indicate that the proposed\nmethod can achieve comparable performance to the conventional one in objective\nand subjective evaluations even if reference speech is not used as the input of\na speaker encoder directly.", "published": "2022-06-21 11:08:05", "link": "http://arxiv.org/abs/2206.10256v1", "categories": ["cs.SD", "cs.HC", "cs.NE", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Rethinking Audio-visual Synchronization for Active Speaker Detection", "abstract": "Active speaker detection (ASD) systems are important modules for analyzing\nmulti-talker conversations. They aim to detect which speakers or none are\ntalking in a visual scene at any given time. Existing research on ASD does not\nagree on the definition of active speakers. We clarify the definition in this\nwork and require synchronization between the audio and visual speaking\nactivities. This clarification of definition is motivated by our extensive\nexperiments, through which we discover that existing ASD methods fail in\nmodeling the audio-visual synchronization and often classify unsynchronized\nvideos as active speaking. To address this problem, we propose a cross-modal\ncontrastive learning strategy and apply positional encoding in attention\nmodules for supervised ASD models to leverage the synchronization cue.\nExperimental results suggest that our model can successfully detect\nunsynchronized speaking as not speaking, addressing the limitation of current\nmodels.", "published": "2022-06-21 14:19:06", "link": "http://arxiv.org/abs/2206.10421v2", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
