{"title": "An Improved Approach for Semantic Graph Composition with CCG", "abstract": "This paper builds on previous work using Combinatory Categorial Grammar (CCG)\nto derive a transparent syntax-semantics interface for Abstract Meaning\nRepresentation (AMR) parsing. We define new semantics for the CCG combinators\nthat is better suited to deriving AMR graphs. In particular, we define\nrelation-wise alternatives for the application and composition combinators:\nthese require that the two constituents being combined overlap in one AMR\nrelation. We also provide a new semantics for type raising, which is necessary\nfor certain constructions. Using these mechanisms, we suggest an analysis of\neventive nouns, which present a challenge for deriving AMR graphs. Our\ntheoretical analysis will facilitate future work on robust and transparent AMR\nparsing using CCG.", "published": "2019-03-28 03:09:11", "link": "http://arxiv.org/abs/1903.11770v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Large-Scale Multi-Length Headline Corpus for Analyzing\n  Length-Constrained Headline Generation Model Evaluation", "abstract": "Browsing news articles on multiple devices is now possible. The lengths of\nnews article headlines have precise upper bounds, dictated by the size of the\ndisplay of the relevant device or interface. Therefore, controlling the length\nof headlines is essential when applying the task of headline generation to news\nproduction. However, because there is no corpus of headlines of multiple\nlengths for a given article, previous research on controlling output length in\nheadline generation has not discussed whether the system outputs could be\nadequately evaluated without multiple references of different lengths. In this\npaper, we introduce two corpora, which are Japanese News Corpus (JNC) and\nJApanese MUlti-Length Headline Corpus (JAMUL), to confirm the validity of\nprevious evaluation settings. The JNC provides common supervision data for\nheadline generation. The JAMUL is a large-scale evaluation dataset for\nheadlines of three different lengths composed by professional editors. We\nreport new findings on these corpora; for example, although the longest length\nreference summary can appropriately evaluate the existing methods controlling\noutput length, this evaluation setting has several problems.", "published": "2019-03-28 03:09:33", "link": "http://arxiv.org/abs/1903.11771v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A dataset for resolving referring expressions in spoken dialogue via\n  contextual query rewrites (CQR)", "abstract": "We present Contextual Query Rewrite (CQR) a dataset for multi-domain\ntask-oriented spoken dialogue systems that is an extension of the Stanford\ndialog corpus (Eric et al., 2017a). While previous approaches have addressed\nthe issue of diverse schemas by learning candidate transformations (Naik et\nal., 2018), we instead model the reference resolution task as a user query\nreformulation task, where the dialog state is serialized into a natural\nlanguage query that can be executed by the downstream spoken language\nunderstanding system. In this paper, we describe our methodology for creating\nthe query reformulation extension to the dialog corpus, and present an initial\nset of experiments to establish a baseline for the CQR task. We have released\nthe corpus to the public [1] to support further research in this area.", "published": "2019-03-28 04:39:34", "link": "http://arxiv.org/abs/1903.11783v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sogou Machine Reading Comprehension Toolkit", "abstract": "Machine reading comprehension have been intensively studied in recent years,\nand neural network-based models have shown dominant performances. In this\npaper, we present a Sogou Machine Reading Comprehension (SMRC) toolkit that can\nbe used to provide the fast and efficient development of modern machine\ncomprehension models, including both published models and original prototypes.\nTo achieve this goal, the toolkit provides dataset readers, a flexible\npreprocessing pipeline, necessary neural network components, and built-in\nmodels, which make the whole process of data preparation, model construction,\nand training easier.", "published": "2019-03-28 09:27:23", "link": "http://arxiv.org/abs/1903.11848v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mining Discourse Markers for Unsupervised Sentence Representation\n  Learning", "abstract": "Current state of the art systems in NLP heavily rely on manually annotated\ndatasets, which are expensive to construct. Very little work adequately\nexploits unannotated data -- such as discourse markers between sentences --\nmainly because of data sparseness and ineffective extraction methods. In the\npresent work, we propose a method to automatically discover sentence pairs with\nrelevant discourse markers, and apply it to massive amounts of data. Our\nresulting dataset contains 174 discourse markers with at least 10k examples\neach, even for rare markers such as coincidentally or amazingly We use the\nresulting data as supervision for learning transferable sentence embeddings. In\naddition, we show that even though sentence representation learning through\nprediction of discourse markers yields state of the art results across\ndifferent transfer tasks, it is not clear that our models made use of the\nsemantic relation between sentences, thus leaving room for further\nimprovements. Our datasets are publicly available\n(https://github.com/synapse-developpement/Discovery)", "published": "2019-03-28 09:30:16", "link": "http://arxiv.org/abs/1903.11850v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Resilient Combination of Complementary CNN and RNN Features for Text\n  Classification through Attention and Ensembling", "abstract": "State-of-the-art methods for text classification include several distinct\nsteps of pre-processing, feature extraction and post-processing. In this work,\nwe focus on end-to-end neural architectures and show that the best performance\nin text classification is obtained by combining information from different\nneural modules. Concretely, we combine convolution, recurrent and attention\nmodules with ensemble methods and show that they are complementary. We\nintroduce ECGA, an end-to-end go-to architecture for novel text classification\ntasks. We prove that it is efficient and robust, as it attains or surpasses the\nstate-of-the-art on varied datasets, including both low and high data regimes.", "published": "2019-03-28 17:43:09", "link": "http://arxiv.org/abs/1903.12157v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modeling Acoustic-Prosodic Cues for Word Importance Prediction in Spoken\n  Dialogues", "abstract": "Prosodic cues in conversational speech aid listeners in discerning a message.\nWe investigate whether acoustic cues in spoken dialogue can be used to identify\nthe importance of individual words to the meaning of a conversation turn.\nIndividuals who are Deaf and Hard of Hearing often rely on real-time captions\nin live meetings. Word error rate, a traditional metric for evaluating\nautomatic speech recognition, fails to capture that some words are more\nimportant for a system to transcribe correctly than others. We present and\nevaluate neural architectures that use acoustic features for 3-class word\nimportance prediction. Our model performs competitively against\nstate-of-the-art text-based word-importance prediction models, and it\ndemonstrates particular benefits when operating on imperfect ASR output.", "published": "2019-03-28 19:43:57", "link": "http://arxiv.org/abs/1903.12238v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "In Search of Meaning: Lessons, Resources and Next Steps for\n  Computational Analysis of Financial Discourse", "abstract": "We critically assess mainstream accounting and finance research applying\nmethods from computational linguistics (CL) to study financial discourse. We\nalso review common themes and innovations in the literature and assess the\nincremental contributions of work applying CL methods over manual content\nanalysis. Key conclusions emerging from our analysis are: (a) accounting and\nfinance research is behind the curve in terms of CL methods generally and word\nsense disambiguation in particular; (b) implementation issues mean the proposed\nbenefits of CL are often less pronounced than proponents suggest; (c)\nstructural issues limit practical relevance; and (d) CL methods and high\nquality manual analysis represent complementary approaches to analyzing\nfinancial discourse. We describe four CL tools that have yet to gain traction\nin mainstream AF research but which we believe offer promising ways to enhance\nthe study of meaning in financial discourse. The four tools are named entity\nrecognition (NER), summarization, semantics and corpus linguistics.", "published": "2019-03-28 21:12:59", "link": "http://arxiv.org/abs/1903.12271v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Imbalanced Sentiment Classification Enhanced with Discourse Marker", "abstract": "Imbalanced data commonly exists in real world, espacially in\nsentiment-related corpus, making it difficult to train a classifier to\ndistinguish latent sentiment in text data. We observe that humans often express\ntransitional emotion between two adjacent discourses with discourse markers\nlike \"but\", \"though\", \"while\", etc, and the head discourse and the tail\ndiscourse 3 usually indicate opposite emotional tendencies. Based on this\nobservation, we propose a novel plug-and-play method, which first samples\ndiscourses according to transitional discourse markers and then validates\nsentimental polarities with the help of a pretrained attention-based model. Our\nmethod increases sample diversity in the first place, can serve as a upstream\npreprocessing part in data augmentation. We conduct experiments on three public\nsentiment datasets, with several frequently used algorithms. Results show that\nour method is found to be consistently effective, even in highly imbalanced\nscenario, and easily be integrated with oversampling method to boost the\nperformance on imbalanced sentiment classification.", "published": "2019-03-28 12:38:58", "link": "http://arxiv.org/abs/1903.11919v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Handling Noisy Labels for Robustly Learning from Self-Training Data for\n  Low-Resource Sequence Labeling", "abstract": "In this paper, we address the problem of effectively self-training neural\nnetworks in a low-resource setting. Self-training is frequently used to\nautomatically increase the amount of training data. However, in a low-resource\nscenario, it is less effective due to unreliable annotations created using\nself-labeling of unlabeled data. We propose to combine self-training with noise\nhandling on the self-labeled data. Directly estimating noise on the combined\nclean training set and self-labeled data can lead to corruption of the clean\ndata and hence, performs worse. Thus, we propose the Clean and Noisy Label\nNeural Network which trains on clean and noisy self-labeled data simultaneously\nby explicitly modelling clean and noisy labels separately. In our experiments\non Chunking and NER, this approach performs more robustly than the baselines.\nComplementary to this explicit approach, noise can also be handled implicitly\nwith the help of an auxiliary learning task. To such a complementary approach,\nour method is more beneficial than other baseline methods and together provides\nthe best performance overall.", "published": "2019-03-28 14:33:50", "link": "http://arxiv.org/abs/1903.12008v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Train, Sort, Explain: Learning to Diagnose Translation Models", "abstract": "Evaluating translation models is a trade-off between effort and detail. On\nthe one end of the spectrum there are automatic count-based methods such as\nBLEU, on the other end linguistic evaluations by humans, which arguably are\nmore informative but also require a disproportionately high effort. To narrow\nthe spectrum, we propose a general approach on how to automatically expose\nsystematic differences between human and machine translations to human experts.\nInspired by adversarial settings, we train a neural text classifier to\ndistinguish human from machine translations. A classifier that performs and\ngeneralizes well after training should recognize systematic differences between\nthe two classes, which we uncover with neural explainability methods. Our\nproof-of-concept implementation, DiaMaT, is open source. Applied to a dataset\ntranslated by a state-of-the-art neural Transformer model, DiaMaT achieves a\nclassification accuracy of 75% and exposes meaningful differences between\nhumans and the Transformer, amidst the current discussion about human parity.", "published": "2019-03-28 14:45:42", "link": "http://arxiv.org/abs/1903.12017v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Distilling Task-Specific Knowledge from BERT into Simple Neural Networks", "abstract": "In the natural language processing literature, neural networks are becoming\nincreasingly deeper and complex. The recent poster child of this trend is the\ndeep language representation model, which includes BERT, ELMo, and GPT. These\ndevelopments have led to the conviction that previous-generation, shallower\nneural networks for language understanding are obsolete. In this paper,\nhowever, we demonstrate that rudimentary, lightweight neural networks can still\nbe made competitive without architecture changes, external training data, or\nadditional input features. We propose to distill knowledge from BERT, a\nstate-of-the-art language representation model, into a single-layer BiLSTM, as\nwell as its siamese counterpart for sentence-pair tasks. Across multiple\ndatasets in paraphrasing, natural language inference, and sentiment\nclassification, we achieve comparable results with ELMo, while using roughly\n100 times fewer parameters and 15 times less inference time.", "published": "2019-03-28 17:23:50", "link": "http://arxiv.org/abs/1903.12136v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Crowd Sourced Data Analysis: Mapping of Programming Concepts to\n  Syntactical Patterns", "abstract": "Since programming concepts do not match their syntactic representations, code\nsearch is a very tedious task. For instance in Java or C, array doesn't match\n[], so using \"array\" as a query, one cannot find what they are looking for.\nOften developers have to search code whether to understand any code, or to\nreuse some part of that code, or just to read it, without natural language\nsearching, developers have to often scroll back and forth or use variable names\nas their queries. In our work, we have used Stackoverflow (SO) question and\nanswers to make a mapping of programming concepts with their respective natural\nlanguage keywords, and then tag these natural language terms to every line of\ncode, which can further we used in searching using natural language keywords.", "published": "2019-03-28 15:13:20", "link": "http://arxiv.org/abs/1903.12495v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Hierarchical Pooling Structure for Weakly Labeled Sound Event Detection", "abstract": "Sound event detection with weakly labeled data is considered as a problem of\nmulti-instance learning. And the choice of pooling function is the key to\nsolving this problem. In this paper, we proposed a hierarchical pooling\nstructure to improve the performance of weakly labeled sound event detection\nsystem. Proposed pooling structure has made remarkable improvements on three\ntypes of pooling function without adding any parameters. Moreover, our system\nhas achieved competitive performance on Task 4 of Detection and Classification\nof Acoustic Scenes and Events (DCASE) 2017 Challenge using hierarchical pooling\nstructure.", "published": "2019-03-28 05:49:26", "link": "http://arxiv.org/abs/1903.11791v4", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multi-Task Learning with High-Order Statistics for X-vector based\n  Text-Independent Speaker Verification", "abstract": "The x-vector based deep neural network (DNN) embedding systems have\ndemonstrated effectiveness for text-independent speaker verification. This\npaper presents a multi-task learning architecture for training the speaker\nembedding DNN with the primary task of classifying the target speakers, and the\nauxiliary task of reconstructing the first- and higher-order statistics of the\noriginal input utterance. The proposed training strategy aggregates both the\nsupervised and unsupervised learning into one framework to make the speaker\nembeddings more discriminative and robust. Experiments are carried out using\nthe NIST SRE16 evaluation dataset and the VOiCES dataset. The results\ndemonstrate that our proposed method outperforms the original x-vector approach\nwith very low additional complexity added.", "published": "2019-03-28 15:40:57", "link": "http://arxiv.org/abs/1903.12058v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A Real-Time Wideband Neural Vocoder at 1.6 kb/s Using LPCNet", "abstract": "Neural speech synthesis algorithms are a promising new approach for coding\nspeech at very low bitrate. They have so far demonstrated quality that far\nexceeds traditional vocoders, at the cost of very high complexity. In this\nwork, we present a low-bitrate neural vocoder based on the LPCNet model. The\nuse of linear prediction and sparse recurrent networks makes it possible to\nachieve real-time operation on general-purpose hardware. We demonstrate that\nLPCNet operating at 1.6 kb/s achieves significantly higher quality than MELP\nand that uncompressed LPCNet can exceed the quality of a waveform codec\noperating at low bitrate. This opens the way for new codec designs based on\nneural synthesis models.", "published": "2019-03-28 16:09:58", "link": "http://arxiv.org/abs/1903.12087v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Deep Neural Network Embeddings with Gating Mechanisms for\n  Text-Independent Speaker Verification", "abstract": "In this paper, gating mechanisms are applied in deep neural network (DNN)\ntraining for x-vector-based text-independent speaker verification. First, a\ngated convolution neural network (GCNN) is employed for modeling the\nframe-level embedding layers. Compared with the time-delay DNN (TDNN), the GCNN\ncan obtain more expressive frame-level representations through carefully\ndesigned memory cell and gating mechanisms. Moreover, we propose a novel\ngated-attention statistics pooling strategy in which the attention scores are\nshared with the output gate. The gated-attention statistics pooling combines\nboth gating and attention mechanisms into one framework; therefore, we can\ncapture more useful information in the temporal pooling layer. Experiments are\ncarried out using the NIST SRE16 and SRE18 evaluation datasets. The results\ndemonstrate the effectiveness of the GCNN and show that the proposed\ngated-attention statistics pooling can further improve the performance.", "published": "2019-03-28 16:15:11", "link": "http://arxiv.org/abs/1903.12092v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Improving Cross-Corpus Speech Emotion Recognition with Adversarial\n  Discriminative Domain Generalization (ADDoG)", "abstract": "Automatic speech emotion recognition provides computers with critical context\nto enable user understanding. While methods trained and tested within the same\ndataset have been shown successful, they often fail when applied to unseen\ndatasets. To address this, recent work has focused on adversarial methods to\nfind more generalized representations of emotional speech. However, many of\nthese methods have issues converging, and only involve datasets collected in\nlaboratory conditions. In this paper, we introduce Adversarial Discriminative\nDomain Generalization (ADDoG), which follows an easier to train \"meet in the\nmiddle\" approach. The model iteratively moves representations learned for each\ndataset closer to one another, improving cross-dataset generalization. We also\nintroduce Multiclass ADDoG, or MADDoG, which is able to extend the proposed\nmethod to more than two datasets, simultaneously. Our results show consistent\nconvergence for the introduced methods, with significantly improved results\nwhen not using labels from the target dataset. We also show how, in most cases,\nADDoG and MADDoG can be used to improve upon baseline state-of-the-art methods\nwhen target dataset labels are added and in-the-wild data are considered. Even\nthough our experiments focus on cross-corpus speech emotion, these methods\ncould be used to remove unwanted factors of variation in other settings.", "published": "2019-03-28 16:19:20", "link": "http://arxiv.org/abs/1903.12094v2", "categories": ["cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Adversarial Approximate Inference for Speech to Electroglottograph\n  Conversion", "abstract": "Speech produced by human vocal apparatus conveys substantial non-semantic\ninformation including the gender of the speaker, voice quality, affective\nstate, abnormalities in the vocal apparatus etc. Such information is attributed\nto the properties of the voice source signal, which is usually estimated from\nthe speech signal. However, most of the source estimation techniques depend\nheavily on the goodness of the model assumptions and are prone to noise. A\npopular alternative is to indirectly obtain the source information through the\nElectroglottographic (EGG) signal that measures the electrical admittance\naround the vocal folds using dedicated hardware. In this paper, we address the\nproblem of estimating the EGG signal directly from the speech signal, devoid of\nany hardware. Sampling from the intractable conditional distribution of the EGG\nsignal given the speech signal is accomplished through optimization of an\nevidence lower bound. This is constructed via minimization of the KL-divergence\nbetween the true and the approximated posteriors of a latent variable learned\nusing a deep neural auto-encoder that serves an informative prior. We\ndemonstrate the efficacy of the method at generating the EGG signal by\nconducting several experiments on datasets comprising multiple speakers, voice\nqualities, noise settings and speech pathologies. The proposed method is\nevaluated on many benchmark metrics and is found to agree with the gold\nstandard while proving better than the state-of-the-art algorithms on a few\ntasks such as epoch extraction.", "published": "2019-03-28 20:30:17", "link": "http://arxiv.org/abs/1903.12248v2", "categories": ["eess.AS", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
