{"title": "ERNIE: Enhanced Language Representation with Informative Entities", "abstract": "Neural language representation models such as BERT pre-trained on large-scale\ncorpora can well capture rich semantic patterns from plain text, and be\nfine-tuned to consistently improve the performance of various NLP tasks.\nHowever, the existing pre-trained language models rarely consider incorporating\nknowledge graphs (KGs), which can provide rich structured knowledge facts for\nbetter language understanding. We argue that informative entities in KGs can\nenhance language representation with external knowledge. In this paper, we\nutilize both large-scale textual corpora and KGs to train an enhanced language\nrepresentation model (ERNIE), which can take full advantage of lexical,\nsyntactic, and knowledge information simultaneously. The experimental results\nhave demonstrated that ERNIE achieves significant improvements on various\nknowledge-driven tasks, and meanwhile is comparable with the state-of-the-art\nmodel BERT on other common NLP tasks. The source code of this paper can be\nobtained from https://github.com/thunlp/ERNIE.", "published": "2019-05-17 06:24:16", "link": "http://arxiv.org/abs/1905.07129v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adaptation of Deep Bidirectional Multilingual Transformers for Russian\n  Language", "abstract": "The paper introduces methods of adaptation of multilingual masked language\nmodels for a specific language. Pre-trained bidirectional language models show\nstate-of-the-art performance on a wide range of tasks including reading\ncomprehension, natural language inference, and sentiment analysis. At the\nmoment there are two alternative approaches to train such models: monolingual\nand multilingual. While language specific models show superior performance,\nmultilingual models allow to perform a transfer from one language to another\nand solve tasks for different languages simultaneously. This work shows that\ntransfer learning from a multilingual model to monolingual model results in\nsignificant growth of performance on such tasks as reading comprehension,\nparaphrase detection, and sentiment analysis. Furthermore, multilingual\ninitialization of monolingual model substantially reduces training time.\nPre-trained models for the Russian language are open sourced.", "published": "2019-05-17 11:39:21", "link": "http://arxiv.org/abs/1905.07213v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Availability-Based Production Predicts Speakers' Real-time Choices of\n  Mandarin Classifiers", "abstract": "Speakers often face choices as to how to structure their intended message\ninto an utterance. Here we investigate the influence of contextual\npredictability on the encoding of linguistic content manifested by speaker\nchoice in a classifier language. In English, a numeral modifies a noun directly\n(e.g., three computers). In classifier languages such as Mandarin Chinese, it\nis obligatory to use a classifier (CL) with the numeral and the noun (e.g.,\nthree CL.machinery computer, three CL.general computer). While different nouns\nare compatible with different specific classifiers, there is a general\nclassifier \"ge\" (CL.general) that can be used with most nouns. When the\nupcoming noun is less predictable, the use of a more specific classifier would\nreduce surprisal at the noun thus potentially facilitate comprehension\n(predicted by Uniform Information Density, Levy & Jaeger, 2007), but the use of\nthat more specific classifier may be dispreferred from a production standpoint\nif accessing the general classifier is always available (predicted by\nAvailability-Based Production; Bock, 1987; Ferreira & Dell, 2000). Here we use\na picture-naming experiment showing that Availability-Based Production predicts\nspeakers' real-time choices of Mandarin classifiers.", "published": "2019-05-17 15:19:17", "link": "http://arxiv.org/abs/1905.07321v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-hop Reading Comprehension across Multiple Documents by Reasoning\n  over Heterogeneous Graphs", "abstract": "Multi-hop reading comprehension (RC) across documents poses new challenge\nover single-document RC because it requires reasoning over multiple documents\nto reach the final answer. In this paper, we propose a new model to tackle the\nmulti-hop RC problem. We introduce a heterogeneous graph with different types\nof nodes and edges, which is named as Heterogeneous Document-Entity (HDE)\ngraph. The advantage of HDE graph is that it contains different granularity\nlevels of information including candidates, documents and entities in specific\ndocument contexts. Our proposed model can do reasoning over the HDE graph with\nnodes representation initialized with co-attention and self-attention based\ncontext encoders. We employ Graph Neural Networks (GNN) based message passing\nalgorithms to accumulate evidences on the proposed HDE graph. Evaluated on the\nblind test set of the Qangaroo WikiHop data set, our HDE graph based single\nmodel delivers competitive result, and the ensemble model achieves the\nstate-of-the-art performance.", "published": "2019-05-17 17:03:11", "link": "http://arxiv.org/abs/1905.07374v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Metric Learning for Fast End-to-End Relation Extraction", "abstract": "Relation extraction (RE) is an indispensable information extraction task in\nseveral disciplines. RE models typically assume that named entity recognition\n(NER) is already performed in a previous step by another independent model.\nSeveral recent efforts, under the theme of end-to-end RE, seek to exploit\ninter-task correlations by modeling both NER and RE tasks jointly. Earlier work\nin this area commonly reduces the task to a table-filling problem wherein an\nadditional expensive decoding step involving beam search is applied to obtain\nglobally consistent cell labels. In efforts that do not employ table-filling,\nglobal optimization in the form of CRFs with Viterbi decoding for the NER\ncomponent is still necessary for competitive performance. We introduce a novel\nneural architecture utilizing the table structure, based on repeated\napplications of 2D convolutions for pooling local dependency and metric-based\nfeatures, that improves on the state-of-the-art without the need for global\noptimization. We validate our model on the ADE and CoNLL04 datasets for\nend-to-end RE and demonstrate $\\approx 1\\%$ gain (in F-score) over prior best\nresults with training and testing times that are seven to ten times faster ---\nthe latter highly advantageous for time-sensitive end user applications.", "published": "2019-05-17 20:20:22", "link": "http://arxiv.org/abs/1905.07458v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Multi-Task Learning Framework for Extracting Drugs and Their\n  Interactions from Drug Labels", "abstract": "Preventable adverse drug reactions as a result of medical errors present a\ngrowing concern in modern medicine. As drug-drug interactions (DDIs) may cause\nadverse reactions, being able to extracting DDIs from drug labels into\nmachine-readable form is an important effort in effectively deploying drug\nsafety information. The DDI track of TAC 2018 introduces two large\nhand-annotated test sets for the task of extracting DDIs from structured\nproduct labels with linkage to standard terminologies. Herein, we describe our\napproach to tackling tasks one and two of the DDI track, which corresponds to\nnamed entity recognition (NER) and sentence-level relation extraction\nrespectively. Namely, our approach resembles a multi-task learning framework\ndesigned to jointly model various sub-tasks including NER and interaction type\nand outcome prediction. On NER, our system ranked second (among eight teams) at\n33.00% and 38.25% F1 on Test Sets 1 and 2 respectively. On relation extraction,\nour system ranked second (among four teams) at 21.59% and 23.55% on Test Sets 1\nand 2 respectively.", "published": "2019-05-17 20:29:40", "link": "http://arxiv.org/abs/1905.07464v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Recovering Dropped Pronouns in Chinese Conversations via Modeling Their\n  Referents", "abstract": "Pronouns are often dropped in Chinese sentences, and this happens more\nfrequently in conversational genres as their referents can be easily understood\nfrom context. Recovering dropped pronouns is essential to applications such as\nInformation Extraction where the referents of these dropped pronouns need to be\nresolved, or Machine Translation when Chinese is the source language. In this\nwork, we present a novel end-to-end neural network model to recover dropped\npronouns in conversational data. Our model is based on a structured attention\nmechanism that models the referents of dropped pronouns utilizing both\nsentence-level and word-level information. Results on three different\nconversational genres show that our approach achieves a significant improvement\nover the current state of the art.", "published": "2019-05-17 05:13:22", "link": "http://arxiv.org/abs/1906.02128v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Question Answering over Incomplete KBs with Knowledge-Aware\n  Reader", "abstract": "We propose a new end-to-end question answering model, which learns to\naggregate answer evidence from an incomplete knowledge base (KB) and a set of\nretrieved text snippets. Under the assumptions that the structured KB is easier\nto query and the acquired knowledge can help the understanding of unstructured\ntext, our model first accumulates knowledge of entities from a question-related\nKB subgraph; then reformulates the question in the latent space and reads the\ntexts with the accumulated entity knowledge at hand. The evidence from KB and\ntexts are finally aggregated to predict answers. On the widely-used KBQA\nbenchmark WebQSP, our model achieves consistent improvements across settings\nwith different extents of KB incompleteness.", "published": "2019-05-17 03:00:46", "link": "http://arxiv.org/abs/1905.07098v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Plotting Markson's 'Mistress'", "abstract": "The post-modern novel 'Wittgenstein's Mistress' by David Markson (1988)\npresents the reader with a very challenging non linear narrative, that itself\nappears to one of the novel's themes. We present a distant reading of this work\ndesigned to complement a close reading of it by David Foster Wallace (1990).\nUsing a combination of text analysis, entity recognition and networks, we plot\nrepetitive structures in the novel's narrative relating them to its critical\nanalysis.", "published": "2019-05-17 10:14:21", "link": "http://arxiv.org/abs/1905.07185v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Conversion Prediction Using Multi-task Conditional Attention Networks to\n  Support the Creation of Effective Ad Creative", "abstract": "Accurately predicting conversions in advertisements is generally a\nchallenging task, because such conversions do not occur frequently. In this\npaper, we propose a new framework to support creating high-performing ad\ncreatives, including the accurate prediction of ad creative text conversions\nbefore delivering to the consumer. The proposed framework includes three key\nideas: multi-task learning, conditional attention, and attention highlighting.\nMulti-task learning is an idea for improving the prediction accuracy of\nconversion, which predicts clicks and conversions simultaneously, to solve the\ndifficulty of data imbalance. Furthermore, conditional attention focuses\nattention of each ad creative with the consideration of its genre and target\ngender, thus improving conversion prediction accuracy. Attention highlighting\nvisualizes important words and/or phrases based on conditional attention. We\nevaluated the proposed framework with actual delivery history data (14,000\ncreatives displayed more than a certain number of times from Gunosy Inc.), and\nconfirmed that these ideas improve the prediction performance of conversions,\nand visualize noteworthy words according to the creatives' attributes.", "published": "2019-05-17 14:25:27", "link": "http://arxiv.org/abs/1905.07289v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning Cross-lingual Embeddings from Twitter via Distant Supervision", "abstract": "Cross-lingual embeddings represent the meaning of words from different\nlanguages in the same vector space. Recent work has shown that it is possible\nto construct such representations by aligning independently learned monolingual\nembedding spaces, and that accurate alignments can be obtained even without\nexternal bilingual data. In this paper we explore a research direction that has\nbeen surprisingly neglected in the literature: leveraging noisy user-generated\ntext to learn cross-lingual embeddings particularly tailored towards social\nmedia applications. While the noisiness and informal nature of the social media\ngenre poses additional challenges to cross-lingual embedding methods, we find\nthat it also provides key opportunities due to the abundance of code-switching\nand the existence of a shared vocabulary of emoji and named entities. Our\ncontribution consists of a very simple post-processing step that exploits these\nphenomena to significantly improve the performance of state-of-the-art\nalignment methods.", "published": "2019-05-17 16:27:43", "link": "http://arxiv.org/abs/1905.07358v3", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Story Ending Prediction by Transferable BERT", "abstract": "Recent advances, such as GPT and BERT, have shown success in incorporating a\npre-trained transformer language model and fine-tuning operation to improve\ndownstream NLP systems. However, this framework still has some fundamental\nproblems in effectively incorporating supervised knowledge from other related\ntasks. In this study, we investigate a transferable BERT (TransBERT) training\nframework, which can transfer not only general language knowledge from\nlarge-scale unlabeled data but also specific kinds of knowledge from various\nsemantically related supervised tasks, for a target task. Particularly, we\npropose utilizing three kinds of transfer tasks, including natural language\ninference, sentiment classification, and next action prediction, to further\ntrain BERT based on a pre-trained model. This enables the model to get a better\ninitialization for the target task. We take story ending prediction as the\ntarget task to conduct experiments. The final result, an accuracy of 91.8%,\ndramatically outperforms previous state-of-the-art baseline methods. Several\ncomparative experiments give some helpful suggestions on how to select transfer\ntasks. Error analysis shows what are the strength and weakness of BERT-based\nmodels for story ending prediction.", "published": "2019-05-17 23:52:08", "link": "http://arxiv.org/abs/1905.07504v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Gmail Smart Compose: Real-Time Assisted Writing", "abstract": "In this paper, we present Smart Compose, a novel system for generating\ninteractive, real-time suggestions in Gmail that assists users in writing mails\nby reducing repetitive typing. In the design and deployment of such a\nlarge-scale and complicated system, we faced several challenges including model\nselection, performance evaluation, serving and other practical issues. At the\ncore of Smart Compose is a large-scale neural language model. We leveraged\nstate-of-the-art machine learning techniques for language model training which\nenabled high-quality suggestion prediction, and constructed novel serving\ninfrastructure for high-throughput and real-time inference. Experimental\nresults show the effectiveness of our proposed system design and deployment\napproach. This system is currently being served in Gmail.", "published": "2019-05-17 07:58:44", "link": "http://arxiv.org/abs/1906.00080v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Deep Unified Multimodal Embeddings for Understanding both Content and\n  Users in Social Media Networks", "abstract": "There has been an explosion of multimodal content generated on social media\nnetworks in the last few years, which has necessitated a deeper understanding\nof social media content and user behavior. We present a novel\ncontent-independent content-user-reaction model for social multimedia content\nanalysis. Compared to prior works that generally tackle semantic content\nunderstanding and user behavior modeling in isolation, we propose a generalized\nsolution to these problems within a unified framework. We embed users, images\nand text drawn from open social media in a common multimodal geometric space,\nusing a novel loss function designed to cope with distant and disparate\nmodalities, and thereby enable seamless three-way retrieval. Our model not only\noutperforms unimodal embedding based methods on cross-modal retrieval tasks but\nalso shows improvements stemming from jointly solving the two tasks on Twitter\ndata. We also show that the user embeddings learned within our joint multimodal\nembedding model are better at predicting user interests compared to those\nlearned with unimodal content on Instagram data. Our framework thus goes beyond\nthe prior practice of using explicit leader-follower link information to\nestablish affiliations by extracting implicit content-centric affiliations from\nisolated users. We provide qualitative results to show that the user clusters\nemerging from learned embeddings have consistent semantics and the ability of\nour model to discover fine-grained semantics from noisy and unstructured data.\nOur work reveals that social multimodal content is inherently multimodal and\npossesses a consistent structure because in social networks meaning is created\nthrough interactions between users and content.", "published": "2019-05-17 01:16:15", "link": "http://arxiv.org/abs/1905.07075v3", "categories": ["cs.IR", "cs.CL", "cs.CV", "cs.SI"], "primary_category": "cs.IR"}
{"title": "End-to-end Adaptation with Backpropagation through WFST for On-device\n  Speech Recognition System", "abstract": "An on-device DNN-HMM speech recognition system efficiently works with a\nlimited vocabulary in the presence of a variety of predictable noise. In such a\ncase, vocabulary and environment adaptation is highly effective. In this paper,\nwe propose a novel method of end-to-end (E2E) adaptation, which adjusts not\nonly an acoustic model (AM) but also a weighted finite-state transducer (WFST).\nWe convert a pretrained WFST to a trainable neural network and adapt the system\nto target environments/vocabulary by E2E joint training with an AM. We\nreplicate Viterbi decoding with forward--backward neural network computation,\nwhich is similar to recurrent neural networks (RNNs). By pooling output score\nsequences, a vocabulary posterior for each utterance is obtained and used for\ndiscriminative loss computation. Experiments using 2--10 hours of\nEnglish/Japanese adaptation datasets indicate that the fine-tuning of only\nWFSTs and that of only AMs are both comparable to a state-of-the-art adaptation\nmethod, and E2E joint training of the two components achieves the best\nrecognition performance. We also adapt each language system to the other\nlanguage using the adaptation data, and the results show that the proposed\nmethod also works well for language adaptations.", "published": "2019-05-17 07:49:33", "link": "http://arxiv.org/abs/1905.07149v3", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Distant Learning for Entity Linking with Automatic Noise Detection", "abstract": "Accurate entity linkers have been produced for domains and languages where\nannotated data (i.e., texts linked to a knowledge base) is available. However,\nlittle progress has been made for the settings where no or very limited amounts\nof labeled data are present (e.g., legal or most scientific domains). In this\nwork, we show how we can learn to link mentions without having any labeled\nexamples, only a knowledge base and a collection of unannotated texts from the\ncorresponding domain. In order to achieve this, we frame the task as a\nmulti-instance learning problem and rely on surface matching to create initial\nnoisy labels. As the learning signal is weak and our surrogate labels are\nnoisy, we introduce a noise detection component in our model: it lets the model\ndetect and disregard examples which are likely to be noisy. Our method, jointly\nlearning to detect noise and link entities, greatly outperforms the surface\nmatching baseline. For a subset of entity categories, it even approaches the\nperformance of supervised learning.", "published": "2019-05-17 10:49:47", "link": "http://arxiv.org/abs/1905.07189v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CHiVE: Varying Prosody in Speech Synthesis with a Linguistically Driven\n  Dynamic Hierarchical Conditional Variational Network", "abstract": "The prosodic aspects of speech signals produced by current text-to-speech\nsystems are typically averaged over training material, and as such lack the\nvariety and liveliness found in natural speech. To avoid monotony and averaged\nprosody contours, it is desirable to have a way of modeling the variation in\nthe prosodic aspects of speech, so audio signals can be synthesized in multiple\nways for a given text. We present a new, hierarchically structured conditional\nvariational autoencoder to generate prosodic features (fundamental frequency,\nenergy and duration) suitable for use with a vocoder or a generative model like\nWaveNet. At inference time, an embedding representing the prosody of a sentence\nmay be sampled from the variational layer to allow for prosodic variation. To\nefficiently capture the hierarchical nature of the linguistic input (words,\nsyllables and phones), both the encoder and decoder parts of the auto-encoder\nare hierarchical, in line with the linguistic structure, with layers being\nclocked dynamically at the respective rates. We show in our experiments that\nour dynamic hierarchical network outperforms a non-hierarchical\nstate-of-the-art baseline, and, additionally, that prosody transfer across\nsentences is possible by employing the prosody embedding of one sentence to\ngenerate the speech signal of another.", "published": "2019-05-17 11:03:58", "link": "http://arxiv.org/abs/1905.07195v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Don't Blame Distributional Semantics if it can't do Entailment", "abstract": "Distributional semantics has had enormous empirical success in Computational\nLinguistics and Cognitive Science in modeling various semantic phenomena, such\nas semantic similarity, and distributional models are widely used in\nstate-of-the-art Natural Language Processing systems. However, the theoretical\nstatus of distributional semantics within a broader theory of language and\ncognition is still unclear: What does distributional semantics model? Can it\nbe, on its own, a fully adequate model of the meanings of linguistic\nexpressions? The standard answer is that distributional semantics is not fully\nadequate in this regard, because it falls short on some of the central aspects\nof formal semantic approaches: truth conditions, entailment, reference, and\ncertain aspects of compositionality. We argue that this standard answer rests\non a misconception: These aspects do not belong in a theory of expression\nmeaning, they are instead aspects of speaker meaning, i.e., communicative\nintentions in a particular context. In a slogan: words do not refer, speakers\ndo. Clearing this up enables us to argue that distributional semantics on its\nown is an adequate model of expression meaning. Our proposal sheds light on the\nrole of distributional semantics in a broader theory of language and cognition,\nits relationship to formal semantics, and its place in computational models.", "published": "2019-05-17 16:26:05", "link": "http://arxiv.org/abs/1905.07356v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Functorial Question Answering", "abstract": "Distributional compositional (DisCo) models are functors that compute the\nmeaning of a sentence from the meaning of its words. We show that DisCo models\nin the category of sets and relations correspond precisely to relational\ndatabases. As a consequence, we get complexity-theoretic reductions from\nsemantics and entailment of a fragment of natural language to evaluation and\ncontainment of conjunctive queries, respectively. Finally, we define question\nanswering as an NP-complete problem.", "published": "2019-05-17 15:23:39", "link": "http://arxiv.org/abs/1905.07408v3", "categories": ["cs.CL", "cs.DB", "cs.LO", "math.CT"], "primary_category": "cs.CL"}
{"title": "The Unexpected Unexpected and the Expected Unexpected: How People's\n  Conception of the Unexpected is Not That Unexpected", "abstract": "The answers people give when asked to 'think of the unexpected' for everyday\nevent scenarios appear to be more expected than unexpected. There are expected\nunexpected outcomes that closely adhere to the given information in a scenario,\nbased on familiar disruptions and common plan-failures. There are also\nunexpected unexpected outcomes that are more inventive, that depart from given\ninformation, adding new concepts/actions. However, people seem to tend to\nconceive of the unexpected as the former more than the latter. Study 1 tests\nthese proposals by analysing the object-concepts people mention in their\nreports of the unexpected and the agreement between their answers. Study 2\nshows that object-choices are weakly influenced by recency, the order of\nsentences in the scenario. The implications of these results for ideas in\nphilosophy, psychology and computing is discussed", "published": "2019-05-17 10:14:07", "link": "http://arxiv.org/abs/1905.08063v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "The Audio Auditor: User-Level Membership Inference in Internet of Things\n  Voice Services", "abstract": "With the rapid development of deep learning techniques, the popularity of\nvoice services implemented on various Internet of Things (IoT) devices is ever\nincreasing. In this paper, we examine user-level membership inference in the\nproblem space of voice services, by designing an audio auditor to verify\nwhether a specific user had unwillingly contributed audio used to train an\nautomatic speech recognition (ASR) model under strict black-box access. With\nuser representation of the input audio data and their corresponding translated\ntext, our trained auditor is effective in user-level audit. We also observe\nthat the auditor trained on specific data can be generalized well regardless of\nthe ASR model architecture. We validate the auditor on ASR models trained with\nLSTM, RNNs, and GRU algorithms on two state-of-the-art pipelines, the hybrid\nASR system and the end-to-end ASR system. Finally, we conduct a real-world\ntrial of our auditor on iPhone Siri, achieving an overall accuracy exceeding\n80\\%. We hope the methodology developed in this paper and findings can inform\nprivacy advocates to overhaul IoT privacy.", "published": "2019-05-17 01:35:26", "link": "http://arxiv.org/abs/1905.07082v6", "categories": ["cs.CR", "cs.SD", "eess.AS"], "primary_category": "cs.CR"}
{"title": "Weakly-Supervised Temporal Localization via Occurrence Count Learning", "abstract": "We propose a novel model for temporal detection and localization which allows\nthe training of deep neural networks using only counts of event occurrences as\ntraining labels. This powerful weakly-supervised framework alleviates the\nburden of the imprecise and time-consuming process of annotating event\nlocations in temporal data. Unlike existing methods, in which localization is\nexplicitly achieved by design, our model learns localization implicitly as a\nbyproduct of learning to count instances. This unique feature is a direct\nconsequence of the model's theoretical properties. We validate the\neffectiveness of our approach in a number of experiments (drum hit and piano\nonset detection in audio, digit detection in images) and demonstrate\nperformance comparable to that of fully-supervised state-of-the-art methods,\ndespite much weaker training requirements.", "published": "2019-05-17 14:37:50", "link": "http://arxiv.org/abs/1905.07293v1", "categories": ["cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A comprehensive study of speech separation: spectrogram vs waveform\n  separation", "abstract": "Speech separation has been studied widely for single-channel close-talk\nmicrophone recordings over the past few years; developed solutions are mostly\nin frequency-domain. Recently, a raw audio waveform separation network (TasNet)\nis introduced for single-channel data, with achieving high Si-SNR\n(scale-invariant source-to-noise ratio) and SDR (source-to-distortion ratio)\ncomparing against the state-of-the-art solution in frequency-domain. In this\nstudy, we incorporate effective components of the TasNet into a\nfrequency-domain separation method. We compare both for alternative scenarios.\nWe introduce a solution for directly optimizing the separation criterion in\nfrequency-domain networks. In addition to speech separation objective and\nsubjective measurements, we evaluate the separation performance on a speech\nrecognition task as well. We study the speech separation problem for far-field\ndata (more similar to naturalistic audio streams) and develop multi-channel\nsolutions for both frequency and time-domain separators with utilizing\nspectral, spatial and speaker location information. For our experiments, we\nsimulated multi-channel spatialized reverberate WSJ0-2mix dataset. Our\nexperimental results show that spectrogram separation can achieve competitive\nperformance with better network design. Multi-channel framework as well is\nshown to improve the single-channel performance relatively up to +35.5% and\n+46% in terms of WER and SDR, respectively.", "published": "2019-05-17 22:54:08", "link": "http://arxiv.org/abs/1905.07497v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Dance Hit Song Prediction", "abstract": "Record companies invest billions of dollars in new talent around the globe\neach year. Gaining insight into what actually makes a hit song would provide\ntremendous benefits for the music industry. In this research we tackle this\nquestion by focussing on the dance hit song classification problem. A database\nof dance hit songs from 1985 until 2013 is built, including basic musical\nfeatures, as well as more advanced features that capture a temporal aspect. A\nnumber of different classifiers are used to build and test dance hit prediction\nmodels. The resulting best model has a good performance when predicting whether\na song is a \"top 10\" dance hit versus a lower listed position.", "published": "2019-05-17 17:01:10", "link": "http://arxiv.org/abs/1905.08076v1", "categories": ["cs.SD", "cs.IR", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
