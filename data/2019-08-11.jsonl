{"title": "TAPER: Time-Aware Patient EHR Representation", "abstract": "Effective representation learning of electronic health records is a\nchallenging task and is becoming more important as the availability of such\ndata is becoming pervasive. The data contained in these records are irregular\nand contain multiple modalities such as notes, and medical codes. They are\npreempted by medical conditions the patient may have, and are typically jotted\ndown by medical staff. Accompanying codes are notes containing valuable\ninformation about patients beyond the structured information contained in\nelectronic health records. We use transformer networks and the recently\nproposed BERT language model to embed these data streams into a unified vector\nrepresentation. The presented approach effectively encodes a patient's visit\ndata into a single distributed representation, which can be used for downstream\ntasks. Our model demonstrates superior performance and generalization on\nmortality, readmission and length of stay tasks using the publicly available\nMIMIC-III ICU dataset. Code avaialble at\nhttps://github.com/sajaddarabi/TAPER-EHR", "published": "2019-08-11 23:15:23", "link": "http://arxiv.org/abs/1908.03971v4", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Emotion Dependent Facial Animation from Affective Speech", "abstract": "In human-to-computer interaction, facial animation in synchrony with\naffective speech can deliver more naturalistic conversational agents. In this\npaper, we present a two-stage deep learning approach for affective speech\ndriven facial shape animation. In the first stage, we classify affective speech\ninto seven emotion categories. In the second stage, we train separate deep\nestimators within each emotion category to synthesize facial shape from the\naffective speech. Objective and subjective evaluations are performed over the\nSAVEE dataset. The proposed emotion dependent facial shape model performs\nbetter in terms of the Mean Squared Error (MSE) loss and in generating the\nlandmark animations, as compared to training a universal model regardless of\nthe emotion.", "published": "2019-08-11 13:15:18", "link": "http://arxiv.org/abs/1908.03904v1", "categories": ["eess.AS", "cs.MM", "cs.SD"], "primary_category": "eess.AS"}
