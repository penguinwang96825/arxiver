{"title": "Predicting the Effectiveness of Self-Training: Application to Sentiment\n  Classification", "abstract": "The goal of this paper is to investigate the connection between the\nperformance gain that can be obtained by selftraining and the similarity\nbetween the corpora used in this approach. Self-training is a semi-supervised\ntechnique designed to increase the performance of machine learning algorithms\nby automatically classifying instances of a task and adding these as additional\ntraining material to the same classifier. In the context of language processing\ntasks, this training material is mostly an (annotated) corpus. Unfortunately\nself-training does not always lead to a performance increase and whether it\nwill is largely unpredictable. We show that the similarity between corpora can\nbe used to identify those setups for which self-training can be beneficial. We\nconsider this research as a step in the process of developing a classifier that\nis able to adapt itself to each new test corpus that it is presented with.", "published": "2016-01-13 15:55:36", "link": "http://arxiv.org/abs/1601.03288v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Political Speech Generation", "abstract": "In this report we present a system that can generate political speeches for a\ndesired political party. Furthermore, the system allows to specify whether a\nspeech should hold a supportive or opposing opinion. The system relies on a\ncombination of several state-of-the-art NLP methods which are discussed in this\nreport. These include n-grams, Justeson & Katz POS tag filter, recurrent neural\nnetworks, and latent Dirichlet allocation. Sequences of words are generated\nbased on probabilities obtained from two underlying models: A language model\ntakes care of the grammatical correctness while a topic model aims for textual\nconsistency. Both models were trained on the Convote dataset which contains\ntranscripts from US congressional floor debates. Furthermore, we present a\nmanual and an automated approach to evaluate the quality of generated speeches.\nIn an experimental evaluation generated speeches have shown very high quality\nin terms of grammatical correctness and sentence transitions.", "published": "2016-01-13 16:58:05", "link": "http://arxiv.org/abs/1601.03313v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Implicit Distortion and Fertility Models for Attention-based\n  Encoder-Decoder NMT Model", "abstract": "Neural machine translation has shown very promising results lately. Most NMT\nmodels follow the encoder-decoder framework. To make encoder-decoder models\nmore flexible, attention mechanism was introduced to machine translation and\nalso other tasks like speech recognition and image captioning. We observe that\nthe quality of translation by attention-based encoder-decoder can be\nsignificantly damaged when the alignment is incorrect. We attribute these\nproblems to the lack of distortion and fertility models. Aiming to resolve\nthese problems, we propose new variations of attention-based encoder-decoder\nand compare them with other models on machine translation. Our proposed method\nachieved an improvement of 2 BLEU points over the original attention-based\nencoder-decoder.", "published": "2016-01-13 17:14:01", "link": "http://arxiv.org/abs/1601.03317v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EvoGrader: an online formative assessment tool for automatically\n  evaluating written evolutionary explanations", "abstract": "EvoGrader is a free, online, on-demand formative assessment service designed\nfor use in undergraduate biology classrooms. EvoGrader's web portal is powered\nby Amazon's Elastic Cloud and run with LightSIDE Lab's open-source\nmachine-learning tools. The EvoGrader web portal allows biology instructors to\nupload a response file (.csv) containing unlimited numbers of evolutionary\nexplanations written in response to 86 different ACORNS (Assessing COntextual\nReasoning about Natural Selection) instrument items. The system automatically\nanalyzes the responses and provides detailed information about the scientific\nand naive concepts contained within each student's response, as well as overall\nstudent (and sample) reasoning model types. Graphs and visual models provided\nby EvoGrader summarize class-level responses; downloadable files of raw scores\n(in .csv format) are also provided for more detailed analyses. Although the\ncomputational machinery that EvoGrader employs is complex, using the system is\neasy. Users only need to know how to use spreadsheets to organize student\nresponses, upload files to the web, and use a web browser. A series of\nexperiments using new samples of 2,200 written evolutionary explanations\ndemonstrate that EvoGrader scores are comparable to those of trained human\nraters, although EvoGrader scoring takes 99% less time and is free. EvoGrader\nwill be of interest to biology instructors teaching large classes who seek to\nemphasize scientific practices such as generating scientific explanations, and\nto teach crosscutting ideas such as evolution and natural selection. The\nsoftware architecture of EvoGrader is described as it may serve as a template\nfor developing machine-learning portals for other core concepts within biology\nand across other disciplines.", "published": "2016-01-13 18:59:06", "link": "http://arxiv.org/abs/1601.03348v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The scarcity of crossing dependencies: a direct outcome of a specific\n  constraint?", "abstract": "The structure of a sentence can be represented as a network where vertices\nare words and edges indicate syntactic dependencies. Interestingly, crossing\nsyntactic dependencies have been observed to be infrequent in human languages.\nThis leads to the question of whether the scarcity of crossings in languages\narises from an independent and specific constraint on crossings. We provide\nstatistical evidence suggesting that this is not the case, as the proportion of\ndependency crossings of sentences from a wide range of languages can be\naccurately estimated by a simple predictor based on a null hypothesis on the\nlocal probability that two dependencies cross given their lengths. The relative\nerror of this predictor never exceeds 5% on average, whereas the error of a\nbaseline predictor assuming a random ordering of the words of a sentence is at\nleast 6 times greater. Our results suggest that the low frequency of crossings\nin natural languages is neither originated by hidden knowledge of language nor\nby the undesirability of crossings per se, but as a mere side effect of the\nprinciple of dependency length minimization.", "published": "2016-01-13 11:48:25", "link": "http://arxiv.org/abs/1601.03210v3", "categories": ["cs.CL", "cs.SI", "physics.soc-ph"], "primary_category": "cs.CL"}
