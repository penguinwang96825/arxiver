{"title": "Agreement Tracking for Multi-Issue Negotiation Dialogues", "abstract": "Automated negotiation support systems aim to help human negotiators reach\nmore favorable outcomes in multi-issue negotiations (e.g., an employer and a\ncandidate negotiating over issues such as salary, hours, and promotions before\na job offer). To be successful, these systems must accurately track agreements\nreached by participants in real-time. Existing approaches either focus on\ntask-oriented dialogues or produce unstructured outputs, rendering them\nunsuitable for this objective. Our work introduces the novel task of agreement\ntracking for two-party multi-issue negotiations, which requires continuous\nmonitoring of agreements within a structured state space. To address the\nscarcity of annotated corpora with realistic multi-issue negotiation dialogues,\nwe use GPT-3 to build GPT-Negochat, a synthesized dataset that we make publicly\navailable. We present a strong initial baseline for our task by\ntransfer-learning a T5 model trained on the MultiWOZ 2.4 corpus. Pre-training\nT5-small and T5-base on MultiWOZ 2.4's DST task enhances results by 21% and 9%\nrespectively over training solely on GPT-Negochat. We validate our method's\nsample-efficiency via smaller training subset experiments. By releasing\nGPT-Negochat and our baseline models, we aim to encourage further research in\nmulti-issue negotiation dialogue agreement tracking.", "published": "2023-07-13 02:00:27", "link": "http://arxiv.org/abs/2307.06524v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Intent-calibrated Self-training for Answer Selection in Open-domain\n  Dialogues", "abstract": "Answer selection in open-domain dialogues aims to select an accurate answer\nfrom candidates. Recent success of answer selection models hinges on training\nwith large amounts of labeled data. However, collecting large-scale labeled\ndata is labor-intensive and time-consuming. In this paper, we introduce the\npredicted intent labels to calibrate answer labels in a self-training paradigm.\nSpecifically, we propose the intent-calibrated self-training (ICAST) to improve\nthe quality of pseudo answer labels through the intent-calibrated answer\nselection paradigm, in which we employ pseudo intent labels to help improve\npseudo answer labels. We carry out extensive experiments on two benchmark\ndatasets with open-domain dialogues. The experimental results show that ICAST\noutperforms baselines consistently with 1%, 5% and 10% labeled data.\nSpecifically, it improves 2.06% and 1.00% of F1 score on the two datasets,\ncompared with the strongest baseline with only 5% labeled data.", "published": "2023-07-13 12:02:51", "link": "http://arxiv.org/abs/2307.06703v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tackling Fake News in Bengali: Unraveling the Impact of Summarization\n  vs. Augmentation on Pre-trained Language Models", "abstract": "With the rise of social media and online news sources, fake news has become a\nsignificant issue globally. However, the detection of fake news in low resource\nlanguages like Bengali has received limited attention in research. In this\npaper, we propose a methodology consisting of four distinct approaches to\nclassify fake news articles in Bengali using summarization and augmentation\ntechniques with five pre-trained language models. Our approach includes\ntranslating English news articles and using augmentation techniques to curb the\ndeficit of fake news articles. Our research also focused on summarizing the\nnews to tackle the token length limitation of BERT based models. Through\nextensive experimentation and rigorous evaluation, we show the effectiveness of\nsummarization and augmentation in the case of Bengali fake news detection. We\nevaluated our models using three separate test datasets. The BanglaBERT Base\nmodel, when combined with augmentation techniques, achieved an impressive\naccuracy of 96% on the first test dataset. On the second test dataset, the\nBanglaBERT model, trained with summarized augmented news articles achieved 97%\naccuracy. Lastly, the mBERT Base model achieved an accuracy of 86% on the third\ntest dataset which was reserved for generalization performance evaluation. The\ndatasets and implementations are available at\nhttps://github.com/arman-sakif/Bengali-Fake-News-Detection", "published": "2023-07-13 14:50:55", "link": "http://arxiv.org/abs/2307.06979v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Revisiting the DARPA Communicator Data using Conversation Analysis", "abstract": "The state of the art in human computer conversation leaves something to be\ndesired and, indeed, talking to a computer can be down-right annoying. This\npaper describes an approach to identifying ``opportunities for improvement'' in\nthese systems by looking for abuse in the form of swear words. The premise is\nthat humans swear at computers as a sanction and, as such, swear words\nrepresent a point of failure where the system did not behave as it should.\nHaving identified where things went wrong, we can work backward through the\ntranscripts and, using conversation analysis (CA) work out how things went\nwrong. Conversation analysis is a qualitative methodology and can appear quite\nalien - indeed unscientific - to those of us from a quantitative background.\nThe paper starts with a description of Conversation analysis in its modern\nform, and then goes on to apply the methodology to transcripts of frustrated\nand annoyed users in the DARPA Communicator project. The conclusion is that\nthere is at least one species of failure caused by the inability of the\nCommunicator systems to handle mixed initiative at the discourse structure\nlevel. Along the way, I hope to demonstrate that there is an alternative future\nfor computational linguistics that does not rely on larger and larger text\ncorpora.", "published": "2023-07-13 15:33:01", "link": "http://arxiv.org/abs/2307.06982v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Electoral Agitation Data Set: The Use Case of the Polish Election", "abstract": "The popularity of social media makes politicians use it for political\nadvertisement. Therefore, social media is full of electoral agitation\n(electioneering), especially during the election campaigns. The election\nadministration cannot track the spread and quantity of messages that count as\nagitation under the election code. It addresses a crucial problem, while also\nuncovering a niche that has not been effectively targeted so far. Hence, we\npresent the first publicly open data set for detecting electoral agitation in\nthe Polish language. It contains 6,112 human-annotated tweets tagged with four\nlegally conditioned categories. We achieved a 0.66 inter-annotator agreement\n(Cohen's kappa score). An additional annotator resolved the mismatches between\nthe first two improving the consistency and complexity of the annotation\nprocess. The newly created data set was used to fine-tune a Polish Language\nModel called HerBERT (achieving a 68% F1 score). We also present a number of\npotential use cases for such data sets and models, enriching the paper with an\nanalysis of the Polish 2020 Presidential Election on Twitter.", "published": "2023-07-13 18:14:43", "link": "http://arxiv.org/abs/2307.07007v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Data Augmentation for Machine Translation via Dependency Subtree\n  Swapping", "abstract": "We present a generic framework for data augmentation via dependency subtree\nswapping that is applicable to machine translation. We extract corresponding\nsubtrees from the dependency parse trees of the source and target sentences and\nswap these across bisentences to create augmented samples. We perform thorough\nfiltering based on graphbased similarities of the dependency trees and\nadditional heuristics to ensure that extracted subtrees correspond to the same\nmeaning. We conduct resource-constrained experiments on 4 language pairs in\nboth directions using the IWSLT text translation datasets and the Hunglish2\ncorpus. The results demonstrate consistent improvements in BLEU score over our\nbaseline models in 3 out of 4 language pairs. Our code is available on GitHub.", "published": "2023-07-13 19:00:26", "link": "http://arxiv.org/abs/2307.07025v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Does Collaborative Human-LM Dialogue Generation Help Information\n  Extraction from Human Dialogues?", "abstract": "The capabilities of pretrained language models have opened opportunities to\nexplore new application areas, but applications involving human-human\ninteraction are limited by the fact that most data is protected from public\nrelease for privacy reasons. Problem-solving human dialogues in real\napplications can be much more complex than existing Wizard-of-Oz collections,\npreventing successful domain transfer. To support information extraction (IE)\nfor a private call center dataset, we introduce a human-in-the-loop dialogue\ngeneration framework capable of synthesizing realistic dialogues. In IE\nexperiments with auto insurance call center dialogues, we observe 25\\% relative\nimprovement in $F_1$ after augmenting a small set of real human conversations\nwith synthetic data. We release code and our synthetic dataset to illustrate\nthe complexity of real-world call center conversations and encourage\ndevelopment of complex dialogue datasets that are more representative of\nnatural data.", "published": "2023-07-13 20:02:50", "link": "http://arxiv.org/abs/2307.07047v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MegaWika: Millions of reports and their sources across 50 diverse\n  languages", "abstract": "To foster the development of new models for collaborative AI-assisted report\ngeneration, we introduce MegaWika, consisting of 13 million Wikipedia articles\nin 50 diverse languages, along with their 71 million referenced source\nmaterials. We process this dataset for a myriad of applications, going beyond\nthe initial Wikipedia citation extraction and web scraping of content,\nincluding translating non-English articles for cross-lingual applications and\nproviding FrameNet parses for automated semantic analysis. MegaWika is the\nlargest resource for sentence-level report generation and the only report\ngeneration dataset that is multilingual. We manually analyze the quality of\nthis resource through a semantically stratified sample. Finally, we provide\nbaseline results and trained models for crucial steps in automated report\ngeneration: cross-lingual question answering and citation retrieval.", "published": "2023-07-13 20:04:02", "link": "http://arxiv.org/abs/2307.07049v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "National Origin Discrimination in Deep-learning-powered Automated Resume\n  Screening", "abstract": "Many companies and organizations have started to use some form of AIenabled\nauto mated tools to assist in their hiring process, e.g. screening resumes,\ninterviewing candi dates, performance evaluation. While those AI tools have\ngreatly improved human re source operations efficiency and provided\nconveniences to job seekers as well, there are increasing concerns on unfair\ntreatment to candidates, caused by underlying bias in AI systems. Laws around\nequal opportunity and fairness, like GDPR, CCPA, are introduced or under\ndevelopment, in attempt to regulate AI. However, it is difficult to implement\nAI regulations in practice, as technologies are constantly advancing and the\nrisk perti nent to their applications can fail to be recognized. This study\nexamined deep learning methods, a recent technology breakthrough, with focus on\ntheir application to automated resume screening. One impressive performance of\ndeep learning methods is the represen tation of individual words as\nlowdimensional numerical vectors, called word embedding, which are learned from\naggregated global wordword cooccurrence statistics from a cor pus, like\nWikipedia or Google news. The resulting word representations possess interest\ning linear substructures of the word vector space and have been widely used in\ndown stream tasks, like resume screening. However, word embedding inherits and\nreinforces the stereotyping from the training corpus, as deep learning models\nessentially learn a probability distribution of words and their relations from\nhistory data. Our study finds out that if we rely on such deeplearningpowered\nautomated resume screening tools, it may lead to decisions favoring or\ndisfavoring certain demographic groups and raise eth ical, even legal,\nconcerns. To address the issue, we developed bias mitigation method. Extensive\nexperiments on real candidate resumes are conducted to validate our study", "published": "2023-07-13 01:35:29", "link": "http://arxiv.org/abs/2307.08624v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ChatGPT and Bard Responses to Polarizing Questions", "abstract": "Recent developments in natural language processing have demonstrated the\npotential of large language models (LLMs) to improve a range of educational and\nlearning outcomes. Of recent chatbots based on LLMs, ChatGPT and Bard have made\nit clear that artificial intelligence (AI) technology will have significant\nimplications on the way we obtain and search for information. However, these\ntools sometimes produce text that is convincing, but often incorrect, known as\nhallucinations. As such, their use can distort scientific facts and spread\nmisinformation. To counter polarizing responses on these tools, it is critical\nto provide an overview of such responses so stakeholders can determine which\ntopics tend to produce more contentious responses -- key to developing targeted\nregulatory policy and interventions. In addition, there currently exists no\nannotated dataset of ChatGPT and Bard responses around possibly polarizing\ntopics, central to the above aims. We address the indicated issues through the\nfollowing contribution: Focusing on highly polarizing topics in the US, we\ncreated and described a dataset of ChatGPT and Bard responses. Broadly, our\nresults indicated a left-leaning bias for both ChatGPT and Bard, with Bard more\nlikely to provide responses around polarizing topics. Bard seemed to have fewer\nguardrails around controversial topics, and appeared more willing to provide\ncomprehensive, and somewhat human-like responses. Bard may thus be more likely\nabused by malicious actors. Stakeholders may utilize our findings to mitigate\nmisinformative and/or polarizing responses from LLMs", "published": "2023-07-13 14:45:47", "link": "http://arxiv.org/abs/2307.12402v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Convolutional Neural Networks for Sentiment Analysis on Weibo Data: A\n  Natural Language Processing Approach", "abstract": "This study addressed the complex task of sentiment analysis on a dataset of\n119,988 original tweets from Weibo using a Convolutional Neural Network (CNN),\noffering a new approach to Natural Language Processing (NLP). The data, sourced\nfrom Baidu's PaddlePaddle AI platform, were meticulously preprocessed,\ntokenized, and categorized based on sentiment labels. A CNN-based model was\nutilized, leveraging word embeddings for feature extraction, and trained to\nperform sentiment classification. The model achieved a macro-average F1-score\nof approximately 0.73 on the test set, showing balanced performance across\npositive, neutral, and negative sentiments. The findings underscore the\neffectiveness of CNNs for sentiment analysis tasks, with implications for\npractical applications in social media analysis, market research, and policy\nstudies. The complete experimental content and code have been made publicly\navailable on the Kaggle data platform for further research and development.\nFuture work may involve exploring different architectures, such as Recurrent\nNeural Networks (RNN) or transformers, or using more complex pre-trained models\nlike BERT, to further improve the model's ability to understand linguistic\nnuances and context.", "published": "2023-07-13 03:02:56", "link": "http://arxiv.org/abs/2307.06540v1", "categories": ["cs.CL", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Going Beyond Local: Global Graph-Enhanced Personalized News\n  Recommendations", "abstract": "Precisely recommending candidate news articles to users has always been a\ncore challenge for personalized news recommendation systems. Most recent works\nprimarily focus on using advanced natural language processing techniques to\nextract semantic information from rich textual data, employing content-based\nmethods derived from local historical news. However, this approach lacks a\nglobal perspective, failing to account for users' hidden motivations and\nbehaviors beyond semantic information. To address this challenge, we propose a\nnovel model called GLORY (Global-LOcal news Recommendation sYstem), which\ncombines global representations learned from other users with local\nrepresentations to enhance personalized recommendation systems. We accomplish\nthis by constructing a Global-aware Historical News Encoder, which includes a\nglobal news graph and employs gated graph neural networks to enrich news\nrepresentations, thereby fusing historical news representations by a historical\nnews aggregator. Similarly, we extend this approach to a Global Candidate News\nEncoder, utilizing a global entity graph and a candidate news aggregator to\nenhance candidate news representation. Evaluation results on two public news\ndatasets demonstrate that our method outperforms existing approaches.\nFurthermore, our model offers more diverse recommendations.", "published": "2023-07-13 06:25:22", "link": "http://arxiv.org/abs/2307.06576v5", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "To share or not to share: What risks would laypeople accept to give\n  sensitive data to differentially-private NLP systems?", "abstract": "Although the NLP community has adopted central differential privacy as a\ngo-to framework for privacy-preserving model training or data sharing, the\nchoice and interpretation of the key parameter, privacy budget $\\varepsilon$\nthat governs the strength of privacy protection, remains largely arbitrary. We\nargue that determining the $\\varepsilon$ value should not be solely in the\nhands of researchers or system developers, but must also take into account the\nactual people who share their potentially sensitive data. In other words: Would\nyou share your instant messages for $\\varepsilon$ of 10? We address this\nresearch gap by designing, implementing, and conducting a behavioral experiment\n(311 lay participants) to study the behavior of people in uncertain\ndecision-making situations with respect to privacy-threatening situations.\nFraming the risk perception in terms of two realistic NLP scenarios and using a\nvignette behavioral study help us determine what $\\varepsilon$ thresholds would\nlead lay people to be willing to share sensitive textual data - to our\nknowledge, the first study of its kind.", "published": "2023-07-13 12:06:48", "link": "http://arxiv.org/abs/2307.06708v2", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Unsupervised Calibration through Prior Adaptation for Text\n  Classification using Large Language Models", "abstract": "A wide variety of natural language tasks are currently being addressed with\nlarge-scale language models (LLMs). These models are usually trained with a\nvery large amount of unsupervised text data and adapted to perform a downstream\nnatural language task using methods like fine-tuning, calibration or in-context\nlearning. In this work, we propose an approach to adapt the prior class\ndistribution to perform text classification tasks without the need for labelled\nsamples and only few in-domain sample queries. The proposed approach treats the\nLLM as a black box, adding a stage where the model posteriors are calibrated to\nthe task. Results show that these methods outperform the un-adapted model for\ndifferent number of training shots in the prompt and a previous approach were\ncalibration is performed without using any adaptation data.", "published": "2023-07-13 12:11:36", "link": "http://arxiv.org/abs/2307.06713v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Why Guided Dialog Policy Learning performs well? Understanding the role\n  of adversarial learning and its alternative", "abstract": "Dialog policies, which determine a system's action based on the current state\nat each dialog turn, are crucial to the success of the dialog. In recent years,\nreinforcement learning (RL) has emerged as a promising option for dialog policy\nlearning (DPL). In RL-based DPL, dialog policies are updated according to\nrewards. The manual construction of fine-grained rewards, such as\nstate-action-based ones, to effectively guide the dialog policy is challenging\nin multi-domain task-oriented dialog scenarios with numerous state-action pair\ncombinations. One way to estimate rewards from collected data is to train the\nreward estimator and dialog policy simultaneously using adversarial learning\n(AL). Although this method has demonstrated superior performance\nexperimentally, it is fraught with the inherent problems of AL, such as mode\ncollapse. This paper first identifies the role of AL in DPL through detailed\nanalyses of the objective functions of dialog policy and reward estimator.\nNext, based on these analyses, we propose a method that eliminates AL from\nreward estimation and DPL while retaining its advantages. We evaluate our\nmethod using MultiWOZ, a multi-domain task-oriented dialog corpus.", "published": "2023-07-13 12:29:29", "link": "http://arxiv.org/abs/2307.06721v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Negated Complementary Commonsense using Large Language Models", "abstract": "Larger language models, such as GPT-3, have shown to be excellent in many\ntasks. However, we demonstrate that out-of-ordinary questions can throw the\nmodel off guard. This work focuses on finding answers to negated complementary\nquestions in commonsense scenarios. We illustrate how such questions adversely\naffect the model responses. We propose a model-agnostic methodology to improve\nthe performance in negated complementary scenarios. Our method outperforms\nfew-shot generation from GPT-3 (by more than 11 points) and, more importantly,\nhighlights the significance of studying the response of large language models\nin negated complementary questions. The code, data, and experiments are\navailable under: https://github.com/navidre/negated_complementary_commonsense.", "published": "2023-07-13 15:03:48", "link": "http://arxiv.org/abs/2307.06794v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Personalization for BERT-based Discriminative Speech Recognition\n  Rescoring", "abstract": "Recognition of personalized content remains a challenge in end-to-end speech\nrecognition. We explore three novel approaches that use personalized content in\na neural rescoring step to improve recognition: gazetteers, prompting, and a\ncross-attention based encoder-decoder model. We use internal de-identified\nen-US data from interactions with a virtual voice assistant supplemented with\npersonalized named entities to compare these approaches. On a test set with\npersonalized named entities, we show that each of these approaches improves\nword error rate by over 10%, against a neural rescoring baseline. We also show\nthat on this test set, natural language prompts can improve word error rate by\n7% without any training and with a marginal loss in generalization. Overall,\ngazetteers were found to perform the best with a 10% improvement in word error\nrate (WER), while also improving WER on a general test set by 1%.", "published": "2023-07-13 15:54:32", "link": "http://arxiv.org/abs/2307.06832v1", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Effective Prompt Extraction from Language Models", "abstract": "The text generated by large language models is commonly controlled by\nprompting, where a prompt prepended to a user's query guides the model's\noutput. The prompts used by companies to guide their models are often treated\nas secrets, to be hidden from the user making the query. They have even been\ntreated as commodities to be bought and sold on marketplaces. However,\nanecdotal reports have shown adversarial users employing prompt extraction\nattacks to recover these prompts. In this paper, we present a framework for\nsystematically measuring the effectiveness of these attacks. In experiments\nwith 3 different sources of prompts and 11 underlying large language models, we\nfind that simple text-based attacks can in fact reveal prompts with high\nprobability. Our framework determines with high precision whether an extracted\nprompt is the actual secret prompt, rather than a model hallucination. Prompt\nextraction from real systems such as Claude 3 and ChatGPT further suggest that\nsystem prompts can be revealed by an adversary despite existing defenses in\nplace.", "published": "2023-07-13 16:15:08", "link": "http://arxiv.org/abs/2307.06865v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DecompEval: Evaluating Generated Texts as Unsupervised Decomposed\n  Question Answering", "abstract": "Existing evaluation metrics for natural language generation (NLG) tasks face\nthe challenges on generalization ability and interpretability. Specifically,\nmost of the well-performed metrics are required to train on evaluation datasets\nof specific NLG tasks and evaluation dimensions, which may cause over-fitting\nto task-specific datasets. Furthermore, existing metrics only provide an\nevaluation score for each dimension without revealing the evidence to interpret\nhow this score is obtained. To deal with these challenges, we propose a simple\nyet effective metric called DecompEval. This metric formulates NLG evaluation\nas an instruction-style question answering task and utilizes instruction-tuned\npre-trained language models (PLMs) without training on evaluation datasets,\naiming to enhance the generalization ability. To make the evaluation process\nmore interpretable, we decompose our devised instruction-style question about\nthe quality of generated texts into the subquestions that measure the quality\nof each sentence. The subquestions with their answers generated by PLMs are\nthen recomposed as evidence to obtain the evaluation result. Experimental\nresults show that DecompEval achieves state-of-the-art performance in untrained\nmetrics for evaluating text summarization and dialogue generation, which also\nexhibits strong dimension-level / task-level generalization ability and\ninterpretability.", "published": "2023-07-13 16:16:51", "link": "http://arxiv.org/abs/2307.06869v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Generating Benchmarks for Factuality Evaluation of Language Models", "abstract": "Before deploying a language model (LM) within a given domain, it is important\nto measure its tendency to generate factually incorrect information in that\ndomain. Existing methods for factuality evaluation of LLM generation focus on\nfacts sampled from the LM itself, and thus do not control the set of evaluated\nfacts and might under-represent domain specific or rare facts. We propose\nFACTOR: Factual Assessment via Corpus TransfORmation, a scalable approach for\nevaluating LM factuality. FACTOR automatically transforms a factual corpus of\ninterest into a benchmark evaluating an LM's propensity to generate true facts\nfrom the corpus vs. similar but incorrect statements. We use our framework to\ncreate three benchmarks: Wiki-FACTOR, News-FACTOR and Expert-FACTOR. We show\nthat: (i) our benchmark scores increase with model size and improve when the LM\nis augmented with retrieval; (ii) benchmark score and perplexity do not always\nagree on model ranking; (iii) when perplexity and benchmark score disagree, the\nlatter better reflects factuality in open-ended generation, as measured by\nhuman annotators. We make our data and code publicly available in\nhttps://github.com/AI21Labs/factor.", "published": "2023-07-13 17:14:38", "link": "http://arxiv.org/abs/2307.06908v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "mBLIP: Efficient Bootstrapping of Multilingual Vision-LLMs", "abstract": "Modular vision-language models (Vision-LLMs) align pretrained image encoders\nwith (frozen) large language models (LLMs) and post-hoc condition LLMs to\n`understand' the image input. With the abundance of readily available\nhigh-quality English image-text data as well as strong monolingual English\nLLMs, the research focus has been on English-only Vision-LLMs. Multilingual\nvision-language models are still predominantly obtained via expensive\nend-to-end pretraining, resulting in comparatively smaller models, trained on\nlimited multilingual image data supplemented with text-only multilingual\ncorpora. We present mBLIP, the first Vision-LLM leveraging multilingual LLMs,\nwhich we obtain in a computationally efficient manner on consumer-level\nhardware. To this end, we \\textit{re-align} an image encoder previously tuned\nto an English LLM to a new, multilingual LLM using only a few million\nmultilingual training examples derived from a mix of vision-and-language tasks,\nwhich we obtain by machine-translating high-quality English data to 95\nlanguages. On the IGLUE benchmark and XM3600, mBLIP yields results competitive\nwith state-of-the-art models and it greatly outperforms strong English-only\nVision-LLMs like Llava 1.5. We release our model, code, and train data at\n\\url{https://github.com/gregor-ge/mBLIP}.", "published": "2023-07-13 17:51:58", "link": "http://arxiv.org/abs/2307.06930v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Copy Is All You Need", "abstract": "The dominant text generation models compose the output by sequentially\nselecting words from a fixed vocabulary. In this paper, we formulate text\ngeneration as progressively copying text segments (e.g., words or phrases) from\nan existing text collection. We compute the contextualized representations of\nmeaningful text segments and index them using efficient vector search toolkits.\nThe task of text generation is then decomposed into a series of copy-and-paste\noperations: at each time step, we seek suitable text spans from the text\ncollection rather than selecting from a standalone vocabulary. Experiments on\nthe standard language modeling benchmark (WikiText-103) show that our approach\nachieves better generation quality according to both automatic and human\nevaluations. Besides, its inference efficiency is comparable to token-level\nautoregressive models thanks to the reduction of decoding steps. We also show\nthat our approach allows for effective domain adaptation by simply switching to\ndomain-specific text collection without extra training. Finally, we observe\nthat our approach attains additional performance gains by simply scaling up to\nlarger text collections, again without further training.\\footnote{Our source\ncodes are publicly available at\n\\url{https://github.com/gmftbyGMFTBY/Copyisallyouneed}.}", "published": "2023-07-13 05:03:26", "link": "http://arxiv.org/abs/2307.06962v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Classical Out-of-Distribution Detection Methods Benchmark in Text\n  Classification Tasks", "abstract": "State-of-the-art models can perform well in controlled environments, but they\noften struggle when presented with out-of-distribution (OOD) examples, making\nOOD detection a critical component of NLP systems. In this paper, we focus on\nhighlighting the limitations of existing approaches to OOD detection in NLP.\nSpecifically, we evaluated eight OOD detection methods that are easily\nintegrable into existing NLP systems and require no additional OOD data or\nmodel modifications. One of our contributions is providing a well-structured\nresearch environment that allows for full reproducibility of the results.\nAdditionally, our analysis shows that existing OOD detection methods for NLP\ntasks are not yet sufficiently sensitive to capture all samples characterized\nby various types of distributional shifts. Particularly challenging testing\nscenarios arise in cases of background shift and randomly shuffled word order\nwithin in domain texts. This highlights the need for future work to develop\nmore effective OOD detection approaches for the NLP problems, and our work\nprovides a well-defined foundation for further research in this area.", "published": "2023-07-13 18:06:12", "link": "http://arxiv.org/abs/2307.07002v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "An Analysis of Dialogue Repair in Virtual Voice Assistants", "abstract": "Language speakers often use what are known as repair initiators to mend\nfundamental disconnects that occur between them during verbal communication.\nPrevious research in this field has mainly focused on the human-to-human use of\nrepair initiator. We proposed an examination of dialogue repair structure\nwherein the dialogue initiator is human and the party that initiates or\nresponds to the repair is a virtual assistant. This study examined the use of\nrepair initiators in both English and Spanish with two popular assistants,\nGoogle Assistant and Apple's Siri. Our aim was to codify the differences, if\nany, in responses by voice assistants to dialogues in need of repair as\ncompared to human-human dialogues also in need of repair. Ultimately the data\ndemonstrated that not only were there differences between human-assistant and\nhuman-human dialogue repair strategies, but that there were likewise\ndifferences among the assistants and the languages studied.", "published": "2023-07-13 21:57:28", "link": "http://arxiv.org/abs/2307.07076v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "AutoHint: Automatic Prompt Optimization with Hint Generation", "abstract": "This paper presents AutoHint, a novel framework for automatic prompt\nengineering and optimization for Large Language Models (LLM). While LLMs have\ndemonstrated remarkable ability in achieving high-quality annotation in various\ntasks, the key to applying this ability to specific tasks lies in developing\nhigh-quality prompts. Thus we propose a framework to inherit the merits of both\nin-context learning and zero-shot learning by incorporating enriched\ninstructions derived from input-output demonstrations to optimize original\nprompt. We refer to the enrichment as the hint and propose a framework to\nautomatically generate the hint from labeled data. More concretely, starting\nfrom an initial prompt, our method first instructs a LLM to deduce new hints\nfor selected samples from incorrect predictions, and then summarizes from\nper-sample hints and adds the results back to the initial prompt to form a new,\nenriched instruction. The proposed method is evaluated on the BIG-Bench\nInstruction Induction dataset for both zero-shot and few-short prompts, where\nexperiments demonstrate our method is able to significantly boost accuracy for\nmultiple tasks.", "published": "2023-07-13 00:49:27", "link": "http://arxiv.org/abs/2307.07415v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring the Integration of Large Language Models into Automatic Speech\n  Recognition Systems: An Empirical Study", "abstract": "This paper explores the integration of Large Language Models (LLMs) into\nAutomatic Speech Recognition (ASR) systems to improve transcription accuracy.\nThe increasing sophistication of LLMs, with their in-context learning\ncapabilities and instruction-following behavior, has drawn significant\nattention in the field of Natural Language Processing (NLP). Our primary focus\nis to investigate the potential of using an LLM's in-context learning\ncapabilities to enhance the performance of ASR systems, which currently face\nchallenges such as ambient noise, speaker accents, and complex linguistic\ncontexts. We designed a study using the Aishell-1 and LibriSpeech datasets,\nwith ChatGPT and GPT-4 serving as benchmarks for LLM capabilities.\nUnfortunately, our initial experiments did not yield promising results,\nindicating the complexity of leveraging LLM's in-context learning for ASR\napplications. Despite further exploration with varied settings and models, the\ncorrected sentences from the LLMs frequently resulted in higher Word Error\nRates (WER), demonstrating the limitations of LLMs in speech applications. This\npaper provides a detailed overview of these experiments, their results, and\nimplications, establishing that using LLMs' in-context learning capabilities to\ncorrect potential errors in speech recognition transcriptions is still a\nchallenging task at the current stage.", "published": "2023-07-13 02:31:55", "link": "http://arxiv.org/abs/2307.06530v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Parmesan: mathematical concept extraction for education", "abstract": "Mathematics is a highly specialized domain with its own unique set of\nchallenges that has seen limited study in natural language processing. However,\nmathematics is used in a wide variety of fields and multidisciplinary research\nin many different domains often relies on an understanding of mathematical\nconcepts. To aid researchers coming from other fields, we develop a prototype\nsystem for searching for and defining mathematical concepts in context,\nfocusing on the field of category theory. This system, Parmesan, depends on\nnatural language processing components including concept extraction, relation\nextraction, definition extraction, and entity linking. In developing this\nsystem, we show that existing techniques cannot be applied directly to the\ncategory theory domain, and suggest hybrid techniques that do perform well,\nthough we expect the system to evolve over time. We also provide two cleaned\nmathematical corpora that power the prototype system, which are based on\njournal articles and wiki pages, respectively. The corpora have been annotated\nwith dependency trees, lemmas, and part-of-speech tags.", "published": "2023-07-13 11:55:03", "link": "http://arxiv.org/abs/2307.06699v2", "categories": ["cs.CL", "cs.IR", "math.CT"], "primary_category": "cs.CL"}
{"title": "LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT", "abstract": "Knowledge Graphs (KG) provide us with a structured, flexible, transparent,\ncross-system, and collaborative way of organizing our knowledge and data across\nvarious domains in society and industrial as well as scientific disciplines.\nKGs surpass any other form of representation in terms of effectiveness.\nHowever, Knowledge Graph Engineering (KGE) requires in-depth experiences of\ngraph structures, web technologies, existing models and vocabularies, rule\nsets, logic, as well as best practices. It also demands a significant amount of\nwork. Considering the advancements in large language models (LLMs) and their\ninterfaces and applications in recent years, we have conducted comprehensive\nexperiments with ChatGPT to explore its potential in supporting KGE. In this\npaper, we present a selection of these experiments and their results to\ndemonstrate how ChatGPT can assist us in the development and management of KGs.", "published": "2023-07-13 17:31:41", "link": "http://arxiv.org/abs/2307.06917v1", "categories": ["cs.AI", "cs.CL", "cs.DB"], "primary_category": "cs.AI"}
{"title": "In-context Autoencoder for Context Compression in a Large Language Model", "abstract": "We propose the In-context Autoencoder (ICAE), leveraging the power of a large\nlanguage model (LLM) to compress a long context into short compact memory slots\nthat can be directly conditioned on by the LLM for various purposes. ICAE is\nfirst pretrained using both autoencoding and language modeling objectives on\nmassive text data, enabling it to generate memory slots that accurately and\ncomprehensively represent the original context. Then, it is fine-tuned on\ninstruction data for producing desirable responses to various prompts.\nExperiments demonstrate that our lightweight ICAE, introducing about 1%\nadditional parameters, effectively achieves $4\\times$ context compression based\non Llama, offering advantages in both improved latency and GPU memory cost\nduring inference, and showing an interesting insight in memorization as well as\npotential for scalability. These promising results imply a novel perspective on\nthe connection between working memory in cognitive science and representation\nlearning in LLMs, revealing ICAE's significant implications in addressing the\nlong context problem and suggesting further research in LLM context management.\nOur data, code and models are available at https://github.com/getao/icae.", "published": "2023-07-13 17:59:21", "link": "http://arxiv.org/abs/2307.06945v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Retrieval Augmented Generation using Engineering Design Knowledge", "abstract": "Aiming to support Retrieval Augmented Generation (RAG) in the design process,\nwe present a method to identify explicit, engineering design facts - {head\nentity :: relationship :: tail entity} from patented artefact descriptions.\nGiven a sentence with a pair of entities (based on noun phrases) marked in a\nunique manner, our method extracts the relationship that is explicitly\ncommunicated in the sentence. For this task, we create a dataset of 375,084\nexamples and fine-tune language models for relation identification (token\nclassification) and elicitation (sequence-to-sequence). The token\nclassification approach achieves up to 99.7 % accuracy. Upon applying the\nmethod to a domain of 4,870 fan system patents, we populate a knowledge base of\nover 2.93 million facts. Using this knowledge base, we demonstrate how Large\nLanguage Models (LLMs) are guided by explicit facts to synthesise knowledge and\ngenerate technical and cohesive responses when sought out for knowledge\nretrieval tasks in the design process.", "published": "2023-07-13 17:25:28", "link": "http://arxiv.org/abs/2307.06985v10", "categories": ["cs.CL", "cs.DB", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Making the Most Out of the Limited Context Length: Predictive Power\n  Varies with Clinical Note Type and Note Section", "abstract": "Recent advances in large language models have led to renewed interest in\nnatural language processing in healthcare using the free text of clinical\nnotes. One distinguishing characteristic of clinical notes is their long time\nspan over multiple long documents. The unique structure of clinical notes\ncreates a new design choice: when the context length for a language model\npredictor is limited, which part of clinical notes should we choose as the\ninput? Existing studies either choose the inputs with domain knowledge or\nsimply truncate them. We propose a framework to analyze the sections with high\npredictive power. Using MIMIC-III, we show that: 1) predictive power\ndistribution is different between nursing notes and discharge notes and 2)\ncombining different types of notes could improve performance when the context\nlength is large. Our findings suggest that a carefully selected sampling\nfunction could enable more efficient information extraction from clinical\nnotes.", "published": "2023-07-13 20:04:05", "link": "http://arxiv.org/abs/2307.07051v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Leveraging Pretrained ASR Encoders for Effective and Efficient\n  End-to-End Speech Intent Classification and Slot Filling", "abstract": "We study speech intent classification and slot filling (SICSF) by proposing\nto use an encoder pretrained on speech recognition (ASR) to initialize an\nend-to-end (E2E) Conformer-Transformer model, which achieves the new\nstate-of-the-art results on the SLURP dataset, with 90.14% intent accuracy and\n82.27% SLURP-F1. We compare our model with encoders pretrained on\nself-supervised learning (SSL), and show that ASR pretraining is much more\neffective than SSL for SICSF. To explore parameter efficiency, we freeze the\nencoder and add Adapter modules, and show that parameter efficiency is only\nachievable with an ASR-pretrained encoder, while the SSL encoder needs full\nfinetuning to achieve comparable results. In addition, we provide an in-depth\ncomparison on end-to-end models versus cascading models (ASR+NLU), and show\nthat E2E models are better than cascaded models unless an oracle ASR model is\nprovided. Last but not least, our model is the first E2E model that achieves\nthe same performance as cascading models with oracle ASR. Code, checkpoints and\nconfigs are available.", "published": "2023-07-13 20:50:19", "link": "http://arxiv.org/abs/2307.07057v1", "categories": ["cs.CL", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Adapting an ASR Foundation Model for Spoken Language Assessment", "abstract": "A crucial part of an accurate and reliable spoken language assessment system\nis the underlying ASR model. Recently, large-scale pre-trained ASR foundation\nmodels such as Whisper have been made available. As the output of these models\nis designed to be human readable, punctuation is added, numbers are presented\nin Arabic numeric form and abbreviations are included. Additionally, these\nmodels have a tendency to skip disfluencies and hesitations in the output.\nThough useful for readability, these attributes are not helpful for assessing\nthe ability of a candidate and providing feedback. Here a precise transcription\nof what a candidate said is needed. In this paper, we give a detailed analysis\nof Whisper outputs and propose two solutions: fine-tuning and soft prompt\ntuning. Experiments are conducted on both public speech corpora and an English\nlearner dataset. Results show that we can effectively alter the decoding\nbehaviour of Whisper to generate the exact words spoken in the response.", "published": "2023-07-13 16:01:58", "link": "http://arxiv.org/abs/2307.09378v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "EFL Students' Attitudes and Contradictions in a Machine-in-the-loop\n  Activity System", "abstract": "This study applies Activity Theory and investigates the attitudes and\ncontradictions of 67 English as a foreign language (EFL) students from four\nHong Kong secondary schools towards machine-in-the-loop writing, where\nartificial intelligence (AI) suggests ideas during composition. Students\nanswered an open-ended question about their feelings on writing with AI.\nResults revealed mostly positive attitudes, with some negative or mixed\nfeelings. From a thematic analysis, contradictions or points of tension between\nstudents and AI stemmed from AI inadequacies, students' balancing enthusiasm\nwith preference, and their striving for language autonomy. The research\nhighlights the benefits and challenges of implementing machine-in-the-loop\nwriting in EFL classrooms, suggesting educators align activity goals with\nstudents' values, language abilities, and AI capabilities to enhance students'\nactivity systems.", "published": "2023-07-13 07:38:11", "link": "http://arxiv.org/abs/2307.13699v1", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "DRAGON: A Dialogue-Based Robot for Assistive Navigation with Visual\n  Language Grounding", "abstract": "Persons with visual impairments (PwVI) have difficulties understanding and\nnavigating spaces around them. Current wayfinding technologies either focus\nsolely on navigation or provide limited communication about the environment.\nMotivated by recent advances in visual-language grounding and semantic\nnavigation, we propose DRAGON, a guiding robot powered by a dialogue system and\nthe ability to associate the environment with natural language. By\nunderstanding the commands from the user, DRAGON is able to guide the user to\nthe desired landmarks on the map, describe the environment, and answer\nquestions from visual observations. Through effective utilization of dialogue,\nthe robot can ground the user's free-form descriptions to landmarks in the\nenvironment, and give the user semantic information through spoken language. We\nconduct a user study with blindfolded participants in an everyday indoor\nenvironment. Our results demonstrate that DRAGON is able to communicate with\nthe user smoothly, provide a good guiding experience, and connect users with\ntheir surrounding environment in an intuitive manner. Videos and code are\navailable at https://sites.google.com/view/dragon-wayfinding/home.", "published": "2023-07-13 17:46:15", "link": "http://arxiv.org/abs/2307.06924v3", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.RO"}
{"title": "LACE: A light-weight, causal model for enhancing coded speech through\n  adaptive convolutions", "abstract": "Classical speech coding uses low-complexity postfilters with zero lookahead\nto enhance the quality of coded speech, but their effectiveness is limited by\ntheir simplicity. Deep Neural Networks (DNNs) can be much more effective, but\nrequire high complexity and model size, or added delay. We propose a DNN model\nthat generates classical filter kernels on a per-frame basis with a model of\njust 300~K parameters and 100~MFLOPS complexity, which is a practical\ncomplexity for desktop or mobile device CPUs. The lack of added delay allows it\nto be integrated into the Opus codec, and we demonstrate that it enables\neffective wideband encoding for bitrates down to 6 kb/s.", "published": "2023-07-13 08:17:36", "link": "http://arxiv.org/abs/2307.06610v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "An Improved Metric of Informational Masking for Perceptual Audio Quality\n  Measurement", "abstract": "Perceptual audio quality measurement systems algorithmically analyze the\noutput of audio processing systems to estimate possible perceived quality\ndegradation using perceptual models of human audition. In this manner, they\nsave the time and resources associated with the design and execution of\nlistening tests (LTs). Models of disturbance audibility predicting peripheral\nauditory masking in quality measurement systems have considerably increased\nsubjective quality prediction performance of signals processed by perceptual\naudio codecs. Additionally, cognitive effects have also been known to regulate\nperceived distortion severity by influencing their salience. However, the\nperformance gains due to cognitive effect models in quality measurement systems\nwere inconsistent so far, particularly for music signals. Firstly, this paper\npresents an improved model of informational masking (IM) -- an important\ncognitive effect in quality perception -- that considers disturbance\ninformation complexity around the masking threshold. Secondly, we incorporate\nthe proposed IM metric into a quality measurement systems using a novel\ninteraction analysis procedure between cognitive effects and distortion\nmetrics. The procedure establishes interactions between cognitive effects and\ndistortion metrics using LT data. The proposed IM metric is shown to outperform\npreviously proposed IM metrics in a validation task against subjective quality\nscores from large and diverse LT databases. Particularly, the proposed system\nshowed an increased quality prediction of music signals coded with bandwidth\nextension techniques, where other models frequently fail.", "published": "2023-07-13 09:59:09", "link": "http://arxiv.org/abs/2307.06656v1", "categories": ["eess.AS", "cs.SD", "eess.SP", "I.2.6; H.4.3"], "primary_category": "eess.AS"}
{"title": "Uncovering the Deceptions: An Analysis on Audio Spoofing Detection and\n  Future Prospects", "abstract": "Audio has become an increasingly crucial biometric modality due to its\nability to provide an intuitive way for humans to interact with machines. It is\ncurrently being used for a range of applications, including person\nauthentication to banking to virtual assistants. Research has shown that these\nsystems are also susceptible to spoofing and attacks. Therefore, protecting\naudio processing systems against fraudulent activities, such as identity theft,\nfinancial fraud, and spreading misinformation, is of paramount importance. This\npaper reviews the current state-of-the-art techniques for detecting audio\nspoofing and discusses the current challenges along with open research\nproblems. The paper further highlights the importance of considering the\nethical and privacy implications of audio spoofing detection systems. Lastly,\nthe work aims to accentuate the need for building more robust and generalizable\nmethods, the integration of automatic speaker verification and countermeasure\nsystems, and better evaluation protocols.", "published": "2023-07-13 10:25:30", "link": "http://arxiv.org/abs/2307.06669v1", "categories": ["cs.SD", "cs.CR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Controllable Emphasis with zero data for text-to-speech", "abstract": "We present a scalable method to produce high quality emphasis for\ntext-to-speech (TTS) that does not require recordings or annotations. Many TTS\nmodels include a phoneme duration model. A simple but effective method to\nachieve emphasized speech consists in increasing the predicted duration of the\nemphasised word. We show that this is significantly better than spectrogram\nmodification techniques improving naturalness by $7.3\\%$ and correct testers'\nidentification of the emphasized word in a sentence by $40\\%$ on a reference\nfemale en-US voice. We show that this technique significantly closes the gap to\nmethods that require explicit recordings. The method proved to be scalable and\npreferred in all four languages tested (English, Spanish, Italian, German), for\ndifferent voices and multiple speaking styles.", "published": "2023-07-13 21:06:23", "link": "http://arxiv.org/abs/2307.07062v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Real-time Percussive Technique Recognition and Embedding Learning for\n  the Acoustic Guitar", "abstract": "Real-time music information retrieval (RT-MIR) has much potential to augment\nthe capabilities of traditional acoustic instruments. We develop RT-MIR\ntechniques aimed at augmenting percussive fingerstyle, which blends acoustic\nguitar playing with guitar body percussion. We formulate several design\nobjectives for RT-MIR systems for augmented instrument performance: (i) causal\nconstraint, (ii) perceptually negligible action-to-sound latency, (iii) control\nintimacy support, (iv) synthesis control support. We present and evaluate\nreal-time guitar body percussion recognition and embedding learning techniques\nbased on convolutional neural networks (CNNs) and CNNs jointly trained with\nvariational autoencoders (VAEs). We introduce a taxonomy of guitar body\npercussion based on hand part and location. We follow a cross-dataset\nevaluation approach by collecting three datasets labelled according to the\ntaxonomy. The embedding quality of the models is assessed using KL-Divergence\nacross distributions corresponding to different taxonomic classes. Results\nindicate that the networks are strong classifiers especially in a simplified\n2-class recognition task, and the VAEs yield improved class separation compared\nto CNNs as evidenced by increased KL-Divergence across distributions. We argue\nthat the VAE embedding quality could support control intimacy and rich\ninteraction when the latent space's parameters are used to control an external\nsynthesis engine. Further design challenges around generalisation to different\ndatasets have been identified.", "published": "2023-07-13 10:48:29", "link": "http://arxiv.org/abs/2307.07426v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Corticomorphic Hybrid CNN-SNN Architecture for EEG-based Low-footprint\n  Low-latency Auditory Attention Detection", "abstract": "In a multi-speaker \"cocktail party\" scenario, a listener can selectively\nattend to a speaker of interest. Studies into the human auditory attention\nnetwork demonstrate cortical entrainment to speech envelopes resulting in\nhighly correlated Electroencephalography (EEG) measurements. Current trends in\nEEG-based auditory attention detection (AAD) using artificial neural networks\n(ANN) are not practical for edge-computing platforms due to longer decision\nwindows using several EEG channels, with higher power consumption and larger\nmemory footprint requirements. Nor are ANNs capable of accurately modeling the\nbrain's top-down attention network since the cortical organization is complex\nand layer. In this paper, we propose a hybrid convolutional neural\nnetwork-spiking neural network (CNN-SNN) corticomorphic architecture, inspired\nby the auditory cortex, which uses EEG data along with multi-speaker speech\nenvelopes to successfully decode auditory attention with low latency down to 1\nsecond, using only 8 EEG electrodes strategically placed close to the auditory\ncortex, at a significantly higher accuracy of 91.03%, compared to the\nstate-of-the-art. Simultaneously, when compared to a traditional CNN reference\nmodel, our model uses ~15% fewer parameters at a lower bit precision resulting\nin ~57% memory footprint reduction. The results show great promise for\nedge-computing in brain-embedded devices, like smart hearing aids.", "published": "2023-07-13 20:33:39", "link": "http://arxiv.org/abs/2307.08501v1", "categories": ["eess.SP", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "eess.SP"}
