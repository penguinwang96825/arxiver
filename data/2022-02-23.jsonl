{"title": "Knowledge Augmented BERT Mutual Network in Multi-turn Spoken Dialogues", "abstract": "Modern spoken language understanding (SLU) systems rely on sophisticated\nsemantic notions revealed in single utterances to detect intents and slots.\nHowever, they lack the capability of modeling multi-turn dynamics within a\ndialogue particularly in long-term slot contexts. Without external knowledge,\ndepending on limited linguistic legitimacy within a word sequence may overlook\ndeep semantic information across dialogue turns. In this paper, we propose to\nequip a BERT-based joint model with a knowledge attention module to mutually\nleverage dialogue contexts between two SLU tasks. A gating mechanism is further\nutilized to filter out irrelevant knowledge triples and to circumvent\ndistracting comprehension. Experimental results in two complicated multi-turn\ndialogue datasets have demonstrate by mutually modeling two SLU tasks with\nfiltered knowledge and dialogue contexts, our approach has considerable\nimprovements compared with several competitive baselines.", "published": "2022-02-23 04:03:35", "link": "http://arxiv.org/abs/2202.11299v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Zero-shot Cross-lingual Transfer of Prompt-based Tuning with a Unified\n  Multilingual Prompt", "abstract": "Prompt-based tuning has been proven effective for pretrained language models\n(PLMs). While most of the existing work focuses on the monolingual prompts, we\nstudy the multilingual prompts for multilingual PLMs, especially in the\nzero-shot cross-lingual setting. To alleviate the effort of designing different\nprompts for multiple languages, we propose a novel model that uses a unified\nprompt for all languages, called UniPrompt. Different from the discrete prompts\nand soft prompts, the unified prompt is model-based and language-agnostic.\nSpecifically, the unified prompt is initialized by a multilingual PLM to\nproduce language-independent representation, after which is fused with the text\ninput. During inference, the prompts can be pre-computed so that no extra\ncomputation cost is needed. To collocate with the unified prompt, we propose a\nnew initialization method for the target label word to further improve the\nmodel's transferability across languages. Extensive experiments show that our\nproposed methods can significantly outperform the strong baselines across\ndifferent languages. We release data and code to facilitate future research.", "published": "2022-02-23 11:57:52", "link": "http://arxiv.org/abs/2202.11451v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Refining the state-of-the-art in Machine Translation, optimizing NMT for\n  the JA <-> EN language pair by leveraging personal domain expertise", "abstract": "Documenting the construction of an NMT (Neural Machine Translation) system\nfor En/Ja based on the Transformer architecture leveraging the OpenNMT\nframework. A systematic exploration of corpora pre-processing, hyperparameter\ntuning and model architecture is carried out to obtain optimal performance. The\nsystem is evaluated using standard auto-evaluation metrics such as BLEU, and my\nsubjective opinion as a Japanese linguist.", "published": "2022-02-23 18:20:14", "link": "http://arxiv.org/abs/2202.11669v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A gentle introduction to Quantum Natural Language Processing", "abstract": "The main goal of this master's thesis is to introduce Quantum Natural\nLanguage Processing (QNLP) in a way understandable by both the NLP engineer and\nthe quantum computing practitioner. QNLP is a recent application of quantum\ncomputing that aims at representing sentences' meaning as vectors encoded into\nquantum computers. To achieve this, the distributional meaning of words is\nextended by the compositional meaning of sentences (DisCoCat model) : the\nvectors representing words' meanings are composed through the syntactic\nstructure of the sentence. This is done using an algorithm based on tensor\nproducts. We see that this algorithm is inefficient on classical computers but\nscales well using quantum circuits. After exposing the practical details of its\nimplementation, we go through three use-cases.", "published": "2022-02-23 20:17:00", "link": "http://arxiv.org/abs/2202.11766v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Using natural language prompts for machine translation", "abstract": "We explore the use of natural language prompts for controlling various\naspects of the outputs generated by machine translation models. We demonstrate\nthat natural language prompts allow us to influence properties like formality\nor specific dialect of the output. We show that using language names to control\nthe output language of multilingual translation models enables positive\ntransfer for unseen language pairs. This unlocks the ability to translate into\nlanguages not seen during fine-tuning by using their English names. We\ninvestigate how scale, number of pre-training steps, number of languages in\nfine-tuning, and language similarity affect this phenomenon.", "published": "2022-02-23 23:20:23", "link": "http://arxiv.org/abs/2202.11822v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prompt-Learning for Short Text Classification", "abstract": "In the short text, the extremely short length, feature sparsity, and high\nambiguity pose huge challenges to classification tasks. Recently, as an\neffective method for tuning Pre-trained Language Models for specific downstream\ntasks, prompt-learning has attracted a vast amount of attention and research.\nThe main intuition behind the prompt-learning is to insert the template into\nthe input and convert the text classification tasks into equivalent cloze-style\ntasks. However, most prompt-learning methods expand label words manually or\nonly consider the class name for knowledge incorporating in cloze-style\nprediction, which will inevitably incur omissions and bias in short text\nclassification tasks. In this paper, we propose a simple short text\nclassification approach that makes use of prompt-learning based on\nknowledgeable expansion. Taking the special characteristics of short text into\nconsideration, the method can consider both the short text itself and class\nname during expanding label words space. Specifically, the top $N$ concepts\nrelated to the entity in the short text are retrieved from the open Knowledge\nGraph like Probase, and we further refine the expanded label words by the\ndistance calculation between selected concepts and class labels. Experimental\nresults show that our approach obtains obvious improvement compared with other\nfine-tuning, prompt-learning, and knowledgeable prompt-tuning methods,\noutperforming the state-of-the-art by up to 6 Accuracy points on three\nwell-known datasets.", "published": "2022-02-23 08:07:06", "link": "http://arxiv.org/abs/2202.11345v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Short-answer scoring with ensembles of pretrained language models", "abstract": "We investigate the effectiveness of ensembles of pretrained transformer-based\nlanguage models on short answer questions using the Kaggle Automated Short\nAnswer Scoring dataset. We fine-tune a collection of popular small, base, and\nlarge pretrained transformer-based language models, and train one feature-base\nmodel on the dataset with the aim of testing ensembles of these models. We used\nan early stopping mechanism and hyperparameter optimization in training. We\nobserve that generally that the larger models perform slightly better, however,\nthey still fall short of state-of-the-art results one their own. Once we\nconsider ensembles of models, there are ensembles of a number of large networks\nthat do produce state-of-the-art results, however, these ensembles are too\nlarge to realistically be put in a production environment.", "published": "2022-02-23 15:12:20", "link": "http://arxiv.org/abs/2202.11558v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "From Unstructured Text to Causal Knowledge Graphs: A Transformer-Based\n  Approach", "abstract": "Qualitative causal relationships compactly express the direction, dependency,\ntemporal constraints, and monotonicity constraints of discrete or continuous\ninteractions in the world. In everyday or academic language, we may express\ninteractions between quantities (e.g., sleep decreases stress), between\ndiscrete events or entities (e.g., a protein inhibits another protein's\ntranscription), or between intentional or functional factors (e.g., hospital\npatients pray to relieve their pain). Extracting and representing these diverse\ncausal relations are critical for cognitive systems that operate in domains\nspanning from scientific discovery to social science. This paper presents a\ntransformer-based NLP architecture that jointly extracts knowledge graphs\nincluding (1) variables or factors described in language, (2) qualitative\ncausal relationships over these variables, (3) qualifiers and magnitudes that\nconstrain these causal relationships, and (4) word senses to localize each\nextracted node within a large ontology. We do not claim that our\ntransformer-based architecture is itself a cognitive system; however, we\nprovide evidence of its accurate knowledge graph extraction in real-world\ndomains and the practicality of its resulting knowledge graphs for cognitive\nsystems that perform graph-based reasoning. We demonstrate this approach and\ninclude promising results in two use cases, processing textual inputs from\nacademic publications, news articles, and social media.", "published": "2022-02-23 20:29:55", "link": "http://arxiv.org/abs/2202.11768v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "UnifiedQA-v2: Stronger Generalization via Broader Cross-Format Training", "abstract": "We present UnifiedQA-v2, a QA model built with the same process as UnifiedQA,\nexcept that it utilizes more supervision -- roughly 3x the number of datasets\nused for UnifiedQA. This generally leads to better in-domain and cross-domain\nresults.", "published": "2022-02-23 18:34:45", "link": "http://arxiv.org/abs/2202.12359v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enabling arbitrary translation objectives with Adaptive Tree Search", "abstract": "We introduce an adaptive tree search algorithm, that can find high-scoring\noutputs under translation models that make no assumptions about the form or\nstructure of the search objective. This algorithm -- a deterministic variant of\nMonte Carlo tree search -- enables the exploration of new kinds of models that\nare unencumbered by constraints imposed to make decoding tractable, such as\nautoregressivity or conditional independence assumptions. When applied to\nautoregressive models, our algorithm has different biases than beam search has,\nwhich enables a new analysis of the role of decoding bias in autoregressive\nmodels. Empirically, we show that our adaptive tree search algorithm finds\noutputs with substantially better model scores compared to beam search in\nautoregressive models, and compared to reranking techniques in models whose\nscores do not decompose additively with respect to the words in the output. We\nalso characterise the correlation of several translation model objectives with\nrespect to BLEU. We find that while some standard models are poorly calibrated\nand benefit from the beam search bias, other often more robust models\n(autoregressive models tuned to maximize expected automatic metric scores, the\nnoisy channel model and a newly proposed objective) benefit from increasing\namounts of search using our proposed decoder, whereas the beam search bias\nlimits the improvements obtained from such objectives. Thus, we argue that as\nmodels improve, the improvements may be masked by over-reliance on beam search\nor reranking based methods.", "published": "2022-02-23 11:48:26", "link": "http://arxiv.org/abs/2202.11444v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "COLD Decoding: Energy-based Constrained Text Generation with Langevin\n  Dynamics", "abstract": "Many applications of text generation require incorporating different\nconstraints to control the semantics or style of generated text. These\nconstraints can be hard (e.g., ensuring certain keywords are included in the\noutput) and soft (e.g., contextualizing the output with the left- or right-hand\ncontext). In this paper, we present Energy-based Constrained Decoding with\nLangevin Dynamics (COLD), a decoding framework which unifies constrained\ngeneration as specifying constraints through an energy function, then\nperforming efficient differentiable reasoning over the constraints through\ngradient-based sampling. COLD decoding is a flexible framework that can be\napplied directly to off-the-shelf left-to-right language models without the\nneed for any task-specific fine-tuning, as demonstrated through three\nchallenging text generation applications: lexically-constrained generation,\nabductive reasoning, and counterfactual reasoning. Our experiments on these\nconstrained generation tasks point to the effectiveness of our approach, both\nin terms of automatic and human evaluation.", "published": "2022-02-23 18:59:27", "link": "http://arxiv.org/abs/2202.11705v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Semi-Structured Query Grounding for Document-Oriented Databases with\n  Deep Retrieval and Its Application to Receipt and POI Matching", "abstract": "Semi-structured query systems for document-oriented databases have many real\napplications. One particular application that we are interested in is matching\neach financial receipt image with its corresponding place of interest (POI,\ne.g., restaurant) in the nationwide database. The problem is especially\nchallenging in the real production environment where many similar or incomplete\nentries exist in the database and queries are noisy (e.g., errors in optical\ncharacter recognition). In this work, we aim to address practical challenges\nwhen using embedding-based retrieval for the query grounding problem in\nsemi-structured data. Leveraging recent advancements in deep language encoding\nfor retrieval, we conduct extensive experiments to find the most effective\ncombination of modules for the embedding and retrieval of both query and\ndatabase entries without any manually engineered component. The proposed model\nsignificantly outperforms the conventional manual pattern-based model while\nrequiring much less development and maintenance cost. We also discuss some core\nobservations in our experiments, which could be helpful for practitioners\nworking on a similar problem in other domains.", "published": "2022-02-23 05:32:34", "link": "http://arxiv.org/abs/2202.13959v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Commonsense Reasoning for Identifying and Understanding the Implicit\n  Need of Help and Synthesizing Assistive Actions", "abstract": "Human-Robot Interaction (HRI) is an emerging subfield of service robotics.\nWhile most existing approaches rely on explicit signals (i.e. voice, gesture)\nto engage, current literature is lacking solutions to address implicit user\nneeds. In this paper, we present an architecture to (a) detect user implicit\nneed of help and (b) generate a set of assistive actions without prior\nlearning. Task (a) will be performed using state-of-the-art solutions for Scene\nGraph Generation coupled to the use of commonsense knowledge; whereas, task (b)\nwill be performed using additional commonsense knowledge as well as a sentiment\nanalysis on graph structure. Finally, we propose an evaluation of our solution\nusing established benchmarks (e.g. ActionGenome dataset) along with human\nexperiments. The main motivation of our approach is the embedding of the\nperception-decision-action loop in a single architecture.", "published": "2022-02-23 07:50:25", "link": "http://arxiv.org/abs/2202.11337v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC", "cs.NE"], "primary_category": "cs.AI"}
{"title": "MuMiN: A Large-Scale Multilingual Multimodal Fact-Checked Misinformation\n  Social Network Dataset", "abstract": "Misinformation is becoming increasingly prevalent on social media and in news\narticles. It has become so widespread that we require algorithmic assistance\nutilising machine learning to detect such content. Training these machine\nlearning models require datasets of sufficient scale, diversity and quality.\nHowever, datasets in the field of automatic misinformation detection are\npredominantly monolingual, include a limited amount of modalities and are not\nof sufficient scale and quality. Addressing this, we develop a data collection\nand linking system (MuMiN-trawl), to build a public misinformation graph\ndataset (MuMiN), containing rich social media data (tweets, replies, users,\nimages, articles, hashtags) spanning 21 million tweets belonging to 26 thousand\nTwitter threads, each of which have been semantically linked to 13 thousand\nfact-checked claims across dozens of topics, events and domains, in 41\ndifferent languages, spanning more than a decade. The dataset is made available\nas a heterogeneous graph via a Python package (mumin). We provide baseline\nresults for two node classification tasks related to the veracity of a claim\ninvolving social media, and demonstrate that these are challenging tasks, with\nthe highest macro-average F1-score being 62.55% and 61.45% for the two tasks,\nrespectively. The MuMiN ecosystem is available at\nhttps://mumin-dataset.github.io/, including the data, documentation, tutorials\nand leaderboards.", "published": "2022-02-23 18:47:34", "link": "http://arxiv.org/abs/2202.11684v2", "categories": ["cs.LG", "cs.CL", "cs.CY", "cs.IR", "cs.SI"], "primary_category": "cs.LG"}
{"title": "Fine-Grained Prediction of Political Leaning on Social Media with\n  Unsupervised Deep Learning", "abstract": "Predicting the political leaning of social media users is an increasingly\npopular task, given its usefulness for electoral forecasts, opinion dynamics\nmodels and for studying the political dimension of polarization and\ndisinformation. Here, we propose a novel unsupervised technique for learning\nfine-grained political leaning from the textual content of social media posts.\nOur technique leverages a deep neural network for learning latent political\nideologies in a representation learning task. Then, users are projected in a\nlow-dimensional ideology space where they are subsequently clustered. The\npolitical leaning of a user is automatically derived from the cluster to which\nthe user is assigned. We evaluated our technique in two challenging\nclassification tasks and we compared it to baselines and other state-of-the-art\napproaches. Our technique obtains the best results among all unsupervised\ntechniques, with micro F1 = 0.426 in the 8-class task and micro F1 = 0.772 in\nthe 3-class task. Other than being interesting on their own, our results also\npave the way for the development of new and better unsupervised approaches for\nthe detection of fine-grained political leaning.", "published": "2022-02-23 09:18:13", "link": "http://arxiv.org/abs/2202.12382v1", "categories": ["cs.SI", "cs.AI", "cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.SI"}
{"title": "End-to-end LPCNet: A Neural Vocoder With Fully-Differentiable LPC\n  Estimation", "abstract": "Neural vocoders have recently demonstrated high quality speech synthesis, but\ntypically require a high computational complexity. LPCNet was proposed as a way\nto reduce the complexity of neural synthesis by using linear prediction (LP) to\nassist an autoregressive model. At inference time, LPCNet relies on the LP\ncoefficients being explicitly computed from the input acoustic features. That\nmakes the design of LPCNet-based systems more complicated, while adding the\nconstraint that the input features must represent a clean speech spectrum. We\npropose an end-to-end version of LPCNet that lifts these limitations by\nlearning to infer the LP coefficients from the input features in the frame rate\nnetwork. Results show that the proposed end-to-end approach equals or exceeds\nthe quality of the original LPCNet model, but without explicit LP analysis. Our\nopen-source end-to-end model still benefits from LPCNet's low complexity, while\nallowing for any type of conditioning features.", "published": "2022-02-23 04:16:34", "link": "http://arxiv.org/abs/2202.11301v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Improving fairness in speaker verification via Group-adapted Fusion\n  Network", "abstract": "Modern speaker verification models use deep neural networks to encode\nutterance audio into discriminative embedding vectors. During the training\nprocess, these networks are typically optimized to differentiate arbitrary\nspeakers. This learning process biases the learning of fine voice\ncharacteristics towards dominant demographic groups, which can lead to an\nunfair performance disparity across different groups. This is observed\nespecially with underrepresented demographic groups sharing similar voice\ncharacteristics. In this work, we investigate the fairness of speaker\nverification models on controlled datasets with imbalanced gender\ndistributions, providing direct evidence that model performance suffers for\nunderrepresented groups. To mitigate this disparity we propose the\ngroup-adapted fusion network (GFN) architecture, a modular architecture based\non group embedding adaptation and score fusion. We show that our method\nalleviates model unfairness by improving speaker verification both overall and\nfor individual groups. Given imbalanced group representation in training, our\nproposed method achieves overall equal error rate (EER) reduction of 9.6% to\n29.0% relative, reduces minority group EER by 13.7% to 18.6%, and results in\n20.0% to 25.4% less EER disparity, compared to baselines. The approach is\napplicable to other types of training data skew in speaker recognition systems.", "published": "2022-02-23 06:20:33", "link": "http://arxiv.org/abs/2202.11323v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Blind Reverberation Time Estimation in Dynamic Acoustic Conditions", "abstract": "The estimation of reverberation time from real-world signals plays a central\nrole in a wide range of applications. In many scenarios, acoustic conditions\nchange over time which in turn requires the estimate to be updated\ncontinuously. Previously proposed methods involving deep neural networks were\nmostly designed and tested under the assumption of static acoustic conditions.\nIn this work, we show that these approaches can perform poorly in dynamically\nevolving acoustic environments. Motivated by a recent trend towards\ndata-centric approaches in machine learning, we propose a novel way of\ngenerating training data and demonstrate, using an existing deep neural network\narchitecture, the considerable improvement in the ability to follow temporal\nchanges in reverberation time.", "published": "2022-02-23 21:18:07", "link": "http://arxiv.org/abs/2202.11790v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Towards Speaker Age Estimation with Label Distribution Learning", "abstract": "Existing methods for speaker age estimation usually treat it as a multi-class\nclassification or a regression problem. However, precise age identification\nremains a challenge due to label ambiguity, \\emph{i.e.}, utterances from\nadjacent age of the same person are often indistinguishable. To address this,\nwe utilize the ambiguous information among the age labels, convert each age\nlabel into a discrete label distribution and leverage the label distribution\nlearning (LDL) method to fit the data. For each audio data sample, our method\nproduces a age distribution of its speaker, and on top of the distribution we\nalso perform two other tasks: age prediction and age uncertainty minimization.\nTherefore, our method naturally combines the age classification and regression\napproaches, which enhances the robustness of our method. We conduct experiments\non the public NIST SRE08-10 dataset and a real-world dataset, which exhibit\nthat our method outperforms baseline methods by a relatively large margin,\nyielding a 10\\% reduction in terms of mean absolute error (MAE) on a real-world\ndataset.", "published": "2022-02-23 11:11:58", "link": "http://arxiv.org/abs/2202.11424v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
{"title": "Listen to Interpret: Post-hoc Interpretability for Audio Networks with\n  NMF", "abstract": "This paper tackles post-hoc interpretability for audio processing networks.\nOur goal is to interpret decisions of a network in terms of high-level audio\nobjects that are also listenable for the end-user. To this end, we propose a\nnovel interpreter design that incorporates non-negative matrix factorization\n(NMF). In particular, a carefully regularized interpreter module is trained to\ntake hidden layer representations of the targeted network as input and produce\ntime activations of pre-learnt NMF components as intermediate outputs. Our\nmethodology allows us to generate intuitive audio-based interpretations that\nexplicitly enhance parts of the input signal most relevant for a network's\ndecision. We demonstrate our method's applicability on popular benchmarks,\nincluding a real-world multi-label classification task.", "published": "2022-02-23 13:00:55", "link": "http://arxiv.org/abs/2202.11479v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Differentially Private Speaker Anonymization", "abstract": "Sharing real-world speech utterances is key to the training and deployment of\nvoice-based services. However, it also raises privacy risks as speech contains\na wealth of personal data. Speaker anonymization aims to remove speaker\ninformation from a speech utterance while leaving its linguistic and prosodic\nattributes intact. State-of-the-art techniques operate by disentangling the\nspeaker information (represented via a speaker embedding) from these attributes\nand re-synthesizing speech based on the speaker embedding of another speaker.\nPrior research in the privacy community has shown that anonymization often\nprovides brittle privacy protection, even less so any provable guarantee. In\nthis work, we show that disentanglement is indeed not perfect: linguistic and\nprosodic attributes still contain speaker information. We remove speaker\ninformation from these attributes by introducing differentially private feature\nextractors based on an autoencoder and an automatic speech recognizer,\nrespectively, trained using noise layers. We plug these extractors in the\nstate-of-the-art anonymization pipeline and generate, for the first time,\nprivate speech utterances with a provable upper bound on the speaker\ninformation they contain. We evaluate empirically the privacy and utility\nresulting from our differentially private speaker anonymization approach on the\nLibriSpeech data set. Experimental results show that the generated utterances\nretain very high utility for automatic speech recognition training and\ninference, while being much better protected against strong adversaries who\nleverage the full knowledge of the anonymization process to try to infer the\nspeaker identity.", "published": "2022-02-23 23:20:30", "link": "http://arxiv.org/abs/2202.11823v2", "categories": ["cs.SD", "cs.CR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Flat Latent Manifolds for Human-machine Co-creation of Music", "abstract": "The use of machine learning in artistic music generation leads to\ncontroversial discussions of the quality of art, for which objective\nquantification is nonsensical. We therefore consider a music-generating\nalgorithm as a counterpart to a human musician, in a setting where reciprocal\ninterplay is to lead to new experiences, both for the musician and the\naudience. To obtain this behaviour, we resort to the framework of recurrent\nVariational Auto-Encoders (VAE) and learn to generate music, seeded by a human\nmusician. In the learned model, we generate novel musical sequences by\ninterpolation in latent space. Standard VAEs however do not guarantee any form\nof smoothness in their latent representation. This translates into abrupt\nchanges in the generated music sequences. To overcome these limitations, we\nregularise the decoder and endow the latent space with a flat Riemannian\nmanifold, i.e., a manifold that is isometric to the Euclidean space. As a\nresult, linearly interpolating in the latent space yields realistic and smooth\nmusical changes that fit the type of machine--musician interactions we aim for.\nWe provide empirical evidence for our method via a set of experiments on music\ndatasets and we deploy our model for an interactive jam session with a\nprofessional drummer. The live performance provides qualitative evidence that\nthe latent representation can be intuitively interpreted and exploited by the\ndrummer to drive the interplay. Beyond the musical application, our approach\nshowcases an instance of human-centred design of machine-learning models,\ndriven by interpretability and the interaction with the end user.", "published": "2022-02-23 09:00:17", "link": "http://arxiv.org/abs/2202.12243v3", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "State-of-the-art in speaker recognition", "abstract": "Recent advances in speech technologies have produced new tools that can be\nused to improve the performance and flexibility of speaker recognition While\nthere are few degrees of freedom or alternative methods when using fingerprint\nor iris identification techniques, speech offers much more flexibility and\ndifferent levels for performing recognition: the system can force the user to\nspeak in a particular manner, different for each attempt to enter. Also with\nvoice input the system has other degrees of freedom, such as the use of\nknowledge/codes that only the user knows, or dialectical/semantical traits that\nare difficult to forge. This paper offers and overview of the state of the art\nin speaker recognition, with special emphasis on the pros and contras, and the\ncurrent research lines. The current research lines include improved\nclassification systems, and the use of high level information by means of\nprobabilistic grammars. In conclusion, speaker recognition is far away from\nbeing a technology where all the possibilities have already been explored.", "published": "2022-02-23 11:49:09", "link": "http://arxiv.org/abs/2202.12705v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Speaker recognition improvement using blind inversion of distortions", "abstract": "In this paper we propose the inversion of nonlinear distortions in order to\nimprove the recognition rates of a speaker recognizer system. We study the\neffect of saturations on the test signals, trying to take into account real\nsituations where the training material has been recorded in a controlled\nsituation but the testing signals present some mismatch with the input signal\nlevel (saturations). The experimental results shows that a combination of data\nfusion with and without nonlinear distortion compensation can improve the\nrecognition rates with saturated test sentences from 80% to 88.57%, while the\nresults with clean speech (without saturation) is 87.76% for one microphone.", "published": "2022-02-23 23:49:41", "link": "http://arxiv.org/abs/2203.01164v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Speech watermarking: an approach for the forensic analysis of digital\n  telephonic recordings", "abstract": "In this article, the authors discuss the problem of forensic authentication\nof digital audio recordings. Although forensic audio has been addressed in\nseveral articles, the existing approaches are focused on analog magnetic\nrecordings, which are less prevalent because of the large amount of digital\nrecorders available on the market (optical, solid state, hard disks, etc.). An\napproach based on digital signal processing that consists of spread spectrum\ntechniques for speech watermarking is presented. This approach presents the\nadvantage that the authentication is based on the signal itself rather than the\nrecording format. Thus, it is valid for usual recording devices in\npolice-controlled telephone intercepts. In addition, our proposal allows for\nthe introduction of relevant information such as the recording date and time\nand all the relevant data (this is not always possible with classical systems).\nOur experimental results reveal that the speech watermarking procedure does not\ninterfere in a significant way with the posterior forensic speaker\nidentification.", "published": "2022-02-23 13:39:03", "link": "http://arxiv.org/abs/2203.02275v2", "categories": ["cs.CR", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CR"}
