{"title": "Tachikuma: Understading Complex Interactions with Multi-Character and\n  Novel Objects by Large Language Models", "abstract": "Recent advancements in natural language and Large Language Models (LLMs) have\nenabled AI agents to simulate human-like interactions within virtual worlds.\nHowever, these interactions still face limitations in complexity and\nflexibility, particularly in scenarios involving multiple characters and novel\nobjects. Pre-defining all interactable objects in the agent's world model\npresents challenges, and conveying implicit intentions to multiple characters\nthrough complex interactions remains difficult. To address these issues, we\npropose integrating virtual Game Masters (GMs) into the agent's world model,\ndrawing inspiration from Tabletop Role-Playing Games (TRPGs). GMs play a\ncrucial role in overseeing information, estimating players' intentions,\nproviding environment descriptions, and offering feedback, compensating for\ncurrent world model deficiencies. To facilitate future explorations for complex\ninteractions, we introduce a benchmark named Tachikuma, comprising a Multiple\ncharacter and novel Object based interaction Estimation (MOE) task and a\nsupporting dataset. MOE challenges models to understand characters' intentions\nand accurately determine their actions within intricate contexts involving\nmulti-character and novel object interactions. Besides, the dataset captures\nlog data from real-time communications during gameplay, providing diverse,\ngrounded, and complex interactions for further explorations. Finally, we\npresent a simple prompting baseline and evaluate its performance, demonstrating\nits effectiveness in enhancing interaction understanding. We hope that our\ndataset and task will inspire further research in complex interactions with\nnatural language, fostering the development of more advanced AI agents.", "published": "2023-07-24 07:40:59", "link": "http://arxiv.org/abs/2307.12573v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Guidance in Radiology Report Summarization: An Empirical Evaluation and\n  Error Analysis", "abstract": "Automatically summarizing radiology reports into a concise impression can\nreduce the manual burden of clinicians and improve the consistency of\nreporting. Previous work aimed to enhance content selection and factuality\nthrough guided abstractive summarization. However, two key issues persist.\nFirst, current methods heavily rely on domain-specific resources to extract the\nguidance signal, limiting their transferability to domains and languages where\nthose resources are unavailable. Second, while automatic metrics like ROUGE\nshow progress, we lack a good understanding of the errors and failure modes in\nthis task. To bridge these gaps, we first propose a domain-agnostic guidance\nsignal in form of variable-length extractive summaries. Our empirical results\non two English benchmarks demonstrate that this guidance signal improves upon\nunguided summarization while being competitive with domain-specific methods.\nAdditionally, we run an expert evaluation of four systems according to a\ntaxonomy of 11 fine-grained errors. We find that the most pressing differences\nbetween automatic summaries and those of radiologists relate to content\nselection including omissions (up to 52%) and additions (up to 57%). We\nhypothesize that latent reporting factors and corpus-level inconsistencies may\nlimit models to reliably learn content selection from the available data,\npresenting promising directions for future work.", "published": "2023-07-24 13:54:37", "link": "http://arxiv.org/abs/2307.12803v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Joint Dropout: Improving Generalizability in Low-Resource Neural Machine\n  Translation through Phrase Pair Variables", "abstract": "Despite the tremendous success of Neural Machine Translation (NMT), its\nperformance on low-resource language pairs still remains subpar, partly due to\nthe limited ability to handle previously unseen inputs, i.e., generalization.\nIn this paper, we propose a method called Joint Dropout, that addresses the\nchallenge of low-resource neural machine translation by substituting phrases\nwith variables, resulting in significant enhancement of compositionality, which\nis a key aspect of generalization. We observe a substantial improvement in\ntranslation quality for language pairs with minimal resources, as seen in BLEU\nand Direct Assessment scores. Furthermore, we conduct an error analysis, and\nfind Joint Dropout to also enhance generalizability of low-resource NMT in\nterms of robustness and adaptability across different domains", "published": "2023-07-24 14:33:49", "link": "http://arxiv.org/abs/2307.12835v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Boosting Punctuation Restoration with Data Generation and Reinforcement\n  Learning", "abstract": "Punctuation restoration is an important task in automatic speech recognition\n(ASR) which aim to restore the syntactic structure of generated ASR texts to\nimprove readability. While punctuated texts are abundant from written\ndocuments, the discrepancy between written punctuated texts and ASR texts\nlimits the usability of written texts in training punctuation restoration\nsystems for ASR texts. This paper proposes a reinforcement learning method to\nexploit in-topic written texts and recent advances in large pre-trained\ngenerative language models to bridge this gap. The experiments show that our\nmethod achieves state-of-the-art performance on the ASR test set on two\nbenchmark datasets for punctuation restoration.", "published": "2023-07-24 17:22:04", "link": "http://arxiv.org/abs/2307.12949v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Aligning Large Language Models with Human: A Survey", "abstract": "Large Language Models (LLMs) trained on extensive textual corpora have\nemerged as leading solutions for a broad array of Natural Language Processing\n(NLP) tasks. Despite their notable performance, these models are prone to\ncertain limitations such as misunderstanding human instructions, generating\npotentially biased content, or factually incorrect (hallucinated) information.\nHence, aligning LLMs with human expectations has become an active area of\ninterest within the research community. This survey presents a comprehensive\noverview of these alignment technologies, including the following aspects. (1)\nData collection: the methods for effectively collecting high-quality\ninstructions for LLM alignment, including the use of NLP benchmarks, human\nannotations, and leveraging strong LLMs. (2) Training methodologies: a detailed\nreview of the prevailing training methods employed for LLM alignment. Our\nexploration encompasses Supervised Fine-tuning, both Online and Offline human\npreference training, along with parameter-efficient training mechanisms. (3)\nModel Evaluation: the methods for evaluating the effectiveness of these\nhuman-aligned LLMs, presenting a multifaceted approach towards their\nassessment. In conclusion, we collate and distill our findings, shedding light\non several promising future research avenues in the field. This survey,\ntherefore, serves as a valuable resource for anyone invested in understanding\nand advancing the alignment of LLMs to better suit human-oriented tasks and\nexpectations. An associated GitHub link collecting the latest papers is\navailable at https://github.com/GaryYufei/AlignLLMHumanSurvey.", "published": "2023-07-24 17:44:58", "link": "http://arxiv.org/abs/2307.12966v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Wisdom of Instruction-Tuned Language Model Crowds. Exploring Model Label\n  Variation", "abstract": "Large Language Models (LLMs) exhibit remarkable text classification\ncapabilities, excelling in zero- and few-shot learning (ZSL and FSL) scenarios.\nHowever, since they are trained on different datasets, performance varies\nwidely across tasks between those models. Recent studies emphasize the\nimportance of considering human label variation in data annotation. However,\nhow this human label variation also applies to LLMs remains unexplored. Given\nthis likely model specialization, we ask: Do aggregate LLM labels improve over\nindividual models (as for human annotators)? We evaluate four recent\ninstruction-tuned LLMs as annotators on five subjective tasks across four\nlanguages. We use ZSL and FSL setups and label aggregation from human\nannotation. Aggregations are indeed substantially better than any individual\nmodel, benefiting from specialization in diverse tasks or languages.\nSurprisingly, FSL does not surpass ZSL, as it depends on the quality of the\nselected examples. However, there seems to be no good information-theoretical\nstrategy to select those. We find that no LLM method rivals even simple\nsupervised models. We also discuss the tradeoffs in accuracy, cost, and\nmoral/ethical considerations between LLM and human annotation.", "published": "2023-07-24 17:49:31", "link": "http://arxiv.org/abs/2307.12973v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating the Ripple Effects of Knowledge Editing in Language Models", "abstract": "Modern language models capture a large body of factual knowledge. However,\nsome facts can be incorrectly induced or become obsolete over time, resulting\nin factually incorrect generations. This has led to the development of various\nediting methods that allow updating facts encoded by the model. Evaluation of\nthese methods has primarily focused on testing whether an individual fact has\nbeen successfully injected, and if similar predictions for other subjects have\nnot changed. Here we argue that such evaluation is limited, since injecting one\nfact (e.g. ``Jack Depp is the son of Johnny Depp'') introduces a ``ripple\neffect'' in the form of additional facts that the model needs to update\n(e.g.``Jack Depp is the sibling of Lily-Rose Depp''). To address this issue, we\npropose a novel set of evaluation criteria that consider the implications of an\nedit on related facts. Using these criteria, we then construct RippleEdits, a\ndiagnostic benchmark of 5K factual edits, capturing a variety of types of\nripple effects. We evaluate prominent editing methods on RippleEdits, showing\nthat current methods fail to introduce consistent changes in the model's\nknowledge. In addition, we find that a simple in-context editing baseline\nobtains the best scores on our benchmark, suggesting a promising research\ndirection for model editing.", "published": "2023-07-24 17:52:46", "link": "http://arxiv.org/abs/2307.12976v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Explaining Math Word Problem Solvers", "abstract": "Automated math word problem solvers based on neural networks have\nsuccessfully managed to obtain 70-80\\% accuracy in solving arithmetic word\nproblems. However, it has been shown that these solvers may rely on superficial\npatterns to obtain their equations. In order to determine what information math\nword problem solvers use to generate solutions, we remove parts of the input\nand measure the model's performance on the perturbed dataset. Our results show\nthat the model is not sensitive to the removal of many words from the input and\ncan still manage to find a correct answer when given a nonsense question. This\nindicates that automatic solvers do not follow the semantic logic of math word\nproblems, and may be overfitting to the presence of specific words.", "published": "2023-07-24 21:05:47", "link": "http://arxiv.org/abs/2307.13128v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Schema-Driven Actionable Insight Generation and Smart Recommendation", "abstract": "In natural language generation (NLG), insight mining is seen as a\ndata-to-text task, where data is mined for interesting patterns and verbalised\ninto 'insight' statements. An 'over-generate and rank' paradigm is intuitively\nused to generate such insights. The multidimensionality and subjectivity of\nthis process make it challenging. This paper introduces a schema-driven method\nto generate actionable insights from data to drive growth and change. It also\nintroduces a technique to rank the insights to align with user interests based\non their feedback. We show preliminary qualitative results of the insights\ngenerated using our technique and demonstrate its ability to adapt to feedback.", "published": "2023-07-24 23:53:13", "link": "http://arxiv.org/abs/2307.13176v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lost In Translation: Generating Adversarial Examples Robust to\n  Round-Trip Translation", "abstract": "Language Models today provide a high accuracy across a large number of\ndownstream tasks. However, they remain susceptible to adversarial attacks,\nparticularly against those where the adversarial examples maintain considerable\nsimilarity to the original text. Given the multilingual nature of text, the\neffectiveness of adversarial examples across translations and how machine\ntranslations can improve the robustness of adversarial examples remain largely\nunexplored. In this paper, we present a comprehensive study on the robustness\nof current text adversarial attacks to round-trip translation. We demonstrate\nthat 6 state-of-the-art text-based adversarial attacks do not maintain their\nefficacy after round-trip translation. Furthermore, we introduce an\nintervention-based solution to this problem, by integrating Machine Translation\ninto the process of adversarial example generation and demonstrating increased\nrobustness to round-trip translation. Our results indicate that finding\nadversarial examples robust to translation can help identify the insufficiency\nof language models that is common across languages, and motivate further\nresearch into multilingual adversarial attacks.", "published": "2023-07-24 04:29:43", "link": "http://arxiv.org/abs/2307.12520v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Generalising Neural Topical Representations", "abstract": "Topic models have evolved from conventional Bayesian probabilistic models to\nrecent Neural Topic Models (NTMs). Although NTMs have shown promising\nperformance when trained and tested on a specific corpus, their generalisation\nability across corpora has yet to be studied. In practice, we often expect that\nan NTM trained on a source corpus can still produce quality topical\nrepresentation (i.e., latent distribution over topics) for the document from\ndifferent target corpora to a certain degree. In this work, we aim to improve\nNTMs further so that their representation power for documents generalises\nreliably across corpora and tasks. To do so, we propose to enhance NTMs by\nnarrowing the semantic distance between similar documents, with the underlying\nassumption that documents from different corpora may share similar semantics.\nSpecifically, we obtain a similar document for each training document by text\ndata augmentation. Then, we optimise NTMs further by minimising the semantic\ndistance between each pair, measured by the Topical Optimal Transport\n(TopicalOT) distance, which computes the optimal transport distance between\ntheir topical representations. Our framework can be readily applied to most\nNTMs as a plug-and-play module. Extensive experiments show that our framework\nsignificantly improves the generalisation ability regarding neural topical\nrepresentation across corpora. Our code and datasets are available at:\nhttps://github.com/Xiaohao-Yang/Topic_Model_Generalisation.", "published": "2023-07-24 07:17:33", "link": "http://arxiv.org/abs/2307.12564v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "RRAML: Reinforced Retrieval Augmented Machine Learning", "abstract": "The emergence of large language models (LLMs) has revolutionized machine\nlearning and related fields, showcasing remarkable abilities in comprehending,\ngenerating, and manipulating human language. However, their conventional usage\nthrough API-based text prompt submissions imposes certain limitations in terms\nof context constraints and external source availability. To address these\nchallenges, we propose a novel framework called Reinforced Retrieval Augmented\nMachine Learning (RRAML). RRAML integrates the reasoning capabilities of LLMs\nwith supporting information retrieved by a purpose-built retriever from a vast\nuser-provided database. By leveraging recent advancements in reinforcement\nlearning, our method effectively addresses several critical challenges.\nFirstly, it circumvents the need for accessing LLM gradients. Secondly, our\nmethod alleviates the burden of retraining LLMs for specific tasks, as it is\noften impractical or impossible due to restricted access to the model and the\ncomputational intensity involved. Additionally we seamlessly link the\nretriever's task with the reasoner, mitigating hallucinations and reducing\nirrelevant, and potentially damaging retrieved documents. We believe that the\nresearch agenda outlined in this paper has the potential to profoundly impact\nthe field of AI, democratizing access to and utilization of LLMs for a wide\nrange of entities.", "published": "2023-07-24 13:51:19", "link": "http://arxiv.org/abs/2307.12798v3", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Corrections of Zipf's and Heaps' Laws Derived from Hapax Rate Models", "abstract": "The article introduces corrections to Zipf's and Heaps' laws based on\nsystematic models of the proportion of hapaxes, i.e., words that occur once.\nThe derivation rests on two assumptions: The first one is the standard urn\nmodel which predicts that marginal frequency distributions for shorter texts\nlook as if word tokens were sampled blindly from a given longer text. The\nsecond assumption posits that the hapax rate is a simple function of the text\nlength. Four such functions are discussed: the constant model, the Davis model,\nthe linear model, and the logistic model. It is shown that the logistic model\nyields the best fit.", "published": "2023-07-24 15:44:23", "link": "http://arxiv.org/abs/2307.12896v4", "categories": ["cs.CL", "stat.AP", "62P99", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Rule By Example: Harnessing Logical Rules for Explainable Hate Speech\n  Detection", "abstract": "Classic approaches to content moderation typically apply a rule-based\nheuristic approach to flag content. While rules are easily customizable and\nintuitive for humans to interpret, they are inherently fragile and lack the\nflexibility or robustness needed to moderate the vast amount of undesirable\ncontent found online today. Recent advances in deep learning have demonstrated\nthe promise of using highly effective deep neural models to overcome these\nchallenges. However, despite the improved performance, these data-driven models\nlack transparency and explainability, often leading to mistrust from everyday\nusers and a lack of adoption by many platforms. In this paper, we present Rule\nBy Example (RBE): a novel exemplar-based contrastive learning approach for\nlearning from logical rules for the task of textual content moderation. RBE is\ncapable of providing rule-grounded predictions, allowing for more explainable\nand customizable predictions compared to typical deep learning-based\napproaches. We demonstrate that our approach is capable of learning rich rule\nembedding representations using only a few data examples. Experimental results\non 3 popular hate speech classification datasets show that RBE is able to\noutperform state-of-the-art deep learning classifiers as well as the use of\nrules in both supervised and unsupervised settings while providing explainable\nmodel predictions via rule-grounding.", "published": "2023-07-24 16:55:37", "link": "http://arxiv.org/abs/2307.12935v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "RLCD: Reinforcement Learning from Contrastive Distillation for Language\n  Model Alignment", "abstract": "We propose Reinforcement Learning from Contrastive Distillation (RLCD), a\nmethod for aligning language models to follow principles expressed in natural\nlanguage (e.g., to be more harmless) without using human feedback. RLCD creates\npreference pairs from two contrasting model outputs, one using a positive\nprompt designed to encourage following the given principles, and one using a\nnegative prompt designed to encourage violating them. Using two different\nprompts causes model outputs to be more differentiated on average, resulting in\ncleaner preference labels in the absence of human annotations. We then use the\npreference pairs to train a preference model, which is in turn used to improve\na base unaligned language model via reinforcement learning. Empirically, RLCD\noutperforms RLAIF (Bai et al., 2022b) and context distillation (Huang et al.,\n2022) baselines across three diverse alignment tasks--harmlessness,\nhelpfulness, and story outline generation--and when using both 7B and 30B model\nscales for simulating preference data.", "published": "2023-07-24 17:23:22", "link": "http://arxiv.org/abs/2307.12950v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The potential of LLMs for coding with low-resource and domain-specific\n  programming languages", "abstract": "This paper presents a study on the feasibility of using large language models\n(LLM) for coding with low-resource and domain-specific programming languages\nthat typically lack the amount of data required for effective LLM processing\ntechniques. This study focuses on the econometric scripting language named\nhansl of the open-source software gretl and employs a proprietary LLM based on\nGPT-3.5. Our findings suggest that LLMs can be a useful tool for writing,\nunderstanding, improving, and documenting gretl code, which includes generating\ndescriptive docstrings for functions and providing precise explanations for\nabstract and poorly documented econometric code. While the LLM showcased\npromoting docstring-to-code translation capability, we also identify some\nlimitations, such as its inability to improve certain sections of code and to\nwrite accurate unit tests. This study is a step towards leveraging the power of\nLLMs to facilitate software development in low-resource programming languages\nand ultimately to lower barriers to entry for their adoption.", "published": "2023-07-24 17:17:13", "link": "http://arxiv.org/abs/2307.13018v1", "categories": ["cs.CL", "cs.SE", "D.2.3; I.2.7"], "primary_category": "cs.CL"}
{"title": "Making Metadata More FAIR Using Large Language Models", "abstract": "With the global increase in experimental data artifacts, harnessing them in a\nunified fashion leads to a major stumbling block - bad metadata. To bridge this\ngap, this work presents a Natural Language Processing (NLP) informed\napplication, called FAIRMetaText, that compares metadata. Specifically,\nFAIRMetaText analyzes the natural language descriptions of metadata and\nprovides a mathematical similarity measure between two terms. This measure can\nthen be utilized for analyzing varied metadata, by suggesting terms for\ncompliance or grouping similar terms for identification of replaceable terms.\nThe efficacy of the algorithm is presented qualitatively and quantitatively on\npublicly available research artifacts and demonstrates large gains across\nmetadata related tasks through an in-depth study of a wide variety of Large\nLanguage Models (LLMs). This software can drastically reduce the human effort\nin sifting through various natural language metadata while employing several\nexperimental datasets on the same topic.", "published": "2023-07-24 19:14:38", "link": "http://arxiv.org/abs/2307.13085v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "How to use LLMs for Text Analysis", "abstract": "This guide introduces Large Language Models (LLM) as a highly versatile text\nanalysis method within the social sciences. As LLMs are easy-to-use, cheap,\nfast, and applicable on a broad range of text analysis tasks, ranging from text\nannotation and classification to sentiment analysis and critical discourse\nanalysis, many scholars believe that LLMs will transform how we do text\nanalysis. This how-to guide is aimed at students and researchers with limited\nprogramming experience, and offers a simple introduction to how LLMs can be\nused for text analysis in your own research project, as well as advice on best\npractices. We will go through each of the steps of analyzing textual data with\nLLMs using Python: installing the software, setting up the API, loading the\ndata, developing an analysis prompt, analyzing the text, and validating the\nresults. As an illustrative example, we will use the challenging task of\nidentifying populism in political texts, and show how LLMs move beyond the\nexisting state-of-the-art.", "published": "2023-07-24 19:54:15", "link": "http://arxiv.org/abs/2307.13106v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Opinion Mining Using Population-tuned Generative Language Models", "abstract": "We present a novel method for mining opinions from text collections using\ngenerative language models trained on data collected from different\npopulations. We describe the basic definitions, methodology and a generic\nalgorithm for opinion insight mining. We demonstrate the performance of our\nmethod in an experiment where a pre-trained generative model is fine-tuned\nusing specifically tailored content with unnatural and fully annotated\nopinions. We show that our approach can learn and transfer the opinions to the\nsemantic classes while maintaining the proportion of polarisation. Finally, we\ndemonstrate the usage of an insight mining system to scale up the discovery of\nopinion insights from a real text corpus.", "published": "2023-07-24 23:42:32", "link": "http://arxiv.org/abs/2307.13173v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving Primary Healthcare Workflow Using Extreme Summarization of\n  Scientific Literature Based on Generative AI", "abstract": "Primary care professionals struggle to keep up to date with the latest\nscientific literature critical in guiding evidence-based practice related to\ntheir daily work. To help solve the above-mentioned problem, we employed\ngenerative artificial intelligence techniques based on large-scale language\nmodels to summarize abstracts of scientific papers. Our objective is to\ninvestigate the potential of generative artificial intelligence in diminishing\nthe cognitive load experienced by practitioners, thus exploring its ability to\nalleviate mental effort and burden. The study participants were provided with\ntwo use cases related to preventive care and behavior change, simulating a\nsearch for new scientific literature. The study included 113 university\nstudents from Slovenia and the United States randomized into three distinct\nstudy groups. The first group was assigned to the full abstracts. The second\ngroup was assigned to the short abstracts generated by AI. The third group had\nthe option to select a full abstract in addition to the AI-generated short\nsummary. Each use case study included ten retrieved abstracts. Our research\ndemonstrates that the use of generative AI for literature review is efficient\nand effective. The time needed to answer questions related to the content of\nabstracts was significantly lower in groups two and three compared to the first\ngroup using full abstracts. The results, however, also show significantly lower\naccuracy in extracted knowledge in cases where full abstract was not available.\nSuch a disruptive technology could significantly reduce the time required for\nhealthcare professionals to keep up with the most recent scientific literature;\nnevertheless, further developments are needed to help them comprehend the\nknowledge accurately.", "published": "2023-07-24 21:42:27", "link": "http://arxiv.org/abs/2307.15715v1", "categories": ["cs.CL", "cs.AI", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Comparative Analysis of Drug-GPT and ChatGPT LLMs for Healthcare\n  Insights: Evaluating Accuracy and Relevance in Patient and HCP Contexts", "abstract": "This study presents a comparative analysis of three Generative Pre-trained\nTransformer (GPT) solutions in a question and answer (Q&A) setting: Drug-GPT 3,\nDrug-GPT 4, and ChatGPT, in the context of healthcare applications. The\nobjective is to determine which model delivers the most accurate and relevant\ninformation in response to prompts related to patient experiences with atopic\ndermatitis (AD) and healthcare professional (HCP) discussions about diabetes.\nThe results demonstrate that while all three models are capable of generating\nrelevant and accurate responses, Drug-GPT 3 and Drug-GPT 4, which are supported\nby curated datasets of patient and HCP social media and message board posts,\nprovide more targeted and in-depth insights. ChatGPT, a more general-purpose\nmodel, generates broader and more general responses, which may be valuable for\nreaders seeking a high-level understanding of the topics but may lack the depth\nand personal insights found in the answers generated by the specialized\nDrug-GPT models. This comparative analysis highlights the importance of\nconsidering the language model's perspective, depth of knowledge, and currency\nwhen evaluating the usefulness of generated information in healthcare\napplications.", "published": "2023-07-24 19:27:11", "link": "http://arxiv.org/abs/2307.16850v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Robust Automatic Speech Recognition via WavAugment Guided Phoneme\n  Adversarial Training", "abstract": "Developing a practically-robust automatic speech recognition (ASR) is\nchallenging since the model should not only maintain the original performance\non clean samples, but also achieve consistent efficacy under small volume\nperturbations and large domain shifts. To address this problem, we propose a\nnovel WavAugment Guided Phoneme Adversarial Training (wapat). wapat use\nadversarial examples in phoneme space as augmentation to make the model\ninvariant to minor fluctuations in phoneme representation and preserve the\nperformance on clean samples. In addition, wapat utilizes the phoneme\nrepresentation of augmented samples to guide the generation of adversaries,\nwhich helps to find more stable and diverse gradient-directions, resulting in\nimproved generalization. Extensive experiments demonstrate the effectiveness of\nwapat on End-to-end Speech Challenge Benchmark (ESB). Notably, SpeechLM-wapat\noutperforms the original model by 6.28% WER reduction on ESB, achieving the new\nstate-of-the-art.", "published": "2023-07-24 03:07:40", "link": "http://arxiv.org/abs/2307.12498v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Gradient-Based Word Substitution for Obstinate Adversarial Examples\n  Generation in Language Models", "abstract": "In this paper, we study the problem of generating obstinate (over-stability)\nadversarial examples by word substitution in NLP, where input text is\nmeaningfully changed but the model's prediction does not, even though it\nshould. Previous word substitution approaches have predominantly focused on\nmanually designed antonym-based strategies for generating obstinate adversarial\nexamples, which hinders its application as these strategies can only find a\nsubset of obstinate adversarial examples and require human efforts. To address\nthis issue, in this paper, we introduce a novel word substitution method named\nGradObstinate, a gradient-based approach that automatically generates obstinate\nadversarial examples without any constraints on the search space or the need\nfor manual design principles. To empirically evaluate the efficacy of\nGradObstinate, we conduct comprehensive experiments on five representative\nmodels (Electra, ALBERT, Roberta, DistillBERT, and CLIP) finetuned on four NLP\nbenchmarks (SST-2, MRPC, SNLI, and SQuAD) and a language-grounding benchmark\n(MSCOCO). Extensive experiments show that our proposed GradObstinate generates\nmore powerful obstinate adversarial examples, exhibiting a higher attack\nsuccess rate compared to antonym-based methods. Furthermore, to show the\ntransferability of obstinate word substitutions found by GradObstinate, we\nreplace the words in four representative NLP benchmarks with their obstinate\nsubstitutions. Notably, obstinate substitutions exhibit a high success rate\nwhen transferred to other models in black-box settings, including even GPT-3\nand ChatGPT. Examples of obstinate adversarial examples found by GradObstinate\nare available at https://huggingface.co/spaces/anonauthors/SecretLanguage.", "published": "2023-07-24 03:44:17", "link": "http://arxiv.org/abs/2307.12507v2", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Fake News Detection Through Graph-based Neural Networks: A Survey", "abstract": "The popularity of online social networks has enabled rapid dissemination of\ninformation. People now can share and consume information much more rapidly\nthan ever before. However, low-quality and/or accidentally/deliberately fake\ninformation can also spread rapidly. This can lead to considerable and negative\nimpacts on society. Identifying, labelling and debunking online misinformation\nas early as possible has become an increasingly urgent problem. Many methods\nhave been proposed to detect fake news including many deep learning and\ngraph-based approaches. In recent years, graph-based methods have yielded\nstrong results, as they can closely model the social context and propagation\nprocess of online news. In this paper, we present a systematic review of fake\nnews detection studies based on graph-based and deep learning-based techniques.\nWe classify existing graph-based methods into knowledge-driven methods,\npropagation-based methods, and heterogeneous social context-based methods,\ndepending on how a graph structure is constructed to model news related\ninformation flows. We further discuss the challenges and open problems in\ngraph-based fake news detection and identify future research directions.", "published": "2023-07-24 09:30:30", "link": "http://arxiv.org/abs/2307.12639v1", "categories": ["cs.SI", "cs.CL", "cs.GR", "cs.LG"], "primary_category": "cs.SI"}
{"title": "A Model for Every User and Budget: Label-Free and Personalized\n  Mixed-Precision Quantization", "abstract": "Recent advancement in Automatic Speech Recognition (ASR) has produced large\nAI models, which become impractical for deployment in mobile devices. Model\nquantization is effective to produce compressed general-purpose models, however\nsuch models may only be deployed to a restricted sub-domain of interest. We\nshow that ASR models can be personalized during quantization while relying on\njust a small set of unlabelled samples from the target domain. To this end, we\npropose myQASR, a mixed-precision quantization method that generates tailored\nquantization schemes for diverse users under any memory requirement with no\nfine-tuning. myQASR automatically evaluates the quantization sensitivity of\nnetwork layers by analysing the full-precision activation values. We are then\nable to generate a personalised mixed-precision quantization scheme for any\npre-determined memory budget. Results for large-scale ASR models show how\nmyQASR improves performance for specific genders, languages, and speakers.", "published": "2023-07-24 10:03:28", "link": "http://arxiv.org/abs/2307.12659v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Code-Switched Urdu ASR for Noisy Telephonic Environment using Data\n  Centric Approach with Hybrid HMM and CNN-TDNN", "abstract": "Call Centers have huge amount of audio data which can be used for achieving\nvaluable business insights and transcription of phone calls is manually tedious\ntask. An effective Automated Speech Recognition system can accurately\ntranscribe these calls for easy search through call history for specific\ncontext and content allowing automatic call monitoring, improving QoS through\nkeyword search and sentiment analysis. ASR for Call Center requires more\nrobustness as telephonic environment are generally noisy. Moreover, there are\nmany low-resourced languages that are on verge of extinction which can be\npreserved with help of Automatic Speech Recognition Technology. Urdu is the\n$10^{th}$ most widely spoken language in the world, with 231,295,440 worldwide\nstill remains a resource constrained language in ASR. Regional call-center\nconversations operate in local language, with a mix of English numbers and\ntechnical terms generally causing a \"code-switching\" problem. Hence, this paper\ndescribes an implementation framework of a resource efficient Automatic Speech\nRecognition/ Speech to Text System in a noisy call-center environment using\nChain Hybrid HMM and CNN-TDNN for Code-Switched Urdu Language. Using Hybrid\nHMM-DNN approach allowed us to utilize the advantages of Neural Network with\nless labelled data. Adding CNN with TDNN has shown to work better in noisy\nenvironment due to CNN's additional frequency dimension which captures extra\ninformation from noisy speech, thus improving accuracy. We collected data from\nvarious open sources and labelled some of the unlabelled data after analysing\nits general context and content from Urdu language as well as from commonly\nused words from other languages, primarily English and were able to achieve WER\nof 5.2% with noisy as well as clean environment in isolated words or numbers as\nwell as in continuous spontaneous speech.", "published": "2023-07-24 13:04:21", "link": "http://arxiv.org/abs/2307.12759v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "A Real-World WebAgent with Planning, Long Context Understanding, and\n  Program Synthesis", "abstract": "Pre-trained large language models (LLMs) have recently achieved better\ngeneralization and sample efficiency in autonomous web automation. However, the\nperformance on real-world websites has still suffered from (1) open domainness,\n(2) limited context length, and (3) lack of inductive bias on HTML. We\nintroduce WebAgent, an LLM-driven agent that learns from self-experience to\ncomplete tasks on real websites following natural language instructions.\nWebAgent plans ahead by decomposing instructions into canonical\nsub-instructions, summarizes long HTML documents into task-relevant snippets,\nand acts on websites via Python programs generated from those. We design\nWebAgent with Flan-U-PaLM, for grounded code generation, and HTML-T5, new\npre-trained LLMs for long HTML documents using local and global attention\nmechanisms and a mixture of long-span denoising objectives, for planning and\nsummarization. We empirically demonstrate that our modular recipe improves the\nsuccess on real websites by over 50%, and that HTML-T5 is the best model to\nsolve various HTML understanding tasks; achieving 18.7% higher success rate\nthan the prior method on MiniWoB web automation benchmark, and SoTA performance\non Mind2Web, an offline task planning evaluation.", "published": "2023-07-24 14:56:30", "link": "http://arxiv.org/abs/2307.12856v4", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "A Hybrid Machine Learning Model for Classifying Gene Mutations in Cancer\n  using LSTM, BiLSTM, CNN, GRU, and GloVe", "abstract": "In our study, we introduce a novel hybrid ensemble model that synergistically\ncombines LSTM, BiLSTM, CNN, GRU, and GloVe embeddings for the classification of\ngene mutations in cancer. This model was rigorously tested using Kaggle's\nPersonalized Medicine: Redefining Cancer Treatment dataset, demonstrating\nexceptional performance across all evaluation metrics. Notably, our approach\nachieved a training accuracy of 80.6%, precision of 81.6%, recall of 80.6%, and\nan F1 score of 83.1%, alongside a significantly reduced Mean Squared Error\n(MSE) of 2.596. These results surpass those of advanced transformer models and\ntheir ensembles, showcasing our model's superior capability in handling the\ncomplexities of gene mutation classification. The accuracy and efficiency of\ngene mutation classification are paramount in the era of precision medicine,\nwhere tailored treatment plans based on individual genetic profiles can\ndramatically improve patient outcomes and save lives. Our model's remarkable\nperformance highlights its potential in enhancing the precision of cancer\ndiagnoses and treatments, thereby contributing significantly to the advancement\nof personalized healthcare.", "published": "2023-07-24 21:01:46", "link": "http://arxiv.org/abs/2307.14361v3", "categories": ["q-bio.QM", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "q-bio.QM"}
{"title": "LLM-Rec: Personalized Recommendation via Prompting Large Language Models", "abstract": "Text-based recommendation holds a wide range of practical applications due to\nits versatility, as textual descriptions can represent nearly any type of item.\nHowever, directly employing the original item descriptions may not yield\noptimal recommendation performance due to the lack of comprehensive information\nto align with user preferences. Recent advances in large language models (LLMs)\nhave showcased their remarkable ability to harness commonsense knowledge and\nreasoning. In this study, we introduce a novel approach, coined LLM-Rec, which\nincorporates four distinct prompting strategies of text enrichment for\nimproving personalized text-based recommendations. Our empirical experiments\nreveal that using LLM-augmented text significantly enhances recommendation\nquality. Even basic MLP (Multi-Layer Perceptron) models achieve comparable or\neven better results than complex content-based methods. Notably, the success of\nLLM-Rec lies in its prompting strategies, which effectively tap into the\nlanguage model's comprehension of both general and specific item\ncharacteristics. This highlights the importance of employing diverse prompts\nand input augmentation techniques to boost the recommendation effectiveness of\nLLMs.", "published": "2023-07-24 18:47:38", "link": "http://arxiv.org/abs/2307.15780v3", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "On The Role of Reasoning in the Identification of Subtle Stereotypes in\n  Natural Language", "abstract": "Large language models (LLMs) are trained on vast, uncurated datasets that\ncontain various forms of biases and language reinforcing harmful stereotypes\nthat may be subsequently inherited by the models themselves. Therefore, it is\nessential to examine and address biases in language models, integrating\nfairness into their development to ensure that these models do not perpetuate\nsocial biases. In this work, we demonstrate the importance of reasoning in\nzero-shot stereotype identification across several open-source LLMs. Accurate\nidentification of stereotypical language is a complex task requiring a nuanced\nunderstanding of social structures, biases, and existing unfair generalizations\nabout particular groups. While improved accuracy is observed through model\nscaling, the use of reasoning, especially multi-step reasoning, is crucial to\nconsistent performance. Additionally, through a qualitative analysis of select\nreasoning traces, we highlight how reasoning improves not just accuracy, but\nalso the interpretability of model decisions. This work firmly establishes\nreasoning as a critical component in automatic stereotype detection and is a\nfirst step towards stronger stereotype mitigation pipelines for LLMs.", "published": "2023-07-24 15:12:13", "link": "http://arxiv.org/abs/2308.00071v3", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG", "68T50"], "primary_category": "cs.CL"}
{"title": "Getting pwn'd by AI: Penetration Testing with Large Language Models", "abstract": "The field of software security testing, more specifically penetration\ntesting, is an activity that requires high levels of expertise and involves\nmany manual testing and analysis steps. This paper explores the potential usage\nof large-language models, such as GPT3.5, to augment penetration testers with\nAI sparring partners. We explore the feasibility of supplementing penetration\ntesters with AI models for two distinct use cases: high-level task planning for\nsecurity testing assignments and low-level vulnerability hunting within a\nvulnerable virtual machine. For the latter, we implemented a closed-feedback\nloop between LLM-generated low-level actions with a vulnerable virtual machine\n(connected through SSH) and allowed the LLM to analyze the machine state for\nvulnerabilities and suggest concrete attack vectors which were automatically\nexecuted within the virtual machine. We discuss promising initial results,\ndetail avenues for improvement, and close deliberating on the ethics of\nproviding AI-based sparring partners.", "published": "2023-07-24 19:59:22", "link": "http://arxiv.org/abs/2308.00121v3", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Performance of Large Language Models in a Computer Science Degree\n  Program", "abstract": "Large language models such as ChatGPT-3.5 and GPT-4.0 are ubiquitous and\ndominate the current discourse. Their transformative capabilities have led to a\nparadigm shift in how we interact with and utilize (text-based) information.\nEach day, new possibilities to leverage the capabilities of these models\nemerge. This paper presents findings on the performance of different large\nlanguage models in a university of applied sciences' undergraduate computer\nscience degree program. Our primary objective is to assess the effectiveness of\nthese models within the curriculum by employing them as educational aids. By\nprompting the models with lecture material, exercise tasks, and past exams, we\naim to evaluate their proficiency across different computer science domains. We\nshowcase the strong performance of current large language models while\nhighlighting limitations and constraints within the context of such a degree\nprogram. We found that ChatGPT-3.5 averaged 79.9% of the total score in 10\ntested modules, BingAI achieved 68.4%, and LLaMa, in the 65 billion parameter\nvariant, 20%. Despite these convincing results, even GPT-4.0 would not pass the\ndegree program - due to limitations in mathematical calculations.", "published": "2023-07-24 14:17:00", "link": "http://arxiv.org/abs/2308.02432v1", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Enhancing image captioning with depth information using a\n  Transformer-based framework", "abstract": "Captioning images is a challenging scene-understanding task that connects\ncomputer vision and natural language processing. While image captioning models\nhave been successful in producing excellent descriptions, the field has\nprimarily focused on generating a single sentence for 2D images. This paper\ninvestigates whether integrating depth information with RGB images can enhance\nthe captioning task and generate better descriptions. For this purpose, we\npropose a Transformer-based encoder-decoder framework for generating a\nmulti-sentence description of a 3D scene. The RGB image and its corresponding\ndepth map are provided as inputs to our framework, which combines them to\nproduce a better understanding of the input scene. Depth maps could be ground\ntruth or estimated, which makes our framework widely applicable to any RGB\ncaptioning dataset. We explored different fusion approaches to fuse RGB and\ndepth images. The experiments are performed on the NYU-v2 dataset and the\nStanford image paragraph captioning dataset. During our work with the NYU-v2\ndataset, we found inconsistent labeling that prevents the benefit of using\ndepth information to enhance the captioning task. The results were even worse\nthan using RGB images only. As a result, we propose a cleaned version of the\nNYU-v2 dataset that is more consistent and informative. Our results on both\ndatasets demonstrate that the proposed framework effectively benefits from\ndepth information, whether it is ground truth or estimated, and generates\nbetter captions. Code, pre-trained models, and the cleaned version of the\nNYU-v2 dataset will be made publically available.", "published": "2023-07-24 17:31:51", "link": "http://arxiv.org/abs/2308.03767v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "eess.IV"], "primary_category": "cs.CV"}
{"title": "3D-LLM: Injecting the 3D World into Large Language Models", "abstract": "Large language models (LLMs) and Vision-Language Models (VLMs) have been\nproven to excel at multiple tasks, such as commonsense reasoning. Powerful as\nthese models can be, they are not grounded in the 3D physical world, which\ninvolves richer concepts such as spatial relationships, affordances, physics,\nlayout, and so on. In this work, we propose to inject the 3D world into large\nlanguage models and introduce a whole new family of 3D-LLMs. Specifically,\n3D-LLMs can take 3D point clouds and their features as input and perform a\ndiverse set of 3D-related tasks, including captioning, dense captioning, 3D\nquestion answering, task decomposition, 3D grounding, 3D-assisted dialog,\nnavigation, and so on. Using three types of prompting mechanisms that we\ndesign, we are able to collect over 300k 3D-language data covering these tasks.\nTo efficiently train 3D-LLMs, we first utilize a 3D feature extractor that\nobtains 3D features from rendered multi- view images. Then, we use 2D VLMs as\nour backbones to train our 3D-LLMs. By introducing a 3D localization mechanism,\n3D-LLMs can better capture 3D spatial information. Experiments on ScanQA show\nthat our model outperforms state-of-the-art baselines by a large margin (e.g.,\nthe BLEU-1 score surpasses state-of-the-art score by 9%). Furthermore,\nexperiments on our held-in datasets for 3D captioning, task composition, and\n3D-assisted dialogue show that our model outperforms 2D VLMs. Qualitative\nexamples also show that our model could perform more tasks beyond the scope of\nexisting LLMs and VLMs. Project Page: : https://vis-www.cs.umass.edu/3dllm/.", "published": "2023-07-24 17:59:02", "link": "http://arxiv.org/abs/2307.12981v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Integration of Frame- and Label-synchronous Beam Search for Streaming\n  Encoder-decoder Speech Recognition", "abstract": "Although frame-based models, such as CTC and transducers, have an affinity\nfor streaming automatic speech recognition, their decoding uses no future\nknowledge, which could lead to incorrect pruning. Conversely, label-based\nattention encoder-decoder mitigates this issue using soft attention to the\ninput, while it tends to overestimate labels biased towards its training\ndomain, unlike CTC. We exploit these complementary attributes and propose to\nintegrate the frame- and label-synchronous (F-/L-Sync) decoding alternately\nperformed within a single beam-search scheme. F-Sync decoding leads the\ndecoding for block-wise processing, while L-Sync decoding provides the\nprioritized hypotheses using look-ahead future frames within a block. We\nmaintain the hypotheses from both decoding methods to perform effective\npruning. Experiments demonstrate that the proposed search algorithm achieves\nlower error rates compared to the other search methods, while being robust\nagainst out-of-domain situations.", "published": "2023-07-24 13:12:50", "link": "http://arxiv.org/abs/2307.12767v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "An objective evaluation of Hearing Aids and DNN-based speech enhancement\n  in complex acoustic scenes", "abstract": "We investigate the objective performance of five high-end commercially\navailable Hearing Aid (HA) devices compared to DNN-based speech enhancement\nalgorithms in complex acoustic environments. To this end, we measure the HRTFs\nof a single HA device to synthesize a binaural dataset for training two\nstate-of-the-art causal and non-causal DNN enhancement models. We then generate\nan evaluation set of realistic speech-in-noise situations using an Ambisonics\nloudspeaker setup and record with a KU100 dummy head wearing each of the HA\ndevices, both with and without the conventional HA algorithms, applying the DNN\nenhancers to the latter. We find that the DNN-based enhancement outperforms the\nHA algorithms in terms of noise suppression and objective intelligibility\nmetrics.", "published": "2023-07-24 15:32:38", "link": "http://arxiv.org/abs/2307.12888v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Adaptation of Whisper models to child speech recognition", "abstract": "Automatic Speech Recognition (ASR) systems often struggle with transcribing\nchild speech due to the lack of large child speech datasets required to\naccurately train child-friendly ASR models. However, there are huge amounts of\nannotated adult speech datasets which were used to create multilingual ASR\nmodels, such as Whisper. Our work aims to explore whether such models can be\nadapted to child speech to improve ASR for children. In addition, we compare\nWhisper child-adaptations with finetuned self-supervised models, such as\nwav2vec2. We demonstrate that finetuning Whisper on child speech yields\nsignificant improvements in ASR performance on child speech, compared to non\nfinetuned Whisper models. Additionally, utilizing self-supervised Wav2vec2\nmodels that have been finetuned on child speech outperforms Whisper finetuning.", "published": "2023-07-24 12:54:45", "link": "http://arxiv.org/abs/2307.13008v1", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "Self-refining of Pseudo Labels for Music Source Separation with Noisy\n  Labeled Data", "abstract": "Music source separation (MSS) faces challenges due to the limited\navailability of correctly-labeled individual instrument tracks. With the push\nto acquire larger datasets to improve MSS performance, the inevitability of\nencountering mislabeled individual instrument tracks becomes a significant\nchallenge to address. This paper introduces an automated technique for refining\nthe labels in a partially mislabeled dataset. Our proposed self-refining\ntechnique, employed with a noisy-labeled dataset, results in only a 1% accuracy\ndegradation in multi-label instrument recognition compared to a classifier\ntrained on a clean-labeled dataset. The study demonstrates the importance of\nrefining noisy-labeled data in MSS model training and shows that utilizing the\nrefined dataset leads to comparable results derived from a clean-labeled\ndataset. Notably, upon only access to a noisy dataset, MSS models trained on a\nself-refined dataset even outperform those trained on a dataset refined with a\nclassifier trained on clean labels.", "published": "2023-07-24 07:47:21", "link": "http://arxiv.org/abs/2307.12576v1", "categories": ["eess.AS", "cs.IR", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Online Continual Learning in Keyword Spotting for Low-Resource Devices\n  via Pooling High-Order Temporal Statistics", "abstract": "Keyword Spotting (KWS) models on embedded devices should adapt fast to new\nuser-defined words without forgetting previous ones. Embedded devices have\nlimited storage and computational resources, thus, they cannot save samples or\nupdate large models. We consider the setup of embedded online continual\nlearning (EOCL), where KWS models with frozen backbone are trained to\nincrementally recognize new words from a non-repeated stream of samples, seen\none at a time. To this end, we propose Temporal Aware Pooling (TAP) which\nconstructs an enriched feature space computing high-order moments of speech\nfeatures extracted by a pre-trained backbone. Our method, TAP-SLDA, updates a\nGaussian model for each class on the enriched feature space to effectively use\naudio representations. In experimental analyses, TAP-SLDA outperforms\ncompetitors on several setups, backbones, and baselines, bringing a relative\naverage gain of 11.3% on the GSC dataset.", "published": "2023-07-24 10:04:27", "link": "http://arxiv.org/abs/2307.12660v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "IteraTTA: An interface for exploring both text prompts and audio priors\n  in generating music with text-to-audio models", "abstract": "Recent text-to-audio generation techniques have the potential to allow novice\nusers to freely generate music audio. Even if they do not have musical\nknowledge, such as about chord progressions and instruments, users can try\nvarious text prompts to generate audio. However, compared to the image domain,\ngaining a clear understanding of the space of possible music audios is\ndifficult because users cannot listen to the variations of the generated audios\nsimultaneously. We therefore facilitate users in exploring not only text\nprompts but also audio priors that constrain the text-to-audio music generation\nprocess. This dual-sided exploration enables users to discern the impact of\ndifferent text prompts and audio priors on the generation results through\niterative comparison of them. Our developed interface, IteraTTA, is\nspecifically designed to aid users in refining text prompts and selecting\nfavorable audio priors from the generated audios. With this, users can\nprogressively reach their loosely-specified goals while understanding and\nexploring the space of possible results. Our implementation and discussions\nhighlight design considerations that are specifically required for\ntext-to-audio models and how interaction techniques can contribute to their\neffectiveness.", "published": "2023-07-24 11:00:01", "link": "http://arxiv.org/abs/2307.13005v1", "categories": ["eess.AS", "cs.AI", "cs.HC", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Joint speech and overlap detection: a benchmark over multiple audio\n  setup and speech domains", "abstract": "Voice activity and overlapped speech detection (respectively VAD and OSD) are\nkey pre-processing tasks for speaker diarization. The final segmentation\nperformance highly relies on the robustness of these sub-tasks. Recent studies\nhave shown VAD and OSD can be trained jointly using a multi-class\nclassification model. However, these works are often restricted to a specific\nspeech domain, lacking information about the generalization capacities of the\nsystems. This paper proposes a complete and new benchmark of different VAD and\nOSD models, on multiple audio setups (single/multi-channel) and speech domains\n(e.g. media, meeting...). Our 2/3-class systems, which combine a Temporal\nConvolutional Network with speech representations adapted to the setup,\noutperform state-of-the-art results. We show that the joint training of these\ntwo tasks offers similar performances in terms of F1-score to two dedicated VAD\nand OSD systems while reducing the training cost. This unique architecture can\nalso be used for single and multichannel speech processing.", "published": "2023-07-24 14:29:21", "link": "http://arxiv.org/abs/2307.13012v1", "categories": ["cs.SD", "cs.AI", "cs.NE", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
