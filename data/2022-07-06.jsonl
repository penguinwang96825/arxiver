{"title": "Gender Biases and Where to Find Them: Exploring Gender Bias in\n  Pre-Trained Transformer-based Language Models Using Movement Pruning", "abstract": "Language model debiasing has emerged as an important field of study in the\nNLP community. Numerous debiasing techniques were proposed, but bias ablation\nremains an unaddressed issue. We demonstrate a novel framework for inspecting\nbias in pre-trained transformer-based language models via movement pruning.\nGiven a model and a debiasing objective, our framework finds a subset of the\nmodel containing less bias than the original model. We implement our framework\nby pruning the model while fine-tuning it on the debiasing objective. Optimized\nare only the pruning scores - parameters coupled with the model's weights that\nact as gates. We experiment with pruning attention heads, an important building\nblock of transformers: we prune square blocks, as well as establish a new way\nof pruning the entire heads. Lastly, we demonstrate the usage of our framework\nusing gender bias, and based on our findings, we propose an improvement to an\nexisting debiasing method. Additionally, we re-discover a bias-performance\ntrade-off: the better the model performs, the more bias it contains.", "published": "2022-07-06 06:20:35", "link": "http://arxiv.org/abs/2207.02463v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Challenge on Semi-Supervised and Reinforced Task-Oriented Dialog\n  Systems", "abstract": "A challenge on Semi-Supervised and Reinforced Task-Oriented Dialog Systems,\nCo-located with EMNLP2022 SereTOD Workshop.", "published": "2022-07-06 13:23:18", "link": "http://arxiv.org/abs/2207.02657v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rethinking the Value of Gazetteer in Chinese Named Entity Recognition", "abstract": "Gazetteer is widely used in Chinese named entity recognition (NER) to enhance\nspan boundary detection and type classification. However, to further understand\nthe generalizability and effectiveness of gazetteers, the NLP community still\nlacks a systematic analysis of the gazetteer-enhanced NER model. In this paper,\nwe first re-examine the effectiveness several common practices of the\ngazetteer-enhanced NER models and carry out a series of detailed analysis to\nevaluate the relationship between the model performance and the gazetteer\ncharacteristics, which can guide us to build a more suitable gazetteer. The\nfindings of this paper are as follows: (1) the gazetteer improves most of the\nsituations that the traditional NER model datasets are difficult to learn. (2)\nthe performance of model greatly benefits from the high-quality pre-trained\nlexeme embeddings. (3) a good gazetteer should cover more entities that can be\nmatched in both the training set and testing set.", "published": "2022-07-06 16:45:25", "link": "http://arxiv.org/abs/2207.02802v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Aspect-Based Sentiment Analysis using Local Context Focus Mechanism with\n  DeBERTa", "abstract": "Text sentiment analysis, also known as opinion mining, is research on the\ncalculation of people's views, evaluations, attitude and emotions expressed by\nentities. Text sentiment analysis can be divided into text-level sentiment\nanalysis, sen-tence-level sentiment analysis and aspect-level sentiment\nanalysis. Aspect-Based Sentiment Analysis (ABSA) is a fine-grained task in the\nfield of sentiment analysis, which aims to predict the polarity of aspects. The\nresearch of pre-training neural model has significantly improved the\nperformance of many natural language processing tasks. In recent years, pre\ntraining model (PTM) has been applied in ABSA. Therefore, there has been a\nquestion, which is whether PTMs contain sufficient syntactic information for\nABSA. In this paper, we explored the recent DeBERTa model (Decoding-enhanced\nBERT with disentangled attention) to solve Aspect-Based Sentiment Analysis\nproblem. DeBERTa is a kind of neural language model based on transformer, which\nuses self-supervised learning to pre-train on a large number of original text\ncorpora. Based on the Local Context Focus (LCF) mechanism, by integrating\nDeBERTa model, we purpose a multi-task learning model for aspect-based\nsentiment analysis. The experiments result on the most commonly used the laptop\nand restaurant datasets of SemEval-2014 and the ACL twitter dataset show that\nLCF mechanism with DeBERTa has significant improvement.", "published": "2022-07-06 03:50:31", "link": "http://arxiv.org/abs/2207.02424v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Compositional Generalization in Grounded Language Learning via Induced\n  Model Sparsity", "abstract": "We provide a study of how induced model sparsity can help achieve\ncompositional generalization and better sample efficiency in grounded language\nlearning problems. We consider simple language-conditioned navigation problems\nin a grid world environment with disentangled observations. We show that\nstandard neural architectures do not always yield compositional generalization.\nTo address this, we design an agent that contains a goal identification module\nthat encourages sparse correlations between words in the instruction and\nattributes of objects, composing them together to find the goal. The output of\nthe goal identification module is the input to a value iteration network\nplanner. Our agent maintains a high level of performance on goals containing\nnovel combinations of properties even when learning from a handful of\ndemonstrations. We examine the internal representations of our agent and find\nthe correct correspondences between words in its dictionary and attributes in\nthe environment.", "published": "2022-07-06 08:46:27", "link": "http://arxiv.org/abs/2207.02518v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Role of Complex NLP in Transformers for Text Ranking?", "abstract": "Even though term-based methods such as BM25 provide strong baselines in\nranking, under certain conditions they are dominated by large pre-trained\nmasked language models (MLMs) such as BERT. To date, the source of their\neffectiveness remains unclear. Is it their ability to truly understand the\nmeaning through modeling syntactic aspects? We answer this by manipulating the\ninput order and position information in a way that destroys the natural\nsequence order of query and passage and shows that the model still achieves\ncomparable performance. Overall, our results highlight that syntactic aspects\ndo not play a critical role in the effectiveness of re-ranking with BERT. We\npoint to other mechanisms such as query-passage cross-attention and richer\nembeddings that capture word meanings based on aggregated context regardless of\nthe word order for being the main attributions for its superior performance.", "published": "2022-07-06 08:54:18", "link": "http://arxiv.org/abs/2207.02522v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learning to Diversify for Product Question Generation", "abstract": "We address the product question generation task. For a given product\ndescription, our goal is to generate questions that reflect potential user\ninformation needs that are either missing or not well covered in the\ndescription. Moreover, we wish to cover diverse user information needs that may\nspan a multitude of product types. To this end, we first show how the T5\npre-trained Transformer encoder-decoder model can be fine-tuned for the task.\nYet, while the T5 generated questions have a reasonable quality compared to the\nstate-of-the-art method for the task (KPCNet), many of such questions are still\ntoo general, resulting in a sub-optimal global question diversity. As an\nalternative, we propose a novel learning-to-diversify (LTD) fine-tuning\napproach that allows to enrich the language learned by the underlying\nTransformer model. Our empirical evaluation shows that, using our approach\nsignificantly improves the global diversity of the underlying Transformer\nmodel, while preserves, as much as possible, its generation relevance.", "published": "2022-07-06 09:26:41", "link": "http://arxiv.org/abs/2207.02534v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Knowing Earlier what Right Means to You: A Comprehensive VQA Dataset for\n  Grounding Relative Directions via Multi-Task Learning", "abstract": "Spatial reasoning poses a particular challenge for intelligent agents and is\nat the same time a prerequisite for their successful interaction and\ncommunication in the physical world. One such reasoning task is to describe the\nposition of a target object with respect to the intrinsic orientation of some\nreference object via relative directions. In this paper, we introduce\nGRiD-A-3D, a novel diagnostic visual question-answering (VQA) dataset based on\nabstract objects. Our dataset allows for a fine-grained analysis of end-to-end\nVQA models' capabilities to ground relative directions. At the same time, model\ntraining requires considerably fewer computational resources compared with\nexisting datasets, yet yields a comparable or even higher performance. Along\nwith the new dataset, we provide a thorough evaluation based on two widely\nknown end-to-end VQA architectures trained on GRiD-A-3D. We demonstrate that\nwithin a few epochs, the subtasks required to reason over relative directions,\nsuch as recognizing and locating objects in a scene and estimating their\nintrinsic orientations, are learned in the order in which relative directions\nare intuitively processed.", "published": "2022-07-06 12:31:49", "link": "http://arxiv.org/abs/2207.02624v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "BioTABQA: Instruction Learning for Biomedical Table Question Answering", "abstract": "Table Question Answering (TQA) is an important but under-explored task. Most\nof the existing QA datasets are in unstructured text format and only few of\nthem use tables as the context. To the best of our knowledge, none of TQA\ndatasets exist in the biomedical domain where tables are frequently used to\npresent information. In this paper, we first curate a table question answering\ndataset, BioTABQA, using 22 templates and the context from a biomedical\ntextbook on differential diagnosis. BioTABQA can not only be used to teach a\nmodel how to answer questions from tables but also evaluate how a model\ngeneralizes to unseen questions, an important scenario for biomedical\napplications. To achieve the generalization evaluation, we divide the templates\ninto 17 training and 5 cross-task evaluations. Then, we develop two baselines\nusing single and multi-tasks learning on BioTABQA. Furthermore, we explore\ninstructional learning, a recent technique showing impressive generalizing\nperformance. Experimental results show that our instruction-tuned model\noutperforms single and multi-task baselines on an average by ~23% and ~6%\nacross various evaluation settings, and more importantly, instruction-tuned\nmodel outperforms baselines by ~5% on cross-tasks.", "published": "2022-07-06 03:40:10", "link": "http://arxiv.org/abs/2207.02419v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Early Discovery of Emerging Entities in Persian Twitter with Semantic\n  Similarity", "abstract": "Discovering emerging entities (EEs) is the problem of finding entities before\ntheir establishment. These entities can be critical for individuals, companies,\nand governments. Many of these entities can be discovered on social media\nplatforms, e.g. Twitter. These identities have been the spot of research in\nacademia and industry in recent years. Similar to any machine learning problem,\ndata availability is one of the major challenges in this problem. This paper\nproposes EEPT. That is an online clustering method able to discover EEs without\nany need for training on a dataset. Additionally, due to the lack of a proper\nevaluation metric, this paper uses a new metric to evaluate the results. The\nresults show that EEPT is promising and finds significant entities before their\nestablishment.", "published": "2022-07-06 04:46:07", "link": "http://arxiv.org/abs/2207.02434v2", "categories": ["cs.CL", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Brain-inspired probabilistic generative model for double articulation\n  analysis of spoken language", "abstract": "The human brain, among its several functions, analyzes the double\narticulation structure in spoken language, i.e., double articulation analysis\n(DAA). A hierarchical structure in which words are connected to form a sentence\nand words are composed of phonemes or syllables is called a double articulation\nstructure. Where and how DAA is performed in the human brain has not been\nestablished, although some insights have been obtained. In addition, existing\ncomputational models based on a probabilistic generative model (PGM) do not\nincorporate neuroscientific findings, and their consistency with the brain has\nnot been previously discussed. This study compared, mapped, and integrated\nthese existing computational models with neuroscientific findings to bridge\nthis gap, and the findings are relevant for future applications and further\nresearch. This study proposes a PGM for a DAA hypothesis that can be realized\nin the brain based on the outcomes of several neuroscientific surveys. The\nstudy involved (i) investigation and organization of anatomical structures\nrelated to spoken language processing, and (ii) design of a PGM that matches\nthe anatomy and functions of the region of interest. Therefore, this study\nprovides novel insights that will be foundational to further exploring DAA in\nthe brain.", "published": "2022-07-06 06:03:10", "link": "http://arxiv.org/abs/2207.02457v1", "categories": ["q-bio.NC", "cs.AI", "cs.CL"], "primary_category": "q-bio.NC"}
{"title": "Kaggle Competition: Cantonese Audio-Visual Speech Recognition for In-car\n  Commands", "abstract": "With the rise of deep learning and intelligent vehicles, the smart assistant\nhas become an essential in-car component to facilitate driving and provide\nextra functionalities. In-car smart assistants should be able to process\ngeneral as well as car-related commands and perform corresponding actions,\nwhich eases driving and improves safety. However, in this research field, most\ndatasets are in major languages, such as English and Chinese. There is a huge\ndata scarcity issue for low-resource languages, hindering the development of\nresearch and applications for broader communities. Therefore, it is crucial to\nhave more benchmarks to raise awareness and motivate the research in\nlow-resource languages. To mitigate this problem, we collect a new dataset,\nnamely Cantonese In-car Audio-Visual Speech Recognition (CI-AVSR), for in-car\nspeech recognition in the Cantonese language with video and audio data.\nTogether with it, we propose Cantonese Audio-Visual Speech Recognition for\nIn-car Commands as a new challenge for the community to tackle low-resource\nspeech recognition under in-car scenarios.", "published": "2022-07-06 13:31:56", "link": "http://arxiv.org/abs/2207.02663v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Strong Heuristics for Named Entity Linking", "abstract": "Named entity linking (NEL) in news is a challenging endeavour due to the\nfrequency of unseen and emerging entities, which necessitates the use of\nunsupervised or zero-shot methods. However, such methods tend to come with\ncaveats, such as no integration of suitable knowledge bases (like Wikidata) for\nemerging entities, a lack of scalability, and poor interpretability. Here, we\nconsider person disambiguation in Quotebank, a massive corpus of\nspeaker-attributed quotations from the news, and investigate the suitability of\nintuitive, lightweight, and scalable heuristics for NEL in web-scale corpora.\nOur best performing heuristic disambiguates 94% and 63% of the mentions on\nQuotebank and the AIDA-CoNLL benchmark, respectively. Additionally, the\nproposed heuristics compare favourably to the state-of-the-art unsupervised and\nzero-shot methods, Eigenthemes and mGENRE, respectively, thereby serving as\nstrong baselines for unsupervised and zero-shot entity linking.", "published": "2022-07-06 17:29:30", "link": "http://arxiv.org/abs/2207.02824v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Branchformer: Parallel MLP-Attention Architectures to Capture Local and\n  Global Context for Speech Recognition and Understanding", "abstract": "Conformer has proven to be effective in many speech processing tasks. It\ncombines the benefits of extracting local dependencies using convolutions and\nglobal dependencies using self-attention. Inspired by this, we propose a more\nflexible, interpretable and customizable encoder alternative, Branchformer,\nwith parallel branches for modeling various ranged dependencies in end-to-end\nspeech processing. In each encoder layer, one branch employs self-attention or\nits variant to capture long-range dependencies, while the other branch utilizes\nan MLP module with convolutional gating (cgMLP) to extract local relationships.\nWe conduct experiments on several speech recognition and spoken language\nunderstanding benchmarks. Results show that our model outperforms both\nTransformer and cgMLP. It also matches with or outperforms state-of-the-art\nresults achieved by Conformer. Furthermore, we show various strategies to\nreduce computation thanks to the two-branch architecture, including the ability\nto have variable inference complexity in a single trained model. The weights\nlearned for merging branches indicate how local and global dependencies are\nutilized in different layers, which benefits model designing.", "published": "2022-07-06 21:08:10", "link": "http://arxiv.org/abs/2207.02971v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "GraphCFC: A Directed Graph Based Cross-Modal Feature Complementation\n  Approach for Multimodal Conversational Emotion Recognition", "abstract": "Emotion Recognition in Conversation (ERC) plays a significant part in\nHuman-Computer Interaction (HCI) systems since it can provide empathetic\nservices. Multimodal ERC can mitigate the drawbacks of uni-modal approaches.\nRecently, Graph Neural Networks (GNNs) have been widely used in a variety of\nfields due to their superior performance in relation modeling. In multimodal\nERC, GNNs are capable of extracting both long-distance contextual information\nand inter-modal interactive information. Unfortunately, since existing methods\nsuch as MMGCN directly fuse multiple modalities, redundant information may be\ngenerated and diverse information may be lost. In this work, we present a\ndirected Graph based Cross-modal Feature Complementation (GraphCFC) module that\ncan efficiently model contextual and interactive information. GraphCFC\nalleviates the problem of heterogeneity gap in multimodal fusion by utilizing\nmultiple subspace extractors and Pair-wise Cross-modal Complementary (PairCC)\nstrategy. We extract various types of edges from the constructed graph for\nencoding, thus enabling GNNs to extract crucial contextual and interactive\ninformation more accurately when performing message passing. Furthermore, we\ndesign a GNN structure called GAT-MLP, which can provide a new unified network\nframework for multimodal learning. The experimental results on two benchmark\ndatasets show that our GraphCFC outperforms the state-of-the-art (SOTA)\napproaches.", "published": "2022-07-06 13:56:48", "link": "http://arxiv.org/abs/2207.12261v4", "categories": ["cs.CL", "cs.LG", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Improving Streaming End-to-End ASR on Transformer-based Causal Models\n  with Encoder States Revision Strategies", "abstract": "There is often a trade-off between performance and latency in streaming\nautomatic speech recognition (ASR). Traditional methods such as look-ahead and\nchunk-based methods, usually require information from future frames to advance\nrecognition accuracy, which incurs inevitable latency even if the computation\nis fast enough. A causal model that computes without any future frames can\navoid this latency, but its performance is significantly worse than traditional\nmethods. In this paper, we propose corresponding revision strategies to improve\nthe causal model. Firstly, we introduce a real-time encoder states revision\nstrategy to modify previous states. Encoder forward computation starts once the\ndata is received and revises the previous encoder states after several frames,\nwhich is no need to wait for any right context. Furthermore, a CTC spike\nposition alignment decoding algorithm is designed to reduce time costs brought\nby the revision strategy. Experiments are all conducted on Librispeech\ndatasets. Fine-tuning on the CTC-based wav2vec2.0 model, our best method can\nachieve 3.7/9.2 WERs on test-clean/other sets, which is also competitive with\nthe chunk-based methods and the knowledge distillation methods.", "published": "2022-07-06 07:59:54", "link": "http://arxiv.org/abs/2207.02495v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Low-resource Low-footprint Wake-word Detection using Knowledge\n  Distillation", "abstract": "As virtual assistants have become more diverse and specialized, so has the\ndemand for application or brand-specific wake words. However, the\nwake-word-specific datasets typically used to train wake-word detectors are\ncostly to create. In this paper, we explore two techniques to leverage acoustic\nmodeling data for large-vocabulary speech recognition to improve a\npurpose-built wake-word detector: transfer learning and knowledge distillation.\nWe also explore how these techniques interact with time-synchronous training\ntargets to improve detection latency. Experiments are presented on the\nopen-source \"Hey Snips\" dataset and a more challenging in-house far-field\ndataset. Using phone-synchronous targets and knowledge distillation from a\nlarge acoustic model, we are able to improve accuracy across dataset sizes for\nboth datasets while reducing latency.", "published": "2022-07-06 15:45:11", "link": "http://arxiv.org/abs/2207.03331v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
