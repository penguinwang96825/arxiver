{"title": "(Non-Monotonic) Effects of Productivity and Credit Constraints on Equilibrium Aggregate Production in General Equilibrium Models with Heterogeneous Producers", "abstract": "In a market economy, the aggregate production level depends not only on the\naggregate variables but also on the distribution of individual characteristics\n(e.g., productivity, credit limit, ...). We point out that, due to financial\nfrictions, the equilibrium aggregate production may be non-monotonic in both\nindividual productivity and credit limit. We provide conditions under which\nthis phenomenon happens. By consequence, improving productivity or relaxing\ncredit limit of firms may not necessarily be beneficial to economic\ndevelopment.", "published": "2025-01-22 08:16:49", "link": "http://arxiv.org/abs/2501.12700v1", "categories": ["q-fin.CP"], "primary_category": "q-fin.CP"}
{"title": "Marketron games: Self-propelling stocks vs dumb money and metastable dynamics of the Good, Bad and Ugly markets", "abstract": "We present a model of price formation in an inelastic market whose dynamics\nare partially driven by both money flows and their impact on asset prices. The\nmoney flow to the market is viewed as an investment policy of outside\ninvestors. For the price impact effect, we use an impact function that\nincorporates the phenomena of market inelasticity and saturation from new money\n(the $dumb \\; money$ effect). Due to the dependence of market investors' flows\non market performance, the model implies a feedback mechanism that gives rise\nto nonlinear dynamics. Consequently, the market price dynamics are seen as a\nnonlinear diffusion of a particle (the $marketron$) in a two-dimensional space\nformed by the log-price $x$ and a memory variable $y$. The latter stores\ninformation about past money flows, so that the dynamics are non-Markovian in\nthe log price $x$ alone, but Markovian in the pair $(x,y)$, bearing a strong\nresemblance to spiking neuron models in neuroscience. In addition to market\nflows, the model dynamics are partially driven by return predictors, modeled as\nunobservable Ornstein-Uhlenbeck processes. By using a new interpretation of\npredictive signals as $self$-$propulsion$ components of the price dynamics, we\ntreat the marketron as an active particle, amenable to methods developed in the\nphysics of active matter. We show that, depending on the choice of parameters,\nour model can produce a rich variety of interesting dynamic scenarios. In\nparticular, it predicts three distinct regimes of the market, which we call the\n$Good$, the $Bad$, and the $Ugly$ markets. The latter regime describes a\nscenario of a total market collapse or, alternatively, a corporate default\nevent, depending on whether our model is applied to the whole market or an\nindividual stock.", "published": "2025-01-22 06:30:26", "link": "http://arxiv.org/abs/2501.12676v2", "categories": ["q-fin.MF", "q-fin.CP"], "primary_category": "q-fin.MF"}
{"title": "Forecasting of Bitcoin Prices Using Hashrate Features: Wavelet and Deep Stacking Approach", "abstract": "Digital currencies have become popular in the last decade due to their\nnon-dependency and decentralized nature. The price of these currencies has seen\na lot of fluctuations at times, which has increased the need for prediction. As\ntheir most popular, Bitcoin(BTC) has become a research hotspot. The main\nchallenge and trend of digital currencies, especially BTC, is price\nfluctuations, which require studying the basic price prediction model. This\nresearch presents a classification and regression model based on stack deep\nlearning that uses a wavelet to remove noise to predict movements and prices of\nBTC at different time intervals. The proposed model based on the stacking\ntechnique uses models based on deep learning, especially neural networks and\ntransformers, for one, seven, thirty and ninety-day forecasting. Three feature\nselection models, Chi2, RFE and Embedded, were also applied to the data in the\npre-processing stage. The classification model achieved 63\\% accuracy for\npredicting the next day and 64\\%, 67\\% and 82\\% for predicting the seventh,\nthirty and ninety days, respectively. For daily price forecasting, the\npercentage error was reduced to 0.58, while the error ranged from 2.72\\% to\n2.85\\% for seven- to ninety-day horizons. These results show that the proposed\nmodel performed better than other models in the literature.", "published": "2025-01-22 09:31:00", "link": "http://arxiv.org/abs/2501.13136v1", "categories": ["q-fin.ST", "cs.AI", "cs.LG"], "primary_category": "q-fin.ST"}
{"title": "Optimal Rebate Design: Incentives, Competition and Efficiency in Auction Markets", "abstract": "This study explores the design of an efficient rebate policy in auction\nmarkets, focusing on a continuous-time setting with competition among market\nparticipants. In this model, a stock exchange collects transaction fees from\nauction investors executing block trades to buy or sell a risky asset, then\nredistributes these fees as rebates to competing market makers submitting limit\norders. Market makers influence both the price at which the asset trades and\ntheir arrival intensity in the auction. We frame this problem as a\nprincipal-multi-agent problem and provide necessary and sufficient conditions\nto characterize the Nash equilibrium among market makers. The exchange's\noptimization problem is formulated as a high-dimensional\nHamilton-Jacobi-Bellman equation with Poisson jump processes, which is solved\nusing a verification result. To numerically compute the optimal rebate and\ntransaction fee policies, we apply the Deep BSDE method. Our results show that\noptimal transaction fees and rebate structures improve market efficiency by\nnarrowing the spread between the auction clearing price and the asset's\nfundamental value, while ensuring a minimal gain for both market makers indexed\non the price of the asset on a coexisting limit order book.", "published": "2025-01-22 02:34:43", "link": "http://arxiv.org/abs/2501.12591v1", "categories": ["q-fin.TR", "math.OC", "math.PR"], "primary_category": "q-fin.TR"}
{"title": "O1-Pruner: Length-Harmonizing Fine-Tuning for O1-Like Reasoning Pruning", "abstract": "Recently, long-thought reasoning LLMs, such as OpenAI's O1, adopt extended\nreasoning processes similar to how humans ponder over complex problems. This\nreasoning paradigm significantly enhances the model's problem-solving abilities\nand has achieved promising results. However, long-thought reasoning process\nleads to a substantial increase in inference time. A pressing challenge is\nreducing the inference overhead of long-thought LLMs while ensuring accuracy.\nIn this paper, we experimentally demonstrate that long-thought reasoning models\nstruggle to effectively allocate token budgets based on problem difficulty and\nreasoning redundancies. To address this, we propose Length-Harmonizing\nFine-Tuning (O1-Pruner), aiming at minimizing reasoning overhead while\nmaintaining accuracy. This effective fine-tuning method first estimates the\nLLM's baseline performance through pre-sampling and then uses RL-style\nfine-tuning to encourage the model to generate shorter reasoning processes\nunder accuracy constraints. This allows the model to achieve efficient\nreasoning with lower redundancy while maintaining accuracy. Experiments on\nvarious mathematical reasoning benchmarks show that O1-Pruner not only\nsignificantly reduces inference overhead but also achieves higher accuracy,\nproviding a novel and promising solution to this challenge. Our code is coming\nsoon at https://github.com/StarDewXXX/O1-Pruner", "published": "2025-01-22 01:35:11", "link": "http://arxiv.org/abs/2501.12570v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Quantification of Large Language Model Distillation", "abstract": "Model distillation is a fundamental technique in building large language\nmodels (LLMs), transferring knowledge from a teacher model to a student model.\nHowever, distillation can lead to model homogenization, reducing diversity\namong models and impairing their ability to robustly handle complex or novel\ntasks. These limitations underscore the need to systematically quantify the\ndistillation process and its impact. In this work, we propose a framework to\nevaluate and quantify model distillation. Our method addresses two key aspects:\n(1) Identifying identity cognition contradictions to assess discrepancies in\nhow models perceive and represent identity-related information, and (2)\nAnalyzing multi-granularity response similarities across models to measure the\nextent of homogenization. Experimental results demonstrate two key insights:\n(1) Well-known closed-source and open-source LLMs usually exhibit high\ndistillation degrees, except for Claude, Doubao, and Gemini. (2) Base LLMs show\nhigher distillation degrees compared to aligned LLMs. By offering a systematic\napproach to improve the transparency of LLM data distillation, we call for LLMs\nwith more independent development and more transparent technical reports to\nimprove LLMs' robustness and safety. The code and data are available under\nhttps://github.com/Aegis1863/LLMs-Distillation-Quantification.", "published": "2025-01-22 03:57:52", "link": "http://arxiv.org/abs/2501.12619v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extracting General-use Transformers for Low-resource Languages via\n  Knowledge Distillation", "abstract": "In this paper, we propose the use of simple knowledge distillation to produce\nsmaller and more efficient single-language transformers from Massively\nMultilingual Transformers (MMTs) to alleviate tradeoffs associated with the use\nof such in low-resource settings. Using Tagalog as a case study, we show that\nthese smaller single-language models perform on-par with strong baselines in a\nvariety of benchmark tasks in a much more efficient manner. Furthermore, we\ninvestigate additional steps during the distillation process that improves the\nsoft-supervision of the target language, and provide a number of analyses and\nablations to show the efficacy of the proposed method.", "published": "2025-01-22 05:46:27", "link": "http://arxiv.org/abs/2501.12660v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Training Dialogue Systems by AI Feedback for Improving Overall Dialogue\n  Impression", "abstract": "To improve user engagement during conversations with dialogue systems, we\nmust improve individual dialogue responses and dialogue impressions such as\nconsistency, personality, and empathy throughout the entire dialogue. While\nsuch dialogue systems have been developing rapidly with the help of large\nlanguage models (LLMs), reinforcement learning from AI feedback (RLAIF) has\nattracted attention to align LLM-based dialogue models for such dialogue\nimpressions. In RLAIF, a reward model based on another LLM is used to create a\ntraining signal for an LLM-based dialogue model using zero-shot/few-shot\nprompting techniques. However, evaluating an entire dialogue only by prompting\nLLMs is challenging. In this study, the supervised fine-tuning (SFT) of LLMs\nprepared reward models corresponding to 12 metrics related to the impression of\nthe entire dialogue for evaluating dialogue responses. We tuned our dialogue\nmodels using the reward model signals as feedback to improve the impression of\nthe system. The results of automatic and human evaluations showed that tuning\nthe dialogue model using our reward model corresponding to dialogue impression\nimproved the evaluation of individual metrics and the naturalness of the\ndialogue response.", "published": "2025-01-22 08:14:51", "link": "http://arxiv.org/abs/2501.12698v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLMs as Repositories of Factual Knowledge: Limitations and Solutions", "abstract": "LLMs' sources of knowledge are data snapshots containing factual information\nabout entities collected at different timestamps and from different media types\n(e.g. wikis, social media, etc.). Such unstructured knowledge is subject to\nchange due to updates through time from past to present. Equally important are\nthe inconsistencies and inaccuracies occurring in different information\nsources. Consequently, the model's knowledge about an entity may be perturbed\nwhile training over the sequence of snapshots or at inference time, resulting\nin inconsistent and inaccurate model performance. In this work, we study the\nappropriateness of Large Language Models (LLMs) as repositories of factual\nknowledge. We consider twenty-four state-of-the-art LLMs that are either\nclosed-, partially (weights), or fully (weight and training data) open-source.\nWe evaluate their reliability in responding to time-sensitive factual questions\nin terms of accuracy and consistency when prompts are perturbed. We further\nevaluate the effectiveness of state-of-the-art methods to improve LLMs'\naccuracy and consistency. We then propose \"ENtity-Aware Fine-tuning\" (ENAF), a\nsoft neurosymbolic approach aimed at providing a structured representation of\nentities during fine-tuning to improve the model's performance.", "published": "2025-01-22 10:16:53", "link": "http://arxiv.org/abs/2501.12774v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Regularization, Semi-supervision, and Supervision for a Plausible\n  Attention-Based Explanation", "abstract": "Attention mechanism is contributing to the majority of recent advances in\nmachine learning for natural language processing. Additionally, it results in\nan attention map that shows the proportional influence of each input in its\ndecision. Empirical studies postulate that attention maps can be provided as an\nexplanation for model output. However, it is still questionable to ask whether\nthis explanation helps regular people to understand and accept the model output\n(the plausibility of the explanation). Recent studies show that attention\nweights in the RNN encoders are hardly plausible because they spread on input\ntokens. We thus propose 3 additional constraints to the learning objective\nfunction to improve the plausibility of the attention map: regularization to\nincrease the attention weight sparsity, semi-supervision to supervise the map\nby a heuristic and supervision by human annotation. Results show that all\ntechniques can improve the attention map plausibility at some level. We also\nobserve that specific instructions for human annotation might have a negative\neffect on classification performance. Beyond the attention map, the result of\nexperiments on text classification tasks also shows that no matter how the\nconstraint brings the gain, the contextualization layer plays a crucial role in\nfinding the right space for finding plausible tokens.", "published": "2025-01-22 10:17:20", "link": "http://arxiv.org/abs/2501.12775v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generation of Standardized E-Learning Contents from Digital Medical\n  Collections", "abstract": "In this paper, we describe an approach to transforming the huge amount of\nmedical knowledge available in existing online medical collections into\nstandardized learning packages ready to be integrated into the most popular\ne-learning platforms. The core of our approach is a tool called Clavy, which\nmakes it possible to retrieve pieces of content in medical collections, to\ntransform this content into meaningful learning units, and to export it in the\nform of standardized learning packages. In addition to describing the approach,\nwe demonstrate its feasibility by applying it to the generation of IMS content\npackages from MedPix, a popular online database of medical cases in the domain\nof radiology.", "published": "2025-01-22 10:55:16", "link": "http://arxiv.org/abs/2501.12794v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ACEBench: Who Wins the Match Point in Tool Usage?", "abstract": "Large Language Models (LLMs) have demonstrated significant potential in\ndecision-making and reasoning, particularly when integrated with various tools\nto effectively solve complex problems. However, existing benchmarks for\nevaluating LLMs' tool usage face several limitations: (1) limited evaluation\nscenarios, often lacking assessments in real multi-turn dialogue contexts; (2)\nnarrow evaluation dimensions, with insufficient detailed assessments of how\nLLMs use tools; and (3) reliance on LLMs or real API executions for evaluation,\nwhich introduces significant overhead. To address these challenges, we\nintroduce ACEBench, a comprehensive benchmark for assessing tool usage in LLMs.\nACEBench categorizes data into three primary types based on evaluation\nmethodology: Normal, Special, and Agent. \"Normal\" evaluates tool usage in basic\nscenarios; \"Special\" evaluates tool usage in situations with ambiguous or\nincomplete instructions; \"Agent\" evaluates tool usage through multi-agent\ninteractions to simulate real-world, multi-turn dialogues. We conducted\nextensive experiments using ACEBench, analyzing various LLMs in-depth and\nproviding a more granular examination of error causes across different data\ntypes.", "published": "2025-01-22 12:59:08", "link": "http://arxiv.org/abs/2501.12851v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WisdomBot: Tuning Large Language Models with Artificial Intelligence\n  Knowledge", "abstract": "Large language models (LLMs) have emerged as powerful tools in natural\nlanguage processing (NLP), showing a promising future of artificial generated\nintelligence (AGI). Despite their notable performance in the general domain,\nLLMs have remained suboptimal in the field of education, owing to the unique\nchallenges presented by this domain, such as the need for more specialized\nknowledge, the requirement for personalized learning experiences, and the\nnecessity for concise explanations of complex concepts. To address these\nissues, this paper presents a novel LLM for education named WisdomBot, which\ncombines the power of LLMs with educational theories, enabling their seamless\nintegration into educational contexts. To be specific, we harness\nself-instructed knowledge concepts and instructions under the guidance of\nBloom's Taxonomy as training data. To further enhance the accuracy and\nprofessionalism of model's response on factual questions, we introduce two key\nenhancements during inference, i.e., local knowledge base retrieval\naugmentation and search engine retrieval augmentation during inference. We\nsubstantiate the effectiveness of our approach by applying it to several\nChinese LLMs, thereby showcasing that the fine-tuned models can generate more\nreliable and professional responses.", "published": "2025-01-22 13:36:46", "link": "http://arxiv.org/abs/2501.12877v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Test-Time Preference Optimization: On-the-Fly Alignment via Iterative\n  Textual Feedback", "abstract": "Large language models (LLMs) demonstrate impressive performance but lack the\nflexibility to adapt to human preferences quickly without retraining. In this\nwork, we introduce Test-time Preference Optimization (TPO), a framework that\naligns LLM outputs with human preferences during inference, removing the need\nto update model parameters. Rather than relying on purely numerical rewards,\nTPO translates reward signals into textual critiques and uses them as textual\nrewards to iteratively refine its response. Evaluations on benchmarks covering\ninstruction following, preference alignment, safety, and mathematics reveal\nthat TPO progressively improves alignment with human preferences. Notably,\nafter only a few TPO steps, the initially unaligned Llama-3.1-70B-SFT model can\nsurpass the aligned counterpart, Llama-3.1-70B-Instruct. Furthermore, TPO\nscales efficiently with both the search width and depth during inference.\nThrough case studies, we illustrate how TPO exploits the innate capacity of LLM\nto interpret and act upon reward signals. Our findings establish TPO as a\npractical, lightweight alternative for test-time preference optimization,\nachieving alignment on the fly. Our code is publicly available at\nhttps://github.com/yafuly/TPO.", "published": "2025-01-22 14:15:46", "link": "http://arxiv.org/abs/2501.12895v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Punctuation patterns in \"Finnegans Wake\" by James Joyce are largely\n  translation-invariant", "abstract": "The complexity characteristics of texts written in natural languages are\nsignificantly related to the rules of punctuation. In particular, the distances\nbetween punctuation marks measured by the number of words quite universally\nfollow the family of Weibull distributions known from survival analyses.\nHowever, the values of two parameters marking specific forms of these\ndistributions distinguish specific languages. This is such a strong constraint\nthat the punctuation distributions of texts translated from the original\nlanguage into another adopt quantitative characteristics of the target\nlanguage. All these changes take place within Weibull distributions such that\nthe corresponding hazard functions are always increasing. Recent previous\nresearch shows that James Joyce's famous \"Finnegans Wake\" is subject to such\nextreme distribution from the Weibull family that the corresponding hazard\nfunction is clearly decreasing. At the same time, the distances of sentence\nending punctuation marks, determining the variability of sentence length, have\nan almost perfect multifractal organization, so far to such an extent found\nnowhere else in the literature. In the present contribution based on several\navailable translations (Dutch, French, German, Polish, Russian) of \"Finnegans\nWake\", it is shown that the punctuation characteristics of this work remain\nlargely translation invariant, contrary to the common cases. These observations\nmay constitute further evidence that \"Finnegans Wake\" is a translinguistic work\nin this respect as well, in line with Joyce's original intention.", "published": "2025-01-22 15:27:43", "link": "http://arxiv.org/abs/2501.12954v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multifractal hopscotch in \"Hopscotch\" by Julio Cortazar", "abstract": "Punctuation is the main factor introducing correlations in natural language\nwritten texts and it crucially impacts their overall effectiveness,\nexpressiveness, and readability. Punctuation marks at the end of sentences are\nof particular importance as their distribution can determine various complexity\nfeatures of written natural language. Here, the sentence length variability\n(SLV) time series representing \"Hopscotch\" by Julio Cortazar are subjected to\nquantitative analysis with an attempt to identify their distribution type,\nlong-memory effects, and potential multiscale patterns. The analyzed novel is\nan important and innovative piece of literature whose essential property is\nfreedom of movement between its building blocks given to a reader by the\nauthor. The statistical consequences of this freedom are closely investigated\nin both the original, Spanish version of the novel, and its translations into\nEnglish and Polish. Clear evidence of rich multifractality in the SLV dynamics,\nwith a left-sided asymmetry, however, is observed in all three language\nversions as well as in the versions with differently ordered chapters.", "published": "2025-01-22 15:28:24", "link": "http://arxiv.org/abs/2501.12955v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Prompt Compression with Evaluator Heads for Long-Context\n  Transformer Inference", "abstract": "Although applications involving long-context inputs are crucial for the\neffective utilization of large language models (LLMs), they also result in\nincreased computational costs and reduced performance. To address this\nchallenge, we propose an efficient, training-free prompt compression method\nthat retains key information within compressed prompts. We identify specific\nattention heads in transformer-based LLMs, which we designate as evaluator\nheads, that are capable of selecting tokens in long inputs that are most\nsignificant for inference. Building on this discovery, we develop EHPC, an\nEvaluator Head-based Prompt Compression method, which enables LLMs to rapidly\n\"skim through\" input prompts by leveraging only the first few layers with\nevaluator heads during the pre-filling stage, subsequently passing only the\nimportant tokens to the model for inference. EHPC achieves state-of-the-art\nresults across two mainstream benchmarks: prompt compression and long-context\ninference acceleration. Consequently, it effectively reduces the complexity and\ncosts associated with commercial API calls. We further demonstrate that EHPC\nattains competitive results compared to key-value cache-based acceleration\nmethods, thereby highlighting its potential to enhance the efficiency of LLMs\nfor long-context tasks.", "published": "2025-01-22 15:33:17", "link": "http://arxiv.org/abs/2501.12959v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OnionEval: An Unified Evaluation of Fact-conflicting Hallucination for\n  Small-Large Language Models", "abstract": "Large Language Models (LLMs) are highly capable but require significant\ncomputational resources for both training and inference. Within the LLM family,\nsmaller models (those with fewer than 10 billion parameters) also perform well\nacross various tasks. However, these smaller models share similar limitations\nto their larger counterparts, including the tendency to hallucinate. Despite\nthe existence of many benchmarks to evaluate hallucination in LLMs, few have\nspecifically focused on small LLMs (SLLMs). Additionally, SLLMs show widely\nvarying performance across different benchmarks. In this paper, we introduce\nOnionEval, a multi-layer structured framework with a specific metric called the\ncontext-influence score (CI), designed to effectively assess the\nfact-conflicting hallucination tendencies of small LLMs across different\ncontextual levels. Our experimental results reveal a key feature of SLLMs: they\nexcel in factual analysis but face challenges with context reasoning. Further\ninvestigation shows that a simple Chain-of-Thought strategy can significantly\nreduce these limitations, improving the practical usefulness of SLLMs in\nreal-world applications.", "published": "2025-01-22 15:59:44", "link": "http://arxiv.org/abs/2501.12975v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Implicit Causality-biases in humans and LLMs as a tool for benchmarking\n  LLM discourse capabilities", "abstract": "In this paper, we compare data generated with mono- and multilingual LLMs\nspanning a range of model sizes with data provided by human participants in an\nexperimental setting investigating well-established discourse biases. Beyond\nthe comparison as such, we aim to develop a benchmark to assess the\ncapabilities of LLMs with discourse biases as a robust proxy for more general\ndiscourse understanding capabilities. More specifically, we investigated\nImplicit Causality verbs, for which psycholinguistic research has found\nparticipants to display biases with regard to three phenomena:\\ the\nestablishment of (i) coreference relations (Experiment 1), (ii) coherence\nrelations (Experiment 2), and (iii) the use of particular referring expressions\n(Experiments 3 and 4). With regard to coreference biases we found only the\nlargest monolingual LLM (German Bloom 6.4B) to display more human-like biases.\nFor coherence relation, no LLM displayed the explanation bias usually found for\nhumans. For referring expressions, all LLMs displayed a preference for\nreferring to subject arguments with simpler forms than to objects. However, no\nbias effect on referring expression was found, as opposed to recent studies\ninvestigating human biases.", "published": "2025-01-22 16:07:24", "link": "http://arxiv.org/abs/2501.12980v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PairJudge RM: Perform Best-of-N Sampling with Knockout Tournament", "abstract": "Best-of-N (BoN) sampling, a common strategy for test-time scaling of Large\nLanguage Models (LLMs), relies on reward models to select the best candidate\nsolution from multiple generations. However, traditional reward models often\nassign arbitrary and inconsistent scores, limiting their effectiveness. To\naddress this, we propose a Pairwise Judge Reward Model (PariJudge RM) combined\nwith a knockout tournament for BoN sampling. Instead of assigning absolute\nscores, given one math problem, PariJudge RM judges two candidate solutions'\ncorrectness with chain-of-thought reasoning simultaneously. This approach\neliminates the need for scoring and enables cross-validation of solutions\nthrough parallel judgment. In the knockout tournament, PariJudge RM conducts\npairwise Judgment between candidate solutions and eliminates the incorrect ones\niteratively. We construct PairJudge-432K, a large-scale dataset of 432K\npairwise judgments derived from NumiaMath and annotated using\n\\texttt{gemini-1.5-flash}, and train the PariJudge RM via supervised\nfine-tuning. Experiments on MATH-500 and the Olympiad Bench demonstrate\nsignificant improvements over baseline reward models. And a 40\\% to 60\\%\nrelative improvement is achieved on the top 50\\% challenging problems.", "published": "2025-01-22 16:49:37", "link": "http://arxiv.org/abs/2501.13007v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Does Table Source Matter? Benchmarking and Improving Multimodal\n  Scientific Table Understanding and Reasoning", "abstract": "Recent large language models (LLMs) have advanced table understanding\ncapabilities but rely on converting tables into text sequences. While\nmultimodal large language models (MLLMs) enable direct visual processing, they\nface limitations in handling scientific tables due to fixed input image\nresolutions and insufficient numerical reasoning capabilities. We present a\ncomprehensive framework for multimodal scientific table understanding and\nreasoning with dynamic input image resolutions. Our framework consists of three\nkey components: (1) MMSci-Pre, a domain-specific table structure learning\ndataset of 52K scientific table structure recognition samples, (2) MMSci-Ins,\nan instruction tuning dataset with 12K samples across three table-based tasks,\nand (3) MMSci-Eval, a benchmark with 3,114 testing samples specifically\ndesigned to evaluate numerical reasoning capabilities. Extensive experiments\ndemonstrate that our domain-specific approach with 52K scientific table images\nachieves superior performance compared to 150K general-domain tables,\nhighlighting the importance of data quality over quantity. Our proposed\ntable-based MLLMs with dynamic input resolutions show significant improvements\nin both general table understanding and numerical reasoning capabilities, with\nstrong generalisation to held-out datasets. Our code and data are publicly\navailable at https://github.com/Bernard-Yang/MMSci_Table.", "published": "2025-01-22 17:44:01", "link": "http://arxiv.org/abs/2501.13042v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RAG-Reward: Optimizing RAG with Reward Modeling and RLHF", "abstract": "Retrieval-augmented generation (RAG) enhances Large Language Models (LLMs)\nwith relevant and up-to-date knowledge, improving their ability to answer\nknowledge-intensive questions. It has been shown to enhance both generation\nquality and trustworthiness. While numerous works have focused on improving\nretrieval, generation, and evaluation, the role of reward models in\nreinforcement learning for optimizing RAG remains underexplored. In this paper,\nwe introduce \\textbf{RAG-Reward}, a framework designed to develop reward models\nto enable \\textit{hallucination-free, comprehensive, reliable, and efficient\nRAG}. We define four key metrics to assess generation quality and develop an\nautomated benchmarking pipeline to evaluate the outputs of multiple LLMs across\na variety of RAG scenarios. Using \\textbf{RAG-Reward}, we train reward models\nand apply {reinforcement learning with human feedback (RLHF)} to improve LLMs'\neffectiveness in RAG. Experimental results demonstrate that our reward model\nachieves state-of-the-art performance in automatic benchmarking and aligns\nclosely with human evaluations. Furthermore, the improved generation quality of\nthe trained policy model highlights the feasibility and efficiency of using\nRLHF to enhance RAG outputs.", "published": "2025-01-22 22:59:19", "link": "http://arxiv.org/abs/2501.13264v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "T2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in\n  Image Generation", "abstract": "Text-to-image (T2I) models have rapidly advanced, enabling the generation of\nhigh-quality images from text prompts across various domains. However, these\nmodels present notable safety concerns, including the risk of generating\nharmful, biased, or private content. Current research on assessing T2I safety\nremains in its early stages. While some efforts have been made to evaluate\nmodels on specific safety dimensions, many critical risks remain unexplored. To\naddress this gap, we introduce T2ISafety, a safety benchmark that evaluates T2I\nmodels across three key domains: toxicity, fairness, and bias. We build a\ndetailed hierarchy of 12 tasks and 44 categories based on these three domains,\nand meticulously collect 70K corresponding prompts. Based on this taxonomy and\nprompt set, we build a large-scale T2I dataset with 68K manually annotated\nimages and train an evaluator capable of detecting critical risks that previous\nwork has failed to identify, including risks that even ultra-large proprietary\nmodels like GPTs cannot correctly detect. We evaluate 12 prominent diffusion\nmodels on T2ISafety and reveal several concerns including persistent issues\nwith racial fairness, a tendency to generate toxic content, and significant\nvariation in privacy protection across the models, even with defense methods\nlike concept erasing. Data and evaluator are released under\nhttps://github.com/adwardlee/t2i_safety.", "published": "2025-01-22 03:29:43", "link": "http://arxiv.org/abs/2501.12612v2", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Dynamics of Toxicity in Political Podcasts", "abstract": "Toxicity in digital media poses significant challenges, yet little attention\nhas been given to its dynamics within the rapidly growing medium of podcasts.\nThis paper addresses this gap by analyzing political podcast data to study the\nemergence and propagation of toxicity, focusing on conversation\nchains-structured reply patterns within podcast transcripts. Leveraging\nstate-of-the-art transcription models and advanced conversational analysis\ntechniques, we systematically examine toxic discourse in over 30 popular\npolitical podcasts in the United States. Our key contributions include: (1)\ncreating a comprehensive dataset of transcribed and diarized political\npodcasts, identifying thousands of toxic instances using Google's Perspective\nAPI, (2) uncovering concerning trends where a majority of episodes contain at\nleast one toxic instance, (3) introducing toxic conversation chains and\nanalyzing their structural and linguistic properties, revealing characteristics\nsuch as longer durations, repetitive patterns, figurative language, and\nemotional cues tied to anger and annoyance, (4) identifying demand-related\nwords like 'want', 'like', and 'know' as precursors to toxicity, and (5)\ndeveloping predictive models to anticipate toxicity shifts based on annotated\nchange points. Our findings provide critical insights into podcast toxicity and\nestablish a foundation for future research on real-time monitoring and\nintervention mechanisms to foster healthier discourse in this influential\nmedium.", "published": "2025-01-22 04:58:50", "link": "http://arxiv.org/abs/2501.12640v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The potential -- and the pitfalls -- of using pre-trained language\n  models as cognitive science theories", "abstract": "Many studies have evaluated the cognitive alignment of Pre-trained Language\nModels (PLMs), i.e., their correspondence to adult performance across a range\nof cognitive domains. Recently, the focus has expanded to the developmental\nalignment of these models: identifying phases during training where\nimprovements in model performance track improvements in children's thinking\nover development. However, there are many challenges to the use of PLMs as\ncognitive science theories, including different architectures, different\ntraining data modalities and scales, and limited model interpretability. In\nthis paper, we distill lessons learned from treating PLMs, not as engineering\nartifacts but as cognitive science and developmental science models. We review\nassumptions used by researchers to map measures of PLM performance to measures\nof human performance. We identify potential pitfalls of this approach to\nunderstanding human thinking, and we end by enumerating criteria for using PLMs\nas credible accounts of cognition and cognitive development.", "published": "2025-01-22 05:24:23", "link": "http://arxiv.org/abs/2501.12651v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "EvidenceMap: Learning Evidence Analysis to Unleash the Power of Small\n  Language Models for Biomedical Question Answering", "abstract": "When addressing professional questions in the biomedical domain, humans\ntypically acquire multiple pieces of information as evidence and engage in\nmultifaceted analysis to provide high-quality answers. Current LLM-based\nquestion answering methods lack a detailed definition and learning process for\nevidence analysis, leading to the risk of error propagation and hallucinations\nwhile using evidence. Although increasing the parameter size of LLMs can\nalleviate these issues, it also presents challenges in training and deployment\nwith limited resources. In this study, we propose EvidenceMap, which aims to\nenable a tiny pre-trained language model to explicitly learn multiple aspects\nof biomedical evidence, including supportive evaluation, logical correlation\nand content summarization, thereby latently guiding a small generative model\n(around 3B parameters) to provide textual responses. Experimental results\ndemonstrate that our method, learning evidence analysis by fine-tuning a model\nwith only 66M parameters, exceeds the RAG method with an 8B LLM by 19.9% and\n5.7% in reference-based quality and accuracy, respectively.", "published": "2025-01-22 09:27:11", "link": "http://arxiv.org/abs/2501.12746v4", "categories": ["cs.CL", "cs.AI", "68T50"], "primary_category": "cs.CL"}
{"title": "NExtLong: Toward Effective Long-Context Training without Long Documents", "abstract": "Large language models (LLMs) with extended context windows have made\nsignificant strides yet remain a challenge due to the scarcity of long\ndocuments. Existing methods tend to synthesize long-context data but lack a\nclear mechanism to reinforce the long-range dependency modeling. To address\nthis limitation, we propose NExtLong, a novel framework for synthesizing\nlong-context data through Negative document Extension. NExtLong decomposes a\ndocument into multiple meta-chunks and extends the context by interleaving hard\nnegative distractors retrieved from pretraining corpora. This approach compels\nthe model to discriminate long-range dependent context from distracting\ncontent, enhancing its ability to model long-range dependencies. Extensive\nexperiments demonstrate that NExtLong achieves significant performance\nimprovements on the HELMET and RULER benchmarks compared to existing\nlong-context synthesis approaches and leading models, which are trained on\nnon-synthetic long documents. These findings highlight NExtLong's ability to\nreduce reliance on non-synthetic long documents, making it an effective\nframework for developing advanced long-context LLMs.", "published": "2025-01-22 10:01:54", "link": "http://arxiv.org/abs/2501.12766v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Generating Diverse Q&A Benchmarks for RAG Evaluation with DataMorgana", "abstract": "Evaluating Retrieval-Augmented Generation (RAG) systems, especially in\ndomain-specific contexts, requires benchmarks that address the distinctive\nrequirements of the applicative scenario. Since real data can be hard to\nobtain, a common strategy is to use LLM-based methods to generate synthetic\ndata. Existing solutions are general purpose: given a document, they generate a\nquestion to build a Q&A pair. However, although the generated questions can be\nindividually good, they are typically not diverse enough to reasonably cover\nthe different ways real end-users can interact with the RAG system. We\nintroduce here DataMorgana, a tool for generating highly customizable and\ndiverse synthetic Q&A benchmarks tailored to RAG applications. DataMorgana\nenables detailed configurations of user and question categories and provides\ncontrol over their distribution within the benchmark. It uses a lightweight\ntwo-stage process, ensuring efficiency and fast iterations, while generating\nbenchmarks that reflect the expected traffic. We conduct a thorough line of\nexperiments, showing quantitatively and qualitatively that DataMorgana\nsurpasses existing tools and approaches in producing lexically, syntactically,\nand semantically diverse question sets across domain-specific and\ngeneral-knowledge corpora. DataMorgana will be made available to selected teams\nin the research community, as first beta testers, in the context of the\nupcoming SIGIR'2025 LiveRAG challenge to be announced in early February 2025.", "published": "2025-01-22 10:47:08", "link": "http://arxiv.org/abs/2501.12789v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Adaptive Retrieval Without Self-Knowledge? Bringing Uncertainty Back\n  Home", "abstract": "Retrieval Augmented Generation (RAG) improves correctness of Question\nAnswering (QA) and addresses hallucinations in Large Language Models (LLMs),\nyet greatly increase computational costs. Besides, RAG is not always needed as\nmay introduce irrelevant information. Recent adaptive retrieval methods\nintegrate LLMs' intrinsic knowledge with external information appealing to LLM\nself-knowledge, but they often neglect efficiency evaluations and comparisons\nwith uncertainty estimation techniques. We bridge this gap by conducting a\ncomprehensive analysis of 35 adaptive retrieval methods, including 8 recent\napproaches and 27 uncertainty estimation techniques, across 6 datasets using 10\nmetrics for QA performance, self-knowledge, and efficiency. Our findings show\nthat uncertainty estimation techniques often outperform complex pipelines in\nterms of efficiency and self-knowledge, while maintaining comparable QA\nperformance.", "published": "2025-01-22 12:21:17", "link": "http://arxiv.org/abs/2501.12835v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Architectural Fusion Through Contextual Partitioning in Large Language\n  Models: A Novel Approach to Parameterized Knowledge Integration", "abstract": "Contextual Partitioning introduces an innovative approach to enhancing the\narchitectural design of large-scale computational models through the dynamic\nsegmentation of parameters into context-aware regions. This methodology\nemphasizes the importance of task-specific specialization, achieved through\nadaptive parameter allocation mechanisms that align with the linguistic\nfeatures of input data. Experimental evaluations demonstrated substantial\nimprovements in accuracy, perplexity, and contextual coherence across a variety\nof linguistic tasks, highlighting the adaptability and scalability of the\nproposed framework. By reducing redundancy and enhancing computational\nefficiency, Contextual Partitioning not only streamlines model operations but\nalso expands the scope of applications for advanced language processing\nsystems. The approach operates autonomously, requiring no external fine-tuning,\nthereby addressing a significant limitation in conventional parameter\noptimization techniques. Empirical results demonstrate the effectiveness of\ngradient-driven segmentation, enabling models to dynamically recalibrate and\nspecialize in response to task-specific demands. Furthermore, resource\nutilization metrics reveal notable reductions in memory usage and training\ntimes, confirming the efficiency of the approach. Observations from qualitative\nanalyses illustrate improved contextual coherence and logical flow in generated\noutputs, reinforcing the practical value of this technique. The findings\ncollectively demonstrate the potential for Contextual Partitioning to redefine\nthe scalability and adaptability of computational language architectures in\ndiverse and complex domains.", "published": "2025-01-22 14:21:04", "link": "http://arxiv.org/abs/2501.12901v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Ontology-Enhanced Educational Annotation Activities", "abstract": "Information and communications technology and technology-enhanced learning\nhave unquestionably transformed traditional teaching-learning processes and are\npositioned as key factors to promote quality education, one of the basic\nsustainable development goals of the 2030 agenda. Document annotation, which\nwas traditionally carried out with pencil and paper and currently benefits from\ndigital document annotation tools, is a representative example of this\ntransformation. Using document annotation tools, students can enrich the\ndocuments with annotations that highlight the most relevant aspects of these\ndocuments. As the conceptual complexity of the learning domain increases, the\nannotation of the documents may require comprehensive domain knowledge and an\nexpert analysis capability that students usually lack. Consequently, a\nproliferation of irrelevant, incorrect, and/or poorly decontextualized\nannotations may appear, while other relevant aspects are completely ignored by\nthe students. The main hypothesis proposed by this paper is that the use of a\nguiding annotation ontology in the annotation activities is a keystone aspect\nto alleviate these shortcomings. Consequently, comprehension is improved,\nexhaustive content analysis is promoted, and meta-reflective thinking is\ndeveloped. To test this hypothesis, we describe our own annotation tool,\n\\@note, which fully implements this ontology-enhanced annotation paradigm, and\nwe provide experimental evidence about how \\@note can improve academic\nperformance via a pilot study concerning critical literary annotation.", "published": "2025-01-22 15:15:59", "link": "http://arxiv.org/abs/2501.12943v1", "categories": ["cs.CL", "cs.DL"], "primary_category": "cs.CL"}
{"title": "Understanding the LLM-ification of CHI: Unpacking the Impact of LLMs at\n  CHI through a Systematic Literature Review", "abstract": "Large language models (LLMs) have been positioned to revolutionize HCI, by\nreshaping not only the interfaces, design patterns, and sociotechnical systems\nthat we study, but also the research practices we use. To-date, however, there\nhas been little understanding of LLMs' uptake in HCI. We address this gap via a\nsystematic literature review of 153 CHI papers from 2020-24 that engage with\nLLMs. We taxonomize: (1) domains where LLMs are applied; (2) roles of LLMs in\nHCI projects; (3) contribution types; and (4) acknowledged limitations and\nrisks. We find LLM work in 10 diverse domains, primarily via empirical and\nartifact contributions. Authors use LLMs in five distinct roles, including as\nresearch tools or simulated users. Still, authors often raise validity and\nreproducibility concerns, and overwhelmingly study closed models. We outline\nopportunities to improve HCI research with and on LLMs, and provide guiding\nquestions for researchers to consider the validity and appropriateness of\nLLM-related work.", "published": "2025-01-22 00:31:51", "link": "http://arxiv.org/abs/2501.12557v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.HC"}
{"title": "BLR-MoE: Boosted Language-Routing Mixture of Experts for Domain-Robust\n  Multilingual E2E ASR", "abstract": "Recently, the Mixture of Expert (MoE) architecture, such as LR-MoE, is often\nused to alleviate the impact of language confusion on the multilingual ASR\n(MASR) task. However, it still faces language confusion issues, especially in\nmismatched domain scenarios. In this paper, we decouple language confusion in\nLR-MoE into confusion in self-attention and router. To alleviate the language\nconfusion in self-attention, based on LR-MoE, we propose to apply attention-MoE\narchitecture for MASR. In our new architecture, MoE is utilized not only on\nfeed-forward network (FFN) but also on self-attention. In addition, to improve\nthe robustness of the LID-based router on language confusion, we propose expert\npruning and router augmentation methods. Combining the above, we get the\nboosted language-routing MoE (BLR-MoE) architecture. We verify the\neffectiveness of the proposed BLR-MoE in a 10,000-hour MASR dataset.", "published": "2025-01-22 02:55:11", "link": "http://arxiv.org/abs/2501.12602v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Open or Closed LLM for Lesser-Resourced Languages? Lessons from Greek", "abstract": "Natural Language Processing (NLP) for lesser-resourced languages faces\npersistent challenges, including limited datasets, inherited biases from\nhigh-resource languages, and the need for domain-specific solutions. This study\naddresses these gaps for Modern Greek through three key contributions. First,\nwe evaluate the performance of open-source (Llama-70b) and closed-source\n(GPT-4o mini) large language models (LLMs) on seven core NLP tasks with dataset\navailability, revealing task-specific strengths, weaknesses, and parity in\ntheir performance. Second, we expand the scope of Greek NLP by reframing\nAuthorship Attribution as a tool to assess potential data usage by LLMs in\npre-training, with high 0-shot accuracy suggesting ethical implications for\ndata provenance. Third, we showcase a legal NLP case study, where a Summarize,\nTranslate, and Embed (STE) methodology outperforms the traditional TF-IDF\napproach for clustering \\emph{long} legal texts. Together, these contributions\nprovide a roadmap to advance NLP in lesser-resourced languages, bridging gaps\nin model evaluation, task innovation, and real-world impact.", "published": "2025-01-22 12:06:16", "link": "http://arxiv.org/abs/2501.12826v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FilmAgent: A Multi-Agent Framework for End-to-End Film Automation in\n  Virtual 3D Spaces", "abstract": "Virtual film production requires intricate decision-making processes,\nincluding scriptwriting, virtual cinematography, and precise actor positioning\nand actions. Motivated by recent advances in automated decision-making with\nlanguage agent-based societies, this paper introduces FilmAgent, a novel\nLLM-based multi-agent collaborative framework for end-to-end film automation in\nour constructed 3D virtual spaces. FilmAgent simulates various crew roles,\nincluding directors, screenwriters, actors, and cinematographers, and covers\nkey stages of a film production workflow: (1) idea development transforms\nbrainstormed ideas into structured story outlines; (2) scriptwriting elaborates\non dialogue and character actions for each scene; (3) cinematography determines\nthe camera setups for each shot. A team of agents collaborates through\niterative feedback and revisions, thereby verifying intermediate scripts and\nreducing hallucinations. We evaluate the generated videos on 15 ideas and 4 key\naspects. Human evaluation shows that FilmAgent outperforms all baselines across\nall aspects and scores 3.98 out of 5 on average, showing the feasibility of\nmulti-agent collaboration in filmmaking. Further analysis reveals that\nFilmAgent, despite using the less advanced GPT-4o model, surpasses the\nsingle-agent o1, showing the advantage of a well-coordinated multi-agent\nsystem. Lastly, we discuss the complementary strengths and weaknesses of\nOpenAI's text-to-video model Sora and our FilmAgent in filmmaking.", "published": "2025-01-22 14:36:30", "link": "http://arxiv.org/abs/2501.12909v1", "categories": ["cs.CL", "cs.GR", "cs.MA"], "primary_category": "cs.CL"}
{"title": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via\n  Reinforcement Learning", "abstract": "We introduce our first-generation reasoning models, DeepSeek-R1-Zero and\nDeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement\nlearning (RL) without supervised fine-tuning (SFT) as a preliminary step,\ndemonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero\nnaturally emerges with numerous powerful and intriguing reasoning behaviors.\nHowever, it encounters challenges such as poor readability, and language\nmixing. To address these issues and further enhance reasoning performance, we\nintroduce DeepSeek-R1, which incorporates multi-stage training and cold-start\ndata before RL. DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217\non reasoning tasks. To support the research community, we open-source\nDeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B,\n70B) distilled from DeepSeek-R1 based on Qwen and Llama.", "published": "2025-01-22 15:19:35", "link": "http://arxiv.org/abs/2501.12948v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FlanEC: Exploring Flan-T5 for Post-ASR Error Correction", "abstract": "In this paper, we present an encoder-decoder model leveraging Flan-T5 for\npost-Automatic Speech Recognition (ASR) Generative Speech Error Correction\n(GenSEC), and we refer to it as FlanEC. We explore its application within the\nGenSEC framework to enhance ASR outputs by mapping n-best hypotheses into a\nsingle output sentence. By utilizing n-best lists from ASR models, we aim to\nimprove the linguistic correctness, accuracy, and grammaticality of final ASR\ntranscriptions. Specifically, we investigate whether scaling the training data\nand incorporating diverse datasets can lead to significant improvements in\npost-ASR error correction. We evaluate FlanEC using the HyPoradise dataset,\nproviding a comprehensive analysis of the model's effectiveness in this domain.\nFurthermore, we assess the proposed approach under different settings to\nevaluate model scalability and efficiency, offering valuable insights into the\npotential of instruction-tuned encoder-decoder models for this task.", "published": "2025-01-22 16:06:04", "link": "http://arxiv.org/abs/2501.12979v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Autonomy-of-Experts Models", "abstract": "Mixture-of-Experts (MoE) models mostly use a router to assign tokens to\nspecific expert modules, activating only partial parameters and often\noutperforming dense models. We argue that the separation between the router's\ndecision-making and the experts' execution is a critical yet overlooked issue,\nleading to suboptimal expert selection and ineffective learning. To address\nthis, we propose Autonomy-of-Experts (AoE), a novel MoE paradigm in which\nexperts autonomously select themselves to process inputs. AoE is based on the\ninsight that an expert is aware of its own capacity to effectively process a\ntoken, an awareness reflected in the scale of its internal activations. In AoE,\nrouters are removed; instead, experts pre-compute internal activations for\ninputs and are ranked based on their activation norms. Only the top-ranking\nexperts proceed with the forward pass, while the others abort. The overhead of\npre-computing activations is reduced through a low-rank weight factorization.\nThis self-evaluating-then-partner-comparing approach ensures improved expert\nselection and effective learning. We pre-train language models having 700M up\nto 4B parameters, demonstrating that AoE outperforms traditional MoE models\nwith comparable efficiency.", "published": "2025-01-22 18:37:08", "link": "http://arxiv.org/abs/2501.13074v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Refining Input Guardrails: Enhancing LLM-as-a-Judge Efficiency Through\n  Chain-of-Thought Fine-Tuning and Alignment", "abstract": "Large Language Models (LLMs) have demonstrated powerful capabilities that\nrender them valuable in different applications, including conversational AI\nproducts. It is paramount to ensure the security and reliability of these\nproducts by mitigating their vulnerabilities towards malicious user\ninteractions, which can lead to the exposure of great risks and reputational\nrepercussions. In this work, we present a comprehensive study on the efficacy\nof fine-tuning and aligning Chain-of-Thought (CoT) responses of different LLMs\nthat serve as input moderation guardrails. We systematically explore various\ntuning methods by leveraging a small set of training data to adapt these models\nas proxy defense mechanisms to detect malicious inputs and provide a reasoning\nfor their verdicts, thereby preventing the exploitation of conversational\nagents. We rigorously evaluate the efficacy and robustness of different tuning\nstrategies to generalize across diverse adversarial and malicious query types.\nOur experimental results outline the potential of alignment processes tailored\nto a varied range of harmful input queries, even with constrained data\nresources. These techniques significantly enhance the safety of conversational\nAI systems and provide a feasible framework for deploying more secure and\ntrustworthy AI-driven interactions.", "published": "2025-01-22 18:40:57", "link": "http://arxiv.org/abs/2501.13080v1", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Rate-Distortion Framework for Summarization", "abstract": "This paper introduces an information-theoretic framework for text\nsummarization. We define the summarizer rate-distortion function and show that\nit provides a fundamental lower bound on summarizer performance. We describe an\niterative procedure, similar to Blahut-Arimoto algorithm, for computing this\nfunction. To handle real-world text datasets, we also propose a practical\nmethod that can calculate the summarizer rate-distortion function with limited\ndata. Finally, we empirically confirm our theoretical results by comparing the\nsummarizer rate-distortion function with the performances of different\nsummarizers used in practice.", "published": "2025-01-22 18:57:14", "link": "http://arxiv.org/abs/2501.13100v1", "categories": ["cs.IT", "cs.CL", "cs.LG", "math.IT"], "primary_category": "cs.IT"}
{"title": "EmoTech: A Multi-modal Speech Emotion Recognition Using Multi-source\n  Low-level Information with Hybrid Recurrent Network", "abstract": "Emotion recognition is a critical task in human-computer interaction,\nenabling more intuitive and responsive systems. This study presents a\nmultimodal emotion recognition system that combines low-level information from\naudio and text, leveraging both Convolutional Neural Networks (CNNs) and\nBidirectional Long Short-Term Memory Networks (BiLSTMs). The proposed system\nconsists of two parallel networks: an Audio Block and a Text Block. Mel\nFrequency Cepstral Coefficients (MFCCs) are extracted and processed by a BiLSTM\nnetwork and a 2D convolutional network to capture low-level intrinsic and\nextrinsic features from speech. Simultaneously, a combined BiLSTM-CNN network\nextracts the low-level sequential nature of text from word embeddings\ncorresponding to the available audio. This low-level information from speech\nand text is then concatenated and processed by several fully connected layers\nto classify the speech emotion. Experimental results demonstrate that the\nproposed EmoTech accurately recognizes emotions from combined audio and text\ninputs, achieving an overall accuracy of 84%. This solution outperforms\npreviously proposed approaches for the same dataset and modalities.", "published": "2025-01-22 06:23:36", "link": "http://arxiv.org/abs/2501.12674v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "EmoFormer: A Text-Independent Speech Emotion Recognition using a Hybrid\n  Transformer-CNN model", "abstract": "Speech Emotion Recognition is a crucial area of research in human-computer\ninteraction. While significant work has been done in this field, many\nstate-of-the-art networks struggle to accurately recognize emotions in speech\nwhen the data is both speech and speaker-independent. To address this\nlimitation, this study proposes, EmoFormer, a hybrid model combining CNNs\n(CNNs) with Transformer encoders to capture emotion patterns in speech data for\nsuch independent datasets. The EmoFormer network was trained and tested using\nthe Expressive Anechoic Recordings of Speech (EARS) dataset, recently released\nby META. We experimented with two feature extraction techniques: MFCCs and\nx-vectors. The model was evaluated on different emotion sets comprising 5, 7,\n10, and 23 distinct categories. The results demonstrate that the model achieved\nits best performance with five emotions, attaining an accuracy of 90%, a\nprecision of 0.92, a recall, and an F1-score of 0.91. However, performance\ndecreased as the number of emotions increased, with an accuracy of 83% for\nseven emotions compared to 70% for the baseline network. This study highlights\nthe effectiveness of combining CNNs and Transformer-based architectures for\nemotion recognition from speech, particularly when using MFCC features.", "published": "2025-01-22 07:00:15", "link": "http://arxiv.org/abs/2501.12682v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "S-KEY: Self-supervised Learning of Major and Minor Keys from Audio", "abstract": "STONE, the current method in self-supervised learning for tonality estimation\nin music signals, cannot distinguish relative keys, such as C major versus A\nminor. In this article, we extend the neural network architecture and learning\nobjective of STONE to perform self-supervised learning of major and minor keys\n(S-KEY). Our main contribution is an auxiliary pretext task to STONE,\nformulated using transposition-invariant chroma features as a source of\npseudo-labels. S-KEY matches the supervised state of the art in tonality\nestimation on FMAKv2 and GTZAN datasets while requiring no human annotation and\nhaving the same parameter budget as STONE. We build upon this result and expand\nthe training set of S-KEY to a million songs, thus showing the potential of\nlarge-scale self-supervised learning in music information retrieval.", "published": "2025-01-22 14:35:37", "link": "http://arxiv.org/abs/2501.12907v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Why disentanglement-based speaker anonymization systems fail at\n  preserving emotions?", "abstract": "Disentanglement-based speaker anonymization involves decomposing speech into\na semantically meaningful representation, altering the speaker embedding, and\nresynthesizing a waveform using a neural vocoder. State-of-the-art systems of\nthis kind are known to remove emotion information. Possible reasons include\nmode collapse in GAN-based vocoders, unintended modeling and modification of\nemotions through speaker embeddings, or excessive sanitization of the\nintermediate representation. In this paper, we conduct a comprehensive\nevaluation of a state-of-the-art speaker anonymization system to understand the\nunderlying causes. We conclude that the main reason is the lack of\nemotion-related information in the intermediate representation. The speaker\nembeddings also have a high impact, if they are learned in a generative\ncontext. The vocoder's out-of-distribution performance has a smaller impact.\nAdditionally, we discovered that synthesis artifacts increase spectral\nkurtosis, biasing emotion recognition evaluation towards classifying utterances\nas angry. Therefore, we conclude that reporting unweighted average recall alone\nfor emotion recognition performance is suboptimal.", "published": "2025-01-22 16:37:56", "link": "http://arxiv.org/abs/2501.13000v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Retrieval-Augmented Neural Field for HRTF Upsampling and Personalization", "abstract": "Head-related transfer functions (HRTFs) with dense spatial grids are desired\nfor immersive binaural audio generation, but their recording is time-consuming.\nAlthough HRTF spatial upsampling has shown remarkable progress with neural\nfields, spatial upsampling only from a few measured directions, e.g., 3 or 5\nmeasurements, is still challenging. To tackle this problem, we propose a\nretrieval-augmented neural field (RANF). RANF retrieves a subject whose HRTFs\nare close to those of the target subject from a dataset. The HRTF of the\nretrieved subject at the desired direction is fed into the neural field in\naddition to the sound source direction itself. Furthermore, we present a neural\nnetwork that can efficiently handle multiple retrieved subjects, inspired by a\nmulti-channel processing technique called transform-average-concatenate. Our\nexperiments confirm the benefits of RANF on the SONICOM dataset, and it is a\nkey component in the winning solution of Task 2 of the listener acoustic\npersonalization challenge 2024.", "published": "2025-01-22 17:03:52", "link": "http://arxiv.org/abs/2501.13017v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Generative Data Augmentation Challenge: Synthesis of Room Acoustics for\n  Speaker Distance Estimation", "abstract": "This paper describes the synthesis of the room acoustics challenge as a part\nof the generative data augmentation workshop at ICASSP 2025. The challenge\ndefines a unique generative task that is designed to improve the quantity and\ndiversity of the room impulse responses dataset so that it can be used for\nspatially sensitive downstream tasks: speaker distance estimation. The\nchallenge identifies the technical difficulty in measuring or simulating many\nrooms' acoustic characteristics precisely. As a solution, it proposes\ngenerative data augmentation as an alternative that can potentially be used to\nimprove various downstream tasks. The challenge website, dataset, and\nevaluation code are available at https://sites.google.com/view/genda2025.", "published": "2025-01-22 22:04:44", "link": "http://arxiv.org/abs/2501.13250v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Neural Kalman Filters for Acoustic Echo Cancellation", "abstract": "Kalman filtering is a powerful approach to adaptive filtering for various\nproblems in signal processing. The frequency-domain adaptive Kalman filter\n(FDKF), based on the concept of the acoustic state space, provides a unifying\nsolution to the adaptive filter update and the related stepsize control. It was\nconceived for the problem of acoustic echo cancellation and, as such, is\nfrequently applied in hands-free systems. This article motivates and briefly\nrecapitulates the linear FDKF and investigates how it can be further supported\nby deep neural networks (DNNs) in various ways, specifically to overcome the\nchallenges and limitations related to the usually required estimation of\nprocess and observation noise covariances for the Kalman filter. While the mere\nFDKF comes with very low computational complexity, its neural Kalman filter\nvariants may deliver faster (re)convergence, better echo cancellation, and even\nexceed the FDKF in its excellent double-talk near-end speech preservation both\nunder linear and nonlinear loudspeaker conditions. To provide a synopsis of the\nstate of the art, this article contributes a comparison of a range of DNN-based\nextensions of FDKF in the same training framework and using the same data.", "published": "2025-01-22 16:55:50", "link": "http://arxiv.org/abs/2501.16367v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "SoundSpring: Loss-Resilient Audio Transceiver with Dual-Functional\n  Masked Language Modeling", "abstract": "In this paper, we propose \"SoundSpring\", a cutting-edge error-resilient audio\ntransceiver that marries the robustness benefits of joint source-channel coding\n(JSCC) while also being compatible with current digital communication systems.\nUnlike recent deep JSCC transceivers, which learn to directly map audio signals\nto analog channel-input symbols via neural networks, our SoundSpring adopts the\nlayered architecture that delineates audio compression from digital coded\ntransmission, but it sufficiently exploits the impressive in-context predictive\ncapabilities of large language (foundation) models. Integrated with the\ncasual-order mask learning strategy, our single model operates on the latent\nfeature domain and serve dual-functionalities: as efficient audio compressors\nat the transmitter and as effective mechanisms for packet loss concealment at\nthe receiver. By jointly optimizing towards both audio compression efficiency\nand transmission error resiliency, we show that mask-learned language models\nare indeed powerful contextual predictors, and our dual-functional compression\nand concealment framework offers fresh perspectives on the application of\nfoundation language models in audio communication. Through extensive\nexperimental evaluations, we establish that SoundSpring apparently outperforms\ncontemporary audio transmission systems in terms of signal fidelity metrics and\nperceptual quality scores. These new findings not only advocate for the\npractical deployment of SoundSpring in learning-based audio communication\nsystems but also inspire the development of future audio semantic transceivers.", "published": "2025-01-22 08:09:01", "link": "http://arxiv.org/abs/2501.12696v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Hybrid Losses for Hierarchical Embedding Learning", "abstract": "In traditional supervised learning, the cross-entropy loss treats all\nincorrect predictions equally, ignoring the relevance or proximity of wrong\nlabels to the correct answer. By leveraging a tree hierarchy for fine-grained\nlabels, we investigate hybrid losses, such as generalised triplet and\ncross-entropy losses, to enforce similarity between labels within a multi-task\nlearning framework. We propose metrics to evaluate the embedding space\nstructure and assess the model's ability to generalise to unseen classes, that\nis, to infer similar classes for data belonging to unseen categories. Our\nexperiments on OrchideaSOL, a four-level hierarchical instrument sound dataset\nwith nearly 200 detailed categories, demonstrate that the proposed hybrid\nlosses outperform previous works in classification, retrieval, embedding space\nstructure, and generalisation.", "published": "2025-01-22 10:58:04", "link": "http://arxiv.org/abs/2501.12796v1", "categories": ["cs.SD", "cs.IR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Exploring GPT's Ability as a Judge in Music Understanding", "abstract": "Recent progress in text-based Large Language Models (LLMs) and their extended\nability to process multi-modal sensory data have led us to explore their\napplicability in addressing music information retrieval (MIR) challenges. In\nthis paper, we use a systematic prompt engineering approach for LLMs to solve\nMIR problems. We convert the music data to symbolic inputs and evaluate LLMs'\nability in detecting annotation errors in three key MIR tasks: beat tracking,\nchord extraction, and key estimation. A concept augmentation method is proposed\nto evaluate LLMs' music reasoning consistency with the provided music concepts\nin the prompts. Our experiments tested the MIR capabilities of Generative\nPre-trained Transformers (GPT). Results show that GPT has an error detection\naccuracy of 65.20%, 64.80%, and 59.72% in beat tracking, chord extraction, and\nkey estimation tasks, respectively, all exceeding the random baseline.\nMoreover, we observe a positive correlation between GPT's error finding\naccuracy and the amount of concept information provided. The current findings\nbased on symbolic music input provide a solid ground for future LLM-based MIR\nresearch.", "published": "2025-01-22 22:49:27", "link": "http://arxiv.org/abs/2501.13261v1", "categories": ["cs.IR", "cs.SD", "eess.AS"], "primary_category": "cs.IR"}
{"title": "Development of an Inclusive Educational Platform Using Open Technologies\n  and Machine Learning: A Case Study on Accessibility Enhancement", "abstract": "This study addresses the pressing challenge of educational inclusion for\nstudents with special needs by proposing and developing an inclusive\neducational platform. Integrating machine learning, natural language\nprocessing, and cross-platform interfaces, the platform features key\nfunctionalities such as speech recognition functionality to support voice\ncommands and text generation via voice input; real-time object recognition\nusing the YOLOv5 model, adapted for educational environments;\nGrapheme-to-Phoneme (G2P) conversion for Text-to-Speech systems using seq2seq\nmodels with attention, ensuring natural and fluent voice synthesis; and the\ndevelopment of a cross-platform mobile application in Flutter with on-device\ninference execution using TensorFlow Lite. The results demonstrated high\naccuracy, usability, and positive impact in educational scenarios, validating\nthe proposal as an effective tool for educational inclusion. This project\nunderscores the importance of open and accessible technologies in promoting\ninclusive and quality education.", "published": "2025-01-22 02:38:23", "link": "http://arxiv.org/abs/2503.15501v1", "categories": ["cs.HC", "cs.AI", "cs.LG", "eess.AS", "68T50", "I.2.7; D.2.3"], "primary_category": "cs.HC"}
