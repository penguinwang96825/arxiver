{"title": "On Structured Sparsity of Phonological Posteriors for Linguistic Parsing", "abstract": "The speech signal conveys information on different time scales from short\ntime scale or segmental, associated to phonological and phonetic information to\nlong time scale or supra segmental, associated to syllabic and prosodic\ninformation. Linguistic and neurocognitive studies recognize the phonological\nclasses at segmental level as the essential and invariant representations used\nin speech temporal organization. In the context of speech processing, a deep\nneural network (DNN) is an effective computational method to infer the\nprobability of individual phonological classes from a short segment of speech\nsignal. A vector of all phonological class probabilities is referred to as\nphonological posterior. There are only very few classes comprising a short term\nspeech signal; hence, the phonological posterior is a sparse vector. Although\nthe phonological posteriors are estimated at segmental level, we claim that\nthey convey supra-segmental information. Specifically, we demonstrate that\nphonological posteriors are indicative of syllabic and prosodic events.\nBuilding on findings from converging linguistic evidence on the gestural model\nof Articulatory Phonology as well as the neural basis of speech perception, we\nhypothesize that phonological posteriors convey properties of linguistic\nclasses at multiple time scales, and this information is embedded in their\nsupport (index) of active coefficients. To verify this hypothesis, we obtain a\nbinary representation of phonological posteriors at the segmental level which\nis referred to as first-order sparsity structure; the high-order structures are\nobtained by the concatenation of first-order binary vectors. It is then\nconfirmed that the classification of supra-segmental linguistic events, the\nproblem known as linguistic parsing, can be achieved with high accuracy using\nasimple binary pattern matching of first-order or high-order structures.", "published": "2016-01-21 14:15:41", "link": "http://arxiv.org/abs/1601.05647v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Syntax-Semantics Interaction Parsing Strategies. Inside SYNTAGMA", "abstract": "This paper discusses SYNTAGMA, a rule based NLP system addressing the tricky\nissues of syntactic ambiguity reduction and word sense disambiguation as well\nas providing innovative and original solutions for constituent generation and\nconstraints management. To provide an insight into how it operates, the\nsystem's general architecture and components, as well as its lexical, syntactic\nand semantic resources are described. After that, the paper addresses the\nmechanism that performs selective parsing through an interaction between\nsyntactic and semantic information, leading the parser to a coherent and\naccurate interpretation of the input text.", "published": "2016-01-21 20:19:31", "link": "http://arxiv.org/abs/1601.05768v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
