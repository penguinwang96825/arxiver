{"title": "Play to Generalize: Learning to Reason Through Game Play", "abstract": "Developing generalizable reasoning capabilities in multimodal large language\nmodels (MLLMs) remains challenging. Motivated by cognitive science literature\nsuggesting that gameplay promotes transferable cognitive skills, we propose a\nnovel post-training paradigm, Visual Game Learning, or ViGaL, where MLLMs\ndevelop out-of-domain generalization of multimodal reasoning through playing\narcade-like games. Specifically, we show that post-training a 7B-parameter MLLM\nvia reinforcement learning (RL) on simple arcade-like games, e.g. Snake,\nsignificantly enhances its downstream performance on multimodal math benchmarks\nlike MathVista, and on multi-discipline questions like MMMU, without seeing any\nworked solutions, equations, or diagrams during RL, suggesting the capture of\ntransferable reasoning skills. Remarkably, our model outperforms specialist\nmodels tuned on multimodal reasoning data in multimodal reasoning benchmarks,\nwhile preserving the base model's performance on general visual benchmarks, a\nchallenge where specialist models often fall short. Our findings suggest a new\npost-training paradigm: synthetic, rule-based games can serve as controllable\nand scalable pre-text tasks that unlock generalizable multimodal reasoning\nabilities in MLLMs.", "published": "2025-06-09 17:59:57", "link": "http://arxiv.org/abs/2506.08011v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Reinforcement Pre-Training", "abstract": "In this work, we introduce Reinforcement Pre-Training (RPT) as a new scaling\nparadigm for large language models and reinforcement learning (RL).\nSpecifically, we reframe next-token prediction as a reasoning task trained\nusing RL, where it receives verifiable rewards for correctly predicting the\nnext token for a given context. RPT offers a scalable method to leverage vast\namounts of text data for general-purpose RL, rather than relying on\ndomain-specific annotated answers. By incentivizing the capability of\nnext-token reasoning, RPT significantly improves the language modeling accuracy\nof predicting the next tokens. Moreover, RPT provides a strong pre-trained\nfoundation for further reinforcement fine-tuning. The scaling curves show that\nincreased training compute consistently improves the next-token prediction\naccuracy. The results position RPT as an effective and promising scaling\nparadigm to advance language model pre-training.", "published": "2025-06-09 17:59:53", "link": "http://arxiv.org/abs/2506.08007v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reparameterized LLM Training via Orthogonal Equivalence Transformation", "abstract": "While large language models (LLMs) are driving the rapid advancement of\nartificial intelligence, effectively and reliably training these large models\nremains one of the field's most significant challenges. To address this\nchallenge, we propose POET, a novel reParameterized training algorithm that\nuses Orthogonal Equivalence Transformation to optimize neurons. Specifically,\nPOET reparameterizes each neuron with two learnable orthogonal matrices and a\nfixed random weight matrix. Because of its provable preservation of spectral\nproperties of weight matrices, POET can stably optimize the objective function\nwith improved generalization. We further develop efficient approximations that\nmake POET flexible and scalable for training large-scale neural networks.\nExtensive experiments validate the effectiveness and scalability of POET in\ntraining LLMs.", "published": "2025-06-09 17:59:34", "link": "http://arxiv.org/abs/2506.08001v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "$\u03c4^2$-Bench: Evaluating Conversational Agents in a Dual-Control Environment", "abstract": "Existing benchmarks for conversational AI agents simulate single-control\nenvironments, where only the AI agent can use tools to interact with the world,\nwhile the user remains a passive information provider. This differs from\nreal-world scenarios like technical support, where users need to actively\nparticipate in modifying the state of the (shared) world. In order to address\nthis gap, we introduce $\\tau^2$-bench, with four key contributions:\n  1) A novel Telecom dual-control domain modeled as a Dec-POMDP, where both\nagent and user make use of tools to act in a shared, dynamic environment that\ntests both agent coordination and communication,\n  2) A compositional task generator that programmatically creates diverse,\nverifiable tasks from atomic components, ensuring domain coverage and\ncontrolled complexity,\n  3) A reliable user simulator tightly coupled with the environment, whose\nbehavior is constrained by tools and observable states, improving simulation\nfidelity,\n  4) Fine-grained analysis of agent performance through multiple ablations\nincluding separating errors arising from reasoning vs\ncommunication/coordination.\n  In particular, our experiments show significant performance drops when agents\nshift from no-user to dual-control, highlighting the challenges of guiding\nusers. Overall, $\\tau^2$-bench provides a controlled testbed for agents that\nmust both reason effectively and guide user actions.", "published": "2025-06-09 17:52:18", "link": "http://arxiv.org/abs/2506.07982v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "HeuriGym: An Agentic Benchmark for LLM-Crafted Heuristics in Combinatorial Optimization", "abstract": "While Large Language Models (LLMs) have demonstrated significant advancements\nin reasoning and agent-based problem-solving, current evaluation methodologies\nfail to adequately assess their capabilities: existing benchmarks either rely\non closed-ended questions prone to saturation and memorization, or subjective\ncomparisons that lack consistency and rigor. In this work, we introduce\nHeuriGym, an agentic framework designed for evaluating heuristic algorithms\ngenerated by LLMs for combinatorial optimization problems, characterized by\nclearly defined objectives and expansive solution spaces. HeuriGym empowers\nLLMs to propose heuristics, receive evaluative feedback via code execution, and\niteratively refine their solutions. We evaluate nine state-of-the-art models on\nnine problems across domains such as computer systems, logistics, and biology,\nexposing persistent limitations in tool use, planning, and adaptive reasoning.\nTo quantify performance, we propose the Quality-Yield Index (QYI), a metric\nthat captures both solution pass rate and quality. Even top models like\nGPT-o4-mini-high and Gemini-2.5-Pro attain QYI scores of only 0.6, well below\nthe expert baseline of 1. Our open-source benchmark aims to guide the\ndevelopment of LLMs toward more effective and realistic problem-solving in\nscientific and engineering domains.", "published": "2025-06-09 17:46:47", "link": "http://arxiv.org/abs/2506.07972v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Reinforcing Multimodal Understanding and Generation with Dual Self-rewards", "abstract": "Building upon large language models (LLMs), recent large multimodal models\n(LMMs) unify cross-model understanding and generation into a single framework.\nHowever, LMMs still struggle to achieve accurate image-text alignment, prone to\ngenerating text responses contradicting the visual input or failing to follow\nthe text-to-image prompts. Current solutions require external supervision\n(e.g., human feedback or reward models) and only address unidirectional\ntasks-either understanding or generation. In this work, based on the\nobservation that understanding and generation are inverse dual tasks, we\nintroduce a self-supervised dual reward mechanism to reinforce the\nunderstanding and generation capabilities of LMMs. Specifically, we sample\nmultiple outputs for a given input in one task domain, then reverse the\ninput-output pairs to compute the dual likelihood of the model as self-rewards\nfor optimization. Extensive experimental results on visual understanding and\ngeneration benchmarks demonstrate that our method can effectively enhance the\nperformance of the model without any external supervision, especially achieving\nremarkable improvements in text-to-image tasks.", "published": "2025-06-09 17:38:45", "link": "http://arxiv.org/abs/2506.07963v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Correlated Errors in Large Language Models", "abstract": "Diversity in training data, architecture, and providers is assumed to\nmitigate homogeneity in LLMs. However, we lack empirical evidence on whether\ndifferent LLMs differ meaningfully. We conduct a large-scale empirical\nevaluation on over 350 LLMs overall, using two popular leaderboards and a\nresume-screening task. We find substantial correlation in model errors -- on\none leaderboard dataset, models agree 60% of the time when both models err. We\nidentify factors driving model correlation, including shared architectures and\nproviders. Crucially, however, larger and more accurate models have highly\ncorrelated errors, even with distinct architectures and providers. Finally, we\nshow the effects of correlation in two downstream tasks: LLM-as-judge\nevaluation and hiring -- the latter reflecting theoretical predictions\nregarding algorithmic monoculture.", "published": "2025-06-09 17:37:18", "link": "http://arxiv.org/abs/2506.07962v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Language Models over Canonical Byte-Pair Encodings", "abstract": "Modern language models represent probability distributions over character\nstrings as distributions over (shorter) token strings derived via a\ndeterministic tokenizer, such as byte-pair encoding. While this approach is\nhighly effective at scaling up language models to large corpora, its current\nincarnations have a concerning property: the model assigns nonzero probability\nmass to an exponential number of $\\it{noncanonical}$ token encodings of each\ncharacter string -- these are token strings that decode to valid character\nstrings but are impossible under the deterministic tokenizer (i.e., they will\nnever be seen in any training corpus, no matter how large). This misallocation\nis both erroneous, as noncanonical strings never appear in training data, and\nwasteful, diverting probability mass away from plausible outputs. These are\navoidable mistakes! In this work, we propose methods to enforce canonicality in\ntoken-level language models, ensuring that only canonical token strings are\nassigned positive probability. We present two approaches: (1) canonicality by\nconditioning, leveraging test-time inference strategies without additional\ntraining, and (2) canonicality by construction, a model parameterization that\nguarantees canonical outputs but requires training. We demonstrate that fixing\ncanonicality mistakes improves the likelihood of held-out data for several\nmodels and corpora.", "published": "2025-06-09 17:26:14", "link": "http://arxiv.org/abs/2506.07956v1", "categories": ["cs.CL", "cs.FL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Statistical Hypothesis Testing for Auditing Robustness in Language Models", "abstract": "Consider the problem of testing whether the outputs of a large language model\n(LLM) system change under an arbitrary intervention, such as an input\nperturbation or changing the model variant. We cannot simply compare two LLM\noutputs since they might differ due to the stochastic nature of the system, nor\ncan we compare the entire output distribution due to computational\nintractability. While existing methods for analyzing text-based outputs exist,\nthey focus on fundamentally different problems, such as measuring bias or\nfairness. To this end, we introduce distribution-based perturbation analysis, a\nframework that reformulates LLM perturbation analysis as a frequentist\nhypothesis testing problem. We construct empirical null and alternative output\ndistributions within a low-dimensional semantic similarity space via Monte\nCarlo sampling, enabling tractable inference without restrictive distributional\nassumptions. The framework is (i) model-agnostic, (ii) supports the evaluation\nof arbitrary input perturbations on any black-box LLM, (iii) yields\ninterpretable p-values; (iv) supports multiple perturbations via controlled\nerror rates; and (v) provides scalar effect sizes. We demonstrate the\nusefulness of the framework across multiple case studies, showing how we can\nquantify response changes, measure true/false positive rates, and evaluate\nalignment with reference models. Above all, we see this as a reliable\nfrequentist hypothesis testing framework for LLM auditing.", "published": "2025-06-09 17:11:07", "link": "http://arxiv.org/abs/2506.07947v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ProtocolLLM: RTL Benchmark for SystemVerilog Generation of Communication Protocols", "abstract": "Recent advances in Large Language Models (LLMs) have shown promising\ncapabilities in generating code for general-purpose programming languages. In\ncontrast, their applicability for hardware description languages, particularly\nfor generating synthesizable and functionally correct designs, remains\nsignificantly underexplored. HDLs such as SystemVerilog are logic-oriented and\ndemand strict adherence to timing semantics, concurrency, and synthesizability\nconstraints. Moreover, HDL-based design flows encompass a broad set of tasks\nbeyond structural code generation, including testbench development,\nassertion-based verification, timing closure, and protocol-level integration\nfor on-chip communication. The objective of our paper is to analyze the\ncapabilities of state-of-the-art LLMs in generating SystemVerilog\nimplementations of standard communication protocols, a core component of\nembedded and System-on-Chip (SoC) architectures. This paper introduces the\nfirst benchmark suite targeting four widely used protocols: SPI, I2C, UART, and\nAXI. We define code generation tasks that capture varying levels of design\nabstraction and prompt specificity. The generated designs are assessed for\nsyntactic correctness, synthesizability, and functional fidelity via waveform\nsimulation and test benches.", "published": "2025-06-09 17:10:47", "link": "http://arxiv.org/abs/2506.07945v1", "categories": ["cs.AR", "cs.AI", "cs.CL"], "primary_category": "cs.AR"}
{"title": "Quantum Graph Transformer for NLP Sentiment Classification", "abstract": "Quantum machine learning is a promising direction for building more efficient\nand expressive models, particularly in domains where understanding complex,\nstructured data is critical. We present the Quantum Graph Transformer (QGT), a\nhybrid graph-based architecture that integrates a quantum self-attention\nmechanism into the message-passing framework for structured language modeling.\nThe attention mechanism is implemented using parameterized quantum circuits\n(PQCs), which enable the model to capture rich contextual relationships while\nsignificantly reducing the number of trainable parameters compared to classical\nattention mechanisms. We evaluate QGT on five sentiment classification\nbenchmarks. Experimental results show that QGT consistently achieves higher or\ncomparable accuracy than existing quantum natural language processing (QNLP)\nmodels, including both attention-based and non-attention-based approaches. When\ncompared with an equivalent classical graph transformer, QGT yields an average\naccuracy improvement of 5.42% on real-world datasets and 4.76% on synthetic\ndatasets. Additionally, QGT demonstrates improved sample efficiency, requiring\nnearly 50% fewer labeled samples to reach comparable performance on the Yelp\ndataset. These results highlight the potential of graph-based QNLP techniques\nfor advancing efficient and scalable language understanding.", "published": "2025-06-09 16:55:41", "link": "http://arxiv.org/abs/2506.07937v1", "categories": ["cs.CL", "quant-ph"], "primary_category": "cs.CL"}
{"title": "Mimicking or Reasoning: Rethinking Multi-Modal In-Context Learning in Vision-Language Models", "abstract": "Vision-language models (VLMs) are widely assumed to exhibit in-context\nlearning (ICL), a property similar to that of their language-only counterparts.\nWhile recent work suggests VLMs can perform multimodal ICL (MM-ICL), studies\nshow they often rely on shallow heuristics -- such as copying or majority\nvoting -- rather than true task understanding. We revisit this assumption by\nevaluating VLMs under distribution shifts, where support examples come from a\ndataset different from the query. Surprisingly, performance often degrades with\nmore demonstrations, and models tend to copy answers rather than learn from\nthem. To investigate further, we propose a new MM-ICL with Reasoning pipeline\nthat augments each demonstration with a generated rationale alongside the\nanswer. We conduct extensive and comprehensive experiments on both perception-\nand reasoning-required datasets with open-source VLMs ranging from 3B to 72B\nand proprietary models such as Gemini 2.0. We conduct controlled studies\nvarying shot count, retrieval method, rationale quality, and distribution. Our\nresults show limited performance sensitivity across these factors, suggesting\nthat current VLMs do not effectively utilize demonstration-level information as\nintended in MM-ICL.", "published": "2025-06-09 16:55:32", "link": "http://arxiv.org/abs/2506.07936v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Solving Inequality Proofs with Large Language Models", "abstract": "Inequality proving, crucial across diverse scientific and mathematical\nfields, tests advanced reasoning skills such as discovering tight bounds and\nstrategic theorem application. This makes it a distinct, demanding frontier for\nlarge language models (LLMs), offering insights beyond general mathematical\nproblem-solving. Progress in this area is hampered by existing datasets that\nare often scarce, synthetic, or rigidly formal. We address this by proposing an\ninformal yet verifiable task formulation, recasting inequality proving into two\nautomatically checkable subtasks: bound estimation and relation prediction.\nBuilding on this, we release IneqMath, an expert-curated dataset of\nOlympiad-level inequalities, including a test set and training corpus enriched\nwith step-wise solutions and theorem annotations. We also develop a novel\nLLM-as-judge evaluation framework, combining a final-answer judge with four\nstep-wise judges designed to detect common reasoning flaws. A systematic\nevaluation of 29 leading LLMs on IneqMath reveals a surprising reality: even\ntop models like o1 achieve less than 10% overall accuracy under step-wise\nscrutiny; this is a drop of up to 65.5% from their accuracy considering only\nfinal answer equivalence. This discrepancy exposes fragile deductive chains and\na critical gap for current LLMs between merely finding an answer and\nconstructing a rigorous proof. Scaling model size and increasing test-time\ncomputation yield limited gains in overall proof correctness. Instead, our\nfindings highlight promising research directions such as theorem-guided\nreasoning and self-refinement. Code and data are available at\nhttps://ineqmath.github.io/.", "published": "2025-06-09 16:43:38", "link": "http://arxiv.org/abs/2506.07927v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Uncovering the Functional Roles of Nonlinearity in Memory", "abstract": "Memory and long-range temporal processing are core requirements for sequence\nmodeling tasks across natural language processing, time-series forecasting,\nspeech recognition, and control. While nonlinear recurrence has long been\nviewed as essential for enabling such mechanisms, recent work suggests that\nlinear dynamics may often suffice. In this study, we go beyond performance\ncomparisons to systematically dissect the functional role of nonlinearity in\nrecurrent networks--identifying both when it is computationally necessary, and\nwhat mechanisms it enables. We use Almost Linear Recurrent Neural Networks\n(AL-RNNs), which allow fine-grained control over nonlinearity, as both a\nflexible modeling tool and a probe into the internal mechanisms of memory.\nAcross a range of classic sequence modeling tasks and a real-world stimulus\nselection task, we find that minimal nonlinearity is not only sufficient but\noften optimal, yielding models that are simpler, more robust, and more\ninterpretable than their fully nonlinear or linear counterparts. Our results\nprovide a principled framework for selectively introducing nonlinearity,\nbridging dynamical systems theory with the functional demands of long-range\nmemory and structured computation in recurrent neural networks, with\nimplications for both artificial and biological neural systems.", "published": "2025-06-09 16:32:19", "link": "http://arxiv.org/abs/2506.07919v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "nlin.CD", "physics.comp-ph"], "primary_category": "cs.LG"}
{"title": "LUCIFER: Language Understanding and Context-Infused Framework for Exploration and Behavior Refinement", "abstract": "In dynamic environments, the rapid obsolescence of pre-existing environmental\nknowledge creates a gap between an agent's internal model and the evolving\nreality of its operational context. This disparity between prior and updated\nenvironmental valuations fundamentally limits the effectiveness of autonomous\ndecision-making. To bridge this gap, the contextual bias of human domain\nstakeholders, who naturally accumulate insights through direct, real-time\nobservation, becomes indispensable. However, translating their nuanced, and\ncontext-rich input into actionable intelligence for autonomous systems remains\nan open challenge. To address this, we propose LUCIFER (Language Understanding\nand Context-Infused Framework for Exploration and Behavior Refinement), a\ndomain-agnostic framework that integrates a hierarchical decision-making\narchitecture with reinforcement learning (RL) and large language models (LLMs)\ninto a unified system. This architecture mirrors how humans decompose complex\ntasks, enabling a high-level planner to coordinate specialised sub-agents, each\nfocused on distinct objectives and temporally interdependent actions. Unlike\ntraditional applications where LLMs are limited to single role, LUCIFER\nintegrates them in two synergistic roles: as context extractors, structuring\nverbal stakeholder input into domain-aware representations that influence\ndecision-making through an attention space mechanism aligning LLM-derived\ninsights with the agent's learning process, and as zero-shot exploration\nfacilitators guiding the agent's action selection process during exploration.\nWe benchmark various LLMs in both roles and demonstrate that LUCIFER improves\nexploration efficiency and decision quality, outperforming flat,\ngoal-conditioned policies. Our findings show the potential of context-driven\ndecision-making, where autonomous systems leverage human contextual knowledge\nfor operational success.", "published": "2025-06-09 16:30:05", "link": "http://arxiv.org/abs/2506.07915v1", "categories": ["cs.AI", "cs.CL", "cs.SY", "eess.SY"], "primary_category": "cs.AI"}
{"title": "MiniCPM4: Ultra-Efficient LLMs on End Devices", "abstract": "This paper introduces MiniCPM4, a highly efficient large language model (LLM)\ndesigned explicitly for end-side devices. We achieve this efficiency through\nsystematic innovation in four key dimensions: model architecture, training\ndata, training algorithms, and inference systems. Specifically, in terms of\nmodel architecture, we propose InfLLM v2, a trainable sparse attention\nmechanism that accelerates both prefilling and decoding phases for long-context\nprocessing. Regarding training data, we propose UltraClean, an efficient and\naccurate pre-training data filtering and generation strategy, and UltraChat v2,\na comprehensive supervised fine-tuning dataset. These datasets enable\nsatisfactory model performance to be achieved using just 8 trillion training\ntokens. Regarding training algorithms, we propose ModelTunnel v2 for efficient\npre-training strategy search, and improve existing post-training methods by\nintroducing chunk-wise rollout for load-balanced reinforcement learning and\ndata-efficient tenary LLM, BitCPM. Regarding inference systems, we propose\nCPM.cu that integrates sparse attention, model quantization, and speculative\nsampling to achieve efficient prefilling and decoding. To meet diverse\non-device requirements, MiniCPM4 is available in two versions, with 0.5B and 8B\nparameters, respectively. Sufficient evaluation results show that MiniCPM4\noutperforms open-source models of similar size across multiple benchmarks,\nhighlighting both its efficiency and effectiveness. Notably, MiniCPM4-8B\ndemonstrates significant speed improvements over Qwen3-8B when processing long\nsequences. Through further adaptation, MiniCPM4 successfully powers diverse\napplications, including trustworthy survey generation and tool use with model\ncontext protocol, clearly showcasing its broad usability.", "published": "2025-06-09 16:16:50", "link": "http://arxiv.org/abs/2506.07900v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MEMOIR: Lifelong Model Editing with Minimal Overwrite and Informed Retention for LLMs", "abstract": "Language models deployed in real-world systems often require post-hoc updates\nto incorporate new or corrected knowledge. However, editing such models\nefficiently and reliably - without retraining or forgetting previous\ninformation - remains a major challenge. Existing methods for lifelong model\nediting either compromise generalization, interfere with past edits, or fail to\nscale to long editing sequences. We propose MEMOIR, a novel scalable framework\nthat injects knowledge through a residual memory, i.e., a dedicated parameter\nmodule, while preserving the core capabilities of the pre-trained model. By\nsparsifying input activations through sample-dependent masks, MEMOIR confines\neach edit to a distinct subset of the memory parameters, minimizing\ninterference among edits. At inference, it identifies relevant edits by\ncomparing the sparse activation patterns of new queries to those stored during\nediting. This enables generalization to rephrased queries by activating only\nthe relevant knowledge while suppressing unnecessary memory activation for\nunrelated prompts. Experiments on question answering, hallucination correction,\nand out-of-distribution generalization benchmarks across LLaMA-3 and Mistral\ndemonstrate that MEMOIR achieves state-of-the-art performance across\nreliability, generalization, and locality metrics, scaling to thousands of\nsequential edits with minimal forgetting.", "published": "2025-06-09 16:16:42", "link": "http://arxiv.org/abs/2506.07899v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Evaluating Large Language Models on the Frame and Symbol Grounding Problems: A Zero-shot Benchmark", "abstract": "Recent advancements in large language models (LLMs) have revitalized\nphilosophical debates surrounding artificial intelligence. Two of the most\nfundamental challenges - namely, the Frame Problem and the Symbol Grounding\nProblem - have historically been viewed as unsolvable within traditional\nsymbolic AI systems. This study investigates whether modern LLMs possess the\ncognitive capacities required to address these problems. To do so, I designed\ntwo benchmark tasks reflecting the philosophical core of each problem,\nadministered them under zero-shot conditions to 13 prominent LLMs (both closed\nand open-source), and assessed the quality of the models' outputs across five\ntrials each. Responses were scored along multiple criteria, including\ncontextual reasoning, semantic coherence, and information filtering. The\nresults demonstrate that while open-source models showed variability in\nperformance due to differences in model size, quantization, and instruction\ntuning, several closed models consistently achieved high scores. These findings\nsuggest that select modern LLMs may be acquiring capacities sufficient to\nproduce meaningful and stable responses to these long-standing theoretical\nchallenges.", "published": "2025-06-09 16:12:47", "link": "http://arxiv.org/abs/2506.07896v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Learning to Focus: Causal Attention Distillation via Gradient-Guided Token Pruning", "abstract": "Large language models (LLMs) have demonstrated significant improvements in\ncontextual understanding. However, their ability to attend to truly critical\ninformation during long-context reasoning and generation still falls behind the\npace. Specifically, our preliminary experiments reveal that certain distracting\npatterns can misdirect the model's attention during inference, and removing\nthese patterns substantially improves reasoning accuracy and generation\nquality. We attribute this phenomenon to spurious correlations in the training\ndata, which obstruct the model's capacity to infer authentic causal\ninstruction-response relationships. This phenomenon may induce redundant\nreasoning processes, potentially resulting in significant inference overhead\nand, more critically, the generation of erroneous or suboptimal responses. To\nmitigate this, we introduce a two-stage framework called Learning to Focus\n(LeaF) leveraging intervention-based inference to disentangle confounding\nfactors. In the first stage, LeaF employs gradient-based comparisons with an\nadvanced teacher to automatically identify confounding tokens based on causal\nrelationships in the training corpus. Then, in the second stage, it prunes\nthese tokens during distillation to enact intervention, aligning the student's\nattention with the teacher's focus distribution on truly critical context\ntokens. Experimental results demonstrate that LeaF not only achieves an\nabsolute improvement in various mathematical reasoning and code generation\nbenchmarks but also effectively suppresses attention to confounding tokens\nduring inference, yielding a more interpretable and reliable reasoning model.", "published": "2025-06-09 15:16:39", "link": "http://arxiv.org/abs/2506.07851v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving large language models with concept-aware fine-tuning", "abstract": "Large language models (LLMs) have become the cornerstone of modern AI.\nHowever, the existing paradigm of next-token prediction fundamentally limits\ntheir ability to form coherent, high-level concepts, making it a critical\nbarrier to human-like understanding and reasoning. Take the phrase \"ribonucleic\nacid\" as an example: an LLM will first decompose it into tokens, i.e.,\nartificial text fragments (\"rib\", \"on\", ...), then learn each token\nsequentially, rather than grasping the phrase as a unified, coherent semantic\nentity. This fragmented representation hinders deeper conceptual understanding\nand, ultimately, the development of truly intelligent systems. In response, we\nintroduce Concept-Aware Fine-Tuning (CAFT), a novel multi-token training method\nthat redefines how LLMs are fine-tuned. By enabling the learning of sequences\nthat span multiple tokens, this method fosters stronger concept-aware learning.\nOur experiments demonstrate significant improvements compared to conventional\nnext-token finetuning methods across diverse tasks, including traditional\napplications like text summarization and domain-specific ones like de novo\nprotein design. Multi-token prediction was previously only possible in the\nprohibitively expensive pretraining phase; CAFT, to our knowledge, is the first\nto bring the multi-token setting to the post-training phase, thus effectively\ndemocratizing its benefits for the broader community of practitioners and\nresearchers. Finally, the unexpected effectiveness of our proposed method\nsuggests wider implications for the machine learning research community. All\ncode and data are available at https://github.com/michaelchen-lab/caft-llm", "published": "2025-06-09 14:55:00", "link": "http://arxiv.org/abs/2506.07833v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "WebUIBench: A Comprehensive Benchmark for Evaluating Multimodal Large Language Models in WebUI-to-Code", "abstract": "With the rapid advancement of Generative AI technology, Multimodal Large\nLanguage Models(MLLMs) have the potential to act as AI software engineers\ncapable of executing complex web application development. Considering that the\nmodel requires a confluence of multidimensional sub-capabilities to address the\nchallenges of various development phases, constructing a multi-view evaluation\nframework is crucial for accurately guiding the enhancement of development\nefficiency. However, existing benchmarks usually fail to provide an assessment\nof sub-capabilities and focus solely on webpage generation outcomes. In this\nwork, we draw inspiration from the principles of software engineering and\nfurther propose WebUIBench, a benchmark systematically designed to evaluate\nMLLMs in four key areas: WebUI Perception, HTML Programming,WebUI-HTML\nUnderstanding, and WebUI-to-Code. WebUIBench comprises 21K high-quality\nquestion-answer pairs derived from over 0.7K real-world websites. The extensive\nevaluation of 29 mainstream MLLMs uncovers the skill characteristics and\nvarious weakness that models encountered during the development process.", "published": "2025-06-09 14:46:02", "link": "http://arxiv.org/abs/2506.07818v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MultiMatch: Multihead Consistency Regularization Matching for Semi-Supervised Text Classification", "abstract": "We introduce MultiMatch, a novel semi-supervised learning (SSL) algorithm\ncombining the paradigms of co-training and consistency regularization with\npseudo-labeling. At its core, MultiMatch features a three-fold pseudo-label\nweighting module designed for three key purposes: selecting and filtering\npseudo-labels based on head agreement and model confidence, and weighting them\naccording to the perceived classification difficulty. This novel module\nenhances and unifies three existing techniques -- heads agreement from\nMultihead Co-training, self-adaptive thresholds from FreeMatch, and Average\nPseudo-Margins from MarginMatch -- resulting in a holistic approach that\nimproves robustness and performance in SSL settings. Experimental results on\nbenchmark datasets highlight the superior performance of MultiMatch, achieving\nstate-of-the-art results on 9 out of 10 setups from 5 natural language\nprocessing datasets and ranking first according to the Friedman test among 19\nmethods. Furthermore, MultiMatch demonstrates exceptional robustness in highly\nimbalanced settings, outperforming the second-best approach by 3.26% -- and\ndata imbalance is a key factor for many text classification tasks.", "published": "2025-06-09 14:27:47", "link": "http://arxiv.org/abs/2506.07801v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "LLM Unlearning Should Be Form-Independent", "abstract": "Large Language Model (LLM) unlearning aims to erase or suppress undesirable\nknowledge within the model, offering promise for controlling harmful or private\ninformation to prevent misuse. However, recent studies highlight its limited\nefficacy in real-world scenarios, hindering practical adoption. In this study,\nwe identify a pervasive issue underlying many downstream failures: the\neffectiveness of existing unlearning methods heavily depends on the form of\ntraining samples and frequently fails to generalize to alternate expressions of\nthe same knowledge. We formally characterize this problem as Form-Dependent\nBias and systematically investigate its specific manifestation patterns across\nvarious downstream tasks. To quantify its prevalence and support future\nresearch, we introduce ORT, a novel benchmark designed to evaluate the\nrobustness of unlearning methods against variations in knowledge expression.\nResults reveal that Form-Dependent Bias is both widespread and severe among\ncurrent techniques.\n  We argue that LLM unlearning should be form-independent to address the\nendless forms of downstream tasks encountered in real-world security-critical\nscenarios. Towards this goal, we introduce Rank-one Concept Redirection (ROCR),\na novel training-free method, as a promising solution path. ROCR performs\nunlearning by targeting the invariants in downstream tasks, specifically the\nactivated dangerous concepts. It is capable of modifying model parameters\nwithin seconds to redirect the model's perception of a specific unlearning\ntarget concept to another harmless concept. Extensive experiments demonstrate\nthat ROCR significantly improves unlearning effectiveness compared to\ntraditional methods while generating highly natural outputs.", "published": "2025-06-09 14:21:25", "link": "http://arxiv.org/abs/2506.07795v1", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Augmenting LLMs' Reasoning by Reinforcing Abstract Thinking", "abstract": "Recent studies have shown that large language models (LLMs), especially\nsmaller ones, often lack robustness in their reasoning. I.e., they tend to\nexperience performance drops when faced with distribution shifts, such as\nchanges to numerical or nominal variables, or insertions of distracting\nclauses. A possible strategy to address this involves generating synthetic data\nto further \"instantiate\" reasoning problems on potential variations. In\ncontrast, our approach focuses on \"abstracting\" reasoning problems. This not\nonly helps counteract distribution shifts but also facilitates the connection\nto symbolic tools for deriving solutions. We find that this abstraction process\nis better acquired through reinforcement learning (RL) than just supervised\nfine-tuning, which often fails to produce faithful abstractions. Our method,\nAbstraL -- which promotes abstract reasoning in LLMs using RL on granular\nabstraction data -- significantly mitigates performance degradation on recent\nGSM perturbation benchmarks.", "published": "2025-06-09 13:34:50", "link": "http://arxiv.org/abs/2506.07751v1", "categories": ["cs.CL", "cs.AI", "cs.SC"], "primary_category": "cs.CL"}
{"title": "Swiss Parliaments Corpus Re-Imagined (SPC_R): Enhanced Transcription with RAG-based Correction and Predicted BLEU", "abstract": "This paper presents a new long-form release of the Swiss Parliaments Corpus,\nconverting entire multi-hour Swiss German debate sessions (each aligned with\nthe official session protocols) into high-quality speech-text pairs. Our\npipeline starts by transcribing all session audio into Standard German using\nWhisper Large-v3 under high-compute settings. We then apply a two-step GPT-4o\ncorrection process: first, GPT-4o ingests the raw Whisper output alongside the\nofficial protocols to refine misrecognitions, mainly named entities. Second, a\nseparate GPT-4o pass evaluates each refined segment for semantic completeness.\nWe filter out any segments whose Predicted BLEU score (derived from Whisper's\naverage token log-probability) and GPT-4o evaluation score fall below a certain\nthreshold. The final corpus contains 801 hours of audio, of which 751 hours\npass our quality control. Compared to the original sentence-level SPC release,\nour long-form dataset achieves a 6-point BLEU improvement, demonstrating the\npower of combining robust ASR, LLM-based correction, and data-driven filtering\nfor low-resource, domain-specific speech corpora.", "published": "2025-06-09 13:11:18", "link": "http://arxiv.org/abs/2506.07726v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual Grammatical Error Annotation: Combining Language-Agnostic Framework with Language-Specific Flexibility", "abstract": "Grammatical Error Correction (GEC) relies on accurate error annotation and\nevaluation, yet existing frameworks, such as $\\texttt{errant}$, face\nlimitations when extended to typologically diverse languages. In this paper, we\nintroduce a standardized, modular framework for multilingual grammatical error\nannotation. Our approach combines a language-agnostic foundation with\nstructured language-specific extensions, enabling both consistency and\nflexibility across languages. We reimplement $\\texttt{errant}$ using\n$\\texttt{stanza}$ to support broader multilingual coverage, and demonstrate the\nframework's adaptability through applications to English, German, Czech,\nKorean, and Chinese, ranging from general-purpose annotation to more customized\nlinguistic refinements. This work supports scalable and interpretable GEC\nannotation across languages and promotes more consistent evaluation in\nmultilingual settings. The complete codebase and annotation tools can be\naccessed at https://github.com/open-writing-evaluation/jp_errant_bea.", "published": "2025-06-09 13:01:19", "link": "http://arxiv.org/abs/2506.07719v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Through the Valley: Path to Effective Long CoT Training for Small Language Models", "abstract": "Long chain-of-thought (CoT) supervision has become a common strategy to\nenhance reasoning in language models. While effective for large models, we\nidentify a phenomenon we call Long CoT Degradation, in which small language\nmodels (SLMs; <=3B parameters) trained on limited long CoT data experience\nsignificant performance deterioration. Through extensive experiments on the\nQwen2.5, LLaMA3 and Gemma3 families, we demonstrate that this degradation is\nwidespread across SLMs. In some settings, models trained on only 8k long CoT\nexamples lose up to 75% of their original performance before fine-tuning.\nStrikingly, we further observe that for some particularly small models, even\ntraining on 220k long CoT examples fails to recover or surpass their original\nperformance prior to fine-tuning. Our analysis attributes this effect to error\naccumulation: while longer responses increase the capacity for multi-step\nreasoning, they also amplify the risk of compounding mistakes. Furthermore, we\nfind that Long CoT Degradation may negatively impacts downstream reinforcement\nlearning (RL), although this can be alleviated by sufficiently scaled\nsupervised fine-tuning (SFT). Our findings challenge common assumptions about\nthe benefits of long CoT training for SLMs and offer practical guidance for\nbuilding more effective small-scale reasoning models.", "published": "2025-06-09 12:56:41", "link": "http://arxiv.org/abs/2506.07712v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Training Superior Sparse Autoencoders for Instruct Models", "abstract": "As large language models (LLMs) grow in scale and capability, understanding\ntheir internal mechanisms becomes increasingly critical. Sparse autoencoders\n(SAEs) have emerged as a key tool in mechanistic interpretability, enabling the\nextraction of human-interpretable features from LLMs. However, existing SAE\ntraining methods are primarily designed for base models, resulting in reduced\nreconstruction quality and interpretability when applied to instruct models. To\nbridge this gap, we propose\n$\\underline{\\textbf{F}}$inetuning-$\\underline{\\textbf{a}}$ligned\n$\\underline{\\textbf{S}}$equential $\\underline{\\textbf{T}}$raining\n($\\textit{FAST}$), a novel training method specifically tailored for instruct\nmodels. $\\textit{FAST}$ aligns the training process with the data distribution\nand activation patterns characteristic of instruct models, resulting in\nsubstantial improvements in both reconstruction and feature interpretability.\nOn Qwen2.5-7B-Instruct, $\\textit{FAST}$ achieves a mean squared error of 0.6468\nin token reconstruction, significantly outperforming baseline methods with\nerrors of 5.1985 and 1.5096. In feature interpretability, $\\textit{FAST}$\nyields a higher proportion of high-quality features, for Llama3.2-3B-Instruct,\n$21.1\\%$ scored in the top range, compared to $7.0\\%$ and $10.2\\%$ for\n$\\textit{BT(P)}$ and $\\textit{BT(F)}$. Surprisingly, we discover that\nintervening on the activations of special tokens via the SAEs leads to\nimprovements in output quality, suggesting new opportunities for fine-grained\ncontrol of model behavior. Code, data, and 240 trained SAEs are available at\nhttps://github.com/Geaming2002/FAST.", "published": "2025-06-09 12:23:34", "link": "http://arxiv.org/abs/2506.07691v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GaRAGe: A Benchmark with Grounding Annotations for RAG Evaluation", "abstract": "We present GaRAGe, a large RAG benchmark with human-curated long-form answers\nand annotations of each grounding passage, allowing a fine-grained evaluation\nof whether LLMs can identify relevant grounding when generating RAG answers.\nOur benchmark contains 2366 questions of diverse complexity, dynamism, and\ntopics, and includes over 35K annotated passages retrieved from both private\ndocument sets and the Web, to reflect real-world RAG use cases. This makes it\nan ideal test bed to evaluate an LLM's ability to identify only the relevant\ninformation necessary to compose a response, or provide a deflective response\nwhen there is insufficient information. Evaluations of multiple\nstate-of-the-art LLMs on GaRAGe show that the models tend to over-summarise\nrather than (a) ground their answers strictly on the annotated relevant\npassages (reaching at most a Relevance-Aware Factuality Score of 60%), or (b)\ndeflect when no relevant grounding is available (reaching at most 31% true\npositive rate in deflections). The F1 in attribution to relevant sources is at\nmost 58.9%, and we show that performance is particularly reduced when answering\ntime-sensitive questions and when having to draw knowledge from sparser private\ngrounding sources.", "published": "2025-06-09 11:47:03", "link": "http://arxiv.org/abs/2506.07671v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Silencing Empowerment, Allowing Bigotry: Auditing the Moderation of Hate Speech on Twitch", "abstract": "To meet the demands of content moderation, online platforms have resorted to\nautomated systems. Newer forms of real-time engagement($\\textit{e.g.}$, users\ncommenting on live streams) on platforms like Twitch exert additional pressures\non the latency expected of such moderation systems. Despite their prevalence,\nrelatively little is known about the effectiveness of these systems. In this\npaper, we conduct an audit of Twitch's automated moderation tool\n($\\texttt{AutoMod}$) to investigate its effectiveness in flagging hateful\ncontent. For our audit, we create streaming accounts to act as siloed test\nbeds, and interface with the live chat using Twitch's APIs to send over\n$107,000$ comments collated from $4$ datasets. We measure $\\texttt{AutoMod}$'s\naccuracy in flagging blatantly hateful content containing misogyny, racism,\nableism and homophobia. Our experiments reveal that a large fraction of hateful\nmessages, up to $94\\%$ on some datasets, $\\textit{bypass moderation}$.\nContextual addition of slurs to these messages results in $100\\%$ removal,\nrevealing $\\texttt{AutoMod}$'s reliance on slurs as a moderation signal. We\nalso find that contrary to Twitch's community guidelines, $\\texttt{AutoMod}$\nblocks up to $89.5\\%$ of benign examples that use sensitive words in\npedagogical or empowering contexts. Overall, our audit points to large gaps in\n$\\texttt{AutoMod}$'s capabilities and underscores the importance for such\nsystems to understand context effectively.", "published": "2025-06-09 11:39:39", "link": "http://arxiv.org/abs/2506.07667v1", "categories": ["cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Synthesis by Design: Controlled Data Generation via Structural Guidance", "abstract": "Mathematical reasoning remains challenging for LLMs due to complex logic and\nthe need for precise computation. Existing methods enhance LLM reasoning by\nsynthesizing datasets through problem rephrasing, but face issues with\ngeneration quality and problem complexity. To address this, we propose to\nextract structural information with generated problem-solving code from\nmathematical reasoning and guide data generation with structured solutions.\nApplied to MATH and GSM8K, our approach produces 39K problems with labeled\nintermediate steps and a 6.1K-problem benchmark of higher difficulty. Results\non our benchmark show that model performance declines as reasoning length\nincreases. Additionally, we conducted fine-tuning experiments using the\nproposed training data on a range of LLMs, and the results validate the\neffectiveness of our dataset. We hope the proposed method and dataset will\ncontribute to future research in enhancing LLM reasoning capabilities.", "published": "2025-06-09 11:38:23", "link": "http://arxiv.org/abs/2506.07664v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Beyond Benchmarks: A Novel Framework for Domain-Specific LLM Evaluation and Knowledge Mapping", "abstract": "The paper addresses two critical challenges in language model (LM)\nevaluation: creating reliable domain-specific benchmarks and understanding\nknowledge representation during domain adaptation. We introduce a deterministic\npipeline that converts raw domain corpora into completion-type benchmarks\nwithout relying on LMs or human curation, eliminating benchmark contamination\nissues while enabling evaluation on the latest domain data. Our approach\ngenerates domain-specific keywords and related word lists using TF and Term\nTF-IDF methods and constructs prompt-target pairs. We evaluate models by\nmeasuring their ability to complete these prompts with the correct\ndomain-specific targets, providing a direct assessment of domain knowledge with\nlow computational cost. Through comprehensive experiments across multiple\nmodels (GPT-2 medium/XL, Llama-2/3.1, OLMo-2, Qwen-2, Mistral) and domains, we\ndemonstrate that our benchmark strongly correlates with expert-generated\nbenchmarks while providing a more accurate measure of domain knowledge than\ntraditional perplexity metrics. We reveal that domain adaptation happens\nrapidly in smaller models (within 500 steps) and illustrate a new approach to\ndomain knowledge evaluation in base models during training for early stopping.\nBy extending mechanistic analysis to domain adaptation, we discover that\ninitial-to-mid layers are primarily responsible for attribute extraction, while\nlater layers focus on next token prediction. Furthermore, we show that during\nadaptation, forgetting begins in the middle layers, where attribute extraction\nhappens and is amplified in later layers. Our work provides both a practical\nevaluation methodology for domain-specific LMs and novel insights into\nknowledge representation during adaptation, with implications for more\nefficient fine-tuning strategies and targeted approaches to mitigate\ncatastrophic forgetting.", "published": "2025-06-09 11:30:12", "link": "http://arxiv.org/abs/2506.07658v1", "categories": ["cs.CL", "I.2.7; I.2.6"], "primary_category": "cs.CL"}
{"title": "Transcript-Prompted Whisper with Dictionary-Enhanced Decoding for Japanese Speech Annotation", "abstract": "In this paper, we propose a method for annotating phonemic and prosodic\nlabels on a given audio-transcript pair, aimed at constructing Japanese\ntext-to-speech (TTS) datasets. Our approach involves fine-tuning a large-scale\npre-trained automatic speech recognition (ASR) model, conditioned on ground\ntruth transcripts, to simultaneously output phrase-level graphemes and\nannotation labels. To further correct errors in phonemic labeling, we employ a\ndecoding strategy that utilizes dictionary prior knowledge. The objective\nevaluation results demonstrate that our proposed method outperforms previous\napproaches relying solely on text or audio. The subjective evaluation results\nindicate that the naturalness of speech synthesized by the TTS model, trained\nwith labels annotated using our method, is comparable to that of a model\ntrained with manual annotations.", "published": "2025-06-09 11:10:24", "link": "http://arxiv.org/abs/2506.07646v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Evaluating LLMs Robustness in Less Resourced Languages with Proxy Models", "abstract": "Large language models (LLMs) have demonstrated impressive capabilities across\nvarious natural language processing (NLP) tasks in recent years. However, their\nsusceptibility to jailbreaks and perturbations necessitates additional\nevaluations. Many LLMs are multilingual, but safety-related training data\ncontains mainly high-resource languages like English. This can leave them\nvulnerable to perturbations in low-resource languages such as Polish. We show\nhow surprisingly strong attacks can be cheaply created by altering just a few\ncharacters and using a small proxy model for word importance calculation. We\nfind that these character and word-level attacks drastically alter the\npredictions of different LLMs, suggesting a potential vulnerability that can be\nused to circumvent their internal safety mechanisms. We validate our attack\nconstruction methodology on Polish, a low-resource language, and find potential\nvulnerabilities of LLMs in this language. Additionally, we show how it can be\nextended to other languages. We release the created datasets and code for\nfurther research.", "published": "2025-06-09 11:09:39", "link": "http://arxiv.org/abs/2506.07645v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TreeReview: A Dynamic Tree of Questions Framework for Deep and Efficient LLM-based Scientific Peer Review", "abstract": "While Large Language Models (LLMs) have shown significant potential in\nassisting peer review, current methods often struggle to generate thorough and\ninsightful reviews while maintaining efficiency. In this paper, we propose\nTreeReview, a novel framework that models paper review as a hierarchical and\nbidirectional question-answering process. TreeReview first constructs a tree of\nreview questions by recursively decomposing high-level questions into\nfine-grained sub-questions and then resolves the question tree by iteratively\naggregating answers from leaf to root to get the final review. Crucially, we\nincorporate a dynamic question expansion mechanism to enable deeper probing by\ngenerating follow-up questions when needed. We construct a benchmark derived\nfrom ICLR and NeurIPS venues to evaluate our method on full review generation\nand actionable feedback comments generation tasks. Experimental results of both\nLLM-based and human evaluation show that TreeReview outperforms strong\nbaselines in providing comprehensive, in-depth, and expert-aligned review\nfeedback, while reducing LLM token usage by up to 80% compared to\ncomputationally intensive approaches. Our code and benchmark dataset are\navailable at https://github.com/YuanChang98/tree-review.", "published": "2025-06-09 11:07:55", "link": "http://arxiv.org/abs/2506.07642v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unblocking Fine-Grained Evaluation of Detailed Captions: An Explaining AutoRater and Critic-and-Revise Pipeline", "abstract": "Large Vision-Language Models (VLMs) now generate highly detailed,\nparagraphlength image captions, yet evaluating their factual accuracy remains\nchallenging. Current methods often miss fine-grained errors, being designed for\nshorter texts or lacking datasets with verified inaccuracies. We introduce\nDOCCI-Critique, a benchmark with 1,400 VLM-generated paragraph captions (100\nimages, 14 VLMs) featuring over 10,216 sentence-level human annotations of\nfactual correctness and explanatory rationales for errors, all within paragraph\ncontext. Building on this, we develop VNLI-Critique, a model for automated\nsentence-level factuality classification and critique generation. We highlight\nthree key applications: (1) VNLI-Critique demonstrates robust generalization,\nvalidated by state-of-the-art performance on the M-HalDetect benchmark and\nstrong results in CHOCOLATE claim verification. (2) The VNLI-Critique driven\nAutoRater for DOCCI-Critique provides reliable VLM rankings, showing excellent\nalignment with human factuality judgments (e.g., 0.98 Spearman). (3) An\ninnovative Critic-and-Revise pipeline, where critiques from VNLI-Critique guide\nLLM-based corrections, achieves substantial improvements in caption factuality\n(e.g., a 46% gain on DetailCaps-4870). Our work offers a crucial benchmark\nalongside practical tools, designed to significantly elevate the standards for\nfine-grained evaluation and foster the improvement of VLM image understanding.\nProject page: https://google.github.io/unblocking-detail-caption", "published": "2025-06-09 10:57:26", "link": "http://arxiv.org/abs/2506.07631v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Intent Matters: Enhancing AI Tutoring with Fine-Grained Pedagogical Intent Annotation", "abstract": "Large language models (LLMs) hold great promise for educational applications,\nparticularly in intelligent tutoring systems. However, effective tutoring\nrequires alignment with pedagogical strategies - something current LLMs lack\nwithout task-specific adaptation. In this work, we explore whether fine-grained\nannotation of teacher intents can improve the quality of LLM-generated tutoring\nresponses. We focus on MathDial, a dialog dataset for math instruction, and\napply an automated annotation framework to re-annotate a portion of the dataset\nusing a detailed taxonomy of eleven pedagogical intents. We then fine-tune an\nLLM using these new annotations and compare its performance to models trained\non the original four-category taxonomy. Both automatic and qualitative\nevaluations show that the fine-grained model produces more pedagogically\naligned and effective responses. Our findings highlight the value of intent\nspecificity for controlled text generation in educational settings, and we\nrelease our annotated data and code to facilitate further research.", "published": "2025-06-09 10:45:18", "link": "http://arxiv.org/abs/2506.07626v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LoRMA: Low-Rank Multiplicative Adaptation for LLMs", "abstract": "Large Language Models have shown remarkable capabilities in the NLP domain.\nTheir effectiveness can mainly be attributed to their ability to adapt to an\narray of downstream tasks. However, generally, full fine-tuning is a\ncomputationally expensive job. To mitigate this, many techniques have been\ndeveloped that prime efficiency, a prominent one being Low-Rank Adaptation\n(LoRA). However, LoRA and its variants employ re-parametrized additive updates.\nIn this paper, we propose Low-Rank Multiplicative Adaptation (LoRMA), which\nshifts the paradigm of additive updates to a richer space of matrix\nmultiplicative transformations. We tackle challenges such as computational\ncomplexity and rank bottleneck of matrix multiplication by effectively\nre-ordering operations and introducing rank inflation strategies. We conduct\nextensive experiments to demonstrate the effectiveness of our approach in terms\nof various evaluation metrics.", "published": "2025-06-09 10:36:46", "link": "http://arxiv.org/abs/2506.07621v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Vuyko Mistral: Adapting LLMs for Low-Resource Dialectal Translation", "abstract": "In this paper we introduce the first effort to adapt large language models\n(LLMs) to the Ukrainian dialect (in our case Hutsul), a low-resource and\nmorphologically complex dialect spoken in the Carpathian Highlands. We created\na parallel corpus of 9852 dialect-to-standard Ukrainian sentence pairs and a\ndictionary of 7320 dialectal word mappings. We also addressed data shortage by\nproposing an advanced Retrieval-Augmented Generation (RAG) pipeline to generate\nsynthetic parallel translation pairs, expanding the corpus with 52142 examples.\nWe have fine-tuned multiple open-source LLMs using LoRA and evaluated them on a\nstandard-to-dialect translation task, also comparing with few-shot GPT-4o\ntranslation. In the absence of human annotators, we adopt a multi-metric\nevaluation strategy combining BLEU, chrF++, TER, and LLM-based judgment\n(GPT-4o). The results show that even small(7B) finetuned models outperform\nzero-shot baselines such as GPT-4o across both automatic and LLM-evaluated\nmetrics. All data, models, and code are publicly released at:\nhttps://github.com/woters/vuyko-hutsul", "published": "2025-06-09 10:30:35", "link": "http://arxiv.org/abs/2506.07617v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PolitiSky24: U.S. Political Bluesky Dataset with User Stance Labels", "abstract": "Stance detection identifies the viewpoint expressed in text toward a specific\ntarget, such as a political figure. While previous datasets have focused\nprimarily on tweet-level stances from established platforms, user-level stance\nresources, especially on emerging platforms like Bluesky remain scarce.\nUser-level stance detection provides a more holistic view by considering a\nuser's complete posting history rather than isolated posts. We present the\nfirst stance detection dataset for the 2024 U.S. presidential election,\ncollected from Bluesky and centered on Kamala Harris and Donald Trump. The\ndataset comprises 16,044 user-target stance pairs enriched with engagement\nmetadata, interaction graphs, and user posting histories. PolitiSky24 was\ncreated using a carefully evaluated pipeline combining advanced information\nretrieval and large language models, which generates stance labels with\nsupporting rationales and text spans for transparency. The labeling approach\nachieves 81\\% accuracy with scalable LLMs. This resource addresses gaps in\npolitical stance analysis through its timeliness, open-data nature, and\nuser-level perspective. The dataset is available at\nhttps://doi.org/10.5281/zenodo.15616911", "published": "2025-06-09 10:06:25", "link": "http://arxiv.org/abs/2506.07606v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.SI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Instructing Large Language Models for Low-Resource Languages: A Systematic Study for Basque", "abstract": "Instructing language models with user intent requires large instruction\ndatasets, which are only available for a limited set of languages. In this\npaper, we explore alternatives to conventional instruction adaptation pipelines\nin low-resource scenarios. We assume a realistic scenario for low-resource\nlanguages, where only the following are available: corpora in the target\nlanguage, existing open-weight multilingual base and instructed backbone LLMs,\nand synthetically generated instructions sampled from the instructed backbone.\nWe present a comprehensive set of experiments for Basque that systematically\nstudy different combinations of these components evaluated on benchmarks and\nhuman preferences from 1,680 participants. Our conclusions show that target\nlanguage corpora are essential, with synthetic instructions yielding robust\nmodels, and, most importantly, that using as backbone an instruction-tuned\nmodel outperforms using a base non-instructed model, and improved results when\nscaling up. Using Llama 3.1 instruct 70B as backbone our model comes near\nfrontier models of much larger sizes for Basque, without using any Basque data\napart from the 1.2B word corpora. We release code, models, instruction\ndatasets, and human preferences to support full reproducibility in future\nresearch on low-resource language adaptation.", "published": "2025-06-09 09:54:47", "link": "http://arxiv.org/abs/2506.07597v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond the Sentence: A Survey on Context-Aware Machine Translation with Large Language Models", "abstract": "Despite the popularity of the large language models (LLMs), their application\nto machine translation is relatively underexplored, especially in context-aware\nsettings. This work presents a literature review of context-aware translation\nwith LLMs. The existing works utilise prompting and fine-tuning approaches,\nwith few focusing on automatic post-editing and creating translation agents for\ncontext-aware machine translation. We observed that the commercial LLMs (such\nas ChatGPT and Tower LLM) achieved better results than the open-source LLMs\n(such as Llama and Bloom LLMs), and prompt-based approaches serve as good\nbaselines to assess the quality of translations. Finally, we present some\ninteresting future directions to explore.", "published": "2025-06-09 09:27:00", "link": "http://arxiv.org/abs/2506.07583v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learning Speaker-Invariant Visual Features for Lipreading", "abstract": "Lipreading is a challenging cross-modal task that aims to convert visual lip\nmovements into spoken text. Existing lipreading methods often extract visual\nfeatures that include speaker-specific lip attributes (e.g., shape, color,\ntexture), which introduce spurious correlations between vision and text. These\ncorrelations lead to suboptimal lipreading accuracy and restrict model\ngeneralization. To address this challenge, we introduce SIFLip, a\nspeaker-invariant visual feature learning framework that disentangles\nspeaker-specific attributes using two complementary disentanglement modules\n(Implicit Disentanglement and Explicit Disentanglement) to improve\ngeneralization. Specifically, since different speakers exhibit semantic\nconsistency between lip movements and phonetic text when pronouncing the same\nwords, our implicit disentanglement module leverages stable text embeddings as\nsupervisory signals to learn common visual representations across speakers,\nimplicitly decoupling speaker-specific features. Additionally, we design a\nspeaker recognition sub-task within the main lipreading pipeline to filter\nspeaker-specific features, then further explicitly disentangle these\npersonalized visual features from the backbone network via gradient reversal.\nExperimental results demonstrate that SIFLip significantly enhances\ngeneralization performance across multiple public datasets. Experimental\nresults demonstrate that SIFLip significantly improves generalization\nperformance across multiple public datasets, outperforming state-of-the-art\nmethods.", "published": "2025-06-09 09:16:14", "link": "http://arxiv.org/abs/2506.07572v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "SAFEFLOW: A Principled Protocol for Trustworthy and Transactional Autonomous Agent Systems", "abstract": "Recent advances in large language models (LLMs) and vision-language models\n(VLMs) have enabled powerful autonomous agents capable of complex reasoning and\nmulti-modal tool use. Despite their growing capabilities, today's agent\nframeworks remain fragile, lacking principled mechanisms for secure information\nflow, reliability, and multi-agent coordination. In this work, we introduce\nSAFEFLOW, a new protocol-level framework for building trustworthy LLM/VLM-based\nagents. SAFEFLOW enforces fine-grained information flow control (IFC),\nprecisely tracking provenance, integrity, and confidentiality of all the data\nexchanged between agents, tools, users, and environments. By constraining LLM\nreasoning to respect these security labels, SAFEFLOW prevents untrusted or\nadversarial inputs from contaminating high-integrity decisions. To ensure\nrobustness in concurrent multi-agent settings, SAFEFLOW introduces\ntransactional execution, conflict resolution, and secure scheduling over shared\nstate, preserving global consistency across agents. We further introduce\nmechanisms, including write-ahead logging, rollback, and secure caches, that\nfurther enhance resilience against runtime errors and policy violations. To\nvalidate the performances, we built SAFEFLOWBENCH, a comprehensive benchmark\nsuite designed to evaluate agent reliability under adversarial, noisy, and\nconcurrent operational conditions. Extensive experiments demonstrate that\nagents built with SAFEFLOW maintain impressive task performance and security\nguarantees even in hostile environments, substantially outperforming\nstate-of-the-art. Together, SAFEFLOW and SAFEFLOWBENCH lay the groundwork for\nprincipled, robust, and secure agent ecosystems, advancing the frontier of\nreliable autonomy.", "published": "2025-06-09 09:04:37", "link": "http://arxiv.org/abs/2506.07564v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "SELT: Self-Evaluation Tree Search for LLMs with Task Decomposition", "abstract": "While Large Language Models (LLMs) have achieved remarkable success in a wide\nrange of applications, their performance often degrades in complex reasoning\ntasks. In this work, we introduce SELT (Self-Evaluation LLM Tree Search), a\nnovel framework that leverages a modified Monte Carlo Tree Search (MCTS) to\nenhance LLM reasoning without relying on external reward models. By redefining\nthe Upper Confidence Bound scoring to align with intrinsic self-evaluation\ncapabilities of LLMs and decomposing the inference process into atomic subtasks\naugmented with semantic clustering at each node, SELT effectively balances\nexploration and exploitation, reduces redundant reasoning paths, and mitigates\nhallucination. We validate our approach on challenging benchmarks, including\nthe knowledge-based MMLU and the Tool Learning dataset Seal-Tools, where SELT\nachieves significant improvements in answer accuracy and reasoning robustness\ncompared to baseline methods. Notably, our framework operates without\ntask-specific fine-tuning, demonstrating strong generalizability across diverse\nreasoning tasks. Relevant results and code are available at\nhttps://github.com/fairyshine/SELT .", "published": "2025-06-09 08:52:27", "link": "http://arxiv.org/abs/2506.07557v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ChemAgent: Enhancing LLMs for Chemistry and Materials Science through Tree-Search Based Tool Learning", "abstract": "Large language models (LLMs) have recently demonstrated promising\ncapabilities in chemistry tasks while still facing challenges due to outdated\npretraining knowledge and the difficulty of incorporating specialized chemical\nexpertise. To address these issues, we propose an LLM-based agent that\nsynergistically integrates 137 external chemical tools created ranging from\nbasic information retrieval to complex reaction predictions, and a dataset\ncuration pipeline to generate the dataset ChemToolBench that facilitates both\neffective tool selection and precise parameter filling during fine-tuning and\nevaluation. We introduce a Hierarchical Evolutionary Monte Carlo Tree Search\n(HE-MCTS) framework, enabling independent optimization of tool planning and\nexecution. By leveraging self-generated data, our approach supports step-level\nfine-tuning (FT) of the policy model and training task-adaptive PRM and ORM\nthat surpass GPT-4o. Experimental evaluations demonstrate that our approach\nsignificantly improves performance in Chemistry QA and discovery tasks,\noffering a robust solution to integrate specialized tools with LLMs for\nadvanced chemical applications. All datasets and code are available at\nhttps://github.com/AI4Chem/ChemistryAgent .", "published": "2025-06-09 08:41:39", "link": "http://arxiv.org/abs/2506.07551v1", "categories": ["cs.LG", "cs.AI", "cs.CE", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Bit-level BPE: Below the byte boundary", "abstract": "Byte-level fallbacks for subword tokenization have become a common practice\nin large language models. In particular, it has been demonstrated to be\nincredibly effective as a pragmatic solution for preventing OOV, especially in\nthe context of larger models. However, breaking a character down to individual\nbytes significantly increases the sequence length for long-tail tokens in\nlanguages such as Chinese, Japanese, and Korean (CJK) and other\ncharacter-diverse contexts such as emoji. The increased sequence length results\nin longer computation during both training and inference. In this work, we\npropose a simple compression technique that reduces the sequence length\nlosslessly.", "published": "2025-06-09 08:28:16", "link": "http://arxiv.org/abs/2506.07541v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Large Language Models with Self-Consistent Natural Language Explanations", "abstract": "Large language models (LLMs) seem to offer an easy path to interpretability:\njust ask them to explain their decisions. Yet, studies show that these post-hoc\nexplanations often misrepresent the true decision process, as revealed by\nmismatches in feature importance. Despite growing evidence of this\ninconsistency, no systematic solutions have emerged, partly due to the high\ncost of estimating feature importance, which limits evaluations to small\ndatasets. To address this, we introduce the Post-hoc Self-Consistency Bank\n(PSCB) - a large-scale benchmark of decisions spanning diverse tasks and\nmodels, each paired with LLM-generated explanations and corresponding feature\nimportance scores. Analysis of PSCB reveals that self-consistency scores barely\ndiffer between correct and incorrect predictions. We also show that the\nstandard metric fails to meaningfully distinguish between explanations. To\novercome this limitation, we propose an alternative metric that more\neffectively captures variation in explanation quality. We use it to fine-tune\nLLMs via Direct Preference Optimization (DPO), leading to significantly better\nalignment between explanations and decision-relevant features, even under\ndomain shift. Our findings point to a scalable path toward more trustworthy,\nself-consistent LLMs.", "published": "2025-06-09 08:06:33", "link": "http://arxiv.org/abs/2506.07523v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Speaker-Distinguishable CTC: Learning Speaker Distinction Using CTC for Multi-Talker Speech Recognition", "abstract": "This paper presents a novel framework for multi-talker automatic speech\nrecognition without the need for auxiliary information. Serialized Output\nTraining (SOT), a widely used approach, suffers from recognition errors due to\nspeaker assignment failures. Although incorporating auxiliary information, such\nas token-level timestamps, can improve recognition accuracy, extracting such\ninformation from natural conversational speech remains challenging. To address\nthis limitation, we propose Speaker-Distinguishable CTC (SD-CTC), an extension\nof CTC that jointly assigns a token and its corresponding speaker label to each\nframe. We further integrate SD-CTC into the SOT framework, enabling the SOT\nmodel to learn speaker distinction using only overlapping speech and\ntranscriptions. Experimental comparisons show that multi-task learning with\nSD-CTC and SOT reduces the error rate of the SOT model by 26% and achieves\nperformance comparable to state-of-the-art methods relying on auxiliary\ninformation.", "published": "2025-06-09 07:43:43", "link": "http://arxiv.org/abs/2506.07515v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "DeRAGEC: Denoising Named Entity Candidates with Synthetic Rationale for ASR Error Correction", "abstract": "We present DeRAGEC, a method for improving Named Entity (NE) correction in\nAutomatic Speech Recognition (ASR) systems. By extending the\nRetrieval-Augmented Generative Error Correction (RAGEC) framework, DeRAGEC\nemploys synthetic denoising rationales to filter out noisy NE candidates before\ncorrection. By leveraging phonetic similarity and augmented definitions, it\nrefines noisy retrieved NEs using in-context learning, requiring no additional\ntraining. Experimental results on CommonVoice and STOP datasets show\nsignificant improvements in Word Error Rate (WER) and NE hit ratio,\noutperforming baseline ASR and RAGEC methods. Specifically, we achieved a 28%\nrelative reduction in WER compared to ASR without postprocessing. Our source\ncode is publicly available at: https://github.com/solee0022/deragec", "published": "2025-06-09 07:37:50", "link": "http://arxiv.org/abs/2506.07510v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What Do Indonesians Really Need from Language Technology? A Nationwide Survey", "abstract": "There is an emerging effort to develop NLP for Indonesias 700+ local\nlanguages, but progress remains costly due to the need for direct engagement\nwith native speakers. However, it is unclear what these language communities\ntruly need from language technology. To address this, we conduct a nationwide\nsurvey to assess the actual needs of native speakers in Indonesia. Our findings\nindicate that addressing language barriers, particularly through machine\ntranslation and information retrieval, is the most critical priority. Although\nthere is strong enthusiasm for advancements in language technology, concerns\naround privacy, bias, and the use of public data for AI training highlight the\nneed for greater transparency and clear communication to support broader AI\nadoption.", "published": "2025-06-09 07:36:15", "link": "http://arxiv.org/abs/2506.07506v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DEBATE: A Dataset for Disentangling Textual Ambiguity in Mandarin Through Speech", "abstract": "Despite extensive research on textual and visual disambiguation,\ndisambiguation through speech (DTS) remains underexplored. This is largely due\nto the lack of high-quality datasets that pair spoken sentences with richly\nambiguous text. To address this gap, we present DEBATE, a unique public Chinese\nspeech-text dataset designed to study how speech cues and\npatterns-pronunciation, pause, stress and intonation-can help resolve textual\nambiguity and reveal a speaker's true intent. DEBATE contains 1,001 carefully\nselected ambiguous utterances, each recorded by 10 native speakers, capturing\ndiverse linguistic ambiguities and their disambiguation through speech. We\ndetail the data collection pipeline and provide rigorous quality analysis.\nAdditionally, we benchmark three state-of-the-art large speech and\naudio-language models, illustrating clear and huge performance gaps between\nmachine and human understanding of spoken intent. DEBATE represents the first\neffort of its kind and offers a foundation for building similar DTS datasets\nacross languages and cultures. The dataset and associated code are available\nat: https://github.com/SmileHnu/DEBATE.", "published": "2025-06-09 07:27:22", "link": "http://arxiv.org/abs/2506.07502v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Graph-of-Causal Evolution: Challenging Chain-of-Model for Reasoning", "abstract": "In view of the problem that each subchain in the chain-of-model (CoM) relies\nonly on the information of the previous subchain and may lose long-range\ndependencies due to the causal mask blocking the global context flow between\nmulti-level subchains, this work proposes a graph of causal evolution (GoCE).\nIts core principle is to map the implicit token representation into a\ndifferentiable and sparse causal adjacency matrix, then permeate causal\nconstraints through each layer of calculation using causal-masked attention and\ncausal-MoE. By combining intervention consistency loss test and self-evolution\ngate, the dynamic balance between causal structure learning and adaptive\nupdating of transformer architecture is realized. The researcher built\nexperimental environments in sandboxes built with Claude Sonnet 4,\no4-mini-high, and DeepSeek R1 respectively with the transformer variant\narchitecture introduced in GoCE. It is evaluated on publicly available datasets\nincluding CLUTRR, CLADDER, EX-FEVER, and CausalQA and compared with the\nbaseline LLMs. The finding proves that GoCE strengthens the transformer's\nability to capture long-range causal dependencies, while the ability to\nself-evolve is improved. It not only surpasses the design of CoM in terms of\ndesign principles, but also provides experience for future research on causal\nlearning and continuous adaptive improvement.", "published": "2025-06-09 07:26:47", "link": "http://arxiv.org/abs/2506.07501v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "A Hybrid GA LLM Framework for Structured Task Optimization", "abstract": "GA LLM is a hybrid framework that combines Genetic Algorithms with Large\nLanguage Models to handle structured generation tasks under strict constraints.\nEach output, such as a plan or report, is treated as a gene, and evolutionary\noperations like selection, crossover, and mutation are guided by the language\nmodel to iteratively improve solutions. The language model provides domain\nknowledge and creative variation, while the genetic algorithm ensures\nstructural integrity and global optimization. GA LLM has proven effective in\ntasks such as itinerary planning, academic outlining, and business reporting,\nconsistently producing well structured and requirement satisfying results. Its\nmodular design also makes it easy to adapt to new tasks. Compared to using a\nlanguage model alone, GA LLM achieves better constraint satisfaction and higher\nquality solutions by combining the strengths of both components.", "published": "2025-06-09 07:00:04", "link": "http://arxiv.org/abs/2506.07483v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Fairness of Large Language Models in Multi-document Summarization", "abstract": "Fairness in multi-document summarization (MDS) is crucial for providing\ncomprehensive views across documents with diverse social attribute values,\nwhich can significantly impact decision-making. For example, a summarization\nsystem that tends to overrepresent negative reviews of products can mislead\ncustomers into disregarding good products. Previous works measure fairness in\nMDS at two levels: summary-level and corpus-level. While summary-level fairness\nfocuses on individual summaries, corpus-level fairness focuses on a corpus of\nsummaries. Recent methods primarily focus on summary-level fairness. We propose\nFairPO, a preference tuning method that focuses on both summary-level and\ncorpus-level fairness in MDS. To improve summary-level fairness, we propose to\ngenerate preference pairs by perturbing document sets. To improve corpus-level\nfairness, we propose fairness-aware preference tuning by dynamically adjusting\nthe weights of preference pairs. Our experiments show that FairPO outperforms\nstrong baselines while maintaining the critical qualities of summaries. The\ncode is available at https://github.com/leehaoyuan/coverage_fairnes.", "published": "2025-06-09 06:52:59", "link": "http://arxiv.org/abs/2506.07479v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chasing Moving Targets with Online Self-Play Reinforcement Learning for Safer Language Models", "abstract": "Conventional language model (LM) safety alignment relies on a reactive,\ndisjoint procedure: attackers exploit a static model, followed by defensive\nfine-tuning to patch exposed vulnerabilities. This sequential approach creates\na mismatch -- attackers overfit to obsolete defenses, while defenders\nperpetually lag behind emerging threats. To address this, we propose\nSelf-RedTeam, an online self-play reinforcement learning algorithm where an\nattacker and defender agent co-evolve through continuous interaction. We cast\nsafety alignment as a two-player zero-sum game, where a single model alternates\nbetween attacker and defender roles -- generating adversarial prompts and\nsafeguarding against them -- while a reward LM adjudicates outcomes. This\nenables dynamic co-adaptation. Grounded in the game-theoretic framework of\nzero-sum games, we establish a theoretical safety guarantee which motivates the\ndesign of our method: if self-play converges to a Nash Equilibrium, the\ndefender will reliably produce safe responses to any adversarial input.\nEmpirically, Self-RedTeam uncovers more diverse attacks (+21.8% SBERT) compared\nto attackers trained against static defenders and achieves higher robustness on\nsafety benchmarks (e.g., +65.5% on WildJailBreak) than defenders trained\nagainst static attackers. We further propose hidden Chain-of-Thought, allowing\nagents to plan privately, which boosts adversarial diversity and reduces\nover-refusals. Our results motivate a shift from reactive patching to proactive\nco-evolution in LM safety training, enabling scalable, autonomous, and robust\nself-improvement of LMs via multi-agent reinforcement learning (MARL).", "published": "2025-06-09 06:35:12", "link": "http://arxiv.org/abs/2506.07468v1", "categories": ["cs.LG", "cs.CL", "cs.MA"], "primary_category": "cs.LG"}
{"title": "CCI4.0: A Bilingual Pretraining Dataset for Enhancing Reasoning in Large Language Models", "abstract": "We introduce CCI4.0, a large-scale bilingual pre-training dataset engineered\nfor superior data quality and diverse human-like reasoning trajectory. CCI4.0\noccupies roughly $35$ TB of disk space and comprises two sub-datasets:\nCCI4.0-M2-Base and CCI4.0-M2-CoT. CCI4.0-M2-Base combines a $5.2$ TB carefully\ncurated Chinese web corpus, a $22.5$ TB English subset from Nemotron-CC, and\ndiverse sources from math, wiki, arxiv, and code. Although these data are\nmostly sourced from well-processed datasets, the quality standards of various\ndomains are dynamic and require extensive expert experience and labor to\nprocess. So, we propose a novel pipeline justifying data quality mainly based\non models through two-stage deduplication, multiclassifier quality scoring, and\ndomain-aware fluency filtering. We extract $4.5$ billion pieces of\nCoT(Chain-of-Thought) templates, named CCI4.0-M2-CoT. Differing from the\ndistillation of CoT from larger models, our proposed staged CoT extraction\nexemplifies diverse reasoning patterns and significantly decreases the\npossibility of hallucination. Empirical evaluations demonstrate that LLMs\npre-trained in CCI4.0 benefit from cleaner, more reliable training signals,\nyielding consistent improvements in downstream tasks, especially in math and\ncode reflection tasks. Our results underscore the critical role of rigorous\ndata curation and human thinking templates in advancing LLM performance,\nshedding some light on automatically processing pretraining corpora.", "published": "2025-06-09 06:14:19", "link": "http://arxiv.org/abs/2506.07463v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "From Calibration to Collaboration: LLM Uncertainty Quantification Should Be More Human-Centered", "abstract": "Large Language Models (LLMs) are increasingly assisting users in the real\nworld, yet their reliability remains a concern. Uncertainty quantification (UQ)\nhas been heralded as a tool to enhance human-LLM collaboration by enabling\nusers to know when to trust LLM predictions. We argue that current practices\nfor uncertainty quantification in LLMs are not optimal for developing useful UQ\nfor human users making decisions in real-world tasks. Through an analysis of 40\nLLM UQ methods, we identify three prevalent practices hindering the community's\nprogress toward its goal of benefiting downstream users: 1) evaluating on\nbenchmarks with low ecological validity; 2) considering only epistemic\nuncertainty; and 3) optimizing metrics that are not necessarily indicative of\ndownstream utility. For each issue, we propose concrete user-centric practices\nand research directions that LLM UQ researchers should consider. Instead of\nhill-climbing on unrepresentative tasks using imperfect metrics, we argue that\nthe community should adopt a more human-centered approach to LLM uncertainty\nquantification.", "published": "2025-06-09 06:10:04", "link": "http://arxiv.org/abs/2506.07461v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GLOS: Sign Language Generation with Temporally Aligned Gloss-Level Conditioning", "abstract": "Sign language generation (SLG), or text-to-sign generation, bridges the gap\nbetween signers and non-signers. Despite recent progress in SLG, existing\nmethods still often suffer from incorrect lexical ordering and low semantic\naccuracy. This is primarily due to sentence-level condition, which encodes the\nentire sentence of the input text into a single feature vector as a condition\nfor SLG. This approach fails to capture the temporal structure of sign language\nand lacks the granularity of word-level semantics, often leading to disordered\nsign sequences and ambiguous motions. To overcome these limitations, we propose\nGLOS, a sign language generation framework with temporally aligned gloss-level\nconditioning. First, we employ gloss-level conditions, which we define as\nsequences of gloss embeddings temporally aligned with the motion sequence. This\nenables the model to access both the temporal structure of sign language and\nword-level semantics at each timestep. As a result, this allows for\nfine-grained control of signs and better preservation of lexical order. Second,\nwe introduce a condition fusion module, temporal alignment conditioning (TAC),\nto efficiently deliver the word-level semantic and temporal structure provided\nby the gloss-level condition to the corresponding motion timesteps. Our method,\nwhich is composed of gloss-level conditions and TAC, generates signs with\ncorrect lexical order and high semantic accuracy, outperforming prior methods\non CSL-Daily and Phoenix-2014T.", "published": "2025-06-09 06:09:03", "link": "http://arxiv.org/abs/2506.07460v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "KScope: A Framework for Characterizing the Knowledge Status of Language Models", "abstract": "Characterizing a large language model's (LLM's) knowledge of a given question\nis challenging. As a result, prior work has primarily examined LLM behavior\nunder knowledge conflicts, where the model's internal parametric memory\ncontradicts information in the external context. However, this does not fully\nreflect how well the model knows the answer to the question. In this paper, we\nfirst introduce a taxonomy of five knowledge statuses based on the consistency\nand correctness of LLM knowledge modes. We then propose KScope, a hierarchical\nframework of statistical tests that progressively refines hypotheses about\nknowledge modes and characterizes LLM knowledge into one of these five\nstatuses. We apply KScope to nine LLMs across four datasets and systematically\nestablish: (1) Supporting context narrows knowledge gaps across models. (2)\nContext features related to difficulty, relevance, and familiarity drive\nsuccessful knowledge updates. (3) LLMs exhibit similar feature preferences when\npartially correct or conflicted, but diverge sharply when consistently wrong.\n(4) Context summarization constrained by our feature analysis, together with\nenhanced credibility, further improves update effectiveness and generalizes\nacross LLMs.", "published": "2025-06-09 06:06:05", "link": "http://arxiv.org/abs/2506.07458v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Understanding Cross-Domain Adaptation in Low-Resource Topic Modeling", "abstract": "Topic modeling plays a vital role in uncovering hidden semantic structures\nwithin text corpora, but existing models struggle in low-resource settings\nwhere limited target-domain data leads to unstable and incoherent topic\ninference. We address this challenge by formally introducing domain adaptation\nfor low-resource topic modeling, where a high-resource source domain informs a\nlow-resource target domain without overwhelming it with irrelevant content. We\nestablish a finite-sample generalization bound showing that effective knowledge\ntransfer depends on robust performance in both domains, minimizing latent-space\ndiscrepancy, and preventing overfitting to the data. Guided by these insights,\nwe propose DALTA (Domain-Aligned Latent Topic Adaptation), a new framework that\nemploys a shared encoder for domain-invariant features, specialized decoders\nfor domain-specific nuances, and adversarial alignment to selectively transfer\nrelevant information. Experiments on diverse low-resource datasets demonstrate\nthat DALTA consistently outperforms state-of-the-art methods in terms of topic\ncoherence, stability, and transferability.", "published": "2025-06-09 05:59:18", "link": "http://arxiv.org/abs/2506.07453v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When Style Breaks Safety: Defending Language Models Against Superficial Style Alignment", "abstract": "Large language models (LLMs) can be prompted with specific styles (e.g.,\nformatting responses as lists), including in jailbreak queries. Although these\nstyle patterns are semantically unrelated to the malicious intents behind\njailbreak queries, their safety impact remains unclear. In this work, we seek\nto understand whether style patterns compromise LLM safety, how superficial\nstyle alignment increases model vulnerability, and how best to mitigate these\nrisks during alignment. We evaluate 32 LLMs across seven jailbreak benchmarks,\nand find that malicious queries with style patterns inflate the attack success\nrate (ASR) for nearly all models. Notably, ASR inflation correlates with both\nthe length of style patterns and the relative attention an LLM exhibits on\nthem. We then investigate superficial style alignment, and find that\nfine-tuning with specific styles makes LLMs more vulnerable to jailbreaks of\nthose same styles. Finally, we propose SafeStyle, a defense strategy that\nincorporates a small amount of safety training data augmented to match the\ndistribution of style patterns in the fine-tuning data. Across three LLMs and\nfive fine-tuning style settings, SafeStyle consistently outperforms baselines\nin maintaining LLM safety.", "published": "2025-06-09 05:57:39", "link": "http://arxiv.org/abs/2506.07452v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.LG"}
{"title": "LlamaRec-LKG-RAG: A Single-Pass, Learnable Knowledge Graph-RAG Framework for LLM-Based Ranking", "abstract": "Recent advances in Large Language Models (LLMs) have driven their adoption in\nrecommender systems through Retrieval-Augmented Generation (RAG) frameworks.\nHowever, existing RAG approaches predominantly rely on flat, similarity-based\nretrieval that fails to leverage the rich relational structure inherent in\nuser-item interactions. We introduce LlamaRec-LKG-RAG, a novel single-pass,\nend-to-end trainable framework that integrates personalized knowledge graph\ncontext into LLM-based recommendation ranking. Our approach extends the\nLlamaRec architecture by incorporating a lightweight user preference module\nthat dynamically identifies salient relation paths within a heterogeneous\nknowledge graph constructed from user behavior and item metadata. These\npersonalized subgraphs are seamlessly integrated into prompts for a fine-tuned\nLlama-2 model, enabling efficient and interpretable recommendations through a\nunified inference step. Comprehensive experiments on ML-100K and Amazon Beauty\ndatasets demonstrate consistent and significant improvements over LlamaRec\nacross key ranking metrics (MRR, NDCG, Recall). LlamaRec-LKG-RAG demonstrates\nthe critical value of structured reasoning in LLM-based recommendations and\nestablishes a foundation for scalable, knowledge-aware personalization in\nnext-generation recommender systems. Code is available\nat~\\href{https://github.com/VahidAz/LlamaRec-LKG-RAG}{repository}.", "published": "2025-06-09 05:52:03", "link": "http://arxiv.org/abs/2506.07449v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "LG-ANNA-Embedding technical report", "abstract": "This report presents a unified instruction-based framework for learning\ngeneralized text embeddings optimized for both information retrieval (IR) and\nnon-IR tasks. Built upon a decoder-only large language model (Mistral-7B), our\napproach combines in-context learning, soft supervision, and adaptive\nhard-negative mining to generate context-aware embeddings without task-specific\nfine-tuning. Structured instructions and few-shot examples are used to guide\nthe model across diverse tasks, enabling strong performance on classification,\nsemantic similarity, clustering, and reranking benchmarks. To improve semantic\ndiscrimination, we employ a soft labeling framework where continuous relevance\nscores, distilled from a high-performance dense retriever and reranker, serve\nas fine-grained supervision signals. In addition, we introduce adaptive\nmargin-based hard-negative mining, which filters out semantically ambiguous\nnegatives based on their similarity to positive examples, thereby enhancing\ntraining stability and retrieval robustness. Our model is evaluated on the\nnewly introduced MTEB (English, v2) benchmark, covering 41 tasks across seven\ncategories. Results show that our method achieves strong generalization and\nranks among the top-performing models by Borda score, outperforming several\nlarger or fully fine-tuned baselines. These findings highlight the\neffectiveness of combining in-context prompting, soft supervision, and adaptive\nsampling for scalable, high-quality embedding generation.", "published": "2025-06-09 05:30:35", "link": "http://arxiv.org/abs/2506.07438v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Well Begun is Half Done: Low-resource Preference Alignment by Weak-to-Strong Decoding", "abstract": "Large Language Models (LLMs) require alignment with human preferences to\navoid generating offensive, false, or meaningless content. Recently,\nlow-resource methods for LLM alignment have been popular, while still facing\nchallenges in obtaining both high-quality and aligned content. Motivated by the\nobservation that the difficulty of generating aligned responses is concentrated\nat the beginning of decoding, we propose a novel framework, Weak-to-Strong\nDecoding (WSD), to enhance the alignment ability of base models by the guidance\nof a small aligned model. The small model first drafts well-aligned beginnings,\nfollowed by the large base model to continue the rest, controlled by a\nwell-designed auto-switch mechanism. We also collect a new dataset, GenerAlign,\nto fine-tune a small-sized Pilot-3B as the draft model, which effectively\nenhances different base models under the WSD framework to outperform all\nbaseline methods, while avoiding degradation on downstream tasks, termed as the\nalignment tax. Extensive experiments are further conducted to examine the\nimpact of different settings and time efficiency, as well as analyses on the\nintrinsic mechanisms of WSD in depth.", "published": "2025-06-09 05:21:22", "link": "http://arxiv.org/abs/2506.07434v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Conjoined Predication and Scalar Implicature", "abstract": "Magri (2016) investigates two puzzles arising from conjunction. Although\nMagri has proposed a solution to the second puzzle, the first remains\nunresolved. This first puzzle reveals a hidden interaction among\nquantification, collective/concurrent interpretation, and contextual updating\ndimensions that have yet to be explored. In essence, the problem is that\ncertain forms of sentences like \"Some Italians come from a warm country,\" when\nconjoined as in \"(Only) Some Italians come from a warm country and are blond,\"\nsound infelicitous, even though no obvious alternative triggers a conflicting\nscalar implicature. In this paper, we offer a conceptual analysis of Magri's\nfirst puzzle by situating it within its original theoretical framework. We\nargue that the oddness arises from the collective or concurrent reading of the\nconjunctive predicate: in examples such as \"(Only) Some Italians come from a\nwarm country and are blond,\" this interpretation generates an indirect\ncontextual contradiction. Moreover, we suggest that the pragmatic mechanisms\ngoverning scalar implicature generation extend beyond what is captured by\nexhaustification-based grammatical licensing accounts.", "published": "2025-06-09 04:59:46", "link": "http://arxiv.org/abs/2506.07429v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Plug-in and Fine-tuning: Bridging the Gap between Small Language Models and Large Language Models", "abstract": "Large language models (LLMs) are renowned for their extensive linguistic\nknowledge and strong generalization capabilities, but their high computational\ndemands make them unsuitable for resource-constrained environments. In\ncontrast, small language models (SLMs) are computationally efficient but often\nlack the broad generalization capacity of LLMs. To bridge this gap, we propose\nPiFi, a novel framework that combines the strengths of both LLMs and SLMs to\nachieve high performance while maintaining efficiency. PiFi integrates a single\nfrozen layer from an LLM into a SLM and fine-tunes the combined model for\nspecific tasks, boosting performance without a significant increase in\ncomputational cost. We show that PiFi delivers consistent performance\nimprovements across a range of natural language processing tasks, including\nboth natural language understanding and generation. Moreover, our findings\ndemonstrate PiFi's ability to effectively leverage LLM knowledge, enhancing\ngeneralization to unseen domains and facilitating the transfer of linguistic\nabilities.", "published": "2025-06-09 04:45:13", "link": "http://arxiv.org/abs/2506.07424v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SEED: Enhancing Text-to-SQL Performance and Practical Usability Through Automatic Evidence Generation", "abstract": "Text-to-SQL enables non-experts to retrieve data from databases by converting\nnatural language queries into SQL. However, state-of-the-art text-to-SQL\nstudies rely on the BIRD dataset, which assumes that evidence is provided along\nwith questions. Although BIRD facilitates research advancements, it assumes\nthat users have expertise and domain knowledge, contradicting the fundamental\ngoal of text-to-SQL. In addition, human-generated evidence in BIRD contains\ndefects, including missing or erroneous evidence, which affects model\nperformance. To address this issue, we propose SEED (System for Evidence\nExtraction and Domain knowledge generation), an approach that automatically\ngenerates evidence to improve performance and practical usability in real-world\nscenarios. SEED systematically analyzes database schema, description files, and\nvalues to extract relevant information. We evaluated SEED on BIRD and Spider,\ndemonstrating that it significantly improves SQL generation accuracy in the\nno-evidence scenario, and in some cases, even outperforms the setting where\nBIRD evidence is provided. Our results highlight that SEED-generated evidence\nnot only bridges the gap between research and real-world deployment but also\nimproves the adaptability and robustness of text-to-SQL models. Our code is\navailable at https://github.com/felix01189/SEED", "published": "2025-06-09 04:44:31", "link": "http://arxiv.org/abs/2506.07423v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Beyond Jailbreaks: Revealing Stealthier and Broader LLM Security Risks Stemming from Alignment Failures", "abstract": "Large language models (LLMs) are increasingly deployed in real-world\napplications, raising concerns about their security. While jailbreak attacks\nhighlight failures under overtly harmful queries, they overlook a critical\nrisk: incorrectly answering harmless-looking inputs can be dangerous and cause\nreal-world harm (Implicit Harm). We systematically reformulate the LLM risk\nlandscape through a structured quadrant perspective based on output factuality\nand input harmlessness, uncovering an overlooked high-risk region. To\ninvestigate this gap, we propose JailFlipBench, a benchmark aims to capture\nimplicit harm, spanning single-modal, multimodal, and factual extension\nscenarios with diverse evaluation metrics. We further develop initial JailFlip\nattack methodologies and conduct comprehensive evaluations across multiple\nopen-source and black-box LLMs, show that implicit harm present immediate and\nurgent real-world risks, calling for broader LLM safety assessments and\nalignment beyond conventional jailbreak paradigms.", "published": "2025-06-09 03:52:43", "link": "http://arxiv.org/abs/2506.07402v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "G-Memory: Tracing Hierarchical Memory for Multi-Agent Systems", "abstract": "Large language model (LLM)-powered multi-agent systems (MAS) have\ndemonstrated cognitive and execution capabilities that far exceed those of\nsingle LLM agents, yet their capacity for self-evolution remains hampered by\nunderdeveloped memory architectures. Upon close inspection, we are alarmed to\ndiscover that prevailing MAS memory mechanisms (1) are overly simplistic,\ncompletely disregarding the nuanced inter-agent collaboration trajectories, and\n(2) lack cross-trial and agent-specific customization, in stark contrast to the\nexpressive memory developed for single agents. To bridge this gap, we introduce\nG-Memory, a hierarchical, agentic memory system for MAS inspired by\norganizational memory theory, which manages the lengthy MAS interaction via a\nthree-tier graph hierarchy: insight, query, and interaction graphs. Upon\nreceiving a new user query, G-Memory performs bi-directional memory traversal\nto retrieve both $\\textit{high-level, generalizable insights}$ that enable the\nsystem to leverage cross-trial knowledge, and $\\textit{fine-grained, condensed\ninteraction trajectories}$ that compactly encode prior collaboration\nexperiences. Upon task execution, the entire hierarchy evolves by assimilating\nnew collaborative trajectories, nurturing the progressive evolution of agent\nteams. Extensive experiments across five benchmarks, three LLM backbones, and\nthree popular MAS frameworks demonstrate that G-Memory improves success rates\nin embodied action and accuracy in knowledge QA by up to $20.89\\%$ and\n$10.12\\%$, respectively, without any modifications to the original frameworks.\nOur codes are available at https://github.com/bingreeky/GMemory.", "published": "2025-06-09 03:43:46", "link": "http://arxiv.org/abs/2506.07398v1", "categories": ["cs.MA", "cs.CL", "cs.LG"], "primary_category": "cs.MA"}
{"title": "Refusal-Feature-guided Teacher for Safe Finetuning via Data Filtering and Alignment Distillation", "abstract": "Recently, major AI service providers such as Google and OpenAI have\nintroduced Finetuning-as-a-Service, which enables users to customize Large\nLanguage Models (LLMs) for specific downstream tasks using their own data.\nHowever, this service is vulnerable to degradation of LLM safety-alignment when\nuser data contains harmful prompts. While some prior works address this issue,\nfundamentally filtering harmful data from user data remains unexplored.\nMotivated by our observation that a directional representation reflecting\nrefusal behavior (called the refusal feature) obtained from safety-aligned LLMs\ncan inherently distinguish between harmful and harmless prompts, we propose the\nRefusal-Feature-guided Teacher (ReFT). Our ReFT model is trained to identify\nharmful prompts based on the similarity between input prompt features and its\nrefusal feature. During finetuning, the ReFT model serves as a teacher that\nfilters harmful prompts from user data and distills alignment knowledge into\nthe base model. Extensive experiments demonstrate that our ReFT-based\nfinetuning strategy effectively minimizes harmful outputs and enhances\nfinetuning accuracy for user-specific tasks, offering a practical solution for\nsecure and reliable deployment of LLMs in Finetuning-as-a-Service.", "published": "2025-06-09 02:10:51", "link": "http://arxiv.org/abs/2506.07356v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving LLM Reasoning through Interpretable Role-Playing Steering", "abstract": "Role-playing has emerged as an effective technique for enhancing the\nreasoning capabilities of large language models (LLMs). However, existing\nmethods primarily rely on prompt engineering, which often lacks stability and\ninterpretability. In this paper, we introduce Sparse Autoencoder Role-Playing\nSteering (SRPS), a novel framework that identifies and manipulates internal\nmodel features associated with role-playing behavior. Our approach extracts\nlatent representations from role-play prompts, selects the most relevant\nfeatures based on activation patterns, and constructs a steering vector that\ncan be injected into the model's residual stream with controllable intensity.\nOur method enables fine-grained control over role-specific behavior and offers\ninsights into how role information influences internal model activations.\nExtensive experiments across various reasoning benchmarks and model sizes\ndemonstrate consistent performance gains. Notably, in the zero-shot\nchain-of-thought (CoT) setting, the accuracy of Llama3.1-8B on CSQA improves\nfrom 31.86% to 39.80%, while Gemma2-9B on SVAMP increases from 37.50% to\n45.10%. These results highlight the potential of SRPS to enhance reasoning\nability in LLMs, providing better interpretability and stability compared to\ntraditional prompt-based role-playing.", "published": "2025-06-09 00:31:17", "link": "http://arxiv.org/abs/2506.07335v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "StableMTL: Repurposing Latent Diffusion Models for Multi-Task Learning from Partially Annotated Synthetic Datasets", "abstract": "Multi-task learning for dense prediction is limited by the need for extensive\nannotation for every task, though recent works have explored training with\npartial task labels. Leveraging the generalization power of diffusion models,\nwe extend the partial learning setup to a zero-shot setting, training a\nmulti-task model on multiple synthetic datasets, each labeled for only a subset\nof tasks. Our method, StableMTL, repurposes image generators for latent\nregression. Adapting a denoising framework with task encoding, per-task\nconditioning and a tailored training scheme. Instead of per-task losses\nrequiring careful balancing, a unified latent loss is adopted, enabling\nseamless scaling to more tasks. To encourage inter-task synergy, we introduce a\nmulti-stream model with a task-attention mechanism that converts N-to-N task\ninteractions into efficient 1-to-N attention, promoting effective cross-task\nsharing. StableMTL outperforms baselines on 7 tasks across 8 benchmarks.", "published": "2025-06-09 17:59:59", "link": "http://arxiv.org/abs/2506.08013v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Vision Transformers Don't Need Trained Registers", "abstract": "We investigate the mechanism underlying a previously identified phenomenon in\nVision Transformers -- the emergence of high-norm tokens that lead to noisy\nattention maps. We observe that in multiple models (e.g., CLIP, DINOv2), a\nsparse set of neurons is responsible for concentrating high-norm activations on\noutlier tokens, leading to irregular attention patterns and degrading\ndownstream visual processing. While the existing solution for removing these\noutliers involves retraining models from scratch with additional learned\nregister tokens, we use our findings to create a training-free approach to\nmitigate these artifacts. By shifting the high-norm activations from our\ndiscovered register neurons into an additional untrained token, we can mimic\nthe effect of register tokens on a model already trained without registers. We\ndemonstrate that our method produces cleaner attention and feature maps,\nenhances performance over base models across multiple downstream visual tasks,\nand achieves results comparable to models explicitly trained with register\ntokens. We then extend test-time registers to off-the-shelf vision-language\nmodels to improve their interpretability. Our results suggest that test-time\nregisters effectively take on the role of register tokens at test-time,\noffering a training-free solution for any pre-trained model released without\nthem.", "published": "2025-06-09 17:59:57", "link": "http://arxiv.org/abs/2506.08010v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "GUI-Reflection: Empowering Multimodal GUI Models with Self-Reflection Behavior", "abstract": "Multimodal Large Language Models (MLLMs) have shown great potential in\nrevolutionizing Graphical User Interface (GUI) automation. However, existing\nGUI models mostly rely on learning from nearly error-free offline trajectories,\nthus lacking reflection and error recovery capabilities. To bridge this gap, we\npropose GUI-Reflection, a novel framework that explicitly integrates\nself-reflection and error correction capabilities into end-to-end multimodal\nGUI models throughout dedicated training stages: GUI-specific pre-training,\noffline supervised fine-tuning (SFT), and online reflection tuning.\nGUI-reflection enables self-reflection behavior emergence with fully automated\ndata generation and learning processes without requiring any human annotation.\nSpecifically, 1) we first propose scalable data pipelines to automatically\nconstruct reflection and error correction data from existing successful\ntrajectories. While existing GUI models mainly focus on grounding and UI\nunderstanding ability, we propose the GUI-Reflection Task Suite to learn and\nevaluate reflection-oriented abilities explicitly. 2) Furthermore, we built a\ndiverse and efficient environment for online training and data collection of\nGUI models on mobile devices. 3) We also present an iterative online reflection\ntuning algorithm leveraging the proposed environment, enabling the model to\ncontinuously enhance its reflection and error correction abilities. Our\nframework equips GUI agents with self-reflection and correction capabilities,\npaving the way for more robust, adaptable, and intelligent GUI automation, with\nall data, models, environments, and tools to be released publicly.", "published": "2025-06-09 17:59:57", "link": "http://arxiv.org/abs/2506.08012v1", "categories": ["cs.AI", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Self Forcing: Bridging the Train-Test Gap in Autoregressive Video Diffusion", "abstract": "We introduce Self Forcing, a novel training paradigm for autoregressive video\ndiffusion models. It addresses the longstanding issue of exposure bias, where\nmodels trained on ground-truth context must generate sequences conditioned on\ntheir own imperfect outputs during inference. Unlike prior methods that denoise\nfuture frames based on ground-truth context frames, Self Forcing conditions\neach frame's generation on previously self-generated outputs by performing\nautoregressive rollout with key-value (KV) caching during training. This\nstrategy enables supervision through a holistic loss at the video level that\ndirectly evaluates the quality of the entire generated sequence, rather than\nrelying solely on traditional frame-wise objectives. To ensure training\nefficiency, we employ a few-step diffusion model along with a stochastic\ngradient truncation strategy, effectively balancing computational cost and\nperformance. We further introduce a rolling KV cache mechanism that enables\nefficient autoregressive video extrapolation. Extensive experiments demonstrate\nthat our approach achieves real-time streaming video generation with sub-second\nlatency on a single GPU, while matching or even surpassing the generation\nquality of significantly slower and non-causal diffusion models. Project\nwebsite: http://self-forcing.github.io/", "published": "2025-06-09 17:59:55", "link": "http://arxiv.org/abs/2506.08009v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Hidden in plain sight: VLMs overlook their visual representations", "abstract": "Language provides a natural interface to specify and evaluate performance on\nvisual tasks. To realize this possibility, vision language models (VLMs) must\nsuccessfully integrate visual and linguistic information. Our work compares\nVLMs to a direct readout of their visual encoders to understand their ability\nto integrate across these modalities. Across a series of vision-centric\nbenchmarks (e.g., depth estimation, correspondence), we find that VLMs perform\nsubstantially worse than their visual encoders, dropping to near-chance\nperformance. We investigate these results through a series of analyses across\nthe entire VLM: namely 1) the degradation of vision representations, 2)\nbrittleness to task prompt, and 3) the language model's role in solving the\ntask. We find that the bottleneck in performing these vision-centric tasks lies\nin this third category; VLMs are not effectively using visual information\neasily accessible throughout the entire model, and they inherit the language\npriors present in the LLM. Our work helps diagnose the failure modes of\nopen-source VLMs, and presents a series of evaluations useful for future\ninvestigations into visual understanding within VLMs.", "published": "2025-06-09 17:59:54", "link": "http://arxiv.org/abs/2506.08008v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Dynamic View Synthesis as an Inverse Problem", "abstract": "In this work, we address dynamic view synthesis from monocular videos as an\ninverse problem in a training-free setting. By redesigning the noise\ninitialization phase of a pre-trained video diffusion model, we enable\nhigh-fidelity dynamic view synthesis without any weight updates or auxiliary\nmodules. We begin by identifying a fundamental obstacle to deterministic\ninversion arising from zero-terminal signal-to-noise ratio (SNR) schedules and\nresolve it by introducing a novel noise representation, termed K-order\nRecursive Noise Representation. We derive a closed form expression for this\nrepresentation, enabling precise and efficient alignment between the\nVAE-encoded and the DDIM inverted latents. To synthesize newly visible regions\nresulting from camera motion, we introduce Stochastic Latent Modulation, which\nperforms visibility aware sampling over the latent space to complete occluded\nregions. Comprehensive experiments demonstrate that dynamic view synthesis can\nbe effectively performed through structured latent manipulation in the noise\ninitialization phase.", "published": "2025-06-09 17:59:47", "link": "http://arxiv.org/abs/2506.08004v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Audio-Sync Video Generation with Multi-Stream Temporal Control", "abstract": "Audio is inherently temporal and closely synchronized with the visual world,\nmaking it a naturally aligned and expressive control signal for controllable\nvideo generation (e.g., movies). Beyond control, directly translating audio\ninto video is essential for understanding and visualizing rich audio narratives\n(e.g., Podcasts or historical recordings). However, existing approaches fall\nshort in generating high-quality videos with precise audio-visual\nsynchronization, especially across diverse and complex audio types. In this\nwork, we introduce MTV, a versatile framework for audio-sync video generation.\nMTV explicitly separates audios into speech, effects, and music tracks,\nenabling disentangled control over lip motion, event timing, and visual mood,\nrespectively -- resulting in fine-grained and semantically aligned video\ngeneration. To support the framework, we additionally present DEMIX, a dataset\ncomprising high-quality cinematic videos and demixed audio tracks. DEMIX is\nstructured into five overlapped subsets, enabling scalable multi-stage training\nfor diverse generation scenarios. Extensive experiments demonstrate that MTV\nachieves state-of-the-art performance across six standard metrics spanning\nvideo quality, text-video consistency, and audio-video alignment. Project page:\nhttps://hjzheng.net/projects/MTV/.", "published": "2025-06-09 17:59:42", "link": "http://arxiv.org/abs/2506.08003v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Thinking vs. Doing: Agents that Reason by Scaling Test-Time Interaction", "abstract": "The current paradigm of test-time scaling relies on generating long reasoning\ntraces (\"thinking\" more) before producing a response. In agent problems that\nrequire interaction, this can be done by generating thinking traces before\nacting in the world. However, this process does not allow agents to acquire new\ninformation from the environment or adapt their behavior over time. In this\nwork, we propose to scale test-time interaction, an untapped dimension of\ntest-time scaling that increases the agent's interaction horizon to enable\nrunning rich behaviors such as exploration, backtracking, and dynamic\nre-planning within a single rollout. To demonstrate the promise of this scaling\ndimension, we study the domain of web agents. We first show that even\nprompting-based interaction scaling without any training can improve task\nsuccess on web benchmarks non-trivially. Building on this, we introduce TTI\n(Test-Time Interaction), a curriculum-based online reinforcement learning (RL)\napproach that trains agents by adaptively adjusting their rollout lengths.\nUsing a Gemma 3 12B model, TTI produces state-of-the-art open-source, open-data\nweb agents on WebVoyager and WebArena benchmarks. We further show that TTI\nenables agents to balance exploration and exploitation adaptively. Our results\nestablish interaction scaling as a powerful, complementary axis to scaling\nper-step compute, offering new avenues for training adaptive agents.", "published": "2025-06-09 17:50:02", "link": "http://arxiv.org/abs/2506.07976v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "SlideCoder: Layout-aware RAG-enhanced Hierarchical Slide Generation from Design", "abstract": "Manual slide creation is labor-intensive and requires expert prior knowledge.\nExisting natural language-based LLM generation methods struggle to capture the\nvisual and structural nuances of slide designs. To address this, we formalize\nthe Reference Image to Slide Generation task and propose Slide2Code, the first\nbenchmark with difficulty-tiered samples based on a novel Slide Complexity\nMetric. We introduce SlideCoder, a layout-aware, retrieval-augmented framework\nfor generating editable slides from reference images. SlideCoder integrates a\nColor Gradient-based Segmentation algorithm and a Hierarchical\nRetrieval-Augmented Generation method to decompose complex tasks and enhance\ncode generation. We also release SlideMaster, a 7B open-source model fine-tuned\nwith improved reverse-engineered data. Experiments show that SlideCoder\noutperforms state-of-the-art baselines by up to 40.5 points, demonstrating\nstrong performance across layout fidelity, execution accuracy, and visual\nconsistency. Our code is available at\nhttps://github.com/vinsontang1/SlideCoder.", "published": "2025-06-09 17:39:48", "link": "http://arxiv.org/abs/2506.07964v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "BridgeVLA: Input-Output Alignment for Efficient 3D Manipulation Learning with Vision-Language Models", "abstract": "Recently, leveraging pre-trained vision-language models (VLMs) for building\nvision-language-action (VLA) models has emerged as a promising approach to\neffective robot manipulation learning. However, only few methods incorporate 3D\nsignals into VLMs for action prediction, and they do not fully leverage the\nspatial structure inherent in 3D data, leading to low sample efficiency. In\nthis paper, we introduce BridgeVLA, a novel 3D VLA model that (1) projects 3D\ninputs to multiple 2D images, ensuring input alignment with the VLM backbone,\nand (2) utilizes 2D heatmaps for action prediction, unifying the input and\noutput spaces within a consistent 2D image space. In addition, we propose a\nscalable pre-training method that equips the VLM backbone with the capability\nto predict 2D heatmaps before downstream policy learning. Extensive experiments\nshow the proposed method is able to learn 3D manipulation efficiently and\neffectively. BridgeVLA outperforms state-of-the-art baseline methods across\nthree simulation benchmarks. In RLBench, it improves the average success rate\nfrom 81.4% to 88.2%. In COLOSSEUM, it demonstrates significantly better\nperformance in challenging generalization settings, boosting the average\nsuccess rate from 56.7% to 64.0%. In GemBench, it surpasses all the comparing\nbaseline methods in terms of average success rate. In real-robot experiments,\nBridgeVLA outperforms a state-of-the-art baseline method by 32% on average. It\ngeneralizes robustly in multiple out-of-distribution settings, including visual\ndisturbances and unseen instructions. Remarkably, it is able to achieve a\nsuccess rate of 96.8% on 10+ tasks with only 3 trajectories per task,\nhighlighting its extraordinary sample efficiency. Project\nWebsite:https://bridgevla.github.io/", "published": "2025-06-09 17:36:34", "link": "http://arxiv.org/abs/2506.07961v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Decoupling the Image Perception and Multimodal Reasoning for Reasoning Segmentation with Digital Twin Representations", "abstract": "Reasoning Segmentation (RS) is a multimodal vision-text task that requires\nsegmenting objects based on implicit text queries, demanding both precise\nvisual perception and vision-text reasoning capabilities. Current RS approaches\nrely on fine-tuning vision-language models (VLMs) for both perception and\nreasoning, but their tokenization of images fundamentally disrupts continuous\nspatial relationships between objects. We introduce DTwinSeger, a novel RS\napproach that leverages Digital Twin (DT) representation as an intermediate\nlayer to decouple perception from reasoning. Innovatively, DTwinSeger\nreformulates RS as a two-stage process, where the first transforms the image\ninto a structured DT representation that preserves spatial relationships and\nsemantic properties and then employs a Large Language Model (LLM) to perform\nexplicit reasoning over this representation to identify target objects. We\npropose a supervised fine-tuning method specifically for LLM with DT\nrepresentation, together with a corresponding fine-tuning dataset Seg-DT, to\nenhance the LLM's reasoning capabilities with DT representations. Experiments\nshow that our method can achieve state-of-the-art performance on two image RS\nbenchmarks and three image referring segmentation benchmarks. It yields that DT\nrepresentation functions as an effective bridge between vision and text,\nenabling complex multimodal reasoning tasks to be accomplished solely with an\nLLM.", "published": "2025-06-09 17:05:02", "link": "http://arxiv.org/abs/2506.07943v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Gradients: When Markets Meet Fine-tuning -- A Distributed Approach to Model Optimisation", "abstract": "Foundation model fine-tuning faces a fundamental challenge: existing AutoML\nplatforms rely on single optimisation strategies that explore only a fraction\nof viable hyperparameter configurations. In this white paper, We introduce\nGradients, a decentralised AutoML platform that transforms hyperparameter\noptimisation into a competitive marketplace where independent miners compete to\ndiscover optimal configurations. Economic incentives align individual\nexploration with collective optimisation goals, driving systematic\ninvestigation of hyperparameter regions that centralised methods miss. We\nevaluate our approach across 180 controlled experiments spanning diverse model\narchitectures (70M to 70B parameters) and task types. Gradients achieves an\n82.8\\% win rate against HuggingFace AutoTrain and 100\\% against TogetherAI,\nDatabricks, and Google Cloud, with mean improvements of 11.8\\% and 42.1\\%\nrespectively. Complex reasoning and retrieval tasks show particularly strong\ngains of 30-40\\%, whilst diffusion models achieve 23.4\\% improvements for\nperson-specific generation. These results demonstrate that competitive,\neconomically-driven approaches can systematically discover superior\nconfigurations that centralised AutoML consistently miss.", "published": "2025-06-09 17:00:38", "link": "http://arxiv.org/abs/2506.07940v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Diffusion of Responsibility in Collective Decision Making", "abstract": "The term \"diffusion of responsibility'' refers to situations in which\nmultiple agents share responsibility for an outcome, obscuring individual\naccountability. This paper examines this frequently undesirable phenomenon in\nthe context of collective decision-making mechanisms.\n  The work shows that if a decision is made by two agents, then the only way to\navoid diffusion of responsibility is for one agent to act as a \"dictator'',\nmaking the decision unilaterally. In scenarios with more than two agents, any\ndiffusion-free mechanism is an \"elected dictatorship'' where the agents elect a\nsingle agent to make a unilateral decision.\n  The technical results are obtained by defining a bisimulation of\ndecision-making mechanisms, proving that bisimulation preserves\nresponsibility-related properties, and establishing the results for a smallest\nbisimular mechanism.", "published": "2025-06-09 16:54:56", "link": "http://arxiv.org/abs/2506.07935v1", "categories": ["cs.MA", "cs.AI", "cs.GT"], "primary_category": "cs.MA"}
{"title": "Diffuse Everything: Multimodal Diffusion Models on Arbitrary State Spaces", "abstract": "Diffusion models have demonstrated remarkable performance in generating\nunimodal data across various tasks, including image, video, and text\ngeneration. On the contrary, the joint generation of multimodal data through\ndiffusion models is still in the early stages of exploration. Existing\napproaches heavily rely on external preprocessing protocols, such as tokenizers\nand variational autoencoders, to harmonize varied data representations into a\nunified, unimodal format. This process heavily demands the high accuracy of\nencoders and decoders, which can be problematic for applications with limited\ndata. To lift this restriction, we propose a novel framework for building\nmultimodal diffusion models on arbitrary state spaces, enabling native\ngeneration of coupled data across different modalities. By introducing an\ninnovative decoupled noise schedule for each modality, we enable both\nunconditional and modality-conditioned generation within a single model\nsimultaneously. We empirically validate our approach for text-image generation\nand mixed-type tabular data synthesis, demonstrating that it achieves\ncompetitive performance.", "published": "2025-06-09 16:20:20", "link": "http://arxiv.org/abs/2506.07903v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "GaussianVAE: Adaptive Learning Dynamics of 3D Gaussians for High-Fidelity Super-Resolution", "abstract": "We present a novel approach for enhancing the resolution and geometric\nfidelity of 3D Gaussian Splatting (3DGS) beyond native training resolution.\nCurrent 3DGS methods are fundamentally limited by their input resolution,\nproducing reconstructions that cannot extrapolate finer details than are\npresent in the training views. Our work breaks this limitation through a\nlightweight generative model that predicts and refines additional 3D Gaussians\nwhere needed most. The key innovation is our Hessian-assisted sampling\nstrategy, which intelligently identifies regions that are likely to benefit\nfrom densification, ensuring computational efficiency. Unlike computationally\nintensive GANs or diffusion approaches, our method operates in real-time\n(0.015s per inference on a single consumer-grade GPU), making it practical for\ninteractive applications. Comprehensive experiments demonstrate significant\nimprovements in both geometric accuracy and rendering quality compared to\nstate-of-the-art methods, establishing a new paradigm for resolution-free 3D\nscene enhancement.", "published": "2025-06-09 16:13:12", "link": "http://arxiv.org/abs/2506.07897v1", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.GR"}
{"title": "Diffusion Counterfactual Generation with Semantic Abduction", "abstract": "Counterfactual image generation presents significant challenges, including\npreserving identity, maintaining perceptual quality, and ensuring faithfulness\nto an underlying causal model. While existing auto-encoding frameworks admit\nsemantic latent spaces which can be manipulated for causal control, they\nstruggle with scalability and fidelity. Advancements in diffusion models\npresent opportunities for improving counterfactual image editing, having\ndemonstrated state-of-the-art visual quality, human-aligned perception and\nrepresentation learning capabilities. Here, we present a suite of\ndiffusion-based causal mechanisms, introducing the notions of spatial, semantic\nand dynamic abduction. We propose a general framework that integrates semantic\nrepresentations into diffusion models through the lens of Pearlian causality to\nedit images via a counterfactual reasoning process. To our knowledge, this is\nthe first work to consider high-level semantic identity preservation for\ndiffusion counterfactuals and to demonstrate how semantic control enables\nprincipled trade-offs between faithful causal control and identity\npreservation.", "published": "2025-06-09 15:54:00", "link": "http://arxiv.org/abs/2506.07883v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity", "abstract": "In this paper, we aim to model 3D scene geometry, appearance, and the\nunderlying physics purely from multi-view videos. By applying various governing\nPDEs as PINN losses or incorporating physics simulation into neural networks,\nexisting works often fail to learn complex physical motions at boundaries or\nrequire object priors such as masks or types. In this paper, we propose\nFreeGave to learn the physics of complex dynamic 3D scenes without needing any\nobject priors. The key to our approach is to introduce a physics code followed\nby a carefully designed divergence-free module for estimating a per-Gaussian\nvelocity field, without relying on the inefficient PINN losses. Extensive\nexperiments on three public datasets and a newly collected challenging\nreal-world dataset demonstrate the superior performance of our method for\nfuture frame extrapolation and motion segmentation. Most notably, our\ninvestigation into the learned physics codes reveals that they truly learn\nmeaningful 3D physical motion patterns in the absence of any human labels in\ntraining.", "published": "2025-06-09 15:31:25", "link": "http://arxiv.org/abs/2506.07865v1", "categories": ["cs.CV", "cs.AI", "cs.CE", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Lightweight Sequential Transformers for Blood Glucose Level Prediction in Type-1 Diabetes", "abstract": "Type 1 Diabetes (T1D) affects millions worldwide, requiring continuous\nmonitoring to prevent severe hypo- and hyperglycemic events. While continuous\nglucose monitoring has improved blood glucose management, deploying predictive\nmodels on wearable devices remains challenging due to computational and memory\nconstraints. To address this, we propose a novel Lightweight Sequential\nTransformer model designed for blood glucose prediction in T1D. By integrating\nthe strengths of Transformers' attention mechanisms and the sequential\nprocessing of recurrent neural networks, our architecture captures long-term\ndependencies while maintaining computational efficiency. The model is optimized\nfor deployment on resource-constrained edge devices and incorporates a balanced\nloss function to handle the inherent data imbalance in hypo- and hyperglycemic\nevents. Experiments on two benchmark datasets, OhioT1DM and DiaTrend,\ndemonstrate that the proposed model outperforms state-of-the-art methods in\npredicting glucose levels and detecting adverse events. This work fills the gap\nbetween high-performance modeling and practical deployment, providing a\nreliable and efficient T1D management solution.", "published": "2025-06-09 15:27:43", "link": "http://arxiv.org/abs/2506.07864v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Fairness Overfitting in Machine Learning: An Information-Theoretic Perspective", "abstract": "Despite substantial progress in promoting fairness in high-stake applications\nusing machine learning models, existing methods often modify the training\nprocess, such as through regularizers or other interventions, but lack formal\nguarantees that fairness achieved during training will generalize to unseen\ndata. Although overfitting with respect to prediction performance has been\nextensively studied, overfitting in terms of fairness loss has received far\nless attention. This paper proposes a theoretical framework for analyzing\nfairness generalization error through an information-theoretic lens. Our novel\nbounding technique is based on Efron-Stein inequality, which allows us to\nderive tight information-theoretic fairness generalization bounds with both\nMutual Information (MI) and Conditional Mutual Information (CMI). Our empirical\nresults validate the tightness and practical relevance of these bounds across\ndiverse fairness-aware learning algorithms. Our framework offers valuable\ninsights to guide the design of algorithms improving fairness generalization.", "published": "2025-06-09 15:24:56", "link": "http://arxiv.org/abs/2506.07861v1", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds", "abstract": "We study the problem of unsupervised 3D semantic segmentation on raw point\nclouds without needing human labels in training. Existing methods usually\nformulate this problem into learning per-point local features followed by a\nsimple grouping strategy, lacking the ability to discover additional and\npossibly richer semantic priors beyond local features. In this paper, we\nintroduce LogoSP to learn 3D semantics from both local and global point\nfeatures. The key to our approach is to discover 3D semantic information by\ngrouping superpoints according to their global patterns in the frequency\ndomain, thus generating highly accurate semantic pseudo-labels for training a\nsegmentation network. Extensive experiments on two indoor and an outdoor\ndatasets show that our LogoSP surpasses all existing unsupervised methods by\nlarge margins, achieving the state-of-the-art performance for unsupervised 3D\nsemantic segmentation. Notably, our investigation into the learned global\npatterns reveals that they truly represent meaningful 3D semantics in the\nabsence of human labels during training.", "published": "2025-06-09 15:21:37", "link": "http://arxiv.org/abs/2506.07857v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Residual Reweighted Conformal Prediction for Graph Neural Networks", "abstract": "Graph Neural Networks (GNNs) excel at modeling relational data but face\nsignificant challenges in high-stakes domains due to unquantified uncertainty.\nConformal prediction (CP) offers statistical coverage guarantees, but existing\nmethods often produce overly conservative prediction intervals that fail to\naccount for graph heteroscedasticity and structural biases. While residual\nreweighting CP variants address some of these limitations, they neglect graph\ntopology, cluster-specific uncertainties, and risk data leakage by reusing\ntraining sets. To address these issues, we propose Residual Reweighted GNN\n(RR-GNN), a framework designed to generate minimal prediction sets with\nprovable marginal coverage guarantees.\n  RR-GNN introduces three major innovations to enhance prediction performance.\nFirst, it employs Graph-Structured Mondrian CP to partition nodes or edges into\ncommunities based on topological features, ensuring cluster-conditional\ncoverage that reflects heterogeneity. Second, it uses Residual-Adaptive\nNonconformity Scores by training a secondary GNN on a held-out calibration set\nto estimate task-specific residuals, dynamically adjusting prediction intervals\naccording to node or edge uncertainty. Third, it adopts a Cross-Training\nProtocol, which alternates the optimization of the primary GNN and the residual\npredictor to prevent information leakage while maintaining graph dependencies.\nWe validate RR-GNN on 15 real-world graphs across diverse tasks, including node\nclassification, regression, and edge weight prediction. Compared to CP\nbaselines, RR-GNN achieves improved efficiency over state-of-the-art methods,\nwith no loss of coverage.", "published": "2025-06-09 15:19:17", "link": "http://arxiv.org/abs/2506.07854v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Temporal FRBR/FRBRoo-Based Model for Component-Level Versioning of Legal Norms", "abstract": "Effectively representing legal norms for automated processing is a critical\nchallenge, particularly in tracking the diachronic evolution of their\nhierarchical components (e.g., articles, paragraphs). While foundational\nframeworks like FRBR/FRBRoo and standards like Akoma Ntoso model legal\ndocuments at a macro level, they lack native mechanisms for granular,\ncomponent-level versioning. This limitation hinders the deterministic\npoint-in-time reconstruction of legal texts, a fundamental capability for\nreliable Legal Tech and AI applications. This paper proposes a structured,\ntemporal model that extends the FRBRoo framework to address this gap. It\nintroduces specialized subclasses of Expressio - Temporal Version (TV) and\nLanguage Version (LV - to represent the state of a legal norm and its\nlinguistic variations at specific points in time. The model applies this same\nparadigm hierarchically, introducing Component Work (CW), Component Temporal\nVersion (CTV), and Component Language Version (CLV) to track the lifecycle of\nindividual articles, paragraphs, and clauses. Using the Brazilian Federal\nConstitution as a case study, the paper demonstrates how each amendment creates\nnew Component Temporal Versions for affected provisions, while unaffected\ncomponents retain their existing versions. This fine-grained, time-aware\narchitecture enables the precise, deterministic retrieval and reconstruction of\nany part of a legal text as it existed on a specific date. The model provides a\nrobust foundation for developing advanced legal information systems, knowledge\ngraphs, and AI tools capable of accurate historical analysis and impact\nassessment, overcoming the limitations of current generative models.", "published": "2025-06-09 15:18:36", "link": "http://arxiv.org/abs/2506.07853v1", "categories": ["cs.AI", "cs.IR"], "primary_category": "cs.AI"}
{"title": "PolyVivid: Vivid Multi-Subject Video Generation with Cross-Modal Interaction and Enhancement", "abstract": "Despite recent advances in video generation, existing models still lack\nfine-grained controllability, especially for multi-subject customization with\nconsistent identity and interaction. In this paper, we propose PolyVivid, a\nmulti-subject video customization framework that enables flexible and\nidentity-consistent generation. To establish accurate correspondences between\nsubject images and textual entities, we design a VLLM-based text-image fusion\nmodule that embeds visual identities into the textual space for precise\ngrounding. To further enhance identity preservation and subject interaction, we\npropose a 3D-RoPE-based enhancement module that enables structured\nbidirectional fusion between text and image embeddings. Moreover, we develop an\nattention-inherited identity injection module to effectively inject fused\nidentity features into the video generation process, mitigating identity drift.\nFinally, we construct an MLLM-based data pipeline that combines MLLM-based\ngrounding, segmentation, and a clique-based subject consolidation strategy to\nproduce high-quality multi-subject data, effectively enhancing subject\ndistinction and reducing ambiguity in downstream video generation. Extensive\nexperiments demonstrate that PolyVivid achieves superior performance in\nidentity fidelity, video realism, and subject alignment, outperforming existing\nopen-source and commercial baselines.", "published": "2025-06-09 15:11:09", "link": "http://arxiv.org/abs/2506.07848v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Diffusion models under low-noise regime", "abstract": "Recent work on diffusion models proposed that they operate in two regimes:\nmemorization, in which models reproduce their training data, and\ngeneralization, in which they generate novel samples. While this has been\ntested in high-noise settings, the behavior of diffusion models as effective\ndenoisers when the corruption level is small remains unclear. To address this\ngap, we systematically investigated the behavior of diffusion models under\nlow-noise diffusion dynamics, with implications for model robustness and\ninterpretability. Using (i) CelebA subsets of varying sample sizes and (ii)\nanalytic Gaussian mixture benchmarks, we reveal that models trained on disjoint\ndata diverge near the data manifold even when their high-noise outputs\nconverge. We quantify how training set size, data geometry, and model objective\nchoice shape denoising trajectories and affect score accuracy, providing\ninsights into how these models actually learn representations of data\ndistributions. This work starts to address gaps in our understanding of\ngenerative model reliability in practical applications where small\nperturbations are common.", "published": "2025-06-09 15:07:16", "link": "http://arxiv.org/abs/2506.07841v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "HAIBU-ReMUD: Reasoning Multimodal Ultrasound Dataset and Model Bridging to General Specific Domains", "abstract": "Multimodal large language models (MLLMs) have shown great potential in\ngeneral domains but perform poorly in some specific domains due to a lack of\ndomain-specific data, such as image-text data or vedio-text data. In some\nspecific domains, there is abundant graphic and textual data scattered around,\nbut lacks standardized arrangement. In the field of medical ultrasound, there\nare ultrasonic diagnostic books, ultrasonic clinical guidelines, ultrasonic\ndiagnostic reports, and so on. However, these ultrasonic materials are often\nsaved in the forms of PDF, images, etc., and cannot be directly used for the\ntraining of MLLMs. This paper proposes a novel image-text reasoning supervised\nfine-tuning data generation pipeline to create specific domain quadruplets\n(image, question, thinking trace, and answer) from domain-specific materials. A\nmedical ultrasound domain dataset ReMUD is established, containing over 45,000\nreasoning and non-reasoning supervised fine-tuning Question Answering (QA) and\nVisual Question Answering (VQA) data. The ReMUD-7B model, fine-tuned on\nQwen2.5-VL-7B-Instruct, outperforms general-domain MLLMs in medical ultrasound\nfield. To facilitate research, the ReMUD dataset, data generation codebase, and\nReMUD-7B parameters will be released at https://github.com/ShiDaizi/ReMUD,\naddressing the data shortage issue in specific domain MLLMs.", "published": "2025-06-09 15:01:38", "link": "http://arxiv.org/abs/2506.07837v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Are Trees Really Green? A Detection Approach of IoT Malware Attacks", "abstract": "Nowadays, the Internet of Things (IoT) is widely employed, and its usage is\ngrowing exponentially because it facilitates remote monitoring, predictive\nmaintenance, and data-driven decision making, especially in the healthcare and\nindustrial sectors. However, IoT devices remain vulnerable due to their\nresource constraints and difficulty in applying security patches. Consequently,\nvarious cybersecurity attacks are reported daily, such as Denial of Service,\nparticularly in IoT-driven solutions. Most attack detection methodologies are\nbased on Machine Learning (ML) techniques, which can detect attack patterns.\nHowever, the focus is more on identification rather than considering the impact\nof ML algorithms on computational resources. This paper proposes a green\nmethodology to identify IoT malware networking attacks based on flow\nprivacy-preserving statistical features. In particular, the hyperparameters of\nthree tree-based models -- Decision Trees, Random Forest and Extra-Trees -- are\noptimized based on energy consumption and test-time performance in terms of\nMatthew's Correlation Coefficient. Our results show that models maintain high\nperformance and detection accuracy while consistently reducing power usage in\nterms of watt-hours (Wh). This suggests that on-premise ML-based Intrusion\nDetection Systems are suitable for IoT and other resource-constrained devices.", "published": "2025-06-09 15:01:04", "link": "http://arxiv.org/abs/2506.07836v1", "categories": ["cs.CR", "cs.AI", "cs.NI"], "primary_category": "cs.CR"}
{"title": "Decentralizing Multi-Agent Reinforcement Learning with Temporal Causal Information", "abstract": "Reinforcement learning (RL) algorithms can find an optimal policy for a\nsingle agent to accomplish a particular task. However, many real-world problems\nrequire multiple agents to collaborate in order to achieve a common goal. For\nexample, a robot executing a task in a warehouse may require the assistance of\na drone to retrieve items from high shelves. In Decentralized Multi-Agent RL\n(DMARL), agents learn independently and then combine their policies at\nexecution time, but often must satisfy constraints on compatibility of local\npolicies to ensure that they can achieve the global task when combined. In this\npaper, we study how providing high-level symbolic knowledge to agents can help\naddress unique challenges of this setting, such as privacy constraints,\ncommunication limitations, and performance concerns. In particular, we extend\nthe formal tools used to check the compatibility of local policies with the\nteam task, making decentralized training with theoretical guarantees usable in\nmore scenarios. Furthermore, we empirically demonstrate that symbolic knowledge\nabout the temporal evolution of events in the environment can significantly\nexpedite the learning process in DMARL.", "published": "2025-06-09 14:53:03", "link": "http://arxiv.org/abs/2506.07829v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Addition in Four Movements: Mapping Layer-wise Information Trajectories in LLMs", "abstract": "Multi-digit addition is a clear probe of the computational power of large\nlanguage models. To dissect the internal arithmetic processes in\nLLaMA-3-8B-Instruct, we combine linear probing with logit-lens inspection.\nInspired by the step-by-step manner in which humans perform addition, we\npropose and analyze a coherent four-stage trajectory in the forward\npass:Formula-structure representations become linearly decodable first, while\nthe answer token is still far down the candidate list.Core computational\nfeatures then emerge prominently.At deeper activation layers, numerical\nabstractions of the result become clearer, enabling near-perfect detection and\ndecoding of the individual digits in the sum.Near the output, the model\norganizes and generates the final content, with the correct token reliably\noccupying the top rank.This trajectory suggests a hierarchical process that\nfavors internal computation over rote memorization. We release our code and\ndata to facilitate reproducibility.", "published": "2025-06-09 14:48:43", "link": "http://arxiv.org/abs/2506.07824v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Accelerating Diffusion Models in Offline RL via Reward-Aware Consistency Trajectory Distillation", "abstract": "Although diffusion models have achieved strong results in decision-making\ntasks, their slow inference speed remains a key limitation. While the\nconsistency model offers a potential solution, its applications to\ndecision-making often struggle with suboptimal demonstrations or rely on\ncomplex concurrent training of multiple networks. In this work, we propose a\nnovel approach to consistency distillation for offline reinforcement learning\nthat directly incorporates reward optimization into the distillation process.\nOur method enables single-step generation while maintaining higher performance\nand simpler training. Empirical evaluations on the Gym MuJoCo benchmarks and\nlong horizon planning demonstrate that our approach can achieve an 8.7%\nimprovement over previous state-of-the-art while offering up to 142x speedup\nover diffusion counterparts in inference time.", "published": "2025-06-09 14:48:19", "link": "http://arxiv.org/abs/2506.07822v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Guideline Forest: Experience-Induced Multi-Guideline Reasoning with Stepwise Aggregation", "abstract": "Human reasoning is flexible, adaptive, and grounded in prior\nexperience-qualities that large language models (LLMs) still struggle to\nemulate. Existing methods either explore diverse reasoning paths at inference\ntime or search for optimal workflows through expensive operations, but both\nfall short in leveraging multiple reusable strategies in a structured,\nefficient manner. We propose Guideline Forest, a framework that enhances LLMs\nreasoning by inducing structured reasoning strategies-called guidelines-from\nverified examples and executing them via step-wise aggregation. Unlike\ntest-time search or single-path distillation, our method draws on verified\nreasoning experiences by inducing reusable guidelines and expanding each into\ndiverse variants. Much like human reasoning, these variants reflect alternative\nthought patterns, are executed in parallel, refined via self-correction, and\naggregated step by step-enabling the model to adaptively resolve uncertainty\nand synthesize robust solutions.We evaluate Guideline Forest on four\nbenchmarks-GSM8K, MATH-500, MBPP, and HumanEval-spanning mathematical and\nprogrammatic reasoning. Guideline Forest consistently outperforms strong\nbaselines, including CoT, ReAct, ToT, FoT, and AFlow. Ablation studies further\nhighlight the effectiveness of multi-path reasoning and stepwise aggregation,\nunderscoring the Guideline Forest's adaptability and generalization potential.", "published": "2025-06-09 14:46:31", "link": "http://arxiv.org/abs/2506.07820v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Self-Cascaded Diffusion Models for Arbitrary-Scale Image Super-Resolution", "abstract": "Arbitrary-scale image super-resolution aims to upsample images to any desired\nresolution, offering greater flexibility than traditional fixed-scale\nsuper-resolution. Recent approaches in this domain utilize regression-based or\ngenerative models, but many of them are a single-stage upsampling process,\nwhich may be challenging to learn across a wide, continuous distribution of\nscaling factors. Progressive upsampling strategies have shown promise in\nmitigating this issue, yet their integration with diffusion models for flexible\nupscaling remains underexplored. Here, we present CasArbi, a novel\nself-cascaded diffusion framework for arbitrary-scale image super-resolution.\nCasArbi meets the varying scaling demands by breaking them down into smaller\nsequential factors and progressively enhancing the image resolution at each\nstep with seamless transitions for arbitrary scales. Our novel\ncoordinate-guided residual diffusion model allows for the learning of\ncontinuous image representations while enabling efficient diffusion sampling.\nExtensive experiments demonstrate that our CasArbi outperforms prior arts in\nboth perceptual and distortion performance metrics across diverse\narbitrary-scale super-resolution benchmarks.", "published": "2025-06-09 14:43:21", "link": "http://arxiv.org/abs/2506.07813v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A Proposal to Extend the Common Model of Cognition with Metacognition", "abstract": "The Common Model of Cognition (CMC) provides an abstract characterization of\nthe structure and processing required by a cognitive architecture for\nhuman-like minds. We propose a unified approach to integrating metacognition\nwithin the CMC. We propose that metacognition involves reasoning over explicit\nrepresentations of an agent's cognitive capabilities and processes in working\nmemory. Our proposal exploits the existing cognitive capabilities of the CMC,\nmaking minimal extensions in the structure and information available within\nworking memory. We provide examples of metacognition within our proposal.", "published": "2025-06-09 14:35:48", "link": "http://arxiv.org/abs/2506.07807v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Enhancing Adversarial Robustness with Conformal Prediction: A Framework for Guaranteed Model Reliability", "abstract": "As deep learning models are increasingly deployed in high-risk applications,\nrobust defenses against adversarial attacks and reliable performance guarantees\nbecome paramount. Moreover, accuracy alone does not provide sufficient\nassurance or reliable uncertainty estimates for these models. This study\nadvances adversarial training by leveraging principles from Conformal\nPrediction. Specifically, we develop an adversarial attack method, termed OPSA\n(OPtimal Size Attack), designed to reduce the efficiency of conformal\nprediction at any significance level by maximizing model uncertainty without\nrequiring coverage guarantees. Correspondingly, we introduce OPSA-AT\n(Adversarial Training), a defense strategy that integrates OPSA within a novel\nconformal training paradigm. Experimental evaluations demonstrate that our OPSA\nattack method induces greater uncertainty compared to baseline approaches for\nvarious defenses. Conversely, our OPSA-AT defensive model significantly\nenhances robustness not only against OPSA but also other adversarial attacks,\nand maintains reliable prediction. Our findings highlight the effectiveness of\nthis integrated approach for developing trustworthy and resilient deep learning\nmodels for safety-critical domains. Our code is available at\nhttps://github.com/bjbbbb/Enhancing-Adversarial-Robustness-with-Conformal-Prediction.", "published": "2025-06-09 14:33:28", "link": "http://arxiv.org/abs/2506.07804v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Re-ranking Reasoning Context with Tree Search Makes Large Vision-Language Models Stronger", "abstract": "Recent advancements in Large Vision Language Models (LVLMs) have\nsignificantly improved performance in Visual Question Answering (VQA) tasks\nthrough multimodal Retrieval-Augmented Generation (RAG). However, existing\nmethods still face challenges, such as the scarcity of knowledge with reasoning\nexamples and erratic responses from retrieved knowledge. To address these\nissues, in this study, we propose a multimodal RAG framework, termed RCTS,\nwhich enhances LVLMs by constructing a Reasoning Context-enriched knowledge\nbase and a Tree Search re-ranking method. Specifically, we introduce a\nself-consistent evaluation mechanism to enrich the knowledge base with\nintrinsic reasoning patterns. We further propose a Monte Carlo Tree Search with\nHeuristic Rewards (MCTS-HR) to prioritize the most relevant examples. This\nensures that LVLMs can leverage high-quality contextual reasoning for better\nand more consistent responses. Extensive experiments demonstrate that our\nframework achieves state-of-the-art performance on multiple VQA datasets,\nsignificantly outperforming In-Context Learning (ICL) and Vanilla-RAG methods.\nIt highlights the effectiveness of our knowledge base and re-ranking method in\nimproving LVLMs. Our code is available at https://github.com/yannqi/RCTS-RAG.", "published": "2025-06-09 14:00:57", "link": "http://arxiv.org/abs/2506.07785v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "REMoH: A Reflective Evolution of Multi-objective Heuristics approach via Large Language Models", "abstract": "Multi-objective optimization is fundamental in complex decision-making tasks.\nTraditional algorithms, while effective, often demand extensive\nproblem-specific modeling and struggle to adapt to nonlinear structures. Recent\nadvances in Large Language Models (LLMs) offer enhanced explainability,\nadaptability, and reasoning. This work proposes Reflective Evolution of\nMulti-objective Heuristics (REMoH), a novel framework integrating NSGA-II with\nLLM-based heuristic generation. A key innovation is a reflection mechanism that\nuses clustering and search-space reflection to guide the creation of diverse,\nhigh-quality heuristics, improving convergence and maintaining solution\ndiversity. The approach is evaluated on the Flexible Job Shop Scheduling\nProblem (FJSSP) in-depth benchmarking against state-of-the-art methods using\nthree instance datasets: Dauzere, Barnes, and Brandimarte. Results demonstrate\nthat REMoH achieves competitive results compared to state-of-the-art approaches\nwith reduced modeling effort and enhanced adaptability. These findings\nunderscore the potential of LLMs to augment traditional optimization, offering\ngreater flexibility, interpretability, and robustness in multi-objective\nscenarios.", "published": "2025-06-09 13:38:28", "link": "http://arxiv.org/abs/2506.07759v1", "categories": ["cs.AI", "cs.NE", "I.2.7; I.2.8; F.2.2"], "primary_category": "cs.AI"}
{"title": "Agent Semantics, Semantic Spacetime, and Graphical Reasoning", "abstract": "Some formal aspects of the Semantic Spacetime graph model are presented, with\nreference to its use for directed knowledge representations and process\nmodelling. A finite $\\gamma(3,4)$ representation is defined to form a closed\nset of operations that can scale to any degree of semantic complexity. The\nSemantic Spacetime postulates bring predictability with minimal constraints to\npathways in graphs. The ubiquitous appearance of absorbing states in any\npartial graph means that a graph process leaks information. The issue is\nclosely associated with the issue of division by zero, which signals a loss of\nclosure and the need for manual injection of remedial information. The Semantic\nSpacetime model (and its Promise Theory) origins help to clarify how such\nabsorbing states are associated with boundary information where intentionality\ncan enter.", "published": "2025-06-09 13:37:47", "link": "http://arxiv.org/abs/2506.07756v1", "categories": ["cs.AI", "cs.LG", "cs.MA", "I.2.11; F.4.1; I.2.4; G.2.2"], "primary_category": "cs.AI"}
{"title": "Comparing Credit Risk Estimates in the Gen-AI Era", "abstract": "Generative AI technologies have demonstrated significant potential across\ndiverse applications. This study provides a comparative analysis of credit\nscore modeling techniques, contrasting traditional approaches with those\nleveraging generative AI. Our findings reveal that current generative AI models\nfall short of matching the performance of traditional methods, regardless of\nthe integration strategy employed. These results highlight the limitations in\nthe current capabilities of generative AI for credit risk scoring, emphasizing\nthe need for further research and development before the possibility of\napplying generative AI for this specific task, or equivalent ones.", "published": "2025-06-09 13:37:04", "link": "http://arxiv.org/abs/2506.07754v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Graph-Assisted Stitching for Offline Hierarchical Reinforcement Learning", "abstract": "Existing offline hierarchical reinforcement learning methods rely on\nhigh-level policy learning to generate subgoal sequences. However, their\nefficiency degrades as task horizons increase, and they lack effective\nstrategies for stitching useful state transitions across different\ntrajectories. We propose Graph-Assisted Stitching (GAS), a novel framework that\nformulates subgoal selection as a graph search problem rather than learning an\nexplicit high-level policy. By embedding states into a Temporal Distance\nRepresentation (TDR) space, GAS clusters semantically similar states from\ndifferent trajectories into unified graph nodes, enabling efficient transition\nstitching. A shortest-path algorithm is then applied to select subgoal\nsequences within the graph, while a low-level policy learns to reach the\nsubgoals. To improve graph quality, we introduce the Temporal Efficiency (TE)\nmetric, which filters out noisy or inefficient transition states, significantly\nenhancing task performance. GAS outperforms prior offline HRL methods across\nlocomotion, navigation, and manipulation tasks. Notably, in the most\nstitching-critical task, it achieves a score of 88.3, dramatically surpassing\nthe previous state-of-the-art score of 1.0. Our source code is available at:\nhttps://github.com/qortmdgh4141/GAS.", "published": "2025-06-09 13:26:23", "link": "http://arxiv.org/abs/2506.07744v1", "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "cs.LG"}
{"title": "ArchiLense: A Framework for Quantitative Analysis of Architectural Styles Based on Vision Large Language Models", "abstract": "Architectural cultures across regions are characterized by stylistic\ndiversity, shaped by historical, social, and technological contexts in addition\nto geograph-ical conditions. Understanding architectural styles requires the\nability to describe and analyze the stylistic features of different architects\nfrom various regions through visual observations of architectural imagery.\nHowever, traditional studies of architectural culture have largely relied on\nsubjective expert interpretations and historical literature reviews, often\nsuffering from regional biases and limited ex-planatory scope. To address these\nchallenges, this study proposes three core contributions: (1) We construct a\nprofessional architectural style dataset named ArchDiffBench, which comprises\n1,765 high-quality architectural images and their corresponding style\nannotations, collected from different regions and historical periods. (2) We\npropose ArchiLense, an analytical framework grounded in Vision-Language Models\nand constructed using the ArchDiffBench dataset. By integrating ad-vanced\ncomputer vision techniques, deep learning, and machine learning algo-rithms,\nArchiLense enables automatic recognition, comparison, and precise\nclassi-fication of architectural imagery, producing descriptive language\noutputs that ar-ticulate stylistic differences. (3) Extensive evaluations show\nthat ArchiLense achieves strong performance in architectural style recognition,\nwith a 92.4% con-sistency rate with expert annotations and 84.5% classification\naccuracy, effec-tively capturing stylistic distinctions across images. The\nproposed approach transcends the subjectivity inherent in traditional analyses\nand offers a more objective and accurate perspective for comparative studies of\narchitectural culture.", "published": "2025-06-09 13:22:57", "link": "http://arxiv.org/abs/2506.07739v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "RSafe: Incentivizing proactive reasoning to build robust and adaptive LLM safeguards", "abstract": "Large Language Models (LLMs) continue to exhibit vulnerabilities despite\ndeliberate safety alignment efforts, posing significant risks to users and\nsociety. To safeguard against the risk of policy-violating content,\nsystem-level moderation via external guard models-designed to monitor LLM\ninputs and outputs and block potentially harmful content-has emerged as a\nprevalent mitigation strategy. Existing approaches of training guard models\nrely heavily on extensive human curated datasets and struggle with\nout-of-distribution threats, such as emerging harmful categories or jailbreak\nattacks. To address these limitations, we propose RSafe, an adaptive\nreasoning-based safeguard that conducts guided safety reasoning to provide\nrobust protection within the scope of specified safety policies. RSafe operates\nin two stages: 1) guided reasoning, where it analyzes safety risks of input\ncontent through policy-guided step-by-step reasoning, and 2) reinforced\nalignment, where rule-based RL optimizes its reasoning paths to align with\naccurate safety prediction. This two-stage training paradigm enables RSafe to\ninternalize safety principles to generalize safety protection capability over\nunseen or adversarial safety violation scenarios. During inference, RSafe\naccepts user-specified safety policies to provide enhanced safeguards tailored\nto specific safety requirements.", "published": "2025-06-09 13:20:04", "link": "http://arxiv.org/abs/2506.07736v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "NeurIPS 2025 E2LM Competition : Early Training Evaluation of Language Models", "abstract": "Existing benchmarks have proven effective for assessing the performance of\nfully trained large language models. However, we find striking differences in\nthe early training stages of small models, where benchmarks often fail to\nprovide meaningful or discriminative signals. To explore how these differences\narise, this competition tackles the challenge of designing scientific knowledge\nevaluation tasks specifically tailored for measuring early training progress of\nlanguage models. Participants are invited to develop novel evaluation\nmethodologies or adapt existing benchmarks to better capture performance\ndifferences among language models. To support this effort, we provide three\npre-trained small models (0.5B, 1B, and 3B parameters), along with intermediate\ncheckpoints sampled during training up to 200B tokens. All experiments and\ndevelopment work can be run on widely available free cloud-based GPU platforms,\nmaking participation accessible to researchers with limited computational\nresources. Submissions will be evaluated based on three criteria: the quality\nof the performance signal they produce, the consistency of model rankings at 1\ntrillion tokens of training, and their relevance to the scientific knowledge\ndomain. By promoting the design of tailored evaluation strategies for early\ntraining, this competition aims to attract a broad range of participants from\nvarious disciplines, including those who may not be machine learning experts or\nhave access to dedicated GPU resources. Ultimately, this initiative seeks to\nmake foundational LLM research more systematic and benchmark-informed from the\nearliest phases of model development.", "published": "2025-06-09 13:15:50", "link": "http://arxiv.org/abs/2506.07731v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "ETA: Efficiency through Thinking Ahead, A Dual Approach to Self-Driving with Large Models", "abstract": "How can we benefit from large models without sacrificing inference speed, a\ncommon dilemma in self-driving systems? A prevalent solution is a dual-system\narchitecture, employing a small model for rapid, reactive decisions and a\nlarger model for slower but more informative analyses. Existing dual-system\ndesigns often implement parallel architectures where inference is either\ndirectly conducted using the large model at each current frame or retrieved\nfrom previously stored inference results. However, these works still struggle\nto enable large models for a timely response to every online frame. Our key\ninsight is to shift intensive computations of the current frame to previous\ntime steps and perform a batch inference of multiple time steps to make large\nmodels respond promptly to each time step. To achieve the shifting, we\nintroduce Efficiency through Thinking Ahead (ETA), an asynchronous system\ndesigned to: (1) propagate informative features from the past to the current\nframe using future predictions from the large model, (2) extract current frame\nfeatures using a small model for real-time responsiveness, and (3) integrate\nthese dual features via an action mask mechanism that emphasizes\naction-critical image regions. Evaluated on the Bench2Drive CARLA\nLeaderboard-v2 benchmark, ETA advances state-of-the-art performance by 8% with\na driving score of 69.53 while maintaining a near-real-time inference speed at\n50 ms.", "published": "2025-06-09 13:11:02", "link": "http://arxiv.org/abs/2506.07725v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Consistent Video Editing as Flow-Driven Image-to-Video Generation", "abstract": "With the prosper of video diffusion models, down-stream applications like\nvideo editing have been significantly promoted without consuming much\ncomputational cost. One particular challenge in this task lies at the motion\ntransfer process from the source video to the edited one, where it requires the\nconsideration of the shape deformation in between, meanwhile maintaining the\ntemporal consistency in the generated video sequence. However, existing methods\nfail to model complicated motion patterns for video editing, and are\nfundamentally limited to object replacement, where tasks with non-rigid object\nmotions like multi-object and portrait editing are largely neglected. In this\npaper, we observe that optical flows offer a promising alternative in complex\nmotion modeling, and present FlowV2V to re-investigate video editing as a task\nof flow-driven Image-to-Video (I2V) generation. Specifically, FlowV2V\ndecomposes the entire pipeline into first-frame editing and conditional I2V\ngeneration, and simulates pseudo flow sequence that aligns with the deformed\nshape, thus ensuring the consistency during editing. Experimental results on\nDAVIS-EDIT with improvements of 13.67% and 50.66% on DOVER and warping error\nillustrate the superior temporal consistency and sample quality of FlowV2V\ncompared to existing state-of-the-art ones. Furthermore, we conduct\ncomprehensive ablation studies to analyze the internal functionalities of the\nfirst-frame paradigm and flow alignment in the proposed method.", "published": "2025-06-09 12:57:30", "link": "http://arxiv.org/abs/2506.07713v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "NOVA3D: Normal Aligned Video Diffusion Model for Single Image to 3D Generation", "abstract": "3D AI-generated content (AIGC) has made it increasingly accessible for anyone\nto become a 3D content creator. While recent methods leverage Score\nDistillation Sampling to distill 3D objects from pretrained image diffusion\nmodels, they often suffer from inadequate 3D priors, leading to insufficient\nmulti-view consistency. In this work, we introduce NOVA3D, an innovative\nsingle-image-to-3D generation framework. Our key insight lies in leveraging\nstrong 3D priors from a pretrained video diffusion model and integrating\ngeometric information during multi-view video fine-tuning. To facilitate\ninformation exchange between color and geometric domains, we propose the\nGeometry-Temporal Alignment (GTA) attention mechanism, thereby improving\ngeneralization and multi-view consistency. Moreover, we introduce the\nde-conflict geometry fusion algorithm, which improves texture fidelity by\naddressing multi-view inaccuracies and resolving discrepancies in pose\nalignment. Extensive experiments validate the superiority of NOVA3D over\nexisting baselines.", "published": "2025-06-09 12:37:46", "link": "http://arxiv.org/abs/2506.07698v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "MCPWorld: A Unified Benchmarking Testbed for API, GUI, and Hybrid Computer Use Agents", "abstract": "(M)LLM-powered computer use agents (CUA) are emerging as a transformative\ntechnique to automate human-computer interaction. However, existing CUA\nbenchmarks predominantly target GUI agents, whose evaluation methods are\nsusceptible to UI changes and ignore function interactions exposed by\napplication APIs, e.g., Model Context Protocol (MCP). To this end, we propose\nMCPWorld, the first automatic CUA testbed for API, GUI, and API-GUI hybrid\nagents. A key principle of MCPWorld is the use of \"white-box apps\", i.e., those\nwith source code availability and can be revised/re-compiled as needed (e.g.,\nadding MCP support), with two notable advantages:\n  (1) It greatly broadens the design space of CUA, such as what and how the app\nfeatures to be exposed/extracted as CUA-callable APIs.\n  (2) It allows MCPWorld to programmatically verify task completion by directly\nmonitoring application behavior through techniques like dynamic code\ninstrumentation, offering robust, accurate CUA evaluation decoupled from\nspecific agent implementations or UI states.\n  Currently, MCPWorld includes 201 well curated and annotated user tasks,\ncovering diversified use cases and difficulty levels. MCPWorld is also fully\ncontainerized with GPU acceleration support for flexible adoption on different\nOS/hardware environments. Our preliminary experiments, using a representative\nLLM-powered CUA framework, achieve 75.12% task completion accuracy,\nsimultaneously providing initial evidence on the practical effectiveness of\nagent automation leveraging MCP. Overall, we anticipate MCPWorld to facilitate\nand standardize the benchmarking of next-generation computer use agents that\ncan leverage rich external tools. Our code and dataset are publicly available\nat https://github.com/SAAgent/MCPWorld.", "published": "2025-06-09 11:50:33", "link": "http://arxiv.org/abs/2506.07672v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "FMaMIL: Frequency-Driven Mamba Multi-Instance Learning for Weakly Supervised Lesion Segmentation in Medical Images", "abstract": "Accurate lesion segmentation in histopathology images is essential for\ndiagnostic interpretation and quantitative analysis, yet it remains challenging\ndue to the limited availability of costly pixel-level annotations. To address\nthis, we propose FMaMIL, a novel two-stage framework for weakly supervised\nlesion segmentation based solely on image-level labels. In the first stage, a\nlightweight Mamba-based encoder is introduced to capture long-range\ndependencies across image patches under the MIL paradigm. To enhance spatial\nsensitivity and structural awareness, we design a learnable frequency-domain\nencoding module that supplements spatial-domain features with spectrum-based\ninformation. CAMs generated in this stage are used to guide segmentation\ntraining. In the second stage, we refine the initial pseudo labels via a\nCAM-guided soft-label supervision and a self-correction mechanism, enabling\nrobust training even under label noise. Extensive experiments on both public\nand private histopathology datasets demonstrate that FMaMIL outperforms\nstate-of-the-art weakly supervised methods without relying on pixel-level\nannotations, validating its effectiveness and potential for digital pathology\napplications.", "published": "2025-06-09 11:18:02", "link": "http://arxiv.org/abs/2506.07652v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "SWE-Dev: Building Software Engineering Agents with Training and Inference Scaling", "abstract": "Large language models (LLMs) have advanced rapidly from conversational\nproblem solving to addressing real-world tasks involving tool use, such as\nsoftware engineering (SWE). Recent LLM-powered toolkits, such as OpenAI Codex\nand Cursor, have offered end-to-end automation of the software development\nprocess. However, building effective SWE agents remains challenging due to the\nlack of high-quality training data and effective test cases. To address this\nissue, we present SWE-Dev, an SWE agent built upon open-source LLMs. First, we\ndevelop a robust pipeline to synthesize test cases for patch evaluation.\nSecond, we scale up agent trajectories to construct the training data for\nbuilding SWE-Dev. Experiments on the SWE-bench-Verified benchmark show that the\nSWE-Dev models can achieve top performance among all open SWE agents.\nSpecifically, the success rates of the SWE-Dev 7B and 32B parameter models\nreach 23.4% and 36.6%, respectively, outperforming state-of-the-art open-source\nmodels. All code, models, and datasets are publicly available at\nhttps://github.com/THUDM/SWE-Dev.", "published": "2025-06-09 11:03:16", "link": "http://arxiv.org/abs/2506.07636v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "SurgBench: A Unified Large-Scale Benchmark for Surgical Video Analysis", "abstract": "Surgical video understanding is pivotal for enabling automated intraoperative\ndecision-making, skill assessment, and postoperative quality improvement.\nHowever, progress in developing surgical video foundation models (FMs) remains\nhindered by the scarcity of large-scale, diverse datasets for pretraining and\nsystematic evaluation. In this paper, we introduce \\textbf{SurgBench}, a\nunified surgical video benchmarking framework comprising a pretraining dataset,\n\\textbf{SurgBench-P}, and an evaluation benchmark, \\textbf{SurgBench-E}.\nSurgBench offers extensive coverage of diverse surgical scenarios, with\nSurgBench-P encompassing 53 million frames across 22 surgical procedures and 11\nspecialties, and SurgBench-E providing robust evaluation across six categories\n(phase classification, camera motion, tool recognition, disease diagnosis,\naction classification, and organ detection) spanning 72 fine-grained tasks.\nExtensive experiments reveal that existing video FMs struggle to generalize\nacross varied surgical video analysis tasks, whereas pretraining on SurgBench-P\nyields substantial performance improvements and superior cross-domain\ngeneralization to unseen procedures and modalities. Our dataset and code are\navailable upon request.", "published": "2025-06-09 10:02:58", "link": "http://arxiv.org/abs/2506.07603v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "SceneRAG: Scene-level Retrieval-Augmented Generation for Video Understanding", "abstract": "Despite recent advances in retrieval-augmented generation (RAG) for video\nunderstanding, effectively understanding long-form video content remains\nunderexplored due to the vast scale and high complexity of video data. Current\nRAG approaches typically segment videos into fixed-length chunks, which often\ndisrupts the continuity of contextual information and fails to capture\nauthentic scene boundaries. Inspired by the human ability to naturally organize\ncontinuous experiences into coherent scenes, we present SceneRAG, a unified\nframework that leverages large language models to segment videos into\nnarrative-consistent scenes by processing ASR transcripts alongside temporal\nmetadata. SceneRAG further sharpens these initial boundaries through\nlightweight heuristics and iterative correction. For each scene, the framework\nfuses information from both visual and textual modalities to extract entity\nrelations and dynamically builds a knowledge graph, enabling robust multi-hop\nretrieval and generation that account for long-range dependencies. Experiments\non the LongerVideos benchmark, featuring over 134 hours of diverse content,\nconfirm that SceneRAG substantially outperforms prior baselines, achieving a\nwin rate of up to 72.5 percent on generation tasks.", "published": "2025-06-09 10:00:54", "link": "http://arxiv.org/abs/2506.07600v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Automating Exploratory Multiomics Research via Language Models", "abstract": "This paper introduces PROTEUS, a fully automated system that produces\ndata-driven hypotheses from raw data files. We apply PROTEUS to clinical\nproteogenomics, a field where effective downstream data analysis and hypothesis\nproposal is crucial for producing novel discoveries. PROTEUS uses separate\nmodules to simulate different stages of the scientific process, from open-ended\ndata exploration to specific statistical analysis and hypothesis proposal. It\nformulates research directions, tools, and results in terms of relationships\nbetween biological entities, using unified graph structures to manage complex\nresearch processes. We applied PROTEUS to 10 clinical multiomics datasets from\npublished research, arriving at 360 total hypotheses. Results were evaluated\nthrough external data validation and automatic open-ended scoring. Through\nexploratory and iterative research, the system can navigate high-throughput and\nheterogeneous multiomics data to arrive at hypotheses that balance reliability\nand novelty. In addition to accelerating multiomic analysis, PROTEUS represents\na path towards tailoring general autonomous systems to specialized scientific\ndomains to achieve open-ended hypothesis generation from data.", "published": "2025-06-09 09:44:21", "link": "http://arxiv.org/abs/2506.07591v1", "categories": ["cs.AI", "q-bio.QM"], "primary_category": "cs.AI"}
{"title": "PrunePEFT: Iterative Hybrid Pruning for Parameter-Efficient Fine-tuning of LLMs", "abstract": "Parameter Efficient Fine-Tuning (PEFT) methods have emerged as effective and\npromising approaches for fine-tuning pre-trained language models. Compared with\nFull parameter Fine-Tuning (FFT), PEFT achieved comparable task performance\nwith a substantial reduction of trainable parameters, which largely saved the\ntraining and storage costs. However, using the PEFT method requires considering\na vast design space, such as the type of PEFT modules and their insertion\nlayers. Inadequate configurations can lead to sub-optimal results. Conventional\nsolutions such as architectural search techniques, while effective, tend to\nintroduce substantial additional overhead. In this paper, we propose a novel\napproach, PrunePEFT, which formulates the PEFT strategy search as a pruning\nproblem and introduces a hybrid pruning strategy that capitalizes on the\nsensitivity of pruning methods to different PEFT modules. This method extends\ntraditional pruning techniques by iteratively removing redundant or conflicting\nPEFT modules, thereby optimizing the fine-tuned configuration. By efficiently\nidentifying the most relevant modules, our approach significantly reduces the\ncomputational burden typically associated with architectural search processes,\nmaking it a more scalable and efficient solution for fine-tuning large\npre-trained models.", "published": "2025-06-09 09:32:58", "link": "http://arxiv.org/abs/2506.07587v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "FedCGD: Collective Gradient Divergence Optimized Scheduling for Wireless Federated Learning", "abstract": "Federated learning (FL) is a promising paradigm for multiple devices to\ncooperatively train a model. When applied in wireless networks, two issues\nconsistently affect the performance of FL, i.e., data heterogeneity of devices\nand limited bandwidth. Many papers have investigated device scheduling\nstrategies considering the two issues. However, most of them recognize data\nheterogeneity as a property of individual devices. In this paper, we prove that\nthe convergence speed of FL is affected by the sum of device-level and\nsample-level collective gradient divergence (CGD). The device-level CGD refers\nto the gradient divergence of the scheduled device group, instead of the sum of\nthe individual device divergence. The sample-level CGD is statistically upper\nbounded by sampling variance, which is inversely proportional to the total\nnumber of samples scheduled for local update. To derive a tractable form of the\ndevice-level CGD, we further consider a classification problem and transform it\ninto the weighted earth moving distance (WEMD) between the group distribution\nand the global distribution. Then we propose FedCGD algorithm to minimize the\nsum of multi-level CGDs by balancing WEMD and sampling variance, within\npolynomial time. Simulation shows that the proposed strategy increases\nclassification accuracy on the CIFAR-10 dataset by up to 4.2\\% while scheduling\n41.8\\% fewer devices, and flexibly switches between reducing WEMD and reducing\nsampling variance.", "published": "2025-06-09 09:24:33", "link": "http://arxiv.org/abs/2506.07581v1", "categories": ["cs.LG", "cs.AI", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Denoising the Future: Top-p Distributions for Moving Through Time", "abstract": "Inference in dynamic probabilistic models is a complex task involving\nexpensive operations. In particular, for Hidden Markov Models, the whole state\nspace has to be enumerated for advancing in time. Even states with negligible\nprobabilities are considered, resulting in computational inefficiency and\nincreased noise due to the propagation of unlikely probability mass. We propose\nto denoise the future and speed up inference by using only the top-p states,\ni.e., the most probable states with accumulated probability p. We show that the\nerror introduced by using only the top-p states is bound by p and the so-called\nminimal mixing rate of the underlying model. Moreover, in our empirical\nevaluation, we show that we can expect speedups of at least an order of\nmagnitude, while the error in terms of total variation distance is below 0.09.", "published": "2025-06-09 09:23:09", "link": "http://arxiv.org/abs/2506.07578v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "LLM-driven Indoor Scene Layout Generation via Scaled Human-aligned Data Synthesis and Multi-Stage Preference Optimization", "abstract": "Automatic indoor layout generation has attracted increasing attention due to\nits potential in interior design, virtual environment construction, and\nembodied AI. Existing methods fall into two categories: prompt-driven\napproaches that leverage proprietary LLM services (e.g., GPT APIs) and\nlearning-based methods trained on layout data upon diffusion-based models.\nPrompt-driven methods often suffer from spatial inconsistency and high\ncomputational costs, while learning-based methods are typically constrained by\ncoarse relational graphs and limited datasets, restricting their generalization\nto diverse room categories. In this paper, we revisit LLM-based indoor layout\ngeneration and present 3D-SynthPlace, a large-scale dataset that combines\nsynthetic layouts generated via a 'GPT synthesize, Human inspect' pipeline,\nupgraded from the 3D-Front dataset. 3D-SynthPlace contains nearly 17,000\nscenes, covering four common room types -- bedroom, living room, kitchen, and\nbathroom -- enriched with diverse objects and high-level spatial annotations.\nWe further introduce OptiScene, a strong open-source LLM optimized for indoor\nlayout generation, fine-tuned based on our 3D-SynthPlace dataset through our\ntwo-stage training. For the warum-up stage I, we adopt supervised fine-tuning\n(SFT), which is taught to first generate high-level spatial descriptions then\nconditionally predict concrete object placements. For the reinforcing stage II,\nto better align the generated layouts with human design preferences, we apply\nmulti-turn direct preference optimization (DPO), which significantly improving\nlayout quality and generation success rates. Extensive experiments demonstrate\nthat OptiScene outperforms traditional prompt-driven and learning-based\nbaselines. Moreover, OptiScene shows promising potential in interactive tasks\nsuch as scene editing and robot navigation.", "published": "2025-06-09 09:13:06", "link": "http://arxiv.org/abs/2506.07570v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "MoE-MLoRA for Multi-Domain CTR Prediction: Efficient Adaptation with Expert Specialization", "abstract": "Personalized recommendation systems must adapt to user interactions across\ndifferent domains. Traditional approaches like MLoRA apply a single adaptation\nper domain but lack flexibility in handling diverse user behaviors. To address\nthis, we propose MoE-MLoRA, a mixture-of-experts framework where each expert is\nfirst trained independently to specialize in its domain before a gating network\nis trained to weight their contributions dynamically. We evaluate MoE-MLoRA\nacross eight CTR models on Movielens and Taobao, showing that it improves\nperformance in large-scale, dynamic datasets (+1.45 Weighed-AUC in Taobao-20)\nbut offers limited benefits in structured datasets with low domain diversity\nand sparsity. Further analysis of the number of experts per domain reveals that\nlarger ensembles do not always improve performance, indicating the need for\nmodel-aware tuning. Our findings highlight the potential of expert-based\narchitectures for multi-domain recommendation systems, demonstrating that\ntask-aware specialization and adaptive gating can enhance predictive accuracy\nin complex environments. The implementation and code are available in our\nGitHub repository.", "published": "2025-06-09 09:03:05", "link": "http://arxiv.org/abs/2506.07563v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Synthesize Privacy-Preserving High-Resolution Images via Private Textual Intermediaries", "abstract": "Generating high fidelity, differentially private (DP) synthetic images offers\na promising route to share and analyze sensitive visual data without\ncompromising individual privacy. However, existing DP image synthesis methods\nstruggle to produce high resolution outputs that faithfully capture the\nstructure of the original data. In this paper, we introduce a novel method,\nreferred to as Synthesis via Private Textual Intermediaries (SPTI), that can\ngenerate high resolution DP images with easy adoption. The key idea is to shift\nthe challenge of DP image synthesis from the image domain to the text domain by\nleveraging state of the art DP text generation methods. SPTI first summarizes\neach private image into a concise textual description using image to text\nmodels, then applies a modified Private Evolution algorithm to generate DP\ntext, and finally reconstructs images using text to image models. Notably, SPTI\nrequires no model training, only inference with off the shelf models. Given a\nprivate dataset, SPTI produces synthetic images of substantially higher quality\nthan prior DP approaches. On the LSUN Bedroom dataset, SPTI attains an FID less\nthan or equal to 26.71 under epsilon equal to 1.0, improving over Private\nEvolution FID of 40.36. Similarly, on MM CelebA HQ, SPTI achieves an FID less\nthan or equal to 33.27 at epsilon equal to 1.0, compared to 57.01 from DP fine\ntuning baselines. Overall, our results demonstrate that Synthesis via Private\nTextual Intermediaries provides a resource efficient and proprietary model\ncompatible framework for generating high resolution DP synthetic images,\ngreatly expanding access to private visual datasets.", "published": "2025-06-09 08:48:06", "link": "http://arxiv.org/abs/2506.07555v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "GTR-CoT: Graph Traversal as Visual Chain of Thought for Molecular Structure Recognition", "abstract": "Optical Chemical Structure Recognition (OCSR) is crucial for digitizing\nchemical knowledge by converting molecular images into machine-readable\nformats. While recent vision-language models (VLMs) have shown potential in\nthis task, their image-captioning approach often struggles with complex\nmolecular structures and inconsistent annotations. To overcome these\nchallenges, we introduce GTR-Mol-VLM, a novel framework featuring two key\ninnovations: (1) the \\textit{Graph Traversal as Visual Chain of Thought}\nmechanism that emulates human reasoning by incrementally parsing molecular\ngraphs through sequential atom-bond predictions, and (2) the data-centric\nprinciple of \\textit{Faithfully Recognize What You've Seen}, which addresses\nthe mismatch between abbreviated structures in images and their expanded\nannotations. To support model development, we constructed GTR-CoT-1.3M, a\nlarge-scale instruction-tuning dataset with meticulously corrected annotations,\nand introduced MolRec-Bench, the first benchmark designed for a fine-grained\nevaluation of graph-parsing accuracy in OCSR. Comprehensive experiments\ndemonstrate that GTR-Mol-VLM achieves superior results compared to specialist\nmodels, chemistry-domain VLMs, and commercial general-purpose VLMs. Notably, in\nscenarios involving molecular images with functional group abbreviations,\nGTR-Mol-VLM outperforms the second-best baseline by approximately 14 percentage\npoints, both in SMILES-based and graph-based metrics. We hope that this work\nwill drive OCSR technology to more effectively meet real-world needs, thereby\nadvancing the fields of cheminformatics and AI for Science. We will release\nGTR-CoT at https://github.com/opendatalab/GTR-CoT.", "published": "2025-06-09 08:47:10", "link": "http://arxiv.org/abs/2506.07553v1", "categories": ["cs.AI", "q-bio.QM"], "primary_category": "cs.AI"}
{"title": "Curriculum Learning With Counterfactual Group Relative Policy Advantage For Multi-Agent Reinforcement Learning", "abstract": "Multi-agent reinforcement learning (MARL) has achieved strong performance in\ncooperative adversarial tasks. However, most existing methods typically train\nagents against fixed opponent strategies and rely on such meta-static\ndifficulty conditions, which limits their adaptability to changing environments\nand often leads to suboptimal policies. Inspired by the success of curriculum\nlearning (CL) in supervised tasks, we propose a dynamic CL framework for MARL\nthat employs an self-adaptive difficulty adjustment mechanism. This mechanism\ncontinuously modulates opponent strength based on real-time agent training\nperformance, allowing agents to progressively learn from easier to more\nchallenging scenarios. However, the dynamic nature of CL introduces instability\ndue to nonstationary environments and sparse global rewards. To address this\nchallenge, we develop a Counterfactual Group Relative Policy Advantage (CGRPA),\nwhich is tightly coupled with the curriculum by providing intrinsic credit\nsignals that reflect each agent's impact under evolving task demands. CGRPA\nconstructs a counterfactual advantage function that isolates individual\ncontributions within group behavior, facilitating more reliable policy updates\nthroughout the curriculum. CGRPA evaluates each agent's contribution through\nconstructing counterfactual action advantage function, providing intrinsic\nrewards that enhance credit assignment and stabilize learning under\nnon-stationary conditions. Extensive experiments demonstrate that our method\nimproves both training stability and final performance, achieving competitive\nresults against state-of-the-art methods. The code is available at\nhttps://github.com/NICE-HKU/CL2MARL-SMAC.", "published": "2025-06-09 08:38:18", "link": "http://arxiv.org/abs/2506.07548v1", "categories": ["cs.AI", "cs.RO"], "primary_category": "cs.AI"}
{"title": "APTOS-2024 challenge report: Generation of synthetic 3D OCT images from fundus photographs", "abstract": "Optical Coherence Tomography (OCT) provides high-resolution, 3D, and\nnon-invasive visualization of retinal layers in vivo, serving as a critical\ntool for lesion localization and disease diagnosis. However, its widespread\nadoption is limited by equipment costs and the need for specialized operators.\nIn comparison, 2D color fundus photography offers faster acquisition and\ngreater accessibility with less dependence on expensive devices. Although\ngenerative artificial intelligence has demonstrated promising results in\nmedical image synthesis, translating 2D fundus images into 3D OCT images\npresents unique challenges due to inherent differences in data dimensionality\nand biological information between modalities. To advance generative models in\nthe fundus-to-3D-OCT setting, the Asia Pacific Tele-Ophthalmology Society\n(APTOS-2024) organized a challenge titled Artificial Intelligence-based OCT\nGeneration from Fundus Images. This paper details the challenge framework\n(referred to as APTOS-2024 Challenge), including: the benchmark dataset,\nevaluation methodology featuring two fidelity metrics-image-based distance\n(pixel-level OCT B-scan similarity) and video-based distance (semantic-level\nvolumetric consistency), and analysis of top-performing solutions. The\nchallenge attracted 342 participating teams, with 42 preliminary submissions\nand 9 finalists. Leading methodologies incorporated innovations in hybrid data\npreprocessing or augmentation (cross-modality collaborative paradigms),\npre-training on external ophthalmic imaging datasets, integration of vision\nfoundation models, and model architecture improvement. The APTOS-2024 Challenge\nis the first benchmark demonstrating the feasibility of fundus-to-3D-OCT\nsynthesis as a potential solution for improving ophthalmic care accessibility\nin under-resourced healthcare settings, while helping to expedite medical\nresearch and clinical applications.", "published": "2025-06-09 08:29:37", "link": "http://arxiv.org/abs/2506.07542v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Domain Randomization for Object Detection in Manufacturing Applications using Synthetic Data: A Comprehensive Study", "abstract": "This paper addresses key aspects of domain randomization in generating\nsynthetic data for manufacturing object detection applications. To this end, we\npresent a comprehensive data generation pipeline that reflects different\nfactors: object characteristics, background, illumination, camera settings, and\npost-processing. We also introduce the Synthetic Industrial Parts Object\nDetection dataset (SIP15-OD) consisting of 15 objects from three industrial use\ncases under varying environments as a test bed for the study, while also\nemploying an industrial dataset publicly available for robotic applications. In\nour experiments, we present more abundant results and insights into the\nfeasibility as well as challenges of sim-to-real object detection. In\nparticular, we identified material properties, rendering methods,\npost-processing, and distractors as important factors. Our method, leveraging\nthese, achieves top performance on the public dataset with Yolov8 models\ntrained exclusively on synthetic data; mAP@50 scores of 96.4% for the robotics\ndataset, and 94.1%, 99.5%, and 95.3% across three of the SIP15-OD use cases,\nrespectively. The results showcase the effectiveness of the proposed domain\nrandomization, potentially covering the distribution close to real data for the\napplications.", "published": "2025-06-09 08:26:19", "link": "http://arxiv.org/abs/2506.07539v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Coordinating Search-Informed Reasoning and Reasoning-Guided Search in Claim Verification", "abstract": "Multi-hop claim verification is inherently challenging, requiring multi-step\nreasoning to construct verification chains while iteratively searching for\ninformation to uncover hidden bridging facts. This process is fundamentally\ninterleaved, as effective reasoning relies on dynamically retrieved evidence,\nwhile effective search demands reasoning to refine queries based on partial\ninformation. To achieve this, we propose Hierarchical Agent Reasoning and\nInformation Search (HARIS), explicitly modeling the coordinated process of\nreasoning-driven searching and search-informed reasoning. HARIS consists of a\nhigh-level reasoning agent that focuses on constructing the main verification\nchain, generating factual questions when more information is needed, and a\nlow-level search agent that iteratively retrieves more information, refining\nits search based on intermediate findings. This design allows each agent to\nspecialize in its respective task, enhancing verification accuracy and\ninterpretability. HARIS is trained using reinforcement learning with\noutcome-based rewards. Experimental results on the EX-FEVER and HOVER\nbenchmarks demonstrate that HARIS achieves strong performance, greatly\nadvancing multi-hop claim verification.", "published": "2025-06-09 08:11:43", "link": "http://arxiv.org/abs/2506.07528v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Learning What Reinforcement Learning Can't: Interleaved Online Fine-Tuning for Hardest Questions", "abstract": "Recent advances in large language model (LLM) reasoning have shown that\nsophisticated behaviors such as planning and self-reflection can emerge through\nreinforcement learning (RL). However, despite these successes, RL in its\ncurrent form remains insufficient to induce capabilities that exceed the\nlimitations of the base model, as it is primarily optimized based on existing\nknowledge of the model rather than facilitating the acquisition of new\ninformation. To address this limitation, we employ supervised fine-tuning (SFT)\nto learn what RL cannot, which enables the incorporation of new knowledge and\nreasoning patterns by leveraging high-quality demonstration data. We analyze\nthe training dynamics of RL and SFT for LLM reasoning and find that RL excels\nat maintaining and improving performance on questions within the model's\noriginal capabilities, while SFT is more effective at enabling progress on\nquestions beyond the current scope of the model. Motivated by the complementary\nstrengths of RL and SFT, we introduce a novel training approach,\n\\textbf{ReLIFT} (\\textbf{Re}inforcement \\textbf{L}earning \\textbf{I}nterleaved\nwith Online \\textbf{F}ine-\\textbf{T}uning). In ReLIFT, the model is primarily\ntrained using RL, but when it encounters challenging questions, high-quality\nsolutions are collected for fine-tuning, and the training process alternates\nbetween RL and fine-tuning to enhance the model's reasoning abilities. ReLIFT\nachieves an average improvement of over +5.2 points across five\ncompetition-level benchmarks and one out-of-distribution benchmark compared to\nother zero-RL models. Furthermore, we demonstrate that ReLIFT outperforms both\nRL and SFT while using only 13\\% of the detailed demonstration data,\nhighlighting its scalability. These results provide compelling evidence that\nReLIFT overcomes the fundamental limitations of RL and underscores the\nsignificant potential.", "published": "2025-06-09 08:11:20", "link": "http://arxiv.org/abs/2506.07527v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "IntenTest: Stress Testing for Intent Integrity in API-Calling LLM Agents", "abstract": "LLM agents are increasingly deployed to automate real-world tasks by invoking\nAPIs through natural language instructions. While powerful, they often suffer\nfrom misinterpretation of user intent, leading to the agent's actions that\ndiverge from the user's intended goal, especially as external toolkits evolve.\nTraditional software testing assumes structured inputs and thus falls short in\nhandling the ambiguity of natural language. We introduce IntenTest, an\nAPI-centric stress testing framework that systematically uncovers intent\nintegrity violations in LLM agents. Unlike prior work focused on fixed\nbenchmarks or adversarial inputs, IntenTest generates realistic tasks based on\ntoolkits' documentation and applies targeted mutations to expose subtle agent\nerrors while preserving user intent. To guide testing, we propose semantic\npartitioning, which organizes natural language tasks into meaningful categories\nbased on toolkit API parameters and their equivalence classes. Within each\npartition, seed tasks are mutated and ranked by a lightweight predictor that\nestimates the likelihood of triggering agent errors. To enhance efficiency,\nIntenTest maintains a datatype-aware strategy memory that retrieves and adapts\neffective mutation patterns from past cases. Experiments on 80 toolkit APIs\ndemonstrate that IntenTest effectively uncovers intent integrity violations,\nsignificantly outperforming baselines in both error-exposing rate and query\nefficiency. Moreover, IntenTest generalizes well to stronger target models\nusing smaller LLMs for test generation, and adapts to evolving APIs across\ndomains.", "published": "2025-06-09 08:09:08", "link": "http://arxiv.org/abs/2506.07524v1", "categories": ["cs.SE", "cs.AI", "cs.CY"], "primary_category": "cs.SE"}
{"title": "LeVo: High-Quality Song Generation with Multi-Preference Alignment", "abstract": "Recent advances in large language models (LLMs) and audio language models\nhave significantly improved music generation, particularly in lyrics-to-song\ngeneration. However, existing approaches still struggle with the complex\ncomposition of songs and the scarcity of high-quality data, leading to\nlimitations in sound quality, musicality, instruction following, and\nvocal-instrument harmony. To address these challenges, we introduce LeVo, an\nLM-based framework consisting of LeLM and a music codec. LeLM is capable of\nparallelly modeling two types of tokens: mixed tokens, which represent the\ncombined audio of vocals and accompaniment to achieve vocal-instrument harmony,\nand dual-track tokens, which separately encode vocals and accompaniment for\nhigh-quality song generation. It employs two decoder-only transformers and a\nmodular extension training strategy to prevent interference between different\ntoken types. To further enhance musicality and instruction following, we\nintroduce a multi-preference alignment method based on Direct Preference\nOptimization (DPO). This method handles diverse human preferences through a\nsemi-automatic data construction process and DPO post-training. Experimental\nresults demonstrate that LeVo consistently outperforms existing methods on both\nobjective and subjective metrics. Ablation studies further justify the\neffectiveness of our designs. Audio examples are available at\nhttps://levo-demo.github.io/.", "published": "2025-06-09 07:57:24", "link": "http://arxiv.org/abs/2506.07520v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Reinforcement Learning via Implicit Imitation Guidance", "abstract": "We study the problem of sample efficient reinforcement learning, where prior\ndata such as demonstrations are provided for initialization in lieu of a dense\nreward signal. A natural approach is to incorporate an imitation learning\nobjective, either as regularization during training or to acquire a reference\npolicy. However, imitation learning objectives can ultimately degrade long-term\nperformance, as it does not directly align with reward maximization. In this\nwork, we propose to use prior data solely for guiding exploration via noise\nadded to the policy, sidestepping the need for explicit behavior cloning\nconstraints. The key insight in our framework, Data-Guided Noise (DGN), is that\ndemonstrations are most useful for identifying which actions should be\nexplored, rather than forcing the policy to take certain actions. Our approach\nachieves up to 2-3x improvement over prior reinforcement learning from offline\ndata methods across seven simulated continuous control tasks.", "published": "2025-06-09 07:32:52", "link": "http://arxiv.org/abs/2506.07505v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "CoCoA-Mix: Confusion-and-Confidence-Aware Mixture Model for Context Optimization", "abstract": "Prompt tuning, which adapts vision-language models by freezing model\nparameters and optimizing only the prompt, has proven effective for\ntask-specific adaptations. The core challenge in prompt tuning is improving\nspecialization for a specific task and generalization for unseen domains.\nHowever, frozen encoders often produce misaligned features, leading to\nconfusion between classes and limiting specialization. To overcome this issue,\nwe propose a confusion-aware loss (CoA-loss) that improves specialization by\nrefining the decision boundaries between confusing classes. Additionally, we\nmathematically demonstrate that a mixture model can enhance generalization\nwithout compromising specialization. This is achieved using confidence-aware\nweights (CoA-weights), which adjust the weights of each prediction in the\nmixture model based on its confidence within the class domains. Extensive\nexperiments show that CoCoA-Mix, a mixture model with CoA-loss and CoA-weights,\noutperforms state-of-the-art methods by enhancing specialization and\ngeneralization. Our code is publicly available at\nhttps://github.com/url-kaist/CoCoA-Mix.", "published": "2025-06-09 07:04:47", "link": "http://arxiv.org/abs/2506.07484v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "I.2.6; I.5.2"], "primary_category": "cs.CV"}
{"title": "Premise Selection for a Lean Hammer", "abstract": "Neural methods are transforming automated reasoning for proof assistants, yet\nintegrating these advances into practical verification workflows remains\nchallenging. Hammers are tools that interface with external automatic theorem\nprovers to automate tedious reasoning steps. They have dramatically improved\nproductivity in proof assistants, but the Lean proof assistant still does not\nhave a hammer despite its growing popularity. We present LeanHammer, the first\nend-to-end domain-general hammer for Lean, built on a novel neural premise\nselection system for a hammer in dependent type theory. Unlike existing Lean\npremise selectors, our approach dynamically adapts to user-specific contexts\nand combines with symbolic proof search and reconstruction to create a\npractical hammer. With comprehensive evaluations, we show that our premise\nselector enables LeanHammer to solve 21\\% more goals relative to existing\npremise selectors, and generalize well to diverse domains. Our work bridges the\ngap between neural retrieval and symbolic reasoning, making formal verification\nmore accessible to researchers and practitioners.", "published": "2025-06-09 06:50:59", "link": "http://arxiv.org/abs/2506.07477v1", "categories": ["cs.LG", "cs.AI", "cs.LO"], "primary_category": "cs.LG"}
{"title": "Ambiguity-Restrained Text-Video Representation Learning for Partially Relevant Video Retrieval", "abstract": "Partially Relevant Video Retrieval~(PRVR) aims to retrieve a video where a\nspecific segment is relevant to a given text query. Typical training processes\nof PRVR assume a one-to-one relationship where each text query is relevant to\nonly one video. However, we point out the inherent ambiguity between text and\nvideo content based on their conceptual scope and propose a framework that\nincorporates this ambiguity into the model learning process. Specifically, we\npropose Ambiguity-Restrained representation Learning~(ARL) to address ambiguous\ntext-video pairs. Initially, ARL detects ambiguous pairs based on two criteria:\nuncertainty and similarity. Uncertainty represents whether instances include\ncommonly shared context across the dataset, while similarity indicates\npair-wise semantic overlap. Then, with the detected ambiguous pairs, our ARL\nhierarchically learns the semantic relationship via multi-positive contrastive\nlearning and dual triplet margin loss. Additionally, we delve into fine-grained\nrelationships within the video instances. Unlike typical training at the\ntext-video level, where pairwise information is provided, we address the\ninherent ambiguity within frames of the same untrimmed video, which often\ncontains multiple contexts. This allows us to further enhance learning at the\ntext-frame level. Lastly, we propose cross-model ambiguity detection to\nmitigate the error propagation that occurs when a single model is employed to\ndetect ambiguous pairs for its training. With all components combined, our\nproposed method demonstrates its effectiveness in PRVR.", "published": "2025-06-09 06:44:45", "link": "http://arxiv.org/abs/2506.07471v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "DeepVideo-R1: Video Reinforcement Fine-Tuning via Difficulty-aware Regressive GRPO", "abstract": "Recent works have demonstrated the effectiveness of reinforcement learning\n(RL)-based post-training in enhancing the reasoning capabilities of large\nlanguage models (LLMs). In particular, Group Relative Policy Optimization\n(GRPO) has shown impressive success by employing a PPO-style reinforcement\nalgorithm with group-based normalized rewards. However, the application of GRPO\nto Video Large Language Models (Video LLMs) has been less studied. In this\npaper, we explore GRPO for video LLMs and identify two primary issues that\nimpede its effective learning: (1) reliance on safeguards, and (2) the\nvanishing advantage problem. To mitigate these challenges, we propose\nDeepVideo-R1, a video large language model trained with our proposed Reg-GRPO\n(Regressive GRPO) and difficulty-aware data augmentation strategy. Reg-GRPO\nreformulates the GRPO objective as a regression task, directly predicting the\nadvantage in GRPO. This design eliminates the need for safeguards like clipping\nand min functions, thereby facilitating more direct policy guidance by aligning\nthe model with the advantage values. We also design the difficulty-aware data\naugmentation strategy that dynamically augments training samples at solvable\ndifficulty levels, fostering diverse and informative reward signals. Our\ncomprehensive experiments show that DeepVideo-R1 significantly improves video\nreasoning performance across multiple video reasoning benchmarks.", "published": "2025-06-09 06:15:54", "link": "http://arxiv.org/abs/2506.07464v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Language-Grounded Hierarchical Planning and Execution with Multi-Robot 3D Scene Graphs", "abstract": "In this paper, we introduce a multi-robot system that integrates mapping,\nlocalization, and task and motion planning (TAMP) enabled by 3D scene graphs to\nexecute complex instructions expressed in natural language. Our system builds a\nshared 3D scene graph incorporating an open-set object-based map, which is\nleveraged for multi-robot 3D scene graph fusion. This representation supports\nreal-time, view-invariant relocalization (via the object-based map) and\nplanning (via the 3D scene graph), allowing a team of robots to reason about\ntheir surroundings and execute complex tasks. Additionally, we introduce a\nplanning approach that translates operator intent into Planning Domain\nDefinition Language (PDDL) goals using a Large Language Model (LLM) by\nleveraging context from the shared 3D scene graph and robot capabilities. We\nprovide an experimental assessment of the performance of our system on\nreal-world tasks in large-scale, outdoor environments.", "published": "2025-06-09 06:02:34", "link": "http://arxiv.org/abs/2506.07454v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Efficient Generation of Diverse Cooperative Agents with World Models", "abstract": "A major bottleneck in the training process for Zero-Shot Coordination (ZSC)\nagents is the generation of partner agents that are diverse in collaborative\nconventions. Current Cross-play Minimization (XPM) methods for population\ngeneration can be very computationally expensive and sample inefficient as the\ntraining objective requires sampling multiple types of trajectories. Each\npartner agent in the population is also trained from scratch, despite all of\nthe partners in the population learning policies of the same coordination task.\nIn this work, we propose that simulated trajectories from the dynamics model of\nan environment can drastically speed up the training process for XPM methods.\nWe introduce XPM-WM, a framework for generating simulated trajectories for XPM\nvia a learned World Model (WM). We show XPM with simulated trajectories removes\nthe need to sample multiple trajectories. In addition, we show our proposed\nmethod can effectively generate partners with diverse conventions that match\nthe performance of previous methods in terms of SP population training reward\nas well as training partners for ZSC agents. Our method is thus, significantly\nmore sample efficient and scalable to a larger number of partners.", "published": "2025-06-09 05:52:45", "link": "http://arxiv.org/abs/2506.07450v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Extending Epistemic Uncertainty Beyond Parameters Would Assist in Designing Reliable LLMs", "abstract": "Although large language models (LLMs) are highly interactive and extendable,\ncurrent approaches to ensure reliability in deployments remain mostly limited\nto rejecting outputs with high uncertainty in order to avoid misinformation.\nThis conservative strategy reflects the current lack of tools to systematically\ndistinguish and respond to different sources of uncertainty. In this paper, we\nadvocate for the adoption of Bayesian Modeling of Experiments -- a framework\nthat provides a coherent foundation to reason about uncertainty and clarify the\nreducibility of uncertainty -- for managing and proactively addressing\nuncertainty that arises in LLM deployments. This framework enables LLMs and\ntheir users to take contextually appropriate steps, such as requesting\nclarification, retrieving external information, or refining inputs. By\nsupporting active resolution rather than passive avoidance, it opens the door\nto more reliable, transparent, and broadly applicable LLM systems, particularly\nin high-stakes, real-world settings.", "published": "2025-06-09 05:52:03", "link": "http://arxiv.org/abs/2506.07448v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "4DGT: Learning a 4D Gaussian Transformer Using Real-World Monocular Videos", "abstract": "We propose 4DGT, a 4D Gaussian-based Transformer model for dynamic scene\nreconstruction, trained entirely on real-world monocular posed videos. Using 4D\nGaussian as an inductive bias, 4DGT unifies static and dynamic components,\nenabling the modeling of complex, time-varying environments with varying object\nlifespans. We proposed a novel density control strategy in training, which\nenables our 4DGT to handle longer space-time input and remain efficient\nrendering at runtime. Our model processes 64 consecutive posed frames in a\nrolling-window fashion, predicting consistent 4D Gaussians in the scene. Unlike\noptimization-based methods, 4DGT performs purely feed-forward inference,\nreducing reconstruction time from hours to seconds and scaling effectively to\nlong video sequences. Trained only on large-scale monocular posed video\ndatasets, 4DGT can outperform prior Gaussian-based networks significantly in\nreal-world videos and achieve on-par accuracy with optimization-based methods\non cross-domain videos. Project page: https://4dgt.github.io", "published": "2025-06-09 17:59:59", "link": "http://arxiv.org/abs/2506.08015v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Dreamland: Controllable World Creation with Simulator and Generative Models", "abstract": "Large-scale video generative models can synthesize diverse and realistic\nvisual content for dynamic world creation, but they often lack element-wise\ncontrollability, hindering their use in editing scenes and training embodied AI\nagents. We propose Dreamland, a hybrid world generation framework combining the\ngranular control of a physics-based simulator and the photorealistic content\noutput of large-scale pretrained generative models. In particular, we design a\nlayered world abstraction that encodes both pixel-level and object-level\nsemantics and geometry as an intermediate representation to bridge the\nsimulator and the generative model. This approach enhances controllability,\nminimizes adaptation cost through early alignment with real-world\ndistributions, and supports off-the-shelf use of existing and future pretrained\ngenerative models. We further construct a D3Sim dataset to facilitate the\ntraining and evaluation of hybrid generation pipelines. Experiments demonstrate\nthat Dreamland outperforms existing baselines with 50.8% improved image\nquality, 17.9% stronger controllability, and has great potential to enhance\nembodied agent training. Code and data will be made available.", "published": "2025-06-09 17:59:52", "link": "http://arxiv.org/abs/2506.08006v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ZeroVO: Visual Odometry with Minimal Assumptions", "abstract": "We introduce ZeroVO, a novel visual odometry (VO) algorithm that achieves\nzero-shot generalization across diverse cameras and environments, overcoming\nlimitations in existing methods that depend on predefined or static camera\ncalibration setups. Our approach incorporates three main innovations. First, we\ndesign a calibration-free, geometry-aware network structure capable of handling\nnoise in estimated depth and camera parameters. Second, we introduce a\nlanguage-based prior that infuses semantic information to enhance robust\nfeature extraction and generalization to previously unseen domains. Third, we\ndevelop a flexible, semi-supervised training paradigm that iteratively adapts\nto new scenes using unlabeled data, further boosting the models' ability to\ngeneralize across diverse real-world scenarios. We analyze complex autonomous\ndriving contexts, demonstrating over 30% improvement against prior methods on\nthree standard benchmarks, KITTI, nuScenes, and Argoverse 2, as well as a newly\nintroduced, high-fidelity synthetic dataset derived from Grand Theft Auto\n(GTA). By not requiring fine-tuning or camera calibration, our work broadens\nthe applicability of VO, providing a versatile solution for real-world\ndeployment at scale.", "published": "2025-06-09 17:59:51", "link": "http://arxiv.org/abs/2506.08005v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Aligning Text, Images, and 3D Structure Token-by-Token", "abstract": "Creating machines capable of understanding the world in 3D is essential in\nassisting designers that build and edit 3D environments and robots navigating\nand interacting within a three-dimensional space. Inspired by advances in\nlanguage and image modeling, we investigate the potential of autoregressive\nmodels for a new modality: structured 3D scenes. To this end, we propose a\nunified LLM framework that aligns language, images, and 3D scenes and provide a\ndetailed ''cookbook'' outlining critical design choices for achieving optimal\ntraining and performance addressing key questions related to data\nrepresentation, modality-specific objectives, and more. We evaluate performance\nacross four core 3D tasks -- rendering, recognition, instruction-following, and\nquestion-answering -- and four 3D datasets, synthetic and real-world. We extend\nour approach to reconstruct complex 3D object shapes by enriching our 3D\nmodality with quantized shape encodings, and show our model's effectiveness on\nreal-world 3D object recognition tasks. Project webpage:\nhttps://glab-caltech.github.io/kyvo/", "published": "2025-06-09 17:59:37", "link": "http://arxiv.org/abs/2506.08002v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MADFormer: Mixed Autoregressive and Diffusion Transformers for Continuous Image Generation", "abstract": "Recent progress in multimodal generation has increasingly combined\nautoregressive (AR) and diffusion-based approaches, leveraging their\ncomplementary strengths: AR models capture long-range dependencies and produce\nfluent, context-aware outputs, while diffusion models operate in continuous\nlatent spaces to refine high-fidelity visual details. However, existing hybrids\noften lack systematic guidance on how and why to allocate model capacity\nbetween these paradigms. In this work, we introduce MADFormer, a Mixed\nAutoregressive and Diffusion Transformer that serves as a testbed for analyzing\nAR-diffusion trade-offs. MADFormer partitions image generation into spatial\nblocks, using AR layers for one-pass global conditioning across blocks and\ndiffusion layers for iterative local refinement within each block. Through\ncontrolled experiments on FFHQ-1024 and ImageNet, we identify two key insights:\n(1) block-wise partitioning significantly improves performance on\nhigh-resolution images, and (2) vertically mixing AR and diffusion layers\nyields better quality-efficiency balances--improving FID by up to 75% under\nconstrained inference compute. Our findings offer practical design principles\nfor future hybrid generative models.", "published": "2025-06-09 17:59:01", "link": "http://arxiv.org/abs/2506.07999v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Generative Modeling of Weights: Generalization or Memorization?", "abstract": "Generative models, with their success in image and video generation, have\nrecently been explored for synthesizing effective neural network weights. These\napproaches take trained neural network checkpoints as training data, and aim to\ngenerate high-performing neural network weights during inference. In this work,\nwe examine four representative methods on their ability to generate novel model\nweights, i.e., weights that are different from the checkpoints seen during\ntraining. Surprisingly, we find that these methods synthesize weights largely\nby memorization: they produce either replicas, or at best simple\ninterpolations, of the training checkpoints. Current methods fail to outperform\nsimple baselines, such as adding noise to the weights or taking a simple weight\nensemble, in obtaining different and simultaneously high-performing models. We\nfurther show that this memorization cannot be effectively mitigated by\nmodifying modeling factors commonly associated with memorization in image\ndiffusion models, or applying data augmentations. Our findings provide a\nrealistic assessment of what types of data current generative models can model,\nand highlight the need for more careful evaluation of generative models in new\ndomains. Our code is available at\nhttps://github.com/boyazeng/weight_memorization.", "published": "2025-06-09 17:58:36", "link": "http://arxiv.org/abs/2506.07998v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "UA-Pose: Uncertainty-Aware 6D Object Pose Estimation and Online Object Completion with Partial References", "abstract": "6D object pose estimation has shown strong generalizability to novel objects.\nHowever, existing methods often require either a complete, well-reconstructed\n3D model or numerous reference images that fully cover the object. Estimating\n6D poses from partial references, which capture only fragments of an object's\nappearance and geometry, remains challenging. To address this, we propose\nUA-Pose, an uncertainty-aware approach for 6D object pose estimation and online\nobject completion specifically designed for partial references. We assume\naccess to either (1) a limited set of RGBD images with known poses or (2) a\nsingle 2D image. For the first case, we initialize a partial object 3D model\nbased on the provided images and poses, while for the second, we use\nimage-to-3D techniques to generate an initial object 3D model. Our method\nintegrates uncertainty into the incomplete 3D model, distinguishing between\nseen and unseen regions. This uncertainty enables confidence assessment in pose\nestimation and guides an uncertainty-aware sampling strategy for online object\ncompletion, enhancing robustness in pose estimation accuracy and improving\nobject completeness. We evaluate our method on the YCB-Video, YCBInEOAT, and\nHO3D datasets, including RGBD sequences of YCB objects manipulated by robots\nand human hands. Experimental results demonstrate significant performance\nimprovements over existing methods, particularly when object observations are\nincomplete or partially captured. Project page:\nhttps://minfenli.github.io/UA-Pose/", "published": "2025-06-09 17:58:12", "link": "http://arxiv.org/abs/2506.07996v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "PairEdit: Learning Semantic Variations for Exemplar-based Image Editing", "abstract": "Recent advancements in text-guided image editing have achieved notable\nsuccess by leveraging natural language prompts for fine-grained semantic\ncontrol. However, certain editing semantics are challenging to specify\nprecisely using textual descriptions alone. A practical alternative involves\nlearning editing semantics from paired source-target examples. Existing\nexemplar-based editing methods still rely on text prompts describing the change\nwithin paired examples or learning implicit text-based editing instructions. In\nthis paper, we introduce PairEdit, a novel visual editing method designed to\neffectively learn complex editing semantics from a limited number of image\npairs or even a single image pair, without using any textual guidance. We\npropose a target noise prediction that explicitly models semantic variations\nwithin paired images through a guidance direction term. Moreover, we introduce\na content-preserving noise schedule to facilitate more effective semantic\nlearning. We also propose optimizing distinct LoRAs to disentangle the learning\nof semantic variations from content. Extensive qualitative and quantitative\nevaluations demonstrate that PairEdit successfully learns intricate semantics\nwhile significantly improving content consistency compared to baseline methods.\nCode will be available at https://github.com/xudonmao/PairEdit.", "published": "2025-06-09 17:57:15", "link": "http://arxiv.org/abs/2506.07992v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Rethinking Cross-Modal Interaction in Multimodal Diffusion Transformers", "abstract": "Multimodal Diffusion Transformers (MM-DiTs) have achieved remarkable progress\nin text-driven visual generation. However, even state-of-the-art MM-DiT models\nlike FLUX struggle with achieving precise alignment between text prompts and\ngenerated content. We identify two key issues in the attention mechanism of\nMM-DiT, namely 1) the suppression of cross-modal attention due to token\nimbalance between visual and textual modalities and 2) the lack of\ntimestep-aware attention weighting, which hinder the alignment. To address\nthese issues, we propose \\textbf{Temperature-Adjusted Cross-modal Attention\n(TACA)}, a parameter-efficient method that dynamically rebalances multimodal\ninteractions through temperature scaling and timestep-dependent adjustment.\nWhen combined with LoRA fine-tuning, TACA significantly enhances text-image\nalignment on the T2I-CompBench benchmark with minimal computational overhead.\nWe tested TACA on state-of-the-art models like FLUX and SD3.5, demonstrating\nits ability to improve image-text alignment in terms of object appearance,\nattribute binding, and spatial relationships. Our findings highlight the\nimportance of balancing cross-modal attention in improving semantic fidelity in\ntext-to-image diffusion models. Our codes are publicly available at\n\\href{https://github.com/Vchitect/TACA}", "published": "2025-06-09 17:54:04", "link": "http://arxiv.org/abs/2506.07986v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Rethinking Crowd-Sourced Evaluation of Neuron Explanations", "abstract": "Interpreting individual neurons or directions in activations space is an\nimportant component of mechanistic interpretability. As such, many algorithms\nhave been proposed to automatically produce neuron explanations, but it is\noften not clear how reliable these explanations are, or which methods produce\nthe best explanations. This can be measured via crowd-sourced evaluations, but\nthey can often be noisy and expensive, leading to unreliable results. In this\npaper, we carefully analyze the evaluation pipeline and develop a\ncost-effective and highly accurate crowdsourced evaluation strategy. In\ncontrast to previous human studies that only rate whether the explanation\nmatches the most highly activating inputs, we estimate whether the explanation\ndescribes neuron activations across all inputs. To estimate this effectively,\nwe introduce a novel application of importance sampling to determine which\ninputs are the most valuable to show to raters, leading to around 30x cost\nreduction compared to uniform sampling. We also analyze the label noise present\nin crowd-sourced evaluations and propose a Bayesian method to aggregate\nmultiple ratings leading to a further ~5x reduction in number of ratings\nrequired for the same accuracy. Finally, we use these methods to conduct a\nlarge-scale study comparing the quality of neuron explanations produced by the\nmost popular methods for two different vision models.", "published": "2025-06-09 17:53:55", "link": "http://arxiv.org/abs/2506.07985v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "CXR-LT 2024: A MICCAI challenge on long-tailed, multi-label, and zero-shot disease classification from chest X-ray", "abstract": "The CXR-LT series is a community-driven initiative designed to enhance lung\ndisease classification using chest X-rays (CXR). It tackles challenges in open\nlong-tailed lung disease classification and enhances the measurability of\nstate-of-the-art techniques. The first event, CXR-LT 2023, aimed to achieve\nthese goals by providing high-quality benchmark CXR data for model development\nand conducting comprehensive evaluations to identify ongoing issues impacting\nlung disease classification performance. Building on the success of CXR-LT\n2023, the CXR-LT 2024 expands the dataset to 377,110 chest X-rays (CXRs) and 45\ndisease labels, including 19 new rare disease findings. It also introduces a\nnew focus on zero-shot learning to address limitations identified in the\nprevious event. Specifically, CXR-LT 2024 features three tasks: (i) long-tailed\nclassification on a large, noisy test set, (ii) long-tailed classification on a\nmanually annotated \"gold standard\" subset, and (iii) zero-shot generalization\nto five previously unseen disease findings. This paper provides an overview of\nCXR-LT 2024, detailing the data curation process and consolidating\nstate-of-the-art solutions, including the use of multimodal models for rare\ndisease detection, advanced generative approaches to handle noisy labels, and\nzero-shot learning strategies for unseen diseases. Additionally, the expanded\ndataset enhances disease coverage to better represent real-world clinical\nsettings, offering a valuable resource for future research. By synthesizing the\ninsights and innovations of participating teams, we aim to advance the\ndevelopment of clinically realistic and generalizable diagnostic models for\nchest radiography.", "published": "2025-06-09 17:53:31", "link": "http://arxiv.org/abs/2506.07984v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Real-time Localization of a Soccer Ball from a Single Camera", "abstract": "We propose a computationally efficient method for real-time three-dimensional\nfootball trajectory reconstruction from a single broadcast camera. In contrast\nto previous work, our approach introduces a multi-mode state model with $W$\ndiscrete modes to significantly accelerate optimization while preserving\ncentimeter-level accuracy -- even in cases of severe occlusion, motion blur,\nand complex backgrounds. The system operates on standard CPUs and achieves low\nlatency suitable for live broadcast settings. Extensive evaluation on a\nproprietary dataset of 6K-resolution Russian Premier League matches\ndemonstrates performance comparable to multi-camera systems, without the need\nfor specialized or costly infrastructure. This work provides a practical method\nfor accessible and accurate 3D ball tracking in professional football\nenvironments.", "published": "2025-06-09 17:52:07", "link": "http://arxiv.org/abs/2506.07981v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "OneIG-Bench: Omni-dimensional Nuanced Evaluation for Image Generation", "abstract": "Text-to-image (T2I) models have garnered significant attention for generating\nhigh-quality images aligned with text prompts. However, rapid T2I model\nadvancements reveal limitations in early benchmarks, lacking comprehensive\nevaluations, for example, the evaluation on reasoning, text rendering and\nstyle. Notably, recent state-of-the-art models, with their rich knowledge\nmodeling capabilities, show promising results on the image generation problems\nrequiring strong reasoning ability, yet existing evaluation systems have not\nadequately addressed this frontier. To systematically address these gaps, we\nintroduce OneIG-Bench, a meticulously designed comprehensive benchmark\nframework for fine-grained evaluation of T2I models across multiple dimensions,\nincluding prompt-image alignment, text rendering precision, reasoning-generated\ncontent, stylization, and diversity. By structuring the evaluation, this\nbenchmark enables in-depth analysis of model performance, helping researchers\nand practitioners pinpoint strengths and bottlenecks in the full pipeline of\nimage generation. Specifically, OneIG-Bench enables flexible evaluation by\nallowing users to focus on a particular evaluation subset. Instead of\ngenerating images for the entire set of prompts, users can generate images only\nfor the prompts associated with the selected dimension and complete the\ncorresponding evaluation accordingly. Our codebase and dataset are now publicly\navailable to facilitate reproducible evaluation studies and cross-model\ncomparisons within the T2I research community.", "published": "2025-06-09 17:50:21", "link": "http://arxiv.org/abs/2506.07977v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CyberV: Cybernetics for Test-time Scaling in Video Understanding", "abstract": "Current Multimodal Large Language Models (MLLMs) may struggle with\nunderstanding long or complex videos due to computational demands at test time,\nlack of robustness, and limited accuracy, primarily stemming from their\nfeed-forward processing nature. These limitations could be more severe for\nmodels with fewer parameters. To address these limitations, we propose a novel\nframework inspired by cybernetic principles, redesigning video MLLMs as\nadaptive systems capable of self-monitoring, self-correction, and dynamic\nresource allocation during inference. Our approach, CyberV, introduces a\ncybernetic loop consisting of an MLLM Inference System, a Sensor, and a\nController. Specifically, the sensor monitors forward processes of the MLLM and\ncollects intermediate interpretations, such as attention drift, then the\ncontroller determines when and how to trigger self-correction and generate\nfeedback to guide the next round. This test-time adaptive scaling framework\nenhances frozen MLLMs without requiring retraining or additional components.\nExperiments demonstrate significant improvements: CyberV boosts Qwen2.5-VL-7B\nby 8.3% and InternVL3-8B by 5.5% on VideoMMMU, surpassing the competitive\nproprietary model GPT-4o. When applied to Qwen2.5-VL-72B, it yields a 10.0%\nimprovement, achieving performance even comparable to human experts.\nFurthermore, our method demonstrates consistent gains on general-purpose\nbenchmarks, such as VideoMME and WorldSense, highlighting its effectiveness and\ngeneralization capabilities in making MLLMs more robust and accurate for\ndynamic video understanding. The code is released at\nhttps://github.com/marinero4972/CyberV.", "published": "2025-06-09 17:45:18", "link": "http://arxiv.org/abs/2506.07971v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SpaCE-10: A Comprehensive Benchmark for Multimodal Large Language Models in Compositional Spatial Intelligence", "abstract": "Multimodal Large Language Models (MLLMs) have achieved remarkable progress in\nvarious multimodal tasks. To pursue higher intelligence in space, MLLMs require\nintegrating multiple atomic spatial capabilities to handle complex and dynamic\ntasks. However, existing benchmarks struggle to comprehensively evaluate the\nspatial intelligence of common MLLMs from the atomic level to the compositional\nlevel. To fill this gap, we present SpaCE-10, a comprehensive benchmark for\ncompositional spatial evaluations. In SpaCE-10, we define 10 atomic spatial\ncapabilities, which are combined to form 8 compositional capabilities. Based on\nthese definitions, we propose a novel hierarchical annotation pipeline to\ngenerate high-quality and diverse question-answer (QA) pairs. With over 150+\nhours of human expert effort, we obtain over 5k QA pairs for 811 real indoor\nscenes in SpaCE-10, which covers various evaluation settings like point cloud\ninput and multi-choice QA. We conduct an extensive evaluation of common MLLMs\non SpaCE-10 and find that even the most advanced MLLM still lags behind humans\nby large margins. Through our careful study, we also draw several significant\nfindings that benefit the MLLM community. For example, we reveal that the\nshortcoming of counting capability greatly limits the compositional spatial\ncapabilities of existing MLLMs. The evaluation code and benchmark datasets are\navailable at https://github.com/Cuzyoung/SpaCE-10.", "published": "2025-06-09 17:41:36", "link": "http://arxiv.org/abs/2506.07966v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Creating a Historical Migration Dataset from Finnish Church Records, 1800-1920", "abstract": "This article presents a large-scale effort to create a structured dataset of\ninternal migration in Finland between 1800 and 1920 using digitized church\nmoving records. These records, maintained by Evangelical-Lutheran parishes,\ndocument the migration of individuals and families and offer a valuable source\nfor studying historical demographic patterns. The dataset includes over six\nmillion entries extracted from approximately 200,000 images of handwritten\nmigration records.\n  The data extraction process was automated using a deep learning pipeline that\nincluded layout analysis, table detection, cell classification, and handwriting\nrecognition. The complete pipeline was applied to all images, resulting in a\nstructured dataset suitable for research.\n  The dataset can be used to study internal migration, urbanization, and family\nmigration, and the spread of disease in preindustrial Finland. A case study\nfrom the Elim\\\"aki parish shows how local migration histories can be\nreconstructed. The work demonstrates how large volumes of handwritten archival\nmaterial can be transformed into structured data to support historical and\ndemographic research.", "published": "2025-06-09 17:32:55", "link": "http://arxiv.org/abs/2506.07960v1", "categories": ["cs.CV", "I.4.6, J.5"], "primary_category": "cs.CV"}
{"title": "Squeeze3D: Your 3D Generation Model is Secretly an Extreme Neural Compressor", "abstract": "We propose Squeeze3D, a novel framework that leverages implicit prior\nknowledge learnt by existing pre-trained 3D generative models to compress 3D\ndata at extremely high compression ratios. Our approach bridges the latent\nspaces between a pre-trained encoder and a pre-trained generation model through\ntrainable mapping networks. Any 3D model represented as a mesh, point cloud, or\na radiance field is first encoded by the pre-trained encoder and then\ntransformed (i.e. compressed) into a highly compact latent code. This latent\ncode can effectively be used as an extremely compressed representation of the\nmesh or point cloud. A mapping network transforms the compressed latent code\ninto the latent space of a powerful generative model, which is then conditioned\nto recreate the original 3D model (i.e. decompression). Squeeze3D is trained\nentirely on generated synthetic data and does not require any 3D datasets. The\nSqueeze3D architecture can be flexibly used with existing pre-trained 3D\nencoders and existing generative models. It can flexibly support different\nformats, including meshes, point clouds, and radiance fields. Our experiments\ndemonstrate that Squeeze3D achieves compression ratios of up to 2187x for\ntextured meshes, 55x for point clouds, and 619x for radiance fields while\nmaintaining visual quality comparable to many existing methods. Squeeze3D only\nincurs a small compression and decompression latency since it does not involve\ntraining object-specific networks to compress an object.", "published": "2025-06-09 16:52:10", "link": "http://arxiv.org/abs/2506.07932v1", "categories": ["cs.GR", "cs.CV", "cs.LG"], "primary_category": "cs.GR"}
{"title": "A Comparative Study of U-Net Architectures for Change Detection in Satellite Images", "abstract": "Remote sensing change detection is essential for monitoring the everchanging\nlandscapes of the Earth. The U-Net architecture has gained popularity for its\ncapability to capture spatial information and perform pixel-wise\nclassification. However, their application in the Remote sensing field remains\nlargely unexplored. Therefore, this paper fill the gap by conducting a\ncomprehensive analysis of 34 papers. This study conducts a comparison and\nanalysis of 18 different U-Net variations, assessing their potential for\ndetecting changes in remote sensing. We evaluate both benefits along with\ndrawbacks of each variation within the framework of this particular\napplication. We emphasize variations that are explicitly built for change\ndetection, such as Siamese Swin-U-Net, which utilizes a Siamese architecture.\nThe analysis highlights the significance of aspects such as managing data from\ndifferent time periods and collecting relationships over a long distance to\nenhance the precision of change detection. This study provides valuable\ninsights for researchers and practitioners that choose U-Net versions for\nremote sensing change detection tasks.", "published": "2025-06-09 16:38:34", "link": "http://arxiv.org/abs/2506.07925v1", "categories": ["cs.CV", "cs.LG", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Speedy Deformable 3D Gaussian Splatting: Fast Rendering and Compression of Dynamic Scenes", "abstract": "Recent extensions of 3D Gaussian Splatting (3DGS) to dynamic scenes achieve\nhigh-quality novel view synthesis by using neural networks to predict the\ntime-varying deformation of each Gaussian. However, performing per-Gaussian\nneural inference at every frame poses a significant bottleneck, limiting\nrendering speed and increasing memory and compute requirements. In this paper,\nwe present Speedy Deformable 3D Gaussian Splatting (SpeeDe3DGS), a general\npipeline for accelerating the rendering speed of dynamic 3DGS and 4DGS\nrepresentations by reducing neural inference through two complementary\ntechniques. First, we propose a temporal sensitivity pruning score that\nidentifies and removes Gaussians with low contribution to the dynamic scene\nreconstruction. We also introduce an annealing smooth pruning mechanism that\nimproves pruning robustness in real-world scenes with imprecise camera poses.\nSecond, we propose GroupFlow, a motion analysis technique that clusters\nGaussians by trajectory similarity and predicts a single rigid transformation\nper group instead of separate deformations for each Gaussian. Together, our\ntechniques accelerate rendering by $10.37\\times$, reduce model size by\n$7.71\\times$, and shorten training time by $2.71\\times$ on the NeRF-DS dataset.\nSpeeDe3DGS also improves rendering speed by $4.20\\times$ and $58.23\\times$ on\nthe D-NeRF and HyperNeRF vrig datasets. Our methods are modular and can be\nintegrated into any deformable 3DGS or 4DGS framework.", "published": "2025-06-09 16:30:48", "link": "http://arxiv.org/abs/2506.07917v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "WeThink: Toward General-purpose Vision-Language Reasoning via Reinforcement Learning", "abstract": "Building on the success of text-based reasoning models like DeepSeek-R1,\nextending these capabilities to multimodal reasoning holds great promise. While\nrecent works have attempted to adapt DeepSeek-R1-style reinforcement learning\n(RL) training paradigms to multimodal large language models (MLLM), focusing on\ndomain-specific tasks like math and visual perception, a critical question\nremains: How can we achieve the general-purpose visual-language reasoning\nthrough RL? To address this challenge, we make three key efforts: (1) A novel\nScalable Multimodal QA Synthesis pipeline that autonomously generates\ncontext-aware, reasoning-centric question-answer (QA) pairs directly from the\ngiven images. (2) The open-source WeThink dataset containing over 120K\nmultimodal QA pairs with annotated reasoning paths, curated from 18 diverse\ndataset sources and covering various question domains. (3) A comprehensive\nexploration of RL on our dataset, incorporating a hybrid reward mechanism that\ncombines rule-based verification with model-based assessment to optimize RL\ntraining efficiency across various task domains. Across 14 diverse MLLM\nbenchmarks, we demonstrate that our WeThink dataset significantly enhances\nperformance, from mathematical reasoning to diverse general multimodal tasks.\nMoreover, we show that our automated data pipeline can continuously increase\ndata diversity to further improve model performance.", "published": "2025-06-09 16:20:54", "link": "http://arxiv.org/abs/2506.07905v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Video Unlearning via Low-Rank Refusal Vector", "abstract": "Video generative models democratize the creation of visual content through\nintuitive instruction following, but they also inherit the biases and harmful\nconcepts embedded within their web-scale training data. This inheritance\ncreates a significant risk, as users can readily generate undesirable and even\nillegal content. This work introduces the first unlearning technique tailored\nexplicitly for video diffusion models to address this critical issue. Our\nmethod requires 5 multi-modal prompt pairs only. Each pair contains a \"safe\"\nand an \"unsafe\" example that differ only by the target concept. Averaging their\nper-layer latent differences produces a \"refusal vector\", which, once\nsubtracted from the model parameters, neutralizes the unsafe concept. We\nintroduce a novel low-rank factorization approach on the covariance difference\nof embeddings that yields robust refusal vectors. This isolates the target\nconcept while minimizing collateral unlearning of other semantics, thus\npreserving the visual quality of the generated video. Our method preserves the\nmodel's generation quality while operating without retraining or access to the\noriginal training data. By embedding the refusal direction directly into the\nmodel's weights, the suppression mechanism becomes inherently more robust\nagainst adversarial bypass attempts compared to surface-level input-output\nfilters. In a thorough qualitative and quantitative evaluation, we show that we\ncan neutralize a variety of harmful contents, including explicit nudity,\ngraphic violence, copyrights, and trademarks. Project page:\nhttps://www.pinlab.org/video-unlearning.", "published": "2025-06-09 16:06:49", "link": "http://arxiv.org/abs/2506.07891v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "EgoM2P: Egocentric Multimodal Multitask Pretraining", "abstract": "Understanding multimodal signals in egocentric vision, such as RGB video,\ndepth, camera poses, and gaze, is essential for applications in augmented\nreality, robotics, and human-computer interaction. These capabilities enable\nsystems to better interpret the camera wearer's actions, intentions, and\nsurrounding environment. However, building large-scale egocentric multimodal\nand multitask models presents unique challenges. Egocentric data are inherently\nheterogeneous, with large variations in modality coverage across devices and\nsettings. Generating pseudo-labels for missing modalities, such as gaze or\nhead-mounted camera trajectories, is often infeasible, making standard\nsupervised learning approaches difficult to scale. Furthermore, dynamic camera\nmotion and the complex temporal and spatial structure of first-person video\npose additional challenges for the direct application of existing multimodal\nfoundation models.\n  To address these challenges, we introduce a set of efficient temporal\ntokenizers and propose EgoM2P, a masked modeling framework that learns from\ntemporally aware multimodal tokens to train a large, general-purpose model for\negocentric 4D understanding. This unified design supports multitasking across\ndiverse egocentric perception and synthesis tasks, including gaze prediction,\negocentric camera tracking, and monocular depth estimation from egocentric\nvideo. EgoM2P also serves as a generative model for conditional egocentric\nvideo synthesis. Across these tasks, EgoM2P matches or outperforms specialist\nmodels while being an order of magnitude faster. We will fully open-source\nEgoM2P to support the community and advance egocentric vision research. Project\npage: https://egom2p.github.io/", "published": "2025-06-09 15:59:25", "link": "http://arxiv.org/abs/2506.07886v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CrosswalkNet: An Optimized Deep Learning Framework for Pedestrian Crosswalk Detection in Aerial Images with High-Performance Computing", "abstract": "With the increasing availability of aerial and satellite imagery, deep\nlearning presents significant potential for transportation asset management,\nsafety analysis, and urban planning. This study introduces CrosswalkNet, a\nrobust and efficient deep learning framework designed to detect various types\nof pedestrian crosswalks from 15-cm resolution aerial images. CrosswalkNet\nincorporates a novel detection approach that improves upon traditional object\ndetection strategies by utilizing oriented bounding boxes (OBB), enhancing\ndetection precision by accurately capturing crosswalks regardless of their\norientation. Several optimization techniques, including Convolutional Block\nAttention, a dual-branch Spatial Pyramid Pooling-Fast module, and cosine\nannealing, are implemented to maximize performance and efficiency. A\ncomprehensive dataset comprising over 23,000 annotated crosswalk instances is\nutilized to train and validate the proposed framework. The best-performing\nmodel achieves an impressive precision of 96.5% and a recall of 93.3% on aerial\nimagery from Massachusetts, demonstrating its accuracy and effectiveness.\nCrosswalkNet has also been successfully applied to datasets from New Hampshire,\nVirginia, and Maine without transfer learning or fine-tuning, showcasing its\nrobustness and strong generalization capability. Additionally, the crosswalk\ndetection results, processed using High-Performance Computing (HPC) platforms\nand provided in polygon shapefile format, have been shown to accelerate data\nprocessing and detection, supporting real-time analysis for safety and mobility\napplications. This integration offers policymakers, transportation engineers,\nand urban planners an effective instrument to enhance pedestrian safety and\nimprove urban mobility.", "published": "2025-06-09 15:56:24", "link": "http://arxiv.org/abs/2506.07885v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Spatio-Temporal State Space Model For Efficient Event-Based Optical Flow", "abstract": "Event cameras unlock new frontiers that were previously unthinkable with\nstandard frame-based cameras. One notable example is low-latency motion\nestimation (optical flow), which is critical for many real-time applications.\nIn such applications, the computational efficiency of algorithms is paramount.\nAlthough recent deep learning paradigms such as CNN, RNN, or ViT have shown\nremarkable performance, they often lack the desired computational efficiency.\nConversely, asynchronous event-based methods including SNNs and GNNs are\ncomputationally efficient; however, these approaches fail to capture sufficient\nspatio-temporal information, a powerful feature required to achieve better\nperformance for optical flow estimation. In this work, we introduce\nSpatio-Temporal State Space Model (STSSM) module along with a novel network\narchitecture to develop an extremely efficient solution with competitive\nperformance. Our STSSM module leverages state-space models to effectively\ncapture spatio-temporal correlations in event data, offering higher performance\nwith lower complexity compared to ViT, CNN-based architectures in similar\nsettings. Our model achieves 4.5x faster inference and 8x lower computations\ncompared to TMA and 2x lower computations compared to EV-FlowNet with\ncompetitive performance on the DSEC benchmark. Our code will be available at\nhttps://github.com/AhmedHumais/E-STMFlow", "published": "2025-06-09 15:51:06", "link": "http://arxiv.org/abs/2506.07878v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VIVAT: Virtuous Improving VAE Training through Artifact Mitigation", "abstract": "Variational Autoencoders (VAEs) remain a cornerstone of generative computer\nvision, yet their training is often plagued by artifacts that degrade\nreconstruction and generation quality. This paper introduces VIVAT, a\nsystematic approach to mitigating common artifacts in KL-VAE training without\nrequiring radical architectural changes. We present a detailed taxonomy of five\nprevalent artifacts - color shift, grid patterns, blur, corner and droplet\nartifacts - and analyze their root causes. Through straightforward\nmodifications, including adjustments to loss weights, padding strategies, and\nthe integration of Spatially Conditional Normalization, we demonstrate\nsignificant improvements in VAE performance. Our method achieves\nstate-of-the-art results in image reconstruction metrics (PSNR and SSIM) across\nmultiple benchmarks and enhances text-to-image generation quality, as evidenced\nby superior CLIP scores. By preserving the simplicity of the KL-VAE framework\nwhile addressing its practical challenges, VIVAT offers actionable insights for\nresearchers and practitioners aiming to optimize VAE training.", "published": "2025-06-09 15:27:03", "link": "http://arxiv.org/abs/2506.07863v1", "categories": ["cs.CV", "cs.LG", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Egocentric Event-Based Vision for Ping Pong Ball Trajectory Prediction", "abstract": "In this paper, we present a real-time egocentric trajectory prediction system\nfor table tennis using event cameras. Unlike standard cameras, which suffer\nfrom high latency and motion blur at fast ball speeds, event cameras provide\nhigher temporal resolution, allowing more frequent state updates, greater\nrobustness to outliers, and accurate trajectory predictions using just a short\ntime window after the opponent's impact. We collect a dataset of ping-pong game\nsequences, including 3D ground-truth trajectories of the ball, synchronized\nwith sensor data from the Meta Project Aria glasses and event streams. Our\nsystem leverages foveated vision, using eye-gaze data from the glasses to\nprocess only events in the viewer's fovea. This biologically inspired approach\nimproves ball detection performance and significantly reduces computational\nlatency, as it efficiently allocates resources to the most perceptually\nrelevant regions, achieving a reduction factor of 10.81 on the collected\ntrajectories. Our detection pipeline has a worst-case total latency of 4.5 ms,\nincluding computation and perception - significantly lower than a frame-based\n30 FPS system, which, in the worst case, takes 66 ms solely for perception.\nFinally, we fit a trajectory prediction model to the estimated states of the\nball, enabling 3D trajectory forecasting in the future. To the best of our\nknowledge, this is the first approach to predict table tennis trajectories from\nan egocentric perspective using event cameras.", "published": "2025-06-09 15:22:55", "link": "http://arxiv.org/abs/2506.07860v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SAM2Auto: Auto Annotation Using FLASH", "abstract": "Vision-Language Models (VLMs) lag behind Large Language Models due to the\nscarcity of annotated datasets, as creating paired visual-textual annotations\nis labor-intensive and expensive. To address this bottleneck, we introduce\nSAM2Auto, the first fully automated annotation pipeline for video datasets\nrequiring no human intervention or dataset-specific training. Our approach\nconsists of two key components: SMART-OD, a robust object detection system that\ncombines automatic mask generation with open-world object detection\ncapabilities, and FLASH (Frame-Level Annotation and Segmentation Handler), a\nmulti-object real-time video instance segmentation (VIS) that maintains\nconsistent object identification across video frames even with intermittent\ndetection gaps. Unlike existing open-world detection methods that require\nframe-specific hyperparameter tuning and suffer from numerous false positives,\nour system employs statistical approaches to minimize detection errors while\nensuring consistent object tracking throughout entire video sequences.\nExtensive experimental validation demonstrates that SAM2Auto achieves\ncomparable accuracy to manual annotation while dramatically reducing annotation\ntime and eliminating labor costs. The system successfully handles diverse\ndatasets without requiring retraining or extensive parameter adjustments,\nmaking it a practical solution for large-scale dataset creation. Our work\nestablishes a new baseline for automated video annotation and provides a\npathway for accelerating VLM development by addressing the fundamental dataset\nbottleneck that has constrained progress in vision-language understanding.", "published": "2025-06-09 15:15:15", "link": "http://arxiv.org/abs/2506.07850v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "F2Net: A Frequency-Fused Network for Ultra-High Resolution Remote Sensing Segmentation", "abstract": "Semantic segmentation of ultra-high-resolution (UHR) remote sensing imagery\nis critical for applications like environmental monitoring and urban planning\nbut faces computational and optimization challenges. Conventional methods\neither lose fine details through downsampling or fragment global context via\npatch processing. While multi-branch networks address this trade-off, they\nsuffer from computational inefficiency and conflicting gradient dynamics during\ntraining. We propose F2Net, a frequency-aware framework that decomposes UHR\nimages into high- and low-frequency components for specialized processing. The\nhigh-frequency branch preserves full-resolution structural details, while the\nlow-frequency branch processes downsampled inputs through dual sub-branches\ncapturing short- and long-range dependencies. A Hybrid-Frequency Fusion module\nintegrates these observations, guided by two novel objectives: Cross-Frequency\nAlignment Loss ensures semantic consistency between frequency components, and\nCross-Frequency Balance Loss regulates gradient magnitudes across branches to\nstabilize training. Evaluated on DeepGlobe and Inria Aerial benchmarks, F2Net\nachieves state-of-the-art performance with mIoU of 80.22 and 83.39,\nrespectively. Our code will be publicly available.", "published": "2025-06-09 15:09:49", "link": "http://arxiv.org/abs/2506.07847v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "R3D2: Realistic 3D Asset Insertion via Diffusion for Autonomous Driving Simulation", "abstract": "Validating autonomous driving (AD) systems requires diverse and\nsafety-critical testing, making photorealistic virtual environments essential.\nTraditional simulation platforms, while controllable, are resource-intensive to\nscale and often suffer from a domain gap with real-world data. In contrast,\nneural reconstruction methods like 3D Gaussian Splatting (3DGS) offer a\nscalable solution for creating photorealistic digital twins of real-world\ndriving scenes. However, they struggle with dynamic object manipulation and\nreusability as their per-scene optimization-based methodology tends to result\nin incomplete object models with integrated illumination effects. This paper\nintroduces R3D2, a lightweight, one-step diffusion model designed to overcome\nthese limitations and enable realistic insertion of complete 3D assets into\nexisting scenes by generating plausible rendering effects-such as shadows and\nconsistent lighting-in real time. This is achieved by training R3D2 on a novel\ndataset: 3DGS object assets are generated from in-the-wild AD data using an\nimage-conditioned 3D generative model, and then synthetically placed into\nneural rendering-based virtual environments, allowing R3D2 to learn realistic\nintegration. Quantitative and qualitative evaluations demonstrate that R3D2\nsignificantly enhances the realism of inserted assets, enabling use-cases like\ntext-to-3D asset insertion and cross-scene/dataset object transfer, allowing\nfor true scalability in AD validation. To promote further research in scalable\nand realistic AD simulation, we will release our dataset and code, see\nhttps://research.zenseact.com/publications/R3D2/.", "published": "2025-06-09 14:50:19", "link": "http://arxiv.org/abs/2506.07826v1", "categories": ["cs.CV", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "M2Restore: Mixture-of-Experts-based Mamba-CNN Fusion Framework for All-in-One Image Restoration", "abstract": "Natural images are often degraded by complex, composite degradations such as\nrain, snow, and haze, which adversely impact downstream vision applications.\nWhile existing image restoration efforts have achieved notable success, they\nare still hindered by two critical challenges: limited generalization across\ndynamically varying degradation scenarios and a suboptimal balance between\npreserving local details and modeling global dependencies. To overcome these\nchallenges, we propose M2Restore, a novel Mixture-of-Experts (MoE)-based\nMamba-CNN fusion framework for efficient and robust all-in-one image\nrestoration. M2Restore introduces three key contributions: First, to boost the\nmodel's generalization across diverse degradation conditions, we exploit a\nCLIP-guided MoE gating mechanism that fuses task-conditioned prompts with\nCLIP-derived semantic priors. This mechanism is further refined via cross-modal\nfeature calibration, which enables precise expert selection for various\ndegradation types. Second, to jointly capture global contextual dependencies\nand fine-grained local details, we design a dual-stream architecture that\nintegrates the localized representational strength of CNNs with the long-range\nmodeling efficiency of Mamba. This integration enables collaborative\noptimization of global semantic relationships and local structural fidelity,\npreserving global coherence while enhancing detail restoration. Third, we\nintroduce an edge-aware dynamic gating mechanism that adaptively balances\nglobal modeling and local enhancement by reallocating computational attention\nto degradation-sensitive regions. This targeted focus leads to more efficient\nand precise restoration. Extensive experiments across multiple image\nrestoration benchmarks validate the superiority of M2Restore in both visual\nquality and quantitative performance.", "published": "2025-06-09 14:43:39", "link": "http://arxiv.org/abs/2506.07814v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Looking Beyond Visible Cues: Implicit Video Question Answering via Dual-Clue Reasoning", "abstract": "Video Question Answering (VideoQA) aims to answer natural language questions\nbased on the given video, with prior work primarily focusing on identifying the\nduration of relevant segments, referred to as explicit visual evidence.\nHowever, explicit visual evidence is not always directly available,\nparticularly when questions target symbolic meanings or deeper intentions,\nleading to significant performance degradation. To fill this gap, we introduce\na novel task and dataset, $\\textbf{I}$mplicit $\\textbf{V}$ideo\n$\\textbf{Q}$uestion $\\textbf{A}$nswering (I-VQA), which focuses on answering\nquestions in scenarios where explicit visual evidence is inaccessible. Given an\nimplicit question and its corresponding video, I-VQA requires answering based\non the contextual visual cues present within the video. To tackle I-VQA, we\npropose a novel reasoning framework, IRM (Implicit Reasoning Model),\nincorporating dual-stream modeling of contextual actions and intent clues as\nimplicit reasoning chains. IRM comprises the Action-Intent Module (AIM) and the\nVisual Enhancement Module (VEM). AIM deduces and preserves question-related\ndual clues by generating clue candidates and performing relation deduction. VEM\nenhances contextual visual representation by leveraging key contextual clues.\nExtensive experiments validate the effectiveness of our IRM in I-VQA tasks,\noutperforming GPT-4o, OpenAI-o3, and fine-tuned VideoChat2 by $0.76\\%$,\n$1.37\\%$, and $4.87\\%$, respectively. Additionally, IRM performs SOTA on\nsimilar implicit advertisement understanding and future prediction in\ntraffic-VQA. Datasets and codes are available for double-blind review in\nanonymous repo: https://github.com/tychen-SJTU/Implicit-VideoQA.", "published": "2025-06-09 14:38:14", "link": "http://arxiv.org/abs/2506.07811v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Incorporating Uncertainty-Guided and Top-k Codebook Matching for Real-World Blind Image Super-Resolution", "abstract": "Recent advancements in codebook-based real image super-resolution (SR) have\nshown promising results in real-world applications. The core idea involves\nmatching high-quality image features from a codebook based on low-resolution\n(LR) image features. However, existing methods face two major challenges:\ninaccurate feature matching with the codebook and poor texture detail\nreconstruction. To address these issues, we propose a novel Uncertainty-Guided\nand Top-k Codebook Matching SR (UGTSR) framework, which incorporates three key\ncomponents: (1) an uncertainty learning mechanism that guides the model to\nfocus on texture-rich regions, (2) a Top-k feature matching strategy that\nenhances feature matching accuracy by fusing multiple candidate features, and\n(3) an Align-Attention module that enhances the alignment of information\nbetween LR and HR features. Experimental results demonstrate significant\nimprovements in texture realism and reconstruction fidelity compared to\nexisting methods. We will release the code upon formal publication.", "published": "2025-06-09 14:37:58", "link": "http://arxiv.org/abs/2506.07809v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Identifiable Object Representations under Spatial Ambiguities", "abstract": "Modular object-centric representations are essential for *human-like\nreasoning* but are challenging to obtain under spatial ambiguities, *e.g. due\nto occlusions and view ambiguities*. However, addressing challenges presents\nboth theoretical and practical difficulties. We introduce a novel multi-view\nprobabilistic approach that aggregates view-specific slots to capture\n*invariant content* information while simultaneously learning disentangled\nglobal *viewpoint-level* information. Unlike prior single-view methods, our\napproach resolves spatial ambiguities, provides theoretical guarantees for\nidentifiability, and requires *no viewpoint annotations*. Extensive experiments\non standard benchmarks and novel complex datasets validate our method's\nrobustness and scalability.", "published": "2025-06-09 14:35:23", "link": "http://arxiv.org/abs/2506.07806v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Image Reconstruction as a Tool for Feature Analysis", "abstract": "Vision encoders are increasingly used in modern applications, from\nvision-only models to multimodal systems such as vision-language models.\nDespite their remarkable success, it remains unclear how these architectures\nrepresent features internally. Here, we propose a novel approach for\ninterpreting vision features via image reconstruction. We compare two related\nmodel families, SigLIP and SigLIP2, which differ only in their training\nobjective, and show that encoders pre-trained on image-based tasks retain\nsignificantly more image information than those trained on non-image tasks such\nas contrastive learning. We further apply our method to a range of vision\nencoders, ranking them by the informativeness of their feature representations.\nFinally, we demonstrate that manipulating the feature space yields predictable\nchanges in reconstructed images, revealing that orthogonal rotations (rather\nthan spatial transformations) control color encoding. Our approach can be\napplied to any vision encoder, shedding light on the inner structure of its\nfeature space. The code and model weights to reproduce the experiments are\navailable in GitHub.", "published": "2025-06-09 14:32:18", "link": "http://arxiv.org/abs/2506.07803v1", "categories": ["cs.CV", "68T10, 68T30, 68T45", "I.2.10"], "primary_category": "cs.CV"}
{"title": "Design and Evaluation of Deep Learning-Based Dual-Spectrum Image Fusion Methods", "abstract": "Visible images offer rich texture details, while infrared images emphasize\nsalient targets. Fusing these complementary modalities enhances scene\nunderstanding, particularly for advanced vision tasks under challenging\nconditions. Recently, deep learning-based fusion methods have gained attention,\nbut current evaluations primarily rely on general-purpose metrics without\nstandardized benchmarks or downstream task performance. Additionally, the lack\nof well-developed dual-spectrum datasets and fair algorithm comparisons hinders\nprogress.\n  To address these gaps, we construct a high-quality dual-spectrum dataset\ncaptured in campus environments, comprising 1,369 well-aligned visible-infrared\nimage pairs across four representative scenarios: daytime, nighttime, smoke\nocclusion, and underpasses. We also propose a comprehensive and fair evaluation\nframework that integrates fusion speed, general metrics, and object detection\nperformance using the lang-segment-anything model to ensure fairness in\ndownstream evaluation.\n  Extensive experiments benchmark several state-of-the-art fusion algorithms\nunder this framework. Results demonstrate that fusion models optimized for\ndownstream tasks achieve superior performance in target detection, especially\nin low-light and occluded scenes. Notably, some algorithms that perform well on\ngeneral metrics do not translate to strong downstream performance, highlighting\nlimitations of current evaluation practices and validating the necessity of our\nproposed framework.\n  The main contributions of this work are: (1)a campus-oriented dual-spectrum\ndataset with diverse and challenging scenes; (2) a task-aware, comprehensive\nevaluation framework; and (3) thorough comparative analysis of leading fusion\nmethods across multiple datasets, offering insights for future development.", "published": "2025-06-09 13:56:32", "link": "http://arxiv.org/abs/2506.07779v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Language-Vision Planner and Executor for Text-to-Visual Reasoning", "abstract": "The advancement in large language models (LLMs) and large vision models has\nfueled the rapid progress in multi-modal visual-text reasoning capabilities.\nHowever, existing vision-language models (VLMs) to date suffer from\ngeneralization performance. Inspired by recent development in LLMs for visual\nreasoning, this paper presents VLAgent, an AI system that can create a\nstep-by-step visual reasoning plan with an easy-to-understand script and\nexecute each step of the plan in real time by integrating planning script with\nexecution verifications via an automated process supported by VLAgent. In the\ntask planning phase, VLAgent fine-tunes an LLM through in-context learning to\ngenerate a step-by-step planner for each user-submitted text-visual reasoning\ntask. During the plan execution phase, VLAgent progressively refines the\ncomposition of neuro-symbolic executable modules to generate high-confidence\nreasoning results. VLAgent has three unique design characteristics: First, we\nimprove the quality of plan generation through in-context learning, improving\nlogic reasoning by reducing erroneous logic steps, incorrect programs, and LLM\nhallucinations. Second, we design a syntax-semantics parser to identify and\ncorrect additional logic errors of the LLM-generated planning script prior to\nlaunching the plan executor. Finally, we employ the ensemble method to improve\nthe generalization performance of our step-executor. Extensive experiments with\nfour visual reasoning benchmarks (GQA, MME, NLVR2, VQAv2) show that VLAgent\nachieves significant performance enhancement for multimodal text-visual\nreasoning applications, compared to the exiting representative VLMs and LLM\nbased visual composition approaches like ViperGPT and VisProg, thanks to the\nnovel optimization modules of VLAgent back-engine (SS-Parser, Plan Repairer,\nOutput Verifiers). Code and data will be made available upon paper acceptance.", "published": "2025-06-09 13:55:55", "link": "http://arxiv.org/abs/2506.07778v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Trend-Aware Fashion Recommendation with Visual Segmentation and Semantic Similarity", "abstract": "We introduce a trend-aware and visually-grounded fashion recommendation\nsystem that integrates deep visual representations, garment-aware segmentation,\nsemantic category similarity and user behavior simulation. Our pipeline\nextracts focused visual embeddings by masking non-garment regions via semantic\nsegmentation followed by feature extraction using pretrained CNN backbones\n(ResNet-50, DenseNet-121, VGG16). To simulate realistic shopping behavior, we\ngenerate synthetic purchase histories influenced by user-specific trendiness\nand item popularity. Recommendations are computed using a weighted scoring\nfunction that fuses visual similarity, semantic coherence and popularity\nalignment. Experiments on the DeepFashion dataset demonstrate consistent gender\nalignment and improved category relevance, with ResNet-50 achieving 64.95%\ncategory similarity and lowest popularity MAE. An ablation study confirms the\ncomplementary roles of visual and popularity cues. Our method provides a\nscalable framework for personalized fashion recommendations that balances\nindividual style with emerging trends. Our implementation is available at\nhttps://github.com/meddjilani/FashionRecommender", "published": "2025-06-09 13:48:16", "link": "http://arxiv.org/abs/2506.07773v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Difference Inversion: Interpolate and Isolate the Difference with Token Consistency for Image Analogy Generation", "abstract": "How can we generate an image B' that satisfies A:A'::B:B', given the input\nimages A,A' and B? Recent works have tackled this challenge through approaches\nlike visual in-context learning or visual instruction. However, these methods\nare typically limited to specific models (e.g. InstructPix2Pix. Inpainting\nmodels) rather than general diffusion models (e.g. Stable Diffusion, SDXL).\nThis dependency may lead to inherited biases or lower editing capabilities. In\nthis paper, we propose Difference Inversion, a method that isolates only the\ndifference from A and A' and applies it to B to generate a plausible B'. To\naddress model dependency, it is crucial to structure prompts in the form of a\n\"Full Prompt\" suitable for input to stable diffusion models, rather than using\nan \"Instruction Prompt\". To this end, we accurately extract the Difference\nbetween A and A' and combine it with the prompt of B, enabling a plug-and-play\napplication of the difference. To extract a precise difference, we first\nidentify it through 1) Delta Interpolation. Additionally, to ensure accurate\ntraining, we propose the 2) Token Consistency Loss and 3) Zero Initialization\nof Token Embeddings. Our extensive experiments demonstrate that Difference\nInversion outperforms existing baselines both quantitatively and qualitatively,\nindicating its ability to generate more feasible B' in a model-agnostic manner.", "published": "2025-06-09 13:34:47", "link": "http://arxiv.org/abs/2506.07750v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Flow-Anything: Learning Real-World Optical Flow Estimation from Large-Scale Single-view Images", "abstract": "Optical flow estimation is a crucial subfield of computer vision, serving as\na foundation for video tasks. However, the real-world robustness is limited by\nanimated synthetic datasets for training. This introduces domain gaps when\napplied to real-world applications and limits the benefits of scaling up\ndatasets. To address these challenges, we propose \\textbf{Flow-Anything}, a\nlarge-scale data generation framework designed to learn optical flow estimation\nfrom any single-view images in the real world. We employ two effective steps to\nmake data scaling-up promising. First, we convert a single-view image into a 3D\nrepresentation using advanced monocular depth estimation networks. This allows\nus to render optical flow and novel view images under a virtual camera. Second,\nwe develop an Object-Independent Volume Rendering module and a Depth-Aware\nInpainting module to model the dynamic objects in the 3D representation. These\ntwo steps allow us to generate realistic datasets for training from large-scale\nsingle-view images, namely \\textbf{FA-Flow Dataset}. For the first time, we\ndemonstrate the benefits of generating optical flow training data from\nlarge-scale real-world images, outperforming the most advanced unsupervised\nmethods and supervised methods on synthetic datasets. Moreover, our models\nserve as a foundation model and enhance the performance of various downstream\nvideo tasks.", "published": "2025-06-09 13:23:44", "link": "http://arxiv.org/abs/2506.07740v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SpikeSMOKE: Spiking Neural Networks for Monocular 3D Object Detection with Cross-Scale Gated Coding", "abstract": "Low energy consumption for 3D object detection is an important research area\nbecause of the increasing energy consumption with their wide application in\nfields such as autonomous driving. The spiking neural networks (SNNs) with\nlow-power consumption characteristics can provide a novel solution for this\nresearch. Therefore, we apply SNNs to monocular 3D object detection and propose\nthe SpikeSMOKE architecture in this paper, which is a new attempt for low-power\nmonocular 3D object detection. As we all know, discrete signals of SNNs will\ngenerate information loss and limit their feature expression ability compared\nwith the artificial neural networks (ANNs).In order to address this issue,\ninspired by the filtering mechanism of biological neuronal synapses, we propose\na cross-scale gated coding mechanism(CSGC), which can enhance feature\nrepresentation by combining cross-scale fusion of attentional methods and gated\nfiltering mechanisms.In addition, to reduce the computation and increase the\nspeed of training, we present a novel light-weight residual block that can\nmaintain spiking computing paradigm and the highest possible detection\nperformance. Compared to the baseline SpikeSMOKE under the 3D Object Detection,\nthe proposed SpikeSMOKE with CSGC can achieve 11.78 (+2.82, Easy), 10.69 (+3.2,\nModerate), and 10.48 (+3.17, Hard) on the KITTI autonomous driving dataset by\nAP|R11 at 0.7 IoU threshold, respectively. It is important to note that the\nresults of SpikeSMOKE can significantly reduce energy consumption compared to\nthe results on SMOKE. For example,the energy consumption can be reduced by\n72.2% on the hard category, while the detection performance is reduced by only\n4%. SpikeSMOKE-L (lightweight) can further reduce the amount of parameters by 3\ntimes and computation by 10 times compared to SMOKE.", "published": "2025-06-09 13:20:10", "link": "http://arxiv.org/abs/2506.07737v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Language Embedding Meets Dynamic Graph: A New Exploration for Neural Architecture Representation Learning", "abstract": "Neural Architecture Representation Learning aims to transform network models\ninto feature representations for predicting network attributes, playing a\ncrucial role in deploying and designing networks for real-world applications.\nRecently, inspired by the success of transformers, transformer-based models\nintegrated with Graph Neural Networks (GNNs) have achieved significant progress\nin representation learning. However, current methods still have some\nlimitations. First, existing methods overlook hardware attribute information,\nwhich conflicts with the current trend of diversified deep learning hardware\nand limits the practical applicability of models. Second, current encoding\napproaches rely on static adjacency matrices to represent topological\nstructures, failing to capture the structural differences between computational\nnodes, which ultimately compromises encoding effectiveness. In this paper, we\nintroduce LeDG-Former, an innovative framework that addresses these limitations\nthrough the synergistic integration of language-based semantic embedding and\ndynamic graph representation learning. Specifically, inspired by large language\nmodels (LLMs), we propose a language embedding framework where both neural\narchitectures and hardware platform specifications are projected into a unified\nsemantic space through tokenization and LLM processing, enabling zero-shot\nprediction across different hardware platforms for the first time. Then, we\npropose a dynamic graph-based transformer for modeling neural architectures,\nresulting in improved neural architecture modeling performance. On the NNLQP\nbenchmark, LeDG-Former surpasses previous methods, establishing a new SOTA\nwhile demonstrating the first successful cross-hardware latency prediction\ncapability. Furthermore, our framework achieves superior performance on the\ncell-structured NAS-Bench-101 and NAS-Bench-201 datasets.", "published": "2025-06-09 13:20:02", "link": "http://arxiv.org/abs/2506.07735v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "ReverB-SNN: Reversing Bit of the Weight and Activation for Spiking Neural Networks", "abstract": "The Spiking Neural Network (SNN), a biologically inspired neural network\ninfrastructure, has garnered significant attention recently. SNNs utilize\nbinary spike activations for efficient information transmission, replacing\nmultiplications with additions, thereby enhancing energy efficiency. However,\nbinary spike activation maps often fail to capture sufficient data information,\nresulting in reduced accuracy. To address this challenge, we advocate reversing\nthe bit of the weight and activation for SNNs, called \\textbf{ReverB-SNN},\ninspired by recent findings that highlight greater accuracy degradation from\nquantizing activations compared to weights. Specifically, our method employs\nreal-valued spike activations alongside binary weights in SNNs. This preserves\nthe event-driven and multiplication-free advantages of standard SNNs while\nenhancing the information capacity of activations. Additionally, we introduce a\ntrainable factor within binary weights to adaptively learn suitable weight\namplitudes during training, thereby increasing network capacity. To maintain\nefficiency akin to vanilla \\textbf{ReverB-SNN}, our trainable binary weight\nSNNs are converted back to standard form using a re-parameterization technique\nduring inference. Extensive experiments across various network architectures\nand datasets, both static and dynamic, demonstrate that our approach\nconsistently outperforms state-of-the-art methods.", "published": "2025-06-09 13:02:03", "link": "http://arxiv.org/abs/2506.07720v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Fine-Grained Motion Compression and Selective Temporal Fusion for Neural B-Frame Video Coding", "abstract": "With the remarkable progress in neural P-frame video coding, neural B-frame\ncoding has recently emerged as a critical research direction. However, most\nexisting neural B-frame codecs directly adopt P-frame coding tools without\nadequately addressing the unique challenges of B-frame compression, leading to\nsuboptimal performance. To bridge this gap, we propose novel enhancements for\nmotion compression and temporal fusion for neural B-frame coding. First, we\ndesign a fine-grained motion compression method. This method incorporates an\ninteractive dual-branch motion auto-encoder with per-branch adaptive\nquantization steps, which enables fine-grained compression of bi-directional\nmotion vectors while accommodating their asymmetric bitrate allocation and\nreconstruction quality requirements. Furthermore, this method involves an\ninteractive motion entropy model that exploits correlations between\nbi-directional motion latent representations by interactively leveraging\npartitioned latent segments as directional priors. Second, we propose a\nselective temporal fusion method that predicts bi-directional fusion weights to\nachieve discriminative utilization of bi-directional multi-scale temporal\ncontexts with varying qualities. Additionally, this method introduces a\nhyperprior-based implicit alignment mechanism for contextual entropy modeling.\nBy treating the hyperprior as a surrogate for the contextual latent\nrepresentation, this mechanism implicitly mitigates the misalignment in the\nfused bi-directional temporal priors. Extensive experiments demonstrate that\nour proposed codec outperforms state-of-the-art neural B-frame codecs and\nachieves comparable or even superior compression performance to the H.266/VVC\nreference software under random-access configurations.", "published": "2025-06-09 12:51:10", "link": "http://arxiv.org/abs/2506.07709v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Adaptive Blind Super-Resolution Network for Spatial-Specific and Spatial-Agnostic Degradations", "abstract": "Prior methodologies have disregarded the diversities among distinct\ndegradation types during image reconstruction, employing a uniform network\nmodel to handle multiple deteriorations. Nevertheless, we discover that\nprevalent degradation modalities, including sampling, blurring, and noise, can\nbe roughly categorized into two classes. We classify the first class as\nspatial-agnostic dominant degradations, less affected by regional changes in\nimage space, such as downsampling and noise degradation. The second class\ndegradation type is intimately associated with the spatial position of the\nimage, such as blurring, and we identify them as spatial-specific dominant\ndegradations. We introduce a dynamic filter network integrating global and\nlocal branches to address these two degradation types. This network can greatly\nalleviate the practical degradation problem. Specifically, the global dynamic\nfiltering layer can perceive the spatial-agnostic dominant degradation in\ndifferent images by applying weights generated by the attention mechanism to\nmultiple parallel standard convolution kernels, enhancing the network's\nrepresentation ability. Meanwhile, the local dynamic filtering layer converts\nfeature maps of the image into a spatially specific dynamic filtering operator,\nwhich performs spatially specific convolution operations on the image features\nto handle spatial-specific dominant degradations. By effectively integrating\nboth global and local dynamic filtering operators, our proposed method\noutperforms state-of-the-art blind super-resolution algorithms in both\nsynthetic and real image datasets.", "published": "2025-06-09 12:48:17", "link": "http://arxiv.org/abs/2506.07705v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "OpenSplat3D: Open-Vocabulary 3D Instance Segmentation using Gaussian Splatting", "abstract": "3D Gaussian Splatting (3DGS) has emerged as a powerful representation for\nneural scene reconstruction, offering high-quality novel view synthesis while\nmaintaining computational efficiency. In this paper, we extend the capabilities\nof 3DGS beyond pure scene representation by introducing an approach for\nopen-vocabulary 3D instance segmentation without requiring manual labeling,\ntermed OpenSplat3D. Our method leverages feature-splatting techniques to\nassociate semantic information with individual Gaussians, enabling fine-grained\nscene understanding. We incorporate Segment Anything Model instance masks with\na contrastive loss formulation as guidance for the instance features to achieve\naccurate instance-level segmentation. Furthermore, we utilize language\nembeddings of a vision-language model, allowing for flexible, text-driven\ninstance identification. This combination enables our system to identify and\nsegment arbitrary objects in 3D scenes based on natural language descriptions.\nWe show results on LERF-mask and LERF-OVS as well as the full ScanNet++\nvalidation set, demonstrating the effectiveness of our approach.", "published": "2025-06-09 12:37:15", "link": "http://arxiv.org/abs/2506.07697v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ProSplat: Improved Feed-Forward 3D Gaussian Splatting for Wide-Baseline Sparse Views", "abstract": "Feed-forward 3D Gaussian Splatting (3DGS) has recently demonstrated promising\nresults for novel view synthesis (NVS) from sparse input views, particularly\nunder narrow-baseline conditions. However, its performance significantly\ndegrades in wide-baseline scenarios due to limited texture details and\ngeometric inconsistencies across views. To address these challenges, in this\npaper, we propose ProSplat, a two-stage feed-forward framework designed for\nhigh-fidelity rendering under wide-baseline conditions. The first stage\ninvolves generating 3D Gaussian primitives via a 3DGS generator. In the second\nstage, rendered views from these primitives are enhanced through an improvement\nmodel. Specifically, this improvement model is based on a one-step diffusion\nmodel, further optimized by our proposed Maximum Overlap Reference view\nInjection (MORI) and Distance-Weighted Epipolar Attention (DWEA). MORI\nsupplements missing texture and color by strategically selecting a reference\nview with maximum viewpoint overlap, while DWEA enforces geometric consistency\nusing epipolar constraints. Additionally, we introduce a divide-and-conquer\ntraining strategy that aligns data distributions between the two stages through\njoint optimization. We evaluate ProSplat on the RealEstate10K and DL3DV-10K\ndatasets under wide-baseline settings. Experimental results demonstrate that\nProSplat achieves an average improvement of 1 dB in PSNR compared to recent\nSOTA methods.", "published": "2025-06-09 11:45:50", "link": "http://arxiv.org/abs/2506.07670v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PIG: Physically-based Multi-Material Interaction with 3D Gaussians", "abstract": "3D Gaussian Splatting has achieved remarkable success in reconstructing both\nstatic and dynamic 3D scenes. However, in a scene represented by 3D Gaussian\nprimitives, interactions between objects suffer from inaccurate 3D\nsegmentation, imprecise deformation among different materials, and severe\nrendering artifacts. To address these challenges, we introduce PIG:\nPhysically-Based Multi-Material Interaction with 3D Gaussians, a novel approach\nthat combines 3D object segmentation with the simulation of interacting objects\nin high precision. Firstly, our method facilitates fast and accurate mapping\nfrom 2D pixels to 3D Gaussians, enabling precise 3D object-level segmentation.\nSecondly, we assign unique physical properties to correspondingly segmented\nobjects within the scene for multi-material coupled interactions. Finally, we\nhave successfully embedded constraint scales into deformation gradients,\nspecifically clamping the scaling and rotation properties of the Gaussian\nprimitives to eliminate artifacts and achieve geometric fidelity and visual\nconsistency. Experimental results demonstrate that our method not only\noutperforms the state-of-the-art (SOTA) in terms of visual quality, but also\nopens up new directions and pipelines for the field of physically realistic\nscene generation.", "published": "2025-06-09 11:25:21", "link": "http://arxiv.org/abs/2506.07657v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Synthetic Visual Genome", "abstract": "Reasoning over visual relationships-spatial, functional, interactional,\nsocial, etc.-is considered to be a fundamental component of human cognition.\nYet, despite the major advances in visual comprehension in multimodal language\nmodels (MLMs), precise reasoning over relationships and their generations\nremains a challenge. We introduce ROBIN: an MLM instruction-tuned with densely\nannotated relationships capable of constructing high-quality dense scene graphs\nat scale. To train ROBIN, we curate SVG, a synthetic scene graph dataset by\ncompleting the missing relations of selected objects in existing scene graphs\nusing a teacher MLM and a carefully designed filtering process to ensure\nhigh-quality. To generate more accurate and rich scene graphs at scale for any\nimage, we introduce SG-EDIT: a self-distillation framework where GPT-4o further\nrefines ROBIN's predicted scene graphs by removing unlikely relations and/or\nsuggesting relevant ones. In total, our dataset contains 146K images and 5.6M\nrelationships for 2.6M objects. Results show that our ROBIN-3B model, despite\nbeing trained on less than 3 million instances, outperforms similar-size models\ntrained on over 300 million instances on relationship understanding benchmarks,\nand even surpasses larger models up to 13B parameters. Notably, it achieves\nstate-of-the-art performance in referring expression comprehension with a score\nof 88.9, surpassing the previous best of 87.4. Our results suggest that\ntraining on the refined scene graph data is crucial to maintaining high\nperformance across diverse visual reasoning task.", "published": "2025-06-09 11:09:10", "link": "http://arxiv.org/abs/2506.07643v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HieraEdgeNet: A Multi-Scale Edge-Enhanced Framework for Automated Pollen Recognition", "abstract": "Automated pollen recognition is vital to paleoclimatology, biodiversity\nmonitoring, and public health, yet conventional methods are hampered by\ninefficiency and subjectivity. Existing deep learning models often struggle to\nachieve the requisite localization accuracy for microscopic targets like\npollen, which are characterized by their minute size, indistinct edges, and\ncomplex backgrounds. To overcome this limitation, we introduce HieraEdgeNet, a\nmulti-scale edge-enhancement framework. The framework's core innovation is the\nintroduction of three synergistic modules: the Hierarchical Edge Module (HEM),\nwhich explicitly extracts a multi-scale pyramid of edge features that\ncorresponds to the semantic hierarchy at early network stages; the Synergistic\nEdge Fusion (SEF) module, for deeply fusing these edge priors with semantic\ninformation at each respective scale; and the Cross Stage Partial Omni-Kernel\nModule (CSPOKM), which maximally refines the most detail-rich feature layers\nusing an Omni-Kernel operator - comprising anisotropic large-kernel\nconvolutions and mixed-domain attention - all within a computationally\nefficient Cross-Stage Partial (CSP) framework. On a large-scale dataset\ncomprising 120 pollen classes, HieraEdgeNet achieves a mean Average Precision\n(mAP@.5) of 0.9501, significantly outperforming state-of-the-art baseline\nmodels such as YOLOv12n and RT-DETR. Furthermore, qualitative analysis confirms\nthat our approach generates feature representations that are more precisely\nfocused on object boundaries. By systematically integrating edge information,\nHieraEdgeNet provides a robust and powerful solution for high-precision,\nhigh-efficiency automated detection of microscopic objects.", "published": "2025-06-09 11:03:31", "link": "http://arxiv.org/abs/2506.07637v1", "categories": ["cs.CV", "cs.LG", "68T07, 68T45", "I.2.10; I.4.9; I.5.4"], "primary_category": "cs.CV"}
{"title": "HuSc3D: Human Sculpture dataset for 3D object reconstruction", "abstract": "3D scene reconstruction from 2D images is one of the most important tasks in\ncomputer graphics. Unfortunately, existing datasets and benchmarks concentrate\non idealized synthetic or meticulously captured realistic data. Such benchmarks\nfail to convey the inherent complexities encountered in newly acquired\nreal-world scenes. In such scenes especially those acquired outside, the\nbackground is often dynamic, and by popular usage of cell phone cameras, there\nmight be discrepancies in, e.g., white balance. To address this gap, we present\nHuSc3D, a novel dataset specifically designed for rigorous benchmarking of 3D\nreconstruction models under realistic acquisition challenges. Our dataset\nuniquely features six highly detailed, fully white sculptures characterized by\nintricate perforations and minimal textural and color variation. Furthermore,\nthe number of images per scene varies significantly, introducing the additional\nchallenge of limited training data for some instances alongside scenes with a\nstandard number of views. By evaluating popular 3D reconstruction methods on\nthis diverse dataset, we demonstrate the distinctiveness of HuSc3D in\neffectively differentiating model performance, particularly highlighting the\nsensitivity of methods to fine geometric details, color ambiguity, and varying\ndata availability--limitations often masked by more conventional datasets.", "published": "2025-06-09 10:47:02", "link": "http://arxiv.org/abs/2506.07628v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Event-Priori-Based Vision-Language Model for Efficient Visual Understanding", "abstract": "Large Language Model (LLM)-based Vision-Language Models (VLMs) have\nsubstantially extended the boundaries of visual understanding capabilities.\nHowever, their high computational demands hinder deployment on\nresource-constrained edge devices. A key source of inefficiency stems from the\nVLM's need to process dense and redundant visual information. Visual inputs\ncontain significant regions irrelevant to text semantics, rendering the\nassociated computations ineffective for inference. This paper introduces a\nnovel Event-Priori-Based Vision-Language Model, termed EP-VLM. Its core\ncontribution is a novel mechanism leveraging motion priors derived from dynamic\nevent vision to enhance VLM efficiency. Inspired by human visual cognition,\nEP-VLM first employs event data to guide the patch-wise sparsification of RGB\nvisual inputs, progressively concentrating VLM computation on salient regions\nof the visual input. Subsequently, we construct a position-preserving\ntokenization strategy for the visual encoder within the VLM architecture. This\nstrategy processes the event-guided, unstructured, sparse visual input while\naccurately preserving positional understanding within the visual input.\nExperimental results demonstrate that EP-VLM achieves significant efficiency\nimprovements while maintaining nearly lossless accuracy compared to baseline\nmodels from the Qwen2-VL series. For instance, against the original\nQwen2-VL-2B, EP-VLM achieves 50% FLOPs savings while retaining 98% of the\noriginal accuracy on the RealWorldQA dataset. This work demonstrates the\npotential of event-based vision priors for improving VLM inference efficiency,\npaving the way for creating more efficient and deployable VLMs for sustainable\nvisual understanding at the edge.", "published": "2025-06-09 10:45:35", "link": "http://arxiv.org/abs/2506.07627v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Scaling Human Activity Recognition: A Comparative Evaluation of Synthetic Data Generation and Augmentation Techniques", "abstract": "Human activity recognition (HAR) is often limited by the scarcity of labeled\ndatasets due to the high cost and complexity of real-world data collection. To\nmitigate this, recent work has explored generating virtual inertial measurement\nunit (IMU) data via cross-modality transfer. While video-based and\nlanguage-based pipelines have each shown promise, they differ in assumptions\nand computational cost. Moreover, their effectiveness relative to traditional\nsensor-level data augmentation remains unclear. In this paper, we present a\ndirect comparison between these two virtual IMU generation approaches against\nclassical data augmentation techniques. We construct a large-scale virtual IMU\ndataset spanning 100 diverse activities from Kinetics-400 and simulate sensor\nsignals at 22 body locations. The three data generation strategies are\nevaluated on benchmark HAR datasets (UTD-MHAD, PAMAP2, HAD-AW) using four\npopular models. Results show that virtual IMU data significantly improves\nperformance over real or augmented data alone, particularly under limited-data\nconditions. We offer practical guidance on choosing data generation strategies\nand highlight the distinct advantages and disadvantages of each approach.", "published": "2025-06-09 10:25:53", "link": "http://arxiv.org/abs/2506.07612v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DragNeXt: Rethinking Drag-Based Image Editing", "abstract": "Drag-Based Image Editing (DBIE), which allows users to manipulate images by\ndirectly dragging objects within them, has recently attracted much attention\nfrom the community. However, it faces two key challenges:\n(\\emph{\\textcolor{magenta}{i}}) point-based drag is often highly ambiguous and\ndifficult to align with users' intentions; (\\emph{\\textcolor{magenta}{ii}})\ncurrent DBIE methods primarily rely on alternating between motion supervision\nand point tracking, which is not only cumbersome but also fails to produce\nhigh-quality results. These limitations motivate us to explore DBIE from a new\nperspective -- redefining it as deformation, rotation, and translation of\nuser-specified handle regions. Thereby, by requiring users to explicitly\nspecify both drag areas and types, we can effectively address the ambiguity\nissue. Furthermore, we propose a simple-yet-effective editing framework, dubbed\n\\textcolor{SkyBlue}{\\textbf{DragNeXt}}. It unifies DBIE as a Latent Region\nOptimization (LRO) problem and solves it through Progressive Backward\nSelf-Intervention (PBSI), simplifying the overall procedure of DBIE while\nfurther enhancing quality by fully leveraging region-level structure\ninformation and progressive guidance from intermediate drag states. We validate\n\\textcolor{SkyBlue}{\\textbf{DragNeXt}} on our NextBench, and extensive\nexperiments demonstrate that our proposed method can significantly outperform\nexisting approaches. Code will be released on github.", "published": "2025-06-09 10:24:29", "link": "http://arxiv.org/abs/2506.07611v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Explore the vulnerability of black-box models via diffusion models", "abstract": "Recent advancements in diffusion models have enabled high-fidelity and\nphotorealistic image generation across diverse applications. However, these\nmodels also present security and privacy risks, including copyright violations,\nsensitive information leakage, and the creation of harmful or offensive content\nthat could be exploited maliciously. In this study, we uncover a novel security\nthreat where an attacker leverages diffusion model APIs to generate synthetic\nimages, which are then used to train a high-performing substitute model. This\nenables the attacker to execute model extraction and transfer-based adversarial\nattacks on black-box classification models with minimal queries, without\nneeding access to the original training data. The generated images are\nsufficiently high-resolution and diverse to train a substitute model whose\noutputs closely match those of the target model. Across the seven benchmarks,\nincluding CIFAR and ImageNet subsets, our method shows an average improvement\nof 27.37% over state-of-the-art methods while using just 0.01 times of the\nquery budget, achieving a 98.68% success rate in adversarial attacks on the\ntarget model.", "published": "2025-06-09 09:36:31", "link": "http://arxiv.org/abs/2506.07590v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Super Encoding Network: Recursive Association of Multi-Modal Encoders for Video Understanding", "abstract": "Video understanding has been considered as one critical step towards world\nmodeling, which is an important long-term problem in AI research. Recently,\nmulti-modal foundation models have shown such potential via large-scale\npretraining. However, these models simply align encoders of different\nmodalities via contrastive learning, while lacking deeper multi-modal\ninteractions, which is critical for understanding complex target movements with\ndiversified video scenes. To fill this gap, we propose a unified Super Encoding\nNetwork (SEN) for video understanding, which builds up such distinct\ninteractions through recursive association of multi-modal encoders in the\nfoundation models. Specifically, we creatively treat those well-trained\nencoders as \"super neurons\" in our SEN. Via designing a Recursive Association\n(RA) block, we progressively fuse multi-modalities with the input video, based\non knowledge integrating, distributing, and prompting of super neurons in a\nrecursive manner. In this way, our SEN can effectively encode deeper\nmulti-modal interactions, for prompting various video understanding tasks in\ndownstream. Extensive experiments show that, our SEN can remarkably boost the\nfour most representative video tasks, including tracking, recognition,\nchatting, and editing, e.g., for pixel-level tracking, the average jaccard\nindex improves 2.7%, temporal coherence(TC) drops 8.8% compared to the popular\nCaDeX++ approach. For one-shot video editing, textual alignment improves 6.4%,\nand frame consistency increases 4.1% compared to the popular TuneA-Video\napproach.", "published": "2025-06-09 09:20:21", "link": "http://arxiv.org/abs/2506.07576v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Uncertainty-o: One Model-agnostic Framework for Unveiling Uncertainty in Large Multimodal Models", "abstract": "Large Multimodal Models (LMMs), harnessing the complementarity among diverse\nmodalities, are often considered more robust than pure Language Large Models\n(LLMs); yet do LMMs know what they do not know? There are three key open\nquestions remaining: (1) how to evaluate the uncertainty of diverse LMMs in a\nunified manner, (2) how to prompt LMMs to show its uncertainty, and (3) how to\nquantify uncertainty for downstream tasks. In an attempt to address these\nchallenges, we introduce Uncertainty-o: (1) a model-agnostic framework designed\nto reveal uncertainty in LMMs regardless of their modalities, architectures, or\ncapabilities, (2) an empirical exploration of multimodal prompt perturbations\nto uncover LMM uncertainty, offering insights and findings, and (3) derive the\nformulation of multimodal semantic uncertainty, which enables quantifying\nuncertainty from multimodal responses. Experiments across 18 benchmarks\nspanning various modalities and 10 LMMs (both open- and closed-source)\ndemonstrate the effectiveness of Uncertainty-o in reliably estimating LMM\nuncertainty, thereby enhancing downstream tasks such as hallucination\ndetection, hallucination mitigation, and uncertainty-aware Chain-of-Thought\nreasoning.", "published": "2025-06-09 09:20:20", "link": "http://arxiv.org/abs/2506.07575v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Towards the Influence of Text Quantity on Writer Retrieval", "abstract": "This paper investigates the task of writer retrieval, which identifies\ndocuments authored by the same individual within a dataset based on handwriting\nsimilarities. While existing datasets and methodologies primarily focus on page\nlevel retrieval, we explore the impact of text quantity on writer retrieval\nperformance by evaluating line- and word level retrieval. We examine three\nstate-of-the-art writer retrieval systems, including both handcrafted and deep\nlearning-based approaches, and analyze their performance using varying amounts\nof text. Our experiments on the CVL and IAM dataset demonstrate that while\nperformance decreases by 20-30% when only one line of text is used as query and\ngallery, retrieval accuracy remains above 90% of full-page performance when at\nleast four lines are included. We further show that text-dependent retrieval\ncan maintain strong performance in low-text scenarios. Our findings also\nhighlight the limitations of handcrafted features in low-text scenarios, with\ndeep learning-based methods like NetVLAD outperforming traditional VLAD\nencoding.", "published": "2025-06-09 09:05:15", "link": "http://arxiv.org/abs/2506.07566v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "OpenDance: Multimodal Controllable 3D Dance Generation Using Large-scale Internet Data", "abstract": "Music-driven dance generation offers significant creative potential yet faces\nconsiderable challenges. The absence of fine-grained multimodal data and the\ndifficulty of flexible multi-conditional generation limit previous works on\ngeneration controllability and diversity in practice. In this paper, we build\nOpenDance5D, an extensive human dance dataset comprising over 101 hours across\n14 distinct genres. Each sample has five modalities to facilitate robust\ncross-modal learning: RGB video, audio, 2D keypoints, 3D motion, and\nfine-grained textual descriptions from human arts. Furthermore, we propose\nOpenDanceNet, a unified masked modeling framework for controllable dance\ngeneration conditioned on music and arbitrary combinations of text prompts,\nkeypoints, or character positioning. Comprehensive experiments demonstrate that\nOpenDanceNet achieves high-fidelity and flexible controllability.", "published": "2025-06-09 09:05:13", "link": "http://arxiv.org/abs/2506.07565v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Cross-channel Perception Learning for H&E-to-IHC Virtual Staining", "abstract": "With the rapid development of digital pathology, virtual staining has become\na key technology in multimedia medical information systems, offering new\npossibilities for the analysis and diagnosis of pathological images. However,\nexisting H&E-to-IHC studies often overlook the cross-channel correlations\nbetween cell nuclei and cell membranes. To address this issue, we propose a\nnovel Cross-Channel Perception Learning (CCPL) strategy. Specifically, CCPL\nfirst decomposes HER2 immunohistochemical staining into Hematoxylin and DAB\nstaining channels, corresponding to cell nuclei and cell membranes,\nrespectively. Using the pathology foundation model Gigapath's Tile Encoder,\nCCPL extracts dual-channel features from both the generated and real images and\nmeasures cross-channel correlations between nuclei and membranes. The features\nof the generated and real stained images, obtained through the Tile Encoder,\nare also used to calculate feature distillation loss, enhancing the model's\nfeature extraction capabilities without increasing the inference burden.\nAdditionally, CCPL performs statistical analysis on the focal optical density\nmaps of both single channels to ensure consistency in staining distribution and\nintensity. Experimental results, based on quantitative metrics such as PSNR,\nSSIM, PCC, and FID, along with professional evaluations from pathologists,\ndemonstrate that CCPL effectively preserves pathological features, generates\nhigh-quality virtual stained images, and provides robust support for automated\npathological diagnosis using multimedia medical data.", "published": "2025-06-09 08:54:15", "link": "http://arxiv.org/abs/2506.07559v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts", "abstract": "One of the primary challenges in optimizing large language models (LLMs) for\nlong-context inference lies in the high memory consumption of the Key-Value\n(KV) cache. Existing approaches, such as quantization, have demonstrated\npromising results in reducing memory usage. However, current quantization\nmethods cannot take both effectiveness and efficiency into account. In this\npaper, we propose MoQAE, a novel mixed-precision quantization method via\nmixture of quantization-aware experts. First, we view different quantization\nbit-width configurations as experts and use the traditional mixture of experts\n(MoE) method to select the optimal configuration. To avoid the inefficiency\ncaused by inputting tokens one by one into the router in the traditional MoE\nmethod, we input the tokens into the router chunk by chunk. Second, we design a\nlightweight router-only fine-tuning process to train MoQAE with a comprehensive\nloss to learn the trade-off between model accuracy and memory usage. Finally,\nwe introduce a routing freezing (RF) and a routing sharing (RS) mechanism to\nfurther reduce the inference overhead. Extensive experiments on multiple\nbenchmark datasets demonstrate that our method outperforms state-of-the-art KV\ncache quantization approaches in both efficiency and effectiveness.", "published": "2025-06-09 08:16:24", "link": "http://arxiv.org/abs/2506.07533v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation", "abstract": "Vision-Language-Action (VLA) models have shown impressive capabilities across\na wide range of robotics manipulation tasks. However, their growing model size\nposes significant challenges for deployment on resource-constrained robotic\nsystems. While 1-bit pretraining has proven effective for enhancing the\ninference efficiency of large language models with minimal performance loss,\nits application to VLA models remains underexplored. In this work, we present\nBitVLA, the first 1-bit VLA model for robotics manipulation, in which every\nparameter is ternary, i.e., {-1, 0, 1}. To further reduce the memory footprint\nof the vision encoder, we propose the distillation-aware training strategy that\ncompresses the full-precision encoder to 1.58-bit weights. During this process,\na full-precision encoder serves as a teacher model to better align latent\nrepresentations. Despite the lack of large-scale robotics pretraining, BitVLA\nachieves performance comparable to the state-of-the-art model OpenVLA-OFT with\n4-bit post-training quantization on the LIBERO benchmark, while consuming only\n29.8% of the memory. These results highlight BitVLA's promise for deployment on\nmemory-constrained edge devices. We release the code and model weights in\nhttps://github.com/ustcwhy/BitVLA.", "published": "2025-06-09 08:15:11", "link": "http://arxiv.org/abs/2506.07530v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Genesis: Multimodal Driving Scene Generation with Spatio-Temporal and Cross-Modal Consistency", "abstract": "We present Genesis, a unified framework for joint generation of multi-view\ndriving videos and LiDAR sequences with spatio-temporal and cross-modal\nconsistency. Genesis employs a two-stage architecture that integrates a\nDiT-based video diffusion model with 3D-VAE encoding, and a BEV-aware LiDAR\ngenerator with NeRF-based rendering and adaptive sampling. Both modalities are\ndirectly coupled through a shared latent space, enabling coherent evolution\nacross visual and geometric domains. To guide the generation with structured\nsemantics, we introduce DataCrafter, a captioning module built on\nvision-language models that provides scene-level and instance-level\nsupervision. Extensive experiments on the nuScenes benchmark demonstrate that\nGenesis achieves state-of-the-art performance across video and LiDAR metrics\n(FVD 16.95, FID 4.24, Chamfer 0.611), and benefits downstream tasks including\nsegmentation and 3D detection, validating the semantic fidelity and practical\nutility of the generated data.", "published": "2025-06-09 07:20:49", "link": "http://arxiv.org/abs/2506.07497v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SpatialLM: Training Large Language Models for Structured Indoor Modeling", "abstract": "SpatialLM is a large language model designed to process 3D point cloud data\nand generate structured 3D scene understanding outputs. These outputs include\narchitectural elements like walls, doors, windows, and oriented object boxes\nwith their semantic categories. Unlike previous methods which exploit\ntask-specific network designs, our model adheres to the standard multimodal LLM\narchitecture and is fine-tuned directly from open-source LLMs.\n  To train SpatialLM, we collect a large-scale, high-quality synthetic dataset\nconsisting of the point clouds of 12,328 indoor scenes (54,778 rooms) with\nground-truth 3D annotations, and conduct a careful study on various modeling\nand training decisions. On public benchmarks, our model gives state-of-the-art\nperformance in layout estimation and competitive results in 3D object\ndetection. With that, we show a feasible path for enhancing the spatial\nunderstanding capabilities of modern LLMs for applications in augmented\nreality, embodied robotics, and more.", "published": "2025-06-09 07:10:58", "link": "http://arxiv.org/abs/2506.07491v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Drive Any Mesh: 4D Latent Diffusion for Mesh Deformation from Video", "abstract": "We propose DriveAnyMesh, a method for driving mesh guided by monocular video.\nCurrent 4D generation techniques encounter challenges with modern rendering\nengines. Implicit methods have low rendering efficiency and are unfriendly to\nrasterization-based engines, while skeletal methods demand significant manual\neffort and lack cross-category generalization. Animating existing 3D assets,\ninstead of creating 4D assets from scratch, demands a deep understanding of the\ninput's 3D structure. To tackle these challenges, we present a 4D diffusion\nmodel that denoises sequences of latent sets, which are then decoded to produce\nmesh animations from point cloud trajectory sequences. These latent sets\nleverage a transformer-based variational autoencoder, simultaneously capturing\n3D shape and motion information. By employing a spatiotemporal,\ntransformer-based diffusion model, information is exchanged across multiple\nlatent frames, enhancing the efficiency and generalization of the generated\nresults. Our experimental results demonstrate that DriveAnyMesh can rapidly\nproduce high-quality animations for complex motions and is compatible with\nmodern rendering engines. This method holds potential for applications in both\nthe gaming and filming industries.", "published": "2025-06-09 07:08:58", "link": "http://arxiv.org/abs/2506.07489v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Text-guided multi-stage cross-perception network for medical image segmentation", "abstract": "Medical image segmentation plays a crucial role in clinical medicine, serving\nas a tool for auxiliary diagnosis, treatment planning, and disease monitoring,\nthus facilitating physicians in the study and treatment of diseases. However,\nexisting medical image segmentation methods are limited by the weak semantic\nexpression of the target segmentation regions, which is caused by the low\ncontrast between the target and non-target segmentation regions. To address\nthis limitation, text prompt information has greast potential to capture the\nlesion location. However, existing text-guided methods suffer from insufficient\ncross-modal interaction and inadequate cross-modal feature expression. To\nresolve these issues, we propose the Text-guided Multi-stage Cross-perception\nnetwork (TMC). In TMC, we introduce a multistage cross-attention module to\nenhance the model's understanding of semantic details and a multi-stage\nalignment loss to improve the consistency of cross-modal semantics. The results\nof the experiments demonstrate that our TMC achieves a superior performance\nwith Dice of 84.77%, 78.50%, 88.73% in three public datasets (QaTa-COV19,\nMosMedData and Breast), outperforming UNet based networks and text-guided\nmethods.", "published": "2025-06-09 06:50:15", "link": "http://arxiv.org/abs/2506.07475v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Stability and Extension of Steady and Ranging Persistence", "abstract": "Persistent homology is a topological data analysis tool that has been widely\ngeneralized, extending its scope outside the field of topology. Among its\nextensions, steady and ranging persistence was developed to study a wide\nvariety of graph properties. Precisely, given a feature of interest on graphs,\nit is possible to build two types of persistence (steady and ranging\npersistence) that follow the evolution of the feature along graph filtrations.\nThis study extends steady and ranging persistence to other objects using\ncategory theory and investigates the stability of such persistence. In\nparticular, a characterization of the features that induce balanced steady and\nranging persistence is provided. The main results of this study are illustrated\nusing a practical implementation for hypergraphs.", "published": "2025-06-09 16:27:39", "link": "http://arxiv.org/abs/2506.07911v1", "categories": ["math.AT", "cs.DM", "math.CT"], "primary_category": "math.AT"}
{"title": "Centrality Change Proneness: an Early Indicator of Microservice Architectural Degradation", "abstract": "Over the past decade, the wide adoption of Microservice Architecture has\nrequired the identification of various patterns and anti-patterns to prevent\nMicroservice Architectural Degradation. Frequently, the systems are modelled as\na network of connected services. Recently, the study of temporal networks has\nemerged as a way to describe and analyze evolving networks. Previous research\nhas explored how software metrics such as size, complexity, and quality are\nrelated to microservice centrality in the architectural network. This study\ninvestigates whether temporal centrality metrics can provide insight into the\nearly detection of architectural degradation by correlating or affecting\nsoftware metrics. We reconstructed the architecture of 7 releases of an OSS\nmicroservice project with 42 services. For every service in every release, we\ncomputed the software and centrality metrics. From one of the latter, we\nderived a new metric, Centrality Change Proneness. We then explored the\ncorrelation between the metrics. We identified 7 size and 5 complexity metrics\nthat have a consistent correlation with centrality, while Centrality Change\nProneness did not affect the software metrics, thus providing yet another\nperspective and an early indicator of microservice architectural degradation.", "published": "2025-06-09 12:22:12", "link": "http://arxiv.org/abs/2506.07690v1", "categories": ["cs.SE", "cs.DM", "cs.NA", "math.NA"], "primary_category": "cs.SE"}
{"title": "Leveraging Network Methods for Hub-like Microservice Detection", "abstract": "Context: Microservice Architecture is a popular architectural paradigm that\nfacilitates flexibility by decomposing applications into small, independently\ndeployable services. Catalogs of architectural anti-patterns have been proposed\nto highlight the negative aspects of flawed microservice design. In particular,\nthe Hub-like anti-pattern lacks an unambiguous definition and detection method.\nAim: In this work, we aim to find a robust detection approach for the Hub-like\nmicroservice anti-pattern that outputs a reasonable number of Hub-like\ncandidates with high precision. Method: We leveraged a dataset of 25\nmicroservice networks and several network hub detection techniques to identify\nthe Hub-like anti-pattern, namely scale-free property, centrality metrics and\nclustering coefficient, minimum description length principle, and the approach\nbehind the Arcan tool. Results and Conclusion: Our findings revealed that the\nstudied architectural networks are not scale-free, that most considered hub\ndetection approaches do not agree on the detected hubs, and that the method by\nKirkley leveraging the Erdos-Renyi encoding is the most accurate one in terms\nof the number of detected hubs and the detection precision. Investigating\nfurther the applicability of these methods to detecting Hub-like components in\nmicroservice-based and other systems opens up new research directions.\nMoreover, our results provide an evaluation of the approach utilized by the\nwidely used Arcan tool and highlight the potential to update the tool to use\nthe normalized degree centrality of a component in the network, or for the\napproach based on ER encoding to be adopted instead.", "published": "2025-06-09 12:13:49", "link": "http://arxiv.org/abs/2506.07683v1", "categories": ["cs.SE", "cs.DM"], "primary_category": "cs.SE"}
{"title": "Half-Iterates of $x(1+x)$, $\\sin(x)$ and $\\exp(x/e)$", "abstract": "The title reflects the original intent of this paper -- to continue exploring\ncompositional square roots -- focusing on Walker's (1991) study of the Abel\nequation $f(\\exp(x/e))=f(x)+1$ for real $x \\neq e$. An unexpected discovery\nchanged everything. We already knew that \\'Ecalle (1974) developed theory\ninspiring relevant calculations across years. Precise details, however, seemed\nto escape attention until recently. Helpful online posts of Jagy (2012) are\nimportant not to overlook. The new algorithm is exceedingly simple and\noutperforms a rival method, due to Mavecha & Laohakosol (2013), which we\nmistakenly advocated until now. Our loyalty has correspondingly shifted.", "published": "2025-06-09 10:42:45", "link": "http://arxiv.org/abs/2506.07625v1", "categories": ["math.NT", "cs.DM", "39B12 (Primary) 11B37, 26A18, 39-08, 39B22, 65D20 (Secondary)"], "primary_category": "math.NT"}
{"title": "HyColor: An Efficient Heuristic Algorithm for Graph Coloring", "abstract": "The graph coloring problem (GCP) is a classic combinatorial optimization\nproblem that aims to find the minimum number of colors assigned to vertices of\na graph such that no two adjacent vertices receive the same color. GCP has been\nextensively studied by researchers from various fields, including mathematics,\ncomputer science, and biological science. Due to the NP-hard nature, many\nheuristic algorithms have been proposed to solve GCP. However, existing GCP\nalgorithms focus on either small hard graphs or large-scale sparse graphs (with\nup to 10^7 vertices). This paper presents an efficient hybrid heuristic\nalgorithm for GCP, named HyColor, which excels in handling large-scale sparse\ngraphs while achieving impressive results on small dense graphs. The efficiency\nof HyColor comes from the following three aspects: a local decision strategy to\nimprove the lower bound on the chromatic number; a graph-reduction strategy to\nreduce the working graph; and a k-core and mixed degree-based greedy heuristic\nfor efficiently coloring graphs. HyColor is evaluated against three\nstate-of-the-art GCP algorithms across four benchmarks, comprising three\nlarge-scale sparse graph benchmarks and one small dense graph benchmark,\ntotaling 209 instances. The results demonstrate that HyColor consistently\noutperforms existing heuristic algorithms in both solution accuracy and\ncomputational efficiency for the majority of instances. Notably, HyColor\nachieved the best solutions in 194 instances (over 93%), with 34 of these\nsolutions significantly surpassing those of other algorithms. Furthermore,\nHyColor successfully determined the chromatic number and achieved optimal\ncoloring in 128 instances.", "published": "2025-06-09 02:45:08", "link": "http://arxiv.org/abs/2506.07373v1", "categories": ["cs.DM", "cs.AI"], "primary_category": "cs.DM"}
{"title": "Addressing Correlated Latent Exogenous Variables in Debiased Recommender Systems", "abstract": "Recommendation systems (RS) aim to provide personalized content, but they\nface a challenge in unbiased learning due to selection bias, where users only\ninteract with items they prefer. This bias leads to a distorted representation\nof user preferences, which hinders the accuracy and fairness of\nrecommendations. To address the issue, various methods such as error imputation\nbased, inverse propensity scoring, and doubly robust techniques have been\ndeveloped. Despite the progress, from the structural causal model perspective,\nprevious debiasing methods in RS assume the independence of the exogenous\nvariables. In this paper, we release this assumption and propose a learning\nalgorithm based on likelihood maximization to learn a prediction model. We\nfirst discuss the correlation and difference between unmeasured confounding and\nour scenario, then we propose a unified method that effectively handles latent\nexogenous variables. Specifically, our method models the data generation\nprocess with latent exogenous variables under mild normality assumptions. We\nthen develop a Monte Carlo algorithm to numerically estimate the likelihood\nfunction. Extensive experiments on synthetic datasets and three real-world\ndatasets demonstrate the effectiveness of our proposed method. The code is at\nhttps://github.com/WallaceSUI/kdd25-background-variable.", "published": "2025-06-09 07:50:21", "link": "http://arxiv.org/abs/2506.07517v1", "categories": ["cs.LG", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Leveraging Historical and Current Interests for Continual Sequential Recommendation", "abstract": "Sequential recommendation models based on the Transformer architecture show\nsuperior performance in harnessing long-range dependencies within user behavior\nvia self-attention. However, naively updating them on continuously arriving\nnon-stationary data streams incurs prohibitive computation costs or leads to\ncatastrophic forgetting. To address this, we propose Continual Sequential\nTransformer for Recommendation (CSTRec) that effectively leverages\nwell-preserved historical user interests while capturing current interests. At\nits core is Continual Sequential Attention (CSA), a linear attention mechanism\nthat retains past knowledge without direct access to old data. CSA integrates\ntwo key components: (1) Cauchy-Schwarz Normalization that stabilizes training\nunder uneven interaction frequencies, and (2) Collaborative Interest Enrichment\nthat mitigates forgetting through shared, learnable interest pools. We further\nintroduce a technique that facilitates learning for cold-start users by\ntransferring historical knowledge from behaviorally similar existing users.\nExtensive experiments on three real-world datasets indicate that CSTRec\noutperforms state-of-the-art baselines in both knowledge retention and\nacquisition.", "published": "2025-06-09 06:20:23", "link": "http://arxiv.org/abs/2506.07466v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Hybrid Beamforming Optimization for MIMO ISAC Exploiting Prior Information: A PCRB-based Approach", "abstract": "This paper considers a multiple-input multiple-output (MIMO) integrated\nsensing and communication (ISAC) system, where a multi-antenna base station\n(BS) with transceiver hybrid analog-digital arrays transmits dual-functional\nsignals to communicate with a multi-antenna user and simultaneously sense the\nunknown and random location information of a target based on the reflected echo\nsignals and the prior distribution information on the target's location. Under\ntransceiver hybrid arrays, we characterize the sensing performance by deriving\nthe posterior Cram\\'{e}r-Rao bound (PCRB) of the mean-squared error which is a\nfunction of the transmit hybrid beamforming and receive analog beamforming. We\nstudy joint transmit hybrid beamforming and receive analog beamforming\noptimization to minimize the PCRB subject to a communication rate requirement.\nWe first consider a sensing-only system and derive the optimal solution to each\nelement in the transmit/receive analog beamforming matrices that minimizes the\nPCRB in closed form. Then, we develop an alternating optimization (AO) based\nalgorithm. Next, we study a narrowband MIMO ISAC system and devise an efficient\nAO-based hybrid beamforming algorithm by leveraging weighted minimum\nmean-squared error and feasible point pursuit successive convex approximation\nmethods. Furthermore, we extend the results for narrowband systems to a MIMO\northogonal frequency-division multiplexing (OFDM) ISAC system. Numerical\nresults validate the effectiveness of our proposed hybrid beamforming designs.\nIt is revealed that the number of receive RF chains has more significant impact\non the sensing performance than its transmit counterpart. Under a given budget\non the total number of transmit/receive RF chains at the BS, the optimal number\nof transmit RF chains increases as the communication rate target increases due\nto the non-trivial PCRB-rate trade-off.", "published": "2025-06-09 15:35:26", "link": "http://arxiv.org/abs/2506.07869v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "On the Fixed-Length-Burst Levenshtein Ball with Unit Radius", "abstract": "Consider a length-$n$ sequence $\\bm{x}$ over a $q$-ary alphabet. The\n\\emph{fixed-length Levenshtein ball} $\\mathcal{L}_t(\\bm{x})$ of radius $t$\nencompasses all length-$n$ $q$-ary sequences that can be derived from $\\bm{x}$\nby performing $t$ deletions followed by $t$ insertions. Analyzing the size and\nstructure of these balls presents significant challenges in combinatorial\ncoding theory. Recent studies have successfully characterized fixed-length\nLevenshtein balls in the context of a single deletion and a single insertion.\nThese works have derived explicit formulas for various key metrics, including\nthe exact size of the balls, extremal bounds (minimum and maximum sizes), as\nwell as expected sizes and their concentration properties. However, the general\ncase involving an arbitrary number of $t$ deletions and $t$ insertions $(t>1)$\nremains largely uninvestigated. This work systematically examines fixed-length\nLevenshtein balls with multiple deletions and insertions, focusing specifically\non \\emph{fixed-length burst Levenshtein balls}, where deletions occur\nconsecutively, as do insertions. We provide comprehensive solutions for\nexplicit cardinality formulas, extremal bounds (minimum and maximum sizes),\nexpected size, and concentration properties surrounding the expected value.", "published": "2025-06-09 14:45:36", "link": "http://arxiv.org/abs/2506.07817v1", "categories": ["cs.IT", "math.CO", "math.IT"], "primary_category": "cs.IT"}
{"title": "Generalization Analysis for Bayesian Optimal Experiment Design under Model Misspecification", "abstract": "In many settings in science and industry, such as drug discovery and clinical\ntrials, a central challenge is designing experiments under time and budget\nconstraints. Bayesian Optimal Experimental Design (BOED) is a paradigm to pick\nmaximally informative designs that has been increasingly applied to such\nproblems. During training, BOED selects inputs according to a pre-determined\nacquisition criterion. During testing, the model learned during training\nencounters a naturally occurring distribution of test samples. This leads to an\ninstance of covariate shift, where the train and test samples are drawn from\ndifferent distributions. Prior work has shown that in the presence of model\nmisspecification, covariate shift amplifies generalization error. Our first\ncontribution is to provide a mathematical decomposition of generalization error\nthat reveals key contributors to generalization error in the presence of model\nmisspecification. We show that generalization error under misspecification is\nthe result of, in addition to covariate shift, a phenomenon we term error\n(de-)amplification which has not been identified or studied in prior work. Our\nsecond contribution is to provide a detailed empirical analysis to show that\nmethods that result in representative and de-amplifying training data increase\ngeneralization performance. Our third contribution is to develop a novel\nacquisition function that mitigates the effects of model misspecification by\nincluding a term for representativeness and implicitly inducing\nde-amplification. Our experimental results demonstrate that our method\noutperforms traditional BOED in the presence of misspecification.", "published": "2025-06-09 14:33:50", "link": "http://arxiv.org/abs/2506.07805v1", "categories": ["stat.ML", "cs.IT", "math.IT"], "primary_category": "stat.ML"}
{"title": "Learned Off-Grid Imager for Low-Altitude Economy with Cooperative ISAC Network", "abstract": "The low-altitude economy is emerging as a key driver of future economic\ngrowth, necessitating effective flight activity surveillance using existing\nmobile cellular network sensing capabilities. However, traditional monostatic\nand localizationbased sensing methods face challenges in fusing sensing results\nand matching channel parameters. To address these challenges, we model\nlow-altitude surveillance as a compressed sensing (CS)-based imaging problem by\nleveraging the cooperation of multiple base stations and the inherent sparsity\nof aerial images. Additionally, we derive the point spread function to analyze\nthe influences of different antenna, subcarrier, and resolution settings on the\nimaging performance. Given the random spatial distribution of unmanned aerial\nvehicles (UAVs), we propose a physics-embedded learning method to mitigate\noff-grid errors in traditional CS-based approaches. Furthermore, to enhance\nrare UAV detection in vast low-altitude airspace, we integrate an online hard\nexample mining scheme into the loss function design, enabling the network to\nadaptively focus on samples with significant discrepancies from the ground\ntruth during training. Simulation results demonstrate the effectiveness of the\nproposed low-altitude surveillance framework. The proposed physicsembedded\nlearning algorithm achieves a 97.55% detection rate, significantly\noutperforming traditional CS-based methods under off-grid conditions. Part of\nthe source code for this paper will be soon accessed at\nhttps://github.com/kiwi1944/LAEImager.", "published": "2025-06-09 14:26:40", "link": "http://arxiv.org/abs/2506.07799v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "A General Coding Framework for Adaptive Private Information Retrieval", "abstract": "The problem of $T$-colluding private information retrieval (PIR) enables the\nuser to retrieve one out of $M$ files from a distributed storage system with\n$N$ servers without revealing anything about the index of the desired file to\nany group of up to $T$ colluding servers. In the considered storage system, the\n$M$ files are stored across the $N$ distributed servers in an $X$-secure\n$K$-coded manner such that any group of up to $X$ colluding servers learns\nnothing about the files; the storage overhead at each server is reduced by a\nfactor of $\\frac{1}{K}$ compared to the total size of the files; and the files\ncan be reconstructed from any $K+X$ servers. However, in practical scenarios,\nwhen the user retrieves the desired file from the distributed system, some\nservers may respond to the user very slowly or not respond at all. These\nservers are referred to as \\emph{stragglers}, and particularly their identities\nand numbers are unknown in advance and may change over time. This paper\nconsiders the adaptive PIR problem that can be capable of tolerating the\npresence of a varying number of stragglers. We propose a general coding method\nfor designing adaptive PIR schemes by introducing the concept of a\n\\emph{feasible PIR coding framework}. We demonstrate that any \\emph{feasible\nPIR coding framework} over a finite field $\\mathbb{F}_q$ with size $q$ can be\nused to construct an adaptive PIR scheme that achieves a retrieval rate of\n$1-\\frac{K+X+T-1}{N-S}$ simultaneously for all numbers of stragglers $0\\leq\nS\\leq N-(K+X+T)$ over the same finite field. Additionally, we provide an\nimplementation of the \\emph{feasible PIR coding framework}, ensuring that the\nadaptive PIR scheme operates over any finite field $\\mathbb{F}_q$ with size\n$q\\geq N+\\max\\{K, N-(K+X+T-1)\\}$.", "published": "2025-06-09 14:04:10", "link": "http://arxiv.org/abs/2506.07787v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "The Universality Lens: Why Even Highly Over-Parametrized Models Learn Well", "abstract": "A fundamental question in modern machine learning is why large,\nover-parameterized models, such as deep neural networks and transformers, tend\nto generalize well, even when their number of parameters far exceeds the number\nof training samples.\n  We investigate this phenomenon through the lens of information theory,\ngrounded in universal learning theory. Specifically, we study a Bayesian\nmixture learner with log-loss and (almost) uniform prior over an expansive\nhypothesis class.\n  Our key result shows that the learner's regret is not determined by the\noverall size of the hypothesis class, but rather by the cumulative probability\nof all models that are close, in Kullback-Leibler divergence distance, to the\ntrue data-generating process. We refer to this cumulative probability as the\nweight of the hypothesis.\n  This leads to a natural notion of model simplicity: simple models are those\nwith large weight and thus require fewer samples to generalize, while complex\nmodels have small weight and need more data. This perspective provides a\nrigorous and intuitive explanation for why over-parameterized models often\navoid overfitting: the presence of simple hypotheses allows the posterior to\nconcentrate on them when supported by the data.\n  We further bridge theory and practice by recalling that stochastic gradient\ndescent with Langevin dynamics samples from the correct posterior distribution,\nenabling our theoretical learner to be approximated using standard machine\nlearning methods combined with ensemble learning.\n  Our analysis yields non-uniform regret bounds and aligns with key practical\nconcepts such as flat minima and model distillation. The results apply broadly\nacross online, batch, and supervised learning settings, offering a unified and\nprincipled understanding of the generalization behavior of modern AI systems.", "published": "2025-06-09 11:32:31", "link": "http://arxiv.org/abs/2506.07661v1", "categories": ["cs.LG", "cs.IT", "math.IT", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Correcting Errors Through Partitioning and Burst-Deletion Correction", "abstract": "In this paper, we propose a partitioning technique that decomposes a pair of\nsequences with overlapping $t$-deletion $s$-substitution balls into sub-pairs,\nwhere the $^{\\leq}t$-burst-deletion balls of each sub-pair intersect. This\ndecomposition facilitates the development of $t$-deletion $s$-substitution\ncorrecting codes that leverage approaches from $^{\\leq}t$-burst-deletion\ncorrection. Building upon established approaches in the\n$^{\\leq}t$-burst-deletion correction domain, we construct $t$-deletion\n$s$-substitution correcting codes for $t\\in \\{1,2\\}$ over binary alphabets and\nfor $t=1$ in non-binary alphabets, with some constructions matching existing\nresults and others outperforming current methods. Our framework offers new\ninsights into the underlying principles of prior works, elucidates the\nlimitations of current approaches, and provides a unified perspective on error\ncorrection strategies.", "published": "2025-06-09 10:14:36", "link": "http://arxiv.org/abs/2506.07609v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Criss-Cross Deletion Correcting Codes: Optimal Constructions with Efficient Decoders", "abstract": "This paper addresses fundamental challenges in two-dimensional error\ncorrection by constructing optimal codes for \\emph{criss-cross deletions}. We\nconsider an $ n \\times n $ array over a $ q $-ary alphabet $\\Sigma_q := \\{0, 1,\n\\ldots, q-1\\}$ that is subject to a \\emph{$(t_r, t_c)$-criss-cross deletion},\nwhich involves the simultaneous removal of $ t_r $ rows and $ t_c $ columns. A\ncode $\\mathcal{C} \\subseteq \\Sigma_q^{n \\times n}$ is defined as a\n\\emph{$(t_r,t_c)$-criss-cross deletion correcting code} if it can successfully\ncorrect these deletions. We derive a sphere-packing type lower bound and a\nGilbert-Varshamov type upper bound on the redundancy of optimal codes. Our\nresults indicate that the optimal redundancy for a $(t_r, t_c)$-criss-cross\ndeletion correcting code lies between $(t_r + t_c)n\\log q + (t_r + t_c)\\log n +\nO_{q,t_r,t_c}(1)$ and $(t_r + t_c)n\\log q + 2(t_r + t_c)\\log n +\nO_{q,t_r,t_c}(1)$, where the logarithm is on base two, and $O_{q,t_r,t_c}(1)$\nis a constant that depends solely on $q$, $t_r$, and $t_c$. For the case of\n$(1,1)$-criss-cross deletions, we develop two families of constructions. One\nachieves a redundancy of $2n\\log q + 2\\log n$ for non-binary alphabets, while\nthe other requires $2n\\log q + 2\\log n + O_q(1)$ bits of redundancy for\narbitrary alphabets. Both constructions match our lower bound, differing only\nby a constant $O_q(1)$ that depends solely on $q$, thereby confirming their\noptimality. For the case of $(t_r, t_c)$-criss-cross deletions, we provide a\nstrategy to derive optimal codes when both unidirectional deletions occur\nconsecutively. We propose decoding algorithms with a time complexity of\n$O(n^2)$ for our codes, which are optimal for two-dimensional scenarios.", "published": "2025-06-09 10:08:45", "link": "http://arxiv.org/abs/2506.07607v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Flexible MIMO for Future Wireless Communications: Which Flexibilities are Possible?", "abstract": "To enable next-generation wireless communication networks with modest\nspectrum availability, multiple-input multiple-output (MIMO) technology needs\nto undergo further evolution. In this paper, we introduce a promising\nnext-generation wireless communication concept: flexible MIMO technology. This\ntechnology represents a MIMO technology with flexible physical configurations\nand integrated applications. We categorize twelve representative flexible MIMO\ntechnologies into three major classifications: flexible deployment\ncharacteristics-based, flexible geometry characteristics-based, and flexible\nreal-time modifications-based. Then, we provide a comprehensive overview of\ntheir fundamental characteristics, potential, and challenges. Furthermore, we\ndemonstrate three vital enablers for the flexible MIMO technology, including\nefficient channel state information (CSI) acquisition schemes, low-complexity\nbeamforming design, and explainable artificial intelligence (AI)-enabled\noptimization. Within these areas, eight critical sub-enabling technologies are\ndiscussed in detail. Finally, we present two case studies-pre-optimized\nirregular arrays and cell-free movable antennas-where significant potential for\nflexible MIMO technologies to enhance the system capacity is showcased.", "published": "2025-06-09 09:58:58", "link": "http://arxiv.org/abs/2506.07599v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Pixel-Sensitive and Robust Steganography Based on Polar Codes", "abstract": "Steganography is an information hiding technique for covert communication.\nThe core issue in steganography design is the rate-distortion coding problem.\nPolar codes, which have been proven to achieve the rate-distortion bound for\nany binary symmetric source, are utilized to design a steganographic scheme\nthat can reach the embedding capacity for the Distortion-Limited Sender problem\nin certain cases. In adaptive steganography, for attack scenarios where each\nnoise element can have different intensities, existing steganographic coding\nmethods fail to resist such attacks. In this paper, we propose a\npixel-sensitive and robust steganographic scheme based on polar codes. Our\nsteganographic scheme not only matches the adaptive distortion well but is also\nrobust against sophisticated noise attacks. Futher, it is proven that our\nscheme achieves the embedding capacity in certain cases. Experimentally, a\nsteganographic scheme can be designed and implemented with a secret message\nerror rate at the $10^{-5}$ level when the attack noise is known to both the\nsender and the receiver. This demonstrates its significant robustness.", "published": "2025-06-09 03:54:27", "link": "http://arxiv.org/abs/2506.07404v1", "categories": ["cs.CR", "cs.IT", "math.IT"], "primary_category": "cs.CR"}
{"title": "Distributed Image Semantic Communication via Nonlinear Transform Coding", "abstract": "This paper investigates distributed source-channel coding for correlated\nimage semantic transmission over wireless channels. In this setup, correlated\nimages at different transmitters are separately encoded and transmitted through\ndedicated channels for joint recovery at the receiver. We propose a general\napproach for distributed image semantic communication that applies to both\nseparate source and channel coding (SSCC) and joint source-channel coding\n(JSCC). Unlike existing learning-based approaches that implicitly learn source\ncorrelation in a purely data-driven manner, our method leverages nonlinear\ntransform coding (NTC) to explicitly model source correlation from both\nprobabilistic and geometric perspectives. A joint entropy model approximates\nthe joint distribution of latent representations to guide adaptive rate\nallocation, while a transformation module aligns latent features for maximal\ncorrelation learning at the decoder. We implement this framework as D-NTSC for\nSSCC and D-NTSCC for JSCC, both built on Swin Transformers for effective\nfeature extraction and correlation exploitation. Variational inference is\nemployed to derive principled loss functions that jointly optimize encoding,\ndecoding, and joint entropy modeling. Extensive experiments on real-world\nmulti-view datasets demonstrate that D-NTSC and D-NTSCC outperform existing\ndistributed SSCC and distributed JSCC baselines, respectively, achieving\nstate-of-the-art performance in both pixel-level and perceptual quality\nmetrics.", "published": "2025-06-09 03:26:47", "link": "http://arxiv.org/abs/2506.07391v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "The error-correcting pair for several classes of NMDS linear codes", "abstract": "The error-correcting pair is a general algebraic decoding method for linear\ncodes. The near maximal distance separable (NMDS) linear code is a subclass of\nlinear codes and has applications in secret sharing scheme and communication\nsystems due to the efficient performance, thus we focus on the error-correcting\npair of NMDS linear codes. In 2023, He and Liao showed that for an NMDS linear\ncode $\\mathcal{C}$ with minimal distance $2\\ell+1$ or $2\\ell+2$, if\n$\\mathcal{C}$ has an $\\ell$-error-correcting pair $\\left( \\mathcal{A},\n\\mathcal{B} \\right)$, then the parameters of $\\mathcal{A}$ have 6 or 10\npossibilities, respectively.\n  In this manuscript, basing on Product Singleton Bound, we give several\nnecessary conditions for that the NMDS linear code $\\mathcal{C}$ with minimal\ndistance $2\\ell+1$ has an $\\ell$-error-correcting pair $(\\mathcal{A},\n\\mathcal{B})$, where the parameters of $\\mathcal{A}$ is the 1st, 2nd, 4th or\n5th case, then basing on twisted generalized Reed-Solomon codes, we give an\nexample for that the parameters of $\\mathcal{A}$ is the 1st case. Moreover, we\nalso give several necessary conditions for that the NMDS linear code\n$\\mathcal{C}$ with minimal distance $2\\ell+2$ has an $\\ell$-error-correcting\npair $(\\mathcal{A}, \\mathcal{B})$, where the parameters of $\\mathcal{A}$ is the\n2nd, 4th, 7th or 8th case, then we give an example for that the parameters of\n$\\mathcal{A}$ is the 1st or 2nd case, respectively.", "published": "2025-06-09 03:02:00", "link": "http://arxiv.org/abs/2506.07380v1", "categories": ["cs.IT", "math.IT", "94A24, 94B05"], "primary_category": "cs.IT"}
{"title": "Fluid Antenna-Empowered Receive Spatial Modulation", "abstract": "Fluid antenna (FA), as an emerging antenna technology, fully exploits spatial\ndiversity. This paper integrates FA with the receive spatial modulation (RSM)\nscheme and proposes a novel FA-empowered RSM (FA-RSM) system. In this system,\nthe transmitter is equipped with an FA that simultaneously activates multiple\nports to transmit precoded signals. We address three key challenges in the\nFA-RSM system: port selection, theoretical analysis, and detection. First, for\nport selection, an optimal algorithm from a capacity maximization perspective\nare proposed, followed by two low-complexity alternatives. Second, for\ntheoretical analysis, performance evaluation metrics are provided for port\nselection, which demonstrate that increasing the number of activated ports\nenhances system performance. Third, regarding detection, two low-complexity\ndetectors are proposed. Simulation results confirm that the FA-RSM system\nsignificantly outperforms the conventional RSM system. The proposed\nlow-complexity port selection algorithms facilitate minimal performance\ndegradation. Moreover, while activating additional ports improves performance,\nthe gain gradually saturates due to inherent spatial correlation, highlighting\nthe importance of effective port selection in reducing system complexity and\ncost. Finally, both proposed detectors achieve near-optimal detection\nperformance with low computational complexity, emphasizing the\nreceiver-friendly nature of the FA-RSM system.", "published": "2025-06-09 02:20:50", "link": "http://arxiv.org/abs/2506.07362v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Realistic Urban Traffic Generator using Decentralized Federated Learning for the SUMO simulator", "abstract": "Realistic urban traffic simulation is essential for sustainable urban\nplanning and the development of intelligent transportation systems. However,\ngenerating high-fidelity, time-varying traffic profiles that accurately reflect\nreal-world conditions, especially in large-scale scenarios, remains a major\nchallenge. Existing methods often suffer from limitations in accuracy,\nscalability, or raise privacy concerns due to centralized data processing. This\nwork introduces DesRUTGe (Decentralized Realistic Urban Traffic Generator), a\nnovel framework that integrates Deep Reinforcement Learning (DRL) agents with\nthe SUMO simulator to generate realistic 24-hour traffic patterns. A key\ninnovation of DesRUTGe is its use of Decentralized Federated Learning (DFL),\nwherein each traffic detector and its corresponding urban zone function as an\nindependent learning node. These nodes train local DRL models using minimal\nhistorical data and collaboratively refine their performance by exchanging\nmodel parameters with selected peers (e.g., geographically adjacent zones),\nwithout requiring a central coordinator. Evaluated using real-world data from\nthe city of Barcelona, DesRUTGe outperforms standard SUMO-based tools such as\nRouteSampler, as well as other centralized learning approaches, by delivering\nmore accurate and privacy-preserving traffic pattern generation.", "published": "2025-06-09 17:51:45", "link": "http://arxiv.org/abs/2506.07980v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Hyperpruning: Efficient Search through Pruned Variants of Recurrent Neural Networks Leveraging Lyapunov Spectrum", "abstract": "A variety of pruning methods have been introduced for over-parameterized\nRecurrent Neural Networks to improve efficiency in terms of power consumption\nand storage utilization. These advances motivate a new paradigm, termed\n`hyperpruning', which seeks to identify the most suitable pruning strategy for\na given network architecture and application. Unlike conventional\nhyperparameter search, where the optimal configuration's accuracy remains\nuncertain, in the context of network pruning, the accuracy of the dense model\nsets the target for the accuracy of the pruned one. The goal, therefore, is to\ndiscover pruned variants that match or even surpass this established accuracy.\nHowever, exhaustive search over pruning configurations is computationally\nexpensive and lacks early performance guarantees. To address this challenge, we\npropose a novel Lyapunov Spectrum (LS)-based distance metric that enables early\ncomparison between pruned and dense networks, allowing accurate prediction of\npost-training performance. By integrating this LS-based distance with standard\nhyperparameter optimization algorithms, we introduce an efficient hyperpruning\nframework, termed LS-based Hyperpruning (LSH). LSH reduces search time by an\norder of magnitude compared to conventional approaches relying on full\ntraining. Experiments on stacked LSTM and RHN architectures using the Penn\nTreebank dataset, and on AWD-LSTM-MoS using WikiText-2, demonstrate that under\nfixed training budgets and target pruning ratios, LSH consistently identifies\nsuperior pruned models. Remarkably, these pruned variants not only outperform\nthose selected by loss-based baseline but also exceed the performance of their\ndense counterpart.", "published": "2025-06-09 17:49:29", "link": "http://arxiv.org/abs/2506.07975v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Two-Phase Deep Learning Framework for Adaptive Time-Stepping in High-Speed Flow Modeling", "abstract": "We consider the problem of modeling high-speed flows using machine learning\nmethods. While most prior studies focus on low-speed fluid flows in which\nuniform time-stepping is practical, flows approaching and exceeding the speed\nof sound exhibit sudden changes such as shock waves. In such cases, it is\nessential to use adaptive time-stepping methods to allow a temporal resolution\nsufficient to resolve these phenomena while simultaneously balancing\ncomputational costs. Here, we propose a two-phase machine learning method,\nknown as ShockCast, to model high-speed flows with adaptive time-stepping. In\nthe first phase, we propose to employ a machine learning model to predict the\ntimestep size. In the second phase, the predicted timestep is used as an input\nalong with the current fluid fields to advance the system state by the\npredicted timestep. We explore several physically-motivated components for\ntimestep prediction and introduce timestep conditioning strategies inspired by\nneural ODE and Mixture of Experts. As ShockCast is the first framework for\nlearning high-speed flows, we evaluate our methods by generating two supersonic\nflow datasets, available at https://huggingface.co/datasets/divelab. Our code\nis publicly available as part of the AIRS library\n(https://github.com/divelab/AIRS).", "published": "2025-06-09 17:44:20", "link": "http://arxiv.org/abs/2506.07969v1", "categories": ["cs.LG", "physics.flu-dyn"], "primary_category": "cs.LG"}
{"title": "Neural Tangent Kernel Analysis to Probe Convergence in Physics-informed Neural Solvers: PIKANs vs. PINNs", "abstract": "Physics-informed Kolmogorov-Arnold Networks (PIKANs), and in particular their\nChebyshev-based variants (cPIKANs), have recently emerged as promising models\nfor solving partial differential equations (PDEs). However, their training\ndynamics and convergence behavior remain largely unexplored both theoretically\nand numerically. In this work, we aim to advance the theoretical understanding\nof cPIKANs by analyzing them using Neural Tangent Kernel (NTK) theory. Our\nobjective is to discern the evolution of kernel structure throughout\ngradient-based training and its subsequent impact on learning efficiency. We\nfirst derive the NTK of standard cKANs in a supervised setting, and then extend\nthe analysis to the physics-informed context. We analyze the spectral\nproperties of NTK matrices, specifically their eigenvalue distributions and\nspectral bias, for four representative PDEs: the steady-state Helmholtz\nequation, transient diffusion and Allen-Cahn equations, and forced vibrations\ngoverned by the Euler-Bernoulli beam equation. We also conduct an investigation\ninto the impact of various optimization strategies, e.g., first-order,\nsecond-order, and hybrid approaches, on the evolution of the NTK and the\nresulting learning dynamics. Results indicate a tractable behavior for NTK in\nthe context of cPIKANs, which exposes learning dynamics that standard\nphysics-informed neural networks (PINNs) cannot capture. Spectral trends also\nreveal when domain decomposition improves training, directly linking kernel\nbehavior to convergence rates under different setups. To the best of our\nknowledge, this is the first systematic NTK study of cPIKANs, providing\ntheoretical insight that clarifies and predicts their empirical performance.", "published": "2025-06-09 17:30:13", "link": "http://arxiv.org/abs/2506.07958v1", "categories": ["cs.LG", "math-ph", "math.AP", "math.MP", "math.SP"], "primary_category": "cs.LG"}
{"title": "Discrete and Continuous Difference of Submodular Minimization", "abstract": "Submodular functions, defined on continuous or discrete domains, arise in\nnumerous applications. We study the minimization of the difference of two\nsubmodular (DS) functions, over both domains, extending prior work restricted\nto set functions. We show that all functions on discrete domains and all smooth\nfunctions on continuous domains are DS. For discrete domains, we observe that\nDS minimization is equivalent to minimizing the difference of two convex (DC)\nfunctions, as in the set function case. We propose a novel variant of the DC\nAlgorithm (DCA) and apply it to the resulting DC Program, obtaining comparable\ntheoretical guarantees as in the set function case. The algorithm can be\napplied to continuous domains via discretization. Experiments demonstrate that\nour method outperforms baselines in integer compressive sensing and integer\nleast squares.", "published": "2025-06-09 17:17:15", "link": "http://arxiv.org/abs/2506.07952v1", "categories": ["math.OC", "cs.DS", "cs.LG"], "primary_category": "math.OC"}
{"title": "Cost-Optimal Active AI Model Evaluation", "abstract": "The development lifecycle of generative AI systems requires continual\nevaluation, data acquisition, and annotation, which is costly in both resources\nand time. In practice, rapid iteration often makes it necessary to rely on\nsynthetic annotation data because of the low cost, despite the potential for\nsubstantial bias. In this paper, we develop novel, cost-aware methods for\nactively balancing the use of a cheap, but often inaccurate, weak rater -- such\nas a model-based autorater that is designed to automatically assess the quality\nof generated content -- with a more expensive, but also more accurate, strong\nrater alternative such as a human. More specifically, the goal of our approach\nis to produce a low variance, unbiased estimate of the mean of the target\n\"strong\" rating, subject to some total annotation budget. Building on recent\nwork in active and prediction-powered statistical inference, we derive a family\nof cost-optimal policies for allocating a given annotation budget between weak\nand strong raters so as to maximize statistical efficiency. Using synthetic and\nreal-world data, we empirically characterize the conditions under which these\npolicies yield improvements over prior methods. We find that, especially in\ntasks where there is high variability in the difficulty of examples, our\npolicies can achieve the same estimation precision at a far lower total\nannotation budget than standard evaluation methods.", "published": "2025-06-09 17:14:41", "link": "http://arxiv.org/abs/2506.07949v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "TokenBreak: Bypassing Text Classification Models Through Token Manipulation", "abstract": "Natural Language Processing (NLP) models are used for text-related tasks such\nas classification and generation. To complete these tasks, input data is first\ntokenized from human-readable text into a format the model can understand,\nenabling it to make inferences and understand context. Text classification\nmodels can be implemented to guard against threats such as prompt injection\nattacks against Large Language Models (LLMs), toxic input and cybersecurity\nrisks such as spam emails. In this paper, we introduce TokenBreak: a novel\nattack that can bypass these protection models by taking advantage of the\ntokenization strategy they use. This attack technique manipulates input text in\nsuch a way that certain models give an incorrect classification. Importantly,\nthe end target (LLM or email recipient) can still understand and respond to the\nmanipulated text and therefore be vulnerable to the very attack the protection\nmodel was put in place to prevent. The tokenizer is tied to model architecture,\nmeaning it is possible to predict whether or not a model is vulnerable to\nattack based on family. We also present a defensive strategy as an added layer\nof protection that can be implemented without having to retrain the defensive\nmodel.", "published": "2025-06-09 17:11:28", "link": "http://arxiv.org/abs/2506.07948v1", "categories": ["cs.LG", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Ensemble-Based Survival Models with the Self-Attended Beran Estimator Predictions", "abstract": "Survival analysis predicts the time until an event of interest, such as\nfailure or death, but faces challenges due to censored data, where some events\nremain unobserved. Ensemble-based models, like random survival forests and\ngradient boosting, are widely used but can produce unstable predictions due to\nvariations in bootstrap samples. To address this, we propose SurvBESA (Survival\nBeran Estimators Self-Attended), a novel ensemble model that combines Beran\nestimators with a self-attention mechanism. Unlike traditional methods,\nSurvBESA applies self-attention to predicted survival functions, smoothing out\nnoise by adjusting each survival function based on its similarity to\nneighboring survival functions. We also explore a special case using Huber's\ncontamination model to define attention weights, simplifying training to a\nquadratic or linear optimization problem. Numerical experiments show that\nSurvBESA outperforms state-of-the-art models. The implementation of SurvBESA is\npublicly available.", "published": "2025-06-09 16:53:25", "link": "http://arxiv.org/abs/2506.07933v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Generative Physics-Informed Reinforcement Learning-Based Approach for Construction of Representative Drive Cycle", "abstract": "Accurate driving cycle construction is crucial for vehicle design, fuel\neconomy analysis, and environmental impact assessments. A generative\nPhysics-Informed Expected SARSA-Monte Carlo (PIESMC) approach that constructs\nrepresentative driving cycles by capturing transient dynamics, acceleration,\ndeceleration, idling, and road grade transitions while ensuring model fidelity\nis introduced. Leveraging a physics-informed reinforcement learning framework\nwith Monte Carlo sampling, PIESMC delivers efficient cycle construction with\nreduced computational cost. Experimental evaluations on two real-world datasets\ndemonstrate that PIESMC replicates key kinematic and energy metrics, achieving\nup to a 57.3% reduction in cumulative kinematic fragment errors compared to the\nMicro-trip-based (MTB) method and a 10.5% reduction relative to the\nMarkov-chain-based (MCB) method. Moreover, it is nearly an order of magnitude\nfaster than conventional techniques. Analyses of vehicle-specific power\ndistributions and wavelet-transformed frequency content further confirm its\nability to reproduce experimental central tendencies and variability.", "published": "2025-06-09 16:44:42", "link": "http://arxiv.org/abs/2506.07929v1", "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "W4S4: WaLRUS Meets S4 for Long-Range Sequence Modeling", "abstract": "State Space Models (SSMs) have emerged as powerful components for sequence\nmodeling, enabling efficient handling of long-range dependencies via linear\nrecurrence and convolutional computation. However, their effectiveness depends\nheavily on the choice and initialization of the state matrix. In this work, we\nbuild on the SaFARi framework and existing WaLRUS SSMs to introduce a new\nvariant, W4S4 (WaLRUS for S4), a new class of SSMs constructed from redundant\nwavelet frames. WaLRUS admits a stable diagonalization and supports fast kernel\ncomputation without requiring low-rank approximations, making it both\ntheoretically grounded and computationally efficient. We show that WaLRUS\nretains information over long horizons significantly better than HiPPO-based\nSSMs, both in isolation and when integrated into deep architectures such as S4.\nOur experiments demonstrate consistent improvements across delay reconstruction\ntasks, classification benchmarks, and long-range sequence modeling, confirming\nthat high-quality, structured initialization enabled by wavelet-based state\ndynamic offers substantial advantages over existing alternatives. WaLRUS\nprovides a scalable and versatile foundation for the next generation of deep\nSSM-based models.", "published": "2025-06-09 16:33:29", "link": "http://arxiv.org/abs/2506.07920v1", "categories": ["cs.LG", "eess.AS", "eess.IV", "eess.SP"], "primary_category": "cs.LG"}
{"title": "CausalPFN: Amortized Causal Effect Estimation via In-Context Learning", "abstract": "Causal effect estimation from observational data is fundamental across\nvarious applications. However, selecting an appropriate estimator from dozens\nof specialized methods demands substantial manual effort and domain expertise.\nWe present CausalPFN, a single transformer that amortizes this workflow:\ntrained once on a large library of simulated data-generating processes that\nsatisfy ignorability, it infers causal effects for new observational datasets\nout-of-the-box. CausalPFN combines ideas from Bayesian causal inference with\nthe large-scale training protocol of prior-fitted networks (PFNs), learning to\nmap raw observations directly to causal effects without any task-specific\nadjustment. Our approach achieves superior average performance on heterogeneous\nand average treatment effect estimation benchmarks (IHDP, Lalonde, ACIC).\nMoreover, it shows competitive performance for real-world policy making on\nuplift modeling tasks. CausalPFN provides calibrated uncertainty estimates to\nsupport reliable decision-making based on Bayesian principles. This\nready-to-use model does not require any further training or tuning and takes a\nstep toward automated causal inference (https://github.com/vdblm/CausalPFN).", "published": "2025-06-09 16:31:06", "link": "http://arxiv.org/abs/2506.07918v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "FunDiff: Diffusion Models over Function Spaces for Physics-Informed Generative Modeling", "abstract": "Recent advances in generative modeling -- particularly diffusion models and\nflow matching -- have achieved remarkable success in synthesizing discrete data\nsuch as images and videos. However, adapting these models to physical\napplications remains challenging, as the quantities of interest are continuous\nfunctions governed by complex physical laws. Here, we introduce\n$\\textbf{FunDiff}$, a novel framework for generative modeling in function\nspaces. FunDiff combines a latent diffusion process with a function autoencoder\narchitecture to handle input functions with varying discretizations, generate\ncontinuous functions evaluable at arbitrary locations, and seamlessly\nincorporate physical priors. These priors are enforced through architectural\nconstraints or physics-informed loss functions, ensuring that generated samples\nsatisfy fundamental physical laws. We theoretically establish minimax\noptimality guarantees for density estimation in function spaces, showing that\ndiffusion-based estimators achieve optimal convergence rates under suitable\nregularity conditions. We demonstrate the practical effectiveness of FunDiff\nacross diverse applications in fluid dynamics and solid mechanics. Empirical\nresults show that our method generates physically consistent samples with high\nfidelity to the target distribution and exhibits robustness to noisy and\nlow-resolution data. Code and datasets are publicly available at\nhttps://github.com/sifanexisted/fundiff.", "published": "2025-06-09 16:19:59", "link": "http://arxiv.org/abs/2506.07902v1", "categories": ["cs.LG", "physics.comp-ph", "stat.ML"], "primary_category": "cs.LG"}
{"title": "SoK: Data Reconstruction Attacks Against Machine Learning Models: Definition, Metrics, and Benchmark", "abstract": "Data reconstruction attacks, which aim to recover the training dataset of a\ntarget model with limited access, have gained increasing attention in recent\nyears. However, there is currently no consensus on a formal definition of data\nreconstruction attacks or appropriate evaluation metrics for measuring their\nquality. This lack of rigorous definitions and universal metrics has hindered\nfurther advancement in this field. In this paper, we address this issue in the\nvision domain by proposing a unified attack taxonomy and formal definitions of\ndata reconstruction attacks. We first propose a set of quantitative evaluation\nmetrics that consider important criteria such as quantifiability, consistency,\nprecision, and diversity. Additionally, we leverage large language models\n(LLMs) as a substitute for human judgment, enabling visual evaluation with an\nemphasis on high-quality reconstructions. Using our proposed taxonomy and\nmetrics, we present a unified framework for systematically evaluating the\nstrengths and limitations of existing attacks and establishing a benchmark for\nfuture research. Empirical results, primarily from a memorization perspective,\nnot only validate the effectiveness of our metrics but also offer valuable\ninsights for designing new attacks.", "published": "2025-06-09 16:00:48", "link": "http://arxiv.org/abs/2506.07888v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Schauder Bases for $C[0, 1]$ Using ReLU, Softplus and Two Sigmoidal Functions", "abstract": "We construct four Schauder bases for the space $C[0,1]$, one using ReLU\nfunctions, another using Softplus functions, and two more using sigmoidal\nversions of the ReLU and Softplus functions. This establishes the existence of\na basis using these functions for the first time, and improves on the universal\napproximation property associated with them.", "published": "2025-06-09 15:55:43", "link": "http://arxiv.org/abs/2506.07884v1", "categories": ["cs.LG", "math.FA", "46B15", "I.2.6"], "primary_category": "cs.LG"}
{"title": "Can Hessian-Based Insights Support Fault Diagnosis in Attention-based Models?", "abstract": "As attention-based deep learning models scale in size and complexity,\ndiagnosing their faults becomes increasingly challenging. In this work, we\nconduct an empirical study to evaluate the potential of Hessian-based analysis\nfor diagnosing faults in attention-based models. Specifically, we use\nHessian-derived insights to identify fragile regions (via curvature analysis)\nand parameter interdependencies (via parameter interaction analysis) within\nattention mechanisms. Through experiments on three diverse models (HAN, 3D-CNN,\nDistilBERT), we show that Hessian-based metrics can localize instability and\npinpoint fault sources more effectively than gradients alone. Our empirical\nfindings suggest that these metrics could significantly improve fault diagnosis\nin complex neural architectures, potentially improving software debugging\npractices.", "published": "2025-06-09 15:40:32", "link": "http://arxiv.org/abs/2506.07871v1", "categories": ["cs.LG", "cs.SE"], "primary_category": "cs.LG"}
{"title": "Deep reinforcement learning for near-deterministic preparation of cubic- and quartic-phase gates in photonic quantum computing", "abstract": "Cubic-phase states are a sufficient resource for universal quantum computing\nover continuous variables. We present results from numerical experiments in\nwhich deep neural networks are trained via reinforcement learning to control a\nquantum optical circuit for generating cubic-phase states, with an average\nsuccess rate of 96%. The only non-Gaussian resource required is\nphoton-number-resolving measurements. We also show that the exact same\nresources enable the direct generation of a quartic-phase gate, with no need\nfor a cubic gate decomposition.", "published": "2025-06-09 15:22:54", "link": "http://arxiv.org/abs/2506.07859v1", "categories": ["quant-ph", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Conditional Local Independence Testing with Application to Dynamic Causal Discovery", "abstract": "In this note, we extend the conditional local independence testing theory\ndeveloped in Christgau et al. (2024) to Ito processes. The result can be\napplied to causal discovery in dynamic systems.", "published": "2025-06-09 15:08:41", "link": "http://arxiv.org/abs/2506.07844v1", "categories": ["stat.ME", "cs.LG"], "primary_category": "stat.ME"}
{"title": "Jarzynski Reweighting and Sampling Dynamics for Training Energy-Based Models: Theoretical Analysis of Different Transition Kernels", "abstract": "Energy-Based Models (EBMs) provide a flexible framework for generative\nmodeling, but their training remains theoretically challenging due to the need\nto approximate normalization constants and efficiently sample from complex,\nmulti-modal distributions. Traditional methods, such as contrastive divergence\nand score matching, introduce biases that can hinder accurate learning. In this\nwork, we present a theoretical analysis of Jarzynski reweighting, a technique\nfrom non-equilibrium statistical mechanics, and its implications for training\nEBMs. We focus on the role of the choice of the kernel and we illustrate these\ntheoretical considerations in two key generative frameworks: (i) flow-based\ndiffusion models, where we reinterpret Jarzynski reweighting in the context of\nstochastic interpolants to mitigate discretization errors and improve sample\nquality, and (ii) Restricted Boltzmann Machines, where we analyze its role in\ncorrecting the biases of contrastive divergence. Our results provide insights\ninto the interplay between kernel choice and model performance, highlighting\nthe potential of Jarzynski reweighting as a principled tool for generative\nlearning.", "published": "2025-06-09 15:08:01", "link": "http://arxiv.org/abs/2506.07843v1", "categories": ["cs.LG", "physics.comp-ph"], "primary_category": "cs.LG"}
{"title": "Accelerating Constrained Sampling: A Large Deviations Approach", "abstract": "The problem of sampling a target probability distribution on a constrained\ndomain arises in many applications including machine learning. For constrained\nsampling, various Langevin algorithms such as projected Langevin Monte Carlo\n(PLMC) based on the discretization of reflected Langevin dynamics (RLD) and\nmore generally skew-reflected non-reversible Langevin Monte Carlo (SRNLMC)\nbased on the discretization of skew-reflected non-reversible Langevin dynamics\n(SRNLD) have been proposed and studied in the literature. This work focuses on\nthe long-time behavior of SRNLD, where a skew-symmetric matrix is added to RLD.\nAlthough the non-asymptotic convergence analysis for SRNLD (and SRNLMC) and the\nacceleration compared to RLD (and PMLC) have been studied in the literature, it\nis not clear how one should design the skew-symmetric matrix in the dynamics to\nachieve good performance in practice. We establish a large deviation principle\n(LDP) for the empirical measure of SRNLD when the skew-symmetric matrix is\nchosen such that its product with the inward unit normal vector field on the\nboundary is zero. By explicitly characterizing the rate functions, we show that\nSRNLD can accelerate the convergence to the target distribution compared to RLD\nwith this choice of the skew-symmetric matrix. Numerical experiments for SRNLMC\nbased on the proposed skew-symmetric matrix show superior performance which\nvalidate the theoretical findings from the large deviations theory.", "published": "2025-06-09 14:44:39", "link": "http://arxiv.org/abs/2506.07816v1", "categories": ["stat.ML", "cs.LG", "math.PR"], "primary_category": "stat.ML"}
{"title": "A weighted quantum ensemble of homogeneous quantum classifiers", "abstract": "Ensemble methods in machine learning aim to improve prediction accuracy by\ncombining multiple models. This is achieved by ensuring diversity among\npredictors to capture different data aspects. Homogeneous ensembles use\nidentical models, achieving diversity through different data subsets, and\nweighted-average ensembles assign higher influence to more accurate models\nthrough a weight learning procedure. We propose a method to achieve a weighted\nhomogeneous quantum ensemble using quantum classifiers with indexing registers\nfor data encoding. This approach leverages instance-based quantum classifiers,\nenabling feature and training point subsampling through superposition and\ncontrolled unitaries, and allowing for a quantum-parallel execution of diverse\ninternal classifiers with different data compositions in superposition. The\nmethod integrates a learning process involving circuit execution and classical\nweight optimization, for a trained ensemble execution with weights encoded in\nthe circuit at test-time. Empirical evaluation demonstrate the effectiveness of\nthe proposed method, offering insights into its performance.", "published": "2025-06-09 14:38:13", "link": "http://arxiv.org/abs/2506.07810v1", "categories": ["quant-ph", "cs.ET", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Diffusion Models-Aided Uplink Channel Estimation for RIS-Assisted Systems", "abstract": "This letter proposes a channel estimation method for reconfigurable\nintelligent surface (RIS)-assisted systems through a novel diffusion model (DM)\nframework. We reformulate the channel estimation problem as a denoising\nprocess, which aligns with the reverse process of the DM. To overcome the\ninherent randomness in the reverse process of conventional DM approaches, we\nadopt a deterministic sampling strategy with a step alignment mechanism that\nensures the accuracy of channel estimation while adapting to different\nsignal-to-noise ratio (SNR). Furthermore, to reduce the number of parameters of\nthe U-Net, we meticulously design a lightweight network that achieves\ncomparable performance, thereby enhancing the practicality of our proposed\nmethod. Extensive simulations demonstrate superior performance over a wide\nrange of SNRs compared to baselines. For instance, the proposed method achieves\nperformance improvements of up to 13.5 dB in normalized mean square error\n(NMSE) at SNR = 0 dB. Notably, the proposed lightweight network exhibits almost\nno performance loss compared to the original U-Net, while requiring only 6.59\\%\nof its parameters.", "published": "2025-06-09 13:46:44", "link": "http://arxiv.org/abs/2506.07770v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Clustered Federated Learning via Embedding Distributions", "abstract": "Federated learning (FL) is a widely used framework for machine learning in\ndistributed data environments where clients hold data that cannot be easily\ncentralised, such as for data protection reasons. FL, however, is known to be\nvulnerable to non-IID data. Clustered FL addresses this issue by finding more\nhomogeneous clusters of clients. We propose a novel one-shot clustering method,\nEMD-CFL, using the Earth Mover's distance (EMD) between data distributions in\nembedding space. We theoretically motivate the use of EMDs using results from\nthe domain adaptation literature and demonstrate empirically superior\nclustering performance in extensive comparisons against 16 baselines and on a\nrange of challenging datasets.", "published": "2025-06-09 13:46:10", "link": "http://arxiv.org/abs/2506.07769v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Quickest Causal Change Point Detection by Adaptive Intervention", "abstract": "We propose an algorithm for change point monitoring in linear causal models\nthat accounts for interventions. Through a special centralization technique, we\ncan concentrate the changes arising from causal propagation across nodes into a\nsingle dimension. Additionally, by selecting appropriate intervention nodes\nbased on Kullback-Leibler divergence, we can amplify the change magnitude. We\nalso present an algorithm for selecting the intervention values, which aids in\nthe identification of the most effective intervention nodes. Two monitoring\nmethods are proposed, each with an adaptive intervention policy to make a\nbalance between exploration and exploitation. We theoretically demonstrate the\nfirst-order optimality of the proposed methods and validate their properties\nusing simulation datasets and two real-world case studies.", "published": "2025-06-09 13:39:35", "link": "http://arxiv.org/abs/2506.07760v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Profiling Electric Vehicles via Early Charging Voltage Patterns", "abstract": "Electric Vehicles (EVs) are rapidly gaining adoption as a sustainable\nalternative to fuel-powered vehicles, making secure charging infrastructure\nessential. Despite traditional authentication protocols, recent results showed\nthat attackers may steal energy through tailored relay attacks. One\ncountermeasure is leveraging the EV's fingerprint on the current exchanged\nduring charging. However, existing methods focus on the final charging stage,\nallowing malicious actors to consume substantial energy before being detected\nand repudiated. This underscores the need for earlier and more effective\nauthentication methods to prevent unauthorized charging. Meanwhile, profiling\nraises privacy concerns, as uniquely identifying EVs through charging patterns\ncould enable user tracking.\n  In this paper, we propose a framework for uniquely identifying EVs using\nphysical measurements from the early charging stages. We hypothesize that\nvoltage behavior early in the process exhibits similar characteristics to\ncurrent behavior in later stages. By extracting features from early voltage\nmeasurements, we demonstrate the feasibility of EV profiling. Our approach\nimproves existing methods by enabling faster and more reliable vehicle\nidentification. We test our solution on a dataset of 7408 usable charges from\n49 EVs, achieving up to 0.86 accuracy. Feature importance analysis shows that\nnear-optimal performance is possible with just 10 key features, improving\nefficiency alongside our lightweight models. This research lays the foundation\nfor a novel authentication factor while exposing potential privacy risks from\nunauthorized access to charging data.", "published": "2025-06-09 12:57:37", "link": "http://arxiv.org/abs/2506.07714v1", "categories": ["cs.CR", "cs.ET", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Evaluating Robustness in Latent Diffusion Models via Embedding Level Augmentation", "abstract": "Latent diffusion models (LDMs) achieve state-of-the-art performance across\nvarious tasks, including image generation and video synthesis. However, they\ngenerally lack robustness, a limitation that remains not fully explored in\ncurrent research. In this paper, we propose several methods to address this\ngap. First, we hypothesize that the robustness of LDMs primarily should be\nmeasured without their text encoder, because if we take and explore the whole\narchitecture, the problems of image generator and text encoders wll be fused.\nSecond, we introduce novel data augmentation techniques designed to reveal\nrobustness shortcomings in LDMs when processing diverse textual prompts. We\nthen fine-tune Stable Diffusion 3 and Stable Diffusion XL models using\nDreambooth, incorporating these proposed augmentation methods across multiple\ntasks. Finally, we propose a novel evaluation pipeline specifically tailored to\nassess the robustness of LDMs fine-tuned via Dreambooth.", "published": "2025-06-09 12:48:45", "link": "http://arxiv.org/abs/2506.07706v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Towards a Small Language Model Lifecycle Framework", "abstract": "Background: The growing demand for efficient and deployable language models\nhas led to increased interest in Small Language Models (SLMs). However,\nexisting research remains fragmented, lacking a unified lifecycle perspective.\n  Objective: This study aims to define a comprehensive lifecycle framework for\nSLMs by synthesizing insights from academic literature and practitioner\nsources.\n  Method: We conducted a comprehensive survey of 36 works, analyzing and\ncategorizing lifecycle-relevant techniques.\n  Results: We propose a modular lifecycle model structured into main, optional,\nand cross-cutting components. The model captures key interconnections across\nstages, supporting method reuse, co-adaptation, and lifecycle-awareness.\n  Conclusion: Our framework provides a coherent foundation for developing and\nmaintaining SLMs, bridging theory and practice, and guiding future research and\ntool development.", "published": "2025-06-09 12:33:05", "link": "http://arxiv.org/abs/2506.07695v1", "categories": ["cs.SE", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Rao-Blackwellised Reparameterisation Gradients", "abstract": "Latent Gaussian variables have been popularised in probabilistic machine\nlearning. In turn, gradient estimators are the machinery that facilitates\ngradient-based optimisation for models with latent Gaussian variables. The\nreparameterisation trick is often used as the default estimator as it is simple\nto implement and yields low-variance gradients for variational inference. In\nthis work, we propose the R2-G2 estimator as the Rao-Blackwellisation of the\nreparameterisation gradient estimator. Interestingly, we show that the local\nreparameterisation gradient estimator for Bayesian MLPs is an instance of the\nR2-G2 estimator and Rao-Blackwellisation. This lets us extend benefits of\nRao-Blackwellised gradients to a suite of probabilistic models. We show that\ninitial training with R2-G2 consistently yields better performance in models\nwith multiple applications of the reparameterisation trick.", "published": "2025-06-09 12:17:19", "link": "http://arxiv.org/abs/2506.07687v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "How Benchmark Prediction from Fewer Data Misses the Mark", "abstract": "Large language model (LLM) evaluation is increasingly costly, prompting\ninterest in methods that speed up evaluation by shrinking benchmark datasets.\nBenchmark prediction (also called efficient LLM evaluation) aims to select a\nsmall subset of evaluation points and predict overall benchmark performance\nfrom that subset. In this paper, we systematically assess the strengths and\nlimitations of 11 benchmark prediction methods across 19 diverse benchmarks.\nFirst, we identify a highly competitive baseline: Take a random sample and fit\na regression model on the sample to predict missing entries. Outperforming most\nexisting methods, this baseline challenges the assumption that careful subset\nselection is necessary for benchmark prediction. Second, we discover that all\nexisting methods crucially depend on model similarity. They work best when\ninterpolating scores among similar models. The effectiveness of benchmark\nprediction sharply declines when new models have higher accuracy than\npreviously seen models. In this setting of extrapolation, none of the previous\nmethods consistently beat a simple average over random samples. To improve over\nthe sample average, we introduce a new method inspired by augmented inverse\npropensity weighting. This method consistently outperforms the random sample\naverage even for extrapolation. However, its performance still relies on model\nsimilarity and the gains are modest in general. This shows that benchmark\nprediction fails just when it is most needed: at the evaluation frontier, where\nthe goal is to evaluate new models of unknown capabilities.", "published": "2025-06-09 11:50:41", "link": "http://arxiv.org/abs/2506.07673v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "ProARD: progressive adversarial robustness distillation: provide wide range of robust students", "abstract": "Adversarial Robustness Distillation (ARD) has emerged as an effective method\nto enhance the robustness of lightweight deep neural networks against\nadversarial attacks. Current ARD approaches have leveraged a large robust\nteacher network to train one robust lightweight student. However, due to the\ndiverse range of edge devices and resource constraints, current approaches\nrequire training a new student network from scratch to meet specific\nconstraints, leading to substantial computational costs and increased CO2\nemissions. This paper proposes Progressive Adversarial Robustness Distillation\n(ProARD), enabling the efficient one-time training of a dynamic network that\nsupports a diverse range of accurate and robust student networks without\nrequiring retraining. We first make a dynamic deep neural network based on\ndynamic layers by encompassing variations in width, depth, and expansion in\neach design stage to support a wide range of architectures. Then, we consider\nthe student network with the largest size as the dynamic teacher network.\nProARD trains this dynamic network using a weight-sharing mechanism to jointly\noptimize the dynamic teacher network and its internal student networks.\nHowever, due to the high computational cost of calculating exact gradients for\nall the students within the dynamic network, a sampling mechanism is required\nto select a subset of students. We show that random student sampling in each\niteration fails to produce accurate and robust students.", "published": "2025-06-09 11:39:25", "link": "http://arxiv.org/abs/2506.07666v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Return of ChebNet: Understanding and Improving an Overlooked GNN on Long Range Tasks", "abstract": "ChebNet, one of the earliest spectral GNNs, has largely been overshadowed by\nMessage Passing Neural Networks (MPNNs), which gained popularity for their\nsimplicity and effectiveness in capturing local graph structure. Despite their\nsuccess, MPNNs are limited in their ability to capture long-range dependencies\nbetween nodes. This has led researchers to adapt MPNNs through rewiring or make\nuse of Graph Transformers, which compromises the computational efficiency that\ncharacterized early spatial message-passing architectures, and typically\ndisregards the graph structure. Almost a decade after its original\nintroduction, we revisit ChebNet to shed light on its ability to model distant\nnode interactions. We find that out-of-box, ChebNet already shows competitive\nadvantages relative to classical MPNNs and GTs on long-range benchmarks, while\nmaintaining good scalability properties for high-order polynomials. However, we\nuncover that this polynomial expansion leads ChebNet to an unstable regime\nduring training. To address this limitation, we cast ChebNet as a stable and\nnon-dissipative dynamical system, which we coin Stable-ChebNet. Our\nStable-ChebNet model allows for stable information propagation, and has\ncontrollable dynamics which do not require the use of eigendecompositions,\npositional encodings, or graph rewiring. Across several benchmarks,\nStable-ChebNet achieves near state-of-the-art performance.", "published": "2025-06-09 10:41:34", "link": "http://arxiv.org/abs/2506.07624v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "The Catechol Benchmark: Time-series Solvent Selection Data for Few-shot Machine Learning", "abstract": "Machine learning has promised to change the landscape of laboratory\nchemistry, with impressive results in molecular property prediction and\nreaction retro-synthesis. However, chemical datasets are often inaccessible to\nthe machine learning community as they tend to require cleaning, thorough\nunderstanding of the chemistry, or are simply not available. In this paper, we\nintroduce a novel dataset for yield prediction, providing the first-ever\ntransient flow dataset for machine learning benchmarking, covering over 1200\nprocess conditions. While previous datasets focus on discrete parameters, our\nexperimental set-up allow us to sample a large number of continuous process\nconditions, generating new challenges for machine learning models. We focus on\nsolvent selection, a task that is particularly difficult to model theoretically\nand therefore ripe for machine learning applications. We showcase benchmarking\nfor regression algorithms, transfer-learning approaches, feature engineering,\nand active learning, with important applications towards solvent replacement\nand sustainable manufacturing.", "published": "2025-06-09 10:34:14", "link": "http://arxiv.org/abs/2506.07619v1", "categories": ["cs.LG", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "FuXi-Air: Urban Air Quality Forecasting Based on Emission-Meteorology-Pollutant multimodal Machine Learning", "abstract": "Air pollution has emerged as a major public health challenge in megacities.\nNumerical simulations and single-site machine learning approaches have been\nwidely applied in air quality forecasting tasks. However, these methods face\nmultiple limitations, including high computational costs, low operational\nefficiency, and limited integration with observational data. With the rapid\nadvancement of artificial intelligence, there is an urgent need to develop a\nlow-cost, efficient air quality forecasting model for smart urban management.\nAn air quality forecasting model, named FuXi-Air, has been constructed in this\nstudy based on multimodal data fusion to support high-precision air quality\nforecasting and operated in typical megacities. The model integrates\nmeteorological forecasts, emission inventories, and pollutant monitoring data\nunder the guidance of air pollution mechanism. By combining an autoregressive\nprediction framework with a frame interpolation strategy, the model\nsuccessfully completes 72-hour forecasts for six major air pollutants at an\nhourly resolution across multiple monitoring sites within 25-30 seconds. In\nterms of both computational efficiency and forecasting accuracy, it outperforms\nthe mainstream numerical air quality models in operational forecasting work.\nAblation experiments concerning key influencing factors show that although\nmeteorological data contribute more to model accuracy than emission inventories\ndo, the integration of multimodal data significantly improves forecasting\nprecision and ensures that reliable predictions are obtained under differing\npollution mechanisms across megacities. This study provides both a technical\nreference and a practical example for applying multimodal data-driven models to\nair quality forecasting and offers new insights into building hybrid\nforecasting systems to support air pollution risk warning in smart city\nmanagement.", "published": "2025-06-09 10:27:50", "link": "http://arxiv.org/abs/2506.07616v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Poisson Midpoint Method for Log Concave Sampling: Beyond the Strong Error Lower Bounds", "abstract": "We study the problem of sampling from strongly log-concave distributions over\n$\\mathbb{R}^d$ using the Poisson midpoint discretization (a variant of the\nrandomized midpoint method) for overdamped/underdamped Langevin dynamics. We\nprove its convergence in the 2-Wasserstein distance ($W_2$), achieving a cubic\nspeedup in dependence on the target accuracy ($\\epsilon$) over the\nEuler-Maruyama discretization, surpassing existing bounds for randomized\nmidpoint methods. Notably, in the case of underdamped Langevin dynamics, we\ndemonstrate the complexity of $W_2$ convergence is much smaller than the\ncomplexity lower bounds for convergence in $L^2$ strong error established in\nthe literature.", "published": "2025-06-09 10:27:15", "link": "http://arxiv.org/abs/2506.07614v1", "categories": ["math.PR", "cs.LG", "math.ST", "stat.TH"], "primary_category": "math.PR"}
{"title": "TimberStrike: Dataset Reconstruction Attack Revealing Privacy Leakage in Federated Tree-Based Systems", "abstract": "Federated Learning has emerged as a privacy-oriented alternative to\ncentralized Machine Learning, enabling collaborative model training without\ndirect data sharing. While extensively studied for neural networks, the\nsecurity and privacy implications of tree-based models remain underexplored.\nThis work introduces TimberStrike, an optimization-based dataset reconstruction\nattack targeting horizontally federated tree-based models. Our attack, carried\nout by a single client, exploits the discrete nature of decision trees by using\nsplit values and decision paths to infer sensitive training data from other\nclients. We evaluate TimberStrike on State-of-the-Art federated gradient\nboosting implementations across multiple frameworks, including Flower, NVFlare,\nand FedTree, demonstrating their vulnerability to privacy breaches. On a\npublicly available stroke prediction dataset, TimberStrike consistently\nreconstructs between 73.05% and 95.63% of the target dataset across all\nimplementations. We further analyze Differential Privacy, showing that while it\npartially mitigates the attack, it also significantly degrades model\nperformance. Our findings highlight the need for privacy-preserving mechanisms\nspecifically designed for tree-based Federated Learning systems, and we provide\npreliminary insights into their design.", "published": "2025-06-09 10:06:03", "link": "http://arxiv.org/abs/2506.07605v1", "categories": ["cs.CR", "cs.DC", "cs.LG"], "primary_category": "cs.CR"}
{"title": "TwinBreak: Jailbreaking LLM Security Alignments based on Twin Prompts", "abstract": "Machine learning is advancing rapidly, with applications bringing notable\nbenefits, such as improvements in translation and code generation. Models like\nChatGPT, powered by Large Language Models (LLMs), are increasingly integrated\ninto daily life. However, alongside these benefits, LLMs also introduce social\nrisks. Malicious users can exploit LLMs by submitting harmful prompts, such as\nrequesting instructions for illegal activities. To mitigate this, models often\ninclude a security mechanism that automatically rejects such harmful prompts.\nHowever, they can be bypassed through LLM jailbreaks. Current jailbreaks often\nrequire significant manual effort, high computational costs, or result in\nexcessive model modifications that may degrade regular utility.\n  We introduce TwinBreak, an innovative safety alignment removal method.\nBuilding on the idea that the safety mechanism operates like an embedded\nbackdoor, TwinBreak identifies and prunes parameters responsible for this\nfunctionality. By focusing on the most relevant model layers, TwinBreak\nperforms fine-grained analysis of parameters essential to model utility and\nsafety. TwinBreak is the first method to analyze intermediate outputs from\nprompts with high structural and content similarity to isolate safety\nparameters. We present the TwinPrompt dataset containing 100 such twin prompts.\nExperiments confirm TwinBreak's effectiveness, achieving 89% to 98% success\nrates with minimal computational requirements across 16 LLMs from five vendors.", "published": "2025-06-09 09:54:25", "link": "http://arxiv.org/abs/2506.07596v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Exploiting Curvature in Online Convex Optimization with Delayed Feedback", "abstract": "In this work, we study the online convex optimization problem with curved\nlosses and delayed feedback. When losses are strongly convex, existing\napproaches obtain regret bounds of order $d_{\\max} \\ln T$, where $d_{\\max}$ is\nthe maximum delay and $T$ is the time horizon. However, in many cases, this\nguarantee can be much worse than $\\sqrt{d_{\\mathrm{tot}}}$ as obtained by a\ndelayed version of online gradient descent, where $d_{\\mathrm{tot}}$ is the\ntotal delay. We bridge this gap by proposing a variant of\nfollow-the-regularized-leader that obtains regret of order\n$\\min\\{\\sigma_{\\max}\\ln T, \\sqrt{d_{\\mathrm{tot}}}\\}$, where $\\sigma_{\\max}$ is\nthe maximum number of missing observations. We then consider exp-concave losses\nand extend the Online Newton Step algorithm to handle delays with an adaptive\nlearning rate tuning, achieving regret $\\min\\{d_{\\max} n\\ln T,\n\\sqrt{d_{\\mathrm{tot}}}\\}$ where $n$ is the dimension. To our knowledge, this\nis the first algorithm to achieve such a regret bound for exp-concave losses.\nWe further consider the problem of unconstrained online linear regression and\nachieve a similar guarantee by designing a variant of the Vovk-Azoury-Warmuth\nforecaster with a clipping trick. Finally, we implement our algorithms and\nconduct experiments under various types of delay and losses, showing an\nimproved performance over existing methods.", "published": "2025-06-09 09:49:54", "link": "http://arxiv.org/abs/2506.07595v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Aircraft Trajectory Dataset Augmentation in Latent Space", "abstract": "Aircraft trajectory modeling plays a crucial role in Air Traffic Management\n(ATM) and is important for various downstream tasks, including conflict\ndetection and landing time prediction. Dataset augmentation through the\naddition of synthetically generated trajectory data is necessary to develop a\nmore robust aircraft trajectory model and ensure that the trajectory dataset is\nsufficient and balanced. In this work, we propose a novel framework called\nATRADA for aircraft trajectory dataset augmentation. In the proposed framework,\na Transformer encoder learns the underlying patterns in the original trajectory\ndataset and converts each data point into a context vector in the learned\nlatent space. The converted dataset in the latent space is projected into\nreduced dimensions using principal component analysis (PCA), and a Gaussian\nmixture model (GMM) is applied to fit the probability distribution of the data\npoints in the reduced-dimensional space. Finally, new samples are drawn from\nthe fitted GMM, the dimension of the samples is reverted to the original\ndimension, and they are decoded with a Multi-Layer Perceptron (MLP). Several\nexperiments demonstrate that the framework effectively generates new,\nhigh-quality synthetic aircraft trajectory data, which were compared to the\nresults of several baselines.", "published": "2025-06-09 09:29:37", "link": "http://arxiv.org/abs/2506.07585v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "MIRA: Medical Time Series Foundation Model for Real-World Health Data", "abstract": "A unified foundation model for medical time series -- pretrained on open\naccess and ethics board-approved medical corpora -- offers the potential to\nreduce annotation burdens, minimize model customization, and enable robust\ntransfer across clinical institutions, modalities, and tasks, particularly in\ndata-scarce or privacy-constrained environments. However, existing generalist\ntime series foundation models struggle to handle medical time series data due\nto their inherent challenges, including irregular intervals, heterogeneous\nsampling rates, and frequent missing values. To address these challenges, we\nintroduce MIRA, a unified foundation model specifically designed for medical\ntime series forecasting. MIRA incorporates a Continuous-Time Rotary Positional\nEncoding that enables fine-grained modeling of variable time intervals, a\nfrequency-specific mixture-of-experts layer that routes computation across\nlatent frequency regimes to further promote temporal specialization, and a\nContinuous Dynamics Extrapolation Block based on Neural ODE that models the\ncontinuous trajectory of latent states, enabling accurate forecasting at\narbitrary target timestamps. Pretrained on a large-scale and diverse medical\ncorpus comprising over 454 billion time points collect from publicly available\ndatasets, MIRA achieves reductions in forecasting errors by an average of 10%\nand 7% in out-of-distribution and in-distribution scenarios, respectively, when\ncompared to other zero-shot and fine-tuned baselines. We also introduce a\ncomprehensive benchmark spanning multiple downstream clinical tasks,\nestablishing a foundation for future research in medical time series modeling.", "published": "2025-06-09 09:27:17", "link": "http://arxiv.org/abs/2506.07584v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Improving Memory Efficiency for Training KANs via Meta Learning", "abstract": "Inspired by the Kolmogorov-Arnold representation theorem, KANs offer a novel\nframework for function approximation by replacing traditional neural network\nweights with learnable univariate functions. This design demonstrates\nsignificant potential as an efficient and interpretable alternative to\ntraditional MLPs. However, KANs are characterized by a substantially larger\nnumber of trainable parameters, leading to challenges in memory efficiency and\nhigher training costs compared to MLPs. To address this limitation, we propose\nto generate weights for KANs via a smaller meta-learner, called MetaKANs. By\ntraining KANs and MetaKANs in an end-to-end differentiable manner, MetaKANs\nachieve comparable or even superior performance while significantly reducing\nthe number of trainable parameters and maintaining promising interpretability.\nExtensive experiments on diverse benchmark tasks, including symbolic\nregression, partial differential equation solving, and image classification,\ndemonstrate the effectiveness of MetaKANs in improving parameter efficiency and\nmemory usage. The proposed method provides an alternative technique for\ntraining KANs, that allows for greater scalability and extensibility, and\nnarrows the training cost gap with MLPs stated in the original paper of KANs.\nOur code is available at https://github.com/Murphyzc/MetaKAN.", "published": "2025-06-09 08:38:26", "link": "http://arxiv.org/abs/2506.07549v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Flowing Datasets with Wasserstein over Wasserstein Gradient Flows", "abstract": "Many applications in machine learning involve data represented as probability\ndistributions. The emergence of such data requires radically novel techniques\nto design tractable gradient flows on probability distributions over this type\nof (infinite-dimensional) objects. For instance, being able to flow labeled\ndatasets is a core task for applications ranging from domain adaptation to\ntransfer learning or dataset distillation. In this setting, we propose to\nrepresent each class by the associated conditional distribution of features,\nand to model the dataset as a mixture distribution supported on these classes\n(which are themselves probability distributions), meaning that labeled datasets\ncan be seen as probability distributions over probability distributions. We\nendow this space with a metric structure from optimal transport, namely the\nWasserstein over Wasserstein (WoW) distance, derive a differential structure on\nthis space, and define WoW gradient flows. The latter enables to design\ndynamics over this space that decrease a given objective functional. We apply\nour framework to transfer learning and dataset distillation tasks, leveraging\nour gradient flow construction as well as novel tractable functionals that take\nthe form of Maximum Mean Discrepancies with Sliced-Wasserstein based kernels\nbetween probability distributions.", "published": "2025-06-09 08:17:35", "link": "http://arxiv.org/abs/2506.07534v1", "categories": ["cs.LG", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Mind the Gap: Removing the Discretization Gap in Differentiable Logic Gate Networks", "abstract": "Modern neural networks demonstrate state-of-the-art performance on numerous\nexisting benchmarks; however, their high computational requirements and energy\nconsumption prompt researchers to seek more efficient solutions for real-world\ndeployment. Logic gate networks (LGNs) learns a large network of logic gates\nfor efficient image classification. However, learning a network that can solve\na simple problem like CIFAR-10 can take days to weeks to train. Even then,\nalmost half of the network remains unused, causing a discretization gap. This\ndiscretization gap hinders real-world deployment of LGNs, as the performance\ndrop between training and inference negatively impacts accuracy. We inject\nGumbel noise with a straight-through estimator during training to significantly\nspeed up training, improve neuron utilization, and decrease the discretization\ngap. We theoretically show that this results from implicit Hessian\nregularization, which improves the convergence properties of LGNs. We train\nnetworks $4.5 \\times$ faster in wall-clock time, reduce the discretization gap\nby $98\\%$, and reduce the number of unused gates by $100\\%$.", "published": "2025-06-09 07:25:51", "link": "http://arxiv.org/abs/2506.07500v1", "categories": ["cs.LG", "cs.PF"], "primary_category": "cs.LG"}
{"title": "Explicit Preference Optimization: No Need for an Implicit Reward Model", "abstract": "The generated responses of large language models (LLMs) are often fine-tuned\nto human preferences through a process called reinforcement learning from human\nfeedback (RLHF). As RLHF relies on a challenging training sequence, whereby a\nseparate reward model is independently learned and then later applied to LLM\npolicy updates, ongoing research effort has targeted more straightforward\nalternatives. In this regard, direct preference optimization (DPO) and its many\noffshoots circumvent the need for a separate reward training step. Instead,\nthrough the judicious use of a reparameterization trick that induces an\n\\textit{implicit} reward, DPO and related methods consolidate learning to the\nminimization of a single loss function. And yet despite demonstrable success in\nsome real-world settings, we prove that DPO-based objectives are nonetheless\nsubject to sub-optimal regularization and counter-intuitive interpolation\nbehaviors, underappreciated artifacts of the reparameterizations upon which\nthey are based. To this end, we introduce an \\textit{explicit} preference\noptimization framework termed EXPO that requires no analogous\nreparameterization to achieve an implicit reward. Quite differently, we merely\nposit intuitively-appealing regularization factors from scratch that\ntransparently avoid the potential pitfalls of key DPO variants, provably\nsatisfying regularization desiderata that prior methods do not. Empirical\nresults serve to corroborate our analyses and showcase the efficacy of EXPO.", "published": "2025-06-09 07:11:01", "link": "http://arxiv.org/abs/2506.07492v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Deep Equivariant Multi-Agent Control Barrier Functions", "abstract": "With multi-agent systems increasingly deployed autonomously at scale in\ncomplex environments, ensuring safety of the data-driven policies is critical.\nControl Barrier Functions have emerged as an effective tool for enforcing\nsafety constraints, yet existing learning-based methods often lack in\nscalability, generalization and sampling efficiency as they overlook inherent\ngeometric structures of the system. To address this gap, we introduce\nsymmetries-infused distributed Control Barrier Functions, enforcing the\nsatisfaction of intrinsic symmetries on learnable graph-based safety\ncertificates. We theoretically motivate the need for equivariant\nparametrization of CBFs and policies, and propose a simple, yet efficient and\nadaptable methodology for constructing such equivariant group-modular networks\nvia the compatible group actions. This approach encodes safety constraints in a\ndistributed data-efficient manner, enabling zero-shot generalization to larger\nand denser swarms. Through extensive simulations on multi-robot navigation\ntasks, we demonstrate that our method outperforms state-of-the-art baselines in\nterms of safety, scalability, and task success rates, highlighting the\nimportance of embedding symmetries in safe distributed neural policies.", "published": "2025-06-09 13:37:29", "link": "http://arxiv.org/abs/2506.07755v1", "categories": ["eess.SY", "cs.MA", "cs.RO", "cs.SY"], "primary_category": "eess.SY"}
{"title": "MedChat: A Multi-Agent Framework for Multimodal Diagnosis with Large Language Models", "abstract": "The integration of deep learning-based glaucoma detection with large language\nmodels (LLMs) presents an automated strategy to mitigate ophthalmologist\nshortages and improve clinical reporting efficiency. However, applying general\nLLMs to medical imaging remains challenging due to hallucinations, limited\ninterpretability, and insufficient domain-specific medical knowledge, which can\npotentially reduce clinical accuracy. Although recent approaches combining\nimaging models with LLM reasoning have improved reporting, they typically rely\non a single generalist agent, restricting their capacity to emulate the diverse\nand complex reasoning found in multidisciplinary medical teams. To address\nthese limitations, we propose MedChat, a multi-agent diagnostic framework and\nplatform that combines specialized vision models with multiple role-specific\nLLM agents, all coordinated by a director agent. This design enhances\nreliability, reduces hallucination risk, and enables interactive diagnostic\nreporting through an interface tailored for clinical review and educational\nuse. Code available at https://github.com/Purdue-M2/MedChat.", "published": "2025-06-09 03:51:18", "link": "http://arxiv.org/abs/2506.07400v1", "categories": ["cs.MA", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.MA"}
{"title": "Shapley-Coop: Credit Assignment for Emergent Cooperation in Self-Interested LLM Agents", "abstract": "Large Language Models (LLMs) show strong collaborative performance in\nmulti-agent systems with predefined roles and workflows. However, in open-ended\nenvironments lacking coordination rules, agents tend to act in self-interested\nways. The central challenge in achieving coordination lies in credit assignment\n-- fairly evaluating each agent's contribution and designing pricing mechanisms\nthat align their heterogeneous goals. This problem is critical as LLMs\nincreasingly participate in complex human-AI collaborations, where fair\ncompensation and accountability rely on effective pricing mechanisms. Inspired\nby how human societies address similar coordination challenges (e.g., through\ntemporary collaborations such as employment or subcontracting), we propose a\ncooperative workflow, Shapley-Coop. Shapley-Coop integrates Shapley\nChain-of-Thought -- leveraging marginal contributions as a principled basis for\npricing -- with structured negotiation protocols for effective price matching,\nenabling LLM agents to coordinate through rational task-time pricing and\npost-task reward redistribution. This approach aligns agent incentives, fosters\ncooperation, and maintains autonomy. We evaluate Shapley-Coop across two\nmulti-agent games and a software engineering simulation, demonstrating that it\nconsistently enhances LLM agent collaboration and facilitates equitable credit\nassignment. These results highlight the effectiveness of Shapley-Coop's pricing\nmechanisms in accurately reflecting individual contributions during task\nexecution.", "published": "2025-06-09 03:24:01", "link": "http://arxiv.org/abs/2506.07388v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "Digital Twin-based Smart Manufacturing: Dynamic Line Reconfiguration for Disturbance Handling", "abstract": "The increasing complexity of modern manufacturing, coupled with demand\nfluctuation, supply chain uncertainties, and product customization, underscores\nthe need for manufacturing systems that can flexibly update their\nconfigurations and swiftly adapt to disturbances. However, current research\nfalls short in providing a holistic reconfigurable manufacturing framework that\nseamlessly monitors system disturbances, optimizes alternative line\nconfigurations based on machine capabilities, and automates simulation\nevaluation for swift adaptations. This paper presents a dynamic manufacturing\nline reconfiguration framework to handle disturbances that result in operation\ntime changes. The framework incorporates a system process digital twin for\nmonitoring disturbances and triggering reconfigurations, a capability-based\nontology model capturing available agent and resource options, a configuration\noptimizer generating optimal line configurations, and a simulation generation\nprogram initializing simulation setups and evaluating line configurations at\napproximately 400x real-time speed. A case study of a battery production line\nhas been conducted to evaluate the proposed framework. In two implemented\ndisturbance scenarios, the framework successfully recovers system throughput\nwith limited resources, preventing the 26% and 63% throughput drops that would\nhave occurred without a reconfiguration plan. The reconfiguration optimizer\nefficiently finds optimal solutions, taking an average of 0.03 seconds to find\na reconfiguration plan for a manufacturing line with 51 operations and 40\navailable agents across 8 agent types.", "published": "2025-06-09 00:16:52", "link": "http://arxiv.org/abs/2506.07332v1", "categories": ["cs.MA", "93A16"], "primary_category": "cs.MA"}
{"title": "FractionalDiffEq.jl: High Performance Fractional Differential Equation Solver in Julia", "abstract": "We present FractionalDiffEq.jl, a comprehensive solver suite for solving\nfractional differential equations, featuring high-performance numerical\nalgorithms in the Julia programming language. FractionalDiffEq.jl is designed\nto be user-friendly and scalable, tackling different types of fractional\ndifferential equations, encompassing powerful numerical algorithms including\npredictor-corrector methods, product-integral methods, and linear multistep\nmethods, etc, and providing a unifying API to accommodate diverse solver\nfeatures. This paper illustrates the convenient usage of FractionalDiffEq.jl in\nmodeling various scientific problems, accompanied by detailed examples and\napplications. FractionalDiffEq.jl leverages best practices in Julia to ensure\nthe high performance of numerical solvers. To validate the efficiency of\nFractionalDiffEq.jl , we conducted extensive benchmarks that prove the\nsuperiority of FractionalDiffEq.jl against other implementations on both stiff\nand non-stiff problems. We further demonstrate its capability on several\nchallenging real-life scenarios including parameter estimation in\nfractional-order tequila fermentation processes, and harmonic oscillator\nproblems, etc, emphasizing the robustness and flexibility of\nFractionalDiffEq.jl.", "published": "2025-06-09 16:40:58", "link": "http://arxiv.org/abs/2506.07926v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Lengthscale-informed sparse grids for kernel methods in high dimensions", "abstract": "Kernel interpolation, especially in the context of Gaussian process\nemulation, is a widely used technique in surrogate modelling, where the goal is\nto cheaply approximate an input-output map using a limited number of function\nevaluations. However, in high-dimensional settings, such methods typically\nsuffer from the curse of dimensionality; the number of required evaluations to\nachieve a fixed approximation error grows exponentially with the input\ndimension. To overcome this, a common technique used in high-dimensional\napproximation methods, such as quasi-Monte Carlo and sparse grids, is to\nexploit functional anisotropy: the idea that some input dimensions are more\n'sensitive' than others. In doing so, such methods can significantly reduce the\ndimension dependence in the error. In this work, we propose a generalisation of\nsparse grid methods that incorporates a form of anisotropy encoded by the\nlengthscale parameter in Mat\\'ern kernels. We derive error bounds and perform\nnumerical experiments that show that our approach enables effective emulation\nover arbitrarily high dimensions for functions exhibiting sufficient\nanisotropy.", "published": "2025-06-09 14:24:57", "link": "http://arxiv.org/abs/2506.07797v1", "categories": ["math.NA", "cs.NA", "41A25, 41A63, 62G08, 65B99, 65C20, 65D12, 65D15, 65D32, 65D40"], "primary_category": "math.NA"}
{"title": "Quantum-Enhanced Spectral Solution of the Poisson Equation", "abstract": "We present a hybrid numerical-quantum method for solving the Poisson equation\nunder homogeneous Dirichlet boundary conditions, leveraging the Quantum Fourier\nTransform (QFT) to enhance computational efficiency and reduce time and space\ncomplexity. This approach bypasses the integration-heavy calculations of\nclassical methods, which have to deal with high computational costs for large\nnumber of points. The proposed method estimates the coefficients of the series\nexpansion of the solution directly within the quantum framework. Numerical\nexperiments validate its effectiveness and reveal significant improvements in\nterms of time and space complexity and solution accuracy, demonstrating the\ncapability of quantum-assisted techniques to contribute in solving partial\ndifferential equations (PDEs). Despite the inherent challenges of quantum\nimplementation, the present work serves as a starting point for future\nresearches aimed at refining and expanding quantum numerical methods.", "published": "2025-06-09 13:25:52", "link": "http://arxiv.org/abs/2506.07743v1", "categories": ["math.NA", "cs.ET", "cs.NA"], "primary_category": "math.NA"}
{"title": "Minimal Subsampled Rank-1 Lattices for Multivariate Approximation with Optimal Convergence Rate", "abstract": "In this paper we show error bounds for randomly subsampled rank-1 lattices.\nWe pay particular attention to the ratio of the size of the subset to the size\nof the initial lattice, which is decisive for the computational complexity. In\nthe special case of Korobov spaces, we achieve the optimal polynomial sampling\ncomplexity whilst having the smallest initial lattice possible. We further\ncharacterize the frequency index set for which a given lattice is\nreconstructing by using the reciprocal of the worst-case error achieved using\nthe lattice in question. This connects existing approaches used in proving\nerror bounds for lattices. We make detailed comments on the implementation and\ntest different algorithms using the subsampled lattice in numerical\nexperiments.", "published": "2025-06-09 13:12:04", "link": "http://arxiv.org/abs/2506.07729v1", "categories": ["math.NA", "cs.NA", "41A25, 94A20"], "primary_category": "math.NA"}
{"title": "Data-Informed Mathematical Characterization of Absorption Properties in Artificial and Natural Porous Materials", "abstract": "In this work, we characterize the water absorption properties of selected\nporous materials through a combined approach that integrates laboratory\nexperiments and mathematical modeling. Specifically, experimental data from\nimbibition tests on marble, travertine, wackestone and mortar mock-ups are used\nto inform and validate the mathematical and simulation frameworks. First, a\nmonotonicity-preserving fitting procedure is developed to preprocess the\nmeasurements, aiming to reduce noise and mitigate instrumental errors. The\nimbibition process is then simulated through a partial differential equation\nmodel, with parameters calibrated against rough and smoothed data. The proposed\nprocedure appears particularly effective to characterize absorption properties\nof different materials and it represents a reliable tool for the study and\npreservation of cultural heritage.", "published": "2025-06-09 11:23:29", "link": "http://arxiv.org/abs/2506.07656v1", "categories": ["math.NA", "cs.NA", "math.OC", "65M32, 65K10, 76S05, 86-10, 76-11"], "primary_category": "math.NA"}
{"title": "IDENT Review: Recent Advances in Identification of Differential Equations from Noisy Data", "abstract": "Differential equations and numerical methods are extensively used to model\nvarious real-world phenomena in science and engineering. With modern\ndevelopments, we aim to find the underlying differential equation from a single\nobservation of time-dependent data. If we assume that the differential equation\nis a linear combination of various linear and nonlinear differential terms,\nthen the identification problem can be formulated as solving a linear system.\nThe goal then reduces to finding the optimal coefficient vector that best\nrepresents the time derivative of the given data. We review some recent works\non the identification of differential equations. We find some common themes for\nthe improved accuracy: (i) The formulation of linear system with proper\ndenoising is important, (ii) how to utilize sparsity and model selection to\nfind the correct coefficient support needs careful attention, and (iii) there\nare ways to improve the coefficient recovery. We present an overview and\nanalysis of these approaches about some recent developments on the topic.", "published": "2025-06-09 10:05:21", "link": "http://arxiv.org/abs/2506.07604v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "The pollution effect for the Ginzburg-Landau equation", "abstract": "In this paper, we investigate the approximation properties of solutions to\nthe Ginzburg-Landau equation (GLE) in finite element spaces. Special attention\nis given to how the errors are influenced by coupling the mesh size $h$ and the\npolynomial degree $p$ of the finite element space to the size of the so-called\nGinzburg-Landau material parameter $\\kappa$. As observed in previous works, the\nfinite element approximations to the GLE are suffering from a numerical\npollution effect, that is, the best-approximation error in the finite element\nspace converges under mild coupling conditions between $h$ and $\\kappa$,\nwhereas the actual finite element solutions possess poor accuracy in a large\npre-asymptotic regime which depends on $\\kappa$. In this paper, we provide a\nnew error analysis that allows us to quantify the pre-asymptotic regime and the\ncorresponding pollution effect in terms of explicit resolution conditions. In\nparticular, we are able to prove that higher polynomial degrees reduce the\npollution effect, i.e., the accuracy of the best-approximation is achieved\nunder relaxed conditions for the mesh size. We provide both error estimates in\nthe $H^1$- and the $L^2$-norm and we illustrate our findings with numerical\nexamples.", "published": "2025-06-09 05:17:59", "link": "http://arxiv.org/abs/2506.07433v1", "categories": ["math.NA", "cs.NA", "65N12, 65N15, 65N30, 35Q56"], "primary_category": "math.NA"}
{"title": "Multiscale model reduction and two-level Schwarz preconditioner for H(curl) elliptic problems", "abstract": "This paper addresses the efficient solution of linear systems arising from\ncurl-conforming finite element discretizations of $H(\\mathrm{curl})$ elliptic\nproblems with heterogeneous coefficients. We first employ the discrete form of\na multiscale spectral generalized finite element method (MS-GFEM) for model\nreduction and prove that the method exhibits exponential convergence with\nrespect to the number of local degrees of freedom. The proposed method and its\nconvergence analysis are applicable in broad settings, including general\nheterogeneous ($L^{\\infty}$) coefficients, domains and subdomains with\nnontrivial topology, irregular subdomain geometries, and high-order finite\nelement discretizations. Furthermore, we formulate the method as an iterative\nsolver, yielding a two-level restricted additive Schwarz type preconditioner\nbased on the MS-GFEM coarse space. The GMRES algorithm, applied to the\npreconditioned system, is shown to converge at a rate of at least $\\Lambda$,\nwhere $\\Lambda$ denotes the error bound of the discrete MS-GFEM approximation.\nNumerical experiments in both two and three dimensions demonstrate the superior\nperformance of the proposed methods in terms of dimensionality reduction.", "published": "2025-06-09 03:02:30", "link": "http://arxiv.org/abs/2506.07381v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Numerical Approximation and Analysis of the Inverse Robin Problem Using the Kohn-Vogelius Method", "abstract": "In this work, we numerically investigate the inverse Robin problem of\nrecovering a piecewise constant Robin coefficient in an elliptic or parabolic\nproblem from the Cauchy data on a part of the boundary, a problem that commonly\narises in applications such as non-destructive corrosion detection. We employ a\nKohn-Vogelius type variational functional for the regularized reconstruction,\nand discretize the resulting optimization problem using the Galerkin finite\nelement method on a graded mesh. We establish rigorous error estimates on the\nrecovered Robin coefficient in terms of the mesh size, temporal step size and\nnoise level. This is achieved by combining the approximation error of the\ndirect problem, a priori estimates on the functional, and suitable conditional\nstability estimates of the continuous inverse problem. We present several\nnumerical experiments to illustrate the approach and to complement the\ntheoretical findings.", "published": "2025-06-09 02:40:34", "link": "http://arxiv.org/abs/2506.07370v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "2N-storage Runge-Kutta methods: Order conditions, general properties and some analytic solutions", "abstract": "Low-storage Runge-Kutta schemes of Williamson's type, so-called 2N-storage\nschemes, are examined. Explicit 2N-storage constraints are derived for the\nfirst time and used to establish new relations between the entries of the\nButcher tableau. An error in the Williamson's formula for converting\ncoefficients between the standard and 2N-storage formats in the special case is\npointed out and corrected. The new relations are used to derive a closed-form\nsolution for four- and five-stage 2N-storage methods with the third order of\nglobal accuracy. Several new four- and five-stage schemes with rational\ncoefficients are presented and numerically examined for illustration.", "published": "2025-06-09 02:13:57", "link": "http://arxiv.org/abs/2506.07359v1", "categories": ["math.NA", "cs.NA", "hep-lat", "physics.comp-ph"], "primary_category": "math.NA"}
{"title": "Stable Computation of Laplacian Eigenfunctions Corresponding to Clustered Eigenvalues", "abstract": "The accurate computation of eigenfunctions corresponding to tightly clustered\nLaplacian eigenvalues remains an extremely difficult problem. In this paper,\nusing the shape difference quotient of eigenvalues, we propose a stable\ncomputation method for the eigenfunctions of clustered eigenvalues caused by\ndomain perturbation.", "published": "2025-06-09 01:03:12", "link": "http://arxiv.org/abs/2506.07340v1", "categories": ["math.SP", "cs.NA", "math.NA", "65N25, 65N30"], "primary_category": "math.SP"}
{"title": "Stochastic portfolio theory with price impact", "abstract": "We develop a framework for stochastic portfolio theory (SPT), which\nincorporates modern nonlinear price impact and impact decay models. Our main\nresult derives the celebrated master formula for (additive) functional\ngeneration of trading strategies in a general high-dimensional market model\nwith price impact. We also develop formulas for an investor's relative wealth\nwith respect to the market portfolio, conditions that guarantee positive\nobserved market prices and derive a stochastic differential equation governing\nthe dynamics of the observed price, investor's holdings and price impact\nprocesses. As an application of these results, we develop conditions for\nrelative arbitrage in the price impact setting analogous to previously obtained\nresults for the frictionless setting. Numerical experiments are presented to\ncomplement the theoretical results.", "published": "2025-06-09 17:57:46", "link": "http://arxiv.org/abs/2506.07993v1", "categories": ["q-fin.MF", "math.PR", "91G10, 60H30"], "primary_category": "q-fin.MF"}
{"title": "Predicting Realized Variance Out of Sample: Can Anything Beat The Benchmark?", "abstract": "The discrepancy between realized volatility and the market's view of\nvolatility has been known to predict individual equity options at the monthly\nhorizon. It is not clear how this predictability depends on a forecast's\nability to predict firm-level volatility. We consider this phenomenon at the\ndaily frequency using high-dimensional machine learning models, as well as\nlow-dimensional factor models. We find that marginal improvements to standard\nforecast error measurements can lead to economically significant gains in\nportfolio performance. This makes a case for re-imagining the way we train\nmodels that are used to construct portfolios.", "published": "2025-06-09 16:44:03", "link": "http://arxiv.org/abs/2506.07928v1", "categories": ["q-fin.ST"], "primary_category": "q-fin.ST"}
{"title": "The Subtle Interplay between Square-root Impact, Order Imbalance \\& Volatility: A Unifying Framework", "abstract": "In this work, we aim to reconcile several apparently contradictory\nobservations in market microstructure: is the famous ''square-root law'' of\nmetaorder impact that decays with time compatible with the random-walk nature\nof prices and the linear impact of order imbalances? Can one entirely explain\nthe volatility of prices as resulting from the flow of uninformed metaorders\nthat mechanically impact prices? We introduce a new theoretical framework to\ndescribe metaorders with different signs, sizes and durations, which all impact\nprices as a square-root of volume but with a subsequent time decay. We show\nthat, as in the original propagator model, price diffusion is ensured by the\nlong memory of cross-correlations between metaorders. In order to account for\nthe effect of strongly fluctuating volumes $q$ of individual trades, we further\nintroduce two $q$-dependent exponents, which allows us to account for the way\nthe moments of generalized volume imbalance and the correlation between price\nchanges and generalized order flow imbalance scales with $T$. We predict in\nparticular that the corresponding power-laws depend in a non-monotonic fashion\non a parameter $a$ that allows one to put the same weight on all child orders\nor overweight large orders, a behaviour clearly borne out by empirical data. We\nalso predict that the correlation between price changes and volume imbalances\nshould display a maximum as a function of $a$, which again matches\nobservations. Such noteworthy agreement between theory and data suggests that\nour framework correctly captures the basic mechanism at the heart of price\nformation, namely the average impact of metaorders. We argue that our results\nsupport the ''Order-Driven'' theory of excess volatility, and are at odds with\nthe idea that a ''Fundamental'' component accounts for a large share of the\nvolatility of financial markets.", "published": "2025-06-09 12:53:25", "link": "http://arxiv.org/abs/2506.07711v1", "categories": ["q-fin.TR", "q-fin.ST"], "primary_category": "q-fin.TR"}
{"title": "Stability of Mean-Field Variational Inference", "abstract": "Mean-field variational inference (MFVI) is a widely used method for\napproximating high-dimensional probability distributions by product measures.\nThis paper studies the stability properties of the mean-field approximation\nwhen the target distribution varies within the class of strongly log-concave\nmeasures. We establish dimension-free Lipschitz continuity of the MFVI\noptimizer with respect to the target distribution, measured in the\n2-Wasserstein distance, with Lipschitz constant inversely proportional to the\nlog-concavity parameter. Under additional regularity conditions, we further\nshow that the MFVI optimizer depends differentiably on the target potential and\ncharacterize the derivative by a partial differential equation.\nMethodologically, we follow a novel approach to MFVI via linearized optimal\ntransport: the non-convex MFVI problem is lifted to a convex optimization over\ntransport maps with a fixed base measure, enabling the use of calculus of\nvariations and functional analysis. We discuss several applications of our\nresults to robust Bayesian inference and empirical Bayes, including a\nquantitative Bernstein--von Mises theorem for MFVI, as well as to distributed\nstochastic control.", "published": "2025-06-09 15:21:37", "link": "http://arxiv.org/abs/2506.07856v1", "categories": ["math.PR", "math.FA", "math.ST", "stat.ML", "stat.TH", "90C25, 49Q22, 62F15, 49N80"], "primary_category": "math.PR"}
{"title": "Heavy Lasso: sparse penalized regression under heavy-tailed noise via data-augmented soft-thresholding", "abstract": "High-dimensional linear regression is a fundamental tool in modern\nstatistics, particularly when the number of predictors exceeds the sample size.\nThe classical Lasso, which relies on the squared loss, performs well under\nGaussian noise assumptions but often deteriorates in the presence of\nheavy-tailed errors or outliers commonly encountered in real data applications\nsuch as genomics, finance, and signal processing. To address these challenges,\nwe propose a novel robust regression method, termed Heavy Lasso, which\nincorporates a loss function inspired by the Student's t-distribution within a\nLasso penalization framework. This loss retains the desirable quadratic\nbehavior for small residuals while adaptively downweighting large deviations,\nthus enhancing robustness to heavy-tailed noise and outliers. Heavy Lasso\nenjoys computationally efficient by leveraging a data augmentation scheme and a\nsoft-thresholding algorithm, which integrate seamlessly with classical Lasso\nsolvers. Theoretically, we establish non-asymptotic bounds under both $\\ell_1$\nand $\\ell_2 $ norms, by employing the framework of localized convexity, showing\nthat the Heavy Lasso estimator achieves rates comparable to those of the Huber\nloss. Extensive numerical studies demonstrate Heavy Lasso's superior\nperformance over classical Lasso and other robust variants, highlighting its\neffectiveness in challenging noisy settings. Our method is implemented in the R\npackage heavylasso available on Github.", "published": "2025-06-09 14:13:02", "link": "http://arxiv.org/abs/2506.07790v1", "categories": ["stat.ME", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Moment Alignment: Unifying Gradient and Hessian Matching for Domain Generalization", "abstract": "Domain generalization (DG) seeks to develop models that generalize well to\nunseen target domains, addressing the prevalent issue of distribution shifts in\nreal-world applications. One line of research in DG focuses on aligning\ndomain-level gradients and Hessians to enhance generalization. However,\nexisting methods are computationally inefficient and the underlying principles\nof these approaches are not well understood. In this paper, we develop the\ntheory of moment alignment for DG. Grounded in \\textit{transfer measure}, a\nprincipled framework for quantifying generalizability between two domains, we\nfirst extend the definition of transfer measure to domain generalization that\nincludes multiple source domains and establish a target error bound. Then, we\nprove that aligning derivatives across domains improves transfer measure both\nwhen the feature extractor induces an invariant optimal predictor across\ndomains and when it does not. Notably, moment alignment provides a unifying\nunderstanding of Invariant Risk Minimization, gradient matching, and Hessian\nmatching, three previously disconnected approaches to DG. We further connect\nfeature moments and derivatives of the classifier head, and establish the\nduality between feature learning and classifier fitting. Building upon our\ntheory, we introduce \\textbf{C}losed-Form \\textbf{M}oment \\textbf{A}lignment\n(CMA), a novel DG algorithm that aligns domain-level gradients and Hessians in\nclosed-form. Our method overcomes the computational inefficiencies of existing\ngradient and Hessian-based techniques by eliminating the need for repeated\nbackpropagation or sampling-based Hessian estimation. We validate the efficacy\nof our approach through two sets of experiments: linear probing and full\nfine-tuning. CMA demonstrates superior performance in both settings compared to\nEmpirical Risk Minimization and state-of-the-art algorithms.", "published": "2025-06-09 02:51:36", "link": "http://arxiv.org/abs/2506.07378v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Towards a Unified Benchmark for Arabic Pronunciation Assessment: Quranic Recitation as Case Study", "abstract": "We present a unified benchmark for mispronunciation detection in Modern\nStandard Arabic (MSA) using Qur'anic recitation as a case study. Our approach\nlays the groundwork for advancing Arabic pronunciation assessment by providing\na comprehensive pipeline that spans data processing, the development of a\nspecialized phoneme set tailored to the nuances of MSA pronunciation, and the\ncreation of the first publicly available test set for this task, which we term\nas the Qur'anic Mispronunciation Benchmark (QuranMB.v1). Furthermore, we\nevaluate several baseline models to provide initial performance insights,\nthereby highlighting both the promise and the challenges inherent in assessing\nMSA pronunciation. By establishing this standardized framework, we aim to\nfoster further research and development in pronunciation assessment in Arabic\nlanguage technology and related applications.", "published": "2025-06-09 13:05:03", "link": "http://arxiv.org/abs/2506.07722v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Unified Semi-Supervised Pipeline for Automatic Speech Recognition", "abstract": "Automatic Speech Recognition has been a longstanding research area, with\nsubstantial efforts dedicated to integrating semi-supervised learning due to\nthe scarcity of labeled datasets. However, most prior work has focused on\nimproving learning algorithms using existing datasets, without providing a\ncomplete public framework for large-scale semi-supervised training across new\ndatasets or languages. In this work, we introduce a fully open-source\nsemi-supervised training framework encompassing the entire pipeline: from\nunlabeled data collection to pseudo-labeling and model training. Our approach\nenables scalable dataset creation for any language using publicly available\nspeech data under Creative Commons licenses. We also propose a novel\npseudo-labeling algorithm, TopIPL, and evaluate it in both low-resource\n(Portuguese, Armenian) and high-resource (Spanish) settings. Notably, TopIPL\nachieves relative WER improvements of 18-40% for Portuguese, 5-16% for\nArmenian, and 2-8% for Spanish.", "published": "2025-06-09 11:31:24", "link": "http://arxiv.org/abs/2506.07659v1", "categories": ["eess.AS", "I.5.1"], "primary_category": "eess.AS"}
{"title": "SongBloom: Coherent Song Generation via Interleaved Autoregressive Sketching and Diffusion Refinement", "abstract": "Generating music with coherent structure, harmonious instrumental and vocal\nelements remains a significant challenge in song generation. Existing language\nmodels and diffusion-based methods often struggle to balance global coherence\nwith local fidelity, resulting in outputs that lack musicality or suffer from\nincoherent progression and mismatched lyrics. This paper introduces\n$\\textbf{SongBloom}$, a novel framework for full-length song generation that\nleverages an interleaved paradigm of autoregressive sketching and\ndiffusion-based refinement. SongBloom employs an autoregressive diffusion model\nthat combines the high fidelity of diffusion models with the scalability of\nlanguage models. Specifically, it gradually extends a musical sketch from short\nto long and refines the details from coarse to fine-grained. The interleaved\ngeneration paradigm effectively integrates prior semantic and acoustic context\nto guide the generation process. Experimental results demonstrate that\nSongBloom outperforms existing methods across both subjective and objective\nmetrics and achieves performance comparable to the state-of-the-art commercial\nmusic generation platforms. Audio samples are available on our demo page:\nhttps://cypress-yang.github.io/SongBloom\\_demo.", "published": "2025-06-09 11:01:01", "link": "http://arxiv.org/abs/2506.07634v1", "categories": ["eess.AS", "cs.MM"], "primary_category": "eess.AS"}
{"title": "Bayesian Learning for Domain-Invariant Speaker Verification and Anti-Spoofing", "abstract": "The performance of automatic speaker verification (ASV) and anti-spoofing\ndrops seriously under real-world domain mismatch conditions. The relaxed\ninstance frequency-wise normalization (RFN), which normalizes the frequency\ncomponents based on the feature statistics along the time and channel axes, is\na promising approach to reducing the domain dependence in the feature maps of a\nspeaker embedding network. We advocate that the different frequencies should\nreceive different weights and that the weights' uncertainty due to domain shift\nshould be accounted for. To these ends, we propose leveraging variational\ninference to model the posterior distribution of the weights, which results in\nBayesian weighted RFN (BWRFN). This approach overcomes the limitations of\nfixed-weight RFN, making it more effective under domain mismatch conditions.\nExtensive experiments on cross-dataset ASV, cross-TTS anti-spoofing, and\nspoofing-robust ASV show that BWRFN is significantly better than WRFN and RFN.", "published": "2025-06-09 08:18:12", "link": "http://arxiv.org/abs/2506.07536v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Generative Voice Bursts during Phone Call", "abstract": "In critical situations, conventional mobile telephony fails to convey\nemergency voice messages to a callee already engaged in another call. The\nstandard call waiting alert does not provide the urgency or content of the\nwaiting call. This paper proposes a novel method for transmitting Generative\nVoice Bursts short, context aware audio messages during ongoing calls, from\neither preauthorized or dynamically prioritized callers. By leveraging\ngenerative AI techniques, the system automatically generates spoken messages\nfrom contextual inputs example like location, health data, images, background\nnoise when the caller is unable to speak due to incapacitation or environmental\nconstraints. The solution incorporates voice, text, and priority inference\nmechanisms, allowing high priority emergency messages to bypass conventional\ncall waiting barriers. The approach employs models such as GPT Neo for\ngenerative text, which is synthesized into audio and delivered in configurable\nintervals G seconds and counts N times, ensuring minimal disruption while\npreserving urgency. This method holds potential for significant impact across\ntelecom, mobile device manufacturing, and emergency communication platforms.", "published": "2025-06-09 08:10:43", "link": "http://arxiv.org/abs/2506.07526v1", "categories": ["cs.SD", "cs.NE", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Towards Energy-Efficient and Low-Latency Voice-Controlled Smart Homes: A Proposal for Offline Speech Recognition and IoT Integration", "abstract": "The smart home systems, based on AI speech recognition and IoT technology,\nenable people to control devices through verbal commands and make people's\nlives more efficient. However, existing AI speech recognition services are\nprimarily deployed on cloud platforms on the Internet. When users issue a\ncommand, speech recognition devices like ``Amazon Echo'' will post a recording\nthrough numerous network nodes, reach multiple servers, and then receive\nresponses through the Internet. This mechanism presents several issues,\nincluding unnecessary energy consumption, communication latency, and the risk\nof a single-point failure. In this position paper, we propose a smart home\nconcept based on offline speech recognition and IoT technology: 1) integrating\noffline keyword spotting (KWS) technologies into household appliances with\nlimited resource hardware to enable them to understand user voice commands; 2)\ndesigning a local IoT network with decentralized architecture to manage and\nconnect various devices, enhancing the robustness and scalability of the\nsystem. This proposal of a smart home based on offline speech recognition and\nIoT technology will allow users to use low-latency voice control anywhere in\nthe home without depending on the Internet and provide better scalability and\nenergy sustainability.", "published": "2025-06-09 07:15:48", "link": "http://arxiv.org/abs/2506.07494v1", "categories": ["cs.SD", "cs.CY", "eess.AS"], "primary_category": "cs.SD"}
{"title": "An introduction to pitch strength in contemporary popular music analysis and production", "abstract": "Music information retrieval distinguishes between low- and high-level\ndescriptions of music. Current generative AI models rely on text descriptions\nthat are higher level than the controls familiar to studio musicians. Pitch\nstrength, a low-level perceptual parameter of contemporary popular music, may\nbe one feature that could make such AI models more suited to music production.\nSignal and perceptual analyses suggest that pitch strength (1) varies\nsignificantly across and inside songs; (2) contributes to both small- and\nlarge-scale structure; (3) contributes to the handling of polyphonic\ndissonance; and (4) may be a feature of upper harmonics made audible in a\nperspective of perceptual richness.", "published": "2025-06-09 06:47:26", "link": "http://arxiv.org/abs/2506.07473v1", "categories": ["cs.SD", "eess.AS", "00A65", "J.5"], "primary_category": "cs.SD"}
{"title": "Lightweight Joint Audio-Visual Deepfake Detection via Single-Stream Multi-Modal Learning Framework", "abstract": "Deepfakes are AI-synthesized multimedia data that may be abused for spreading\nmisinformation. Deepfake generation involves both visual and audio\nmanipulation. To detect audio-visual deepfakes, previous studies commonly\nemploy two relatively independent sub-models to learn audio and visual\nfeatures, respectively, and fuse them subsequently for deepfake detection.\nHowever, this may underutilize the inherent correlations between audio and\nvisual features. Moreover, utilizing two isolated feature learning sub-models\ncan result in redundant neural layers, making the overall model inefficient and\nimpractical for resource-constrained environments.\n  In this work, we design a lightweight network for audio-visual deepfake\ndetection via a single-stream multi-modal learning framework. Specifically, we\nintroduce a collaborative audio-visual learning block to efficiently integrate\nmulti-modal information while learning the visual and audio features. By\niteratively employing this block, our single-stream network achieves a\ncontinuous fusion of multi-modal features across its layers. Thus, our network\nefficiently captures visual and audio features without the need for excessive\nblock stacking, resulting in a lightweight network design. Furthermore, we\npropose a multi-modal classification module that can boost the dependence of\nthe visual and audio classifiers on modality content. It also enhances the\nwhole resistance of the video classifier against the mismatches between audio\nand visual modalities. We conduct experiments on the DF-TIMIT, FakeAVCeleb, and\nDFDC benchmark datasets. Compared to state-of-the-art audio-visual joint\ndetection methods, our method is significantly lightweight with only 0.48M\nparameters, yet it achieves superiority in both uni-modal and multi-modal\ndeepfakes, as well as in unseen types of deepfakes.", "published": "2025-06-09 02:13:04", "link": "http://arxiv.org/abs/2506.07358v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Low-Complexity Super-Resolution Signature Estimation of XL-MIMO FMCW Radar", "abstract": "Extremely Large-Scale (XL) multiple input multiple output (MIMO) antenna\nsystems combined with ultra-wide signal bandwidth (BW) offer the potential for\nultra-high-resolution sensing in frequency modulated continuous wave (FMCW)\nradars. However, the use of ultra-wide BW results in significant spatial delays\nacross the array aperture, comparable to the range resolution, leading to the\nspatial wideband effect (SWE). SWE introduces coupling between the range and\nangle domains, rendering conventional narrowband signal processing techniques\nineffective for target signature estimation. In this paper, we propose an\nefficient super-resolution signature estimation technique for XL-MIMO FMCW\nradars operating under SWE, leveraging compressive sensing (CS) methods. The\nproposed 2D CS-based approach offers low computational complexity, making it\nhighly suitable for real-time applications in large-scale radar systems.\nNumerical simulation results validate the superior performance of the proposed\nmethod compared to existing wideband and narrowband estimation techniques.", "published": "2025-06-09 17:51:08", "link": "http://arxiv.org/abs/2506.07979v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Double Low-Rank 4D Tensor Decomposition for Circular RIS-Aided mmWave MIMO-NOMA System Channel Estimation in Mobility Scenarios", "abstract": "Channel estimation is not only essential to highly reliable data transmission\nand massive device access but also an important component of the integrated\nsensing and communication (ISAC) in the sixth-generation (6G) mobile\ncommunication systems. In this paper, we consider a downlink channel estimation\nproblem for circular reconfigurable intelligent surface (RIS)-aided\nmillimeter-wave (mmWave) multiple-input multiple-output non-orthogonal multiple\naccess (MIMO-NOMA) system in mobility scenarios. First, we propose a subframe\npartitioning scheme to facilitate the modeling of the received signal as a\nfourth-order tensor satisfying a canonical polyadic decomposition (CPD) form,\nthereby formulating the channel estimation problem as tensor decomposition and\nparameter extraction problems. Then, by exploiting both the global and local\nlow-rank properties of the received signal, we propose a double low-rank 4D\ntensor decomposition model to decompose the received signal into four factor\nmatrices, which is efficiently solved via alternating direction method of\nmultipliers (ADMM). Subsequently, we propose a two-stage parameter estimation\nmethod based on the Jacobi-Anger expansion and the special structure of\ncircular RIS to uniquely decouple the angle parameters. Furthermore, the time\ndelay, Doppler shift, and channel gain parameters can also be estimated without\nambiguities, and their estimation accuracy can be efficiently improved,\nespecially at low signal-to-noise ratio (SNR). Finally, a concise closed-form\nexpression for the Cram\\'er-Rao bound (CRB) is derived as a performance\nbenchmark. Numerical experiments are conducted to demonstrate the effectiveness\nof the proposed method compared with the other discussed methods.", "published": "2025-06-09 16:25:26", "link": "http://arxiv.org/abs/2506.07909v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Phase-Only Positioning: Overcoming Integer Ambiguity Challenge through Deep Learning", "abstract": "This paper investigates uplink carrier phase positioning (CPP) in cell-free\n(CF) or distributed antenna system context, assuming a challenging case where\nonly phase measurements are utilized as observations. In general, CPP can\nachieve sub-meter to centimeter-level accuracy but is challenged by the integer\nambiguity problem. In this work, we propose two deep learning approaches for\nphase-only positioning, overcoming the integer ambiguity challenge. The first\none directly uses phase measurements, while the second one first estimates\ninteger ambiguities and then integrates them with phase measurements for\nimproved accuracy. Our numerical results demonstrate that an inference\ncomplexity reduction of two to three orders of magnitude is achieved, compared\nto maximum likelihood baseline solution, depending on the approach and\nparameter configuration. This emphasizes the potential of the developed deep\nlearning solutions for efficient and precise positioning in future CF 6G\nsystems.", "published": "2025-06-09 16:05:47", "link": "http://arxiv.org/abs/2506.07890v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Stone Soup: ADS-B-based Multi-Target Tracking with Stochastic Integration Filter", "abstract": "This paper focuses on the multi-target tracking using the Stone Soup\nframework. In particular, we aim at evaluation of two multi-target tracking\nscenarios based on the simulated class-B dataset and ADS-B class-A dataset\nprovided by OpenSky Network. The scenarios are evaluated w.r.t. selection of a\nlocal state estimator using a range of the Stone Soup metrics. Source code with\nscenario definitions and Stone Soup set-up are provided along with the paper.", "published": "2025-06-09 16:01:47", "link": "http://arxiv.org/abs/2506.07889v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Diffusion-RL for Scalable Resource Allocation for 6G Networks", "abstract": "This paper presents a novel approach to resource allocation in Open Radio\nAccess Networks (O-RAN), leveraging a Generative AI technique with network\nslicing to address the diverse demands of 5G and 6G service types such as\nEnhanced Mobile Broadband (eMBB), Ultra-Reliable Low-Latency Communications\n(URLLC), and Massive Machine-Type Communications (mMTC). Additionally, we\nprovide a comprehensive analysis and comparison of machine learning (ML)\ntechniques for resource allocation within O-RAN, evaluating their effectiveness\nin optimizing network performance. We introduce a diffusion-based reinforcement\nlearning (Diffusion-RL) algorithm designed to optimize the allocation of\nphysical resource blocks (PRBs) and power consumption, thereby maximizing\nweighted throughput and minimizing the delay for user equipment (UE). The\nDiffusion-RL model incorporates controlled noise and perturbations to explore\noptimal resource distribution while meeting each service type's Quality of\nService (QoS) requirements. We evaluate the performance of our proposed method\nagainst several benchmarks, including an exhaustive search algorithm, deep\nQ-networks (DQN), and the Semi-Supervised Variational Autoencoder (SS-VAE).\nComprehensive metrics, such as throughput and latency, are presented for each\nservice type. Experimental results demonstrate that the Diffusion-based RL\napproach outperforms existing methods in efficiency, scalability, and\nrobustness, offering a promising solution for resource allocation in dynamic\nand heterogeneous O-RAN environments with significant implications for future\n6G networks.", "published": "2025-06-09 15:52:18", "link": "http://arxiv.org/abs/2506.07880v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Towards a Base-Station-on-Chip: RISC-V Hardware Acceleration for wireless communication", "abstract": "The evolution of 5G and the emergence of 6G wireless communication systems\nimpose higher demands for computing capabilities and lower power consumption in\nthe front-end and processing circuitry. Furthermore, the incorporation of\nArtificial Intelligence (AI)/Machine Learning (ML) in the Radio Access Network\n(RAN) introduces heightened computational needs and stringent low-latency\nrequirements for both training and inference. The concept of a Base Station on\nChip (BSoC) addresses those demands by consolidating of the signal processing,\nneural network computations and network management functions into a single\nchip. This new computing platform relies on a sophisticated hardware/software\nco-design to optimize performance, power efficiency, and scalability, enabling\na compact, yet adaptable and intelligent base station solution for\nnext-generation wireless networks. This research investigates the efficient\nimplementation of conventional Channel Estimation (CE), massive Multiple Input\nMultiple Output (mMIMO), and beamforming kernels on a state-of-the-art RISC-V\nvector Digital Signal Processors (DSP) to capitalize on Data Level Parallelism\n(DLP). Moreover, it explores how RISC-V Vector Extensions (RVV) combined with\ncustom instructions can effectively address the throughput and latency demands\nof LOW Physical Layer (PHY) kernels.", "published": "2025-06-09 15:41:24", "link": "http://arxiv.org/abs/2506.07873v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Device-Free Localization with Multiple Antenna Receivers: Simulations and Results", "abstract": "Device-Free Localization (DFL) is a passive radio method able to detect,\nestimate, and localize targets (e.g., human or other obstacles) that do not\nneed to carry any electronic device. According to the Integrated Sensing And\nCommunication (ISAC) paradigm, DFL networks exploit Radio Frequency (RF)\ndevices, used for communication purposes, to evaluate also the excess\nattenuation due to targets moving in the monitored area, to estimate the target\npositions and movements. Several target models have been discussed in the\nliterature to evaluate the target positions by exploiting the RF signals\nreceived by networked devices. Among these models, Electromagnetic (EM) body\nmodels emerged as an interesting research field for excess attenuation\nprediction using commercial RF devices. While these RF devices are usually\nsingle-antenna boards, the availability of low-cost multi-antenna devices e.g.\nthose used in WLAN (Wireless Local Area Network) scenarios, allow us to exploit\narray-based signal processing techniques for DFL applications as well. Using an\narray-capable EM body model, this paper shows how to employ array-based\nprocessing to improve angular detection of targets. Unlike single-antenna\ndevices that can provide only attenuation information, multi-antenna devices\ncan provide both angular and attenuation estimates about the target location.\nTo this end, simulations are presented and preliminary results are discussed.\nThe proposed framework paves the way for a wider use of multi-antenna devices\nbased, for instance, on WiFi6 and WiFi7 standards.", "published": "2025-06-09 14:00:11", "link": "http://arxiv.org/abs/2506.07784v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "An Efficient Method for Evaluating the Feasibility of Spaceborne SAR for Ocean Ship Detection", "abstract": "This letter presents an effective method for assessing the feasibility of\ndetecting ocean ships using spaceborne synthetic aperture radar (SAR). The\ntechnique employs the minimum detectable radar cross-section criterion under\nspecified false alarm and detection probabilities. The benefits of the proposed\nmethod are illustrated by evaluating the feasibility of detecting small ships\nwith SAR from a satellite in very low Earth orbit.", "published": "2025-06-09 12:16:16", "link": "http://arxiv.org/abs/2506.07686v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "CommSense: A Rapid and Accurate ISAC Paradigm", "abstract": "Future 6G networks envisions to blur the line between communication and\nsensing, leveraging ubiquitous OFDM waveforms for both high throughput data and\nenvironmental awareness. In this work, we do a thorough analysis of\nCommunication based Sensing (CommSense) framework that embeds lightweight, PCA\nbased detectors into standard OFDM receivers; enabling real-time, device free\ndetection of passive scatterers (e.g.\\ drones, vehicles etc.) without any extra\ntransmitters. Starting from a realistic three link Rician channel model (direct\nTx\\(\\rightarrow\\)Rx, cascaded Tx\\(\\rightarrow\\)Scatterer and\nScatterer\\(\\rightarrow\\)Rx), we compare four detectors: the full dimensional\nLikelihood Ratio Test (Full LRT), PCA based LRT, PCA+SVM with linear and RBF\nkernels. By projecting \\(N\\)-dimensional CSI onto a \\(P\\ll N\\) principal\ncomponent subspace, inference time gets reduced by an order of magnitude\ncompared to the full LRT, while achieving optimal error rates i.e. empirical\nerrors align tightly with the Bhattacharyya error bound and Area Under ROC\nCurve (AUC)\\(\\approx1\\) for \\(P\\approx10\\). PCA+SVM classifiers further improve\nrobustness in very high dimensions (\\(N=1024\\)), maintaining AUC\\(\\gtrsim0.60\\)\nat \\(-10\\)dB and exceeding 0.90 by 0dB even when full LRT fails due to\nnumerical overflow. From the simulated result we have shown LRT based\ntechniques are susceptible to the parameter estimation error, where as SVM is\nresilient to that. Our results demonstrate that PCA driven detection when\npaired with lightweight SVMs can deliver fast, accurate, and robust scatterer\nsensing, paving the way for integrated sensing and communication (ISAC) in 6G\nand beyond.", "published": "2025-06-09 12:14:44", "link": "http://arxiv.org/abs/2506.07685v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Quasi-Closed-Form Driven Near-Field Flat-Top Beamfocusing with Concentric Circular Vertical Polarized Dipole Array For Large Intelligent Surface Applications", "abstract": "This letter presents a near-field flat-top beam synthesis method based on a\nsemi-closed-form approach. First, the feasibility of achieving a flat-top beam\nin the near field is examined using a closed-form analysis. A circular\nconcentric ring array structure is adopted, and it is observed that circular\nrings with different radii exhibit distinct gain characteristics along the\nfocal region on the z-axis. Specifically, smaller radii lead to a monotonic\nincrease in electric field strength near the focus, whereas larger radii result\nin a monotonic decrease. Based on this behavior, parameters such as the number\nof rings and the initial radius are determined through field superposition.\nSubsequently, an optimization algorithm is employed to fine-tune the excitation\namplitudes of the individual rings in order to suppress sidelobes. The\neffectiveness of the proposed method is validated through full-wave\nelectromagnetic simulations.", "published": "2025-06-09 12:04:50", "link": "http://arxiv.org/abs/2506.07678v1", "categories": ["physics.optics", "eess.SP"], "primary_category": "physics.optics"}
{"title": "Foundation Model Empowered Synesthesia of Machines (SoM): AI-native Intelligent Multi-Modal Sensing-Communication Integration", "abstract": "To support future intelligent multifunctional sixth-generation (6G) wireless\ncommunication networks, Synesthesia of Machines (SoM) is proposed as a novel\nparadigm for artificial intelligence (AI)-native intelligent multi-modal\nsensing-communication integration. However, existing SoM system designs rely on\ntask-specific AI models and face challenges such as scarcity of massive\nhigh-quality datasets, constrained modeling capability, poor generalization,\nand limited universality. Recently, foundation models (FMs) have emerged as a\nnew deep learning paradigm and have been preliminarily applied to SoM-related\ntasks, but a systematic design framework is still lacking. In this paper, we\nfor the first time present a systematic categorization of FMs for SoM system\ndesign, dividing them into general-purpose FMs, specifically large language\nmodels (LLMs), and SoM domain-specific FMs, referred to as wireless foundation\nmodels. Furthermore, we derive key characteristics of FMs in addressing\nexisting challenges in SoM systems and propose two corresponding roadmaps,\ni.e., LLM-based and wireless foundation model-based design. For each roadmap,\nwe provide a framework containing key design steps as a guiding pipeline and\nseveral representative case studies of FM-empowered SoM system design.\nSpecifically, we propose LLM-based path loss generation (LLM4PG) and scatterer\ngeneration (LLM4SG) schemes, and wireless channel foundation model (WiCo) for\nSoM mechanism exploration, LLM-based wireless multi-task SoM transceiver\n(LLM4WM) and wireless foundation model (WiFo) for SoM-enhanced transceiver\ndesign, and wireless cooperative perception foundation model (WiPo) for\nSoM-enhanced cooperative perception, demonstrating the significant superiority\nof FMs over task-specific models. Finally, we summarize and highlight potential\ndirections for future research.", "published": "2025-06-09 11:12:02", "link": "http://arxiv.org/abs/2506.07647v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Robust Transceiver Design for RIS Enhanced Dual-Functional Radar-Communication with Movable Antenna", "abstract": "Movable antennas (MAs) have demonstrated significant potential in enhancing\nthe performance of dual-functional radar-communication (DFRC) systems. In this\npaper, we explore an MA-aided DFRC system that utilizes a reconfigurable\nintelligent surface (RIS) to enhance signal coverage for communications in dead\nzones. To enhance the radar sensing performance in practical DFRC environments,\nwe propose a unified robust transceiver design framework aimed at maximizing\nthe minimum radar signal-to-interference-plus-noise ratio (SINR) in a cluttered\nenvironment. Our approach jointly optimizes transmit beamforming, receive\nfiltering, antenna placement, and RIS reflecting coefficients under imperfect\nchannel state information (CSI) for both sensing and communication channels. To\ndeal with the channel uncertainty-constrained issue, we leverage the convex\nhull method to transform the primal problem into a more tractable form. We then\nintroduce a two-layer block coordinate descent (BCD) algorithm, incorporating\nfractional programming (FP), successive convex approximation (SCA), S-Lemma,\nand penalty techniques to reformulate it into a series of semidefinite program\n(SDP) subproblems that can be efficiently solved. We provide a comprehensive\nanalysis of the convergence and computational complexity for the proposed\ndesign framework. Simulation results demonstrate the robustness of the proposed\nmethod, and show that the MA-based design framework can significantly enhance\nthe radar SINR performance while achieving an effective balance between the\nradar and communication performance.", "published": "2025-06-09 10:23:12", "link": "http://arxiv.org/abs/2506.07610v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Computation Capacity Maximization for Pinching Antennas-Assisted Wireless Powered MEC Systems", "abstract": "In this paper,we investigate a novel wireless powered mobile edge computing\n(MEC) system assisted by pinching antennas (PAs), where devices first harvest\nenergy from a base station and then offload computation-intensive tasks to an\nMEC server. As an emerging technology, PAs utilize long dielectric waveguides\nembedded with multiple localized dielectric particles, which can be spatially\nconfigured through a pinching mechanism to effectively reduce large-scale\npropagation loss. This capability facilitates both efficient downlink energy\ntransfer and uplink task offloading. To fully exploit these advantages, we\nadopt a non-orthogonal multiple access (NOMA) framework and formulate a joint\noptimization problem to maximize the system's computational capacity by jointly\noptimizing device transmit power, time allocation, PA positions in both uplink\nand downlink, and radiation control. To address the resulting non-convexity\ncaused by variable coupling, we develop an alternating optimization algorithm\nthat integrates particle swarm optimization (PSO) with successive convex\napproximation. Simulation results demonstrate that the proposed PA-assisted\ndesign substantially improves both energy harvesting efficiency and\ncomputational performance compared to conventional antenna systems.", "published": "2025-06-09 09:55:07", "link": "http://arxiv.org/abs/2506.07598v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Synesthesia of Machines (SoM)-Aided Online FDD Precoding via Heterogeneous Multi-Modal Sensing: A Vertical Federated Learning Approach", "abstract": "This paper investigates a heterogeneous multi-vehicle, multi-modal sensing\n(H-MVMM) aided online precoding problem. The proposed H-MVMM scheme utilizes a\nvertical federated learning (VFL) framework to minimize pilot sequence length\nand optimize the sum rate. This offers a promising solution for reducing\nlatency in frequency division duplexing systems. To achieve this, three\npreprocessing modules are designed to transform raw sensory data into\ninformative representations relevant to precoding. The approach effectively\naddresses local data heterogeneity arising from diverse on-board sensor\nconfigurations through a well-structured VFL training procedure. Additionally,\na label-free online model updating strategy is introduced, enabling the H-MVMM\nscheme to adapt its weights flexibly. This strategy features a pseudo downlink\nchannel state information label simulator (PCSI-Simulator), which is trained\nusing a semi-supervised learning (SSL) approach alongside an online loss\nfunction. Numerical results show that the proposed method can closely\napproximate the performance of traditional optimization techniques with perfect\nchannel state information, achieving a significant 90.6\\% reduction in pilot\nsequence length.", "published": "2025-06-09 08:17:54", "link": "http://arxiv.org/abs/2506.07535v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Unified Anti-Jamming Design in Complex Environments Based on Cross-Modal Fusion and Intelligent Decision-Making", "abstract": "With the rapid development of radar jamming systems, especially digital radio\nfrequency memory (DRFM), the electromagnetic environment has become\nincreasingly complex. In recent years, most existing studies have focused\nsolely on either jamming recognition or anti-jamming strategy design. In this\npaper, we propose a unified framework that integrates interference recognition\nwith intelligent anti-jamming strategy selection. Specifically, time-frequency\n(TF) features of radar echoes are first extracted using both Short-Time Fourier\nTransform (STFT) and Smoothed Pseudo Wigner-Ville Distribution (SPWVD). A\nfeature fusion method is then designed to effectively combine these two types\nof time-frequency representations. The fused TF features are further combined\nwith time-domain features of the radar echoes through a cross-modal fusion\nmodule based on an attention mechanism. Finally, the recognition results,\ntogether with information obtained from the passive radar, are fed into a Deep\nQ-Network (DQN)-based intelligent anti-jamming strategy network to select\njamming suppression waveforms. The key jamming parameters obtained by the\npassive radar provide essential information for intelligent decision-making,\nenabling the generation of more effective strategies tailored to specific\njamming types. The proposed method demonstrates improvements in both jamming\ntype recognition accuracy and the stability of anti-jamming strategy selection\nunder complex environments. Experimental results show that our method achieves\nsuperior performance compared to Support Vector Machines (SVM), VGG-16, and\n2D-CNN methods, with respective improvements of 1.41%, 2.5%, and 14.51% in\noverall accuracy. Moreover, in comparison with the SARSA algorithm, the\ndesigned algorithm achieves faster reward convergence and more stable strategy\ngeneration.", "published": "2025-06-09 08:15:31", "link": "http://arxiv.org/abs/2506.07532v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Multipath Component-Enhanced Signal Processing for Integrated Sensing and Communication Systems", "abstract": "Integrated sensing and communication (ISAC) has gained traction in academia\nand industry. Recently, multipath components (MPCs), as a type of spatial\nresource, have the potential to improve the sensing performance in ISAC\nsystems, especially in richly scattering environments. In this paper, we\npropose to leverage MPC and Khatri-Rao space-time (KRST) code within a single\nISAC system to realize high-accuracy sensing for multiple dynamic targets and\nmulti-user communication. Specifically, we propose a novel MPC-enhanced sensing\nprocessing scheme with symbol-level fusion, referred to as the \"SL-MPS\" scheme,\nto achieve high-accuracy localization of multiple dynamic targets and empower\nthe single ISAC system with a new capability of absolute velocity estimation\nfor multiple targets with a single sensing attempt. Furthermore, the KRST code\nis applied to flexibly balance communication and sensing performance in richly\nscattering environments. To evaluate the contribution of MPCs, the closed-form\nCram\\'er-Rao lower bounds (CRLBs) of location and absolute velocity estimation\nare derived. Simulation results illustrate that the proposed SL-MPS scheme is\nmore robust and accurate in localization and absolute velocity estimation\ncompared with the existing state-of-the-art schemes.", "published": "2025-06-09 07:18:26", "link": "http://arxiv.org/abs/2506.07495v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Decoding Saccadic Eye Movements from Brain Signals Using an Endovascular Neural Interface", "abstract": "An Oculomotor Brain-Computer Interface (BCI) records neural activity from\nregions of the brain involved in planning eye movements and translates this\nactivity into control commands. While previous successful oculomotor BCI\nstudies primarily relied on invasive microelectrode implants in non-human\nprimates, this study investigates the feasibility of an oculomotor BCI using a\nminimally invasive endovascular Stentrode device implanted near the\nsupplementary motor area in a patient with amyotrophic lateral sclerosis (ALS).\nTo achieve this, self-paced visually-guided and free-viewing saccade tasks were\ndesigned, in which the participant performed saccades in four directions (left,\nright, up, down), with simultaneous recording of endovascular EEG and eye gaze.\nThe visually guided saccades were cued with visual stimuli, whereas the\nfree-viewing saccades were self-directed without explicit cues. The results\nshowed that while the neural responses of visually guided saccades overlapped\nwith the cue-evoked potentials, the free-viewing saccades exhibited distinct\nsaccade-related potentials that began shortly before eye movement, peaked\napproximately 50 ms after saccade onset, and persisted for around 200 ms. In\nthe frequency domain, these responses appeared as a low-frequency\nsynchronisation below 15 Hz. Classification of 'fixation vs. saccade' was\nrobust, achieving mean area under the receiver operating characteristic curve\n(AUC) scores of 0.88 within sessions and 0.86 between sessions. In contrast,\nclassifying saccade direction proved more challenging, yielding within-session\nAUC scores of 0.67 for four-class decoding and up to 0.75 for the\nbest-performing binary comparisons (left vs. up and left vs. down). This\nproof-of-concept study demonstrates the feasibility of an endovascular\noculomotor BCI in an ALS patient, establishing a foundation for future\noculomotor BCI studies in human subjects.", "published": "2025-06-09 06:56:47", "link": "http://arxiv.org/abs/2506.07481v1", "categories": ["eess.SP", "q-bio.NC"], "primary_category": "eess.SP"}
{"title": "Silencing Empowerment, Allowing Bigotry: Auditing the Moderation of Hate Speech on Twitch", "abstract": "To meet the demands of content moderation, online platforms have resorted to\nautomated systems. Newer forms of real-time engagement($\\textit{e.g.}$, users\ncommenting on live streams) on platforms like Twitch exert additional pressures\non the latency expected of such moderation systems. Despite their prevalence,\nrelatively little is known about the effectiveness of these systems. In this\npaper, we conduct an audit of Twitch's automated moderation tool\n($\\texttt{AutoMod}$) to investigate its effectiveness in flagging hateful\ncontent. For our audit, we create streaming accounts to act as siloed test\nbeds, and interface with the live chat using Twitch's APIs to send over\n$107,000$ comments collated from $4$ datasets. We measure $\\texttt{AutoMod}$'s\naccuracy in flagging blatantly hateful content containing misogyny, racism,\nableism and homophobia. Our experiments reveal that a large fraction of hateful\nmessages, up to $94\\%$ on some datasets, $\\textit{bypass moderation}$.\nContextual addition of slurs to these messages results in $100\\%$ removal,\nrevealing $\\texttt{AutoMod}$'s reliance on slurs as a moderation signal. We\nalso find that contrary to Twitch's community guidelines, $\\texttt{AutoMod}$\nblocks up to $89.5\\%$ of benign examples that use sensitive words in\npedagogical or empowering contexts. Overall, our audit points to large gaps in\n$\\texttt{AutoMod}$'s capabilities and underscores the importance for such\nsystems to understand context effectively.", "published": "2025-06-09 11:39:39", "link": "http://arxiv.org/abs/2506.07667v2", "categories": ["cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SAFEFLOW: A Principled Protocol for Trustworthy and Transactional Autonomous Agent Systems", "abstract": "Recent advances in large language models (LLMs) and vision-language models\n(VLMs) have enabled powerful autonomous agents capable of complex reasoning and\nmulti-modal tool use. Despite their growing capabilities, today's agent\nframeworks remain fragile, lacking principled mechanisms for secure information\nflow, reliability, and multi-agent coordination. In this work, we introduce\nSAFEFLOW, a new protocol-level framework for building trustworthy LLM/VLM-based\nagents. SAFEFLOW enforces fine-grained information flow control (IFC),\nprecisely tracking provenance, integrity, and confidentiality of all the data\nexchanged between agents, tools, users, and environments. By constraining LLM\nreasoning to respect these security labels, SAFEFLOW prevents untrusted or\nadversarial inputs from contaminating high-integrity decisions. To ensure\nrobustness in concurrent multi-agent settings, SAFEFLOW introduces\ntransactional execution, conflict resolution, and secure scheduling over shared\nstate, preserving global consistency across agents. We further introduce\nmechanisms, including write-ahead logging, rollback, and secure caches, that\nfurther enhance resilience against runtime errors and policy violations. To\nvalidate the performances, we built SAFEFLOWBENCH, a comprehensive benchmark\nsuite designed to evaluate agent reliability under adversarial, noisy, and\nconcurrent operational conditions. Extensive experiments demonstrate that\nagents built with SAFEFLOW maintain impressive task performance and security\nguarantees even in hostile environments, substantially outperforming\nstate-of-the-art. Together, SAFEFLOW and SAFEFLOWBENCH lay the groundwork for\nprincipled, robust, and secure agent ecosystems, advancing the frontier of\nreliable autonomy.", "published": "2025-06-09 09:04:37", "link": "http://arxiv.org/abs/2506.07564v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Thinking vs. Doing: Agents that Reason by Scaling Test-Time Interaction", "abstract": "The current paradigm of test-time scaling relies on generating long reasoning\ntraces (\"thinking\" more) before producing a response. In agent problems that\nrequire interaction, this can be done by generating thinking traces before\nacting in the world. However, this process does not allow agents to acquire new\ninformation from the environment or adapt their behavior over time. In this\nwork, we propose to scale test-time interaction, an untapped dimension of\ntest-time scaling that increases the agent's interaction horizon to enable\nrunning rich behaviors such as exploration, backtracking, and dynamic\nre-planning within a single rollout. To demonstrate the promise of this scaling\ndimension, we study the domain of web agents. We first show that even\nprompting-based interaction scaling without any training can improve task\nsuccess on web benchmarks non-trivially. Building on this, we introduce TTI\n(Test-Time Interaction), a curriculum-based online reinforcement learning (RL)\napproach that trains agents by adaptively adjusting their rollout lengths.\nUsing a Gemma 3 12B model, TTI produces state-of-the-art open-source, open-data\nweb agents on WebVoyager and WebArena benchmarks. We further show that TTI\nenables agents to balance exploration and exploitation adaptively. Our results\nestablish interaction scaling as a powerful, complementary axis to scaling\nper-step compute, offering new avenues for training adaptive agents.", "published": "2025-06-09 17:50:02", "link": "http://arxiv.org/abs/2506.07976v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Guideline Forest: Experience-Induced Multi-Guideline Reasoning with Stepwise Aggregation", "abstract": "Human reasoning is flexible, adaptive, and grounded in prior\nexperience-qualities that large language models (LLMs) still struggle to\nemulate. Existing methods either explore diverse reasoning paths at inference\ntime or search for optimal workflows through expensive operations, but both\nfall short in leveraging multiple reusable strategies in a structured,\nefficient manner. We propose Guideline Forest, a framework that enhances LLMs\nreasoning by inducing structured reasoning strategies-called guidelines-from\nverified examples and executing them via step-wise aggregation. Unlike\ntest-time search or single-path distillation, our method draws on verified\nreasoning experiences by inducing reusable guidelines and expanding each into\ndiverse variants. Much like human reasoning, these variants reflect alternative\nthought patterns, are executed in parallel, refined via self-correction, and\naggregated step by step-enabling the model to adaptively resolve uncertainty\nand synthesize robust solutions.We evaluate Guideline Forest on four\nbenchmarks-GSM8K, MATH-500, MBPP, and HumanEval-spanning mathematical and\nprogrammatic reasoning. Guideline Forest consistently outperforms strong\nbaselines, including CoT, ReAct, ToT, FoT, and AFlow. Ablation studies further\nhighlight the effectiveness of multi-path reasoning and stepwise aggregation,\nunderscoring the Guideline Forest's adaptability and generalization potential.", "published": "2025-06-09 14:46:31", "link": "http://arxiv.org/abs/2506.07820v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "ArchiLense: A Framework for Quantitative Analysis of Architectural Styles Based on Vision Large Language Models", "abstract": "Architectural cultures across regions are characterized by stylistic\ndiversity, shaped by historical, social, and technological contexts in addition\nto geograph-ical conditions. Understanding architectural styles requires the\nability to describe and analyze the stylistic features of different architects\nfrom various regions through visual observations of architectural imagery.\nHowever, traditional studies of architectural culture have largely relied on\nsubjective expert interpretations and historical literature reviews, often\nsuffering from regional biases and limited ex-planatory scope. To address these\nchallenges, this study proposes three core contributions: (1) We construct a\nprofessional architectural style dataset named ArchDiffBench, which comprises\n1,765 high-quality architectural images and their corresponding style\nannotations, collected from different regions and historical periods. (2) We\npropose ArchiLense, an analytical framework grounded in Vision-Language Models\nand constructed using the ArchDiffBench dataset. By integrating ad-vanced\ncomputer vision techniques, deep learning, and machine learning algo-rithms,\nArchiLense enables automatic recognition, comparison, and precise\nclassi-fication of architectural imagery, producing descriptive language\noutputs that ar-ticulate stylistic differences. (3) Extensive evaluations show\nthat ArchiLense achieves strong performance in architectural style recognition,\nwith a 92.4% con-sistency rate with expert annotations and 84.5% classification\naccuracy, effec-tively capturing stylistic distinctions across images. The\nproposed approach transcends the subjectivity inherent in traditional analyses\nand offers a more objective and accurate perspective for comparative studies of\narchitectural culture.", "published": "2025-06-09 13:22:57", "link": "http://arxiv.org/abs/2506.07739v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "MoE-MLoRA for Multi-Domain CTR Prediction: Efficient Adaptation with Expert Specialization", "abstract": "Personalized recommendation systems must adapt to user interactions across\ndifferent domains. Traditional approaches like MLoRA apply a single adaptation\nper domain but lack flexibility in handling diverse user behaviors. To address\nthis, we propose MoE-MLoRA, a mixture-of-experts framework where each expert is\nfirst trained independently to specialize in its domain before a gating network\nis trained to weight their contributions dynamically. We evaluate MoE-MLoRA\nacross eight CTR models on Movielens and Taobao, showing that it improves\nperformance in large-scale, dynamic datasets (+1.45 Weighed-AUC in Taobao-20)\nbut offers limited benefits in structured datasets with low domain diversity\nand sparsity. Further analysis of the number of experts per domain reveals that\nlarger ensembles do not always improve performance, indicating the need for\nmodel-aware tuning. Our findings highlight the potential of expert-based\narchitectures for multi-domain recommendation systems, demonstrating that\ntask-aware specialization and adaptive gating can enhance predictive accuracy\nin complex environments. The implementation and code are available in our\nGitHub repository.", "published": "2025-06-09 09:03:05", "link": "http://arxiv.org/abs/2506.07563v2", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "GTR-CoT: Graph Traversal as Visual Chain of Thought for Molecular Structure Recognition", "abstract": "Optical Chemical Structure Recognition (OCSR) is crucial for digitizing\nchemical knowledge by converting molecular images into machine-readable\nformats. While recent vision-language models (VLMs) have shown potential in\nthis task, their image-captioning approach often struggles with complex\nmolecular structures and inconsistent annotations. To overcome these\nchallenges, we introduce GTR-Mol-VLM, a novel framework featuring two key\ninnovations: (1) the Graph Traversal as Visual Chain of Thought mechanism that\nemulates human reasoning by incrementally parsing molecular graphs through\nsequential atom-bond predictions, and (2) the data-centric principle of\nFaithfully Recognize What You've Seen, which addresses the mismatch between\nabbreviated structures in images and their expanded annotations. To support\nmodel development, we constructed GTR-CoT-1.3M, a large-scale\ninstruction-tuning dataset with meticulously corrected annotations, and\nintroduced MolRec-Bench, the first benchmark designed for a fine-grained\nevaluation of graph-parsing accuracy in OCSR. Comprehensive experiments\ndemonstrate that GTR-Mol-VLM achieves superior results compared to specialist\nmodels, chemistry-domain VLMs, and commercial general-purpose VLMs. Notably, in\nscenarios involving molecular images with functional group abbreviations,\nGTR-Mol-VLM outperforms the second-best baseline by approximately 14 percentage\npoints, both in SMILES-based and graph-based metrics. We hope that this work\nwill drive OCSR technology to more effectively meet real-world needs, thereby\nadvancing the fields of cheminformatics and AI for Science. We will release\nGTR-CoT at https://github.com/opendatalab/GTR-CoT.", "published": "2025-06-09 08:47:10", "link": "http://arxiv.org/abs/2506.07553v2", "categories": ["cs.AI", "q-bio.QM"], "primary_category": "cs.AI"}
{"title": "OneIG-Bench: Omni-dimensional Nuanced Evaluation for Image Generation", "abstract": "Text-to-image (T2I) models have garnered significant attention for generating\nhigh-quality images aligned with text prompts. However, rapid T2I model\nadvancements reveal limitations in early benchmarks, lacking comprehensive\nevaluations, for example, the evaluation on reasoning, text rendering and\nstyle. Notably, recent state-of-the-art models, with their rich knowledge\nmodeling capabilities, show promising results on the image generation problems\nrequiring strong reasoning ability, yet existing evaluation systems have not\nadequately addressed this frontier. To systematically address these gaps, we\nintroduce OneIG-Bench, a meticulously designed comprehensive benchmark\nframework for fine-grained evaluation of T2I models across multiple dimensions,\nincluding prompt-image alignment, text rendering precision, reasoning-generated\ncontent, stylization, and diversity. By structuring the evaluation, this\nbenchmark enables in-depth analysis of model performance, helping researchers\nand practitioners pinpoint strengths and bottlenecks in the full pipeline of\nimage generation. Specifically, OneIG-Bench enables flexible evaluation by\nallowing users to focus on a particular evaluation subset. Instead of\ngenerating images for the entire set of prompts, users can generate images only\nfor the prompts associated with the selected dimension and complete the\ncorresponding evaluation accordingly. Our codebase and dataset are now publicly\navailable to facilitate reproducible evaluation studies and cross-model\ncomparisons within the T2I research community.", "published": "2025-06-09 17:50:21", "link": "http://arxiv.org/abs/2506.07977v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Deep reinforcement learning for near-deterministic preparation of cubic- and quartic-phase gates in photonic quantum computing", "abstract": "Cubic-phase states are a sufficient resource for universal quantum computing\nover continuous variables. We present results from numerical experiments in\nwhich deep neural networks are trained via reinforcement learning to control a\nquantum optical circuit for generating cubic-phase states, with an average\nsuccess rate of 96%. The only non-Gaussian resource required is\nphoton-number-resolving measurements. We also show that the exact same\nresources enable the direct generation of a quartic-phase gate, with no need\nfor a cubic gate decomposition.", "published": "2025-06-09 15:22:54", "link": "http://arxiv.org/abs/2506.07859v2", "categories": ["quant-ph", "cs.LG"], "primary_category": "quant-ph"}
{"title": "The Subtle Interplay between Square-root Impact, Order Imbalance & Volatility: A Unifying Framework", "abstract": "In this work, we aim to reconcile several apparently contradictory\nobservations in market microstructure: is the famous ''square-root law'' of\nmetaorder impact that decays with time compatible with the random-walk nature\nof prices and the linear impact of order imbalances? Can one entirely explain\nthe volatility of prices as resulting from the flow of uninformed metaorders\nthat mechanically impact prices? We introduce a new theoretical framework to\ndescribe metaorders with different signs, sizes and durations, which all impact\nprices as a square-root of volume but with a subsequent time decay. We show\nthat, as in the original propagator model, price diffusion is ensured by the\nlong memory of cross-correlations between metaorders. In order to account for\nthe effect of strongly fluctuating volumes $q$ of individual trades, we further\nintroduce two $q$-dependent exponents, which allows us to account for the way\nthe moments of generalized volume imbalance and the correlation between price\nchanges and generalized order flow imbalance scales with $T$. We predict in\nparticular that the corresponding power-laws depend in a non-monotonic fashion\non a parameter $a$ that allows one to put the same weight on all child orders\nor overweight large orders, a behaviour clearly borne out by empirical data. We\nalso predict that the correlation between price changes and volume imbalances\nshould display a maximum as a function of $a$, which again matches\nobservations. Such noteworthy agreement between theory and data suggests that\nour framework correctly captures the basic mechanism at the heart of price\nformation, namely the average impact of metaorders. We argue that our results\nsupport the ''Order-Driven'' theory of excess volatility, and are at odds with\nthe idea that a ''Fundamental'' component accounts for a large share of the\nvolatility of financial markets.", "published": "2025-06-09 12:53:25", "link": "http://arxiv.org/abs/2506.07711v2", "categories": ["q-fin.TR", "q-fin.ST"], "primary_category": "q-fin.TR"}
{"title": "An introduction to pitch strength in contemporary popular music analysis and production", "abstract": "Music information retrieval distinguishes between low- and high-level\ndescriptions of music. Current generative AI models rely on text descriptions\nthat are higher level than the controls familiar to studio musicians. Pitch\nstrength, a low-level perceptual parameter of contemporary popular music, may\nbe one feature that could make such AI models more suited to music production.\nSignal and perceptual analyses suggest that pitch strength (1) varies\nsignificantly across and inside songs; (2) contributes to both small- and\nlarge-scale structure; (3) contributes to the handling of polyphonic\ndissonance; and (4) may be a feature of upper harmonics made audible in a\nperspective of perceptual richness.", "published": "2025-06-09 06:47:26", "link": "http://arxiv.org/abs/2506.07473v2", "categories": ["cs.SD", "eess.AS", "00A65", "J.5"], "primary_category": "cs.SD"}
{"title": "Stone Soup: ADS-B-based Multi-Target Tracking with Stochastic Integration Filter", "abstract": "This paper focuses on the multi-target tracking using the Stone Soup\nframework. In particular, we aim at evaluation of two multi-target tracking\nscenarios based on the simulated class-B dataset and ADS-B class-A dataset\nprovided by OpenSky Network. The scenarios are evaluated w.r.t. selection of a\nlocal state estimator using a range of the Stone Soup metrics. Source code with\nscenario definitions and Stone Soup set-up are provided along with the paper.", "published": "2025-06-09 16:01:47", "link": "http://arxiv.org/abs/2506.07889v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "From Passive to Active Reasoning: Can Large Language Models Ask the Right Questions under Incomplete Information?", "abstract": "While existing benchmarks probe the reasoning abilities of large language\nmodels (LLMs) across diverse domains, they predominantly assess passive\nreasoning, providing models with all the information needed to reach a\nsolution. By contrast, active reasoning-where an LLM must interact with\nexternal systems to acquire missing evidence or data-has received little\nsystematic attention. To address this shortfall, we present AR-Bench, a novel\nbenchmark designed explicitly to evaluate an LLM's active reasoning skills.\nAR-Bench comprises three task families-detective cases, situation puzzles, and\nguessing numbers-that together simulate real-world, agentic scenarios and\nmeasure performance across commonsense, logical, and symbolic reasoning\nchallenges. Empirical evaluation on AR-Bench demonstrates that contemporary\nLLMs exhibit pronounced difficulties with active reasoning: they frequently\nfail to acquire or leverage the information needed to solve tasks. This gap\nhighlights a stark divergence between their passive and active reasoning\nabilities. Moreover, ablation studies indicate that even advanced strategies,\nsuch as tree-based searching or post-training approaches, yield only modest\ngains and fall short of the levels required for real-world deployment.\nCollectively, these findings highlight the critical need to advance methodology\nfor active reasoning, e.g., incorporating interactive learning, real-time\nfeedback loops, and environment-aware objectives for training. The benchmark is\npublicly available at: https://github.com/tmlr-group/AR-Bench.", "published": "2025-06-09 23:56:41", "link": "http://arxiv.org/abs/2506.08295v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "From Debate to Equilibrium: Belief-Driven Multi-Agent LLM Reasoning via Bayesian Nash Equilibrium", "abstract": "Multi-agent frameworks can substantially boost the reasoning power of large\nlanguage models (LLMs), but they typically incur heavy computational costs and\nlack convergence guarantees. To overcome these challenges, we recast multi-LLM\ncoordination as an incomplete-information game and seek a Bayesian Nash\nequilibrium (BNE), in which each agent optimally responds to its probabilistic\nbeliefs about the strategies of others. We introduce Efficient Coordination via\nNash Equilibrium (ECON), a hierarchical reinforcement-learning paradigm that\nmarries distributed reasoning with centralized final output. Under ECON, each\nLLM independently selects responses that maximize its expected reward,\nconditioned on its beliefs about co-agents, without requiring costly\ninter-agent exchanges. We mathematically prove that ECON attains a markedly\ntighter regret bound than non-equilibrium multi-agent schemes. Empirically,\nECON outperforms existing multi-LLM approaches by 11.2% on average across six\nbenchmarks spanning complex reasoning and planning tasks. Further experiments\ndemonstrate ECON's ability to flexibly incorporate additional models,\nconfirming its scalability and paving the way toward larger, more powerful\nmulti-LLM ensembles. The code is publicly available at:\nhttps://github.com/tmlr-group/ECON.", "published": "2025-06-09 23:49:14", "link": "http://arxiv.org/abs/2506.08292v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Instruction-Tuned Video-Audio Models Elucidate Functional Specialization in the Brain", "abstract": "Recent voxel-wise multimodal brain encoding studies have shown that\nmultimodal large language models (MLLMs) exhibit a higher degree of brain\nalignment compared to unimodal models in both unimodal and multimodal stimulus\nsettings. More recently, instruction-tuned multimodal models have shown to\ngenerate task-specific representations that align strongly with brain activity.\nHowever, prior work evaluating the brain alignment of MLLMs has primarily\nfocused on unimodal settings or relied on non-instruction-tuned multimodal\nmodels for multimodal stimuli. To address this gap, we investigated brain\nalignment, that is, measuring the degree of predictivity of neural activity\nrecorded while participants were watching naturalistic movies (video along with\naudio) with representations derived from MLLMs. We utilized\ninstruction-specific embeddings from six video and two audio instruction-tuned\nMLLMs. Experiments with 13 video task-specific instructions show that\ninstruction-tuned video MLLMs significantly outperform non-instruction-tuned\nmultimodal (by 15%) and unimodal models (by 20%). Our evaluation of MLLMs for\nboth video and audio tasks using language-guided instructions shows clear\ndisentanglement in task-specific representations from MLLMs, leading to precise\ndifferentiation of multimodal functional processing in the brain. We also find\nthat MLLM layers align hierarchically with the brain, with early sensory areas\nshowing strong alignment with early layers, while higher-level visual and\nlanguage regions align more with middle to late layers. These findings provide\nclear evidence for the role of task-specific instructions in improving the\nalignment between brain activity and MLLMs, and open new avenues for mapping\njoint information processing in both the systems. We make the code publicly\navailable [https://github.com/subbareddy248/mllm_videos].", "published": "2025-06-09 22:48:36", "link": "http://arxiv.org/abs/2506.08277v1", "categories": ["q-bio.NC", "cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "q-bio.NC"}
{"title": "Reinforcement Learning from Human Feedback with High-Confidence Safety Constraints", "abstract": "Existing approaches to language model alignment often treat safety as a\ntradeoff against helpfulness, which can lead to unacceptable responses in\nsensitive domains. To ensure reliable performance in such settings, we propose\nHigh-Confidence Safe Reinforcement Learning from Human Feedback (HC-RLHF), a\nmethod that provides high-confidence safety guarantees while maximizing\nhelpfulness. Similar to previous methods, HC-RLHF explicitly decouples human\npreferences into helpfulness and harmlessness (safety), which are learned by\ntraining a reward model and a cost model, respectively. It then employs a\ntwo-step process to find safe solutions. In the first step, it optimizes the\nreward function under an intentionally pessimistic version of the cost\nconstraint. In the second step, the trained model undergoes a safety test to\nverify whether its performance stays within an upper-confidence bound of the\nactual cost constraint. We provide a theoretical analysis of HC-RLHF, including\nproof that it will not return an unsafe solution with a probability greater\nthan a user-specified threshold. For our empirical analysis, we apply HC-RLHF\nto align three different language models (Qwen2-1.5B, Qwen2.5-3B, and\nLLaMa3.2-3B) with human preferences. Our results demonstrate that HC-RLHF\nproduces safe models with high probability and can improve harmlessness and\nhelpfulness compared to previous methods.", "published": "2025-06-09 22:03:56", "link": "http://arxiv.org/abs/2506.08266v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.AP"], "primary_category": "cs.LG"}
{"title": "Automatic Generation of Inference Making Questions for Reading Comprehension Assessments", "abstract": "Inference making is an essential but complex skill in reading comprehension\n(RC). Some inferences require resolving references across sentences, and some\nrely on using prior knowledge to fill in the detail that is not explicitly\nwritten in the text. Diagnostic RC questions can help educators provide more\neffective and targeted reading instruction and interventions for school-age\nstudents. We introduce a taxonomy of inference types for RC and use it to\nanalyze the distribution of items within a diagnostic RC item bank. Next, we\npresent experiments using GPT-4o to generate bridging-inference RC items for\ngiven reading passages via few-shot prompting, comparing conditions with and\nwithout chain-of-thought prompts. Generated items were evaluated on three\naspects: overall item quality, appropriate inference type, and LLM reasoning,\nachieving high inter-rater agreements above 0.90. Our results show that GPT-4o\nproduced 93.8% good-quality questions suitable for operational use in grade\n3-12 contexts; however, only 42.6% of the generated questions accurately\nmatched the targeted inference type. We conclude that combining automatic item\ngeneration with human judgment offers a promising path toward scalable,\nhigh-quality diagnostic RC assessments.", "published": "2025-06-09 21:50:12", "link": "http://arxiv.org/abs/2506.08260v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "RADAR: Benchmarking Language Models on Imperfect Tabular Data", "abstract": "Language models (LMs) are increasingly being deployed to perform autonomous\ndata analyses. However, their data awareness -- the ability to recognize,\nreason over, and appropriately handle data artifacts such as missing values,\noutliers, and logical inconsistencies -- remains underexplored. These artifacts\nare especially common in real-world tabular data and, if mishandled, can\nsignificantly compromise the validity of analytical conclusions. To address\nthis gap, we present RADAR, a benchmark for systematically evaluating\ndata-aware reasoning on tabular data. We develop a framework to simulate data\nartifacts via programmatic perturbations to enable targeted evaluation of model\nbehavior. RADAR comprises 2980 table query pairs, grounded in real-world data\nspanning 9 domains and 5 data artifact types. In addition to evaluating\nartifact handling, RADAR systematically varies table size to study how\nreasoning performance holds when increasing table size. Our evaluation reveals\nthat, despite decent performance on tables without data artifacts, frontier\nmodels degrade significantly when data artifacts are introduced, exposing\ncritical gaps in their capacity for robust, data-aware analysis. Designed to be\nflexible and extensible, RADAR supports diverse perturbation types and\ncontrollable table sizes, offering a valuable resource for advancing tabular\nreasoning.", "published": "2025-06-09 21:32:47", "link": "http://arxiv.org/abs/2506.08249v1", "categories": ["cs.DB", "cs.CL"], "primary_category": "cs.DB"}
{"title": "Can AI Validate Science? Benchmarking LLMs for Accurate Scientific Claim $\\rightarrow$ Evidence Reasoning", "abstract": "Large language models (LLMs) are increasingly being used for complex research\ntasks such as literature review, idea generation, and scientific paper\nanalysis, yet their ability to truly understand and process the intricate\nrelationships within complex research papers, such as the logical links between\nclaims and supporting evidence remains largely unexplored. In this study, we\npresent CLAIM-BENCH, a comprehensive benchmark for evaluating LLMs'\ncapabilities in scientific claim-evidence extraction and validation, a task\nthat reflects deeper comprehension of scientific argumentation. We\nsystematically compare three approaches which are inspired by divide and\nconquer approaches, across six diverse LLMs, highlighting model-specific\nstrengths and weaknesses in scientific comprehension. Through evaluation\ninvolving over 300 claim-evidence pairs across multiple research domains, we\nreveal significant limitations in LLMs' ability to process complex scientific\ncontent. Our results demonstrate that closed-source models like GPT-4 and\nClaude consistently outperform open-source counterparts in precision and recall\nacross claim-evidence identification tasks. Furthermore, strategically designed\nthree-pass and one-by-one prompting approaches significantly improve LLMs'\nabilities to accurately link dispersed evidence with claims, although this\ncomes at increased computational cost. CLAIM-BENCH sets a new standard for\nevaluating scientific comprehension in LLMs, offering both a diagnostic tool\nand a path forward for building systems capable of deeper, more reliable\nreasoning across full-length papers.", "published": "2025-06-09 21:04:39", "link": "http://arxiv.org/abs/2506.08235v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Compound AI Systems Optimization: A Survey of Methods, Challenges, and Future Directions", "abstract": "Recent advancements in large language models (LLMs) and AI systems have led\nto a paradigm shift in the design and optimization of complex AI workflows. By\nintegrating multiple components, compound AI systems have become increasingly\nadept at performing sophisticated tasks. However, as these systems grow in\ncomplexity, new challenges arise in optimizing not only individual components\nbut also their interactions. While traditional optimization methods such as\nsupervised fine-tuning (SFT) and reinforcement learning (RL) remain\nfoundational, the rise of natural language feedback introduces promising new\napproaches, especially for optimizing non-differentiable systems. This paper\nprovides a systematic review of recent progress in optimizing compound AI\nsystems, encompassing both numerical and language-based techniques. We\nformalize the notion of compound AI system optimization, classify existing\nmethods along several key dimensions, and highlight open research challenges\nand future directions in this rapidly evolving field. A list of surveyed papers\nis publicly available at https://github.com/MiuLab/AISysOpt-Survey.", "published": "2025-06-09 21:04:14", "link": "http://arxiv.org/abs/2506.08234v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "\"I Wrote, I Paused, I Rewrote\" Teaching LLMs to Read Between the Lines of Student Writing", "abstract": "Large language models(LLMs) like Gemini are becoming common tools for\nsupporting student writing. But most of their feedback is based only on the\nfinal essay missing important context about how that text was written. In this\npaper, we explore whether using writing process data, collected through\nkeystroke logging and periodic snapshots, can help LLMs give feedback that\nbetter reflects how learners think and revise while writing. We built a digital\nwriting tool that captures both what students type and how their essays evolve\nover time. Twenty students used this tool to write timed essays, which were\nthen evaluated in two ways: (i) LLM generated feedback using both the final\nessay and the full writing trace, and (ii) After the task, students completed\nsurveys about how useful and relatable they found the feedback. Early results\nshow that learners preferred the process-aware LLM feedback, finding it more in\ntune with their own thinking. We also found that certain types of edits, like\nadding new content or reorganizing paragraphs, aligned closely with higher\nscores in areas like coherence and elaboration. Our findings suggest that\nmaking LLMs more aware of the writing process can lead to feedback that feels\nmore meaningful, personal, and supportive.", "published": "2025-06-09 20:42:02", "link": "http://arxiv.org/abs/2506.08221v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation", "abstract": "Both text-to-image generation and large language models (LLMs) have made\nsignificant advancements. However, many text-to-image models still employ the\nsomewhat outdated T5 and CLIP as their text encoders. In this work, we\ninvestigate the effectiveness of using modern decoder-only LLMs as text\nencoders for text-to-image diffusion models. We build a standardized training\nand evaluation pipeline that allows us to isolate and evaluate the effect of\ndifferent text embeddings. We train a total of 27 text-to-image models with 12\ndifferent text encoders to analyze the critical aspects of LLMs that could\nimpact text-to-image generation, including the approaches to extract\nembeddings, different LLMs variants, and model sizes. Our experiments reveal\nthat the de facto way of using last-layer embeddings as conditioning leads to\ninferior performance. Instead, we explore embeddings from various layers and\nfind that using layer-normalized averaging across all layers significantly\nimproves alignment with complex prompts. Most LLMs with this conditioning\noutperform the baseline T5 model, showing enhanced performance in advanced\nvisio-linguistic reasoning skills.", "published": "2025-06-09 20:29:53", "link": "http://arxiv.org/abs/2506.08210v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "GradEscape: A Gradient-Based Evader Against AI-Generated Text Detectors", "abstract": "In this paper, we introduce GradEscape, the first gradient-based evader\ndesigned to attack AI-generated text (AIGT) detectors. GradEscape overcomes the\nundifferentiable computation problem, caused by the discrete nature of text, by\nintroducing a novel approach to construct weighted embeddings for the detector\ninput. It then updates the evader model parameters using feedback from victim\ndetectors, achieving high attack success with minimal text modification. To\naddress the issue of tokenizer mismatch between the evader and the detector, we\nintroduce a warm-started evader method, enabling GradEscape to adapt to\ndetectors across any language model architecture. Moreover, we employ novel\ntokenizer inference and model extraction techniques, facilitating effective\nevasion even in query-only access.\n  We evaluate GradEscape on four datasets and three widely-used language\nmodels, benchmarking it against four state-of-the-art AIGT evaders.\nExperimental results demonstrate that GradEscape outperforms existing evaders\nin various scenarios, including with an 11B paraphrase model, while utilizing\nonly 139M parameters. We have successfully applied GradEscape to two real-world\ncommercial AIGT detectors. Our analysis reveals that the primary vulnerability\nstems from disparity in text expression styles within the training data. We\nalso propose a potential defense strategy to mitigate the threat of AIGT\nevaders. We open-source our GradEscape for developing more robust AIGT\ndetectors.", "published": "2025-06-09 19:56:42", "link": "http://arxiv.org/abs/2506.08188v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Unable to forget: Proactive lnterference Reveals Working Memory Limits in LLMs Beyond Context Length", "abstract": "Information retrieval in Large Language Models (LLMs) is increasingly\nrecognized as intertwined with generation capabilities rather than mere lookup.\nWhile longer contexts are often assumed to improve retrieval, the effects of\nintra-context interference remain understudied. To address this, we adapt the\nproactive interference (PI) paradigm from cognitive science, where earlier\ninformation disrupts recall of newer updates. In humans, susceptibility to such\ninterference is inversely linked to working memory capacity. We introduce\nPI-LLM, an evaluation that sequentially streams semantically related key-value\nupdates and queries only the final values. Although these final values are\nclearly positioned just before the query, LLM retrieval accuracy declines\nlog-linearly toward zero as interference accumulates; errors arise from\nretrieving previously overwritten values. Attempts to mitigate interference via\nprompt engineering (e.g., instructing models to ignore earlier input) yield\nlimited success. These findings reveal a fundamental constraint on LLMs'\nability to disentangle interference and flexibly manipulate information,\nsuggesting a working memory bottleneck beyond mere context access. This calls\nfor approaches that strengthen models' ability to suppress irrelevant content\nduring retrieval.", "published": "2025-06-09 19:49:11", "link": "http://arxiv.org/abs/2506.08184v1", "categories": ["cs.CL", "cs.AI", "q-bio.NC"], "primary_category": "cs.CL"}
{"title": "LLM-BT: Back-Translation as a Framework for Terminology Standardization and Dynamic Semantic Embedding", "abstract": "The rapid growth of English technical terms challenges traditional\nexpert-driven standardization, especially in fast-evolving fields like AI and\nquantum computing. Manual methods struggle to ensure multilingual consistency.\nWe propose \\textbf{LLM-BT}, a back-translation framework powered by large\nlanguage models (LLMs) to automate terminology verification and standardization\nvia cross-lingual semantic alignment. Our contributions are: \\textbf{(1)\nTerm-Level Consistency Validation:} Using English $\\rightarrow$ intermediate\nlanguage $\\rightarrow$ English back-translation, LLM-BT achieves high term\nconsistency across models (e.g., GPT-4, DeepSeek, Grok), with case studies\nshowing over 90\\% exact or semantic matches. \\textbf{(2) Multi-Path\nVerification Workflow:} A novel ``Retrieve--Generate--Verify--Optimize''\npipeline integrates serial (e.g., EN $\\rightarrow$ ZHcn $\\rightarrow$ ZHtw\n$\\rightarrow$ EN) and parallel (e.g., EN $\\rightarrow$ Chinese/Portuguese\n$\\rightarrow$ EN) BT routes. BLEU and term accuracy indicate strong\ncross-lingual robustness (BLEU $>$ 0.45; Portuguese accuracy 100\\%).\n\\textbf{(3) Back-Translation as Semantic Embedding:} BT is conceptualized as\ndynamic semantic embedding, revealing latent meaning trajectories. Unlike\nstatic embeddings, LLM-BT provides transparent path-based embeddings shaped by\nmodel evolution. LLM-BT transforms back-translation into an active engine for\nmultilingual terminology standardization, enabling human--AI collaboration:\nmachines ensure semantic fidelity, humans guide cultural interpretation. This\ninfrastructure supports terminology governance across scientific and\ntechnological fields worldwide.", "published": "2025-06-09 19:39:09", "link": "http://arxiv.org/abs/2506.08174v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Artificial Intelligence Write Like Borges? An Evaluation Protocol for Spanish Microfiction", "abstract": "Automated story writing has been a subject of study for over 60 years. Large\nlanguage models can generate narratively consistent and linguistically coherent\nshort fiction texts. Despite these advancements, rigorous assessment of such\noutputs for literary merit - especially concerning aesthetic qualities - has\nreceived scant attention. In this paper, we address the challenge of evaluating\nAI-generated microfictions and argue that this task requires consideration of\nliterary criteria across various aspects of the text, such as thematic\ncoherence, textual clarity, interpretive depth, and aesthetic quality. To\nfacilitate this, we present GrAImes: an evaluation protocol grounded in\nliterary theory, specifically drawing from a literary perspective, to offer an\nobjective framework for assessing AI-generated microfiction. Furthermore, we\nreport the results of our validation of the evaluation protocol, as answered by\nboth literature experts and literary enthusiasts. This protocol will serve as a\nfoundation for evaluating automatically generated microfictions and assessing\ntheir literary value.", "published": "2025-06-09 19:34:13", "link": "http://arxiv.org/abs/2506.08172v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ETT-CKGE: Efficient Task-driven Tokens for Continual Knowledge Graph Embedding", "abstract": "Continual Knowledge Graph Embedding (CKGE) seeks to integrate new knowledge\nwhile preserving past information. However, existing methods struggle with\nefficiency and scalability due to two key limitations: (1) suboptimal knowledge\npreservation between snapshots caused by manually designed node/relation\nimportance scores that ignore graph dependencies relevant to the downstream\ntask, and (2) computationally expensive graph traversal for node/relation\nimportance calculation, leading to slow training and high memory overhead. To\naddress these limitations, we introduce ETT-CKGE (Efficient, Task-driven,\nTokens for Continual Knowledge Graph Embedding), a novel task-guided CKGE\nmethod that leverages efficient task-driven tokens for efficient and effective\nknowledge transfer between snapshots. Our method introduces a set of learnable\ntokens that directly capture task-relevant signals, eliminating the need for\nexplicit node scoring or traversal. These tokens serve as consistent and\nreusable guidance across snapshots, enabling efficient token-masked embedding\nalignment between snapshots. Importantly, knowledge transfer is achieved\nthrough simple matrix operations, significantly reducing training time and\nmemory usage. Extensive experiments across six benchmark datasets demonstrate\nthat ETT-CKGE consistently achieves superior or competitive predictive\nperformance, while substantially improving training efficiency and scalability\ncompared to state-of-the-art CKGE methods. The code is available at:\nhttps://github.com/lijingzhu1/ETT-CKGE/tree/main", "published": "2025-06-09 19:07:59", "link": "http://arxiv.org/abs/2506.08158v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual Hate Speech Detection in Social Media Using Translation-Based Approaches with Large Language Models", "abstract": "Social media platforms are critical spaces for public discourse, shaping\nopinions and community dynamics, yet their widespread use has amplified harmful\ncontent, particularly hate speech, threatening online safety and inclusivity.\nWhile hate speech detection has been extensively studied in languages like\nEnglish and Spanish, Urdu remains underexplored, especially using\ntranslation-based approaches. To address this gap, we introduce a trilingual\ndataset of 10,193 tweets in English (3,834 samples), Urdu (3,197 samples), and\nSpanish (3,162 samples), collected via keyword filtering, with a balanced\ndistribution of 4,849 Hateful and 5,344 Not-Hateful labels. Our methodology\nleverages attention layers as a precursor to transformer-based models and large\nlanguage models (LLMs), enhancing feature extraction for multilingual hate\nspeech detection. For non-transformer models, we use TF-IDF for feature\nextraction. The dataset is benchmarked using state-of-the-art models, including\nGPT-3.5 Turbo and Qwen 2.5 72B, alongside traditional machine learning models\nlike SVM and other transformers (e.g., BERT, RoBERTa). Three annotators,\nfollowing rigorous guidelines, ensured high dataset quality, achieving a\nFleiss' Kappa of 0.821. Our approach, integrating attention layers with GPT-3.5\nTurbo and Qwen 2.5 72B, achieves strong performance, with macro F1 scores of\n0.87 for English (GPT-3.5 Turbo), 0.85 for Spanish (GPT-3.5 Turbo), 0.81 for\nUrdu (Qwen 2.5 72B), and 0.88 for the joint multilingual model (Qwen 2.5 72B).\nThese results reflect improvements of 8.75% in English (over SVM baseline\n0.80), 8.97% in Spanish (over SVM baseline 0.78), 5.19% in Urdu (over SVM\nbaseline 0.77), and 7.32% in the joint multilingual model (over SVM baseline\n0.82). Our framework offers a robust solution for multilingual hate speech\ndetection, fostering safer digital communities worldwide.", "published": "2025-06-09 18:53:56", "link": "http://arxiv.org/abs/2506.08147v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AutoSDT: Scaling Data-Driven Discovery Tasks Toward Open Co-Scientists", "abstract": "Despite long-standing efforts in accelerating scientific discovery with AI,\nbuilding AI co-scientists remains challenging due to limited high-quality data\nfor training and evaluation. To tackle this data scarcity issue, we present\nAutoSDT, an automatic pipeline that collects high-quality coding tasks in\nreal-world data-driven discovery workflows. AutoSDT leverages the coding\ncapabilities and parametric knowledge of LLMs to search for diverse sources,\nselect ecologically valid tasks, and synthesize accurate task instructions and\ncode solutions. Using our pipeline, we construct AutoSDT-5K, a dataset of 5,404\ncoding tasks for data-driven discovery that covers four scientific disciplines\nand 756 unique Python packages. To the best of our knowledge, AutoSDT-5K is the\nonly automatically collected and the largest open dataset for data-driven\nscientific discovery. Expert feedback on a subset of 256 tasks shows the\neffectiveness of AutoSDT: 93% of the collected tasks are ecologically valid,\nand 92.2% of the synthesized programs are functionally correct. Trained on\nAutoSDT-5K, the Qwen2.5-Coder-Instruct LLM series, dubbed AutoSDT-Coder, show\nsubstantial improvement on two challenging data-driven discovery benchmarks,\nScienceAgentBench and DiscoveryBench. Most notably, AutoSDT-Coder-32B reaches\nthe same level of performance as GPT-4o on ScienceAgentBench with a success\nrate of 7.8%, doubling the performance of its base model. On DiscoveryBench, it\nlifts the hypothesis matching score to 8.1, bringing a 17.4% relative\nimprovement and closing the gap between open-weight models and GPT-4o.", "published": "2025-06-09 18:41:50", "link": "http://arxiv.org/abs/2506.08140v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Treewidth of Outer $k$-Planar Graphs", "abstract": "Treewidth is an important structural graph parameter that quantifies how\nclosely a graph resembles a tree-like structure. It has applications in many\nalgorithmic and combinatorial problems. In this paper, we study treewidth of\nouter $k$-planar graphs - graphs admitting a convex drawing where all vertices\nlie on a circle and each edge crosses at most $k$ other edges. We also consider\na more general class of outer min-$k$-planar graphs, which are graphs admitting\na convex drawing where for every crossing of two edges at least one of these\nedges is crossed at most $k$ times.\n  Firman, Gutowski, Kryven, Okada and Wolff [GD 2024] proved that every outer\n$k$-planar graph has treewidth at most $1.5k+2$ and provided a lower bound of\n$k+2$ for even $k$. We establish a lower bound of $1.5k+0.5$ for every odd $k$.\nAdditionally, they showed that every outer min-$k$-planar graph has treewidth\nat most $3k+1$. We improve this upper bound to $3 \\cdot \\lfloor 0.5k\n\\rfloor+4$.\n  Our approach also allows us to upper bound the separation number, a parameter\nclosely related to treewidth, of outer min-$k$-planar graphs by $2 \\cdot\n\\lfloor 0.5k \\rfloor+4$. This improves the previous bound of $2k+1$ and\nachieves a bound with an optimal multiplicative constant.", "published": "2025-06-09 18:58:23", "link": "http://arxiv.org/abs/2506.08151v1", "categories": ["cs.DM", "math.CO"], "primary_category": "cs.DM"}
{"title": "Serendipitous Recommendation with Multimodal LLM", "abstract": "Conventional recommendation systems succeed in identifying relevant content\nbut often fail to provide users with surprising or novel items. Multimodal\nLarge Language Models (MLLMs) possess the world knowledge and multimodal\nunderstanding needed for serendipity, but their integration into\nbillion-item-scale platforms presents significant challenges. In this paper, we\npropose a novel hierarchical framework where fine-tuned MLLMs provide\nhigh-level guidance to conventional recommendation models, steering them\ntowards more serendipitous suggestions. This approach leverages MLLM strengths\nin understanding multimodal content and user interests while retaining the\nefficiency of traditional models for item-level recommendation. This mitigates\nthe complexity of applying MLLMs directly to vast action spaces. We also\ndemonstrate a chain-of-thought strategy enabling MLLMs to discover novel user\ninterests by first understanding video content and then identifying relevant\nyet unexplored interest clusters. Through live experiments within a commercial\nshort-form video platform serving billions of users, we show that our\nMLLM-powered approach significantly improves both recommendation serendipity\nand user satisfaction.", "published": "2025-06-09 23:13:22", "link": "http://arxiv.org/abs/2506.08283v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "No Stupid Questions: An Analysis of Question Query Generation for Citation Recommendation", "abstract": "Existing techniques for citation recommendation are constrained by their\nadherence to article contents and metadata. We leverage GPT-4o-mini's latent\nexpertise as an inquisitive assistant by instructing it to ask questions which,\nwhen answered, could expose new insights about an excerpt from a scientific\narticle. We evaluate the utility of these questions as retrieval queries,\nmeasuring their effectiveness in retrieving and ranking masked target\ndocuments. In some cases, generated questions ended up being better queries\nthan extractive keyword queries generated by the same model. We additionally\npropose MMR-RBO, a variation of Maximal Marginal Relevance (MMR) using\nRank-Biased Overlap (RBO) to identify which questions will perform\ncompetitively with the keyword baseline. As all question queries yield unique\nresult sets, we contend that there are no stupid questions.", "published": "2025-06-09 20:13:32", "link": "http://arxiv.org/abs/2506.08196v1", "categories": ["cs.IR", "cs.DL"], "primary_category": "cs.IR"}
{"title": "Hierarchical Lexical Graph for Enhanced Multi-Hop Retrieval", "abstract": "Retrieval-Augmented Generation (RAG) grounds large language models in\nexternal evidence, yet it still falters when answers must be pieced together\nacross semantically distant documents. We close this gap with the Hierarchical\nLexical Graph (HLG), a three-tier index that (i) traces every atomic\nproposition to its source, (ii) clusters propositions into latent topics, and\n(iii) links entities and relations to expose cross-document paths. On top of\nHLG we build two complementary, plug-and-play retrievers: StatementGraphRAG,\nwhich performs fine-grained entity-aware beam search over propositions for\nhigh-precision factoid questions, and TopicGraphRAG, which selects coarse\ntopics before expanding along entity links to supply broad yet relevant context\nfor exploratory queries. Additionally, existing benchmarks lack the complexity\nrequired to rigorously evaluate multi-hop summarization systems, often focusing\non single-document queries or limited datasets. To address this, we introduce a\nsynthetic dataset generation pipeline that curates realistic, multi-document\nquestion-answer pairs, enabling robust evaluation of multi-hop retrieval\nsystems. Extensive experiments across five datasets demonstrate that our\nmethods outperform naive chunk-based RAG achieving an average relative\nimprovement of 23.1% in retrieval recall and correctness. Open-source Python\nlibrary is available at https://github.com/awslabs/graphrag-toolkit.", "published": "2025-06-09 17:58:35", "link": "http://arxiv.org/abs/2506.08074v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Learning-Based Multiuser Scheduling in MIMO-OFDM Systems with Hybrid Beamforming", "abstract": "We investigate the multiuser scheduling problem in multiple-input\nmultiple-output (MIMO) systems using orthogonal frequency division multiplexing\n(OFDM) and hybrid beamforming in which a base station (BS) communicates with\nmultiple users over millimeter wave (mmWave) channels in the downlink. Improved\nscheduling is critical for enhancing spectral efficiency and the long-term\nperformance of the system from the perspective of proportional fairness (PF)\nmetric in hybrid beamforming systems due to its limited multiplexing gain. Our\nobjective is to maximize PF by properly designing the analog and digital\nprecoders within the hybrid beamforming and selecting the users subject to the\nnumber of radio frequency (RF) chains. Leveraging the characteristics of mmWave\nchannels, we apply a two-timescale protocol. On a long timescale, we assign an\nanalog beam to each user. Scheduling the users and designing the digital\nprecoder are done accordingly on a short timescale. To conduct scheduling, we\npropose combinatorial solutions, such as greedy and sorting algorithms,\nfollowed by a machine learning (ML) approach. Our numerical results highlight\nthe trade-off between the performance and complexity of the proposed\napproaches. Consequently, we show that the choice of approach depends on the\nspecific criteria within a given scenario.", "published": "2025-06-09 21:59:05", "link": "http://arxiv.org/abs/2506.08263v1", "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "A structure preserving H-curl algebraic multigrid method for the eddy current equations", "abstract": "A new algebraic multigrid method (AMG) is presented for solving the linear\nsystems associated with the eddy current approximation to the Maxwell\nequations. This AMG method extends an idea proposed by Reitzinger and Schoberl.\nThe main feature of the Reitzinger and Schoberl algorithm (RSAMG) is that it\nmaintains null-space properties of the Curl-Curl operator throughout all levels\nof the AMG hierarchy. It does this by enforcing a commuting relationship\ninvolving grid transfers and the discrete gradient operator. This null-space\npreservation property is critical to the algorithm's success, however enforcing\nthis commuting relationship is non-trivial except in the special case where one\nleverages a piece-wise constant nodal interpolation operator. For this reason,\nmesh independent convergence rates are generally not observed for RSAMG due to\nits reliance on sub-optimal piece-wise constant interpolation. We present a new\nAMG algorithm that enforces the same commuting relationship. The main advance\nis that the new structure preserving H-curl algorithm (SpHcurlAMG) does not\nrely on piece-wise constant interpolation and can leverage fairly general and\nmore sophisticated nodal interpolation operators. The key idea is to employ\nenergy minimization AMG (EAMG) to construct edge interpolation grid transfers\nand to enforce the commuting relationship by embedding it as constraints within\nan EAMG procedure. While it might appear that solving such a constrained energy\nminimization is costly, we illustrate how this is not the case in our context.\nNumerical results are then given demonstrating mesh independent convergence\nover a range of test problems.", "published": "2025-06-09 23:18:12", "link": "http://arxiv.org/abs/2506.08284v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "On Finite Element Methods for Heterogeneous Elliptic Problems", "abstract": "Dealing with variational formulations of second order elliptic problems with\ndiscontinuous coefficients, we recall a single field minimization problem of an\nextended functional presented by Bevilacqua et al (1974), which we associate\nwith the basic idea supporting discontinuous Galerkin finite element methods.\nWe review residual based stabilized mixed methods applied to Darcy flow in\nhomogeneous porous media and extend them to heterogeneous media with an\ninterface of discontinuity. For smooth interfaces, the proposed formulations\npreserve the continuity of the flux and exactly imposes the constraint between\nthe tangent components of Darcy velocity on the interface. Convergence studies\nfor a heterogeneous and anisotropic porous medium confirm the same rates of\nconvergence predicted for homogeneous problem with smooth solutions.", "published": "2025-06-09 21:39:48", "link": "http://arxiv.org/abs/2506.08251v1", "categories": ["math.NA", "cs.NA", "65N12, 65N22, 65N30, 35A35"], "primary_category": "math.NA"}
{"title": "Smile asymptotic for Bachelier Implied Volatility", "abstract": "We investigate the asymptotic behaviour of the Implied Volatility in the\nBachelier setting, extending the framework introduced by Benaim and Friz for\nthe Black-Scholes setting. Exploiting the theory of regular variation, we\nderive explicit expressions for the Bachelier Implied Volatility in the wings\nof the smile, linking these to the tail behaviour of the underlying's returns'\ndistribution. Furthermore, we establish a direct connection between the\nanalyticity strip of the returns' characteristic function and the asymptotic\nformula for the Implied Volatility smile at extreme moneyness.", "published": "2025-06-09 15:11:04", "link": "http://arxiv.org/abs/2506.08067v1", "categories": ["q-fin.PR", "math.PR", "q-fin.MF", "60E10, 91G20"], "primary_category": "q-fin.PR"}
{"title": "The Impact of Feature Scaling In Machine Learning: Effects on Regression and Classification Tasks", "abstract": "This research addresses the critical lack of comprehensive studies on feature\nscaling by systematically evaluating 12 scaling techniques - including several\nless common transformations - across 14 different Machine Learning algorithms\nand 16 datasets for classification and regression tasks. We meticulously\nanalyzed impacts on predictive performance (using metrics such as accuracy,\nMAE, MSE, and $R^2$) and computational costs (training time, inference time,\nand memory usage). Key findings reveal that while ensemble methods (such as\nRandom Forest and gradient boosting models like XGBoost, CatBoost and LightGBM)\ndemonstrate robust performance largely independent of scaling, other widely\nused models such as Logistic Regression, SVMs, TabNet, and MLPs show\nsignificant performance variations highly dependent on the chosen scaler. This\nextensive empirical analysis, with all source code, experimental results, and\nmodel parameters made publicly available to ensure complete transparency and\nreproducibility, offers model-specific crucial guidance to practitioners on the\nneed for an optimal selection of feature scaling techniques.", "published": "2025-06-09 22:32:51", "link": "http://arxiv.org/abs/2506.08274v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Parameter-free approximate equivariance for tasks with finite group symmetry", "abstract": "Equivariant neural networks incorporate symmetries through group actions,\nembedding them as an inductive bias to improve performance on a wide variety of\ntasks. However, existing equivariant methods can be computationally intensive,\nwith high parameter counts, and are often tied to a specific architecture. We\npropose a simple zero-parameter approach that imposes approximate equivariance\nfor a finite group in the latent representation, as an additional term in the\nloss function. We conduct experiments which allow the network to learn a group\nrepresentation on the latent space, and show in every case it prefers to learn\nthe regular representation. Fixing this action on the latent space, this yields\na simple method to impose approximate equivariance as an additional loss\npenalty. We benchmark our approach on three datasets and compare it against\nseveral existing equivariant methods, showing that in many cases it achieves\nsimilar or better performance for a fraction of the parameters.", "published": "2025-06-09 21:23:26", "link": "http://arxiv.org/abs/2506.08244v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Constrained Pareto Set Identification with Bandit Feedback", "abstract": "In this paper, we address the problem of identifying the Pareto Set under\nfeasibility constraints in a multivariate bandit setting. Specifically, given a\n$K$-armed bandit with unknown means $\\mu_1, \\dots, \\mu_K \\in \\mathbb{R}^d$, the\ngoal is to identify the set of arms whose mean is not uniformly worse than that\nof another arm (i.e., not smaller for all objectives), while satisfying some\nknown set of linear constraints, expressing, for example, some minimal\nperformance on each objective. Our focus lies in fixed-confidence\nidentification, for which we introduce an algorithm that significantly\noutperforms racing-like algorithms and the intuitive two-stage approach that\nfirst identifies feasible arms and then their Pareto Set. We further prove an\ninformation-theoretic lower bound on the sample complexity of any algorithm for\nconstrained Pareto Set identification, showing that the sample complexity of\nour approach is near-optimal. Our theoretical results are supported by an\nextensive empirical evaluation on a series of benchmarks.", "published": "2025-06-09 18:29:28", "link": "http://arxiv.org/abs/2506.08127v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "WWAggr: A Window Wasserstein-based Aggregation for Ensemble Change Point Detection", "abstract": "Change Point Detection (CPD) aims to identify moments of abrupt distribution\nshifts in data streams. Real-world high-dimensional CPD remains challenging due\nto data pattern complexity and violation of common assumptions. Resorting to\nstandalone deep neural networks, the current state-of-the-art detectors have\nyet to achieve perfect quality. Concurrently, ensembling provides more robust\nsolutions, boosting the performance. In this paper, we investigate ensembles of\ndeep change point detectors and realize that standard prediction aggregation\ntechniques, e.g., averaging, are suboptimal and fail to account for problem\npeculiarities. Alternatively, we introduce WWAggr -- a novel task-specific\nmethod of ensemble aggregation based on the Wasserstein distance. Our procedure\nis versatile, working effectively with various ensembles of deep CPD models.\nMoreover, unlike existing solutions, we practically lift a long-standing\nproblem of the decision threshold selection for CPD.", "published": "2025-06-09 13:52:10", "link": "http://arxiv.org/abs/2506.08066v1", "categories": ["stat.ML", "cs.AI", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Universal Differential Equations for Scientific Machine Learning of Node-Wise Battery Dynamics in Smart Grids", "abstract": "Universal Differential Equations (UDEs), which blend neural networks with\nphysical differential equations, have emerged as a powerful framework for\nscientific machine learning (SciML), enabling data-efficient, interpretable,\nand physically consistent modeling. In the context of smart grid systems,\nmodeling node-wise battery dynamics remains a challenge due to the\nstochasticity of solar input and variability in household load profiles.\nTraditional approaches often struggle with generalization and fail to capture\nunmodeled residual dynamics. This work proposes a UDE-based approach to learn\nnode-specific battery evolution by embedding a neural residual into a\nphysically inspired battery ODE. Synthetic yet realistic solar generation and\nload demand data are used to simulate battery dynamics over time. The neural\ncomponent learns to model unobserved or stochastic corrections arising from\nheterogeneity in node demand and environmental conditions. Comprehensive\nexperiments reveal that the trained UDE aligns closely with ground truth\nbattery trajectories, exhibits smooth convergence behavior, and maintains\nstability in long-term forecasts. These findings affirm the viability of\nUDE-based SciML approaches for battery modeling in decentralized energy\nnetworks and suggest broader implications for real-time control and\noptimization in renewable-integrated smart grids.", "published": "2025-06-09 22:24:55", "link": "http://arxiv.org/abs/2506.08272v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Low-Cost Wideband Tilted Beam Antenna for Millimeter-wave Vehicle Applications", "abstract": "To facilitate vehicle coverage for millimeter-wave applications, this\ncommunication presents a low-cost, wideband tilted-beam antenna. A novel design\nis proposed in which a slot antenna is both directly excited and\nelectromagnetically coupled to a monopole array. This slot-monopole\nconfiguration is inherently robust against substrate losses, enabling low-cost\nfabrication while maintaining high realized gain and compact size. Furthermore,\nthe slot-fed structure effectively excites multiple resonant modes within the\nmonopole array, resulting in a significantly enhanced bandwidth. Experimental\nresults demonstrate that the antenna achieves a -10-dB impedance bandwidth of\nover 76.5% (20-44.78 GHz) and a peak realized gain of 6.1 dBi.", "published": "2025-06-09 21:17:22", "link": "http://arxiv.org/abs/2506.08239v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Power Domain Sparse Dimensional Constellation Multiple Access (PD-SDCMA) for Enabled Flexible PONs", "abstract": "With the commercial deployment of 5G and the in-depth research of 6G, the\ndemand for high-speed data services in the next-generation fiber optic access\nsystems is growing increasingly. Passive optical networks (PONs) have become a\nresearch hotspot due to their characteristics of low loss, high bandwidth, and\nlow cost. However, the traditional orthogonal multiple access (OMA-PON) has\ndifficulty meeting the requirements of the next-generation PON for high\nspectral efficiency and flexibility. In this paper, a novel transmission\ntechnology, namely power-domain sparse dimension constellation multiple access\n(PD-SDCMA), is proposed for the first time. Through the signal space dimension\nselection strategy (S2D-strategy) in the high-dimensional signal space, the\nlow-dimensional constellation is sparsely superimposed into the\nhigh-dimensional space, thereby reducing multi-user interference and enhancing\nthe system capacity. PD-SDCMA supports higher-order modulation formats and more\naccess groups, and is also compatible with the existing orthogonal frequency\ndivision multiplexing (OFDM) architecture. The simulation results show that in\na 25 km single-mode fiber system, compared with PD-NOMA and 3D-NOMA, PD-SDCMA\ncan support more users and significantly reduce BER. This technology provides\nan efficient and low-cost solution for the evolution of Flexible PONs.", "published": "2025-06-09 03:39:50", "link": "http://arxiv.org/abs/2506.08053v1", "categories": ["cs.ET", "cs.NI", "eess.SP"], "primary_category": "cs.ET"}
{"title": "MoE-MLoRA for Multi-Domain CTR Prediction: Efficient Adaptation with Expert Specialization", "abstract": "Personalized recommendation systems must adapt to user interactions across\ndifferent domains. Traditional approaches like MLoRA apply a single adaptation\nper domain but lack flexibility in handling diverse user behaviors. To address\nthis, we propose MoE-MLoRA, a mixture-of-experts framework where each expert is\nfirst trained independently to specialize in its domain before a gating network\nis trained to weight their contributions dynamically. We evaluate MoE-MLoRA\nacross eight CTR models on Movielens and Taobao, showing that it improves\nperformance in large-scale, dynamic datasets (+1.45 Weighed-AUC in Taobao-20)\nbut offers limited benefits in structured datasets with low domain diversity\nand sparsity. Further analysis of the number of experts per domain reveals that\nlarger ensembles do not always improve performance, indicating the need for\nmodel-aware tuning. Our findings highlight the potential of expert-based\narchitectures for multi-domain recommendation systems, demonstrating that\ntask-aware specialization and adaptive gating can enhance predictive accuracy\nin complex environments. The implementation and code are available in our\nGitHub repository.", "published": "2025-06-09 09:03:05", "link": "http://arxiv.org/abs/2506.07563v3", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "MedChat: A Multi-Agent Framework for Multimodal Diagnosis with Large Language Models", "abstract": "The integration of deep learning-based glaucoma detection with large language\nmodels (LLMs) presents an automated strategy to mitigate ophthalmologist\nshortages and improve clinical reporting efficiency. However, applying general\nLLMs to medical imaging remains challenging due to hallucinations, limited\ninterpretability, and insufficient domain-specific medical knowledge, which can\npotentially reduce clinical accuracy. Although recent approaches combining\nimaging models with LLM reasoning have improved reporting, they typically rely\non a single generalist agent, restricting their capacity to emulate the diverse\nand complex reasoning found in multidisciplinary medical teams. To address\nthese limitations, we propose MedChat, a multi-agent diagnostic framework and\nplatform that combines specialized vision models with multiple role-specific\nLLM agents, all coordinated by a director agent. This design enhances\nreliability, reduces hallucination risk, and enables interactive diagnostic\nreporting through an interface tailored for clinical review and educational\nuse. Code available at https://github.com/Purdue-M2/MedChat.", "published": "2025-06-09 03:51:18", "link": "http://arxiv.org/abs/2506.07400v2", "categories": ["cs.MA", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.MA"}
{"title": "Solving partial differential equations in participating media", "abstract": "We consider the problem of solving partial differential equations (PDEs) in\ndomains with complex microparticle geometry that is impractical, or\nintractable, to model explicitly. Drawing inspiration from volume rendering, we\npropose tackling this problem by treating the domain as a participating medium\nthat models microparticle geometry stochastically, through aggregate\nstatistical properties (e.g., particle density). We first introduce the problem\nsetting of PDE simulation in participating media. We then specialize to\nexponential media and describe the properties that make them an attractive\nmodel of microparticle geometry for PDE simulation problems. We use these\nproperties to develop two new algorithms, volumetric walk on spheres and\nvolumetric walk on stars, that generalize previous Monte Carlo algorithms to\nenable efficient and discretization-free simulation of linear elliptic PDEs\n(e.g., Laplace) in participating media. We demonstrate experimentally that our\nalgorithms can solve Laplace boundary value problems with complex microparticle\ngeometry more accurately and more efficiently than previous approaches, such as\nensemble averaging and homogenization.", "published": "2025-06-09 21:12:22", "link": "http://arxiv.org/abs/2506.08237v1", "categories": ["cs.GR", "cs.NA", "math.NA"], "primary_category": "cs.GR"}
{"title": "Benchmarking Pre-Trained Time Series Models for Electricity Price Forecasting", "abstract": "Accurate electricity price forecasting (EPF) is crucial for effective\ndecision-making in power trading on the spot market. While recent advances in\ngenerative artificial intelligence (GenAI) and pre-trained large language\nmodels (LLMs) have inspired the development of numerous time series foundation\nmodels (TSFMs) for time series forecasting, their effectiveness in EPF remains\nuncertain. To address this gap, we benchmark several state-of-the-art\npretrained models--Chronos-Bolt, Chronos-T5, TimesFM, Moirai, Time-MoE, and\nTimeGPT--against established statistical and machine learning (ML) methods for\nEPF. Using 2024 day-ahead auction (DAA) electricity prices from Germany,\nFrance, the Netherlands, Austria, and Belgium, we generate daily forecasts with\na one-day horizon. Chronos-Bolt and Time-MoE emerge as the strongest among the\nTSFMs, performing on par with traditional models. However, the biseasonal MSTL\nmodel, which captures daily and weekly seasonality, stands out for its\nconsistent performance across countries and evaluation metrics, with no TSFM\nstatistically outperforming it.", "published": "2025-06-09 18:10:00", "link": "http://arxiv.org/abs/2506.08113v1", "categories": ["cs.LG", "cs.AI", "q-fin.ST"], "primary_category": "cs.LG"}
{"title": "The Subtle Interplay between Square-root Impact, Order Imbalance & Volatility: A Unifying Framework", "abstract": "In this work, we aim to reconcile several apparently contradictory\nobservations in market microstructure: is the famous ''square-root law'' of\nmetaorder impact that decays with time compatible with the random-walk nature\nof prices and the linear impact of order imbalances? Can one entirely explain\nthe volatility of prices as resulting from the flow of uninformed metaorders\nthat mechanically impact prices? We introduce a new theoretical framework to\ndescribe metaorders with different signs, sizes and durations, which all impact\nprices as a square-root of volume but with a subsequent time decay. We show\nthat, as in the original propagator model, price diffusion is ensured by the\nlong memory of cross-correlations between metaorders. In order to account for\nthe effect of strongly fluctuating volumes $q$ of individual trades, we further\nintroduce two $q$-dependent exponents, which allows us to account for the way\nthe moments of generalized volume imbalance and the correlation between price\nchanges and generalized order flow imbalance scales with $T$. We predict in\nparticular that the corresponding power-laws depend in a non-monotonic fashion\non a parameter $a$ that allows one to put the same weight on all child orders\nor overweight large orders, a behaviour clearly borne out by empirical data. We\nalso predict that the correlation between price changes and volume imbalances\nshould display a maximum as a function of $a$, which again matches\nobservations. Such noteworthy agreement between theory and data suggests that\nour framework correctly captures the basic mechanism at the heart of price\nformation, namely the average impact of metaorders. We argue that our results\nsupport the ''Order-Driven'' theory of excess volatility, and are at odds with\nthe idea that a ''Fundamental'' component accounts for a large share of the\nvolatility of financial markets.", "published": "2025-06-09 12:53:25", "link": "http://arxiv.org/abs/2506.07711v3", "categories": ["q-fin.TR", "q-fin.ST"], "primary_category": "q-fin.TR"}
{"title": "Towards Energy-Efficient and Low-Latency Voice-Controlled Smart Homes: A Proposal for Offline Speech Recognition and IoT Integration", "abstract": "The smart home systems, based on AI speech recognition and IoT technology,\nenable people to control devices through verbal commands and make people's\nlives more efficient. However, existing AI speech recognition services are\nprimarily deployed on cloud platforms on the Internet. When users issue a\ncommand, speech recognition devices like ``Amazon Echo'' will post a recording\nthrough numerous network nodes, reach multiple servers, and then receive\nresponses through the Internet. This mechanism presents several issues,\nincluding unnecessary energy consumption, communication latency, and the risk\nof a single-point failure. In this position paper, we propose a smart home\nconcept based on offline speech recognition and IoT technology: 1) integrating\noffline keyword spotting (KWS) technologies into household appliances with\nlimited resource hardware to enable them to understand user voice commands; 2)\ndesigning a local IoT network with decentralized architecture to manage and\nconnect various devices, enhancing the robustness and scalability of the\nsystem. This proposal of a smart home based on offline speech recognition and\nIoT technology will allow users to use low-latency voice control anywhere in\nthe home without depending on the Internet and provide better scalability and\nenergy sustainability.", "published": "2025-06-09 07:15:48", "link": "http://arxiv.org/abs/2506.07494v2", "categories": ["cs.SD", "cs.CY", "eess.AS"], "primary_category": "cs.SD"}
{"title": "An introduction to pitch strength in contemporary popular music analysis and production", "abstract": "Music information retrieval distinguishes between low- and high-level\ndescriptions of music. Current generative AI models rely on text descriptions\nthat are higher level than the controls familiar to studio musicians. Pitch\nstrength, a low-level perceptual parameter of contemporary popular music, may\nbe one feature that could make such AI models more suited to music production.\nSignal and perceptual analyses suggest that pitch strength (1) varies\nsignificantly across and inside songs; (2) contributes to both small- and\nlarge-scale structure; (3) contributes to the handling of polyphonic\ndissonance; and (4) may be a feature of upper harmonics made audible in a\nperspective of perceptual richness.", "published": "2025-06-09 06:47:26", "link": "http://arxiv.org/abs/2506.07473v3", "categories": ["cs.SD", "eess.AS", "00A65", "J.5"], "primary_category": "cs.SD"}
{"title": "Centrality Change Proneness: an Early Indicator of Microservice Architectural Degradation", "abstract": "Over the past decade, the wide adoption of Microservice Architecture has\nrequired the identification of various patterns and anti-patterns to prevent\nMicroservice Architectural Degradation. Frequently, the systems are modelled as\na network of connected services. Recently, the study of temporal networks has\nemerged as a way to describe and analyze evolving networks. Previous research\nhas explored how software metrics such as size, complexity, and quality are\nrelated to microservice centrality in the architectural network. This study\ninvestigates whether temporal centrality metrics can provide insight into the\nearly detection of architectural degradation by correlating or affecting\nsoftware metrics. We reconstructed the architecture of 7 releases of an OSS\nmicroservice project with 42 services. For every service in every release, we\ncomputed the software and centrality metrics. From one of the latter, we\nderived a new metric, Centrality Change Proneness. We then explored the\ncorrelation between the metrics. We identified 7 size and 5 complexity metrics\nthat have a consistent correlation with centrality, while Centrality Change\nProneness did not affect the software metrics, thus providing yet another\nperspective and an early indicator of microservice architectural degradation.", "published": "2025-06-09 12:22:12", "link": "http://arxiv.org/abs/2506.07690v2", "categories": ["cs.SE", "cs.DM", "cs.NA", "math.NA"], "primary_category": "cs.SE"}
{"title": "Leveraging Network Methods for Hub-like Microservice Detection", "abstract": "Context: Microservice Architecture is a popular architectural paradigm that\nfacilitates flexibility by decomposing applications into small, independently\ndeployable services. Catalogs of architectural anti-patterns have been proposed\nto highlight the negative aspects of flawed microservice design. In particular,\nthe Hub-like anti-pattern lacks an unambiguous definition and detection method.\nAim: In this work, we aim to find a robust detection approach for the Hub-like\nmicroservice anti-pattern that outputs a reasonable number of Hub-like\ncandidates with high precision. Method: We leveraged a dataset of 25\nmicroservice networks and several network hub detection techniques to identify\nthe Hub-like anti-pattern, namely scale-free property, centrality metrics and\nclustering coefficient, minimum description length principle, and the approach\nbehind the Arcan tool. Results and Conclusion: Our findings revealed that the\nstudied architectural networks are not scale-free, that most considered hub\ndetection approaches do not agree on the detected hubs, and that the method by\nKirkley leveraging the Erdos-Renyi encoding is the most accurate one in terms\nof the number of detected hubs and the detection precision. Investigating\nfurther the applicability of these methods to detecting Hub-like components in\nmicroservice-based and other systems opens up new research directions.\nMoreover, our results provide an evaluation of the approach utilized by the\nwidely used Arcan tool and highlight the potential to update the tool to use\nthe normalized degree centrality of a component in the network, or for the\napproach based on ER encoding to be adopted instead.", "published": "2025-06-09 12:13:49", "link": "http://arxiv.org/abs/2506.07683v2", "categories": ["cs.SE", "cs.DM"], "primary_category": "cs.SE"}
{"title": "The Impact of Feature Scaling In Machine Learning: Effects on Regression and Classification Tasks", "abstract": "This research addresses the critical lack of comprehensive studies on feature\nscaling by systematically evaluating 12 scaling techniques - including several\nless common transformations - across 14 different Machine Learning algorithms\nand 16 datasets for classification and regression tasks. We meticulously\nanalyzed impacts on predictive performance (using metrics such as accuracy,\nMAE, MSE, and $R^2$) and computational costs (training time, inference time,\nand memory usage). Key findings reveal that while ensemble methods (such as\nRandom Forest and gradient boosting models like XGBoost, CatBoost and LightGBM)\ndemonstrate robust performance largely independent of scaling, other widely\nused models such as Logistic Regression, SVMs, TabNet, and MLPs show\nsignificant performance variations highly dependent on the chosen scaler. This\nextensive empirical analysis, with all source code, experimental results, and\nmodel parameters made publicly available to ensure complete transparency and\nreproducibility, offers model-specific crucial guidance to practitioners on the\nneed for an optimal selection of feature scaling techniques.", "published": "2025-06-09 22:32:51", "link": "http://arxiv.org/abs/2506.08274v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Towards a Unified Benchmark for Arabic Pronunciation Assessment: Quranic Recitation as Case Study", "abstract": "We present a unified benchmark for mispronunciation detection in Modern\nStandard Arabic (MSA) using Qur'anic recitation as a case study. Our approach\nlays the groundwork for advancing Arabic pronunciation assessment by providing\na comprehensive pipeline that spans data processing, the development of a\nspecialized phoneme set tailored to the nuances of MSA pronunciation, and the\ncreation of the first publicly available test set for this task, which we term\nas the Qur'anic Mispronunciation Benchmark (QuranMB.v1). Furthermore, we\nevaluate several baseline models to provide initial performance insights,\nthereby highlighting both the promise and the challenges inherent in assessing\nMSA pronunciation. By establishing this standardized framework, we aim to\nfoster further research and development in pronunciation assessment in Arabic\nlanguage technology and related applications.", "published": "2025-06-09 13:05:03", "link": "http://arxiv.org/abs/2506.07722v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ScIRGen: Synthesize Realistic and Large-Scale RAG Dataset for Scientific Research", "abstract": "Scientific researchers need intensive information about datasets to\neffectively evaluate and develop theories and methodologies. The information\nneeds regarding datasets are implicitly embedded in particular research tasks,\nrather than explicitly expressed in search queries. However, existing\nscientific retrieval and question-answering (QA) datasets typically address\nstraightforward questions, which do not align with the distribution of\nreal-world research inquiries. To bridge this gap, we developed ScIRGen, a\ndataset generation framework for scientific QA \\& retrieval that more\naccurately reflects the information needs of professional science researchers,\nand uses it to create a large-scale scientific retrieval-augmented generation\n(RAG) dataset with realistic queries, datasets and papers. Technically, we\ndesigned a dataset-oriented information extraction method that leverages\nacademic papers to augment the dataset representation. We then proposed a\nquestion generation framework by employing cognitive taxonomy to ensure the\nquality of synthesized questions. We also design a method to automatically\nfilter synthetic answers based on the perplexity shift of LLMs, which is highly\naligned with human judgment of answers' validity. Collectively, these\nmethodologies culminated in the creation of the 61k QA dataset, ScIRGen-Geo. We\nbenchmarked representative methods on the ScIRGen-Geo dataset for their\nquestion-answering and retrieval capabilities, finding out that current methods\nstill suffer from reasoning from complex questions. This work advances the\ndevelopment of more sophisticated tools to support the intricate information\nneeds of the scientific community.", "published": "2025-06-09 11:47:13", "link": "http://arxiv.org/abs/2506.11117v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Agent Semantics, Semantic Spacetime, and Graphical Reasoning", "abstract": "Some formal aspects of the Semantic Spacetime graph model are presented, with\nreference to its use for directed knowledge representations and process\nmodelling. A finite $\\gamma(3,4)$ representation is defined to form a closed\nset of operations that can scale to any degree of semantic complexity. The\nSemantic Spacetime postulates bring predictability with minimal constraints to\npathways in graphs. The ubiquitous appearance of absorbing states in any\npartial graph means that a graph process leaks information. The issue is\nclosely associated with the issue of division by zero, which signals a loss of\nclosure and the need for manual injection of remedial information. The Semantic\nSpacetime model (and its Promise Theory) origins help to clarify how such\nabsorbing states are associated with boundary information where intentionality\ncan enter.", "published": "2025-06-09 13:37:47", "link": "http://arxiv.org/abs/2506.07756v2", "categories": ["cs.AI", "cs.LG", "cs.MA", "I.2.11; F.4.1; I.2.4; G.2.2"], "primary_category": "cs.AI"}
{"title": "Benchmarking Foundation Speech and Language Models for Alzheimer's Disease and Related Dementia Detection from Spontaneous Speech", "abstract": "Background: Alzheimer's disease and related dementias (ADRD) are progressive\nneurodegenerative conditions where early detection is vital for timely\nintervention and care. Spontaneous speech contains rich acoustic and linguistic\nmarkers that may serve as non-invasive biomarkers for cognitive decline.\nFoundation models, pre-trained on large-scale audio or text data, produce\nhigh-dimensional embeddings encoding contextual and acoustic features.\n  Methods: We used the PREPARE Challenge dataset, which includes audio\nrecordings from over 1,600 participants with three cognitive statuses: healthy\ncontrol (HC), mild cognitive impairment (MCI), and Alzheimer's Disease (AD). We\nexcluded non-English, non-spontaneous, or poor-quality recordings. The final\ndataset included 703 (59.13%) HC, 81 (6.81%) MCI, and 405 (34.06%) AD cases. We\nbenchmarked a range of open-source foundation speech and language models to\nclassify cognitive status into the three categories.\n  Results: The Whisper-medium model achieved the highest performance among\nspeech models (accuracy = 0.731, AUC = 0.802). Among language models, BERT with\npause annotation performed best (accuracy = 0.662, AUC = 0.744). ADRD detection\nusing state-of-the-art automatic speech recognition (ASR) model-generated audio\nembeddings outperformed others. Including non-semantic features like pause\npatterns consistently improved text-based classification.\n  Conclusion: This study introduces a benchmarking framework using foundation\nmodels and a clinically relevant dataset. Acoustic-based approaches --\nparticularly ASR-derived embeddings -- demonstrate strong potential for\nscalable, non-invasive, and cost-effective early detection of ADRD.", "published": "2025-06-09 17:52:31", "link": "http://arxiv.org/abs/2506.11119v1", "categories": ["cs.CL", "cs.SD", "eess.AS", "68T10 (Primary), 68U99 (Secondary)", "I.2.1; J.3"], "primary_category": "cs.CL"}
