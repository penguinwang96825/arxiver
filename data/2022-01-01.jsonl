{"title": "Zero-shot Commonsense Question Answering with Cloze Translation and\n  Consistency Optimization", "abstract": "Commonsense question answering (CQA) aims to test if models can answer\nquestions regarding commonsense knowledge that everyone knows. Prior works that\nincorporate external knowledge bases have shown promising results, but\nknowledge bases are expensive to construct and are often limited to a fixed set\nof relations. In this paper, we instead focus on better utilizing the\n\\textit{implicit knowledge} stored in pre-trained language models. While\nresearchers have found that the knowledge embedded in pre-trained language\nmodels can be extracted by having them fill in the blanks of carefully designed\nprompts for relation extraction and text classification, it remains unclear if\nwe can adopt this paradigm in CQA where the inputs and outputs take much more\nflexible forms. To this end, we investigate four translation methods that can\ntranslate natural questions into cloze-style sentences to better solicit\ncommonsense knowledge from language models, including a syntactic-based model,\nan unsupervised neural model, and two supervised neural models. In addition, to\ncombine the different translation methods, we propose to encourage consistency\namong model predictions on different translated questions with unlabeled data.\nWe demonstrate the effectiveness of our methods on three CQA datasets in\nzero-shot settings. We show that our methods are complementary to a knowledge\nbase improved model, and combining them can lead to state-of-the-art zero-shot\nperformance. Analyses also reveal distinct characteristics of the different\ncloze translation methods and provide insights on why combining them can lead\nto great improvements.", "published": "2022-01-01 07:12:49", "link": "http://arxiv.org/abs/2201.00136v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Challenges of sampling and how phylogenetic comparative methods help:\n  With a case study of the Pama-Nyungan laminal contrast", "abstract": "Phylogenetic comparative methods are new in our field and are shrouded, for\nmost linguists, in at least a little mystery. Yet the path that led to their\ndiscovery in comparative biology is so similar to the methodological history of\nbalanced sampling, that it is only an accident of history that they were not\ndiscovered by a typologist. Here we clarify the essential logic behind\nphylogenetic comparative methods and their fundamental relatedness to a deep\nintellectual tradition focussed on sampling. Then we introduce concepts,\nmethods and tools which will enable typologists to use these methods in\neveryday typological research. The key commonality of phylogenetic comparative\nmethods and balanced sampling is that they attempt to deal with statistical\nnon-independence due to genealogy. Whereas sampling can never achieve\nindependence and requires most comparative data to be discarded, phylogenetic\ncomparative methods achieve independence while retaining and using all data. We\ndiscuss the essential notions of phylogenetic signal; uncertainty about trees;\ntypological averages and proportions that are sensitive to genealogy;\ncomparison across language families; and the effects of areality. Extensive\nsupplementary materials illustrate computational tools for practical analysis\nand we illustrate the methods discussed with a typological case study of the\nlaminal contrast in Pama-Nyungan.", "published": "2022-01-01 14:33:20", "link": "http://arxiv.org/abs/2201.00195v1", "categories": ["q-bio.PE", "cs.CL", "91F20", "J.5"], "primary_category": "q-bio.PE"}
{"title": "Automated Fake News Detection using cross-checking with reliable sources", "abstract": "Over the past decade, fake news and misinformation have turned into a major\nproblem that has impacted different aspects of our lives, including politics\nand public health. Inspired by natural human behavior, we present an approach\nthat automates the detection of fake news. Natural human behavior is to\ncross-check new information with reliable sources. We use Natural Language\nProcessing (NLP) and build a machine learning (ML) model that automates the\nprocess of cross-checking new information with a set of predefined reliable\nsources. We implement this for Twitter and build a model that flags fake\ntweets. Specifically, for a given tweet, we use its text to find relevant news\nfrom reliable news agencies. We then train a Random Forest model that checks if\nthe textual content of the tweet is aligned with the trusted news. If it is\nnot, the tweet is classified as fake. This approach can be generally applied to\nany kind of information and is not limited to a specific news story or a\ncategory of information. Our implementation of this approach gives a $70\\%$\naccuracy which outperforms other generic fake-news classification models. These\nresults pave the way towards a more sensible and natural approach to fake news\ndetection.", "published": "2022-01-01 00:59:58", "link": "http://arxiv.org/abs/2201.00083v1", "categories": ["cs.CL", "cs.SI", "physics.soc-ph"], "primary_category": "cs.CL"}
{"title": "Semantic Search for Large Scale Clinical Ontologies", "abstract": "Finding concepts in large clinical ontologies can be challenging when queries\nuse different vocabularies. A search algorithm that overcomes this problem is\nuseful in applications such as concept normalisation and ontology matching,\nwhere concepts can be referred to in different ways, using different synonyms.\nIn this paper, we present a deep learning based approach to build a semantic\nsearch system for large clinical ontologies. We propose a Triplet-BERT model\nand a method that generates training data directly from the ontologies. The\nmodel is evaluated using five real benchmark data sets and the results show\nthat our approach achieves high results on both free text to concept and\nconcept to concept searching tasks, and outperforms all baseline methods.", "published": "2022-01-01 05:15:42", "link": "http://arxiv.org/abs/2201.00118v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Bird Species Classification And Acoustic Features Selection Based on\n  Distributed Neural Network with Two Stage Windowing of Short-Term Features", "abstract": "Identification of bird species from audio records is one of the challenging\ntasks due to the existence of multiple species in the same recording, noise in\nthe background, and long-term recording. Besides, choosing a proper acoustic\nfeature from audio recording for bird species classification is another\nproblem. In this paper, a hybrid method is represented comprising both\ntraditional signal processing and a deep learning-based approach to classify\nbird species from audio recordings of diverse sources and types. Besides, a\ndetailed study with 34 different features helps to select the proper feature\nset for classification and analysis in real-time applications. Moreover, the\nproposed deep neural network uses both acoustic and temporal feature learning.\nThe proposed method starts with detecting voice activity from the raw signal,\nfollowed by extracting short-term features from the processed recording using\n50 ms (with 25ms overlapping) time windows. Later, the short-term features are\nreshaped using second stage (non-overlapping) windowing to be trained through a\ndistributed 2D Convolutional Neural Network (CNN) that forwards the output\nfeatures to a Long and Short Term Memory (LSTM) Network. Then a final dense\nlayer classifies the bird species. For the 10 class classifier, the highest\naccuracy achieved was 90.45\\% for a feature set consisting of 13 Mel Frequency\nCepstral Coefficients (MFCCs) and 12 Chroma Vectors. The corresponding\nspecificity and AUC scores are 98.94\\% and 94.09\\%, respectively.", "published": "2022-01-01 05:42:20", "link": "http://arxiv.org/abs/2201.00124v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Generating Adversarial Samples For Training Wake-up Word Detection\n  Systems Against Confusing Words", "abstract": "Wake-up word detection models are widely used in real life, but suffer from\nsevere performance degradation when encountering adversarial samples. In this\npaper we discuss the concept of confusing words in adversarial samples.\nConfusing words are commonly encountered, which are various kinds of words that\nsound similar to the predefined keywords. To enhance the wake word detection\nsystem's robustness against confusing words, we propose several methods to\ngenerate the adversarial confusing samples for simulating real confusing words\nscenarios in which we usually do not have any real confusing samples in the\ntraining set. The generated samples include concatenated audio, synthesized\ndata, and partially masked keywords. Moreover, we use a domain embedding\nconcatenated system to improve the performance. Experimental results show that\nthe adversarial samples generated in our approach help improve the system's\nrobustness in both the common scenario and the confusing words scenario. In\naddition, we release the confusing words testing database called HI-MIA-CW for\nfuture research.", "published": "2022-01-01 11:01:43", "link": "http://arxiv.org/abs/2201.00167v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
