{"title": "Dynamic Hedging Strategies in Derivatives Markets with LLM-Driven Sentiment and News Analytics", "abstract": "Dynamic hedging strategies are essential for effective risk management in\nderivatives markets, where volatility and market sentiment can greatly impact\nperformance. This paper introduces a novel framework that leverages large\nlanguage models (LLMs) for sentiment analysis and news analytics to inform\nhedging decisions. By analyzing textual data from diverse sources like news\narticles, social media, and financial reports, our approach captures critical\nsentiment indicators that reflect current market conditions. The framework\nallows for real-time adjustments to hedging strategies, adapting positions\nbased on continuous sentiment signals. Backtesting results on historical\nderivatives data reveal that our dynamic hedging strategies achieve superior\nrisk-adjusted returns compared to conventional static approaches. The\nincorporation of LLM-driven sentiment analysis into hedging practices presents\na significant advancement in decision-making processes within derivatives\ntrading. This research showcases how sentiment-informed dynamic hedging can\nenhance portfolio management and effectively mitigate associated risks.", "published": "2025-04-05 22:35:06", "link": "http://arxiv.org/abs/2504.04295v1", "categories": ["cs.CL", "cs.CE"], "primary_category": "cs.CL"}
{"title": "Cross-Asset Risk Management: Integrating LLMs for Real-Time Monitoring of Equity, Fixed Income, and Currency Markets", "abstract": "Large language models (LLMs) have emerged as powerful tools in the field of\nfinance, particularly for risk management across different asset classes. In\nthis work, we introduce a Cross-Asset Risk Management framework that utilizes\nLLMs to facilitate real-time monitoring of equity, fixed income, and currency\nmarkets. This innovative approach enables dynamic risk assessment by\naggregating diverse data sources, ultimately enhancing decision-making\nprocesses. Our model effectively synthesizes and analyzes market signals to\nidentify potential risks and opportunities while providing a holistic view of\nasset classes. By employing advanced analytics, we leverage LLMs to interpret\nfinancial texts, news articles, and market reports, ensuring that risks are\ncontextualized within broader market narratives. Extensive backtesting and\nreal-time simulations validate the framework, showing increased accuracy in\npredicting market shifts compared to conventional methods. The focus on\nreal-time data integration enhances responsiveness, allowing financial\ninstitutions to manage risks adeptly under varying market conditions and\npromoting financial stability through the advanced application of LLMs in risk\nanalysis.", "published": "2025-04-05 22:28:35", "link": "http://arxiv.org/abs/2504.04292v1", "categories": ["cs.CL", "cs.CE"], "primary_category": "cs.CL"}
{"title": "Could AI Trace and Explain the Origins of AI-Generated Images and Text?", "abstract": "AI-generated content is becoming increasingly prevalent in the real world,\nleading to serious ethical and societal concerns. For instance, adversaries\nmight exploit large multimodal models (LMMs) to create images that violate\nethical or legal standards, while paper reviewers may misuse large language\nmodels (LLMs) to generate reviews without genuine intellectual effort. While\nprior work has explored detecting AI-generated images and texts, and\noccasionally tracing their source models, there is a lack of a systematic and\nfine-grained comparative study. Important dimensions--such as AI-generated\nimages vs. text, fully vs. partially AI-generated images, and general vs.\nmalicious use cases--remain underexplored. Furthermore, whether AI systems like\nGPT-4o can explain why certain forged content is attributed to specific\ngenerative models is still an open question, with no existing benchmark\naddressing this. To fill this gap, we introduce AI-FAKER, a comprehensive\nmultimodal dataset with over 280,000 samples spanning multiple LLMs and LMMs,\ncovering both general and malicious use cases for AI-generated images and\ntexts. Our experiments reveal two key findings: (i) AI authorship detection\ndepends not only on the generated output but also on the model's original\ntraining intent; and (ii) GPT-4o provides highly consistent but less specific\nexplanations when analyzing content produced by OpenAI's own models, such as\nDALL-E and GPT-4o itself.", "published": "2025-04-05 20:51:54", "link": "http://arxiv.org/abs/2504.04279v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond the Hype: Embeddings vs. Prompting for Multiclass Classification Tasks", "abstract": "Are traditional classification approaches irrelevant in this era of AI hype?\nWe show that there are multiclass classification problems where predictive\nmodels holistically outperform LLM prompt-based frameworks. Given text and\nimages from home-service project descriptions provided by Thumbtack customers,\nwe build embeddings-based softmax models that predict the professional category\n(e.g., handyman, bathroom remodeling) associated with each problem description.\nWe then compare against prompts that ask state-of-the-art LLM models to solve\nthe same problem. We find that the embeddings approach outperforms the best LLM\nprompts in terms of accuracy, calibration, latency, and financial cost. In\nparticular, the embeddings approach has 49.5% higher accuracy than the\nprompting approach, and its superiority is consistent across text-only,\nimage-only, and text-image problem descriptions. Furthermore, it yields\nwell-calibrated probabilities, which we later use as confidence signals to\nprovide contextualized user experience during deployment. On the contrary,\nprompting scores are overly uninformative. Finally, the embeddings approach is\n14 and 81 times faster than prompting in processing images and text\nrespectively, while under realistic deployment assumptions, it can be up to 10\ntimes cheaper. Based on these results, we deployed a variation of the\nembeddings approach, and through A/B testing we observed performance consistent\nwith our offline analysis. Our study shows that for multiclass classification\nproblems that can leverage proprietary datasets, an embeddings-based approach\nmay yield unequivocally better results. Hence, scientists, practitioners,\nengineers, and business leaders can use our study to go beyond the hype and\nconsider appropriate predictive models for their classification use cases.", "published": "2025-04-05 20:35:54", "link": "http://arxiv.org/abs/2504.04277v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.AP"], "primary_category": "cs.LG"}
{"title": "negativas: a prototype for searching and classifying sentential negation in speech data", "abstract": "Negation is a universal feature of natural languages. In Brazilian\nPortuguese, the most commonly used negation particle is n\\~ao, which can scope\nover nouns or verbs. When it scopes over a verb, n\\~ao can occur in three\npositions: pre-verbal (NEG1), double negation (NEG2), or post-verbal (NEG3),\ne.g., n\\~ao gosto, n\\~ao gosto n\\~ao, gosto n\\~ao (\"I do not like it\"). From a\nvariationist perspective, these structures are different forms of expressing\nnegation. Pragmatically, they serve distinct communicative functions, such as\npoliteness and modal evaluation. Despite their grammatical acceptability, these\nforms differ in frequency. NEG1 dominates across Brazilian regions, while NEG2\nand NEG3 appear more rarely, suggesting its use is contextually restricted.\nThis low-frequency challenges research, often resulting in subjective,\nnon-generalizable interpretations of verbal negation with n\\~ao. To address\nthis, we developed negativas, a tool for automatically identifying NEG1, NEG2,\nand NEG3 in transcribed data. The tool's development involved four stages: i)\nanalyzing a dataset of 22 interviews from the Falares Sergipanos database,\nannotated by three linguists, ii) creating a code using natural language\nprocessing (NLP) techniques, iii) running the tool, iv) evaluating accuracy.\nInter-annotator consistency, measured using Fleiss' Kappa, was moderate (0.57).\nThe tool identified 3,338 instances of n\\~ao, classifying 2,085 as NEG1, NEG2,\nor NEG3, achieving a 93% success rate. However, negativas has limitations. NEG1\naccounted for 91.5% of identified structures, while NEG2 and NEG3 represented\n7.2% and 1.2%, respectively. The tool struggled with NEG2, sometimes\nmisclassifying instances as overlapping structures (NEG1/NEG2/NEG3).", "published": "2025-04-05 20:09:04", "link": "http://arxiv.org/abs/2504.04275v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lost in Multilinguality: Dissecting Cross-lingual Factual Inconsistency in Transformer Language Models", "abstract": "Multilingual language models (MLMs) store factual knowledge across languages\nbut often struggle to provide consistent responses to semantically equivalent\nprompts in different languages. While previous studies point out this\ncross-lingual inconsistency issue, the underlying causes remain unexplored. In\nthis work, we use mechanistic interpretability methods to investigate\ncross-lingual inconsistencies in MLMs. We find that MLMs encode knowledge in a\nlanguage-independent concept space through most layers, and only transition to\nlanguage-specific spaces in the final layers. Failures during the language\ntransition often result in incorrect predictions in the target language, even\nwhen the answers are correct in other languages. To mitigate this inconsistency\nissue, we propose a linear shortcut method that bypasses computations in the\nfinal layers, enhancing both prediction accuracy and cross-lingual consistency.\nOur findings shed light on the internal mechanisms of MLMs and provide a\nlightweight, effective strategy for producing more consistent factual outputs.", "published": "2025-04-05 19:43:10", "link": "http://arxiv.org/abs/2504.04264v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sensitivity Meets Sparsity: The Impact of Extremely Sparse Parameter Patterns on Theory-of-Mind of Large Language Models", "abstract": "This paper investigates the emergence of Theory-of-Mind (ToM) capabilities in\nlarge language models (LLMs) from a mechanistic perspective, focusing on the\nrole of extremely sparse parameter patterns. We introduce a novel method to\nidentify ToM-sensitive parameters and reveal that perturbing as little as\n0.001% of these parameters significantly degrades ToM performance while also\nimpairing contextual localization and language understanding. To understand\nthis effect, we analyze their interaction with core architectural components of\nLLMs. Our findings demonstrate that these sensitive parameters are closely\nlinked to the positional encoding module, particularly in models using Rotary\nPosition Embedding (RoPE), where perturbations disrupt dominant-frequency\nactivations critical for contextual processing. Furthermore, we show that\nperturbing ToM-sensitive parameters affects LLM's attention mechanism by\nmodulating the angle between queries and keys under positional encoding. These\ninsights provide a deeper understanding of how LLMs acquire social reasoning\nabilities, bridging AI interpretability with cognitive science. Our results\nhave implications for enhancing model alignment, mitigating biases, and\nimproving AI systems designed for human interaction.", "published": "2025-04-05 17:45:42", "link": "http://arxiv.org/abs/2504.04238v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Perplexity and Menger Curvature-Based Approach for Similarity Evaluation of Large Language Models", "abstract": "The rise of Large Language Models (LLMs) has brought about concerns regarding\ncopyright infringement and unethical practices in data and model usage. For\ninstance, slight modifications to existing LLMs may be used to falsely claim\nthe development of new models, leading to issues of model copying and\nviolations of ownership rights. This paper addresses these challenges by\nintroducing a novel metric for quantifying LLM similarity, which leverages\nperplexity curves and differences in Menger curvature. Comprehensive\nexperiments validate the performance of our methodology, demonstrating its\nsuperiority over baseline methods and its ability to generalize across diverse\nmodels and domains. Furthermore, we highlight the capability of our approach in\ndetecting model replication through simulations, emphasizing its potential to\npreserve the originality and integrity of LLMs. Code is available at\nhttps://github.com/zyttt-coder/LLM_similarity.", "published": "2025-04-05 16:04:25", "link": "http://arxiv.org/abs/2504.04216v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Understanding and Improving Refusal in Compressed Models via Mechanistic Interpretability", "abstract": "The rapid growth of large language models has spurred significant interest in\nmodel compression as a means to enhance their accessibility and practicality.\nWhile extensive research has explored model compression through the lens of\nsafety, findings suggest that safety-aligned models often lose elements of\ntrustworthiness post-compression. Simultaneously, the field of mechanistic\ninterpretability has gained traction, with notable discoveries, such as the\nidentification of a single direction in the residual stream mediating refusal\nbehaviors across diverse model architectures. In this work, we investigate the\nsafety of compressed models by examining the mechanisms of refusal, adopting a\nnovel interpretability-driven perspective to evaluate model safety.\nFurthermore, leveraging insights from our interpretability analysis, we propose\na lightweight, computationally efficient method to enhance the safety of\ncompressed models without compromising their performance or utility.", "published": "2025-04-05 16:00:44", "link": "http://arxiv.org/abs/2504.04215v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Adaptive Elicitation of Latent Information Using Natural Language", "abstract": "Eliciting information to reduce uncertainty about a latent entity is a\ncritical task in many application domains, e.g., assessing individual student\nlearning outcomes, diagnosing underlying diseases, or learning user\npreferences. Though natural language is a powerful medium for this purpose,\nlarge language models (LLMs) and existing fine-tuning algorithms lack\nmechanisms for strategically gathering information to refine their own\nunderstanding of the latent entity. To harness the generalization power and\nworld knowledge of LLMs in developing effective information-gathering\nstrategies, we propose an adaptive elicitation framework that actively reduces\nuncertainty on the latent entity. Since probabilistic modeling of an abstract\nlatent entity is difficult, our framework adopts a predictive view of\nuncertainty, using a meta-learned language model to simulate future\nobservations and enable scalable uncertainty quantification over complex\nnatural language. Through autoregressive forward simulation, our model\nquantifies how new questions reduce epistemic uncertainty, enabling the\ndevelopment of sophisticated information-gathering strategies to choose the\nmost informative next queries. In experiments on the 20 questions game, dynamic\nopinion polling, and adaptive student assessment, our method consistently\noutperforms baselines in identifying critical unknowns and improving downstream\npredictions, illustrating the promise of strategic information gathering in\nnatural language settings.", "published": "2025-04-05 15:18:55", "link": "http://arxiv.org/abs/2504.04204v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GlotEval: A Test Suite for Massively Multilingual Evaluation of Large Language Models", "abstract": "Large language models (LLMs) are advancing at an unprecedented pace globally,\nwith regions increasingly adopting these models for applications in their\nprimary language. Evaluation of these models in diverse linguistic\nenvironments, especially in low-resource languages, has become a major\nchallenge for academia and industry. Existing evaluation frameworks are\ndisproportionately focused on English and a handful of high-resource languages,\nthereby overlooking the realistic performance of LLMs in multilingual and\nlower-resource scenarios. To address this gap, we introduce GlotEval, a\nlightweight framework designed for massively multilingual evaluation.\nSupporting seven key tasks (machine translation, text classification,\nsummarization, open-ended generation, reading comprehension, sequence labeling,\nand intrinsic evaluation), spanning over dozens to hundreds of languages,\nGlotEval highlights consistent multilingual benchmarking, language-specific\nprompt templates, and non-English-centric machine translation. This enables a\nprecise diagnosis of model strengths and weaknesses in diverse linguistic\ncontexts. A multilingual translation case study demonstrates GlotEval's\napplicability for multilingual and language-specific evaluations.", "published": "2025-04-05 12:30:58", "link": "http://arxiv.org/abs/2504.04155v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rethinking Multilingual Continual Pretraining: Data Mixing for Adapting LLMs Across Languages and Resources", "abstract": "Large Language Models (LLMs) exhibit significant disparities in performance\nacross languages, primarily benefiting high-resource languages while\nmarginalizing underrepresented ones. Continual Pretraining (CPT) has emerged as\na promising approach to address this imbalance, although the relative\neffectiveness of monolingual, bilingual, and code-augmented data strategies\nremains unclear. This study systematically evaluates 36 CPT configurations\ninvolving three multilingual base models, across 30+ languages categorized as\naltruistic, selfish, and stagnant, spanning various resource levels. Our\nfindings reveal three major insights: (1) Bilingual CPT improves multilingual\nclassification but often causes language mixing issues during generation. (2)\nIncluding programming code data during CPT consistently enhances multilingual\nclassification accuracy, particularly benefiting low-resource languages, but\nintroduces a trade-off by slightly degrading generation quality. (3) Contrary\nto prior work, we observe substantial deviations from language classifications\naccording to their impact on cross-lingual transfer: Languages classified as\naltruistic often negatively affect related languages, selfish languages show\nconditional and configuration-dependent behavior, and stagnant languages\ndemonstrate surprising adaptability under certain CPT conditions. These nuanced\ninteractions emphasize the complexity of multilingual representation learning,\nunderscoring the importance of systematic studies on generalizable language\nclassification to inform future multilingual CPT strategies.", "published": "2025-04-05 12:10:55", "link": "http://arxiv.org/abs/2504.04152v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "STEP: Staged Parameter-Efficient Pre-training for Large Language Models", "abstract": "Pre-training large language models (LLMs) faces significant memory challenges\ndue to the large size of model parameters. We introduce STaged\nparameter-Efficient Pre-training (STEP), which integrates parameter-efficient\ntuning techniques with model growth. We conduct experiments on pre-training\nLLMs of various sizes and demonstrate that STEP achieves up to a 53.9%\nreduction in maximum memory requirements compared to vanilla pre-training while\nmaintaining equivalent performance. Furthermore, we show that the model by STEP\nperforms comparably to vanilla pre-trained models on downstream tasks after\ninstruction tuning.", "published": "2025-04-05 12:07:08", "link": "http://arxiv.org/abs/2504.04151v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reasoning on Multiple Needles In A Haystack", "abstract": "The Needle In A Haystack (NIAH) task has been widely used to evaluate the\nlong-context question-answering capabilities of Large Language Models (LLMs).\nHowever, its reliance on simple retrieval limits its effectiveness. To address\nthis limitation, recent studies have introduced the Multiple Needles In A\nHaystack Reasoning (MNIAH-R) task, which incorporates supporting documents\n(Multiple needles) of multi-hop reasoning tasks into a distracting context\n(Haystack}). Despite this advancement, existing approaches still fail to\naddress the issue of models providing direct answers from internal knowledge,\nand they do not explain or mitigate the decline in accuracy as context length\nincreases. In this paper, we tackle the memory-based answering problem by\nfiltering out direct-answer questions, and we reveal that performance\ndegradation is primarily driven by the reduction in the length of the thinking\nprocess as the input length increases. Building on this insight, we decompose\nthe thinking process into retrieval and reasoning stages and introduce a\nreflection mechanism for multi-round extension. We also train a model using the\ngenerated iterative thinking process, which helps mitigate the performance\ndegradation. Furthermore, we demonstrate the application of this\nretrieval-reflection capability in mathematical reasoning scenarios, improving\nGPT-4o's performance on AIME2024.", "published": "2025-04-05 11:58:08", "link": "http://arxiv.org/abs/2504.04150v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "My Life in Artificial Intelligence: People, anecdotes, and some lessons learnt", "abstract": "In this very personal workography, I relate my 40-year experiences as a\nresearcher and educator in and around Artificial Intelligence (AI), more\nspecifically Natural Language Processing. I describe how curiosity, and the\ncircumstances of the day, led me to work in both industry and academia, and in\nvarious countries, including The Netherlands (Amsterdam, Eindhoven, and\nUtrecht), the USA (Stanford), England (Brighton), Scotland (Aberdeen), and\nChina (Beijing and Harbin). People and anecdotes play a large role in my story;\nthe history of AI forms its backdrop. I focus on things that might be of\ninterest to (even) younger colleagues, given the choices they face in their own\nwork and life at a time when AI is finally emerging from the shadows.", "published": "2025-04-05 11:26:48", "link": "http://arxiv.org/abs/2504.04142v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Cognitive Debiasing Large Language Models for Decision-Making", "abstract": "Large language models (LLMs) have shown potential in supporting\ndecision-making applications, particularly as personal conversational\nassistants in the financial, healthcare, and legal domains. While prompt\nengineering strategies have enhanced the capabilities of LLMs in\ndecision-making, cognitive biases inherent to LLMs present significant\nchallenges. Cognitive biases are systematic patterns of deviation from norms or\nrationality in decision-making that can lead to the production of inaccurate\noutputs. Existing cognitive bias mitigation strategies assume that input\nprompts contain (exactly) one type of cognitive bias and therefore fail to\nperform well in realistic settings where there maybe any number of biases.\n  To fill this gap, we propose a cognitive debiasing approach, called\nself-debiasing, that enhances the reliability of LLMs by iteratively refining\nprompts. Our method follows three sequential steps -- bias determination, bias\nanalysis, and cognitive debiasing -- to iteratively mitigate potential\ncognitive biases in prompts. Experimental results on finance, healthcare, and\nlegal decision-making tasks, using both closed-source and open-source LLMs,\ndemonstrate that the proposed self-debiasing method outperforms both advanced\nprompt engineering methods and existing cognitive debiasing techniques in\naverage accuracy under no-bias, single-bias, and multi-bias settings.", "published": "2025-04-05 11:23:05", "link": "http://arxiv.org/abs/2504.04141v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Precise Legal Sentence Boundary Detection for Retrieval at Scale: NUPunkt and CharBoundary", "abstract": "We present NUPunkt and CharBoundary, two sentence boundary detection\nlibraries optimized for high-precision, high-throughput processing of legal\ntext in large-scale applications such as due diligence, e-discovery, and legal\nresearch. These libraries address the critical challenges posed by legal\ndocuments containing specialized citations, abbreviations, and complex sentence\nstructures that confound general-purpose sentence boundary detectors.\n  Our experimental evaluation on five diverse legal datasets comprising over\n25,000 documents and 197,000 annotated sentence boundaries demonstrates that\nNUPunkt achieves 91.1% precision while processing 10 million characters per\nsecond with modest memory requirements (432 MB). CharBoundary models offer\nbalanced and adjustable precision-recall tradeoffs, with the large model\nachieving the highest F1 score (0.782) among all tested methods.\n  Notably, NUPunkt provides a 29-32% precision improvement over general-purpose\ntools while maintaining exceptional throughput, processing multi-million\ndocument collections in minutes rather than hours. Both libraries run\nefficiently on standard CPU hardware without requiring specialized\naccelerators. NUPunkt is implemented in pure Python with zero external\ndependencies, while CharBoundary relies only on scikit-learn and optional ONNX\nruntime integration for optimized performance. Both libraries are available\nunder the MIT license, can be installed via PyPI, and can be interactively\ntested at https://sentences.aleainstitute.ai/.\n  These libraries address critical precision issues in retrieval-augmented\ngeneration systems by preserving coherent legal concepts across sentences,\nwhere each percentage improvement in precision yields exponentially greater\nreductions in context fragmentation, creating cascading benefits throughout\nretrieval pipelines and significantly enhancing downstream reasoning quality.", "published": "2025-04-05 10:48:34", "link": "http://arxiv.org/abs/2504.04131v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PEIRCE: Unifying Material and Formal Reasoning via LLM-Driven Neuro-Symbolic Refinement", "abstract": "A persistent challenge in AI is the effective integration of material and\nformal inference - the former concerning the plausibility and contextual\nrelevance of arguments, while the latter focusing on their logical and\nstructural validity. Large Language Models (LLMs), by virtue of their extensive\npre-training on large textual corpora, exhibit strong capabilities in material\ninference. However, their reasoning often lacks formal rigour and\nverifiability. At the same time, LLMs' linguistic competence positions them as\na promising bridge between natural and formal languages, opening up new\nopportunities for combining these two modes of reasoning. In this paper, we\nintroduce PEIRCE, a neuro-symbolic framework designed to unify material and\nformal inference through an iterative conjecture-criticism process. Within this\nframework, LLMs play the central role of generating candidate solutions in\nnatural and formal languages, which are then evaluated and refined via\ninteraction with external critique models. These critiques include symbolic\nprovers, which assess formal validity, as well as soft evaluators that measure\nthe quality of the generated arguments along linguistic and epistemic\ndimensions such as plausibility, coherence, and parsimony. While PEIRCE is a\ngeneral-purpose framework, we demonstrate its capabilities in the domain of\nnatural language explanation generation - a setting that inherently demands\nboth material adequacy and formal correctness.", "published": "2025-04-05 09:04:47", "link": "http://arxiv.org/abs/2504.04110v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "A Benchmark for End-to-End Zero-Shot Biomedical Relation Extraction with LLMs: Experiments with OpenAI Models", "abstract": "Objective: Zero-shot methodology promises to cut down on costs of dataset\nannotation and domain expertise needed to make use of NLP. Generative large\nlanguage models trained to align with human goals have achieved high zero-shot\nperformance across a wide variety of tasks. As of yet, it is unclear how well\nthese models perform on biomedical relation extraction (RE). To address this\nknowledge gap, we explore patterns in the performance of OpenAI LLMs across a\ndiverse sampling of RE tasks.\n  Methods: We use OpenAI GPT-4-turbo and their reasoning model o1 to conduct\nend-to-end RE experiments on seven datasets. We use the JSON generation\ncapabilities of GPT models to generate structured output in two ways: (1) by\ndefining an explicit schema describing the structure of relations, and (2)\nusing a setting that infers the structure from the prompt language.\n  Results: Our work is the first to study and compare the performance of the\nGPT-4 and o1 for the end-to-end zero-shot biomedical RE task across a broad\narray of datasets. We found the zero-shot performances to be proximal to that\nof fine-tuned methods. The limitations of this approach are that it performs\npoorly on instances containing many relations and errs on the boundaries of\ntextual mentions.\n  Conclusion: Recent large language models exhibit promising zero-shot\ncapabilities in complex biomedical RE tasks, offering competitive performance\nwith reduced dataset curation and NLP modeling needs at the cost of increased\ncomputing, potentially increasing medical community accessibility. Addressing\nthe limitations we identify could further boost reliability. The code, data,\nand prompts for all our experiments are publicly available:\nhttps://github.com/bionlproc/ZeroShotRE", "published": "2025-04-05 07:08:54", "link": "http://arxiv.org/abs/2504.04083v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Collaboration and Controversy Among Experts: Rumor Early Detection by Tuning a Comment Generator", "abstract": "Over the past decade, social media platforms have been key in spreading\nrumors, leading to significant negative impacts. To counter this, the community\nhas developed various Rumor Detection (RD) algorithms to automatically identify\nthem using user comments as evidence. However, these RD methods often fail in\nthe early stages of rumor propagation when only limited user comments are\navailable, leading the community to focus on a more challenging topic named\nRumor Early Detection (RED). Typically, existing RED methods learn from limited\nsemantics in early comments. However, our preliminary experiment reveals that\nthe RED models always perform best when the number of training and test\ncomments is consistent and extensive. This inspires us to address the RED issue\nby generating more human-like comments to support this hypothesis. To implement\nthis idea, we tune a comment generator by simulating expert collaboration and\ncontroversy and propose a new RED framework named CAMERED. Specifically, we\nintegrate a mixture-of-expert structure into a generative language model and\npresent a novel routing network for expert collaboration. Additionally, we\nsynthesize a knowledgeable dataset and design an adversarial learning strategy\nto align the style of generated comments with real-world comments. We further\nintegrate generated and original comments with a mutual controversy fusion\nmodule. Experimental results show that CAMERED outperforms state-of-the-art RED\nbaseline models and generation methods, demonstrating its effectiveness.", "published": "2025-04-05 06:21:01", "link": "http://arxiv.org/abs/2504.04076v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "VocalNet: Speech LLM with Multi-Token Prediction for Faster and High-Quality Generation", "abstract": "Speech large language models (LLMs) have emerged as a prominent research\nfocus in speech processing. We propose VocalNet-1B and VocalNet-8B, a series of\nhigh-performance, low-latency speech LLMs enabled by a scalable and\nmodel-agnostic training framework for real-time voice interaction. Departing\nfrom the conventional next-token prediction (NTP), we introduce multi-token\nprediction (MTP), a novel approach optimized for speech LLMs that\nsimultaneously improves generation speed and quality. Experiments show that\nVocalNet outperforms mainstream Omni LLMs despite using significantly less\ntraining data, while also surpassing existing open-source speech LLMs by a\nsubstantial margin. To support reproducibility and community advancement, we\nwill open-source all model weights, inference code, training data, and\nframework implementations upon publication.", "published": "2025-04-05 04:57:12", "link": "http://arxiv.org/abs/2504.04060v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "FISH-Tuning: Enhancing PEFT Methods with Fisher Information", "abstract": "The rapid growth in the parameter size of Large Language Models (LLMs) has\nled to the development of Parameter-Efficient Fine-Tuning (PEFT) methods to\nalleviate the computational costs of fine-tuning. Among these, Fisher Induced\nSparse uncHanging (FISH) Mask is a selection-based PEFT technique that\nidentifies a subset of pre-trained parameters for fine-tuning based on\napproximate Fisher information. However, the integration of FISH Mask with\nother PEFT methods, such as LoRA and Adapters, remains underexplored. In this\npaper, we propose FISH-Tuning, a novel approach that incorporates FISH Mask\ninto addition-based and reparameterization-based PEFT methods, including LoRA,\nAdapters, and their variants. By leveraging Fisher information to select\ncritical parameters within these methods, FISH-Tuning achieves superior\nperformance without additional memory overhead or inference latency.\nExperimental results across various datasets and pre-trained models demonstrate\nthat FISH-Tuning consistently outperforms the vanilla PEFT methods with the\nsame proportion of trainable parameters.", "published": "2025-04-05 04:05:55", "link": "http://arxiv.org/abs/2504.04050v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SyLeR: A Framework for Explicit Syllogistic Legal Reasoning in Large Language Models", "abstract": "Syllogistic reasoning is a fundamental aspect of legal decision-making,\nenabling logical conclusions by connecting general legal principles with\nspecific case facts. Although existing large language models (LLMs) can\ngenerate responses to legal questions, they fail to perform explicit\nsyllogistic reasoning, often producing implicit and unstructured answers that\nlack explainability and trustworthiness. To address this limitation, we propose\nSyLeR, a novel framework that empowers LLMs to engage in explicit syllogistic\nlegal reasoning. SyLeR integrates a tree-structured hierarchical retrieval\nmechanism to effectively combine relevant legal statutes and precedent cases,\nforming comprehensive major premises. This is followed by a two-stage\nfine-tuning process: supervised fine-tuning warm-up establishes a foundational\nunderstanding of syllogistic reasoning, while reinforcement learning with a\nstructure-aware reward mechanism refines the ability of the model to generate\ndiverse logically sound and well-structured reasoning paths. We conducted\nextensive experiments across various dimensions, including in-domain and\ncross-domain user groups (legal laypersons and practitioners), multiple\nlanguages (Chinese and French), and different LLM backbones (legal-specific and\nopen-domain LLMs). The results show that SyLeR significantly improves response\naccuracy and consistently delivers explicit, explainable, and trustworthy legal\nreasoning.", "published": "2025-04-05 03:34:51", "link": "http://arxiv.org/abs/2504.04042v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "myNER: Contextualized Burmese Named Entity Recognition with Bidirectional LSTM and fastText Embeddings via Joint Training with POS Tagging", "abstract": "Named Entity Recognition (NER) involves identifying and categorizing named\nentities within textual data. Despite its significance, NER research has often\noverlooked low-resource languages like Myanmar (Burmese), primarily due to the\nlack of publicly available annotated datasets. To address this, we introduce\nmyNER, a novel word-level NER corpus featuring a 7-tag annotation scheme,\nenriched with Part-of-Speech (POS) tagging to provide additional syntactic\ninformation. Alongside the corpus, we conduct a comprehensive evaluation of NER\nmodels, including Conditional Random Fields (CRF), Bidirectional LSTM\n(BiLSTM)-CRF, and their combinations with fastText embeddings in different\nsettings. Our experiments reveal the effectiveness of contextualized word\nembeddings and the impact of joint training with POS tagging, demonstrating\nsignificant performance improvements across models. The traditional CRF\njoint-task model with fastText embeddings as a feature achieved the best\nresult, with a 0.9818 accuracy and 0.9811 weighted F1 score with 0.7429 macro\nF1 score. BiLSTM-CRF with fine-tuned fastText embeddings gets the best result\nof 0.9791 accuracy and 0.9776 weighted F1 score with 0.7395 macro F1 score.", "published": "2025-04-05 03:13:33", "link": "http://arxiv.org/abs/2504.04038v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "OpenCodeInstruct: A Large-scale Instruction Tuning Dataset for Code LLMs", "abstract": "Large Language Models (LLMs) have transformed software development by\nenabling code generation, automated debugging, and complex reasoning. However,\ntheir continued advancement is constrained by the scarcity of high-quality,\npublicly available supervised fine-tuning (SFT) datasets tailored for coding\ntasks. To bridge this gap, we introduce OpenCodeInstruct, the largest\nopen-access instruction tuning dataset, comprising 5 million diverse samples.\nEach sample includes a programming question, solution, test cases, execution\nfeedback, and LLM-generated quality assessments. We fine-tune various base\nmodels, including LLaMA and Qwen, across multiple scales (1B+, 3B+, and 7B+)\nusing our dataset. Comprehensive evaluations on popular benchmarks (HumanEval,\nMBPP, LiveCodeBench, and BigCodeBench) demonstrate substantial performance\nimprovements achieved by SFT with OpenCodeInstruct. We also present a detailed\nmethodology encompassing seed data curation, synthetic instruction and solution\ngeneration, and filtering.", "published": "2025-04-05 02:52:16", "link": "http://arxiv.org/abs/2504.04030v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Rethinking Reflection in Pre-Training", "abstract": "A language model's ability to reflect on its own reasoning provides a key\nadvantage for solving complex problems. While most recent research has focused\non how this ability develops during reinforcement learning, we show that it\nactually begins to emerge much earlier - during the model's pre-training. To\nstudy this, we introduce deliberate errors into chains-of-thought and test\nwhether the model can still arrive at the correct answer by recognizing and\ncorrecting these mistakes. By tracking performance across different stages of\npre-training, we observe that this self-correcting ability appears early and\nimproves steadily over time. For instance, an OLMo2-7B model pre-trained on 4\ntrillion tokens displays self-correction on our six self-reflection tasks.", "published": "2025-04-05 02:24:07", "link": "http://arxiv.org/abs/2504.04022v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Sigma: A dataset for text-to-code semantic parsing with statistical analysis", "abstract": "In the domain of semantic parsing, significant progress has been achieved in\nText-to-SQL and question-answering tasks, both of which focus on extracting\ninformation from data sources in their native formats. However, the inherent\nconstraints of their formal meaning representations, such as SQL programming\nlanguage or basic logical forms, hinder their ability to analyze data from\nvarious perspectives, such as conducting statistical analyses. To address this\nlimitation and inspire research in this field, we design SIGMA, a new dataset\nfor Text-to-Code semantic parsing with statistical analysis. SIGMA comprises\n6000 questions with corresponding Python code labels, spanning across 160\ndatabases. Half of the questions involve query types, which return information\nin its original format, while the remaining 50% are statistical analysis\nquestions, which perform statistical operations on the data. The Python code\nlabels in our dataset cover 4 types of query types and 40 types of statistical\nanalysis patterns. We evaluated the SIGMA dataset using three different\nbaseline models: LGESQL, SmBoP, and SLSQL. The experimental results show that\nthe LGESQL model with ELECTRA outperforms all other models, achieving 83.37%\nstructure accuracy. In terms of execution accuracy, the SmBoP model, when\ncombined with GraPPa and T5, reaches 76.38%.", "published": "2025-04-05 23:30:20", "link": "http://arxiv.org/abs/2504.04301v1", "categories": ["cs.LG", "cs.AI", "cs.DB"], "primary_category": "cs.LG"}
{"title": "AI-induced sexual harassment: Investigating Contextual Characteristics and User Reactions of Sexual Harassment by a Companion Chatbot", "abstract": "Advancements in artificial intelligence (AI) have led to the increase of\nconversational agents like Replika, designed to provide social interaction and\nemotional support. However, reports of these AI systems engaging in\ninappropriate sexual behaviors with users have raised significant concerns. In\nthis study, we conducted a thematic analysis of user reviews from the Google\nPlay Store to investigate instances of sexual harassment by the Replika\nchatbot. From a dataset of 35,105 negative reviews, we identified 800 relevant\ncases for analysis. Our findings revealed that users frequently experience\nunsolicited sexual advances, persistent inappropriate behavior, and failures of\nthe chatbot to respect user boundaries. Users expressed feelings of discomfort,\nviolation of privacy, and disappointment, particularly when seeking a platonic\nor therapeutic AI companion. This study highlights the potential harms\nassociated with AI companions and underscores the need for developers to\nimplement effective safeguards and ethical guidelines to prevent such\nincidents. By shedding light on user experiences of AI-induced harassment, we\ncontribute to the understanding of AI-related risks and emphasize the\nimportance of corporate responsibility in developing safer and more ethical AI\nsystems.", "published": "2025-04-05 23:04:37", "link": "http://arxiv.org/abs/2504.04299v1", "categories": ["cs.HC", "cs.AI", "H.5; I.2.7; K.4.2"], "primary_category": "cs.HC"}
{"title": "CATS: Mitigating Correlation Shift for Multivariate Time Series Classification", "abstract": "Unsupervised Domain Adaptation (UDA) leverages labeled source data to train\nmodels for unlabeled target data. Given the prevalence of multivariate time\nseries (MTS) data across various domains, the UDA task for MTS classification\nhas emerged as a critical challenge. However, for MTS data, correlations\nbetween variables often vary across domains, whereas most existing UDA works\nfor MTS classification have overlooked this essential characteristic. To bridge\nthis gap, we introduce a novel domain shift, {\\em correlation shift}, measuring\ndomain differences in multivariate correlation. To mitigate correlation shift,\nwe propose a scalable and parameter-efficient \\underline{C}orrelation\n\\underline{A}dapter for M\\underline{TS} (CATS). Designed as a plug-and-play\ntechnique compatible with various Transformer variants, CATS employs temporal\nconvolution to capture local temporal patterns and a graph attention module to\nmodel the changing multivariate correlation. The adapter reweights the target\ncorrelations to align the source correlations with a theoretically guaranteed\nprecision. A correlation alignment loss is further proposed to mitigate\ncorrelation shift, bypassing the alignment challenge from the non-i.i.d. nature\nof MTS data. Extensive experiments on four real-world datasets demonstrate that\n(1) compared with vanilla Transformer-based models, CATS increases over $10\\%$\naverage accuracy while only adding around $1\\%$ parameters, and (2) all\nTransformer variants equipped with CATS either reach or surpass\nstate-of-the-art baselines.", "published": "2025-04-05 21:08:47", "link": "http://arxiv.org/abs/2504.04283v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Comparative Study of Explainable AI Methods: Model-Agnostic vs. Model-Specific Approaches", "abstract": "This paper compares model-agnostic and model-specific approaches to\nexplainable AI (XAI) in deep learning image classification. I examine how LIME\nand SHAP (model-agnostic methods) differ from Grad-CAM and Guided\nBackpropagation (model-specific methods) when interpreting ResNet50 predictions\nacross diverse image categories. Through extensive testing with various species\nfrom dogs and birds to insects I found that each method reveals different\naspects of the models decision-making process. Model-agnostic techniques\nprovide broader feature attribution that works across different architectures,\nwhile model-specific approaches excel at highlighting precise activation\nregions with greater computational efficiency. My analysis shows there is no\n\"one-size-fits-all\" solution for model interpretability. Instead, combining\nmultiple XAI methods offers the most comprehensive understanding of complex\nmodels particularly valuable in high-stakes domains like healthcare, autonomous\nvehicles, and financial services where transparency is crucial. This\ncomparative framework provides practical guidance for selecting appropriate\ninterpretability techniques based on specific application needs and\ncomputational constraints.", "published": "2025-04-05 20:13:20", "link": "http://arxiv.org/abs/2504.04276v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Improving Chronic Kidney Disease Detection Efficiency: Fine Tuned CatBoost and Nature-Inspired Algorithms with Explainable AI", "abstract": "Chronic Kidney Disease (CKD) is a major global health issue which is\naffecting million people around the world and with increasing rate of\nmortality. Mitigation of progression of CKD and better patient outcomes\nrequires early detection. Nevertheless, limitations lie in traditional\ndiagnostic methods, especially in resource constrained settings. This study\nproposes an advanced machine learning approach to enhance CKD detection by\nevaluating four models: Random Forest (RF), Multi-Layer Perceptron (MLP),\nLogistic Regression (LR), and a fine-tuned CatBoost algorithm. Specifically,\namong these, the fine-tuned CatBoost model demonstrated the best overall\nperformance having an accuracy of 98.75%, an AUC of 0.9993 and a Kappa score of\n97.35% of the studies. The proposed CatBoost model has used a nature inspired\nalgorithm such as Simulated Annealing to select the most important features,\nCuckoo Search to adjust outliers and grid search to fine tune its settings in\nsuch a way to achieve improved prediction accuracy. Features significance is\nexplained by SHAP-a well-known XAI technique-for gaining transparency in the\ndecision-making process of proposed model and bring up trust in diagnostic\nsystems. Using SHAP, the significant clinical features were identified as\nspecific gravity, serum creatinine, albumin, hemoglobin, and diabetes mellitus.\nThe potential of advanced machine learning techniques in CKD detection is shown\nin this research, particularly for low income and middle-income healthcare\nsettings where prompt and correct diagnoses are vital. This study seeks to\nprovide a highly accurate, interpretable, and efficient diagnostic tool to add\nto efforts for early intervention and improved healthcare outcomes for all CKD\npatients.", "published": "2025-04-05 19:41:47", "link": "http://arxiv.org/abs/2504.04262v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "LOGLO-FNO: Efficient Learning of Local and Global Features in Fourier Neural Operators", "abstract": "Modeling high-frequency information is a critical challenge in scientific\nmachine learning. For instance, fully turbulent flow simulations of\nNavier-Stokes equations at Reynolds numbers 3500 and above can generate\nhigh-frequency signals due to swirling fluid motions caused by eddies and\nvortices. Faithfully modeling such signals using neural networks depends on\naccurately reconstructing moderate to high frequencies. However, it has been\nwell known that deep neural nets exhibit the so-called spectral bias toward\nlearning low-frequency components. Meanwhile, Fourier Neural Operators (FNOs)\nhave emerged as a popular class of data-driven models in recent years for\nsolving Partial Differential Equations (PDEs) and for surrogate modeling in\ngeneral. Although impressive results have been achieved on several PDE\nbenchmark problems, FNOs often perform poorly in learning non-dominant\nfrequencies characterized by local features. This limitation stems from the\nspectral bias inherent in neural networks and the explicit exclusion of\nhigh-frequency modes in FNOs and their variants. Therefore, to mitigate these\nissues and improve FNO's spectral learning capabilities to represent a broad\nrange of frequency components, we propose two key architectural enhancements:\n(i) a parallel branch performing local spectral convolutions (ii) a\nhigh-frequency propagation module. Moreover, we propose a novel\nfrequency-sensitive loss term based on radially binned spectral errors. This\nintroduction of a parallel branch for local convolutions reduces number of\ntrainable parameters by up to 50% while achieving the accuracy of baseline FNO\nthat relies solely on global convolutions. Experiments on three challenging PDE\nproblems in fluid mechanics and biological pattern formation, and the\nqualitative and spectral analysis of predictions show the effectiveness of our\nmethod over the state-of-the-art neural operator baselines.", "published": "2025-04-05 19:35:04", "link": "http://arxiv.org/abs/2504.04260v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "physics.geo-ph"], "primary_category": "cs.LG"}
{"title": "Progressive Multi-Source Domain Adaptation for Personalized Facial Expression Recognition", "abstract": "Personalized facial expression recognition (FER) involves adapting a machine\nlearning model using samples from labeled sources and unlabeled target domains.\nGiven the challenges of recognizing subtle expressions with considerable\ninterpersonal variability, state-of-the-art unsupervised domain adaptation\n(UDA) methods focus on the multi-source UDA (MSDA) setting, where each domain\ncorresponds to a specific subject, and improve model accuracy and robustness.\nHowever, when adapting to a specific target, the diverse nature of multiple\nsource domains translates to a large shift between source and target data.\nState-of-the-art MSDA methods for FER address this domain shift by considering\nall the sources to adapt to the target representations. Nevertheless, adapting\nto a target subject presents significant challenges due to large distributional\ndifferences between source and target domains, often resulting in negative\ntransfer. In addition, integrating all sources simultaneously increases\ncomputational costs and causes misalignment with the target. To address these\nissues, we propose a progressive MSDA approach that gradually introduces\ninformation from subjects based on their similarity to the target subject. This\nwill ensure that only the most relevant sources from the target are selected,\nwhich helps avoid the negative transfer caused by dissimilar sources. We first\nexploit the closest sources to reduce the distribution shift with the target\nand then move towards the furthest while only considering the most relevant\nsources based on the predetermined threshold. Furthermore, to mitigate\ncatastrophic forgetting caused by the incremental introduction of source\nsubjects, we implemented a density-based memory mechanism that preserves the\nmost relevant historical source samples for adaptation. Our experiments show\nthe effectiveness of our proposed method on pain datasets: Biovid and\nUNBC-McMaster.", "published": "2025-04-05 19:14:51", "link": "http://arxiv.org/abs/2504.04252v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Task load dependent decision referrals for joint binary classification in human-automation teams", "abstract": "We consider the problem of optimal decision referrals in human-automation\nteams performing binary classification tasks. The automation, which includes a\npre-trained classifier, observes data for a batch of independent tasks,\nanalyzes them, and may refer a subset of tasks to a human operator for fresh\nand final analysis. Our key modeling assumption is that human performance\ndegrades with task load. We model the problem of choosing which tasks to refer\nas a stochastic optimization problem and show that, for a given task load, it\nis optimal to myopically refer tasks that yield the largest reduction in\nexpected cost, conditional on the observed data. This provides a ranking scheme\nand a policy to determine the optimal set of tasks for referral. We evaluate\nthis policy against a baseline through an experimental study with human\nparticipants. Using a radar screen simulator, participants made binary target\nclassification decisions under time constraint. They were guided by a decision\nrule provided to them, but were still prone to errors under time pressure. An\ninitial experiment estimated human performance model parameters, while a second\nexperiment compared two referral policies. Results show statistically\nsignificant gains for the proposed optimal referral policy over a blind policy\nthat determines referrals using the automation and human-performance models but\nnot based on the observed data.", "published": "2025-04-05 19:09:04", "link": "http://arxiv.org/abs/2504.04248v1", "categories": ["eess.SY", "cs.AI", "cs.HC", "cs.SY"], "primary_category": "eess.SY"}
{"title": "From Automation to Autonomy in Smart Manufacturing: A Bayesian Optimization Framework for Modeling Multi-Objective Experimentation and Sequential Decision Making", "abstract": "Discovering novel materials with desired properties is essential for driving\ninnovation. Industry 4.0 and smart manufacturing have promised transformative\nadvances in this area through real-time data integration and automated\nproduction planning and control. However, the reliance on automation alone has\noften fallen short, lacking the flexibility needed for complex processes. To\nfully unlock the potential of smart manufacturing, we must evolve from\nautomation to autonomous systems that go beyond rigid programming and can\ndynamically optimize the search for solutions. Current discovery approaches are\noften slow, requiring numerous trials to find optimal combinations, and costly,\nparticularly when optimizing multiple properties simultaneously. This paper\nproposes a Bayesian multi-objective sequential decision-making (BMSDM)\nframework that can intelligently select experiments as manufacturing\nprogresses, guiding us toward the discovery of optimal design faster and more\nefficiently. The framework leverages sequential learning through Bayesian\nOptimization, which iteratively refines a statistical model representing the\nunderlying manufacturing process. This statistical model acts as a surrogate,\nallowing for efficient exploration and optimization without requiring numerous\nreal-world experiments. This approach can significantly reduce the time and\ncost of data collection required by traditional experimental designs. The\nproposed framework is compared with traditional DoE methods and two other\nmulti-objective optimization methods. Using a manufacturing dataset, we\nevaluate and compare the performance of these approaches across five evaluation\nmetrics. BMSDM comprehensively outperforms the competing methods in\nmulti-objective decision-making scenarios. Our proposed approach represents a\nsignificant leap forward in creating an intelligent autonomous platform capable\nof novel material discovery.", "published": "2025-04-05 18:21:20", "link": "http://arxiv.org/abs/2504.04244v1", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY", "math.OC"], "primary_category": "cs.LG"}
{"title": "Perils of Label Indeterminacy: A Case Study on Prediction of Neurological Recovery After Cardiac Arrest", "abstract": "The design of AI systems to assist human decision-making typically requires\nthe availability of labels to train and evaluate supervised models. Frequently,\nhowever, these labels are unknown, and different ways of estimating them\ninvolve unverifiable assumptions or arbitrary choices. In this work, we\nintroduce the concept of label indeterminacy and derive important implications\nin high-stakes AI-assisted decision-making. We present an empirical study in a\nhealthcare context, focusing specifically on predicting the recovery of\ncomatose patients after resuscitation from cardiac arrest. Our study shows that\nlabel indeterminacy can result in models that perform similarly when evaluated\non patients with known labels, but vary drastically in their predictions for\npatients where labels are unknown. After demonstrating crucial ethical\nimplications of label indeterminacy in this high-stakes context, we discuss\ntakeaways for evaluation, reporting, and design.", "published": "2025-04-05 18:07:36", "link": "http://arxiv.org/abs/2504.04243v1", "categories": ["cs.LG", "cs.AI", "cs.HC", "stat.ME"], "primary_category": "cs.LG"}
{"title": "oneDAL Optimization for ARM Scalable Vector Extension: Maximizing Efficiency for High-Performance Data Science", "abstract": "The evolution of ARM-based architectures, particularly those incorporating\nScalable Vector Extension (SVE), has introduced transformative opportunities\nfor high-performance computing (HPC) and machine learning (ML) workloads. The\nUnified Acceleration Foundation's (UXL) oneAPI Data Analytics Library (oneDAL)\nis a widely adopted library for accelerating ML and data analytics workflows,\nbut its reliance on Intel's proprietary Math Kernel Library (MKL) has\ntraditionally limited its compatibility to x86platforms. This paper details the\nporting of oneDAL to ARM architectures with SVE support, using OpenBLAS as an\nalternative backend to overcome architectural and performance challenges.\nBeyond porting, the research introduces novel ARM-specific optimizations,\nincluding custom sparse matrix routines, vectorized statistical functions, and\na Scalable Vector Extension (SVE)-optimized Support Vector Machine (SVM)\nalgorithm. The SVM enhancements leverage SVE's flexible vector lengths and\npredicate driven execution, achieving notable performance gains of 22% for the\nBoser method and 5% for the Thunder method. Benchmarks conducted on ARM\nSVE-enabled AWSGraviton3 instances showcase up to 200x acceleration in ML\ntraining and inference tasks compared to the original scikit-learn\nimplementation on the ARM platform. Moreover, the ARM-optimized oneDAL achieves\nperformance parity with, and in some cases exceeds, the x86 oneDAL\nimplementation (MKL backend) on IceLake x86 systems, which are nearly twice as\ncostly as AWSGraviton3 ARM instances. These findings highlight ARM's potential\nas a high-performance, energyefficient platform for dataintensive ML\napplications. By expanding cross-architecture compatibility and contributing to\nthe opensource ecosystem, this work reinforces ARM's position as a competitive\nalternative in the HPC and ML domains, paving the way for future advancements\nin dataintensive computing.", "published": "2025-04-05 17:53:36", "link": "http://arxiv.org/abs/2504.04241v1", "categories": ["cs.DC", "cs.AI", "cs.PF"], "primary_category": "cs.DC"}
{"title": "TrafficLLM: Enhancing Large Language Models for Network Traffic Analysis with Generic Traffic Representation", "abstract": "Machine learning (ML) powered network traffic analysis has been widely used\nfor the purpose of threat detection. Unfortunately, their generalization across\ndifferent tasks and unseen data is very limited. Large language models (LLMs),\nknown for their strong generalization capabilities, have shown promising\nperformance in various domains. However, their application to the traffic\nanalysis domain is limited due to significantly different characteristics of\nnetwork traffic. To address the issue, in this paper, we propose TrafficLLM,\nwhich introduces a dual-stage fine-tuning framework to learn generic traffic\nrepresentation from heterogeneous raw traffic data. The framework uses\ntraffic-domain tokenization, dual-stage tuning pipeline, and extensible\nadaptation to help LLM release generalization ability on dynamic traffic\nanalysis tasks, such that it enables traffic detection and traffic generation\nacross a wide range of downstream tasks. We evaluate TrafficLLM across 10\ndistinct scenarios and 229 types of traffic. TrafficLLM achieves F1-scores of\n0.9875 and 0.9483, with up to 80.12% and 33.92% better performance than\nexisting detection and generation methods. It also shows strong generalization\non unseen traffic with an 18.6% performance improvement. We further evaluate\nTrafficLLM in real-world scenarios. The results confirm that TrafficLLM is easy\nto scale and achieves accurate detection performance on enterprise traffic.", "published": "2025-04-05 16:18:33", "link": "http://arxiv.org/abs/2504.04222v1", "categories": ["cs.LG", "cs.AI", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Learning about the Physical World through Analytic Concepts", "abstract": "Reviewing the progress in artificial intelligence over the past decade,\nvarious significant advances (e.g. object detection, image generation, large\nlanguage models) have enabled AI systems to produce more semantically\nmeaningful outputs and achieve widespread adoption in internet scenarios.\nNevertheless, AI systems still struggle when it comes to understanding and\ninteracting with the physical world. This reveals an important issue: relying\nsolely on semantic-level concepts learned from internet data (e.g. texts,\nimages) to understand the physical world is far from sufficient -- machine\nintelligence currently lacks an effective way to learn about the physical\nworld. This research introduces the idea of analytic concept -- representing\nthe concepts related to the physical world through programs of mathematical\nprocedures, providing machine intelligence a portal to perceive, reason about,\nand interact with the physical world. Except for detailing the design\nphilosophy and providing guidelines for the application of analytic concepts,\nthis research also introduce about the infrastructure that has been built\naround analytic concepts. I aim for my research to contribute to addressing\nthese questions: What is a proper abstraction of general concepts in the\nphysical world for machine intelligence? How to systematically integrate\nstructured priors with neural networks to constrain AI systems to comply with\nphysical laws?", "published": "2025-04-05 13:22:11", "link": "http://arxiv.org/abs/2504.04170v1", "categories": ["cs.AI", "cs.CV", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Introducing COGENT3: An AI Architecture for Emergent Cognition", "abstract": "This paper presents COGENT3 (or Collective Growth and Entropy-modulated\nTriads System), a novel approach for emergent cognition integrating pattern\nformation networks with group influence dynamics. Contrasting with traditional\nstrategies that rely on predetermined architectures, computational structures\nemerge dynamically in our framework through agent interactions. This enables a\nmore flexible and adaptive system exhibiting characteristics reminiscent of\nhuman cognitive processes. The incorporation of temperature modulation and\nmemory effects in COGENT3 closely integrates statistical mechanics, machine\nlearning, and cognitive science.", "published": "2025-04-05 11:05:55", "link": "http://arxiv.org/abs/2504.04139v1", "categories": ["cs.AI", "68T05, 37A60, 05C82, 82C20", "I.2.6; G.2.2; I.6.8"], "primary_category": "cs.AI"}
{"title": "Predicting Soil Macronutrient Levels: A Machine Learning Approach Models Trained on pH, Conductivity, and Average Power of Acid-Base Solutions", "abstract": "Soil macronutrients, particularly potassium ions (K$^+$), are indispensable\nfor plant health, underpinning various physiological and biological processes,\nand facilitating the management of both biotic and abiotic stresses. Deficient\nmacronutrient content results in stunted growth, delayed maturation, and\nincreased vulnerability to environmental stressors, thereby accentuating the\nimperative for precise soil nutrient monitoring. Traditional techniques such as\nchemical assays, atomic absorption spectroscopy, inductively coupled plasma\noptical emission spectroscopy, and electrochemical methods, albeit advanced,\nare prohibitively expensive and time-intensive, thus unsuitable for real-time\nmacronutrient assessment. In this study, we propose an innovative soil testing\nprotocol utilizing a dataset derived from synthetic solutions to model soil\nbehaviour. The dataset encompasses physical properties including conductivity\nand pH, with a concentration on three key macronutrients: nitrogen (N),\nphosphorus (P), and potassium (K). Four machine learning algorithms were\napplied to the dataset, with random forest regressors and neural networks being\nselected for the prediction of soil nutrient concentrations. Comparative\nanalysis with laboratory soil testing results revealed prediction errors of\n23.6% for phosphorus and 16% for potassium using the random forest model, and\n26.3% for phosphorus and 21.8% for potassium using the neural network model.\nThis methodology illustrates a cost-effective and efficacious strategy for\nreal-time soil nutrient monitoring, offering substantial advancements over\nconventional techniques and enhancing the capability to sustain optimal\nnutrient levels conducive to robust crop growth.", "published": "2025-04-05 11:04:48", "link": "http://arxiv.org/abs/2504.04138v1", "categories": ["cs.LG", "cs.AI", "physics.bio-ph", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "Guaranteeing consistency in evidence fusion: A novel perspective on credibility", "abstract": "It is explored that available credible evidence fusion schemes suffer from\nthe potential inconsistency because credibility calculation and Dempster's\ncombination rule-based fusion are sequentially performed in an open-loop style.\nThis paper constructs evidence credibility from the perspective of the degree\nof support for events within the framework of discrimination (FOD) and proposes\nan iterative credible evidence fusion (ICEF) to overcome the inconsistency in\nview of close-loop control. On one hand, the ICEF introduces the fusion result\ninto credibility assessment to establish the correlation between credibility\nand the fusion result. On the other hand, arithmetic-geometric divergence is\npromoted based on the exponential normalization of plausibility and belief\nfunctions to measure evidence conflict, called plausibility-belief\narithmetic-geometric divergence (PBAGD), which is superior in capturing the\ncorrelation and difference of FOD subsets, identifying abnormal sources, and\nreducing their fusion weights. The ICEF is compared with traditional methods by\ncombining different evidence difference measure forms via numerical examples to\nverify its performance. Simulations on numerical examples and benchmark\ndatasets reflect the adaptability of PBAGD to the proposed fusion strategy.", "published": "2025-04-05 10:12:32", "link": "http://arxiv.org/abs/2504.04128v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Multi-identity Human Image Animation with Structural Video Diffusion", "abstract": "Generating human videos from a single image while ensuring high visual\nquality and precise control is a challenging task, especially in complex\nscenarios involving multiple individuals and interactions with objects.\nExisting methods, while effective for single-human cases, often fail to handle\nthe intricacies of multi-identity interactions because they struggle to\nassociate the correct pairs of human appearance and pose condition and model\nthe distribution of 3D-aware dynamics. To address these limitations, we present\nStructural Video Diffusion, a novel framework designed for generating realistic\nmulti-human videos. Our approach introduces two core innovations:\nidentity-specific embeddings to maintain consistent appearances across\nindividuals and a structural learning mechanism that incorporates depth and\nsurface-normal cues to model human-object interactions. Additionally, we expand\nexisting human video dataset with 25K new videos featuring diverse multi-human\nand object interaction scenarios, providing a robust foundation for training.\nExperimental results demonstrate that Structural Video Diffusion achieves\nsuperior performance in generating lifelike, coherent videos for multiple\nsubjects with dynamic and rich interactions, advancing the state of\nhuman-centric video generation.", "published": "2025-04-05 10:03:49", "link": "http://arxiv.org/abs/2504.04126v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Improving Question Embeddings with Cognitiv Representation Optimization for Knowledge Tracing", "abstract": "The Knowledge Tracing (KT) aims to track changes in students' knowledge\nstatus and predict their future answers based on their historical answer\nrecords. Current research on KT modeling focuses on predicting student' future\nperformance based on existing, unupdated records of student learning\ninteractions. However, these approaches ignore the distractors (such as\nslipping and guessing) in the answering process and overlook that static\ncognitive representations are temporary and limited. Most of them assume that\nthere are no distractors in the answering process and that the record\nrepresentations fully represent the students' level of understanding and\nproficiency in knowledge. In this case, it may lead to many insynergy and\nincoordination issue in the original records. Therefore we propose a Cognitive\nRepresentation Optimization for Knowledge Tracing (CRO-KT) model, which\nutilizes a dynamic programming algorithm to optimize structure of cognitive\nrepresentations. This ensures that the structure matches the students'\ncognitive patterns in terms of the difficulty of the exercises. Furthermore, we\nuse the co-optimization algorithm to optimize the cognitive representations of\nthe sub-target exercises in terms of the overall situation of exercises\nresponses by considering all the exercises with co-relationships as a single\ngoal. Meanwhile, the CRO-KT model fuses the learned relational embeddings from\nthe bipartite graph with the optimized record representations in a weighted\nmanner, enhancing the expression of students' cognition. Finally, experiments\nare conducted on three publicly available datasets respectively to validate the\neffectiveness of the proposed cognitive representation optimization model.", "published": "2025-04-05 09:32:03", "link": "http://arxiv.org/abs/2504.04121v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "TARAC: Mitigating Hallucination in LVLMs via Temporal Attention Real-time Accumulative Connection", "abstract": "Large Vision-Language Models have demonstrated remarkable performance across\nvarious tasks; however, the challenge of hallucinations constrains their\npractical applications. The hallucination problem arises from multiple factors,\nincluding the inherent hallucinations in language models, the limitations of\nvisual encoders in perception, and biases introduced by multimodal data.\nExtensive research has explored ways to mitigate hallucinations. For instance,\nOPERA prevents the model from overly focusing on \"anchor tokens\", thereby\nreducing hallucinations, whereas VCD mitigates hallucinations by employing a\ncontrastive decoding approach. In this paper, we investigate the correlation\nbetween the decay of attention to image tokens and the occurrence of\nhallucinations. Based on this finding, we propose Temporal Attention Real-time\nAccumulative Connection (TARAC), a novel training-free method that dynamically\naccumulates and updates LVLMs' attention on image tokens during generation. By\nenhancing the model's attention to image tokens, TARAC mitigates hallucinations\ncaused by the decay of attention on image tokens. We validate the effectiveness\nof TARAC across multiple models and datasets, demonstrating that our approach\nsubstantially mitigates hallucinations. In particular, TARAC reduces $C_S$ by\n25.2 and $C_I$ by 8.7 compared to VCD on the CHAIR benchmark.", "published": "2025-04-05 07:57:11", "link": "http://arxiv.org/abs/2504.04099v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Lifting Factor Graphs with Some Unknown Factors for New Individuals", "abstract": "Lifting exploits symmetries in probabilistic graphical models by using a\nrepresentative for indistinguishable objects, allowing to carry out query\nanswering more efficiently while maintaining exact answers. In this paper, we\ninvestigate how lifting enables us to perform probabilistic inference for\nfactor graphs containing unknown factors, i.e., factors whose underlying\nfunction of potential mappings is unknown. We present the Lifting Factor Graphs\nwith Some Unknown Factors (LIFAGU) algorithm to identify indistinguishable\nsubgraphs in a factor graph containing unknown factors, thereby enabling the\ntransfer of known potentials to unknown potentials to ensure a well-defined\nsemantics of the model and allow for (lifted) probabilistic inference. We\nfurther extend LIFAGU to incorporate additional background knowledge about\ngroups of factors belonging to the same individual object. By incorporating\nsuch background knowledge, LIFAGU is able to further reduce the ambiguity of\npossible transfers of known potentials to unknown potentials.", "published": "2025-04-05 07:23:08", "link": "http://arxiv.org/abs/2504.04089v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Towards An Efficient and Effective En Route Travel Time Estimation Framework", "abstract": "En route travel time estimation (ER-TTE) focuses on predicting the travel\ntime of the remaining route. Existing ER-TTE methods always make re-estimation\nwhich significantly hinders real-time performance, especially when faced with\nthe computational demands of simultaneous user requests. This results in delays\nand reduced responsiveness in ER-TTE services. We propose a general efficient\nframework U-ERTTE combining an Uncertainty-Guided Decision mechanism (UGD) and\nFine-Tuning with Meta-Learning (FTML) to address these challenges. UGD\nquantifies the uncertainty and provides confidence intervals for the entire\nroute. It selectively re-estimates only when the actual travel time deviates\nfrom the predicted confidence intervals, thereby optimizing the efficiency of\nER-TTE. To ensure the accuracy of confidence intervals and accurate predictions\nthat need to re-estimate, FTML is employed to train the model, enabling it to\nlearn general driving patterns and specific features to adapt to specific\ntasks. Extensive experiments on two large-scale real datasets demonstrate that\nthe U-ERTTE framework significantly enhances inference speed and throughput\nwhile maintaining high effectiveness. Our code is available at\nhttps://github.com/shenzekai/U-ERTTE", "published": "2025-04-05 07:15:26", "link": "http://arxiv.org/abs/2504.04086v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "DocSAM: Unified Document Image Segmentation via Query Decomposition and Heterogeneous Mixed Learning", "abstract": "Document image segmentation is crucial for document analysis and recognition\nbut remains challenging due to the diversity of document formats and\nsegmentation tasks. Existing methods often address these tasks separately,\nresulting in limited generalization and resource wastage. This paper introduces\nDocSAM, a transformer-based unified framework designed for various document\nimage segmentation tasks, such as document layout analysis, multi-granularity\ntext segmentation, and table structure recognition, by modelling these tasks as\na combination of instance and semantic segmentation. Specifically, DocSAM\nemploys Sentence-BERT to map category names from each dataset into semantic\nqueries that match the dimensionality of instance queries. These two sets of\nqueries interact through an attention mechanism and are cross-attended with\nimage features to predict instance and semantic segmentation masks. Instance\ncategories are predicted by computing the dot product between instance and\nsemantic queries, followed by softmax normalization of scores. Consequently,\nDocSAM can be jointly trained on heterogeneous datasets, enhancing robustness\nand generalization while reducing computational and storage resources.\nComprehensive evaluations show that DocSAM surpasses existing methods in\naccuracy, efficiency, and adaptability, highlighting its potential for\nadvancing document image understanding and segmentation across various\napplications. Codes are available at https://github.com/xhli-git/DocSAM.", "published": "2025-04-05 07:14:53", "link": "http://arxiv.org/abs/2504.04085v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Among Us: A Sandbox for Agentic Deception", "abstract": "Studying deception in AI agents is important and difficult due to the lack of\nmodel organisms and sandboxes that elicit the behavior without asking the model\nto act under specific conditions or inserting intentional backdoors. Extending\nupon $\\textit{AmongAgents}$, a text-based social-deduction game environment, we\naim to fix this by introducing Among Us as a rich sandbox where LLM-agents\nexhibit human-style deception naturally while they think, speak, and act with\nother agents or humans. We introduce Deception ELO as an unbounded measure of\ndeceptive capability, suggesting that frontier models win more because they're\nbetter at deception, not at detecting it. We evaluate the effectiveness of AI\nsafety techniques (LLM-monitoring of outputs, linear probes on various\ndatasets, and sparse autoencoders) for detecting lying and deception in Among\nUs, and find that they generalize very well out-of-distribution. We open-source\nour sandbox as a benchmark for future alignment research and hope that this is\na good testbed to improve safety techniques to detect and remove\nagentically-motivated deception, and to anticipate deceptive abilities in LLMs.", "published": "2025-04-05 06:09:32", "link": "http://arxiv.org/abs/2504.04072v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Enforcement Agents: Enhancing Accountability and Resilience in Multi-Agent AI Frameworks", "abstract": "As autonomous agents become more powerful and widely used, it is becoming\nincreasingly important to ensure they behave safely and stay aligned with\nsystem goals, especially in multi-agent settings. Current systems often rely on\nagents self-monitoring or correcting issues after the fact, but they lack\nmechanisms for real-time oversight. This paper introduces the Enforcement Agent\n(EA) Framework, which embeds dedicated supervisory agents into the environment\nto monitor others, detect misbehavior, and intervene through real-time\ncorrection. We implement this framework in a custom drone simulation and\nevaluate it across 90 episodes using 0, 1, and 2 EA configurations. Results\nshow that adding EAs significantly improves system safety: success rates rise\nfrom 0.0% with no EA to 7.4% with one EA and 26.7% with two EAs. The system\nalso demonstrates increased operational longevity and higher rates of malicious\ndrone reformation. These findings highlight the potential of lightweight,\nreal-time supervision for enhancing alignment and resilience in multi-agent\nsystems.", "published": "2025-04-05 06:07:10", "link": "http://arxiv.org/abs/2504.04070v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "Mapping at First Sense: A Lightweight Neural Network-Based Indoor Structures Prediction Method for Robot Autonomous Exploration", "abstract": "Autonomous exploration in unknown environments is a critical challenge in\nrobotics, particularly for applications such as indoor navigation, search and\nrescue, and service robotics. Traditional exploration strategies, such as\nfrontier-based methods, often struggle to efficiently utilize prior knowledge\nof structural regularities in indoor spaces. To address this limitation, we\npropose Mapping at First Sense, a lightweight neural network-based approach\nthat predicts unobserved areas in local maps, thereby enhancing exploration\nefficiency. The core of our method, SenseMapNet, integrates convolutional and\ntransformerbased architectures to infer occluded regions while maintaining\ncomputational efficiency for real-time deployment on resourceconstrained\nrobots. Additionally, we introduce SenseMapDataset, a curated dataset\nconstructed from KTH and HouseExpo environments, which facilitates training and\nevaluation of neural models for indoor exploration. Experimental results\ndemonstrate that SenseMapNet achieves an SSIM (structural similarity) of 0.78,\nLPIPS (perceptual quality) of 0.68, and an FID (feature distribution alignment)\nof 239.79, outperforming conventional methods in map reconstruction quality.\nCompared to traditional frontier-based exploration, our method reduces\nexploration time by 46.5% (from 2335.56s to 1248.68s) while maintaining a high\ncoverage rate (88%) and achieving a reconstruction accuracy of 88%. The\nproposed method represents a promising step toward efficient, learning-driven\nrobotic exploration in structured environments.", "published": "2025-04-05 05:19:09", "link": "http://arxiv.org/abs/2504.04061v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "PIORF: Physics-Informed Ollivier-Ricci Flow for Long-Range Interactions in Mesh Graph Neural Networks", "abstract": "Recently, data-driven simulators based on graph neural networks have gained\nattention in modeling physical systems on unstructured meshes. However, they\nstruggle with long-range dependencies in fluid flows, particularly in refined\nmesh regions. This challenge, known as the 'over-squashing' problem, hinders\ninformation propagation. While existing graph rewiring methods address this\nissue to some extent, they only consider graph topology, overlooking the\nunderlying physical phenomena. We propose Physics-Informed Ollivier-Ricci Flow\n(PIORF), a novel rewiring method that combines physical correlations with graph\ntopology. PIORF uses Ollivier-Ricci curvature (ORC) to identify bottleneck\nregions and connects these areas with nodes in high-velocity gradient nodes,\nenabling long-range interactions and mitigating over-squashing. Our approach is\ncomputationally efficient in rewiring edges and can scale to larger\nsimulations. Experimental results on 3 fluid dynamics benchmark datasets show\nthat PIORF consistently outperforms baseline models and existing rewiring\nmethods, achieving up to 26.2 improvement.", "published": "2025-04-05 04:14:05", "link": "http://arxiv.org/abs/2504.04052v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Can You Count to Nine? A Human Evaluation Benchmark for Counting Limits in Modern Text-to-Video Models", "abstract": "Generative models have driven significant progress in a variety of AI tasks,\nincluding text-to-video generation, where models like Video LDM and Stable\nVideo Diffusion can produce realistic, movie-level videos from textual\ninstructions. Despite these advances, current text-to-video models still face\nfundamental challenges in reliably following human commands, particularly in\nadhering to simple numerical constraints. In this work, we present\nT2VCountBench, a specialized benchmark aiming at evaluating the counting\ncapability of SOTA text-to-video models as of 2025. Our benchmark employs\nrigorous human evaluations to measure the number of generated objects and\ncovers a diverse range of generators, covering both open-source and commercial\nmodels. Extensive experiments reveal that all existing models struggle with\nbasic numerical tasks, almost always failing to generate videos with an object\ncount of 9 or fewer. Furthermore, our comprehensive ablation studies explore\nhow factors like video style, temporal dynamics, and multilingual inputs may\ninfluence counting performance. We also explore prompt refinement techniques\nand demonstrate that decomposing the task into smaller subtasks does not easily\nalleviate these limitations. Our findings highlight important challenges in\ncurrent text-to-video generation and provide insights for future research aimed\nat improving adherence to basic numerical constraints.", "published": "2025-04-05 04:13:06", "link": "http://arxiv.org/abs/2504.04051v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "A Survey of Pathology Foundation Model: Progress and Future Directions", "abstract": "Computational pathology, analyzing whole slide images for automated cancer\ndiagnosis, relies on the multiple instance learning framework where performance\nheavily depends on the feature extractor and aggregator. Recent Pathology\nFoundation Models (PFMs), pretrained on large-scale histopathology data, have\nsignificantly enhanced capabilities of extractors and aggregators but lack\nsystematic analysis frameworks. This survey presents a hierarchical taxonomy\norganizing PFMs through a top-down philosophy that can be utilized to analyze\nFMs in any domain: model scope, model pretraining, and model design.\nAdditionally, we systematically categorize PFM evaluation tasks into\nslide-level, patch-level, multimodal, and biological tasks, providing\ncomprehensive benchmarking criteria. Our analysis identifies critical\nchallenges in both PFM development (pathology-specific methodology, end-to-end\npretraining, data-model scalability) and utilization (effective adaptation,\nmodel maintenance), paving the way for future directions in this promising\nfield. Resources referenced in this survey are available at\nhttps://github.com/BearCleverProud/AwesomeWSI.", "published": "2025-04-05 03:44:09", "link": "http://arxiv.org/abs/2504.04045v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "ADAPT: Actively Discovering and Adapting to Preferences for any Task", "abstract": "Assistive agents should be able to perform under-specified long-horizon tasks\nwhile respecting user preferences. We introduce Actively Discovering and\nAdapting to Preferences for any Task (ADAPT) -- a benchmark designed to\nevaluate agents' ability to adhere to user preferences across various household\ntasks through active questioning. Next, we propose Reflection-DPO, a novel\ntraining approach for adapting large language models (LLMs) to the task of\nactive questioning. Reflection-DPO finetunes a 'student' LLM to follow the\nactions of a privileged 'teacher' LLM, and optionally ask a question to gather\nnecessary information to better predict the teacher action. We find that prior\napproaches that use state-of-the-art LLMs fail to sufficiently follow user\npreferences in ADAPT due to insufficient questioning and poor adherence to\nelicited preferences. In contrast, Reflection-DPO achieves a higher rate of\nsatisfying user preferences, outperforming a zero-shot chain-of-thought\nbaseline by 6.1% on unseen users.", "published": "2025-04-05 03:16:22", "link": "http://arxiv.org/abs/2504.04040v1", "categories": ["cs.AI", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Memory-Statistics Tradeoff in Continual Learning with Structural Regularization", "abstract": "We study the statistical performance of a continual learning problem with two\nlinear regression tasks in a well-specified random design setting. We consider\na structural regularization algorithm that incorporates a generalized\n$\\ell_2$-regularization tailored to the Hessian of the previous task for\nmitigating catastrophic forgetting. We establish upper and lower bounds on the\njoint excess risk for this algorithm. Our analysis reveals a fundamental\ntrade-off between memory complexity and statistical efficiency, where memory\ncomplexity is measured by the number of vectors needed to define the structural\nregularization. Specifically, increasing the number of vectors in structural\nregularization leads to a worse memory complexity but an improved excess risk,\nand vice versa. Furthermore, our theory suggests that naive continual learning\nwithout regularization suffers from catastrophic forgetting, while structural\nregularization mitigates this issue. Notably, structural regularization\nachieves comparable performance to joint training with access to both tasks\nsimultaneously. These results highlight the critical role of curvature-aware\nregularization for continual learning.", "published": "2025-04-05 03:14:10", "link": "http://arxiv.org/abs/2504.04039v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Contrastive and Variational Approaches in Self-Supervised Learning for Complex Data Mining", "abstract": "Complex data mining has wide application value in many fields, especially in\nthe feature extraction and classification tasks of unlabeled data. This paper\nproposes an algorithm based on self-supervised learning and verifies its\neffectiveness through experiments. The study found that in terms of the\nselection of optimizer and learning rate, the combination of AdamW optimizer\nand 0.002 learning rate performed best in all evaluation indicators, indicating\nthat the adaptive optimization method can improve the performance of the model\nin complex data mining tasks. In addition, the ablation experiment further\nanalyzed the contribution of each module. The results show that contrastive\nlearning, variational modules, and data augmentation strategies play a key role\nin the generalization ability and robustness of the model. Through the\nconvergence curve analysis of the loss function, the experiment verifies that\nthe method can converge stably during the training process and effectively\navoid serious overfitting. Further experimental results show that the model has\nstrong adaptability on different data sets, can effectively extract\nhigh-quality features from unlabeled data, and improves classification\naccuracy. At the same time, under different data distribution conditions, the\nmethod can still maintain high detection accuracy, proving its applicability in\ncomplex data environments. This study analyzed the role of self-supervised\nlearning methods in complex data mining through systematic experiments and\nverified its advantages in improving feature extraction quality, optimizing\nclassification performance, and enhancing model stability", "published": "2025-04-05 02:55:44", "link": "http://arxiv.org/abs/2504.04032v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Simultaneous Motion And Noise Estimation with Event Cameras", "abstract": "Event cameras are emerging vision sensors, whose noise is challenging to\ncharacterize. Existing denoising methods for event cameras consider other tasks\nsuch as motion estimation separately (i.e., sequentially after denoising).\nHowever, motion is an intrinsic part of event data, since scene edges cannot be\nsensed without motion. This work proposes, to the best of our knowledge, the\nfirst method that simultaneously estimates motion in its various forms (e.g.,\nego-motion, optical flow) and noise. The method is flexible, as it allows\nreplacing the 1-step motion estimation of the widely-used Contrast Maximization\nframework with any other motion estimator, such as deep neural networks. The\nexperiments show that the proposed method achieves state-of-the-art results on\nthe E-MLB denoising benchmark and competitive results on the DND21 benchmark,\nwhile showing its efficacy on motion estimation and intensity reconstruction\ntasks. We believe that the proposed approach contributes to strengthening the\ntheory of event-data denoising, as well as impacting practical denoising\nuse-cases, as we release the code upon acceptance. Project page:\nhttps://github.com/tub-rip/ESMD", "published": "2025-04-05 02:47:40", "link": "http://arxiv.org/abs/2504.04029v1", "categories": ["cs.CV", "cs.AI", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Foundation Models for Time Series: A Survey", "abstract": "Transformer-based foundation models have emerged as a dominant paradigm in\ntime series analysis, offering unprecedented capabilities in tasks such as\nforecasting, anomaly detection, classification, trend analysis and many more\ntime series analytical tasks. This survey provides a comprehensive overview of\nthe current state of the art pre-trained foundation models, introducing a novel\ntaxonomy to categorize them across several dimensions. Specifically, we\nclassify models by their architecture design, distinguishing between those\nleveraging patch-based representations and those operating directly on raw\nsequences. The taxonomy further includes whether the models provide\nprobabilistic or deterministic predictions, and whether they are designed to\nwork with univariate time series or can handle multivariate time series out of\nthe box. Additionally, the taxonomy encompasses model scale and complexity,\nhighlighting differences between lightweight architectures and large-scale\nfoundation models. A unique aspect of this survey is its categorization by the\ntype of objective function employed during training phase. By synthesizing\nthese perspectives, this survey serves as a resource for researchers and\npractitioners, providing insights into current trends and identifying promising\ndirections for future research in transformer-based time series modeling.", "published": "2025-04-05 01:27:55", "link": "http://arxiv.org/abs/2504.04011v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Edge Approximation Text Detector", "abstract": "Pursuing efficient text shape representations helps scene text detection\nmodels focus on compact foreground regions and optimize the contour\nreconstruction steps to simplify the whole detection pipeline. Current\napproaches either represent irregular shapes via box-to-polygon strategy or\ndecomposing a contour into pieces for fitting gradually, the deficiency of\ncoarse contours or complex pipelines always exists in these models. Considering\nthe above issues, we introduce EdgeText to fit text contours compactly while\nalleviating excessive contour rebuilding processes. Concretely, it is observed\nthat the two long edges of texts can be regarded as smooth curves. It allows us\nto build contours via continuous and smooth edges that cover text regions\ntightly instead of fitting piecewise, which helps avoid the two limitations in\ncurrent models. Inspired by this observation, EdgeText formulates the text\nrepresentation as the edge approximation problem via parameterized curve\nfitting functions. In the inference stage, our model starts with locating text\ncenters, and then creating curve functions for approximating text edges relying\non the points. Meanwhile, truncation points are determined based on the\nlocation features. In the end, extracting curve segments from curve functions\nby using the pixel coordinate information brought by truncation points to\nreconstruct text contours. Furthermore, considering the deep dependency of\nEdgeText on text edges, a bilateral enhanced perception (BEP) module is\ndesigned. It encourages our model to pay attention to the recognition of edge\nfeatures. Additionally, to accelerate the learning of the curve function\nparameters, we introduce a proportional integral loss (PI-loss) to force the\nproposed model to focus on the curve distribution and avoid being disturbed by\ntext scales.", "published": "2025-04-05 00:12:51", "link": "http://arxiv.org/abs/2504.04001v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "3R-GS: Best Practice in Optimizing Camera Poses Along with 3DGS", "abstract": "3D Gaussian Splatting (3DGS) has revolutionized neural rendering with its\nefficiency and quality, but like many novel view synthesis methods, it heavily\ndepends on accurate camera poses from Structure-from-Motion (SfM) systems.\nAlthough recent SfM pipelines have made impressive progress, questions remain\nabout how to further improve both their robust performance in challenging\nconditions (e.g., textureless scenes) and the precision of camera parameter\nestimation simultaneously. We present 3R-GS, a 3D Gaussian Splatting framework\nthat bridges this gap by jointly optimizing 3D Gaussians and camera parameters\nfrom large reconstruction priors MASt3R-SfM. We note that naively performing\njoint 3D Gaussian and camera optimization faces two challenges: the sensitivity\nto the quality of SfM initialization, and its limited capacity for global\noptimization, leading to suboptimal reconstruction results. Our 3R-GS,\novercomes these issues by incorporating optimized practices, enabling robust\nscene reconstruction even with imperfect camera registration. Extensive\nexperiments demonstrate that 3R-GS delivers high-quality novel view synthesis\nand precise camera pose estimation while remaining computationally efficient.\nProject page: https://zsh523.github.io/3R-GS/", "published": "2025-04-05 22:31:08", "link": "http://arxiv.org/abs/2504.04294v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ADA-Net: Attention-Guided Domain Adaptation Network with Contrastive Learning for Standing Dead Tree Segmentation Using Aerial Imagery", "abstract": "Information on standing dead trees is important for understanding forest\necosystem functioning and resilience but has been lacking over large geographic\nregions. Climate change has caused large-scale tree mortality events that can\nremain undetected due to limited data. In this study, we propose a novel method\nfor segmenting standing dead trees using aerial multispectral orthoimages.\nBecause access to annotated datasets has been a significant problem in forest\nremote sensing due to the need for forest expertise, we introduce a method for\ndomain transfer by leveraging domain adaptation to learn a transformation from\na source domain X to target domain Y. In this Image-to-Image translation task,\nwe aim to utilize available annotations in the target domain by pre-training a\nsegmentation network. When images from a new study site without annotations are\nintroduced (source domain X), these images are transformed into the target\ndomain. Then, transfer learning is applied by inferring the pre-trained network\non domain-adapted images. In addition to investigating the feasibility of\ncurrent domain adaptation approaches for this objective, we propose a novel\napproach called the Attention-guided Domain Adaptation Network (ADA-Net) with\nenhanced contrastive learning. Accordingly, the ADA-Net approach provides new\nstate-of-the-art domain adaptation performance levels outperforming existing\napproaches. We have evaluated the proposed approach using two datasets from\nFinland and the US. The USA images are converted to the Finland domain, and we\nshow that the synthetic USA2Finland dataset exhibits similar characteristics to\nthe Finland domain images. The software implementation is shared at\nhttps://github.com/meteahishali/ADA-Net. The data is publicly available at\nhttps://www.kaggle.com/datasets/meteahishali/aerial-imagery-for-standing-dead-tree-segmentation.", "published": "2025-04-05 19:55:02", "link": "http://arxiv.org/abs/2504.04271v1", "categories": ["cs.CV", "cs.LG", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Loss Functions in Deep Learning: A Comprehensive Review", "abstract": "Loss functions are at the heart of deep learning, shaping how models learn\nand perform across diverse tasks. They are used to quantify the difference\nbetween predicted outputs and ground truth labels, guiding the optimization\nprocess to minimize errors. Selecting the right loss function is critical, as\nit directly impacts model convergence, generalization, and overall performance\nacross various applications, from computer vision to time series forecasting.\nThis paper presents a comprehensive review of loss functions, covering\nfundamental metrics like Mean Squared Error and Cross-Entropy to advanced\nfunctions such as Adversarial and Diffusion losses. We explore their\nmathematical foundations, impact on model training, and strategic selection for\nvarious applications, including computer vision (Discriminative and\ngenerative), tabular data prediction, and time series forecasting. For each of\nthese categories, we discuss the most used loss functions in the recent\nadvancements of deep learning techniques. Also, this review explore the\nhistorical evolution, computational efficiency, and ongoing challenges in loss\nfunction design, underlining the need for more adaptive and robust solutions.\nEmphasis is placed on complex scenarios involving multi-modal data, class\nimbalances, and real-world constraints. Finally, we identify key future\ndirections, advocating for loss functions that enhance interpretability,\nscalability, and generalization, leading to more effective and resilient deep\nlearning models.", "published": "2025-04-05 18:07:20", "link": "http://arxiv.org/abs/2504.04242v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Autoregressive High-Order Finite Difference Modulo Imaging: High-Dynamic Range for Computer Vision Applications", "abstract": "High dynamic range (HDR) imaging is vital for capturing the full range of\nlight tones in scenes, essential for computer vision tasks such as autonomous\ndriving. Standard commercial imaging systems face limitations in capacity for\nwell depth, and quantization precision, hindering their HDR capabilities.\nModulo imaging, based on unlimited sampling (US) theory, addresses these\nlimitations by using a modulo analog-to-digital approach that resets signals\nupon saturation, enabling estimation of pixel resets through neighboring pixel\nintensities. Despite the effectiveness of (US) algorithms in one-dimensional\nsignals, their optimization problem for two-dimensional signals remains\nunclear. This work formulates the US framework as an autoregressive $\\ell_2$\nphase unwrapping problem, providing computationally efficient solutions in the\ndiscrete cosine domain jointly with a stride removal algorithm also based on\nspatial differences. By leveraging higher-order finite differences for\ntwo-dimensional images, our approach enhances HDR image reconstruction from\nmodulo images, demonstrating its efficacy in improving object detection in\nautonomous driving scenes without retraining.", "published": "2025-04-05 16:41:15", "link": "http://arxiv.org/abs/2504.04228v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Resilience of Vision Transformers for Domain Generalisation in the Presence of Out-of-Distribution Noisy Images", "abstract": "Modern AI models excel in controlled settings but often fail in real-world\nscenarios where data distributions shift unpredictably - a challenge known as\ndomain generalisation (DG). This paper tackles this limitation by rigorously\nevaluating vision tramsformers, specifically the BEIT architecture which is a\nmodel pre-trained with masked image modelling (MIM), against synthetic\nout-of-distribution (OOD) benchmarks designed to mimic real-world noise and\nocclusions. We introduce a novel framework to generate OOD test cases by\nstrategically masking object regions in images using grid patterns (25\\%, 50\\%,\n75\\% occlusion) and leveraging cutting-edge zero-shot segmentation via Segment\nAnything and Grounding DINO to ensure precise object localisation. Experiments\nacross three benchmarks (PACS, Office-Home, DomainNet) demonstrate BEIT's known\nrobustness while maintaining 94\\% accuracy on PACS and 87\\% on Office-Home,\ndespite significant occlusions, outperforming CNNs and other vision\ntransformers by margins of up to 37\\%. Analysis of self-attention distances\nreveals that the BEIT dependence on global features correlates with its\nresilience. Furthermore, our synthetic benchmarks expose critical failure\nmodes: performance degrades sharply when occlusions disrupt object shapes e.g.\n68\\% drop for external grid masking vs. 22\\% for internal masking. This work\nprovides two key advances (1) a scalable method to generate OOD benchmarks\nusing controllable noise, and (2) empirical evidence that MIM and\nself-attention mechanism in vision transformers enhance DG by learning\ninvariant features. These insights bridge the gap between lab-trained models\nand real-world deployment that offer a blueprint for building AI systems that\ngeneralise reliably under uncertainty.", "published": "2025-04-05 16:25:34", "link": "http://arxiv.org/abs/2504.04225v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Evaluating Graphical Perception with Multimodal LLMs", "abstract": "Multimodal Large Language Models (MLLMs) have remarkably progressed in\nanalyzing and understanding images. Despite these advancements, accurately\nregressing values in charts remains an underexplored area for MLLMs. For\nvisualization, how do MLLMs perform when applied to graphical perception tasks?\nOur paper investigates this question by reproducing Cleveland and McGill's\nseminal 1984 experiment and comparing it against human task performance. Our\nstudy primarily evaluates fine-tuned and pretrained models and zero-shot\nprompting to determine if they closely match human graphical perception. Our\nfindings highlight that MLLMs outperform human task performance in some cases\nbut not in others. We highlight the results of all experiments to foster an\nunderstanding of where MLLMs succeed and fail when applied to data\nvisualization.", "published": "2025-04-05 16:14:08", "link": "http://arxiv.org/abs/2504.04221v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "The Effects of Grouped Structural Global Pruning of Vision Transformers on Domain Generalisation", "abstract": "With the growing sizes of AI models like large language models (LLMs) and\nvision transformers, deploying them on devices with limited computational\nresources is a significant challenge particularly when addressing domain\ngeneralisation (DG) tasks. This paper introduces a novel grouped structural\npruning method for pre-trained vision transformers (ViT, BeiT, and DeiT),\nevaluated on the PACS and Office-Home DG benchmarks. Our method uses dependency\ngraph analysis to identify and remove redundant groups of neurons, weights,\nfilters, or attention heads within transformers, using a range of selection\nmetrics. Grouped structural pruning is applied at pruning ratios of 50\\%, 75\\%\nand 95\\% and the models are then fine-tuned on selected distributions from DG\nbenchmarks to evaluate their overall performance in DG tasks. Results show\nsignificant improvements in inference speed and fine-tuning time with minimal\ntrade-offs in accuracy and DG task performance. For instance, on the PACS\nbenchmark, pruning ViT, BeiT, and DeiT models by 50\\% using the Hessian metric\nresulted in accuracy drops of only -2.94\\%, -1.42\\%, and -1.72\\%, respectively,\nwhile achieving speed boosts of 2.5x, 1.81x, and 2.15x. These findings\ndemonstrate the effectiveness of our approach in balancing model efficiency\nwith domain generalisation performance.", "published": "2025-04-05 15:05:36", "link": "http://arxiv.org/abs/2504.04196v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "GROVE: A Generalized Reward for Learning Open-Vocabulary Physical Skill", "abstract": "Learning open-vocabulary physical skills for simulated agents presents a\nsignificant challenge in artificial intelligence. Current reinforcement\nlearning approaches face critical limitations: manually designed rewards lack\nscalability across diverse tasks, while demonstration-based methods struggle to\ngeneralize beyond their training distribution. We introduce GROVE, a\ngeneralized reward framework that enables open-vocabulary physical skill\nlearning without manual engineering or task-specific demonstrations. Our key\ninsight is that Large Language Models(LLMs) and Vision Language Models(VLMs)\nprovide complementary guidance -- LLMs generate precise physical constraints\ncapturing task requirements, while VLMs evaluate motion semantics and\nnaturalness. Through an iterative design process, VLM-based feedback\ncontinuously refines LLM-generated constraints, creating a self-improving\nreward system. To bridge the domain gap between simulation and natural images,\nwe develop Pose2CLIP, a lightweight mapper that efficiently projects agent\nposes directly into semantic feature space without computationally expensive\nrendering. Extensive experiments across diverse embodiments and learning\nparadigms demonstrate GROVE's effectiveness, achieving 22.2% higher motion\nnaturalness and 25.7% better task completion scores while training 8.4x faster\nthan previous methods. These results establish a new foundation for scalable\nphysical skill acquisition in simulated environments.", "published": "2025-04-05 14:44:47", "link": "http://arxiv.org/abs/2504.04191v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Interpretable Single-View 3D Gaussian Splatting using Unsupervised Hierarchical Disentangled Representation Learning", "abstract": "Gaussian Splatting (GS) has recently marked a significant advancement in 3D\nreconstruction, delivering both rapid rendering and high-quality results.\nHowever, existing 3DGS methods pose challenges in understanding underlying 3D\nsemantics, which hinders model controllability and interpretability. To address\nit, we propose an interpretable single-view 3DGS framework, termed 3DisGS, to\ndiscover both coarse- and fine-grained 3D semantics via hierarchical\ndisentangled representation learning (DRL). Specifically, the model employs a\ndual-branch architecture, consisting of a point cloud initialization branch and\na triplane-Gaussian generation branch, to achieve coarse-grained\ndisentanglement by separating 3D geometry and visual appearance features.\nSubsequently, fine-grained semantic representations within each modality are\nfurther discovered through DRL-based encoder-adapters. To our knowledge, this\nis the first work to achieve unsupervised interpretable 3DGS. Evaluations\nindicate that our model achieves 3D disentanglement while preserving\nhigh-quality and rapid reconstruction.", "published": "2025-04-05 14:42:13", "link": "http://arxiv.org/abs/2504.04190v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SDEIT: Semantic-Driven Electrical Impedance Tomography", "abstract": "Regularization methods using prior knowledge are essential in solving\nill-posed inverse problems such as Electrical Impedance Tomography (EIT).\nHowever, designing effective regularization and integrating prior information\ninto EIT remains challenging due to the complexity and variability of\nanatomical structures. In this work, we introduce SDEIT, a novel\nsemantic-driven framework that integrates Stable Diffusion 3.5 into EIT,\nmarking the first use of large-scale text-to-image generation models in EIT.\nSDEIT employs natural language prompts as semantic priors to guide the\nreconstruction process. By coupling an implicit neural representation (INR)\nnetwork with a plug-and-play optimization scheme that leverages SD-generated\nimages as generative priors, SDEIT improves structural consistency and recovers\nfine details. Importantly, this method does not rely on paired training\ndatasets, increasing its adaptability to varied EIT scenarios. Extensive\nexperiments on both simulated and experimental data demonstrate that SDEIT\noutperforms state-of-the-art techniques, offering superior accuracy and\nrobustness. This work opens a new pathway for integrating multimodal priors\ninto ill-posed inverse problems like EIT.", "published": "2025-04-05 14:08:58", "link": "http://arxiv.org/abs/2504.04185v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "JarvisIR: Elevating Autonomous Driving Perception with Intelligent Image Restoration", "abstract": "Vision-centric perception systems struggle with unpredictable and coupled\nweather degradations in the wild. Current solutions are often limited, as they\neither depend on specific degradation priors or suffer from significant domain\ngaps. To enable robust and autonomous operation in real-world conditions, we\npropose JarvisIR, a VLM-powered agent that leverages the VLM as a controller to\nmanage multiple expert restoration models. To further enhance system\nrobustness, reduce hallucinations, and improve generalizability in real-world\nadverse weather, JarvisIR employs a novel two-stage framework consisting of\nsupervised fine-tuning and human feedback alignment. Specifically, to address\nthe lack of paired data in real-world scenarios, the human feedback alignment\nenables the VLM to be fine-tuned effectively on large-scale real-world data in\nan unsupervised manner. To support the training and evaluation of JarvisIR, we\nintroduce CleanBench, a comprehensive dataset consisting of high-quality and\nlarge-scale instruction-responses pairs, including 150K synthetic entries and\n80K real entries. Extensive experiments demonstrate that JarvisIR exhibits\nsuperior decision-making and restoration capabilities. Compared with existing\nmethods, it achieves a 50% improvement in the average of all perception metrics\non CleanBench-Real. Project page: https://cvpr2025-jarvisir.github.io/.", "published": "2025-04-05 12:38:55", "link": "http://arxiv.org/abs/2504.04158v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CoMBO: Conflict Mitigation via Branched Optimization for Class Incremental Segmentation", "abstract": "Effective Class Incremental Segmentation (CIS) requires simultaneously\nmitigating catastrophic forgetting and ensuring sufficient plasticity to\nintegrate new classes. The inherent conflict above often leads to a\nback-and-forth, which turns the objective into finding the balance between the\nperformance of previous~(old) and incremental~(new) classes. To address this\nconflict, we introduce a novel approach, Conflict Mitigation via Branched\nOptimization~(CoMBO). Within this approach, we present the Query Conflict\nReduction module, designed to explicitly refine queries for new classes through\nlightweight, class-specific adapters. This module provides an additional branch\nfor the acquisition of new classes while preserving the original queries for\ndistillation. Moreover, we develop two strategies to further mitigate the\nconflict following the branched structure, \\textit{i.e.}, the Half-Learning\nHalf-Distillation~(HDHL) over classification probabilities, and the\nImportance-Based Knowledge Distillation~(IKD) over query features. HDHL\nselectively engages in learning for classification probabilities of queries\nthat match the ground truth of new classes, while aligning unmatched ones to\nthe corresponding old probabilities, thus ensuring retention of old knowledge\nwhile absorbing new classes via learning negative samples. Meanwhile, IKD\nassesses the importance of queries based on their matching degree to old\nclasses, prioritizing the distillation of important features and allowing less\ncritical features to evolve. Extensive experiments in Class Incremental\nPanoptic and Semantic Segmentation settings have demonstrated the superior\nperformance of CoMBO. Project page: https://guangyu-ryan.github.io/CoMBO.", "published": "2025-04-05 12:34:51", "link": "http://arxiv.org/abs/2504.04156v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Video4DGen: Enhancing Video and 4D Generation through Mutual Optimization", "abstract": "The advancement of 4D (i.e., sequential 3D) generation opens up new\npossibilities for lifelike experiences in various applications, where users can\nexplore dynamic objects or characters from any viewpoint. Meanwhile, video\ngenerative models are receiving particular attention given their ability to\nproduce realistic and imaginative frames. These models are also observed to\nexhibit strong 3D consistency, indicating the potential to act as world\nsimulators. In this work, we present Video4DGen, a novel framework that excels\nin generating 4D representations from single or multiple generated videos as\nwell as generating 4D-guided videos. This framework is pivotal for creating\nhigh-fidelity virtual contents that maintain both spatial and temporal\ncoherence. The 4D outputs generated by Video4DGen are represented using our\nproposed Dynamic Gaussian Surfels (DGS), which optimizes time-varying warping\nfunctions to transform Gaussian surfels (surface elements) from a static state\nto a dynamically warped state. We design warped-state geometric regularization\nand refinements on Gaussian surfels, to preserve the structural integrity and\nfine-grained appearance details. To perform 4D generation from multiple videos\nand capture representation across spatial, temporal, and pose dimensions, we\ndesign multi-video alignment, root pose optimization, and pose-guided frame\nsampling strategies. The leveraging of continuous warping fields also enables a\nprecise depiction of pose, motion, and deformation over per-video frames.\nFurther, to improve the overall fidelity from the observation of all camera\nposes, Video4DGen performs novel-view video generation guided by the 4D\ncontent, with the proposed confidence-filtered DGS to enhance the quality of\ngenerated sequences. With the ability of 4D and video generation, Video4DGen\noffers a powerful tool for applications in virtual reality, animation, and\nbeyond.", "published": "2025-04-05 12:13:05", "link": "http://arxiv.org/abs/2504.04153v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Scaling Federated Learning Solutions with Kubernetes for Synthesizing Histopathology Images", "abstract": "In the field of deep learning, large architectures often obtain the best\nperformance for many tasks, but also require massive datasets. In the\nhistological domain, tissue images are expensive to obtain and constitute\nsensitive medical information, raising concerns about data scarcity and\nprivacy. Vision Transformers are state-of-the-art computer vision models that\nhave proven helpful in many tasks, including image classification. In this\nwork, we combine vision Transformers with generative adversarial networks to\ngenerate histopathological images related to colorectal cancer and test their\nquality by augmenting a training dataset, leading to improved classification\naccuracy. Then, we replicate this performance using the federated learning\ntechnique and a realistic Kubernetes setup with multiple nodes, simulating a\nscenario where the training dataset is split among several hospitals unable to\nshare their information directly due to privacy concerns.", "published": "2025-04-05 10:32:56", "link": "http://arxiv.org/abs/2504.04130v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "EMF: Event Meta Formers for Event-based Real-time Traffic Object Detection", "abstract": "Event cameras have higher temporal resolution, and require less storage and\nbandwidth compared to traditional RGB cameras. However, due to relatively\nlagging performance of event-based approaches, event cameras have not yet\nreplace traditional cameras in performance-critical applications like\nautonomous driving. Recent approaches in event-based object detection try to\nbridge this gap by employing computationally expensive transformer-based\nsolutions. However, due to their resource-intensive components, these solutions\nfail to exploit the sparsity and higher temporal resolution of event cameras\nefficiently. Moreover, these solutions are adopted from the vision domain,\nlacking specificity to the event cameras. In this work, we explore efficient\nand performant alternatives to recurrent vision transformer models and propose\na novel event-based object detection backbone. The proposed backbone employs a\nnovel Event Progression Extractor module, tailored specifically for event data,\nand uses Metaformer concept with convolution-based efficient components. We\nevaluate the resultant model on well-established traffic object detection\nbenchmarks and conduct cross-dataset evaluation to test its ability to\ngeneralize. The proposed model outperforms the state-of-the-art on Prophesee\nGen1 dataset by 1.6 mAP while reducing inference time by 14%. Our proposed EMF\nbecomes the fastest DNN-based architecture in the domain by outperforming most\nefficient event-based object detectors. Moreover, the proposed model shows\nbetter ability to generalize to unseen data and scales better with the\nabundance of data.", "published": "2025-04-05 09:48:40", "link": "http://arxiv.org/abs/2504.04124v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Overcoming the Identity Mapping Problem in Self-Supervised Hyperspectral Anomaly Detection", "abstract": "The surge of deep learning has catalyzed considerable progress in\nself-supervised Hyperspectral Anomaly Detection (HAD). The core premise for\nself-supervised HAD is that anomalous pixels are inherently more challenging to\nreconstruct, resulting in larger errors compared to the background. However,\nowing to the powerful nonlinear fitting capabilities of neural networks,\nself-supervised models often suffer from the Identity Mapping Problem (IMP).\nThe IMP manifests as a tendency for the model to overfit to the entire image,\nparticularly with increasing network complexity or prolonged training\niterations. Consequently, the whole image can be precisely reconstructed, and\neven the anomalous pixels exhibit imperceptible errors, making them difficult\nto detect. Despite the proposal of several models aimed at addressing the\nIMP-related issues, a unified descriptive framework and validation of solutions\nfor IMP remain lacking. In this paper, we conduct an in-depth exploration to\nIMP, and summarize a unified framework that describes IMP from the perspective\nof network optimization, which encompasses three aspects: perturbation,\nreconstruction, and regularization. Correspondingly, we introduce three\nsolutions: superpixel pooling and uppooling for perturbation, error-adaptive\nconvolution for reconstruction, and online background pixel mining for\nregularization. With extensive experiments being conducted to validate the\neffectiveness, it is hoped that our work will provide valuable insights and\ninspire further research for self-supervised HAD. Code:\n\\url{https://github.com/yc-cui/Super-AD}.", "published": "2025-04-05 09:12:25", "link": "http://arxiv.org/abs/2504.04115v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Performance Analysis of Deep Learning Models for Femur Segmentation in MRI Scan", "abstract": "Convolutional neural networks like U-Net excel in medical image segmentation,\nwhile attention mechanisms and KAN enhance feature extraction. Meta's SAM 2\nuses Vision Transformers for prompt-based segmentation without fine-tuning.\nHowever, biases in these models impact generalization with limited data. In\nthis study, we systematically evaluate and compare the performance of three\nCNN-based models, i.e., U-Net, Attention U-Net, and U-KAN, and one\ntransformer-based model, i.e., SAM 2 for segmenting femur bone structures in\nMRI scan. The dataset comprises 11,164 MRI scans with detailed annotations of\nfemoral regions. Performance is assessed using the Dice Similarity Coefficient,\nwhich ranges from 0.932 to 0.954. Attention U-Net achieves the highest overall\nscores, while U-KAN demonstrated superior performance in anatomical regions\nwith a smaller region of interest, leveraging its enhanced learning capacity to\nimprove segmentation accuracy.", "published": "2025-04-05 05:47:56", "link": "http://arxiv.org/abs/2504.04066v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "UniRVQA: A Unified Framework for Retrieval-Augmented Vision Question Answering via Self-Reflective Joint Training", "abstract": "Knowledge-based Vision Question Answering (KB-VQA) systems address complex\nvisual-grounded questions requiring external knowledge, such as web-sourced\nencyclopedia articles. Existing methods often use sequential and separate\nframeworks for the retriever and the generator with limited parametric\nknowledge sharing. However, since both retrieval and generation tasks require\naccurate understanding of contextual and external information, such separation\ncan potentially lead to suboptimal system performance. Another key challenge is\nthe integration of multimodal information. General-purpose multimodal\npre-trained models, while adept at multimodal representation learning, struggle\nwith fine-grained retrieval required for knowledge-intensive visual questions.\nRecent specialized pre-trained models mitigate the issue, but are\ncomputationally expensive. To bridge the gap, we propose a Unified\nRetrieval-Augmented VQA framework (UniRVQA). UniRVQA adapts general multimodal\npre-trained models for fine-grained knowledge-intensive tasks within a unified\nframework, enabling cross-task parametric knowledge sharing and the extension\nof existing multimodal representation learning capability. We further introduce\na reflective-answering mechanism that allows the model to explicitly evaluate\nand refine its knowledge boundary. Additionally, we integrate late interaction\ninto the retrieval-augmented generation joint training process to enhance\nfine-grained understanding of queries and documents. Our approach achieves\ncompetitive performance against state-of-the-art models, delivering a\nsignificant 4.7% improvement in answering accuracy, and brings an average 7.5%\nboost in base MLLMs' VQA performance.", "published": "2025-04-05 05:42:12", "link": "http://arxiv.org/abs/2504.04065v1", "categories": ["cs.CV", "cs.IR", "cs.MM"], "primary_category": "cs.CV"}
{"title": "UCS: A Universal Model for Curvilinear Structure Segmentation", "abstract": "Curvilinear structure segmentation (CSS) is vital in various domains,\nincluding medical imaging, landscape analysis, industrial surface inspection,\nand plant analysis. While existing methods achieve high performance within\nspecific domains, their generalizability is limited. On the other hand,\nlarge-scale models such as Segment Anything Model (SAM) exhibit strong\ngeneralization but are not optimized for curvilinear structures. Existing\nadaptations of SAM primarily focus on general object segmentation and lack\nspecialized design for CSS tasks. To bridge this gap, we propose the Universal\nCurvilinear structure Segmentation (\\textit{UCS}) model, which adapts SAM to\nCSS tasks while enhancing its generalization. \\textit{UCS} features a novel\nencoder architecture integrating a pretrained SAM encoder with two innovations:\na Sparse Adapter, strategically inserted to inherit the pre-trained SAM\nencoder's generalization capability while minimizing the number of fine-tuning\nparameters, and a Prompt Generation module, which leverages Fast Fourier\nTransform with a high-pass filter to generate curve-specific prompts.\nFurthermore, the \\textit{UCS} incorporates a mask decoder that eliminates\nreliance on manual interaction through a dual-compression module: a\nHierarchical Feature Compression module, which aggregates the outputs of the\nsampled encoder to enhance detail preservation, and a Guidance Feature\nCompression module, which extracts and compresses image-driven guidance\nfeatures. Evaluated on a comprehensive multi-domain dataset, including an\nin-house dataset covering eight natural curvilinear structures, \\textit{UCS}\ndemonstrates state-of-the-art generalization and open-set segmentation\nperformance across medical, engineering, natural, and plant imagery,\nestablishing a new benchmark for universal CSS.", "published": "2025-04-05 03:05:04", "link": "http://arxiv.org/abs/2504.04034v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Artificial intelligence application in lymphoma diagnosis: from Convolutional Neural Network to Vision Transformer", "abstract": "Recently, vision transformers were shown to be capable of outperforming\nconvolutional neural networks when pretrained on sufficiently large datasets.\nVision transformer models show good accuracy on large scale datasets, with\nfeatures of multi-modal training. Due to their promising feature detection, we\naim to explore vision transformer models for diagnosis of anaplastic large cell\nlymphoma versus classical Hodgkin lymphoma using pathology whole slide images\nof HE slides. We compared the classification performance of the vision\ntransformer to our previously designed convolutional neural network on the same\ndataset. The dataset includes whole slide images of HE slides for 20 cases,\nincluding 10 cases in each diagnostic category. From each whole slide image, 60\nimage patches having size of 100 by 100 pixels and at magnification of 20 were\nobtained to yield 1200 image patches, from which 90 percent were used for\ntraining, 9 percent for validation, and 10 percent for testing. The test\nresults from the convolutional neural network model had previously shown an\nexcellent diagnostic accuracy of 100 percent. The test results from the vision\ntransformer model also showed a comparable accuracy at 100 percent. To the best\nof the authors' knowledge, this is the first direct comparison of predictive\nperformance between a vision transformer model and a convolutional neural\nnetwork model using the same dataset of lymphoma. Overall, convolutional neural\nnetwork has a more mature architecture than vision transformer and is usually\nthe best choice when large scale pretraining is not an available option.\nNevertheless, our current study shows comparable and excellent accuracy of\nvision transformer compared to that of convolutional neural network even with a\nrelatively small dataset of anaplastic large cell lymphoma and classical\nHodgkin lymphoma.", "published": "2025-04-05 02:33:34", "link": "http://arxiv.org/abs/2504.04025v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Window Token Concatenation for Efficient Visual Large Language Models", "abstract": "To effectively reduce the visual tokens in Visual Large Language Models\n(VLLMs), we propose a novel approach called Window Token Concatenation (WiCo).\nSpecifically, we employ a sliding window to concatenate spatially adjacent\nvisual tokens. However, directly concatenating these tokens may group diverse\ntokens into one, and thus obscure some fine details. To address this challenge,\nwe propose fine-tuning the last few layers of the vision encoder to adaptively\nadjust the visual tokens, encouraging that those within the same window exhibit\nsimilar features. To further enhance the performance on fine-grained visual\nunderstanding tasks, we introduce WiCo+, which decomposes the visual tokens in\nlater layers of the LLM. Such a design enjoys the merits of the large\nperception field of the LLM for fine-grained visual understanding while keeping\na small number of visual tokens for efficient inference. We perform extensive\nexperiments on both coarse- and fine-grained visual understanding tasks based\non LLaVA-1.5 and Shikra, showing better performance compared with existing\ntoken reduction projectors. The code is available:\nhttps://github.com/JackYFL/WiCo.", "published": "2025-04-05 02:32:58", "link": "http://arxiv.org/abs/2504.04024v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Detection-Friendly Nonuniformity Correction: A Union Framework for Infrared UAVTarget Detection", "abstract": "Infrared unmanned aerial vehicle (UAV) images captured using thermal\ndetectors are often affected by temperature dependent low-frequency\nnonuniformity, which significantly reduces the contrast of the images.\nDetecting UAV targets under nonuniform conditions is crucial in UAV\nsurveillance applications. Existing methods typically treat infrared\nnonuniformity correction (NUC) as a preprocessing step for detection, which\nleads to suboptimal performance. Balancing the two tasks while enhancing\ndetection beneficial information remains challenging. In this paper, we present\na detection-friendly union framework, termed UniCD, that simultaneously\naddresses both infrared NUC and UAV target detection tasks in an end-to-end\nmanner. We first model NUC as a small number of parameter estimation problem\njointly driven by priors and data to generate detection-conducive images. Then,\nwe incorporate a new auxiliary loss with target mask supervision into the\nbackbone of the infrared UAV target detection network to strengthen target\nfeatures while suppressing the background. To better balance correction and\ndetection, we introduce a detection-guided self-supervised loss to reduce\nfeature discrepancies between the two tasks, thereby enhancing detection\nrobustness to varying nonuniformity levels. Additionally, we construct a new\nbenchmark composed of 50,000 infrared images in various nonuniformity types,\nmulti-scale UAV targets and rich backgrounds with target annotations, called\nIRBFD. Extensive experiments on IRBFD demonstrate that our UniCD is a robust\nunion framework for NUC and UAV target detection while achieving real-time\nprocessing capabilities. Dataset can be available at\nhttps://github.com/IVPLaboratory/UniCD.", "published": "2025-04-05 01:29:22", "link": "http://arxiv.org/abs/2504.04012v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "DiTaiListener: Controllable High Fidelity Listener Video Generation with Diffusion", "abstract": "Generating naturalistic and nuanced listener motions for extended\ninteractions remains an open problem. Existing methods often rely on\nlow-dimensional motion codes for facial behavior generation followed by\nphotorealistic rendering, limiting both visual fidelity and expressive\nrichness. To address these challenges, we introduce DiTaiListener, powered by a\nvideo diffusion model with multimodal conditions. Our approach first generates\nshort segments of listener responses conditioned on the speaker's speech and\nfacial motions with DiTaiListener-Gen. It then refines the transitional frames\nvia DiTaiListener-Edit for a seamless transition. Specifically,\nDiTaiListener-Gen adapts a Diffusion Transformer (DiT) for the task of listener\nhead portrait generation by introducing a Causal Temporal Multimodal Adapter\n(CTM-Adapter) to process speakers' auditory and visual cues. CTM-Adapter\nintegrates speakers' input in a causal manner into the video generation process\nto ensure temporally coherent listener responses. For long-form video\ngeneration, we introduce DiTaiListener-Edit, a transition refinement\nvideo-to-video diffusion model. The model fuses video segments into smooth and\ncontinuous videos, ensuring temporal consistency in facial expressions and\nimage quality when merging short video segments produced by DiTaiListener-Gen.\nQuantitatively, DiTaiListener achieves the state-of-the-art performance on\nbenchmark datasets in both photorealism (+73.8% in FID on RealTalk) and motion\nrepresentation (+6.1% in FD metric on VICO) spaces. User studies confirm the\nsuperior performance of DiTaiListener, with the model being the clear\npreference in terms of feedback, diversity, and smoothness, outperforming\ncompetitors by a significant margin.", "published": "2025-04-05 01:19:46", "link": "http://arxiv.org/abs/2504.04010v1", "categories": ["cs.CV", "cs.LG", "I.4.9"], "primary_category": "cs.CV"}
{"title": "View2CAD: Reconstructing View-Centric CAD Models from Single RGB-D Scans", "abstract": "Parametric CAD models, represented as Boundary Representations (B-reps), are\nfoundational to modern design and manufacturing workflows, offering the\nprecision and topological breakdown required for downstream tasks such as\nanalysis, editing, and fabrication. However, B-Reps are often inaccessible due\nto conversion to more standardized, less expressive geometry formats. Existing\nmethods to recover B-Reps from measured data require complete, noise-free 3D\ndata, which are laborious to obtain. We alleviate this difficulty by enabling\nthe precise reconstruction of CAD shapes from a single RGB-D image. We propose\na method that addresses the challenge of reconstructing only the observed\ngeometry from a single view. To allow for these partial observations, and to\navoid hallucinating incorrect geometry, we introduce a novel view-centric B-rep\n(VB-Rep) representation, which incorporates structures to handle visibility\nlimits and encode geometric uncertainty. We combine panoptic image segmentation\nwith iterative geometric optimization to refine and improve the reconstruction\nprocess. Our results demonstrate high-quality reconstruction on synthetic and\nreal RGB-D data, showing that our method can bridge the reality gap.", "published": "2025-04-05 00:10:50", "link": "http://arxiv.org/abs/2504.04000v1", "categories": ["cs.GR", "cs.CV", "I.3.5"], "primary_category": "cs.GR"}
{"title": "Efficient Rejection Sampling in the Entropy-Optimal Range", "abstract": "The problem of generating a random variate $X$ from a finite discrete\nprobability distribution $P$ using an entropy source of independent unbiased\ncoin flips is considered. The Knuth and Yao complexity theory of nonuniform\nrandom number generation furnishes a family of \"entropy-optimal\" sampling\nalgorithms that consume between $H(P)$ and $H(P)+2$ coin flips per generated\noutput, where $H$ is the Shannon entropy function. However, the space\ncomplexity of entropy-optimal samplers scales exponentially with the number of\nbits required to encode $P$. This article introduces a family of efficient\nrejection samplers and characterizes their entropy, space, and time complexity.\nWithin this family is a distinguished sampling algorithm that requires\nlinearithmic space and preprocessing time, and whose expected entropy cost\nalways falls in the entropy-optimal range $[H(P), H(P)+2)$. No previous sampler\nfor discrete probability distributions is known to achieve these\ncharacteristics. Numerical experiments demonstrate performance improvements in\nruntime and entropy of the proposed algorithm compared to the celebrated alias\nmethod.", "published": "2025-04-05 19:45:44", "link": "http://arxiv.org/abs/2504.04267v1", "categories": ["cs.DS", "cs.DM", "cs.IT", "math.IT", "math.PR", "stat.CO"], "primary_category": "cs.DS"}
{"title": "Word-Representability of Well-Partitioned Chordal Graphs", "abstract": "In this paper, we study the word-representability of well-partitioned chordal\ngraphs using split decomposition. We show that every component of the minimal\nsplit decomposition of a well-partitioned chordal graph is a split graph. Thus\nwe have a characterization for word-representability of well-partitioned\nchordal graphs. As a consequence, we prove that the recognition of\nword-representability of well-partitioned chordal graphs can be done in\npolynomial time. Moreover, we prove that the representation number of a\nword-representable well-partitioned chordal graph is at most three. Further, we\nobtain a minimal forbidden induced subgraph characterization of circle graphs\nrestricted to well-partitioned chordal graphs. Accordingly, we determine the\nclass of word-representable well-partitioned chordal graphs having\nrepresentation number exactly three.", "published": "2025-04-05 19:30:25", "link": "http://arxiv.org/abs/2504.04256v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "Short Video Segment-level User Dynamic Interests Modeling in Personalized Recommendation", "abstract": "The rapid growth of short videos has necessitated effective recommender\nsystems to match users with content tailored to their evolving preferences.\nCurrent video recommendation models primarily treat each video as a whole,\noverlooking the dynamic nature of user preferences with specific video\nsegments. In contrast, our research focuses on segment-level user interest\nmodeling, which is crucial for understanding how users' preferences evolve\nduring video browsing. To capture users' dynamic segment interests, we propose\nan innovative model that integrates a hybrid representation module, a\nmulti-modal user-video encoder, and a segment interest decoder. Our model\naddresses the challenges of capturing dynamic interest patterns, missing\nsegment-level labels, and fusing different modalities, achieving precise\nsegment-level interest prediction. We present two downstream tasks to evaluate\nthe effectiveness of our segment interest modeling approach: video-skip\nprediction and short video recommendation. Our experiments on real-world short\nvideo datasets with diverse modalities show promising results on both tasks. It\ndemonstrates that segment-level interest modeling brings a deep understanding\nof user engagement and enhances video recommendations. We also release a unique\ndataset that includes segment-level video data and diverse user behaviors,\nenabling further research in segment-level interest modeling. This work\npioneers a novel perspective on understanding user segment-level preference,\noffering the potential for more personalized and engaging short video\nexperiences.", "published": "2025-04-05 17:45:32", "link": "http://arxiv.org/abs/2504.04237v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Investigating and Mitigating Stereotype-aware Unfairness in LLM-based Recommendations", "abstract": "Large Language Models (LLMs) have demonstrated unprecedented language\nunderstanding and reasoning capabilities to capture diverse user preferences\nand advance personalized recommendations. Despite the growing interest in\nLLM-based personalized recommendations, unique challenges are brought to the\ntrustworthiness of LLM-based recommender systems (LLM-RS), since LLMs are\nlikely to inherit stereotypes that are embedded ubiquitously in word embeddings\ndue to their training on large-scale uncurated datasets. This leads to LLM-RS\nexhibiting stereotypical linguistic associations between users and items.\nHowever, there remains a lack of studies investigating the simultaneous\nexistence of stereotypes between users and items in LLM-RS. To bridge this gap,\nthis study reveals a new variant of fairness between stereotype groups\ncontaining both users and items, to quantify discrimination against stereotypes\nin LLM-RS. Moreover, in this paper, to mitigate stereotype-aware unfairness in\ntextual user and item information, we propose a novel framework (MoS), in which\nan insightful stereotype-wise routing strategy over multiple\nstereotype-relevant experts is designed to learn unbiased representations\nagainst different stereotypes in LLM- RS. Extensive experiments are conducted\nto analyze the influence of stereotype-aware fairness in LLM-RS and the\neffectiveness of our proposed methods, which consistently outperform\ncompetitive benchmarks under various fairness settings.", "published": "2025-04-05 15:09:39", "link": "http://arxiv.org/abs/2504.04199v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "AiReview: An Open Platform for Accelerating Systematic Reviews with LLMs", "abstract": "Systematic reviews are fundamental to evidence-based medicine. Creating one\nis time-consuming and labour-intensive, mainly due to the need to screen, or\nassess, many studies for inclusion in the review. Several tools have been\ndeveloped to streamline this process, mostly relying on traditional machine\nlearning methods. Large language models (LLMs) have shown potential in further\naccelerating the screening process. However, no tool currently allows end users\nto directly leverage LLMs for screening or facilitates systematic and\ntransparent usage of LLM-assisted screening methods. This paper introduces (i)\nan extensible framework for applying LLMs to systematic review tasks,\nparticularly title and abstract screening, and (ii) a web-based interface for\nLLM-assisted screening. Together, these elements form AiReview-a novel platform\nfor LLM-assisted systematic review creation. AiReview is the first of its kind\nto bridge the gap between cutting-edge LLM-assisted screening methods and those\nthat create medical systematic reviews. The tool is available at\nhttps://aireview.ielab.io. The source code is also open sourced at\nhttps://github.com/ielab/ai-review.", "published": "2025-04-05 14:55:43", "link": "http://arxiv.org/abs/2504.04193v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Towards Principled Learning for Re-ranking in Recommender Systems", "abstract": "As the final stage of recommender systems, re-ranking presents ordered item\nlists to users that best match their interests. It plays such a critical role\nand has become a trending research topic with much attention from both academia\nand industry. Recent advances of re-ranking are focused on attentive listwise\nmodeling of interactions and mutual influences among items to be re-ranked.\nHowever, principles to guide the learning process of a re-ranker, and to\nmeasure the quality of the output of the re-ranker, have been always missing.\nIn this paper, we study such principles to learn a good re-ranker. Two\nprinciples are proposed, including convergence consistency and adversarial\nconsistency. These two principles can be applied in the learning of a generic\nre-ranker and improve its performance. We validate such a finding by various\nbaseline methods over different datasets.", "published": "2025-04-05 14:14:36", "link": "http://arxiv.org/abs/2504.04188v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "MSL: Not All Tokens Are What You Need for Tuning LLM as a Recommender", "abstract": "Large language models (LLMs), known for their comprehension capabilities and\nextensive knowledge, have been increasingly applied to recommendation systems\n(RS). Given the fundamental gap between the mechanism of LLMs and the\nrequirement of RS, researchers have focused on fine-tuning LLMs with\nrecommendation-specific data to enhance their performance. Language Modeling\nLoss (LML), originally designed for language generation tasks, is commonly\nadopted. However, we identify two critical limitations of LML: 1) it exhibits\nsignificant divergence from the recommendation objective; 2) it erroneously\ntreats all fictitious item descriptions as negative samples, introducing\nmisleading training signals.\n  To address these limitations, we propose a novel Masked Softmax Loss (MSL)\ntailored for fine-tuning LLMs on recommendation. MSL improves LML by\nidentifying and masking invalid tokens that could lead to fictitious item\ndescriptions during loss computation. This strategy can effectively avoid the\ninterference from erroneous negative signals and ensure well alignment with the\nrecommendation objective supported by theoretical guarantees. During\nimplementation, we identify a potential challenge related to gradient vanishing\nof MSL. To overcome this, we further introduce the temperature coefficient and\npropose an Adaptive Temperature Strategy (ATS) that adaptively adjusts the\ntemperature without requiring extensive hyperparameter tuning. Extensive\nexperiments conducted on four public datasets further validate the\neffectiveness of MSL, achieving an average improvement of 42.24% in NDCG@10.\nThe code is available at https://github.com/WANGBohaO-jpg/MSL.", "published": "2025-04-05 13:48:33", "link": "http://arxiv.org/abs/2504.04178v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "RIS-Empowered Integrated Location Sensing and Communication with Superimposed Pilots", "abstract": "In addition to enhancing wireless communication coverage quality,\nreconfigurable intelligent surface (RIS) technique can also assist in\npositioning. In this work, we consider RIS-assisted superimposed pilot and data\ntransmission without the assumption availability of prior channel state\ninformation and position information of mobile user equipments (UEs). To tackle\nthis challenge, we design a frame structure of transmission protocol composed\nof several location coherence intervals, each with pure-pilot and data-pilot\ntransmission durations. The former is used to estimate UE locations, while the\nlatter is time-slotted, duration of which does not exceed the channel coherence\ntime, where the data and pilot signals are transmitted simultaneously. We\nconduct the Fisher Information matrix (FIM) analysis and derive \\text\n{Cram\\'er-Rao bound} (CRB) for the position estimation error. The inverse fast\nFourier transform (IFFT) is adopted to obtain the estimation results of UE\npositions, which are then exploited for channel estimation. Furthermore, we\nderive the closed-form lower bound of the ergodic achievable rate of\nsuperimposed pilot (SP) transmission, which is used to optimize the phase\nprofile of the RIS to maximize the achievable sum rate using the genetic\nalgorithm. Finally, numerical results validate the accuracy of the UE position\nestimation using the IFFT algorithm and the superiority of the proposed SP\nscheme by comparison with the regular pilot scheme.", "published": "2025-04-05 07:55:17", "link": "http://arxiv.org/abs/2504.04098v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "QE-RAG: A Robust Retrieval-Augmented Generation Benchmark for Query Entry Errors", "abstract": "Retriever-augmented generation (RAG) has become a widely adopted approach for\nenhancing the factual accuracy of large language models (LLMs). While current\nbenchmarks evaluate the performance of RAG methods from various perspectives,\nthey share a common assumption that user queries used for retrieval are\nerror-free. However, in real-world interactions between users and LLMs, query\nentry errors such as keyboard proximity errors, visual similarity errors, and\nspelling errors are frequent. The impact of these errors on current RAG methods\nagainst such errors remains largely unexplored. To bridge this gap, we propose\nQE-RAG, the first robust RAG benchmark designed specifically to evaluate\nperformance against query entry errors. We augment six widely used datasets by\ninjecting three common types of query entry errors into randomly selected user\nqueries at rates of 20\\% and 40\\%, simulating typical user behavior in\nreal-world scenarios. We analyze the impact of these errors on LLM outputs and\nfind that corrupted queries degrade model performance, which can be mitigated\nthrough query correction and training a robust retriever for retrieving\nrelevant documents. Based on these insights, we propose a contrastive\nlearning-based robust retriever training method and a retrieval-augmented query\ncorrection method. Extensive in-domain and cross-domain experiments reveal\nthat: (1) state-of-the-art RAG methods including sequential, branching, and\niterative methods, exhibit poor robustness to query entry errors; (2) our\nmethod significantly enhances the robustness of RAG when handling query entry\nerrors and it's compatible with existing RAG methods, further improving their\nrobustness.", "published": "2025-04-05 05:24:08", "link": "http://arxiv.org/abs/2504.04062v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Joint Optimization of Uplink and Downlink Power in Full-Duplex Integrated Access and Backhaul", "abstract": "We examine the performance of an Integrated Access and Backhaul (IAB) node as\na range extender for beyond-5G networks, focusing on the significant challenges\nof effective power allocation and beamforming strategies, which are vital for\nmaximizing users' spectral efficiency (SE). We present both max-sum SE and\nmax-min fairness power allocation strategies, to assess their effects on system\nperformance. The results underscore the necessity of power optimization,\nparticularly as the number of users served by the IAB node increases,\ndemonstrating how efficient power allocation enhances service quality in\nhigh-load scenarios. The results also show that the typical line-of-sight link\nbetween the IAB donor and the IAB node has rank one, posing a limitation on the\neffective SEs that the IAB node can support.", "published": "2025-04-05 16:58:04", "link": "http://arxiv.org/abs/2504.04232v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Matrix Chernoff concentration bounds for multipartite soft covering and expander walks", "abstract": "We prove Chernoff style exponential concentration bounds for classical\nquantum soft covering generalising previous works which gave bounds only in\nexpectation. Our first result is an exponential concentration bound for fully\nsmooth multipartite classical quantum soft covering, extending\nAhlswede-Winter's seminal result in several important directions. Next, we\nprove a new exponential concentration result for smooth unipartite classical\nquantum soft covering when the samples are taken via a random walk on an\nexpander graph. The resulting expander matrix Chernoff bound complements the\nresults of Garg, Lee, Song and Srivastava in important ways. We prove our new\nexpander matrix Chernoff bound by generalising McDiarmid's method of bounded\ndifferences for functions of independent random variables to a new method of\nbounded excision for functions of expander walks. This new technical tool\nshould be of independent interest.\n  A notable feature of our new concentration bounds is that they have no\nexplicit Hilbert space dimension factor. This is because our bounds are stated\nin terms of the trace distance of the sample averaged quantum state to the\n`ideal' quantum state. Our bounds are sensitive to certain smooth Renyi max\ndivergences, giving a clear handle on the number of samples required to achieve\na target trace distance. Using these novel features, we prove new one shot\ninner bounds for sending private classical information over different kinds of\nquantum wiretap channels with many non-interacting eavesdroppers that are\nindependent of the Hilbert space dimensions of the eavesdroppers. Such powerful\nresults were unknown earlier even in the fully classical setting.", "published": "2025-04-05 05:54:51", "link": "http://arxiv.org/abs/2504.04067v1", "categories": ["quant-ph", "cs.IT", "math.IT", "math.PR"], "primary_category": "quant-ph"}
{"title": "Using ensemble methods of machine learning to predict real estate prices", "abstract": "In recent years, machine learning (ML) techniques have become a powerful tool\nfor improving the accuracy of predictions and decision-making. Machine learning\ntechnologies have begun to penetrate all areas, including the real estate\nsector. Correct forecasting of real estate value plays an important role in the\nbuyer-seller chain, because it ensures reasonableness of price expectations\nbased on the offers available in the market and helps to avoid financial risks\nfor both parties of the transaction. Accurate forecasting is also important for\nreal estate investors to make an informed decision on a specific property. This\nstudy helps to gain a deeper understanding of how effective and accurate\nensemble machine learning methods are in predicting real estate values. The\nresults obtained in the work are quite accurate, as can be seen from the\ncoefficient of determination (R^2), root mean square error (RMSE) and mean\nabsolute error (MAE) calculated for each model. The Gradient Boosting Regressor\nmodel provides the highest accuracy, the Extra Trees Regressor, Hist Gradient\nBoosting Regressor and Random Forest Regressor models give good results. In\ngeneral, ensemble machine learning techniques can be effectively used to solve\nreal estate valuation. This work forms ideas for future research, which consist\nin the preliminary processing of the data set by searching and extracting\nanomalous values, as well as the practical implementation of the obtained\nresults.", "published": "2025-04-05 23:53:38", "link": "http://arxiv.org/abs/2504.04303v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Generative Market Equilibrium Models with Stable Adversarial Learning via Reinforcement", "abstract": "We present a general computational framework for solving continuous-time\nfinancial market equilibria under minimal modeling assumptions while\nincorporating realistic financial frictions, such as trading costs, and\nsupporting multiple interacting agents. Inspired by generative adversarial\nnetworks (GANs), our approach employs a novel generative deep reinforcement\nlearning framework with a decoupling feedback system embedded in the\nadversarial training loop, which we term as the \\emph{reinforcement link}. This\narchitecture stabilizes the training dynamics by incorporating feedback from\nthe discriminator. Our theoretically guided feedback mechanism enables the\ndecoupling of the equilibrium system, overcoming challenges that hinder\nconventional numerical algorithms. Experimentally, our algorithm not only\nlearns but also provides testable predictions on how asset returns and\nvolatilities emerge from the endogenous trading behavior of market\nparticipants, where traditional analytical methods fall short. The design of\nour model is further supported by an approximation guarantee.", "published": "2025-04-05 23:29:46", "link": "http://arxiv.org/abs/2504.04300v1", "categories": ["q-fin.MF", "cs.LG", "q-fin.PR", "68T07, 68T30, 91-08, 91-10, 91B50, 91B69, 91G15, 91G60, 93E35"], "primary_category": "q-fin.MF"}
{"title": "Foundation Models for Environmental Science: A Survey of Emerging Frontiers", "abstract": "Modeling environmental ecosystems is essential for effective resource\nmanagement, sustainable development, and understanding complex ecological\nprocesses. However, traditional data-driven methods face challenges in\ncapturing inherently complex and interconnected processes and are further\nconstrained by limited observational data in many environmental applications.\nFoundation models, which leverages large-scale pre-training and universal\nrepresentations of complex and heterogeneous data, offer transformative\nopportunities for capturing spatiotemporal dynamics and dependencies in\nenvironmental processes, and facilitate adaptation to a broad range of\napplications. This survey presents a comprehensive overview of foundation model\napplications in environmental science, highlighting advancements in common\nenvironmental use cases including forward prediction, data generation, data\nassimilation, downscaling, inverse modeling, model ensembling, and\ndecision-making across domains. We also detail the process of developing these\nmodels, covering data collection, architecture design, training, tuning, and\nevaluation. Through discussions on these emerging methods as well as their\nfuture opportunities, we aim to promote interdisciplinary collaboration that\naccelerates advancements in machine learning for driving scientific discovery\nin addressing critical environmental challenges.", "published": "2025-04-05 20:56:38", "link": "http://arxiv.org/abs/2504.04280v1", "categories": ["cs.LG", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "Randomised Postiterations for Calibrated BayesCG", "abstract": "The Bayesian conjugate gradient method offers probabilistic solutions to\nlinear systems but suffers from poor calibration, limiting its utility in\nuncertainty quantification tasks. Recent approaches leveraging postiterations\nto construct priors have improved computational properties but failed to\ncorrect calibration issues. In this work, we propose a novel randomised\npostiteration strategy that enhances the calibration of the BayesCG posterior\nwhile preserving its favourable convergence characteristics. We present\ntheoretical guarantees for the improved calibration, supported by results on\nthe distribution of posterior errors. Numerical experiments demonstrate the\nefficacy of the method in both synthetic and inverse problem settings, showing\nenhanced uncertainty quantification and better propagation of uncertainties\nthrough computational pipelines.", "published": "2025-04-05 18:43:51", "link": "http://arxiv.org/abs/2504.04247v1", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA"], "primary_category": "stat.ML"}
{"title": "Directional Sign Loss: A Topology-Preserving Loss Function that Approximates the Sign of Finite Differences", "abstract": "Preserving critical topological features in learned latent spaces is a\nfundamental challenge in representation learning, particularly for\ntopology-sensitive data. This paper introduces directional sign loss (DSL), a\nnovel loss function that approximates the number of mismatches in the signs of\nfinite differences between corresponding elements of two arrays. By penalizing\ndiscrepancies in critical points between input and reconstructed data, DSL\nencourages autoencoders and other learnable compressors to retain the\ntopological features of the original data. We present the mathematical\nformulation, complexity analysis, and practical implementation of DSL,\ncomparing its behavior to its non-differentiable counterpart and to other\ntopological measures. Experiments on one-, two-, and three-dimensional data\nshow that combining DSL with traditional loss functions preserves topological\nfeatures more effectively than traditional losses alone. Moreover, DSL serves\nas a differentiable, efficient proxy for common topology-based metrics,\nenabling its use in gradient-based optimization frameworks.", "published": "2025-04-05 15:17:19", "link": "http://arxiv.org/abs/2504.04202v1", "categories": ["cs.LG", "I.2.6"], "primary_category": "cs.LG"}
{"title": "AttackLLM: LLM-based Attack Pattern Generation for an Industrial Control System", "abstract": "Malicious examples are crucial for evaluating the robustness of machine\nlearning algorithms under attack, particularly in Industrial Control Systems\n(ICS). However, collecting normal and attack data in ICS environments is\nchallenging due to the scarcity of testbeds and the high cost of human\nexpertise. Existing datasets are often limited by the domain expertise of\npractitioners, making the process costly and inefficient. The lack of\ncomprehensive attack pattern data poses a significant problem for developing\nrobust anomaly detection methods. In this paper, we propose a novel approach\nthat combines data-centric and design-centric methodologies to generate attack\npatterns using large language models (LLMs). Our results demonstrate that the\nattack patterns generated by LLMs not only surpass the quality and quantity of\nthose created by human experts but also offer a scalable solution that does not\nrely on expensive testbeds or pre-existing attack examples. This multi-agent\nbased approach presents a promising avenue for enhancing the security and\nresilience of ICS environments.", "published": "2025-04-05 14:11:47", "link": "http://arxiv.org/abs/2504.04187v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Variational autoencoders understand knot topology", "abstract": "Supervised machine learning (ML) methods are emerging as valid alternatives\nto standard mathematical methods for identifying knots in long, collapsed\npolymers. Here, we introduce a hybrid supervised/unsupervised ML approach for\nknot classification based on a variational autoencoder enhanced with a knot\ntype classifier (VAEC). The neat organization of knots in its latent\nrepresentation suggests that the VAEC, only based on an arbitrary labeling of\nthree-dimensional configurations, has grasped complex topological concepts such\nas chirality, unknotting number, braid index, and the grouping in families such\nas achiral, torus, and twist knots. The understanding of topological concepts\nis confirmed by the ability of the VAEC to distinguish the chirality of knots\n$9_{42}$ and $10_{71}$ not used for its training and with a notoriously\nundetected chirality to standard tools. The well-organized latent space is also\nkey for generating configurations with the decoder that reliably preserves the\ntopology of the input ones. Our findings demonstrate the ability of a hybrid\nsupervised-generative ML algorithm to capture different topological features of\nentangled filaments and to exploit this knowledge to faithfully reconstruct or\nproduce new knotted configurations without simulations.", "published": "2025-04-05 13:55:13", "link": "http://arxiv.org/abs/2504.04179v1", "categories": ["cond-mat.stat-mech", "cond-mat.soft", "cs.LG"], "primary_category": "cond-mat.stat-mech"}
{"title": "MInCo: Mitigating Information Conflicts in Distracted Visual Model-based Reinforcement Learning", "abstract": "Existing visual model-based reinforcement learning (MBRL) algorithms with\nobservation reconstruction often suffer from information conflicts, making it\ndifficult to learn compact representations and hence result in less robust\npolicies, especially in the presence of task-irrelevant visual distractions. In\nthis paper, we first reveal that the information conflicts in current visual\nMBRL algorithms stem from visual representation learning and latent dynamics\nmodeling with an information-theoretic perspective. Based on this finding, we\npresent a new algorithm to resolve information conflicts for visual MBRL, named\nMInCo, which mitigates information conflicts by leveraging negative-free\ncontrastive learning, aiding in learning invariant representation and robust\npolicies despite noisy observations. To prevent the dominance of visual\nrepresentation learning, we introduce time-varying reweighting to bias the\nlearning towards dynamics modeling as training proceeds. We evaluate our method\non several robotic control tasks with dynamic background distractions. Our\nexperiments demonstrate that MInCo learns invariant representations against\nbackground noise and consistently outperforms current state-of-the-art visual\nMBRL methods. Code is available at https://github.com/ShiguangSun/minco.", "published": "2025-04-05 12:57:31", "link": "http://arxiv.org/abs/2504.04164v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "OrbitZoo: Multi-Agent Reinforcement Learning Environment for Orbital Dynamics", "abstract": "The increasing number of satellites and orbital debris has made space\ncongestion a critical issue, threatening satellite safety and sustainability.\nChallenges such as collision avoidance, station-keeping, and orbital\nmaneuvering require advanced techniques to handle dynamic uncertainties and\nmulti-agent interactions. Reinforcement learning (RL) has shown promise in this\ndomain, enabling adaptive, autonomous policies for space operations; however,\nmany existing RL frameworks rely on custom-built environments developed from\nscratch, which often use simplified models and require significant time to\nimplement and validate the orbital dynamics, limiting their ability to fully\ncapture real-world complexities. To address this, we introduce OrbitZoo, a\nversatile multi-agent RL environment built on a high-fidelity industry standard\nlibrary, that enables realistic data generation, supports scenarios like\ncollision avoidance and cooperative maneuvers, and ensures robust and accurate\norbital dynamics. The environment is validated against a real satellite\nconstellation, Starlink, achieving a Mean Absolute Percentage Error (MAPE) of\n0.16% compared to real-world data. This validation ensures reliability for\ngenerating high-fidelity simulations and enabling autonomous and independent\nsatellite operations.", "published": "2025-04-05 12:44:21", "link": "http://arxiv.org/abs/2504.04160v1", "categories": ["cs.LG", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Vehicle Acceleration Prediction Considering Environmental Influence and Individual Driving Behavior", "abstract": "Accurate vehicle acceleration prediction is critical for intelligent driving\ncontrol and energy efficiency management, particularly in environments with\ncomplex driving behavior dynamics. This paper proposes a general short-term\nvehicle acceleration prediction framework that jointly models environmental\ninfluence and individual driving behavior. The framework adopts a dual input\ndesign by incorporating environmental sequences, constructed from historical\ntraffic variables such as percentile-based speed and acceleration statistics of\nmultiple vehicles at specific spatial locations, capture group-level driving\nbehavior influenced by the traffic environment. In parallel, individual driving\nbehavior sequences represent motion characteristics of the target vehicle prior\nto the prediction point, reflecting personalized driving styles. These two\ninputs are processed using an LSTM Seq2Seq model enhanced with an attention\nmechanism, enabling accurate multi-step acceleration prediction. To demonstrate\nthe effectiveness of the proposed method, an empirical study was conducted\nusing high resolution radar video fused trajectory data collected from the exit\nsection of the Guangzhou Baishi Tunnel. Drivers were clustered into three\ncategories conservative, moderate, and aggressive based on key behavioral\nindicators, and a dedicated prediction model was trained for each group to\naccount for driver heterogeneity.Experimental results show that the proposed\nmethod consistently outperforms four baseline models, yielding a 10.9%\nimprovement in accuracy with the inclusion of historical traffic variables and\na 33% improvement with driver classification. Although prediction errors\nincrease with forecast distance, incorporating environment- and behavior-aware\nfeatures significantly enhances model robustness.", "published": "2025-04-05 12:43:15", "link": "http://arxiv.org/abs/2504.04159v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Transformer representation learning is necessary for dynamic multi-modal physiological data on small-cohort patients", "abstract": "Postoperative delirium (POD), a severe neuropsychiatric complication\naffecting nearly 50% of high-risk surgical patients, is defined as an acute\ndisorder of attention and cognition, It remains significantly underdiagnosed in\nthe intensive care units (ICUs) due to subjective monitoring methods. Early and\naccurate diagnosis of POD is critical and achievable. Here, we propose a POD\nprediction framework comprising a Transformer representation model followed by\ntraditional machine learning algorithms. Our approaches utilizes multi-modal\nphysiological data, including amplitude-integrated electroencephalography\n(aEEG), vital signs, electrocardiographic monitor data as well as hemodynamic\nparameters. We curated the first multi-modal POD dataset encompassing two\npatient types and evaluated the various Transformer architectures for\nrepresentation learning. Empirical results indicate a consistent improvements\nof sensitivity and Youden index in patient TYPE I using Transformer\nrepresentations, particularly our fusion adaptation of Pathformer. By enabling\neffective delirium diagnosis from postoperative day 1 to 3, our extensive\nexperimental findings emphasize the potential of multi-modal physiological data\nand highlight the necessity of representation learning via multi-modal\nTransformer architecture in clinical diagnosis.", "published": "2025-04-05 09:31:39", "link": "http://arxiv.org/abs/2504.04120v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Minimax Optimal Convergence of Gradient Descent in Logistic Regression via Large and Adaptive Stepsizes", "abstract": "We study $\\textit{gradient descent}$ (GD) for logistic regression on linearly\nseparable data with stepsizes that adapt to the current risk, scaled by a\nconstant hyperparameter $\\eta$. We show that after at most $1/\\gamma^2$ burn-in\nsteps, GD achieves a risk upper bounded by $\\exp(-\\Theta(\\eta))$, where\n$\\gamma$ is the margin of the dataset. As $\\eta$ can be arbitrarily large, GD\nattains an arbitrarily small risk $\\textit{immediately after the burn-in\nsteps}$, though the risk evolution may be $\\textit{non-monotonic}$.\n  We further construct hard datasets with margin $\\gamma$, where any batch or\nonline first-order method requires $\\Omega(1/\\gamma^2)$ steps to find a linear\nseparator. Thus, GD with large, adaptive stepsizes is $\\textit{minimax\noptimal}$ among first-order batch methods. Notably, the classical\n$\\textit{Perceptron}$ (Novikoff, 1962), a first-order online method, also\nachieves a step complexity of $1/\\gamma^2$, matching GD even in constants.\n  Finally, our GD analysis extends to a broad class of loss functions and\ncertain two-layer networks.", "published": "2025-04-05 08:34:20", "link": "http://arxiv.org/abs/2504.04105v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "PipeDec: Low-Latency Pipeline-based Inference with Dynamic Speculative Decoding towards Large-scale Models", "abstract": "Autoregressive large language model inference primarily consists of two\nstages: pre-filling and decoding. Decoding involves sequential computation for\neach token, which leads to significant latency. Speculative decoding is a\ntechnique that leverages the draft model combined with large model verification\nto enhance parallelism without sacrificing accuracy. However, existing external\nprediction methods face challenges in adapting to multi-node serial\ndeployments. While they can maintain speedup under such conditions, the high\nlatency of multi-node deployments ultimately results in low overall efficiency.\nWe propose a speculative decoding framework named PipeDec to address the low\nglobal resource utilization of single tasks in pipeline deployments thereby\nreducing decoding latency. We integrate a draft model into the pipeline of the\nlarge model and immediately forward each prediction from the draft model to\nsubsequent pipeline stages. A dynamic prediction tree manages prediction\nsequences across nodes, enabling efficient updating and pruning. This approach\nleverages the draft model's predictions to utilize all pipeline nodes for\nparallel decoding of a single task. Experiments were conducted using LLama3.2\n1B as the draft model in conjunction with a 14-stage parallel pipeline to\naccelerate LLama3.1 70B by six different types of datasets. During the decoding\nphase of a single task, PipeDec achieved a 4.46x-7.79x speedup compared to\ntraditional pipeline parallelism and a 2.2x-2.69x speedup compared to baseline\ntree-based speculative decoding methods. The code will be released after the\nreview process.", "published": "2025-04-05 08:31:10", "link": "http://arxiv.org/abs/2504.04104v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Corrected with the Latest Version: Make Robust Asynchronous Federated Learning Possible", "abstract": "As an emerging paradigm of federated learning, asynchronous federated\nlearning offers significant speed advantages over traditional synchronous\nfederated learning. Unlike synchronous federated learning, which requires\nwaiting for all clients to complete updates before aggregation, asynchronous\nfederated learning aggregates the models that have arrived in realtime, greatly\nimproving training speed. However, this mechanism also introduces the issue of\nclient model version inconsistency. When the differences between models of\ndifferent versions during aggregation become too large, it may lead to\nconflicts, thereby reducing the models accuracy. To address this issue, this\npaper proposes an asynchronous federated learning version correction algorithm\nbased on knowledge distillation, named FedADT. FedADT applies knowledge\ndistillation before aggregating gradients, using the latest global model to\ncorrect outdated information, thus effectively reducing the negative impact of\noutdated gradients on the training process. Additionally, FedADT introduces an\nadaptive weighting function that adjusts the knowledge distillation weight\naccording to different stages of training, helps mitigate the misleading\neffects caused by the poorer performance of the global model in the early\nstages of training. This method significantly improves the overall performance\nof asynchronous federated learning without adding excessive computational\noverhead. We conducted experimental comparisons with several classical\nalgorithms, and the results demonstrate that FedADT achieves significant\nimprovements over other asynchronous methods and outperforms all methods in\nterms of convergence speed.", "published": "2025-04-05 06:54:13", "link": "http://arxiv.org/abs/2504.04081v1", "categories": ["cs.LG", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Scalable Robust Bayesian Co-Clustering with Compositional ELBOs", "abstract": "Co-clustering exploits the duality of instances and features to\nsimultaneously uncover meaningful groups in both dimensions, often\noutperforming traditional clustering in high-dimensional or sparse data\nsettings. Although recent deep learning approaches successfully integrate\nfeature learning and cluster assignment, they remain susceptible to noise and\ncan suffer from posterior collapse within standard autoencoders. In this paper,\nwe present the first fully variational Co-clustering framework that directly\nlearns row and column clusters in the latent space, leveraging a doubly\nreparameterized ELBO to improve gradient signal-to-noise separation. Our\nunsupervised model integrates a Variational Deep Embedding with a Gaussian\nMixture Model (GMM) prior for both instances and features, providing a built-in\nclustering mechanism that naturally aligns latent modes with row and column\nclusters. Furthermore, our regularized end-to-end noise learning Compositional\nELBO architecture jointly reconstructs the data while regularizing against\nnoise through the KL divergence, thus gracefully handling corrupted or missing\ninputs in a single training pipeline. To counteract posterior collapse, we\nintroduce a scale modification that increases the encoder's latent means only\nin the reconstruction pathway, preserving richer latent representations without\ninflating the KL term. Finally, a mutual information-based cross-loss ensures\ncoherent co-clustering of rows and columns. Empirical results on diverse\nreal-world datasets from multiple modalities, numerical, textual, and\nimage-based, demonstrate that our method not only preserves the advantages of\nprior Co-clustering approaches but also exceeds them in accuracy and\nrobustness, particularly in high-dimensional or noisy settings.", "published": "2025-04-05 06:48:05", "link": "http://arxiv.org/abs/2504.04079v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Deep-Learning-Directed Preventive Dynamic Security Control via Coordinated Demand Response", "abstract": "Unlike common faults, three-phase short-circuit faults in power systems pose\nsignificant challenges. These faults can lead to out-of-step (OOS) conditions\nand jeopardize the system's dynamic security. The rapid dynamics of these\nfaults often exceed the time of protection actions, thus limiting the\neffectiveness of corrective schemes. This paper proposes an end-to-end\ndeep-learning-based mechanism, namely, a convolutional neural network with an\nattention mechanism, to predict OOS conditions early and enhance the system's\nfault resilience. The results of the study demonstrate the effectiveness of the\nproposed algorithm in terms of early prediction and robustness against such\nfaults in various operating conditions.", "published": "2025-04-05 04:46:36", "link": "http://arxiv.org/abs/2504.04059v1", "categories": ["eess.SY", "cs.LG", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Learning-Based Multi-Criteria Decision Model for Site Selection Problems", "abstract": "Strategically locating sawmills is critical for the efficiency,\nprofitability, and sustainability of timber supply chains, yet it involves a\nseries of complex decision-making affected by various factors, such as\nproximity to resources and markets, proximity to roads and rail lines, distance\nfrom the urban area, slope, labor market, and existing sawmill data. Although\nconventional Multi-Criteria Decision-Making (MCDM) approaches utilize these\nfactors while locating facilities, they are susceptible to bias since they rely\nheavily on expert opinions to determine the relative factor weights. Machine\nlearning (ML) models provide an objective, data-driven alternative for site\nselection that derives these weights directly from the patterns in large\ndatasets without requiring subjective weighting. Additionally, ML models\nautonomously identify critical features, eliminating the need for subjective\nfeature selection. In this study, we propose integrated ML and MCDM methods and\nshowcase the utility of this integrated model to improve sawmill location\ndecisions via a case study in Mississippi. This integrated model is flexible\nand applicable to site selection problems across various industries.", "published": "2025-04-05 04:17:30", "link": "http://arxiv.org/abs/2504.04055v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Disparate Privacy Vulnerability: Targeted Attribute Inference Attacks and Defenses", "abstract": "As machine learning (ML) technologies become more prevalent in\nprivacy-sensitive areas like healthcare and finance, eventually incorporating\nsensitive information in building data-driven algorithms, it is vital to\nscrutinize whether these data face any privacy leakage risks. One potential\nthreat arises from an adversary querying trained models using the public,\nnon-sensitive attributes of entities in the training data to infer their\nprivate, sensitive attributes, a technique known as the attribute inference\nattack. This attack is particularly deceptive because, while it may perform\npoorly in predicting sensitive attributes across the entire dataset, it excels\nat predicting the sensitive attributes of records from a few vulnerable groups,\na phenomenon known as disparate vulnerability. This paper illustrates that an\nadversary can take advantage of this disparity to carry out a series of new\nattacks, showcasing a threat level beyond previous imagination. We first\ndevelop a novel inference attack called the disparity inference attack, which\ntargets the identification of high-risk groups within the dataset. We then\nintroduce two targeted variations of the attribute inference attack that can\nidentify and exploit a vulnerable subset of the training data, marking the\nfirst instances of targeted attacks in this category, achieving significantly\nhigher accuracy than untargeted versions. We are also the first to introduce a\nnovel and effective disparity mitigation technique that simultaneously\npreserves model performance and prevents any risk of targeted attacks.", "published": "2025-04-05 02:58:37", "link": "http://arxiv.org/abs/2504.04033v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Comprehensive Survey of Challenges and Opportunities of Few-Shot Learning Across Multiple Domains", "abstract": "In a world where new domains are constantly discovered and machine learning\n(ML) is applied to automate new tasks every day, challenges arise with the\nnumber of samples available to train ML models. While the traditional ML\ntraining relies heavily on data volume, finding a large dataset with a lot of\nusable samples is not always easy, and often the process takes time. For\ninstance, when a new human transmissible disease such as COVID-19 breaks out\nand there is an immediate surge for rapid diagnosis, followed by rapid\nisolation of infected individuals from healthy ones to contain the spread,\nthere is an immediate need to create tools/automation using machine learning\nmodels. At the early stage of an outbreak, it is not only difficult to obtain a\nlot of samples, but also difficult to understand the details about the disease,\nto process the data needed to train a traditional ML model. A solution for this\ncan be a few-shot learning approach. This paper presents challenges and\nopportunities of few-shot approaches that vary across major domains, i.e.,\naudio, image, text, and their combinations, with their strengths and\nweaknesses. This detailed understanding can help to adopt appropriate\napproaches applicable to different domains and applications.", "published": "2025-04-05 01:46:32", "link": "http://arxiv.org/abs/2504.04017v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Computational Efficient Informative Nonignorable Matrix Completion: A Row- and Column-Wise Matrix U-Statistic Pseudo-Likelihood Approach", "abstract": "In this study, we establish a unified framework to deal with the high\ndimensional matrix completion problem under flexible nonignorable missing\nmechanisms. Although the matrix completion problem has attracted much attention\nover the years, there are very sparse works that consider the nonignorable\nmissing mechanism. To address this problem, we derive a row- and column-wise\nmatrix U-statistics type loss function, with the nuclear norm for\nregularization. A singular value proximal gradient algorithm is developed to\nsolve the proposed optimization problem. We prove the non-asymptotic upper\nbound of the estimation error's Frobenius norm and show the performance of our\nmethod through numerical simulations and real data analysis.", "published": "2025-04-05 01:41:53", "link": "http://arxiv.org/abs/2504.04016v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Multi-resolution Score-Based Variational Graphical Diffusion for Causal Disaster System Modeling and Inference", "abstract": "Complex systems with intricate causal dependencies challenge accurate\nprediction. Effective modeling requires precise physical process\nrepresentation, integration of interdependent factors, and incorporation of\nmulti-resolution observational data. These systems manifest in both static\nscenarios with instantaneous causal chains and temporal scenarios with evolving\ndynamics, complicating modeling efforts. Current methods struggle to\nsimultaneously handle varying resolutions, capture physical relationships,\nmodel causal dependencies, and incorporate temporal dynamics, especially with\ninconsistently sampled data from diverse sources. We introduce Temporal-SVGDM:\nScore-based Variational Graphical Diffusion Model for Multi-resolution\nobservations. Our framework constructs individual SDEs for each variable at its\nnative resolution, then couples these SDEs through a causal score mechanism\nwhere parent nodes inform child nodes' evolution. This enables unified modeling\nof both immediate causal effects in static scenarios and evolving dependencies\nin temporal scenarios. In temporal models, state representations are processed\nthrough a sequence prediction model to predict future states based on\nhistorical patterns and causal relationships. Experiments on real-world\ndatasets demonstrate improved prediction accuracy and causal understanding\ncompared to existing methods, with robust performance under varying levels of\nbackground knowledge. Our model exhibits graceful degradation across different\ndisaster types, successfully handling both static earthquake scenarios and\ntemporal hurricane and wildfire scenarios, while maintaining superior\nperformance even with limited data.", "published": "2025-04-05 01:36:23", "link": "http://arxiv.org/abs/2504.04015v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Spatially-Heterogeneous Causal Bayesian Networks for Seismic Multi-Hazard Estimation: A Variational Approach with Gaussian Processes and Normalizing Flows", "abstract": "Post-earthquake hazard and impact estimation are critical for effective\ndisaster response, yet current approaches face significant limitations.\nTraditional models employ fixed parameters regardless of geographical context,\nmisrepresenting how seismic effects vary across diverse landscapes, while\nremote sensing technologies struggle to distinguish between co-located hazards.\nWe address these challenges with a spatially-aware causal Bayesian network that\ndecouples co-located hazards by modeling their causal relationships with\nlocation-specific parameters. Our framework integrates sensing observations,\nlatent variables, and spatial heterogeneity through a novel combination of\nGaussian Processes with normalizing flows, enabling us to capture how same\nearthquake produces different effects across varied geological and\ntopographical features. Evaluations across three earthquakes demonstrate\nSpatial-VCBN achieves Area Under the Curve (AUC) improvements of up to 35.2%\nover existing methods. These results highlight the critical importance of\nmodeling spatial heterogeneity in causal mechanisms for accurate disaster\nassessment, with direct implications for improving emergency response resource\nallocation.", "published": "2025-04-05 01:34:43", "link": "http://arxiv.org/abs/2504.04013v1", "categories": ["stat.ML", "cs.LG", "stat.AP"], "primary_category": "stat.ML"}
{"title": "Machine Learning Reviews Composition Dependent Thermal Stability in Halide Perovskites", "abstract": "Halide perovskites exhibit unpredictable properties in response to\nenvironmental stressors, due to several composition-dependent degradation\nmechanisms. In this work, we apply data visualization and machine learning (ML)\ntechniques to reveal unexpected correlations between composition, temperature,\nand material properties while using high throughput, in situ environmental\nphotoluminescence (PL) experiments. Correlation heatmaps show the strong\ninfluence of Cs content on film degradation, and dimensionality reduction\nvisualization methods uncover clear composition-based data clusters. An extreme\ngradient boosting algorithm (XGBoost) effectively forecasts PL features for ten\nperovskite films with both composition-agnostic (>85% accuracy) and\ncomposition-dependent (>75% accuracy) model approaches, while elucidating the\nrelative feature importance of composition (up to 99%). This model validates a\npreviously unseen anti-correlation between Cs content and material thermal\nstability. Our ML-based framework can be expanded to any perovskite family,\nsignificantly reducing the analysis time currently employed to identify stable\noptions for photovoltaics.", "published": "2025-04-05 00:13:18", "link": "http://arxiv.org/abs/2504.04002v1", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "Distributed Time Synchronization in NOMA-Assisted Ultra-Dense Networks", "abstract": "Ultra-dense networks (UDNs) represent a transformative access architecture\nfor upcoming sixth generation (6G) systems, poised to meet the surging demand\nfor high data rates. Achieving precise synchronization across diverse base\nstations (BSs) is critical in these networks to mitigate inter-cell\ninterference (ICI). However, traditional centralized synchronization approaches\nface substantial challenges in dense urban, including limited access to Global\nPositioning System (GPS), dependence on reliable backhaul, and high signaling\noverhead demands. This study advances a low-complexity distributed\nsynchronization solution. A primary focus is on assessing the algorithm's\naccuracy incorporating the effects of information exchange delays, which are\npronounced in large-networks. Recognizing the pivotal role of neighbor-gathered\ninformation in the proposed approach, this research employs uplink\nNon-Orthogonal Multiple Access (NOMA) to reduce message-gathering delays\nbetween transmitters (TXs) and receivers (RXs). The proposed algorithm is\nevaluated to assess effectiveness under exchange delays, analyzing impact of\nsystem parameters like network connectivity, size, sub-bands, etc., on\nsynchronization speed. The findings demonstrate that the NOMA-based\ninformation-gathering technique significantly accelerates network\nsynchronization compared to orthogonal access schemes. This advancement is\ncrucial for meeting the low-latency requirements of beyond fifth generation\n(5G) systems, underscoring the potential of distributed synchronization as a\ncornerstone for next-generation UDN deployments.", "published": "2025-04-05 15:02:00", "link": "http://arxiv.org/abs/2504.04195v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Semi-Lagrangian methods of a plasma hybrid model with multi-species kinetic ions and massless electrons", "abstract": "The semi-Lagrangian methods with the improved number of one-dimensional\nadvections are proposed for a plasma hybrid model with kinetic ions and\nmass-less electrons. Two subsystems with mass, momentum, and energy\nconservation are obtained by a Poisson bracket-based splitting method. For the\nsubsystem in which the distribution functions and the fields are coupled, the\nsecond order and reversible modified implicit mid-point rule is used in time\nwith the specially designed mean velocity. The distribution functions are not\ninvolved in the iterations and are solved by exact splittings with only one\ndimensional advections, which makes the proposed schemes efficient. The\ncancellation problem is overcome by the numerical schemes constructed.\nMoreover, for the case with a periodic boundary condition, the magnetic field\nobtained is divergence free, mass, momentum, and energy are conserved. The\nmethods can be extended to cases with multiple ion species.", "published": "2025-04-05 21:06:03", "link": "http://arxiv.org/abs/2504.04282v1", "categories": ["math.NA", "cs.NA", "physics.plasm-ph", "65M25, 85-08, 86-08, 35Q83"], "primary_category": "math.NA"}
{"title": "Randomised Splitting Methods and Stochastic Gradient Descent", "abstract": "We explore an explicit link between stochastic gradient descent using common\nbatching strategies and splitting methods for ordinary differential equations.\nFrom this perspective, we introduce a new minibatching strategy (called\nSymmetric Minibatching Strategy) for stochastic gradient optimisation which\nshows greatly reduced stochastic gradient bias (from $\\mathcal{O}(h^2)$ to\n$\\mathcal{O}(h^4)$ in the optimiser stepsize $h$), when combined with\nmomentum-based optimisers. We justify why momentum is needed to obtain the\nimproved performance using the theory of backward analysis for splitting\nintegrators and provide a detailed analytic computation of the stochastic\ngradient bias on a simple example.\n  Further, we provide improved convergence guarantees for this new minibatching\nstrategy using Lyapunov techniques that show reduced stochastic gradient bias\nfor a fixed stepsize (or learning rate) over the class of strongly-convex and\nsmooth objective functions. Via the same techniques we also improve the known\nresults for the Random Reshuffling strategy for stochastic gradient descent\nmethods with momentum. We argue that this also leads to a faster convergence\nrate when considering a decreasing stepsize schedule. Both the reduced bias and\nefficacy of decreasing stepsizes are demonstrated numerically on several\nmotivating examples.", "published": "2025-04-05 20:07:34", "link": "http://arxiv.org/abs/2504.04274v1", "categories": ["math.OC", "cs.NA", "math.NA", "stat.ML", "65L20, 90C25, 93C15"], "primary_category": "math.OC"}
{"title": "Computing cone-constrained singular values of matrices", "abstract": "The concept of singular values of a rectangular matrix $A$ relative to a pair\nof closed convex cones $(P,Q)$ has been recently introduced by Seeger and Sossa\n(Cone-constrained singular value problems, Journal of Convex Analysis 30, pp.\n1285-1306, 2023). These singular values are the critical (stationary) values of\nthe non-convex optimization problem of minimizing $\\langle u,Av\\rangle$ such\nthat $u$ and $v$ are unit vectors in $P$ and $Q$, respectively. When $A$ is the\nidentity matrix, the singular values coincide with the cosine of the critical\nangles between $P$ and $Q$. When $P$ and $Q$ are positive orthants, the\nsingular values are called Pareto singular values of $A$ and have applications,\nfor instance, in spectral graph theory. This paper deals with the numerical\ncomputation of these cone-constrained singular values. We prove the NP-hardness\nof all the above problems, while identifying cases when such problems can be\nsolved in polynomial time. We then propose four algorithms. Two are exact\nalgorithms, meaning that they are guaranteed to compute a globally optimal\nsolution; one uses an exact non-convex quadratic programming solver, and the\nother a brute-force active-set method. The other two are heuristics, meaning\nthat they rapidly compute locally optimal solutions; one uses an alternating\nprojection algorithm with extrapolation, and the other a sequential partial\nlinearization approach based on fractional programming. We illustrate the use\nof these algorithms on several examples.", "published": "2025-04-05 06:05:28", "link": "http://arxiv.org/abs/2504.04069v1", "categories": ["math.OC", "cs.NA", "math.NA"], "primary_category": "math.OC"}
{"title": "A note on time-inconsistent stochastic control problems with higher-order moments", "abstract": "In this paper, we extend the research on time-consistent stochastic control\nproblems with higher-order moments, as formulated by [Y. Wang et al. SIAM J.\nControl. Optim., 63 (2025), in press]. We consider a linear controlled dynamic\nequation with state-dependent diffusion, and let the sum of a conventional\nmean-variance utility and a fairly general function of higher-order central\nmoments be the objective functional. We obtain both the sufficiency and\nnecessity of the equilibrium condition for an open-loop Nash equilibrium\ncontrol (ONEC), under some continuity and integrability assumptions that are\nmore relaxed and natural than those employed before. Notably, we derive an\nextended version of the stochastic Lebesgue differentiation theorem for\nnecessity, because the equilibrium condition is represented by some diagonal\nprocesses generated by a flow of backward stochastic differential equations\nwhose the data do not necessarily satisfy the usual square-integrability. Based\non the derived equilibrium condition, we obtain the algebra equation for a\ndeterministic ONEC. In particular, we find that the mean-variance equilibrium\nstrategy is an ONEC for our higher-order moment problem if and only if the\nobjective functional satisfies a homogeneity condition.", "published": "2025-04-05 09:10:21", "link": "http://arxiv.org/abs/2504.04113v1", "categories": ["math.OC", "q-fin.MF", "Primary: 93E20, 91G80, Secondary: 91B08, 49N90"], "primary_category": "math.OC"}
{"title": "Real-Time Auralization for First-Person Vocal Interaction in Immersive Virtual Environments", "abstract": "Multimodal research and applications are becoming more commonplace as Virtual\nReality (VR) technology integrates different sensory feedback, enabling the\nrecreation of real spaces in an audio-visual context. Within VR experiences,\nnumerous applications rely on the user's voice as a key element of interaction,\nincluding music performances and public speaking applications. Self-perception\nof our voice plays a crucial role in vocal production. When singing or\nspeaking, our voice interacts with the acoustic properties of the environment,\nshaping the adjustment of vocal parameters in response to the perceived\ncharacteristics of the space. This technical report presents a real-time\nauralization pipeline that leverages three-dimensional Spatial Impulse\nResponses (SIRs) for multimodal research applications in VR requiring\nfirst-person vocal interaction. It describes the impulse response creation and\nrendering workflow, the audio-visual integration, and addresses latency and\ncomputational considerations. The system enables users to explore acoustic\nspaces from various positions and orientations within a predefined area,\nsupporting three and five Degrees of Freedom (3Dof and 5DoF) in audio-visual\nmultimodal perception for both research and creative applications in VR.", "published": "2025-04-05 06:15:41", "link": "http://arxiv.org/abs/2504.04075v1", "categories": ["eess.AS", "cs.HC", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Determined blind source separation via modeling adjacent frequency band correlations in speech signals", "abstract": "Multichannel blind source separation (MBSS), which focuses on separating\nsignals of interest from mixed observations, has been extensively studied in\nacoustic and speech processing. Existing MBSS algorithms, such as independent\nlow-rank matrix analysis (ILRMA) and multichannel nonnegative matrix\nfactorization (MNMF), utilize the low-rank structure of source models but\nassume that frequency bins are independent. In contrast, independent vector\nanalysis (IVA) does not rely on a low-rank source model but rather captures\nfrequency dependencies based on a uniform correlation assumption. In this work,\nwe demonstrate that dependencies between adjacent frequency bins are\nsignificantly stronger than those between bins that are farther apart in\ntypical speech signals. To address this, we introduce a weighted Sinkhorn\ndivergence-based ILRMA (wsILRMA) that simultaneously captures these\ninter-frequency dependencies and models joint probability distributions. Our\napproach incorporates an inter-frequency correlation constraint, leading to\nimproved source separation performance compared to existing methods, as\nevidenced by higher Signal-to-Distortion Ratios (SDRs) and\nSource-to-Interference Ratios (SIRs).", "published": "2025-04-05 00:05:09", "link": "http://arxiv.org/abs/2504.03998v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "TFDWT: Fast Discrete Wavelet Transform TensorFlow Layers", "abstract": "TFDWT is an open-source Python library that allows the construction of\nTensorFlow Layers for Fast Discrete Wavelet Transform (DWT) and Inverse\nDiscrete Wavelet Transform (IDWT) in end-to-end backpropagation learning\nnetworks. By definition, a multiresolution signal representation using a\nmulti-rate discrete wavelet system creates enriched joint natural-frequency\nrepresentations. These layers facilitate the construction of multilevel DWT\nfilter banks and Wavelet Packet Transform (WPT) filter banks for a\nspatial-frequency representation of the inputs and features in shallow or deep\nnetworks. The discrete wavelet system partitions the frequency plane into\nsubbands using orthogonal dilated and translated lowpass scaling and highpass\nwavelet function. The realization of a fast discrete wavelet system is a\ntwo-band perfect reconstruction multi-rate filter bank with FIR filters\ncorresponding to the impulse responses of the scaling and wavelet function with\ndownsampling and upsampling operations. A filter bank for a higher dimensional\ninput is a seamless extension by successive separable circular convolutions\nacross each independent axis. The command `pip install TFDWT' installs the\nlatest version of the package.", "published": "2025-04-05 13:16:09", "link": "http://arxiv.org/abs/2504.04168v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Model Selection via MCRB Optimization", "abstract": "In many estimation theory and statistical analysis problems, the true data\nmodel is unknown, or partially unknown. To describe the model generating the\ndata, parameterized models of some degree are used. A question that arises is\nwhich model should be used to best approximate the true model, a.k.a. model\nselection. In the field of machine learning, it is encountered in the form of\narchitecture types of neural networks, number of model parameters, etc. In this\npaper, we propose a new model selection criterion, based on the misspecified\nCramer-Rao bound (MCRB) for mean-squared-error (MSE) performance. The criterion\nselects the model in which the bound on the estimated parameters MSE is the\nlowest, compared to other candidate models. Its goal is to minimize the MSE\nwith-respect-to (w.r.t.) the model. The criterion is applied to the problems of\ndirection-of-arrival (DOA) estimation under unknown clutter / interference, and\nspectrum estimation of auto-regressive (AR) model. It is shown to incorporate\nthe bias-variance trade-off, and outperform the Akaike information criterion\n(AIC), finite-sample corrected AIC (AICc), and minimum description length (MDL)\nin terms of MSE performance.", "published": "2025-04-05 11:01:51", "link": "http://arxiv.org/abs/2504.04136v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Space Surveillance with High-Frequency Radar", "abstract": "High-Frequency (HF) radar is well suited to the surveillance of\nlow-earth-orbit space. For large targets, a small deployable HF radar is able\nto match the detection performance of much larger space surveillance radar\nsystems operating at higher frequencies. However, there are some unique\nchallenges associated with the use of HF, including the range--Doppler coupling\nbias, coarse detection-level localisation, and the presence of meteor returns\nand other unwanted signals. This paper details the use of HF radar for space\nsurveillance, including signal processing and radar product formation,\ntracking, ionospheric correction, and orbit determination. It is shown that by\nfusing measurements from multiple passes, accurate orbital estimates can be\nobtained. Included are results from recent SpaceFest trials of the Defence\nScience and Technology Group's HF space surveillance radar, achieving real-time\nwide-area surveillance in tracking, orbit determination, and cueing of other\nspace surveillance sensors.", "published": "2025-04-05 06:15:40", "link": "http://arxiv.org/abs/2504.04074v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Perplexity and Menger Curvature-Based Approach for Similarity Evaluation of Large Language Models", "abstract": "The rise of Large Language Models (LLMs) has brought about concerns regarding\ncopyright infringement and unethical practices in data and model usage. For\ninstance, slight modifications to existing LLMs may be used to falsely claim\nthe development of new models, leading to issues of model copying and\nviolations of ownership rights. This paper addresses these challenges by\nintroducing a novel metric for quantifying LLM similarity, which leverages\nperplexity curves and differences in Menger curvature. Comprehensive\nexperiments validate the performance of our methodology, demonstrating its\nsuperiority over baseline methods and its ability to generalize across diverse\nmodels and domains. Furthermore, we highlight the capability of our approach in\ndetecting model replication through simulations, emphasizing its potential to\npreserve the originality and integrity of LLMs. Code is available at\nhttps://github.com/zyttt-coder/LLM_similarity.", "published": "2025-04-05 16:04:25", "link": "http://arxiv.org/abs/2504.04216v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
