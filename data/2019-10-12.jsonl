{"title": "Acquisition of Inflectional Morphology in Artificial Neural Networks\n  With Prior Knowledge", "abstract": "How does knowledge of one language's morphology influence learning of\ninflection rules in a second one? In order to investigate this question in\nartificial neural network models, we perform experiments with a\nsequence-to-sequence architecture, which we train on different combinations of\neight source and three target languages. A detailed analysis of the model\noutputs suggests the following conclusions: (i) if source and target language\nare closely related, acquisition of the target language's inflectional\nmorphology constitutes an easier task for the model; (ii) knowledge of a\nprefixing (resp. suffixing) language makes acquisition of a suffixing (resp.\nprefixing) language's morphology more challenging; and (iii) surprisingly, a\nsource language which exhibits an agglutinative morphology simplifies learning\nof a second language's inflectional morphology, independent of their\nrelatedness.", "published": "2019-10-12 01:10:24", "link": "http://arxiv.org/abs/1910.05456v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Zero-shot Dependency Parsing with Pre-trained Multilingual Sentence\n  Representations", "abstract": "We investigate whether off-the-shelf deep bidirectional sentence\nrepresentations trained on a massively multilingual corpus (multilingual BERT)\nenable the development of an unsupervised universal dependency parser. This\napproach only leverages a mix of monolingual corpora in many languages and does\nnot require any translation data making it applicable to low-resource\nlanguages. In our experiments we outperform the best CoNLL 2018\nlanguage-specific systems in all of the shared task's six truly low-resource\nlanguages while using a single system. However, we also find that (i) parsing\naccuracy still varies dramatically when changing the training languages and\n(ii) in some target languages zero-shot transfer fails under all tested\nconditions, raising concerns on the 'universality' of the whole approach.", "published": "2019-10-12 03:44:56", "link": "http://arxiv.org/abs/1910.05479v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From the Paft to the Fiiture: a Fully Automatic NMT and Word Embeddings\n  Method for OCR Post-Correction", "abstract": "A great deal of historical corpora suffer from errors introduced by the OCR\n(optical character recognition) methods used in the digitization process.\nCorrecting these errors manually is a time-consuming process and a great part\nof the automatic approaches have been relying on rules or supervised machine\nlearning. We present a fully automatic unsupervised way of extracting parallel\ndata for training a character-based sequence-to-sequence NMT (neural machine\ntranslation) model to conduct OCR error correction.", "published": "2019-10-12 09:23:11", "link": "http://arxiv.org/abs/1910.05535v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SmokEng: Towards Fine-grained Classification of Tobacco-related Social\n  Media Text", "abstract": "Contemporary datasets on tobacco consumption focus on one of two topics,\neither public health mentions and disease surveillance, or sentiment analysis\non topical tobacco products and services. However, two primary considerations\nare not accounted for, the language of the demographic affected and a\ncombination of the topics mentioned above in a fine-grained classification\nmechanism. In this paper, we create a dataset of 3144 tweets, which are\nselected based on the presence of colloquial slang related to smoking and\nanalyze it based on the semantics of the tweet. Each class is created and\nannotated based on the content of the tweets such that further hierarchical\nmethods can be easily applied.\n  Further, we prove the efficacy of standard text classification methods on\nthis dataset, by designing experiments which do both binary as well as\nmulti-class classification. Our experiments tackle the identification of either\na specific topic (such as tobacco product promotion), a general mention\n(cigarettes and related products) or a more fine-grained classification. This\nmethodology paves the way for further analysis, such as understanding sentiment\nor style, which makes this dataset a vital contribution to both disease\nsurveillance and tobacco use research.", "published": "2019-10-12 17:06:07", "link": "http://arxiv.org/abs/1910.05598v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "VAIS Hate Speech Detection System: A Deep Learning based Approach for\n  System Combination", "abstract": "Nowadays, Social network sites (SNSs) such as Facebook, Twitter are common\nplaces where people show their opinions, sentiments and share information with\nothers. However, some people use SNSs to post abuse and harassment threats in\norder to prevent other SNSs users from expressing themselves as well as seeking\ndifferent opinions. To deal with this problem, SNSs have to use a lot of\nresources including people to clean the aforementioned content. In this paper,\nwe propose a supervised learning model based on the ensemble method to solve\nthe problem of detecting hate content on SNSs in order to make conversations on\nSNSs more effective. Our proposed model got the first place for public\ndashboard with 0.730 F1 macro-score and the third place with 0.584 F1\nmacro-score for private dashboard at the sixth international workshop on\nVietnamese Language and Speech Processing 2019.", "published": "2019-10-12 17:46:16", "link": "http://arxiv.org/abs/1910.05608v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations", "abstract": "We propose vq-wav2vec to learn discrete representations of audio segments\nthrough a wav2vec-style self-supervised context prediction task. The algorithm\nuses either a gumbel softmax or online k-means clustering to quantize the dense\nrepresentations. Discretization enables the direct application of algorithms\nfrom the NLP community which require discrete inputs. Experiments show that\nBERT pre-training achieves a new state of the art on TIMIT phoneme\nclassification and WSJ speech recognition.", "published": "2019-10-12 00:55:06", "link": "http://arxiv.org/abs/1910.05453v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Context-Gated Convolution", "abstract": "As the basic building block of Convolutional Neural Networks (CNNs), the\nconvolutional layer is designed to extract local patterns and lacks the ability\nto model global context in its nature. Many efforts have been recently devoted\nto complementing CNNs with the global modeling ability, especially by a family\nof works on global feature interaction. In these works, the global context\ninformation is incorporated into local features before they are fed into\nconvolutional layers. However, research on neuroscience reveals that the\nneurons' ability of modifying their functions dynamically according to context\nis essential for the perceptual tasks, which has been overlooked in most of\nCNNs. Motivated by this, we propose one novel Context-Gated Convolution (CGC)\nto explicitly modify the weights of convolutional layers adaptively under the\nguidance of global context. As such, being aware of the global context, the\nmodulated convolution kernel of our proposed CGC can better extract\nrepresentative local patterns and compose discriminative features. Moreover,\nour proposed CGC is lightweight and applicable with modern CNN architectures,\nand consistently improves the performance of CNNs according to extensive\nexperiments on image classification, action recognition, and machine\ntranslation. Our code of this paper is available at\nhttps://github.com/XudongLinthu/context-gated-convolution.", "published": "2019-10-12 15:30:18", "link": "http://arxiv.org/abs/1910.05577v4", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Prediction Focused Topic Models via Feature Selection", "abstract": "Supervised topic models are often sought to balance prediction quality and\ninterpretability. However, when models are (inevitably) misspecified, standard\napproaches rarely deliver on both. We introduce a novel approach, the\nprediction-focused topic model, that uses the supervisory signal to retain only\nvocabulary terms that improve, or at least do not hinder, prediction\nperformance. By removing terms with irrelevant signal, the topic model is able\nto learn task-relevant, coherent topics. We demonstrate on several data sets\nthat compared to existing approaches, prediction-focused topic models learn\nmuch more coherent topics while maintaining competitive predictions.", "published": "2019-10-12 05:08:43", "link": "http://arxiv.org/abs/1910.05495v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "VAIS ASR: Building a conversational speech recognition system using\n  language model combination", "abstract": "Automatic Speech Recognition (ASR) systems have been evolving quickly and\nreaching human parity in certain cases. The systems usually perform pretty well\non reading style and clean speech, however, most of the available systems\nsuffer from situation where the speaking style is conversation and in noisy\nenvironments. It is not straight-forward to tackle such problems due to\ndifficulties in data collection for both speech and text. In this paper, we\nattempt to mitigate the problems using language models combination techniques\nthat allows us to utilize both large amount of writing style text and small\nnumber of conversation text data. Evaluation on the VLSP 2019 ASR challenges\nshowed that our system achieved 4.85% WER on the VLSP 2018 and 15.09% WER on\nthe VLSP 2019 data sets.", "published": "2019-10-12 17:37:52", "link": "http://arxiv.org/abs/1910.05603v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "A Research Platform for Multi-Robot Dialogue with Humans", "abstract": "This paper presents a research platform that supports spoken dialogue\ninteraction with multiple robots. The demonstration showcases our crafted\nMultiBot testing scenario in which users can verbally issue search, navigate,\nand follow instructions to two robotic teammates: a simulated ground robot and\nan aerial robot. This flexible language and robotic platform takes advantage of\nexisting tools for speech recognition and dialogue management that are\ncompatible with new domains, and implements an inter-agent communication\nprotocol (tactical behavior specification), where verbal instructions are\nencoded for tasks assigned to the appropriate robot.", "published": "2019-10-12 18:59:50", "link": "http://arxiv.org/abs/1910.05624v1", "categories": ["cs.RO", "cs.CL", "cs.HC"], "primary_category": "cs.RO"}
{"title": "Statically Detecting Vulnerabilities by Processing Programming Languages\n  as Natural Languages", "abstract": "Web applications continue to be a favorite target for hackers due to a\ncombination of wide adoption and rapid deployment cycles, which often lead to\nthe introduction of high impact vulnerabilities. Static analysis tools are\nimportant to search for bugs automatically in the program source code,\nsupporting developers on their removal. However, building these tools requires\nprogramming the knowledge on how to discover the vulnerabilities. This paper\npresents an alternative approach in which tools learn to detect flaws\nautomatically by resorting to artificial intelligence concepts, more concretely\nto natural language processing. The approach employs a sequence model to learn\nto characterize vulnerabilities based on an annotated corpus. Afterwards, the\nmodel is utilized to discover and identify vulnerabilities in the source code.\nIt was implemented in the DEKANT tool and evaluated experimentally with a large\nset of PHP applications and WordPress plugins. Overall, we found several\nhundred vulnerabilities belonging to 12 classes of input validation\nvulnerabilities, where 62 of them were zero-day.", "published": "2019-10-12 18:23:42", "link": "http://arxiv.org/abs/1910.06826v1", "categories": ["cs.CR", "cs.CL", "cs.PL", "D.2.5; I.2.7"], "primary_category": "cs.CR"}
{"title": "Emotion Generation and Recognition: A StarGAN Approach", "abstract": "The main idea of this ISO is to use StarGAN (A type of GAN model) to perform\ntraining and testing on an emotion dataset resulting in a emotion recognition\nwhich can be generated by the valence arousal score of the 7 basic expressions.\nWe have created an entirely new dataset consisting of 4K videos. This dataset\nconsists of all the basic 7 types of emotions: Happy, Sad, Angry, Surprised,\nFear, Disgust, Neutral. We have performed face detection and alignment followed\nby annotating basic valence arousal values to the frames/images in the dataset\ndepending on the emotions manually. Then the existing StarGAN model is trained\non our created dataset after which some manual subjects were chosen to test the\nefficiency of the trained StarGAN model.", "published": "2019-10-12 16:24:46", "link": "http://arxiv.org/abs/1910.11090v1", "categories": ["cs.CV", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.CV"}
