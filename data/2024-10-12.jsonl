{"title": "Keys to Robust Edits: from Theoretical Insights to Practical Advances", "abstract": "Large language models (LLMs) have revolutionized knowledge storage and\nretrieval, but face challenges with conflicting and outdated information.\nKnowledge editing techniques have been proposed to address these issues, yet\nthey struggle with robustness tests involving long contexts, paraphrased\nsubjects, and continuous edits. This work investigates the cause of these\nfailures in locate-and-edit methods, offering theoretical insights into their\nkey-value modeling and deriving mathematical bounds for robust and specific\nedits, leading to a novel 'group discussion' conceptual model for\nlocate-and-edit methods. Empirical analysis reveals that keys used by current\nmethods fail to meet robustness and specificity requirements. To address this,\nwe propose a Robust Edit Pathway (REP) that disentangles editing keys from\nLLMs' inner representations. Evaluations on LLaMA2-7B and Mistral-7B using the\nCounterFact dataset show that REP significantly improves robustness across\nvarious metrics, both in-domain and out-of-domain, with minimal trade-offs in\nsuccess rate and locality. Our findings advance the development of reliable and\nflexible knowledge updating in LLMs.", "published": "2024-10-12 02:54:12", "link": "http://arxiv.org/abs/2410.09338v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM$\\times$MapReduce: Simplified Long-Sequence Processing using Large\n  Language Models", "abstract": "Enlarging the context window of large language models (LLMs) has become a\ncrucial research area, particularly for applications involving extremely long\ntexts. In this work, we propose a novel training-free framework for processing\nlong texts, utilizing a divide-and-conquer strategy to achieve comprehensive\ndocument understanding. The proposed LLM$\\times$MapReduce framework splits the\nentire document into several chunks for LLMs to read and then aggregates the\nintermediate answers to produce the final output. The main challenge for\ndivide-and-conquer long text processing frameworks lies in the risk of losing\nessential long-range information when splitting the document, which can lead\nthe model to produce incomplete or incorrect answers based on the segmented\ntexts. Disrupted long-range information can be classified into two categories:\ninter-chunk dependency and inter-chunk conflict. We design a structured\ninformation protocol to better cope with inter-chunk dependency and an\nin-context confidence calibration mechanism to resolve inter-chunk conflicts.\nExperimental results demonstrate that LLM$\\times$MapReduce can outperform\nrepresentative open-source and commercial long-context LLMs, and is applicable\nto several different models.", "published": "2024-10-12 03:13:44", "link": "http://arxiv.org/abs/2410.09342v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ELICIT: LLM Augmentation via External In-Context Capability", "abstract": "Enhancing the adaptive capabilities of large language models is a critical\npursuit in both research and application. Traditional fine-tuning methods\nrequire substantial data and computational resources, especially for enhancing\nspecific capabilities, while in-context learning is limited by the need for\nappropriate demonstrations and efficient token usage. Inspired by the\nexpression of in-context learned capabilities through task vectors and the\nconcept of modularization, we propose \\alg, a framework consisting of two\nmodules designed to effectively store and reuse task vectors to elicit the\ndiverse capabilities of models without additional training or inference tokens.\nOur comprehensive experiments and analysis demonstrate that our pipeline is\nhighly transferable across different input formats, tasks, and model\narchitectures. ELICIT serves as a plug-and-play performance booster to enable\nadaptive elicitation of model capabilities. By externally storing and reusing\nvectors that represent in-context learned capabilities, \\alg not only\ndemonstrates the potential to operate modular capabilities but also\nsignificantly enhances the performance, versatility, adaptability, and\nscalability of large language models. Our code will be publicly available at\nhttps://github.com/LINs-lab/ELICIT.", "published": "2024-10-12 03:19:06", "link": "http://arxiv.org/abs/2410.09343v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond Exact Match: Semantically Reassessing Event Extraction by Large\n  Language Models", "abstract": "Event extraction has gained extensive research attention due to its broad\nrange of applications. However, the current mainstream evaluation method for\nevent extraction relies on token-level exact match, which misjudges numerous\nsemantic-level correct cases. This reliance leads to a significant discrepancy\nbetween the evaluated performance of models under exact match criteria and\ntheir real performance. To address this problem, we propose a reliable and\nsemantic evaluation framework for event extraction, named RAEE, which\naccurately assesses extraction results at semantic-level instead of\ntoken-level. Specifically, RAEE leverages large language models (LLMs) as\nevaluation agents, incorporating an adaptive mechanism to achieve adaptive\nevaluations for precision and recall of triggers and arguments. Extensive\nexperiments demonstrate that: (1) RAEE achieves a very strong correlation with\nhuman judgments; (2) after reassessing 14 models, including advanced LLMs, on\n10 datasets, there is a significant performance gap between exact match and\nRAEE. The exact match evaluation significantly underestimates the performance\nof existing event extraction models, and in particular underestimates the\ncapabilities of LLMs; (3) fine-grained analysis under RAEE evaluation reveals\ninsightful phenomena worth further exploration. The evaluation toolkit of our\nproposed RAEE is publicly released.", "published": "2024-10-12 07:54:01", "link": "http://arxiv.org/abs/2410.09418v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Solving the Challenge Set without Solving the Task: On Winograd Schemas\n  as a Test of Pronominal Coreference Resolution", "abstract": "Challenge sets such as the Winograd Schema Challenge (WSC) are used to\nbenchmark systems' ability to resolve ambiguities in natural language. If one\nassumes as in existing work that solving a given challenge set is at least as\ndifficult as solving some more general task, then high performance on the\nchallenge set should indicate high performance on the general task overall.\nHowever, we show empirically that this assumption of difficulty does not always\nhold. In particular, we demonstrate that despite the strong performance of\nprompted language models (LMs) on the WSC and its variants, these same modeling\ntechniques perform relatively poorly at resolving certain pronominal\nambiguities attested in OntoNotes and related datasets that are perceived to be\neasier. Motivated by these findings, we propose a method for ensembling a\nprompted LM with a supervised, task-specific system that is overall more\naccurate at resolving pronominal coreference across datasets. Finally, we\nemphasize that datasets involving the same linguistic phenomenon draw on\ndistinct, but overlapping, capabilities, and evaluating on any one dataset\nalone does not provide a complete picture of a system's overall capability.", "published": "2024-10-12 09:04:53", "link": "http://arxiv.org/abs/2410.09448v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Continuous Risk Prediction", "abstract": "Lifelong learning (LL) capabilities are essential for QA models to excel in\nreal-world applications, and architecture-based LL approaches have proven to be\na promising direction for achieving this goal. However, adapting existing\nmethods to QA tasks is far from straightforward. Many prior approaches either\nrely on access to task identities during testing or fail to adequately model\nsamples from unseen tasks, which limits their practical applicability. To\novercome these limitations, we introduce Diana , a novel\n\\underline{d}ynam\\underline{i}c \\underline{a}rchitecture-based\nlifelo\\underline{n}g Q\\underline{A} framework designed to learn a sequence of\nQA tasks using a prompt-enhanced language model.Diana leverages four\nhierarchically structured types of prompts to capture QA knowledge at multiple\nlevels of granularity. Task-level prompts are specifically designed to encode\ntask-specific knowledge, ensuring strong lifelong learning performance.\nMeanwhile, instance-level prompts are utilized to capture shared knowledge\nacross diverse input samples, enhancing the model's generalization\ncapabilities. Additionally, Diana incorporates dedicated prompts to explicitly\nhandle unseen tasks and introduces a set of prompt key vectors that facilitate\nefficient knowledge transfer and sharing between tasks. Through extensive\nexperimentation, we demonstrate that Diana achieves state-of-the-art\nperformance among lifelong QA models, with particularly notable improvements in\nits ability to handle previously unseen tasks. This makes Diana a significant\nadvancement in the field of lifelong learning for question-answering systems.", "published": "2024-10-12 09:06:09", "link": "http://arxiv.org/abs/2410.09449v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Efficient Visual-Language Alignment of the Q-Former for Visual\n  Reasoning Tasks", "abstract": "Recent advancements in large language models have demonstrated enhanced\ncapabilities in visual reasoning tasks by employing additional encoders for\naligning different modalities. While the Q-Former has been widely used as a\ngeneral encoder for aligning several modalities including image, video, audio,\nand 3D with large language models, previous works on its efficient training and\nthe analysis of its individual components have been limited. In this work, we\ninvestigate the effectiveness of parameter efficient fine-tuning (PEFT) the\nQ-Former using InstructBLIP with visual reasoning benchmarks ScienceQA and\nIconQA. We observe that applying PEFT to the Q-Former achieves comparable\nperformance to full fine-tuning using under 2% of the trainable parameters.\nAdditionally, we employ AdaLoRA for dynamic parameter budget reallocation to\nexamine the relative importance of the Q-Former's sublayers with 4 different\nbenchmarks. Our findings reveal that the self-attention layers are noticeably\nmore important in perceptual visual-language reasoning tasks, and relative\nimportance of FFN layers depends on the complexity of visual-language patterns\ninvolved in tasks. The code is available at\nhttps://github.com/AttentionX/InstructBLIP_PEFT.", "published": "2024-10-12 10:51:05", "link": "http://arxiv.org/abs/2410.09489v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AERA Chat: An Interactive Platform for Automated Explainable Student\n  Answer Assessment", "abstract": "Generating rationales that justify scoring decisions has emerged as a\npromising approach to enhance explainability in the development of automated\nscoring systems. However, the scarcity of publicly available rationale data and\nthe high cost of annotation have resulted in existing methods typically relying\non noisy rationales generated by large language models (LLMs). To address these\nchallenges, we have developed AERA Chat, an interactive platform, to provide\nvisually explained assessment of student answers and streamline the\nverification of rationales. Users can input questions and student answers to\nobtain automated, explainable assessment results from LLMs. The platform's\ninnovative visualization features and robust evaluation tools make it useful\nfor educators to assist their marking process, and for researchers to evaluate\nassessment performance and quality of rationales generated by different LLMs,\nor as a tool for efficient annotation. We evaluated three rationale generation\napproaches on our platform to demonstrate its capability.", "published": "2024-10-12 11:57:53", "link": "http://arxiv.org/abs/2410.09507v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LexSumm and LexT5: Benchmarking and Modeling Legal Summarization Tasks\n  in English", "abstract": "In the evolving NLP landscape, benchmarks serve as yardsticks for gauging\nprogress. However, existing Legal NLP benchmarks only focus on predictive\ntasks, overlooking generative tasks. This work curates LexSumm, a benchmark\ndesigned for evaluating legal summarization tasks in English. It comprises\neight English legal summarization datasets, from diverse jurisdictions, such as\nthe US, UK, EU and India. Additionally, we release LexT5, legal oriented\nsequence-to-sequence model, addressing the limitation of the existing\nBERT-style encoder-only models in the legal domain. We assess its capabilities\nthrough zero-shot probing on LegalLAMA and fine-tuning on LexSumm. Our analysis\nreveals abstraction and faithfulness errors even in summaries generated by\nzero-shot LLMs, indicating opportunities for further improvements. LexSumm\nbenchmark and LexT5 model are available at\nhttps://github.com/TUMLegalTech/LexSumm-LexT5.", "published": "2024-10-12 13:16:51", "link": "http://arxiv.org/abs/2410.09527v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Speaker Turn-Aware Multi-Task Adversarial Network for Joint User\n  Satisfaction Estimation and Sentiment Analysis", "abstract": "User Satisfaction Estimation is an important task and increasingly being\napplied in goal-oriented dialogue systems to estimate whether the user is\nsatisfied with the service. It is observed that whether the user's needs are\nmet often triggers various sentiments, which can be pertinent to the successful\nestimation of user satisfaction, and vice versa. Thus, User Satisfaction\nEstimation (USE) and Sentiment Analysis (SA) should be treated as a joint,\ncollaborative effort, considering the strong connections between the sentiment\nstates of speakers and the user satisfaction. Existing joint learning\nframeworks mainly unify the two highly pertinent tasks over cascade or\nshared-bottom implementations, however they fail to distinguish task-specific\nand common features, which will produce sub-optimal utterance representations\nfor downstream tasks. In this paper, we propose a novel Speaker Turn-Aware\nMulti-Task Adversarial Network (STMAN) for dialogue-level USE and\nutterance-level SA. Specifically, we first introduce a multi-task adversarial\nstrategy which trains a task discriminator to make utterance representation\nmore task-specific, and then utilize a speaker-turn aware multi-task\ninteraction strategy to extract the common features which are complementary to\neach task. Extensive experiments conducted on two real-world service dialogue\ndatasets show that our model outperforms several state-of-the-art methods.", "published": "2024-10-12 15:03:53", "link": "http://arxiv.org/abs/2410.09556v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SAPIENT: Mastering Multi-turn Conversational Recommendation with\n  Strategic Planning and Monte Carlo Tree Search", "abstract": "Conversational Recommender Systems (CRS) proactively engage users in\ninteractive dialogues to elicit user preferences and provide personalized\nrecommendations. Existing methods train Reinforcement Learning (RL)-based agent\nwith greedy action selection or sampling strategy, and may suffer from\nsuboptimal conversational planning. To address this, we present a novel Monte\nCarlo Tree Search (MCTS)-based CRS framework SAPIENT. SAPIENT consists of a\nconversational agent (S-agent) and a conversational planner (S-planner).\nS-planner builds a conversational search tree with MCTS based on the initial\nactions proposed by S-agent to find conversation plans. The best conversation\nplans from S-planner are used to guide the training of S-agent, creating a\nself-training loop where S-agent can iteratively improve its capability for\nconversational planning. Furthermore, we propose an efficient variant SAPIENT-e\nfor trade-off between training efficiency and performance. Extensive\nexperiments on four benchmark datasets validate the effectiveness of our\napproach, showing that SAPIENT outperforms the state-of-the-art baselines.", "published": "2024-10-12 16:21:33", "link": "http://arxiv.org/abs/2410.09580v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "I or Not I: Unraveling the Linguistic Echoes of Identity in Samuel\n  Beckett's \"Not I\" Through Natural Language Processing", "abstract": "Exploring the depths of Samuel Beckett's \"Not I\" through advanced natural\nlanguage processing techniques, this research uncovers the intricate linguistic\nstructures that underpin the text. By analyzing word frequency, detecting\nemotional sentiments with a BERT-based model, and examining repetitive motifs,\nwe unveil how Beckett's minimalist yet complex language reflects the\nprotagonist's fragmented psyche. Our results demonstrate that recurring themes\nof time, memory, and existential angst are artfully woven through recursive\nlinguistic patterns and rhythmic repetition. This innovative approach not only\ndeepens our understanding of Beckett's stylistic contributions but also\nhighlights his unique role in modern literature, where language transcends\nsimple communication to explore profound existential questions.", "published": "2024-10-12 18:11:57", "link": "http://arxiv.org/abs/2410.09608v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Quebec Automobile Insurance Question-Answering With Retrieval-Augmented\n  Generation", "abstract": "Large Language Models (LLMs) perform outstandingly in various downstream\ntasks, and the use of the Retrieval-Augmented Generation (RAG) architecture has\nbeen shown to improve performance for legal question answering (Nuruzzaman and\nHussain, 2020; Louis et al., 2024). However, there are limited applications in\ninsurance questions-answering, a specific type of legal document. This paper\nintroduces two corpora: the Quebec Automobile Insurance Expertise Reference\nCorpus and a set of 82 Expert Answers to Layperson Automobile Insurance\nQuestions. Our study leverages both corpora to automatically and manually\nassess a GPT4-o, a state-of-the-art LLM, to answer Quebec automobile insurance\nquestions. Our results demonstrate that, on average, using our expertise\nreference corpus generates better responses on both automatic and manual\nevaluation metrics. However, they also highlight that LLM QA is unreliable\nenough for mass utilization in critical areas. Indeed, our results show that\nbetween 5% to 13% of answered questions include a false statement that could\nlead to customer misunderstanding.", "published": "2024-10-12 19:24:18", "link": "http://arxiv.org/abs/2410.09623v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhanced Electronic Health Records Text Summarization Using Large\n  Language Models", "abstract": "The development of Electronic Health Records summarization systems has\nrevolutionized patient data management. Previous research advanced this field\nby adapting Large Language Models for clinical tasks, using diverse datasets to\ngenerate general EHR summaries. However, clinicians often require specific,\nfocused summaries for quicker insights. This project builds on prior work by\ncreating a system that generates clinician-preferred, focused summaries,\nimproving EHR summarization for more efficient patient care. The proposed\nsystem leverages the Google Flan-T5 model to generate tailored EHR summaries\nbased on clinician-specified topics. The approach involved fine-tuning the\nFlan-T5 model on an EHR question-answering dataset formatted in the Stanford\nQuestion Answering Dataset (SQuAD) style, which is a large-scale reading\ncomprehension dataset with questions and answers. Fine-tuning utilized the\nSeq2SeqTrainer from the Hugging Face Transformers library with optimized\nhyperparameters. Key evaluation metrics demonstrated promising results: the\nsystem achieved an Exact Match (EM) score of 81.81%. ROUGE (Recall-Oriented\nUnderstudy for Gisting Evaluation) metrics showed strong performance, with\nROUGE-1 at 96.03%, ROUGE-2 at 86.67%, and ROUGE-L at 96.10%. Additionally, the\nBilingual Evaluation Understudy (BLEU) score was 63%, reflecting the model's\ncoherence in generating summaries. By enhancing EHR summarization through LLMs,\nthis project supports digital transformation efforts in healthcare,\nstreamlining workflows, and enabling more personalized patient care.", "published": "2024-10-12 19:36:41", "link": "http://arxiv.org/abs/2410.09628v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Society of Medical Simplifiers", "abstract": "Medical text simplification is crucial for making complex biomedical\nliterature more accessible to non-experts. Traditional methods struggle with\nthe specialized terms and jargon of medical texts, lacking the flexibility to\nadapt the simplification process dynamically. In contrast, recent advancements\nin large language models (LLMs) present unique opportunities by offering\nenhanced control over text simplification through iterative refinement and\ncollaboration between specialized agents. In this work, we introduce the\nSociety of Medical Simplifiers, a novel LLM-based framework inspired by the\n\"Society of Mind\" (SOM) philosophy. Our approach leverages the strengths of\nLLMs by assigning five distinct roles, i.e., Layperson, Simplifier, Medical\nExpert, Language Clarifier, and Redundancy Checker, organized into interaction\nloops. This structure allows the agents to progressively improve text\nsimplification while maintaining the complexity and accuracy of the original\ncontent. Evaluations on the Cochrane text simplification dataset demonstrate\nthat our framework is on par with or outperforms state-of-the-art methods,\nachieving superior readability and content preservation through controlled\nsimplification processes.", "published": "2024-10-12 19:52:56", "link": "http://arxiv.org/abs/2410.09631v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SciGisPy: a Novel Metric for Biomedical Text Simplification via Gist\n  Inference Score", "abstract": "Biomedical literature is often written in highly specialized language, posing\nsignificant comprehension challenges for non-experts. Automatic text\nsimplification (ATS) offers a solution by making such texts more accessible\nwhile preserving critical information. However, evaluating ATS for biomedical\ntexts is still challenging due to the limitations of existing evaluation\nmetrics. General-domain metrics like SARI, BLEU, and ROUGE focus on\nsurface-level text features, and readability metrics like FKGL and ARI fail to\naccount for domain-specific terminology or assess how well the simplified text\nconveys core meanings (gist). To address this, we introduce SciGisPy, a novel\nevaluation metric inspired by Gist Inference Score (GIS) from Fuzzy-Trace\nTheory (FTT). SciGisPy measures how well a simplified text facilitates the\nformation of abstract inferences (gist) necessary for comprehension, especially\nin the biomedical domain. We revise GIS for this purpose by introducing\ndomain-specific enhancements, including semantic chunking, Information Content\n(IC) theory, and specialized embeddings, while removing unsuitable indexes. Our\nexperimental evaluation on the Cochrane biomedical text simplification dataset\ndemonstrates that SciGisPy outperforms the original GIS formulation, with a\nsignificant increase in correctly identified simplified texts (84% versus\n44.8%). The results and a thorough ablation study confirm that SciGisPy better\ncaptures the essential meaning of biomedical content, outperforming existing\napproaches.", "published": "2024-10-12 19:53:56", "link": "http://arxiv.org/abs/2410.09632v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RepMatch: Quantifying Cross-Instance Similarities in Representation\n  Space", "abstract": "Advances in dataset analysis techniques have enabled more sophisticated\napproaches to analyzing and characterizing training data instances, often\ncategorizing data based on attributes such as ``difficulty''. In this work, we\nintroduce RepMatch, a novel method that characterizes data through the lens of\nsimilarity. RepMatch quantifies the similarity between subsets of training\ninstances by comparing the knowledge encoded in models trained on them,\novercoming the limitations of existing analysis methods that focus solely on\nindividual instances and are restricted to within-dataset analysis. Our\nframework allows for a broader evaluation, enabling similarity comparisons\nacross arbitrary subsets of instances, supporting both dataset-to-dataset and\ninstance-to-dataset analyses. We validate the effectiveness of RepMatch across\nmultiple NLP tasks, datasets, and models. Through extensive experimentation, we\ndemonstrate that RepMatch can effectively compare datasets, identify more\nrepresentative subsets of a dataset (that lead to better performance than\nrandomly selected subsets of equivalent size), and uncover heuristics\nunderlying the construction of some challenge datasets.", "published": "2024-10-12 20:42:28", "link": "http://arxiv.org/abs/2410.09642v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adapters for Altering LLM Vocabularies: What Languages Benefit the Most?", "abstract": "Vocabulary adaptation, which integrates new vocabulary into pre-trained\nlanguage models, enables expansion to new languages and mitigates token\nover-fragmentation. However, existing approaches are limited by their reliance\non heuristics or external embeddings. We propose VocADT, a novel method for\nvocabulary adaptation using adapter modules that are trained to learn the\noptimal linear combination of existing embeddings while keeping the model's\nweights fixed. VocADT offers a flexible and scalable solution without depending\non external resources or language constraints. Across 11 languages-with diverse\nscripts, resource availability, and fragmentation-we demonstrate that VocADT\noutperforms the original Mistral model and other baselines across various\nmultilingual tasks including natural language understanding and machine\ntranslation. We find that Latin-script languages and highly fragmented\nlanguages benefit the most from vocabulary adaptation. We further fine-tune the\nadapted model on the generative task of machine translation and find that\nvocabulary adaptation is still beneficial after fine-tuning and that VocADT is\nthe most effective.", "published": "2024-10-12 20:45:24", "link": "http://arxiv.org/abs/2410.09644v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "COrAL: Order-Agnostic Language Modeling for Efficient Iterative\n  Refinement", "abstract": "Iterative refinement has emerged as an effective paradigm for enhancing the\ncapabilities of large language models (LLMs) on complex tasks. However,\nexisting approaches typically implement iterative refinement at the application\nor prompting level, relying on autoregressive (AR) modeling. The sequential\ntoken generation in AR models can lead to high inference latency. To overcome\nthese challenges, we propose Context-Wise Order-Agnostic Language Modeling\n(COrAL), which incorporates iterative refinement directly into the LLM\narchitecture while maintaining computational efficiency. Our approach models\nmultiple token dependencies within manageable context windows, enabling the\nmodel to perform iterative refinement internally during the generation process.\nLeveraging the order-agnostic nature of COrAL, we introduce sliding blockwise\norder-agnostic decoding, which performs multi-token forward prediction and\nbackward reconstruction within context windows. This allows the model to\niteratively refine its outputs in parallel in the sliding block, effectively\ncapturing diverse dependencies without the high inference cost of sequential\ngeneration. Empirical evaluations on reasoning tasks demonstrate that COrAL\nimproves performance and inference speed, respectively, achieving absolute\naccuracy gains of $4.6\\%$ on GSM8K and $4.0\\%$ on LogiQA, along with inference\nspeedups of up to $3.9\\times$ over next-token baselines. Preliminary results on\ncode generation indicate a drop in pass rates due to inconsistencies in\norder-agnostic outputs, highlighting the inherent quality--speed trade-off. Our\ncode is publicly available at https://github.com/YuxiXie/COrAL.", "published": "2024-10-12 23:56:19", "link": "http://arxiv.org/abs/2410.09675v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "\\llinstruct: An Instruction-tuned model for English Language Proficiency\n  Assessments", "abstract": "We present \\llinstruct: An 8B instruction-tuned model that is designed to\ngenerate content for English Language Proficiency Assessments (ELPA) and\nrelated applications. Our work involves creating a new dataset of 70K\ninstructions and explanations in the ELPA domain and using these to fine-tune\nLlama-3 8B models (SFT) of different sizes (e.g., SFT-17K, SFT-50K and\nSFT-70K). Human evaluations are conducted over unseen instructions to compare\nthese SFT models against SOTA models (e.g., Dolly-2, Mistral, Llama-3 base\nversion, and GPT-3.5). The findings show although all three SFT models perform\ncomparably, the model trained on largest instruction dataset -- SFT-70K - leads\nto the most valid outputs ready for assessments. However, although the SFT\nmodels perform better than larger model, e.g., GPT 3.5 on the aspect of\nexplanations of outputs, many outputs still need human interventions to make\nthem actual ready for real world assessments.", "published": "2024-10-12 00:47:45", "link": "http://arxiv.org/abs/2410.09314v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Hey AI Can You Grade My Essay?: Automatic Essay Grading", "abstract": "Automatic essay grading (AEG) has attracted the the attention of the NLP\ncommunity because of its applications to several educational applications, such\nas scoring essays, short answers, etc. AEG systems can save significant time\nand money when grading essays. In the existing works, the essays are graded\nwhere a single network is responsible for the whole process, which may be\nineffective because a single network may not be able to learn all the features\nof a human-written essay. In this work, we have introduced a new model that\noutperforms the state-of-the-art models in the field of AEG. We have used the\nconcept of collaborative and transfer learning, where one network will be\nresponsible for checking the grammatical and structural features of the\nsentences of an essay while another network is responsible for scoring the\noverall idea present in the essay. These learnings are transferred to another\nnetwork to score the essay. We also compared the performances of the different\nmodels mentioned in our work, and our proposed model has shown the highest\naccuracy of 85.50%.", "published": "2024-10-12 01:17:55", "link": "http://arxiv.org/abs/2410.09319v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Zero-shot Commonsense Reasoning over Machine Imagination", "abstract": "Recent approaches to zero-shot commonsense reasoning have enabled Pre-trained\nLanguage Models (PLMs) to learn a broad range of commonsense knowledge without\nbeing tailored to specific situations. However, they often suffer from human\nreporting bias inherent in textual commonsense knowledge, leading to\ndiscrepancies in understanding between PLMs and humans. In this work, we aim to\nbridge this gap by introducing an additional information channel to PLMs. We\npropose Imagine (Machine Imagination-based Reasoning), a novel zero-shot\ncommonsense reasoning framework designed to complement textual inputs with\nvisual signals derived from machine-generated images. To achieve this, we\nenhance PLMs with imagination capabilities by incorporating an image generator\ninto the reasoning process. To guide PLMs in effectively leveraging machine\nimagination, we create a synthetic pre-training dataset that simulates visual\nquestion-answering. Our extensive experiments on diverse reasoning benchmarks\nand analysis show that Imagine outperforms existing methods by a large margin,\nhighlighting the strength of machine imagination in mitigating reporting bias\nand enhancing generalization capabilities.", "published": "2024-10-12 02:15:11", "link": "http://arxiv.org/abs/2410.09329v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Rethinking Data Selection at Scale: Random Selection is Almost All You\n  Need", "abstract": "Supervised fine-tuning (SFT) is crucial for aligning Large Language Models\n(LLMs) with human instructions. The primary goal during SFT is to select a\nsmall yet representative subset of training data from the larger pool, such\nthat fine-tuning with this subset achieves results comparable to or even\nexceeding those obtained using the entire dataset. However, most existing data\nselection techniques are designed for small-scale data pools, which fail to\nmeet the demands of real-world SFT scenarios. In this paper, we replicated\nseveral self-scoring methods those that do not rely on external model\nassistance on two million scale datasets, and found that nearly all methods\nstruggled to significantly outperform random selection when dealing with such\nlarge-scale data pools. Moreover, our comparisons suggest that, during SFT,\ndiversity in data selection is more critical than simply focusing on high\nquality data. We also analyzed the limitations of several current approaches,\nexplaining why they perform poorly on large-scale datasets and why they are\nunsuitable for such contexts. Finally, we found that filtering data by token\nlength offers a stable and efficient method for improving results. This\napproach, particularly when training on long text data, proves highly\nbeneficial for relatively weaker base models, such as Llama3.", "published": "2024-10-12 02:48:34", "link": "http://arxiv.org/abs/2410.09335v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Generative Subgraph Retrieval for Knowledge Graph-Grounded Dialog\n  Generation", "abstract": "Knowledge graph-grounded dialog generation requires retrieving a\ndialog-relevant subgraph from the given knowledge base graph and integrating it\nwith the dialog history. Previous works typically represent the graph using an\nexternal encoder, such as graph neural networks, and retrieve relevant triplets\nbased on the similarity between single-vector representations of triplets and\nthe dialog history. However, these external encoders fail to leverage the rich\nknowledge of pretrained language models, and the retrieval process is also\nsuboptimal due to the information bottleneck caused by the single-vector\nabstraction of the dialog history. In this work, we propose Dialog generation\nwith Generative Subgraph Retrieval (DialogGSR), which retrieves relevant\nknowledge subgraphs by directly generating their token sequences on top of\nlanguage models. For effective generative subgraph retrieval, we introduce two\nkey methods: (i) structure-aware knowledge graph linearization with\nself-supervised graph-specific tokens and (ii) graph-constrained decoding\nutilizing graph structural proximity-based entity informativeness scores for\nvalid and relevant generative retrieval. DialogGSR achieves state-of-the-art\nperformance in knowledge graph-grounded dialog generation, as demonstrated on\nOpenDialKG and KOMODIS datasets.", "published": "2024-10-12 03:33:42", "link": "http://arxiv.org/abs/2410.09350v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LogLM: From Task-based to Instruction-based Automated Log Analysis", "abstract": "Automatic log analysis is essential for the efficient Operation and\nMaintenance (O&M) of software systems, providing critical insights into system\nbehaviors. However, existing approaches mostly treat log analysis as training a\nmodel to perform an isolated task ( e.g., anomaly detection, log parsing, etc.)\nusing task-specific log-label pairs. These task-based approaches are inflexible\nin generalizing to complex scenarios, depend on task-specific training data,\nand cost significantly when deploying multiple models. In this paper, we\npropose an instruction-based training approach that transforms log-label pairs\nfrom multiple tasks and domains into a unified format of instruction-response\npairs. Our trained model, LogLM, can follow complex user instructions and\ngeneralize better across different tasks, thereby increasing flexibility and\nreducing the dependence on task-specific training data. By integrating major\nlog analysis tasks into a single model, our approach also relieves model\ndeployment burden. Experimentally, LogLM outperforms existing approaches across\nfive log analysis capabilities, and exhibits strong generalization abilities on\ncomplex instructions and unseen tasks.", "published": "2024-10-12 03:36:52", "link": "http://arxiv.org/abs/2410.09352v2", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Text Classification using Graph Convolutional Networks: A Comprehensive\n  Survey", "abstract": "Text classification is a quintessential and practical problem in natural\nlanguage processing with applications in diverse domains such as sentiment\nanalysis, fake news detection, medical diagnosis, and document classification.\nA sizable body of recent works exists where researchers have studied and\ntackled text classification from different angles with varying degrees of\nsuccess. Graph convolution network (GCN)-based approaches have gained a lot of\ntraction in this domain over the last decade with many implementations\nachieving state-of-the-art performance in more recent literature and thus,\nwarranting the need for an updated survey. This work aims to summarize and\ncategorize various GCN-based Text Classification approaches with regard to the\narchitecture and mode of supervision. It identifies their strengths and\nlimitations and compares their performance on various benchmark datasets. We\nalso discuss future research directions and the challenges that exist in this\ndomain.", "published": "2024-10-12 07:03:42", "link": "http://arxiv.org/abs/2410.09399v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FB-Bench: A Fine-Grained Multi-Task Benchmark for Evaluating LLMs'\n  Responsiveness to Human Feedback", "abstract": "Human feedback is crucial in the interactions between humans and Large\nLanguage Models (LLMs). However, existing research primarily focuses on\nbenchmarking LLMs in single-turn dialogues. Even in benchmarks designed for\nmulti-turn dialogues, the user inputs are often independent, neglecting the\nnuanced and complex nature of human feedback within real-world usage scenarios.\nTo fill this research gap, we introduce FB-Bench, a fine-grained, multi-task\nbenchmark designed to evaluate LLMs' responsiveness to human feedback under\nreal-world usage scenarios in Chinese. Drawing from the two main interaction\nscenarios, FB-Bench comprises 591 meticulously curated samples, encompassing\neight task types, five deficiency types of response, and nine feedback types.\nWe extensively evaluate a broad array of popular LLMs, revealing significant\nvariations in their performance across different interaction scenarios. Further\nanalysis indicates that task, human feedback, and deficiencies of previous\nresponses can also significantly impact LLMs' responsiveness. Our findings\nunderscore both the strengths and limitations of current models, providing\nvaluable insights and directions for future research. Code and datasets are\navailable at https://github.com/PKU-Baichuan-MLSystemLab/FB-Bench.", "published": "2024-10-12 07:40:01", "link": "http://arxiv.org/abs/2410.09412v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language\n  Models Alignment", "abstract": "As large vision-language models (LVLMs) evolve rapidly, the demand for\nhigh-quality and diverse data to align these models becomes increasingly\ncrucial. However, the creation of such data with human supervision proves\ncostly and time-intensive. In this paper, we investigate the efficacy of AI\nfeedback to scale supervision for aligning LVLMs. We introduce VLFeedback, the\nfirst large-scale vision-language feedback dataset, comprising over 82K\nmulti-modal instructions and comprehensive rationales generated by\noff-the-shelf models without human annotations. To evaluate the effectiveness\nof AI feedback for vision-language alignment, we train Silkie, an LVLM\nfine-tuned via direct preference optimization on VLFeedback. Silkie showcases\nexceptional performance regarding helpfulness, visual faithfulness, and safety\nmetrics. It outperforms its base model by 6.9\\% and 9.5\\% in perception and\ncognition tasks, reduces hallucination issues on MMHal-Bench, and exhibits\nenhanced resilience against red-teaming attacks. Furthermore, our analysis\nunderscores the advantage of AI feedback, particularly in fostering preference\ndiversity to deliver more comprehensive improvements. Our dataset, training\ncode and models are available at https://vlf-silkie.github.io.", "published": "2024-10-12 07:56:47", "link": "http://arxiv.org/abs/2410.09421v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "FlatQuant: Flatness Matters for LLM Quantization", "abstract": "Recently, quantization has been widely used for the compression and\nacceleration of large language models~(LLMs). Due to the outliers in LLMs, it\nis crucial to flatten weights and activations to minimize quantization error\nwith the equally spaced quantization points. Prior research explores various\npre-quantization transformations to suppress outliers, such as per-channel\nscaling and Hadamard transformation. However, we observe that these transformed\nweights and activations can still remain steep and outspread. In this paper, we\npropose FlatQuant (Fast and Learnable Affine Transformation), a new\npost-training quantization approach to enhance flatness of weights and\nactivations. Our approach identifies optimal affine transformations tailored to\neach linear layer, calibrated in hours via a lightweight objective. To reduce\nruntime overhead, we apply Kronecker decomposition to the transformation\nmatrices, and fuse all operations in FlatQuant into a single kernel. Extensive\nexperiments show that FlatQuant sets up a new state-of-the-art quantization\nbenchmark. For instance, it achieves less than $\\textbf{1}\\%$ accuracy drop for\nW4A4 quantization on the LLaMA-3-70B model, surpassing SpinQuant by\n$\\textbf{7.5}\\%$. For inference latency, FlatQuant reduces the slowdown induced\nby pre-quantization transformation from 0.26x of QuaRot to merely\n$\\textbf{0.07x}$, bringing up to $\\textbf{2.3x}$ speedup for prefill and\n$\\textbf{1.7x}$ speedup for decoding, respectively. Code is available at:\n\\url{https://github.com/ruikangliu/FlatQuant}.", "published": "2024-10-12 08:10:28", "link": "http://arxiv.org/abs/2410.09426v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Declarative Knowledge Distillation from Large Language Models for Visual\n  Question Answering Datasets", "abstract": "Visual Question Answering (VQA) is the task of answering a question about an\nimage and requires processing multimodal input and reasoning to obtain the\nanswer. Modular solutions that use declarative representations within the\nreasoning component have a clear advantage over end-to-end trained systems\nregarding interpretability. The downside is that crafting the rules for such a\ncomponent can be an additional burden on the developer. We address this\nchallenge by presenting an approach for declarative knowledge distillation from\nLarge Language Models (LLMs). Our method is to prompt an LLM to extend an\ninitial theory on VQA reasoning, given as an answer-set program, to meet the\nrequirements of the VQA task. Examples from the VQA dataset are used to guide\nthe LLM, validate the results, and mend rules if they are not correct by using\nfeedback from the ASP solver. We demonstrate that our approach works on the\nprominent CLEVR and GQA datasets. Our results confirm that distilling knowledge\nfrom LLMs is in fact a promising direction besides data-driven rule learning\napproaches.", "published": "2024-10-12 08:17:03", "link": "http://arxiv.org/abs/2410.09428v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Automatic Speech Recognition with BERT and CTC Transformers: A Review", "abstract": "This review paper provides a comprehensive analysis of recent advances in\nautomatic speech recognition (ASR) with bidirectional encoder representations\nfrom transformers BERT and connectionist temporal classification (CTC)\ntransformers. The paper first introduces the fundamental concepts of ASR and\ndiscusses the challenges associated with it. It then explains the architecture\nof BERT and CTC transformers and their potential applications in ASR. The paper\nreviews several studies that have used these models for speech recognition\ntasks and discusses the results obtained. Additionally, the paper highlights\nthe limitations of these models and outlines potential areas for further\nresearch. All in all, this review provides valuable insights for researchers\nand practitioners who are interested in ASR with BERT and CTC transformers.", "published": "2024-10-12 09:27:48", "link": "http://arxiv.org/abs/2410.09456v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "CollabEdit: Towards Non-destructive Collaborative Knowledge Editing", "abstract": "Collaborative learning of large language models (LLMs) has emerged as a new\nparadigm for utilizing private data from different parties to guarantee\nefficiency and privacy. Meanwhile, Knowledge Editing (KE) for LLMs has also\ngarnered increased attention due to its ability to manipulate the behaviors of\nLLMs explicitly, yet leaves the collaborative KE case (in which knowledge edits\nof multiple parties are aggregated in a privacy-preserving and continual\nmanner) unexamined. To this end, this manuscript dives into the first\ninvestigation of collaborative KE, in which we start by carefully identifying\nthe unique three challenges therein, including knowledge overlap, knowledge\nconflict, and knowledge forgetting. We then propose a non-destructive\ncollaborative KE framework, COLLABEDIT, which employs a novel model merging\nmechanism to mimic the global KE behavior while preventing the severe\nperformance drop. Extensive experiments on two canonical datasets demonstrate\nthe superiority of COLLABEDIT compared to other destructive baselines, and\nresults shed light on addressing three collaborative KE challenges and future\napplications. Our code is available at https://github.com/LINs-lab/CollabEdit.", "published": "2024-10-12 12:10:14", "link": "http://arxiv.org/abs/2410.09508v4", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Scito2M: A 2 Million, 30-Year Cross-disciplinary Dataset for Temporal\n  Scientometric Analysis", "abstract": "Understanding the creation, evolution, and dissemination of scientific\nknowledge is crucial for bridging diverse subject areas and addressing complex\nglobal challenges such as pandemics, climate change, and ethical AI.\nScientometrics, the quantitative and qualitative study of scientific\nliterature, provides valuable insights into these processes. We introduce\nScito2M, a longitudinal scientometric dataset with over two million academic\npublications, providing comprehensive contents information and citation graphs\nto support cross-disciplinary analyses. Using Scito2M, we conduct a temporal\nstudy spanning over 30 years to explore key questions in scientometrics: the\nevolution of academic terminology, citation patterns, and interdisciplinary\nknowledge exchange. Our findings reveal critical insights, such as disparities\nin epistemic cultures, knowledge production modes, and citation practices. For\nexample, rapidly developing, application-driven fields like LLMs exhibit\nsignificantly shorter citation age (2.48 years) compared to traditional\ntheoretical disciplines like oral history (9.71 years).", "published": "2024-10-12 12:16:57", "link": "http://arxiv.org/abs/2410.09510v1", "categories": ["cs.DL", "cs.CL"], "primary_category": "cs.DL"}
{"title": "LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language\n  Model for Commonsense Reasoning", "abstract": "Large language models (LLMs) sometimes demonstrate poor performance on\nknowledge-intensive tasks, commonsense reasoning is one of them. Researchers\ntypically address these issues by retrieving related knowledge from knowledge\ngraphs or employing self-enhancement methods to elicit knowledge in LLMs.\nHowever, noisy knowledge and invalid reasoning issues hamper their ability to\nanswer questions accurately. To this end, we propose a novel method named\neliciting, filtering and integrating knowledge in large language model\n(LINKED). In it, we design a reward model to filter out the noisy knowledge and\ntake the marginal consistent reasoning module to reduce invalid reasoning. With\nour comprehensive experiments on two complex commonsense reasoning benchmarks,\nour method outperforms SOTA baselines (up to 9.0% improvement of accuracy).\nBesides, to measure the positive and negative impact of the injected knowledge,\nwe propose a new metric called effectiveness-preservation score for the\nknowledge enhancement works. Finally, through extensive experiments, we conduct\nan in-depth analysis and find many meaningful conclusions about LLMs in\ncommonsense reasoning tasks.", "published": "2024-10-12 14:12:22", "link": "http://arxiv.org/abs/2410.09541v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MIRAGE: Evaluating and Explaining Inductive Reasoning Process in\n  Language Models", "abstract": "Inductive reasoning is an essential capability for large language models\n(LLMs) to achieve higher intelligence, which requires the model to generalize\nrules from observed facts and then apply them to unseen examples. We present\nMIRAGE, a synthetic dataset that addresses the limitations of previous work,\nspecifically the lack of comprehensive evaluation and flexible test data. In\nit, we evaluate LLMs' capabilities in both the inductive and deductive stages,\nallowing for flexible variation in input distribution, task scenario, and task\ndifficulty to analyze the factors influencing LLMs' inductive reasoning. Based\non these multi-faceted evaluations, we demonstrate that the LLM is a poor\nrule-based reasoner. In many cases, when conducting inductive reasoning, they\ndo not rely on a correct rule to answer the unseen case. From the perspectives\nof different prompting methods, observation numbers, and task forms, models\ntend to consistently conduct correct deduction without correct inductive rules.\nBesides, we find that LLMs are good neighbor-based reasoners. In the inductive\nreasoning process, the model tends to focus on observed facts that are close to\nthe current test example in feature space. By leveraging these similar\nexamples, the model maintains strong inductive capabilities within a localized\nregion, significantly improving its deductive performance.", "published": "2024-10-12 14:12:36", "link": "http://arxiv.org/abs/2410.09542v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring space efficiency in a tree-based linear model for extreme\n  multi-label classification", "abstract": "Extreme multi-label classification (XMC) aims to identify relevant subsets\nfrom numerous labels. Among the various approaches for XMC, tree-based linear\nmodels are effective due to their superior efficiency and simplicity. However,\nthe space complexity of tree-based methods is not well-studied. Many past works\nassume that storing the model is not affordable and apply techniques such as\npruning to save space, which may lead to performance loss. In this work, we\nconduct both theoretical and empirical analyses on the space to store a tree\nmodel under the assumption of sparse data, a condition frequently met in text\ndata. We found that, some features may be unused when training binary\nclassifiers in a tree method, resulting in zero values in the weight vectors.\nHence, storing only non-zero elements can greatly save space. Our experimental\nresults indicate that tree models can achieve up to a 95% reduction in storage\nspace compared to the standard one-vs-rest method for multi-label text\nclassification. Our research provides a simple procedure to estimate the size\nof a tree model before training any classifier in the tree nodes. Then, if the\nmodel size is already acceptable, this approach can help avoid modifying the\nmodel through weight pruning or other techniques.", "published": "2024-10-12 15:02:40", "link": "http://arxiv.org/abs/2410.09554v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Extended Japanese Commonsense Morality Dataset with Masked Token and\n  Label Enhancement", "abstract": "Rapid advancements in artificial intelligence (AI) have made it crucial to\nintegrate moral reasoning into AI systems. However, existing models and\ndatasets often overlook regional and cultural differences. To address this\nshortcoming, we have expanded the JCommonsenseMorality (JCM) dataset, the only\npublicly available dataset focused on Japanese morality. The Extended JCM\n(eJCM) has grown from the original 13,975 sentences to 31,184 sentences using\nour proposed sentence expansion method called Masked Token and Label\nEnhancement (MTLE). MTLE selectively masks important parts of sentences related\nto moral judgment and replaces them with alternative expressions generated by a\nlarge language model (LLM), while re-assigning appropriate labels. The model\ntrained using our eJCM achieved an F1 score of 0.857, higher than the scores\nfor the original JCM (0.837), ChatGPT one-shot classification (0.841), and data\naugmented using AugGPT, a state-of-the-art augmentation method (0.850).\nSpecifically, in complex moral reasoning tasks unique to Japanese culture, the\nmodel trained with eJCM showed a significant improvement in performance\n(increasing from 0.681 to 0.756) and achieved a performance close to that of\nGPT-4 Turbo (0.787). These results demonstrate the validity of the eJCM dataset\nand the importance of developing models and datasets that consider the cultural\ncontext.", "published": "2024-10-12 15:21:40", "link": "http://arxiv.org/abs/2410.09564v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Are You Human? An Adversarial Benchmark to Expose LLMs", "abstract": "Large Language Models (LLMs) have demonstrated an alarming ability to\nimpersonate humans in conversation, raising concerns about their potential\nmisuse in scams and deception. Humans have a right to know if they are\nconversing to an LLM. We evaluate text-based prompts designed as challenges to\nexpose LLM imposters in real-time. To this end we compile and release an\nopen-source benchmark dataset that includes 'implicit challenges' that exploit\nan LLM's instruction-following mechanism to cause role deviation, and 'exlicit\nchallenges' that test an LLM's ability to perform simple tasks typically easy\nfor humans but difficult for LLMs. Our evaluation of 9 leading models from the\nLMSYS leaderboard revealed that explicit challenges successfully detected LLMs\nin 78.4% of cases, while implicit challenges were effective in 22.9% of\ninstances. User studies validate the real-world applicability of our methods,\nwith humans outperforming LLMs on explicit challenges (78% vs 22% success\nrate). Our framework unexpectedly revealed that many study participants were\nusing LLMs to complete tasks, demonstrating its effectiveness in detecting both\nAI impostors and human misuse of AI tools. This work addresses the critical\nneed for reliable, real-time LLM detection methods in high-stakes\nconversations.", "published": "2024-10-12 15:33:50", "link": "http://arxiv.org/abs/2410.09569v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Future of Learning in the Age of Generative AI: Automated Question\n  Generation and Assessment with Large Language Models", "abstract": "In recent years, large language models (LLMs) and generative AI have\nrevolutionized natural language processing (NLP), offering unprecedented\ncapabilities in education. This chapter explores the transformative potential\nof LLMs in automated question generation and answer assessment. It begins by\nexamining the mechanisms behind LLMs, emphasizing their ability to comprehend\nand generate human-like text. The chapter then discusses methodologies for\ncreating diverse, contextually relevant questions, enhancing learning through\ntailored, adaptive strategies. Key prompting techniques, such as zero-shot and\nchain-of-thought prompting, are evaluated for their effectiveness in generating\nhigh-quality questions, including open-ended and multiple-choice formats in\nvarious languages. Advanced NLP methods like fine-tuning and prompt-tuning are\nexplored for their role in generating task-specific questions, despite\nassociated costs. The chapter also covers the human evaluation of generated\nquestions, highlighting quality variations across different methods and areas\nfor improvement. Furthermore, it delves into automated answer assessment,\ndemonstrating how LLMs can accurately evaluate responses, provide constructive\nfeedback, and identify nuanced understanding or misconceptions. Examples\nillustrate both successful assessments and areas needing improvement. The\ndiscussion underscores the potential of LLMs to replace costly, time-consuming\nhuman assessments when appropriately guided, showcasing their advanced\nunderstanding and reasoning capabilities in streamlining educational processes.", "published": "2024-10-12 15:54:53", "link": "http://arxiv.org/abs/2410.09576v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Training Dynamics of Transformers to Recognize Word Co-occurrence via\n  Gradient Flow Analysis", "abstract": "Understanding the training dynamics of transformers is important to explain\nthe impressive capabilities behind large language models. In this work, we\nstudy the dynamics of training a shallow transformer on a task of recognizing\nco-occurrence of two designated words. In the literature of studying training\ndynamics of transformers, several simplifications are commonly adopted such as\nweight reparameterization, attention linearization, special initialization, and\nlazy regime. In contrast, we analyze the gradient flow dynamics of\nsimultaneously training three attention matrices and a linear MLP layer from\nrandom initialization, and provide a framework of analyzing such dynamics via a\ncoupled dynamical system. We establish near minimum loss and characterize the\nattention model after training. We discover that gradient flow serves as an\ninherent mechanism that naturally divide the training process into two phases.\nIn Phase 1, the linear MLP quickly aligns with the two target signals for\ncorrect classification, whereas the softmax attention remains almost unchanged.\nIn Phase 2, the attention matrices and the MLP evolve jointly to enlarge the\nclassification margin and reduce the loss to a near minimum value. Technically,\nwe prove a novel property of the gradient flow, termed \\textit{automatic\nbalancing of gradients}, which enables the loss values of different samples to\ndecrease almost at the same rate and further facilitates the proof of near\nminimum training loss. We also conduct experiments to verify our theoretical\nresults.", "published": "2024-10-12 17:50:58", "link": "http://arxiv.org/abs/2410.09605v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Traversing Emotional Landscapes and Linguistic Patterns in Bernard-Marie\n  Kolt\u00e8s' Plays: An NLP Perspective", "abstract": "This study employs Natural Language Processing (NLP) to analyze the intricate\nlinguistic and emotional dimensions within the plays of Bernard-Marie Kolt\\`es,\na central figure in contemporary French theatre. By integrating advanced\ncomputational techniques, we dissect Kolt\\`es' narrative style, revealing the\nsubtle interplay between language and emotion across his dramatic oeuvre. Our\nfindings highlight how Kolt\\`es crafts his narratives, enriching our\nunderstanding of his thematic explorations and contributing to the broader\nfield of digital humanities in literary analysis.", "published": "2024-10-12 18:13:47", "link": "http://arxiv.org/abs/2410.09609v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Transformer-based Language Models for Reasoning in the Description Logic\n  ALCQ", "abstract": "Recent advancements in transformer-based language models have sparked\nresearch into their logical reasoning capabilities. Most of the benchmarks used\nto evaluate these models are simple: generated from short (fragments of)\nfirst-order logic sentences with only a few logical operators and quantifiers.\nWe construct the natural language dataset, DELTA$_D$, using the expressive\ndescription logic language $\\mathcal{ALCQ}$. DELTA$_D$ comprises 384K examples\nand increases in two dimensions: i) reasoning depth, and ii) linguistic\ncomplexity. In this way, we systematically investigate the logical reasoning\ncapabilities of a supervised fine-tuned DeBERTa-based model and two large\nlanguage models (GPT-3.5, GPT-4) with few-shot prompting. We show that the\nDeBERTa-based model fine-tuned on our dataset can master the entailment\nchecking task. Moreover, the performance of GPTs can improve significantly even\nwhen a small number of samples is provided (9 shots). We open-source our code\nand datasets.", "published": "2024-10-12 18:25:34", "link": "http://arxiv.org/abs/2410.09613v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "OpenR: An Open Source Framework for Advanced Reasoning with Large\n  Language Models", "abstract": "In this technical report, we introduce OpenR, an open-source framework\ndesigned to integrate key components for enhancing the reasoning capabilities\nof large language models (LLMs). OpenR unifies data acquisition, reinforcement\nlearning training (both online and offline), and non-autoregressive decoding\ninto a cohesive software platform. Our goal is to establish an open-source\nplatform and community to accelerate the development of LLM reasoning. Inspired\nby the success of OpenAI's o1 model, which demonstrated improved reasoning\nabilities through step-by-step reasoning and reinforcement learning, OpenR\nintegrates test-time compute, reinforcement learning, and process supervision\nto improve reasoning in LLMs. Our work is the first to provide an open-source\nframework that explores the core techniques of OpenAI's o1 model with\nreinforcement learning, achieving advanced reasoning capabilities beyond\ntraditional autoregressive methods. We demonstrate the efficacy of OpenR by\nevaluating it on the MATH dataset, utilising publicly available data and search\nmethods. Our initial experiments confirm substantial gains, with relative\nimprovements in reasoning and performance driven by test-time computation and\nreinforcement learning through process reward models. The OpenR framework,\nincluding code, models, and datasets, is accessible at\nhttps://openreasoner.github.io.", "published": "2024-10-12 23:42:16", "link": "http://arxiv.org/abs/2410.09671v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Scaled and Inter-token Relation Enhanced Transformer for\n  Sample-restricted Residential NILM", "abstract": "Transformers have demonstrated exceptional performance across various domains\ndue to their self-attention mechanism, which captures complex relationships in\ndata. However, training on smaller datasets poses challenges, as standard\nattention mechanisms can over-smooth attention scores and overly prioritize\nintra-token relationships, reducing the capture of meaningful inter-token\ndependencies critical for tasks like Non-Intrusive Load Monitoring (NILM). To\naddress this, we propose a novel transformer architecture with two key\ninnovations: inter-token relation enhancement and dynamic temperature tuning.\nThe inter-token relation enhancement mechanism removes diagonal entries in the\nsimilarity matrix to improve attention focus on inter-token relations. The\ndynamic temperature tuning mechanism, a learnable parameter, adapts attention\nsharpness during training, preventing over-smoothing and enhancing sensitivity\nto token relationships. We validate our method on the REDD dataset and show\nthat it outperforms the original transformer and state-of-the-art models by\n10-15\\% in F1 score across various appliance types, demonstrating its efficacy\nfor training on smaller datasets.", "published": "2024-10-12 18:58:45", "link": "http://arxiv.org/abs/2410.12861v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Affinity Propagation for Improved Public Sentiment Insights", "abstract": "With the large amount of data generated every day, public sentiment is a key\nfactor for various fields, including marketing, politics, and social research.\nUnderstanding the public sentiment about different topics can provide valuable\ninsights. However, most traditional approaches for sentiment analysis often\ndepend on supervised learning, which requires a significant amount of labeled\ndata. This makes it both expensive and time-consuming to implement. This\nproject introduces an approach using unsupervised learning techniques,\nparticularly Affinity Propagation (AP) clustering, to analyze sentiment. AP\nclustering groups text data based on natural patterns, without needing\npredefined cluster numbers. The paper compares AP with K-means clustering,\nusing TF-IDF Vectorization for text representation and Principal Component\nAnalysis (PCA) for dimensionality reduction. To enhance performance, AP is\ncombined with Agglomerative Hierarchical Clustering. This hybrid method refines\nclusters further, capturing both global and local sentiment structures more\neffectively. The effectiveness of these methods is evaluated using the\nSilhouette Score, Calinski-Harabasz Score, and Davies-Bouldin Index. Results\nshow that AP with Agglomerative Hierarchical Clustering significantly\noutperforms K-means. This research contributes to Natural Language Processing\n(NLP) by proposing a scalable and efficient unsupervised learning framework for\nsentiment analysis, highlighting the significant societal impact of advanced AI\ntechniques in analyzing public sentiment without the need for extensive labeled\ndata.", "published": "2024-10-12 19:20:33", "link": "http://arxiv.org/abs/2410.12862v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Yesterday's News: Benchmarking Multi-Dimensional Out-of-Distribution\n  Generalisation of Misinformation Detection Models", "abstract": "This paper introduces misinfo-general, a benchmark dataset for evaluating\nmisinformation models' ability to perform out-of-distribution generalisation.\nMisinformation changes rapidly, much quicker than moderators can annotate at\nscale, resulting in a shift between the training and inference data\ndistributions. As a result, misinformation models need to be able to perform\nout-of-distribution generalisation, an understudied problem in existing\ndatasets. We identify 6 axes of generalisation-time, event, topic, publisher,\npolitical bias, misinformation type-and design evaluation procedures for each.\nWe also analyse some baseline models, highlighting how these fail important\ndesiderata.", "published": "2024-10-12 09:46:36", "link": "http://arxiv.org/abs/2410.18122v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Impeding LLM-assisted Cheating in Introductory Programming Assignments\n  via Adversarial Perturbation", "abstract": "While Large language model (LLM)-based programming assistants such as CoPilot\nand ChatGPT can help improve the productivity of professional software\ndevelopers, they can also facilitate cheating in introductory computer\nprogramming courses. Assuming instructors have limited control over the\nindustrial-strength models, this paper investigates the baseline performance of\n5 widely used LLMs on a collection of introductory programming problems,\nexamines adversarial perturbations to degrade their performance, and describes\nthe results of a user study aimed at understanding the efficacy of such\nperturbations in hindering actual code generation for introductory programming\nassignments. The user study suggests that i) perturbations combinedly reduced\nthe average correctness score by 77%, ii) the drop in correctness caused by\nthese perturbations was affected based on their detectability.", "published": "2024-10-12 01:01:00", "link": "http://arxiv.org/abs/2410.09318v2", "categories": ["cs.CL", "cs.CY", "cs.SE"], "primary_category": "cs.CL"}
{"title": "DARE the Extreme: Revisiting Delta-Parameter Pruning For Fine-Tuned\n  Models", "abstract": "Storing open-source fine-tuned models separately introduces redundancy and\nincreases response times in applications utilizing multiple models.\nDelta-parameter pruning (DPP), particularly the random drop and rescale (DARE)\nmethod proposed by Yu et al., addresses this by pruning the majority of delta\nparameters--the differences between fine-tuned and pre-trained model\nweights--while typically maintaining minimal performance loss. However, DARE\nfails when either the pruning rate or the magnitude of the delta parameters is\nlarge. We highlight two key reasons for this failure: (1) an excessively large\nrescaling factor as pruning rates increase, and (2) high mean and variance in\nthe delta parameters. To push DARE's limits, we introduce DAREx (DARE the\neXtreme), which features two algorithmic improvements: (1) DAREx-q, a rescaling\nfactor modification that significantly boosts performance at high pruning rates\n(e.g., >30 % on COLA and SST2 for encoder models, with even greater gains in\ndecoder models), and (2) DAREx-L2, which combines DARE with AdamR, an\nin-training method that applies appropriate delta regularization before DPP. We\nalso demonstrate that DAREx-q can be seamlessly combined with vanilla\nparameter-efficient fine-tuning techniques like LoRA and can facilitate\nstructural DPP. Additionally, we revisit the application of importance-based\npruning techniques within DPP, demonstrating that they outperform random-based\nmethods when delta parameters are large. Through this comprehensive study, we\ndevelop a pipeline for selecting the most appropriate DPP method under various\npractical scenarios.", "published": "2024-10-12 03:21:58", "link": "http://arxiv.org/abs/2410.09344v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Inference and Verbalization Functions During In-Context Learning", "abstract": "Large language models (LMs) are capable of in-context learning from a few\ndemonstrations (example-label pairs) to solve new tasks during inference.\nDespite the intuitive importance of high-quality demonstrations, previous work\nhas observed that, in some settings, ICL performance is minimally affected by\nirrelevant labels (Min et al., 2022). We hypothesize that LMs perform ICL with\nirrelevant labels via two sequential processes: an inference function that\nsolves the task, followed by a verbalization function that maps the inferred\nanswer to the label space. Importantly, we hypothesize that the inference\nfunction is invariant to remappings of the label space (e.g., \"true\"/\"false\" to\n\"cat\"/\"dog\"), enabling LMs to share the same inference function across settings\nwith different label words. We empirically validate this hypothesis with\ncontrolled layer-wise interchange intervention experiments. Our findings\nconfirm the hypotheses on multiple datasets and tasks (natural language\ninference, sentiment analysis, and topic classification) and further suggest\nthat the two functions can be localized in specific layers across various\nopen-sourced models, including GEMMA-7B, MISTRAL-7B-V0.3, GEMMA-2-27B, and\nLLAMA-3.1-70B.", "published": "2024-10-12 03:31:37", "link": "http://arxiv.org/abs/2410.09349v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Fine-grained Attention I/O Complexity: Comprehensive Analysis for\n  Backward Passes", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nprocessing long-context information. However, the quadratic complexity of\nattention computation with respect to sequence length poses significant\ncomputational challenges, and I/O aware algorithms have been proposed. This\npaper presents a comprehensive analysis of the I/O complexity for attention\nmechanisms, focusing on backward passes by categorizing into small and large\ncache scenarios. Using the red-blue pebble game framework, we establish tight\nbounds on I/O complexity across all cache sizes. We confirm that the de facto\nstandard I/O aware algorithm FlashAttention is optimal for both forward and\nbackward passes for the large cache size scenario. For small cache sizes, we\nprovide an algorithm that improves over existing methods and achieves the tight\nbounds. Additionally, we extend our analysis to sparse attention, a mainstream\nspeeding-up approach, deriving fine-grained lower bounds for both forward and\nbackward passes and both small and large caches. Our findings complete the\ntheoretical foundation for I/O complexity in attention mechanisms, offering\ninsights for designing efficient algorithms of LLM training and inference.", "published": "2024-10-12 07:01:30", "link": "http://arxiv.org/abs/2410.09397v1", "categories": ["cs.LG", "cs.AI", "cs.CC", "cs.CL"], "primary_category": "cs.LG"}
{"title": "CAMPHOR: Collaborative Agents for Multi-input Planning and High-Order\n  Reasoning On Device", "abstract": "While server-side Large Language Models (LLMs) demonstrate proficiency in\nfunction calling and complex reasoning, deploying Small Language Models (SLMs)\ndirectly on devices brings opportunities to improve latency and privacy but\nalso introduces unique challenges for accuracy and memory. We introduce\nCAMPHOR, an innovative on-device SLM multi-agent framework designed to handle\nmultiple user inputs and reason over personal context locally, ensuring privacy\nis maintained. CAMPHOR employs a hierarchical architecture where a high-order\nreasoning agent decomposes complex tasks and coordinates expert agents\nresponsible for personal context retrieval, tool interaction, and dynamic plan\ngeneration. By implementing parameter sharing across agents and leveraging\nprompt compression, we significantly reduce model size, latency, and memory\nusage. To validate our approach, we present a novel dataset capturing\nmulti-agent task trajectories centered on personalized mobile assistant\nuse-cases. Our experiments reveal that fine-tuned SLM agents not only surpass\nclosed-source LLMs in task completion F1 by~35\\% but also eliminate the need\nfor server-device communication, all while enhancing privacy.", "published": "2024-10-12 07:28:10", "link": "http://arxiv.org/abs/2410.09407v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FedEx-LoRA: Exact Aggregation for Federated and Efficient Fine-Tuning of\n  Foundation Models", "abstract": "Low-Rank Adaptation (LoRA) is a popular technique for efficient fine-tuning\nof foundation models. However, applying LoRA in federated learning\nenvironments, where data is distributed across multiple clients, presents\nunique challenges. Existing methods rely on traditional federated averaging of\nLoRA adapters, resulting in inexact updates. To address this, we propose\nFederated Exact LoRA, or FedEx-LoRA, which adds a residual error term to the\npretrained frozen weight matrix. Our approach achieves exact updates with\nminimal computational and communication overhead, preserving LoRA's efficiency.\nWe evaluate the method on various models across arithmetic reasoning,\ncommonsense reasoning, natural language understanding and natural language\ngeneration tasks, showing consistent performance gains over state-of-the-art\nmethods across multiple settings. Through extensive analysis, we quantify that\nthe deviations in updates from the ideal solution are significant, highlighting\nthe need for exact aggregation. Our method's simplicity, efficiency, and broad\napplicability position it as a promising solution for accurate and effective\nfederated fine-tuning of foundation models. Our code is publicly available at\nhttps://github.com/RaghavSinghal10/fedex-lora.", "published": "2024-10-12 08:22:44", "link": "http://arxiv.org/abs/2410.09432v3", "categories": ["cs.DC", "cs.CL", "cs.CV"], "primary_category": "cs.DC"}
{"title": "MTL-LoRA: Low-Rank Adaptation for Multi-Task Learning", "abstract": "Parameter-efficient fine-tuning (PEFT) has been widely employed for domain\nadaptation, with LoRA being one of the most prominent methods due to its\nsimplicity and effectiveness. However, in multi-task learning (MTL) scenarios,\nLoRA tends to obscure the distinction between tasks by projecting sparse\nhigh-dimensional features from different tasks into the same dense\nlow-dimensional intrinsic space. This leads to task interference and suboptimal\nperformance for LoRA and its variants. To tackle this challenge, we propose\nMTL-LoRA, which retains the advantages of low-rank adaptation while\nsignificantly enhancing MTL capabilities. MTL-LoRA augments LoRA by\nincorporating additional task-adaptive parameters that differentiate\ntask-specific information and capture shared knowledge across various tasks\nwithin low-dimensional spaces. This approach enables pre-trained models to\njointly adapt to different target domains with a limited number of trainable\nparameters. Comprehensive experimental results, including evaluations on public\nacademic benchmarks for natural language understanding, commonsense reasoning,\nand image-text understanding, as well as real-world industrial text Ads\nrelevance datasets, demonstrate that MTL-LoRA outperforms LoRA and its various\nvariants with comparable or even fewer learnable parameters in MTL setting.", "published": "2024-10-12 08:32:26", "link": "http://arxiv.org/abs/2410.09437v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "VERITAS-NLI : Validation and Extraction of Reliable Information Through\n  Automated Scraping and Natural Language Inference", "abstract": "In today's day and age where information is rapidly spread through online\nplatforms, the rise of fake news poses an alarming threat to the integrity of\npublic discourse, societal trust, and reputed news sources. Classical machine\nlearning and Transformer-based models have been extensively studied for the\ntask of fake news detection, however they are hampered by their reliance on\ntraining data and are unable to generalize on unseen headlines. To address\nthese challenges, we propose our novel solution, leveraging web-scraping\ntechniques and Natural Language Inference (NLI) models to retrieve external\nknowledge necessary for verifying the accuracy of a headline. Our system is\nevaluated on a diverse self-curated evaluation dataset spanning over multiple\nnews channels and broad domains. Our best performing pipeline achieves an\naccuracy of 84.3% surpassing the best classical Machine Learning model by 33.3%\nand Bidirectional Encoder Representations from Transformers (BERT) by 31.0% .\nThis highlights the efficacy of combining dynamic web-scraping with Natural\nLanguage Inference to find support for a claimed headline in the corresponding\nexternally retrieved knowledge for the task of fake news detection.", "published": "2024-10-12 09:25:12", "link": "http://arxiv.org/abs/2410.09455v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.1; I.2.7"], "primary_category": "cs.CL"}
{"title": "Emphasis Rendering for Conversational Text-to-Speech with Multi-modal\n  Multi-scale Context Modeling", "abstract": "Conversational Text-to-Speech (CTTS) aims to accurately express an utterance\nwith the appropriate style within a conversational setting, which attracts more\nattention nowadays. While recognizing the significance of the CTTS task, prior\nstudies have not thoroughly investigated speech emphasis expression, which is\nessential for conveying the underlying intention and attitude in human-machine\ninteraction scenarios, due to the scarcity of conversational emphasis datasets\nand the difficulty in context understanding. In this paper, we propose a novel\nEmphasis Rendering scheme for the CTTS model, termed ER-CTTS, that includes two\nmain components: 1) we simultaneously take into account textual and acoustic\ncontexts, with both global and local semantic modeling to understand the\nconversation context comprehensively; 2) we deeply integrate multi-modal and\nmulti-scale context to learn the influence of context on the emphasis\nexpression of the current utterance. Finally, the inferred emphasis feature is\nfed into the neural speech synthesizer to generate conversational speech. To\naddress data scarcity, we create emphasis intensity annotations on the existing\nconversational dataset (DailyTalk). Both objective and subjective evaluations\nsuggest that our model outperforms the baseline models in emphasis rendering\nwithin a conversational setting. The code and audio samples are available at\nhttps://github.com/CodeStoreTTS/ER-CTTS.", "published": "2024-10-12 13:02:31", "link": "http://arxiv.org/abs/2410.09524v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Reconstructive Visual Instruction Tuning", "abstract": "This paper introduces reconstructive visual instruction tuning (ROSS), a\nfamily of Large Multimodal Models (LMMs) that exploit vision-centric\nsupervision signals. In contrast to conventional visual instruction tuning\napproaches that exclusively supervise text outputs, ROSS prompts LMMs to\nsupervise visual outputs via reconstructing input images. By doing so, it\ncapitalizes on the inherent richness and detail present within input images\nthemselves, which are often lost in pure text supervision. However, producing\nmeaningful feedback from natural images is challenging due to the heavy spatial\nredundancy of visual signals. To address this issue, ROSS employs a denoising\nobjective to reconstruct latent representations of input images, avoiding\ndirectly regressing exact raw RGB values. This intrinsic activation design\ninherently encourages LMMs to maintain image detail, thereby enhancing their\nfine-grained comprehension capabilities and reducing hallucinations.\nEmpirically, ROSS consistently brings significant improvements across different\nvisual encoders and language models. In comparison with extrinsic assistance\nstate-of-the-art alternatives that aggregate multiple visual experts, ROSS\ndelivers competitive performance with a single SigLIP visual encoder,\ndemonstrating the efficacy of our vision-centric supervision tailored for\nvisual outputs.", "published": "2024-10-12 15:54:29", "link": "http://arxiv.org/abs/2410.09575v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Toward General Instruction-Following Alignment for Retrieval-Augmented\n  Generation", "abstract": "Following natural instructions is crucial for the effective application of\nRetrieval-Augmented Generation (RAG) systems. Despite recent advancements in\nLarge Language Models (LLMs), research on assessing and improving\ninstruction-following (IF) alignment within the RAG domain remains limited. To\naddress this issue, we propose VIF-RAG, the first automated, scalable, and\nverifiable synthetic pipeline for instruction-following alignment in RAG\nsystems. We start by manually crafting a minimal set of atomic instructions\n(<100) and developing combination rules to synthesize and verify complex\ninstructions for a seed set. We then use supervised models for instruction\nrewriting while simultaneously generating code to automate the verification of\ninstruction quality via a Python executor. Finally, we integrate these\ninstructions with extensive RAG and general data samples, scaling up to a\nhigh-quality VIF-RAG-QA dataset (>100k) through automated processes. To further\nbridge the gap in instruction-following auto-evaluation for RAG systems, we\nintroduce FollowRAG Benchmark, which includes approximately 3K test samples,\ncovering 22 categories of general instruction constraints and four\nknowledge-intensive QA datasets. Due to its robust pipeline design, FollowRAG\ncan seamlessly integrate with different RAG benchmarks. Using FollowRAG and\neight widely-used IF and foundational abilities benchmarks for LLMs, we\ndemonstrate that VIF-RAG markedly enhances LLM performance across a broad range\nof general instruction constraints while effectively leveraging its\ncapabilities in RAG scenarios. Further analysis offers practical insights for\nachieving IF alignment in RAG systems. Our code and datasets are released at\nhttps://FollowRAG.github.io.", "published": "2024-10-12 16:30:51", "link": "http://arxiv.org/abs/2410.09584v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Synthetic Knowledge Ingestion: Towards Knowledge Refinement and\n  Injection for Enhancing Large Language Models", "abstract": "Large language models (LLMs) are proficient in capturing factual knowledge\nacross various domains. However, refining their capabilities on previously seen\nknowledge or integrating new knowledge from external sources remains a\nsignificant challenge. In this work, we propose a novel synthetic knowledge\ningestion method called Ski, which leverages fine-grained synthesis,\ninterleaved generation, and assemble augmentation strategies to construct\nhigh-quality data representations from raw knowledge sources. We then integrate\nSki and its variations with three knowledge injection techniques: Retrieval\nAugmented Generation (RAG), Supervised Fine-tuning (SFT), and Continual\nPre-training (CPT) to inject and refine knowledge in language models. Extensive\nempirical experiments are conducted on various question-answering tasks\nspanning finance, biomedicine, and open-generation domains to demonstrate that\nSki significantly outperforms baseline methods by facilitating effective\nknowledge injection. We believe that our work is an important step towards\nenhancing the factual accuracy of LLM outputs by refining knowledge\nrepresentation and injection capabilities.", "published": "2024-10-12 19:38:09", "link": "http://arxiv.org/abs/2410.09629v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning the Bitter Lesson: Empirical Evidence from 20 Years of CVPR\n  Proceedings", "abstract": "This study examines the alignment of \\emph{Conference on Computer Vision and\nPattern Recognition} (CVPR) research with the principles of the \"bitter lesson\"\nproposed by Rich Sutton. We analyze two decades of CVPR abstracts and titles\nusing large language models (LLMs) to assess the field's embracement of these\nprinciples. Our methodology leverages state-of-the-art natural language\nprocessing techniques to systematically evaluate the evolution of research\napproaches in computer vision. The results reveal significant trends in the\nadoption of general-purpose learning algorithms and the utilization of\nincreased computational resources. We discuss the implications of these\nfindings for the future direction of computer vision research and its potential\nimpact on broader artificial intelligence development. This work contributes to\nthe ongoing dialogue about the most effective strategies for advancing machine\nlearning and computer vision, offering insights that may guide future research\npriorities and methodologies in the field.", "published": "2024-10-12 21:06:13", "link": "http://arxiv.org/abs/2410.09649v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Many Heads Are Better Than One: Improved Scientific Idea Generation by A\n  LLM-Based Multi-Agent System", "abstract": "The rapid advancement of scientific progress requires innovative tools that\ncan accelerate knowledge discovery. Although recent AI methods, particularly\nlarge language models (LLMs), have shown promise in tasks such as hypothesis\ngeneration and experimental design, they fall short of replicating the\ncollaborative nature of real-world scientific practices, where diverse experts\nwork together in teams to tackle complex problems. To address the limitations,\nwe propose an LLM-based multi-agent system, i.e., Virtual Scientists (VirSci),\ndesigned to mimic the teamwork inherent in scientific research. VirSci\norganizes a team of agents to collaboratively generate, evaluate, and refine\nresearch ideas. Through comprehensive experiments, we demonstrate that this\nmulti-agent approach outperforms the state-of-the-art method in producing novel\nscientific ideas. We further investigate the collaboration mechanisms that\ncontribute to its tendency to produce ideas with higher novelty, offering\nvaluable insights to guide future research and illuminating pathways toward\nbuilding a robust system for autonomous scientific discovery. The code is\navailable at https://github.com/open-sciencelab/Virtual-Scientists.", "published": "2024-10-12 07:16:22", "link": "http://arxiv.org/abs/2410.09403v2", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Survival of the Safest: Towards Secure Prompt Optimization through\n  Interleaved Multi-Objective Evolution", "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities;\nhowever, the optimization of their prompts has historically prioritized\nperformance metrics at the expense of crucial safety and security\nconsiderations. To overcome this shortcoming, we introduce \"Survival of the\nSafest\" (SoS), an innovative multi-objective prompt optimization framework that\nenhances both performance and security in LLMs simultaneously. SoS utilizes an\ninterleaved multi-objective evolution strategy, integrating semantic, feedback,\nand crossover mutations to effectively traverse the prompt landscape. Differing\nfrom the computationally demanding Pareto front methods, SoS provides a\nscalable solution that expedites optimization in complex, high-dimensional\ndiscrete search spaces while keeping computational demands low. Our approach\naccommodates flexible weighting of objectives and generates a pool of optimized\ncandidates, empowering users to select prompts that optimally meet their\nspecific performance and security needs. Experimental evaluations across\ndiverse benchmark datasets affirm SoS's efficacy in delivering high performance\nand notably enhancing safety and security compared to single-objective methods.\nThis advancement marks a significant stride towards the deployment of LLM\nsystems that are both high-performing and secure across varied industrial\napplications", "published": "2024-10-12 21:16:29", "link": "http://arxiv.org/abs/2410.09652v1", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CR"}
{"title": "SLAM-AAC: Enhancing Audio Captioning with Paraphrasing Augmentation and\n  CLAP-Refine through LLMs", "abstract": "Automated Audio Captioning (AAC) aims to generate natural textual\ndescriptions for input audio signals. Recent progress in audio pre-trained\nmodels and large language models (LLMs) has significantly enhanced audio\nunderstanding and textual reasoning capabilities, making improvements in AAC\npossible. In this paper, we propose SLAM-AAC to further enhance AAC with\nparaphrasing augmentation and CLAP-Refine through LLMs. Our approach uses the\nself-supervised EAT model to extract fine-grained audio representations, which\nare then aligned with textual embeddings via lightweight linear layers. The\ncaption generation LLM is efficiently fine-tuned using the LoRA adapter.\nDrawing inspiration from the back-translation method in machine translation, we\nimplement paraphrasing augmentation to expand the Clotho dataset during\npre-training. This strategy helps alleviate the limitation of scarce audio-text\npairs and generates more diverse captions from a small set of audio clips.\nDuring inference, we introduce the plug-and-play CLAP-Refine strategy to fully\nexploit multiple decoding outputs, akin to the n-best rescoring strategy in\nspeech recognition. Using the CLAP model for audio-text similarity calculation,\nwe could select the textual descriptions generated by multiple searching beams\nthat best match the input audio. Experimental results show that SLAM-AAC\nachieves state-of-the-art performance on Clotho V2 and AudioCaps, surpassing\nprevious mainstream models.", "published": "2024-10-12 11:43:54", "link": "http://arxiv.org/abs/2410.09503v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Objective Measurements of Voice Quality", "abstract": "The quality of human voice plays an important role across various fields like\nmusic, speech therapy, and communication, yet it lacks a universally accepted,\nobjective definition. Instead, voice quality is referred to using subjective\ndescriptors like \"rough\", \"breathy\" etc. Despite this subjectivity, extensive\nresearch across disciplines has linked these voice qualities to specific\ninformation about the speaker, such as health, physiological traits, and\nothers. Current machine learning approaches for voice profiling rely on\ndata-driven analysis without fully incorporating these established\ncorrelations, due to their qualitative nature. This paper aims to objectively\nquantify voice quality by synthesizing formulaic representations from past\nfindings that correlate voice qualities to signal-processing metrics. We\nintroduce formulae for 24 voice sub-qualities based on 25 signal properties,\ngrounded in scientific literature. These formulae are tested against datasets\nwith subjectively labeled voice qualities, demonstrating their validity.", "published": "2024-10-12 16:07:03", "link": "http://arxiv.org/abs/2410.09578v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Towards the Synthesis of Non-speech Vocalizations", "abstract": "In this report, we focus on the unconditional generation of infant cry sounds\nusing the DiffWave framework, which has shown great promise in generating\nhigh-quality audio from noise. We use two distinct datasets of infant cries:\nthe Baby Chillanto and the deBarbaro cry dataset. These datasets are used to\ntrain the DiffWave model to generate new cry sounds that maintain high fidelity\nand diversity. The focus here is on DiffWave's capability to handle the\nunconditional generation task.", "published": "2024-10-12 04:00:56", "link": "http://arxiv.org/abs/2410.09360v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ExpGest: Expressive Speaker Generation Using Diffusion Model and Hybrid\n  Audio-Text Guidance", "abstract": "Existing gesture generation methods primarily focus on upper body gestures\nbased on audio features, neglecting speech content, emotion, and locomotion.\nThese limitations result in stiff, mechanical gestures that fail to convey the\ntrue meaning of audio content. We introduce ExpGest, a novel framework\nleveraging synchronized text and audio information to generate expressive\nfull-body gestures. Unlike AdaIN or one-hot encoding methods, we design a noise\nemotion classifier for optimizing adversarial direction noise, avoiding melody\ndistortion and guiding results towards specified emotions. Moreover, aligning\nsemantic and gestures in the latent space provides better generalization\ncapabilities. ExpGest, a diffusion model-based gesture generation framework, is\nthe first attempt to offer mixed generation modes, including audio-driven\ngestures and text-shaped motion. Experiments show that our framework\neffectively learns from combined text-driven motion and audio-induced gesture\ndatasets, and preliminary results demonstrate that ExpGest achieves more\nexpressive, natural, and controllable global motion in speakers compared to\nstate-of-the-art models.", "published": "2024-10-12 07:01:17", "link": "http://arxiv.org/abs/2410.09396v1", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "DRCap: Decoding CLAP Latents with Retrieval-Augmented Generation for\n  Zero-shot Audio Captioning", "abstract": "While automated audio captioning (AAC) has made notable progress, traditional\nfully supervised AAC models still face two critical challenges: the need for\nexpensive audio-text pair data for training and performance degradation when\ntransferring across domains. To overcome these limitations, we present DRCap, a\ndata-efficient and flexible zero-shot audio captioning system that requires\ntext-only data for training and can quickly adapt to new domains without\nadditional fine-tuning. DRCap integrates a contrastive language-audio\npre-training (CLAP) model and a large-language model (LLM) as its backbone.\nDuring training, the model predicts the ground-truth caption with a fixed text\nencoder from CLAP, whereas, during inference, the text encoder is replaced with\nthe audio encoder to generate captions for audio clips in a zero-shot manner.\nTo mitigate the modality gap of the CLAP model, we use both the projection\nstrategy from the encoder side and the retrieval-augmented generation strategy\nfrom the decoder side. Specifically, audio embeddings are first projected onto\na text embedding support to absorb extensive semantic information within the\njoint multi-modal space of CLAP. At the same time, similar captions retrieved\nfrom a datastore are fed as prompts to instruct the LLM, incorporating external\nknowledge to take full advantage of its strong generative capability.\nConditioned on both the projected CLAP embedding and the retrieved similar\ncaptions, the model is able to produce a more accurate and semantically rich\ntextual description. By tailoring the text embedding support and the caption\ndatastore to the target domain, DRCap acquires a robust ability to adapt to new\ndomains in a training-free manner. Experimental results demonstrate that DRCap\noutperforms all other zero-shot models in in-domain scenarios and achieves\nstate-of-the-art performance in cross-domain scenarios.", "published": "2024-10-12 10:21:00", "link": "http://arxiv.org/abs/2410.09472v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Can We Estimate Purchase Intention Based on Zero-shot Speech Emotion\n  Recognition?", "abstract": "This paper proposes a zero-shot speech emotion recognition (SER) method that\nestimates emotions not previously defined in the SER model training.\nConventional methods are limited to recognizing emotions defined by a single\nword. Moreover, we have the motivation to recognize unknown bipolar emotions\nsuch as ``I want to buy - I do not want to buy.'' In order to allow the model\nto define classes using sentences freely and to estimate unknown bipolar\nemotions, our proposed method expands upon the contrastive language-audio\npre-training (CLAP) framework by introducing multi-class and multi-task\nsettings. We also focus on purchase intention as a bipolar emotion and\ninvestigate the model's performance to zero-shot estimate it. This study is the\nfirst attempt to estimate purchase intention from speech directly. Experiments\nconfirm that the results of zero-shot estimation by the proposed method are at\nthe same level as those of the model trained by supervised learning.", "published": "2024-10-12 20:25:16", "link": "http://arxiv.org/abs/2410.09636v1", "categories": ["eess.AS", "cs.AI", "cs.LG"], "primary_category": "eess.AS"}
