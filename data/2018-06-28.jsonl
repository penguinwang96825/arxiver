{"title": "DeepTag: inferring all-cause diagnoses from clinical notes in\n  under-resourced medical domain", "abstract": "Large scale veterinary clinical records can become a powerful resource for\npatient care and research. However, clinicians lack the time and resource to\nannotate patient records with standard medical diagnostic codes and most\nveterinary visits are captured in free text notes. The lack of standard coding\nmakes it challenging to use the clinical data to improve patient care. It is\nalso a major impediment to cross-species translational research, which relies\non the ability to accurately identify patient cohorts with specific diagnostic\ncriteria in humans and animals. In order to reduce the coding burden for\nveterinary clinical practice and aid translational research, we have developed\na deep learning algorithm, DeepTag, which automatically infers diagnostic codes\nfrom veterinary free text notes. DeepTag is trained on a newly curated dataset\nof 112,558 veterinary notes manually annotated by experts. DeepTag extends\nmulti-task LSTM with an improved hierarchical objective that captures the\nsemantic structures between diseases. To foster human-machine collaboration,\nDeepTag also learns to abstain in examples when it is uncertain and defers them\nto human experts, resulting in improved performance. DeepTag accurately infers\ndisease codes from free text even in challenging cross-hospital settings where\nthe text comes from different clinical settings than the ones used for\ntraining. It enables automated disease annotation across a broad range of\nclinical diagnoses with minimal pre-processing. The technical framework in this\nwork can be applied in other medical domains that currently lack medical coding\nresources.", "published": "2018-06-28 00:45:04", "link": "http://arxiv.org/abs/1806.10722v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rich Character-Level Information for Korean Morphological Analysis and\n  Part-of-Speech Tagging", "abstract": "Due to the fact that Korean is a highly agglutinative, character-rich\nlanguage, previous work on Korean morphological analysis typically employs the\nuse of sub-character features known as graphemes or otherwise utilizes\ncomprehensive prior linguistic knowledge (i.e., a dictionary of known\nmorphological transformation forms, or actions). These models have been created\nwith the assumption that character-level, dictionary-less morphological\nanalysis was intractable due to the number of actions required. We present, in\nthis study, a multi-stage action-based model that can perform morphological\ntransformation and part-of-speech tagging using arbitrary units of input and\napply it to the case of character-level Korean morphological analysis. Among\nmodels that do not employ prior linguistic knowledge, we achieve\nstate-of-the-art word and sentence-level tagging accuracy with the Sejong\nKorean corpus using our proposed data-driven Bi-LSTM model.", "published": "2018-06-28 05:09:38", "link": "http://arxiv.org/abs/1806.10771v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Predicting CEFRL levels in learner English on the basis of metrics and\n  full texts", "abstract": "This paper analyses the contribution of language metrics and, potentially, of\nlinguistic structures, to classify French learners of English according to\nlevels of the Common European Framework of Reference for Languages (CEFRL). The\npurpose is to build a model for the prediction of learner levels as a function\nof language complexity features. We used the EFCAMDAT corpus, a database of one\nmillion written assignments by learners. After applying language complexity\nmetrics on the texts, we built a representation matching the language metrics\nof the texts to their assigned CEFRL levels. Lexical and syntactic metrics were\ncomputed with LCA, LSA, and koRpus. Several supervised learning models were\nbuilt by using Gradient Boosted Trees and Keras Neural Network methods and by\ncontrasting pairs of CEFRL levels. Results show that it is possible to\nimplement pairwise distinctions, especially for levels ranging from A1 to B1\n(A1=>A2: 0.916 AUC and A2=>B1: 0.904 AUC). Model explanation reveals\nsignificant linguistic features for the predictiveness in the corpus. Word\ntokens and word types appear to play a significant role in determining levels.\nThis shows that levels are highly dependent on specific semantic profiles.", "published": "2018-06-28 17:42:54", "link": "http://arxiv.org/abs/1806.11099v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-Discourse and Multilingual Exploration of Textual Corpora with the\n  DualNeighbors Algorithm", "abstract": "Word choice is dependent on the cultural context of writers and their\nsubjects. Different words are used to describe similar actions, objects, and\nfeatures based on factors such as class, race, gender, geography and political\naffinity. Exploratory techniques based on locating and counting words may,\ntherefore, lead to conclusions that reinforce culturally inflected boundaries.\nWe offer a new method, the DualNeighbors algorithm, for linking thematically\nsimilar documents both within and across discursive and linguistic barriers to\nreveal cross-cultural connections. Qualitative and quantitative evaluations of\nthis technique are shown as applied to two cultural datasets of interest to\nresearchers across the humanities and social sciences. An open-source\nimplementation of the DualNeighbors algorithm is provided to assist in its\napplication.", "published": "2018-06-28 20:55:18", "link": "http://arxiv.org/abs/1806.11183v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GenerationMania: Learning to Semantically Choreograph", "abstract": "Beatmania is a rhythm action game where players must reproduce some of the\nsounds of a song by pressing specific controller buttons at the correct time.\nIn this paper we investigate the use of deep neural networks to automatically\ncreate game stages - called charts - for arbitrary pieces of music. Our\ntechnique uses a multi-layer feed-forward network trained on sound sequence\nsummary statistics to predict which sounds in the music are to be played by the\nplayer and which will play automatically. We use another neural network along\nwith rules to determine which controls should be mapped to which sounds. We\nevaluated our system on the ability to reconstruct charts in a held-out test\nset, achieving an $F_1$-score that significantly beats LSTM baselines.", "published": "2018-06-28 20:20:04", "link": "http://arxiv.org/abs/1806.11170v5", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
