{"title": "To What Extent are Name Variants Used as Named Entities in Turkish\n  Tweets?", "abstract": "Social media texts differ from regular texts in various aspects. One of the\nmain differences is the common use of informal name variants instead of\nwell-formed named entities in social media compared to regular texts. These\nname variants may come in the form of abbreviations, nicknames, contractions,\nand hypocoristic uses, in addition to names distorted due to capitalization and\nwriting errors. In this paper, we present an analysis of the named entities in\na publicly-available tweet dataset in Turkish with respect to their being name\nvariants belonging to different categories. We also provide finer-grained\nannotations of the named entities as well-formed names and different categories\nof name variants, where these annotations are made publicly-available. The\nanalysis presented and the accompanying annotations will contribute to related\nresearch on the treatment of named entities in social media.", "published": "2019-12-17 11:43:17", "link": "http://arxiv.org/abs/1912.07940v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Open Set Authorship Attribution toward Demystifying Victorian\n  Periodicals", "abstract": "Existing research in computational authorship attribution (AA) has primarily\nfocused on attribution tasks with a limited number of authors in a closed-set\nconfiguration. This restricted set-up is far from being realistic in dealing\nwith highly entangled real-world AA tasks that involve a large number of\ncandidate authors for attribution during test time. In this paper, we study AA\nin historical texts using anew data set compiled from the Victorian literature.\nWe investigate the predictive capacity of most common English words in\ndistinguishing writings of most prominent Victorian novelists. We challenged\nthe closed-set classification assumption and discussed the limitations of\nstandard machine learning techniques in dealing with the open set AA task. Our\nexperiments suggest that a linear classifier can achieve near perfect\nattribution accuracy under closed set assumption yet, the need for more robust\napproaches becomes evident once a large candidate pool has to be considered in\nthe open-set classification setting.", "published": "2019-12-17 20:15:34", "link": "http://arxiv.org/abs/1912.08259v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chinese Named Entity Recognition Augmented with Lexicon Memory", "abstract": "Inspired by a concept of content-addressable retrieval from cognitive\nscience, we propose a novel fragment-based model augmented with a lexicon-based\nmemory for Chinese NER, in which both the character-level and word-level\nfeatures are combined to generate better feature representations for possible\nname candidates. It is observed that locating the boundary information of\nentity names is useful in order to classify them into pre-defined categories.\nPosition-dependent features, including prefix and suffix are introduced for NER\nin the form of distributed representation. The lexicon-based memory is used to\nhelp generate such position-dependent features and deal with the problem of\nout-of-vocabulary words. Experimental results showed that the proposed model,\ncalled LEMON, achieved state-of-the-art on four datasets.", "published": "2019-12-17 21:38:22", "link": "http://arxiv.org/abs/1912.08282v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The performance evaluation of Multi-representation in the Deep Learning\n  models for Relation Extraction Task", "abstract": "Single implementing, concatenating, adding or replacing of the\nrepresentations has yielded significant improvements on many NLP tasks. Mainly\nin Relation Extraction where static, contextualized and others representations\nthat are capable of explaining word meanings through the linguistic features\nthat these incorporates. In this work addresses the question of how is improved\nthe relation extraction using different types of representations generated by\npretrained language representation models. We benchmarked our approach using\npopular word representation models, replacing and concatenating static,\ncontextualized and others representations of hand-extracted features. The\nexperiments show that representation is a crucial element to choose when DL\napproach is applied. Word embeddings from Flair and BERT can be well\ninterpreted by a deep learning model for RE task, and replacing static word\nembeddings with contextualized word representations could lead to significant\nimprovements. While, the hand-created representations requires is\ntime-consuming and not is ensure a improve in combination with others\nrepresentations.", "published": "2019-12-17 21:58:51", "link": "http://arxiv.org/abs/1912.08290v1", "categories": ["cs.CL", "68T50, 68T35"], "primary_category": "cs.CL"}
{"title": "A Multi-task Learning Model for Chinese-oriented Aspect Polarity\n  Classification and Aspect Term Extraction", "abstract": "Aspect-based sentiment analysis (ABSA) task is a multi-grained task of\nnatural language processing and consists of two subtasks: aspect term\nextraction (ATE) and aspect polarity classification (APC). Most of the existing\nwork focuses on the subtask of aspect term polarity inferring and ignores the\nsignificance of aspect term extraction. Besides, the existing researches do not\npay attention to the research of the Chinese-oriented ABSA task. Based on the\nlocal context focus (LCF) mechanism, this paper firstly proposes a multi-task\nlearning model for Chinese-oriented aspect-based sentiment analysis, namely\nLCF-ATEPC. Compared with existing models, this model equips the capability of\nextracting aspect term and inferring aspect term polarity synchronously,\nmoreover, this model is effective to analyze both Chinese and English comments\nsimultaneously and the experiment on a multilingual mixed dataset proved its\navailability. By integrating the domain-adapted BERT model, the LCF-ATEPC model\nachieved the state-of-the-art performance of aspect term extraction and aspect\npolarity classification in four Chinese review datasets. Besides, the\nexperimental results on the most commonly used SemEval-2014 task4 Restaurant\nand Laptop datasets outperform the state-of-the-art performance on the ATE and\nAPC subtask.", "published": "2019-12-17 12:47:33", "link": "http://arxiv.org/abs/1912.07976v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Meshed-Memory Transformer for Image Captioning", "abstract": "Transformer-based architectures represent the state of the art in sequence\nmodeling tasks like machine translation and language understanding. Their\napplicability to multi-modal contexts like image captioning, however, is still\nlargely under-explored. With the aim of filling this gap, we present M$^2$ - a\nMeshed Transformer with Memory for Image Captioning. The architecture improves\nboth the image encoding and the language generation steps: it learns a\nmulti-level representation of the relationships between image regions\nintegrating learned a priori knowledge, and uses a mesh-like connectivity at\ndecoding stage to exploit low- and high-level features. Experimentally, we\ninvestigate the performance of the M$^2$ Transformer and different\nfully-attentive models in comparison with recurrent ones. When tested on COCO,\nour proposal achieves a new state of the art in single-model and ensemble\nconfigurations on the \"Karpathy\" test split and on the online test server. We\nalso assess its performances when describing objects unseen in the training\nset. Trained models and code for reproducing the experiments are publicly\navailable at: https://github.com/aimagelab/meshed-memory-transformer.", "published": "2019-12-17 19:03:23", "link": "http://arxiv.org/abs/1912.08226v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Analyzing Structures in the Semantic Vector Space: A Framework for\n  Decomposing Word Embeddings", "abstract": "Word embeddings are rich word representations, which in combination with deep\nneural networks, lead to large performance gains for many NLP tasks. However,\nword embeddings are represented by dense, real-valued vectors and they are\ntherefore not directly interpretable. Thus, computational operations based on\nthem are also not well understood. In this paper, we present an approach for\nanalyzing structures in the semantic vector space to get a better understanding\nof the underlying semantic encoding principles. We present a framework for\ndecomposing word embeddings into smaller meaningful units which we call\nsub-vectors. The framework opens up a wide range of possibilities analyzing\nphenomena in vector space semantics, as well as solving concrete NLP problems:\nWe introduce the category completion task and show that a sub-vector based\napproach is superior to supervised techniques; We present a sub-vector based\nmethod for solving the word analogy task, which substantially outperforms\ndifferent variants of the traditional vector-offset method.", "published": "2019-12-17 09:01:30", "link": "http://arxiv.org/abs/1912.10434v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Cross-Lingual Ability of Multilingual BERT: An Empirical Study", "abstract": "Recent work has exhibited the surprising cross-lingual abilities of\nmultilingual BERT (M-BERT) -- surprising since it is trained without any\ncross-lingual objective and with no aligned data. In this work, we provide a\ncomprehensive study of the contribution of different components in M-BERT to\nits cross-lingual ability. We study the impact of linguistic properties of the\nlanguages, the architecture of the model, and the learning objectives. The\nexperimental study is done in the context of three typologically different\nlanguages -- Spanish, Hindi, and Russian -- and using two conceptually\ndifferent NLP tasks, textual entailment and named entity recognition. Among our\nkey conclusions is the fact that the lexical overlap between languages plays a\nnegligible role in the cross-lingual success, while the depth of the network is\nan integral part of it. All our models and implementations can be found on our\nproject page: http://cogcomp.org/page/publication_view/900 .", "published": "2019-12-17 06:53:05", "link": "http://arxiv.org/abs/1912.07840v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Libri-Light: A Benchmark for ASR with Limited or No Supervision", "abstract": "We introduce a new collection of spoken English audio suitable for training\nspeech recognition systems under limited or no supervision. It is derived from\nopen-source audio books from the LibriVox project. It contains over 60K hours\nof audio, which is, to our knowledge, the largest freely-available corpus of\nspeech. The audio has been segmented using voice activity detection and is\ntagged with SNR, speaker ID and genre descriptions. Additionally, we provide\nbaseline systems and evaluation metrics working under three settings: (1) the\nzero resource/unsupervised setting (ABX), (2) the semi-supervised setting (PER,\nCER) and (3) the distant supervision setting (WER). Settings (2) and (3) use\nlimited textual resources (10 minutes to 10 hours) aligned with the speech.\nSetting (3) uses large amounts of unaligned text. They are evaluated on the\nstandard LibriSpeech dev and test sets for comparison with the supervised\nstate-of-the-art.", "published": "2019-12-17 08:47:30", "link": "http://arxiv.org/abs/1912.07875v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Knowledge-Enhanced Attentive Learning for Answer Selection in Community\n  Question Answering Systems", "abstract": "In the community question answering (CQA) system, the answer selection task\naims to identify the best answer for a specific question, and thus is playing a\nkey role in enhancing the service quality through recommending appropriate\nanswers for new questions. Recent advances in CQA answer selection focus on\nenhancing the performance by incorporating the community information,\nparticularly the expertise (previous answers) and authority (position in the\nsocial network) of an answerer. However, existing approaches for incorporating\nsuch information are limited in (a) only considering either the expertise or\nthe authority, but not both; (b) ignoring the domain knowledge to differentiate\ntopics of previous answers; and (c) simply using the authority information to\nadjust the similarity score, instead of fully utilizing it in the process of\nmeasuring the similarity between segments of the question and the answer. We\npropose the Knowledge-enhanced Attentive Answer Selection (KAAS) model, which\nenhances the performance through (a) considering both the expertise and the\nauthority of the answerer; (b) utilizing the human-labeled tags, the taxonomy\nof the tags, and the votes as the domain knowledge to infer the expertise of\nthe answer; (c) using matrix decomposition of the social network (formed by\nfollowing-relationship) to infer the authority of the answerer and\nincorporating such information in the process of evaluating the similarity\nbetween segments. Besides, for vertical community, we incorporate an external\nknowledge graph to capture more professional information for vertical CQA\nsystems. Then we adopt the attention mechanism to integrate the analysis of the\ntext of questions and answers and the aforementioned community information.\nExperiments with both vertical and general CQA sites demonstrate the superior\nperformance of the proposed KAAS model.", "published": "2019-12-17 10:33:17", "link": "http://arxiv.org/abs/1912.07915v1", "categories": ["cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.AI"}
{"title": "Analyzing Information Leakage of Updates to Natural Language Models", "abstract": "To continuously improve quality and reflect changes in data, machine learning\napplications have to regularly retrain and update their core models. We show\nthat a differential analysis of language model snapshots before and after an\nupdate can reveal a surprising amount of detailed information about changes in\nthe training data. We propose two new metrics---\\emph{differential score} and\n\\emph{differential rank}---for analyzing the leakage due to updates of natural\nlanguage models. We perform leakage analysis using these metrics across models\ntrained on several different datasets using different methods and\nconfigurations. We discuss the privacy implications of our findings, propose\nmitigation strategies and evaluate their effect.", "published": "2019-12-17 11:46:08", "link": "http://arxiv.org/abs/1912.07942v4", "categories": ["cs.LG", "cs.CL", "cs.CR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Pioneer dataset and automatic recognition of Urdu handwritten characters\n  using a deep autoencoder and convolutional neural network", "abstract": "Automatic recognition of Urdu handwritten digits and characters, is a\nchallenging task. It has applications in postal address reading, bank's cheque\nprocessing, and digitization and preservation of handwritten manuscripts from\nold ages. While there exists a significant work for automatic recognition of\nhandwritten English characters and other major languages of the world, the work\ndone for Urdu lan-guage is extremely insufficient. This paper has two goals.\nFirstly, we introduce a pioneer dataset for handwritten digits and characters\nof Urdu, containing samples from more than 900 individuals. Secondly, we report\nresults for automatic recog-nition of handwritten digits and characters as\nachieved by using deep auto-encoder network and convolutional neural network.\nMore specifically, we use a two-layer and a three-layer deep autoencoder\nnetwork and convolutional neural network and evaluate the two frameworks in\nterms of recognition accuracy. The proposed framework of deep autoencoder can\nsuccessfully recognize digits and characters with an accuracy of 97% for digits\nonly, 81% for characters only and 82% for both digits and characters\nsimultaneously. In comparison, the framework of convolutional neural network\nhas accuracy of 96.7% for digits only, 86.5% for characters only and 82.7% for\nboth digits and characters simultaneously. These frameworks can serve as\nbaselines for future research on Urdu handwritten text.", "published": "2019-12-17 11:49:13", "link": "http://arxiv.org/abs/1912.07943v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "In Nomine Function: Naming Functions in Stripped Binaries with Neural\n  Networks", "abstract": "In this paper we investigate the problem of automatically naming pieces of\nassembly code. Where by naming we mean assigning to an assembly function a\nstring of words that would likely be assigned by a human reverse engineer. We\nformally and precisely define the framework in which our investigation takes\nplace. That is we define the problem, we provide reasonable justifications for\nthe choices that we made for the design of training and the tests. We performed\nan analysis on a large real-world corpora constituted by nearly 9 millions of\nfunctions taken from more than 22k softwares. In such framework we test\nbaselines coming from the field of Natural Language Processing (e.g., Seq2Seq\nnetworks and Transformer). Interestingly, our evaluation shows promising\nresults beating the state-of-the-art and reaching good performance. We\ninvestigate the applicability of tine-tuning (i.e., taking a model already\ntrained on a large generic corpora and retraining it for a specific task). Such\ntechnique is popular and well-known in the NLP field. Our results confirm that\nfine-tuning is effective even when neural networks are applied to binaries. We\nshow that a model, pre-trained on the aforementioned corpora, when fine-tuned\nhas higher performances on specific domains (such as predicting names in system\nutilites, malware, etc).", "published": "2019-12-17 11:59:41", "link": "http://arxiv.org/abs/1912.07946v3", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Application of Word2vec in Phoneme Recognition", "abstract": "In this paper, we present how to hybridize a Word2vec model and an\nattention-based end-to-end speech recognition model. We build a phoneme\nrecognition system based on Listen, Attend and Spell model. And the phoneme\nrecognition model uses a word2vec model to initialize the embedding matrix for\nthe improvement of the performance, which can increase the distance among the\nphoneme vectors. At the same time, in order to solve the problem of overfitting\nin the 61 phoneme recognition model on TIMIT dataset, we propose a new training\nmethod. A 61-39 phoneme mapping comparison table is used to inverse map the\nphonemes of the dataset to generate more 61 phoneme training data. At the end\nof training, replace the dataset with a standard dataset for corrective\ntraining. Our model can achieve the best result under the TIMIT dataset which\nis 16.5% PER (Phoneme Error Rate).", "published": "2019-12-17 13:45:13", "link": "http://arxiv.org/abs/1912.08011v2", "categories": ["cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Garbage In, Garbage Out? Do Machine Learning Application Papers in\n  Social Computing Report Where Human-Labeled Training Data Comes From?", "abstract": "Many machine learning projects for new application areas involve teams of\nhumans who label data for a particular purpose, from hiring crowdworkers to the\npaper's authors labeling the data themselves. Such a task is quite similar to\n(or a form of) structured content analysis, which is a longstanding methodology\nin the social sciences and humanities, with many established best practices. In\nthis paper, we investigate to what extent a sample of machine learning\napplication papers in social computing --- specifically papers from ArXiv and\ntraditional publications performing an ML classification task on Twitter data\n--- give specific details about whether such best practices were followed. Our\nteam conducted multiple rounds of structured content analysis of each paper,\nmaking determinations such as: Does the paper report who the labelers were,\nwhat their qualifications were, whether they independently labeled the same\nitems, whether inter-rater reliability metrics were disclosed, what level of\ntraining and/or instructions were given to labelers, whether compensation for\ncrowdworkers is disclosed, and if the training data is publicly available. We\nfind a wide divergence in whether such practices were followed and documented.\nMuch of machine learning research and education focuses on what is done once a\n\"gold standard\" of training data is available, but we discuss issues around the\nequally-important aspect of whether such data is reliable in the first place.", "published": "2019-12-17 23:49:19", "link": "http://arxiv.org/abs/1912.08320v1", "categories": ["cs.CY", "cs.CL", "cs.DL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Differentiable Reasoning on Large Knowledge Bases and Natural Language", "abstract": "Reasoning with knowledge expressed in natural language and Knowledge Bases\n(KBs) is a major challenge for Artificial Intelligence, with applications in\nmachine reading, dialogue, and question answering. General neural architectures\nthat jointly learn representations and transformations of text are very\ndata-inefficient, and it is hard to analyse their reasoning process. These\nissues are addressed by end-to-end differentiable reasoning systems such as\nNeural Theorem Provers (NTPs), although they can only be used with small-scale\nsymbolic KBs. In this paper we first propose Greedy NTPs (GNTPs), an extension\nto NTPs addressing their complexity and scalability limitations, thus making\nthem applicable to real-world datasets. This result is achieved by dynamically\nconstructing the computation graph of NTPs and including only the most\npromising proof paths during inference, thus obtaining orders of magnitude more\nefficient models. Then, we propose a novel approach for jointly reasoning over\nKBs and textual mentions, by embedding logic facts and natural language\nsentences in a shared embedding space. We show that GNTPs perform on par with\nNTPs at a fraction of their cost while achieving competitive link prediction\nresults on large datasets, providing explanations for predictions, and inducing\ninterpretable models. Source code, datasets, and supplementary material are\navailable online at https://github.com/uclnlp/gntp.", "published": "2019-12-17 23:01:54", "link": "http://arxiv.org/abs/1912.10824v1", "categories": ["cs.LG", "cs.CL", "cs.LO"], "primary_category": "cs.LG"}
{"title": "A Heterogeneous Graphical Model to Understand User-Level Sentiments in\n  Social Media", "abstract": "Social Media has seen a tremendous growth in the last decade and is\ncontinuing to grow at a rapid pace. With such adoption, it is increasingly\nbecoming a rich source of data for opinion mining and sentiment analysis. The\ndetection and analysis of sentiment in social media is thus a valuable topic\nand attracts a lot of research efforts. Most of the earlier efforts focus on\nsupervised learning approaches to solve this problem, which require expensive\nhuman annotations and therefore limits their practical use. In our work, we\npropose a semi-supervised approach to predict user-level sentiments for\nspecific topics. We define and utilize a heterogeneous graph built from the\nsocial networks of the users with the knowledge that connected users in social\nnetworks typically share similar sentiments. Compared with the previous works,\nwe have several novelties: (1) we incorporate the influences/authoritativeness\nof the users into the model, 2) we include comment-based and like-based\nuser-user links to the graph, 3) we superimpose multiple heterogeneous graphs\ninto one thereby allowing multiple types of links to exist between two users.", "published": "2019-12-17 10:29:26", "link": "http://arxiv.org/abs/1912.07911v1", "categories": ["cs.LG", "cs.CL", "cs.IR", "cs.SI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Unified Framework for Speech Separation", "abstract": "Speech separation refers to extracting each individual speech source in a\ngiven mixed signal. Recent advancements in speech separation and ongoing\nresearch in this area, have made these approaches as promising techniques for\npre-processing of naturalistic audio streams. After incorporating deep learning\ntechniques into speech separation, performance on these systems is improving\nfaster. The initial solutions introduced for deep learning based speech\nseparation analyzed the speech signals into time-frequency domain with STFT;\nand then encoded mixed signals were fed into a deep neural network based\nseparator. Most recently, new methods are introduced to separate waveform of\nthe mixed signal directly without analyzing them using STFT. Here, we introduce\na unified framework to include both spectrogram and waveform separations into a\nsingle structure, while being only different in the kernel function used to\nencode and decode the data; where, both can achieve competitive performance.\nThis new framework provides flexibility; in addition, depending on the\ncharacteristics of the data, or limitations of the memory and latency can set\nthe hyper-parameters to flow in a pipeline of the framework which fits the task\nproperly. We extend single-channel speech separation into multi-channel\nframework with end-to-end training of the network while optimizing the speech\nseparation criterion (i.e., Si-SNR) directly. We emphasize on how tied kernel\nfunctions for calculating spatial features, encoder, and decoder in\nmulti-channel framework can be effective. We simulate spatialized reverberate\ndata for both WSJ0 and LibriSpeech corpora here, and while these two sets of\ndata are different in the matter of size and duration, the effect of capturing\nshorter and longer dependencies of previous/+future samples are studied in\ndetail. We report SDR, Si-SNR and PESQ to evaluate the performance of developed\nsolutions.", "published": "2019-12-17 04:21:03", "link": "http://arxiv.org/abs/1912.07814v1", "categories": ["cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
