{"title": "Hierarchical Relation-Guided Type-Sentence Alignment for Long-Tail\n  Relation Extraction with Distant Supervision", "abstract": "Distant supervision uses triple facts in knowledge graphs to label a corpus\nfor relation extraction, leading to wrong labeling and long-tail problems. Some\nworks use the hierarchy of relations for knowledge transfer to long-tail\nrelations. However, a coarse-grained relation often implies only an attribute\n(e.g., domain or topic) of the distant fact, making it hard to discriminate\nrelations based solely on sentence semantics. One solution is resorting to\nentity types, but open questions remain about how to fully leverage the\ninformation of entity types and how to align multi-granular entity types with\nsentences. In this work, we propose a novel model to enrich\ndistantly-supervised sentences with entity types. It consists of (1) a pairwise\ntype-enriched sentence encoding module injecting both context-free and -related\nbackgrounds to alleviate sentence-level wrong labeling, and (2) a hierarchical\ntype-sentence alignment module enriching a sentence with the triple fact's\nbasic attributes to support long-tail relations. Our model achieves new\nstate-of-the-art results in overall and long-tail performance on benchmarks.", "published": "2021-09-19 00:46:57", "link": "http://arxiv.org/abs/2109.09036v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge-Enhanced Evidence Retrieval for Counterargument Generation", "abstract": "Finding counterevidence to statements is key to many tasks, including\ncounterargument generation. We build a system that, given a statement,\nretrieves counterevidence from diverse sources on the Web. At the core of this\nsystem is a natural language inference (NLI) model that determines whether a\ncandidate sentence is valid counterevidence or not. Most NLI models to date,\nhowever, lack proper reasoning abilities necessary to find counterevidence that\ninvolves complex inference. Thus, we present a knowledge-enhanced NLI model\nthat aims to handle causality- and example-based inference by incorporating\nknowledge graphs. Our NLI model outperforms baselines for NLI tasks, especially\nfor instances that require the targeted inference. In addition, this NLI model\nfurther improves the counterevidence retrieval system, notably finding complex\ncounterevidence better.", "published": "2021-09-19 04:31:21", "link": "http://arxiv.org/abs/2109.09057v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adversarial Training with Contrastive Learning in NLP", "abstract": "For years, adversarial training has been extensively studied in natural\nlanguage processing (NLP) settings. The main goal is to make models robust so\nthat similar inputs derive in semantically similar outcomes, which is not a\ntrivial problem since there is no objective measure of semantic similarity in\nlanguage. Previous works use an external pre-trained NLP model to tackle this\nchallenge, introducing an extra training stage with huge memory consumption\nduring training. However, the recent popular approach of contrastive learning\nin language processing hints a convenient way of obtaining such similarity\nrestrictions. The main advantage of the contrastive learning approach is that\nit aims for similar data points to be mapped close to each other and further\nfrom different ones in the representation space. In this work, we propose\nadversarial training with contrastive learning (ATCL) to adversarially train a\nlanguage processing task using the benefits of contrastive learning. The core\nidea is to make linear perturbations in the embedding space of the input via\nfast gradient methods (FGM) and train the model to keep the original and\nperturbed representations close via contrastive learning. In NLP experiments,\nwe applied ATCL to language modeling and neural machine translation tasks. The\nresults show not only an improvement in the quantitative (perplexity and BLEU)\nscores when compared to the baselines, but ATCL also achieves good qualitative\nresults in the semantic level for both tasks without using a pre-trained model.", "published": "2021-09-19 07:23:45", "link": "http://arxiv.org/abs/2109.09075v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do Long-Range Language Models Actually Use Long-Range Context?", "abstract": "Language models are generally trained on short, truncated input sequences,\nwhich limits their ability to use discourse-level information present in\nlong-range context to improve their predictions. Recent efforts to improve the\nefficiency of self-attention have led to a proliferation of long-range\nTransformer language models, which can process much longer sequences than\nmodels of the past. However, the ways in which such models take advantage of\nthe long-range context remain unclear. In this paper, we perform a fine-grained\nanalysis of two long-range Transformer language models (including the\n\\emph{Routing Transformer}, which achieves state-of-the-art perplexity on the\nPG-19 long-sequence LM benchmark dataset) that accept input sequences of up to\n8K tokens. Our results reveal that providing long-range context (i.e., beyond\nthe previous 2K tokens) to these models only improves their predictions on a\nsmall set of tokens (e.g., those that can be copied from the distant context)\nand does not help at all for sentence-level prediction tasks. Finally, we\ndiscover that PG-19 contains a variety of different document types and domains,\nand that long-range context helps most for literary novels (as opposed to\ntextbooks or magazines).", "published": "2021-09-19 12:49:43", "link": "http://arxiv.org/abs/2109.09115v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Preventing Author Profiling through Zero-Shot Multilingual\n  Back-Translation", "abstract": "Documents as short as a single sentence may inadvertently reveal sensitive\ninformation about their authors, including e.g. their gender or ethnicity.\nStyle transfer is an effective way of transforming texts in order to remove any\ninformation that enables author profiling. However, for a number of current\nstate-of-the-art approaches the improved privacy is accompanied by an\nundesirable drop in the down-stream utility of the transformed data. In this\npaper, we propose a simple, zero-shot way to effectively lower the risk of\nauthor profiling through multilingual back-translation using off-the-shelf\ntranslation models. We compare our models with five representative text style\ntransfer models on three datasets across different domains. Results from both\nan automatic and a human evaluation show that our approach achieves the best\noverall performance while requiring no training data. We are able to lower the\nadversarial prediction of gender and race by up to $22\\%$ while retaining\n$95\\%$ of the original utility on downstream tasks.", "published": "2021-09-19 14:36:22", "link": "http://arxiv.org/abs/2109.09133v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FST Morphological Analyser and Generator for Mapud\u00fcngun", "abstract": "Following the Mapuche grammar by Smeets, this article describes the main\nmorphophonological aspects of Mapud\\\"ungun, explaining what triggers them and\nthe contexts where they arise. We present a computational approach producing a\nfinite state morphological analyser (and generator) capable of classifying and\nappropriately tagging all the components (roots and suffixes) that interact in\na Mapuche word form. The bulk of the article focuses on presenting details\nabout the morphology of Mapud\\\"ungun verb and its formalisation using FOMA. A\nsystem evaluation process and its results are also present in this article.", "published": "2021-09-19 17:32:17", "link": "http://arxiv.org/abs/2109.09176v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating Crowdsourcing Protocols for Evaluating the Factual\n  Consistency of Summaries", "abstract": "Current pre-trained models applied to summarization are prone to factual\ninconsistencies which either misrepresent the source text or introduce\nextraneous information. Thus, comparing the factual consistency of summaries is\nnecessary as we develop improved models. However, the optimal human evaluation\nsetup for factual consistency has not been standardized. To address this issue,\nwe crowdsourced evaluations for factual consistency using the rating-based\nLikert scale and ranking-based Best-Worst Scaling protocols, on 100 articles\nfrom each of the CNN-Daily Mail and XSum datasets over four state-of-the-art\nmodels, to determine the most reliable evaluation framework. We find that\nranking-based protocols offer a more reliable measure of summary quality across\ndatasets, while the reliability of Likert ratings depends on the target dataset\nand the evaluation design. Our crowdsourcing templates and summary evaluations\nwill be publicly available to facilitate future research on factual consistency\nin summarization.", "published": "2021-09-19 19:05:00", "link": "http://arxiv.org/abs/2109.09195v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CLIFF: Contrastive Learning for Improving Faithfulness and Factuality in\n  Abstractive Summarization", "abstract": "We study generating abstractive summaries that are faithful and factually\nconsistent with the given articles. A novel contrastive learning formulation is\npresented, which leverages both reference summaries, as positive training data,\nand automatically generated erroneous summaries, as negative training data, to\ntrain summarization systems that are better at distinguishing between them. We\nfurther design four types of strategies for creating negative samples, to\nresemble errors made commonly by two state-of-the-art models, BART and PEGASUS,\nfound in our new human annotations of summary errors. Experiments on XSum and\nCNN/Daily Mail show that our contrastive learning framework is robust across\ndatasets and models. It consistently produces more factual summaries than\nstrong comparisons with post error correction, entailment-based reranking, and\nunlikelihood training, according to QA-based factuality evaluation. Human\njudges echo the observation and find that our model summaries correct more\nerrors.", "published": "2021-09-19 20:05:21", "link": "http://arxiv.org/abs/2109.09209v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Conditional probing: measuring usable information beyond a baseline", "abstract": "Probing experiments investigate the extent to which neural representations\nmake properties -- like part-of-speech -- predictable. One suggests that a\nrepresentation encodes a property if probing that representation produces\nhigher accuracy than probing a baseline representation like non-contextual word\nembeddings. Instead of using baselines as a point of comparison, we're\ninterested in measuring information that is contained in the representation but\nnot in the baseline. For example, current methods can detect when a\nrepresentation is more useful than the word identity (a baseline) for\npredicting part-of-speech; however, they cannot detect when the representation\nis predictive of just the aspects of part-of-speech not explainable by the word\nidentity. In this work, we extend a theory of usable information called\n$\\mathcal{V}$-information and propose conditional probing, which explicitly\nconditions on the information in the baseline. In a case study, we find that\nafter conditioning on non-contextual word embeddings, properties like\npart-of-speech are accessible at deeper layers of a network than previously\nthought.", "published": "2021-09-19 21:56:58", "link": "http://arxiv.org/abs/2109.09234v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MirrorWiC: On Eliciting Word-in-Context Representations from Pretrained\n  Language Models", "abstract": "Recent work indicated that pretrained language models (PLMs) such as BERT and\nRoBERTa can be transformed into effective sentence and word encoders even via\nsimple self-supervised techniques. Inspired by this line of work, in this paper\nwe propose a fully unsupervised approach to improving word-in-context (WiC)\nrepresentations in PLMs, achieved via a simple and efficient WiC-targeted\nfine-tuning procedure: MirrorWiC. The proposed method leverages only raw texts\nsampled from Wikipedia, assuming no sense-annotated data, and learns\ncontext-aware word representations within a standard contrastive learning\nsetup. We experiment with a series of standard and comprehensive WiC benchmarks\nacross multiple languages. Our proposed fully unsupervised MirrorWiC models\nobtain substantial gains over off-the-shelf PLMs across all monolingual,\nmultilingual and cross-lingual setups. Moreover, on some standard WiC\nbenchmarks, MirrorWiC is even on-par with supervised models fine-tuned with\nin-task data and sense labels.", "published": "2021-09-19 22:19:01", "link": "http://arxiv.org/abs/2109.09237v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Wav-BERT: Cooperative Acoustic and Linguistic Representation Learning\n  for Low-Resource Speech Recognition", "abstract": "Unifying acoustic and linguistic representation learning has become\nincreasingly crucial to transfer the knowledge learned on the abundance of\nhigh-resource language data for low-resource speech recognition. Existing\napproaches simply cascade pre-trained acoustic and language models to learn the\ntransfer from speech to text. However, how to solve the representation\ndiscrepancy of speech and text is unexplored, which hinders the utilization of\nacoustic and linguistic information. Moreover, previous works simply replace\nthe embedding layer of the pre-trained language model with the acoustic\nfeatures, which may cause the catastrophic forgetting problem. In this work, we\nintroduce Wav-BERT, a cooperative acoustic and linguistic representation\nlearning method to fuse and utilize the contextual information of speech and\ntext. Specifically, we unify a pre-trained acoustic model (wav2vec 2.0) and a\nlanguage model (BERT) into an end-to-end trainable framework. A Representation\nAggregation Module is designed to aggregate acoustic and linguistic\nrepresentation, and an Embedding Attention Module is introduced to incorporate\nacoustic information into BERT, which can effectively facilitate the\ncooperation of two pre-trained models and thus boost the representation\nlearning. Extensive experiments show that our Wav-BERT significantly\noutperforms the existing approaches and achieves state-of-the-art performance\non low-resource speech recognition.", "published": "2021-09-19 16:39:22", "link": "http://arxiv.org/abs/2109.09161v2", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Training Dynamic based data filtering may not work for NLP datasets", "abstract": "The recent increase in dataset size has brought about significant advances in\nnatural language understanding. These large datasets are usually collected\nthrough automation (search engines or web crawlers) or crowdsourcing which\ninherently introduces incorrectly labeled data. Training on these datasets\nleads to memorization and poor generalization. Thus, it is pertinent to develop\ntechniques that help in the identification and isolation of mislabelled data.\nIn this paper, we study the applicability of the Area Under the Margin (AUM)\nmetric to identify and remove/rectify mislabelled examples in NLP datasets. We\nfind that mislabelled samples can be filtered using the AUM metric in NLP\ndatasets but it also removes a significant number of correctly labeled points\nand leads to the loss of a large amount of relevant language information. We\nshow that models rely on the distributional information instead of relying on\nsyntactic and semantic representations.", "published": "2021-09-19 18:50:45", "link": "http://arxiv.org/abs/2109.09191v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Zero-Label Language Learning", "abstract": "This paper explores zero-label learning in Natural Language Processing (NLP),\nwhereby no human-annotated data is used anywhere during training and models are\ntrained purely on synthetic data. At the core of our framework is a novel\napproach for better leveraging the powerful pretrained language models.\nSpecifically, inspired by the recent success of few-shot inference on GPT-3, we\npresent a training data creation procedure named Unsupervised Data Generation\n(UDG), which leverages few-shot prompts to synthesize high-quality training\ndata without real human annotations. Our method enables zero-label learning as\nwe train task-specific models solely on the synthetic data, yet we achieve\nbetter or comparable results from strong baseline models trained on\nhuman-labeled data. Furthermore, when mixed with labeled data, our approach\nserves as a highly effective data augmentation procedure, achieving new\nstate-of-the-art results on the SuperGLUE benchmark.", "published": "2021-09-19 19:00:07", "link": "http://arxiv.org/abs/2109.09193v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "UPV at CheckThat! 2021: Mitigating Cultural Differences for Identifying\n  Multilingual Check-worthy Claims", "abstract": "Identifying check-worthy claims is often the first step of automated\nfact-checking systems. Tackling this task in a multilingual setting has been\nunderstudied. Encoding inputs with multilingual text representations could be\none approach to solve the multilingual check-worthiness detection. However,\nthis approach could suffer if cultural bias exists within the communities on\ndetermining what is check-worthy.In this paper, we propose a language\nidentification task as an auxiliary task to mitigate unintended bias.With this\npurpose, we experiment joint training by using the datasets from CLEF-2021\nCheckThat!, that contain tweets in English, Arabic, Bulgarian, Spanish and\nTurkish. Our results show that joint training of language identification and\ncheck-worthy claim detection tasks can provide performance gains for some of\nthe selected languages.", "published": "2021-09-19 21:46:16", "link": "http://arxiv.org/abs/2109.09232v1", "categories": ["cs.CL", "cs.LG", "I.7; J.4"], "primary_category": "cs.CL"}
{"title": "Navigating the Kaleidoscope of COVID-19 Misinformation Using Deep\n  Learning", "abstract": "Irrespective of the success of the deep learning-based mixed-domain transfer\nlearning approach for solving various Natural Language Processing tasks, it\ndoes not lend a generalizable solution for detecting misinformation from\nCOVID-19 social media data. Due to the inherent complexity of this type of\ndata, caused by its dynamic (context evolves rapidly), nuanced (misinformation\ntypes are often ambiguous), and diverse (skewed, fine-grained, and overlapping\ncategories) nature, it is imperative for an effective model to capture both the\nlocal and global context of the target domain. By conducting a systematic\ninvestigation, we show that: (i) the deep Transformer-based pre-trained models,\nutilized via the mixed-domain transfer learning, are only good at capturing the\nlocal context, thus exhibits poor generalization, and (ii) a combination of\nshallow network-based domain-specific models and convolutional neural networks\ncan efficiently extract local as well as global context directly from the\ntarget data in a hierarchical fashion, enabling it to offer a more\ngeneralizable solution.", "published": "2021-09-19 15:49:25", "link": "http://arxiv.org/abs/2110.15703v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "What BERT Based Language Models Learn in Spoken Transcripts: An\n  Empirical Study", "abstract": "Language Models (LMs) have been ubiquitously leveraged in various tasks\nincluding spoken language understanding (SLU). Spoken language requires careful\nunderstanding of speaker interactions, dialog states and speech induced\nmultimodal behaviors to generate a meaningful representation of the\nconversation. In this work, we propose to dissect SLU into three representative\nproperties:conversational (disfluency, pause, overtalk), channel (speaker-type,\nturn-tasks) and ASR (insertion, deletion,substitution). We probe BERT based\nlanguage models (BERT, RoBERTa) trained on spoken transcripts to investigate\nits ability to understand multifarious properties in absence of any speech\ncues. Empirical results indicate that LM is surprisingly good at capturing\nconversational properties such as pause prediction and overtalk detection from\nlexical tokens. On the downsides, the LM scores low on turn-tasks and ASR\nerrors predictions. Additionally, pre-training the LM on spoken transcripts\nrestrain its linguistic understanding. Finally, we establish the efficacy and\ntransferability of the mentioned properties on two benchmark datasets:\nSwitchboard Dialog Act and Disfluency datasets.", "published": "2021-09-19 11:23:50", "link": "http://arxiv.org/abs/2109.09105v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Unified and Multilingual Author Profiling for Detecting Haters", "abstract": "This paper presents a unified user profiling framework to identify hate\nspeech spreaders by processing their tweets regardless of the language. The\nframework encodes the tweets with sentence transformers and applies an\nattention mechanism to select important tweets for learning user profiles.\nFurthermore, the attention layer helps to explain why a user is a hate speech\nspreader by producing attention weights at both token and post level. Our\nproposed model outperformed the state-of-the-art multilingual transformer\nmodels.", "published": "2021-09-19 21:53:23", "link": "http://arxiv.org/abs/2109.09233v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ARCA23K: An audio dataset for investigating open-set label noise", "abstract": "The availability of audio data on sound sharing platforms such as Freesound\ngives users access to large amounts of annotated audio. Utilising such data for\ntraining is becoming increasingly popular, but the problem of label noise that\nis often prevalent in such datasets requires further investigation. This paper\nintroduces ARCA23K, an Automatically Retrieved and Curated Audio dataset\ncomprised of over 23000 labelled Freesound clips. Unlike past datasets such as\nFSDKaggle2018 and FSDnoisy18K, ARCA23K facilitates the study of label noise in\na more controlled manner. We describe the entire process of creating the\ndataset such that it is fully reproducible, meaning researchers can extend our\nwork with little effort. We show that the majority of labelling errors in\nARCA23K are due to out-of-vocabulary audio clips, and we refer to this type of\nlabel noise as open-set label noise. Experiments are carried out in which we\nstudy the impact of label noise in terms of classification performance and\nrepresentation learning.", "published": "2021-09-19 21:10:25", "link": "http://arxiv.org/abs/2109.09227v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
