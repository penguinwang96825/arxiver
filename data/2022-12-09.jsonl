{"title": "From Cloze to Comprehension: Retrofitting Pre-trained Masked Language\n  Model to Pre-trained Machine Reader", "abstract": "We present Pre-trained Machine Reader (PMR), a novel method for retrofitting\npre-trained masked language models (MLMs) to pre-trained machine reading\ncomprehension (MRC) models without acquiring labeled data. PMR can resolve the\ndiscrepancy between model pre-training and downstream fine-tuning of existing\nMLMs. To build the proposed PMR, we constructed a large volume of\ngeneral-purpose and high-quality MRC-style training data by using Wikipedia\nhyperlinks and designed a Wiki Anchor Extraction task to guide the MRC-style\npre-training. Apart from its simplicity, PMR effectively solves extraction\ntasks, such as Extractive Question Answering and Named Entity Recognition. PMR\nshows tremendous improvements over existing approaches, especially in\nlow-resource scenarios. When applied to the sequence classification task in the\nMRC formulation, PMR enables the extraction of high-quality rationales to\nexplain the classification process, thereby providing greater prediction\nexplainability. PMR also has the potential to serve as a unified model for\ntackling various extraction and classification tasks in the MRC formulation.", "published": "2022-12-09 10:21:56", "link": "http://arxiv.org/abs/2212.04755v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CKG: Dynamic Representation Based on Context and Knowledge Graph", "abstract": "Recently, neural language representation models pre-trained on large corpus\ncan capture rich co-occurrence information and be fine-tuned in downstream\ntasks to improve the performance. As a result, they have achieved\nstate-of-the-art results in a large range of language tasks. However, there\nexists other valuable semantic information such as similar, opposite, or other\npossible meanings in external knowledge graphs (KGs). We argue that entities in\nKGs could be used to enhance the correct semantic meaning of language\nsentences. In this paper, we propose a new method CKG: Dynamic Representation\nBased on \\textbf{C}ontext and \\textbf{K}nowledge \\textbf{G}raph. On the one\nside, CKG can extract rich semantic information of large corpus. On the other\nside, it can make full use of inside information such as co-occurrence in large\ncorpus and outside information such as similar entities in KGs. We conduct\nextensive experiments on a wide range of tasks, including QQP, MRPC, SST-5,\nSQuAD, CoNLL 2003, and SNLI. The experiment results show that CKG achieves SOTA\n89.2 on SQuAD compared with SAN (84.4), ELMo (85.8), and BERT$_{Base}$ (88.5).", "published": "2022-12-09 15:17:35", "link": "http://arxiv.org/abs/2212.04909v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Plug-and-Play Recipe Generation with Content Planning", "abstract": "Recent pre-trained language models have shown promising capabilities in\ngenerating fluent and realistic natural language text. However, generating\nmulti-sentence text with global content planning has been a long-existing\nresearch question. Current approaches for controlled text generation can hardly\naddress this issue, as they usually condition on single known control\nattributes. In this study, we propose a low-cost yet effective framework which\nexplicitly models the global content plan of the generated text. Specifically,\nit optimizes the joint distribution of the natural language sequence and the\nglobal content plan in a plug-and-play manner. We conduct extensive experiments\non the well-established Recipe1M+ benchmark. Both automatic and human\nevaluations verify that our model achieves the state-of-the-art performance on\nthe task of recipe generation", "published": "2022-12-09 19:39:10", "link": "http://arxiv.org/abs/2212.05093v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Open-world Story Generation with Structured Knowledge Enhancement: A\n  Comprehensive Survey", "abstract": "Storytelling and narrative are fundamental to human experience, intertwined\nwith our social and cultural engagement. As such, researchers have long\nattempted to create systems that can generate stories automatically. In recent\nyears, powered by deep learning and massive data resources, automatic story\ngeneration has shown significant advances. However, considerable challenges,\nlike the need for global coherence in generated stories, still hamper\ngenerative models from reaching the same storytelling ability as human\nnarrators. To tackle these challenges, many studies seek to inject structured\nknowledge into the generation process, which is referred to as structured\nknowledge-enhanced story generation. Incorporating external knowledge can\nenhance the logical coherence among story events, achieve better knowledge\ngrounding, and alleviate over-generalization and repetition problems in\nstories. This survey provides the latest and comprehensive review of this\nresearch field: (i) we present a systematic taxonomy regarding how existing\nmethods integrate structured knowledge into story generation; (ii) we summarize\ninvolved story corpora, structured knowledge datasets, and evaluation metrics;\n(iii) we give multidimensional insights into the challenges of\nknowledge-enhanced story generation and cast light on promising directions for\nfuture study.", "published": "2022-12-09 02:19:07", "link": "http://arxiv.org/abs/2212.04634v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Comparative Study of Sentiment Analysis for Multi-Sourced Social Media\n  Platforms", "abstract": "There is a vast amount of data generated every second due to the rapidly\ngrowing technology in the current world. This area of research attempts to\ndetermine the feelings or opinions of people on social media posts. The dataset\nwe used was a multi-source dataset from the comment section of various social\nnetworking sites like Twitter, Reddit, etc. Natural Language Processing\nTechniques were employed to perform sentiment analysis on the obtained dataset.\nIn this paper, we provide a comparative analysis using techniques of\nlexicon-based, machine learning and deep learning approaches. The Machine\nLearning algorithm used in this work is Naive Bayes, the Lexicon-based approach\nused in this work is TextBlob, and the deep-learning algorithm used in this\nwork is LSTM.", "published": "2022-12-09 06:33:49", "link": "http://arxiv.org/abs/2212.04688v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AUC Maximization for Low-Resource Named Entity Recognition", "abstract": "Current work in named entity recognition (NER) uses either cross entropy (CE)\nor conditional random fields (CRF) as the objective/loss functions to optimize\nthe underlying NER model. Both of these traditional objective functions for the\nNER problem generally produce adequate performance when the data distribution\nis balanced and there are sufficient annotated training examples. But since NER\nis inherently an imbalanced tagging problem, the model performance under the\nlow-resource settings could suffer using these standard objective functions.\nBased on recent advances in area under the ROC curve (AUC) maximization, we\npropose to optimize the NER model by maximizing the AUC score. We give evidence\nthat by simply combining two binary-classifiers that maximize the AUC score,\nsignificant performance improvement over traditional loss functions is achieved\nunder low-resource NER settings. We also conduct extensive experiments to\ndemonstrate the advantages of our method under the low-resource and\nhighly-imbalanced data distribution settings. To the best of our knowledge,\nthis is the first work that brings AUC maximization to the NER setting.\nFurthermore, we show that our method is agnostic to different types of NER\nembeddings, models and domains. The code to replicate this work will be\nprovided upon request.", "published": "2022-12-09 12:06:15", "link": "http://arxiv.org/abs/2212.04800v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TRBLLmaker -- Transformer Reads Between Lyrics Lines maker", "abstract": "Even for us, it can be challenging to comprehend the meaning of songs. As\npart of this project, we explore the process of generating the meaning of\nsongs. Despite the widespread use of text-to-text models, few attempts have\nbeen made to achieve a similar objective. Songs are primarily studied in the\ncontext of sentiment analysis. This involves identifying opinions and emotions\nin texts, evaluating them as positive or negative, and utilizing these\nevaluations to make music recommendations. In this paper, we present a\ngenerative model that offers implicit meanings for several lines of a song. Our\nmodel uses a decoder Transformer architecture GPT-2, where the input is the\nlyrics of a song. Furthermore, we compared the performance of this architecture\nwith that of the encoder-decoder Transformer architecture of the T5 model. We\nalso examined the effect of different prompt types with the option of appending\nadditional information, such as the name of the artist and the title of the\nsong. Moreover, we tested different decoding methods with different training\nparameters and evaluated our results using ROUGE. In order to build our\ndataset, we utilized the 'Genious' API, which allowed us to acquire the lyrics\nof songs and their explanations, as well as their rich metadata.", "published": "2022-12-09 15:27:36", "link": "http://arxiv.org/abs/2212.04917v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LADIS: Language Disentanglement for 3D Shape Editing", "abstract": "Natural language interaction is a promising direction for democratizing 3D\nshape design. However, existing methods for text-driven 3D shape editing face\nchallenges in producing decoupled, local edits to 3D shapes. We address this\nproblem by learning disentangled latent representations that ground language in\n3D geometry. To this end, we propose a complementary tool set including a novel\nnetwork architecture, a disentanglement loss, and a new editing procedure.\nAdditionally, to measure edit locality, we define a new metric that we call\npart-wise edit precision. We show that our method outperforms existing SOTA\nmethods by 20% in terms of edit locality, and up to 6.6% in terms of language\nreference resolution accuracy. Our work suggests that by solely disentangling\nlanguage representations, downstream 3D shape editing can become more local to\nrelevant parts, even if the model was never given explicit part-based\nsupervision.", "published": "2022-12-09 17:54:28", "link": "http://arxiv.org/abs/2212.05011v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Training-Free Structured Diffusion Guidance for Compositional\n  Text-to-Image Synthesis", "abstract": "Large-scale diffusion models have achieved state-of-the-art results on\ntext-to-image synthesis (T2I) tasks. Despite their ability to generate\nhigh-quality yet creative images, we observe that attribution-binding and\ncompositional capabilities are still considered major challenging issues,\nespecially when involving multiple objects. In this work, we improve the\ncompositional skills of T2I models, specifically more accurate attribute\nbinding and better image compositions. To do this, we incorporate linguistic\nstructures with the diffusion guidance process based on the controllable\nproperties of manipulating cross-attention layers in diffusion-based T2I\nmodels. We observe that keys and values in cross-attention layers have strong\nsemantic meanings associated with object layouts and content. Therefore, we can\nbetter preserve the compositional semantics in the generated image by\nmanipulating the cross-attention representations based on linguistic insights.\nBuilt upon Stable Diffusion, a SOTA T2I model, our structured cross-attention\ndesign is efficient that requires no additional training samples. We achieve\nbetter compositional skills in qualitative and quantitative results, leading to\na 5-8% advantage in head-to-head user comparison studies. Lastly, we conduct an\nin-depth analysis to reveal potential causes of incorrect image compositions\nand justify the properties of cross-attention layers in the generation process.", "published": "2022-12-09 18:30:24", "link": "http://arxiv.org/abs/2212.05032v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Incorporating Emotions into Health Mention Classification Task on Social\n  Media", "abstract": "The health mention classification (HMC) task is the process of identifying\nand classifying mentions of health-related concepts in text. This can be useful\nfor identifying and tracking the spread of diseases through social media posts.\nHowever, this is a non-trivial task. Here we build on recent studies suggesting\nthat using emotional information may improve upon this task. Our study results\nin a framework for health mention classification that incorporates affective\nfeatures. We present two methods, an intermediate task fine-tuning approach\n(implicit) and a multi-feature fusion approach (explicit) to incorporate\nemotions into our target task of HMC. We evaluated our approach on 5\nHMC-related datasets from different social media platforms including three from\nTwitter, one from Reddit and another from a combination of social media\nsources. Extensive experiments demonstrate that our approach results in\nstatistically significant performance gains on HMC tasks. By using the\nmulti-feature fusion approach, we achieve at least a 3% improvement in F1 score\nover BERT baselines across all datasets. We also show that considering only\nnegative emotions does not significantly affect performance on the HMC task.\nAdditionally, our results indicate that HMC models infused with emotional\nknowledge are an effective alternative, especially when other HMC datasets are\nunavailable for domain-specific fine-tuning. The source code for our models is\nfreely available at https://github.com/tahirlanre/Emotion_PHM.", "published": "2022-12-09 18:38:41", "link": "http://arxiv.org/abs/2212.05039v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multi-task Learning for Personal Health Mention Detection on Social\n  Media", "abstract": "Detecting personal health mentions on social media is essential to complement\nexisting health surveillance systems. However, annotating data for detecting\nhealth mentions at a large scale is a challenging task. This research employs a\nmultitask learning framework to leverage available annotated data from a\nrelated task to improve the performance on the main task to detect personal\nhealth experiences mentioned in social media texts. Specifically, we focus on\nincorporating emotional information into our target task by using emotion\ndetection as an auxiliary task. Our approach significantly improves a wide\nrange of personal health mention detection tasks compared to a strong\nstate-of-the-art baseline.", "published": "2022-12-09 23:49:00", "link": "http://arxiv.org/abs/2212.05147v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Moto: Enhancing Embedding with Multiple Joint Factors for Chinese Text\n  Classification", "abstract": "Recently, language representation techniques have achieved great performances\nin text classification. However, most existing representation models are\nspecifically designed for English materials, which may fail in Chinese because\nof the huge difference between these two languages. Actually, few existing\nmethods for Chinese text classification process texts at a single level.\nHowever, as a special kind of hieroglyphics, radicals of Chinese characters are\ngood semantic carriers. In addition, Pinyin codes carry the semantic of tones,\nand Wubi reflects the stroke structure information, \\textit{etc}.\nUnfortunately, previous researches neglected to find an effective way to\ndistill the useful parts of these four factors and to fuse them. In our works,\nwe propose a novel model called Moto: Enhancing Embedding with\n\\textbf{M}ultiple J\\textbf{o}int Fac\\textbf{to}rs. Specifically, we design an\nattention mechanism to distill the useful parts by fusing the four-level\ninformation above more effectively. We conduct extensive experiments on four\npopular tasks. The empirical results show that our Moto achieves SOTA 0.8316\n($F_1$-score, 2.11\\% improvement) on Chinese news titles, 96.38 (1.24\\%\nimprovement) on Fudan Corpus and 0.9633 (3.26\\% improvement) on THUCNews.", "published": "2022-12-09 15:45:57", "link": "http://arxiv.org/abs/2212.08105v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multidimensional Service Quality Scoring System", "abstract": "This supplementary paper aims to introduce the Multidimensional Service\nQuality Scoring System (MSQs), a review-based method for quantifying host\nservice quality mentioned and employed in the paper Exit and transition:\nExploring the survival status of Airbnb listings in a time of\nprofessionalization. MSQs is not an end-to-end implementation and is\nessentially composed of three pipelines, namely Data Collection and\nPreprocessing, Objects Recognition and Grouping, and Aspect-based Service\nScoring. Using the study mentioned above as a case, the technical details of\nMSQs are explained in this article.", "published": "2022-12-09 00:29:37", "link": "http://arxiv.org/abs/2212.04611v1", "categories": ["cs.LG", "cs.CL", "stat.ME"], "primary_category": "cs.LG"}
{"title": "MED-SE: Medical Entity Definition-based Sentence Embedding", "abstract": "We propose Medical Entity Definition-based Sentence Embedding (MED-SE), a\nnovel unsupervised contrastive learning framework designed for clinical texts,\nwhich exploits the definitions of medical entities. To this end, we conduct an\nextensive analysis of multiple sentence embedding techniques in clinical\nsemantic textual similarity (STS) settings. In the entity-centric setting that\nwe have designed, MED-SE achieves significantly better performance, while the\nexisting unsupervised methods including SimCSE show degraded performance. Our\nexperiments elucidate the inherent discrepancies between the general- and\nclinical-domain texts, and suggest that entity-centric contrastive approaches\nmay help bridge this gap and lead to a better representation of clinical\nsentences.", "published": "2022-12-09 09:10:19", "link": "http://arxiv.org/abs/2212.04734v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Understanding Online Migration Decisions Following the Banning of\n  Radical Communities", "abstract": "The proliferation of radical online communities and their violent offshoots\nhas sparked great societal concern. However, the current practice of banning\nsuch communities from mainstream platforms has unintended consequences: (I) the\nfurther radicalization of their members in fringe platforms where they migrate;\nand (ii) the spillover of harmful content from fringe back onto mainstream\nplatforms. Here, in a large observational study on two banned subreddits,\nr/The\\_Donald and r/fatpeoplehate, we examine how factors associated with the\nRECRO radicalization framework relate to users' migration decisions.\nSpecifically, we quantify how these factors affect users' decisions to post on\nfringe platforms and, for those who do, whether they continue posting on the\nmainstream platform. Our results show that individual-level factors, those\nrelating to the behavior of users, are associated with the decision to post on\nthe fringe platform. Whereas social-level factors, users' connection with the\nradical community, only affect the propensity to be coactive on both platforms.\nOverall, our findings pave the way for evidence-based moderation policies, as\nthe decisions to migrate and remain coactive amplify unintended consequences of\ncommunity bans.", "published": "2022-12-09 10:43:15", "link": "http://arxiv.org/abs/2212.04765v1", "categories": ["cs.SI", "cs.CL", "physics.soc-ph", "stat.AP"], "primary_category": "cs.SI"}
{"title": "MOPRD: A multidisciplinary open peer review dataset", "abstract": "Open peer review is a growing trend in academic publications. Public access\nto peer review data can benefit both the academic and publishing communities.\nIt also serves as a great support to studies on review comment generation and\nfurther to the realization of automated scholarly paper review. However, most\nof the existing peer review datasets do not provide data that cover the whole\npeer review process. Apart from this, their data are not diversified enough as\nthe data are mainly collected from the field of computer science. These two\ndrawbacks of the currently available peer review datasets need to be addressed\nto unlock more opportunities for related studies. In response, we construct\nMOPRD, a multidisciplinary open peer review dataset. This dataset consists of\npaper metadata, multiple version manuscripts, review comments, meta-reviews,\nauthor's rebuttal letters, and editorial decisions. Moreover, we propose a\nmodular guided review comment generation method based on MOPRD. Experiments\nshow that our method delivers better performance as indicated by both automatic\nmetrics and human evaluation. We also explore other potential applications of\nMOPRD, including meta-review generation, editorial decision prediction, author\nrebuttal generation, and scientometric analysis. MOPRD is a strong endorsement\nfor further studies in peer review-related research and other applications.", "published": "2022-12-09 16:35:14", "link": "http://arxiv.org/abs/2212.04972v2", "categories": ["cs.DL", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.DL"}
{"title": "Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints", "abstract": "Training large, deep neural networks to convergence can be prohibitively\nexpensive. As a result, often only a small selection of popular, dense models\nare reused across different contexts and tasks. Increasingly, sparsely\nactivated models, which seek to decouple model size from computation costs, are\nbecoming an attractive alternative to dense models. Although more efficient in\nterms of quality and computation cost, sparse models remain data-hungry and\ncostly to train from scratch in the large scale regime. In this work, we\npropose sparse upcycling -- a simple way to reuse sunk training costs by\ninitializing a sparsely activated Mixture-of-Experts model from a dense\ncheckpoint. We show that sparsely upcycled T5 Base, Large, and XL language\nmodels and Vision Transformer Base and Large models, respectively,\nsignificantly outperform their dense counterparts on SuperGLUE and ImageNet,\nusing only ~50% of the initial dense pretraining sunk cost. The upcycled models\nalso outperform sparse models trained from scratch on 100% of the initial dense\npretraining computation budget.", "published": "2022-12-09 18:57:37", "link": "http://arxiv.org/abs/2212.05055v2", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Decomposing a Recurrent Neural Network into Modules for Enabling\n  Reusability and Replacement", "abstract": "Can we take a recurrent neural network (RNN) trained to translate between\nlanguages and augment it to support a new natural language without retraining\nthe model from scratch? Can we fix the faulty behavior of the RNN by replacing\nportions associated with the faulty behavior? Recent works on decomposing a\nfully connected neural network (FCNN) and convolutional neural network (CNN)\ninto modules have shown the value of engineering deep models in this manner,\nwhich is standard in traditional SE but foreign for deep learning models.\nHowever, prior works focus on the image-based multiclass classification\nproblems and cannot be applied to RNN due to (a) different layer structures,\n(b) loop structures, (c) different types of input-output architectures, and (d)\nusage of both nonlinear and logistic activation functions. In this work, we\npropose the first approach to decompose an RNN into modules. We study different\ntypes of RNNs, i.e., Vanilla, LSTM, and GRU. Further, we show how such RNN\nmodules can be reused and replaced in various scenarios. We evaluate our\napproach against 5 canonical datasets (i.e., Math QA, Brown Corpus,\nWiki-toxicity, Clinc OOS, and Tatoeba) and 4 model variants for each dataset.\nWe found that decomposing a trained model has a small cost (Accuracy: -0.6%,\nBLEU score: +0.10%). Also, the decomposed modules can be reused and replaced\nwithout needing to retrain.", "published": "2022-12-09 03:29:38", "link": "http://arxiv.org/abs/2212.05970v3", "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "The Turing Deception", "abstract": "This research revisits the classic Turing test and compares recent large\nlanguage models such as ChatGPT for their abilities to reproduce human-level\ncomprehension and compelling text generation. Two task challenges --\nsummarization, and question answering -- prompt ChatGPT to produce original\ncontent (98-99%) from a single text entry and also sequential questions\noriginally posed by Turing in 1950. We score the original and generated content\nagainst the OpenAI GPT-2 Output Detector from 2019, and establish multiple\ncases where the generated content proves original and undetectable (98%). The\nquestion of a machine fooling a human judge recedes in this work relative to\nthe question of \"how would one prove it?\" The original contribution of the work\npresents a metric and simple grammatical set for understanding the writing\nmechanics of chatbots in evaluating their readability and statistical clarity,\nengagement, delivery, and overall quality. While Turing's original prose scores\nat least 14% below the machine-generated output, the question of whether an\nalgorithm displays hints of Turing's truly original thoughts (the \"Lovelace\n2.0\" test) remains unanswered and potentially unanswerable for now.", "published": "2022-12-09 16:32:11", "link": "http://arxiv.org/abs/2212.06721v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Geometry-aware DoA Estimation using a Deep Neural Network with\n  mixed-data input features", "abstract": "Unlike model-based direction of arrival (DoA) estimation algorithms,\nsupervised learning-based DoA estimation algorithms based on deep neural\nnetworks (DNNs) are usually trained for one specific microphone array geometry,\nresulting in poor performance when applied to a different array geometry. In\nthis paper we illustrate the fundamental difference between supervised\nlearning-based and model-based algorithms leading to this sensitivity. Aiming\nat designing a supervised learning-based DoA estimation algorithm that\ngeneralizes well to different array geometries, in this paper we propose a\ngeometry-aware DoA estimation algorithm. The algorithm uses a fully connected\nDNN and takes mixed data as input features, namely the time lags maximizing the\ngeneralized cross-correlation with phase transform and the microphone\ncoordinates, which are assumed to be known. Experimental results for a\nreverberant scenario demonstrate the flexibility of the proposed algorithm\ntowards different array geometries and show that the proposed algorithm\noutperforms model-based algorithms such as steered response power with phase\ntransform.", "published": "2022-12-09 11:41:16", "link": "http://arxiv.org/abs/2212.04788v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Hyperbolic Audio Source Separation", "abstract": "We introduce a framework for audio source separation using embeddings on a\nhyperbolic manifold that compactly represent the hierarchical relationship\nbetween sound sources and time-frequency features. Inspired by recent successes\nmodeling hierarchical relationships in text and images with hyperbolic\nembeddings, our algorithm obtains a hyperbolic embedding for each\ntime-frequency bin of a mixture signal and estimates masks using hyperbolic\nsoftmax layers. On a synthetic dataset containing mixtures of multiple people\ntalking and musical instruments playing, our hyperbolic model performed\ncomparably to a Euclidean baseline in terms of source to distortion ratio, with\nstronger performance at low embedding dimensions. Furthermore, we find that\ntime-frequency regions containing multiple overlapping sources are embedded\ntowards the center (i.e., the most uncertain region) of the hyperbolic space,\nand we can use this certainty estimate to efficiently trade-off between\nartifact introduction and interference reduction when isolating individual\nsounds.", "published": "2022-12-09 17:47:48", "link": "http://arxiv.org/abs/2212.05008v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Machine Learning-based Classification of Birds through Birdsong", "abstract": "Audio sound recognition and classification is used for many tasks and\napplications including human voice recognition, music recognition and audio\ntagging. In this paper we apply Mel Frequency Cepstral Coefficients (MFCC) in\ncombination with a range of machine learning models to identify (Australian)\nbirds from publicly available audio files of their birdsong. We present\napproaches used for data processing and augmentation and compare the results of\nvarious state of the art machine learning models. We achieve an overall\naccuracy of 91% for the top-5 birds from the 30 selected as the case study.\nApplying the models to more challenging and diverse audio files comprising 152\nbird species, we achieve an accuracy of 58%", "published": "2022-12-09 06:20:50", "link": "http://arxiv.org/abs/2212.04684v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Uncertainty Estimation in Deep Speech Enhancement Using Complex Gaussian\n  Mixture Models", "abstract": "Single-channel deep speech enhancement approaches often estimate a single\nmultiplicative mask to extract clean speech without a measure of its accuracy.\nInstead, in this work, we propose to quantify the uncertainty associated with\nclean speech estimates in neural network-based speech enhancement. Predictive\nuncertainty is typically categorized into aleatoric uncertainty and epistemic\nuncertainty. The former accounts for the inherent uncertainty in data and the\nlatter corresponds to the model uncertainty. Aiming for robust clean speech\nestimation and efficient predictive uncertainty quantification, we propose to\nintegrate statistical complex Gaussian mixture models (CGMMs) into a deep\nspeech enhancement framework. More specifically, we model the dependency\nbetween input and output stochastically by means of a conditional probability\ndensity and train a neural network to map the noisy input to the full posterior\ndistribution of clean speech, modeled as a mixture of multiple complex Gaussian\ncomponents. Experimental results on different datasets show that the proposed\nalgorithm effectively captures predictive uncertainty and that combining\npowerful statistical models and deep learning also delivers a superior speech\nenhancement performance.", "published": "2022-12-09 13:03:09", "link": "http://arxiv.org/abs/2212.04831v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
