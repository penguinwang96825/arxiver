{"title": "SemStamp: A Semantic Watermark with Paraphrastic Robustness for Text\n  Generation", "abstract": "Existing watermarking algorithms are vulnerable to paraphrase attacks because\nof their token-level design. To address this issue, we propose SemStamp, a\nrobust sentence-level semantic watermarking algorithm based on\nlocality-sensitive hashing (LSH), which partitions the semantic space of\nsentences. The algorithm encodes and LSH-hashes a candidate sentence generated\nby an LLM, and conducts sentence-level rejection sampling until the sampled\nsentence falls in watermarked partitions in the semantic embedding space. A\nmargin-based constraint is used to enhance its robustness. To show the\nadvantages of our algorithm, we propose a \"bigram\" paraphrase attack using the\nparaphrase that has the fewest bigram overlaps with the original sentence. This\nattack is shown to be effective against the existing token-level watermarking\nmethod. Experimental results show that our novel semantic watermark algorithm\nis not only more robust than the previous state-of-the-art method on both\ncommon and bigram paraphrase attacks, but also is better at preserving the\nquality of generation.", "published": "2023-10-06 03:33:42", "link": "http://arxiv.org/abs/2310.03991v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analysis of the Reasoning with Redundant Information Provided Ability of\n  Large Language Models", "abstract": "Recent advancements in Large Language Models (LLMs) have demonstrated\nimpressive capabilities across a range of natural language processing tasks,\nespecially in reasoning, a cornerstone for achieving Artificial General\nIntelligence (AGI). However, commonly used benchmarks may not fully encapsulate\nthe inferential abilities of these models in real-world scenarios. To address\nthis gap, a new form of Question-Answering (QA) task, termed Reasoning with\nRedundant Information Provided (RRIP), is introduced. The study designed a\nmodified version of the grade school math 8K (GSM-8K) dataset which has several\nvariants focusing on different attributes of redundant information. This\ninvestigation evaluates two popular LLMs, LlaMA2-13B-chat and generative\npre-trained transformer 3.5 (GPT-3.5), contrasting their performance on\ntraditional QA tasks against the RRIP tasks. Findings indicate that while these\nmodels achieved moderate success on standard QA benchmarks, their performance\nnotably declines when assessed on RRIP tasks. The study not only highlights the\nlimitations of current LLMs in handling redundant information but also suggests\nthat future training of these models should focus on incorporating redundant\ninformation into the training data to increase the performance on RRIP tasks.", "published": "2023-10-06 06:20:06", "link": "http://arxiv.org/abs/2310.04039v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Written and spoken corpus of real and fake social media postings about\n  COVID-19", "abstract": "This study investigates the linguistic traits of fake news and real news.\nThere are two parts to this study: text data and speech data. The text data for\nthis study consisted of 6420 COVID-19 related tweets re-filtered from Patwa et\nal. (2021). After cleaning, the dataset contained 3049 tweets, with 2161\nlabeled as 'real' and 888 as 'fake'. The speech data for this study was\ncollected from TikTok, focusing on COVID-19 related videos. Research assistants\nfact-checked each video's content using credible sources and labeled them as\n'Real', 'Fake', or 'Questionable', resulting in a dataset of 91 real entries\nand 109 fake entries from 200 TikTok videos with a total word count of 53,710\nwords. The data was analysed using the Linguistic Inquiry and Word Count (LIWC)\nsoftware to detect patterns in linguistic data. The results indicate a set of\nlinguistic features that distinguish fake news from real news in both written\nand speech data. This offers valuable insights into the role of language in\nshaping trust, social media interactions, and the propagation of fake news.", "published": "2023-10-06 13:21:04", "link": "http://arxiv.org/abs/2310.04237v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KoMultiText: Large-Scale Korean Text Dataset for Classifying Biased\n  Speech in Real-World Online Services", "abstract": "With the growth of online services, the need for advanced text classification\nalgorithms, such as sentiment analysis and biased text detection, has become\nincreasingly evident. The anonymous nature of online services often leads to\nthe presence of biased and harmful language, posing challenges to maintaining\nthe health of online communities. This phenomenon is especially relevant in\nSouth Korea, where large-scale hate speech detection algorithms have not yet\nbeen broadly explored. In this paper, we introduce \"KoMultiText\", a new\ncomprehensive, large-scale dataset collected from a well-known South Korean SNS\nplatform. Our proposed dataset provides annotations including (1) Preferences,\n(2) Profanities, and (3) Nine types of Bias for the text samples, enabling\nmulti-task learning for simultaneous classification of user-generated texts.\nLeveraging state-of-the-art BERT-based language models, our approach surpasses\nhuman-level accuracy across diverse classification tasks, as measured by\nvarious metrics. Beyond academic contributions, our work can provide practical\nsolutions for real-world hate speech and bias mitigation, contributing directly\nto the improvement of online community health. Our work provides a robust\nfoundation for future research aiming to improve the quality of online\ndiscourse and foster societal well-being. All source codes and datasets are\npublicly accessible at https://github.com/Dasol-Choi/KoMultiText.", "published": "2023-10-06 15:19:39", "link": "http://arxiv.org/abs/2310.04313v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Stability in Simultaneous Speech Translation: A\n  Revision-Controllable Decoding Approach", "abstract": "Simultaneous Speech-to-Text translation serves a critical role in real-time\ncrosslingual communication. Despite the advancements in recent years,\nchallenges remain in achieving stability in the translation process, a concern\nprimarily manifested in the flickering of partial results. In this paper, we\npropose a novel revision-controllable method designed to address this issue.\nOur method introduces an allowed revision window within the beam search pruning\nprocess to screen out candidate translations likely to cause extensive\nrevisions, leading to a substantial reduction in flickering and, crucially,\nproviding the capability to completely eliminate flickering. The experiments\ndemonstrate the proposed method can significantly improve the decoding\nstability without compromising substantially on the translation quality.", "published": "2023-10-06 17:48:12", "link": "http://arxiv.org/abs/2310.04399v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RECOMP: Improving Retrieval-Augmented LMs with Compression and Selective\n  Augmentation", "abstract": "Retrieving documents and prepending them in-context at inference time\nimproves performance of language model (LMs) on a wide range of tasks. However,\nthese documents, often spanning hundreds of words, make inference substantially\nmore expensive. We propose compressing the retrieved documents into textual\nsummaries prior to in-context integration. This not only reduces the\ncomputational costs but also relieves the burden of LMs to identify relevant\ninformation in long retrieved documents. We present two compressors -- an\nextractive compressor which selects useful sentences from retrieved documents\nand an abstractive compressor which generates summaries by synthesizing\ninformation from multiple documents. Both compressors are trained to improve\nLMs' performance on end tasks when the generated summaries are prepended to the\nLMs' input, while keeping the summary concise.If the retrieved documents are\nirrelevant to the input or offer no additional information to LM, our\ncompressor can return an empty string, implementing selective augmentation.We\nevaluate our approach on language modeling task and open domain question\nanswering task. We achieve a compression rate of as low as 6% with minimal loss\nin performance for both tasks, significantly outperforming the off-the-shelf\nsummarization models. We show that our compressors trained for one LM can\ntransfer to other LMs on the language modeling task and provide summaries\nlargely faithful to the retrieved documents.", "published": "2023-10-06 17:55:36", "link": "http://arxiv.org/abs/2310.04408v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Envisioning Narrative Intelligence: A Creative Visual Storytelling\n  Anthology", "abstract": "In this paper, we collect an anthology of 100 visual stories from authors who\nparticipated in our systematic creative process of improvised story-building\nbased on image sequences. Following close reading and thematic analysis of our\nanthology, we present five themes that characterize the variations found in\nthis creative visual storytelling process: (1) Narrating What is in Vision vs.\nEnvisioning; (2) Dynamically Characterizing Entities/Objects; (3) Sensing\nExperiential Information About the Scenery; (4) Modulating the Mood; (5)\nEncoding Narrative Biases. In understanding the varied ways that people derive\nstories from images, we offer considerations for collecting story-driven\ntraining data to inform automatic story generation. In correspondence with each\ntheme, we envision narrative intelligence criteria for computational visual\nstorytelling as: creative, reliable, expressive, grounded, and responsible.\nFrom these criteria, we discuss how to foreground creative expression, account\nfor biases, and operate in the bounds of visual storyworlds.", "published": "2023-10-06 18:47:20", "link": "http://arxiv.org/abs/2310.04529v1", "categories": ["cs.CL", "J.5"], "primary_category": "cs.CL"}
{"title": "Measuring Information in Text Explanations", "abstract": "Text-based explanation is a particularly promising approach in explainable\nAI, but the evaluation of text explanations is method-dependent. We argue that\nplacing the explanations on an information-theoretic framework could unify the\nevaluations of two popular text explanation methods: rationale and natural\nlanguage explanations (NLE). This framework considers the post-hoc text\npipeline as a series of communication channels, which we refer to as\n``explanation channels''. We quantify the information flow through these\nchannels, thereby facilitating the assessment of explanation characteristics.\nWe set up tools for quantifying two information scores: relevance and\ninformativeness. We illustrate what our proposed information scores measure by\ncomparing them against some traditional evaluation metrics. Our\ninformation-theoretic scores reveal some unique observations about the\nunderlying mechanisms of two representative text explanations. For example, the\nNLEs trade-off slightly between transmitting the input-related information and\nthe target-related information, whereas the rationales do not exhibit such a\ntrade-off mechanism. Our work contributes to the ongoing efforts in\nestablishing rigorous and standardized evaluation criteria in the rapidly\nevolving field of explainable AI.", "published": "2023-10-06 19:46:51", "link": "http://arxiv.org/abs/2310.04557v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Process for Topic Modelling Via Word Embeddings", "abstract": "This work combines algorithms based on word embeddings, dimensionality\nreduction, and clustering. The objective is to obtain topics from a set of\nunclassified texts. The algorithm to obtain the word embeddings is the BERT\nmodel, a neural network architecture widely used in NLP tasks. Due to the high\ndimensionality, a dimensionality reduction technique called UMAP is used. This\nmethod manages to reduce the dimensions while preserving part of the local and\nglobal information of the original data. K-Means is used as the clustering\nalgorithm to obtain the topics. Then, the topics are evaluated using the TF-IDF\nstatistics, Topic Diversity, and Topic Coherence to get the meaning of the\nwords on the clusters. The results of the process show good values, so the\ntopic modeling of this process is a viable option for classifying or clustering\ntexts without labels.", "published": "2023-10-06 15:10:35", "link": "http://arxiv.org/abs/2312.03705v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chain of Natural Language Inference for Reducing Large Language Model\n  Ungrounded Hallucinations", "abstract": "Large language models (LLMs) can generate fluent natural language texts when\ngiven relevant documents as background context. This ability has attracted\nconsiderable interest in developing industry applications of LLMs. However,\nLLMs are prone to generate hallucinations that are not supported by the\nprovided sources. In this paper, we propose a hierarchical framework to detect\nand mitigate such ungrounded hallucination. Our framework uses Chain of Natural\nLanguage Inference (CoNLI) for hallucination detection and hallucination\nreduction via post-editing. Our approach achieves state-of-the-art performance\non hallucination detection and enhances text quality through rewrite, using\nLLMs without any fine-tuning or domain-specific prompt engineering. We show\nthat this simple plug-and-play framework can serve as an effective choice for\nhallucination detection and reduction, achieving competitive performance across\nvarious contexts.", "published": "2023-10-06 00:10:46", "link": "http://arxiv.org/abs/2310.03951v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Thought Propagation: An Analogical Approach to Complex Reasoning with\n  Large Language Models", "abstract": "Large Language Models (LLMs) have achieved remarkable success in reasoning\ntasks with the development of prompting methods. However, existing prompting\napproaches cannot reuse insights of solving similar problems and suffer from\naccumulated errors in multi-step reasoning, since they prompt LLMs to reason\n\\textit{from scratch}. To address these issues, we propose\n\\textbf{\\textit{Thought Propagation} (TP)}, which explores the analogous\nproblems and leverages their solutions to enhance the complex reasoning ability\nof LLMs. These analogous problems are related to the input one, with reusable\nsolutions and problem-solving strategies. Thus, it is promising to propagate\ninsights of solving previous analogous problems to inspire new problem-solving.\nTo achieve this, TP first prompts LLMs to propose and solve a set of analogous\nproblems that are related to the input one. Then, TP reuses the results of\nanalogous problems to directly yield a new solution or derive a\nknowledge-intensive plan for execution to amend the initial solution obtained\nfrom scratch. TP is compatible with existing prompting approaches, allowing\nplug-and-play generalization and enhancement in a wide range of tasks without\nmuch labor in task-specific prompt engineering. Experiments across three\nchallenging tasks demonstrate TP enjoys a substantial improvement over the\nbaselines by an average of 12\\% absolute increase in finding the optimal\nsolutions in Shortest-path Reasoning, 13\\% improvement of human preference in\nCreative Writing, and 15\\% enhancement in the task completion rate of LLM-Agent\nPlanning.", "published": "2023-10-06 01:40:09", "link": "http://arxiv.org/abs/2310.03965v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Quantized Transformer Language Model Implementations on Edge Devices", "abstract": "Large-scale transformer-based models like the Bidirectional Encoder\nRepresentations from Transformers (BERT) are widely used for Natural Language\nProcessing (NLP) applications, wherein these models are initially pre-trained\nwith a large corpus with millions of parameters and then fine-tuned for a\ndownstream NLP task. One of the major limitations of these large-scale models\nis that they cannot be deployed on resource-constrained devices due to their\nlarge model size and increased inference latency. In order to overcome these\nlimitations, such large-scale models can be converted to an optimized\nFlatBuffer format, tailored for deployment on resource-constrained edge\ndevices. Herein, we evaluate the performance of such FlatBuffer transformed\nMobileBERT models on three different edge devices, fine-tuned for Reputation\nanalysis of English language tweets in the RepLab 2013 dataset. In addition,\nthis study encompassed an evaluation of the deployed models, wherein their\nlatency, performance, and resource efficiency were meticulously assessed. Our\nexperiment results show that, compared to the original BERT large model, the\nconverted and quantized MobileBERT models have 160$\\times$ smaller footprints\nfor a 4.1% drop in accuracy while analyzing at least one tweet per second on\nedge devices. Furthermore, our study highlights the privacy-preserving aspect\nof TinyML systems as all data is processed locally within a serverless\nenvironment.", "published": "2023-10-06 01:59:19", "link": "http://arxiv.org/abs/2310.03971v1", "categories": ["cs.CL", "cs.AR"], "primary_category": "cs.CL"}
{"title": "HuBERTopic: Enhancing Semantic Representation of HuBERT through\n  Self-supervision Utilizing Topic Model", "abstract": "Recently, the usefulness of self-supervised representation learning (SSRL)\nmethods has been confirmed in various downstream tasks. Many of these models,\nas exemplified by HuBERT and WavLM, use pseudo-labels generated from spectral\nfeatures or the model's own representation features. From previous studies, it\nis known that the pseudo-labels contain semantic information. However, the\nmasked prediction task, the learning criterion of HuBERT, focuses on local\ncontextual information and may not make effective use of global semantic\ninformation such as speaker, theme of speech, and so on. In this paper, we\npropose a new approach to enrich the semantic representation of HuBERT. We\napply topic model to pseudo-labels to generate a topic label for each\nutterance. An auxiliary topic classification task is added to HuBERT by using\ntopic labels as teachers. This allows additional global semantic information to\nbe incorporated in an unsupervised manner. Experimental results demonstrate\nthat our method achieves comparable or better performance than the baseline in\nmost tasks, including automatic speech recognition and five out of the eight\nSUPERB tasks. Moreover, we find that topic labels include various information\nabout utterance, such as gender, speaker, and its theme. This highlights the\neffectiveness of our approach in capturing multifaceted semantic nuances.", "published": "2023-10-06 02:19:09", "link": "http://arxiv.org/abs/2310.03975v1", "categories": ["cs.SD", "cs.CL"], "primary_category": "cs.SD"}
{"title": "A Comprehensive Evaluation of Large Language Models on Benchmark\n  Biomedical Text Processing Tasks", "abstract": "Recently, Large Language Models (LLM) have demonstrated impressive capability\nto solve a wide range of tasks. However, despite their success across various\ntasks, no prior work has investigated their capability in the biomedical domain\nyet. To this end, this paper aims to evaluate the performance of LLMs on\nbenchmark biomedical tasks. For this purpose, we conduct a comprehensive\nevaluation of 4 popular LLMs in 6 diverse biomedical tasks across 26 datasets.\nTo the best of our knowledge, this is the first work that conducts an extensive\nevaluation and comparison of various LLMs in the biomedical domain.\nInterestingly, we find based on our evaluation that in biomedical datasets that\nhave smaller training sets, zero-shot LLMs even outperform the current\nstate-of-the-art fine-tuned biomedical models. This suggests that pretraining\non large text corpora makes LLMs quite specialized even in the biomedical\ndomain. We also find that not a single LLM can outperform other LLMs in all\ntasks, with the performance of different LLMs may vary depending on the task.\nWhile their performance is still quite poor in comparison to the biomedical\nmodels that were fine-tuned on large training sets, our findings demonstrate\nthat LLMs have the potential to be a valuable tool for various biomedical tasks\nthat lack large annotated data.", "published": "2023-10-06 14:16:28", "link": "http://arxiv.org/abs/2310.04270v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Amortizing intractable inference in large language models", "abstract": "Autoregressive large language models (LLMs) compress knowledge from their\ntraining data through next-token conditional distributions. This limits\ntractable querying of this knowledge to start-to-end autoregressive sampling.\nHowever, many tasks of interest -- including sequence continuation, infilling,\nand other forms of constrained generation -- involve sampling from intractable\nposterior distributions. We address this limitation by using amortized Bayesian\ninference to sample from these intractable posteriors. Such amortization is\nalgorithmically achieved by fine-tuning LLMs via diversity-seeking\nreinforcement learning algorithms: generative flow networks (GFlowNets). We\nempirically demonstrate that this distribution-matching paradigm of LLM\nfine-tuning can serve as an effective alternative to maximum-likelihood\ntraining and reward-maximizing policy optimization. As an important\napplication, we interpret chain-of-thought reasoning as a latent variable\nmodeling problem and demonstrate that our approach enables data-efficient\nadaptation of LLMs to tasks that require multi-step rationalization and tool\nuse.", "published": "2023-10-06 16:36:08", "link": "http://arxiv.org/abs/2310.04363v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Effective Slogan Generation with Noise Perturbation", "abstract": "Slogans play a crucial role in building the brand's identity of the firm. A\nslogan is expected to reflect firm's vision and brand's value propositions in\nmemorable and likeable ways. Automating the generation of slogans with such\ncharacteristics is challenging. Previous studies developted and tested slogan\ngeneration with syntactic control and summarization models which are not\ncapable of generating distinctive slogans. We introduce a a novel apporach that\nleverages pre-trained transformer T5 model with noise perturbation on newly\nproposed 1:N matching pair dataset. This approach serves as a contributing\nfator in generting distinctive and coherent slogans. Turthermore, the proposed\napproach incorporates descriptions about the firm and brand into the generation\nof slogans. We evaluate generated slogans based on ROUGE1, ROUGEL and Cosine\nSimilarity metrics and also assess them with human subjects in terms of\nslogan's distinctiveness, coherence, and fluency. The results demonstrate that\nour approach yields better performance than baseline models and other\ntransformer-based models.", "published": "2023-10-06 04:48:48", "link": "http://arxiv.org/abs/2310.04472v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Auto-survey Challenge", "abstract": "We present a novel platform for evaluating the capability of Large Language\nModels (LLMs) to autonomously compose and critique survey papers spanning a\nvast array of disciplines including sciences, humanities, education, and law.\nWithin this framework, AI systems undertake a simulated peer-review mechanism\nakin to traditional scholarly journals, with human organizers serving in an\neditorial oversight capacity. Within this framework, we organized a competition\nfor the AutoML conference 2023. Entrants are tasked with presenting stand-alone\nmodels adept at authoring articles from designated prompts and subsequently\nappraising them. Assessment criteria include clarity, reference\nappropriateness, accountability, and the substantive value of the content. This\npaper presents the design of the competition, including the implementation\nbaseline submissions and methods of evaluation.", "published": "2023-10-06 09:12:35", "link": "http://arxiv.org/abs/2310.04480v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Ada-Instruct: Adapting Instruction Generators for Complex Reasoning", "abstract": "Instructions augmentation is a crucial step for unleashing the full potential\nof large language models (LLMs) in downstream tasks. Existing Self-Instruct\nmethods primarily simulate new instructions from a few initial instructions\nwith in-context learning. However, our study identifies a critical flaw in this\napproach: even with GPT4o, Self-Instruct cannot generate complex instructions\nof length $\\ge 100$, which is necessary in complex tasks such as code\ncompletion.\n  To address this issue, our key insight is that fine-tuning open source LLMs\nwith only ten examples can produce complex instructions that maintain\ndistributional consistency for complex reasoning tasks. We introduce\nAda-Instruct, an adaptive instruction generator developed through fine-tuning.\nWe empirically validated Ada-Instruct's efficacy across different applications.\nThe results highlight Ada-Instruct's capacity to generate long, intricate, and\ndistributionally consistent instructions.", "published": "2023-10-06 13:28:04", "link": "http://arxiv.org/abs/2310.04484v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Foundation Models for Knowledge Graph Reasoning", "abstract": "Foundation models in language and vision have the ability to run inference on\nany textual and visual inputs thanks to the transferable representations such\nas a vocabulary of tokens in language. Knowledge graphs (KGs) have different\nentity and relation vocabularies that generally do not overlap. The key\nchallenge of designing foundation models on KGs is to learn such transferable\nrepresentations that enable inference on any graph with arbitrary entity and\nrelation vocabularies. In this work, we make a step towards such foundation\nmodels and present ULTRA, an approach for learning universal and transferable\ngraph representations. ULTRA builds relational representations as a function\nconditioned on their interactions. Such a conditioning strategy allows a\npre-trained ULTRA model to inductively generalize to any unseen KG with any\nrelation vocabulary and to be fine-tuned on any graph. Conducting link\nprediction experiments on 57 different KGs, we find that the zero-shot\ninductive inference performance of a single pre-trained ULTRA model on unseen\ngraphs of various sizes is often on par or better than strong baselines trained\non specific graphs. Fine-tuning further boosts the performance.", "published": "2023-10-06 20:00:07", "link": "http://arxiv.org/abs/2310.04562v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "From Nuisance to News Sense: Augmenting the News with Cross-Document\n  Evidence and Context", "abstract": "Reading and understanding the stories in the news is increasingly difficult.\nReporting on stories evolves rapidly, politicized news venues offer different\nperspectives (and sometimes different facts), and misinformation is rampant.\nHowever, existing solutions merely aggregate an overwhelming amount of\ninformation from heterogenous sources, such as different news outlets, social\nmedia, and news bias rating agencies. We present NEWSSENSE, a novel sensemaking\ntool and reading interface designed to collect and integrate information from\nmultiple news articles on a central topic, using a form of reference-free fact\nverification. NEWSSENSE augments a central, grounding article of the user's\nchoice by linking it to related articles from different sources, providing\ninline highlights on how specific claims in the chosen article are either\nsupported or contradicted by information from other articles. Using NEWSSENSE,\nusers can seamlessly digest and cross-check multiple information sources\nwithout disturbing their natural reading flow. Our pilot study shows that\nNEWSSENSE has the potential to help users identify key information, verify the\ncredibility of news articles, and explore different perspectives.", "published": "2023-10-06 21:15:11", "link": "http://arxiv.org/abs/2310.04592v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Segmented Harmonic Loss: Handling Class-Imbalanced Multi-Label Clinical\n  Data for Medical Coding with Large Language Models", "abstract": "The precipitous rise and adoption of Large Language Models (LLMs) have\nshattered expectations with the fastest adoption rate of any consumer-facing\ntechnology in history. Healthcare, a field that traditionally uses NLP\ntechniques, was bound to be affected by this meteoric rise. In this paper, we\ngauge the extent of the impact by evaluating the performance of LLMs for the\ntask of medical coding on real-life noisy data. We conducted several\nexperiments on MIMIC III and IV datasets with encoder-based LLMs, such as BERT.\nFurthermore, we developed Segmented Harmonic Loss, a new loss function to\naddress the extreme class imbalance that we found to prevail in most medical\ndata in a multi-label scenario by segmenting and decoupling co-occurring\nclasses of the dataset with a new segmentation algorithm. We also devised a\ntechnique based on embedding similarity to tackle noisy data. Our experimental\nresults show that when trained with the proposed loss, the LLMs achieve\nsignificant performance gains even on noisy long-tailed datasets, outperforming\nthe F1 score of the state-of-the-art by over ten percentage points.", "published": "2023-10-06 21:20:28", "link": "http://arxiv.org/abs/2310.04595v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "In nomine patris... Elements for a semantics of medieval paternity", "abstract": "This article examines medieval concepts of paternity and father-son\nrelationships through the digital analysis of medieval textual corpora.\nAlthough historians have access to enormous digital collections in 2023, they\nhave rarely fully exploited these resources. The author proposes a historical\nsemantic approach to this theme, using modeling tools and text mining in\ngeneral, to analyze the evolution of terms related to paternity. The study\nproposes three conclusions: 1. a semantic break occurred in the semantic field\nof paternity at the turn of Antiquity and the Early Middle Ages. The meaning of\npater and its derivatives changed radically over the course of the 4th-6th\ncenturies, particularly as a result of the influence of the dogma of the\nChristian Trinity. Medieval fatherhood was multidimensional, encompassing both\nbiological and spiritual aspects, in other words, complex relationships between\nmultiple carnal and spiritual (i.e. divine) fathers. 2. The role of spiritual\nkinship is crucial to understanding medieval fatherhood, as the work of Anita\nGuerreau-Jalabert and J{\\'e}r{\\^o}me Baschet has already shown. Initially\nattributed to God, this ''ideal paternity'' (paternitas) gradually extended to\nmembers of the Church (popes, bishops, abbots), underlining at the same time\nthe growing importance of spiritual kinship over biological kinship over the\ncenturies studied. 3. To reveal these structures, invisible to the naked eye,\nan interdisciplinary approach is rigorously required. Complementary\ninvestigations into the lemmas mater, filia, frater and other family terms are\nrequired. The use of digital tools and historical semantic analysis opens up\nnew perspectives for researchers in history, anthropology, linguistics and data\nmining, enabling them to explore the representation systems of ancient\nsocieties in depth and with nuance.", "published": "2023-10-06 09:10:58", "link": "http://arxiv.org/abs/2311.04907v1", "categories": ["cs.DL", "cs.CL"], "primary_category": "cs.DL"}
{"title": "From Text to Self: Users' Perceptions of Potential of AI on\n  Interpersonal Communication and Self", "abstract": "In the rapidly evolving landscape of AI-mediated communication (AIMC), tools\npowered by Large Language Models (LLMs) are becoming integral to interpersonal\ncommunication. Employing a mixed-methods approach, we conducted a one-week\ndiary and interview study to explore users' perceptions of these tools' ability\nto: 1) support interpersonal communication in the short-term, and 2) lead to\npotential long-term effects. Our findings indicate that participants view AIMC\nsupport favorably, citing benefits such as increased communication confidence,\nand finding precise language to express their thoughts, navigating linguistic\nand cultural barriers. However, the study also uncovers current limitations of\nAIMC tools, including verbosity, unnatural responses, and excessive emotional\nintensity. These shortcomings are further exacerbated by user concerns about\ninauthenticity and potential overreliance on the technology. Furthermore, we\nidentified four key communication spaces delineated by communication stakes\n(high or low) and relationship dynamics (formal or informal) that\ndifferentially predict users' attitudes toward AIMC tools. Specifically,\nparticipants found the tool is more suitable for communicating in formal\nrelationships than informal ones and more beneficial in high-stakes than\nlow-stakes communication.", "published": "2023-10-06 02:19:10", "link": "http://arxiv.org/abs/2310.03976v3", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Dementia Assessment Using Mandarin Speech with an Attention-based Speech\n  Recognition Encoder", "abstract": "Dementia diagnosis requires a series of different testing methods, which is\ncomplex and time-consuming. Early detection of dementia is crucial as it can\nprevent further deterioration of the condition. This paper utilizes a speech\nrecognition model to construct a dementia assessment system tailored for\nMandarin speakers during the picture description task. By training an\nattention-based speech recognition model on voice data closely resembling\nreal-world scenarios, we have significantly enhanced the model's recognition\ncapabilities. Subsequently, we extracted the encoder from the speech\nrecognition model and added a linear layer for dementia assessment. We\ncollected Mandarin speech data from 99 subjects and acquired their clinical\nassessments from a local hospital. We achieved an accuracy of 92.04% in\nAlzheimer's disease detection and a mean absolute error of 9% in clinical\ndementia rating score prediction.", "published": "2023-10-06 03:04:11", "link": "http://arxiv.org/abs/2310.03985v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Enhancing Financial Sentiment Analysis via Retrieval Augmented Large\n  Language Models", "abstract": "Financial sentiment analysis is critical for valuation and investment\ndecision-making. Traditional NLP models, however, are limited by their\nparameter size and the scope of their training datasets, which hampers their\ngeneralization capabilities and effectiveness in this field. Recently, Large\nLanguage Models (LLMs) pre-trained on extensive corpora have demonstrated\nsuperior performance across various NLP tasks due to their commendable\nzero-shot abilities. Yet, directly applying LLMs to financial sentiment\nanalysis presents challenges: The discrepancy between the pre-training\nobjective of LLMs and predicting the sentiment label can compromise their\npredictive performance. Furthermore, the succinct nature of financial news,\noften devoid of sufficient context, can significantly diminish the reliability\nof LLMs' sentiment analysis. To address these challenges, we introduce a\nretrieval-augmented LLMs framework for financial sentiment analysis. This\nframework includes an instruction-tuned LLMs module, which ensures LLMs behave\nas predictors of sentiment labels, and a retrieval-augmentation module which\nretrieves additional context from reliable external sources. Benchmarked\nagainst traditional models and LLMs like ChatGPT and LLaMA, our approach\nachieves 15\\% to 48\\% performance gain in accuracy and F1 score.", "published": "2023-10-06 05:40:23", "link": "http://arxiv.org/abs/2310.04027v2", "categories": ["cs.CL", "q-fin.ST", "q-fin.TR"], "primary_category": "cs.CL"}
{"title": "Automatic Aspect Extraction from Scientific Texts", "abstract": "Being able to extract from scientific papers their main points, key insights,\nand other important information, referred to here as aspects, might facilitate\nthe process of conducting a scientific literature review. Therefore, the aim of\nour research is to create a tool for automatic aspect extraction from\nRussian-language scientific texts of any domain. In this paper, we present a\ncross-domain dataset of scientific texts in Russian, annotated with such\naspects as Task, Contribution, Method, and Conclusion, as well as a baseline\nalgorithm for aspect extraction, based on the multilingual BERT model\nfine-tuned on our data. We show that there are some differences in aspect\nrepresentation in different domains, but even though our model was trained on a\nlimited number of scientific domains, it is still able to generalize to new\ndomains, as was proved by cross-domain experiments. The code and the dataset\nare available at\n\\url{https://github.com/anna-marshalova/automatic-aspect-extraction-from-scientific-texts}.", "published": "2023-10-06 07:59:54", "link": "http://arxiv.org/abs/2310.04074v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "mlirSynth: Automatic, Retargetable Program Raising in Multi-Level IR\n  using Program Synthesis", "abstract": "MLIR is an emerging compiler infrastructure for modern hardware, but existing\nprograms cannot take advantage of MLIR's high-performance compilation if they\nare described in lower-level general purpose languages. Consequently, to avoid\nprograms needing to be rewritten manually, this has led to efforts to\nautomatically raise lower-level to higher-level dialects in MLIR. However,\ncurrent methods rely on manually-defined raising rules, which limit their\napplicability and make them challenging to maintain as MLIR dialects evolve.\n  We present mlirSynth -- a novel approach which translates programs from\nlower-level MLIR dialects to high-level ones without manually defined rules.\nInstead, it uses available dialect definitions to construct a program space and\nsearches it effectively using type constraints and equivalences. We demonstrate\nits effectiveness \\revi{by raising C programs} to two distinct high-level MLIR\ndialects, which enables us to use existing high-level dialect specific\ncompilation flows. On Polybench, we show a greater coverage than previous\napproaches, resulting in geomean speedups of 2.5x (Intel) and 3.4x (AMD) over\nstate-of-the-art compilation flows for the C programming language. mlirSynth\nalso enables retargetability to domain-specific accelerators, resulting in a\ngeomean speedup of 21.6x on a TPU.", "published": "2023-10-06 12:21:50", "link": "http://arxiv.org/abs/2310.04196v1", "categories": ["cs.PL", "cs.CL", "cs.DC", "cs.PF"], "primary_category": "cs.PL"}
{"title": "Keyword Augmented Retrieval: Novel framework for Information Retrieval\n  integrated with speech interface", "abstract": "Retrieving answers in a quick and low cost manner without hallucinations from\na combination of structured and unstructured data using Language models is a\nmajor hurdle. This is what prevents employment of Language models in knowledge\nretrieval automation. This becomes accentuated when one wants to integrate a\nspeech interface on top of a text based knowledge retrieval system. Besides,\nfor commercial search and chat-bot applications, complete reliance on\ncommercial large language models (LLMs) like GPT 3.5 etc. can be very costly.\nIn the present study, the authors have addressed the aforementioned problem by\nfirst developing a keyword based search framework which augments discovery of\nthe context from the document to be provided to the LLM. The keywords in turn\nare generated by a relatively smaller LLM and cached for comparison with\nkeywords generated by the same smaller LLM against the query raised. This\nsignificantly reduces time and cost to find the context within documents. Once\nthe context is set, a larger LLM uses that to provide answers based on a prompt\ntailored for Q\\&A. This research work demonstrates that use of keywords in\ncontext identification reduces the overall inference time and cost of\ninformation retrieval. Given this reduction in inference time and cost with the\nkeyword augmented retrieval framework, a speech based interface for user input\nand response readout was integrated. This allowed a seamless interaction with\nthe language model.", "published": "2023-10-06 12:44:04", "link": "http://arxiv.org/abs/2310.04205v2", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.IR"}
{"title": "Transferring speech-generic and depression-specific knowledge for\n  Alzheimer's disease detection", "abstract": "The detection of Alzheimer's disease (AD) from spontaneous speech has\nattracted increasing attention while the sparsity of training data remains an\nimportant issue. This paper handles the issue by knowledge transfer,\nspecifically from both speech-generic and depression-specific knowledge. The\npaper first studies sequential knowledge transfer from generic foundation\nmodels pretrained on large amounts of speech and text data. A block-wise\nanalysis is performed for AD diagnosis based on the representations extracted\nfrom different intermediate blocks of different foundation models. Apart from\nthe knowledge from speech-generic representations, this paper also proposes to\nsimultaneously transfer the knowledge from a speech depression detection task\nbased on the high comorbidity rates of depression and AD. A parallel knowledge\ntransfer framework is studied that jointly learns the information shared\nbetween these two tasks. Experimental results show that the proposed method\nimproves AD and depression detection, and produces a state-of-the-art F1 score\nof 0.928 for AD diagnosis on the commonly used ADReSSo dataset.", "published": "2023-10-06 16:28:07", "link": "http://arxiv.org/abs/2310.04358v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Hermes: Unlocking Security Analysis of Cellular Network Protocols by\n  Synthesizing Finite State Machines from Natural Language Specifications", "abstract": "In this paper, we present Hermes, an end-to-end framework to automatically\ngenerate formal representations from natural language cellular specifications.\nWe first develop a neural constituency parser, NEUTREX, to process\ntransition-relevant texts and extract transition components (i.e., states,\nconditions, and actions). We also design a domain-specific language to\ntranslate these transition components to logical formulas by leveraging\ndependency parse trees. Finally, we compile these logical formulas to generate\ntransitions and create the formal model as finite state machines. To\ndemonstrate the effectiveness of Hermes, we evaluate it on 4G NAS, 5G NAS, and\n5G RRC specifications and obtain an overall accuracy of 81-87%, which is a\nsubstantial improvement over the state-of-the-art. Our security analysis of the\nextracted models uncovers 3 new vulnerabilities and identifies 19 previous\nattacks in 4G and 5G specifications, and 7 deviations in commercial 4G\nbasebands.", "published": "2023-10-06 17:19:40", "link": "http://arxiv.org/abs/2310.04381v2", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Language Agent Tree Search Unifies Reasoning Acting and Planning in\n  Language Models", "abstract": "While language models (LMs) have shown potential across a range of\ndecision-making tasks, their reliance on simple acting processes limits their\nbroad deployment as autonomous agents. In this paper, we introduce Language\nAgent Tree Search (LATS) -- the first general framework that synergizes the\ncapabilities of LMs in reasoning, acting, and planning. By leveraging the\nin-context learning ability of LMs, we integrate Monte Carlo Tree Search into\nLATS to enable LMs as agents, along with LM-powered value functions and\nself-reflections for proficient exploration and enhanced decision-making. A key\nfeature of our approach is the incorporation of an environment for external\nfeedback, which offers a more deliberate and adaptive problem-solving mechanism\nthat surpasses the constraints of existing techniques. Our experimental\nevaluation across diverse domains, including programming, interactive\nquestion-answering (QA), web navigation, and math, validates the effectiveness\nand generality of LATS in decision-making while maintaining competitive or\nimproved reasoning performance. Notably, LATS achieves state-of-the-art pass@1\naccuracy (92.7%) for programming on HumanEval with GPT-4 and demonstrates\ngradient-free performance (average score of 75.9) comparable to gradient-based\nfine-tuning for web navigation on WebShop with GPT-3.5. Code can be found at\nhttps://github.com/lapisrocks/LanguageAgentTreeSearch", "published": "2023-10-06 17:55:11", "link": "http://arxiv.org/abs/2310.04406v3", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Policy-Gradient Training of Language Models for Ranking", "abstract": "Text retrieval plays a crucial role in incorporating factual knowledge for\ndecision making into language processing pipelines, ranging from chat-based web\nsearch to question answering systems. Current state-of-the-art text retrieval\nmodels leverage pre-trained large language models (LLMs) to achieve competitive\nperformance, but training LLM-based retrievers via typical contrastive losses\nrequires intricate heuristics, including selecting hard negatives and using\nadditional supervision as learning signals. This reliance on heuristics stems\nfrom the fact that the contrastive loss itself is heuristic and does not\ndirectly optimize the downstream metrics of decision quality at the end of the\nprocessing pipeline. To address this issue, we introduce Neural PG-RANK, a\nnovel training algorithm that learns to rank by instantiating a LLM as a\nPlackett-Luce ranking policy. Neural PG-RANK provides a principled method for\nend-to-end training of retrieval models as part of larger decision systems via\npolicy gradient, with little reliance on complex heuristics, and it effectively\nunifies the training objective with downstream decision-making quality. We\nconduct extensive experiments on various text retrieval benchmarks. The results\ndemonstrate that when the training objective aligns with the evaluation setup,\nNeural PG-RANK yields remarkable in-domain performance improvement, with\nsubstantial out-of-domain generalization to some critical datasets employed in\ndownstream question answering tasks.", "published": "2023-10-06 17:55:23", "link": "http://arxiv.org/abs/2310.04407v2", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Demystifying Embedding Spaces using Large Language Models", "abstract": "Embeddings have become a pivotal means to represent complex, multi-faceted\ninformation about entities, concepts, and relationships in a condensed and\nuseful format. Nevertheless, they often preclude direct interpretation. While\ndownstream tasks make use of these compressed representations, meaningful\ninterpretation usually requires visualization using dimensionality reduction or\nspecialized machine learning interpretability methods. This paper addresses the\nchallenge of making such embeddings more interpretable and broadly useful, by\nemploying Large Language Models (LLMs) to directly interact with embeddings --\ntransforming abstract vectors into understandable narratives. By injecting\nembeddings into LLMs, we enable querying and exploration of complex embedding\ndata. We demonstrate our approach on a variety of diverse tasks, including:\nenhancing concept activation vectors (CAVs), communicating novel embedded\nentities, and decoding user preferences in recommender systems. Our work\ncouples the immense information potential of embeddings with the interpretative\npower of LLMs.", "published": "2023-10-06 05:27:28", "link": "http://arxiv.org/abs/2310.04475v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Acoustic and linguistic representations for speech continuous emotion\n  recognition in call center conversations", "abstract": "The goal of our research is to automatically retrieve the satisfaction and\nthe frustration in real-life call-center conversations. This study focuses an\nindustrial application in which the customer satisfaction is continuously\ntracked down to improve customer services. To compensate the lack of large\nannotated emotional databases, we explore the use of pre-trained speech\nrepresentations as a form of transfer learning towards AlloSat corpus.\nMoreover, several studies have pointed out that emotion can be detected not\nonly in speech but also in facial trait, in biological response or in textual\ninformation. In the context of telephone conversations, we can break down the\naudio information into acoustic and linguistic by using the speech signal and\nits transcription. Our experiments confirms the large gain in performance\nobtained with the use of pre-trained features. Surprisingly, we found that the\nlinguistic content is clearly the major contributor for the prediction of\nsatisfaction and best generalizes to unseen data. Our experiments conclude to\nthe definitive advantage of using CamemBERT representations, however the\nbenefit of the fusion of acoustic and linguistic modalities is not as obvious.\nWith models learnt on individual annotations, we found that fusion approaches\nare more robust to the subjectivity of the annotation task. This study also\ntackles the problem of performances variability and intends to estimate this\nvariability from different views: weights initialization, confidence intervals\nand annotation subjectivity. A deep analysis on the linguistic content\ninvestigates interpretable factors able to explain the high contribution of the\nlinguistic modality for this task.", "published": "2023-10-06 10:22:51", "link": "http://arxiv.org/abs/2310.04481v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "I.2.7"], "primary_category": "eess.AS"}
{"title": "Reward Dropout Improves Control: Bi-objective Perspective on Reinforced\n  LM", "abstract": "We study the theoretical aspects of Reinforced Language Models (RLMs) from a\nbi-objective optimization perspective. Specifically, we consider the RLMs as a\nPareto optimization problem that maximizes the two conflicting objectives,\ni.e., reward objective and likelihood objectives, simultaneously. Our main\ncontribution consists of three parts. First, we establish the theoretical\nfoundations of RLM as a Pareto optimization problem by presenting Reward Upper\nBOund (RUBO) and Pareto optimality. Our theoretical outcomes are supported by\nnot only deductive proofs but also empirical results. Second, we propose Reward\nDropout, a simple yet powerful method that guarantees to improve a bi-objective\noptimization of RLM. Lastly, we demonstrate that the Reward Dropout is\nconsistently effective across five benchmark datasets and four benchmark LLMs,\nmeaning that the Reward Dropout significantly improves the optimization\nperformance of RLMs.", "published": "2023-10-06 12:33:32", "link": "http://arxiv.org/abs/2310.04483v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Module-wise Adaptive Distillation for Multimodality Foundation Models", "abstract": "Pre-trained multimodal foundation models have demonstrated remarkable\ngeneralizability but pose challenges for deployment due to their large sizes.\nOne effective approach to reducing their sizes is layerwise distillation,\nwherein small student models are trained to match the hidden representations of\nlarge teacher models at each layer. Motivated by our observation that certain\narchitecture components, referred to as modules, contribute more significantly\nto the student's performance than others, we propose to track the contributions\nof individual modules by recording the loss decrement after distillation each\nmodule and choose the module with a greater contribution to distill more\nfrequently. Such an approach can be naturally formulated as a multi-armed\nbandit (MAB) problem, where modules and loss decrements are considered as arms\nand rewards, respectively. We then develop a modified-Thompson sampling\nalgorithm named OPTIMA to address the nonstationarity of module contributions\nresulting from model updating. Specifically, we leverage the observed\ncontributions in recent history to estimate the changing contribution of each\nmodule and select modules based on these estimations to maximize the cumulative\ncontribution. We evaluate the effectiveness of OPTIMA through distillation\nexperiments on various multimodal understanding and image captioning tasks,\nusing the CoCa-Large model (Yu et al., 2022) as the teacher model.", "published": "2023-10-06 19:24:00", "link": "http://arxiv.org/abs/2310.04550v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Can pruning make Large Language Models more efficient?", "abstract": "Transformer models have revolutionized natural language processing with their\nunparalleled ability to grasp complex contextual relationships. However, the\nvast number of parameters in these models has raised concerns regarding\ncomputational efficiency, environmental impact, and deployability on\nresource-limited platforms. To address these challenges, this paper\ninvestigates the application of weight pruning-a strategic reduction of model\nparameters based on their significance-as an optimization strategy for\nTransformer architectures. Through extensive experimentation, we explore\nvarious pruning methodologies, highlighting their impact on model performance,\nsize, and computational demands. Our findings suggest that with judicious\nselection of pruning hyperparameters, significant reductions in model size are\nattainable without considerable compromise on performance. Moreover, when\ncoupled with post-pruning fine-tuning strategies, some pruned models even\nexhibit enhanced generalization capabilities. This work seeks to bridge the gap\nbetween model efficiency and performance, paving the way for more scalable and\nenvironmentally responsible deep learning applications.", "published": "2023-10-06 20:28:32", "link": "http://arxiv.org/abs/2310.04573v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Copy Suppression: Comprehensively Understanding an Attention Head", "abstract": "We present a single attention head in GPT-2 Small that has one main role\nacross the entire training distribution. If components in earlier layers\npredict a certain token, and this token appears earlier in the context, the\nhead suppresses it: we call this copy suppression. Attention Head 10.7 (L10H7)\nsuppresses naive copying behavior which improves overall model calibration.\nThis explains why multiple prior works studying certain narrow tasks found\nnegative heads that systematically favored the wrong answer. We uncover the\nmechanism that the Negative Heads use for copy suppression with weights-based\nevidence and are able to explain 76.9% of the impact of L10H7 in GPT-2 Small.\nTo the best of our knowledge, this is the most comprehensive description of the\ncomplete role of a component in a language model to date. One major effect of\ncopy suppression is its role in self-repair. Self-repair refers to how ablating\ncrucial model components results in downstream neural network parts\ncompensating for this ablation. Copy suppression leads to self-repair: if an\ninitial overconfident copier is ablated, then there is nothing to suppress. We\nshow that self-repair is implemented by several mechanisms, one of which is\ncopy suppression, which explains 39% of the behavior in a narrow task.\nInteractive visualisations of the copy suppression phenomena may be seen at our\nweb app https://copy-suppression.streamlit.app/", "published": "2023-10-06 23:37:24", "link": "http://arxiv.org/abs/2310.04625v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Document-Level Relation Extraction with Relation Correlation Enhancement", "abstract": "Document-level relation extraction (DocRE) is a task that focuses on\nidentifying relations between entities within a document. However, existing\nDocRE models often overlook the correlation between relations and lack a\nquantitative analysis of relation correlations. To address this limitation and\neffectively capture relation correlations in DocRE, we propose a relation graph\nmethod, which aims to explicitly exploit the interdependency among relations.\nFirstly, we construct a relation graph that models relation correlations using\nstatistical co-occurrence information derived from prior relation knowledge.\nSecondly, we employ a re-weighting scheme to create an effective relation\ncorrelation matrix to guide the propagation of relation information.\nFurthermore, we leverage graph attention networks to aggregate relation\nembeddings. Importantly, our method can be seamlessly integrated as a\nplug-and-play module into existing models. Experimental results demonstrate\nthat our approach can enhance the performance of multi-relation extraction,\nhighlighting the effectiveness of considering relation correlations in DocRE.", "published": "2023-10-06 10:59:00", "link": "http://arxiv.org/abs/2310.13000v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "How to Capture Higher-order Correlations? Generalizing Matrix Softmax\n  Attention to Kronecker Computation", "abstract": "In the classical transformer attention scheme, we are given three $n \\times\nd$ size matrices $Q, K, V$ (the query, key, and value tokens), and the goal is\nto compute a new $n \\times d$ size matrix $D^{-1} \\exp(QK^\\top) V$ where $D =\n\\mathrm{diag}( \\exp(QK^\\top) {\\bf 1}_n )$. In this work, we study a\ngeneralization of attention which captures triple-wise correlations. This\ngeneralization is able to solve problems about detecting triple-wise\nconnections that were shown to be impossible for transformers. The potential\ndownside of this generalization is that it appears as though computations are\neven more difficult, since the straightforward algorithm requires cubic time in\n$n$. However, we show that in the bounded-entry setting (which arises in\npractice, and which is well-studied in both theory and practice), there is\nactually a near-linear time algorithm. More precisely, we show that bounded\nentries are both necessary and sufficient for quickly performing generalized\ncomputations:\n  $\\bullet$ On the positive side, if all entries of the input matrices are\nbounded above by $o(\\sqrt[3]{\\log n})$ then we show how to approximate the\n``tensor-type'' attention matrix in $n^{1+o(1)}$ time.\n  $\\bullet$ On the negative side, we show that if the entries of the input\nmatrices may be as large as $\\Omega(\\sqrt[3]{\\log n})$, then there is no\nalgorithm that runs faster than $n^{3-o(1)}$ (assuming the Strong Exponential\nTime Hypothesis from fine-grained complexity theory).\n  We also show that our construction, algorithms, and lower bounds naturally\ngeneralize to higher-order tensors and correlations. Interestingly, the higher\nthe order of the tensors, the lower the bound on the entries needs to be for an\nefficient algorithm. Our results thus yield a natural tradeoff between the\nboundedness of the entries, and order of the tensor one may use for more\nexpressive, efficient attention computation.", "published": "2023-10-06 07:42:39", "link": "http://arxiv.org/abs/2310.04064v1", "categories": ["cs.DS", "cs.CC", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.DS"}
{"title": "Conversational Factor Information Retrieval Model (ConFIRM)", "abstract": "This paper introduces the Conversational Factor Information Retrieval Method\n(ConFIRM), a novel approach to fine-tuning large language models (LLMs) for\ndomain-specific retrieval tasks. ConFIRM leverages the Five-Factor Model of\npersonality to generate synthetic datasets that accurately reflect target\npopulation characteristics, addressing data scarcity in specialized domains. We\ndemonstrate ConFIRM's effectiveness through a case study in the finance sector,\nfine-tuning a Llama-2-7b model using personality-aligned data from the\nPolyU-Asklora Fintech Adoption Index. The resulting model achieved 91% accuracy\nin classifying financial queries, with an average inference time of 0.61\nseconds on an NVIDIA A100 GPU. ConFIRM shows promise for creating more accurate\nand personalized AI-driven information retrieval systems across various\ndomains, potentially mitigating issues of hallucinations and outdated\ninformation in LLMs deployed", "published": "2023-10-06 12:31:05", "link": "http://arxiv.org/abs/2310.13001v4", "categories": ["cs.IR", "cs.AI", "cs.CE", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "A privacy-preserving method using secret key for convolutional neural\n  network-based speech classification", "abstract": "In this paper, we propose a privacy-preserving method with a secret key for\nconvolutional neural network (CNN)-based speech classification tasks. Recently,\nmany methods related to privacy preservation have been developed in image\nclassification research fields. In contrast, in speech classification research\nfields, little research has considered these risks. To promote research on\nprivacy preservation for speech classification, we provide an encryption method\nwith a secret key in CNN-based speech classification systems. The encryption\nmethod is based on a random matrix with an invertible inverse. The encrypted\nspeech data with a correct key can be accepted by a model with an encrypted\nkernel generated using an inverse matrix of a random matrix. Whereas the\nencrypted speech data is strongly distorted, the classification tasks can be\ncorrectly performed when a correct key is provided. Additionally, in this\npaper, we evaluate the difficulty of reconstructing the original information\nfrom the encrypted spectrograms and waveforms. In our experiments, the proposed\nencryption methods are performed in automatic speech recognition~(ASR) and\nautomatic speaker verification~(ASV) tasks. The results show that the encrypted\ndata can be used completely the same as the original data when a correct secret\nkey is provided in the transformer-based ASR and x-vector-based ASV with\nself-supervised front-end systems. The robustness of the encrypted data against\nreconstruction attacks is also illustrated.", "published": "2023-10-06 06:14:35", "link": "http://arxiv.org/abs/2310.04035v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Spatial sampling and beamforming for spherical microphone arrays", "abstract": "Spherical microphone arrays have been recently studied for spatial sound\nrecording, speech communication, and sound field analysis for room acoustics\nand noise control. Complementary theoretical studies presented progress in\nspatial sampling and beamforming methods. This paper reviews recent results in\nspatial sampling that facilitate a wide range of spherical array\nconfigurations, from a single rigid sphere to free positioning of microphones.\nThe paper then presents an overview of beamforming methods recently presented\nfor spherical arrays, from the widely used delay-and-sum and Dolph-Chebyshev,\nto the more advanced optimal methods, typically performed in the spherical\nharmonics domain.", "published": "2023-10-06 11:38:01", "link": "http://arxiv.org/abs/2310.04169v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Zones of quiet in a broadband diffuse sound field", "abstract": "The zones of quiet in pure-tone diffuse sound fields have been studied\nextensively in the past, both theoretically and experimentally, with the well\nknown result of the 10\\,dB attenuation extending to about a tenth of a\nwavelength. Recent results on the spatial-temporal correlation of broadband\ndiffuse sound fields are used in this study to develop a theoretical framework\nfor predicting the extension of the zones of quiet in broadband diffuse sound\nfields. This can be used to study the acoustic limitations imposed on local\nactive sound control systems such as an active headrest when controlling\nbroadband noise. Spatial-temporal correlation is first revised, after which\nderivations of the diffuse field zones of quiet in the near-field and the\nfar-field of the secondary source are presented. The theoretical analysis is\nsupported by simulation examples comparing the zones of quiet for diffuse\nfields excited by tonal and broadband signals. It is shown that as a first\napproximation the zone of quiet of a low-pass filtered noise is comparable to\nthat of a pure-tone with a frequency equal to the center frequency of the\nbroadband noise bandwidth.", "published": "2023-10-06 12:11:36", "link": "http://arxiv.org/abs/2310.04191v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Optimal model-based beamforming and independent steering for spherical\n  loudspeaker arrays", "abstract": "Spherical loudspeaker arrays have been recently studied for directional sound\nradiation, where the compact arrangement of the loudspeaker units around a\nsphere facilitated the control of sound radiation in three-dimensional space.\nDirectivity of sound radiation, or beamforming, was achieved by driving each\nloudspeaker unit independently, where the design of beamforming weights was\ntypically achieved by numerical optimization with reference to a given desired\nbeam pattern. This is in contrast to the methods already developed for\nmicrophone arrays in general and spherical microphone arrays in particular,\nwhere beamformer weights are designed to satisfy a wider range of objectives,\nrelated to directivity, robustness, and side-lobe level, for example. This\npaper presents the development of a physical-model-based, optimal beamforming\nframework for spherical loudspeaker arrays, similar to the framework already\ndeveloped for spherical microphone arrays, facilitating efficient beamforming\nin the spherical harmonics domain, with independent steering. In particular, it\nis shown that from a beamforming perspective, the spherical loudspeaker array\nis similar to the spherical microphone array with microphones arranged around a\nrigid sphere. Experimental investigation validates the theoretical framework of\nbeamformer design.", "published": "2023-10-06 12:40:02", "link": "http://arxiv.org/abs/2310.04202v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Zero-Shot Emotion Transfer For Cross-Lingual Speech Synthesis", "abstract": "Zero-shot emotion transfer in cross-lingual speech synthesis aims to transfer\nemotion from an arbitrary speech reference in the source language to the\nsynthetic speech in the target language. Building such a system faces\nchallenges of unnatural foreign accents and difficulty in modeling the shared\nemotional expressions of different languages. Building on the DelightfulTTS\nneural architecture, this paper addresses these challenges by introducing\nspecifically-designed modules to model the language-specific prosody features\nand language-shared emotional expressions separately. Specifically, the\nlanguage-specific speech prosody is learned by a non-autoregressive predictive\ncoding (NPC) module to improve the naturalness of the synthetic cross-lingual\nspeech. The shared emotional expression between different languages is\nextracted from a pre-trained self-supervised model HuBERT with strong\ngeneralization capabilities. We further use hierarchical emotion modeling to\ncapture more comprehensive emotions across different languages. Experimental\nresults demonstrate the proposed framework's effectiveness in synthesizing\nbi-lingual emotional speech for the monolingual target speaker without\nemotional training data.", "published": "2023-10-06 01:18:21", "link": "http://arxiv.org/abs/2310.03963v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Layer-Adapted Implicit Distribution Alignment Networks for Cross-Corpus\n  Speech Emotion Recognition", "abstract": "In this paper, we propose a new unsupervised domain adaptation (DA) method\ncalled layer-adapted implicit distribution alignment networks (LIDAN) to\naddress the challenge of cross-corpus speech emotion recognition (SER). LIDAN\nextends our previous ICASSP work, deep implicit distribution alignment networks\n(DIDAN), whose key contribution lies in the introduction of a novel\nregularization term called implicit distribution alignment (IDA). This term\nallows DIDAN trained on source (training) speech samples to remain applicable\nto predicting emotion labels for target (testing) speech samples, regardless of\ncorpus variance in cross-corpus SER. To further enhance this method, we extend\nIDA to layer-adapted IDA (LIDA), resulting in LIDAN. This layer-adpated\nextention consists of three modified IDA terms that consider emotion labels at\ndifferent levels of granularity. These terms are strategically arranged within\ndifferent fully connected layers in LIDAN, aligning with the increasing\nemotion-discriminative abilities with respect to the layer depth. This\narrangement enables LIDAN to more effectively learn emotion-discriminative and\ncorpus-invariant features for SER across various corpora compared to DIDAN. It\nis also worthy to mention that unlike most existing methods that rely on\nestimating statistical moments to describe pre-assumed explicit distributions,\nboth IDA and LIDA take a different approach. They utilize an idea of target\nsample reconstruction to directly bridge the feature distribution gap without\nmaking assumptions about their distribution type. As a result, DIDAN and LIDAN\ncan be viewed as implicit cross-corpus SER methods. To evaluate LIDAN, we\nconducted extensive cross-corpus SER experiments on EmoDB, eNTERFACE, and CASIA\ncorpora. The experimental results demonstrate that LIDAN surpasses recent\nstate-of-the-art explicit unsupervised DA methods in tackling cross-corpus SER\ntasks.", "published": "2023-10-06 03:34:48", "link": "http://arxiv.org/abs/2310.03992v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "U-Style: Cascading U-nets with Multi-level Speaker and Style Modeling\n  for Zero-Shot Voice Cloning", "abstract": "Zero-shot speaker cloning aims to synthesize speech for any target speaker\nunseen during TTS system building, given only a single speech reference of the\nspeaker at hand. Although more practical in real applications, the current\nzero-shot methods still produce speech with undesirable naturalness and speaker\nsimilarity. Moreover, endowing the target speaker with arbitrary speaking\nstyles in the zero-shot setup has not been considered. This is because the\nunique challenge of zero-shot speaker and style cloning is to learn the\ndisentangled speaker and style representations from only short references\nrepresenting an arbitrary speaker and an arbitrary style. To address this\nchallenge, we propose U-Style, which employs Grad-TTS as the backbone,\nparticularly cascading a speaker-specific encoder and a style-specific encoder\nbetween the text encoder and the diffusion decoder. Thus, leveraging signal\nperturbation, U-Style is explicitly decomposed into speaker- and style-specific\nmodeling parts, achieving better speaker and style disentanglement. To improve\nunseen speaker and style modeling ability, these two encoders conduct\nmulti-level speaker and style modeling by skip-connected U-nets, incorporating\nthe representation extraction and information reconstruction process. Besides,\nto improve the naturalness of synthetic speech, we adopt mean-based instance\nnormalization and style adaptive layer normalization in these encoders to\nperform representation extraction and condition adaptation, respectively.\nExperiments show that U-Style significantly surpasses the state-of-the-art\nmethods in unseen speaker cloning regarding naturalness and speaker similarity.\nNotably, U-Style can transfer the style from an unseen source speaker to\nanother unseen target speaker, achieving flexible combinations of desired\nspeaker timbre and style in zero-shot voice cloning.", "published": "2023-10-06 04:24:41", "link": "http://arxiv.org/abs/2310.04004v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Analysis on the Influence of Synchronization Error on Fixed-filter\n  Active Noise Control", "abstract": "The efficacy of active noise control technology in mitigating urban noise,\nparticularly in relation to low-frequency components, has been\nwell-established. In the realm of traditional academic research, adaptive\nalgorithms, such as the filtered reference least mean square method, are\nextensively employed to achieve real-time noise reduction in many applications.\nNevertheless, the utilization of this technology in commercial goods is often\nhindered by its significant computing complexity and inherent instability. In\nthis particular scenario, the adoption of the fixed-filter strategy emerges as\na viable alternative for addressing these challenges, albeit with a potential\ntrade-off in terms of noise reduction efficacy. This work aims to conduct a\ntheoretical investigation into the synchronization error of the digital Active\nNoise Control (ANC) system. Keywords: Fixed-filter, Active noise control,\nMultichannel active noise control.", "published": "2023-10-06 13:48:14", "link": "http://arxiv.org/abs/2310.04249v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "DPM-TSE: A Diffusion Probabilistic Model for Target Sound Extraction", "abstract": "Common target sound extraction (TSE) approaches primarily relied on\ndiscriminative approaches in order to separate the target sound while\nminimizing interference from the unwanted sources, with varying success in\nseparating the target from the background. This study introduces DPM-TSE, a\nfirst generative method based on diffusion probabilistic modeling (DPM) for\ntarget sound extraction, to achieve both cleaner target renderings as well as\nimproved separability from unwanted sounds. The technique also tackles common\nbackground noise issues with DPM by introducing a correction method for noise\nschedules and sample steps. This approach is evaluated using both objective and\nsubjective quality metrics on the FSD Kaggle 2018 dataset. The results show\nthat DPM-TSE has a significant improvement in perceived quality in terms of\ntarget extraction and purity.", "published": "2023-10-06 20:13:57", "link": "http://arxiv.org/abs/2310.04567v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "MBTFNet: Multi-Band Temporal-Frequency Neural Network For Singing Voice\n  Enhancement", "abstract": "A typical neural speech enhancement (SE) approach mainly handles speech and\nnoise mixtures, which is not optimal for singing voice enhancement scenarios.\nMusic source separation (MSS) models treat vocals and various accompaniment\ncomponents equally, which may reduce performance compared to the model that\nonly considers vocal enhancement. In this paper, we propose a novel multi-band\ntemporal-frequency neural network (MBTFNet) for singing voice enhancement,\nwhich particularly removes background music, noise and even backing vocals from\nsinging recordings. MBTFNet combines inter and intra-band modeling for better\nprocessing of full-band signals. Dual-path modeling are introduced to expand\nthe receptive field of the model. We propose an implicit personalized\nenhancement (IPE) stage based on signal-to-noise ratio (SNR) estimation, which\nfurther improves the performance of MBTFNet. Experiments show that our proposed\nmodel significantly outperforms several state-of-the-art SE and MSS models.", "published": "2023-10-06 16:44:47", "link": "http://arxiv.org/abs/2310.04369v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Music Recommendation Based on Audio Fingerprint", "abstract": "This work combined different audio features to obtain a more robust\nfingerprint to be used in a music recommendation process. The combination of\nthese methods resulted in a high-dimensional vector. To reduce the number of\nvalues, PCA was applied to the set of resulting fingerprints, selecting the\nnumber of principal components that corresponded to an explained variance of\n$95\\%$. Finally, with these PCA-fingerprints, the similarity matrix of each\nfingerprint with the entire data set was calculated. The process was applied to\n200 songs from a personal music library; the songs were tagged with the\nartists' corresponding genres. The recommendations (fingerprints of songs with\nthe closest similarity) were rated successful if the recommended songs' genre\nmatched the target songs' genre. With this procedure, it was possible to obtain\nan accuracy of $89\\%$ (successful recommendations out of total recommendation\nrequests).", "published": "2023-10-06 03:49:13", "link": "http://arxiv.org/abs/2310.17655v1", "categories": ["eess.AS", "cs.IR", "cs.SD"], "primary_category": "eess.AS"}
