{"title": "Can Network Embedding of Distributional Thesaurus be Combined with Word\n  Vectors for Better Representation?", "abstract": "Distributed representations of words learned from text have proved to be\nsuccessful in various natural language processing tasks in recent times. While\nsome methods represent words as vectors computed from text using predictive\nmodel (Word2vec) or dense count based model (GloVe), others attempt to\nrepresent these in a distributional thesaurus network structure where the\nneighborhood of a word is a set of words having adequate context overlap. Being\nmotivated by recent surge of research in network embedding techniques\n(DeepWalk, LINE, node2vec etc.), we turn a distributional thesaurus network\ninto dense word vectors and investigate the usefulness of distributional\nthesaurus embedding in improving overall word representation. This is the first\nattempt where we show that combining the proposed word representation obtained\nby distributional thesaurus embedding with the state-of-the-art word\nrepresentations helps in improving the performance by a significant margin when\nevaluated against NLP tasks like word similarity and relatedness, synonym\ndetection, analogy detection. Additionally, we show that even without using any\nhandcrafted lexical resources we can come up with representations having\ncomparable performance in the word similarity and relatedness tasks compared to\nthe representations where a lexical resource has been used.", "published": "2018-02-17 05:52:23", "link": "http://arxiv.org/abs/1802.06196v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CytonMT: an Efficient Neural Machine Translation Open-source Toolkit\n  Implemented in C++", "abstract": "This paper presents an open-source neural machine translation toolkit named\nCytonMT (https://github.com/arthurxlw/cytonMt). The toolkit is built from\nscratch only using C++ and NVIDIA's GPU-accelerated libraries. The toolkit\nfeatures training efficiency, code simplicity and translation quality.\nBenchmarks show that CytonMT accelerates the training speed by 64.5% to 110.8%\non neural networks of various sizes, and achieves competitive translation\nquality.", "published": "2018-02-17 03:11:50", "link": "http://arxiv.org/abs/1802.07170v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Global-scale phylogenetic linguistic inference from lexical resources", "abstract": "Automatic phylogenetic inference plays an increasingly important role in\ncomputational historical linguistics. Most pertinent work is currently based on\nexpert cognate judgments. This limits the scope of this approach to a small\nnumber of well-studied language families. We used machine learning techniques\nto compile data suitable for phylogenetic inference from the ASJP database, a\ncollection of almost 7,000 phonetically transcribed word lists over 40\nconcepts, covering two third of the extant world-wide linguistic diversity.\nFirst, we estimated Pointwise Mutual Information scores between sound classes\nusing weighted sequence alignment and general-purpose optimization. From this\nwe computed a dissimilarity matrix over all ASJP word lists. This matrix is\nsuitable for distance-based phylogenetic inference. Second, we applied cognate\nclustering to the ASJP data, using supervised training of an SVM classifier on\nexpert cognacy judgments. Third, we defined two types of binary characters,\nbased on automatically inferred cognate classes and on sound-class occurrences.\nSeveral tests are reported demonstrating the suitability of these characters\nfor character-based phylogenetic inference.", "published": "2018-02-17 13:51:59", "link": "http://arxiv.org/abs/1802.06079v1", "categories": ["cs.CL", "q-bio.QM"], "primary_category": "cs.CL"}
{"title": "Building a Word Segmenter for Sanskrit Overnight", "abstract": "There is an abundance of digitised texts available in Sanskrit. However, the\nword segmentation task in such texts are challenging due to the issue of\n'Sandhi'. In Sandhi, words in a sentence often fuse together to form a single\nchunk of text, where the word delimiter vanishes and sounds at the word\nboundaries undergo transformations, which is also reflected in the written\ntext. Here, we propose an approach that uses a deep sequence to sequence\n(seq2seq) model that takes only the sandhied string as the input and predicts\nthe unsandhied string. The state of the art models are linguistically involved\nand have external dependencies for the lexical and morphological analysis of\nthe input. Our model can be trained \"overnight\" and be used for production. In\nspite of the knowledge lean approach, our system preforms better than the\ncurrent state of the art by gaining a percentage increase of 16.79 % than the\ncurrent state of the art.", "published": "2018-02-17 04:05:36", "link": "http://arxiv.org/abs/1802.06185v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Sentiment Analysis on Speaker Specific Speech Data", "abstract": "Sentiment analysis has evolved over past few decades, most of the work in it\nrevolved around textual sentiment analysis with text mining techniques. But\naudio sentiment analysis is still in a nascent stage in the research community.\nIn this proposed research, we perform sentiment analysis on speaker\ndiscriminated speech transcripts to detect the emotions of the individual\nspeakers involved in the conversation. We analyzed different techniques to\nperform speaker discrimination and sentiment analysis to find efficient\nalgorithms to perform this task.", "published": "2018-02-17 08:39:47", "link": "http://arxiv.org/abs/1802.06209v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "CREPE: A Convolutional Representation for Pitch Estimation", "abstract": "The task of estimating the fundamental frequency of a monophonic sound\nrecording, also known as pitch tracking, is fundamental to audio processing\nwith multiple applications in speech processing and music information\nretrieval. To date, the best performing techniques, such as the pYIN algorithm,\nare based on a combination of DSP pipelines and heuristics. While such\ntechniques perform very well on average, there remain many cases in which they\nfail to correctly estimate the pitch. In this paper, we propose a data-driven\npitch tracking algorithm, CREPE, which is based on a deep convolutional neural\nnetwork that operates directly on the time-domain waveform. We show that the\nproposed model produces state-of-the-art results, performing equally or better\nthan pYIN. Furthermore, we evaluate the model's generalizability in terms of\nnoise robustness. A pre-trained version of CREPE is made freely available as an\nopen-source Python module for easy application.", "published": "2018-02-17 03:50:11", "link": "http://arxiv.org/abs/1802.06182v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
