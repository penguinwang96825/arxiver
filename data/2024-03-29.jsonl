{"title": "Are LLMs Effective Backbones for Fine-tuning? An Experimental\n  Investigation of Supervised LLMs on Chinese Short Text Matching", "abstract": "The recent success of Large Language Models (LLMs) has garnered significant\nattention in both academia and industry. Prior research on LLMs has primarily\nfocused on enhancing or leveraging their generalization capabilities in zero-\nand few-shot settings. However, there has been limited investigation into\neffectively fine-tuning LLMs for a specific natural language understanding task\nin supervised settings. In this study, we conduct an experimental analysis by\nfine-tuning LLMs for the task of Chinese short text matching. We explore\nvarious factors that influence performance when fine-tuning LLMs, including\ntask modeling methods, prompt formats, and output formats.", "published": "2024-03-29 02:36:54", "link": "http://arxiv.org/abs/2403.19930v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SLFNet: Generating Semantic Logic Forms from Natural Language Using\n  Semantic Probability Graphs", "abstract": "Building natural language interfaces typically uses a semantic parser to\nparse the user's natural language and convert it into structured\n\\textbf{S}emantic \\textbf{L}ogic \\textbf{F}orms (SLFs). The mainstream approach\nis to adopt a sequence-to-sequence framework, which requires that natural\nlanguage commands and SLFs must be represented serially. Since a single natural\nlanguage may have multiple SLFs or multiple natural language commands may have\nthe same SLF, training a sequence-to-sequence model is sensitive to the choice\namong them, a phenomenon recorded as \"order matters\". To solve this problem, we\npropose a novel neural network, SLFNet, which firstly incorporates dependent\nsyntactic information as prior knowledge and can capture the long-range\ninteractions between contextual information and words. Secondly construct\nsemantic probability graphs to obtain local dependencies between predictor\nvariables. Finally we propose the Multi-Head SLF Attention mechanism to\nsynthesize SLFs from natural language commands based on Sequence-to-Slots.\nExperiments show that SLFNet achieves state-of-the-art performance on the\nChineseQCI-TS and Okapi datasets, and competitive performance on the ATIS\ndataset.", "published": "2024-03-29 02:42:39", "link": "http://arxiv.org/abs/2403.19936v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Model based Situational Dialogues for Second Language\n  Learning", "abstract": "In second language learning, scenario-based conversation practice is\nimportant for language learners to achieve fluency in speaking, but students\noften lack sufficient opportunities to practice their conversational skills\nwith qualified instructors or native speakers. To bridge this gap, we propose\nsituational dialogue models for students to engage in conversational practice.\nOur situational dialogue models are fine-tuned on large language models (LLMs),\nwith the aim of combining the engaging nature of an open-ended conversation\nwith the focused practice of scenario-based tasks. Leveraging the\ngeneralization capabilities of LLMs, we demonstrate that our situational\ndialogue models perform effectively not only on training topics but also on\ntopics not encountered during training. This offers a promising solution to\nsupport a wide range of conversational topics without extensive manual work.\nAdditionally, research in the field of dialogue systems still lacks reliable\nautomatic evaluation metrics, leading to human evaluation as the gold standard\n(Smith et al., 2022), which is typically expensive. To address the limitations\nof existing evaluation methods, we present a novel automatic evaluation method\nthat employs fine-tuned LLMs to efficiently and effectively assess the\nperformance of situational dialogue models.", "published": "2024-03-29 06:43:55", "link": "http://arxiv.org/abs/2403.20005v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transformer-Lite: High-efficiency Deployment of Large Language Models on\n  Mobile Phone GPUs", "abstract": "The Large Language Model (LLM) is widely employed for tasks such as\nintelligent assistants, text summarization, translation, and multi-modality on\nmobile phones. However, the current methods for on-device LLM deployment\nmaintain slow inference speed, which causes poor user experience. To facilitate\nhigh-efficiency LLM deployment on device GPUs, we propose four optimization\ntechniques: (a) a symbolic expression-based approach to support dynamic shape\nmodel inference; (b) operator optimizations and execution priority setting to\nenhance inference speed and reduce phone lagging; (c) an FP4 quantization\nmethod termed M0E4 to reduce dequantization overhead; (d) a sub-tensor-based\ntechnique to eliminate the need for copying KV cache after LLM inference.\nFurthermore, we implement these methods in our mobile inference engine,\nTransformer-Lite, which is compatible with both Qualcomm and MTK processors. We\nevaluated Transformer-Lite's performance using LLMs with varied architectures\nand parameters ranging from 2B to 14B. Specifically, we achieved prefill and\ndecoding speeds of 121 token/s and 14 token/s for ChatGLM2 6B, and 330 token/s\nand 30 token/s for smaller Gemma 2B, respectively. Compared with CPU-based\nFastLLM and GPU-based MLC-LLM, our engine attains over 10x speedup for the\nprefill speed and 2~3x speedup for the decoding speed.", "published": "2024-03-29 08:26:53", "link": "http://arxiv.org/abs/2403.20041v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can LLMs Learn from Previous Mistakes? Investigating LLMs' Errors to\n  Boost for Reasoning", "abstract": "Recent works have shown the benefits to LLMs from fine-tuning golden-standard\nChain-of-Thought (CoT) rationales or using them as correct examples in few-shot\nprompting. While humans can indeed imitate correct examples, learning from our\nmistakes is another vital aspect of human cognition. Hence, a question\nnaturally arises: \\textit{can LLMs learn and benefit from their mistakes,\nespecially for their reasoning? } This study investigates this problem from\nboth the prompting and model-tuning perspectives. We begin by introducing\n\\textsc{CoTErrorSet}, a new benchmark with 609,432 questions, each designed\nwith both correct and error references, and demonstrating the types and reasons\nfor making such mistakes. To explore the effectiveness of those mistakes, we\ndesign two methods: (1) \\textbf{Self-rethinking} prompting guides LLMs to\nrethink whether they have made similar previous mistakes; and (2)\n\\textbf{Mistake tuning} involves finetuning models in both correct and\nincorrect reasoning domains, rather than only tuning models to learn ground\ntruth in traditional methodology. We conduct a series of experiments to prove\nLLMs can obtain benefits from mistakes in both directions. Our two methods\noffer potentially cost-effective strategies by leveraging errors to enhance\nreasoning capabilities, which costs significantly less than creating\nmeticulously hand-crafted golden references. We ultimately make a thorough\nanalysis of the reasons behind LLMs' errors, which provides directions that\nfuture research needs to overcome. \\textsc{CoTErrorSet} will be published soon\non \\texttt{\\url{https://github.com/YookiTong/Learn-from-Mistakes-CotErrorSet}}.", "published": "2024-03-29 08:30:34", "link": "http://arxiv.org/abs/2403.20046v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-Lingual Transfer Robustness to Lower-Resource Languages on\n  Adversarial Datasets", "abstract": "Multilingual Language Models (MLLMs) exhibit robust cross-lingual transfer\ncapabilities, or the ability to leverage information acquired in a source\nlanguage and apply it to a target language. These capabilities find practical\napplications in well-established Natural Language Processing (NLP) tasks such\nas Named Entity Recognition (NER). This study aims to investigate the\neffectiveness of a source language when applied to a target language,\nparticularly in the context of perturbing the input test set. We evaluate on 13\npairs of languages, each including one high-resource language (HRL) and one\nlow-resource language (LRL) with a geographic, genetic, or borrowing\nrelationship. We evaluate two well-known MLLMs--MBERT and XLM-R--on these\npairs, in native LRL and cross-lingual transfer settings, in two tasks, under a\nset of different perturbations. Our findings indicate that NER cross-lingual\ntransfer depends largely on the overlap of entity chunks. If a source and\ntarget language have more entities in common, the transfer ability is stronger.\nModels using cross-lingual transfer also appear to be somewhat more robust to\ncertain perturbations of the input, perhaps indicating an ability to leverage\nstronger representations derived from the HRL. Our research provides valuable\ninsights into cross-lingual transfer and its implications for NLP applications,\nand underscores the need to consider linguistic nuances and potential\nlimitations when employing MLLMs across distinct languages.", "published": "2024-03-29 08:47:15", "link": "http://arxiv.org/abs/2403.20056v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IPA Transcription of Bengali Texts", "abstract": "The International Phonetic Alphabet (IPA) serves to systematize phonemes in\nlanguage, enabling precise textual representation of pronunciation. In Bengali\nphonology and phonetics, ongoing scholarly deliberations persist concerning the\nIPA standard and core Bengali phonemes. This work examines prior research,\nidentifies current and potential issues, and suggests a framework for a Bengali\nIPA standard, facilitating linguistic analysis and NLP resource creation and\ndownstream technology development. In this work, we present a comprehensive\nstudy of Bengali IPA transcription and introduce a novel IPA transcription\nframework incorporating a novel dataset with DL-based benchmarks.", "published": "2024-03-29 09:33:34", "link": "http://arxiv.org/abs/2403.20084v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Efficient Approach for Studying Cross-Lingual Transfer in\n  Multilingual Language Models", "abstract": "The capacity and effectiveness of pre-trained multilingual models (MLMs) for\nzero-shot cross-lingual transfer is well established. However, phenomena of\npositive or negative transfer, and the effect of language choice still need to\nbe fully understood, especially in the complex setting of massively\nmultilingual LMs. We propose an \\textit{efficient} method to study transfer\nlanguage influence in zero-shot performance on another target language. Unlike\nprevious work, our approach disentangles downstream tasks from language, using\ndedicated adapter units. Our findings suggest that some languages do not\nlargely affect others, while some languages, especially ones unseen during\npre-training, can be extremely beneficial or detrimental for different target\nlanguages. We find that no transfer language is beneficial for all target\nlanguages. We do, curiously, observe languages previously unseen by MLMs\nconsistently benefit from transfer from almost any language. We additionally\nuse our modular approach to quantify negative interference efficiently and\ncategorize languages accordingly. Furthermore, we provide a list of promising\ntransfer-target language configurations that consistently lead to target\nlanguage performance improvements. Code and data are publicly available:\nhttps://github.com/ffaisal93/neg_inf", "published": "2024-03-29 09:52:18", "link": "http://arxiv.org/abs/2403.20088v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NLP for Counterspeech against Hate: A Survey and How-To Guide", "abstract": "In recent years, counterspeech has emerged as one of the most promising\nstrategies to fight online hate. These non-escalatory responses tackle online\nabuse while preserving the freedom of speech of the users, and can have a\ntangible impact in reducing online and offline violence. Recently, there has\nbeen growing interest from the Natural Language Processing (NLP) community in\naddressing the challenges of analysing, collecting, classifying, and\nautomatically generating counterspeech, to reduce the huge burden of manually\nproducing it. In particular, researchers have taken different directions in\naddressing these challenges, thus providing a variety of related tasks and\nresources. In this paper, we provide a guide for doing research on\ncounterspeech, by describing - with detailed examples - the steps to undertake,\nand providing best practices that can be learnt from the NLP studies on this\ntopic. Finally, we discuss open challenges and future directions of\ncounterspeech research in NLP.", "published": "2024-03-29 10:32:44", "link": "http://arxiv.org/abs/2403.20103v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "User Modeling Challenges in Interactive AI Assistant Systems", "abstract": "Interactive Artificial Intelligent(AI) assistant systems are designed to\noffer timely guidance to help human users to complete a variety tasks. One of\nthe remaining challenges is to understand user's mental states during the task\nfor more personalized guidance. In this work, we analyze users' mental states\nduring task executions and investigate the capabilities and challenges for\nlarge language models to interpret user profiles for more personalized user\nguidance.", "published": "2024-03-29 11:54:13", "link": "http://arxiv.org/abs/2403.20134v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fine-tuning Large Language Models for Automated Diagnostic Screening\n  Summaries", "abstract": "Improving mental health support in developing countries is a pressing need.\nOne potential solution is the development of scalable, automated systems to\nconduct diagnostic screenings, which could help alleviate the burden on mental\nhealth professionals. In this work, we evaluate several state-of-the-art Large\nLanguage Models (LLMs), with and without fine-tuning, on our custom dataset for\ngenerating concise summaries from mental state examinations. We rigorously\nevaluate four different models for summary generation using established ROUGE\nmetrics and input from human evaluators. The results highlight that our\ntop-performing fine-tuned model outperforms existing models, achieving ROUGE-1\nand ROUGE-L values of 0.810 and 0.764, respectively. Furthermore, we assessed\nthe fine-tuned model's generalizability on a publicly available D4 dataset, and\nthe outcomes were promising, indicating its potential applicability beyond our\ncustom dataset.", "published": "2024-03-29 12:25:37", "link": "http://arxiv.org/abs/2403.20145v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IndiBias: A Benchmark Dataset to Measure Social Biases in Language\n  Models for Indian Context", "abstract": "The pervasive influence of social biases in language data has sparked the\nneed for benchmark datasets that capture and evaluate these biases in Large\nLanguage Models (LLMs). Existing efforts predominantly focus on English\nlanguage and the Western context, leaving a void for a reliable dataset that\nencapsulates India's unique socio-cultural nuances. To bridge this gap, we\nintroduce IndiBias, a comprehensive benchmarking dataset designed specifically\nfor evaluating social biases in the Indian context. We filter and translate the\nexisting CrowS-Pairs dataset to create a benchmark dataset suited to the Indian\ncontext in Hindi language. Additionally, we leverage LLMs including ChatGPT and\nInstructGPT to augment our dataset with diverse societal biases and stereotypes\nprevalent in India. The included bias dimensions encompass gender, religion,\ncaste, age, region, physical appearance, and occupation. We also build a\nresource to address intersectional biases along three intersectional\ndimensions. Our dataset contains 800 sentence pairs and 300 tuples for bias\nmeasurement across different demographics. The dataset is available in English\nand Hindi, providing a size comparable to existing benchmark datasets.\nFurthermore, using IndiBias we compare ten different language models on\nmultiple bias measurement metrics. We observed that the language models exhibit\nmore bias across a majority of the intersectional groups.", "published": "2024-03-29 12:32:06", "link": "http://arxiv.org/abs/2403.20147v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Systematic Analysis of Subwords and Cross-Lingual Transfer in\n  Multilingual Translation", "abstract": "Multilingual modelling can improve machine translation for low-resource\nlanguages, partly through shared subword representations. This paper studies\nthe role of subword segmentation in cross-lingual transfer. We systematically\ncompare the efficacy of several subword methods in promoting synergy and\npreventing interference across different linguistic typologies. Our findings\nshow that subword regularisation boosts synergy in multilingual modelling,\nwhereas BPE more effectively facilitates transfer during cross-lingual\nfine-tuning. Notably, our results suggest that differences in orthographic word\nboundary conventions (the morphological granularity of written words) may\nimpede cross-lingual transfer more significantly than linguistic unrelatedness.\nOur study confirms that decisions around subword modelling can be key to\noptimising the benefits of multilingual modelling.", "published": "2024-03-29 13:09:23", "link": "http://arxiv.org/abs/2403.20157v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Measuring Taiwanese Mandarin Language Understanding", "abstract": "The evaluation of large language models (LLMs) has drawn substantial\nattention in the field recently. This work focuses on evaluating LLMs in a\nChinese context, specifically, for Traditional Chinese which has been largely\nunderrepresented in existing benchmarks. We present TMLU, a holistic evaluation\nsuit tailored for assessing the advanced knowledge and reasoning capability in\nLLMs, under the context of Taiwanese Mandarin. TMLU consists of an array of 37\nsubjects across social science, STEM, humanities, Taiwan-specific content, and\nothers, ranging from middle school to professional levels. In addition, we\ncurate chain-of-thought-like few-shot explanations for each subject to\nfacilitate the evaluation of complex reasoning skills. To establish a\ncomprehensive baseline, we conduct extensive experiments and analysis on 24\nadvanced LLMs. The results suggest that Chinese open-weight models demonstrate\ninferior performance comparing to multilingual proprietary ones, and\nopen-weight models tailored for Taiwanese Mandarin lag behind the\nSimplified-Chinese counterparts. The findings indicate great headrooms for\nimprovement, and emphasize the goal of TMLU to foster the development of\nlocalized Taiwanese-Mandarin LLMs. We release the benchmark and evaluation\nscripts for the community to promote future research.", "published": "2024-03-29 13:56:21", "link": "http://arxiv.org/abs/2403.20180v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Alignment of Discourse Relations of Different Discourse\n  Annotation Frameworks", "abstract": "Existing discourse corpora are annotated based on different frameworks, which\nshow significant dissimilarities in definitions of arguments and relations and\nstructural constraints. Despite surface differences, these frameworks share\nbasic understandings of discourse relations. The relationship between these\nframeworks has been an open research question, especially the correlation\nbetween relation inventories utilized in different frameworks. Better\nunderstanding of this question is helpful for integrating discourse theories\nand enabling interoperability of discourse corpora annotated under different\nframeworks. However, studies that explore correlations between discourse\nrelation inventories are hindered by different criteria of discourse\nsegmentation, and expert knowledge and manual examination are typically needed.\nSome semi-automatic methods have been proposed, but they rely on corpora\nannotated in multiple frameworks in parallel. In this paper, we introduce a\nfully automatic approach to address the challenges. Specifically, we extend the\nlabel-anchored contrastive learning method introduced by Zhang et al. (2022b)\nto learn label embeddings during a classification task. These embeddings are\nthen utilized to map discourse relations from different frameworks. We show\nexperimental results on RST-DT (Carlson et al., 2001) and PDTB 3.0 (Prasad et\nal., 2018).", "published": "2024-03-29 14:18:26", "link": "http://arxiv.org/abs/2403.20196v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Advancing the Arabic WordNet: Elevating Content Quality", "abstract": "High-quality WordNets are crucial for achieving high-quality results in NLP\napplications that rely on such resources. However, the wordnets of most\nlanguages suffer from serious issues of correctness and completeness with\nrespect to the words and word meanings they define, such as incorrect lemmas,\nmissing glosses and example sentences, or an inadequate, Western-centric\nrepresentation of the morphology and the semantics of the language. Previous\nefforts have largely focused on increasing lexical coverage while ignoring\nother qualitative aspects. In this paper, we focus on the Arabic language and\nintroduce a major revision of the Arabic WordNet that addresses multiple\ndimensions of lexico-semantic resource quality. As a result, we updated more\nthan 58% of the synsets of the existing Arabic WordNet by adding missing\ninformation and correcting errors. In order to address issues of language\ndiversity and untranslatability, we also extended the wordnet structure by new\nelements: phrasets and lexical gaps.", "published": "2024-03-29 14:54:19", "link": "http://arxiv.org/abs/2403.20215v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LUQ: Long-text Uncertainty Quantification for LLMs", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capability in a\nvariety of NLP tasks. However, LLMs are also prone to generate nonfactual\ncontent. Uncertainty Quantification (UQ) is pivotal in enhancing our\nunderstanding of a model's confidence on its generation, thereby aiding in the\nmitigation of nonfactual outputs. Existing research on UQ predominantly targets\nshort text generation, typically yielding brief, word-limited responses.\nHowever, real-world applications frequently necessitate much longer responses.\nOur study first highlights the limitations of current UQ methods in handling\nlong text generation. We then introduce \\textsc{Luq} and its two variations, a\nseries of novel sampling-based UQ approaches specifically designed for long\ntext. Our findings reveal that \\textsc{Luq} outperforms existing baseline\nmethods in correlating with the model's factuality scores (negative coefficient\nof -0.85 observed for Gemini Pro). To further improve the factuality of LLM\nresponses, we propose \\textsc{Luq-Ensemble}, a method that ensembles responses\nfrom multiple models and selects the response with the lowest uncertainty. The\nensembling method greatly improves the response factuality upon the best\nstandalone LLM.", "published": "2024-03-29 16:49:24", "link": "http://arxiv.org/abs/2403.20279v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards a Framework for Evaluating Explanations in Automated Fact\n  Verification", "abstract": "As deep neural models in NLP become more complex, and as a consequence\nopaque, the necessity to interpret them becomes greater. A burgeoning interest\nhas emerged in rationalizing explanations to provide short and coherent\njustifications for predictions. In this position paper, we advocate for a\nformal framework for key concepts and properties about rationalizing\nexplanations to support their evaluation systematically. We also outline one\nsuch formal framework, tailored to rationalizing explanations of increasingly\ncomplex structures, from free-form explanations to deductive explanations, to\nargumentative explanations (with the richest structure). Focusing on the\nautomated fact verification task, we provide illustrations of the use and\nusefulness of our formalization for evaluating explanations, tailored to their\nvarying structures.", "published": "2024-03-29 17:50:28", "link": "http://arxiv.org/abs/2403.20322v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On-the-fly Definition Augmentation of LLMs for Biomedical NER", "abstract": "Despite their general capabilities, LLMs still struggle on biomedical NER\ntasks, which are difficult due to the presence of specialized terminology and\nlack of training data. In this work we set out to improve LLM performance on\nbiomedical NER in limited data settings via a new knowledge augmentation\napproach which incorporates definitions of relevant concepts on-the-fly. During\nthis process, to provide a test bed for knowledge augmentation, we perform a\ncomprehensive exploration of prompting strategies. Our experiments show that\ndefinition augmentation is useful for both open source and closed LLMs. For\nexample, it leads to a relative improvement of 15\\% (on average) in GPT-4\nperformance (F1) across all (six) of our test datasets. We conduct extensive\nablations and analyses to demonstrate that our performance improvements stem\nfrom adding relevant definitional knowledge. We find that careful prompting\nstrategies also improve LLM performance, allowing them to outperform fine-tuned\nlanguage models in few-shot settings. To facilitate future research in this\ndirection, we release our code at https://github.com/allenai/beacon.", "published": "2024-03-29 20:59:27", "link": "http://arxiv.org/abs/2404.00152v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The LSCD Benchmark: a Testbed for Diachronic Word Meaning Tasks", "abstract": "Lexical Semantic Change Detection (LSCD) is a complex, lemma-level task,\nwhich is usually operationalized based on two subsequently applied usage-level\ntasks: First, Word-in-Context (WiC) labels are derived for pairs of usages.\nThen, these labels are represented in a graph on which Word Sense Induction\n(WSI) is applied to derive sense clusters. Finally, LSCD labels are derived by\ncomparing sense clusters over time. This modularity is reflected in most LSCD\ndatasets and models. It also leads to a large heterogeneity in modeling options\nand task definitions, which is exacerbated by a variety of dataset versions,\npreprocessing options and evaluation metrics. This heterogeneity makes it\ndifficult to evaluate models under comparable conditions, to choose optimal\nmodel combinations or to reproduce results. Hence, we provide a benchmark\nrepository standardizing LSCD evaluation. Through transparent implementation\nresults become easily reproducible and by standardization different components\ncan be freely combined. The repository reflects the task's modularity by\nallowing model evaluation for WiC, WSI and LSCD. This allows for careful\nevaluation of increasingly complex model components providing new ways of model\noptimization.", "published": "2024-03-29 22:11:54", "link": "http://arxiv.org/abs/2404.00176v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Word Ladders: A Mobile Application for Semantic Data Collection", "abstract": "Word Ladders is a free mobile application for Android and iOS, developed for\ncollecting linguistic data, specifically lists of words related to each other\nthrough semantic relations of categorical inclusion, within the Abstraction\nproject (ERC-2021-STG-101039777). We hereby provide an overview of Word\nLadders, explaining its game logic, motivation and expected results and\napplications to nlp tasks as well as to the investigation of cognitive\nscientific open questions", "published": "2024-03-29 22:41:40", "link": "http://arxiv.org/abs/2404.00184v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GPTA: Generative Prompt Tuning Assistant for Synergistic Downstream\n  Neural Network Enhancement with LLMs", "abstract": "This study introduces GPTA, a Large Language Model assistance training\nframework, that enhances the training of downstream task models via prefix\nprompt. By minimizing data exposure to LLM, the framework addresses the\nsecurity and legal challenges of applying LLM in downstream task model\ntraining. GPTA utilizes a new synergistic training approach, optimizing the\ndownstream models with parameter gradients and LLMs with the novel ``dialogue\ngradient''. The framework not only demonstrates significant improvements in\nmodel performance across six NLP benchmark datasets, but also reduces\noverfitting in low-resource scenarios effectively. The detailed analyses\nfurther validate that our pioneer framework provides a cost-efficient and\nadaptive method for downstream task model training with LLM support.", "published": "2024-03-29 23:04:04", "link": "http://arxiv.org/abs/2404.00189v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DiJiang: Efficient Large Language Models through Compact Kernelization", "abstract": "In an effort to reduce the computational load of Transformers, research on\nlinear attention has gained significant momentum. However, the improvement\nstrategies for attention mechanisms typically necessitate extensive retraining,\nwhich is impractical for large language models with a vast array of parameters.\nIn this paper, we present DiJiang, a novel Frequency Domain Kernelization\napproach that enables the transformation of a pre-trained vanilla Transformer\ninto a linear complexity model with little training costs. By employing a\nweighted Quasi-Monte Carlo method for sampling, the proposed approach\ntheoretically offers superior approximation efficiency. To further reduce the\ntraining computational complexity, our kernelization is based on Discrete\nCosine Transform (DCT) operations. Extensive experiments demonstrate that the\nproposed method achieves comparable performance to the original Transformer,\nbut with significantly reduced training costs and much faster inference speeds.\nOur DiJiang-7B achieves comparable performance with LLaMA2-7B on various\nbenchmark while requires only about 1/50 training cost. Code is available at\nhttps://github.com/YuchuanTian/DiJiang.", "published": "2024-03-29 02:32:15", "link": "http://arxiv.org/abs/2403.19928v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On Large Language Models' Hallucination with Regard to Known Facts", "abstract": "Large language models are successful in answering factoid questions but are\nalso prone to hallucination. We investigate the phenomenon of LLMs possessing\ncorrect answer knowledge yet still hallucinating from the perspective of\ninference dynamics, an area not previously covered in studies on\nhallucinations. We are able to conduct this analysis via two key ideas. First,\nwe identify the factual questions that query the same triplet knowledge but\nresult in different answers. The difference between the model behaviors on the\ncorrect and incorrect outputs hence suggests the patterns when hallucinations\nhappen. Second, to measure the pattern, we utilize mappings from the residual\nstreams to vocabulary space. We reveal the different dynamics of the output\ntoken probabilities along the depths of layers between the correct and\nhallucinated cases. In hallucinated cases, the output token's information\nrarely demonstrates abrupt increases and consistent superiority in the later\nstages of the model. Leveraging the dynamic curve as a feature, we build a\nclassifier capable of accurately detecting hallucinatory predictions with an\n88\\% success rate. Our study shed light on understanding the reasons for LLMs'\nhallucinations on their known facts, and more importantly, on accurately\npredicting when they are hallucinating.", "published": "2024-03-29 06:48:30", "link": "http://arxiv.org/abs/2403.20009v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Adverb Is the Key: Simple Text Data Augmentation with Adverb Deletion", "abstract": "In the field of text data augmentation, rule-based methods are widely adopted\nfor real-world applications owing to their cost-efficiency. However,\nconventional rule-based approaches suffer from the possibility of losing the\noriginal semantics of the given text. We propose a novel text data augmentation\nstrategy that avoids such phenomena through a straightforward deletion of\nadverbs, which play a subsidiary role in the sentence. Our comprehensive\nexperiments demonstrate the efficiency and effectiveness of our proposed\napproach for not just single text classification, but also natural language\ninference that requires semantic preservation. We publicly released our source\ncode for reproducibility.", "published": "2024-03-29 07:01:39", "link": "http://arxiv.org/abs/2403.20015v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "FSMR: A Feature Swapping Multi-modal Reasoning Approach with Joint\n  Textual and Visual Clues", "abstract": "Multi-modal reasoning plays a vital role in bridging the gap between textual\nand visual information, enabling a deeper understanding of the context. This\npaper presents the Feature Swapping Multi-modal Reasoning (FSMR) model,\ndesigned to enhance multi-modal reasoning through feature swapping. FSMR\nleverages a pre-trained visual-language model as an encoder, accommodating both\ntext and image inputs for effective feature representation from both\nmodalities. It introduces a unique feature swapping module, enabling the\nexchange of features between identified objects in images and corresponding\nvocabulary words in text, thereby enhancing the model's comprehension of the\ninterplay between images and text. To further bolster its multi-modal alignment\ncapabilities, FSMR incorporates a multi-modal cross-attention mechanism,\nfacilitating the joint modeling of textual and visual information. During\ntraining, we employ image-text matching and cross-entropy losses to ensure\nsemantic consistency between visual and language elements. Extensive\nexperiments on the PMR dataset demonstrate FSMR's superiority over\nstate-of-the-art baseline models across various performance metrics.", "published": "2024-03-29 07:28:50", "link": "http://arxiv.org/abs/2403.20026v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "ChatGPT v.s. Media Bias: A Comparative Study of GPT-3.5 and Fine-tuned\n  Language Models", "abstract": "In our rapidly evolving digital sphere, the ability to discern media bias\nbecomes crucial as it can shape public sentiment and influence pivotal\ndecisions. The advent of large language models (LLMs), such as ChatGPT, noted\nfor their broad utility in various natural language processing (NLP) tasks,\ninvites exploration of their efficacy in media bias detection. Can ChatGPT\ndetect media bias? This study seeks to answer this question by leveraging the\nMedia Bias Identification Benchmark (MBIB) to assess ChatGPT's competency in\ndistinguishing six categories of media bias, juxtaposed against fine-tuned\nmodels such as BART, ConvBERT, and GPT-2. The findings present a dichotomy:\nChatGPT performs at par with fine-tuned models in detecting hate speech and\ntext-level context bias, yet faces difficulties with subtler elements of other\nbias detections, namely, fake news, racial, gender, and cognitive biases.", "published": "2024-03-29 13:12:09", "link": "http://arxiv.org/abs/2403.20158v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Shallow Cross-Encoders for Low-Latency Retrieval", "abstract": "Transformer-based Cross-Encoders achieve state-of-the-art effectiveness in\ntext retrieval. However, Cross-Encoders based on large transformer models (such\nas BERT or T5) are computationally expensive and allow for scoring only a small\nnumber of documents within a reasonably small latency window. However, keeping\nsearch latencies low is important for user satisfaction and energy usage. In\nthis paper, we show that weaker shallow transformer models (i.e., transformers\nwith a limited number of layers) actually perform better than full-scale models\nwhen constrained to these practical low-latency settings since they can\nestimate the relevance of more documents in the same time budget. We further\nshow that shallow transformers may benefit from the generalized Binary\nCross-Entropy (gBCE) training scheme, which has recently demonstrated success\nfor recommendation tasks. Our experiments with TREC Deep Learning passage\nranking query sets demonstrate significant improvements in shallow and\nfull-scale models in low-latency scenarios. For example, when the latency limit\nis 25ms per query, MonoBERT-Large (a cross-encoder based on a full-scale BERT\nmodel) is only able to achieve NDCG@10 of 0.431 on TREC DL 2019, while\nTinyBERT-gBCE (a cross-encoder based on TinyBERT trained with gBCE) reaches\nNDCG@10 of 0.652, a +51% gain over MonoBERT-Large. We also show that shallow\nCross-Encoders are effective even when used without a GPU (e.g., with CPU\ninference, NDCG@10 decreases only by 3% compared to GPU inference with 50ms\nlatency), which makes Cross-Encoders practical to run even without specialized\nhardware acceleration.", "published": "2024-03-29 15:07:21", "link": "http://arxiv.org/abs/2403.20222v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "LayerNorm: A key component in parameter-efficient fine-tuning", "abstract": "Fine-tuning a pre-trained model, such as Bidirectional Encoder\nRepresentations from Transformers (BERT), has been proven to be an effective\nmethod for solving many natural language processing (NLP) tasks. However, due\nto the large number of parameters in many state-of-the-art NLP models,\nincluding BERT, the process of fine-tuning is computationally expensive. One\nattractive solution to this issue is parameter-efficient fine-tuning, which\ninvolves modifying only a minimal segment of the model while keeping the\nremainder unchanged. Yet, it remains unclear which segment of the BERT model is\ncrucial for fine-tuning. In this paper, we first analyze different components\nin the BERT model to pinpoint which one undergoes the most significant changes\nafter fine-tuning. We find that output LayerNorm changes more than any other\ncomponents when fine-tuned for different General Language Understanding\nEvaluation (GLUE) tasks. Then we show that only fine-tuning the LayerNorm can\nreach comparable, or in some cases better, performance to full fine-tuning and\nother parameter-efficient fine-tuning methods. Moreover, we use Fisher\ninformation to determine the most critical subset of LayerNorm and demonstrate\nthat many NLP tasks in the GLUE benchmark can be solved by fine-tuning only a\nsmall portion of LayerNorm with negligible performance degradation.", "published": "2024-03-29 16:53:11", "link": "http://arxiv.org/abs/2403.20284v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Can LLMs Correct Physicians, Yet? Investigating Effective Interaction\n  Methods in the Medical Domain", "abstract": "We explore the potential of Large Language Models (LLMs) to assist and\npotentially correct physicians in medical decision-making tasks. We evaluate\nseveral LLMs, including Meditron, Llama2, and Mistral, to analyze the ability\nof these models to interact effectively with physicians across different\nscenarios. We consider questions from PubMedQA and several tasks, ranging from\nbinary (yes/no) responses to long answer generation, where the answer of the\nmodel is produced after an interaction with a physician. Our findings suggest\nthat prompt design significantly influences the downstream accuracy of LLMs and\nthat LLMs can provide valuable feedback to physicians, challenging incorrect\ndiagnoses and contributing to more accurate decision-making. For example, when\nthe physician is accurate 38% of the time, Mistral can produce the correct\nanswer, improving accuracy up to 74% depending on the prompt being used, while\nLlama2 and Meditron models exhibit greater sensitivity to prompt choice. Our\nanalysis also uncovers the challenges of ensuring that LLM-generated\nsuggestions are pertinent and useful, emphasizing the need for further research\nin this area.", "published": "2024-03-29 16:59:13", "link": "http://arxiv.org/abs/2403.20288v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ChainNet: Structured Metaphor and Metonymy in WordNet", "abstract": "The senses of a word exhibit rich internal structure. In a typical lexicon,\nthis structure is overlooked: a word's senses are encoded as a list without\ninter-sense relations. We present ChainNet, a lexical resource which for the\nfirst time explicitly identifies these structures. ChainNet expresses how\nsenses in the Open English Wordnet are derived from one another: every nominal\nsense of a word is either connected to another sense by metaphor or metonymy,\nor is disconnected in the case of homonymy. Because WordNet senses are linked\nto resources which capture information about their meaning, ChainNet represents\nthe first dataset of grounded metaphor and metonymy.", "published": "2024-03-29 17:22:53", "link": "http://arxiv.org/abs/2403.20308v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Gecko: Versatile Text Embeddings Distilled from Large Language Models", "abstract": "We present Gecko, a compact and versatile text embedding model. Gecko\nachieves strong retrieval performance by leveraging a key idea: distilling\nknowledge from large language models (LLMs) into a retriever. Our two-step\ndistillation process begins with generating diverse, synthetic paired data\nusing an LLM. Next, we further refine the data quality by retrieving a set of\ncandidate passages for each query, and relabeling the positive and hard\nnegative passages using the same LLM. The effectiveness of our approach is\ndemonstrated by the compactness of the Gecko. On the Massive Text Embedding\nBenchmark (MTEB), Gecko with 256 embedding dimensions outperforms all existing\nentries with 768 embedding size. Gecko with 768 embedding dimensions achieves\nan average score of 66.31, competing with 7x larger models and 5x higher\ndimensional embeddings.", "published": "2024-03-29 17:56:40", "link": "http://arxiv.org/abs/2403.20327v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Classifying Conspiratorial Narratives At Scale: False Alarms and\n  Erroneous Connections", "abstract": "Online discussions frequently involve conspiracy theories, which can\ncontribute to the proliferation of belief in them. However, not all discussions\nsurrounding conspiracy theories promote them, as some are intended to debunk\nthem. Existing research has relied on simple proxies or focused on a\nconstrained set of signals to identify conspiracy theories, which limits our\nunderstanding of conspiratorial discussions across different topics and online\ncommunities. This work establishes a general scheme for classifying discussions\nrelated to conspiracy theories based on authors' perspectives on the conspiracy\nbelief, which can be expressed explicitly through narrative elements, such as\nthe agent, action, or objective, or implicitly through references to known\ntheories, such as chemtrails or the New World Order. We leverage human-labeled\nground truth to train a BERT-based model for classifying online CTs, which we\nthen compared to the Generative Pre-trained Transformer machine (GPT) for\ndetecting online conspiratorial content. Despite GPT's known strengths in its\nexpressiveness and contextual understanding, our study revealed significant\nflaws in its logical reasoning, while also demonstrating comparable strengths\nfrom our classifiers. We present the first large-scale classification study\nusing posts from the most active conspiracy-related Reddit forums and find that\nonly one-third of the posts are classified as positive. This research sheds\nlight on the potential applications of large language models in tasks demanding\nnuanced contextual comprehension.", "published": "2024-03-29 20:29:12", "link": "http://arxiv.org/abs/2404.00141v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Individual Text Corpora Predict Openness, Interests, Knowledge and Level\n  of Education", "abstract": "Here we examine whether the personality dimension of openness to experience\ncan be predicted from the individual google search history. By web scraping,\nindividual text corpora (ICs) were generated from 214 participants with a mean\nnumber of 5 million word tokens. We trained word2vec models and used the\nsimilarities of each IC to label words, which were derived from a lexical\napproach of personality. These IC-label-word similarities were utilized as\npredictive features in neural models. For training and validation, we relied on\n179 participants and held out a test sample of 35 participants. A grid search\nwith varying number of predictive features, hidden units and boost factor was\nperformed. As model selection criterion, we used R2 in the validation samples\npenalized by the absolute R2 difference between training and validation. The\nselected neural model explained 35% of the openness variance in the test\nsample, while an ensemble model with the same architecture often provided\nslightly more stable predictions for intellectual interests, knowledge in\nhumanities and level of education. Finally, a learning curve analysis suggested\nthat around 500 training participants are required for generalizable\npredictions. We discuss ICs as a complement or replacement of survey-based\npsychodiagnostics.", "published": "2024-03-29 21:44:24", "link": "http://arxiv.org/abs/2404.00165v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DataAgent: Evaluating Large Language Models' Ability to Answer\n  Zero-Shot, Natural Language Queries", "abstract": "Conventional processes for analyzing datasets and extracting meaningful\ninformation are often time-consuming and laborious. Previous work has\nidentified manual, repetitive coding and data collection as major obstacles\nthat hinder data scientists from undertaking more nuanced labor and high-level\nprojects. To combat this, we evaluated OpenAI's GPT-3.5 as a \"Language Data\nScientist\" (LDS) that can extrapolate key findings, including correlations and\nbasic information, from a given dataset. The model was tested on a diverse set\nof benchmark datasets to evaluate its performance across multiple standards,\nincluding data science code-generation based tasks involving libraries such as\nNumPy, Pandas, Scikit-Learn, and TensorFlow, and was broadly successful in\ncorrectly answering a given data science query related to the benchmark\ndataset. The LDS used various novel prompt engineering techniques to\neffectively answer a given question, including Chain-of-Thought reinforcement\nand SayCan prompt engineering. Our findings demonstrate great potential for\nleveraging Large Language Models for low-level, zero-shot data analysis.", "published": "2024-03-29 22:59:34", "link": "http://arxiv.org/abs/2404.00188v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LLaVA-Gemma: Accelerating Multimodal Foundation Models with a Compact\n  Language Model", "abstract": "We train a suite of multimodal foundation models (MMFM) using the popular\nLLaVA framework with the recently released Gemma family of large language\nmodels (LLMs). Of particular interest is the 2B parameter Gemma model, which\nprovides opportunities to construct capable small-scale MMFMs. In line with\nfindings from other papers in this space, we test the effect of ablating three\ndesign features: pretraining the connector, utilizing a more powerful image\nbackbone, and increasing the size of the language backbone. The resulting\nmodels, which we call LLaVA-Gemma, exhibit moderate performance on an array of\nevaluations, but fail to improve past the current comparably sized SOTA models.\nCloser analysis of performance shows mixed effects; skipping pretraining tends\nto reduce performance, larger vision models sometimes improve performance, and\nincreasing language model size has inconsistent effects. We publicly release\ntraining recipes, code and weights for our models for the LLaVA-Gemma models.", "published": "2024-03-29 21:32:50", "link": "http://arxiv.org/abs/2404.01331v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Constructing Multilingual Visual-Text Datasets Revealing Visual\n  Multilingual Ability of Vision Language Models", "abstract": "Large language models (LLMs) have increased interest in vision language\nmodels (VLMs), which process image-text pairs as input. Studies investigating\nthe visual understanding ability of VLMs have been proposed, but such studies\nare still preliminary because existing datasets do not permit a comprehensive\nevaluation of the fine-grained visual linguistic abilities of VLMs across\nmultiple languages. To further explore the strengths of VLMs, such as GPT-4V\n\\cite{openai2023GPT4}, we developed new datasets for the systematic and\nqualitative analysis of VLMs. Our contribution is four-fold: 1) we introduced\nnine vision-and-language (VL) tasks (including object recognition, image-text\nmatching, and more) and constructed multilingual visual-text datasets in four\nlanguages: English, Japanese, Swahili, and Urdu through utilizing templates\ncontaining \\textit{questions} and prompting GPT4-V to generate the\n\\textit{answers} and the \\textit{rationales}, 2) introduced a new VL task named\n\\textit{unrelatedness}, 3) introduced rationales to enable human understanding\nof the VLM reasoning process, and 4) employed human evaluation to measure the\nsuitability of proposed datasets for VL tasks. We show that VLMs can be\nfine-tuned on our datasets. Our work is the first to conduct such analyses in\nSwahili and Urdu. Also, it introduces \\textit{rationales} in VL analysis, which\nplayed a vital role in the evaluation.", "published": "2024-03-29 10:53:07", "link": "http://arxiv.org/abs/2406.15359v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Towards a Robust Retrieval-Based Summarization System", "abstract": "This paper describes an investigation of the robustness of large language\nmodels (LLMs) for retrieval augmented generation (RAG)-based summarization\ntasks. While LLMs provide summarization capabilities, their performance in\ncomplex, real-world scenarios remains under-explored. Our first contribution is\nLogicSumm, an innovative evaluation framework incorporating realistic scenarios\nto assess LLM robustness during RAG-based summarization. Based on limitations\nidentified by LogiSumm, we then developed SummRAG, a comprehensive system to\ncreate training dialogues and fine-tune a model to enhance robustness within\nLogicSumm's scenarios. SummRAG is an example of our goal of defining structured\nmethods to test the capabilities of an LLM, rather than addressing issues in a\none-off fashion. Experimental results confirm the power of SummRAG, showcasing\nimproved logical coherence and summarization quality. Data, corresponding model\nweights, and Python code are available online.", "published": "2024-03-29 00:14:46", "link": "http://arxiv.org/abs/2403.19889v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MANGO: A Benchmark for Evaluating Mapping and Navigation Abilities of\n  Large Language Models", "abstract": "Large language models such as ChatGPT and GPT-4 have recently achieved\nastonishing performance on a variety of natural language processing tasks. In\nthis paper, we propose MANGO, a benchmark to evaluate their capabilities to\nperform text-based mapping and navigation. Our benchmark includes 53 mazes\ntaken from a suite of textgames: each maze is paired with a walkthrough that\nvisits every location but does not cover all possible paths. The task is\nquestion-answering: for each maze, a large language model reads the walkthrough\nand answers hundreds of mapping and navigation questions such as \"How should\nyou go to Attic from West of House?\" and \"Where are we if we go north and east\nfrom Cellar?\". Although these questions are easy to humans, it turns out that\neven GPT-4, the best-to-date language model, performs poorly at answering them.\nFurther, our experiments suggest that a strong mapping and navigation ability\nwould benefit large language models in performing relevant downstream tasks,\nsuch as playing textgames. Our MANGO benchmark will facilitate future research\non methods that improve the mapping and navigation capabilities of language\nmodels. We host our leaderboard, data, code, and evaluation program at\nhttps://mango.ttic.edu and https://github.com/oaklight/mango/.", "published": "2024-03-29 01:53:24", "link": "http://arxiv.org/abs/2403.19913v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.CL"}
{"title": "Enhancing the General Agent Capabilities of Low-Parameter LLMs through\n  Tuning and Multi-Branch Reasoning", "abstract": "Open-source pre-trained Large Language Models (LLMs) exhibit strong language\nunderstanding and generation capabilities, making them highly successful in a\nvariety of tasks. However, when used as agents for dealing with complex\nproblems in the real world, their performance is far inferior to large\ncommercial models such as ChatGPT and GPT-4. As intelligent agents, LLMs need\nto have the capabilities of task planning, long-term memory, and the ability to\nleverage external tools to achieve satisfactory performance. Various methods\nhave been proposed to enhance the agent capabilities of LLMs. On the one hand,\nmethods involve constructing agent-specific data and fine-tuning the models. On\nthe other hand, some methods focus on designing prompts that effectively\nactivate the reasoning abilities of the LLMs. We explore both strategies on the\n7B and 13B models. We propose a comprehensive method for constructing\nagent-specific data using GPT-4. Through supervised fine-tuning with\nconstructed data, we find that for these models with a relatively small number\nof parameters, supervised fine-tuning can significantly reduce hallucination\noutputs and formatting errors in agent tasks. Furthermore, techniques such as\nmulti-path reasoning and task decomposition can effectively decrease problem\ncomplexity and enhance the performance of LLMs as agents. We evaluate our\nmethod on five agent tasks of AgentBench and achieve satisfactory results.", "published": "2024-03-29 03:48:12", "link": "http://arxiv.org/abs/2403.19962v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Development of Compositionality and Generalization through Interactive\n  Learning of Language and Action of Robots", "abstract": "Humans excel at applying learned behavior to unlearned situations. A crucial\ncomponent of this generalization behavior is our ability to compose/decompose a\nwhole into reusable parts, an attribute known as compositionality. One of the\nfundamental questions in robotics concerns this characteristic. \"How can\nlinguistic compositionality be developed concomitantly with sensorimotor skills\nthrough associative learning, particularly when individuals only learn partial\nlinguistic compositions and their corresponding sensorimotor patterns?\" To\naddress this question, we propose a brain-inspired neural network model that\nintegrates vision, proprioception, and language into a framework of predictive\ncoding and active inference, based on the free-energy principle. The\neffectiveness and capabilities of this model were assessed through various\nsimulation experiments conducted with a robot arm. Our results show that\ngeneralization in learning to unlearned verb-noun compositions, is\nsignificantly enhanced when training variations of task composition are\nincreased. We attribute this to self-organized compositional structures in\nlinguistic latent state space being influenced significantly by sensorimotor\nlearning. Ablation studies show that visual attention and working memory are\nessential to accurately generate visuo-motor sequences to achieve\nlinguistically represented goals. These insights advance our understanding of\nmechanisms underlying development of compositionality through interactions of\nlinguistic and sensorimotor experience.", "published": "2024-03-29 06:22:37", "link": "http://arxiv.org/abs/2403.19995v2", "categories": ["cs.AI", "cs.CL", "cs.RO", "68T35, 68T40", "I.2.9"], "primary_category": "cs.AI"}
{"title": "PURPLE: Making a Large Language Model a Better SQL Writer", "abstract": "Large Language Model (LLM) techniques play an increasingly important role in\nNatural Language to SQL (NL2SQL) translation. LLMs trained by extensive corpora\nhave strong natural language understanding and basic SQL generation abilities\nwithout additional tuning specific to NL2SQL tasks. Existing LLMs-based NL2SQL\napproaches try to improve the translation by enhancing the LLMs with an\nemphasis on user intention understanding. However, LLMs sometimes fail to\ngenerate appropriate SQL due to their lack of knowledge in organizing complex\nlogical operator composition. A promising method is to input the LLMs with\ndemonstrations, which include known NL2SQL translations from various databases.\nLLMs can learn to organize operator compositions from the input demonstrations\nfor the given task. In this paper, we propose PURPLE (Pre-trained models\nUtilized to Retrieve Prompts for Logical Enhancement), which improves accuracy\nby retrieving demonstrations containing the requisite logical operator\ncomposition for the NL2SQL task on hand, thereby guiding LLMs to produce better\nSQL translation. PURPLE achieves a new state-of-the-art performance of 80.5%\nexact-set match accuracy and 87.8% execution match accuracy on the validation\nset of the popular NL2SQL benchmark Spider. PURPLE maintains high accuracy\nacross diverse benchmarks, budgetary constraints, and various LLMs, showing\nrobustness and cost-effectiveness.", "published": "2024-03-29 07:01:29", "link": "http://arxiv.org/abs/2403.20014v1", "categories": ["cs.DB", "cs.AI", "cs.CL"], "primary_category": "cs.DB"}
{"title": "RealKIE: Five Novel Datasets for Enterprise Key Information Extraction", "abstract": "We introduce RealKIE, a benchmark of five challenging datasets aimed at\nadvancing key information extraction methods, with an emphasis on enterprise\napplications. The datasets include a diverse range of documents including SEC\nS1 Filings, US Non-disclosure Agreements, UK Charity Reports, FCC Invoices, and\nResource Contracts. Each presents unique challenges: poor text serialization,\nsparse annotations in long documents, and complex tabular layouts. These\ndatasets provide a realistic testing ground for key information extraction\ntasks like investment analysis and legal data processing.\n  In addition to presenting these datasets, we offer an in-depth description of\nthe annotation process, document processing techniques, and baseline modeling\napproaches. This contribution facilitates the development of NLP models capable\nof handling practical challenges and supports further research into information\nextraction technologies applicable to industry-specific problems.\n  The annotated data and OCR outputs are available to download at\nhttps://indicodatasolutions.github.io/RealKIE/ code to reproduce the baselines\nwill be available shortly.", "published": "2024-03-29 10:31:32", "link": "http://arxiv.org/abs/2403.20101v1", "categories": ["cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Exploring Pathological Speech Quality Assessment with ASR-Powered\n  Wav2Vec2 in Data-Scarce Context", "abstract": "Automatic speech quality assessment has raised more attention as an\nalternative or support to traditional perceptual clinical evaluation. However,\nmost research so far only gains good results on simple tasks such as binary\nclassification, largely due to data scarcity. To deal with this challenge,\ncurrent works tend to segment patients' audio files into many samples to\naugment the datasets. Nevertheless, this approach has limitations, as it\nindirectly relates overall audio scores to individual segments. This paper\nintroduces a novel approach where the system learns at the audio level instead\nof segments despite data scarcity. This paper proposes to use the pre-trained\nWav2Vec2 architecture for both SSL, and ASR as feature extractor in speech\nassessment. Carried out on the HNC dataset, our ASR-driven approach established\na new baseline compared with other approaches, obtaining average $MSE=0.73$ and\n$MSE=1.15$ for the prediction of intelligibility and severity scores\nrespectively, using only 95 training samples. It shows that the ASR based\nWav2Vec2 model brings the best results and may indicate a strong correlation\nbetween ASR and speech quality assessment. We also measure its ability on\nvariable segment durations and speech content, exploring factors influencing\nits decision.", "published": "2024-03-29 13:59:34", "link": "http://arxiv.org/abs/2403.20184v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Using LLMs to Model the Beliefs and Preferences of Targeted Populations", "abstract": "We consider the problem of aligning a large language model (LLM) to model the\npreferences of a human population. Modeling the beliefs, preferences, and\nbehaviors of a specific population can be useful for a variety of different\napplications, such as conducting simulated focus groups for new products,\nconducting virtual surveys, and testing behavioral interventions, especially\nfor interventions that are expensive, impractical, or unethical. Existing work\nhas had mixed success using LLMs to accurately model human behavior in\ndifferent contexts. We benchmark and evaluate two well-known fine-tuning\napproaches and evaluate the resulting populations on their ability to match the\npreferences of real human respondents on a survey of preferences for battery\nelectric vehicles (BEVs). We evaluate our models against their ability to match\npopulation-wide statistics as well as their ability to match individual\nresponses, and we investigate the role of temperature in controlling the\ntrade-offs between these two. Additionally, we propose and evaluate a novel\nloss term to improve model performance on responses that require a numeric\nresponse.", "published": "2024-03-29 15:58:46", "link": "http://arxiv.org/abs/2403.20252v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ELITR-Bench: A Meeting Assistant Benchmark for Long-Context Language\n  Models", "abstract": "Research on Large Language Models (LLMs) has recently witnessed an increasing\ninterest in extending the models' context size to better capture dependencies\nwithin long documents. While benchmarks have been proposed to assess long-range\nabilities, existing efforts primarily considered generic tasks that are not\nnecessarily aligned with real-world applications. In contrast, we propose a new\nbenchmark for long-context LLMs focused on a practical meeting assistant\nscenario in which the long contexts consist of transcripts obtained by\nautomatic speech recognition, presenting unique challenges for LLMs due to the\ninherent noisiness and oral nature of such data. Our benchmark, ELITR-Bench,\naugments the existing ELITR corpus by adding 271 manually crafted questions\nwith their ground-truth answers, as well as noisy versions of meeting\ntranscripts altered to target different Word Error Rate levels. Our experiments\nwith 12 long-context LLMs on ELITR-Bench confirm the progress made across\nsuccessive generations of both proprietary and open models, and point out their\ndiscrepancies in terms of robustness to transcript noise. We also provide a\nthorough analysis of our GPT-4-based evaluation, including insights from a\ncrowdsourcing study. Our findings indicate that while GPT-4's scores align with\nhuman judges, its ability to distinguish beyond three score levels may be\nlimited.", "published": "2024-03-29 16:13:31", "link": "http://arxiv.org/abs/2403.20262v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Latxa: An Open Language Model and Evaluation Suite for Basque", "abstract": "We introduce Latxa, a family of large language models for Basque ranging from\n7 to 70 billion parameters. Latxa is based on Llama 2, which we continue\npretraining on a new Basque corpus comprising 4.3M documents and 4.2B tokens.\nAddressing the scarcity of high-quality benchmarks for Basque, we further\nintroduce 4 multiple choice evaluation datasets: EusProficiency, comprising\n5,169 questions from official language proficiency exams; EusReading,\ncomprising 352 reading comprehension questions; EusTrivia, comprising 1,715\ntrivia questions from 5 knowledge areas; and EusExams, comprising 16,774\nquestions from public examinations. In our extensive evaluation, Latxa\noutperforms all previous open models we compare to by a large margin. In\naddition, it is competitive with GPT-4 Turbo in language proficiency and\nunderstanding, despite lagging behind in reading comprehension and\nknowledge-intensive tasks. Both the Latxa family of models, as well as our new\npretraining corpora and evaluation datasets, are publicly available under open\nlicenses. Our suite enables reproducible research on methods to build LLMs for\nlow-resource languages.", "published": "2024-03-29 16:16:48", "link": "http://arxiv.org/abs/2403.20266v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Emotion-Anchored Contrastive Learning Framework for Emotion Recognition\n  in Conversation", "abstract": "Emotion Recognition in Conversation (ERC) involves detecting the underlying\nemotion behind each utterance within a conversation. Effectively generating\nrepresentations for utterances remains a significant challenge in this task.\nRecent works propose various models to address this issue, but they still\nstruggle with differentiating similar emotions such as excitement and\nhappiness. To alleviate this problem, We propose an Emotion-Anchored\nContrastive Learning (EACL) framework that can generate more distinguishable\nutterance representations for similar emotions. To achieve this, we utilize\nlabel encodings as anchors to guide the learning of utterance representations\nand design an auxiliary loss to ensure the effective separation of anchors for\nsimilar emotions. Moreover, an additional adaptation process is proposed to\nadapt anchors to serve as effective classifiers to improve classification\nperformance. Across extensive experiments, our proposed EACL achieves\nstate-of-the-art emotion recognition performance and exhibits superior\nperformance on similar emotions. Our code is available at\nhttps://github.com/Yu-Fangxu/EACL.", "published": "2024-03-29 17:00:55", "link": "http://arxiv.org/abs/2403.20289v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "ReALM: Reference Resolution As Language Modeling", "abstract": "Reference resolution is an important problem, one that is essential to\nunderstand and successfully handle context of different kinds. This context\nincludes both previous turns and context that pertains to non-conversational\nentities, such as entities on the user's screen or those running in the\nbackground. While LLMs have been shown to be extremely powerful for a variety\nof tasks, their use in reference resolution, particularly for\nnon-conversational entities, remains underutilized. This paper demonstrates how\nLLMs can be used to create an extremely effective system to resolve references\nof various types, by showing how reference resolution can be converted into a\nlanguage modeling problem, despite involving forms of entities like those on\nscreen that are not traditionally conducive to being reduced to a text-only\nmodality. We demonstrate large improvements over an existing system with\nsimilar functionality across different types of references, with our smallest\nmodel obtaining absolute gains of over 5% for on-screen references. We also\nbenchmark against GPT-3.5 and GPT-4, with our smallest model achieving\nperformance comparable to that of GPT-4, and our larger models substantially\noutperforming it.", "published": "2024-03-29 17:59:06", "link": "http://arxiv.org/abs/2403.20329v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unsolvable Problem Detection: Robust Understanding Evaluation for Large\n  Multimodal Models", "abstract": "This paper introduces a novel task to evaluate the robust understanding\ncapability of Large Multimodal Models (LMMs), termed $\\textbf{Unsolvable\nProblem Detection (UPD)}$. Multiple-choice question answering (MCQA) is widely\nused to assess the understanding capability of LMMs, but it does not guarantee\nthat LMMs truly comprehend the answer. UPD assesses the LMM's ability to\nwithhold answers when encountering unsolvable problems of MCQA, verifying\nwhether the model truly understands the answer. UPD encompasses three problems:\nAbsent Answer Detection (AAD), Incompatible Answer Set Detection (IASD), and\nIncompatible Visual Question Detection (IVQD), covering unsolvable cases like\nanswer-lacking or incompatible choices and image-question mismatches. For the\nevaluation, we introduce the MM-UPD Bench, a benchmark for assessing\nperformance across various ability dimensions. Our experiments reveal that even\nmost LMMs, which demonstrate adequate performance on existing benchmarks,\nstruggle significantly with MM-UPD, underscoring a novel aspect of\ntrustworthiness that current benchmarks have overlooked. A detailed analysis\nshows that LMMs have different bottlenecks and chain-of-thought and\nself-reflection improved performance for LMMs with the bottleneck in their LLM\ncapability. We hope our insights will enhance the broader understanding and\ndevelopment of more reliable LMMs.", "published": "2024-03-29 17:59:53", "link": "http://arxiv.org/abs/2403.20331v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Where Are You From? Let Me Guess! Subdialect Recognition of Speeches in\n  Sorani Kurdish", "abstract": "Classifying Sorani Kurdish subdialects poses a challenge due to the need for\npublicly available datasets or reliable resources like social media or websites\nfor data collection. We conducted field visits to various cities and villages\nto address this issue, connecting with native speakers from different age\ngroups, genders, academic backgrounds, and professions. We recorded their\nvoices while engaging in conversations covering diverse topics such as\nlifestyle, background history, hobbies, interests, vacations, and life lessons.\nThe target area of the research was the Kurdistan Region of Iraq. As a result,\nwe accumulated 29 hours, 16 minutes, and 40 seconds of audio recordings from\n107 interviews, constituting an unbalanced dataset encompassing six\nsubdialects. Subsequently, we adapted three deep learning models: ANN, CNN, and\nRNN-LSTM. We explored various configurations, including different track\ndurations, dataset splitting, and imbalanced dataset handling techniques such\nas oversampling and undersampling. Two hundred and twenty-five(225) experiments\nwere conducted, and the outcomes were evaluated. The results indicated that the\nRNN-LSTM outperforms the other methods by achieving an accuracy of 96%. CNN\nachieved an accuracy of 93%, and ANN 75%. All three models demonstrated\nimproved performance when applied to balanced datasets, primarily when we\nfollowed the oversampling approach. Future studies can explore additional\nfuture research directions to include other Kurdish dialects.", "published": "2024-03-29 19:27:04", "link": "http://arxiv.org/abs/2404.00124v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Entertainment chatbot for the digital inclusion of elderly people\n  without abstraction capabilities", "abstract": "Current language processing technologies allow the creation of conversational\nchatbot platforms. Even though artificial intelligence is still too immature to\nsupport satisfactory user experience in many mass market domains,\nconversational interfaces have found their way into ad hoc applications such as\ncall centres and online shopping assistants. However, they have not been\napplied so far to social inclusion of elderly people, who are particularly\nvulnerable to the digital divide. Many of them relieve their loneliness with\ntraditional media such as TV and radio, which are known to create a feeling of\ncompanionship. In this paper we present the EBER chatbot, designed to reduce\nthe digital gap for the elderly. EBER reads news in the background and adapts\nits responses to the user's mood. Its novelty lies in the concept of\n\"intelligent radio\", according to which, instead of simplifying a digital\ninformation system to make it accessible to the elderly, a traditional channel\nthey find familiar -- background news -- is augmented with interactions via\nvoice dialogues. We make it possible by combining Artificial Intelligence\nModelling Language, automatic Natural Language Generation and Sentiment\nAnalysis. The system allows accessing digital content of interest by combining\nwords extracted from user answers to chatbot questions with keywords extracted\nfrom the news items. This approach permits defining metrics of the abstraction\ncapabilities of the users depending on a spatial representation of the word\nspace. To prove the suitability of the proposed solution we present results of\nreal experiments conducted with elderly people that provided valuable insights.\nOur approach was considered satisfactory during the tests and improved the\ninformation search capabilities of the participants.", "published": "2024-03-29 12:10:21", "link": "http://arxiv.org/abs/2404.01327v1", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Explaining Large Language Models Decisions Using Shapley Values", "abstract": "The emergence of large language models (LLMs) has opened up exciting\npossibilities for simulating human behavior and cognitive processes, with\npotential applications in various domains, including marketing research and\nconsumer behavior analysis. However, the validity of utilizing LLMs as\nstand-ins for human subjects remains uncertain due to glaring divergences that\nsuggest fundamentally different underlying processes at play and the\nsensitivity of LLM responses to prompt variations. This paper presents a novel\napproach based on Shapley values from cooperative game theory to interpret LLM\nbehavior and quantify the relative contribution of each prompt component to the\nmodel's output. Through two applications - a discrete choice experiment and an\ninvestigation of cognitive biases - we demonstrate how the Shapley value method\ncan uncover what we term \"token noise\" effects, a phenomenon where LLM\ndecisions are disproportionately influenced by tokens providing minimal\ninformative content. This phenomenon raises concerns about the robustness and\ngeneralizability of insights obtained from LLMs in the context of human\nbehavior simulation. Our model-agnostic approach extends its utility to\nproprietary LLMs, providing a valuable tool for practitioners and researchers\nto strategically optimize prompts and mitigate apparent cognitive biases. Our\nfindings underscore the need for a more nuanced understanding of the factors\ndriving LLM responses before relying on them as substitutes for human subjects\nin survey settings. We emphasize the importance of researchers reporting\nresults conditioned on specific prompt templates and exercising caution when\ndrawing parallels between human behavior and LLMs.", "published": "2024-03-29 22:49:43", "link": "http://arxiv.org/abs/2404.01332v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Backdoor Approach with Inverted Labels Using Dirty Label-Flipping\n  Attacks", "abstract": "Audio-based machine learning systems frequently use public or third-party\ndata, which might be inaccurate. This exposes deep neural network (DNN) models\ntrained on such data to potential data poisoning attacks. In this type of\nassault, attackers can train the DNN model using poisoned data, potentially\ndegrading its performance. Another type of data poisoning attack that is\nextremely relevant to our investigation is label flipping, in which the\nattacker manipulates the labels for a subset of data. It has been demonstrated\nthat these assaults may drastically reduce system performance, even for\nattackers with minimal abilities. In this study, we propose a backdoor attack\nnamed 'DirtyFlipping', which uses dirty label techniques, \"label-on-label\", to\ninput triggers (clapping) in the selected data patterns associated with the\ntarget class, thereby enabling a stealthy backdoor.", "published": "2024-03-29 00:09:48", "link": "http://arxiv.org/abs/2404.00076v2", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG", "eess.SP"], "primary_category": "cs.CR"}
{"title": "Identifying Banking Transaction Descriptions via Support Vector Machine\n  Short-Text Classification Based on a Specialized Labelled Corpus", "abstract": "Short texts are omnipresent in real-time news, social network commentaries,\netc. Traditional text representation methods have been successfully applied to\nself-contained documents of medium size. However, information in short texts is\noften insufficient, due, for example, to the use of mnemonics, which makes them\nhard to classify. Therefore, the particularities of specific domains must be\nexploited. In this article we describe a novel system that combines Natural\nLanguage Processing techniques with Machine Learning algorithms to classify\nbanking transaction descriptions for personal finance management, a problem\nthat was not previously considered in the literature. We trained and tested\nthat system on a labelled dataset with real customer transactions that will be\navailable to other researchers on request. Motivated by existing solutions in\nspam detection, we also propose a short text similarity detector to reduce\ntraining set size based on the Jaccard distance. Experimental results with a\ntwo-stage classifier combining this detector with a SVM indicate a high\naccuracy in comparison with alternative approaches, taking into account\ncomplexity and computing time. Finally, we present a use case with a personal\nfinance application, CoinScrap, which is available at Google Play and App\nStore.", "published": "2024-03-29 13:15:46", "link": "http://arxiv.org/abs/2404.08664v1", "categories": ["cs.IR", "cs.AI", "cs.CE", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Non-Exponential Reverberation Modeling Using Dark Velvet Noise", "abstract": "Previous research on late-reverberation modeling has mainly focused on\nexponentially decaying room impulse responses, whereas methods for accurately\nmodeling non-exponential reverberation remain challenging. This paper extends\nthe previously proposed basic dark-velvet-noise reverberation algorithm and\nproposes a parametrization scheme for modeling late reverberation with\narbitrary temporal energy decay. Each pulse in the velvet-noise sequence is\nrouted to a single dictionary filter that is selected from a set of filters\nbased on weighted probabilities. The probabilities control the spectral\nevolution of the late-reverberation model and are optimized to fit a target\nimpulse response via non-negative least-squares optimization. In this way, the\nfrequency-dependent energy decay of a target late-reverberation impulse\nresponse can be fitted with mean and maximum T60 errors of 4% and 8%,\nrespectively, requiring about 50% less coloration filters than a previously\nproposed filtered velvet-noise algorithm. Furthermore, the extended\ndark-velvet-noise reverberation algorithm allows the modeled impulse response\nto be gated, the frequency-dependent reverberation time to be modified, and the\nmodel's spectral evolution and broadband decay to be decoupled. The proposed\nmethod is suitable for the parametric late-reverberation synthesis of various\nacoustic environments, especially spaces that exhibit a non-exponential energy\ndecay, motivating its use in musical audio and virtual reality.", "published": "2024-03-29 09:54:37", "link": "http://arxiv.org/abs/2403.20090v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "3D-Speaker-Toolkit: An Open-Source Toolkit for Multimodal Speaker\n  Verification and Diarization", "abstract": "We introduce 3D-Speaker-Toolkit, an open-source toolkit for multimodal\nspeaker verification and diarization, designed for meeting the needs of\nacademic researchers and industrial practitioners. The 3D-Speaker-Toolkit\nadeptly leverages the combined strengths of acoustic, semantic, and visual\ndata, seamlessly fusing these modalities to offer robust speaker recognition\ncapabilities. The acoustic module extracts speaker embeddings from acoustic\nfeatures, employing both fully-supervised and self-supervised learning\napproaches. The semantic module leverages advanced language models to\ncomprehend the substance and context of spoken language, thereby augmenting the\nsystem's proficiency in distinguishing speakers through linguistic patterns.\nThe visual module applies image processing technologies to scrutinize facial\nfeatures, which bolsters the precision of speaker diarization in multi-speaker\nenvironments. Collectively, these modules empower the 3D-Speaker-Toolkit to\nachieve substantially improved accuracy and reliability in speaker-related\ntasks. With 3D-Speaker-Toolkit, we establish a new benchmark for multimodal\nspeaker analysis. The toolkit also includes a handful of open-source\nstate-of-the-art models and a large-scale dataset containing over 10,000\nspeakers. The toolkit is publicly available at\nhttps://github.com/modelscope/3D-Speaker.", "published": "2024-03-29 04:42:12", "link": "http://arxiv.org/abs/2403.19971v3", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Sound event localization and classification using WASN in Outdoor\n  Environment", "abstract": "Deep learning-based sound event localization and classification is an\nemerging research area within wireless acoustic sensor networks. However,\ncurrent methods for sound event localization and classification typically rely\non a single microphone array, making them susceptible to signal attenuation and\nenvironmental noise, which limits their monitoring range. Moreover, methods\nusing multiple microphone arrays often focus solely on source localization,\nneglecting the aspect of sound event classification. In this paper, we propose\na deep learning-based method that employs multiple features and attention\nmechanisms to estimate the location and class of sound source. We introduce a\nSoundmap feature to capture spatial information across multiple frequency\nbands. We also use the Gammatone filter to generate acoustic features more\nsuitable for outdoor environments. Furthermore, we integrate attention\nmechanisms to learn channel-wise relationships and temporal dependencies within\nthe acoustic features. To evaluate our proposed method, we conduct experiments\nusing simulated datasets with different levels of noise and size of monitoring\nareas, as well as different arrays and source positions. The experimental\nresults demonstrate the superiority of our proposed method over\nstate-of-the-art methods in both sound event classification and sound source\nlocalization tasks. And we provide further analysis to explain the reasons for\nthe observed errors.", "published": "2024-03-29 11:44:14", "link": "http://arxiv.org/abs/2403.20130v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Voice Signal Processing for Machine Learning. The Case of Speaker\n  Isolation", "abstract": "The widespread use of automated voice assistants along with other recent\ntechnological developments have increased the demand for applications that\nprocess audio signals and human voice in particular. Voice recognition tasks\nare typically performed using artificial intelligence and machine learning\nmodels. Even though end-to-end models exist, properly pre-processing the signal\ncan greatly reduce the complexity of the task and allow it to be solved with a\nsimpler ML model and fewer computational resources. However, ML engineers who\nwork on such tasks might not have a background in signal processing which is an\nentirely different area of expertise.\n  The objective of this work is to provide a concise comparative analysis of\nFourier and Wavelet transforms that are most commonly used as signal\ndecomposition methods for audio processing tasks. Metrics for evaluating speech\nintelligibility are also discussed, namely Scale-Invariant Signal-to-Distortion\nRatio (SI-SDR), Perceptual Evaluation of Speech Quality (PESQ), and Short-Time\nObjective Intelligibility (STOI). The level of detail in the exposition is\nmeant to be sufficient for an ML engineer to make informed decisions when\nchoosing, fine-tuning, and evaluating a decomposition method for a specific ML\nmodel. The exposition contains mathematical definitions of the relevant\nconcepts accompanied with intuitive non-mathematical explanations in order to\nmake the text more accessible to engineers without deep expertise in signal\nprocessing. Formal mathematical definitions and proofs of theorems are\nintentionally omitted in order to keep the text concise.", "published": "2024-03-29 14:31:36", "link": "http://arxiv.org/abs/2403.20202v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Data-Driven Room Acoustic Modeling Via Differentiable Feedback Delay\n  Networks With Learnable Delay Lines", "abstract": "Over the past few decades, extensive research has been devoted to the design\nof artificial reverberation algorithms aimed at emulating the room acoustics of\nphysical environments. Despite significant advancements, automatic parameter\ntuning of delay-network models remains an open challenge. We introduce a novel\nmethod for finding the parameters of a Feedback Delay Network (FDN) such that\nits output renders target attributes of a measured room impulse response. The\nproposed approach involves the implementation of a differentiable FDN with\ntrainable delay lines, which, for the first time, allows us to simultaneously\nlearn each and every delay-network parameter via backpropagation. The iterative\noptimization process seeks to minimize a perceptually-motivated time-domain\nloss function incorporating differentiable terms accounting for energy decay\nand echo density. Through experimental validation, we show that the proposed\nmethod yields time-invariant frequency-independent FDNs capable of closely\nmatching the desired acoustical characteristics, and outperforms existing\nmethods based on genetic algorithms and analytical FDN design.", "published": "2024-03-29 10:48:32", "link": "http://arxiv.org/abs/2404.00082v4", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
