{"title": "One Sentence One Model for Neural Machine Translation", "abstract": "Neural machine translation (NMT) becomes a new state-of-the-art and achieves\npromising translation results using a simple encoder-decoder neural network.\nThis neural network is trained once on the parallel corpus and the fixed\nnetwork is used to translate all the test sentences. We argue that the general\nfixed network cannot best fit the specific test sentences. In this paper, we\npropose the dynamic NMT which learns a general network as usual, and then\nfine-tunes the network for each test sentence. The fine-tune work is done on a\nsmall set of the bilingual training data that is obtained through similarity\nsearch according to the test sentence. Extensive experiments demonstrate that\nthis method can significantly improve the translation performance, especially\nwhen highly similar sentences are available.", "published": "2016-09-21 10:28:57", "link": "http://arxiv.org/abs/1609.06490v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Weakly supervised spoken term discovery using cross-lingual side\n  information", "abstract": "Recent work on unsupervised term discovery (UTD) aims to identify and cluster\nrepeated word-like units from audio alone. These systems are promising for some\nvery low-resource languages where transcribed audio is unavailable, or where no\nwritten form of the language exists. However, in some cases it may still be\nfeasible (e.g., through crowdsourcing) to obtain (possibly noisy) text\ntranslations of the audio. If so, this information could be used as a source of\nside information to improve UTD. Here, we present a simple method for rescoring\nthe output of a UTD system using text translations, and test it on a corpus of\nSpanish audio with English translations. We show that it greatly improves the\naverage precision of the results over a wide range of system configurations and\ndata preprocessing methods.", "published": "2016-09-21 12:43:53", "link": "http://arxiv.org/abs/1609.06530v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semi-supervised knowledge extraction for detection of drugs and their\n  effects", "abstract": "New Psychoactive Substances (NPS) are drugs that lay in a grey area of\nlegislation, since they are not internationally and officially banned, possibly\nleading to their not prosecutable trade. The exacerbation of the phenomenon is\nthat NPS can be easily sold and bought online. Here, we consider large corpora\nof textual posts, published on online forums specialized on drug discussions,\nplus a small set of known substances and associated effects, which we call\nseeds. We propose a semi-supervised approach to knowledge extraction, applied\nto the detection of drugs (comprising NPS) and effects from the corpora under\ninvestigation. Based on the very small set of initial seeds, the work\nhighlights how a contrastive approach and context deduction are effective in\ndetecting substances and effects from the corpora. Our promising results, which\nfeature a F1 score close to 0.9, pave the way for shortening the detection time\nof new psychoactive substances, once these are discussed and advertised on the\nInternet.", "published": "2016-09-21 14:24:44", "link": "http://arxiv.org/abs/1609.06577v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Minimally Supervised Written-to-Spoken Text Normalization", "abstract": "In speech-applications such as text-to-speech (TTS) or automatic speech\nrecognition (ASR), \\emph{text normalization} refers to the task of converting\nfrom a \\emph{written} representation into a representation of how the text is\nto be \\emph{spoken}. In all real-world speech applications, the text\nnormalization engine is developed---in large part---by hand. For example, a\nhand-built grammar may be used to enumerate the possible ways of saying a given\ntoken in a given language, and a statistical model used to select the most\nappropriate pronunciation in context. In this study we examine the tradeoffs\nassociated with using more or less language-specific domain knowledge in a text\nnormalization engine. In the most data-rich scenario, we have access to a\ncarefully constructed hand-built normalization grammar that for any given token\nwill produce a set of all possible verbalizations for that token. We also\nassume a corpus of aligned written-spoken utterances, from which we can train a\nranking model that selects the appropriate verbalization for the given context.\nAs a substitute for the carefully constructed grammar, we also consider a\nscenario with a language-universal normalization \\emph{covering grammar}, where\nthe developer merely needs to provide a set of lexical items particular to the\nlanguage. As a substitute for the aligned corpus, we also consider a scenario\nwhere one only has the spoken side, and the corresponding written side is\n\"hallucinated\" by composing the spoken side with the inverted normalization\ngrammar. We investigate the accuracy of a text normalization engine under each\nof these scenarios. We report the results of experiments on English and\nRussian.", "published": "2016-09-21 17:51:11", "link": "http://arxiv.org/abs/1609.06649v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Joint CTC-Attention based End-to-End Speech Recognition using Multi-task\n  Learning", "abstract": "Recently, there has been an increasing interest in end-to-end speech\nrecognition that directly transcribes speech to text without any predefined\nalignments. One approach is the attention-based encoder-decoder framework that\nlearns a mapping between variable-length input and output sequences in one step\nusing a purely data-driven method. The attention model has often been shown to\nimprove the performance over another end-to-end approach, the Connectionist\nTemporal Classification (CTC), mainly because it explicitly uses the history of\nthe target character without any conditional independence assumptions. However,\nwe observed that the performance of the attention has shown poor results in\nnoisy condition and is hard to learn in the initial training stage with long\ninput sequences. This is because the attention model is too flexible to predict\nproper alignments in such cases due to the lack of left-to-right constraints as\nused in CTC. This paper presents a novel method for end-to-end speech\nrecognition to improve robustness and achieve fast convergence by using a joint\nCTC-attention model within the multi-task learning framework, thereby\nmitigating the alignment issue. An experiment on the WSJ and CHiME-4 tasks\ndemonstrates its advantages over both the CTC and attention-based\nencoder-decoder baselines, showing 5.4-14.6% relative improvements in Character\nError Rate (CER).", "published": "2016-09-21 22:48:53", "link": "http://arxiv.org/abs/1609.06773v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KU-ISPL Language Recognition System for NIST 2015 i-Vector Machine\n  Learning Challenge", "abstract": "In language recognition, the task of rejecting/differentiating closely spaced\nversus acoustically far spaced languages remains a major challenge. For\nconfusable closely spaced languages, the system needs longer input test\nduration material to obtain sufficient information to distinguish between\nlanguages. Alternatively, if languages are distinct and not\nacoustically/linguistically similar to others, duration is not a sufficient\nremedy. The solution proposed here is to explore duration distribution analysis\nfor near/far languages based on the Language Recognition i-Vector Machine\nLearning Challenge 2015 (LRiMLC15) database. Using this knowledge, we propose a\nlikelihood ratio based fusion approach that leveraged both score and duration\ninformation. The experimental results show that the use of duration and score\nfusion improves language recognition performance by 5% relative in LRiMLC15\ncost.", "published": "2016-09-21 02:14:23", "link": "http://arxiv.org/abs/1609.06404v1", "categories": ["cs.SD", "cs.CL"], "primary_category": "cs.SD"}
{"title": "The Color of the Cat is Gray: 1 Million Full-Sentences Visual Question\n  Answering (FSVQA)", "abstract": "Visual Question Answering (VQA) task has showcased a new stage of interaction\nbetween language and vision, two of the most pivotal components of artificial\nintelligence. However, it has mostly focused on generating short and repetitive\nanswers, mostly single words, which fall short of rich linguistic capabilities\nof humans. We introduce Full-Sentence Visual Question Answering (FSVQA)\ndataset, consisting of nearly 1 million pairs of questions and full-sentence\nanswers for images, built by applying a number of rule-based natural language\nprocessing techniques to original VQA dataset and captions in the MS COCO\ndataset. This poses many additional complexities to conventional VQA task, and\nwe provide a baseline for approaching and evaluating the task, on top of which\nwe invite the research community to build further improvements.", "published": "2016-09-21 18:12:04", "link": "http://arxiv.org/abs/1609.06657v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Character-level and Multi-channel Convolutional Neural Networks for\n  Large-scale Authorship Attribution", "abstract": "Convolutional neural networks (CNNs) have demonstrated superior capability\nfor extracting information from raw signals in computer vision. Recently,\ncharacter-level and multi-channel CNNs have exhibited excellent performance for\nsentence classification tasks. We apply CNNs to large-scale authorship\nattribution, which aims to determine an unknown text's author among many\ncandidate authors, motivated by their ability to process character-level\nsignals and to differentiate between a large number of classes, while making\nfast predictions in comparison to state-of-the-art approaches. We extensively\nevaluate CNN-based approaches that leverage word and character channels and\ncompare them against state-of-the-art methods for a large range of author\nnumbers, shedding new light on traditional approaches. We show that\ncharacter-level CNNs outperform the state-of-the-art on four out of five\ndatasets in different domains. Additionally, we present the first application\nof authorship attribution to reddit.", "published": "2016-09-21 19:08:15", "link": "http://arxiv.org/abs/1609.06686v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Twitter Opinion Topic Model: Extracting Product Opinions from Tweets by\n  Leveraging Hashtags and Sentiment Lexicon", "abstract": "Aspect-based opinion mining is widely applied to review data to aggregate or\nsummarize opinions of a product, and the current state-of-the-art is achieved\nwith Latent Dirichlet Allocation (LDA)-based model. Although social media data\nlike tweets are laden with opinions, their \"dirty\" nature (as natural language)\nhas discouraged researchers from applying LDA-based opinion model for product\nreview mining. Tweets are often informal, unstructured and lacking labeled data\nsuch as categories and ratings, making it challenging for product opinion\nmining. In this paper, we propose an LDA-based opinion model named Twitter\nOpinion Topic Model (TOTM) for opinion mining and sentiment analysis. TOTM\nleverages hashtags, mentions, emoticons and strong sentiment words that are\npresent in tweets in its discovery process. It improves opinion prediction by\nmodeling the target-opinion interaction directly, thus discovering target\nspecific opinion words, neglected in existing approaches. Moreover, we propose\na new formulation of incorporating sentiment prior information into a topic\nmodel, by utilizing an existing public sentiment lexicon. This is novel in that\nit learns and updates with the data. We conduct experiments on 9 million tweets\non electronic products, and demonstrate the improved performance of TOTM in\nboth quantitative evaluations and qualitative analysis. We show that\naspect-based opinion analysis on massive volume of tweets provides useful\nopinions on products.", "published": "2016-09-21 14:25:23", "link": "http://arxiv.org/abs/1609.06578v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Gov2Vec: Learning Distributed Representations of Institutions and Their\n  Legal Text", "abstract": "We compare policy differences across institutions by embedding\nrepresentations of the entire legal corpus of each institution and the\nvocabulary shared across all corpora into a continuous vector space. We apply\nour method, Gov2Vec, to Supreme Court opinions, Presidential actions, and\nofficial summaries of Congressional bills. The model discerns meaningful\ndifferences between government branches. We also learn representations for more\nfine-grained word sources: individual Presidents and (2-year) Congresses. The\nsimilarities between learned representations of Congresses over time and\nsitting Presidents are negatively correlated with the bill veto rate, and the\ntemporal ordering of Presidents and Congresses was implicitly learned from only\ntext. With the resulting vectors we answer questions such as: how does Obama\nand the 113th House differ in addressing climate change and how does this vary\nfrom environmental or economic perspectives? Our work illustrates\nvector-arithmetic-based investigations of complex relationships between word\nsources based on their texts. We are extending this to create a more\ncomprehensive legal semantic map.", "published": "2016-09-21 16:09:12", "link": "http://arxiv.org/abs/1609.06616v2", "categories": ["cs.CL", "cs.IR", "cs.NE", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Document Image Coding and Clustering for Script Discrimination", "abstract": "The paper introduces a new method for discrimination of documents given in\ndifferent scripts. The document is mapped into a uniformly coded text of\nnumerical values. It is derived from the position of the letters in the text\nline, based on their typographical characteristics. Each code is considered as\na gray level. Accordingly, the coded text determines a 1-D image, on which\ntexture analysis by run-length statistics and local binary pattern is\nperformed. It defines feature vectors representing the script content of the\ndocument. A modified clustering approach employed on document feature vector\ngroups documents written in the same script. Experimentation performed on two\ncustom oriented databases of historical documents in old Cyrillic, angular and\nround Glagolitic as well as Antiqua and Fraktur scripts demonstrates the\nsuperiority of the proposed method with respect to well-known methods in the\nstate-of-the-art.", "published": "2016-09-21 10:52:03", "link": "http://arxiv.org/abs/1609.06492v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.NE", "97R40, 62H35, 68U15, 68T50,"], "primary_category": "cs.CV"}
