{"title": "Plausibility Vaccine: Injecting LLM Knowledge for Event Plausibility", "abstract": "Despite advances in language modelling, distributional methods that build\nsemantic representations from co-occurrences fail to discriminate between\nplausible and implausible events. In this work, we investigate how plausibility\nprediction can be improved by injecting latent knowledge prompted from large\nlanguage models using parameter-efficient fine-tuning. We train 12 task\nadapters to learn various physical properties and association measures and\nperform adapter fusion to compose latent semantic knowledge from each task on\ntop of pre-trained AlBERT embeddings. We automate auxiliary task data\ngeneration, which enables us to scale our approach and fine-tune our learned\nrepresentations across two plausibility datasets. Our code is available at\nhttps://github.com/Jacob-Chmura/plausibility-vaccine.", "published": "2025-03-16 21:55:17", "link": "http://arxiv.org/abs/2503.12667v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Logic-RAG: Augmenting Large Multimodal Models with Visual-Spatial Knowledge for Road Scene Understanding", "abstract": "Large multimodal models (LMMs) are increasingly integrated into autonomous\ndriving systems for user interaction. However, their limitations in\nfine-grained spatial reasoning pose challenges for system interpretability and\nuser trust. We introduce Logic-RAG, a novel Retrieval-Augmented Generation\n(RAG) framework that improves LMMs' spatial understanding in driving scenarios.\nLogic-RAG constructs a dynamic knowledge base (KB) about object-object\nrelationships in first-order logic (FOL) using a perception module, a\nquery-to-logic embedder, and a logical inference engine. We evaluated Logic-RAG\non visual-spatial queries using both synthetic and real-world driving videos.\nWhen using popular LMMs (GPT-4V, Claude 3.5) as proxies for an autonomous\ndriving system, these models achieved only 55% accuracy on synthetic driving\nscenes and under 75% on real-world driving scenes. Augmenting them with\nLogic-RAG increased their accuracies to over 80% and 90%, respectively. An\nablation study showed that even without logical inference, the fact-based\ncontext constructed by Logic-RAG alone improved accuracy by 15%. Logic-RAG is\nextensible: it allows seamless replacement of individual components with\nimproved versions and enables domain experts to compose new knowledge in both\nFOL and natural language. In sum, Logic-RAG addresses critical spatial\nreasoning deficiencies in LMMs for autonomous driving applications. Code and\ndata are available at https://github.com/Imran2205/LogicRAG.", "published": "2025-03-16 21:36:36", "link": "http://arxiv.org/abs/2503.12663v1", "categories": ["cs.CV", "cs.CL", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "VeriLA: A Human-Centered Evaluation Framework for Interpretable Verification of LLM Agent Failures", "abstract": "AI practitioners increasingly use large language model (LLM) agents in\ncompound AI systems to solve complex reasoning tasks, these agent executions\noften fail to meet human standards, leading to errors that compromise the\nsystem's overall performance. Addressing these failures through human\nintervention is challenging due to the agents' opaque reasoning processes,\nmisalignment with human expectations, the complexity of agent dependencies, and\nthe high cost of manual inspection. This paper thus introduces a human-centered\nevaluation framework for Verifying LLM Agent failures (VeriLA), which\nsystematically assesses agent failures to reduce human effort and make these\nagent failures interpretable to humans. The framework first defines clear\nexpectations of each agent by curating human-designed agent criteria. Then, it\ndevelops a human-aligned agent verifier module, trained with human gold\nstandards, to assess each agent's execution output. This approach enables\ngranular evaluation of each agent's performance by revealing failures from a\nhuman standard, offering clear guidelines for revision, and reducing human\ncognitive load. Our case study results show that VeriLA is both interpretable\nand efficient in helping practitioners interact more effectively with the\nsystem. By upholding accountability in human-agent collaboration, VeriLA paves\nthe way for more trustworthy and human-aligned compound AI systems.", "published": "2025-03-16 21:11:18", "link": "http://arxiv.org/abs/2503.12651v1", "categories": ["cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.AI"}
{"title": "LLM-Mediated Guidance of MARL Systems", "abstract": "In complex multi-agent environments, achieving efficient learning and\ndesirable behaviours is a significant challenge for Multi-Agent Reinforcement\nLearning (MARL) systems. This work explores the potential of combining MARL\nwith Large Language Model (LLM)-mediated interventions to guide agents toward\nmore desirable behaviours. Specifically, we investigate how LLMs can be used to\ninterpret and facilitate interventions that shape the learning trajectories of\nmultiple agents. We experimented with two types of interventions, referred to\nas controllers: a Natural Language (NL) Controller and a Rule-Based (RB)\nController. The NL Controller, which uses an LLM to simulate human-like\ninterventions, showed a stronger impact than the RB Controller. Our findings\nindicate that agents particularly benefit from early interventions, leading to\nmore efficient training and higher performance. Both intervention types\noutperform the baseline without interventions, highlighting the potential of\nLLM-mediated guidance to accelerate training and enhance MARL performance in\nchallenging environments.", "published": "2025-03-16 20:16:13", "link": "http://arxiv.org/abs/2503.13553v1", "categories": ["cs.MA", "cs.AI", "cs.CL"], "primary_category": "cs.MA"}
{"title": "Online Misinformation Detection in Live Streaming Videos", "abstract": "Online misinformation detection is an important issue and methods are\nproposed to detect and curb misinformation in various forms. However, previous\nstudies are conducted in an offline manner. We claim a realistic misinformation\ndetection setting that has not been studied yet is online misinformation\ndetection in live streaming videos (MDLS). In the proposal, we formulate the\nproblem of MDLS and illustrate the importance and the challenge of the task.\nBesides, we propose feasible ways of developing the problem into AI challenges\nas well as potential solutions to the problem.", "published": "2025-03-16 19:43:25", "link": "http://arxiv.org/abs/2503.12627v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "UniBERTs: Adversarial Training for Language-Universal Representations", "abstract": "This paper presents UniBERT, a compact multilingual language model that\nleverages an innovative training framework integrating three components: masked\nlanguage modeling, adversarial training, and knowledge distillation.\nPre-trained on a meticulously curated Wikipedia corpus spanning 107 languages,\nUniBERT is designed to reduce the computational demands of large-scale models\nwhile maintaining competitive performance across various natural language\nprocessing tasks. Comprehensive evaluations on four tasks -- named entity\nrecognition, natural language inference, question answering, and semantic\ntextual similarity -- demonstrate that our multilingual training strategy\nenhanced by an adversarial objective significantly improves cross-lingual\ngeneralization. Specifically, UniBERT models show an average relative\nimprovement of 7.72% over traditional baselines, which achieved an average\nrelative improvement of only 1.17%, with statistical analysis confirming the\nsignificance of these gains (p-value = 0.0181). This work highlights the\nbenefits of combining adversarial training and knowledge distillation to build\nscalable and robust language models, thereby advancing the field of\nmultilingual and cross-lingual natural language processing.", "published": "2025-03-16 18:44:06", "link": "http://arxiv.org/abs/2503.12608v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fragile Mastery: Are Domain-Specific Trade-Offs Undermining On-Device Language Models?", "abstract": "The application of on-device language models (ODLMs) on resource-constrained\nedge devices is a multi-dimensional problem that strikes a fine balance between\ncomputational effectiveness, memory, power usage, and linguistic capacity\nacross heterogeneous tasks. This holistic study conducts a thorough\ninvestigation of the trade-offs between domain-specific optimization and\ncross-domain robustness, culminating in the proposal of the Generalized Edge\nModel (GEM), a new architecture that aims to balance specialization and\ngeneralization in a harmonious manner. With a rigorous experimental approach\ntesting 47 well-chosen benchmarks in eight domains--healthcare, law, finance,\nSTEM, commonsense, conversational AI, multilingual, and domain-adaptive\ntasks--we show that conventional optimization techniques decrease target task\nperplexity by 18-25% but result in a precipitous decline in general-task\nperformance with F1 scores decreasing by 12-29%, as reported by Liu et al. GEM\nemploys a Sparse Cross-Attention Router (SCAR) to dynamically allocate\ncomputation to a variable number of computing resources with a cross-domain F1\naccuracy of 0.89 on less than 100ms latency across Raspberry Pi 4, Pixel 6,\niPhone 13, and bespoke custom neural processing units (NPUs). Compared to GPT-4\nLite, GEM enhances the general-task level by 7% with respect and parity in\ndomain-specific performance. We propose three new measurement tools--Domain\nSpecialization Index (DSI), Generalization Gap (GG), and Cross-Domain Transfer\nRatio (CDTR)--which show strong correlation between model compression intensity\nand brittleness.", "published": "2025-03-16 18:30:26", "link": "http://arxiv.org/abs/2503.22698v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MoECollab: Democratizing LLM Development Through Collaborative Mixture of Experts", "abstract": "Large Language Model (LLM) development has become increasingly centralized,\nlimiting participation to well-resourced organizations. This paper introduces\nMoECollab, a novel framework leveraging Mixture of Experts (MoE) architecture\nto enable distributed, collaborative LLM development. By decomposing monolithic\nmodels into specialized expert modules coordinated by a trainable gating\nnetwork, our framework allows diverse contributors to participate regardless of\ncomputational resources. We provide a complete technical implementation with\nmathematical foundations for expert dynamics, gating mechanisms, and\nintegration strategies. Experiments on multiple datasets demonstrate that our\napproach achieves accuracy improvements of 3-7% over baseline models while\nreducing computational requirements by 34%. Expert specialization yields\nsignificant domain-specific gains, with improvements from 51% to 88% F1 score\nin general classification and from 23% to 44% accuracy in news categorization.\nWe formalize the routing entropy optimization problem and demonstrate how\nproper regularization techniques lead to 14% higher expert utilization rates.\nThese results validate MoECollab as an effective approach for democratizing LLM\ndevelopment through architecturally-supported collaboration.", "published": "2025-03-16 17:52:40", "link": "http://arxiv.org/abs/2503.12592v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "RaSA: Rank-Sharing Low-Rank Adaptation", "abstract": "Low-rank adaptation (LoRA) has been prominently employed for\nparameter-efficient fine-tuning of large language models (LLMs). However, the\nlimited expressive capacity of LoRA, stemming from the low-rank constraint, has\nbeen recognized as a bottleneck, particularly in rigorous tasks like code\ngeneration and mathematical reasoning. To address this limitation, we introduce\nRank-Sharing Low-Rank Adaptation (RaSA), an innovative extension that enhances\nthe expressive capacity of LoRA by leveraging partial rank sharing across\nlayers. By forming a shared rank pool and applying layer-specific weighting,\nRaSA effectively increases the number of ranks without augmenting parameter\noverhead. Our theoretically grounded and empirically validated approach\ndemonstrates that RaSA not only maintains the core advantages of LoRA but also\nsignificantly boosts performance in challenging code and math tasks. Code, data\nand scripts are available at: https://github.com/zwhe99/RaSA.", "published": "2025-03-16 17:16:36", "link": "http://arxiv.org/abs/2503.12576v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Granular Multimodal Clue Fusion for Meme Understanding", "abstract": "With the continuous emergence of various social media platforms frequently\nused in daily life, the multimodal meme understanding (MMU) task has been\ngarnering increasing attention. MMU aims to explore and comprehend the meanings\nof memes from various perspectives by performing tasks such as metaphor\nrecognition, sentiment analysis, intention detection, and offensiveness\ndetection. Despite making progress, limitations persist due to the loss of\nfine-grained metaphorical visual clue and the neglect of multimodal text-image\nweak correlation. To overcome these limitations, we propose a multi-granular\nmultimodal clue fusion model (MGMCF) to advance MMU. Firstly, we design an\nobject-level semantic mining module to extract object-level image feature\nclues, achieving fine-grained feature clue extraction and enhancing the model's\nability to capture metaphorical details and semantics. Secondly, we propose a\nbrand-new global-local cross-modal interaction model to address the weak\ncorrelation between text and images. This model facilitates effective\ninteraction between global multimodal contextual clues and local unimodal\nfeature clues, strengthening their representations through a bidirectional\ncross-modal attention mechanism. Finally, we devise a dual-semantic guided\ntraining strategy to enhance the model's understanding and alignment of\nmultimodal representations in the semantic space. Experiments conducted on the\nwidely-used MET-MEME bilingual dataset demonstrate significant improvements\nover state-of-the-art baselines. Specifically, there is an 8.14% increase in\nprecision for offensiveness detection task, and respective accuracy\nenhancements of 3.53%, 3.89%, and 3.52% for metaphor recognition, sentiment\nanalysis, and intention detection tasks. These results, underpinned by in-depth\nanalyses, underscore the effectiveness and potential of our approach for\nadvancing MMU.", "published": "2025-03-16 16:16:53", "link": "http://arxiv.org/abs/2503.12560v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AdaReTaKe: Adaptive Redundancy Reduction to Perceive Longer for Video-language Understanding", "abstract": "Multimodal Large Language Models (MLLMs) have revolutionized video\nunderstanding, yet are still limited by context length when processing long\nvideos. Recent methods compress videos by leveraging visual redundancy\nuniformly, yielding promising results. Nevertheless, our quantitative analysis\nshows that redundancy varies significantly across time and model layers,\nnecessitating a more flexible compression strategy. We propose AdaReTaKe, a\ntraining-free method that flexibly reduces visual redundancy by allocating\ncompression ratios among time and layers with theoretical guarantees.\nIntegrated into state-of-the-art MLLMs, AdaReTaKe improves processing capacity\nfrom 256 to 2048 frames while preserving critical information. Experiments on\nVideoMME, MLVU, LongVideoBench, and LVBench datasets demonstrate that AdaReTaKe\noutperforms existing methods by 2.3% and 2.8% for 7B and 72B models,\nrespectively, with even greater improvements of 5.9% and 6.0% on the longest\nLVBench. Our code is available at\nhttps://github.com/SCZwangxiao/video-FlexReduc.git.", "published": "2025-03-16 16:14:52", "link": "http://arxiv.org/abs/2503.12559v1", "categories": ["cs.CV", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "From Guessing to Asking: An Approach to Resolving the Persona Knowledge Gap in LLMs during Multi-Turn Conversations", "abstract": "In multi-turn dialogues, large language models (LLM) face a critical\nchallenge of ensuring coherence while adapting to user-specific information.\nThis study introduces the persona knowledge gap, the discrepancy between a\nmodel's internal understanding and the knowledge required for coherent,\npersonalized conversations. While prior research has recognized these gaps,\ncomputational methods for their identification and resolution remain\nunderexplored. We propose Conversation Preference Elicitation and\nRecommendation (CPER), a novel framework that dynamically detects and resolves\npersona knowledge gaps using intrinsic uncertainty quantification and\nfeedback-driven refinement. CPER consists of three key modules: a Contextual\nUnderstanding Module for preference extraction, a Dynamic Feedback Module for\nmeasuring uncertainty and refining persona alignment, and a Persona-Driven\nResponse Generation module for adapting responses based on accumulated user\ncontext. We evaluate CPER on two real-world datasets: CCPE-M for preferential\nmovie recommendations and ESConv for mental health support. Using A/B testing,\nhuman evaluators preferred CPER's responses 42% more often than baseline models\nin CCPE-M and 27% more often in ESConv. A qualitative human evaluation confirms\nthat CPER's responses are preferred for maintaining contextual relevance and\ncoherence, particularly in longer (12+ turn) conversations.", "published": "2025-03-16 15:55:29", "link": "http://arxiv.org/abs/2503.12556v1", "categories": ["cs.CL", "cs.AI", "I.2; I.2.7"], "primary_category": "cs.CL"}
{"title": "Towards Hierarchical Multi-Step Reward Models for Enhanced Reasoning in Large Language Models", "abstract": "Recent studies show that Large Language Models (LLMs) achieve strong\nreasoning capabilities through supervised fine-tuning or reinforcement\nlearning. However, a key approach, the Process Reward Model (PRM), suffers from\nreward hacking, making it unreliable in identifying the best intermediate\nsteps. In this paper, we propose a novel reward model approach, Hierarchical\nReward Model (HRM), which evaluates both individual and consecutive reasoning\nsteps from fine-grained and coarse-grained level. HRM performs better in\nassessing reasoning coherence and self-reflection, particularly when the\nprevious reasoning step is incorrect. Furthermore, to address the inefficiency\nof autonomous generating PRM training data via Monte Carlo Tree Search (MCTS),\nwe introduce a lightweight and effective data augmentation strategy called\nHierarchical Node Compression (HNC) based on node merging (combining two\nconsecutive reasoning steps into one step) in the tree structure. This approach\ndiversifies MCTS results for HRM with negligible computational overhead,\nenhancing label robustness by introducing noise. Empirical results on the\nPRM800K dataset demonstrate that HRM, in conjunction with HNC, achieves\nsuperior stability and reliability in evaluation compared to PRM. Furthermore,\ncross-domain evaluations on MATH500 and GSM8K confirm HRM's superior\ngeneralization and robustness across diverse reasoning tasks. The code for all\nexperiments will be released at https:\n//github.com/tengwang0318/hierarchial_reward_model.", "published": "2025-03-16 15:18:40", "link": "http://arxiv.org/abs/2503.13551v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Basic Category Usage in Vision Language Models", "abstract": "The field of psychology has long recognized a basic level of categorization\nthat humans use when labeling visual stimuli, a term coined by Rosch in 1976.\nThis level of categorization has been found to be used most frequently, to have\nhigher information density, and to aid in visual language tasks with priming in\nhumans. Here, we investigate basic level categorization in two recently\nreleased, open-source vision-language models (VLMs). This paper demonstrates\nthat Llama 3.2 Vision Instruct (11B) and Molmo 7B-D both prefer basic level\ncategorization consistent with human behavior. Moreover, the models'\npreferences are consistent with nuanced human behaviors like the biological\nversus non-biological basic level effects and the well established expert basic\nlevel shift, further suggesting that VLMs acquire cognitive categorization\nbehaviors from the human data on which they are trained.", "published": "2025-03-16 14:50:54", "link": "http://arxiv.org/abs/2503.12530v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating Human-Aligned Large Language Model Uncertainty", "abstract": "Recent work has sought to quantify large language model uncertainty to\nfacilitate model control and modulate user trust. Previous works focus on\nmeasures of uncertainty that are theoretically grounded or reflect the average\novert behavior of the model. In this work, we investigate a variety of\nuncertainty measures, in order to identify measures that correlate with human\ngroup-level uncertainty. We find that Bayesian measures and a variation on\nentropy measures, top-k entropy, tend to agree with human behavior as a\nfunction of model size. We find that some strong measures decrease in\nhuman-similarity with model size, but, by multiple linear regression, we find\nthat combining multiple uncertainty measures provide comparable human-alignment\nwith reduced size-dependency.", "published": "2025-03-16 14:45:43", "link": "http://arxiv.org/abs/2503.12528v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EXAONE Deep: Reasoning Enhanced Language Models", "abstract": "We present EXAONE Deep series, which exhibits superior capabilities in\nvarious reasoning tasks, including math and coding benchmarks. We train our\nmodels mainly on the reasoning-specialized dataset that incorporates long\nstreams of thought processes. Evaluation results show that our smaller models,\nEXAONE Deep 2.4B and 7.8B, outperform other models of comparable size, while\nthe largest model, EXAONE Deep 32B, demonstrates competitive performance\nagainst leading open-weight models. All EXAONE Deep models are openly available\nfor research purposes and can be downloaded from\nhttps://huggingface.co/LGAI-EXAONE", "published": "2025-03-16 14:39:33", "link": "http://arxiv.org/abs/2503.12524v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CAKE: Cascading and Adaptive KV Cache Eviction with Layer Preferences", "abstract": "Large language models (LLMs) excel at processing long sequences, boosting\ndemand for key-value (KV) caching. While recent efforts to evict KV cache have\nalleviated the inference burden, they often fail to allocate resources\nrationally across layers with different attention patterns. In this paper, we\nintroduce Cascading and Adaptive KV cache Eviction (CAKE), a novel approach\nthat frames KV cache eviction as a \"cake-slicing problem.\" CAKE assesses\nlayer-specific preferences by considering attention dynamics in both spatial\nand temporal dimensions, allocates rational cache size for layers accordingly,\nand manages memory constraints in a cascading manner. This approach enables a\nglobal view of cache allocation, adaptively distributing resources across\ndiverse attention mechanisms while maintaining memory budgets. CAKE also\nemploys a new eviction indicator that considers the shifting importance of\ntokens over time, addressing limitations in existing methods that overlook\ntemporal dynamics. Comprehensive experiments on LongBench and NeedleBench show\nthat CAKE maintains model performance with only 3.2% of the KV cache and\nconsistently outperforms current baselines across various models and memory\nconstraints, particularly in low-memory settings. Additionally, CAKE achieves\nover 10x speedup in decoding latency compared to full cache when processing\ncontexts of 128K tokens with FlashAttention-2. Our code is available at\nhttps://github.com/antgroup/cakekv.", "published": "2025-03-16 12:49:44", "link": "http://arxiv.org/abs/2503.12491v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Using LLMs for Automated Privacy Policy Analysis: Prompt Engineering, Fine-Tuning and Explainability", "abstract": "Privacy policies are widely used by digital services and often required for\nlegal purposes. Many machine learning based classifiers have been developed to\nautomate detection of different concepts in a given privacy policy, which can\nhelp facilitate other automated tasks such as producing a more reader-friendly\nsummary and detecting legal compliance issues. Despite the successful\napplications of large language models (LLMs) to many NLP tasks in various\ndomains, there is very little work studying the use of LLMs for automated\nprivacy policy analysis, therefore, if and how LLMs can help automate privacy\npolicy analysis remains under-explored. To fill this research gap, we conducted\na comprehensive evaluation of LLM-based privacy policy concept classifiers,\nemploying both prompt engineering and LoRA (low-rank adaptation) fine-tuning,\non four state-of-the-art (SOTA) privacy policy corpora and taxonomies. Our\nexperimental results demonstrated that combining prompt engineering and\nfine-tuning can make LLM-based classifiers outperform other SOTA methods,\n\\emph{significantly} and \\emph{consistently} across privacy policy\ncorpora/taxonomies and concepts. Furthermore, we evaluated the explainability\nof the LLM-based classifiers using three metrics: completeness, logicality, and\ncomprehensibility. For all three metrics, a score exceeding 91.1\\% was observed\nin our evaluation, indicating that LLMs are not only useful to improve the\nclassification performance, but also to enhance the explainability of detection\nresults.", "published": "2025-03-16 10:50:31", "link": "http://arxiv.org/abs/2503.16516v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "HKCanto-Eval: A Benchmark for Evaluating Cantonese Language Understanding and Cultural Comprehension in LLMs", "abstract": "The ability of language models to comprehend and interact in diverse\nlinguistic and cultural landscapes is crucial. The Cantonese language used in\nHong Kong presents unique challenges for natural language processing due to its\nrich cultural nuances and lack of dedicated evaluation datasets. The\nHKCanto-Eval benchmark addresses this gap by evaluating the performance of\nlarge language models (LLMs) on Cantonese language understanding tasks,\nextending to English and Written Chinese for cross-lingual evaluation.\nHKCanto-Eval integrates cultural and linguistic nuances intrinsic to Hong Kong,\nproviding a robust framework for assessing language models in realistic\nscenarios. Additionally, the benchmark includes questions designed to tap into\nthe underlying linguistic metaknowledge of the models. Our findings indicate\nthat while proprietary models generally outperform open-weight models,\nsignificant limitations remain in handling Cantonese-specific linguistic and\ncultural knowledge, highlighting the need for more targeted training data and\nevaluation methods. The code can be accessed at\nhttps://github.com/hon9kon9ize/hkeval2025", "published": "2025-03-16 10:26:24", "link": "http://arxiv.org/abs/2503.12440v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CorpusStudio: Surfacing Emergent Patterns in a Corpus of Prior Work while Writing", "abstract": "Many communities, including the scientific community, develop implicit\nwriting norms. Understanding them is crucial for effective communication with\nthat community. Writers gradually develop an implicit understanding of norms by\nreading papers and receiving feedback on their writing. However, it is\ndifficult to both externalize this knowledge and apply it to one's own writing.\nWe propose two new writing support concepts that reify document and\nsentence-level patterns in a given text corpus: (1) an ordered distribution\nover section titles and (2) given the user's draft and cursor location, many\nretrieved contextually relevant sentences. Recurring words in the latter are\nalgorithmically highlighted to help users see any emergent norms. Study results\n(N=16) show that participants revised the structure and content using these\nconcepts, gaining confidence in aligning with or breaking norms after reviewing\nmany examples. These results demonstrate the value of reifying distributions\nover other authors' writing choices during the writing process.", "published": "2025-03-16 10:16:21", "link": "http://arxiv.org/abs/2503.12436v1", "categories": ["cs.HC", "cs.CL", "H.5.2; I.2.7"], "primary_category": "cs.HC"}
{"title": "Understanding Common Ground Misalignment in Goal-Oriented Dialog: A Case-Study with Ubuntu Chat Logs", "abstract": "While it is commonly accepted that maintaining common ground plays a role in\nconversational success, little prior research exists connecting conversational\ngrounding to success in task-oriented conversations. We study failures of\ngrounding in the Ubuntu IRC dataset, where participants use text-only\ncommunication to resolve technical issues. We find that disruptions in\nconversational flow often stem from a misalignment in common ground, driven by\na divergence in beliefs and assumptions held by participants. These\ndisruptions, which we call conversational friction, significantly correlate\nwith task success. We find that although LLMs can identify overt cases of\nconversational friction, they struggle with subtler and more context-dependent\ninstances requiring pragmatic or domain-specific reasoning.", "published": "2025-03-16 06:19:44", "link": "http://arxiv.org/abs/2503.12370v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Highlighting Case Studies in LLM Literature Review of Interdisciplinary System Science", "abstract": "Large Language Models (LLMs) were used to assist four Commonwealth Scientific\nand Industrial Research Organisation (CSIRO) researchers to perform systematic\nliterature reviews (SLR). We evaluate the performance of LLMs for SLR tasks in\nthese case studies. In each, we explore the impact of changing parameters on\nthe accuracy of LLM responses. The LLM was tasked with extracting evidence from\nchosen academic papers to answer specific research questions. We evaluate the\nmodels' performance in faithfully reproducing quotes from the literature and\nsubject experts were asked to assess the model performance in answering the\nresearch questions. We developed a semantic text highlighting tool to\nfacilitate expert review of LLM responses.\n  We found that state of the art LLMs were able to reproduce quotes from texts\nwith greater than 95% accuracy and answer research questions with an accuracy\nof approximately 83%. We use two methods to determine the correctness of LLM\nresponses; expert review and the cosine similarity of transformer embeddings of\nLLM and expert answers. The correlation between these methods ranged from 0.48\nto 0.77, providing evidence that the latter is a valid metric for measuring\nsemantic similarity.", "published": "2025-03-16 05:52:18", "link": "http://arxiv.org/abs/2503.16515v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "IPCGRL: Language-Instructed Reinforcement Learning for Procedural Level Generation", "abstract": "Recent research has highlighted the significance of natural language in\nenhancing the controllability of generative models. While various efforts have\nbeen made to leverage natural language for content generation, research on deep\nreinforcement learning (DRL) agents utilizing text-based instructions for\nprocedural content generation remains limited. In this paper, we propose\nIPCGRL, an instruction-based procedural content generation method via\nreinforcement learning, which incorporates a sentence embedding model. IPCGRL\nfine-tunes task-specific embedding representations to effectively compress\ngame-level conditions. We evaluate IPCGRL in a two-dimensional level generation\ntask and compare its performance with a general-purpose embedding method. The\nresults indicate that IPCGRL achieves up to a 21.4% improvement in\ncontrollability and a 17.2% improvement in generalizability for unseen\ninstructions. Furthermore, the proposed method extends the modality of\nconditional input, enabling a more flexible and expressive interaction\nframework for procedural content generation.", "published": "2025-03-16 04:53:38", "link": "http://arxiv.org/abs/2503.12358v3", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Numerical Words and Linguistic Loops: The Perpetual Four-Letter Routine", "abstract": "This study presents a fascinating linguistic property related to the number\nof letters in words and their corresponding numerical values. By selecting any\narbitrary word, counting its constituent letters, and subsequently spelling out\nthe resulting count and tallying the letters anew, an unanticipated pattern is\nobserved. Remarkably, this iterative sequence, conducted on a dataset of\n100,000 random words, invariably converges to the numeral four (4), termed the\nLinguistic Loop (LL) constant. Examining 73 languages utilizing the Latin\nalphabet, this research reveals distinctive patterns. Among them, 28 languages\nexhibit LL-positive behavior adhering to the established property, while 31\nlanguages deviate as LL-negative. Additionally, 13 languages display nuanced\ntendencies: eight feature two LL constants (bi-positivity), and five feature\nthree constants (tri-positivity). This discovery highlights a linguistic quirk\nwithin Latin alphabet-based language number-word representations, uncovering an\nintriguing facet across diverse alphabetic systems. It also raises questions\nabout the underlying linguistic and cognitive mechanisms responsible for this\nphenomenon.", "published": "2025-03-16 04:53:23", "link": "http://arxiv.org/abs/2503.12357v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Synthesizing Privacy-Preserving Text Data via Finetuning without Finetuning Billion-Scale LLMs", "abstract": "Synthetic data offers a promising path to train models while preserving data\nprivacy. Differentially private (DP) finetuning of large language models (LLMs)\nas data generator is effective, but is impractical when computation resources\nare limited. Meanwhile, prompt-based methods such as private evolution, depend\nheavily on the manual prompts, and ineffectively use private information in\ntheir iterative data selection process. To overcome these limitations, we\npropose CTCL (Data Synthesis with ConTrollability and CLustering), a novel\nframework for generating privacy-preserving synthetic data without extensive\nprompt engineering or billion-scale LLM finetuning. CTCL pretrains a\nlightweight 140M conditional generator and a clustering-based topic model on\nlarge-scale public data. To further adapt to the private domain, the generator\nis DP finetuned on private data for fine-grained textual information, while the\ntopic model extracts a DP histogram representing distributional information.\nThe DP generator then samples according to the DP histogram to synthesize a\ndesired number of data examples. Evaluation across five diverse domains\ndemonstrates the effectiveness of our framework, particularly in the strong\nprivacy regime. Systematic ablation validates the design of each framework\ncomponent and highlights the scalability of our approach.", "published": "2025-03-16 04:00:32", "link": "http://arxiv.org/abs/2503.12347v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "General Table Question Answering via Answer-Formula Joint Generation", "abstract": "Advanced table question answering (TableQA) methods prompt large language\nmodels (LLMs) to generate answer text, SQL query, Python code, or custom\noperations, which impressively improve the complex reasoning problems in the\nTableQA task. However, these methods lack the versatility to cope with specific\nquestion types or table structures. In contrast, the Spreadsheet Formula, the\nwidely-used and well-defined operation language for tabular data, has not been\nthoroughly explored to solve TableQA. In this paper, we first attempt to use\nFormula as the logical form for solving complex reasoning on the tables with\ndifferent structures. Specifically, we construct a large Formula-annotated\nTableQA dataset \\texttt{FromulaQA} from existing datasets. In addition, we\npropose \\texttt{TabAF}, a general table answering framework to solve multiple\ntypes of tasks over multiple types of tables simultaneously. Unlike existing\nmethods, \\texttt{TabAF} decodes answers and Formulas with a single LLM\nbackbone, demonstrating great versatility and generalization. \\texttt{TabAF}\nbased on Llama3.1-70B achieves new state-of-the-art performance on the\nWikiTableQuestion, HiTab and TabFact.", "published": "2025-03-16 03:51:06", "link": "http://arxiv.org/abs/2503.12345v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SVD-LLM V2: Optimizing Singular Value Truncation for Large Language Model Compression", "abstract": "Despite significant advancements, the practical deployment of Large Language\nModels (LLMs) is often hampered by their immense sizes, highlighting the need\nfor effective compression techniques. Singular Value Decomposition (SVD) is a\npromising LLM compression technique. However, existing SVD-based compression\nmethods fall short in reducing truncation losses, leading to less competitive\nperformance in compressed models. In this work, we introduce SVD-LLM V2, a\nSVD-based LLM compression method that optimizes singular value truncation in\nSVD compression with two techniques. First, SVD-LLM V2 proposes to use\ntheoretical truncation loss of weight matrices to assign a unique compression\nratio to each weight matrix at different layers to accommodate weight\nredundancy heterogeneity. Second, SVD-LLM V2 proposes loss-optimized weight\ntruncation to ensure that the truncated singular values result in a lower and\nmore stable truncation loss in practice. We evaluate SVD-LLM V2 on ten datasets\nand five LLMs at various scales. Our results show SVD-LLM V2 outperforms\nstate-of-the-art SVD-based LLM compression methods. Our code is available at\nhttps://github.com/AIoT-MLSys-Lab/SVD-LLM", "published": "2025-03-16 03:27:12", "link": "http://arxiv.org/abs/2503.12340v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CapArena: Benchmarking and Analyzing Detailed Image Captioning in the LLM Era", "abstract": "Image captioning has been a longstanding challenge in vision-language\nresearch. With the rise of LLMs, modern Vision-Language Models (VLMs) generate\ndetailed and comprehensive image descriptions. However, benchmarking the\nquality of such captions remains unresolved. This paper addresses two key\nquestions: (1) How well do current VLMs actually perform on image captioning,\nparticularly compared to humans? We built CapArena, a platform with over 6000\npairwise caption battles and high-quality human preference votes. Our\narena-style evaluation marks a milestone, showing that leading models like\nGPT-4o achieve or even surpass human performance, while most open-source models\nlag behind. (2) Can automated metrics reliably assess detailed caption quality?\nUsing human annotations from CapArena, we evaluate traditional and recent\ncaptioning metrics, as well as VLM-as-a-Judge. Our analysis reveals that while\nsome metrics (e.g., METEOR) show decent caption-level agreement with humans,\ntheir systematic biases lead to inconsistencies in model ranking. In contrast,\nVLM-as-a-Judge demonstrates robust discernment at both the caption and model\nlevels. Building on these insights, we release CapArena-Auto, an accurate and\nefficient automated benchmark for detailed captioning, achieving 94.3%\ncorrelation with human rankings at just $4 per test. Data and resources will be\nopen-sourced at https://caparena.github.io.", "published": "2025-03-16 02:56:09", "link": "http://arxiv.org/abs/2503.12329v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "State Fourier Diffusion Language Model (SFDLM): A Scalable, Novel Iterative Approach to Language Modeling", "abstract": "In recent years, diffusion based methods have emerged as a powerful paradigm\nfor generative modeling. Although discrete diffusion for natural language\nprocessing has been explored to a lesser extent, it shows promise for tasks\nrequiring iterative denoising of token based data. In standard approaches to\ntext generation, transformers dominate, but their reliance on self attention\noften incurs high computational costs. This paper introduces a fully diffusion\ndriven discrete text generation model built without any transformer or large\nconvolution modules. Instead, the model integrates structured state space\ndynamics in the time domain with a novel Complex Fourier Multi Layer Perceptron\nmodule that operates in the frequency domain. The forward noising process\nrandomly samples the vocabulary to replace tokens with a controlled\nprobability, while the learned reverse model systematically reverts corrupted\nsequences toward their original states. By composing local state space updates\nwith global Fourier based mixing, the approach effectively captures both short\nand long range dependencies.", "published": "2025-03-16 02:17:40", "link": "http://arxiv.org/abs/2503.17382v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "One Goal, Many Challenges: Robust Preference Optimization Amid Content-Aware and Multi-Source Noise", "abstract": "Large Language Models (LLMs) have made significant strides in generating\nhuman-like responses, largely due to preference alignment techniques. However,\nthese methods often assume unbiased human feedback, which is rarely the case in\nreal-world scenarios. This paper introduces Content-Aware Noise-Resilient\nPreference Optimization (CNRPO), a novel framework that addresses multiple\nsources of content-dependent noise in preference learning. CNRPO employs a\nmulti-objective optimization approach to separate true preferences from\ncontent-aware noises, effectively mitigating their impact. We leverage backdoor\nattack mechanisms to efficiently learn and control various noise sources within\na single model. Theoretical analysis and extensive experiments on different\nsynthetic noisy datasets demonstrate that CNRPO significantly improves\nalignment with primary human preferences while controlling for secondary noises\nand biases, such as response length and harmfulness.", "published": "2025-03-16 00:22:00", "link": "http://arxiv.org/abs/2503.12301v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Quasilinearization with Regularizing Tensor Paraproducts", "abstract": "We construct an extension of the Bony quasilinearization formula as a tensor\nparaproduct decomposition to obtain an approximation, $\\tilde{A}(f)$, to $A(f)$\nwhere $f \\in \\text{tensor-} \\Lambda^{\\alpha}([0,1]^2)$ and $A \\in C^2$. The\nrough content of $A(f)$ is encoded in the approximation of $\\tilde{A}(f)$ while\nthe residual, $\\Delta(A,f) = A(f) - \\tilde{A}(f)$, which is of regularity\n$\\text{tensor-} \\Lambda^{2 \\alpha}([0,1]^2)$, contains the smooth content of\n$A(f)$.", "published": "2025-03-16 19:46:56", "link": "http://arxiv.org/abs/2503.12629v1", "categories": ["math.AP", "cs.DM"], "primary_category": "math.AP"}
{"title": "SING: Semantic Image Communications using Null-Space and INN-Guided Diffusion Models", "abstract": "Joint source-channel coding systems based on deep neural networks (DeepJSCC)\nhave recently demonstrated remarkable performance in wireless image\ntransmission. Existing methods primarily focus on minimizing distortion between\nthe transmitted image and the reconstructed version at the receiver, often\noverlooking perceptual quality. This can lead to severe perceptual degradation\nwhen transmitting images under extreme conditions, such as low bandwidth\ncompression ratios (BCRs) and low signal-to-noise ratios (SNRs). In this work,\nwe propose SING, a novel two-stage JSCC framework that formulates the recovery\nof high-quality source images from corrupted reconstructions as an inverse\nproblem. Depending on the availability of information about the DeepJSCC\nencoder/decoder and the channel at the receiver, SING can either approximate\nthe stochastic degradation as a linear transformation, or leverage invertible\nneural networks (INNs) for precise modeling. Both approaches enable the\nseamless integration of diffusion models into the reconstruction process,\nenhancing perceptual quality. Experimental results demonstrate that SING\noutperforms DeepJSCC and other approaches, delivering superior perceptual\nquality even under extremely challenging conditions, including scenarios with\nsignificant distribution mismatches between the training and test data.", "published": "2025-03-16 12:32:11", "link": "http://arxiv.org/abs/2503.12484v1", "categories": ["eess.IV", "cs.AI", "cs.IT", "cs.LG", "eess.SP", "math.IT"], "primary_category": "eess.IV"}
{"title": "Variability of radio signal attenuation by single deciduous tree versus reception angle at 80 GHz", "abstract": "Vegetation significantly affects radio signal attenuation, influenced by\nfactors such as signal frequency, plant species, and foliage density. Existing\nattenuation models typically address specific scenarios, like single trees,\nrows of trees, or green spaces, with the ITU-R P.833 recommendation being a\nwidely recognized standard. Most assessments for single trees focus on the\nprimary radiation direction of the transmitting antenna. This paper introduces\na novel approach to evaluating radio signal scattering by a single deciduous\ntree. Through measurements at 80 GHz and a bandwidth of approximately 2 GHz, we\nanalyze how total signal attenuation varies with the reception angle relative\nto the transmitter-tree axis. The findings from various directional\nmeasurements contribute to a comprehensive attenuation model applicable to any\nreception angle and also highlight the impact of bandwidth on the received\nsignal level.", "published": "2025-03-16 10:38:54", "link": "http://arxiv.org/abs/2503.12445v1", "categories": ["eess.SP", "cs.IT", "math.IT", "94A40, 94A05, 94A12, 94A17", "E.4; H.4.3"], "primary_category": "eess.SP"}
{"title": "Power angular spectrum versus Doppler spectrum -- Measurements and analysis", "abstract": "In this paper, we present an empirical verification of the method of\ndetermining the Doppler spectrum (DS) from the power angular spectrum (PAS).\nMeasurements were made for the frequency of 3.5 GHz, under non-line-of-sight\nconditions in suburban areas characteristic of a university campus. In the\nstatic scenario, the measured PAS was the basis for the determination of DSs,\nwhich were compared with the DSs measured in the mobile scenario. The obtained\nresults show that the proposed method gives some approximation to DS determined\nwith the classic methods used so far.", "published": "2025-03-16 10:37:40", "link": "http://arxiv.org/abs/2503.12443v1", "categories": ["eess.SP", "cs.IT", "math.IT", "94A40, 94A05, 94A12, 94A17", "E.4; H.4.3"], "primary_category": "eess.SP"}
{"title": "Spectral efficiency for mmWave downlink with beam misalignment in urban macro scenario", "abstract": "In this paper, we analyze the spectral efficiency for millimeter wave\ndownlink with beam misalignment in urban macro scenario. For this purpose, we\nuse a new approach based on the modified Shannon formula, which considers the\npropagation environment and antenna system coefficients. These factors are\ndetermined based on a multi-ellipsoidal propagation model. The obtained results\nshow that under non-line-of-sight conditions, the appropriate selection of the\nantenna beam orientation may increase the spectral efficiency in relation to\nthe direct line to a user.", "published": "2025-03-16 10:37:07", "link": "http://arxiv.org/abs/2503.12442v1", "categories": ["eess.SP", "cs.IT", "math.IT", "94A40, 94A05, 94A12, 94A17", "E.4; H.4.3"], "primary_category": "eess.SP"}
{"title": "XAI-Driven Client Selection for Federated Learning in Scalable 6G Network Slicing", "abstract": "In recent years, network slicing has embraced artificial intelligence (AI)\nmodels to manage the growing complexity of communication networks. In such a\nsituation, AI-driven zero-touch network automation should present a high degree\nof flexibility and viability, especially when deployed in live production\nnetworks. However, centralized controllers suffer from high data communication\noverhead due to the vast amount of user data, and most network slices are\nreluctant to share private data. In federated learning systems, selecting\ntrustworthy clients to participate in training is critical for ensuring system\nperformance and reliability. The present paper proposes a new approach to\nclient selection by leveraging an XAI method to guarantee scalable and fast\noperation of federated learning based analytic engines that implement\nslice-level resource provisioning at the RAN-Edge in a non-IID scenario.\nAttributions from XAI are used to guide the selection of devices participating\nin training. This approach enhances network trustworthiness for users and\naddresses the black-box nature of neural network models. The simulations\nconducted outperformed the standard approach in terms of both convergence time\nand computational cost, while also demonstrating high scalability.", "published": "2025-03-16 10:14:25", "link": "http://arxiv.org/abs/2503.12435v1", "categories": ["cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.IT"}
{"title": "Secrecy Analysis of Energy-Harvesting Backscatter Communications with Tag Selection in Nakagami-m Fading", "abstract": "Backscatter communication is an energy-efficient technique that enables\nsustainable wireless connectivity with a minimal environmental impact. In this\npaper, the secrecy performance of practical non-linear energy-harvesting\nbackscatter communications with various tag selection schemes is analyzed in\nNakagami-m fading channels. We consider four tag selection schemes:\nsub-optimal, minimal eaves-dropping, optimal, and random tag selection.\nClosed-form expressions for secrecy outage probability (SOP) and intercept\nprobability (IP) are derived for each scheme, along with asymptotic expressions\nto provide deeper insights. The impact of system and fading parameters on SOP\nand IP is investigated, and simulation results are presented to validate the\naccuracy of the analytical expressions.", "published": "2025-03-16 08:02:23", "link": "http://arxiv.org/abs/2503.12400v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Coding methods for string reconstruction from erroneous prefix-suffix compositions", "abstract": "The number of zeros and the number of ones in a binary string are referred to\nas the composition of the string, and the prefix-suffix compositions of a\nstring are a multiset formed by the compositions of the prefixes and suffixes\nof all possible lengths of the string. In this work, we present binary codes of\nlength n in which every codeword can be efficiently reconstructed from its\nerroneous prefix-suffix compositions with at most t composition errors. All our\nconstructions have decoding complexity polynomial in n and the best of our\nconstructions has constant rate and can correct $t = \\Theta(n)$ errors. As a\ncomparison, no prior constructions can afford to efficiently correct $t =\n\\Theta(n)$ arbitrary composition errors.\n  Additionally, we propose a method of encoding h arbitrary strings of the same\nlength so that they can be reconstructed from the multiset union of their\nerror-free prefix-suffix compositions, at the expense of h-fold coding\noverhead. In contrast, existing methods can only recover h distinct strings,\nalbeit with code rate asymptotically equal to 1/h. Building on the top of the\nproposed method, we also present a coding scheme that enables efficient\nrecovery of h strings from their erroneous prefix-suffix compositions with $t =\n\\Theta(n)$ errors.", "published": "2025-03-16 03:43:34", "link": "http://arxiv.org/abs/2503.12342v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Agent-Based Simulation of UAV Battery Recharging for IoT Applications: Precision Agriculture, Disaster Recovery, and Dengue Vector Control", "abstract": "The low battery autonomy of Unnamed Aerial Vehicles (UAVs or drones) can make\nsmart farming (precision agriculture), disaster recovery, and the fighting\nagainst dengue vector applications difficult. This article considers two\napproaches, first enumerating the characteristics observed in these three IoT\napplication types and then modeling an UAV's battery recharge coordination\nusing the Agent-Based Simulation (ABS) approach. In this way, we propose that\neach drone inside the swarm does not communicate concerning this recharge\ncoordination decision, reducing energy usage and permitting remote usage. A\ntotal of 6000 simulations were run to evaluate how two proposed policies, the\nBaseLine (BL) and ChargerThershold (CT) coordination recharging policy, behave\nin 30 situations regarding how each simulation sets conclude the simulation\nruns and how much time they work until recharging results. CT policy shows more\nreliable results in extreme system usage. This work conclusion presents the\npotential of these three IoT applications to achieve their perpetual service\nwithout communication between drones and ground stations. This work can be a\nbaseline for future policies and simulation parameter enhancements.", "published": "2025-03-16 23:04:28", "link": "http://arxiv.org/abs/2503.12685v1", "categories": ["cs.MA", "cs.RO"], "primary_category": "cs.MA"}
{"title": "On Some Fundamental Problems for Multi-Agent Systems Over Multilayer Networks", "abstract": "Many researchers have considered multi-agent systems over single-layer\nnetworks as models for studying diffusion phenomena. Since real-world networks\ninvolve connections between agents with different semantics (e.g., family\nmember, friend, colleague), the study of multi-agent systems over multilayer\nnetworks has assumed importance. Our focus is on one class of multi-agent\nsystem models over multilayer networks, namely multilayer synchronous dynamical\nsystems (MSyDSs). We study several fundamental problems for this model. We\nestablish properties of the phase spaces of MSyDSs and bring out interesting\ndifferences between single-layer and multilayer dynamical systems. We show\nthat, in general, the problem of determining whether two given MSyDSs are\ninequivalent is NP-complete. This hardness result holds even when the only\ndifference between the two systems is the local function at just one node in\none layer. We also present efficient algorithms for the equivalence problem for\nrestricted versions of MSyDSs (e.g., systems where each local function is a\nbounded-threshold function, systems where the number of layers is fixed and\neach local function is symmetric). In addition, we investigate the expressive\npower of MSyDSs based on the number of layers. In particular, we examine\nconditions under which a system with k >= 2 layers has an equivalent system\nwith k-1 or fewer layers.", "published": "2025-03-16 22:56:44", "link": "http://arxiv.org/abs/2503.12684v1", "categories": ["cs.MA", "cs.CC", "F.1; F.2"], "primary_category": "cs.MA"}
{"title": "Negotiative Alignment: Embracing Disagreement to Achieve Fairer Outcomes -- Insights from Urban Studies", "abstract": "Cities are not monolithic; they are arenas of negotiation among groups that\nhold varying needs, values, and experiences. Conventional methods of urban\nassessment -- from standardized surveys to AI-driven evaluations -- frequently\nrely on a single consensus metric (e.g., an average measure of inclusivity or\nsafety). Although such aggregations simplify design decisions, they risk\nobscuring the distinct perspectives of marginalized populations. In this paper,\nwe present findings from a community-centered study in Montreal involving 35\nresidents with diverse demographic and social identities, particularly\nwheelchair users, seniors, and LGBTQIA2+ individuals. Using rating and ranking\ntasks on 20 urban sites, we observe that disagreements are systematic rather\nthan random, reflecting structural inequalities, differing cultural values, and\npersonal experiences of safety and accessibility.\n  Based on these empirical insights, we propose negotiative alignment, an AI\nframework that treats disagreement as an essential input to be preserved,\nanalyzed, and addressed. Negotiative alignment builds on pluralistic models by\ndynamically updating stakeholder preferences through multi-agent negotiation\nmechanisms, ensuring no single perspective is marginalized. We outline how this\nframework can be integrated into urban analytics -- and other decision-making\ncontexts -- to retain minority viewpoints, adapt to changing stakeholder\nconcerns, and enhance fairness and accountability. The study demonstrates that\npreserving and engaging with disagreement, rather than striving for an\nartificial consensus, can produce more equitable and responsive AI-driven\noutcomes in urban design.", "published": "2025-03-16 18:55:54", "link": "http://arxiv.org/abs/2503.12613v1", "categories": ["cs.HC", "cs.AI", "cs.CY", "cs.MA"], "primary_category": "cs.HC"}
{"title": "Adaptive AUV Hunting Policy with Covert Communication via Diffusion Model", "abstract": "Collaborative underwater target hunting, facilitated by multiple autonomous\nunderwater vehicles (AUVs), plays a significant role in various domains,\nespecially military missions. Existing research predominantly focuses on\ndesigning efficient and high-success-rate hunting policy, particularly\naddressing the target's evasion capabilities. However, in real-world scenarios,\nthe target can not only adjust its evasion policy based on its observations and\npredictions but also possess eavesdropping capabilities. If communication among\nhunter AUVs, such as hunting policy exchanges, is intercepted by the target, it\ncan adapt its escape policy accordingly, significantly reducing the success\nrate of the hunting mission. To address this challenge, we propose a covert\ncommunication-guaranteed collaborative target hunting framework, which ensures\nefficient hunting in complex underwater environments while defending against\nthe target's eavesdropping. To the best of our knowledge, this is the first\nstudy to incorporate the confidentiality of inter-agent communication into the\ndesign of target hunting policy. Furthermore, given the complexity of\ncoordinating multiple AUVs in dynamic and unpredictable environments, we\npropose an adaptive multi-agent diffusion policy (AMADP), which incorporates\nthe strong generative ability of diffusion models into the multi-agent\nreinforcement learning (MARL) algorithm. Experimental results demonstrate that\nAMADP achieves faster convergence and higher hunting success rates while\nmaintaining covertness constraints.", "published": "2025-03-16 13:35:53", "link": "http://arxiv.org/abs/2503.13547v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "GameChat: Multi-LLM Dialogue for Safe, Agile, and Socially Optimal Multi-Agent Navigation in Constrained Environments", "abstract": "Safe, agile, and socially compliant multi-robot navigation in cluttered and\nconstrained environments remains a critical challenge. This is especially\ndifficult with self-interested agents in decentralized settings, where there is\nno central authority to resolve conflicts induced by spatial symmetry. We\naddress this challenge by proposing a novel approach, GameChat, which\nfacilitates safe, agile, and deadlock-free navigation for both cooperative and\nself-interested agents. Key to our approach is the use of natural language\ncommunication to resolve conflicts, enabling agents to prioritize more urgent\ntasks and break spatial symmetry in a socially optimal manner. Our algorithm\nensures subgame perfect equilibrium, preventing agents from deviating from\nagreed-upon behaviors and supporting cooperation. Furthermore, we guarantee\nsafety through control barrier functions and preserve agility by minimizing\ndisruptions to agents' planned trajectories. We evaluate GameChat in simulated\nenvironments with doorways and intersections. The results show that even in the\nworst case, GameChat reduces the time for all agents to reach their goals by\nover 35% from a naive baseline and by over 20% from SMG-CBF in the intersection\nscenario, while doubling the rate of ensuring the agent with a higher priority\ntask reaches the goal first, from 50% (equivalent to random chance) to a 100%\nperfect performance at maximizing social welfare.", "published": "2025-03-16 03:02:40", "link": "http://arxiv.org/abs/2503.12333v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Realized Volatility Forecasting for New Issues and Spin-Offs using Multi-Source Transfer Learning", "abstract": "Forecasting the volatility of financial assets is essential for various\nfinancial applications. This paper addresses the challenging task of\nforecasting the volatility of financial assets with limited historical data,\nsuch as new issues or spin-offs, by proposing a multi-source transfer learning\napproach. Specifically, we exploit complementary source data of assets with a\nsubstantial historical data record by selecting source time series instances\nthat are most similar to the limited target data of the new issue/spin-off.\nBased on these instances and the target data, we estimate linear and non-linear\nrealized volatility models and compare their forecasting performance to\nforecasts of models trained exclusively on the target data, and models trained\non the entire source and target data. The results show that our transfer\nlearning approach outperforms the alternative models and that the integration\nof complementary data is also beneficial immediately after the initial trading\nday of the new issue/spin-off.", "published": "2025-03-16 20:56:44", "link": "http://arxiv.org/abs/2503.12648v1", "categories": ["cs.LG", "q-fin.CP"], "primary_category": "cs.LG"}
{"title": "Semi-Decision-Focused Learning with Deep Ensembles: A Practical Framework for Robust Portfolio Optimization", "abstract": "I propose Semi-Decision-Focused Learning, a practical adaptation of\nDecision-Focused Learning for portfolio optimization. Rather than directly\noptimizing complex financial metrics, I employ simple target portfolios\n(Max-Sortino or One-Hot) and train models with a convex, cross-entropy loss. I\nfurther incorporate Deep Ensemble methods to reduce variance and stabilize\nperformance. Experiments on two universes (one upward-trending and another\nrange-bound) show consistent outperformance over baseline portfolios,\ndemonstrating the effectiveness and robustness of my approach. Code is\navailable at https://github.com/sDFLwDE/sDFLwDE", "published": "2025-03-16 10:57:45", "link": "http://arxiv.org/abs/2503.13544v2", "categories": ["cs.LG", "q-fin.CP", "q-fin.PM"], "primary_category": "cs.LG"}
{"title": "Intraday Battery Dispatch for Hybrid Renewable Energy Assets", "abstract": "We develop a mathematical model for intraday dispatch of co-located\nwind-battery energy assets. Focusing on the primary objective of firming\ngrid-side actual production vis-a-vis the preset day-ahead hourly generation\ntargets, we conduct a comprehensive study of the resulting stochastic control\nproblem across different firming formulations and wind generation dynamics.\nAmong others, we provide a closed-form solution in the special case of a\nquadratic objective and linear dynamics, as well as design a novel adaptation\nof a Gaussian Process-based Regression Monte Carlo algorithm for our setting.\nExtensions studied include an asymmetric loss function for peak shaving,\ncapturing the cost of battery cycling, and the role of battery duration. In the\napplied portion of our work, we calibrate our model to a collection of 140+\nwind-battery assets in Texas, benchmarking the economic benefits of firming\nbased on outputs of a realistic unit commitment and economic dispatch solver.", "published": "2025-03-16 00:32:07", "link": "http://arxiv.org/abs/2503.12305v1", "categories": ["math.OC", "q-fin.CP", "q-fin.MF"], "primary_category": "math.OC"}
{"title": "What Can 240,000 New Credit Transactions Tell Us About the Impact of NGEU Funds?", "abstract": "Using a panel data local projections model and controlling for firm\ncharacteristics, procurement bid attributes, and macroeconomic conditions, the\nstudy estimates the dynamic effects of procurement awards on new lending, a\nmore precise measure than the change in the stock of credit. The analysis\nfurther examines heterogeneity in credit responses based on firm size,\nindustry, credit maturity, and value chain position of the firms. The empirical\nevidence confirms that public procurement awards significantly increase new\nlending, with NGEU-funded contracts generating stronger credit expansion than\ntraditional procurement during the recent period. The results show that the\nimpact of NGEU procurement programs aligns closely with historical procurement\nimpacts, with differences driven mainly by lower utilization rates. Moreover,\nintegrating high-frequency financial data with procurement records highlights\nthe potential of Big Data in refining public policy design.", "published": "2025-03-16 19:50:03", "link": "http://arxiv.org/abs/2504.01964v2", "categories": ["q-fin.ST", "cs.LG"], "primary_category": "q-fin.ST"}
{"title": "Context-Aware Two-Step Training Scheme for Domain Invariant Speech Separation", "abstract": "Speech separation seeks to isolate individual speech signals from a\nmulti-talk speech mixture. Despite much progress, a system well-trained on\nsynthetic data often experiences performance degradation on out-of-domain data,\nsuch as real-world speech mixtures. To address this, we introduce a novel\ncontext-aware, two-stage training scheme for speech separation models. In this\ntraining scheme, the conventional end-to-end architecture is replaced with a\nframework that contains a context extractor and a segregator. The two modules\nare trained step by step to simulate the speech separation process of an\nauditory system. We evaluate the proposed training scheme through cross-domain\nexperiments on both synthetic and real-world speech mixtures, and demonstrate\nthat our new scheme effectively boosts separation quality across different\ndomains without adaptation, as measured by signal quality metrics and word\nerror rate (WER). Additionally, an ablation study on the real test set\nhighlights that the context information, including phoneme and word\nrepresentations from pretrained SSL models, serves as effective domain\ninvariant training targets for separation models.", "published": "2025-03-16 17:49:07", "link": "http://arxiv.org/abs/2503.12589v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A General Close-loop Predictive Coding Framework for Auditory Working Memory", "abstract": "Auditory working memory is essential for various daily activities, such as\nlanguage acquisition, conversation. It involves the temporary storage and\nmanipulation of information that is no longer present in the environment. While\nextensively studied in neuroscience and cognitive science, research on its\nmodeling within neural networks remains limited. To address this gap, we\npropose a general framework based on a close-loop predictive coding paradigm to\nperform short auditory signal memory tasks. The framework is evaluated on two\nwidely used benchmark datasets for environmental sound and speech,\ndemonstrating high semantic similarity across both datasets.", "published": "2025-03-16 13:57:37", "link": "http://arxiv.org/abs/2503.12506v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Serenade: A Singing Style Conversion Framework Based On Audio Infilling", "abstract": "We propose Serenade, a novel framework for the singing style conversion (SSC)\ntask. Although singer identity conversion has made great strides in the\nprevious years, converting the singing style of a singer has been an unexplored\nresearch area. We find three main challenges in SSC: modeling the target style,\ndisentangling source style, and retaining the source melody. To model the\ntarget singing style, we use an audio infilling task by predicting a masked\nsegment of the target mel-spectrogram with a flow-matching model using the\ncomplement of the masked target mel-spectrogram along with disentangled\nacoustic features. On the other hand, to disentangle the source singing style,\nwe use a cyclic training approach, where we use synthetic converted samples as\nsource inputs and reconstruct the original source mel-spectrogram as a target.\nFinally, to retain the source melody better, we investigate a post-processing\nmodule using a source-filter-based vocoder and resynthesize the converted\nwaveforms using the original F0 patterns. Our results showed that the Serenade\nframework can handle generalized SSC tasks with the best overall similarity\nscore, especially in modeling breathy and mixed singing styles. Moreover,\nalthough resynthesizing with the original F0 patterns alleviated out-of-tune\nsinging and improved naturalness, we found a slight tradeoff in similarity due\nto not changing the F0 patterns into the target style.", "published": "2025-03-16 07:20:22", "link": "http://arxiv.org/abs/2503.12388v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
