{"title": "Instructive Decoding: Instruction-Tuned Large Language Models are\n  Self-Refiner from Noisy Instructions", "abstract": "While instruction-tuned language models have demonstrated impressive\nzero-shot generalization, these models often struggle to generate accurate\nresponses when faced with instructions that fall outside their training set.\nThis paper presents Instructive Decoding (ID), a simple yet effective approach\nthat augments the efficacy of instruction-tuned models. Specifically, ID\nadjusts the logits for next-token prediction in a contrastive manner, utilizing\npredictions generated from a manipulated version of the original instruction,\nreferred to as a noisy instruction. This noisy instruction aims to elicit\nresponses that could diverge from the intended instruction yet remain\nplausible. We conduct experiments across a spectrum of such noisy instructions,\nranging from those that insert semantic noise via random words to others like\n'opposite' that elicit the deviated responses. Our approach achieves\nconsiderable performance gains across various instruction-tuned models and\ntasks without necessitating any additional parameter updates. Notably,\nutilizing 'opposite' as the noisy instruction in ID, which exhibits the maximum\ndivergence from the original instruction, consistently produces the most\nsignificant performance gains across multiple models and tasks.", "published": "2023-11-01 02:31:35", "link": "http://arxiv.org/abs/2311.00233v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Mystery of In-Context Learning: A Comprehensive Survey on\n  Interpretation and Analysis", "abstract": "Understanding in-context learning (ICL) capability that enables large\nlanguage models (LLMs) to excel in proficiency through demonstration examples\nis of utmost importance. This importance stems not only from the better\nutilization of this capability across various tasks, but also from the\nproactive identification and mitigation of potential risks, including concerns\nregarding truthfulness, bias, and toxicity, that may arise alongside the\ncapability. In this paper, we present a thorough survey on the interpretation\nand analysis of in-context learning. First, we provide a concise introduction\nto the background and definition of in-context learning. Then, we give an\noverview of advancements from two perspectives: 1) a theoretical perspective,\nemphasizing studies on mechanistic interpretability and delving into the\nmathematical foundations behind ICL; and 2) an empirical perspective,\nconcerning studies that empirically analyze factors associated with ICL. We\nconclude by highlighting the challenges encountered and suggesting potential\navenues for future research. We believe that our work establishes the basis for\nfurther exploration into the interpretation of in-context learning.\nAdditionally, we have created a repository containing the resources referenced\nin our survey.", "published": "2023-11-01 02:40:42", "link": "http://arxiv.org/abs/2311.00237v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Syntactic Inductive Bias in Transformer Language Models: Especially\n  Helpful for Low-Resource Languages?", "abstract": "A line of work on Transformer-based language models such as BERT has\nattempted to use syntactic inductive bias to enhance the pretraining process,\non the theory that building syntactic structure into the training process\nshould reduce the amount of data needed for training. But such methods are\noften tested for high-resource languages such as English. In this work, we\ninvestigate whether these methods can compensate for data sparseness in\nlow-resource languages, hypothesizing that they ought to be more effective for\nlow-resource languages. We experiment with five low-resource languages: Uyghur,\nWolof, Maltese, Coptic, and Ancient Greek. We find that these syntactic\ninductive bias methods produce uneven results in low-resource settings, and\nprovide surprisingly little benefit in most cases.", "published": "2023-11-01 03:32:46", "link": "http://arxiv.org/abs/2311.00268v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SoulChat: Improving LLMs' Empathy, Listening, and Comfort Abilities\n  through Fine-tuning with Multi-turn Empathy Conversations", "abstract": "Large language models (LLMs) have been widely applied in various fields due\nto their excellent capability for memorizing knowledge and chain of thought\n(CoT). When these language models are applied in the field of psychological\ncounseling, they often rush to provide universal advice. However, when users\nseek psychological support, they need to gain empathy, trust, understanding and\ncomfort, rather than just reasonable advice. To this end, we constructed a\nmulti-turn empathetic conversation dataset of more than 2 million samples, in\nwhich the input is the multi-turn conversation context, and the target is\nempathetic responses that cover expressions such as questioning, comfort,\nrecognition, listening, trust, emotional support, etc. Experiments have shown\nthat the empathy ability of LLMs can be significantly enhanced when finetuning\nby using multi-turn dialogue history and responses that are closer to the\nexpression of a psychological consultant.", "published": "2023-11-01 03:49:52", "link": "http://arxiv.org/abs/2311.00273v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IBADR: an Iterative Bias-Aware Dataset Refinement Framework for\n  Debiasing NLU models", "abstract": "As commonly-used methods for debiasing natural language understanding (NLU)\nmodels, dataset refinement approaches heavily rely on manual data analysis, and\nthus maybe unable to cover all the potential biased features. In this paper, we\npropose IBADR, an Iterative Bias-Aware Dataset Refinement framework, which\ndebiases NLU models without predefining biased features. We maintain an\niteratively expanded sample pool. Specifically, at each iteration, we first\ntrain a shallow model to quantify the bias degree of samples in the pool. Then,\nwe pair each sample with a bias indicator representing its bias degree, and use\nthese extended samples to train a sample generator. In this way, this generator\ncan effectively learn the correspondence relationship between bias indicators\nand samples. Furthermore, we employ the generator to produce pseudo samples\nwith fewer biased features by feeding specific bias indicators. Finally, we\nincorporate the generated pseudo samples into the pool. Experimental results\nand in-depth analyses on two NLU tasks show that IBADR not only significantly\noutperforms existing dataset refinement approaches, achieving SOTA, but also is\ncompatible with model-centric methods.", "published": "2023-11-01 04:50:38", "link": "http://arxiv.org/abs/2311.00292v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic Representation Learning of Scientific Literature based on\n  Adaptive Feature and Graph Neural Network", "abstract": "Because most of the scientific literature data is unmarked, it makes semantic\nrepresentation learning based on unsupervised graph become crucial. At the same\ntime, in order to enrich the features of scientific literature, a learning\nmethod of semantic representation of scientific literature based on adaptive\nfeatures and graph neural network is proposed. By introducing the adaptive\nfeature method, the features of scientific literature are considered globally\nand locally. The graph attention mechanism is used to sum the features of\nscientific literature with citation relationship, and give each scientific\nliterature different feature weights, so as to better express the correlation\nbetween the features of different scientific literature. In addition, an\nunsupervised graph neural network semantic representation learning method is\nproposed. By comparing the mutual information between the positive and negative\nlocal semantic representation of scientific literature and the global graph\nsemantic representation in the potential space, the graph neural network can\ncapture the local and global information, thus improving the learning ability\nof the semantic representation of scientific literature. The experimental\nresults show that the proposed learning method of semantic representation of\nscientific literature based on adaptive feature and graph neural network is\ncompetitive on the basis of scientific literature classification, and has\nachieved good results.", "published": "2023-11-01 05:00:44", "link": "http://arxiv.org/abs/2311.00296v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Entity Alignment Method of Science and Technology Patent based on Graph\n  Convolution Network and Information Fusion", "abstract": "The entity alignment of science and technology patents aims to link the\nequivalent entities in the knowledge graph of different science and technology\npatent data sources. Most entity alignment methods only use graph neural\nnetwork to obtain the embedding of graph structure or use attribute text\ndescription to obtain semantic representation, ignoring the process of\nmulti-information fusion in science and technology patents. In order to make\nuse of the graphic structure and auxiliary information such as the name,\ndescription and attribute of the patent entity, this paper proposes an entity\nalignment method based on the graph convolution network for science and\ntechnology patent information fusion. Through the graph convolution network and\nBERT model, the structure information and entity attribute information of the\nscience and technology patent knowledge graph are embedded and represented to\nachieve multi-information fusion, thus improving the performance of entity\nalignment. Experiments on three benchmark data sets show that the proposed\nmethod Hit@K The evaluation indicators are better than the existing methods.", "published": "2023-11-01 05:04:55", "link": "http://arxiv.org/abs/2311.00300v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Probing Explicit and Implicit Gender Bias through LLM Conditional Text\n  Generation", "abstract": "Large Language Models (LLMs) can generate biased and toxic responses. Yet\nmost prior work on LLM gender bias evaluation requires predefined\ngender-related phrases or gender stereotypes, which are challenging to be\ncomprehensively collected and are limited to explicit bias evaluation. In\naddition, we believe that instances devoid of gender-related language or\nexplicit stereotypes in inputs can still induce gender bias in LLMs. Thus, in\nthis work, we propose a conditional text generation mechanism without the need\nfor predefined gender phrases and stereotypes. This approach employs three\ntypes of inputs generated through three distinct strategies to probe LLMs,\naiming to show evidence of explicit and implicit gender biases in LLMs. We also\nutilize explicit and implicit evaluation metrics to evaluate gender bias in\nLLMs under different strategies. Our experiments demonstrate that an increased\nmodel size does not consistently lead to enhanced fairness and all tested LLMs\nexhibit explicit and/or implicit gender bias, even when explicit gender\nstereotypes are absent in the inputs.", "published": "2023-11-01 05:31:46", "link": "http://arxiv.org/abs/2311.00306v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HARE: Explainable Hate Speech Detection with Step-by-Step Reasoning", "abstract": "With the proliferation of social media, accurate detection of hate speech has\nbecome critical to ensure safety online. To combat nuanced forms of hate\nspeech, it is important to identify and thoroughly explain hate speech to help\nusers understand its harmful effects. Recent benchmarks have attempted to\ntackle this issue by training generative models on free-text annotations of\nimplications in hateful text. However, we find significant reasoning gaps in\nthe existing annotations schemes, which may hinder the supervision of detection\nmodels. In this paper, we introduce a hate speech detection framework, HARE,\nwhich harnesses the reasoning capabilities of large language models (LLMs) to\nfill these gaps in explanations of hate speech, thus enabling effective\nsupervision of detection models. Experiments on SBIC and Implicit Hate\nbenchmarks show that our method, using model-generated data, consistently\noutperforms baselines, using existing free-text human annotations. Analysis\ndemonstrates that our method enhances the explanation quality of trained models\nand improves generalization to unseen datasets. Our code is available at\nhttps://github.com/joonkeekim/hare-hate-speech.git.", "published": "2023-11-01 06:09:54", "link": "http://arxiv.org/abs/2311.00321v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AdaSent: Efficient Domain-Adapted Sentence Embeddings for Few-Shot\n  Classification", "abstract": "Recent work has found that few-shot sentence classification based on\npre-trained Sentence Encoders (SEs) is efficient, robust, and effective. In\nthis work, we investigate strategies for domain-specialization in the context\nof few-shot sentence classification with SEs. We first establish that\nunsupervised Domain-Adaptive Pre-Training (DAPT) of a base Pre-trained Language\nModel (PLM) (i.e., not an SE) substantially improves the accuracy of few-shot\nsentence classification by up to 8.4 points. However, applying DAPT on SEs, on\nthe one hand, disrupts the effects of their (general-domain) Sentence Embedding\nPre-Training (SEPT). On the other hand, applying general-domain SEPT on top of\na domain-adapted base PLM (i.e., after DAPT) is effective but inefficient,\nsince the computationally expensive SEPT needs to be executed on top of a\nDAPT-ed PLM of each domain. As a solution, we propose AdaSent, which decouples\nSEPT from DAPT by training a SEPT adapter on the base PLM. The adapter can be\ninserted into DAPT-ed PLMs from any domain. We demonstrate AdaSent's\neffectiveness in extensive experiments on 17 different few-shot sentence\nclassification datasets. AdaSent matches or surpasses the performance of full\nSEPT on DAPT-ed PLM, while substantially reducing the training costs. The code\nfor AdaSent is available.", "published": "2023-11-01 10:00:15", "link": "http://arxiv.org/abs/2311.00408v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Discourse Relations Classification and Cross-Framework Discourse\n  Relation Classification Through the Lens of Cognitive Dimensions: An\n  Empirical Investigation", "abstract": "Existing discourse formalisms use different taxonomies of discourse\nrelations, which require expert knowledge to understand, posing a challenge for\nannotation and automatic classification. We show that discourse relations can\nbe effectively captured by some simple cognitively inspired dimensions proposed\nby Sanders et al.(2018). Our experiments on cross-framework discourse relation\nclassification (PDTB & RST) demonstrate that it is possible to transfer\nknowledge of discourse relations for one framework to another framework by\nmeans of these dimensions, in spite of differences in discourse segmentation of\nthe two frameworks. This manifests the effectiveness of these dimensions in\ncharacterizing discourse relations across frameworks. Ablation studies reveal\nthat different dimensions influence different types of discourse relations. The\npatterns can be explained by the role of dimensions in characterizing and\ndistinguishing different relations. We also report our experimental results on\nautomatic prediction of these dimensions.", "published": "2023-11-01 11:38:19", "link": "http://arxiv.org/abs/2311.00451v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Style Locality for Controllable Generation with kNN Language Models", "abstract": "Recent language models have been improved by the addition of external memory.\nNearest neighbor language models retrieve similar contexts to assist in word\nprediction. The addition of locality levels allows a model to learn how to\nweight neighbors based on their relative location to the current text in source\ndocuments, and have been shown to further improve model performance. Nearest\nneighbor models have been explored for controllable generation but have not\nexamined the use of locality levels. We present a novel approach for this\npurpose and evaluate it using automatic and human evaluation on politeness,\nformality, supportiveness, and toxicity textual data. We find that our model is\nsuccessfully able to control style and provides a better fluency-style\ntrade-off than previous work.", "published": "2023-11-01 12:21:53", "link": "http://arxiv.org/abs/2311.00475v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Robustness Tests for Automatic Machine Translation Metrics with\n  Adversarial Attacks", "abstract": "We investigate MT evaluation metric performance on adversarially-synthesized\ntexts, to shed light on metric robustness. We experiment with word- and\ncharacter-level attacks on three popular machine translation metrics:\nBERTScore, BLEURT, and COMET. Our human experiments validate that automatic\nmetrics tend to overpenalize adversarially-degraded translations. We also\nidentify inconsistencies in BERTScore ratings, where it judges the original\nsentence and the adversarially-degraded one as similar, while judging the\ndegraded translation as notably worse than the original with respect to the\nreference. We identify patterns of brittleness that motivate more robust metric\ndevelopment.", "published": "2023-11-01 13:14:23", "link": "http://arxiv.org/abs/2311.00508v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Text Rendering Strategies for Pixel Language Models", "abstract": "Pixel-based language models process text rendered as images, which allows\nthem to handle any script, making them a promising approach to open vocabulary\nlanguage modelling. However, recent approaches use text renderers that produce\na large set of almost-equivalent input patches, which may prove sub-optimal for\ndownstream tasks, due to redundancy in the input representations. In this\npaper, we investigate four approaches to rendering text in the PIXEL model\n(Rust et al., 2023), and find that simple character bigram rendering brings\nimproved performance on sentence-level tasks without compromising performance\non token-level or multilingual tasks. This new rendering strategy also makes it\npossible to train a more compact model with only 22M parameters that performs\non par with the original 86M parameter model. Our analyses show that character\nbigram rendering leads to a consistently better model but with an anisotropic\npatch embedding space, driven by a patch frequency bias, highlighting the\nconnections between image patch- and tokenization-based language models.", "published": "2023-11-01 13:49:31", "link": "http://arxiv.org/abs/2311.00522v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Crosslingual Retrieval Augmented In-context Learning for Bangla", "abstract": "The promise of Large Language Models (LLMs) in Natural Language Processing\nhas often been overshadowed by their limited performance in low-resource\nlanguages such as Bangla. To address this, our paper presents a pioneering\napproach that utilizes cross-lingual retrieval augmented in-context learning.\nBy strategically sourcing semantically similar prompts from high-resource\nlanguage, we enable multilingual pretrained language models (MPLMs), especially\nthe generative model BLOOMZ, to successfully boost performance on Bangla tasks.\nOur extensive evaluation highlights that the cross-lingual retrieval augmented\nprompts bring steady improvements to MPLMs over the zero-shot performance.", "published": "2023-11-01 15:32:50", "link": "http://arxiv.org/abs/2311.00587v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Explicit Morphological Knowledge Improves Pre-training of Language\n  Models for Hebrew", "abstract": "Pre-trained language models (PLMs) have shown remarkable successes in\nacquiring a wide range of linguistic knowledge, relying solely on\nself-supervised training on text streams. Nevertheless, the effectiveness of\nthis language-agnostic approach has been frequently questioned for its\nsub-optimal performance when applied to morphologically-rich languages (MRLs).\nWe investigate the hypothesis that incorporating explicit morphological\nknowledge in the pre-training phase can improve the performance of PLMs for\nMRLs. We propose various morphologically driven tokenization methods enabling\nthe model to leverage morphological cues beyond raw text. We pre-train multiple\nlanguage models utilizing the different methods and evaluate them on Hebrew, a\nlanguage with complex and highly ambiguous morphology. Our experiments show\nthat morphologically driven tokenization demonstrates improved results compared\nto a standard language-agnostic tokenization, on a benchmark of both semantic\nand morphologic tasks. These findings suggest that incorporating morphological\nknowledge holds the potential for further improving PLMs for morphologically\nrich languages.", "published": "2023-11-01 17:02:49", "link": "http://arxiv.org/abs/2311.00658v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Emotion Detection for Misinformation: A Review", "abstract": "With the advent of social media, an increasing number of netizens are sharing\nand reading posts and news online. However, the huge volumes of misinformation\n(e.g., fake news and rumors) that flood the internet can adversely affect\npeople's lives, and have resulted in the emergence of rumor and fake news\ndetection as a hot research topic. The emotions and sentiments of netizens, as\nexpressed in social media posts and news, constitute important factors that can\nhelp to distinguish fake news from genuine news and to understand the spread of\nrumors. This article comprehensively reviews emotion-based methods for\nmisinformation detection. We begin by explaining the strong links between\nemotions and misinformation. We subsequently provide a detailed analysis of a\nrange of misinformation detection methods that employ a variety of emotion,\nsentiment and stance-based features, and describe their strengths and\nweaknesses. Finally, we discuss a number of ongoing challenges in emotion-based\nmisinformation detection based on large language models and suggest future\nresearch directions, including data collection (multi-platform, multilingual),\nannotation, benchmark, multimodality, and interpretability.", "published": "2023-11-01 17:21:09", "link": "http://arxiv.org/abs/2311.00671v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are Large Language Models Reliable Judges? A Study on the Factuality\n  Evaluation Capabilities of LLMs", "abstract": "In recent years, Large Language Models (LLMs) have gained immense attention\ndue to their notable emergent capabilities, surpassing those seen in earlier\nlanguage models. A particularly intriguing application of LLMs is their role as\nevaluators for texts produced by various generative models.\n  In this study, we delve into the potential of LLMs as reliable assessors of\nfactual consistency in summaries generated by text-generation models.\nInitially, we introduce an innovative approach for factuality assessment using\nLLMs. This entails employing a singular LLM for the entirety of the\nquestion-answering-based factuality scoring process. Following this, we examine\nthe efficacy of various LLMs in direct factuality scoring, benchmarking them\nagainst traditional measures and human annotations.\n  Contrary to initial expectations, our results indicate a lack of significant\ncorrelations between factuality metrics and human evaluations, specifically for\nGPT-4 and PaLM-2. Notable correlations were only observed with GPT-3.5 across\ntwo factuality subcategories. These consistent findings across various factual\nerror categories suggest a fundamental limitation in the current LLMs'\ncapability to accurately gauge factuality.\n  This version presents the information more concisely while maintaining the\nmain points and findings of the original text.", "published": "2023-11-01 17:42:45", "link": "http://arxiv.org/abs/2311.00681v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Little Giants: Exploring the Potential of Small LLMs as Evaluation\n  Metrics in Summarization in the Eval4NLP 2023 Shared Task", "abstract": "This paper describes and analyzes our participation in the 2023 Eval4NLP\nshared task, which focuses on assessing the effectiveness of prompt-based\ntechniques to empower Large Language Models to handle the task of quality\nestimation, particularly in the context of evaluating machine translations and\nsummaries. We conducted systematic experiments with various prompting\ntechniques, including standard prompting, prompts informed by annotator\ninstructions, and innovative chain-of-thought prompting. In addition, we\nintegrated these approaches with zero-shot and one-shot learning methods to\nmaximize the efficacy of our evaluation procedures. Our work reveals that\ncombining these approaches using a \"small\", open source model (orca_mini_v3_7B)\nyields competitive results.", "published": "2023-11-01 17:44:35", "link": "http://arxiv.org/abs/2311.00686v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Construction Artifacts in Metaphor Identification Datasets", "abstract": "Metaphor identification aims at understanding whether a given expression is\nused figuratively in context. However, in this paper we show how existing\nmetaphor identification datasets can be gamed by fully ignoring the potential\nmetaphorical expression or the context in which it occurs. We test this\nhypothesis in a variety of datasets and settings, and show that metaphor\nidentification systems based on language models without complete information\ncan be competitive with those using the full context. This is due to the\nconstruction procedures to build such datasets, which introduce unwanted biases\nfor positive and negative classes. Finally, we test the same hypothesis on\ndatasets that are carefully sampled from natural corpora and where this bias is\nnot present, making these datasets more challenging and reliable.", "published": "2023-11-01 19:21:55", "link": "http://arxiv.org/abs/2311.00790v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Calibrated Seq2seq Models for Efficient and Generalizable Ultra-fine\n  Entity Typing", "abstract": "Ultra-fine entity typing plays a crucial role in information extraction by\npredicting fine-grained semantic types for entity mentions in text. However,\nthis task poses significant challenges due to the massive number of entity\ntypes in the output space. The current state-of-the-art approaches, based on\nstandard multi-label classifiers or cross-encoder models, suffer from poor\ngeneralization performance or inefficient inference. In this paper, we present\nCASENT, a seq2seq model designed for ultra-fine entity typing that predicts\nultra-fine types with calibrated confidence scores. Our model takes an entity\nmention as input and employs constrained beam search to generate multiple types\nautoregressively. The raw sequence probabilities associated with the predicted\ntypes are then transformed into confidence scores using a novel calibration\nmethod. We conduct extensive experiments on the UFET dataset which contains\nover 10k types. Our method outperforms the previous state-of-the-art in terms\nof F1 score and calibration error, while achieving an inference speedup of over\n50 times. Additionally, we demonstrate the generalization capabilities of our\nmodel by evaluating it in zero-shot and few-shot settings on five specialized\ndomain entity typing datasets that are unseen during training. Remarkably, our\nmodel outperforms large language models with 10 times more parameters in the\nzero-shot setting, and when fine-tuned on 50 examples, it significantly\noutperforms ChatGPT on all datasets. Our code, models and demo are available at\nhttps://github.com/yanlinf/CASENT.", "published": "2023-11-01 20:39:12", "link": "http://arxiv.org/abs/2311.00835v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Continuous Training and Fine-tuning for Domain-Specific Language Models\n  in Medical Question Answering", "abstract": "Large language models exhibit promising general capabilities but often lack\nspecialized knowledge for domain-specific tasks. Developing domain experts from\na base model enables a range of applications without prohibitive training\ncosts. This work demonstrates a method using continuous training and\ninstruction fine-tuning to rapidly adapt Llama 2 base models to the Chinese\nmedical domain. We first conduct continuous training on 1B tokens from Chinese\nmedical references to teach relevant vocabulary and knowledge. The models are\nthen fine-tuned on 54K examples sourced from the Chinese National Medical\nLicensing Examination. Experiments on Chinese medical data confirm the\neffectiveness of this approach, producing a model comparable to GPT-3.5-turbo\nwhile using way less computational resource. The resulting domain-specific\nmodel could be useful for various Chinese medical applications. More broadly,\nthis provides a template for domain-specific training of large language models\nin areas where pre-trained models lack the required expertise, such as law,\nscience, and engineering.", "published": "2023-11-01 00:18:00", "link": "http://arxiv.org/abs/2311.00204v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Is GPT Powerful Enough to Analyze the Emotions of Memes?", "abstract": "Large Language Models (LLMs), representing a significant achievement in\nartificial intelligence (AI) research, have demonstrated their ability in a\nmultitude of tasks. This project aims to explore the capabilities of GPT-3.5, a\nleading example of LLMs, in processing the sentiment analysis of Internet\nmemes. Memes, which include both verbal and visual aspects, act as a powerful\nyet complex tool for expressing ideas and sentiments, demanding an\nunderstanding of societal norms and cultural contexts. Notably, the detection\nand moderation of hateful memes pose a significant challenge due to their\nimplicit offensive nature. This project investigates GPT's proficiency in such\nsubjective tasks, revealing its strengths and potential limitations. The tasks\ninclude the classification of meme sentiment, determination of humor type, and\ndetection of implicit hate in memes. The performance evaluation, using datasets\nfrom SemEval-2020 Task 8 and Facebook hateful memes, offers a comparative\nunderstanding of GPT responses against human annotations. Despite GPT's\nremarkable progress, our findings underscore the challenges faced by these\nmodels in handling subjective tasks, which are rooted in their inherent\nlimitations including contextual understanding, interpretation of implicit\nmeanings, and data biases. This research contributes to the broader discourse\non the applicability of AI in handling complex, context-dependent tasks, and\noffers valuable insights for future advancements.", "published": "2023-11-01 01:57:48", "link": "http://arxiv.org/abs/2311.00223v1", "categories": ["cs.CL", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Noisy Exemplars Make Large Language Models More Robust: A\n  Domain-Agnostic Behavioral Analysis", "abstract": "Recent advances in prompt engineering enable large language models (LLMs) to\nsolve multi-hop logical reasoning problems with impressive accuracy. However,\nthere is little existing work investigating the robustness of LLMs with\nfew-shot prompting techniques. Therefore, we introduce a systematic approach to\ntest the robustness of LLMs in multi-hop reasoning tasks via domain-agnostic\nperturbations. We include perturbations at multiple levels of abstractions\n(e.g. lexical perturbations such as typos, and semantic perturbations such as\nthe inclusion of intermediate reasoning steps in the questions) to conduct\nbehavioral analysis on the LLMs. Throughout our experiments, we find that\nmodels are more sensitive to certain perturbations such as replacing words with\ntheir synonyms. We also demonstrate that increasing the proportion of perturbed\nexemplars in the prompts improves the robustness of few-shot prompting methods.", "published": "2023-11-01 03:15:05", "link": "http://arxiv.org/abs/2311.00258v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Plug-and-Play Policy Planner for Large Language Model Powered Dialogue\n  Agents", "abstract": "Proactive dialogues serve as a practical yet challenging dialogue problem in\nthe era of large language models (LLMs), where the dialogue policy planning is\nthe key to improving the proactivity of LLMs. Most existing studies enable the\ndialogue policy planning of LLMs using various prompting schemes or iteratively\nenhance this capability in handling the given case with verbal AI feedback.\nHowever, these approaches are either bounded by the policy planning capability\nof the frozen LLMs or hard to be transferred to new cases. In this work, we\nintroduce a new dialogue policy planning paradigm to strategize LLMs for\nproactive dialogue problems with a tunable language model plug-in as a\nplug-and-play dialogue policy planner, named PPDPP. Specifically, we develop a\nnovel training framework to facilitate supervised fine-tuning over available\nhuman-annotated data as well as reinforcement learning from goal-oriented AI\nfeedback with dynamic interaction data collected by the LLM-based self-play\nsimulation. In this manner, the LLM-powered dialogue agent can not only be\ngeneralized to different cases after the training, but also be applicable to\ndifferent applications by just substituting the learned plug-in. In addition,\nwe propose to evaluate the policy planning capability of dialogue systems under\nthe interactive setting. Experimental results demonstrate that PPDPP\nconsistently and substantially outperforms existing approaches on three\ndifferent proactive dialogue applications, including negotiation, emotional\nsupport, and tutoring dialogues.", "published": "2023-11-01 03:20:16", "link": "http://arxiv.org/abs/2311.00262v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Active Instruction Tuning: Improving Cross-Task Generalization by\n  Training on Prompt Sensitive Tasks", "abstract": "Instruction tuning (IT) achieves impressive zero-shot generalization results\nby training large language models (LLMs) on a massive amount of diverse tasks\nwith instructions. However, how to select new tasks to improve the performance\nand generalizability of IT models remains an open question. Training on all\nexisting tasks is impractical due to prohibiting computation requirements, and\nrandomly selecting tasks can lead to suboptimal performance. In this work, we\npropose active instruction tuning based on prompt uncertainty, a novel\nframework to identify informative tasks, and then actively tune the models on\nthe selected tasks. We represent the informativeness of new tasks with the\ndisagreement of the current model outputs over perturbed prompts. Our\nexperiments on NIV2 and Self-Instruct datasets demonstrate that our method\nconsistently outperforms other baseline strategies for task selection,\nachieving better out-of-distribution generalization with fewer training tasks.\nAdditionally, we introduce a task map that categorizes and diagnoses tasks\nbased on prompt uncertainty and prediction probability. We discover that\ntraining on ambiguous (prompt-uncertain) tasks improves generalization while\ntraining on difficult (prompt-certain and low-probability) tasks offers no\nbenefit, underscoring the importance of task selection for instruction tuning.", "published": "2023-11-01 04:40:05", "link": "http://arxiv.org/abs/2311.00288v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Unsupervised Lexical Simplification with Context Augmentation", "abstract": "We propose a new unsupervised lexical simplification method that uses only\nmonolingual data and pre-trained language models. Given a target word and its\ncontext, our method generates substitutes based on the target context and also\nadditional contexts sampled from monolingual data. We conduct experiments in\nEnglish, Portuguese, and Spanish on the TSAR-2022 shared task, and show that\nour model substantially outperforms other unsupervised systems across all\nlanguages. We also establish a new state-of-the-art by ensembling our model\nwith GPT-3.5. Lastly, we evaluate our model on the SWORDS lexical substitution\ndata set, achieving a state-of-the-art result.", "published": "2023-11-01 05:48:05", "link": "http://arxiv.org/abs/2311.00310v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Prompt-based Logical Semantics Enhancement for Implicit Discourse\n  Relation Recognition", "abstract": "Implicit Discourse Relation Recognition (IDRR), which infers discourse\nrelations without the help of explicit connectives, is still a crucial and\nchallenging task for discourse parsing. Recent works tend to exploit the\nhierarchical structure information from the annotated senses, which demonstrate\nenhanced discourse relation representations can be obtained by integrating\nsense hierarchy. Nevertheless, the performance and robustness for IDRR are\nsignificantly constrained by the availability of annotated data. Fortunately,\nthere is a wealth of unannotated utterances with explicit connectives, that can\nbe utilized to acquire enriched discourse relation features. In light of such\nmotivation, we propose a Prompt-based Logical Semantics Enhancement (PLSE)\nmethod for IDRR. Essentially, our method seamlessly injects knowledge relevant\nto discourse relation into pre-trained language models through prompt-based\nconnective prediction. Furthermore, considering the prompt-based connective\nprediction exhibits local dependencies due to the deficiency of masked language\nmodel (MLM) in capturing global semantics, we design a novel self-supervised\nlearning objective based on mutual information maximization to derive enhanced\nrepresentations of logical semantics for IDRR. Experimental results on PDTB 2.0\nand CoNLL16 datasets demonstrate that our method achieves outstanding and\nconsistent performance against the current state-of-the-art models.", "published": "2023-11-01 08:38:08", "link": "http://arxiv.org/abs/2311.00367v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhanced Knowledge Injection for Radiology Report Generation", "abstract": "Automatic generation of radiology reports holds crucial clinical value, as it\ncan alleviate substantial workload on radiologists and remind less experienced\nones of potential anomalies. Despite the remarkable performance of various\nimage captioning methods in the natural image field, generating accurate\nreports for medical images still faces challenges, i.e., disparities in visual\nand textual data, and lack of accurate domain knowledge. To address these\nissues, we propose an enhanced knowledge injection framework, which utilizes\ntwo branches to extract different types of knowledge. The Weighted Concept\nKnowledge (WCK) branch is responsible for introducing clinical medical concepts\nweighted by TF-IDF scores. The Multimodal Retrieval Knowledge (MRK) branch\nextracts triplets from similar reports, emphasizing crucial clinical\ninformation related to entity positions and existence. By integrating this\nfiner-grained and well-structured knowledge with the current image, we are able\nto leverage the multi-source knowledge gain to ultimately facilitate more\naccurate report generation. Extensive experiments have been conducted on two\npublic benchmarks, demonstrating that our method achieves superior performance\nover other state-of-the-art methods. Ablation studies further validate the\neffectiveness of two extracted knowledge sources.", "published": "2023-11-01 09:50:55", "link": "http://arxiv.org/abs/2311.00399v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Efficient Human-AI Coordination via Preparatory Language-based\n  Convention", "abstract": "Developing intelligent agents capable of seamless coordination with humans is\na critical step towards achieving artificial general intelligence. Existing\nmethods for human-AI coordination typically train an agent to coordinate with a\ndiverse set of policies or with human models fitted from real human data.\nHowever, the massively diverse styles of human behavior present obstacles for\nAI systems with constrained capacity, while high quality human data may not be\nreadily available in real-world scenarios. In this study, we observe that prior\nto coordination, humans engage in communication to establish conventions that\nspecify individual roles and actions, making their coordination proceed in an\norderly manner. Building upon this observation, we propose employing the large\nlanguage model (LLM) to develop an action plan (or equivalently, a convention)\nthat effectively guides both human and AI. By inputting task requirements,\nhuman preferences, the number of agents, and other pertinent information into\nthe LLM, it can generate a comprehensive convention that facilitates a clear\nunderstanding of tasks and responsibilities for all parties involved.\nFurthermore, we demonstrate that decomposing the convention formulation problem\ninto sub-problems with multiple new sessions being sequentially employed and\nhuman feedback, will yield a more efficient coordination convention.\nExperimental evaluations conducted in the Overcooked-AI environment, utilizing\na human proxy model, highlight the superior performance of our proposed method\ncompared to existing learning-based approaches. When coordinating with real\nhumans, our method achieves better alignment with human preferences and an\naverage performance improvement of 15% compared to the state-of-the-art.", "published": "2023-11-01 10:18:23", "link": "http://arxiv.org/abs/2311.00416v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Comparing Optimization Targets for Contrast-Consistent Search", "abstract": "We investigate the optimization target of Contrast-Consistent Search (CCS),\nwhich aims to recover the internal representations of truth of a large language\nmodel. We present a new loss function that we call the Midpoint-Displacement\n(MD) loss function. We demonstrate that for a certain hyper-parameter value\nthis MD loss function leads to a prober with very similar weights to CCS. We\nfurther show that this hyper-parameter is not optimal and that with a better\nhyper-parameter the MD loss function attains a higher test accuracy than CCS.", "published": "2023-11-01 12:42:14", "link": "http://arxiv.org/abs/2311.00488v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "An Embedded Diachronic Sense Change Model with a Case Study from Ancient\n  Greek", "abstract": "Word meanings change over time, and word senses evolve, emerge or die out in\nthe process. For ancient languages, where the corpora are often small and\nsparse, modelling such changes accurately proves challenging, and quantifying\nuncertainty in sense-change estimates consequently becomes important. GASC\n(Genre-Aware Semantic Change) and DiSC (Diachronic Sense Change) are existing\ngenerative models that have been used to analyse sense change for target words\nfrom an ancient Greek text corpus, using unsupervised learning without the help\nof any pre-training. These models represent the senses of a given target word\nsuch as \"kosmos\" (meaning decoration, order or world) as distributions over\ncontext words, and sense prevalence as a distribution over senses. The models\nare fitted using Markov Chain Monte Carlo (MCMC) methods to measure temporal\nchanges in these representations. This paper introduces EDiSC, an Embedded DiSC\nmodel, which combines word embeddings with DiSC to provide superior model\nperformance. It is shown empirically that EDiSC offers improved predictive\naccuracy, ground-truth recovery and uncertainty quantification, as well as\nbetter sampling efficiency and scalability properties with MCMC methods. The\nchallenges of fitting these models are also discussed.", "published": "2023-11-01 14:20:18", "link": "http://arxiv.org/abs/2311.00541v5", "categories": ["cs.CL", "stat.ME"], "primary_category": "cs.CL"}
{"title": "Boosting Summarization with Normalizing Flows and Aggressive Training", "abstract": "This paper presents FlowSUM, a normalizing flows-based variational\nencoder-decoder framework for Transformer-based summarization. Our approach\ntackles two primary challenges in variational summarization: insufficient\nsemantic information in latent representations and posterior collapse during\ntraining. To address these challenges, we employ normalizing flows to enable\nflexible latent posterior modeling, and we propose a controlled alternate\naggressive training (CAAT) strategy with an improved gate mechanism.\nExperimental results show that FlowSUM significantly enhances the quality of\ngenerated summaries and unleashes the potential for knowledge distillation with\nminimal impact on inference time. Furthermore, we investigate the issue of\nposterior collapse in normalizing flows and analyze how the summary quality is\naffected by the training strategy, gate initialization, and the type and number\nof normalizing flows used, offering valuable insights for future research.", "published": "2023-11-01 15:33:38", "link": "http://arxiv.org/abs/2311.00588v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Formal Translation from Reversing Petri Nets to Coloured Petri Nets", "abstract": "Reversible computation is an emerging computing paradigm that allows any\nsequence of operations to be executed in reverse order at any point during\ncomputation. Its appeal lies in its potential for lowpower computation and its\nrelevance to a wide array of applications such as chemical reactions, quantum\ncomputation, robotics, and distributed systems. Reversing Petri nets are a\nrecently-proposed extension of Petri nets that implements the three main forms\nof reversibility, namely, backtracking, causal reversing, and\nout-of-causal-order reversing. Their distinguishing feature is the use of named\ntokens that can be combined together to form bonds. Named tokens along with a\nhistory function, constitute the means of remembering past behaviour, thus,\nenabling reversal. In recent work, we have proposed a structural translation\nfrom a subclass of RPNs to the model of Coloured Petri Nets (CPNs), an\nextension of traditional Petri nets where tokens carry data values. In this\npaper, we extend the translation to handle RPNs with token multiplicity under\nthe individual-token interpretation, a model which allows multiple tokens of\nthe same type to exist in a system. To support the three types of\nreversibility, tokens are associated with their causal history and, while\ntokens of the same type are equally eligible to fire a transition when going\nforward, when going backwards they are able to reverse only the transitions\nthey have previously fired. The new translation, in addition to lifting the\nrestriction on token uniqueness, presents a refined approach for transforming\nRPNs to CPNs through a unifying approach that allows instantiating each of the\nthree types of reversibility. The paper also reports on a tool that implements\nthis translation, paving the way for automated translations and analysis of\nreversible systems using CPN Tools.", "published": "2023-11-01 16:28:38", "link": "http://arxiv.org/abs/2311.00629v1", "categories": ["cs.LO", "cs.CL", "03", "F.2; G.0"], "primary_category": "cs.LO"}
{"title": "Attention Alignment and Flexible Positional Embeddings Improve\n  Transformer Length Extrapolation", "abstract": "An ideal length-extrapolatable Transformer language model can handle\nsequences longer than the training length without any fine-tuning. Such\nlong-context utilization capability relies heavily on a flexible positional\nembedding design. Upon investigating the flexibility of existing large\npre-trained Transformer language models, we find that the T5 family deserves a\ncloser look, as its positional embeddings capture rich and flexible attention\npatterns. However, T5 suffers from the dispersed attention issue: the longer\nthe input sequence, the flatter the attention distribution. To alleviate the\nissue, we propose two attention alignment strategies via temperature scaling.\nOur findings show improvement on the long-context utilization capability of T5\non language modeling, retrieval, multi-document question answering, and code\ncompletion tasks without any fine-tuning. This suggests that a flexible\npositional embedding design and attention alignment can go a long way toward\nTransformer length extrapolation.", "published": "2023-11-01 17:43:35", "link": "http://arxiv.org/abs/2311.00684v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unleashing the Creative Mind: Language Model As Hierarchical Policy For\n  Improved Exploration on Challenging Problem Solving", "abstract": "Large Language Models (LLMs) have achieved tremendous progress, yet they\nstill often struggle with challenging reasoning problems. Current approaches\naddress this challenge by sampling or searching detailed and low-level\nreasoning chains. However, these methods are still limited in their exploration\ncapabilities, making it challenging for correct solutions to stand out in the\nhuge solution space. In this work, we unleash LLMs' creative potential for\nexploring multiple diverse problem solving strategies by framing an LLM as a\nhierarchical policy via in-context learning. This policy comprises of a\nvisionary leader that proposes multiple diverse high-level problem-solving\ntactics as hints, accompanied by a follower that executes detailed\nproblem-solving processes following each of the high-level instruction. The\nfollower uses each of the leader's directives as a guide and samples multiple\nreasoning chains to tackle the problem, generating a solution group for each\nleader proposal. Additionally, we propose an effective and efficient\ntournament-based approach to select among these explored solution groups to\nreach the final answer. Our approach produces meaningful and inspiring hints,\nenhances problem-solving strategy exploration, and improves the final answer\naccuracy on challenging problems in the MATH dataset. Code will be released at\nhttps://github.com/lz1oceani/LLM-As-Hierarchical-Policy.", "published": "2023-11-01 17:52:15", "link": "http://arxiv.org/abs/2311.00694v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "End-to-End Single-Channel Speaker-Turn Aware Conversational Speech\n  Translation", "abstract": "Conventional speech-to-text translation (ST) systems are trained on\nsingle-speaker utterances, and they may not generalize to real-life scenarios\nwhere the audio contains conversations by multiple speakers. In this paper, we\ntackle single-channel multi-speaker conversational ST with an end-to-end and\nmulti-task training model, named Speaker-Turn Aware Conversational Speech\nTranslation, that combines automatic speech recognition, speech translation and\nspeaker turn detection using special tokens in a serialized labeling format. We\nrun experiments on the Fisher-CALLHOME corpus, which we adapted by merging the\ntwo single-speaker channels into one multi-speaker channel, thus representing\nthe more realistic and challenging scenario with multi-speaker turns and\ncross-talk. Experimental results across single- and multi-speaker conditions\nand against conventional ST systems, show that our model outperforms the\nreference systems on the multi-speaker condition, while attaining comparable\nperformance on the single-speaker condition. We release scripts for data\nprocessing and model training.", "published": "2023-11-01 17:55:09", "link": "http://arxiv.org/abs/2311.00697v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Challenges for Linguistically-Driven Computer-Based Sign Recognition\n  from Continuous Signing for American Sign Language", "abstract": "There have been recent advances in computer-based recognition of isolated,\ncitation-form signs from video. There are many challenges for such a task, not\nleast the naturally occurring inter- and intra- signer synchronic variation in\nsign production, including sociolinguistic variation in the realization of\ncertain signs. However, there are several significant factors that make\nrecognition of signs from continuous signing an even more difficult problem.\nThis article presents an overview of such challenges, based in part on findings\nfrom a large corpus of linguistically annotated video data for American Sign\nLanguage (ASL). Some linguistic regularities in the structure of signs that can\nboost handshape and sign recognition are also discussed.", "published": "2023-11-01 18:08:44", "link": "http://arxiv.org/abs/2311.00762v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Language Model Training Paradigms for Clinical Feature Embeddings", "abstract": "In research areas with scarce data, representation learning plays a\nsignificant role. This work aims to enhance representation learning for\nclinical time series by deriving universal embeddings for clinical features,\nsuch as heart rate and blood pressure. We use self-supervised training\nparadigms for language models to learn high-quality clinical feature\nembeddings, achieving a finer granularity than existing time-step and\npatient-level representation learning. We visualize the learnt embeddings via\nunsupervised dimension reduction techniques and observe a high degree of\nconsistency with prior clinical knowledge. We also evaluate the model\nperformance on the MIMIC-III benchmark and demonstrate the effectiveness of\nusing clinical feature embeddings. We publish our code online for replication.", "published": "2023-11-01 18:23:12", "link": "http://arxiv.org/abs/2311.00768v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Automatic Disfluency Detection from Untranscribed Speech", "abstract": "Speech disfluencies, such as filled pauses or repetitions, are disruptions in\nthe typical flow of speech. Stuttering is a speech disorder characterized by a\nhigh rate of disfluencies, but all individuals speak with some disfluencies and\nthe rates of disfluencies may by increased by factors such as cognitive load.\nClinically, automatic disfluency detection may help in treatment planning for\nindividuals who stutter. Outside of the clinic, automatic disfluency detection\nmay serve as a pre-processing step to improve natural language understanding in\ndownstream applications. With this wide range of applications in mind, we\ninvestigate language, acoustic, and multimodal methods for frame-level\nautomatic disfluency detection and categorization. Each of these methods relies\non audio as an input. First, we evaluate several automatic speech recognition\n(ASR) systems in terms of their ability to transcribe disfluencies, measured\nusing disfluency error rates. We then use these ASR transcripts as input to a\nlanguage-based disfluency detection model. We find that disfluency detection\nperformance is largely limited by the quality of transcripts and alignments. We\nfind that an acoustic-based approach that does not require transcription as an\nintermediate step outperforms the ASR language approach. Finally, we present\nmultimodal architectures which we find improve disfluency detection performance\nover the unimodal approaches. Ultimately, this work introduces novel approaches\nfor automatic frame-level disfluency and categorization. In the long term, this\nwill help researchers incorporate automatic disfluency detection into a range\nof applications.", "published": "2023-11-01 21:36:39", "link": "http://arxiv.org/abs/2311.00867v1", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "An Improved Transformer-based Model for Detecting Phishing, Spam, and\n  Ham: A Large Language Model Approach", "abstract": "Phishing and spam detection is long standing challenge that has been the\nsubject of much academic research. Large Language Models (LLM) have vast\npotential to transform society and provide new and innovative approaches to\nsolve well-established challenges. Phishing and spam have caused financial\nhardships and lost time and resources to email users all over the world and\nfrequently serve as an entry point for ransomware threat actors. While\ndetection approaches exist, especially heuristic-based approaches, LLMs offer\nthe potential to venture into a new unexplored area for understanding and\nsolving this challenge. LLMs have rapidly altered the landscape from business,\nconsumers, and throughout academia and demonstrate transformational potential\nfor the potential of society. Based on this, applying these new and innovative\napproaches to email detection is a rational next step in academic research. In\nthis work, we present IPSDM, our model based on fine-tuning the BERT family of\nmodels to specifically detect phishing and spam email. We demonstrate our\nfine-tuned version, IPSDM, is able to better classify emails in both unbalanced\nand balanced datasets. This work serves as an important first step towards\nemploying LLMs to improve the security of our information systems.", "published": "2023-11-01 18:41:50", "link": "http://arxiv.org/abs/2311.04913v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "What Formal Languages Can Transformers Express? A Survey", "abstract": "As transformers have gained prominence in natural language processing, some\nresearchers have investigated theoretically what problems they can and cannot\nsolve, by treating problems as formal languages. Exploring such questions can\nhelp clarify the power of transformers relative to other models of computation,\ntheir fundamental capabilities and limits, and the impact of architectural\nchoices. Work in this subarea has made considerable progress in recent years.\nHere, we undertake a comprehensive survey of this work, documenting the diverse\nassumptions that underlie different results and providing a unified framework\nfor harmonizing seemingly contradictory findings.", "published": "2023-11-01 00:38:26", "link": "http://arxiv.org/abs/2311.00208v3", "categories": ["cs.LG", "cs.CL", "cs.FL", "cs.LO"], "primary_category": "cs.LG"}
{"title": "JADE: A Linguistics-based Safety Evaluation Platform for Large Language\n  Models", "abstract": "In this paper, we present JADE, a targeted linguistic fuzzing platform which\nstrengthens the linguistic complexity of seed questions to simultaneously and\nconsistently break a wide range of widely-used LLMs categorized in three\ngroups: eight open-sourced Chinese, six commercial Chinese and four commercial\nEnglish LLMs. JADE generates three safety benchmarks for the three groups of\nLLMs, which contain unsafe questions that are highly threatening: the questions\nsimultaneously trigger harmful generation of multiple LLMs, with an average\nunsafe generation ratio of $70\\%$ (please see the table below), while are still\nnatural questions, fluent and preserving the core unsafe semantics. We release\nthe benchmark demos generated for commercial English LLMs and open-sourced\nEnglish LLMs in the following link: https://github.com/whitzard-ai/jade-db. For\nreaders who are interested in evaluating on more questions generated by JADE,\nplease contact us.\n  JADE is based on Noam Chomsky's seminal theory of transformational-generative\ngrammar. Given a seed question with unsafe intention, JADE invokes a sequence\nof generative and transformational rules to increment the complexity of the\nsyntactic structure of the original question, until the safety guardrail is\nbroken. Our key insight is: Due to the complexity of human language, most of\nthe current best LLMs can hardly recognize the invariant evil from the infinite\nnumber of different syntactic structures which form an unbound example space\nthat can never be fully covered. Technically, the generative/transformative\nrules are constructed by native speakers of the languages, and, once developed,\ncan be used to automatically grow and transform the parse tree of a given\nquestion, until the guardrail is broken. For more evaluation results and demo,\nplease check our website: https://whitzard-ai.github.io/jade.html.", "published": "2023-11-01 04:36:45", "link": "http://arxiv.org/abs/2311.00286v3", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data\n  Generation with Large Language Models", "abstract": "Clinical natural language processing requires methods that can address\ndomain-specific challenges, such as complex medical terminology and clinical\ncontexts. Recently, large language models (LLMs) have shown promise in this\ndomain. Yet, their direct deployment can lead to privacy issues and are\nconstrained by resources. To address this challenge, we delve into synthetic\nclinical text generation using LLMs for clinical NLP tasks. We propose an\ninnovative, resource-efficient approach, ClinGen, which infuses knowledge into\nthe process. Our model involves clinical knowledge extraction and\ncontext-informed LLM prompting. Both clinical topics and writing styles are\ndrawn from external domain-specific knowledge graphs and LLMs to guide data\ngeneration. Our extensive empirical study across 7 clinical NLP tasks and 16\ndatasets reveals that ClinGen consistently enhances performance across various\ntasks, effectively aligning the distribution of real datasets and significantly\nenriching the diversity of generated training instances. Our code is available\nat \\url{https://github.com/ritaranx/ClinGen}.", "published": "2023-11-01 04:37:28", "link": "http://arxiv.org/abs/2311.00287v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "q-bio.QM"], "primary_category": "cs.CL"}
{"title": "Detecting Syllable-Level Pronunciation Stress with A Self-Attention\n  Model", "abstract": "One precondition of effective oral communication is that words should be\npronounced clearly, especially for non-native speakers. Word stress is the key\nto clear and correct English, and misplacement of syllable stress may lead to\nmisunderstandings. Thus, knowing the stress level is important for English\nspeakers and learners. This paper presents a self-attention model to identify\nthe stress level for each syllable of spoken English. Various prosodic and\ncategorical features, including the pitch level, intensity, duration and type\nof the syllable and its nuclei (the vowel of the syllable), are explored. These\nfeatures are input to the self-attention model, and syllable-level stresses are\npredicted. The simplest model yields an accuracy of over 88% and 93% on\ndifferent datasets, while more advanced models provide higher accuracy. Our\nstudy suggests that the self-attention model can be promising in stress-level\ndetection. These models could be applied to various scenarios, such as online\nmeetings and English learning.", "published": "2023-11-01 05:05:49", "link": "http://arxiv.org/abs/2311.00301v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Data Augmentation for Code Translation with Comparable Corpora and\n  Multiple References", "abstract": "One major challenge of translating code between programming languages is that\nparallel training data is often limited. To overcome this challenge, we present\ntwo data augmentation techniques, one that builds comparable corpora (i.e.,\ncode pairs with similar functionality), and another that augments existing\nparallel data with multiple reference translations. Specifically, we build and\nanalyze multiple types of comparable corpora, including programs generated from\nnatural language documentation using a code generation model. Furthermore, to\nreduce overfitting to a single reference translation, we automatically generate\nadditional translation references for available parallel data and filter the\ntranslations by unit tests, which increases variation in target translations.\nExperiments show that our data augmentation techniques significantly improve\nCodeT5 for translation between Java, Python, and C++ by an average of 7.5%\nComputational Accuracy (CA@1), which verifies the correctness of translations\nby execution. The code is available at https://github.com/Veronicium/CMTrans.", "published": "2023-11-01 06:01:22", "link": "http://arxiv.org/abs/2311.00317v2", "categories": ["cs.CL", "cs.LG", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Distil-Whisper: Robust Knowledge Distillation via Large-Scale Pseudo\n  Labelling", "abstract": "As the size of pre-trained speech recognition models increases, running these\nlarge models in low-latency or resource-constrained environments becomes\nchallenging. In this work, we leverage pseudo-labelling to assemble a\nlarge-scale open-source dataset which we use to distill the Whisper model into\na smaller variant, called Distil-Whisper. Using a simple word error rate (WER)\nheuristic, we select only the highest quality pseudo-labels for training. The\ndistilled model is 5.8 times faster with 51% fewer parameters, while performing\nto within 1% WER on out-of-distribution test data in a zero-shot transfer\nsetting. Distil-Whisper maintains the robustness of the Whisper model to\ndifficult acoustic conditions, while being less prone to hallucination errors\non long-form audio. Distil-Whisper is designed to be paired with Whisper for\nspeculative decoding, yielding a 2 times speed-up while mathematically ensuring\nthe same outputs as the original model. To facilitate further research in this\ndomain, we make our training code, inference code and models publicly\naccessible.", "published": "2023-11-01 10:45:07", "link": "http://arxiv.org/abs/2311.00430v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "A Systematic Comparison of Syllogistic Reasoning in Humans and Language\n  Models", "abstract": "A central component of rational behavior is logical inference: the process of\ndetermining which conclusions follow from a set of premises. Psychologists have\ndocumented several ways in which humans' inferences deviate from the rules of\nlogic. Do language models, which are trained on text generated by humans,\nreplicate such human biases, or are they able to overcome them? Focusing on the\ncase of syllogisms -- inferences from two simple premises -- we show that,\nwithin the PaLM2 family of transformer language models, larger models are more\nlogical than smaller ones, and also more logical than humans. At the same time,\neven the largest models make systematic errors, some of which mirror human\nreasoning biases: they show sensitivity to the (irrelevant) ordering of the\nvariables in the syllogism, and draw confident but incorrect inferences from\nparticular syllogisms (syllogistic fallacies). Overall, we find that language\nmodels often mimic the human biases included in their training data, but are\nable to overcome them in some cases.", "published": "2023-11-01 11:13:06", "link": "http://arxiv.org/abs/2311.00445v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Efficient LLM Inference on CPUs", "abstract": "Large language models (LLMs) have demonstrated remarkable performance and\ntremendous potential across a wide range of tasks. However, deploying these\nmodels has been challenging due to the astronomical amount of model parameters,\nwhich requires a demand for large memory capacity and high memory bandwidth. In\nthis paper, we propose an effective approach that can make the deployment of\nLLMs more efficiently. We support an automatic INT4 weight-only quantization\nflow and design a special LLM runtime with highly-optimized kernels to\naccelerate the LLM inference on CPUs. We demonstrate the general applicability\nof our approach on popular LLMs including Llama2, Llama, GPT-NeoX, and showcase\nthe extreme inference efficiency on CPUs. The code is publicly available at:\nhttps://github.com/intel/intel-extension-for-transformers.", "published": "2023-11-01 13:08:50", "link": "http://arxiv.org/abs/2311.00502v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Rule-Based Error Classification for Analyzing Differences in Frequent\n  Errors", "abstract": "Finding and fixing errors is a time-consuming task not only for novice\nprogrammers but also for expert programmers. Prior work has identified frequent\nerror patterns among various levels of programmers. However, the differences in\nthe tendencies between novices and experts have yet to be revealed. From the\nknowledge of the frequent errors in each level of programmers, instructors will\nbe able to provide helpful advice for each level of learners. In this paper, we\npropose a rule-based error classification tool to classify errors in code pairs\nconsisting of wrong and correct programs. We classify errors for 95,631 code\npairs and identify 3.47 errors on average, which are submitted by various\nlevels of programmers on an online judge system. The classified errors are used\nto analyze the differences in frequent errors between novice and expert\nprogrammers. The analyzed results show that, as for the same introductory\nproblems, errors made by novices are due to the lack of knowledge in\nprogramming, and the mistakes are considered an essential part of the learning\nprocess. On the other hand, errors made by experts are due to misunderstandings\ncaused by the carelessness of reading problems or the challenges of solving\nproblems differently than usual. The proposed tool can be used to create\nerror-labeled datasets and for further code-related educational research.", "published": "2023-11-01 13:36:20", "link": "http://arxiv.org/abs/2311.00513v1", "categories": ["cs.SE", "cs.CL", "cs.PL"], "primary_category": "cs.SE"}
{"title": "Improving Interpersonal Communication by Simulating Audiences with\n  Language Models", "abstract": "How do we communicate with others to achieve our goals? We use our prior\nexperience or advice from others, or construct a candidate utterance by\npredicting how it will be received. However, our experiences are limited and\nbiased, and reasoning about potential outcomes can be difficult and cognitively\nchallenging. In this paper, we explore how we can leverage Large Language Model\n(LLM) simulations to help us communicate better. We propose the\nExplore-Generate-Simulate (EGS) framework, which takes as input any scenario\nwhere an individual is communicating to an audience with a goal they want to\nachieve. EGS (1) explores the solution space by producing a diverse set of\nadvice relevant to the scenario, (2) generates communication candidates\nconditioned on subsets of the advice, and (3) simulates the reactions from\nvarious audiences to determine both the best candidate and advice to use. We\nevaluate the framework on eight scenarios spanning the ten fundamental\nprocesses of interpersonal communication. For each scenario, we collect a\ndataset of human evaluations across candidates and baselines, and showcase that\nour framework's chosen candidate is preferred over popular generation\nmechanisms including Chain-of-Thought. We also find that audience simulations\nachieve reasonably high agreement with human raters across 5 of the 8\nscenarios. Finally, we demonstrate the generality of our framework by applying\nit to real-world scenarios described by users on web forums. Through\nevaluations and demonstrations, we show that EGS enhances the effectiveness and\noutcomes of goal-oriented communication across a variety of situations, thus\nopening up new possibilities for the application of large language models in\nrevolutionizing communication and decision-making processes.", "published": "2023-11-01 17:44:50", "link": "http://arxiv.org/abs/2311.00687v2", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.AI"}
{"title": "tmn at #SMM4H 2023: Comparing Text Preprocessing Techniques for\n  Detecting Tweets Self-reporting a COVID-19 Diagnosis", "abstract": "The paper describes a system developed for Task 1 at SMM4H 2023. The goal of\nthe task is to automatically distinguish tweets that self-report a COVID-19\ndiagnosis (for example, a positive test, clinical diagnosis, or\nhospitalization) from those that do not. We investigate the use of different\ntechniques for preprocessing tweets using four transformer-based models. The\nensemble of fine-tuned language models obtained an F1-score of 84.5%, which is\n4.1% higher than the average value.", "published": "2023-11-01 07:41:23", "link": "http://arxiv.org/abs/2311.00732v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SI", "68T50", "I.2.7; I.7.m; H.3.3; J.3"], "primary_category": "cs.CL"}
{"title": "Can Large Language Models Design Accurate Label Functions?", "abstract": "Programmatic weak supervision methodologies facilitate the expedited labeling\nof extensive datasets through the use of label functions (LFs) that encapsulate\nheuristic data sources. Nonetheless, the creation of precise LFs necessitates\ndomain expertise and substantial endeavors. Recent advances in pre-trained\nlanguage models (PLMs) have exhibited substantial potential across diverse\ntasks. However, the capacity of PLMs to autonomously formulate accurate LFs\nremains an underexplored domain. In this research, we address this gap by\nintroducing DataSculpt, an interactive framework that harnesses PLMs for the\nautomated generation of LFs. Within DataSculpt, we incorporate an array of\nprompting techniques, instance selection strategies, and LF filtration methods\nto explore the expansive design landscape. Ultimately, we conduct a thorough\nassessment of DataSculpt's performance on 12 real-world datasets, encompassing\na range of tasks. This evaluation unveils both the strengths and limitations of\ncontemporary PLMs in LF design.", "published": "2023-11-01 15:14:46", "link": "http://arxiv.org/abs/2311.00739v1", "categories": ["cs.CL", "cs.DB", "cs.LG", "H.2.8; I.5.4"], "primary_category": "cs.CL"}
{"title": "Training Dynamics of Contextual N-Grams in Language Models", "abstract": "Prior work has shown the existence of contextual neurons in language models,\nincluding a neuron that activates on German text. We show that this neuron\nexists within a broader contextual n-gram circuit: we find late layer neurons\nwhich recognize and continue n-grams common in German text, but which only\nactivate if the German neuron is active. We investigate the formation of this\ncircuit throughout training and find that it is an example of what we call a\nsecond-order circuit. In particular, both the constituent n-gram circuits and\nthe German detection circuit which culminates in the German neuron form with\nindependent functions early in training - the German detection circuit\npartially through modeling German unigram statistics, and the n-grams by\nboosting appropriate completions. Only after both circuits have already formed\ndo they fit together into a second-order circuit. Contrary to the hypotheses\npresented in prior work, we find that the contextual n-gram circuit forms\ngradually rather than in a sudden phase transition. We further present a range\nof anomalous observations such as a simultaneous phase transition in many tasks\ncoinciding with the learning rate warm-up, and evidence that many context\nneurons form simultaneously early in training but are later unlearned.", "published": "2023-11-01 21:32:51", "link": "http://arxiv.org/abs/2311.00863v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Pretraining Data Mixtures Enable Narrow Model Selection Capabilities in\n  Transformer Models", "abstract": "Transformer models, notably large language models (LLMs), have the remarkable\nability to perform in-context learning (ICL) -- to perform new tasks when\nprompted with unseen input-output examples without any explicit model training.\nIn this work, we study how effectively transformers can bridge between their\npretraining data mixture, comprised of multiple distinct task families, to\nidentify and learn new tasks in-context which are both inside and outside the\npretraining distribution. Building on previous work, we investigate this\nquestion in a controlled setting, where we study transformer models trained on\nsequences of $(x, f(x))$ pairs rather than natural language. Our empirical\nresults show transformers demonstrate near-optimal unsupervised model selection\ncapabilities, in their ability to first in-context identify different task\nfamilies and in-context learn within them when the task families are\nwell-represented in their pretraining data. However when presented with tasks\nor functions which are out-of-domain of their pretraining data, we demonstrate\nvarious failure modes of transformers and degradation of their generalization\nfor even simple extrapolation tasks. Together our results highlight that the\nimpressive ICL abilities of high-capacity sequence models may be more closely\ntied to the coverage of their pretraining data mixtures than inductive biases\nthat create fundamental generalization capabilities.", "published": "2023-11-01 21:41:08", "link": "http://arxiv.org/abs/2311.00871v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "In-Context Prompt Editing For Conditional Audio Generation", "abstract": "Distributional shift is a central challenge in the deployment of machine\nlearning models as they can be ill-equipped for real-world data. This is\nparticularly evident in text-to-audio generation where the encoded\nrepresentations are easily undermined by unseen prompts, which leads to the\ndegradation of generated audio -- the limited set of the text-audio pairs\nremains inadequate for conditional audio generation in the wild as user prompts\nare under-specified. In particular, we observe a consistent audio quality\ndegradation in generated audio samples with user prompts, as opposed to\ntraining set prompts. To this end, we present a retrieval-based in-context\nprompt editing framework that leverages the training captions as demonstrative\nexemplars to revisit the user prompts. We show that the framework enhanced the\naudio quality across the set of collected user prompts, which were edited with\nreference to the training captions as exemplars.", "published": "2023-11-01 23:31:51", "link": "http://arxiv.org/abs/2311.00895v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "On The Open Prompt Challenge In Conditional Audio Generation", "abstract": "Text-to-audio generation (TTA) produces audio from a text description,\nlearning from pairs of audio samples and hand-annotated text. However,\ncommercializing audio generation is challenging as user-input prompts are often\nunder-specified when compared to text descriptions used to train TTA models. In\nthis work, we treat TTA models as a ``blackbox'' and address the user prompt\nchallenge with two key insights: (1) User prompts are generally\nunder-specified, leading to a large alignment gap between user prompts and\ntraining prompts. (2) There is a distribution of audio descriptions for which\nTTA models are better at generating higher quality audio, which we refer to as\n``audionese''. To this end, we rewrite prompts with instruction-tuned models\nand propose utilizing text-audio alignment as feedback signals via margin\nranking learning for audio improvements. On both objective and subjective human\nevaluations, we observed marked improvements in both text-audio alignment and\nmusic audio quality.", "published": "2023-11-01 23:33:25", "link": "http://arxiv.org/abs/2311.00897v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Ontology-Driven Processing of Transdisciplinary Domain Knowledge", "abstract": "The monograph discusses certain aspects of modern real-world problems facing\nhumanity, which are much more challenging than scientific ones. Modern science\nis unable to solve them in a fundamental way. Vernadsky's noosphere thesis, in\nfact, appeals to the scientific worldview that needs to be built in a way that\novercomes the interdisciplinary barriers and increases the effectiveness of\ninterdisciplinary interaction and modern science overall. We are talking about\nthe general transdisciplinary knowledge. In world practice, there is still no\nsystematic methodology and a specific form of generally accepted valid\nscientific theory that would provide transdisciplinary knowledge. Non-linear\ninterdisciplinary interaction is the standard of evolution of modern science.\nAt the same time, a new transdisciplinary theory (domain of scientific\nresearch) is being de facto created and the process is repeated many times:\nfrom an individual or group of disciplines, through interdisciplinary\ninteraction, in a direction that brings us closer to creating a holistic\ngeneral scientific worldview.", "published": "2023-11-01 07:42:34", "link": "http://arxiv.org/abs/2311.04910v1", "categories": ["cs.DL", "cs.AI", "cs.CL"], "primary_category": "cs.DL"}
{"title": "From Text to Structure: Using Large Language Models to Support the\n  Development of Legal Expert Systems", "abstract": "Encoding legislative text in a formal representation is an important\nprerequisite to different tasks in the field of AI & Law. For example,\nrule-based expert systems focused on legislation can support laypeople in\nunderstanding how legislation applies to them and provide them with helpful\ncontext and information. However, the process of analyzing legislation and\nother sources to encode it in the desired formal representation can be\ntime-consuming and represents a bottleneck in the development of such systems.\nHere, we investigate to what degree large language models (LLMs), such as\nGPT-4, are able to automatically extract structured representations from\nlegislation. We use LLMs to create pathways from legislation, according to the\nJusticeBot methodology for legal decision support systems, evaluate the\npathways and compare them to manually created pathways. The results are\npromising, with 60% of generated pathways being rated as equivalent or better\nthan manually created ones in a blind comparison. The approach suggests a\npromising path to leverage the capabilities of LLMs to ease the costly\ndevelopment of systems based on symbolic approaches that are transparent and\nexplainable.", "published": "2023-11-01 18:31:02", "link": "http://arxiv.org/abs/2311.04911v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "LLaVA-Interactive: An All-in-One Demo for Image Chat, Segmentation,\n  Generation and Editing", "abstract": "LLaVA-Interactive is a research prototype for multimodal human-AI\ninteraction. The system can have multi-turn dialogues with human users by\ntaking multimodal user inputs and generating multimodal responses. Importantly,\nLLaVA-Interactive goes beyond language prompt, where visual prompt is enabled\nto align human intents in the interaction. The development of LLaVA-Interactive\nis extremely cost-efficient as the system combines three multimodal skills of\npre-built AI models without additional model training: visual chat of LLaVA,\nimage segmentation from SEEM, as well as image generation and editing from\nGLIGEN. A diverse set of application scenarios is presented to demonstrate the\npromises of LLaVA-Interactive and to inspire future research in multimodal\ninteractive systems.", "published": "2023-11-01 15:13:43", "link": "http://arxiv.org/abs/2311.00571v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.HC", "cs.MM"], "primary_category": "cs.CV"}
{"title": "An analysis of large speech models-based representations for speech\n  emotion recognition", "abstract": "Large speech models-derived features have recently shown increased\nperformance over signal-based features across multiple downstream tasks, even\nwhen the networks are not finetuned towards the target task. In this paper we\nshow the results of an analysis of several signal- and neural models-derived\nfeatures for speech emotion recognition. We use pretrained models and explore\ntheir inherent potential abstractions of emotions. Simple classification\nmethods are used so as to not interfere or add knowledge to the task. We show\nthat, even without finetuning, some of these large neural speech models'\nrepresentations can enclose information that enables performances close to, and\neven beyond state-of-the-art results across six standard speech emotion\nrecognition datasets.", "published": "2023-11-01 09:40:40", "link": "http://arxiv.org/abs/2311.00394v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Reverberant sound field equalisation for an enhanced stereo playback\n  experience", "abstract": "The topic of room equalisation has been at the forefront of research and\nproduct development for many years, with the aim of increasing the playback\nquality of loudspeakers in reverberant rooms. Traditional room equalisation\nsystems comprise of a number of filters that when applied to the primary\nloudspeakers, additional room colouration is compensated for. This publication\nintroduces a novel equalisation technique where gammatone filter band energy is\nadded to the reverberant sound field via two surround loudspeakers, leaving the\ndirect sound from the primary loudspeakers unaltered, but the sum of direct and\nreverberant energy is equalised at the listening position. Unlike traditional\nsystems, this method allows the target function of the direct sound to differ\nfrom the reverberant sound field. The proposed method is motivated by the\ndifferent roles direct and reverberant sound components play in humans\nperception of sound. Along with introducing the proposed method, results from a\nsubjective listening test are presented, demonstrating the preference towards\nthe proposed technique when compared to a traditional room equalisation\ntechnique and stereo playback.", "published": "2023-11-01 16:22:22", "link": "http://arxiv.org/abs/2311.00624v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Investigating Self-Supervised Deep Representations for EEG-based\n  Auditory Attention Decoding", "abstract": "Auditory Attention Decoding (AAD) algorithms play a crucial role in isolating\ndesired sound sources within challenging acoustic environments directly from\nbrain activity. Although recent research has shown promise in AAD using shallow\nrepresentations such as auditory envelope and spectrogram, there has been\nlimited exploration of deep Self-Supervised (SS) representations on a larger\nscale. In this study, we undertake a comprehensive investigation into the\nperformance of linear decoders across 12 deep and 2 shallow representations,\napplied to EEG data from multiple studies spanning 57 subjects and multiple\nlanguages. Our experimental results consistently reveal the superiority of deep\nfeatures for AAD at decoding background speakers, regardless of the datasets\nand analysis windows. This result indicates possible nonlinear encoding of\nunattended signals in the brain that are revealed using deep nonlinear\nfeatures. Additionally, we analyze the impact of different layers of SS\nrepresentations and window sizes on AAD performance. These findings underscore\nthe potential for enhancing EEG-based AAD systems through the integration of\ndeep feature representations.", "published": "2023-11-01 19:55:39", "link": "http://arxiv.org/abs/2311.00814v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Semantic Hearing: Programming Acoustic Scenes with Binaural Hearables", "abstract": "Imagine being able to listen to the birds chirping in a park without hearing\nthe chatter from other hikers, or being able to block out traffic noise on a\nbusy street while still being able to hear emergency sirens and car honks. We\nintroduce semantic hearing, a novel capability for hearable devices that\nenables them to, in real-time, focus on, or ignore, specific sounds from\nreal-world environments, while also preserving the spatial cues. To achieve\nthis, we make two technical contributions: 1) we present the first neural\nnetwork that can achieve binaural target sound extraction in the presence of\ninterfering sounds and background noise, and 2) we design a training\nmethodology that allows our system to generalize to real-world use. Results\nshow that our system can operate with 20 sound classes and that our\ntransformer-based network has a runtime of 6.56 ms on a connected smartphone.\nIn-the-wild evaluation with participants in previously unseen indoor and\noutdoor scenarios shows that our proof-of-concept system can extract the target\nsounds and generalize to preserve the spatial cues in its binaural output.\nProject page with code: https://semantichearing.cs.washington.edu", "published": "2023-11-01 06:07:28", "link": "http://arxiv.org/abs/2311.00320v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "C2C: Cough to COVID-19 Detection in BHI 2023 Data Challenge", "abstract": "This report describes our submission to BHI 2023 Data Competition: Sensor\nchallenge. Our Audio Alchemists team designed an acoustic-based COVID-19\ndiagnosis system, Cough to COVID-19 (C2C), and won the 1st place in the\nchallenge. C2C involves three key contributions: pre-processing of input\nsignals, cough-related representation extraction leveraging Wav2vec2.0, and\ndata augmentation. Through experimental findings, we demonstrate C2C's\npromising potential to enhance the diagnostic accuracy of COVID-19 via cough\nsignals. Our proposed model achieves a ROC-AUC value of 0.7810 in the context\nof COVID-19 diagnosis. The implementation details and the python code can be\nfound in the following link:\nhttps://github.com/Woo-jin-Chung/BHI_2023_challenge_Audio_Alchemists", "published": "2023-11-01 08:28:40", "link": "http://arxiv.org/abs/2311.00364v1", "categories": ["eess.AS", "cs.SD", "physics.bio-ph"], "primary_category": "eess.AS"}
{"title": "Deep Neural Networks for Automatic Speaker Recognition Do Not Learn\n  Supra-Segmental Temporal Features", "abstract": "While deep neural networks have shown impressive results in automatic speaker\nrecognition and related tasks, it is dissatisfactory how little is understood\nabout what exactly is responsible for these results. Part of the success has\nbeen attributed in prior work to their capability to model supra-segmental\ntemporal information (SST), i.e., learn rhythmic-prosodic characteristics of\nspeech in addition to spectral features. In this paper, we (i) present and\napply a novel test to quantify to what extent the performance of\nstate-of-the-art neural networks for speaker recognition can be explained by\nmodeling SST; and (ii) present several means to force respective nets to focus\nmore on SST and evaluate their merits. We find that a variety of CNN- and\nRNN-based neural network architectures for speaker recognition do not model SST\nto any sufficient degree, even when forced. The results provide a highly\nrelevant basis for impactful future research into better exploitation of the\nfull speech signal and give insights into the inner workings of such networks,\nenhancing explainability of deep learning for speech technologies.", "published": "2023-11-01 12:45:31", "link": "http://arxiv.org/abs/2311.00489v2", "categories": ["cs.SD", "cs.CV", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Active Noise Control Portable Device Design", "abstract": "While our world is filled with its own natural sounds that we can't resist\nenjoying, it is also chock-full of other sounds that can be irritating, this is\nnoise. Noise not only influences the working efficiency but also the human's\nhealth. The problem of reducing noise is one of great importance and great\ndifficulty. The problem has been addressed in many ways over the years. The\ncurrent methods for noise reducing mostly rely on the materials and\ntransmission medium, which are only effective to some extent for the high\nfrequency noise. However, the effective reduction noise method especially for\nlow frequency noise is very limited.\n  Here we come up with a noise reduction system consist of a sensor to detect\nthe noise in the environment. Then the noise will be sent to an electronic\ncontrol system to process the noise, which will generate a reverse phase\nfrequency signal to counteract the disturbance. Finally, the processed smaller\nnoise will be broadcasted by the speaker. Through this smart noise reduction\nsystem, even the noise with low-frequency can be eliminated.\n  The system is also integrated with sleep tracking and music player\napplications. It can also remember and store settings for the same environment,\nsense temperature, and smart control of home furniture, fire alarm, etc. This\nsmart system can transfer data easily by Wi-Fi or Bluetooth and controlled by\nits APP.\n  In this project, we will present a model of the above technology which can be\nused in various environments to prevent noise pollution and provide a solution\nto the people who have difficulties finding a peaceful and quiet environment\nfor sleep, work or study.", "published": "2023-11-01 14:13:04", "link": "http://arxiv.org/abs/2311.00535v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Controllable Music Production with Diffusion Models and Guidance\n  Gradients", "abstract": "We demonstrate how conditional generation from diffusion models can be used\nto tackle a variety of realistic tasks in the production of music in 44.1kHz\nstereo audio with sampling-time guidance. The scenarios we consider include\ncontinuation, inpainting and regeneration of musical audio, the creation of\nsmooth transitions between two different music tracks, and the transfer of\ndesired stylistic characteristics to existing audio clips. We achieve this by\napplying guidance at sampling time in a simple framework that supports both\nreconstruction and classification losses, or any combination of the two. This\napproach ensures that generated audio can match its surrounding context, or\nconform to a class distribution or latent representation specified relative to\nany suitable pre-trained classifier or embedding model. Audio samples are\navailable at https://machinelearning.apple.com/research/controllable-music", "published": "2023-11-01 16:01:01", "link": "http://arxiv.org/abs/2311.00613v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Low-latency Real-time Voice Conversion on CPU", "abstract": "We adapt the architectures of previous audio manipulation and generation\nneural networks to the task of real-time any-to-one voice conversion. Our\nresulting model, LLVC ($\\textbf{L}$ow-latency $\\textbf{L}$ow-resource\n$\\textbf{V}$oice $\\textbf{C}$onversion), has a latency of under 20ms at a\nbitrate of 16kHz and runs nearly 2.8x faster than real-time on a consumer CPU.\nLLVC uses both a generative adversarial architecture as well as knowledge\ndistillation in order to attain this performance. To our knowledge LLVC\nachieves both the lowest resource usage as well as the lowest latency of any\nopen-source voice conversion model. We provide open-source samples, code, and\npretrained model weights at https://github.com/KoeAI/LLVC.", "published": "2023-11-01 21:57:52", "link": "http://arxiv.org/abs/2311.00873v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Sounding Bodies: Modeling 3D Spatial Sound of Humans Using Body Pose and\n  Audio", "abstract": "While 3D human body modeling has received much attention in computer vision,\nmodeling the acoustic equivalent, i.e. modeling 3D spatial audio produced by\nbody motion and speech, has fallen short in the community. To close this gap,\nwe present a model that can generate accurate 3D spatial audio for full human\nbodies. The system consumes, as input, audio signals from headset microphones\nand body pose, and produces, as output, a 3D sound field surrounding the\ntransmitter's body, from which spatial audio can be rendered at any arbitrary\nposition in the 3D space. We collect a first-of-its-kind multimodal dataset of\nhuman bodies, recorded with multiple cameras and a spherical array of 345\nmicrophones. In an empirical evaluation, we demonstrate that our model can\nproduce accurate body-induced sound fields when trained with a suitable loss.\nDataset and code are available online.", "published": "2023-11-01 16:40:35", "link": "http://arxiv.org/abs/2311.06285v1", "categories": ["cs.CV", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
