{"title": "Neural Sentence Ordering Based on Constraint Graphs", "abstract": "Sentence ordering aims at arranging a list of sentences in the correct order.\nBased on the observation that sentence order at different distances may rely on\ndifferent types of information, we devise a new approach based on\nmulti-granular orders between sentences. These orders form multiple constraint\ngraphs, which are then encoded by Graph Isomorphism Networks and fused into\nsentence representations. Finally, sentence order is determined using the\norder-enhanced sentence representations. Our experiments on five benchmark\ndatasets show that our method outperforms all the existing baselines\nsignificantly, achieving a new state-of-the-art performance. The results\ndemonstrate the advantage of considering multiple types of order information\nand using graph neural networks to integrate sentence content and order\ninformation for the task. Our code is available at\nhttps://github.com/DaoD/ConstraintGraph4NSO.", "published": "2021-01-27 02:53:10", "link": "http://arxiv.org/abs/2101.11178v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FGNET-RH: Fine-Grained Named Entity Typing via Refinement in Hyperbolic\n  Space", "abstract": "Fine-Grained Named Entity Typing (FG-NET) aims at classifying the entity\nmentions into a wide range of entity types (usually hundreds) depending upon\nthe context. While distant supervision is the most common way to acquire\nsupervised training data, it brings in label noise, as it assigns type labels\nto the entity mentions irrespective of mentions context. In attempts to deal\nwith the label noise, leading research on the FG-NET assumes that the\nfine-grained entity typing data possesses a euclidean nature, which restraints\nthe ability of the existing models in combating the label noise. Given the fact\nthat the fine-grained type hierarchy exhibits a hierarchical structure, it\nmakes hyperbolic space a natural choice to model the FG-NET data. In this\nresearch, we propose FGNET-RH, a novel framework that benefits from the\nhyperbolic geometry in combination with the graph structures to perform entity\ntyping in a performance-enhanced fashion. FGNET-RH initially uses LSTM networks\nto encode the mention in relation with its context, later it forms a graph to\ndistill/refine the mention encodings in the hyperbolic space. Finally, the\nrefined mention encoding is used for entity typing. Experimentation using\ndifferent benchmark datasets shows that FGNET-RH improves the performance on\nFG-NET by up to 3.5-% in terms of strict accuracy.", "published": "2021-01-27 05:39:05", "link": "http://arxiv.org/abs/2101.11212v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PPT: Parsimonious Parser Transfer for Unsupervised Cross-Lingual\n  Adaptation", "abstract": "Cross-lingual transfer is a leading technique for parsing low-resource\nlanguages in the absence of explicit supervision. Simple `direct transfer' of a\nlearned model based on a multilingual input encoding has provided a strong\nbenchmark. This paper presents a method for unsupervised cross-lingual transfer\nthat improves over direct transfer systems by using their output as implicit\nsupervision as part of self-training on unlabelled text in the target language.\nThe method assumes minimal resources and provides maximal flexibility by (a)\naccepting any pre-trained arc-factored dependency parser; (b) assuming no\naccess to source language data; (c) supporting both projective and\nnon-projective parsing; and (d) supporting multi-source transfer. With English\nas the source language, we show significant improvements over state-of-the-art\ntransfer models on both distant and nearby languages, despite our conceptually\nsimpler approach. We provide analyses of the choice of source languages for\nmulti-source transfer, and the advantage of non-projective parsing. Our code is\navailable online.", "published": "2021-01-27 05:52:26", "link": "http://arxiv.org/abs/2101.11216v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How to Evaluate a Summarizer: Study Design and Statistical Analysis for\n  Manual Linguistic Quality Evaluation", "abstract": "Manual evaluation is essential to judge progress on automatic text\nsummarization. However, we conduct a survey on recent summarization system\npapers that reveals little agreement on how to perform such evaluation studies.\nWe conduct two evaluation experiments on two aspects of summaries' linguistic\nquality (coherence and repetitiveness) to compare Likert-type and ranking\nannotations and show that best choice of evaluation method can vary from one\naspect to another. In our survey, we also find that study parameters such as\nthe overall number of annotators and distribution of annotators to annotation\nitems are often not fully reported and that subsequent statistical analysis\nignores grouping factors arising from one annotator judging multiple summaries.\nUsing our evaluation experiments, we show that the total number of annotators\ncan have a strong impact on study power and that current statistical analysis\nmethods can inflate type I error rates up to eight-fold. In addition, we\nhighlight that for the purpose of system comparison the current practice of\neliciting multiple judgements per summary leads to less powerful and reliable\nannotations given a fixed study budget.", "published": "2021-01-27 10:14:15", "link": "http://arxiv.org/abs/2101.11298v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual and cross-lingual document classification: A meta-learning\n  approach", "abstract": "The great majority of languages in the world are considered under-resourced\nfor the successful application of deep learning methods. In this work, we\npropose a meta-learning approach to document classification in limited-resource\nsetting and demonstrate its effectiveness in two different settings: few-shot,\ncross-lingual adaptation to previously unseen languages; and multilingual joint\ntraining when limited target-language data is available during training. We\nconduct a systematic comparison of several meta-learning methods, investigate\nmultiple settings in terms of data availability and show that meta-learning\nthrives in settings with a heterogeneous task distribution. We propose a\nsimple, yet effective adjustment to existing meta-learning methods which allows\nfor better and more stable learning, and set a new state of the art on several\nlanguages while performing on-par on others, using only a small amount of\nlabeled data.", "published": "2021-01-27 10:22:56", "link": "http://arxiv.org/abs/2101.11302v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A phonetic model of non-native spoken word processing", "abstract": "Non-native speakers show difficulties with spoken word processing. Many\nstudies attribute these difficulties to imprecise phonological encoding of\nwords in the lexical memory. We test an alternative hypothesis: that some of\nthese difficulties can arise from the non-native speakers' phonetic perception.\nWe train a computational model of phonetic learning, which has no access to\nphonology, on either one or two languages. We first show that the model\nexhibits predictable behaviors on phone-level and word-level discrimination\ntasks. We then test the model on a spoken word processing task, showing that\nphonology may not be necessary to explain some of the word processing effects\nobserved in non-native speakers. We run an additional analysis of the model's\nlexical representation space, showing that the two training languages are not\nfully separated in that space, similarly to the languages of a bilingual human\nspeaker.", "published": "2021-01-27 11:46:21", "link": "http://arxiv.org/abs/2101.11332v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Empirical Study of Cross-Lingual Transferability in Generative\n  Dialogue State Tracker", "abstract": "There has been a rapid development in data-driven task-oriented dialogue\nsystems with the benefit of large-scale datasets. However, the progress of\ndialogue systems in low-resource languages lags far behind due to the lack of\nhigh-quality data. To advance the cross-lingual technology in building dialog\nsystems, DSTC9 introduces the task of cross-lingual dialog state tracking,\nwhere we test the DST module in a low-resource language given the rich-resource\ntraining dataset.\n  This paper studies the transferability of a cross-lingual generative dialogue\nstate tracking system using a multilingual pre-trained seq2seq model. We\nexperiment under different settings, including joint-training or pre-training\non cross-lingual and cross-ontology datasets. We also find out the low\ncross-lingual transferability of our approaches and provides investigation and\ndiscussion.", "published": "2021-01-27 12:45:55", "link": "http://arxiv.org/abs/2101.11360v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Evolution of Syntactic Information Encoded by BERT's\n  Contextualized Representations", "abstract": "The adaptation of pretrained language models to solve supervised tasks has\nbecome a baseline in NLP, and many recent works have focused on studying how\nlinguistic information is encoded in the pretrained sentence representations.\nAmong other information, it has been shown that entire syntax trees are\nimplicitly embedded in the geometry of such models. As these models are often\nfine-tuned, it becomes increasingly important to understand how the encoded\nknowledge evolves along the fine-tuning. In this paper, we analyze the\nevolution of the embedded syntax trees along the fine-tuning process of BERT\nfor six different tasks, covering all levels of the linguistic structure.\nExperimental results show that the encoded syntactic information is forgotten\n(PoS tagging), reinforced (dependency and constituency parsing) or preserved\n(semantics-related tasks) in different ways along the fine-tuning process\ndepending on the task.", "published": "2021-01-27 15:41:09", "link": "http://arxiv.org/abs/2101.11492v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mining Large-Scale Low-Resource Pronunciation Data From Wikipedia", "abstract": "Pronunciation modeling is a key task for building speech technology in new\nlanguages, and while solid grapheme-to-phoneme (G2P) mapping systems exist,\nlanguage coverage can stand to be improved. The information needed to build G2P\nmodels for many more languages can easily be found on Wikipedia, but\nunfortunately, it is stored in disparate formats. We report on a system we\nbuilt to mine a pronunciation data set in 819 languages from loosely structured\ntables within Wikipedia. The data includes phoneme inventories, and for 63\nlow-resource languages, also includes the grapheme-to-phoneme (G2P) mapping. 54\nof these languages do not have easily findable G2P mappings online otherwise.\nWe turned the information from Wikipedia into a structured, machine-readable\nTSV format, and make the resulting data set publicly available so it can be\nimproved further and used in a variety of applications involving low-resource\nlanguages.", "published": "2021-01-27 18:04:54", "link": "http://arxiv.org/abs/2101.11575v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transformer Based Deliberation for Two-Pass Speech Recognition", "abstract": "Interactive speech recognition systems must generate words quickly while also\nproducing accurate results. Two-pass models excel at these requirements by\nemploying a first-pass decoder that quickly emits words, and a second-pass\ndecoder that requires more context but is more accurate. Previous work has\nestablished that a deliberation network can be an effective second-pass model.\nThe model attends to two kinds of inputs at once: encoded audio frames and the\nhypothesis text from the first-pass model. In this work, we explore using\ntransformer layers instead of long-short term memory (LSTM) layers for\ndeliberation rescoring. In transformer layers, we generalize the\n\"encoder-decoder\" attention to attend to both encoded audio and first-pass text\nhypotheses. The output context vectors are then combined by a merger layer.\nCompared to LSTM-based deliberation, our best transformer deliberation achieves\n7% relative word error rate improvements along with a 38% reduction in\ncomputation. We also compare against non-deliberation transformer rescoring,\nand find a 9% relative improvement.", "published": "2021-01-27 18:05:22", "link": "http://arxiv.org/abs/2101.11577v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Compositionality Through Language Transmission, using Artificial Neural\n  Networks", "abstract": "We propose an architecture and process for using the Iterated Learning Model\n(\"ILM\") for artificial neural networks. We show that ILM does not lead to the\nsame clear compositionality as observed using DCGs, but does lead to a modest\nimprovement in compositionality, as measured by holdout accuracy and topologic\nsimilarity. We show that ILM can lead to an anti-correlation between holdout\naccuracy and topologic rho. We demonstrate that ILM can increase\ncompositionality when using non-symbolic high-dimensional images as input.", "published": "2021-01-27 23:08:16", "link": "http://arxiv.org/abs/2101.11739v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LSOIE: A Large-Scale Dataset for Supervised Open Information Extraction", "abstract": "Open Information Extraction (OIE) systems seek to compress the factual\npropositions of a sentence into a series of n-ary tuples. These tuples are\nuseful for downstream tasks in natural language processing like knowledge base\ncreation, textual entailment, and natural language understanding. However,\ncurrent OIE datasets are limited in both size and diversity. We introduce a new\ndataset by converting the QA-SRL 2.0 dataset to a large-scale OIE dataset\n(LSOIE). Our LSOIE dataset is 20 times larger than the next largest\nhuman-annotated OIE dataset. We construct and evaluate several benchmark OIE\nmodels on LSOIE, providing baselines for future improvements on the task. Our\nLSOIE data, models, and code are made publicly available", "published": "2021-01-27 02:49:26", "link": "http://arxiv.org/abs/2101.11177v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Joint Coreference Resolution and Character Linking for Multiparty\n  Conversation", "abstract": "Character linking, the task of linking mentioned people in conversations to\nthe real world, is crucial for understanding the conversations. For the\nefficiency of communication, humans often choose to use pronouns (e.g., \"she\")\nor normal phrases (e.g., \"that girl\") rather than named entities (e.g.,\n\"Rachel\") in the spoken language, which makes linking those mentions to real\npeople a much more challenging than a regular entity linking task. To address\nthis challenge, we propose to incorporate the richer context from the\ncoreference relations among different mentions to help the linking. On the\nother hand, considering that finding coreference clusters itself is not a\ntrivial task and could benefit from the global character information, we\npropose to jointly solve these two tasks. Specifically, we propose C$^2$, the\njoint learning model of Coreference resolution and Character linking. The\nexperimental results demonstrate that C$^2$ can significantly outperform\nprevious works on both tasks. Further analyses are conducted to analyze the\ncontribution of all modules in the proposed model and the effect of all\nhyper-parameters.", "published": "2021-01-27 04:47:04", "link": "http://arxiv.org/abs/2101.11204v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Robustness to Label Noise in Text Classification via Noise\n  Modeling", "abstract": "Large datasets in NLP suffer from noisy labels, due to erroneous automatic\nand human annotation procedures. We study the problem of text classification\nwith label noise, and aim to capture this noise through an auxiliary noise\nmodel over the classifier. We first assign a probability score to each training\nsample of having a noisy label, through a beta mixture model fitted on the\nlosses at an early epoch of training. Then, we use this score to selectively\nguide the learning of the noise model and classifier. Our empirical evaluation\non two text classification tasks shows that our approach can improve over the\nbaseline accuracy, and prevent over-fitting to the noise.", "published": "2021-01-27 05:41:57", "link": "http://arxiv.org/abs/2101.11214v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "VisualMRC: Machine Reading Comprehension on Document Images", "abstract": "Recent studies on machine reading comprehension have focused on text-level\nunderstanding but have not yet reached the level of human understanding of the\nvisual layout and content of real-world documents. In this study, we introduce\na new visual machine reading comprehension dataset, named VisualMRC, wherein\ngiven a question and a document image, a machine reads and comprehends texts in\nthe image to answer the question in natural language. Compared with existing\nvisual question answering (VQA) datasets that contain texts in images,\nVisualMRC focuses more on developing natural language understanding and\ngeneration abilities. It contains 30,000+ pairs of a question and an\nabstractive answer for 10,000+ document images sourced from multiple domains of\nwebpages. We also introduce a new model that extends existing\nsequence-to-sequence models, pre-trained with large-scale text corpora, to take\ninto account the visual layout and content of documents. Experiments with\nVisualMRC show that this model outperformed the base sequence-to-sequence\nmodels and a state-of-the-art VQA model. However, its performance is still\nbelow that of humans on most automatic evaluation metrics. The dataset will\nfacilitate research aimed at connecting vision and language understanding.", "published": "2021-01-27 09:03:06", "link": "http://arxiv.org/abs/2101.11272v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Language Modelling as a Multi-Task Problem", "abstract": "In this paper, we propose to study language modelling as a multi-task\nproblem, bringing together three strands of research: multi-task learning,\nlinguistics, and interpretability. Based on hypotheses derived from linguistic\ntheory, we investigate whether language models adhere to learning principles of\nmulti-task learning during training. To showcase the idea, we analyse the\ngeneralisation behaviour of language models as they learn the linguistic\nconcept of Negative Polarity Items (NPIs). Our experiments demonstrate that a\nmulti-task setting naturally emerges within the objective of the more general\ntask of language modelling.We argue that this insight is valuable for\nmulti-task learning, linguistics and interpretability research and can lead to\nexciting new findings in all three domains.", "published": "2021-01-27 09:47:42", "link": "http://arxiv.org/abs/2101.11287v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Adversarial Stylometry in the Wild: Transferable Lexical Substitution\n  Attacks on Author Profiling", "abstract": "Written language contains stylistic cues that can be exploited to\nautomatically infer a variety of potentially sensitive author information.\nAdversarial stylometry intends to attack such models by rewriting an author's\ntext. Our research proposes several components to facilitate deployment of\nthese adversarial attacks in the wild, where neither data nor target models are\naccessible. We introduce a transformer-based extension of a lexical replacement\nattack, and show it achieves high transferability when trained on a weakly\nlabeled corpus -- decreasing target model performance below chance. While not\ncompletely inconspicuous, our more successful attacks also prove notably less\ndetectable by humans. Our framework therefore provides a promising direction\nfor future privacy-preserving adversarial attacks.", "published": "2021-01-27 10:42:44", "link": "http://arxiv.org/abs/2101.11310v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Triangular Bidword Generation for Sponsored Search Auction", "abstract": "Sponsored search auction is a crucial component of modern search engines. It\nrequires a set of candidate bidwords that advertisers can place bids on.\nExisting methods generate bidwords from search queries or advertisement\ncontent. However, they suffer from the data noise in <query, bidword> and\n<advertisement, bidword> pairs. In this paper, we propose a triangular bidword\ngeneration model (TRIDENT), which takes the high-quality data of paired <query,\nadvertisement> as a supervision signal to indirectly guide the bidword\ngeneration process. Our proposed model is simple yet effective: by using\nbidword as the bridge between search query and advertisement, the generation of\nsearch query, advertisement and bidword can be jointly learned in the\ntriangular training framework. This alleviates the problem that the training\ndata of bidword may be noisy. Experimental results, including automatic and\nhuman evaluations, show that our proposed TRIDENT can generate relevant and\ndiverse bidwords for both search queries and advertisements. Our evaluation on\nonline real data validates the effectiveness of the TRIDENT's generated\nbidwords for product search.", "published": "2021-01-27 12:25:22", "link": "http://arxiv.org/abs/2101.11349v1", "categories": ["cs.CL", "cs.SI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "KoreALBERT: Pretraining a Lite BERT Model for Korean Language\n  Understanding", "abstract": "A Lite BERT (ALBERT) has been introduced to scale up deep bidirectional\nrepresentation learning for natural languages. Due to the lack of pretrained\nALBERT models for Korean language, the best available practice is the\nmultilingual model or resorting back to the any other BERT-based model. In this\npaper, we develop and pretrain KoreALBERT, a monolingual ALBERT model\nspecifically for Korean language understanding. We introduce a new training\nobjective, namely Word Order Prediction (WOP), and use alongside the existing\nMLM and SOP criteria to the same architecture and model parameters. Despite\nhaving significantly fewer model parameters (thus, quicker to train), our\npretrained KoreALBERT outperforms its BERT counterpart on 6 different NLU\ntasks. Consistent with the empirical results in English by Lan et al.,\nKoreALBERT seems to improve downstream task performance involving\nmulti-sentence encoding for Korean language. The pretrained KoreALBERT is\npublicly available to encourage research and application development for Korean\nNLP.", "published": "2021-01-27 12:48:53", "link": "http://arxiv.org/abs/2101.11363v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Inheritance-guided Hierarchical Assignment for Clinical Automatic\n  Diagnosis", "abstract": "Clinical diagnosis, which aims to assign diagnosis codes for a patient based\non the clinical note, plays an essential role in clinical decision-making.\nConsidering that manual diagnosis could be error-prone and time-consuming, many\nintelligent approaches based on clinical text mining have been proposed to\nperform automatic diagnosis. However, these methods may not achieve\nsatisfactory results due to the following challenges. First, most of the\ndiagnosis codes are rare, and the distribution is extremely unbalanced. Second,\nexisting methods are challenging to capture the correlation between diagnosis\ncodes. Third, the lengthy clinical note leads to the excessive dispersion of\nkey information related to codes. To tackle these challenges, we propose a\nnovel framework to combine the inheritance-guided hierarchical assignment and\nco-occurrence graph propagation for clinical automatic diagnosis. Specifically,\nwe propose a hierarchical joint prediction strategy to address the challenge of\nunbalanced codes distribution. Then, we utilize graph convolutional neural\nnetworks to obtain the correlation and semantic representations of medical\nontology. Furthermore, we introduce multi attention mechanisms to extract\ncrucial information. Finally, extensive experiments on MIMIC-III dataset\nclearly validate the effectiveness of our method.", "published": "2021-01-27 13:16:51", "link": "http://arxiv.org/abs/2101.11374v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Scheduled Sampling in Vision-Language Pretraining with Decoupled\n  Encoder-Decoder Network", "abstract": "Despite having impressive vision-language (VL) pretraining with BERT-based\nencoder for VL understanding, the pretraining of a universal encoder-decoder\nfor both VL understanding and generation remains challenging. The difficulty\noriginates from the inherently different peculiarities of the two disciplines,\ne.g., VL understanding tasks capitalize on the unrestricted message passing\nacross modalities, while generation tasks only employ visual-to-textual message\npassing. In this paper, we start with a two-stream decoupled design of\nencoder-decoder structure, in which two decoupled cross-modal encoder and\ndecoder are involved to separately perform each type of proxy tasks, for\nsimultaneous VL understanding and generation pretraining. Moreover, for VL\npretraining, the dominant way is to replace some input visual/word tokens with\nmask tokens and enforce the multi-modal encoder/decoder to reconstruct the\noriginal tokens, but no mask token is involved when fine-tuning on downstream\ntasks. As an alternative, we propose a primary scheduled sampling strategy that\nelegantly mitigates such discrepancy via pretraining encoder-decoder in a\ntwo-pass manner. Extensive experiments demonstrate the compelling\ngeneralizability of our pretrained encoder-decoder by fine-tuning on four VL\nunderstanding and generation downstream tasks. Source code is available at\n\\url{https://github.com/YehLi/TDEN}.", "published": "2021-01-27 17:36:57", "link": "http://arxiv.org/abs/2101.11562v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Exploring multi-task multi-lingual learning of transformer models for\n  hate speech and offensive speech identification in social media", "abstract": "Hate Speech has become a major content moderation issue for online social\nmedia platforms. Given the volume and velocity of online content production, it\nis impossible to manually moderate hate speech related content on any platform.\nIn this paper we utilize a multi-task and multi-lingual approach based on\nrecently proposed Transformer Neural Networks to solve three sub-tasks for hate\nspeech. These sub-tasks were part of the 2019 shared task on hate speech and\noffensive content (HASOC) identification in Indo-European languages. We expand\non our submission to that competition by utilizing multi-task models which are\ntrained using three approaches, a) multi-task learning with separate task\nheads, b) back-translation, and c) multi-lingual training. Finally, we\ninvestigate the performance of various models and identify instances where the\nTransformer based models perform differently and better. We show that it is\npossible to to utilize different combined approaches to obtain models that can\ngeneralize easily on different languages and tasks, while trading off slight\naccuracy (in some cases) for a much reduced inference time compute cost. We\nopen source an updated version of our HASOC 2019 code with the new improvements\nat https://github.com/socialmediaie/MTML_HateSpeech.", "published": "2021-01-27 01:25:22", "link": "http://arxiv.org/abs/2101.11155v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SI", "68T50 68T50 (Primary), 68T07 (Secondary)", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Enquire One's Parent and Child Before Decision: Fully Exploit\n  Hierarchical Structure for Self-Supervised Taxonomy Expansion", "abstract": "Taxonomy is a hierarchically structured knowledge graph that plays a crucial\nrole in machine intelligence. The taxonomy expansion task aims to find a\nposition for a new term in an existing taxonomy to capture the emerging\nknowledge in the world and keep the taxonomy dynamically updated. Previous\ntaxonomy expansion solutions neglect valuable information brought by the\nhierarchical structure and evaluate the correctness of merely an added edge,\nwhich downgrade the problem to node-pair scoring or mini-path classification.\nIn this paper, we propose the Hierarchy Expansion Framework (HEF), which fully\nexploits the hierarchical structure's properties to maximize the coherence of\nexpanded taxonomy. HEF makes use of taxonomy's hierarchical structure in\nmultiple aspects: i) HEF utilizes subtrees containing most relevant nodes as\nself-supervision data for a complete comparison of parental and sibling\nrelations; ii) HEF adopts a coherence modeling module to evaluate the coherence\nof a taxonomy's subtree by integrating hypernymy relation detection and several\ntree-exclusive features; iii) HEF introduces the Fitting Score for position\nselection, which explicitly evaluates both path and level selections and takes\nfull advantage of parental relations to interchange information for\ndisambiguation and self-correction. Extensive experiments show that by better\nexploiting the hierarchical structure and optimizing taxonomy's coherence, HEF\nvastly surpasses the prior state-of-the-art on three benchmark datasets by an\naverage improvement of 46.7% in accuracy and 32.3% in mean reciprocal rank.", "published": "2021-01-27 08:57:47", "link": "http://arxiv.org/abs/2101.11268v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Knowledge-driven Natural Language Understanding of English Text and its\n  Applications", "abstract": "Understanding the meaning of a text is a fundamental challenge of natural\nlanguage understanding (NLU) research. An ideal NLU system should process a\nlanguage in a way that is not exclusive to a single task or a dataset. Keeping\nthis in mind, we have introduced a novel knowledge driven semantic\nrepresentation approach for English text. By leveraging the VerbNet lexicon, we\nare able to map syntax tree of the text to its commonsense meaning represented\nusing basic knowledge primitives. The general purpose knowledge represented\nfrom our approach can be used to build any reasoning based NLU system that can\nalso provide justification. We applied this approach to construct two NLU\napplications that we present here: SQuARE (Semantic-based Question Answering\nand Reasoning Engine) and StaCACK (Stateful Conversational Agent using\nCommonsense Knowledge). Both these systems work by \"truly understanding\" the\nnatural language text they process and both provide natural language\nexplanations for their responses while maintaining high accuracy.", "published": "2021-01-27 22:02:50", "link": "http://arxiv.org/abs/2101.11707v1", "categories": ["cs.CL", "cs.AI", "cs.LO"], "primary_category": "cs.CL"}
{"title": "BOLD: Dataset and Metrics for Measuring Biases in Open-Ended Language\n  Generation", "abstract": "Recent advances in deep learning techniques have enabled machines to generate\ncohesive open-ended text when prompted with a sequence of words as context.\nWhile these models now empower many downstream applications from conversation\nbots to automatic storytelling, they have been shown to generate texts that\nexhibit social biases. To systematically study and benchmark social biases in\nopen-ended language generation, we introduce the Bias in Open-Ended Language\nGeneration Dataset (BOLD), a large-scale dataset that consists of 23,679\nEnglish text generation prompts for bias benchmarking across five domains:\nprofession, gender, race, religion, and political ideology. We also propose new\nautomated metrics for toxicity, psycholinguistic norms, and text gender\npolarity to measure social biases in open-ended text generation from multiple\nangles. An examination of text generated from three popular language models\nreveals that the majority of these models exhibit a larger social bias than\nhuman-written Wikipedia text across all domains. With these results we\nhighlight the need to benchmark biases in open-ended language generation and\ncaution users of language generation models on downstream tasks to be cognizant\nof these embedded prejudices.", "published": "2021-01-27 22:07:03", "link": "http://arxiv.org/abs/2101.11718v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Low-Power Audio Keyword Spotting using Tsetlin Machines", "abstract": "The emergence of Artificial Intelligence (AI) driven Keyword Spotting (KWS)\ntechnologies has revolutionized human to machine interaction. Yet, the\nchallenge of end-to-end energy efficiency, memory footprint and system\ncomplexity of current Neural Network (NN) powered AI-KWS pipelines has remained\never present. This paper evaluates KWS utilizing a learning automata powered\nmachine learning algorithm called the Tsetlin Machine (TM). Through significant\nreduction in parameter requirements and choosing logic over arithmetic based\nprocessing, the TM offers new opportunities for low-power KWS while maintaining\nhigh learning efficacy. In this paper we explore a TM based keyword spotting\n(KWS) pipeline to demonstrate low complexity with faster rate of convergence\ncompared to NNs. Further, we investigate the scalability with increasing\nkeywords and explore the potential for enabling low-power on-chip KWS.", "published": "2021-01-27 11:57:39", "link": "http://arxiv.org/abs/2101.11336v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
