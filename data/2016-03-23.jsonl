{"title": "Neural Summarization by Extracting Sentences and Words", "abstract": "Traditional approaches to extractive summarization rely heavily on\nhuman-engineered features. In this work we propose a data-driven approach based\non neural networks and continuous sentence features. We develop a general\nframework for single-document summarization composed of a hierarchical document\nencoder and an attention-based extractor. This architecture allows us to\ndevelop different classes of summarization models which can extract sentences\nor words. We train our models on large scale corpora containing hundreds of\nthousands of document-summary pairs. Experimental results on two summarization\ndatasets demonstrate that our models obtain results comparable to the state of\nthe art without any access to linguistic annotation.", "published": "2016-03-23 16:05:46", "link": "http://arxiv.org/abs/1603.07252v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating semantic models with word-sentence relatedness", "abstract": "Semantic textual similarity (STS) systems are designed to encode and evaluate\nthe semantic similarity between words, phrases, sentences, and documents. One\nmethod for assessing the quality or authenticity of semantic information\nencoded in these systems is by comparison with human judgments. A data set for\nevaluating semantic models was developed consisting of 775 English\nword-sentence pairs, each annotated for semantic relatedness by human raters\nengaged in a Maximum Difference Scaling (MDS) task, as well as a faster\nalternative task. As a sample application of this relatedness data,\nbehavior-based relatedness was compared to the relatedness computed via four\noff-the-shelf STS models: n-gram, Latent Semantic Analysis (LSA), Word2Vec, and\nUMBC Ebiquity. Some STS models captured much of the variance in the human\njudgments collected, but they were not sensitive to the implicatures and\nentailments that were processed and considered by the participants. All text\nstimuli and judgment data have been made freely available.", "published": "2016-03-23 16:12:34", "link": "http://arxiv.org/abs/1603.07253v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enabling Cognitive Intelligence Queries in Relational Databases using\n  Low-dimensional Word Embeddings", "abstract": "We apply distributed language embedding methods from Natural Language\nProcessing to assign a vector to each database entity associated token (for\nexample, a token may be a word occurring in a table row, or the name of a\ncolumn). These vectors, of typical dimension 200, capture the meaning of tokens\nbased on the contexts in which the tokens appear together. To form vectors, we\napply a learning method to a token sequence derived from the database. We\ndescribe various techniques for extracting token sequences from a database. The\ntechniques differ in complexity, in the token sequences they output and in the\ndatabase information used (e.g., foreign keys). The vectors can be used to\nalgebraically quantify semantic relationships between the tokens such as\nsimilarities and analogies. Vectors enable a dual view of the data: relational\nand (meaningful rather than purely syntactical) text. We introduce and explore\na new class of queries called cognitive intelligence (CI) queries that extract\ninformation from the database based, in part, on the relationships encoded by\nvectors. We have implemented a prototype system on top of Spark to exhibit the\npower of CI queries. Here, CI queries are realized via SQL UDFs. This power\ngoes far beyond text extensions to relational systems due to the information\nencoded in vectors. We also consider various extensions to the basic scheme,\nincluding using a collection of views derived from the database to focus on a\ndomain of interest, utilizing vectors and/or text from external sources,\nmaintaining vectors as the database evolves and exploring a database without\nutilizing its schema. For the latter, we consider minimal extensions to SQL to\nvastly improve query expressiveness.", "published": "2016-03-23 13:57:33", "link": "http://arxiv.org/abs/1603.07185v1", "categories": ["cs.CL", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Recurrent Neural Network Encoder with Attention for Community Question\n  Answering", "abstract": "We apply a general recurrent neural network (RNN) encoder framework to\ncommunity question answering (cQA) tasks. Our approach does not rely on any\nlinguistic processing, and can be applied to different languages or domains.\nFurther improvements are observed when we extend the RNN encoders with a neural\nattention mechanism that encourages reasoning over entire sequences. To deal\nwith practical issues such as data sparsity and imbalanced labels, we apply\nvarious techniques such as transfer learning and multitask learning. Our\nexperiments on the SemEval-2016 cQA task show 10% improvement on a MAP score\ncompared to an information retrieval-based approach, and achieve comparable\nperformance to a strong handcrafted feature-based method.", "published": "2016-03-23 01:52:54", "link": "http://arxiv.org/abs/1603.07044v1", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "The Anatomy of a Search and Mining System for Digital Archives", "abstract": "Samtla (Search And Mining Tools with Linguistic Analysis) is a digital\nhumanities system designed in collaboration with historians and linguists to\nassist them with their research work in quantifying the content of any textual\ncorpora through approximate phrase search and document comparison. The\nretrieval engine uses a character-based n-gram language model rather than the\nconventional word-based one so as to achieve great flexibility in language\nagnostic query processing.\n  The index is implemented as a space-optimised character-based suffix tree\nwith an accompanying database of document content and metadata. A number of\ntext mining tools are integrated into the system to allow researchers to\ndiscover textual patterns, perform comparative analysis, and find out what is\ncurrently popular in the research community.\n  Herein we describe the system architecture, user interface, models and\nalgorithms, and data storage of the Samtla system. We also present several case\nstudies of its usage in practice together with an evaluation of the systems'\nranking performance through crowdsourcing.", "published": "2016-03-23 12:02:12", "link": "http://arxiv.org/abs/1603.07150v1", "categories": ["cs.DL", "cs.CL", "cs.IR"], "primary_category": "cs.DL"}
{"title": "CONDITOR1: Topic Maps and DITA labelling tool for textual documents with\n  historical information", "abstract": "Conditor is a software tool which works with textual documents containing\nhistorical information. The purpose of this work two-fold: firstly to show the\nvalidity of the developed engine to correctly identify and label the entities\nof the universe of discourse with a labelled-combined XTM-DITA model. Secondly\nto explain the improvements achieved in the information retrieval process\nthanks to the use of a object-oriented database (JPOX) as well as its\nintegration into the Lucene-type database search process to not only accomplish\nmore accurate searches, but to also help the future development of a\nrecommender system. We finish with a brief demo in a 3D-graph of the results of\nthe aforementioned search.", "published": "2016-03-23 19:26:20", "link": "http://arxiv.org/abs/1603.07313v1", "categories": ["cs.DL", "cs.CL", "cs.IR"], "primary_category": "cs.DL"}
