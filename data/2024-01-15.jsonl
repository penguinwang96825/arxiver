{"title": "Leveraging the power of transformers for guilt detection in text", "abstract": "In recent years, language models and deep learning techniques have\nrevolutionized natural language processing tasks, including emotion detection.\nHowever, the specific emotion of guilt has received limited attention in this\nfield. In this research, we explore the applicability of three\ntransformer-based language models for detecting guilt in text and compare their\nperformance for general emotion detection and guilt detection. Our proposed\nmodel outformed BERT and RoBERTa models by two and one points respectively.\nAdditionally, we analyze the challenges in developing accurate guilt-detection\nmodels and evaluate our model's effectiveness in detecting related emotions\nlike \"shame\" through qualitative analysis of results.", "published": "2024-01-15 01:40:39", "link": "http://arxiv.org/abs/2401.07414v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Stability Analysis of ChatGPT-based Sentiment Analysis in AI Quality\n  Assurance", "abstract": "In the era of large AI models, the complex architecture and vast parameters\npresent substantial challenges for effective AI quality management (AIQM), e.g.\nlarge language model (LLM). This paper focuses on investigating the quality\nassurance of a specific LLM-based AI product--a ChatGPT-based sentiment\nanalysis system. The study delves into stability issues related to both the\noperation and robustness of the expansive AI model on which ChatGPT is based.\nExperimental analysis is conducted using benchmark datasets for sentiment\nanalysis. The results reveal that the constructed ChatGPT-based sentiment\nanalysis system exhibits uncertainty, which is attributed to various\noperational factors. It demonstrated that the system also exhibits stability\nissues in handling conventional small text attacks involving robustness.", "published": "2024-01-15 03:00:39", "link": "http://arxiv.org/abs/2401.07441v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GWPT: A Green Word-Embedding-based POS Tagger", "abstract": "As a fundamental tool for natural language processing (NLP), the\npart-of-speech (POS) tagger assigns the POS label to each word in a sentence. A\nnovel lightweight POS tagger based on word embeddings is proposed and named\nGWPT (green word-embedding-based POS tagger) in this work. Following the green\nlearning (GL) methodology, GWPT contains three modules in cascade: 1)\nrepresentation learning, 2) feature learning, and 3) decision learning modules.\nThe main novelty of GWPT lies in representation learning. It uses\nnon-contextual or contextual word embeddings, partitions embedding dimension\nindices into low-, medium-, and high-frequency sets, and represents them with\ndifferent N-grams. It is shown by experimental results that GWPT offers\nstate-of-the-art accuracies with fewer model parameters and significantly lower\ncomputational complexity in both training and inference as compared with\ndeep-learning-based methods.", "published": "2024-01-15 05:06:17", "link": "http://arxiv.org/abs/2401.07475v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "See the Unseen: Better Context-Consistent Knowledge-Editing by Noises", "abstract": "Knowledge-editing updates knowledge of large language models (LLMs) and\ncontributes to the interpretability and application of LLMs. However, knowledge\napplying is context-consistent: LLMs can recall the same knowledge in different\ncontexts. Existing works ignore this property and the editing lacks\ngeneralization. In this paper, we empirically find that the effects of\ndifferent contexts upon LLMs in recalling the same knowledge follow a\nGaussian-like distribution. We then sample Gaussian noises to simulate the\neffects of different contexts when updating LLMs. By such, we can make LLMs see\nthe unseen contexts where the edited knowledge will be applied, therefore\nimproving the editing generalization. Experimental results on three LLMs\ndemonstrate the effectiveness of our methods and also distinguish our methods\nfrom the others of fine-tuning LLMs by noises.", "published": "2024-01-15 09:09:14", "link": "http://arxiv.org/abs/2401.07544v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MAPLE: Multilingual Evaluation of Parameter Efficient Finetuning of\n  Large Language Models", "abstract": "Parameter Efficient Finetuning (PEFT) has emerged as a viable solution for\nimproving the performance of Large Language Models (LLMs) without requiring\nmassive resources and compute. Prior work on multilingual evaluation has shown\nthat there is a large gap between the performance of LLMs on English and other\nlanguages. Further, there is also a large gap between the performance of\nsmaller open-source models and larger LLMs. Finetuning can be an effective way\nto bridge this gap and make language models more equitable. In this work, we\nfinetune the LLama-2-7B and Mistral-7B models on two synthetic multilingual\ninstruction tuning datasets to determine its effect on model performance on six\ndownstream tasks covering forty languages in all. Additionally, we experiment\nwith various parameters, such as rank for low-rank adaptation and values of\nquantisation to determine their effects on downstream performance and find that\nhigher rank and higher quantisation values benefit low-resource languages. We\nfind that PEFT of smaller open-source models sometimes bridges the gap between\nthe performance of these models and the larger ones, however, English\nperformance can take a hit. We also find that finetuning sometimes improves\nperformance on low-resource languages, while degrading performance on\nhigh-resource languages.", "published": "2024-01-15 11:06:43", "link": "http://arxiv.org/abs/2401.07598v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Assisted Knowledge Graph Authoring: Human-Supervised Knowledge Graph\n  Construction from Natural Language", "abstract": "Encyclopedic knowledge graphs, such as Wikidata, host an extensive repository\nof millions of knowledge statements. However, domain-specific knowledge from\nfields such as history, physics, or medicine is significantly underrepresented\nin those graphs. Although few domain-specific knowledge graphs exist (e.g.,\nPubmed for medicine), developing specialized retrieval applications for many\ndomains still requires constructing knowledge graphs from scratch. To\nfacilitate knowledge graph construction, we introduce WAKA: a Web application\nthat allows domain experts to create knowledge graphs through the medium with\nwhich they are most familiar: natural language.", "published": "2024-01-15 13:51:00", "link": "http://arxiv.org/abs/2401.07683v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prompting open-source and commercial language models for grammatical\n  error correction of English learner text", "abstract": "Thanks to recent advances in generative AI, we are able to prompt large\nlanguage models (LLMs) to produce texts which are fluent and grammatical. In\naddition, it has been shown that we can elicit attempts at grammatical error\ncorrection (GEC) from LLMs when prompted with ungrammatical input sentences. We\nevaluate how well LLMs can perform at GEC by measuring their performance on\nestablished benchmark datasets. We go beyond previous studies, which only\nexamined GPT* models on a selection of English GEC datasets, by evaluating\nseven open-source and three commercial LLMs on four established GEC benchmarks.\nWe investigate model performance and report results against individual error\ntypes. Our results indicate that LLMs do not always outperform supervised\nEnglish GEC models except in specific contexts -- namely commercial LLMs on\nbenchmarks annotated with fluency corrections as opposed to minimal edits. We\nfind that several open-source models outperform commercial ones on minimal edit\nbenchmarks, and that in some settings zero-shot prompting is just as\ncompetitive as few-shot prompting.", "published": "2024-01-15 14:19:47", "link": "http://arxiv.org/abs/2401.07702v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the importance of Data Scale in Pretraining Arabic Language Models", "abstract": "Pretraining monolingual language models have been proven to be vital for\nperformance in Arabic Natural Language Processing (NLP) tasks. In this paper,\nwe conduct a comprehensive study on the role of data in Arabic Pretrained\nLanguage Models (PLMs). More precisely, we reassess the performance of a suite\nof state-of-the-art Arabic PLMs by retraining them on massive-scale,\nhigh-quality Arabic corpora. We have significantly improved the performance of\nthe leading Arabic encoder-only BERT-base and encoder-decoder T5-base models on\nthe ALUE and ORCA leaderboards, thereby reporting state-of-the-art results in\ntheir respective model categories. In addition, our analysis strongly suggests\nthat pretraining data by far is the primary contributor to performance,\nsurpassing other factors. Our models and source code are publicly available at\nhttps://github.com/huawei-noah/Pretrained-Language-Model/tree/master/JABER-PyTorch.", "published": "2024-01-15 15:11:15", "link": "http://arxiv.org/abs/2401.07760v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Flexibly Scaling Large Language Models Contexts Through Extensible\n  Tokenization", "abstract": "Large language models (LLMs) are in need of sufficient contexts to handle\nmany critical applications, such as retrieval augmented generation and few-shot\nlearning. However, due to the constrained window size, the LLMs can only access\nto the information within a limited context. Although the size of context\nwindow can be extended by fine-tuning, it will result in a substantial cost in\nboth training and inference stage. In this paper, we present Extensible\nTokenization as an alternative method which realizes the flexible scaling of\nLLMs' context. Extensible Tokenization stands as a midware in between of the\ntokenized context and the LLM, which transforms the raw token embeddings into\nthe extensible embeddings. Such embeddings provide a more compact\nrepresentation for the long context, on top of which the LLM is able to\nperceive more information with the same context window. Extensible Tokenization\nis also featured by its flexibility: the scaling factor can be flexibly\ndetermined within a feasible scope, leading to the extension of an arbitrary\ncontext length at the inference time. Besides, Extensible Tokenization is\nintroduced as a drop-in component, which can be seamlessly plugged into not\nonly the LLM itself and but also its fine-tuned derivatives, bringing in the\nextended contextual information while fully preserving the LLM's existing\ncapabilities. We perform comprehensive experiments on long-context language\nmodeling and understanding tasks, which verify Extensible Tokenization as an\neffective, efficient, flexible, and compatible method to extend LLM's context.\nOur model and source code will be made publicly available.", "published": "2024-01-15 16:00:50", "link": "http://arxiv.org/abs/2401.07793v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Wikidata as a seed for Web Extraction", "abstract": "Wikidata has grown to a knowledge graph with an impressive size. To date, it\ncontains more than 17 billion triples collecting information about people,\nplaces, films, stars, publications, proteins, and many more. On the other side,\nmost of the information on the Web is not published in highly structured data\nrepositories like Wikidata, but rather as unstructured and semi-structured\ncontent, more concretely in HTML pages containing text and tables. Finding,\nmonitoring, and organizing this data in a knowledge graph is requiring\nconsiderable work from human editors. The volume and complexity of the data\nmake this task difficult and time-consuming. In this work, we present a\nframework that is able to identify and extract new facts that are published\nunder multiple Web domains so that they can be proposed for validation by\nWikidata editors. The framework is relying on question-answering technologies.\nWe take inspiration from ideas that are used to extract facts from textual\ncollections and adapt them to extract facts from Web pages. For achieving this,\nwe demonstrate that language models can be adapted to extract facts not only\nfrom textual collections but also from Web pages. By exploiting the information\nalready contained in Wikidata the proposed framework can be trained without the\nneed for any additional learning signals and can extract new facts for a wide\nrange of properties and domains. Following this path, Wikidata can be used as a\nseed to extract facts on the Web. Our experiments show that we can achieve a\nmean performance of 84.07 at F1-score. Moreover, our estimations show that we\ncan potentially extract millions of facts that can be proposed for human\nvalidation. The goal is to help editors in their daily tasks and contribute to\nthe completion of the Wikidata knowledge graph.", "published": "2024-01-15 16:35:52", "link": "http://arxiv.org/abs/2401.07812v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Question Translation Training for Better Multilingual Reasoning", "abstract": "Large language models show compelling performance on reasoning tasks but they\ntend to perform much worse in languages other than English. This is\nunsurprising given that their training data largely consists of English text\nand instructions. A typical solution is to translate instruction data into all\nlanguages of interest, and then train on the resulting multilingual data, which\nis called translate-training. This approach not only incurs high cost, but also\nresults in poorly translated data due to the non-standard formatting of\nmathematical chain-of-thought. In this paper, we explore the benefits of\nquestion alignment, where we train the model to translate reasoning questions\ninto English by finetuning on X-English parallel question data. In this way we\nperform targeted, in-domain language alignment which makes best use of English\ninstruction data to unlock the LLMs' multilingual reasoning abilities.\nExperimental results on LLaMA2-13B show that question alignment leads to\nconsistent improvements over the translate-training approach: an average\nimprovement of 11.3% and 16.1% accuracy across ten languages on the MGSM and\nMSVAMP multilingual reasoning benchmarks. The project will be available at:\nhttps://github.com/NJUNLP/QAlign.", "published": "2024-01-15 16:39:10", "link": "http://arxiv.org/abs/2401.07817v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Milestones in Bengali Sentiment Analysis leveraging Transformer-models:\n  Fundamentals, Challenges and Future Directions", "abstract": "Sentiment Analysis (SA) refers to the task of associating a view polarity\n(usually, positive, negative, or neutral; or even fine-grained such as slightly\nangry, sad, etc.) to a given text, essentially breaking it down to a supervised\n(since we have the view labels apriori) classification task. Although heavily\nstudied in resource-rich languages such as English thus pushing the SOTA by\nleaps and bounds, owing to the arrival of the Transformer architecture, the\nsame cannot be said for resource-poor languages such as Bengali (BN). For a\nlanguage spoken by roughly 300 million people, the technology enabling them to\nrun trials on their favored tongue is severely lacking. In this paper, we\nanalyze the SOTA for SA in Bengali, particularly, Transformer-based models. We\ndiscuss available datasets, their drawbacks, the nuances associated with\nBengali i.e. what makes this a challenging language to apply SA on, and finally\nprovide insights for future direction to mitigate the limitations in the field.", "published": "2024-01-15 17:23:02", "link": "http://arxiv.org/abs/2401.07847v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unlocking Efficiency in Large Language Model Inference: A Comprehensive\n  Survey of Speculative Decoding", "abstract": "To mitigate the high inference latency stemming from autoregressive decoding\nin Large Language Models (LLMs), Speculative Decoding has emerged as a novel\ndecoding paradigm for LLM inference. In each decoding step, this method first\ndrafts several future tokens efficiently and then verifies them in parallel.\nUnlike autoregressive decoding, Speculative Decoding facilitates the\nsimultaneous decoding of multiple tokens per step, thereby accelerating\ninference. This paper presents a comprehensive overview and analysis of this\npromising decoding paradigm. We begin by providing a formal definition and\nformulation of Speculative Decoding. Then, we organize in-depth discussions on\nits key facets, such as drafter selection and verification strategies.\nFurthermore, we present a comparative analysis of leading methods under\nthird-party testing environments. We aim for this work to serve as a catalyst\nfor further research on Speculative Decoding, ultimately contributing to more\nefficient LLM inference.", "published": "2024-01-15 17:26:50", "link": "http://arxiv.org/abs/2401.07851v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Authorship Obfuscation in Multilingual Machine-Generated Text Detection", "abstract": "High-quality text generation capability of recent Large Language Models\n(LLMs) causes concerns about their misuse (e.g., in massive generation/spread\nof disinformation). Machine-generated text (MGT) detection is important to cope\nwith such threats. However, it is susceptible to authorship obfuscation (AO)\nmethods, such as paraphrasing, which can cause MGTs to evade detection. So far,\nthis was evaluated only in monolingual settings. Thus, the susceptibility of\nrecently proposed multilingual detectors is still unknown. We fill this gap by\ncomprehensively benchmarking the performance of 10 well-known AO methods,\nattacking 37 MGT detection methods against MGTs in 11 languages (i.e., 10\n$\\times$ 37 $\\times$ 11 = 4,070 combinations). We also evaluate the effect of\ndata augmentation on adversarial robustness using obfuscated texts. The results\nindicate that all tested AO methods can cause evasion of automated detection in\nall tested languages, where homoglyph attacks are especially successful.\nHowever, some of the AO methods severely damaged the text, making it no longer\nreadable or easily recognizable by humans (e.g., changed language, weird\ncharacters).", "published": "2024-01-15 17:57:41", "link": "http://arxiv.org/abs/2401.07867v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The What, Why, and How of Context Length Extension Techniques in Large\n  Language Models -- A Detailed Survey", "abstract": "The advent of Large Language Models (LLMs) represents a notable breakthrough\nin Natural Language Processing (NLP), contributing to substantial progress in\nboth text comprehension and generation. However, amidst these advancements, it\nis noteworthy that LLMs often face a limitation in terms of context length\nextrapolation. Understanding and extending the context length for LLMs is\ncrucial in enhancing their performance across various NLP applications. In this\nsurvey paper, we delve into the multifaceted aspects of exploring why it is\nessential, and the potential transformations that superior techniques could\nbring to NLP applications. We study the inherent challenges associated with\nextending context length and present an organized overview of the existing\nstrategies employed by researchers. Additionally, we discuss the intricacies of\nevaluating context extension techniques and highlight the open challenges that\nresearchers face in this domain. Furthermore, we explore whether there is a\nconsensus within the research community regarding evaluation standards and\nidentify areas where further agreement is needed. This comprehensive survey\naims to serve as a valuable resource for researchers, guiding them through the\nnuances of context length extension techniques and fostering discussions on\nfuture advancements in this evolving field.", "published": "2024-01-15 18:07:21", "link": "http://arxiv.org/abs/2401.07872v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Pitfalls of Defining Hallucination", "abstract": "Despite impressive advances in Natural Language Generation (NLG) and Large\nLanguage Models (LLMs), researchers are still unclear about important aspects\nof NLG evaluation. To substantiate this claim, I examine current\nclassifications of hallucination and omission in Data-text NLG, and I propose a\nlogic-based synthesis of these classfications. I conclude by highlighting some\nremaining limitations of all current thinking about hallucination and by\ndiscussing implications for LLMs.", "published": "2024-01-15 18:53:15", "link": "http://arxiv.org/abs/2401.07897v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Word Boundary Information Isn't Useful for Encoder Language Models", "abstract": "All existing transformer-based approaches to NLP using subword tokenisation\nalgorithms encode whitespace (word boundary information) through the use of\nspecial space symbols (such as \\#\\# or \\_) forming part of tokens. These\nsymbols have been shown to a) lead to reduced morphological validity of\ntokenisations, and b) give substantial vocabulary redundancy. As such, removing\nthese symbols has been shown to have a beneficial effect on the processing of\nmorphologically complex words for transformer encoders in the pretrain-finetune\nparadigm. In this work, we explore whether word boundary information is at all\nuseful to such models. In particular, we train transformer encoders across four\ndifferent training scales, and investigate several alternative approaches to\nincluding word boundary information, evaluating on a range of tasks across\ndifferent domains and problem set-ups: GLUE (for sentence-level\nclassification), NER (for token-level classification), and two classification\ndatasets involving complex words (Superbizarre and FLOTA). Overall, through an\nextensive experimental setup that includes the pre-training of 29 models, we\nfind no substantial improvements from our alternative approaches, suggesting\nthat modifying tokenisers to remove word boundary information isn't leading to\na loss of useful information.", "published": "2024-01-15 19:21:08", "link": "http://arxiv.org/abs/2401.07923v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Lexicon for Studying Radicalization in Incel Communities", "abstract": "Incels are an extremist online community of men who believe in an ideology\nrooted in misogyny, racism, the glorification of violence, and dehumanization.\nIn their online forums, they use an extensive, evolving cryptolect - a set of\ningroup terms that have meaning within the group, reflect the ideology,\ndemonstrate membership in the community, and are difficult for outsiders to\nunderstand. This paper presents a lexicon with terms and definitions for common\nincel root words, prefixes, and affixes. The lexicon is text-based for use in\nautomated analysis and is derived via a Qualitative Content Analysis of the\nmost frequent incel words, their structure, and their meaning on five of the\nmost active incel communities from 2016 to 2023. This lexicon will support\nfuture work examining radicalization and deradicalization/disengagement within\nthe community.", "published": "2024-01-15 19:39:29", "link": "http://arxiv.org/abs/2401.07928v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SemEval-2017 Task 4: Sentiment Analysis in Twitter using BERT", "abstract": "This paper uses the BERT model, which is a transformer-based architecture, to\nsolve task 4A, English Language, Sentiment Analysis in Twitter of SemEval2017.\nBERT is a very powerful large language model for classification tasks when the\namount of training data is small. For this experiment, we have used the\nBERT(BASE) model, which has 12 hidden layers. This model provides better\naccuracy, precision, recall, and f1 score than the Naive Bayes baseline model.\nIt performs better in binary classification subtasks than the multi-class\nclassification subtasks. We also considered all kinds of ethical issues during\nthis experiment, as Twitter data contains personal and sensible information.\nThe dataset and code used in our experiment can be found in this GitHub\nrepository.", "published": "2024-01-15 20:17:31", "link": "http://arxiv.org/abs/2401.07944v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SciInstruct: a Self-Reflective Instruction Annotated Dataset for\n  Training Scientific Language Models", "abstract": "Large Language Models (LLMs) have shown promise in assisting scientific\ndiscovery. However, such applications are currently limited by LLMs'\ndeficiencies in understanding intricate scientific concepts, deriving symbolic\nequations, and solving advanced numerical calculations. To bridge these gaps,\nwe introduce SciInstruct, a suite of scientific instructions for training\nscientific language models capable of college-level scientific reasoning.\nCentral to our approach is a novel self-reflective instruction annotation\nframework to address the data scarcity challenge in the science domain. This\nframework leverages existing LLMs to generate step-by-step reasoning for\nunlabelled scientific questions, followed by a process of self-reflective\ncritic-and-revise. Applying this framework, we curated a diverse and\nhigh-quality dataset encompassing physics, chemistry, math, and formal proofs.\nWe analyze the curated SciInstruct from multiple interesting perspectives\n(e.g., domain, scale, source, question type, answer length, etc.). To verify\nthe effectiveness of SciInstruct, we fine-tuned different language models with\nSciInstruct, i.e., ChatGLM3 (6B and 32B), Llama3-8B-Instruct, and Mistral-7B:\nMetaMath, enhancing their scientific and mathematical reasoning capabilities,\nwithout sacrificing the language understanding capabilities of the base model.\nWe release all codes and SciInstruct at https://github.com/THUDM/SciGLM.", "published": "2024-01-15 20:22:21", "link": "http://arxiv.org/abs/2401.07950v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Efficient Methods in Medical Question Answering using Knowledge\n  Graph Embeddings", "abstract": "In Natural Language Processing (NLP), Machine Reading Comprehension (MRC) is\nthe task of answering a question based on a given context. To handle questions\nin the medical domain, modern language models such as BioBERT, SciBERT and even\nChatGPT are trained on vast amounts of in-domain medical corpora. However,\nin-domain pre-training is expensive in terms of time and resources. In this\npaper, we propose a resource-efficient approach for injecting domain knowledge\ninto a model without relying on such domain-specific pre-training.\n  Knowledge graphs are powerful resources for accessing medical information.\nBuilding on existing work, we introduce a method using Multi-Layer Perceptrons\n(MLPs) for aligning and integrating embeddings extracted from medical knowledge\ngraphs with the embedding spaces of pre-trained language models (LMs). The\naligned embeddings are fused with open-domain LMs BERT and RoBERTa that are\nfine-tuned for two MRC tasks, span detection (COVID-QA) and multiple-choice\nquestions (PubMedQA). We compare our method to prior techniques that rely on a\nvocabulary overlap for embedding alignment and show how our method circumvents\nthis requirement to deliver better performance. On both datasets, our method\nallows BERT/RoBERTa to either perform on par (occasionally exceeding) with\nstronger domain-specific models or show improvements in general over prior\ntechniques. With the proposed approach, we signal an alternative method to\nin-domain pre-training to achieve domain proficiency. Our code is available\nhere.", "published": "2024-01-15 21:43:46", "link": "http://arxiv.org/abs/2401.07977v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Effect of Human v/s Synthetic Test Data and Round-tripping on\n  Assessment of Sentiment Analysis Systems for Bias", "abstract": "Sentiment Analysis Systems (SASs) are data-driven Artificial Intelligence\n(AI) systems that output polarity and emotional intensity when given a piece of\ntext as input. Like other AIs, SASs are also known to have unstable behavior\nwhen subjected to changes in data which can make it problematic to trust out of\nconcerns like bias when AI works with humans and data has protected attributes\nlike gender, race, and age. Recently, an approach was introduced to assess SASs\nin a blackbox setting without training data or code, and rating them for bias\nusing synthetic English data. We augment it by introducing two human-generated\nchatbot datasets and also consider a round-trip setting of translating the data\nfrom one language to the same through an intermediate language. We find that\nthese settings show SASs performance in a more realistic light. Specifically,\nwe find that rating SASs on the chatbot data showed more bias compared to the\nsynthetic data, and round-tripping using Spanish and Danish as intermediate\nlanguages reduces the bias (up to 68% reduction) in human-generated data while,\nin synthetic data, it takes a surprising turn by increasing the bias! Our\nfindings will help researchers and practitioners refine their SAS testing\nstrategies and foster trust as SASs are considered part of more\nmission-critical applications for global use.", "published": "2024-01-15 15:27:18", "link": "http://arxiv.org/abs/2401.12985v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Taec: a Manually annotated text dataset for trait and phenotype\n  extraction and entity linking in wheat breeding literature", "abstract": "Wheat varieties show a large diversity of traits and phenotypes. Linking them\nto genetic variability is essential for shorter and more efficient wheat\nbreeding programs. Newly desirable wheat variety traits include disease\nresistance to reduce pesticide use, adaptation to climate change, resistance to\nheat and drought stresses, or low gluten content of grains. Wheat breeding\nexperiments are documented by a large body of scientific literature and\nobservational data obtained in-field and under controlled conditions. The\ncross-referencing of complementary information from the literature and\nobservational data is essential to the study of the genotype-phenotype\nrelationship and to the improvement of wheat selection. The scientific\nliterature on genetic marker-assisted selection describes much information\nabout the genotype-phenotype relationship. However, the variety of expressions\nused to refer to traits and phenotype values in scientific articles is a hinder\nto finding information and cross-referencing it. When trained adequately by\nannotated examples, recent text mining methods perform highly in named entity\nrecognition and linking in the scientific domain. While several corpora contain\nannotations of human and animal phenotypes, currently, no corpus is available\nfor training and evaluating named entity recognition and entity-linking methods\nin plant phenotype literature. The Triticum aestivum trait Corpus is a new gold\nstandard for traits and phenotypes of wheat. It consists of 540 PubMed\nreferences fully annotated for trait, phenotype, and species named entities\nusing the Wheat Trait and Phenotype Ontology and the species taxonomy of the\nNational Center for Biotechnology Information. A study of the performance of\ntools trained on the Triticum aestivum trait Corpus shows that the corpus is\nsuitable for the training and evaluation of named entity recognition and\nlinking.", "published": "2024-01-15 03:23:24", "link": "http://arxiv.org/abs/2401.07447v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Only Send What You Need: Learning to Communicate Efficiently in\n  Federated Multilingual Machine Translation", "abstract": "Federated learning (FL) is a promising approach for solving multilingual\ntasks, potentially enabling clients with their own language-specific data to\ncollaboratively construct a high-quality neural machine translation (NMT)\nmodel. However, communication constraints in practical network systems present\nchallenges for exchanging large-scale NMT engines between FL parties. In this\npaper, we propose a meta-learning-based adaptive parameter selection\nmethodology, MetaSend, that improves the communication efficiency of model\ntransmissions from clients during FL-based multilingual NMT training. Our\napproach learns a dynamic threshold for filtering parameters prior to\ntransmission without compromising the NMT model quality, based on the tensor\ndeviations of clients between different FL rounds. Through experiments on two\nNMT datasets with different language distributions, we demonstrate that\nMetaSend obtains substantial improvements over baselines in translation quality\nin the presence of a limited communication budget.", "published": "2024-01-15 04:04:26", "link": "http://arxiv.org/abs/2401.07456v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Utilizing deep learning models for the identification of enhancers and\n  super-enhancers based on genomic and epigenomic features", "abstract": "This paper provides an extensive examination of a sizable dataset of English\ntweets focusing on nine widely recognized cryptocurrencies, specifically\nCardano, Binance, Bitcoin, Dogecoin, Ethereum, Fantom, Matic, Shiba, and\nRipple. Our primary objective was to conduct a psycholinguistic and emotion\nanalysis of social media content associated with these cryptocurrencies. To\nenable investigators to make more informed decisions. The study involved\ncomparing linguistic characteristics across the diverse digital coins, shedding\nlight on the distinctive linguistic patterns that emerge within each coin's\ncommunity. To achieve this, we utilized advanced text analysis techniques.\nAdditionally, our work unveiled an intriguing Understanding of the interplay\nbetween these digital assets within the cryptocurrency community. By examining\nwhich coin pairs are mentioned together most frequently in the dataset, we\nestablished correlations between different cryptocurrencies. To ensure the\nreliability of our findings, we initially gathered a total of 832,559 tweets\nfrom Twitter. These tweets underwent a rigorous preprocessing stage, resulting\nin a refined dataset of 115,899 tweets that were used for our analysis.\nOverall, our research offers valuable Perception into the linguistic nuances of\nvarious digital coins' online communities and provides a deeper understanding\nof their interactions in the cryptocurrency space.", "published": "2024-01-15 04:58:50", "link": "http://arxiv.org/abs/2401.07470v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Developing ChatGPT for Biology and Medicine: A Complete Review of\n  Biomedical Question Answering", "abstract": "ChatGPT explores a strategic blueprint of question answering (QA) in\ndelivering medical diagnosis, treatment recommendations, and other healthcare\nsupport. This is achieved through the increasing incorporation of medical\ndomain data via natural language processing (NLP) and multimodal paradigms. By\ntransitioning the distribution of text, images, videos, and other modalities\nfrom the general domain to the medical domain, these techniques have expedited\nthe progress of medical domain question answering (MDQA). They bridge the gap\nbetween human natural language and sophisticated medical domain knowledge or\nexpert manual annotations, handling large-scale, diverse, unbalanced, or even\nunlabeled data analysis scenarios in medical contexts. Central to our focus is\nthe utilizing of language models and multimodal paradigms for medical question\nanswering, aiming to guide the research community in selecting appropriate\nmechanisms for their specific medical research requirements. Specialized tasks\nsuch as unimodal-related question answering, reading comprehension, reasoning,\ndiagnosis, relation extraction, probability modeling, and others, as well as\nmultimodal-related tasks like vision question answering, image caption,\ncross-modal retrieval, report summarization, and generation, are discussed in\ndetail. Each section delves into the intricate specifics of the respective\nmethod under consideration. This paper highlights the structures and\nadvancements of medical domain explorations against general domain methods,\nemphasizing their applications across different tasks and datasets. It also\noutlines current challenges and opportunities for future medical domain\nresearch, paving the way for continued innovation and application in this\nrapidly evolving field.", "published": "2024-01-15 07:21:16", "link": "http://arxiv.org/abs/2401.07510v3", "categories": ["cs.CL", "cs.AI", "cs.CL, 92-02", "I.2.1"], "primary_category": "cs.CL"}
{"title": "Survey of Natural Language Processing for Education: Taxonomy,\n  Systematic Review, and Future Trends", "abstract": "Natural Language Processing (NLP) aims to analyze text or speech via\ntechniques in the computer science field. It serves the applications in domains\nof healthcare, commerce, education and so on. Particularly, NLP has been widely\napplied to the education domain and its applications have enormous potential to\nhelp teaching and learning. In this survey, we review recent advances in NLP\nwith the focus on solving problems relevant to the education domain. In detail,\nwe begin with introducing the related background and the real-world scenarios\nin education where NLP techniques could contribute. Then, we present a taxonomy\nof NLP in the education domain and highlight typical NLP applications including\nquestion answering, question construction, automated assessment, and error\ncorrection. Next, we illustrate the task definition, challenges, and\ncorresponding cutting-edge techniques based on the above taxonomy. In\nparticular, LLM-involved methods are included for discussion due to the wide\nusage of LLMs in diverse NLP applications. After that, we showcase some\noff-the-shelf demonstrations in this domain. At last, we conclude with six\npromising directions for future research, including more datasets in education\ndomain, controllable usage of LLMs, intervention of difficulty-level control,\ninterpretable educational NLP, methods with adaptive learning, and integrated\nsystems for education. We organize all relevant datasets and papers in the\nopen-available Github Link for better\nreview~\\url{https://github.com/LiXinyuan1015/NLP-for-Education}.", "published": "2024-01-15 07:48:42", "link": "http://arxiv.org/abs/2401.07518v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TAROT: A Hierarchical Framework with Multitask Co-Pretraining on\n  Semi-Structured Data towards Effective Person-Job Fit", "abstract": "Person-job fit is an essential part of online recruitment platforms in\nserving various downstream applications like Job Search and Candidate\nRecommendation. Recently, pretrained large language models have further\nenhanced the effectiveness by leveraging richer textual information in user\nprofiles and job descriptions apart from user behavior features and job\nmetadata. However, the general domain-oriented design struggles to capture the\nunique structural information within user profiles and job descriptions,\nleading to a loss of latent semantic correlations. We propose TAROT, a\nhierarchical multitask co-pretraining framework, to better utilize structural\nand semantic information for informative text embeddings. TAROT targets\nsemi-structured text in profiles and jobs, and it is co-pretained with\nmulti-grained pretraining tasks to constrain the acquired semantic information\nat each level. Experiments on a real-world LinkedIn dataset show significant\nperformance improvements, proving its effectiveness in person-job fit tasks.", "published": "2024-01-15 07:57:58", "link": "http://arxiv.org/abs/2401.07525v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MM-SAP: A Comprehensive Benchmark for Assessing Self-Awareness of\n  Multimodal Large Language Models in Perception", "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) have\ndemonstrated exceptional capabilities in visual perception and understanding.\nHowever, these models also suffer from hallucinations, which limit their\nreliability as AI systems. We believe that these hallucinations are partially\ndue to the models' struggle with understanding what they can and cannot\nperceive from images, a capability we refer to as self-awareness in perception.\nDespite its importance, this aspect of MLLMs has been overlooked in prior\nstudies. In this paper, we aim to define and evaluate the self-awareness of\nMLLMs in perception. To do this, we first introduce the knowledge quadrant in\nperception, which helps define what MLLMs know and do not know about images.\nUsing this framework, we propose a novel benchmark, the Self-Awareness in\nPerception for MLLMs (MM-SAP), specifically designed to assess this capability.\nWe apply MM-SAP to a variety of popular MLLMs, offering a comprehensive\nanalysis of their self-awareness and providing detailed insights. The\nexperiment results reveal that current MLLMs possess limited self-awareness\ncapabilities, pointing to a crucial area for future advancement in the\ndevelopment of trustworthy MLLMs. Code and data are available at\nhttps://github.com/YHWmz/MM-SAP.", "published": "2024-01-15 08:19:22", "link": "http://arxiv.org/abs/2401.07529v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Safe Reinforcement Learning with Free-form Natural Language Constraints\n  and Pre-Trained Language Models", "abstract": "Safe reinforcement learning (RL) agents accomplish given tasks while adhering\nto specific constraints. Employing constraints expressed via\neasily-understandable human language offers considerable potential for\nreal-world applications due to its accessibility and non-reliance on domain\nexpertise. Previous safe RL methods with natural language constraints typically\nadopt a recurrent neural network, which leads to limited capabilities when\ndealing with various forms of human language input. Furthermore, these methods\noften require a ground-truth cost function, necessitating domain expertise for\nthe conversion of language constraints into a well-defined cost function that\ndetermines constraint violation. To address these issues, we proposes to use\npre-trained language models (LM) to facilitate RL agents' comprehension of\nnatural language constraints and allow them to infer costs for safe policy\nlearning. Through the use of pre-trained LMs and the elimination of the need\nfor a ground-truth cost, our method enhances safe policy learning under a\ndiverse set of human-derived free-form natural language constraints.\nExperiments on grid-world navigation and robot control show that the proposed\nmethod can achieve strong performance while adhering to given constraints. The\nusage of pre-trained LMs allows our method to comprehend complicated\nconstraints and learn safe policies without the need for ground-truth cost at\nany stage of training or evaluation. Extensive ablation studies are conducted\nto demonstrate the efficacy of each part of our method.", "published": "2024-01-15 09:37:03", "link": "http://arxiv.org/abs/2401.07553v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Exploiting GPT-4 Vision for Zero-shot Point Cloud Understanding", "abstract": "In this study, we tackle the challenge of classifying the object category in\npoint clouds, which previous works like PointCLIP struggle to address due to\nthe inherent limitations of the CLIP architecture. Our approach leverages GPT-4\nVision (GPT-4V) to overcome these challenges by employing its advanced\ngenerative abilities, enabling a more adaptive and robust classification\nprocess. We adapt the application of GPT-4V to process complex 3D data,\nenabling it to achieve zero-shot recognition capabilities without altering the\nunderlying model architecture. Our methodology also includes a systematic\nstrategy for point cloud image visualization, mitigating domain gap and\nenhancing GPT-4V's efficiency. Experimental validation demonstrates our\napproach's superiority in diverse scenarios, setting a new benchmark in\nzero-shot point cloud classification.", "published": "2024-01-15 10:16:44", "link": "http://arxiv.org/abs/2401.07572v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Consolidating Strategies for Countering Hate Speech Using Persuasive\n  Dialogues", "abstract": "Hateful comments are prevalent on social media platforms. Although tools for\nautomatically detecting, flagging, and blocking such false, offensive, and\nharmful content online have lately matured, such reactive and brute force\nmethods alone provide short-term and superficial remedies while the\nperpetrators persist. With the public availability of large language models\nwhich can generate articulate synthetic and engaging content at scale, there\nare concerns about the rapid growth of dissemination of such malicious content\non the web. There is now a need to focus on deeper, long-term solutions that\ninvolve engaging with the human perpetrator behind the source of the content to\nchange their viewpoint or at least bring down the rhetoric using persuasive\nmeans. To do that, we propose defining and experimenting with controllable\nstrategies for generating counter-arguments to hateful comments in online\nconversations. We experiment with controlling response generation using\nfeatures based on (i) argument structure and reasoning-based Walton argument\nschemes, (ii) counter-argument speech acts, and (iii) human\ncharacteristics-based qualities such as Big-5 personality traits and human\nvalues. Using automatic and human evaluations, we determine the best\ncombination of features that generate fluent, argumentative, and logically\nsound arguments for countering hate. We further share the developed\ncomputational models for automatically annotating text with such features, and\na silver-standard annotated version of an existing hate speech dialog corpora.", "published": "2024-01-15 16:31:18", "link": "http://arxiv.org/abs/2401.07810v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "EMBRE: Entity-aware Masking for Biomedical Relation Extraction", "abstract": "Information extraction techniques, including named entity recognition (NER)\nand relation extraction (RE), are crucial in many domains to support making\nsense of vast amounts of unstructured text data by identifying and connecting\nrelevant information. Such techniques can assist researchers in extracting\nvaluable insights. In this paper, we introduce the Entity-aware Masking for\nBiomedical Relation Extraction (EMBRE) method for biomedical relation\nextraction, as applied in the context of the BioRED challenge Task 1, in which\nhuman-annotated entities are provided as input. Specifically, we integrate\nentity knowledge into a deep neural network by pretraining the backbone model\nwith an entity masking objective. We randomly mask named entities for each\ninstance and let the model identify the masked entity along with its type. In\nthis way, the model is capable of learning more specific knowledge and more\nrobust representations. Then, we utilize the pre-trained model as our backbone\nto encode language representations and feed these representations into two\nmultilayer perceptron (MLPs) to predict the logits for relation and novelty,\nrespectively. The experimental results demonstrate that our proposed method can\nimprove the performances of entity pair, relation and novelty extraction over\nour baseline.", "published": "2024-01-15 18:12:01", "link": "http://arxiv.org/abs/2401.07877v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AI-as-exploration: Navigating intelligence space", "abstract": "Artificial Intelligence is a field that lives many lives, and the term has\ncome to encompass a motley collection of scientific and commercial endeavours.\nIn this paper, I articulate the contours of a rather neglected but central\nscientific role that AI has to play, which I dub `AI-as-exploration'.The basic\nthrust of AI-as-exploration is that of creating and studying systems that can\nreveal candidate building blocks of intelligence that may differ from the forms\nof human and animal intelligence we are familiar with. In other words, I\nsuggest that AI is one of the best tools we have for exploring intelligence\nspace, namely the space of possible intelligent systems. I illustrate the value\nof AI-as-exploration by focusing on a specific case study, i.e., recent work on\nthe capacity to combine novel and invented concepts in humans and Large\nLanguage Models. I show that the latter, despite showing human-level accuracy\nin such a task, probably solve it in ways radically different, but no less\nrelevant to intelligence research, to those hypothesised for humans.", "published": "2024-01-15 21:06:20", "link": "http://arxiv.org/abs/2401.07964v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Model Editing at Scale leads to Gradual and Catastrophic Forgetting", "abstract": "Editing knowledge in large language models is an attractive capability to\nhave which allows us to correct incorrectly learnt facts during pre-training,\nas well as update the model with an ever-growing list of new facts. While\nexisting model editing techniques have shown promise, they are usually\nevaluated using metrics for reliability, specificity and generalization over\none or few edits. We argue that for model editing to have practical utility, we\nmust be able to make multiple edits to the same model. With this in mind, we\nevaluate the current model editing methods at scale, focusing on two state of\nthe art methods: ROME and MEMIT. We find that as the model is edited\nsequentially with multiple facts, it continually forgets previously edited\nfacts and the ability to perform downstream tasks. This forgetting happens in\ntwo phases -- an initial gradual but progressive forgetting phase followed by\nabrupt or catastrophic forgetting phase. Both gradual and catastrophic\nforgetting limit the usefulness of model editing methods at scale -- the former\nmaking model editing less effective as multiple edits are made to the model\nwhile the latter caps the scalability of such model editing methods. Our\nanalysis also highlights other key limitations of ROME and MEMIT at scale. With\nour work, we push for the development and evaluation of model editing methods\nkeeping scalability in mind.", "published": "2024-01-15 03:57:15", "link": "http://arxiv.org/abs/2401.07453v4", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Editing Arbitrary Propositions in LLMs without Subject Labels", "abstract": "Large Language Model (LLM) editing modifies factual information in LLMs.\nLocate-and-Edit (L\\&E) methods accomplish this by finding where relevant\ninformation is stored within the neural network, and editing the weights at\nthat location. The goal of editing is to modify the response of an LLM to a\nproposition independently of its phrasing, while not modifying its response to\nother related propositions. Existing methods are limited to binary\npropositions, which represent straightforward binary relations between a\nsubject and an object. Furthermore, existing methods rely on semantic subject\nlabels, which may not be available or even be well-defined in practice. In this\npaper, we show that both of these issues can be effectively skirted with a\nsimple and fast localization method called Gradient Tracing (GT). This\nlocalization method allows editing arbitrary propositions instead of just\nbinary ones, and does so without the need for subject labels. As propositions\nalways have a truth value, our experiments prompt an LLM as a boolean\nclassifier, and edit its T/F response to propositions. Our method applies GT\nfor location tracing, and then edit the model at that location using a mild\nvariant of Rank-One Model Editing (ROME). On datasets of binary propositions\nderived from the CounterFact dataset, we show that our method -- without access\nto subject labels -- performs close to state-of-the-art L\\&E methods which has\naccess subject labels. We then introduce a new dataset, Factual Accuracy\nClassification Test (FACT), which includes non-binary propositions and for\nwhich subject labels are not generally applicable, and therefore is beyond the\nscope of existing L\\&E methods. Nevertheless, we show that with our method\nediting is possible on FACT.", "published": "2024-01-15 08:08:24", "link": "http://arxiv.org/abs/2401.07526v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Cascaded Cross-Modal Transformer for Audio-Textual Classification", "abstract": "Speech classification tasks often require powerful language understanding\nmodels to grasp useful features, which becomes problematic when limited\ntraining data is available. To attain superior classification performance, we\npropose to harness the inherent value of multimodal representations by\ntranscribing speech using automatic speech recognition (ASR) models and\ntranslating the transcripts into different languages via pretrained translation\nmodels. We thus obtain an audio-textual (multimodal) representation for each\ndata sample. Subsequently, we combine language-specific Bidirectional Encoder\nRepresentations from Transformers (BERT) with Wav2Vec2.0 audio features via a\nnovel cascaded cross-modal transformer (CCMT). Our model is based on two\ncascaded transformer blocks. The first one combines text-specific features from\ndistinct languages, while the second one combines acoustic features with\nmultilingual features previously learned by the first transformer block. We\nemployed our system in the Requests Sub-Challenge of the ACM Multimedia 2023\nComputational Paralinguistics Challenge. CCMT was declared the winning\nsolution, obtaining an unweighted average recall (UAR) of 65.41% and 85.87% for\ncomplaint and request detection, respectively. Moreover, we applied our\nframework on the Speech Commands v2 and HarperValleyBank dialog data sets,\nsurpassing previous studies reporting results on these benchmarks. Our code is\nfreely available for download at: https://github.com/ristea/ccmt.", "published": "2024-01-15 10:18:08", "link": "http://arxiv.org/abs/2401.07575v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Quantum Transfer Learning for Acceptability Judgements", "abstract": "Hybrid quantum-classical classifiers promise to positively impact critical\naspects of natural language processing tasks, particularly\nclassification-related ones. Among the possibilities currently investigated,\nquantum transfer learning, i.e., using a quantum circuit for fine-tuning\npre-trained classical models for a specific task, is attracting significant\nattention as a potential platform for proving quantum advantage.\n  This work shows potential advantages, both in terms of performance and\nexpressiveness, of quantum transfer learning algorithms trained on embedding\nvectors extracted from a large language model to perform classification on a\nclassical Linguistics task: acceptability judgments. Acceptability judgment is\nthe ability to determine whether a sentence is considered natural and\nwell-formed by a native speaker. The approach has been tested on sentences\nextracted from ItaCoLa, a corpus that collects Italian sentences labeled with\ntheir acceptability judgment. The evaluation phase shows results for the\nquantum transfer learning pipeline comparable to state-of-the-art classical\ntransfer learning algorithms, proving current quantum computers' capabilities\nto tackle NLP tasks for ready-to-use applications. Furthermore, a qualitative\nlinguistic analysis, aided by explainable AI methods, reveals the capabilities\nof quantum transfer learning algorithms to correctly classify complex and more\nstructured sentences, compared to their classical counterpart. This finding\nsets the ground for a quantifiable quantum advantage in NLP in the near future.", "published": "2024-01-15 15:40:16", "link": "http://arxiv.org/abs/2401.07777v1", "categories": ["cs.CL", "physics.comp-ph", "quant-ph"], "primary_category": "cs.CL"}
{"title": "Consolidating Trees of Robotic Plans Generated Using Large Language\n  Models to Improve Reliability", "abstract": "The inherent probabilistic nature of Large Language Models (LLMs) introduces\nan element of unpredictability, raising concerns about potential discrepancies\nin their output. This paper introduces an innovative approach aims to generate\ncorrect and optimal robotic task plans for diverse real-world demands and\nscenarios. LLMs have been used to generate task plans, but they are unreliable\nand may contain wrong, questionable, or high-cost steps. The proposed approach\nuses LLM to generate a number of task plans as trees and amalgamates them into\na graph by removing questionable paths. Then an optimal task tree can be\nretrieved to circumvent questionable and high-cost nodes, thereby improving\nplanning accuracy and execution efficiency. The approach is further improved by\nincorporating a large knowledge network. Leveraging GPT-4 further, the\nhigh-level task plan is converted into a low-level Planning Domain Definition\nLanguage (PDDL) plan executable by a robot. Evaluation results highlight the\nsuperior accuracy and efficiency of our approach compared to previous\nmethodologies in the field of task planning.", "published": "2024-01-15 18:01:59", "link": "http://arxiv.org/abs/2401.07868v1", "categories": ["cs.RO", "cs.AI", "cs.CL"], "primary_category": "cs.RO"}
{"title": "JumpCoder: Go Beyond Autoregressive Coder via Online Modification", "abstract": "While existing code large language models (code LLMs) exhibit impressive\ncapabilities in code generation, their autoregressive sequential generation\ninherently lacks reversibility. This limitation hinders them from timely\ncorrecting previous missing statements during coding as humans do, often\nleading to error propagation and suboptimal performance. We introduce\nJumpCoder, a novel model-agnostic framework that enables human-like online\nmodification and non-sequential generation to augment code LLMs. The key idea\nbehind JumpCoder is to insert new code into the currently generated code when\nnecessary during generation, which is achieved through an auxiliary infilling\nmodel that works in tandem with the code LLM. Since identifying the best infill\nposition beforehand is intractable, we adopt an \\textit{infill-first,\njudge-later} strategy, which experiments with filling at the $k$ most critical\npositions following the generation of each line, and uses an Abstract Syntax\nTree (AST) parser alongside the Generation Model Scoring to effectively judge\nthe validity of each potential infill. Extensive experiments using six\nstate-of-the-art code LLMs across multiple and multilingual benchmarks\nconsistently indicate significant improvements over all baselines. Our code is\npublic at https://github.com/Keytoyze/JumpCoder.", "published": "2024-01-15 18:04:29", "link": "http://arxiv.org/abs/2401.07870v2", "categories": ["cs.CL", "cs.AI", "cs.SE"], "primary_category": "cs.CL"}
{"title": "The Chronicles of RAG: The Retriever, the Chunk and the Generator", "abstract": "Retrieval Augmented Generation (RAG) has become one of the most popular\nparadigms for enabling LLMs to access external data, and also as a mechanism\nfor grounding to mitigate against hallucinations. When implementing RAG you can\nface several challenges like effective integration of retrieval models,\nefficient representation learning, data diversity, computational efficiency\noptimization, evaluation, and quality of text generation. Given all these\nchallenges, every day a new technique to improve RAG appears, making it\nunfeasible to experiment with all combinations for your problem. In this\ncontext, this paper presents good practices to implement, optimize, and\nevaluate RAG for the Brazilian Portuguese language, focusing on the\nestablishment of a simple pipeline for inference and experiments. We explored a\ndiverse set of methods to answer questions about the first Harry Potter book.\nTo generate the answers we used the OpenAI's gpt-4, gpt-4-1106-preview,\ngpt-3.5-turbo-1106, and Google's Gemini Pro. Focusing on the quality of the\nretriever, our approach achieved an improvement of MRR@10 by 35.4% compared to\nthe baseline. When optimizing the input size in the application, we observed\nthat it is possible to further enhance it by 2.4%. Finally, we present the\ncomplete architecture of the RAG with our recommendations. As result, we moved\nfrom a baseline of 57.88% to a maximum relative score of 98.61%.", "published": "2024-01-15 18:25:18", "link": "http://arxiv.org/abs/2401.07883v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Learned Best-Effort LLM Serving", "abstract": "Many applications must provide low-latency LLM service to users or risk\nunacceptable user experience. However, over-provisioning resources to serve\nfluctuating request patterns is often prohibitively expensive. In this work, we\npresent a best-effort serving system that employs deep reinforcement learning\nto adjust service quality based on the task distribution and system load. Our\nbest-effort system can maintain availability with over 10x higher client\nrequest rates, serves above 96% of peak performance 4.1x more often, and serves\nabove 98% of peak performance 2.3x more often than static serving on\nunpredictable workloads. Our learned router is robust to shifts in both the\narrival and task distribution. Compared to static serving, learned best-effort\nserving allows for cost-efficient serving through increased hardware utility.\nAdditionally, we argue that learned best-effort LLM serving is applicable in\nwide variety of settings and provides application developers great flexibility\nto meet their specific needs.", "published": "2024-01-15 18:28:17", "link": "http://arxiv.org/abs/2401.07886v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Are self-explanations from Large Language Models faithful?", "abstract": "Instruction-tuned Large Language Models (LLMs) excel at many tasks and will\neven explain their reasoning, so-called self-explanations. However, convincing\nand wrong self-explanations can lead to unsupported confidence in LLMs, thus\nincreasing risk. Therefore, it's important to measure if self-explanations\ntruly reflect the model's behavior. Such a measure is called\ninterpretability-faithfulness and is challenging to perform since the ground\ntruth is inaccessible, and many LLMs only have an inference API. To address\nthis, we propose employing self-consistency checks to measure faithfulness. For\nexample, if an LLM says a set of words is important for making a prediction,\nthen it should not be able to make its prediction without these words. While\nself-consistency checks are a common approach to faithfulness, they have not\npreviously been successfully applied to LLM self-explanations for\ncounterfactual, feature attribution, and redaction explanations. Our results\ndemonstrate that faithfulness is explanation, model, and task-dependent,\nshowing self-explanations should not be trusted in general. For example, with\nsentiment classification, counterfactuals are more faithful for Llama2, feature\nattribution for Mistral, and redaction for Falcon 40B.", "published": "2024-01-15 19:39:15", "link": "http://arxiv.org/abs/2401.07927v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Study on Large Language Models' Limitations in Multiple-Choice\n  Question Answering", "abstract": "The widespread adoption of Large Language Models (LLMs) has become\ncommonplace, particularly with the emergence of open-source models. More\nimportantly, smaller models are well-suited for integration into consumer\ndevices and are frequently employed either as standalone solutions or as\nsubroutines in various AI tasks. Despite their ubiquitous use, there is no\nsystematic analysis of their specific capabilities and limitations. In this\nstudy, we tackle one of the most widely used tasks - answering Multiple Choice\nQuestion (MCQ). We analyze 26 small open-source models and find that 65% of the\nmodels do not understand the task, only 4 models properly select an answer from\nthe given choices, and only 5 of these models are choice order independent.\nThese results are rather alarming given the extensive use of MCQ tests with\nthese models. We recommend exercising caution and testing task understanding\nbefore using MCQ to evaluate LLMs in any field whatsoever.", "published": "2024-01-15 20:42:16", "link": "http://arxiv.org/abs/2401.07955v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MCMChaos: Improvising Rap Music with MCMC Methods and Chaos Theory", "abstract": "A novel freestyle rap software, MCMChaos 0.0.1, based on rap music\ntranscriptions created in previous research is presented. The software has\nthree different versions, each making use of different mathematical simulation\nmethods: collapsed gibbs sampler and lorenz attractor simulation. As far as we\nknow, these simulation methods have never been used in rap music generation\nbefore. The software implements Python Text-to-Speech processing (pyttxs) to\nconvert text wrangled from the MCFlow corpus into English speech. In each\nversion, values simulated from each respective mathematical model alter the\nrate of speech, volume, and (in the multiple voice case) the voice of the\ntext-to-speech engine on a line-by-line basis. The user of the software is\npresented with a real-time graphical user interface (GUI) which instantaneously\nchanges the initial values read into the mathematical simulation methods.\nFuture research might attempt to allow for more user control and autonomy.", "published": "2024-01-15 21:10:19", "link": "http://arxiv.org/abs/2401.07967v1", "categories": ["cs.SD", "cs.CL", "cs.HC", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Novel Approach for Automatic Program Repair using Round-Trip\n  Translation with Large Language Models", "abstract": "Research shows that grammatical mistakes in a sentence can be corrected by\ntranslating it to another language and back using neural machine translation\nwith language models. We investigate whether this correction capability of\nLarge Language Models (LLMs) extends to Automatic Program Repair (APR). Current\ngenerative models for APR are pre-trained on source code and fine-tuned for\nrepair. This paper proposes bypassing the fine-tuning step and using Round-Trip\nTranslation (RTT): translation of code from one programming language to another\nprogramming or natural language, and back. We hypothesize that RTT with LLMs\nrestores the most commonly seen patterns in code during pre-training, i.e.,\nperforms a regression toward the mean, which removes bugs as they are a form of\nnoise w.r.t. the more frequent, natural, bug-free code in the training data. To\ntest this hypothesis, we employ eight recent LLMs pre-trained on code,\nincluding the latest GPT versions, and four common program repair benchmarks in\nJava. We find that RTT with English as an intermediate language repaired 101 of\n164 bugs with GPT-4 on the HumanEval-Java dataset. Moreover, 46 of these are\nunique bugs that are not repaired by other LLMs fine-tuned for APR. Our\nfindings highlight the viability of round-trip translation with LLMs as a\ntechnique for automated program repair and its potential for research in\nsoftware engineering.\n  Keywords: automated program repair, large language model, machine translation", "published": "2024-01-15 22:36:31", "link": "http://arxiv.org/abs/2401.07994v1", "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Decoupled Spatial and Temporal Processing for Resource Efficient\n  Multichannel Speech Enhancement", "abstract": "We present a novel model designed for resource-efficient multichannel speech\nenhancement in the time domain, with a focus on low latency, lightweight, and\nlow computational requirements. The proposed model incorporates explicit\nspatial and temporal processing within deep neural network (DNN) layers.\nInspired by frequency-dependent multichannel filtering, our spatial filtering\nprocess applies multiple trainable filters to each hidden unit across the\nspatial dimension, resulting in a multichannel output. The temporal processing\nis applied over a single-channel output stream from the spatial processing\nusing a Long Short-Term Memory (LSTM) network. The output from the temporal\nprocessing stage is then further integrated into the spatial dimension through\nelementwise multiplication. This explicit separation of spatial and temporal\nprocessing results in a resource-efficient network design. Empirical findings\nfrom our experiments show that our proposed model significantly outperforms\nrobust baseline models while demanding far fewer parameters and computations,\nwhile achieving an ultra-low algorithmic latency of just 2 milliseconds.", "published": "2024-01-15 18:15:52", "link": "http://arxiv.org/abs/2401.07879v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "On the Importance of Neural Wiener Filter for Resource Efficient\n  Multichannel Speech Enhancement", "abstract": "We introduce a time-domain framework for efficient multichannel speech\nenhancement, emphasizing low latency and computational efficiency. This\nframework incorporates two compact deep neural networks (DNNs) surrounding a\nmultichannel neural Wiener filter (NWF). The first DNN enhances the speech\nsignal to estimate NWF coefficients, while the second DNN refines the output\nfrom the NWF. The NWF, while conceptually similar to the traditional\nfrequency-domain Wiener filter, undergoes a training process optimized for\nlow-latency speech enhancement, involving fine-tuning of both analysis and\nsynthesis transforms. Our research results illustrate that the NWF output,\nhaving minimal nonlinear distortions, attains performance levels akin to those\nof the first DNN, deviating from conventional Wiener filter paradigms. Training\nall components jointly outperforms sequential training, despite its simplicity.\nConsequently, this framework achieves superior performance with fewer\nparameters and reduced computational demands, making it a compelling solution\nfor resource-efficient multichannel speech enhancement.", "published": "2024-01-15 18:23:12", "link": "http://arxiv.org/abs/2401.07882v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SeMaScore : a new evaluation metric for automatic speech recognition\n  tasks", "abstract": "In this study, we present SeMaScore, generated using a segment-wise mapping\nand scoring algorithm that serves as an evaluation metric for automatic speech\nrecognition tasks. SeMaScore leverages both the error rate and a more robust\nsimilarity score. We show that our algorithm's score generation improves upon\nthe state-of-the-art BERTScore. Our experimental results show that SeMaScore\ncorresponds well with expert human assessments, signal-to-noise ratio levels,\nand other natural language metrics. We outperform BERTScore by 41x in metric\ncomputation speed. Overall, we demonstrate that SeMaScore serves as a more\ndependable evaluation metric, particularly in real-world situations involving\natypical speech patterns.", "published": "2024-01-15 07:13:43", "link": "http://arxiv.org/abs/2401.07506v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Multi-view MidiVAE: Fusing Track- and Bar-view Representations for Long\n  Multi-track Symbolic Music Generation", "abstract": "Variational Autoencoders (VAEs) constitute a crucial component of neural\nsymbolic music generation, among which some works have yielded outstanding\nresults and attracted considerable attention. Nevertheless, previous VAEs still\nencounter issues with overly long feature sequences and generated results lack\ncontextual coherence, thus the challenge of modeling long multi-track symbolic\nmusic still remains unaddressed. To this end, we propose Multi-view MidiVAE, as\none of the pioneers in VAE methods that effectively model and generate long\nmulti-track symbolic music. The Multi-view MidiVAE utilizes the two-dimensional\n(2-D) representation, OctupleMIDI, to capture relationships among notes while\nreducing the feature sequences length. Moreover, we focus on instrumental\ncharacteristics and harmony as well as global and local information about the\nmusical composition by employing a hybrid variational encoding-decoding\nstrategy to integrate both Track- and Bar-view MidiVAE features. Objective and\nsubjective experimental results on the CocoChorales dataset demonstrate that,\ncompared to the baseline, Multi-view MidiVAE exhibits significant improvements\nin terms of modeling long multi-track symbolic music.", "published": "2024-01-15 08:41:01", "link": "http://arxiv.org/abs/2401.07532v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Effect of target signals and delays on spatially selective active noise\n  control for open-fitting hearables", "abstract": "Spatially selective active noise control (ANC) hearables are designed to\nreduce unwanted noise from certain directions while preserving desired sounds\nfrom other directions. In previous studies, the target signal has been defined\neither as the delayed desired component in one of the reference microphone\nsignals or as the desired component in the error microphone signal without any\ndelay. In this paper, we systematically investigate the influence of delays in\ndifferent target signals on the ANC performance and provide an intuitive\nexplanation for how the system obtains the desired signal. Simulations were\nconducted on a pair of open-fitting hearables for localized speech and noise\nsources in an anechoic environment. The performance was assessed in terms of\nnoise reduction, signal quality and control effort. Results indicate that\noptimal performance is achieved without delays when the target signal is\ndefined at the error microphone, whereas causality necessitates delays when the\ntarget signal is defined at the reference microphone. The optimal delay is\nfound to be the acoustic delay between this reference microphone and the error\nmicrophone from the desired source.", "published": "2024-01-15 13:48:49", "link": "http://arxiv.org/abs/2401.07681v1", "categories": ["eess.AS", "cs.SY", "eess.SY"], "primary_category": "eess.AS"}
{"title": "Comparison of Frequency-Fusion Mechanisms for Binaural\n  Direction-of-Arrival Estimation for Multiple Speakers", "abstract": "To estimate the direction of arrival (DOA) of multiple speakers with methods\nthat use prototype transfer functions, frequency-dependent spatial spectra\n(SPS) are usually constructed. To make the DOA estimation robust, SPS from\ndifferent frequencies can be combined. According to how the SPS are combined,\nfrequency fusion mechanisms are categorized into narrowband, broadband, or\nspeaker-grouped, where the latter mechanism requires a speaker-wise grouping of\nfrequencies. For a binaural hearing aid setup, in this paper we propose an\ninteraural time difference (ITD)-based speaker-grouped frequency fusion\nmechanism. By exploiting the DOA dependence of ITDs, frequencies can be grouped\naccording to a common ITD and be used for DOA estimation of the respective\nspeaker. We apply the proposed ITD-based speaker-grouped frequency fusion\nmechanism for different DOA estimation methods, namely the multiple signal\nclassification, steered response power and a recently published method based on\nrelative transfer function (RTF) vectors. In our experiments, we compare DOA\nestimation with different fusion mechanisms. For all considered DOA estimation\nmethods, the proposed ITD-based speaker-grouped frequency fusion mechanism\nresults in a higher DOA estimation accuracy compared with the narrowband and\nbroadband fusion mechanisms.", "published": "2024-01-15 17:25:58", "link": "http://arxiv.org/abs/2401.07849v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Machine Perceptual Quality: Evaluating the Impact of Severe Lossy\n  Compression on Audio and Image Models", "abstract": "In the field of neural data compression, the prevailing focus has been on\noptimizing algorithms for either classical distortion metrics, such as PSNR or\nSSIM, or human perceptual quality. With increasing amounts of data consumed by\nmachines rather than humans, a new paradigm of machine-oriented\ncompression$\\unicode{x2013}$which prioritizes the retention of features salient\nfor machine perception over traditional human-centric\ncriteria$\\unicode{x2013}$has emerged, creating several new challenges to the\ndevelopment, evaluation, and deployment of systems utilizing lossy compression.\nIn particular, it is unclear how different approaches to lossy compression will\naffect the performance of downstream machine perception tasks. To address this\nunder-explored area, we evaluate various perception\nmodels$\\unicode{x2013}$including image classification, image segmentation,\nspeech recognition, and music source separation$\\unicode{x2013}$under severe\nlossy compression. We utilize several popular codecs spanning conventional,\nneural, and generative compression architectures. Our results indicate three\nkey findings: (1) using generative compression, it is feasible to leverage\nhighly compressed data while incurring a negligible impact on machine\nperceptual quality; (2) machine perceptual quality correlates strongly with\ndeep similarity metrics, indicating a crucial role of these metrics in the\ndevelopment of machine-oriented codecs; and (3) using lossy compressed\ndatasets, (e.g. ImageNet) for pre-training can lead to counter-intuitive\nscenarios where lossy compression increases machine perceptual quality rather\nthan degrading it. To encourage engagement on this growing area of research,\nour code and experiments are available at:\nhttps://github.com/danjacobellis/MPQ.", "published": "2024-01-15 20:47:24", "link": "http://arxiv.org/abs/2401.07957v1", "categories": ["eess.IV", "cs.CV", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "eess.IV"}
