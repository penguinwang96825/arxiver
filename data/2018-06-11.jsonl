{"title": "Part-of-Speech Tagging on an Endangered Language: a Parallel\n  Griko-Italian Resource", "abstract": "Most work on part-of-speech (POS) tagging is focused on high resource\nlanguages, or examines low-resource and active learning settings through\nsimulated studies. We evaluate POS tagging techniques on an actual endangered\nlanguage, Griko. We present a resource that contains 114 narratives in Griko,\nalong with sentence-level translations in Italian, and provides gold\nannotations for the test set. Based on a previously collected small corpus, we\ninvestigate several traditional methods, as well as methods that take advantage\nof monolingual data or project cross-lingual POS tags. We show that the\ncombination of a semi-supervised method with cross-lingual transfer is more\nappropriate for this extremely challenging setting, with the best tagger\nachieving an accuracy of 72.9%. With an applied active learning scheme, which\nwe use to collect sentence-level annotations over the test set, we achieve\nimprovements of more than 21 percentage points.", "published": "2018-06-11 01:08:52", "link": "http://arxiv.org/abs/1806.03757v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Addition of Code Mixed Features to Enhance the Sentiment Prediction of\n  Song Lyrics", "abstract": "Sentiment analysis, also called opinion mining, is the field of study that\nanalyzes people's opinions,sentiments, attitudes and emotions. Songs are\nimportant to sentiment analysis since the songs and mood are mutually dependent\non each other. Based on the selected song it becomes easy to find the mood of\nthe listener, in future it can be used for recommendation. The song lyric is a\nrich source of datasets containing words that are helpful in analysis and\nclassification of sentiments generated from it. Now a days we observe a lot of\ninter-sentential and intra-sentential code-mixing in songs which has a varying\nimpact on audience. To study this impact we created a Telugu songs dataset\nwhich contained both Telugu-English code-mixed and pure Telugu songs. In this\npaper, we classify the songs based on its arousal as exciting or non-exciting.\nWe develop a language identification tool and introduce code-mixing features\nobtained from it as additional features. Our system with these additional\nfeatures attains 4-5% accuracy greater than traditional approaches on our\ndataset.", "published": "2018-06-11 06:08:40", "link": "http://arxiv.org/abs/1806.03821v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Know What You Don't Know: Unanswerable Questions for SQuAD", "abstract": "Extractive reading comprehension systems can often locate the correct answer\nto a question in a context document, but they also tend to make unreliable\nguesses on questions for which the correct answer is not stated in the context.\nExisting datasets either focus exclusively on answerable questions, or use\nautomatically generated unanswerable questions that are easy to identify. To\naddress these weaknesses, we present SQuAD 2.0, the latest version of the\nStanford Question Answering Dataset (SQuAD). SQuAD 2.0 combines existing SQuAD\ndata with over 50,000 unanswerable questions written adversarially by\ncrowdworkers to look similar to answerable ones. To do well on SQuAD 2.0,\nsystems must not only answer questions when possible, but also determine when\nno answer is supported by the paragraph and abstain from answering. SQuAD 2.0\nis a challenging natural language understanding task for existing models: a\nstrong neural system that gets 86% F1 on SQuAD 1.1 achieves only 66% F1 on\nSQuAD 2.0.", "published": "2018-06-11 06:10:11", "link": "http://arxiv.org/abs/1806.03822v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Distance-Free Modeling of Multi-Predicate Interactions in End-to-End\n  Japanese Predicate-Argument Structure Analysis", "abstract": "Capturing interactions among multiple predicate-argument structures (PASs) is\na crucial issue in the task of analyzing PAS in Japanese. In this paper, we\npropose new Japanese PAS analysis models that integrate the label prediction\ninformation of arguments in multiple PASs by extending the input and last\nlayers of a standard deep bidirectional recurrent neural network (bi-RNN)\nmodel. In these models, using the mechanisms of pooling and attention, we aim\nto directly capture the potential interactions among multiple PASs, without\nbeing disturbed by the word order and distance. Our experiments show that the\nproposed models improve the prediction accuracy specifically for cases where\nthe predicate and argument are in an indirect dependency relation and achieve a\nnew state of the art in the overall $F_1$ on a standard benchmark corpus.", "published": "2018-06-11 09:18:52", "link": "http://arxiv.org/abs/1806.03869v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Co-Matching Model for Multi-choice Reading Comprehension", "abstract": "Multi-choice reading comprehension is a challenging task, which involves the\nmatching between a passage and a question-answer pair. This paper proposes a\nnew co-matching approach to this problem, which jointly models whether a\npassage can match both a question and a candidate answer. Experimental results\non the RACE dataset demonstrate that our approach achieves state-of-the-art\nperformance.", "published": "2018-06-11 15:50:13", "link": "http://arxiv.org/abs/1806.04068v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WikiRef: Wikilinks as a route to recommending appropriate references for\n  scientific Wikipedia pages", "abstract": "The exponential increase in the usage of Wikipedia as a key source of\nscientific knowledge among the researchers is making it absolutely necessary to\nmetamorphose this knowledge repository into an integral and self-contained\nsource of information for direct utilization. Unfortunately, the references\nwhich support the content of each Wikipedia entity page, are far from complete.\nWhy are the reference section ill-formed for most Wikipedia pages? Is this\nsection edited as frequently as the other sections of a page? Can there be\nappropriate surrogates that can automatically enhance the reference section? In\nthis paper, we propose a novel two step approach -- WikiRef -- that (i)\nleverages the wikilinks present in a scientific Wikipedia target page and,\nthereby, (ii) recommends highly relevant references to be included in that\ntarget page appropriately and automatically borrowed from the reference section\nof the wikilinks. In the first step, we build a classifier to ascertain whether\na wikilink is a potential source of reference or not. In the following step, we\nrecommend references to the target page from the reference section of the\nwikilinks that are classified as potential sources of references in the first\nstep. We perform an extensive evaluation of our approach on datasets from two\ndifferent domains -- Computer Science and Physics. For Computer Science we\nachieve a notably good performance with a precision@1 of 0.44 for reference\nrecommendation as opposed to 0.38 obtained from the most competitive baseline.\nFor the Physics dataset, we obtain a similar performance boost of 10% with\nrespect to the most competitive baseline.", "published": "2018-06-11 16:26:56", "link": "http://arxiv.org/abs/1806.04092v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Finding Syntax in Human Encephalography with Beam Search", "abstract": "Recurrent neural network grammars (RNNGs) are generative models of\n(tree,string) pairs that rely on neural networks to evaluate derivational\nchoices. Parsing with them using beam search yields a variety of incremental\ncomplexity metrics such as word surprisal and parser action count. When used as\nregressors against human electrophysiological responses to naturalistic text,\nthey derive two amplitude effects: an early peak and a P600-like later peak. By\ncontrast, a non-syntactic neural language model yields no reliable effects.\nModel comparisons attribute the early peak to syntactic composition within the\nRNNG. This pattern of results recommends the RNNG+beam search combination as a\nmechanistic model of the syntactic processing that occurs during normal human\nlanguage comprehension.", "published": "2018-06-11 17:51:23", "link": "http://arxiv.org/abs/1806.04127v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Corpus with Multi-Level Annotations of Patients, Interventions and\n  Outcomes to Support Language Processing for Medical Literature", "abstract": "We present a corpus of 5,000 richly annotated abstracts of medical articles\ndescribing clinical randomized controlled trials. Annotations include\ndemarcations of text spans that describe the Patient population enrolled, the\nInterventions studied and to what they were Compared, and the Outcomes measured\n(the `PICO' elements). These spans are further annotated at a more granular\nlevel, e.g., individual interventions within them are marked and mapped onto a\nstructured medical vocabulary. We acquired annotations from a diverse set of\nworkers with varying levels of expertise and cost. We describe our data\ncollection process and the corpus itself in detail. We then outline a set of\nchallenging NLP tasks that would aid searching of the medical literature and\nthe practice of evidence-based medicine.", "published": "2018-06-11 18:52:01", "link": "http://arxiv.org/abs/1806.04185v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Degree based Classification of Harmful Speech using Twitter Data", "abstract": "Harmful speech has various forms and it has been plaguing the social media in\ndifferent ways. If we need to crackdown different degrees of hate speech and\nabusive behavior amongst it, the classification needs to be based on complex\nramifications which needs to be defined and hold accountable for, other than\nracist, sexist or against some particular group and community. This paper\nprimarily describes how we created an ontological classification of harmful\nspeech based on degree of hateful intent, and used it to annotate twitter data\naccordingly. The key contribution of this paper is the new dataset of tweets we\ncreated based on ontological classes and degrees of harmful speech found in the\ntext. We also propose supervised classification system for recognizing these\nrespective harmful speech classes in the texts hence.", "published": "2018-06-11 19:07:40", "link": "http://arxiv.org/abs/1806.04197v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Let's do it \"again\": A First Computational Approach to Detecting\n  Adverbial Presupposition Triggers", "abstract": "We introduce the task of predicting adverbial presupposition triggers such as\nalso and again. Solving such a task requires detecting recurring or similar\nevents in the discourse context, and has applications in natural language\ngeneration tasks such as summarization and dialogue systems. We create two new\ndatasets for the task, derived from the Penn Treebank and the Annotated English\nGigaword corpora, as well as a novel attention mechanism tailored to this task.\nOur attention mechanism augments a baseline recurrent neural network without\nthe need for additional trainable parameters, minimizing the added\ncomputational cost of our mechanism. We demonstrate that our model\nstatistically outperforms a number of baselines, including an LSTM-based\nlanguage model.", "published": "2018-06-11 22:44:38", "link": "http://arxiv.org/abs/1806.04262v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Multilingual Topics from Incomparable Corpus", "abstract": "Multilingual topic models enable crosslingual tasks by extracting consistent\ntopics from multilingual corpora. Most models require parallel or comparable\ntraining corpora, which limits their ability to generalize. In this paper, we\nfirst demystify the knowledge transfer mechanism behind multilingual topic\nmodels by defining an alternative but equivalent formulation. Based on this\nanalysis, we then relax the assumption of training data required by most\nexisting models, creating a model that only requires a dictionary for training.\nExperiments show that our new method effectively learns coherent multilingual\ntopics from partially and fully incomparable corpora with limited amounts of\ndictionary resources.", "published": "2018-06-11 23:51:18", "link": "http://arxiv.org/abs/1806.04270v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Multimodal Classifier Generative Adversarial Network for Carry and\n  Place Tasks from Ambiguous Language Instructions", "abstract": "This paper focuses on a multimodal language understanding method for\ncarry-and-place tasks with domestic service robots. We address the case of\nambiguous instructions, that is, when the target area is not specified. For\ninstance \"put away the milk and cereal\" is a natural instruction where there is\nambiguity regarding the target area, considering environments in daily life.\nConventionally, this instruction can be disambiguated from a dialogue system,\nbut at the cost of time and cumbersome interaction. Instead, we propose a\nmultimodal approach, in which the instructions are disambiguated using the\nrobot's state and environment context. We develop the Multi-Modal Classifier\nGenerative Adversarial Network (MMC-GAN) to predict the likelihood of different\ntarget areas considering the robot's physical limitation and the target\nclutter. Our approach, MMC-GAN, significantly improves accuracy compared with\nbaseline methods that use instructions only or simple deep neural networks.", "published": "2018-06-11 07:52:28", "link": "http://arxiv.org/abs/1806.03847v1", "categories": ["cs.RO", "cs.CL"], "primary_category": "cs.RO"}
{"title": "Prosody Modifications for Question-Answering in Voice-Only Settings", "abstract": "Many popular form factors of digital assistants---such as Amazon Echo, Apple\nHomepod, or Google Home---enable the user to hold a conversation with these\nsystems based only on the speech modality. The lack of a screen presents unique\nchallenges. To satisfy the information need of a user, the presentation of the\nanswer needs to be optimized for such voice-only interactions. In this paper,\nwe propose a task of evaluating the usefulness of audio transformations (i.e.,\nprosodic modifications) for voice-only question answering. We introduce a\ncrowdsourcing setup where we evaluate the quality of our proposed modifications\nalong multiple dimensions corresponding to the informativeness, naturalness,\nand ability of the user to identify key parts of the answer. We offer a set of\nprosodic modifications that highlight potentially important parts of the answer\nusing various acoustic cues. Our experiments show that some of these prosodic\nmodifications lead to better comprehension at the expense of only slightly\ndegraded naturalness of the audio.", "published": "2018-06-11 13:25:23", "link": "http://arxiv.org/abs/1806.03957v4", "categories": ["cs.CL", "cs.HC", "H.3.3; H.5.2"], "primary_category": "cs.CL"}
{"title": "Navigating with Graph Representations for Fast and Scalable Decoding of\n  Neural Language Models", "abstract": "Neural language models (NLMs) have recently gained a renewed interest by\nachieving state-of-the-art performance across many natural language processing\n(NLP) tasks. However, NLMs are very computationally demanding largely due to\nthe computational cost of the softmax layer over a large vocabulary. We observe\nthat, in decoding of many NLP tasks, only the probabilities of the top-K\nhypotheses need to be calculated preciously and K is often much smaller than\nthe vocabulary size. This paper proposes a novel softmax layer approximation\nalgorithm, called Fast Graph Decoder (FGD), which quickly identifies, for a\ngiven context, a set of K words that are most likely to occur according to a\nNLM. We demonstrate that FGD reduces the decoding time by an order of magnitude\nwhile attaining close to the full softmax baseline accuracy on neural machine\ntranslation and language modeling tasks. We also prove the theoretical\nguarantee on the softmax approximation quality.", "published": "2018-06-11 18:57:49", "link": "http://arxiv.org/abs/1806.04189v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Automatic Target Recovery for Hindi-English Code Mixed Puns", "abstract": "In order for our computer systems to be more human-like, with a higher\nemotional quotient, they need to be able to process and understand intrinsic\nhuman language phenomena like humour. In this paper, we consider a subtype of\nhumour - puns, which are a common type of wordplay-based jokes. In particular,\nwe consider code-mixed puns which have become increasingly mainstream on social\nmedia, in informal conversations and advertisements and aim to build a system\nwhich can automatically identify the pun location and recover the target of\nsuch puns. We first study and classify code-mixed puns into two categories\nnamely intra-sentential and intra-word, and then propose a four-step algorithm\nto recover the pun targets for puns belonging to the intra-sentential category.\nOur algorithm uses language models, and phonetic similarity-based features to\nget the desired results. We test our approach on a small set of code-mixed\npunning advertisements, and observe that our system is successfully able to\nrecover the targets for 67% of the puns.", "published": "2018-06-11 09:45:34", "link": "http://arxiv.org/abs/1806.04535v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Interactive Visual Grounding of Referring Expressions for Human-Robot\n  Interaction", "abstract": "This paper presents INGRESS, a robot system that follows human natural\nlanguage instructions to pick and place everyday objects. The core issue here\nis the grounding of referring expressions: infer objects and their\nrelationships from input images and language expressions. INGRESS allows for\nunconstrained object categories and unconstrained language expressions.\nFurther, it asks questions to disambiguate referring expressions interactively.\nTo achieve these, we take the approach of grounding by generation and propose a\ntwo-stage neural network model for grounding. The first stage uses a neural\nnetwork to generate visual descriptions of objects, compares them with the\ninput language expression, and identifies a set of candidate objects. The\nsecond stage uses another neural network to examine all pairwise relations\nbetween the candidates and infers the most likely referred object. The same\nneural networks are used for both grounding and question generation for\ndisambiguation. Experiments show that INGRESS outperformed a state-of-the-art\nmethod on the RefCOCO dataset and in robot experiments with humans.", "published": "2018-06-11 06:58:19", "link": "http://arxiv.org/abs/1806.03831v1", "categories": ["cs.RO", "cs.CL", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Straight to the Tree: Constituency Parsing with Neural Syntactic\n  Distance", "abstract": "In this work, we propose a novel constituency parsing scheme. The model\npredicts a vector of real-valued scalars, named syntactic distances, for each\nsplit position in the input sentence. The syntactic distances specify the order\nin which the split points will be selected, recursively partitioning the input,\nin a top-down fashion. Compared to traditional shift-reduce parsing schemes,\nour approach is free from the potential problem of compounding errors, while\nbeing faster and easier to parallelize. Our model achieves competitive\nperformance amongst single model, discriminative parsers in the PTB dataset and\noutperforms previous models in the CTB dataset.", "published": "2018-06-11 18:18:00", "link": "http://arxiv.org/abs/1806.04168v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Autoencoders for music sound modeling: a comparison of linear, shallow,\n  deep, recurrent and variational models", "abstract": "This study investigates the use of non-linear unsupervised dimensionality\nreduction techniques to compress a music dataset into a low-dimensional\nrepresentation which can be used in turn for the synthesis of new sounds. We\nsystematically compare (shallow) autoencoders (AEs), deep autoencoders (DAEs),\nrecurrent autoencoders (with Long Short-Term Memory cells -- LSTM-AEs) and\nvariational autoencoders (VAEs) with principal component analysis (PCA) for\nrepresenting the high-resolution short-term magnitude spectrum of a large and\ndense dataset of music notes into a lower-dimensional vector (and then convert\nit back to a magnitude spectrum used for sound resynthesis). Our experiments\nwere conducted on the publicly available multi-instrument and multi-pitch\ndatabase NSynth. Interestingly and contrary to the recent literature on image\nprocessing, we can show that PCA systematically outperforms shallow AE. Only\ndeep and recurrent architectures (DAEs and LSTM-AEs) lead to a lower\nreconstruction error. The optimization criterion in VAEs being the sum of the\nreconstruction error and a regularization term, it naturally leads to a lower\nreconstruction accuracy than DAEs but we show that VAEs are still able to\noutperform PCA while providing a low-dimensional latent space with nice\n\"usability\" properties. We also provide corresponding objective measures of\nperceptual audio quality (PEMO-Q scores), which generally correlate well with\nthe reconstruction error.", "published": "2018-06-11 16:39:16", "link": "http://arxiv.org/abs/1806.04096v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
