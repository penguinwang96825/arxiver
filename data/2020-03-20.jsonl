{"title": "TNT-KID: Transformer-based Neural Tagger for Keyword Identification", "abstract": "With growing amounts of available textual data, development of algorithms\ncapable of automatic analysis, categorization and summarization of these data\nhas become a necessity. In this research we present a novel algorithm for\nkeyword identification, i.e., an extraction of one or multi-word phrases\nrepresenting key aspects of a given document, called Transformer-based Neural\nTagger for Keyword IDentification (TNT-KID). By adapting the transformer\narchitecture for a specific task at hand and leveraging language model\npretraining on a domain specific corpus, the model is capable of overcoming\ndeficiencies of both supervised and unsupervised state-of-the-art approaches to\nkeyword extraction by offering competitive and robust performance on a variety\nof different datasets while requiring only a fraction of manually labeled data\nrequired by the best performing systems. This study also offers thorough error\nanalysis with valuable insights into the inner workings of the model and an\nablation study measuring the influence of specific components of the keyword\nidentification workflow on the overall performance.", "published": "2020-03-20 09:55:10", "link": "http://arxiv.org/abs/2003.09166v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language Technology Programme for Icelandic 2019-2023", "abstract": "In this paper, we describe a new national language technology programme for\nIcelandic. The programme, which spans a period of five years, aims at making\nIcelandic usable in communication and interactions in the digital world, by\ndeveloping accessible, open-source language resources and software. The\nresearch and development work within the programme is carried out by a\nconsortium of universities, institutions, and private companies, with a strong\nemphasis on cooperation between academia and industries. Five core projects\nwill be the main content of the programme: language resources, speech\nrecognition, speech synthesis, machine translation, and spell and grammar\nchecking. We also describe other national language technology programmes and\ngive an overview over the history of language technology in Iceland.", "published": "2020-03-20 12:54:43", "link": "http://arxiv.org/abs/2003.09244v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FedNER: Privacy-preserving Medical Named Entity Recognition with\n  Federated Learning", "abstract": "Medical named entity recognition (NER) has wide applications in intelligent\nhealthcare. Sufficient labeled data is critical for training accurate medical\nNER model. However, the labeled data in a single medical platform is usually\nlimited. Although labeled datasets may exist in many different medical\nplatforms, they cannot be directly shared since medical data is highly\nprivacy-sensitive. In this paper, we propose a privacy-preserving medical NER\nmethod based on federated learning, which can leverage the labeled data in\ndifferent platforms to boost the training of medical NER model and remove the\nneed of exchanging raw data among different platforms. Since the labeled data\nin different platforms usually has some differences in entity type and\nannotation criteria, instead of constraining different platforms to share the\nsame model, we decompose the medical NER model in each platform into a shared\nmodule and a private module. The private module is used to capture the\ncharacteristics of the local data in each platform, and is updated using local\nlabeled data. The shared module is learned across different medical platform to\ncapture the shared NER knowledge. Its local gradients from different platforms\nare aggregated to update the global shared module, which is further delivered\nto each platform to update their local shared modules. Experiments on three\npublicly available datasets validate the effectiveness of our method.", "published": "2020-03-20 14:17:16", "link": "http://arxiv.org/abs/2003.09288v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detecting Mismatch between Text Script and Voice-over Using Utterance\n  Verification Based on Phoneme Recognition Ranking", "abstract": "The purpose of this study is to detect the mismatch between text script and\nvoice-over. For this, we present a novel utterance verification (UV) method,\nwhich calculates the degree of correspondence between a voice-over and the\nphoneme sequence of a script. We found that the phoneme recognition\nprobabilities of exaggerated voice-overs decrease compared to ordinary\nutterances, but their rankings do not demonstrate any significant change. The\nproposed method, therefore, uses the recognition ranking of each phoneme\nsegment corresponding to a phoneme sequence for measuring the confidence of a\nvoice-over utterance for its corresponding script. The experimental results\nshow that the proposed UV method outperforms a state-of-the-art approach using\ncross modal attention used for detecting mismatch between speech and\ntranscription.", "published": "2020-03-20 10:35:35", "link": "http://arxiv.org/abs/2003.09180v1", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "TArC: Incrementally and Semi-Automatically Collecting a Tunisian Arabish\n  Corpus", "abstract": "This article describes the constitution process of the first\nmorpho-syntactically annotated Tunisian Arabish Corpus (TArC). Arabish, also\nknown as Arabizi, is a spontaneous coding of Arabic dialects in Latin\ncharacters and arithmographs (numbers used as letters). This code-system was\ndeveloped by Arabic-speaking users of social media in order to facilitate the\nwriting in the Computer-Mediated Communication (CMC) and text messaging\ninformal frameworks. There is variety in the realization of Arabish amongst\ndialects, and each Arabish code-system is under-resourced, in the same way as\nmost of the Arabic dialects. In the last few years, the focus on Arabic\ndialects in the NLP field has considerably increased. Taking this into\nconsideration, TArC will be a useful support for different types of analyses,\ncomputational and linguistic, as well as for NLP tools training. In this\narticle we will describe preliminary work on the TArC semi-automatic\nconstruction process and some of the first analyses we developed on TArC. In\naddition, in order to provide a complete overview of the challenges faced\nduring the building process, we will present the main Tunisian dialect\ncharacteristics and their encoding in Tunisian Arabish.", "published": "2020-03-20 22:29:42", "link": "http://arxiv.org/abs/2003.09520v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Framework for Generating Explanations from Temporal Personal Health\n  Data", "abstract": "Whereas it has become easier for individuals to track their personal health\ndata (e.g., heart rate, step count, food log), there is still a wide chasm\nbetween the collection of data and the generation of meaningful explanations to\nhelp users better understand what their data means to them. With an increased\ncomprehension of their data, users will be able to act upon the newfound\ninformation and work towards striving closer to their health goals. We aim to\nbridge the gap between data collection and explanation generation by mining the\ndata for interesting behavioral findings that may provide hints about a user's\ntendencies. Our focus is on improving the explainability of temporal personal\nhealth data via a set of informative summary templates, or \"protoforms.\" These\nprotoforms span both evaluation-based summaries that help users evaluate their\nhealth goals and pattern-based summaries that explain their implicit behaviors.\nIn addition to individual users, the protoforms we use are also designed for\npopulation-level summaries. We apply our approach to generate summaries (both\nunivariate and multivariate) from real user data and show that our system can\ngenerate interesting and useful explanations.", "published": "2020-03-20 23:32:08", "link": "http://arxiv.org/abs/2003.09530v2", "categories": ["cs.CL", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Automatic Identification of Types of Alterations in Historical\n  Manuscripts", "abstract": "Alterations in historical manuscripts such as letters represent a promising\nfield of research. On the one hand, they help understand the construction of\ntext. On the other hand, topics that are being considered sensitive at the time\nof the manuscript gain coherence and contextuality when taking alterations into\naccount, especially in the case of deletions. The analysis of alterations in\nmanuscripts, though, is a traditionally very tedious work. In this paper, we\npresent a machine learning-based approach to help categorize alterations in\ndocuments. In particular, we present a new probabilistic model (Alteration\nLatent Dirichlet Allocation, alterLDA in the following) that categorizes\ncontent-related alterations. The method proposed here is developed based on\nexperiments carried out on the digital scholarly edition Berlin Intellectuals,\nfor which alterLDA achieves high performance in the recognition of alterations\non labelled data. On unlabelled data, applying alterLDA leads to interesting\nnew insights into the alteration behavior of authors, editors and other\nmanuscript contributors, as well as insights into sensitive topics in the\ncorrespondence of Berlin intellectuals around 1800. In addition to the findings\nbased on the digital scholarly edition Berlin Intellectuals, we present a\ngeneral framework for the analysis of text genesis that can be used in the\ncontext of other digital resources representing document variants. To that end,\nwe present in detail the methodological steps that are to be followed in order\nto achieve such results, giving thereby a prime example of an Machine Learning\napplication the Digital Humanities.", "published": "2020-03-20 08:05:27", "link": "http://arxiv.org/abs/2003.09136v3", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Parallel Intent and Slot Prediction using MLB Fusion", "abstract": "Intent and Slot Identification are two important tasks in Spoken Language\nUnderstanding (SLU). For a natural language utterance, there is a high\ncorrelation between these two tasks. A lot of work has been done on each of\nthese using Recurrent-Neural-Networks (RNN), Convolution Neural Networks (CNN)\nand Attention based models. Most of the past work used two separate models for\nintent and slot prediction. Some of them also used sequence-to-sequence type\nmodels where slots are predicted after evaluating the utterance-level intent.\nIn this work, we propose a parallel Intent and Slot Prediction technique where\nseparate Bidirectional Gated Recurrent Units (GRU) are used for each task. We\nposit the usage of MLB (Multimodal Low-rank Bilinear Attention Network) fusion\nfor improvement in performance of intent and slot learning. To the best of our\nknowledge, this is the first attempt of using such a technique on text based\nproblems. Also, our proposed methods outperform the existing state-of-the-art\nresults for both intent and slot prediction on two benchmark datasets", "published": "2020-03-20 11:48:16", "link": "http://arxiv.org/abs/2003.09211v1", "categories": ["cs.CL", "cs.AI", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Acoustic Scene Classification using Audio Tagging", "abstract": "Acoustic scene classification systems using deep neural networks classify\ngiven recordings into pre-defined classes. In this study, we propose a novel\nscheme for acoustic scene classification which adopts an audio tagging system\ninspired by the human perception mechanism. When humans identify an acoustic\nscene, the existence of different sound events provides discriminative\ninformation which affects the judgement. The proposed framework mimics this\nmechanism using various approaches. Firstly, we employ three methods to\nconcatenate tag vectors extracted using an audio tagging system with an\nintermediate hidden layer of an acoustic scene classification system. We also\nexplore the multi-head attention on the feature map of an acoustic scene\nclassification system using tag vectors. Experiments conducted on the detection\nand classification of acoustic scenes and events 2019 task 1-a dataset\ndemonstrate the effectiveness of the proposed scheme. Concatenation and\nmulti-head attention show a classification accuracy of 75.66 % and 75.58 %,\nrespectively, compared to 73.63 % accuracy of the baseline. The system with the\nproposed two approaches combined demonstrates an accuracy of 76.75 %.", "published": "2020-03-20 09:53:02", "link": "http://arxiv.org/abs/2003.09164v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Improving Embedding Extraction for Speaker Verification with Ladder\n  Network", "abstract": "Speaker verification is an established yet challenging task in speech\nprocessing and a very vibrant research area. Recent speaker verification (SV)\nsystems rely on deep neural networks to extract high-level embeddings which are\nable to characterize the users' voices. Most of the studies have investigated\non improving the discriminability of the networks to extract better embeddings\nfor performances improvement. However, only few research focus on improving the\ngeneralization. In this paper, we propose to apply the ladder network framework\nin the SV systems, which combines the supervised and unsupervised learning\nfashions. The ladder network can make the system to have better high-level\nembedding by balancing the trade-off to keep/discard as much useful/useless\ninformation as possible. We evaluated the framework on two state-of-the-art SV\nsystems, d-vector and x-vector, which can be used for different use cases. The\nexperiments showed that the proposed approach relatively improved the\nperformance by 10% at most without adding parameters and augmented data.", "published": "2020-03-20 07:08:38", "link": "http://arxiv.org/abs/2003.09125v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Acoustic Scene Classification with Squeeze-Excitation Residual Networks", "abstract": "Acoustic scene classification (ASC) is a problem related to the field of\nmachine listening whose objective is to classify/tag an audio clip in a\npredefined label describing a scene location (e. g. park, airport, etc.). Many\nstate-of-the-art solutions to ASC incorporate data augmentation techniques and\nmodel ensembles. However, considerable improvements can also be achieved only\nby modifying the architecture of convolutional neural networks (CNNs). In this\nwork we propose two novel squeeze-excitation blocks to improve the accuracy of\na CNN-based ASC framework based on residual learning. The main idea of\nsqueeze-excitation blocks is to learn spatial and channel-wise feature maps\nindependently instead of jointly as standard CNNs do. This is usually achieved\nby some global grouping operators, linear operators and a final calibration\nbetween the input of the block and its obtained relationships. The behavior of\nthe block that implements such operators and, therefore, the entire neural\nnetwork, can be modified depending on the input to the block, the established\nresidual configurations and the selected non-linear activations. The analysis\nhas been carried out using the TAU Urban Acoustic Scenes 2019 dataset\n(https://zenodo.org/record/2589280) presented in the 2019 edition of the DCASE\nchallenge. All configurations discussed in this document exceed the performance\nof the baseline proposed by the DCASE organization by 13\\% percentage points.\nIn turn, the novel configurations proposed in this paper outperform the\nresidual configurations proposed in previous works.", "published": "2020-03-20 14:07:11", "link": "http://arxiv.org/abs/2003.09284v3", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Exploring Inherent Properties of the Monophonic Melody of Songs", "abstract": "Melody is one of the most important components in music. Unlike other\ncomponents in music theory, such as harmony and counterpoint, computable\nfeatures for melody is urgently in need. These features are highly demanded as\ndata-driven methods dominating the fields such as musical information retrieval\nand automatic music composition. To boost the performance of\ndeep-learning-related musical tasks, we propose a set of interpretable features\non monophonic melody for computational purposes. These features are defined not\nonly in mathematical form, but also with some considerations on composers\n'intuition. For example, the Melodic Center of Gravity can reflect the\nsentence-wise contour of the melody, the local / global melody dynamics\nquantifies the dynamics of a melody that couples pitch and time in a sentence.\nWe found that these features are considered by people universally in many\ngenres of songs, even for atonal composition practices. Hopefully, these\nmelodic features can provide nov el inspiration for future researchers as a\ntool in the field of MIR and automatic composition.", "published": "2020-03-20 14:13:16", "link": "http://arxiv.org/abs/2003.09287v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
