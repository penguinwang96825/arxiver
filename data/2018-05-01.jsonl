{"title": "Dynamic Sentence Sampling for Efficient Training of Neural Machine\n  Translation", "abstract": "Traditional Neural machine translation (NMT) involves a fixed training\nprocedure where each sentence is sampled once during each epoch. In reality,\nsome sentences are well-learned during the initial few epochs; however, using\nthis approach, the well-learned sentences would continue to be trained along\nwith those sentences that were not well learned for 10-30 epochs, which results\nin a wastage of time. Here, we propose an efficient method to dynamically\nsample the sentences in order to accelerate the NMT training. In this approach,\na weight is assigned to each sentence based on the measured difference between\nthe training costs of two iterations. Further, in each epoch, a certain\npercentage of sentences are dynamically sampled according to their weights.\nEmpirical results based on the NIST Chinese-to-English and the WMT\nEnglish-to-German tasks depict that the proposed method can significantly\naccelerate the NMT training and improve the NMT performance.", "published": "2018-05-01 04:09:09", "link": "http://arxiv.org/abs/1805.00178v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Nugget Proposal Networks for Chinese Event Detection", "abstract": "Neural network based models commonly regard event detection as a word-wise\nclassification task, which suffer from the mismatch problem between words and\nevent triggers, especially in languages without natural word delimiters such as\nChinese. In this paper, we propose Nugget Proposal Networks (NPNs), which can\nsolve the word-trigger mismatch problem by directly proposing entire trigger\nnuggets centered at each character regardless of word boundaries. Specifically,\nNPNs perform event detection in a character-wise paradigm, where a hybrid\nrepresentation for each character is first learned to capture both structural\nand semantic information from both characters and words. Then based on learned\nrepresentations, trigger nuggets are proposed and categorized by exploiting\ncharacter compositional structures of Chinese event triggers. Experiments on\nboth ACE2005 and TAC KBP 2017 datasets show that NPNs significantly outperform\nthe state-of-the-art methods.", "published": "2018-05-01 09:16:53", "link": "http://arxiv.org/abs/1805.00249v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Capturing Ambiguity in Crowdsourcing Frame Disambiguation", "abstract": "FrameNet is a computational linguistics resource composed of semantic frames,\nhigh-level concepts that represent the meanings of words. In this paper, we\npresent an approach to gather frame disambiguation annotations in sentences\nusing a crowdsourcing approach with multiple workers per sentence to capture\ninter-annotator disagreement. We perform an experiment over a set of 433\nsentences annotated with frames from the FrameNet corpus, and show that the\naggregated crowd annotations achieve an F1 score greater than 0.67 as compared\nto expert linguists. We highlight cases where the crowd annotation was correct\neven though the expert is in disagreement, arguing for the need to have\nmultiple annotators per sentence. Most importantly, we examine cases in which\ncrowd workers could not agree, and demonstrate that these cases exhibit\nambiguity, either in the sentence, frame, or the task itself, and argue that\ncollapsing such cases to a single, discrete truth value (i.e. correct or\nincorrect) is inappropriate, creating arbitrary targets for machine learning.", "published": "2018-05-01 11:08:00", "link": "http://arxiv.org/abs/1805.00270v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multitask Parsing Across Semantic Representations", "abstract": "The ability to consolidate information of different types is at the core of\nintelligence, and has tremendous practical value in allowing learning for one\ntask to benefit from generalizations learned for others. In this paper we\ntackle the challenging task of improving semantic parsing performance, taking\nUCCA parsing as a test case, and AMR, SDP and Universal Dependencies (UD)\nparsing as auxiliary tasks. We experiment on three languages, using a uniform\ntransition-based system and learning architecture for all parsing tasks.\nDespite notable conceptual, formal and domain differences, we show that\nmultitask learning significantly improves UCCA parsing in both in-domain and\nout-of-domain settings.", "published": "2018-05-01 12:21:50", "link": "http://arxiv.org/abs/1805.00287v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-representation Ensembles and Delayed SGD Updates Improve\n  Syntax-based NMT", "abstract": "We explore strategies for incorporating target syntax into Neural Machine\nTranslation. We specifically focus on syntax in ensembles containing multiple\nsentence representations. We formulate beam search over such ensembles using\nWFSTs, and describe a delayed SGD update training procedure that is especially\neffective for long representations like linearized syntax. Our approach gives\nstate-of-the-art performance on a difficult Japanese-English task.", "published": "2018-05-01 17:48:10", "link": "http://arxiv.org/abs/1805.00456v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "\"I ain't tellin' white folks nuthin\": A quantitative exploration of the\n  race-related problem of candour in the WPA slave narratives", "abstract": "From 1936-38, the Works Progress Administration interviewed thousands of\nformer slaves about their life experiences. While these interviews are crucial\nto understanding the \"peculiar institution\" from the standpoint of the slave\nhimself, issues relating to bias cloud analyses of these interviews. The\nproblem I investigate is the problem of candour in the WPA slave narratives: it\nis widely held in the historical community that the strict racial caste system\nof the Deep South compelled black ex-slaves to tell white interviewers what\nthey thought they wanted to hear, suggesting that there was a significant\ndifference candour depending on whether their interviewer was white or black.\nIn this work, I attempt to quantitatively characterise this race-related\nproblem of candour. Prior work has either been of an impressionistic,\nqualitative nature, or utilised exceedingly simple quantitative methodology. In\ncontrast, I use more sophisticated statistical methods: in particular word\nfrequency and sentiment analysis and comparative topic modelling with LDA to\ntry and identify differences in the content and sentiment expressed by\nex-slaves in front of white interviewers versus black interviewers. While my\nsentiment analysis methodology was ultimately unsuccessful due to the\ncomplexity of the task, my word frequency analysis and comparative topic\nmodelling methods both showed strong evidence that the content expressed in\nfront of white interviewers was different from that of black interviewers. In\nparticular, I found that the ex-slaves spoke much more about unfavourable\naspects of slavery like whipping and slave patrollers in front of interviewers\nof their own race. I hope that my more-sophisticated statistical methodology\nhelps improve the robustness of the argument for the existence of this problem\nof candour in the slave narratives, which some would seek to deny for\nrevisionist purposes.", "published": "2018-05-01 05:24:40", "link": "http://arxiv.org/abs/1805.00471v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Conversational Language Generation for Rich Content about\n  Hotels", "abstract": "Dialogue systems for hotel and tourist information have typically simplified\nthe richness of the domain, focusing system utterances on only a few selected\nattributes such as price, location and type of rooms. However, much more\ncontent is typically available for hotels, often as many as 50 distinct\ninstantiated attributes for an individual entity. New methods are needed to use\nthis content to generate natural dialogues for hotel information, and in\ngeneral for any domain with such rich complex content. We describe three\nexperiments aimed at collecting data that can inform an NLG for hotels\ndialogues, and show, not surprisingly, that the sentences in the original\nwritten hotel descriptions provided on webpages for each hotel are\nstylistically not a very good match for conversational interaction. We quantify\nthe stylistic features that characterize the differences between the original\ntextual data and the collected dialogic data. We plan to use these in stylistic\nmodels for generation, and for scoring retrieved utterances for use in hotel\ndialogues", "published": "2018-05-01 21:05:34", "link": "http://arxiv.org/abs/1805.00551v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Response Ranking with Deep Matching Networks and External Knowledge in\n  Information-seeking Conversation Systems", "abstract": "Intelligent personal assistant systems with either text-based or voice-based\nconversational interfaces are becoming increasingly popular around the world.\nRetrieval-based conversation models have the advantages of returning fluent and\ninformative responses. Most existing studies in this area are on open domain\n\"chit-chat\" conversations or task / transaction oriented conversations. More\nresearch is needed for information-seeking conversations. There is also a lack\nof modeling external knowledge beyond the dialog utterances among current\nconversational models. In this paper, we propose a learning framework on the\ntop of deep neural matching networks that leverages external knowledge for\nresponse ranking in information-seeking conversation systems. We incorporate\nexternal knowledge into deep neural models with pseudo-relevance feedback and\nQA correspondence knowledge distillation. Extensive experiments with three\ninformation-seeking conversation data sets including both open benchmarks and\ncommercial data show that, our methods outperform various baseline methods\nincluding several deep text matching models and the state-of-the-art method on\nresponse selection in multi-turn conversations. We also perform analysis over\ndifferent response types, model variations and ranking examples. Our models and\nresearch findings provide new insights on how to utilize external knowledge\nwith deep neural models for response selection and have implications for the\ndesign of the next generation of information-seeking conversation systems.", "published": "2018-05-01 05:05:05", "link": "http://arxiv.org/abs/1805.00188v3", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "An Annotated Corpus for Machine Reading of Instructions in Wet Lab\n  Protocols", "abstract": "We describe an effort to annotate a corpus of natural language instructions\nconsisting of 622 wet lab protocols to facilitate automatic or semi-automatic\nconversion of protocols into a machine-readable format and benefit biological\nresearch. Experimental results demonstrate the utility of our corpus for\ndeveloping machine learning approaches to shallow semantic parsing of\ninstructional texts. We make our annotated Wet Lab Protocol Corpus available to\nthe research community.", "published": "2018-05-01 05:52:12", "link": "http://arxiv.org/abs/1805.00195v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Adaptive Scaling for Sparse Detection in Information Extraction", "abstract": "This paper focuses on detection tasks in information extraction, where\npositive instances are sparsely distributed and models are usually evaluated\nusing F-measure on positive classes. These characteristics often result in\ndeficient performance of neural network based detection models. In this paper,\nwe propose adaptive scaling, an algorithm which can handle the positive\nsparsity problem and directly optimize over F-measure via dynamic\ncost-sensitive learning. To this end, we borrow the idea of marginal utility\nfrom economics and propose a theoretical framework for instance importance\nmeasuring without introducing any additional hyper-parameters. Experiments show\nthat our algorithm leads to a more effective and stable training of neural\nnetwork based detection models.", "published": "2018-05-01 09:21:34", "link": "http://arxiv.org/abs/1805.00250v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Word2Vec and Doc2Vec in Unsupervised Sentiment Analysis of Clinical\n  Discharge Summaries", "abstract": "In this study, we explored application of Word2Vec and Doc2Vec for sentiment\nanalysis of clinical discharge summaries. We applied unsupervised learning\nsince the data sets did not have sentiment annotations. Note that unsupervised\nlearning is a more realistic scenario than supervised learning which requires\nan access to a training set of sentiment-annotated data. We aim to detect if\nthere exists any underlying bias towards or against a certain disease. We used\nSentiWordNet to establish a gold sentiment standard for the data sets and\nevaluate performance of Word2Vec and Doc2Vec methods. We have shown that the\nWord2vec and Doc2Vec methods complement each other results in sentiment\nanalysis of the data sets.", "published": "2018-05-01 14:07:44", "link": "http://arxiv.org/abs/1805.00352v1", "categories": ["cs.CL", "cs.LG", "68T05, 68T50"], "primary_category": "cs.CL"}
{"title": "Memory-augmented Dialogue Management for Task-oriented Dialogue Systems", "abstract": "Dialogue management (DM) decides the next action of a dialogue system\naccording to the current dialogue state, and thus plays a central role in\ntask-oriented dialogue systems. Since dialogue management requires to have\naccess to not only local utterances, but also the global semantics of the\nentire dialogue session, modeling the long-range history information is a\ncritical issue. To this end, we propose a novel Memory-Augmented Dialogue\nmanagement model (MAD) which employs a memory controller and two additional\nmemory structures, i.e., a slot-value memory and an external memory. The\nslot-value memory tracks the dialogue state by memorizing and updating the\nvalues of semantic slots (for instance, cuisine, price, and location), and the\nexternal memory augments the representation of hidden states of traditional\nrecurrent neural networks through storing more context information. To update\nthe dialogue state efficiently, we also propose slot-level attention on user\nutterances to extract specific semantic information for each slot. Experiments\nshow that our model can obtain state-of-the-art performance and outperforms\nexisting baselines.", "published": "2018-05-01 02:14:00", "link": "http://arxiv.org/abs/1805.00150v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "68T50"], "primary_category": "cs.CL"}
{"title": "Joint Bootstrapping Machines for High Confidence Relation Extraction", "abstract": "Semi-supervised bootstrapping techniques for relationship extraction from\ntext iteratively expand a set of initial seed instances. Due to the lack of\nlabeled data, a key challenge in bootstrapping is semantic drift: if a false\npositive instance is added during an iteration, then all following iterations\nare contaminated. We introduce BREX, a new bootstrapping method that protects\nagainst such contamination by highly effective confidence assessment. This is\nachieved by using entity and template seeds jointly (as opposed to just one as\nin previous work), by expanding entities and templates in parallel and in a\nmutually constraining fashion in each iteration and by introducing\nhigherquality similarity measures for templates. Experimental results show that\nBREX achieves an F1 that is 0.13 (0.87 vs. 0.74) better than the state of the\nart for four relationships.", "published": "2018-05-01 09:39:19", "link": "http://arxiv.org/abs/1805.00254v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Randomly weighted CNNs for (music) audio classification", "abstract": "The computer vision literature shows that randomly weighted neural networks\nperform reasonably as feature extractors. Following this idea, we study how\nnon-trained (randomly weighted) convolutional neural networks perform as\nfeature extractors for (music) audio classification tasks. We use features\nextracted from the embeddings of deep architectures as input to a classifier -\nwith the goal to compare classification accuracies when using different\nrandomly weighted architectures. By following this methodology, we run a\ncomprehensive evaluation of the current deep architectures for audio\nclassification, and provide evidence that the architectures alone are an\nimportant piece for resolving (music) audio problems using deep neural\nnetworks.", "published": "2018-05-01 08:49:53", "link": "http://arxiv.org/abs/1805.00237v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Adversarial adaptive 1-D convolutional neural networks for bearing fault\n  diagnosis under varying working condition", "abstract": "Traditional intelligent fault diagnosis of rolling bearings work well only\nunder a common assumption that the labeled training data (source domain) and\nunlabeled testing data (target domain) are drawn from the same distribution.\nHowever, in many real-world applications, this assumption does not hold,\nespecially when the working condition varies. In this paper, a new adversarial\nadaptive 1-D CNN called A2CNN is proposed to address this problem. A2CNN\nconsists of four parts, namely, a source feature extractor, a target feature\nextractor, a label classifier and a domain discriminator. The layers between\nthe source and target feature extractor are partially untied during the\ntraining stage to take both training efficiency and domain adaptation into\nconsideration. Experiments show that A2CNN has strong fault-discriminative and\ndomain-invariant capacity, and therefore can achieve high accuracy under\ndifferent working conditions. We also visualize the learned features and the\nnetworks to explore the reasons behind the high performance of our proposed\nmodel.", "published": "2018-05-01 13:15:24", "link": "http://arxiv.org/abs/1805.00778v3", "categories": ["eess.SP", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "eess.SP"}
