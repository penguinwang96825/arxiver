{"title": "FinRobot: AI Agent for Equity Research and Valuation with Large Language Models", "abstract": "As financial markets grow increasingly complex, there is a rising need for\nautomated tools that can effectively assist human analysts in equity research,\nparticularly within sell-side research. While Generative AI (GenAI) has\nattracted significant attention in this field, existing AI solutions often fall\nshort due to their narrow focus on technical factors and limited capacity for\ndiscretionary judgment. These limitations hinder their ability to adapt to new\ndata in real-time and accurately assess risks, which diminishes their practical\nvalue for investors.\n  This paper presents FinRobot, the first AI agent framework specifically\ndesigned for equity research. FinRobot employs a multi-agent Chain of Thought\n(CoT) system, integrating both quantitative and qualitative analyses to emulate\nthe comprehensive reasoning of a human analyst. The system is structured around\nthree specialized agents: the Data-CoT Agent, which aggregates diverse data\nsources for robust financial integration; the Concept-CoT Agent, which mimics\nan analysts reasoning to generate actionable insights; and the Thesis-CoT\nAgent, which synthesizes these insights into a coherent investment thesis and\nreport. FinRobot provides thorough company analysis supported by precise\nnumerical data, industry-appropriate valuation metrics, and realistic risk\nassessments. Its dynamically updatable data pipeline ensures that research\nremains timely and relevant, adapting seamlessly to new financial information.\nUnlike existing automated research tools, such as CapitalCube and Wright\nReports, FinRobot delivers insights comparable to those produced by major\nbrokerage firms and fundamental research vendors. We open-source FinRobot at\n\\url{https://github. com/AI4Finance-Foundation/FinRobot}.", "published": "2024-11-13 17:38:07", "link": "http://arxiv.org/abs/2411.08804v1", "categories": ["q-fin.CP", "cs.LG", "q-fin.ST", "q-fin.TR"], "primary_category": "q-fin.CP"}
{"title": "Analyst Reports and Stock Performance: Evidence from the Chinese Market", "abstract": "This article applies natural language processing (NLP) to extract and\nquantify textual information to predict stock performance. Using an extensive\ndataset of Chinese analyst reports and employing a customized BERT deep\nlearning model for Chinese text, this study categorizes the sentiment of the\nreports as positive, neutral, or negative. The findings underscore the\npredictive capacity of this sentiment indicator for stock volatility, excess\nreturns, and trading volume. Specifically, analyst reports with strong positive\nsentiment will increase excess return and intraday volatility, and vice versa,\nreports with strong negative sentiment also increase volatility and trading\nvolume, but decrease future excess return. The magnitude of this effect is\ngreater for positive sentiment reports than for negative sentiment reports.\nThis article contributes to the empirical literature on sentiment analysis and\nthe response of the stock market to news in the Chinese stock market.", "published": "2024-11-13 16:08:40", "link": "http://arxiv.org/abs/2411.08726v2", "categories": ["cs.CL", "q-fin.CP"], "primary_category": "cs.CL"}
{"title": "Quantifying Qualitative Insights: Leveraging LLMs to Market Predict", "abstract": "Recent advancements in Large Language Models (LLMs) have the potential to\ntransform financial analytics by integrating numerical and textual data.\nHowever, challenges such as insufficient context when fusing multimodal\ninformation and the difficulty in measuring the utility of qualitative outputs,\nwhich LLMs generate as text, have limited their effectiveness in tasks such as\nfinancial forecasting. This study addresses these challenges by leveraging\ndaily reports from securities firms to create high-quality contextual\ninformation. The reports are segmented into text-based key factors and combined\nwith numerical data, such as price information, to form context sets. By\ndynamically updating few-shot examples based on the query time, the sets\nincorporate the latest information, forming a highly relevant set closely\naligned with the query point. Additionally, a crafted prompt is designed to\nassign scores to the key factors, converting qualitative insights into\nquantitative results. The derived scores undergo a scaling process,\ntransforming them into real-world values that are used for prediction. Our\nexperiments demonstrate that LLMs outperform time-series models in market\nforecasting, though challenges such as imperfect reproducibility and limited\nexplainability remain.", "published": "2024-11-13 07:45:40", "link": "http://arxiv.org/abs/2411.08404v1", "categories": ["q-fin.CP", "cs.LG"], "primary_category": "q-fin.CP"}
{"title": "Hybrid Vector Auto Regression and Neural Network Model for Order Flow Imbalance Prediction in High Frequency Trading", "abstract": "In high frequency trading, accurate prediction of Order Flow Imbalance (OFI)\nis crucial for understanding market dynamics and maintaining liquidity. This\npaper introduces a hybrid predictive model that combines Vector Auto Regression\n(VAR) with a simple feedforward neural network (FNN) to forecast OFI and assess\ntrading intensity. The VAR component captures linear dependencies, while\nresiduals are fed into the FNN to model non-linear patterns, enabling a\ncomprehensive approach to OFI prediction. Additionally, the model calculates\nthe intensity on the Buy or Sell side, providing insights into which side holds\ngreater trading pressure. These insights facilitate the development of trading\nstrategies by identifying periods of high buy or sell intensity. Using both\nsynthetic and real trading data from Binance, we demonstrate that the hybrid\nmodel offers significant improvements in predictive accuracy and enhances\nstrategic decision-making based on OFI dynamics. Furthermore, we compare the\nhybrid models performance with standalone FNN and VAR models, showing that the\nhybrid approach achieves superior forecasting accuracy across both synthetic\nand real datasets, making it the most effective model for OFI prediction in\nhigh frequency trading.", "published": "2024-11-13 07:06:22", "link": "http://arxiv.org/abs/2411.08382v1", "categories": ["q-fin.CP", "q-fin.ST", "q-fin.TR"], "primary_category": "q-fin.CP"}
{"title": "Multi-asset return risk measures", "abstract": "We revisit the recently introduced concept of return risk measures (RRMs). We\nextend it by allowing risk management via multiple so-called eligible assets.\nThe resulting new risk measures are called multi-asset return risk measures\n(MARRMs). We analyze properties of these risk measures. In particular, we prove\nthat a positively homogeneous MARRM is quasi-convex if and only if it is\nconvex. Furthermore, we state conditions to avoid inconsistent risk\nevaluations. Then, we point out the connection between MARRMs and the\nwell-known concept of multi-asset risk measures (MARMs). This is used to obtain\nvarious dual representations of MARRMs. Moreover, we compare RRMs, MARMs, and\nMARRMs in numerous case studies. First, using typical continuous-time financial\nmarkets and different notions of acceptability of losses, we compare MARRMs and\nMARMs and draw conclusions about the cost of risk mitigation. Second, in a\nreal-world example, we compare the relative difference between RRMs and MARRMs\nin times of crisis.", "published": "2024-11-13 16:49:23", "link": "http://arxiv.org/abs/2411.08763v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "Robot See, Robot Do: Imitation Reward for Noisy Financial Environments", "abstract": "The sequential nature of decision-making in financial asset trading aligns\nnaturally with the reinforcement learning (RL) framework, making RL a common\napproach in this domain. However, the low signal-to-noise ratio in financial\nmarkets results in noisy estimates of environment components, including the\nreward function, which hinders effective policy learning by RL agents. Given\nthe critical importance of reward function design in RL problems, this paper\nintroduces a novel and more robust reward function by leveraging imitation\nlearning, where a trend labeling algorithm acts as an expert. We integrate\nimitation (expert's) feedback with reinforcement (agent's) feedback in a\nmodel-free RL algorithm, effectively embedding the imitation learning problem\nwithin the RL paradigm to handle the stochasticity of reward signals. Empirical\nresults demonstrate that this novel approach improves financial performance\nmetrics compared to traditional benchmarks and RL agents trained solely using\nreinforcement feedback.", "published": "2024-11-13 14:24:47", "link": "http://arxiv.org/abs/2411.08637v1", "categories": ["cs.LG", "cs.RO", "q-fin.TR"], "primary_category": "cs.LG"}
{"title": "Refining Translations with LLMs: A Constraint-Aware Iterative Prompting\n  Approach", "abstract": "Large language models (LLMs) have demonstrated remarkable proficiency in\nmachine translation (MT), even without specific training on the languages in\nquestion. However, translating rare words in low-resource or domain-specific\ncontexts remains challenging for LLMs. To address this issue, we propose a\nmulti-step prompt chain that enhances translation faithfulness by prioritizing\nkey terms crucial for semantic accuracy. Our method first identifies these\nkeywords and retrieves their translations from a bilingual dictionary,\nintegrating them into the LLM's context using Retrieval-Augmented Generation\n(RAG). We further mitigate potential output hallucinations caused by long\nprompts through an iterative self-checking mechanism, where the LLM refines its\ntranslations based on lexical and semantic constraints. Experiments using Llama\nand Qwen as base models on the FLORES-200 and WMT datasets demonstrate\nsignificant improvements over baselines, highlighting the effectiveness of our\napproach in enhancing translation faithfulness and robustness, particularly in\nlow-resource scenarios.", "published": "2024-11-13 05:40:24", "link": "http://arxiv.org/abs/2411.08348v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tree-of-Table: Unleashing the Power of LLMs for Enhanced Large-Scale\n  Table Understanding", "abstract": "The ubiquity and value of tables as semi-structured data across various\ndomains necessitate advanced methods for understanding their complexity and\nvast amounts of information. Despite the impressive capabilities of large\nlanguage models (LLMs) in advancing the natural language understanding\nfrontier, their application to large-scale tabular data presents significant\nchallenges, specifically regarding table size and complex intricate\nrelationships. Existing works have shown promise with small-scale tables but\noften flounder when tasked with the complex reasoning required by larger,\ninterconnected tables found in real-world scenarios. To address this gap, we\nintroduce \"Tree-of-Table\", a novel approach designed to enhance LLMs' reasoning\ncapabilities over large and complex tables. Our method employs Table\nCondensation and Decomposition to distill and reorganize relevant data into a\nmanageable format, followed by the construction of a hierarchical Table-Tree\nthat facilitates tree-structured reasoning. Through a meticulous Table-Tree\nExecution process, we systematically unravel the tree-structured reasoning\nchain to derive the solutions. Experiments across diverse datasets, including\nWikiTQ, TableFact, FeTaQA, and BIRD, demonstrate that Tree-of-Table sets a new\nbenchmark with superior performance, showcasing remarkable efficiency and\ngeneralization capabilities in large-scale table reasoning.", "published": "2024-11-13 11:02:04", "link": "http://arxiv.org/abs/2411.08516v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Topic Modeling with Large Language Models in the Loop", "abstract": "Topic modeling is a fundamental task in natural language processing, allowing\nthe discovery of latent thematic structures in text corpora. While Large\nLanguage Models (LLMs) have demonstrated promising capabilities in topic\ndiscovery, their direct application to topic modeling suffers from issues such\nas incomplete topic coverage, misalignment of topics, and inefficiency. To\naddress these limitations, we propose LLM-ITL, a novel LLM-in-the-loop\nframework that integrates LLMs with Neural Topic Models (NTMs). In LLM-ITL,\nglobal topics and document representations are learned through the NTM.\nMeanwhile, an LLM refines these topics using an Optimal Transport (OT)-based\nalignment objective, where the refinement is dynamically adjusted based on the\nLLM's confidence in suggesting topical words for each set of input words. With\nthe flexibility of being integrated into many existing NTMs, the proposed\napproach enhances the interpretability of topics while preserving the\nefficiency of NTMs in learning topics and document representations. Extensive\nexperiments demonstrate that LLM-ITL helps NTMs significantly improve their\ntopic interpretability while maintaining the quality of document\nrepresentation. Our code and datasets will be available at Github.", "published": "2024-11-13 11:31:02", "link": "http://arxiv.org/abs/2411.08534v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are Triggers Needed for Document-Level Event Extraction?", "abstract": "Most existing work on event extraction has focused on sentence-level texts\nand presumes the identification of a trigger-span -- a word or phrase in the\ninput that evokes the occurrence of an event of interest. Event arguments are\nthen extracted with respect to the trigger. Indeed, triggers are treated as\nintegral to, and trigger detection as an essential component of, event\nextraction. In this paper, we provide the first investigation of the role of\ntriggers for the more difficult and much less studied task of document-level\nevent extraction. We analyze their usefulness in multiple end-to-end and\npipelined neural event extraction models for three document-level event\nextraction datasets, measuring performance using triggers of varying quality\n(human-annotated, LLM-generated, keyword-based, and random). Our research shows\nthat trigger effectiveness varies based on the extraction task's\ncharacteristics and data quality, with basic, automatically-generated triggers\nserving as a viable alternative to human-annotated ones. Furthermore, providing\ndetailed event descriptions to the extraction model helps maintain robust\nperformance even when trigger quality degrades. Perhaps surprisingly, we also\nfind that the mere existence of trigger input, even random ones, is important\nfor prompt-based LLM approaches to the task.", "published": "2024-11-13 15:50:38", "link": "http://arxiv.org/abs/2411.08708v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dynamic Rewarding with Prompt Optimization Enables Tuning-free\n  Self-Alignment of Language Models", "abstract": "Aligning Large Language Models (LLMs) traditionally relies on costly training\nand human preference annotations. Self-alignment seeks to reduce these expenses\nby enabling models to align themselves. To further lower costs and achieve\nalignment without any expensive tuning or annotations, we introduce a new\ntuning-free approach for self-alignment, Dynamic Rewarding with Prompt\nOptimization (DRPO). Our approach leverages a search-based optimization\nframework that allows LLMs to iteratively self-improve and craft the optimal\nalignment instructions, all without additional training or human intervention.\nThe core of DRPO is a dynamic rewarding mechanism, which identifies and\nrectifies model-specific alignment weaknesses, allowing LLMs to adapt\nefficiently to diverse alignment challenges. Empirical evaluations on eight\nrecent LLMs, both open- and closed-sourced, demonstrate that DRPO significantly\nenhances alignment performance, with base models outperforming their\nSFT/RLHF-tuned counterparts. Moreover, the prompts automatically optimized by\nDRPO surpass those curated by human experts, further validating the\neffectiveness of our approach. Our findings highlight the great potential of\ncurrent LLMs to achieve adaptive self-alignment through inference-time\noptimization, complementing tuning-based alignment methods.", "published": "2024-11-13 16:15:38", "link": "http://arxiv.org/abs/2411.08733v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Perspective Stance Detection", "abstract": "Subjective NLP tasks usually rely on human annotations provided by multiple\nannotators, whose judgments may vary due to their diverse backgrounds and life\nexperiences. Traditional methods often aggregate multiple annotations into a\nsingle ground truth, disregarding the diversity in perspectives that arises\nfrom annotator disagreement. In this preliminary study, we examine the effect\nof including multiple annotations on model accuracy in classification. Our\nmethodology investigates the performance of perspective-aware classification\nmodels in stance detection task and further inspects if annotator disagreement\naffects the model confidence. The results show that multi-perspective approach\nyields better classification performance outperforming the baseline which uses\nthe single label. This entails that designing more inclusive perspective-aware\nAI models is not only an essential first step in implementing responsible and\nethical AI, but it can also achieve superior results than using the traditional\napproaches.", "published": "2024-11-13 16:30:41", "link": "http://arxiv.org/abs/2411.08752v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CamemBERT 2.0: A Smarter French Language Model Aged to Perfection", "abstract": "French language models, such as CamemBERT, have been widely adopted across\nindustries for natural language processing (NLP) tasks, with models like\nCamemBERT seeing over 4 million downloads per month. However, these models face\nchallenges due to temporal concept drift, where outdated training data leads to\na decline in performance, especially when encountering new topics and\nterminology. This issue emphasizes the need for updated models that reflect\ncurrent linguistic trends. In this paper, we introduce two new versions of the\nCamemBERT base model-CamemBERTav2 and CamemBERTv2-designed to address these\nchallenges. CamemBERTav2 is based on the DeBERTaV3 architecture and makes use\nof the Replaced Token Detection (RTD) objective for better contextual\nunderstanding, while CamemBERTv2 is built on RoBERTa, which uses the Masked\nLanguage Modeling (MLM) objective. Both models are trained on a significantly\nlarger and more recent dataset with longer context length and an updated\ntokenizer that enhances tokenization performance for French. We evaluate the\nperformance of these models on both general-domain NLP tasks and\ndomain-specific applications, such as medical field tasks, demonstrating their\nversatility and effectiveness across a range of use cases. Our results show\nthat these updated models vastly outperform their predecessors, making them\nvaluable tools for modern NLP systems. All our new models, as well as\nintermediate checkpoints, are made openly available on Huggingface.", "published": "2024-11-13 18:49:35", "link": "http://arxiv.org/abs/2411.08868v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Large-Scale Study of Relevance Assessments with Large Language Models:\n  An Initial Look", "abstract": "The application of large language models to provide relevance assessments\npresents exciting opportunities to advance information retrieval, natural\nlanguage processing, and beyond, but to date many unknowns remain. This paper\nreports on the results of a large-scale evaluation (the TREC 2024 RAG Track)\nwhere four different relevance assessment approaches were deployed in situ: the\n\"standard\" fully manual process that NIST has implemented for decades and three\ndifferent alternatives that take advantage of LLMs to different extents using\nthe open-source UMBRELA tool. This setup allows us to correlate system rankings\ninduced by the different approaches to characterize tradeoffs between cost and\nquality. We find that in terms of nDCG@20, nDCG@100, and Recall@100, system\nrankings induced by automatically generated relevance assessments from UMBRELA\ncorrelate highly with those induced by fully manual assessments across a\ndiverse set of 77 runs from 19 teams. Our results suggest that automatically\ngenerated UMBRELA judgments can replace fully manual judgments to accurately\ncapture run-level effectiveness. Surprisingly, we find that LLM assistance does\nnot appear to increase correlation with fully manual assessments, suggesting\nthat costs associated with human-in-the-loop processes do not bring obvious\ntangible benefits. Overall, human assessors appear to be stricter than UMBRELA\nin applying relevance criteria. Our work validates the use of LLMs in academic\nTREC-style evaluations and provides the foundation for future studies.", "published": "2024-11-13 01:12:35", "link": "http://arxiv.org/abs/2411.08275v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Knowledge Bases in Support of Large Language Models for Processing Web\n  News", "abstract": "Large Language Models (LLMs) have received considerable interest in wide\napplications lately. During pre-training via massive datasets, such a model\nimplicitly memorizes the factual knowledge of trained datasets in its hidden\nparameters. However, knowledge held implicitly in parameters often makes its\nuse by downstream applications ineffective due to the lack of common-sense\nreasoning. In this article, we introduce a general framework that permits to\nbuild knowledge bases with an aid of LLMs, tailored for processing Web news.\nThe framework applies a rule-based News Information Extractor (NewsIE) to news\nitems for extracting their relational tuples, referred to as knowledge bases,\nwhich are then graph-convoluted with the implicit knowledge facts of news items\nobtained by LLMs, for their classification. It involves two lightweight\ncomponents: 1) NewsIE: for extracting the structural information of every news\nitem, in the form of relational tuples; 2) BERTGraph: for graph convoluting the\nimplicit knowledge facts with relational tuples extracted by NewsIE. We have\nevaluated our framework under different news-related datasets for news category\nclassification, with promising experimental results.", "published": "2024-11-13 01:33:05", "link": "http://arxiv.org/abs/2411.08278v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "R3HF: Reward Redistribution for Enhancing Reinforcement Learning from\n  Human Feedback", "abstract": "Reinforcement learning from human feedback (RLHF) provides a paradigm for\naligning large language models (LLMs) with human preferences. This involves the\ninitial training of a reward model based on pairwise human feedback. The reward\nmodel is subsequently utilized in reinforcement learning to assess the scores\nof each generated sentence as a whole, further guiding the optimization of\nLLMs. However, current approaches have a significant shortcoming: \\emph{They\nallocate a single, sparse, and delayed reward to an entire sequence of output}.\nThis may overlook some significant individual contributions of each token\ntowards the desired outcome. To overcome this limitation, our paper proposes a\nnovel reward redistribution method called R3HF, which facilitates a more\nfine-grained, token-level reward allocation. Specifically, our method treats\nthe reward prediction task of the reward model as a regression problem. As a\nresult, the redistributed rewards are computed by evaluating the specific\ncontribution of each token to the reward model's output. This detailed approach\nimproves the model's understanding of language nuances, leading to more precise\nenhancements in its performance. Our method is crafted to integrate seamlessly\nwith most current techniques while incurring minimal computational costs.\nThrough comprehensive experiments across diverse datasets and tasks, we have\nverified the effectiveness and superiority of our approach.", "published": "2024-11-13 02:45:21", "link": "http://arxiv.org/abs/2411.08302v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Bangla Grammatical Error Detection Leveraging Transformer-based Token\n  Classification", "abstract": "Bangla is the seventh most spoken language by a total number of speakers in\nthe world, and yet the development of an automated grammar checker in this\nlanguage is an understudied problem. Bangla grammatical error detection is a\ntask of detecting sub-strings of a Bangla text that contain grammatical,\npunctuation, or spelling errors, which is crucial for developing an automated\nBangla typing assistant. Our approach involves breaking down the task as a\ntoken classification problem and utilizing state-of-the-art transformer-based\nmodels. Finally, we combine the output of these models and apply rule-based\npost-processing to generate a more reliable and comprehensive result. Our\nsystem is evaluated on a dataset consisting of over 25,000 texts from various\nsources. Our best model achieves a Levenshtein distance score of 1.04. Finally,\nwe provide a detailed analysis of different components of our system.", "published": "2024-11-13 05:22:45", "link": "http://arxiv.org/abs/2411.08344v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Interpretable Syntactic Representations Enable Hierarchical Word Vectors", "abstract": "The distributed representations currently used are dense and uninterpretable,\nleading to interpretations that themselves are relative, overcomplete, and hard\nto interpret. We propose a method that transforms these word vectors into\nreduced syntactic representations. The resulting representations are compact\nand interpretable allowing better visualization and comparison of the word\nvectors and we successively demonstrate that the drawn interpretations are in\nline with human judgment. The syntactic representations are then used to create\nhierarchical word vectors using an incremental learning approach similar to the\nhierarchical aspect of human learning. As these representations are drawn from\npre-trained vectors, the generation process and learning approach are\ncomputationally efficient. Most importantly, we find out that syntactic\nrepresentations provide a plausible interpretation of the vectors and\nsubsequent hierarchical vectors outperform the original vectors in benchmark\ntests.", "published": "2024-11-13 07:10:18", "link": "http://arxiv.org/abs/2411.08384v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CLaSP: Learning Concepts for Time-Series Signals from Natural Language\n  Supervision", "abstract": "This paper presents CLaSP, a novel model for retrieving time-series signals\nusing natural language queries that describe signal characteristics. The\nability to search time-series signals based on descriptive queries is essential\nin domains such as industrial diagnostics, where data scientists often need to\nfind signals with specific characteristics. However, existing methods rely on\nsketch-based inputs, predefined synonym dictionaries, or domain-specific manual\ndesigns, limiting their scalability and adaptability. CLaSP addresses these\nchallenges by employing contrastive learning to map time-series signals to\nnatural language descriptions. Unlike prior approaches, it eliminates the need\nfor predefined synonym dictionaries and leverages the rich contextual knowledge\nof large language models (LLMs). Using the TRUCE and SUSHI datasets, which pair\ntime-series signals with natural language descriptions, we demonstrate that\nCLaSP achieves high accuracy in retrieving a variety of time series patterns\nbased on natural language queries.", "published": "2024-11-13 07:32:58", "link": "http://arxiv.org/abs/2411.08397v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Evaluating Large Language Models for Graph Query Generation", "abstract": "Large Language Models (LLMs) are revolutionizing the landscape of Generative\nArtificial Intelligence (GenAI), with innovative LLM-backed solutions emerging\nrapidly. However, when applied to database technologies, specifically query\ngeneration for graph databases and Knowledge Graphs (KGs), LLMs still face\nsignificant challenges. While research on LLM-driven query generation for\nStructured Query Language (SQL) exists, similar systems for graph databases\nremain underdeveloped. This paper presents a comparative study addressing the\nchallenge of generating Cypher queries a powerful language for interacting with\ngraph databases using open-access LLMs. We rigorously evaluate several LLM\nagents (OpenAI ChatGPT 4o, Claude Sonnet 3.5, Google Gemini Pro 1.5, and a\nlocally deployed Llama 3.1 8B) using a designed few-shot learning prompt and\nRetrieval Augmented Generation (RAG) backed by Chain-of-Thoughts (CoT)\nreasoning. Our empirical analysis of query generation accuracy reveals that\nClaude Sonnet 3.5 outperforms its counterparts in this specific domain.\nFurther, we highlight promising future research directions to address the\nidentified limitations and advance LLM-driven query generation for graph\ndatabases.", "published": "2024-11-13 09:11:56", "link": "http://arxiv.org/abs/2411.08449v2", "categories": ["cs.ET", "cs.CL"], "primary_category": "cs.ET"}
{"title": "Towards Objective and Unbiased Decision Assessments with LLM-Enhanced\n  Hierarchical Attention Networks", "abstract": "How objective and unbiased are we while making decisions? This work\ninvestigates cognitive bias identification in high-stake decision making\nprocess by human experts, questioning its effectiveness in real-world settings,\nsuch as candidates assessments for university admission. We begin with a\nstatistical analysis assessing correlations among different decision points\namong in the current process, which discovers discrepancies that imply\ncognitive bias and inconsistency in decisions. This motivates our exploration\nof bias-aware AI-augmented workflow that surpass human judgment. We propose\nBGM-HAN, an enhanced Hierarchical Attention Network with Byte-Pair Encoding,\nGated Residual Connections and Multi-Head Attention. Using it as a backbone\nmodel, we further propose a Shortlist-Analyse-Recommend (SAR) agentic workflow,\nwhich simulate real-world decision-making. In our experiments, both the\nproposed model and the agentic workflow significantly improves on both human\njudgment and alternative models, validated with real-world data.", "published": "2024-11-13 10:42:11", "link": "http://arxiv.org/abs/2411.08504v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Dynamic Subset Tuning: Expanding the Operational Range of\n  Parameter-Efficient Training for Large Language Models", "abstract": "We propose a novel parameter-efficient training (PET) method for large\nlanguage models that adapts models to downstream tasks by optimizing a small\nsubset of the existing model parameters. Unlike prior methods, this subset is\nnot fixed in location but rather which parameters are modified evolves over the\ncourse of training. This dynamic parameter selection can yield good performance\nwith many fewer parameters than extant methods. Our method enables a seamless\nscaling of the subset size across an arbitrary proportion of the total model\nsize, while popular PET approaches like prompt tuning and LoRA cover only a\nsmall part of this spectrum. We match or outperform prompt tuning and LoRA in\nmost cases on a variety of NLP tasks (MT, QA, GSM8K, SuperGLUE) for a given\nparameter budget across different model families and sizes.", "published": "2024-11-13 13:53:10", "link": "http://arxiv.org/abs/2411.08610v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Theoretical Analysis of Byte-Pair Encoding", "abstract": "Byte-Pair Encoding (BPE) is a widely used method for subword tokenization,\nwith origins in grammar-based text compression. It is employed in a variety of\nlanguage processing tasks such as machine translation or large language model\n(LLM) pretraining, to create a token dictionary of a prescribed size. Most\nevaluations of BPE to date are empirical, and the reasons for its good\npractical performance are not well understood.\n  In this paper we focus on the optimization problem underlying BPE: finding a\npair encoding that achieves optimal compression utility. We show that this\nproblem is APX-complete, indicating that it is unlikely to admit a\npolynomial-time approximation scheme. This answers, in a stronger form, a\nquestion recently raised by Zouhar et al.\n  On the positive side, we show that BPE approximates the compression utility\nof the optimal pair encoding to a worst-case factor between $0.333$ and\n$0.625$. Our results aim to explain the ongoing success of BPE and are, to our\nknowledge, the first rigorous guarantees on its compression utility that hold\nfor all inputs.", "published": "2024-11-13 15:04:02", "link": "http://arxiv.org/abs/2411.08671v1", "categories": ["cs.DS", "cs.CL"], "primary_category": "cs.DS"}
{"title": "Separating Tongue from Thought: Activation Patching Reveals\n  Language-Agnostic Concept Representations in Transformers", "abstract": "A central question in multilingual language modeling is whether large\nlanguage models (LLMs) develop a universal concept representation, disentangled\nfrom specific languages. In this paper, we address this question by analyzing\nlatent representations (latents) during a word translation task in\ntransformer-based LLMs. We strategically extract latents from a source\ntranslation prompt and insert them into the forward pass on a target\ntranslation prompt. By doing so, we find that the output language is encoded in\nthe latent at an earlier layer than the concept to be translated. Building on\nthis insight, we conduct two key experiments. First, we demonstrate that we can\nchange the concept without changing the language and vice versa through\nactivation patching alone. Second, we show that patching with the mean over\nlatents across different languages does not impair and instead improves the\nmodels' performance in translating the concept. Our results provide evidence\nfor the existence of language-agnostic concept representations within the\ninvestigated models.", "published": "2024-11-13 16:26:19", "link": "http://arxiv.org/abs/2411.08745v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Zero-shot Cross-lingual Transfer Learning with Multiple Source and\n  Target Languages for Information Extraction: Language Selection and\n  Adversarial Training", "abstract": "The majority of previous researches addressing multi-lingual IE are limited\nto zero-shot cross-lingual single-transfer (one-to-one) setting, with\nhigh-resource languages predominantly as source training data. As a result,\nthese works provide little understanding and benefit for the realistic goal of\ndeveloping a multi-lingual IE system that can generalize to as many languages\nas possible. Our study aims to fill this gap by providing a detailed analysis\non Cross-Lingual Multi-Transferability (many-to-many transfer learning), for\nthe recent IE corpora that cover a diverse set of languages. Specifically, we\nfirst determine the correlation between single-transfer performance and a wide\nrange of linguistic-based distances. From the obtained insights, a combined\nlanguage distance metric can be developed that is not only highly correlated\nbut also robust across different tasks and model scales. Next, we investigate\nthe more general zero-shot multi-lingual transfer settings where multiple\nlanguages are involved in the training and evaluation processes. Language\nclustering based on the newly defined distance can provide directions for\nachieving the optimal cost-performance trade-off in data (languages) selection\nproblem. Finally, a relational-transfer setting is proposed to further\nincorporate multi-lingual unlabeled data based on adversarial training using\nthe relation induced from the above linguistic distance.", "published": "2024-11-13 17:13:25", "link": "http://arxiv.org/abs/2411.08785v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Sparse Upcycling: Inference Inefficient Finetuning", "abstract": "Small, highly trained, open-source large language models are widely used due\nto their inference efficiency, but further improving their quality remains a\nchallenge. Sparse upcycling is a promising approach that transforms a\npretrained dense model into a Mixture-of-Experts (MoE) architecture, increasing\nthe model's parameter count and quality. In this work, we compare the\neffectiveness of sparse upcycling against continued pretraining (CPT) across\ndifferent model sizes, compute budgets, and pretraining durations. Our\nexperiments show that sparse upcycling can achieve better quality, with\nimprovements of over 20% relative to CPT in certain scenarios. However, this\ncomes with a significant inference cost, leading to 40% slowdowns in\nhigh-demand inference settings for larger models. Our findings highlight the\ntrade-off between model quality and inference efficiency, offering insights for\npractitioners seeking to balance model quality and deployment constraints.", "published": "2024-11-13 19:02:36", "link": "http://arxiv.org/abs/2411.08968v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Robustness and Confounders in the Demographic Alignment of LLMs with\n  Human Perceptions of Offensiveness", "abstract": "Large language models (LLMs) are known to exhibit demographic biases, yet few\nstudies systematically evaluate these biases across multiple datasets or\naccount for confounding factors. In this work, we examine LLM alignment with\nhuman annotations in five offensive language datasets, comprising approximately\n220K annotations. Our findings reveal that while demographic traits,\nparticularly race, influence alignment, these effects are inconsistent across\ndatasets and often entangled with other factors. Confounders -- such as\ndocument difficulty, annotator sensitivity, and within-group agreement --\naccount for more variation in alignment patterns than demographic traits alone.\nSpecifically, alignment increases with higher annotator sensitivity and group\nagreement, while greater document difficulty corresponds to reduced alignment.\nOur results underscore the importance of multi-dataset analyses and\nconfounder-aware methodologies in developing robust measures of demographic\nbias in LLMs.", "published": "2024-11-13 19:08:23", "link": "http://arxiv.org/abs/2411.08977v2", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "CoCoP: Enhancing Text Classification with LLM through Code Completion\n  Prompt", "abstract": "Text classification is a fundamental task in natural language processing\n(NLP), and large language models (LLMs) have demonstrated their capability to\nperform this task across various domains. However, the performance of LLMs\nheavily depends on the quality of their input prompts. Recent studies have also\nshown that LLMs exhibit remarkable results in code-related tasks. To leverage\nthe capabilities of LLMs in text classification, we propose the Code Completion\nPrompt (CoCoP) method, which transforms the text classification problem into a\ncode completion task. CoCoP significantly improves text classification\nperformance across diverse datasets by utilizing LLMs' code-completion\ncapability. For instance, CoCoP enhances the accuracy of the SST2 dataset by\nmore than 20%. Moreover, when CoCoP integrated with LLMs specifically designed\nfor code-related tasks (code models), such as CodeLLaMA, this method\ndemonstrates better or comparable performance to few-shot learning techniques\nwhile using only one-tenth of the model size. The source code of our proposed\nmethod will be available to the public upon the acceptance of the paper.", "published": "2024-11-13 19:12:02", "link": "http://arxiv.org/abs/2411.08979v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Refusal in LLMs is an Affine Function", "abstract": "We propose affine concept editing (ACE) as an approach for steering language\nmodels' behavior by intervening directly in activations. We begin with an\naffine decomposition of model activation vectors and show that prior methods\nfor steering model behavior correspond to subsets of terms of this\ndecomposition. We then provide a derivation of ACE and use it to control\nrefusal behavior on ten different models, including Llama 3 70B. ACE combines\naffine subspace projection and activation addition to reliably control the\nmodel's refusal responses across prompt types. We evaluate the results using\nLLM-based scoring on a collection of harmful and harmless prompts. Our\nexperiments demonstrate that ACE consistently achieves more precise control\nover model behavior than existing methods and generalizes to models where\ndirectional ablation via affine subspace projection alone produces incoherent\noutputs. Code for reproducing our results is available at\nhttps://github.com/EleutherAI/steering-llama3 .", "published": "2024-11-13 20:12:55", "link": "http://arxiv.org/abs/2411.09003v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Cut Your Losses in Large-Vocabulary Language Models", "abstract": "As language models grow ever larger, so do their vocabularies. This has\nshifted the memory footprint of LLMs during training disproportionately to one\nsingle layer: the cross-entropy in the loss computation. Cross-entropy builds\nup a logit matrix with entries for each pair of input tokens and vocabulary\nitems and, for small models, consumes an order of magnitude more memory than\nthe rest of the LLM combined. We propose Cut Cross-Entropy (CCE), a method that\ncomputes the cross-entropy loss without materializing the logits for all tokens\ninto global memory. Rather, CCE only computes the logit for the correct token\nand evaluates the log-sum-exp over all logits on the fly. We implement a custom\nkernel that performs the matrix multiplications and the log-sum-exp reduction\nover the vocabulary in flash memory, making global memory consumption for the\ncross-entropy computation negligible. This has a dramatic effect. Taking the\nGemma 2 (2B) model as an example, CCE reduces the memory footprint of the loss\ncomputation from 24 GB to 1 MB, and the total training-time memory consumption\nof the classifier head from 28 GB to 1 GB. To improve the throughput of CCE, we\nleverage the inherent sparsity of softmax and propose to skip elements of the\ngradient computation that have a negligible (i.e., below numerical precision)\ncontribution to the gradient. Experiments demonstrate that the dramatic\nreduction in memory consumption is accomplished without sacrificing training\nspeed or convergence.", "published": "2024-11-13 20:30:15", "link": "http://arxiv.org/abs/2411.09009v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Are LLMs Prescient? A Continuous Evaluation using Daily News as the\n  Oracle", "abstract": "Many existing evaluation benchmarks for Large Language Models (LLMs) quickly\nbecome outdated due to the emergence of new models and training data. These\nbenchmarks also fall short in assessing how LLM performance changes over time,\nas they consist of static questions without a temporal dimension. To address\nthese limitations, we propose using future event prediction as a continuous\nevaluation method to assess LLMs' temporal generalization and forecasting\nabilities. Our benchmark, Daily Oracle, automatically generates question-answer\n(QA) pairs from daily news, challenging LLMs to predict \"future\" event\noutcomes. Our findings reveal that as pre-training data becomes outdated, LLM\nperformance degrades over time. While Retrieval Augmented Generation (RAG) has\nthe potential to enhance prediction accuracy, the performance degradation\npattern persists, highlighting the need for continuous model updates.", "published": "2024-11-13 04:20:20", "link": "http://arxiv.org/abs/2411.08324v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Chinese Multi-label Affective Computing Dataset Based on Social Media\n  Network Users", "abstract": "Emotion and personality are central elements in understanding human\npsychological states. Emotions reflect an individual subjective experiences,\nwhile personality reveals relatively stable behavioral and cognitive patterns.\nExisting affective computing datasets often annotate emotion and personality\ntraits separately, lacking fine-grained labeling of micro-emotions and emotion\nintensity in both single-label and multi-label classifications. Chinese emotion\ndatasets are extremely scarce, and datasets capturing Chinese user personality\ntraits are even more limited. To address these gaps, this study collected data\nfrom the major social media platform Weibo, screening 11,338 valid users from\nover 50,000 individuals with diverse MBTI personality labels and acquiring\n566,900 posts along with the user MBTI personality tags. Using the EQN method,\nwe compiled a multi-label Chinese affective computing dataset that integrates\nthe same user's personality traits with six emotions and micro-emotions, each\nannotated with intensity levels. Validation results across multiple NLP\nclassification models demonstrate the dataset strong utility. This dataset is\ndesigned to advance machine recognition of complex human emotions and provide\ndata support for research in psychology, education, marketing, finance, and\npolitics.", "published": "2024-11-13 05:38:55", "link": "http://arxiv.org/abs/2411.08347v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.CV"}
{"title": "One STEP at a time: Language Agents are Stepwise Planners", "abstract": "Language agents have shown promising adaptability in dynamic environments to\nperform complex tasks. However, despite the versatile knowledge embedded in\nlarge language models, these agents still fall short when it comes to tasks\nthat require planning. We introduce STEP, a novel framework designed to\nefficiently learn from previous experiences to enhance the planning\ncapabilities of language agents in future steps. Concretely, STEP functions\nthrough four interconnected components. First, the Planner takes on the task,\nbreaks it down into subtasks and provides relevant insights. Then the Executor\ngenerates action candidates, while the Evaluator ensures the actions align with\nlearned rules from previous experiences. Lastly, Memory stores experiences to\ninform future decisions. In the ScienceWorld benchmark, our results show that\nSTEP consistently outperforms state-of-the-art models, achieving an overall\nscore of 67.4 and successfully completing 12 out of 18 tasks. These findings\nhighlight STEP's potential as a framework for enhancing planning capabilities\nin language agents, paving the way for more sophisticated task-solving in\ndynamic environments.", "published": "2024-11-13 08:32:42", "link": "http://arxiv.org/abs/2411.08432v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Operationalizing Right to Data Protection", "abstract": "The widespread practice of indiscriminate data scraping to fine-tune language\nmodels (LMs) raises significant legal and ethical concerns, particularly\nregarding compliance with data protection laws such as the General Data\nProtection Regulation (GDPR). This practice often results in the unauthorized\nuse of personal information, prompting growing debate within the academic and\nregulatory communities. Recent works have introduced the concept of generating\nunlearnable datasets (by adding imperceptible noise to the clean data), such\nthat the underlying model achieves lower loss during training but fails to\ngeneralize to the unseen test setting. Though somewhat effective, these\napproaches are predominantly designed for images and are limited by several\npractical constraints like requiring knowledge of the target model. To this\nend, we introduce RegText, a framework that injects imperceptible spurious\ncorrelations into natural language datasets, effectively rendering them\nunlearnable without affecting semantic content. We demonstrate RegText's\nutility through rigorous empirical analysis of small and large LMs. Notably,\nRegText can restrict newer models like GPT-4o and Llama from learning on our\ngenerated data, resulting in a drop in their test accuracy compared to their\nzero-shot performance and paving the way for generating unlearnable text to\nprotect public data.", "published": "2024-11-13 10:43:31", "link": "http://arxiv.org/abs/2411.08506v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "CorrSynth -- A Correlated Sampling Method for Diverse Dataset Generation\n  from LLMs", "abstract": "Large language models (LLMs) have demonstrated remarkable performance in\ndiverse tasks using zero-shot and few-shot prompting. Even though their\ncapabilities of data synthesis have been studied well in recent years, the\ngenerated data suffers from a lack of diversity, less adherence to the prompt,\nand potential biases that creep into the data from the generator model. In this\nwork, we tackle the challenge of generating datasets with high diversity, upon\nwhich a student model is trained for downstream tasks. Taking the route of\ndecoding-time guidance-based approaches, we propose CorrSynth, which generates\ndata that is more diverse and faithful to the input prompt using a correlated\nsampling strategy. Further, our method overcomes the complexity drawbacks of\nsome other guidance-based techniques like classifier-based guidance. With\nextensive experiments, we show the effectiveness of our approach and\nsubstantiate our claims. In particular, we perform intrinsic evaluation to show\nthe improvements in diversity. Our experiments show that CorrSynth improves\nboth student metrics and intrinsic metrics upon competitive baselines across\nfour datasets, showing the innate advantage of our method.", "published": "2024-11-13 12:09:23", "link": "http://arxiv.org/abs/2411.08553v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Preview of XiYan-SQL: A Multi-Generator Ensemble Framework for\n  Text-to-SQL", "abstract": "To tackle the challenges of large language model performance in natural\nlanguage to SQL tasks, we introduce XiYan-SQL, an innovative framework that\nemploys a multi-generator ensemble strategy to improve candidate generation. We\nintroduce M-Schema, a semi-structured schema representation method designed to\nenhance the understanding of database structures. To enhance the quality and\ndiversity of generated candidate SQL queries, XiYan-SQL integrates the\nsignificant potential of in-context learning (ICL) with the precise control of\nsupervised fine-tuning. On one hand, we propose a series of training strategies\nto fine-tune models to generate high-quality candidates with diverse\npreferences. On the other hand, we implement the ICL approach with an example\nselection method based on named entity recognition to prevent overemphasis on\nentities. The refiner optimizes each candidate by correcting logical or\nsyntactical errors. To address the challenge of identifying the best candidate,\nwe fine-tune a selection model to distinguish nuances of candidate SQL queries.\nThe experimental results on multiple dialect datasets demonstrate the\nrobustness of XiYan-SQL in addressing challenges across different scenarios.\nOverall, our proposed XiYan-SQL achieves the state-of-the-art execution\naccuracy of 75.63% on Bird benchmark, 89.65% on the Spider test set, 69.86% on\nSQL-Eval, 41.20% on NL2GQL. The proposed framework not only enhances the\nquality and diversity of SQL queries but also outperforms previous methods.", "published": "2024-11-13 13:30:21", "link": "http://arxiv.org/abs/2411.08599v3", "categories": ["cs.AI", "cs.CL", "cs.DB", "cs.LG", "I.2; H.2"], "primary_category": "cs.AI"}
{"title": "A Comparative Study of Discrete Speech Tokens for Semantic-Related Tasks\n  with Large Language Models", "abstract": "With the rise of Speech Large Language Models (Speech LLMs), there has been\ngrowing interest in discrete speech tokens for their ability to integrate with\ntext-based tokens seamlessly. Compared to most studies that focus on continuous\nspeech features, although discrete-token based LLMs have shown promising\nresults on certain tasks, the performance gap between these two paradigms is\nrarely explored. In this paper, we present a fair and thorough comparison\nbetween discrete and continuous features across a variety of semantic-related\ntasks using a light-weight LLM (Qwen1.5-0.5B). Our findings reveal that\ncontinuous features generally outperform discrete tokens, particularly in tasks\nrequiring fine-grained semantic understanding. Moreover, this study goes beyond\nsurface-level comparison by identifying key factors behind the\nunder-performance of discrete tokens, such as limited token granularity and\ninefficient information retention. To enhance the performance of discrete\ntokens, we explore potential aspects based on our analysis. We hope our results\ncan offer new insights into the opportunities for advancing discrete speech\ntokens in Speech LLMs.", "published": "2024-11-13 16:20:20", "link": "http://arxiv.org/abs/2411.08742v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Can sparse autoencoders be used to decompose and interpret steering\n  vectors?", "abstract": "Steering vectors are a promising approach to control the behaviour of large\nlanguage models. However, their underlying mechanisms remain poorly understood.\nWhile sparse autoencoders (SAEs) may offer a potential method to interpret\nsteering vectors, recent findings show that SAE-reconstructed vectors often\nlack the steering properties of the original vectors. This paper investigates\nwhy directly applying SAEs to steering vectors yields misleading\ndecompositions, identifying two reasons: (1) steering vectors fall outside the\ninput distribution for which SAEs are designed, and (2) steering vectors can\nhave meaningful negative projections in feature directions, which SAEs are not\ndesigned to accommodate. These limitations hinder the direct use of SAEs for\ninterpreting steering vectors.", "published": "2024-11-13 17:16:48", "link": "http://arxiv.org/abs/2411.08790v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "The Limited Impact of Medical Adaptation of Large Language and\n  Vision-Language Models", "abstract": "Several recent works seek to adapt general-purpose large language models\n(LLMs) and vision-language models (VLMs) for medical applications through\ncontinued pretraining on publicly available biomedical corpora. These works\ntypically claim that such domain-adaptive pretraining improves performance on\nvarious downstream medical tasks, such as answering medical exam questions. In\nthis paper, we compare ten \"medical\" LLMs and two VLMs against their\ncorresponding base models, arriving at a different conclusion: all medical VLMs\nand nearly all medical LLMs fail to consistently improve over their base models\nin the zero-/few-shot prompting and supervised fine-tuning regimes for medical\nquestion answering (QA). For instance, on clinical-note-based QA tasks in the\n3-shot setting, medical LLMs outperform their base models in only 26.7% of\ncases, reach a (statistical) tie in 16.7% of cases, and perform significantly\nworse in the remaining 56.7% of cases. Our conclusions are based on (i)\ncomparing each medical model directly against its base model; (ii) optimizing\nthe prompts for each model separately in zero-/few-shot prompting; and (iii)\naccounting for statistical uncertainty in comparisons. Our findings suggest\nthat state-of-the-art general-domain models may already exhibit strong medical\nknowledge and reasoning capabilities, and offer recommendations to strengthen\nthe conclusions of future studies.", "published": "2024-11-13 18:50:13", "link": "http://arxiv.org/abs/2411.08870v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Bridging the Visual Gap: Fine-Tuning Multimodal Models with\n  Knowledge-Adapted Captions", "abstract": "Recent research increasingly focuses on training vision-language models\n(VLMs) with long, detailed image captions. However, small-scale VLMs often\nstruggle to balance the richness of these captions with the risk of\nhallucinating content during fine-tuning. In this paper, we explore how well\nVLMs adapt to such captions. To quantify caption quality, we propose Decomposed\nNLI (DNLI), an evaluation framework that breaks down generated captions into\nindividual propositions, assessing each in isolation. This fine-grained\nanalysis reveals a critical balance between capturing descriptive details and\npreventing hallucinations. Our findings show that simply reducing caption\ncomplexity or employing standard data curation techniques does not effectively\nresolve this issue. To tackle this challenge, we introduce Knowledge Adapted\n(KnowAda) fine-tuning, a data-centric approach that automatically adapts\ntraining data with the model's existing knowledge and visual understanding.\nKnowAda minimizes hallucinations while preserving high descriptiveness. We\nvalidate this approach across several small-scale VLMs (up to 7B parameters)\nand dense caption datasets, demonstrating that KnowAda effectively balances\nhallucination reduction and descriptiveness. Our results show that KnowAda\noutperforms various baselines in both automatic metrics and human evaluations.\nWe will release our code and models.", "published": "2024-11-13 20:50:04", "link": "http://arxiv.org/abs/2411.09018v3", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "CHAI for LLMs: Improving Code-Mixed Translation in Large Language Models\n  through Reinforcement Learning with AI Feedback", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\nvarious NLP tasks but struggle with code-mixed (or code-switched) language\nunderstanding. For example, prior work benchmarking the performance of\nmultilingual LLMs on code-mixed translation tasks has demonstrated that current\nstate-of-the-art multilingual LLMs are ineffective in dealing with code-mixed\nlanguages. However, the question of how to improve the capability of\nmultilingual LLMs to handle code-mixed language has not received any attention\nto date. In this paper, we tackle this research gap by proposing CHAI, a novel\ngeneral-purpose framework for improving the ability of multilingual LLMs to\nhandle code-mixed languages. CHAI relies on three novel contributions made in\nthis paper. First, we explore the ability of LLMs to provide accurate\nannotations for code-mixed translation tasks. Second, we leverage this ability\nof LLMs as annotators to generate preference data for code-mixed translation\ntasks at scale, which are then used within a reinforcement learning from AI\nfeedback (RLAIF) procedure to improve LLMs' capability on code-mixed tasks.\nThird, we conduct a rigorous experimental evaluation across various real-world\ndatasets and settings. Our analysis shows that CHAI-powered LLMs outperform\nstate-of-the-art open-source LLMs by 25.66% (in terms of win rate adjudicated\nby human annotators) in code-mixed translation tasks. This work represents a\nfirst step towards developing more inclusive code-mixed LLMs.", "published": "2024-11-13 22:56:00", "link": "http://arxiv.org/abs/2411.09073v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Direct Speech-to-Speech Neural Machine Translation: A Survey", "abstract": "Speech-to-Speech Translation (S2ST) models transform speech from one language\nto another target language with the same linguistic information. S2ST is\nimportant for bridging the communication gap among communities and has diverse\napplications. In recent years, researchers have introduced direct S2ST models,\nwhich have the potential to translate speech without relying on intermediate\ntext generation, have better decoding latency, and the ability to preserve\nparalinguistic and non-linguistic features. However, direct S2ST has yet to\nachieve quality performance for seamless communication and still lags behind\nthe cascade models in terms of performance, especially in real-world\ntranslation. To the best of our knowledge, no comprehensive survey is available\non the direct S2ST system, which beginners and advanced researchers can look\nupon for a quick survey. The present work provides a comprehensive review of\ndirect S2ST models, data and application issues, and performance metrics. We\ncritically analyze the models' performance over the benchmark datasets and\nprovide research challenges and future directions.", "published": "2024-11-13 13:01:21", "link": "http://arxiv.org/abs/2411.14453v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Towards Efficient Neurally-Guided Program Induction for ARC-AGI", "abstract": "ARC-AGI is an open-world problem domain in which the ability to generalize\nout-of-distribution is a crucial quality. Under the program induction paradigm,\nwe present a series of experiments that reveal the efficiency and\ngeneralization characteristics of various neurally-guided program induction\napproaches. The three paradigms we consider are Learning the grid space,\nLearning the program space, and Learning the transform space. We implement and\nexperiment thoroughly on the first two, and retain the second one for ARC-AGI\nsubmission. After identifying the strengths and weaknesses of both of these\napproaches, we suggest the third as a potential solution, and run preliminary\nexperiments.", "published": "2024-11-13 14:44:03", "link": "http://arxiv.org/abs/2411.17708v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Hateful Meme Detection through Context-Sensitive Prompting and\n  Fine-Grained Labeling", "abstract": "The prevalence of multi-modal content on social media complicates automated\nmoderation strategies. This calls for an enhancement in multi-modal\nclassification and a deeper understanding of understated meanings in images and\nmemes. Although previous efforts have aimed at improving model performance\nthrough fine-tuning, few have explored an end-to-end optimization pipeline that\naccounts for modalities, prompting, labeling, and fine-tuning. In this study,\nwe propose an end-to-end conceptual framework for model optimization in complex\ntasks. Experiments support the efficacy of this traditional yet novel\nframework, achieving the highest accuracy and AUROC. Ablation experiments\ndemonstrate that isolated optimizations are not ineffective on their own.", "published": "2024-11-13 08:05:41", "link": "http://arxiv.org/abs/2411.10480v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.MM", "68T45, 68T50, 68T07", "I.2.10; I.2.7; I.2.6"], "primary_category": "cs.CV"}
{"title": "State-Space Estimation of Spatially Dynamic Room Impulse Responses using\n  a Room Acoustic Model-based Prior", "abstract": "The estimation of room impulse responses (RIRs) between static loudspeaker\nand microphone locations can be done using a number of well-established\nmeasurement and inference procedures. While these procedures assume a\ntime-invariant acoustic system, time variations need to be considered for the\ncase of spatially dynamic scenarios where loudspeakers and microphones are\nsubject to movement. If the RIR is modeled using image sources, then movement\nimplies that the distance to each image source varies over time, making the\nestimation of the spatially dynamic RIR particularly challenging. In this\npaper, we propose a procedure to estimate the early part of the spatially\ndynamic RIR between a stationary source and a microphone moving on a linear\ntrajectory at constant velocity. The procedure is built upon a state-space\nmodel, where the state to be estimated represents the early RIR, the\nobservation corresponds to a microphone recording in a spatially dynamic\nscenario, and time-varying distances to the image sources are incorporated into\nthe state transition matrix obtained from static RIRs at the start and end\npoint of the trajectory. The performance of the proposed approach is evaluated\nagainst state-of-the-art RIR interpolation and state-space estimation methods\nusing simulations, demonstrating the potential of the proposed state-space\nmodel.", "published": "2024-11-13 09:55:02", "link": "http://arxiv.org/abs/2411.08477v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Language Models for Music Medicine Generation", "abstract": "Music therapy has been shown in recent years to provide multiple health\nbenefits related to emotional wellness. In turn, maintaining a healthy\nemotional state has proven to be effective for patients undergoing treatment,\nsuch as Parkinson's patients or patients suffering from stress and anxiety. We\npropose fine-tuning MusicGen, a music-generating transformer model, to create\nshort musical clips that assist patients in transitioning from negative to\ndesired emotional states. Using low-rank decomposition fine-tuning on the\nMTG-Jamendo Dataset with emotion tags, we generate 30-second clips that adhere\nto the iso principle, guiding patients through intermediate states in the\nvalence-arousal circumplex. The generated music is evaluated using a music\nemotion recognition model to ensure alignment with intended emotions. By\nconcatenating these clips, we produce a 15-minute \"music medicine\" resembling a\nmusic therapy session. Our approach is the first model to leverage Language\nModels to generate music medicine. Ultimately, the output is intended to be\nused as a temporary relief between music therapy sessions with a\nboard-certified therapist.", "published": "2024-11-13 23:17:47", "link": "http://arxiv.org/abs/2411.09080v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "PerceiverS: A Multi-Scale Perceiver with Effective Segmentation for\n  Long-Term Expressive Symbolic Music Generation", "abstract": "AI-based music generation has progressed significantly in recent years.\nHowever, creating symbolic music that is both long-structured and expressive\nremains a considerable challenge. In this paper, we propose PerceiverS\n(Segmentation and Scale), a novel architecture designed to address this issue\nby leveraging both Effective Segmentation and Multi-Scale attention mechanisms.\nOur approach enhances symbolic music generation by simultaneously learning\nlong-term structural dependencies and short-term expressive details. By\ncombining cross-attention and self-attention in a Multi-Scale setting,\nPerceiverS captures long-range musical structure while preserving musical\ndiversity. The proposed model has been evaluated using the Maestro dataset and\nhas demonstrated improvements in generating music of conventional length with\nexpressive nuances. The project demos and the generated music samples can be\naccessed through the link: https://perceivers.github.io", "published": "2024-11-13 03:14:10", "link": "http://arxiv.org/abs/2411.08307v2", "categories": ["cs.AI", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.AI"}
{"title": "Evaluating Synthetic Command Attacks on Smart Voice Assistants", "abstract": "Recent advances in voice synthesis, coupled with the ease with which speech\ncan be harvested for millions of people, introduce new threats to applications\nthat are enabled by devices such as voice assistants (e.g., Amazon Alexa,\nGoogle Home etc.). We explore if unrelated and limited amount of speech from a\ntarget can be used to synthesize commands for a voice assistant like Amazon\nAlexa. More specifically, we investigate attacks on voice assistants with\nsynthetic commands when they match command sources to authorized users, and\napplications (e.g., Alexa Skills) process commands only when their source is an\nauthorized user with a chosen confidence level. We demonstrate that even simple\nconcatenative speech synthesis can be used by an attacker to command voice\nassistants to perform sensitive operations. We also show that such attacks,\nwhen launched by exploiting compromised devices in the vicinity of voice\nassistants, can have relatively small host and network footprint. Our results\ndemonstrate the need for better defenses against synthetic malicious commands\nthat could target voice assistants.", "published": "2024-11-13 03:51:58", "link": "http://arxiv.org/abs/2411.08316v2", "categories": ["cs.CR", "cs.SD", "eess.AS"], "primary_category": "cs.CR"}
{"title": "Developing an Effective Training Dataset to Enhance the Performance of\n  AI-based Speaker Separation Systems", "abstract": "This paper addresses the challenge of speaker separation, which remains an\nactive research topic despite the promising results achieved in recent years.\nThese results, however, often degrade in real recording conditions due to the\npresence of noise, echo, and other interferences. This is because neural models\nare typically trained on synthetic datasets consisting of mixed audio signals\nand their corresponding ground truths, which are generated using computer\nsoftware and do not fully represent the complexities of real-world recording\nscenarios. The lack of realistic training sets for speaker separation remains a\nmajor hurdle, as obtaining individual sounds from mixed audio signals is a\nnontrivial task. To address this issue, we propose a novel method for\nconstructing a realistic training set that includes mixture signals and\ncorresponding ground truths for each speaker. We evaluate this dataset on a\ndeep learning model and compare it to a synthetic dataset. We got a 1.65 dB\nimprovement in Scale Invariant Signal to Distortion Ratio (SI-SDR) for speaker\nseparation accuracy in realistic mixing. Our findings highlight the potential\nof realistic training sets for enhancing the performance of speaker separation\nmodels in real-world scenarios.", "published": "2024-11-13 06:55:18", "link": "http://arxiv.org/abs/2411.08375v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
