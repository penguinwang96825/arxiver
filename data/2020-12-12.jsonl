{"title": "Mapping the Timescale Organization of Neural Language Models", "abstract": "In the human brain, sequences of language input are processed within a\ndistributed and hierarchical architecture, in which higher stages of processing\nencode contextual information over longer timescales. In contrast, in recurrent\nneural networks which perform natural language processing, we know little about\nhow the multiple timescales of contextual information are functionally\norganized. Therefore, we applied tools developed in neuroscience to map the\n\"processing timescales\" of individual units within a word-level LSTM language\nmodel. This timescale-mapping method assigned long timescales to units\npreviously found to track long-range syntactic dependencies. Additionally, the\nmapping revealed a small subset of the network (less than 15% of units) with\nlong timescales and whose function had not previously been explored. We next\nprobed the functional organization of the network by examining the relationship\nbetween the processing timescale of units and their network connectivity. We\nidentified two classes of long-timescale units: \"controller\" units composed a\ndensely interconnected subnetwork and strongly projected to the rest of the\nnetwork, while \"integrator\" units showed the longest timescales in the network,\nand expressed projection profiles closer to the mean projection profile.\nAblating integrator and controller units affected model performance at\ndifferent positions within a sentence, suggesting distinctive functions of\nthese two sets of units. Finally, we tested the generalization of these results\nto a character-level LSTM model and models with different architectures. In\nsummary, we demonstrated a model-free technique for mapping the timescale\norganization in recurrent neural networks, and we applied this method to reveal\nthe timescale and functional organization of neural language models.", "published": "2020-12-12 03:52:15", "link": "http://arxiv.org/abs/2012.06717v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SenSeNet: Neural Keyphrase Generation with Document Structure", "abstract": "Keyphrase Generation (KG) is the task of generating central topics from a\ngiven document or literary work, which captures the crucial information\nnecessary to understand the content. Documents such as scientific literature\ncontain rich meta-sentence information, which represents the logical-semantic\nstructure of the documents. However, previous approaches ignore the constraints\nof document logical structure, and hence they mistakenly generate keyphrases\nfrom unimportant sentences. To address this problem, we propose a new method\ncalled Sentence Selective Network (SenSeNet) to incorporate the meta-sentence\ninductive bias into KG. In SenSeNet, we use a straight-through estimator for\nend-to-end training and incorporate weak supervision in the training of the\nsentence selection module. Experimental results show that SenSeNet can\nconsistently improve the performance of major KG models based on seq2seq\nframework, which demonstrate the effectiveness of capturing structural\ninformation and distinguishing the significance of sentences in KG task.", "published": "2020-12-12 08:21:08", "link": "http://arxiv.org/abs/2012.06754v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GDPNet: Refining Latent Multi-View Graph for Relation Extraction", "abstract": "Relation Extraction (RE) is to predict the relation type of two entities that\nare mentioned in a piece of text, e.g., a sentence or a dialogue. When the\ngiven text is long, it is challenging to identify indicative words for the\nrelation prediction. Recent advances on RE task are from BERT-based sequence\nmodeling and graph-based modeling of relationships among the tokens in the\nsequence. In this paper, we propose to construct a latent multi-view graph to\ncapture various possible relationships among tokens. We then refine this graph\nto select important words for relation prediction. Finally, the representation\nof the refined graph and the BERT-based sequence representation are\nconcatenated for relation extraction. Specifically, in our proposed GDPNet\n(Gaussian Dynamic Time Warping Pooling Net), we utilize Gaussian Graph\nGenerator (GGG) to generate edges of the multi-view graph. The graph is then\nrefined by Dynamic Time Warping Pooling (DTWPool). On DialogRE and TACRED, we\nshow that GDPNet achieves the best performance on dialogue-level RE, and\ncomparable performance with the state-of-the-arts on sentence-level RE.", "published": "2020-12-12 10:43:41", "link": "http://arxiv.org/abs/2012.06780v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AffectON: Incorporating Affect Into Dialog Generation", "abstract": "Due to its expressivity, natural language is paramount for explicit and\nimplicit affective state communication among humans. The same linguistic\ninquiry (e.g., How are you?) might induce responses with different affects\ndepending on the affective state of the conversational partner(s) and the\ncontext of the conversation. Yet, most dialog systems do not consider affect as\nconstitutive aspect of response generation. In this paper, we introduce\nAffectON, an approach for generating affective responses during inference. For\ngenerating language in a targeted affect, our approach leverages a\nprobabilistic language model and an affective space. AffectON is language model\nagnostic, since it can work with probabilities generated by any language model\n(e.g., sequence-to-sequence models, neural language models, n-grams). Hence, it\ncan be employed for both affective dialog and affective language generation. We\nexperimented with affective dialog generation and evaluated the generated text\nobjectively and subjectively. For the subjective part of the evaluation, we\ndesigned a custom user interface for rating and provided recommendations for\nthe design of such interfaces. The results, both subjective and objective\ndemonstrate that our approach is successful in pulling the generated language\ntoward the targeted affect, with little sacrifice in syntactic coherence.", "published": "2020-12-12 16:02:08", "link": "http://arxiv.org/abs/2012.06847v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Source Code Classification for Energy Efficiency in Parallel Ultra\n  Low-Power Microcontrollers", "abstract": "The analysis of source code through machine learning techniques is an\nincreasingly explored research topic aiming at increasing smartness in the\nsoftware toolchain to exploit modern architectures in the best possible way. In\nthe case of low-power, parallel embedded architectures, this means finding the\nconfiguration, for instance in terms of the number of cores, leading to minimum\nenergy consumption. Depending on the kernel to be executed, the energy optimal\nscaling configuration is not trivial. While recent work has focused on\ngeneral-purpose systems to learn and predict the best execution target in terms\nof the execution time of a snippet of code or kernel (e.g. offload OpenCL\nkernel on multicore CPU or GPU), in this work we focus on static compile-time\nfeatures to assess if they can be successfully used to predict the minimum\nenergy configuration on PULP, an ultra-low-power architecture featuring an\non-chip cluster of RISC-V processors. Experiments show that using machine\nlearning models on the source code to select the best energy scaling\nconfiguration automatically is viable and has the potential to be used in the\ncontext of automatic system configuration for energy minimisation.", "published": "2020-12-12 15:12:03", "link": "http://arxiv.org/abs/2012.06836v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Yelp Review Rating Prediction: Machine Learning and Deep Learning Models", "abstract": "We predict restaurant ratings from Yelp reviews based on Yelp Open Dataset.\nData distribution is presented, and one balanced training dataset is built. Two\nvectorizers are experimented for feature engineering. Four machine learning\nmodels including Naive Bayes, Logistic Regression, Random Forest, and Linear\nSupport Vector Machine are implemented. Four transformer-based models\ncontaining BERT, DistilBERT, RoBERTa, and XLNet are also applied. Accuracy,\nweighted F1 score, and confusion matrix are used for model evaluation. XLNet\nachieves 70% accuracy for 5-star classification compared with Logistic\nRegression with 64% accuracy.", "published": "2020-12-12 01:07:48", "link": "http://arxiv.org/abs/2012.06690v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Less Is More: Improved RNN-T Decoding Using Limited Label Context and\n  Path Merging", "abstract": "End-to-end models that condition the output label sequence on all previously\npredicted labels have emerged as popular alternatives to conventional systems\nfor automatic speech recognition (ASR). Since unique label histories correspond\nto distinct models states, such models are decoded using an approximate\nbeam-search process which produces a tree of hypotheses.\n  In this work, we study the influence of the amount of label context on the\nmodel's accuracy, and its impact on the efficiency of the decoding process. We\nfind that we can limit the context of the recurrent neural network transducer\n(RNN-T) during training to just four previous word-piece labels, without\ndegrading word error rate (WER) relative to the full-context baseline. Limiting\ncontext also provides opportunities to improve the efficiency of the\nbeam-search process during decoding by removing redundant paths from the active\nbeam, and instead retaining them in the final lattice. This path-merging scheme\ncan also be applied when decoding the baseline full-context model through an\napproximation. Overall, we find that the proposed path-merging scheme is\nextremely effective allowing us to improve oracle WERs by up to 36% over the\nbaseline, while simultaneously reducing the number of model evaluations by up\nto 5.3% without any degradation in WER.", "published": "2020-12-12 07:39:21", "link": "http://arxiv.org/abs/2012.06749v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "VoxSRC 2020: The Second VoxCeleb Speaker Recognition Challenge", "abstract": "We held the second installment of the VoxCeleb Speaker Recognition Challenge\nin conjunction with Interspeech 2020. The goal of this challenge was to assess\nhow well current speaker recognition technology is able to diarise and\nrecognize speakers in unconstrained or `in the wild' data. It consisted of: (i)\na publicly available speaker recognition and diarisation dataset from YouTube\nvideos together with ground truth annotation and standardised evaluation\nsoftware; and (ii) a virtual public challenge and workshop held at Interspeech\n2020. This paper outlines the challenge, and describes the baselines, methods\nused, and results. We conclude with a discussion of the progress over the first\ninstallment of the challenge.", "published": "2020-12-12 17:20:57", "link": "http://arxiv.org/abs/2012.06867v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "DEAAN: Disentangled Embedding and Adversarial Adaptation Network for\n  Robust Speaker Representation Learning", "abstract": "Despite speaker verification has achieved significant performance improvement\nwith the development of deep neural networks, domain mismatch is still a\nchallenging problem in this field. In this study, we propose a novel framework\nto disentangle speaker-related and domain-specific features and apply domain\nadaptation on the speaker-related feature space solely. Instead of performing\ndomain adaptation directly on the feature space where domain information is not\nremoved, using disentanglement can efficiently boost adaptation performance. To\nbe specific, our model's input speech from the source and target domains is\nfirst encoded into different latent feature spaces. The adversarial domain\nadaptation is conducted on the shared speaker-related feature space to\nencourage the property of domain-invariance. Further, we minimize the mutual\ninformation between speaker-related and domain-specific features for both\ndomains to enforce the disentanglement. Experimental results on the VOiCES\ndataset demonstrate that our proposed framework can effectively generate more\nspeaker-discriminative and domain-invariant speaker representations with a\nrelative 20.3% reduction of EER compared to the original ResNet-based system.", "published": "2020-12-12 19:46:56", "link": "http://arxiv.org/abs/2012.06896v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
