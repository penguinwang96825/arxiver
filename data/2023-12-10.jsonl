{"title": "MISCA: A Joint Model for Multiple Intent Detection and Slot Filling with\n  Intent-Slot Co-Attention", "abstract": "The research study of detecting multiple intents and filling slots is\nbecoming more popular because of its relevance to complicated real-world\nsituations. Recent advanced approaches, which are joint models based on graphs,\nmight still face two potential issues: (i) the uncertainty introduced by\nconstructing graphs based on preliminary intents and slots, which may transfer\nintent-slot correlation information to incorrect label node destinations, and\n(ii) direct incorporation of multiple intent labels for each token w.r.t.\ntoken-level intent voting might potentially lead to incorrect slot predictions,\nthereby hurting the overall performance. To address these two issues, we\npropose a joint model named MISCA. Our MISCA introduces an intent-slot\nco-attention mechanism and an underlying layer of label attention mechanism.\nThese mechanisms enable MISCA to effectively capture correlations between\nintents and slot labels, eliminating the need for graph construction. They also\nfacilitate the transfer of correlation information in both directions: from\nintents to slots and from slots to intents, through multiple levels of\nlabel-specific representations, without relying on token-level intent\ninformation. Experimental results show that MISCA outperforms previous models,\nachieving new state-of-the-art overall accuracy performances on two benchmark\ndatasets MixATIS and MixSNIPS. This highlights the effectiveness of our\nattention mechanisms.", "published": "2023-12-10 03:38:41", "link": "http://arxiv.org/abs/2312.05741v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Defendant Legal Judgment Prediction via Hierarchical Reasoning", "abstract": "Multiple defendants in a criminal fact description generally exhibit complex\ninteractions, and cannot be well handled by existing Legal Judgment Prediction\n(LJP) methods which focus on predicting judgment results (e.g., law articles,\ncharges, and terms of penalty) for single-defendant cases. To address this\nproblem, we propose the task of multi-defendant LJP, which aims to\nautomatically predict the judgment results for each defendant of\nmulti-defendant cases. Two challenges arise with the task of multi-defendant\nLJP: (1) indistinguishable judgment results among various defendants; and (2)\nthe lack of a real-world dataset for training and evaluation. To tackle the\nfirst challenge, we formalize the multi-defendant judgment process as\nhierarchical reasoning chains and introduce a multi-defendant LJP method, named\nHierarchical Reasoning Network (HRN), which follows the hierarchical reasoning\nchains to determine criminal relationships, sentencing circumstances, law\narticles, charges, and terms of penalty for each defendant. To tackle the\nsecond challenge, we collect a real-world multi-defendant LJP dataset, namely\nMultiLJP, to accelerate the relevant research in the future. Extensive\nexperiments on MultiLJP verify the effectiveness of our proposed HRN.", "published": "2023-12-10 04:46:30", "link": "http://arxiv.org/abs/2312.05762v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ASVD: Activation-aware Singular Value Decomposition for Compressing\n  Large Language Models", "abstract": "In this paper, we introduce a new post-training compression paradigm for\nLarge Language Models (LLMs) to facilitate their wider adoption. We delve into\nLLM weight low-rank decomposition, and find that the challenges of this task\nstem from the distribution variance in the LLM activations and the sensitivity\ndifference among various kinds of layers. To address these issues, we propose a\ntraining-free approach called Activation-aware Singular Value Decomposition\n(ASVD). Specifically, ASVD manages activation outliers by transforming the\nweight matrix based on the activation distribution. This transformation allows\nthe outliers in the activation matrix to be absorbed into the transformed\nweight matrix, thereby enhancing decomposition accuracy. Additionally, we\npropose an efficient iterative calibration process to optimize layer-specific\ndecomposition by addressing the varying sensitivity of different LLM layers. In\nthis way, ASVD can compress a network by 10%-30%. Based on the success of the\nlow-rank decomposition of projection matrices in the self-attention module, we\nfurther introduce ASVD to compress the KV cache. By reducing the channel\ndimension of KV activations, memory requirements for KV cache can be largely\nreduced. ASVD can further achieve 50% KV cache reductions without performance\ndrop in a training-free manner. Code is anonymously available in supplementary\nmaterials.", "published": "2023-12-10 08:41:24", "link": "http://arxiv.org/abs/2312.05821v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NovaCOMET: Open Commonsense Foundation Models with Symbolic Knowledge\n  Distillation", "abstract": "We present NovaCOMET, an open commonsense knowledge model, that combines the\nbest aspects of knowledge and general task models. Compared to previous\nknowledge models, NovaCOMET allows open-format relations enabling direct\napplication to reasoning tasks; compared to general task models like Flan-T5,\nit explicitly centers knowledge, enabling superior performance for commonsense\nreasoning.\n  NovaCOMET leverages the knowledge of opaque proprietary models to create an\nopen knowledge pipeline. First, knowledge is symbolically distilled into\nNovATOMIC, a publicly-released discrete knowledge graph which can be audited,\ncritiqued, and filtered. Next, we train NovaCOMET on NovATOMIC by fine-tuning\nan open-source pretrained model. NovaCOMET uses an open-format training\nobjective, replacing the fixed relation sets of past knowledge models, enabling\narbitrary structures within the data to serve as inputs or outputs.\n  The resulting generation model, optionally augmented with human annotation,\nmatches or exceeds comparable open task models like Flan-T5 on a range of\ncommonsense generation tasks. NovaCOMET serves as a counterexample to the\ncontemporary focus on instruction tuning only, demonstrating a distinct\nadvantage to explicitly modeling commonsense knowledge as well.", "published": "2023-12-10 19:45:24", "link": "http://arxiv.org/abs/2312.05979v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Constructing Vec-tionaries to Extract Message Features from Texts: A\n  Case Study of Moral Appeals", "abstract": "While researchers often study message features like moral content in text,\nsuch as party manifestos and social media, their quantification remains a\nchallenge. Conventional human coding struggles with scalability and intercoder\nreliability. While dictionary-based methods are cost-effective and\ncomputationally efficient, they often lack contextual sensitivity and are\nlimited by the vocabularies developed for the original applications. In this\npaper, we present an approach to construct vec-tionary measurement tools that\nboost validated dictionaries with word embeddings through nonlinear\noptimization. By harnessing semantic relationships encoded by embeddings,\nvec-tionaries improve the measurement of message features from text, especially\nthose in short format, by expanding the applicability of original vocabularies\nto other contexts. Importantly, a vec-tionary can produce additional metrics to\ncapture the valence and ambivalence of a message feature beyond its strength in\ntexts. Using moral content in tweets as a case study, we illustrate the steps\nto construct the moral foundations vec-tionary, showcasing its ability to\nprocess texts missed by conventional dictionaries and word embedding methods\nand to produce measurements better aligned with crowdsourced human assessments.\nFurthermore, additional metrics from the vec-tionary unveiled unique insights\nthat facilitated predicting outcomes such as message retransmission.", "published": "2023-12-10 20:37:29", "link": "http://arxiv.org/abs/2312.05990v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Models on Lexical Semantic Change Detection: An\n  Evaluation", "abstract": "Lexical Semantic Change Detection stands out as one of the few areas where\nLarge Language Models (LLMs) have not been extensively involved. Traditional\nmethods like PPMI, and SGNS remain prevalent in research, alongside newer\nBERT-based approaches. Despite the comprehensive coverage of various natural\nlanguage processing domains by LLMs, there is a notable scarcity of literature\nconcerning their application in this specific realm. In this work, we seek to\nbridge this gap by introducing LLMs into the domain of Lexical Semantic Change\nDetection. Our work presents novel prompting solutions and a comprehensive\nevaluation that spans all three generations of language models, contributing to\nthe exploration of LLMs in this research area.", "published": "2023-12-10 21:26:35", "link": "http://arxiv.org/abs/2312.06002v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploiting Representation Bias for Data Distillation in Abstractive Text\n  Summarization", "abstract": "Abstractive text summarization is surging with the number of training samples\nto cater to the needs of the deep learning models. These models tend to exploit\nthe training data representations to attain superior performance by improving\nthe quantitative element of the resultant summary. However, increasing the size\nof the training set may not always be the ideal solution to maximize the\nperformance, and therefore, a need to revisit the quality of training samples\nand the learning protocol of deep learning models is a must. In this paper, we\naim to discretize the vector space of the abstractive text summarization models\nto understand the characteristics learned between the input embedding space and\nthe models' encoder space. We show that deep models fail to capture the\ndiversity of the input space. Further, the distribution of data points on the\nencoder space indicates that an unchecked increase in the training samples does\nnot add value; rather, a tear-down of data samples is highly needed to make the\nmodels focus on variability and faithfulness. We employ clustering techniques\nto learn the diversity of a model's sample space and how data points are mapped\nfrom the embedding space to the encoder space and vice versa. Further, we\ndevise a metric to filter out redundant data points to make the model more\nrobust and less data hungry. We benchmark our proposed method using\nquantitative metrics, such as Rouge, and qualitative metrics, such as\nBERTScore, FEQA and Pyramid score. We also quantify the reasons that inhibit\nthe models from learning the diversity from the varied input samples.", "published": "2023-12-10 22:30:03", "link": "http://arxiv.org/abs/2312.06022v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Arabic Handwritten Text Line Dataset", "abstract": "Segmentation of Arabic manuscripts into lines of text and words is an\nimportant step to make recognition systems more efficient and accurate. The\nproblem of segmentation into text lines is solved since there are carefully\nannotated dataset dedicated to this task. However, To the best of our\nknowledge, there are no dataset annotating the word position of Arabic texts.\nIn this paper, we present a new dataset specifically designed for historical\nArabic script in which we annotate position in word level.", "published": "2023-12-10 14:32:25", "link": "http://arxiv.org/abs/2312.07573v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evidence-based Interpretable Open-domain Fact-checking with Large\n  Language Models", "abstract": "Universal fact-checking systems for real-world claims face significant\nchallenges in gathering valid and sufficient real-time evidence and making\nreasoned decisions. In this work, we introduce the Open-domain Explainable\nFact-checking (OE-Fact) system for claim-checking in real-world scenarios. The\nOE-Fact system can leverage the powerful understanding and reasoning\ncapabilities of large language models (LLMs) to validate claims and generate\ncausal explanations for fact-checking decisions. To adapt the traditional\nthree-module fact-checking framework to the open domain setting, we first\nretrieve claim-related information as relevant evidence from open websites.\nAfter that, we retain the evidence relevant to the claim through LLM and\nsimilarity calculation for subsequent verification. We evaluate the performance\nof our adapted three-module OE-Fact system on the Fact Extraction and\nVerification (FEVER) dataset. Experimental results show that our OE-Fact system\noutperforms general fact-checking baseline systems in both closed- and\nopen-domain scenarios, ensuring stable and accurate verdicts while providing\nconcise and convincing real-time explanations for fact-checking decisions.", "published": "2023-12-10 09:27:50", "link": "http://arxiv.org/abs/2312.05834v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mutual Enhancement of Large and Small Language Models with Cross-Silo\n  Knowledge Transfer", "abstract": "While large language models (LLMs) are empowered with broad knowledge, their\ntask-specific performance is often suboptimal. It necessitates fine-tuning LLMs\nwith task-specific data, but such data may be inaccessible due to privacy\nconcerns. In this paper, we propose a novel approach to enhance LLMs with\nsmaller language models (SLMs) that are trained on clients using their private\ntask-specific data. To enable mutual enhancement between LLMs and SLMs, we\npropose CrossLM, where the SLMs promote the LLM to generate task-specific\nhigh-quality data, and both the LLM and SLMs are enhanced with the generated\ndata. We evaluate CrossLM using publicly accessible language models across a\nrange of benchmark tasks. The results demonstrate that CrossLM significantly\nenhances the task-specific performance of SLMs on clients and the LLM on the\ncloud server simultaneously while preserving the LLM's generalization\ncapability.", "published": "2023-12-10 09:52:32", "link": "http://arxiv.org/abs/2312.05842v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Perceiving University Student's Opinions from Google App Reviews", "abstract": "Google app market captures the school of thought of users from every corner\nof the globe via ratings and text reviews, in a multilinguistic arena. The\npotential information from the reviews cannot be extracted manually, due to its\nexponential growth. So, Sentiment analysis, by machine learning and deep\nlearning algorithms employing NLP, explicitly uncovers and interprets the\nemotions. This study performs the sentiment classification of the app reviews\nand identifies the university student's behavior towards the app market via\nexploratory analysis. We applied machine learning algorithms using the TP, TF,\nand TF IDF text representation scheme and evaluated its performance on Bagging,\nan ensemble learning method. We used word embedding, Glove, on the deep\nlearning paradigms. Our model was trained on Google app reviews and tested on\nStudent's App Reviews(SAR). The various combinations of these algorithms were\ncompared amongst each other using F score and accuracy and inferences were\nhighlighted graphically. SVM, amongst other classifiers, gave fruitful\naccuracy(93.41%), F score(89%) on bigram and TF IDF scheme. Bagging enhanced\nthe performance of LR and NB with accuracy of 87.88% and 86.69% and F score of\n86% and 78% respectively. Overall, LSTM on Glove embedding recorded the highest\naccuracy(95.2%) and F score(88%).", "published": "2023-12-10 12:34:30", "link": "http://arxiv.org/abs/2312.06705v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Speech and Text-Based Emotion Recognizer", "abstract": "Affective computing is a field of study that focuses on developing systems\nand technologies that can understand, interpret, and respond to human emotions.\nSpeech Emotion Recognition (SER), in particular, has got a lot of attention\nfrom researchers in the recent past. However, in many cases, the publicly\navailable datasets, used for training and evaluation, are scarce and imbalanced\nacross the emotion labels. In this work, we focused on building a balanced\ncorpus from these publicly available datasets by combining these datasets as\nwell as employing various speech data augmentation techniques. Furthermore, we\nexperimented with different architectures for speech emotion recognition. Our\nbest system, a multi-modal speech, and text-based model, provides a performance\nof UA(Unweighed Accuracy) + WA (Weighed Accuracy) of 157.57 compared to the\nbaseline algorithm performance of 119.66", "published": "2023-12-10 05:17:39", "link": "http://arxiv.org/abs/2312.11503v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Beyond Gradient and Priors in Privacy Attacks: Leveraging Pooler Layer\n  Inputs of Language Models in Federated Learning", "abstract": "Language models trained via federated learning (FL) demonstrate impressive\ncapabilities in handling complex tasks while protecting user privacy. Recent\nstudies indicate that leveraging gradient information and prior knowledge can\npotentially reveal training samples within FL setting. However, these\ninvestigations have overlooked the potential privacy risks tied to the\nintrinsic architecture of the models. This paper presents a two-stage privacy\nattack strategy that targets the vulnerabilities in the architecture of\ncontemporary language models, significantly enhancing attack performance by\ninitially recovering certain feature directions as additional supervisory\nsignals. Our comparative experiments demonstrate superior attack performance\nacross various datasets and scenarios, highlighting the privacy leakage risk\nassociated with the increasingly complex architectures of language models. We\ncall for the community to recognize and address these potential privacy risks\nin designing large language models.", "published": "2023-12-10 01:19:59", "link": "http://arxiv.org/abs/2312.05720v4", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs", "abstract": "Large language models (LLMs) encapsulate a vast amount of factual information\nwithin their pre-trained weights, as evidenced by their ability to answer\ndiverse questions across different domains. However, this knowledge is\ninherently limited, relying heavily on the characteristics of the training\ndata. Consequently, using external datasets to incorporate new information or\nrefine the capabilities of LLMs on previously seen information poses a\nsignificant challenge. In this study, we compare two common approaches:\nunsupervised fine-tuning and retrieval-augmented generation (RAG). We evaluate\nboth approaches on a variety of knowledge-intensive tasks across different\ntopics. Our findings reveal that while unsupervised fine-tuning offers some\nimprovement, RAG consistently outperforms it, both for existing knowledge\nencountered during training and entirely new knowledge. Moreover, we find that\nLLMs struggle to learn new factual information through unsupervised\nfine-tuning, and that exposing them to numerous variations of the same fact\nduring training could alleviate this problem.", "published": "2023-12-10 16:52:00", "link": "http://arxiv.org/abs/2312.05934v3", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "ConSequence: Synthesizing Logically Constrained Sequences for Electronic\n  Health Record Generation", "abstract": "Generative models can produce synthetic patient records for analytical tasks\nwhen real data is unavailable or limited. However, current methods struggle\nwith adhering to domain-specific knowledge and removing invalid data. We\npresent ConSequence, an effective approach to integrating domain knowledge into\nsequential generative neural network outputs. Our rule-based formulation\nincludes temporal aggregation and antecedent evaluation modules, ensured by an\nefficient matrix multiplication formulation, to satisfy hard and soft logical\nconstraints across time steps. Existing constraint methods often fail to\nguarantee constraint satisfaction, lack the ability to handle temporal\nconstraints, and hinder the learning and computational efficiency of the model.\nIn contrast, our approach efficiently handles all types of constraints with\nguaranteed logical coherence. We demonstrate ConSequence's effectiveness in\ngenerating electronic health records, outperforming competitors in achieving\ncomplete temporal and spatial constraint satisfaction without compromising\nruntime performance or generative quality. Specifically, ConSequence\nsuccessfully prevents all rule violations while improving the model quality in\nreducing its test perplexity by 5% and incurring less than a 13% slowdown in\ngeneration speed compared to an unconstrained model.", "published": "2023-12-10 18:43:37", "link": "http://arxiv.org/abs/2312.05964v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Early ChatGPT User Portrait through the Lens of Data", "abstract": "Since its launch, ChatGPT has achieved remarkable success as a versatile\nconversational AI platform, drawing millions of users worldwide and garnering\nwidespread recognition across academic, industrial, and general communities.\nThis paper aims to point a portrait of early GPT users and understand how they\nevolved. Specific questions include their topics of interest and their\npotential careers; and how this changes over time. We conduct a detailed\nanalysis of real-world ChatGPT datasets with multi-turn conversations between\nusers and ChatGPT. Through a multi-pronged approach, we quantify conversation\ndynamics by examining the number of turns, then gauge sentiment to understand\nuser sentiment variations, and finally employ Latent Dirichlet Allocation (LDA)\nto discern overarching topics within the conversation. By understanding shifts\nin user demographics and interests, we aim to shed light on the changing nature\nof human-AI interaction and anticipate future trends in user engagement with\nlanguage models.", "published": "2023-12-10 07:08:51", "link": "http://arxiv.org/abs/2312.10078v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.HC"}
{"title": "The performance of multiple language models in identifying offensive\n  language on social media", "abstract": "Text classification is an important topic in the field of natural language\nprocessing. It has been preliminarily applied in information retrieval, digital\nlibrary, automatic abstracting, text filtering, word semantic discrimination\nand many other fields. The aim of this research is to use a variety of\nalgorithms to test the ability to identify offensive posts and evaluate their\nperformance against a variety of assessment methods. The motivation for this\nproject is to reduce the harm of these languages to human censors by automating\nthe screening of offending posts. The field is a new one, and despite much\ninterest in the past two years, there has been no focus on the object of the\noffence. Through the experiment of this project, it should inspire future\nresearch on identification methods as well as identification content.", "published": "2023-12-10 18:58:26", "link": "http://arxiv.org/abs/2312.11504v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Voice Activity Detection (VAD) in Noisy Environments", "abstract": "In the realm of digital audio processing, Voice Activity Detection (VAD)\nplays a pivotal role in distinguishing speech from non-speech elements, a task\nthat becomes increasingly complex in noisy environments. This paper details the\ndevelopment and implementation of a VAD system, specifically engineered to\nmaintain high accuracy in the presence of various ambient noises. We introduce\na novel algorithm enhanced with a specially designed filtering technique,\neffectively isolating speech even amidst diverse background sounds. Our\ncomprehensive testing and validation demonstrate the system's robustness,\nhighlighting its capability to discern speech from noise with remarkable\nprecision. The exploration delves into: (1) the core principles underpinning\nVAD and its crucial role in modern audio processing; (2) the methodologies we\nemployed to filter ambient noise; and (3) a presentation of evidence affirming\nour system's superior performance in noisy conditions.", "published": "2023-12-10 08:17:21", "link": "http://arxiv.org/abs/2312.05815v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Neural Speech Embeddings for Speech Synthesis Based on Deep Generative\n  Networks", "abstract": "Brain-to-speech technology represents a fusion of interdisciplinary\napplications encompassing fields of artificial intelligence, brain-computer\ninterfaces, and speech synthesis. Neural representation learning based\nintention decoding and speech synthesis directly connects the neural activity\nto the means of human linguistic communication, which may greatly enhance the\nnaturalness of communication. With the current discoveries on representation\nlearning and the development of the speech synthesis technologies, direct\ntranslation of brain signals into speech has shown great promise. Especially,\nthe processed input features and neural speech embeddings which are given to\nthe neural network play a significant role in the overall performance when\nusing deep generative models for speech generation from brain signals. In this\npaper, we introduce the current brain-to-speech technology with the possibility\nof speech synthesis from brain signals, which may ultimately facilitate\ninnovation in non-verbal communication. Also, we perform comprehensive analysis\non the neural features and neural speech embeddings underlying the\nneurophysiological activation while performing speech, which may play a\nsignificant role in the speech synthesis works.", "published": "2023-12-10 08:12:08", "link": "http://arxiv.org/abs/2312.05814v2", "categories": ["cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.AI"}
{"title": "mir_ref: A Representation Evaluation Framework for Music Information\n  Retrieval Tasks", "abstract": "Music Information Retrieval (MIR) research is increasingly leveraging\nrepresentation learning to obtain more compact, powerful music audio\nrepresentations for various downstream MIR tasks. However, current\nrepresentation evaluation methods are fragmented due to discrepancies in audio\nand label preprocessing, downstream model and metric implementations, data\navailability, and computational resources, often leading to inconsistent and\nlimited results. In this work, we introduce mir_ref, an MIR Representation\nEvaluation Framework focused on seamless, transparent, local-first experiment\norchestration to support representation development. It features\nimplementations of a variety of components such as MIR datasets, tasks,\nembedding models, and tools for result analysis and visualization, while\nfacilitating the implementation of custom components. To demonstrate its\nutility, we use it to conduct an extensive evaluation of several embedding\nmodels across various tasks and datasets, including evaluating their robustness\nto various audio perturbations and the ease of extracting relevant information\nfrom them.", "published": "2023-12-10 20:57:01", "link": "http://arxiv.org/abs/2312.05994v2", "categories": ["cs.SD", "cs.IR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Practical Survey on Emerging Threats from AI-driven Voice Attacks: How\n  Vulnerable are Commercial Voice Control Systems?", "abstract": "The emergence of Artificial Intelligence (AI)-driven audio attacks has\nrevealed new security vulnerabilities in voice control systems. While\nresearchers have introduced a multitude of attack strategies targeting voice\ncontrol systems (VCS), the continual advancements of VCS have diminished the\nimpact of many such attacks. Recognizing this dynamic landscape, our study\nendeavors to comprehensively assess the resilience of commercial voice control\nsystems against a spectrum of malicious audio attacks. Through extensive\nexperimentation, we evaluate six prominent attack techniques across a\ncollection of voice control interfaces and devices. Contrary to prevailing\nnarratives, our results suggest that commercial voice control systems exhibit\nenhanced resistance to existing threats. Particularly, our research highlights\nthe ineffectiveness of white-box attacks in black-box scenarios. Furthermore,\nthe adversaries encounter substantial obstacles in obtaining precise gradient\nestimations during query-based interactions with commercial systems, such as\nApple Siri and Samsung Bixby. Meanwhile, we find that current defense\nstrategies are not completely immune to advanced attacks. Our findings\ncontribute valuable insights for enhancing defense mechanisms in VCS. Through\nthis survey, we aim to raise awareness within the academic community about the\nsecurity concerns of VCS and advocate for continued research in this crucial\narea.", "published": "2023-12-10 21:51:13", "link": "http://arxiv.org/abs/2312.06010v2", "categories": ["cs.CR", "cs.SD", "eess.AS"], "primary_category": "cs.CR"}
