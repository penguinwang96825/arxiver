{"title": "MedDM:LLM-executable clinical guidance tree for clinical decision-making", "abstract": "It is becoming increasingly emphasis on the importance of LLM participating\nin clinical diagnosis decision-making. However, the low specialization refers\nto that current medical LLMs can not provide specific medical advice, which are\nmore like a medical Q\\&A. And there is no suitable clinical guidance tree data\nset that can be used directly with LLM. To address this issue, we first propose\nLLM-executavle clinical guidance tree(CGT), which can be directly used by large\nlanguage models, and construct medical diagnostic decision-making dataset\n(MedDM), from flowcharts in clinical practice guidelines. We propose an\napproach to screen flowcharts from medical literature, followed by their\nidentification and conversion into standardized diagnostic decision trees.\nConstructed a knowledge base with 1202 decision trees, which came from 5000\nmedical literature and covered 12 hospital departments, including internal\nmedicine, surgery, psychiatry, and over 500 diseases.Moreover, we propose a\nmethod for reasoning on LLM-executable CGT and a Patient-LLM multi-turn\ndialogue framework.", "published": "2023-12-05 02:44:07", "link": "http://arxiv.org/abs/2312.02441v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Empathy and Distress Detection using Ensembles of Transformer Models", "abstract": "This paper presents our approach for the WASSA 2023 Empathy, Emotion and\nPersonality Shared Task. Empathy and distress are human feelings that are\nimplicitly expressed in natural discourses. Empathy and distress detection are\ncrucial challenges in Natural Language Processing that can aid our\nunderstanding of conversations. The provided dataset consists of several\nlong-text examples in the English language, with each example associated with a\nnumeric score for empathy and distress. We experiment with several BERT-based\nmodels as a part of our approach. We also try various ensemble methods. Our\nfinal submission has a Pearson's r score of 0.346, placing us third in the\nempathy and distress detection subtask.", "published": "2023-12-05 08:50:34", "link": "http://arxiv.org/abs/2312.02578v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Text Intimacy Analysis using Ensembles of Multilingual Transformers", "abstract": "Intimacy estimation of a given text has recently gained importance due to the\nincrease in direct interaction of NLP systems with humans. Intimacy is an\nimportant aspect of natural language and has a substantial impact on our\neveryday communication. Thus the level of intimacy can provide us with deeper\ninsights and richer semantics of conversations. In this paper, we present our\nwork on the SemEval shared task 9 on predicting the level of intimacy for the\ngiven text. The dataset consists of tweets in ten languages, out of which only\nsix are available in the training dataset. We conduct several experiments and\nshow that an ensemble of multilingual models along with a language-specific\nmonolingual model has the best performance. We also evaluate other data\naugmentation methods such as translation and present the results. Lastly, we\nstudy the results thoroughly and present some noteworthy insights into this\nproblem.", "published": "2023-12-05 09:04:22", "link": "http://arxiv.org/abs/2312.02590v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLMs for Multi-Modal Knowledge Extraction and Analysis in\n  Intelligence/Safety-Critical Applications", "abstract": "Large Language Models have seen rapid progress in capability in recent years;\nthis progress has been accelerating and their capabilities, measured by various\nbenchmarks, are beginning to approach those of humans. There is a strong demand\nto use such models in a wide variety of applications but, due to unresolved\nvulnerabilities and limitations, great care needs to be used before applying\nthem to intelligence and safety-critical applications. This paper reviews\nrecent literature related to LLM assessment and vulnerabilities to synthesize\nthe current research landscape and to help understand what advances are most\ncritical to enable use of of these technologies in intelligence and\nsafety-critical applications. The vulnerabilities are broken down into ten\nhigh-level categories and overlaid onto a high-level life cycle of an LLM. Some\ngeneral categories of mitigations are reviewed.", "published": "2023-12-05 19:04:50", "link": "http://arxiv.org/abs/2312.03088v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Understanding Environmental Posts: Sentiment and Emotion Analysis of\n  Social Media Data", "abstract": "Social media is now the predominant source of information due to the\navailability of immediate public response. As a result, social media data has\nbecome a valuable resource for comprehending public sentiments. Studies have\nshown that it can amplify ideas and influence public sentiments. This study\nanalyzes the public perception of climate change and the environment over a\ndecade from 2014 to 2023. Using the Pointwise Mutual Information (PMI)\nalgorithm, we identify sentiment and explore prevailing emotions expressed\nwithin environmental tweets across various social media platforms, namely\nTwitter, Reddit, and YouTube. Accuracy on a human-annotated dataset was 0.65,\nhigher than Vader score but lower than that of an expert rater (0.90). Our\nfindings suggest that negative environmental tweets are far more common than\npositive or neutral ones. Climate change, air quality, emissions, plastic, and\nrecycling are the most discussed topics on all social media platforms,\nhighlighting its huge global concern. The most common emotions in environmental\ntweets are fear, trust, and anticipation, demonstrating public reactions wide\nand complex nature. By identifying patterns and trends in opinions related to\nthe environment, we hope to provide insights that can help raise awareness\nregarding environmental issues, inform the development of interventions, and\nadapt further actions to meet environmental challenges.", "published": "2023-12-05 19:26:28", "link": "http://arxiv.org/abs/2312.03095v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Assertion Enhanced Few-Shot Learning: Instructive Technique for Large\n  Language Models to Generate Educational Explanations", "abstract": "Human educators possess an intrinsic ability to anticipate and seek\neducational explanations from students, which drives them to pose\nthought-provoking questions when students cannot articulate these explanations\nindependently. We aim to imbue Intelligent Tutoring Systems with this ability\nusing few-shot learning capability of Large Language Models. Our work proposes\na novel prompting technique, Assertion Enhanced Few-Shot Learning, to\nfacilitate the generation of accurate, detailed oriented educational\nexplanations. Our central hypothesis is that, in educational domain, few-shot\ndemonstrations are necessary but not a sufficient condition for quality\nexplanation generation. We conducted a study involving 12 in-service teachers,\ncomparing our approach to Traditional Few-Shot Learning. The results show that\nAssertion Enhanced Few-Shot Learning improves explanation accuracy by 15% and\nyields higher-quality explanations, as evaluated by teachers. We also conduct a\nqualitative ablation study to factor the impact of assertions to provide\neducator-friendly prompting guidelines for generating explanations in their\ndomain of interest.", "published": "2023-12-05 20:41:34", "link": "http://arxiv.org/abs/2312.03122v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Online Data Mixing For Language Model Pre-Training", "abstract": "The data used to pretrain large language models has a decisive impact on a\nmodel's downstream performance, which has led to a large body of work on data\nselection methods that aim to automatically determine the most suitable data to\nuse for pretraining. Existing data selection methods suffer from slow and\ncomputationally expensive processes, a problem amplified by the increasing size\nof models and of pretraining datasets. Data mixing, on the other hand, reduces\nthe complexity of data selection by grouping data points together and\ndetermining sampling probabilities across entire groups. However, data mixing\nproportions are typically fixed before training and therefore cannot adapt to\nchanging training dynamics. To address these limitations, we develop an\nefficient algorithm for Online Data Mixing (ODM) that combines elements from\nboth data selection and data mixing. Based on multi-armed bandit algorithms,\nour online approach optimizes the data mixing proportions during training.\nRemarkably, our method trains a model that reaches the final perplexity of the\nnext best method with 19\\% fewer training iterations, and improves performance\non the 5-shot MMLU benchmark by 1.9% relative accuracy, while adding negligible\nwall-clock time during pretraining.", "published": "2023-12-05 00:42:35", "link": "http://arxiv.org/abs/2312.02406v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Visually Grounded Language Learning: a review of language games,\n  datasets, tasks, and models", "abstract": "In recent years, several machine learning models have been proposed. They are\ntrained with a language modelling objective on large-scale text-only data. With\nsuch pretraining, they can achieve impressive results on many Natural Language\nUnderstanding and Generation tasks. However, many facets of meaning cannot be\nlearned by ``listening to the radio\" only. In the literature, many\nVision+Language (V+L) tasks have been defined with the aim of creating models\nthat can ground symbols in the visual modality. In this work, we provide a\nsystematic literature review of several tasks and models proposed in the V+L\nfield. We rely on Wittgenstein's idea of `language games' to categorise such\ntasks into 3 different families: 1) discriminative games, 2) generative games,\nand 3) interactive games. Our analysis of the literature provides evidence that\nfuture work should be focusing on interactive games where communication in\nNatural Language is important to resolve ambiguities about object referents and\naction plans and that physical embodiment is essential to understand the\nsemantics of situations and events. Overall, these represent key requirements\nfor developing grounded meanings in neural models.", "published": "2023-12-05 02:17:29", "link": "http://arxiv.org/abs/2312.02431v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MUFFIN: Curating Multi-Faceted Instructions for Improving\n  Instruction-Following", "abstract": "In the realm of large language models (LLMs), enhancing instruction-following\ncapability often involves curating expansive training data. This is achieved\nthrough two primary schemes: i) Scaling-Inputs: Amplifying (input, output)\npairs per task instruction, aiming for better instruction adherence. ii)\nScaling Input-Free Tasks: Enlarging tasks, each composed of an (instruction,\noutput) pair (without requiring a separate input anymore). However, LLMs under\nScaling-Inputs tend to be overly sensitive to inputs, leading to\nmisinterpretation or non-compliance with instructions. Conversely, Scaling\nInput-Free Tasks demands a substantial number of tasks but is less effective in\ninstruction following when dealing with instances in Scaling-Inputs. This work\nintroduces MUFFIN, a new scheme of instruction-following dataset curation.\nSpecifically, we automatically Scale Tasks per Input by diversifying these\ntasks with various input facets. Experimental results across four zero-shot\nbenchmarks, spanning both Scaling-Inputs and Scaling Input-Free Tasks schemes,\nreveal that LLMs, at various scales, trained on MUFFIN generally demonstrate\nsuperior instruction-following capabilities compared to those trained on the\ntwo aforementioned schemes.", "published": "2023-12-05 02:32:08", "link": "http://arxiv.org/abs/2312.02436v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MKA: A Scalable Medical Knowledge Assisted Mechanism for Generative\n  Models on Medical Conversation Tasks", "abstract": "Using natural language processing (NLP) technologies to develop medical\nchatbots makes the diagnosis of the patient more convenient and efficient,\nwhich is a typical application in healthcare AI. Because of its importance,\nlots of research have been come out. Recently, the neural generative models\nhave shown their impressive ability as the core of chatbot, while it cannot\nscale well when directly applied to medical conversation due to the lack of\nmedical-specific knowledge. To address the limitation, a scalable Medical\nKnowledge Assisted mechanism, MKA, is proposed in this paper. The mechanism\naims to assist general neural generative models to achieve better performance\non the medical conversation task. The medical-specific knowledge graph is\ndesigned within the mechanism, which contains 6 types of medical-related\ninformation, including department, drug, check, symptom, disease, food.\nBesides, the specific token concatenation policy is defined to effectively\ninject medical information into the input data. Evaluation of our method is\ncarried out on two typical medical datasets, MedDG and MedDialog-CN. The\nevaluation results demonstrate that models combined with our mechanism\noutperform original methods in multiple automatic evaluation metrics. Besides,\nMKA-Bert-GPT achieves state-of-the-art performance. The open-sourced codes are\npublic:\nhttps://github.com/LIANGKE23/Knowledge_Assisted_Medical_Dialogue_Generation_Mechanism", "published": "2023-12-05 04:55:54", "link": "http://arxiv.org/abs/2312.02496v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DRAFT: Dense Retrieval Augmented Few-shot Topic classifier Framework", "abstract": "With the growing volume of diverse information, the demand for classifying\narbitrary topics has become increasingly critical. To address this challenge,\nwe introduce DRAFT, a simple framework designed to train a classifier for\nfew-shot topic classification. DRAFT uses a few examples of a specific topic as\nqueries to construct Customized dataset with a dense retriever model.\nMulti-query retrieval (MQR) algorithm, which effectively handles multiple\nqueries related to a specific topic, is applied to construct the Customized\ndataset. Subsequently, we fine-tune a classifier using the Customized dataset\nto identify the topic. To demonstrate the efficacy of our proposed approach, we\nconduct evaluations on both widely used classification benchmark datasets and\nmanually constructed datasets with 291 diverse topics, which simulate diverse\ncontents encountered in real-world applications. DRAFT shows competitive or\nsuperior performance compared to baselines that use in-context learning, such\nas GPT-3 175B and InstructGPT 175B, on few-shot topic classification tasks\ndespite having 177 times fewer parameters, demonstrating its effectiveness.", "published": "2023-12-05 06:28:45", "link": "http://arxiv.org/abs/2312.02532v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "DemaFormer: Damped Exponential Moving Average Transformer with\n  Energy-Based Modeling for Temporal Language Grounding", "abstract": "Temporal Language Grounding seeks to localize video moments that semantically\ncorrespond to a natural language query. Recent advances employ the attention\nmechanism to learn the relations between video moments and the text query.\nHowever, naive attention might not be able to appropriately capture such\nrelations, resulting in ineffective distributions where target video moments\nare difficult to separate from the remaining ones. To resolve the issue, we\npropose an energy-based model framework to explicitly learn moment-query\ndistributions. Moreover, we propose DemaFormer, a novel Transformer-based\narchitecture that utilizes exponential moving average with a learnable damping\nfactor to effectively encode moment-query inputs. Comprehensive experiments on\nfour public temporal language grounding datasets showcase the superiority of\nour methods over the state-of-the-art baselines.", "published": "2023-12-05 07:37:21", "link": "http://arxiv.org/abs/2312.02549v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "ULMA: Unified Language Model Alignment with Human Demonstration and\n  Point-wise Preference", "abstract": "Aligning language models to human expectations, e.g., being helpful and\nharmless, has become a pressing challenge for large language models. A typical\nalignment procedure consists of supervised fine-tuning and preference learning.\nMost preference learning methods, such as RLHF and DPO, depend on pairwise\npreference data, which inadequately address scenarios where human feedback is\npoint-wise, leading to potential information loss and suboptimal performance.\nAddressing this gap, we introduce Point-wise Direct Preference Optimization, a\nnovel preference learning method designed to harness point-wise feedback\neffectively. Our work also uncovers a novel connection between supervised\nfine-tuning and point-wise preference learning, culminating in Unified Language\nModel Alignment, a single-step method that unifies the alignment with human\ndemonstrations and point-wise preferences. Extensive experiments on point-wise\npreference datasets with binary or continuous labels validate the effectiveness\nof our methods. Our code and a new dataset with high-quality demonstration\nsamples on harmlessness are released.", "published": "2023-12-05 07:52:12", "link": "http://arxiv.org/abs/2312.02554v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Impact of Tokenization on LLaMa Russian Adaptation", "abstract": "Latest instruction-tuned large language models (LLM) show great results on\nvarious tasks, however, they often face performance degradation for non-English\ninput. There is evidence that the reason lies in inefficient tokenization\ncaused by low language representation in pre-training data which hinders the\ncomprehension of non-English instructions, limiting the potential of target\nlanguage instruction-tuning. In this work we investigate the possibility of\naddressing the issue with vocabulary substitution in the context of LLaMa\nRussian language adaptation. We explore three variants of vocabulary adaptation\nand test their performance on Saiga instruction-tuning and fine-tuning on\nRussian Super Glue benchmark. The results of automatic evaluation show that\nvocabulary substitution not only improves the model's quality in Russian but\nalso accelerates fine-tuning (35%) and inference (up to 60%) while reducing\nmemory consumption. Additional human evaluation of the instruction-tuned models\ndemonstrates that models with Russian-adapted vocabulary generate answers with\nhigher user preference than the original Saiga-LLaMa model.", "published": "2023-12-05 09:16:03", "link": "http://arxiv.org/abs/2312.02598v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Prompt Optimization via Adversarial In-Context Learning", "abstract": "We propose a new method, Adversarial In-Context Learning (adv-ICL), to\noptimize prompt for in-context learning (ICL) by employing one LLM as a\ngenerator, another as a discriminator, and a third as a prompt modifier. As in\ntraditional adversarial learning, adv-ICL is implemented as a two-player game\nbetween the generator and discriminator, where the generator tries to generate\nrealistic enough output to fool the discriminator. In each round, given an\ninput prefixed by task instructions and several exemplars, the generator\nproduces an output. The discriminator is then tasked with classifying the\ngenerator input-output pair as model-generated or real data. Based on the\ndiscriminator loss, the prompt modifier proposes possible edits to the\ngenerator and discriminator prompts, and the edits that most improve the\nadversarial loss are selected. We show that adv-ICL results in significant\nimprovements over state-of-the-art prompt optimization techniques for both open\nand closed-source models on 11 generation and classification tasks including\nsummarization, arithmetic reasoning, machine translation, data-to-text\ngeneration, and the MMLU and big-bench hard benchmarks. In addition, because\nour method uses pre-trained models and updates only prompts rather than model\nparameters, it is computationally efficient, easy to extend to any LLM and\ntask, and effective in low-resource settings.", "published": "2023-12-05 09:44:45", "link": "http://arxiv.org/abs/2312.02614v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Large Knowledge Model: Perspectives and Challenges", "abstract": "Humankind's understanding of the world is fundamentally linked to our\nperception and cognition, with \\emph{human languages} serving as one of the\nmajor carriers of \\emph{world knowledge}. In this vein, \\emph{Large Language\nModels} (LLMs) like ChatGPT epitomize the pre-training of extensive,\nsequence-based world knowledge into neural networks, facilitating the\nprocessing and manipulation of this knowledge in a parametric space. This\narticle explores large models through the lens of \"knowledge\". We initially\ninvestigate the role of symbolic knowledge such as Knowledge Graphs (KGs) in\nenhancing LLMs, covering aspects like knowledge-augmented language model,\nstructure-inducing pre-training, knowledgeable prompts, structured CoT,\nknowledge editing, semantic tools for LLM and knowledgeable AI agents.\nSubsequently, we examine how LLMs can boost traditional symbolic knowledge\nbases, encompassing aspects like using LLM as KG builder and controller,\nstructured knowledge pretraining, and LLM-enhanced symbolic reasoning.\nConsidering the intricate nature of human knowledge, we advocate for the\ncreation of \\emph{Large Knowledge Models} (LKM), specifically engineered to\nmanage diversified spectrum of knowledge structures. This promising undertaking\nwould entail several key challenges, such as disentangling knowledge base from\nlanguage models, cognitive alignment with human knowledge, integration of\nperception and cognition, and building large commonsense models for interacting\nwith physical world, among others. We finally propose a five-\"A\" principle to\ndistinguish the concept of LKM.", "published": "2023-12-05 12:07:30", "link": "http://arxiv.org/abs/2312.02706v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Towards Measuring Representational Similarity of Large Language Models", "abstract": "Understanding the similarity of the numerous released large language models\n(LLMs) has many uses, e.g., simplifying model selection, detecting illegal\nmodel reuse, and advancing our understanding of what makes LLMs perform well.\nIn this work, we measure the similarity of representations of a set of LLMs\nwith 7B parameters. Our results suggest that some LLMs are substantially\ndifferent from others. We identify challenges of using representational\nsimilarity measures that suggest the need of careful study of similarity scores\nto avoid false conclusions.", "published": "2023-12-05 12:48:04", "link": "http://arxiv.org/abs/2312.02730v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Compositional Generalization for Data-to-Text Generation", "abstract": "Data-to-text generation involves transforming structured data, often\nrepresented as predicate-argument tuples, into coherent textual descriptions.\nDespite recent advances, systems still struggle when confronted with unseen\ncombinations of predicates, producing unfaithful descriptions (e.g.\nhallucinations or omissions). We refer to this issue as compositional\ngeneralisation, and it encouraged us to create a benchmark for assessing the\nperformance of different approaches on this specific problem. Furthermore, we\npropose a novel model that addresses compositional generalization by clustering\npredicates into groups. Our model generates text in a sentence-by-sentence\nmanner, relying on one cluster of predicates at a time. This approach\nsignificantly outperforms T5~baselines across all evaluation metrics.Notably,\nit achieved a 31% improvement over T5 in terms of a metric focused on\nmaintaining faithfulness to the input.", "published": "2023-12-05 13:23:15", "link": "http://arxiv.org/abs/2312.02748v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Large Language Models on Graphs: A Comprehensive Survey", "abstract": "Large language models (LLMs), such as GPT4 and LLaMA, are creating\nsignificant advancements in natural language processing, due to their strong\ntext encoding/decoding ability and newly found emergent capability (e.g.,\nreasoning). While LLMs are mainly designed to process pure texts, there are\nmany real-world scenarios where text data is associated with rich structure\ninformation in the form of graphs (e.g., academic networks, and e-commerce\nnetworks) or scenarios where graph data is paired with rich textual information\n(e.g., molecules with descriptions). Besides, although LLMs have shown their\npure text-based reasoning ability, it is underexplored whether such ability can\nbe generalized to graphs (i.e., graph-based reasoning). In this paper, we\nprovide a systematic review of scenarios and techniques related to large\nlanguage models on graphs. We first summarize potential scenarios of adopting\nLLMs on graphs into three categories, namely pure graphs, text-attributed\ngraphs, and text-paired graphs. We then discuss detailed techniques for\nutilizing LLMs on graphs, including LLM as Predictor, LLM as Encoder, and LLM\nas Aligner, and compare the advantages and disadvantages of different schools\nof models. Furthermore, we discuss the real-world applications of such methods\nand summarize open-source codes and benchmark datasets. Finally, we conclude\nwith potential future research directions in this fast-growing field. The\nrelated source can be found at\nhttps://github.com/PeterGriffinJin/Awesome-Language-Model-on-Graphs.", "published": "2023-12-05 14:14:27", "link": "http://arxiv.org/abs/2312.02783v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Weakly Supervised Detection of Hallucinations in LLM Activations", "abstract": "We propose an auditing method to identify whether a large language model\n(LLM) encodes patterns such as hallucinations in its internal states, which may\npropagate to downstream tasks. We introduce a weakly supervised auditing\ntechnique using a subset scanning approach to detect anomalous patterns in LLM\nactivations from pre-trained models. Importantly, our method does not need\nknowledge of the type of patterns a-priori. Instead, it relies on a reference\ndataset devoid of anomalies during testing. Further, our approach enables the\nidentification of pivotal nodes responsible for encoding these patterns, which\nmay offer crucial insights for fine-tuning specific sub-networks for bias\nmitigation. We introduce two new scanning methods to handle LLM activations for\nanomalous sentences that may deviate from the expected distribution in either\ndirection. Our results confirm prior findings of BERT's limited internal\ncapacity for encoding hallucinations, while OPT appears capable of encoding\nhallucination information internally. Importantly, our scanning approach,\nwithout prior exposure to false statements, performs comparably to a fully\nsupervised out-of-distribution classifier.", "published": "2023-12-05 14:35:11", "link": "http://arxiv.org/abs/2312.02798v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Leveraging Domain Adaptation and Data Augmentation to Improve Qur'anic\n  IR in English and Arabic", "abstract": "In this work, we approach the problem of Qur'anic information retrieval (IR)\nin Arabic and English. Using the latest state-of-the-art methods in neural IR,\nwe research what helps to tackle this task more efficiently. Training retrieval\nmodels requires a lot of data, which is difficult to obtain for training\nin-domain. Therefore, we commence with training on a large amount of general\ndomain data and then continue training on in-domain data. To handle the lack of\nin-domain data, we employed a data augmentation technique, which considerably\nimproved results in MRR@10 and NDCG@5 metrics, setting the state-of-the-art in\nQur'anic IR for both English and Arabic. The absence of an Islamic corpus and\ndomain-specific model for IR task in English motivated us to address this lack\nof resources and take preliminary steps of the Islamic corpus compilation and\ndomain-specific language model (LM) pre-training, which helped to improve the\nperformance of the retrieval models that use the domain-specific LM as the\nshared backbone. We examined several language models (LMs) in Arabic to select\none that efficiently deals with the Qur'anic IR task. Besides transferring\nsuccessful experiments from English to Arabic, we conducted additional\nexperiments with retrieval task in Arabic to amortize the scarcity of general\ndomain datasets used to train the retrieval models. Handling Qur'anic IR task\ncombining English and Arabic allowed us to enhance the comparison and share\nvaluable insights across models and languages.", "published": "2023-12-05 14:44:08", "link": "http://arxiv.org/abs/2312.02803v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Clustering Pseudo Language Family in Multilingual Translation Models\n  with Fisher Information Matrix", "abstract": "In multilingual translation research, the comprehension and utilization of\nlanguage families are of paramount importance. Nevertheless, clustering\nlanguages based solely on their ancestral families can yield suboptimal results\ndue to variations in the datasets employed during the model's training phase.\nTo mitigate this challenge, we introduce an innovative method that leverages\nthe fisher information matrix (FIM) to cluster language families, anchored on\nthe multilingual translation model's characteristics. We hypothesize that\nlanguage pairs with similar effects on model parameters exhibit a considerable\ndegree of linguistic congruence and should thus be grouped cohesively. This\nconcept has led us to define pseudo language families. We provide an in-depth\ndiscussion regarding the inception and application of these pseudo language\nfamilies. Empirical evaluations reveal that employing these pseudo language\nfamilies enhances performance over conventional language families in adapting a\nmultilingual translation model to unfamiliar language pairs. The proposed\nmethodology may also be extended to scenarios requiring language similarity\nmeasurements. The source code and associated scripts can be accessed at\nhttps://github.com/ecoli-hit/PseudoFamily.", "published": "2023-12-05 15:03:27", "link": "http://arxiv.org/abs/2312.02820v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "WhisBERT: Multimodal Text-Audio Language Modeling on 100M Words", "abstract": "Training on multiple modalities of input can augment the capabilities of a\nlanguage model. Here, we ask whether such a training regime can improve the\nquality and efficiency of these systems as well. We focus on text--audio and\nintroduce Whisbert, which is inspired by the text--image approach of FLAVA\n(Singh et al., 2022). In accordance with Babylm guidelines (Warstadt et al.,\n2023), we pretrain Whisbert on a dataset comprising only 100 million words plus\ntheir corresponding speech from the word-aligned version of the People's Speech\ndataset (Galvez et al., 2021). To assess the impact of multimodality, we\ncompare versions of the model that are trained on text only and on both audio\nand text simultaneously. We find that while Whisbert is able to perform well on\nmultimodal masked modeling and surpasses the Babylm baselines in most benchmark\ntasks, it struggles to optimize its complex objective and outperform its\ntext-only Whisbert baseline.", "published": "2023-12-05 18:03:13", "link": "http://arxiv.org/abs/2312.02931v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Rank-without-GPT: Building GPT-Independent Listwise Rerankers on\n  Open-Source Large Language Models", "abstract": "Listwise rerankers based on large language models (LLM) are the zero-shot\nstate-of-the-art. However, current works in this direction all depend on the\nGPT models, making it a single point of failure in scientific reproducibility.\nMoreover, it raises the concern that the current research findings only hold\nfor GPT models but not LLM in general. In this work, we lift this pre-condition\nand build for the first time effective listwise rerankers without any form of\ndependency on GPT. Our passage retrieval experiments show that our best list se\nreranker surpasses the listwise rerankers based on GPT-3.5 by 13% and achieves\n97% effectiveness of the ones built on GPT-4. Our results also show that the\nexisting training datasets, which were expressly constructed for pointwise\nranking, are insufficient for building such listwise rerankers. Instead,\nhigh-quality listwise ranking data is required and crucial, calling for further\nwork on building human-annotated listwise data resources.", "published": "2023-12-05 18:57:40", "link": "http://arxiv.org/abs/2312.02969v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Inherent limitations of LLMs regarding spatial information", "abstract": "Despite the significant advancements in natural language processing\ncapabilities demonstrated by large language models such as ChatGPT, their\nproficiency in comprehending and processing spatial information, especially\nwithin the domains of 2D and 3D route planning, remains notably underdeveloped.\nThis paper investigates the inherent limitations of ChatGPT and similar models\nin spatial reasoning and navigation-related tasks, an area critical for\napplications ranging from autonomous vehicle guidance to assistive technologies\nfor the visually impaired. In this paper, we introduce a novel evaluation\nframework complemented by a baseline dataset, meticulously crafted for this\nstudy. This dataset is structured around three key tasks: plotting spatial\npoints, planning routes in two-dimensional (2D) spaces, and devising pathways\nin three-dimensional (3D) environments. We specifically developed this dataset\nto assess the spatial reasoning abilities of ChatGPT. Our evaluation reveals\nkey insights into the model's capabilities and limitations in spatial\nunderstanding.", "published": "2023-12-05 16:02:20", "link": "http://arxiv.org/abs/2312.03042v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Visual Program Distillation: Distilling Tools and Programmatic Reasoning\n  into Vision-Language Models", "abstract": "Solving complex visual tasks such as \"Who invented the musical instrument on\nthe right?\" involves a composition of skills: understanding space, recognizing\ninstruments, and also retrieving prior knowledge. Recent work shows promise by\ndecomposing such tasks using a large language model (LLM) into an executable\nprogram that invokes specialized vision models. However, generated programs are\nerror-prone: they omit necessary steps, include spurious ones, and are unable\nto recover when the specialized models give incorrect outputs. Moreover, they\nrequire loading multiple models, incurring high latency and computation costs.\nWe propose Visual Program Distillation (VPD), an instruction tuning framework\nthat produces a vision-language model (VLM) capable of solving complex visual\ntasks with a single forward pass. VPD distills the reasoning ability of LLMs by\nusing them to sample multiple candidate programs, which are then executed and\nverified to identify a correct one. It translates each correct program into a\nlanguage description of the reasoning steps, which are then distilled into a\nVLM. Extensive experiments show that VPD improves the VLM's ability to count,\nunderstand spatial relations, and reason compositionally. Our VPD-trained\nPaLI-X outperforms all prior VLMs, achieving state-of-the-art performance\nacross complex vision tasks, including MMBench, OK-VQA, A-OKVQA, TallyQA, POPE,\nand Hateful Memes. An evaluation with human annotators also confirms that VPD\nimproves model response factuality and consistency. Finally, experiments on\ncontent moderation demonstrate that VPD is also helpful for adaptation to\nreal-world applications with limited data.", "published": "2023-12-05 18:58:37", "link": "http://arxiv.org/abs/2312.03052v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Combining Counting Processes and Classification Improves a Stopping Rule\n  for Technology Assisted Review", "abstract": "Technology Assisted Review (TAR) stopping rules aim to reduce the cost of\nmanually assessing documents for relevance by minimising the number of\ndocuments that need to be examined to ensure a desired level of recall. This\npaper extends an effective stopping rule using information derived from a text\nclassifier that can be trained without the need for any additional annotation.\nExperiments on multiple data sets (CLEF e-Health, TREC Total Recall, TREC Legal\nand RCV1) showed that the proposed approach consistently improves performance\nand outperforms several alternative methods.", "published": "2023-12-05 22:28:42", "link": "http://arxiv.org/abs/2312.03171v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Mismatch Quest: Visual and Textual Feedback for Image-Text Misalignment", "abstract": "While existing image-text alignment models reach high quality binary\nassessments, they fall short of pinpointing the exact source of misalignment.\nIn this paper, we present a method to provide detailed textual and visual\nexplanation of detected misalignments between text-image pairs. We leverage\nlarge language models and visual grounding models to automatically construct a\ntraining set that holds plausible misaligned captions for a given image and\ncorresponding textual explanations and visual indicators. We also publish a new\nhuman curated test set comprising ground-truth textual and visual misalignment\nannotations. Empirical results show that fine-tuning vision language models on\nour training set enables them to articulate misalignments and visually indicate\nthem within images, outperforming strong baselines both on the binary alignment\nclassification and the explanation generation tasks. Our method code and human\ncurated test set are available at: https://mismatch-quest.github.io/", "published": "2023-12-05 20:07:34", "link": "http://arxiv.org/abs/2312.03766v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "GPT vs Human for Scientific Reviews: A Dual Source Review on\n  Applications of ChatGPT in Science", "abstract": "The new polymath Large Language Models (LLMs) can speed-up greatly scientific\nreviews, possibly using more unbiased quantitative metrics, facilitating\ncross-disciplinary connections, and identifying emerging trends and research\ngaps by analyzing large volumes of data. However, at the present time, they\nlack the required deep understanding of complex methodologies, they have\ndifficulty in evaluating innovative claims, and they are unable to assess\nethical issues and conflicts of interest. Herein, we consider 13 GPT-related\npapers across different scientific domains, reviewed by a human reviewer and\nSciSpace, a large language model, with the reviews evaluated by three distinct\ntypes of evaluators, namely GPT-3.5, a crowd panel, and GPT-4. We found that\n50% of SciSpace's responses to objective questions align with those of a human\nreviewer, with GPT-4 (informed evaluator) often rating the human reviewer\nhigher in accuracy, and SciSpace higher in structure, clarity, and\ncompleteness. In subjective questions, the uninformed evaluators (GPT-3.5 and\ncrowd panel) showed varying preferences between SciSpace and human responses,\nwith the crowd panel showing a preference for the human responses. However,\nGPT-4 rated them equally in accuracy and structure but favored SciSpace for\ncompleteness.", "published": "2023-12-05 21:41:52", "link": "http://arxiv.org/abs/2312.03769v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Decoding Data Quality via Synthetic Corruptions: Embedding-guided\n  Pruning of Code Data", "abstract": "Code datasets, often collected from diverse and uncontrolled sources such as\nGitHub, potentially suffer from quality issues, thereby affecting the\nperformance and training efficiency of Large Language Models (LLMs) optimized\nfor code generation. Previous studies demonstrated the benefit of using\nembedding spaces for data pruning, but they mainly focused on duplicate removal\nor increasing variety, and in other modalities, such as images. Our work\nfocuses on using embeddings to identify and remove \"low-quality\" code data.\nFirst, we explore features of \"low-quality\" code in embedding space, through\nthe use of synthetic corruptions. Armed with this knowledge, we devise novel\npruning metrics that operate in embedding space to identify and remove\nlow-quality entries in the Stack dataset. We demonstrate the benefits of this\nsynthetic corruption informed pruning (SCIP) approach on the well-established\nHumanEval and MBPP benchmarks, outperforming existing embedding-based methods.\nImportantly, we achieve up to a 3% performance improvement over no pruning,\nthereby showing the promise of insights from synthetic corruptions for data\npruning.", "published": "2023-12-05 01:19:30", "link": "http://arxiv.org/abs/2312.02418v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Let's Think Outside the Box: Exploring Leap-of-Thought in Large Language\n  Models with Creative Humor Generation", "abstract": "Chain-of-Thought (CoT) guides large language models (LLMs) to reason\nstep-by-step, and can motivate their logical reasoning ability. While effective\nfor logical tasks, CoT is not conducive to creative problem-solving which often\nrequires out-of-box thoughts and is crucial for innovation advancements. In\nthis paper, we explore the Leap-of-Thought (LoT) abilities within LLMs -- a\nnon-sequential, creative paradigm involving strong associations and knowledge\nleaps. To this end, we study LLMs on the popular Oogiri game which needs\nparticipants to have good creativity and strong associative thinking for\nresponding unexpectedly and humorously to the given image, text, or both, and\nthus is suitable for LoT study. Then to investigate LLMs' LoT ability in the\nOogiri game, we first build a multimodal and multilingual Oogiri-GO dataset\nwhich contains over 130,000 samples from the Oogiri game, and observe the\ninsufficient LoT ability or failures of most existing LLMs on the Oogiri game.\nAccordingly, we introduce a creative Leap-of-Thought (CLoT) paradigm to improve\nLLM's LoT ability. CLoT first formulates the Oogiri-GO dataset into\nLoT-oriented instruction tuning data to train pretrained LLM for achieving\ncertain LoT humor generation and discrimination abilities. Then CLoT designs an\nexplorative self-refinement that encourages the LLM to generate more creative\nLoT data via exploring parallels between seemingly unrelated concepts and\nselects high-quality data to train itself for self-refinement. CLoT not only\nexcels in humor generation in the Oogiri game but also boosts creative\nabilities in various tasks like cloud guessing game and divergent association\ntask. These findings advance our understanding and offer a pathway to improve\nLLMs' creative capacities for innovative applications across domains. The\ndataset, code, and models will be released online.\nhttps://zhongshsh.github.io/CLoT/.", "published": "2023-12-05 02:41:57", "link": "http://arxiv.org/abs/2312.02439v3", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Scaling Laws for Adversarial Attacks on Language Model Activations", "abstract": "We explore a class of adversarial attacks targeting the activations of\nlanguage models. By manipulating a relatively small subset of model\nactivations, $a$, we demonstrate the ability to control the exact prediction of\na significant number (in some cases up to 1000) of subsequent tokens $t$. We\nempirically verify a scaling law where the maximum number of target tokens\n$t_\\mathrm{max}$ predicted depends linearly on the number of tokens $a$ whose\nactivations the attacker controls as $t_\\mathrm{max} = \\kappa a$. We find that\nthe number of bits of control in the input space needed to control a single bit\nin the output space (what we call attack resistance $\\chi$) is remarkably\nconstant between $\\approx 16$ and $\\approx 25$ over 2 orders of magnitude of\nmodel sizes for different language models. Compared to attacks on tokens,\nattacks on activations are predictably much stronger, however, we identify a\nsurprising regularity where one bit of input steered either via activations or\nvia tokens is able to exert control over a similar amount of output bits. This\ngives support for the hypothesis that adversarial attacks are a consequence of\ndimensionality mismatch between the input and output spaces. A practical\nimplication of the ease of attacking language model activations instead of\ntokens is for multi-modal and selected retrieval models, where additional data\nsources are added as activations directly, sidestepping the tokenized input.\nThis opens up a new, broad attack surface. By using language models as a\ncontrollable test-bed to study adversarial attacks, we were able to experiment\nwith input-output dimensions that are inaccessible in computer vision,\nespecially where the output dimension dominates.", "published": "2023-12-05 14:12:15", "link": "http://arxiv.org/abs/2312.02780v1", "categories": ["cs.LG", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Can a Tabula Recta provide security in the XXI century?", "abstract": "In the not so unlikely scenario of total compromise of computers accessible\nto a group of users, they might be tempted to resort to human-computable\npaper-and-pencil cryptographic methods aided by a classic Tabula Recta, which\nhelps to perform addition and subtraction directly with letters. But do these\nclassic algorithms, or some new ones using the same simple tools, have any\nchance against computer-aided cryptanalysis? In this paper I discuss how some\nhuman-computable algorithms can indeed afford sufficient security in this\nsituation, drawing conclusions from computer-based statistical analysis. Three\nkinds of algorithms are discussed: those that concentrate entropy from shared\ntext sources, stream ciphers based on arithmetic of non-binary spaces, and\nhash-like algorithms that may be used to generate a password from a challenge\ntext.", "published": "2023-12-05 16:36:27", "link": "http://arxiv.org/abs/2312.02869v1", "categories": ["cs.CR", "cs.CL", "cs.CY"], "primary_category": "cs.CR"}
{"title": "Concept Drift Adaptation in Text Stream Mining Settings: A Systematic\n  Review", "abstract": "The society produces textual data online in several ways, e.g., via reviews\nand social media posts. Therefore, numerous researchers have been working on\ndiscovering patterns in textual data that can indicate peoples' opinions,\ninterests, etc. Most tasks regarding natural language processing are addressed\nusing traditional machine learning methods and static datasets. This setting\ncan lead to several problems, e.g., outdated datasets and models, which degrade\nin performance over time. This is particularly true regarding concept drift, in\nwhich the data distribution changes over time. Furthermore, text streaming\nscenarios also exhibit further challenges, such as the high speed at which data\narrives over time. Models for stream scenarios must adhere to the\naforementioned constraints while learning from the stream, thus storing texts\nfor limited periods and consuming low memory. This study presents a systematic\nliterature review regarding concept drift adaptation in text stream scenarios.\nConsidering well-defined criteria, we selected 48 papers published between 2018\nand August 2024 to unravel aspects such as text drift categories, detection\ntypes, model update mechanisms, stream mining tasks addressed, and text\nrepresentation methods and their update mechanisms. Furthermore, we discussed\ndrift visualization and simulation and listed real-world datasets used in the\nselected papers. Finally, we brought forward a discussion on existing works in\nthe area, also highlighting open challenges and future research directions for\nthe community.", "published": "2023-12-05 17:15:16", "link": "http://arxiv.org/abs/2312.02901v2", "categories": ["cs.LG", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Let the LLMs Talk: Simulating Human-to-Human Conversational QA via\n  Zero-Shot LLM-to-LLM Interactions", "abstract": "Conversational question-answering (CQA) systems aim to create interactive\nsearch systems that effectively retrieve information by interacting with users.\nTo replicate human-to-human conversations, existing work uses human annotators\nto play the roles of the questioner (student) and the answerer (teacher).\nDespite its effectiveness, challenges exist as human annotation is\ntime-consuming, inconsistent, and not scalable. To address this issue and\ninvestigate the applicability of large language models (LLMs) in CQA\nsimulation, we propose a simulation framework that employs zero-shot learner\nLLMs for simulating teacher-student interactions. Our framework involves two\nLLMs interacting on a specific topic, with the first LLM acting as a student,\ngenerating questions to explore a given search topic. The second LLM plays the\nrole of a teacher by answering questions and is equipped with additional\ninformation, including a text on the given topic. We implement both the student\nand teacher by zero-shot prompting the GPT-4 model. To assess the effectiveness\nof LLMs in simulating CQA interactions and understand the disparities between\nLLM- and human-generated conversations, we evaluate the simulated data from\nvarious perspectives. We begin by evaluating the teacher's performance through\nboth automatic and human assessment. Next, we evaluate the performance of the\nstudent, analyzing and comparing the disparities between questions generated by\nthe LLM and those generated by humans. Furthermore, we conduct extensive\nanalyses to thoroughly examine the LLM performance by benchmarking\nstate-of-the-art reading comprehension models on both datasets. Our results\nreveal that the teacher LLM generates lengthier answers that tend to be more\naccurate and complete. The student LLM generates more diverse questions,\ncovering more aspects of a given topic.", "published": "2023-12-05 17:38:02", "link": "http://arxiv.org/abs/2312.02913v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Describing Differences in Image Sets with Natural Language", "abstract": "How do two sets of images differ? Discerning set-level differences is crucial\nfor understanding model behaviors and analyzing datasets, yet manually sifting\nthrough thousands of images is impractical. To aid in this discovery process,\nwe explore the task of automatically describing the differences between two\n$\\textbf{sets}$ of images, which we term Set Difference Captioning. This task\ntakes in image sets $D_A$ and $D_B$, and outputs a description that is more\noften true on $D_A$ than $D_B$. We outline a two-stage approach that first\nproposes candidate difference descriptions from image sets and then re-ranks\nthe candidates by checking how well they can differentiate the two sets. We\nintroduce VisDiff, which first captions the images and prompts a language model\nto propose candidate descriptions, then re-ranks these descriptions using CLIP.\nTo evaluate VisDiff, we collect VisDiffBench, a dataset with 187 paired image\nsets with ground truth difference descriptions. We apply VisDiff to various\ndomains, such as comparing datasets (e.g., ImageNet vs. ImageNetV2), comparing\nclassification models (e.g., zero-shot CLIP vs. supervised ResNet), summarizing\nmodel failure modes (supervised ResNet), characterizing differences between\ngenerative models (e.g., StableDiffusionV1 and V2), and discovering what makes\nimages memorable. Using VisDiff, we are able to find interesting and previously\nunknown differences in datasets and models, demonstrating its utility in\nrevealing nuanced insights.", "published": "2023-12-05 18:59:16", "link": "http://arxiv.org/abs/2312.02974v2", "categories": ["cs.CV", "cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Protein Language Model-Powered 3D Ligand Binding Site Prediction from\n  Protein Sequence", "abstract": "Prediction of ligand binding sites of proteins is a fundamental and important\ntask for understanding the function of proteins and screening potential drugs.\nMost existing methods require experimentally determined protein holo-structures\nas input. However, such structures can be unavailable on novel or less-studied\nproteins. To tackle this limitation, we propose LaMPSite, which only takes\nprotein sequences and ligand molecular graphs as input for ligand binding site\npredictions. The protein sequences are used to retrieve residue-level\nembeddings and contact maps from the pre-trained ESM-2 protein language model.\nThe ligand molecular graphs are fed into a graph neural network to compute\natom-level embeddings. Then we compute and update the protein-ligand\ninteraction embedding based on the protein residue-level embeddings and ligand\natom-level embeddings, and the geometric constraints in the inferred protein\ncontact map and ligand distance map. A final pooling on protein-ligand\ninteraction embedding would indicate which residues belong to the binding\nsites. Without any 3D coordinate information of proteins, our proposed model\nachieves competitive performance compared to baseline methods that require 3D\nprotein structures when predicting binding sites. Given that less than 50% of\nproteins have reliable structure information in the current stage, LaMPSite\nwill provide new opportunities for drug discovery.", "published": "2023-12-05 01:47:38", "link": "http://arxiv.org/abs/2312.03016v1", "categories": ["q-bio.QM", "cs.CL", "cs.LG"], "primary_category": "q-bio.QM"}
{"title": "Beyond Isolation: Multi-Agent Synergy for Improving Knowledge Graph\n  Construction", "abstract": "This paper introduces CooperKGC, a novel framework challenging the\nconventional solitary approach of large language models (LLMs) in knowledge\ngraph construction (KGC). CooperKGC establishes a collaborative processing\nnetwork, assembling a team capable of concurrently addressing entity, relation,\nand event extraction tasks. Experimentation demonstrates that fostering\ncollaboration within CooperKGC enhances knowledge selection, correction, and\naggregation capabilities across multiple rounds of interactions.", "published": "2023-12-05 07:27:08", "link": "http://arxiv.org/abs/2312.03022v3", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Training on Synthetic Data Beats Real Data in Multimodal Relation\n  Extraction", "abstract": "The task of multimodal relation extraction has attracted significant research\nattention, but progress is constrained by the scarcity of available training\ndata. One natural thought is to extend existing datasets with cross-modal\ngenerative models. In this paper, we consider a novel problem setting, where\nonly unimodal data, either text or image, are available during training. We aim\nto train a multimodal classifier from synthetic data that perform well on real\nmultimodal test data. However, training with synthetic data suffers from two\nobstacles: lack of data diversity and label information loss. To alleviate the\nissues, we propose Mutual Information-aware Multimodal Iterated Relational dAta\nGEneration (MI2RAGE), which applies Chained Cross-modal Generation (CCG) to\npromote diversity in the generated data and exploits a teacher network to\nselect valuable training samples with high mutual information with the\nground-truth labels. Comparing our method to direct training on synthetic data,\nwe observed a significant improvement of 24.06% F1 with synthetic text and\n26.42% F1 with synthetic images. Notably, our best model trained on completely\nsynthetic images outperforms prior state-of-the-art models trained on real\nmultimodal data by a margin of 3.76% in F1. Our codebase will be made available\nupon acceptance.", "published": "2023-12-05 08:11:34", "link": "http://arxiv.org/abs/2312.03025v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Clinical Notes Reveal Physician Fatigue", "abstract": "Physicians write notes about patients. In doing so, they reveal much about\nthemselves. Using data from 129,228 emergency room visits, we train a model to\nidentify notes written by fatigued physicians -- those who worked 5 or more of\nthe prior 7 days. In a hold-out set, the model accurately identifies notes\nwritten by these high-workload physicians, and also flags notes written in\nother high-fatigue settings: on overnight shifts, and after high patient\nvolumes. Model predictions also correlate with worse decision-making on at\nleast one important metric: yield of testing for heart attack is 18% lower with\neach standard deviation increase in model-predicted fatigue. Finally, the model\nindicates that notes written about Black and Hispanic patients have 12% and 21%\nhigher predicted fatigue than Whites -- larger than overnight vs. daytime\ndifferences. These results have an important implication for large language\nmodels (LLMs). Our model indicates that fatigued doctors write more predictable\nnotes. Perhaps unsurprisingly, because word prediction is the core of how LLMs\nwork, we find that LLM-written notes have 17% higher predicted fatigue than\nreal physicians' notes. This indicates that LLMs may introduce distortions in\ngenerated text that are not yet fully understood.", "published": "2023-12-05 19:00:18", "link": "http://arxiv.org/abs/2312.03077v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "RESIN-EDITOR: A Schema-guided Hierarchical Event Graph Visualizer and\n  Editor", "abstract": "In this paper, we present RESIN-EDITOR, an interactive event graph visualizer\nand editor designed for analyzing complex events. Our RESIN-EDITOR system\nallows users to render and freely edit hierarchical event graphs extracted from\nmultimedia and multi-document news clusters with guidance from human-curated\nevent schemas. RESIN-EDITOR's unique features include hierarchical graph\nvisualization, comprehensive source tracing, and interactive user editing,\nwhich is more powerful and versatile than existing Information Extraction (IE)\nvisualization tools. In our evaluation of RESIN-EDITOR, we demonstrate ways in\nwhich our tool is effective in understanding complex events and enhancing\nsystem performance. The source code, a video demonstration, and a live website\nfor RESIN-EDITOR have been made publicly available.", "published": "2023-12-05 19:25:38", "link": "http://arxiv.org/abs/2312.03093v1", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "FlexModel: A Framework for Interpretability of Distributed Large\n  Language Models", "abstract": "With the growth of large language models, now incorporating billions of\nparameters, the hardware prerequisites for their training and deployment have\nseen a corresponding increase. Although existing tools facilitate model\nparallelization and distributed training, deeper model interactions, crucial\nfor interpretability and responsible AI techniques, still demand thorough\nknowledge of distributed computing. This often hinders contributions from\nresearchers with machine learning expertise but limited distributed computing\nbackground. Addressing this challenge, we present FlexModel, a software package\nproviding a streamlined interface for engaging with models distributed across\nmulti-GPU and multi-node configurations. The library is compatible with\nexisting model distribution libraries and encapsulates PyTorch models. It\nexposes user-registerable HookFunctions to facilitate straightforward\ninteraction with distributed model internals, bridging the gap between\ndistributed and single-device model paradigms. Primarily, FlexModel enhances\naccessibility by democratizing model interactions and promotes more inclusive\nresearch in the domain of large-scale neural networks. The package is found at\nhttps://github.com/VectorInstitute/flex_model.", "published": "2023-12-05 21:19:33", "link": "http://arxiv.org/abs/2312.03140v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DC"], "primary_category": "cs.LG"}
{"title": "A Comparative Study of AI-Generated (GPT-4) and Human-crafted MCQs in\n  Programming Education", "abstract": "There is a constant need for educators to develop and maintain effective\nup-to-date assessments. While there is a growing body of research in computing\neducation on utilizing large language models (LLMs) in generation and\nengagement with coding exercises, the use of LLMs for generating programming\nMCQs has not been extensively explored. We analyzed the capability of GPT-4 to\nproduce multiple-choice questions (MCQs) aligned with specific learning\nobjectives (LOs) from Python programming classes in higher education.\nSpecifically, we developed an LLM-powered (GPT-4) system for generation of MCQs\nfrom high-level course context and module-level LOs. We evaluated 651\nLLM-generated and 449 human-crafted MCQs aligned to 246 LOs from 6 Python\ncourses. We found that GPT-4 was capable of producing MCQs with clear language,\na single correct choice, and high-quality distractors. We also observed that\nthe generated MCQs appeared to be well-aligned with the LOs. Our findings can\nbe leveraged by educators wishing to take advantage of the state-of-the-art\ngenerative models to support MCQ authoring efforts.", "published": "2023-12-05 22:29:43", "link": "http://arxiv.org/abs/2312.03173v1", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "How should the advent of large language models affect the practice of\n  science?", "abstract": "Large language models (LLMs) are being increasingly incorporated into\nscientific workflows. However, we have yet to fully grasp the implications of\nthis integration. How should the advent of large language models affect the\npractice of science? For this opinion piece, we have invited four diverse\ngroups of scientists to reflect on this query, sharing their perspectives and\nengaging in debate. Schulz et al. make the argument that working with LLMs is\nnot fundamentally different from working with human collaborators, while Bender\net al. argue that LLMs are often misused and over-hyped, and that their\nlimitations warrant a focus on more specialized, easily interpretable tools.\nMarelli et al. emphasize the importance of transparent attribution and\nresponsible use of LLMs. Finally, Botvinick and Gershman advocate that humans\nshould retain responsibility for determining the scientific roadmap. To\nfacilitate the discussion, the four perspectives are complemented with a\nresponse from each group. By putting these different perspectives in\nconversation, we aim to bring attention to important considerations within the\nacademic community regarding the adoption of LLMs and their impact on both\ncurrent and future scientific practices.", "published": "2023-12-05 10:45:12", "link": "http://arxiv.org/abs/2312.03759v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.DL"], "primary_category": "cs.CL"}
{"title": "Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability,\n  Explainability, and Safety", "abstract": "Explainability and Safety engender Trust. These require a model to exhibit\nconsistency and reliability. To achieve these, it is necessary to use and\nanalyze data and knowledge with statistical and symbolic AI methods relevant to\nthe AI application - neither alone will do. Consequently, we argue and seek to\ndemonstrate that the NeuroSymbolic AI approach is better suited for making AI a\ntrusted AI system. We present the CREST framework that shows how Consistency,\nReliability, user-level Explainability, and Safety are built on NeuroSymbolic\nmethods that use data and knowledge to support requirements for critical\napplications such as health and well-being. This article focuses on Large\nLanguage Models (LLMs) as the chosen AI system within the CREST framework. LLMs\nhave garnered substantial attention from researchers due to their versatility\nin handling a broad array of natural language processing (NLP) scenarios. For\nexample, ChatGPT and Google's MedPaLM have emerged as highly promising\nplatforms for providing information in general and health-related queries,\nrespectively. Nevertheless, these models remain black boxes despite\nincorporating human feedback and instruction-guided tuning. For instance,\nChatGPT can generate unsafe responses despite instituting safety guardrails.\nCREST presents a plausible approach harnessing procedural and graph-based\nknowledge within a NeuroSymbolic framework to shed light on the challenges\nassociated with LLMs.", "published": "2023-12-05 06:13:55", "link": "http://arxiv.org/abs/2312.06798v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "I.2; I.2.7; J.3; H.3.3"], "primary_category": "cs.AI"}
{"title": "Flood Event Extraction from News Media to Support Satellite-Based Flood\n  Insurance", "abstract": "Floods cause large losses to property, life, and livelihoods across the world\nevery year, hindering sustainable development. Safety nets to help absorb\nfinancial shocks in disasters, such as insurance, are often unavailable in\nregions of the world most vulnerable to floods, like Bangladesh. Index-based\ninsurance has emerged as an affordable solution, which considers weather data\nor information from satellites to create a \"flood index\" that should correlate\nwith the damage insured. However, existing flood event databases are often\nincomplete, and satellite sensors are not reliable under extreme weather\nconditions (e.g., because of clouds), which limits the spatial and temporal\nresolution of current approaches for index-based insurance.\n  In this work, we explore a novel approach for supporting satellite-based\nflood index insurance by extracting high-resolution spatio-temporal information\nfrom news media. First, we publish a dataset consisting of 40,000 news articles\ncovering flood events in Bangladesh by 10 prominent news sources, and inundated\narea estimates for each division in Bangladesh collected from a satellite radar\nsensor. Second, we show that keyword-based models are not adequate for this\nnovel application, while context-based classifiers cover complex and implicit\nflood related patterns. Third, we show that time series extracted from news\nmedia have substantial correlation Spearman's rho$=0.70 with satellite\nestimates of inundated area. Our work demonstrates that news media is a\npromising source for improving the temporal resolution and expanding the\nspatial coverage of the available flood damage data.", "published": "2023-12-05 18:39:42", "link": "http://arxiv.org/abs/2312.14943v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Auralization based on multi-perspective ambisonic room impulse responses", "abstract": "Most often, virtual acoustic rendering employs real-time updated room\nacoustic simulations to accomplish auralization for a variable listener\nperspective. As an alternative, we propose and test a technique to interpolate\nroom impulse responses, specifically Ambisonic room impulse responses (ARIRs)\navailable at a grid of spatially distributed receiver perspectives, measured or\nsimulated in a desired acoustic environment. In particular, we extrapolate a\ntriplet of neighboring ARIRs to the variable listener perspective, preceding\ntheir linear interpolation. The extrapolation is achieved by decomposing each\nARIR into localized sound events and re-assigning their direction, time, and\nlevel to what could be observed at the listener perspective, with as much\ntemporal, directional, and perspective context as possible. We propose to\nundertake this decomposition in two levels: Peaks in the early ARIRs are\ndecomposed into jointly localized sound events, based on time differences of\narrival observed in either an ARIR triplet, or all ARIRs observing the direct\nsound. Sound events that could not be jointly localized are treated as\nresiduals whose less precise localization utilizes direction-of-arrival\ndetection and the estimated time of arrival. For the interpolated rendering,\nsuitable parameter settings are found by evaluating the proposed method in a\nlistening experiment, using both measured and simulated ARIR data sets, under\nstatic and time-varying conditions.", "published": "2023-12-05 08:54:34", "link": "http://arxiv.org/abs/2312.02581v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Integrating Plug-and-Play Data Priors with Weighted Prediction Error for\n  Speech Dereverberation", "abstract": "Speech dereverberation aims to alleviate the detrimental effects of\nlate-reverberant components. While the weighted prediction error (WPE) method\nhas shown superior performance in dereverberation, there is still room for\nfurther improvement in terms of performance and robustness in complex and noisy\nenvironments. Recent research has highlighted the effectiveness of integrating\nphysics-based and data-driven methods, enhancing the performance of various\nsignal processing tasks while maintaining interpretability. Motivated by these\nadvancements, this paper presents a novel dereverberation frame-work, which\nincorporates data-driven methods for capturing speech priors within the WPE\nframework. The plug-and-play strategy (PnP), specifically the regularization by\ndenoising (RED) strategy, is utilized to incorporate speech prior information\nlearnt from data during the optimization problem solving iterations.\nExperimental results validate the effectiveness of the proposed approach.", "published": "2023-12-05 14:03:11", "link": "http://arxiv.org/abs/2312.02773v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Distributed Speech Dereverberation Using Weighted Prediction Error", "abstract": "Speech dereverberation aims to alleviate the negative impact of late\nreverberant reflections. The weighted prediction error (WPE) method is a\nwell-established technique known for its superior performance in\ndereverberation. However, in scenarios where microphone nodes are dispersed,\nthe centralized approach of the WPE method requires aggregating all\nobservations for inverse filtering, resulting in a significant computational\nburden. This paper introduces a distributed speech dereverberation method that\nemphasizes low computational complexity at each node. Specifically, we leverage\nthe distributed adaptive node-specific signal estimation (DANSE) algorithm\nwithin the multichannel linear prediction (MCLP) process. This approach\nempowers each node to perform local operations with reduced complexity while\nachieving the global performance through inter-node cooperation. Experimental\nresults validate the effectiveness of our proposed method, showcasing its\nability to achieve efficient speech dereverberation in dispersed microphone\nnode scenarios.", "published": "2023-12-05 13:22:58", "link": "http://arxiv.org/abs/2312.03034v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Leveraging Laryngograph Data for Robust Voicing Detection in Speech", "abstract": "Accurately detecting voiced intervals in speech signals is a critical step in\npitch tracking and has numerous applications. While conventional signal\nprocessing methods and deep learning algorithms have been proposed for this\ntask, their need to fine-tune threshold parameters for different datasets and\nlimited generalization restrict their utility in real-world applications. To\naddress these challenges, this study proposes a supervised voicing detection\nmodel that leverages recorded laryngograph data. The model is based on a\ndensely-connected convolutional recurrent neural network (DC-CRN), and trained\non data with reference voicing decisions extracted from laryngograph data sets.\nPretraining is also investigated to improve the generalization ability of the\nmodel. The proposed model produces robust voicing detection results,\noutperforming other strong baseline methods, and generalizes well to unseen\ndatasets. The source code of the proposed model with pretraining is provided\nalong with the list of used laryngograph datasets to facilitate further\nresearch in this area.", "published": "2023-12-05 20:57:00", "link": "http://arxiv.org/abs/2312.03129v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "AV2AV: Direct Audio-Visual Speech to Audio-Visual Speech Translation\n  with Unified Audio-Visual Speech Representation", "abstract": "This paper proposes a novel direct Audio-Visual Speech to Audio-Visual Speech\nTranslation (AV2AV) framework, where the input and output of the system are\nmultimodal (i.e., audio and visual speech). With the proposed AV2AV, two key\nadvantages can be brought: 1) We can perform real-like conversations with\nindividuals worldwide in a virtual meeting by utilizing our own primary\nlanguages. In contrast to Speech-to-Speech Translation (A2A), which solely\ntranslates between audio modalities, the proposed AV2AV directly translates\nbetween audio-visual speech. This capability enhances the dialogue experience\nby presenting synchronized lip movements along with the translated speech. 2)\nWe can improve the robustness of the spoken language translation system. By\nemploying the complementary information of audio-visual speech, the system can\neffectively translate spoken language even in the presence of acoustic noise,\nshowcasing robust performance. To mitigate the problem of the absence of a\nparallel AV2AV translation dataset, we propose to train our spoken language\ntranslation system with the audio-only dataset of A2A. This is done by learning\nunified audio-visual speech representations through self-supervised learning in\nadvance to train the translation system. Moreover, we propose an AV-Renderer\nthat can generate raw audio and video in parallel. It is designed with\nzero-shot speaker modeling, thus the speaker in source audio-visual speech can\nbe maintained at the target translated audio-visual speech. The effectiveness\nof AV2AV is evaluated with extensive experiments in a many-to-many language\ntranslation setting. Demo page is available on\nhttps://choijeongsoo.github.io/av2av.", "published": "2023-12-05 05:36:44", "link": "http://arxiv.org/abs/2312.02512v2", "categories": ["cs.CV", "cs.AI", "cs.MM", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Diffusion-Based Speech Enhancement in Matched and Mismatched Conditions\n  Using a Heun-Based Sampler", "abstract": "Diffusion models are a new class of generative models that have recently been\napplied to speech enhancement successfully. Previous works have demonstrated\ntheir superior performance in mismatched conditions compared to state-of-the\nart discriminative models. However, this was investigated with a single\ndatabase for training and another one for testing, which makes the results\nhighly dependent on the particular databases. Moreover, recent developments\nfrom the image generation literature remain largely unexplored for speech\nenhancement. These include several design aspects of diffusion models, such as\nthe noise schedule or the reverse sampler. In this work, we systematically\nassess the generalization performance of a diffusion-based speech enhancement\nmodel by using multiple speech, noise and binaural room impulse response (BRIR)\ndatabases to simulate mismatched acoustic conditions. We also experiment with a\nnoise schedule and a sampler that have not been applied to speech enhancement\nbefore. We show that the proposed system substantially benefits from using\nmultiple databases for training, and achieves superior performance compared to\nstate-of-the-art discriminative models in both matched and mismatched\nconditions. We also show that a Heun-based sampler achieves superior\nperformance at a smaller computational cost compared to a sampler commonly used\nfor speech enhancement.", "published": "2023-12-05 11:40:38", "link": "http://arxiv.org/abs/2312.02683v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
