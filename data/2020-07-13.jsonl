{"title": "Do You Have the Right Scissors? Tailoring Pre-trained Language Models\n  via Monte-Carlo Methods", "abstract": "It has been a common approach to pre-train a language model on a large corpus\nand fine-tune it on task-specific data. In practice, we observe that\nfine-tuning a pre-trained model on a small dataset may lead to over- and/or\nunder-estimation problem. In this paper, we propose MC-Tailor, a novel method\nto alleviate the above issue in text generation tasks by truncating and\ntransferring the probability mass from over-estimated regions to\nunder-estimated ones. Experiments on a variety of text generation datasets show\nthat MC-Tailor consistently and significantly outperforms the fine-tuning\napproach. Our code is available at this url.", "published": "2020-07-13 02:53:03", "link": "http://arxiv.org/abs/2007.06162v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generating Fluent Adversarial Examples for Natural Languages", "abstract": "Efficiently building an adversarial attacker for natural language processing\n(NLP) tasks is a real challenge. Firstly, as the sentence space is discrete, it\nis difficult to make small perturbations along the direction of gradients.\nSecondly, the fluency of the generated examples cannot be guaranteed. In this\npaper, we propose MHA, which addresses both problems by performing\nMetropolis-Hastings sampling, whose proposal is designed with the guidance of\ngradients. Experiments on IMDB and SNLI show that our proposed MHA outperforms\nthe baseline model on attacking capability. Adversarial training with MAH also\nleads to better robustness and performance.", "published": "2020-07-13 03:56:37", "link": "http://arxiv.org/abs/2007.06174v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rewiring the Transformer with Depth-Wise LSTMs", "abstract": "Stacking non-linear layers allows deep neural networks to model complicated\nfunctions, and including residual connections in Transformer layers is\nbeneficial for convergence and performance. However, residual connections may\nmake the model \"forget\" distant layers and fail to fuse information from\nprevious layers effectively. Selectively managing the representation\naggregation of Transformer layers may lead to better performance. In this\npaper, we present a Transformer with depth-wise LSTMs connecting cascading\nTransformer layers and sub-layers. We show that layer normalization and\nfeed-forward computation within a Transformer layer can be absorbed into\ndepth-wise LSTMs connecting pure Transformer attention layers. Our experiments\nwith the 6-layer Transformer show significant BLEU improvements in both WMT 14\nEnglish-German / French tasks and the OPUS-100 many-to-many multilingual NMT\ntask, and our deep Transformer experiments demonstrate the effectiveness of\ndepth-wise LSTM on the convergence and performance of deep Transformers.", "published": "2020-07-13 09:19:34", "link": "http://arxiv.org/abs/2007.06257v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GGPONC: A Corpus of German Medical Text with Rich Metadata Based on\n  Clinical Practice Guidelines", "abstract": "The lack of publicly accessible text corpora is a major obstacle for progress\nin natural language processing. For medical applications, unfortunately, all\nlanguage communities other than English are low-resourced. In this work, we\npresent GGPONC (German Guideline Program in Oncology NLP Corpus), a freely\ndistributable German language corpus based on clinical practice guidelines for\noncology. This corpus is one of the largest ever built from German medical\ndocuments. Unlike clinical documents, clinical guidelines do not contain any\npatient-related information and can therefore be used without data protection\nrestrictions. Moreover, GGPONC is the first corpus for the German language\ncovering diverse conditions in a large medical subfield and provides a variety\nof metadata, such as literature references and evidence levels. By applying and\nevaluating existing medical information extraction pipelines for German text,\nwe are able to draw comparisons for the use of medical language to other\ncorpora, medical and non-medical ones.", "published": "2020-07-13 14:25:49", "link": "http://arxiv.org/abs/2007.06400v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HSD Shared Task in VLSP Campaign 2019:Hate Speech Detection for Social\n  Good", "abstract": "The paper describes the organisation of the \"HateSpeech Detection\" (HSD) task\nat the VLSP workshop 2019 on detecting the fine-grained presence of hate speech\nin Vietnamese textual items (i.e., messages) extracted from Facebook, which is\nthe most popular social network site (SNS) in Vietnam. The task is organised as\na multi-class classification task and based on a large-scale dataset containing\n25,431 Vietnamese textual items from Facebook. The task participants were\nchallenged to build a classification model that is capable of classifying an\nitem to one of 3 classes, i.e., \"HATE\", \"OFFENSIVE\" and \"CLEAN\". HSD attracted\na large number of participants and was a popular task at VLSP 2019. In\nparticular, there were 71 teams signed up for the task, 14 of them submitted\nresults with 380 valid submissions from 20th September 2019 to 4th October\n2019.", "published": "2020-07-13 16:43:14", "link": "http://arxiv.org/abs/2007.06493v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "COVID-19 SignSym: a fast adaptation of a general clinical NLP tool to\n  identify and normalize COVID-19 signs and symptoms to OMOP common data model", "abstract": "The COVID-19 pandemic swept across the world rapidly, infecting millions of\npeople. An efficient tool that can accurately recognize important clinical\nconcepts of COVID-19 from free text in electronic health records (EHRs) will be\nvaluable to accelerate COVID-19 clinical research. To this end, this study aims\nat adapting the existing CLAMP natural language processing tool to quickly\nbuild COVID-19 SignSym, which can extract COVID-19 signs/symptoms and their 8\nattributes (body location, severity, temporal expression, subject, condition,\nuncertainty, negation, and course) from clinical text. The extracted\ninformation is also mapped to standard concepts in the Observational Medical\nOutcomes Partnership common data model. A hybrid approach of combining deep\nlearning-based models, curated lexicons, and pattern-based rules was applied to\nquickly build the COVID-19 SignSym from CLAMP, with optimized performance. Our\nextensive evaluation using 3 external sites with clinical notes of COVID-19\npatients, as well as the online medical dialogues of COVID-19, shows COVID-19\nSign-Sym can achieve high performance across data sources. The workflow used\nfor this study can be generalized to other use cases, where existing clinical\nnatural language processing tools need to be customized for specific\ninformation needs within a short time. COVID-19 SignSym is freely accessible to\nthe research community as a downloadable package\n(https://clamp.uth.edu/covid/nlp.php) and has been used by 16 healthcare\norganizations to support clinical research of COVID-19.", "published": "2020-07-13 15:57:26", "link": "http://arxiv.org/abs/2007.10286v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reducing Language Biases in Visual Question Answering with\n  Visually-Grounded Question Encoder", "abstract": "Recent studies have shown that current VQA models are heavily biased on the\nlanguage priors in the train set to answer the question, irrespective of the\nimage. E.g., overwhelmingly answer \"what sport is\" as \"tennis\" or \"what color\nbanana\" as \"yellow.\" This behavior restricts them from real-world application\nscenarios. In this work, we propose a novel model-agnostic question encoder,\nVisually-Grounded Question Encoder (VGQE), for VQA that reduces this effect.\nVGQE utilizes both visual and language modalities equally while encoding the\nquestion. Hence the question representation itself gets sufficient\nvisual-grounding, and thus reduces the dependency of the model on the language\npriors. We demonstrate the effect of VGQE on three recent VQA models and\nachieve state-of-the-art results on the bias-sensitive split of the VQAv2\ndataset; VQA-CPv2. Further, unlike the existing bias-reduction techniques, on\nthe standard VQAv2 benchmark, our approach does not drop the accuracy; instead,\nit improves the performance.", "published": "2020-07-13 05:36:36", "link": "http://arxiv.org/abs/2007.06198v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "A model of interaction semantics", "abstract": "Purpose: The purpose of this article is to propose, based on a model of an\ninteraction semantics, a certain understanding of the ''meaning'' of the\nexchanged characters within an interaction.\n  Methodology: Based on a model of system interaction, I structure the model of\ninteraction semantics similar to the semantics of a formal language: first, I\nidentify adequate variables in my interaction model to assign values to, and\nsecond, I identify the interpretation function to provide meaning. Thereby I\narrive at a model of interaction semantics which, in the sense of the late\nLudwig Wittgenstein, can do without a 'mental' mapping from characters to\nconcepts.\n  Findings: The key findings are a better understanding of the tight relation\nbetween the informatical approach to model interactions and game theory; of the\ncentral 'chicken and egg' problem, any natural language has to solve, namely\nthat to interact sensibly, we have to understand each other and to acquire a\ncommon understanding, we have to interact with each other, which I call the\n'simultaneous interaction and understanding (SIAU)' problem; why ontologies are\nless 'semantic' then their proponents suggest; and how 'semantic'\ninteroperability is to be achieved.\n  Value: The main value of the proposed model of interaction semantics is that\nit could be applied in many different disciplines and therefore could serve as\na basis for scientists of natural sciences and humanities as well as engineers\nto understand each other more easily talking about semantics, especially with\nthe advent of cyber-physical systems.", "published": "2020-07-13 09:22:59", "link": "http://arxiv.org/abs/2007.06258v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "A Label Attention Model for ICD Coding from Clinical Text", "abstract": "ICD coding is a process of assigning the International Classification of\nDisease diagnosis codes to clinical/medical notes documented by health\nprofessionals (e.g. clinicians). This process requires significant human\nresources, and thus is costly and prone to error. To handle the problem,\nmachine learning has been utilized for automatic ICD coding. Previous\nstate-of-the-art models were based on convolutional neural networks, using a\nsingle/several fixed window sizes. However, the lengths and interdependence\nbetween text fragments related to ICD codes in clinical text vary\nsignificantly, leading to the difficulty of deciding what the best window sizes\nare. In this paper, we propose a new label attention model for automatic ICD\ncoding, which can handle both the various lengths and the interdependence of\nthe ICD code related text fragments. Furthermore, as the majority of ICD codes\nare not frequently used, leading to the extremely imbalanced data issue, we\nadditionally propose a hierarchical joint learning mechanism extending our\nlabel attention model to handle the issue, using the hierarchical relationships\namong the codes. Our label attention model achieves new state-of-the-art\nresults on three benchmark MIMIC datasets, and the joint learning mechanism\nhelps improve the performances for infrequent codes.", "published": "2020-07-13 12:42:43", "link": "http://arxiv.org/abs/2007.06351v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An Enhanced Text Classification to Explore Health based Indian\n  Government Policy Tweets", "abstract": "Government-sponsored policy-making and scheme generations is one of the means\nof protecting and promoting the social, economic, and personal development of\nthe citizens. The evaluation of effectiveness of these schemes done by\ngovernment only provide the statistical information in terms of facts and\nfigures which do not include the in-depth knowledge of public perceptions,\nexperiences and views on the topic. In this research work, we propose an\nimproved text classification framework that classifies the Twitter data of\ndifferent health-based government schemes. The proposed framework leverages the\nlanguage representation models (LR models) BERT, ELMO, and USE. However, these\nLR models have less real-time applicability due to the scarcity of the ample\nannotated data. To handle this, we propose a novel GloVe word embeddings and\nclass-specific sentiments based text augmentation approach (named Mod-EDA)\nwhich boosts the performance of text classification task by increasing the size\nof labeled data. Furthermore, the trained model is leveraged to identify the\nlevel of engagement of citizens towards these policies in different communities\nsuch as middle-income and low-income groups.", "published": "2020-07-13 17:04:44", "link": "http://arxiv.org/abs/2007.06511v2", "categories": ["cs.CL", "cs.LG", "I.2.7; H.2.8; I.5.4"], "primary_category": "cs.CL"}
{"title": "ProtTrans: Towards Cracking the Language of Life's Code Through\n  Self-Supervised Deep Learning and High Performance Computing", "abstract": "Computational biology and bioinformatics provide vast data gold-mines from\nprotein sequences, ideal for Language Models taken from NLP. These LMs reach\nfor new prediction frontiers at low inference costs. Here, we trained two\nauto-regressive models (Transformer-XL, XLNet) and four auto-encoder models\n(BERT, Albert, Electra, T5) on data from UniRef and BFD containing up to 393\nbillion amino acids. The LMs were trained on the Summit supercomputer using\n5616 GPUs and TPU Pod up-to 1024 cores. Dimensionality reduction revealed that\nthe raw protein LM-embeddings from unlabeled data captured some biophysical\nfeatures of protein sequences. We validated the advantage of using the\nembeddings as exclusive input for several subsequent tasks. The first was a\nper-residue prediction of protein secondary structure (3-state accuracy\nQ3=81%-87%); the second were per-protein predictions of protein sub-cellular\nlocalization (ten-state accuracy: Q10=81%) and membrane vs. water-soluble\n(2-state accuracy Q2=91%). For the per-residue predictions the transfer of the\nmost informative embeddings (ProtT5) for the first time outperformed the\nstate-of-the-art without using evolutionary information thereby bypassing\nexpensive database searches. Taken together, the results implied that protein\nLMs learned some of the grammar of the language of life. To facilitate future\nwork, we released our models at https://github.com/agemagician/ProtTrans.", "published": "2020-07-13 07:54:20", "link": "http://arxiv.org/abs/2007.06225v3", "categories": ["cs.LG", "cs.CL", "cs.DC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "RNA-2QCFA: Evolving Two-way Quantum Finite Automata with Classical\n  States for RNA Secondary Structures", "abstract": "Recently, the use of mathematical methods and computer science applications\nhave got significant response among biochemists and biologists to modeling the\nbiological systems. The computational and mathematical methods have enormous\npotential for modeling the deoxyribonucleic acid (DNA) and ribonucleic acid\n(RNA) structures. The modeling of DNA and RNA secondary structures using\nautomata theory had a significant impact in the fields of computer science. It\nis a natural goal to model the RNA secondary biomolecular structures using\nquantum computational models. Two-way quantum finite automata with classical\nstates are more dominant than two-way probabilistic finite automata in language\nrecognition. The main objective of this paper is on using two-way quantum\nfinite automata with classical states to simulate, model and analyze the\nribonucleic acid (RNA) sequences.", "published": "2020-07-13 09:54:09", "link": "http://arxiv.org/abs/2007.06273v1", "categories": ["cs.FL", "cs.CL", "quant-ph"], "primary_category": "cs.FL"}
{"title": "Paranoid Transformer: Reading Narrative of Madness as Computational\n  Approach to Creativity", "abstract": "This papers revisits the receptive theory in context of computational\ncreativity. It presents a case study of a Paranoid Transformer - a fully\nautonomous text generation engine with raw output that could be read as the\nnarrative of a mad digital persona without any additional human post-filtering.\nWe describe technical details of the generative system, provide examples of\noutput and discuss the impact of receptive theory, chance discovery and\nsimulation of fringe mental state on the understanding of computational\ncreativity.", "published": "2020-07-13 10:18:24", "link": "http://arxiv.org/abs/2007.06290v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "68T50, 68T07, 91F20, 68T42", "H.1.2; J.5; K.4"], "primary_category": "cs.CL"}
{"title": "A Feature Analysis for Multimodal News Retrieval", "abstract": "Content-based information retrieval is based on the information contained in\ndocuments rather than using metadata such as keywords. Most information\nretrieval methods are either based on text or image. In this paper, we\ninvestigate the usefulness of multimodal features for cross-lingual news search\nin various domains: politics, health, environment, sport, and finance. To this\nend, we consider five feature types for image and text and compare the\nperformance of the retrieval system using different combinations. Experimental\nresults show that retrieval results can be improved when considering both\nvisual and textual information. In addition, it is observed that among textual\nfeatures entity overlap outperforms word embeddings, while geolocation\nembeddings achieve better performance among visual features in the retrieval\ntask.", "published": "2020-07-13 14:09:29", "link": "http://arxiv.org/abs/2007.06390v2", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Automatic Lyrics Transcription using Dilated Convolutional Neural\n  Networks with Self-Attention", "abstract": "Speech recognition is a well developed research field so that the current\nstate of the art systems are being used in many applications in the software\nindustry, yet as by today, there still does not exist such robust system for\nthe recognition of words and sentences from singing voice. This paper proposes\na complete pipeline for this task which may commonly be referred as automatic\nlyrics transcription (ALT). We have trained convolutional time-delay neural\nnetworks with self-attention on monophonic karaoke recordings using a sequence\nclassification objective for building the acoustic model. The dataset used in\nthis study, DAMP - Sing! 300x30x2 [1] is filtered to have songs with only\nEnglish lyrics. Different language models are tested including MaxEnt and\nRecurrent Neural Networks based methods which are trained on the lyrics of pop\nsongs in English. An in-depth analysis of the self-attention mechanism is held\nwhile tuning its context width and the number of attention heads. Using the\nbest settings, our system achieves notable improvement to the state-of-the-art\nin ALT and provides a new baseline for the task.", "published": "2020-07-13 16:36:30", "link": "http://arxiv.org/abs/2007.06486v2", "categories": ["eess.AS", "cs.CL", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Situated Multimodal Control of a Mobile Robot: Navigation through a\n  Virtual Environment", "abstract": "We present a new interface for controlling a navigation robot in novel\nenvironments using coordinated gesture and language. We use a TurtleBot3 robot\nwith a LIDAR and a camera, an embodied simulation of what the robot has\nencountered while exploring, and a cross-platform bridge facilitating generic\ncommunication. A human partner can deliver instructions to the robot using\nspoken English and gestures relative to the simulated environment, to guide the\nrobot through navigation tasks.", "published": "2020-07-13 16:37:01", "link": "http://arxiv.org/abs/2007.09053v1", "categories": ["cs.RO", "cs.AI", "cs.CL"], "primary_category": "cs.RO"}
{"title": "Exclusion and Inclusion -- A model agnostic approach to feature\n  importance in DNNs", "abstract": "Deep Neural Networks in NLP have enabled systems to learn complex non-linear\nrelationships. One of the major bottlenecks towards being able to use DNNs for\nreal world applications is their characterization as black boxes. To solve this\nproblem, we introduce a model agnostic algorithm which calculates phrase-wise\nimportance of input features. We contend that our method is generalizable to a\ndiverse set of tasks, by carrying out experiments for both Regression and\nClassification. We also observe that our approach is robust to outliers,\nimplying that it only captures the essential aspects of the input.", "published": "2020-07-13 07:50:53", "link": "http://arxiv.org/abs/2007.16010v1", "categories": ["cs.CL", "cs.LG", "stat.CO", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Learning Reasoning Strategies in End-to-End Differentiable Proving", "abstract": "Attempts to render deep learning models interpretable, data-efficient, and\nrobust have seen some success through hybridisation with rule-based systems,\nfor example, in Neural Theorem Provers (NTPs). These neuro-symbolic models can\ninduce interpretable rules and learn representations from data via\nback-propagation, while providing logical explanations for their predictions.\nHowever, they are restricted by their computational complexity, as they need to\nconsider all possible proof paths for explaining a goal, thus rendering them\nunfit for large-scale applications. We present Conditional Theorem Provers\n(CTPs), an extension to NTPs that learns an optimal rule selection strategy via\ngradient-based optimisation. We show that CTPs are scalable and yield\nstate-of-the-art results on the CLUTRR dataset, which tests systematic\ngeneralisation of neural models by learning to reason over smaller graphs and\nevaluating on larger ones. Finally, CTPs show better link prediction results on\nstandard benchmarks in comparison with other neural-symbolic models, while\nbeing explainable. All source code and datasets are available online, at\nhttps://github.com/uclnlp/ctp.", "published": "2020-07-13 16:22:14", "link": "http://arxiv.org/abs/2007.06477v3", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.NE", "cs.SC"], "primary_category": "cs.AI"}
{"title": "Vector-Quantized Timbre Representation", "abstract": "Timbre is a set of perceptual attributes that identifies different types of\nsound sources. Although its definition is usually elusive, it can be seen from\na signal processing viewpoint as all the spectral features that are perceived\nindependently from pitch and loudness. Some works have studied high-level\ntimbre synthesis by analyzing the feature relationships of different\ninstruments, but acoustic properties remain entangled and generation bound to\nindividual sounds. This paper targets a more flexible synthesis of an\nindividual timbre by learning an approximate decomposition of its spectral\nproperties with a set of generative features. We introduce an auto-encoder with\na discrete latent space that is disentangled from loudness in order to learn a\nquantized representation of a given timbre distribution. Timbre transfer can be\nperformed by encoding any variable-length input signals into the quantized\nlatent features that are decoded according to the learned timbre. We detail\nresults for translating audio between orchestral instruments and singing voice,\nas well as transfers from vocal imitations to instruments as an intuitive\nmodality to drive sound synthesis. Furthermore, we can map the discrete latent\nspace to acoustic descriptors and directly perform descriptor-based synthesis.", "published": "2020-07-13 12:35:45", "link": "http://arxiv.org/abs/2007.06349v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Artificial Neural Networks Jamming on the Beat", "abstract": "This paper addresses the issue of long-scale correlations that is\ncharacteristic for symbolic music and is a challenge for modern generative\nalgorithms. It suggests a very simple workaround for this challenge, namely,\ngeneration of a drum pattern that could be further used as a foundation for\nmelody generation. The paper presents a large dataset of drum patterns\nalongside with corresponding melodies. It explores two possible methods for\ndrum pattern generation. Exploring a latent space of drum patterns one could\ngenerate new drum patterns with a given music style. Finally, the paper\ndemonstrates that a simple artificial neural network could be trained to\ngenerate melodies corresponding with these drum patters used as inputs.\nResulting system could be used for end-to-end generation of symbolic music with\nsong-like structure and higher long-scale correlations between the notes.", "published": "2020-07-13 10:09:20", "link": "http://arxiv.org/abs/2007.06284v3", "categories": ["eess.AS", "cs.LG", "cs.SD", "68T07, 68T50", "J.5; E.0"], "primary_category": "eess.AS"}
{"title": "DNN Speaker Tracking with Embeddings", "abstract": "In multi-speaker applications is common to have pre-computed models from\nenrolled speakers. Using these models to identify the instances in which these\nspeakers intervene in a recording is the task of speaker tracking. In this\npaper, we propose a novel embedding-based speaker tracking method.\nSpecifically, our design is based on a convolutional neural network that mimics\na typical speaker verification PLDA (probabilistic linear discriminant\nanalysis) classifier and finds the regions uttered by the target speakers in an\nonline fashion. The system was studied from two different perspectives:\ndiarization and tracking; results on both show a significant improvement over\nthe PLDA baseline under the same experimental conditions. Two standard public\ndatasets, CALLHOME and DIHARD II single channel, were modified to create\ntwo-speaker subsets with overlapping and non-overlapping regions. We evaluate\nthe robustness of our supervised approach with models generated from different\nsegment lengths. A relative improvement of 17% in DER for DIHARD II single\nchannel shows promising performance. Furthermore, to make the baseline system\nsimilar to speaker tracking, non-target speakers were added to the recordings.\nEven in these adverse conditions, our approach is robust enough to outperform\nthe PLDA baseline.", "published": "2020-07-13 18:40:14", "link": "http://arxiv.org/abs/2007.10248v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Stutter Diagnosis and Therapy System Based on Deep Learning", "abstract": "Stuttering, also called stammering, is a communication disorder that breaks\nthe continuity of the speech. This program of work is an attempt to develop\nautomatic recognition procedures to assess stuttered dysfluencies and use these\nassessments to filter out speech therapies for an individual. Stuttering may be\nin the form of repetitions, prolongations or abnormal stoppages of sounds and\nsyllables. Our system aims to help stutterers by diagnosing the severity and\ntype of stutter and also by suggesting appropriate therapies for practice by\nlearning the correlation between stutter descriptors and the effectiveness of\nspeech therapies on them. This paper focuses on the implementation of a stutter\ndiagnosis agent using Gated Recurrent CNN on MFCC audio features and therapy\nrecommendation agent using SVM. It also presents the results obtained and\nvarious key findings of the system developed.", "published": "2020-07-13 10:24:02", "link": "http://arxiv.org/abs/2007.08003v1", "categories": ["cs.CY", "cs.CV", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CY"}
