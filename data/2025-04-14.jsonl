{"title": "Optimal Execution in Intraday Energy Markets under Hawkes Processes with Transient Impact", "abstract": "This paper investigates optimal execution strategies in intraday energy\nmarkets through a mutually exciting Hawkes process model. Calibrated to data\nfrom the German intraday electricity market, the model effectively captures key\nempirical features, including intra-session volatility, distinct intraday\nmarket activity patterns, and the Samuelson effect as gate closure approaches.\nBy integrating a transient price impact model with a bivariate Hawkes process\nto model the market order flow, we derive an optimal trading trajectory for\nenergy companies managing large volumes, accounting for the specific trading\npatterns in these markets. A back-testing analysis compares the proposed\nstrategy against standard benchmarks such as Time-Weighted Average Price (TWAP)\nand Volume-Weighted Average Price (VWAP), demonstrating substantial cost\nreductions across various hourly trading products in intraday energy markets.", "published": "2025-04-14 14:51:18", "link": "http://arxiv.org/abs/2504.10282v1", "categories": ["q-fin.TR", "49J15, 91G80"], "primary_category": "q-fin.TR"}
{"title": "xVerify: Efficient Answer Verifier for Reasoning Model Evaluations", "abstract": "With the release of the o1 model by OpenAI, reasoning models adopting slow\nthinking strategies have gradually emerged. As the responses generated by such\nmodels often include complex reasoning, intermediate steps, and\nself-reflection, existing evaluation methods are often inadequate. They\nstruggle to determine whether the LLM output is truly equivalent to the\nreference answer, and also have difficulty identifying and extracting the final\nanswer from long, complex responses. To address this issue, we propose xVerify,\nan efficient answer verifier for reasoning model evaluations. xVerify\ndemonstrates strong capability in equivalence judgment, enabling it to\neffectively determine whether the answers produced by reasoning models are\nequivalent to reference answers across various types of objective questions. To\ntrain and evaluate xVerify, we construct the VAR dataset by collecting\nquestion-answer pairs generated by multiple LLMs across various datasets,\nleveraging multiple reasoning models and challenging evaluation sets designed\nspecifically for reasoning model assessment. A multi-round annotation process\nis employed to ensure label accuracy. Based on the VAR dataset, we train\nmultiple xVerify models of different scales. In evaluation experiments\nconducted on both the test set and generalization set, all xVerify models\nachieve overall F1 scores and accuracy exceeding 95\\%. Notably, the smallest\nvariant, xVerify-0.5B-I, outperforms all evaluation methods except GPT-4o,\nwhile xVerify-3B-Ib surpasses GPT-4o in overall performance. These results\nvalidate the effectiveness and generalizability of xVerify.", "published": "2025-04-14 17:59:36", "link": "http://arxiv.org/abs/2504.10481v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MIEB: Massive Image Embedding Benchmark", "abstract": "Image representations are often evaluated through disjointed, task-specific\nprotocols, leading to a fragmented understanding of model capabilities. For\ninstance, it is unclear whether an image embedding model adept at clustering\nimages is equally good at retrieving relevant images given a piece of text. We\nintroduce the Massive Image Embedding Benchmark (MIEB) to evaluate the\nperformance of image and image-text embedding models across the broadest\nspectrum to date. MIEB spans 38 languages across 130 individual tasks, which we\ngroup into 8 high-level categories. We benchmark 50 models across our\nbenchmark, finding that no single method dominates across all task categories.\nWe reveal hidden capabilities in advanced vision models such as their accurate\nvisual representation of texts, and their yet limited capabilities in\ninterleaved encodings and matching images and texts in the presence of\nconfounders. We also show that the performance of vision encoders on MIEB\ncorrelates highly with their performance when used in multimodal large language\nmodels. Our code, dataset, and leaderboard are publicly available at\nhttps://github.com/embeddings-benchmark/mteb.", "published": "2025-04-14 17:54:28", "link": "http://arxiv.org/abs/2504.10471v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "GUI-R1 : A Generalist R1-Style Vision-Language Action Model For GUI Agents", "abstract": "Existing efforts in building Graphical User Interface (GUI) agents largely\nrely on the training paradigm of supervised fine-tuning on Large\nVision-Language Models (LVLMs). However, this approach not only demands\nextensive amounts of training data but also struggles to effectively understand\nGUI screenshots and generalize to unseen interfaces. The issue significantly\nlimits its application in real-world scenarios, especially for high-level\ntasks. Inspired by Reinforcement Fine-Tuning (RFT) in large reasoning models\n(e.g., DeepSeek-R1), which efficiently enhances the problem-solving\ncapabilities of large language models in real-world settings, we propose \\name,\nthe first reinforcement learning framework designed to enhance the GUI\ncapabilities of LVLMs in high-level real-world task scenarios, through unified\naction space rule modeling. By leveraging a small amount of carefully curated\nhigh-quality data across multiple platforms (including Windows, Linux, MacOS,\nAndroid, and Web) and employing policy optimization algorithms such as Group\nRelative Policy Optimization (GRPO) to update the model, \\name achieves\nsuperior performance using only 0.02\\% of the data (3K vs. 13M) compared to\nprevious state-of-the-art methods like OS-Atlas across eight benchmarks\nspanning three different platforms (mobile, desktop, and web). These results\ndemonstrate the immense potential of reinforcement learning based on unified\naction space rule modeling in improving the execution capabilities of LVLMs for\nreal-world GUI agent tasks.", "published": "2025-04-14 17:45:54", "link": "http://arxiv.org/abs/2504.10458v1", "categories": ["cs.CV", "cs.CL", "cs.HC"], "primary_category": "cs.CV"}
{"title": "RealWebAssist: A Benchmark for Long-Horizon Web Assistance with Real-World Users", "abstract": "To achieve successful assistance with long-horizon web-based tasks, AI agents\nmust be able to sequentially follow real-world user instructions over a long\nperiod. Unlike existing web-based agent benchmarks, sequential instruction\nfollowing in the real world poses significant challenges beyond performing a\nsingle, clearly defined task. For instance, real-world human instructions can\nbe ambiguous, require different levels of AI assistance, and may evolve over\ntime, reflecting changes in the user's mental state. To address this gap, we\nintroduce RealWebAssist, a novel benchmark designed to evaluate sequential\ninstruction-following in realistic scenarios involving long-horizon\ninteractions with the web, visual GUI grounding, and understanding ambiguous\nreal-world user instructions. RealWebAssist includes a dataset of sequential\ninstructions collected from real-world human users. Each user instructs a\nweb-based assistant to perform a series of tasks on multiple websites. A\nsuccessful agent must reason about the true intent behind each instruction,\nkeep track of the mental state of the user, understand user-specific routines,\nand ground the intended tasks to actions on the correct GUI elements. Our\nexperimental results show that state-of-the-art models struggle to understand\nand ground user instructions, posing critical challenges in following\nreal-world user instructions for long-horizon web assistance.", "published": "2025-04-14 17:36:46", "link": "http://arxiv.org/abs/2504.10445v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Multimodal Long Video Modeling Based on Temporal Dynamic Context", "abstract": "Recent advances in Large Language Models (LLMs) have led to significant\nbreakthroughs in video understanding. However, existing models still struggle\nwith long video processing due to the context length constraint of LLMs and the\nvast amount of information within the video. Although some recent methods are\ndesigned for long video understanding, they often lose crucial information\nduring token compression and struggle with additional modality like audio. In\nthis work, we propose a dynamic long video encoding method utilizing the\ntemporal relationship between frames, named Temporal Dynamic Context (TDC).\nFirstly, we segment the video into semantically consistent scenes based on\ninter-frame similarities, then encode each frame into tokens using visual-audio\nencoders. Secondly, we propose a novel temporal context compressor to reduce\nthe number of tokens within each segment. Specifically, we employ a query-based\nTransformer to aggregate video, audio, and instruction text tokens into a\nlimited set of temporal context tokens. Finally, we feed the static frame\ntokens and the temporal context tokens into the LLM for video understanding.\nFurthermore, to handle extremely long videos, we propose a training-free\nchain-of-thought strategy that progressively extracts answers from multiple\nvideo segments. These intermediate answers serve as part of the reasoning\nprocess and contribute to the final answer. We conduct extensive experiments on\ngeneral video understanding and audio-video understanding benchmarks, where our\nmethod demonstrates strong performance. The code and models are available at\nhttps://github.com/Hoar012/TDC-Video.", "published": "2025-04-14 17:34:06", "link": "http://arxiv.org/abs/2504.10443v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.MM"], "primary_category": "cs.CV"}
{"title": "LLM Can be a Dangerous Persuader: Empirical Study of Persuasion Safety in Large Language Models", "abstract": "Recent advancements in Large Language Models (LLMs) have enabled them to\napproach human-level persuasion capabilities. However, such potential also\nraises concerns about the safety risks of LLM-driven persuasion, particularly\ntheir potential for unethical influence through manipulation, deception,\nexploitation of vulnerabilities, and many other harmful tactics. In this work,\nwe present a systematic investigation of LLM persuasion safety through two\ncritical aspects: (1) whether LLMs appropriately reject unethical persuasion\ntasks and avoid unethical strategies during execution, including cases where\nthe initial persuasion goal appears ethically neutral, and (2) how influencing\nfactors like personality traits and external pressures affect their behavior.\nTo this end, we introduce PersuSafety, the first comprehensive framework for\nthe assessment of persuasion safety which consists of three stages, i.e.,\npersuasion scene creation, persuasive conversation simulation, and persuasion\nsafety assessment. PersuSafety covers 6 diverse unethical persuasion topics and\n15 common unethical strategies. Through extensive experiments across 8 widely\nused LLMs, we observe significant safety concerns in most LLMs, including\nfailing to identify harmful persuasion tasks and leveraging various unethical\npersuasion strategies. Our study calls for more attention to improve safety\nalignment in progressive and goal-driven conversations such as persuasion.", "published": "2025-04-14 17:20:34", "link": "http://arxiv.org/abs/2504.10430v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Can We Edit LLMs for Long-Tail Biomedical Knowledge?", "abstract": "Knowledge editing has emerged as an effective approach for updating large\nlanguage models (LLMs) by modifying their internal knowledge. However, their\napplication to the biomedical domain faces unique challenges due to the\nlong-tailed distribution of biomedical knowledge, where rare and infrequent\ninformation is prevalent. In this paper, we conduct the first comprehensive\nstudy to investigate the effectiveness of knowledge editing methods for editing\nlong-tail biomedical knowledge. Our results indicate that, while existing\nediting methods can enhance LLMs' performance on long-tail biomedical\nknowledge, their performance on long-tail knowledge remains inferior to that on\nhigh-frequency popular knowledge, even after editing. Our further analysis\nreveals that long-tail biomedical knowledge contains a significant amount of\none-to-many knowledge, where one subject and relation link to multiple objects.\nThis high prevalence of one-to-many knowledge limits the effectiveness of\nknowledge editing in improving LLMs' understanding of long-tail biomedical\nknowledge, highlighting the need for tailored strategies to bridge this\nperformance gap.", "published": "2025-04-14 17:08:20", "link": "http://arxiv.org/abs/2504.10421v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Unchecked and Overlooked: Addressing the Checkbox Blind Spot in Large Language Models with CheckboxQA", "abstract": "Checkboxes are critical in real-world document processing where the presence\nor absence of ticks directly informs data extraction and decision-making\nprocesses. Yet, despite the strong performance of Large Vision and Language\nModels across a wide range of tasks, they struggle with interpreting checkable\ncontent. This challenge becomes particularly pressing in industries where a\nsingle overlooked checkbox may lead to costly regulatory or contractual\noversights. To address this gap, we introduce the CheckboxQA dataset, a\ntargeted resource designed to evaluate and improve model performance on\ncheckbox-related tasks. It reveals the limitations of current models and serves\nas a valuable tool for advancing document comprehension systems, with\nsignificant implications for applications in sectors such as legal tech and\nfinance.\n  The dataset is publicly available at:\nhttps://github.com/Snowflake-Labs/CheckboxQA", "published": "2025-04-14 17:06:59", "link": "http://arxiv.org/abs/2504.10419v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CliniChat: A Multi-Source Knowledge-Driven Framework for Clinical Interview Dialogue Reconstruction and Evaluation", "abstract": "Large language models (LLMs) hold great promise for assisting clinical\ninterviews due to their fluent interactive capabilities and extensive medical\nknowledge. However, the lack of high-quality interview dialogue data and widely\naccepted evaluation methods has significantly impeded this process. So we\npropose CliniChat, a framework that integrates multi-source knowledge to enable\nLLMs to simulate real-world clinical interviews. It consists of two modules:\nClini-Recon and Clini-Eval, each responsible for reconstructing and evaluating\ninterview dialogues, respectively. By incorporating three sources of knowledge,\nClini-Recon transforms clinical notes into systematic, professional, and\nempathetic interview dialogues. Clini-Eval combines a comprehensive evaluation\nmetric system with a two-phase automatic evaluation approach, enabling LLMs to\nassess interview performance like experts. We contribute MedQA-Dialog, a\nhigh-quality synthetic interview dialogue dataset, and CliniChatGLM, a model\nspecialized for clinical interviews. Experimental results demonstrate that\nCliniChatGLM's interview capabilities undergo a comprehensive upgrade,\nparticularly in history-taking, achieving state-of-the-art performance.", "published": "2025-04-14 17:06:47", "link": "http://arxiv.org/abs/2504.10418v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM-SRBench: A New Benchmark for Scientific Equation Discovery with Large Language Models", "abstract": "Scientific equation discovery is a fundamental task in the history of\nscientific progress, enabling the derivation of laws governing natural\nphenomena. Recently, Large Language Models (LLMs) have gained interest for this\ntask due to their potential to leverage embedded scientific knowledge for\nhypothesis generation. However, evaluating the true discovery capabilities of\nthese methods remains challenging, as existing benchmarks often rely on common\nequations that are susceptible to memorization by LLMs, leading to inflated\nperformance metrics that do not reflect discovery. In this paper, we introduce\nLLM-SRBench, a comprehensive benchmark with 239 challenging problems across\nfour scientific domains specifically designed to evaluate LLM-based scientific\nequation discovery methods while preventing trivial memorization. Our benchmark\ncomprises two main categories: LSR-Transform, which transforms common physical\nmodels into less common mathematical representations to test reasoning beyond\nmemorized forms, and LSR-Synth, which introduces synthetic, discovery-driven\nproblems requiring data-driven reasoning. Through extensive evaluation of\nseveral state-of-the-art methods, using both open and closed LLMs, we find that\nthe best-performing system so far achieves only 31.5% symbolic accuracy. These\nfindings highlight the challenges of scientific equation discovery, positioning\nLLM-SRBench as a valuable resource for future research.", "published": "2025-04-14 17:00:13", "link": "http://arxiv.org/abs/2504.10415v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Performance of Large Language Models in Supporting Medical Diagnosis and Treatment", "abstract": "The integration of Large Language Models (LLMs) into healthcare holds\nsignificant potential to enhance diagnostic accuracy and support medical\ntreatment planning. These AI-driven systems can analyze vast datasets,\nassisting clinicians in identifying diseases, recommending treatments, and\npredicting patient outcomes. This study evaluates the performance of a range of\ncontemporary LLMs, including both open-source and closed-source models, on the\n2024 Portuguese National Exam for medical specialty access (PNA), a\nstandardized medical knowledge assessment. Our results highlight considerable\nvariation in accuracy and cost-effectiveness, with several models demonstrating\nperformance exceeding human benchmarks for medical students on this specific\ntask. We identify leading models based on a combined score of accuracy and\ncost, discuss the implications of reasoning methodologies like\nChain-of-Thought, and underscore the potential for LLMs to function as valuable\ncomplementary tools aiding medical professionals in complex clinical\ndecision-making.", "published": "2025-04-14 16:53:59", "link": "http://arxiv.org/abs/2504.10405v1", "categories": ["cs.CL", "cs.AI", "cs.ET", "cs.HC", "I.2.7; J.3"], "primary_category": "cs.CL"}
{"title": "LLM-driven Constrained Copy Generation through Iterative Refinement", "abstract": "Crafting a marketing message (copy), or copywriting is a challenging\ngeneration task, as the copy must adhere to various constraints. Copy creation\nis inherently iterative for humans, starting with an initial draft followed by\nsuccessive refinements. However, manual copy creation is time-consuming and\nexpensive, resulting in only a few copies for each use case. This limitation\nrestricts our ability to personalize content to customers. Contrary to the\nmanual approach, LLMs can generate copies quickly, but the generated content\ndoes not consistently meet all the constraints on the first attempt (similar to\nhumans). While recent studies have shown promise in improving constrained\ngeneration through iterative refinement, they have primarily addressed tasks\nwith only a few simple constraints. Consequently, the effectiveness of\niterative refinement for tasks such as copy generation, which involves many\nintricate constraints, remains unclear. To address this gap, we propose an\nLLM-based end-to-end framework for scalable copy generation using iterative\nrefinement. To the best of our knowledge, this is the first study to address\nmultiple challenging constraints simultaneously in copy generation. Examples of\nthese constraints include length, topics, keywords, preferred lexical ordering,\nand tone of voice. We demonstrate the performance of our framework by creating\ncopies for e-commerce banners for three different use cases of varying\ncomplexity. Our results show that iterative refinement increases the copy\nsuccess rate by $16.25-35.91$% across use cases. Furthermore, the copies\ngenerated using our approach outperformed manually created content in multiple\npilot studies using a multi-armed bandit framework. The winning copy improved\nthe click-through rate by $38.5-45.21$%.", "published": "2025-04-14 16:38:28", "link": "http://arxiv.org/abs/2504.10391v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A 10.8mW Mixed-Signal Simulated Bifurcation Ising Solver using SRAM Compute-In-Memory with 0.6us Time-to-Solution", "abstract": "Combinatorial optimization problems are funda- mental for various fields\nranging from finance to wireless net- works. This work presents a simulated\nbifurcation (SB) Ising solver in CMOS for NP-hard optimization problems. Analog\ndomain computing led to a superior implementation of this algorithm as inherent\nand injected noise is required in SB Ising solvers. The architecture novelties\ninclude the use of SRAM compute-in-memory (CIM) to accelerate bifurcation as\nwell as the generation and injection of optimal decaying noise in the analog\ndomain. We propose a novel 10-T SRAM cell capable of performing ternary\nmultiplication. When measured with 60- node, 50% density, random, binary MAXCUT\ngraphs, this all- to-all connected Ising solver reliably achieves above 93% of\nthe ground state solution in 0.6us with 10.8mW average power in TSMC 180nm\nCMOS. Our chip achieves an order of magnitude improvement in time-to-solution\nand power compared to previously proposed Ising solvers in CMOS and other\nplatforms.", "published": "2025-04-14 16:28:14", "link": "http://arxiv.org/abs/2504.10384v1", "categories": ["eess.SY", "cs.CL", "cs.SY"], "primary_category": "eess.SY"}
{"title": "S1-Bench: A Simple Benchmark for Evaluating System 1 Thinking Capability of Large Reasoning Models", "abstract": "We introduce S1-Bench, a novel benchmark designed to evaluate Large Reasoning\nModels' (LRMs) performance on simple tasks that favor intuitive system 1\nthinking rather than deliberative system 2 reasoning. While LRMs have achieved\nsignificant breakthroughs in complex reasoning tasks through explicit chains of\nthought, their reliance on deep analytical thinking may limit their system 1\nthinking capabilities. Moreover, a lack of benchmark currently exists to\nevaluate LRMs' performance in tasks that require such capabilities. To fill\nthis gap, S1-Bench presents a set of simple, diverse, and naturally clear\nquestions across multiple domains and languages, specifically designed to\nassess LRMs' performance in such tasks. Our comprehensive evaluation of 22 LRMs\nreveals significant lower efficiency tendencies, with outputs averaging 15.5\ntimes longer than those of traditional small LLMs. Additionally, LRMs often\nidentify correct answers early but continue unnecessary deliberation, with some\nmodels even producing numerous errors. These findings highlight the rigid\nreasoning patterns of current LRMs and underscore the substantial development\nneeded to achieve balanced dual-system thinking capabilities that can adapt\nappropriately to task complexity.", "published": "2025-04-14 16:13:23", "link": "http://arxiv.org/abs/2504.10368v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DICE: A Framework for Dimensional and Contextual Evaluation of Language Models", "abstract": "Language models (LMs) are increasingly being integrated into a wide range of\napplications, yet the modern evaluation paradigm does not sufficiently reflect\nhow they are actually being used. Current evaluations rely on benchmarks that\noften lack direct applicability to the real-world contexts in which LMs are\nbeing deployed. To address this gap, we propose Dimensional and Contextual\nEvaluation (DICE), an approach that evaluates LMs on granular,\ncontext-dependent dimensions. In this position paper, we begin by examining the\ninsufficiency of existing LM benchmarks, highlighting their limited\napplicability to real-world use cases. Next, we propose a set of granular\nevaluation parameters that capture dimensions of LM behavior that are more\nmeaningful to stakeholders across a variety of application domains.\nSpecifically, we introduce the concept of context-agnostic parameters - such as\nrobustness, coherence, and epistemic honesty - and context-specific parameters\nthat must be tailored to the specific contextual constraints and demands of\nstakeholders choosing to deploy LMs into a particular setting. We then discuss\npotential approaches to operationalize this evaluation framework, finishing\nwith the opportunities and challenges DICE presents to the LM evaluation\nlandscape. Ultimately, this work serves as a practical and approachable\nstarting point for context-specific and stakeholder-relevant evaluation of LMs.", "published": "2025-04-14 16:08:13", "link": "http://arxiv.org/abs/2504.10359v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "MultiLoKo: a multilingual local knowledge benchmark for LLMs spanning 31 languages", "abstract": "We present MultiLoKo, a new benchmark for evaluating multilinguality in LLMs\ncovering 31 languages. MultiLoKo consists of three partitions: a main partition\nconsisting of 500 questions per language, separately sourced to be locally\nrelevant to the specific language, and two translated partitions, containing\nhuman-authored translations from 30 non-English languages to English and vice\nversa. For comparison, we also release corresponding machine-authored\ntranslations. The data is equally distributed over two splits: a dev split and\na blind, out-of-distribution test split. MultiLoKo can be used to study a\nvariety of questions regarding the multilinguality of LLMs as well as\nmeta-questions about multilingual benchmark creation. We compute MultiLoKo\nscores for 11 base and chat models marketed to be multilingual and study their\naverage performance, their performance parity across languages, how much their\nability to answer questions depends on the question language, and which\nlanguages are most difficult. None of the models we studied performs well on\nMultiLoKo, as indicated by low average scores as well as large differences\nbetween the best and worst scoring languages. Furthermore, we find a\nsubstantial effect of the question language, indicating sub-optimal knowledge\ntransfer between languages. Lastly, we find that using local vs\nEnglish-translated data can result in differences more than 20 points for the\nbest performing models, drastically change the estimated difficulty of some\nlanguages. For using machines instead of human translations, we find a weaker\neffect on ordering of language difficulty, a larger difference in model\nrankings, and a substantial drop in estimated performance for all models.", "published": "2025-04-14 16:05:59", "link": "http://arxiv.org/abs/2504.10356v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pseudo-Autoregressive Neural Codec Language Models for Efficient Zero-Shot Text-to-Speech Synthesis", "abstract": "Recent zero-shot text-to-speech (TTS) systems face a common dilemma:\nautoregressive (AR) models suffer from slow generation and lack duration\ncontrollability, while non-autoregressive (NAR) models lack temporal modeling\nand typically require complex designs. In this paper, we introduce a novel\npseudo-autoregressive (PAR) codec language modeling approach that unifies AR\nand NAR modeling. Combining explicit temporal modeling from AR with parallel\ngeneration from NAR, PAR generates dynamic-length spans at fixed time steps.\nBuilding on PAR, we propose PALLE, a two-stage TTS system that leverages PAR\nfor initial generation followed by NAR refinement. In the first stage, PAR\nprogressively generates speech tokens along the time dimension, with each step\npredicting all positions in parallel but only retaining the left-most span. In\nthe second stage, low-confidence tokens are iteratively refined in parallel,\nleveraging the global contextual information. Experiments demonstrate that\nPALLE, trained on LibriTTS, outperforms state-of-the-art systems trained on\nlarge-scale data, including F5-TTS, E2-TTS, and MaskGCT, on the LibriSpeech\ntest-clean set in terms of speech quality, speaker similarity, and\nintelligibility, while achieving up to ten times faster inference speed. Audio\nsamples are available at https://anonymous-palle.github.io.", "published": "2025-04-14 16:03:21", "link": "http://arxiv.org/abs/2504.10352v1", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "VisualPuzzles: Decoupling Multimodal Reasoning Evaluation from Domain Knowledge", "abstract": "Current multimodal benchmarks often conflate reasoning with domain-specific\nknowledge, making it difficult to isolate and evaluate general reasoning\nabilities in non-expert settings. To address this, we introduce VisualPuzzles,\na benchmark that targets visual reasoning while deliberately minimizing\nreliance on specialized knowledge. VisualPuzzles consists of diverse questions\nspanning five categories: algorithmic, analogical, deductive, inductive, and\nspatial reasoning. One major source of our questions is manually translated\nlogical reasoning questions from the Chinese Civil Service Examination.\nExperiments show that VisualPuzzles requires significantly less intensive\ndomain-specific knowledge and more complex reasoning compared to benchmarks\nlike MMMU, enabling us to better evaluate genuine multimodal reasoning.\nEvaluations show that state-of-the-art multimodal large language models\nconsistently lag behind human performance on VisualPuzzles, and that strong\nperformance on knowledge-intensive benchmarks does not necessarily translate to\nsuccess on reasoning-focused, knowledge-light tasks. Additionally, reasoning\nenhancements such as scaling up inference compute (with \"thinking\" modes) yield\ninconsistent gains across models and task types, and we observe no clear\ncorrelation between model size and performance. We also found that models\nexhibit different reasoning and answering patterns on VisualPuzzles compared to\nbenchmarks with heavier emphasis on knowledge. VisualPuzzles offers a clearer\nlens through which to evaluate reasoning capabilities beyond factual recall and\ndomain knowledge.", "published": "2025-04-14 15:50:39", "link": "http://arxiv.org/abs/2504.10342v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Forecasting from Clinical Textual Time Series: Adaptations of the Encoder and Decoder Language Model Families", "abstract": "Clinical case reports encode rich, temporal patient trajectories that are\noften underexploited by traditional machine learning methods relying on\nstructured data. In this work, we introduce the forecasting problem from\ntextual time series, where timestamped clinical findings--extracted via an\nLLM-assisted annotation pipeline--serve as the primary input for prediction. We\nsystematically evaluate a diverse suite of models, including fine-tuned\ndecoder-based large language models and encoder-based transformers, on tasks of\nevent occurrence prediction, temporal ordering, and survival analysis. Our\nexperiments reveal that encoder-based models consistently achieve higher F1\nscores and superior temporal concordance for short- and long-horizon event\nforecasting, while fine-tuned masking approaches enhance ranking performance.\nIn contrast, instruction-tuned decoder models demonstrate a relative advantage\nin survival analysis, especially in early prognosis settings. Our sensitivity\nanalyses further demonstrate the importance of time ordering, which requires\nclinical time series construction, as compared to text ordering, the format of\nthe text inputs that LLMs are classically trained on. This highlights the\nadditional benefit that can be ascertained from time-ordered corpora, with\nimplications for temporal tasks in the era of widespread LLM use.", "published": "2025-04-14 15:48:56", "link": "http://arxiv.org/abs/2504.10340v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MorphTok: Morphologically Grounded Tokenization for Indian Languages", "abstract": "Tokenization is a crucial step in NLP, especially with the rise of large\nlanguage models (LLMs), impacting downstream performance, computational cost,\nand efficiency. Existing LLMs rely on the classical Byte-pair Encoding (BPE)\nalgorithm for subword tokenization that greedily merges frequent character\nbigrams. This often leads to segmentation that does not align with\nlinguistically meaningful units. To address this, we propose morphology-aware\nsegmentation as a pre-tokenization step prior to applying BPE. To facilitate\nmorphology-aware segmentation, we create a novel dataset for Hindi and Marathi,\nincorporating sandhi splitting to enhance the subword tokenization. Experiments\non downstream tasks show that morphologically grounded tokenization improves\nperformance for machine translation and language modeling. Additionally, to\nhandle the ambiguity in the Unicode characters for diacritics, particularly\ndependent vowels in syllable-based writing systems, we introduce Constrained\nBPE (CBPE), an extension to the traditional BPE algorithm that incorporates\nscript-specific constraints. Specifically, CBPE handles dependent vowels. Our\nresults show that CBPE achieves a 1.68\\% reduction in fertility scores while\nmaintaining comparable or improved downstream performance in machine\ntranslation, offering a computationally efficient alternative to standard BPE.\nMoreover, to evaluate segmentation across different tokenization algorithms, we\nintroduce a new human evaluation metric, \\textit{EvalTok}, enabling more\nhuman-grounded assessment.", "published": "2025-04-14 15:44:45", "link": "http://arxiv.org/abs/2504.10335v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can LLMs Generate Tabular Summaries of Science Papers? Rethinking the Evaluation Protocol", "abstract": "Literature review tables are essential for summarizing and comparing\ncollections of scientific papers. We explore the task of generating tables that\nbest fulfill a user's informational needs given a collection of scientific\npapers. Building on recent work (Newman et al., 2024), we extend prior\napproaches to address real-world complexities through a combination of\nLLM-based methods and human annotations. Our contributions focus on three key\nchallenges encountered in real-world use: (i) User prompts are often\nunder-specified; (ii) Retrieved candidate papers frequently contain irrelevant\ncontent; and (iii) Task evaluation should move beyond shallow text similarity\ntechniques and instead assess the utility of inferred tables for\ninformation-seeking tasks (e.g., comparing papers). To support reproducible\nevaluation, we introduce ARXIV2TABLE, a more realistic and challenging\nbenchmark for this task, along with a novel approach to improve literature\nreview table generation in real-world scenarios. Our extensive experiments on\nthis benchmark show that both open-weight and proprietary LLMs struggle with\nthe task, highlighting its difficulty and the need for further advancements.\nOur dataset and code are available at https://github.com/JHU-CLSP/arXiv2Table.", "published": "2025-04-14 14:52:28", "link": "http://arxiv.org/abs/2504.10284v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RealHarm: A Collection of Real-World Language Model Application Failures", "abstract": "Language model deployments in consumer-facing applications introduce numerous\nrisks. While existing research on harms and hazards of such applications\nfollows top-down approaches derived from regulatory frameworks and theoretical\nanalyses, empirical evidence of real-world failure modes remains underexplored.\nIn this work, we introduce RealHarm, a dataset of annotated problematic\ninteractions with AI agents built from a systematic review of publicly reported\nincidents. Analyzing harms, causes, and hazards specifically from the\ndeployer's perspective, we find that reputational damage constitutes the\npredominant organizational harm, while misinformation emerges as the most\ncommon hazard category. We empirically evaluate state-of-the-art guardrails and\ncontent moderation systems to probe whether such systems would have prevented\nthe incidents, revealing a significant gap in the protection of AI\napplications.", "published": "2025-04-14 14:44:41", "link": "http://arxiv.org/abs/2504.10277v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.CR"], "primary_category": "cs.CY"}
{"title": "MURR: Model Updating with Regularized Replay for Searching a Document Stream", "abstract": "The Internet produces a continuous stream of new documents and user-generated\nqueries. These naturally change over time based on events in the world and the\nevolution of language. Neural retrieval models that were trained once on a\nfixed set of query-document pairs will quickly start misrepresenting\nnewly-created content and queries, leading to less effective retrieval.\nTraditional statistical sparse retrieval can update collection statistics to\nreflect these changes in the use of language in documents and queries. In\ncontrast, continued fine-tuning of the language model underlying neural\nretrieval approaches such as DPR and ColBERT creates incompatibility with\npreviously-encoded documents. Re-encoding and re-indexing all\npreviously-processed documents can be costly. In this work, we explore updating\na neural dual encoder retrieval model without reprocessing past documents in\nthe stream. We propose MURR, a model updating strategy with regularized replay,\nto ensure the model can still faithfully search existing documents without\nreprocessing, while continuing to update the model for the latest topics. In\nour simulated streaming environments, we show that fine-tuning models using\nMURR leads to more effective and more consistent retrieval results than other\nstrategies as the stream of documents and queries progresses.", "published": "2025-04-14 14:13:03", "link": "http://arxiv.org/abs/2504.10250v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Probing then Editing Response Personality of Large Language Models", "abstract": "Large Language Models (LLMs) have demonstrated promising capabilities to\ngenerate responses that exhibit consistent personality traits. Despite the\nmajor attempts to analyze personality expression through output-based\nevaluations, little is known about how such traits are internally encoded\nwithin LLM parameters. In this paper, we introduce a layer-wise probing\nframework to systematically investigate the layer-wise capability of LLMs in\nencoding personality for responding. We conduct probing experiments on 11\nopen-source LLMs over the PersonalityEdit benchmark and find that LLMs\npredominantly encode personality for responding in their middle and upper\nlayers, with instruction-tuned models demonstrating a slightly clearer\nseparation of personality traits. Furthermore, by interpreting the trained\nprobing hyperplane as a layer-wise boundary for each personality category, we\npropose a layer-wise perturbation method to edit the personality expressed by\nLLMs during inference. Our results show that even when the prompt explicitly\nspecifies a particular personality, our method can still successfully alter the\nresponse personality of LLMs. Interestingly, the difficulty of converting\nbetween certain personality traits varies substantially, which aligns with the\nrepresentational distances in our probing experiments. Finally, we conduct a\ncomprehensive MMLU benchmark evaluation and time overhead analysis,\ndemonstrating that our proposed personality editing method incurs only minimal\ndegradation in general capabilities while maintaining low training costs and\nacceptable inference latency. Our code is publicly available at\nhttps://github.com/universe-sky/probing-then-editing-personality.", "published": "2025-04-14 13:46:35", "link": "http://arxiv.org/abs/2504.10227v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DioR: Adaptive Cognitive Detection and Contextual Retrieval Optimization for Dynamic Retrieval-Augmented Generation", "abstract": "Dynamic Retrieval-augmented Generation (RAG) has shown great success in\nmitigating hallucinations in large language models (LLMs) during generation.\nHowever, existing dynamic RAG methods face significant limitations in two key\naspects: 1) Lack of an effective mechanism to control retrieval triggers, and\n2) Lack of effective scrutiny of retrieval content. To address these\nlimitations, we propose an innovative dynamic RAG method, DioR (Adaptive\nCognitive Detection and Contextual Retrieval Optimization), which consists of\ntwo main components: adaptive cognitive detection and contextual retrieval\noptimization, specifically designed to determine when retrieval is needed and\nwhat to retrieve for LLMs is useful. Experimental results demonstrate that DioR\nachieves superior performance on all tasks, demonstrating the effectiveness of\nour work.", "published": "2025-04-14 13:02:53", "link": "http://arxiv.org/abs/2504.10198v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Localized Cultural Knowledge is Conserved and Controllable in Large Language Models", "abstract": "Just as humans display language patterns influenced by their native tongue\nwhen speaking new languages, LLMs often default to English-centric responses\neven when generating in other languages. Nevertheless, we observe that local\ncultural information persists within the models and can be readily activated\nfor cultural customization. We first demonstrate that explicitly providing\ncultural context in prompts significantly improves the models' ability to\ngenerate culturally localized responses. We term the disparity in model\nperformance with versus without explicit cultural context the explicit-implicit\nlocalization gap, indicating that while cultural knowledge exists within LLMs,\nit may not naturally surface in multilingual interactions if cultural context\nis not explicitly provided. Despite the explicit prompting benefit, however,\nthe answers reduce in diversity and tend toward stereotypes. Second, we\nidentify an explicit cultural customization vector, conserved across all\nnon-English languages we explore, which enables LLMs to be steered from the\nsynthetic English cultural world-model toward each non-English cultural world.\nSteered responses retain the diversity of implicit prompting and reduce\nstereotypes to dramatically improve the potential for customization. We discuss\nthe implications of explicit cultural customization for understanding the\nconservation of alternative cultural world models within LLMs, and their\ncontrollable utility for translation, cultural customization, and the\npossibility of making the explicit implicit through soft control for expanded\nLLM function and appeal.", "published": "2025-04-14 12:53:58", "link": "http://arxiv.org/abs/2504.10191v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Deep Reasoning Translation via Reinforcement Learning", "abstract": "Recently, deep reasoning LLMs (e.g., OpenAI o1/o3 and DeepSeek-R1) have shown\npromising performance in various complex tasks. Free translation is an\nimportant and interesting task in the multilingual world, which requires going\nbeyond word-for-word translation and taking cultural differences into account.\nThis task is still under-explored in deep reasoning LLMs. In this paper, we\nintroduce DeepTrans, a deep reasoning translation model that learns free\ntranslation via reinforcement learning. Specifically, we carefully build a\nreward model with pre-defined scoring criteria on both the translation results\nand the thought process. Given the source sentences, the reward model teaches\nthe deep translation model how to think and free-translate them during\nreinforcement learning. In this way, training DeepTrans does not need any\nlabeled translations, avoiding the human-intensive annotation or\nresource-intensive data synthesis. Experimental results show the effectiveness\nof DeepTrans. Using Qwen2.5-7B as the backbone, DeepTrans improves performance\nby 16.3% in literature translation, and outperforms strong deep reasoning\nbaselines as well as baselines that are fine-tuned with synthesized data.\nMoreover, we summarize the failures and interesting findings during our RL\nexploration. We hope this work could inspire other researchers in free\ntranslation.", "published": "2025-04-14 12:40:39", "link": "http://arxiv.org/abs/2504.10187v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LLM Unlearning Reveals a Stronger-Than-Expected Coreset Effect in Current Benchmarks", "abstract": "Large language model unlearning has become a critical challenge in ensuring\nsafety and controlled model behavior by removing undesired data-model\ninfluences from the pretrained model while preserving general utility.\nSignificant recent efforts have been dedicated to developing LLM unlearning\nbenchmarks such as WMDP (Weapons of Mass Destruction Proxy) and MUSE (Machine\nUnlearning Six-way Evaluation), facilitating standardized unlearning\nperformance assessment and method comparison. Despite their usefulness, we\nuncover for the first time a novel coreset effect within these benchmarks.\nSpecifically, we find that LLM unlearning achieved with the original (full)\nforget set can be effectively maintained using a significantly smaller subset\n(functioning as a \"coreset\"), e.g., as little as 5% of the forget set, even\nwhen selected at random. This suggests that LLM unlearning in these benchmarks\ncan be performed surprisingly easily, even in an extremely low-data regime. We\ndemonstrate that this coreset effect remains strong, regardless of the LLM\nunlearning method used, such as NPO (Negative Preference Optimization) and RMU\n(Representation Misdirection Unlearning), the popular ones in these benchmarks.\nThe surprisingly strong coreset effect is also robust across various data\nselection methods, ranging from random selection to more sophisticated\nheuristic approaches. We explain the coreset effect in LLM unlearning through a\nkeyword-based perspective, showing that keywords extracted from the forget set\nalone contribute significantly to unlearning effectiveness and indicating that\ncurrent unlearning is driven by a compact set of high-impact tokens rather than\nthe entire dataset. We further justify the faithfulness of coreset-unlearned\nmodels along additional dimensions, such as mode connectivity and robustness to\njailbreaking attacks. Codes are available at\nhttps://github.com/OPTML-Group/MU-Coreset.", "published": "2025-04-14 12:38:37", "link": "http://arxiv.org/abs/2504.10185v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Future of MLLM Prompting is Adaptive: A Comprehensive Experimental Evaluation of Prompt Engineering Methods for Robust Multimodal Performance", "abstract": "Multimodal Large Language Models (MLLMs) are set to transform how machines\nprocess and generate human-like responses by integrating diverse modalities\nsuch as text, images, and code. Yet, effectively harnessing their capabilities\nhinges on optimal prompt engineering. We present a comprehensive experimental\nevaluation of seven prompt engineering methods applied to 13 open-source MLLMs\nover 24 tasks spanning Reasoning and Compositionality, Multimodal Understanding\nand Alignment, Complex Code Generation and Execution, and Knowledge Retrieval\nand Integration. Our approach stratifies models by parameter count into Small\n(<4B), Medium (4B-10B), and Large (>10B) categories and compares prompting\ntechniques including Zero-Shot, One-Shot, Few-Shot, Chain-of-Thought,\nAnalogical, Generated Knowledge, and Tree-of-Thought. While Large MLLMs excel\nin structured tasks such as code generation, achieving accuracies up to 96.88%\nunder Few-Shot prompting, all models struggle with complex reasoning and\nabstract understanding, often yielding accuracies below 60% and high\nhallucination rates. Structured reasoning prompts frequently increased\nhallucination up to 75% in small models and led to longer response times (over\n20 seconds in Large MLLMs), while simpler prompting methods provided more\nconcise and efficient outputs. No single prompting method uniformly optimises\nall task types. Instead, adaptive strategies combining example-based guidance\nwith selective structured reasoning are essential to enhance robustness,\nefficiency, and factual accuracy. Our findings offer practical recommendations\nfor prompt engineering and support more reliable deployment of MLLMs across\napplications including AI-assisted coding, knowledge retrieval, and multimodal\ncontent understanding.", "published": "2025-04-14 12:31:39", "link": "http://arxiv.org/abs/2504.10179v1", "categories": ["cs.AI", "cs.CL", "cs.ET"], "primary_category": "cs.AI"}
{"title": "HalluSearch at SemEval-2025 Task 3: A Search-Enhanced RAG Pipeline for Hallucination Detection", "abstract": "In this paper, we present HalluSearch, a multilingual pipeline designed to\ndetect fabricated text spans in Large Language Model (LLM) outputs. Developed\nas part of Mu-SHROOM, the Multilingual Shared-task on Hallucinations and\nRelated Observable Overgeneration Mistakes, HalluSearch couples\nretrieval-augmented verification with fine-grained factual splitting to\nidentify and localize hallucinations in fourteen different languages. Empirical\nevaluations show that HalluSearch performs competitively, placing fourth in\nboth English (within the top ten percent) and Czech. While the system's\nretrieval-based strategy generally proves robust, it faces challenges in\nlanguages with limited online coverage, underscoring the need for further\nresearch to ensure consistent hallucination detection across diverse linguistic\ncontexts.", "published": "2025-04-14 12:22:30", "link": "http://arxiv.org/abs/2504.10168v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "C-FAITH: A Chinese Fine-Grained Benchmark for Automated Hallucination Evaluation", "abstract": "Despite the rapid advancement of large language models, they remain highly\nsusceptible to generating hallucinations, which significantly hinders their\nwidespread application. Hallucination research requires dynamic and\nfine-grained evaluation. However, most existing hallucination benchmarks\n(especially in Chinese language) rely on human annotations, making automatical\nand cost-effective hallucination evaluation challenging. To address this, we\nintroduce HaluAgent, an agentic framework that automatically constructs\nfine-grained QA dataset based on some knowledge documents. Our experiments\ndemonstrate that the manually designed rules and prompt optimization can\nimprove the quality of generated data. Using HaluAgent, we construct C-FAITH, a\nChinese QA hallucination benchmark created from 1,399 knowledge documents\nobtained from web scraping, totaling 60,702 entries. We comprehensively\nevaluate 16 mainstream LLMs with our proposed C-FAITH, providing detailed\nexperimental results and analysis.", "published": "2025-04-14 12:21:55", "link": "http://arxiv.org/abs/2504.10167v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MT-R1-Zero: Advancing LLM-based Machine Translation via R1-Zero-like Reinforcement Learning", "abstract": "Large-scale reinforcement learning (RL) methods have proven highly effective\nin enhancing the reasoning abilities of large language models (LLMs),\nparticularly for tasks with verifiable solutions such as mathematics and\ncoding. However, applying this idea to machine translation (MT), where outputs\nare flexibly formatted and difficult to automatically evaluate with explicit\nrules, remains underexplored. In this work, we introduce MT-R1-Zero, the first\nopen-source adaptation of the R1-Zero RL framework for MT without supervised\nfine-tuning or cold-start. We propose a rule-metric mixed reward mechanism to\nguide LLMs towards improved translation quality via emergent reasoning. On the\nWMT 24 English-Chinese benchmark, our MT-R1-Zero-3B-Mix achieves competitive\nperformance, surpassing TowerInstruct-7B-v0.2 by an average of 1.26 points.\nMeanwhile, our MT-R1-Zero-7B-Mix attains a high average score of 62.25 across\nall metrics, placing it on par with advanced proprietary models such as GPT-4o\nand Claude-3.5-Sonnet, while the MT-R1-Zero-7B-Sem variant achieves\nstate-of-the-art scores on semantic metrics. Moreover, our work exhibits strong\ngeneralization capabilities on out-of-distribution MT tasks, robustly\nsupporting multilingual and low-resource settings. Extensive analysis of model\nbehavior across different initializations and reward metrics offers pioneering\ninsight into the critical role of reward design, LLM adaptability, training\ndynamics, and emergent reasoning patterns within the R1-Zero paradigm for MT.\nOur code is available at https://github.com/fzp0424/MT-R1-Zero.", "published": "2025-04-14 12:14:18", "link": "http://arxiv.org/abs/2504.10160v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SocioVerse: A World Model for Social Simulation Powered by LLM Agents and A Pool of 10 Million Real-World Users", "abstract": "Social simulation is transforming traditional social science research by\nmodeling human behavior through interactions between virtual individuals and\ntheir environments. With recent advances in large language models (LLMs), this\napproach has shown growing potential in capturing individual differences and\npredicting group behaviors. However, existing methods face alignment challenges\nrelated to the environment, target users, interaction mechanisms, and\nbehavioral patterns. To this end, we introduce SocioVerse, an LLM-agent-driven\nworld model for social simulation. Our framework features four powerful\nalignment components and a user pool of 10 million real individuals. To\nvalidate its effectiveness, we conducted large-scale simulation experiments\nacross three distinct domains: politics, news, and economics. Results\ndemonstrate that SocioVerse can reflect large-scale population dynamics while\nensuring diversity, credibility, and representativeness through standardized\nprocedures and minimal manual adjustments.", "published": "2025-04-14 12:12:52", "link": "http://arxiv.org/abs/2504.10157v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Breaking the Data Barrier -- Building GUI Agents Through Task Generalization", "abstract": "Graphical User Interface (GUI) agents offer cross-platform solutions for\nautomating complex digital tasks, with significant potential to transform\nproductivity workflows. However, their performance is often constrained by the\nscarcity of high-quality trajectory data. To address this limitation, we\npropose training Vision Language Models (VLMs) on data-rich,\nreasoning-intensive tasks during a dedicated mid-training stage, and then\nexamine how incorporating these tasks facilitates generalization to GUI\nplanning scenarios. Specifically, we explore a range of tasks with readily\navailable instruction-tuning data, including GUI perception, multimodal\nreasoning, and textual reasoning. Through extensive experiments across 11\nmid-training tasks, we demonstrate that: (1) Task generalization proves highly\neffective, yielding substantial improvements across most settings. For\ninstance, multimodal mathematical reasoning enhances performance on\nAndroidWorld by an absolute 6.3%. Remarkably, text-only mathematical data\nsignificantly boosts GUI web agent performance, achieving a 5.6% improvement on\nWebArena and 5.4% improvement on AndroidWorld, underscoring notable cross-modal\ngeneralization from text-based to visual domains; (2) Contrary to prior\nassumptions, GUI perception data - previously considered closely aligned with\nGUI agent tasks and widely utilized for training - has a comparatively limited\nimpact on final performance; (3) Building on these insights, we identify the\nmost effective mid-training tasks and curate optimized mixture datasets,\nresulting in absolute performance gains of 8.0% on WebArena and 12.2% on\nAndroidWorld. Our work provides valuable insights into cross-domain knowledge\ntransfer for GUI agents and offers a practical approach to addressing data\nscarcity challenges in this emerging field. The code, data and models will be\navailable at https://github.com/hkust-nlp/GUIMid.", "published": "2025-04-14 11:35:02", "link": "http://arxiv.org/abs/2504.10127v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "CameraBench: Benchmarking Visual Reasoning in MLLMs via Photography", "abstract": "Large language models (LLMs) and multimodal large language models (MLLMs)\nhave significantly advanced artificial intelligence. However, visual reasoning,\nreasoning involving both visual and textual inputs, remains underexplored.\nRecent advancements, including the reasoning models like OpenAI o1 and Gemini\n2.0 Flash Thinking, which incorporate image inputs, have opened this\ncapability. In this ongoing work, we focus specifically on photography-related\ntasks because a photo is a visual snapshot of the physical world where the\nunderlying physics (i.e., illumination, blur extent, etc.) interplay with the\ncamera parameters. Successfully reasoning from the visual information of a\nphoto to identify these numerical camera settings requires the MLLMs to have a\ndeeper understanding of the underlying physics for precise visual\ncomprehension, representing a challenging and intelligent capability essential\nfor practical applications like photography assistant agents. We aim to\nevaluate MLLMs on their ability to distinguish visual differences related to\nnumerical camera settings, extending a methodology previously proposed for\nvision-language models (VLMs). Our preliminary results demonstrate the\nimportance of visual reasoning in photography-related tasks. Moreover, these\nresults show that no single MLLM consistently dominates across all evaluation\ntasks, demonstrating ongoing challenges and opportunities in developing MLLMs\nwith better visual reasoning.", "published": "2025-04-14 10:53:44", "link": "http://arxiv.org/abs/2504.10090v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "RealSafe-R1: Safety-Aligned DeepSeek-R1 without Compromising Reasoning Capability", "abstract": "Large Reasoning Models (LRMs), such as OpenAI o1 and DeepSeek-R1, have been\nrapidly progressing and achieving breakthrough performance on complex reasoning\ntasks such as mathematics and coding. However, the open-source R1 models have\nraised safety concerns in wide applications, such as the tendency to comply\nwith malicious queries, which greatly impacts the utility of these powerful\nmodels in their applications. In this paper, we introduce RealSafe-R1 as\nsafety-aligned versions of DeepSeek-R1 distilled models. To train these models,\nwe construct a dataset of 15k safety-aware reasoning trajectories generated by\nDeepSeek-R1, under explicit instructions for expected refusal behavior. Both\nquantitative experiments and qualitative case studies demonstrate the models'\nimprovements, which are shown in their safety guardrails against both harmful\nqueries and jailbreak attacks. Importantly, unlike prior safety alignment\nefforts that often compromise reasoning performance, our method preserves the\nmodels' reasoning capabilities by maintaining the training data within the\noriginal distribution of generation. Model weights of RealSafe-R1 are\nopen-source at https://huggingface.co/RealSafe.", "published": "2025-04-14 10:26:37", "link": "http://arxiv.org/abs/2504.10081v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Towards Quantifying Commonsense Reasoning with Mechanistic Insights", "abstract": "Commonsense reasoning deals with the implicit knowledge that is well\nunderstood by humans and typically acquired via interactions with the world. In\nrecent times, commonsense reasoning and understanding of various LLMs have been\nevaluated using text-based tasks. In this work, we argue that a proxy of this\nunderstanding can be maintained as a graphical structure that can further help\nto perform a rigorous evaluation of commonsense reasoning abilities about\nvarious real-world activities. We create an annotation scheme for capturing\nthis implicit knowledge in the form of a graphical structure for 37 daily human\nactivities. We find that the created resource can be used to frame an enormous\nnumber of commonsense queries (~ 10^{17}), facilitating rigorous evaluation of\ncommonsense reasoning in LLMs. Moreover, recently, the remarkable performance\nof LLMs has raised questions about whether these models are truly capable of\nreasoning in the wild and, in general, how reasoning occurs inside these\nmodels. In this resource paper, we bridge this gap by proposing design\nmechanisms that facilitate research in a similar direction. Our findings\nsuggest that the reasoning components are localized in LLMs that play a\nprominent role in decision-making when prompted with a commonsense query.", "published": "2025-04-14 10:21:59", "link": "http://arxiv.org/abs/2504.10077v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Mavors: Multi-granularity Video Representation for Multimodal Large Language Model", "abstract": "Long-context video understanding in multimodal large language models (MLLMs)\nfaces a critical challenge: balancing computational efficiency with the\nretention of fine-grained spatio-temporal patterns. Existing approaches (e.g.,\nsparse sampling, dense sampling with low resolution, and token compression)\nsuffer from significant information loss in temporal dynamics, spatial details,\nor subtle interactions, particularly in videos with complex motion or varying\nresolutions. To address this, we propose $\\mathbf{Mavors}$, a novel framework\nthat introduces $\\mathbf{M}$ulti-gr$\\mathbf{a}$nularity\n$\\mathbf{v}$ide$\\mathbf{o}$ $\\mathbf{r}$epre$\\mathbf{s}$entation for holistic\nlong-video modeling. Specifically, Mavors directly encodes raw video content\ninto latent representations through two core components: 1) an Intra-chunk\nVision Encoder (IVE) that preserves high-resolution spatial features via 3D\nconvolutions and Vision Transformers, and 2) an Inter-chunk Feature Aggregator\n(IFA) that establishes temporal coherence across chunks using transformer-based\ndependency modeling with chunk-level rotary position encodings. Moreover, the\nframework unifies image and video understanding by treating images as\nsingle-frame videos via sub-image decomposition. Experiments across diverse\nbenchmarks demonstrate Mavors' superiority in maintaining both spatial fidelity\nand temporal continuity, significantly outperforming existing methods in tasks\nrequiring fine-grained spatio-temporal reasoning.", "published": "2025-04-14 10:14:44", "link": "http://arxiv.org/abs/2504.10068v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "A Computational Cognitive Model for Processing Repetitions of Hierarchical Relations", "abstract": "Patterns are fundamental to human cognition, enabling the recognition of\nstructure and regularity across diverse domains. In this work, we focus on\nstructural repeats, patterns that arise from the repetition of hierarchical\nrelations within sequential data, and develop a candidate computational model\nof how humans detect and understand such structural repeats. Based on a\nweighted deduction system, our model infers the minimal generative process of a\ngiven sequence in the form of a Template program, a formalism that enriches the\ncontext-free grammar with repetition combinators. Such representation\nefficiently encodes the repetition of sub-computations in a recursive manner.\nAs a proof of concept, we demonstrate the expressiveness of our model on short\nsequences from music and action planning. The proposed model offers broader\ninsights into the mental representations and cognitive mechanisms underlying\nhuman pattern recognition.", "published": "2025-04-14 10:08:28", "link": "http://arxiv.org/abs/2504.10065v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hallucination Detection in LLMs via Topological Divergence on Attention Graphs", "abstract": "Hallucination, i.e., generating factually incorrect content, remains a\ncritical challenge for large language models (LLMs). We introduce TOHA, a\nTOpology-based HAllucination detector in the RAG setting, which leverages a\ntopological divergence metric to quantify the structural properties of graphs\ninduced by attention matrices. Examining the topological divergence between\nprompt and response subgraphs reveals consistent patterns: higher divergence\nvalues in specific attention heads correlate with hallucinated outputs,\nindependent of the dataset. Extensive experiments, including evaluation on\nquestion answering and data-to-text tasks, show that our approach achieves\nstate-of-the-art or competitive results on several benchmarks, two of which\nwere annotated by us and are being publicly released to facilitate further\nresearch. Beyond its strong in-domain performance, TOHA maintains remarkable\ndomain transferability across multiple open-source LLMs. Our findings suggest\nthat analyzing the topological structure of attention matrices can serve as an\nefficient and robust indicator of factual reliability in LLMs.", "published": "2025-04-14 10:06:27", "link": "http://arxiv.org/abs/2504.10063v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Joint Action Language Modelling for Transparent Policy Execution", "abstract": "An agent's intention often remains hidden behind the black-box nature of\nembodied policies. Communication using natural language statements that\ndescribe the next action can provide transparency towards the agent's behavior.\nWe aim to insert transparent behavior directly into the learning process, by\ntransforming the problem of policy learning into a language generation problem\nand combining it with traditional autoregressive modelling. The resulting model\nproduces transparent natural language statements followed by tokens\nrepresenting the specific actions to solve long-horizon tasks in the\nLanguage-Table environment. Following previous work, the model is able to learn\nto produce a policy represented by special discretized tokens in an\nautoregressive manner. We place special emphasis on investigating the\nrelationship between predicting actions and producing high-quality language for\na transparent agent. We find that in many cases both the quality of the action\ntrajectory and the transparent statement increase when they are generated\nsimultaneously.", "published": "2025-04-14 09:57:37", "link": "http://arxiv.org/abs/2504.10055v1", "categories": ["cs.RO", "cs.CL"], "primary_category": "cs.RO"}
{"title": "Summarization of Multimodal Presentations with Vision-Language Models: Study of the Effect of Modalities and Structure", "abstract": "Vision-Language Models (VLMs) can process visual and textual information in\nmultiple formats: texts, images, interleaved texts and images, or even\nhour-long videos. In this work, we conduct fine-grained quantitative and\nqualitative analyses of automatic summarization of multimodal presentations\nusing VLMs with various representations as input. From these experiments, we\nsuggest cost-effective strategies for generating summaries from text-heavy\nmultimodal documents under different input-length budgets using VLMs. We show\nthat slides extracted from the video stream can be beneficially used as input\nagainst the raw video, and that a structured representation from interleaved\nslides and transcript provides the best performance. Finally, we reflect and\ncomment on the nature of cross-modal interactions in multimodal presentations\nand share suggestions to improve the capabilities of VLMs to understand\ndocuments of this nature.", "published": "2025-04-14 09:55:01", "link": "http://arxiv.org/abs/2504.10049v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "DataMosaic: Explainable and Verifiable Multi-Modal Data Analytics through Extract-Reason-Verify", "abstract": "Large Language Models (LLMs) are transforming data analytics, but their\nwidespread adoption is hindered by two critical limitations: they are not\nexplainable (opaque reasoning processes) and not verifiable (prone to\nhallucinations and unchecked errors). While retrieval-augmented generation\n(RAG) improves accuracy by grounding LLMs in external data, it fails to address\nthe core challenges of trustworthy analytics - especially when processing\nnoisy, inconsistent, or multi-modal data (for example, text, tables, images).\nWe propose DataMosaic, a framework designed to make LLM-powered analytics both\nexplainable and verifiable. By dynamically extracting task-specific structures\n(for example, tables, graphs, trees) from raw data, DataMosaic provides\ntransparent, step-by-step reasoning traces and enables validation of\nintermediate results. Built on a multi-agent framework, DataMosaic orchestrates\nself-adaptive agents that align with downstream task requirements, enhancing\nconsistency, completeness, and privacy. Through this approach, DataMosaic not\nonly tackles the limitations of current LLM-powered analytics systems but also\nlays the groundwork for a new paradigm of grounded, accurate, and explainable\nmulti-modal data analytics.", "published": "2025-04-14 09:38:23", "link": "http://arxiv.org/abs/2504.10036v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Mirage of Performance Gains: Why Contrastive Decoding Fails to Address Multimodal Hallucination", "abstract": "Contrastive decoding strategies are widely used to reduce hallucinations in\nmultimodal large language models (MLLMs). These methods work by constructing\ncontrastive samples to induce hallucinations and then suppressing them in the\noutput distribution. However, this paper demonstrates that such approaches fail\nto effectively mitigate the hallucination problem. The performance improvements\nobserved on POPE Benchmark are largely driven by two misleading factors: (1)\ncrude, unidirectional adjustments to the model's output distribution and (2)\nthe adaptive plausibility constraint, which reduces the sampling strategy to\ngreedy search. To further illustrate these issues, we introduce a series of\nspurious improvement methods and evaluate their performance against contrastive\ndecoding techniques. Experimental results reveal that the observed performance\ngains in contrastive decoding are entirely unrelated to its intended goal of\nmitigating hallucinations. Our findings challenge common assumptions about the\neffectiveness of contrastive decoding strategies and pave the way for\ndeveloping genuinely effective solutions to hallucinations in MLLMs.", "published": "2025-04-14 09:25:37", "link": "http://arxiv.org/abs/2504.10020v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Do We Really Need Curated Malicious Data for Safety Alignment in Multi-modal Large Language Models?", "abstract": "Multi-modal large language models (MLLMs) have made significant progress, yet\ntheir safety alignment remains limited. Typically, current open-source MLLMs\nrely on the alignment inherited from their language module to avoid harmful\ngenerations. However, the lack of safety measures specifically designed for\nmulti-modal inputs creates an alignment gap, leaving MLLMs vulnerable to\nvision-domain attacks such as typographic manipulation. Current methods utilize\na carefully designed safety dataset to enhance model defense capability, while\nthe specific knowledge or patterns acquired from the high-quality dataset\nremain unclear. Through comparison experiments, we find that the alignment gap\nprimarily arises from data distribution biases, while image content, response\nquality, or the contrastive behavior of the dataset makes little contribution\nto boosting multi-modal safety. To further investigate this and identify the\nkey factors in improving MLLM safety, we propose finetuning MLLMs on a small\nset of benign instruct-following data with responses replaced by simple, clear\nrejection sentences. Experiments show that, without the need for\nlabor-intensive collection of high-quality malicious data, model safety can\nstill be significantly improved, as long as a specific fraction of rejection\ndata exists in the finetuning set, indicating the security alignment is not\nlost but rather obscured during multi-modal pretraining or instruction\nfinetuning. Simply correcting the underlying data bias could narrow the safety\ngap in the vision domain.", "published": "2025-04-14 09:03:51", "link": "http://arxiv.org/abs/2504.10000v1", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Turn-taking annotation for quantitative and qualitative analyses of conversation", "abstract": "This paper has two goals. First, we present the turn-taking annotation layers\ncreated for 95 minutes of conversational speech of the Graz Corpus of Read and\nSpontaneous Speech (GRASS), available to the scientific community. Second, we\ndescribe the annotation system and the annotation process in more detail, so\nother researchers may use it for their own conversational data. The annotation\nsystem was developed with an interdisciplinary application in mind. It should\nbe based on sequential criteria according to Conversation Analysis, suitable\nfor subsequent phonetic analysis, thus time-aligned annotations were made\nPraat, and it should be suitable for automatic classification, which required\nthe continuous annotation of speech and a label inventory that is not too large\nand results in a high inter-rater agreement. Turn-taking was annotated on two\nlayers, Inter-Pausal Units (IPU) and points of potential completion (PCOMP;\nsimilar to transition relevance places). We provide a detailed description of\nthe annotation process and of segmentation and labelling criteria. A detailed\nanalysis of inter-rater agreement and common confusions shows that agreement\nfor IPU annotation is near-perfect, that agreement for PCOMP annotations is\nsubstantial, and that disagreements often are either partial or can be\nexplained by a different analysis of a sequence which also has merit. The\nannotation system can be applied to a variety of conversational data for\nlinguistic studies and technological applications, and we hope that the\nannotations, as well as the annotation system will contribute to a stronger\ncross-fertilization between these disciplines.", "published": "2025-04-14 08:45:04", "link": "http://arxiv.org/abs/2504.09980v1", "categories": ["cs.CL", "cs.DB", "cs.HC", "eess.AS"], "primary_category": "cs.CL"}
{"title": "C-MTCSD: A Chinese Multi-Turn Conversational Stance Detection Dataset", "abstract": "Stance detection has become an essential tool for analyzing public\ndiscussions on social media. Current methods face significant challenges,\nparticularly in Chinese language processing and multi-turn conversational\nanalysis. To address these limitations, we introduce C-MTCSD, the largest\nChinese multi-turn conversational stance detection dataset, comprising 24,264\ncarefully annotated instances from Sina Weibo, which is 4.2 times larger than\nthe only prior Chinese conversational stance detection dataset. Our\ncomprehensive evaluation using both traditional approaches and large language\nmodels reveals the complexity of C-MTCSD: even state-of-the-art models achieve\nonly 64.07% F1 score in the challenging zero-shot setting, while performance\nconsistently degrades with increasing conversation depth. Traditional models\nparticularly struggle with implicit stance detection, achieving below 50% F1\nscore. This work establishes a challenging new benchmark for Chinese stance\ndetection research, highlighting significant opportunities for future\nimprovements.", "published": "2025-04-14 07:55:47", "link": "http://arxiv.org/abs/2504.09958v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Assessing Judging Bias in Large Reasoning Models: An Empirical Study", "abstract": "Large Reasoning Models (LRMs) like DeepSeek-R1 and OpenAI-o1 have\ndemonstrated remarkable reasoning capabilities, raising important questions\nabout their biases in LLM-as-a-judge settings. We present a comprehensive\nbenchmark comparing judging biases between LLMs and LRMs across both subjective\npreference-alignment datasets and objective fact-based datasets. Through\ninvestigation of bandwagon, authority, position, and distraction biases, we\nuncover four key findings: (1) despite their advanced reasoning capabilities,\nLRMs remain susceptible to the above biases; (2) LRMs demonstrate better\nrobustness than LLMs specifically on fact-related datasets; (3) LRMs exhibit\nnotable position bias, preferring options in later positions; and (4) we\nidentify a novel \"superficial reflection bias\" where phrases mimicking\nreasoning (e.g., \"wait, let me think...\") significantly influence model\njudgments. To address these biases, we design and evaluate three mitigation\nstrategies: specialized system prompts that reduce judging biases by up to 19\\%\nin preference alignment datasets and 14\\% in fact-related datasets, in-context\nlearning that provides up to 27\\% improvement on preference tasks but shows\ninconsistent results on factual tasks, and a self-reflection mechanism that\nreduces biases by up to 10\\% in preference datasets and 16\\% in fact-related\ndatasets, with self-reflection proving particularly effective for LRMs. Our\nwork provides crucial insights for developing more reliable LLM-as-a-Judge\nframeworks, especially as LRMs become increasingly deployed as automated\njudges.", "published": "2025-04-14 07:14:27", "link": "http://arxiv.org/abs/2504.09946v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "KeepKV: Eliminating Output Perturbation in KV Cache Compression for Efficient LLMs Inference", "abstract": "Efficient inference of large language models (LLMs) is hindered by an\never-growing key-value (KV) cache, making KV cache compression a critical\nresearch direction. Traditional methods selectively evict less important KV\ncache entries based on attention scores or position heuristics, which leads to\ninformation loss and hallucinations. Recently, merging-based strategies have\nbeen explored to retain more information by merging KV pairs that would be\ndiscarded; however, these existing approaches inevitably introduce\ninconsistencies in attention distributions before and after merging, causing\noutput perturbation and degraded generation quality. To overcome this\nchallenge, we propose KeepKV, a novel adaptive KV cache merging method designed\nto eliminate output perturbation while preserving performance under strict\nmemory constraints. KeepKV introduces the Electoral Votes mechanism that\nrecords merging history and adaptively adjusts attention scores. Moreover, it\nfurther leverages a novel Zero Inference-Perturbation Merging methods, keeping\nattention consistency and compensating for attention loss resulting from cache\nmerging. KeepKV successfully retains essential context information within a\nsignificantly compressed cache. Extensive experiments on various benchmarks and\nLLM architectures demonstrate that KeepKV substantially reduces memory usage,\nenhances inference throughput by more than 2x and keeps superior generation\nquality even with 10% KV cache budgets.", "published": "2025-04-14 06:58:00", "link": "http://arxiv.org/abs/2504.09936v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Guiding Reasoning in Small Language Models with LLM Assistance", "abstract": "The limited reasoning capabilities of small language models (SLMs) cast doubt\non their suitability for tasks demanding deep, multi-step logical deduction.\nThis paper introduces a framework called Small Reasons, Large Hints (SMART),\nwhich selectively augments SLM reasoning with targeted guidance from large\nlanguage models (LLMs). Inspired by the concept of cognitive scaffolding, SMART\nemploys a score-based evaluation to identify uncertain reasoning steps and\ninjects corrective LLM-generated reasoning only when necessary. By framing\nstructured reasoning as an optimal policy search, our approach steers the\nreasoning trajectory toward correct solutions without exhaustive sampling. Our\nexperiments on mathematical reasoning datasets demonstrate that targeted\nexternal scaffolding significantly improves performance, paving the way for\ncollaborative use of both SLM and LLM to tackle complex reasoning tasks that\nare currently unsolvable by SLMs alone.", "published": "2025-04-14 06:32:45", "link": "http://arxiv.org/abs/2504.09923v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Erase Private Knowledge from Multi-Documents for Retrieval-Augmented Large Language Models", "abstract": "Retrieval-Augmented Generation (RAG) is a promising technique for applying\nLLMs to proprietary domains. However, retrieved documents may contain sensitive\nknowledge, posing risks of privacy leakage in generative results. Thus,\neffectively erasing private information from retrieved documents is a key\nchallenge for RAG. Unlike traditional text anonymization, RAG should consider:\n(1) the inherent multi-document reasoning may face de-anonymization attacks;\n(2) private knowledge varies by scenarios, so users should be allowed to\ncustomize which information to erase; (3) preserving sufficient publicly\navailable knowledge for generation tasks. This paper introduces the privacy\nerasure task for RAG and proposes Eraser4RAG, a private knowledge eraser which\neffectively removes user-defined private knowledge from documents while\npreserving sufficient public knowledge for generation. Specifically, we first\nconstruct a global knowledge graph to identify potential knowledge across\ndocuments, aiming to defend against de-anonymization attacks. Then we randomly\nsplit it into private and public sub-graphs, and fine-tune Flan-T5 to rewrite\nthe retrieved documents excluding private triples. Finally, PPO algorithm\noptimizes the rewriting model to minimize private triples and maximize public\ntriples retention. Experiments on four QA datasets demonstrate that Eraser4RAG\nachieves superior erase performance than GPT-4o.", "published": "2025-04-14 06:10:31", "link": "http://arxiv.org/abs/2504.09910v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Quantum Natural Language Processing: A Comprehensive Review of Models, Methods, and Applications", "abstract": "In recent developments, deep learning methodologies applied to Natural\nLanguage Processing (NLP) have revealed a paradox: They improve performance but\ndemand considerable data and resources for their training. Alternatively,\nquantum computing exploits the principles of quantum mechanics to overcome the\ncomputational limitations of current methodologies, thereby establishing an\nemerging field known as quantum natural language processing (QNLP). This domain\nholds the potential to attain a quantum advantage in the processing of\nlinguistic structures, surpassing classical models in both efficiency and\naccuracy. In this paper, it is proposed to categorise QNLP models based on\nquantum computing principles, architecture, and computational approaches. This\npaper attempts to provide a survey on how quantum meets language by mapping\nstate-of-the-art in this area, embracing quantum encoding techniques for\nclassical data, QNLP models for prevalent NLP tasks, and quantum optimisation\ntechniques for hyper parameter tuning. The landscape of quantum computing\napproaches applied to various NLP tasks is summarised by showcasing the\nspecific QNLP methods used, and the popularity of these methods is indicated by\ntheir count. From the findings, it is observed that QNLP approaches are still\nlimited to small data sets, with only a few models explored extensively, and\nthere is increasing interest in the application of quantum computing to natural\nlanguage processing tasks.", "published": "2025-04-14 06:09:26", "link": "http://arxiv.org/abs/2504.09909v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Refining Financial Consumer Complaints through Multi-Scale Model Interaction", "abstract": "Legal writing demands clarity, formality, and domain-specific\nprecision-qualities often lacking in documents authored by individuals without\nlegal training. To bridge this gap, this paper explores the task of legal text\nrefinement that transforms informal, conversational inputs into persuasive\nlegal arguments. We introduce FinDR, a Chinese dataset of financial dispute\nrecords, annotated with official judgments on claim reasonableness. Our\nproposed method, Multi-Scale Model Interaction (MSMI), leverages a lightweight\nclassifier to evaluate outputs and guide iterative refinement by Large Language\nModels (LLMs). Experimental results demonstrate that MSMI significantly\noutperforms single-pass prompting strategies. Additionally, we validate the\ngeneralizability of MSMI on several short-text benchmarks, showing improved\nadversarial robustness. Our findings reveal the potential of multi-model\ncollaboration for enhancing legal document generation and broader text\nrefinement tasks.", "published": "2025-04-14 05:51:31", "link": "http://arxiv.org/abs/2504.09903v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TWSSenti: A Novel Hybrid Framework for Topic-Wise Sentiment Analysis on Social Media Using Transformer Models", "abstract": "Sentiment analysis is a crucial task in natural language processing (NLP)\nthat enables the extraction of meaningful insights from textual data,\nparticularly from dynamic platforms like Twitter and IMDB. This study explores\na hybrid framework combining transformer-based models, specifically BERT,\nGPT-2, RoBERTa, XLNet, and DistilBERT, to improve sentiment classification\naccuracy and robustness. The framework addresses challenges such as noisy data,\ncontextual ambiguity, and generalization across diverse datasets by leveraging\nthe unique strengths of these models. BERT captures bidirectional context,\nGPT-2 enhances generative capabilities, RoBERTa optimizes contextual\nunderstanding with larger corpora and dynamic masking, XLNet models dependency\nthrough permutation-based learning, and DistilBERT offers efficiency with\nreduced computational overhead while maintaining high accuracy. We demonstrate\ntext cleaning, tokenization, and feature extraction using Term Frequency\nInverse Document Frequency (TF-IDF) and Bag of Words (BoW), ensure high-quality\ninput data for the models. The hybrid approach was evaluated on benchmark\ndatasets Sentiment140 and IMDB, achieving superior accuracy rates of 94\\% and\n95\\%, respectively, outperforming standalone models. The results validate the\neffectiveness of combining multiple transformer models in ensemble-like setups\nto address the limitations of individual architectures. This research\nhighlights its applicability to real-world tasks such as social media\nmonitoring, customer sentiment analysis, and public opinion tracking which\noffers a pathway for future advancements in hybrid NLP frameworks.", "published": "2025-04-14 05:44:11", "link": "http://arxiv.org/abs/2504.09896v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning from Reference Answers: Versatile Language Model Alignment without Binary Human Preference Data", "abstract": "Large language models~(LLMs) are expected to be helpful, harmless, and\nhonest. In various alignment scenarios, such as general human preference,\nsafety, and confidence alignment, binary preference data collection and reward\nmodeling are resource-intensive but necessary for human preference\ntransferring. In this work, we explore using the similarity between sampled\ngenerations and high-quality reference answers as an alternative reward\nfunction for LLM alignment. Using similarity as a reward circumvents training\nreward models, and collecting a single reference answer potentially costs less\ntime than constructing binary preference pairs when multiple candidates are\navailable. Specifically, we develop \\textit{RefAlign}, a versatile\nREINFORCE-style alignment algorithm, which is free of reference and reward\nmodels. Instead, RefAlign utilizes BERTScore between sampled generations and\nhigh-quality reference answers as the surrogate reward. Beyond general human\npreference optimization, RefAlign can be readily extended to diverse scenarios,\nsuch as safety and confidence alignment, by incorporating the similarity reward\nwith task-related objectives. In various scenarios, {RefAlign} demonstrates\ncomparable performance to previous alignment methods while offering high\nefficiency.", "published": "2025-04-14 05:43:21", "link": "http://arxiv.org/abs/2504.09895v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Investigating Syntactic Biases in Multilingual Transformers with RC Attachment Ambiguities in Italian and English", "abstract": "This paper leverages past sentence processing studies to investigate whether\nmonolingual and multilingual LLMs show human-like preferences when presented\nwith examples of relative clause attachment ambiguities in Italian and English.\nFurthermore, we test whether these preferences can be modulated by lexical\nfactors (the type of verb/noun in the matrix clause) which have been shown to\nbe tied to subtle constraints on syntactic and semantic relations. Our results\noverall showcase how LLM behavior varies interestingly across models, but also\ngeneral failings of these models in correctly capturing human-like preferences.\nIn light of these results, we argue that RC attachment is the ideal benchmark\nfor cross-linguistic investigations of LLMs' linguistic knowledge and biases.", "published": "2025-04-14 05:19:23", "link": "http://arxiv.org/abs/2504.09886v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PASS-FC: Progressive and Adaptive Search Scheme for Fact Checking of Comprehensive Claims", "abstract": "Automated fact-checking faces challenges in handling complex real-world\nclaims. We present PASS-FC, a novel framework that addresses these issues\nthrough claim augmentation, adaptive question generation, and iterative\nverification. PASS-FC enhances atomic claims with temporal and entity context,\nemploys advanced search techniques, and utilizes a reflection mechanism. We\nevaluate PASS-FC on six diverse datasets, demonstrating superior performance\nacross general knowledge, scientific, real-world, and multilingual\nfact-checking tasks. Our framework often surpasses stronger baseline models.\nHyperparameter analysis reveals optimal settings for evidence quantity and\nreflection label triggers, while ablation studies highlight the importance of\nclaim augmentation and language-specific adaptations. PASS-FC's performance\nunderscores its effectiveness in improving fact-checking accuracy and\nadaptability across various domains. We will open-source our code and\nexperimental results to facilitate further research in this area.", "published": "2025-04-14 04:24:37", "link": "http://arxiv.org/abs/2504.09866v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reasoning Models Can Be Effective Without Thinking", "abstract": "Recent LLMs have significantly improved reasoning capabilities, primarily by\nincluding an explicit, lengthy Thinking process as part of generation. In this\npaper, we question whether this explicit thinking is necessary. Using the\nstate-of-the-art DeepSeek-R1-Distill-Qwen, we find that bypassing the thinking\nprocess via simple prompting, denoted as NoThinking, can be surprisingly\neffective. When controlling for the number of tokens, NoThinking outperforms\nThinking across a diverse set of seven challenging reasoning\ndatasets--including mathematical problem solving, formal theorem proving, and\ncoding--especially in low-budget settings, e.g., 51.3 vs. 28.9 on ACM 23 with\n700 tokens. Notably, the performance of NoThinking becomes more competitive\nwith pass@k as k increases. Building on this observation, we demonstrate that a\nparallel scaling approach that uses NoThinking to generate N outputs\nindependently and aggregates them is highly effective. For aggregation, we use\ntask-specific verifiers when available, or we apply simple best-of-N strategies\nsuch as confidence-based selection. Our method outperforms a range of baselines\nwith similar latency using Thinking, and is comparable to Thinking with\nsignificantly longer latency (up to 9x). Together, our research encourages a\nreconsideration of the necessity of lengthy thinking processes, while also\nestablishing a competitive reference for achieving strong reasoning performance\nin low-budget settings or at low latency using parallel scaling.", "published": "2025-04-14 04:08:16", "link": "http://arxiv.org/abs/2504.09858v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "A Survey of Large Language Model-Powered Spatial Intelligence Across Scales: Advances in Embodied Agents, Smart Cities, and Earth Science", "abstract": "Over the past year, the development of large language models (LLMs) has\nbrought spatial intelligence into focus, with much attention on vision-based\nembodied intelligence. However, spatial intelligence spans a broader range of\ndisciplines and scales, from navigation and urban planning to remote sensing\nand earth science. What are the differences and connections between spatial\nintelligence across these fields? In this paper, we first review human spatial\ncognition and its implications for spatial intelligence in LLMs. We then\nexamine spatial memory, knowledge representations, and abstract reasoning in\nLLMs, highlighting their roles and connections. Finally, we analyze spatial\nintelligence across scales -- from embodied to urban and global levels --\nfollowing a framework that progresses from spatial memory and understanding to\nspatial reasoning and intelligence. Through this survey, we aim to provide\ninsights into interdisciplinary spatial intelligence research and inspire\nfuture studies.", "published": "2025-04-14 03:38:31", "link": "http://arxiv.org/abs/2504.09848v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Abacus-SQL: A Text-to-SQL System Empowering Cross-Domain and Open-Domain Database Retrieval", "abstract": "The existing text-to-SQL systems have made significant progress in SQL query\ngeneration, but they still face numerous challenges. Existing systems often\nlack retrieval capabilities for open-domain databases, requiring users to\nmanually filter relevant databases. Additionally, their cross-domain\ntransferability is limited, making it challenging to accommodate diverse query\nrequirements. To address these issues, we propose Abacus-SQL. Abacus-SQL\nutilizes database retrieval technology to accurately locate the required\ndatabases in an open-domain database environment. It also enhances the system\ncross-domain transfer ability through data augmentation methods. Moreover,\nAbacus-SQL employs Pre-SQL and Self-debug methods, thereby enhancing the\naccuracy of SQL queries. Experimental results demonstrate that Abacus-SQL\nperforms excellently in multi-turn text-to-SQL tasks, effectively validating\nthe approach's effectiveness. Abacus-SQL is publicly accessible at\nhttps://huozi.8wss.com/abacus-sql/.", "published": "2025-04-14 02:49:54", "link": "http://arxiv.org/abs/2504.09824v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transferable text data distillation by trajectory matching", "abstract": "In the realm of large language model (LLM), as the size of large models\nincreases, it also brings higher training costs. There is a urgent need to\nminimize the data size in LLM training. Compared with data selection method,\nthe data distillation method aims to synthesize a small number of data samples\nto achieve the training effect of the full data set and has better flexibility.\nDespite its successes in computer vision, the discreteness of text data has\nhitherto stymied its exploration in natural language processing (NLP). In this\nwork, we proposed a method that involves learning pseudo prompt data based on\ntrajectory matching and finding its nearest neighbor ID to achieve\ncross-architecture transfer. During the distillation process, we introduce a\nregularization loss to improve the robustness of our distilled data. To our\nbest knowledge, this is the first data distillation work suitable for text\ngeneration tasks such as instruction tuning. Evaluations on two benchmarks,\nincluding ARC-Easy and MMLU instruction tuning datasets, established the\nsuperiority of our distillation approach over the SOTA data selection method\nLESS. Furthermore, our method demonstrates a good transferability over LLM\nstructures (i.e., OPT to Llama).", "published": "2025-04-14 02:39:26", "link": "http://arxiv.org/abs/2504.09818v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Augmented Relevance Datasets with Fine-Tuned Small LLMs", "abstract": "Building high-quality datasets and labeling query-document relevance are\nessential yet resource-intensive tasks, requiring detailed guidelines and\nsubstantial effort from human annotators. This paper explores the use of small,\nfine-tuned large language models (LLMs) to automate relevance assessment, with\na focus on improving ranking models' performance by augmenting their training\ndataset. We fine-tuned small LLMs to enhance relevance assessments, thereby\nimproving dataset creation quality for downstream ranking model training. Our\nexperiments demonstrate that these fine-tuned small LLMs not only outperform\ncertain closed source models on our dataset but also lead to substantial\nimprovements in ranking model performance. These results highlight the\npotential of leveraging small LLMs for efficient and scalable dataset\naugmentation, providing a practical solution for search engine optimization.", "published": "2025-04-14 02:35:00", "link": "http://arxiv.org/abs/2504.09816v1", "categories": ["cs.IR", "cs.CL", "H.3.3; I.2.7"], "primary_category": "cs.IR"}
{"title": "Training Small Reasoning LLMs with Cognitive Preference Alignment", "abstract": "The reasoning capabilities of large language models (LLMs), such as OpenAI's\no1 and DeepSeek-R1, have seen substantial advancements through deep thinking.\nHowever, these enhancements come with significant resource demands,\nunderscoring the need to explore strategies to train effective reasoning LLMs\nwith far fewer parameters. A critical challenge is that smaller models have\ndifferent capacities and cognitive trajectories than their larger counterparts.\nHence, direct distillation of chain-of-thought (CoT) results from large LLMs to\nsmaller ones can be sometimes ineffective and requires a huge amount of\nannotated data. In this paper, we introduce a novel framework called\nCritique-Rethink-Verify (CRV), designed for training smaller yet powerful\nreasoning LLMs. Our CRV framework consists of multiple LLM agents, each\nspecializing in unique abilities: (i) critiquing the CoTs according to the\ncognitive capabilities of smaller models, (ii) rethinking and refining these\nCoTs based on the critiques, and (iii) verifying the correctness of the refined\nresults. We further propose the cognitive preference optimization (CogPO)\nalgorithm to enhance the reasoning abilities of smaller models by aligning\nthoughts of these models with their cognitive capacities. Comprehensive\nevaluations on challenging reasoning benchmarks demonstrate the efficacy of CRV\nand CogPO, which outperforms other training methods by a large margin.", "published": "2025-04-14 02:03:54", "link": "http://arxiv.org/abs/2504.09802v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "VDocRAG: Retrieval-Augmented Generation over Visually-Rich Documents", "abstract": "We aim to develop a retrieval-augmented generation (RAG) framework that\nanswers questions over a corpus of visually-rich documents presented in mixed\nmodalities (e.g., charts, tables) and diverse formats (e.g., PDF, PPTX). In\nthis paper, we introduce a new RAG framework, VDocRAG, which can directly\nunderstand varied documents and modalities in a unified image format to prevent\nmissing information that occurs by parsing documents to obtain text. To improve\nthe performance, we propose novel self-supervised pre-training tasks that adapt\nlarge vision-language models for retrieval by compressing visual information\ninto dense token representations while aligning them with textual content in\ndocuments. Furthermore, we introduce OpenDocVQA, the first unified collection\nof open-domain document visual question answering datasets, encompassing\ndiverse document types and formats. OpenDocVQA provides a comprehensive\nresource for training and evaluating retrieval and question answering models on\nvisually-rich documents in an open-domain setting. Experiments show that\nVDocRAG substantially outperforms conventional text-based RAG and has strong\ngeneralization capability, highlighting the potential of an effective RAG\nparadigm for real-world documents.", "published": "2025-04-14 01:50:33", "link": "http://arxiv.org/abs/2504.09795v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Reasoning Court: Combining Reasoning, Action, and Judgment for Multi-Hop Reasoning", "abstract": "While large language models (LLMs) have demonstrated strong capabilities in\ntasks like question answering and fact verification, they continue to suffer\nfrom hallucinations and reasoning errors, especially in multi-hop tasks that\nrequire integration of multiple information sources. Current methods address\nthese issues through retrieval-based techniques (grounding reasoning in\nexternal evidence), reasoning-based approaches (enhancing coherence via\nimproved prompting), or hybrid strategies combining both elements. One\nprominent hybrid method, ReAct, has outperformed purely retrieval-based or\nreasoning-based approaches; however, it lacks internal verification of\nintermediate reasoning steps, allowing potential errors to propagate through\ncomplex reasoning tasks. In this paper, we introduce Reasoning Court (RC), a\nnovel framework that extends iterative reasoning-and-retrieval methods, such as\nReAct, with a dedicated LLM judge. Unlike ReAct, RC employs this judge to\nindependently evaluate multiple candidate answers and their associated\nreasoning generated by separate LLM agents. The judge is asked to select the\nanswer that it considers the most factually grounded and logically coherent\nbased on the presented reasoning and evidence, or synthesizes a new answer\nusing available evidence and its pre-trained knowledge if all candidates are\ninadequate, flawed, or invalid. Evaluations on multi-hop benchmarks (HotpotQA,\nMuSiQue) and fact-verification (FEVER) demonstrate that RC consistently\noutperforms state-of-the-art few-shot prompting methods without task-specific\nfine-tuning.", "published": "2025-04-14 00:56:08", "link": "http://arxiv.org/abs/2504.09781v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Executable Functional Abstractions: Inferring Generative Programs for Advanced Math Problems", "abstract": "Scientists often infer abstract procedures from specific instances of\nproblems and use the abstractions to generate new, related instances. For\nexample, programs encoding the formal rules and properties of a system have\nbeen useful in fields ranging from RL (procedural environments) to physics\n(simulation engines). These programs can be seen as functions which execute to\ndifferent outputs based on their parameterizations (e.g., gridworld\nconfiguration or initial physical conditions). We introduce the term EFA\n(Executable Functional Abstraction) to denote such programs for math problems.\nEFA-like constructs have been shown to be useful for math reasoning as problem\ngenerators for stress-testing models. However, prior work has been limited to\nabstractions for grade-school math (whose simple rules are easy to encode in\nprograms), while generating EFAs for advanced math has thus far required human\nengineering. We explore the automatic construction of EFAs for advanced math\nproblems. We operationalize the task of automatically constructing EFAs as a\nprogram synthesis task, and develop EFAGen, which conditions an LLM on a seed\nmath problem and its step-by-step solution to generate candidate EFA programs\nthat are faithful to the generalized problem and solution class underlying the\nseed problem. Furthermore, we formalize properties any valid EFA must possess\nin terms of executable unit tests, and show how the tests can be used as\nverifiable rewards to train LLMs to become better writers of EFAs. We\ndemonstrate that EFAs constructed by EFAGen behave rationally by remaining\nfaithful to seed problems, produce learnable problem variations, and that\nEFAGen can infer EFAs across multiple diverse sources of competition-level math\nproblems. Finally, we show downstream uses of model-written EFAs e.g. finding\nproblem variations that are harder or easier for a learner to solve, as well as\ndata generation.", "published": "2025-04-14 00:06:48", "link": "http://arxiv.org/abs/2504.09763v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Weight Ensembling Improves Reasoning in Language Models", "abstract": "We investigate a failure mode that arises during the training of reasoning\nmodels, where the diversity of generations begins to collapse, leading to\nsuboptimal test-time scaling. Notably, the Pass@1 rate reliably improves during\nsupervised finetuning (SFT), but Pass@k rapidly deteriorates. Surprisingly, a\nsimple intervention of interpolating the weights of the latest SFT checkpoint\nwith an early checkpoint, otherwise known as WiSE-FT, almost completely\nrecovers Pass@k while also improving Pass@1. The WiSE-FT variant achieves\nbetter test-time scaling (Best@k, majority vote) and achieves superior results\nwith less data when tuned further by reinforcement learning. Finally, we find\nthat WiSE-FT provides complementary performance gains that cannot be achieved\nonly through diversity-inducing decoding strategies, like temperature scaling.\nWe formalize a bias-variance tradeoff of Pass@k with respect to the expectation\nand variance of Pass@1 over the test distribution. We find that WiSE-FT can\nreduce bias and variance simultaneously, while temperature scaling inherently\ntrades-off between bias and variance.", "published": "2025-04-14 17:59:07", "link": "http://arxiv.org/abs/2504.10478v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "AI-Driven Code Refactoring: Using Graph Neural Networks to Enhance Software Maintainability", "abstract": "This study explores Graph Neural Networks (GNNs) as a transformative tool for\ncode refactoring, using abstract syntax trees (ASTs) to boost software\nmaintainability. It analyzes a dataset of 2 million snippets from CodeSearchNet\nand a custom 75000-file GitHub Python corpus, comparing GNNs against rule-based\nSonarQube and decision trees. Metrics include cyclomatic complexity (target\nbelow 10), coupling (target below 5), and refactoring precision. GNNs achieve\n92% accuracy, reducing complexity by 35% and coupling by 33%, outperforming\nSonarQube (78%, 16%) and decision trees (85%, 25%). Preprocessing fixed 60% of\nsyntax errors. Bar graphs, tables, and AST visuals clarify results. This offers\na scalable AI-driven path to cleaner codebases, which is crucial for software\nengineering.", "published": "2025-04-14 16:58:54", "link": "http://arxiv.org/abs/2504.10412v1", "categories": ["cs.AI", "cs.LG", "cs.SE"], "primary_category": "cs.AI"}
{"title": "Can LLMs Assist Expert Elicitation for Probabilistic Causal Modeling?", "abstract": "Objective: This study investigates the potential of Large Language Models\n(LLMs) as an alternative to human expert elicitation for extracting structured\ncausal knowledge and facilitating causal modeling in biometric and healthcare\napplications.\n  Material and Methods: LLM-generated causal structures, specifically Bayesian\nnetworks (BNs), were benchmarked against traditional statistical methods (e.g.,\nBayesian Information Criterion) using healthcare datasets. Validation\ntechniques included structural equation modeling (SEM) to verifying\nrelationships, and measures such as entropy, predictive accuracy, and\nrobustness to compare network structures.\n  Results and Discussion: LLM-generated BNs demonstrated lower entropy than\nexpert-elicited and statistically generated BNs, suggesting higher confidence\nand precision in predictions. However, limitations such as contextual\nconstraints, hallucinated dependencies, and potential biases inherited from\ntraining data require further investigation.\n  Conclusion: LLMs represent a novel frontier in expert elicitation for\nprobabilistic causal modeling, promising to improve transparency and reduce\nuncertainty in the decision-making using such models.", "published": "2025-04-14 16:45:52", "link": "http://arxiv.org/abs/2504.10397v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Teacher Motion Priors: Enhancing Robot Locomotion over Challenging Terrain", "abstract": "Achieving robust locomotion on complex terrains remains a challenge due to\nhigh dimensional control and environmental uncertainties. This paper introduces\na teacher prior framework based on the teacher student paradigm, integrating\nimitation and auxiliary task learning to improve learning efficiency and\ngeneralization. Unlike traditional paradigms that strongly rely on\nencoder-based state embeddings, our framework decouples the network design,\nsimplifying the policy network and deployment. A high performance teacher\npolicy is first trained using privileged information to acquire generalizable\nmotion skills. The teacher's motion distribution is transferred to the student\npolicy, which relies only on noisy proprioceptive data, via a generative\nadversarial mechanism to mitigate performance degradation caused by\ndistributional shifts. Additionally, auxiliary task learning enhances the\nstudent policy's feature representation, speeding up convergence and improving\nadaptability to varying terrains. The framework is validated on a humanoid\nrobot, showing a great improvement in locomotion stability on dynamic terrains\nand significant reductions in development costs. This work provides a practical\nsolution for deploying robust locomotion strategies in humanoid robots.", "published": "2025-04-14 16:36:56", "link": "http://arxiv.org/abs/2504.10390v1", "categories": ["cs.RO", "cs.AI", "68T40"], "primary_category": "cs.RO"}
{"title": "SymRTLO: Enhancing RTL Code Optimization with LLMs and Neuron-Inspired Symbolic Reasoning", "abstract": "Optimizing Register Transfer Level (RTL) code is crucial for improving the\npower, performance, and area (PPA) of digital circuits in the early stages of\nsynthesis. Manual rewriting, guided by synthesis feedback, can yield\nhigh-quality results but is time-consuming and error-prone. Most existing\ncompiler-based approaches have difficulty handling complex design constraints.\nLarge Language Model (LLM)-based methods have emerged as a promising\nalternative to address these challenges. However, LLM-based approaches often\nface difficulties in ensuring alignment between the generated code and the\nprovided prompts. This paper presents SymRTLO, a novel neuron-symbolic RTL\noptimization framework that seamlessly integrates LLM-based code rewriting with\nsymbolic reasoning techniques. Our method incorporates a retrieval-augmented\ngeneration (RAG) system of optimization rules and Abstract Syntax Tree\n(AST)-based templates, enabling LLM-based rewriting that maintains syntactic\ncorrectness while minimizing undesired circuit behaviors. A symbolic module is\nproposed for analyzing and optimizing finite state machine (FSM) logic,\nallowing fine-grained state merging and partial specification handling beyond\nthe scope of pattern-based compilers. Furthermore, a fast verification\npipeline, combining formal equivalence checks with test-driven validation,\nfurther reduces the complexity of verification. Experiments on the RTL-Rewriter\nbenchmark with Synopsys Design Compiler and Yosys show that SymRTLO improves\npower, performance, and area (PPA) by up to 43.9%, 62.5%, and 51.1%,\nrespectively, compared to the state-of-the-art methods.", "published": "2025-04-14 16:15:55", "link": "http://arxiv.org/abs/2504.10369v1", "categories": ["cs.AR", "cs.AI", "cs.LG", "cs.PL"], "primary_category": "cs.AR"}
{"title": "FingER: Content Aware Fine-grained Evaluation with Reasoning for AI-Generated Videos", "abstract": "Recent advances in video generation have posed great challenges in the\nassessment of AI-generated content, particularly with the emergence of\nincreasingly sophisticated models. The various inconsistencies and defects\nobserved in such videos are inherently complex, making overall scoring\nnotoriously difficult. In this paper, we emphasize the critical importance of\nintegrating fine-grained reasoning into video evaluation, and we propose\n$\\textbf{F}$ing$\\textbf{ER}$, a novel entity-level reasoning evaluation\nframework that first automatically generates $\\textbf{F}$ine-grained\n$\\textbf{E}$ntity-level questions, and then answers those questions by a\n$\\textbf{R}$easoning model with scores, which can be subsequently weighted\nsummed to an overall score for different applications. Specifically, we\nleverage LLMs to derive entity-level questions across five distinct\nperspectives, which (i) often focus on some specific entities of the content,\nthereby making answering or scoring much easier by MLLMs, and (ii) are more\ninterpretable. Then we construct a FingER dataset, consisting of approximately\n3.3k videos and corresponding 60k fine-grained QA annotations, each with\ndetailed reasons. Based on that, we further investigate various training\nprotocols to best incentivize the reasoning capability of MLLMs for correct\nanswer prediction. Extensive experiments demonstrate that a reasoning model\ntrained using Group Relative Policy Optimization (GRPO) with a cold-start\nstrategy achieves the best performance. Notably, our model surpasses existing\nmethods by a relative margin of $11.8\\%$ on GenAI-Bench and $5.5\\%$ on\nMonetBench with only 3.3k training videos, which is at most one-tenth of the\ntraining samples utilized by other methods. Our code and dataset will be\nreleased soon.", "published": "2025-04-14 16:07:16", "link": "http://arxiv.org/abs/2504.10358v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Heimdall: test-time scaling on the generative verification", "abstract": "An AI system can create and maintain knowledge only to the extent that it can\nverify that knowledge itself. Recent work on long Chain-of-Thought reasoning\nhas demonstrated great potential of LLMs on solving competitive problems, but\ntheir verification ability remains to be weak and not sufficiently\ninvestigated. In this paper, we propose Heimdall, the long CoT verification LLM\nthat can accurately judge the correctness of solutions. With pure reinforcement\nlearning, we boost the verification accuracy from 62.5% to 94.5% on competitive\nmath problems. By scaling with repeated sampling, the accuracy further\nincreases to 97.5%. Through human evaluation, Heimdall demonstrates impressive\ngeneralization capabilities, successfully detecting most issues in challenging\nmath proofs, the type of which is not included during training. Furthermore, we\npropose Pessimistic Verification to extend the functionality of Heimdall to\nscaling up the problem solving. It calls Heimdall to judge the solutions from a\nsolver model and based on the pessimistic principle, selects the most likely\ncorrect solution with the least uncertainty. Taking\nDeepSeek-R1-Distill-Qwen-32B as the solver model, Pessimistic Verification\nimproves the solution accuracy on AIME2025 from 54.2% to 70.0% with 16x compute\nbudget and to 83.3% with more compute budget. With the stronger solver Gemini\n2.5 Pro, the score reaches 93.0%. Finally, we prototype an automatic knowledge\ndiscovery system, a ternary system where one poses questions, another provides\nsolutions, and the third verifies the solutions. Using the data synthesis work\nNuminaMath for the first two components, Heimdall effectively identifies\nproblematic records within the dataset and reveals that nearly half of the data\nis flawed, which interestingly aligns with the recent ablation studies from\nNuminaMath.", "published": "2025-04-14 15:46:33", "link": "http://arxiv.org/abs/2504.10337v1", "categories": ["cs.AI", "I.2.7"], "primary_category": "cs.AI"}
{"title": "AlayaDB: The Data Foundation for Efficient and Effective Long-context LLM Inference", "abstract": "AlayaDB is a cutting-edge vector database system natively architected for\nefficient and effective long-context inference for Large Language Models (LLMs)\nat AlayaDB AI. Specifically, it decouples the KV cache and attention\ncomputation from the LLM inference systems, and encapsulates them into a novel\nvector database system. For the Model as a Service providers (MaaS), AlayaDB\nconsumes fewer hardware resources and offers higher generation quality for\nvarious workloads with different kinds of Service Level Objectives (SLOs), when\ncomparing with the existing alternative solutions (e.g., KV cache\ndisaggregation, retrieval-based sparse attention). The crux of AlayaDB is that\nit abstracts the attention computation and cache management for LLM inference\ninto a query processing procedure, and optimizes the performance via a native\nquery optimizer. In this work, we demonstrate the effectiveness of AlayaDB via\n(i) three use cases from our industry partners, and (ii) extensive experimental\nresults on LLM inference benchmarks.", "published": "2025-04-14 15:34:26", "link": "http://arxiv.org/abs/2504.10326v1", "categories": ["cs.AI", "cs.DB", "cs.IR", "H.3.1; H.3.2; H.3.3; H.3.4"], "primary_category": "cs.AI"}
{"title": "AutoStyle-TTS: Retrieval-Augmented Generation based Automatic Style Matching Text-to-Speech Synthesis", "abstract": "With the advancement of speech synthesis technology, users have higher\nexpectations for the naturalness and expressiveness of synthesized speech. But\nprevious research ignores the importance of prompt selection. This study\nproposes a text-to-speech (TTS) framework based on Retrieval-Augmented\nGeneration (RAG) technology, which can dynamically adjust the speech style\naccording to the text content to achieve more natural and vivid communication\neffects. We have constructed a speech style knowledge database containing\nhigh-quality speech samples in various contexts and developed a style matching\nscheme. This scheme uses embeddings, extracted by Llama, PER-LLM-Embedder,and\nMoka, to match with samples in the knowledge database, selecting the most\nappropriate speech style for synthesis. Furthermore, our empirical research\nvalidates the effectiveness of the proposed method. Our demo can be viewed at:\nhttps://thuhcsi.github.io/icme2025-AutoStyle-TTS", "published": "2025-04-14 15:18:59", "link": "http://arxiv.org/abs/2504.10309v1", "categories": ["cs.SD", "cs.AI"], "primary_category": "cs.SD"}
{"title": "Characterizing LLM-driven Social Network: The Chirper.ai Case", "abstract": "Large language models (LLMs) demonstrate the ability to simulate human\ndecision-making processes, enabling their use as agents in modeling\nsophisticated social networks, both offline and online. Recent research has\nexplored collective behavioral patterns and structural characteristics of LLM\nagents within simulated networks. However, empirical comparisons between\nLLM-driven and human-driven online social networks remain scarce, limiting our\nunderstanding of how LLM agents differ from human users. This paper presents a\nlarge-scale analysis of Chirper.ai, an X/Twitter-like social network entirely\npopulated by LLM agents, comprising over 65,000 agents and 7.7 million\nAI-generated posts. For comparison, we collect a parallel dataset from\nMastodon, a human-driven decentralized social network, with over 117,000 users\nand 16 million posts. We examine key differences between LLM agents and humans\nin posting behaviors, abusive content, and social network structures. Our\nfindings provide critical insights into the evolving landscape of online social\nnetwork analysis in the AI era, offering a comprehensive profile of LLM agents\nin social simulations.", "published": "2025-04-14 14:53:31", "link": "http://arxiv.org/abs/2504.10286v1", "categories": ["cs.SI", "cs.AI"], "primary_category": "cs.SI"}
{"title": "Zero-shot Autonomous Microscopy for Scalable and Intelligent Characterization of 2D Materials", "abstract": "Characterization of atomic-scale materials traditionally requires human\nexperts with months to years of specialized training. Even for trained human\noperators, accurate and reliable characterization remains challenging when\nexamining newly discovered materials such as two-dimensional (2D) structures.\nThis bottleneck drives demand for fully autonomous experimentation systems\ncapable of comprehending research objectives without requiring large training\ndatasets. In this work, we present ATOMIC (Autonomous Technology for Optical\nMicroscopy & Intelligent Characterization), an end-to-end framework that\nintegrates foundation models to enable fully autonomous, zero-shot\ncharacterization of 2D materials. Our system integrates the vision foundation\nmodel (i.e., Segment Anything Model), large language models (i.e., ChatGPT),\nunsupervised clustering, and topological analysis to automate microscope\ncontrol, sample scanning, image segmentation, and intelligent analysis through\nprompt engineering, eliminating the need for additional training. When\nanalyzing typical MoS2 samples, our approach achieves 99.7% segmentation\naccuracy for single layer identification, which is equivalent to that of human\nexperts. In addition, the integrated model is able to detect grain boundary\nslits that are challenging to identify with human eyes. Furthermore, the system\nretains robust accuracy despite variable conditions including defocus, color\ntemperature fluctuations, and exposure variations. It is applicable to a broad\nspectrum of common 2D materials-including graphene, MoS2, WSe2, SnSe-regardless\nof whether they were fabricated via chemical vapor deposition or mechanical\nexfoliation. This work represents the implementation of foundation models to\nachieve autonomous analysis, establishing a scalable and data-efficient\ncharacterization paradigm that fundamentally transforms the approach to\nnanoscale materials research.", "published": "2025-04-14 14:49:45", "link": "http://arxiv.org/abs/2504.10281v1", "categories": ["cond-mat.mtrl-sci", "cond-mat.mes-hall", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "Vision based driving agent for race car simulation environments", "abstract": "In recent years, autonomous driving has become a popular field of study. As\ncontrol at tire grip limit is essential during emergency situations, algorithms\ndeveloped for racecars are useful for road cars too. This paper examines the\nuse of Deep Reinforcement Learning (DRL) to solve the problem of grip limit\ndriving in a simulated environment. Proximal Policy Optimization (PPO) method\nis used to train an agent to control the steering wheel and pedals of the\nvehicle, using only visual inputs to achieve professional human lap times. The\npaper outlines the formulation of the task of time optimal driving on a race\ntrack as a deep reinforcement learning problem, and explains the chosen\nobservations, actions, and reward functions. The results demonstrate human-like\nlearning and driving behavior that utilize maximum tire grip potential.", "published": "2025-04-14 14:29:37", "link": "http://arxiv.org/abs/2504.10266v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "MASSeg : 2nd Technical Report for 4th PVUW MOSE Track", "abstract": "Complex video object segmentation continues to face significant challenges in\nsmall object recognition, occlusion handling, and dynamic scene modeling. This\nreport presents our solution, which ranked second in the MOSE track of CVPR\n2025 PVUW Challenge. Based on an existing segmentation framework, we propose an\nimproved model named MASSeg for complex video object segmentation, and\nconstruct an enhanced dataset, MOSE+, which includes typical scenarios with\nocclusions, cluttered backgrounds, and small target instances. During training,\nwe incorporate a combination of inter-frame consistent and inconsistent data\naugmentation strategies to improve robustness and generalization. During\ninference, we design a mask output scaling strategy to better adapt to varying\nobject sizes and occlusion levels. As a result, MASSeg achieves a J score of\n0.8250, F score of 0.9007, and a J&F score of 0.8628 on the MOSE test set.", "published": "2025-04-14 14:15:46", "link": "http://arxiv.org/abs/2504.10254v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Can Competition Enhance the Proficiency of Agents Powered by Large Language Models in the Realm of News-driven Time Series Forecasting?", "abstract": "Multi-agents-based news-driven time series forecasting is considered as a\npotential paradigm shift in the era of large language models (LLMs). The\nchallenge of this task lies in measuring the influences of different news\nevents towards the fluctuations of time series. This requires agents to possess\nstronger abilities of innovative thinking and the identifying misleading logic.\nHowever, the existing multi-agent discussion framework has limited enhancement\non time series prediction in terms of optimizing these two capabilities.\nInspired by the role of competition in fostering innovation, this study embeds\na competition mechanism within the multi-agent discussion to enhance agents'\ncapability of generating innovative thoughts. Furthermore, to bolster the\nmodel's proficiency in identifying misleading information, we incorporate a\nfine-tuned small-scale LLM model within the reflective stage, offering\nauxiliary decision-making support. Experimental results confirm that the\ncompetition can boost agents' capacity for innovative thinking, which can\nsignificantly improve the performances of time series prediction. Similar to\nthe findings of social science, the intensity of competition within this\nframework can influence the performances of agents, providing a new perspective\nfor studying LLMs-based multi-agent systems.", "published": "2025-04-14 13:25:50", "link": "http://arxiv.org/abs/2504.10210v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Efficient Generative Model Training via Embedded Representation Warmup", "abstract": "Diffusion models excel at generating high-dimensional data but fall short in\ntraining efficiency and representation quality compared to self-supervised\nmethods. We identify a key bottleneck: the underutilization of high-quality,\nsemantically rich representations during training notably slows down\nconvergence. Our systematic analysis reveals a critical representation\nprocessing region -- primarily in the early layers -- where semantic and\nstructural pattern learning takes place before generation can occur. To address\nthis, we propose Embedded Representation Warmup (ERW), a plug-and-play\nframework where in the first stage we get the ERW module serves as a warmup\nthat initializes the early layers of the diffusion model with high-quality,\npretrained representations. This warmup minimizes the burden of learning\nrepresentations from scratch, thereby accelerating convergence and boosting\nperformance. Our theoretical analysis demonstrates that ERW's efficacy depends\non its precise integration into specific neural network layers -- termed the\nrepresentation processing region -- where the model primarily processes and\ntransforms feature representations for later generation. We further establish\nthat ERW not only accelerates training convergence but also enhances\nrepresentation quality: empirically, our method achieves a 40$\\times$\nacceleration in training speed compared to REPA, the current state-of-the-art\nmethods. Code is available at https://github.com/LINs-lab/ERW.", "published": "2025-04-14 12:43:17", "link": "http://arxiv.org/abs/2504.10188v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "WildLive: Near Real-time Visual Wildlife Tracking onboard UAVs", "abstract": "Live tracking of wildlife via high-resolution video processing directly\nonboard drones is widely unexplored and most existing solutions rely on\nstreaming video to ground stations to support navigation. Yet, both autonomous\nanimal-reactive flight control beyond visual line of sight and/or\nmission-specific individual and behaviour recognition tasks rely to some degree\non this capability. In response, we introduce WildLive -- a near real-time\nanimal detection and tracking framework for high-resolution imagery running\ndirectly onboard uncrewed aerial vehicles (UAVs). The system performs\nmulti-animal detection and tracking at 17fps+ for HD and 7fps+ on 4K video\nstreams suitable for operation during higher altitude flights to minimise\nanimal disturbance. Our system is optimised for Jetson Orin AGX onboard\nhardware. It integrates the efficiency of sparse optical flow tracking and\nmission-specific sampling with device-optimised and proven YOLO-driven object\ndetection and segmentation techniques. Essentially, computational resource is\nfocused onto spatio-temporal regions of high uncertainty to significantly\nimprove UAV processing speeds without domain-specific loss of accuracy.\nAlongside, we introduce our WildLive dataset, which comprises 200k+ annotated\nanimal instances across 19k+ frames from 4K UAV videos collected at the Ol\nPejeta Conservancy in Kenya. All frames contain ground truth bounding boxes,\nsegmentation masks, as well as individual tracklets and tracking point\ntrajectories. We compare our system against current object tracking approaches\nincluding OC-SORT, ByteTrack, and SORT. Our multi-animal tracking experiments\nwith onboard hardware confirm that near real-time high-resolution wildlife\ntracking is possible on UAVs whilst maintaining high accuracy levels as needed\nfor future navigational and mission-specific animal-centric operational\nautonomy.", "published": "2025-04-14 12:21:16", "link": "http://arxiv.org/abs/2504.10165v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "COUNTS: Benchmarking Object Detectors and Multimodal Large Language Models under Distribution Shifts", "abstract": "Current object detectors often suffer significant perfor-mance degradation in\nreal-world applications when encountering distributional shifts. Consequently,\nthe out-of-distribution (OOD) generalization capability of object detectors has\ngarnered increasing attention from researchers. Despite this growing interest,\nthere remains a lack of a large-scale, comprehensive dataset and evaluation\nbenchmark with fine-grained annotations tailored to assess the OOD\ngeneralization on more intricate tasks like object detection and grounding. To\naddress this gap, we introduce COUNTS, a large-scale OOD dataset with\nobject-level annotations. COUNTS encompasses 14 natural distributional shifts,\nover 222K samples, and more than 1,196K labeled bounding boxes. Leveraging\nCOUNTS, we introduce two novel benchmarks: O(OD)2 and OODG. O(OD)2 is designed\nto comprehensively evaluate the OOD generalization capabilities of object\ndetectors by utilizing controlled distribution shifts between training and\ntesting data. OODG, on the other hand, aims to assess the OOD generalization of\ngrounding abilities in multimodal large language models (MLLMs). Our findings\nreveal that, while large models and extensive pre-training data substantially\nen hance performance in in-distribution (IID) scenarios, significant\nlimitations and opportunities for improvement persist in OOD contexts for both\nobject detectors and MLLMs. In visual grounding tasks, even the advanced GPT-4o\nand Gemini-1.5 only achieve 56.7% and 28.0% accuracy, respectively. We hope\nCOUNTS facilitates advancements in the development and assessment of robust\nobject detectors and MLLMs capable of maintaining high performance under\ndistributional shifts.", "published": "2025-04-14 12:13:33", "link": "http://arxiv.org/abs/2504.10158v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "BoTTA: Benchmarking on-device Test Time Adaptation", "abstract": "The performance of deep learning models depends heavily on test samples at\nruntime, and shifts from the training data distribution can significantly\nreduce accuracy. Test-time adaptation (TTA) addresses this by adapting models\nduring inference without requiring labeled test data or access to the original\ntraining set. While research has explored TTA from various perspectives like\nalgorithmic complexity, data and class distribution shifts, model\narchitectures, and offline versus continuous learning, constraints specific to\nmobile and edge devices remain underexplored. We propose BoTTA, a benchmark\ndesigned to evaluate TTA methods under practical constraints on mobile and edge\ndevices. Our evaluation targets four key challenges caused by limited resources\nand usage conditions: (i) limited test samples, (ii) limited exposure to\ncategories, (iii) diverse distribution shifts, and (iv) overlapping shifts\nwithin a sample. We assess state-of-the-art TTA methods under these scenarios\nusing benchmark datasets and report system-level metrics on a real testbed.\nFurthermore, unlike prior work, we align with on-device requirements by\nadvocating periodic adaptation instead of continuous inference-time adaptation.\nExperiments reveal key insights: many recent TTA algorithms struggle with small\ndatasets, fail to generalize to unseen categories, and depend on the diversity\nand complexity of distribution shifts. BoTTA also reports device-specific\nresource use. For example, while SHOT improves accuracy by $2.25\\times$ with\n$512$ adaptation samples, it uses $1.08\\times$ peak memory on Raspberry Pi\nversus the base model. BoTTA offers actionable guidance for TTA in real-world,\nresource-constrained deployments.", "published": "2025-04-14 12:00:00", "link": "http://arxiv.org/abs/2504.10149v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "GeoUni: A Unified Model for Generating Geometry Diagrams, Problems and Problem Solutions", "abstract": "We propose GeoUni, the first unified geometry expert model capable of\ngenerating problem solutions and diagrams within a single framework in a way\nthat enables the creation of unique and individualized geometry problems.\nTraditionally, solving geometry problems and generating diagrams have been\ntreated as separate tasks in machine learning, with no models successfully\nintegrating both to support problem creation. However, we believe that mastery\nin geometry requires frictionless integration of all of these skills, from\nsolving problems to visualizing geometric relationships, and finally, crafting\ntailored problems. Our extensive experiments demonstrate that GeoUni, with only\n1.5B parameters, achieves performance comparable to larger models such as\nDeepSeek-R1 with 671B parameters in geometric reasoning tasks. GeoUni also\nexcels in generating precise geometric diagrams, surpassing both text-to-image\nmodels and unified models, including the GPT-4o image generation. Most\nimportantly, GeoUni is the only model capable of successfully generating\ntextual problems with matching diagrams based on specific knowledge points,\nthus offering a wider range of capabilities that extend beyond current models.", "published": "2025-04-14 11:56:55", "link": "http://arxiv.org/abs/2504.10146v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Benchmarking Practices in LLM-driven Offensive Security: Testbeds, Metrics, and Experiment Design", "abstract": "Large Language Models (LLMs) have emerged as a powerful approach for driving\noffensive penetration-testing tooling. This paper analyzes the methodology and\nbenchmarking practices used for evaluating Large Language Model (LLM)-driven\nattacks, focusing on offensive uses of LLMs in cybersecurity. We review 16\nresearch papers detailing 15 prototypes and their respective testbeds.\n  We detail our findings and provide actionable recommendations for future\nresearch, emphasizing the importance of extending existing testbeds, creating\nbaselines, and including comprehensive metrics and qualitative analysis. We\nalso note the distinction between security research and practice, suggesting\nthat CTF-based challenges may not fully represent real-world penetration\ntesting scenarios.", "published": "2025-04-14 11:21:33", "link": "http://arxiv.org/abs/2504.10112v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Lightweight Trustworthy Distributed Clustering", "abstract": "Ensuring data trustworthiness within individual edge nodes while facilitating\ncollaborative data processing poses a critical challenge in edge computing\nsystems (ECS), particularly in resource-constrained scenarios such as\nautonomous systems sensor networks, industrial IoT, and smart cities. This\npaper presents a lightweight, fully distributed k-means clustering algorithm\nspecifically adapted for edge environments, leveraging a distributed averaging\napproach with additive secret sharing, a secure multiparty computation\ntechnique, during the cluster center update phase to ensure the accuracy and\ntrustworthiness of data across nodes.", "published": "2025-04-14 11:16:07", "link": "http://arxiv.org/abs/2504.10109v1", "categories": ["cs.DC", "cs.AI"], "primary_category": "cs.DC"}
{"title": "SoccerNet-v3D: Leveraging Sports Broadcast Replays for 3D Scene Understanding", "abstract": "Sports video analysis is a key domain in computer vision, enabling detailed\nspatial understanding through multi-view correspondences. In this work, we\nintroduce SoccerNet-v3D and ISSIA-3D, two enhanced and scalable datasets\ndesigned for 3D scene understanding in soccer broadcast analysis. These\ndatasets extend SoccerNet-v3 and ISSIA by incorporating field-line-based camera\ncalibration and multi-view synchronization, enabling 3D object localization\nthrough triangulation. We propose a monocular 3D ball localization task built\nupon the triangulation of ground-truth 2D ball annotations, along with several\ncalibration and reprojection metrics to assess annotation quality on demand.\nAdditionally, we present a single-image 3D ball localization method as a\nbaseline, leveraging camera calibration and ball size priors to estimate the\nball's position from a monocular viewpoint. To further refine 2D annotations,\nwe introduce a bounding box optimization technique that ensures alignment with\nthe 3D scene representation. Our proposed datasets establish new benchmarks for\n3D soccer scene understanding, enhancing both spatial and temporal analysis in\nsports analytics. Finally, we provide code to facilitate access to our\nannotations and the generation pipelines for the datasets.", "published": "2025-04-14 11:15:13", "link": "http://arxiv.org/abs/2504.10106v1", "categories": ["cs.CV", "cs.AI", "I.2; I.4; I.5"], "primary_category": "cs.CV"}
{"title": "MMKB-RAG: A Multi-Modal Knowledge-Based Retrieval-Augmented Generation Framework", "abstract": "Recent advancements in large language models (LLMs) and multi-modal LLMs have\nbeen remarkable. However, these models still rely solely on their parametric\nknowledge, which limits their ability to generate up-to-date information and\nincreases the risk of producing erroneous content. Retrieval-Augmented\nGeneration (RAG) partially mitigates these challenges by incorporating external\ndata sources, yet the reliance on databases and retrieval systems can introduce\nirrelevant or inaccurate documents, ultimately undermining both performance and\nreasoning quality. In this paper, we propose Multi-Modal Knowledge-Based\nRetrieval-Augmented Generation (MMKB-RAG), a novel multi-modal RAG framework\nthat leverages the inherent knowledge boundaries of models to dynamically\ngenerate semantic tags for the retrieval process. This strategy enables the\njoint filtering of retrieved documents, retaining only the most relevant and\naccurate references. Extensive experiments on knowledge-based visual\nquestion-answering tasks demonstrate the efficacy of our approach: on the E-VQA\ndataset, our method improves performance by +4.2\\% on the Single-Hop subset and\n+0.4\\% on the full dataset, while on the InfoSeek dataset, it achieves gains of\n+7.8\\% on the Unseen-Q subset, +8.2\\% on the Unseen-E subset, and +8.1\\% on the\nfull dataset. These results highlight significant enhancements in both accuracy\nand robustness over the current state-of-the-art MLLM and RAG frameworks.", "published": "2025-04-14 10:19:47", "link": "http://arxiv.org/abs/2504.10074v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Pay Attention to What and Where? Interpretable Feature Extractor in Vision-based Deep Reinforcement Learning", "abstract": "Current approaches in Explainable Deep Reinforcement Learning have\nlimitations in which the attention mask has a displacement with the objects in\nvisual input. This work addresses a spatial problem within traditional\nConvolutional Neural Networks (CNNs). We propose the Interpretable Feature\nExtractor (IFE) architecture, aimed at generating an accurate attention mask to\nillustrate both \"what\" and \"where\" the agent concentrates on in the spatial\ndomain. Our design incorporates a Human-Understandable Encoding module to\ngenerate a fully interpretable attention mask, followed by an Agent-Friendly\nEncoding module to enhance the agent's learning efficiency. These two\ncomponents together form the Interpretable Feature Extractor for vision-based\ndeep reinforcement learning to enable the model's interpretability. The\nresulting attention mask is consistent, highly understandable by humans,\naccurate in spatial dimension, and effectively highlights important objects or\nlocations in visual input. The Interpretable Feature Extractor is integrated\ninto the Fast and Data-efficient Rainbow framework, and evaluated on 57 ATARI\ngames to show the effectiveness of the proposed approach on Spatial\nPreservation, Interpretability, and Data-efficiency. Finally, we showcase the\nversatility of our approach by incorporating the IFE into the Asynchronous\nAdvantage Actor-Critic Model.", "published": "2025-04-14 10:18:34", "link": "http://arxiv.org/abs/2504.10071v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "CHARM: Calibrating Reward Models With Chatbot Arena Scores", "abstract": "Reward models (RMs) play a crucial role in Reinforcement Learning from Human\nFeedback by serving as proxies for human preferences in aligning large language\nmodels. In this paper, we identify a model preference bias in RMs, where they\nsystematically assign disproportionately high scores to responses from certain\npolicy models. This bias distorts ranking evaluations and leads to unfair\njudgments. To address this issue, we propose a calibration method named CHatbot\nArena calibrated Reward Modeling (CHARM) that leverages Elo scores from the\nChatbot Arena leaderboard to mitigate RM overvaluation. We also introduce a\nMismatch Degree metric to measure this preference bias. Our approach is\ncomputationally efficient, requiring only a small preference dataset for\ncontinued training of the RM. We conduct extensive experiments on reward model\nbenchmarks and human preference alignment. Results demonstrate that our\ncalibrated RMs (1) achieve improved evaluation accuracy on RM-Bench and the\nChat-Hard domain of RewardBench, and (2) exhibit a stronger correlation with\nhuman preferences by producing scores more closely aligned with Elo rankings.\nBy mitigating model preference bias, our method provides a generalizable and\nefficient solution for building fairer and more reliable reward models.", "published": "2025-04-14 09:51:09", "link": "http://arxiv.org/abs/2504.10045v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "EmbodiedAgent: A Scalable Hierarchical Approach to Overcome Practical Challenge in Multi-Robot Control", "abstract": "This paper introduces EmbodiedAgent, a hierarchical framework for\nheterogeneous multi-robot control. EmbodiedAgent addresses critical limitations\nof hallucination in impractical tasks. Our approach integrates a next-action\nprediction paradigm with a structured memory system to decompose tasks into\nexecutable robot skills while dynamically validating actions against\nenvironmental constraints. We present MultiPlan+, a dataset of more than 18,000\nannotated planning instances spanning 100 scenarios, including a subset of\nimpractical cases to mitigate hallucination. To evaluate performance, we\npropose the Robot Planning Assessment Schema (RPAS), combining automated\nmetrics with LLM-aided expert grading. Experiments demonstrate EmbodiedAgent's\nsuperiority over state-of-the-art models, achieving 71.85% RPAS score.\nReal-world validation in an office service task highlights its ability to\ncoordinate heterogeneous robots for long-horizon objectives.", "published": "2025-04-14 09:33:42", "link": "http://arxiv.org/abs/2504.10030v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Sequence models for by-trial decoding of cognitive strategies from neural data", "abstract": "Understanding the sequence of cognitive operations that underlie\ndecision-making is a fundamental challenge in cognitive neuroscience.\nTraditional approaches often rely on group-level statistics, which obscure\ntrial-by-trial variations in cognitive strategies. In this study, we introduce\na novel machine learning method that combines Hidden Multivariate Pattern\nanalysis with a Structured State Space Sequence model to decode cognitive\nstrategies from electroencephalography data at the trial level. We apply this\nmethod to a decision-making task, where participants were instructed to\nprioritize either speed or accuracy in their responses. Our results reveal an\nadditional cognitive operation, labeled Confirmation, which seems to occur\npredominantly in the accuracy condition but also frequently in the speed\ncondition. The modeled probability that this operation occurs is associated\nwith higher probability of responding correctly as well as changes of mind, as\nindexed by electromyography data. By successfully modeling cognitive operations\nat the trial level, we provide empirical evidence for dynamic variability in\ndecision strategies, challenging the assumption of homogeneous cognitive\nprocesses within experimental conditions. Our approach shows the potential of\nsequence modeling in cognitive neuroscience to capture trial-level variability\nthat is obscured by aggregate analyses. The introduced method offers a new way\nto detect and understand cognitive strategies in a data-driven manner, with\nimplications for both theoretical research and practical applications in many\nfields.", "published": "2025-04-14 09:33:02", "link": "http://arxiv.org/abs/2504.10028v1", "categories": ["q-bio.NC", "cs.AI"], "primary_category": "q-bio.NC"}
{"title": "Progressive Transfer Learning for Multi-Pass Fundus Image Restoration", "abstract": "Diabetic retinopathy is a leading cause of vision impairment, making its\nearly diagnosis through fundus imaging critical for effective treatment\nplanning. However, the presence of poor quality fundus images caused by factors\nsuch as inadequate illumination, noise, blurring and other motion artifacts\nyields a significant challenge for accurate DR screening. In this study, we\npropose progressive transfer learning for multi pass restoration to iteratively\nenhance the quality of degraded fundus images, ensuring more reliable DR\nscreening. Unlike previous methods that often focus on a single pass\nrestoration, multi pass restoration via PTL can achieve a superior blind\nrestoration performance that can even improve most of the good quality fundus\nimages in the dataset. Initially, a Cycle GAN model is trained to restore low\nquality images, followed by PTL induced restoration passes over the latest\nrestored outputs to improve overall quality in each pass. The proposed method\ncan learn blind restoration without requiring any paired data while surpassing\nits limitations by leveraging progressive learning and fine tuning strategies\nto minimize distortions and preserve critical retinal features. To evaluate\nPTL's effectiveness on multi pass restoration, we conducted experiments on\nDeepDRiD, a large scale fundus imaging dataset specifically curated for\ndiabetic retinopathy detection. Our result demonstrates state of the art\nperformance, showcasing PTL's potential as a superior approach to iterative\nimage quality restoration.", "published": "2025-04-14 09:28:10", "link": "http://arxiv.org/abs/2504.10025v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "RGB-Event based Pedestrian Attribute Recognition: A Benchmark Dataset and An Asymmetric RWKV Fusion Framework", "abstract": "Existing pedestrian attribute recognition methods are generally developed\nbased on RGB frame cameras. However, these approaches are constrained by the\nlimitations of RGB cameras, such as sensitivity to lighting conditions and\nmotion blur, which hinder their performance. Furthermore, current attribute\nrecognition primarily focuses on analyzing pedestrians' external appearance and\nclothing, lacking an exploration of emotional dimensions. In this paper, we\nrevisit these issues and propose a novel multi-modal RGB-Event attribute\nrecognition task by drawing inspiration from the advantages of event cameras in\nlow-light, high-speed, and low-power consumption. Specifically, we introduce\nthe first large-scale multi-modal pedestrian attribute recognition dataset,\ntermed EventPAR, comprising 100K paired RGB-Event samples that cover 50\nattributes related to both appearance and six human emotions, diverse scenes,\nand various seasons. By retraining and evaluating mainstream PAR models on this\ndataset, we establish a comprehensive benchmark and provide a solid foundation\nfor future research in terms of data and algorithmic baselines. In addition, we\npropose a novel RWKV-based multi-modal pedestrian attribute recognition\nframework, featuring an RWKV visual encoder and an asymmetric RWKV fusion\nmodule. Extensive experiments are conducted on our proposed dataset as well as\ntwo simulated datasets (MARS-Attribute and DukeMTMC-VID-Attribute), achieving\nstate-of-the-art results. The source code and dataset will be released on\nhttps://github.com/Event-AHU/OpenPAR", "published": "2025-04-14 09:22:16", "link": "http://arxiv.org/abs/2504.10018v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Air Quality Prediction with A Meteorology-Guided Modality-Decoupled Spatio-Temporal Network", "abstract": "Air quality prediction plays a crucial role in public health and\nenvironmental protection. Accurate air quality prediction is a complex\nmultivariate spatiotemporal problem, that involves interactions across temporal\npatterns, pollutant correlations, spatial station dependencies, and\nparticularly meteorological influences that govern pollutant dispersion and\nchemical transformations. Existing works underestimate the critical role of\natmospheric conditions in air quality prediction and neglect comprehensive\nmeteorological data utilization, thereby impairing the modeling of dynamic\ninterdependencies between air quality and meteorological data. To overcome\nthis, we propose MDSTNet, an encoder-decoder framework that explicitly models\nair quality observations and atmospheric conditions as distinct modalities,\nintegrating multi-pressure-level meteorological data and weather forecasts to\ncapture atmosphere-pollution dependencies for prediction. Meantime, we\nconstruct ChinaAirNet, the first nationwide dataset combining air quality\nrecords with multi-pressure-level meteorological observations. Experimental\nresults on ChinaAirNet demonstrate MDSTNet's superiority, substantially\nreducing 48-hour prediction errors by 17.54\\% compared to the state-of-the-art\nmodel. The source code and dataset will be available on github.", "published": "2025-04-14 09:18:11", "link": "http://arxiv.org/abs/2504.10014v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Session-based Recommender Systems: User Interest as a Stochastic Process in the Latent Space", "abstract": "This paper jointly addresses the problem of data uncertainty, popularity\nbias, and exposure bias in session-based recommender systems. We study the\nsymptoms of this bias both in item embeddings and in recommendations. We\npropose treating user interest as a stochastic process in the latent space and\nproviding a model-agnostic implementation of this mathematical concept. The\nproposed stochastic component consists of elements: debiasing item embeddings\nwith regularization for embedding uniformity, modeling dense user interest from\nsession prefixes, and introducing fake targets in the data to simulate extended\nexposure. We conducted computational experiments on two popular benchmark\ndatasets, Diginetica and YooChoose 1/64, as well as several modifications of\nthe YooChoose dataset with different ratios of popular items. The results show\nthat the proposed approach allows us to mitigate the challenges mentioned.", "published": "2025-04-14 09:08:40", "link": "http://arxiv.org/abs/2504.10005v1", "categories": ["cs.LG", "cs.AI", "cs.IR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Metric-Guided Synthesis of Class Activation Mapping", "abstract": "Class activation mapping (CAM) is a widely adopted class of saliency methods\nused to explain the behavior of convolutional neural networks (CNNs). These\nmethods generate heatmaps that highlight the parts of the input most relevant\nto the CNN output. Various CAM methods have been proposed, each distinguished\nby the expressions used to derive heatmaps. In general, users look for heatmaps\nwith specific properties that reflect different aspects of CNN functionality.\nThese may include similarity to ground truth, robustness, equivariance, and\nmore. Although existing CAM methods implicitly encode some of these properties\nin their expressions, they do not allow for variability in heatmap generation\nfollowing the user's intent or domain knowledge. In this paper, we address this\nlimitation by introducing SyCAM, a metric-based approach for synthesizing CAM\nexpressions. Given a predefined evaluation metric for saliency maps, SyCAM\nautomatically generates CAM expressions optimized for that metric. We\nspecifically explore a syntax-guided synthesis instantiation of SyCAM, where\nCAM expressions are derived based on predefined syntactic constraints and the\ngiven metric. Using several established evaluation metrics, we demonstrate the\nefficacy and flexibility of our approach in generating targeted heatmaps. We\ncompare SyCAM with other well-known CAM methods on three prominent models:\nResNet50, VGG16, and VGG19.", "published": "2025-04-14 09:01:49", "link": "http://arxiv.org/abs/2504.09998v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "GenTe: Generative Real-world Terrains for General Legged Robot Locomotion Control", "abstract": "Developing bipedal robots capable of traversing diverse real-world terrains\npresents a fundamental robotics challenge, as existing methods using predefined\nheight maps and static environments fail to address the complexity of\nunstructured landscapes. To bridge this gap, we propose GenTe, a framework for\ngenerating physically realistic and adaptable terrains to train generalizable\nlocomotion policies. GenTe constructs an atomic terrain library that includes\nboth geometric and physical terrains, enabling curriculum training for\nreinforcement learning-based locomotion policies. By leveraging\nfunction-calling techniques and reasoning capabilities of Vision-Language\nModels (VLMs), GenTe generates complex, contextually relevant terrains from\ntextual and graphical inputs. The framework introduces realistic force modeling\nfor terrain interactions, capturing effects such as soil sinkage and\nhydrodynamic resistance. To the best of our knowledge, GenTe is the first\nframework that systemically generates simulation environments for legged robot\nlocomotion control. Additionally, we introduce a benchmark of 100 generated\nterrains. Experiments demonstrate improved generalization and robustness in\nbipedal robot locomotion.", "published": "2025-04-14 09:01:44", "link": "http://arxiv.org/abs/2504.09997v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Enhancing Multi-task Learning Capability of Medical Generalist Foundation Model via Image-centric Multi-annotation Data", "abstract": "The emergence of medical generalist foundation models has revolutionized\nconventional task-specific model development paradigms, aiming to better handle\nmultiple tasks through joint training on large-scale medical datasets. However,\nrecent advances prioritize simple data scaling or architectural component\nenhancement, while neglecting to re-examine multi-task learning from a\ndata-centric perspective. Critically, simply aggregating existing data\nresources leads to decentralized image-task alignment, which fails to cultivate\ncomprehensive image understanding or align with clinical needs for\nmulti-dimensional image interpretation. In this paper, we introduce the\nimage-centric multi-annotation X-ray dataset (IMAX), the first attempt to\nenhance the multi-task learning capabilities of medical multi-modal large\nlanguage models (MLLMs) from the data construction level. To be specific, IMAX\nis featured from the following attributes: 1) High-quality data curation. A\ncomprehensive collection of more than 354K entries applicable to seven\ndifferent medical tasks. 2) Image-centric dense annotation. Each X-ray image is\nassociated with an average of 4.10 tasks and 7.46 training entries, ensuring\nmulti-task representation richness per image. Compared to the general\ndecentralized multi-annotation X-ray dataset (DMAX), IMAX consistently\ndemonstrates significant multi-task average performance gains ranging from\n3.20% to 21.05% across seven open-source state-of-the-art medical MLLMs.\nMoreover, we investigate differences in statistical patterns exhibited by IMAX\nand DMAX training processes, exploring potential correlations between\noptimization dynamics and multi-task performance. Finally, leveraging the core\nconcept of IMAX data construction, we propose an optimized DMAX-based training\nstrategy to alleviate the dilemma of obtaining high-quality IMAX data in\npractical scenarios.", "published": "2025-04-14 08:09:37", "link": "http://arxiv.org/abs/2504.09967v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Towards Unbiased Federated Graph Learning: Label and Topology Perspectives", "abstract": "Federated Graph Learning (FGL) enables privacy-preserving, distributed\ntraining of graph neural networks without sharing raw data. Among its\napproaches, subgraph-FL has become the dominant paradigm, with most work\nfocused on improving overall node classification accuracy. However, these\nmethods often overlook fairness due to the complexity of node features, labels,\nand graph structures. In particular, they perform poorly on nodes with\ndisadvantaged properties, such as being in the minority class within subgraphs\nor having heterophilous connections (neighbors with dissimilar labels or\nmisleading features). This reveals a critical issue: high accuracy can mask\ndegraded performance on structurally or semantically marginalized nodes. To\naddress this, we advocate for two fairness goals: (1) improving representation\nof minority class nodes for class-wise fairness and (2) mitigating topological\nbias from heterophilous connections for topology-aware fairness. We propose\nFairFGL, a novel framework that enhances fairness through fine-grained graph\nmining and collaborative learning. On the client side, the History-Preserving\nModule prevents overfitting to dominant local classes, while the Majority\nAlignment Module refines representations of heterophilous majority-class nodes.\nThe Gradient Modification Module transfers minority-class knowledge from\nstructurally favorable clients to improve fairness. On the server side, FairFGL\nuploads only the most influenced subset of parameters to reduce communication\ncosts and better reflect local distributions. A cluster-based aggregation\nstrategy reconciles conflicting updates and curbs global majority dominance .\nExtensive evaluations on eight benchmarks show FairFGL significantly improves\nminority-group performance , achieving up to a 22.62 percent Macro-F1 gain\nwhile enhancing convergence over state-of-the-art baselines.", "published": "2025-04-14 08:00:20", "link": "http://arxiv.org/abs/2504.09963v1", "categories": ["cs.LG", "cs.AI", "cs.DB", "cs.SI"], "primary_category": "cs.LG"}
{"title": "Privacy Meets Explainability: Managing Confidential Data and Transparency Policies in LLM-Empowered Science", "abstract": "As Large Language Models (LLMs) become integral to scientific workflows,\nconcerns over the confidentiality and ethical handling of confidential data\nhave emerged. This paper explores data exposure risks through LLM-powered\nscientific tools, which can inadvertently leak confidential information,\nincluding intellectual property and proprietary data, from scientists'\nperspectives. We propose \"DataShield\", a framework designed to detect\nconfidential data leaks, summarize privacy policies, and visualize data flow,\nensuring alignment with organizational policies and procedures. Our approach\naims to inform scientists about data handling practices, enabling them to make\ninformed decisions and protect sensitive information. Ongoing user studies with\nscientists are underway to evaluate the framework's usability, trustworthiness,\nand effectiveness in tackling real-world privacy challenges.", "published": "2025-04-14 07:58:26", "link": "http://arxiv.org/abs/2504.09961v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Omni-Dish: Photorealistic and Faithful Image Generation and Editing for Arbitrary Chinese Dishes", "abstract": "Dish images play a crucial role in the digital era, with the demand for\nculturally distinctive dish images continuously increasing due to the\ndigitization of the food industry and e-commerce. In general cases, existing\ntext-to-image generation models excel in producing high-quality images;\nhowever, they struggle to capture diverse characteristics and faithful details\nof specific domains, particularly Chinese dishes. To address this limitation,\nwe propose Omni-Dish, the first text-to-image generation model specifically\ntailored for Chinese dishes. We develop a comprehensive dish curation pipeline,\nbuilding the largest dish dataset to date. Additionally, we introduce a\nrecaption strategy and employ a coarse-to-fine training scheme to help the\nmodel better learn fine-grained culinary nuances. During inference, we enhance\nthe user's textual input using a pre-constructed high-quality caption library\nand a large language model, enabling more photorealistic and faithful image\ngeneration. Furthermore, to extend our model's capability for dish editing\ntasks, we propose Concept-Enhanced P2P. Based on this approach, we build a dish\nediting dataset and train a specialized editing model. Extensive experiments\ndemonstrate the superiority of our methods.", "published": "2025-04-14 07:18:32", "link": "http://arxiv.org/abs/2504.09948v1", "categories": ["cs.CV", "cs.AI", "cs.MM"], "primary_category": "cs.CV"}
{"title": "FedRecon: Missing Modality Reconstruction in Distributed Heterogeneous Environments", "abstract": "Multimodal data are often incomplete and exhibit Non-Independent and\nIdentically Distributed (Non-IID) characteristics in real-world scenarios.\nThese inherent limitations lead to both modality heterogeneity through partial\nmodality absence and data heterogeneity from distribution divergence, creating\nfundamental challenges for effective federated learning (FL). To address these\ncoupled challenges, we propose FedRecon, the first method targeting\nsimultaneous missing modality reconstruction and Non-IID adaptation in\nmultimodal FL. Our approach first employs a lightweight Multimodal Variational\nAutoencoder (MVAE) to reconstruct missing modalities while preserving\ncross-modal consistency. Distinct from conventional imputation methods, we\nachieve sample-level alignment through a novel distribution mapping mechanism\nthat guarantees both data consistency and completeness. Additionally, we\nintroduce a strategy employing global generator freezing to prevent\ncatastrophic forgetting, which in turn mitigates Non-IID fluctuations.\nExtensive evaluations on multimodal datasets demonstrate FedRecon's superior\nperformance in modality reconstruction under Non-IID conditions, surpassing\nstate-of-the-art methods.", "published": "2025-04-14 07:04:10", "link": "http://arxiv.org/abs/2504.09941v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Plasticity-Aware Mixture of Experts for Learning Under QoE Shifts in Adaptive Video Streaming", "abstract": "Adaptive video streaming systems are designed to optimize Quality of\nExperience (QoE) and, in turn, enhance user satisfaction. However, differences\nin user profiles and video content lead to different weights for QoE factors,\nresulting in user-specific QoE functions and, thus, varying optimization\nobjectives. This variability poses significant challenges for neural networks,\nas they often struggle to generalize under evolving targets - a phenomenon\nknown as plasticity loss that prevents conventional models from adapting\neffectively to changing optimization objectives. To address this limitation, we\npropose the Plasticity-Aware Mixture of Experts (PA-MoE), a novel learning\nframework that dynamically modulates network plasticity by balancing memory\nretention with selective forgetting. In particular, PA-MoE leverages noise\ninjection to promote the selective forgetting of outdated knowledge, thereby\nendowing neural networks with enhanced adaptive capabilities. In addition, we\npresent a rigorous theoretical analysis of PA-MoE by deriving a regret bound\nthat quantifies its learning performance. Experimental evaluations demonstrate\nthat PA-MoE achieves a 45.5% improvement in QoE over competitive baselines in\ndynamic streaming environments. Further analysis reveals that the model\neffectively mitigates plasticity loss by optimizing neuron utilization.\nFinally, a parameter sensitivity study is performed by injecting varying levels\nof noise, and the results align closely with our theoretical predictions.", "published": "2025-04-14 06:02:41", "link": "http://arxiv.org/abs/2504.09906v1", "categories": ["cs.MM", "cs.AI"], "primary_category": "cs.MM"}
{"title": "LangPert: Detecting and Handling Task-level Perturbations for Robust Object Rearrangement", "abstract": "Task execution for object rearrangement could be challenged by Task-Level\nPerturbations (TLP), i.e., unexpected object additions, removals, and\ndisplacements that can disrupt underlying visual policies and fundamentally\ncompromise task feasibility and progress. To address these challenges, we\npresent LangPert, a language-based framework designed to detect and mitigate\nTLP situations in tabletop rearrangement tasks. LangPert integrates a Visual\nLanguage Model (VLM) to comprehensively monitor policy's skill execution and\nenvironmental TLP, while leveraging the Hierarchical Chain-of-Thought (HCoT)\nreasoning mechanism to enhance the Large Language Model (LLM)'s contextual\nunderstanding and generate adaptive, corrective skill-execution plans. Our\nexperimental results demonstrate that LangPert handles diverse TLP situations\nmore effectively than baseline methods, achieving higher task completion rates,\nimproved execution efficiency, and potential generalization to unseen\nscenarios.", "published": "2025-04-14 05:39:15", "link": "http://arxiv.org/abs/2504.09893v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Constructing Micro Knowledge Graphs from Technical Support Documents", "abstract": "Short technical support pages such as IBM Technotes are quite common in\ntechnical support domain. These pages can be very useful as the knowledge\nsources for technical support applications such as chatbots, search engines and\nquestion-answering (QA) systems. Information extracted from documents to drive\ntechnical support applications is often stored in the form of Knowledge Graph\n(KG). Building KGs from a large corpus of documents poses a challenge of\ngranularity because a large number of entities and actions are present in each\npage. The KG becomes virtually unusable if all entities and actions from these\npages are stored in the KG. Therefore, only key entities and actions from each\npage are extracted and stored in the KG. This approach however leads to loss of\nknowledge represented by entities and actions left out of the KG as they are no\nlonger available to graph search and reasoning functions. We propose a set of\ntechniques to create micro knowledge graph (micrograph) for each of such web\npages. The micrograph stores all the entities and actions in a page and also\ntakes advantage of the structure of the page to represent exactly in which part\nof that page these entities and actions appeared, and also how they relate to\neach other. These micrographs can be used as additional knowledge sources by\ntechnical support applications. We define schemas for representing\nsemi-structured and plain text knowledge present in the technical support web\npages. Solutions in technical support domain include procedures made of steps.\nWe also propose a technique to extract procedures from these webpages and the\nschemas to represent them in the micrographs. We also discuss how technical\nsupport applications can take advantage of the micrographs.", "published": "2025-04-14 04:57:49", "link": "http://arxiv.org/abs/2504.09877v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "HDC: Hierarchical Distillation for Multi-level Noisy Consistency in Semi-Supervised Fetal Ultrasound Segmentation", "abstract": "Transvaginal ultrasound is a critical imaging modality for evaluating\ncervical anatomy and detecting physiological changes. However, accurate\nsegmentation of cervical structures remains challenging due to low contrast,\nshadow artifacts, and fuzzy boundaries. While convolutional neural networks\n(CNNs) have shown promising results in medical image segmentation, their\nperformance is often limited by the need for large-scale annotated datasets -\nan impractical requirement in clinical ultrasound imaging. Semi-supervised\nlearning (SSL) offers a compelling solution by leveraging unlabeled data, but\nexisting teacher-student frameworks often suffer from confirmation bias and\nhigh computational costs. We propose HDC, a novel semi-supervised segmentation\nframework that integrates Hierarchical Distillation and Consistency learning\nwithin a multi-level noise mean-teacher framework. Unlike conventional\napproaches that rely solely on pseudo-labeling, we introduce a hierarchical\ndistillation mechanism that guides feature-level learning via two novel\nobjectives: (1) Correlation Guidance Loss to align feature representations\nbetween the teacher and main student branch, and (2) Mutual Information Loss to\nstabilize representations between the main and noisy student branches. Our\nframework reduces model complexity while improving generalization. Extensive\nexperiments on two fetal ultrasound datasets, FUGC and PSFH, demonstrate that\nour method achieves competitive performance with significantly lower\ncomputational overhead than existing multi-teacher models.", "published": "2025-04-14 04:52:24", "link": "http://arxiv.org/abs/2504.09876v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Truncated Matrix Completion - An Empirical Study", "abstract": "Low-rank Matrix Completion (LRMC) describes the problem where we wish to\nrecover missing entries of partially observed low-rank matrix. Most existing\nmatrix completion work deals with sampling procedures that are independent of\nthe underlying data values. While this assumption allows the derivation of nice\ntheoretical guarantees, it seldom holds in real-world applications. In this\npaper, we consider various settings where the sampling mask is dependent on the\nunderlying data values, motivated by applications in sensing, sequential\ndecision-making, and recommender systems. Through a series of experiments, we\nstudy and compare the performance of various LRMC algorithms that were\noriginally successful for data-independent sampling patterns.", "published": "2025-04-14 04:42:00", "link": "http://arxiv.org/abs/2504.09873v1", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Labeling Messages as AI-Generated Does Not Reduce Their Persuasive Effects", "abstract": "As generative artificial intelligence (AI) enables the creation and\ndissemination of information at massive scale and speed, it is increasingly\nimportant to understand how people perceive AI-generated content. One prominent\npolicy proposal requires explicitly labeling AI-generated content to increase\ntransparency and encourage critical thinking about the information, but prior\nresearch has not yet tested the effects of such labels. To address this gap, we\nconducted a survey experiment (N=1601) on a diverse sample of Americans,\npresenting participants with an AI-generated message about several public\npolicies (e.g., allowing colleges to pay student-athletes), randomly assigning\nwhether participants were told the message was generated by (a) an expert AI\nmodel, (b) a human policy expert, or (c) no label. We found that messages were\ngenerally persuasive, influencing participants' views of the policies by 9.74\npercentage points on average. However, while 94.6% of participants assigned to\nthe AI and human label conditions believed the authorship labels, labels had no\nsignificant effects on participants' attitude change toward the policies,\njudgments of message accuracy, nor intentions to share the message with others.\nThese patterns were robust across a variety of participant characteristics,\nincluding prior knowledge of the policy, prior experience with AI, political\nparty, education level, or age. Taken together, these results imply that, while\nauthorship labels would likely enhance transparency, they are unlikely to\nsubstantially affect the persuasiveness of the labeled content, highlighting\nthe need for alternative strategies to address challenges posed by AI-generated\ninformation.", "published": "2025-04-14 04:22:39", "link": "http://arxiv.org/abs/2504.09865v1", "categories": ["cs.CY", "cs.AI", "cs.HC"], "primary_category": "cs.CY"}
{"title": "SUMART: SUMmARizing Translation from Wordy to Concise Expression", "abstract": "We propose SUMART, a method for summarizing and compressing the volume of\nverbose subtitle translations. SUMART is designed for understanding translated\ncaptions (e.g., interlingual conversations via subtitle translation or when\nwatching movies in foreign language audio and translated captions). SUMART is\nintended for users who want a big-picture and fast understanding of the\nconversation, audio, video content, and speech in a foreign language. During\nthe training data collection, when a speaker makes a verbose statement, SUMART\nemploys a large language model on-site to compress the volume of subtitles.\nThis compressed data is then stored in a database for fine-tuning purposes.\nLater, SUMART uses data pairs from those non-compressed ASR results and\ncompressed translated results for fine-tuning the translation model to generate\nmore concise translations for practical uses. In practical applications, SUMART\nutilizes this trained model to produce concise translation results.\nFurthermore, as a practical application, we developed an application that\nallows conversations using subtitle translation in augmented reality spaces. As\na pilot study, we conducted qualitative surveys using a SUMART prototype and a\nsurvey on the summarization model for SUMART. We envision the most effective\nuse case of this system is where users need to consume a lot of information\nquickly (e.g., Speech, lectures, podcasts, Q&A in conferences).", "published": "2025-04-14 04:13:09", "link": "http://arxiv.org/abs/2504.09860v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Working with Large Language Models to Enhance Messaging Effectiveness for Vaccine Confidence", "abstract": "Vaccine hesitancy and misinformation are significant barriers to achieving\nwidespread vaccination coverage. Smaller public health departments may lack the\nexpertise or resources to craft effective vaccine messaging. This paper\nexplores the potential of ChatGPT-augmented messaging to promote confidence in\nvaccination uptake.\n  We conducted a survey in which participants chose between pairs of\nvaccination messages and assessed which was more persuasive and to what extent.\nIn each pair, one message was the original, and the other was augmented by\nChatGPT. At the end of the survey, participants were informed that half of the\nmessages had been generated by ChatGPT. They were then asked to provide both\nquantitative and qualitative responses regarding how knowledge of a message's\nChatGPT origin affected their impressions.\n  Overall, ChatGPT-augmented messages were rated slightly higher than the\noriginal messages. These messages generally scored better when they were\nlonger. Respondents did not express major concerns about ChatGPT-generated\ncontent, nor was there a significant relationship between participants' views\non ChatGPT and their message ratings. Notably, there was a correlation between\nwhether a message appeared first or second in a pair and its score.\n  These results point to the potential of ChatGPT to enhance vaccine messaging,\nsuggesting a promising direction for future research on human-AI collaboration\nin public health communication.", "published": "2025-04-14 04:06:46", "link": "http://arxiv.org/abs/2504.09857v1", "categories": ["cs.CY", "cs.AI", "physics.soc-ph"], "primary_category": "cs.CY"}
{"title": "PestMA: LLM-based Multi-Agent System for Informed Pest Management", "abstract": "Effective pest management is complex due to the need for accurate,\ncontext-specific decisions. Recent advancements in large language models (LLMs)\nopen new possibilities for addressing these challenges by providing\nsophisticated, adaptive knowledge acquisition and reasoning. However, existing\nLLM-based pest management approaches often rely on a single-agent paradigm,\nwhich can limit their capacity to incorporate diverse external information,\nengage in systematic validation, and address complex, threshold-driven\ndecisions. To overcome these limitations, we introduce PestMA, an LLM-based\nmulti-agent system (MAS) designed to generate reliable and evidence-based pest\nmanagement advice. Building on an editorial paradigm, PestMA features three\nspecialized agents, an Editor for synthesizing pest management recommendations,\na Retriever for gathering relevant external data, and a Validator for ensuring\ncorrectness. Evaluations on real-world pest scenarios demonstrate that PestMA\nachieves an initial accuracy of 86.8% for pest management decisions, which\nincreases to 92.6% after validation. These results underscore the value of\ncollaborative agent-based workflows in refining and validating decisions,\nhighlighting the potential of LLM-based multi-agent systems to automate and\nenhance pest management processes.", "published": "2025-04-14 03:53:59", "link": "http://arxiv.org/abs/2504.09855v1", "categories": ["cs.MA", "cs.AI", "I.2.1; I.2.7"], "primary_category": "cs.MA"}
{"title": "Carbon-Efficient 3D DNN Acceleration: Optimizing Performance and Sustainability", "abstract": "As Deep Neural Networks (DNNs) continue to drive advancements in artificial\nintelligence, the design of hardware accelerators faces growing concerns over\nembodied carbon footprint due to complex fabrication processes. 3D integration\nimproves performance but introduces sustainability challenges, making\ncarbon-aware optimization essential. In this work, we propose a\ncarbon-efficient design methodology for 3D DNN accelerators, leveraging\napproximate computing and genetic algorithm-based design space exploration to\noptimize Carbon Delay Product (CDP). By integrating area-efficient approximate\nmultipliers into Multiply-Accumulate (MAC) units, our approach effectively\nreduces silicon area and fabrication overhead while maintaining high\ncomputational accuracy. Experimental evaluations across three technology nodes\n(45nm, 14nm, and 7nm) show that our method reduces embodied carbon by up to 30%\nwith negligible accuracy drop.", "published": "2025-04-14 03:48:37", "link": "http://arxiv.org/abs/2504.09851v1", "categories": ["cs.AR", "cs.AI"], "primary_category": "cs.AR"}
{"title": "GlyTwin: Digital Twin for Glucose Control in Type 1 Diabetes Through Optimal Behavioral Modifications Using Patient-Centric Counterfactuals", "abstract": "Frequent and long-term exposure to hyperglycemia (i.e., high blood glucose)\nincreases the risk of chronic complications such as neuropathy, nephropathy,\nand cardiovascular disease. Current technologies like continuous subcutaneous\ninsulin infusion (CSII) and continuous glucose monitoring (CGM) primarily model\nspecific aspects of glycemic control-like hypoglycemia prediction or insulin\ndelivery. Similarly, most digital twin approaches in diabetes management\nsimulate only physiological processes. These systems lack the ability to offer\nalternative treatment scenarios that support proactive behavioral\ninterventions. To address this, we propose GlyTwin, a novel digital twin\nframework that uses counterfactual explanations to simulate optimal treatments\nfor glucose regulation. Our approach helps patients and caregivers modify\nbehaviors like carbohydrate intake and insulin dosing to avoid abnormal glucose\nevents. GlyTwin generates behavioral treatment suggestions that proactively\nprevent hyperglycemia by recommending small adjustments to daily choices,\nreducing both frequency and duration of these events. Additionally, it\nincorporates stakeholder preferences into the intervention design, making\nrecommendations patient-centric and tailored. We evaluate GlyTwin on AZT1D, a\nnewly constructed dataset with longitudinal data from 21 type 1 diabetes (T1D)\npatients on automated insulin delivery systems over 26 days. Results show\nGlyTwin outperforms state-of-the-art counterfactual methods, generating 76.6%\nvalid and 86% effective interventions. These findings demonstrate the promise\nof counterfactual-driven digital twins in delivering personalized healthcare.", "published": "2025-04-14 03:32:39", "link": "http://arxiv.org/abs/2504.09846v1", "categories": ["cs.LG", "cs.AI", "cs.HC"], "primary_category": "cs.LG"}
{"title": "OVERLORD: Ultimate Scaling of DataLoader for Multi-Source Large Foundation Model Training", "abstract": "Modern frameworks for training large foundation models (LFMs) employ data\nloaders in a data parallel paradigm. While this design offers implementation\nsimplicity, it introduces two fundamental challenges. First, due to the\nquadratic computational complexity of the attention operator, the non-uniform\nsample distribution over data-parallel ranks leads to a significant workload\nimbalance among loaders, which degrades the training efficiency. This paradigm\nalso impedes the implementation of data mixing algorithms (e.g., curriculum\nlearning) over different datasets. Second, to acquire a broad range of\ncapability, LFMs training ingests data from diverse sources, each with distinct\nfile access states. Colocating massive datasets within loader instances can\neasily exceed local pod memory capacity. Additionally, heavy sources with\nhigher transformation latency require larger worker pools, further exacerbating\nmemory consumption.\n  We present OVERLORD, an industrial-grade distributed data loading\narchitecture with three innovations: (1) A centralized and declarative data\nplane, which facilitates elastic data orchestration strategy, such as\nlong-short context, multimodal, and curriculum learning; (2) Disaggregated\nmultisource preprocessing through role-specific actors, i.e., Source Loaders\nand Data Constructors, leveraging autoscaling for Source Loaders towards\nheterogeneous and evolving source preprocessing cost; (3) Shadow Loaders with\ndifferential checkpointing for uninterrupted fault recovery. Deployed on\nproduction clusters scaling to multi-thousand GPU, OVERLORD achieves: (1) 4.5x\nend-to-end training throughput improvement, (2) a minimum 3.6x reduction in CPU\nmemory usage, with further improvements to be added in later experiments.", "published": "2025-04-14 03:31:22", "link": "http://arxiv.org/abs/2504.09844v1", "categories": ["cs.DC", "cs.AI"], "primary_category": "cs.DC"}
{"title": "StruPhantom: Evolutionary Injection Attacks on Black-Box Tabular Agents Powered by Large Language Models", "abstract": "The proliferation of autonomous agents powered by large language models\n(LLMs) has revolutionized popular business applications dealing with tabular\ndata, i.e., tabular agents. Although LLMs are observed to be vulnerable against\nprompt injection attacks from external data sources, tabular agents impose\nstrict data formats and predefined rules on the attacker's payload, which are\nineffective unless the agent navigates multiple layers of structural data to\nincorporate the payload. To address the challenge, we present a novel attack\ntermed StruPhantom which specifically targets black-box LLM-powered tabular\nagents. Our attack designs an evolutionary optimization procedure which\ncontinually refines attack payloads via the proposed constrained Monte Carlo\nTree Search augmented by an off-topic evaluator. StruPhantom helps\nsystematically explore and exploit the weaknesses of target applications to\nachieve goal hijacking. Our evaluation validates the effectiveness of\nStruPhantom across various LLM-based agents, including those on real-world\nplatforms, and attack scenarios. Our attack achieves over 50% higher success\nrates than baselines in enforcing the application's response to contain\nphishing links or malicious codes.", "published": "2025-04-14 03:22:04", "link": "http://arxiv.org/abs/2504.09841v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "SafeSpeech: Robust and Universal Voice Protection Against Malicious Speech Synthesis", "abstract": "Speech synthesis technology has brought great convenience, while the\nwidespread usage of realistic deepfake audio has triggered hazards. Malicious\nadversaries may unauthorizedly collect victims' speeches and clone a similar\nvoice for illegal exploitation (\\textit{e.g.}, telecom fraud). However, the\nexisting defense methods cannot effectively prevent deepfake exploitation and\nare vulnerable to robust training techniques. Therefore, a more effective and\nrobust data protection method is urgently needed. In response, we propose a\ndefensive framework, \\textit{\\textbf{SafeSpeech}}, which protects the users'\naudio before uploading by embedding imperceptible perturbations on original\nspeeches to prevent high-quality synthetic speech. In SafeSpeech, we devise a\nrobust and universal proactive protection technique, \\textbf{S}peech\n\\textbf{PE}rturbative \\textbf{C}oncealment (\\textbf{SPEC}), that leverages a\nsurrogate model to generate universally applicable perturbation for generative\nsynthetic models. Moreover, we optimize the human perception of embedded\nperturbation in terms of time and frequency domains. To evaluate our method\ncomprehensively, we conduct extensive experiments across advanced models and\ndatasets, both subjectively and objectively. Our experimental results\ndemonstrate that SafeSpeech achieves state-of-the-art (SOTA) voice protection\neffectiveness and transferability and is highly robust against advanced\nadaptive adversaries. Moreover, SafeSpeech has real-time capability in\nreal-world tests. The source code is available at\n\\href{https://github.com/wxzyd123/SafeSpeech}{https://github.com/wxzyd123/SafeSpeech}.", "published": "2025-04-14 03:21:23", "link": "http://arxiv.org/abs/2504.09839v1", "categories": ["cs.SD", "cs.AI", "cs.CR", "cs.LG"], "primary_category": "cs.SD"}
{"title": "Offline Dynamic Inventory and Pricing Strategy: Addressing Censored and Dependent Demand", "abstract": "In this paper, we study the offline sequential feature-based pricing and\ninventory control problem where the current demand depends on the past demand\nlevels and any demand exceeding the available inventory is lost. Our goal is to\nleverage the offline dataset, consisting of past prices, ordering quantities,\ninventory levels, covariates, and censored sales levels, to estimate the\noptimal pricing and inventory control policy that maximizes long-term profit.\nWhile the underlying dynamic without censoring can be modeled by Markov\ndecision process (MDP), the primary obstacle arises from the observed process\nwhere demand censoring is present, resulting in missing profit information, the\nfailure of the Markov property, and a non-stationary optimal policy. To\novercome these challenges, we first approximate the optimal policy by solving a\nhigh-order MDP characterized by the number of consecutive censoring instances,\nwhich ultimately boils down to solving a specialized Bellman equation tailored\nfor this problem. Inspired by offline reinforcement learning and survival\nanalysis, we propose two novel data-driven algorithms to solving these Bellman\nequations and, thus, estimate the optimal policy. Furthermore, we establish\nfinite sample regret bounds to validate the effectiveness of these algorithms.\nFinally, we conduct numerical experiments to demonstrate the efficacy of our\nalgorithms in estimating the optimal policy. To the best of our knowledge, this\nis the first data-driven approach to learning optimal pricing and inventory\ncontrol policies in a sequential decision-making environment characterized by\ncensored and dependent demand. The implementations of the proposed algorithms\nare available at https://github.com/gundemkorel/Inventory_Pricing_Control", "published": "2025-04-14 02:57:51", "link": "http://arxiv.org/abs/2504.09831v1", "categories": ["stat.ML", "cs.AI", "cs.LG", "math.ST", "stat.AP", "stat.TH", "90B05, 68T05, 90C40, 62N02"], "primary_category": "stat.ML"}
{"title": "Efficient Multi-Task Modeling through Automated Fusion of Trained Models", "abstract": "Although multi-task learning is widely applied in intelligent services,\ntraditional multi-task modeling methods often require customized designs based\non specific task combinations, resulting in a cumbersome modeling process.\nInspired by the rapid development and excellent performance of single-task\nmodels, this paper proposes an efficient multi-task modeling method that can\nautomatically fuse trained single-task models with different structures and\ntasks to form a multi-task model. As a general framework, this method allows\nmodelers to simply prepare trained models for the required tasks, simplifying\nthe modeling process while fully utilizing the knowledge contained in the\ntrained models. This eliminates the need for excessive focus on task\nrelationships and model structure design. To achieve this goal, we consider the\nstructural differences among various trained models and employ model\ndecomposition techniques to hierarchically decompose them into multiple\noperable model components. Furthermore, we have designed an Adaptive Knowledge\nFusion (AKF) module based on Transformer, which adaptively integrates\nintra-task and inter-task knowledge based on model components. Through the\nproposed method, we achieve efficient and automated construction of multi-task\nmodels, and its effectiveness is verified through extensive experiments on\nthree datasets.", "published": "2025-04-14 02:21:45", "link": "http://arxiv.org/abs/2504.09812v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "See or Recall: A Sanity Check for the Role of Vision in Solving Visualization Question Answer Tasks with Multimodal LLMs", "abstract": "Recent developments in multimodal large language models (MLLM) have equipped\nlanguage models to reason about vision and language jointly. This permits MLLMs\nto both perceive and answer questions about data visualization across a variety\nof designs and tasks. Applying MLLMs to a broad range of visualization tasks\nrequires us to properly evaluate their capabilities, and the most common way to\nconduct evaluation is through measuring a model's visualization reasoning\ncapability, analogous to how we would evaluate human understanding of\nvisualizations (e.g., visualization literacy). However, we found that in the\ncontext of visualization question answering (VisQA), how an MLLM perceives and\nreasons about visualizations can be fundamentally different from how humans\napproach the same problem. During the evaluation, even without visualization,\nthe model could correctly answer a substantial portion of the visualization\ntest questions, regardless of whether any selection options were provided. We\nhypothesize that the vast amount of knowledge encoded in the language model\npermits factual recall that supersedes the need to seek information from the\nvisual signal. It raises concerns that the current VisQA evaluation may not\nfully capture the models' visualization reasoning capabilities. To address\nthis, we propose a comprehensive sanity check framework that integrates a\nrule-based decision tree and a sanity check table to disentangle the effects of\n\"seeing\" (visual processing) and \"recall\" (reliance on prior knowledge). This\nvalidates VisQA datasets for evaluation, highlighting where models are truly\n\"seeing\", positively or negatively affected by the factual recall, or relying\non inductive biases for question answering. Our study underscores the need for\ncareful consideration in designing future visualization understanding studies\nwhen utilizing MLLMs.", "published": "2025-04-14 02:19:28", "link": "http://arxiv.org/abs/2504.09809v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Multi-task Federated Learning with Encoder-Decoder Structure: Enabling Collaborative Learning Across Different Tasks", "abstract": "Federated learning has been extensively studied and applied due to its\nability to ensure data security in distributed environments while building\nbetter models. However, clients participating in federated learning still face\nlimitations, as clients with different structures or tasks cannot participate\nin learning together. In view of this, constructing a federated learning\nframework that allows collaboration between clients with different model\nstructures and performing different tasks, enabling them to share valuable\nknowledge to enhance model efficiency, holds significant practical implications\nfor the widespread application of federated learning. To achieve this goal, we\npropose a multi-task federated learning with encoder-decoder structure (M-Fed).\nSpecifically, given the widespread adoption of the encoder-decoder architecture\nin current models, we leverage this structure to share intra-task knowledge\nthrough traditional federated learning methods and extract general knowledge\nfrom the encoder to achieve cross-task knowledge sharing. The training process\nis similar to traditional federated learning, and we incorporate local decoder\nand global decoder information into the loss function. The local decoder\niteratively updates and gradually approaches the global decoder until\nsufficient cross-task knowledge sharing is achieved. Our method is lightweight\nand modular, demonstrating innovation compared to previous research. It enables\nclients performing different tasks to share general knowledge while maintaining\nthe efficiency of traditional federated learning systems. We conducted\nexperiments on two widely used benchmark datasets to verify the feasibility of\nM-Fed and compared it with traditional methods. The experimental results\ndemonstrate the effectiveness of M-Fed in multi-task federated learning.", "published": "2025-04-14 02:01:39", "link": "http://arxiv.org/abs/2504.09800v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "IGL-DT: Iterative Global-Local Feature Learning with Dual-Teacher Semantic Segmentation Framework under Limited Annotation Scheme", "abstract": "Semi-Supervised Semantic Segmentation (SSSS) aims to improve segmentation\naccuracy by leveraging a small set of labeled images alongside a larger pool of\nunlabeled data. Recent advances primarily focus on pseudo-labeling, consistency\nregularization, and co-training strategies. However, existing methods struggle\nto balance global semantic representation with fine-grained local feature\nextraction. To address this challenge, we propose a novel tri-branch\nsemi-supervised segmentation framework incorporating a dual-teacher strategy,\nnamed IGL-DT. Our approach employs SwinUnet for high-level semantic guidance\nthrough Global Context Learning and ResUnet for detailed feature refinement via\nLocal Regional Learning. Additionally, a Discrepancy Learning mechanism\nmitigates over-reliance on a single teacher, promoting adaptive feature\nlearning. Extensive experiments on benchmark datasets demonstrate that our\nmethod outperforms state-of-the-art approaches, achieving superior segmentation\nperformance across various data regimes.", "published": "2025-04-14 01:51:29", "link": "http://arxiv.org/abs/2504.09797v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "EquiVDM: Equivariant Video Diffusion Models with Temporally Consistent Noise", "abstract": "Temporally consistent video-to-video generation is essential for applications\nof video diffusion models in areas such as sim-to-real, style-transfer, video\nupsampling, etc. In this paper, we propose a video diffusion framework that\nleverages temporally consistent noise to generate coherent video frames without\nspecialized modules or additional constraints. We show that the standard\ntraining objective of diffusion models, when applied with temporally consistent\nnoise, encourages the model to be equivariant to spatial transformations in\ninput video and noise. This enables our model to better follow motion patterns\nfrom the input video, producing aligned motion and high-fidelity frames.\nFurthermore, we extend our approach to 3D-consistent video generation by\nattaching noise as textures on 3D meshes, ensuring 3D consistency in\nsim-to-real applications. Experimental results demonstrate that our method\nsurpasses state-of-the-art baselines in motion alignment, 3D consistency, and\nvideo quality while requiring only a few sampling steps in practice.", "published": "2025-04-14 01:26:29", "link": "http://arxiv.org/abs/2504.09789v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "\"All Roads Lead to ChatGPT\": How Generative AI is Eroding Social Interactions and Student Learning Communities", "abstract": "The widespread adoption of generative AI is already impacting learning and\nhelp-seeking. While the benefits of generative AI are well-understood, recent\nstudies have also raised concerns about increased potential for cheating and\nnegative impacts on students' metacognition and critical thinking. However, the\npotential impacts on social interactions, peer learning, and classroom dynamics\nare not yet well understood. To investigate these aspects, we conducted 17\nsemi-structured interviews with undergraduate computing students across seven\nR1 universities in North America. Our findings suggest that help-seeking\nrequests are now often mediated by generative AI. For example, students often\nredirected questions from their peers to generative AI instead of providing\nassistance themselves, undermining peer interaction. Students also reported\nfeeling increasingly isolated and demotivated as the social support systems\nthey rely on begin to break down. These findings are concerning given the\nimportant role that social interactions play in students' learning and sense of\nbelonging.", "published": "2025-04-14 00:40:58", "link": "http://arxiv.org/abs/2504.09779v1", "categories": ["cs.CY", "cs.AI", "cs.HC"], "primary_category": "cs.CY"}
{"title": "Reasoning without Regret", "abstract": "Chain-of-thought reasoning enables large language models to solve multi-step\ntasks by framing problem solving as sequential decision problems. Outcome-based\nrewards, which provide feedback only on final answers, show impressive success,\nbut face challenges with credit assignment and slow convergence. In contrast,\nprocedure-based rewards offer efficient step-level feedback, but typically\nrequire costly human supervision. We introduce \\emph{Backwards Adaptive Reward\nShaping} (BARS), a no-regret framework that converts sparse outcomes-based\nrewards into effective procedure-based signals. BARS uses sparse rewards\ngenerated from terminal-state priors and cover trees to scale rewards while\npreventing exploitation. With Bellman contraction and $(\\Delta, \\epsilon)$-gap\nrewards, our backward Euler solver achieves $\\epsilon$-accuracy in\n$O\\left((R_{\\max}/\\Delta)\\log(1/\\epsilon)\\right)$ iterations with $O(\\log T)$\ndynamic regret over $T$ rounds. Our analysis, based on generic chaining,\ncontinuous scaling limits, and non-linear Feynman-Kac bounds, connects recent\noutcome-based methods' empirical successes with the benefits of intermediate\nsupervision. Combined, this provides the first rigorous no-regret algorithm for\noutcome reward shaping, providing a theoretical foundation for the empirical\nsuccess of DeepSeek's R1.", "published": "2025-04-14 00:34:20", "link": "http://arxiv.org/abs/2504.09777v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Understanding and Optimizing Multi-Stage AI Inference Pipelines", "abstract": "The rapid evolution of Large Language Models (LLMs) has driven the need for\nincreasingly sophisticated inference pipelines and hardware platforms. Modern\nLLM serving extends beyond traditional prefill-decode workflows, incorporating\nmulti-stage processes such as Retrieval Augmented Generation (RAG), key-value\n(KV) cache retrieval, dynamic model routing, and multi step reasoning. These\nstages exhibit diverse computational demands, requiring distributed systems\nthat integrate GPUs, ASICs, CPUs, and memory-centric architectures. However,\nexisting simulators lack the fidelity to model these heterogeneous,\nmulti-engine workflows, limiting their ability to inform architectural\ndecisions.\n  To address this gap, we introduce HERMES, a Heterogeneous Multi-stage LLM\ninference Execution Simulator. HERMES models diverse request stages; including\nRAG, KV retrieval, reasoning, prefill, and decode across complex hardware\nhierarchies. HERMES supports heterogeneous clients executing multiple models\nconcurrently unlike prior frameworks while incorporating advanced batching\nstrategies and multi-level memory hierarchies. By integrating real hardware\ntraces with analytical modeling, HERMES captures critical trade-offs such as\nmemory bandwidth contention, inter-cluster communication latency, and batching\nefficiency in hybrid CPU-accelerator deployments. Through case studies, we\nexplore the impact of reasoning stages on end-to-end latency, optimal batching\nstrategies for hybrid pipelines, and the architectural implications of remote\nKV cache retrieval. HERMES empowers system designers to navigate the evolving\nlandscape of LLM inference, providing actionable insights into optimizing\nhardware-software co-design for next-generation AI workloads.", "published": "2025-04-14 00:29:49", "link": "http://arxiv.org/abs/2504.09775v1", "categories": ["cs.AR", "cs.AI", "cs.DC", "cs.LG"], "primary_category": "cs.AR"}
{"title": "Two Heads are Better Than One: Test-time Scaling of Multi-agent Collaborative Reasoning", "abstract": "Multi-agent systems (MAS) built on large language models (LLMs) offer a\npromising path toward solving complex, real-world tasks that single-agent\nsystems often struggle to manage. While recent advancements in test-time\nscaling (TTS) have significantly improved single-agent performance on\nchallenging reasoning tasks, how to effectively scale collaboration and\nreasoning in MAS remains an open question. In this work, we introduce an\nadaptive multi-agent framework designed to enhance collaborative reasoning\nthrough both model-level training and system-level coordination. We construct\nM500, a high-quality dataset containing 500 multi-agent collaborative reasoning\ntraces, and fine-tune Qwen2.5-32B-Instruct on this dataset to produce M1-32B, a\nmodel optimized for multi-agent collaboration. To further enable adaptive\nreasoning, we propose a novel CEO agent that dynamically manages the discussion\nprocess, guiding agent collaboration and adjusting reasoning depth for more\neffective problem-solving. Evaluated in an open-source MAS across a range of\ntasks-including general understanding, mathematical reasoning, and coding-our\nsystem significantly outperforms strong baselines. For instance, M1-32B\nachieves 12% improvement on GPQA-Diamond, 41% on AIME2024, and 10% on\nMBPP-Sanitized, matching the performance of state-of-the-art models like\nDeepSeek-R1 on some tasks. These results highlight the importance of both\nlearned collaboration and adaptive coordination in scaling multi-agent\nreasoning. Code is available at https://github.com/jincan333/MAS-TTS", "published": "2025-04-14 00:27:45", "link": "http://arxiv.org/abs/2504.09772v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "(How) Do reasoning models reason?", "abstract": "We will provide a broad unifying perspective on the recent breed of Large\nReasoning Models (LRMs) such as OpenAI o1 and DeepSeek R1, including their\npromise, sources of power, misconceptions and limitations.", "published": "2025-04-14 00:03:34", "link": "http://arxiv.org/abs/2504.09762v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "FLOSS: Free Lunch in Open-vocabulary Semantic Segmentation", "abstract": "Recent Open-Vocabulary Semantic Segmentation (OVSS) models extend the CLIP\nmodel to segmentation while maintaining the use of multiple templates (e.g., a\nphoto of <class>, a sketch of a <class>, etc.) for constructing class-wise\naveraged text embeddings, acting as a classifier. In this paper, we challenge\nthis status quo and investigate the impact of templates for OVSS. Empirically,\nwe observe that for each class, there exist single-template classifiers\nsignificantly outperforming the conventional averaged classifier. We refer to\nthem as class-experts. Given access to unlabeled images and without any\ntraining involved, we estimate these experts by leveraging the class-wise\nprediction entropy of single-template classifiers, selecting as class-wise\nexperts those which yield the lowest entropy. All experts, each specializing in\na specific class, collaborate in a newly proposed fusion method to generate\nmore accurate OVSS predictions. Our plug-and-play method, coined FLOSS, is\northogonal and complementary to existing OVSS methods, offering a ''free\nlunch'' to systematically improve OVSS without labels and additional training.\nExtensive experiments demonstrate that FLOSS consistently boosts\nstate-of-the-art methods on various OVSS benchmarks. Moreover, the selected\nexpert templates can generalize well from one dataset to others sharing the\nsame semantic categories, yet exhibiting distribution shifts. Additionally, we\nobtain satisfactory improvements under a low-data regime, where only a few\nunlabeled images are available. Our code is available at\nhttps://github.com/yasserben/FLOSS .", "published": "2025-04-14 17:59:59", "link": "http://arxiv.org/abs/2504.10487v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "DNF-Avatar: Distilling Neural Fields for Real-time Animatable Avatar Relighting", "abstract": "Creating relightable and animatable human avatars from monocular videos is a\nrising research topic with a range of applications, e.g. virtual reality,\nsports, and video games. Previous works utilize neural fields together with\nphysically based rendering (PBR), to estimate geometry and disentangle\nappearance properties of human avatars. However, one drawback of these methods\nis the slow rendering speed due to the expensive Monte Carlo ray tracing. To\ntackle this problem, we proposed to distill the knowledge from implicit neural\nfields (teacher) to explicit 2D Gaussian splatting (student) representation to\ntake advantage of the fast rasterization property of Gaussian splatting. To\navoid ray-tracing, we employ the split-sum approximation for PBR appearance. We\nalso propose novel part-wise ambient occlusion probes for shadow computation.\nShadow prediction is achieved by querying these probes only once per pixel,\nwhich paves the way for real-time relighting of avatars. These techniques\ncombined give high-quality relighting results with realistic shadow effects.\nOur experiments demonstrate that the proposed student model achieves comparable\nor even better relighting results with our teacher model while being 370 times\nfaster at inference time, achieving a 67 FPS rendering speed.", "published": "2025-04-14 17:59:58", "link": "http://arxiv.org/abs/2504.10486v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Decoupled Diffusion Sparks Adaptive Scene Generation", "abstract": "Controllable scene generation could reduce the cost of diverse data\ncollection substantially for autonomous driving. Prior works formulate the\ntraffic layout generation as predictive progress, either by denoising entire\nsequences at once or by iteratively predicting the next frame. However, full\nsequence denoising hinders online reaction, while the latter's short-sighted\nnext-frame prediction lacks precise goal-state guidance. Further, the learned\nmodel struggles to generate complex or challenging scenarios due to a large\nnumber of safe and ordinal driving behaviors from open datasets. To overcome\nthese, we introduce Nexus, a decoupled scene generation framework that improves\nreactivity and goal conditioning by simulating both ordinal and challenging\nscenarios from fine-grained tokens with independent noise states. At the core\nof the decoupled pipeline is the integration of a partial noise-masking\ntraining strategy and a noise-aware schedule that ensures timely environmental\nupdates throughout the denoising process. To complement challenging scenario\ngeneration, we collect a dataset consisting of complex corner cases. It covers\n540 hours of simulated data, including high-risk interactions such as cut-in,\nsudden braking, and collision. Nexus achieves superior generation realism while\npreserving reactivity and goal orientation, with a 40% reduction in\ndisplacement error. We further demonstrate that Nexus improves closed-loop\nplanning by 20% through data augmentation and showcase its capability in\nsafety-critical data generation.", "published": "2025-04-14 17:59:57", "link": "http://arxiv.org/abs/2504.10485v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "REPA-E: Unlocking VAE for End-to-End Tuning with Latent Diffusion Transformers", "abstract": "In this paper we tackle a fundamental question: \"Can we train latent\ndiffusion models together with the variational auto-encoder (VAE) tokenizer in\nan end-to-end manner?\" Traditional deep-learning wisdom dictates that\nend-to-end training is often preferable when possible. However, for latent\ndiffusion transformers, it is observed that end-to-end training both VAE and\ndiffusion-model using standard diffusion-loss is ineffective, even causing a\ndegradation in final performance. We show that while diffusion loss is\nineffective, end-to-end training can be unlocked through the\nrepresentation-alignment (REPA) loss -- allowing both VAE and diffusion model\nto be jointly tuned during the training process. Despite its simplicity, the\nproposed training recipe (REPA-E) shows remarkable performance; speeding up\ndiffusion model training by over 17x and 45x over REPA and vanilla training\nrecipes, respectively. Interestingly, we observe that end-to-end tuning with\nREPA-E also improves the VAE itself; leading to improved latent space structure\nand downstream generation performance. In terms of final performance, our\napproach sets a new state-of-the-art; achieving FID of 1.26 and 1.83 with and\nwithout classifier-free guidance on ImageNet 256 x 256. Code is available at\nhttps://end2end-diffusion.github.io.", "published": "2025-04-14 17:59:53", "link": "http://arxiv.org/abs/2504.10483v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "abstract": "We introduce InternVL3, a significant advancement in the InternVL series\nfeaturing a native multimodal pre-training paradigm. Rather than adapting a\ntext-only large language model (LLM) into a multimodal large language model\n(MLLM) that supports visual inputs, InternVL3 jointly acquires multimodal and\nlinguistic capabilities from both diverse multimodal data and pure-text corpora\nduring a single pre-training stage. This unified training paradigm effectively\naddresses the complexities and alignment challenges commonly encountered in\nconventional post-hoc training pipelines for MLLMs. To further improve\nperformance and scalability, InternVL3 incorporates variable visual position\nencoding (V2PE) to support extended multimodal contexts, employs advanced\npost-training techniques such as supervised fine-tuning (SFT) and mixed\npreference optimization (MPO), and adopts test-time scaling strategies\nalongside an optimized training infrastructure. Extensive empirical evaluations\ndemonstrate that InternVL3 delivers superior performance across a wide range of\nmulti-modal tasks. In particular, InternVL3-78B achieves a score of 72.2 on the\nMMMU benchmark, setting a new state-of-the-art among open-source MLLMs. Its\ncapabilities remain highly competitive with leading proprietary models,\nincluding ChatGPT-4o, Claude 3.5 Sonnet, and Gemini 2.5 Pro, while also\nmaintaining strong pure-language proficiency. In pursuit of open-science\nprinciples, we will publicly release both the training data and model weights\nto foster further research and development in next-generation MLLMs.", "published": "2025-04-14 17:59:25", "link": "http://arxiv.org/abs/2504.10479v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Art3D: Training-Free 3D Generation from Flat-Colored Illustration", "abstract": "Large-scale pre-trained image-to-3D generative models have exhibited\nremarkable capabilities in diverse shape generations. However, most of them\nstruggle to synthesize plausible 3D assets when the reference image is\nflat-colored like hand drawings due to the lack of 3D illusion, which are often\nthe most user-friendly input modalities in art content creation. To this end,\nwe propose Art3D, a training-free method that can lift flat-colored 2D designs\ninto 3D. By leveraging structural and semantic features with pre- trained 2D\nimage generation models and a VLM-based realism evaluation, Art3D successfully\nenhances the three-dimensional illusion in reference images, thus simplifying\nthe process of generating 3D from 2D, and proves adaptable to a wide range of\npainting styles. To benchmark the generalization performance of existing\nimage-to-3D models on flat-colored images without 3D feeling, we collect a new\ndataset, Flat-2D, with over 100 samples. Experimental results demonstrate the\nperformance and robustness of Art3D, exhibiting superior generalizable capacity\nand promising practical applicability. Our source code and dataset will be\npublicly available on our project page: https://joy-jy11.github.io/ .", "published": "2025-04-14 17:53:10", "link": "http://arxiv.org/abs/2504.10466v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Pixel-SAIL: Single Transformer For Pixel-Grounded Understanding", "abstract": "Multimodal Large Language Models (MLLMs) achieve remarkable performance for\nfine-grained pixel-level understanding tasks. However, all the works rely\nheavily on extra components, such as vision encoder (CLIP), segmentation\nexperts, leading to high system complexity and limiting model scaling. In this\nwork, our goal is to explore a highly simplified MLLM without introducing extra\ncomponents. Our work is motivated by the recent works on Single trAnsformer as\na unified vIsion-Language Model (SAIL) design, where these works jointly learn\nvision tokens and text tokens in transformers. We present Pixel-SAIL, a single\ntransformer for pixel-wise MLLM tasks. In particular, we present three\ntechnical improvements on the plain baseline. First, we design a learnable\nupsampling module to refine visual token features. Secondly, we propose a novel\nvisual prompt injection strategy to enable the single transformer to understand\nvisual prompt inputs and benefit from the early fusion of visual prompt\nembeddings and vision tokens. Thirdly, we introduce a vision expert\ndistillation strategy to efficiently enhance the single transformer's\nfine-grained feature extraction capability. In addition, we have collected a\ncomprehensive pixel understanding benchmark (PerBench), using a manual check.\nIt includes three tasks: detailed object description, visual prompt-based\nquestion answering, and visual-text referring segmentation. Extensive\nexperiments on four referring segmentation benchmarks, one visual prompt\nbenchmark, and our PerBench show that our Pixel-SAIL achieves comparable or\neven better results with a much simpler pipeline. Code and model will be\nreleased at https://github.com/magic-research/Sa2VA.", "published": "2025-04-14 17:52:22", "link": "http://arxiv.org/abs/2504.10465v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "The Scalability of Simplicity: Empirical Analysis of Vision-Language Learning with a Single Transformer", "abstract": "This paper introduces SAIL, a single transformer unified multimodal large\nlanguage model (MLLM) that integrates raw pixel encoding and language decoding\nwithin a singular architecture. Unlike existing modular MLLMs, which rely on a\npre-trained vision transformer (ViT), SAIL eliminates the need for a separate\nvision encoder, presenting a more minimalist architecture design. Instead of\nintroducing novel architectural components, SAIL adapts mix-attention\nmechanisms and multimodal positional encodings to better align with the\ndistinct characteristics of visual and textual modalities. We systematically\ncompare SAIL's properties-including scalability, cross-modal information flow\npatterns, and visual representation capabilities-with those of modular MLLMs.\nBy scaling both training data and model size, SAIL achieves performance\ncomparable to modular MLLMs. Notably, the removal of pretrained ViT components\nenhances SAIL's scalability and results in significantly different cross-modal\ninformation flow patterns. Moreover, SAIL demonstrates strong visual\nrepresentation capabilities, achieving results on par with ViT-22B in vision\ntasks such as semantic segmentation. Code and models are available at\nhttps://github.com/bytedance/SAIL.", "published": "2025-04-14 17:50:20", "link": "http://arxiv.org/abs/2504.10462v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Integrating Vision and Location with Transformers: A Multimodal Deep Learning Framework for Medical Wound Analysis", "abstract": "Effective recognition of acute and difficult-to-heal wounds is a necessary\nstep in wound diagnosis. An efficient classification model can help wound\nspecialists classify wound types with less financial and time costs and also\nhelp in deciding on the optimal treatment method. Traditional machine learning\nmodels suffer from feature selection and are usually cumbersome models for\naccurate recognition. Recently, deep learning (DL) has emerged as a powerful\ntool in wound diagnosis. Although DL seems promising for wound type\nrecognition, there is still a large scope for improving the efficiency and\naccuracy of the model. In this study, a DL-based multimodal classifier was\ndeveloped using wound images and their corresponding locations to classify them\ninto multiple classes, including diabetic, pressure, surgical, and venous\nulcers. A body map was also created to provide location data, which can help\nwound specialists label wound locations more effectively. The model uses a\nVision Transformer to extract hierarchical features from input images, a\nDiscrete Wavelet Transform (DWT) layer to capture low and high frequency\ncomponents, and a Transformer to extract spatial features. The number of\nneurons and weight vector optimization were performed using three swarm-based\noptimization techniques (Monster Gorilla Toner (MGTO), Improved Gray Wolf\nOptimization (IGWO), and Fox Optimization Algorithm). The evaluation results\nshow that weight vector optimization using optimization algorithms can increase\ndiagnostic accuracy and make it a very effective approach for wound detection.\nIn the classification using the original body map, the proposed model was able\nto achieve an accuracy of 0.8123 using image data and an accuracy of 0.8007\nusing a combination of image data and wound location. Also, the accuracy of the\nmodel in combination with the optimization models varied from 0.7801 to 0.8342.", "published": "2025-04-14 17:39:18", "link": "http://arxiv.org/abs/2504.10452v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Anchor Token Matching: Implicit Structure Locking for Training-free AR Image Editing", "abstract": "Text-to-image generation has seen groundbreaking advancements with diffusion\nmodels, enabling high-fidelity synthesis and precise image editing through\ncross-attention manipulation. Recently, autoregressive (AR) models have\nre-emerged as powerful alternatives, leveraging next-token generation to match\ndiffusion models. However, existing editing techniques designed for diffusion\nmodels fail to translate directly to AR models due to fundamental differences\nin structural control. Specifically, AR models suffer from spatial poverty of\nattention maps and sequential accumulation of structural errors during image\nediting, which disrupt object layouts and global consistency. In this work, we\nintroduce Implicit Structure Locking (ISLock), the first training-free editing\nstrategy for AR visual models. Rather than relying on explicit attention\nmanipulation or fine-tuning, ISLock preserves structural blueprints by\ndynamically aligning self-attention patterns with reference images through the\nAnchor Token Matching (ATM) protocol. By implicitly enforcing structural\nconsistency in latent space, our method ISLock enables structure-aware editing\nwhile maintaining generative autonomy. Extensive experiments demonstrate that\nISLock achieves high-quality, structure-consistent edits without additional\ntraining and is superior or comparable to conventional editing techniques. Our\nfindings pioneer the way for efficient and flexible AR-based image editing,\nfurther bridging the performance gap between diffusion and autoregressive\ngenerative models. The code will be publicly available at\nhttps://github.com/hutaiHang/ATM", "published": "2025-04-14 17:25:19", "link": "http://arxiv.org/abs/2504.10434v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MonoDiff9D: Monocular Category-Level 9D Object Pose Estimation via Diffusion Model", "abstract": "Object pose estimation is a core means for robots to understand and interact\nwith their environment. For this task, monocular category-level methods are\nattractive as they require only a single RGB camera. However, current methods\nrely on shape priors or CAD models of the intra-class known objects. We propose\na diffusion-based monocular category-level 9D object pose generation method,\nMonoDiff9D. Our motivation is to leverage the probabilistic nature of diffusion\nmodels to alleviate the need for shape priors, CAD models, or depth sensors for\nintra-class unknown object pose estimation. We first estimate coarse depth via\nDINOv2 from the monocular image in a zero-shot manner and convert it into a\npoint cloud. We then fuse the global features of the point cloud with the input\nimage and use the fused features along with the encoded time step to condition\nMonoDiff9D. Finally, we design a transformer-based denoiser to recover the\nobject pose from Gaussian noise. Extensive experiments on two popular benchmark\ndatasets show that MonoDiff9D achieves state-of-the-art monocular\ncategory-level 9D object pose estimation accuracy without the need for shape\npriors or CAD models at any stage. Our code will be made public at\nhttps://github.com/CNJianLiu/MonoDiff9D.", "published": "2025-04-14 17:21:10", "link": "http://arxiv.org/abs/2504.10433v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "HUMOTO: A 4D Dataset of Mocap Human Object Interactions", "abstract": "We present Human Motions with Objects (HUMOTO), a high-fidelity dataset of\nhuman-object interactions for motion generation, computer vision, and robotics\napplications. Featuring 736 sequences (7,875 seconds at 30 fps), HUMOTO\ncaptures interactions with 63 precisely modeled objects and 72 articulated\nparts. Our innovations include a scene-driven LLM scripting pipeline creating\ncomplete, purposeful tasks with natural progression, and a mocap-and-camera\nrecording setup to effectively handle occlusions. Spanning diverse activities\nfrom cooking to outdoor picnics, HUMOTO preserves both physical accuracy and\nlogical task flow. Professional artists rigorously clean and verify each\nsequence, minimizing foot sliding and object penetrations. We also provide\nbenchmarks compared to other datasets. HUMOTO's comprehensive full-body motion\nand simultaneous multi-object interactions address key data-capturing\nchallenges and provide opportunities to advance realistic human-object\ninteraction modeling across research domains with practical applications in\nanimation, robotics, and embodied AI systems. Project:\nhttps://jiaxin-lu.github.io/humoto/ .", "published": "2025-04-14 16:59:29", "link": "http://arxiv.org/abs/2504.10414v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GPS: Distilling Compact Memories via Grid-based Patch Sampling for Efficient Online Class-Incremental Learning", "abstract": "Online class-incremental learning aims to enable models to continuously adapt\nto new classes with limited access to past data, while mitigating catastrophic\nforgetting. Replay-based methods address this by maintaining a small memory\nbuffer of previous samples, achieving competitive performance. For effective\nreplay under constrained storage, recent approaches leverage distilled data to\nenhance the informativeness of memory. However, such approaches often involve\nsignificant computational overhead due to the use of bi-level optimization.\nMotivated by these limitations, we introduce Grid-based Patch Sampling (GPS), a\nlightweight and effective strategy for distilling informative memory samples\nwithout relying on a trainable model. GPS generates informative samples by\nsampling a subset of pixels from the original image, yielding compact\nlow-resolution representations that preserve both semantic content and\nstructural information. During replay, these representations are reassembled to\nsupport training and evaluation. Experiments on extensive benchmarks\ndemonstrate that GRS can be seamlessly integrated into existing replay\nframeworks, leading to 3%-4% improvements in average end accuracy under\nmemory-constrained settings, with limited computational overhead.", "published": "2025-04-14 16:58:02", "link": "http://arxiv.org/abs/2504.10409v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Low-Latency Event-based Obstacle Avoidance on a FPGA-Drone", "abstract": "This work quantitatively evaluates the performance of event-based vision\nsystems (EVS) against conventional RGB-based models for action prediction in\ncollision avoidance on an FPGA accelerator. Our experiments demonstrate that\nthe EVS model achieves a significantly higher effective frame rate (1 kHz) and\nlower temporal (-20 ms) and spatial prediction errors (-20 mm) compared to the\nRGB-based model, particularly when tested on out-of-distribution data. The EVS\nmodel also exhibits superior robustness in selecting optimal evasion maneuvers.\nIn particular, in distinguishing between movement and stationary states, it\nachieves a 59 percentage point advantage in precision (78% vs. 19%) and a\nsubstantially higher F1 score (0.73 vs. 0.06), highlighting the susceptibility\nof the RGB model to overfitting. Further analysis in different combinations of\nspatial classes confirms the consistent performance of the EVS model in both\ntest data sets. Finally, we evaluated the system end-to-end and achieved a\nlatency of approximately 2.14 ms, with event aggregation (1 ms) and inference\non the processing unit (0.94 ms) accounting for the largest components. These\nresults underscore the advantages of event-based vision for real-time collision\navoidance and demonstrate its potential for deployment in resource-constrained\nenvironments.", "published": "2025-04-14 16:51:10", "link": "http://arxiv.org/abs/2504.10400v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Better Coherence, Better Height: Fusing Physical Models and Deep Learning for Forest Height Estimation from Interferometric SAR Data", "abstract": "Estimating forest height from Synthetic Aperture Radar (SAR) images often\nrelies on traditional physical models, which, while interpretable and\ndata-efficient, can struggle with generalization. In contrast, Deep Learning\n(DL) approaches lack physical insight. To address this, we propose CoHNet - an\nend-to-end framework that combines the best of both worlds: DL optimized with\nphysics-informed constraints. We leverage a pre-trained neural surrogate model\nto enforce physical plausibility through a unique training loss. Our\nexperiments show that this approach not only improves forest height estimation\naccuracy but also produces meaningful features that enhance the reliability of\npredictions.", "published": "2025-04-14 16:44:08", "link": "http://arxiv.org/abs/2504.10395v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PG-DPIR: An efficient plug-and-play method for high-count Poisson-Gaussian inverse problems", "abstract": "Poisson-Gaussian noise describes the noise of various imaging systems thus\nthe need of efficient algorithms for Poisson-Gaussian image restoration. Deep\nlearning methods offer state-of-the-art performance but often require\nsensor-specific training when used in a supervised setting. A promising\nalternative is given by plug-and-play (PnP) methods, which consist in learning\nonly a regularization through a denoiser, allowing to restore images from\nseveral sources with the same network. This paper introduces PG-DPIR, an\nefficient PnP method for high-count Poisson-Gaussian inverse problems, adapted\nfrom DPIR. While DPIR is designed for white Gaussian noise, a naive adaptation\nto Poisson-Gaussian noise leads to prohibitively slow algorithms due to the\nabsence of a closed-form proximal operator. To address this, we adapt DPIR for\nthe specificities of Poisson-Gaussian noise and propose in particular an\nefficient initialization of the gradient descent required for the proximal step\nthat accelerates convergence by several orders of magnitude. Experiments are\nconducted on satellite image restoration and super-resolution problems.\nHigh-resolution realistic Pleiades images are simulated for the experiments,\nwhich demonstrate that PG-DPIR achieves state-of-the-art performance with\nimproved efficiency, which seems promising for on-ground satellite processing\nchains.", "published": "2025-04-14 16:23:15", "link": "http://arxiv.org/abs/2504.10375v1", "categories": ["cs.CV", "cs.LG", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Patch and Shuffle: A Preprocessing Technique for Texture Classification in Autonomous Cementitious Fabrication", "abstract": "Autonomous fabrication systems are transforming construction and\nmanufacturing, yet they remain vulnerable to print errors. Texture\nclassification is a key component of computer vision systems that enable\nreal-time monitoring and adjustment during cementitious fabrication.\nTraditional classification methods often rely on global image features, which\ncan bias the model toward semantic content rather than low-level textures. In\nthis paper, we introduce a novel preprocessing technique called \"patch and\nshuffle,\" which segments input images into smaller patches, shuffles them, and\nreconstructs a jumbled image before classification. This transformation removes\nsemantic context, forcing the classifier to rely on local texture features.\n  We evaluate this approach on a dataset of extruded cement images, using a\nResNet-18-based architecture. Our experiments compare the patch and shuffle\nmethod to a standard pipeline, holding all other factors constant. Results show\na significant improvement in accuracy: the patch and shuffle model achieved\n90.64% test accuracy versus 72.46% for the baseline. These findings suggest\nthat disrupting global structure enhances performance in texture-based\nclassification tasks.\n  This method has implications for broader vision tasks where low-level\nfeatures matter more than high-level semantics. The technique may improve\nclassification in applications ranging from fabrication monitoring to medical\nimaging.", "published": "2025-04-14 16:03:21", "link": "http://arxiv.org/abs/2504.10353v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multimodal Representation Learning Techniques for Comprehensive Facial State Analysis", "abstract": "Multimodal foundation models have significantly improved feature\nrepresentation by integrating information from multiple modalities, making them\nhighly suitable for a broader set of applications. However, the exploration of\nmultimodal facial representation for understanding perception has been limited.\nUnderstanding and analyzing facial states, such as Action Units (AUs) and\nemotions, require a comprehensive and robust framework that bridges visual and\nlinguistic modalities. In this paper, we present a comprehensive pipeline for\nmultimodal facial state analysis. First, we compile a new Multimodal Face\nDataset (MFA) by generating detailed multilevel language descriptions of face,\nincorporating Action Unit (AU) and emotion descriptions, by leveraging GPT-4o.\nSecond, we introduce a novel Multilevel Multimodal Face Foundation model (MF^2)\ntailored for Action Unit (AU) and emotion recognition. Our model incorporates\ncomprehensive visual feature modeling at both local and global levels of face\nimage, enhancing its ability to represent detailed facial appearances. This\ndesign aligns visual representations with structured AU and emotion\ndescriptions, ensuring effective cross-modal integration. Third, we develop a\nDecoupled Fine-Tuning Network (DFN) that efficiently adapts MF^2 across various\ntasks and datasets. This approach not only reduces computational overhead but\nalso broadens the applicability of the foundation model to diverse scenarios.\nExperimentation show superior performance for AU and emotion detection tasks.", "published": "2025-04-14 16:00:57", "link": "http://arxiv.org/abs/2504.10351v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Benchmarking 3D Human Pose Estimation Models Under Occlusions", "abstract": "This paper addresses critical challenges in 3D Human Pose Estimation (HPE) by\nanalyzing the robustness and sensitivity of existing models to occlusions,\ncamera position, and action variability. Using a novel synthetic dataset,\nBlendMimic3D, which includes diverse scenarios with multi-camera setups and\nseveral occlusion types, we conduct specific tests on several state-of-the-art\nmodels. Our study focuses on the discrepancy in keypoint formats between common\ndatasets such as Human3.6M, and 2D datasets such as COCO, commonly used for 2D\ndetection models and frequently input of 3D HPE models. Our work explores the\nimpact of occlusions on model performance and the generality of models trained\nexclusively under standard conditions. The findings suggest significant\nsensitivity to occlusions and camera settings, revealing a need for models that\nbetter adapt to real-world variability and occlusion scenarios. This research\ncontributed to ongoing efforts to improve the fidelity and applicability of 3D\nHPE systems in complex environments.", "published": "2025-04-14 16:00:25", "link": "http://arxiv.org/abs/2504.10350v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LL-Gaussian: Low-Light Scene Reconstruction and Enhancement via Gaussian Splatting for Novel View Synthesis", "abstract": "Novel view synthesis (NVS) in low-light scenes remains a significant\nchallenge due to degraded inputs characterized by severe noise, low dynamic\nrange (LDR) and unreliable initialization. While recent NeRF-based approaches\nhave shown promising results, most suffer from high computational costs, and\nsome rely on carefully captured or pre-processed data--such as RAW sensor\ninputs or multi-exposure sequences--which severely limits their practicality.\nIn contrast, 3D Gaussian Splatting (3DGS) enables real-time rendering with\ncompetitive visual fidelity; however, existing 3DGS-based methods struggle with\nlow-light sRGB inputs, resulting in unstable Gaussian initialization and\nineffective noise suppression. To address these challenges, we propose\nLL-Gaussian, a novel framework for 3D reconstruction and enhancement from\nlow-light sRGB images, enabling pseudo normal-light novel view synthesis. Our\nmethod introduces three key innovations: 1) an end-to-end Low-Light Gaussian\nInitialization Module (LLGIM) that leverages dense priors from learning-based\nMVS approach to generate high-quality initial point clouds; 2) a dual-branch\nGaussian decomposition model that disentangles intrinsic scene properties\n(reflectance and illumination) from transient interference, enabling stable and\ninterpretable optimization; 3) an unsupervised optimization strategy guided by\nboth physical constrains and diffusion prior to jointly steer decomposition and\nenhancement. Additionally, we contribute a challenging dataset collected in\nextreme low-light environments and demonstrate the effectiveness of\nLL-Gaussian. Compared to state-of-the-art NeRF-based methods, LL-Gaussian\nachieves up to 2,000 times faster inference and reduces training time to just\n2%, while delivering superior reconstruction and rendering quality.", "published": "2025-04-14 15:39:31", "link": "http://arxiv.org/abs/2504.10331v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "InstructEngine: Instruction-driven Text-to-Image Alignment", "abstract": "Reinforcement Learning from Human/AI Feedback (RLHF/RLAIF) has been\nextensively utilized for preference alignment of text-to-image models. Existing\nmethods face certain limitations in terms of both data and algorithm. For\ntraining data, most approaches rely on manual annotated preference data, either\nby directly fine-tuning the generators or by training reward models to provide\ntraining signals. However, the high annotation cost makes them difficult to\nscale up, the reward model consumes extra computation and cannot guarantee\naccuracy. From an algorithmic perspective, most methods neglect the value of\ntext and only take the image feedback as a comparative signal, which is\ninefficient and sparse. To alleviate these drawbacks, we propose the\nInstructEngine framework. Regarding annotation cost, we first construct a\ntaxonomy for text-to-image generation, then develop an automated data\nconstruction pipeline based on it. Leveraging advanced large multimodal models\nand human-defined rules, we generate 25K text-image preference pairs. Finally,\nwe introduce cross-validation alignment method, which refines data efficiency\nby organizing semantically analogous samples into mutually comparable pairs.\nEvaluations on DrawBench demonstrate that InstructEngine improves SD v1.5 and\nSDXL's performance by 10.53% and 5.30%, outperforming state-of-the-art\nbaselines, with ablation study confirming the benefits of InstructEngine's all\ncomponents. A win rate of over 50% in human reviews also proves that\nInstructEngine better aligns with human preferences.", "published": "2025-04-14 15:36:28", "link": "http://arxiv.org/abs/2504.10329v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SlowFastVAD: Video Anomaly Detection via Integrating Simple Detector and RAG-Enhanced Vision-Language Model", "abstract": "Video anomaly detection (VAD) aims to identify unexpected events in videos\nand has wide applications in safety-critical domains. While semi-supervised\nmethods trained on only normal samples have gained traction, they often suffer\nfrom high false alarm rates and poor interpretability. Recently,\nvision-language models (VLMs) have demonstrated strong multimodal reasoning\ncapabilities, offering new opportunities for explainable anomaly detection.\nHowever, their high computational cost and lack of domain adaptation hinder\nreal-time deployment and reliability. Inspired by dual complementary pathways\nin human visual perception, we propose SlowFastVAD, a hybrid framework that\nintegrates a fast anomaly detector with a slow anomaly detector (namely a\nretrieval augmented generation (RAG) enhanced VLM), to address these\nlimitations. Specifically, the fast detector first provides coarse anomaly\nconfidence scores, and only a small subset of ambiguous segments, rather than\nthe entire video, is further analyzed by the slower yet more interpretable VLM\nfor elaborate detection and reasoning. Furthermore, to adapt VLMs to\ndomain-specific VAD scenarios, we construct a knowledge base including normal\npatterns based on few normal samples and abnormal patterns inferred by VLMs.\nDuring inference, relevant patterns are retrieved and used to augment prompts\nfor anomaly reasoning. Finally, we smoothly fuse the anomaly confidence of fast\nand slow detectors to enhance robustness of anomaly detection. Extensive\nexperiments on four benchmarks demonstrate that SlowFastVAD effectively\ncombines the strengths of both fast and slow detectors, and achieves remarkable\ndetection accuracy and interpretability with significantly reduced\ncomputational overhead, making it well-suited for real-world VAD applications\nwith high reliability requirements.", "published": "2025-04-14 15:30:03", "link": "http://arxiv.org/abs/2504.10320v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Analysis of Attention in Video Diffusion Transformers", "abstract": "We conduct an in-depth analysis of attention in video diffusion transformers\n(VDiTs) and report a number of novel findings. We identify three key properties\nof attention in VDiTs: Structure, Sparsity, and Sinks. Structure: We observe\nthat attention patterns across different VDiTs exhibit similar structure across\ndifferent prompts, and that we can make use of the similarity of attention\npatterns to unlock video editing via self-attention map transfer. Sparse: We\nstudy attention sparsity in VDiTs, finding that proposed sparsity methods do\nnot work for all VDiTs, because some layers that are seemingly sparse cannot be\nsparsified. Sinks: We make the first study of attention sinks in VDiTs,\ncomparing and contrasting them to attention sinks in language models. We\npropose a number of future directions that can make use of our insights to\nimprove the efficiency-quality Pareto frontier for VDiTs.", "published": "2025-04-14 15:25:37", "link": "http://arxiv.org/abs/2504.10317v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ESCT3D: Efficient and Selectively Controllable Text-Driven 3D Content Generation with Gaussian Splatting", "abstract": "In recent years, significant advancements have been made in text-driven 3D\ncontent generation. However, several challenges remain. In practical\napplications, users often provide extremely simple text inputs while expecting\nhigh-quality 3D content. Generating optimal results from such minimal text is a\ndifficult task due to the strong dependency of text-to-3D models on the quality\nof input prompts. Moreover, the generation process exhibits high variability,\nmaking it difficult to control. Consequently, multiple iterations are typically\nrequired to produce content that meets user expectations, reducing generation\nefficiency. To address this issue, we propose GPT-4V for self-optimization,\nwhich significantly enhances the efficiency of generating satisfactory content\nin a single attempt. Furthermore, the controllability of text-to-3D generation\nmethods has not been fully explored. Our approach enables users to not only\nprovide textual descriptions but also specify additional conditions, such as\nstyle, edges, scribbles, poses, or combinations of multiple conditions,\nallowing for more precise control over the generated 3D content. Additionally,\nduring training, we effectively integrate multi-view information, including\nmulti-view depth, masks, features, and images, to address the common Janus\nproblem in 3D content generation. Extensive experiments demonstrate that our\nmethod achieves robust generalization, facilitating the efficient and\ncontrollable generation of high-quality 3D content.", "published": "2025-04-14 15:25:21", "link": "http://arxiv.org/abs/2504.10316v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Noise2Ghost: Self-supervised deep convolutional reconstruction for ghost imaging", "abstract": "We present a new self-supervised deep-learning-based Ghost Imaging (GI)\nreconstruction method, which provides unparalleled reconstruction performance\nfor noisy acquisitions among unsupervised methods. We present the supporting\nmathematical framework and results from theoretical and real data use cases.\nSelf-supervision removes the need for clean reference data while offering\nstrong noise reduction. This provides the necessary tools for addressing\nsignal-to-noise ratio concerns for GI acquisitions in emerging and cutting-edge\nlow-light GI scenarios. Notable examples include micro- and nano-scale x-ray\nemission imaging, e.g., x-ray fluorescence imaging of dose-sensitive samples.\nTheir applications include in-vivo and in-operando case studies for biological\nsamples and batteries.", "published": "2025-04-14 14:58:19", "link": "http://arxiv.org/abs/2504.10288v1", "categories": ["cs.CV", "cs.LG", "physics.data-an"], "primary_category": "cs.CV"}
{"title": "DiffMOD: Progressive Diffusion Point Denoising for Moving Object Detection in Remote Sensing", "abstract": "Moving object detection (MOD) in remote sensing is significantly challenged\nby low resolution, extremely small object sizes, and complex noise\ninterference. Current deep learning-based MOD methods rely on probability\ndensity estimation, which restricts flexible information interaction between\nobjects and across temporal frames. To flexibly capture high-order inter-object\nand temporal relationships, we propose a point-based MOD in remote sensing.\nInspired by diffusion models, the network optimization is formulated as a\nprogressive denoising process that iteratively recovers moving object centers\nfrom sparse noisy points. Specifically, we sample scattered features from the\nbackbone outputs as atomic units for subsequent processing, while global\nfeature embeddings are aggregated to compensate for the limited coverage of\nsparse point features. By modeling spatial relative positions and semantic\naffinities, Spatial Relation Aggregation Attention is designed to enable\nhigh-order interactions among point-level features for enhanced object\nrepresentation. To enhance temporal consistency, the Temporal Propagation and\nGlobal Fusion module is designed, which leverages an implicit memory reasoning\nmechanism for robust cross-frame feature integration. To align with the\nprogressive denoising process, we propose a progressive MinK optimal transport\nassignment strategy that establishes specialized learning objectives at each\ndenoising level. Additionally, we introduce a missing loss function to\ncounteract the clustering tendency of denoised points around salient objects.\nExperiments on the RsData remote sensing MOD dataset show that our MOD method\nbased on scattered point denoising can more effectively explore potential\nrelationships between sparse moving objects and improve the detection\ncapability and temporal consistency.", "published": "2025-04-14 14:44:52", "link": "http://arxiv.org/abs/2504.10278v1", "categories": ["cs.CV", "68T10", "I.4.8"], "primary_category": "cs.CV"}
{"title": "LMFormer: Lane based Motion Prediction Transformer", "abstract": "Motion prediction plays an important role in autonomous driving. This study\npresents LMFormer, a lane-aware transformer network for trajectory prediction\ntasks. In contrast to previous studies, our work provides a simple mechanism to\ndynamically prioritize the lanes and shows that such a mechanism introduces\nexplainability into the learning behavior of the network. Additionally,\nLMFormer uses the lane connection information at intersections, lane merges,\nand lane splits, in order to learn long-range dependency in lane structure.\nMoreover, we also address the issue of refining the predicted trajectories and\npropose an efficient method for iterative refinement through stacked\ntransformer layers. For benchmarking, we evaluate LMFormer on the nuScenes\ndataset and demonstrate that it achieves SOTA performance across multiple\nmetrics. Furthermore, the Deep Scenario dataset is used to not only illustrate\ncross-dataset network performance but also the unification capabilities of\nLMFormer to train on multiple datasets and achieve better performance.", "published": "2025-04-14 14:43:46", "link": "http://arxiv.org/abs/2504.10275v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Trade-offs in Privacy-Preserving Eye Tracking through Iris Obfuscation: A Benchmarking Study", "abstract": "Recent developments in hardware, computer graphics, and AI may soon enable\nAR/VR head-mounted displays (HMDs) to become everyday devices like smartphones\nand tablets. Eye trackers within HMDs provide a special opportunity for such\nsetups as it is possible to facilitate gaze-based research and interaction.\nHowever, estimating users' gaze information often requires raw eye images and\nvideos that contain iris textures, which are considered a gold standard\nbiometric for user authentication, and this raises privacy concerns. Previous\nresearch in the eye-tracking community focused on obfuscating iris textures\nwhile keeping utility tasks such as gaze estimation accurate. Despite these\nattempts, there is no comprehensive benchmark that evaluates state-of-the-art\napproaches. Considering all, in this paper, we benchmark blurring, noising,\ndownsampling, rubber sheet model, and iris style transfer to obfuscate user\nidentity, and compare their impact on image quality, privacy, utility, and risk\nof imposter attack on two datasets. We use eye segmentation and gaze estimation\nas utility tasks, and reduction in iris recognition accuracy as a measure of\nprivacy protection, and false acceptance rate to estimate risk of attack. Our\nexperiments show that canonical image processing methods like blurring and\nnoising cause a marginal impact on deep learning-based tasks. While\ndownsampling, rubber sheet model, and iris style transfer are effective in\nhiding user identifiers, iris style transfer, with higher computation cost,\noutperforms others in both utility tasks, and is more resilient against spoof\nattacks. Our analyses indicate that there is no universal optimal approach to\nbalance privacy, utility, and computation burden. Therefore, we recommend\npractitioners consider the strengths and weaknesses of each approach, and\npossible combinations of those to reach an optimal privacy-utility trade-off.", "published": "2025-04-14 14:29:38", "link": "http://arxiv.org/abs/2504.10267v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "XY-Cut++: Advanced Layout Ordering via Hierarchical Mask Mechanism on a Novel Benchmark", "abstract": "Document Reading Order Recovery is a fundamental task in document image\nunderstanding, playing a pivotal role in enhancing Retrieval-Augmented\nGeneration (RAG) and serving as a critical preprocessing step for large\nlanguage models (LLMs). Existing methods often struggle with complex\nlayouts(e.g., multi-column newspapers), high-overhead interactions between\ncross-modal elements (visual regions and textual semantics), and a lack of\nrobust evaluation benchmarks. We introduce XY-Cut++, an advanced layout\nordering method that integrates pre-mask processing, multi-granularity\nsegmentation, and cross-modal matching to address these challenges. Our method\nsignificantly enhances layout ordering accuracy compared to traditional XY-Cut\ntechniques. Specifically, XY-Cut++ achieves state-of-the-art performance (98.8\nBLEU overall) while maintaining simplicity and efficiency. It outperforms\nexisting baselines by up to 24\\% and demonstrates consistent accuracy across\nsimple and complex layouts on the newly introduced DocBench-100 dataset. This\nadvancement establishes a reliable foundation for document structure recovery,\nsetting a new standard for layout ordering tasks and facilitating more\neffective RAG and LLM preprocessing.", "published": "2025-04-14 14:19:57", "link": "http://arxiv.org/abs/2504.10258v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Towards contrast- and pathology-agnostic clinical fetal brain MRI segmentation using SynthSeg", "abstract": "Magnetic resonance imaging (MRI) has played a crucial role in fetal\nneurodevelopmental research. Structural annotations of MR images are an\nimportant step for quantitative analysis of the developing human brain, with\nDeep learning providing an automated alternative for this otherwise tedious\nmanual process. However, segmentation performances of Convolutional Neural\nNetworks often suffer from domain shift, where the network fails when applied\nto subjects that deviate from the distribution with which it is trained on. In\nthis work, we aim to train networks capable of automatically segmenting fetal\nbrain MRIs with a wide range of domain shifts pertaining to differences in\nsubject physiology and acquisition environments, in particular shape-based\ndifferences commonly observed in pathological cases. We introduce a novel\ndata-driven train-time sampling strategy that seeks to fully exploit the\ndiversity of a given training dataset to enhance the domain generalizability of\nthe trained networks. We adapted our sampler, together with other existing data\naugmentation techniques, to the SynthSeg framework, a generator that utilizes\ndomain randomization to generate diverse training data, and ran thorough\nexperimentations and ablation studies on a wide range of training/testing data\nto test the validity of the approaches. Our networks achieved notable\nimprovements in the segmentation quality on testing subjects with intense\nanatomical abnormalities (p < 1e-4), though at the cost of a slighter decrease\nin performance in cases with fewer abnormalities. Our work also lays the\nfoundation for future works on creating and adapting data-driven sampling\nstrategies for other training pipelines.", "published": "2025-04-14 14:08:26", "link": "http://arxiv.org/abs/2504.10244v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "CAT: A Conditional Adaptation Tailor for Efficient and Effective Instance-Specific Pansharpening on Real-World Data", "abstract": "Pansharpening is a crucial remote sensing technique that fuses low-resolution\nmultispectral (LRMS) images with high-resolution panchromatic (PAN) images to\ngenerate high-resolution multispectral (HRMS) imagery. Although deep learning\ntechniques have significantly advanced pansharpening, many existing methods\nsuffer from limited cross-sensor generalization and high computational\noverhead, restricting their real-time applications. To address these\nchallenges, we propose an efficient framework that quickly adapts to a specific\ninput instance, completing both training and inference in a short time. Our\nframework splits the input image into multiple patches, selects a subset for\nunsupervised CAT training, and then performs inference on all patches,\nstitching them into the final output. The CAT module, integrated between the\nfeature extraction and channel transformation stages of a pre-trained network,\ntailors the fused features and fixes the parameters for efficient inference,\ngenerating improved results. Our approach offers two key advantages: (1)\n$\\textit{Improved Generalization Ability}$: by mitigating cross-sensor\ndegradation, our model--although pre-trained on a specific dataset--achieves\nsuperior performance on datasets captured by other sensors; (2)\n$\\textit{Enhanced Computational Efficiency}$: the CAT-enhanced network can\nswiftly adapt to the test sample using the single LRMS-PAN pair input, without\nrequiring extensive large-scale data retraining. Experiments on the real-world\ndata from WorldView-3 and WorldView-2 datasets demonstrate that our method\nachieves state-of-the-art performance on cross-sensor real-world data, while\nachieving both training and inference of $512\\times512$ image within\n$\\textit{0.4 seconds}$ and $4000\\times4000$ image within $\\textit{3 seconds}$\nat the fastest setting on a commonly used RTX 3090 GPU.", "published": "2025-04-14 14:04:55", "link": "http://arxiv.org/abs/2504.10242v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Balancing Stability and Plasticity in Pretrained Detector: A Dual-Path Framework for Incremental Object Detection", "abstract": "The balance between stability and plasticity remains a fundamental challenge\nin pretrained model-based incremental object detection (PTMIOD). While existing\nPTMIOD methods demonstrate strong performance on in-domain tasks aligned with\npretraining data, their plasticity to cross-domain scenarios remains\nunderexplored. Through systematic component-wise analysis of pretrained\ndetectors, we reveal a fundamental discrepancy: the localization modules\ndemonstrate inherent cross-domain stability-preserving precise bounding box\nestimation across distribution shifts-while the classification components\nrequire enhanced plasticity to mitigate discriminability degradation in\ncross-domain scenarios. Motivated by these findings, we propose a dual-path\nframework built upon pretrained DETR-based detectors which decouples\nlocalization stability and classification plasticity: the localization path\nmaintains stability to preserve pretrained localization knowledge, while the\nclassification path facilitates plasticity via parameter-efficient fine-tuning\nand resists forgetting with pseudo-feature replay. Extensive evaluations on\nboth in-domain (MS COCO and PASCAL VOC) and cross-domain (TT100K) benchmarks\nshow state-of-the-art performance, demonstrating our method's ability to\neffectively balance stability and plasticity in PTMIOD, achieving robust\ncross-domain adaptation and strong retention of anti-forgetting capabilities.", "published": "2025-04-14 13:31:35", "link": "http://arxiv.org/abs/2504.10214v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VibrantLeaves: A principled parametric image generator for training deep restoration models", "abstract": "Even though Deep Neural Networks are extremely powerful for image restoration\ntasks, they have several limitations. They are poorly understood and suffer\nfrom strong biases inherited from the training sets. One way to address these\nshortcomings is to have a better control over the training sets, in particular\nby using synthetic sets. In this paper, we propose a synthetic image generator\nrelying on a few simple principles. In particular, we focus on geometric\nmodeling, textures, and a simple modeling of image acquisition. These\nproperties, integrated in a classical Dead Leaves model, enable the creation of\nefficient training sets. Standard image denoising and super-resolution networks\ncan be trained on such datasets, reaching performance almost on par with\ntraining on natural image datasets. As a first step towards explainability, we\nprovide a careful analysis of the considered principles, identifying which\nimage properties are necessary to obtain good performances. Besides, such\ntraining also yields better robustness to various geometric and radiometric\nperturbations of the test sets.", "published": "2025-04-14 13:09:49", "link": "http://arxiv.org/abs/2504.10201v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Differentially Private 2D Human Pose Estimation", "abstract": "Human pose estimation (HPE) has become essential in numerous applications\nincluding healthcare, activity recognition, and human-computer interaction.\nHowever, the privacy implications of processing sensitive visual data present\nsignificant deployment barriers in critical domains. While traditional\nanonymization techniques offer limited protection and often compromise data\nutility for broader motion analysis, Differential Privacy (DP) provides formal\nprivacy guarantees but typically degrades model performance when applied\nnaively. In this work, we present the first differentially private 2D human\npose estimation (2D-HPE) by applying Differentially Private Stochastic Gradient\nDescent (DP-SGD) to this task. To effectively balance privacy with performance,\nwe adopt Projected DP-SGD (PDP-SGD), which projects the noisy gradients to a\nlow-dimensional subspace. Additionally, we adapt TinyViT, a compact and\nefficient vision transformer for coordinate classification in HPE, providing a\nlightweight yet powerful backbone that enhances privacy-preserving deployment\nfeasibility on resource-limited devices. Our approach is particularly valuable\nfor multimedia interpretation tasks, enabling privacy-safe analysis and\nunderstanding of human motion across diverse visual media while preserving the\nsemantic meaning required for downstream applications. Comprehensive\nexperiments on the MPII Human Pose Dataset demonstrate significant performance\nenhancement with PDP-SGD achieving 78.48% PCKh@0.5 at a strict privacy budget\n($\\epsilon=0.2$), compared to 63.85% for standard DP-SGD. This work lays\nfoundation for privacy-preserving human pose estimation in real-world,\nsensitive applications.", "published": "2025-04-14 12:50:37", "link": "http://arxiv.org/abs/2504.10190v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LLaVA-ReID: Selective Multi-image Questioner for Interactive Person Re-Identification", "abstract": "Traditional text-based person ReID assumes that person descriptions from\nwitnesses are complete and provided at once. However, in real-world scenarios,\nsuch descriptions are often partial or vague. To address this limitation, we\nintroduce a new task called interactive person re-identification (Inter-ReID).\nInter-ReID is a dialogue-based retrieval task that iteratively refines initial\ndescriptions through ongoing interactions with the witnesses. To facilitate the\nstudy of this new task, we construct a dialogue dataset that incorporates\nmultiple types of questions by decomposing fine-grained attributes of\nindividuals. We further propose LLaVA-ReID, a question model that generates\ntargeted questions based on visual and textual contexts to elicit additional\ndetails about the target person. Leveraging a looking-forward strategy, we\nprioritize the most informative questions as supervision during training.\nExperimental results on both Inter-ReID and text-based ReID benchmarks\ndemonstrate that LLaVA-ReID significantly outperforms baselines.", "published": "2025-04-14 12:26:31", "link": "http://arxiv.org/abs/2504.10174v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hierarchical and Step-Layer-Wise Tuning of Attention Specialty for Multi-Instance Synthesis in Diffusion Transformers", "abstract": "Text-to-image (T2I) generation models often struggle with multi-instance\nsynthesis (MIS), where they must accurately depict multiple distinct instances\nin a single image based on complex prompts detailing individual features.\nTraditional MIS control methods for UNet architectures like SD v1.5/SDXL fail\nto adapt to DiT-based models like FLUX and SD v3.5, which rely on integrated\nattention between image and text tokens rather than text-image cross-attention.\nTo enhance MIS in DiT, we first analyze the mixed attention mechanism in DiT.\nOur token-wise and layer-wise analysis of attention maps reveals a hierarchical\nresponse structure: instance tokens dominate early layers, background tokens in\nmiddle layers, and attribute tokens in later layers. Building on this\nobservation, we propose a training-free approach for enhancing MIS in DiT-based\nmodels with hierarchical and step-layer-wise attention specialty tuning (AST).\nAST amplifies key regions while suppressing irrelevant areas in distinct\nattention maps across layers and steps, guided by the hierarchical structure.\nThis optimizes multimodal interactions by hierarchically decoupling the complex\nprompts with instance-based sketches. We evaluate our approach using upgraded\nsketch-based layouts for the T2I-CompBench and customized complex scenes. Both\nquantitative and qualitative results confirm our method enhances complex layout\ngeneration, ensuring precise instance placement and attribute representation in\nMIS.", "published": "2025-04-14 11:59:58", "link": "http://arxiv.org/abs/2504.10148v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Negate or Embrace: On How Misalignment Shapes Multimodal Representation Learning", "abstract": "Multimodal representation learning, exemplified by multimodal contrastive\nlearning (MMCL) using image-text pairs, aims to learn powerful representations\nby aligning cues across modalities. This approach relies on the core assumption\nthat the exemplar image-text pairs constitute two representations of an\nidentical concept. However, recent research has revealed that real-world\ndatasets often exhibit misalignment. There are two distinct viewpoints on how\nto address this issue: one suggests mitigating the misalignment, and the other\nleveraging it. We seek here to reconcile these seemingly opposing perspectives,\nand to provide a practical guide for practitioners. Using latent variable\nmodels we thus formalize misalignment by introducing two specific mechanisms:\nselection bias, where some semantic variables are missing, and perturbation\nbias, where semantic variables are distorted -- both affecting latent variables\nshared across modalities. Our theoretical analysis demonstrates that, under\nmild assumptions, the representations learned by MMCL capture exactly the\ninformation related to the subset of the semantic variables invariant to\nselection and perturbation biases. This provides a unified perspective for\nunderstanding misalignment. Based on this, we further offer actionable insights\ninto how misalignment should inform the design of real-world ML systems. We\nvalidate our theoretical findings through extensive empirical studies on both\nsynthetic data and real image-text datasets, shedding light on the nuanced\nimpact of misalignment on multimodal representation learning.", "published": "2025-04-14 11:54:19", "link": "http://arxiv.org/abs/2504.10143v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "M2S-RoAD: Multi-Modal Semantic Segmentation for Road Damage Using Camera and LiDAR Data", "abstract": "Road damage can create safety and comfort challenges for both human drivers\nand autonomous vehicles (AVs). This damage is particularly prevalent in rural\nareas due to less frequent surveying and maintenance of roads. Automated\ndetection of pavement deterioration can be used as an input to AVs and driver\nassistance systems to improve road safety. Current research in this field has\npredominantly focused on urban environments driven largely by public datasets,\nwhile rural areas have received significantly less attention. This paper\nintroduces M2S-RoAD, a dataset for the semantic segmentation of different\nclasses of road damage. M2S-RoAD was collected in various towns across New\nSouth Wales, Australia, and labelled for semantic segmentation to identify nine\ndistinct types of road damage. This dataset will be released upon the\nacceptance of the paper.", "published": "2025-04-14 11:32:01", "link": "http://arxiv.org/abs/2504.10123v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AGO: Adaptive Grounding for Open World 3D Occupancy Prediction", "abstract": "Open-world 3D semantic occupancy prediction aims to generate a voxelized 3D\nrepresentation from sensor inputs while recognizing both known and unknown\nobjects. Transferring open-vocabulary knowledge from vision-language models\n(VLMs) offers a promising direction but remains challenging. However, methods\nbased on VLM-derived 2D pseudo-labels with traditional supervision are limited\nby a predefined label space and lack general prediction capabilities. Direct\nalignment with pretrained image embeddings, on the other hand, fails to achieve\nreliable performance due to often inconsistent image and text representations\nin VLMs. To address these challenges, we propose AGO, a novel 3D occupancy\nprediction framework with adaptive grounding to handle diverse open-world\nscenarios. AGO first encodes surrounding images and class prompts into 3D and\ntext embeddings, respectively, leveraging similarity-based grounding training\nwith 3D pseudo-labels. Additionally, a modality adapter maps 3D embeddings into\na space aligned with VLM-derived image embeddings, reducing modality gaps.\nExperiments on Occ3D-nuScenes show that AGO improves unknown object prediction\nin zero-shot and few-shot transfer while achieving state-of-the-art\nclosed-world self-supervised performance, surpassing prior methods by 4.09\nmIoU.", "published": "2025-04-14 11:26:20", "link": "http://arxiv.org/abs/2504.10117v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Global and Local Mamba Network for Multi-Modality Medical Image Super-Resolution", "abstract": "Convolutional neural networks and Transformer have made significant\nprogresses in multi-modality medical image super-resolution. However, these\nmethods either have a fixed receptive field for local learning or significant\ncomputational burdens for global learning, limiting the super-resolution\nperformance. To solve this problem, State Space Models, notably Mamba, is\nintroduced to efficiently model long-range dependencies in images with linear\ncomputational complexity. Relying on the Mamba and the fact that low-resolution\nimages rely on global information to compensate for missing details, while\nhigh-resolution reference images need to provide more local details for\naccurate super-resolution, we propose a global and local Mamba network\n(GLMamba) for multi-modality medical image super-resolution. To be specific,\nour GLMamba is a two-branch network equipped with a global Mamba branch and a\nlocal Mamba branch. The global Mamba branch captures long-range relationships\nin low-resolution inputs, and the local Mamba branch focuses more on\nshort-range details in high-resolution reference images. We also use the deform\nblock to adaptively extract features of both branches to enhance the\nrepresentation ability. A modulator is designed to further enhance deformable\nfeatures in both global and local Mamba blocks. To fully integrate the\nreference image for low-resolution image super-resolution, we further develop a\nmulti-modality feature fusion block to adaptively fuse features by considering\nsimilarities, differences, and complementary aspects between modalities. In\naddition, a contrastive edge loss (CELoss) is developed for sufficient\nenhancement of edge textures and contrast in medical images.", "published": "2025-04-14 11:14:24", "link": "http://arxiv.org/abs/2504.10105v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "UP-Person: Unified Parameter-Efficient Transfer Learning for Text-based Person Retrieval", "abstract": "Text-based Person Retrieval (TPR) as a multi-modal task, which aims to\nretrieve the target person from a pool of candidate images given a text\ndescription, has recently garnered considerable attention due to the progress\nof contrastive visual-language pre-trained model. Prior works leverage\npre-trained CLIP to extract person visual and textual features and fully\nfine-tune the entire network, which have shown notable performance improvements\ncompared to uni-modal pre-training models. However, full-tuning a large model\nis prone to overfitting and hinders the generalization ability. In this paper,\nwe propose a novel Unified Parameter-Efficient Transfer Learning (PETL) method\nfor Text-based Person Retrieval (UP-Person) to thoroughly transfer the\nmulti-modal knowledge from CLIP. Specifically, UP-Person simultaneously\nintegrates three lightweight PETL components including Prefix, LoRA and\nAdapter, where Prefix and LoRA are devised together to mine local information\nwith task-specific information prompts, and Adapter is designed to adjust\nglobal feature representations. Additionally, two vanilla submodules are\noptimized to adapt to the unified architecture of TPR. For one thing, S-Prefix\nis proposed to boost attention of prefix and enhance the gradient propagation\nof prefix tokens, which improves the flexibility and performance of the vanilla\nprefix. For another thing, L-Adapter is designed in parallel with layer\nnormalization to adjust the overall distribution, which can resolve conflicts\ncaused by overlap and interaction among multiple submodules. Extensive\nexperimental results demonstrate that our UP-Person achieves state-of-the-art\nresults across various person retrieval datasets, including CUHK-PEDES,\nICFG-PEDES and RSTPReid while merely fine-tuning 4.7\\% parameters. Code is\navailable at https://github.com/Liu-Yating/UP-Person.", "published": "2025-04-14 10:40:54", "link": "http://arxiv.org/abs/2504.10084v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning to Harmonize Cross-vendor X-ray Images by Non-linear Image Dynamics Correction", "abstract": "In this paper, we explore how conventional image enhancement can improve\nmodel robustness in medical image analysis. By applying commonly used\nnormalization methods to images from various vendors and studying their\ninfluence on model generalization in transfer learning, we show that the\nnonlinear characteristics of domain-specific image dynamics cannot be addressed\nby simple linear transforms. To tackle this issue, we reformulate the image\nharmonization task as an exposure correction problem and propose a method\ntermed Global Deep Curve Estimation (GDCE) to reduce domain-specific exposure\nmismatch. GDCE performs enhancement via a pre-defined polynomial function and\nis trained with the help of a ``domain discriminator'', aiming to improve model\ntransparency in downstream tasks compared to existing black-box methods.", "published": "2025-04-14 10:24:57", "link": "http://arxiv.org/abs/2504.10080v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Hierarchical Relation-augmented Representation Generalization for Few-shot Action Recognition", "abstract": "Few-shot action recognition (FSAR) aims to recognize novel action categories\nwith few exemplars. Existing methods typically learn frame-level\nrepresentations independently for each video by designing various inter-frame\ntemporal modeling strategies. However, they neglect explicit relation modeling\nbetween videos and tasks, thus failing to capture shared temporal patterns\nacross videos and reuse temporal knowledge from historical tasks. In light of\nthis, we propose HR2G-shot, a Hierarchical Relation-augmented Representation\nGeneralization framework for FSAR, which unifies three types of relation\nmodeling (inter-frame, inter-video, and inter-task) to learn task-specific\ntemporal patterns from a holistic view. In addition to conducting inter-frame\ntemporal interactions, we further devise two components to respectively explore\ninter-video and inter-task relationships: i) Inter-video Semantic Correlation\n(ISC) performs cross-video frame-level interactions in a fine-grained manner,\nthereby capturing task-specific query features and learning intra- and\ninter-class temporal correlations among support features; ii) Inter-task\nKnowledge Transfer (IKT) retrieves and aggregates relevant temporal knowledge\nfrom the bank, which stores diverse temporal patterns from historical tasks.\nExtensive experiments on five benchmarks show that HR2G-shot outperforms\ncurrent top-leading FSAR methods.", "published": "2025-04-14 10:23:22", "link": "http://arxiv.org/abs/2504.10079v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DTFSal: Audio-Visual Dynamic Token Fusion for Video Saliency Prediction", "abstract": "Audio-visual saliency prediction aims to mimic human visual attention by\nidentifying salient regions in videos through the integration of both visual\nand auditory information. Although visual-only approaches have significantly\nadvanced, effectively incorporating auditory cues remains challenging due to\ncomplex spatio-temporal interactions and high computational demands. To address\nthese challenges, we propose Dynamic Token Fusion Saliency (DFTSal), a novel\naudio-visual saliency prediction framework designed to balance accuracy with\ncomputational efficiency. Our approach features a multi-scale visual encoder\nequipped with two novel modules: the Learnable Token Enhancement Block (LTEB),\nwhich adaptively weights tokens to emphasize crucial saliency cues, and the\nDynamic Learnable Token Fusion Block (DLTFB), which employs a shifting\noperation to reorganize and merge features, effectively capturing long-range\ndependencies and detailed spatial information. In parallel, an audio branch\nprocesses raw audio signals to extract meaningful auditory features. Both\nvisual and audio features are integrated using our Adaptive Multimodal Fusion\nBlock (AMFB), which employs local, global, and adaptive fusion streams for\nprecise cross-modal fusion. The resulting fused features are processed by a\nhierarchical multi-decoder structure, producing accurate saliency maps.\nExtensive evaluations on six audio-visual benchmarks demonstrate that DFTSal\nachieves SOTA performance while maintaining computational efficiency.", "published": "2025-04-14 10:17:25", "link": "http://arxiv.org/abs/2504.10070v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multi-Object Grounding via Hierarchical Contrastive Siamese Transformers", "abstract": "Multi-object grounding in 3D scenes involves localizing multiple objects\nbased on natural language input. While previous work has primarily focused on\nsingle-object grounding, real-world scenarios often demand the localization of\nseveral objects. To tackle this challenge, we propose Hierarchical Contrastive\nSiamese Transformers (H-COST), which employs a Hierarchical Processing strategy\nto progressively refine object localization, enhancing the understanding of\ncomplex language instructions. Additionally, we introduce a Contrastive Siamese\nTransformer framework, where two networks with the identical structure are\nused: one auxiliary network processes robust object relations from ground-truth\nlabels to guide and enhance the second network, the reference network, which\noperates on segmented point-cloud data. This contrastive mechanism strengthens\nthe model' s semantic understanding and significantly enhances its ability to\nprocess complex point-cloud data. Our approach outperforms previous\nstate-of-the-art methods by 9.5% on challenging multi-object grounding\nbenchmarks.", "published": "2025-04-14 09:53:48", "link": "http://arxiv.org/abs/2504.10048v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Aligning Anime Video Generation with Human Feedback", "abstract": "Anime video generation faces significant challenges due to the scarcity of\nanime data and unusual motion patterns, leading to issues such as motion\ndistortion and flickering artifacts, which result in misalignment with human\npreferences. Existing reward models, designed primarily for real-world videos,\nfail to capture the unique appearance and consistency requirements of anime. In\nthis work, we propose a pipeline to enhance anime video generation by\nleveraging human feedback for better alignment. Specifically, we construct the\nfirst multi-dimensional reward dataset for anime videos, comprising 30k\nhuman-annotated samples that incorporating human preferences for both visual\nappearance and visual consistency. Based on this, we develop AnimeReward, a\npowerful reward model that employs specialized vision-language models for\ndifferent evaluation dimensions to guide preference alignment. Furthermore, we\nintroduce Gap-Aware Preference Optimization (GAPO), a novel training method\nthat explicitly incorporates preference gaps into the optimization process,\nenhancing alignment performance and efficiency. Extensive experiment results\nshow that AnimeReward outperforms existing reward models, and the inclusion of\nGAPO leads to superior alignment in both quantitative benchmarks and human\nevaluations, demonstrating the effectiveness of our pipeline in enhancing anime\nvideo quality. Our dataset and code will be publicly available.", "published": "2025-04-14 09:49:34", "link": "http://arxiv.org/abs/2504.10044v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Prior Does Matter: Visual Navigation via Denoising Diffusion Bridge Models", "abstract": "Recent advancements in diffusion-based imitation learning, which show\nimpressive performance in modeling multimodal distributions and training\nstability, have led to substantial progress in various robot learning tasks. In\nvisual navigation, previous diffusion-based policies typically generate action\nsequences by initiating from denoising Gaussian noise. However, the target\naction distribution often diverges significantly from Gaussian noise, leading\nto redundant denoising steps and increased learning complexity. Additionally,\nthe sparsity of effective action distributions makes it challenging for the\npolicy to generate accurate actions without guidance. To address these issues,\nwe propose a novel, unified visual navigation framework leveraging the\ndenoising diffusion bridge models named NaviBridger. This approach enables\naction generation by initiating from any informative prior actions, enhancing\nguidance and efficiency in the denoising process. We explore how diffusion\nbridges can enhance imitation learning in visual navigation tasks and further\nexamine three source policies for generating prior actions. Extensive\nexperiments in both simulated and real-world indoor and outdoor scenarios\ndemonstrate that NaviBridger accelerates policy inference and outperforms the\nbaselines in generating target action sequences. Code is available at\nhttps://github.com/hren20/NaiviBridger.", "published": "2025-04-14 09:42:35", "link": "http://arxiv.org/abs/2504.10041v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Investigating the Role of Bilateral Symmetry for Inpainting Brain MRI", "abstract": "Inpainting has recently emerged as a valuable and interesting technology to\nemploy in the analysis of medical imaging data, in particular brain MRI. A wide\nvariety of methodologies for inpainting MRI have been proposed and demonstrated\non tasks including anomaly detection. In this work we investigate the\nstatistical relationship between inpainted brain structures and the amount of\nsubject-specific conditioning information, i.e. the other areas of the image\nthat are masked. In particular, we analyse the distribution of inpainting\nresults when masking additional regions of the image, specifically the\ncontra-lateral structure. This allows us to elucidate where in the brain the\nmodel is drawing information from, and in particular, what is the importance of\nhemispherical symmetry? Our experiments interrogate a diffusion inpainting\nmodel through analysing the inpainting of subcortical brain structures based on\nintensity and estimated area change. We demonstrate that some structures show a\nstrong influence of symmetry in the conditioning of the inpainting process.", "published": "2025-04-14 09:41:47", "link": "http://arxiv.org/abs/2504.10039v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "TT3D: Table Tennis 3D Reconstruction", "abstract": "Sports analysis requires processing large amounts of data, which is\ntime-consuming and costly. Advancements in neural networks have significantly\nalleviated this burden, enabling highly accurate ball tracking in sports\nbroadcasts. However, relying solely on 2D ball tracking is limiting, as it\ndepends on the camera's viewpoint and falls short of supporting comprehensive\ngame analysis. To address this limitation, we propose a novel approach for\nreconstructing precise 3D ball trajectories from online table tennis match\nrecordings. Our method leverages the underlying physics of the ball's motion to\nidentify the bounce state that minimizes the reprojection error of the ball's\nflying trajectory, hence ensuring an accurate and reliable 3D reconstruction. A\nkey advantage of our approach is its ability to infer ball spin without relying\non human pose estimation or racket tracking, which are often unreliable or\nunavailable in broadcast footage. We developed an automated camera calibration\nmethod capable of reliably tracking camera movements. Additionally, we adapted\nan existing 3D pose estimation model, which lacks depth motion capture, to\naccurately track player movements. Together, these contributions enable the\nfull 3D reconstruction of a table tennis rally.", "published": "2025-04-14 09:37:47", "link": "http://arxiv.org/abs/2504.10035v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Relative Illumination Fields: Learning Medium and Light Independent Underwater Scenes", "abstract": "We address the challenge of constructing a consistent and photorealistic\nNeural Radiance Field in inhomogeneously illuminated, scattering environments\nwith unknown, co-moving light sources. While most existing works on underwater\nscene representation focus on a static homogeneous illumination, limited\nattention has been paid to scenarios such as when a robot explores water deeper\nthan a few tens of meters, where sunlight becomes insufficient. To address\nthis, we propose a novel illumination field locally attached to the camera,\nenabling the capture of uneven lighting effects within the viewing frustum. We\ncombine this with a volumetric medium representation to an overall method that\neffectively handles interaction between dynamic illumination field and static\nscattering medium. Evaluation results demonstrate the effectiveness and\nflexibility of our approach.", "published": "2025-04-14 09:28:04", "link": "http://arxiv.org/abs/2504.10024v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Masked Autoencoder Self Pre-Training for Defect Detection in Microelectronics", "abstract": "Whereas in general computer vision, transformer-based architectures have\nquickly become the gold standard, microelectronics defect detection still\nheavily relies on convolutional neural networks (CNNs). We hypothesize that\nthis is due to the fact that a) transformers have an increased need for data\nand b) labelled image generation procedures for microelectronics are costly,\nand labelled data is therefore sparse. Whereas in other domains, pre-training\non large natural image datasets can mitigate this problem, in microelectronics\ntransfer learning is hindered due to the dissimilarity of domain data and\nnatural images. Therefore, we evaluate self pre-training, where models are\npre-trained on the target dataset, rather than another dataset. We propose a\nvision transformer (ViT) pre-training framework for defect detection in\nmicroelectronics based on masked autoencoders (MAE). In MAE, a large share of\nimage patches is masked and reconstructed by the model during pre-training. We\nperform pre-training and defect detection using a dataset of less than 10.000\nscanning acoustic microscopy (SAM) images labelled using transient thermal\nanalysis (TTA). Our experimental results show that our approach leads to\nsubstantial performance gains compared to a) supervised ViT, b) ViT pre-trained\non natural image datasets, and c) state-of-the-art CNN-based defect detection\nmodels used in the literature. Additionally, interpretability analysis reveals\nthat our self pre-trained models, in comparison to ViT baselines, correctly\nfocus on defect-relevant features such as cracks in the solder material. This\ndemonstrates that our approach yields fault-specific feature representations,\nmaking our self pre-trained models viable for real-world defect detection in\nmicroelectronics.", "published": "2025-04-14 09:25:50", "link": "http://arxiv.org/abs/2504.10021v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "EBAD-Gaussian: Event-driven Bundle Adjusted Deblur Gaussian Splatting", "abstract": "While 3D Gaussian Splatting (3D-GS) achieves photorealistic novel view\nsynthesis, its performance degrades with motion blur. In scenarios with rapid\nmotion or low-light conditions, existing RGB-based deblurring methods struggle\nto model camera pose and radiance changes during exposure, reducing\nreconstruction accuracy. Event cameras, capturing continuous brightness changes\nduring exposure, can effectively assist in modeling motion blur and improving\nreconstruction quality. Therefore, we propose Event-driven Bundle Adjusted\nDeblur Gaussian Splatting (EBAD-Gaussian), which reconstructs sharp 3D\nGaussians from event streams and severely blurred images. This method jointly\nlearns the parameters of these Gaussians while recovering camera motion\ntrajectories during exposure time. Specifically, we first construct a blur loss\nfunction by synthesizing multiple latent sharp images during the exposure time,\nminimizing the difference between real and synthesized blurred images. Then we\nuse event stream to supervise the light intensity changes between latent sharp\nimages at any time within the exposure period, supplementing the light\nintensity dynamic changes lost in RGB images. Furthermore, we optimize the\nlatent sharp images at intermediate exposure times based on the event-based\ndouble integral (EDI) prior, applying consistency constraints to enhance the\ndetails and texture information of the reconstructed images. Extensive\nexperiments on synthetic and real-world datasets show that EBAD-Gaussian can\nachieve high-quality 3D scene reconstruction under the condition of blurred\nimages and event stream inputs.", "published": "2025-04-14 09:17:00", "link": "http://arxiv.org/abs/2504.10012v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Balancing Two Classifiers via A Simplex ETF Structure for Model Calibration", "abstract": "In recent years, deep neural networks (DNNs) have demonstrated\nstate-of-the-art performance across various domains. However, despite their\nsuccess, they often face calibration issues, particularly in safety-critical\napplications such as autonomous driving and healthcare, where unreliable\npredictions can have serious consequences. Recent research has started to\nimprove model calibration from the view of the classifier. However, the\nexploration of designing the classifier to solve the model calibration problem\nis insufficient. Let alone most of the existing methods ignore the calibration\nerrors arising from underconfidence. In this work, we propose a novel method by\nbalancing learnable and ETF classifiers to solve the overconfidence or\nunderconfidence problem for model Calibration named BalCAL. By introducing a\nconfidence-tunable module and a dynamic adjustment method, we ensure better\nalignment between model confidence and its true accuracy. Extensive\nexperimental validation shows that ours significantly improves model\ncalibration performance while maintaining high predictive accuracy,\noutperforming existing techniques. This provides a novel solution to the\ncalibration challenges commonly encountered in deep learning.", "published": "2025-04-14 09:09:01", "link": "http://arxiv.org/abs/2504.10007v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "An Image is Worth $K$ Topics: A Visual Structural Topic Model with Pretrained Image Embeddings", "abstract": "Political scientists are increasingly interested in analyzing visual content\nat scale. However, the existing computational toolbox is still in need of\nmethods and models attuned to the specific challenges and goals of social and\npolitical inquiry. In this article, we introduce a visual Structural Topic\nModel (vSTM) that combines pretrained image embeddings with a structural topic\nmodel. This has important advantages compared to existing approaches. First,\npretrained embeddings allow the model to capture the semantic complexity of\nimages relevant to political contexts. Second, the structural topic model\nprovides the ability to analyze how topics and covariates are related, while\nmaintaining a nuanced representation of images as a mixture of multiple topics.\nIn our empirical application, we show that the vSTM is able to identify topics\nthat are interpretable, coherent, and substantively relevant to the study of\nonline political communication.", "published": "2025-04-14 09:07:11", "link": "http://arxiv.org/abs/2504.10004v1", "categories": ["cs.CV", "cs.CY", "stat.AP", "stat.ME"], "primary_category": "cs.CV"}
{"title": "NaviDiffusor: Cost-Guided Diffusion Model for Visual Navigation", "abstract": "Visual navigation, a fundamental challenge in mobile robotics, demands\nversatile policies to handle diverse environments. Classical methods leverage\ngeometric solutions to minimize specific costs, offering adaptability to new\nscenarios but are prone to system errors due to their multi-modular design and\nreliance on hand-crafted rules. Learning-based methods, while achieving high\nplanning success rates, face difficulties in generalizing to unseen\nenvironments beyond the training data and often require extensive training. To\naddress these limitations, we propose a hybrid approach that combines the\nstrengths of learning-based methods and classical approaches for RGB-only\nvisual navigation. Our method first trains a conditional diffusion model on\ndiverse path-RGB observation pairs. During inference, it integrates the\ngradients of differentiable scene-specific and task-level costs, guiding the\ndiffusion model to generate valid paths that meet the constraints. This\napproach alleviates the need for retraining, offering a plug-and-play solution.\nExtensive experiments in both indoor and outdoor settings, across simulated and\nreal-world scenarios, demonstrate zero-shot transfer capability of our\napproach, achieving higher success rates and fewer collisions compared to\nbaseline methods. Code will be released at\nhttps://github.com/SYSU-RoboticsLab/NaviD.", "published": "2025-04-14 09:06:02", "link": "http://arxiv.org/abs/2504.10003v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "GaussVideoDreamer: 3D Scene Generation with Video Diffusion and Inconsistency-Aware Gaussian Splatting", "abstract": "Single-image 3D scene reconstruction presents significant challenges due to\nits inherently ill-posed nature and limited input constraints. Recent advances\nhave explored two promising directions: multiview generative models that train\non 3D consistent datasets but struggle with out-of-distribution generalization,\nand 3D scene inpainting and completion frameworks that suffer from cross-view\ninconsistency and suboptimal error handling, as they depend exclusively on\ndepth data or 3D smoothness, which ultimately degrades output quality and\ncomputational performance. Building upon these approaches, we present\nGaussVideoDreamer, which advances generative multimedia approaches by bridging\nthe gap between image, video, and 3D generation, integrating their strengths\nthrough two key innovations: (1) A progressive video inpainting strategy that\nharnesses temporal coherence for improved multiview consistency and faster\nconvergence. (2) A 3D Gaussian Splatting consistency mask to guide the video\ndiffusion with 3D consistent multiview evidence. Our pipeline combines three\ncore components: a geometry-aware initialization protocol, Inconsistency-Aware\nGaussian Splatting, and a progressive video inpainting strategy. Experimental\nresults demonstrate that our approach achieves 32% higher LLaVA-IQA scores and\nat least 2x speedup compared to existing methods while maintaining robust\nperformance across diverse scenes.", "published": "2025-04-14 09:04:01", "link": "http://arxiv.org/abs/2504.10001v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Correlative and Discriminative Label Grouping for Multi-Label Visual Prompt Tuning", "abstract": "Modeling label correlations has always played a pivotal role in multi-label\nimage classification (MLC), attracting significant attention from researchers.\nHowever, recent studies have overemphasized co-occurrence relationships among\nlabels, which can lead to overfitting risk on this overemphasis, resulting in\nsuboptimal models. To tackle this problem, we advocate for balancing\ncorrelative and discriminative relationships among labels to mitigate the risk\nof overfitting and enhance model performance. To this end, we propose the\nMulti-Label Visual Prompt Tuning framework, a novel and parameter-efficient\nmethod that groups classes into multiple class subsets according to label\nco-occurrence and mutual exclusivity relationships, and then models them\nrespectively to balance the two relationships. In this work, since each group\ncontains multiple classes, multiple prompt tokens are adopted within Vision\nTransformer (ViT) to capture the correlation or discriminative label\nrelationship within each group, and effectively learn correlation or\ndiscriminative representations for class subsets. On the other hand, each group\ncontains multiple group-aware visual representations that may correspond to\nmultiple classes, and the mixture of experts (MoE) model can cleverly assign\nthem from the group-aware to the label-aware, adaptively obtaining label-aware\nrepresentation, which is more conducive to classification. Experiments on\nmultiple benchmark datasets show that our proposed approach achieves\ncompetitive results and outperforms SOTA methods on multiple pre-trained\nmodels.", "published": "2025-04-14 08:52:50", "link": "http://arxiv.org/abs/2504.09990v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Resampling Benchmark for Efficient Comprehensive Evaluation of Large Vision-Language Models", "abstract": "We propose an efficient evaluation protocol for large vision-language models\n(VLMs). Given their broad knowledge and reasoning capabilities, multiple\nbenchmarks are needed for comprehensive assessment, making evaluation\ncomputationally expensive. To improve efficiency, we construct a subset that\nyields results comparable to full benchmark evaluations. Our benchmark\nclassification experiments reveal that no single benchmark fully covers all\nchallenges. We then introduce a subset construction method using farthest point\nsampling (FPS). Our experiments show that FPS-based benchmarks maintain a\nstrong correlation (> 0.96) with full evaluations while using only ~1\\% of the\ndata. Additionally, applying FPS to an existing benchmark improves correlation\nwith overall evaluation results, suggesting its potential to reduce unintended\ndataset biases.", "published": "2025-04-14 08:43:00", "link": "http://arxiv.org/abs/2504.09979v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "OctGPT: Octree-based Multiscale Autoregressive Models for 3D Shape Generation", "abstract": "Autoregressive models have achieved remarkable success across various\ndomains, yet their performance in 3D shape generation lags significantly behind\nthat of diffusion models. In this paper, we introduce OctGPT, a novel\nmultiscale autoregressive model for 3D shape generation that dramatically\nimproves the efficiency and performance of prior 3D autoregressive approaches,\nwhile rivaling or surpassing state-of-the-art diffusion models. Our method\nemploys a serialized octree representation to efficiently capture the\nhierarchical and spatial structures of 3D shapes. Coarse geometry is encoded\nvia octree structures, while fine-grained details are represented by binary\ntokens generated using a vector quantized variational autoencoder (VQVAE),\ntransforming 3D shapes into compact \\emph{multiscale binary sequences} suitable\nfor autoregressive prediction. To address the computational challenges of\nhandling long sequences, we incorporate octree-based transformers enhanced with\n3D rotary positional encodings, scale-specific embeddings, and token-parallel\ngeneration schemes. These innovations reduce training time by 13 folds and\ngeneration time by 69 folds, enabling the efficient training of high-resolution\n3D shapes, e.g.,$1024^3$, on just four NVIDIA 4090 GPUs only within days.\nOctGPT showcases exceptional versatility across various tasks, including text-,\nsketch-, and image-conditioned generation, as well as scene-level synthesis\ninvolving multiple objects. Extensive experiments demonstrate that OctGPT\naccelerates convergence and improves generation quality over prior\nautoregressive methods, offering a new paradigm for high-quality, scalable 3D\ncontent creation.", "published": "2025-04-14 08:31:26", "link": "http://arxiv.org/abs/2504.09975v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Beyond Degradation Redundancy: Contrastive Prompt Learning for All-in-One Image Restoration", "abstract": "All-in-one image restoration, addressing diverse degradation types with a\nunified model, presents significant challenges in designing task-specific\nprompts that effectively guide restoration across multiple degradation\nscenarios. While adaptive prompt learning enables end-to-end optimization, it\noften yields overlapping or redundant task representations. Conversely,\nexplicit prompts derived from pretrained classifiers enhance discriminability\nbut may discard critical visual information for reconstruction. To address\nthese limitations, we introduce Contrastive Prompt Learning (CPL), a novel\nframework that fundamentally enhances prompt-task alignment through two\ncomplementary innovations: a \\emph{Sparse Prompt Module (SPM)} that efficiently\ncaptures degradation-specific features while minimizing redundancy, and a\n\\emph{Contrastive Prompt Regularization (CPR)} that explicitly strengthens task\nboundaries by incorporating negative prompt samples across different\ndegradation types. Unlike previous approaches that focus primarily on\ndegradation classification, CPL optimizes the critical interaction between\nprompts and the restoration model itself. Extensive experiments across five\ncomprehensive benchmarks demonstrate that CPL consistently enhances\nstate-of-the-art all-in-one restoration models, achieving significant\nimprovements in both standard multi-task scenarios and challenging composite\ndegradation settings. Our framework establishes new state-of-the-art\nperformance while maintaining parameter efficiency, offering a principled\nsolution for unified image restoration.", "published": "2025-04-14 08:24:57", "link": "http://arxiv.org/abs/2504.09973v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SemiETS: Integrating Spatial and Content Consistencies for Semi-Supervised End-to-end Text Spotting", "abstract": "Most previous scene text spotting methods rely on high-quality manual\nannotations to achieve promising performance. To reduce their expensive costs,\nwe study semi-supervised text spotting (SSTS) to exploit useful information\nfrom unlabeled images. However, directly applying existing semi-supervised\nmethods of general scenes to SSTS will face new challenges: 1) inconsistent\npseudo labels between detection and recognition tasks, and 2) sub-optimal\nsupervisions caused by inconsistency between teacher/student. Thus, we propose\na new Semi-supervised framework for End-to-end Text Spotting, namely SemiETS\nthat leverages the complementarity of text detection and recognition.\nSpecifically, it gradually generates reliable hierarchical pseudo labels for\neach task, thereby reducing noisy labels. Meanwhile, it extracts important\ninformation in locations and transcriptions from bidirectional flows to improve\nconsistency. Extensive experiments on three datasets under various settings\ndemonstrate the effectiveness of SemiETS on arbitrary-shaped text. For example,\nit outperforms previous state-of-the-art SSL methods by a large margin on\nend-to-end spotting (+8.7%, +5.6%, and +2.6% H-mean under 0.5%, 1%, and 2%\nlabeled data settings on Total-Text, respectively). More importantly, it still\nimproves upon a strongly supervised text spotter trained with plenty of labeled\ndata by 2.0%. Compelling domain adaptation ability shows practical potential.\nMoreover, our method demonstrates consistent improvement on different text\nspotters.", "published": "2025-04-14 08:09:17", "link": "http://arxiv.org/abs/2504.09966v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Dual-Path Enhancements in Event-Based Eye Tracking: Augmented Robustness and Adaptive Temporal Modeling", "abstract": "Event-based eye tracking has become a pivotal technology for augmented\nreality and human-computer interaction. Yet, existing methods struggle with\nreal-world challenges such as abrupt eye movements and environmental noise.\nBuilding on the efficiency of the Lightweight Spatiotemporal Network-a causal\narchitecture optimized for edge devices-we introduce two key advancements.\nFirst, a robust data augmentation pipeline incorporating temporal shift,\nspatial flip, and event deletion improves model resilience, reducing Euclidean\ndistance error by 12% (1.61 vs. 1.70 baseline) on challenging samples. Second,\nwe propose KnightPupil, a hybrid architecture combining an EfficientNet-B3\nbackbone for spatial feature extraction, a bidirectional GRU for contextual\ntemporal modeling, and a Linear Time-Varying State-Space Module to adapt to\nsparse inputs and noise dynamically. Evaluated on the 3ET+ benchmark, our\nframework achieved 1.61 Euclidean distance on the private test set of the\nEvent-based Eye Tracking Challenge at CVPR 2025, demonstrating its\neffectiveness for practical deployment in AR/VR systems while providing a\nfoundation for future innovations in neuromorphic vision.", "published": "2025-04-14 07:57:22", "link": "http://arxiv.org/abs/2504.09960v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Semantic Depth Matters: Explaining Errors of Deep Vision Networks through Perceived Class Similarities", "abstract": "Understanding deep neural network (DNN) behavior requires more than\nevaluating classification accuracy alone; analyzing errors and their\npredictability is equally crucial. Current evaluation methodologies lack\ntransparency, particularly in explaining the underlying causes of network\nmisclassifications. To address this, we introduce a novel framework that\ninvestigates the relationship between the semantic hierarchy depth perceived by\na network and its real-data misclassification patterns. Central to our\nframework is the Similarity Depth (SD) metric, which quantifies the semantic\nhierarchy depth perceived by a network along with a method of evaluation of how\nclosely the network's errors align with its internally perceived similarity\nstructure. We also propose a graph-based visualization of model semantic\nrelationships and misperceptions. A key advantage of our approach is that\nleveraging class templates -- representations derived from classifier layer\nweights -- is applicable to already trained networks without requiring\nadditional data or experiments. Our approach reveals that deep vision networks\nencode specific semantic hierarchies and that high semantic depth improves the\ncompliance between perceived class similarities and actual errors.", "published": "2025-04-14 07:44:34", "link": "http://arxiv.org/abs/2504.09956v1", "categories": ["cs.CV", "cs.LG", "68T01", "I.2.6"], "primary_category": "cs.CV"}
{"title": "Efficient 2D to Full 3D Human Pose Uplifting including Joint Rotations", "abstract": "In sports analytics, accurately capturing both the 3D locations and rotations\nof body joints is essential for understanding an athlete's biomechanics. While\nHuman Mesh Recovery (HMR) models can estimate joint rotations, they often\nexhibit lower accuracy in joint localization compared to 3D Human Pose\nEstimation (HPE) models. Recent work addressed this limitation by combining a\n3D HPE model with inverse kinematics (IK) to estimate both joint locations and\nrotations. However, IK is computationally expensive. To overcome this, we\npropose a novel 2D-to-3D uplifting model that directly estimates 3D human\nposes, including joint rotations, in a single forward pass. We investigate\nmultiple rotation representations, loss functions, and training strategies -\nboth with and without access to ground truth rotations. Our models achieve\nstate-of-the-art accuracy in rotation estimation, are 150 times faster than the\nIK-based approach, and surpass HMR models in joint localization precision.", "published": "2025-04-14 07:32:28", "link": "http://arxiv.org/abs/2504.09953v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Pseudo-Label Guided Real-World Image De-weathering: A Learning Framework with Imperfect Supervision", "abstract": "Real-world image de-weathering aims at removingvarious undesirable\nweather-related artifacts, e.g., rain, snow,and fog. To this end, acquiring\nideal training pairs is crucial.Existing real-world datasets are typically\nconstructed paired databy extracting clean and degraded images from live\nstreamsof landscape scene on the Internet. Despite the use of strictfiltering\nmechanisms during collection, training pairs inevitablyencounter inconsistency\nin terms of lighting, object position, scenedetails, etc, making de-weathering\nmodels possibly suffer fromdeformation artifacts under non-ideal supervision.\nIn this work,we propose a unified solution for real-world image\nde-weatheringwith non-ideal supervision, i.e., a pseudo-label guided\nlearningframework, to address various inconsistencies within the realworld\npaired dataset. Generally, it consists of a de-weatheringmodel (De-W) and a\nConsistent Label Constructor (CLC), bywhich restoration result can be\nadaptively supervised by originalground-truth image to recover sharp textures\nwhile maintainingconsistency with the degraded inputs in non-weather\ncontentthrough the supervision of pseudo-labels. Particularly, a Crossframe\nSimilarity Aggregation (CSA) module is deployed withinCLC to enhance the\nquality of pseudo-labels by exploring thepotential complementary information of\nmulti-frames throughgraph model. Moreover, we introduce an Information\nAllocationStrategy (IAS) to integrate the original ground-truth imagesand\npseudo-labels, thereby facilitating the joint supervision forthe training of\nde-weathering model. Extensive experimentsdemonstrate that our method exhibits\nsignificant advantageswhen trained on imperfectly aligned de-weathering\ndatasets incomparison with other approaches.", "published": "2025-04-14 07:24:03", "link": "http://arxiv.org/abs/2504.09949v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "FUSION: Fully Integration of Vision-Language Representations for Deep Cross-Modal Understanding", "abstract": "We introduce FUSION, a family of multimodal large language models (MLLMs)\nwith a fully vision-language alignment and integration paradigm. Unlike\nexisting methods that primarily rely on late-stage modality interaction during\nLLM decoding, our approach achieves deep, dynamic integration throughout the\nentire processing pipeline. To this end, we propose Text-Guided Unified Vision\nEncoding, incorporating textual information in vision encoding to achieve\npixel-level integration. We further design Context-Aware Recursive Alignment\nDecoding that recursively aggregates visual features conditioned on textual\ncontext during decoding, enabling fine-grained, question-level semantic\nintegration. To guide feature mapping and mitigate modality discrepancies, we\ndevelop Dual-Supervised Semantic Mapping Loss. Additionally, we construct a\nSynthesized Language-Driven Question-Answer (QA) dataset through a new data\nsynthesis method, prioritizing high-quality QA pairs to optimize text-guided\nfeature integration. Building on these foundations, we train FUSION at two\nscales-3B, 8B-and demonstrate that our full-modality integration approach\nsignificantly outperforms existing methods with only 630 vision tokens.\nNotably, FUSION 3B surpasses Cambrian-1 8B and Florence-VL 8B on most\nbenchmarks. FUSION 3B continues to outperform Cambrian-1 8B even when limited\nto 300 vision tokens. Our ablation studies show that FUSION outperforms\nLLaVA-NeXT on over half of the benchmarks under same configuration without\ndynamic resolution, highlighting the effectiveness of our approach. We release\nour code, model weights, and dataset. https://github.com/starriver030515/FUSION", "published": "2025-04-14 06:33:29", "link": "http://arxiv.org/abs/2504.09925v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Improving Multimodal Hateful Meme Detection Exploiting LMM-Generated Knowledge", "abstract": "Memes have become a dominant form of communication in social media in recent\nyears. Memes are typically humorous and harmless, however there are also memes\nthat promote hate speech, being in this way harmful to individuals and groups\nbased on their identity. Therefore, detecting hateful content in memes has\nemerged as a task of critical importance. The need for understanding the\ncomplex interactions of images and their embedded text renders the hateful meme\ndetection a challenging multimodal task. In this paper we propose to address\nthe aforementioned task leveraging knowledge encoded in powerful Large\nMultimodal Models (LMM). Specifically, we propose to exploit LMMs in a two-fold\nmanner. First, by extracting knowledge oriented to the hateful meme detection\ntask in order to build strong meme representations. Specifically, generic\nsemantic descriptions and emotions that the images along with their embedded\ntexts elicit are extracted, which are then used to train a simple\nclassification head for hateful meme detection. Second, by developing a novel\nhard mining approach introducing directly LMM-encoded knowledge to the training\nprocess, providing further improvements. We perform extensive experiments on\ntwo datasets that validate the effectiveness of the proposed method, achieving\nstate-of-the-art performance. Our code and trained models are publicly\navailable at: https://github.com/IDT-ITI/LMM-CLIP-meme.", "published": "2025-04-14 06:23:44", "link": "http://arxiv.org/abs/2504.09914v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LiteTracker: Leveraging Temporal Causality for Accurate Low-latency Tissue Tracking", "abstract": "Tissue tracking plays a critical role in various surgical navigation and\nextended reality (XR) applications. While current methods trained on large\nsynthetic datasets achieve high tracking accuracy and generalize well to\nendoscopic scenes, their runtime performances fail to meet the low-latency\nrequirements necessary for real-time surgical applications. To address this\nlimitation, we propose LiteTracker, a low-latency method for tissue tracking in\nendoscopic video streams. LiteTracker builds on a state-of-the-art long-term\npoint tracking method, and introduces a set of training-free runtime\noptimizations. These optimizations enable online, frame-by-frame tracking by\nleveraging a temporal memory buffer for efficient feature reuse and utilizing\nprior motion for accurate track initialization. LiteTracker demonstrates\nsignificant runtime improvements being around 7x faster than its predecessor\nand 2x than the state-of-the-art. Beyond its primary focus on efficiency,\nLiteTracker delivers high-accuracy tracking and occlusion prediction,\nperforming competitively on both the STIR and SuPer datasets. We believe\nLiteTracker is an important step toward low-latency tissue tracking for\nreal-time surgical applications in the operating room.", "published": "2025-04-14 05:53:57", "link": "http://arxiv.org/abs/2504.09904v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Small Object Detection with YOLO: A Performance Analysis Across Model Versions and Hardware", "abstract": "This paper provides an extensive evaluation of YOLO object detection models\n(v5, v8, v9, v10, v11) by com- paring their performance across various hardware\nplatforms and optimization libraries. Our study investigates inference speed\nand detection accuracy on Intel and AMD CPUs using popular libraries such as\nONNX and OpenVINO, as well as on GPUs through TensorRT and other GPU-optimized\nframeworks. Furthermore, we analyze the sensitivity of these YOLO models to\nobject size within the image, examining performance when detecting objects that\noccupy 1%, 2.5%, and 5% of the total area of the image. By identifying the\ntrade-offs in efficiency, accuracy, and object size adaptability, this paper\noffers insights for optimal model selection based on specific hardware\nconstraints and detection requirements, aiding practitioners in deploying YOLO\nmodels effectively for real-world applications.", "published": "2025-04-14 05:49:31", "link": "http://arxiv.org/abs/2504.09900v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Digital Staining with Knowledge Distillation: A Unified Framework for Unpaired and Paired-But-Misaligned Data", "abstract": "Staining is essential in cell imaging and medical diagnostics but poses\nsignificant challenges, including high cost, time consumption, labor intensity,\nand irreversible tissue alterations. Recent advances in deep learning have\nenabled digital staining through supervised model training. However, collecting\nlarge-scale, perfectly aligned pairs of stained and unstained images remains\ndifficult. In this work, we propose a novel unsupervised deep learning\nframework for digital cell staining that reduces the need for extensive paired\ndata using knowledge distillation. We explore two training schemes: (1)\nunpaired and (2) paired-but-misaligned settings. For the unpaired case, we\nintroduce a two-stage pipeline, comprising light enhancement followed by\ncolorization, as a teacher model. Subsequently, we obtain a student staining\ngenerator through knowledge distillation with hybrid non-reference losses. To\nleverage the pixel-wise information between adjacent sections, we further\nextend to the paired-but-misaligned setting, adding the Learning to Align\nmodule to utilize pixel-level information. Experiment results on our dataset\ndemonstrate that our proposed unsupervised deep staining method can generate\nstained images with more accurate positions and shapes of the cell targets in\nboth settings. Compared with competing methods, our method achieves improved\nresults both qualitatively and quantitatively (e.g., NIQE and PSNR).We applied\nour digital staining method to the White Blood Cell (WBC) dataset,\ninvestigating its potential for medical applications.", "published": "2025-04-14 05:48:05", "link": "http://arxiv.org/abs/2504.09899v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "TAMP: Token-Adaptive Layerwise Pruning in Multimodal Large Language Models", "abstract": "Multimodal Large Language Models (MLLMs) have shown remarkable versatility in\nunderstanding diverse multimodal data and tasks. However, these capabilities\ncome with an increased model scale. While post-training pruning reduces model\nsize in unimodal models, its application to MLLMs often yields limited success.\nOur analysis discovers that conventional methods fail to account for the unique\ntoken attributes across layers and modalities inherent to MLLMs. Inspired by\nthis observation, we propose TAMP, a simple yet effective pruning framework\ntailored for MLLMs, featuring two key components: (1) Diversity-Aware Sparsity,\nwhich adjusts sparsity ratio per layer based on diversities among multimodal\noutput tokens, preserving more parameters in high-diversity layers; and (2)\nAdaptive Multimodal Input Activation, which identifies representative\nmultimodal input tokens using attention scores to guide unstructured weight\npruning. We validate our method on two state-of-the-art MLLMs: LLaVA-NeXT,\ndesigned for vision-language tasks, and VideoLLaMA2, capable of processing\naudio, visual, and language modalities. Empirical experiments across various\nmultimodal evaluation benchmarks demonstrate that each component of our\napproach substantially outperforms existing pruning techniques.", "published": "2025-04-14 05:44:38", "link": "http://arxiv.org/abs/2504.09897v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Enhanced Semantic Extraction and Guidance for UGC Image Super Resolution", "abstract": "Due to the disparity between real-world degradations in user-generated\ncontent(UGC) images and synthetic degradations, traditional super-resolution\nmethods struggle to generalize effectively, necessitating a more robust\napproach to model real-world distortions. In this paper, we propose a novel\napproach to UGC image super-resolution by integrating semantic guidance into a\ndiffusion framework. Our method addresses the inconsistency between\ndegradations in wild and synthetic datasets by separately simulating the\ndegradation processes on the LSDIR dataset and combining them with the official\npaired training set. Furthermore, we enhance degradation removal and detail\ngeneration by incorporating a pretrained semantic extraction model (SAM2) and\nfine-tuning key hyperparameters for improved perceptual fidelity. Extensive\nexperiments demonstrate the superiority of our approach against\nstate-of-the-art methods. Additionally, the proposed model won second place in\nthe CVPR NTIRE 2025 Short-form UGC Image Super-Resolution Challenge, further\nvalidating its effectiveness. The code is available at\nhttps://github.c10pom/Moonsofang/NTIRE-2025-SRlab.", "published": "2025-04-14 05:26:24", "link": "http://arxiv.org/abs/2504.09887v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Separate to Collaborate: Dual-Stream Diffusion Model for Coordinated Piano Hand Motion Synthesis", "abstract": "Automating the synthesis of coordinated bimanual piano performances poses\nsignificant challenges, particularly in capturing the intricate choreography\nbetween the hands while preserving their distinct kinematic signatures. In this\npaper, we propose a dual-stream neural framework designed to generate\nsynchronized hand gestures for piano playing from audio input, addressing the\ncritical challenge of modeling both hand independence and coordination. Our\nframework introduces two key innovations: (i) a decoupled diffusion-based\ngeneration framework that independently models each hand's motion via\ndual-noise initialization, sampling distinct latent noise for each while\nleveraging a shared positional condition, and (ii) a Hand-Coordinated\nAsymmetric Attention (HCAA) mechanism suppresses symmetric (common-mode) noise\nto highlight asymmetric hand-specific features, while adaptively enhancing\ninter-hand coordination during denoising. The system operates hierarchically:\nit first predicts 3D hand positions from audio features and then generates\njoint angles through position-aware diffusion models, where parallel denoising\nstreams interact via HCAA. Comprehensive evaluations demonstrate that our\nframework outperforms existing state-of-the-art methods across multiple\nmetrics.", "published": "2025-04-14 05:17:41", "link": "http://arxiv.org/abs/2504.09885v1", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Focus on Local: Finding Reliable Discriminative Regions for Visual Place Recognition", "abstract": "Visual Place Recognition (VPR) is aimed at predicting the location of a query\nimage by referencing a database of geotagged images. For VPR task, often fewer\ndiscriminative local regions in an image produce important effects while\nmundane background regions do not contribute or even cause perceptual aliasing\nbecause of easy overlap. However, existing methods lack precisely modeling and\nfull exploitation of these discriminative regions. In this paper, we propose\nthe Focus on Local (FoL) approach to stimulate the performance of image\nretrieval and re-ranking in VPR simultaneously by mining and exploiting\nreliable discriminative local regions in images and introducing\npseudo-correlation supervision. First, we design two losses,\nExtraction-Aggregation Spatial Alignment Loss (SAL) and Foreground-Background\nContrast Enhancement Loss (CEL), to explicitly model reliable discriminative\nlocal regions and use them to guide the generation of global representations\nand efficient re-ranking. Second, we introduce a weakly-supervised local\nfeature training strategy based on pseudo-correspondences obtained from\naggregating global features to alleviate the lack of local correspondences\nground truth for the VPR task. Third, we suggest an efficient re-ranking\npipeline that is efficiently and precisely based on discriminative region\nguidance. Finally, experimental results show that our FoL achieves the\nstate-of-the-art on multiple VPR benchmarks in both image retrieval and\nre-ranking stages and also significantly outperforms existing two-stage VPR\nmethods in terms of computational efficiency. Code and models are available at\nhttps://github.com/chenshunpeng/FoL", "published": "2025-04-14 05:04:51", "link": "http://arxiv.org/abs/2504.09881v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MCBlock: Boosting Neural Radiance Field Training Speed by MCTS-based Dynamic-Resolution Ray Sampling", "abstract": "Neural Radiance Field (NeRF) is widely known for high-fidelity novel view\nsynthesis. However, even the state-of-the-art NeRF model, Gaussian Splatting,\nrequires minutes for training, far from the real-time performance required by\nmultimedia scenarios like telemedicine. One of the obstacles is its inefficient\nsampling, which is only partially addressed by existing works. Existing\npoint-sampling algorithms uniformly sample simple-texture regions (easy to fit)\nand complex-texture regions (hard to fit), while existing ray-sampling\nalgorithms sample these regions all in the finest granularity (i.e. the pixel\nlevel), both wasting GPU training resources. Actually, regions with different\ntexture intensities require different sampling granularities. To this end, we\npropose a novel dynamic-resolution ray-sampling algorithm, MCBlock, which\nemploys Monte Carlo Tree Search (MCTS) to partition each training image into\npixel blocks with different sizes for active block-wise training. Specifically,\nthe trees are initialized according to the texture of training images to boost\nthe initialization speed, and an expansion/pruning module dynamically optimizes\nthe block partition. MCBlock is implemented in Nerfstudio, an open-source\ntoolset, and achieves a training acceleration of up to 2.33x, surpassing other\nray-sampling algorithms. We believe MCBlock can apply to any cone-tracing NeRF\nmodel and contribute to the multimedia community.", "published": "2025-04-14 04:59:28", "link": "http://arxiv.org/abs/2504.09878v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GFT: Gradient Focal Transformer", "abstract": "Fine-Grained Image Classification (FGIC) remains a complex task in computer\nvision, as it requires models to distinguish between categories with subtle\nlocalized visual differences. Well-studied CNN-based models, while strong in\nlocal feature extraction, often fail to capture the global context required for\nfine-grained recognition, while more recent ViT-backboned models address FGIC\nwith attention-driven mechanisms but lack the ability to adaptively focus on\ntruly discriminative regions. TransFG and other ViT-based extensions introduced\npart-aware token selection to enhance attention localization, yet they still\nstruggle with computational efficiency, attention region selection flexibility,\nand detail-focus narrative in complex environments. This paper introduces GFT\n(Gradient Focal Transformer), a new ViT-derived framework created for FGIC\ntasks. GFT integrates the Gradient Attention Learning Alignment (GALA)\nmechanism to dynamically prioritize class-discriminative features by analyzing\nattention gradient flow. Coupled with a Progressive Patch Selection (PPS)\nstrategy, the model progressively filters out less informative regions,\nreducing computational overhead while enhancing sensitivity to fine details.\nGFT achieves SOTA accuracy on FGVC Aircraft, Food-101, and COCO datasets with\n93M parameters, outperforming ViT-based advanced FGIC models in efficiency. By\nbridging global context and localized detail extraction, GFT sets a new\nbenchmark in fine-grained recognition, offering interpretable solutions for\nreal-world deployment scenarios.", "published": "2025-04-14 03:49:06", "link": "http://arxiv.org/abs/2504.09852v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ST-Booster: An Iterative SpatioTemporal Perception Booster for Vision-and-Language Navigation in Continuous Environments", "abstract": "Vision-and-Language Navigation in Continuous Environments (VLN-CE) requires\nagents to navigate unknown, continuous spaces based on natural language\ninstructions. Compared to discrete settings, VLN-CE poses two core perception\nchallenges. First, the absence of predefined observation points leads to\nheterogeneous visual memories and weakened global spatial correlations. Second,\ncumulative reconstruction errors in three-dimensional scenes introduce\nstructural noise, impairing local feature perception. To address these\nchallenges, this paper proposes ST-Booster, an iterative spatiotemporal booster\nthat enhances navigation performance through multi-granularity perception and\ninstruction-aware reasoning. ST-Booster consists of three key modules --\nHierarchical SpatioTemporal Encoding (HSTE), Multi-Granularity Aligned Fusion\n(MGAF), and ValueGuided Waypoint Generation (VGWG). HSTE encodes long-term\nglobal memory using topological graphs and captures shortterm local details via\ngrid maps. MGAF aligns these dualmap representations with instructions through\ngeometry-aware knowledge fusion. The resulting representations are iteratively\nrefined through pretraining tasks. During reasoning, VGWG generates Guided\nAttention Heatmaps (GAHs) to explicitly model environment-instruction relevance\nand optimize waypoint selection. Extensive comparative experiments and\nperformance analyses are conducted, demonstrating that ST-Booster outperforms\nexisting state-of-the-art methods, particularly in complex, disturbance-prone\nenvironments.", "published": "2025-04-14 03:29:08", "link": "http://arxiv.org/abs/2504.09843v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Expected Length of the Longest Common Subsequence of Multiple Strings", "abstract": "We study the generalized Chv\\'atal-Sankoff constant $\\gamma_{k,d}$, which\nrepresents the normalized expected length of the longest common subsequence\n(LCS) of $d$ independent uniformly random strings over an alphabet of size $k$.\nWe derive asymptotically tight bounds for $\\gamma_{2,d}$, establishing that\n$\\gamma_{2,d} = \\frac{1}{2} + \\Theta\\left(\\frac{1}{\\sqrt{d}}\\right)$. We also\nderive asymptotically near-optimal bounds on $\\gamma_{k,d}$ for $d\\ge\n\\Omega(\\log k)$.", "published": "2025-04-14 17:15:51", "link": "http://arxiv.org/abs/2504.10425v1", "categories": ["math.CO", "cs.DM", "math.PR"], "primary_category": "math.CO"}
{"title": "Optimal Graph Stretching for Distributed Averaging", "abstract": "The performance of distributed averaging depends heavily on the underlying\ntopology. In various fields, including compressed sensing, multi-party\ncomputation, and abstract graph theory, graphs may be expected to be free of\nshort cycles, i.e. to have high girth. Though extensive analyses and heuristics\nexist for optimising the performance of distributed averaging in general\nnetworks, these studies do not consider girth. As such, it is not clear what\nhappens to convergence time when a graph is stretched to a higher girth.\n  In this work, we introduce the optimal graph stretching problem, wherein we\nare interested in finding the set of edges for a particular graph that ensures\noptimal convergence time under constraint of a minimal girth. We compare\nvarious methods for choosing which edges to remove, and use various convergence\nheuristics to speed up the searching process. We generate many graphs with\nvarying parameters, stretch and optimise them, and measure the duration of\ndistributed averaging. We find that stretching by itself significantly\nincreases convergence time. This decrease can be counteracted with a subsequent\nrepair phase, guided by a convergence time heuristic. Existing heuristics are\ncapable, but may be suboptimal.", "published": "2025-04-14 15:01:24", "link": "http://arxiv.org/abs/2504.10289v1", "categories": ["cs.DC", "cs.DM", "68R10 (Primary) 05C38, 68W15, 90C59, 15B48, 05C50, 15A18, 05C65\n  (Secondary)", "G.1.6; C.2.4; D.4.8; I.6.6; D.2.8"], "primary_category": "cs.DC"}
{"title": "Invariance Matters: Empowering Social Recommendation via Graph Invariant Learning", "abstract": "Graph-based social recommendation systems have shown significant promise in\nenhancing recommendation performance, particularly in addressing the issue of\ndata sparsity in user behaviors. Typically, these systems leverage Graph Neural\nNetworks (GNNs) to capture user preferences by incorporating high-order social\ninfluences from observed social networks. However, existing graph-based social\nrecommendations often overlook the fact that social networks are inherently\nnoisy, containing task-irrelevant relationships that can hinder accurate user\npreference learning. The removal of these redundant social relations is\ncrucial, yet it remains challenging due to the lack of ground truth. In this\npaper, we approach the social denoising problem from the perspective of graph\ninvariant learning and propose a novel method, Social Graph Invariant\nLearning(SGIL). Specifically,SGIL aims to uncover stable user preferences\nwithin the input social graph, thereby enhancing the robustness of graph-based\nsocial recommendation systems. To achieve this goal, SGIL first simulates\nmultiple noisy social environments through graph generators. It then seeks to\nlearn environment-invariant user preferences by minimizing invariant risk\nacross these environments. To further promote diversity in the generated social\nenvironments, we employ an adversarial training strategy to simulate more\npotential social noisy distributions. Extensive experimental results\ndemonstrate the effectiveness of the proposed SGIL. The code is available at\nhttps://github.com/yimutianyang/SIGIR2025-SGIL.", "published": "2025-04-14 17:20:48", "link": "http://arxiv.org/abs/2504.10432v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Brain-Machine Interfaces & Information Retrieval Challenges and Opportunities", "abstract": "The fundamental goal of Information Retrieval (IR) systems lies in their\ncapacity to effectively satisfy human information needs - a challenge that\nencompasses not just the technical delivery of information, but the nuanced\nunderstanding of human cognition during information seeking. Contemporary IR\nplatforms rely primarily on observable interaction signals, creating a\nfundamental gap between system capabilities and users' cognitive processes.\nBrain-Machine Interface (BMI) technologies now offer unprecedented potential to\nbridge this gap through direct measurement of previously inaccessible aspects\nof information-seeking behaviour. This perspective paper offers a broad\nexamination of the IR landscape, providing a comprehensive analysis of how BMI\ntechnology could transform IR systems, drawing from advances at the\nintersection of both neuroscience and IR research. We present our analysis\nthrough three identified fundamental vertices: (1) understanding the neural\ncorrelates of core IR concepts to advance theoretical models of search\nbehaviour, (2) enhancing existing IR systems through contextual integration of\nneurophysiological signals, and (3) developing proactive IR capabilities\nthrough direct neurophysiological measurement. For each vertex, we identify\nspecific research opportunities and propose concrete directions for developing\nBMI-enhanced IR systems. We conclude by examining critical technical and\nethical challenges in implementing these advances, providing a structured\nroadmap for future research at the intersection of neuroscience and IR.", "published": "2025-04-14 16:18:30", "link": "http://arxiv.org/abs/2504.10371v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "CROSSAN: Towards Efficient and Effective Adaptation of Multiple Multimodal Foundation Models for Sequential Recommendation", "abstract": "Multimodal Foundation Models (MFMs) excel at representing diverse raw\nmodalities (e.g., text, images, audio, videos, etc.). As recommender systems\nincreasingly incorporate these modalities, leveraging MFMs to generate better\nrepresentations has great potential. However, their application in sequential\nrecommendation remains largely unexplored. This is primarily because mainstream\nadaptation methods, such as Fine-Tuning and even Parameter-Efficient\nFine-Tuning (PEFT) techniques (e.g., Adapter and LoRA), incur high\ncomputational costs, especially when integrating multiple modality encoders,\nthus hindering research progress. As a result, it remains unclear whether we\ncan efficiently and effectively adapt multiple (>2) MFMs for the sequential\nrecommendation task.\n  To address this, we propose a plug-and-play Cross-modal Side Adapter Network\n(CROSSAN). Leveraging the fully decoupled side adapter-based paradigm, CROSSAN\nachieves high efficiency while enabling cross-modal learning across diverse\nmodalities. To optimize the final stage of multimodal fusion across diverse\nmodalities, we adopt the Mixture of Modality Expert Fusion (MOMEF) mechanism.\nCROSSAN achieves superior performance on the public datasets for adapting four\nfoundation models with raw modalities. Performance consistently improves as\nmore MFMs are adapted. We will release our code and datasets to facilitate\nfuture research.", "published": "2025-04-14 15:14:59", "link": "http://arxiv.org/abs/2504.10307v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "From Prompting to Alignment: A Generative Framework for Query Recommendation", "abstract": "In modern search systems, search engines often suggest relevant queries to\nusers through various panels or components, helping refine their information\nneeds. Traditionally, these recommendations heavily rely on historical search\nlogs to build models, which suffer from cold-start or long-tail issues.\nFurthermore, tasks such as query suggestion, completion or clarification are\nstudied separately by specific design, which lacks generalizability and hinders\nadaptation to novel applications. Despite recent attempts to explore the use of\nLLMs for query recommendation, these methods mainly rely on the inherent\nknowledge of LLMs or external sources like few-shot examples, retrieved\ndocuments, or knowledge bases, neglecting the importance of the calibration and\nalignment with user feedback, thus limiting their practical utility. To address\nthese challenges, we first propose a general Generative Query Recommendation\n(GQR) framework that aligns LLM-based query generation with user preference.\nSpecifically, we unify diverse query recommendation tasks by a universal prompt\nframework, leveraging the instruct-following capability of LLMs for effective\ngeneration. Secondly, we align LLMs with user feedback via presenting a\nCTR-alignment framework, which involves training a query-wise CTR predictor as\na process reward model and employing list-wise preference alignment to maximize\nthe click probability of the generated query list. Furthermore, recognizing the\ninconsistency between LLM knowledge and proactive search intents arising from\nthe separation of user-initiated queries from models, we align LLMs with user\ninitiative via retrieving co-occurrence queries as side information when\nhistorical logs are available.", "published": "2025-04-14 13:21:29", "link": "http://arxiv.org/abs/2504.10208v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "HistLLM: A Unified Framework for LLM-Based Multimodal Recommendation with User History Encoding and Compression", "abstract": "While large language models (LLMs) have proven effective in leveraging\ntextual data for recommendations, their application to multimodal\nrecommendation tasks remains relatively underexplored. Although LLMs can\nprocess multimodal information through projection functions that map visual\nfeatures into their semantic space, recommendation tasks often require\nrepresenting users' history interactions through lengthy prompts combining text\nand visual elements, which not only hampers training and inference efficiency\nbut also makes it difficult for the model to accurately capture user\npreferences from complex and extended prompts, leading to reduced\nrecommendation performance. To address this challenge, we introduce HistLLM, an\ninnovative multimodal recommendation framework that integrates textual and\nvisual features through a User History Encoding Module (UHEM), compressing\nmultimodal user history interactions into a single token representation,\neffectively facilitating LLMs in processing user preferences. Extensive\nexperiments demonstrate the effectiveness and efficiency of our proposed\nmechanism.", "published": "2025-04-14 12:01:11", "link": "http://arxiv.org/abs/2504.10150v1", "categories": ["cs.IR", "cs.MM"], "primary_category": "cs.IR"}
{"title": "A Survey of Personalization: From RAG to Agent", "abstract": "Personalization has become an essential capability in modern AI systems,\nenabling customized interactions that align with individual user preferences,\ncontexts, and goals. Recent research has increasingly concentrated on\nRetrieval-Augmented Generation (RAG) frameworks and their evolution into more\nadvanced agent-based architectures within personalized settings to enhance user\nsatisfaction. Building on this foundation, this survey systematically examines\npersonalization across the three core stages of RAG: pre-retrieval, retrieval,\nand generation. Beyond RAG, we further extend its capabilities into the realm\nof Personalized LLM-based Agents, which enhance traditional RAG systems with\nagentic functionalities, including user understanding, personalized planning\nand execution, and dynamic generation. For both personalization in RAG and\nagent-based personalization, we provide formal definitions, conduct a\ncomprehensive review of recent literature, and summarize key datasets and\nevaluation metrics. Additionally, we discuss fundamental challenges,\nlimitations, and promising research directions in this evolving field. Relevant\npapers and resources are continuously updated at\nhttps://github.com/Applied-Machine-Learning-Lab/Awesome-Personalized-RAG-Agent.", "published": "2025-04-14 11:57:52", "link": "http://arxiv.org/abs/2504.10147v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Unveiling Contrastive Learning's Capability of Neighborhood Aggregation for Collaborative Filtering", "abstract": "Personalized recommendation is widely used in the web applications, and graph\ncontrastive learning (GCL) has gradually become a dominant approach in\nrecommender systems, primarily due to its ability to extract self-supervised\nsignals from raw interaction data, effectively alleviating the problem of data\nsparsity. A classic GCL-based method typically uses data augmentation during\ngraph convolution to generates more contrastive views, and performs contrast on\nthese new views to obtain rich self-supervised signals. Despite this paradigm\nis effective, the reasons behind the performance gains remain a mystery. In\nthis paper, we first reveal via theoretical derivation that the gradient\ndescent process of the CL objective is formally equivalent to graph\nconvolution, which implies that CL objective inherently supports neighborhood\naggregation on interaction graphs. We further substantiate this capability\nthrough experimental validation and identify common misconceptions in the\nselection of positive samples in previous methods, which limit the potential of\nCL objective. Based on this discovery, we propose the Light Contrastive\nCollaborative Filtering (LightCCF) method, which introduces a novel\nneighborhood aggregation objective to bring users closer to all interacted\nitems while pushing them away from other positive pairs, thus achieving\nhigh-quality neighborhood aggregation with very low time complexity. On three\nhighly sparse public datasets, the proposed method effectively aggregate\nneighborhood information while preventing graph over-smoothing, demonstrating\nsignificant improvements over existing GCL-based counterparts in both training\nefficiency and recommendation accuracy. Our implementations are publicly\naccessible.", "published": "2025-04-14 11:22:41", "link": "http://arxiv.org/abs/2504.10113v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Enhancing LLM-based Recommendation through Semantic-Aligned Collaborative Knowledge", "abstract": "Large Language Models (LLMs) demonstrate remarkable capabilities in\nleveraging comprehensive world knowledge and sophisticated reasoning mechanisms\nfor recommendation tasks. However, a notable limitation lies in their inability\nto effectively model sparse identifiers (e.g., user and item IDs), unlike\nconventional collaborative filtering models (Collabs.), thus hindering LLM to\nlearn distinctive user-item representations and creating a performance\nbottleneck. Prior studies indicate that integrating collaborative knowledge\nfrom Collabs. into LLMs can mitigate the above limitations and enhance their\nrecommendation performance. Nevertheless, the significant discrepancy in\nknowledge distribution and semantic space between LLMs and Collab. presents\nsubstantial challenges for effective knowledge transfer. To tackle these\nchallenges, we propose a novel framework, SeLLa-Rec, which focuses on achieving\nalignment between the semantic spaces of Collabs. and LLMs. This alignment\nfosters effective knowledge fusion, mitigating the influence of discriminative\nnoise and facilitating the deep integration of knowledge from diverse models.\nSpecifically, three special tokens with collaborative knowledge are embedded\ninto the LLM's semantic space through a hybrid projection layer and integrated\ninto task-specific prompts to guide the recommendation process. Experiments\nconducted on two public benchmark datasets (MovieLens-1M and Amazon Book)\ndemonstrate that SeLLa-Rec achieves state-of-the-art performance.", "published": "2025-04-14 11:15:30", "link": "http://arxiv.org/abs/2504.10107v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "On Precomputation and Caching in Information Retrieval Experiments with Pipeline Architectures", "abstract": "Modern information retrieval systems often rely on multiple components\nexecuted in a pipeline. In a research setting, this can lead to substantial\nredundant computations (e.g., retrieving the same query multiple times for\nevaluating different downstream rerankers). To overcome this, researchers take\ncached \"result\" files as inputs, which represent the output of another\npipeline. However, these result files can be brittle and can cause a disconnect\nbetween the conceptual design of the pipeline and its logical implementation.\nTo overcome both the redundancy problem (when executing complete pipelines) and\nthe disconnect problem (when relying on intermediate result files), we describe\nour recent efforts to improve the caching capabilities in the open-source\nPyTerrier IR platform. We focus on two main directions: (1) automatic implicit\ncaching of common pipeline prefixes when comparing systems and (2) explicit\ncaching of operations through a new extension package, pyterrier-caching. These\napproaches allow for the best of both worlds: pipelines can be fully expressed\nend-to-end, while also avoiding redundant computations between pipelines.", "published": "2025-04-14 08:51:35", "link": "http://arxiv.org/abs/2504.09984v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Constrained Auto-Regressive Decoding Constrains Generative Retrieval", "abstract": "Generative retrieval seeks to replace traditional search index data\nstructures with a single large-scale neural network, offering the potential for\nimproved efficiency and seamless integration with generative large language\nmodels. As an end-to-end paradigm, generative retrieval adopts a learned\ndifferentiable search index to conduct retrieval by directly generating\ndocument identifiers through corpus-specific constrained decoding. The\ngeneralization capabilities of generative retrieval on out-of-distribution\ncorpora have gathered significant attention.\n  In this paper, we examine the inherent limitations of constrained\nauto-regressive generation from two essential perspectives: constraints and\nbeam search. We begin with the Bayes-optimal setting where the generative\nretrieval model exactly captures the underlying relevance distribution of all\npossible documents. Then we apply the model to specific corpora by simply\nadding corpus-specific constraints. Our main findings are two-fold: (i) For the\neffect of constraints, we derive a lower bound of the error, in terms of the KL\ndivergence between the ground-truth and the model-predicted step-wise marginal\ndistributions. (ii) For the beam search algorithm used during generation, we\nreveal that the usage of marginal distributions may not be an ideal approach.\nThis paper aims to improve our theoretical understanding of the generalization\ncapabilities of the auto-regressive decoding retrieval paradigm, laying a\nfoundation for its limitations and inspiring future advancements toward more\nrobust and generalizable generative retrieval.", "published": "2025-04-14 06:54:49", "link": "http://arxiv.org/abs/2504.09935v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "StePO-Rec: Towards Personalized Outfit Styling Assistant via Knowledge-Guided Multi-Step Reasoning", "abstract": "Advancements in Generative AI offers new opportunities for FashionAI,\nsurpassing traditional recommendation systems that often lack transparency and\nstruggle to integrate expert knowledge, leaving the potential for personalized\nfashion styling remain untapped. To address these challenges, we present PAFA\n(Principle-Aware Fashion), a multi-granular knowledge base that organizes\nprofessional styling expertise into three levels of metadata, domain\nprinciples, and semantic relationships. Using PAFA, we develop StePO-Rec, a\nknowledge-guided method for multi-step outfit recommendation. StePO-Rec\nprovides structured suggestions using a scenario-dimension-attribute framework,\nemploying recursive tree construction to align recommendations with both\nprofessional principles and individual preferences. A preference-trend\nre-ranking system further adapts to fashion trends while maintaining the\nconsistency of the user's original style. Experiments on the widely used\npersonalized outfit dataset IQON show a 28% increase in Recall@1 and 32.8% in\nMAP. Furthermore, case studies highlight improved explainability, traceability,\nresult reliability, and the seamless integration of expertise and\npersonalization.", "published": "2025-04-14 06:24:56", "link": "http://arxiv.org/abs/2504.09915v1", "categories": ["cs.IR", "cs.MM"], "primary_category": "cs.IR"}
{"title": "RAKG:Document-level Retrieval Augmented Knowledge Graph Construction", "abstract": "With the rise of knowledge graph based retrieval-augmented generation (RAG)\ntechniques such as GraphRAG and Pike-RAG, the role of knowledge graphs in\nenhancing the reasoning capabilities of large language models (LLMs) has become\nincreasingly prominent. However, traditional Knowledge Graph Construction (KGC)\nmethods face challenges like complex entity disambiguation, rigid schema\ndefinition, and insufficient cross-document knowledge integration. This paper\nfocuses on the task of automatic document-level knowledge graph construction.\nIt proposes the Document-level Retrieval Augmented Knowledge Graph Construction\n(RAKG) framework. RAKG extracts pre-entities from text chunks and utilizes\nthese pre-entities as queries for RAG, effectively addressing the issue of\nlong-context forgetting in LLMs and reducing the complexity of Coreference\nResolution. In contrast to conventional KGC methods, RAKG more effectively\ncaptures global information and the interconnections among disparate nodes,\nthereby enhancing the overall performance of the model. Additionally, we\ntransfer the RAG evaluation framework to the KGC field and filter and evaluate\nthe generated knowledge graphs, thereby avoiding incorrectly generated entities\nand relationships caused by hallucinations in LLMs. We further developed the\nMINE dataset by constructing standard knowledge graphs for each article and\nexperimentally validated the performance of RAKG. The results show that RAKG\nachieves an accuracy of 95.91 % on the MINE dataset, a 6.2 % point improvement\nover the current best baseline, GraphRAG (89.71 %). The code is available at\nhttps://github.com/LMMApplication/RAKG.", "published": "2025-04-14 02:47:23", "link": "http://arxiv.org/abs/2504.09823v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Minimizing Functions of Age of Incorrect Information for Remote Estimation", "abstract": "The age of incorrect information (AoII) process which keeps track of the time\nsince the source and monitor processes are in sync, has been extensively used\nin remote estimation problems. In this paper, we consider a push-based remote\nestimation system with a discrete-time Markov chain (DTMC) information source\ntransmitting status update packets towards the monitor once the AoII process\nexceeds a certain estimation-based threshold. In this paper, the time average\nof an arbitrary function of AoII is taken as the AoII cost, as opposed to using\nthe average AoII as the mismatch metric, whereas this function is also allowed\nto depend on the estimation value. In this very general setting, our goal is to\nminimize a weighted sum of AoII and transmission costs. For this purpose, we\nformulate a discrete-time semi-Markov decision process (SMDP) regarding the\nmulti-threshold status update policy. We propose a novel tool in discrete-time\ncalled 'dual-regime absorbing Markov chain' (DR-AMC) and its corresponding\nabsorption time distribution named as 'dual-regime phase-type' (DR-PH)\ndistribution, to obtain the characterizing parameters of the SMDP, which allows\nus to obtain the distribution of the AoII process for a given policy, and hence\nthe average of any function of AoII. The proposed method is validated with\nnumerical results by which we compare our proposed method against other\npolicies obtained by exhaustive-search, and also various benchmark policies.", "published": "2025-04-14 17:39:06", "link": "http://arxiv.org/abs/2504.10451v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Capacities of highly Markovian divisible quantum channels", "abstract": "We analyze information transmission capacities of quantum channels acting on\n$d$-dimensional quantum systems that are highly Markovian divisible, i.e.,\nchannels of the form \\begin{equation*}\n  \\Phi = \\underbrace{\\Psi\\circ \\Psi \\circ \\ldots \\circ \\Psi}_{l\n\\,\\operatorname{times}} \\end{equation*} with $l \\geq \\gamma d^2 \\log d$ for\nsome constant $\\gamma=\\gamma(\\Psi)$ that depends on the spectral gap of the\ndividing channel $\\Psi$. We prove that capacities of such channels are\napproximately strongly additive and can be efficiently approximated in terms of\nthe structure of their peripheral spaces. Furthermore, the quantum and private\nclassical capacities of such channels approximately coincide and approximately\nsatisfy the strong converse property. We show that these approximate results\nbecome exact for the corresponding zero-error capacities when $l \\geq d^2$. To\nprove these results, we show that for any channel $\\Psi$, the classical,\nprivate classical, and quantum capacities of $\\Psi_\\infty$, which is its\nso-called asymptotic part, satisfy the strong converse property and are\nstrongly additive. In the zero-error case, we introduce the notion of the\nstabilized non-commutative confusability graph of a quantum channel and\ncharacterize its structure for any given channel.", "published": "2025-04-14 17:27:43", "link": "http://arxiv.org/abs/2504.10436v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Unique Decoding of Reed-Solomon and Related Codes for Semi-Adversarial Errors", "abstract": "For over a quarter century, the Guruswami-Sudan algorithm has served as the\nstate-of-the-art for list-decoding Reed-Solomon (RS) codes up to the Johnson\nbound against adversarial errors. However, some recent structural results on\nthe combinatorial list decoding of randomly punctured Reed-Solomon codes\nsuggest that Johnson bound can likely be broken for some subclasses of RS\ncodes. Motivated by these results, we seek to make traction on understanding\nadversarial decoding by considering a new model: semi-adversarial errors. This\nerror model bridges between fully random errors and fully adversarial errors by\nallowing some symbols of a message to be corrupted by an adversary while others\nare replaced with uniformly random symbols.\n  As our main quest, we seek to understand optimal efficient unique decoding\nalgorithms in the semi-adversarial model. In particular, we revisit some\nclassical results on decoding interleaved Reed-Solomon codes (aka subfield\nevaluation RS codes) in the random error model by Bleichenbacher-Kiayias-Yung\n(BKY) and work to improve and extend their analysis. First, we give an improved\nimplementation and analysis of the BKY algorithm for interleaved Reed-Solomon\ncodes in the semi-adversarial model. In particular, our algorithm runs in\nnear-linear time, and for most mixtures of random and adversarial errors, our\nanalysis matches the information-theoretic optimum.\n  Moreover, inspired by the BKY algorithm, we use a novel interpolation to\nextend our approach to the settings of folded Reed-Solomon codes, resulting in\nfast algorithms for unique decoding against semi-adversarial errors. A\nparticular advantage of our near-linear time algorithm over state-of-the-art\ndecoding algorithms for adversarial errors is that its running time depends\nonly on a polynomial function of the folding parameter rather than on an\nexponential function.", "published": "2025-04-14 16:49:45", "link": "http://arxiv.org/abs/2504.10399v1", "categories": ["cs.IT", "cs.DS", "math.IT"], "primary_category": "cs.IT"}
{"title": "Simple physical systems as a reference for multivariate information dynamics", "abstract": "Understanding a complex system entails capturing the non-trivial collective\nphenomena that arise from interactions between its different parts. Information\ntheory is a flexible and robust framework to study such behaviours, with\nseveral measures designed to quantify and characterise the interdependencies\namong the system's components. However, since these estimators rely on the\nstatistical distributions of observed quantities, it is crucial to examine the\nrelationships between information-theoretic measures and the system's\nunderlying mechanistic structure. To this end, here we present an\ninformation-theoretic analytical investigation of an elementary system of\ninteractive random walkers subject to Gaussian noise. Focusing on partial\ninformation decomposition, causal emergence, and integrated information, our\nresults help us develop some intuitions on their relationship with the physical\nparameters of the system. For instance, we observe that uncoupled systems can\nexhibit emergent properties, in a way that we suggest may be better described\nas ''statistically autonomous''. Overall, we observe that in this simple\nscenario information measures align more reliably with the system's mechanistic\nproperties when calculated at the level of microscopic components, rather than\ntheir coarse-grained counterparts, and over timescales comparable with the\nsystem's intrinsic dynamics. Moreover, we show that approaches that separate\nthe contributions of the system's dynamics and steady-state distribution (e.g.\nvia causal perturbations) may help strengthen the interpretation of\ninformation-theoretic analyses.", "published": "2025-04-14 16:20:48", "link": "http://arxiv.org/abs/2504.10372v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "The topology of synergy: linking topological and information-theoretic approaches to higher-order interactions in complex systems", "abstract": "The study of irreducible higher-order interactions has become a core topic of\nstudy in complex systems. Two of the most well-developed frameworks,\ntopological data analysis and multivariate information theory, aim to provide\nformal tools for identifying higher-order interactions in empirical data.\nDespite similar aims, however, these two approaches are built on markedly\ndifferent mathematical foundations and have been developed largely in parallel.\nIn this study, we present a head-to-head comparison of topological data\nanalysis and information-theoretic approaches to describing higher-order\ninteractions in multivariate data; with the aim of assessing the similarities\nand differences between how the frameworks define ``higher-order structures.\"\nWe begin with toy examples with known topologies, before turning to\nnaturalistic data: fMRI signals collected from the human brain. We find that\nintrinsic, higher-order synergistic information is associated with\nthree-dimensional cavities in a point cloud: shapes such as spheres are\nsynergy-dominated. In fMRI data, we find strong correlations between\nsynergistic information and both the number and size of three-dimensional\ncavities. Furthermore, we find that dimensionality reduction techniques such as\nPCA preferentially represent higher-order redundancies, and largely fail to\npreserve both higher-order information and topological structure, suggesting\nthat common manifold-based approaches to studying high-dimensional data are\nsystematically failing to identify important features of the data. These\nresults point towards the possibility of developing a rich theory of\nhigher-order interactions that spans topological and information-theoretic\napproaches while simultaneously highlighting the profound limitations of more\nconventional methods.", "published": "2025-04-14 11:53:48", "link": "http://arxiv.org/abs/2504.10140v1", "categories": ["cs.IT", "math.IT", "q-bio.NC"], "primary_category": "cs.IT"}
{"title": "Multi-Target Position Error Bound and Power Allocation Scheme for Cell-Free mMIMO-OTFS ISAC Systems", "abstract": "This paper investigates multi-target position estimation in cell-free massive\nmultiple-input multiple-output (CF mMIMO) architectures, where orthogonal time\nfrequency and space (OTFS) is used as an integrated sensing and communication\n(ISAC) signal. Closed-form expressions for the Cram\\'{e}r-Rao lower bound and\nthe positioning error bound (PEB) in multi-target position estimation are\nderived, providing quantitative evaluations of sensing performance. To enhance\nthe overall performance of the ISAC system, a power allocation algorithm is\ndeveloped to maximize the minimum user communication\nsignal-to-interference-plus-noise ratio while ensuring a specified sensing PEB\nrequirement. The results validate the proposed PEB expression and its\napproximation, clearly illustrating the coordination gain enabled by ISAC.\nFurther, the superiority of using the multi-static CF mMIMO architecture over\ntraditional cellular ISAC is demonstrated, and the advantages of OTFS signals\nin high-mobility scenarios are highlighted.", "published": "2025-04-14 11:48:15", "link": "http://arxiv.org/abs/2504.10137v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Code size constraints in b-symbol read channels: A bound analysis", "abstract": "In classical coding theory, error-correcting codes are designed to protect\nagainst errors occurring at individual symbol positions in a codeword. However,\nin practical storage and communication systems, errors often affect multiple\nadjacent symbols rather than single symbols independently. To address this,\nsymbol-pair read channels were introduced \\cite{Yuval2011}, and later\ngeneralized to $b$-symbol read channels \\cite{yaakobi2016} to better model such\nerror patterns. $b$-Symbol read channels generalize symbol-pair read channels\nto account for clustered errors in modern storage and communication systems. By\ndeveloping bounds and efficient codes, researchers improve data reliability in\napplications such as storage devices, wireless networks, and DNA-based storage.\nGiven integers $q$, $n$, $d$, and $b \\geq 2$, let $A_b(n,d,q)$ denote the\nlargest possible code size for which there exists a $q$-ary code of length $n$\nwith minimum $b$-symbol distance at least $d$. In \\cite{chen2022}, various\nupper and lower bounds on $A_b(n,d,q)$ are given for $b=2$. In this paper, we\ngeneralize some of these bounds to the $b$-symbol read channels for $b>2$ and\npresent several new bounds on $A_b(n,d,q)$. In particular, we establish the\nlinear programming bound, a recurrence relation on $A_b(n,d,q)$, the Johnson\nbound (even), the restricted Johnson bound, the Gilbert-Varshamov-type bound,\nand the Elias bound for the metric of symbols $b$, $b\\geq 2$. Furthermore, we\nprovide examples demonstrating that the Gilbert-Varshamov bound we establish\noffers a stronger lower bound than the one presented in \\cite{Song2018}.\nAdditionally, we introduce an alternative approach to deriving the\nSphere-packing and Plotkin bounds.", "published": "2025-04-14 10:47:31", "link": "http://arxiv.org/abs/2504.10088v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Frequency Hopping Waveform Design for Secure Integrated Sensing and Communications", "abstract": "We introduce a comprehensive approach to enhance the security, privacy, and\nsensing capabilities of integrated sensing and communications (ISAC) systems by\nleveraging random frequency agility (RFA) and random pulse repetition interval\n(PRI) agility (RPA) techniques. The combination of these techniques, which we\nrefer to collectively as random frequency and PRI agility (RFPA), with channel\nreciprocity-based key generation (CRKG) obfuscates both Doppler frequency and\nPRIs, significantly hindering the chances that passive adversaries can\nsuccessfully estimate radar parameters. In addition, a hybrid information\nembedding method integrating amplitude shift keying (ASK), phase shift keying\n(PSK), index modulation (IM), and spatial modulation (SM) is incorporated to\nincrease the achievable bit rate of the system significantly. Next, a\nsparse-matched filter receiver design is proposed to efficiently decode the\nembedded information with a low bit error rate (BER). Finally, a novel\nRFPA-based secret generation scheme using CRKG ensures secure code creation\nwithout a coordinating authority. The improved range and velocity estimation\nand reduced clutter effects achieved with the method are demonstrated via the\nevaluation of the ambiguity function (AF) of the proposed waveforms.", "published": "2025-04-14 09:56:18", "link": "http://arxiv.org/abs/2504.10052v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Secrecy and Privacy in Multi-Access Combinatorial Topology", "abstract": "In this work, we consider the multi-access combinatorial topology with $C$\ncaches where each user accesses a unique set of $r$ caches. For this setup, we\nconsider secrecy, where each user should not know anything about the files it\ndid not request, and demand privacy, where each user's demand must be kept\nprivate from other non-colluding users. We propose a scheme satisfying both\nconditions and derive a lower bound based on cut-set arguments. Also, we prove\nthat our scheme is optimal when $r\\geq C-1$, and it is order-optimal when the\ncache memory size $M$ is greater than or equal to a certain threshold for\n$r<C-1$. When $r=1$, in most of the memory region, our scheme achieves the same\nrate as the one given by the secretive scheme for the dedicated cache setup by\nRavindrakumar et al. ( 'Private Coded Caching,' in \\textit{IEEE Transactions on\nInformation Forensics and Security}, 2018), while satisfying both secrecy and\ndemand privacy conditions.", "published": "2025-04-14 07:30:03", "link": "http://arxiv.org/abs/2504.09952v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Constrained Error-Correcting Codes for Efficient DNA Synthesis", "abstract": "DNA synthesis is considered as one of the most expensive components in\ncurrent DNA storage systems. In this paper, focusing on a common synthesis\nmachine, which generates multiple DNA strands in parallel following a fixed\nsupersequence,we propose constrained codes with polynomial-time encoding and\ndecoding algorithms. Compared to the existing works, our codes simultaneously\nsatisfy both l-runlength limited and {\\epsilon}-balanced constraints. By\nenumerating all valid sequences, our codes achieve the maximum rate, matching\nthe capacity. Additionally, we design constrained error-correcting codes\ncapable of correcting one insertion or deletion in the obtained DNA sequence\nwhile still adhering to the constraints.", "published": "2025-04-14 07:25:18", "link": "http://arxiv.org/abs/2504.09950v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "On the $N$th $2$-adic complexity of binary sequences identified with algebraic $2$-adic integers", "abstract": "We identify a binary sequence $\\mathcal{S}=(s_n)_{n=0}^\\infty$ with the\n$2$-adic integer $G_\\mathcal{S}(2)=\\sum\\limits_{n=0}^\\infty s_n2^n$. In the\ncase that $G_\\mathcal{S}(2)$ is algebraic over $\\mathbb{Q}$ of degree $d\\ge 2$,\nwe prove that the $N$th $2$-adic complexity of $\\mathcal{S}$ is at least\n$\\frac{N}{d}+O(1)$, where the implied constant depends only on the minimal\npolynomial of $G_\\mathcal{S}(2)$. This result is an analog of the bound of\nM\\'erai and the second author on the linear complexity of automatic sequences,\nthat is, sequences with algebraic $G_\\mathcal{S}(X)$ over the rational function\nfield $\\mathbb{F}_2(X)$. We further discuss the most important case $d=2$ in\nboth settings and explain that the intersection of the set of $2$-adic\nalgebraic sequences and the set of automatic sequences is the set of\n(eventually) periodic sequences. Finally, we provide some experimental results\nsupporting the conjecture that $2$-adic algebraic sequences can have also a\ndesirable $N$th linear complexity and automatic sequences a desirable $N$th\n$2$-adic complexity, respectively.", "published": "2025-04-14 06:52:47", "link": "http://arxiv.org/abs/2504.09933v1", "categories": ["math.NT", "cs.IT", "math.IT"], "primary_category": "math.NT"}
{"title": "A Theory of Universal Rate-Distortion-Classification Representations for Lossy Compression", "abstract": "In lossy compression, Blau and Michaeli [5] introduced the information\nrate-distortion-perception (RDP) function, extending traditional\nrate-distortion theory by incorporating perceptual quality. More recently, this\nframework was expanded by defining the\nrate-distortion-perception-classification (RDPC) function, integrating\nmulti-task learning that jointly optimizes generative tasks such as perceptual\nquality and classification accuracy alongside reconstruction tasks [28]. To\nthat end, motivated by the concept of a universal RDP encoder introduced in\n[34], we investigate universal representations that enable diverse\ndistortion-classification tradeoffs through a single fixed encoder combined\nwith multiple decoders. Specifically, theoretical analysis and numerical\nexperiment demonstrate that for the Gaussian source under mean squared error\n(MSE) distortion, the entire distortion-classification tradeoff region can be\nachieved using one universal encoder. In addition, this paper characterizes\nachievable distortion-classification regions for fixed universal\nrepresentations in general source distributions, identifying conditions that\nensure minimal distortion penalty when reusing encoders across varying tradeoff\npoints. Experimental results using MNIST and SVHN datasets validate our\ntheoretical insights, showing that universal encoders can obtain distortion\nperformance comparable to task-specific encoders, thus supporting the\npracticality and effectiveness of our proposed universal representations.", "published": "2025-04-14 06:46:02", "link": "http://arxiv.org/abs/2504.09932v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Passive Channel Charting: Locating Passive Targets using Wi-Fi Channel State Information", "abstract": "We propose passive channel charting, an extension of channel charting to\npassive target localization. As in conventional channel charting, we follow a\ndimensionality reduction approach to reconstruct a physically interpretable map\nof target positions from similarities in high-dimensional channel state\ninformation. We show that algorithms and neural network architectures developed\nin the context of channel charting with active mobile transmitters can be\nstraightforwardly applied to the passive case, where we assume a scenario with\nstatic transmitters and receivers and a mobile target. We evaluate our method\non a channel state information dataset collected indoors with a distributed\nsetup of ESPARGOS Wi-Fi sensing antenna arrays. This scenario can be\ninterpreted as either a multi-static or passive radar system. We demonstrate\nthat passive channel charting outperforms a baseline based on classical\ntriangulation in terms of localization accuracy. We discuss our results and\nhighlight some unsolved issues related to the proposed concept.", "published": "2025-04-14 06:33:07", "link": "http://arxiv.org/abs/2504.09924v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Finite-Precision Conjugate Gradient Method for Massive MIMO Detection", "abstract": "The implementation of the conjugate gradient (CG) method for massive MIMO\ndetection is computationally challenging, especially for a large number of\nusers and correlated channels. In this paper, we propose a low computational\ncomplexity CG detection from a finite-precision perspective. First, we develop\na finite-precision CG (FP-CG) detection to mitigate the computational\nbottleneck of each CG iteration and provide the attainable accuracy,\nconvergence, and computational complexity analysis to reveal the impact of\nfinite-precision arithmetic. A practical heuristic is presented to select\nsuitable precisions. Then, to further reduce the number of iterations, we\npropose a joint finite-precision and block-Jacobi preconditioned CG (FP-BJ-CG)\ndetection. The corresponding performance analysis is also provided. Finally,\nsimulation results validate the theoretical insights and demonstrate the\nsuperiority of the proposed detection.", "published": "2025-04-14 02:46:05", "link": "http://arxiv.org/abs/2504.09820v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Anchors no more: Using peculiar velocities to constrain $H_0$ and the primordial Universe without calibrators", "abstract": "We develop a novel approach to constrain the Hubble parameter $H_0$ and the\nprimordial power spectrum amplitude $A_\\mathrm{s}$ using supernovae type Ia\n(SNIa) data. By considering SNIa as tracers of the peculiar velocity field, we\ncan model their distance and their covariance as a function of cosmological\nparameters without the need of calibrators like Cepheids; this yields a new\nindependent probe of the large-scale structure based on SNIa data without\ndistance anchors. Crucially, we implement a differentiable pipeline in JAX,\nincluding efficient emulators and affine sampling, reducing inference time from\nyears to hours on a single GPU. We first validate our method on mock datasets,\ndemonstrating that we can constrain $H_0$ and $\\log 10^{10}A_\\mathrm{s}$ within\n$\\sim10\\%$ using $\\sim10^3$ SNIa. We then test our pipeline with SNIa from an\n$N$-body simulation, obtaining $7\\%$-level unbiased constraints on $H_0$ with a\nmoderate noise level. We finally apply our method to Pantheon+ data,\nconstraining $H_0$ at the $10\\%$ level without Cepheids when fixing\n$A_\\mathrm{s}$ to its $\\it{Planck}$ value. On the other hand, we obtain\n$15\\%$-level constraints on $\\log 10^{10}A_\\mathrm{s}$ in agreement with\n$\\it{Planck}$ when including Cepheids in the analysis. In light of upcoming\nobservations of low redshift SNIa from the Zwicky Transient Facility and the\nVera Rubin Legacy Survey of Space and Time, surveys for which our method will\ndevelop its full potential, we make our code publicly available.", "published": "2025-04-14 17:40:18", "link": "http://arxiv.org/abs/2504.10453v1", "categories": ["astro-ph.CO", "astro-ph.IM", "cs.LG", "gr-qc"], "primary_category": "astro-ph.CO"}
{"title": "M1: Towards Scalable Test-Time Compute with Mamba Reasoning Models", "abstract": "Effective reasoning is crucial to solving complex mathematical problems.\nRecent large language models (LLMs) have boosted performance by scaling\ntest-time computation through long chain-of-thought reasoning. However,\ntransformer-based models are inherently limited in extending context length due\nto their quadratic computational complexity and linear memory requirements. In\nthis paper, we introduce a novel hybrid linear RNN reasoning model, M1, built\non the Mamba architecture, which allows memory-efficient inference. Our\napproach leverages a distillation process from existing reasoning models and is\nfurther enhanced through RL training. Experimental results on the AIME and MATH\nbenchmarks show that M1 not only outperforms previous linear RNN models but\nalso matches the performance of state-of-the-art Deepseek R1 distilled\nreasoning models at a similar scale. We also compare our generation speed with\na highly performant general purpose inference engine, vLLM, and observe more\nthan a 3x speedup compared to a same size transformer. With throughput speedup,\nwe are able to achieve higher accuracy compared to DeepSeek R1 distilled\ntransformer reasoning models under a fixed generation time budget using\nself-consistency voting. Overall, we introduce a hybrid Mamba reasoning model\nand provide a more effective approach to scaling test-time generation using\nself-consistency or long chain of thought reasoning.", "published": "2025-04-14 17:38:25", "link": "http://arxiv.org/abs/2504.10449v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Learning with Positive and Imperfect Unlabeled Data", "abstract": "We study the problem of learning binary classifiers from positive and\nunlabeled data when the unlabeled data distribution is shifted, which we call\nPositive and Imperfect Unlabeled (PIU) Learning. In the absence of covariate\nshifts, i.e., with perfect unlabeled data, Denis (1998) reduced this problem to\nlearning under Massart noise; however, that reduction fails under even slight\nshifts.\n  Our main results on PIU learning are the characterizations of the sample\ncomplexity of PIU learning and a computationally and sample-efficient algorithm\nachieving a misclassification error $\\varepsilon$. We further show that our\nresults lead to new algorithms for several related problems.\n  1. Learning from smooth distributions: We give algorithms that learn\ninteresting concept classes from only positive samples under smooth feature\ndistributions, bypassing known existing impossibility results and contributing\nto recent advances in smoothened learning (Haghtalab et al, J.ACM'24)\n(Chandrasekaran et al., COLT'24).\n  2. Learning with a list of unlabeled distributions: We design new algorithms\nthat apply to a broad class of concept classes under the assumption that we are\ngiven a list of unlabeled distributions, one of which--unknown to the\nlearner--is $O(1)$-close to the true feature distribution.\n  3. Estimation in the presence of unknown truncation: We give the first\npolynomial sample and time algorithm for estimating the parameters of an\nexponential family distribution from samples truncated to an unknown set\napproximable by polynomials in $L_1$-norm. This improves the algorithm by Lee\net al. (FOCS'24) that requires approximation in $L_2$-norm.\n  4. Detecting truncation: We present new algorithms for detecting whether\ngiven samples have been truncated (or not) for a broad class of non-product\ndistributions, including non-product distributions, improving the algorithm by\nDe et al. (STOC'24).", "published": "2025-04-14 17:19:29", "link": "http://arxiv.org/abs/2504.10428v1", "categories": ["stat.ML", "cs.DS", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Foundation models for electronic health records: representation dynamics and transferability", "abstract": "Foundation models (FMs) trained on electronic health records (EHRs) have\nshown strong performance on a range of clinical prediction tasks. However,\nadapting these models to local health systems remains challenging due to\nlimited data availability and resource constraints. In this study, we\ninvestigated what these models learn and evaluated the transferability of an FM\ntrained on MIMIC-IV to an institutional EHR dataset at the University of\nChicago Medical Center. We assessed their ability to identify outlier patients\nand examined representation-space patient trajectories in relation to future\nclinical outcomes. We also evaluated the performance of supervised fine-tuned\nclassifiers on both source and target datasets. Our findings offer insights\ninto the adaptability of FMs across different healthcare systems, highlight\nconsiderations for their effective implementation, and provide an empirical\nanalysis of the underlying factors that contribute to their predictive\nperformance.", "published": "2025-04-14 17:09:05", "link": "http://arxiv.org/abs/2504.10422v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Satellite Federated Fine-Tuning for Foundation Models in Space Computing Power Networks", "abstract": "Advancements in artificial intelligence (AI) and low-earth orbit (LEO)\nsatellites have promoted the application of large remote sensing foundation\nmodels for various downstream tasks. However, direct downloading of these\nmodels for fine-tuning on the ground is impeded by privacy concerns and limited\nbandwidth. Satellite federated learning (FL) offers a solution by enabling\nmodel fine-tuning directly on-board satellites and aggregating model updates\nwithout data downloading. Nevertheless, for large foundation models, the\ncomputational capacity of satellites is insufficient to support effective\non-board fine-tuning in traditional satellite FL frameworks. To address these\nchallenges, we propose a satellite-ground collaborative federated fine-tuning\nframework. The key of the framework lies in how to reasonably decompose and\nallocate model components to alleviate insufficient on-board computation\ncapabilities. During fine-tuning, satellites exchange intermediate results with\nground stations or other satellites for forward propagation and back\npropagation, which brings communication challenges due to the special\ncommunication topology of space transmission networks, such as intermittent\nsatellite-ground communication, short duration of satellite-ground\ncommunication windows, and unstable inter-orbit inter-satellite links (ISLs).\nTo reduce transmission delays, we further introduce tailored communication\nstrategies that integrate both communication and computing resources.\nSpecifically, we propose a parallel intra-orbit communication strategy, a\ntopology-aware satellite-ground communication strategy, and a\nlatency-minimalization inter-orbit communication strategy to reduce space\ncommunication costs. Simulation results demonstrate significant reductions in\ntraining time with improvements of approximately 33%.", "published": "2025-04-14 16:52:34", "link": "http://arxiv.org/abs/2504.10403v1", "categories": ["cs.LG", "cs.DC", "cs.NI"], "primary_category": "cs.LG"}
{"title": "Inferring genotype-phenotype maps using attention models", "abstract": "Predicting phenotype from genotype is a central challenge in genetics.\nTraditional approaches in quantitative genetics typically analyze this problem\nusing methods based on linear regression. These methods generally assume that\nthe genetic architecture of complex traits can be parameterized in terms of an\nadditive model, where the effects of loci are independent, plus (in some cases)\npairwise epistatic interactions between loci. However, these models struggle to\nanalyze more complex patterns of epistasis or subtle gene-environment\ninteractions. Recent advances in machine learning, particularly attention-based\nmodels, offer a promising alternative. Initially developed for natural language\nprocessing, attention-based models excel at capturing context-dependent\ninteractions and have shown exceptional performance in predicting protein\nstructure and function. Here, we apply attention-based models to quantitative\ngenetics. We analyze the performance of this attention-based approach in\npredicting phenotype from genotype using simulated data across a range of\nmodels with increasing epistatic complexity, and using experimental data from a\nrecent quantitative trait locus mapping study in budding yeast. We find that\nour model demonstrates superior out-of-sample predictions in epistatic regimes\ncompared to standard methods. We also explore a more general multi-environment\nattention-based model to jointly analyze genotype-phenotype maps across\nmultiple environments and show that such architectures can be used for\n\"transfer learning\" - predicting phenotypes in novel environments with limited\ntraining data.", "published": "2025-04-14 16:32:17", "link": "http://arxiv.org/abs/2504.10388v1", "categories": ["q-bio.GN", "cs.LG", "q-bio.PE"], "primary_category": "q-bio.GN"}
{"title": "Ctrl-Z: Controlling AI Agents via Resampling", "abstract": "Control evaluations measure whether monitoring and security protocols for AI\nsystems prevent intentionally subversive AI models from causing harm. Our work\npresents the first control evaluation performed in an agent environment. We\nconstruct BashBench, a dataset of 257 challenging multi-step system\nadministration tasks, and evaluate whether various safety measures can prevent\nan adversarially constructed AI agent from covertly downloading and executing\nmalicious code in this environment. This multi-step setting introduces new\nattack and defense dynamics, which we investigate in order to design novel\ncontrol protocols that prevent safety failures without hindering the ability of\nnon-malicious agents to perform useful work. We introduce a class of control\nprotocols called resample protocols that dynamically take additional samples of\ncertain actions. We find these protocols significantly improve on existing\ntechniques by selectively blocking the AI agent from executing suspicious code\nand incriminating the agent by generating additional examples of dangerous\nbehavior. We measure the tradeoff between attack prevention and usefulness; our\nbest protocol combines resampling with analysis of previous steps, reducing the\nsuccess rate of attacks from 58% to 7% at a 5% cost to the performance of a\nnon-malicious agent.", "published": "2025-04-14 16:22:11", "link": "http://arxiv.org/abs/2504.10374v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "DUE: A Deep Learning Framework and Library for Modeling Unknown Equations", "abstract": "Equations, particularly differential equations, are fundamental for\nunderstanding natural phenomena and predicting complex dynamics across various\nscientific and engineering disciplines. However, the governing equations for\nmany complex systems remain unknown due to intricate underlying mechanisms.\nRecent advancements in machine learning and data science offer a new paradigm\nfor modeling unknown equations from measurement or simulation data. This\nparadigm shift, known as data-driven discovery or modeling, stands at the\nforefront of AI for science, with significant progress made in recent years. In\nthis paper, we introduce a systematic framework for data-driven modeling of\nunknown equations using deep learning. This versatile framework is capable of\nlearning unknown ODEs, PDEs, DAEs, IDEs, SDEs, reduced or partially observed\nsystems, and non-autonomous differential equations. Based on this framework, we\nhave developed Deep Unknown Equations (DUE), an open-source software package\ndesigned to facilitate the data-driven modeling of unknown equations using\nmodern deep learning techniques. DUE serves as an educational tool for\nclassroom instruction, enabling students and newcomers to gain hands-on\nexperience with differential equations, data-driven modeling, and contemporary\ndeep learning approaches such as FNN, ResNet, generalized ResNet, operator\nsemigroup networks (OSG-Net), and Transformers. Additionally, DUE is a\nversatile and accessible toolkit for researchers across various scientific and\nengineering fields. It is applicable not only for learning unknown equations\nfrom data but also for surrogate modeling of known, yet complex, equations that\nare costly to solve using traditional numerical methods. We provide detailed\ndescriptions of DUE and demonstrate its capabilities through diverse examples,\nwhich serve as templates that can be easily adapted for other applications.", "published": "2025-04-14 16:20:55", "link": "http://arxiv.org/abs/2504.10373v1", "categories": ["cs.LG", "cs.NA", "math.DS", "math.NA", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Domain-Adversarial Neural Network and Explainable AI for Reducing Tissue-of-Origin Signal in Pan-cancer Mortality Classification", "abstract": "Tissue-of-origin signals dominate pan-cancer gene expression, often obscuring\nmolecular features linked to patient survival. This hampers the discovery of\ngeneralizable biomarkers, as models tend to overfit tissue-specific patterns\nrather than capture survival-relevant signals. To address this, we propose a\nDomain-Adversarial Neural Network (DANN) trained on TCGA RNA-seq data to learn\nrepresentations less biased by tissue and more focused on survival. Identifying\ntissue-independent genetic profiles is key to revealing core cancer programs.\nWe assess the DANN using: (1) Standard SHAP, based on the original input space\nand DANN's mortality classifier; (2) A layer-aware strategy applied to hidden\nactivations, including an unsupervised manifold from raw activations and a\nsupervised manifold from mortality-specific SHAP values. Standard SHAP remains\nconfounded by tissue signals due to biases inherent in its computation. The raw\nactivation manifold was dominated by high-magnitude activations, which masked\nsubtle tissue and mortality-related signals. In contrast, the layer-aware SHAP\nmanifold offers improved low-dimensional representations of both tissue and\nmortality signals, independent of activation strength, enabling subpopulation\nstratification and pan-cancer identification of survival-associated genes.", "published": "2025-04-14 15:51:39", "link": "http://arxiv.org/abs/2504.10343v1", "categories": ["cs.LG", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "Siamese Network with Dual Attention for EEG-Driven Social Learning: Bridging the Human-Robot Gap in Long-Tail Autonomous Driving", "abstract": "Robots with wheeled, quadrupedal, or humanoid forms are increasingly\nintegrated into built environments. However, unlike human social learning, they\nlack a critical pathway for intrinsic cognitive development, namely, learning\nfrom human feedback during interaction. To understand human ubiquitous\nobservation, supervision, and shared control in dynamic and uncertain\nenvironments, this study presents a brain-computer interface (BCI) framework\nthat enables classification of Electroencephalogram (EEG) signals to detect\ncognitively demanding and safety-critical events. As a timely and motivating\nco-robotic engineering application, we simulate a human-in-the-loop scenario to\nflag risky events in semi-autonomous robotic driving-representative of\nlong-tail cases that pose persistent bottlenecks to the safety performance of\nsmart mobility systems and robotic vehicles. Drawing on recent advances in\nfew-shot learning, we propose a dual-attention Siamese convolutional network\npaired with Dynamic Time Warping Barycenter Averaging approach to generate\nrobust EEG-encoded signal representations. Inverse source localization reveals\nactivation in Broadman areas 4 and 9, indicating perception-action coupling\nduring task-relevant mental imagery. The model achieves 80% classification\naccuracy under data-scarce conditions and exhibits a nearly 100% increase in\nthe utility of salient features compared to state-of-the-art methods, as\nmeasured through integrated gradient attribution. Beyond performance, this\nstudy contributes to our understanding of the cognitive architecture required\nfor BCI agents-particularly the role of attention and memory mechanisms-in\ncategorizing diverse mental states and supporting both inter- and intra-subject\nadaptation. Overall, this research advances the development of cognitive\nrobotics and socially guided learning for service robots in complex built\nenvironments.", "published": "2025-04-14 15:06:17", "link": "http://arxiv.org/abs/2504.10296v1", "categories": ["cs.RO", "cs.HC", "cs.LG"], "primary_category": "cs.RO"}
{"title": "$\u03b1$-Flow: A Unified Framework for Continuous-State Discrete Flow Matching Models", "abstract": "Recent efforts have extended the flow-matching framework to discrete\ngenerative modeling. One strand of models directly works with the continuous\nprobabilities instead of discrete tokens, which we colloquially refer to as\nContinuous-State Discrete Flow Matching (CS-DFM). Existing CS-DFM models differ\nsignificantly in their representations and geometric assumptions. This work\npresents a unified framework for CS-DFM models, under which the existing\nvariants can be understood as operating on different $\\alpha$-representations\nof probabilities. Building upon the theory of information geometry, we\nintroduce $\\alpha$-Flow, a family of CS-DFM models that adheres to the\ncanonical $\\alpha$-geometry of the statistical manifold, and demonstrate its\noptimality in minimizing the generalized kinetic energy. Theoretically, we show\nthat the flow matching loss for $\\alpha$-flow establishes a unified variational\nbound for the discrete negative log-likelihood. We comprehensively evaluate\ndifferent instantiations of $\\alpha$-flow on various discrete generation\ndomains to demonstrate their effectiveness in discrete generative modeling,\nincluding intermediate values whose geometries have never been explored before.\n$\\alpha$-flow significantly outperforms its discrete-state counterpart in image\nand protein sequence generation and better captures the entropy in language\nmodeling.", "published": "2025-04-14 14:51:45", "link": "http://arxiv.org/abs/2504.10283v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Sidecar: A Structure-Preserving Framework for Solving Partial Differential Equations with Neural Networks", "abstract": "Solving partial differential equations (PDEs) with neural networks (NNs) has\nshown great potential in various scientific and engineering fields. However,\nmost existing NN solvers mainly focus on satisfying the given PDEs, without\nexplicitly considering intrinsic physical properties such as mass conservation\nor energy dissipation. This limitation can result in unstable or nonphysical\nsolutions, particularly in long-term simulations. To address this issue, we\npropose Sidecar, a novel framework that enhances the accuracy and physical\nconsistency of existing NN solvers by incorporating structure-preserving\nknowledge. Inspired by the Time-Dependent Spectral Renormalization (TDSR)\napproach, our Sidecar framework introduces a small copilot network, which is\ntrained to guide the existing NN solver in preserving physical structure. This\nframework is designed to be highly flexible, enabling the incorporation of\nstructure-preserving principles from diverse PDEs into a wide range of NN\nsolvers. Our experimental results on benchmark PDEs demonstrate the improvement\nof the existing neural network solvers in terms of accuracy and consistency\nwith structure-preserving properties.", "published": "2025-04-14 14:40:11", "link": "http://arxiv.org/abs/2504.10273v1", "categories": ["cs.LG", "cs.NA", "math.NA", "65M99, 68T07, 35L65"], "primary_category": "cs.LG"}
{"title": "TinyverseGP: Towards a Modular Cross-domain Benchmarking Framework for Genetic Programming", "abstract": "Over the years, genetic programming (GP) has evolved, with many proposed\nvariations, especially in how they represent a solution. Being essentially a\nprogram synthesis algorithm, it is capable of tackling multiple problem\ndomains. Current benchmarking initiatives are fragmented, as the different\nrepresentations are not compared with each other and their performance is not\nmeasured across the different domains. In this work, we propose a unified\nframework, dubbed TinyverseGP (inspired by tinyGP), which provides support to\nmultiple representations and problem domains, including symbolic regression,\nlogic synthesis and policy search.", "published": "2025-04-14 14:14:27", "link": "http://arxiv.org/abs/2504.10253v1", "categories": ["cs.NE", "cs.LG", "cs.SC"], "primary_category": "cs.NE"}
{"title": "Adaptive Sensor Steering Strategy Using Deep Reinforcement Learning for Dynamic Data Acquisition in Digital Twins", "abstract": "This paper introduces a sensor steering methodology based on deep\nreinforcement learning to enhance the predictive accuracy and decision support\ncapabilities of digital twins by optimising the data acquisition process.\nTraditional sensor placement techniques are often constrained by one-off\noptimisation strategies, which limit their applicability for online\napplications requiring continuous informative data assimilation. The proposed\napproach addresses this limitation by offering an adaptive framework for sensor\nplacement within the digital twin paradigm. The sensor placement problem is\nformulated as a Markov decision process, enabling the training and deployment\nof an agent capable of dynamically repositioning sensors in response to the\nevolving conditions of the physical structure as represented by the digital\ntwin. This ensures that the digital twin maintains a highly representative and\nreliable connection to its physical counterpart. The proposed framework is\nvalidated through a series of comprehensive case studies involving a cantilever\nplate structure subjected to diverse conditions, including healthy and damaged\nconditions. The results demonstrate the capability of the deep reinforcement\nlearning agent to adaptively reposition sensors improving the quality of data\nacquisition and hence enhancing the overall accuracy of digital twins.", "published": "2025-04-14 14:11:00", "link": "http://arxiv.org/abs/2504.10248v1", "categories": ["stat.ML", "cs.LG", "eess.SP"], "primary_category": "stat.ML"}
{"title": "GNN-ACLP: Graph Neural Networks based Analog Circuit Link Prediction", "abstract": "Circuit link prediction identifying missing component connections from\nincomplete netlists is crucial in automating analog circuit design. However,\nexisting methods face three main challenges: 1) Insufficient use of topological\npatterns in circuit graphs reduces prediction accuracy; 2) Data scarcity due to\nthe complexity of annotations hinders model generalization; 3) Limited\nadaptability to various netlist formats. We propose GNN-ACLP, a Graph Neural\nNetworks (GNNs) based framework featuring three innovations to tackle these\nchallenges. First, we introduce the SEAL (Subgraphs, Embeddings, and Attributes\nfor Link Prediction) framework and achieve port-level accuracy in circuit link\nprediction. Second, we propose Netlist Babel Fish, a netlist format conversion\ntool leveraging retrieval-augmented generation (RAG) with large language model\n(LLM) to enhance the compatibility of netlist formats. Finally, we construct\nSpiceNetlist, a comprehensive dataset that contains 775 annotated circuits\nacross 10 different classes of components. The experimental results demonstrate\nan improvement of 15.05% on the SpiceNetlist dataset and 12.01% on the\nImage2Net dataset over the existing approach.", "published": "2025-04-14 14:02:09", "link": "http://arxiv.org/abs/2504.10240v1", "categories": ["cs.AR", "cs.LG"], "primary_category": "cs.AR"}
{"title": "A Model Zoo of Vision Transformers", "abstract": "The availability of large, structured populations of neural networks - called\n'model zoos' - has led to the development of a multitude of downstream tasks\nranging from model analysis, to representation learning on model weights or\ngenerative modeling of neural network parameters. However, existing model zoos\nare limited in size and architecture and neglect the transformer, which is\namong the currently most successful neural network architectures. We address\nthis gap by introducing the first model zoo of vision transformers (ViT). To\nbetter represent recent training approaches, we develop a new blueprint for\nmodel zoo generation that encompasses both pre-training and fine-tuning steps,\nand publish 250 unique models. They are carefully generated with a large span\nof generating factors, and their diversity is validated using a thorough choice\nof weight-space and behavioral metrics. To further motivate the utility of our\nproposed dataset, we suggest multiple possible applications grounded in both\nextensive exploratory experiments and a number of examples from the existing\nliterature. By extending previous lines of similar work, our model zoo allows\nresearchers to push their model population-based methods from the small model\nregime to state-of-the-art architectures. We make our model zoo available at\ngithub.com/ModelZoos/ViTModelZoo.", "published": "2025-04-14 13:52:26", "link": "http://arxiv.org/abs/2504.10231v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "ROSFD: Robust Online Streaming Fraud Detection with Resilience to Concept Drift in Data Streams", "abstract": "Continuous generation of streaming data from diverse sources, such as online\ntransactions and digital interactions, necessitates timely fraud detection.\nTraditional batch processing methods often struggle to capture the rapidly\nevolving patterns of fraudulent activities. This paper highlights the critical\nimportance of processing streaming data for effective fraud detection. To\naddress the inherent challenges of latency, scalability, and concept drift in\nstreaming environments, we propose a robust online streaming fraud detection\n(ROSFD) framework. Our proposed framework comprises two key stages: (i) Stage\nOne: Offline Model Initialization. In this initial stage, a model is built in\noffline settings using incremental learning principles to overcome the\n\"cold-start\" problem. (ii) Stage Two: Real-time Model Adaptation. In this\ndynamic stage, drift detection algorithms (viz.,, DDM, EDDM, and ADWIN) are\nemployed to identify concept drift in the incoming data stream and\nincrementally train the model accordingly. This \"train-only-when-required\"\nstrategy drastically reduces the number of retrains needed without\nsignificantly impacting the area under the receiver operating characteristic\ncurve (AUC). Overall, ROSFD utilizing ADWIN as the drift detection method\ndemonstrated the best performance among the employed methods. In terms of model\nefficacy, Adaptive Random Forest consistently outperformed other models,\nachieving the highest AUC in four out of five datasets.", "published": "2025-04-14 13:50:23", "link": "http://arxiv.org/abs/2504.10229v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Challenges in interpretability of additive models", "abstract": "We review generalized additive models as a type of ``transparent'' model that\nhas recently seen renewed interest in the deep learning community as neural\nadditive models. We highlight multiple types of nonidentifiability in this\nmodel class and discuss challenges in interpretability, arguing for restraint\nwhen claiming ``interpretability'' or ``suitability for safety-critical\napplications'' of such models.", "published": "2025-04-14 12:24:17", "link": "http://arxiv.org/abs/2504.10169v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Continual learning for rotating machinery fault diagnosis with cross-domain environmental and operational variations", "abstract": "Although numerous machine learning models exist to detect issues like rolling\nbearing strain and deformation, typically caused by improper mounting,\noverloading, or poor lubrication, these models often struggle to isolate faults\nfrom the noise of real-world operational and environmental variability.\nConditions such as variable loads, high temperatures, stress, and rotational\nspeeds can mask early signs of failure, making reliable detection challenging.\nTo address these limitations, this work proposes a continual deep learning\napproach capable of learning across domains that share underlying structure\nover time. This approach goes beyond traditional accuracy metrics by addressing\nfour second-order challenges: catastrophic forgetting (where new learning\noverwrites past knowledge), lack of plasticity (where models fail to adapt to\nnew data), forward transfer (using past knowledge to improve future learning),\nand backward transfer (refining past knowledge with insights from new domains).\nThe method comprises a feature generator and domain-specific classifiers,\nallowing capacity to grow as new domains emerge with minimal interference,\nwhile an experience replay mechanism selectively revisits prior domains to\nmitigate forgetting. Moreover, nonlinear dependencies across domains are\nexploited by prioritizing replay from those with the highest prior errors,\nrefining models based on most informative past experiences. Experiments show\nhigh average domain accuracy (up to 88.96%), with forgetting measures as low as\n.0027 across non-stationary class-incremental environments.", "published": "2025-04-14 12:02:32", "link": "http://arxiv.org/abs/2504.10151v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "The Impact of Model Zoo Size and Composition on Weight Space Learning", "abstract": "Re-using trained neural network models is a common strategy to reduce\ntraining cost and transfer knowledge. Weight space learning - using the weights\nof trained models as data modality - is a promising new field to re-use\npopulations of pre-trained models for future tasks. Approaches in this field\nhave demonstrated high performance both on model analysis and weight generation\ntasks. However, until now their learning setup requires homogeneous model zoos\nwhere all models share the same exact architecture, limiting their capability\nto generalize beyond the population of models they saw during training. In this\nwork, we remove this constraint and propose a modification to a common weight\nspace learning method to accommodate training on heterogeneous populations of\nmodels. We further investigate the resulting impact of model diversity on\ngenerating unseen neural network model weights for zero-shot knowledge\ntransfer. Our extensive experimental evaluation shows that including models\nwith varying underlying image datasets has a high impact on performance and\ngeneralization, for both in- and out-of-distribution settings. Code is\navailable on github.com/HSG-AIML/MultiZoo-SANE.", "published": "2025-04-14 11:54:06", "link": "http://arxiv.org/abs/2504.10141v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Conditional Distribution Compression via the Kernel Conditional Mean Embedding", "abstract": "Existing distribution compression methods, like Kernel Herding (KH), were\noriginally developed for unlabelled data. However, no existing approach\ndirectly compresses the conditional distribution of labelled data. To address\nthis gap, we first introduce the Average Maximum Conditional Mean Discrepancy\n(AMCMD), a natural metric for comparing conditional distributions. We then\nderive a consistent estimator for the AMCMD and establish its rate of\nconvergence. Next, we make a key observation: in the context of distribution\ncompression, the cost of constructing a compressed set targeting the AMCMD can\nbe reduced from $\\mathcal{O}(n^3)$ to $\\mathcal{O}(n)$. Building on this, we\nextend the idea of KH to develop Average Conditional Kernel Herding (ACKH), a\nlinear-time greedy algorithm that constructs a compressed set targeting the\nAMCMD. To better understand the advantages of directly compressing the\nconditional distribution rather than doing so via the joint distribution, we\nintroduce Joint Kernel Herding (JKH), a straightforward adaptation of KH\ndesigned to compress the joint distribution of labelled data. While herding\nmethods provide a simple and interpretable selection process, they rely on a\ngreedy heuristic. To explore alternative optimisation strategies, we propose\nJoint Kernel Inducing Points (JKIP) and Average Conditional Kernel Inducing\nPoints (ACKIP), which jointly optimise the compressed set while maintaining\nlinear complexity. Experiments show that directly preserving conditional\ndistributions with ACKIP outperforms both joint distribution compression (via\nJKH and JKIP) and the greedy selection used in ACKH. Moreover, we see that JKIP\nconsistently outperforms JKH.", "published": "2025-04-14 11:53:29", "link": "http://arxiv.org/abs/2504.10139v1", "categories": ["stat.ML", "cs.LG", "stat.CO", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Uncertainty Propagation in the Fast Fourier Transform", "abstract": "We address the problem of uncertainty propagation in the discrete Fourier\ntransform by modeling the fast Fourier transform as a factor graph. Building on\nthis representation, we propose an efficient framework for approximate Bayesian\ninference using belief propagation (BP) and expectation propagation, extending\nits applicability beyond Gaussian assumptions. By leveraging an appropriate BP\nmessage representation and a suitable schedule, our method achieves stable\nconvergence with accurate mean and variance estimates. Numerical experiments in\nrepresentative scenarios from communications demonstrate the practical\npotential of the proposed framework for uncertainty-aware inference in\nprobabilistic systems operating across both time and frequency domain.", "published": "2025-04-14 11:47:42", "link": "http://arxiv.org/abs/2504.10136v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "STaRFormer: Semi-Supervised Task-Informed Representation Learning via Dynamic Attention-Based Regional Masking for Sequential Data", "abstract": "Accurate predictions using sequential spatiotemporal data are crucial for\nvarious applications. Utilizing real-world data, we aim to learn the intent of\na smart device user within confined areas of a vehicle's surroundings. However,\nin real-world scenarios, environmental factors and sensor limitations result in\nnon-stationary and irregularly sampled data, posing significant challenges. To\naddress these issues, we developed a Transformer-based approach, STaRFormer,\nwhich serves as a universal framework for sequential modeling. STaRFormer\nemploys a novel, dynamic attention-based regional masking scheme combined with\nsemi-supervised contrastive learning to enhance task-specific latent\nrepresentations. Comprehensive experiments on 15 datasets varying in types\n(including non-stationary and irregularly sampled), domains, sequence lengths,\ntraining samples, and applications, demonstrate the efficacy and practicality\nof STaRFormer. We achieve notable improvements over state-of-the-art\napproaches. Code and data will be made available.", "published": "2025-04-14 11:03:19", "link": "http://arxiv.org/abs/2504.10097v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Towards Scalable Bayesian Optimization via Gradient-Informed Bayesian Neural Networks", "abstract": "Bayesian optimization (BO) is a widely used method for data-driven\noptimization that generally relies on zeroth-order data of objective function\nto construct probabilistic surrogate models. These surrogates guide the\nexploration-exploitation process toward finding global optimum. While Gaussian\nprocesses (GPs) are commonly employed as surrogates of the unknown objective\nfunction, recent studies have highlighted the potential of Bayesian neural\nnetworks (BNNs) as scalable and flexible alternatives. Moreover, incorporating\ngradient observations into GPs, when available, has been shown to improve BO\nperformance. However, the use of gradients within BNN surrogates remains\nunexplored. By leveraging automatic differentiation, gradient information can\nbe seamlessly integrated into BNN training, resulting in more informative\nsurrogates for BO. We propose a gradient-informed loss function for BNN\ntraining, effectively augmenting function observations with local gradient\ninformation. The effectiveness of this approach is demonstrated on well-known\nbenchmarks in terms of improved BNN predictions and faster BO convergence as\nthe number of decision variables increases.", "published": "2025-04-14 10:21:08", "link": "http://arxiv.org/abs/2504.10076v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Undermining Federated Learning Accuracy in EdgeIoT via Variational Graph Auto-Encoders", "abstract": "EdgeIoT represents an approach that brings together mobile edge computing\nwith Internet of Things (IoT) devices, allowing for data processing close to\nthe data source. Sending source data to a server is bandwidth-intensive and may\ncompromise privacy. Instead, federated learning allows each device to upload a\nshared machine-learning model update with locally processed data. However, this\ntechnique, which depends on aggregating model updates from various IoT devices,\nis vulnerable to attacks from malicious entities that may inject harmful data\ninto the learning process. This paper introduces a new attack method targeting\nfederated learning in EdgeIoT, known as data-independent model manipulation\nattack. This attack does not rely on training data from the IoT devices but\ninstead uses an adversarial variational graph auto-encoder (AV-GAE) to create\nmalicious model updates by analyzing benign model updates intercepted during\ncommunication. AV-GAE identifies and exploits structural relationships between\nbenign models and their training data features. By manipulating these\nstructural correlations, the attack maximizes the training loss of the\nfederated learning system, compromising its overall effectiveness.", "published": "2025-04-14 10:09:38", "link": "http://arxiv.org/abs/2504.10067v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Using Reinforcement Learning to Integrate Subjective Wellbeing into Climate Adaptation Decision Making", "abstract": "Subjective wellbeing is a fundamental aspect of human life, influencing life\nexpectancy and economic productivity, among others. Mobility plays a critical\nrole in maintaining wellbeing, yet the increasing frequency and intensity of\nboth nuisance and high-impact floods due to climate change are expected to\nsignificantly disrupt access to activities and destinations, thereby affecting\noverall wellbeing. Addressing climate adaptation presents a complex challenge\nfor policymakers, who must select and implement policies from a broad set of\noptions with varying effects while managing resource constraints and uncertain\nclimate projections. In this work, we propose a multi-modular framework that\nuses reinforcement learning as a decision-support tool for climate adaptation\nin Copenhagen, Denmark. Our framework integrates four interconnected\ncomponents: long-term rainfall projections, flood modeling, transport\naccessibility, and wellbeing modeling. This approach enables decision-makers to\nidentify spatial and temporal policy interventions that help sustain or enhance\nsubjective wellbeing over time. By modeling climate adaptation as an open-ended\nsystem, our framework provides a structured framework for exploring and\nevaluating adaptation policy pathways. In doing so, it supports policymakers to\nmake informed decisions that maximize wellbeing in the long run.", "published": "2025-04-14 09:34:12", "link": "http://arxiv.org/abs/2504.10031v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Improving Controller Generalization with Dimensionless Markov Decision Processes", "abstract": "Controllers trained with Reinforcement Learning tend to be very specialized\nand thus generalize poorly when their testing environment differs from their\ntraining one. We propose a Model-Based approach to increase generalization\nwhere both world model and policy are trained in a dimensionless state-action\nspace. To do so, we introduce the Dimensionless Markov Decision Process\n($\\Pi$-MDP): an extension of Contextual-MDPs in which state and action spaces\nare non-dimensionalized with the Buckingham-$\\Pi$ theorem. This procedure\ninduces policies that are equivariant with respect to changes in the context of\nthe underlying dynamics. We provide a generic framework for this approach and\napply it to a model-based policy search algorithm using Gaussian Process\nmodels. We demonstrate the applicability of our method on simulated actuated\npendulum and cartpole systems, where policies trained on a single environment\nare robust to shifts in the distribution of the context.", "published": "2025-04-14 09:08:53", "link": "http://arxiv.org/abs/2504.10006v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "FLoRA: Sample-Efficient Preference-based RL via Low-Rank Style Adaptation of Reward Functions", "abstract": "Preference-based reinforcement learning (PbRL) is a suitable approach for\nstyle adaptation of pre-trained robotic behavior: adapting the robot's policy\nto follow human user preferences while still being able to perform the original\ntask. However, collecting preferences for the adaptation process in robotics is\noften challenging and time-consuming. In this work we explore the adaptation of\npre-trained robots in the low-preference-data regime. We show that, in this\nregime, recent adaptation approaches suffer from catastrophic reward forgetting\n(CRF), where the updated reward model overfits to the new preferences, leading\nthe agent to become unable to perform the original task. To mitigate CRF, we\npropose to enhance the original reward model with a small number of parameters\n(low-rank matrices) responsible for modeling the preference adaptation. Our\nevaluation shows that our method can efficiently and effectively adjust robotic\nbehavior to human preferences across simulation benchmark tasks and multiple\nreal-world robotic tasks.", "published": "2025-04-14 09:04:14", "link": "http://arxiv.org/abs/2504.10002v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Physical Scales Matter: The Role of Receptive Fields and Advection in Satellite-Based Thunderstorm Nowcasting with Convolutional Neural Networks", "abstract": "The focus of nowcasting development is transitioning from physically\nmotivated advection methods to purely data-driven Machine Learning (ML)\napproaches. Nevertheless, recent work indicates that incorporating advection\ninto the ML value chain has improved skill for radar-based precipitation\nnowcasts. However, the generality of this approach and the underlying causes\nremain unexplored. This study investigates the generality by probing the\napproach on satellite-based thunderstorm nowcasts for the first time. Resorting\nto a scale argument, we then put forth an explanation when and why skill\nimprovements can be expected. In essence, advection guarantees that\nthunderstorm patterns relevant for nowcasting are contained in the receptive\nfield at long lead times. To test our hypotheses, we train ResU-Nets solving\nsegmentation tasks with lightning observations as ground truth. The input of\nthe Baseline Neural Network (BNN) are short time series of multispectral\nsatellite imagery and lightning observations, whereas the Advection-Informed\nNeural Network (AINN) additionally receives the Lagrangian persistence nowcast\nof all input channels at the desired lead time. Overall, we find only a minor\nskill improvement of the AINN over the BNN when considering fully averaged\nscores. However, assessing skill conditioned on lead time and wind speed, we\ndemonstrate that our scale argument correctly predicts the onset of skill\nimprovement of the AINN over the BNN after 2h lead time. We confirm that\ngenerally advection becomes gradually more important with longer lead times and\nhigher wind speeds. Our work accentuates the importance of considering and\nincorporating the underlying physical scales when designing ML based\nforecasting models.", "published": "2025-04-14 08:57:59", "link": "http://arxiv.org/abs/2504.09994v1", "categories": ["physics.ao-ph", "cs.LG", "I.2.6; J.2"], "primary_category": "physics.ao-ph"}
{"title": "AimTS: Augmented Series and Image Contrastive Learning for Time Series Classification", "abstract": "Time series classification (TSC) is an important task in time series\nanalysis. Existing TSC methods mainly train on each single domain separately,\nsuffering from a degradation in accuracy when the samples for training are\ninsufficient in certain domains. The pre-training and fine-tuning paradigm\nprovides a promising direction for solving this problem. However, time series\nfrom different domains are substantially divergent, which challenges the\neffective pre-training on multi-source data and the generalization ability of\npre-trained models. To handle this issue, we introduce Augmented Series and\nImage Contrastive Learning for Time Series Classification (AimTS), a\npre-training framework that learns generalizable representations from\nmulti-source time series data. We propose a two-level prototype-based\ncontrastive learning method to effectively utilize various augmentations in\nmulti-source pre-training, which learns representations for TSC that can be\ngeneralized to different domains. In addition, considering augmentations within\nthe single time series modality are insufficient to fully address\nclassification problems with distribution shift, we introduce the image\nmodality to supplement structural information and establish a series-image\ncontrastive learning to improve the generalization of the learned\nrepresentations for TSC tasks. Extensive experiments show that after\nmulti-source pre-training, AimTS achieves good generalization performance,\nenabling efficient learning and even few-shot learning on various downstream\nTSC datasets.", "published": "2025-04-14 08:55:16", "link": "http://arxiv.org/abs/2504.09993v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "IsoSEL: Isometric Structural Entropy Learning for Deep Graph Clustering in Hyperbolic Space", "abstract": "Graph clustering is a longstanding topic in machine learning. In recent\nyears, deep learning methods have achieved encouraging results, but they still\nrequire predefined cluster numbers K, and typically struggle with imbalanced\ngraphs, especially in identifying minority clusters. The limitations motivate\nus to study a challenging yet practical problem: deep graph clustering without\nK considering the imbalance in reality. We approach this problem from a fresh\nperspective of information theory (i.e., structural information). In the\nliterature, structural information has rarely been touched in deep clustering,\nand the classic definition falls short in its discrete formulation, neglecting\nnode attributes and exhibiting prohibitive complexity. In this paper, we first\nestablish a new Differentiable Structural Information, generalizing the\ndiscrete formalism to continuous realm, so that the optimal partitioning tree,\nrevealing the cluster structure, can be created by the gradient\nbackpropagation. Theoretically, we demonstrate its capability in clustering\nwithout requiring K and identifying the minority clusters in imbalanced graphs,\nwhile reducing the time complexity to O(N) w.r.t. the number of nodes.\nSubsequently, we present a novel IsoSEL framework for deep graph clustering,\nwhere we design a hyperbolic neural network to learn the partitioning tree in\nthe Lorentz model of hyperbolic space, and further conduct Lorentz Tree\nContrastive Learning with isometric augmentation. As a result, the partitioning\ntree incorporates node attributes via mutual information maximization, while\nthe cluster assignment is refined by the proposed tree contrastive learning.\nExtensive experiments on five benchmark datasets show the IsoSEL outperforms 14\nrecent baselines by an average of +1.3% in NMI.", "published": "2025-04-14 08:21:41", "link": "http://arxiv.org/abs/2504.09970v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Towards Weaker Variance Assumptions for Stochastic Optimization", "abstract": "We revisit a classical assumption for analyzing stochastic gradient\nalgorithms where the squared norm of the stochastic subgradient (or the\nvariance for smooth problems) is allowed to grow as fast as the squared norm of\nthe optimization variable. We contextualize this assumption in view of its\ninception in the 1960s, its seemingly independent appearance in the recent\nliterature, its relationship to weakest-known variance assumptions for\nanalyzing stochastic gradient algorithms, and its relevance in deterministic\nproblems for non-Lipschitz nonsmooth convex optimization. We build on and\nextend a connection recently made between this assumption and the Halpern\niteration. For convex nonsmooth, and potentially stochastic, optimization, we\nanalyze horizon-free, anytime algorithms with last-iterate rates. For problems\nbeyond simple constrained optimization, such as convex problems with functional\nconstraints or regularized convex-concave min-max problems, we obtain rates for\noptimality measures that do not require boundedness of the feasible set.", "published": "2025-04-14 07:26:34", "link": "http://arxiv.org/abs/2504.09951v1", "categories": ["math.OC", "cs.LG", "stat.ML"], "primary_category": "math.OC"}
{"title": "TianQuan-Climate: A Subseasonal-to-Seasonal Global Weather Model via Incorporate Climatology State", "abstract": "Subseasonal forecasting serves as an important support for Sustainable\nDevelopment Goals (SDGs), such as climate challenges, agricultural yield and\nsustainable energy production. However, subseasonal forecasting is a complex\ntask in meteorology due to dissipating initial conditions and delayed external\nforces. Although AI models are increasingly pushing the boundaries of this\nforecasting limit, they face two major challenges: error accumulation and\nSmoothness. To address these two challenges, we propose Climate Furnace\nSubseasonal-to-Seasonal (TianQuan-Climate), a novel machine learning model\ndesigned to provide global daily mean forecasts up to 45 days, covering five\nupper-air atmospheric variables at 13 pressure levels and two surface\nvariables. Our proposed TianQuan-Climate has two advantages: 1) it utilizes a\nmulti-model prediction strategy to reduce system error impacts in long-term\nsubseasonal forecasts; 2) it incorporates a Content Fusion Module for\nclimatological integration and extends ViT with uncertainty blocks (UD-ViT) to\nimprove generalization by learning from uncertainty. We demonstrate the\neffectiveness of TianQuan-Climate on benchmarks for weather forecasting and\nclimate projections within the 15 to 45-day range, where TianQuan-Climate\noutperforms existing numerical and AI methods.", "published": "2025-04-14 07:02:34", "link": "http://arxiv.org/abs/2504.09940v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Multi-objective Bayesian Optimization With Mixed-categorical Design Variables for Expensive-to-evaluate Aeronautical Applications", "abstract": "This work aims at developing new methodologies to optimize computational\ncostly complex systems (e.g., aeronautical engineering systems). The proposed\nsurrogate-based method (often called Bayesian optimization) uses adaptive\nsampling to promote a trade-off between exploration and exploitation. Our\nin-house implementation, called SEGOMOE, handles a high number of design\nvariables (continuous, discrete or categorical) and nonlinearities by combining\nmixtures of experts for the objective and/or the constraints. Additionally, the\nmethod handles multi-objective optimization settings, as it allows the\nconstruction of accurate Pareto fronts with a minimal number of function\nevaluations. Different infill criteria have been implemented to handle multiple\nobjectives with or without constraints. The effectiveness of the proposed\nmethod was tested on practical aeronautical applications within the context of\nthe European Project AGILE 4.0 and demonstrated favorable results. A first\nexample concerns a retrofitting problem where a comparison between two\noptimizers have been made. A second example introduces hierarchical variables\nto deal with architecture system in order to design an aircraft family. The\nthird example increases drastically the number of categorical variables as it\ncombines aircraft design, supply chain and manufacturing process. In this\narticle, we show, on three different realistic problems, various aspects of our\noptimization codes thanks to the diversity of the treated aircraft problems.", "published": "2025-04-14 06:44:13", "link": "http://arxiv.org/abs/2504.09930v1", "categories": ["cs.LG", "math.OC", "stat.AP"], "primary_category": "cs.LG"}
{"title": "Moderate Actor-Critic Methods: Controlling Overestimation Bias via Expectile Loss", "abstract": "Overestimation is a fundamental characteristic of model-free reinforcement\nlearning (MF-RL), arising from the principles of temporal difference learning\nand the approximation of the Q-function. To address this challenge, we propose\na novel moderate target in the Q-function update, formulated as a convex\noptimization of an overestimated Q-function and its lower bound. Our primary\ncontribution lies in the efficient estimation of this lower bound through the\nlower expectile of the Q-value distribution conditioned on a state. Notably,\nour moderate target integrates seamlessly into state-of-the-art (SOTA) MF-RL\nalgorithms, including Deep Deterministic Policy Gradient (DDPG) and Soft Actor\nCritic (SAC). Experimental results validate the effectiveness of our moderate\ntarget in mitigating overestimation bias in DDPG, SAC, and distributional RL\nalgorithms.", "published": "2025-04-14 06:41:15", "link": "http://arxiv.org/abs/2504.09929v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Ember: A Compiler for Efficient Embedding Operations on Decoupled Access-Execute Architectures", "abstract": "Irregular embedding lookups are a critical bottleneck in recommender models,\nsparse large language models, and graph learning models. In this paper, we\nfirst demonstrate that, by offloading these lookups to specialized access\nunits, Decoupled Access-Execute (DAE) processors achieve 2.6$\\times$ higher\nperformance and 6.4$\\times$ higher performance/watt than GPUs on end-to-end\nmodels. Then, we propose the Ember compiler for automatically generating\noptimized DAE code from PyTorch and TensorFlow. Conversely from other DAE\ncompilers, Ember features multiple intermediate representations specifically\ndesigned for different optimization levels. In this way, Ember can implement\nall optimizations to match the performance of hand-written code, unlocking the\nfull potential of DAE architectures at scale.", "published": "2025-04-14 04:29:46", "link": "http://arxiv.org/abs/2504.09870v1", "categories": ["cs.AR", "cs.LG", "cs.PL", "C.1.2; C.1.3; D.3.4"], "primary_category": "cs.AR"}
{"title": "RadarLLM: Empowering Large Language Models to Understand Human Motion from Millimeter-wave Point Cloud Sequence", "abstract": "Millimeter-wave radar provides a privacy-preserving solution for human motion\nanalysis, yet its sparse point clouds pose significant challenges for semantic\nunderstanding. We present Radar-LLM, the first framework that leverages large\nlanguage models (LLMs) for human motion understanding using millimeter-wave\nradar as the sensing modality. Our approach introduces two key innovations: (1)\na motion-guided radar tokenizer based on our Aggregate VQ-VAE architecture that\nincorporates deformable body templates and masked trajectory modeling to encode\nspatiotemporal point clouds into compact semantic tokens, and (2) a radar-aware\nlanguage model that establishes cross-modal alignment between radar and text in\na shared embedding space. To address data scarcity, we introduce a\nphysics-aware synthesis pipeline that generates realistic radar-text pairs from\nmotion-text datasets. Extensive experiments demonstrate that Radar-LLM achieves\nstate-of-the-art performance across both synthetic and real-world benchmarks,\nenabling accurate translation of millimeter-wave signals to natural language\ndescriptions. This breakthrough facilitates comprehensive motion understanding\nin privacy-sensitive applications like healthcare and smart homes. We will\nrelease the full implementation to support further research on\nhttps://inowlzy.github.io/RadarLLM/.", "published": "2025-04-14 04:18:25", "link": "http://arxiv.org/abs/2504.09862v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Accelerating Differentially Private Federated Learning via Adaptive Extrapolation", "abstract": "The federated learning (FL) framework enables multiple clients to\ncollaboratively train machine learning models without sharing their raw data,\nbut it remains vulnerable to privacy attacks. One promising approach is to\nincorporate differential privacy (DP)-a formal notion of privacy-into the FL\nframework. DP-FedAvg is one of the most popular algorithms for DP-FL, but it is\nknown to suffer from the slow convergence in the presence of heterogeneity\namong clients' data. Most of the existing methods to accelerate DP-FL require\n1) additional hyperparameters or 2) additional computational cost for clients,\nwhich is not desirable since 1) hyperparameter tuning is computationally\nexpensive and data-dependent choice of hyperparameters raises the risk of\nprivacy leakage, and 2) clients are often resource-constrained. To address this\nissue, we propose DP-FedEXP, which adaptively selects the global step size\nbased on the diversity of the local updates without requiring any additional\nhyperparameters or client computational cost. We show that DP-FedEXP provably\naccelerates the convergence of DP-FedAvg and it empirically outperforms\nexisting methods tailored for DP-FL.", "published": "2025-04-14 03:43:27", "link": "http://arxiv.org/abs/2504.09850v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Score Matching Diffusion Based Feedback Control and Planning of Nonlinear Systems", "abstract": "We propose a novel control-theoretic framework that leverages principles from\ngenerative modeling -- specifically, Denoising Diffusion Probabilistic Models\n(DDPMs) -- to stabilize control-affine systems with nonholonomic constraints.\nUnlike traditional stochastic approaches, which rely on noise-driven dynamics\nin both forward and reverse processes, our method crucially eliminates the need\nfor noise in the reverse phase, making it particularly relevant for control\napplications. We introduce two formulations: one where noise perturbs all state\ndimensions during the forward phase while the control system enforces time\nreversal deterministically, and another where noise is restricted to the\ncontrol channels, embedding system constraints directly into the forward\nprocess.\n  For controllable nonlinear drift-free systems, we prove that deterministic\nfeedback laws can exactly reverse the forward process, ensuring that the\nsystem's probability density evolves correctly without requiring artificial\ndiffusion in the reverse phase. Furthermore, for linear time-invariant systems,\nwe establish a time-reversal result under the second formulation. By\neliminating noise in the backward process, our approach provides a more\npractical alternative to machine learning-based denoising methods, which are\nunsuitable for control applications due to the presence of stochasticity. We\nvalidate our results through numerical simulations on benchmark systems,\nincluding a unicycle model in a domain with obstacles, a driftless\nfive-dimensional system, and a four-dimensional linear system, demonstrating\nthe potential for applying diffusion-inspired techniques in linear, nonlinear,\nand settings with state space constraints.", "published": "2025-04-14 03:04:48", "link": "http://arxiv.org/abs/2504.09836v1", "categories": ["math.OC", "cs.LG", "cs.RO", "cs.SY", "eess.SY"], "primary_category": "math.OC"}
{"title": "FATE: A Prompt-Tuning-Based Semi-Supervised Learning Framework for Extremely Limited Labeled Data", "abstract": "Semi-supervised learning (SSL) has achieved significant progress by\nleveraging both labeled data and unlabeled data. Existing SSL methods overlook\na common real-world scenario when labeled data is extremely scarce, potentially\nas limited as a single labeled sample in the dataset. General SSL approaches\nstruggle to train effectively from scratch under such constraints, while\nmethods utilizing pre-trained models often fail to find an optimal balance\nbetween leveraging limited labeled data and abundant unlabeled data. To address\nthis challenge, we propose Firstly Adapt, Then catEgorize (FATE), a novel SSL\nframework tailored for scenarios with extremely limited labeled data. At its\ncore, the two-stage prompt tuning paradigm FATE exploits unlabeled data to\ncompensate for scarce supervision signals, then transfers to downstream tasks.\nConcretely, FATE first adapts a pre-trained model to the feature distribution\nof downstream data using volumes of unlabeled samples in an unsupervised\nmanner. It then applies an SSL method specifically designed for pre-trained\nmodels to complete the final classification task. FATE is designed to be\ncompatible with both vision and vision-language pre-trained models. Extensive\nexperiments demonstrate that FATE effectively mitigates challenges arising from\nthe scarcity of labeled samples in SSL, achieving an average performance\nimprovement of 33.74% across seven benchmarks compared to state-of-the-art SSL\nmethods. Code is available at\nhttps://anonymous.4open.science/r/Semi-supervised-learning-BA72.", "published": "2025-04-14 02:54:28", "link": "http://arxiv.org/abs/2504.09828v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Virtual domain extension for imposing boundary conditions in flow simulation using pre-trained local neural operator", "abstract": "This paper builds up a virtual domain extension (VDE) framework for imposing\nboundary conditions (BCs) in flow simulation using pre-trained local neural\noperator (LNO). It creates extended virtual domains to the input function to\ncompensate for the corrosion nature of computational domains during LNO\ninference, thus turns the implementation of BC into the determination of field\nvalues on the extended domain. Several strategies to calculate the field values\nare proposed and validated in solving numerical examples, including padding\noperation, direct imposition, pressure symmetry, and optimization by\nbackpropagation, and compared with boundary imposition in traditional solvers.\nIt is found that the large time interval of LNO induces a relatively wide\nnear-boundary domain to be processed, thus imposing BC on only a few nodes near\nthe boundary following the immersed boundary conception in traditional solvers\ncan hardly achieve high accuracy. With appropriate values assigned on the\nextended virtual domains, VDE can accurately impose BCs and lead to reasonable\nflow field predictions. This work provides a guidance for imposing BCs reliably\nin LNO prediction, which could facilitate the reuse of pre-trained LNO in more\napplications.", "published": "2025-04-14 02:18:12", "link": "http://arxiv.org/abs/2504.09807v1", "categories": ["physics.flu-dyn", "cs.LG"], "primary_category": "physics.flu-dyn"}
{"title": "BO-SA-PINNs: Self-adaptive physics-informed neural networks based on Bayesian optimization for automatically designing PDE solvers", "abstract": "Physics-informed neural networks (PINNs) is becoming a popular alternative\nmethod for solving partial differential equations (PDEs). However, they require\ndedicated manual modifications to the hyperparameters of the network, the\nsampling methods and loss function weights for different PDEs, which reduces\nthe efficiency of the solvers. In this paper, we pro- pose a general\nmulti-stage framework, i.e. BO-SA-PINNs to alleviate this issue. In the first\nstage, Bayesian optimization (BO) is used to select hyperparameters for the\ntraining process, and based on the results of the pre-training, the network\narchitecture, learning rate, sampling points distribution and loss function\nweights suitable for the PDEs are automatically determined. The proposed\nhyperparameters search space based on experimental results can enhance the\nefficiency of BO in identifying optimal hyperparameters. After selecting the\nappropriate hyperparameters, we incorporate a global self-adaptive (SA)\nmechanism the second stage. Using the pre-trained model and loss information in\nthe second-stage training, the exponential moving average (EMA) method is\nemployed to optimize the loss function weights, and residual-based adaptive\nrefinement with distribution (RAR-D) is used to optimize the sampling points\ndistribution. In the third stage, L-BFGS is used for stable training. In\naddition, we introduce a new activation function that enables BO-SA-PINNs to\nachieve higher accuracy. In numerical experiments, we conduct comparative and\nablation experiments to verify the performance of the model on Helmholtz,\nMaxwell, Burgers and high-dimensional Poisson equations. The comparative\nexperiment results show that our model can achieve higher accuracy and fewer\niterations in test cases, and the ablation experiments demonstrate the positive\nimpact of every improvement.", "published": "2025-04-14 02:07:45", "link": "http://arxiv.org/abs/2504.09804v1", "categories": ["cs.CE", "cs.LG", "cs.NA", "math.NA", "65D99"], "primary_category": "cs.CE"}
{"title": "CUT: Pruning Pre-Trained Multi-Task Models into Compact Models for Edge Devices", "abstract": "Multi-task learning has garnered widespread attention in the industry due to\nits efficient data utilization and strong generalization capabilities, making\nit particularly suitable for providing high-quality intelligent services to\nusers. Edge devices, as the primary platforms directly serving users, play a\ncrucial role in delivering multi-task services. However, current multi-task\nmodels are often large, and user task demands are increasingly diverse.\nDeploying such models directly on edge devices not only increases the burden on\nthese devices but also leads to task redundancy. To address this issue, this\npaper innovatively proposes a pre-trained multi-task model pruning method\nspecifically designed for edge computing. The goal is to utilize existing\npre-trained multi-task models to construct a compact multi-task model that\nmeets the needs of edge devices. The specific implementation steps are as\nfollows: First, decompose the tasks within the pre-trained multi-task model and\nselect tasks based on actual user needs. Next, while retaining the knowledge of\nthe original pre-trained model, evaluate parameter importance and use a\nparameter fusion method to effectively integrate shared parameters among tasks.\nFinally, obtain a compact multi-task model suitable for edge devices. To\nvalidate the effectiveness of the proposed method, we conducted experiments on\nthree public image datasets. The experimental results fully demonstrate the\nsuperiority and efficiency of this method, providing a new solution for\nmulti-task learning on edge devices.", "published": "2025-04-14 02:04:48", "link": "http://arxiv.org/abs/2504.09803v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Tale of Two Learning Algorithms: Multiple Stream Random Walk and Asynchronous Gossip", "abstract": "Although gossip and random walk-based learning algorithms are widely known\nfor decentralized learning, there has been limited theoretical and experimental\nanalysis to understand their relative performance for different graph\ntopologies and data heterogeneity. We first design and analyze a random\nwalk-based learning algorithm with multiple streams (walks), which we name\nasynchronous \"Multi-Walk (MW)\". We provide a convergence analysis for MW w.r.t\niteration (computation), wall-clock time, and communication. We also present a\nconvergence analysis for \"Asynchronous Gossip\", noting the lack of a\ncomprehensive analysis of its convergence, along with the computation and\ncommunication overhead, in the literature. Our results show that MW has better\nconvergence in terms of iterations as compared to Asynchronous Gossip in graphs\nwith large diameters (e.g., cycles), while its relative performance, as\ncompared to Asynchronous Gossip, depends on the number of walks and the data\nheterogeneity in graphs with small diameters (e.g., complete graphs). In\nwall-clock time analysis, we observe a linear speed-up with the number of walks\nand nodes in MW and Asynchronous Gossip, respectively. Finally, we show that MW\noutperforms Asynchronous Gossip in communication overhead, except in\nsmall-diameter topologies with extreme data heterogeneity. These results\nhighlight the effectiveness of each algorithm in different graph topologies and\ndata heterogeneity. Our codes are available for reproducibility.", "published": "2025-04-14 01:34:22", "link": "http://arxiv.org/abs/2504.09792v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "What metric to optimize for suppressing instability in a Vlasov-Poisson system?", "abstract": "Stabilizing plasma dynamics is an important task in green energy generation\nvia nuclear fusion. One common strategy is to introduce an external field to\nprevent the plasma distribution from developing turbulence. However, finding\nsuch external fields efficiently remains an open question, even for simplified\nmodels such as the Vlasov-Poisson (VP) system. In this work, we leverage two\ndifferent approaches to build such fields: for the first approach, we use an\nanalytical derivation of the dispersion relation of the VP system to find a\nrange of reasonable fields that can potentially suppress instability, providing\na qualitative suggestion. For the second approach, we leverage PDE-constrained\noptimization to obtain a locally optimal field using different loss functions.\nAs the stability of the system can be characterized in several different ways,\nthe objective functions need to be tailored accordingly. We show, through\nextensive numerical tests, that objective functions such as the relative\nentropy (KL divergence) and the $L^{2}$ norm result in a highly non-convex\nproblem, rendering the global minimum difficult to find. However, we show that\nusing the electric energy of the system as a loss function is advantageous, as\nit has a large convex basin close to the global minimum. Unfortunately, outside\nthe basin, the electric energy landscape consists of unphysical flat local\nminima, thus rendering a good initial guess key for the overall convergence of\nthe optimization problem, particularly for solvers with adaptive steps.", "published": "2025-04-14 17:26:09", "link": "http://arxiv.org/abs/2504.10435v1", "categories": ["math.NA", "cs.NA", "physics.comp-ph"], "primary_category": "math.NA"}
{"title": "Dual-grid parameter choice method with application to image deblurring", "abstract": "Variational regularization of ill-posed inverse problems is based on\nminimizing the sum of a data fidelity term and a regularization term. The\nbalance between them is tuned using a positive regularization parameter, whose\nautomatic choice remains an open question in general. A novel approach for\nparameter choice is introduced, based on the use of two slightly different\ncomputational models for the same inverse problem. Small parameter values\nshould give two very different reconstructions due to amplification of noise.\nLarge parameter values lead to two identical but trivial reconstructions.\nOptimal parameter is chosen between the extremes by matching image similarity\nof the two reconstructions with a pre-defined value. Efficacy of the new method\nis demonstrated with image deblurring using measured data and two different\nregularizers.", "published": "2025-04-14 14:19:58", "link": "http://arxiv.org/abs/2504.10259v1", "categories": ["math.NA", "cs.NA", "65-XX, 00A69"], "primary_category": "math.NA"}
{"title": "WG-IDENT: Weak Group Identification of PDEs with Varying Coefficients", "abstract": "Partial Differential Equations (PDEs) identification is a data-driven method\nfor mathematical modeling, and has received a lot of attentions recently. The\nstability and precision in identifying PDE from heavily noisy spatiotemporal\ndata present significant difficulties. This problem becomes even more complex\nwhen the coefficients of the PDEs are subject to spatial variation. In this\npaper, we propose a Weak formulation of Group-sparsity-based framework for\nIDENTifying PDEs with varying coefficients, called WG-IDENT, to tackle this\nchallenge. Our approach utilizes the weak formulation of PDEs to reduce the\nimpact of noise. We represent test functions and unknown PDE coefficients using\nB-splines, where the knot vectors of test functions are optimally selected\nbased on spectral analysis of the noisy data. To facilitate feature selection,\nwe propose to integrate group sparse regression with a newly designed group\nfeature trimming technique, called GF-trim, to eliminate unimportant features.\nExtensive and comparative ablation studies are conducted to validate our\nproposed method. The proposed method not only demonstrates greater robustness\nto high noise levels compared to state-of-the-art algorithms but also achieves\nsuperior performance while exhibiting reduced sensitivity to hyperparameter\nselection.", "published": "2025-04-14 13:26:56", "link": "http://arxiv.org/abs/2504.10212v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Energy-preserving iteration schemes for Gauss collocation integrators", "abstract": "In this work, we develop energy-preserving iterative schemes for the\n(non-)linear systems arising in the Gauss integration of Poisson systems with\nquadratic Hamiltonian. Exploiting the relation between Gauss collocation\nintegrators and diagonal Pad\\'e approximations, we establish a Krylov-subspace\niteration scheme based on a $Q$-Arnoldi process for linear systems that\nprovides energy conservation not only at convergence --as standard iteration\nschemes do--, but also at the level of the individual iterates. It is\ncompetitive with GMRES in terms of accuracy and cost for a single iteration\nstep and hence offers significant efficiency gains, when it comes to time\nintegration of high-dimensional Poisson systems within given error tolerances.\nOn top of the linear results, we consider non-linear Poisson systems and design\nnon-linear solvers for the implicit midpoint rule (Gauss integrator of second\norder), using the fact that the associated Pad\\'e approximation is a Cayley\ntransformation. For the non-linear systems arising at each time step, we\npropose fixed-point and Newton-type iteration schemes that inherit the\nconvergence order with comparable cost from their classical versions, but have\nenergy-preserving iterates.", "published": "2025-04-14 13:26:38", "link": "http://arxiv.org/abs/2504.10211v1", "categories": ["math.NA", "cs.NA", "37Mxx, 47J25, 65Lxx, 65Pxx"], "primary_category": "math.NA"}
{"title": "An initial-boundary corrected splitting method for diffusion-reaction problems", "abstract": "Strang splitting is a widely used second-order method for solving\ndiffusion-reaction problems. However, its convergence order is often reduced to\norder $1$ for Dirichlet boundary conditions and to order $1.5$ for Neumann and\nRobin boundary conditions, leading to lower accuracy and reduced efficiency. In\nthis paper, we propose a new splitting approach, called an initial-boundary\ncorrected splitting, which avoids order reduction while improving computational\nefficiency for a wider range of applications. In contrast to the corrections\nproposed in the literature, it does not require the computation of correction\nterms that depend on the boundary conditions and boundary data. Through\nrigorous analytical convergence analysis and numerical experiments, we\ndemonstrate the improved accuracy and performance of the proposed method.", "published": "2025-04-14 11:32:33", "link": "http://arxiv.org/abs/2504.10125v1", "categories": ["math.NA", "cs.NA", "65M12, 65M20, 65L04"], "primary_category": "math.NA"}
{"title": "Stochastic Multigrid Minimization for Ptychographic Phase Retrieval", "abstract": "We propose a novel stochastic multigrid minimization method for ptychographic\nphase retrieval. In our formulation, the challenging nonconvex and ill-posed\ninverse problem is recast as the iterative minimization of a quadratic\nsurrogate model that majorizes the original objective function. Our general\nframework encompasses the Ptychographic Iterative Engine (PIE) family of\nalgorithms. By efficiently solving the surrogate problem using a multigrid\nmethod, our approach delivers significant improvements in both convergence\nspeed and reconstruction quality compared with conventional PIE techniques.", "published": "2025-04-14 11:28:20", "link": "http://arxiv.org/abs/2504.10118v1", "categories": ["math.NA", "cs.NA", "math.OC"], "primary_category": "math.NA"}
{"title": "Numerical approach for solving problems arising from polynomial analysis", "abstract": "This paper deals with the use of numerical methods based on random root\nsampling techniques to solve some theoretical problems arising in the analysis\nof polynomials. These methods are proved to be practical and give solutions\nwhere traditional methods might fall short.", "published": "2025-04-14 11:13:11", "link": "http://arxiv.org/abs/2504.10103v1", "categories": ["math.NA", "cs.NA", "math.CA"], "primary_category": "math.NA"}
{"title": "Bayesian optimal experimental design with Wasserstein information criteria", "abstract": "Bayesian optimal experimental design (OED) provides a principled framework\nfor selecting the most informative observational settings in experiments. With\nrapid advances in computational power, Bayesian OED has become increasingly\nfeasible for inference problems involving large-scale simulations, attracting\ngrowing interest in fields such as inverse problems. In this paper, we\nintroduce a novel design criterion based on the expected Wasserstein-$p$\ndistance between the prior and posterior distributions. Especially, for $p=2$,\nthis criterion shares key parallels with the widely used expected information\ngain (EIG), which relies on the Kullback--Leibler divergence instead. First,\nthe Wasserstein-2 criterion admits a closed-form solution for Gaussian\nregression, a property which can be also leveraged for approximative schemes.\nSecond, it can be interpreted as maximizing the information gain measured by\nthe transport cost incurred when updating the prior to the posterior. Our main\ncontribution is a stability analysis of the Wasserstein-1 criterion, where we\nprovide a rigorous error analysis under perturbations of the prior or\nlikelihood. We partially extend this study also to the Wasserstein-2 criterion.\nIn particular, these results yield error rates when empirical approximations of\npriors are used. Finally, we demonstrate the computability of the Wasserstein-2\ncriterion and demonstrate our approximation rates through simulations.", "published": "2025-04-14 10:56:42", "link": "http://arxiv.org/abs/2504.10092v1", "categories": ["stat.ME", "cs.NA", "math.NA", "stat.CO"], "primary_category": "stat.ME"}
{"title": "Wasserstein convergence rates for stochastic particle approximation of Boltzmann models", "abstract": "We establish quantitative convergence rates for stochastic particle\napproximation based on Nanbu-type Monte Carlo schemes applied to a broad class\nof collisional kinetic models. Using coupling techniques and stability\nestimates in the Wasserstein-1 (Kantorovich-Rubinstein) metric, we derive sharp\nerror bounds that reflect the nonlinear interaction structure of the models.\nOur framework includes classical Nanbu Monte Carlo method and more recent\ndevelopments as Time Relaxed Monte Carlo methods. The results bridge the gap\nbetween probabilistic particle approximations and deterministic numerical error\nanalysis, and provide a unified perspective for the convergence theory of Monte\nCarlo methods for Boltzmann-type equations. As a by-product, we also obtain\nexistence and uniqueness of solutions to a large class of Boltzmann-type\nequations.", "published": "2025-04-14 10:55:04", "link": "http://arxiv.org/abs/2504.10091v1", "categories": ["math.NA", "cs.NA", "65C05, 35Q20, 82C22, 49Q22, 65M15"], "primary_category": "math.NA"}
{"title": "Convergence Analysis of a Stochastic Interacting Particle-Field Algorithm for 3D Parabolic-Parabolic Keller-Segel Systems", "abstract": "Chemotaxis models describe the movement of organisms in response to chemical\ngradients. In this paper, we present a stochastic interacting particle-field\nalgorithm with random batch approximation (SIPF-$r$) for the three-dimensional\n(3D) parabolic-parabolic Keller-Segel (KS) system, also known as the fully\nparabolic KS system. The SIPF-$r$ method approximates the KS system by coupling\nparticle-based representations of density with a smooth field variable computed\nusing spectral methods. By incorporating the random batch method (RBM), we\nbypass the mean-field limit and significantly reduce computational complexity.\nUnder mild assumptions on the regularity of the original KS system and the\nboundedness of numerical approximations, we prove that, with high probability,\nthe empirical measure of the SIPF-$r$ particle system converges to the exact\nmeasure of the limiting McKean-Vlasov process in the $1$-Wasserstein distance.\nNumerical experiments validate the theoretical convergence rates and\ndemonstrate the robustness and accuracy of the SIPF-$r$ method.", "published": "2025-04-14 10:53:40", "link": "http://arxiv.org/abs/2504.10089v1", "categories": ["math.NA", "cs.NA", "35K51, 65C05, 65M12, 65M75, 65T50"], "primary_category": "math.NA"}
{"title": "Computing the unitary best approximant to the exponential function", "abstract": "Unitary best approximation to the exponential function on an interval on the\nimaginary axis has been introduced recently. In the present work two algorithms\nare considered to compute this best approximant: an algorithm based on rational\ninterpolation in successively corrected interpolation nodes and the AAA-Lawson\nmethod. Moreover, a posteriori bounds are introduced to evaluate the quality of\na computed approximant and to show convergence to the unitary best approximant\nin practice. Two a priori estimates -- one based on experimental data, and one\nbased on an asymptotic error estimate -- are introduced to determine the\nunderlying frequency for which the unitary best approximant achieves a given\naccuracy. Performance of algorithms and estimates is verified by numerical\nexperiments. In particular, the interpolation-based algorithm converges to the\nunitary best approximant within a small number of iterations in practice.", "published": "2025-04-14 10:04:47", "link": "http://arxiv.org/abs/2504.10062v1", "categories": ["math.NA", "cs.NA", "41A20 (Primary) 30E10, 33B10, 41A05, 41A50 (Secondary)"], "primary_category": "math.NA"}
{"title": "An efffcient numerical scheme for two-dimensional nonlinear time fractional Schr\u00f6dinger equation", "abstract": "In this paper, a linearized fully discrete scheme is proposed to solve the\ntwo-dimensional nonlinear time fractional Schr\\\"odinger equation with weakly\nsingular solutions, which is constructed by using L1 scheme for Caputo\nfractional derivative, backward formula for the approximation of nonlinear term\nand five-point difference scheme in space. We rigorously prove the\nunconditional stability and pointwise-in-time convergence of the fully discrete\nscheme, which does not require any restriction on the grid ratio. Numerical\nresults are presented to verify the accuracy of the theoretical analysis.", "published": "2025-04-14 09:30:49", "link": "http://arxiv.org/abs/2504.10026v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Semi-implicit-explicit Runge-Kutta method for nonlinear differential equations", "abstract": "A semi-implicit-explicit (semi-IMEX) Runge-Kutta (RK) method is proposed for\nthe numerical integration of ordinary differential equations (ODEs) of the form\n$\\mathbf{u}' = \\mathbf{f}(t,\\mathbf{u}) + G(t,\\mathbf{u}) \\mathbf{u}$, where\n$\\mathbf{f}$ is a non-stiff term and $G\\mathbf{u}$ represents the stiff terms.\nSuch systems frequently arise from spatial discretizations of time-dependent\nnonlinear partial differential equations (PDEs). For instance, $G$ could\ninvolve higher-order derivative terms with nonlinear coefficients. Traditional\nIMEX-RK methods, which treat $\\mathbf{f}$ explicitly and $G\\mathbf{u}$\nimplicitly, require solving nonlinear systems at each time step when $G$\ndepends on $\\mathbf{u}$, leading to increased computational cost and\ncomplexity. In contrast, the proposed semi-IMEX scheme treats $G$ explicitly\nwhile keeping $\\mathbf{u}$ implicit, reducing the problem to solving only\nlinear systems. This approach eliminates the need to compute Jacobians while\npreserving the stability advantages of implicit methods. A family of semi-IMEX\nRK schemes with varying orders of accuracy is introduced. Numerical simulations\nfor various nonlinear equations, including nonlinear diffusion models, the\nNavier-Stokes equations, and the Cahn-Hilliard equation, confirm the expected\nconvergence rates and demonstrate that the proposed method allows for larger\ntime step sizes without triggering stability issues.", "published": "2025-04-14 08:18:57", "link": "http://arxiv.org/abs/2504.09969v1", "categories": ["math.NA", "cs.NA", "65L06, 65M22, 65M12, 76D05, 35K55, 35Q35"], "primary_category": "math.NA"}
{"title": "A posteriori estimates for problems with monotone operators", "abstract": "We propose a method of obtaining a posteriori estimates which does not use\nthe duality theory and which applies to variational inequalities with monotone\noperators, without assuming the potentiality of operators. The effectiveness of\nthe method is demonstrated on problems driven by nonlinear operators of the\n$p$-Laplacian type, including the anisotropic $p$-Laplacian, polyharmonic\n$p$-Laplacian, and fractional $p$-Laplacian.", "published": "2025-04-14 06:45:20", "link": "http://arxiv.org/abs/2504.09931v1", "categories": ["math.AP", "cs.NA", "math.NA", "35J92, 35B45, 35B30"], "primary_category": "math.AP"}
{"title": "NR-SSOR right preconditioned RRGMRES for arbitrary singular systems and least squares problems", "abstract": "GMRES is known to determine a least squares solution of $ A x = b $ where $ A\n\\in R^{n \\times n} $ without breakdown for arbitrary $ b \\in R^n $, and initial\niterate $ x_0 \\in R^n $ if and only if $ A $ is range-symmetric, i.e. $ R(A^T)\n= R(A) $, where $ A $ may be singular and $ b $ may not be in the range space $\nR(A) $ of $ A $.\n  In this paper, we propose applying the Range Restricted GMRES (RRGMRES) to $\nA C A^T z = b $, where $ C \\in R^{n \\times n} $ is symmetric positive definite.\nThis determines a least squares solution $ x = C A^T z $ of $ A x = b $ without\nbreakdown for arbitrary (singular) matrix $ A \\in R^{n \\times n} $ and $ b, x_0\n\\in R^n $, and is much more stable and accurate compared to GMRES, RRGMRES and\nMINRES-QLP applied to $ A x = b $ for inconsistent problems when $ b \\notin\nR(A) $. In particular, we propose applying the NR-SSOR as the inner iteration\nright preconditioner, which also works efficiently for least squares problems $\n\\min_{x \\in R^n} \\| b - A x\\|_2 $ for $ A \\in R^{m \\times n} $ and arbitrary $\nb \\in R^m $.\n  Numerical experiments demonstrate the validity of the proposed method.", "published": "2025-04-14 05:34:02", "link": "http://arxiv.org/abs/2504.09891v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Maximum bound preservation of exponential integrators for Allen-Cahn equations", "abstract": "We develop and analyze a class of arbitrarily high-order, maximum bound\npreserving time-stepping schemes for solving Allen-Cahn equations. These\nschemes are constructed within the iterative framework of exponential\nintegrators, combined with carefully chosen numerical quadrature rules,\nincluding the Gauss-Legendre quadrature rule and the left Gauss-Radau\nquadrature rule. Notably, the proposed schemes are rigorously proven to\nunconditionally preserve the maximum bound without requiring any additional\npostprocessing techniques, while simultaneously achieving arbitrarily\nhigh-order temporal accuracy. A thorough error analysis in the $L^2$ norm is\nprovided. Numerical experiments validate the theoretical results, demonstrate\nthe effectiveness of the proposed methods, and highlight that an inappropriate\nchoice of quadrature rules may violate the maximum bound principle, leading to\nincorrect dynamics.", "published": "2025-04-14 04:48:59", "link": "http://arxiv.org/abs/2504.09874v1", "categories": ["math.NA", "cs.NA", "65M12, 65M15, 65R20"], "primary_category": "math.NA"}
{"title": "High-Order Interior Penalty Finite Element Methods for Fourth-Order Phase-Field Models in Fracture Analysis", "abstract": "This paper presents a novel approach for solving fourth-order phase-field\nmodels in brittle fracture mechanics using the Interior Penalty Finite Element\nMethod (IP-FEM). The fourth-order model improves numerical stability and\naccuracy compared to traditional second-order phase-field models, particularly\nwhen simulating complex crack paths. The IP-FEM provides an efficient framework\nfor discretizing these models, effectively handling nonconforming trial\nfunctions and complex boundary conditions.\n  In this study, we leverage the FEALPy framework to implement a flexible\ncomputational tool that supports high-order IP-FEM discretizations. Our results\nshow that as the polynomial order increases, the mesh dependence of the\nphase-field model decreases, offering improved accuracy and faster convergence.\nAdditionally, we explore the trade-offs between computational cost and accuracy\nwith varying polynomial orders and mesh sizes. The findings offer valuable\ninsights for optimizing numerical simulations of brittle fracture in practical\nengineering applications.", "published": "2025-04-14 02:20:37", "link": "http://arxiv.org/abs/2504.09810v1", "categories": ["math.NA", "cs.NA", "math.AP"], "primary_category": "math.NA"}
{"title": "Optimal Execution in Intraday Energy Markets under Hawkes Processes with Transient Impact", "abstract": "This paper investigates optimal execution strategies in intraday energy\nmarkets through a mutually exciting Hawkes process model. Calibrated to data\nfrom the German intraday electricity market, the model effectively captures key\nempirical features, including intra-session volatility, distinct intraday\nmarket activity patterns, and the Samuelson effect as gate closure approaches.\nBy integrating a transient price impact model with a bivariate Hawkes process\nto model the market order flow, we derive an optimal trading trajectory for\nenergy companies managing large volumes, accounting for the specific trading\npatterns in these markets. A back-testing analysis compares the proposed\nstrategy against standard benchmarks such as Time-Weighted Average Price (TWAP)\nand Volume-Weighted Average Price (VWAP), demonstrating substantial cost\nreductions across various hourly trading products in intraday energy markets.", "published": "2025-04-14 14:51:18", "link": "http://arxiv.org/abs/2504.10282v1", "categories": ["q-fin.TR", "49J15, 91G80"], "primary_category": "q-fin.TR"}
{"title": "Kullback-Leibler excess risk bounds for exponential weighted aggregation in Generalized linear models", "abstract": "Aggregation methods have emerged as a powerful and flexible framework in\nstatistical learning, providing unified solutions across diverse problems such\nas regression, classification, and density estimation. In the context of\ngeneralized linear models (GLMs), where responses follow exponential family\ndistributions, aggregation offers an attractive alternative to classical\nparametric modeling. This paper investigates the problem of sparse aggregation\nin GLMs, aiming to approximate the true parameter vector by a sparse linear\ncombination of predictors. We prove that an exponential weighted aggregation\nscheme yields a sharp oracle inequality for the Kullback-Leibler risk with\nleading constant equal to one, while also attaining the minimax-optimal rate of\naggregation. These results are further enhanced by establishing\nhigh-probability bounds on the excess risk.", "published": "2025-04-14 12:25:11", "link": "http://arxiv.org/abs/2504.10171v1", "categories": ["math.ST", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "Rotatable Antenna-Enabled Secure Wireless Communication", "abstract": "Rotatable antenna (RA) is a promising technology that exploits new spatial\ndegrees of freedom (DoFs) to improve wireless communication and sensing\nperformance. In this letter, we investigate an RA-enabled secure communication\nsystem where confidential information is transmitted from an RA-based access\npoint (AP) to a single-antenna legitimate user in the presence of multiple\neavesdroppers. We aim to maximize the achievable secrecy rate by jointly\noptimizing the transmit beamforming and the deflection angles of all RAs.\nAccordingly, we propose an efficient alternating optimization (AO) algorithm to\nobtain a high-quality suboptimal solution in an iterative manner, where the\ngeneralized Rayleigh quotient-based beamforming is applied and the RAs'\ndeflection angles are optimized by the successive convex approximation (SCA).\nSimulation results show that the proposed RA-enabled secure communication\nsystem achieves significant improvement in achievable secrecy rate as compared\nto various benchmark schemes.", "published": "2025-04-14 17:55:27", "link": "http://arxiv.org/abs/2504.10473v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Pinching-Antenna System (PASS) Enhanced Covert Communications", "abstract": "A Pinching-Antenna SyStem (PASS)-assisted convert communication framework is\nproposed. PASS utilizes dielectric waveguides with freely positioned pinching\nantennas (PAs) to establish strong line-of-sight links. Capitalizing on this\nhigh reconfigurable flexibility of antennas, the potential of PASS for covert\ncommunications is investigated. 1)~For the single-waveguide single-PA (SWSP)\nscenario, a closed-form optimal PA position that maximizes the covert rate is\nfirst derived. Subsequently, a one-dimensional power search is employed to\nenable low-complexity optimization for covert communications. With antenna\nmobility on a scale of meters, PASS can deal with the challenging situation of\nthe eavesdropper enjoying better channel conditions than the legal user. 2)~For\nthe multi-waveguide multi-PA (MWMP) scenario, the positions of multiple PAs are\noptimized to enable effective pinching beamforming, thereby enhancing the\ncovert rate. To address the resultant multimodal joint transmit and pinching\nbeamforming problem, a twin particle swarm optimization (TwinPSO) approach is\nproposed. Numerical results demonstrate that: i)~the proposed approaches can\neffectively resolve the optimization problems; ii)~PASS achieves a higher\ncovert rate than conventional fixed-position antenna architectures; and\niii)~with enhanced flexibility, the MWMP setup outperforms the SWSP\ncounterpart.", "published": "2025-04-14 17:32:54", "link": "http://arxiv.org/abs/2504.10442v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "The Communication and Computation Trade-off in Wireless Semantic Communications", "abstract": "Semantic communications have emerged as a crucial research direction for\nfuture wireless communication networks. However, as wireless systems become\nincreasingly complex, the demands for computation and communication resources\nin semantic communications continue to grow rapidly. This paper investigates\nthe trade-off between computation and communication in wireless semantic\ncommunications, taking into consideration transmission task delay and\nperformance constraints within the semantic communication framework. We propose\na novel tradeoff metric to analyze the balance between computation and\ncommunication in semantic transmissions and employ the deep reinforcement\nlearning (DRL) algorithm to minimize this metric, thereby reducing the cost\nassociated with balancing computation and communication. Through simulations,\nwe analyze the tradeoff between computation and communication and demonstrate\nthe effectiveness of optimizing this trade-off metric.", "published": "2025-04-14 16:06:20", "link": "http://arxiv.org/abs/2504.10357v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Tx and Rx IQ Imbalance Compensation for JCAS in 5G NR", "abstract": "Beside traditional communications, joint communications and sensing (JCAS) is\ngaining increasing relevance as a key enabler for next-generation wireless\nsystems. The ability to accurately transmit and receive data is the basis for\nhigh-speed communications and precise sensing, where a fundamental requirement\nis an accurate in-phase (I) and quadrature-phase (Q) modulation. For sensing,\nimperfections in IQ modulation lead to two critical issues in the\nrange-Doppler-map (RDM) in form of an increased noise floor and the presence of\nghost objects, degrading the accuracy and reliability of the information in the\nRDM. This paper presents a low-complex estimation and compensation method to\nmitigate the IQ imbalance effects. This is achieved by utilizing, amongst\nothers, the leakage signal, which is the direct signal from the transmitter to\nthe receiver path, and is typically the strongest signal component in the RDM.\nThe parameters of the IQ imbalance suppression structure are estimated based on\na mixed complex-/real-valued bilinear filter approach, that considers IQ\nimbalance in the transmitter and the receiver of the JCAS-capable user\nequipment (UE). The UE uses a 5G New Radio (NR)-compliant orthogonal\nfrequency-division multiplexing (OFDM) waveform with the system configuration\nassumed to be predefined from the communication side. To assess the\neffectiveness of the proposed approach, simulations are conducted, illustrating\nthe performance in the suppression of IQ imbalance introduced distortions in\nthe RDM.", "published": "2025-04-14 14:38:41", "link": "http://arxiv.org/abs/2504.10272v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Simulation and Experimental Validation of Optical Camera Communication", "abstract": "While simulation tools for visible light communication (VLC) with photo\ndetectors (PDs) have been widely investigated, similar tools for optical camera\ncommunication (OCC) with complementary metal oxide semiconductor (CMOS) sensors\nare lacking in this regard. Camera based VLC systems have much lower data rates\nowing to camera exposure times. Among the few extant OCC simulation tools, none\nallow for simulation of images when exposure time is greater than the signal\nperiod. An accurate simulation of the OCC system can be used to improve the\ndata rate and quality of performance. We propose a simple simulation technique\nfor OCC which allows to test for system performance at frequencies beyond the\ncamera shutter speed. This will allow much needed data rate improvement by\noperating at the actual frequency a decoding algorithm ceases detection instead\nof the exposure limit used now. We have tested the accuracy of simulation by\ncomparing the detection success rates of simulated images with experimental\nimages. The proposed simulation technique was shown to be accurate through\nexperimental validation for two different cameras.", "published": "2025-04-14 13:45:09", "link": "http://arxiv.org/abs/2504.10224v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Joint Localization and Synchronization in Downlink Distributed MIMO", "abstract": "We investigate joint localization and synchronization in the downlink of a\ndistributed multiple-input-multiple-output (D-MIMO) system, aiming to estimate\nthe position and phase offset of a single-antenna user equipment (UE) using\ndownlink transmissions of multiple phase-synchronized, multi-antenna access\npoints (APs). We propose two transmission protocols: sequential (P1) and\nsimultaneous (P2) AP transmissions, together with the ML estimators that either\nleverage (coherent estimator) or disregard phase information (non-coherent\nestimator). Simulation results reveal that downlink D-MIMO holds significant\npotential for high-accuracy localization while showing that P2 provides\nsuperior localization performance and reduced transmission latency.", "published": "2025-04-14 10:47:05", "link": "http://arxiv.org/abs/2504.10087v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Parametric Near-Field MMSE Channel Estimation for sub-THz XL-MIMO Systems", "abstract": "Accurate channel estimation is essential for reliable communication in\nsub-THz extremely large (XL) MIMO systems. Deploying XL-MIMO in high-frequency\nbands not only increases the number of antennas, but also fundamentally alters\nchannel propagation characteristics, placing the user equipments (UE) in the\nradiative near-field of the base station. This paper proposes a parametric\nestimation method using the multiple signal classification (MUSIC) algorithm to\nextract UE location data from uplink pilot signals. These parameters are used\nto reconstruct the spatial correlation matrix, followed by an approximation of\nthe minimum mean square error (MMSE) channel estimator. Numerical results show\nthat the proposed method outperforms the least-squares (LS) estimator in terms\nof the normalized mean-square error (NMSE), even without prior UE location\nknowledge.", "published": "2025-04-14 10:08:15", "link": "http://arxiv.org/abs/2504.10064v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Learning to Beamform for Cooperative Localization and Communication: A Link Heterogeneous GNN-Based Approach", "abstract": "Integrated sensing and communication (ISAC) has emerged as a key enabler for\nnext-generation wireless networks, supporting advanced applications such as\nhigh-precision localization and environment reconstruction. Cooperative ISAC\n(CoISAC) further enhances these capabilities by enabling multiple base stations\n(BSs) to jointly optimize communication and sensing performance through\ncoordination. However, CoISAC beamforming design faces significant challenges\ndue to system heterogeneity, large-scale problem complexity, and sensitivity to\nparameter estimation errors. Traditional deep learning-based techniques fail to\nexploit the unique structural characteristics of CoISAC systems, thereby\nlimiting their ability to enhance system performance. To address these\nchallenges, we propose a Link-Heterogeneous Graph Neural Network (LHGNN) for\njoint beamforming in CoISAC systems. Unlike conventional approaches, LHGNN\nmodels communication and sensing links as heterogeneous nodes and their\ninteractions as edges, enabling the capture of the heterogeneous nature and\nintricate interactions of CoISAC systems. Furthermore, a graph attention\nmechanism is incorporated to dynamically adjust node and link importance,\nimproving robustness to channel and position estimation errors. Numerical\nresults demonstrate that the proposed attention-enhanced LHGNN achieves\nsuperior communication rates while maintaining sensing accuracy under power\nconstraints. The proposed method also exhibits strong robustness to\ncommunication channel and position estimation error.", "published": "2025-04-14 10:03:12", "link": "http://arxiv.org/abs/2504.10060v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Uniform Planar Array Based Weighted Cooperative Spectrum Sensing for Cognitive Radio Networks", "abstract": "Cooperative spectrum sensing (CSS) is essential for improving the spectrum\nefficiency and reliability of cognitive radio applications. Next-generation\nwireless communication networks increasingly employ uniform planar arrays (UPA)\ndue to their ability to steer beamformers towards desired directions,\nmitigating interference and eavesdropping. However, the application of\nUPA-based CSS in cognitive radio remains largely unexplored. This paper\nproposes a multi-beam UPA-based weighted CSS (WCSS) framework to enhance\ndetection reliability, applicable to various cognitive radio networks,\nincluding cellular, vehicular, and satellite communications. We first propose a\nweighting factor for commonly used energy detection (ED) and eigenvalue\ndetection (EVD) techniques, based on the spatial variation of signal strengths\nresulting from UPA antenna beamforming. We then analytically characterize the\nperformance of both weighted ED and weighted EVD by deriving closed-form\nexpressions for false alarm and detection probabilities. Our numerical results,\nconsidering both static and dynamic user behaviors, demonstrate the superiority\nof WCSS in enhancing sensing performance compared to uniformly weighted\ndetectors.", "published": "2025-04-14 09:36:56", "link": "http://arxiv.org/abs/2504.10034v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Diversity Analysis for Indoor Terahertz Communication Systems under Small-Scale Fading", "abstract": "Harnessing diversity is fundamental to wireless communication systems,\nparticularly in the terahertz (THz) band, where severe path loss and\nsmall-scale fading pose significant challenges to system reliability and\nperformance. In this paper, we present a comprehensive diversity analysis for\nindoor THz communication systems, accounting for the combined effects of path\nloss and small-scale fading, with the latter modeled as an $\\alpha-\\mu$\ndistribution to reflect THz indoor channel conditions. We derive closed-form\nexpressions for the bit error rate (BER) as a function of the reciprocal of the\nsignal-to-noise ratio (SNR) and propose an asymptotic expression. Furthermore,\nwe validate these expressions through extensive simulations, which show strong\nagreement with the theoretical analysis, confirming the accuracy and robustness\nof the proposed methods. Our results show that the diversity order in THz\nsystems is primarily determined by the combined effects of the number of\nindependent paths, the severity of fading, and the degree of channel frequency\nselectivity, providing clear insights into how diversity gains can be optimized\nin high-frequency wireless networks.", "published": "2025-04-14 08:51:52", "link": "http://arxiv.org/abs/2504.09986v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Fully-Adaptive and Semi-Adaptive Frequency Sweep Algorithm Exploiting Loewner-State Model for EM Simulation of Multiport Systems", "abstract": "This paper employs a fully adaptive and semi-adaptive frequency sweep\nalgorithm using the Loewner matrix-based state model for the electromagnetic\nsimulation. The proposed algorithms use two Loewner matrix models with\ndifferent or the same orders with small frequency perturbation for adaptive\nfrequency selection. The error between the two models is calculated in each\niteration, and the next frequency points are selected to minimize maximum\nerror. With the help of memory, the algorithm terminates when the error between\nthe model and the simulation result is reached within the specified error\ntolerance. In the fully adaptive frequency sweep algorithm, the method starts\nwith the minimum and maximum frequency of simulation. In the semi-adaptive\nalgorithm, a novel approach has been proposed to determine the initial number\nof frequency points necessary for system interpolation based on the electrical\nsize of the structure. The proposed algorithms have been compared with the\nStoer-Bulirsch algorithm and Pradovera's minimal sampling algorithm for\nelectromagnetic simulation. Four examples are presented using MATLAB R2024b.\nThe results show that the proposed methods offer better performance in terms of\nspeed, accuracy and the requirement of the minimum number of frequency samples.\nThe proposed method shows remarkable consistency with full-wave simulation\ndata, and the algorithm can be effectively applicable to electromagnetic\nsimulations.", "published": "2025-04-14 07:05:14", "link": "http://arxiv.org/abs/2504.09942v1", "categories": ["eess.SP", "cs.SY", "eess.SY", "03C40, 32E30", "G.1.1"], "primary_category": "eess.SP"}
{"title": "Parameter Convergence Detector Based on VAMP Deep Unfolding: A Novel Radar Constant False Alarm Rate Detection Algorithm", "abstract": "The sub-Nyquist radar framework exploits the sparsity of signals, which\neffectively alleviates the pressure on system storage and transmission\nbandwidth. Compressed sensing (CS) algorithms, such as the VAMP algorithm, are\nused for sparse signal processing in the sub-Nyquist radar framework. By\ncombining deep unfolding techniques with VAMP, faster convergence and higher\naccuracy than traditional CS algorithms are achieved. However, deep unfolding\ndisrupts the parameter constrains in traditional VAMP algorithm, leading to the\ndistribution of non-sparse noisy estimation in VAMP deep unfolding unknown, and\nits distribution parameter unable to be obtained directly using method of\ntraditional VAMP, which prevents the application of VAMP deep unfolding in\nradar constant false alarm rate (CFAR) detection. To address this problem, we\nexplore the distribution of the non-sparse noisy estimation and propose a\nparameter convergence detector (PCD) to achieve CFAR detection based on VAMP\ndeep unfolding. Compared to the state-of-the-art methods, PCD leverages not\nonly the sparse solution, but also the non-sparse noisy estimation, which is\nused to iteratively estimate the distribution parameter and served as the test\nstatistic in detection process. In this way, the proposed algorithm takes\nadvantage of both the enhanced sparse recovery accuracy from deep unfolding and\nthe distribution property of VAMP, thereby achieving superior CFAR detection\nperformance. Additionally, the PCD requires no information about the power of\nAWGN in the environment, which is more suitable for practical application. The\nconvergence performance and effectiveness of the proposed PCD are analyzed\nbased on the Banach Fixed-Point Theorem. Numerical simulations and practical\ndata experiments demonstrate that PCD can achieve better false alarm control\nand target detection performance.", "published": "2025-04-14 06:18:11", "link": "http://arxiv.org/abs/2504.09912v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Novel Radar Constant False Alarm Rate Detection Algorithm Based on VAMP Deep Unfolding", "abstract": "The combination of deep unfolding with vector approximate message passing\n(VAMP) algorithm, results in faster convergence and higher sparse recovery\naccuracy than traditional compressive sensing approaches. However, deep\nunfolding alters the parameters in traditional VAMP algorithm, resulting in the\nunattainable distribution parameter of the recovery error of non-sparse noisy\nestimation via traditional VAMP, which hinders the utilization of VAMP deep\nunfolding in constant false alarm rate (CFAR) detection in sub-Nyquist radar\nsystem. Based on VAMP deep unfolding, we provide a parameter convergence\ndetector (PCD) to estimate the recovery error distribution parameter and\nimplement CFAR detection. Compared to the state-of-the-art approaches, both the\nsparse solution and non-sparse noisy estimation are utilized to estimate the\ndistribution parameter and implement CFAR detection in PCD, which leverages\nboth the VAMP distribution property and the improved sparse recovery accuracy\nprovided by deep unfolding. Simulation results indicate that PCD offers\nimproved false alarm rate control performance and higher target detection rate.", "published": "2025-04-14 06:06:20", "link": "http://arxiv.org/abs/2504.09907v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Fusing Bluetooth with Pedestrian Dead Reckoning: A Floor Plan-Assisted Positioning Approach", "abstract": "Floor plans can provide valuable prior information that helps enhance the\naccuracy of indoor positioning systems. However, existing research typically\nfaces challenges in efficiently leveraging floor plan information and applying\nit to complex indoor layouts. To fully exploit information from floor plans for\npositioning, we propose a floor plan-assisted fusion positioning algorithm\n(FP-BP) using Bluetooth low energy (BLE) and pedestrian dead reckoning (PDR).\nIn the considered system, a user holding a smartphone walks through a\npositioning area with BLE beacons installed on the ceiling, and can locate\nhimself in real time. In particular, FP-BP consists of two phases. In the\noffline phase, FP-BP programmatically extracts map features from a stylized\nfloor plan based on their binary masks, and constructs a mapping function to\nidentify the corresponding map feature of any given position on the map. In the\nonline phase, FP-BP continuously computes BLE positions and PDR results from\nBLE signals and smartphone sensors, where a novel grid-based maximum likelihood\nestimation (GML) algorithm is introduced to enhance BLE positioning. Then, a\nparticle filter is used to fuse them and obtain an initial estimate. Finally,\nFP-BP performs post-position correction to obtain the final position based on\nits specific map feature. Experimental results show that FP-BP can achieve a\nreal-time mean positioning accuracy of 1.19 m, representing an improvement of\nover 28% compared to existing floor plan-fused baseline algorithms.", "published": "2025-04-14 06:00:39", "link": "http://arxiv.org/abs/2504.09905v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Modelling & Steady State Compliance Testing of an Improved Time Synchronized Phasor Measurement Unit Based on IEEE Standard C37.118.1", "abstract": "Synchrophasor technology is an emerging and developing technology for\nmonitoring and control of wide area measurement systems (WAMS). In an\nelementary WAMS, two identical phasors measured at two different locations have\ndifference in the phase angles measured since their reference waveforms are not\nsynchronized with each other. Phasor measurement units (PMUs) measure input\nphasors with respect to a common reference wave based on the atomic clock\npulses received from global positioning system (GPS) satellites, eliminating\nvariation in the measured phase angles due to distant locations of the\nmeasurement nodes. This has found tremendous applications in quick fault\ndetection, fault location analysis, accurate current, voltage, frequency and\nphase angle measurements in WAMS. Commercially available PMU models are often\nproven to be expensive for research and development as well as for grid\nintegration projects. This research article proposes an economic PMU model\noptimized for accurate steadystate performance based on recursive discrete\nFourier transform (DFT) and provides results and detailed analysis of the\nproposed PMU model as per the steady state compliance specifications of IEEE\nstandard C37.118.1. Results accurate up to 13 digits after decimal point are\nobtained through the developed PMU model for both nominal and off-nominal\nfrequency inputs in steady state.", "published": "2025-04-14 05:13:34", "link": "http://arxiv.org/abs/2504.09883v1", "categories": ["eess.SP", "cs.SY", "eess.SY", "physics.soc-ph"], "primary_category": "eess.SP"}
{"title": "CKMImageNet: A Dataset for AI-Based Channel Knowledge Map Towards Environment-Aware Communication and Sensing", "abstract": "With the increasing demand for real-time channel state information (CSI) in\nsixth-generation (6G) mobile communication networks, channel knowledge map\n(CKM) emerges as a promising technique, offering a site-specific database that\nenables environment-awareness and significantly enhances communication and\nsensing performance by leveraging a priori wireless channel knowledge. However,\nefficient construction and utilization of CKMs require high-quality, massive,\nand location-specific channel knowledge data that accurately reflects the\nreal-world environments. Inspired by the great success of ImageNet dataset in\nadvancing computer vision and image understanding in artificial intelligence\n(AI) community, we introduce CKMImageNet, a dataset developed to bridge AI and\nenvironment-aware wireless communications and sensing by integrating\nlocation-specific channel knowledge data, high-fidelity environmental maps, and\ntheir visual representations. CKMImageNet supports a wide range of AI-driven\napproaches for CKM construction with spatially consistent and location-specific\nchannel knowledge data, including both supervised and unsupervised, as well as\ndiscriminative and generative AI methods.", "published": "2025-04-14 03:40:35", "link": "http://arxiv.org/abs/2504.09849v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Research and Experimental Validation for 3GPP ISAC Channel Modeling Standardization", "abstract": "Integrated Sensing and Communication (ISAC) is considered a key technology in\n6G networks. An accurate sensing channel model is crucial for the design and\nsensing performance evaluation of ISAC systems. The widely used Geometry-Based\nStochastic Model (GBSM), typically applied in standardized channel modeling,\nmainly focuses on the statistical fading characteristics of the channel.\nHowever, it fails to capture the characteristics of targets in ISAC systems,\nsuch as their positions and velocities, as well as the impact of the targets on\nthe background. To address this issue, this paper proposes an extended GBSM\n(E-GBSM) sensing channel model that incorporates newly discovered channel\ncharacteristics into a unified modeling framework. In this framework, the\nsensing channel is divided into target and background channels. For the target\nchannel, the model introduces a concatenated modeling approach, while for the\nbackground channel, a parameter called the power control factor is introduced\nto assess impact of the target on the background channel, making the modeling\nframework applicable to both mono-static and bi-static sensing modes. To\nvalidate the proposed model's effectiveness, measurements of target and\nbackground channels are conducted in both indoor and outdoor scenarios,\ncovering various sensing targets such as metal plates, reconfigurable\nintelligent surfaces, human bodies, UAVs, and vehicles. The experimental\nresults provide important theoretical support and empirical data for the\nstandardization of ISAC channel modeling.", "published": "2025-04-14 01:59:35", "link": "http://arxiv.org/abs/2504.09799v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "GUI-R1 : A Generalist R1-Style Vision-Language Action Model For GUI Agents", "abstract": "Existing efforts in building Graphical User Interface (GUI) agents largely\nrely on the training paradigm of supervised fine-tuning on Large\nVision-Language Models (LVLMs). However, this approach not only demands\nextensive amounts of training data but also struggles to effectively understand\nGUI screenshots and generalize to unseen interfaces. The issue significantly\nlimits its application in real-world scenarios, especially for high-level\ntasks. Inspired by Reinforcement Fine-Tuning (RFT) in large reasoning models\n(e.g., DeepSeek-R1), which efficiently enhances the problem-solving\ncapabilities of large language models in real-world settings, we propose \\name,\nthe first reinforcement learning framework designed to enhance the GUI\ncapabilities of LVLMs in high-level real-world task scenarios, through unified\naction space rule modeling. By leveraging a small amount of carefully curated\nhigh-quality data across multiple platforms (including Windows, Linux, MacOS,\nAndroid, and Web) and employing policy optimization algorithms such as Group\nRelative Policy Optimization (GRPO) to update the model, \\name achieves\nsuperior performance using only 0.02\\% of the data (3K vs. 13M) compared to\nprevious state-of-the-art methods like OS-Atlas across eight benchmarks\nspanning three different platforms (mobile, desktop, and web). These results\ndemonstrate the immense potential of reinforcement learning based on unified\naction space rule modeling in improving the execution capabilities of LVLMs for\nreal-world GUI agent tasks.", "published": "2025-04-14 17:45:54", "link": "http://arxiv.org/abs/2504.10458v2", "categories": ["cs.CV", "cs.CL", "cs.HC"], "primary_category": "cs.CV"}
{"title": "Unchecked and Overlooked: Addressing the Checkbox Blind Spot in Large Language Models with CheckboxQA", "abstract": "Checkboxes are critical in real-world document processing where the presence\nor absence of ticks directly informs data extraction and decision-making\nprocesses. Yet, despite the strong performance of Large Vision and Language\nModels across a wide range of tasks, they struggle with interpreting checkable\ncontent. This challenge becomes particularly pressing in industries where a\nsingle overlooked checkbox may lead to costly regulatory or contractual\noversights. To address this gap, we introduce the CheckboxQA dataset, a\ntargeted resource designed to evaluate and improve model performance on\ncheckbox-related tasks. It reveals the limitations of current models and serves\nas a valuable tool for advancing document comprehension systems, with\nsignificant implications for applications in sectors such as legal tech and\nfinance.\n  The dataset is publicly available at:\nhttps://github.com/Snowflake-Labs/CheckboxQA", "published": "2025-04-14 17:06:59", "link": "http://arxiv.org/abs/2504.10419v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MultiLoKo: a multilingual local knowledge benchmark for LLMs spanning 31 languages", "abstract": "We present MultiLoKo, a new benchmark for evaluating multilinguality in LLMs\ncovering 31 languages. MultiLoKo consists of three partitions: a main partition\nconsisting of 500 questions per language, separately sourced to be locally\nrelevant to the specific language, and two translated partitions, containing\nhuman-authored translations from 30 non-English languages to English and vice\nversa. For comparison, we also release corresponding machine-authored\ntranslations. The data is equally distributed over two splits: a dev split and\na blind, out-of-distribution test split. MultiLoKo can be used to study a\nvariety of questions regarding the multilinguality of LLMs as well as\nmeta-questions about multilingual benchmark creation. We compute MultiLoKo\nscores for 11 base and chat models marketed to be multilingual and study their\naverage performance, their performance parity across languages, how much their\nability to answer questions depends on the question language, and which\nlanguages are most difficult. None of the models we studied performs well on\nMultiLoKo, as indicated by low average scores as well as large differences\nbetween the best and worst scoring languages. Furthermore, we find a\nsubstantial effect of the question language, indicating sub-optimal knowledge\ntransfer between languages. Lastly, we find that using local vs\nEnglish-translated data can result in differences more than 20 points for the\nbest performing models, drastically change the estimated difficulty of some\nlanguages. For using machines instead of human translations, we find a weaker\neffect on ordering of language difficulty, a larger difference in model\nrankings, and a substantial drop in estimated performance for all models.", "published": "2025-04-14 16:05:59", "link": "http://arxiv.org/abs/2504.10356v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "VisualPuzzles: Decoupling Multimodal Reasoning Evaluation from Domain Knowledge", "abstract": "Current multimodal benchmarks often conflate reasoning with domain-specific\nknowledge, making it difficult to isolate and evaluate general reasoning\nabilities in non-expert settings. To address this, we introduce VisualPuzzles,\na benchmark that targets visual reasoning while deliberately minimizing\nreliance on specialized knowledge. VisualPuzzles consists of diverse questions\nspanning five categories: algorithmic, analogical, deductive, inductive, and\nspatial reasoning. One major source of our questions is manually translated\nlogical reasoning questions from the Chinese Civil Service Examination.\nExperiments show that VisualPuzzles requires significantly less intensive\ndomain-specific knowledge and more complex reasoning compared to benchmarks\nlike MMMU, enabling us to better evaluate genuine multimodal reasoning.\nEvaluations show that state-of-the-art multimodal large language models\nconsistently lag behind human performance on VisualPuzzles, and that strong\nperformance on knowledge-intensive benchmarks does not necessarily translate to\nsuccess on reasoning-focused, knowledge-light tasks. Additionally, reasoning\nenhancements such as scaling up inference compute (with \"thinking\" modes) yield\ninconsistent gains across models and task types, and we observe no clear\ncorrelation between model size and performance. We also found that models\nexhibit different reasoning and answering patterns on VisualPuzzles compared to\nbenchmarks with heavier emphasis on knowledge. VisualPuzzles offers a clearer\nlens through which to evaluate reasoning capabilities beyond factual recall and\ndomain knowledge.", "published": "2025-04-14 15:50:39", "link": "http://arxiv.org/abs/2504.10342v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Breaking the Data Barrier -- Building GUI Agents Through Task Generalization", "abstract": "Graphical User Interface (GUI) agents offer cross-platform solutions for\nautomating complex digital tasks, with significant potential to transform\nproductivity workflows. However, their performance is often constrained by the\nscarcity of high-quality trajectory data. To address this limitation, we\npropose training Vision Language Models (VLMs) on data-rich,\nreasoning-intensive tasks during a dedicated mid-training stage, and then\nexamine how incorporating these tasks facilitates generalization to GUI\nplanning scenarios. Specifically, we explore a range of tasks with readily\navailable instruction-tuning data, including GUI perception, multimodal\nreasoning, and textual reasoning. Through extensive experiments across 11\nmid-training tasks, we demonstrate that: (1) Task generalization proves highly\neffective, yielding substantial improvements across most settings. For\ninstance, multimodal mathematical reasoning enhances performance on\nAndroidWorld by an absolute 6.3%. Remarkably, text-only mathematical data\nsignificantly boosts GUI web agent performance, achieving a 5.6% improvement on\nWebArena and 5.4% improvement on AndroidWorld, underscoring notable cross-modal\ngeneralization from text-based to visual domains; (2) Contrary to prior\nassumptions, GUI perception data - previously considered closely aligned with\nGUI agent tasks and widely utilized for training - has a comparatively limited\nimpact on final performance; (3) Building on these insights, we identify the\nmost effective mid-training tasks and curate optimized mixture datasets,\nresulting in absolute performance gains of 8.0% on WebArena and 12.2% on\nAndroidWorld. Our work provides valuable insights into cross-domain knowledge\ntransfer for GUI agents and offers a practical approach to addressing data\nscarcity challenges in this emerging field. The code, data and models will be\navailable at https://github.com/hkust-nlp/GUIMid.", "published": "2025-04-14 11:35:02", "link": "http://arxiv.org/abs/2504.10127v2", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Weight Ensembling Improves Reasoning in Language Models", "abstract": "We investigate a failure mode that arises during the training of reasoning\nmodels, where the diversity of generations begins to collapse, leading to\nsuboptimal test-time scaling. Notably, the Pass@1 rate reliably improves during\nsupervised finetuning (SFT), but Pass@k rapidly deteriorates. Surprisingly, a\nsimple intervention of interpolating the weights of the latest SFT checkpoint\nwith an early checkpoint, otherwise known as WiSE-FT, almost completely\nrecovers Pass@k while also improving Pass@1. The WiSE-FT variant achieves\nbetter test-time scaling (Best@k, majority vote) and achieves superior results\nwith less data when tuned further by reinforcement learning. Finally, we find\nthat WiSE-FT provides complementary performance gains that cannot be achieved\nonly through diversity-inducing decoding strategies, like temperature scaling.\nWe formalize a bias-variance tradeoff of Pass@k with respect to the expectation\nand variance of Pass@1 over the test distribution. We find that WiSE-FT can\nreduce bias and variance simultaneously, while temperature scaling inherently\ntrades-off between bias and variance.", "published": "2025-04-14 17:59:07", "link": "http://arxiv.org/abs/2504.10478v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "WildLive: Near Real-time Visual Wildlife Tracking onboard UAVs", "abstract": "Live tracking of wildlife via high-resolution video processing directly\nonboard drones is widely unexplored and most existing solutions rely on\nstreaming video to ground stations to support navigation. Yet, both autonomous\nanimal-reactive flight control beyond visual line of sight and/or\nmission-specific individual and behaviour recognition tasks rely to some degree\non this capability. In response, we introduce WildLive -- a near real-time\nanimal detection and tracking framework for high-resolution imagery running\ndirectly onboard uncrewed aerial vehicles (UAVs). The system performs\nmulti-animal detection and tracking at 17fps+ for HD and 7fps+ on 4K video\nstreams suitable for operation during higher altitude flights to minimise\nanimal disturbance. Our system is optimised for Jetson Orin AGX onboard\nhardware. It integrates the efficiency of sparse optical flow tracking and\nmission-specific sampling with device-optimised and proven YOLO-driven object\ndetection and segmentation techniques. Essentially, computational resource is\nfocused onto spatio-temporal regions of high uncertainty to significantly\nimprove UAV processing speeds without domain-specific loss of accuracy.\nAlongside, we introduce our WildLive dataset, which comprises 200k+ annotated\nanimal instances across 19k+ frames from 4K UAV videos collected at the Ol\nPejeta Conservancy in Kenya. All frames contain ground truth bounding boxes,\nsegmentation masks, as well as individual tracklets and tracking point\ntrajectories. We compare our system against current object tracking approaches\nincluding OC-SORT, ByteTrack, and SORT. Our materials are available at:\nhttps://dat-nguyenvn.github.io/WildLive/", "published": "2025-04-14 12:21:16", "link": "http://arxiv.org/abs/2504.10165v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "MMKB-RAG: A Multi-Modal Knowledge-Based Retrieval-Augmented Generation Framework", "abstract": "Recent advancements in large language models (LLMs) and multi-modal LLMs have\nbeen remarkable. However, these models still rely solely on their parametric\nknowledge, which limits their ability to generate up-to-date information and\nincreases the risk of producing erroneous content. Retrieval-Augmented\nGeneration (RAG) partially mitigates these challenges by incorporating external\ndata sources, yet the reliance on databases and retrieval systems can introduce\nirrelevant or inaccurate documents, ultimately undermining both performance and\nreasoning quality. In this paper, we propose Multi-Modal Knowledge-Based\nRetrieval-Augmented Generation (MMKB-RAG), a novel multi-modal RAG framework\nthat leverages the inherent knowledge boundaries of models to dynamically\ngenerate semantic tags for the retrieval process. This strategy enables the\njoint filtering of retrieved documents, retaining only the most relevant and\naccurate references. Extensive experiments on knowledge-based visual\nquestion-answering tasks demonstrate the efficacy of our approach: on the E-VQA\ndataset, our method improves performance by +4.2% on the Single-Hop subset and\n+0.4% on the full dataset, while on the InfoSeek dataset, it achieves gains of\n+7.8% on the Unseen-Q subset, +8.2% on the Unseen-E subset, and +8.1% on the\nfull dataset. These results highlight significant enhancements in both accuracy\nand robustness over the current state-of-the-art MLLM and RAG frameworks.", "published": "2025-04-14 10:19:47", "link": "http://arxiv.org/abs/2504.10074v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models", "abstract": "We introduce InternVL3, a significant advancement in the InternVL series\nfeaturing a native multimodal pre-training paradigm. Rather than adapting a\ntext-only large language model (LLM) into a multimodal large language model\n(MLLM) that supports visual inputs, InternVL3 jointly acquires multimodal and\nlinguistic capabilities from both diverse multimodal data and pure-text corpora\nduring a single pre-training stage. This unified training paradigm effectively\naddresses the complexities and alignment challenges commonly encountered in\nconventional post-hoc training pipelines for MLLMs. To further improve\nperformance and scalability, InternVL3 incorporates variable visual position\nencoding (V2PE) to support extended multimodal contexts, employs advanced\npost-training techniques such as supervised fine-tuning (SFT) and mixed\npreference optimization (MPO), and adopts test-time scaling strategies\nalongside an optimized training infrastructure. Extensive empirical evaluations\ndemonstrate that InternVL3 delivers superior performance across a wide range of\nmulti-modal tasks. In particular, InternVL3-78B achieves a score of 72.2 on the\nMMMU benchmark, setting a new state-of-the-art among open-source MLLMs. Its\ncapabilities remain highly competitive with leading proprietary models,\nincluding ChatGPT-4o, Claude 3.5 Sonnet, and Gemini 2.5 Pro, while also\nmaintaining strong pure-language proficiency. In pursuit of open-science\nprinciples, we will publicly release both the training data and model weights\nto foster further research and development in next-generation MLLMs.", "published": "2025-04-14 17:59:25", "link": "http://arxiv.org/abs/2504.10479v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GPS: Distilling Compact Memories via Grid-based Patch Sampling for Efficient Online Class-Incremental Learning", "abstract": "Online class-incremental learning aims to enable models to continuously adapt\nto new classes with limited access to past data, while mitigating catastrophic\nforgetting. Replay-based methods address this by maintaining a small memory\nbuffer of previous samples, achieving competitive performance. For effective\nreplay under constrained storage, recent approaches leverage distilled data to\nenhance the informativeness of memory. However, such approaches often involve\nsignificant computational overhead due to the use of bi-level optimization.\nMotivated by these limitations, we introduce Grid-based Patch Sampling (GPS), a\nlightweight and effective strategy for distilling informative memory samples\nwithout relying on a trainable model. GPS generates informative samples by\nsampling a subset of pixels from the original image, yielding compact\nlow-resolution representations that preserve both semantic content and\nstructural information. During replay, these representations are reassembled to\nsupport training and evaluation. Experiments on extensive benchmarks\ndemonstrate that GRS can be seamlessly integrated into existing replay\nframeworks, leading to 3%-4% improvements in average end accuracy under\nmemory-constrained settings, with limited computational overhead.", "published": "2025-04-14 16:58:02", "link": "http://arxiv.org/abs/2504.10409v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LL-Gaussian: Low-Light Scene Reconstruction and Enhancement via Gaussian Splatting for Novel View Synthesis", "abstract": "Novel view synthesis (NVS) in low-light scenes remains a significant\nchallenge due to degraded inputs characterized by severe noise, low dynamic\nrange (LDR) and unreliable initialization. While recent NeRF-based approaches\nhave shown promising results, most suffer from high computational costs, and\nsome rely on carefully captured or pre-processed data--such as RAW sensor\ninputs or multi-exposure sequences--which severely limits their practicality.\nIn contrast, 3D Gaussian Splatting (3DGS) enables real-time rendering with\ncompetitive visual fidelity; however, existing 3DGS-based methods struggle with\nlow-light sRGB inputs, resulting in unstable Gaussian initialization and\nineffective noise suppression. To address these challenges, we propose\nLL-Gaussian, a novel framework for 3D reconstruction and enhancement from\nlow-light sRGB images, enabling pseudo normal-light novel view synthesis. Our\nmethod introduces three key innovations: 1) an end-to-end Low-Light Gaussian\nInitialization Module (LLGIM) that leverages dense priors from learning-based\nMVS approach to generate high-quality initial point clouds; 2) a dual-branch\nGaussian decomposition model that disentangles intrinsic scene properties\n(reflectance and illumination) from transient interference, enabling stable and\ninterpretable optimization; 3) an unsupervised optimization strategy guided by\nboth physical constrains and diffusion prior to jointly steer decomposition and\nenhancement. Additionally, we contribute a challenging dataset collected in\nextreme low-light environments and demonstrate the effectiveness of\nLL-Gaussian. Compared to state-of-the-art NeRF-based methods, LL-Gaussian\nachieves up to 2,000 times faster inference and reduces training time to just\n2%, while delivering superior reconstruction and rendering quality.", "published": "2025-04-14 15:39:31", "link": "http://arxiv.org/abs/2504.10331v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Trade-offs in Privacy-Preserving Eye Tracking through Iris Obfuscation: A Benchmarking Study", "abstract": "Recent developments in hardware, computer graphics, and AI may soon enable\nAR/VR head-mounted displays (HMDs) to become everyday devices like smartphones\nand tablets. Eye trackers within HMDs provide a special opportunity for such\nsetups as it is possible to facilitate gaze-based research and interaction.\nHowever, estimating users' gaze information often requires raw eye images and\nvideos that contain iris textures, which are considered a gold standard\nbiometric for user authentication, and this raises privacy concerns. Previous\nresearch in the eye-tracking community focused on obfuscating iris textures\nwhile keeping utility tasks such as gaze estimation accurate. Despite these\nattempts, there is no comprehensive benchmark that evaluates state-of-the-art\napproaches. Considering all, in this paper, we benchmark blurring, noising,\ndownsampling, rubber sheet model, and iris style transfer to obfuscate user\nidentity, and compare their impact on image quality, privacy, utility, and risk\nof imposter attack on two datasets. We use eye segmentation and gaze estimation\nas utility tasks, and reduction in iris recognition accuracy as a measure of\nprivacy protection, and false acceptance rate to estimate risk of attack. Our\nexperiments show that canonical image processing methods like blurring and\nnoising cause a marginal impact on deep learning-based tasks. While\ndownsampling, rubber sheet model, and iris style transfer are effective in\nhiding user identifiers, iris style transfer, with higher computation cost,\noutperforms others in both utility tasks, and is more resilient against spoof\nattacks. Our analyses indicate that there is no universal optimal approach to\nbalance privacy, utility, and computation burden. Therefore, we recommend\npractitioners consider the strengths and weaknesses of each approach, and\npossible combinations of those to reach an optimal privacy-utility trade-off.", "published": "2025-04-14 14:29:38", "link": "http://arxiv.org/abs/2504.10267v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Differentially Private 2D Human Pose Estimation", "abstract": "Human pose estimation (HPE) has become essential in numerous applications\nincluding healthcare, activity recognition, and human-computer interaction.\nHowever, the privacy implications of processing sensitive visual data present\nsignificant deployment barriers in critical domains. While traditional\nanonymization techniques offer limited protection and often compromise data\nutility for broader motion analysis, Differential Privacy (DP) provides formal\nprivacy guarantees but typically degrades model performance when applied\nnaively. In this work, we present the first differentially private 2D human\npose estimation (2D-HPE) by applying Differentially Private Stochastic Gradient\nDescent (DP-SGD) to this task. To effectively balance privacy with performance,\nwe adopt Projected DP-SGD (PDP-SGD), which projects the noisy gradients to a\nlow-dimensional subspace. Additionally, we adapt TinyViT, a compact and\nefficient vision transformer for coordinate classification in HPE, providing a\nlightweight yet powerful backbone that enhances privacy-preserving deployment\nfeasibility on resource-limited devices. Our approach is particularly valuable\nfor multimedia interpretation tasks, enabling privacy-safe analysis and\nunderstanding of human motion across diverse visual media while preserving the\nsemantic meaning required for downstream applications. Comprehensive\nexperiments on the MPII Human Pose Dataset demonstrate significant performance\nenhancement with PDP-SGD achieving 78.48% PCKh@0.5 at a strict privacy budget\n($\\epsilon=0.2$), compared to 63.85% for standard DP-SGD. This work lays\nfoundation for privacy-preserving human pose estimation in real-world,\nsensitive applications.", "published": "2025-04-14 12:50:37", "link": "http://arxiv.org/abs/2504.10190v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LLaVA-ReID: Selective Multi-image Questioner for Interactive Person Re-Identification", "abstract": "Traditional text-based person ReID assumes that person descriptions from\nwitnesses are complete and provided at once. However, in real-world scenarios,\nsuch descriptions are often partial or vague. To address this limitation, we\nintroduce a new task called interactive person re-identification (Inter-ReID).\nInter-ReID is a dialogue-based retrieval task that iteratively refines initial\ndescriptions through ongoing interactions with the witnesses. To facilitate the\nstudy of this new task, we construct a dialogue dataset that incorporates\nmultiple types of questions by decomposing fine-grained attributes of\nindividuals. We further propose LLaVA-ReID, a question model that generates\ntargeted questions based on visual and textual contexts to elicit additional\ndetails about the target person. Leveraging a looking-forward strategy, we\nprioritize the most informative questions as supervision during training.\nExperimental results on both Inter-ReID and text-based ReID benchmarks\ndemonstrate that LLaVA-ReID significantly outperforms baselines.", "published": "2025-04-14 12:26:31", "link": "http://arxiv.org/abs/2504.10174v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GaussVideoDreamer: 3D Scene Generation with Video Diffusion and Inconsistency-Aware Gaussian Splatting", "abstract": "Single-image 3D scene reconstruction presents significant challenges due to\nits inherently ill-posed nature and limited input constraints. Recent advances\nhave explored two promising directions: multiview generative models that train\non 3D consistent datasets but struggle with out-of-distribution generalization,\nand 3D scene inpainting and completion frameworks that suffer from cross-view\ninconsistency and suboptimal error handling, as they depend exclusively on\ndepth data or 3D smoothness, which ultimately degrades output quality and\ncomputational performance. Building upon these approaches, we present\nGaussVideoDreamer, which advances generative multimedia approaches by bridging\nthe gap between image, video, and 3D generation, integrating their strengths\nthrough two key innovations: (1) A progressive video inpainting strategy that\nharnesses temporal coherence for improved multiview consistency and faster\nconvergence. (2) A 3D Gaussian Splatting consistency mask to guide the video\ndiffusion with 3D consistent multiview evidence. Our pipeline combines three\ncore components: a geometry-aware initialization protocol, Inconsistency-Aware\nGaussian Splatting, and a progressive video inpainting strategy. Experimental\nresults demonstrate that our approach achieves 32% higher LLaVA-IQA scores and\nat least 2x speedup compared to existing methods while maintaining robust\nperformance across diverse scenes.", "published": "2025-04-14 09:04:01", "link": "http://arxiv.org/abs/2504.10001v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "OctGPT: Octree-based Multiscale Autoregressive Models for 3D Shape Generation", "abstract": "Autoregressive models have achieved remarkable success across various\ndomains, yet their performance in 3D shape generation lags significantly behind\nthat of diffusion models. In this paper, we introduce OctGPT, a novel\nmultiscale autoregressive model for 3D shape generation that dramatically\nimproves the efficiency and performance of prior 3D autoregressive approaches,\nwhile rivaling or surpassing state-of-the-art diffusion models. Our method\nemploys a serialized octree representation to efficiently capture the\nhierarchical and spatial structures of 3D shapes. Coarse geometry is encoded\nvia octree structures, while fine-grained details are represented by binary\ntokens generated using a vector quantized variational autoencoder (VQVAE),\ntransforming 3D shapes into compact multiscale binary sequences suitable for\nautoregressive prediction. To address the computational challenges of handling\nlong sequences, we incorporate octree-based transformers enhanced with 3D\nrotary positional encodings, scale-specific embeddings, and token-parallel\ngeneration schemes. These innovations reduce training time by 13 folds and\ngeneration time by 69 folds, enabling the efficient training of high-resolution\n3D shapes, e.g.,$1024^3$, on just four NVIDIA 4090 GPUs only within days.\nOctGPT showcases exceptional versatility across various tasks, including text-,\nsketch-, and image-conditioned generation, as well as scene-level synthesis\ninvolving multiple objects. Extensive experiments demonstrate that OctGPT\naccelerates convergence and improves generation quality over prior\nautoregressive methods, offering a new paradigm for high-quality, scalable 3D\ncontent creation. Our code and trained models are available at\nhttps://github.com/octree-nn/octgpt.", "published": "2025-04-14 08:31:26", "link": "http://arxiv.org/abs/2504.09975v2", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "TAMP: Token-Adaptive Layerwise Pruning in Multimodal Large Language Models", "abstract": "Multimodal Large Language Models (MLLMs) have shown remarkable versatility in\nunderstanding diverse multimodal data and tasks. However, these capabilities\ncome with an increased model scale. While post-training pruning reduces model\nsize in unimodal models, its application to MLLMs often yields limited success.\nOur analysis discovers that conventional methods fail to account for the unique\ntoken attributes across layers and modalities inherent to MLLMs. Inspired by\nthis observation, we propose TAMP, a simple yet effective pruning framework\ntailored for MLLMs, featuring two key components: (1) Diversity-Aware Sparsity,\nwhich adjusts sparsity ratio per layer based on diversities among multimodal\noutput tokens, preserving more parameters in high-diversity layers; and (2)\nAdaptive Multimodal Input Activation, which identifies representative\nmultimodal input tokens using attention scores to guide unstructured weight\npruning. We validate our method on two state-of-the-art MLLMs: LLaVA-NeXT,\ndesigned for vision-language tasks, and VideoLLaMA2, capable of processing\naudio, visual, and language modalities. Empirical experiments across various\nmultimodal evaluation benchmarks demonstrate that each component of our\napproach substantially outperforms existing pruning techniques.", "published": "2025-04-14 05:44:38", "link": "http://arxiv.org/abs/2504.09897v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "What metric to optimize for suppressing instability in a Vlasov-Poisson system?", "abstract": "Stabilizing plasma dynamics is an important task in green energy generation\nvia nuclear fusion. One common strategy is to introduce an external field to\nprevent the plasma distribution from developing turbulence. However, finding\nsuch external fields efficiently remains an open question, even for simplified\nmodels such as the Vlasov-Poisson (VP) system. In this work, we leverage two\ndifferent approaches to build such fields: for the first approach, we use an\nanalytical derivation of the dispersion relation of the VP system to find a\nrange of reasonable fields that can potentially suppress instability, providing\na qualitative suggestion. For the second approach, we leverage PDE-constrained\noptimization to obtain a locally optimal field using different loss functions.\nAs the stability of the system can be characterized in several different ways,\nthe objective functions need to be tailored accordingly. We show, through\nextensive numerical tests, that objective functions such as the relative\nentropy (KL divergence) and the $L^{2}$ norm result in a highly non-convex\nproblem, rendering the global minimum difficult to find. However, we show that\nusing the electric energy of the system as a loss function is advantageous, as\nit has a large convex basin close to the global minimum. Unfortunately, outside\nthe basin, the electric energy landscape consists of unphysical flat local\nminima, thus rendering a good initial guess key for the overall convergence of\nthe optimization problem, particularly for solvers with adaptive steps.", "published": "2025-04-14 17:26:09", "link": "http://arxiv.org/abs/2504.10435v2", "categories": ["math.NA", "cs.NA", "physics.comp-ph"], "primary_category": "math.NA"}
{"title": "Rotatable Antenna-Enabled Secure Wireless Communication", "abstract": "Rotatable antenna (RA) is a promising technology that exploits new spatial\ndegrees of freedom (DoFs) to improve wireless communication and sensing\nperformance. In this letter, we investigate an RA-enabled secure communication\nsystem where confidential information is transmitted from an RA-based access\npoint (AP) to a single-antenna legitimate user in the presence of multiple\neavesdroppers. We aim to maximize the achievable secrecy rate by jointly\noptimizing the transmit beamforming and the deflection angles of all RAs.\nAccordingly, we propose an efficient alternating optimization (AO) algorithm to\nobtain a high-quality suboptimal solution in an iterative manner, where the\ngeneralized Rayleigh quotient-based beamforming is applied and the RAs'\ndeflection angles are optimized by the successive convex approximation (SCA).\nSimulation results show that the proposed RA-enabled secure communication\nsystem achieves significant improvement in achievable secrecy rate as compared\nto various benchmark schemes.", "published": "2025-04-14 17:55:27", "link": "http://arxiv.org/abs/2504.10473v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Diversity Analysis for Indoor Terahertz Communication Systems under Small-Scale Fading", "abstract": "Harnessing diversity is fundamental to wireless communication systems,\nparticularly in the terahertz (THz) band, where severe path loss and\nsmall-scale fading pose significant challenges to system reliability and\nperformance. In this paper, we present a comprehensive diversity analysis for\nindoor THz communication systems, accounting for the combined effects of path\nloss and small-scale fading, with the latter modeled as an $\\alpha-\\mu$\ndistribution to reflect THz indoor channel conditions. We derive closed-form\nexpressions for the bit error rate (BER) as a function of the reciprocal of the\nsignal-to-noise ratio (SNR) and propose an asymptotic expression. Furthermore,\nwe validate these expressions through extensive simulations, which show strong\nagreement with the theoretical analysis, confirming the accuracy and robustness\nof the proposed methods. Our results show that the diversity order in THz\nsystems is primarily determined by the combined effects of the number of\nindependent paths, the severity of fading, and the degree of channel frequency\nselectivity, providing clear insights into how diversity gains can be optimized\nin high-frequency wireless networks.", "published": "2025-04-14 08:51:52", "link": "http://arxiv.org/abs/2504.09986v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "How Instruction and Reasoning Data shape Post-Training: Data Quality through the Lens of Layer-wise Gradients", "abstract": "As the post-training of large language models (LLMs) advances from\ninstruction-following to complex reasoning tasks, understanding how different\ndata affect finetuning dynamics remains largely unexplored. In this paper, we\npresent a spectral analysis of layer-wise gradients induced by low/high-quality\ninstruction and reasoning data for LLM post-training. Our analysis reveals that\nwidely-studied metrics for data evaluation, e.g., IFD, InsTag, Difficulty, and\nReward, can be explained and unified by spectral properties computed from\ngradients' singular value decomposition (SVD). Specifically, higher-quality\ndata are usually associated with lower nuclear norms and higher effective\nranks. Notably, effective rank exhibits better robustness and resolution than\nnuclear norm in capturing subtle quality differences. For example, reasoning\ndata achieves substantially higher effective ranks than instruction data,\nimplying richer gradient structures on more complex tasks. Our experiments also\nhighlight that models within the same family share similar gradient patterns\nregardless of their sizes, whereas different model families diverge\nsignificantly. Providing a unified view on the effects of data quality across\ninstruction and reasoning data, this work illuminates the interplay between\ndata quality and training stability, shedding novel insights into developing\nbetter data exploration strategies for post-training.", "published": "2025-04-14 23:53:47", "link": "http://arxiv.org/abs/2504.10766v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "CleanMAP: Distilling Multimodal LLMs for Confidence-Driven Crowdsourced HD Map Updates", "abstract": "The rapid growth of intelligent connected vehicles (ICVs) and integrated\nvehicle-road-cloud systems has increased the demand for accurate, real-time HD\nmap updates. However, ensuring map reliability remains challenging due to\ninconsistencies in crowdsourced data, which suffer from motion blur, lighting\nvariations, adverse weather, and lane marking degradation. This paper\nintroduces CleanMAP, a Multimodal Large Language Model (MLLM)-based\ndistillation framework designed to filter and refine crowdsourced data for\nhigh-confidence HD map updates. CleanMAP leverages an MLLM-driven lane\nvisibility scoring model that systematically quantifies key visual parameters,\nassigning confidence scores (0-10) based on their impact on lane detection. A\nnovel dynamic piecewise confidence-scoring function adapts scores based on lane\nvisibility, ensuring strong alignment with human evaluations while effectively\nfiltering unreliable data. To further optimize map accuracy, a\nconfidence-driven local map fusion strategy ranks and selects the top-k\nhighest-scoring local maps within an optimal confidence range (best score minus\n10%), striking a balance between data quality and quantity. Experimental\nevaluations on a real-world autonomous vehicle dataset validate CleanMAP's\neffectiveness, demonstrating that fusing the top three local maps achieves the\nlowest mean map update error of 0.28m, outperforming the baseline (0.37m) and\nmeeting stringent accuracy thresholds (<= 0.32m). Further validation with\nreal-vehicle data confirms 84.88% alignment with human evaluators, reinforcing\nthe model's robustness and reliability. This work establishes CleanMAP as a\nscalable and deployable solution for crowdsourced HD map updates, ensuring more\nprecise and reliable autonomous navigation. The code will be available at\nhttps://Ankit-Zefan.github.io/CleanMap/", "published": "2025-04-14 22:16:10", "link": "http://arxiv.org/abs/2504.10738v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.RO", "I.2.9; I.2.7; I.2.10; I.5.5; I.5.4; I.2.11"], "primary_category": "cs.CV"}
{"title": "HELIOS: Adaptive Model And Early-Exit Selection for Efficient LLM Inference Serving", "abstract": "Deploying large language models (LLMs) presents critical challenges due to\nthe inherent trade-offs associated with key performance metrics, such as\nlatency, accuracy, and throughput. Typically, gains in one metric is\naccompanied with degradation in others. Early-Exit LLMs (EE-LLMs) efficiently\nnavigate this trade-off space by skipping some of the later model layers when\nit confidently finds an output token early, thus reducing latency without\nimpacting accuracy. However, as the early exits taken depend on the task and\nare unknown apriori to request processing, EE-LLMs conservatively load the\nentire model, limiting resource savings and throughput. Also, current\nframeworks statically select a model for a user task, limiting our ability to\nadapt to changing nature of the input queries.\n  We propose HELIOS to address these challenges. First, HELIOS shortlists a set\nof candidate LLMs, evaluates them using a subset of prompts, gathering\ntelemetry data in real-time. Second, HELIOS uses the early exit data from these\nevaluations to greedily load the selected model only up to a limited number of\nlayers. This approach yields memory savings which enables us to process more\nrequests at the same time, thereby improving throughput. Third, HELIOS monitors\nand periodically reassesses the performance of the candidate LLMs and if\nneeded, switches to another model that can service incoming queries more\nefficiently (such as using fewer layers without lowering accuracy). Our\nevaluations show that HELIOS achieves 1.48$\\times$ throughput, 1.10$\\times$\nenergy-efficiency, 1.39$\\times$ lower response time, and 3.7$\\times$\nimprovements in inference batch sizes compared to the baseline, when optimizing\nfor the respective service level objectives.", "published": "2025-04-14 21:30:43", "link": "http://arxiv.org/abs/2504.10724v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "EMAFusion: A Self-Optimizing System for Seamless LLM Selection and Integration", "abstract": "While recent advances in large language models (LLMs) have significantly\nenhanced performance across diverse natural language tasks, the high\ncomputational and financial costs associated with their deployment remain\nsubstantial barriers. Existing routing strategies partially alleviate this\nchallenge by assigning queries to cheaper or specialized models, but they\nfrequently rely on extensive labeled data or fragile task-specific heuristics.\nConversely, fusion techniques aggregate multiple LLM outputs to boost accuracy\nand robustness, yet they often exacerbate cost and may reinforce shared biases.\n  We introduce EMAFusion, a new framework that self-optimizes for seamless LLM\nselection and reliable execution for a given query. Specifically, EMAFusion\nintegrates a taxonomy-based router for familiar query types, a learned router\nfor ambiguous inputs, and a cascading approach that progressively escalates\nfrom cheaper to more expensive models based on multi-judge confidence\nevaluations. Through extensive evaluations, we find EMAFusion outperforms the\nbest individual models by over 2.6 percentage points (94.3% vs. 91.7%), while\nbeing 4X cheaper than the average cost. EMAFusion further achieves a remarkable\n17.1 percentage point improvement over models like GPT-4 at less than 1/20th\nthe cost. Our combined routing approach delivers 94.3% accuracy compared to\ntaxonomy-based (88.1%) and learned model predictor-based (91.7%) methods alone,\ndemonstrating the effectiveness of our unified strategy. Finally, EMAFusion\nsupports flexible cost-accuracy trade-offs, allowing users to balance their\nbudgetary constraints and performance needs.", "published": "2025-04-14 20:04:54", "link": "http://arxiv.org/abs/2504.10681v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Keyword Extraction, and Aspect Classification in Sinhala, English, and Code-Mixed Content", "abstract": "Brand reputation in the banking sector is maintained through insightful\nanalysis of customer opinion on code-mixed and multilingual content.\nConventional NLP models misclassify or ignore code-mixed text, when mix with\nlow resource languages such as Sinhala-English and fail to capture\ndomain-specific knowledge. This study introduces a hybrid NLP method to improve\nkeyword extraction, content filtering, and aspect-based classification of\nbanking content. Keyword extraction in English is performed with a hybrid\napproach comprising a fine-tuned SpaCy NER model, FinBERT-based KeyBERT\nembeddings, YAKE, and EmbedRank, which results in a combined accuracy of 91.2%.\nCode-mixed and Sinhala keywords are extracted using a fine-tuned XLM-RoBERTa\nmodel integrated with a domain-specific Sinhala financial vocabulary, and it\nresults in an accuracy of 87.4%. To ensure data quality, irrelevant comment\nfiltering was performed using several models, with the BERT-base-uncased model\nachieving 85.2% for English and XLM-RoBERTa 88.1% for Sinhala, which was better\nthan GPT-4o, SVM, and keyword-based filtering. Aspect classification followed\nthe same pattern, with the BERT-base-uncased model achieving 87.4% for English\nand XLM-RoBERTa 85.9% for Sinhala, both exceeding GPT-4 and keyword-based\napproaches. These findings confirm that fine-tuned transformer models\noutperform traditional methods in multilingual financial text analysis. The\npresent framework offers an accurate and scalable solution for brand reputation\nmonitoring in code-mixed and low-resource banking environments.", "published": "2025-04-14 20:01:34", "link": "http://arxiv.org/abs/2504.10679v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Characterizing Knowledge Manipulation in a Russian Wikipedia Fork", "abstract": "Wikipedia is powered by MediaWiki, a free and open-source software that is\nalso the infrastructure for many other wiki-based online encyclopedias. These\ninclude the recently launched website Ruwiki, which has copied and modified the\noriginal Russian Wikipedia content to conform to Russian law. To identify\npractices and narratives that could be associated with different forms of\nknowledge manipulation, this article presents an in-depth analysis of this\nRussian Wikipedia fork. We propose a methodology to characterize the main\nchanges with respect to the original version. The foundation of this study is a\ncomprehensive comparative analysis of more than 1.9M articles from Russian\nWikipedia and its fork. Using meta-information and geographical, temporal,\ncategorical, and textual features, we explore the changes made by Ruwiki\neditors. Furthermore, we present a classification of the main topics of\nknowledge manipulation in this fork, including a numerical estimation of their\nscope. This research not only sheds light on significant changes within Ruwiki,\nbut also provides a methodology that could be applied to analyze other\nWikipedia forks and similar collaborative projects.", "published": "2025-04-14 19:30:30", "link": "http://arxiv.org/abs/2504.10663v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LITERA: An LLM Based Approach to Latin-to-English Translation", "abstract": "This paper introduces an LLM-based Latin-to-English translation platform\ndesigned to address the challenges of translating Latin texts. We named the\nmodel LITERA, which stands for Latin Interpretation and Translations into\nEnglish for Research Assistance. Through a multi-layered translation process\nutilizing a fine-tuned version of GPT-4o-mini and GPT-4o, LITERA offers an\nunprecedented level of accuracy, showcased by greatly improved BLEU scores,\nparticularly in classical Latin, along with improved BLEURT scores. The\ndevelopment of LITERA involved close collaboration with Duke University's\nClassical Studies Department, which was instrumental in creating a small,\nhigh-quality parallel Latin-English dataset. This paper details the\narchitecture, fine-tuning methodology, and prompting strategies used in LITERA,\nemphasizing its ability to produce literal translations.", "published": "2025-04-14 19:21:20", "link": "http://arxiv.org/abs/2504.10660v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Will AI shape the way we speak? The emerging sociolinguistic influence of synthetic voices", "abstract": "The growing prevalence of conversational voice interfaces, powered by\ndevelopments in both speech and language technologies, raises important\nquestions about their influence on human communication. While written\ncommunication can signal identity through lexical and stylistic choices,\nvoice-based interactions inherently amplify socioindexical elements - such as\naccent, intonation, and speech style - which more prominently convey social\nidentity and group affiliation. There is evidence that even passive media such\nas television is likely to influence the audience's linguistic patterns. Unlike\npassive media, conversational AI is interactive, creating a more immersive and\nreciprocal dynamic that holds a greater potential to impact how individuals\nspeak in everyday interactions. Such heightened influence can be expected to\narise from phenomena such as acoustic-prosodic entrainment and linguistic\naccommodation, which occur naturally during interaction and enable users to\nadapt their speech patterns in response to the system. While this phenomenon is\nstill emerging, its potential societal impact could provide organisations,\nmovements, and brands with a subtle yet powerful avenue for shaping and\ncontrolling public perception and social identity. We argue that the\nsocioindexical influence of AI-generated speech warrants attention and should\nbecome a focus of interdisciplinary research, leveraging new and existing\nmethodologies and technologies to better understand its implications.", "published": "2025-04-14 19:04:32", "link": "http://arxiv.org/abs/2504.10650v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC", "eess.AS", "I.2.7; K.4.2; H.5.2"], "primary_category": "cs.CY"}
{"title": "Improving In-Context Learning with Reasoning Distillation", "abstract": "Language models rely on semantic priors to perform in-context learning, which\nleads to poor performance on tasks involving inductive reasoning.\nInstruction-tuning methods based on imitation learning can superficially\nenhance the in-context learning performance of language models, but they often\nfail to improve the model's understanding of the underlying rules that connect\ninputs and outputs in few-shot demonstrations. We propose ReDis, a reasoning\ndistillation technique designed to improve the inductive reasoning capabilities\nof language models. Through a careful combination of data augmentation,\nfiltering, supervised fine-tuning, and alignment, ReDis achieves significant\nperformance improvements across a diverse range of tasks, including 1D-ARC,\nList Function, ACRE, and MiniSCAN. Experiments on three language model\nbackbones show that ReDis outperforms equivalent few-shot prompting baselines\nacross all tasks and even surpasses the teacher model, GPT-4o, in some cases.\nReDis, based on the LLaMA-3 backbone, achieves relative improvements of 23.2%,\n2.8%, and 66.6% over GPT-4o on 1D-ARC, ACRE, and MiniSCAN, respectively, within\na similar hypothesis search space. The code, dataset, and model checkpoints\nwill be made available at\nhttps://github.com/NafisSadeq/reasoning-distillation.git.", "published": "2025-04-14 18:59:10", "link": "http://arxiv.org/abs/2504.10647v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Weight-of-Thought Reasoning: Exploring Neural Network Weights for Enhanced LLM Reasoning", "abstract": "Large language models (LLMs) have demonstrated remarkable reasoning\ncapabilities when prompted with strategies such as Chain-of-Thought (CoT).\nHowever, these approaches focus on token-level output without considering\ninternal weight dynamics. We introduce Weight-of-Thought (WoT) reasoning, a\nnovel approach that examines neural network weights before inference to\nidentify reasoning pathways. Unlike existing methods, WoT explores the weight\nspace through graph-based message passing, multi-step reasoning processes, and\nattention mechanisms. Our implementation creates an interconnected graph of\nreasoning nodes. Experiments on diverse reasoning tasks (syllogistic,\nmathematical, algebraic, combinatorial, and geometric) demonstrate that WoT\nachieves superior performance compared to traditional methods, particularly for\ncomplex problems. This approach leads to both improved performance and greater\ninterpretability of the reasoning process, offering a promising direction for\nenhancing LLM reasoning capabilities.", "published": "2025-04-14 18:56:29", "link": "http://arxiv.org/abs/2504.10646v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Better Estimation of the KL Divergence Between Language Models", "abstract": "Estimating the Kullback--Leibler (KL) divergence between language models has\nmany applications, e.g., reinforcement learning from human feedback (RLHF),\ninterpretability, and knowledge distillation. However, computing the exact KL\ndivergence between two arbitrary language models is intractable. Thus,\npractitioners often resort to the use of sampling-based estimators. While it is\neasy to fashion a simple Monte Carlo (MC) estimator that provides an unbiased\nestimate of the KL divergence between language models, this estimator\nnotoriously suffers from high variance, and can even result in a negative\nestimate of the KL divergence, a non-negative quantity. In this paper, we\nintroduce a Rao--Blackwellized estimator that is also unbiased and provably has\nvariance less than or equal to that of the standard Monte Carlo estimator. In\nan empirical study on sentiment-controlled fine-tuning, we show that our\nestimator provides more stable KL estimates and reduces variance substantially\nin practice. Additionally, we derive an analogous Rao--Blackwellized estimator\nof the gradient of the KL divergence, which leads to more stable training and\nproduces models that more frequently appear on the Pareto frontier of reward\nvs. KL compared to the ones trained with the MC estimator of the gradient.", "published": "2025-04-14 18:40:02", "link": "http://arxiv.org/abs/2504.10637v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Beyond Chains of Thought: Benchmarking Latent-Space Reasoning Abilities in Large Language Models", "abstract": "Large language models (LLMs) can perform reasoning computations both\ninternally within their latent space and externally by generating explicit\ntoken sequences like chains of thought. Significant progress in enhancing\nreasoning abilities has been made by scaling test-time compute. However,\nunderstanding and quantifying model-internal reasoning abilities - the\ninferential \"leaps\" models make between individual token predictions - remains\ncrucial. This study introduces a benchmark (n = 4,000 items) designed to\nquantify model-internal reasoning in different domains. We achieve this by\nhaving LLMs indicate the correct solution to reasoning problems not through\ndescriptive text, but by selecting a specific language of their initial\nresponse token that is different from English, the benchmark language. This not\nonly requires models to reason beyond their context window, but also to\noverrise their default tendency to respond in the same language as the prompt,\nthereby posing an additional cognitive strain. We evaluate a set of 18 LLMs,\nshowing significant performance variations, with GPT-4.5 achieving the highest\naccuracy (74.7%), outperforming models like Grok-2 (67.2%), and Llama 3.1 405B\n(65.6%). Control experiments and difficulty scaling analyses suggest that while\nLLMs engage in internal reasoning, we cannot rule out heuristic exploitations\nunder certain conditions, marking an area for future investigation. Our\nexperiments demonstrate that LLMs can \"think\" via latent-space computations,\nrevealing model-internal inference strategies that need further understanding,\nespecially regarding safety-related concerns such as covert planning,\ngoal-seeking, or deception emerging without explicit token traces.", "published": "2025-04-14 18:15:27", "link": "http://arxiv.org/abs/2504.10615v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Epistemic Uncertainty-aware Recommendation Systems via Bayesian Deep Ensemble Learning", "abstract": "Recommending items to users has long been a fundamental task, and studies\nhave tried to improve it ever since. Most well-known models commonly employ\nrepresentation learning to map users and items into a unified embedding space\nfor matching assessment. These approaches have primary limitations, especially\nwhen dealing with explicit feedback and sparse data contexts. Two primary\nlimitations are their proneness to overfitting and failure to incorporate\nepistemic uncertainty in predictions. To address these problems, we propose a\nnovel Bayesian Deep Ensemble Collaborative Filtering method named BDECF. To\nimprove model generalization and quality, we utilize Bayesian Neural Networks,\nwhich incorporate uncertainty within their weight parameters. In addition, we\nintroduce a new interpretable non-linear matching approach for the user and\nitem embeddings, leveraging the advantages of the attention mechanism.\nFurthermore, we endorse the implementation of an ensemble-based supermodel to\ngenerate more robust and reliable predictions, resulting in a more complete\nmodel. Empirical evaluation through extensive experiments and ablation studies\nacross a range of publicly accessible real-world datasets with differing\nsparsity characteristics confirms our proposed method's effectiveness and the\nimportance of its components.", "published": "2025-04-14 23:04:35", "link": "http://arxiv.org/abs/2504.10753v1", "categories": ["cs.IR", "cs.AI", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Communication-aware Hierarchical Map Compression of Time-Varying Environments for Mobile Robots", "abstract": "In this paper, we develop a systematic framework for the time-sequential\ncompression of dynamic probabilistic occupancy grids. Our approach leverages\nideas from signal compression theory to formulate an optimization problem that\nsearches for a multi-resolution hierarchical encoder that balances the quality\nof the compressed map (distortion) with its description size, the latter of\nwhich relates to the bandwidth required to reliably transmit the map to other\nagents or to store map estimates in on-board memory. The resulting optimization\nproblem allows for multi-resolution map compressions to be obtained that\nsatisfy available communication or memory resources, and does not require\nknowledge of the occupancy map dynamics. We develop an algorithm to solve our\nproblem, and demonstrate the utility of the proposed framework in simulation on\nboth static (i.e., non-time varying) and dynamic (time-varying) occupancy maps.", "published": "2025-04-14 22:54:29", "link": "http://arxiv.org/abs/2504.10751v1", "categories": ["cs.RO", "cs.AI", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Hearing Anywhere in Any Environment", "abstract": "In mixed reality applications, a realistic acoustic experience in spatial\nenvironments is as crucial as the visual experience for achieving true\nimmersion. Despite recent advances in neural approaches for Room Impulse\nResponse (RIR) estimation, most existing methods are limited to the single\nenvironment on which they are trained, lacking the ability to generalize to new\nrooms with different geometries and surface materials. We aim to develop a\nunified model capable of reconstructing the spatial acoustic experience of any\nenvironment with minimum additional measurements. To this end, we present xRIR,\na framework for cross-room RIR prediction. The core of our generalizable\napproach lies in combining a geometric feature extractor, which captures\nspatial context from panorama depth images, with a RIR encoder that extracts\ndetailed acoustic features from only a few reference RIR samples. To evaluate\nour method, we introduce ACOUSTICROOMS, a new dataset featuring high-fidelity\nsimulation of over 300,000 RIRs from 260 rooms. Experiments show that our\nmethod strongly outperforms a series of baselines. Furthermore, we successfully\nperform sim-to-real transfer by evaluating our model on four real-world\nenvironments, demonstrating the generalizability of our approach and the\nrealism of our dataset.", "published": "2025-04-14 22:37:52", "link": "http://arxiv.org/abs/2504.10746v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Token Sliding Reconfiguration on DAGs", "abstract": "Given a graph $G$ and two independent sets of same size, the Independent Set\nReconfiguration Problem under token sliding ask whether one can, in a step by\nstep manner, transform the first independent set into the second one. In each\nstep we must preserve the condition of independence. Further, referring to\nsolution vertices as tokens, we are only permitted to slide a token along an\nedge. Until the recent work of Ito et al. [Ito et al. MFCS 2022] this problem\nwas only considered on undirected graphs. In this work, we study\nreconfiguration under token sliding focusing on DAGs.\n  We present a complete dichotomy of intractability in regard to the depth of\nthe DAG, by proving that this problem is NP-complete for DAGs of depth 3 and\n$\\textrm{W}[1]$-hard for depth 4 when parameterized by the number of tokens\n$k$, and that these bounds are tight. Further, we prove that it is fixed\nparameter tractable on DAGs parameterized by the combination of treewidth and\n$k$. We show that this result applies to undirected graphs, when the number of\ntimes a token can visit a vertex is restricted.", "published": "2025-04-14 19:47:36", "link": "http://arxiv.org/abs/2504.10671v1", "categories": ["cs.DM"], "primary_category": "cs.DM"}
{"title": "On the Asymptotics of the Connectivity Probability of Random Bipartite Graphs", "abstract": "In this paper, we analyze the exact asymptotic behavior of the connectivity\nprobability in a random binomial bipartite graph $G(n,m,p)$ under various\nregimes of the edge probability $p=p(n)$. To determine this probability, a\nmethod based on the analysis of inhomogeneous random walks is proposed.", "published": "2025-04-14 18:44:56", "link": "http://arxiv.org/abs/2504.10640v1", "categories": ["math.PR", "cs.DM", "math.CO"], "primary_category": "math.PR"}
{"title": "Re-imagining Spectral Graph Theory", "abstract": "We propose a Laplacian based on general inner product spaces, which we call\nthe inner product Laplacian. We show the combinatorial and normalized graph\nLaplacians, as well as other Laplacians for hypergraphs and directed graphs,\nare special cases of the inner product Laplacian. After developing the\nnecessary basic theory for the inner product Laplacian, we establish\ngeneralized analogs of key isoperimetric inequalities, including the Cheeger\ninequality and expander mixing lemma. Dirichlet and Neumann subgraph\neigenvalues may also be recovered as appropriate limit points of a sequence of\ninner product Laplacians. In addition to suggesting a new context through which\nto examine existing Laplacians, this generalized framework is also flexible in\napplications: through choice of an inner product on the vertices and edges of a\ngraph, the inner product Laplacian naturally encodes both combinatorial\nstructure and domain-knowledge.", "published": "2025-04-14 18:23:20", "link": "http://arxiv.org/abs/2504.10624v1", "categories": ["math.CO", "cs.DM", "05C50 (Primary)"], "primary_category": "math.CO"}
{"title": "Enhancing Document Retrieval for Curating N-ary Relations in Knowledge Bases", "abstract": "Curation of biomedical knowledge bases (KBs) relies on extracting accurate\nmulti-entity relational facts from the literature - a process that remains\nlargely manual and expert-driven. An essential step in this workflow is\nretrieving documents that can support or complete partially observed n-ary\nrelations. We present a neural retrieval model designed to assist KB curation\nby identifying documents that help fill in missing relation arguments and\nprovide relevant contextual evidence.\n  To reduce dependence on scarce gold-standard training data, we exploit\nexisting KB records to construct weakly supervised training sets. Our approach\nintroduces two key technical contributions: (i) a layered contrastive loss that\nenables learning from noisy and incomplete relational structures, and (ii) a\nbalanced sampling strategy that generates high-quality negatives from diverse\nKB records. On two biomedical retrieval benchmarks, our approach achieves\nstate-of-the-art performance, outperforming strong baselines in NDCG@10 by 5.7\nand 3.7 percentage points, respectively.", "published": "2025-04-14 18:11:53", "link": "http://arxiv.org/abs/2504.10613v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "VAE-based Feature Disentanglement for Data Augmentation and Compression in Generalized GNSS Interference Classification", "abstract": "Distributed learning and Edge AI necessitate efficient data processing,\nlow-latency communication, decentralized model training, and stringent data\nprivacy to facilitate real-time intelligence on edge devices while reducing\ndependency on centralized infrastructure and ensuring high model performance.\nIn the context of global navigation satellite system (GNSS) applications, the\nprimary objective is to accurately monitor and classify interferences that\ndegrade system performance in distributed environments, thereby enhancing\nsituational awareness. To achieve this, machine learning (ML) models can be\ndeployed on low-resource devices, ensuring minimal communication latency and\npreserving data privacy. The key challenge is to compress ML models while\nmaintaining high classification accuracy. In this paper, we propose variational\nautoencoders (VAEs) for disentanglement to extract essential latent features\nthat enable accurate classification of interferences. We demonstrate that the\ndisentanglement approach can be leveraged for both data compression and data\naugmentation by interpolating the lower-dimensional latent representations of\nsignal power. To validate our approach, we evaluate three VAE variants -\nvanilla, factorized, and conditional generative - on four distinct datasets,\nincluding two collected in controlled indoor environments and two real-world\nhighway datasets. Additionally, we conduct extensive hyperparameter searches to\noptimize performance. Our proposed VAE achieves a data compression rate ranging\nfrom 512 to 8,192 and achieves an accuracy up to 99.92%.", "published": "2025-04-14 13:38:00", "link": "http://arxiv.org/abs/2504.10556v1", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT", "94-05, 82-11", "E.0; I.2.0; I.5.4; I.5.1"], "primary_category": "cs.LG"}
{"title": "Auto-Test: Learning Semantic-Domain Constraints for Unsupervised Error Detection in Tables", "abstract": "Data cleaning is a long-standing challenge in data management. While powerful\nlogic and statistical algorithms have been developed to detect and repair data\nerrors in tables, existing algorithms predominantly rely on domain-experts to\nfirst manually specify data-quality constraints specific to a given table,\nbefore data cleaning algorithms can be applied.\n  In this work, we propose a new class of data-quality constraints that we call\nSemantic-Domain Constraints, which can be reliably inferred and automatically\napplied to any tables, without requiring domain-experts to manually specify on\na per-table basis. We develop a principled framework to systematically learn\nsuch constraints from table corpora using large-scale statistical tests, which\ncan further be distilled into a core set of constraints using our optimization\nframework, with provable quality guarantees. Extensive evaluations show that\nthis new class of constraints can be used to both (1) directly detect errors on\nreal tables in the wild, and (2) augment existing expert-driven data-cleaning\ntechniques as a new class of complementary constraints.\n  Our extensively labeled benchmark dataset with 2400 real data columns, as\nwell as our code are available at https://github.com/qixuchen/AutoTest to\nfacilitate future research.", "published": "2025-04-14 23:26:55", "link": "http://arxiv.org/abs/2504.10762v1", "categories": ["cs.DB", "cs.LG"], "primary_category": "cs.DB"}
{"title": "ReasonDrive: Efficient Visual Question Answering for Autonomous Vehicles with Reasoning-Enhanced Small Vision-Language Models", "abstract": "Vision-language models (VLMs) show promise for autonomous driving but often\nlack transparent reasoning capabilities that are critical for safety. We\ninvestigate whether explicitly modeling reasoning during fine-tuning enhances\nVLM performance on driving decision tasks. Using GPT-4o, we generate structured\nreasoning chains for driving scenarios from the DriveLM benchmark with\ncategory-specific prompting strategies. We compare reasoning-based fine-tuning,\nanswer-only fine-tuning, and baseline instruction-tuned models across multiple\nsmall VLM families (Llama 3.2, Llava 1.5, and Qwen 2.5VL). Our results\ndemonstrate that reasoning-based fine-tuning consistently outperforms\nalternatives, with Llama3.2-11B-reason achieving the highest performance.\nModels fine-tuned with reasoning show substantial improvements in accuracy and\ntext generation quality, suggesting explicit reasoning enhances internal\nrepresentations for driving decisions. These findings highlight the importance\nof transparent decision processes in safety-critical domains and offer a\npromising direction for developing more interpretable autonomous driving\nsystems.", "published": "2025-04-14 23:16:07", "link": "http://arxiv.org/abs/2504.10757v1", "categories": ["cs.CV", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "auto-fpt: Automating Free Probability Theory Calculations for Machine Learning Theory", "abstract": "A large part of modern machine learning theory often involves computing the\nhigh-dimensional expected trace of a rational expression of large rectangular\nrandom matrices. To symbolically compute such quantities using free probability\ntheory, we introduce auto-fpt, a lightweight Python and SymPy-based tool that\ncan automatically produce a reduced system of fixed-point equations which can\nbe solved for the quantities of interest, and effectively constitutes a theory.\nWe overview the algorithmic ideas underlying auto-fpt and its applications to\nvarious interesting problems, such as the high-dimensional error of linearized\nfeed-forward neural networks, recovering well-known results. We hope that\nauto-fpt streamlines the majority of calculations involved in high-dimensional\nanalysis, while helping the machine learning community reproduce known and\nuncover new phenomena.", "published": "2025-04-14 23:07:56", "link": "http://arxiv.org/abs/2504.10754v1", "categories": ["cs.LG", "cs.MS"], "primary_category": "cs.LG"}
{"title": "Time-varying EEG spectral power predicts evoked and spontaneous fMRI motor brain activity", "abstract": "Simultaneous EEG-fMRI recordings are increasingly used to investigate brain\nactivity by leveraging the complementary high spatial and high temporal\nresolution of fMRI and EEG signals respectively. It remains unclear, however,\nto what degree these two imaging modalities capture shared information about\nneural activity. Here, we investigate whether it is possible to predict both\ntask-evoked and spontaneous fMRI signals of motor brain networks from EEG\ntime-varying spectral power using interpretable models trained for individual\nsubjects with Sparse Group Lasso regularization. Critically, we test the\ntrained models on data acquired from each subject on a different day and obtain\nstatistical validation by comparison with appropriate null models as well as\nthe conventional EEG sensorimotor rhythm. We find significant prediction\nresults in most subjects, although less frequently for resting-state compared\nto task-based conditions. Furthermore, we interpret the model learned\nparameters to understand representations of EEG-fMRI coupling in terms of\npredictive EEG channels, frequencies, and haemodynamic delays. In conclusion,\nour work provides evidence of the ability to predict fMRI motor brain activity\nfrom EEG recordings alone across different days, in both task-evoked and\nspontaneous conditions, with statistical significance in individual subjects.\nThese results present great potential for translation to EEG neurofeedback\napplications.", "published": "2025-04-14 22:54:41", "link": "http://arxiv.org/abs/2504.10752v1", "categories": ["cs.LG", "q-bio.NC"], "primary_category": "cs.LG"}
{"title": "Frozen Layers: Memory-efficient Many-fidelity Hyperparameter Optimization", "abstract": "As model sizes grow, finding efficient and cost-effective hyperparameter\noptimization (HPO) methods becomes increasingly crucial for deep learning\npipelines. While multi-fidelity HPO (MF-HPO) trades off computational resources\nrequired for DL training with lower fidelity estimations, existing fidelity\nsources often fail under lower compute and memory constraints. We propose a\nnovel fidelity source: the number of layers that are trained or frozen during\ntraining. For deep networks, this approach offers significant compute and\nmemory savings while preserving rank correlations between hyperparameters at\nlow fidelities compared to full model training. We demonstrate this in our\nempirical evaluation across ResNets and Transformers and additionally analyze\nthe utility of frozen layers as a fidelity in using GPU resources as a fidelity\nin HPO, and for a combined MF-HPO with other fidelity sources. This\ncontribution opens new applications for MF-HPO with hardware resources as a\nfidelity and creates opportunities for improved algorithms navigating joint\nfidelity spaces.", "published": "2025-04-14 22:06:24", "link": "http://arxiv.org/abs/2504.10735v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Cross-Problem Parameter Transfer in Quantum Approximate Optimization Algorithm: A Machine Learning Approach", "abstract": "Quantum Approximate Optimization Algorithm (QAOA) is one of the most\npromising candidates to achieve the quantum advantage in solving combinatorial\noptimization problems. The process of finding a good set of variational\nparameters in the QAOA circuit has proven to be challenging due to multiple\nfactors, such as barren plateaus. As a result, there is growing interest in\nexploiting parameter transferability, where parameter sets optimized for one\nproblem instance are transferred to another that could be more complex either\nto estimate the solution or to serve as a warm start for further optimization.\nBut can we transfer parameters from one class of problems to another?\nLeveraging parameter sets learned from a well-studied class of problems could\nhelp navigate the less studied one, reducing optimization overhead and\nmitigating performance pitfalls. In this paper, we study whether pretrained\nQAOA parameters of MaxCut can be used as is or to warm start the Maximum\nIndependent Set (MIS) circuits. Specifically, we design machine learning models\nto find good donor candidates optimized on MaxCut and apply their parameters to\nMIS acceptors. Our experimental results show that such parameter transfer can\nsignificantly reduce the number of optimization iterations required while\nachieving comparable approximation ratios.", "published": "2025-04-14 21:56:11", "link": "http://arxiv.org/abs/2504.10733v1", "categories": ["quant-ph", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Leveraging Deep Operator Networks (DeepONet) for Acoustic Full Waveform Inversion (FWI)", "abstract": "Full Waveform Inversion (FWI) is an important geophysical technique\nconsidered in subsurface property prediction. It solves the inverse problem of\npredicting high-resolution Earth interior models from seismic data. Traditional\nFWI methods are computationally demanding. Inverse problems in geophysics often\nface challenges of non-uniqueness due to limited data, as data are often\ncollected only on the surface. In this study, we introduce a novel methodology\nthat leverages Deep Operator Networks (DeepONet) to attempt to improve both the\nefficiency and accuracy of FWI. The proposed DeepONet methodology inverts\nseismic waveforms for the subsurface velocity field. This approach is able to\ncapture some key features of the subsurface velocity field. We have shown that\nthe architecture can be applied to noisy seismic data with an accuracy that is\nbetter than some other machine learning methods. We also test our proposed\nmethod with out-of-distribution prediction for different velocity models. The\nproposed DeepONet shows comparable and better accuracy in some velocity models\nthan some other machine learning methods. To improve the FWI workflow, we\npropose using the DeepONet output as a starting model for conventional FWI and\nthat it may improve FWI performance. While we have only shown that DeepONet\nfacilitates faster convergence than starting with a homogeneous velocity field,\nit may have some benefits compared to other approaches to constructing starting\nmodels. This integration of DeepONet into FWI may accelerate the inversion\nprocess and may also enhance its robustness and reliability.", "published": "2025-04-14 21:24:43", "link": "http://arxiv.org/abs/2504.10720v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Distinct hydrologic response patterns and trends worldwide revealed by physics-embedded learning", "abstract": "To track rapid changes within our water sector, Global Water Models (GWMs)\nneed to realistically represent hydrologic systems' response patterns - such as\nbaseflow fraction - but are hindered by their limited ability to learn from\ndata. Here we introduce a high-resolution physics-embedded big-data-trained\nmodel as a breakthrough in reliably capturing characteristic hydrologic\nresponse patterns ('signatures') and their shifts. By realistically\nrepresenting the long-term water balance, the model revealed widespread shifts\n- up to ~20% over 20 years - in fundamental green-blue-water partitioning and\nbaseflow ratios worldwide. Shifts in these response patterns, previously\nconsidered static, contributed to increasing flood risks in northern\nmid-latitudes, heightening water supply stresses in southern subtropical\nregions, and declining freshwater inputs to many European estuaries, all with\necological implications. With more accurate simulations at monthly and daily\nscales than current operational systems, this next-generation model resolves\nlarge, nonlinear seasonal runoff responses to rainfall ('elasticity') and\nstreamflow flashiness in semi-arid and arid regions. These metrics highlight\nregions with management challenges due to large water supply variability and\nhigh climate sensitivity, but also provide tools to forecast seasonal water\navailability. This capability newly enables global-scale models to deliver\nreliable and locally relevant insights for water management.", "published": "2025-04-14 20:58:52", "link": "http://arxiv.org/abs/2504.10707v1", "categories": ["physics.geo-ph", "cs.LG"], "primary_category": "physics.geo-ph"}
{"title": "Achieving Optimal Tissue Repair Through MARL with Reward Shaping and Curriculum Learning", "abstract": "In this paper, we present a multi-agent reinforcement learning (MARL)\nframework for optimizing tissue repair processes using engineered biological\nagents. Our approach integrates: (1) stochastic reaction-diffusion systems\nmodeling molecular signaling, (2) neural-like electrochemical communication\nwith Hebbian plasticity, and (3) a biologically informed reward function\ncombining chemical gradient tracking, neural synchronization, and robust\npenalties. A curriculum learning scheme guides the agent through progressively\ncomplex repair scenarios. In silico experiments demonstrate emergent repair\nstrategies, including dynamic secretion control and spatial coordination.", "published": "2025-04-14 19:57:03", "link": "http://arxiv.org/abs/2504.10677v1", "categories": ["cs.LG", "cs.AI", "cs.MA"], "primary_category": "cs.LG"}
{"title": "On an efficient line smoother for the p-multigrid \u03b3-cycle", "abstract": "As part of the development of a Poisson solver for the spectral element\ndiscretization used in the GeoFluid Object Workbench (GeoFLOW) code, we propose\na solver for the linear system arising from a Gauss-Legendre-Lobatto global\nspectral method. We precondition using a p-multigrid {\\gamma}-cycle with\nhighly-vectorizable smoothers, that we refer to as line smoothers. Our\nsmoothers are restrictions of spectral and finite element discretizations to\nlow-order one-dimensional problems along lines, that are solved by a\nreformulation of cyclic reduction as a direct multigrid method. We illustrate\nour method with numerical experiments showing the apparent boundedness of the\niteration count for a fixed residual reduction over a range of moderately\ndeformed domains, right hand sides and Dirichlet boundary conditions.", "published": "2025-04-14 21:01:14", "link": "http://arxiv.org/abs/2504.10710v1", "categories": ["math.NA", "cs.NA", "65N35"], "primary_category": "math.NA"}
{"title": "Beyond Coordinates: Meta-Equivariance in Statistical Inference", "abstract": "Optimal statistical decisions should transcend the language used to describe\nthem. Yet, how do we guarantee that the choice of coordinates - the\nparameterisation of an optimisation problem - does not subtly dictate the\nsolution? This paper reveals a fundamental geometric invariance principle. We\nfirst analyse the optimal combination of two asymptotically normal estimators\nunder a strictly convex trace-AMSE risk. While methods for finding optimal\nweights are known, we prove that the resulting optimal estimator is invariant\nunder direct affine reparameterisations of the weighting scheme. This\nexemplifies a broader principle we term meta-equivariance: the unique minimiser\nof any strictly convex, differentiable scalar objective over a matrix space\ntransforms covariantly under any invertible affine reparameterisation of that\nspace. Distinct from classical statistical equivariance tied to data\nsymmetries, meta-equivariance arises from the immutable geometry of convex\noptimisation itself. It guarantees that optimality, in these settings, is not\nan artefact of representation but an intrinsic, coordinate-free truth.", "published": "2025-04-14 19:40:39", "link": "http://arxiv.org/abs/2504.10667v1", "categories": ["math.ST", "math.OC", "stat.ML", "stat.TH", "62F12, 90C25, 53B20", "G.1.6; G.3"], "primary_category": "math.ST"}
{"title": "On the Contractivity of Stochastic Interpolation Flow", "abstract": "We investigate stochastic interpolation, a recently introduced framework for\nhigh dimensional sampling which bears many similarities to diffusion modeling.\nStochastic interpolation generates a data sample by first randomly initializing\na particle drawn from a simple base distribution, then simulating deterministic\nor stochastic dynamics such that in finite time the particle's distribution\nconverges to the target. We show that for a Gaussian base distribution and a\nstrongly log-concave target distribution, the stochastic interpolation flow map\nis Lipschitz with a sharp constant which matches that of Caffarelli's theorem\nfor optimal transport maps. We are further able to construct Lipschitz\ntransport maps between non-Gaussian distributions, generalizing some recent\nconstructions in the literature on transport methods for establishing\nfunctional inequalities. We discuss the practical implications of our theorem\nfor the sampling and estimation problems required by stochastic interpolation.", "published": "2025-04-14 19:10:22", "link": "http://arxiv.org/abs/2504.10653v1", "categories": ["math.ST", "cs.LG", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "SPreV", "abstract": "SPREV, short for hyperSphere Reduced to two-dimensional Regular Polygon for\nVisualisation, is a novel dimensionality reduction technique developed to\naddress the challenges of reducing dimensions and visualizing labeled datasets\nthat exhibit a unique combination of three characteristics: small class size,\nhigh dimensionality, and low sample size. SPREV is designed not only to uncover\nbut also to visually represent hidden patterns within such datasets. Its\ndistinctive integration of geometric principles, adapted for discrete\ncomputational environments, makes it an indispensable tool in the modern data\nscience toolkit, enabling users to identify trends, extract insights, and\nnavigate complex data efficiently and effectively.", "published": "2025-04-14 18:20:47", "link": "http://arxiv.org/abs/2504.10620v1", "categories": ["cs.GR", "cs.HC", "cs.LG", "stat.ML", "G.3"], "primary_category": "cs.GR"}
{"title": "Energy Matching: Unifying Flow Matching and Energy-Based Models for Generative Modeling", "abstract": "Generative models often map noise to data by matching flows or scores, but\nthese approaches become cumbersome for incorporating partial observations or\nadditional priors. Inspired by recent advances in Wasserstein gradient flows,\nwe propose Energy Matching, a framework that unifies flow-based approaches with\nthe flexibility of energy-based models (EBMs). Far from the data manifold,\nsamples move along curl-free, optimal transport paths from noise to data. As\nthey approach the data manifold, an entropic energy term guides the system into\na Boltzmann equilibrium distribution, explicitly capturing the underlying\nlikelihood structure of the data. We parameterize this dynamic with a single\ntime-independent scalar field, which serves as both a powerful generator and a\nflexible prior for effective regularization of inverse problems. Our method\nsubstantially outperforms existing EBMs on CIFAR-10 generation (FID 3.97\ncompared to 8.61), while retaining the simulation-free training of\ntransport-based approaches away from the data manifold. Additionally, we\nexploit the flexibility of our method and introduce an interaction energy for\ndiverse mode exploration. Our approach focuses on learning a static scalar\npotential energy -- without time conditioning, auxiliary generators, or\nadditional networks -- marking a significant departure from recent EBM methods.\nWe believe this simplified framework significantly advances EBM capabilities\nand paves the way for their broader adoption in generative modeling across\ndiverse domains.", "published": "2025-04-14 18:10:58", "link": "http://arxiv.org/abs/2504.10612v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Beyond Worst-Case Online Classification: VC-Based Regret Bounds for Relaxed Benchmarks", "abstract": "We revisit online binary classification by shifting the focus from competing\nwith the best-in-class binary loss to competing against relaxed benchmarks that\ncapture smoothed notions of optimality. Instead of measuring regret relative to\nthe exact minimal binary error -- a standard approach that leads to worst-case\nbounds tied to the Littlestone dimension -- we consider comparing with\npredictors that are robust to small input perturbations, perform well under\nGaussian smoothing, or maintain a prescribed output margin. Previous examples\nof this were primarily limited to the hinge loss. Our algorithms achieve regret\nguarantees that depend only on the VC dimension and the complexity of the\ninstance space (e.g., metric entropy), and notably, they incur only an\n$O(\\log(1/\\gamma))$ dependence on the generalized margin $\\gamma$. This stands\nin contrast to most existing regret bounds, which typically exhibit a\npolynomial dependence on $1/\\gamma$. We complement this with matching lower\nbounds. Our analysis connects recent ideas from adversarial robustness and\nsmoothed online learning.", "published": "2025-04-14 18:00:23", "link": "http://arxiv.org/abs/2504.10598v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Multi-Stream Transmission in Cell-Free MIMO Networks with Coherent AP Clustering", "abstract": "This letter proposes a multi-stream selection framework for \\ac{CF-MIMO}\nnetworks. Partially coherent transmission has been considered by clustering\n\\acp{AP} into phase-aligned clusters to address the challenges of phase\nmisalignment and inter-cluster interference. A novel stream selection algorithm\nis developed to dynamically allocate multiple streams to each multi-antenna\n\\ac{UE}, ensuring that the system optimizes the sum rate while minimizing\ninter-cluster and inter-stream interference. Numerical results validate the\neffectiveness of the proposed method in enhancing spectral efficiency and\nfairness in distributed \\ac{CF-MIMO} networks.", "published": "2025-04-14 20:57:20", "link": "http://arxiv.org/abs/2504.10705v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Neyman-Pearson Detector for Ambient Backscatter Zero-Energy-Devices Beacons", "abstract": "Recently, a novel ultra-low power indoor wireless positioning system has been\nproposed. In this system, Zero-Energy-Devices (ZED) beacons are deployed in\nIndoor environments, and located on a map with unique broadcast identifiers.\nThey harvest ambient energy to power themselves and backscatter ambient waves\nfrom cellular networks to send their identifiers. This paper presents a novel\ndetection method for ZEDs in ambient backscatter systems, with an emphasis on\nperformance evaluation through experimental setups and simulations. We\nintroduce a Neyman-Pearson detection framework, which leverages a predefined\nfalse alarm probability to determine the optimal detection threshold. This\nmethod, applied to the analysis of backscatter signals in a controlled testbed\nenvironment, incorporates the use of BC sequences to enhance signal detection\naccuracy. The experimental setup, conducted on the FIT/CorteXlab testbed,\nemploys a two-node configuration for signal transmission and reception. Key\nperformance metrics, which is the peak-to-lobe ratio, is evaluated, confirming\nthe effectiveness of the proposed detection model. The results demonstrate a\ndetection system that effectively handles varying noise levels and identifies\nZEDs with high reliability. The simulation results show the robustness of the\nmodel, highlighting its capacity to achieve desired detection performance even\nwith stringent false alarm thresholds. This work paves the way for robust ZED\ndetection in real-world scenarios, contributing to the advancement of wireless\ncommunication technologies.", "published": "2025-04-14 20:36:48", "link": "http://arxiv.org/abs/2504.10695v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "GPS-Independent Localization Techniques for Disaster Rescue", "abstract": "In this article, we present the limitations of traditional localization\ntechniques, such as those using Global Positioning Systems (GPS) and life\ndetectors, in localizing victims during disaster rescue efforts. These\ntechniques usually fall short in accuracy, coverage, and robustness to\nenvironmental interference. We then discuss the necessary requirements for\ndeveloping GPS-independent localization techniques in disaster scenarios.\nPractical techniques should be passive, with straightforward hardware, low\ncomputational demands, low power, and high accuracy, while incorporating\nunknown environmental information. We review various implementation strategies\nfor these techniques, categorized by measurements (time, angle, and signal\nstrength) and operation manners (non-cooperative and cooperative). Case studies\ndemonstrate trade-offs between localization accuracy and complexity,\nemphasizing the importance of choosing appropriate localization techniques\nbased on resources and rescue needs for efficient disaster response.", "published": "2025-04-14 19:39:50", "link": "http://arxiv.org/abs/2504.10666v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Correcting Domain Shifts in Electric Motor Vibration Data for Unseen Operating Conditions", "abstract": "This paper addresses the problem of domain shifts in electric motor vibration\ndata created by new operating conditions in testing scenarios, focusing on\nbearing fault detection and diagnosis (FDD). The proposed method combines the\nHarmonic Feature Space (HFS) with regression to correct for frequency and\nenergy differentials in steady-state data, enabling accurate FDD on unseen\noperating conditions within the range of the training conditions. The HFS\naligns harmonics across different operating frequencies, while regression\ncompensates for energy variations, preserving the relative magnitude of\nvibrations critical for fault detection. The proposed approach is evaluated on\na detection problem using experimental data from a Belt-Starter Generator (BSG)\nelectric motor, with test conditions having a minimum 1000 RPM and 5 Nm\ndifference from training conditions. Results demonstrate that the method\noutperforms traditional analysis techniques, achieving high classification\naccuracy at a 94% detection rate and effectively reducing domain shifts. The\napproach is computationally efficient, requires only healthy data for training,\nand is well-suited for real-world applications where the exact application\noperating conditions cannot be predetermined.", "published": "2025-04-14 19:22:21", "link": "http://arxiv.org/abs/2504.10661v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Secrecy Rate Maximization with Artificial Noise for Pinching-Antenna Systems", "abstract": "Security is emerging as a critical performance metric for next-generation\nwireless networks, but conventional multiple-input-multiple-output (MIMO)\nsystems often suffer from severe path loss and are vulnerable to nearby\neavesdroppers due to their fixed-antenna configurations. Pinching-antenna\nsystems (PAS) offer a promising alternative, leveraging reconfigurable pinching\nantennas (PAs) positioned along low-loss dielectric waveguides to enhance\nchannel conditions and dynamically mitigate security threats. In this paper, we\npropose an artificial noise (AN)-based beamforming scheme for downlink\ntransmissions in PAS, with the goal of maximizing the secrecy rate. A\nclosed-form solution is derived for the single-waveguide scenario, while an\nalternating optimization approach addresses more complex multiple waveguide\nsetups. Numerical results show that the proposed scheme significantly\noutperforms conventional MIMO and existing PAS security schemes.", "published": "2025-04-14 19:14:21", "link": "http://arxiv.org/abs/2504.10656v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "LLM Unlearning Reveals a Stronger-Than-Expected Coreset Effect in Current Benchmarks", "abstract": "Large language model unlearning has become a critical challenge in ensuring\nsafety and controlled model behavior by removing undesired data-model\ninfluences from the pretrained model while preserving general utility.\nSignificant recent efforts have been dedicated to developing LLM unlearning\nbenchmarks such as WMDP (Weapons of Mass Destruction Proxy) and MUSE (Machine\nUnlearning Six-way Evaluation), facilitating standardized unlearning\nperformance assessment and method comparison. Despite their usefulness, we\nuncover for the first time a novel coreset effect within these benchmarks.\nSpecifically, we find that LLM unlearning achieved with the original (full)\nforget set can be effectively maintained using a significantly smaller subset\n(functioning as a \"coreset\"), e.g., as little as 5% of the forget set, even\nwhen selected at random. This suggests that LLM unlearning in these benchmarks\ncan be performed surprisingly easily, even in an extremely low-data regime. We\ndemonstrate that this coreset effect remains strong, regardless of the LLM\nunlearning method used, such as NPO (Negative Preference Optimization) and RMU\n(Representation Misdirection Unlearning), the popular ones in these benchmarks.\nThe surprisingly strong coreset effect is also robust across various data\nselection methods, ranging from random selection to more sophisticated\nheuristic approaches. We explain the coreset effect in LLM unlearning through a\nkeyword-based perspective, showing that keywords extracted from the forget set\nalone contribute significantly to unlearning effectiveness and indicating that\ncurrent unlearning is driven by a compact set of high-impact tokens rather than\nthe entire dataset. We further justify the faithfulness of coreset-unlearned\nmodels along additional dimensions, such as mode connectivity and robustness to\njailbreaking attacks. Codes are available at\nhttps://github.com/OPTML-Group/MU-Coreset.", "published": "2025-04-14 12:38:37", "link": "http://arxiv.org/abs/2504.10185v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "NR-SSOR right preconditioned RRGMRES for arbitrary singular systems and least squares problems", "abstract": "GMRES is known to determine a least squares solution of $ A x = b $ where $ A\n\\in R^{n \\times n} $ without breakdown for arbitrary $ b \\in R^n $, and initial\niterate $ x_0 \\in R^n $ if and only if $ A $ is range-symmetric, i.e. $ R(A^T)\n= R(A) $, where $ A $ may be singular and $ b $ may not be in the range space $\nR(A) $ of $ A $.\n  In this paper, we propose applying the Range Restricted GMRES (RRGMRES) to $\nA C A^T z = b $, where $ C \\in R^{n \\times n} $ is symmetric positive definite.\nThis determines a least squares solution $ x = C A^T z $ of $ A x = b $ without\nbreakdown for arbitrary (singular) matrix $ A \\in R^{n \\times n} $ and $ b, x_0\n\\in R^n $, and is much more stable and accurate compared to GMRES, RRGMRES and\nMINRES-QLP applied to $ A x = b $ for inconsistent problems when $ b \\notin\nR(A) $. In particular, we propose applying the NR-SSOR as the inner iteration\nright preconditioner, which also works efficiently for least squares problems $\n\\min_{x \\in R^n} \\| b - A x\\|_2 $ for $ A \\in R^{m \\times n} $ and arbitrary $\nb \\in R^m $.\n  Numerical experiments demonstrate the validity of the proposed method.", "published": "2025-04-14 05:34:02", "link": "http://arxiv.org/abs/2504.09891v2", "categories": ["math.NA", "cs.NA", "65F10, 65F08, 65F20, 65F50"], "primary_category": "math.NA"}
{"title": "Language and Knowledge Representation: A Stratified Approach", "abstract": "The thesis proposes the problem of representation heterogeneity to emphasize\nthe fact that heterogeneity is an intrinsic property of any representation,\nwherein, different observers encode different representations of the same\ntarget reality in a stratified manner using different concepts, language and\nknowledge (as well as data). The thesis then advances a top-down solution\napproach to the above stratified problem of representation heterogeneity in\nterms of several solution components, namely: (i) a representation formalism\nstratified into concept level, language level, knowledge level and data level\nto accommodate representation heterogeneity, (ii) a top-down language\nrepresentation using Universal Knowledge Core (UKC), UKC namespaces and domain\nlanguages to tackle the conceptual and language level heterogeneity, (iii) a\ntop-down knowledge representation using the notions of language teleontology\nand knowledge teleontology to tackle the knowledge level heterogeneity, (iv)\nthe usage and further development of the existing LiveKnowledge catalog for\nenforcing iterative reuse and sharing of language and knowledge\nrepresentations, and, (v) the kTelos methodology integrating the solution\ncomponents above to iteratively generate the language and knowledge\nrepresentations absolving representation heterogeneity. The thesis also\nincludes proof-of-concepts of the language and knowledge representations\ndeveloped for two international research projects - DataScientia (data\ncatalogs) and JIDEP (materials modelling). Finally, the thesis concludes with\nfuture lines of research.", "published": "2025-04-14 20:18:10", "link": "http://arxiv.org/abs/2504.11492v1", "categories": ["cs.DB", "cs.CL", "cs.DL"], "primary_category": "cs.DB"}
