{"title": "Token Sliding Reconfiguration on DAGs", "abstract": "Given a graph $G$ and two independent sets of same size, the Independent Set\nReconfiguration Problem under token sliding ask whether one can, in a step by\nstep manner, transform the first independent set into the second one. In each\nstep we must preserve the condition of independence. Further, referring to\nsolution vertices as tokens, we are only permitted to slide a token along an\nedge. Until the recent work of Ito et al. [Ito et al. MFCS 2022] this problem\nwas only considered on undirected graphs. In this work, we study\nreconfiguration under token sliding focusing on DAGs.\n  We present a complete dichotomy of intractability in regard to the depth of\nthe DAG, by proving that this problem is NP-complete for DAGs of depth 3 and\n$\\textrm{W}[1]$-hard for depth 4 when parameterized by the number of tokens\n$k$, and that these bounds are tight. Further, we prove that it is fixed\nparameter tractable on DAGs parameterized by the combination of treewidth and\n$k$. We show that this result applies to undirected graphs, when the number of\ntimes a token can visit a vertex is restricted.", "published": "2025-04-14 19:47:36", "link": "http://arxiv.org/abs/2504.10671v1", "categories": ["cs.DM"], "primary_category": "cs.DM"}
{"title": "On the Asymptotics of the Connectivity Probability of Random Bipartite Graphs", "abstract": "In this paper, we analyze the exact asymptotic behavior of the connectivity\nprobability in a random binomial bipartite graph $G(n,m,p)$ under various\nregimes of the edge probability $p=p(n)$. To determine this probability, a\nmethod based on the analysis of inhomogeneous random walks is proposed.", "published": "2025-04-14 18:44:56", "link": "http://arxiv.org/abs/2504.10640v1", "categories": ["math.PR", "cs.DM", "math.CO"], "primary_category": "math.PR"}
{"title": "Re-imagining Spectral Graph Theory", "abstract": "We propose a Laplacian based on general inner product spaces, which we call\nthe inner product Laplacian. We show the combinatorial and normalized graph\nLaplacians, as well as other Laplacians for hypergraphs and directed graphs,\nare special cases of the inner product Laplacian. After developing the\nnecessary basic theory for the inner product Laplacian, we establish\ngeneralized analogs of key isoperimetric inequalities, including the Cheeger\ninequality and expander mixing lemma. Dirichlet and Neumann subgraph\neigenvalues may also be recovered as appropriate limit points of a sequence of\ninner product Laplacians. In addition to suggesting a new context through which\nto examine existing Laplacians, this generalized framework is also flexible in\napplications: through choice of an inner product on the vertices and edges of a\ngraph, the inner product Laplacian naturally encodes both combinatorial\nstructure and domain-knowledge.", "published": "2025-04-14 18:23:20", "link": "http://arxiv.org/abs/2504.10624v1", "categories": ["math.CO", "cs.DM", "05C50 (Primary)"], "primary_category": "math.CO"}
{"title": "Expected Length of the Longest Common Subsequence of Multiple Strings", "abstract": "We study the generalized Chv\\'atal-Sankoff constant $\\gamma_{k,d}$, which\nrepresents the normalized expected length of the longest common subsequence\n(LCS) of $d$ independent uniformly random strings over an alphabet of size $k$.\nWe derive asymptotically tight bounds for $\\gamma_{2,d}$, establishing that\n$\\gamma_{2,d} = \\frac{1}{2} + \\Theta\\left(\\frac{1}{\\sqrt{d}}\\right)$. We also\nderive asymptotically near-optimal bounds on $\\gamma_{k,d}$ for $d\\ge\n\\Omega(\\log k)$.", "published": "2025-04-14 17:15:51", "link": "http://arxiv.org/abs/2504.10425v1", "categories": ["math.CO", "cs.DM", "math.PR"], "primary_category": "math.CO"}
{"title": "Optimal Graph Stretching for Distributed Averaging", "abstract": "The performance of distributed averaging depends heavily on the underlying\ntopology. In various fields, including compressed sensing, multi-party\ncomputation, and abstract graph theory, graphs may be expected to be free of\nshort cycles, i.e. to have high girth. Though extensive analyses and heuristics\nexist for optimising the performance of distributed averaging in general\nnetworks, these studies do not consider girth. As such, it is not clear what\nhappens to convergence time when a graph is stretched to a higher girth.\n  In this work, we introduce the optimal graph stretching problem, wherein we\nare interested in finding the set of edges for a particular graph that ensures\noptimal convergence time under constraint of a minimal girth. We compare\nvarious methods for choosing which edges to remove, and use various convergence\nheuristics to speed up the searching process. We generate many graphs with\nvarying parameters, stretch and optimise them, and measure the duration of\ndistributed averaging. We find that stretching by itself significantly\nincreases convergence time. This decrease can be counteracted with a subsequent\nrepair phase, guided by a convergence time heuristic. Existing heuristics are\ncapable, but may be suboptimal.", "published": "2025-04-14 15:01:24", "link": "http://arxiv.org/abs/2504.10289v1", "categories": ["cs.DC", "cs.DM", "68R10 (Primary) 05C38, 68W15, 90C59, 15B48, 05C50, 15A18, 05C65\n  (Secondary)", "G.1.6; C.2.4; D.4.8; I.6.6; D.2.8"], "primary_category": "cs.DC"}
{"title": "Epistemic Uncertainty-aware Recommendation Systems via Bayesian Deep Ensemble Learning", "abstract": "Recommending items to users has long been a fundamental task, and studies\nhave tried to improve it ever since. Most well-known models commonly employ\nrepresentation learning to map users and items into a unified embedding space\nfor matching assessment. These approaches have primary limitations, especially\nwhen dealing with explicit feedback and sparse data contexts. Two primary\nlimitations are their proneness to overfitting and failure to incorporate\nepistemic uncertainty in predictions. To address these problems, we propose a\nnovel Bayesian Deep Ensemble Collaborative Filtering method named BDECF. To\nimprove model generalization and quality, we utilize Bayesian Neural Networks,\nwhich incorporate uncertainty within their weight parameters. In addition, we\nintroduce a new interpretable non-linear matching approach for the user and\nitem embeddings, leveraging the advantages of the attention mechanism.\nFurthermore, we endorse the implementation of an ensemble-based supermodel to\ngenerate more robust and reliable predictions, resulting in a more complete\nmodel. Empirical evaluation through extensive experiments and ablation studies\nacross a range of publicly accessible real-world datasets with differing\nsparsity characteristics confirms our proposed method's effectiveness and the\nimportance of its components.", "published": "2025-04-14 23:04:35", "link": "http://arxiv.org/abs/2504.10753v1", "categories": ["cs.IR", "cs.AI", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Enhancing Document Retrieval for Curating N-ary Relations in Knowledge Bases", "abstract": "Curation of biomedical knowledge bases (KBs) relies on extracting accurate\nmulti-entity relational facts from the literature - a process that remains\nlargely manual and expert-driven. An essential step in this workflow is\nretrieving documents that can support or complete partially observed n-ary\nrelations. We present a neural retrieval model designed to assist KB curation\nby identifying documents that help fill in missing relation arguments and\nprovide relevant contextual evidence.\n  To reduce dependence on scarce gold-standard training data, we exploit\nexisting KB records to construct weakly supervised training sets. Our approach\nintroduces two key technical contributions: (i) a layered contrastive loss that\nenables learning from noisy and incomplete relational structures, and (ii) a\nbalanced sampling strategy that generates high-quality negatives from diverse\nKB records. On two biomedical retrieval benchmarks, our approach achieves\nstate-of-the-art performance, outperforming strong baselines in NDCG@10 by 5.7\nand 3.7 percentage points, respectively.", "published": "2025-04-14 18:11:53", "link": "http://arxiv.org/abs/2504.10613v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Invariance Matters: Empowering Social Recommendation via Graph Invariant Learning", "abstract": "Graph-based social recommendation systems have shown significant promise in\nenhancing recommendation performance, particularly in addressing the issue of\ndata sparsity in user behaviors. Typically, these systems leverage Graph Neural\nNetworks (GNNs) to capture user preferences by incorporating high-order social\ninfluences from observed social networks. However, existing graph-based social\nrecommendations often overlook the fact that social networks are inherently\nnoisy, containing task-irrelevant relationships that can hinder accurate user\npreference learning. The removal of these redundant social relations is\ncrucial, yet it remains challenging due to the lack of ground truth. In this\npaper, we approach the social denoising problem from the perspective of graph\ninvariant learning and propose a novel method, Social Graph Invariant\nLearning(SGIL). Specifically,SGIL aims to uncover stable user preferences\nwithin the input social graph, thereby enhancing the robustness of graph-based\nsocial recommendation systems. To achieve this goal, SGIL first simulates\nmultiple noisy social environments through graph generators. It then seeks to\nlearn environment-invariant user preferences by minimizing invariant risk\nacross these environments. To further promote diversity in the generated social\nenvironments, we employ an adversarial training strategy to simulate more\npotential social noisy distributions. Extensive experimental results\ndemonstrate the effectiveness of the proposed SGIL. The code is available at\nhttps://github.com/yimutianyang/SIGIR2025-SGIL.", "published": "2025-04-14 17:20:48", "link": "http://arxiv.org/abs/2504.10432v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Brain-Machine Interfaces & Information Retrieval Challenges and Opportunities", "abstract": "The fundamental goal of Information Retrieval (IR) systems lies in their\ncapacity to effectively satisfy human information needs - a challenge that\nencompasses not just the technical delivery of information, but the nuanced\nunderstanding of human cognition during information seeking. Contemporary IR\nplatforms rely primarily on observable interaction signals, creating a\nfundamental gap between system capabilities and users' cognitive processes.\nBrain-Machine Interface (BMI) technologies now offer unprecedented potential to\nbridge this gap through direct measurement of previously inaccessible aspects\nof information-seeking behaviour. This perspective paper offers a broad\nexamination of the IR landscape, providing a comprehensive analysis of how BMI\ntechnology could transform IR systems, drawing from advances at the\nintersection of both neuroscience and IR research. We present our analysis\nthrough three identified fundamental vertices: (1) understanding the neural\ncorrelates of core IR concepts to advance theoretical models of search\nbehaviour, (2) enhancing existing IR systems through contextual integration of\nneurophysiological signals, and (3) developing proactive IR capabilities\nthrough direct neurophysiological measurement. For each vertex, we identify\nspecific research opportunities and propose concrete directions for developing\nBMI-enhanced IR systems. We conclude by examining critical technical and\nethical challenges in implementing these advances, providing a structured\nroadmap for future research at the intersection of neuroscience and IR.", "published": "2025-04-14 16:18:30", "link": "http://arxiv.org/abs/2504.10371v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "AlayaDB: The Data Foundation for Efficient and Effective Long-context LLM Inference", "abstract": "AlayaDB is a cutting-edge vector database system natively architected for\nefficient and effective long-context inference for Large Language Models (LLMs)\nat AlayaDB AI. Specifically, it decouples the KV cache and attention\ncomputation from the LLM inference systems, and encapsulates them into a novel\nvector database system. For the Model as a Service providers (MaaS), AlayaDB\nconsumes fewer hardware resources and offers higher generation quality for\nvarious workloads with different kinds of Service Level Objectives (SLOs), when\ncomparing with the existing alternative solutions (e.g., KV cache\ndisaggregation, retrieval-based sparse attention). The crux of AlayaDB is that\nit abstracts the attention computation and cache management for LLM inference\ninto a query processing procedure, and optimizes the performance via a native\nquery optimizer. In this work, we demonstrate the effectiveness of AlayaDB via\n(i) three use cases from our industry partners, and (ii) extensive experimental\nresults on LLM inference benchmarks.", "published": "2025-04-14 15:34:26", "link": "http://arxiv.org/abs/2504.10326v1", "categories": ["cs.AI", "cs.DB", "cs.IR", "H.3.1; H.3.2; H.3.3; H.3.4"], "primary_category": "cs.AI"}
{"title": "CROSSAN: Towards Efficient and Effective Adaptation of Multiple Multimodal Foundation Models for Sequential Recommendation", "abstract": "Multimodal Foundation Models (MFMs) excel at representing diverse raw\nmodalities (e.g., text, images, audio, videos, etc.). As recommender systems\nincreasingly incorporate these modalities, leveraging MFMs to generate better\nrepresentations has great potential. However, their application in sequential\nrecommendation remains largely unexplored. This is primarily because mainstream\nadaptation methods, such as Fine-Tuning and even Parameter-Efficient\nFine-Tuning (PEFT) techniques (e.g., Adapter and LoRA), incur high\ncomputational costs, especially when integrating multiple modality encoders,\nthus hindering research progress. As a result, it remains unclear whether we\ncan efficiently and effectively adapt multiple (>2) MFMs for the sequential\nrecommendation task.\n  To address this, we propose a plug-and-play Cross-modal Side Adapter Network\n(CROSSAN). Leveraging the fully decoupled side adapter-based paradigm, CROSSAN\nachieves high efficiency while enabling cross-modal learning across diverse\nmodalities. To optimize the final stage of multimodal fusion across diverse\nmodalities, we adopt the Mixture of Modality Expert Fusion (MOMEF) mechanism.\nCROSSAN achieves superior performance on the public datasets for adapting four\nfoundation models with raw modalities. Performance consistently improves as\nmore MFMs are adapted. We will release our code and datasets to facilitate\nfuture research.", "published": "2025-04-14 15:14:59", "link": "http://arxiv.org/abs/2504.10307v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "MURR: Model Updating with Regularized Replay for Searching a Document Stream", "abstract": "The Internet produces a continuous stream of new documents and user-generated\nqueries. These naturally change over time based on events in the world and the\nevolution of language. Neural retrieval models that were trained once on a\nfixed set of query-document pairs will quickly start misrepresenting\nnewly-created content and queries, leading to less effective retrieval.\nTraditional statistical sparse retrieval can update collection statistics to\nreflect these changes in the use of language in documents and queries. In\ncontrast, continued fine-tuning of the language model underlying neural\nretrieval approaches such as DPR and ColBERT creates incompatibility with\npreviously-encoded documents. Re-encoding and re-indexing all\npreviously-processed documents can be costly. In this work, we explore updating\na neural dual encoder retrieval model without reprocessing past documents in\nthe stream. We propose MURR, a model updating strategy with regularized replay,\nto ensure the model can still faithfully search existing documents without\nreprocessing, while continuing to update the model for the latest topics. In\nour simulated streaming environments, we show that fine-tuning models using\nMURR leads to more effective and more consistent retrieval results than other\nstrategies as the stream of documents and queries progresses.", "published": "2025-04-14 14:13:03", "link": "http://arxiv.org/abs/2504.10250v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "From Prompting to Alignment: A Generative Framework for Query Recommendation", "abstract": "In modern search systems, search engines often suggest relevant queries to\nusers through various panels or components, helping refine their information\nneeds. Traditionally, these recommendations heavily rely on historical search\nlogs to build models, which suffer from cold-start or long-tail issues.\nFurthermore, tasks such as query suggestion, completion or clarification are\nstudied separately by specific design, which lacks generalizability and hinders\nadaptation to novel applications. Despite recent attempts to explore the use of\nLLMs for query recommendation, these methods mainly rely on the inherent\nknowledge of LLMs or external sources like few-shot examples, retrieved\ndocuments, or knowledge bases, neglecting the importance of the calibration and\nalignment with user feedback, thus limiting their practical utility. To address\nthese challenges, we first propose a general Generative Query Recommendation\n(GQR) framework that aligns LLM-based query generation with user preference.\nSpecifically, we unify diverse query recommendation tasks by a universal prompt\nframework, leveraging the instruct-following capability of LLMs for effective\ngeneration. Secondly, we align LLMs with user feedback via presenting a\nCTR-alignment framework, which involves training a query-wise CTR predictor as\na process reward model and employing list-wise preference alignment to maximize\nthe click probability of the generated query list. Furthermore, recognizing the\ninconsistency between LLM knowledge and proactive search intents arising from\nthe separation of user-initiated queries from models, we align LLMs with user\ninitiative via retrieving co-occurrence queries as side information when\nhistorical logs are available.", "published": "2025-04-14 13:21:29", "link": "http://arxiv.org/abs/2504.10208v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "HistLLM: A Unified Framework for LLM-Based Multimodal Recommendation with User History Encoding and Compression", "abstract": "While large language models (LLMs) have proven effective in leveraging\ntextual data for recommendations, their application to multimodal\nrecommendation tasks remains relatively underexplored. Although LLMs can\nprocess multimodal information through projection functions that map visual\nfeatures into their semantic space, recommendation tasks often require\nrepresenting users' history interactions through lengthy prompts combining text\nand visual elements, which not only hampers training and inference efficiency\nbut also makes it difficult for the model to accurately capture user\npreferences from complex and extended prompts, leading to reduced\nrecommendation performance. To address this challenge, we introduce HistLLM, an\ninnovative multimodal recommendation framework that integrates textual and\nvisual features through a User History Encoding Module (UHEM), compressing\nmultimodal user history interactions into a single token representation,\neffectively facilitating LLMs in processing user preferences. Extensive\nexperiments demonstrate the effectiveness and efficiency of our proposed\nmechanism.", "published": "2025-04-14 12:01:11", "link": "http://arxiv.org/abs/2504.10150v1", "categories": ["cs.IR", "cs.MM"], "primary_category": "cs.IR"}
{"title": "A Survey of Personalization: From RAG to Agent", "abstract": "Personalization has become an essential capability in modern AI systems,\nenabling customized interactions that align with individual user preferences,\ncontexts, and goals. Recent research has increasingly concentrated on\nRetrieval-Augmented Generation (RAG) frameworks and their evolution into more\nadvanced agent-based architectures within personalized settings to enhance user\nsatisfaction. Building on this foundation, this survey systematically examines\npersonalization across the three core stages of RAG: pre-retrieval, retrieval,\nand generation. Beyond RAG, we further extend its capabilities into the realm\nof Personalized LLM-based Agents, which enhance traditional RAG systems with\nagentic functionalities, including user understanding, personalized planning\nand execution, and dynamic generation. For both personalization in RAG and\nagent-based personalization, we provide formal definitions, conduct a\ncomprehensive review of recent literature, and summarize key datasets and\nevaluation metrics. Additionally, we discuss fundamental challenges,\nlimitations, and promising research directions in this evolving field. Relevant\npapers and resources are continuously updated at\nhttps://github.com/Applied-Machine-Learning-Lab/Awesome-Personalized-RAG-Agent.", "published": "2025-04-14 11:57:52", "link": "http://arxiv.org/abs/2504.10147v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Unveiling Contrastive Learning's Capability of Neighborhood Aggregation for Collaborative Filtering", "abstract": "Personalized recommendation is widely used in the web applications, and graph\ncontrastive learning (GCL) has gradually become a dominant approach in\nrecommender systems, primarily due to its ability to extract self-supervised\nsignals from raw interaction data, effectively alleviating the problem of data\nsparsity. A classic GCL-based method typically uses data augmentation during\ngraph convolution to generates more contrastive views, and performs contrast on\nthese new views to obtain rich self-supervised signals. Despite this paradigm\nis effective, the reasons behind the performance gains remain a mystery. In\nthis paper, we first reveal via theoretical derivation that the gradient\ndescent process of the CL objective is formally equivalent to graph\nconvolution, which implies that CL objective inherently supports neighborhood\naggregation on interaction graphs. We further substantiate this capability\nthrough experimental validation and identify common misconceptions in the\nselection of positive samples in previous methods, which limit the potential of\nCL objective. Based on this discovery, we propose the Light Contrastive\nCollaborative Filtering (LightCCF) method, which introduces a novel\nneighborhood aggregation objective to bring users closer to all interacted\nitems while pushing them away from other positive pairs, thus achieving\nhigh-quality neighborhood aggregation with very low time complexity. On three\nhighly sparse public datasets, the proposed method effectively aggregate\nneighborhood information while preventing graph over-smoothing, demonstrating\nsignificant improvements over existing GCL-based counterparts in both training\nefficiency and recommendation accuracy. Our implementations are publicly\naccessible.", "published": "2025-04-14 11:22:41", "link": "http://arxiv.org/abs/2504.10113v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Enhancing LLM-based Recommendation through Semantic-Aligned Collaborative Knowledge", "abstract": "Large Language Models (LLMs) demonstrate remarkable capabilities in\nleveraging comprehensive world knowledge and sophisticated reasoning mechanisms\nfor recommendation tasks. However, a notable limitation lies in their inability\nto effectively model sparse identifiers (e.g., user and item IDs), unlike\nconventional collaborative filtering models (Collabs.), thus hindering LLM to\nlearn distinctive user-item representations and creating a performance\nbottleneck. Prior studies indicate that integrating collaborative knowledge\nfrom Collabs. into LLMs can mitigate the above limitations and enhance their\nrecommendation performance. Nevertheless, the significant discrepancy in\nknowledge distribution and semantic space between LLMs and Collab. presents\nsubstantial challenges for effective knowledge transfer. To tackle these\nchallenges, we propose a novel framework, SeLLa-Rec, which focuses on achieving\nalignment between the semantic spaces of Collabs. and LLMs. This alignment\nfosters effective knowledge fusion, mitigating the influence of discriminative\nnoise and facilitating the deep integration of knowledge from diverse models.\nSpecifically, three special tokens with collaborative knowledge are embedded\ninto the LLM's semantic space through a hybrid projection layer and integrated\ninto task-specific prompts to guide the recommendation process. Experiments\nconducted on two public benchmark datasets (MovieLens-1M and Amazon Book)\ndemonstrate that SeLLa-Rec achieves state-of-the-art performance.", "published": "2025-04-14 11:15:30", "link": "http://arxiv.org/abs/2504.10107v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Session-based Recommender Systems: User Interest as a Stochastic Process in the Latent Space", "abstract": "This paper jointly addresses the problem of data uncertainty, popularity\nbias, and exposure bias in session-based recommender systems. We study the\nsymptoms of this bias both in item embeddings and in recommendations. We\npropose treating user interest as a stochastic process in the latent space and\nproviding a model-agnostic implementation of this mathematical concept. The\nproposed stochastic component consists of elements: debiasing item embeddings\nwith regularization for embedding uniformity, modeling dense user interest from\nsession prefixes, and introducing fake targets in the data to simulate extended\nexposure. We conducted computational experiments on two popular benchmark\ndatasets, Diginetica and YooChoose 1/64, as well as several modifications of\nthe YooChoose dataset with different ratios of popular items. The results show\nthat the proposed approach allows us to mitigate the challenges mentioned.", "published": "2025-04-14 09:08:40", "link": "http://arxiv.org/abs/2504.10005v1", "categories": ["cs.LG", "cs.AI", "cs.IR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "On Precomputation and Caching in Information Retrieval Experiments with Pipeline Architectures", "abstract": "Modern information retrieval systems often rely on multiple components\nexecuted in a pipeline. In a research setting, this can lead to substantial\nredundant computations (e.g., retrieving the same query multiple times for\nevaluating different downstream rerankers). To overcome this, researchers take\ncached \"result\" files as inputs, which represent the output of another\npipeline. However, these result files can be brittle and can cause a disconnect\nbetween the conceptual design of the pipeline and its logical implementation.\nTo overcome both the redundancy problem (when executing complete pipelines) and\nthe disconnect problem (when relying on intermediate result files), we describe\nour recent efforts to improve the caching capabilities in the open-source\nPyTerrier IR platform. We focus on two main directions: (1) automatic implicit\ncaching of common pipeline prefixes when comparing systems and (2) explicit\ncaching of operations through a new extension package, pyterrier-caching. These\napproaches allow for the best of both worlds: pipelines can be fully expressed\nend-to-end, while also avoiding redundant computations between pipelines.", "published": "2025-04-14 08:51:35", "link": "http://arxiv.org/abs/2504.09984v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Constrained Auto-Regressive Decoding Constrains Generative Retrieval", "abstract": "Generative retrieval seeks to replace traditional search index data\nstructures with a single large-scale neural network, offering the potential for\nimproved efficiency and seamless integration with generative large language\nmodels. As an end-to-end paradigm, generative retrieval adopts a learned\ndifferentiable search index to conduct retrieval by directly generating\ndocument identifiers through corpus-specific constrained decoding. The\ngeneralization capabilities of generative retrieval on out-of-distribution\ncorpora have gathered significant attention.\n  In this paper, we examine the inherent limitations of constrained\nauto-regressive generation from two essential perspectives: constraints and\nbeam search. We begin with the Bayes-optimal setting where the generative\nretrieval model exactly captures the underlying relevance distribution of all\npossible documents. Then we apply the model to specific corpora by simply\nadding corpus-specific constraints. Our main findings are two-fold: (i) For the\neffect of constraints, we derive a lower bound of the error, in terms of the KL\ndivergence between the ground-truth and the model-predicted step-wise marginal\ndistributions. (ii) For the beam search algorithm used during generation, we\nreveal that the usage of marginal distributions may not be an ideal approach.\nThis paper aims to improve our theoretical understanding of the generalization\ncapabilities of the auto-regressive decoding retrieval paradigm, laying a\nfoundation for its limitations and inspiring future advancements toward more\nrobust and generalizable generative retrieval.", "published": "2025-04-14 06:54:49", "link": "http://arxiv.org/abs/2504.09935v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "StePO-Rec: Towards Personalized Outfit Styling Assistant via Knowledge-Guided Multi-Step Reasoning", "abstract": "Advancements in Generative AI offers new opportunities for FashionAI,\nsurpassing traditional recommendation systems that often lack transparency and\nstruggle to integrate expert knowledge, leaving the potential for personalized\nfashion styling remain untapped. To address these challenges, we present PAFA\n(Principle-Aware Fashion), a multi-granular knowledge base that organizes\nprofessional styling expertise into three levels of metadata, domain\nprinciples, and semantic relationships. Using PAFA, we develop StePO-Rec, a\nknowledge-guided method for multi-step outfit recommendation. StePO-Rec\nprovides structured suggestions using a scenario-dimension-attribute framework,\nemploying recursive tree construction to align recommendations with both\nprofessional principles and individual preferences. A preference-trend\nre-ranking system further adapts to fashion trends while maintaining the\nconsistency of the user's original style. Experiments on the widely used\npersonalized outfit dataset IQON show a 28% increase in Recall@1 and 32.8% in\nMAP. Furthermore, case studies highlight improved explainability, traceability,\nresult reliability, and the seamless integration of expertise and\npersonalization.", "published": "2025-04-14 06:24:56", "link": "http://arxiv.org/abs/2504.09915v1", "categories": ["cs.IR", "cs.MM"], "primary_category": "cs.IR"}
{"title": "Constructing Micro Knowledge Graphs from Technical Support Documents", "abstract": "Short technical support pages such as IBM Technotes are quite common in\ntechnical support domain. These pages can be very useful as the knowledge\nsources for technical support applications such as chatbots, search engines and\nquestion-answering (QA) systems. Information extracted from documents to drive\ntechnical support applications is often stored in the form of Knowledge Graph\n(KG). Building KGs from a large corpus of documents poses a challenge of\ngranularity because a large number of entities and actions are present in each\npage. The KG becomes virtually unusable if all entities and actions from these\npages are stored in the KG. Therefore, only key entities and actions from each\npage are extracted and stored in the KG. This approach however leads to loss of\nknowledge represented by entities and actions left out of the KG as they are no\nlonger available to graph search and reasoning functions. We propose a set of\ntechniques to create micro knowledge graph (micrograph) for each of such web\npages. The micrograph stores all the entities and actions in a page and also\ntakes advantage of the structure of the page to represent exactly in which part\nof that page these entities and actions appeared, and also how they relate to\neach other. These micrographs can be used as additional knowledge sources by\ntechnical support applications. We define schemas for representing\nsemi-structured and plain text knowledge present in the technical support web\npages. Solutions in technical support domain include procedures made of steps.\nWe also propose a technique to extract procedures from these webpages and the\nschemas to represent them in the micrographs. We also discuss how technical\nsupport applications can take advantage of the micrographs.", "published": "2025-04-14 04:57:49", "link": "http://arxiv.org/abs/2504.09877v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "RAKG:Document-level Retrieval Augmented Knowledge Graph Construction", "abstract": "With the rise of knowledge graph based retrieval-augmented generation (RAG)\ntechniques such as GraphRAG and Pike-RAG, the role of knowledge graphs in\nenhancing the reasoning capabilities of large language models (LLMs) has become\nincreasingly prominent. However, traditional Knowledge Graph Construction (KGC)\nmethods face challenges like complex entity disambiguation, rigid schema\ndefinition, and insufficient cross-document knowledge integration. This paper\nfocuses on the task of automatic document-level knowledge graph construction.\nIt proposes the Document-level Retrieval Augmented Knowledge Graph Construction\n(RAKG) framework. RAKG extracts pre-entities from text chunks and utilizes\nthese pre-entities as queries for RAG, effectively addressing the issue of\nlong-context forgetting in LLMs and reducing the complexity of Coreference\nResolution. In contrast to conventional KGC methods, RAKG more effectively\ncaptures global information and the interconnections among disparate nodes,\nthereby enhancing the overall performance of the model. Additionally, we\ntransfer the RAG evaluation framework to the KGC field and filter and evaluate\nthe generated knowledge graphs, thereby avoiding incorrectly generated entities\nand relationships caused by hallucinations in LLMs. We further developed the\nMINE dataset by constructing standard knowledge graphs for each article and\nexperimentally validated the performance of RAKG. The results show that RAKG\nachieves an accuracy of 95.91 % on the MINE dataset, a 6.2 % point improvement\nover the current best baseline, GraphRAG (89.71 %). The code is available at\nhttps://github.com/LMMApplication/RAKG.", "published": "2025-04-14 02:47:23", "link": "http://arxiv.org/abs/2504.09823v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Augmented Relevance Datasets with Fine-Tuned Small LLMs", "abstract": "Building high-quality datasets and labeling query-document relevance are\nessential yet resource-intensive tasks, requiring detailed guidelines and\nsubstantial effort from human annotators. This paper explores the use of small,\nfine-tuned large language models (LLMs) to automate relevance assessment, with\na focus on improving ranking models' performance by augmenting their training\ndataset. We fine-tuned small LLMs to enhance relevance assessments, thereby\nimproving dataset creation quality for downstream ranking model training. Our\nexperiments demonstrate that these fine-tuned small LLMs not only outperform\ncertain closed source models on our dataset but also lead to substantial\nimprovements in ranking model performance. These results highlight the\npotential of leveraging small LLMs for efficient and scalable dataset\naugmentation, providing a practical solution for search engine optimization.", "published": "2025-04-14 02:35:00", "link": "http://arxiv.org/abs/2504.09816v1", "categories": ["cs.IR", "cs.CL", "H.3.3; I.2.7"], "primary_category": "cs.IR"}
{"title": "VDocRAG: Retrieval-Augmented Generation over Visually-Rich Documents", "abstract": "We aim to develop a retrieval-augmented generation (RAG) framework that\nanswers questions over a corpus of visually-rich documents presented in mixed\nmodalities (e.g., charts, tables) and diverse formats (e.g., PDF, PPTX). In\nthis paper, we introduce a new RAG framework, VDocRAG, which can directly\nunderstand varied documents and modalities in a unified image format to prevent\nmissing information that occurs by parsing documents to obtain text. To improve\nthe performance, we propose novel self-supervised pre-training tasks that adapt\nlarge vision-language models for retrieval by compressing visual information\ninto dense token representations while aligning them with textual content in\ndocuments. Furthermore, we introduce OpenDocVQA, the first unified collection\nof open-domain document visual question answering datasets, encompassing\ndiverse document types and formats. OpenDocVQA provides a comprehensive\nresource for training and evaluating retrieval and question answering models on\nvisually-rich documents in an open-domain setting. Experiments show that\nVDocRAG substantially outperforms conventional text-based RAG and has strong\ngeneralization capability, highlighting the potential of an effective RAG\nparadigm for real-world documents.", "published": "2025-04-14 01:50:33", "link": "http://arxiv.org/abs/2504.09795v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Minimizing Functions of Age of Incorrect Information for Remote Estimation", "abstract": "The age of incorrect information (AoII) process which keeps track of the time\nsince the source and monitor processes are in sync, has been extensively used\nin remote estimation problems. In this paper, we consider a push-based remote\nestimation system with a discrete-time Markov chain (DTMC) information source\ntransmitting status update packets towards the monitor once the AoII process\nexceeds a certain estimation-based threshold. In this paper, the time average\nof an arbitrary function of AoII is taken as the AoII cost, as opposed to using\nthe average AoII as the mismatch metric, whereas this function is also allowed\nto depend on the estimation value. In this very general setting, our goal is to\nminimize a weighted sum of AoII and transmission costs. For this purpose, we\nformulate a discrete-time semi-Markov decision process (SMDP) regarding the\nmulti-threshold status update policy. We propose a novel tool in discrete-time\ncalled 'dual-regime absorbing Markov chain' (DR-AMC) and its corresponding\nabsorption time distribution named as 'dual-regime phase-type' (DR-PH)\ndistribution, to obtain the characterizing parameters of the SMDP, which allows\nus to obtain the distribution of the AoII process for a given policy, and hence\nthe average of any function of AoII. The proposed method is validated with\nnumerical results by which we compare our proposed method against other\npolicies obtained by exhaustive-search, and also various benchmark policies.", "published": "2025-04-14 17:39:06", "link": "http://arxiv.org/abs/2504.10451v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Capacities of highly Markovian divisible quantum channels", "abstract": "We analyze information transmission capacities of quantum channels acting on\n$d$-dimensional quantum systems that are highly Markovian divisible, i.e.,\nchannels of the form \\begin{equation*}\n  \\Phi = \\underbrace{\\Psi\\circ \\Psi \\circ \\ldots \\circ \\Psi}_{l\n\\,\\operatorname{times}} \\end{equation*} with $l \\geq \\gamma d^2 \\log d$ for\nsome constant $\\gamma=\\gamma(\\Psi)$ that depends on the spectral gap of the\ndividing channel $\\Psi$. We prove that capacities of such channels are\napproximately strongly additive and can be efficiently approximated in terms of\nthe structure of their peripheral spaces. Furthermore, the quantum and private\nclassical capacities of such channels approximately coincide and approximately\nsatisfy the strong converse property. We show that these approximate results\nbecome exact for the corresponding zero-error capacities when $l \\geq d^2$. To\nprove these results, we show that for any channel $\\Psi$, the classical,\nprivate classical, and quantum capacities of $\\Psi_\\infty$, which is its\nso-called asymptotic part, satisfy the strong converse property and are\nstrongly additive. In the zero-error case, we introduce the notion of the\nstabilized non-commutative confusability graph of a quantum channel and\ncharacterize its structure for any given channel.", "published": "2025-04-14 17:27:43", "link": "http://arxiv.org/abs/2504.10436v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Unique Decoding of Reed-Solomon and Related Codes for Semi-Adversarial Errors", "abstract": "For over a quarter century, the Guruswami-Sudan algorithm has served as the\nstate-of-the-art for list-decoding Reed-Solomon (RS) codes up to the Johnson\nbound against adversarial errors. However, some recent structural results on\nthe combinatorial list decoding of randomly punctured Reed-Solomon codes\nsuggest that Johnson bound can likely be broken for some subclasses of RS\ncodes. Motivated by these results, we seek to make traction on understanding\nadversarial decoding by considering a new model: semi-adversarial errors. This\nerror model bridges between fully random errors and fully adversarial errors by\nallowing some symbols of a message to be corrupted by an adversary while others\nare replaced with uniformly random symbols.\n  As our main quest, we seek to understand optimal efficient unique decoding\nalgorithms in the semi-adversarial model. In particular, we revisit some\nclassical results on decoding interleaved Reed-Solomon codes (aka subfield\nevaluation RS codes) in the random error model by Bleichenbacher-Kiayias-Yung\n(BKY) and work to improve and extend their analysis. First, we give an improved\nimplementation and analysis of the BKY algorithm for interleaved Reed-Solomon\ncodes in the semi-adversarial model. In particular, our algorithm runs in\nnear-linear time, and for most mixtures of random and adversarial errors, our\nanalysis matches the information-theoretic optimum.\n  Moreover, inspired by the BKY algorithm, we use a novel interpolation to\nextend our approach to the settings of folded Reed-Solomon codes, resulting in\nfast algorithms for unique decoding against semi-adversarial errors. A\nparticular advantage of our near-linear time algorithm over state-of-the-art\ndecoding algorithms for adversarial errors is that its running time depends\nonly on a polynomial function of the folding parameter rather than on an\nexponential function.", "published": "2025-04-14 16:49:45", "link": "http://arxiv.org/abs/2504.10399v1", "categories": ["cs.IT", "cs.DS", "math.IT"], "primary_category": "cs.IT"}
{"title": "Simple physical systems as a reference for multivariate information dynamics", "abstract": "Understanding a complex system entails capturing the non-trivial collective\nphenomena that arise from interactions between its different parts. Information\ntheory is a flexible and robust framework to study such behaviours, with\nseveral measures designed to quantify and characterise the interdependencies\namong the system's components. However, since these estimators rely on the\nstatistical distributions of observed quantities, it is crucial to examine the\nrelationships between information-theoretic measures and the system's\nunderlying mechanistic structure. To this end, here we present an\ninformation-theoretic analytical investigation of an elementary system of\ninteractive random walkers subject to Gaussian noise. Focusing on partial\ninformation decomposition, causal emergence, and integrated information, our\nresults help us develop some intuitions on their relationship with the physical\nparameters of the system. For instance, we observe that uncoupled systems can\nexhibit emergent properties, in a way that we suggest may be better described\nas ''statistically autonomous''. Overall, we observe that in this simple\nscenario information measures align more reliably with the system's mechanistic\nproperties when calculated at the level of microscopic components, rather than\ntheir coarse-grained counterparts, and over timescales comparable with the\nsystem's intrinsic dynamics. Moreover, we show that approaches that separate\nthe contributions of the system's dynamics and steady-state distribution (e.g.\nvia causal perturbations) may help strengthen the interpretation of\ninformation-theoretic analyses.", "published": "2025-04-14 16:20:48", "link": "http://arxiv.org/abs/2504.10372v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "VAE-based Feature Disentanglement for Data Augmentation and Compression in Generalized GNSS Interference Classification", "abstract": "Distributed learning and Edge AI necessitate efficient data processing,\nlow-latency communication, decentralized model training, and stringent data\nprivacy to facilitate real-time intelligence on edge devices while reducing\ndependency on centralized infrastructure and ensuring high model performance.\nIn the context of global navigation satellite system (GNSS) applications, the\nprimary objective is to accurately monitor and classify interferences that\ndegrade system performance in distributed environments, thereby enhancing\nsituational awareness. To achieve this, machine learning (ML) models can be\ndeployed on low-resource devices, ensuring minimal communication latency and\npreserving data privacy. The key challenge is to compress ML models while\nmaintaining high classification accuracy. In this paper, we propose variational\nautoencoders (VAEs) for disentanglement to extract essential latent features\nthat enable accurate classification of interferences. We demonstrate that the\ndisentanglement approach can be leveraged for both data compression and data\naugmentation by interpolating the lower-dimensional latent representations of\nsignal power. To validate our approach, we evaluate three VAE variants -\nvanilla, factorized, and conditional generative - on four distinct datasets,\nincluding two collected in controlled indoor environments and two real-world\nhighway datasets. Additionally, we conduct extensive hyperparameter searches to\noptimize performance. Our proposed VAE achieves a data compression rate ranging\nfrom 512 to 8,192 and achieves an accuracy up to 99.92%.", "published": "2025-04-14 13:38:00", "link": "http://arxiv.org/abs/2504.10556v1", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT", "94-05, 82-11", "E.0; I.2.0; I.5.4; I.5.1"], "primary_category": "cs.LG"}
{"title": "The topology of synergy: linking topological and information-theoretic approaches to higher-order interactions in complex systems", "abstract": "The study of irreducible higher-order interactions has become a core topic of\nstudy in complex systems. Two of the most well-developed frameworks,\ntopological data analysis and multivariate information theory, aim to provide\nformal tools for identifying higher-order interactions in empirical data.\nDespite similar aims, however, these two approaches are built on markedly\ndifferent mathematical foundations and have been developed largely in parallel.\nIn this study, we present a head-to-head comparison of topological data\nanalysis and information-theoretic approaches to describing higher-order\ninteractions in multivariate data; with the aim of assessing the similarities\nand differences between how the frameworks define ``higher-order structures.\"\nWe begin with toy examples with known topologies, before turning to\nnaturalistic data: fMRI signals collected from the human brain. We find that\nintrinsic, higher-order synergistic information is associated with\nthree-dimensional cavities in a point cloud: shapes such as spheres are\nsynergy-dominated. In fMRI data, we find strong correlations between\nsynergistic information and both the number and size of three-dimensional\ncavities. Furthermore, we find that dimensionality reduction techniques such as\nPCA preferentially represent higher-order redundancies, and largely fail to\npreserve both higher-order information and topological structure, suggesting\nthat common manifold-based approaches to studying high-dimensional data are\nsystematically failing to identify important features of the data. These\nresults point towards the possibility of developing a rich theory of\nhigher-order interactions that spans topological and information-theoretic\napproaches while simultaneously highlighting the profound limitations of more\nconventional methods.", "published": "2025-04-14 11:53:48", "link": "http://arxiv.org/abs/2504.10140v1", "categories": ["cs.IT", "math.IT", "q-bio.NC"], "primary_category": "cs.IT"}
{"title": "Multi-Target Position Error Bound and Power Allocation Scheme for Cell-Free mMIMO-OTFS ISAC Systems", "abstract": "This paper investigates multi-target position estimation in cell-free massive\nmultiple-input multiple-output (CF mMIMO) architectures, where orthogonal time\nfrequency and space (OTFS) is used as an integrated sensing and communication\n(ISAC) signal. Closed-form expressions for the Cram\\'{e}r-Rao lower bound and\nthe positioning error bound (PEB) in multi-target position estimation are\nderived, providing quantitative evaluations of sensing performance. To enhance\nthe overall performance of the ISAC system, a power allocation algorithm is\ndeveloped to maximize the minimum user communication\nsignal-to-interference-plus-noise ratio while ensuring a specified sensing PEB\nrequirement. The results validate the proposed PEB expression and its\napproximation, clearly illustrating the coordination gain enabled by ISAC.\nFurther, the superiority of using the multi-static CF mMIMO architecture over\ntraditional cellular ISAC is demonstrated, and the advantages of OTFS signals\nin high-mobility scenarios are highlighted.", "published": "2025-04-14 11:48:15", "link": "http://arxiv.org/abs/2504.10137v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Code size constraints in b-symbol read channels: A bound analysis", "abstract": "In classical coding theory, error-correcting codes are designed to protect\nagainst errors occurring at individual symbol positions in a codeword. However,\nin practical storage and communication systems, errors often affect multiple\nadjacent symbols rather than single symbols independently. To address this,\nsymbol-pair read channels were introduced \\cite{Yuval2011}, and later\ngeneralized to $b$-symbol read channels \\cite{yaakobi2016} to better model such\nerror patterns. $b$-Symbol read channels generalize symbol-pair read channels\nto account for clustered errors in modern storage and communication systems. By\ndeveloping bounds and efficient codes, researchers improve data reliability in\napplications such as storage devices, wireless networks, and DNA-based storage.\nGiven integers $q$, $n$, $d$, and $b \\geq 2$, let $A_b(n,d,q)$ denote the\nlargest possible code size for which there exists a $q$-ary code of length $n$\nwith minimum $b$-symbol distance at least $d$. In \\cite{chen2022}, various\nupper and lower bounds on $A_b(n,d,q)$ are given for $b=2$. In this paper, we\ngeneralize some of these bounds to the $b$-symbol read channels for $b>2$ and\npresent several new bounds on $A_b(n,d,q)$. In particular, we establish the\nlinear programming bound, a recurrence relation on $A_b(n,d,q)$, the Johnson\nbound (even), the restricted Johnson bound, the Gilbert-Varshamov-type bound,\nand the Elias bound for the metric of symbols $b$, $b\\geq 2$. Furthermore, we\nprovide examples demonstrating that the Gilbert-Varshamov bound we establish\noffers a stronger lower bound than the one presented in \\cite{Song2018}.\nAdditionally, we introduce an alternative approach to deriving the\nSphere-packing and Plotkin bounds.", "published": "2025-04-14 10:47:31", "link": "http://arxiv.org/abs/2504.10088v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Frequency Hopping Waveform Design for Secure Integrated Sensing and Communications", "abstract": "We introduce a comprehensive approach to enhance the security, privacy, and\nsensing capabilities of integrated sensing and communications (ISAC) systems by\nleveraging random frequency agility (RFA) and random pulse repetition interval\n(PRI) agility (RPA) techniques. The combination of these techniques, which we\nrefer to collectively as random frequency and PRI agility (RFPA), with channel\nreciprocity-based key generation (CRKG) obfuscates both Doppler frequency and\nPRIs, significantly hindering the chances that passive adversaries can\nsuccessfully estimate radar parameters. In addition, a hybrid information\nembedding method integrating amplitude shift keying (ASK), phase shift keying\n(PSK), index modulation (IM), and spatial modulation (SM) is incorporated to\nincrease the achievable bit rate of the system significantly. Next, a\nsparse-matched filter receiver design is proposed to efficiently decode the\nembedded information with a low bit error rate (BER). Finally, a novel\nRFPA-based secret generation scheme using CRKG ensures secure code creation\nwithout a coordinating authority. The improved range and velocity estimation\nand reduced clutter effects achieved with the method are demonstrated via the\nevaluation of the ambiguity function (AF) of the proposed waveforms.", "published": "2025-04-14 09:56:18", "link": "http://arxiv.org/abs/2504.10052v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Secrecy and Privacy in Multi-Access Combinatorial Topology", "abstract": "In this work, we consider the multi-access combinatorial topology with $C$\ncaches where each user accesses a unique set of $r$ caches. For this setup, we\nconsider secrecy, where each user should not know anything about the files it\ndid not request, and demand privacy, where each user's demand must be kept\nprivate from other non-colluding users. We propose a scheme satisfying both\nconditions and derive a lower bound based on cut-set arguments. Also, we prove\nthat our scheme is optimal when $r\\geq C-1$, and it is order-optimal when the\ncache memory size $M$ is greater than or equal to a certain threshold for\n$r<C-1$. When $r=1$, in most of the memory region, our scheme achieves the same\nrate as the one given by the secretive scheme for the dedicated cache setup by\nRavindrakumar et al. ( 'Private Coded Caching,' in \\textit{IEEE Transactions on\nInformation Forensics and Security}, 2018), while satisfying both secrecy and\ndemand privacy conditions.", "published": "2025-04-14 07:30:03", "link": "http://arxiv.org/abs/2504.09952v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Constrained Error-Correcting Codes for Efficient DNA Synthesis", "abstract": "DNA synthesis is considered as one of the most expensive components in\ncurrent DNA storage systems. In this paper, focusing on a common synthesis\nmachine, which generates multiple DNA strands in parallel following a fixed\nsupersequence,we propose constrained codes with polynomial-time encoding and\ndecoding algorithms. Compared to the existing works, our codes simultaneously\nsatisfy both l-runlength limited and {\\epsilon}-balanced constraints. By\nenumerating all valid sequences, our codes achieve the maximum rate, matching\nthe capacity. Additionally, we design constrained error-correcting codes\ncapable of correcting one insertion or deletion in the obtained DNA sequence\nwhile still adhering to the constraints.", "published": "2025-04-14 07:25:18", "link": "http://arxiv.org/abs/2504.09950v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "On the $N$th $2$-adic complexity of binary sequences identified with algebraic $2$-adic integers", "abstract": "We identify a binary sequence $\\mathcal{S}=(s_n)_{n=0}^\\infty$ with the\n$2$-adic integer $G_\\mathcal{S}(2)=\\sum\\limits_{n=0}^\\infty s_n2^n$. In the\ncase that $G_\\mathcal{S}(2)$ is algebraic over $\\mathbb{Q}$ of degree $d\\ge 2$,\nwe prove that the $N$th $2$-adic complexity of $\\mathcal{S}$ is at least\n$\\frac{N}{d}+O(1)$, where the implied constant depends only on the minimal\npolynomial of $G_\\mathcal{S}(2)$. This result is an analog of the bound of\nM\\'erai and the second author on the linear complexity of automatic sequences,\nthat is, sequences with algebraic $G_\\mathcal{S}(X)$ over the rational function\nfield $\\mathbb{F}_2(X)$. We further discuss the most important case $d=2$ in\nboth settings and explain that the intersection of the set of $2$-adic\nalgebraic sequences and the set of automatic sequences is the set of\n(eventually) periodic sequences. Finally, we provide some experimental results\nsupporting the conjecture that $2$-adic algebraic sequences can have also a\ndesirable $N$th linear complexity and automatic sequences a desirable $N$th\n$2$-adic complexity, respectively.", "published": "2025-04-14 06:52:47", "link": "http://arxiv.org/abs/2504.09933v1", "categories": ["math.NT", "cs.IT", "math.IT"], "primary_category": "math.NT"}
{"title": "A Theory of Universal Rate-Distortion-Classification Representations for Lossy Compression", "abstract": "In lossy compression, Blau and Michaeli [5] introduced the information\nrate-distortion-perception (RDP) function, extending traditional\nrate-distortion theory by incorporating perceptual quality. More recently, this\nframework was expanded by defining the\nrate-distortion-perception-classification (RDPC) function, integrating\nmulti-task learning that jointly optimizes generative tasks such as perceptual\nquality and classification accuracy alongside reconstruction tasks [28]. To\nthat end, motivated by the concept of a universal RDP encoder introduced in\n[34], we investigate universal representations that enable diverse\ndistortion-classification tradeoffs through a single fixed encoder combined\nwith multiple decoders. Specifically, theoretical analysis and numerical\nexperiment demonstrate that for the Gaussian source under mean squared error\n(MSE) distortion, the entire distortion-classification tradeoff region can be\nachieved using one universal encoder. In addition, this paper characterizes\nachievable distortion-classification regions for fixed universal\nrepresentations in general source distributions, identifying conditions that\nensure minimal distortion penalty when reusing encoders across varying tradeoff\npoints. Experimental results using MNIST and SVHN datasets validate our\ntheoretical insights, showing that universal encoders can obtain distortion\nperformance comparable to task-specific encoders, thus supporting the\npracticality and effectiveness of our proposed universal representations.", "published": "2025-04-14 06:46:02", "link": "http://arxiv.org/abs/2504.09932v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Passive Channel Charting: Locating Passive Targets using Wi-Fi Channel State Information", "abstract": "We propose passive channel charting, an extension of channel charting to\npassive target localization. As in conventional channel charting, we follow a\ndimensionality reduction approach to reconstruct a physically interpretable map\nof target positions from similarities in high-dimensional channel state\ninformation. We show that algorithms and neural network architectures developed\nin the context of channel charting with active mobile transmitters can be\nstraightforwardly applied to the passive case, where we assume a scenario with\nstatic transmitters and receivers and a mobile target. We evaluate our method\non a channel state information dataset collected indoors with a distributed\nsetup of ESPARGOS Wi-Fi sensing antenna arrays. This scenario can be\ninterpreted as either a multi-static or passive radar system. We demonstrate\nthat passive channel charting outperforms a baseline based on classical\ntriangulation in terms of localization accuracy. We discuss our results and\nhighlight some unsolved issues related to the proposed concept.", "published": "2025-04-14 06:33:07", "link": "http://arxiv.org/abs/2504.09924v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Finite-Precision Conjugate Gradient Method for Massive MIMO Detection", "abstract": "The implementation of the conjugate gradient (CG) method for massive MIMO\ndetection is computationally challenging, especially for a large number of\nusers and correlated channels. In this paper, we propose a low computational\ncomplexity CG detection from a finite-precision perspective. First, we develop\na finite-precision CG (FP-CG) detection to mitigate the computational\nbottleneck of each CG iteration and provide the attainable accuracy,\nconvergence, and computational complexity analysis to reveal the impact of\nfinite-precision arithmetic. A practical heuristic is presented to select\nsuitable precisions. Then, to further reduce the number of iterations, we\npropose a joint finite-precision and block-Jacobi preconditioned CG (FP-BJ-CG)\ndetection. The corresponding performance analysis is also provided. Finally,\nsimulation results validate the theoretical insights and demonstrate the\nsuperiority of the proposed detection.", "published": "2025-04-14 02:46:05", "link": "http://arxiv.org/abs/2504.09820v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Communication-aware Hierarchical Map Compression of Time-Varying Environments for Mobile Robots", "abstract": "In this paper, we develop a systematic framework for the time-sequential\ncompression of dynamic probabilistic occupancy grids. Our approach leverages\nideas from signal compression theory to formulate an optimization problem that\nsearches for a multi-resolution hierarchical encoder that balances the quality\nof the compressed map (distortion) with its description size, the latter of\nwhich relates to the bandwidth required to reliably transmit the map to other\nagents or to store map estimates in on-board memory. The resulting optimization\nproblem allows for multi-resolution map compressions to be obtained that\nsatisfy available communication or memory resources, and does not require\nknowledge of the occupancy map dynamics. We develop an algorithm to solve our\nproblem, and demonstrate the utility of the proposed framework in simulation on\nboth static (i.e., non-time varying) and dynamic (time-varying) occupancy maps.", "published": "2025-04-14 22:54:29", "link": "http://arxiv.org/abs/2504.10751v1", "categories": ["cs.RO", "cs.AI", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Achieving Optimal Tissue Repair Through MARL with Reward Shaping and Curriculum Learning", "abstract": "In this paper, we present a multi-agent reinforcement learning (MARL)\nframework for optimizing tissue repair processes using engineered biological\nagents. Our approach integrates: (1) stochastic reaction-diffusion systems\nmodeling molecular signaling, (2) neural-like electrochemical communication\nwith Hebbian plasticity, and (3) a biologically informed reward function\ncombining chemical gradient tracking, neural synchronization, and robust\npenalties. A curriculum learning scheme guides the agent through progressively\ncomplex repair scenarios. In silico experiments demonstrate emergent repair\nstrategies, including dynamic secretion control and spatial coordination.", "published": "2025-04-14 19:57:03", "link": "http://arxiv.org/abs/2504.10677v1", "categories": ["cs.LG", "cs.AI", "cs.MA"], "primary_category": "cs.LG"}
{"title": "PestMA: LLM-based Multi-Agent System for Informed Pest Management", "abstract": "Effective pest management is complex due to the need for accurate,\ncontext-specific decisions. Recent advancements in large language models (LLMs)\nopen new possibilities for addressing these challenges by providing\nsophisticated, adaptive knowledge acquisition and reasoning. However, existing\nLLM-based pest management approaches often rely on a single-agent paradigm,\nwhich can limit their capacity to incorporate diverse external information,\nengage in systematic validation, and address complex, threshold-driven\ndecisions. To overcome these limitations, we introduce PestMA, an LLM-based\nmulti-agent system (MAS) designed to generate reliable and evidence-based pest\nmanagement advice. Building on an editorial paradigm, PestMA features three\nspecialized agents, an Editor for synthesizing pest management recommendations,\na Retriever for gathering relevant external data, and a Validator for ensuring\ncorrectness. Evaluations on real-world pest scenarios demonstrate that PestMA\nachieves an initial accuracy of 86.8% for pest management decisions, which\nincreases to 92.6% after validation. These results underscore the value of\ncollaborative agent-based workflows in refining and validating decisions,\nhighlighting the potential of LLM-based multi-agent systems to automate and\nenhance pest management processes.", "published": "2025-04-14 03:53:59", "link": "http://arxiv.org/abs/2504.09855v1", "categories": ["cs.MA", "cs.AI", "I.2.1; I.2.7"], "primary_category": "cs.MA"}
{"title": "On an efficient line smoother for the p-multigrid \u03b3-cycle", "abstract": "As part of the development of a Poisson solver for the spectral element\ndiscretization used in the GeoFluid Object Workbench (GeoFLOW) code, we propose\na solver for the linear system arising from a Gauss-Legendre-Lobatto global\nspectral method. We precondition using a p-multigrid {\\gamma}-cycle with\nhighly-vectorizable smoothers, that we refer to as line smoothers. Our\nsmoothers are restrictions of spectral and finite element discretizations to\nlow-order one-dimensional problems along lines, that are solved by a\nreformulation of cyclic reduction as a direct multigrid method. We illustrate\nour method with numerical experiments showing the apparent boundedness of the\niteration count for a fixed residual reduction over a range of moderately\ndeformed domains, right hand sides and Dirichlet boundary conditions.", "published": "2025-04-14 21:01:14", "link": "http://arxiv.org/abs/2504.10710v1", "categories": ["math.NA", "cs.NA", "65N35"], "primary_category": "math.NA"}
{"title": "What metric to optimize for suppressing instability in a Vlasov-Poisson system?", "abstract": "Stabilizing plasma dynamics is an important task in green energy generation\nvia nuclear fusion. One common strategy is to introduce an external field to\nprevent the plasma distribution from developing turbulence. However, finding\nsuch external fields efficiently remains an open question, even for simplified\nmodels such as the Vlasov-Poisson (VP) system. In this work, we leverage two\ndifferent approaches to build such fields: for the first approach, we use an\nanalytical derivation of the dispersion relation of the VP system to find a\nrange of reasonable fields that can potentially suppress instability, providing\na qualitative suggestion. For the second approach, we leverage PDE-constrained\noptimization to obtain a locally optimal field using different loss functions.\nAs the stability of the system can be characterized in several different ways,\nthe objective functions need to be tailored accordingly. We show, through\nextensive numerical tests, that objective functions such as the relative\nentropy (KL divergence) and the $L^{2}$ norm result in a highly non-convex\nproblem, rendering the global minimum difficult to find. However, we show that\nusing the electric energy of the system as a loss function is advantageous, as\nit has a large convex basin close to the global minimum. Unfortunately, outside\nthe basin, the electric energy landscape consists of unphysical flat local\nminima, thus rendering a good initial guess key for the overall convergence of\nthe optimization problem, particularly for solvers with adaptive steps.", "published": "2025-04-14 17:26:09", "link": "http://arxiv.org/abs/2504.10435v2", "categories": ["math.NA", "cs.NA", "physics.comp-ph"], "primary_category": "math.NA"}
{"title": "DUE: A Deep Learning Framework and Library for Modeling Unknown Equations", "abstract": "Equations, particularly differential equations, are fundamental for\nunderstanding natural phenomena and predicting complex dynamics across various\nscientific and engineering disciplines. However, the governing equations for\nmany complex systems remain unknown due to intricate underlying mechanisms.\nRecent advancements in machine learning and data science offer a new paradigm\nfor modeling unknown equations from measurement or simulation data. This\nparadigm shift, known as data-driven discovery or modeling, stands at the\nforefront of AI for science, with significant progress made in recent years. In\nthis paper, we introduce a systematic framework for data-driven modeling of\nunknown equations using deep learning. This versatile framework is capable of\nlearning unknown ODEs, PDEs, DAEs, IDEs, SDEs, reduced or partially observed\nsystems, and non-autonomous differential equations. Based on this framework, we\nhave developed Deep Unknown Equations (DUE), an open-source software package\ndesigned to facilitate the data-driven modeling of unknown equations using\nmodern deep learning techniques. DUE serves as an educational tool for\nclassroom instruction, enabling students and newcomers to gain hands-on\nexperience with differential equations, data-driven modeling, and contemporary\ndeep learning approaches such as FNN, ResNet, generalized ResNet, operator\nsemigroup networks (OSG-Net), and Transformers. Additionally, DUE is a\nversatile and accessible toolkit for researchers across various scientific and\nengineering fields. It is applicable not only for learning unknown equations\nfrom data but also for surrogate modeling of known, yet complex, equations that\nare costly to solve using traditional numerical methods. We provide detailed\ndescriptions of DUE and demonstrate its capabilities through diverse examples,\nwhich serve as templates that can be easily adapted for other applications.", "published": "2025-04-14 16:20:55", "link": "http://arxiv.org/abs/2504.10373v1", "categories": ["cs.LG", "cs.NA", "math.DS", "math.NA", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Sidecar: A Structure-Preserving Framework for Solving Partial Differential Equations with Neural Networks", "abstract": "Solving partial differential equations (PDEs) with neural networks (NNs) has\nshown great potential in various scientific and engineering fields. However,\nmost existing NN solvers mainly focus on satisfying the given PDEs, without\nexplicitly considering intrinsic physical properties such as mass conservation\nor energy dissipation. This limitation can result in unstable or nonphysical\nsolutions, particularly in long-term simulations. To address this issue, we\npropose Sidecar, a novel framework that enhances the accuracy and physical\nconsistency of existing NN solvers by incorporating structure-preserving\nknowledge. Inspired by the Time-Dependent Spectral Renormalization (TDSR)\napproach, our Sidecar framework introduces a small copilot network, which is\ntrained to guide the existing NN solver in preserving physical structure. This\nframework is designed to be highly flexible, enabling the incorporation of\nstructure-preserving principles from diverse PDEs into a wide range of NN\nsolvers. Our experimental results on benchmark PDEs demonstrate the improvement\nof the existing neural network solvers in terms of accuracy and consistency\nwith structure-preserving properties.", "published": "2025-04-14 14:40:11", "link": "http://arxiv.org/abs/2504.10273v1", "categories": ["cs.LG", "cs.NA", "math.NA", "65M99, 68T07, 35L65"], "primary_category": "cs.LG"}
{"title": "Dual-grid parameter choice method with application to image deblurring", "abstract": "Variational regularization of ill-posed inverse problems is based on\nminimizing the sum of a data fidelity term and a regularization term. The\nbalance between them is tuned using a positive regularization parameter, whose\nautomatic choice remains an open question in general. A novel approach for\nparameter choice is introduced, based on the use of two slightly different\ncomputational models for the same inverse problem. Small parameter values\nshould give two very different reconstructions due to amplification of noise.\nLarge parameter values lead to two identical but trivial reconstructions.\nOptimal parameter is chosen between the extremes by matching image similarity\nof the two reconstructions with a pre-defined value. Efficacy of the new method\nis demonstrated with image deblurring using measured data and two different\nregularizers.", "published": "2025-04-14 14:19:58", "link": "http://arxiv.org/abs/2504.10259v1", "categories": ["math.NA", "cs.NA", "65-XX, 00A69"], "primary_category": "math.NA"}
{"title": "WG-IDENT: Weak Group Identification of PDEs with Varying Coefficients", "abstract": "Partial Differential Equations (PDEs) identification is a data-driven method\nfor mathematical modeling, and has received a lot of attentions recently. The\nstability and precision in identifying PDE from heavily noisy spatiotemporal\ndata present significant difficulties. This problem becomes even more complex\nwhen the coefficients of the PDEs are subject to spatial variation. In this\npaper, we propose a Weak formulation of Group-sparsity-based framework for\nIDENTifying PDEs with varying coefficients, called WG-IDENT, to tackle this\nchallenge. Our approach utilizes the weak formulation of PDEs to reduce the\nimpact of noise. We represent test functions and unknown PDE coefficients using\nB-splines, where the knot vectors of test functions are optimally selected\nbased on spectral analysis of the noisy data. To facilitate feature selection,\nwe propose to integrate group sparse regression with a newly designed group\nfeature trimming technique, called GF-trim, to eliminate unimportant features.\nExtensive and comparative ablation studies are conducted to validate our\nproposed method. The proposed method not only demonstrates greater robustness\nto high noise levels compared to state-of-the-art algorithms but also achieves\nsuperior performance while exhibiting reduced sensitivity to hyperparameter\nselection.", "published": "2025-04-14 13:26:56", "link": "http://arxiv.org/abs/2504.10212v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Energy-preserving iteration schemes for Gauss collocation integrators", "abstract": "In this work, we develop energy-preserving iterative schemes for the\n(non-)linear systems arising in the Gauss integration of Poisson systems with\nquadratic Hamiltonian. Exploiting the relation between Gauss collocation\nintegrators and diagonal Pad\\'e approximations, we establish a Krylov-subspace\niteration scheme based on a $Q$-Arnoldi process for linear systems that\nprovides energy conservation not only at convergence --as standard iteration\nschemes do--, but also at the level of the individual iterates. It is\ncompetitive with GMRES in terms of accuracy and cost for a single iteration\nstep and hence offers significant efficiency gains, when it comes to time\nintegration of high-dimensional Poisson systems within given error tolerances.\nOn top of the linear results, we consider non-linear Poisson systems and design\nnon-linear solvers for the implicit midpoint rule (Gauss integrator of second\norder), using the fact that the associated Pad\\'e approximation is a Cayley\ntransformation. For the non-linear systems arising at each time step, we\npropose fixed-point and Newton-type iteration schemes that inherit the\nconvergence order with comparable cost from their classical versions, but have\nenergy-preserving iterates.", "published": "2025-04-14 13:26:38", "link": "http://arxiv.org/abs/2504.10211v1", "categories": ["math.NA", "cs.NA", "37Mxx, 47J25, 65Lxx, 65Pxx"], "primary_category": "math.NA"}
{"title": "An initial-boundary corrected splitting method for diffusion-reaction problems", "abstract": "Strang splitting is a widely used second-order method for solving\ndiffusion-reaction problems. However, its convergence order is often reduced to\norder $1$ for Dirichlet boundary conditions and to order $1.5$ for Neumann and\nRobin boundary conditions, leading to lower accuracy and reduced efficiency. In\nthis paper, we propose a new splitting approach, called an initial-boundary\ncorrected splitting, which avoids order reduction while improving computational\nefficiency for a wider range of applications. In contrast to the corrections\nproposed in the literature, it does not require the computation of correction\nterms that depend on the boundary conditions and boundary data. Through\nrigorous analytical convergence analysis and numerical experiments, we\ndemonstrate the improved accuracy and performance of the proposed method.", "published": "2025-04-14 11:32:33", "link": "http://arxiv.org/abs/2504.10125v1", "categories": ["math.NA", "cs.NA", "65M12, 65M20, 65L04"], "primary_category": "math.NA"}
{"title": "Stochastic Multigrid Minimization for Ptychographic Phase Retrieval", "abstract": "We propose a novel stochastic multigrid minimization method for ptychographic\nphase retrieval. In our formulation, the challenging nonconvex and ill-posed\ninverse problem is recast as the iterative minimization of a quadratic\nsurrogate model that majorizes the original objective function. Our general\nframework encompasses the Ptychographic Iterative Engine (PIE) family of\nalgorithms. By efficiently solving the surrogate problem using a multigrid\nmethod, our approach delivers significant improvements in both convergence\nspeed and reconstruction quality compared with conventional PIE techniques.", "published": "2025-04-14 11:28:20", "link": "http://arxiv.org/abs/2504.10118v1", "categories": ["math.NA", "cs.NA", "math.OC"], "primary_category": "math.NA"}
{"title": "Numerical approach for solving problems arising from polynomial analysis", "abstract": "This paper deals with the use of numerical methods based on random root\nsampling techniques to solve some theoretical problems arising in the analysis\nof polynomials. These methods are proved to be practical and give solutions\nwhere traditional methods might fall short.", "published": "2025-04-14 11:13:11", "link": "http://arxiv.org/abs/2504.10103v1", "categories": ["math.NA", "cs.NA", "math.CA"], "primary_category": "math.NA"}
{"title": "Bayesian optimal experimental design with Wasserstein information criteria", "abstract": "Bayesian optimal experimental design (OED) provides a principled framework\nfor selecting the most informative observational settings in experiments. With\nrapid advances in computational power, Bayesian OED has become increasingly\nfeasible for inference problems involving large-scale simulations, attracting\ngrowing interest in fields such as inverse problems. In this paper, we\nintroduce a novel design criterion based on the expected Wasserstein-$p$\ndistance between the prior and posterior distributions. Especially, for $p=2$,\nthis criterion shares key parallels with the widely used expected information\ngain (EIG), which relies on the Kullback--Leibler divergence instead. First,\nthe Wasserstein-2 criterion admits a closed-form solution for Gaussian\nregression, a property which can be also leveraged for approximative schemes.\nSecond, it can be interpreted as maximizing the information gain measured by\nthe transport cost incurred when updating the prior to the posterior. Our main\ncontribution is a stability analysis of the Wasserstein-1 criterion, where we\nprovide a rigorous error analysis under perturbations of the prior or\nlikelihood. We partially extend this study also to the Wasserstein-2 criterion.\nIn particular, these results yield error rates when empirical approximations of\npriors are used. Finally, we demonstrate the computability of the Wasserstein-2\ncriterion and demonstrate our approximation rates through simulations.", "published": "2025-04-14 10:56:42", "link": "http://arxiv.org/abs/2504.10092v1", "categories": ["stat.ME", "cs.NA", "math.NA", "stat.CO"], "primary_category": "stat.ME"}
{"title": "Wasserstein convergence rates for stochastic particle approximation of Boltzmann models", "abstract": "We establish quantitative convergence rates for stochastic particle\napproximation based on Nanbu-type Monte Carlo schemes applied to a broad class\nof collisional kinetic models. Using coupling techniques and stability\nestimates in the Wasserstein-1 (Kantorovich-Rubinstein) metric, we derive sharp\nerror bounds that reflect the nonlinear interaction structure of the models.\nOur framework includes classical Nanbu Monte Carlo method and more recent\ndevelopments as Time Relaxed Monte Carlo methods. The results bridge the gap\nbetween probabilistic particle approximations and deterministic numerical error\nanalysis, and provide a unified perspective for the convergence theory of Monte\nCarlo methods for Boltzmann-type equations. As a by-product, we also obtain\nexistence and uniqueness of solutions to a large class of Boltzmann-type\nequations.", "published": "2025-04-14 10:55:04", "link": "http://arxiv.org/abs/2504.10091v1", "categories": ["math.NA", "cs.NA", "65C05, 35Q20, 82C22, 49Q22, 65M15"], "primary_category": "math.NA"}
{"title": "Convergence Analysis of a Stochastic Interacting Particle-Field Algorithm for 3D Parabolic-Parabolic Keller-Segel Systems", "abstract": "Chemotaxis models describe the movement of organisms in response to chemical\ngradients. In this paper, we present a stochastic interacting particle-field\nalgorithm with random batch approximation (SIPF-$r$) for the three-dimensional\n(3D) parabolic-parabolic Keller-Segel (KS) system, also known as the fully\nparabolic KS system. The SIPF-$r$ method approximates the KS system by coupling\nparticle-based representations of density with a smooth field variable computed\nusing spectral methods. By incorporating the random batch method (RBM), we\nbypass the mean-field limit and significantly reduce computational complexity.\nUnder mild assumptions on the regularity of the original KS system and the\nboundedness of numerical approximations, we prove that, with high probability,\nthe empirical measure of the SIPF-$r$ particle system converges to the exact\nmeasure of the limiting McKean-Vlasov process in the $1$-Wasserstein distance.\nNumerical experiments validate the theoretical convergence rates and\ndemonstrate the robustness and accuracy of the SIPF-$r$ method.", "published": "2025-04-14 10:53:40", "link": "http://arxiv.org/abs/2504.10089v1", "categories": ["math.NA", "cs.NA", "35K51, 65C05, 65M12, 65M75, 65T50"], "primary_category": "math.NA"}
{"title": "Computing the unitary best approximant to the exponential function", "abstract": "Unitary best approximation to the exponential function on an interval on the\nimaginary axis has been introduced recently. In the present work two algorithms\nare considered to compute this best approximant: an algorithm based on rational\ninterpolation in successively corrected interpolation nodes and the AAA-Lawson\nmethod. Moreover, a posteriori bounds are introduced to evaluate the quality of\na computed approximant and to show convergence to the unitary best approximant\nin practice. Two a priori estimates -- one based on experimental data, and one\nbased on an asymptotic error estimate -- are introduced to determine the\nunderlying frequency for which the unitary best approximant achieves a given\naccuracy. Performance of algorithms and estimates is verified by numerical\nexperiments. In particular, the interpolation-based algorithm converges to the\nunitary best approximant within a small number of iterations in practice.", "published": "2025-04-14 10:04:47", "link": "http://arxiv.org/abs/2504.10062v1", "categories": ["math.NA", "cs.NA", "41A20 (Primary) 30E10, 33B10, 41A05, 41A50 (Secondary)"], "primary_category": "math.NA"}
{"title": "An efffcient numerical scheme for two-dimensional nonlinear time fractional Schr\u00f6dinger equation", "abstract": "In this paper, a linearized fully discrete scheme is proposed to solve the\ntwo-dimensional nonlinear time fractional Schr\\\"odinger equation with weakly\nsingular solutions, which is constructed by using L1 scheme for Caputo\nfractional derivative, backward formula for the approximation of nonlinear term\nand five-point difference scheme in space. We rigorously prove the\nunconditional stability and pointwise-in-time convergence of the fully discrete\nscheme, which does not require any restriction on the grid ratio. Numerical\nresults are presented to verify the accuracy of the theoretical analysis.", "published": "2025-04-14 09:30:49", "link": "http://arxiv.org/abs/2504.10026v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Semi-implicit-explicit Runge-Kutta method for nonlinear differential equations", "abstract": "A semi-implicit-explicit (semi-IMEX) Runge-Kutta (RK) method is proposed for\nthe numerical integration of ordinary differential equations (ODEs) of the form\n$\\mathbf{u}' = \\mathbf{f}(t,\\mathbf{u}) + G(t,\\mathbf{u}) \\mathbf{u}$, where\n$\\mathbf{f}$ is a non-stiff term and $G\\mathbf{u}$ represents the stiff terms.\nSuch systems frequently arise from spatial discretizations of time-dependent\nnonlinear partial differential equations (PDEs). For instance, $G$ could\ninvolve higher-order derivative terms with nonlinear coefficients. Traditional\nIMEX-RK methods, which treat $\\mathbf{f}$ explicitly and $G\\mathbf{u}$\nimplicitly, require solving nonlinear systems at each time step when $G$\ndepends on $\\mathbf{u}$, leading to increased computational cost and\ncomplexity. In contrast, the proposed semi-IMEX scheme treats $G$ explicitly\nwhile keeping $\\mathbf{u}$ implicit, reducing the problem to solving only\nlinear systems. This approach eliminates the need to compute Jacobians while\npreserving the stability advantages of implicit methods. A family of semi-IMEX\nRK schemes with varying orders of accuracy is introduced. Numerical simulations\nfor various nonlinear equations, including nonlinear diffusion models, the\nNavier-Stokes equations, and the Cahn-Hilliard equation, confirm the expected\nconvergence rates and demonstrate that the proposed method allows for larger\ntime step sizes without triggering stability issues.", "published": "2025-04-14 08:18:57", "link": "http://arxiv.org/abs/2504.09969v1", "categories": ["math.NA", "cs.NA", "65L06, 65M22, 65M12, 76D05, 35K55, 35Q35"], "primary_category": "math.NA"}
{"title": "A posteriori estimates for problems with monotone operators", "abstract": "We propose a method of obtaining a posteriori estimates which does not use\nthe duality theory and which applies to variational inequalities with monotone\noperators, without assuming the potentiality of operators. The effectiveness of\nthe method is demonstrated on problems driven by nonlinear operators of the\n$p$-Laplacian type, including the anisotropic $p$-Laplacian, polyharmonic\n$p$-Laplacian, and fractional $p$-Laplacian.", "published": "2025-04-14 06:45:20", "link": "http://arxiv.org/abs/2504.09931v1", "categories": ["math.AP", "cs.NA", "math.NA", "35J92, 35B45, 35B30"], "primary_category": "math.AP"}
{"title": "NR-SSOR right preconditioned RRGMRES for arbitrary singular systems and least squares problems", "abstract": "GMRES is known to determine a least squares solution of $ A x = b $ where $ A\n\\in R^{n \\times n} $ without breakdown for arbitrary $ b \\in R^n $, and initial\niterate $ x_0 \\in R^n $ if and only if $ A $ is range-symmetric, i.e. $ R(A^T)\n= R(A) $, where $ A $ may be singular and $ b $ may not be in the range space $\nR(A) $ of $ A $.\n  In this paper, we propose applying the Range Restricted GMRES (RRGMRES) to $\nA C A^T z = b $, where $ C \\in R^{n \\times n} $ is symmetric positive definite.\nThis determines a least squares solution $ x = C A^T z $ of $ A x = b $ without\nbreakdown for arbitrary (singular) matrix $ A \\in R^{n \\times n} $ and $ b, x_0\n\\in R^n $, and is much more stable and accurate compared to GMRES, RRGMRES and\nMINRES-QLP applied to $ A x = b $ for inconsistent problems when $ b \\notin\nR(A) $. In particular, we propose applying the NR-SSOR as the inner iteration\nright preconditioner, which also works efficiently for least squares problems $\n\\min_{x \\in R^n} \\| b - A x\\|_2 $ for $ A \\in R^{m \\times n} $ and arbitrary $\nb \\in R^m $.\n  Numerical experiments demonstrate the validity of the proposed method.", "published": "2025-04-14 05:34:02", "link": "http://arxiv.org/abs/2504.09891v2", "categories": ["math.NA", "cs.NA", "65F10, 65F08, 65F20, 65F50"], "primary_category": "math.NA"}
{"title": "Maximum bound preservation of exponential integrators for Allen-Cahn equations", "abstract": "We develop and analyze a class of arbitrarily high-order, maximum bound\npreserving time-stepping schemes for solving Allen-Cahn equations. These\nschemes are constructed within the iterative framework of exponential\nintegrators, combined with carefully chosen numerical quadrature rules,\nincluding the Gauss-Legendre quadrature rule and the left Gauss-Radau\nquadrature rule. Notably, the proposed schemes are rigorously proven to\nunconditionally preserve the maximum bound without requiring any additional\npostprocessing techniques, while simultaneously achieving arbitrarily\nhigh-order temporal accuracy. A thorough error analysis in the $L^2$ norm is\nprovided. Numerical experiments validate the theoretical results, demonstrate\nthe effectiveness of the proposed methods, and highlight that an inappropriate\nchoice of quadrature rules may violate the maximum bound principle, leading to\nincorrect dynamics.", "published": "2025-04-14 04:48:59", "link": "http://arxiv.org/abs/2504.09874v1", "categories": ["math.NA", "cs.NA", "65M12, 65M15, 65R20"], "primary_category": "math.NA"}
{"title": "Truncated Matrix Completion - An Empirical Study", "abstract": "Low-rank Matrix Completion (LRMC) describes the problem where we wish to\nrecover missing entries of partially observed low-rank matrix. Most existing\nmatrix completion work deals with sampling procedures that are independent of\nthe underlying data values. While this assumption allows the derivation of nice\ntheoretical guarantees, it seldom holds in real-world applications. In this\npaper, we consider various settings where the sampling mask is dependent on the\nunderlying data values, motivated by applications in sensing, sequential\ndecision-making, and recommender systems. Through a series of experiments, we\nstudy and compare the performance of various LRMC algorithms that were\noriginally successful for data-independent sampling patterns.", "published": "2025-04-14 04:42:00", "link": "http://arxiv.org/abs/2504.09873v1", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA", "stat.ML"], "primary_category": "cs.LG"}
{"title": "High-Order Interior Penalty Finite Element Methods for Fourth-Order Phase-Field Models in Fracture Analysis", "abstract": "This paper presents a novel approach for solving fourth-order phase-field\nmodels in brittle fracture mechanics using the Interior Penalty Finite Element\nMethod (IP-FEM). The fourth-order model improves numerical stability and\naccuracy compared to traditional second-order phase-field models, particularly\nwhen simulating complex crack paths. The IP-FEM provides an efficient framework\nfor discretizing these models, effectively handling nonconforming trial\nfunctions and complex boundary conditions.\n  In this study, we leverage the FEALPy framework to implement a flexible\ncomputational tool that supports high-order IP-FEM discretizations. Our results\nshow that as the polynomial order increases, the mesh dependence of the\nphase-field model decreases, offering improved accuracy and faster convergence.\nAdditionally, we explore the trade-offs between computational cost and accuracy\nwith varying polynomial orders and mesh sizes. The findings offer valuable\ninsights for optimizing numerical simulations of brittle fracture in practical\nengineering applications.", "published": "2025-04-14 02:20:37", "link": "http://arxiv.org/abs/2504.09810v1", "categories": ["math.NA", "cs.NA", "math.AP"], "primary_category": "math.NA"}
{"title": "BO-SA-PINNs: Self-adaptive physics-informed neural networks based on Bayesian optimization for automatically designing PDE solvers", "abstract": "Physics-informed neural networks (PINNs) is becoming a popular alternative\nmethod for solving partial differential equations (PDEs). However, they require\ndedicated manual modifications to the hyperparameters of the network, the\nsampling methods and loss function weights for different PDEs, which reduces\nthe efficiency of the solvers. In this paper, we pro- pose a general\nmulti-stage framework, i.e. BO-SA-PINNs to alleviate this issue. In the first\nstage, Bayesian optimization (BO) is used to select hyperparameters for the\ntraining process, and based on the results of the pre-training, the network\narchitecture, learning rate, sampling points distribution and loss function\nweights suitable for the PDEs are automatically determined. The proposed\nhyperparameters search space based on experimental results can enhance the\nefficiency of BO in identifying optimal hyperparameters. After selecting the\nappropriate hyperparameters, we incorporate a global self-adaptive (SA)\nmechanism the second stage. Using the pre-trained model and loss information in\nthe second-stage training, the exponential moving average (EMA) method is\nemployed to optimize the loss function weights, and residual-based adaptive\nrefinement with distribution (RAR-D) is used to optimize the sampling points\ndistribution. In the third stage, L-BFGS is used for stable training. In\naddition, we introduce a new activation function that enables BO-SA-PINNs to\nachieve higher accuracy. In numerical experiments, we conduct comparative and\nablation experiments to verify the performance of the model on Helmholtz,\nMaxwell, Burgers and high-dimensional Poisson equations. The comparative\nexperiment results show that our model can achieve higher accuracy and fewer\niterations in test cases, and the ablation experiments demonstrate the positive\nimpact of every improvement.", "published": "2025-04-14 02:07:45", "link": "http://arxiv.org/abs/2504.09804v1", "categories": ["cs.CE", "cs.LG", "cs.NA", "math.NA", "65D99"], "primary_category": "cs.CE"}
{"title": "Optimal Execution in Intraday Energy Markets under Hawkes Processes with Transient Impact", "abstract": "This paper investigates optimal execution strategies in intraday energy\nmarkets through a mutually exciting Hawkes process model. Calibrated to data\nfrom the German intraday electricity market, the model effectively captures key\nempirical features, including intra-session volatility, distinct intraday\nmarket activity patterns, and the Samuelson effect as gate closure approaches.\nBy integrating a transient price impact model with a bivariate Hawkes process\nto model the market order flow, we derive an optimal trading trajectory for\nenergy companies managing large volumes, accounting for the specific trading\npatterns in these markets. A back-testing analysis compares the proposed\nstrategy against standard benchmarks such as Time-Weighted Average Price (TWAP)\nand Volume-Weighted Average Price (VWAP), demonstrating substantial cost\nreductions across various hourly trading products in intraday energy markets.", "published": "2025-04-14 14:51:18", "link": "http://arxiv.org/abs/2504.10282v1", "categories": ["q-fin.TR", "49J15, 91G80"], "primary_category": "q-fin.TR"}
{"title": "Beyond Coordinates: Meta-Equivariance in Statistical Inference", "abstract": "Optimal statistical decisions should transcend the language used to describe\nthem. Yet, how do we guarantee that the choice of coordinates - the\nparameterisation of an optimisation problem - does not subtly dictate the\nsolution? This paper reveals a fundamental geometric invariance principle. We\nfirst analyse the optimal combination of two asymptotically normal estimators\nunder a strictly convex trace-AMSE risk. While methods for finding optimal\nweights are known, we prove that the resulting optimal estimator is invariant\nunder direct affine reparameterisations of the weighting scheme. This\nexemplifies a broader principle we term meta-equivariance: the unique minimiser\nof any strictly convex, differentiable scalar objective over a matrix space\ntransforms covariantly under any invertible affine reparameterisation of that\nspace. Distinct from classical statistical equivariance tied to data\nsymmetries, meta-equivariance arises from the immutable geometry of convex\noptimisation itself. It guarantees that optimality, in these settings, is not\nan artefact of representation but an intrinsic, coordinate-free truth.", "published": "2025-04-14 19:40:39", "link": "http://arxiv.org/abs/2504.10667v1", "categories": ["math.ST", "math.OC", "stat.ML", "stat.TH", "62F12, 90C25, 53B20", "G.1.6; G.3"], "primary_category": "math.ST"}
{"title": "On the Contractivity of Stochastic Interpolation Flow", "abstract": "We investigate stochastic interpolation, a recently introduced framework for\nhigh dimensional sampling which bears many similarities to diffusion modeling.\nStochastic interpolation generates a data sample by first randomly initializing\na particle drawn from a simple base distribution, then simulating deterministic\nor stochastic dynamics such that in finite time the particle's distribution\nconverges to the target. We show that for a Gaussian base distribution and a\nstrongly log-concave target distribution, the stochastic interpolation flow map\nis Lipschitz with a sharp constant which matches that of Caffarelli's theorem\nfor optimal transport maps. We are further able to construct Lipschitz\ntransport maps between non-Gaussian distributions, generalizing some recent\nconstructions in the literature on transport methods for establishing\nfunctional inequalities. We discuss the practical implications of our theorem\nfor the sampling and estimation problems required by stochastic interpolation.", "published": "2025-04-14 19:10:22", "link": "http://arxiv.org/abs/2504.10653v1", "categories": ["math.ST", "cs.LG", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "SPreV", "abstract": "SPREV, short for hyperSphere Reduced to two-dimensional Regular Polygon for\nVisualisation, is a novel dimensionality reduction technique developed to\naddress the challenges of reducing dimensions and visualizing labeled datasets\nthat exhibit a unique combination of three characteristics: small class size,\nhigh dimensionality, and low sample size. SPREV is designed not only to uncover\nbut also to visually represent hidden patterns within such datasets. Its\ndistinctive integration of geometric principles, adapted for discrete\ncomputational environments, makes it an indispensable tool in the modern data\nscience toolkit, enabling users to identify trends, extract insights, and\nnavigate complex data efficiently and effectively.", "published": "2025-04-14 18:20:47", "link": "http://arxiv.org/abs/2504.10620v1", "categories": ["cs.GR", "cs.HC", "cs.LG", "stat.ML", "G.3"], "primary_category": "cs.GR"}
{"title": "Energy Matching: Unifying Flow Matching and Energy-Based Models for Generative Modeling", "abstract": "Generative models often map noise to data by matching flows or scores, but\nthese approaches become cumbersome for incorporating partial observations or\nadditional priors. Inspired by recent advances in Wasserstein gradient flows,\nwe propose Energy Matching, a framework that unifies flow-based approaches with\nthe flexibility of energy-based models (EBMs). Far from the data manifold,\nsamples move along curl-free, optimal transport paths from noise to data. As\nthey approach the data manifold, an entropic energy term guides the system into\na Boltzmann equilibrium distribution, explicitly capturing the underlying\nlikelihood structure of the data. We parameterize this dynamic with a single\ntime-independent scalar field, which serves as both a powerful generator and a\nflexible prior for effective regularization of inverse problems. Our method\nsubstantially outperforms existing EBMs on CIFAR-10 generation (FID 3.97\ncompared to 8.61), while retaining the simulation-free training of\ntransport-based approaches away from the data manifold. Additionally, we\nexploit the flexibility of our method and introduce an interaction energy for\ndiverse mode exploration. Our approach focuses on learning a static scalar\npotential energy -- without time conditioning, auxiliary generators, or\nadditional networks -- marking a significant departure from recent EBM methods.\nWe believe this simplified framework significantly advances EBM capabilities\nand paves the way for their broader adoption in generative modeling across\ndiverse domains.", "published": "2025-04-14 18:10:58", "link": "http://arxiv.org/abs/2504.10612v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Beyond Worst-Case Online Classification: VC-Based Regret Bounds for Relaxed Benchmarks", "abstract": "We revisit online binary classification by shifting the focus from competing\nwith the best-in-class binary loss to competing against relaxed benchmarks that\ncapture smoothed notions of optimality. Instead of measuring regret relative to\nthe exact minimal binary error -- a standard approach that leads to worst-case\nbounds tied to the Littlestone dimension -- we consider comparing with\npredictors that are robust to small input perturbations, perform well under\nGaussian smoothing, or maintain a prescribed output margin. Previous examples\nof this were primarily limited to the hinge loss. Our algorithms achieve regret\nguarantees that depend only on the VC dimension and the complexity of the\ninstance space (e.g., metric entropy), and notably, they incur only an\n$O(\\log(1/\\gamma))$ dependence on the generalized margin $\\gamma$. This stands\nin contrast to most existing regret bounds, which typically exhibit a\npolynomial dependence on $1/\\gamma$. We complement this with matching lower\nbounds. Our analysis connects recent ideas from adversarial robustness and\nsmoothed online learning.", "published": "2025-04-14 18:00:23", "link": "http://arxiv.org/abs/2504.10598v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Learning with Positive and Imperfect Unlabeled Data", "abstract": "We study the problem of learning binary classifiers from positive and\nunlabeled data when the unlabeled data distribution is shifted, which we call\nPositive and Imperfect Unlabeled (PIU) Learning. In the absence of covariate\nshifts, i.e., with perfect unlabeled data, Denis (1998) reduced this problem to\nlearning under Massart noise; however, that reduction fails under even slight\nshifts.\n  Our main results on PIU learning are the characterizations of the sample\ncomplexity of PIU learning and a computationally and sample-efficient algorithm\nachieving a misclassification error $\\varepsilon$. We further show that our\nresults lead to new algorithms for several related problems.\n  1. Learning from smooth distributions: We give algorithms that learn\ninteresting concept classes from only positive samples under smooth feature\ndistributions, bypassing known existing impossibility results and contributing\nto recent advances in smoothened learning (Haghtalab et al, J.ACM'24)\n(Chandrasekaran et al., COLT'24).\n  2. Learning with a list of unlabeled distributions: We design new algorithms\nthat apply to a broad class of concept classes under the assumption that we are\ngiven a list of unlabeled distributions, one of which--unknown to the\nlearner--is $O(1)$-close to the true feature distribution.\n  3. Estimation in the presence of unknown truncation: We give the first\npolynomial sample and time algorithm for estimating the parameters of an\nexponential family distribution from samples truncated to an unknown set\napproximable by polynomials in $L_1$-norm. This improves the algorithm by Lee\net al. (FOCS'24) that requires approximation in $L_2$-norm.\n  4. Detecting truncation: We present new algorithms for detecting whether\ngiven samples have been truncated (or not) for a broad class of non-product\ndistributions, including non-product distributions, improving the algorithm by\nDe et al. (STOC'24).", "published": "2025-04-14 17:19:29", "link": "http://arxiv.org/abs/2504.10428v1", "categories": ["stat.ML", "cs.DS", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "$\u03b1$-Flow: A Unified Framework for Continuous-State Discrete Flow Matching Models", "abstract": "Recent efforts have extended the flow-matching framework to discrete\ngenerative modeling. One strand of models directly works with the continuous\nprobabilities instead of discrete tokens, which we colloquially refer to as\nContinuous-State Discrete Flow Matching (CS-DFM). Existing CS-DFM models differ\nsignificantly in their representations and geometric assumptions. This work\npresents a unified framework for CS-DFM models, under which the existing\nvariants can be understood as operating on different $\\alpha$-representations\nof probabilities. Building upon the theory of information geometry, we\nintroduce $\\alpha$-Flow, a family of CS-DFM models that adheres to the\ncanonical $\\alpha$-geometry of the statistical manifold, and demonstrate its\noptimality in minimizing the generalized kinetic energy. Theoretically, we show\nthat the flow matching loss for $\\alpha$-flow establishes a unified variational\nbound for the discrete negative log-likelihood. We comprehensively evaluate\ndifferent instantiations of $\\alpha$-flow on various discrete generation\ndomains to demonstrate their effectiveness in discrete generative modeling,\nincluding intermediate values whose geometries have never been explored before.\n$\\alpha$-flow significantly outperforms its discrete-state counterpart in image\nand protein sequence generation and better captures the entropy in language\nmodeling.", "published": "2025-04-14 14:51:45", "link": "http://arxiv.org/abs/2504.10283v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Adaptive Sensor Steering Strategy Using Deep Reinforcement Learning for Dynamic Data Acquisition in Digital Twins", "abstract": "This paper introduces a sensor steering methodology based on deep\nreinforcement learning to enhance the predictive accuracy and decision support\ncapabilities of digital twins by optimising the data acquisition process.\nTraditional sensor placement techniques are often constrained by one-off\noptimisation strategies, which limit their applicability for online\napplications requiring continuous informative data assimilation. The proposed\napproach addresses this limitation by offering an adaptive framework for sensor\nplacement within the digital twin paradigm. The sensor placement problem is\nformulated as a Markov decision process, enabling the training and deployment\nof an agent capable of dynamically repositioning sensors in response to the\nevolving conditions of the physical structure as represented by the digital\ntwin. This ensures that the digital twin maintains a highly representative and\nreliable connection to its physical counterpart. The proposed framework is\nvalidated through a series of comprehensive case studies involving a cantilever\nplate structure subjected to diverse conditions, including healthy and damaged\nconditions. The results demonstrate the capability of the deep reinforcement\nlearning agent to adaptively reposition sensors improving the quality of data\nacquisition and hence enhancing the overall accuracy of digital twins.", "published": "2025-04-14 14:11:00", "link": "http://arxiv.org/abs/2504.10248v1", "categories": ["stat.ML", "cs.LG", "eess.SP"], "primary_category": "stat.ML"}
{"title": "Kullback-Leibler excess risk bounds for exponential weighted aggregation in Generalized linear models", "abstract": "Aggregation methods have emerged as a powerful and flexible framework in\nstatistical learning, providing unified solutions across diverse problems such\nas regression, classification, and density estimation. In the context of\ngeneralized linear models (GLMs), where responses follow exponential family\ndistributions, aggregation offers an attractive alternative to classical\nparametric modeling. This paper investigates the problem of sparse aggregation\nin GLMs, aiming to approximate the true parameter vector by a sparse linear\ncombination of predictors. We prove that an exponential weighted aggregation\nscheme yields a sharp oracle inequality for the Kullback-Leibler risk with\nleading constant equal to one, while also attaining the minimax-optimal rate of\naggregation. These results are further enhanced by establishing\nhigh-probability bounds on the excess risk.", "published": "2025-04-14 12:25:11", "link": "http://arxiv.org/abs/2504.10171v1", "categories": ["math.ST", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "Challenges in interpretability of additive models", "abstract": "We review generalized additive models as a type of ``transparent'' model that\nhas recently seen renewed interest in the deep learning community as neural\nadditive models. We highlight multiple types of nonidentifiability in this\nmodel class and discuss challenges in interpretability, arguing for restraint\nwhen claiming ``interpretability'' or ``suitability for safety-critical\napplications'' of such models.", "published": "2025-04-14 12:24:17", "link": "http://arxiv.org/abs/2504.10169v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Conditional Distribution Compression via the Kernel Conditional Mean Embedding", "abstract": "Existing distribution compression methods, like Kernel Herding (KH), were\noriginally developed for unlabelled data. However, no existing approach\ndirectly compresses the conditional distribution of labelled data. To address\nthis gap, we first introduce the Average Maximum Conditional Mean Discrepancy\n(AMCMD), a natural metric for comparing conditional distributions. We then\nderive a consistent estimator for the AMCMD and establish its rate of\nconvergence. Next, we make a key observation: in the context of distribution\ncompression, the cost of constructing a compressed set targeting the AMCMD can\nbe reduced from $\\mathcal{O}(n^3)$ to $\\mathcal{O}(n)$. Building on this, we\nextend the idea of KH to develop Average Conditional Kernel Herding (ACKH), a\nlinear-time greedy algorithm that constructs a compressed set targeting the\nAMCMD. To better understand the advantages of directly compressing the\nconditional distribution rather than doing so via the joint distribution, we\nintroduce Joint Kernel Herding (JKH), a straightforward adaptation of KH\ndesigned to compress the joint distribution of labelled data. While herding\nmethods provide a simple and interpretable selection process, they rely on a\ngreedy heuristic. To explore alternative optimisation strategies, we propose\nJoint Kernel Inducing Points (JKIP) and Average Conditional Kernel Inducing\nPoints (ACKIP), which jointly optimise the compressed set while maintaining\nlinear complexity. Experiments show that directly preserving conditional\ndistributions with ACKIP outperforms both joint distribution compression (via\nJKH and JKIP) and the greedy selection used in ACKH. Moreover, we see that JKIP\nconsistently outperforms JKH.", "published": "2025-04-14 11:53:29", "link": "http://arxiv.org/abs/2504.10139v1", "categories": ["stat.ML", "cs.LG", "stat.CO", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Towards Scalable Bayesian Optimization via Gradient-Informed Bayesian Neural Networks", "abstract": "Bayesian optimization (BO) is a widely used method for data-driven\noptimization that generally relies on zeroth-order data of objective function\nto construct probabilistic surrogate models. These surrogates guide the\nexploration-exploitation process toward finding global optimum. While Gaussian\nprocesses (GPs) are commonly employed as surrogates of the unknown objective\nfunction, recent studies have highlighted the potential of Bayesian neural\nnetworks (BNNs) as scalable and flexible alternatives. Moreover, incorporating\ngradient observations into GPs, when available, has been shown to improve BO\nperformance. However, the use of gradients within BNN surrogates remains\nunexplored. By leveraging automatic differentiation, gradient information can\nbe seamlessly integrated into BNN training, resulting in more informative\nsurrogates for BO. We propose a gradient-informed loss function for BNN\ntraining, effectively augmenting function observations with local gradient\ninformation. The effectiveness of this approach is demonstrated on well-known\nbenchmarks in terms of improved BNN predictions and faster BO convergence as\nthe number of decision variables increases.", "published": "2025-04-14 10:21:08", "link": "http://arxiv.org/abs/2504.10076v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Towards Weaker Variance Assumptions for Stochastic Optimization", "abstract": "We revisit a classical assumption for analyzing stochastic gradient\nalgorithms where the squared norm of the stochastic subgradient (or the\nvariance for smooth problems) is allowed to grow as fast as the squared norm of\nthe optimization variable. We contextualize this assumption in view of its\ninception in the 1960s, its seemingly independent appearance in the recent\nliterature, its relationship to weakest-known variance assumptions for\nanalyzing stochastic gradient algorithms, and its relevance in deterministic\nproblems for non-Lipschitz nonsmooth convex optimization. We build on and\nextend a connection recently made between this assumption and the Halpern\niteration. For convex nonsmooth, and potentially stochastic, optimization, we\nanalyze horizon-free, anytime algorithms with last-iterate rates. For problems\nbeyond simple constrained optimization, such as convex problems with functional\nconstraints or regularized convex-concave min-max problems, we obtain rates for\noptimality measures that do not require boundedness of the feasible set.", "published": "2025-04-14 07:26:34", "link": "http://arxiv.org/abs/2504.09951v1", "categories": ["math.OC", "cs.LG", "stat.ML"], "primary_category": "math.OC"}
{"title": "Offline Dynamic Inventory and Pricing Strategy: Addressing Censored and Dependent Demand", "abstract": "In this paper, we study the offline sequential feature-based pricing and\ninventory control problem where the current demand depends on the past demand\nlevels and any demand exceeding the available inventory is lost. Our goal is to\nleverage the offline dataset, consisting of past prices, ordering quantities,\ninventory levels, covariates, and censored sales levels, to estimate the\noptimal pricing and inventory control policy that maximizes long-term profit.\nWhile the underlying dynamic without censoring can be modeled by Markov\ndecision process (MDP), the primary obstacle arises from the observed process\nwhere demand censoring is present, resulting in missing profit information, the\nfailure of the Markov property, and a non-stationary optimal policy. To\novercome these challenges, we first approximate the optimal policy by solving a\nhigh-order MDP characterized by the number of consecutive censoring instances,\nwhich ultimately boils down to solving a specialized Bellman equation tailored\nfor this problem. Inspired by offline reinforcement learning and survival\nanalysis, we propose two novel data-driven algorithms to solving these Bellman\nequations and, thus, estimate the optimal policy. Furthermore, we establish\nfinite sample regret bounds to validate the effectiveness of these algorithms.\nFinally, we conduct numerical experiments to demonstrate the efficacy of our\nalgorithms in estimating the optimal policy. To the best of our knowledge, this\nis the first data-driven approach to learning optimal pricing and inventory\ncontrol policies in a sequential decision-making environment characterized by\ncensored and dependent demand. The implementations of the proposed algorithms\nare available at https://github.com/gundemkorel/Inventory_Pricing_Control", "published": "2025-04-14 02:57:51", "link": "http://arxiv.org/abs/2504.09831v1", "categories": ["stat.ML", "cs.AI", "cs.LG", "math.ST", "stat.AP", "stat.TH", "90B05, 68T05, 90C40, 62N02"], "primary_category": "stat.ML"}
{"title": "Hearing Anywhere in Any Environment", "abstract": "In mixed reality applications, a realistic acoustic experience in spatial\nenvironments is as crucial as the visual experience for achieving true\nimmersion. Despite recent advances in neural approaches for Room Impulse\nResponse (RIR) estimation, most existing methods are limited to the single\nenvironment on which they are trained, lacking the ability to generalize to new\nrooms with different geometries and surface materials. We aim to develop a\nunified model capable of reconstructing the spatial acoustic experience of any\nenvironment with minimum additional measurements. To this end, we present xRIR,\na framework for cross-room RIR prediction. The core of our generalizable\napproach lies in combining a geometric feature extractor, which captures\nspatial context from panorama depth images, with a RIR encoder that extracts\ndetailed acoustic features from only a few reference RIR samples. To evaluate\nour method, we introduce ACOUSTICROOMS, a new dataset featuring high-fidelity\nsimulation of over 300,000 RIRs from 260 rooms. Experiments show that our\nmethod strongly outperforms a series of baselines. Furthermore, we successfully\nperform sim-to-real transfer by evaluating our model on four real-world\nenvironments, demonstrating the generalizability of our approach and the\nrealism of our dataset.", "published": "2025-04-14 22:37:52", "link": "http://arxiv.org/abs/2504.10746v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Will AI shape the way we speak? The emerging sociolinguistic influence of synthetic voices", "abstract": "The growing prevalence of conversational voice interfaces, powered by\ndevelopments in both speech and language technologies, raises important\nquestions about their influence on human communication. While written\ncommunication can signal identity through lexical and stylistic choices,\nvoice-based interactions inherently amplify socioindexical elements - such as\naccent, intonation, and speech style - which more prominently convey social\nidentity and group affiliation. There is evidence that even passive media such\nas television is likely to influence the audience's linguistic patterns. Unlike\npassive media, conversational AI is interactive, creating a more immersive and\nreciprocal dynamic that holds a greater potential to impact how individuals\nspeak in everyday interactions. Such heightened influence can be expected to\narise from phenomena such as acoustic-prosodic entrainment and linguistic\naccommodation, which occur naturally during interaction and enable users to\nadapt their speech patterns in response to the system. While this phenomenon is\nstill emerging, its potential societal impact could provide organisations,\nmovements, and brands with a subtle yet powerful avenue for shaping and\ncontrolling public perception and social identity. We argue that the\nsocioindexical influence of AI-generated speech warrants attention and should\nbecome a focus of interdisciplinary research, leveraging new and existing\nmethodologies and technologies to better understand its implications.", "published": "2025-04-14 19:04:32", "link": "http://arxiv.org/abs/2504.10650v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC", "eess.AS", "I.2.7; K.4.2; H.5.2"], "primary_category": "cs.CY"}
{"title": "Pseudo-Autoregressive Neural Codec Language Models for Efficient Zero-Shot Text-to-Speech Synthesis", "abstract": "Recent zero-shot text-to-speech (TTS) systems face a common dilemma:\nautoregressive (AR) models suffer from slow generation and lack duration\ncontrollability, while non-autoregressive (NAR) models lack temporal modeling\nand typically require complex designs. In this paper, we introduce a novel\npseudo-autoregressive (PAR) codec language modeling approach that unifies AR\nand NAR modeling. Combining explicit temporal modeling from AR with parallel\ngeneration from NAR, PAR generates dynamic-length spans at fixed time steps.\nBuilding on PAR, we propose PALLE, a two-stage TTS system that leverages PAR\nfor initial generation followed by NAR refinement. In the first stage, PAR\nprogressively generates speech tokens along the time dimension, with each step\npredicting all positions in parallel but only retaining the left-most span. In\nthe second stage, low-confidence tokens are iteratively refined in parallel,\nleveraging the global contextual information. Experiments demonstrate that\nPALLE, trained on LibriTTS, outperforms state-of-the-art systems trained on\nlarge-scale data, including F5-TTS, E2-TTS, and MaskGCT, on the LibriSpeech\ntest-clean set in terms of speech quality, speaker similarity, and\nintelligibility, while achieving up to ten times faster inference speed. Audio\nsamples are available at https://anonymous-palle.github.io.", "published": "2025-04-14 16:03:21", "link": "http://arxiv.org/abs/2504.10352v1", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Turn-taking annotation for quantitative and qualitative analyses of conversation", "abstract": "This paper has two goals. First, we present the turn-taking annotation layers\ncreated for 95 minutes of conversational speech of the Graz Corpus of Read and\nSpontaneous Speech (GRASS), available to the scientific community. Second, we\ndescribe the annotation system and the annotation process in more detail, so\nother researchers may use it for their own conversational data. The annotation\nsystem was developed with an interdisciplinary application in mind. It should\nbe based on sequential criteria according to Conversation Analysis, suitable\nfor subsequent phonetic analysis, thus time-aligned annotations were made\nPraat, and it should be suitable for automatic classification, which required\nthe continuous annotation of speech and a label inventory that is not too large\nand results in a high inter-rater agreement. Turn-taking was annotated on two\nlayers, Inter-Pausal Units (IPU) and points of potential completion (PCOMP;\nsimilar to transition relevance places). We provide a detailed description of\nthe annotation process and of segmentation and labelling criteria. A detailed\nanalysis of inter-rater agreement and common confusions shows that agreement\nfor IPU annotation is near-perfect, that agreement for PCOMP annotations is\nsubstantial, and that disagreements often are either partial or can be\nexplained by a different analysis of a sequence which also has merit. The\nannotation system can be applied to a variety of conversational data for\nlinguistic studies and technological applications, and we hope that the\nannotations, as well as the annotation system will contribute to a stronger\ncross-fertilization between these disciplines.", "published": "2025-04-14 08:45:04", "link": "http://arxiv.org/abs/2504.09980v1", "categories": ["cs.CL", "cs.DB", "cs.HC", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Separate to Collaborate: Dual-Stream Diffusion Model for Coordinated Piano Hand Motion Synthesis", "abstract": "Automating the synthesis of coordinated bimanual piano performances poses\nsignificant challenges, particularly in capturing the intricate choreography\nbetween the hands while preserving their distinct kinematic signatures. In this\npaper, we propose a dual-stream neural framework designed to generate\nsynchronized hand gestures for piano playing from audio input, addressing the\ncritical challenge of modeling both hand independence and coordination. Our\nframework introduces two key innovations: (i) a decoupled diffusion-based\ngeneration framework that independently models each hand's motion via\ndual-noise initialization, sampling distinct latent noise for each while\nleveraging a shared positional condition, and (ii) a Hand-Coordinated\nAsymmetric Attention (HCAA) mechanism suppresses symmetric (common-mode) noise\nto highlight asymmetric hand-specific features, while adaptively enhancing\ninter-hand coordination during denoising. The system operates hierarchically:\nit first predicts 3D hand positions from audio features and then generates\njoint angles through position-aware diffusion models, where parallel denoising\nstreams interact via HCAA. Comprehensive evaluations demonstrate that our\nframework outperforms existing state-of-the-art methods across multiple\nmetrics.", "published": "2025-04-14 05:17:41", "link": "http://arxiv.org/abs/2504.09885v1", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multi-Stream Transmission in Cell-Free MIMO Networks with Coherent AP Clustering", "abstract": "This letter proposes a multi-stream selection framework for \\ac{CF-MIMO}\nnetworks. Partially coherent transmission has been considered by clustering\n\\acp{AP} into phase-aligned clusters to address the challenges of phase\nmisalignment and inter-cluster interference. A novel stream selection algorithm\nis developed to dynamically allocate multiple streams to each multi-antenna\n\\ac{UE}, ensuring that the system optimizes the sum rate while minimizing\ninter-cluster and inter-stream interference. Numerical results validate the\neffectiveness of the proposed method in enhancing spectral efficiency and\nfairness in distributed \\ac{CF-MIMO} networks.", "published": "2025-04-14 20:57:20", "link": "http://arxiv.org/abs/2504.10705v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Neyman-Pearson Detector for Ambient Backscatter Zero-Energy-Devices Beacons", "abstract": "Recently, a novel ultra-low power indoor wireless positioning system has been\nproposed. In this system, Zero-Energy-Devices (ZED) beacons are deployed in\nIndoor environments, and located on a map with unique broadcast identifiers.\nThey harvest ambient energy to power themselves and backscatter ambient waves\nfrom cellular networks to send their identifiers. This paper presents a novel\ndetection method for ZEDs in ambient backscatter systems, with an emphasis on\nperformance evaluation through experimental setups and simulations. We\nintroduce a Neyman-Pearson detection framework, which leverages a predefined\nfalse alarm probability to determine the optimal detection threshold. This\nmethod, applied to the analysis of backscatter signals in a controlled testbed\nenvironment, incorporates the use of BC sequences to enhance signal detection\naccuracy. The experimental setup, conducted on the FIT/CorteXlab testbed,\nemploys a two-node configuration for signal transmission and reception. Key\nperformance metrics, which is the peak-to-lobe ratio, is evaluated, confirming\nthe effectiveness of the proposed detection model. The results demonstrate a\ndetection system that effectively handles varying noise levels and identifies\nZEDs with high reliability. The simulation results show the robustness of the\nmodel, highlighting its capacity to achieve desired detection performance even\nwith stringent false alarm thresholds. This work paves the way for robust ZED\ndetection in real-world scenarios, contributing to the advancement of wireless\ncommunication technologies.", "published": "2025-04-14 20:36:48", "link": "http://arxiv.org/abs/2504.10695v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "GPS-Independent Localization Techniques for Disaster Rescue", "abstract": "In this article, we present the limitations of traditional localization\ntechniques, such as those using Global Positioning Systems (GPS) and life\ndetectors, in localizing victims during disaster rescue efforts. These\ntechniques usually fall short in accuracy, coverage, and robustness to\nenvironmental interference. We then discuss the necessary requirements for\ndeveloping GPS-independent localization techniques in disaster scenarios.\nPractical techniques should be passive, with straightforward hardware, low\ncomputational demands, low power, and high accuracy, while incorporating\nunknown environmental information. We review various implementation strategies\nfor these techniques, categorized by measurements (time, angle, and signal\nstrength) and operation manners (non-cooperative and cooperative). Case studies\ndemonstrate trade-offs between localization accuracy and complexity,\nemphasizing the importance of choosing appropriate localization techniques\nbased on resources and rescue needs for efficient disaster response.", "published": "2025-04-14 19:39:50", "link": "http://arxiv.org/abs/2504.10666v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Correcting Domain Shifts in Electric Motor Vibration Data for Unseen Operating Conditions", "abstract": "This paper addresses the problem of domain shifts in electric motor vibration\ndata created by new operating conditions in testing scenarios, focusing on\nbearing fault detection and diagnosis (FDD). The proposed method combines the\nHarmonic Feature Space (HFS) with regression to correct for frequency and\nenergy differentials in steady-state data, enabling accurate FDD on unseen\noperating conditions within the range of the training conditions. The HFS\naligns harmonics across different operating frequencies, while regression\ncompensates for energy variations, preserving the relative magnitude of\nvibrations critical for fault detection. The proposed approach is evaluated on\na detection problem using experimental data from a Belt-Starter Generator (BSG)\nelectric motor, with test conditions having a minimum 1000 RPM and 5 Nm\ndifference from training conditions. Results demonstrate that the method\noutperforms traditional analysis techniques, achieving high classification\naccuracy at a 94% detection rate and effectively reducing domain shifts. The\napproach is computationally efficient, requires only healthy data for training,\nand is well-suited for real-world applications where the exact application\noperating conditions cannot be predetermined.", "published": "2025-04-14 19:22:21", "link": "http://arxiv.org/abs/2504.10661v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Secrecy Rate Maximization with Artificial Noise for Pinching-Antenna Systems", "abstract": "Security is emerging as a critical performance metric for next-generation\nwireless networks, but conventional multiple-input-multiple-output (MIMO)\nsystems often suffer from severe path loss and are vulnerable to nearby\neavesdroppers due to their fixed-antenna configurations. Pinching-antenna\nsystems (PAS) offer a promising alternative, leveraging reconfigurable pinching\nantennas (PAs) positioned along low-loss dielectric waveguides to enhance\nchannel conditions and dynamically mitigate security threats. In this paper, we\npropose an artificial noise (AN)-based beamforming scheme for downlink\ntransmissions in PAS, with the goal of maximizing the secrecy rate. A\nclosed-form solution is derived for the single-waveguide scenario, while an\nalternating optimization approach addresses more complex multiple waveguide\nsetups. Numerical results show that the proposed scheme significantly\noutperforms conventional MIMO and existing PAS security schemes.", "published": "2025-04-14 19:14:21", "link": "http://arxiv.org/abs/2504.10656v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Rotatable Antenna-Enabled Secure Wireless Communication", "abstract": "Rotatable antenna (RA) is a promising technology that exploits new spatial\ndegrees of freedom (DoFs) to improve wireless communication and sensing\nperformance. In this letter, we investigate an RA-enabled secure communication\nsystem where confidential information is transmitted from an RA-based access\npoint (AP) to a single-antenna legitimate user in the presence of multiple\neavesdroppers. We aim to maximize the achievable secrecy rate by jointly\noptimizing the transmit beamforming and the deflection angles of all RAs.\nAccordingly, we propose an efficient alternating optimization (AO) algorithm to\nobtain a high-quality suboptimal solution in an iterative manner, where the\ngeneralized Rayleigh quotient-based beamforming is applied and the RAs'\ndeflection angles are optimized by the successive convex approximation (SCA).\nSimulation results show that the proposed RA-enabled secure communication\nsystem achieves significant improvement in achievable secrecy rate as compared\nto various benchmark schemes.", "published": "2025-04-14 17:55:27", "link": "http://arxiv.org/abs/2504.10473v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Pinching-Antenna System (PASS) Enhanced Covert Communications", "abstract": "A Pinching-Antenna SyStem (PASS)-assisted convert communication framework is\nproposed. PASS utilizes dielectric waveguides with freely positioned pinching\nantennas (PAs) to establish strong line-of-sight links. Capitalizing on this\nhigh reconfigurable flexibility of antennas, the potential of PASS for covert\ncommunications is investigated. 1)~For the single-waveguide single-PA (SWSP)\nscenario, a closed-form optimal PA position that maximizes the covert rate is\nfirst derived. Subsequently, a one-dimensional power search is employed to\nenable low-complexity optimization for covert communications. With antenna\nmobility on a scale of meters, PASS can deal with the challenging situation of\nthe eavesdropper enjoying better channel conditions than the legal user. 2)~For\nthe multi-waveguide multi-PA (MWMP) scenario, the positions of multiple PAs are\noptimized to enable effective pinching beamforming, thereby enhancing the\ncovert rate. To address the resultant multimodal joint transmit and pinching\nbeamforming problem, a twin particle swarm optimization (TwinPSO) approach is\nproposed. Numerical results demonstrate that: i)~the proposed approaches can\neffectively resolve the optimization problems; ii)~PASS achieves a higher\ncovert rate than conventional fixed-position antenna architectures; and\niii)~with enhanced flexibility, the MWMP setup outperforms the SWSP\ncounterpart.", "published": "2025-04-14 17:32:54", "link": "http://arxiv.org/abs/2504.10442v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "The Communication and Computation Trade-off in Wireless Semantic Communications", "abstract": "Semantic communications have emerged as a crucial research direction for\nfuture wireless communication networks. However, as wireless systems become\nincreasingly complex, the demands for computation and communication resources\nin semantic communications continue to grow rapidly. This paper investigates\nthe trade-off between computation and communication in wireless semantic\ncommunications, taking into consideration transmission task delay and\nperformance constraints within the semantic communication framework. We propose\na novel tradeoff metric to analyze the balance between computation and\ncommunication in semantic transmissions and employ the deep reinforcement\nlearning (DRL) algorithm to minimize this metric, thereby reducing the cost\nassociated with balancing computation and communication. Through simulations,\nwe analyze the tradeoff between computation and communication and demonstrate\nthe effectiveness of optimizing this trade-off metric.", "published": "2025-04-14 16:06:20", "link": "http://arxiv.org/abs/2504.10357v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Tx and Rx IQ Imbalance Compensation for JCAS in 5G NR", "abstract": "Beside traditional communications, joint communications and sensing (JCAS) is\ngaining increasing relevance as a key enabler for next-generation wireless\nsystems. The ability to accurately transmit and receive data is the basis for\nhigh-speed communications and precise sensing, where a fundamental requirement\nis an accurate in-phase (I) and quadrature-phase (Q) modulation. For sensing,\nimperfections in IQ modulation lead to two critical issues in the\nrange-Doppler-map (RDM) in form of an increased noise floor and the presence of\nghost objects, degrading the accuracy and reliability of the information in the\nRDM. This paper presents a low-complex estimation and compensation method to\nmitigate the IQ imbalance effects. This is achieved by utilizing, amongst\nothers, the leakage signal, which is the direct signal from the transmitter to\nthe receiver path, and is typically the strongest signal component in the RDM.\nThe parameters of the IQ imbalance suppression structure are estimated based on\na mixed complex-/real-valued bilinear filter approach, that considers IQ\nimbalance in the transmitter and the receiver of the JCAS-capable user\nequipment (UE). The UE uses a 5G New Radio (NR)-compliant orthogonal\nfrequency-division multiplexing (OFDM) waveform with the system configuration\nassumed to be predefined from the communication side. To assess the\neffectiveness of the proposed approach, simulations are conducted, illustrating\nthe performance in the suppression of IQ imbalance introduced distortions in\nthe RDM.", "published": "2025-04-14 14:38:41", "link": "http://arxiv.org/abs/2504.10272v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Simulation and Experimental Validation of Optical Camera Communication", "abstract": "While simulation tools for visible light communication (VLC) with photo\ndetectors (PDs) have been widely investigated, similar tools for optical camera\ncommunication (OCC) with complementary metal oxide semiconductor (CMOS) sensors\nare lacking in this regard. Camera based VLC systems have much lower data rates\nowing to camera exposure times. Among the few extant OCC simulation tools, none\nallow for simulation of images when exposure time is greater than the signal\nperiod. An accurate simulation of the OCC system can be used to improve the\ndata rate and quality of performance. We propose a simple simulation technique\nfor OCC which allows to test for system performance at frequencies beyond the\ncamera shutter speed. This will allow much needed data rate improvement by\noperating at the actual frequency a decoding algorithm ceases detection instead\nof the exposure limit used now. We have tested the accuracy of simulation by\ncomparing the detection success rates of simulated images with experimental\nimages. The proposed simulation technique was shown to be accurate through\nexperimental validation for two different cameras.", "published": "2025-04-14 13:45:09", "link": "http://arxiv.org/abs/2504.10224v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Uncertainty Propagation in the Fast Fourier Transform", "abstract": "We address the problem of uncertainty propagation in the discrete Fourier\ntransform by modeling the fast Fourier transform as a factor graph. Building on\nthis representation, we propose an efficient framework for approximate Bayesian\ninference using belief propagation (BP) and expectation propagation, extending\nits applicability beyond Gaussian assumptions. By leveraging an appropriate BP\nmessage representation and a suitable schedule, our method achieves stable\nconvergence with accurate mean and variance estimates. Numerical experiments in\nrepresentative scenarios from communications demonstrate the practical\npotential of the proposed framework for uncertainty-aware inference in\nprobabilistic systems operating across both time and frequency domain.", "published": "2025-04-14 11:47:42", "link": "http://arxiv.org/abs/2504.10136v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Joint Localization and Synchronization in Downlink Distributed MIMO", "abstract": "We investigate joint localization and synchronization in the downlink of a\ndistributed multiple-input-multiple-output (D-MIMO) system, aiming to estimate\nthe position and phase offset of a single-antenna user equipment (UE) using\ndownlink transmissions of multiple phase-synchronized, multi-antenna access\npoints (APs). We propose two transmission protocols: sequential (P1) and\nsimultaneous (P2) AP transmissions, together with the ML estimators that either\nleverage (coherent estimator) or disregard phase information (non-coherent\nestimator). Simulation results reveal that downlink D-MIMO holds significant\npotential for high-accuracy localization while showing that P2 provides\nsuperior localization performance and reduced transmission latency.", "published": "2025-04-14 10:47:05", "link": "http://arxiv.org/abs/2504.10087v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Parametric Near-Field MMSE Channel Estimation for sub-THz XL-MIMO Systems", "abstract": "Accurate channel estimation is essential for reliable communication in\nsub-THz extremely large (XL) MIMO systems. Deploying XL-MIMO in high-frequency\nbands not only increases the number of antennas, but also fundamentally alters\nchannel propagation characteristics, placing the user equipments (UE) in the\nradiative near-field of the base station. This paper proposes a parametric\nestimation method using the multiple signal classification (MUSIC) algorithm to\nextract UE location data from uplink pilot signals. These parameters are used\nto reconstruct the spatial correlation matrix, followed by an approximation of\nthe minimum mean square error (MMSE) channel estimator. Numerical results show\nthat the proposed method outperforms the least-squares (LS) estimator in terms\nof the normalized mean-square error (NMSE), even without prior UE location\nknowledge.", "published": "2025-04-14 10:08:15", "link": "http://arxiv.org/abs/2504.10064v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Learning to Beamform for Cooperative Localization and Communication: A Link Heterogeneous GNN-Based Approach", "abstract": "Integrated sensing and communication (ISAC) has emerged as a key enabler for\nnext-generation wireless networks, supporting advanced applications such as\nhigh-precision localization and environment reconstruction. Cooperative ISAC\n(CoISAC) further enhances these capabilities by enabling multiple base stations\n(BSs) to jointly optimize communication and sensing performance through\ncoordination. However, CoISAC beamforming design faces significant challenges\ndue to system heterogeneity, large-scale problem complexity, and sensitivity to\nparameter estimation errors. Traditional deep learning-based techniques fail to\nexploit the unique structural characteristics of CoISAC systems, thereby\nlimiting their ability to enhance system performance. To address these\nchallenges, we propose a Link-Heterogeneous Graph Neural Network (LHGNN) for\njoint beamforming in CoISAC systems. Unlike conventional approaches, LHGNN\nmodels communication and sensing links as heterogeneous nodes and their\ninteractions as edges, enabling the capture of the heterogeneous nature and\nintricate interactions of CoISAC systems. Furthermore, a graph attention\nmechanism is incorporated to dynamically adjust node and link importance,\nimproving robustness to channel and position estimation errors. Numerical\nresults demonstrate that the proposed attention-enhanced LHGNN achieves\nsuperior communication rates while maintaining sensing accuracy under power\nconstraints. The proposed method also exhibits strong robustness to\ncommunication channel and position estimation error.", "published": "2025-04-14 10:03:12", "link": "http://arxiv.org/abs/2504.10060v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Uniform Planar Array Based Weighted Cooperative Spectrum Sensing for Cognitive Radio Networks", "abstract": "Cooperative spectrum sensing (CSS) is essential for improving the spectrum\nefficiency and reliability of cognitive radio applications. Next-generation\nwireless communication networks increasingly employ uniform planar arrays (UPA)\ndue to their ability to steer beamformers towards desired directions,\nmitigating interference and eavesdropping. However, the application of\nUPA-based CSS in cognitive radio remains largely unexplored. This paper\nproposes a multi-beam UPA-based weighted CSS (WCSS) framework to enhance\ndetection reliability, applicable to various cognitive radio networks,\nincluding cellular, vehicular, and satellite communications. We first propose a\nweighting factor for commonly used energy detection (ED) and eigenvalue\ndetection (EVD) techniques, based on the spatial variation of signal strengths\nresulting from UPA antenna beamforming. We then analytically characterize the\nperformance of both weighted ED and weighted EVD by deriving closed-form\nexpressions for false alarm and detection probabilities. Our numerical results,\nconsidering both static and dynamic user behaviors, demonstrate the superiority\nof WCSS in enhancing sensing performance compared to uniformly weighted\ndetectors.", "published": "2025-04-14 09:36:56", "link": "http://arxiv.org/abs/2504.10034v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Diversity Analysis for Indoor Terahertz Communication Systems under Small-Scale Fading", "abstract": "Harnessing diversity is fundamental to wireless communication systems,\nparticularly in the terahertz (THz) band, where severe path loss and\nsmall-scale fading pose significant challenges to system reliability and\nperformance. In this paper, we present a comprehensive diversity analysis for\nindoor THz communication systems, accounting for the combined effects of path\nloss and small-scale fading, with the latter modeled as an $\\alpha-\\mu$\ndistribution to reflect THz indoor channel conditions. We derive closed-form\nexpressions for the bit error rate (BER) as a function of the reciprocal of the\nsignal-to-noise ratio (SNR) and propose an asymptotic expression. Furthermore,\nwe validate these expressions through extensive simulations, which show strong\nagreement with the theoretical analysis, confirming the accuracy and robustness\nof the proposed methods. Our results show that the diversity order in THz\nsystems is primarily determined by the combined effects of the number of\nindependent paths, the severity of fading, and the degree of channel frequency\nselectivity, providing clear insights into how diversity gains can be optimized\nin high-frequency wireless networks.", "published": "2025-04-14 08:51:52", "link": "http://arxiv.org/abs/2504.09986v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Fully-Adaptive and Semi-Adaptive Frequency Sweep Algorithm Exploiting Loewner-State Model for EM Simulation of Multiport Systems", "abstract": "This paper employs a fully adaptive and semi-adaptive frequency sweep\nalgorithm using the Loewner matrix-based state model for the electromagnetic\nsimulation. The proposed algorithms use two Loewner matrix models with\ndifferent or the same orders with small frequency perturbation for adaptive\nfrequency selection. The error between the two models is calculated in each\niteration, and the next frequency points are selected to minimize maximum\nerror. With the help of memory, the algorithm terminates when the error between\nthe model and the simulation result is reached within the specified error\ntolerance. In the fully adaptive frequency sweep algorithm, the method starts\nwith the minimum and maximum frequency of simulation. In the semi-adaptive\nalgorithm, a novel approach has been proposed to determine the initial number\nof frequency points necessary for system interpolation based on the electrical\nsize of the structure. The proposed algorithms have been compared with the\nStoer-Bulirsch algorithm and Pradovera's minimal sampling algorithm for\nelectromagnetic simulation. Four examples are presented using MATLAB R2024b.\nThe results show that the proposed methods offer better performance in terms of\nspeed, accuracy and the requirement of the minimum number of frequency samples.\nThe proposed method shows remarkable consistency with full-wave simulation\ndata, and the algorithm can be effectively applicable to electromagnetic\nsimulations.", "published": "2025-04-14 07:05:14", "link": "http://arxiv.org/abs/2504.09942v1", "categories": ["eess.SP", "cs.SY", "eess.SY", "03C40, 32E30", "G.1.1"], "primary_category": "eess.SP"}
{"title": "Parameter Convergence Detector Based on VAMP Deep Unfolding: A Novel Radar Constant False Alarm Rate Detection Algorithm", "abstract": "The sub-Nyquist radar framework exploits the sparsity of signals, which\neffectively alleviates the pressure on system storage and transmission\nbandwidth. Compressed sensing (CS) algorithms, such as the VAMP algorithm, are\nused for sparse signal processing in the sub-Nyquist radar framework. By\ncombining deep unfolding techniques with VAMP, faster convergence and higher\naccuracy than traditional CS algorithms are achieved. However, deep unfolding\ndisrupts the parameter constrains in traditional VAMP algorithm, leading to the\ndistribution of non-sparse noisy estimation in VAMP deep unfolding unknown, and\nits distribution parameter unable to be obtained directly using method of\ntraditional VAMP, which prevents the application of VAMP deep unfolding in\nradar constant false alarm rate (CFAR) detection. To address this problem, we\nexplore the distribution of the non-sparse noisy estimation and propose a\nparameter convergence detector (PCD) to achieve CFAR detection based on VAMP\ndeep unfolding. Compared to the state-of-the-art methods, PCD leverages not\nonly the sparse solution, but also the non-sparse noisy estimation, which is\nused to iteratively estimate the distribution parameter and served as the test\nstatistic in detection process. In this way, the proposed algorithm takes\nadvantage of both the enhanced sparse recovery accuracy from deep unfolding and\nthe distribution property of VAMP, thereby achieving superior CFAR detection\nperformance. Additionally, the PCD requires no information about the power of\nAWGN in the environment, which is more suitable for practical application. The\nconvergence performance and effectiveness of the proposed PCD are analyzed\nbased on the Banach Fixed-Point Theorem. Numerical simulations and practical\ndata experiments demonstrate that PCD can achieve better false alarm control\nand target detection performance.", "published": "2025-04-14 06:18:11", "link": "http://arxiv.org/abs/2504.09912v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Novel Radar Constant False Alarm Rate Detection Algorithm Based on VAMP Deep Unfolding", "abstract": "The combination of deep unfolding with vector approximate message passing\n(VAMP) algorithm, results in faster convergence and higher sparse recovery\naccuracy than traditional compressive sensing approaches. However, deep\nunfolding alters the parameters in traditional VAMP algorithm, resulting in the\nunattainable distribution parameter of the recovery error of non-sparse noisy\nestimation via traditional VAMP, which hinders the utilization of VAMP deep\nunfolding in constant false alarm rate (CFAR) detection in sub-Nyquist radar\nsystem. Based on VAMP deep unfolding, we provide a parameter convergence\ndetector (PCD) to estimate the recovery error distribution parameter and\nimplement CFAR detection. Compared to the state-of-the-art approaches, both the\nsparse solution and non-sparse noisy estimation are utilized to estimate the\ndistribution parameter and implement CFAR detection in PCD, which leverages\nboth the VAMP distribution property and the improved sparse recovery accuracy\nprovided by deep unfolding. Simulation results indicate that PCD offers\nimproved false alarm rate control performance and higher target detection rate.", "published": "2025-04-14 06:06:20", "link": "http://arxiv.org/abs/2504.09907v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Fusing Bluetooth with Pedestrian Dead Reckoning: A Floor Plan-Assisted Positioning Approach", "abstract": "Floor plans can provide valuable prior information that helps enhance the\naccuracy of indoor positioning systems. However, existing research typically\nfaces challenges in efficiently leveraging floor plan information and applying\nit to complex indoor layouts. To fully exploit information from floor plans for\npositioning, we propose a floor plan-assisted fusion positioning algorithm\n(FP-BP) using Bluetooth low energy (BLE) and pedestrian dead reckoning (PDR).\nIn the considered system, a user holding a smartphone walks through a\npositioning area with BLE beacons installed on the ceiling, and can locate\nhimself in real time. In particular, FP-BP consists of two phases. In the\noffline phase, FP-BP programmatically extracts map features from a stylized\nfloor plan based on their binary masks, and constructs a mapping function to\nidentify the corresponding map feature of any given position on the map. In the\nonline phase, FP-BP continuously computes BLE positions and PDR results from\nBLE signals and smartphone sensors, where a novel grid-based maximum likelihood\nestimation (GML) algorithm is introduced to enhance BLE positioning. Then, a\nparticle filter is used to fuse them and obtain an initial estimate. Finally,\nFP-BP performs post-position correction to obtain the final position based on\nits specific map feature. Experimental results show that FP-BP can achieve a\nreal-time mean positioning accuracy of 1.19 m, representing an improvement of\nover 28% compared to existing floor plan-fused baseline algorithms.", "published": "2025-04-14 06:00:39", "link": "http://arxiv.org/abs/2504.09905v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Modelling & Steady State Compliance Testing of an Improved Time Synchronized Phasor Measurement Unit Based on IEEE Standard C37.118.1", "abstract": "Synchrophasor technology is an emerging and developing technology for\nmonitoring and control of wide area measurement systems (WAMS). In an\nelementary WAMS, two identical phasors measured at two different locations have\ndifference in the phase angles measured since their reference waveforms are not\nsynchronized with each other. Phasor measurement units (PMUs) measure input\nphasors with respect to a common reference wave based on the atomic clock\npulses received from global positioning system (GPS) satellites, eliminating\nvariation in the measured phase angles due to distant locations of the\nmeasurement nodes. This has found tremendous applications in quick fault\ndetection, fault location analysis, accurate current, voltage, frequency and\nphase angle measurements in WAMS. Commercially available PMU models are often\nproven to be expensive for research and development as well as for grid\nintegration projects. This research article proposes an economic PMU model\noptimized for accurate steadystate performance based on recursive discrete\nFourier transform (DFT) and provides results and detailed analysis of the\nproposed PMU model as per the steady state compliance specifications of IEEE\nstandard C37.118.1. Results accurate up to 13 digits after decimal point are\nobtained through the developed PMU model for both nominal and off-nominal\nfrequency inputs in steady state.", "published": "2025-04-14 05:13:34", "link": "http://arxiv.org/abs/2504.09883v1", "categories": ["eess.SP", "cs.SY", "eess.SY", "physics.soc-ph"], "primary_category": "eess.SP"}
{"title": "CKMImageNet: A Dataset for AI-Based Channel Knowledge Map Towards Environment-Aware Communication and Sensing", "abstract": "With the increasing demand for real-time channel state information (CSI) in\nsixth-generation (6G) mobile communication networks, channel knowledge map\n(CKM) emerges as a promising technique, offering a site-specific database that\nenables environment-awareness and significantly enhances communication and\nsensing performance by leveraging a priori wireless channel knowledge. However,\nefficient construction and utilization of CKMs require high-quality, massive,\nand location-specific channel knowledge data that accurately reflects the\nreal-world environments. Inspired by the great success of ImageNet dataset in\nadvancing computer vision and image understanding in artificial intelligence\n(AI) community, we introduce CKMImageNet, a dataset developed to bridge AI and\nenvironment-aware wireless communications and sensing by integrating\nlocation-specific channel knowledge data, high-fidelity environmental maps, and\ntheir visual representations. CKMImageNet supports a wide range of AI-driven\napproaches for CKM construction with spatially consistent and location-specific\nchannel knowledge data, including both supervised and unsupervised, as well as\ndiscriminative and generative AI methods.", "published": "2025-04-14 03:40:35", "link": "http://arxiv.org/abs/2504.09849v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Research and Experimental Validation for 3GPP ISAC Channel Modeling Standardization", "abstract": "Integrated Sensing and Communication (ISAC) is considered a key technology in\n6G networks. An accurate sensing channel model is crucial for the design and\nsensing performance evaluation of ISAC systems. The widely used Geometry-Based\nStochastic Model (GBSM), typically applied in standardized channel modeling,\nmainly focuses on the statistical fading characteristics of the channel.\nHowever, it fails to capture the characteristics of targets in ISAC systems,\nsuch as their positions and velocities, as well as the impact of the targets on\nthe background. To address this issue, this paper proposes an extended GBSM\n(E-GBSM) sensing channel model that incorporates newly discovered channel\ncharacteristics into a unified modeling framework. In this framework, the\nsensing channel is divided into target and background channels. For the target\nchannel, the model introduces a concatenated modeling approach, while for the\nbackground channel, a parameter called the power control factor is introduced\nto assess impact of the target on the background channel, making the modeling\nframework applicable to both mono-static and bi-static sensing modes. To\nvalidate the proposed model's effectiveness, measurements of target and\nbackground channels are conducted in both indoor and outdoor scenarios,\ncovering various sensing targets such as metal plates, reconfigurable\nintelligent surfaces, human bodies, UAVs, and vehicles. The experimental\nresults provide important theoretical support and empirical data for the\nstandardization of ISAC channel modeling.", "published": "2025-04-14 01:59:35", "link": "http://arxiv.org/abs/2504.09799v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Rotatable Antenna-Enabled Secure Wireless Communication", "abstract": "Rotatable antenna (RA) is a promising technology that exploits new spatial\ndegrees of freedom (DoFs) to improve wireless communication and sensing\nperformance. In this letter, we investigate an RA-enabled secure communication\nsystem where confidential information is transmitted from an RA-based access\npoint (AP) to a single-antenna legitimate user in the presence of multiple\neavesdroppers. We aim to maximize the achievable secrecy rate by jointly\noptimizing the transmit beamforming and the deflection angles of all RAs.\nAccordingly, we propose an efficient alternating optimization (AO) algorithm to\nobtain a high-quality suboptimal solution in an iterative manner, where the\ngeneralized Rayleigh quotient-based beamforming is applied and the RAs'\ndeflection angles are optimized by the successive convex approximation (SCA)\ntechnique. Simulation results show that the proposed RA-enabled secure\ncommunication system achieves significant improvement in achievable secrecy\nrate as compared to various benchmark schemes.", "published": "2025-04-14 17:55:27", "link": "http://arxiv.org/abs/2504.10473v3", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Fusing Bluetooth with Pedestrian Dead Reckoning: A Floor Plan-Assisted Positioning Approach", "abstract": "Floor plans can provide valuable prior information that helps enhance the\naccuracy of indoor positioning systems. However, existing research typically\nfaces challenges in efficiently leveraging floor plan information and applying\nit to complex indoor layouts. To fully exploit information from floor plans for\npositioning, we propose a floor plan-assisted fusion positioning algorithm\n(FP-BP) using Bluetooth low energy (BLE) and pedestrian dead reckoning (PDR).\nIn the considered system, a user holding a smartphone walks through a\npositioning area with BLE beacons installed on the ceiling, and can locate\nhimself in real time. In particular, FP-BP consists of two phases. In the\noffline phase, FP-BP programmatically extracts map features from a stylized\nfloor plan based on their binary masks, and constructs a mapping function to\nidentify the corresponding map feature of any given position on the map. In the\nonline phase, FP-BP continuously computes BLE positions and PDR results from\nBLE signals and smartphone sensors, where a novel grid-based maximum likelihood\nestimation (GML) algorithm is introduced to enhance BLE positioning. Then, a\nparticle filter is used to fuse them and obtain an initial estimate. Finally,\nFP-BP performs post-position correction to obtain the final position based on\nits specific map feature. Experimental results show that FP-BP can achieve a\nreal-time mean positioning accuracy of 1.19 m, representing an improvement of\nover 28% compared to existing floor plan-fused baseline algorithms.", "published": "2025-04-14 06:00:39", "link": "http://arxiv.org/abs/2504.09905v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "HistLLM: A Unified Framework for LLM-Based Multimodal Recommendation with User History Encoding and Compression", "abstract": "While large language models (LLMs) have proven effective in leveraging\ntextual data for recommendations, their application to multimodal\nrecommendation tasks remains relatively underexplored. Although LLMs can\nprocess multimodal information through projection functions that map visual\nfeatures into their semantic space, recommendation tasks often require\nrepresenting users' history interactions through lengthy prompts combining text\nand visual elements, which not only hampers training and inference efficiency\nbut also makes it difficult for the model to accurately capture user\npreferences from complex and extended prompts, leading to reduced\nrecommendation performance. To address this challenge, we introduce HistLLM, an\ninnovative multimodal recommendation framework that integrates textual and\nvisual features through a User History Encoding Module (UHEM), compressing\nmultimodal user history interactions into a single token representation,\neffectively facilitating LLMs in processing user preferences. Extensive\nexperiments demonstrate the effectiveness and efficiency of our proposed\nmechanism.", "published": "2025-04-14 12:01:11", "link": "http://arxiv.org/abs/2504.10150v2", "categories": ["cs.IR", "cs.MM"], "primary_category": "cs.IR"}
{"title": "Code size constraints in b-symbol read channels: A bound analysis", "abstract": "In classical coding theory, error-correcting codes are designed to protect\nagainst errors occurring at individual symbol positions in a codeword. However,\nin practical storage and communication systems, errors often affect multiple\nadjacent symbols rather than single symbols independently. To address this,\nsymbol-pair read channels were introduced \\cite{Yuval2011}, and later\ngeneralized to $b$-symbol read channels \\cite{yaakobi2016} to better model such\nerror patterns. $b$-Symbol read channels generalize symbol-pair read channels\nto account for clustered errors in modern storage and communication systems. By\ndeveloping bounds and efficient codes, researchers improve data reliability in\napplications such as storage devices, wireless networks, and DNA-based storage.\nGiven integers $q$, $n$, $d$, and $b \\geq 2$, let $A_b(n,d,q)$ denote the\nlargest possible code size for which there exists a $q$-ary code of length $n$\nwith minimum $b$-symbol distance at least $d$. In \\cite{chen2022}, various\nupper and lower bounds on $A_b(n,d,q)$ are given for $b=2$. In this paper, we\ngeneralize some of these bounds to the $b$-symbol read channels for $b>2$ and\npresent several new bounds on $A_b(n,d,q)$. In particular, we establish the\nlinear programming bound, a recurrence relation on $A_b(n,d,q)$, the Johnson\nbound (even), the restricted Johnson bound, the Gilbert-Varshamov-type bound,\nand the Elias bound for the metric of symbols $b$, $b\\geq 2$. Furthermore, we\nprovide examples demonstrating that the Gilbert-Varshamov bound we establish\noffers a stronger lower bound than the one presented in \\cite{Song2018}.\nAdditionally, we introduce an alternative approach to deriving the\nSphere-packing and Plotkin bounds.", "published": "2025-04-14 10:47:31", "link": "http://arxiv.org/abs/2504.10088v2", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Active Reconfigurable Intelligent Surface Assisted MIMO: Electromagnetic-Compliant Modeling with Mutual Coupling", "abstract": "Reconfigurable Intelligent Surfaces (RIS) represent a transformative\ntechnology for sixth-generation (6G) wireless communications, but it suffers\nfrom a significant limitation, namely the double-fading attenuation. Active RIS\nhas emerged as a promising solution, effectively mitigating the attenuation\nissues associated with conventional RIS-assisted systems. However, the current\nacademic work on active RIS focuses on the system-level optimization of active\nRIS, often overlooking the development of models that are compatible with its\nelectromagnetic (EM) and physical properties. The challenge of constructing\nrealistic, EM-compliant models for active RIS-assisted communication, as well\nas understanding their implications on system-level optimization, remains an\nopen research area. To tackle these problems, in this paper we develop a novel\nEM-compliant model with mutual coupling (MC) for active RIS-assisted wireless\nsystems by integrating the developed scattering-parameter ($S$-parameter) based\nactive RIS framework with multiport network theory, which facilitates\nsystem-level analysis and optimization. To evaluate the performance of the\nEM-compliant active RIS model, we design the joint optimization scheme based on\nthe transmit beamforming at the transmitter and the reflection coefficient at\nthe active RIS to maximize the achievable rate of EM-compliant active\nRIS-assisted MIMO system. To tackle the inherent non-convexity of this problem,\nwe employ the Sherman-Morrison inversion and Neumann series (SMaN)-based\nalternating optimization (AO) algorithm. Simulation results verified that EM\nproperty (i.e., MC effect) is an indispensable factor in the optimization\nprocess of MIMO systems. Neglecting this effect introduces a substantial\nperformance gap, highlighting its significance in the more pronounced the MC\neffect is, the greater the gap in achievable rates.", "published": "2025-04-14 03:34:11", "link": "http://arxiv.org/abs/2504.15961v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Predictive AI with External Knowledge Infusion for Stocks", "abstract": "Fluctuations in stock prices are influenced by a complex interplay of factors\nthat go beyond mere historical data. These factors, themselves influenced by\nexternal forces, encompass inter-stock dynamics, broader economic factors,\nvarious government policy decisions, outbreaks of wars, etc. Furthermore, all\nof these factors are dynamic and exhibit changes over time. In this paper, for\nthe first time, we tackle the forecasting problem under external influence by\nproposing learning mechanisms that not only learn from historical trends but\nalso incorporate external knowledge from temporal knowledge graphs. Since there\nare no such datasets or temporal knowledge graphs available, we study this\nproblem with stock market data, and we construct comprehensive temporal\nknowledge graph datasets. In our proposed approach, we model relations on\nexternal temporal knowledge graphs as events of a Hawkes process on graphs.\nWith extensive experiments, we show that learned dynamic representations\neffectively rank stocks based on returns across multiple holding periods,\noutperforming related baselines on relevant metrics.", "published": "2025-04-14 14:15:48", "link": "http://arxiv.org/abs/2504.20058v1", "categories": ["q-fin.ST", "cs.LG"], "primary_category": "q-fin.ST"}
{"title": "Token Sliding Reconfiguration on DAGs", "abstract": "Given a graph $G$ and two independent sets of same size, the Independent Set\nReconfiguration Problem under token sliding ask whether one can, in a step by\nstep manner, transform the first independent set into the second one. In each\nstep we must preserve the condition of independence. Further, referring to\nsolution vertices as tokens, we are only permitted to slide a token along an\nedge. Until the recent work of Ito et al. [Ito et al. MFCS 2022] this problem\nwas only considered on undirected graphs. In this work, we study\nreconfiguration under token sliding focusing on DAGs.\n  We present a complete dichotomy of intractability in regard to the depth of\nthe DAG, by proving that this problem is NP-complete for DAGs of depth 3 and\n$\\textrm{W}[1]$-hard for depth 4 when parameterized by the number of tokens\n$k$, and that these bounds are tight. Further, we prove that it is fixed\nparameter tractable on DAGs parameterized by the combination of treewidth and\n$k$. We show that this result applies to undirected graphs, when the number of\ntimes a token can visit a vertex is restricted.", "published": "2025-04-14 19:47:36", "link": "http://arxiv.org/abs/2504.10671v2", "categories": ["cs.DM"], "primary_category": "cs.DM"}
