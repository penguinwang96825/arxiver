{"title": "Bilingual Document Alignment with Latent Semantic Indexing", "abstract": "We apply cross-lingual Latent Semantic Indexing to the Bilingual Document\nAlignment Task at WMT16. Reduced-rank singular value decomposition of a\nbilingual term-document matrix derived from known English/French page pairs in\nthe training data allows us to map monolingual documents into a joint semantic\nspace. Two variants of cosine similarity between the vectors that place each\ndocument into the joint semantic space are combined with a measure of string\nsimilarity between corresponding URLs to produce 1:1 alignments of\nEnglish/French web pages in a variety of domains. The system achieves a recall\nof ca. 88% if no in-domain data is used for building the latent semantic model,\nand 93% if such data is included.\n  Analysing the system's errors on the training data, we argue that evaluating\naligner performance based on exact URL matches under-estimates their true\nperformance and propose an alternative that is able to account for duplicates\nand near-duplicates in the underlying data.", "published": "2017-07-29 00:46:23", "link": "http://arxiv.org/abs/1707.09443v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sentiment Analysis on Financial News Headlines using Training Dataset\n  Augmentation", "abstract": "This paper discusses the approach taken by the UWaterloo team to arrive at a\nsolution for the Fine-Grained Sentiment Analysis problem posed by Task 5 of\nSemEval 2017. The paper describes the document vectorization and sentiment\nscore prediction techniques used, as well as the design and implementation\ndecisions taken while building the system for this task. The system uses text\nvectorization models, such as N-gram, TF-IDF and paragraph embeddings, coupled\nwith regression model variants to predict the sentiment scores. Amongst the\nmethods examined, unigrams and bigrams coupled with simple linear regression\nobtained the best baseline accuracy. The paper also explores data augmentation\nmethods to supplement the training dataset. This system was designed for\nSubtask 2 (News Statements and Headlines).", "published": "2017-07-29 01:47:53", "link": "http://arxiv.org/abs/1707.09448v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Curriculum Learning and Minibatch Bucketing in Neural Machine\n  Translation", "abstract": "We examine the effects of particular orderings of sentence pairs on the\non-line training of neural machine translation (NMT). We focus on two types of\nsuch orderings: (1) ensuring that each minibatch contains sentences similar in\nsome aspect and (2) gradual inclusion of some sentence types as the training\nprogresses (so called \"curriculum learning\"). In our English-to-Czech\nexperiments, the internal homogeneity of minibatches has no effect on the\ntraining but some of our \"curricula\" achieve a small improvement over the\nbaseline.", "published": "2017-07-29 15:58:55", "link": "http://arxiv.org/abs/1707.09533v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Language Representations for Typology Prediction", "abstract": "One central mystery of neural NLP is what neural models \"know\" about their\nsubject matter. When a neural machine translation system learns to translate\nfrom one language to another, does it learn the syntax or semantics of the\nlanguages? Can this knowledge be extracted from the system to fill holes in\nhuman scientific knowledge? Existing typological databases contain relatively\nfull feature specifications for only a few hundred languages. Exploiting the\nexistence of parallel texts in more than a thousand languages, we build a\nmassive many-to-one neural machine translation (NMT) system from 1017 languages\ninto English, and use this to predict information missing from typological\ndatabases. Experiments show that the proposed method is able to infer not only\nsyntactic, but also phonological and phonetic inventory features, and improves\nover a baseline that has access to information about the languages' geographic\nand phylogenetic neighbors.", "published": "2017-07-29 23:38:25", "link": "http://arxiv.org/abs/1707.09569v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Zero-Shot Activity Recognition with Verb Attribute Induction", "abstract": "In this paper, we investigate large-scale zero-shot activity recognition by\nmodeling the visual and linguistic attributes of action verbs. For example, the\nverb \"salute\" has several properties, such as being a light movement, a social\nact, and short in duration. We use these attributes as the internal mapping\nbetween visual and textual representations to reason about a previously unseen\naction. In contrast to much prior work that assumes access to gold standard\nattributes for zero-shot classes and focuses primarily on object attributes,\nour model uniquely learns to infer action attributes from dictionary\ndefinitions and distributed word representations. Experimental results confirm\nthat action attributes inferred from language can provide a predictive signal\nfor zero-shot prediction of previously unseen activities.", "published": "2017-07-29 06:05:52", "link": "http://arxiv.org/abs/1707.09468v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Benchmarking Multimodal Sentiment Analysis", "abstract": "We propose a framework for multimodal sentiment analysis and emotion\nrecognition using convolutional neural network-based feature extraction from\ntext and visual modalities. We obtain a performance improvement of 10% over the\nstate of the art by combining visual, text and audio features. We also discuss\nsome major issues frequently ignored in multimodal sentiment analysis research:\nthe role of speaker-independent models, importance of the modalities and\ngeneralizability. The paper thus serve as a new benchmark for further research\nin multimodal sentiment analysis and also demonstrates the different facets of\nanalysis to be considered while performing such tasks.", "published": "2017-07-29 16:40:50", "link": "http://arxiv.org/abs/1707.09538v1", "categories": ["cs.MM", "cs.CL"], "primary_category": "cs.MM"}
{"title": "Men Also Like Shopping: Reducing Gender Bias Amplification using\n  Corpus-level Constraints", "abstract": "Language is increasingly being used to define rich visual recognition\nproblems with supporting image collections sourced from the web. Structured\nprediction models are used in these tasks to take advantage of correlations\nbetween co-occurring labels and visual input but risk inadvertently encoding\nsocial biases found in web corpora. In this work, we study data and models\nassociated with multilabel object classification and visual semantic role\nlabeling. We find that (a) datasets for these tasks contain significant gender\nbias and (b) models trained on these datasets further amplify existing bias.\nFor example, the activity cooking is over 33% more likely to involve females\nthan males in a training set, and a trained model further amplifies the\ndisparity to 68% at test time. We propose to inject corpus-level constraints\nfor calibrating existing structured prediction models and design an algorithm\nbased on Lagrangian relaxation for collective inference. Our method results in\nalmost no performance loss for the underlying recognition task but decreases\nthe magnitude of bias amplification by 47.5% and 40.5% for multilabel\nclassification and visual semantic role labeling, respectively.", "published": "2017-07-29 03:38:32", "link": "http://arxiv.org/abs/1707.09457v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "stat.ML"], "primary_category": "cs.AI"}
{"title": "Topology Analysis of International Networks Based on Debates in the\n  United Nations", "abstract": "In complex, high dimensional and unstructured data it is often difficult to\nextract meaningful patterns. This is especially the case when dealing with\ntextual data. Recent studies in machine learning, information theory and\nnetwork science have developed several novel instruments to extract the\nsemantics of unstructured data, and harness it to build a network of relations.\nSuch approaches serve as an efficient tool for dimensionality reduction and\npattern detection. This paper applies semantic network science to extract\nideological proximity in the international arena, by focusing on the data from\nGeneral Debates in the UN General Assembly on the topics of high salience to\ninternational community. UN General Debate corpus (UNGDC) covers all high-level\ndebates in the UN General Assembly from 1970 to 2014, covering all UN member\nstates. The research proceeds in three main steps. First, Latent Dirichlet\nAllocation (LDA) is used to extract the topics of the UN speeches, and\ntherefore semantic information. Each country is then assigned a vector\nspecifying the exposure to each of the topics identified. This intermediate\noutput is then used in to construct a network of countries based on information\ntheoretical metrics where the links capture similar vectorial patterns in the\ntopic distributions. Topology of the networks is then analyzed through network\nproperties like density, path length and clustering. Finally, we identify\nspecific topological features of our networks using the map equation framework\nto detect communities in our networks of countries.", "published": "2017-07-29 10:09:04", "link": "http://arxiv.org/abs/1707.09491v1", "categories": ["cs.CL", "cs.CG", "math.AT", "stat.AP"], "primary_category": "cs.CL"}
