{"title": "A novel approach to sentiment analysis in Persian using discourse and\n  external semantic information", "abstract": "Sentiment analysis attempts to identify, extract and quantify affective\nstates and subjective information from various types of data such as text,\naudio, and video. Many approaches have been proposed to extract the sentiment\nof individuals from documents written in natural languages in recent years. The\nmajority of these approaches have focused on English, while resource-lean\nlanguages such as Persian suffer from the lack of research work and language\nresources. Due to this gap in Persian, the current work is accomplished to\nintroduce new methods for sentiment analysis which have been applied on\nPersian. The proposed approach in this paper is two-fold: The first one is\nbased on classifier combination, and the second one is based on deep neural\nnetworks which benefits from word embedding vectors. Both approaches takes\nadvantage of local discourse information and external knowledge bases, and also\ncover several language issues such as negation and intensification,\nandaddresses different granularity levels, namely word, aspect, sentence,\nphrase and document-levels. To evaluate the performance of the proposed\napproach, a Persian dataset is collected from Persian hotel reviews referred as\nhotel reviews. The proposed approach has been compared to counterpart methods\nbased on the benchmark dataset. The experimental results approve the\neffectiveness of the proposed approach when compared to related works.", "published": "2020-07-18 18:40:40", "link": "http://arxiv.org/abs/2007.09495v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Feature-level Rating System using Customer Reviews and Review Votes", "abstract": "This work studies how we can obtain feature-level ratings of the mobile\nproducts from the customer reviews and review votes to influence decision\nmaking, both for new customers and manufacturers. Such a rating system gives a\nmore comprehensive picture of the product than what a product-level rating\nsystem offers. While product-level ratings are too generic, feature-level\nratings are particular; we exactly know what is good or bad about the product.\nThere has always been a need to know which features fall short or are doing\nwell according to the customer's perception. It keeps both the manufacturer and\nthe customer well-informed in the decisions to make in improving the product\nand buying, respectively. Different customers are interested in different\nfeatures. Thus, feature-level ratings can make buying decisions personalized.\nWe analyze the customer reviews collected on an online shopping site (Amazon)\nabout various mobile products and the review votes. Explicitly, we carry out a\nfeature-focused sentiment analysis for this purpose. Eventually, our analysis\nyields ratings to 108 features for 4k+ mobiles sold online. It helps in\ndecision making on how to improve the product (from the manufacturer's\nperspective) and in making the personalized buying decisions (from the buyer's\nperspective) a possibility. Our analysis has applications in recommender\nsystems, consumer research, etc.", "published": "2020-07-18 20:13:58", "link": "http://arxiv.org/abs/2007.09513v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Semi-Supervised Learning Approach to Discover Enterprise User Insights\n  from Feedback and Support", "abstract": "With the evolution of the cloud and customer centric culture, we inherently\naccumulate huge repositories of textual reviews, feedback, and support\ndata.This has driven enterprises to seek and research engagement patterns, user\nnetwork analysis, topic detections, etc.However, huge manual work is still\nnecessary to mine data to be able to mine actionable outcomes. In this paper,\nwe proposed and developed an innovative Semi-Supervised Learning approach by\nutilizing Deep Learning and Topic Modeling to have a better understanding of\nthe user voice.This approach combines a BERT-based multiclassification\nalgorithm through supervised learning combined with a novel Probabilistic and\nSemantic Hybrid Topic Inference (PSHTI) Model through unsupervised learning,\naiming at automating the process of better identifying the main topics or areas\nas well as the sub-topics from the textual feedback and support.There are three\nmajor break-through: 1. As the advancement of deep learning technology, there\nhave been tremendous innovations in the NLP field, yet the traditional topic\nmodeling as one of the NLP applications lag behind the tide of deep learning.\nIn the methodology and technical perspective, we adopt transfer learning to\nfine-tune a BERT-based multiclassification system to categorize the main topics\nand then utilize the novel PSHTI model to infer the sub-topics under the\npredicted main topics. 2. The traditional unsupervised learning-based topic\nmodels or clustering methods suffer from the difficulty of automatically\ngenerating a meaningful topic label, but our system enables mapping the top\nwords to the self-help issues by utilizing domain knowledge about the product\nthrough web-crawling. 3. This work provides a prominent showcase by leveraging\nthe state-of-the-art methodology in the real production to help shed light to\ndiscover user insights and drive business investment priorities.", "published": "2020-07-18 01:18:00", "link": "http://arxiv.org/abs/2007.09303v3", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Drinking from a Firehose: Continual Learning with Web-scale Natural\n  Language", "abstract": "Continual learning systems will interact with humans, with each other, and\nwith the physical world through time -- and continue to learn and adapt as they\ndo. An important open problem for continual learning is a large-scale benchmark\nthat enables realistic evaluation of algorithms. In this paper, we study a\nnatural setting for continual learning on a massive scale. We introduce the\nproblem of personalized online language learning (POLL), which involves fitting\npersonalized language models to a population of users that evolves over time.\nTo facilitate research on POLL, we collect massive datasets of Twitter posts.\nThese datasets, Firehose10M and Firehose100M, comprise 100 million tweets,\nposted by one million users over six years. Enabled by the Firehose datasets,\nwe present a rigorous evaluation of continual learning algorithms on an\nunprecedented scale. Based on this analysis, we develop a simple algorithm for\ncontinual gradient descent (ConGraD) that outperforms prior continual learning\nmethods on the Firehose datasets as well as earlier benchmarks. Collectively,\nthe POLL problem setting, the Firehose datasets, and the ConGraD algorithm\nenable a complete benchmark for reproducible research on web-scale continual\nlearning.", "published": "2020-07-18 05:40:02", "link": "http://arxiv.org/abs/2007.09335v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "On a Novel Application of Wasserstein-Procrustes for Unsupervised\n  Cross-Lingual Learning", "abstract": "The emergence of unsupervised word embeddings, pre-trained on very large\nmonolingual text corpora, is at the core of the ongoing neural revolution in\nNatural Language Processing (NLP). Initially introduced for English, such\npre-trained word embeddings quickly emerged for a number of other languages.\nSubsequently, there have been a number of attempts to align the embedding\nspaces across languages, which could enable a number of cross-language NLP\napplications. Performing the alignment using unsupervised cross-lingual\nlearning (UCL) is especially attractive as it requires little data and often\nrivals supervised and semi-supervised approaches. Here, we analyze popular\nmethods for UCL and we find that often their objectives are, intrinsically,\nversions of the Wasserstein-Procrustes problem. Hence, we devise an approach to\nsolve Wasserstein-Procrustes in a direct way, which can be used to refine and\nto improve popular UCL methods such as iterative closest point (ICP),\nmultilingual unsupervised and supervised embeddings (MUSE) and supervised\nProcrustes methods. Our evaluation experiments on standard datasets show\nsizable improvements over these approaches. We believe that our rethinking of\nthe Wasserstein-Procrustes problem could enable further research, thus helping\nto develop better algorithms for aligning word embeddings across languages. Our\ncode and instructions to reproduce the experiments are available at\nhttps://github.com/guillemram97/wp-hungarian.", "published": "2020-07-18 15:35:09", "link": "http://arxiv.org/abs/2007.09456v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Hierarchical Topic Mining via Joint Spherical Tree and Text Embedding", "abstract": "Mining a set of meaningful topics organized into a hierarchy is intuitively\nappealing since topic correlations are ubiquitous in massive text corpora. To\naccount for potential hierarchical topic structures, hierarchical topic models\ngeneralize flat topic models by incorporating latent topic hierarchies into\ntheir generative modeling process. However, due to their purely unsupervised\nnature, the learned topic hierarchy often deviates from users' particular needs\nor interests. To guide the hierarchical topic discovery process with minimal\nuser supervision, we propose a new task, Hierarchical Topic Mining, which takes\na category tree described by category names only, and aims to mine a set of\nrepresentative terms for each category from a text corpus to help a user\ncomprehend his/her interested topics. We develop a novel joint tree and text\nembedding method along with a principled optimization procedure that allows\nsimultaneous modeling of the category tree structure and the corpus generative\nprocess in the spherical space for effective category-representative term\ndiscovery. Our comprehensive experiments show that our model, named JoSH, mines\na high-quality set of hierarchical topics with high efficiency and benefits\nweakly-supervised hierarchical text classification tasks.", "published": "2020-07-18 23:30:47", "link": "http://arxiv.org/abs/2007.09536v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
