{"title": "Named Entity Recognition System for Sindhi Language", "abstract": "Named Entity Recognition (NER) System aims to extract the existing\ninformation into the following categories such as: Persons Name, Organization,\nLocation, Date and Time, Term, Designation and Short forms. Now, it is\nconsidered to be important aspect for many natural languages processing (NLP)\ntasks such as: information retrieval system, machine translation system,\ninformation extraction system and question answering. Even at a surface level,\nthe understanding of the named entities involved in a document gives richer\nanalytical framework and cross referencing. It has been used for different\nArabic Script-Based languages like, Arabic, Persian and Urdu but, Sindhi could\nnot come into being yet. This paper explains the problem of NER in the\nframework of Sindhi Language and provides relevant solution. The system is\ndeveloped to tag ten different Named Entities. We have used Ruled based\napproach for NER system of Sindhi Language. For the training and testing, 936\nwords were used and calculated performance accuracy of 98.71%.", "published": "2019-09-28 07:45:55", "link": "http://arxiv.org/abs/1910.03475v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Part of speech tagging for code switched data", "abstract": "We address the problem of Part of Speech tagging (POS) in the context of\nlinguistic code switching (CS). CS is the phenomenon where a speaker switches\nbetween two languages or variants of the same language within or across\nutterances, known as intra-sentential or inter-sentential CS, respectively.\nProcessing CS data is especially challenging in intra-sentential data given\nstate of the art monolingual NLP technology since such technology is geared\ntoward the processing of one language at a time. In this paper we explore\nmultiple strategies of applying state of the art POS taggers to CS data. We\ninvestigate the landscape in two CS language pairs, Spanish-English and Modern\nStandard Arabic-Arabic dialects. We compare the use of two POS taggers vs. a\nunified tagger trained on CS data. Our results show that applying a machine\nlearning framework using two state of the art POS taggers achieves better\nperformance compared to all other approaches that we investigate.", "published": "2019-09-28 02:12:39", "link": "http://arxiv.org/abs/1909.13006v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WASA: A Web Application for Sequence Annotation", "abstract": "Data annotation is an important and necessary task for all NLP applications.\nDesigning and implementing a web-based application that enables many annotators\nto annotate and enter their input into one central database is not a trivial\ntask. These kinds of web-based applications require a consistent and robust\nbackup for the underlying database and support to enhance the efficiency and\nspeed of the annotation. Also, they need to ensure that the annotations are\nstored with a minimal amount of redundancy in order to take advantage of the\navailable resources(e.g, storage space). In this paper, we introduce WASA, a\nweb-based annotation system for managing large-scale multilingual Code\nSwitching (CS) data annotation. Although WASA has the ability to perform the\nannotation for any token sequence with arbitrary tag sets, we will focus on how\nWASA is used for CS annotation. The system supports concurrent annotation,\nhandles multiple encodings, allows for several levels of management control,\nand enables quality control measures while seamlessly reporting annotation\nstatistics from various perspectives and at different levels of granularity.\nMoreover, the system is integrated with a robust language specific date\nprepossessing tool to enhance the speed and efficiency of the annotation. We\ndescribe the annotation and the administration interfaces as well as the\nbackend engine.", "published": "2019-09-28 02:37:23", "link": "http://arxiv.org/abs/1909.13008v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Creating a Large Multi-Layered Representational Repository of Linguistic\n  Code Switched Arabic Data", "abstract": "We present our effort to create a large Multi-Layered representational\nrepository of Linguistic Code-Switched Arabic data. The process involves\ndeveloping clear annotation standards and Guidelines, streamlining the\nannotation process, and implementing quality control measures. We used two main\nprotocols for annotation: in-lab gold annotations and crowd sourcing\nannotations. We developed a web-based annotation tool to facilitate the\nmanagement of the annotation process. The current version of the repository\ncontains a total of 886,252 tokens that are tagged into one of sixteen\ncode-switching tags. The data exhibits code switching between Modern Standard\nArabic and Egyptian Dialectal Arabic representing three data genres: Tweets,\ncommentaries, and discussion fora. The overall Inter-Annotator Agreement is\n93.1%.", "published": "2019-09-28 02:42:18", "link": "http://arxiv.org/abs/1909.13009v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Overview for the Second Shared Task on Language Identification in\n  Code-Switched Data", "abstract": "We present an overview of the second shared task on language identification\nin code-switched data. For the shared task, we had code-switched data from two\ndifferent language pairs: Modern Standard Arabic-Dialectal Arabic (MSA-DA) and\nSpanish-English (SPA-ENG). We had a total of nine participating teams, with all\nteams submitting a system for SPA-ENG and four submitting for MSA-DA. Through\nevaluation, we found that once again language identification is more difficult\nfor the language pair that is more closely related. We also found that this\nyear's systems performed better overall than the systems from the previous\nshared task indicating overall progress in the state of the art for this task.", "published": "2019-09-28 03:26:31", "link": "http://arxiv.org/abs/1909.13016v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OpenNRE: An Open and Extensible Toolkit for Neural Relation Extraction", "abstract": "OpenNRE is an open-source and extensible toolkit that provides a unified\nframework to implement neural models for relation extraction (RE).\nSpecifically, by implementing typical RE methods, OpenNRE not only allows\ndevelopers to train custom models to extract structured relational facts from\nthe plain text but also supports quick model validation for researchers.\nBesides, OpenNRE provides various functional RE modules based on both\nTensorFlow and PyTorch to maintain sufficient modularity and extensibility,\nmaking it becomes easy to incorporate new models into the framework. Besides\nthe toolkit, we also release an online system to meet real-time extraction\nwithout any training and deploying. Meanwhile, the online system can extract\nfacts in various scenarios as well as aligning the extracted facts to Wikidata,\nwhich may benefit various downstream knowledge-driven applications (e.g.,\ninformation retrieval and question answering). More details of the toolkit and\nonline system can be obtained from http://github.com/thunlp/OpenNRE.", "published": "2019-09-28 12:26:07", "link": "http://arxiv.org/abs/1909.13078v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Integrated Triaging for Fast Reading Comprehension", "abstract": "Although according to several benchmarks automatic machine reading\ncomprehension (MRC) systems have recently reached super-human performance, less\nattention has been paid to their computational efficiency. However, efficiency\nis of crucial importance for training and deployment in real world\napplications. This paper introduces Integrated Triaging, a framework that\nprunes almost all context in early layers of a network, leaving the remaining\n(deep) layers to scan only a tiny fraction of the full corpus. This pruning\ndrastically increases the efficiency of MRC models and further prevents the\nlater layers from overfitting to prevalent short paragraphs in the training\nset. Our framework is extremely flexible and naturally applicable to a wide\nvariety of models. Our experiment on doc-SQuAD and TriviaQA tasks demonstrates\nits effectiveness in consistently improving both speed and quality of several\ndiverse MRC models.", "published": "2019-09-28 18:28:56", "link": "http://arxiv.org/abs/1909.13128v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Source-Target Domain Mismatch Problem in Machine Translation", "abstract": "While we live in an increasingly interconnected world, different places still\nexhibit strikingly different cultures and many events we experience in our\nevery day life pertain only to the specific place we live in. As a result,\npeople often talk about different things in different parts of the world. In\nthis work we study the effect of local context in machine translation and\npostulate that particularly in low resource settings this causes the domains of\nthe source and target language to greatly mismatch, as the two languages are\noften spoken in further apart regions of the world with more distinctive\ncultural traits and unrelated local events. We first formalize the concept of\nsource-target domain mismatch, propose a metric to quantify it, and provide\nempirical evidence corroborating our intuition that organic text produced by\npeople speaking very different languages exhibits the most dramatic\ndifferences. We conclude with an empirical study of how source-target domain\nmismatch affects training of machine translation systems for low resource\nlanguage pairs. In particular, we find that it severely affects\nback-translation, but the degradation can be alleviated by combining\nback-translation with self-training and by increasing the relative amount of\ntarget side monolingual data.", "published": "2019-09-28 21:03:09", "link": "http://arxiv.org/abs/1909.13151v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generalized Zero-shot ICD Coding", "abstract": "The International Classification of Diseases (ICD) is a list of\nclassification codes for the diagnoses. Automatic ICD coding is in high demand\nas the manual coding can be labor-intensive and error-prone. It is a\nmulti-label text classification task with extremely long-tailed label\ndistribution, making it difficult to perform fine-grained classification on\nboth frequent and zero-shot codes at the same time. In this paper, we propose a\nlatent feature generation framework for generalized zero-shot ICD coding, where\nwe aim to improve the prediction on codes that have no labeled data without\ncompromising the performance on seen codes. Our framework generates pseudo\nfeatures conditioned on the ICD code descriptions and exploits the ICD code\nhierarchical structure. To guarantee the semantic consistency between the\ngenerated features and real features, we reconstruct the keywords in the input\ndocuments that are related to the conditioned ICD codes. To the best of our\nknowledge, this works represents the first one that proposes an adversarial\ngenerative model for the generalized zero-shot learning on multi-label text\nclassification. Extensive experiments demonstrate the effectiveness of our\napproach. On the public MIMIC-III dataset, our methods improve the F1 score\nfrom nearly 0 to 20.91% for the zero-shot codes, and increase the AUC score by\n3% (absolute improvement) from previous state of the art. We also show that the\nframework improves the performance on few-shot codes.", "published": "2019-09-28 21:32:55", "link": "http://arxiv.org/abs/1909.13154v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Translation, Sentiment and Voices: A Computational Model to Translate\n  and Analyse Voices from Real-Time Video Calling", "abstract": "With internet quickly becoming an easy access to many, voice calling over\ninternet is slowly gaining momentum. Individuals has been engaging in video\ncommunication across the world in different languages. The decade saw the\nemergence of language translation using neural networks as well. With more data\nbeing generated in audio and visual forms, there has become a need and a\nchallenge to analyse such information for many researchers from academia and\nindustry. The availability of video chat corpora is limited as organizations\nprotect user privacy and ensure data security. For this reason, an audio-visual\ncommunication system (VidALL) has been developed and audio-speeches were\nextracted. To understand human nature while answering a video call, an analysis\nwas conducted where polarity and vocal intensity were considered as parameters.\nSimultaneously, a translation model using a neural approach was developed to\ntranslate English sentences to French. Simple RNN-based and Embedded-RNN based\nmodels were used for the translation model. BLEU score and target sentence\ncomparators were used to check sentence correctness. Embedded-RNN showed an\naccuracy of 88.71 percentage and predicted correct sentences. A key finding\nsuggest that polarity is a good estimator to understand human emotion.", "published": "2019-09-28 22:11:03", "link": "http://arxiv.org/abs/1909.13162v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Self-Attention Transducers for End-to-End Speech Recognition", "abstract": "Recurrent neural network transducers (RNN-T) have been successfully applied\nin end-to-end speech recognition. However, the recurrent structure makes it\ndifficult for parallelization . In this paper, we propose a self-attention\ntransducer (SA-T) for speech recognition. RNNs are replaced with self-attention\nblocks, which are powerful to model long-term dependencies inside sequences and\nable to be efficiently parallelized. Furthermore, a path-aware regularization\nis proposed to assist SA-T to learn alignments and improve the performance.\nAdditionally, a chunk-flow mechanism is utilized to achieve online decoding.\nAll experiments are conducted on a Mandarin Chinese dataset AISHELL-1. The\nresults demonstrate that our proposed approach achieves a 21.3% relative\nreduction in character error rate compared with the baseline RNN-T. In\naddition, the SA-T with chunk-flow mechanism can perform online decoding with\nonly a little degradation of the performance.", "published": "2019-09-28 06:48:47", "link": "http://arxiv.org/abs/1909.13037v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Emirati-Accented Speaker Identification in Stressful Talking Conditions", "abstract": "This research is dedicated to improving text-independent Emirati-accented\nspeaker identification performance in stressful talking conditions using three\ndistinct classifiers: First-Order Hidden Markov Models (HMM1s), Second-Order\nHidden Markov Models (HMM2s), and Third-Order Hidden Markov Models (HMM3s). The\ndatabase that has been used in this work was collected from 25 per gender\nEmirati native speakers uttering eight widespread Emirati sentences in each of\nneutral, shouted, slow, loud, soft, and fast talking conditions. The extracted\nfeatures of the captured database are called Mel-Frequency Cepstral\nCoefficients (MFCCs). Based on HMM1s, HMM2s, and HMM3s, average\nEmirati-accented speaker identification accuracy in stressful conditions is\n58.6%, 61.1%, and 65.0%, respectively. The achieved average speaker\nidentification accuracy in stressful conditions based on HMM3s is so similar to\nthat attained in subjective assessment by human listeners.", "published": "2019-09-28 11:16:50", "link": "http://arxiv.org/abs/1909.13070v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Attention-based method for categorizing different types of online\n  harassment language", "abstract": "In the era of social media and networking platforms, Twitter has been doomed\nfor abuse and harassment toward users specifically women. Monitoring the\ncontents including sexism and sexual harassment in traditional media is easier\nthan monitoring on the online social media platforms like Twitter, because of\nthe large amount of user generated content in these media. So, the research\nabout the automated detection of content containing sexual or racist harassment\nis an important issue and could be the basis for removing that content or\nflagging it for human evaluation. Previous studies have been focused on\ncollecting data about sexism and racism in very broad terms. However, there is\nno much study focusing on different types of online harassment attracting\nnatural language processing techniques. In this work, we present an\nmulti-attention based approach for the detection of different types of\nharassment in tweets. Our approach is based on the Recurrent Neural Networks\nand particularly we are using a deep, classification specific multi-attention\nmechanism. Moreover, we tackle the problem of imbalanced data, using a\nback-translation method. Finally, we present a comparison between different\napproaches based on the Recurrent Neural Networks.", "published": "2019-09-28 14:32:46", "link": "http://arxiv.org/abs/1909.13104v2", "categories": ["cs.CL", "cs.LG", "cs.SI", "stat.ML"], "primary_category": "cs.CL"}
