{"title": "Applying Automated Machine Translation to Educational Video Courses", "abstract": "We studied the capability of automated machine translation in the online\nvideo education space by automatically translating Khan Academy videos with\nstate-of-the-art translation models and applying text-to-speech synthesis and\naudio/video synchronization to build engaging videos in target languages. We\nalso analyzed and established two reliable translation confidence estimators\nbased on round-trip translations in order to efficiently manage translation\nquality and reduce human translation effort. Finally, we developed a deployable\nsystem to deliver translated videos to end users and collect user corrections\nfor iterative improvement.", "published": "2023-01-09 01:44:29", "link": "http://arxiv.org/abs/2301.03141v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Active Learning for Abstractive Text Summarization", "abstract": "Construction of human-curated annotated datasets for abstractive text\nsummarization (ATS) is very time-consuming and expensive because creating each\ninstance requires a human annotator to read a long document and compose a\nshorter summary that would preserve the key information relayed by the original\ndocument. Active Learning (AL) is a technique developed to reduce the amount of\nannotation required to achieve a certain level of machine learning model\nperformance. In information extraction and text classification, AL can reduce\nthe amount of labor up to multiple times. Despite its potential for aiding\nexpensive annotation, as far as we know, there were no effective AL query\nstrategies for ATS. This stems from the fact that many AL strategies rely on\nuncertainty estimation, while as we show in our work, uncertain instances are\nusually noisy, and selecting them can degrade the model performance compared to\npassive annotation. We address this problem by proposing the first effective\nquery strategy for AL in ATS based on diversity principles. We show that given\na certain annotation budget, using our strategy in AL annotation helps to\nimprove the model performance in terms of ROUGE and consistency scores.\nAdditionally, we analyze the effect of self-learning and show that it can\nfurther increase the performance of the model.", "published": "2023-01-09 10:33:14", "link": "http://arxiv.org/abs/2301.03252v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Universal Information Extraction as Unified Semantic Matching", "abstract": "The challenge of information extraction (IE) lies in the diversity of label\nschemas and the heterogeneity of structures. Traditional methods require\ntask-specific model design and rely heavily on expensive supervision, making\nthem difficult to generalize to new schemas. In this paper, we decouple IE into\ntwo basic abilities, structuring and conceptualizing, which are shared by\ndifferent tasks and schemas. Based on this paradigm, we propose to universally\nmodel various IE tasks with Unified Semantic Matching (USM) framework, which\nintroduces three unified token linking operations to model the abilities of\nstructuring and conceptualizing. In this way, USM can jointly encode schema and\ninput text, uniformly extract substructures in parallel, and controllably\ndecode target structures on demand. Empirical evaluation on 4 IE tasks shows\nthat the proposed method achieves state-of-the-art performance under the\nsupervised experiments and shows strong generalization ability in zero/few-shot\ntransfer settings.", "published": "2023-01-09 11:51:31", "link": "http://arxiv.org/abs/2301.03282v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ERNIE 3.0 Tiny: Frustratingly Simple Method to Improve Task-Agnostic\n  Distillation Generalization", "abstract": "Task-agnostic knowledge distillation attempts to address the problem of\ndeploying large pretrained language model in resource-constrained scenarios by\ncompressing a large pretrained model called teacher into a smaller one called\nstudent such that the student can be directly finetuned on downstream tasks and\nretains comparable performance. However, we empirically find that there is a\ngeneralization gap between the student and the teacher in existing methods. In\nthis work, we show that we can leverage multi-task learning in task-agnostic\ndistillation to advance the generalization of the resulted student. In\nparticular, we propose Multi-task Infused Task-agnostic Knowledge Distillation\n(MITKD). We first enhance the teacher by multi-task training it on multiple\ndownstream tasks and then perform distillation to produce the student.\nExperimental results demonstrate that our method yields a student with much\nbetter generalization, significantly outperforms existing baselines, and\nestablishes a new state-of-the-art result on in-domain, out-domain, and\nlow-resource datasets in the setting of task-agnostic distillation. Moreover,\nour method even exceeds an 8x larger BERT$_{\\text{Base}}$ on SQuAD and four\nGLUE tasks. In addition, by combining ERNIE 3.0, our method achieves\nstate-of-the-art results on 10 Chinese datasets.", "published": "2023-01-09 15:12:50", "link": "http://arxiv.org/abs/2301.03416v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Standardization of Arabic Dialects for Machine Translation", "abstract": "Based on an annotated multimedia corpus, television series Mar{\\=a}y{\\=a}\n2013, we dig into the question of ''automatic standardization'' of Arabic\ndialects for machine translation. Here we distinguish between rule-based\nmachine translation and statistical machine translation. Machine translation\nfrom Arabic most of the time takes standard or modern Arabic as the source\nlanguage and produces quite satisfactory translations thanks to the\navailability of the translation memories necessary for training the models. The\ncase is different for the translation of Arabic dialects. The productions are\nmuch less efficient. In our research we try to apply machine translation\nmethods to a dialect/standard (or modern) Arabic pair to automatically produce\na standard Arabic text from a dialect input, a process we call ''automatic\nstandardization''. we opt here for the application of ''statistical models''\nbecause ''automatic standardization'' based on rules is more hard with the lack\nof ''diglossic'' dictionaries on the one hand and the difficulty of creating\nlinguistic rules for each dialect on the other. Carrying out this research\ncould then lead to combining ''automatic standardization'' software and\nautomatic translation software so that we take the output of the first software\nand introduce it as input into the second one to obtain at the end a quality\nmachine translation. This approach may also have educational applications such\nas the development of applications to help understand different Arabic dialects\nby transforming dialectal texts into standard Arabic.", "published": "2023-01-09 15:52:40", "link": "http://arxiv.org/abs/2301.03447v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Color Me Intrigued: Quantifying Usage of Colors in Fiction", "abstract": "We present preliminary results in quantitative analyses of color usage in\nselected authors' works from LitBank. Using Glasgow Norms, human ratings on\n5000+ words, we measure attributes of nouns dependent on color terms. Early\nresults demonstrate a significant increase in noun concreteness over time. We\nalso propose future research directions for computational literary color\nanalytics.", "published": "2023-01-09 18:20:10", "link": "http://arxiv.org/abs/2301.03559v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FullStop:Punctuation and Segmentation Prediction for Dutch with\n  Transformers", "abstract": "When applying automated speech recognition (ASR) for Belgian Dutch (Van Dyck\net al. 2021), the output consists of an unsegmented stream of words, without\nany punctuation. A next step is to perform segmentation and insert punctuation,\nmaking the ASR output more readable and easy to manually correct. As far as we\nknow there is no publicly available punctuation insertion system for Dutch that\nfunctions at a usable level. The model we present here is an extension of the\nmodels of Guhr et al. (2021) for Dutch and is made publicly available. We\ntrained a sequence classification model, based on the Dutch language model\nRobBERT (Delobelle et al. 2020). For every word in the input sequence, the\nmodels predicts a punctuation marker that follows the word. We have also\nextended a multilingual model, for cases where the language is unknown or where\ncode switching applies. When performing the task of segmentation, the\napplication of the best models onto out of domain test data, a sliding window\nof 200 words of the ASR output stream is sent to the classifier, and\nsegmentation is applied when the system predicts a segmenting punctuation sign\nwith a ratio above threshold. Results show to be much better than a machine\ntranslation baseline approach.", "published": "2023-01-09 13:12:05", "link": "http://arxiv.org/abs/2301.03319v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "AI2: The next leap toward native language based and explainable machine\n  learning framework", "abstract": "The machine learning frameworks flourished in the last decades, allowing\nartificial intelligence to get out of academic circles to be applied to\nenterprise domains. This field has significantly advanced, but there is still\nsome meaningful improvement to reach the subsequent expectations. The proposed\nframework, named AI$^{2}$, uses a natural language interface that allows a\nnon-specialist to benefit from machine learning algorithms without necessarily\nknowing how to program with a programming language. The primary contribution of\nthe AI$^{2}$ framework allows a user to call the machine learning algorithms in\nEnglish, making its interface usage easier. The second contribution is\ngreenhouse gas (GHG) awareness. It has some strategies to evaluate the GHG\ngenerated by the algorithm to be called and to propose alternatives to find a\nsolution without executing the energy-intensive algorithm. Another contribution\nis a preprocessing module that helps to describe and to load data properly.\nUsing an English text-based chatbot, this module guides the user to define\nevery dataset so that it can be described, normalized, loaded and divided\nappropriately. The last contribution of this paper is about explainability. For\ndecades, the scientific community has known that machine learning algorithms\nimply the famous black-box problem. Traditional machine learning methods\nconvert an input into an output without being able to justify this result. The\nproposed framework explains the algorithm's process with the proper texts,\ngraphics and tables. The results, declined in five cases, present usage\napplications from the user's English command to the explained output.\nUltimately, the AI$^{2}$ framework represents the next leap toward native\nlanguage-based, human-oriented concerns about machine learning framework.", "published": "2023-01-09 14:48:35", "link": "http://arxiv.org/abs/2301.03391v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Mining Healthcare Procurement Data Using Text Mining and Natural\n  Language Processing -- Reflection From An Industrial Project", "abstract": "While text mining and NLP research has been established for decades, there\nremain gaps in the literature that reports the use of these techniques in\nbuilding real-world applications. For example, they typically look at single\nand sometimes simplified tasks, and do not discuss in-depth data heterogeneity\nand inconsistency that is common in real-world problems or their implication on\nthe development of their methods. Also, few prior work has focused on the\nhealthcare domain. In this work, we describe an industry project that developed\ntext mining and NLP solutions to mine millions of heterogeneous, multilingual\nprocurement documents in the healthcare sector. We extract structured\nprocurement contract data that is used to power a platform for dynamically\nassessing supplier risks. Our work makes unique contributions in a number of\nways. First, we deal with highly heterogeneous, multilingual data and we\ndocument our approach to tackle these challenges. This is mainly based on a\nmethod that effectively uses domain knowledge and generalises to multiple text\nmining and NLP tasks and languages. Second, applying this method to mine\nmillions of procurement documents, we develop the first structured procurement\ncontract database that will help facilitate the tendering process. Second,\nFinally, we discuss lessons learned for practical text mining/NLP development,\nand make recommendations for future research and practice.", "published": "2023-01-09 15:59:55", "link": "http://arxiv.org/abs/2301.03458v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Leveraging Contextual Relatedness to Identify Suicide Documentation in\n  Clinical Notes through Zero Shot Learning", "abstract": "Identifying suicidality including suicidal ideation, attempts, and risk\nfactors in electronic health record data in clinical notes is difficult. A\nmajor difficulty is the lack of training samples given the small number of true\npositive instances among the increasingly large number of patients being\nscreened. This paper describes a novel methodology that identifies suicidality\nin clinical notes by addressing this data sparsity issue through zero-shot\nlearning. U.S. Veterans Affairs clinical notes served as data. The training\ndataset label was determined using diagnostic codes of suicide attempt and\nself-harm. A base string associated with the target label of suicidality was\nused to provide auxiliary information by narrowing the positive training cases\nto those containing the base string. A deep neural network was trained by\nmapping the training documents contents to a semantic space. For comparison, we\ntrained another deep neural network using the identical training dataset labels\nand bag-of-words features. The zero shot learning model outperformed the\nbaseline model in terms of AUC, sensitivity, specificity, and positive\npredictive value at multiple probability thresholds. In applying a 0.90\nprobability threshold, the methodology identified notes not associated with a\nrelevant ICD 10 CM code that documented suicidality, with 94 percent accuracy.\nThis new method can effectively identify suicidality without requiring manual\nannotation.", "published": "2023-01-09 17:26:07", "link": "http://arxiv.org/abs/2301.03531v1", "categories": ["cs.AI", "cs.CL", "I.2.7; J.3"], "primary_category": "cs.AI"}
{"title": "Logically at Factify 2: A Multi-Modal Fact Checking System Based on\n  Evidence Retrieval techniques and Transformer Encoder Architecture", "abstract": "In this paper, we present the Logically submissions to De-Factify 2 challenge\n(DE-FACTIFY 2023) on the task 1 of Multi-Modal Fact Checking. We describes our\nsubmissions to this challenge including explored evidence retrieval and\nselection techniques, pre-trained cross-modal and unimodal models, and a\ncross-modal veracity model based on the well established Transformer Encoder\n(TE) architecture which is heavily relies on the concept of self-attention.\nExploratory analysis is also conducted on this Factify 2 data set that uncovers\nthe salient multi-modal patterns and hypothesis motivating the architecture\nproposed in this work. A series of preliminary experiments were done to\ninvestigate and benchmarking different pre-trained embedding models, evidence\nretrieval settings and thresholds. The final system, a standard two-stage\nevidence based veracity detection system, yields weighted avg. 0.79 on both val\nset and final blind test set on the task 1, which achieves 3rd place with a\nsmall margin to the top performing system on the leaderboard among 9\nparticipants.", "published": "2023-01-09 00:19:11", "link": "http://arxiv.org/abs/2301.03127v2", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Removing Non-Stationary Knowledge From Pre-Trained Language Models for\n  Entity-Level Sentiment Classification in Finance", "abstract": "Extraction of sentiment signals from news text, stock message boards, and\nbusiness reports, for stock movement prediction, has been a rising field of\ninterest in finance. Building upon past literature, the most recent works\nattempt to better capture sentiment from sentences with complex syntactic\nstructures by introducing aspect-level sentiment classification (ASC). Despite\nthe growing interest, however, fine-grained sentiment analysis has not been\nfully explored in non-English literature due to the shortage of annotated\nfinance-specific data. Accordingly, it is necessary for non-English languages\nto leverage datasets and pre-trained language models (PLM) of different\ndomains, languages, and tasks to best their performance. To facilitate\nfinance-specific ASC research in the Korean language, we build KorFinASC, a\nKorean aspect-level sentiment classification dataset for finance consisting of\n12,613 human-annotated samples, and explore methods of intermediate transfer\nlearning. Our experiments indicate that past research has been ignorant towards\nthe potentially wrong knowledge of financial entities encoded during the\ntraining phase, which has overestimated the predictive power of PLMs. In our\nwork, we use the term \"non-stationary knowledge'' to refer to information that\nwas previously correct but is likely to change, and present \"TGT-Masking'', a\nnovel masking pattern to restrict PLMs from speculating knowledge of the kind.\nFinally, through a series of transfer learning with TGT-Masking applied we\nimprove 22.63% of classification accuracy compared to standalone models on\nKorFinASC.", "published": "2023-01-09 01:26:55", "link": "http://arxiv.org/abs/2301.03136v2", "categories": ["cs.CL", "cs.LG", "q-fin.GN"], "primary_category": "cs.CL"}
{"title": "Machine Learning Algorithms for Depression Detection and Their\n  Comparison", "abstract": "Textual emotional intelligence is playing a ubiquitously important role in\nleveraging human emotions on social media platforms. Social media platforms are\nprivileged with emotional content and are leveraged for various purposes like\nopinion mining, emotion mining, and sentiment analysis. This data analysis is\nalso levered for the prevention of online bullying, suicide prevention, and\ndepression detection among social media users. In this article, we have\ndesigned an automatic depression detection of online social media users by\nanalyzing their social media behavior. The designed depression detection\nclassification can be effectively used to mine user's social media interactions\nand one can determine whether a social media user is suffering from depression\nor not. The underlying classifier is made using state-of-art technology in\nemotional artificial intelligence which includes LSTM (Long Short Term Memory)\nand other machine learning classifiers. The highest accuracy of the classifier\nis around 70% of LSTM and for SVM the highest accuracy is 81.79%. We trained\nthe classifier on the datasets that are widely used in literature for emotion\nmining tasks. A confusion matrix of results is also given.", "published": "2023-01-09 09:34:38", "link": "http://arxiv.org/abs/2301.03222v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Online Fake Review Detection Using Supervised Machine Learning And BERT\n  Model", "abstract": "Online shopping stores have grown steadily over the past few years. Due to\nthe massive growth of these businesses, the detection of fake reviews has\nattracted attention. Fake reviews are seriously trying to mislead customers and\nthereby undermine the honesty and authenticity of online shopping environments.\nSo far, various fake review classifiers have been proposed that take into\naccount the actual content of the review. To improve the accuracies of existing\nfake review classification or detection approaches, we propose to use BERT\n(Bidirectional Encoder Representation from Transformers) model to extract word\nembeddings from texts (i.e. reviews). Word embeddings are obtained in various\nbasic methods such as SVM (Support vector machine), Random Forests, Naive\nBayes, and others. The confusion matrix method was also taken into account to\nevaluate and graphically represent the results. The results indicate that the\nSVM classifiers outperform the others in terms of accuracy and f1-score with an\naccuracy of 87.81%, which is 7.6% higher than the classifier used in the\nprevious study [5].", "published": "2023-01-09 09:40:56", "link": "http://arxiv.org/abs/2301.03225v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Universal Multimodal Representation for Language Understanding", "abstract": "Representation learning is the foundation of natural language processing\n(NLP). This work presents new methods to employ visual information as assistant\nsignals to general NLP tasks. For each sentence, we first retrieve a flexible\nnumber of images either from a light topic-image lookup table extracted over\nthe existing sentence-image pairs or a shared cross-modal embedding space that\nis pre-trained on out-of-shelf text-image pairs. Then, the text and images are\nencoded by a Transformer encoder and convolutional neural network,\nrespectively. The two sequences of representations are further fused by an\nattention layer for the interaction of the two modalities. In this study, the\nretrieval process is controllable and flexible. The universal visual\nrepresentation overcomes the lack of large-scale bilingual sentence-image\npairs. Our method can be easily applied to text-only tasks without manually\nannotated multimodal parallel corpora. We apply the proposed method to a wide\nrange of natural language generation and understanding tasks, including neural\nmachine translation, natural language inference, and semantic similarity.\nExperimental results show that our method is generally effective for different\ntasks and languages. Analysis indicates that the visual signals enrich textual\nrepresentations of content words, provide fine-grained grounding information\nabout the relationship between concepts and events, and potentially conduce to\ndisambiguation.", "published": "2023-01-09 13:54:11", "link": "http://arxiv.org/abs/2301.03344v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Learning Bidirectional Action-Language Translation with Limited\n  Supervision and Incongruent Input", "abstract": "Human infant learning happens during exploration of the environment, by\ninteraction with objects, and by listening to and repeating utterances\ncasually, which is analogous to unsupervised learning. Only occasionally, a\nlearning infant would receive a matching verbal description of an action it is\ncommitting, which is similar to supervised learning. Such a learning mechanism\ncan be mimicked with deep learning. We model this weakly supervised learning\nparadigm using our Paired Gated Autoencoders (PGAE) model, which combines an\naction and a language autoencoder. After observing a performance drop when\nreducing the proportion of supervised training, we introduce the Paired\nTransformed Autoencoders (PTAE) model, using Transformer-based crossmodal\nattention. PTAE achieves significantly higher accuracy in language-to-action\nand action-to-language translations, particularly in realistic but difficult\ncases when only few supervised training samples are available. We also test\nwhether the trained model behaves realistically with conflicting multimodal\ninput. In accordance with the concept of incongruence in psychology, conflict\ndeteriorates the model output. Conflicting action input has a more severe\nimpact than conflicting language input, and more conflicting features lead to\nlarger interference. PTAE can be trained on mostly unlabelled data where\nlabeled data is scarce, and it behaves plausibly when tested with incongruent\ninput.", "published": "2023-01-09 14:09:09", "link": "http://arxiv.org/abs/2301.03353v2", "categories": ["cs.CL", "cs.AI", "cs.NE", "cs.RO"], "primary_category": "cs.CL"}
{"title": "MAQA: A Multimodal QA Benchmark for Negation", "abstract": "Multimodal learning can benefit from the representation power of pretrained\nLarge Language Models (LLMs). However, state-of-the-art transformer based LLMs\noften ignore negations in natural language and there is no existing benchmark\nto quantitatively evaluate whether multimodal transformers inherit this\nweakness. In this study, we present a new multimodal question answering (QA)\nbenchmark adapted from labeled music videos in AudioSet (Gemmeke et al., 2017)\nwith the goal of systematically evaluating if multimodal transformers can\nperform complex reasoning to recognize new concepts as negation of previously\nlearned concepts. We show that with standard fine-tuning approach multimodal\ntransformers are still incapable of correctly interpreting negation\nirrespective of model size. However, our experiments demonstrate that\naugmenting the original training task distributions with negated QA examples\nallow the model to reliably reason with negation. To do this, we describe a\nnovel data generation procedure that prompts the 540B-parameter PaLM model to\nautomatically generate negated QA examples as compositions of easily accessible\nvideo tags. The generated examples contain more natural linguistic patterns and\nthe gains compared to template-based task augmentation approach are\nsignificant.", "published": "2023-01-09 10:11:23", "link": "http://arxiv.org/abs/2301.03238v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Introducing Model Inversion Attacks on Automatic Speaker Recognition", "abstract": "Model inversion (MI) attacks allow to reconstruct average per-class\nrepresentations of a machine learning (ML) model's training data. It has been\nshown that in scenarios where each class corresponds to a different individual,\nsuch as face classifiers, this represents a severe privacy risk. In this work,\nwe explore a new application for MI: the extraction of speakers' voices from a\nspeaker recognition system. We present an approach to (1) reconstruct audio\nsamples from a trained ML model and (2) extract intermediate voice feature\nrepresentations which provide valuable insights into the speakers' biometrics.\n  Therefore, we propose an extension of MI attacks which we call sliding model\ninversion. Our sliding MI extends standard MI by iteratively inverting\noverlapping chunks of the audio samples and thereby leveraging the sequential\nproperties of audio data for enhanced inversion performance. We show that one\ncan use the inverted audio data to generate spoofed audio samples to\nimpersonate a speaker, and execute voice-protected commands for highly secured\nsystems on their behalf. To the best of our knowledge, our work is the first\none extending MI attacks to audio data, and our results highlight the security\nrisks resulting from the extraction of the biometric data in that setup.", "published": "2023-01-09 08:51:15", "link": "http://arxiv.org/abs/2301.03206v1", "categories": ["cs.SD", "cs.CR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Latent Autoregressive Source Separation", "abstract": "Autoregressive models have achieved impressive results over a wide range of\ndomains in terms of generation quality and downstream task performance. In the\ncontinuous domain, a key factor behind this success is the usage of quantized\nlatent spaces (e.g., obtained via VQ-VAE autoencoders), which allow for\ndimensionality reduction and faster inference times. However, using existing\npre-trained models to perform new non-trivial tasks is difficult since it\nrequires additional fine-tuning or extensive training to elicit prompting. This\npaper introduces LASS as a way to perform vector-quantized Latent\nAutoregressive Source Separation (i.e., de-mixing an input signal into its\nconstituent sources) without requiring additional gradient-based optimization\nor modifications of existing models. Our separation method relies on the\nBayesian formulation in which the autoregressive models are the priors, and a\ndiscrete (non-parametric) likelihood function is constructed by performing\nfrequency counts over latent sums of addend tokens. We test our method on\nimages and audio with several sampling strategies (e.g., ancestral, beam\nsearch) showing competitive results with existing approaches in terms of\nseparation quality while offering at the same time significant speedups in\nterms of inference time and scalability to higher dimensional data.", "published": "2023-01-09 17:32:00", "link": "http://arxiv.org/abs/2301.08562v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
