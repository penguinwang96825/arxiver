{"title": "Unsupervised word segmentation and lexicon discovery using acoustic word\n  embeddings", "abstract": "In settings where only unlabelled speech data is available, speech technology\nneeds to be developed without transcriptions, pronunciation dictionaries, or\nlanguage modelling text. A similar problem is faced when modelling infant\nlanguage acquisition. In these cases, categorical linguistic structure needs to\nbe discovered directly from speech audio. We present a novel unsupervised\nBayesian model that segments unlabelled speech and clusters the segments into\nhypothesized word groupings. The result is a complete unsupervised tokenization\nof the input speech in terms of discovered word types. In our approach, a\npotential word segment (of arbitrary length) is embedded in a fixed-dimensional\nacoustic vector space. The model, implemented as a Gibbs sampler, then builds a\nwhole-word acoustic model in this space while jointly performing segmentation.\nWe report word error rates in a small-vocabulary connected digit recognition\ntask by mapping the unsupervised decoded output to ground truth transcriptions.\nThe model achieves around 20% error rate, outperforming a previous HMM-based\nsystem by about 10% absolute. Moreover, in contrast to the baseline, our model\ndoes not require a pre-specified vocabulary size.", "published": "2016-03-09 11:14:23", "link": "http://arxiv.org/abs/1603.02845v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lexical bundles in computational linguistics academic literature", "abstract": "In this study we analyzed a corpus of 8 million words academic literature\nfrom Computational lingustics' academic literature. the lexical bundles from\nthis corpus are categorized based on structures and functions.", "published": "2016-03-09 14:56:44", "link": "http://arxiv.org/abs/1603.02905v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Implicit Discourse Relation Classification via Multi-Task Neural\n  Networks", "abstract": "Without discourse connectives, classifying implicit discourse relations is a\nchallenging task and a bottleneck for building a practical discourse parser.\nPrevious research usually makes use of one kind of discourse framework such as\nPDTB or RST to improve the classification performance on discourse relations.\nActually, under different discourse annotation frameworks, there exist multiple\ncorpora which have internal connections. To exploit the combination of\ndifferent discourse corpora, we design related discourse classification tasks\nspecific to a corpus, and propose a novel Convolutional Neural Network embedded\nmulti-task learning system to synthesize these tasks by learning both unique\nand shared representations for each task. The experimental results on the PDTB\nimplicit discourse relation classification task demonstrate that our model\nachieves significant gains over baseline systems.", "published": "2016-03-09 03:13:37", "link": "http://arxiv.org/abs/1603.02776v1", "categories": ["cs.CL", "cs.AI", "cs.NE"], "primary_category": "cs.CL"}
