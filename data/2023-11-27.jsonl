{"title": "A Corpus for Named Entity Recognition in Chinese Novels with\n  Multi-genres", "abstract": "Entities like person, location, organization are important for literary text\nanalysis. The lack of annotated data hinders the progress of named entity\nrecognition (NER) in literary domain. To promote the research of literary NER,\nwe build the largest multi-genre literary NER corpus containing 263,135\nentities in 105,851 sentences from 260 online Chinese novels spanning 13\ndifferent genres. Based on the corpus, we investigate characteristics of\nentities from different genres. We propose several baseline NER models and\nconduct cross-genre and cross-domain experiments. Experimental results show\nthat genre difference significantly impact NER performance though not as much\nas domain difference like literary domain and news domain. Compared with NER in\nnews domain, literary NER still needs much improvement and the\nOut-of-Vocabulary (OOV) problem is more challenging due to the high variety of\nentities in literary works. Our data and models are open-sourced at\nhttps://github.com/hjzhao73/MultiGenre-ChineseNovel", "published": "2023-11-27 03:08:41", "link": "http://arxiv.org/abs/2311.15509v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Overview of the VLSP 2022 -- Abmusu Shared Task: A Data Challenge for\n  Vietnamese Abstractive Multi-document Summarization", "abstract": "This paper reports the overview of the VLSP 2022 - Vietnamese abstractive\nmulti-document summarization (Abmusu) shared task for Vietnamese News. This\ntask is hosted at the 9$^{th}$ annual workshop on Vietnamese Language and\nSpeech Processing (VLSP 2022). The goal of Abmusu shared task is to develop\nsummarization systems that could create abstractive summaries automatically for\na set of documents on a topic. The model input is multiple news documents on\nthe same topic, and the corresponding output is a related abstractive summary.\nIn the scope of Abmusu shared task, we only focus on Vietnamese news\nsummarization and build a human-annotated dataset of 1,839 documents in 600\nclusters, collected from Vietnamese news in 8 categories. Participated models\nare evaluated and ranked in terms of \\texttt{ROUGE2-F1} score, the most typical\nevaluation metric for document summarization problem.", "published": "2023-11-27 04:01:13", "link": "http://arxiv.org/abs/2311.15525v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The effect of source disclosure on evaluation of AI-generated messages:\n  A two-part study", "abstract": "Advancements in artificial intelligence (AI) over the last decade demonstrate\nthat machines can exhibit communicative behavior and influence how humans\nthink, feel, and behave. In fact, the recent development of ChatGPT has shown\nthat large language models (LLMs) can be leveraged to generate high-quality\ncommunication content at scale and across domains, suggesting that they will be\nincreasingly used in practice. However, many questions remain about how knowing\nthe source of the messages influences recipients' evaluation of and preference\nfor AI-generated messages compared to human-generated messages. This paper\ninvestigated this topic in the context of vaping prevention messaging. In Study\n1, which was pre-registered, we examined the influence of source disclosure on\npeople's evaluation of AI-generated health prevention messages compared to\nhuman-generated messages. We found that source disclosure (i.e., labeling the\nsource of a message as AI vs. human) significantly impacted the evaluation of\nthe messages but did not significantly alter message rankings. In a follow-up\nstudy (Study 2), we examined how the influence of source disclosure may vary by\nthe participants' negative attitudes towards AI. We found a significant\nmoderating effect of negative attitudes towards AI on message evaluation, but\nnot for message selection. However, for those with moderate levels of negative\nattitudes towards AI, source disclosure decreased the preference for\nAI-generated messages. Overall, the results of this series of studies showed a\nslight bias against AI-generated messages once the source was disclosed, adding\nto the emerging area of study that lies at the intersection of AI and\ncommunication.", "published": "2023-11-27 05:20:47", "link": "http://arxiv.org/abs/2311.15544v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FreeAL: Towards Human-Free Active Learning in the Era of Large Language\n  Models", "abstract": "Collecting high-quality labeled data for model training is notoriously\ntime-consuming and labor-intensive for various NLP tasks. While copious\nsolutions, such as active learning for small language models (SLMs) and\nprevalent in-context learning in the era of large language models (LLMs), have\nbeen proposed and alleviate the labeling burden to some extent, their\nperformances are still subject to human intervention. It is still underexplored\nhow to reduce the annotation cost in the LLMs era. To bridge this, we\nrevolutionize traditional active learning and propose an innovative\ncollaborative learning framework FreeAL to interactively distill and filter the\ntask-specific knowledge from LLMs. During collaborative training, an LLM serves\nas an active annotator inculcating its coarse-grained knowledge, while a\ndownstream SLM is incurred as a student to filter out high-quality in-context\nsamples to feedback LLM for the subsequent label refinery. Extensive\nexperiments on eight benchmark datasets demonstrate that FreeAL largely\nenhances the zero-shot performances for both SLM and LLM without any human\nsupervision. The code is available at https://github.com/Justherozen/FreeAL .", "published": "2023-11-27 08:23:08", "link": "http://arxiv.org/abs/2311.15614v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The WebCrow French Crossword Solver", "abstract": "Crossword puzzles are one of the most popular word games, played in different\nlanguages all across the world, where riddle style can vary significantly from\none country to another. Automated crossword resolution is challenging, and\ntypical solvers rely on large databases of previously solved crosswords. In\nthis work, we extend WebCrow 2.0, an automatic crossword solver, to French,\nmaking it the first program for crossword solving in the French language. To\ncope with the lack of a large repository of clue-answer crossword data, WebCrow\n2.0 exploits multiple modules, called experts, that retrieve candidate answers\nfrom heterogeneous resources, such as the web, knowledge graphs, and linguistic\nrules. We compared WebCrow's performance against humans in two different\nchallenges. Despite the limited amount of past crosswords, French WebCrow was\ncompetitive, actually outperforming humans in terms of speed and accuracy, thus\nproving its capabilities to generalize to new languages.", "published": "2023-11-27 08:45:31", "link": "http://arxiv.org/abs/2311.15626v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MoDS: Model-oriented Data Selection for Instruction Tuning", "abstract": "Instruction tuning has become the de facto method to equip large language\nmodels (LLMs) with the ability of following user instructions. Usually,\nhundreds of thousands or millions of instruction-following pairs are employed\nto fine-tune the foundation LLMs. Recently, some studies show that a small\nnumber of high-quality instruction data is enough. However, how to select\nappropriate instruction data for a given LLM is still an open problem. To\naddress this problem, in this paper we present a model-oriented data selection\n(MoDS) approach, which selects instruction data based on a new criteria\nconsidering three aspects: quality, coverage and necessity. First, our approach\nutilizes a quality evaluation model to filter out the high-quality subset from\nthe original instruction dataset, and then designs an algorithm to further\nselect from the high-quality subset a seed instruction dataset with good\ncoverage. The seed dataset is applied to fine-tune the foundation LLM to obtain\nan initial instruction-following LLM. Finally, we develop a necessity\nevaluation model to find out the instruction data which are performed badly in\nthe initial instruction-following LLM and consider them necessary instructions\nto further improve the LLMs. In this way, we can get a small high-quality,\nbroad-coverage and high-necessity subset from the original instruction\ndatasets. Experimental results show that, the model fine-tuned with 4,000\ninstruction pairs selected by our approach could perform better than the model\nfine-tuned with the full original dataset which includes 214k instruction data.", "published": "2023-11-27 09:33:13", "link": "http://arxiv.org/abs/2311.15653v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge Unlearning for LLMs: Tasks, Methods, and Challenges", "abstract": "In recent years, large language models (LLMs) have spurred a new research\nparadigm in natural language processing. Despite their excellent capability in\nknowledge-based question answering and reasoning, their potential to retain\nfaulty or even harmful knowledge poses risks of malicious application. The\nchallenge of mitigating this issue and transforming these models into purer\nassistants is crucial for their widespread applicability. Unfortunately,\nRetraining LLMs repeatedly to eliminate undesirable knowledge is impractical\ndue to their immense parameters. Knowledge unlearning, derived from analogous\nstudies on machine unlearning, presents a promising avenue to address this\nconcern and is notably advantageous in the context of LLMs. It allows for the\nremoval of harmful knowledge in an efficient manner, without affecting\nunrelated knowledge in the model. To this end, we provide a survey of knowledge\nunlearning in the era of LLMs. Firstly, we formally define the knowledge\nunlearning problem and distinguish it from related works. Subsequently, we\ncategorize existing knowledge unlearning methods into three classes: those\nbased on parameter optimization, parameter merging, and in-context learning,\nand introduce details of these unlearning methods. We further present\nevaluation datasets used in existing methods, and finally conclude this survey\nby presenting the ongoing challenges and future directions.", "published": "2023-11-27 12:37:51", "link": "http://arxiv.org/abs/2311.15766v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging deep active learning to identify low-resource mobility\n  functioning information in public clinical notes", "abstract": "Function is increasingly recognized as an important indicator of whole-person\nhealth, although it receives little attention in clinical natural language\nprocessing research. We introduce the first public annotated dataset\nspecifically on the Mobility domain of the International Classification of\nFunctioning, Disability and Health (ICF), aiming to facilitate automatic\nextraction and analysis of functioning information from free-text clinical\nnotes. We utilize the National NLP Clinical Challenges (n2c2) research dataset\nto construct a pool of candidate sentences using keyword expansion. Our active\nlearning approach, using query-by-committee sampling weighted by density\nrepresentativeness, selects informative sentences for human annotation. We\ntrain BERT and CRF models, and use predictions from these models to guide the\nselection of new sentences for subsequent annotation iterations. Our final\ndataset consists of 4,265 sentences with a total of 11,784 entities, including\n5,511 Action entities, 5,328 Mobility entities, 306 Assistance entities, and\n639 Quantification entities. The inter-annotator agreement (IAA), averaged over\nall entity types, is 0.72 for exact matching and 0.91 for partial matching. We\nalso train and evaluate common BERT models and state-of-the-art Nested NER\nmodels. The best F1 scores are 0.84 for Action, 0.7 for Mobility, 0.62 for\nAssistance, and 0.71 for Quantification. Empirical results demonstrate\npromising potential of NER models to accurately extract mobility functioning\ninformation from clinical text. The public availability of our annotated\ndataset will facilitate further research to comprehensively capture functioning\ninformation in electronic health records (EHRs).", "published": "2023-11-27 15:53:11", "link": "http://arxiv.org/abs/2311.15946v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BERT Goes Off-Topic: Investigating the Domain Transfer Challenge using\n  Genre Classification", "abstract": "While performance of many text classification tasks has been recently\nimproved due to Pre-trained Language Models (PLMs), in this paper we show that\nthey still suffer from a performance gap when the underlying distribution of\ntopics changes. For example, a genre classifier trained on \\textit{political}\ntopics often fails when tested on documents about \\textit{sport} or\n\\textit{medicine}. In this work, we quantify this phenomenon empirically with a\nlarge corpus and a large set of topics. Consequently, we verify that domain\ntransfer remains challenging both for classic PLMs, such as BERT, and for\nmodern large models, such as GPT-3. We also suggest and successfully test a\npossible remedy: after augmenting the training dataset with\ntopically-controlled synthetic texts, the F1 score improves by up to 50\\% for\nsome topics, nearing on-topic training results, while others show little to no\nimprovement. While our empirical results focus on genre classification, our\nmethodology is applicable to other classification tasks such as gender,\nauthorship, or sentiment classification. The code and data to replicate the\nexperiments are available at https://github.com/dminus1/genre", "published": "2023-11-27 18:53:31", "link": "http://arxiv.org/abs/2311.16083v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DUnE: Dataset for Unified Editing", "abstract": "Even the most advanced language models remain susceptible to errors\nnecessitating to modify these models without initiating a comprehensive\nretraining process. Model editing refers to the modification of a model's\nknowledge or representations in a manner that produces the desired outcomes.\nPrior research primarily centered around editing factual data e.g. \"Messi plays\nfor Inter Miami\" confining the definition of an edit to a knowledge triplet\ni.e. (subject, object, relation). However, as the applications of language\nmodels expand, so do the diverse ways in which we wish to edit and refine their\noutputs. In this study, we broaden the scope of the editing problem to include\nan array of editing cases such as debiasing and rectifying reasoning errors and\ndefine an edit as any natural language expression that solicits a change in the\nmodel's outputs. We are introducing DUnE-an editing benchmark where edits are\nnatural language sentences and propose that DUnE presents a challenging yet\nrelevant task. To substantiate this claim, we conduct an extensive series of\nexperiments testing various editing approaches to address DUnE, demonstrating\ntheir respective strengths and weaknesses. We show that retrieval-augmented\nlanguage modeling can outperform specialized editing techniques and neither set\nof approaches has fully solved the generalized editing problem covered by our\nbenchmark.", "published": "2023-11-27 18:56:14", "link": "http://arxiv.org/abs/2311.16087v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reducing Gender Bias in Machine Translation through Counterfactual Data\n  Generation", "abstract": "Recent advances in neural methods have led to substantial improvement in the\nquality of Neural Machine Translation (NMT) systems. However, these systems\nfrequently produce translations with inaccurate gender (Stanovsky et al.,\n2019), which can be traced to bias in training data. Saunders and Byrne (2020)\ntackle this problem with a handcrafted dataset containing balanced gendered\nprofession words. By using this data to fine-tune an existing NMT model, they\nshow that gender bias can be significantly mitigated, albeit at the expense of\ntranslation quality due to catastrophic forgetting. They recover some of the\nlost quality with modified training objectives or additional models at\ninference. We find, however, that simply supplementing the handcrafted dataset\nwith a random sample from the base model training corpus is enough to\nsignificantly reduce the catastrophic forgetting. We also propose a novel\ndomain-adaptation technique that leverages in-domain data created with the\ncounterfactual data generation techniques proposed by Zmigrod et al. (2019) to\nfurther improve accuracy on the WinoMT challenge test set without significant\nloss in translation quality. We show its effectiveness in NMT systems from\nEnglish into three morphologically rich languages French, Spanish, and Italian.\nThe relevant dataset and code will be available at Github.", "published": "2023-11-27 23:03:01", "link": "http://arxiv.org/abs/2311.16362v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Optimizing and Fine-tuning Large Language Model for Urban Renewal", "abstract": "This study aims to innovatively explore adaptive applications of large\nlanguage models (LLM) in urban renewal. It also aims to improve its performance\nand text generation quality for knowledge question-answering (QA) tasks. Based\non the ChatGLM, we automatically generate QA datasets using urban renewal\nscientific literature corpora in a self-instruct manner and then conduct joint\nfine-tuning training on the model using the Prefix and LoRA fine-tuning methods\nto create an LLM for urban renewal. By guiding the LLM to automatically\ngenerate QA data based on prompt words and given text, it is possible to\nquickly obtain datasets in the urban renewal field and provide data support for\nthe fine-tuning training of LLMs. The experimental results show that the joint\nfine-tuning training method proposed in this study can significantly improve\nthe performance of LLM on the QA tasks. Compared with LoRA fine-tuning, the\nmethod improves the Bleu and Rouge metrics on the test by about 5%; compared\nwith the model before fine-tuning, the method improves the Bleu and Rouge\nmetrics by about 15%-20%. This study demonstrates the effectiveness and\nsuperiority of the joint fine-tuning method using Prefix and LoRA for ChatGLM\nin the urban renewal knowledge QA tasks. It provides a new approach for\nfine-tuning LLMs on urban renewal-related tasks.", "published": "2023-11-27 02:17:11", "link": "http://arxiv.org/abs/2311.15490v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving Word Sense Disambiguation in Neural Machine Translation with\n  Salient Document Context", "abstract": "Lexical ambiguity is a challenging and pervasive problem in machine\ntranslation (\\mt). We introduce a simple and scalable approach to resolve\ntranslation ambiguity by incorporating a small amount of extra-sentential\ncontext in neural \\mt. Our approach requires no sense annotation and no change\nto standard model architectures. Since actual document context is not available\nfor the vast majority of \\mt training data, we collect related sentences for\neach input to construct pseudo-documents. Salient words from pseudo-documents\nare then encoded as a prefix to each source sentence to condition the\ngeneration of the translation. To evaluate, we release \\docmucow, a challenge\nset for translation disambiguation based on the English-German \\mucow\n\\cite{raganato-etal-2020-evaluation} augmented with document IDs. Extensive\nexperiments show that our method translates ambiguous source words better than\nstrong sentence-level baselines and comparable document-level baselines while\nreducing training costs.", "published": "2023-11-27 03:05:48", "link": "http://arxiv.org/abs/2311.15507v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Comparative and Experimental Study on Automatic Question Answering\n  Systems and its Robustness against Word Jumbling", "abstract": "Question answer generation using Natural Language Processing models is\nubiquitous in the world around us. It is used in many use cases such as the\nbuilding of chat bots, suggestive prompts in google search and also as a way of\nnavigating information in banking mobile applications etc. It is highly\nrelevant because a frequently asked questions (FAQ) list can only have a finite\namount of questions but a model which can perform question answer generation\ncould be able to answer completely new questions that are within the scope of\nthe data. This helps us to be able to answer new questions accurately as long\nas it is a relevant question. In commercial applications, it can be used to\nincrease customer satisfaction and ease of usage. However a lot of data is\ngenerated by humans so it is susceptible to human error and this can adversely\naffect the model's performance and we are investigating this through our work", "published": "2023-11-27 03:17:09", "link": "http://arxiv.org/abs/2311.15513v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Noisy Self-Training with Synthetic Queries for Dense Retrieval", "abstract": "Although existing neural retrieval models reveal promising results when\ntraining data is abundant and the performance keeps improving as training data\nincreases, collecting high-quality annotated data is prohibitively costly. To\nthis end, we introduce a novel noisy self-training framework combined with\nsynthetic queries, showing that neural retrievers can be improved in a\nself-evolution manner with no reliance on any external models. Experimental\nresults show that our method improves consistently over existing methods on\nboth general-domain (e.g., MS-MARCO) and out-of-domain (i.e., BEIR) retrieval\nbenchmarks. Extra analysis on low-resource settings reveals that our method is\ndata efficient and outperforms competitive baselines, with as little as 30% of\nlabelled training data. Further extending the framework for reranker training\ndemonstrates that the proposed method is general and yields additional gains on\ntasks of diverse domains.\\footnote{Source code is available at\n\\url{https://github.com/Fantabulous-J/Self-Training-DPR}}", "published": "2023-11-27 06:19:50", "link": "http://arxiv.org/abs/2311.15563v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Boot and Switch: Alternating Distillation for Zero-Shot Dense Retrieval", "abstract": "Neural 'dense' retrieval models are state of the art for many datasets,\nhowever these models often exhibit limited domain transfer ability. Existing\napproaches to adaptation are unwieldy, such as requiring explicit supervision,\ncomplex model architectures, or massive external models. We present\n$\\texttt{ABEL}$, a simple but effective unsupervised method to enhance passage\nretrieval in zero-shot settings. Our technique follows a straightforward loop:\na dense retriever learns from supervision signals provided by a reranker, and\nsubsequently, the reranker is updated based on feedback from the improved\nretriever. By iterating this loop, the two components mutually enhance one\nanother's performance. Experimental results demonstrate that our unsupervised\n$\\texttt{ABEL}$ model outperforms both leading supervised and unsupervised\nretrievers on the BEIR benchmark. Meanwhile, it exhibits strong adaptation\nabilities to tasks and domains that were unseen during training. By either\nfine-tuning $\\texttt{ABEL}$ on labelled data or integrating it with existing\nsupervised dense retrievers, we achieve state-of-the-art\nresults.\\footnote{Source code is available at\n\\url{https://github.com/Fantabulous-J/BootSwitch}.}", "published": "2023-11-27 06:22:57", "link": "http://arxiv.org/abs/2311.15564v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "EgoThink: Evaluating First-Person Perspective Thinking Capability of\n  Vision-Language Models", "abstract": "Vision-language models (VLMs) have recently shown promising results in\ntraditional downstream tasks. Evaluation studies have emerged to assess their\nabilities, with the majority focusing on the third-person perspective, and only\na few addressing specific tasks from the first-person perspective. However, the\ncapability of VLMs to \"think\" from a first-person perspective, a crucial\nattribute for advancing autonomous agents and robotics, remains largely\nunexplored. To bridge this research gap, we introduce EgoThink, a novel visual\nquestion-answering benchmark that encompasses six core capabilities with twelve\ndetailed dimensions. The benchmark is constructed using selected clips from\negocentric videos, with manually annotated question-answer pairs containing\nfirst-person information. To comprehensively assess VLMs, we evaluate eighteen\npopular VLMs on EgoThink. Moreover, given the open-ended format of the answers,\nwe use GPT-4 as the automatic judge to compute single-answer grading.\nExperimental results indicate that although GPT-4V leads in numerous\ndimensions, all evaluated VLMs still possess considerable potential for\nimprovement in first-person perspective tasks. Meanwhile, enlarging the number\nof trainable parameters has the most significant impact on model performance on\nEgoThink. In conclusion, EgoThink serves as a valuable addition to existing\nevaluation benchmarks for VLMs, providing an indispensable resource for future\nresearch in the realm of embodied artificial intelligence and robotics.", "published": "2023-11-27 07:44:25", "link": "http://arxiv.org/abs/2311.15596v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "InfoPattern: Unveiling Information Propagation Patterns in Social Media", "abstract": "Social media play a significant role in shaping public opinion and\ninfluencing ideological communities through information propagation. Our demo\nInfoPattern centers on the interplay between language and human ideology. The\ndemo (Code: https://github.com/blender-nlp/InfoPattern ) is capable of: (1) red\nteaming to simulate adversary responses from opposite ideology communities; (2)\nstance detection to identify the underlying political sentiments in each\nmessage; (3) information propagation graph discovery to reveal the evolution of\nclaims across various communities over time. (Live Demo:\nhttps://incas.csl.illinois.edu/blender/About )", "published": "2023-11-27 09:12:35", "link": "http://arxiv.org/abs/2311.15642v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Cerbero-7B: A Leap Forward in Language-Specific LLMs Through Enhanced\n  Chat Corpus Generation and Evaluation", "abstract": "This study introduces a novel approach for generating high-quality,\nlanguage-specific chat corpora using a self-chat mechanism. We combine a\ngenerator LLM for creating new samples and an embedder LLM to ensure diversity.\nA new Masked Language Modelling (MLM) model-based quality assessment metric is\nproposed for evaluating and filtering the corpora. Utilizing the llama2-70b as\nthe generator and a multilingual sentence transformer as embedder, we generate\nan Italian chat corpus and refine the Fauno corpus, which is based on\ntranslated English ChatGPT self-chat data. The refinement uses structural\nassertions and Natural Language Processing techniques. Both corpora undergo a\ncomprehensive quality evaluation using the proposed MLM model-based quality\nmetric. The Italian LLM fine-tuned with these corpora demonstrates\nsignificantly enhanced language comprehension and question-answering skills.\nThe resultant model, cerbero-7b, establishes a new state-of-the-art for Italian\nLLMs. This approach marks a substantial advancement in the development of\nlanguage-specific LLMs, with a special emphasis on augmenting corpora for\nunderrepresented languages like Italian.", "published": "2023-11-27 10:34:55", "link": "http://arxiv.org/abs/2311.15698v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Italian Crossword Generator: Enhancing Education through Interactive\n  Word Puzzles", "abstract": "Educational crosswords offer numerous benefits for students, including\nincreased engagement, improved understanding, critical thinking, and memory\nretention. Creating high-quality educational crosswords can be challenging, but\nrecent advances in natural language processing and machine learning have made\nit possible to use language models to generate nice wordplays. The exploitation\nof cutting-edge language models like GPT3-DaVinci, GPT3-Curie, GPT3-Babbage,\nGPT3-Ada, and BERT-uncased has led to the development of a comprehensive system\nfor generating and verifying crossword clues. A large dataset of clue-answer\npairs was compiled to fine-tune the models in a supervised manner to generate\noriginal and challenging clues from a given keyword. On the other hand, for\ngenerating crossword clues from a given text, Zero/Few-shot learning techniques\nwere used to extract clues from the input text, adding variety and creativity\nto the puzzles. We employed the fine-tuned model to generate data and labeled\nthe acceptability of clue-answer parts with human supervision. To ensure\nquality, we developed a classifier by fine-tuning existing language models on\nthe labeled dataset. Conversely, to assess the quality of clues generated from\nthe given text using zero/few-shot learning, we employed a zero-shot learning\napproach to check the quality of generated clues. The results of the evaluation\nhave been very promising, demonstrating the effectiveness of the approach in\ncreating high-standard educational crosswords that offer students engaging and\nrewarding learning experiences.", "published": "2023-11-27 11:17:29", "link": "http://arxiv.org/abs/2311.15723v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Data Generation for Post-OCR correction of Cyrillic handwriting", "abstract": "This paper introduces a novel approach to post-Optical Character Recognition\nCorrection (POC) for handwritten Cyrillic text, addressing a significant gap in\ncurrent research methodologies. This gap is due to the lack of large text\ncorporas that provide OCR errors for further training of language-based POC\nmodels, which are demanding in terms of corpora size. Our study primarily\nfocuses on the development and application of a synthetic handwriting\ngeneration engine based on B\\'ezier curves. Such an engine generates highly\nrealistic handwritten text in any amounts, which we utilize to create a\nsubstantial dataset by transforming Russian text corpora sourced from the\ninternet. We apply a Handwritten Text Recognition (HTR) model to this dataset\nto identify OCR errors, forming the basis for our POC model training. The\ncorrection model is trained on a 90-symbol input context, utilizing a\npre-trained T5 architecture with a seq2seq correction task. We evaluate our\napproach on HWR200 and School_notebooks_RU datasets as they provide significant\nchallenges in the HTR domain. Furthermore, POC can be used to highlight errors\nfor teachers, evaluating student performance. This can be done simply by\ncomparing sentences before and after correction, displaying differences in\ntext. Our primary contribution lies in the innovative use of B\\'ezier curves\nfor Cyrillic text generation and subsequent error correction using a\nspecialized POC model. We validate our approach by presenting Word Accuracy\nRate (WAR) and Character Accuracy Rate (CAR) results, both with and without\npost-OCR correction, using real open corporas of handwritten Cyrillic text.\nThese results, coupled with our methodology, are designed to be reproducible,\npaving the way for further advancements in the field of OCR and handwritten\ntext analysis. Paper contributions can be found in\nhttps://github.com/dbrainio/CyrillicHandwritingPOC", "published": "2023-11-27 15:01:26", "link": "http://arxiv.org/abs/2311.15896v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "WorldSense: A Synthetic Benchmark for Grounded Reasoning in Large\n  Language Models", "abstract": "We propose WorldSense, a benchmark designed to assess the extent to which\nLLMs are consistently able to sustain tacit world models, by testing how they\ndraw simple inferences from descriptions of simple arrangements of entities.\nWorldsense is a synthetic benchmark with three problem types, each with their\nown trivial control, which explicitly avoids bias by decorrelating the abstract\nstructure of problems from the vocabulary and expressions, and by decorrelating\nall problem subparts with the correct response. We run our benchmark on three\nstate-of-the-art chat-LLMs (GPT3.5, GPT4 and Llama2-chat) and show that these\nmodels make errors even with as few as three objects. Furthermore, they have\nquite heavy response biases, preferring certain responses irrespective of the\nquestion. Errors persist even with chain-of-thought prompting and in-context\nlearning. Lastly, we show that while finetuning on similar problems does result\nin substantial improvements -- within- and out-of-distribution -- the finetuned\nmodels do not generalise beyond a constraint problem space.", "published": "2023-11-27 15:38:17", "link": "http://arxiv.org/abs/2311.15930v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Tell2Design: A Dataset for Language-Guided Floor Plan Generation", "abstract": "We consider the task of generating designs directly from natural language\ndescriptions, and consider floor plan generation as the initial research area.\nLanguage conditional generative models have recently been very successful in\ngenerating high-quality artistic images. However, designs must satisfy\ndifferent constraints that are not present in generating artistic images,\nparticularly spatial and relational constraints. We make multiple contributions\nto initiate research on this task. First, we introduce a novel dataset,\n\\textit{Tell2Design} (T2D), which contains more than $80k$ floor plan designs\nassociated with natural language instructions. Second, we propose a\nSequence-to-Sequence model that can serve as a strong baseline for future\nresearch. Third, we benchmark this task with several text-conditional image\ngeneration models. We conclude by conducting human evaluations on the generated\nsamples and providing an analysis of human performance. We hope our\ncontributions will propel the research on language-guided design generation\nforward.", "published": "2023-11-27 15:49:29", "link": "http://arxiv.org/abs/2311.15941v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "A Quantitative Approach to Understand Self-Supervised Models as\n  Cross-lingual Feature Extractors", "abstract": "In this work, we study the features extracted by English self-supervised\nlearning (SSL) models in cross-lingual contexts and propose a new metric to\npredict the quality of feature representations. Using automatic speech\nrecognition (ASR) as a downstream task, we analyze the effect of model size,\ntraining objectives, and model architecture on the models' performance as a\nfeature extractor for a set of topologically diverse corpora. We develop a\nnovel metric, the Phonetic-Syntax Ratio (PSR), to measure the phonetic and\nsynthetic information in the extracted representations using deep generalized\ncanonical correlation analysis. Results show the contrastive loss in the\nwav2vec2.0 objective facilitates more effective cross-lingual feature\nextraction. There is a positive correlation between PSR scores and ASR\nperformance, suggesting that phonetic information extracted by monolingual SSL\nmodels can be used for downstream tasks in cross-lingual settings. The proposed\nmetric is an effective indicator of the quality of the representations and can\nbe useful for model selection.", "published": "2023-11-27 15:58:28", "link": "http://arxiv.org/abs/2311.15954v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Novel Preprocessing Technique for Data Embedding in Engineering Code\n  Generation Using Large Language Model", "abstract": "We present four main contributions to enhance the performance of Large\nLanguage Models (LLMs) in generating domain-specific code: (i) utilizing\nLLM-based data splitting and data renovation techniques to improve the semantic\nrepresentation of embeddings' space; (ii) introducing the Chain of Density for\nRenovation Credibility (CoDRC), driven by LLMs, and the Adaptive Text\nRenovation (ATR) algorithm for assessing data renovation reliability; (iii)\ndeveloping the Implicit Knowledge Expansion and Contemplation (IKEC) Prompt\ntechnique; and (iv) effectively refactoring existing scripts to generate new\nand high-quality scripts with LLMs. By using engineering simulation software\nRedHawk-SC as a case study, we demonstrate the effectiveness of our data\npre-processing method for expanding and categorizing scripts. When combined\nwith IKEC, these techniques enhance the Retrieval-Augmented Generation (RAG)\nmethod in retrieving more relevant information, ultimately achieving a 73.33%\n\"Percentage of Correct Lines\" for code generation problems in MapReduce\napplications.", "published": "2023-11-27 19:17:39", "link": "http://arxiv.org/abs/2311.16267v2", "categories": ["cs.CL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Student Mastery or AI Deception? Analyzing ChatGPT's Assessment\n  Proficiency and Evaluating Detection Strategies", "abstract": "Generative AI systems such as ChatGPT have a disruptive effect on learning\nand assessment. Computer science requires practice to develop skills in problem\nsolving and programming that are traditionally developed using assignments.\nGenerative AI has the capability of completing these assignments for students\nwith high accuracy, which dramatically increases the potential for academic\nintegrity issues and students not achieving desired learning outcomes. This\nwork investigates the performance of ChatGPT by evaluating it across three\ncourses (CS1,CS2,databases). ChatGPT completes almost all introductory\nassessments perfectly. Existing detection methods, such as MOSS and JPlag\n(based on similarity metrics) and GPTzero (AI detection), have mixed success in\nidentifying AI solutions. Evaluating instructors and teaching assistants using\nheuristics to distinguish between student and AI code shows that their\ndetection is not sufficiently accurate. These observations emphasize the need\nfor adapting assessments and improved detection methods.", "published": "2023-11-27 20:10:13", "link": "http://arxiv.org/abs/2311.16292v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Influence Scores at Scale for Efficient Language Data Sampling", "abstract": "Modern ML systems ingest data aggregated from diverse sources, such as\nsynthetic, human-annotated, and live customer traffic. Understanding\n\\textit{which} examples are important to the performance of a learning\nalgorithm is crucial for efficient model training. Recently, a growing body of\nliterature has given rise to various \"influence scores,\" which use training\nartifacts such as model confidence or checkpointed gradients to identify\nimportant subsets of data. However, these methods have primarily been developed\nin computer vision settings, and it remains unclear how well they generalize to\nlanguage-based tasks using pretrained models.\n  In this paper, we explore the applicability of influence scores in language\nclassification tasks. We evaluate a diverse subset of these scores on the SNLI\ndataset by quantifying accuracy changes in response to pruning training data\nthrough random and influence-score-based sampling. We then stress-test one of\nthe scores -- \"variance of gradients\" (VoG) from Agarwal et al. (2022) -- in an\nNLU model stack that was exposed to dynamic user speech patterns in a voice\nassistant type of setting. Our experiments demonstrate that in many cases,\nencoder-based language models can be finetuned on roughly 50% of the original\ndata without degradation in performance metrics. Along the way, we summarize\nlessons learned from applying out-of-the-box implementations of influence\nscores, quantify the effects of noisy and class-imbalanced data, and offer\nrecommendations on score-based sampling for better accuracy and training\nefficiency.", "published": "2023-11-27 20:19:22", "link": "http://arxiv.org/abs/2311.16298v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Comprehensive Benchmarking of Entropy and Margin Based Scoring Metrics\n  for Data Selection", "abstract": "While data selection methods have been studied extensively in active\nlearning, data pruning, and data augmentation settings, there is little\nevidence for the efficacy of these methods in industry scale settings,\nparticularly in low-resource languages. Our work presents ways of assessing\nprospective training examples in those settings for their \"usefulness\" or\n\"difficulty\". We also demonstrate how these measures can be used in selecting\nimportant examples for training supervised machine learning models. We\nprimarily experiment with entropy and Error L2-Norm (EL2N) scores. We use these\nmetrics to curate high quality datasets from a large pool of \\textit{Weak\nSignal Labeled} data, which assigns no-defect high confidence hypotheses during\ninference as ground truth labels. We then conduct training data augmentation\nexperiments using these de-identified datasets and demonstrate that score-based\nselection can result in a 2% decrease in semantic error rate and 4%-7% decrease\nin domain classification error rate when compared to the baseline technique of\nrandom selection.", "published": "2023-11-27 20:33:54", "link": "http://arxiv.org/abs/2311.16302v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Releasing the CRaQAn (Coreference Resolution in Question-Answering): An\n  open-source dataset and dataset creation methodology using\n  instruction-following models", "abstract": "Instruction-following language models demand robust methodologies for\ninformation retrieval to augment instructions for question-answering\napplications. A primary challenge is the resolution of coreferences in the\ncontext of chunking strategies for long documents. The critical barrier to\nexperimentation of handling coreferences is a lack of open source datasets,\nspecifically in question-answering tasks that require coreference resolution.\nIn this work we present our Coreference Resolution in Question-Answering\n(CRaQAn) dataset, an open-source dataset that caters to the nuanced information\nretrieval requirements of coreference resolution in question-answering tasks by\nproviding over 250 question-answer pairs containing coreferences. To develop\nthis dataset, we developed a novel approach for creating high-quality datasets\nusing an instruction-following model (GPT-4) and a Recursive Criticism and\nImprovement Loop.", "published": "2023-11-27 21:54:50", "link": "http://arxiv.org/abs/2311.16338v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ChartLlama: A Multimodal LLM for Chart Understanding and Generation", "abstract": "Multi-modal large language models have demonstrated impressive performances\non most vision-language tasks. However, the model generally lacks the\nunderstanding capabilities for specific domain data, particularly when it comes\nto interpreting chart figures. This is mainly due to the lack of relevant\nmulti-modal instruction tuning datasets. In this article, we create a\nhigh-quality instruction-tuning dataset leveraging GPT-4. We develop a\nmulti-step data generation process in which different steps are responsible for\ngenerating tabular data, creating chart figures, and designing instruction\ntuning data separately. Our method's flexibility enables us to generate\ndiverse, high-quality instruction-tuning data consistently and efficiently\nwhile maintaining a low resource expenditure. Additionally, it allows us to\nincorporate a wider variety of chart and task types not yet featured in\nexisting datasets. Next, we introduce ChartLlama, a multi-modal large language\nmodel that we've trained using our created dataset. ChartLlama outperforms all\nprior methods in ChartQA, Chart-to-text, and Chart-extraction evaluation\nbenchmarks. Additionally, ChartLlama significantly improves upon the baseline\nin our specially compiled chart dataset, which includes new chart and task\ntypes. The results of ChartLlama confirm the value and huge potential of our\nproposed data generation method in enhancing chart comprehension.", "published": "2023-11-27 15:20:23", "link": "http://arxiv.org/abs/2311.16483v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "DP-OPT: Make Large Language Model Your Privacy-Preserving Prompt\n  Engineer", "abstract": "Large Language Models (LLMs) have emerged as dominant tools for various\ntasks, particularly when tailored for a specific target by prompt tuning.\nNevertheless, concerns surrounding data privacy present obstacles due to the\ntuned prompts' dependency on sensitive private information. A practical\nsolution is to host a local LLM and optimize a soft prompt privately using\ndata. Yet, hosting a local model becomes problematic when model ownership is\nprotected. Alternative methods, like sending data to the model's provider for\ntraining, intensify these privacy issues facing an untrusted provider. In this\npaper, we present a novel solution called Differentially-Private Offsite Prompt\nTuning (DP-OPT) to address this challenge. Our approach involves tuning a\ndiscrete prompt on the client side and then applying it to the desired cloud\nmodels. We demonstrate that prompts suggested by LLMs themselves can be\ntransferred without compromising performance significantly. To ensure that the\nprompts do not leak private information, we introduce the first private prompt\ngeneration mechanism, by a differentially-private (DP) ensemble of in-context\nlearning with private demonstrations. With DP-OPT, generating\nprivacy-preserving prompts by Vicuna-7b can yield competitive performance\ncompared to non-private in-context learning on GPT3.5 or local private prompt\ntuning. Codes are available at https://github.com/VITA-Group/DP-OPT .", "published": "2023-11-27 02:01:10", "link": "http://arxiv.org/abs/2312.03724v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Interpretation modeling: Social grounding of sentences by reasoning over\n  their implicit moral judgments", "abstract": "The social and implicit nature of human communication ramifies readers'\nunderstandings of written sentences. Single gold-standard interpretations\nrarely exist, challenging conventional assumptions in natural language\nprocessing. This work introduces the interpretation modeling (IM) task which\ninvolves modeling several interpretations of a sentence's underlying semantics\nto unearth layers of implicit meaning. To obtain these, IM is guided by\nmultiple annotations of social relation and common ground - in this work\napproximated by reader attitudes towards the author and their understanding of\nmoral judgments subtly embedded in the sentence. We propose a number of\nmodeling strategies that rely on one-to-one and one-to-many generation methods\nthat take inspiration from the philosophical study of interpretation. A\nfirst-of-its-kind IM dataset is curated to support experiments and analyses.\nThe modeling results, coupled with scrutiny of the dataset, underline the\nchallenges of IM as conflicting and complex interpretations are socially\nplausible. This interplay of diverse readings is affirmed by automated and\nhuman evaluations on the generated interpretations. Finally, toxicity analyses\nin the generated interpretations demonstrate the importance of IM for refining\nfilters of content and assisting content moderators in safeguarding the safety\nin online discourse.", "published": "2023-11-27 07:50:55", "link": "http://arxiv.org/abs/2312.03726v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Content-Localization based System for Analyzing Sentiment and Hate\n  Behaviors in Low-Resource Dialectal Arabic: English to Levantine and Gulf", "abstract": "Even though online social movements can quickly become viral on social media,\nlanguages can be a barrier to timely monitoring and analyzing the underlying\nonline social behaviors (OSB). This is especially true for under-resourced\nlanguages on social media like dialectal Arabic; the primary language used by\nArabs on social media. Therefore, it is crucial to provide solutions to\nefficiently exploit resources from high-resourced languages to solve\nlanguage-dependent OSB analysis in under-resourced languages. This paper\nproposes to localize content of resources in high-resourced languages into\nunder-resourced Arabic dialects. Content localization goes beyond content\ntranslation that converts text from one language to another; content\nlocalization adapts culture, language nuances and regional preferences from one\nlanguage to a specific language/dialect. Automating understanding of the\nnatural and familiar day-to-day expressions in different regions, is the key to\nachieve a wider analysis of OSB especially for smart cities. In this paper, we\nutilize content-localization based neural machine translation to develop\nsentiment and hate classifiers for two low-resourced Arabic dialects: Levantine\nand Gulf. Not only this but we also leverage unsupervised learning to\nfacilitate the analysis of sentiment and hate predictions by inferring hidden\ntopics from the corresponding data and providing coherent interpretations of\nthose topics in their native language/dialects. The experimental evaluations\nand proof-of-concept COVID-19 case study on real data have validated the\neffectiveness of our proposed system in precisely distinguishing sentiments and\naccurately identifying hate content in both Levantine and Gulf Arabic dialects.\nOur findings shed light on the importance of considering the unique nature of\ndialects within the same language and ignoring the dialectal aspect would lead\nto misleading analysis.", "published": "2023-11-27 15:37:33", "link": "http://arxiv.org/abs/2312.03727v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Real Customization or Just Marketing: Are Customized Versions of Chat\n  GPT Useful?", "abstract": "Large Language Models (LLMs), as the case of OpenAI ChatGPT-4 Turbo, are\nrevolutionizing several industries, including higher education. In this\ncontext, LLMs can be personalized through a fine-tuning process to meet the\nstudent demands on every particular subject, like statistics. Recently, OpenAI\nhas launched the possibility to fine-tune their model with a natural language\nweb interface, enabling the possibility to create customized GPT version\ndeliberately conditioned to meet the demands of a specific task. The objective\nof this research is to assess the potential of the customized GPTs that have\nrecently been launched by OpenAI. After developing a Business Statistics\nVirtual Professor (BSVP), tailored for students at the Universidad Pontificia\nComillas, its behavior was evaluated and compared with that of ChatGPT-4 Turbo.\nThe results lead to several conclusions. Firstly, a substantial modification in\nthe style of communication was observed. Following the instructions it was\ntrained with, BSVP provided responses in a more relatable and friendly tone,\neven incorporating a few minor jokes. Secondly, and this is a matter of\nrelevance, when explicitly asked for something like, \"I would like to practice\na programming exercise similar to those in R practice 4,\" BSVP was capable of\nproviding a far superior response: having access to contextual documentation,\nit could fulfill the request, something beyond ChatGPT-4 Turbo's capabilities.\nOn the downside, the response times were generally higher. Lastly, regarding\noverall performance, quality, depth, and alignment with the specific content of\nthe course, no statistically significant differences were observed in the\nresponses between BSVP and ChatGPT-4 Turbo. It appears that customized\nassistants trained with prompts present advantages as virtual aids for\nstudents, yet they do not constitute a substantial improvement over ChatGPT-4\nTurbo.", "published": "2023-11-27 15:46:15", "link": "http://arxiv.org/abs/2312.03728v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Cognitive Dissonance: Why Do Language Model Outputs Disagree with\n  Internal Representations of Truthfulness?", "abstract": "Neural language models (LMs) can be used to evaluate the truth of factual\nstatements in two ways: they can be either queried for statement probabilities,\nor probed for internal representations of truthfulness. Past work has found\nthat these two procedures sometimes disagree, and that probes tend to be more\naccurate than LM outputs. This has led some researchers to conclude that LMs\n\"lie\" or otherwise encode non-cooperative communicative intents. Is this an\naccurate description of today's LMs, or can query-probe disagreement arise in\nother ways? We identify three different classes of disagreement, which we term\nconfabulation, deception, and heterogeneity. In many cases, the superiority of\nprobes is simply attributable to better calibration on uncertain answers rather\nthan a greater fraction of correct, high-confidence answers. In some cases,\nqueries and probes perform better on different subsets of inputs, and accuracy\ncan further be improved by ensembling the two. Code is available at\ngithub.com/lingo-mit/lm-truthfulness.", "published": "2023-11-27 18:59:14", "link": "http://arxiv.org/abs/2312.03729v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "FakeWatch ElectionShield: A Benchmarking Framework to Detect Fake News\n  for Credible US Elections", "abstract": "In today's technologically driven world, the spread of fake news,\nparticularly during crucial events such as elections, presents an increasing\nchallenge to the integrity of information. To address this challenge, we\nintroduce FakeWatch ElectionShield, an innovative framework carefully designed\nto detect fake news. We have created a novel dataset of North American\nelection-related news articles through a blend of advanced language models\n(LMs) and thorough human verification, for precision and relevance. We propose\na model hub of LMs for identifying fake news. Our goal is to provide the\nresearch community with adaptable and accurate classification models in\nrecognizing the dynamic nature of misinformation. Extensive evaluation of fake\nnews classifiers on our dataset and a benchmark dataset shows our that while\nstate-of-the-art LMs slightly outperform the traditional ML models, classical\nmodels are still competitive with their balance of accuracy, explainability,\nand computational efficiency. This research sets the foundation for future\nstudies to address misinformation related to elections.", "published": "2023-11-27 21:01:21", "link": "http://arxiv.org/abs/2312.03730v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Function-constrained Program Synthesis", "abstract": "This work introduces (1) a technique that allows large language models (LLMs)\nto leverage user-provided code when solving programming tasks and (2) a method\nto iteratively generate modular sub-functions that can aid future code\ngeneration attempts when the initial code generated by the LLM is inadequate.\nGenerating computer programs in general-purpose programming languages like\nPython poses a challenge for LLMs when instructed to use code provided in the\nprompt. Code-specific LLMs (e.g., GitHub Copilot, CodeLlama2) can generate code\ncompletions in real-time by drawing on all code available in a development\nenvironment. However, restricting code-specific LLMs to use only in-context\ncode is not straightforward, as the model is not explicitly instructed to use\nthe user-provided code and users cannot highlight precisely which snippets of\ncode the model should incorporate into its context. Moreover, current systems\nlack effective recovery methods, forcing users to iteratively re-prompt the\nmodel with modified prompts until a sufficient solution is reached. Our method\ndiffers from traditional LLM-powered code-generation by constraining\ncode-generation to an explicit function set and enabling recovery from failed\nattempts through automatically generated sub-functions. When the LLM cannot\nproduce working code, we generate modular sub-functions to aid subsequent\nattempts at generating functional code. A by-product of our method is a library\nof reusable sub-functions that can solve related tasks, imitating a software\nteam where efficiency scales with experience. We also introduce a new\n\"half-shot\" evaluation paradigm that provides tighter estimates of LLMs' coding\nabilities compared to traditional zero-shot evaluation. Our proposed evaluation\nmethod encourages models to output solutions in a structured format, decreasing\nsyntax errors that can be mistaken for poor coding ability.", "published": "2023-11-27 02:55:34", "link": "http://arxiv.org/abs/2311.15500v2", "categories": ["cs.LG", "cs.CL", "cs.PL"], "primary_category": "cs.LG"}
{"title": "Deficiency of Large Language Models in Finance: An Empirical Examination\n  of Hallucination", "abstract": "The hallucination issue is recognized as a fundamental deficiency of large\nlanguage models (LLMs), especially when applied to fields such as finance,\neducation, and law. Despite the growing concerns, there has been a lack of\nempirical investigation. In this paper, we provide an empirical examination of\nLLMs' hallucination behaviors in financial tasks. First, we empirically\ninvestigate LLM model's ability of explaining financial concepts and\nterminologies. Second, we assess LLM models' capacity of querying historical\nstock prices. Third, to alleviate the hallucination issue, we evaluate the\nefficacy of four practical methods, including few-shot learning, Decoding by\nContrasting Layers (DoLa), the Retrieval Augmentation Generation (RAG) method\nand the prompt-based tool learning method for a function to generate a query\ncommand. Finally, our major finding is that off-the-shelf LLMs experience\nserious hallucination behaviors in financial tasks. Therefore, there is an\nurgent need to call for research efforts in mitigating LLMs' hallucination.", "published": "2023-11-27 05:27:13", "link": "http://arxiv.org/abs/2311.15548v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "q-fin.ST"], "primary_category": "cs.CL"}
{"title": "Evaluating the Efficacy of Hybrid Deep Learning Models in Distinguishing\n  AI-Generated Text", "abstract": "My research investigates the use of cutting-edge hybrid deep learning models\nto accurately differentiate between AI-generated text and human writing. I\napplied a robust methodology, utilising a carefully selected dataset comprising\nAI and human texts from various sources, each tagged with instructions.\nAdvanced natural language processing techniques facilitated the analysis of\ntextual features. Combining sophisticated neural networks, the custom model\nenabled it to detect nuanced differences between AI and human content.", "published": "2023-11-27 06:26:53", "link": "http://arxiv.org/abs/2311.15565v3", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7", "I.2.7"], "primary_category": "cs.CL"}
{"title": "SpotServe: Serving Generative Large Language Models on Preemptible\n  Instances", "abstract": "The high computational and memory requirements of generative large language\nmodels (LLMs) make it challenging to serve them cheaply. This paper aims to\nreduce the monetary cost for serving LLMs by leveraging preemptible GPU\ninstances on modern clouds, which offer accesses to spare GPUs at a much\ncheaper price than regular instances but may be preempted by the cloud at any\ntime. Serving LLMs on preemptible instances requires addressing challenges\ninduced by frequent instance preemptions and the necessity of migrating\ninstances to handle these preemptions.\n  This paper presents SpotServe, the first distributed LLM serving system on\npreemptible instances. Several key techniques in SpotServe realize fast and\nreliable serving of generative LLMs on cheap preemptible instances. First,\nSpotServe dynamically adapts the LLM parallelization configuration for dynamic\ninstance availability and fluctuating workload, while balancing the trade-off\namong the overall throughput, inference latency and monetary costs. Second, to\nminimize the cost of migrating instances for dynamic reparallelization, the\ntask of migrating instances is formulated as a bipartite graph matching\nproblem, which uses the Kuhn-Munkres algorithm to identify an optimal migration\nplan that minimizes communications. Finally, to take advantage of the grace\nperiod offered by modern clouds, we introduce stateful inference recovery, a\nnew inference mechanism that commits inference progress at a much finer\ngranularity and allows SpotServe to cheaply resume inference upon preemption.\nWe evaluate on real spot instance preemption traces and various popular LLMs\nand show that SpotServe can reduce the P99 tail latency by 2.4 - 9.1x compared\nwith the best existing LLM serving systems. We also show that SpotServe can\nleverage the price advantage of preemptive instances, saving 54% monetary cost\ncompared with only using on-demand instances.", "published": "2023-11-27 06:31:17", "link": "http://arxiv.org/abs/2311.15566v1", "categories": ["cs.DC", "cs.CL", "cs.LG"], "primary_category": "cs.DC"}
{"title": "Injecting linguistic knowledge into BERT for Dialogue State Tracking", "abstract": "Dialogue State Tracking (DST) models often employ intricate neural network\narchitectures, necessitating substantial training data, and their inference\nprocess lacks transparency. This paper proposes a method that extracts\nlinguistic knowledge via an unsupervised framework and subsequently utilizes\nthis knowledge to augment BERT's performance and interpretability in DST tasks.\nThe knowledge extraction procedure is computationally economical and does not\nrequire annotations or additional training data. The injection of the extracted\nknowledge can be achieved by the addition of simple neural modules. We employ\nthe Convex Polytopic Model (CPM) as a feature extraction tool for DST tasks and\nillustrate that the acquired features correlate with syntactic and semantic\npatterns in the dialogues. This correlation facilitates a comprehensive\nunderstanding of the linguistic features influencing the DST model's\ndecision-making process. We benchmark this framework on various DST tasks and\nobserve a notable improvement in accuracy.", "published": "2023-11-27 08:38:42", "link": "http://arxiv.org/abs/2311.15623v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Justifiable Artificial Intelligence: Engineering Large Language Models\n  for Legal Applications", "abstract": "In this work, I discuss how Large Language Models can be applied in the legal\ndomain, circumventing their current drawbacks. Despite their large success and\nacceptance, their lack of explainability hinders legal experts to trust in\ntheir output, and this happens rightfully so. However, in this paper, I argue\nin favor of a new view, Justifiable Artificial Intelligence, instead of\nfocusing on Explainable Artificial Intelligence. I discuss in this paper how\ngaining evidence for and against a Large Language Model's output may make their\ngenerated texts more trustworthy - or hold them accountable for misinformation.", "published": "2023-11-27 10:59:16", "link": "http://arxiv.org/abs/2311.15716v1", "categories": ["cs.CL", "cs.HC", "cs.IR", "H.4.2; H.3.3; H.5.2"], "primary_category": "cs.CL"}
{"title": "Towards Vision Enhancing LLMs: Empowering Multimodal Knowledge Storage\n  and Sharing in LLMs", "abstract": "Recent advancements in multimodal large language models (MLLMs) have achieved\nsignificant multimodal generation capabilities, akin to GPT-4. These models\npredominantly map visual information into language representation space,\nleveraging the vast knowledge and powerful text generation abilities of LLMs to\nproduce multimodal instruction-following responses. We could term this method\nas LLMs for Vision because of its employing LLMs for visual-language\nunderstanding, yet observe that these MLLMs neglect the potential of harnessing\nvisual knowledge to enhance overall capabilities of LLMs, which could be\nregraded as Vision Enhancing LLMs. In this paper, we propose an approach called\nMKS2, aimed at enhancing LLMs through empowering Multimodal Knowledge Storage\nand Sharing in LLMs. Specifically, we introduce the Modular Visual Memory, a\ncomponent integrated into the internal blocks of LLMs, designed to store\nopen-world visual information efficiently. Additionally, we present a soft\nMixtures-of-Multimodal Experts architecture in LLMs to invoke multimodal\nknowledge collaboration during generation. Our comprehensive experiments\ndemonstrate that MKS2 substantially augments the reasoning capabilities of LLMs\nin contexts necessitating physical or commonsense knowledge. It also delivers\ncompetitive results on multimodal benchmarks.", "published": "2023-11-27 12:29:20", "link": "http://arxiv.org/abs/2311.15759v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Increasing Coverage and Precision of Textual Information in Multilingual\n  Knowledge Graphs", "abstract": "Recent work in Natural Language Processing and Computer Vision has been using\ntextual information -- e.g., entity names and descriptions -- available in\nknowledge graphs to ground neural models to high-quality structured data.\nHowever, when it comes to non-English languages, the quantity and quality of\ntextual information are comparatively scarce. To address this issue, we\nintroduce the novel task of automatic Knowledge Graph Enhancement (KGE) and\nperform a thorough investigation on bridging the gap in both the quantity and\nquality of textual information between English and non-English languages. More\nspecifically, we: i) bring to light the problem of increasing multilingual\ncoverage and precision of entity names and descriptions in Wikidata; ii)\ndemonstrate that state-of-the-art methods, namely, Machine Translation (MT),\nWeb Search (WS), and Large Language Models (LLMs), struggle with this task;\niii) present M-NTA, a novel unsupervised approach that combines MT, WS, and\nLLMs to generate high-quality textual information; and, iv) study the impact of\nincreasing multilingual coverage and precision of non-English textual\ninformation in Entity Linking, Knowledge Graph Completion, and Question\nAnswering. As part of our effort towards better multilingual knowledge graphs,\nwe also introduce WikiKGE-10, the first human-curated benchmark to evaluate KGE\napproaches in 10 languages across 7 language families.", "published": "2023-11-27 12:54:47", "link": "http://arxiv.org/abs/2311.15781v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "YUAN 2.0: A Large Language Model with Localized Filtering-based\n  Attention", "abstract": "In this work, we develop and release Yuan 2.0, a series of large language\nmodels with parameters ranging from 2.1 billion to 102.6 billion. The Localized\nFiltering-based Attention (LFA) is introduced to incorporate prior knowledge of\nlocal dependencies of natural language into Attention. A data filtering and\ngenerating system is presented to build pre-training and fine-tuning dataset in\nhigh quality. A distributed training method with non-uniform pipeline parallel,\ndata parallel, and optimizer parallel is proposed, which greatly reduces the\nbandwidth requirements of intra-node communication, and achieves good\nperformance in large-scale distributed training. Yuan 2.0 models display\nimpressive ability in code generation, math problem-solving, and chatting\ncompared with existing models. The latest version of YUAN 2.0, including model\nweights and source code, is accessible at Github.", "published": "2023-11-27 13:01:59", "link": "http://arxiv.org/abs/2311.15786v4", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Efficient Pre-training for Localized Instruction Generation of Videos", "abstract": "Procedural videos, exemplified by recipe demonstrations, are instrumental in\nconveying step-by-step instructions. However, understanding such videos is\nchallenging as it involves the precise localization of steps and the generation\nof textual instructions. Manually annotating steps and writing instructions is\ncostly, which limits the size of current datasets and hinders effective\nlearning. Leveraging large but noisy video-transcript datasets for pre-training\ncan boost performance but demands significant computational resources.\nFurthermore, transcripts contain irrelevant content and differ in style from\nhuman-written instructions. To mitigate these issues, we propose a novel\ntechnique, Sieve-&-Swap, to automatically generate high-quality training data\nfor the recipe domain: (i) Sieve: filters irrelevant transcripts and (ii) Swap:\nacquires high-quality text by replacing transcripts with human-written\ninstruction from a text-only recipe dataset. The resulting dataset is three\norders of magnitude smaller than current web-scale datasets but enables\nefficient training of large-scale models. Alongside Sieve-&-Swap, we propose\nProcedure Transformer (ProcX), a model for end-to-end step localization and\ninstruction generation for procedural videos. When pre-trained on our curated\ndataset, this model achieves state-of-the-art performance on YouCook2 and Tasty\nwhile using a fraction of the training data. We have released code and dataset.", "published": "2023-11-27 16:07:37", "link": "http://arxiv.org/abs/2311.15964v4", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "SPIN: Sparsifying and Integrating Internal Neurons in Large Language\n  Models for Text Classification", "abstract": "Among the many tasks that Large Language Models (LLMs) have revolutionized is\ntext classification. Current text classification paradigms, however, rely\nsolely on the output of the final layer in the LLM, with the rich information\ncontained in internal neurons largely untapped. In this study, we present SPIN:\na model-agnostic framework that sparsifies and integrates internal neurons of\nintermediate layers of LLMs for text classification. Specifically, SPIN\nsparsifies internal neurons by linear probing-based salient neuron selection\nlayer by layer, avoiding noise from unrelated neurons and ensuring efficiency.\nThe cross-layer salient neurons are then integrated to serve as multi-layered\nfeatures for the classification head. Extensive experimental results show our\nproposed SPIN significantly improves text classification accuracy, efficiency,\nand interpretability.", "published": "2023-11-27 16:28:20", "link": "http://arxiv.org/abs/2311.15983v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "BioLORD-2023: Semantic Textual Representations Fusing LLM and Clinical\n  Knowledge Graph Insights", "abstract": "In this study, we investigate the potential of Large Language Models to\ncomplement biomedical knowledge graphs in the training of semantic models for\nthe biomedical and clinical domains. Drawing on the wealth of the UMLS\nknowledge graph and harnessing cutting-edge Large Language Models, we propose a\nnew state-of-the-art approach for obtaining high-fidelity representations of\nbiomedical concepts and sentences, consisting of three steps: an improved\ncontrastive learning phase, a novel self-distillation phase, and a weight\naveraging phase. Through rigorous evaluations via the extensive BioLORD testing\nsuite and diverse downstream tasks, we demonstrate consistent and substantial\nperformance improvements over the previous state of the art (e.g. +2pts on\nMedSTS, +2.5pts on MedNLI-S, +6.1pts on EHR-Rel-B). Besides our new\nstate-of-the-art biomedical model for English, we also distill and release a\nmultilingual model compatible with 50+ languages and finetuned on 7 European\nlanguages. Many clinical pipelines can benefit from our latest models. Our new\nmultilingual model enables a range of languages to benefit from our\nadvancements in biomedical semantic representation learning, opening a new\navenue for bioinformatics researchers around the world. As a result, we hope to\nsee BioLORD-2023 becoming a precious tool for future biomedical applications.", "published": "2023-11-27 18:46:17", "link": "http://arxiv.org/abs/2311.16075v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "MEDITRON-70B: Scaling Medical Pretraining for Large Language Models", "abstract": "Large language models (LLMs) can potentially democratize access to medical\nknowledge. While many efforts have been made to harness and improve LLMs'\nmedical knowledge and reasoning capacities, the resulting models are either\nclosed-source (e.g., PaLM, GPT-4) or limited in scale (<= 13B parameters),\nwhich restricts their abilities. In this work, we improve access to large-scale\nmedical LLMs by releasing MEDITRON: a suite of open-source LLMs with 7B and 70B\nparameters adapted to the medical domain. MEDITRON builds on Llama-2 (through\nour adaptation of Nvidia's Megatron-LM distributed trainer), and extends\npretraining on a comprehensively curated medical corpus, including selected\nPubMed articles, abstracts, and internationally-recognized medical guidelines.\nEvaluations using four major medical benchmarks show significant performance\ngains over several state-of-the-art baselines before and after task-specific\nfinetuning. Overall, MEDITRON achieves a 6% absolute performance gain over the\nbest public baseline in its parameter class and 3% over the strongest baseline\nwe finetuned from Llama-2. Compared to closed-source LLMs, MEDITRON-70B\noutperforms GPT-3.5 and Med-PaLM and is within 5% of GPT-4 and 10% of\nMed-PaLM-2. We release our code for curating the medical pretraining corpus and\nthe MEDITRON model weights to drive open-source development of more capable\nmedical LLMs.", "published": "2023-11-27 18:49:43", "link": "http://arxiv.org/abs/2311.16079v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "How Many Unicorns Are in This Image? A Safety Evaluation Benchmark for\n  Vision LLMs", "abstract": "This work focuses on the potential of Vision LLMs (VLLMs) in visual\nreasoning. Different from prior studies, we shift our focus from evaluating\nstandard performance to introducing a comprehensive safety evaluation suite,\ncovering both out-of-distribution (OOD) generalization and adversarial\nrobustness. For the OOD evaluation, we present two novel VQA datasets, each\nwith one variant, designed to test model performance under challenging\nconditions. In exploring adversarial robustness, we propose a straightforward\nattack strategy for misleading VLLMs to produce visual-unrelated responses.\nMoreover, we assess the efficacy of two jailbreaking strategies, targeting\neither the vision or language component of VLLMs. Our evaluation of 21 diverse\nmodels, ranging from open-source VLLMs to GPT-4V, yields interesting\nobservations: 1) Current VLLMs struggle with OOD texts but not images, unless\nthe visual information is limited; and 2) These VLLMs can be easily misled by\ndeceiving vision encoders only, and their vision-language training often\ncompromise safety protocols. We release this safety evaluation suite at\nhttps://github.com/UCSC-VLAA/vllm-safety-benchmark.", "published": "2023-11-27 18:59:42", "link": "http://arxiv.org/abs/2311.16101v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Pre-trained Language Models Do Not Help Auto-regressive Text-to-Image\n  Generation", "abstract": "Recent advances in image tokenizers, such as VQ-VAE, have enabled\ntext-to-image generation using auto-regressive methods, similar to language\nmodeling. However, these methods have yet to leverage pre-trained language\nmodels, despite their adaptability to various downstream tasks. In this work,\nwe explore this gap by adapting a pre-trained language model for\nauto-regressive text-to-image generation, and find that pre-trained language\nmodels offer limited help. We provide a two-fold explanation by analyzing\ntokens from each modality. First, we demonstrate that image tokens possess\nsignificantly different semantics compared to text tokens, rendering\npre-trained language models no more effective in modeling them than randomly\ninitialized ones. Second, the text tokens in the image-text datasets are too\nsimple compared to normal language model pre-training data, which causes the\ncatastrophic degradation of language models' capability.", "published": "2023-11-27 07:19:26", "link": "http://arxiv.org/abs/2311.16201v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "ChatTraffic: Text-to-Traffic Generation via Diffusion Model", "abstract": "Traffic prediction is one of the most significant foundations in Intelligent\nTransportation Systems (ITS). Traditional traffic prediction methods rely only\non historical traffic data to predict traffic trends and face two main\nchallenges. 1) insensitivity to unusual events. 2) limited performance in\nlong-term prediction. In this work, we explore how generative models combined\nwith text describing the traffic system can be applied for traffic generation,\nand name the task Text-to-Traffic Generation (TTG). The key challenge of the\nTTG task is how to associate text with the spatial structure of the road\nnetwork and traffic data for generating traffic situations. To this end, we\npropose ChatTraffic, the first diffusion model for text-to-traffic generation.\nTo guarantee the consistency between synthetic and real data, we augment a\ndiffusion model with the Graph Convolutional Network (GCN) to extract spatial\ncorrelations of traffic data. In addition, we construct a large dataset\ncontaining text-traffic pairs for the TTG task. We benchmarked our model\nqualitatively and quantitatively on the released dataset. The experimental\nresults indicate that ChatTraffic can generate realistic traffic situations\nfrom the text. Our code and dataset are available at\nhttps://github.com/ChyaZhang/ChatTraffic.", "published": "2023-11-27 08:52:10", "link": "http://arxiv.org/abs/2311.16203v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Safe-CLIP: Removing NSFW Concepts from Vision-and-Language Models", "abstract": "Large-scale vision-and-language models, such as CLIP, are typically trained\non web-scale data, which can introduce inappropriate content and lead to the\ndevelopment of unsafe and biased behavior. This, in turn, hampers their\napplicability in sensitive and trustworthy contexts and could raise significant\nconcerns in their adoption. Our research introduces a novel approach to\nenhancing the safety of vision-and-language models by diminishing their\nsensitivity to NSFW (not safe for work) inputs. In particular, our methodology\nseeks to sever \"toxic\" linguistic and visual concepts, unlearning the linkage\nbetween unsafe linguistic or visual items and unsafe regions of the embedding\nspace. We show how this can be done by fine-tuning a CLIP model on synthetic\ndata obtained from a large language model trained to convert between safe and\nunsafe sentences, and a text-to-image generator. We conduct extensive\nexperiments on the resulting embedding space for cross-modal retrieval,\ntext-to-image, and image-to-text generation, where we show that our model can\nbe remarkably employed with pre-trained generative models. Our source code and\ntrained models are available at: https://github.com/aimagelab/safe-clip.", "published": "2023-11-27 19:02:17", "link": "http://arxiv.org/abs/2311.16254v3", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "An Exploration of Left-Corner Transformations", "abstract": "The left-corner transformation (Rosenkrantz and Lewis, 1970) is used to\nremove left recursion from context-free grammars, which is an important step\ntowards making the grammar parsable top-down with simple techniques. This paper\ngeneralizes prior left-corner transformations to support semiring-weighted\nproduction rules and to provide finer-grained control over which left corners\nmay be moved. Our generalized left-corner transformation (GLCT) arose from\nunifying the left-corner transformation and speculation transformation (Eisner\nand Blatz, 2007), originally for logic programming. Our new transformation and\nspeculation define equivalent weighted languages. Yet, their derivation trees\nare structurally different in an important way: GLCT replaces left recursion\nwith right recursion, and speculation does not. We also provide several\ntechnical results regarding the formal relationships between the outputs of\nGLCT, speculation, and the original grammar. Lastly, we empirically investigate\nthe efficiency of GLCT for left-recursion elimination from grammars of nine\nlanguages.", "published": "2023-11-27 19:04:37", "link": "http://arxiv.org/abs/2311.16258v1", "categories": ["cs.CL", "cs.DS", "cs.FL"], "primary_category": "cs.CL"}
{"title": "WsiCaption: Multiple Instance Generation of Pathology Reports for\n  Gigapixel Whole-Slide Images", "abstract": "Whole slide images are the foundation of digital pathology for the diagnosis\nand treatment of carcinomas. Writing pathology reports is laborious and\nerror-prone for inexperienced pathologists. To reduce the workload and improve\nclinical automation, we investigate how to generate pathology reports given\nwhole slide images. On the data end, we curated the largest WSI-text dataset\n(PathText). In specific, we collected nearly 10000 high-quality WSI-text pairs\nfor visual-language models by recognizing and cleaning pathology reports which\nnarrate diagnostic slides in TCGA. On the model end, we propose the multiple\ninstance generative model (MI-Gen) which can produce pathology reports for\ngigapixel WSIs. We benchmark our model on the largest subset of TCGA-PathoText.\nExperimental results show our model can generate pathology reports which\ncontain multiple clinical clues and achieve competitive performance on certain\nslide-level tasks. We observe that simple semantic extraction from the\npathology reports can achieve the best performance (0.838 of F1 score) on BRCA\nsubtyping surpassing previous state-of-the-art approaches. Our collected\ndataset and related code are available.", "published": "2023-11-27 05:05:41", "link": "http://arxiv.org/abs/2311.16480v4", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning\n  Benchmark for Expert AGI", "abstract": "We introduce MMMU: a new benchmark designed to evaluate multimodal models on\nmassive multi-discipline tasks demanding college-level subject knowledge and\ndeliberate reasoning. MMMU includes 11.5K meticulously collected multimodal\nquestions from college exams, quizzes, and textbooks, covering six core\ndisciplines: Art & Design, Business, Science, Health & Medicine, Humanities &\nSocial Science, and Tech & Engineering. These questions span 30 subjects and\n183 subfields, comprising 30 highly heterogeneous image types, such as charts,\ndiagrams, maps, tables, music sheets, and chemical structures. Unlike existing\nbenchmarks, MMMU focuses on advanced perception and reasoning with\ndomain-specific knowledge, challenging models to perform tasks akin to those\nfaced by experts. The evaluation of 14 open-source LMMs as well as the\nproprietary GPT-4V(ision) and Gemini highlights the substantial challenges\nposed by MMMU. Even the advanced GPT-4V and Gemini Ultra only achieve\naccuracies of 56% and 59% respectively, indicating significant room for\nimprovement. We believe MMMU will stimulate the community to build\nnext-generation multimodal foundation models towards expert artificial general\nintelligence.", "published": "2023-11-27 17:33:21", "link": "http://arxiv.org/abs/2311.16502v4", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Compositional Chain-of-Thought Prompting for Large Multimodal Models", "abstract": "The combination of strong visual backbones and Large Language Model (LLM)\nreasoning has led to Large Multimodal Models (LMMs) becoming the current\nstandard for a wide range of vision and language (VL) tasks. However, recent\nresearch has shown that even the most advanced LMMs still struggle to capture\naspects of compositional visual reasoning, such as attributes and relationships\nbetween objects. One solution is to utilize scene graphs (SGs)--a formalization\nof objects and their relations and attributes that has been extensively used as\na bridge between the visual and textual domains. Yet, scene graph data requires\nscene graph annotations, which are expensive to collect and thus not easily\nscalable. Moreover, finetuning an LMM based on SG data can lead to catastrophic\nforgetting of the pretraining objective. To overcome this, inspired by\nchain-of-thought methods, we propose Compositional Chain-of-Thought (CCoT), a\nnovel zero-shot Chain-of-Thought prompting method that utilizes SG\nrepresentations in order to extract compositional knowledge from an LMM.\nSpecifically, we first generate an SG using the LMM, and then use that SG in\nthe prompt to produce a response. Through extensive experiments, we find that\nthe proposed CCoT approach not only improves LMM performance on several vision\nand language VL compositional benchmarks but also improves the performance of\nseveral popular LMMs on general multimodal benchmarks, without the need for\nfine-tuning or annotated ground-truth SGs. Code:\nhttps://github.com/chancharikmitra/CCoT", "published": "2023-11-27 22:23:27", "link": "http://arxiv.org/abs/2311.17076v3", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "SCStory: Self-supervised and Continual Online Story Discovery", "abstract": "We present a framework SCStory for online story discovery, that helps people\ndigest rapidly published news article streams in real-time without human\nannotations. To organize news article streams into stories, existing approaches\ndirectly encode the articles and cluster them based on representation\nsimilarity. However, these methods yield noisy and inaccurate story discovery\nresults because the generic article embeddings do not effectively reflect the\nstory-indicative semantics in an article and cannot adapt to the rapidly\nevolving news article streams. SCStory employs self-supervised and continual\nlearning with a novel idea of story-indicative adaptive modeling of news\narticle streams. With a lightweight hierarchical embedding module that first\nlearns sentence representations and then article representations, SCStory\nidentifies story-relevant information of news articles and uses them to\ndiscover stories. The embedding module is continuously updated to adapt to\nevolving news streams with a contrastive learning objective, backed up by two\nunique techniques, confidence-aware memory replay and prioritized-augmentation,\nemployed for label absence and data scarcity problems. Thorough experiments on\nreal and the latest news data sets demonstrate that SCStory outperforms\nexisting state-of-the-art algorithms for unsupervised online story discovery.", "published": "2023-11-27 04:50:01", "link": "http://arxiv.org/abs/2312.03725v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Automatic Time Signature Determination for New Scores Using Lyrics for\n  Latent Rhythmic Structure", "abstract": "There has recently been a sharp increase in interest in Artificial\nIntelligence-Generated Content (AIGC). Despite this, musical components such as\ntime signatures have not been studied sufficiently to form an algorithmic\ndetermination approach for new compositions, especially lyrical songs. This is\nlikely because of the neglect of musical details, which is critical for\nconstructing a robust framework. Specifically, time signatures establish the\nfundamental rhythmic structure for almost all aspects of a song, including the\nphrases and notes. In this paper, we propose a novel approach that only uses\nlyrics as input to automatically generate a fitting time signature for lyrical\nsongs and uncover the latent rhythmic structure utilizing explainable machine\nlearning models. In particular, we devise multiple methods that are associated\nwith discovering lyrical patterns and creating new features that simultaneously\ncontain lyrical, rhythmic, and statistical information. In this approach, the\nbest of our experimental results reveal a 97.6% F1 score and a 0.996 Area Under\nthe Curve (AUC) of the Receiver Operating Characteristic (ROC) score. In\nconclusion, our research directly generates time signatures from lyrics\nautomatically for new scores utilizing machine learning, which is an innovative\nidea that approaches an understudied component of musicology and therefore\ncontributes significantly to the future of Artificial Intelligence (AI) music\ngeneration.", "published": "2023-11-27 01:44:02", "link": "http://arxiv.org/abs/2311.15480v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.MM", "cs.SD"], "primary_category": "cs.LG"}
{"title": "Reinforcement Learning from Diffusion Feedback: Q* for Image Search", "abstract": "Large vision-language models are steadily gaining personalization\ncapabilities at the cost of fine-tuning or data augmentation. We present two\nmodels for image generation using model-agnostic learning that align semantic\npriors with generative capabilities. RLDF, or Reinforcement Learning from\nDiffusion Feedback, is a singular approach for visual imitation through\nprior-preserving reward function guidance. This employs Q-learning (with\nstandard Q*) for generation and follows a semantic-rewarded trajectory for\nimage search through finite encoding-tailored actions. The second proposed\nmethod, noisy diffusion gradient, is optimization driven. At the root of both\nmethods is a special CFG encoding that we propose for continual semantic\nguidance. Using only a single input image and no text input, RLDF generates\nhigh-quality images over varied domains including retail, sports and\nagriculture showcasing class-consistency and strong visual diversity. Project\nwebsite is available at https://infernolia.github.io/RLDF.", "published": "2023-11-27 09:20:12", "link": "http://arxiv.org/abs/2311.15648v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Spatial Diarization for Meeting Transcription with Ad-Hoc Acoustic\n  Sensor Networks", "abstract": "We propose a diarization system, that estimates \"who spoke when\" based on\nspatial information, to be used as a front-end of a meeting transcription\nsystem running on the signals gathered from an acoustic sensor network (ASN).\nAlthough the spatial distribution of the microphones is advantageous,\nexploiting the spatial diversity for diarization and signal enhancement is\nchallenging, because the microphones' positions are typically unknown, and the\nrecorded signals are initially unsynchronized in general. Here, we approach\nthese issues by first blindly synchronizing the signals and then estimating\ntime differences of arrival (TDOAs). The TDOA information is exploited to\nestimate the speakers' activity, even in the presence of multiple speakers\nbeing simultaneously active. This speaker activity information serves as a\nguide for a spatial mixture model, on which basis the individual speaker's\nsignals are extracted via beamforming. Finally, the extracted signals are\nforwarded to a speech recognizer. Additionally, a novel initialization scheme\nfor spatial mixture models based on the TDOA estimates is proposed. Experiments\nconducted on real recordings from the LibriWASN data set have shown that our\nproposed system is advantageous compared to a system using a spatial mixture\nmodel, which does not make use of external diarization information.", "published": "2023-11-27 07:46:48", "link": "http://arxiv.org/abs/2311.15597v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Voice Anonymization for All -- Bias Evaluation of the Voice Privacy\n  Challenge Baseline System", "abstract": "In an age of voice-enabled technology, voice anonymization offers a solution\nto protect people's privacy, provided these systems work equally well across\nsubgroups. This study investigates bias in voice anonymization systems within\nthe context of the Voice Privacy Challenge. We curate a novel benchmark dataset\nto assess performance disparities among speaker subgroups based on sex and\ndialect. We analyze the impact of three anonymization systems and attack models\non speaker subgroup bias and reveal significant performance variations.\nNotably, subgroup bias intensifies with advanced attacker capabilities,\nemphasizing the challenge of achieving equal performance across all subgroups.\nOur study highlights the need for inclusive benchmark datasets and\ncomprehensive evaluation strategies that address subgroup bias in voice\nanonymization.", "published": "2023-11-27 13:26:49", "link": "http://arxiv.org/abs/2311.15804v1", "categories": ["eess.AS", "cs.CY"], "primary_category": "eess.AS"}
{"title": "Lightly Weighted Automatic Audio Parameter Extraction for the Quality\n  Assessment of Consensus Auditory-Perceptual Evaluation of Voice", "abstract": "The Consensus Auditory-Perceptual Evaluation of Voice is a widely employed\ntool in clinical voice quality assessment that is significant for streaming\ncommunication among clinical professionals and benchmarking for the\ndetermination of further treatment. Currently, because the assessment relies on\nexperienced clinicians, it tends to be inconsistent, and thus, difficult to\nstandardize. To address this problem, we propose to leverage lightly weighted\nautomatic audio parameter extraction, to increase the clinical relevance,\nreduce the complexity, and enhance the interpretability of voice quality\nassessment. The proposed method utilizes age, sex, and five audio parameters:\njitter, absolute jitter, shimmer, harmonic-to-noise ratio (HNR), and zero\ncrossing. A classical machine learning approach is employed. The result reveals\nthat our approach performs similar to state-of-the-art (SOTA) methods, and\noutperforms the latent representation obtained by using popular audio\npre-trained models. This approach provide insights into the feasibility of\ndifferent feature extraction approaches for voice evaluation. Audio parameters\nsuch as jitter and the HNR are proven to be suitable for characterizing voice\nquality attributes, such as roughness and strain. Conversely, pre-trained\nmodels exhibit limitations in effectively addressing noise-related scorings.\nThis study contributes toward more comprehensive and precise voice quality\nevaluations, achieved by a comprehensively exploring diverse assessment\nmethodologies.", "published": "2023-11-27 07:19:22", "link": "http://arxiv.org/abs/2311.15582v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Phonetic-aware speaker embedding for far-field speaker verification", "abstract": "When a speaker verification (SV) system operates far from the sound sourced,\nsignificant challenges arise due to the interference of noise and\nreverberation. Studies have shown that incorporating phonetic information into\nspeaker embedding can improve the performance of text-independent SV. Inspired\nby this observation, we propose a joint-training speech recognition and speaker\nrecognition (JTSS) framework to exploit phonetic content for far-field SV. The\nframework encourages speaker embeddings to preserve phonetic information by\nmatching the frame-based feature maps of a speaker embedding network with\nwav2vec's vectors. The intuition is that phonetic information can preserve\nlow-level acoustic dynamics with speaker information and thus partly compensate\nfor the degradation due to noise and reverberation. Results show that the\nproposed framework outperforms the standard speaker embedding on the VOiCES\nChallenge 2019 evaluation set and the VoxCeleb1 test set. This indicates that\nleveraging phonetic information under far-field conditions is effective for\nlearning robust speaker representations.", "published": "2023-11-27 08:45:35", "link": "http://arxiv.org/abs/2311.15627v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Ultrasensitive Textile Strain Sensors Redefine Wearable Silent Speech\n  Interfaces with High Machine Learning Efficiency", "abstract": "Our research presents a wearable Silent Speech Interface (SSI) technology\nthat excels in device comfort, time-energy efficiency, and speech decoding\naccuracy for real-world use. We developed a biocompatible, durable textile\nchoker with an embedded graphene-based strain sensor, capable of accurately\ndetecting subtle throat movements. This sensor, surpassing other strain sensors\nin sensitivity by 420%, simplifies signal processing compared to traditional\nvoice recognition methods. Our system uses a computationally efficient neural\nnetwork, specifically a one-dimensional convolutional neural network with\nresidual structures, to decode speech signals. This network is energy and\ntime-efficient, reducing computational load by 90% while achieving 95.25%\naccuracy for a 20-word lexicon and swiftly adapting to new users and words with\nminimal samples. This innovation demonstrates a practical, sensitive, and\nprecise wearable SSI suitable for daily communication applications.", "published": "2023-11-27 10:17:00", "link": "http://arxiv.org/abs/2311.15683v2", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "A-JEPA: Joint-Embedding Predictive Architecture Can Listen", "abstract": "This paper presents that the masked-modeling principle driving the success of\nlarge foundational vision models can be effectively applied to audio by making\npredictions in a latent space. We introduce Audio-based Joint-Embedding\nPredictive Architecture (A-JEPA), a simple extension method for self-supervised\nlearning from the audio spectrum. Following the design of I-JEPA, our A-JEPA\nencodes visible audio spectrogram patches with a curriculum masking strategy\nvia context encoder, and predicts the representations of regions sampled at\nwell-designed locations. The target representations of those regions are\nextracted by the exponential moving average of context encoder, \\emph{i.e.},\ntarget encoder, on the whole spectrogram. We find it beneficial to transfer\nrandom block masking into time-frequency aware masking in a curriculum manner,\nconsidering the complexity of highly correlated in local time and frequency in\naudio spectrograms. To enhance contextual semantic understanding and\nrobustness, we fine-tune the encoder with a regularized masking on target\ndatasets, instead of input dropping or zero. Empirically, when built with\nVision Transformers structure, we find A-JEPA to be highly scalable and sets\nnew state-of-the-art performance on multiple audio and speech classification\ntasks, outperforming other recent models that use externally supervised\npre-training.", "published": "2023-11-27 13:53:53", "link": "http://arxiv.org/abs/2311.15830v3", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "CheapNET: Improving Light-weight speech enhancement network by projected\n  loss function", "abstract": "Noise suppression and echo cancellation are critical in speech enhancement\nand essential for smart devices and real-time communication. Deployed in voice\nprocessing front-ends and edge devices, these algorithms must ensure efficient\nreal-time inference with low computational demands. Traditional edge-based\nnoise suppression often uses MSE-based amplitude spectrum mask training, but\nthis approach has limitations. We introduce a novel projection loss function,\ndiverging from MSE, to enhance noise suppression. This method uses projection\ntechniques to isolate key audio components from noise, significantly improving\nmodel performance. For echo cancellation, the function enables direct\npredictions on LAEC pre-processed outputs, substantially enhancing performance.\nOur noise suppression model achieves near state-of-the-art results with only\n3.1M parameters and 0.4GFlops/s computational load. Moreover, our echo\ncancellation model outperforms replicated industry-leading models, introducing\na new perspective in speech enhancement.", "published": "2023-11-27 16:03:42", "link": "http://arxiv.org/abs/2311.15959v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
