{"title": "Joint Entity Extraction and Assertion Detection for Clinical Text", "abstract": "Negative medical findings are prevalent in clinical reports, yet\ndiscriminating them from positive findings remains a challenging task for\ninformation extraction. Most of the existing systems treat this task as a\npipeline of two separate tasks, i.e., named entity recognition (NER) and\nrule-based negation detection. We consider this as a multi-task problem and\npresent a novel end-to-end neural model to jointly extract entities and\nnegations. We extend a standard hierarchical encoder-decoder NER model and\nfirst adopt a shared encoder followed by separate decoders for the two tasks.\nThis architecture performs considerably better than the previous rule-based and\nmachine learning-based systems. To overcome the problem of increased parameter\nsize especially for low-resource settings, we propose the Conditional Softmax\nShared Decoder architecture which achieves state-of-art results for NER and\nnegation detection on the 2010 i2b2/VA challenge dataset and a proprietary\nde-identified clinical dataset.", "published": "2018-12-13 05:32:23", "link": "http://arxiv.org/abs/1812.05270v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards a General-Purpose Linguistic Annotation Backend", "abstract": "Language documentation is inherently a time-intensive process; transcription,\nglossing, and corpus management consume a significant portion of documentary\nlinguists' work. Advances in natural language processing can help to accelerate\nthis work, using the linguists' past decisions as training material, but\nquestions remain about how to prioritize human involvement. In this extended\nabstract, we describe the beginnings of a new project that will attempt to ease\nthis language documentation process through the use of natural language\nprocessing (NLP) technology. It is based on (1) methods to adapt NLP tools to\nnew languages, based on recent advances in massively multilingual neural\nnetworks, and (2) backend APIs and interfaces that allow linguists to upload\ntheir data. We then describe our current progress on two fronts: automatic\nphoneme transcription, and glossing. Finally, we briefly describe our future\ndirections.", "published": "2018-12-13 05:33:11", "link": "http://arxiv.org/abs/1812.05272v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Find a Reasonable Ending for Stories: Does Logic Relation Help the Story\n  Cloze Test?", "abstract": "Natural language understanding is a challenging problem that covers a wide\nrange of tasks. While previous methods generally train each task separately, we\nconsider combining the cross-task features to enhance the task performance. In\nthis paper, we incorporate the logic information with the help of the Natural\nLanguage Inference (NLI) task to the Story Cloze Test (SCT). Previous work on\nSCT considered various semantic information, such as sentiment and topic, but\nlack the logic information between sentences which is an essential element of\nstories. Thus we propose to extract the logic information during the course of\nthe story to improve the understanding of the whole story. The logic\ninformation is modeled with the help of the NLI task. Experimental results\nprove the strength of the logic information.", "published": "2018-12-13 13:20:40", "link": "http://arxiv.org/abs/1812.05411v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dynamic Feature Generation Network for Answer Selection", "abstract": "Extracting appropriate features to represent a corpus is an important task\nfor textual mining. Previous attention based work usually enhance feature at\nthe lexical level, which lacks the exploration of feature augmentation at the\nsentence level. In this paper, we exploit a Dynamic Feature Generation Network\n(DFGN) to solve this problem. Specifically, DFGN generates features based on a\nvariety of attention mechanisms and attaches features to sentence\nrepresentation. Then a thresholder is designed to filter the mined features\nautomatically. DFGN extracts the most significant characteristics from datasets\nto keep its practicability and robustness. Experimental results on multiple\nwell-known answer selection datasets show that our proposed approach\nsignificantly outperforms state-of-the-art baselines. We give a detailed\nanalysis of the experiments to illustrate why DFGN provides excellent retrieval\nand interpretative ability.", "published": "2018-12-13 11:23:18", "link": "http://arxiv.org/abs/1812.05366v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Abstractive Text Summarization by Incorporating Reader Comments", "abstract": "In neural abstractive summarization field, conventional sequence-to-sequence\nbased models often suffer from summarizing the wrong aspect of the document\nwith respect to the main aspect. To tackle this problem, we propose the task of\nreader-aware abstractive summary generation, which utilizes the reader comments\nto help the model produce better summary about the main aspect. Unlike\ntraditional abstractive summarization task, reader-aware summarization\nconfronts two main challenges: (1) Comments are informal and noisy; (2) jointly\nmodeling the news document and the reader comments is challenging. To tackle\nthe above challenges, we design an adversarial learning model named\nreader-aware summary generator (RASG), which consists of four components: (1) a\nsequence-to-sequence based summary generator; (2) a reader attention module\ncapturing the reader focused aspects; (3) a supervisor modeling the semantic\ngap between the generated summary and reader focused aspects; (4) a goal\ntracker producing the goal for each generation step. The supervisor and the\ngoal tacker are used to guide the training of our framework in an adversarial\nmanner. Extensive experiments are conducted on our large-scale real-world text\nsummarization dataset, and the results show that RASG achieves the\nstate-of-the-art performance in terms of both automatic metrics and human\nevaluations. The experimental results also demonstrate the effectiveness of\neach module in our framework. We release our large-scale dataset for further\nresearch.", "published": "2018-12-13 13:13:23", "link": "http://arxiv.org/abs/1812.05407v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Adversarial Inference for Multi-Sentence Video Description", "abstract": "While significant progress has been made in the image captioning task, video\ndescription is still in its infancy due to the complex nature of video data.\nGenerating multi-sentence descriptions for long videos is even more\nchallenging. Among the main issues are the fluency and coherence of the\ngenerated descriptions, and their relevance to the video. Recently,\nreinforcement and adversarial learning based methods have been explored to\nimprove the image captioning models; however, both types of methods suffer from\na number of issues, e.g. poor readability and high redundancy for RL and\nstability issues for GANs. In this work, we instead propose to apply\nadversarial techniques during inference, designing a discriminator which\nencourages better multi-sentence video description. In addition, we find that a\nmulti-discriminator \"hybrid\" design, where each discriminator targets one\naspect of a description, leads to the best results. Specifically, we decouple\nthe discriminator to evaluate on three criteria: 1) visual relevance to the\nvideo, 2) language diversity and fluency, and 3) coherence across sentences.\nOur approach results in more accurate, diverse, and coherent multi-sentence\nvideo descriptions, as shown by automatic as well as human evaluation on the\npopular ActivityNet Captions dataset.", "published": "2018-12-13 19:07:17", "link": "http://arxiv.org/abs/1812.05634v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Multilayer Network Model of Movie Script", "abstract": "Network models have been increasingly used in the past years to support\nsummarization and analysis of narratives, such as famous TV series, books and\nnews. Inspired by social network analysis, most of these models focus on the\ncharacters at play. The network model well captures all characters\ninteractions, giving a broad picture of the narration's content. A few works\nwent beyond by introducing additional semantic elements, always captured in a\nsingle layer network. In contrast, we introduce in this work a multilayer\nnetwork model to capture more elements of the narration of a movie from its\nscript: people, locations, and other semantic elements. This model enables new\nmeasures and insights on movies. We demonstrate this model on two very popular\nmovies.", "published": "2018-12-13 22:50:04", "link": "http://arxiv.org/abs/1812.05718v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Modeling Multi-speaker Latent Space to Improve Neural TTS: Quick\n  Enrolling New Speaker and Enhancing Premium Voice", "abstract": "Neural TTS has shown it can generate high quality synthesized speech. In this\npaper, we investigate the multi-speaker latent space to improve neural TTS for\nadapting the system to new speakers with only several minutes of speech or\nenhancing a premium voice by utilizing the data from other speakers for richer\ncontextual coverage and better generalization. A multi-speaker neural TTS model\nis built with the embedded speaker information in both spectral and speaker\nlatent space. The experimental results show that, with less than 5 minutes of\ntraining data from a new speaker, the new model can achieve an MOS score of\n4.16 in naturalness and 4.64 in speaker similarity close to human recordings\n(4.74). For a well-trained premium voice, we can achieve an MOS score of 4.5\nfor out-of-domain texts, which is comparable to an MOS of 4.58 for professional\nrecordings, and significantly outperforms single speaker result of 4.28.", "published": "2018-12-13 03:41:58", "link": "http://arxiv.org/abs/1812.05253v4", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "TextBugger: Generating Adversarial Text Against Real-world Applications", "abstract": "Deep Learning-based Text Understanding (DLTU) is the backbone technique\nbehind various applications, including question answering, machine translation,\nand text classification. Despite its tremendous popularity, the security\nvulnerabilities of DLTU are still largely unknown, which is highly concerning\ngiven its increasing use in security-sensitive applications such as sentiment\nanalysis and toxic content detection. In this paper, we show that DLTU is\ninherently vulnerable to adversarial text attacks, in which maliciously crafted\ntexts trigger target DLTU systems and services to misbehave. Specifically, we\npresent TextBugger, a general attack framework for generating adversarial\ntexts. In contrast to prior works, TextBugger differs in significant ways: (i)\neffective -- it outperforms state-of-the-art attacks in terms of attack success\nrate; (ii) evasive -- it preserves the utility of benign text, with 94.9\\% of\nthe adversarial text correctly recognized by human readers; and (iii) efficient\n-- it generates adversarial text with computational complexity sub-linear to\nthe text length. We empirically evaluate TextBugger on a set of real-world DLTU\nsystems and services used for sentiment analysis and toxic content detection,\ndemonstrating its effectiveness, evasiveness, and efficiency. For instance,\nTextBugger achieves 100\\% success rate on the IMDB dataset based on Amazon AWS\nComprehend within 4.61 seconds and preserves 97\\% semantic similarity. We\nfurther discuss possible defense mechanisms to mitigate such attack and the\nadversary's potential countermeasures, which leads to promising directions for\nfurther research.", "published": "2018-12-13 05:32:43", "link": "http://arxiv.org/abs/1812.05271v1", "categories": ["cs.CR", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Dynamic Transfer Learning for Named Entity Recognition", "abstract": "State-of-the-art named entity recognition (NER) systems have been improving\ncontinuously using neural architectures over the past several years. However,\nmany tasks including NER require large sets of annotated data to achieve such\nperformance. In particular, we focus on NER from clinical notes, which is one\nof the most fundamental and critical problems for medical text analysis. Our\nwork centers on effectively adapting these neural architectures towards\nlow-resource settings using parameter transfer methods. We complement a\nstandard hierarchical NER model with a general transfer learning framework\nconsisting of parameter sharing between the source and target tasks, and\nshowcase scores significantly above the baseline architecture. These sharing\nschemes require an exponential search over tied parameter sets to generate an\noptimal configuration. To mitigate the problem of exhaustively searching for\nmodel optimization, we propose the Dynamic Transfer Networks (DTN), a gated\narchitecture which learns the appropriate parameter sharing scheme between\nsource and target datasets. DTN achieves the improvements of the optimized\ntransfer learning framework with just a single training setting, effectively\nremoving the need for exponential search.", "published": "2018-12-13 07:02:54", "link": "http://arxiv.org/abs/1812.05288v4", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Speech and Speaker Recognition from Raw Waveform with SincNet", "abstract": "Deep neural networks can learn complex and abstract representations, that are\nprogressively obtained by combining simpler ones. A recent trend in speech and\nspeaker recognition consists in discovering these representations starting from\nraw audio samples directly. Differently from standard hand-crafted features\nsuch as MFCCs or FBANK, the raw waveform can potentially help neural networks\ndiscover better and more customized representations. The high-dimensional raw\ninputs, however, can make training significantly more challenging. This paper\nsummarizes our recent efforts to develop a neural architecture that efficiently\nprocesses speech from audio waveforms. In particular, we propose SincNet, a\nnovel Convolutional Neural Network (CNN) that encourages the first layer to\ndiscover meaningful filters by exploiting parametrized sinc functions. In\ncontrast to standard CNNs, which learn all the elements of each filter, only\nlow and high cutoff frequencies of band-pass filters are directly learned from\ndata. This inductive bias offers a very compact way to derive a customized\nfront-end, that only depends on some parameters with a clear physical meaning.\nOur experiments, conducted on both speaker and speech recognition, show that\nthe proposed architecture converges faster, performs better, and is more\ncomputationally efficient than standard CNNs.", "published": "2018-12-13 16:01:11", "link": "http://arxiv.org/abs/1812.05920v2", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Coupled Representation Learning for Domains, Intents and Slots in Spoken\n  Language Understanding", "abstract": "Representation learning is an essential problem in a wide range of\napplications and it is important for performing downstream tasks successfully.\nIn this paper, we propose a new model that learns coupled representations of\ndomains, intents, and slots by taking advantage of their hierarchical\ndependency in a Spoken Language Understanding system. Our proposed model learns\nthe vector representation of intents based on the slots tied to these intents\nby aggregating the representations of the slots. Similarly, the vector\nrepresentation of a domain is learned by aggregating the representations of the\nintents tied to a specific domain. To the best of our knowledge, it is the\nfirst approach to jointly learning the representations of domains, intents, and\nslots using their hierarchical relationships. The experimental results\ndemonstrate the effectiveness of the representations learned by our model, as\nevidenced by improved performance on the contextual cross-domain reranking\ntask.", "published": "2018-12-13 22:23:51", "link": "http://arxiv.org/abs/1812.06083v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Same but Different: Distant Supervision for Predicting and Understanding\n  Entity Linking Difficulty", "abstract": "Entity Linking (EL) is the task of automatically identifying entity mentions\nin a piece of text and resolving them to a corresponding entity in a reference\nknowledge base like Wikipedia. There is a large number of EL tools available\nfor different types of documents and domains, yet EL remains a challenging task\nwhere the lack of precision on particularly ambiguous mentions often spoils the\nusefulness of automated disambiguation results in real applications. A priori\napproximations of the difficulty to link a particular entity mention can\nfacilitate flagging of critical cases as part of semi-automated EL systems,\nwhile detecting latent factors that affect the EL performance, like\ncorpus-specific features, can provide insights on how to improve a system based\non the special characteristics of the underlying corpus. In this paper, we\nfirst introduce a consensus-based method to generate difficulty labels for\nentity mentions on arbitrary corpora. The difficulty labels are then exploited\nas training data for a supervised classification task able to predict the EL\ndifficulty of entity mentions using a variety of features. Experiments over a\ncorpus of news articles show that EL difficulty can be estimated with high\naccuracy, revealing also latent features that affect EL performance. Finally,\nevaluation results demonstrate the effectiveness of the proposed method to\ninform semi-automated EL pipelines.", "published": "2018-12-13 12:48:40", "link": "http://arxiv.org/abs/1812.10387v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Measuring Societal Biases from Text Corpora with Smoothed First-Order\n  Co-occurrence", "abstract": "Text corpora are widely used resources for measuring societal biases and\nstereotypes. The common approach to measuring such biases using a corpus is by\ncalculating the similarities between the embedding vector of a word (like\nnurse) and the vectors of the representative words of the concepts of interest\n(such as genders). In this study, we show that, depending on what one aims to\nquantify as bias, this commonly-used approach can introduce non-relevant\nconcepts into bias measurement. We propose an alternative approach to bias\nmeasurement utilizing the smoothed first-order co-occurrence relations between\nthe word and the representative concept words, which we derive by\nreconstructing the co-occurrence estimates inherent in word embedding models.\nWe compare these approaches by conducting several experiments on the scenario\nof measuring gender bias of occupational words, according to an English\nWikipedia corpus. Our experiments show higher correlations of the measured\ngender bias with the actual gender bias statistics of the U.S. job market - on\ntwo collections and with a variety of word embedding models - using the\nfirst-order approach in comparison with the vector similarity-based approaches.\nThe first-order approach also suggests a more severe bias towards female in a\nfew specific occupations than the other approaches.", "published": "2018-12-13 21:00:05", "link": "http://arxiv.org/abs/1812.10424v4", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
