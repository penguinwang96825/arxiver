{"title": "Optimal position-building strategies in competition", "abstract": "This paper develops a mathematical framework for building a position in a\nstock over a fixed period of time while in competition with one or more other\ntraders doing the same thing. We develop a game-theoretic framework that takes\nplace in the space of trading strategies where action sets are trading\nstrategies and traders try to devise best-response strategies to their\nadversaries. In this setup trading is guided by a desire to minimize the total\ncost of trading arising from a mixture of temporary and permanent market impact\ncaused by the aggregate level of trading including the trader and the\ncompetition. We describe a notion of equilibrium strategies, show that they\nexist and provide closed-form solutions.", "published": "2024-09-05 14:42:23", "link": "http://arxiv.org/abs/2409.03586v2", "categories": ["q-fin.TR"], "primary_category": "q-fin.TR"}
{"title": "MARAGS: A Multi-Adapter System for Multi-Task Retrieval Augmented\n  Generation Question Answering", "abstract": "In this paper we present a multi-adapter retrieval augmented generation\nsystem (MARAGS) for Meta's Comprehensive RAG (CRAG) competition for KDD CUP\n2024. CRAG is a question answering dataset contains 3 different subtasks aimed\nat realistic question and answering RAG related tasks, with a diverse set of\nquestion topics, question types, time dynamic answers, and questions featuring\nentities of varying popularity.\n  Our system follows a standard setup for web based RAG, which uses processed\nweb pages to provide context for an LLM to produce generations, while also\nquerying API endpoints for additional information. MARAGS also utilizes\nmultiple different adapters to solve the various requirements for these tasks\nwith a standard cross-encoder model for ranking candidate passages relevant for\nanswering the question. Our system achieved 2nd place for Task 1 as well as 3rd\nplace on Task 2.", "published": "2024-09-05 01:58:29", "link": "http://arxiv.org/abs/2409.03171v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Healthcare LLM Trust with Atypical Presentations Recalibration", "abstract": "Black-box large language models (LLMs) are increasingly deployed in various\nenvironments, making it essential for these models to effectively convey their\nconfidence and uncertainty, especially in high-stakes settings. However, these\nmodels often exhibit overconfidence, leading to potential risks and\nmisjudgments. Existing techniques for eliciting and calibrating LLM confidence\nhave primarily focused on general reasoning datasets, yielding only modest\nimprovements. Accurate calibration is crucial for informed decision-making and\npreventing adverse outcomes but remains challenging due to the complexity and\nvariability of tasks these models perform. In this work, we investigate the\nmiscalibration behavior of black-box LLMs within the healthcare setting. We\npropose a novel method, \\textit{Atypical Presentations Recalibration}, which\nleverages atypical presentations to adjust the model's confidence estimates.\nOur approach significantly improves calibration, reducing calibration errors by\napproximately 60\\% on three medical question answering datasets and\noutperforming existing methods such as vanilla verbalized confidence, CoT\nverbalized confidence and others. Additionally, we provide an in-depth analysis\nof the role of atypicality within the recalibration framework.", "published": "2024-09-05 03:45:35", "link": "http://arxiv.org/abs/2409.03225v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GraphInsight: Unlocking Insights in Large Language Models for Graph\n  Structure Understanding", "abstract": "Although Large Language Models (LLMs) have demonstrated potential in\nprocessing graphs, they struggle with comprehending graphical structure\ninformation through prompts of graph description sequences, especially as the\ngraph size increases. We attribute this challenge to the uneven memory\nperformance of LLMs across different positions in graph description sequences,\nknown as ''positional biases''. To address this, we propose GraphInsight, a\nnovel framework aimed at improving LLMs' comprehension of both macro- and\nmicro-level graphical information. GraphInsight is grounded in two key\nstrategies: 1) placing critical graphical information in positions where LLMs\nexhibit stronger memory performance, and 2) investigating a lightweight\nexternal knowledge base for regions with weaker memory performance, inspired by\nretrieval-augmented generation (RAG). Moreover, GraphInsight explores\nintegrating these two strategies into LLM agent processes for composite graph\ntasks that require multi-step reasoning. Extensive empirical studies on\nbenchmarks with a wide range of evaluation tasks show that GraphInsight\nsignificantly outperforms all other graph description methods (e.g., prompting\ntechniques and reordering strategies) in understanding graph structures of\nvarying sizes.", "published": "2024-09-05 05:34:16", "link": "http://arxiv.org/abs/2409.03258v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Con-ReCall: Detecting Pre-training Data in LLMs via Contrastive Decoding", "abstract": "The training data in large language models is key to their success, but it\nalso presents privacy and security risks, as it may contain sensitive\ninformation. Detecting pre-training data is crucial for mitigating these\nconcerns. Existing methods typically analyze target text in isolation or solely\nwith non-member contexts, overlooking potential insights from simultaneously\nconsidering both member and non-member contexts. While previous work suggested\nthat member contexts provide little information due to the minor distributional\nshift they induce, our analysis reveals that these subtle shifts can be\neffectively leveraged when contrasted with non-member contexts. In this paper,\nwe propose Con-ReCall, a novel approach that leverages the asymmetric\ndistributional shifts induced by member and non-member contexts through\ncontrastive decoding, amplifying subtle differences to enhance membership\ninference. Extensive empirical evaluations demonstrate that Con-ReCall achieves\nstate-of-the-art performance on the WikiMIA benchmark and is robust against\nvarious text manipulation techniques.", "published": "2024-09-05 09:10:38", "link": "http://arxiv.org/abs/2409.03363v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rx Strategist: Prescription Verification using LLM Agents System", "abstract": "To protect patient safety, modern pharmaceutical complexity demands strict\nprescription verification. We offer a new approach - Rx Strategist - that makes\nuse of knowledge graphs and different search strategies to enhance the power of\nLarge Language Models (LLMs) inside an agentic framework. This multifaceted\ntechnique allows for a multi-stage LLM pipeline and reliable information\nretrieval from a custom-built active ingredient database. Different facets of\nprescription verification, such as indication, dose, and possible drug\ninteractions, are covered in each stage of the pipeline. We alleviate the\ndrawbacks of monolithic LLM techniques by spreading reasoning over these\nstages, improving correctness and reliability while reducing memory demands.\nOur findings demonstrate that Rx Strategist surpasses many current LLMs,\nachieving performance comparable to that of a highly experienced clinical\npharmacist. In the complicated world of modern medications, this combination of\nLLMs with organized knowledge and sophisticated search methods presents a\nviable avenue for reducing prescription errors and enhancing patient outcomes.", "published": "2024-09-05 11:42:26", "link": "http://arxiv.org/abs/2409.03440v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Attend First, Consolidate Later: On the Importance of Attention in\n  Different LLM Layers", "abstract": "In decoder-based LLMs, the representation of a given layer serves two\npurposes: as input to the next layer during the computation of the current\ntoken; and as input to the attention mechanism of future tokens. In this work,\nwe show that the importance of the latter role might be overestimated. To show\nthat, we start by manipulating the representations of previous tokens; e.g. by\nreplacing the hidden states at some layer k with random vectors. Our\nexperimenting with four LLMs and four tasks show that this operation often\nleads to small to negligible drop in performance. Importantly, this happens if\nthe manipulation occurs in the top part of the model-k is in the final 30-50%\nof the layers. In contrast, doing the same manipulation in earlier layers might\nlead to chance level performance. We continue by switching the hidden state of\ncertain tokens with hidden states of other tokens from another prompt; e.g.,\nreplacing the word \"Italy\" with \"France\" in \"What is the capital of Italy?\". We\nfind that when applying this switch in the top 1/3 of the model, the model\nignores it (answering \"Rome\"). However if we apply it before, the model\nconforms to the switch (\"Paris\"). Our results hint at a two stage process in\ntransformer-based LLMs: the first part gathers input from previous tokens,\nwhile the second mainly processes that information internally.", "published": "2024-09-05 15:33:24", "link": "http://arxiv.org/abs/2409.03621v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM-based multi-agent poetry generation in non-cooperative environments", "abstract": "Despite substantial progress of large language models (LLMs) for automatic\npoetry generation, the generated poetry lacks diversity while the training\nprocess differs greatly from human learning. Under the rationale that the\nlearning process of the poetry generation systems should be more human-like and\ntheir output more diverse and novel, we introduce a framework based on social\nlearning where we emphasize non-cooperative interactions besides cooperative\ninteractions to encourage diversity. Our experiments are the first attempt at\nLLM-based multi-agent systems in non-cooperative environments for poetry\ngeneration employing both TRAINING-BASED agents (GPT-2) and PROMPTING-BASED\nagents (GPT-3 and GPT-4). Our evaluation based on 96k generated poems shows\nthat our framework benefits the poetry generation process for TRAINING-BASED\nagents resulting in 1) a 3.0-3.7 percentage point (pp) increase in diversity\nand a 5.6-11.3 pp increase in novelty according to distinct and novel n-grams.\nThe generated poetry from TRAINING-BASED agents also exhibits group divergence\nin terms of lexicons, styles and semantics. PROMPTING-BASED agents in our\nframework also benefit from non-cooperative environments and a more diverse\nensemble of models with non-homogeneous agents has the potential to further\nenhance diversity, with an increase of 7.0-17.5 pp according to our\nexperiments. However, PROMPTING-BASED agents show a decrease in lexical\ndiversity over time and do not exhibit the group-based divergence intended in\nthe social network. Our paper argues for a paradigm shift in creative tasks\nsuch as automatic poetry generation to include social learning processes (via\nLLM-based agent modeling) similar to human interaction.", "published": "2024-09-05 16:12:29", "link": "http://arxiv.org/abs/2409.03659v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Attention Heads of Large Language Models: A Survey", "abstract": "Since the advent of ChatGPT, Large Language Models (LLMs) have excelled in\nvarious tasks but remain as black-box systems. Understanding the reasoning\nbottlenecks of LLMs has become a critical challenge, as these limitations are\ndeeply tied to their internal architecture. Among these, attention heads have\nemerged as a focal point for investigating the underlying mechanics of LLMs. In\nthis survey, we aim to demystify the internal reasoning processes of LLMs by\nsystematically exploring the roles and mechanisms of attention heads. We first\nintroduce a novel four-stage framework inspired by the human thought process:\nKnowledge Recalling, In-Context Identification, Latent Reasoning, and\nExpression Preparation. Using this framework, we comprehensively review\nexisting research to identify and categorize the functions of specific\nattention heads. Additionally, we analyze the experimental methodologies used\nto discover these special heads, dividing them into two categories:\nModeling-Free and Modeling-Required methods. We further summarize relevant\nevaluation methods and benchmarks. Finally, we discuss the limitations of\ncurrent research and propose several potential future directions.", "published": "2024-09-05 17:59:12", "link": "http://arxiv.org/abs/2409.03752v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Persona Setting Pitfall: Persistent Outgroup Biases in Large Language\n  Models Arising from Social Identity Adoption", "abstract": "Drawing parallels between human cognition and artificial intelligence, we\nexplored how large language models (LLMs) internalize identities imposed by\ntargeted prompts. Informed by Social Identity Theory, these identity\nassignments lead LLMs to distinguish between \"we\" (the ingroup) and \"they\" (the\noutgroup). This self-categorization generates both ingroup favoritism and\noutgroup bias. Nonetheless, existing literature has predominantly focused on\ningroup favoritism, often overlooking outgroup bias, which is a fundamental\nsource of intergroup prejudice and discrimination. Our experiment addresses\nthis gap by demonstrating that outgroup bias manifests as strongly as ingroup\nfavoritism. Furthermore, we successfully mitigated the inherent pro-liberal,\nanti-conservative bias in LLMs by guiding them to adopt the perspectives of the\ninitially disfavored group. These results were replicated in the context of\ngender bias. Our findings highlight the potential to develop more equitable and\nbalanced language models.", "published": "2024-09-05 18:08:47", "link": "http://arxiv.org/abs/2409.03843v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sirius: Contextual Sparsity with Correction for Efficient LLMs", "abstract": "With the blossom of large language models (LLMs), inference efficiency\nbecomes increasingly important. Various approximation methods are proposed to\nreduce the cost at inference time. Contextual Sparsity (CS) is appealing for\nits training-free nature and its ability to reach a higher compression ratio\nseemingly without quality degradation. However, after a comprehensive\nevaluation of contextual sparsity methods on various complex generation tasks,\nwe find that although CS succeeds in prompt-understanding tasks, CS\nsignificantly degrades the model performance for reasoning, deduction, and\nknowledge-based tasks. Despite the gap in end-to-end accuracy, we observed that\nsparse models often share general problem-solving logic and require only a few\ntoken corrections to recover the original model performance. This paper\nintroduces Sirius, an efficient correction mechanism, which significantly\nrecovers CS models quality on reasoning tasks while maintaining its efficiency\ngain. Sirius is evaluated on 6 models with 8 difficult generation tasks in\nreasoning, math, and coding and shows consistent effectiveness and efficiency.\nAlso, we carefully develop a system implementation for Sirius and show that\nSirius achieves roughly 20% reduction in latency for 8B model on-chip and 35%\nreduction for 70B model offloading. We open-source our implementation of Sirius\nat https://github.com/Infini-AI-Lab/Sirius.git.", "published": "2024-09-05 18:38:07", "link": "http://arxiv.org/abs/2409.03856v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CACER: Clinical Concept Annotations for Cancer Events and Relations", "abstract": "Clinical notes contain unstructured representations of patient histories,\nincluding the relationships between medical problems and prescription drugs. To\ninvestigate the relationship between cancer drugs and their associated symptom\nburden, we extract structured, semantic representations of medical problem and\ndrug information from the clinical narratives of oncology notes. We present\nClinical Concept Annotations for Cancer Events and Relations (CACER), a novel\ncorpus with fine-grained annotations for over 48,000 medical problems and drug\nevents and 10,000 drug-problem and problem-problem relations. Leveraging CACER,\nwe develop and evaluate transformer-based information extraction (IE) models\nsuch as BERT, Flan-T5, Llama3, and GPT-4 using fine-tuning and in-context\nlearning (ICL). In event extraction, the fine-tuned BERT and Llama3 models\nachieved the highest performance at 88.2-88.0 F1, which is comparable to the\ninter-annotator agreement (IAA) of 88.4 F1. In relation extraction, the\nfine-tuned BERT, Flan-T5, and Llama3 achieved the highest performance at\n61.8-65.3 F1. GPT-4 with ICL achieved the worst performance across both tasks.\nThe fine-tuned models significantly outperformed GPT-4 in ICL, highlighting the\nimportance of annotated training data and model optimization. Furthermore, the\nBERT models performed similarly to Llama3. For our task, LLMs offer no\nperformance advantage over the smaller BERT models. The results emphasize the\nneed for annotated training data to optimize models. Multiple fine-tuned\ntransformer models achieved performance comparable to IAA for several\nextraction tasks.", "published": "2024-09-05 20:42:35", "link": "http://arxiv.org/abs/2409.03905v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Experimentation in Content Moderation using RWKV", "abstract": "This paper investigates the RWKV model's efficacy in content moderation\nthrough targeted experimentation. We introduce a novel dataset specifically\ndesigned for distillation into smaller models, enhancing content moderation\npractices. This comprehensive dataset encompasses images, videos, sounds, and\ntext data that present societal challenges. Leveraging advanced Large Language\nModels (LLMs), we generated an extensive set of responses -- 558,958 for text\nand 83,625 for images -- to train and refine content moderation systems. Our\ncore experimentation involved fine-tuning the RWKV model, capitalizing on its\nCPU-efficient architecture to address large-scale content moderation tasks. By\nhighlighting the dataset's potential for knowledge distillation, this study not\nonly demonstrates RWKV's capability in improving the accuracy and efficiency of\ncontent moderation systems but also paves the way for developing more compact,\nresource-efficient models in this domain. Datasets and models can be found in\nHuggingFace: https://huggingface.co/modrwkv", "published": "2024-09-05 23:17:18", "link": "http://arxiv.org/abs/2409.03939v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Debate on Graph: a Flexible and Reliable Reasoning Framework for Large\n  Language Models", "abstract": "Large Language Models (LLMs) may suffer from hallucinations in real-world\napplications due to the lack of relevant knowledge. In contrast, knowledge\ngraphs encompass extensive, multi-relational structures that store a vast array\nof symbolic facts. Consequently, integrating LLMs with knowledge graphs has\nbeen extensively explored, with Knowledge Graph Question Answering (KGQA)\nserving as a critical touchstone for the integration. This task requires LLMs\nto answer natural language questions by retrieving relevant triples from\nknowledge graphs. However, existing methods face two significant challenges:\n\\textit{excessively long reasoning paths distracting from the answer\ngeneration}, and \\textit{false-positive relations hindering the path\nrefinement}. In this paper, we propose an iterative interactive KGQA framework\nthat leverages the interactive learning capabilities of LLMs to perform\nreasoning and Debating over Graphs (DoG). Specifically, DoG employs a\nsubgraph-focusing mechanism, allowing LLMs to perform answer trying after each\nreasoning step, thereby mitigating the impact of lengthy reasoning paths. On\nthe other hand, DoG utilizes a multi-role debate team to gradually simplify\ncomplex questions, reducing the influence of false-positive relations. This\ndebate mechanism ensures the reliability of the reasoning process. Experimental\nresults on five public datasets demonstrate the effectiveness and superiority\nof our architecture. Notably, DoG outperforms the state-of-the-art method ToG\nby 23.7\\% and 9.1\\% in accuracy on WebQuestions and GrailQA, respectively.\nFurthermore, the integration experiments with various LLMs on the mentioned\ndatasets highlight the flexibility of DoG. Code is available at\n\\url{https://github.com/reml-group/DoG}.", "published": "2024-09-05 01:11:58", "link": "http://arxiv.org/abs/2409.03155v1", "categories": ["cs.CL", "cs.AI", "I.2.4"], "primary_category": "cs.CL"}
{"title": "MaterialBENCH: Evaluating College-Level Materials Science\n  Problem-Solving Abilities of Large Language Models", "abstract": "A college-level benchmark dataset for large language models (LLMs) in the\nmaterials science field, MaterialBENCH, is constructed. This dataset consists\nof problem-answer pairs, based on university textbooks. There are two types of\nproblems: one is the free-response answer type, and the other is the\nmultiple-choice type. Multiple-choice problems are constructed by adding three\nincorrect answers as choices to a correct answer, so that LLMs can choose one\nof the four as a response. Most of the problems for free-response answer and\nmultiple-choice types overlap except for the format of the answers. We also\nconduct experiments using the MaterialBENCH on LLMs, including ChatGPT-3.5,\nChatGPT-4, Bard (at the time of the experiments), and GPT-3.5 and GPT-4 with\nthe OpenAI API. The differences and similarities in the performance of LLMs\nmeasured by the MaterialBENCH are analyzed and discussed. Performance\ndifferences between the free-response type and multiple-choice type in the same\nmodels and the influence of using system massages on multiple-choice problems\nare also studied. We anticipate that MaterialBENCH will encourage further\ndevelopments of LLMs in reasoning abilities to solve more complicated problems\nand eventually contribute to materials research and discovery.", "published": "2024-09-05 01:36:00", "link": "http://arxiv.org/abs/2409.03161v2", "categories": ["cs.CL", "cond-mat.mtrl-sci"], "primary_category": "cs.CL"}
{"title": "Bypassing DARCY Defense: Indistinguishable Universal Adversarial\n  Triggers", "abstract": "Neural networks (NN) classification models for Natural Language Processing\n(NLP) are vulnerable to the Universal Adversarial Triggers (UAT) attack that\ntriggers a model to produce a specific prediction for any input. DARCY borrows\nthe \"honeypot\" concept to bait multiple trapdoors, effectively detecting the\nadversarial examples generated by UAT. Unfortunately, we find a new UAT\ngeneration method, called IndisUAT, which produces triggers (i.e., tokens) and\nuses them to craft adversarial examples whose feature distribution is\nindistinguishable from that of the benign examples in a randomly-chosen\ncategory at the detection layer of DARCY. The produced adversarial examples\nincur the maximal loss of predicting results in the DARCY-protected models.\nMeanwhile, the produced triggers are effective in black-box models for text\ngeneration, text inference, and reading comprehension. Finally, the evaluation\nresults under NN models for NLP tasks indicate that the IndisUAT method can\neffectively circumvent DARCY and penetrate other defenses. For example,\nIndisUAT can reduce the true positive rate of DARCY's detection by at least\n40.8% and 90.6%, and drop the accuracy by at least 33.3% and 51.6% in the RNN\nand CNN models, respectively. IndisUAT reduces the accuracy of the BERT's\nadversarial defense model by at least 34.0%, and makes the GPT-2 language model\nspew racist outputs even when conditioned on non-racial context.", "published": "2024-09-05 02:19:34", "link": "http://arxiv.org/abs/2409.03183v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "An Effective Deployment of Diffusion LM for Data Augmentation in\n  Low-Resource Sentiment Classification", "abstract": "Sentiment classification (SC) often suffers from low-resource challenges such\nas domain-specific contexts, imbalanced label distributions, and few-shot\nscenarios. The potential of the diffusion language model (LM) for textual data\naugmentation (DA) remains unexplored, moreover, textual DA methods struggle to\nbalance the diversity and consistency of new samples. Most DA methods either\nperform logical modifications or rephrase less important tokens in the original\nsequence with the language model. In the context of SC, strong emotional tokens\ncould act critically on the sentiment of the whole sequence. Therefore,\ncontrary to rephrasing less important context, we propose DiffusionCLS to\nleverage a diffusion LM to capture in-domain knowledge and generate pseudo\nsamples by reconstructing strong label-related tokens. This approach ensures a\nbalance between consistency and diversity, avoiding the introduction of noise\nand augmenting crucial features of datasets. DiffusionCLS also comprises a\nNoise-Resistant Training objective to help the model generalize. Experiments\ndemonstrate the effectiveness of our method in various low-resource scenarios\nincluding domain-specific and domain-general problems. Ablation studies confirm\nthe effectiveness of our framework's modules, and visualization studies\nhighlight optimal deployment conditions, reinforcing our conclusions.", "published": "2024-09-05 02:51:28", "link": "http://arxiv.org/abs/2409.03203v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Preserving Empirical Probabilities in BERT for Small-sample Clinical\n  Entity Recognition", "abstract": "Named Entity Recognition (NER) encounters the challenge of unbalanced labels,\nwhere certain entity types are overrepresented while others are\nunderrepresented in real-world datasets. This imbalance can lead to biased\nmodels that perform poorly on minority entity classes, impeding accurate and\nequitable entity recognition. This paper explores the effects of unbalanced\nentity labels of the BERT-based pre-trained model. We analyze the different\nmechanisms of loss calculation and loss propagation for the task of token\nclassification on randomized datasets. Then we propose ways to improve the\ntoken classification for the highly imbalanced task of clinical entity\nrecognition.", "published": "2024-09-05 04:38:49", "link": "http://arxiv.org/abs/2409.03238v1", "categories": ["cs.CL", "cs.LG", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "E2CL: Exploration-based Error Correction Learning for Embodied Agents", "abstract": "Language models are exhibiting increasing capability in knowledge utilization\nand reasoning. However, when applied as agents in embodied environments, they\noften suffer from misalignment between their intrinsic knowledge and\nenvironmental knowledge, leading to infeasible actions. Traditional environment\nalignment methods, such as supervised learning on expert trajectories and\nreinforcement learning, encounter limitations in covering environmental\nknowledge and achieving efficient convergence, respectively. Inspired by human\nlearning, we propose Exploration-based Error Correction Learning (E2CL), a\nnovel framework that leverages exploration-induced errors and environmental\nfeedback to enhance environment alignment for embodied agents. E2CL\nincorporates teacher-guided and teacher-free explorations to gather\nenvironmental feedback and correct erroneous actions. The agent learns to\nprovide feedback and self-correct, thereby enhancing its adaptability to target\nenvironments. Extensive experiments in the VirtualHome environment demonstrate\nthat E2CL-trained agents outperform those trained by baseline methods and\nexhibit superior self-correction capabilities.", "published": "2024-09-05 05:22:27", "link": "http://arxiv.org/abs/2409.03256v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Understanding LLM Development Through Longitudinal Study: Insights from\n  the Open Ko-LLM Leaderboard", "abstract": "This paper conducts a longitudinal study over eleven months to address the\nlimitations of prior research on the Open Ko-LLM Leaderboard, which have relied\non empirical studies with restricted observation periods of only five months.\nBy extending the analysis duration, we aim to provide a more comprehensive\nunderstanding of the progression in developing Korean large language models\n(LLMs). Our study is guided by three primary research questions: (1) What are\nthe specific challenges in improving LLM performance across diverse tasks on\nthe Open Ko-LLM Leaderboard over time? (2) How does model size impact task\nperformance correlations across various benchmarks? (3) How have the patterns\nin leaderboard rankings shifted over time on the Open Ko-LLM Leaderboard?. By\nanalyzing 1,769 models over this period, our research offers a comprehensive\nexamination of the ongoing advancements in LLMs and the evolving nature of\nevaluation frameworks.", "published": "2024-09-05 05:31:29", "link": "http://arxiv.org/abs/2409.03257v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "N-gram Prediction and Word Difference Representations for Language\n  Modeling", "abstract": "Causal language modeling (CLM) serves as the foundational framework\nunderpinning remarkable successes of recent large language models (LLMs).\nDespite its success, the training approach for next word prediction poses a\npotential risk of causing the model to overly focus on local dependencies\nwithin a sentence. While prior studies have been introduced to predict future N\nwords simultaneously, they were primarily applied to tasks such as masked\nlanguage modeling (MLM) and neural machine translation (NMT). In this study, we\nintroduce a simple N-gram prediction framework for the CLM task. Moreover, we\nintroduce word difference representation (WDR) as a surrogate and\ncontextualized target representation during model training on the basis of\nN-gram prediction framework. To further enhance the quality of next word\nprediction, we propose an ensemble method that incorporates the future N words'\nprediction results. Empirical evaluations across multiple benchmark datasets\nencompassing CLM and NMT tasks demonstrate the significant advantages of our\nproposed methods over the conventional CLM.", "published": "2024-09-05 07:03:23", "link": "http://arxiv.org/abs/2409.03295v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Normal forms in Virus Machines", "abstract": "In the present work, we further study the computational power of virus\nmachines (VMs in short). VMs provide a computing paradigm inspired by the\ntransmission and replication networks of viruses. VMs consist of process units\n(called hosts) structured by a directed graph whose arcs are called channels\nand an instruction graph that controls the transmissions of virus objects among\nhosts. The present work complements our understanding of the computing power of\nVMs by introducing normal forms; these expressions restrict the features in a\ngiven computing model. Some of the features that we restrict in our normal\nforms include (a) the number of hosts, (b) the number of instructions, and (c)\nthe number of virus objects in each host. After we recall some known results on\nthe computing power of VMs we give our normal forms, such as the size of the\nloops in the network, proving new characterisations of family of sets, such as\nthe finite sets, semilinear sets, or NRE.", "published": "2024-09-05 08:03:47", "link": "http://arxiv.org/abs/2409.03327v1", "categories": ["cs.CL", "cs.FL", "68Q07 (Primary) 68Q10, 68R01 (Secondary)", "F.0; F.1.1"], "primary_category": "cs.CL"}
{"title": "Sketch: A Toolkit for Streamlining LLM Operations", "abstract": "Large language models (LLMs) represented by GPT family have achieved\nremarkable success. The characteristics of LLMs lie in their ability to\naccommodate a wide range of tasks through a generative approach. However, the\nflexibility of their output format poses challenges in controlling and\nharnessing the model's outputs, thereby constraining the application of LLMs in\nvarious domains. In this work, we present Sketch, an innovative toolkit\ndesigned to streamline LLM operations across diverse fields. Sketch comprises\nthe following components: (1) a suite of task description schemas and prompt\ntemplates encompassing various NLP tasks; (2) a user-friendly, interactive\nprocess for building structured output LLM services tailored to various NLP\ntasks; (3) an open-source dataset for output format control, along with tools\nfor dataset construction; and (4) an open-source model based on\nLLaMA3-8B-Instruct that adeptly comprehends and adheres to output formatting\ninstructions. We anticipate this initiative to bring considerable convenience\nto LLM users, achieving the goal of ''plug-and-play'' for various applications.\nThe components of Sketch will be progressively open-sourced at\nhttps://github.com/cofe-ai/Sketch.", "published": "2024-09-05 08:45:44", "link": "http://arxiv.org/abs/2409.03346v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CogniDual Framework: Self-Training Large Language Models within a\n  Dual-System Theoretical Framework for Improving Cognitive Tasks", "abstract": "Cognitive psychology investigates perception, attention, memory, language,\nproblem-solving, decision-making, and reasoning. Kahneman's dual-system theory\nelucidates the human decision-making process, distinguishing between the rapid,\nintuitive System 1 and the deliberative, rational System 2. Recent advancements\nhave positioned large language Models (LLMs) as formidable tools nearing\nhuman-level proficiency in various cognitive tasks. Nonetheless, the presence\nof a dual-system framework analogous to human cognition in LLMs remains\nunexplored. This study introduces the \\textbf{CogniDual Framework for LLMs}\n(CFLLMs), designed to assess whether LLMs can, through self-training, evolve\nfrom deliberate deduction to intuitive responses, thereby emulating the human\nprocess of acquiring and mastering new information. Our findings reveal the\ncognitive mechanisms behind LLMs' response generation, enhancing our\nunderstanding of their capabilities in cognitive psychology. Practically,\nself-trained models can provide faster responses to certain queries, reducing\ncomputational demands during inference.", "published": "2024-09-05 09:33:24", "link": "http://arxiv.org/abs/2409.03381v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "How Much Data is Enough Data? Fine-Tuning Large Language Models for\n  In-House Translation: Performance Evaluation Across Multiple Dataset Sizes", "abstract": "Decoder-only LLMs have shown impressive performance in MT due to their\nability to learn from extensive datasets and generate high-quality\ntranslations. However, LLMs often struggle with the nuances and style required\nfor organisation-specific translation. In this study, we explore the\neffectiveness of fine-tuning Large Language Models (LLMs), particularly Llama 3\n8B Instruct, leveraging translation memories (TMs), as a valuable resource to\nenhance accuracy and efficiency. We investigate the impact of fine-tuning the\nLlama 3 model using TMs from a specific organisation in the software sector.\nOur experiments cover five translation directions across languages of varying\nresource levels (English to Brazilian Portuguese, Czech, German, Finnish, and\nKorean). We analyse diverse sizes of training datasets (1k to 207k segments) to\nevaluate their influence on translation quality. We fine-tune separate models\nfor each training set and evaluate their performance based on automatic\nmetrics, BLEU, chrF++, TER, and COMET. Our findings reveal improvement in\ntranslation performance with larger datasets across all metrics. On average,\nBLEU and COMET scores increase by 13 and 25 points, respectively, on the\nlargest training set against the baseline model. Notably, there is a\nperformance deterioration in comparison with the baseline model when\nfine-tuning on only 1k and 2k examples; however, we observe a substantial\nimprovement as the training dataset size increases. The study highlights the\npotential of integrating TMs with LLMs to create bespoke translation models\ntailored to the specific needs of businesses, thus enhancing translation\nquality and reducing turn-around times. This approach offers a valuable insight\nfor organisations seeking to leverage TMs and LLMs for optimal translation\noutcomes, especially in narrower domains.", "published": "2024-09-05 12:06:38", "link": "http://arxiv.org/abs/2409.03454v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "From MOOC to MAIC: Reshaping Online Teaching and Learning through\n  LLM-driven Agents", "abstract": "Since the first instances of online education, where courses were uploaded to\naccessible and shared online platforms, this form of scaling the dissemination\nof human knowledge to reach a broader audience has sparked extensive discussion\nand widespread adoption. Recognizing that personalized learning still holds\nsignificant potential for improvement, new AI technologies have been\ncontinuously integrated into this learning format, resulting in a variety of\neducational AI applications such as educational recommendation and intelligent\ntutoring. The emergence of intelligence in large language models (LLMs) has\nallowed for these educational enhancements to be built upon a unified\nfoundational model, enabling deeper integration. In this context, we propose\nMAIC (Massive AI-empowered Course), a new form of online education that\nleverages LLM-driven multi-agent systems to construct an AI-augmented\nclassroom, balancing scalability with adaptivity. Beyond exploring the\nconceptual framework and technical innovations, we conduct preliminary\nexperiments at Tsinghua University, one of China's leading universities.\nDrawing from over 100,000 learning records of more than 500 students, we obtain\na series of valuable observations and initial analyses. This project will\ncontinue to evolve, ultimately aiming to establish a comprehensive open\nplatform that supports and unifies research, technology, and applications in\nexploring the possibilities of online education in the era of large model AI.\nWe envision this platform as a collaborative hub, bringing together educators,\nresearchers, and innovators to collectively explore the future of AI-driven\nonline education.", "published": "2024-09-05 13:22:51", "link": "http://arxiv.org/abs/2409.03512v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Image Over Text: Transforming Formula Recognition Evaluation with\n  Character Detection Matching", "abstract": "Formula recognition presents significant challenges due to the complicated\nstructure and varied notation of mathematical expressions. Despite continuous\nadvancements in formula recognition models, the evaluation metrics employed by\nthese models, such as BLEU and Edit Distance, still exhibit notable\nlimitations. They overlook the fact that the same formula has diverse\nrepresentations and is highly sensitive to the distribution of training data,\nthereby causing unfairness in formula recognition evaluation. To this end, we\npropose a Character Detection Matching (CDM) metric, ensuring the evaluation\nobjectivity by designing an image-level rather than a LaTeX-level metric score.\nSpecifically, CDM renders both the model-predicted LaTeX and the ground-truth\nLaTeX formulas into image-formatted formulas, then employs visual feature\nextraction and localization techniques for precise character-level matching,\nincorporating spatial position information. Such a spatially-aware and\ncharacter-matching method offers a more accurate and equitable evaluation\ncompared with previous BLEU and Edit Distance metrics that rely solely on\ntext-based character matching. Experimentally, we evaluated various formula\nrecognition models using CDM, BLEU, and ExpRate metrics. Their results\ndemonstrate that the CDM aligns more closely with human evaluation standards\nand provides a fairer comparison across different models by eliminating\ndiscrepancies caused by diverse formula representations. Code is available at\nhttps://github.com/opendatalab/UniMERNet/tree/main/cdm.", "published": "2024-09-05 16:01:21", "link": "http://arxiv.org/abs/2409.03643v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "On the Limited Generalization Capability of the Implicit Reward Model\n  Induced by Direct Preference Optimization", "abstract": "Reinforcement Learning from Human Feedback (RLHF) is an effective approach\nfor aligning language models to human preferences. Central to RLHF is learning\na reward function for scoring human preferences. Two main approaches for\nlearning a reward model are 1) training an EXplicit Reward Model (EXRM) as in\nRLHF, and 2) using an implicit reward learned from preference data through\nmethods such as Direct Preference Optimization (DPO). Prior work has shown that\nthe implicit reward model of DPO (denoted as DPORM) can approximate an EXRM in\nthe limit. DPORM's effectiveness directly implies the optimality of the learned\npolicy, and also has practical implication for LLM alignment methods including\niterative DPO. However, it is unclear how well DPORM empirically matches the\nperformance of EXRM. This work studies the accuracy at distinguishing preferred\nand rejected answers for both DPORM and EXRM. Our findings indicate that even\nthough DPORM fits the training dataset comparably, it generalizes less\neffectively than EXRM, especially when the validation datasets contain\ndistribution shifts. Across five out-of-distribution settings, DPORM has a mean\ndrop in accuracy of 3% and a maximum drop of 7%. These findings highlight that\nDPORM has limited generalization ability and substantiates the integration of\nan explicit reward model in iterative DPO approaches.", "published": "2024-09-05 16:08:19", "link": "http://arxiv.org/abs/2409.03650v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "The representation landscape of few-shot learning and fine-tuning in\n  large language models", "abstract": "In-context learning (ICL) and supervised fine-tuning (SFT) are two common\nstrategies for improving the performance of modern large language models (LLMs)\non specific tasks. Despite their different natures, these strategies often lead\nto comparable performance gains. However, little is known about whether they\ninduce similar representations inside LLMs. We approach this problem by\nanalyzing the probability landscape of their hidden representations in the two\ncases. More specifically, we compare how LLMs solve the same question-answering\ntask, finding that ICL and SFT create very different internal structures, in\nboth cases undergoing a sharp transition in the middle of the network. In the\nfirst half of the network, ICL shapes interpretable representations\nhierarchically organized according to their semantic content. In contrast, the\nprobability landscape obtained with SFT is fuzzier and semantically mixed. In\nthe second half of the model, the fine-tuned representations develop\nprobability modes that better encode the identity of answers, while the\nlandscape of ICL representations is characterized by less defined peaks. Our\napproach reveals the diverse computational strategies developed inside LLMs to\nsolve the same task across different conditions, allowing us to make a step\ntowards designing optimal methods to extract information from language models.", "published": "2024-09-05 16:15:12", "link": "http://arxiv.org/abs/2409.03662v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Fused Large Language Model for Predicting Startup Success", "abstract": "Investors are continuously seeking profitable investment opportunities in\nstartups and, hence, for effective decision-making, need to predict a startup's\nprobability of success. Nowadays, investors can use not only various\nfundamental information about a startup (e.g., the age of the startup, the\nnumber of founders, and the business sector) but also textual description of a\nstartup's innovation and business model, which is widely available through\nonline venture capital (VC) platforms such as Crunchbase. To support the\ndecision-making of investors, we develop a machine learning approach with the\naim of locating successful startups on VC platforms. Specifically, we develop,\ntrain, and evaluate a tailored, fused large language model to predict startup\nsuccess. Thereby, we assess to what extent self-descriptions on VC platforms\nare predictive of startup success. Using 20,172 online profiles from\nCrunchbase, we find that our fused large language model can predict startup\nsuccess, with textual self-descriptions being responsible for a significant\npart of the predictive power. Our work provides a decision support tool for\ninvestors to find profitable investment opportunities.", "published": "2024-09-05 16:22:31", "link": "http://arxiv.org/abs/2409.03668v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "A Different Level Text Protection Mechanism With Differential Privacy", "abstract": "The article introduces a method for extracting words of different degrees of\nimportance based on the BERT pre-training model and proves the effectiveness of\nthis method. The article also discusses the impact of maintaining the same\nperturbation results for words of different importance on the overall text\nutility. This method can be applied to long text protection.", "published": "2024-09-05 17:13:38", "link": "http://arxiv.org/abs/2409.03707v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "RAG based Question-Answering for Contextual Response Prediction System", "abstract": "Large Language Models (LLMs) have shown versatility in various Natural\nLanguage Processing (NLP) tasks, including their potential as effective\nquestion-answering systems. However, to provide precise and relevant\ninformation in response to specific customer queries in industry settings, LLMs\nrequire access to a comprehensive knowledge base to avoid hallucinations.\nRetrieval Augmented Generation (RAG) emerges as a promising technique to\naddress this challenge. Yet, developing an accurate question-answering\nframework for real-world applications using RAG entails several challenges: 1)\ndata availability issues, 2) evaluating the quality of generated content, and\n3) the costly nature of human evaluation. In this paper, we introduce an\nend-to-end framework that employs LLMs with RAG capabilities for industry use\ncases. Given a customer query, the proposed system retrieves relevant knowledge\ndocuments and leverages them, along with previous chat history, to generate\nresponse suggestions for customer service agents in the contact centers of a\nmajor retail company. Through comprehensive automated and human evaluations, we\nshow that this solution outperforms the current BERT-based algorithms in\naccuracy and relevance. Our findings suggest that RAG-based LLMs can be an\nexcellent support to human customer service representatives by lightening their\nworkload.", "published": "2024-09-05 17:14:23", "link": "http://arxiv.org/abs/2409.03708v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "CA-BERT: Leveraging Context Awareness for Enhanced Multi-Turn Chat\n  Interaction", "abstract": "Effective communication in automated chat systems hinges on the ability to\nunderstand and respond to context. Traditional models often struggle with\ndetermining when additional context is necessary for generating appropriate\nresponses. This paper introduces Context-Aware BERT (CA-BERT), a\ntransformer-based model specifically fine-tuned to address this challenge.\nCA-BERT innovatively applies deep learning techniques to discern context\nnecessity in multi-turn chat interactions, enhancing both the relevance and\naccuracy of responses.\n  We describe the development of CA-BERT, which adapts the robust architecture\nof BERT with a novel training regimen focused on a specialized dataset of chat\ndialogues. The model is evaluated on its ability to classify context necessity,\ndemonstrating superior performance over baseline BERT models in terms of\naccuracy and efficiency. Furthermore, CA-BERT's implementation showcases\nsignificant reductions in training time and resource usage, making it feasible\nfor real-time applications.\n  The results indicate that CA-BERT can effectively enhance the functionality\nof chatbots by providing a nuanced understanding of context, thereby improving\nuser experience and interaction quality in automated systems. This study not\nonly advances the field of NLP in chat applications but also provides a\nframework for future research into context-sensitive AI developments.", "published": "2024-09-05 06:27:59", "link": "http://arxiv.org/abs/2409.13701v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Shaping the Future of Endangered and Low-Resource Languages -- Our Role\n  in the Age of LLMs: A Keynote at ECIR 2024", "abstract": "Isidore of Seville is credited with the adage that it is language that gives\nbirth to a people, and not the other way around , underlining the profound role\nplayed by language in the formation of cultural and social identity. Today, of\nthe more than 7100 languages listed, a significant number are endangered. Since\nthe 1970s, linguists, information seekers and enthusiasts have helped develop\ndigital resources and automatic tools to support a wide range of languages,\nincluding endangered ones. The advent of Large Language Model (LLM)\ntechnologies holds both promise and peril. They offer unprecedented\npossibilities for the translation and generation of content and resources, key\nelements in the preservation and revitalisation of languages. They also present\nthreat of homogenisation, cultural oversimplification and the further\nmarginalisation of already vulnerable languages. The talk this paper is based\non has proposed an initiatory journey, exploring the potential paths and\npartnerships between technology and tradition, with a particular focus on the\nOccitan language. Occitan is a language from Southern France, parts of Spain\nand Italy that played a major cultural and economic role, particularly in the\nMiddle Ages. It is now endangered according to UNESCO. The talk critically has\nexamined how human expertise and artificial intelligence can work together to\noffer hope for preserving the linguistic diversity that forms the foundation of\nour global and especially our European heritage while addressing some of the\nethical and practical challenges that accompany the use of these powerful\ntechnologies. This paper is based on the keynote I gave at the 46th European\nConference on Information Retrieval (ECIR 2024). As an alternative to reading\nthis paper, a video talk is available online. 1 Date: 26 March 2024.", "published": "2024-09-05 06:54:30", "link": "http://arxiv.org/abs/2409.13702v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Entity Extraction from High-Level Corruption Schemes via Large Language\n  Models", "abstract": "The rise of financial crime that has been observed in recent years has\ncreated an increasing concern around the topic and many people, organizations\nand governments are more and more frequently trying to combat it. Despite the\nincrease of interest in this area, there is a lack of specialized datasets that\ncan be used to train and evaluate works that try to tackle those problems. This\narticle proposes a new micro-benchmark dataset for algorithms and models that\nidentify individuals and organizations, and their multiple writings, in news\narticles, and presents an approach that assists in its creation. Experimental\nefforts are also reported, using this dataset, to identify individuals and\norganizations in financial-crime-related articles using various low-billion\nparameter Large Language Models (LLMs). For these experiments, standard metrics\n(Accuracy, Precision, Recall, F1 Score) are reported and various prompt\nvariants comprising the best practices of prompt engineering are tested. In\naddition, to address the problem of ambiguous entity mentions, a simple, yet\neffective LLM-based disambiguation method is proposed, ensuring that the\nevaluation aligns with reality. Finally, the proposed approach is compared\nagainst a widely used state-of-the-art open-source baseline, showing the\nsuperiority of the proposed method.", "published": "2024-09-05 10:27:32", "link": "http://arxiv.org/abs/2409.13704v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "GraphEx: A Graph-based Extraction Method for Advertiser Keyphrase\n  Recommendation", "abstract": "Online sellers and advertisers are recommended keyphrases for their listed\nproducts, which they bid on to enhance their sales. One popular paradigm that\ngenerates such recommendations is Extreme Multi-Label Classification (XMC),\nwhich involves tagging/mapping keyphrases to items. We outline the limitations\nof using traditional item-query based tagging or mapping techniques for\nkeyphrase recommendations on E-Commerce platforms. We introduce GraphEx, an\ninnovative graph-based approach that recommends keyphrases to sellers using\nextraction of token permutations from item titles. Additionally, we demonstrate\nthat relying on traditional metrics such as precision/recall can be misleading\nin practical applications, thereby necessitating a combination of metrics to\nevaluate performance in real-world scenarios. These metrics are designed to\nassess the relevance of keyphrases to items and the potential for buyer\noutreach. GraphEx outperforms production models at eBay, achieving the\nobjectives mentioned above. It supports near real-time inferencing in\nresource-constrained production environments and scales effectively for\nbillions of items.", "published": "2024-09-05 00:25:37", "link": "http://arxiv.org/abs/2409.03140v3", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Continual Skill and Task Learning via Dialogue", "abstract": "Continual and interactive robot learning is a challenging problem as the\nrobot is present with human users who expect the robot to learn novel skills to\nsolve novel tasks perpetually with sample efficiency. In this work we present a\nframework for robots to query and learn visuo-motor robot skills and task\nrelevant information via natural language dialog interactions with human users.\nPrevious approaches either focus on improving the performance of instruction\nfollowing agents, or passively learn novel skills or concepts. Instead, we used\ndialog combined with a language-skill grounding embedding to query or confirm\nskills and/or tasks requested by a user. To achieve this goal, we developed and\nintegrated three different components for our agent. Firstly, we propose a\nnovel visual-motor control policy ACT with Low Rank Adaptation (ACT-LoRA),\nwhich enables the existing SoTA ACT model to perform few-shot continual\nlearning. Secondly, we develop an alignment model that projects demonstrations\nacross skill embodiments into a shared embedding allowing us to know when to\nask questions and/or demonstrations from users. Finally, we integrated an\nexisting LLM to interact with a human user to perform grounded interactive\ncontinual skill learning to solve a task. Our ACT-LoRA model learns novel\nfine-tuned skills with a 100% accuracy when trained with only five\ndemonstrations for a novel skill while still maintaining a 74.75% accuracy on\npre-trained skills in the RLBench dataset where other models fall significantly\nshort. We also performed a human-subjects study with 8 subjects to demonstrate\nthe continual learning capabilities of our combined framework. We achieve a\nsuccess rate of 75% in the task of sandwich making with the real robot learning\nfrom participant data demonstrating that robots can learn novel skills or task\nknowledge from dialogue with non-expert users using our approach.", "published": "2024-09-05 01:51:54", "link": "http://arxiv.org/abs/2409.03166v2", "categories": ["cs.RO", "cs.AI", "cs.CL"], "primary_category": "cs.RO"}
{"title": "xLAM: A Family of Large Action Models to Empower AI Agent Systems", "abstract": "Autonomous agents powered by large language models (LLMs) have attracted\nsignificant research interest. However, the open-source community faces many\nchallenges in developing specialized models for agent tasks, driven by the\nscarcity of high-quality agent datasets and the absence of standard protocols\nin this area. We introduce and publicly release xLAM, a series of large action\nmodels designed for AI agent tasks. The xLAM series includes five models with\nboth dense and mixture-of-expert architectures, ranging from 1B to 8x22B\nparameters, trained using a scalable, flexible pipeline that unifies, augments,\nand synthesizes diverse datasets to enhance AI agents' generalizability and\nperformance across varied environments. Our experimental results demonstrate\nthat xLAM consistently delivers exceptional performance across multiple agent\nability benchmarks, notably securing the 1st position on the Berkeley\nFunction-Calling Leaderboard, outperforming GPT-4, Claude-3, and many other\nmodels in terms of tool use. By releasing the xLAM series, we aim to advance\nthe performance of open-source LLMs for autonomous AI agents, potentially\naccelerating progress and democratizing access to high-performance models for\nagent tasks. Models are available at\nhttps://huggingface.co/collections/Salesforce/xlam-models-65f00e2a0a63bbcd1c2dade4", "published": "2024-09-05 03:22:22", "link": "http://arxiv.org/abs/2409.03215v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Strategic Chain-of-Thought: Guiding Accurate Reasoning in LLMs through\n  Strategy Elicitation", "abstract": "The Chain-of-Thought (CoT) paradigm has emerged as a critical approach for\nenhancing the reasoning capabilities of large language models (LLMs). However,\ndespite their widespread adoption and success, CoT methods often exhibit\ninstability due to their inability to consistently ensure the quality of\ngenerated reasoning paths, leading to sub-optimal reasoning performance. To\naddress this challenge, we propose the \\textbf{Strategic Chain-of-Thought}\n(SCoT), a novel methodology designed to refine LLM performance by integrating\nstrategic knowledge prior to generating intermediate reasoning steps. SCoT\nemploys a two-stage approach within a single prompt: first eliciting an\neffective problem-solving strategy, which is then used to guide the generation\nof high-quality CoT paths and final answers. Our experiments across eight\nchallenging reasoning datasets demonstrate significant improvements, including\na 21.05\\% increase on the GSM8K dataset and 24.13\\% on the Tracking\\_Objects\ndataset, respectively, using the Llama3-8b model. Additionally, we extend the\nSCoT framework to develop a few-shot method with automatically matched\ndemonstrations, yielding even stronger results. These findings underscore the\nefficacy of SCoT, highlighting its potential to substantially enhance LLM\nperformance in complex reasoning tasks.", "published": "2024-09-05 06:28:05", "link": "http://arxiv.org/abs/2409.03271v1", "categories": ["cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.AI"}
{"title": "ChartMoE: Mixture of Diversely Aligned Expert Connector for Chart\n  Understanding", "abstract": "Automatic chart understanding is crucial for content comprehension and\ndocument parsing. Multimodal Large Language Models (MLLMs) have demonstrated\nremarkable capabilities in chart understanding through domain-specific\nalignment and fine-tuning. However, current MLLMs still struggle to provide\nfaithful data and reliable analysis only based on charts. To address it, we\npropose ChartMoE, which employs the Mixture of Expert (MoE) architecture to\nreplace the traditional linear projector to bridge the modality gap.\nSpecifically, we train several linear connectors through distinct alignment\ntasks, which are utilized as the foundational initialization parameters for\ndifferent experts. Additionally, we introduce ChartMoE-Align, a dataset with\nnearly 1 million chart-table-JSON-code quadruples to conduct three alignment\ntasks (chart-table/JSON/code). Combined with the vanilla connector, we\ninitialize different experts diversely and adopt high-quality knowledge\nlearning to further refine the MoE connector and LLM parameters. Extensive\nexperiments demonstrate the effectiveness of the MoE connector and our\ninitialization strategy, e.g., ChartMoE improves the accuracy of the previous\nstate-of-the-art from 80.48\\% to 84.64\\% on the ChartQA benchmark.", "published": "2024-09-05 06:41:02", "link": "http://arxiv.org/abs/2409.03277v3", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "iText2KG: Incremental Knowledge Graphs Construction Using Large Language\n  Models", "abstract": "Most available data is unstructured, making it challenging to access valuable\ninformation. Automatically building Knowledge Graphs (KGs) is crucial for\nstructuring data and making it accessible, allowing users to search for\ninformation effectively. KGs also facilitate insights, inference, and\nreasoning. Traditional NLP methods, such as named entity recognition and\nrelation extraction, are key in information retrieval but face limitations,\nincluding the use of predefined entity types and the need for supervised\nlearning. Current research leverages large language models' capabilities, such\nas zero- or few-shot learning. However, unresolved and semantically duplicated\nentities and relations still pose challenges, leading to inconsistent graphs\nand requiring extensive post-processing. Additionally, most approaches are\ntopic-dependent. In this paper, we propose iText2KG, a method for incremental,\ntopic-independent KG construction without post-processing. This plug-and-play,\nzero-shot method is applicable across a wide range of KG construction scenarios\nand comprises four modules: Document Distiller, Incremental Entity Extractor,\nIncremental Relation Extractor, and Graph Integrator and Visualization. Our\nmethod demonstrates superior performance compared to baseline methods across\nthree scenarios: converting scientific papers to graphs, websites to graphs,\nand CVs to graphs.", "published": "2024-09-05 06:49:14", "link": "http://arxiv.org/abs/2409.03284v1", "categories": ["cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.AI"}
{"title": "LLM Detectors Still Fall Short of Real World: Case of LLM-Generated\n  Short News-Like Posts", "abstract": "With the emergence of widely available powerful LLMs, disinformation\ngenerated by large Language Models (LLMs) has become a major concern.\nHistorically, LLM detectors have been touted as a solution, but their\neffectiveness in the real world is still to be proven. In this paper, we focus\non an important setting in information operations -- short news-like posts\ngenerated by moderately sophisticated attackers.\n  We demonstrate that existing LLM detectors, whether zero-shot or\npurpose-trained, are not ready for real-world use in that setting. All tested\nzero-shot detectors perform inconsistently with prior benchmarks and are highly\nvulnerable to sampling temperature increase, a trivial attack absent from\nrecent benchmarks. A purpose-trained detector generalizing across LLMs and\nunseen attacks can be developed, but it fails to generalize to new\nhuman-written texts.\n  We argue that the former indicates domain-specific benchmarking is needed,\nwhile the latter suggests a trade-off between the adversarial evasion\nresilience and overfitting to the reference human text, with both needing\nevaluation in benchmarks and currently absent. We believe this suggests a\nre-consideration of current LLM detector benchmarking approaches and provides a\ndynamically extensible benchmark to allow it\n(https://github.com/Reliable-Information-Lab-HEVS/benchmark_llm_texts_detection).", "published": "2024-09-05 06:55:13", "link": "http://arxiv.org/abs/2409.03291v2", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG", "I.2.7; K.6.5"], "primary_category": "cs.CL"}
{"title": "Leveraging Large Language Models through Natural Language Processing to\n  provide interpretable Machine Learning predictions of mental deterioration in\n  real time", "abstract": "Based on official estimates, 50 million people worldwide are affected by\ndementia, and this number increases by 10 million new patients every year.\nWithout a cure, clinical prognostication and early intervention represent the\nmost effective ways to delay its progression. To this end, Artificial\nIntelligence and computational linguistics can be exploited for natural\nlanguage analysis, personalized assessment, monitoring, and treatment. However,\ntraditional approaches need more semantic knowledge management and\nexplicability capabilities. Moreover, using Large Language Models (LLMs) for\ncognitive decline diagnosis is still scarce, even though these models represent\nthe most advanced way for clinical-patient communication using intelligent\nsystems. Consequently, we leverage an LLM using the latest Natural Language\nProcessing (NLP) techniques in a chatbot solution to provide interpretable\nMachine Learning prediction of cognitive decline in real-time.\nLinguistic-conceptual features are exploited for appropriate natural language\nanalysis. Through explainability, we aim to fight potential biases of the\nmodels and improve their potential to help clinical workers in their diagnosis\ndecisions. More in detail, the proposed pipeline is composed of (i) data\nextraction employing NLP-based prompt engineering; (ii) stream-based data\nprocessing including feature engineering, analysis, and selection; (iii)\nreal-time classification; and (iv) the explainability dashboard to provide\nvisual and natural language descriptions of the prediction outcome.\nClassification results exceed 80 % in all evaluation metrics, with a recall\nvalue for the mental deterioration class about 85 %. To sum up, we contribute\nwith an affordable, flexible, non-invasive, personalized diagnostic system to\nthis work.", "published": "2024-09-05 09:27:05", "link": "http://arxiv.org/abs/2409.03375v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fine-tuning large language models for domain adaptation: Exploration of\n  training strategies, scaling, model merging and synergistic capabilities", "abstract": "The advancement of Large Language Models (LLMs) for domain applications in\nfields such as materials science and engineering depends on the development of\nfine-tuning strategies that adapt models for specialized, technical\ncapabilities. In this work, we explore the effects of Continued Pretraining\n(CPT), Supervised Fine-Tuning (SFT), and various preference-based optimization\napproaches, including Direct Preference Optimization (DPO) and Odds Ratio\nPreference Optimization (ORPO), on fine-tuned LLM performance. Our analysis\nshows how these strategies influence model outcomes and reveals that the\nmerging of multiple fine-tuned models can lead to the emergence of capabilities\nthat surpass the individual contributions of the parent models. We find that\nmodel merging leads to new functionalities that neither parent model could\nachieve alone, leading to improved performance in domain-specific assessments.\nExperiments with different model architectures are presented, including Llama\n3.1 8B and Mistral 7B models, where similar behaviors are observed. Exploring\nwhether the results hold also for much smaller models, we use a tiny LLM with\n1.7 billion parameters and show that very small LLMs do not necessarily feature\nemergent capabilities under model merging, suggesting that model scaling may be\na key component. In open-ended yet consistent chat conversations between a\nhuman and AI models, our assessment reveals detailed insights into how\ndifferent model variants perform and show that the smallest model achieves a\nhigh intelligence score across key criteria including reasoning depth,\ncreativity, clarity, and quantitative precision. Other experiments include the\ndevelopment of image generation prompts based on disparate biological material\ndesign concepts, to create new microstructures, architectural concepts, and\nurban design based on biological materials-inspired construction principles.", "published": "2024-09-05 11:49:53", "link": "http://arxiv.org/abs/2409.03444v1", "categories": ["cs.CL", "cond-mat.mtrl-sci", "cs.AI"], "primary_category": "cs.CL"}
{"title": "100 instances is all you need: predicting the success of a new LLM on\n  unseen data by testing on a few instances", "abstract": "Predicting the performance of LLMs on individual task instances is essential\nto ensure their reliability in high-stakes applications. To do so, a\npossibility is to evaluate the considered LLM on a set of task instances and\ntrain an assessor to predict its performance based on features of the\ninstances. However, this approach requires evaluating each new LLM on a\nsufficiently large set of task instances to train an assessor specific to it.\nIn this work, we leverage the evaluation results of previously tested LLMs to\nreduce the number of evaluations required to predict the performance of a new\nLLM. In practice, we propose to test the new LLM on a small set of reference\ninstances and train a generic assessor which predicts the performance of the\nLLM on an instance based on the performance of the former on the reference set\nand features of the instance of interest. We conduct empirical studies on\nHELM-Lite and KindsOfReasoning, a collection of existing reasoning datasets\nthat we introduce, where we evaluate all instruction-fine-tuned OpenAI models\nuntil the January 2024 version of GPT4. When predicting performance on\ninstances with the same distribution as those used to train the generic\nassessor, we find this achieves performance comparable to the LLM-specific\nassessors trained on the full set of instances. Additionally, we find that\nrandomly selecting the reference instances performs as well as some advanced\nselection methods we tested. For out of distribution, however, no clear winner\nemerges and the overall performance is worse, suggesting that the inherent\npredictability of LLMs is low.", "published": "2024-09-05 14:19:45", "link": "http://arxiv.org/abs/2409.03563v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LAST: Language Model Aware Speech Tokenization", "abstract": "Speech tokenization serves as the foundation of speech language model (LM),\nenabling them to perform various tasks such as spoken language modeling,\ntext-to-speech, speech-to-text, etc. Most speech tokenizers are trained\nindependently of the LM training process, relying on separate acoustic models\nand quantization methods. Following such an approach may create a mismatch\nbetween the tokenization process and its usage afterward. In this study, we\npropose a novel approach to training a speech tokenizer by leveraging\nobjectives from pre-trained textual LMs. We advocate for the integration of\nthis objective into the process of learning discrete speech representations.\nOur aim is to transform features from a pre-trained speech model into a new\nfeature space that enables better clustering for speech LMs. We empirically\ninvestigate the impact of various model design choices, including speech\nvocabulary size and text LM size. Our results demonstrate the proposed\ntokenization method outperforms the evaluated baselines considering both spoken\nlanguage modeling and speech-to-text. More importantly, unlike prior work, the\nproposed method allows the utilization of a single pre-trained LM for\nprocessing both speech and text inputs, setting it apart from conventional\ntokenization approaches.", "published": "2024-09-05 16:57:39", "link": "http://arxiv.org/abs/2409.03701v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Planning In Natural Language Improves LLM Search For Code Generation", "abstract": "While scaling training compute has led to remarkable improvements in large\nlanguage models (LLMs), scaling inference compute has not yet yielded analogous\ngains. We hypothesize that a core missing component is a lack of diverse LLM\noutputs, leading to inefficient search due to models repeatedly sampling highly\nsimilar, yet incorrect generations. We empirically demonstrate that this lack\nof diversity can be mitigated by searching over candidate plans for solving a\nproblem in natural language. Based on this insight, we propose PlanSearch, a\nnovel search algorithm which shows strong results across HumanEval+, MBPP+, and\nLiveCodeBench (a contamination-free benchmark for competitive coding).\nPlanSearch generates a diverse set of observations about the problem and then\nuses these observations to construct plans for solving the problem. By\nsearching over plans in natural language rather than directly over code\nsolutions, PlanSearch explores a significantly more diverse range of potential\nsolutions compared to baseline search methods. Using PlanSearch on top of\nClaude 3.5 Sonnet achieves a state-of-the-art pass@200 of 77.0% on\nLiveCodeBench, outperforming both the best score achieved without search\n(pass@1 = 41.4%) and using standard repeated sampling (pass@200 = 60.6%).\nFinally, we show that, across all models, search algorithms, and benchmarks\nanalyzed, we can accurately predict performance gains due to search as a direct\nfunction of the diversity over generated ideas. Code can be found at\nhttps://github.com/scaleapi/plansearch.", "published": "2024-09-05 17:44:49", "link": "http://arxiv.org/abs/2409.03733v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "How Do Your Code LLMs Perform? Empowering Code Instruction Tuning with\n  High-Quality Data", "abstract": "Recently, there has been a growing interest in studying how to construct\nbetter code instruction tuning data. However, we observe Code models trained\nwith these datasets exhibit high performance on HumanEval but perform worse on\nother benchmarks such as LiveCodeBench. Upon further investigation, we find\nthat many datasets suffer from severe data leakage. After cleaning up most of\nthe leaked data, some well-known high-quality datasets perform poorly. This\ndiscovery reveals a new challenge: identifying which dataset genuinely qualify\nas high-quality code instruction data. To address this, we propose an efficient\ncode data pruning strategy for selecting good samples. Our approach is based on\nthree dimensions: instruction complexity, response quality, and instruction\ndiversity. Based on our selected data, we present XCoder, a family of models\nfinetuned from LLaMA3. Our experiments show XCoder achieves new\nstate-of-the-art performance using fewer training data, which verify the\neffectiveness of our data strategy. Moreover, we perform a comprehensive\nanalysis on the data composition and find existing code datasets have different\ncharacteristics according to their construction methods, which provide new\ninsights for future code LLMs. Our models and dataset are released in\nhttps://github.com/banksy23/XCoder", "published": "2024-09-05 17:46:30", "link": "http://arxiv.org/abs/2409.03810v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Lightweight Transducer Based on Frame-Level Criterion", "abstract": "The transducer model trained based on sequence-level criterion requires a lot\nof memory due to the generation of the large probability matrix. We proposed a\nlightweight transducer model based on frame-level criterion, which uses the\nresults of the CTC forced alignment algorithm to determine the label for each\nframe. Then the encoder output can be combined with the decoder output at the\ncorresponding time, rather than adding each element output by the encoder to\neach element output by the decoder as in the transducer. This significantly\nreduces memory and computation requirements. To address the problem of\nimbalanced classification caused by excessive blanks in the label, we decouple\nthe blank and non-blank probabilities and truncate the gradient of the blank\nclassifier to the main network. Experiments on the AISHELL-1 demonstrate that\nthis enables the lightweight transducer to achieve similar results to\ntransducer. Additionally, we use richer information to predict the probability\nof blank, achieving superior results to transducer.", "published": "2024-09-05 02:24:18", "link": "http://arxiv.org/abs/2409.13698v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Debiasing Text Safety Classifiers through a Fairness-Aware Ensemble", "abstract": "Increasing use of large language models (LLMs) demand performant guardrails\nto ensure the safety of inputs and outputs of LLMs. When these safeguards are\ntrained on imbalanced data, they can learn the societal biases. We present a\nlight-weight, post-processing method for mitigating counterfactual fairness in\nclosed-source text safety classifiers. Our approach involves building an\nensemble that not only outperforms the input classifiers and policy-aligns\nthem, but also acts as a debiasing regularizer. We introduce two\nthreshold-agnostic metrics to assess the counterfactual fairness of a model,\nand demonstrate how combining these metrics with Fair Data Reweighting (FDW)\nhelps mitigate biases. We create an expanded Open AI dataset, and a new\ntemplated LLM-generated dataset based on user-prompts, both of which are\ncounterfactually balanced across identity groups and cover four key areas of\nsafety; we will work towards publicly releasing these datasets. Our results\nshow that our approach improves counterfactual fairness with minimal impact on\nmodel performance.", "published": "2024-09-05 14:35:35", "link": "http://arxiv.org/abs/2409.13705v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "WildVis: Open Source Visualizer for Million-Scale Chat Logs in the Wild", "abstract": "The increasing availability of real-world conversation data offers exciting\nopportunities for researchers to study user-chatbot interactions. However, the\nsheer volume of this data makes manually examining individual conversations\nimpractical. To overcome this challenge, we introduce WildVis, an interactive\ntool that enables fast, versatile, and large-scale conversation analysis.\nWildVis provides search and visualization capabilities in the text and\nembedding spaces based on a list of criteria. To manage million-scale datasets,\nwe implemented optimizations including search index construction, embedding\nprecomputation and compression, and caching to ensure responsive user\ninteractions within seconds. We demonstrate WildVis' utility through three case\nstudies: facilitating chatbot misuse research, visualizing and comparing topic\ndistributions across datasets, and characterizing user-specific conversation\npatterns. WildVis is open-source and designed to be extendable, supporting\nadditional datasets and customized search and visualization functionalities.", "published": "2024-09-05 17:59:15", "link": "http://arxiv.org/abs/2409.03753v2", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene\n  Understanding", "abstract": "Complex 3D scene understanding has gained increasing attention, with scene\nencoding strategies playing a crucial role in this success. However, the\noptimal scene encoding strategies for various scenarios remain unclear,\nparticularly compared to their image-based counterparts. To address this issue,\nwe present a comprehensive study that probes various visual encoding models for\n3D scene understanding, identifying the strengths and limitations of each model\nacross different scenarios. Our evaluation spans seven vision foundation\nencoders, including image-based, video-based, and 3D foundation models. We\nevaluate these models in four tasks: Vision-Language Scene Reasoning, Visual\nGrounding, Segmentation, and Registration, each focusing on different aspects\nof scene understanding. Our evaluations yield key findings: DINOv2 demonstrates\nsuperior performance, video models excel in object-level tasks, diffusion\nmodels benefit geometric tasks, and language-pretrained models show unexpected\nlimitations in language-related tasks. These insights challenge some\nconventional understandings, provide novel perspectives on leveraging visual\nfoundation models, and highlight the need for more flexible encoder selection\nin future vision-language and scene-understanding tasks. Code:\nhttps://github.com/YunzeMan/Lexicon3D", "published": "2024-09-05 17:59:56", "link": "http://arxiv.org/abs/2409.03757v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "A spherical harmonic-domain spatial audio signal enhancement method\n  based on minimum variance distortionless response", "abstract": "Spatial audio signal enhancement aims to reduce interfering source\ncontributions while preserving the desired sound field with its spatial cues\nintact. Existing methods generally rely on impractical assumptions (e.g. no\nreverberation or accurate estimations of impractical information) or have\nlimited applicability. This paper presents a spherical harmonic (SH)-domain\nminimum variance distortionless response (MVDR)-based spatial signal enhancer\nusing Relative Harmonic Coefficients (ReHCs) to extract clean SH coefficients\nfrom noisy ones in reverberant environments. A simulation study shows the\nproposed method achieves lower estimation error, higher speech-distortion-ratio\n(SDR), and comparable noise reduction (NR) within the sweet area in a\nreverberant environment, compared to a beamforming-and-projection method as the\nbaseline.", "published": "2024-09-05 06:27:09", "link": "http://arxiv.org/abs/2409.03269v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "A Dual-Path Framework with Frequency-and-Time Excited Network for\n  Anomalous Sound Detection", "abstract": "In contrast to human speech, machine-generated sounds of the same type often\nexhibit consistent frequency characteristics and discernible temporal\nperiodicity. However, leveraging these dual attributes in anomaly detection\nremains relatively under-explored. In this paper, we propose an automated\ndual-path framework that learns prominent frequency and temporal patterns for\ndiverse machine types. One pathway uses a novel Frequency-and-Time Excited\nNetwork (FTE-Net) to learn the salient features across frequency and time axes\nof the spectrogram. It incorporates a Frequency-and-Time Chunkwise Encoder\n(FTC-Encoder) and an excitation network. The other pathway uses a 1D\nconvolutional network for utterance-level spectrum. Experimental results on the\nDCASE 2023 task 2 dataset show the state-of-the-art performance of our proposed\nmethod. Moreover, visualizations of the intermediate feature maps in the\nexcitation network are provided to illustrate the effectiveness of our method.", "published": "2024-09-05 15:15:47", "link": "http://arxiv.org/abs/2409.03610v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Toward Any-to-Any Emotion Voice Conversion using Disentangled Diffusion\n  Framework", "abstract": "Emotional Voice Conversion (EVC) aims to modify the emotional expression of\nspeech for various applications, such as human-machine interaction. Previous\ndeep learning-based approaches using generative adversarial networks and\nautoencoder models have shown promise but suffer from quality degradation and\nlimited emotion control. To address these issues, a novel diffusion-based EVC\nframework with disentangled loss and expressive guidance is proposed. Our\nmethod separates speaker and emotional features to maintain speech quality\nwhile improving emotional expressiveness. Tested on real-world and acted-out\ndatasets, the approach achieved significant improvements in emotion\nclassification accuracy for both in-the-wild and act-out datasets and showed\nreduced distortion compared to state-of-the-art models.", "published": "2024-09-05 15:50:50", "link": "http://arxiv.org/abs/2409.03636v3", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "FireRedTTS: A Foundation Text-To-Speech Framework for Industry-Level\n  Generative Speech Applications", "abstract": "This work proposes FireRedTTS, a foundation text-to-speech framework, to meet\nthe growing demands for personalized and diverse generative speech\napplications. The framework comprises three parts: data processing, foundation\nsystem, and downstream applications. First, we comprehensively present our data\nprocessing pipeline, which transforms massive raw audio into a large-scale\nhigh-quality TTS dataset with rich annotations and a wide coverage of content,\nspeaking style, and timbre. Then, we propose a language-model-based foundation\nTTS system. The speech signal is compressed into discrete semantic tokens via a\nsemantic-aware speech tokenizer, and can be generated by a language model from\nthe prompt text and audio. Then, a two-stage waveform generator is proposed to\ndecode them to the high-fidelity waveform. We present two applications of this\nsystem: voice cloning for dubbing and human-like speech generation for\nchatbots. The experimental results demonstrate the solid in-context learning\ncapability of FireRedTTS, which can stably synthesize high-quality speech\nconsistent with the prompt text and audio. For dubbing, FireRedTTS can clone\ntarget voices in a zero-shot way for the UGC scenario and adapt to studio-level\nexpressive voice characters in the PUGC scenario via few-shot fine-tuning with\n1-hour recording. Moreover, FireRedTTS achieves controllable human-like speech\ngeneration in a casual style with paralinguistic behaviors and emotions via\ninstruction tuning, to better serve spoken chatbots.", "published": "2024-09-05 06:48:02", "link": "http://arxiv.org/abs/2409.03283v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Speaker and Style Disentanglement of Speech Based on Contrastive\n  Predictive Coding Supported Factorized Variational Autoencoder", "abstract": "Speech signals encompass various information across multiple levels including\ncontent, speaker, and style. Disentanglement of these information, although\nchallenging, is important for applications such as voice conversion. The\ncontrastive predictive coding supported factorized variational autoencoder\nachieves unsupervised disentanglement of a speech signal into speaker and\ncontent embeddings by assuming speaker info to be temporally more stable than\ncontent-induced variations. However, this assumption may introduce other\ntemporal stable information into the speaker embeddings, like environment or\nemotion, which we call style. In this work, we propose a method to further\ndisentangle non-content features into distinct speaker and style features,\nnotably by leveraging readily accessible and well-defined speaker labels\nwithout the necessity for style labels. Experimental results validate the\nproposed method's effectiveness on extracting disentangled features, thereby\nfacilitating speaker, style, or combined speaker-style conversion.", "published": "2024-09-05 13:33:04", "link": "http://arxiv.org/abs/2409.03520v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Privacy versus Emotion Preservation Trade-offs in Emotion-Preserving\n  Speaker Anonymization", "abstract": "Advances in speech technology now allow unprecedented access to personally\nidentifiable information through speech. To protect such information, the\ndifferential privacy field has explored ways to anonymize speech while\npreserving its utility, including linguistic and paralinguistic aspects.\nHowever, anonymizing speech while maintaining emotional state remains\nchallenging. We explore this problem in the context of the VoicePrivacy 2024\nchallenge. Specifically, we developed various speaker anonymization pipelines\nand find that approaches either excel at anonymization or preserving emotion\nstate, but not both simultaneously. Achieving both would require an in-domain\nemotion recognizer. Additionally, we found that it is feasible to train a\nsemi-effective speaker verification system using only emotion representations,\ndemonstrating the challenge of separating these two modalities.", "published": "2024-09-05 16:10:31", "link": "http://arxiv.org/abs/2409.03655v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Estimating Indoor Scene Depth Maps from Ultrasonic Echoes", "abstract": "Measuring 3D geometric structures of indoor scenes requires dedicated depth\nsensors, which are not always available. Echo-based depth estimation has\nrecently been studied as a promising alternative solution. All previous studies\nhave assumed the use of echoes in the audible range. However, one major problem\nis that audible echoes cannot be used in quiet spaces or other situations where\nproducing audible sounds is prohibited. In this paper, we consider echo-based\ndepth estimation using inaudible ultrasonic echoes. While ultrasonic waves\nprovide high measurement accuracy in theory, the actual depth estimation\naccuracy when ultrasonic echoes are used has remained unclear, due to its\ndisadvantage of being sensitive to noise and susceptible to attenuation. We\nfirst investigate the depth estimation accuracy when the frequency of the sound\nsource is restricted to the high-frequency band, and found that the accuracy\ndecreased when the frequency was limited to ultrasonic ranges. Based on this\nobservation, we propose a novel deep learning method to improve the accuracy of\nultrasonic echo-based depth estimation by using audible echoes as auxiliary\ndata only during training. Experimental results with a public dataset\ndemonstrate that our method improves the estimation accuracy.", "published": "2024-09-05 08:28:36", "link": "http://arxiv.org/abs/2409.03336v2", "categories": ["cs.SD", "cs.CV", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Real-time Speech Enhancement on Raw Signals with Deep State-space\n  Modeling", "abstract": "We present aTENNuate, a simple deep state-space autoencoder configured for\nefficient online raw speech enhancement in an end-to-end fashion. The network's\nperformance is primarily evaluated on raw speech denoising, with additional\nassessments on tasks such as super-resolution and de-quantization. We benchmark\naTENNuate on the VoiceBank + DEMAND and the Microsoft DNS1 synthetic test sets.\nThe network outperforms previous real-time denoising models in terms of PESQ\nscore, parameter count, MACs, and latency. Even as a raw waveform processing\nmodel, the model maintains high fidelity to the clean signal with minimal\naudible artifacts. In addition, the model remains performant even when the\nnoisy input is compressed down to 4000Hz and 4 bits, suggesting general speech\nenhancement capabilities in low-resource environments. Code is available at\ngithub.com/Brainchip-Inc/aTENNuate", "published": "2024-09-05 09:28:56", "link": "http://arxiv.org/abs/2409.03377v3", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multimodal Laryngoscopic Video Analysis for Assisted Diagnosis of Vocal\n  Fold Paralysis", "abstract": "This paper presents the Multimodal Laryngoscopic Video Analyzing System\n(MLVAS), a novel system that leverages both audio and video data to\nautomatically extract key segments and metrics from raw laryngeal\nvideostroboscopic videos for assisted clinical assessment. The system\nintegrates video-based glottis detection with an audio keyword spotting method\nto analyze both video and audio data, identifying patient vocalizations and\nrefining video highlights to ensure optimal inspection of vocal fold movements.\nAdditionally, MLVAS features an advanced strobing video extraction module that\nspecifically identifies strobing frames from laryngeal videostroboscopy by\nanalyzing hue, saturation, and value fluctuations. Beyond key segment\nextraction, MLVAS provides effective metrics for Vocal Fold Paralysis (VFP)\ndetection. It employs a novel two-stage glottis segmentation process using a\nU-Net for initial segmentation, followed by a diffusion-based refinement to\nreduce false positives, providing better segmentation masks for downstream\ntasks. MLVAS estimates the vibration dynamics for both left and right vocal\nfolds from the segmented glottis masks to detect unilateral VFP by measuring\nthe angle deviation with the estimated glottal midline. Comparing the variance\nbetween left's and right's dynamics, the system effectively distinguishes\nbetween left and right VFP. We conducted several ablation studies to\ndemonstrate the effectiveness of each module in the proposed MLVAS. The\nexperimental results on a public segmentation dataset show the effectiveness of\nour proposed segmentation module. In addition, VFP classification results on a\nreal-world clinic dataset demonstrate MLVAS's ability of providing reliable and\nobjective metrics as well as visualization for assisted clinical diagnosis.", "published": "2024-09-05 14:56:38", "link": "http://arxiv.org/abs/2409.03597v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "MetaBGM: Dynamic Soundtrack Transformation For Continuous Multi-Scene\n  Experiences With Ambient Awareness And Personalization", "abstract": "This paper introduces MetaBGM, a groundbreaking framework for generating\nbackground music that adapts to dynamic scenes and real-time user interactions.\nWe define multi-scene as variations in environmental contexts, such as\ntransitions in game settings or movie scenes. To tackle the challenge of\nconverting backend data into music description texts for audio generation\nmodels, MetaBGM employs a novel two-stage generation approach that transforms\ncontinuous scene and user state data into these texts, which are then fed into\nan audio generation model for real-time soundtrack creation. Experimental\nresults demonstrate that MetaBGM effectively generates contextually relevant\nand dynamic background music for interactive applications.", "published": "2024-09-05 18:12:11", "link": "http://arxiv.org/abs/2409.03844v1", "categories": ["cs.SD", "cs.AI", "cs.HC", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
