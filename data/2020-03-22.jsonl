{"title": "Prior Knowledge Driven Label Embedding for Slot Filling in Natural\n  Language Understanding", "abstract": "Traditional slot filling in natural language understanding (NLU) predicts a\none-hot vector for each word. This form of label representation lacks semantic\ncorrelation modelling, which leads to severe data sparsity problem, especially\nwhen adapting an NLU model to a new domain. To address this issue, a novel\nlabel embedding based slot filling framework is proposed in this paper. Here,\ndistributed label embedding is constructed for each slot using prior knowledge.\nThree encoding methods are investigated to incorporate different kinds of prior\nknowledge about slots: atomic concepts, slot descriptions, and slot exemplars.\nThe proposed label embeddings tend to share text patterns and reuses data with\ndifferent slot labels. This makes it useful for adaptive NLU with limited data.\nAlso, since label embedding is independent of NLU model, it is compatible with\nalmost all deep learning based slot filling models. The proposed approaches are\nevaluated on three datasets. Experiments on single domain and domain adaptation\ntasks show that label embedding achieves significant performance improvement\nover traditional one-hot label representation as well as advanced zero-shot\napproaches.", "published": "2020-03-22 07:27:07", "link": "http://arxiv.org/abs/2003.09831v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SAC: Accelerating and Structuring Self-Attention via Sparse Adaptive\n  Connection", "abstract": "While the self-attention mechanism has been widely used in a wide variety of\ntasks, it has the unfortunate property of a quadratic cost with respect to the\ninput length, which makes it difficult to deal with long inputs. In this paper,\nwe present a method for accelerating and structuring self-attentions: Sparse\nAdaptive Connection (SAC). In SAC, we regard the input sequence as a graph and\nattention operations are performed between linked nodes. In contrast with\nprevious self-attention models with pre-defined structures (edges), the model\nlearns to construct attention edges to improve task-specific performances. In\nthis way, the model is able to select the most salient nodes and reduce the\nquadratic complexity regardless of the sequence length. Based on SAC, we show\nthat previous variants of self-attention models are its special cases. Through\nextensive experiments on neural machine translation, language modeling, graph\nrepresentation learning and image classification, we demonstrate SAC is\ncompetitive with state-of-the-art models while significantly reducing memory\ncost.", "published": "2020-03-22 07:58:44", "link": "http://arxiv.org/abs/2003.09833v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Visual Question Answering for Cultural Heritage", "abstract": "Technology and the fruition of cultural heritage are becoming increasingly\nmore entwined, especially with the advent of smart audio guides, virtual and\naugmented reality, and interactive installations. Machine learning and computer\nvision are important components of this ongoing integration, enabling new\ninteraction modalities between user and museum. Nonetheless, the most frequent\nway of interacting with paintings and statues still remains taking pictures.\nYet images alone can only convey the aesthetics of the artwork, lacking is\ninformation which is often required to fully understand and appreciate it.\nUsually this additional knowledge comes both from the artwork itself (and\ntherefore the image depicting it) and from an external source of knowledge,\nsuch as an information sheet. While the former can be inferred by computer\nvision algorithms, the latter needs more structured data to pair visual content\nwith relevant information. Regardless of its source, this information still\nmust be be effectively transmitted to the user. A popular emerging trend in\ncomputer vision is Visual Question Answering (VQA), in which users can interact\nwith a neural network by posing questions in natural language and receiving\nanswers about the visual content. We believe that this will be the evolution of\nsmart audio guides for museum visits and simple image browsing on personal\nsmartphones. This will turn the classic audio guide into a smart personal\ninstructor with which the visitor can interact by asking for explanations\nfocused on specific interests. The advantages are twofold: on the one hand the\ncognitive burden of the visitor will decrease, limiting the flow of information\nto what the user actually wants to hear; and on the other hand it proposes the\nmost natural way of interacting with a guide, favoring engagement.", "published": "2020-03-22 10:26:08", "link": "http://arxiv.org/abs/2003.09853v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "A Better Variant of Self-Critical Sequence Training", "abstract": "In this work, we present a simple yet better variant of Self-Critical\nSequence Training. We make a simple change in the choice of baseline function\nin REINFORCE algorithm. The new baseline can bring better performance with no\nextra cost, compared to the greedy decoding baseline.", "published": "2020-03-22 19:04:25", "link": "http://arxiv.org/abs/2003.09971v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Toward Tag-free Aspect Based Sentiment Analysis: A Multiple Attention\n  Network Approach", "abstract": "Existing aspect based sentiment analysis (ABSA) approaches leverage various\nneural network models to extract the aspect sentiments via learning\naspect-specific feature representations. However, these approaches heavily rely\non manual tagging of user reviews according to the predefined aspects as the\ninput, a laborious and time-consuming process. Moreover, the underlying methods\ndo not explain how and why the opposing aspect level polarities in a user\nreview lead to the overall polarity. In this paper, we tackle these two\nproblems by designing and implementing a new Multiple-Attention Network (MAN)\napproach for more powerful ABSA without the need for aspect tags using two new\ntag-free data sets crawled directly from TripAdvisor\n({https://www.tripadvisor.com}). With the Self- and Position-Aware attention\nmechanism, MAN is capable of extracting both aspect level and overall\nsentiments from the text reviews using the aspect level and overall customer\nratings, and it can also detect the vital aspect(s) leading to the overall\nsentiment polarity among different aspects via a new aspect ranking scheme. We\ncarry out extensive experiments to demonstrate the strong performance of MAN\ncompared to other state-of-the-art ABSA approaches and the explainability of\nour approach by visualizing and interpreting attention weights in case studies.", "published": "2020-03-22 20:18:20", "link": "http://arxiv.org/abs/2003.09986v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Invariant Rationalization", "abstract": "Selective rationalization improves neural network interpretability by\nidentifying a small subset of input features -- the rationale -- that best\nexplains or supports the prediction. A typical rationalization criterion, i.e.\nmaximum mutual information (MMI), finds the rationale that maximizes the\nprediction performance based only on the rationale. However, MMI can be\nproblematic because it picks up spurious correlations between the input\nfeatures and the output. Instead, we introduce a game-theoretic invariant\nrationalization criterion where the rationales are constrained to enable the\nsame predictor to be optimal across different environments. We show both\ntheoretically and empirically that the proposed rationales can rule out\nspurious correlations, generalize better to different test scenarios, and align\nbetter with human judgments. Our data and code are available.", "published": "2020-03-22 00:50:27", "link": "http://arxiv.org/abs/2003.09772v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Pairwise Multi-Class Document Classification for Semantic Relations\n  between Wikipedia Articles", "abstract": "Many digital libraries recommend literature to their users considering the\nsimilarity between a query document and their repository. However, they often\nfail to distinguish what is the relationship that makes two documents alike. In\nthis paper, we model the problem of finding the relationship between two\ndocuments as a pairwise document classification task. To find the semantic\nrelation between documents, we apply a series of techniques, such as GloVe,\nParagraph-Vectors, BERT, and XLNet under different configurations (e.g.,\nsequence length, vector concatenation scheme), including a Siamese architecture\nfor the Transformer-based systems. We perform our experiments on a newly\nproposed dataset of 32,168 Wikipedia article pairs and Wikidata properties that\ndefine the semantic document relations. Our results show vanilla BERT as the\nbest performing system with an F1-score of 0.93, which we manually examine to\nbetter understand its applicability to other domains. Our findings suggest that\nclassifying semantic relations between documents is a solvable task and\nmotivates the development of recommender systems based on the evaluated\ntechniques. The discussions in this paper serve as first steps in the\nexploration of documents through SPARQL-like queries such that one could find\ndocuments that are similar in one aspect but dissimilar in another.", "published": "2020-03-22 12:52:56", "link": "http://arxiv.org/abs/2003.09881v1", "categories": ["cs.DL", "cs.CL", "cs.IR"], "primary_category": "cs.DL"}
{"title": "Low Latency ASR for Simultaneous Speech Translation", "abstract": "User studies have shown that reducing the latency of our simultaneous lecture\ntranslation system should be the most important goal. We therefore have worked\non several techniques for reducing the latency for both components, the\nautomatic speech recognition and the speech translation module. Since the\ncommonly used commitment latency is not appropriate in our case of continuous\nstream decoding, we focused on word latency. We used it to analyze the\nperformance of our current system and to identify opportunities for\nimprovements. In order to minimize the latency we combined run-on decoding with\na technique for identifying stable partial hypotheses when stream decoding and\na protocol for dynamic output update that allows to revise the most recent\nparts of the transcription. This combination reduces the latency at word level,\nwhere the words are final and will never be updated again in the future, from\n18.1s to 1.1s without sacrificing performance in terms of word error rate.", "published": "2020-03-22 13:37:05", "link": "http://arxiv.org/abs/2003.09891v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "365 Dots in 2019: Quantifying Attention of News Sources", "abstract": "We investigate the overlap of topics of online news articles from a variety\nof sources. To do this, we provide a platform for studying the news by\nmeasuring this overlap and scoring news stories according to the degree of\nattention in near-real time. This can enable multiple studies, including\nidentifying topics that receive the most attention from news organizations and\nidentifying slow news days versus major news days. Our application, StoryGraph,\nperiodically (10-minute intervals) extracts the first five news articles from\nthe RSS feeds of 17 US news media organizations across the partisanship\nspectrum (left, center, and right). From these articles, StoryGraph extracts\nnamed entities (PEOPLE, LOCATIONS, ORGANIZATIONS, etc.) and then represents\neach news article with its set of extracted named entities. Finally, StoryGraph\ngenerates a news similarity graph where the nodes represent news articles, and\nan edge between a pair of nodes represents a high degree of similarity between\nthe nodes (similar news stories). Each news story within the news similarity\ngraph is assigned an attention score which quantifies the amount of attention\nthe topics in the news story receive collectively from the news media\norganizations. The StoryGraph service has been running since August 2017, and\nusing this method, we determined that the top news story of 2018 was the\n\"Kavanaugh hearings\" with attention score of 25.85 on September 27, 2018.\nSimilarly, the top news story for 2019 so far (2019-12-12) is \"AG William\nBarr's release of his principal conclusions of the Mueller Report,\" with an\nattention score of 22.93 on March 24, 2019.", "published": "2020-03-22 20:32:47", "link": "http://arxiv.org/abs/2003.09989v1", "categories": ["cs.IR", "cs.CL", "cs.SI"], "primary_category": "cs.IR"}
{"title": "High Performance Sequence-to-Sequence Model for Streaming Speech\n  Recognition", "abstract": "Recently sequence-to-sequence models have started to achieve state-of-the-art\nperformance on standard speech recognition tasks when processing audio data in\nbatch mode, i.e., the complete audio data is available when starting\nprocessing. However, when it comes to performing run-on recognition on an input\nstream of audio data while producing recognition results in real-time and with\nlow word-based latency, these models face several challenges. For many\ntechniques, the whole audio sequence to be decoded needs to be available at the\nstart of the processing, e.g., for the attention mechanism or the bidirectional\nLSTM (BLSTM). In this paper, we propose several techniques to mitigate these\nproblems. We introduce an additional loss function controlling the uncertainty\nof the attention mechanism, a modified beam search identifying partial, stable\nhypotheses, ways of working with BLSTM in the encoder, and the use of chunked\nBLSTM. Our experiments show that with the right combination of these\ntechniques, it is possible to perform run-on speech recognition with low\nword-based latency without sacrificing in word error rate performance.", "published": "2020-03-22 23:04:32", "link": "http://arxiv.org/abs/2003.10022v2", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Multi-Label Text Classification using Attention-based Graph Neural\n  Network", "abstract": "In Multi-Label Text Classification (MLTC), one sample can belong to more than\none class. It is observed that most MLTC tasks, there are dependencies or\ncorrelations among labels. Existing methods tend to ignore the relationship\namong labels. In this paper, a graph attention network-based model is proposed\nto capture the attentive dependency structure among the labels. The graph\nattention network uses a feature matrix and a correlation matrix to capture and\nexplore the crucial dependencies between the labels and generate classifiers\nfor the task. The generated classifiers are applied to sentence feature vectors\nobtained from the text feature extraction network (BiLSTM) to enable end-to-end\ntraining. Attention allows the system to assign different weights to neighbor\nnodes per label, thus allowing it to learn the dependencies among labels\nimplicitly. The results of the proposed model are validated on five real-world\nMLTC datasets. The proposed model achieves similar or better performance\ncompared to the previous state-of-the-art models.", "published": "2020-03-22 17:12:43", "link": "http://arxiv.org/abs/2003.11644v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Using News Articles and Financial Data to predict the likelihood of\n  bankruptcy", "abstract": "Over the past decade, millions of companies have filed for bankruptcy. This\nhas been caused by a plethora of reasons, namely, high interest rates, heavy\ndebts and government regulations. The effect of a company going bankrupt can be\ndevastating, hurting not only workers and shareholders, but also clients,\nsuppliers and any related external companies. One of the aims of this paper is\nto provide a framework for company bankruptcy to be predicted by making use of\nfinancial figures, provided by our external dataset, in conjunction with the\nsentiment of news articles about certain sectors. News articles are used to\nattempt to quantify the sentiment on a company and its sector from an external\nperspective, rather than simply using internal figures. This work builds on\nprevious studies carried out by multiple researchers, to bring us closer to\nlessening the impact of such events.", "published": "2020-03-22 17:29:41", "link": "http://arxiv.org/abs/2003.13414v1", "categories": ["q-fin.GN", "cs.CL", "cs.SI"], "primary_category": "q-fin.GN"}
{"title": "Semantic-based End-to-End Learning for Typhoon Intensity Prediction", "abstract": "Disaster prediction is one of the most critical tasks towards disaster\nsurveillance and preparedness. Existing technologies employ different machine\nlearning approaches to predict incoming disasters from historical environmental\ndata. However, for short-term disasters (e.g., earthquakes), historical data\nalone has a limited prediction capability. Therefore, additional sources of\nwarnings are required for accurate prediction. We consider social media as a\nsupplementary source of knowledge in addition to historical environmental data.\nHowever, social media posts (e.g., tweets) is very informal and contains only\nlimited content. To alleviate these limitations, we propose the combination of\nsemantically-enriched word embedding models to represent entities in tweets\nwith their semantic representations computed with the traditionalword2vec.\nMoreover, we study how the correlation between social media posts and typhoons\nmagnitudes (also called intensities)-in terms of volume and sentiments of\ntweets-. Based on these insights, we propose an end-to-end based framework that\nlearns from disaster-related tweets and environmental data to improve typhoon\nintensity prediction. This paper is an extension of our work originally\npublished in K-CAP 2019 [32]. We extended this paper by building our framework\nwith state-of-the-art deep neural models, up-dated our dataset with new\ntyphoons and their tweets to-date and benchmark our approach against recent\nbaselines in disaster prediction. Our experimental results show that our\napproach outperforms the accuracy of the state-of-the-art baselines in terms of\nF1-score with (CNN by12.1%and BiLSTM by3.1%) improvement compared with last\nexperiments", "published": "2020-03-22 01:13:20", "link": "http://arxiv.org/abs/2003.13779v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "A Time-domain Monaural Speech Enhancement with Feedback Learning", "abstract": "In this paper, we propose a type of neural network with feedback learning in\nthe time domain called FTNet for monaural speech enhancement, where the\nproposed network consists of three principal components. The first part is\ncalled stage recurrent neural network, which is introduced to effectively\naggregate the deep feature dependencies across different stages with a memory\nmechanism and also remove the interference stage by stage. The second part is\nthe convolutional auto-encoder. The third part consists of a series of\nconcatenated gated linear units, which are capable of facilitating the\ninformation flow and gradually increasing the receptive fields. Feedback\nlearning is adopted to improve the parameter efficiency and therefore, the\nnumber of trainable parameters is effectively reduced without sacrificing its\nperformance. Numerous experiments are conducted on TIMIT corpus and\nexperimental results demonstrate that the proposed network can achieve\nconsistently better performance in terms of both PESQ and STOI scores than two\nstate-of-the-art time domain-based baselines in different conditions.", "published": "2020-03-22 05:36:08", "link": "http://arxiv.org/abs/2003.09815v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Audio Impairment Recognition Using a Correlation-Based Feature\n  Representation", "abstract": "Audio impairment recognition is based on finding noise in audio files and\ncategorising the impairment type. Recently, significant performance improvement\nhas been obtained thanks to the usage of advanced deep learning models.\nHowever, feature robustness is still an unresolved issue and it is one of the\nmain reasons why we need powerful deep learning architectures. In the presence\nof a variety of musical styles, hand-crafted features are less efficient in\ncapturing audio degradation characteristics and they are prone to failure when\nrecognising audio impairments and could mistakenly learn musical concepts\nrather than impairment types. In this paper, we propose a new representation of\nhand-crafted features that is based on the correlation of feature pairs. We\nexperimentally compare the proposed correlation-based feature representation\nwith a typical raw feature representation used in machine learning and we show\nsuperior performance in terms of compact feature dimensionality and improved\ncomputational speed in the test stage whilst achieving comparable accuracy.", "published": "2020-03-22 13:34:37", "link": "http://arxiv.org/abs/2003.09889v2", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Training for Speech Recognition on Coprocessors", "abstract": "Automatic Speech Recognition (ASR) has increased in popularity in recent\nyears. The evolution of processor and storage technologies has enabled more\nadvanced ASR mechanisms, fueling the development of virtual assistants such as\nAmazon Alexa, Apple Siri, Microsoft Cortana, and Google Home. The interest in\nsuch assistants, in turn, has amplified the novel developments in ASR research.\nHowever, despite this popularity, there has not been a detailed training\nefficiency analysis of modern ASR systems. This mainly stems from: the\nproprietary nature of many modern applications that depend on ASR, like the\nones listed above; the relatively expensive co-processor hardware that is used\nto accelerate ASR by big vendors to enable such applications; and the absence\nof well-established benchmarks. The goal of this paper is to address the latter\ntwo of these challenges. The paper first describes an ASR model, based on a\ndeep neural network inspired by recent work in this domain, and our experiences\nbuilding it. Then we evaluate this model on three CPU-GPU co-processor\nplatforms that represent different budget categories. Our results demonstrate\nthat utilizing hardware acceleration yields good results even without high-end\nequipment. While the most expensive platform (10X price of the least expensive\none) converges to the initial accuracy target 10-30% and 60-70% faster than the\nother two, the differences among the platforms almost disappear at slightly\nhigher accuracy targets. In addition, our results further highlight both the\ndifficulty of evaluating ASR systems due to the complex, long, and resource\nintensive nature of the model training in this domain, and the importance of\nestablishing benchmarks for ASR.", "published": "2020-03-22 11:21:29", "link": "http://arxiv.org/abs/2003.12366v2", "categories": ["eess.AS", "cs.LG", "cs.SD", "stat.ML", "I.2; C.1; H.2"], "primary_category": "eess.AS"}
