{"title": "Rough differential equations for volatility", "abstract": "We introduce a canonical way of performing the joint lift of a Brownian\nmotion $W$ and a low-regularity adapted stochastic rough path $\\mathbf{X}$,\nextending [Diehl, Oberhauser and Riedel (2015). A L\\'evy area between Brownian\nmotion and rough paths with applications to robust nonlinear filtering and\nrough partial differential equations]. Applying this construction to the case\nwhere $\\mathbf{X}$ is the canonical lift of a one-dimensional fractional\nBrownian motion (possibly correlated with $W$) completes the partial rough path\nof [Fukasawa and Takano (2024). A partial rough path space for rough\nvolatility]. We use this to model rough volatility with the versatile toolkit\nof rough differential equations (RDEs), namely by taking the price and\nvolatility processes to be the solution to a single RDE. We argue that our\nframework is already interesting when $W$ and $X$ are independent, as\ncorrelation between the price and volatility can be introduced in the dynamics.\nThe lead-lag scheme of [Flint, Hambly, and Lyons (2016). Discretely sampled\nsignals and the rough Hoff process] is extended to our fractional setting as an\napproximation theory for the rough path in the correlated case. Continuity of\nthe solution map transforms this into a numerical scheme for RDEs. We\nnumerically test this framework and use it to calibrate a simple new rough\nvolatility model to market data.", "published": "2024-12-30 18:57:29", "link": "http://arxiv.org/abs/2412.21192v1", "categories": ["q-fin.MF", "math.PR", "60L20, 60L90, 60G22, 65C30, 91G20, 91G60"], "primary_category": "q-fin.MF"}
{"title": "Strategic Learning and Trading in Broker-Mediated Markets", "abstract": "We study strategic interactions in a broker-mediated market. A broker\nprovides liquidity to an informed trader and to noise traders while managing\ninventory in the lit market. The broker and the informed trader maximise their\ntrading performance while filtering each other's private information; the\ntrader estimates the broker's trading activity in the lit market while the\nbroker estimates the informed trader's private signal. Brokers hold a strategic\nadvantage over traders who rely solely on prices to filter information. We find\nthat information leakage in the client's trading flow yields an economic value\nto the broker that is comparable to transaction costs; she speculates\nprofitably and mitigates risk effectively, which, in turn, adversely impacts\nthe informed trader's performance. In contrast, low signal-to-noise sources,\nsuch as prices, result in the broker's trading performance being\nindistinguishable from that of a naive strategy that internalises noise flow,\nexternalises informed flow, and offloads inventory at a constant rate.", "published": "2024-12-30 10:34:44", "link": "http://arxiv.org/abs/2412.20847v1", "categories": ["q-fin.TR"], "primary_category": "q-fin.TR"}
{"title": "Knowledge Editing for Large Language Model with Knowledge Neuronal\n  Ensemble", "abstract": "As real-world knowledge is constantly evolving, ensuring the timeliness and\naccuracy of a model's knowledge is crucial. This has made knowledge editing in\nlarge language models increasingly important. However, existing knowledge\nediting methods face several challenges, including parameter localization\ncoupling, imprecise localization, and a lack of dynamic interaction across\nlayers. In this paper, we propose a novel knowledge editing method called\nKnowledge Neuronal Ensemble (KNE). A knowledge neuronal ensemble represents a\ngroup of neurons encoding specific knowledge, thus mitigating the issue of\nfrequent parameter modification caused by coupling in parameter localization.\nThe KNE method enhances the precision and accuracy of parameter localization by\ncomputing gradient attribution scores for each parameter at each layer. During\nthe editing process, only the gradients and losses associated with the\nknowledge neuronal ensemble are computed, with error backpropagation performed\naccordingly, ensuring dynamic interaction and collaborative updates among\nparameters. Experimental results on three widely used knowledge editing\ndatasets show that the KNE method significantly improves the accuracy of\nknowledge editing and achieves, or even exceeds, the performance of the best\nbaseline methods in portability and locality metrics.", "published": "2024-12-30 00:58:00", "link": "http://arxiv.org/abs/2412.20637v1", "categories": ["cs.CL", "68T50"], "primary_category": "cs.CL"}
{"title": "Align Attention Heads Before Merging Them: An Effective Way for\n  Converting MHA to GQA", "abstract": "Large language models have been shown to perform well on a variety of natural\nlanguage processing problems. However, as the model size and the input\nsequence's length increase, the rapid increase of KV Cache significantly slows\ndown inference speed. Therefore GQA model, as an alternative to MHA model, has\nbeen widely introduced into LLMs. In this work, we propose a low-cost method\nfor pruning MHA models into GQA models with any compression ratio of key-value\nheads. Our method is based on $\\mathit{L_0}$ masks to gradually remove\nredundant parameters. In addition, we apply orthogonal transformations to\nattention heads without changing the model to increase similarity between\nattention heads before pruning training, in order to further improve\nperformance of the model. Our method can be compatible with rotary position\nembedding (RoPE), which means the model after training can be fully adapted to\nthe mainstream standard GQA framework. Experiments demonstrate that our\nstrategy can compress up to 87.5% of key-value heads of the LLaMA2-7B model\nwithout too much performance degradation, just achieved through supervised\nfine-tuning.", "published": "2024-12-30 03:05:45", "link": "http://arxiv.org/abs/2412.20677v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Depression and Anxiety Prediction Using Deep Language Models and\n  Transfer Learning", "abstract": "Digital screening and monitoring applications can aid providers in the\nmanagement of behavioral health conditions. We explore deep language models for\ndetecting depression, anxiety, and their co-occurrence from conversational\nspeech collected during 16k user interactions with an application. Labels come\nfrom PHQ-8 and GAD-7 results also collected by the application. We find that\nresults for binary classification range from 0.86 to 0.79 AUC, depending on\ncondition and co-occurrence. Best performance is achieved when a user has\neither both or neither condition, and we show that this result is not\nattributable to data skew. Finally, we find evidence suggesting that underlying\nword sequence cues may be more salient for depression than for anxiety.", "published": "2024-12-30 06:33:39", "link": "http://arxiv.org/abs/2412.20741v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are LLMs Really Not Knowledgable? Mining the Submerged Knowledge in\n  LLMs' Memory", "abstract": "Large language models (LLMs) have shown promise as potential knowledge bases,\nyet they often struggle with question-answering tasks and are prone to\nhallucinations. While previous research attributes these issues to knowledge\ngaps in the model's parameters, our investigation reveals a different\nphenomenon: LLMs often retain correct knowledge even when generating incorrect\nanswers. Through analysis of model's internal representations, we find that\ncorrect answers frequently appear among high-probability tokens despite not\nbeing selected as final outputs. Based on this observation, we introduce\nHits@k, a new metric to assess knowledge retention independent of expression\naccuracy. Our extensive experiments demonstrate that LLMs store significantly\nmore knowledge than their QA performance suggests. Building on these findings,\nwe develop SkipUnsure, a method to improve answer accuracy by leveraging\ndetected but unexpressed knowledge. Experiments on both open-domain and\nspecific-domain datasets show consistent improvements, with accuracy gains of\nup to 11.8% on DBPedia and 6.3% on IMDB, without requiring model retraining.", "published": "2024-12-30 10:29:18", "link": "http://arxiv.org/abs/2412.20846v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Plug-and-Play Training Framework for Preference Optimization", "abstract": "Recently, preference optimization methods such as DPO have significantly\nenhanced large language models (LLMs) in wide tasks including dialogue and\nquestion-answering. However, current methods fail to account for the varying\ndifficulty levels of training samples during preference optimization, leading\nto mediocre performance in tasks with high accuracy requirements, particularly\nin mathematical reasoning. To address this limitation, we propose a novel\ntraining framework, which employs multiple sampling to analyze output\ndistributions, assign different weights to samples, and incorporate these\nweights into the preference optimization process. This plug-and-play approach\nenables LLMs to prioritize challenging examples during training, improving\nlearning efficiency. Experimental results demonstrate that our framework\nintegrates seamlessly with various preference optimization methods and achieves\nconsistent improvements in mathematical reasoning tasks.", "published": "2024-12-30 15:01:48", "link": "http://arxiv.org/abs/2412.20996v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GePBench: Evaluating Fundamental Geometric Perception for Multimodal\n  Large Language Models", "abstract": "Multimodal large language models (MLLMs) have made significant progress in\nintegrating visual and linguistic understanding. Existing benchmarks typically\nfocus on high-level semantic capabilities, such as scene understanding and\nvisual reasoning, but often overlook a crucial, foundational ability: geometric\nperception. Geometric perception involves understanding geometric shapes,\nstructures, and spatial relationships, which are essential for supporting\nhigher-level semantic tasks. Despite its importance, this capability remains\nunderexplored in current MLLM research. To address this gap, we introduce\nGePBench, a novel benchmark designed to assess the geometric perception\nabilities of MLLMs. Our extensive evaluations reveal that current\nstate-of-the-art MLLMs exhibit significant deficiencies in geometric perception\ntasks. Furthermore, we show that models trained with GePBench data demonstrate\nsubstantial improvements on a wide range of benchmark tasks, highlighting the\ncritical role of geometric perception in enabling advanced multimodal\napplications. Our code and datasets will be publicly available.", "published": "2024-12-30 16:01:43", "link": "http://arxiv.org/abs/2412.21036v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Multi-Task Inferencing with a Shared Backbone and Lightweight\n  Task-Specific Adapters for Automatic Scoring", "abstract": "The integration of Artificial Intelligence (AI) in education requires\nscalable and efficient frameworks that balance performance, adaptability, and\ncost. This paper addresses these needs by proposing a shared backbone model\narchitecture enhanced with lightweight LoRA adapters for task-specific\nfine-tuning, targeting the automated scoring of student responses across 27\nmutually exclusive tasks. By achieving competitive performance (average QWK of\n0.848 compared to 0.888 for fully fine-tuned models) while reducing GPU memory\nconsumption by 60% and inference latency by 40%, the framework demonstrates\nsignificant efficiency gains. This approach aligns with the workshops' focus on\nimproving language models for educational tasks, creating responsible\ninnovations for cost-sensitive deployment, and supporting educators by\nstreamlining assessment workflows. The findings underscore the potential of\nscalable AI to enhance learning outcomes while maintaining fairness and\ntransparency in automated scoring systems.", "published": "2024-12-30 16:34:11", "link": "http://arxiv.org/abs/2412.21065v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do NOT Think That Much for 2+3=? On the Overthinking of o1-Like LLMs", "abstract": "The remarkable performance of models like the OpenAI o1 can be attributed to\ntheir ability to emulate human-like long-time thinking during inference. These\nmodels employ extended chain-of-thought (CoT) processes, exploring multiple\nstrategies to enhance problem-solving capabilities. However, a critical\nquestion remains: How to intelligently and efficiently scale computational\nresources during testing. This paper presents the first comprehensive study on\nthe prevalent issue of overthinking in these models, where excessive\ncomputational resources are allocated for simple problems with minimal benefit.\nWe introduce novel efficiency metrics from both outcome and process\nperspectives to evaluate the rational use of computational resources by o1-like\nmodels. Using a self-training paradigm, we propose strategies to mitigate\noverthinking, streamlining reasoning processes without compromising accuracy.\nExperimental results show that our approach successfully reduces computational\noverhead while preserving model performance across a range of testsets with\nvarying difficulty levels, such as GSM8K, MATH500, GPQA, and AIME.", "published": "2024-12-30 18:55:12", "link": "http://arxiv.org/abs/2412.21187v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing AI Safety Through the Fusion of Low Rank Adapters", "abstract": "Instruction fine-tuning of large language models (LLMs) is a powerful method\nfor improving task-specific performance, but it can inadvertently lead to a\nphenomenon where models generate harmful responses when faced with malicious\nprompts. In this paper, we explore Low-Rank Adapter Fusion (LoRA) as a means to\nmitigate these risks while preserving the model's ability to handle diverse\ninstructions effectively. Through an extensive comparative analysis against\nestablished baselines using recognized benchmark datasets, we demonstrate a\n42\\% reduction in the harmfulness rate by leveraging LoRA fusion between a task\nadapter and a safety adapter, the latter of which is specifically trained on\nour safety dataset. However, we also observe exaggerated safety behaviour,\nwhere the model rejects safe prompts that closely resemble unsafe ones", "published": "2024-12-30 13:12:27", "link": "http://arxiv.org/abs/2501.06208v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ChartAdapter: Large Vision-Language Model for Chart Summarization", "abstract": "Chart summarization, which focuses on extracting key information from charts\nand interpreting it in natural language, is crucial for generating and\ndelivering insights through effective and accessible data analysis. Traditional\nmethods for chart understanding and summarization often rely on multi-stage\npipelines, which may produce suboptimal semantic alignment between visual and\ntextual information. In comparison, recently developed LLM-based methods are\nmore dependent on the capability of foundation images or languages, while\nignoring the characteristics of chart data and its relevant challenges. To\naddress these limitations, we propose ChartAdapter, a novel lightweight\ntransformer module designed to bridge the gap between charts and textual\nsummaries. ChartAdapter employs learnable query vectors to extract implicit\nsemantics from chart data and incorporates a cross-modal alignment projector to\nenhance vision-to-language generative learning. By integrating ChartAdapter\nwith an LLM, we enable end-to-end training and efficient chart summarization.\nTo further enhance the training, we introduce a three-stage hierarchical\ntraining procedure and develop a large-scale dataset specifically curated for\nchart summarization, comprising 190,618 samples. Experimental results on the\nstandard Chart-to-Text testing set demonstrate that our approach significantly\noutperforms existing methods, including state-of-the-art models, in generating\nhigh-quality chart summaries. Ablation studies further validate the\neffectiveness of key components in ChartAdapter. This work highlights the\npotential of tailored LLM-based approaches to advance chart understanding and\nsets a strong foundation for future research in this area.", "published": "2024-12-30 05:07:34", "link": "http://arxiv.org/abs/2412.20715v1", "categories": ["cs.MM", "cs.CL"], "primary_category": "cs.MM"}
{"title": "HunyuanProver: A Scalable Data Synthesis Framework and Guided Tree\n  Search for Automated Theorem Proving", "abstract": "We introduce HunyuanProver, an language model finetuned from the Hunyuan 7B\nfor interactive automatic theorem proving with LEAN4. To alleviate the data\nsparsity issue, we design a scalable framework to iterative synthesize data\nwith low cost. Besides, guided tree search algorithms are designed to enable\neffective ``system 2 thinking`` of the prover. HunyuanProver achieves\nstate-of-the-art (SOTA) performances on major benchmarks. Specifically, it\nachieves a pass of 68.4% on the miniF2F-test compared to 65.9%, the current\nSOTA results. It proves 4 IMO statements (imo_1960_p2, imo_1962_p2},\nimo_1964_p2 and imo_1983_p6) in miniF2F-test. To benefit the community, we will\nopen-source a dataset of 30k synthesized instances, where each instance\ncontains the original question in natural language, the converted statement by\nautoformalization, and the proof by HunyuanProver.", "published": "2024-12-30 06:18:33", "link": "http://arxiv.org/abs/2412.20735v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Attributing Culture-Conditioned Generations to Pretraining Corpora", "abstract": "In open-ended generative tasks like narrative writing or dialogue, large\nlanguage models often exhibit cultural biases, showing limited knowledge and\ngenerating templated outputs for less prevalent cultures. Recent works show\nthat these biases may stem from uneven cultural representation in pretraining\ncorpora. This work investigates how pretraining leads to biased\nculture-conditioned generations by analyzing how models associate entities with\ncultures based on pretraining data patterns. We propose the MEMOed framework\n(MEMOrization from pretraining document) to determine whether a generation for\na culture arises from memorization. Using MEMOed on culture-conditioned\ngenerations about food and clothing for 110 cultures, we find that\nhigh-frequency cultures in pretraining data yield more generations with\nmemorized symbols, while some low-frequency cultures produce none.\nAdditionally, the model favors generating entities with extraordinarily high\nfrequency regardless of the conditioned culture, reflecting biases toward\nfrequent pretraining terms irrespective of relevance. We hope that the MEMOed\nframework and our insights will inspire more works on attributing model\nperformance on pretraining data.", "published": "2024-12-30 07:09:25", "link": "http://arxiv.org/abs/2412.20760v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Disentangling Preference Representation and Text Generation for\n  Efficient Individual Preference Alignment", "abstract": "Aligning Large Language Models (LLMs) with general human preferences has been\nproved crucial in improving the interaction quality between LLMs and human.\nHowever, human values are inherently diverse among different individuals,\nmaking it insufficient to align LLMs solely with general preferences. To\naddress this, personalizing LLMs according to individual feedback emerges as a\npromising solution. Nonetheless, this approach presents challenges in terms of\nthe efficiency of alignment algorithms. In this work, we introduce a flexible\nparadigm for individual preference alignment. Our method fundamentally improves\nefficiency by disentangling preference representation from text generation in\nLLMs. We validate our approach across multiple text generation tasks and\ndemonstrate that it can produce aligned quality as well as or better than\nPEFT-based methods, while reducing additional training time for each new\nindividual preference by $80\\%$ to $90\\%$ in comparison with them.", "published": "2024-12-30 09:58:31", "link": "http://arxiv.org/abs/2412.20834v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DoTA: Weight-Decomposed Tensor Adaptation for Large Language Models", "abstract": "Low-rank adaptation (LoRA) reduces the computational and memory demands of\nfine-tuning large language models (LLMs) by approximating updates with low-rank\nmatrices. However, low-rank approximation in two-dimensional space fails to\ncapture high-dimensional structures within the target matrix. Recently, tensor\ndecomposition methods have been explored for fine-tuning LLMs, leveraging their\nability to extract structured information. Yet, these approaches primarily rely\non random initialization, and the impact of initialization on tensor adaptation\nremains underexplored. In this paper, we reveal that random initialization\nsignificantly diverges from the validation loss achieved by full fine-tuning.\nTo address this, we propose Weight-Decomposed Tensor Adaptation (DoTA), which\nleverages the Matrix Product Operator (MPO) decomposition of pre-trained\nweights for effective initialization in fine-tuning LLMs. Additionally, we\nintroduce QDoTA, a quantized version of DoTA designed for 4-bit quantization.\nExperiments on commonsense and arithmetic reasoning tasks show that DoTA\noutperforms random initialization methods with fewer parameters. QDoTA further\nreduces memory consumption and achieves comparable performance to DoTA on\ncommonsense reasoning tasks. We will release our code to support future\nresearch.", "published": "2024-12-30 12:00:47", "link": "http://arxiv.org/abs/2412.20891v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GASLITEing the Retrieval: Exploring Vulnerabilities in Dense\n  Embedding-based Search", "abstract": "Dense embedding-based text retrieval$\\unicode{x2013}$retrieval of relevant\npassages from corpora via deep learning encodings$\\unicode{x2013}$has emerged\nas a powerful method attaining state-of-the-art search results and popularizing\nthe use of Retrieval Augmented Generation (RAG). Still, like other search\nmethods, embedding-based retrieval may be susceptible to search-engine\noptimization (SEO) attacks, where adversaries promote malicious content by\nintroducing adversarial passages to corpora. To faithfully assess and gain\ninsights into the susceptibility of such systems to SEO, this work proposes the\nGASLITE attack, a mathematically principled gradient-based search method for\ngenerating adversarial passages without relying on the corpus content or\nmodifying the model. Notably, GASLITE's passages (1) carry adversary-chosen\ninformation while (2) achieving high retrieval ranking for a selected query\ndistribution when inserted to corpora. We use GASLITE to extensively evaluate\nretrievers' robustness, testing nine advanced models under varied threat\nmodels, while focusing on realistic adversaries targeting queries on a specific\nconcept (e.g., a public figure). We found GASLITE consistently outperformed\nbaselines by $\\geq$140% success rate, in all settings. Particularly,\nadversaries using GASLITE require minimal effort to manipulate search\nresults$\\unicode{x2013}$by injecting a negligible amount of adversarial\npassages ($\\leq$0.0001% of the corpus), they could make them visible in the\ntop-10 results for 61-100% of unseen concept-specific queries against most\nevaluated models. Inspecting variance in retrievers' robustness, we identify\nkey factors that may contribute to models' susceptibility to SEO, including\nspecific properties in the embedding space's geometry.", "published": "2024-12-30 13:49:28", "link": "http://arxiv.org/abs/2412.20953v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Efficiently Serving LLM Reasoning Programs with Certaindex", "abstract": "The rapid evolution of large language models (LLMs) has unlocked their\ncapabilities in advanced reasoning tasks like mathematical problem-solving,\ncode generation, and legal analysis. Central to this progress are\ninference-time reasoning algorithms, which refine outputs by exploring multiple\nsolution paths, at the cost of increasing compute demands and response\nlatencies. Existing serving systems fail to adapt to the scaling behaviors of\nthese algorithms or the varying difficulty of queries, leading to inefficient\nresource use and unmet latency targets.\n  We present Dynasor, a system that optimizes inference-time compute for LLM\nreasoning queries. Unlike traditional engines, Dynasor tracks and schedules\nrequests within reasoning queries and uses Certaindex, a proxy that measures\nstatistical reasoning progress based on model certainty, to guide compute\nallocation dynamically. Dynasor co-adapts scheduling with reasoning progress:\nit allocates more compute to hard queries, reduces compute for simpler ones,\nand terminates unpromising queries early, balancing accuracy, latency, and\ncost. On diverse datasets and algorithms, Dynasor reduces compute by up to 50%\nin batch processing and sustaining 3.3x higher query rates or 4.7x tighter\nlatency SLOs in online serving.", "published": "2024-12-30 14:57:53", "link": "http://arxiv.org/abs/2412.20993v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "KARPA: A Training-free Method of Adapting Knowledge Graph as References\n  for Large Language Model's Reasoning Path Aggregation", "abstract": "Large language models (LLMs) demonstrate exceptional performance across a\nvariety of tasks, yet they are often affected by hallucinations and the\ntimeliness of knowledge. Leveraging knowledge graphs (KGs) as external\nknowledge sources has emerged as a viable solution, but existing methods for\nLLM-based knowledge graph question answering (KGQA) are often limited by\nstep-by-step decision-making on KGs, restricting the global planning and\nreasoning capabilities of LLMs, or they require fine-tuning or pre-training on\nspecific KGs. To address these challenges, we propose Knowledge graph Assisted\nReasoning Path Aggregation (KARPA), a novel framework that harnesses the global\nplanning abilities of LLMs for efficient and accurate KG reasoning. KARPA\noperates in three steps: pre-planning relation paths using the LLM's global\nplanning capabilities, matching semantically relevant paths via an embedding\nmodel, and reasoning over these paths to generate answers. Unlike existing KGQA\nmethods, KARPA avoids stepwise traversal, requires no additional training, and\nis adaptable to various LLM architectures. Extensive experimental results show\nthat KARPA achieves state-of-the-art performance in KGQA tasks, delivering both\nhigh efficiency and accuracy. Our code will be available on Github.", "published": "2024-12-30 14:58:46", "link": "http://arxiv.org/abs/2412.20995v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Verbosity-Aware Rationale Reduction: Effective Reduction of Redundant\n  Rationale via Principled Criteria", "abstract": "Large Language Models (LLMs) rely on generating extensive intermediate\nreasoning units (e.g., tokens, sentences) to enhance final answer quality\nacross a wide range of complex tasks. While generating multiple reasoning paths\nor iteratively refining rationales proves effective for improving performance,\nthese approaches inevitably result in significantly higher inference costs. In\nthis work, we propose a novel sentence-level rationale reduction training\nframework that leverages likelihood-based criteria, verbosity, to identify and\nremove redundant reasoning sentences. Unlike previous approaches that utilize\ntoken-level reduction, our sentence-level reduction framework maintains model\nperformance while reducing generation length. This preserves the original\nreasoning abilities of LLMs and achieves an average 17.15% reduction in\ngeneration costs across various models and tasks.", "published": "2024-12-30 15:15:08", "link": "http://arxiv.org/abs/2412.21006v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MapQaTor: A System for Efficient Annotation of Map Query Datasets", "abstract": "Mapping and navigation services like Google Maps, Apple Maps, Openstreet\nMaps, are essential for accessing various location-based data, yet they often\nstruggle to handle natural language geospatial queries. Recent advancements in\nLarge Language Models (LLMs) show promise in question answering (QA), but\ncreating reliable geospatial QA datasets from map services remains challenging.\nWe introduce MapQaTor, a web application that streamlines the creation of\nreproducible, traceable map-based QA datasets. With its plug-and-play\narchitecture, MapQaTor enables seamless integration with any maps API, allowing\nusers to gather and visualize data from diverse sources with minimal setup. By\ncaching API responses, the platform ensures consistent ground truth, enhancing\nthe reliability of the data even as real-world information evolves. MapQaTor\ncentralizes data retrieval, annotation, and visualization within a single\nplatform, offering a unique opportunity to evaluate the current state of\nLLM-based geospatial reasoning while advancing their capabilities for improved\ngeospatial understanding. Evaluation metrics show that, MapQaTor speeds up the\nannotation process by at least 30 times compared to manual methods,\nunderscoring its potential for developing geospatial resources, such as complex\nmap reasoning datasets. The website is live at: https://mapqator.github.io/ and\na demo video is available at: https://youtu.be/7_aV9Wmhs6Q.", "published": "2024-12-30 15:33:19", "link": "http://arxiv.org/abs/2412.21015v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Plancraft: an evaluation dataset for planning with LLM agents", "abstract": "We present Plancraft, a multi-modal evaluation dataset for LLM agents.\nPlancraft has both a text-only and multi-modal interface, based on the\nMinecraft crafting GUI. We include the Minecraft Wiki to evaluate tool use and\nRetrieval Augmented Generation (RAG), as well as an oracle planner and oracle\nRAG information extractor, to ablate the different components of a modern agent\narchitecture. To evaluate decision-making, Plancraft also includes a subset of\nexamples that are intentionally unsolvable, providing a realistic challenge\nthat requires the agent not only to complete tasks but also to decide whether\nthey are solvable at all. We benchmark both open-source and closed-source LLMs\nand strategies on our task and compare their performance to a handcrafted\nplanner. We find that LLMs and VLMs struggle with the planning problems that\nPlancraft introduces, and we offer suggestions on how to improve their\ncapabilities.", "published": "2024-12-30 15:58:41", "link": "http://arxiv.org/abs/2412.21033v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring and Controlling Diversity in LLM-Agent Conversation", "abstract": "Controlling diversity in LLM-agent world simulations is essential for\nmaintaining stability in structured tasks while enabling variation where\ncreativity is needed. However, we observe that dialogue diversity declines\nsignificantly over long-term simulation. To investigate the role of prompt\ndesign in conversational diversity, we modularized the utterance generation\nprompt and found that reducing the given information leads to more diverse\noutputs. Based on this insight, we propose Adaptive Prompt Pruning (APP), a\nnovel method that allows users to control diversity through a single parameter,\nlambda. APP dynamically prunes the utterance generation prompt based on their\nattention weights and is compatible with traditional diversity control\ntechniques. We demonstrate that APP effectively controls output diversity\nthrough extensive experiments, and propose a method to balance the control\ntrade-offs. Additionally, we provide an in-depth analysis to offer insights\ninto optimizing diversity control in multi-agent simulation.", "published": "2024-12-30 17:25:58", "link": "http://arxiv.org/abs/2412.21102v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Training Software Engineering Agents and Verifiers with SWE-Gym", "abstract": "We present SWE-Gym, the first environment for training real-world software\nengineering (SWE) agents. SWE-Gym contains 2,438 real-world Python task\ninstances, each comprising a codebase with an executable runtime environment,\nunit tests, and a task specified in natural language. We use SWE-Gym to train\nlanguage model based SWE agents , achieving up to 19% absolute gains in resolve\nrate on the popular SWE-Bench Verified and Lite test sets. We also experiment\nwith inference-time scaling through verifiers trained on agent trajectories\nsampled from SWE-Gym. When combined with our fine-tuned SWE agents, we achieve\n32.0% and 26.0% on SWE-Bench Verified and Lite, respectively, reflecting a new\nstate-of-the-art for open-weight SWE agents. To facilitate further research, we\npublicly release SWE-Gym, models, and agent trajectories.", "published": "2024-12-30 18:15:39", "link": "http://arxiv.org/abs/2412.21139v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Facilitating large language model Russian adaptation with Learned\n  Embedding Propagation", "abstract": "Rapid advancements of large language model (LLM) technologies led to the\nintroduction of powerful open-source instruction-tuned LLMs that have the same\ntext generation quality as the state-of-the-art counterparts such as GPT-4.\nWhile the emergence of such models accelerates the adoption of LLM technologies\nin sensitive-information environments the authors of such models don not\ndisclose the training data necessary for replication of the results thus making\nthe achievements model-exclusive. Since those open-source models are also\nmultilingual this in turn reduces the benefits of training a language specific\nLLMs as improved inference computation efficiency becomes the only guaranteed\nadvantage of such costly procedure. More cost-efficient options such as\nvocabulary extension and subsequent continued pre-training are also inhibited\nby the lack of access to high-quality instruction-tuning data since it is the\nmajor factor behind the resulting LLM task-solving capabilities. To address the\nlimitations and cut the costs of the language adaptation pipeline we propose\nLearned Embedding Propagation (LEP). Unlike existing approaches our method has\nlower training data size requirements due to minimal impact on existing LLM\nknowledge which we reinforce using novel ad-hoc embedding propagation procedure\nthat allows to skip the instruction-tuning step and instead implant the new\nlanguage knowledge directly into any existing instruct-tuned variant. We\nevaluated four Russian vocabulary adaptations for LLaMa-3-8B and Mistral-7B,\nshowing that LEP is competitive with traditional instruction-tuning methods,\nachieving performance comparable to OpenChat 3.5 and LLaMa-3-8B-Instruct, with\nfurther improvements via self-calibration and continued tuning enhancing\ntask-solving capabilities.", "published": "2024-12-30 18:15:45", "link": "http://arxiv.org/abs/2412.21140v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "HumanEval Pro and MBPP Pro: Evaluating Large Language Models on\n  Self-invoking Code Generation", "abstract": "We introduce self-invoking code generation, a new task designed to evaluate\nthe progressive reasoning and problem-solving capabilities of LLMs. In this\ntask, models are presented with a base problem and a related, more complex\nproblem. They must solve the base problem and then utilize its solution to\naddress the more complex one. This work features three key contributions.\nFirst, we propose a general recipe for generating more challenging versions of\nexisting benchmarks, resulting in three new benchmarks: HumanEval Pro, MBPP\nPro, and BigCodeBench-Lite Pro, specifically designed to assess LLMs on\nself-invoking code generation. Second, from the analysis of experimental\nresults over twenty LLMs on our benchmarks, we have two important observations:\n(i) Most LLMs excel in traditional code generation benchmarks like HumanEval\nand MBPP, but their performance declines on self-invoking tasks. For example,\no1-mini achieves 96.2% pass@1 on HumanEval but only 76.2% on HumanEval Pro.\n(ii) On self-invoking code generation task, the instruction-tuned models\ndemonstrate only marginal improvements compared to the base models. Third, we\ndisclose the types of failure modes that exist in our evaluation results. All\nthese results underscore the need for further advancements in self-invoking\ncode generation tasks and provide a new direction for future research on\nenhancing LLMs' code reasoning capabilities.", "published": "2024-12-30 18:58:58", "link": "http://arxiv.org/abs/2412.21199v2", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Position Information Emerges in Causal Transformers Without Positional\n  Encodings via Similarity of Nearby Embeddings", "abstract": "Transformers with causal attention can solve tasks that require positional\ninformation without using positional encodings. In this work, we propose and\ninvestigate a new hypothesis about how positional information can be stored\nwithout using explicit positional encoding. We observe that nearby embeddings\nare more similar to each other than faraway embeddings, allowing the\ntransformer to potentially reconstruct the positions of tokens. We show that\nthis pattern can occur in both the trained and the randomly initialized\nTransformer models with causal attention and no positional encodings over a\ncommon range of hyperparameters.", "published": "2024-12-30 03:35:41", "link": "http://arxiv.org/abs/2501.00073v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Data-Centric Approach to Detecting and Mitigating Demographic Bias in\n  Pediatric Mental Health Text: A Case Study in Anxiety Detection", "abstract": "Introduction: Healthcare AI models often inherit biases from their training\ndata. While efforts have primarily targeted bias in structured data, mental\nhealth heavily depends on unstructured data. This study aims to detect and\nmitigate linguistic differences related to non-biological differences in the\ntraining data of AI models designed to assist in pediatric mental health\nscreening. Our objectives are: (1) to assess the presence of bias by evaluating\noutcome parity across sex subgroups, (2) to identify bias sources through\ntextual distribution analysis, and (3) to develop a de-biasing method for\nmental health text data. Methods: We examined classification parity across\ndemographic groups and assessed how gendered language influences model\npredictions. A data-centric de-biasing method was applied, focusing on\nneutralizing biased terms while retaining salient clinical information. This\nmethodology was tested on a model for automatic anxiety detection in pediatric\npatients. Results: Our findings revealed a systematic under-diagnosis of female\nadolescent patients, with a 4% lower accuracy and a 9% higher False Negative\nRate (FNR) compared to male patients, likely due to disparities in information\ndensity and linguistic differences in patient notes. Notes for male patients\nwere on average 500 words longer, and linguistic similarity metrics indicated\ndistinct word distributions between genders. Implementing our de-biasing\napproach reduced diagnostic bias by up to 27%, demonstrating its effectiveness\nin enhancing equity across demographic groups. Discussion: We developed a\ndata-centric de-biasing framework to address gender-based content disparities\nwithin clinical text. By neutralizing biased language and enhancing focus on\nclinically essential information, our approach demonstrates an effective\nstrategy for mitigating bias in AI healthcare models trained on text.", "published": "2024-12-30 20:00:22", "link": "http://arxiv.org/abs/2501.00129v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Temporal reasoning for timeline summarisation in social media", "abstract": "This paper explores whether enhancing temporal reasoning capabilities in\nLarge Language Models (LLMs) can improve the quality of timeline summarisation,\nthe task of summarising long texts containing sequences of events, such as\nsocial media threads. We first introduce NarrativeReason, a novel dataset\nfocused on temporal relationships among sequential events within narratives,\ndistinguishing it from existing temporal reasoning datasets that primarily\naddress pair-wise event relationships. Our approach then combines temporal\nreasoning with timeline summarisation through a knowledge distillation\nframework, where we first fine-tune a teacher model on temporal reasoning tasks\nand then distill this knowledge into a student model while simultaneously\ntraining it for the task of timeline summarisation. Experimental results\ndemonstrate that our model achieves superior performance on out-of-domain\nmental health-related timeline summarisation tasks, which involve long social\nmedia threads with repetitions of events and a mix of emotions, highlighting\nthe importance and generalisability of leveraging temporal reasoning to improve\ntimeline summarisation.", "published": "2024-12-30 21:54:33", "link": "http://arxiv.org/abs/2501.00152v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Measuring Large Language Models Capacity to Annotate Journalistic\n  Sourcing", "abstract": "Since the launch of ChatGPT in late 2022, the capacities of Large Language\nModels and their evaluation have been in constant discussion and evaluation\nboth in academic research and in the industry. Scenarios and benchmarks have\nbeen developed in several areas such as law, medicine and math (Bommasani et\nal., 2023) and there is continuous evaluation of model variants. One area that\nhas not received sufficient scenario development attention is journalism, and\nin particular journalistic sourcing and ethics. Journalism is a crucial\ntruth-determination function in democracy (Vincent, 2023), and sourcing is a\ncrucial pillar to all original journalistic output. Evaluating the capacities\nof LLMs to annotate stories for the different signals of sourcing and how\nreporters justify them is a crucial scenario that warrants a benchmark\napproach. It offers potential to build automated systems to contrast more\ntransparent and ethically rigorous forms of journalism with everyday fare. In\nthis paper we lay out a scenario to evaluate LLM performance on identifying and\nannotating sourcing in news stories on a five-category schema inspired from\njournalism studies (Gans, 2004). We offer the use case, our dataset and metrics\nand as the first step towards systematic benchmarking. Our accuracy findings\nindicate LLM-based approaches have more catching to do in identifying all the\nsourced statements in a story, and equally, in matching the type of sources. An\neven harder task is spotting source justifications.", "published": "2024-12-30 22:15:57", "link": "http://arxiv.org/abs/2501.00164v2", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "QUBE: Enhancing Automatic Heuristic Design via Quality-Uncertainty\n  Balanced Evolution", "abstract": "Solving NP-hard problems traditionally relies on heuristics, yet manually\ndesigning effective heuristics for complex problems remains a significant\nchallenge. While recent advancements like FunSearch have shown that large\nlanguage models (LLMs) can be integrated into evolutionary algorithms (EAs) for\nheuristic design, their potential is hindered by limitations in balancing\nexploitation and exploration. We introduce Quality-Uncertainty Balanced\nEvolution (QUBE), a novel approach that enhances LLM+EA methods by redefining\nthe priority criterion within the FunSearch framework. QUBE employs the\nQuality-Uncertainty Trade-off Criterion (QUTC), based on our proposed\nUncertainty-Inclusive Quality metric, to evaluate and guide the evolutionary\nprocess. Through extensive experiments on challenging NP-complete problems,\nQUBE demonstrates significant performance improvements over FunSearch and\nbaseline methods. Our code are available at\nhttps://github.com/zzjchen/QUBE_code.", "published": "2024-12-30 04:05:22", "link": "http://arxiv.org/abs/2412.20694v4", "categories": ["cs.NE", "cs.AI", "cs.CL"], "primary_category": "cs.NE"}
{"title": "Enhancing Multimodal Emotion Recognition through Multi-Granularity\n  Cross-Modal Alignment", "abstract": "Multimodal emotion recognition (MER), leveraging speech and text, has emerged\nas a pivotal domain within human-computer interaction, demanding sophisticated\nmethods for effective multimodal integration. The challenge of aligning\nfeatures across these modalities is significant, with most existing approaches\nadopting a singular alignment strategy. Such a narrow focus not only limits\nmodel performance but also fails to address the complexity and ambiguity\ninherent in emotional expressions. In response, this paper introduces a\nMulti-Granularity Cross-Modal Alignment (MGCMA) framework, distinguished by its\ncomprehensive approach encompassing distribution-based, instance-based, and\ntoken-based alignment modules. This framework enables a multi-level perception\nof emotional information across modalities. Our experiments on IEMOCAP\ndemonstrate that our proposed method outperforms current state-of-the-art\ntechniques.", "published": "2024-12-30 09:30:41", "link": "http://arxiv.org/abs/2412.20821v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Enhancing Annotated Bibliography Generation with LLM Ensembles", "abstract": "This work proposes a novel approach to enhancing annotated bibliography\ngeneration through Large Language Model (LLM) ensembles. In particular,\nmultiple LLMs in different roles -- controllable text generation, evaluation,\nand summarization -- are introduced and validated using a systematic\nmethodology to enhance model performance in scholarly tasks. Output diversity\namong the ensemble that generates text is obtained using different LLM\nparameters, followed by an LLM acting as a judge to assess relevance, accuracy,\nand coherence. Responses selected by several combining strategies are then\nmerged and refined through summarization and redundancy removal techniques. The\npreliminary experimental validation demonstrates that the combined outputs from\nthe LLM ensemble improve coherence and relevance compared to individual\nresponses, leading to a 38% improvement in annotation quality and a 51%\nreduction in content redundancy, thus highlighting the potential for automating\ncomplex scholarly tasks while maintaining high-quality standards.", "published": "2024-12-30 11:07:05", "link": "http://arxiv.org/abs/2412.20864v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TangoFlux: Super Fast and Faithful Text to Audio Generation with Flow\n  Matching and Clap-Ranked Preference Optimization", "abstract": "We introduce TangoFlux, an efficient Text-to-Audio (TTA) generative model\nwith 515M parameters, capable of generating up to 30 seconds of 44.1kHz audio\nin just 3.7 seconds on a single A40 GPU. A key challenge in aligning TTA models\nlies in the difficulty of creating preference pairs, as TTA lacks structured\nmechanisms like verifiable rewards or gold-standard answers available for Large\nLanguage Models (LLMs). To address this, we propose CLAP-Ranked Preference\nOptimization (CRPO), a novel framework that iteratively generates and optimizes\npreference data to enhance TTA alignment. We demonstrate that the audio\npreference dataset generated using CRPO outperforms existing alternatives. With\nthis framework, TangoFlux achieves state-of-the-art performance across both\nobjective and subjective benchmarks. We open source all code and models to\nsupport further research in TTA generation.", "published": "2024-12-30 16:02:44", "link": "http://arxiv.org/abs/2412.21037v2", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Aviary: training language agents on challenging scientific tasks", "abstract": "Solving complex real-world tasks requires cycles of actions and observations.\nThis is particularly true in science, where tasks require many cycles of\nanalysis, tool use, and experimentation. Language agents are promising for\nautomating intellectual tasks in science because they can interact with tools\nvia natural language or code. Yet their flexibility creates conceptual and\npractical challenges for software implementations, since agents may comprise\nnon-standard components such as internal reasoning, planning, tool usage, as\nwell as the inherent stochasticity of temperature-sampled language models.\nHere, we introduce Aviary, an extensible gymnasium for language agents. We\nformalize agents as policies solving language-grounded partially observable\nMarkov decision processes, which we term language decision processes. We then\nimplement five environments, including three challenging scientific\nenvironments: (1) manipulating DNA constructs for molecular cloning, (2)\nanswering research questions by accessing scientific literature, and (3)\nengineering protein stability. These environments were selected for their focus\non multi-step reasoning and their relevance to contemporary biology research.\nFinally, with online training and scaling inference-time compute, we show that\nlanguage agents backed by open-source, non-frontier LLMs can match and exceed\nboth frontier LLM agents and human experts on multiple tasks at up to 100x\nlower inference cost.", "published": "2024-12-30 18:33:28", "link": "http://arxiv.org/abs/2412.21154v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "CaseSumm: A Large-Scale Dataset for Long-Context Summarization from U.S.\n  Supreme Court Opinions", "abstract": "This paper introduces CaseSumm, a novel dataset for long-context\nsummarization in the legal domain that addresses the need for longer and more\ncomplex datasets for summarization evaluation. We collect 25.6K U.S. Supreme\nCourt (SCOTUS) opinions and their official summaries, known as \"syllabuses.\"\nOur dataset is the largest open legal case summarization dataset, and is the\nfirst to include summaries of SCOTUS decisions dating back to 1815.\n  We also present a comprehensive evaluation of LLM-generated summaries using\nboth automatic metrics and expert human evaluation, revealing discrepancies\nbetween these assessment methods. Our evaluation shows Mistral 7b, a smaller\nopen-source model, outperforms larger models on most automatic metrics and\nsuccessfully generates syllabus-like summaries. In contrast, human expert\nannotators indicate that Mistral summaries contain hallucinations. The\nannotators consistently rank GPT-4 summaries as clearer and exhibiting greater\nsensitivity and specificity. Further, we find that LLM-based evaluations are\nnot more correlated with human evaluations than traditional automatic metrics.\nFurthermore, our analysis identifies specific hallucinations in generated\nsummaries, including precedent citation errors and misrepresentations of case\nfacts. These findings demonstrate the limitations of current automatic\nevaluation methods for legal summarization and highlight the critical role of\nhuman evaluation in assessing summary quality, particularly in complex,\nhigh-stakes domains.\n  CaseSumm is available at https://huggingface.co/datasets/ChicagoHAI/CaseSumm", "published": "2024-12-30 19:00:01", "link": "http://arxiv.org/abs/2501.00097v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DeepLL: Considering Linear Logic for the Analysis of Deep Learning\n  Experiments", "abstract": "Deep Learning experiments have critical requirements regarding the careful\nhandling of their datasets as well as the efficient and correct usage of APIs\nthat interact with hardware accelerators. On the one hand, software mistakes\nduring data handling can contaminate experiments and lead to incorrect results.\nOn the other hand, poorly coded APIs that interact with the hardware can lead\nto sub-optimal usage and untrustworthy conclusions. In this work we investigate\nthe use of Linear Logic for the analysis of Deep Learning experiments. We show\nthat primitives and operators of Linear Logic can be used to express: (i) an\nabstract representation of the control flow of an experiment, (ii) a set of\navailable experimental resources, such as API calls to the underlying\ndata-structures and hardware as well as (iii) reasoning rules about the correct\nconsumption of resources during experiments. Our proposed model is not only\nlightweight but also easy to comprehend having both a symbolic and a visual\ncomponent. Finally, its artifacts are themselves proofs in Linear Logic that\ncan be readily verified by off-the-shelf reasoners.", "published": "2024-12-30 22:38:56", "link": "http://arxiv.org/abs/2501.00169v1", "categories": ["cs.PL", "cs.AI", "cs.CL", "cs.SE"], "primary_category": "cs.PL"}
{"title": "The Text Classification Pipeline: Starting Shallow going Deeper", "abstract": "Text classification stands as a cornerstone within the realm of Natural\nLanguage Processing (NLP), particularly when viewed through computer science\nand engineering. The past decade has seen deep learning revolutionize text\nclassification, propelling advancements in text retrieval, categorization,\ninformation extraction, and summarization. The scholarly literature includes\ndatasets, models, and evaluation criteria, with English being the predominant\nlanguage of focus, despite studies involving Arabic, Chinese, Hindi, and\nothers. The efficacy of text classification models relies heavily on their\nability to capture intricate textual relationships and non-linear correlations,\nnecessitating a comprehensive examination of the entire text classification\npipeline.\n  In the NLP domain, a plethora of text representation techniques and model\narchitectures have emerged, with Large Language Models (LLMs) and Generative\nPre-trained Transformers (GPTs) at the forefront. These models are adept at\ntransforming extensive textual data into meaningful vector representations\nencapsulating semantic information. The multidisciplinary nature of text\nclassification, encompassing data mining, linguistics, and information\nretrieval, highlights the importance of collaborative research to advance the\nfield. This work integrates traditional and contemporary text mining\nmethodologies, fostering a holistic understanding of text classification.", "published": "2024-12-30 23:01:19", "link": "http://arxiv.org/abs/2501.00174v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "ACL-rlg: A Dataset for Reading List Generation", "abstract": "Familiarizing oneself with a new scientific field and its existing literature\ncan be daunting due to the large amount of available articles. Curated lists of\nacademic references, or reading lists, compiled by experts, offer a structured\nway to gain a comprehensive overview of a domain or a specific scientific\nchallenge. In this work, we introduce ACL-rlg, the largest open\nexpert-annotated reading list dataset. We also provide multiple baselines for\nevaluating reading list generation and formally define it as a retrieval task.\nOur qualitative study highlights the fact that traditional scholarly search\nengines and indexing methods perform poorly on this task, and GPT-4o, despite\nshowing better results, exhibits signs of potential data contamination.", "published": "2024-12-30 07:48:32", "link": "http://arxiv.org/abs/2502.15692v1", "categories": ["cs.DL", "cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.DL"}
{"title": "Two-component spatiotemporal template for activation-inhibition of\n  speech in ECoG", "abstract": "I compute the average trial-by-trial power of band-limited speech activity\nacross epochs of multi-channel high-density electrocorticography (ECoG)\nrecorded from multiple subjects during a consonant-vowel speaking task. I show\nthat previously seen anti-correlations of average beta frequency activity\n(12-35 Hz) to high-frequency gamma activity (70-140 Hz) during speech movement\nare observable between individual ECoG channels in the sensorimotor cortex\n(SMC). With this I fit a variance-based model using principal component\nanalysis to the band-powers of individual channels of session-averaged ECoG\ndata in the SMC and project SMC channels onto their lower-dimensional principal\ncomponents.\n  Spatiotemporal relationships between speech-related activity and principal\ncomponents are identified by correlating the principal components of both\nfrequency bands to individual ECoG channels over time using windowed\ncorrelation. Correlations of principal component areas to sensorimotor areas\nreveal a distinct two-component activation-inhibition-like representation for\nspeech that resembles distinct local sensorimotor areas recently shown to have\ncomplex interplay in whole-body motor control, inhibition, and posture. Notably\nthe third principal component shows insignificant correlations across all\nsubjects, suggesting two components of ECoG are sufficient to represent SMC\nactivity during speech movement.", "published": "2024-12-30 18:50:37", "link": "http://arxiv.org/abs/2412.21178v1", "categories": ["q-bio.NC", "cs.CL", "cs.LG", "eess.AS", "eess.SP"], "primary_category": "q-bio.NC"}
{"title": "Distributed Mixture-of-Agents for Edge Inference with Large Language\n  Models", "abstract": "Mixture-of-Agents (MoA) has recently been proposed as a method to enhance\nperformance of large language models (LLMs), enabling multiple individual LLMs\nto work together for collaborative inference. This collaborative approach\nresults in improved responses to user prompts compared to relying on a single\nLLM. In this paper, we consider such an MoA architecture in a distributed\nsetting, where LLMs operate on individual edge devices, each uniquely\nassociated with a user and equipped with its own distributed computing power.\nThese devices exchange information using decentralized gossip algorithms,\nallowing different device nodes to talk without the supervision of a\ncentralized server. In the considered setup, different users have their own LLM\nmodels to address user prompts. Additionally, the devices gossip either their\nown user-specific prompts or augmented prompts to generate more refined answers\nto certain queries. User prompts are temporarily stored in the device queues\nwhen their corresponding LLMs are busy. Given the memory limitations of edge\ndevices, it is crucial to ensure that the average queue sizes in the system\nremain bounded. In this paper, we address this by theoretically calculating the\nqueuing stability conditions for the device queues under reasonable\nassumptions, which we validate experimentally as well. Further, we demonstrate\nthrough experiments, leveraging open-source LLMs for the implementation of\ndistributed MoA, that certain MoA configurations produce higher-quality\nresponses compared to others, as evaluated on AlpacaEval 2.0 benchmark. The\nimplementation is available at:\nhttps://github.com/purbeshmitra/distributed_moa.", "published": "2024-12-30 18:59:06", "link": "http://arxiv.org/abs/2412.21200v1", "categories": ["cs.IT", "cs.CL", "cs.DC", "cs.LG", "cs.NI", "math.IT"], "primary_category": "cs.IT"}
{"title": "Metadata-Enhanced Speech Emotion Recognition: Augmented Residual\n  Integration and Co-Attention in Two-Stage Fine-Tuning", "abstract": "Speech Emotion Recognition (SER) involves analyzing vocal expressions to\ndetermine the emotional state of speakers, where the comprehensive and thorough\nutilization of audio information is paramount. Therefore, we propose a novel\napproach on self-supervised learning (SSL) models that employs all available\nauxiliary information -- specifically metadata -- to enhance performance.\nThrough a two-stage fine-tuning method in multi-task learning, we introduce the\nAugmented Residual Integration (ARI) module, which enhances transformer layers\nin encoder of SSL models. The module efficiently preserves acoustic features\nacross all different levels, thereby significantly improving the performance of\nmetadata-related auxiliary tasks that require various levels of features.\nMoreover, the Co-attention module is incorporated due to its complementary\nnature with ARI, enabling the model to effectively utilize multidimensional\ninformation and contextual relationships from metadata-related auxiliary tasks.\nUnder pre-trained base models and speaker-independent setup, our approach\nconsistently surpasses state-of-the-art (SOTA) models on multiple SSL encoders\nfor the IEMOCAP dataset.", "published": "2024-12-30 04:49:43", "link": "http://arxiv.org/abs/2412.20707v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Improving Acoustic Scene Classification in Low-Resource Conditions", "abstract": "Acoustic Scene Classification (ASC) identifies an environment based on an\naudio signal. This paper explores ASC in low-resource conditions and proposes a\nnovel model, DS-FlexiNet, which combines depthwise separable convolutions from\nMobileNetV2 with ResNet-inspired residual connections for a balance of\nefficiency and accuracy. To address hardware limitations and device\nheterogeneity, DS-FlexiNet employs Quantization Aware Training (QAT) for model\ncompression and data augmentation methods like Auto Device Impulse Response\n(ADIR) and Freq-MixStyle (FMS) to improve cross-device generalization.\nKnowledge Distillation (KD) from twelve teacher models further enhances\nperformance on unseen devices. The architecture includes a custom Residual\nNormalization layer to handle domain differences across devices, and depthwise\nseparable convolutions reduce computational overhead without sacrificing\nfeature representation. Experimental results show that DS-FlexiNet excels in\nboth adaptability and performance under resource-constrained conditions.", "published": "2024-12-30 05:42:20", "link": "http://arxiv.org/abs/2412.20722v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Phoneme-Level Contrastive Learning for User-Defined Keyword Spotting\n  with Flexible Enrollment", "abstract": "User-defined keyword spotting (KWS) enhances the user experience by allowing\nindividuals to customize keywords. However, in open-vocabulary scenarios, most\nexisting methods commonly suffer from high false alarm rates with confusable\nwords and are limited to either audio-only or text-only enrollment. Therefore,\nin this paper, we first explore the model's robustness against confusable\nwords. Specifically, we propose Phoneme-Level Contrastive Learning (PLCL),\nwhich refines and aligns query and source feature representations at the\nphoneme level. This method enhances the model's disambiguation capability\nthrough fine-grained positive and negative comparisons for more accurate\nalignment, and it is generalizable to jointly optimize both audio-text and\naudio-audio matching, adapting to various enrollment modes. Furthermore, we\nmaintain a context-agnostic phoneme memory bank to construct confusable\nnegatives for data augmentation. Based on this, a third-category discriminator\nis specifically designed to distinguish hard negatives. Overall, we develop a\nrobust and flexible KWS system, supporting different modality enrollment\nmethods within a unified framework. Verified on the LibriPhrase dataset, the\nproposed approach achieves state-of-the-art performance.", "published": "2024-12-30 08:59:20", "link": "http://arxiv.org/abs/2412.20805v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "DiCoW: Diarization-Conditioned Whisper for Target Speaker Automatic\n  Speech Recognition", "abstract": "Speaker-attributed automatic speech recognition (ASR) in multi-speaker\nenvironments remains a significant challenge, particularly when systems\nconditioned on speaker embeddings fail to generalize to unseen speakers. In\nthis work, we propose Diarization-Conditioned Whisper (DiCoW), a novel approach\nto target-speaker ASR that leverages speaker diarization outputs as\nconditioning information. DiCoW extends the pre-trained Whisper model by\nintegrating diarization labels directly, eliminating reliance on speaker\nembeddings and reducing the need for extensive speaker-specific training data.\nOur method introduces frame-level diarization-dependent transformations (FDDT)\nand query-key biasing (QKb) techniques to refine the model's focus on target\nspeakers while effectively handling overlapping speech. By leveraging\ndiarization outputs as conditioning signals, DiCoW simplifies the workflow for\nmulti-speaker ASR, improves generalization to unseen speakers and enables more\nreliable transcription in real-world multi-speaker recordings. Additionally, we\nexplore the integration of a connectionist temporal classification (CTC) head\nto Whisper and demonstrate its ability to improve transcription efficiency\nthrough hybrid decoding. Notably, we show that our approach is not limited to\nWhisper; it also provides similar benefits when applied to the Branchformer\nmodel. We validate DiCoW on real-world datasets, including AMI and NOTSOFAR-1\nfrom CHiME-8 challenge, as well as synthetic benchmarks such as Libri2Mix and\nLibriCSS, enabling direct comparisons with previous methods. Results\ndemonstrate that DiCoW enhances the model's target-speaker ASR capabilities\nwhile maintaining Whisper's accuracy and robustness on single-speaker data.", "published": "2024-12-30 19:24:15", "link": "http://arxiv.org/abs/2501.00114v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Tackling Cognitive Impairment Detection from Speech: A submission to the\n  PROCESS Challenge", "abstract": "This work describes our group's submission to the PROCESS Challenge 2024,\nwith the goal of assessing cognitive decline through spontaneous speech, using\nthree guided clinical tasks. This joint effort followed a holistic approach,\nencompassing both knowledge-based acoustic and text-based feature sets, as well\nas LLM-based macrolinguistic descriptors, pause-based acoustic biomarkers, and\nmultiple neural representations (e.g., LongFormer, ECAPA-TDNN, and Trillson\nembeddings). Combining these feature sets with different classifiers resulted\nin a large pool of models, from which we selected those that provided the best\nbalance between train, development, and individual class performance. Our\nresults show that our best performing systems correspond to combinations of\nmodels that are complementary to each other, relying on acoustic and textual\ninformation from all three clinical tasks.", "published": "2024-12-30 21:41:33", "link": "http://arxiv.org/abs/2501.00145v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Language-based Audio Retrieval with Co-Attention Networks", "abstract": "In recent years, user-generated audio content has proliferated across various\nmedia platforms, creating a growing need for efficient retrieval methods that\nallow users to search for audio clips using natural language queries. This\ntask, known as language-based audio retrieval, presents significant challenges\ndue to the complexity of learning semantic representations from heterogeneous\ndata across both text and audio modalities. In this work, we introduce a novel\nframework for the language-based audio retrieval task that leverages\nco-attention mechanismto jointly learn meaningful representations from both\nmodalities. To enhance the model's ability to capture fine-grained cross-modal\ninteractions, we propose a cascaded co-attention architecture, where\nco-attention modules are stacked or iterated to progressively refine the\nsemantic alignment between text and audio. Experiments conducted on two public\ndatasets show that the proposed method can achieve better performance than the\nstate-of-the-art method. Specifically, our best performed co-attention model\nachieves a 16.6% improvement in mean Average Precision on Clotho dataset, and a\n15.1% improvement on AudioCaps.", "published": "2024-12-30 12:49:55", "link": "http://arxiv.org/abs/2412.20914v1", "categories": ["cs.SD", "cs.IR", "eess.AS"], "primary_category": "cs.SD"}
