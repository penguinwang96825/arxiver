{"title": "Prompting Neural Machine Translation with Translation Memories", "abstract": "Improving machine translation (MT) systems with translation memories (TMs) is\nof great interest to practitioners in the MT community. However, previous\napproaches require either a significant update of the model architecture and/or\nadditional training efforts to make the models well-behaved when TMs are taken\nas additional input. In this paper, we present a simple but effective method to\nintroduce TMs into neural machine translation (NMT) systems. Specifically, we\ntreat TMs as prompts to the NMT model at test time, but leave the training\nprocess unchanged. The result is a slight update of an existing NMT system,\nwhich can be implemented in a few hours by anyone who is familiar with NMT.\nExperimental results on several datasets demonstrate that our system\nsignificantly outperforms strong baselines.", "published": "2023-01-13 03:33:26", "link": "http://arxiv.org/abs/2301.05380v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "It's Just a Matter of Time: Detecting Depression with Time-Enriched\n  Multimodal Transformers", "abstract": "Depression detection from user-generated content on the internet has been a\nlong-lasting topic of interest in the research community, providing valuable\nscreening tools for psychologists. The ubiquitous use of social media platforms\nlays out the perfect avenue for exploring mental health manifestations in posts\nand interactions with other users. Current methods for depression detection\nfrom social media mainly focus on text processing, and only a few also utilize\nimages posted by users. In this work, we propose a flexible time-enriched\nmultimodal transformer architecture for detecting depression from social media\nposts, using pretrained models for extracting image and text embeddings. Our\nmodel operates directly at the user-level, and we enrich it with the relative\ntime between posts by using time2vec positional embeddings. Moreover, we\npropose another model variant, which can operate on randomly sampled and\nunordered sets of posts to be more robust to dataset noise. We show that our\nmethod, using EmoBERTa and CLIP embeddings, surpasses other methods on two\nmultimodal datasets, obtaining state-of-the-art results of 0.931 F1 score on a\npopular multimodal Twitter dataset, and 0.902 F1 score on the only multimodal\nReddit dataset.", "published": "2023-01-13 09:40:19", "link": "http://arxiv.org/abs/2301.05453v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FUN with Fisher: Improving Generalization of Adapter-Based Cross-lingual\n  Transfer with Scheduled Unfreezing", "abstract": "Standard fine-tuning of language models typically performs well on\nin-distribution data, but suffers with generalization to distribution shifts.\nIn this work, we aim to improve the generalization of adapter-based\ncross-lingual task transfer where such cross-language distribution shifts are\nimminent. We investigate scheduled unfreezing algorithms -- originally proposed\nto mitigate catastrophic forgetting in transfer learning -- for fine-tuning\ntask adapters. Our experiments show that scheduled unfreezing methods close the\ngap to full fine-tuning and achieve stronger cross-lingual transfer\nperformance, suggesting that these methods can go beyond just mitigating\ncatastrophic forgetting. Next, aiming to understand these empirical findings,\nwe investigate the learning dynamics of scheduled unfreezing using Fisher\nInformation. Our experiments reveal that scheduled unfreezing induces different\nlearning dynamics compared to standard fine-tuning, and provide evidence that\nthe dynamics of Fisher Information during training correlate with cross-lingual\ngeneralization performance. We additionally propose a general scheduled\nunfreezing algorithm that achieves an average of 2 points improvement over four\ndatasets compared to standard fine-tuning and provides empirical evidence for a\ntheory-based justification of the heuristic unfreezing schedule for adapter\ntraining.", "published": "2023-01-13 11:26:53", "link": "http://arxiv.org/abs/2301.05487v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The 2022 n2c2/UW Shared Task on Extracting Social Determinants of Health", "abstract": "Objective: The n2c2/UW SDOH Challenge explores the extraction of social\ndeterminant of health (SDOH) information from clinical notes. The objectives\ninclude the advancement of natural language processing (NLP) information\nextraction techniques for SDOH and clinical information more broadly. This\npaper presents the shared task, data, participating teams, performance results,\nand considerations for future work.\n  Materials and Methods: The task used the Social History Annotated Corpus\n(SHAC), which consists of clinical text with detailed event-based annotations\nfor SDOH events such as alcohol, drug, tobacco, employment, and living\nsituation. Each SDOH event is characterized through attributes related to\nstatus, extent, and temporality. The task includes three subtasks related to\ninformation extraction (Subtask A), generalizability (Subtask B), and learning\ntransfer (Subtask C). In addressing this task, participants utilized a range of\ntechniques, including rules, knowledge bases, n-grams, word embeddings, and\npretrained language models (LM).\n  Results: A total of 15 teams participated, and the top teams utilized\npretrained deep learning LM. The top team across all subtasks used a\nsequence-to-sequence approach achieving 0.901 F1 for Subtask A, 0.774 F1\nSubtask B, and 0.889 F1 for Subtask C.\n  Conclusions: Similar to many NLP tasks and domains, pretrained LM yielded the\nbest performance, including generalizability and learning transfer. An error\nanalysis indicates extraction performance varies by SDOH, with lower\nperformance achieved for conditions, like substance use and homelessness, that\nincrease health risks (risk factors) and higher performance achieved for\nconditions, like substance abstinence and living with family, that reduce\nhealth risks (protective factors).", "published": "2023-01-13 14:20:23", "link": "http://arxiv.org/abs/2301.05571v2", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "From stage to page: language independent bootstrap measures of\n  distinctiveness in fictional speech", "abstract": "Stylometry is mostly applied to authorial style. Recently, researchers have\nbegun investigating the style of characters, finding that the variation remains\nwithin authorial bounds. We address the stylistic distinctiveness of characters\nin drama. Our primary contribution is methodological; we introduce and evaluate\ntwo non-parametric methods to produce a summary statistic for character\ndistinctiveness that can be usefully applied and compared across languages and\ntimes. Our first method is based on bootstrap distances between 3-gram\nprobability distributions, the second (reminiscent of 'unmasking' techniques)\non word keyness curves. Both methods are validated and explored by applying\nthem to a reasonably large corpus (a subset of DraCor): we analyse 3301\ncharacters drawn from 2324 works, covering five centuries and four languages\n(French, German, Russian, and the works of Shakespeare). Both methods appear\nuseful; the 3-gram method is statistically more powerful but the word keyness\nmethod offers rich interpretability. Both methods are able to capture\nphonological differences such as accent or dialect, as well as broad\ndifferences in topic and lexical richness. Based on exploratory analysis, we\nfind that smaller characters tend to be more distinctive, and that women are\ncross-linguistically more distinctive than men, with this latter finding\ncarefully interrogated using multiple regression. This greater distinctiveness\nstems from a historical tendency for female characters to be restricted to an\n'internal narrative domain' covering mainly direct discourse and\nfamily/romantic themes. It is hoped that direct, comparable statistical\nmeasures will form a basis for more sophisticated future studies, and advances\nin theory.", "published": "2023-01-13 16:58:43", "link": "http://arxiv.org/abs/2301.05659v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "In BLOOM: Creativity and Affinity in Artificial Lyrics and Art", "abstract": "We apply a large multilingual language model (BLOOM-176B) in open-ended\ngeneration of Chinese song lyrics, and evaluate the resulting lyrics for\ncoherence and creativity using human reviewers. We find that current\ncomputational metrics for evaluating large language model outputs (MAUVE) have\nlimitations in evaluation of creative writing. We note that the human concept\nof creativity requires lyrics to be both comprehensible and distinctive -- and\nthat humans assess certain types of machine-generated lyrics to score more\nhighly than real lyrics by popular artists. Inspired by the inherently\nmultimodal nature of album releases, we leverage a Chinese-language stable\ndiffusion model to produce high-quality lyric-guided album art, demonstrating a\ncreative approach for an artist seeking inspiration for an album or single.\nFinally, we introduce the MojimLyrics dataset, a Chinese-language dataset of\npopular song lyrics for future research.", "published": "2023-01-13 06:22:22", "link": "http://arxiv.org/abs/2301.05402v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Structuring ontologies in a context of collaborative system modelling", "abstract": "Prospective studies require discussing and collaborating with the\nstakeholders to create scenarios of the possible evolution of the studied\nvalue-chain. However, stakeholders don't always use the same words when\nreferring to one idea. Constructing an ontology and homogenizing vocabularies\nis thus crucial to identify key variables which serve in the construction of\nthe needed scenarios. Nevertheless, it is a very complex and timeconsuming\ntask. In this paper we present the method we used to manually build ontologies\nadapted to the needs of two complementary system-analysis models (namely the\n\"Godet\" and the \"MyChoice\" models), starting from interviews of the agri-food\nsystem's stakeholders.", "published": "2023-01-13 11:13:39", "link": "http://arxiv.org/abs/2301.05478v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Multilingual Detection of Check-Worthy Claims using World Languages and\n  Adapter Fusion", "abstract": "Check-worthiness detection is the task of identifying claims, worthy to be\ninvestigated by fact-checkers. Resource scarcity for non-world languages and\nmodel learning costs remain major challenges for the creation of models\nsupporting multilingual check-worthiness detection. This paper proposes\ncross-training adapters on a subset of world languages, combined by adapter\nfusion, to detect claims emerging globally in multiple languages. (1) With a\nvast number of annotators available for world languages and the\nstorage-efficient adapter models, this approach is more cost efficient. Models\ncan be updated more frequently and thus stay up-to-date. (2) Adapter fusion\nprovides insights and allows for interpretation regarding the influence of each\nadapter model on a particular language. The proposed solution often\noutperformed the top multilingual approaches in our benchmark tasks.", "published": "2023-01-13 11:50:08", "link": "http://arxiv.org/abs/2301.05494v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Classification of Cross-cultural News Events", "abstract": "We present a methodology to support the analysis of culture from text such as\nnews events and demonstrate its usefulness on categorizing news events from\ndifferent categories (society, business, health, recreation, science, shopping,\nsports, arts, computers, games and home) across different geographical\nlocations (different places in 117 countries). We group countries based on the\nculture that they follow and then filter the news events based on their content\ncategory. The news events are automatically labelled with the help of Hofstedes\ncultural dimensions. We present combinations of events across different\ncategories and check the performances of different classification methods. We\nalso presents experimental comparison of different number of features in order\nto find a suitable set to represent the culture.", "published": "2023-01-13 13:41:18", "link": "http://arxiv.org/abs/2301.05543v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Natural Language Processing of Aviation Occurrence Reports for Safety\n  Management", "abstract": "Occurrence reporting is a commonly used method in safety management systems\nto obtain insight in the prevalence of hazards and accident scenarios. In\nsupport of safety data analysis, reports are often categorized according to a\ntaxonomy. However, the processing of the reports can require significant effort\nfrom safety analysts and a common problem is interrater variability in labeling\nprocesses. Also, in some cases, reports are not processed according to a\ntaxonomy, or the taxonomy does not fully cover the contents of the documents.\nThis paper explores various Natural Language Processing (NLP) methods to\nsupport the analysis of aviation safety occurrence reports. In particular, the\nproblems studied are the automatic labeling of reports using a classification\nmodel, extracting the latent topics in a collection of texts using a topic\nmodel and the automatic generation of probable cause texts. Experimental\nresults showed that (i) under the right conditions the labeling of occurrence\nreports can be effectively automated with a transformer-based classifier, (ii)\ntopic modeling can be useful for finding the topics present in a collection of\nreports, and (iii) using a summarization model can be a promising direction for\ngenerating probable cause texts.", "published": "2023-01-13 17:00:09", "link": "http://arxiv.org/abs/2301.05663v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Infusing Commonsense World Models with Graph Knowledge", "abstract": "While language models have become more capable of producing compelling\nlanguage, we find there are still gaps in maintaining consistency, especially\nwhen describing events in a dynamically changing world. We study the setting of\ngenerating narratives in an open world text adventure game, where a graph\nrepresentation of the underlying game state can be used to train models that\nconsume and output both grounded graph representations and natural language\ndescriptions and actions. We build a large set of tasks by combining\ncrowdsourced and simulated gameplays with a novel dataset of complex actions in\norder to to construct such models. We find it is possible to improve the\nconsistency of action narration models by training on graph contexts and\ntargets, even if graphs are not present at test time. This is shown both in\nautomatic metrics and human evaluations. We plan to release our code, the new\nset of tasks, and best performing models.", "published": "2023-01-13 19:58:27", "link": "http://arxiv.org/abs/2301.05746v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multilingual Alzheimer's Dementia Recognition through Spontaneous\n  Speech: a Signal Processing Grand Challenge", "abstract": "This Signal Processing Grand Challenge (SPGC) targets a difficult automatic\nprediction problem of societal and medical relevance, namely, the detection of\nAlzheimer's Dementia (AD). Participants were invited to employ signal\nprocessing and machine learning methods to create predictive models based on\nspontaneous speech data. The Challenge has been designed to assess the extent\nto which predictive models built based on speech in one language (English)\ngeneralise to another language (Greek). To the best of our knowledge no work\nhas investigated acoustic features of the speech signal in multilingual AD\ndetection. Our baseline system used conventional machine learning algorithms\nwith Active Data Representation of acoustic features, achieving accuracy of\n73.91% on AD detection, and 4.95 root mean squared error on cognitive score\nprediction.", "published": "2023-01-13 14:09:13", "link": "http://arxiv.org/abs/2301.05562v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "68T10 (Primary) 92C55 (Secondary)", "J.3; I.2.6; I.5.1"], "primary_category": "eess.AS"}
{"title": "Automated speech- and text-based classification of neuropsychiatric\n  conditions in a multidiagnostic setting", "abstract": "Speech patterns have been identified as potential diagnostic markers for\nneuropsychiatric conditions. However, most studies only compare a single\nclinical group to healthy controls, whereas clinical practice often requires\ndifferentiating between multiple potential diagnoses (multiclass settings). To\naddress this, we assembled a dataset of repeated recordings from 420\nparticipants (67 with major depressive disorder, 106 with schizophrenia and 46\nwith autism, as well as matched controls), and tested the performance of a\nrange of conventional machine learning models and advanced Transformer models\non both binary and multiclass classification, based on voice and text features.\n  While binary models performed comparably to previous research (F1 scores\nbetween 0.54-0.75 for autism spectrum disorder, ASD; 0.67-0.92 for major\ndepressive disorder, MDD; and 0.71-0.83 for schizophrenia); when\ndifferentiating between multiple diagnostic groups performance decreased\nmarkedly (F1 scores between 0.35-0.44 for ASD, 0.57-0.75 for MDD, 0.15-0.66 for\nschizophrenia, and 0.38-0.52 macro F1). Combining voice and text-based models\nyielded increased performance, suggesting that they capture complementary\ndiagnostic information.\n  Our results indicate that models trained on binary classification may learn\nto rely on markers of generic differences between clinical and non-clinical\npopulations, or markers of clinical features that overlap across conditions,\nrather than identifying markers specific to individual conditions. We provide\nrecommendations for future research in the field, suggesting increased focus on\ndeveloping larger transdiagnostic datasets that include more fine-grained\nclinical features, and that can support the development of models that better\ncapture the complexity of neuropsychiatric conditions and naturalistic\ndiagnostic assessment.", "published": "2023-01-13 08:24:21", "link": "http://arxiv.org/abs/2301.06916v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "stat.AP"], "primary_category": "cs.CL"}
