{"title": "Combine Convolution with Recurrent Networks for Text Classification", "abstract": "Convolutional neural network (CNN) and recurrent neural network (RNN) are two\npopular architectures used in text classification. Traditional methods to\ncombine the strengths of the two networks rely on streamlining them or\nconcatenating features extracted from them. In this paper, we propose a novel\nmethod to keep the strengths of the two networks to a great extent. In the\nproposed model, a convolutional neural network is applied to learn a 2D weight\nmatrix where each row reflects the importance of each word from different\naspects. Meanwhile, we use a bi-directional RNN to process each word and employ\na neural tensor layer that fuses forward and backward hidden states to get word\nrepresentations. In the end, the weight matrix and word representations are\ncombined to obtain the representation in a 2D matrix form for the text. We\ncarry out experiments on a number of datasets for text classification. The\nexperimental results confirm the effectiveness of the proposed method.", "published": "2020-06-29 03:36:04", "link": "http://arxiv.org/abs/2006.15795v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Framework for Pre-processing of Social Media Feeds based on Integrated\n  Local Knowledge Base", "abstract": "Most of the previous studies on the semantic analysis of social media feeds\nhave not considered the issue of ambiguity that is associated with slangs,\nabbreviations, and acronyms that are embedded in social media posts. These\nnoisy terms have implicit meanings and form part of the rich semantic context\nthat must be analysed to gain complete insights from social media feeds. This\npaper proposes an improved framework for pre-processing of social media feeds\nfor better performance. To do this, the use of an integrated knowledge base\n(ikb) which comprises a local knowledge source (Naijalingo), urban dictionary\nand internet slang was combined with the adapted Lesk algorithm to facilitate\nsemantic analysis of social media feeds. Experimental results showed that the\nproposed approach performed better than existing methods when it was tested on\nthree machine learning models, which are support vector machines, multilayer\nperceptron, and convolutional neural networks. The framework had an accuracy of\n94.07% on a standardized dataset, and 99.78% on localised dataset when used to\nextract sentiments from tweets. The improved performance on the localised\ndataset reveals the advantage of integrating the use of local knowledge sources\ninto the process of analysing social media feeds particularly in interpreting\nslangs/acronyms/abbreviations that have contextually rooted meanings.", "published": "2020-06-29 07:56:22", "link": "http://arxiv.org/abs/2006.15854v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hinting Semantic Parsing with Statistical Word Sense Disambiguation", "abstract": "The task of Semantic Parsing can be approximated as a transformation of an\nutterance into a logical form graph where edges represent semantic roles and\nnodes represent word senses. The resulting representation should be capture the\nmeaning of the utterance and be suitable for reasoning. Word senses and\nsemantic roles are interdependent, meaning errors in assigning word senses can\ncause errors in assigning semantic roles and vice versa. While statistical\napproaches to word sense disambiguation outperform logical, rule-based semantic\nparsers for raw word sense assignment, these statistical word sense\ndisambiguation systems do not produce the rich role structure or detailed\nsemantic representation of the input. In this work, we provide hints from a\nstatistical WSD system to guide a logical semantic parser to produce better\nsemantic type assignments while maintaining the soundness of the resulting\nlogical forms. We observe an improvement of up to 10.5% in F-score, however we\nfind that this improvement comes at a cost to the structural integrity of the\nparse", "published": "2020-06-29 11:20:13", "link": "http://arxiv.org/abs/2006.15942v2", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Improving Sequence Tagging for Vietnamese Text Using Transformer-based\n  Neural Models", "abstract": "This paper describes our study on using mutilingual BERT embeddings and some\nnew neural models for improving sequence tagging tasks for the Vietnamese\nlanguage. We propose new model architectures and evaluate them extensively on\ntwo named entity recognition datasets of VLSP 2016 and VLSP 2018, and on two\npart-of-speech tagging datasets of VLSP 2010 and VLSP 2013. Our proposed models\noutperform existing methods and achieve new state-of-the-art results. In\nparticular, we have pushed the accuracy of part-of-speech tagging to 95.40% on\nthe VLSP 2010 corpus, to 96.77% on the VLSP 2013 corpus; and the F1 score of\nnamed entity recognition to 94.07% on the VLSP 2016 corpus, to 90.31% on the\nVLSP 2018 corpus. Our code and pre-trained models viBERT and vELECTRA are\nreleased as open source to facilitate adoption and further research.", "published": "2020-06-29 12:39:44", "link": "http://arxiv.org/abs/2006.15994v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Measuring Memorization Effect in Word-Level Neural Networks Probing", "abstract": "Multiple studies have probed representations emerging in neural networks\ntrained for end-to-end NLP tasks and examined what word-level linguistic\ninformation may be encoded in the representations. In classical probing, a\nclassifier is trained on the representations to extract the target linguistic\ninformation. However, there is a threat of the classifier simply memorizing the\nlinguistic labels for individual words, instead of extracting the linguistic\nabstractions from the representations, thus reporting false positive results.\nWhile considerable efforts have been made to minimize the memorization problem,\nthe task of actually measuring the amount of memorization happening in the\nclassifier has been understudied so far. In our work, we propose a simple\ngeneral method for measuring the memorization effect, based on a symmetric\nselection of comparable sets of test words seen versus unseen in training. Our\nmethod can be used to explicitly quantify the amount of memorization happening\nin a probing setup, so that an adequate setup can be chosen and the results of\nthe probing can be interpreted with a reliability estimate. We exemplify this\nby showcasing our method on a case study of probing for part of speech in a\ntrained neural machine translation encoder.", "published": "2020-06-29 14:35:42", "link": "http://arxiv.org/abs/2006.16082v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Want to Identify, Extract and Normalize Adverse Drug Reactions in\n  Tweets? Use RoBERTa", "abstract": "This paper presents our approach for task 2 and task 3 of Social Media Mining\nfor Health (SMM4H) 2020 shared tasks. In task 2, we have to differentiate\nadverse drug reaction (ADR) tweets from nonADR tweets and is treated as binary\nclassification. Task3 involves extracting ADR mentions and then mapping them to\nMedDRA codes. Extracting ADR mentions is treated as sequence labeling and\nnormalizing ADR mentions is treated as multi-class classification. Our system\nis based on pre-trained language model RoBERTa and it achieves a) F1-score of\n58% in task2 which is 12% more than the average score b) relaxed F1-score of\n70.1% in ADR extraction of task 3 which is 13.7% more than the average score\nand relaxed F1-score of 35% in ADR extraction + normalization of task3 which is\n5.8% more than the average score. Overall, our models achieve promising results\nin both the tasks with significant improvements over average scores.", "published": "2020-06-29 16:10:27", "link": "http://arxiv.org/abs/2006.16146v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards the Study of Morphological Processing of the Tangkhul Language", "abstract": "There is no or little work on natural language processing of Tangkhul\nlanguage. The current work is a humble beginning of morphological processing of\nthis language using an unsupervised approach. We use a small corpus collected\nfrom different sources of text books, short stories and articles of other\ntopics. Based on the experiments carried out, the morpheme identification task\nusing morphessor gives reasonable and interesting output despite using a small\ncorpus.", "published": "2020-06-29 17:24:09", "link": "http://arxiv.org/abs/2006.16212v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ANA at SemEval-2020 Task 4: mUlti-task learNIng for cOmmonsense\n  reasoNing (UNION)", "abstract": "In this paper, we describe our mUlti-task learNIng for cOmmonsense reasoNing\n(UNION) system submitted for Task C of the SemEval2020 Task 4, which is to\ngenerate a reason explaining why a given false statement is non-sensical.\nHowever, we found in the early experiments that simple adaptations such as\nfine-tuning GPT2 often yield dull and non-informative generations (e.g. simple\nnegations). In order to generate more meaningful explanations, we propose\nUNION, a unified end-to-end framework, to utilize several existing commonsense\ndatasets so that it allows a model to learn more dynamics under the scope of\ncommonsense reasoning. In order to perform model selection efficiently,\naccurately and promptly, we also propose a couple of auxiliary automatic\nevaluation metrics so that we can extensively compare the models from different\nperspectives. Our submitted system not only results in a good performance in\nthe proposed metrics but also outperforms its competitors with the highest\nachieved score of 2.10 for human evaluation while remaining a BLEU score of\n15.7. Our code is made publicly available at GitHub.", "published": "2020-06-29 21:44:51", "link": "http://arxiv.org/abs/2006.16403v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Is Japanese gendered language used on Twitter ? A large scale study", "abstract": "This study analyzes the usage of Japanese gendered language on Twitter.\nStarting from a collection of 408 million Japanese tweets from 2015 till 2019\nand an additional sample of 2355 manually classified Twitter accounts timelines\ninto gender and categories (politicians, musicians, etc). A large scale textual\nanalysis is performed on this corpus to identify and examine sentence-final\nparticles (SFPs) and first-person pronouns appearing in the texts. It turns out\nthat gendered language is in fact used also on Twitter, in about 6% of the\ntweets, and that the prescriptive classification into \"male\" and \"female\"\nlanguage does not always meet the expectations, with remarkable exceptions.\nFurther, SFPs and pronouns show increasing or decreasing trends, indicating an\nevolution of the language used on Twitter.", "published": "2020-06-29 11:07:10", "link": "http://arxiv.org/abs/2006.15935v2", "categories": ["cs.CL", "stat.AP"], "primary_category": "cs.CL"}
{"title": "Leveraging Subword Embeddings for Multinational Address Parsing", "abstract": "Address parsing consists of identifying the segments that make up an address\nsuch as a street name or a postal code. Because of its importance for tasks\nlike record linkage, address parsing has been approached with many techniques.\nNeural network methods defined a new state-of-the-art for address parsing.\nWhile this approach yielded notable results, previous work has only focused on\napplying neural networks to achieve address parsing of addresses from one\nsource country. We propose an approach in which we employ subword embeddings\nand a Recurrent Neural Network architecture to build a single model capable of\nlearning to parse addresses from multiple countries at the same time while\ntaking into account the difference in languages and address formatting systems.\nWe achieved accuracies around 99 % on the countries used for training with no\npre-processing nor post-processing needed. We explore the possibility of\ntransferring the address parsing knowledge obtained by training on some\ncountries' addresses to others with no further training in a zero-shot transfer\nlearning setting. We achieve good results for 80 % of the countries (33 out of\n41), almost 50 % of which (20 out of 41) is near state-of-the-art performance.\nIn addition, we propose an open-source Python implementation of our trained\nmodels.", "published": "2020-06-29 16:14:27", "link": "http://arxiv.org/abs/2006.16152v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multichannel CNN with Attention for Text Classification", "abstract": "Recent years, the approaches based on neural networks have shown remarkable\npotential for sentence modeling. There are two main neural network structures:\nrecurrent neural network (RNN) and convolution neural network (CNN). RNN can\ncapture long term dependencies and store the semantics of the previous\ninformation in a fixed-sized vector. However, RNN is a biased model and its\nability to extract global semantics is restricted by the fixed-sized vector.\nAlternatively, CNN is able to capture n-gram features of texts by utilizing\nconvolutional filters. But the width of convolutional filters restricts its\nperformance. In order to combine the strengths of the two kinds of networks and\nalleviate their shortcomings, this paper proposes Attention-based Multichannel\nConvolutional Neural Network (AMCNN) for text classification. AMCNN utilizes a\nbi-directional long short-term memory to encode the history and future\ninformation of words into high dimensional representations, so that the\ninformation of both the front and back of the sentence can be fully expressed.\nThen the scalar attention and vectorial attention are applied to obtain\nmultichannel representations. The scalar attention can calculate the word-level\nimportance and the vectorial attention can calculate the feature-level\nimportance. In the classification task, AMCNN uses a CNN structure to cpture\nword relations on the representations generated by the scalar and vectorial\nattention mechanism instead of calculating the weighted sums. It can\neffectively extract the n-gram features of the text. The experimental results\non the benchmark datasets demonstrate that AMCNN achieves better performance\nthan state-of-the-art methods. In addition, the visualization results verify\nthe semantic richness of multichannel representations.", "published": "2020-06-29 16:37:51", "link": "http://arxiv.org/abs/2006.16174v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Universal linguistic inductive biases via meta-learning", "abstract": "How do learners acquire languages from the limited data available to them?\nThis process must involve some inductive biases - factors that affect how a\nlearner generalizes - but it is unclear which inductive biases can explain\nobserved patterns in language acquisition. To facilitate computational modeling\naimed at addressing this question, we introduce a framework for giving\nparticular linguistic inductive biases to a neural network model; such a model\ncan then be used to empirically explore the effects of those inductive biases.\nThis framework disentangles universal inductive biases, which are encoded in\nthe initial values of a neural network's parameters, from non-universal\nfactors, which the neural network must learn from data in a given language. The\ninitial state that encodes the inductive biases is found with meta-learning, a\ntechnique through which a model discovers how to acquire new languages more\neasily via exposure to many possible languages. By controlling the properties\nof the languages that are used during meta-learning, we can control the\ninductive biases that meta-learning imparts. We demonstrate this framework with\na case study based on syllable structure. First, we specify the inductive\nbiases that we intend to give our model, and then we translate those inductive\nbiases into a space of languages from which a model can meta-learn. Finally,\nusing existing analysis techniques, we verify that our approach has imparted\nthe linguistic inductive biases that it was intended to impart.", "published": "2020-06-29 19:15:10", "link": "http://arxiv.org/abs/2006.16324v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning Sparse Prototypes for Text Generation", "abstract": "Prototype-driven text generation uses non-parametric models that first choose\nfrom a library of sentence \"prototypes\" and then modify the prototype to\ngenerate the output text. While effective, these methods are inefficient at\ntest time as a result of needing to store and index the entire training corpus.\nFurther, existing methods often require heuristics to identify which prototypes\nto reference at training time. In this paper, we propose a novel generative\nmodel that automatically learns a sparse prototype support set that,\nnonetheless, achieves strong language modeling performance. This is achieved by\n(1) imposing a sparsity-inducing prior on the prototype selection distribution,\nand (2) utilizing amortized variational inference to learn a prototype\nretrieval function. In experiments, our model outperforms previous\nprototype-driven language models while achieving up to a 1000x memory\nreduction, as well as a 1000x speed-up at test time. More interestingly, we\nshow that the learned prototypes are able to capture semantics and syntax at\ndifferent granularity as we vary the sparsity of prototype selection, and that\ncertain sentence attributes can be controlled by specifying the prototype for\ngeneration.", "published": "2020-06-29 19:41:26", "link": "http://arxiv.org/abs/2006.16336v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Reading Between the Demographic Lines: Resolving Sources of Bias in\n  Toxicity Classifiers", "abstract": "The censorship of toxic comments is often left to the judgment of imperfect\nmodels. Perspective API, a creation of Google technology incubator Jigsaw, is\nperhaps the most widely used toxicity classifier in industry; the model is\nemployed by several online communities including The New York Times to identify\nand filter out toxic comments with the goal of preserving online safety.\nUnfortunately, Google's model tends to unfairly assign higher toxicity scores\nto comments containing words referring to the identities of commonly targeted\ngroups (e.g., \"woman,'' \"gay,'' etc.) because these identities are frequently\nreferenced in a disrespectful manner in the training data. As a result,\ncomments generated by marginalized groups referencing their identities are\noften mistakenly censored. It is important to be cognizant of this unintended\nbias and strive to mitigate its effects. To address this issue, we have\nconstructed several toxicity classifiers with the intention of reducing\nunintended bias while maintaining strong classification performance.", "published": "2020-06-29 21:40:55", "link": "http://arxiv.org/abs/2006.16402v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Building Interpretable Interaction Trees for Deep NLP Models", "abstract": "This paper proposes a method to disentangle and quantify interactions among\nwords that are encoded inside a DNN for natural language processing. We\nconstruct a tree to encode salient interactions extracted by the DNN. Six\nmetrics are proposed to analyze properties of interactions between constituents\nin a sentence. The interaction is defined based on Shapley values of words,\nwhich are considered as an unbiased estimation of word contributions to the\nnetwork prediction. Our method is used to quantify word interactions encoded\ninside the BERT, ELMo, LSTM, CNN, and Transformer networks. Experimental\nresults have provided a new perspective to understand these DNNs, and have\ndemonstrated the effectiveness of our method.", "published": "2020-06-29 10:26:50", "link": "http://arxiv.org/abs/2007.04298v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Answering Questions on COVID-19 in Real-Time", "abstract": "The recent outbreak of the novel coronavirus is wreaking havoc on the world\nand researchers are struggling to effectively combat it. One reason why the\nfight is difficult is due to the lack of information and knowledge. In this\nwork, we outline our effort to contribute to shrinking this knowledge vacuum by\ncreating covidAsk, a question answering (QA) system that combines biomedical\ntext mining and QA techniques to provide answers to questions in real-time. Our\nsystem also leverages information retrieval (IR) approaches to provide\nentity-level answers that are complementary to QA models. Evaluation of\ncovidAsk is carried out by using a manually created dataset called COVID-19\nQuestions which is based on information from various sources, including the CDC\nand the WHO. We hope our system will be able to aid researchers in their search\nfor knowledge and information not only for COVID-19, but for future pandemics\nas well.", "published": "2020-06-29 06:34:35", "link": "http://arxiv.org/abs/2006.15830v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Data augmentation versus noise compensation for x- vector speaker\n  recognition systems in noisy environments", "abstract": "The explosion of available speech data and new speaker modeling methods based\non deep neural networks (DNN) have given the ability to develop more robust\nspeaker recognition systems. Among DNN speaker modelling techniques, x-vector\nsystem has shown a degree of robustness in noisy environments. Previous studies\nsuggest that by increasing the number of speakers in the training data and\nusing data augmentation more robust speaker recognition systems are achievable\nin noisy environments. In this work, we want to know if explicit noise\ncompensation techniques continue to be effective despite the general noise\nrobustness of these systems. For this study, we will use two different x-vector\nnetworks: the first one is trained on Voxceleb1 (Protocol1), and the second one\nis trained on Voxceleb1+Voxveleb2 (Protocol2). We propose to add a denoising\nx-vector subsystem before scoring. Experimental results show that, the x-vector\nsystem used in Protocol2 is more robust than the other one used Protocol1.\nDespite this observation we will show that explicit noise compensation gives\nalmost the same EER relative gain in both protocols. For example, in the\nProtocol2 we have 21% to 66% improvement of EER with denoising techniques.", "published": "2020-06-29 09:50:45", "link": "http://arxiv.org/abs/2006.15903v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Transformer-based joint-encoding for Emotion Recognition and Sentiment\n  Analysis", "abstract": "Understanding expressed sentiment and emotions are two crucial factors in\nhuman multimodal language. This paper describes a Transformer-based\njoint-encoding (TBJE) for the task of Emotion Recognition and Sentiment\nAnalysis. In addition to use the Transformer architecture, our approach relies\non a modular co-attention and a glimpse layer to jointly encode one or more\nmodalities. The proposed solution has also been submitted to the ACL20: Second\nGrand-Challenge on Multimodal Language to be evaluated on the CMU-MOSEI\ndataset. The code to replicate the presented experiments is open-source:\nhttps://github.com/jbdel/MOSEI_UMONS.", "published": "2020-06-29 11:51:46", "link": "http://arxiv.org/abs/2006.15955v1", "categories": ["cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Natural Backdoor Attack on Text Data", "abstract": "Recently, advanced NLP models have seen a surge in the usage of various\napplications. This raises the security threats of the released models. In\naddition to the clean models' unintentional weaknesses, {\\em i.e.,} adversarial\nattacks, the poisoned models with malicious intentions are much more dangerous\nin real life. However, most existing works currently focus on the adversarial\nattacks on NLP models instead of positioning attacks, also named\n\\textit{backdoor attacks}. In this paper, we first propose the \\textit{natural\nbackdoor attacks} on NLP models. Moreover, we exploit the various attack\nstrategies to generate trigger on text data and investigate different types of\ntriggers based on modification scope, human recognition, and special cases.\nLast, we evaluate the backdoor attacks, and the results show the excellent\nperformance of with 100\\% backdoor attacks success rate and sacrificing of\n0.83\\% on the text classification task.", "published": "2020-06-29 16:40:14", "link": "http://arxiv.org/abs/2006.16176v4", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multi-Head Attention: Collaborate Instead of Concatenate", "abstract": "Attention layers are widely used in natural language processing (NLP) and are\nbeginning to influence computer vision architectures. Training very large\ntransformer models allowed significant improvement in both fields, but once\ntrained, these networks show symptoms of over-parameterization. For instance,\nit is known that many attention heads can be pruned without impacting accuracy.\nThis work aims to enhance current understanding on how multiple heads interact.\nMotivated by the observation that attention heads learn redundant key/query\nprojections, we propose a collaborative multi-head attention layer that enables\nheads to learn shared projections. Our scheme decreases the number of\nparameters in an attention layer and can be used as a drop-in replacement in\nany transformer architecture. Our experiments confirm that sharing key/query\ndimensions can be exploited in language understanding, machine translation and\nvision. We also show that it is possible to re-parametrize a pre-trained\nmulti-head attention layer into our collaborative attention layer.\nCollaborative multi-head attention reduces the size of the key and query\nprojections by 4 for same accuracy and speed. Our code is public.", "published": "2020-06-29 20:28:52", "link": "http://arxiv.org/abs/2006.16362v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Multi-Partition Embedding Interaction with Block Term Format for\n  Knowledge Graph Completion", "abstract": "Knowledge graph completion is an important task that aims to predict the\nmissing relational link between entities. Knowledge graph embedding methods\nperform this task by representing entities and relations as embedding vectors\nand modeling their interactions to compute the matching score of each triple.\nPrevious work has usually treated each embedding as a whole and has modeled the\ninteractions between these whole embeddings, potentially making the model\nexcessively expensive or requiring specially designed interaction mechanisms.\nIn this work, we propose the multi-partition embedding interaction (MEI) model\nwith block term format to systematically address this problem. MEI divides each\nembedding into a multi-partition vector to efficiently restrict the\ninteractions. Each local interaction is modeled with the Tucker tensor format\nand the full interaction is modeled with the block term tensor format, enabling\nMEI to control the trade-off between expressiveness and computational cost,\nlearn the interaction mechanisms from data automatically, and achieve\nstate-of-the-art performance on the link prediction task. In addition, we\ntheoretically study the parameter efficiency problem and derive a simple\nempirically verified criterion for optimal parameter trade-off. We also apply\nthe framework of MEI to provide a new generalized explanation for several\nspecially designed interaction mechanisms in previous models. The source code\nis released at https://github.com/tranhungnghiep/MEI-KGE.", "published": "2020-06-29 20:37:11", "link": "http://arxiv.org/abs/2006.16365v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Classification of cancer pathology reports: a large-scale comparative\n  study", "abstract": "We report about the application of state-of-the-art deep learning techniques\nto the automatic and interpretable assignment of ICD-O3 topography and\nmorphology codes to free-text cancer reports. We present results on a large\ndataset (more than 80 000 labeled and 1 500 000 unlabeled anonymized reports\nwritten in Italian and collected from hospitals in Tuscany over more than a\ndecade) and with a large number of classes (134 morphological classes and 61\ntopographical classes). We compare alternative architectures in terms of\nprediction accuracy and interpretability and show that our best model achieves\na multiclass accuracy of 90.3% on topography site assignment and 84.8% on\nmorphology type assignment. We found that in this context hierarchical models\nare not better than flat models and that an element-wise maximum aggregator is\nslightly better than attentive models on site classification. Moreover, the\nmaximum aggregator offers a way to interpret the classification process.", "published": "2020-06-29 20:47:33", "link": "http://arxiv.org/abs/2006.16370v1", "categories": ["cs.LG", "cs.CL", "eess.IV", "stat.ML", "I.2.6; I.2.7; J.3"], "primary_category": "cs.LG"}
{"title": "An EM Approach to Non-autoregressive Conditional Sequence Generation", "abstract": "Autoregressive (AR) models have been the dominating approach to conditional\nsequence generation, but are suffering from the issue of high inference\nlatency. Non-autoregressive (NAR) models have been recently proposed to reduce\nthe latency by generating all output tokens in parallel but could only achieve\ninferior accuracy compared to their autoregressive counterparts, primarily due\nto a difficulty in dealing with the multi-modality in sequence generation. This\npaper proposes a new approach that jointly optimizes both AR and NAR models in\na unified Expectation-Maximization (EM) framework. In the E-step, an AR model\nlearns to approximate the regularized posterior of the NAR model. In the\nM-step, the NAR model is updated on the new posterior and selects the training\nexamples for the next AR model. This iterative process can effectively guide\nthe system to remove the multi-modality in the output sequences. To our\nknowledge, this is the first EM approach to NAR sequence generation. We\nevaluate our method on the task of machine translation. Experimental results on\nbenchmark data sets show that the proposed approach achieves competitive, if\nnot better, performance with existing NAR models and significantly reduces the\ninference latency.", "published": "2020-06-29 20:58:57", "link": "http://arxiv.org/abs/2006.16378v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Knowledge-Aware Language Model Pretraining", "abstract": "How much knowledge do pretrained language models hold? Recent research\nobserved that pretrained transformers are adept at modeling semantics but it is\nunclear to what degree they grasp human knowledge, or how to ensure they do so.\nIn this paper we incorporate knowledge-awareness in language model pretraining\nwithout changing the transformer architecture, inserting explicit knowledge\nlayers, or adding external storage of semantic information. Rather, we simply\nsignal the existence of entities to the input of the transformer in\npretraining, with an entity-extended tokenizer; and at the output, with an\nadditional entity prediction task. Our experiments show that solely by adding\nthese entity signals in pretraining, significantly more knowledge is packed\ninto the transformer parameters: we observe improved language modeling\naccuracy, factual correctness in LAMA knowledge probing tasks, and semantics in\nthe hidden representations through edge probing.We also show that our\nknowledge-aware language model (KALM) can serve as a drop-in replacement for\nGPT-2 models, significantly improving downstream tasks like zero-shot\nquestion-answering with no task-related training.", "published": "2020-06-29 06:09:59", "link": "http://arxiv.org/abs/2007.00655v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Prosodic Prominence and Boundaries in Sequence-to-Sequence Speech\n  Synthesis", "abstract": "Recent advances in deep learning methods have elevated synthetic speech\nquality to human level, and the field is now moving towards addressing prosodic\nvariation in synthetic speech.Despite successes in this effort, the\nstate-of-the-art systems fall short of faithfully reproducing local prosodic\nevents that give rise to, e.g., word-level emphasis and phrasal structure. This\ntype of prosodic variation often reflects long-distance semantic relationships\nthat are not accessible for end-to-end systems with a single sentence as their\nsynthesis domain. One of the possible solutions might be conditioning the\nsynthesized speech by explicit prosodic labels, potentially generated using\nlonger portions of text. In this work we evaluate whether augmenting the\ntextual input with such prosodic labels capturing word-level prominence and\nphrasal boundary strength can result in more accurate realization of sentence\nprosody. We use an automatic wavelet-based technique to extract such labels\nfrom speech material, and use them as an input to a tacotron-like synthesis\nsystem alongside textual information. The results of objective evaluation of\nsynthesized speech show that using the prosodic labels significantly improves\nthe output in terms of faithfulness of f0 and energy contours, in comparison\nwith state-of-the-art implementations.", "published": "2020-06-29 12:09:21", "link": "http://arxiv.org/abs/2006.15967v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Ultra2Speech -- A Deep Learning Framework for Formant Frequency\n  Estimation and Tracking from Ultrasound Tongue Images", "abstract": "Thousands of individuals need surgical removal of their larynx due to\ncritical diseases every year and therefore, require an alternative form of\ncommunication to articulate speech sounds after the loss of their voice box.\nThis work addresses the articulatory-to-acoustic mapping problem based on\nultrasound (US) tongue images for the development of a silent-speech interface\n(SSI) that can provide them with an assistance in their daily interactions. Our\napproach targets automatically extracting tongue movement information by\nselecting an optimal feature set from US images and mapping these features to\nthe acoustic space. We use a novel deep learning architecture to map US tongue\nimages from the US probe placed beneath a subject's chin to formants that we\ncall, Ultrasound2Formant (U2F) Net. It uses hybrid spatio-temporal 3D\nconvolutions followed by feature shuffling, for the estimation and tracking of\nvowel formants from US images. The formant values are then utilized to\nsynthesize continuous time-varying vowel trajectories, via Klatt Synthesizer.\nOur best model achieves R-squared (R^2) measure of 99.96% for the regression\ntask. Our network lays the foundation for an SSI as it successfully tracks the\ntongue contour automatically as an internal representation without any explicit\nannotation.", "published": "2020-06-29 20:42:11", "link": "http://arxiv.org/abs/2006.16367v1", "categories": ["eess.IV", "cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "eess.IV"}
