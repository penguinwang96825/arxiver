{"title": "EmotionGIF-Yankee: A Sentiment Classifier with Robust Model Based\n  Ensemble Methods", "abstract": "This paper provides a method to classify sentiment with robust model based\nensemble methods. We preprocess tweet data to enhance coverage of tokenizer. To\nreduce domain bias, we first train tweet dataset for pre-trained language\nmodel. Besides, each classifier has its strengths and weakness, we leverage\ndifferent types of models with ensemble methods: average and power weighted\nsum. From the experiments, we show that our approach has achieved positive\neffect for sentiment classification. Our system reached third place among 26\nteams from the evaluation in SocialNLP 2020 EmotionGIF competition.", "published": "2020-07-05 07:48:51", "link": "http://arxiv.org/abs/2007.02259v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CORD19STS: COVID-19 Semantic Textual Similarity Dataset", "abstract": "In order to combat the COVID-19 pandemic, society can benefit from various\nnatural language processing applications, such as dialog medical diagnosis\nsystems and information retrieval engines calibrated specifically for COVID-19.\nThese applications rely on the ability to measure semantic textual similarity\n(STS), making STS a fundamental task that can benefit several downstream\napplications. However, existing STS datasets and models fail to translate their\nperformance to a domain-specific environment such as COVID-19. To overcome this\ngap, we introduce CORD19STS dataset which includes 13,710 annotated sentence\npairs collected from COVID-19 open research dataset (CORD-19) challenge. To be\nspecific, we generated one million sentence pairs using different sampling\nstrategies. We then used a finetuned BERT-like language model, which we call\nSen-SCI-CORD19-BERT, to calculate the similarity scores between sentence pairs\nto provide a balanced dataset with respect to the different semantic similarity\nlevels, which gives us a total of 32K sentence pairs. Each sentence pair was\nannotated by five Amazon Mechanical Turk (AMT) crowd workers, where the labels\nrepresent different semantic similarity levels between the sentence pairs (i.e.\nrelated, somewhat-related, and not-related). After employing a rigorous\nqualification tasks to verify collected annotations, our final CORD19STS\ndataset includes 13,710 sentence pairs.", "published": "2020-07-05 22:23:37", "link": "http://arxiv.org/abs/2007.02461v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tweets Sentiment Analysis via Word Embeddings and Machine Learning\n  Techniques", "abstract": "Sentiment analysis of social media data consists of attitudes, assessments,\nand emotions which can be considered a way human think. Understanding and\nclassifying the large collection of documents into positive and negative\naspects are a very difficult task. Social networks such as Twitter, Facebook,\nand Instagram provide a platform in order to gather information about peoples\nsentiments and opinions. Considering the fact that people spend hours daily on\nsocial media and share their opinion on various different topics helps us\nanalyze sentiments better. More and more companies are using social media tools\nto provide various services and interact with customers. Sentiment Analysis\n(SA) classifies the polarity of given tweets to positive and negative tweets in\norder to understand the sentiments of the public. This paper aims to perform\nsentiment analysis of real-time 2019 election twitter data using the feature\nselection model word2vec and the machine learning algorithm random forest for\nsentiment classification. Word2vec with Random Forest improves the accuracy of\nsentiment analysis significantly compared to traditional methods such as BOW\nand TF-IDF. Word2vec improves the quality of features by considering contextual\nsemantics of words in a text hence improving the accuracy of machine learning\nand sentiment analysis.", "published": "2020-07-05 08:10:30", "link": "http://arxiv.org/abs/2007.04303v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Proving Non-Inclusion of B\u00fcchi Automata based on Monte Carlo Sampling", "abstract": "The search for a proof of correctness and the search for counterexamples\n(bugs) are complementary aspects of verification. In order to maximize the\npractical use of verification tools it is better to pursue them at the same\ntime. While this is well-understood in the termination analysis of programs,\nthis is not the case for the language inclusion analysis of B\\\"uchi automata,\nwhere research mainly focused on improving algorithms for proving language\ninclusion, with the search for counterexamples left to the expensive\ncomplementation operation.\n  In this paper, we present $\\mathsf{IMC}^2$, a specific algorithm for proving\nB\\\"uchi automata non-inclusion $\\mathcal{L}(\\mathcal{A}) \\not\\subseteq\n\\mathcal{L}(\\mathcal{B})$, based on Grosu and Smolka's algorithm\n$\\mathsf{MC}^2$ developed for Monte Carlo model checking against LTL formulas.\nThe algorithm we propose takes $M = \\lceil \\ln \\delta / \\ln (1-\\epsilon)\n\\rceil$ random lasso-shaped samples from $\\mathcal{A}$ to decide whether to\nreject the hypothesis $\\mathcal{L}(\\mathcal{A}) \\not\\subseteq\n\\mathcal{L}(\\mathcal{B})$, for given error probability $\\epsilon$ and\nconfidence level $1 - \\delta$. With such a number of samples, $\\mathsf{IMC}^2$\nensures that the probability of witnessing $\\mathcal{L}(\\mathcal{A})\n\\not\\subseteq \\mathcal{L}(\\mathcal{B})$ via further sampling is less than\n$\\delta$, under the assumption that the probability of finding a lasso\ncounterexample is larger than $\\epsilon$. Extensive experimental evaluation\nshows that $\\mathsf{IMC}^2$ is a fast and reliable way to find counterexamples\nto B\\\"uchi automata inclusion.", "published": "2020-07-05 10:17:02", "link": "http://arxiv.org/abs/2007.02282v2", "categories": ["cs.FL", "cs.CL"], "primary_category": "cs.FL"}
{"title": "Improving Chinese Segmentation-free Word Embedding With Unsupervised\n  Association Measure", "abstract": "Recent work on segmentation-free word embedding(sembei) developed a new\npipeline of word embedding for unsegmentated language while avoiding\nsegmentation as a preprocessing step. However, too many noisy n-grams existing\nin the embedding vocabulary that do not have strong association strength\nbetween characters would limit the quality of learned word embedding. To deal\nwith this problem, a new version of segmentation-free word embedding model is\nproposed by collecting n-grams vocabulary via a novel unsupervised association\nmeasure called pointwise association with times information(PATI). Comparing\nwith the commonly used n-gram filtering method like frequency used in sembei\nand pointwise mutual information(PMI), the proposed method leverages more\nlatent information from the corpus and thus is able to collect more valid\nn-grams that have stronger cohesion as embedding targets in unsegmented\nlanguage data, such as Chinese texts. Further experiments on Chinese SNS data\nshow that the proposed model improves performance of word embedding in\ndownstream tasks.", "published": "2020-07-05 13:55:19", "link": "http://arxiv.org/abs/2007.02342v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Starfish: A Prototype for Universal Preprocessing and Text-Embedded\n  Programming", "abstract": "We present a novel concept of universal text preprocessing and text-embedded\nprogramming (PTEP). Preprocessing and text-embedded programming has been widely\nused in programming languages and frameworks in a fragmented and mutually\nisolated way. The PTEP ideas can be found in the implementation of the \\TeX\\\ntypesetting system; they are prominent in PHP and similar web languages, and\nfinally they are used in the Jupyter data science framework. This paper\npresents this area of research and related work in a more unified framework,\nand we describe the implemented system Starfish that satisfies the following\nnovel principles of PTEP: universality, update and replace modes, flexiblity,\nconfigurability, and transparency. We describe the operating model and design\nof Starfish, which is an open-source system implementing universal\npreprocessing and text-embedded programming in Perl. The system is transparent\nand its design allows direct implementation in other programming languages as\nwell.", "published": "2020-07-05 15:37:44", "link": "http://arxiv.org/abs/2007.02366v1", "categories": ["cs.PL", "cs.CL", "D.3.4; I.7.1; I.7.2; I.2.7; I.2.2"], "primary_category": "cs.PL"}
{"title": "Auto-captions on GIF: A Large-scale Video-sentence Dataset for\n  Vision-language Pre-training", "abstract": "In this work, we present Auto-captions on GIF, which is a new large-scale\npre-training dataset for generic video understanding. All video-sentence pairs\nare created by automatically extracting and filtering video caption annotations\nfrom billions of web pages. Auto-captions on GIF dataset can be utilized to\npre-train the generic feature representation or encoder-decoder structure for\nvideo captioning, and other downstream tasks (e.g., sentence localization in\nvideos, video question answering, etc.) as well. We present a detailed analysis\nof Auto-captions on GIF dataset in comparison to existing video-sentence\ndatasets. We also provide an evaluation of a Transformer-based encoder-decoder\nstructure for vision-language pre-training, which is further adapted to video\ncaptioning downstream task and yields the compelling generalizability on\nMSR-VTT. The dataset is available at\n\\url{http://www.auto-video-captions.top/2020/dataset}.", "published": "2020-07-05 16:11:57", "link": "http://arxiv.org/abs/2007.02375v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "You Autocomplete Me: Poisoning Vulnerabilities in Neural Code Completion", "abstract": "Code autocompletion is an integral feature of modern code editors and IDEs.\nThe latest generation of autocompleters uses neural language models, trained on\npublic open-source code repositories, to suggest likely (not just statically\nfeasible) completions given the current context.\n  We demonstrate that neural code autocompleters are vulnerable to poisoning\nattacks. By adding a few specially-crafted files to the autocompleter's\ntraining corpus (data poisoning), or else by directly fine-tuning the\nautocompleter on these files (model poisoning), the attacker can influence its\nsuggestions for attacker-chosen contexts. For example, the attacker can \"teach\"\nthe autocompleter to suggest the insecure ECB mode for AES encryption, SSLv3\nfor the SSL/TLS protocol version, or a low iteration count for password-based\nencryption. Moreover, we show that these attacks can be targeted: an\nautocompleter poisoned by a targeted attack is much more likely to suggest the\ninsecure completion for files from a specific repo or specific developer.\n  We quantify the efficacy of targeted and untargeted data- and model-poisoning\nattacks against state-of-the-art autocompleters based on Pythia and GPT-2. We\nthen evaluate existing defenses against poisoning attacks and show that they\nare largely ineffective.", "published": "2020-07-05 01:13:36", "link": "http://arxiv.org/abs/2007.02220v3", "categories": ["cs.CR", "cs.CL", "cs.LG", "cs.PL"], "primary_category": "cs.CR"}
{"title": "Sentiment Analysis on Customer Responses", "abstract": "Sentiment analysis is one of the fastest spreading research areas in computer\nscience, making it challenging to keep track of all the activities in the area.\nWe present a customer feedback reviews on product, where we utilize opinion\nmining, text mining and sentiments, which has affected the surrounded world by\nchanging their opinion on a specific product. Data used in this study are\nonline product reviews collected from Amazon.com. We performed a comparative\nsentiment analysis of retrieved reviews. This research paper provides you with\nsentimental analysis of various smart phone opinions on smart phones dividing\nthem Positive, Negative and Neutral Behaviour.", "published": "2020-07-05 04:50:40", "link": "http://arxiv.org/abs/2007.02237v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "News Sentiment Analysis", "abstract": "Modern technological era has reshaped traditional lifestyle in several\ndomains. The medium of publishing news and events has become faster with the\nadvancement of Information Technology. IT has also been flooded with immense\namounts of data, which is being published every minute of every day, by\nmillions of users, in the shape of comments, blogs, news sharing through blogs,\nsocial media micro-blogging websites and many more. Manual traversal of such\nhuge data is a challenging job, thus, sophisticated methods are acquired to\nperform this task automatically and efficiently. News reports events that\ncomprise of emotions - good, bad, neutral. Sentiment analysis is utilized to\ninvestigate human emotions present in textual information. This paper presents\na lexicon-based approach for sentiment analysis of news articles. The\nexperiments have been performed on BBC news data set, which expresses the\napplicability and validation of the adopted approach.", "published": "2020-07-05 05:15:35", "link": "http://arxiv.org/abs/2007.02238v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unsupervised Paraphrasing via Deep Reinforcement Learning", "abstract": "Paraphrasing is expressing the meaning of an input sentence in different\nwording while maintaining fluency (i.e., grammatical and syntactical\ncorrectness). Most existing work on paraphrasing use supervised models that are\nlimited to specific domains (e.g., image captions). Such models can neither be\nstraightforwardly transferred to other domains nor generalize well, and\ncreating labeled training data for new domains is expensive and laborious. The\nneed for paraphrasing across different domains and the scarcity of labeled\ntraining data in many such domains call for exploring unsupervised paraphrase\ngeneration methods. We propose Progressive Unsupervised Paraphrasing (PUP): a\nnovel unsupervised paraphrase generation method based on deep reinforcement\nlearning (DRL). PUP uses a variational autoencoder (trained using a\nnon-parallel corpus) to generate a seed paraphrase that warm-starts the DRL\nmodel. Then, PUP progressively tunes the seed paraphrase guided by our novel\nreward function which combines semantic adequacy, language fluency, and\nexpression diversity measures to quantify the quality of the generated\nparaphrases in each iteration without needing parallel sentences. Our extensive\nexperimental evaluation shows that PUP outperforms unsupervised\nstate-of-the-art paraphrasing techniques in terms of both automatic metrics and\nuser studies on four real datasets. We also show that PUP outperforms\ndomain-adapted supervised algorithms on several datasets. Our evaluation also\nshows that PUP achieves a great trade-off between semantic similarity and\ndiversity of expression.", "published": "2020-07-05 05:54:02", "link": "http://arxiv.org/abs/2007.02244v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Exploratory Analysis of COVID-19 Related Tweets in North America to\n  Inform Public Health Institutes", "abstract": "Social media is a rich source where we can learn about people's reactions to\nsocial issues. As COVID-19 has significantly impacted on people's lives, it is\nessential to capture how people react to public health interventions and\nunderstand their concerns. In this paper, we aim to investigate people's\nreactions and concerns about COVID-19 in North America, especially focusing on\nCanada. We analyze COVID-19 related tweets using topic modeling and\naspect-based sentiment analysis, and interpret the results with public health\nexperts. We compare timeline of topics discussed with timing of implementation\nof public health interventions for COVID-19. We also examine people's sentiment\nabout COVID-19 related issues. We discuss how the results can be helpful for\npublic health agencies when designing a policy for new interventions. Our work\nshows how Natural Language Processing (NLP) techniques could be applied to\npublic health questions with domain expert involvement.", "published": "2020-07-05 21:38:28", "link": "http://arxiv.org/abs/2007.02452v1", "categories": ["cs.CL", "cs.CY", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Unsupervised Online Grounding of Natural Language during Human-Robot\n  Interactions", "abstract": "Allowing humans to communicate through natural language with robots requires\nconnections between words and percepts. The process of creating these\nconnections is called symbol grounding and has been studied for nearly three\ndecades. Although many studies have been conducted, not many considered\ngrounding of synonyms and the employed algorithms either work only offline or\nin a supervised manner. In this paper, a cross-situational learning based\ngrounding framework is proposed that allows grounding of words and phrases\nthrough corresponding percepts without human supervision and online, i.e. it\ndoes not require any explicit training phase, but instead updates the obtained\nmappings for every new encountered situation. The proposed framework is\nevaluated through an interaction experiment between a human tutor and a robot,\nand compared to an existing unsupervised grounding framework. The results show\nthat the proposed framework is able to ground words through their corresponding\npercepts online and in an unsupervised manner, while outperforming the baseline\nframework.", "published": "2020-07-05 17:48:26", "link": "http://arxiv.org/abs/2007.04304v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.CL"}
