{"title": "Dialogue Learning with Human Teaching and Feedback in End-to-End\n  Trainable Task-Oriented Dialogue Systems", "abstract": "In this work, we present a hybrid learning method for training task-oriented\ndialogue systems through online user interactions. Popular methods for learning\ntask-oriented dialogues include applying reinforcement learning with user\nfeedback on supervised pre-training models. Efficiency of such learning method\nmay suffer from the mismatch of dialogue state distribution between offline\ntraining and online interactive learning stages. To address this challenge, we\npropose a hybrid imitation and reinforcement learning method, with which a\ndialogue agent can effectively learn from its interaction with users by\nlearning from human teaching and feedback. We design a neural network based\ntask-oriented dialogue agent that can be optimized end-to-end with the proposed\nlearning method. Experimental results show that our end-to-end dialogue agent\ncan learn effectively from the mistake it makes via imitation learning from\nuser teaching. Applying reinforcement learning with user feedback after the\nimitation learning stage further improves the agent's capability in\nsuccessfully completing a task.", "published": "2018-04-18 00:26:38", "link": "http://arxiv.org/abs/1804.06512v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Diachronic Usage Relatedness (DURel): A Framework for the Annotation of\n  Lexical Semantic Change", "abstract": "We propose a framework that extends synchronic polysemy annotation to\ndiachronic changes in lexical meaning, to counteract the lack of resources for\nevaluating computational models of lexical semantic change. Our framework\nexploits an intuitive notion of semantic relatedness, and distinguishes between\ninnovative and reductive meaning changes with high inter-annotator agreement.\nThe resulting test set for German comprises ratings from five annotators for\nthe relatedness of 1,320 use pairs across 22 target words.", "published": "2018-04-18 00:50:56", "link": "http://arxiv.org/abs/1804.06517v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Aspect Level Sentiment Classification with Attention-over-Attention\n  Neural Networks", "abstract": "Aspect-level sentiment classification aims to identify the sentiment\nexpressed towards some aspects given context sentences. In this paper, we\nintroduce an attention-over-attention (AOA) neural network for aspect level\nsentiment classification. Our approach models aspects and sentences in a joint\nway and explicitly captures the interaction between aspects and context\nsentences. With the AOA module, our model jointly learns the representations\nfor aspects and sentences, and automatically focuses on the important parts in\nsentences. Our experiments on laptop and restaurant datasets demonstrate our\napproach outperforms previous LSTM-based architectures.", "published": "2018-04-18 03:15:01", "link": "http://arxiv.org/abs/1804.06536v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fast Lexically Constrained Decoding with Dynamic Beam Allocation for\n  Neural Machine Translation", "abstract": "The end-to-end nature of neural machine translation (NMT) removes many ways\nof manually guiding the translation process that were available in older\nparadigms. Recent work, however, has introduced a new capability: lexically\nconstrained or guided decoding, a modification to beam search that forces the\ninclusion of pre-specified words and phrases in the output. However, while\ntheoretically sound, existing approaches have computational complexities that\nare either linear (Hokamp and Liu, 2017) or exponential (Anderson et al., 2017)\nin the number of constraints. We present a algorithm for lexically constrained\ndecoding with a complexity of O(1) in the number of constraints. We demonstrate\nthe algorithms remarkable ability to properly place these constraints, and use\nit to explore the shaky relationship between model and BLEU scores. Our\nimplementation is available as part of Sockeye.", "published": "2018-04-18 09:06:11", "link": "http://arxiv.org/abs/1804.06609v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "End-to-end Graph-based TAG Parsing with Neural Networks", "abstract": "We present a graph-based Tree Adjoining Grammar (TAG) parser that uses\nBiLSTMs, highway connections, and character-level CNNs. Our best end-to-end\nparser, which jointly performs supertagging, POS tagging, and parsing,\noutperforms the previously reported best results by more than 2.2 LAS and UAS\npoints. The graph-based parsing architecture allows for global inference and\nrich feature representations for TAG parsing, alleviating the fundamental\ntrade-off between transition-based and graph-based parsing systems. We also\ndemonstrate that the proposed parser achieves state-of-the-art performance in\nthe downstream tasks of Parsing Evaluation using Textual Entailments (PETE) and\nUnbounded Dependency Recovery. This provides further support for the claim that\nTAG is a viable formalism for problems that require rich structural analysis of\nsentences.", "published": "2018-04-18 09:07:16", "link": "http://arxiv.org/abs/1804.06610v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Experiments with Universal CEFR Classification", "abstract": "The Common European Framework of Reference (CEFR) guidelines describe\nlanguage proficiency of learners on a scale of 6 levels. While the description\nof CEFR guidelines is generic across languages, the development of automated\nproficiency classification systems for different languages follow different\napproaches. In this paper, we explore universal CEFR classification using\ndomain-specific and domain-agnostic, theory-guided as well as data-driven\nfeatures. We report the results of our preliminary experiments in monolingual,\ncross-lingual, and multilingual classification with three languages: German,\nCzech, and Italian. Our results show that both monolingual and multilingual\nmodels achieve similar performance, and cross-lingual classification yields\nlower, but comparable results to monolingual classification.", "published": "2018-04-18 10:33:47", "link": "http://arxiv.org/abs/1804.06636v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NTUA-SLP at SemEval-2018 Task 2: Predicting Emojis using RNNs with\n  Context-aware Attention", "abstract": "In this paper we present a deep-learning model that competed at SemEval-2018\nTask 2 \"Multilingual Emoji Prediction\". We participated in subtask A, in which\nwe are called to predict the most likely associated emoji in English tweets.\nThe proposed architecture relies on a Long Short-Term Memory network, augmented\nwith an attention mechanism, that conditions the weight of each word, on a\n\"context vector\" which is taken as the aggregation of a tweet's meaning.\nMoreover, we initialize the embedding layer of our model, with word2vec word\nembeddings, pretrained on a dataset of 550 million English tweets. Finally, our\nmodel does not rely on hand-crafted features or lexicons and is trained\nend-to-end with back-propagation. We ranked 2nd out of 48 teams.", "published": "2018-04-18 11:30:57", "link": "http://arxiv.org/abs/1804.06657v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NTUA-SLP at SemEval-2018 Task 1: Predicting Affective Content in Tweets\n  with Deep Attentive RNNs and Transfer Learning", "abstract": "In this paper we present deep-learning models that submitted to the\nSemEval-2018 Task~1 competition: \"Affect in Tweets\". We participated in all\nsubtasks for English tweets. We propose a Bi-LSTM architecture equipped with a\nmulti-layer self attention mechanism. The attention mechanism improves the\nmodel performance and allows us to identify salient words in tweets, as well as\ngain insight into the models making them more interpretable. Our model utilizes\na set of word2vec word embeddings trained on a large collection of 550 million\nTwitter messages, augmented by a set of word affective features. Due to the\nlimited amount of task-specific training data, we opted for a transfer learning\napproach by pretraining the Bi-LSTMs on the dataset of Semeval 2017, Task 4A.\nThe proposed approach ranked 1st in Subtask E \"Multi-Label Emotion\nClassification\", 2nd in Subtask A \"Emotion Intensity Regression\" and achieved\ncompetitive results in other subtasks.", "published": "2018-04-18 11:31:06", "link": "http://arxiv.org/abs/1804.06658v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NTUA-SLP at SemEval-2018 Task 3: Tracking Ironic Tweets using Ensembles\n  of Word and Character Level Attentive RNNs", "abstract": "In this paper we present two deep-learning systems that competed at\nSemEval-2018 Task 3 \"Irony detection in English tweets\". We design and ensemble\ntwo independent models, based on recurrent neural networks (Bi-LSTM), which\noperate at the word and character level, in order to capture both the semantic\nand syntactic information in tweets. Our models are augmented with a\nself-attention mechanism, in order to identify the most informative words. The\nembedding layer of our word-level model is initialized with word2vec word\nembeddings, pretrained on a collection of 550 million English tweets. We did\nnot utilize any handcrafted features, lexicons or external datasets as prior\ninformation and our models are trained end-to-end using back propagation on\nconstrained data. Furthermore, we provide visualizations of tweets with\nannotations for the salient tokens of the attention layer that can help to\ninterpret the inner workings of the proposed models. We ranked 2nd out of 42\nteams in Subtask A and 2nd out of 31 teams in Subtask B. However,\npost-task-completion enhancements of our models achieve state-of-the-art\nresults ranking 1st for both subtasks.", "published": "2018-04-18 11:35:56", "link": "http://arxiv.org/abs/1804.06659v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Alquist: The Alexa Prize Socialbot", "abstract": "This paper describes a new open domain dialogue system Alquist developed as\npart of the Alexa Prize competition for the Amazon Echo line of products. The\nAlquist dialogue system is designed to conduct a coherent and engaging\nconversation on popular topics. We are presenting a hybrid system combining\nseveral machine learning and rule based approaches. We discuss and describe the\nAlquist pipeline, data acquisition, and processing, dialogue manager, NLG,\nknowledge aggregation and hierarchy of sub-dialogs. We present some of the\nexperimental results.", "published": "2018-04-18 13:22:06", "link": "http://arxiv.org/abs/1804.06705v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Map Context-Dependent Sentences to Executable Formal Queries", "abstract": "We propose a context-dependent model to map utterances within an interaction\nto executable formal queries. To incorporate interaction history, the model\nmaintains an interaction-level encoder that updates after each turn, and can\ncopy sub-sequences of previously predicted queries during generation. Our\napproach combines implicit and explicit modeling of references between\nutterances. We evaluate our model on the ATIS flight planning interactions, and\ndemonstrate the benefits of modeling context and explicit references.", "published": "2018-04-18 18:34:46", "link": "http://arxiv.org/abs/1804.06868v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sentences with Gapping: Parsing and Reconstructing Elided Predicates", "abstract": "Sentences with gapping, such as Paul likes coffee and Mary tea, lack an overt\npredicate to indicate the relation between two or more arguments. Surface\nsyntax representations of such sentences are often produced poorly by parsers,\nand even if correct, not well suited to downstream natural language\nunderstanding tasks such as relation extraction that are typically designed to\nextract information from sentences with canonical clause structure. In this\npaper, we present two methods for parsing to a Universal Dependencies graph\nrepresentation that explicitly encodes the elided material with additional\nnodes and edges. We find that both methods can reconstruct elided material from\ndependency trees with high accuracy when the parser correctly predicts the\nexistence of a gap. We further demonstrate that one of our methods can be\napplied to other languages based on a case study on Swedish.", "published": "2018-04-18 21:32:17", "link": "http://arxiv.org/abs/1804.06922v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Forecasting the presence and intensity of hostility on Instagram using\n  linguistic and social features", "abstract": "Online antisocial behavior, such as cyberbullying, harassment, and trolling,\nis a widespread problem that threatens free discussion and has negative\nphysical and mental health consequences for victims and communities. While\nprior work has proposed automated methods to identify hostile comments in\nonline discussions, these methods work retrospectively on comments that have\nalready been posted, making it difficult to intervene before an interaction\nescalates. In this paper we instead consider the problem of forecasting future\nhostilities in online discussions, which we decompose into two tasks: (1) given\nan initial sequence of non-hostile comments in a discussion, predict whether\nsome future comment will contain hostility; and (2) given the first hostile\ncomment in a discussion, predict whether this will lead to an escalation of\nhostility in subsequent comments. Thus, we aim to forecast both the presence\nand intensity of hostile comments based on linguistic and social features from\nearlier comments. To evaluate our approach, we introduce a corpus of over 30K\nannotated Instagram comments from over 1,100 posts. Our approach is able to\npredict the appearance of a hostile comment on an Instagram post ten or more\nhours in the future with an AUC of .82 (task 1), and can furthermore\ndistinguish between high and low levels of future hostility with an AUC of .91\n(task 2).", "published": "2018-04-18 14:32:34", "link": "http://arxiv.org/abs/1804.06759v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods", "abstract": "We introduce a new benchmark, WinoBias, for coreference resolution focused on\ngender bias. Our corpus contains Winograd-schema style sentences with entities\ncorresponding to people referred by their occupation (e.g. the nurse, the\ndoctor, the carpenter). We demonstrate that a rule-based, a feature-rich, and a\nneural coreference system all link gendered pronouns to pro-stereotypical\nentities with higher accuracy than anti-stereotypical entities, by an average\ndifference of 21.1 in F1 score. Finally, we demonstrate a data-augmentation\napproach that, in combination with existing word-embedding debiasing\ntechniques, removes the bias demonstrated by these systems in WinoBias without\nsignificantly affecting their performance on existing coreference benchmark\ndatasets. Our dataset and code are available at http://winobias.org.", "published": "2018-04-18 18:51:00", "link": "http://arxiv.org/abs/1804.06876v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Neural Automated Essay Scoring and Coherence Modeling for Adversarially\n  Crafted Input", "abstract": "We demonstrate that current state-of-the-art approaches to Automated Essay\nScoring (AES) are not well-suited to capturing adversarially crafted input of\ngrammatical but incoherent sequences of sentences. We develop a neural model of\nlocal coherence that can effectively learn connectedness features between\nsentences, and propose a framework for integrating and jointly training the\nlocal coherence model with a state-of-the-art AES model. We evaluate our\napproach against a number of baselines and experimentally demonstrate its\neffectiveness on both the AES task and the task of flagging adversarial input,\nfurther contributing to the development of an approach that strengthens the\nvalidity of neural essay scoring models.", "published": "2018-04-18 19:55:18", "link": "http://arxiv.org/abs/1804.06898v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Unspeech: Unsupervised Speech Context Embeddings", "abstract": "We introduce \"Unspeech\" embeddings, which are based on unsupervised learning\nof context feature representations for spoken language. The embeddings were\ntrained on up to 9500 hours of crawled English speech data without\ntranscriptions or speaker information, by using a straightforward learning\nobjective based on context and non-context discrimination with negative\nsampling. We use a Siamese convolutional neural network architecture to train\nUnspeech embeddings and evaluate them on speaker comparison, utterance\nclustering and as a context feature in TDNN-HMM acoustic models trained on\nTED-LIUM, comparing it to i-vector baselines. Particularly decoding\nout-of-domain speech data from the recently released Common Voice corpus shows\nconsistent WER reductions. We release our source code and pre-trained Unspeech\nmodels under a permissive open source license.", "published": "2018-04-18 15:02:10", "link": "http://arxiv.org/abs/1804.06775v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Quantifying the visual concreteness of words and topics in multimodal\n  datasets", "abstract": "Multimodal machine learning algorithms aim to learn visual-textual\ncorrespondences. Previous work suggests that concepts with concrete visual\nmanifestations may be easier to learn than concepts with abstract ones. We give\nan algorithm for automatically computing the visual concreteness of words and\ntopics within multimodal datasets. We apply the approach in four settings,\nranging from image captions to images/text scraped from historical books. In\naddition to enabling explorations of concepts in multimodal datasets, our\nconcreteness scores predict the capacity of machine learning algorithms to\nlearn textual/visual relationships. We find that 1) concrete concepts are\nindeed easier to learn; 2) the large number of algorithms we consider have\nsimilar failure cases; 3) the precise positive relationship between\nconcreteness and performance varies between datasets. We conclude with\nrecommendations for using concreteness scores to facilitate future multimodal\nresearch.", "published": "2018-04-18 15:23:04", "link": "http://arxiv.org/abs/1804.06786v2", "categories": ["cs.CL", "cs.CV", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Object Ordering with Bidirectional Matchings for Visual Reasoning", "abstract": "Visual reasoning with compositional natural language instructions, e.g.,\nbased on the newly-released Cornell Natural Language Visual Reasoning (NLVR)\ndataset, is a challenging task, where the model needs to have the ability to\ncreate an accurate mapping between the diverse phrases and the several objects\nplaced in complex arrangements in the image. Further, this mapping needs to be\nprocessed to answer the question in the statement given the ordering and\nrelationship of the objects across three similar images. In this paper, we\npropose a novel end-to-end neural model for the NLVR task, where we first use\njoint bidirectional attention to build a two-way conditioning between the\nvisual information and the language phrases. Next, we use an RL-based pointer\nnetwork to sort and process the varying number of unordered objects (so as to\nmatch the order of the statement phrases) in each of the three images and then\npool over the three decisions. Our model achieves strong improvements (of 4-6%\nabsolute) over the state-of-the-art on both the structured representation and\nraw image versions of the dataset.", "published": "2018-04-18 18:39:17", "link": "http://arxiv.org/abs/1804.06870v2", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Exploiting Partially Annotated Data for Temporal Relation Extraction", "abstract": "Annotating temporal relations (TempRel) between events described in natural\nlanguage is known to be labor intensive, partly because the total number of\nTempRels is quadratic in the number of events. As a result, only a small number\nof documents are typically annotated, limiting the coverage of various\nlexical/semantic phenomena. In order to improve existing approaches, one\npossibility is to make use of the readily available, partially annotated data\n(P as in partial) that cover more documents. However, missing annotations in P\nare known to hurt, rather than help, existing systems. This work is a case\nstudy in exploring various usages of P for TempRel extraction. Results show\nthat despite missing annotations, P is still a useful supervision signal for\nthis task within a constrained bootstrapping learning framework. The system\ndescribed in this system is publicly available.", "published": "2018-04-18 21:33:00", "link": "http://arxiv.org/abs/1804.08420v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Shaking Acoustic Spectral Sub-bands Can Better Regularize Learning in\n  Affective Computing", "abstract": "In this work, we investigate a recently proposed regularization technique\nbased on multi-branch architectures, called Shake-Shake regularization, for the\ntask of speech emotion recognition. In addition, we also propose variants to\nincorporate domain knowledge into model configurations. The experimental\nresults demonstrate: $1)$ independently shaking sub-bands delivers favorable\nmodels compared to shaking the entire spectral-temporal feature maps. $2)$ with\nproper patience in early stopping, the proposed models can simultaneously\noutperform the baseline and maintain a smaller performance gap between training\nand validation.", "published": "2018-04-18 15:11:19", "link": "http://arxiv.org/abs/1804.06779v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Deep Layered Learning in MIR", "abstract": "Deep learning has boosted the performance of many music information retrieval\n(MIR) systems in recent years. Yet, the complex hierarchical arrangement of\nmusic makes end-to-end learning hard for some MIR tasks - a very deep and\nflexible processing chain is necessary to model some aspect of music audio.\nRepresentations involving tones, chords, and rhythm are fundamental building\nblocks of music. This paper discusses how these can be used as intermediate\ntargets and priors in MIR to deal with structurally complex learning problems,\nwith learning modules connected in a directed acyclic graph. It is suggested\nthat this strategy for inference, referred to as deep layered learning (DLL),\ncan help generalization by (1) - enforcing the validity and invariance of\nintermediate representations during processing, and by (2) - letting the\ninferred representations establish the musical organization to support\nhigher-level invariant processing. A background to modular music processing is\nprovided together with an overview of previous publications. Relevant concepts\nfrom information processing, such as pruning, skip connections, and performance\nsupervision are reviewed within the context of DLL. A test is finally\nperformed, showing how layered learning affects pitch tracking. It is indicated\nthat especially offsets are easier to detect if guided by extracted framewise\nfundamental frequencies.", "published": "2018-04-18 01:30:05", "link": "http://arxiv.org/abs/1804.07297v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Generating Music using an LSTM Network", "abstract": "A model of music needs to have the ability to recall past details and have a\nclear, coherent understanding of musical structure. Detailed in the paper is a\nneural network architecture that predicts and generates polyphonic music\naligned with musical rules. The probabilistic model presented is a Bi-axial\nLSTM trained with a kernel reminiscent of a convolutional kernel. When analyzed\nquantitatively and qualitatively, this approach performs well in composing\npolyphonic music. Link to the code is provided.", "published": "2018-04-18 21:14:00", "link": "http://arxiv.org/abs/1804.07300v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
