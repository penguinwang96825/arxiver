{"title": "Finding Pragmatic Differences Between Disciplines", "abstract": "Scholarly documents have a great degree of variation, both in terms of\ncontent (semantics) and structure (pragmatics). Prior work in scholarly\ndocument understanding emphasizes semantics through document summarization and\ncorpus topic modeling but tends to omit pragmatics such as document\norganization and flow. Using a corpus of scholarly documents across 19\ndisciplines and state-of-the-art language modeling techniques, we learn a fixed\nset of domain-agnostic descriptors for document sections and \"retrofit\" the\ncorpus to these descriptors (also referred to as \"normalization\"). Then, we\nanalyze the position and ordering of these descriptors across documents to\nunderstand the relationship between discipline and structure. We report\nwithin-discipline structural archetypes, variability, and between-discipline\ncomparisons, supporting the hypothesis that scholarly communities, despite\ntheir size, diversity, and breadth, share similar avenues for expressing their\nwork. Our findings lay the foundation for future work in assessing research\nquality, domain style transfer, and further pragmatic analysis.", "published": "2023-09-30 00:46:14", "link": "http://arxiv.org/abs/2310.00204v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detecting Unseen Multiword Expressions in American Sign Language", "abstract": "Multiword expressions present unique challenges in many translation tasks. In\nan attempt to ultimately apply a multiword expression detection system to the\ntranslation of American Sign Language, we built and tested two systems that\napply word embeddings from GloVe to determine whether or not the word\nembeddings of lexemes can be used to predict whether or not those lexemes\ncompose a multiword expression. It became apparent that word embeddings carry\ndata that can detect non-compositionality with decent accuracy.", "published": "2023-09-30 00:54:59", "link": "http://arxiv.org/abs/2310.00207v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AutoHall: Automated Hallucination Dataset Generation for Large Language\n  Models", "abstract": "While Large language models (LLMs) have garnered widespread applications\nacross various domains due to their powerful language understanding and\ngeneration capabilities, the detection of non-factual or hallucinatory content\ngenerated by LLMs remains scarce. Currently, one significant challenge in\nhallucination detection is the laborious task of time-consuming and expensive\nmanual annotation of the hallucinatory generation. To address this issue, this\npaper first introduces a method for automatically constructing model-specific\nhallucination datasets based on existing fact-checking datasets called\nAutoHall. Furthermore, we propose a zero-resource and black-box hallucination\ndetection method based on self-contradiction. We conduct experiments towards\nprevalent open-/closed-source LLMs, achieving superior hallucination detection\nperformance compared to extant baselines. Moreover, our experiments reveal\nvariations in hallucination proportions and types among different models.", "published": "2023-09-30 05:20:02", "link": "http://arxiv.org/abs/2310.00259v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AfriSpeech-200: Pan-African Accented Speech Dataset for Clinical and\n  General Domain ASR", "abstract": "Africa has a very low doctor-to-patient ratio. At very busy clinics, doctors\ncould see 30+ patients per day -- a heavy patient burden compared with\ndeveloped countries -- but productivity tools such as clinical automatic speech\nrecognition (ASR) are lacking for these overworked clinicians. However,\nclinical ASR is mature, even ubiquitous, in developed nations, and\nclinician-reported performance of commercial clinical ASR systems is generally\nsatisfactory. Furthermore, the recent performance of general domain ASR is\napproaching human accuracy. However, several gaps exist. Several publications\nhave highlighted racial bias with speech-to-text algorithms and performance on\nminority accents lags significantly. To our knowledge, there is no publicly\navailable research or benchmark on accented African clinical ASR, and speech\ndata is non-existent for the majority of African accents. We release\nAfriSpeech, 200hrs of Pan-African English speech, 67,577 clips from 2,463\nunique speakers across 120 indigenous accents from 13 countries for clinical\nand general domain ASR, a benchmark test set, with publicly available\npre-trained models with SOTA performance on the AfriSpeech benchmark.", "published": "2023-09-30 06:38:43", "link": "http://arxiv.org/abs/2310.00274v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Understanding In-Context Learning from Repetitions", "abstract": "This paper explores the elusive mechanism underpinning in-context learning in\nLarge Language Models (LLMs). Our work provides a novel perspective by\nexamining in-context learning via the lens of surface repetitions. We\nquantitatively investigate the role of surface features in text generation, and\nempirically establish the existence of \\emph{token co-occurrence\nreinforcement}, a principle that strengthens the relationship between two\ntokens based on their contextual co-occurrences. By investigating the dual\nimpacts of these features, our research illuminates the internal workings of\nin-context learning and expounds on the reasons for its failures. This paper\nprovides an essential contribution to the understanding of in-context learning\nand its potential limitations, providing a fresh perspective on this exciting\ncapability.", "published": "2023-09-30 08:13:49", "link": "http://arxiv.org/abs/2310.00297v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RelBERT: Embedding Relations with Language Models", "abstract": "Many applications need access to background knowledge about how different\nconcepts and entities are related. Although Knowledge Graphs (KG) and Large\nLanguage Models (LLM) can address this need to some extent, KGs are inevitably\nincomplete and their relational schema is often too coarse-grained, while LLMs\nare inefficient and difficult to control. As an alternative, we propose to\nextract relation embeddings from relatively small language models. In\nparticular, we show that masked language models such as RoBERTa can be\nstraightforwardly fine-tuned for this purpose, using only a small amount of\ntraining data. The resulting model, which we call RelBERT, captures relational\nsimilarity in a surprisingly fine-grained way, allowing us to set a new\nstate-of-the-art in analogy benchmarks. Crucially, RelBERT is capable of\nmodelling relations that go well beyond what the model has seen during\ntraining. For instance, we obtained strong results on relations between named\nentities with a model that was only trained on lexical relations between\nconcepts, and we observed that RelBERT can recognise morphological analogies\ndespite not being trained on such examples. Overall, we find that RelBERT\nsignificantly outperforms strategies based on prompting language models that\nare several orders of magnitude larger, including recent GPT-based models and\nopen source models.", "published": "2023-09-30 08:15:36", "link": "http://arxiv.org/abs/2310.00299v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards LLM-based Fact Verification on News Claims with a Hierarchical\n  Step-by-Step Prompting Method", "abstract": "While large pre-trained language models (LLMs) have shown their impressive\ncapabilities in various NLP tasks, they are still under-explored in the\nmisinformation domain. In this paper, we examine LLMs with in-context learning\n(ICL) for news claim verification, and find that only with 4-shot demonstration\nexamples, the performance of several prompting methods can be comparable with\nprevious supervised models. To further boost performance, we introduce a\nHierarchical Step-by-Step (HiSS) prompting method which directs LLMs to\nseparate a claim into several subclaims and then verify each of them via\nmultiple questions-answering steps progressively. Experiment results on two\npublic misinformation datasets show that HiSS prompting outperforms\nstate-of-the-art fully-supervised approach and strong few-shot ICL-enabled\nbaselines.", "published": "2023-09-30 08:33:04", "link": "http://arxiv.org/abs/2310.00305v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Decoding In-Context Learning: Neuroscience-inspired Analysis of\n  Representations in Large Language Models", "abstract": "Large language models (LLMs) exhibit remarkable performance improvement\nthrough in-context learning (ICL) by leveraging task-specific examples in the\ninput. However, the mechanisms behind this improvement remain elusive. In this\nwork, we investigate how LLM embeddings and attention representations change\nfollowing in-context-learning, and how these changes mediate improvement in\nbehavior. We employ neuroscience-inspired techniques such as representational\nsimilarity analysis (RSA) and propose novel methods for parameterized probing\nand measuring ratio of attention to relevant vs. irrelevant information in\nLlama-2 70B and Vicuna 13B. We designed two tasks with a priori relationships\namong their conditions: linear regression and reading comprehension. We formed\nhypotheses about expected similarities in task representations and measured\nhypothesis alignment of LLM representations before and after ICL as well as\nchanges in attention. Our analyses revealed a meaningful correlation between\nimprovements in behavior after ICL and changes in both embeddings and attention\nweights across LLM layers. This empirical framework empowers a nuanced\nunderstanding of how latent representations shape LLM behavior, offering\nvaluable tools and insights for future research and practical applications.", "published": "2023-09-30 09:01:35", "link": "http://arxiv.org/abs/2310.00313v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Representation Generalization in Authorship Identification", "abstract": "Authorship identification ascertains the authorship of texts whose origins\nremain undisclosed. That authorship identification techniques work as reliably\nas they do has been attributed to the fact that authorial style is properly\ncaptured and represented. Although modern authorship identification methods\nhave evolved significantly over the years and have proven effective in\ndistinguishing authorial styles, the generalization of stylistic features\nacross domains has not been systematically reviewed. The presented work\naddresses the challenge of enhancing the generalization of stylistic\nrepresentations in authorship identification, particularly when there are\ndiscrepancies between training and testing samples. A comprehensive review of\nempirical studies was conducted, focusing on various stylistic features and\ntheir effectiveness in representing an author's style. The influencing factors\nsuch as topic, genre, and register on writing style were also explored, along\nwith strategies to mitigate their impact. While some stylistic features, like\ncharacter n-grams and function words, have proven to be robust and\ndiscriminative, others, such as content words, can introduce biases and hinder\ncross-domain generalization. Representations learned using deep learning\nmodels, especially those incorporating character n-grams and syntactic\ninformation, show promise in enhancing representation generalization. The\nfindings underscore the importance of selecting appropriate stylistic features\nfor authorship identification, especially in cross-domain scenarios. The\nrecognition of the strengths and weaknesses of various linguistic features\npaves the way for more accurate authorship identification in diverse contexts.", "published": "2023-09-30 17:11:00", "link": "http://arxiv.org/abs/2310.00436v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Many Voices of Duying: Revisiting the Disputed Essays Between Lu Xun\n  and Zhou Zuoren", "abstract": "Lu Xun and Zhou Zuoren stand as two of the most influential writers in modern\nChinese literature. Beyond their familial ties as brothers, they were also\nintimate collaborators during the nascent stages of their writing careers. This\nresearch employs quantitative methods to revisit three disputed essays\npseudonymously published by the brothers in 1912. Our stylometric analysis uses\nan interpretable authorship attribution model to investigate the essays'\nauthorship and examine the brothers' respective writing styles. Our findings\nsuggest that 'Looking at the Country of China' was authored by Lu Xun.\nMoreover, 'People of Yue, Forget Not Your Ancestors' Instructions' seems to be\neither predominantly authored or extensively revised by Lu Xun given its\nnotable stylistic similarities to 'Looking at the Land of Yue,' a piece Zhou\nZuoren recognized as his own, but edited by Lu Xun. The third essay, 'Where Has\nthe Character of the Republic Gone?,' exhibits a 'diluted', mixed writing\nstyle, suggesting thorough collaboration. We offer visual representations of\nessay features to facilitate a nuanced and intuitive understanding. We have\nuncovered evidence suggesting Lu Xun's covert engagement with social issues\nduring his purported 'silent era' and provided insights into the brothers'\nformative intellectual trajectories.", "published": "2023-09-30 17:41:39", "link": "http://arxiv.org/abs/2310.01440v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Strategies for Modeling Sign Language Phonology", "abstract": "Like speech, signs are composed of discrete, recombinable features called\nphonemes. Prior work shows that models which can recognize phonemes are better\nat sign recognition, motivating deeper exploration into strategies for modeling\nsign language phonemes. In this work, we learn graph convolution networks to\nrecognize the sixteen phoneme \"types\" found in ASL-LEX 2.0. Specifically, we\nexplore how learning strategies like multi-task and curriculum learning can\nleverage mutually useful information between phoneme types to facilitate better\nmodeling of sign language phonemes. Results on the Sem-Lex Benchmark show that\ncurriculum learning yields an average accuracy of 87% across all phoneme types,\noutperforming fine-tuning and multi-task strategies for most phoneme types.", "published": "2023-09-30 00:19:10", "link": "http://arxiv.org/abs/2310.00195v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "The Sem-Lex Benchmark: Modeling ASL Signs and Their Phonemes", "abstract": "Sign language recognition and translation technologies have the potential to\nincrease access and inclusion of deaf signing communities, but research\nprogress is bottlenecked by a lack of representative data. We introduce a new\nresource for American Sign Language (ASL) modeling, the Sem-Lex Benchmark. The\nBenchmark is the current largest of its kind, consisting of over 84k videos of\nisolated sign productions from deaf ASL signers who gave informed consent and\nreceived compensation. Human experts aligned these videos with other sign\nlanguage resources including ASL-LEX, SignBank, and ASL Citizen, enabling\nuseful expansions for sign and phonological feature recognition. We present a\nsuite of experiments which make use of the linguistic information in ASL-LEX,\nevaluating the practicality and fairness of the Sem-Lex Benchmark for isolated\nsign recognition (ISR). We use an SL-GCN model to show that the phonological\nfeatures are recognizable with 85% accuracy, and that they are effective as an\nauxiliary target to ISR. Learning to recognize phonological features alongside\ngloss results in a 6% improvement for few-shot ISR accuracy and a 2%\nimprovement for ISR accuracy overall. Instructions for downloading the data can\nbe found at https://github.com/leekezar/SemLex.", "published": "2023-09-30 00:25:43", "link": "http://arxiv.org/abs/2310.00196v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Investigating the Efficacy of Large Language Models in Reflective\n  Assessment Methods through Chain of Thoughts Prompting", "abstract": "Large Language Models, such as Generative Pre-trained Transformer 3 (aka.\nGPT-3), have been developed to understand language through the analysis of\nextensive text data, allowing them to identify patterns and connections between\nwords. While LLMs have demonstrated impressive performance across various\ntext-related tasks, they encounter challenges in tasks associated with\nreasoning. To address this challenge, Chain of Thought(CoT) prompting method\nhas been proposed as a means to enhance LLMs' proficiency in complex reasoning\ntasks like solving math word problems and answering questions based on logical\nargumentative reasoning. The primary aim of this research is to assess how well\nfour language models can grade reflective essays of third-year medical\nstudents. The assessment will specifically target the evaluation of critical\nthinking skills using CoT prompting.\n  The research will provide the following contributions; to introduce and\neducate on the process of instructing models to evaluate reflective essays from\na dataset they have not been previously trained on; to illustrate the use of\nCoT prompting as an instructional approach for training large models to carry\nout particular tasks. Our results suggest that among all the models, Llama-7b\nperforms the least effectively, displaying the highest mean squared error.\nConversely, ChatGPT emerges as the superior model, boasting a higher Cohen\nkappa score value of 0.53. Lastly, it's important to note that the selected\nmodels do prioritise user privacy by allowing users to delete their own\nconducted conversations.", "published": "2023-09-30 06:25:27", "link": "http://arxiv.org/abs/2310.00272v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Corex: Pushing the Boundaries of Complex Reasoning through Multi-Model\n  Collaboration", "abstract": "Large Language Models (LLMs) are evolving at an unprecedented pace and have\nexhibited considerable capability in the realm of natural language processing\n(NLP) with world knowledge. Benefiting from ultra-large-scale training corpora,\na single LLM can manage typical NLP tasks competently. However, its performance\nin executing reasoning tasks is still confined by the limitations of its\ninternal representations. To push this boundary further, we introduce Corex in\nthis paper, a suite of novel general-purpose strategies that transform LLMs\ninto autonomous agents pioneering multi-model collaborations for complex\ntask-solving. Inspired by human behaviors, Corex is constituted by diverse\ncollaboration paradigms including Debate, Review, and Retrieve modes, which\ncollectively work towards enhancing the factuality, faithfulness, and\nreliability of the reasoning process. These paradigms foster task-agnostic\napproaches that enable LLMs to ''think outside the box,'' thereby overcoming\nhallucinations and providing better solutions. Through extensive experiments\nacross four different types of reasoning tasks, we demonstrate that\norchestrating multiple LLMs to work in concert yields substantially better\nperformance compared to existing methods. Further results and in-depth analysis\ndemonstrate the cost-effectiveness of our method, facilitating collaboration\namong different LLMs and promoting annotation efficiency.", "published": "2023-09-30 07:11:39", "link": "http://arxiv.org/abs/2310.00280v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Evolving Diverse Red-team Language Models in Multi-round Multi-agent\n  Games", "abstract": "The primary challenge in deploying Large Language Model (LLM) is ensuring its\nharmlessness. Red team can identify vulnerabilities by attacking LLM to attain\nsafety. However, current efforts heavily rely on single-round prompt designs\nand unilateral red team optimizations against fixed blue teams. These static\napproaches lead to significant reductions in generation diversity, known as the\nmode collapse, which makes it difficult to discover the potential risks in the\nincreasingly complex human-LLM interactions. Here we introduce dynamic Red Team\nGame (RTG) to comprehensively analyze the multi-round offensive and defensive\ninteractions between red team and blue team. Furthermore, we develop a Gamified\nRed Team Solver (GRTS) with diversity measures to mitigate mode collapse and\ntheoretically guarantee the convergence of approximate Nash equilibrium which\nresults in better strategies for both teams. Empirical results demonstrate that\nGRTS explore diverse and implicit attacks to adaptively exploit various LLMs,\nsurpassing the constraints of specific modes. Insightfully, the geometrical\nstructure we unveil of the red team task aligns with the spinning top\nhypothesis, confirming the necessity of constructing a diverse LLM population\nas a promising proxy for heterogeneous human expert red-teamers. This paves the\nway for scalable toxicity detection and safe alignment for LLMs.", "published": "2023-09-30 09:35:50", "link": "http://arxiv.org/abs/2310.00322v5", "categories": ["cs.CL", "cs.GT"], "primary_category": "cs.CL"}
{"title": "Unlocking Bias Detection: Leveraging Transformer-Based Models for\n  Content Analysis", "abstract": "Bias detection in text is crucial for combating the spread of negative\nstereotypes, misinformation, and biased decision-making. Traditional language\nmodels frequently face challenges in generalizing beyond their training data\nand are typically designed for a single task, often focusing on bias detection\nat the sentence level. To address this, we present the Contextualized\nBi-Directional Dual Transformer (CBDT) \\textcolor{green}{\\faLeaf} classifier.\nThis model combines two complementary transformer networks: the Context\nTransformer and the Entity Transformer, with a focus on improving bias\ndetection capabilities. We have prepared a dataset specifically for training\nthese models to identify and locate biases in texts. Our evaluations across\nvarious datasets demonstrate CBDT \\textcolor{green} effectiveness in\ndistinguishing biased narratives from neutral ones and identifying specific\nbiased terms. This work paves the way for applying the CBDT \\textcolor{green}\nmodel in various linguistic and cultural contexts, enhancing its utility in\nbias detection efforts. We also make the annotated dataset available for\nresearch purposes.", "published": "2023-09-30 12:06:04", "link": "http://arxiv.org/abs/2310.00347v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Gaze-Driven Sentence Simplification for Language Learners: Enhancing\n  Comprehension and Readability", "abstract": "Language learners should regularly engage in reading challenging materials as\npart of their study routine. Nevertheless, constantly referring to dictionaries\nis time-consuming and distracting. This paper presents a novel gaze-driven\nsentence simplification system designed to enhance reading comprehension while\nmaintaining their focus on the content. Our system incorporates machine\nlearning models tailored to individual learners, combining eye gaze features\nand linguistic features to assess sentence comprehension. When the system\nidentifies comprehension difficulties, it provides simplified versions by\nreplacing complex vocabulary and grammar with simpler alternatives via GPT-3.5.\nWe conducted an experiment with 19 English learners, collecting data on their\neye movements while reading English text. The results demonstrated that our\nsystem is capable of accurately estimating sentence-level comprehension.\nAdditionally, we found that GPT-3.5 simplification improved readability in\nterms of traditional readability metrics and individual word difficulty,\nparaphrasing across different linguistic levels.", "published": "2023-09-30 12:18:31", "link": "http://arxiv.org/abs/2310.00355v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "AutomaTikZ: Text-Guided Synthesis of Scientific Vector Graphics with\n  TikZ", "abstract": "Generating bitmap graphics from text has gained considerable attention, yet\nfor scientific figures, vector graphics are often preferred. Given that vector\ngraphics are typically encoded using low-level graphics primitives, generating\nthem directly is difficult. To address this, we propose the use of TikZ, a\nwell-known abstract graphics language that can be compiled to vector graphics,\nas an intermediate representation of scientific figures. TikZ offers\nhuman-oriented, high-level commands, thereby facilitating conditional language\nmodeling with any large language model. To this end, we introduce DaTikZ, the\nfirst large-scale TikZ dataset consisting of 120k TikZ drawings aligned with\ncaptions. We fine-tune LLaMA on DaTikZ, as well as our new model CLiMA, which\naugments LLaMA with multimodal CLIP embeddings. In both human and automatic\nevaluation, CLiMA and LLaMA outperform commercial GPT-4 and Claude 2 in terms\nof similarity to human-created figures, with CLiMA additionally improving\ntext-image alignment. Our detailed analysis shows that all models generalize\nwell and are not susceptible to memorization. GPT-4 and Claude 2, however, tend\nto generate more simplistic figures compared to both humans and our models. We\nmake our framework, AutomaTikZ, along with model weights and datasets, publicly\navailable.", "published": "2023-09-30 13:15:49", "link": "http://arxiv.org/abs/2310.00367v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Dynamic Demonstrations Controller for In-Context Learning", "abstract": "In-context learning (ICL) is a new paradigm for natural language processing\n(NLP), where a large language model (LLM) observes a small number of\ndemonstrations and a test instance as its input, and directly makes predictions\nwithout updating model parameters. Previous studies have revealed that ICL is\nsensitive to the selection and the ordering of demonstrations. However, there\nare few studies regarding the impact of the demonstration number on the ICL\nperformance within a limited input length of LLM, because it is commonly\nbelieved that the number of demonstrations is positively correlated with model\nperformance. In this paper, we found this conclusion does not always hold true.\nThrough pilot experiments, we discover that increasing the number of\ndemonstrations does not necessarily lead to improved performance. Building upon\nthis insight, we propose a Dynamic Demonstrations Controller (D$^2$Controller),\nwhich can improve the ICL performance by adjusting the number of demonstrations\ndynamically. The experimental results show that D$^2$Controller yields a 4.6%\nrelative improvement on ten different sizes of LLMs across ten datasets.\nMoreover, we also extend our method to previous ICL models and achieve\ncompetitive results.", "published": "2023-09-30 14:04:22", "link": "http://arxiv.org/abs/2310.00385v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Open-Domain Dialogue Quality Evaluation: Deriving Nugget-level Scores\n  from Turn-level Scores", "abstract": "Existing dialogue quality evaluation systems can return a score for a given\nsystem turn from a particular viewpoint, e.g., engagingness. However, to\nimprove dialogue systems by locating exactly where in a system turn potential\nproblems lie, a more fine-grained evaluation may be necessary. We therefore\npropose an evaluation approach where a turn is decomposed into nuggets (i.e.,\nexpressions associated with a dialogue act), and nugget-level evaluation is\nenabled by leveraging an existing turn-level evaluation system. We demonstrate\nthe potential effectiveness of our evaluation method through a case study.", "published": "2023-09-30 15:14:50", "link": "http://arxiv.org/abs/2310.00410v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Question-Answering Model for Schizophrenia Symptoms and Their Impact on\n  Daily Life using Mental Health Forums Data", "abstract": "In recent years, there is strong emphasis on mining medical data using\nmachine learning techniques. A common problem is to obtain a noiseless set of\ntextual documents, with a relevant content for the research question, and\ndeveloping a Question Answering (QA) model for a specific medical field. The\npurpose of this paper is to present a new methodology for building a medical\ndataset and obtain a QA model for analysis of symptoms and impact on daily life\nfor a specific disease domain. The ``Mental Health'' forum was used, a forum\ndedicated to people suffering from schizophrenia and different mental\ndisorders. Relevant posts of active users, who regularly participate, were\nextrapolated providing a new method of obtaining low-bias content and without\nprivacy issues. Furthermore, it is shown how to pre-process the dataset to\nconvert it into a QA dataset. The Bidirectional Encoder Representations from\nTransformers (BERT), DistilBERT, RoBERTa, and BioBERT models were fine-tuned\nand evaluated via F1-Score, Exact Match, Precision and Recall. Accurate\nempirical experiments demonstrated the effectiveness of the proposed method for\nobtaining an accurate dataset for QA model implementation. By fine-tuning the\nBioBERT QA model, we achieved an F1 score of 0.885, showing a considerable\nimprovement and outperforming the state-of-the-art model for mental disorders\ndomain.", "published": "2023-09-30 17:50:50", "link": "http://arxiv.org/abs/2310.00448v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "UPAR: A Kantian-Inspired Prompting Framework for Enhancing Large\n  Language Model Capabilities", "abstract": "Large Language Models (LLMs) have demonstrated impressive inferential\ncapabilities, with numerous research endeavors devoted to enhancing this\ncapacity through prompting. Despite these efforts, a unified epistemological\nfoundation is still conspicuously absent. Drawing inspiration from Kant's a\npriori philosophy, we propose the UPAR prompting framework, designed to emulate\nthe structure of human cognition within LLMs. The UPAR framework is delineated\ninto four phases: \"Understand\", \"Plan\", \"Act\", and \"Reflect\", enabling the\nextraction of structured information from complex contexts, prior planning of\nsolutions, execution according to plan, and self-reflection. This structure\nsignificantly augments the explainability and accuracy of LLM inference,\nproducing a human-understandable and inspectable inferential trajectory.\nFurthermore, our work offers an epistemological foundation for existing\nprompting techniques, allowing for a possible systematic integration of these\nmethods. With GPT-4, our approach elevates the accuracy from COT baseline of\n22.92% to 58.33% in a challenging subset of GSM8K, and from 67.91% to 75.40% in\nthe causal judgment task. Without using few-shot examples or external tools,\nUPAR significantly outperforms existing prompting methods on SCIBENCH, a\nchallenging dataset containing collegiate-level mathematics, chemistry, and\nphysics scientific problems.", "published": "2023-09-30 20:18:50", "link": "http://arxiv.org/abs/2310.01441v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Brief History of Prompt: Leveraging Language Models. (Through Advanced\n  Prompting)", "abstract": "This paper presents a comprehensive exploration of the evolution of prompt\nengineering and generation in the field of natural language processing (NLP).\nStarting from the early language models and information retrieval systems, we\ntrace the key developments that have shaped prompt engineering over the years.\nThe introduction of attention mechanisms in 2015 revolutionized language\nunderstanding, leading to advancements in controllability and\ncontext-awareness. Subsequent breakthroughs in reinforcement learning\ntechniques further enhanced prompt engineering, addressing issues like exposure\nbias and biases in generated text. We examine the significant contributions in\n2018 and 2019, focusing on fine-tuning strategies, control codes, and\ntemplate-based generation. The paper also discusses the growing importance of\nfairness, human-AI collaboration, and low-resource adaptation. In 2020 and\n2021, contextual prompting and transfer learning gained prominence, while 2022\nand 2023 witnessed the emergence of advanced techniques like unsupervised\npre-training and novel reward shaping. Throughout the paper, we reference\nspecific research studies that exemplify the impact of various developments on\nprompt engineering. The journey of prompt engineering continues, with ethical\nconsiderations being paramount for the responsible and inclusive future of AI\nsystems.", "published": "2023-09-30 22:27:37", "link": "http://arxiv.org/abs/2310.04438v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Pairwise Proximal Policy Optimization: Harnessing Relative Feedback for\n  LLM Alignment", "abstract": "Large Language Models (LLMs) can acquire extensive world knowledge through\npre-training on large corpora. However, due to exposure to low-quality data,\nLLMs may exhibit harmful behavior without aligning with human values. The\ndominant approach for steering LLMs towards beneficial behavior involves\nReinforcement Learning with Human Feedback (RLHF), with Proximal Policy\nOptimization (PPO) serving as the default RL optimizer. Despite its\neffectiveness, PPO has limitations when optimizing rewards trained from\ncomparison-based loss. Primarily, PPO is not invariant to equivalent reward\nfunctions containing identical preference information due to the need to\ncalibrate the reward scale. Additionally, PPO's necessity for token-wise\nupdates introduces complexity in both function approximation and algorithm\ndesign compared to trajectory-wise optimization. This paper proposes a new\nframework, reinforcement learning with relative feedback, and a novel\ntrajectory-wise policy gradient algorithm, Pairwise Proximal Policy\nOptimization (P3O) that operates directly on comparative rewards. We show\ntheoretically that P3O is invariant to equivalent rewards and avoids the\ncomplexity of PPO. Empirical evaluations demonstrate that P3O outperforms PPO\nin the KL-Reward trade-off and can align with human preferences as well as or\nbetter than prior methods. In summary, this work introduces a simpler yet\neffective approach for aligning LLMs to human preferences through relative\nfeedback.", "published": "2023-09-30 01:23:22", "link": "http://arxiv.org/abs/2310.00212v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "SLM: Bridge the thin gap between speech and text foundation models", "abstract": "We present a joint Speech and Language Model (SLM), a multitask,\nmultilingual, and dual-modal model that takes advantage of pretrained\nfoundational speech and language models. SLM freezes the pretrained foundation\nmodels to maximally preserves their capabilities, and only trains a simple\nadapter with just 1\\% (156M) of the foundation models' parameters. This\nadaptation not only leads SLM to achieve strong performance on conventional\ntasks such as speech recognition (ASR) and speech translation (AST), but also\nintroduces the novel capability of zero-shot instruction-following for more\ndiverse tasks: given a speech input and a text instruction, SLM is able to\nperform unseen generation tasks including contextual biasing ASR using\nreal-time context, dialog generation, speech continuation, and question\nanswering, etc. Our approach demonstrates that the representational gap between\npretrained speech and language models might be narrower than one would expect,\nand can be bridged by a simple adaptation mechanism. As a result, SLM is not\nonly efficient to train, but also inherits strong capabilities already acquired\nin foundation models of different modalities.", "published": "2023-09-30 02:27:45", "link": "http://arxiv.org/abs/2310.00230v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "ValueDCG: Measuring Comprehensive Human Value Understanding Ability of\n  Language Models", "abstract": "Personal values are a crucial factor behind human decision-making.\nConsidering that Large Language Models (LLMs) have been shown to impact human\ndecisions significantly, it is essential to make sure they accurately\nunderstand human values to ensure their safety. However, evaluating their grasp\nof these values is complex due to the value's intricate and adaptable nature.\nWe argue that truly understanding values in LLMs requires considering both\n\"know what\" and \"know why\". To this end, we present a comprehensive evaluation\nmetric, ValueDCG (Value Discriminator-Critique Gap), to quantitatively assess\nthe two aspects with an engineering implementation. We assess four\nrepresentative LLMs and provide compelling evidence that the growth rates of\nLLM's \"know what\" and \"know why\" capabilities do not align with increases in\nparameter numbers, resulting in a decline in the models' capacity to understand\nhuman values as larger amounts of parameters. This may further suggest that\nLLMs might craft plausible explanations based on the provided context without\ntruly understanding their inherent value, indicating potential risks.", "published": "2023-09-30 13:47:55", "link": "http://arxiv.org/abs/2310.00378v4", "categories": ["cs.CL", "cs.AI", "cs.CY", "I.2.m; K.4.m"], "primary_category": "cs.CL"}
{"title": "It HAS to be Subjective: Human Annotator Simulation via Zero-shot\n  Density Estimation", "abstract": "Human annotator simulation (HAS) serves as a cost-effective substitute for\nhuman evaluation such as data annotation and system assessment. Human\nperception and behaviour during human evaluation exhibit inherent variability\ndue to diverse cognitive processes and subjective interpretations, which should\nbe taken into account in modelling to better mimic the way people perceive and\ninteract with the world. This paper introduces a novel meta-learning framework\nthat treats HAS as a zero-shot density estimation problem, which incorporates\nhuman variability and allows for the efficient generation of human-like\nannotations for unlabelled test inputs. Under this framework, we propose two\nnew model classes, conditional integer flows and conditional softmax flows, to\naccount for ordinal and categorical annotations, respectively. The proposed\nmethod is evaluated on three real-world human evaluation tasks and shows\nsuperior capability and efficiency to predict the aggregated behaviours of\nhuman annotators, match the distribution of human annotations, and simulate the\ninter-annotator disagreements.", "published": "2023-09-30 20:54:59", "link": "http://arxiv.org/abs/2310.00486v1", "categories": ["cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "From Language Modeling to Instruction Following: Understanding the\n  Behavior Shift in LLMs after Instruction Tuning", "abstract": "Large Language Models (LLMs) have achieved remarkable success, where\ninstruction tuning is the critical step in aligning LLMs with user intentions.\nIn this work, we investigate how the instruction tuning adjusts pre-trained\nmodels with a focus on intrinsic changes. Specifically, we first develop\nseveral local and global explanation methods, including a gradient-based method\nfor input-output attribution, and techniques for interpreting patterns and\nconcepts in self-attention and feed-forward layers. The impact of instruction\ntuning is then studied by comparing the explanations derived from the\npre-trained and instruction-tuned models. This approach provides an internal\nperspective of the model shifts on a human-comprehensible level. Our findings\nreveal three significant impacts of instruction tuning: 1) It empowers LLMs to\nrecognize the instruction parts of user prompts, and promotes the response\ngeneration constantly conditioned on the instructions. 2) It encourages the\nself-attention heads to capture more word-word relationships about instruction\nverbs. 3) It encourages the feed-forward networks to rotate their pre-trained\nknowledge toward user-oriented tasks. These insights contribute to a more\ncomprehensive understanding of instruction tuning and lay the groundwork for\nfuture work that aims at explaining and optimizing LLMs for various\napplications. Our code and data are publicly available at\nhttps://github.com/JacksonWuxs/Interpret_Instruction_Tuning_LLMs.", "published": "2023-09-30 21:16:05", "link": "http://arxiv.org/abs/2310.00492v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Novel U-Net Architecture for Denoising of Real-world Noise Corrupted\n  Phonocardiogram Signal", "abstract": "The bio-acoustic information contained within heart sound signals are\nutilized by physicians world-wide for auscultation purpose. However, the heart\nsounds are inherently susceptible to noise contamination. Various sources of\nnoises like lung sound, coughing, sneezing, and other background noises are\ninvolved in such contamination. Such corruption of the heart sound signal often\nleads to inconclusive or false diagnosis. To address this issue, we have\nproposed a novel U-Net based deep neural network architecture for denoising of\nphonocardiogram (PCG) signal in this paper. For the design, development and\nvalidation of the proposed architecture, a novel approach of synthesizing\nreal-world noise corrupted PCG signals have been proposed. For the purpose, an\nopen-access real-world noise sample dataset and an open-access PCG dataset has\nbeen utilized. The performance of the proposed denoising methodology has been\nevaluated on the synthesized noisy PCG dataset. The performance of the proposed\nalgorithm has been compared with existing state-of-the-art (SoA) denoising\nalgorithms qualitatively and quantitatively. The proposed denoising technique\nhas shown improvement in performance as comparison to the SoAs.", "published": "2023-09-30 01:35:50", "link": "http://arxiv.org/abs/2310.00216v1", "categories": ["eess.SP", "cs.SD", "eess.AS"], "primary_category": "eess.SP"}
{"title": "Active Learning Based Fine-Tuning Framework for Speech Emotion\n  Recognition", "abstract": "Speech emotion recognition (SER) has drawn increasing attention for its\napplications in human-machine interaction. However, existing SER methods ignore\nthe information gap between the pre-training speech recognition task and the\ndownstream SER task, leading to sub-optimal performance. Moreover, they require\nmuch time to fine-tune on each specific speech dataset, restricting their\neffectiveness in real-world scenes with large-scale noisy data. To address\nthese issues, we propose an active learning (AL) based Fine-Tuning framework\nfor SER that leverages task adaptation pre-training (TAPT) and AL methods to\nenhance performance and efficiency. Specifically, we first use TAPT to minimize\nthe information gap between the pre-training and the downstream task. Then, AL\nmethods are used to iteratively select a subset of the most informative and\ndiverse samples for fine-tuning, reducing time consumption. Experiments\ndemonstrate that using only 20\\%pt. samples improves 8.45\\%pt. accuracy and\nreduces 79\\%pt. time consumption.", "published": "2023-09-30 07:23:29", "link": "http://arxiv.org/abs/2310.00283v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Time-Variant Overlap-Add in Partitions", "abstract": "Virtual and augmented realities are increasingly popular tools in many\ndomains such as architecture, production, training and education,\n(psycho)therapy, gaming, and others. For a convincing rendering of sound in\nvirtual and augmented environments, audio signals must be convolved in\nreal-time with impulse responses that change from one moment in time to\nanother. Key requirements for the implementation of such time-variant real-time\nconvolution algorithms are short latencies, moderate computational cost and\nmemory footprint, and no perceptible switching artifacts. In this engineering\nreport, we introduce a partitioned convolution algorithm that is able to\nquickly switch between impulse responses without introducing perceptible\nartifacts, while maintaining a constant computational load and low memory\nusage. Implementations in several popular programming languages are freely\navailable via GitHub.", "published": "2023-09-30 09:17:51", "link": "http://arxiv.org/abs/2310.00319v1", "categories": ["eess.SP", "cs.SD", "eess.AS"], "primary_category": "eess.SP"}
{"title": "Music- and Lyrics-driven Dance Synthesis", "abstract": "Lyrics often convey information about the songs that are beyond the auditory\ndimension, enriching the semantic meaning of movements and musical themes. Such\ninsights are important in the dance choreography domain. However, most existing\ndance synthesis methods mainly focus on music-to-dance generation, without\nconsidering the semantic information. To complement it, we introduce JustLMD, a\nnew multimodal dataset of 3D dance motion with music and lyrics. To the best of\nour knowledge, this is the first dataset with triplet information including\ndance motion, music, and lyrics. Additionally, we showcase a cross-modal\ndiffusion-based network designed to generate 3D dance motion conditioned on\nmusic and lyrics. The proposed JustLMD dataset encompasses 4.6 hours of 3D\ndance motion in 1867 sequences, accompanied by musical tracks and their\ncorresponding English lyrics.", "published": "2023-09-30 18:27:14", "link": "http://arxiv.org/abs/2310.00455v1", "categories": ["cs.MM", "cs.GR", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
