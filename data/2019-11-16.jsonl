{"title": "Utterance-to-Utterance Interactive Matching Network for Multi-Turn\n  Response Selection in Retrieval-Based Chatbots", "abstract": "This paper proposes an utterance-to-utterance interactive matching network\n(U2U-IMN) for multi-turn response selection in retrieval-based chatbots.\nDifferent from previous methods following context-to-response matching or\nutterance-to-response matching frameworks, this model treats both contexts and\nresponses as sequences of utterances when calculating the matching degrees\nbetween them. For a context-response pair, the U2U-IMN model first encodes each\nutterance separately using recurrent and self-attention layers. Then, a global\nand bidirectional interaction between the context and the response is conducted\nusing the attention mechanism to collect the matching information between them.\nThe distances between context and response utterances are employed as a prior\ncomponent when calculating the attention weights. Finally, sentence-level\naggregation and context-response-level aggregation are executed in turn to\nobtain the feature vector for matching degree prediction. Experiments on four\npublic datasets showed that our proposed method outperformed baseline methods\non all metrics, achieving a new state-of-the-art performance and demonstrating\ncompatibility across domains for multi-turn response selection.", "published": "2019-11-16 02:47:03", "link": "http://arxiv.org/abs/1911.06940v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Robust Reading Comprehension with Linguistic Constraints via Posterior\n  Regularization", "abstract": "In spite of great advancements of machine reading comprehension (RC),\nexisting RC models are still vulnerable and not robust to different types of\nadversarial examples. Neural models over-confidently predict wrong answers to\nsemantic different adversarial examples, while over-sensitively predict wrong\nanswers to semantic equivalent adversarial examples. Existing methods which\nimprove the robustness of such neural models merely mitigate one of the two\nissues but ignore the other. In this paper, we address the over-confidence\nissue and the over-sensitivity issue existing in current RC models\nsimultaneously with the help of external linguistic knowledge. We first\nincorporate external knowledge to impose different linguistic constraints\n(entity constraint, lexical constraint, and predicate constraint), and then\nregularize RC models through posterior regularization. Linguistic constraints\ninduce more reasonable predictions for both semantic different and semantic\nequivalent adversarial examples, and posterior regularization provides an\neffective mechanism to incorporate these constraints. Our method can be applied\nto any existing neural RC models including state-of-the-art BERT models.\nExtensive experiments show that our method remarkably improves the robustness\nof base RC models, and is better to cope with these two issues simultaneously.", "published": "2019-11-16 03:41:40", "link": "http://arxiv.org/abs/1911.06948v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contribution au Niveau de l'Approche Indirecte \u00e0 Base de Transfert\n  dans la Traduction Automatique", "abstract": "In this thesis, we address several important issues concerning the\nmorphological analysis of Arabic language applied to textual data and machine\ntranslation. First, we provided an overview on machine translation, its history\nand its development, then we exposed human translation techniques for eventual\ninspiration in machine translation, and we exposed linguistic approaches and\nparticularly indirect transfer approaches. Finally, we presented our\ncontributions to the resolution of morphosyntactic problems in computer\nlinguistics as multilingual information retrieval and machine translation. As a\nfirst contribution, we developed a morphological analyzer for Arabic, and we\nhave exploited it in the bilingual information retrieval such as a computer\napplication of multilingual documentary. Results validation showed a\nstatistically significant performance. In a second contribution, we proposed a\nlist of morphosyntactic transfer rules from English to Arabic for translation\nin three phases: analysis, transfer, generation. We focused on the transfer\nphase without semantic distortion for an abstraction of English in a sufficient\nsubset of Arabic.", "published": "2019-11-16 13:34:16", "link": "http://arxiv.org/abs/1911.07030v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improved Document Modelling with a Neural Discourse Parser", "abstract": "Despite the success of attention-based neural models for natural language\ngeneration and classification tasks, they are unable to capture the discourse\nstructure of larger documents. We hypothesize that explicit discourse\nrepresentations have utility for NLP tasks over longer documents or document\nsequences, which sequence-to-sequence models are unable to capture. For\nabstractive summarization, for instance, conventional neural models simply\nmatch source documents and the summary in a latent space without explicit\nrepresentation of text structure or relations. In this paper, we propose to use\nneural discourse representations obtained from a rhetorical structure theory\n(RST) parser to enhance document representations. Specifically, document\nrepresentations are generated for discourse spans, known as the elementary\ndiscourse units (EDUs). We empirically investigate the benefit of the proposed\napproach on two different tasks: abstractive summarization and popularity\nprediction of online petitions. We find that the proposed approach leads to\nimprovements in all cases.", "published": "2019-11-16 00:07:09", "link": "http://arxiv.org/abs/1911.06919v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Automated Sexual Violence Report Tracking", "abstract": "Tracking sexual violence is a challenging task. In this paper, we present a\nsupervised learning-based automated sexual violence report tracking model that\nis more scalable, and reliable than its crowdsource based counterparts. We\ndefine the sexual violence report tracking problem by considering victim,\nperpetrator contexts and the nature of the violence. We find that our model\ncould identify sexual violence reports with a precision and recall of 80.4% and\n83.4%, respectively. Moreover, we also applied the model during and after the\n\\#MeToo movement. Several interesting findings are discovered which are not\neasily identifiable from a shallow analysis.", "published": "2019-11-16 05:25:01", "link": "http://arxiv.org/abs/1911.06961v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Learning Autocomplete Systems as a Communication Game", "abstract": "We study textual autocomplete---the task of predicting a full sentence from a\npartial sentence---as a human-machine communication game. Specifically, we\nconsider three competing goals for effective communication: use as few tokens\nas possible (efficiency), transmit sentences faithfully (accuracy), and be\nlearnable to humans (interpretability). We propose an unsupervised approach\nwhich tackles all three desiderata by constraining the communication scheme to\nkeywords extracted from a source sentence for interpretability and optimizing\nthe efficiency-accuracy tradeoff. Our experiments show that this approach\nresults in an autocomplete system that is 52% more accurate at a given\nefficiency level compared to baselines, is robust to user variations, and saves\ntime by nearly 50% compared to typing full sentences.", "published": "2019-11-16 05:34:47", "link": "http://arxiv.org/abs/1911.06964v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AttaCut: A Fast and Accurate Neural Thai Word Segmenter", "abstract": "Word segmentation is a fundamental pre-processing step for Thai Natural\nLanguage Processing. The current off-the-shelf solutions are not benchmarked\nconsistently, so it is difficult to compare their trade-offs. We conducted a\nspeed and accuracy comparison of the popular systems on three different domains\nand found that the state-of-the-art deep learning system is slow and moreover\ndoes not use sub-word structures to guide the model. Here, we propose a fast\nand accurate neural Thai Word Segmenter that uses dilated CNN filters to\ncapture the environment of each character and uses syllable embeddings as\nfeatures. Our system runs at least 5.6x faster and outperforms the previous\nstate-of-the-art system on some domains. In addition, we develop the first\nML-based Thai orthographical syllable segmenter, which yields syllable\nembeddings to be used as features by the word segmenter.", "published": "2019-11-16 16:27:44", "link": "http://arxiv.org/abs/1911.07056v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Understanding and Improving Layer Normalization", "abstract": "Layer normalization (LayerNorm) is a technique to normalize the distributions\nof intermediate layers. It enables smoother gradients, faster training, and\nbetter generalization accuracy. However, it is still unclear where the\neffectiveness stems from. In this paper, our main contribution is to take a\nstep further in understanding LayerNorm. Many of previous studies believe that\nthe success of LayerNorm comes from forward normalization. Unlike them, we find\nthat the derivatives of the mean and variance are more important than forward\nnormalization by re-centering and re-scaling backward gradients. Furthermore,\nwe find that the parameters of LayerNorm, including the bias and gain, increase\nthe risk of over-fitting and do not work in most cases. Experiments show that a\nsimple version of LayerNorm (LayerNorm-simple) without the bias and gain\noutperforms LayerNorm on four datasets. It obtains the state-of-the-art\nperformance on En-Vi machine translation. To address the over-fitting problem,\nwe propose a new normalization method, Adaptive Normalization (AdaNorm), by\nreplacing the bias and gain with a new transformation function. Experiments\nshow that AdaNorm demonstrates better results than LayerNorm on seven out of\neight datasets.", "published": "2019-11-16 11:00:16", "link": "http://arxiv.org/abs/1911.07013v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Classification as Decoder: Trading Flexibility for Control in Medical\n  Dialogue", "abstract": "Generative seq2seq dialogue systems are trained to predict the next word in\ndialogues that have already occurred. They can learn from large unlabeled\nconversation datasets, build a deeper understanding of conversational context,\nand generate a wide variety of responses. This flexibility comes at the cost of\ncontrol, a concerning tradeoff in doctor/patient interactions. Inaccuracies,\ntypos, or undesirable content in the training data will be reproduced by the\nmodel at inference time. We trade a small amount of labeling effort and some\nloss of response variety in exchange for quality control. More specifically, a\npretrained language model encodes the conversational context, and we finetune a\nclassification head to map an encoded conversational context to a response\nclass, where each class is a noisily labeled group of interchangeable\nresponses. Experts can update these exemplar responses over time as best\npractices change without retraining the classifier or invalidating old training\ndata. Expert evaluation of 775 unseen doctor/patient conversations shows that\nonly 12% of the discriminative model's responses are worse than the what the\ndoctor ended up writing, compared to 18% for the generative model.", "published": "2019-11-16 01:58:27", "link": "http://arxiv.org/abs/1911.08554v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "N-HANS: Introducing the Augsburg Neuro-Holistic Audio-eNhancement System", "abstract": "N-HANS is a Python toolkit for in-the-wild audio enhancement, including\nspeech, music, and general audio denoising, separation, and selective noise or\nsource suppression. The functionalities are realised based on two neural\nnetwork models sharing the same architecture, but trained separately. The\nmodels are comprised of stacks of residual blocks, each conditioned on\nadditional speech or environmental noise recordings for adapting to different\nunseen speakers or environments in real life. In addition to a Python API, a\ncommand line interface is provided to researchers and developers, both of which\nare documented at https://github.com/N-HANS/N-HANS. Experimental results\nindicate that N-HANS achieves outstanding performance, and ensure its reliable\nusage in real-life audio and speech-related tasks, reaching very high audio and\nspeech quality.", "published": "2019-11-16 17:30:00", "link": "http://arxiv.org/abs/1911.07062v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "VOICe: A Sound Event Detection Dataset For Generalizable Domain\n  Adaptation", "abstract": "The performance of sound event detection methods can significantly degrade\nwhen they are used in unseen conditions (e.g. recording devices, ambient\nnoise). Domain adaptation is a promising way to tackle this problem. In this\npaper, we present VOICe, the first dataset for the development and evaluation\nof domain adaptation methods for sound event detection. VOICe consists of\nmixtures with three different sound events (\"baby crying\", \"glass breaking\",\nand \"gunshot\"), which are over-imposed over three different categories of\nacoustic scenes: vehicle, outdoors, and indoors. Moreover, the mixtures are\nalso offered without any background noise. VOICe is freely available online\n(https://doi.org/10.5281/zenodo.3514950). In addition, using an\nadversarial-based training method, we evaluate the performance of a domain\nadaptation method on VOICe.", "published": "2019-11-16 21:00:48", "link": "http://arxiv.org/abs/1911.07098v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Music theme recognition using CNN and self-attention", "abstract": "We present an efficient architecture to detect mood/themes in music tracks on\nautotagging-moodtheme subset of the MTG-Jamendo dataset. Our approach consists\nof two blocks, a CNN block based on MobileNetV2 architecture and a\nself-attention block from Transformer architecture to capture long term\ntemporal characteristics. We show that our proposed model produces a\nsignificant improvement over the baseline model. Our model (team name: AMLAG)\nachieves 4th place on PR-AUC-macro Leaderboard in MediaEval 2019: Emotion and\nTheme Recognition in Music Using Jamendo.", "published": "2019-11-16 14:53:01", "link": "http://arxiv.org/abs/1911.07041v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
