{"title": "Recursive Graphical Neural Networks for Text Classification", "abstract": "The complicated syntax structure of natural language is hard to be explicitly\nmodeled by sequence-based models. Graph is a natural structure to describe the\ncomplicated relation between tokens. The recent advance in Graph Neural\nNetworks (GNN) provides a powerful tool to model graph structure data, but\nsimple graph models such as Graph Convolutional Networks (GCN) suffer from\nover-smoothing problem, that is, when stacking multiple layers, all nodes will\nconverge to the same value. In this paper, we propose a novel Recursive\nGraphical Neural Networks model (ReGNN) to represent text organized in the form\nof graph. In our proposed model, LSTM is used to dynamically decide which part\nof the aggregated neighbor information should be transmitted to upper layers\nthus alleviating the over-smoothing problem. Furthermore, to encourage the\nexchange between the local and global information, a global graph-level node is\ndesigned. We conduct experiments on both single and multiple label text\nclassification tasks. Experiment results show that our ReGNN model surpasses\nthe strong baselines significantly in most of the datasets and greatly\nalleviates the over-smoothing problem.", "published": "2019-09-18 01:54:53", "link": "http://arxiv.org/abs/1909.08166v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Natural Language Inference with a Pretrained Parser", "abstract": "We introduce a novel approach to incorporate syntax into natural language\ninference (NLI) models. Our method uses contextual token-level vector\nrepresentations from a pretrained dependency parser. Like other contextual\nembedders, our method is broadly applicable to any neural model. We experiment\nwith four strong NLI models (decomposable attention model, ESIM, BERT, and\nMT-DNN), and show consistent benefit to accuracy across three NLI benchmarks.", "published": "2019-09-18 05:54:32", "link": "http://arxiv.org/abs/1909.08217v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pre-trained Language Model for Biomedical Question Answering", "abstract": "The recent success of question answering systems is largely attributed to\npre-trained language models. However, as language models are mostly pre-trained\non general domain corpora such as Wikipedia, they often have difficulty in\nunderstanding biomedical questions. In this paper, we investigate the\nperformance of BioBERT, a pre-trained biomedical language model, in answering\nbiomedical questions including factoid, list, and yes/no type questions.\nBioBERT uses almost the same structure across various question types and\nachieved the best performance in the 7th BioASQ Challenge (Task 7b, Phase B).\nBioBERT pre-trained on SQuAD or SQuAD 2.0 easily outperformed previous\nstate-of-the-art models. BioBERT obtains the best performance when it uses the\nappropriate pre-/post-processing strategies for questions, passages, and\nanswers.", "published": "2019-09-18 06:53:30", "link": "http://arxiv.org/abs/1909.08229v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Text Length Adaptation in Sentiment Classification", "abstract": "Can a text classifier generalize well for datasets where the text length is\ndifferent? For example, when short reviews are sentiment-labeled, can these\ntransfer to predict the sentiment of long reviews (i.e., short to long\ntransfer), or vice versa? While unsupervised transfer learning has been\nwell-studied for cross domain/lingual transfer tasks, Cross Length Transfer\n(CLT) has not yet been explored. One reason is the assumption that length\ndifference is trivially transferable in classification. We show that it is not,\nbecause short/long texts differ in context richness and word intensity. We\ndevise new benchmark datasets from diverse domains and languages, and show that\nexisting models from similar tasks cannot deal with the unique challenge of\ntransferring across text lengths. We introduce a strong baseline model called\nBaggedCNN that treats long texts as bags containing short texts. We propose a\nstate-of-the-art CLT model called Length Transfer Networks (LeTraNets) that\nintroduces a two-way encoding scheme for short and long texts using multiple\ntraining mechanisms. We test our models and find that existing models perform\nworse than the BaggedCNN baseline, while LeTraNets outperforms all models.", "published": "2019-09-18 09:21:28", "link": "http://arxiv.org/abs/1909.08306v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Subword ELMo", "abstract": "Embedding from Language Models (ELMo) has shown to be effective for improving\nmany natural language processing (NLP) tasks, and ELMo takes character\ninformation to compose word representation to train language models.However,\nthe character is an insufficient and unnatural linguistic unit for word\nrepresentation.Thus we introduce Embedding from Subword-aware Language Models\n(ESuLMo) which learns word representation from subwords using unsupervised\nsegmentation over words.We show that ESuLMo can enhance four benchmark NLP\ntasks more effectively than ELMo, including syntactic dependency parsing,\nsemantic role labeling, implicit discourse relation recognition and textual\nentailment, which brings a meaningful improvement over ELMo.", "published": "2019-09-18 11:14:53", "link": "http://arxiv.org/abs/1909.08357v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Using BERT for Word Sense Disambiguation", "abstract": "Word Sense Disambiguation (WSD), which aims to identify the correct sense of\na given polyseme, is a long-standing problem in NLP. In this paper, we propose\nto use BERT to extract better polyseme representations for WSD and explore\nseveral ways of combining BERT and the classifier. We also utilize sense\ndefinitions to train a unified classifier for all words, which enables the\nmodel to disambiguate unseen polysemes. Experiments show that our model\nachieves the state-of-the-art results on the standard English All-word WSD\nevaluation.", "published": "2019-09-18 11:15:22", "link": "http://arxiv.org/abs/1909.08358v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hierarchical Meta-Embeddings for Code-Switching Named Entity Recognition", "abstract": "In countries that speak multiple main languages, mixing up different\nlanguages within a conversation is commonly called code-switching. Previous\nworks addressing this challenge mainly focused on word-level aspects such as\nword embeddings. However, in many cases, languages share common subwords,\nespecially for closely related languages, but also for languages that are\nseemingly irrelevant. Therefore, we propose Hierarchical Meta-Embeddings (HME)\nthat learn to combine multiple monolingual word-level and subword-level\nembeddings to create language-agnostic lexical representations. On the task of\nNamed Entity Recognition for English-Spanish code-switching data, our model\nachieves the state-of-the-art performance in the multilingual settings. We also\nshow that, in cross-lingual settings, our model not only leverages closely\nrelated languages, but also learns from languages with different roots.\nFinally, we show that combining different subunits are crucial for capturing\ncode-switching entities.", "published": "2019-09-18 15:34:12", "link": "http://arxiv.org/abs/1909.08504v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Code-Switched Language Models Using Neural Based Synthetic Data from\n  Parallel Sentences", "abstract": "Training code-switched language models is difficult due to lack of data and\ncomplexity in the grammatical structure. Linguistic constraint theories have\nbeen used for decades to generate artificial code-switching sentences to cope\nwith this issue. However, this require external word alignments or constituency\nparsers that create erroneous results on distant languages. We propose a\nsequence-to-sequence model using a copy mechanism to generate code-switching\ndata by leveraging parallel monolingual translations from a limited source of\ncode-switching data. The model learns how to combine words from parallel\nsentences and identifies when to switch one language to the other. Moreover, it\ncaptures code-switching constraints by attending and aligning the words in\ninputs, without requiring any external knowledge. Based on experimental\nresults, the language model trained with the generated sentences achieves\nstate-of-the-art performance and improves end-to-end automatic speech\nrecognition.", "published": "2019-09-18 17:11:41", "link": "http://arxiv.org/abs/1909.08582v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-Lingual Contextual Word Embeddings Mapping With Multi-Sense Words\n  In Mind", "abstract": "Recent work in cross-lingual contextual word embedding learning cannot handle\nmulti-sense words well. In this work, we explore the characteristics of\ncontextual word embeddings and show the link between contextual word embeddings\nand word senses. We propose two improving solutions by considering contextual\nmulti-sense word embeddings as noise (removal) and by generating cluster level\naverage anchor embeddings for contextual multi-sense word embeddings\n(replacement). Experiments show that our solutions can improve the supervised\ncontextual word embeddings alignment for multi-sense words in a microscopic\nperspective without hurting the macroscopic performance on the bilingual\nlexicon induction task. For unsupervised alignment, our methods significantly\nimprove the performance on the bilingual lexicon induction task for more than\n10 points.", "published": "2019-09-18 20:10:32", "link": "http://arxiv.org/abs/1909.08681v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sentiment-Aware Recommendation System for Healthcare using Social Media", "abstract": "Over the last decade, health communities (known as forums) have evolved into\nplatforms where more and more users share their medical experiences, thereby\nseeking guidance and interacting with people of the community. The shared\ncontent, though informal and unstructured in nature, contains valuable medical\nand/or health-related information and can be leveraged to produce structured\nsuggestions to the common people. In this paper, at first we propose a stacked\ndeep learning model for sentiment analysis from the medical forum data. The\nstacked model comprises of Convolutional Neural Network (CNN) followed by a\nLong Short Term Memory (LSTM) and then by another CNN. For a blog classified\nwith positive sentiment, we retrieve the top-n similar posts. Thereafter, we\ndevelop a probabilistic model for suggesting the suitable treatments or\nprocedures for a particular disease or health condition. We believe that\nintegration of medical sentiment and suggestion would be beneficial to the\nusers for finding the relevant contents regarding medications and medical\nconditions, without having to manually stroll through a large amount of\nunstructured contents.", "published": "2019-09-18 20:20:25", "link": "http://arxiv.org/abs/1909.08686v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modeling Conversation Structure and Temporal Dynamics for Jointly\n  Predicting Rumor Stance and Veracity", "abstract": "Automatically verifying rumorous information has become an important and\nchallenging task in natural language processing and social media analytics.\nPrevious studies reveal that people's stances towards rumorous messages can\nprovide indicative clues for identifying the veracity of rumors, and thus\ndetermining the stances of public reactions is a crucial preceding step for\nrumor veracity prediction. In this paper, we propose a hierarchical multi-task\nlearning framework for jointly predicting rumor stance and veracity on Twitter,\nwhich consists of two components. The bottom component of our framework\nclassifies the stances of tweets in a conversation discussing a rumor via\nmodeling the structural property based on a novel graph convolutional network.\nThe top component predicts the rumor veracity by exploiting the temporal\ndynamics of stance evolution. Experimental results on two benchmark datasets\nshow that our method outperforms previous methods in both rumor stance\nclassification and veracity prediction.", "published": "2019-09-18 05:02:56", "link": "http://arxiv.org/abs/1909.08211v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Natural Language Generation for Non-Expert Users", "abstract": "Motivated by the difficulty in presenting computational results, especially\nwhen the results are a collection of atoms in a logical language, to users, who\nare not proficient in computer programming and/or the logical representation of\nthe results, we propose a system for automatic generation of natural language\ndescriptions for applications targeting mainstream users. Differently from many\nearlier systems with the same aim, the proposed system does not employ\ntemplates for the generation task. It assumes that there exist some natural\nlanguage sentences in the application domain and uses this repository for the\nnatural language description. It does not require, however, a large corpus as\nit is often required in machine learning approaches. The systems consist of two\nmain components. The first one aims at analyzing the sentences and constructs a\nGrammatical Framework (GF) for given sentences and is implemented using the\nStanford parser and an answer set program. The second component is for sentence\nconstruction and relies on GF Library. The paper includes two use cases to\ndemostrate the capability of the system. As the sentence construction is done\nvia GF, the paper includes a use case evaluation showing that the proposed\nsystem could also be utilized in addressing a challenge to create an abstract\nWikipedia, which is recently discussed in the BlueSky session of the 2018\nInternational Semantic Web Conference.", "published": "2019-09-18 07:09:07", "link": "http://arxiv.org/abs/1909.08250v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "A Lexical, Syntactic, and Semantic Perspective for Understanding Style\n  in Text", "abstract": "With a growing interest in modeling inherent subjectivity in natural\nlanguage, we present a linguistically-motivated process to understand and\nanalyze the writing style of individuals from three perspectives: lexical,\nsyntactic, and semantic. We discuss the stylistically expressive elements\nwithin each of these levels and use existing methods to quantify the linguistic\nintuitions related to some of these elements. We show that such a multi-level\nanalysis is useful for developing a well-knit understanding of style - which is\nindependent of the natural language task at hand, and also demonstrate its\nvalue in solving three downstream tasks: authors' style analysis, authorship\nattribution, and emotion prediction. We conduct experiments on a variety of\ndatasets, comprising texts from social networking sites, user reviews, legal\ndocuments, literary books, and newswire. The results on the aforementioned\ntasks and datasets illustrate that such a multi-level understanding of style,\nwhich has been largely ignored in recent works, models style-related\nsubjectivity in text and can be leveraged to improve performance on multiple\ndownstream tasks both qualitatively and quantitatively.", "published": "2019-09-18 10:55:46", "link": "http://arxiv.org/abs/1909.08349v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Simple, Scalable Adaptation for Neural Machine Translation", "abstract": "Fine-tuning pre-trained Neural Machine Translation (NMT) models is the\ndominant approach for adapting to new languages and domains. However,\nfine-tuning requires adapting and maintaining a separate model for each target\ntask. We propose a simple yet efficient approach for adaptation in NMT. Our\nproposed approach consists of injecting tiny task specific adapter layers into\na pre-trained model. These lightweight adapters, with just a small fraction of\nthe original model size, adapt the model to multiple individual tasks\nsimultaneously. We evaluate our approach on two tasks: (i) Domain Adaptation\nand (ii) Massively Multilingual NMT. Experiments on domain adaptation\ndemonstrate that our proposed approach is on par with full fine-tuning on\nvarious domains, dataset sizes and model capacities. On a massively\nmultilingual dataset of 103 languages, our adaptation approach bridges the gap\nbetween individual bilingual models and one massively multilingual model for\nmost language pairs, paving the way towards universal machine translation.", "published": "2019-09-18 14:38:34", "link": "http://arxiv.org/abs/1909.08478v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Word Recognition, Competition, and Activation in a Model of Visually\n  Grounded Speech", "abstract": "In this paper, we study how word-like units are represented and activated in\na recurrent neural model of visually grounded speech. The model used in our\nexperiments is trained to project an image and its spoken description in a\ncommon representation space. We show that a recurrent model trained on spoken\nsentences implicitly segments its input into word-like units and reliably maps\nthem to their correct visual referents. We introduce a methodology originating\nfrom linguistics to analyse the representation learned by neural networks --\nthe gating paradigm -- and show that the correct representation of a word is\nonly activated if the network has access to first phoneme of the target word,\nsuggesting that the network does not rely on a global acoustic pattern.\nFurthermore, we find out that not all speech frames (MFCC vectors in our case)\nplay an equal role in the final encoded representation of a given word, but\nthat some frames have a crucial effect on it. Finally, we suggest that word\nrepresentation could be activated through a process of lexical competition.", "published": "2019-09-18 15:00:56", "link": "http://arxiv.org/abs/1909.08491v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Alleviating Sequence Information Loss with Data Overlapping and Prime\n  Batch Sizes", "abstract": "In sequence modeling tasks the token order matters, but this information can\nbe partially lost due to the discretization of the sequence into data points.\nIn this paper, we study the imbalance between the way certain token pairs are\nincluded in data points and others are not. We denote this a token order\nimbalance (TOI) and we link the partial sequence information loss to a\ndiminished performance of the system as a whole, both in text and speech\nprocessing tasks. We then provide a mechanism to leverage the full token order\ninformation -Alleviated TOI- by iteratively overlapping the token composition\nof data points. For recurrent networks, we use prime numbers for the batch size\nto avoid redundancies when building batches from overlapped data points. The\nproposed method achieved state of the art performance in both text and speech\nrelated tasks.", "published": "2019-09-18 20:50:51", "link": "http://arxiv.org/abs/1909.08700v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CASA-NLU: Context-Aware Self-Attentive Natural Language Understanding\n  for Task-Oriented Chatbots", "abstract": "Natural Language Understanding (NLU) is a core component of dialog systems.\nIt typically involves two tasks - intent classification (IC) and slot labeling\n(SL), which are then followed by a dialogue management (DM) component. Such NLU\nsystems cater to utterances in isolation, thus pushing the problem of context\nmanagement to DM. However, contextual information is critical to the correct\nprediction of intents and slots in a conversation. Prior work on contextual NLU\nhas been limited in terms of the types of contextual signals used and the\nunderstanding of their impact on the model. In this work, we propose a\ncontext-aware self-attentive NLU (CASA-NLU) model that uses multiple signals,\nsuch as previous intents, slots, dialog acts and utterances over a variable\ncontext window, in addition to the current user utterance. CASA-NLU outperforms\na recurrent contextual NLU baseline on two conversational datasets, yielding a\ngain of up to 7% on the IC task for one of the datasets. Moreover, a\nnon-contextual variant of CASA-NLU achieves state-of-the-art performance for IC\ntask on standard public datasets - Snips and ATIS.", "published": "2019-09-18 21:00:04", "link": "http://arxiv.org/abs/1909.08705v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Weighed Domain-Invariant Representation Learning for Cross-domain\n  Sentiment Analysis", "abstract": "Cross-domain sentiment analysis is currently a hot topic in the research and\nengineering areas. One of the most popular frameworks in this field is the\ndomain-invariant representation learning (DIRL) paradigm, which aims to learn a\ndistribution-invariant feature representation across domains. However, in this\nwork, we find out that applying DIRL may harm domain adaptation when the label\ndistribution $\\rm{P}(\\rm{Y})$ changes across domains. To address this problem,\nwe propose a modification to DIRL, obtaining a novel weighted domain-invariant\nrepresentation learning (WDIRL) framework. We show that it is easy to transfer\nexisting SOTA DIRL models to WDIRL. Empirical studies on extensive cross-domain\nsentiment analysis tasks verified our statements and showed the effectiveness\nof our proposed solution.", "published": "2019-09-18 02:03:03", "link": "http://arxiv.org/abs/1909.08167v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Memory-Augmented Neural Networks for Machine Translation", "abstract": "Memory-augmented neural networks (MANNs) have been shown to outperform other\nrecurrent neural network architectures on a series of artificial sequence\nlearning tasks, yet they have had limited application to real-world tasks. We\nevaluate direct application of Neural Turing Machines (NTM) and Differentiable\nNeural Computers (DNC) to machine translation. We further propose and evaluate\ntwo models which extend the attentional encoder-decoder with capabilities\ninspired by memory augmented neural networks. We evaluate our proposed models\non IWSLT Vietnamese to English and ACL Romanian to English datasets. Our\nproposed models and the memory augmented neural networks perform similarly to\nthe attentional encoder-decoder on the Vietnamese to English translation task\nwhile have a 0.3-1.9 lower BLEU score for the Romanian to English task.\nInterestingly, our analysis shows that despite being equipped with additional\nflexibility and being randomly initialized memory augmented neural networks\nlearn an algorithm for machine translation almost identical to the attentional\nencoder-decoder.", "published": "2019-09-18 09:39:14", "link": "http://arxiv.org/abs/1909.08314v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Enriching BERT with Knowledge Graph Embeddings for Document\n  Classification", "abstract": "In this paper, we focus on the classification of books using short\ndescriptive texts (cover blurbs) and additional metadata. Building upon BERT, a\ndeep neural language model, we demonstrate how to combine text representations\nwith metadata and knowledge graph embeddings, which encode author information.\nCompared to the standard BERT approach we achieve considerably better results\nfor the classification task. For a more coarse-grained classification using\neight labels we achieve an F1- score of 87.20, while a detailed classification\nusing 343 labels yields an F1-score of 64.70. We make the source code and\ntrained models of our experiments publicly available", "published": "2019-09-18 12:40:39", "link": "http://arxiv.org/abs/1909.08402v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fine-Tuning Language Models from Human Preferences", "abstract": "Reward learning enables the application of reinforcement learning (RL) to\ntasks where reward is defined by human judgment, building a model of reward by\nasking humans questions. Most work on reward learning has used simulated\nenvironments, but complex information about values is often expressed in\nnatural language, and we believe reward learning for language is a key to\nmaking RL practical and safe for real-world tasks. In this paper, we build on\nadvances in generative pretraining of language models to apply reward learning\nto four natural language tasks: continuing text with positive sentiment or\nphysically descriptive language, and summarization tasks on the TL;DR and\nCNN/Daily Mail datasets. For stylistic continuation we achieve good results\nwith only 5,000 comparisons evaluated by humans. For summarization, models\ntrained with 60,000 comparisons copy whole sentences from the input but skip\nirrelevant preamble; this leads to reasonable ROUGE scores and very good\nperformance according to our human labelers, but may be exploiting the fact\nthat labelers rely on simple heuristics.", "published": "2019-09-18 17:33:39", "link": "http://arxiv.org/abs/1909.08593v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Do We Need Neural Models to Explain Human Judgments of Acceptability?", "abstract": "Native speakers can judge whether a sentence is an acceptable instance of\ntheir language. Acceptability provides a means of evaluating whether\ncomputational language models are processing language in a human-like manner.\nWe test the ability of computational language models, simple language features,\nand word embeddings to predict native English speakers judgments of\nacceptability on English-language essays written by non-native speakers. We\nfind that much of the sentence acceptability variance can be captured by a\ncombination of features including misspellings, word order, and word similarity\n(Pearson's r = 0.494). While predictive neural models fit acceptability\njudgments well (r = 0.527), we find that a 4-gram model with statistical\nsmoothing is just as good (r = 0.528). Thanks to incorporating a count of\nmisspellings, our 4-gram model surpasses both the previous unsupervised\nstate-of-the art (Lau et al., 2015; r = 0.472), and the average non-expert\nnative speaker (r = 0.46). Our results demonstrate that acceptability is well\ncaptured by n-gram statistics and simple language features.", "published": "2019-09-18 19:02:53", "link": "http://arxiv.org/abs/1909.08663v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Espresso: A Fast End-to-end Neural Speech Recognition Toolkit", "abstract": "We present Espresso, an open-source, modular, extensible end-to-end neural\nautomatic speech recognition (ASR) toolkit based on the deep learning library\nPyTorch and the popular neural machine translation toolkit fairseq. Espresso\nsupports distributed training across GPUs and computing nodes, and features\nvarious decoding approaches commonly employed in ASR, including look-ahead\nword-based language model fusion, for which a fast, parallelized decoder is\nimplemented. Espresso achieves state-of-the-art ASR performance on the WSJ,\nLibriSpeech, and Switchboard data sets among other end-to-end systems without\ndata augmentation, and is 4--11x faster for decoding than similar systems (e.g.\nESPnet).", "published": "2019-09-18 22:05:05", "link": "http://arxiv.org/abs/1909.08723v3", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Corporate IT-support Help-Desk Process Hybrid-Automation Solution with\n  Machine Learning Approach", "abstract": "Comprehensive IT support teams in large scale organizations require more man\npower for handling engagement and requests of employees from different channels\non a 24*7 basis. Automated email technical queries help desk is proposed to\nhave instant real-time quick solutions and email categorisation. Email topic\nmodelling with various machine learning, deep-learning approaches are compared\nwith different features for a scalable, generalised solution along with\nsure-shot static rules. Email's title, body, attachment, OCR text, and some\nfeature engineered custom features are given as input elements. XGBoost\ncascaded hierarchical models, Bi-LSTM model with word embeddings perform well\nshowing 77.3 overall accuracy For the real world corporate email data set. By\nintroducing the thresholding techniques, the overall automation system\narchitecture provides 85.6 percentage of accuracy for real world corporate\nemails. Combination of quick fixes, static rules, ML categorization as a low\ncost inference solution reduces 81 percentage of the human effort in the\nprocess of automation and real time implementation.", "published": "2019-09-18 10:07:01", "link": "http://arxiv.org/abs/1909.09018v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Language models and Automated Essay Scoring", "abstract": "In this paper, we present a new comparative study on automatic essay scoring\n(AES). The current state-of-the-art natural language processing (NLP) neural\nnetwork architectures are used in this work to achieve above human-level\naccuracy on the publicly available Kaggle AES dataset. We compare two powerful\nlanguage models, BERT and XLNet, and describe all the layers and network\narchitectures in these models. We elucidate the network architectures of BERT\nand XLNet using clear notation and diagrams and explain the advantages of\ntransformer architectures over traditional recurrent neural network\narchitectures. Linear algebra notation is used to clarify the functions of\ntransformers and attention mechanisms. We compare the results with more\ntraditional methods, such as bag of words (BOW) and long short term memory\n(LSTM) networks.", "published": "2019-09-18 18:50:18", "link": "http://arxiv.org/abs/1909.09482v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Bayesian Strategies for Likelihood Ratio Computation in Forensic Voice\n  Comparison with Automatic Systems", "abstract": "This paper explores several strategies for Forensic Voice Comparison (FVC),\naimed at improving the performance of the LRs when using generative Gaussian\nscore-to-LR models. First, different anchoring strategies are proposed, with\nthe objective of adapting the LR computation process to the case at hand,\nalways respecting the propositions defined for the particular case. Second, a\nfully-Bayesian Gaussian model is used to tackle the sparsity in the training\nscores that is often present when the proposed anchoring strategies are used.\nExperiments are performed using the 2014 i-Vector challenge set-up, which\npresents high variability in a telephone speech context. The results show that\nthe proposed fully-Bayesian model clearly outperforms a more common\nMaximum-Likelihood approach, leading to high robustness when the scores to\ntrain the model become sparse.", "published": "2019-09-18 09:39:41", "link": "http://arxiv.org/abs/1909.08315v1", "categories": ["eess.AS", "cs.CV", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Cutting Music Source Separation Some Slakh: A Dataset to Study the\n  Impact of Training Data Quality and Quantity", "abstract": "Music source separation performance has greatly improved in recent years with\nthe advent of approaches based on deep learning. Such methods typically require\nlarge amounts of labelled training data, which in the case of music consist of\nmixtures and corresponding instrument stems. However, stems are unavailable for\nmost commercial music, and only limited datasets have so far been released to\nthe public. It can thus be difficult to draw conclusions when comparing various\nsource separation methods, as the difference in performance may stem as much\nfrom better data augmentation techniques or training tricks to alleviate the\nlimited availability of training data, as from intrinsically better model\narchitectures and objective functions. In this paper, we present the\nsynthesized Lakh dataset (Slakh) as a new tool for music source separation\nresearch. Slakh consists of high-quality renderings of instrumental mixtures\nand corresponding stems generated from the Lakh MIDI dataset (LMD) using\nprofessional-grade sample-based virtual instruments. A first version,\nSlakh2100, focuses on 2100 songs, resulting in 145 hours of mixtures. While not\nfully comparable because it is purely instrumental, this dataset contains an\norder of magnitude more data than MUSDB18, the {\\it de facto} standard dataset\nin the field. We show that Slakh can be used to effectively augment existing\ndatasets for musical instrument separation, while opening the door to a wide\narray of data-intensive music signal analysis tasks.", "published": "2019-09-18 15:14:27", "link": "http://arxiv.org/abs/1909.08494v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Emotion Filtering at the Edge", "abstract": "Voice controlled devices and services have become very popular in the\nconsumer IoT. Cloud-based speech analysis services extract information from\nvoice inputs using speech recognition techniques. Services providers can thus\nbuild very accurate profiles of users' demographic categories, personal\npreferences, emotional states, etc., and may therefore significantly compromise\ntheir privacy. To address this problem, we have developed a privacy-preserving\nintermediate layer between users and cloud services to sanitize voice input\ndirectly at edge devices. We use CycleGAN-based speech conversion to remove\nsensitive information from raw voice input signals before regenerating\nneutralized signals for forwarding. We implement and evaluate our emotion\nfiltering approach using a relatively cheap Raspberry Pi 4, and show that\nperformance accuracy is not compromised at the edge. In fact, signals generated\nat the edge differ only slightly (~0.16%) from cloud-based approaches for\nspeech recognition. Experimental evaluation of generated signals show that\nidentification of the emotional state of a speaker can be reduced by ~91%.", "published": "2019-09-18 15:28:12", "link": "http://arxiv.org/abs/1909.08500v1", "categories": ["eess.AS", "cs.CR", "cs.HC", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Deep Latent Space Learning for Cross-modal Mapping of Audio and Visual\n  Signals", "abstract": "We propose a novel deep training algorithm for joint representation of audio\nand visual information which consists of a single stream network (SSNet)\ncoupled with a novel loss function to learn a shared deep latent space\nrepresentation of multimodal information. The proposed framework characterizes\nthe shared latent space by leveraging the class centers which helps to\neliminate the need for pairwise or triplet supervision. We quantitatively and\nqualitatively evaluate the proposed approach on VoxCeleb, a benchmarks\naudio-visual dataset on a multitude of tasks including cross-modal\nverification, cross-modal matching, and cross-modal retrieval. State-of-the-art\nperformance is achieved on cross-modal verification and matching while\ncomparable results are observed on the remaining applications. Our experiments\ndemonstrate the effectiveness of the technique for cross-modal biometric\napplications.", "published": "2019-09-18 20:18:44", "link": "http://arxiv.org/abs/1909.08685v1", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
