{"title": "Linguistic Analysis of Requirements of a Space Project and their\n  Conformity with the Recommendations Proposed by a Controlled Natural Language", "abstract": "The long term aim of the project carried out by the French National Space\nAgency (CNES) is to design a writing guide based on the real and regular\nwriting of requirements. As a first step in the project, this paper proposes a\nlin-guistic analysis of requirements written in French by CNES engineers. The\naim is to determine to what extent they conform to two rules laid down in\nINCOSE, a recent guide for writing requirements. Although CNES engineers are\nnot obliged to follow any Controlled Natural Language in their writing of\nrequirements, we believe that language regularities are likely to emerge from\nthis task, mainly due to the writers' experience. The issue is approached using\nnatural language processing tools to identify sentences that do not comply with\nINCOSE rules. We further review these sentences to understand why the\nrecommendations cannot (or should not) always be applied when specifying\nlarge-scale projects.", "published": "2014-06-06 18:09:59", "link": "http://arxiv.org/abs/1406.1765v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Recursive Neural Networks Can Learn Logical Semantics", "abstract": "Tree-structured recursive neural networks (TreeRNNs) for sentence meaning\nhave been successful for many applications, but it remains an open question\nwhether the fixed-length representations that they learn can support tasks as\ndemanding as logical deduction. We pursue this question by evaluating whether\ntwo such models---plain TreeRNNs and tree-structured neural tensor networks\n(TreeRNTNs)---can correctly learn to identify logical relationships such as\nentailment and contradiction using these representations. In our first set of\nexperiments, we generate artificial data from a logical grammar and use it to\nevaluate the models' ability to learn to handle basic relational reasoning,\nrecursive structures, and quantification. We then evaluate the models on the\nmore natural SICK challenge data. Both models perform competitively on the SICK\ndata and generalize well in all three experiments on simulated data, suggesting\nthat they can learn suitable representations for logical inference in natural\nlanguage.", "published": "2014-06-06 22:09:27", "link": "http://arxiv.org/abs/1406.1827v4", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
