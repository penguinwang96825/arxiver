{"title": "Detecting Incongruity Between News Headline and Body Text via a Deep\n  Hierarchical Encoder", "abstract": "Some news headlines mislead readers with overrated or false information, and\nidentifying them in advance will better assist readers in choosing proper news\nstories to consume. This research introduces million-scale pairs of news\nheadline and body text dataset with incongruity label, which can uniquely be\nutilized for detecting news stories with misleading headlines. On this dataset,\nwe develop two neural networks with hierarchical architectures that model a\ncomplex textual representation of news articles and measure the incongruity\nbetween the headline and the body text. We also present a data augmentation\nmethod that dramatically reduces the text input size a model handles by\nindependently investigating each paragraph of news stories, which further\nboosts the performance. Our experiments and qualitative evaluations demonstrate\nthat the proposed methods outperform existing approaches and efficiently detect\nnews stories with misleading headlines in the real world.", "published": "2018-11-17 00:21:10", "link": "http://arxiv.org/abs/1811.07066v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bilingual Dictionary Induction for Bantu Languages", "abstract": "We present a method for learning bilingual translation dictionaries between\nEnglish and Bantu languages. We show that exploiting the grammatical structure\ncommon to Bantu languages enables bilingual dictionary induction for languages\nwhere training data is unavailable.", "published": "2018-11-17 02:36:07", "link": "http://arxiv.org/abs/1811.07080v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unnamed Entity Recognition of Sense Mentions", "abstract": "We consider the problem of recognizing mentions of human senses in text. Our\ncontribution is a method for acquiring labeled data, and a learning method that\nis trained on this data. Experiments show the effectiveness of our proposed\ndata labeling approach and our learning model on the task of sense recognition\nin text.", "published": "2018-11-17 03:58:26", "link": "http://arxiv.org/abs/1811.07092v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sense Perception Common Sense Relationships", "abstract": "Often missing in existing knowledge bases of facts, are relationships that\nencode common sense knowledge about unnamed entities. In this paper, we propose\nto extract novel, common sense relationships pertaining to sense perception\nconcepts such as sound and smell.", "published": "2018-11-17 04:24:14", "link": "http://arxiv.org/abs/1811.07098v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Deep Dive into Anonymity: A Large Scale Analysis of Quora Questions", "abstract": "Anonymity forms an integral and important part of our digital life. It\nenables us to express our true selves without the fear of judgment. In this\npaper, we investigate the different aspects of anonymity in the social Q&A site\nQuora. The choice of Quora is motivated by the fact that this is one of the\nrare social Q&A sites that allow users to explicitly post anonymous questions\nand such activity in this forum has become normative rather than a taboo.\nThrough an analysis of 5.1 million questions, we observe that at a global scale\nalmost no difference manifests between the linguistic structure of the\nanonymous and the non-anonymous questions. We find that topical mixing at the\nglobal scale to be the primary reason for the absence. However, the differences\nstart to feature once we \"deep dive\" and (topically) cluster the questions and\ncompare the clusters that have high volumes of anonymous questions with those\nthat have low volumes of anonymous questions. In particular, we observe that\nthe choice to post the question as anonymous is dependent on the user's\nperception of anonymity and they often choose to speak about depression,\nanxiety, social ties and personal issues under the guise of anonymity. We\nfurther perform personality trait analysis and observe that the anonymous group\nof users has positive correlation with extraversion, agreeableness, and\nnegative correlation with openness. Subsequently, to gain further insights, we\nbuild an anonymity grid to identify the differences in the perception on\nanonymity of the user posting the question and the community of users answering\nit. We also look into the first response time of the questions and observe that\nit is lowest for topics which talk about personal and sensitive issues, which\nhints toward a higher degree of community support and user engagement.", "published": "2018-11-17 21:26:20", "link": "http://arxiv.org/abs/1811.07223v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Robust cross-domain disfluency detection with pattern match networks", "abstract": "In this paper we introduce a novel pattern match neural network architecture\nthat uses neighbor similarity scores as features, eliminating the need for\nfeature engineering in a disfluency detection task. We evaluate the approach in\ndisfluency detection for four different speech genres, showing that the\napproach is as effective as hand-engineered pattern match features when used on\nin-domain data and achieves superior performance in cross-domain scenarios.", "published": "2018-11-17 22:34:20", "link": "http://arxiv.org/abs/1811.07236v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "An Affect-Rich Neural Conversational Model with Biased Attention and\n  Weighted Cross-Entropy Loss", "abstract": "Affect conveys important implicit information in human communication. Having\nthe capability to correctly express affect during human-machine conversations\nis one of the major milestones in artificial intelligence. In recent years,\nextensive research on open-domain neural conversational models has been\nconducted. However, embedding affect into such models is still under explored.\nIn this paper, we propose an end-to-end affect-rich open-domain neural\nconversational model that produces responses not only appropriate in syntax and\nsemantics, but also with rich affect. Our model extends the Seq2Seq model and\nadopts VAD (Valence, Arousal and Dominance) affective notations to embed each\nword with affects. In addition, our model considers the effect of negators and\nintensifiers via a novel affective attention mechanism, which biases attention\ntowards affect-rich words in input sentences. Lastly, we train our model with\nan affect-incorporated objective function to encourage the generation of\naffect-rich words in the output responses. Evaluations based on both perplexity\nand human evaluations show that our model outperforms the state-of-the-art\nbaseline model of comparable size in producing natural and affect-rich\nresponses.", "published": "2018-11-17 02:29:18", "link": "http://arxiv.org/abs/1811.07078v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Emergence of linguistic conventions in multi-agent reinforcement\n  learning", "abstract": "Recently, emergence of signaling conventions, among which language is a prime\nexample, draws a considerable interdisciplinary interest ranging from game\ntheory, to robotics to evolutionary linguistics. Such a wide spectrum of\nresearch is based on much different assumptions and methodologies, but\ncomplexity of the problem precludes formulation of a unifying and commonly\naccepted explanation. We examine formation of signaling conventions in a\nframework of a multi-agent reinforcement learning model. When the network of\ninteractions between agents is a complete graph or a sufficiently dense random\ngraph, a global consensus is typically reached with the emerging language being\na nearly unique object-word mapping or containing some synonyms and homonyms.\nOn finite-dimensional lattices, the model gets trapped in disordered\nconfigurations with a local consensus only. Such a trapping can be avoided by\nintroducing a population renewal, which in the presence of superlinear\nreinforcement restores an ordinary surface-tension driven coarsening and\nconsiderably enhances formation of efficient signaling.", "published": "2018-11-17 18:38:09", "link": "http://arxiv.org/abs/1811.07208v1", "categories": ["physics.soc-ph", "cond-mat.stat-mech", "cs.CL"], "primary_category": "physics.soc-ph"}
{"title": "Improving Automatic Source Code Summarization via Deep Reinforcement\n  Learning", "abstract": "Code summarization provides a high level natural language description of the\nfunction performed by code, as it can benefit the software maintenance, code\ncategorization and retrieval. To the best of our knowledge, most\nstate-of-the-art approaches follow an encoder-decoder framework which encodes\nthe code into a hidden space and then decode it into natural language space,\nsuffering from two major drawbacks: a) Their encoders only consider the\nsequential content of code, ignoring the tree structure which is also critical\nfor the task of code summarization, b) Their decoders are typically trained to\npredict the next word by maximizing the likelihood of next ground-truth word\nwith previous ground-truth word given. However, it is expected to generate the\nentire sequence from scratch at test time. This discrepancy can cause an\n\\textit{exposure bias} issue, making the learnt decoder suboptimal. In this\npaper, we incorporate an abstract syntax tree structure as well as sequential\ncontent of code snippets into a deep reinforcement learning framework (i.e.,\nactor-critic network). The actor network provides the confidence of predicting\nthe next word according to current state. On the other hand, the critic network\nevaluates the reward value of all possible extensions of the current state and\ncan provide global guidance for explorations. We employ an advantage reward\ncomposed of BLEU metric to train both networks. Comprehensive experiments on a\nreal-world dataset show the effectiveness of our proposed model when compared\nwith some state-of-the-art methods.", "published": "2018-11-17 22:21:12", "link": "http://arxiv.org/abs/1811.07234v1", "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Unsupervised Post-processing of Word Vectors via Conceptor Negation", "abstract": "Word vectors are at the core of many natural language processing tasks.\nRecently, there has been interest in post-processing word vectors to enrich\ntheir semantic information. In this paper, we introduce a novel word vector\npost-processing technique based on matrix conceptors (Jaeger2014), a family of\nregularized identity maps. More concretely, we propose to use conceptors to\nsuppress those latent features of word vectors having high variances. The\nproposed method is purely unsupervised: it does not rely on any corpus or\nexternal linguistic database. We evaluate the post-processed word vectors on a\nbattery of intrinsic lexical evaluation tasks, showing that the proposed method\nconsistently outperforms existing state-of-the-art alternatives. We also show\nthat post-processed word vectors can be used for the downstream natural\nlanguage processing task of dialogue state tracking, yielding improved results\nin different dialogue domains.", "published": "2018-11-17 20:12:40", "link": "http://arxiv.org/abs/1811.11001v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Correcting the Common Discourse Bias in Linear Representation of\n  Sentences using Conceptors", "abstract": "Distributed representations of words, better known as word embeddings, have\nbecome important building blocks for natural language processing tasks.\nNumerous studies are devoted to transferring the success of unsupervised word\nembeddings to sentence embeddings. In this paper, we introduce a simple\nrepresentation of sentences in which a sentence embedding is represented as a\nweighted average of word vectors followed by a soft projection. We demonstrate\nthe effectiveness of this proposed method on the clinical semantic textual\nsimilarity task of the BioCreative/OHNLP Challenge 2018.", "published": "2018-11-17 20:20:20", "link": "http://arxiv.org/abs/1811.11002v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Representation Mixing for TTS Synthesis", "abstract": "Recent character and phoneme-based parametric TTS systems using deep learning\nhave shown strong performance in natural speech generation. However, the choice\nbetween character or phoneme input can create serious limitations for practical\ndeployment, as direct control of pronunciation is crucial in certain cases. We\ndemonstrate a simple method for combining multiple types of linguistic\ninformation in a single encoder, named representation mixing, enabling flexible\nchoice between character, phoneme, or mixed representations during inference.\nExperiments and user studies on a public audiobook corpus show the efficacy of\nour approach.", "published": "2018-11-17 22:45:15", "link": "http://arxiv.org/abs/1811.07240v2", "categories": ["cs.LG", "cs.CL", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Polyphonic audio tagging with sequentially labelled data using CRNN with\n  learnable gated linear units", "abstract": "Audio tagging aims to detect the types of sound events occurring in an audio\nrecording. To tag the polyphonic audio recordings, we propose to use\nConnectionist Temporal Classification (CTC) loss function on the top of\nConvolutional Recurrent Neural Network (CRNN) with learnable Gated Linear Units\n(GLU-CTC), based on a new type of audio label data: Sequentially Labelled Data\n(SLD). In GLU-CTC, CTC objective function maps the frame-level probability of\nlabels to clip-level probability of labels. To compare the mapping ability of\nGLU-CTC for sound events, we train a CRNN with GLU based on Global Max Pooling\n(GLU-GMP) and a CRNN with GLU based on Global Average Pooling (GLU-GAP). And we\nalso compare the proposed GLU-CTC system with the baseline system, which is a\nCRNN trained using CTC loss function without GLU. The experiments show that the\nGLU-CTC achieves an Area Under Curve (AUC) score of 0.882 in audio tagging,\noutperforming the GLU-GMP of 0.803, GLU-GAP of 0.766 and baseline system of\n0.837. That means based on the same CRNN model with GLU, the performance of CTC\nmapping is better than the GMP and GAP mapping. Given both based on the CTC\nmapping, the CRNN with GLU outperforms the CRNN without GLU.", "published": "2018-11-17 01:19:25", "link": "http://arxiv.org/abs/1811.07072v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "The Intrinsic Memorability of Everyday Sounds", "abstract": "Our aural experience plays an integral role in the perception and memory of\nthe events in our lives. Some of the sounds we encounter throughout the day\nstay lodged in our minds more easily than others; these, in turn, may serve as\npowerful triggers of our memories. In this paper, we measure the memorability\nof everyday sounds across 20,000 crowd-sourced aural memory games, and assess\nthe degree to which a sound's memorability is constant across subjects. We then\nuse this data to analyze the relationship between memorability and acoustic\nfeatures like harmonicity, spectral skew, and models of cognitive salience; we\nalso assess the relationship between memorability and high-level features with\na dependence on the sound source itself, such as its familiarity, valence,\narousal, source type, causal certainty, and verbalizability. We find that (1)\nour crowd-sourced measures of memorability and confusability are reliable and\nrobust across participants; (2) that the authors' measure of collective causal\nuncertainty detailed in our previous work, coupled with measures of\nvisualizability and valence, are the strongest individual predictors of\nmemorability; (3) that acoustic and salience features play a heightened role in\ndetermining \"confusability\" (the false positive selection rate associated with\na sound) relative to memorability, and that (4), within the framework of our\nassessment, memorability is an intrinsic property of the sounds from the\ndataset, shown to be independent of surrounding context. We suggest that\nmodeling these cognitive processes opens the door for human-inspired\ncompression of sound environments, automatic curation of large-scale\nenvironmental recording datasets, and real-time modification of aural events to\nalter their likelihood of memorability.", "published": "2018-11-17 02:46:45", "link": "http://arxiv.org/abs/1811.07082v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multipath-enabled private audio with noise", "abstract": "We address the problem of privately communicating audio messages to multiple\nlisteners in a reverberant room using a set of loudspeakers. We propose two\nmethods based on emitting noise. In the first method, the loudspeakers emit\nnoise signals that are appropriately filtered so that after echoing along\nmultiple paths in the room, they sum up and descramble to yield distinct\nmeaningful audio messages only at specific focusing spots, while being\nincoherent everywhere else. In the second method, adapted from wireless\ncommunications, we project noise signals onto the nullspace of the MIMO channel\nmatrix between the loudspeakers and listeners. Loudspeakers reproduce a sum of\nthe projected noise signals and intended messages. Again because of echoes, the\nMIMO nullspace changes across different locations in the room. Thus, the\nlisteners at focusing spots hear intended messages, while the acoustic channel\nof an eavesdropper at any other location is jammed. We show, using both\nnumerical and real experiments, that with a small number of speakers and a few\nimpulse response measurements, audio messages can indeed be communicated to a\nset of listeners while ensuring negligible intelligibility elsewhere.", "published": "2018-11-17 00:03:31", "link": "http://arxiv.org/abs/1811.07065v3", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Designing nearly tight window for improving time-frequency masking", "abstract": "Many audio signal processing methods are formulated in the time-frequency\n(T-F) domain which is obtained by the short-time Fourier transform (STFT). The\nproperties of the STFT are fully characterized by window function, number of\nfrequency channels, and time-shift. Thus, designing a better window is\nimportant for improving the performance of the processing especially when a\nless redundant T-F representation is desirable. While many window functions\nhave been proposed in the literature, they are designed to have a good\nfrequency response for analysis, which may not perform well in terms of signal\nprocessing. The window design must take the effect of the reconstruction (from\nthe T-F domain into the time domain) into account for improving the\nperformance. In this paper, an optimization-based design method of a nearly\ntight window is proposed to obtain a window performing well for the T-F domain\nsignal processing.", "published": "2018-11-17 10:04:43", "link": "http://arxiv.org/abs/1811.08783v2", "categories": ["eess.SP", "cs.SD", "eess.AS"], "primary_category": "eess.SP"}
