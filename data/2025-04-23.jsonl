{"title": "IberBench: LLM Evaluation on Iberian Languages", "abstract": "Large Language Models (LLMs) remain difficult to evaluate comprehensively,\nparticularly for languages other than English, where high-quality data is often\nlimited. Existing benchmarks and leaderboards are predominantly\nEnglish-centric, with only a few addressing other languages. These benchmarks\nfall short in several key areas: they overlook the diversity of language\nvarieties, prioritize fundamental Natural Language Processing (NLP)\ncapabilities over tasks of industrial relevance, and are static. With these\naspects in mind, we present IberBench, a comprehensive and extensible benchmark\ndesigned to assess LLM performance on both fundamental and industry-relevant\nNLP tasks, in languages spoken across the Iberian Peninsula and Ibero-America.\nIberBench integrates 101 datasets from evaluation campaigns and recent\nbenchmarks, covering 22 task categories such as sentiment and emotion analysis,\ntoxicity detection, and summarization. The benchmark addresses key limitations\nin current evaluation practices, such as the lack of linguistic diversity and\nstatic evaluation setups by enabling continual updates and community-driven\nmodel and dataset submissions moderated by a committee of experts. We evaluate\n23 LLMs ranging from 100 million to 14 billion parameters and provide empirical\ninsights into their strengths and limitations. Our findings indicate that (i)\nLLMs perform worse on industry-relevant tasks than in fundamental ones, (ii)\nperformance is on average lower for Galician and Basque, (iii) some tasks show\nresults close to random, and (iv) in other tasks LLMs perform above random but\nbelow shared task systems. IberBench offers open-source implementations for the\nentire evaluation pipeline, including dataset normalization and hosting,\nincremental evaluation of LLMs, and a publicly accessible leaderboard.", "published": "2025-04-23 17:48:25", "link": "http://arxiv.org/abs/2504.16921v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OptimAI: Optimization from Natural Language Using LLM-Powered AI Agents", "abstract": "Optimization plays a vital role in scientific research and practical\napplications, but formulating a concrete optimization problem described in\nnatural language into a mathematical form and selecting a suitable solver to\nsolve the problem requires substantial domain expertise. We introduce\n\\textbf{OptimAI}, a framework for solving \\underline{Optim}ization problems\ndescribed in natural language by leveraging LLM-powered \\underline{AI} agents,\nachieving superior performance over current state-of-the-art methods. Our\nframework is built upon four key roles: (1) a \\emph{formulator} that translates\nnatural language problem descriptions into precise mathematical formulations;\n(2) a \\emph{planner} that constructs a high-level solution strategy prior to\nexecution; and (3) a \\emph{coder} and a \\emph{code critic} capable of\ninteracting with the environment and reflecting on outcomes to refine future\nactions. Ablation studies confirm that all roles are essential; removing the\nplanner or code critic results in $5.8\\times$ and $3.1\\times$ drops in\nproductivity, respectively. Furthermore, we introduce UCB-based debug\nscheduling to dynamically switch between alternative plans, yielding an\nadditional $3.3\\times$ productivity gain. Our design emphasizes multi-agent\ncollaboration, allowing us to conveniently explore the synergistic effect of\ncombining diverse models within a unified system. Our approach attains 88.1\\%\naccuracy on the NLP4LP dataset and 71.2\\% on the Optibench (non-linear w/o\ntable) subset, reducing error rates by 58\\% and 50\\% respectively over prior\nbest results.", "published": "2025-04-23 17:45:05", "link": "http://arxiv.org/abs/2504.16918v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Tracing Thought: Using Chain-of-Thought Reasoning to Identify the LLM Behind AI-Generated Text", "abstract": "In recent years, the detection of AI-generated text has become a critical\narea of research due to concerns about academic integrity, misinformation, and\nethical AI deployment. This paper presents COT Fine-tuned, a novel framework\nfor detecting AI-generated text and identifying the specific language model.\nresponsible for generating the text. We propose a dual-task approach, where\nTask A involves classifying text as AI-generated or human-written, and Task B\nidentifies the specific LLM behind the text. The key innovation of our method\nlies in the use of Chain-of-Thought reasoning, which enables the model to\ngenerate explanations for its predictions, enhancing transparency and\ninterpretability. Our experiments demonstrate that COT Fine-tuned achieves high\naccuracy in both tasks, with strong performance in LLM identification and\nhuman-AI classification. We also show that the CoT reasoning process\ncontributes significantly to the models effectiveness and interpretability.", "published": "2025-04-23 17:39:49", "link": "http://arxiv.org/abs/2504.16913v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AIMO-2 Winning Solution: Building State-of-the-Art Mathematical Reasoning Models with OpenMathReasoning dataset", "abstract": "This paper presents our winning submission to the AI Mathematical Olympiad -\nProgress Prize 2 (AIMO-2) competition. Our recipe for building state-of-the-art\nmathematical reasoning models relies on three key pillars. First, we create a\nlarge-scale dataset comprising 540K unique high-quality math problems,\nincluding olympiad-level problems, and their 3.2M long-reasoning solutions.\nSecond, we develop a novel method to integrate code execution with long\nreasoning models through iterative training, generation, and quality filtering,\nresulting in 1.7M high-quality Tool-Integrated Reasoning solutions. Third, we\ncreate a pipeline to train models to select the most promising solution from\nmany candidates. We show that such generative solution selection (GenSelect)\ncan significantly improve upon majority voting baseline. Combining these ideas,\nwe train a series of models that achieve state-of-the-art results on\nmathematical reasoning benchmarks. To facilitate further research, we release\nour code, models, and the complete OpenMathReasoning dataset under a\ncommercially permissive license.", "published": "2025-04-23 17:13:04", "link": "http://arxiv.org/abs/2504.16891v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Do Large Language Models know who did what to whom?", "abstract": "Large Language Models (LLMs) are commonly criticized for not understanding\nlanguage. However, many critiques focus on cognitive abilities that, in humans,\nare distinct from language processing. Here, we instead study a kind of\nunderstanding tightly linked to language: inferring who did what to whom\n(thematic roles) in a sentence. Does the central training objective of\nLLMs-word prediction-result in sentence representations that capture thematic\nroles? In two experiments, we characterized sentence representations in four\nLLMs. In contrast to human similarity judgments, in LLMs the overall\nrepresentational similarity of sentence pairs reflected syntactic similarity\nbut not whether their agent and patient assignments were identical vs.\nreversed. Furthermore, we found little evidence that thematic role information\nwas available in any subset of hidden units. However, some attention heads\nrobustly captured thematic roles, independently of syntax. Therefore, LLMs can\nextract thematic roles but, relative to humans, this information influences\ntheir representations more weakly.", "published": "2025-04-23 17:00:45", "link": "http://arxiv.org/abs/2504.16884v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Planning with Diffusion Models for Target-Oriented Dialogue Systems", "abstract": "Target-Oriented Dialogue (TOD) remains a significant challenge in the LLM\nera, where strategic dialogue planning is crucial for directing conversations\ntoward specific targets. However, existing dialogue planning methods generate\ndialogue plans in a step-by-step sequential manner, and may suffer from\ncompounding errors and myopic actions. To address these limitations, we\nintroduce a novel dialogue planning framework, DiffTOD, which leverages\ndiffusion models to enable non-sequential dialogue planning. DiffTOD formulates\ndialogue planning as a trajectory generation problem with conditional guidance,\nand leverages a diffusion language model to estimate the likelihood of the\ndialogue trajectory. To optimize the dialogue action strategies, DiffTOD\nintroduces three tailored guidance mechanisms for different target types,\noffering flexible guidance towards diverse TOD targets at test time. Extensive\nexperiments across three diverse TOD settings show that DiffTOD can effectively\nperform non-myopic lookahead exploration and optimize action strategies over a\nlong horizon through non-sequential dialogue planning, and demonstrates strong\nflexibility across complex and diverse dialogue scenarios. Our code and data\nare accessible through https://anonymous.4open.science/r/DiffTOD.", "published": "2025-04-23 16:27:15", "link": "http://arxiv.org/abs/2504.16858v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Emo Pillars: Knowledge Distillation to Support Fine-Grained Context-Aware and Context-Less Emotion Classification", "abstract": "Most datasets for sentiment analysis lack context in which an opinion was\nexpressed, often crucial for emotion understanding, and are mainly limited by a\nfew emotion categories. Foundation large language models (LLMs) like GPT-4\nsuffer from over-predicting emotions and are too resource-intensive. We design\nan LLM-based data synthesis pipeline and leverage a large model, Mistral-7b,\nfor the generation of training examples for more accessible, lightweight\nBERT-type encoder models. We focus on enlarging the semantic diversity of\nexamples and propose grounding the generation into a corpus of narratives to\nproduce non-repetitive story-character-centered utterances with unique contexts\nover 28 emotion classes. By running 700K inferences in 450 GPU hours, we\ncontribute with the dataset of 100K contextual and also 300K context-less\nexamples to cover both scenarios. We use it for fine-tuning pre-trained\nencoders, which results in several Emo Pillars models. We show that Emo Pillars\nmodels are highly adaptive to new domains when tuned to specific tasks such as\nGoEmotions, ISEAR, IEMOCAP, and EmoContext, reaching the SOTA performance on\nthe first three. We also validate our dataset, conducting statistical analysis\nand human evaluation, and confirm the success of our measures in utterance\ndiversification (although less for the neutral class) and context\npersonalization, while pointing out the need for improved handling of\nout-of-taxonomy labels within the pipeline.", "published": "2025-04-23 16:23:17", "link": "http://arxiv.org/abs/2504.16856v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Monte Carlo Planning with Large Language Model for Text-Based Game Agents", "abstract": "Text-based games provide valuable environments for language-based autonomous\nagents. However, planning-then-learning paradigms, such as those combining\nMonte Carlo Tree Search (MCTS) and reinforcement learning (RL), are notably\ntime-consuming due to extensive iterations. Additionally, these algorithms\nperform uncertainty-driven exploration but lack language understanding and\nreasoning abilities. In this paper, we introduce the Monte Carlo planning with\nDynamic Memory-guided Large language model (MC-DML) algorithm. MC-DML leverages\nthe language understanding and reasoning capabilities of Large Language Models\n(LLMs) alongside the exploratory advantages of tree search algorithms.\nSpecifically, we enhance LLMs with in-trial and cross-trial memory mechanisms,\nenabling them to learn from past experiences and dynamically adjust action\nevaluations during planning. We conduct experiments on a series of text-based\ngames from the Jericho benchmark. Our results demonstrate that the MC-DML\nalgorithm significantly enhances performance across various games at the\ninitial planning phase, outperforming strong contemporary methods that require\nmultiple iterations. This demonstrates the effectiveness of our algorithm,\npaving the way for more efficient language-grounded planning in complex\nenvironments.", "published": "2025-04-23 16:23:15", "link": "http://arxiv.org/abs/2504.16855v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GreenMind: A Next-Generation Vietnamese Large Language Model for Structured and Logical Reasoning", "abstract": "Chain-of-Thought (CoT) is a robust approach for tackling LLM tasks that\nrequire intermediate reasoning steps prior to generating a final answer. In\nthis paper, we present GreenMind-Medium-14B-R1, the Vietnamese reasoning model\ninspired by the finetuning strategy based on Group Relative Policy\nOptimization. We also leverage a high-quality Vietnamese synthesized reasoning\ndataset and design two reward functions to tackle the main limitations of this\ntechnique: (i) language mixing, where we explicitly detect the presence of\nbiased language characters during the process of sampling tokens, and (ii) we\nleverage Sentence Transformer-based models to ensure that the generated\nreasoning content maintains factual correctness and does not distort the final\noutput. Experimental results on the Vietnamese dataset from the VLSP 2023\nChallenge demonstrate that our model outperforms prior works and enhances\nlinguistic consistency in its responses. Furthermore, we extend our evaluation\nto SeaExam-a multilingual multiple-choice dataset, showing the effectiveness of\nour reasoning method compared to few-shot prompting techniques.", "published": "2025-04-23 15:48:55", "link": "http://arxiv.org/abs/2504.16832v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Process Reward Models That Think", "abstract": "Step-by-step verifiers -- also known as process reward models (PRMs) -- are a\nkey ingredient for test-time scaling. PRMs require step-level supervision,\nmaking them expensive to train. This work aims to build data-efficient PRMs as\nverbalized step-wise reward models that verify every step in the solution by\ngenerating a verification chain-of-thought (CoT). We propose ThinkPRM, a long\nCoT verifier fine-tuned on orders of magnitude fewer process labels than those\nrequired by discriminative PRMs. Our approach capitalizes on the inherent\nreasoning abilities of long CoT models, and outperforms LLM-as-a-Judge and\ndiscriminative verifiers -- using only 1% of the process labels in PRM800K --\nacross several challenging benchmarks. Specifically, ThinkPRM beats the\nbaselines on ProcessBench, MATH-500, and AIME '24 under best-of-N selection and\nreward-guided search. In an out-of-domain evaluation on a subset of\nGPQA-Diamond and LiveCodeBench, our PRM surpasses discriminative verifiers\ntrained on the full PRM800K by 8% and 4.5%, respectively. Lastly, under the\nsame token budget, ThinkPRM scales up verification compute more effectively\ncompared to LLM-as-a-Judge, outperforming it by 7.2% on a subset of\nProcessBench. Our work highlights the value of generative, long CoT PRMs that\ncan scale test-time compute for verification while requiring minimal\nsupervision for training. Our code, data, and models will be released at\nhttps://github.com/mukhal/thinkprm.", "published": "2025-04-23 15:44:54", "link": "http://arxiv.org/abs/2504.16828v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "LLM-assisted Graph-RAG Information Extraction from IFC Data", "abstract": "IFC data has become the general building information standard for\ncollaborative work in the construction industry. However, IFC data can be very\ncomplicated because it allows for multiple ways to represent the same product\ninformation. In this research, we utilise the capabilities of LLMs to parse the\nIFC data with Graph Retrieval-Augmented Generation (Graph-RAG) technique to\nretrieve building object properties and their relations. We will show that,\ndespite limitations due to the complex hierarchy of the IFC data, the Graph-RAG\nparsing enhances generative LLMs like GPT-4o with graph-based knowledge,\nenabling natural language query-response retrieval without the need for a\ncomplex pipeline.", "published": "2025-04-23 15:31:11", "link": "http://arxiv.org/abs/2504.16813v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Random Long-Context Access for Mamba via Hardware-aligned Hierarchical Sparse Attention", "abstract": "A key advantage of Recurrent Neural Networks (RNNs) over Transformers is\ntheir linear computational and space complexity enables faster training and\ninference for long sequences. However, RNNs are fundamentally unable to\nrandomly access historical context, and simply integrating attention mechanisms\nmay undermine their efficiency advantages. To overcome this limitation, we\npropose \\textbf{H}ierarchical \\textbf{S}parse \\textbf{A}ttention (HSA), a novel\nattention mechanism that enhances RNNs with long-range random access\nflexibility while preserving their merits in efficiency and length\ngeneralization. HSA divides inputs into chunks, selecting the top-$k$ chunks\nand hierarchically aggregates information. The core innovation lies in learning\ntoken-to-chunk relevance based on fine-grained token-level information inside\neach chunk. This approach enhances the precision of chunk selection across both\nin-domain and out-of-domain context lengths. To make HSA efficient, we further\nintroduce a hardware-aligned kernel design. By combining HSA with Mamba, we\nintroduce RAMba, which achieves perfect accuracy in passkey retrieval across 64\nmillion contexts despite pre-training on only 4K-length contexts, and\nsignificant improvements on various downstream tasks, with nearly constant\nmemory footprint. These results show RAMba's huge potential in long-context\nmodeling.", "published": "2025-04-23 15:15:06", "link": "http://arxiv.org/abs/2504.16795v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Credible plan-driven RAG method for Multi-hop Question Answering", "abstract": "Multi-hop question answering (QA) presents a considerable challenge for\nRetrieval-Augmented Generation (RAG), requiring the structured decomposition of\ncomplex queries into logical reasoning paths and the generation of dependable\nintermediate results. However, deviations in reasoning paths or errors in\nintermediate results, which are common in current RAG methods, may propagate\nand accumulate throughout the reasoning process, diminishing the accuracy of\nthe answer to complex queries. To address this challenge, we propose the\nPlan-then-Act-and-Review (PAR RAG) framework, which is organized into three key\nstages: planning, act, and review, and aims to offer an interpretable and\nincremental reasoning paradigm for accurate and reliable multi-hop question\nanswering by mitigating error propagation.PAR RAG initially applies a top-down\nproblem decomposition strategy, formulating a comprehensive plan that\nintegrates multiple executable steps from a holistic viewpoint. This approach\navoids the pitfalls of local optima common in traditional RAG methods, ensuring\nthe accuracy of the entire reasoning path. Subsequently, PAR RAG incorporates a\nplan execution mechanism based on multi-granularity verification. By utilizing\nboth coarse-grained similarity information and fine-grained relevant data, the\nframework thoroughly checks and adjusts intermediate results, ensuring process\naccuracy while effectively managing error propagation and amplification.\nExperimental results on multi-hop QA datasets demonstrate that the PAR RAG\nframework substantially outperforms existing state-of-the-art methods in key\nmetrics, including EM and F1 scores.", "published": "2025-04-23 15:03:17", "link": "http://arxiv.org/abs/2504.16787v1", "categories": ["cs.CL", "cs.AI", "I.2.0"], "primary_category": "cs.CL"}
{"title": "MOOSComp: Improving Lightweight Long-Context Compressor via Mitigating Over-Smoothing and Incorporating Outlier Scores", "abstract": "Recent advances in large language models have significantly improved their\nability to process long-context input, but practical applications are\nchallenged by increased inference time and resource consumption, particularly\nin resource-constrained environments. To address these challenges, we propose\nMOOSComp, a token-classification-based long-context compression method that\nenhances the performance of a BERT-based compressor by mitigating the\nover-smoothing problem and incorporating outlier scores. In the training phase,\nwe add an inter-class cosine similarity loss term to penalize excessively\nsimilar token representations, thereby improving the token classification\naccuracy. During the compression phase, we introduce outlier scores to preserve\nrare but critical tokens that are prone to be discarded in task-agnostic\ncompression. These scores are integrated with the classifier's output, making\nthe compressor more generalizable to various tasks. Superior performance is\nachieved at various compression ratios on long-context understanding and\nreasoning benchmarks. Moreover, our method obtains a speedup of 3.3x at a 4x\ncompression ratio on a resource-constrained mobile device.", "published": "2025-04-23 15:02:53", "link": "http://arxiv.org/abs/2504.16786v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Evaluation Framework for AI Systems in \"the Wild\"", "abstract": "Generative AI (GenAI) models have become vital across industries, yet current\nevaluation methods have not adapted to their widespread use. Traditional\nevaluations often rely on benchmarks and fixed datasets, frequently failing to\nreflect real-world performance, which creates a gap between lab-tested outcomes\nand practical applications. This white paper proposes a comprehensive framework\nfor how we should evaluate real-world GenAI systems, emphasizing diverse,\nevolving inputs and holistic, dynamic, and ongoing assessment approaches. The\npaper offers guidance for practitioners on how to design evaluation methods\nthat accurately reflect real-time capabilities, and provides policymakers with\nrecommendations for crafting GenAI policies focused on societal impacts, rather\nthan fixed performance numbers or parameter sizes. We advocate for holistic\nframeworks that integrate performance, fairness, and ethics and the use of\ncontinuous, outcome-oriented methods that combine human and automated\nassessments while also being transparent to foster trust among stakeholders.\nImplementing these strategies ensures GenAI models are not only technically\nproficient but also ethically responsible and impactful.", "published": "2025-04-23 14:52:39", "link": "http://arxiv.org/abs/2504.16778v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "How Effective are Generative Large Language Models in Performing Requirements Classification?", "abstract": "In recent years, transformer-based large language models (LLMs) have\nrevolutionised natural language processing (NLP), with generative models\nopening new possibilities for tasks that require context-aware text generation.\nRequirements engineering (RE) has also seen a surge in the experimentation of\nLLMs for different tasks, including trace-link detection, regulatory\ncompliance, and others. Requirements classification is a common task in RE.\nWhile non-generative LLMs like BERT have been successfully applied to this\ntask, there has been limited exploration of generative LLMs. This gap raises an\nimportant question: how well can generative LLMs, which produce context-aware\noutputs, perform in requirements classification? In this study, we explore the\neffectiveness of three generative LLMs-Bloom, Gemma, and Llama-in performing\nboth binary and multi-class requirements classification. We design an extensive\nexperimental study involving over 400 experiments across three widely used\ndatasets (PROMISE NFR, Functional-Quality, and SecReq). Our study concludes\nthat while factors like prompt design and LLM architecture are universally\nimportant, others-such as dataset variations-have a more situational impact,\ndepending on the complexity of the classification task. This insight can guide\nfuture model development and deployment strategies, focusing on optimising\nprompt structures and aligning model architectures with task-specific needs for\nimproved performance.", "published": "2025-04-23 14:41:11", "link": "http://arxiv.org/abs/2504.16768v1", "categories": ["cs.CL", "cs.AI", "cs.SE"], "primary_category": "cs.CL"}
{"title": "HEMA : A Hippocampus-Inspired Extended Memory Architecture for Long-Context AI Conversations", "abstract": "Large language models (LLMs) struggle with maintaining coherence in extended\nconversations spanning hundreds of turns, despite performing well within their\ncontext windows. This paper introduces HEMA (Hippocampus-Inspired Extended\nMemory Architecture), a dual-memory system inspired by human cognitive\nprocesses. HEMA combines Compact Memory - a continuously updated one-sentence\nsummary preserving global narrative coherence, and Vector Memory - an episodic\nstore of chunk embeddings queried via cosine similarity. When integrated with a\n6B-parameter transformer, HEMA maintains coherent dialogues beyond 300 turns\nwhile keeping prompt length under 3,500 tokens. Experimental results show\nsubstantial improvements: factual recall accuracy increases from 41% to 87%,\nand human-rated coherence improves from 2.7 to 4.3 on a 5-point scale. With 10K\nindexed chunks, Vector Memory achieves P@5 >= 0.80 and R@50 >= 0.74, doubling\nthe area under the precision-recall curve compared to summarization-only\napproaches. Ablation studies reveal two key insights: semantic forgetting\nthrough age-weighted pruning reduces retrieval latency by 34% with minimal\nrecall loss, and a two-level summary hierarchy prevents cascade errors in\nultra-long conversations exceeding 1,000 turns. HEMA demonstrates that\ncombining verbatim recall with semantic continuity provides a practical\nsolution for privacy-aware conversational AI capable of month-long dialogues\nwithout model retraining.", "published": "2025-04-23 14:27:12", "link": "http://arxiv.org/abs/2504.16754v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "IRIS: Interactive Research Ideation System for Accelerating Scientific Discovery", "abstract": "The rapid advancement in capabilities of large language models (LLMs) raises\na pivotal question: How can LLMs accelerate scientific discovery? This work\ntackles the crucial first stage of research, generating novel hypotheses. While\nrecent work on automated hypothesis generation focuses on multi-agent\nframeworks and extending test-time compute, none of the approaches effectively\nincorporate transparency and steerability through a synergistic\nHuman-in-the-loop (HITL) approach. To address this gap, we introduce IRIS:\nInteractive Research Ideation System, an open-source platform designed for\nresearchers to leverage LLM-assisted scientific ideation. IRIS incorporates\ninnovative features to enhance ideation, including adaptive test-time compute\nexpansion via Monte Carlo Tree Search (MCTS), fine-grained feedback mechanism,\nand query-based literature synthesis. Designed to empower researchers with\ngreater control and insight throughout the ideation process. We additionally\nconduct a user study with researchers across diverse disciplines, validating\nthe effectiveness of our system in enhancing ideation. We open-source our code\nat https://github.com/Anikethh/IRIS-Interactive-Research-Ideation-System", "published": "2025-04-23 14:01:36", "link": "http://arxiv.org/abs/2504.16728v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "A Post-trainer's Guide to Multilingual Training Data: Uncovering Cross-lingual Transfer Dynamics", "abstract": "In order for large language models to be useful across the globe, they are\nfine-tuned to follow instructions on multilingual data. Despite the ubiquity of\nsuch post-training, a clear understanding of the dynamics that enable\ncross-lingual transfer remains elusive. This study examines cross-lingual\ntransfer (CLT) dynamics in realistic post-training settings. We study two model\nfamilies of up to 35B parameters in size trained on carefully controlled\nmixtures of multilingual data on three generative tasks with varying levels of\ncomplexity (summarization, instruction following, and mathematical reasoning)\nin both single-task and multi-task instruction tuning settings. Overall, we\nfind that the dynamics of cross-lingual transfer and multilingual performance\ncannot be explained by isolated variables, varying depending on the combination\nof post-training settings. Finally, we identify the conditions that lead to\neffective cross-lingual transfer in practice.", "published": "2025-04-23 12:52:49", "link": "http://arxiv.org/abs/2504.16677v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ParetoHqD: Fast Offline Multiobjective Alignment of Large Language Models using Pareto High-quality Data", "abstract": "Aligning large language models with multiple human expectations and values is\ncrucial for ensuring that they adequately serve a variety of user needs. To\nthis end, offline multiobjective alignment algorithms such as the\nRewards-in-Context algorithm have shown strong performance and efficiency.\nHowever, inappropriate preference representations and training with imbalanced\nreward scores limit the performance of such algorithms. In this work, we\nintroduce ParetoHqD that addresses the above issues by representing human\npreferences as preference directions in the objective space and regarding data\nnear the Pareto front as ''high-quality'' data. For each preference, ParetoHqD\nfollows a two-stage supervised fine-tuning process, where each stage uses an\nindividual Pareto high-quality training set that best matches its preference\ndirection. The experimental results have demonstrated the superiority of\nParetoHqD over five baselines on two multiobjective alignment tasks.", "published": "2025-04-23 11:35:57", "link": "http://arxiv.org/abs/2504.16628v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "TIFIN India at SemEval-2025: Harnessing Translation to Overcome Multilingual IR Challenges in Fact-Checked Claim Retrieval", "abstract": "We address the challenge of retrieving previously fact-checked claims in\nmonolingual and crosslingual settings - a critical task given the global\nprevalence of disinformation. Our approach follows a two-stage strategy: a\nreliable baseline retrieval system using a fine-tuned embedding model and an\nLLM-based reranker. Our key contribution is demonstrating how LLM-based\ntranslation can overcome the hurdles of multilingual information retrieval.\nAdditionally, we focus on ensuring that the bulk of the pipeline can be\nreplicated on a consumer GPU. Our final integrated system achieved a success@10\nscore of 0.938 and 0.81025 on the monolingual and crosslingual test sets,\nrespectively.", "published": "2025-04-23 11:34:35", "link": "http://arxiv.org/abs/2504.16627v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Debunking with Dialogue? Exploring AI-Generated Counterspeech to Challenge Conspiracy Theories", "abstract": "Counterspeech is a key strategy against harmful online content, but scaling\nexpert-driven efforts is challenging. Large Language Models (LLMs) present a\npotential solution, though their use in countering conspiracy theories is\nunder-researched. Unlike for hate speech, no datasets exist that pair\nconspiracy theory comments with expert-crafted counterspeech. We address this\ngap by evaluating the ability of GPT-4o, Llama 3, and Mistral to effectively\napply counterspeech strategies derived from psychological research provided\nthrough structured prompts. Our results show that the models often generate\ngeneric, repetitive, or superficial results. Additionally, they\nover-acknowledge fear and frequently hallucinate facts, sources, or figures,\nmaking their prompt-based use in practical applications problematic.", "published": "2025-04-23 10:32:45", "link": "http://arxiv.org/abs/2504.16604v1", "categories": ["cs.CL", "cs.AI", "cs.SI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Comparing Large Language Models and Traditional Machine Translation Tools for Translating Medical Consultation Summaries: A Pilot Study", "abstract": "This study evaluates how well large language models (LLMs) and traditional\nmachine translation (MT) tools translate medical consultation summaries from\nEnglish into Arabic, Chinese, and Vietnamese. It assesses both patient,\nfriendly and clinician, focused texts using standard automated metrics. Results\nshowed that traditional MT tools generally performed better, especially for\ncomplex texts, while LLMs showed promise, particularly in Vietnamese and\nChinese, when translating simpler summaries. Arabic translations improved with\ncomplexity due to the language's morphology. Overall, while LLMs offer\ncontextual flexibility, they remain inconsistent, and current evaluation\nmetrics fail to capture clinical relevance. The study highlights the need for\ndomain-specific training, improved evaluation methods, and human oversight in\nmedical translation.", "published": "2025-04-23 10:31:33", "link": "http://arxiv.org/abs/2504.16601v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PIS: Linking Importance Sampling and Attention Mechanisms for Efficient Prompt Compression", "abstract": "Large language models (LLMs) have achieved remarkable progress, demonstrating\nunprecedented capabilities across various natural language processing tasks.\nHowever, the high costs associated with such exceptional performance limit the\nwidespread adoption of LLMs, highlighting the need for prompt compression.\nExisting prompt compression methods primarily rely on heuristic truncation or\nabstractive summarization techniques, which fundamentally overlook the\nintrinsic mechanisms of LLMs and lack a systematic evaluation of token\nimportance for generation. In this work, we introduce Prompt Importance\nSampling (PIS), a novel compression framework that dynamically compresses\nprompts by sampling important tokens based on the analysis of attention scores\nof hidden states. PIS employs a dual-level compression mechanism: 1) at the\ntoken level, we quantify saliency using LLM-native attention scores and\nimplement adaptive compression through a lightweight 9-layer reinforcement\nlearning (RL) network; 2) at the semantic level, we propose a Russian roulette\nsampling strategy for sentence-level importance sampling. Comprehensive\nevaluations across multiple domain benchmarks demonstrate that our method\nachieves state-of-the-art compression performance. Notably, our framework\nserendipitously enhances reasoning efficiency through optimized context\nstructuring. This work advances prompt engineering by offering both theoretical\ngrounding and practical efficiency in context management for LLMs.", "published": "2025-04-23 09:53:01", "link": "http://arxiv.org/abs/2504.16574v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Transformers for Complex Query Answering over Knowledge Hypergraphs", "abstract": "Complex Query Answering (CQA) has been extensively studied in recent years.\nIn order to model data that is closer to real-world distribution, knowledge\ngraphs with different modalities have been introduced. Triple KGs, as the\nclassic KGs composed of entities and relations of arity 2, have limited\nrepresentation of real-world facts. Real-world data is more sophisticated.\nWhile hyper-relational graphs have been introduced, there are limitations in\nrepresenting relationships of varying arity that contain entities with equal\ncontributions. To address this gap, we sampled new CQA datasets: JF17k-HCQA and\nM-FB15k-HCQA. Each dataset contains various query types that include logical\noperations such as projection, negation, conjunction, and disjunction. In order\nto answer knowledge hypergraph (KHG) existential first-order queries, we\npropose a two-stage transformer model, the Logical Knowledge Hypergraph\nTransformer (LKHGT), which consists of a Projection Encoder for atomic\nprojection and a Logical Encoder for complex logical operations. Both encoders\nare equipped with Type Aware Bias (TAB) for capturing token interactions.\nExperimental results on CQA datasets show that LKHGT is a state-of-the-art CQA\nmethod over KHG and is able to generalize to out-of-distribution query types.", "published": "2025-04-23 09:07:21", "link": "http://arxiv.org/abs/2504.16537v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "QuaDMix: Quality-Diversity Balanced Data Selection for Efficient LLM Pretraining", "abstract": "Quality and diversity are two critical metrics for the training data of large\nlanguage models (LLMs), positively impacting performance. Existing studies\noften optimize these metrics separately, typically by first applying quality\nfiltering and then adjusting data proportions. However, these approaches\noverlook the inherent trade-off between quality and diversity, necessitating\ntheir joint consideration. Given a fixed training quota, it is essential to\nevaluate both the quality of each data point and its complementary effect on\nthe overall dataset. In this paper, we introduce a unified data selection\nframework called QuaDMix, which automatically optimizes the data distribution\nfor LLM pretraining while balancing both quality and diversity. Specifically,\nwe first propose multiple criteria to measure data quality and employ domain\nclassification to distinguish data points, thereby measuring overall diversity.\nQuaDMix then employs a unified parameterized data sampling function that\ndetermines the sampling probability of each data point based on these quality\nand diversity related labels. To accelerate the search for the optimal\nparameters involved in the QuaDMix framework, we conduct simulated experiments\non smaller models and use LightGBM for parameters searching, inspired by the\nRegMix method. Our experiments across diverse models and datasets demonstrate\nthat QuaDMix achieves an average performance improvement of 7.2% across\nmultiple benchmarks. These results outperform the independent strategies for\nquality and diversity, highlighting the necessity and ability to balance data\nquality and diversity.", "published": "2025-04-23 08:36:50", "link": "http://arxiv.org/abs/2504.16511v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "T-VEC: A Telecom-Specific Vectorization Model with Enhanced Semantic Understanding via Deep Triplet Loss Fine-Tuning", "abstract": "The specialized vocabulary and complex concepts of the telecommunications\nindustry present significant challenges for standard Natural Language\nProcessing models. Generic text embeddings often fail to capture\ntelecom-specific semantics, hindering downstream task performance. We introduce\nT-VEC (Telecom Vectorization Model), a novel embedding model tailored for the\ntelecom domain through deep fine-tuning. Developed by NetoAI, T-VEC is created\nby adapting the state-of-the-art gte-Qwen2-1.5B-instruct model using a triplet\nloss objective on a meticulously curated, large-scale dataset of\ntelecom-specific data. Crucially, this process involved substantial\nmodification of weights across 338 layers of the base model, ensuring deep\nintegration of domain knowledge, far exceeding superficial adaptation\ntechniques. We quantify this deep change via weight difference analysis. A key\ncontribution is the development and open-sourcing (MIT License) of the first\ndedicated telecom-specific tokenizer, enhancing the handling of industry\njargon. T-VEC achieves a leading average MTEB score (0.825) compared to\nestablished models and demonstrates vastly superior performance (0.9380 vs.\nless than 0.07) on our internal telecom-specific triplet evaluation benchmark,\nindicating an exceptional grasp of domain-specific nuances, visually confirmed\nby improved embedding separation. This work positions NetoAI at the forefront\nof telecom AI innovation, providing the community with a powerful, deeply\nadapted, open-source tool.", "published": "2025-04-23 07:10:37", "link": "http://arxiv.org/abs/2504.16460v1", "categories": ["cs.CL", "cs.AI", "68T50"], "primary_category": "cs.CL"}
{"title": "EMRModel: A Large Language Model for Extracting Medical Consultation Dialogues into Structured Medical Records", "abstract": "Medical consultation dialogues contain critical clinical information, yet\ntheir unstructured nature hinders effective utilization in diagnosis and\ntreatment. Traditional methods, relying on rule-based or shallow machine\nlearning techniques, struggle to capture deep and implicit semantics. Recently,\nlarge pre-trained language models and Low-Rank Adaptation (LoRA), a lightweight\nfine-tuning method, have shown promise for structured information extraction.\nWe propose EMRModel, a novel approach that integrates LoRA-based fine-tuning\nwith code-style prompt design, aiming to efficiently convert medical\nconsultation dialogues into structured electronic medical records (EMRs).\nAdditionally, we construct a high-quality, realistically grounded dataset of\nmedical consultation dialogues with detailed annotations. Furthermore, we\nintroduce a fine-grained evaluation benchmark for medical consultation\ninformation extraction and provide a systematic evaluation methodology,\nadvancing the optimization of medical natural language processing (NLP) models.\nExperimental results show EMRModel achieves an F1 score of 88.1%, improving\nby49.5% over standard pre-trained models. Compared to traditional LoRA\nfine-tuning methods, our model shows superior performance, highlighting its\neffectiveness in structured medical record extraction tasks.", "published": "2025-04-23 06:17:55", "link": "http://arxiv.org/abs/2504.16448v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MAGIC: Near-Optimal Data Attribution for Deep Learning", "abstract": "The goal of predictive data attribution is to estimate how adding or removing\na given set of training datapoints will affect model predictions. In convex\nsettings, this goal is straightforward (i.e., via the infinitesimal jackknife).\nIn large-scale (non-convex) settings, however, existing methods are far less\nsuccessful -- current methods' estimates often only weakly correlate with\nground truth. In this work, we present a new data attribution method (MAGIC)\nthat combines classical methods and recent advances in metadifferentiation to\n(nearly) optimally estimate the effect of adding or removing training data on\nmodel predictions.", "published": "2025-04-23 05:32:37", "link": "http://arxiv.org/abs/2504.16430v1", "categories": ["cs.LG", "cs.CL", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Can Large Language Models Help Multimodal Language Analysis? MMLA: A Comprehensive Benchmark", "abstract": "Multimodal language analysis is a rapidly evolving field that leverages\nmultiple modalities to enhance the understanding of high-level semantics\nunderlying human conversational utterances. Despite its significance, little\nresearch has investigated the capability of multimodal large language models\n(MLLMs) to comprehend cognitive-level semantics. In this paper, we introduce\nMMLA, a comprehensive benchmark specifically designed to address this gap. MMLA\ncomprises over 61K multimodal utterances drawn from both staged and real-world\nscenarios, covering six core dimensions of multimodal semantics: intent,\nemotion, dialogue act, sentiment, speaking style, and communication behavior.\nWe evaluate eight mainstream branches of LLMs and MLLMs using three methods:\nzero-shot inference, supervised fine-tuning, and instruction tuning. Extensive\nexperiments reveal that even fine-tuned models achieve only about 60%~70%\naccuracy, underscoring the limitations of current MLLMs in understanding\ncomplex human language. We believe that MMLA will serve as a solid foundation\nfor exploring the potential of large language models in multimodal language\nanalysis and provide valuable resources to advance this field. The datasets and\ncode are open-sourced at https://github.com/thuiar/MMLA.", "published": "2025-04-23 05:25:13", "link": "http://arxiv.org/abs/2504.16427v1", "categories": ["cs.CL", "cs.AI", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Evaluating Multi-Hop Reasoning in Large Language Models: A Chemistry-Centric Case Study", "abstract": "In this study, we introduced a new benchmark consisting of a curated dataset\nand a defined evaluation process to assess the compositional reasoning\ncapabilities of large language models within the chemistry domain. We designed\nand validated a fully automated pipeline, verified by subject matter experts,\nto facilitate this task. Our approach integrates OpenAI reasoning models with\nnamed entity recognition (NER) systems to extract chemical entities from recent\nliterature, which are then augmented with external knowledge bases to form a\ncomprehensive knowledge graph. By generating multi-hop questions across these\ngraphs, we assess LLM performance in both context-augmented and non-context\naugmented settings. Our experiments reveal that even state-of-the-art models\nface significant challenges in multi-hop compositional reasoning. The results\nreflect the importance of augmenting LLMs with document retrieval, which can\nhave a substantial impact on improving their performance. However, even perfect\nretrieval accuracy with full context does not eliminate reasoning errors,\nunderscoring the complexity of compositional reasoning. This work not only\nbenchmarks and highlights the limitations of current LLMs but also presents a\nnovel data generation pipeline capable of producing challenging reasoning\ndatasets across various domains. Overall, this research advances our\nunderstanding of reasoning in computational linguistics.", "published": "2025-04-23 04:36:19", "link": "http://arxiv.org/abs/2504.16414v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Out-of-the-Box Conditional Text Embeddings from Large Language Models", "abstract": "Conditional text embedding is a proposed representation that captures the\nshift in perspective on texts when conditioned on a specific aspect. Previous\nmethods have relied on extensive training data for fine-tuning models, leading\nto challenges in terms of labor and resource costs. We propose PonTE, a novel\nunsupervised conditional text embedding method that leverages a causal large\nlanguage model and a conditional prompt. Through experiments on conditional\nsemantic text similarity and text clustering, we demonstrate that PonTE can\ngenerate useful conditional text embeddings and achieve performance comparable\nto supervised methods without fine-tuning. We also show the interpretability of\ntext embeddings with PonTE by analyzing word generation following prompts and\nembedding visualization.", "published": "2025-04-23 04:27:15", "link": "http://arxiv.org/abs/2504.16411v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Less is More: Enhancing Structured Multi-Agent Reasoning via Quality-Guided Distillation", "abstract": "The XLLM@ACL2025 Shared Task-III formulates a low-resource structural\nreasoning task that challenges LLMs to generate interpretable, step-by-step\nrationales with minimal labeled data. We present Less is More, the third-place\nwinning approach in the XLLM@ACL2025 Shared Task-III, which focuses on\nstructured reasoning from only 24 labeled examples. Our approach leverages a\nmulti-agent framework with reverse-prompt induction, retrieval-augmented\nreasoning synthesis via GPT-4o, and dual-stage reward-guided filtering to\ndistill high-quality supervision across three subtasks: question parsing, CoT\nparsing, and step-level verification. All modules are fine-tuned from\nMeta-Llama-3-8B-Instruct under a unified LoRA+ setup. By combining structure\nvalidation with reward filtering across few-shot and zero-shot prompts, our\npipeline consistently improves structure reasoning quality. These results\nunderscore the value of controllable data distillation in enhancing structured\ninference under low-resource constraints. Our code is available at\nhttps://github.com/Jiahao-Yuan/Less-is-More.", "published": "2025-04-23 04:19:52", "link": "http://arxiv.org/abs/2504.16408v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ConTextual: Improving Clinical Text Summarization in LLMs with Context-preserving Token Filtering and Knowledge Graphs", "abstract": "Unstructured clinical data can serve as a unique and rich source of\ninformation that can meaningfully inform clinical practice. Extracting the most\npertinent context from such data is critical for exploiting its true potential\ntoward optimal and timely decision-making in patient care. While prior research\nhas explored various methods for clinical text summarization, most prior\nstudies either process all input tokens uniformly or rely on heuristic-based\nfilters, which can overlook nuanced clinical cues and fail to prioritize\ninformation critical for decision-making. In this study, we propose Contextual,\na novel framework that integrates a Context-Preserving Token Filtering method\nwith a Domain-Specific Knowledge Graph (KG) for contextual augmentation. By\npreserving context-specific important tokens and enriching them with structured\nknowledge, ConTextual improves both linguistic coherence and clinical fidelity.\nOur extensive empirical evaluations on two public benchmark datasets\ndemonstrate that ConTextual consistently outperforms other baselines. Our\nproposed approach highlights the complementary role of token-level filtering\nand structured retrieval in enhancing both linguistic and clinical integrity,\nas well as offering a scalable solution for improving precision in clinical\ntext generation.", "published": "2025-04-23 03:42:46", "link": "http://arxiv.org/abs/2504.16394v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SplitReason: Learning To Offload Reasoning", "abstract": "Reasoning in large language models (LLMs) tends to produce substantially\nlonger token generation sequences than simpler language modeling tasks. This\nextended generation length reflects the multi-step, compositional nature of\nreasoning and is often correlated with higher solution accuracy. From an\nefficiency perspective, longer token generation exacerbates the inherently\nsequential and memory-bound decoding phase of LLMs. However, not all parts of\nthis expensive reasoning process are equally difficult to generate. We leverage\nthis observation by offloading only the most challenging parts of the reasoning\nprocess to a larger, more capable model, while performing most of the\ngeneration with a smaller, more efficient model; furthermore, we teach the\nsmaller model to identify these difficult segments and independently trigger\noffloading when needed. To enable this behavior, we annotate difficult segments\nacross 18k reasoning traces from the OpenR1-Math-220k chain-of-thought (CoT)\ndataset. We then apply supervised fine-tuning (SFT) and reinforcement learning\nfine-tuning (RLFT) to a 1.5B-parameter reasoning model, training it to learn to\noffload the most challenging parts of its own reasoning process to a larger\nmodel. This approach improves AIME24 reasoning accuracy by 24% and 28.3% while\noffloading 1.35% and 5% of the generated tokens respectively. We open-source\nour SplitReason model, data, code and logs.", "published": "2025-04-23 03:00:02", "link": "http://arxiv.org/abs/2504.16379v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Text-to-TrajVis: Enabling Trajectory Data Visualizations from Natural Language Questions", "abstract": "This paper introduces the Text-to-TrajVis task, which aims to transform\nnatural language questions into trajectory data visualizations, facilitating\nthe development of natural language interfaces for trajectory visualization\nsystems. As this is a novel task, there is currently no relevant dataset\navailable in the community. To address this gap, we first devised a new\nvisualization language called Trajectory Visualization Language (TVL) to\nfacilitate querying trajectory data and generating visualizations. Building on\nthis foundation, we further proposed a dataset construction method that\nintegrates Large Language Models (LLMs) with human efforts to create\nhigh-quality data. Specifically, we first generate TVLs using a comprehensive\nand systematic process, and then label each TVL with corresponding natural\nlanguage questions using LLMs. This process results in the creation of the\nfirst large-scale Text-to-TrajVis dataset, named TrajVL, which contains 18,140\n(question, TVL) pairs. Based on this dataset, we systematically evaluated the\nperformance of multiple LLMs (GPT, Qwen, Llama, etc.) on this task. The\nexperimental results demonstrate that this task is both feasible and highly\nchallenging and merits further exploration within the research community.", "published": "2025-04-23 02:15:52", "link": "http://arxiv.org/abs/2504.16358v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transformer-Based Extraction of Statutory Definitions from the U.S. Code", "abstract": "Automatic extraction of definitions from legal texts is critical for\nenhancing the comprehension and clarity of complex legal corpora such as the\nUnited States Code (U.S.C.). We present an advanced NLP system leveraging\ntransformer-based architectures to automatically extract defined terms, their\ndefinitions, and their scope from the U.S.C. We address the challenges of\nautomatically identifying legal definitions, extracting defined terms, and\ndetermining their scope within this complex corpus of over 200,000 pages of\nfederal statutory law. Building upon previous feature-based machine learning\nmethods, our updated model employs domain-specific transformers (Legal-BERT)\nfine-tuned specifically for statutory texts, significantly improving extraction\naccuracy. Our work implements a multi-stage pipeline that combines document\nstructure analysis with state-of-the-art language models to process legal text\nfrom the XML version of the U.S. Code. Each paragraph is first classified using\na fine-tuned legal domain BERT model to determine if it contains a definition.\nOur system then aggregates related paragraphs into coherent definitional units\nand applies a combination of attention mechanisms and rule-based patterns to\nextract defined terms and their jurisdictional scope. The definition extraction\nsystem is evaluated on multiple titles of the U.S. Code containing thousands of\ndefinitions, demonstrating significant improvements over previous approaches.\nOur best model achieves 96.8% precision and 98.9% recall (98.2% F1-score),\nsubstantially outperforming traditional machine learning classifiers. This work\ncontributes to improving accessibility and understanding of legal information\nwhile establishing a foundation for downstream legal reasoning tasks.", "published": "2025-04-23 02:09:53", "link": "http://arxiv.org/abs/2504.16353v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "I-Con: A Unifying Framework for Representation Learning", "abstract": "As the field of representation learning grows, there has been a proliferation\nof different loss functions to solve different classes of problems. We\nintroduce a single information-theoretic equation that generalizes a large\ncollection of modern loss functions in machine learning. In particular, we\nintroduce a framework that shows that several broad classes of machine learning\nmethods are precisely minimizing an integrated KL divergence between two\nconditional distributions: the supervisory and learned representations. This\nviewpoint exposes a hidden information geometry underlying clustering, spectral\nmethods, dimensionality reduction, contrastive learning, and supervised\nlearning. This framework enables the development of new loss functions by\ncombining successful techniques from across the literature. We not only present\na wide array of proofs, connecting over 23 different approaches, but we also\nleverage these theoretical results to create state-of-the-art unsupervised\nimage classifiers that achieve a +8% improvement over the prior\nstate-of-the-art on unsupervised classification on ImageNet-1K. We also\ndemonstrate that I-Con can be used to derive principled debiasing methods which\nimprove contrastive representation learners.", "published": "2025-04-23 17:59:01", "link": "http://arxiv.org/abs/2504.16929v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "Latent Diffusion Planning for Imitation Learning", "abstract": "Recent progress in imitation learning has been enabled by policy\narchitectures that scale to complex visuomotor tasks, multimodal distributions,\nand large datasets. However, these methods often rely on learning from large\namount of expert demonstrations. To address these shortcomings, we propose\nLatent Diffusion Planning (LDP), a modular approach consisting of a planner\nwhich can leverage action-free demonstrations, and an inverse dynamics model\nwhich can leverage suboptimal data, that both operate over a learned latent\nspace. First, we learn a compact latent space through a variational\nautoencoder, enabling effective forecasting of future states in image-based\ndomains. Then, we train a planner and an inverse dynamics model with diffusion\nobjectives. By separating planning from action prediction, LDP can benefit from\nthe denser supervision signals of suboptimal and action-free data. On simulated\nvisual robotic manipulation tasks, LDP outperforms state-of-the-art imitation\nlearning approaches, as they cannot leverage such additional data.", "published": "2025-04-23 17:53:34", "link": "http://arxiv.org/abs/2504.16925v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Generalized Neighborhood Attention: Multi-dimensional Sparse Attention at the Speed of Light", "abstract": "Many sparse attention mechanisms such as Neighborhood Attention have\ntypically failed to consistently deliver speedup over the self attention\nbaseline. This is largely due to the level of complexity in attention\ninfrastructure, and the rapid evolution of AI hardware architecture. At the\nsame time, many state-of-the-art foundational models, particularly in computer\nvision, are heavily bound by attention, and need reliable sparsity to escape\nthe O(n^2) complexity. In this paper, we study a class of promising sparse\nattention mechanisms that focus on locality, and aim to develop a better\nanalytical model of their performance improvements. We first introduce\nGeneralized Neighborhood Attention (GNA), which can describe sliding window,\nstrided sliding window, and blocked attention. We then consider possible design\nchoices in implementing these approaches, and create a simulator that can\nprovide much more realistic speedup upper bounds for any given setting.\nFinally, we implement GNA on top of a state-of-the-art fused multi-headed\nattention (FMHA) kernel designed for the NVIDIA Blackwell architecture in\nCUTLASS. Our implementation can fully realize the maximum speedup theoretically\npossible in many perfectly block-sparse cases, and achieves an effective\nutilization of 1.3 petaFLOPs/second in FP16. In addition, we plug various GNA\nconfigurations into off-the-shelf generative models, such as Cosmos-7B,\nHunyuanVideo, and FLUX, and show that it can deliver 28% to 46% end-to-end\nspeedup on B200 without any fine-tuning. We will open source our simulator and\nBlackwell kernels directly through the NATTEN project.", "published": "2025-04-23 17:49:53", "link": "http://arxiv.org/abs/2504.16922v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "BadVideo: Stealthy Backdoor Attack against Text-to-Video Generation", "abstract": "Text-to-video (T2V) generative models have rapidly advanced and found\nwidespread applications across fields like entertainment, education, and\nmarketing. However, the adversarial vulnerabilities of these models remain\nrarely explored. We observe that in T2V generation tasks, the generated videos\noften contain substantial redundant information not explicitly specified in the\ntext prompts, such as environmental elements, secondary objects, and additional\ndetails, providing opportunities for malicious attackers to embed hidden\nharmful content. Exploiting this inherent redundancy, we introduce BadVideo,\nthe first backdoor attack framework tailored for T2V generation. Our attack\nfocuses on designing target adversarial outputs through two key strategies: (1)\nSpatio-Temporal Composition, which combines different spatiotemporal features\nto encode malicious information; (2) Dynamic Element Transformation, which\nintroduces transformations in redundant elements over time to convey malicious\ninformation. Based on these strategies, the attacker's malicious target\nseamlessly integrates with the user's textual instructions, providing high\nstealthiness. Moreover, by exploiting the temporal dimension of videos, our\nattack successfully evades traditional content moderation systems that\nprimarily analyze spatial information within individual frames. Extensive\nexperiments demonstrate that BadVideo achieves high attack success rates while\npreserving original semantics and maintaining excellent performance on clean\ninputs. Overall, our work reveals the adversarial vulnerability of T2V models,\ncalling attention to potential risks and misuse. Our project page is at\nhttps://wrt2000.github.io/BadVideo2025/.", "published": "2025-04-23 17:34:48", "link": "http://arxiv.org/abs/2504.16907v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Building A Secure Agentic AI Application Leveraging A2A Protocol", "abstract": "As Agentic AI systems evolve from basic workflows to complex multi agent\ncollaboration, robust protocols such as Google's Agent2Agent (A2A) become\nessential enablers. To foster secure adoption and ensure the reliability of\nthese complex interactions, understanding the secure implementation of A2A is\nessential. This paper addresses this goal by providing a comprehensive security\nanalysis centered on the A2A protocol. We examine its fundamental elements and\noperational dynamics, situating it within the framework of agent communication\ndevelopment. Utilizing the MAESTRO framework, specifically designed for AI\nrisks, we apply proactive threat modeling to assess potential security issues\nin A2A deployments, focusing on aspects such as Agent Card management, task\nexecution integrity, and authentication methodologies.\n  Based on these insights, we recommend practical secure development\nmethodologies and architectural best practices designed to build resilient and\neffective A2A systems. Our analysis also explores how the synergy between A2A\nand the Model Context Protocol (MCP) can further enhance secure\ninteroperability. This paper equips developers and architects with the\nknowledge and practical guidance needed to confidently leverage the A2A\nprotocol for building robust and secure next generation agentic applications.", "published": "2025-04-23 17:27:49", "link": "http://arxiv.org/abs/2504.16902v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Approximating Optimal Labelings for Temporal Connectivity", "abstract": "In a temporal graph the edge set dynamically changes over time according to a\nset of time-labels associated with each edge that indicates at which time-steps\nthe edge is available. Two vertices are connected if there is a path connecting\nthem in which the edges are traversed in increasing order of their labels. We\nstudy the problem of scheduling the availability time of the edges of a\ntemporal graph in such a way that all pairs of vertices are connected within a\ngiven maximum allowed time $a$ and the overall number of labels is minimized.\n  The problem, known as \\emph{Minimum Aged Labeling} (MAL), has several\napplications in logistics, distribution scheduling, and information spreading\nin social networks, where carefully choosing the time-labels can significantly\nreduce infrastructure costs, fuel consumption, or greenhouse gases.\n  The problem MAL has previously been proved to be NP-complete on undirected\ngraphs and \\APX-hard on directed graphs. In this paper, we extend our knowledge\non the complexity and approximability of MAL in several directions. We first\nshow that the problem cannot be approximated within a factor better than\n$O(\\log n)$ when $a\\geq 2$, unless $\\text{P} = \\text{NP}$, and a factor better\nthan $2^{\\log ^{1-\\epsilon} n}$ when $a\\geq 3$, unless $\\text{NP}\\subseteq\n\\text{DTIME}(2^{\\text{polylog}(n)})$, where $n$ is the number of vertices in\nthe graph. Then we give a set of approximation algorithms that, under some\nconditions, almost match these lower bounds. In particular, we show that the\napproximation depends on a relation between $a$ and the diameter of the input\ngraph.\n  We further establish a connection with a foundational optimization problem on\nstatic graphs called \\emph{Diameter Constrained Spanning Subgraph} (DCSS) and\nshow that our hardness results also apply to DCSS.", "published": "2025-04-23 16:00:33", "link": "http://arxiv.org/abs/2504.16837v1", "categories": ["cs.DS", "cs.AI"], "primary_category": "cs.DS"}
{"title": "Improving Significant Wave Height Prediction Using Chronos Models", "abstract": "Accurate wave height prediction is critical for maritime safety and coastal\nresilience, yet conventional physics-based models and traditional machine\nlearning methods face challenges in computational efficiency and nonlinear\ndynamics modeling. This study introduces Chronos, the first implementation of a\nlarge language model (LLM)-powered temporal architecture (Chronos) optimized\nfor wave forecasting. Through advanced temporal pattern recognition applied to\nhistorical wave data from three strategically chosen marine zones in the\nNorthwest Pacific basin, our framework achieves multimodal improvements: (1)\n14.3% reduction in training time with 2.5x faster inference speed compared to\nPatchTST baselines, achieving 0.575 mean absolute scaled error (MASE) units;\n(2) superior short-term forecasting (1-24h) across comprehensive metrics; (3)\nsustained predictive leadership in extended-range forecasts (1-120h); and (4)\ndemonstrated zero-shot capability maintaining median performance (rank 4/12)\nagainst specialized operational models. This LLM-enhanced temporal modeling\nparadigm establishes a new standard in wave prediction, offering both\ncomputationally efficient solutions and a transferable framework for complex\ngeophysical systems modeling.", "published": "2025-04-23 15:56:28", "link": "http://arxiv.org/abs/2504.16834v1", "categories": ["cs.LG", "cs.AI", "physics.ao-ph"], "primary_category": "cs.LG"}
{"title": "Radiometer Calibration using Machine Learning", "abstract": "Radiometers are crucial instruments in radio astronomy, forming the primary\ncomponent of nearly all radio telescopes. They measure the intensity of\nelectromagnetic radiation, converting this radiation into electrical signals. A\nradiometer's primary components are an antenna and a Low Noise Amplifier (LNA),\nwhich is the core of the ``receiver'' chain. Instrumental effects introduced by\nthe receiver are typically corrected or removed during calibration. However,\nimpedance mismatches between the antenna and receiver can introduce unwanted\nsignal reflections and distortions. Traditional calibration methods, such as\nDicke switching, alternate the receiver input between the antenna and a\nwell-characterised reference source to mitigate errors by comparison. Recent\nadvances in Machine Learning (ML) offer promising alternatives. Neural\nnetworks, which are trained using known signal sources, provide a powerful\nmeans to model and calibrate complex systems where traditional analytical\napproaches struggle. These methods are especially relevant for detecting the\nfaint sky-averaged 21-cm signal from atomic hydrogen at high redshifts. This is\none of the main challenges in observational Cosmology today. Here, for the\nfirst time, we introduce and test a machine learning-based calibration\nframework capable of achieving the precision required for radiometric\nexperiments aiming to detect the 21-cm line.", "published": "2025-04-23 15:10:25", "link": "http://arxiv.org/abs/2504.16791v1", "categories": ["astro-ph.IM", "astro-ph.CO", "cs.AI"], "primary_category": "astro-ph.IM"}
{"title": "Towards Explainable AI: Multi-Modal Transformer for Video-based Image Description Generation", "abstract": "Understanding and analyzing video actions are essential for producing\ninsightful and contextualized descriptions, especially for video-based\napplications like intelligent monitoring and autonomous systems. The proposed\nwork introduces a novel framework for generating natural language descriptions\nfrom video datasets by combining textual and visual modalities. The suggested\narchitecture makes use of ResNet50 to extract visual features from video frames\nthat are taken from the Microsoft Research Video Description Corpus (MSVD), and\nBerkeley DeepDrive eXplanation (BDD-X) datasets. The extracted visual\ncharacteristics are converted into patch embeddings and then run through an\nencoder-decoder model based on Generative Pre-trained Transformer-2 (GPT-2). In\norder to align textual and visual representations and guarantee high-quality\ndescription production, the system uses multi-head self-attention and\ncross-attention techniques. The model's efficacy is demonstrated by performance\nevaluation using BLEU (1-4), CIDEr, METEOR, and ROUGE-L. The suggested\nframework outperforms traditional methods with BLEU-4 scores of 0.755 (BDD-X)\nand 0.778 (MSVD), CIDEr scores of 1.235 (BDD-X) and 1.315 (MSVD), METEOR scores\nof 0.312 (BDD-X) and 0.329 (MSVD), and ROUGE-L scores of 0.782 (BDD-X) and\n0.795 (MSVD). By producing human-like, contextually relevant descriptions,\nstrengthening interpretability, and improving real-world applications, this\nresearch advances explainable AI.", "published": "2025-04-23 15:03:37", "link": "http://arxiv.org/abs/2504.16788v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Noise-Tolerant Coreset-Based Class Incremental Continual Learning", "abstract": "Many applications of computer vision require the ability to adapt to novel\ndata distributions after deployment. Adaptation requires algorithms capable of\ncontinual learning (CL). Continual learners must be plastic to adapt to novel\ntasks while minimizing forgetting of previous tasks.However, CL opens up\navenues for noise to enter the training pipeline and disrupt the CL. This work\nfocuses on label noise and instance noise in the context of class-incremental\nlearning (CIL), where new classes are added to a classifier over time, and\nthere is no access to external data from past classes. We aim to understand the\nsensitivity of CL methods that work by replaying items from a memory\nconstructed using the idea of Coresets. We derive a new bound for the\nrobustness of such a method to uncorrelated instance noise under a general\nadditive noise threat model, revealing several insights. Putting the theory\ninto practice, we create two continual learning algorithms to construct\nnoise-tolerant replay buffers. We empirically compare the effectiveness of\nprior memory-based continual learners and the proposed algorithms under label\nand uncorrelated instance noise on five diverse datasets. We show that existing\nmemory-based CL are not robust whereas the proposed methods exhibit significant\nimprovements in maximizing classification accuracy and minimizing forgetting in\nthe noisy CIL setting.", "published": "2025-04-23 14:34:20", "link": "http://arxiv.org/abs/2504.16763v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Lightweight Latent Verifiers for Efficient Meta-Generation Strategies", "abstract": "Verifiers are auxiliary models that assess the correctness of outputs\ngenerated by base large language models (LLMs). They play a crucial role in\nmany strategies for solving reasoning-intensive problems with LLMs. Typically,\nverifiers are LLMs themselves, often as large (or larger) than the base model\nthey support, making them computationally expensive. In this work, we introduce\na novel lightweight verification approach, LiLaVe, which reliably extracts\ncorrectness signals from the hidden states of the base LLM. A key advantage of\nLiLaVe is its ability to operate with only a small fraction of the\ncomputational budget required by traditional LLM-based verifiers. To\ndemonstrate its practicality, we couple LiLaVe with popular meta-generation\nstrategies, like best-of-n or self-consistency. Moreover, we design novel\nLiLaVe-based approaches, like conditional self-correction or conditional\nmajority voting, that significantly improve both accuracy and efficiency in\ngeneration tasks with smaller LLMs. Our work demonstrates the fruitfulness of\nextracting latent information from the hidden states of LLMs, and opens the\ndoor to scalable and resource-efficient solutions for reasoning-intensive\napplications.", "published": "2025-04-23 14:33:20", "link": "http://arxiv.org/abs/2504.16760v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "MOSAIC: A Skill-Centric Algorithmic Framework for Long-Horizon Manipulation Planning", "abstract": "Planning long-horizon motions using a set of predefined skills is a key\nchallenge in robotics and AI. Addressing this challenge requires methods that\nsystematically explore skill combinations to uncover task-solving sequences,\nharness generic, easy-to-learn skills (e.g., pushing, grasping) to generalize\nacross unseen tasks, and bypass reliance on symbolic world representations that\ndemand extensive domain and task-specific knowledge. Despite significant\nprogress, these elements remain largely disjoint in existing approaches,\nleaving a critical gap in achieving robust, scalable solutions for complex,\nlong-horizon problems. In this work, we present MOSAIC, a skill-centric\nframework that unifies these elements by using the skills themselves to guide\nthe planning process. MOSAIC uses two families of skills: Generators compute\nexecutable trajectories and world configurations, and Connectors link these\nindependently generated skill trajectories by solving boundary value problems,\nenabling progress toward completing the overall task. By breaking away from the\nconventional paradigm of incrementally discovering skills from predefined start\nor goal states--a limitation that significantly restricts exploration--MOSAIC\nfocuses planning efforts on regions where skills are inherently effective. We\ndemonstrate the efficacy of MOSAIC in both simulated and real-world robotic\nmanipulation tasks, showcasing its ability to solve complex long-horizon\nplanning problems using a diverse set of skills incorporating generative\ndiffusion models, motion planning algorithms, and manipulation-specific models.\nVisit https://skill-mosaic.github.io for demonstrations and examples.", "published": "2025-04-23 14:09:42", "link": "http://arxiv.org/abs/2504.16738v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "A Survey of AI Agent Protocols", "abstract": "The rapid development of large language models (LLMs) has led to the\nwidespread deployment of LLM agents across diverse industries, including\ncustomer service, content generation, data analysis, and even healthcare.\nHowever, as more LLM agents are deployed, a major issue has emerged: there is\nno standard way for these agents to communicate with external tools or data\nsources. This lack of standardized protocols makes it difficult for agents to\nwork together or scale effectively, and it limits their ability to tackle\ncomplex, real-world tasks. A unified communication protocol for LLM agents\ncould change this. It would allow agents and tools to interact more smoothly,\nencourage collaboration, and triggering the formation of collective\nintelligence. In this paper, we provide a systematic overview of existing\ncommunication protocols for LLM agents. We classify them into four main\ncategories and make an analysis to help users and developers select the most\nsuitable protocols for specific applications. Additionally, we conduct a\ncomparative performance analysis of these protocols across key dimensions such\nas security, scalability, and latency. Finally, we explore future challenges,\nsuch as how protocols can adapt and survive in fast-evolving environments, and\nwhat qualities future protocols might need to support the next generation of\nLLM agent ecosystems. We expect this work to serve as a practical reference for\nboth researchers and engineers seeking to design, evaluate, or integrate robust\ncommunication infrastructures for intelligent agents.", "published": "2025-04-23 14:07:26", "link": "http://arxiv.org/abs/2504.16736v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "V$^2$R-Bench: Holistically Evaluating LVLM Robustness to Fundamental Visual Variations", "abstract": "Large Vision Language Models (LVLMs) excel in various vision-language tasks.\nYet, their robustness to visual variations in position, scale, orientation, and\ncontext that objects in natural scenes inevitably exhibit due to changes in\nviewpoint and environment remains largely underexplored. To bridge this gap, we\nintroduce V$^2$R-Bench, a comprehensive benchmark framework for evaluating\nVisual Variation Robustness of LVLMs, which encompasses automated evaluation\ndataset generation and principled metrics for thorough robustness assessment.\nThrough extensive evaluation on 21 LVLMs, we reveal a surprising vulnerability\nto visual variations, in which even advanced models that excel at complex\nvision-language tasks significantly underperform on simple tasks such as object\nrecognition. Interestingly, these models exhibit a distinct visual position\nbias that contradicts theories of effective receptive fields, and demonstrate a\nhuman-like visual acuity threshold. To identify the source of these\nvulnerabilities, we present a systematic framework for component-level\nanalysis, featuring a novel visualization approach for aligned visual features.\nResults show that these vulnerabilities stem from error accumulation in the\npipeline architecture and inadequate multimodal alignment. Complementary\nexperiments with synthetic data further demonstrate that these limitations are\nfundamentally architectural deficiencies, scoring the need for architectural\ninnovations in future LVLM designs.", "published": "2025-04-23 14:01:32", "link": "http://arxiv.org/abs/2504.16727v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Detecting and Understanding Hateful Contents in Memes Through Captioning and Visual Question-Answering", "abstract": "Memes are widely used for humor and cultural commentary, but they are\nincreasingly exploited to spread hateful content. Due to their multimodal\nnature, hateful memes often evade traditional text-only or image-only detection\nsystems, particularly when they employ subtle or coded references. To address\nthese challenges, we propose a multimodal hate detection framework that\nintegrates key components: OCR to extract embedded text, captioning to describe\nvisual content neutrally, sub-label classification for granular categorization\nof hateful content, RAG for contextually relevant retrieval, and VQA for\niterative analysis of symbolic and contextual cues. This enables the framework\nto uncover latent signals that simpler pipelines fail to detect. Experimental\nresults on the Facebook Hateful Memes dataset reveal that the proposed\nframework exceeds the performance of unimodal and conventional multimodal\nmodels in both accuracy and AUC-ROC.", "published": "2025-04-23 13:52:14", "link": "http://arxiv.org/abs/2504.16723v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "PMG: Progressive Motion Generation via Sparse Anchor Postures Curriculum Learning", "abstract": "In computer animation, game design, and human-computer interaction,\nsynthesizing human motion that aligns with user intent remains a significant\nchallenge. Existing methods have notable limitations: textual approaches offer\nhigh-level semantic guidance but struggle to describe complex actions\naccurately; trajectory-based techniques provide intuitive global motion\ndirection yet often fall short in generating precise or customized character\nmovements; and anchor poses-guided methods are typically confined to synthesize\nonly simple motion patterns. To generate more controllable and precise human\nmotions, we propose \\textbf{ProMoGen (Progressive Motion Generation)}, a novel\nframework that integrates trajectory guidance with sparse anchor motion\ncontrol. Global trajectories ensure consistency in spatial direction and\ndisplacement, while sparse anchor motions only deliver precise action guidance\nwithout displacement. This decoupling enables independent refinement of both\naspects, resulting in a more controllable, high-fidelity, and sophisticated\nmotion synthesis. ProMoGen supports both dual and single control paradigms\nwithin a unified training process. Moreover, we recognize that direct learning\nfrom sparse motions is inherently unstable, we introduce \\textbf{SAP-CL (Sparse\nAnchor Posture Curriculum Learning)}, a curriculum learning strategy that\nprogressively adjusts the number of anchors used for guidance, thereby enabling\nmore precise and stable convergence. Extensive experiments demonstrate that\nProMoGen excels in synthesizing vivid and diverse motions guided by predefined\ntrajectory and arbitrary anchor frames. Our approach seamlessly integrates\npersonalized motion with structured guidance, significantly outperforming\nstate-of-the-art methods across multiple control scenarios.", "published": "2025-04-23 13:51:42", "link": "http://arxiv.org/abs/2504.16722v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Offline Robotic World Model: Learning Robotic Policies without a Physics Simulator", "abstract": "Reinforcement Learning (RL) has demonstrated impressive capabilities in\nrobotic control but remains challenging due to high sample complexity, safety\nconcerns, and the sim-to-real gap. While offline RL eliminates the need for\nrisky real-world exploration by learning from pre-collected data, it suffers\nfrom distributional shift, limiting policy generalization. Model-Based RL\n(MBRL) addresses this by leveraging predictive models for synthetic rollouts,\nyet existing approaches often lack robust uncertainty estimation, leading to\ncompounding errors in offline settings. We introduce Offline Robotic World\nModel (RWM-O), a model-based approach that explicitly estimates epistemic\nuncertainty to improve policy learning without reliance on a physics simulator.\nBy integrating these uncertainty estimates into policy optimization, our\napproach penalizes unreliable transitions, reducing overfitting to model errors\nand enhancing stability. Experimental results show that RWM-O improves\ngeneralization and safety, enabling policy learning purely from real-world data\nand advancing scalable, data-efficient RL for robotics.", "published": "2025-04-23 12:58:15", "link": "http://arxiv.org/abs/2504.16680v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Representation Learning via Non-Contrastive Mutual Information", "abstract": "Labeling data is often very time consuming and expensive, leaving us with a\nmajority of unlabeled data. Self-supervised representation learning methods\nsuch as SimCLR (Chen et al., 2020) or BYOL (Grill et al., 2020) have been very\nsuccessful at learning meaningful latent representations from unlabeled image\ndata, resulting in much more general and transferable representations for\ndownstream tasks. Broadly, self-supervised methods fall into two types: 1)\nContrastive methods, such as SimCLR; and 2) Non-Contrastive methods, such as\nBYOL. Contrastive methods are generally trying to maximize mutual information\nbetween related data points, so they need to compare every data point to every\nother data point, resulting in high variance, and thus requiring large batch\nsizes to work well. Non-contrastive methods like BYOL have much lower variance\nas they do not need to make pairwise comparisons, but are much trickier to\nimplement as they have the possibility of collapsing to a constant vector. In\nthis paper, we aim to develop a self-supervised objective that combines the\nstrength of both types. We start with a particular contrastive method called\nthe Spectral Contrastive Loss (HaoChen et al., 2021; Lu et al., 2024), and we\nconvert it into a more general non-contrastive form; this removes the pairwise\ncomparisons resulting in lower variance, but keeps the mutual information\nformulation of the contrastive method preventing collapse. We call our new\nobjective the Mutual Information Non-Contrastive (MINC) loss. We test MINC by\nlearning image representations on ImageNet (similar to SimCLR and BYOL) and\nshow that it consistently improves upon the Spectral Contrastive loss baseline.", "published": "2025-04-23 12:35:27", "link": "http://arxiv.org/abs/2504.16667v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML", "I.2.6; I.2.10"], "primary_category": "cs.LG"}
{"title": "MAYA: Addressing Inconsistencies in Generative Password Guessing through a Unified Benchmark", "abstract": "The rapid evolution of generative models has led to their integration across\nvarious fields, including password guessing, aiming to generate passwords that\nresemble human-created ones in complexity, structure, and patterns. Despite\ngenerative model's promise, inconsistencies in prior research and a lack of\nrigorous evaluation have hindered a comprehensive understanding of their true\npotential. In this paper, we introduce MAYA, a unified, customizable,\nplug-and-play password benchmarking framework. MAYA provides a standardized\napproach for evaluating generative password-guessing models through a rigorous\nset of advanced testing scenarios and a collection of eight real-life password\ndatasets. Using MAYA, we comprehensively evaluate six state-of-the-art\napproaches, which have been re-implemented and adapted to ensure\nstandardization, for a total of over 15,000 hours of computation. Our findings\nindicate that these models effectively capture different aspects of human\npassword distribution and exhibit strong generalization capabilities. However,\ntheir effectiveness varies significantly with long and complex passwords.\nThrough our evaluation, sequential models consistently outperform other\ngenerative architectures and traditional password-guessing tools, demonstrating\nunique capabilities in generating accurate and complex guesses. Moreover,\nmodels learn and generate different password distributions, enabling a\nmulti-model attack that outperforms the best individual model. By releasing\nMAYA, we aim to foster further research, providing the community with a new\ntool to consistently and reliably benchmark password-generation techniques. Our\nframework is publicly available at\nhttps://github.com/williamcorrias/MAYA-Password-Benchmarking", "published": "2025-04-23 12:16:59", "link": "http://arxiv.org/abs/2504.16651v1", "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "cs.CR"}
{"title": "SSLR: A Semi-Supervised Learning Method for Isolated Sign Language Recognition", "abstract": "Sign language is the primary communication language for people with disabling\nhearing loss. Sign language recognition (SLR) systems aim to recognize sign\ngestures and translate them into spoken language. One of the main challenges in\nSLR is the scarcity of annotated datasets. To address this issue, we propose a\nsemi-supervised learning (SSL) approach for SLR (SSLR), employing a\npseudo-label method to annotate unlabeled samples. The sign gestures are\nrepresented using pose information that encodes the signer's skeletal joint\npoints. This information is used as input for the Transformer backbone model\nutilized in the proposed approach. To demonstrate the learning capabilities of\nSSL across various labeled data sizes, several experiments were conducted using\ndifferent percentages of labeled data with varying numbers of classes. The\nperformance of the SSL approach was compared with a fully supervised\nlearning-based model on the WLASL-100 dataset. The obtained results of the SSL\nmodel outperformed the supervised learning-based model with less labeled data\nin many cases.", "published": "2025-04-23 11:59:52", "link": "http://arxiv.org/abs/2504.16640v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Bridging Econometrics and AI: VaR Estimation via Reinforcement Learning and GARCH Models", "abstract": "In an environment of increasingly volatile financial markets, the accurate\nestimation of risk remains a major challenge. Traditional econometric models,\nsuch as GARCH and its variants, are based on assumptions that are often too\nrigid to adapt to the complexity of the current market dynamics. To overcome\nthese limitations, we propose a hybrid framework for Value-at-Risk (VaR)\nestimation, combining GARCH volatility models with deep reinforcement learning.\nOur approach incorporates directional market forecasting using the Double Deep\nQ-Network (DDQN) model, treating the task as an imbalanced classification\nproblem. This architecture enables the dynamic adjustment of risk-level\nforecasts according to market conditions. Empirical validation on daily\nEurostoxx 50 data covering periods of crisis and high volatility shows a\nsignificant improvement in the accuracy of VaR estimates, as well as a\nreduction in the number of breaches and also in capital requirements, while\nrespecting regulatory risk thresholds. The ability of the model to adjust risk\nlevels in real time reinforces its relevance to modern and proactive risk\nmanagement.", "published": "2025-04-23 11:54:22", "link": "http://arxiv.org/abs/2504.16635v1", "categories": ["cs.AI", "q-fin.CP", "q-fin.RM", "q-fin.ST"], "primary_category": "cs.AI"}
{"title": "Cognitive Silicon: An Architectural Blueprint for Post-Industrial Computing Systems", "abstract": "Autonomous AI systems reveal foundational limitations in deterministic,\nhuman-authored computing architectures. This paper presents Cognitive Silicon:\na hypothetical full-stack architectural framework projected toward 2035,\nexploring a possible trajectory for cognitive computing system design. The\nproposed architecture would integrate symbolic scaffolding, governed memory,\nruntime moral coherence, and alignment-aware execution across\nsilicon-to-semantics layers. Our design grammar has emerged from dialectical\nco-design with LLMs under asymmetric epistemic conditions--creating structured\nfriction to expose blind spots and trade-offs. The envisioned framework would\nestablish mortality as a natural consequence of physical constraints,\nnon-copyable tacit knowledge, and non-cloneable identity keys as\ncognitive-embodiment primitives. Core tensions (trust/agency,\nscaffolding/emergence, execution/governance) would function as central\narchitectural pressures rather than edge cases. The architecture theoretically\nconverges with the Free Energy Principle, potentially offering a formal account\nof how cognitive systems could maintain identity through prediction error\nminimization across physical and computational boundaries. The resulting\nframework aims to deliver a morally tractable cognitive infrastructure that\ncould maintain human-alignment through irreversible hardware constraints and\nidentity-bound epistemic mechanisms resistant to replication or subversion.", "published": "2025-04-23 11:24:30", "link": "http://arxiv.org/abs/2504.16622v1", "categories": ["cs.AI", "cs.CY"], "primary_category": "cs.AI"}
{"title": "Case Study: Fine-tuning Small Language Models for Accurate and Private CWE Detection in Python Code", "abstract": "Large Language Models (LLMs) have demonstrated significant capabilities in\nunderstanding and analyzing code for security vulnerabilities, such as Common\nWeakness Enumerations (CWEs). However, their reliance on cloud infrastructure\nand substantial computational requirements pose challenges for analyzing\nsensitive or proprietary codebases due to privacy concerns and inference costs.\nThis work explores the potential of Small Language Models (SLMs) as a viable\nalternative for accurate, on-premise vulnerability detection. We investigated\nwhether a 350-million parameter pre-trained code model (codegen-mono) could be\neffectively fine-tuned to detect the MITRE Top 25 CWEs specifically within\nPython code. To facilitate this, we developed a targeted dataset of 500\nexamples using a semi-supervised approach involving LLM-driven synthetic data\ngeneration coupled with meticulous human review. Initial tests confirmed that\nthe base codegen-mono model completely failed to identify CWEs in our samples.\nHowever, after applying instruction-following fine-tuning, the specialized SLM\nachieved remarkable performance on our test set, yielding approximately 99%\naccuracy, 98.08% precision, 100% recall, and a 99.04% F1-score. These results\nstrongly suggest that fine-tuned SLMs can serve as highly accurate and\nefficient tools for CWE detection, offering a practical and privacy-preserving\nsolution for integrating advanced security analysis directly into development\nworkflows.", "published": "2025-04-23 10:05:27", "link": "http://arxiv.org/abs/2504.16584v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "MMHCL: Multi-Modal Hypergraph Contrastive Learning for Recommendation", "abstract": "The burgeoning presence of multimodal content-sharing platforms propels the\ndevelopment of personalized recommender systems. Previous works usually suffer\nfrom data sparsity and cold-start problems, and may fail to adequately explore\nsemantic user-product associations from multimodal data. To address these\nissues, we propose a novel Multi-Modal Hypergraph Contrastive Learning (MMHCL)\nframework for user recommendation. For a comprehensive information exploration\nfrom user-product relations, we construct two hypergraphs, i.e. a user-to-user\n(u2u) hypergraph and an item-to-item (i2i) hypergraph, to mine shared\npreferences among users and intricate multimodal semantic resemblance among\nitems, respectively. This process yields denser second-order semantics that are\nfused with first-order user-item interaction as complementary to alleviate the\ndata sparsity issue. Then, we design a contrastive feature enhancement paradigm\nby applying synergistic contrastive learning. By maximizing/minimizing the\nmutual information between second-order (e.g. shared preference pattern for\nusers) and first-order (information of selected items for users) embeddings of\nthe same/different users and items, the feature distinguishability can be\neffectively enhanced. Compared with using sparse primary user-item interaction\nonly, our MMHCL obtains denser second-order hypergraphs and excavates more\nabundant shared attributes to explore the user-product associations, which to a\ncertain extent alleviates the problems of data sparsity and cold-start.\nExtensive experiments have comprehensively demonstrated the effectiveness of\nour method. Our code is publicly available at: https://github.com/Xu107/MMHCL.", "published": "2025-04-23 09:58:54", "link": "http://arxiv.org/abs/2504.16576v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "PsyCounAssist: A Full-Cycle AI-Powered Psychological Counseling Assistant System", "abstract": "Psychological counseling is a highly personalized and dynamic process that\nrequires therapists to continuously monitor emotional changes, document session\ninsights, and maintain therapeutic continuity. In this paper, we introduce\nPsyCounAssist, a comprehensive AI-powered counseling assistant system\nspecifically designed to augment psychological counseling practices.\nPsyCounAssist integrates multimodal emotion recognition combining speech and\nphotoplethysmography (PPG) signals for accurate real-time affective analysis,\nautomated structured session reporting using large language models (LLMs), and\npersonalized AI-generated follow-up support. Deployed on Android-based tablet\ndevices, the system demonstrates practical applicability and flexibility in\nreal-world counseling scenarios. Experimental evaluation confirms the\nreliability of PPG-based emotional classification and highlights the system's\npotential for non-intrusive, privacy-aware emotional support. PsyCounAssist\nrepresents a novel approach to ethically and effectively integrating AI into\npsychological counseling workflows.", "published": "2025-04-23 09:49:05", "link": "http://arxiv.org/abs/2504.16573v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "A Vision for AI-Driven Adaptation of Dynamic AR Content to Users and Environments", "abstract": "Augmented Reality (AR) is transforming the way we interact with virtual\ninformation in the physical world. By overlaying digital content in real-world\nenvironments, AR enables new forms of immersive and engaging experiences.\nHowever, existing AR systems often struggle to effectively manage the many\ninteractive possibilities that AR presents. This vision paper speculates on\nAI-driven approaches for adaptive AR content placement, dynamically adjusting\nto user movement and environmental changes. By leveraging machine learning\nmethods, such a system would intelligently manage content distribution between\nAR projections integrated into the external environment and fixed static\ncontent, enabling seamless UI layout and potentially reducing users' cognitive\nload. By exploring the possibilities of AI-driven dynamic AR content placement,\nwe aim to envision new opportunities for innovation and improvement in various\nindustries, from urban navigation and workplace productivity to immersive\nlearning and beyond. This paper outlines a vision for the development of more\nintuitive, engaging, and effective AI-powered AR experiences.", "published": "2025-04-23 09:42:38", "link": "http://arxiv.org/abs/2504.16562v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Exploring human-SAV interaction using large language models: The impact of psychological ownership and anthropomorphism on user experience", "abstract": "There has been extensive prior work exploring how psychological factors such\nas anthropomorphism affect the adoption of shared autonomous vehicles (SAVs).\nHowever, limited research has been conducted on how prompt strategies in large\nlanguage model (LLM)-powered SAV User Interfaces (UIs) affect users'\nperceptions, experiences, and intentions to adopt such technology. In this\nwork, we investigate how conversational UIs powered by LLMs drive these\npsychological factors and psychological ownership, the sense of possession a\nuser may come to feel towards an entity or object they may not legally own. We\ndesigned four SAV UIs with varying levels of anthropomorphic characteristics\nand psychological ownership triggers. Quantitative measures of psychological\nownership, anthropomorphism, quality of service, disclosure tendency, sentiment\nof SAV responses, and overall acceptance were collected after participants\ninteracted with each SAV. Qualitative feedback was also gathered regarding the\nexperience of psychological ownership during the interactions. The results\nindicate that an SAV conversational UI designed to be more anthropomorphic and\nto induce psychological ownership improved users' perceptions of the SAV's\nhuman-like qualities and improved the sentiment of responses compared to a\ncontrol condition. These findings provide practical guidance for designing\nLLM-based conversational UIs that enhance user experience and adoption of SAVs.", "published": "2025-04-23 09:25:22", "link": "http://arxiv.org/abs/2504.16548v1", "categories": ["cs.HC", "cs.AI", "cs.ET"], "primary_category": "cs.HC"}
{"title": "Think Hierarchically, Act Dynamically: Hierarchical Multi-modal Fusion and Reasoning for Vision-and-Language Navigation", "abstract": "Vision-and-Language Navigation (VLN) aims to enable embodied agents to follow\nnatural language instructions and reach target locations in real-world\nenvironments. While prior methods often rely on either global scene\nrepresentations or object-level features, these approaches are insufficient for\ncapturing the complex interactions across modalities required for accurate\nnavigation. In this paper, we propose a Multi-level Fusion and Reasoning\nArchitecture (MFRA) to enhance the agent's ability to reason over visual\nobservations, language instructions and navigation history. Specifically, MFRA\nintroduces a hierarchical fusion mechanism that aggregates multi-level\nfeatures-ranging from low-level visual cues to high-level semantic\nconcepts-across multiple modalities. We further design a reasoning module that\nleverages fused representations to infer navigation actions through\ninstruction-guided attention and dynamic context integration. By selectively\ncapturing and combining relevant visual, linguistic, and temporal signals, MFRA\nimproves decision-making accuracy in complex navigation scenarios. Extensive\nexperiments on benchmark VLN datasets including REVERIE, R2R, and SOON\ndemonstrate that MFRA achieves superior performance compared to\nstate-of-the-art methods, validating the effectiveness of multi-level modal\nfusion for embodied navigation.", "published": "2025-04-23 08:41:27", "link": "http://arxiv.org/abs/2504.16516v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Federated Learning of Low-Rank One-Shot Image Detection Models in Edge Devices with Scalable Accuracy and Compute Complexity", "abstract": "This paper introduces a novel federated learning framework termed LoRa-FL\ndesigned for training low-rank one-shot image detection models deployed on edge\ndevices. By incorporating low-rank adaptation techniques into one-shot\ndetection architectures, our method significantly reduces both computational\nand communication overhead while maintaining scalable accuracy. The proposed\nframework leverages federated learning to collaboratively train lightweight\nimage recognition models, enabling rapid adaptation and efficient deployment\nacross heterogeneous, resource-constrained devices. Experimental evaluations on\nthe MNIST and CIFAR10 benchmark datasets, both in an\nindependent-and-identically-distributed (IID) and non-IID setting, demonstrate\nthat our approach achieves competitive detection performance while\nsignificantly reducing communication bandwidth and compute complexity. This\nmakes it a promising solution for adaptively reducing the communication and\ncompute power overheads, while not sacrificing model accuracy.", "published": "2025-04-23 08:40:44", "link": "http://arxiv.org/abs/2504.16515v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Amplified Vulnerabilities: Structured Jailbreak Attacks on LLM-based Multi-Agent Debate", "abstract": "Multi-Agent Debate (MAD), leveraging collaborative interactions among Large\nLanguage Models (LLMs), aim to enhance reasoning capabilities in complex tasks.\nHowever, the security implications of their iterative dialogues and\nrole-playing characteristics, particularly susceptibility to jailbreak attacks\neliciting harmful content, remain critically underexplored. This paper\nsystematically investigates the jailbreak vulnerabilities of four prominent MAD\nframeworks built upon leading commercial LLMs (GPT-4o, GPT-4, GPT-3.5-turbo,\nand DeepSeek) without compromising internal agents. We introduce a novel\nstructured prompt-rewriting framework specifically designed to exploit MAD\ndynamics via narrative encapsulation, role-driven escalation, iterative\nrefinement, and rhetorical obfuscation. Our extensive experiments demonstrate\nthat MAD systems are inherently more vulnerable than single-agent setups.\nCrucially, our proposed attack methodology significantly amplifies this\nfragility, increasing average harmfulness from 28.14% to 80.34% and achieving\nattack success rates as high as 80% in certain scenarios. These findings reveal\nintrinsic vulnerabilities in MAD architectures and underscore the urgent need\nfor robust, specialized defenses prior to real-world deployment.", "published": "2025-04-23 08:01:50", "link": "http://arxiv.org/abs/2504.16489v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "On Developers' Self-Declaration of AI-Generated Code: An Analysis of Practices", "abstract": "AI code generation tools have gained significant popularity among developers,\nwho use them to assist in software development due to their capability to\ngenerate code. Existing studies mainly explored the quality, e.g., correctness\nand security, of AI-generated code, while in real-world software development,\nthe prerequisite is to distinguish AI-generated code from human-written code,\nwhich emphasizes the need to explicitly declare AI-generated code by\ndevelopers. To this end, this study intends to understand the ways developers\nuse to self-declare AI-generated code and explore the reasons why developers\nchoose to self-declare or not. We conducted a mixed-methods study consisting of\ntwo phases. In the first phase, we mined GitHub repositories and collected 613\ninstances of AI-generated code snippets. In the second phase, we conducted a\nfollow-up industrial survey, which received 111 valid responses. Our research\nrevealed the practices followed by developers to self-declare AI-generated\ncode. Most practitioners (76.6%) always or sometimes self-declare AI-generated\ncode. In contrast, other practitioners (23.4%) noted that they never\nself-declare AI-generated code. The reasons for self-declaring AI-generated\ncode include the need to track and monitor the code for future review and\ndebugging, and ethical considerations. The reasons for not self-declaring\nAI-generated code include extensive modifications to AI-generated code and the\ndevelopers' perception that self-declaration is an unnecessary activity. We\nfinally provided guidelines for practitioners to self-declare AI-generated\ncode, addressing ethical and code quality concerns.", "published": "2025-04-23 07:52:39", "link": "http://arxiv.org/abs/2504.16485v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "The Dance of Atoms-De Novo Protein Design with Diffusion Model", "abstract": "The de novo design of proteins refers to creating proteins with specific\nstructures and functions that do not naturally exist. In recent years, the\naccumulation of high-quality protein structure and sequence data and\ntechnological advancements have paved the way for the successful application of\ngenerative artificial intelligence (AI) models in protein design. These models\nhave surpassed traditional approaches that rely on fragments and\nbioinformatics. They have significantly enhanced the success rate of de novo\nprotein design, and reduced experimental costs, leading to breakthroughs in the\nfield. Among various generative AI models, diffusion models have yielded the\nmost promising results in protein design. In the past two to three years, more\nthan ten protein design models based on diffusion models have emerged. Among\nthem, the representative model, RFDiffusion, has demonstrated success rates in\n25 protein design tasks that far exceed those of traditional methods, and other\nAI-based approaches like RFjoint and hallucination. This review will\nsystematically examine the application of diffusion models in generating\nprotein backbones and sequences. We will explore the strengths and limitations\nof different models, summarize successful cases of protein design using\ndiffusion models, and discuss future development directions.", "published": "2025-04-23 07:45:00", "link": "http://arxiv.org/abs/2504.16479v1", "categories": ["q-bio.BM", "cs.AI"], "primary_category": "q-bio.BM"}
{"title": "Harden and Catch for Just-in-Time Assured LLM-Based Software Testing: Open Research Challenges", "abstract": "Despite decades of research and practice in automated software testing,\nseveral fundamental concepts remain ill-defined and under-explored, yet offer\nenormous potential real-world impact. We show that these concepts raise\nexciting new challenges in the context of Large Language Models for software\ntest generation. More specifically, we formally define and investigate the\nproperties of hardening and catching tests. A hardening test is one that seeks\nto protect against future regressions, while a catching test is one that\ncatches such a regression or a fault in new functionality introduced by a code\nchange. Hardening tests can be generated at any time and may become catching\ntests when a future regression is caught. We also define and motivate the\nCatching `Just-in-Time' (JiTTest) Challenge, in which tests are generated\n`just-in-time' to catch new faults before they land into production. We show\nthat any solution to Catching JiTTest generation can also be repurposed to\ncatch latent faults in legacy code. We enumerate possible outcomes for\nhardening and catching tests and JiTTests, and discuss open research problems,\ndeployment options, and initial results from our work on automated LLM-based\nhardening at Meta. This paper\\footnote{Author order is alphabetical. The\ncorresponding author is Mark Harman.} was written to accompany the keynote by\nthe authors at the ACM International Conference on the Foundations of Software\nEngineering (FSE) 2025.", "published": "2025-04-23 07:32:43", "link": "http://arxiv.org/abs/2504.16472v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "ManipDreamer: Boosting Robotic Manipulation World Model with Action Tree and Visual Guidance", "abstract": "While recent advancements in robotic manipulation video synthesis have shown\npromise, significant challenges persist in ensuring effective\ninstruction-following and achieving high visual quality. Recent methods, like\nRoboDreamer, utilize linguistic decomposition to divide instructions into\nseparate lower-level primitives, conditioning the world model on these\nprimitives to achieve compositional instruction-following. However, these\nseparate primitives do not consider the relationships that exist between them.\nFurthermore, recent methods neglect valuable visual guidance, including depth\nand semantic guidance, both crucial for enhancing visual quality. This paper\nintroduces ManipDreamer, an advanced world model based on the action tree and\nvisual guidance. To better learn the relationships between instruction\nprimitives, we represent the instruction as the action tree and assign\nembeddings to tree nodes, each instruction can acquire its embeddings by\nnavigating through the action tree. The instruction embeddings can be used to\nguide the world model. To enhance visual quality, we combine depth and semantic\nguidance by introducing a visual guidance adapter compatible with the world\nmodel. This visual adapter enhances both the temporal and physical consistency\nof video generation. Based on the action tree and visual guidance, ManipDreamer\nsignificantly boosts the instruction-following ability and visual quality.\nComprehensive evaluations on robotic manipulation benchmarks reveal that\nManipDreamer achieves large improvements in video quality metrics in both seen\nand unseen tasks, with PSNR improved from 19.55 to 21.05, SSIM improved from\n0.7474 to 0.7982 and reduced Flow Error from 3.506 to 3.201 in unseen tasks,\ncompared to the recent RoboDreamer model. Additionally, our method increases\nthe success rate of robotic manipulation tasks by 2.5% in 6 RLbench tasks on\naverage.", "published": "2025-04-23 07:23:41", "link": "http://arxiv.org/abs/2504.16464v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Private Federated Learning using Preference-Optimized Synthetic Data", "abstract": "In practical settings, differentially private Federated learning (DP-FL) is\nthe dominant method for training models from private, on-device client data.\nRecent work has suggested that DP-FL may be enhanced or outperformed by methods\nthat use DP synthetic data (Wu et al., 2024; Hou et al., 2024). The primary\nalgorithms for generating DP synthetic data for FL applications require careful\nprompt engineering based on public information and/or iterative private client\nfeedback. Our key insight is that the private client feedback collected by\nprior DP synthetic data methods (Hou et al., 2024; Xie et al., 2024) can be\nviewed as a preference ranking. Our algorithm, Preference Optimization for\nPrivate Client Data (POPri) harnesses client feedback using preference\noptimization algorithms such as Direct Preference Optimization (DPO) to\nfine-tune LLMs to generate high-quality DP synthetic data. To evaluate POPri,\nwe release LargeFedBench, a new federated text benchmark for uncontaminated LLM\nevaluations on federated client data. POPri substantially improves the utility\nof DP synthetic data relative to prior work on LargeFedBench datasets and an\nexisting benchmark from Xie et al. (2024). POPri closes the gap between\nnext-token prediction accuracy in the fully-private and non-private settings by\nup to 68%, compared to 52% for prior synthetic data methods, and 10% for\nstate-of-the-art DP federated learning methods. The code and data are available\nat https://github.com/meiyuw/POPri.", "published": "2025-04-23 05:57:20", "link": "http://arxiv.org/abs/2504.16438v1", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.DC"], "primary_category": "cs.LG"}
{"title": "iTFKAN: Interpretable Time Series Forecasting with Kolmogorov-Arnold Network", "abstract": "As time evolves, data within specific domains exhibit predictability that\nmotivates time series forecasting to predict future trends from historical\ndata. However, current deep forecasting methods can achieve promising\nperformance but generally lack interpretability, hindering trustworthiness and\npractical deployment in safety-critical applications such as auto-driving and\nhealthcare. In this paper, we propose a novel interpretable model, iTFKAN, for\ncredible time series forecasting. iTFKAN enables further exploration of model\ndecision rationales and underlying data patterns due to its interpretability\nachieved through model symbolization. Besides, iTFKAN develops two strategies,\nprior knowledge injection, and time-frequency synergy learning, to effectively\nguide model learning under complex intertwined time series data. Extensive\nexperimental results demonstrated that iTFKAN can achieve promising forecasting\nperformance while simultaneously possessing high interpretive capabilities.", "published": "2025-04-23 05:34:49", "link": "http://arxiv.org/abs/2504.16432v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "A Survey of Foundation Model-Powered Recommender Systems: From Feature-Based, Generative to Agentic Paradigms", "abstract": "Recommender systems (RS) have become essential in filtering information and\npersonalizing content for users. RS techniques have traditionally relied on\nmodeling interactions between users and items as well as the features of\ncontent using models specific to each task. The emergence of foundation models\n(FMs), large scale models trained on vast amounts of data such as GPT, LLaMA\nand CLIP, is reshaping the recommendation paradigm. This survey provides a\ncomprehensive overview of the Foundation Models for Recommender Systems\n(FM4RecSys), covering their integration in three paradigms: (1) Feature-Based\naugmentation of representations, (2) Generative recommendation approaches, and\n(3) Agentic interactive systems. We first review the data foundations of RS,\nfrom traditional explicit or implicit feedback to multimodal content sources.\nWe then introduce FMs and their capabilities for representation learning,\nnatural language understanding, and multi-modal reasoning in RS contexts. The\ncore of the survey discusses how FMs enhance RS under different paradigms.\nAfterward, we examine FM applications in various recommendation tasks. Through\nan analysis of recent research, we highlight key opportunities that have been\nrealized as well as challenges encountered. Finally, we outline open research\ndirections and technical challenges for next-generation FM4RecSys. This survey\nnot only reviews the state-of-the-art methods but also provides a critical\nanalysis of the trade-offs among the feature-based, the generative, and the\nagentic paradigms, outlining key open issues and future research directions.", "published": "2025-04-23 05:02:51", "link": "http://arxiv.org/abs/2504.16420v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "PixelWeb: The First Web GUI Dataset with Pixel-Wise Labels", "abstract": "Graphical User Interface (GUI) datasets are crucial for various downstream\ntasks. However, GUI datasets often generate annotation information through\nautomatic labeling, which commonly results in inaccurate GUI element BBox\nannotations, including missing, duplicate, or meaningless BBoxes. These issues\ncan degrade the performance of models trained on these datasets, limiting their\neffectiveness in real-world applications. Additionally, existing GUI datasets\nonly provide BBox annotations visually, which restricts the development of\nvisually related GUI downstream tasks. To address these issues, we introduce\nPixelWeb, a large-scale GUI dataset containing over 100,000 annotated web\npages. PixelWeb is constructed using a novel automatic annotation approach that\nintegrates visual feature extraction and Document Object Model (DOM) structure\nanalysis through two core modules: channel derivation and layer analysis.\nChannel derivation ensures accurate localization of GUI elements in cases of\nocclusion and overlapping elements by extracting BGRA four-channel bitmap\nannotations. Layer analysis uses the DOM to determine the visibility and\nstacking order of elements, providing precise BBox annotations. Additionally,\nPixelWeb includes comprehensive metadata such as element images, contours, and\nmask annotations. Manual verification by three independent annotators confirms\nthe high quality and accuracy of PixelWeb annotations. Experimental results on\nGUI element detection tasks show that PixelWeb achieves performance on the\nmAP95 metric that is 3-7 times better than existing datasets. We believe that\nPixelWeb has great potential for performance improvement in downstream tasks\nsuch as GUI generation and automated user interaction.", "published": "2025-04-23 05:01:25", "link": "http://arxiv.org/abs/2504.16419v1", "categories": ["cs.CV", "cs.AI", "cs.HC"], "primary_category": "cs.CV"}
{"title": "FeedQUAC: Quick Unobtrusive AI-Generated Commentary", "abstract": "Design thrives on feedback. However, gathering constant feedback throughout\nthe design process can be labor-intensive and disruptive. We explore how AI can\nbridge this gap by providing effortless, ambient feedback. We introduce\nFeedQUAC, a design companion that delivers real-time AI-generated commentary\nfrom a variety of perspectives through different personas. A design probe study\nwith eight participants highlights how designers can leverage quick yet ambient\nAI feedback to enhance their creative workflows. Participants highlight\nbenefits such as convenience, playfulness, confidence boost, and inspiration\nfrom this lightweight feedback agent, while suggesting additional features,\nlike chat interaction and context curation. We discuss the role of AI feedback,\nits strengths and limitations, and how to integrate it into existing design\nworkflows while balancing user involvement. Our findings also suggest that\nambient interaction is a valuable consideration for both the design and\nevaluation of future creativity support systems.", "published": "2025-04-23 04:48:00", "link": "http://arxiv.org/abs/2504.16416v1", "categories": ["cs.HC", "cs.AI", "cs.CY", "cs.MM"], "primary_category": "cs.HC"}
{"title": "Assessing the Feasibility of Internet-Sourced Video for Automatic Cattle Lameness Detection", "abstract": "Cattle lameness is often caused by hoof injuries or interdigital dermatitis,\nleads to pain and significantly impacts essential physiological activities such\nas walking, feeding, and drinking. This study presents a deep learning-based\nmodel for detecting cattle lameness, sickness, or gait abnormalities using\npublicly available video data. The dataset consists of 50 unique videos from 40\nindividual cattle, recorded from various angles in both indoor and outdoor\nenvironments. Half of the dataset represents naturally walking\n(normal/non-lame) cattle, while the other half consists of cattle exhibiting\ngait abnormalities (lame). To enhance model robustness and generalizability,\ndata augmentation was applied to the training data. The pre-processed videos\nwere then classified using two deep learning models: ConvLSTM2D and 3D CNN. A\ncomparative analysis of the results demonstrates strong classification\nperformance. Specifically, the 3D CNN model achieved a video-level\nclassification accuracy of 90%, with precision, recall, and f1-score of 90.9%,\n90.9%, and 90.91% respectively. The ConvLSTM2D model exhibited a slightly lower\naccuracy of 85%. This study highlights the effectiveness of directly applying\nclassification models to learn spatiotemporal features from video data,\noffering an alternative to traditional multi-stage approaches that typically\ninvolve object detection, pose estimation, and feature extraction. Besides, the\nfindings demonstrate that the proposed deep learning models, particularly the\n3D CNN, effectively classify and detect lameness in cattle while simplifying\nthe processing pipeline.", "published": "2025-04-23 04:17:41", "link": "http://arxiv.org/abs/2504.16404v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV"], "primary_category": "cs.CV"}
{"title": "PINN-MEP: Continuous Neural Representations for Minimum-Energy Path Discovery in Molecular Systems", "abstract": "Characterizing conformational transitions in physical systems remains a\nfundamental challenge in the computational sciences. Traditional sampling\nmethods like molecular dynamics (MD) or MCMC often struggle with the\nhigh-dimensional nature of molecular systems and the high energy barriers of\ntransitions between stable states. While these transitions are rare events in\nsimulation timescales, they often represent the most biologically significant\nprocesses - for example, the conformational change of an ion channel protein\nfrom its closed to open state, which controls cellular ion flow and is crucial\nfor neural signaling. Such transitions in real systems may take milliseconds to\nseconds but could require months or years of continuous simulation to observe\neven once. We present a method that reformulates transition path generation as\na continuous optimization problem solved through physics-informed neural\nnetworks (PINNs) inspired by string methods for minimum-energy path (MEP)\ngeneration. By representing transition paths as implicit neural functions and\nleveraging automatic differentiation with differentiable molecular dynamics\nforce fields, our method enables the efficient discovery of physically\nrealistic transition pathways without requiring expensive path sampling. We\ndemonstrate our method's effectiveness on two proteins, including an explicitly\nhydrated bovine pancreatic trypsin inhibitor (BPTI) system with over 8,300\natoms.", "published": "2025-04-23 03:02:29", "link": "http://arxiv.org/abs/2504.16381v1", "categories": ["physics.chem-ph", "cs.AI", "physics.comp-ph"], "primary_category": "physics.chem-ph"}
{"title": "Cyberoception: Finding a Painlessly-Measurable New Sense in the Cyberworld Towards Emotion-Awareness in Computing", "abstract": "In Affective computing, recognizing users' emotions accurately is the basis\nof affective human-computer interaction. Understanding users' interoception\ncontributes to a better understanding of individually different emotional\nabilities, which is essential for achieving inter-individually accurate emotion\nestimation. However, existing interoception measurement methods, such as the\nheart rate discrimination task, have several limitations, including their\ndependence on a well-controlled laboratory environment and precision apparatus,\nmaking monitoring users' interoception challenging. This study aims to\ndetermine other forms of data that can explain users' interoceptive or similar\nstates in their real-world lives and propose a novel hypothetical concept\n\"cyberoception,\" a new sense (1) which has properties similar to interoception\nin terms of the correlation with other emotion-related abilities, and (2) which\ncan be measured only by the sensors embedded inside commodity smartphone\ndevices in users' daily lives. Results from a 10-day-long in-lab/in-the-wild\nhybrid experiment reveal a specific cyberoception type \"Turn On\" (users'\nsubjective sensory perception about the frequency of turning-on behavior on\ntheir smartphones), significantly related to participants' emotional valence.\nWe anticipate that cyberoception to serve as a fundamental building block for\ndeveloping more \"emotion-aware\", user-friendly applications and services.", "published": "2025-04-23 02:56:55", "link": "http://arxiv.org/abs/2504.16378v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "CLPSTNet: A Progressive Multi-Scale Convolutional Steganography Model Integrating Curriculum Learning", "abstract": "In recent years, a large number of works have introduced Convolutional Neural\nNetworks (CNNs) into image steganography, which transform traditional\nsteganography methods such as hand-crafted features and prior knowledge design\ninto steganography methods that neural networks autonomically learn information\nembedding. However, due to the inherent complexity of digital images, issues of\ninvisibility and security persist when using CNN models for information\nembedding. In this paper, we propose Curriculum Learning Progressive Steganophy\nNetwork (CLPSTNet). The network consists of multiple progressive multi-scale\nconvolutional modules that integrate Inception structures and dilated\nconvolutions. The module contains multiple branching pathways, starting from a\nsmaller convolutional kernel and dilatation rate, extracting the basic, local\nfeature information from the feature map, and gradually expanding to the\nconvolution with a larger convolutional kernel and dilatation rate for\nperceiving the feature information of a larger receptive field, so as to\nrealize the multi-scale feature extraction from shallow to deep, and from fine\nto coarse, allowing the shallow secret information features to be refined in\ndifferent fusion stages. The experimental results show that the proposed\nCLPSTNet not only has high PSNR , SSIM metrics and decoding accuracy on three\nlarge public datasets, ALASKA2, VOC2012 and ImageNet, but also the\nsteganographic images generated by CLPSTNet have low steganalysis scores.You\ncan find our code at\n\\href{https://github.com/chaos-boops/CLPSTNet}{https://github.com/chaos-boops/CLPSTNet}.", "published": "2025-04-23 02:34:25", "link": "http://arxiv.org/abs/2504.16364v1", "categories": ["cs.CV", "cs.AI", "cs.CR"], "primary_category": "cs.CV"}
{"title": "DP2FL: Dual Prompt Personalized Federated Learning in Foundation Models", "abstract": "Personalized federated learning (PFL) has garnered significant attention for\nits ability to address heterogeneous client data distributions while preserving\ndata privacy. However, when local client data is limited, deep learning models\noften suffer from insufficient training, leading to suboptimal performance.\nFoundation models, such as CLIP (Contrastive Language-Image Pretraining),\nexhibit strong feature extraction capabilities and can alleviate this issue by\nfine-tuning on limited local data. Despite their potential, foundation models\nare rarely utilized in federated learning scenarios, and challenges related to\nintegrating new clients remain largely unresolved. To address these challenges,\nwe propose the Dual Prompt Personalized Federated Learning (DP2FL) framework,\nwhich introduces dual prompts and an adaptive aggregation strategy. DP2FL\ncombines global task awareness with local data-driven insights, enabling local\nmodels to achieve effective generalization while remaining adaptable to\nspecific data distributions. Moreover, DP2FL introduces a global model that\nenables prediction on new data sources and seamlessly integrates newly added\nclients without requiring retraining. Experimental results in highly\nheterogeneous environments validate the effectiveness of DP2FL's prompt design\nand aggregation strategy, underscoring the advantages of prediction on novel\ndata sources and demonstrating the seamless integration of new clients into the\nfederated learning framework.", "published": "2025-04-23 02:13:56", "link": "http://arxiv.org/abs/2504.16357v1", "categories": ["cs.DC", "cs.AI", "cs.LG"], "primary_category": "cs.DC"}
{"title": "Disentangling and Generating Modalities for Recommendation in Missing Modality Scenarios", "abstract": "Multi-modal recommender systems (MRSs) have achieved notable success in\nimproving personalization by leveraging diverse modalities such as images,\ntext, and audio. However, two key challenges remain insufficiently addressed:\n(1) Insufficient consideration of missing modality scenarios and (2) the\noverlooking of unique characteristics of modality features. These challenges\nresult in significant performance degradation in realistic situations where\nmodalities are missing. To address these issues, we propose Disentangling and\nGenerating Modality Recommender (DGMRec), a novel framework tailored for\nmissing modality scenarios. DGMRec disentangles modality features into general\nand specific modality features from an information-based perspective, enabling\nricher representations for recommendation. Building on this, it generates\nmissing modality features by integrating aligned features from other modalities\nand leveraging user modality preferences. Extensive experiments show that\nDGMRec consistently outperforms state-of-the-art MRSs in challenging scenarios,\nincluding missing modalities and new item settings as well as diverse missing\nratios and varying levels of missing modalities. Moreover, DGMRec's\ngeneration-based approach enables cross-modal retrieval, a task inapplicable\nfor existing MRSs, highlighting its adaptability and potential for real-world\napplications. Our code is available at https://github.com/ptkjw1997/DGMRec.", "published": "2025-04-23 02:04:14", "link": "http://arxiv.org/abs/2504.16352v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "QAOA-GPT: Efficient Generation of Adaptive and Regular Quantum Approximate Optimization Algorithm Circuits", "abstract": "Quantum computing has the potential to improve our ability to solve certain\noptimization problems that are computationally difficult for classical\ncomputers, by offering new algorithmic approaches that may provide speedups\nunder specific conditions. In this work, we introduce QAOA-GPT, a generative\nframework that leverages Generative Pretrained Transformers (GPT) to directly\nsynthesize quantum circuits for solving quadratic unconstrained binary\noptimization problems, and demonstrate it on the MaxCut problem on graphs. To\ndiversify the training circuits and ensure their quality, we have generated a\nsynthetic dataset using the adaptive QAOA approach, a method that incrementally\nbuilds and optimizes problem-specific circuits. The experiments conducted on a\ncurated set of graph instances demonstrate that QAOA-GPT, generates high\nquality quantum circuits for new problem instances unseen in the training as\nwell as successfully parametrizes QAOA. Our results show that using QAOA-GPT to\ngenerate quantum circuits will significantly decrease both the computational\noverhead of classical QAOA and adaptive approaches that often use gradient\nevaluation to generate the circuit and the classical optimization of the\ncircuit parameters. Our work shows that generative AI could be a promising\navenue to generate compact quantum circuits in a scalable way.", "published": "2025-04-23 02:00:36", "link": "http://arxiv.org/abs/2504.16350v1", "categories": ["quant-ph", "cs.AI"], "primary_category": "quant-ph"}
{"title": "Mining Software Repositories for Expert Recommendation", "abstract": "We propose an automated approach to bug assignment to developers in large\nopen-source software projects. This way, we assist human bug triagers who are\nin charge of finding the best developer with the right level of expertise in a\nparticular area to be assigned to a newly reported issue. Our approach is based\non the history of software development as documented in the issue tracking\nsystems. We deploy BERTopic and techniques from TopicMiner. Our approach works\nbased on the bug reports' features, such as the corresponding products and\ncomponents, as well as their priority and severity levels. We sort developers\nbased on their experience with specific combinations of new reports. The\nevaluation is performed using Top-k accuracy, and the results are compared with\nthe reported results in prior work, namely TopicMiner MTM, BUGZIE, Bug triaging\nvia deep Reinforcement Learning BT-RL, and LDA-SVM. The evaluation data come\nfrom various Eclipse and Mozilla projects, such as JDT, Firefox, and\nThunderbird.", "published": "2025-04-23 01:41:08", "link": "http://arxiv.org/abs/2504.16343v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Procedural Dataset Generation for Zero-Shot Stereo Matching", "abstract": "Synthetic datasets are a crucial ingredient for training stereo matching\nnetworks, but the question of what makes a stereo dataset effective remains\nlargely unexplored. We investigate the design space of synthetic datasets by\nvarying the parameters of a procedural dataset generator, and report the\neffects on zero-shot stereo matching performance using standard benchmarks. We\ncollect the best settings to produce Infinigen-Stereo, a procedural generator\nspecifically optimized for zero-shot stereo datasets. Models trained only on\ndata from our system outperform robust baselines trained on a combination of\nexisting synthetic datasets and have stronger zero-shot stereo matching\nperformance than public checkpoints from prior works. We open source our system\nat https://github.com/princeton-vl/InfinigenStereo to enable further research\non procedural stereo datasets.", "published": "2025-04-23 17:59:33", "link": "http://arxiv.org/abs/2504.16930v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DreamO: A Unified Framework for Image Customization", "abstract": "Recently, extensive research on image customization (e.g., identity, subject,\nstyle, background, etc.) demonstrates strong customization capabilities in\nlarge-scale generative models. However, most approaches are designed for\nspecific tasks, restricting their generalizability to combine different types\nof condition. Developing a unified framework for image customization remains an\nopen challenge. In this paper, we present DreamO, an image customization\nframework designed to support a wide range of tasks while facilitating seamless\nintegration of multiple conditions. Specifically, DreamO utilizes a diffusion\ntransformer (DiT) framework to uniformly process input of different types.\nDuring training, we construct a large-scale training dataset that includes\nvarious customization tasks, and we introduce a feature routing constraint to\nfacilitate the precise querying of relevant information from reference images.\nAdditionally, we design a placeholder strategy that associates specific\nplaceholders with conditions at particular positions, enabling control over the\nplacement of conditions in the generated results. Moreover, we employ a\nprogressive training strategy consisting of three stages: an initial stage\nfocused on simple tasks with limited data to establish baseline consistency, a\nfull-scale training stage to comprehensively enhance the customization\ncapabilities, and a final quality alignment stage to correct quality biases\nintroduced by low-quality data. Extensive experiments demonstrate that the\nproposed DreamO can effectively perform various image customization tasks with\nhigh quality and flexibly integrate different types of control conditions.", "published": "2025-04-23 17:41:44", "link": "http://arxiv.org/abs/2504.16915v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "High-Quality Cloud-Free Optical Image Synthesis Using Multi-Temporal SAR and Contaminated Optical Data", "abstract": "Addressing gaps caused by cloud cover and the long revisit cycle of\nsatellites is vital for providing essential data to support remote sensing\napplications. This paper tackles the challenges of missing optical data\nsynthesis, particularly in complex scenarios with cloud cover. We propose\nCRSynthNet, a novel image synthesis network that incorporates innovative\ndesigned modules such as the DownUp Block and Fusion Attention to enhance\naccuracy. Experimental results validate the effectiveness of CRSynthNet,\ndemonstrating substantial improvements in restoring structural details,\npreserving spectral consist, and achieving superior visual effects that far\nexceed those produced by comparison methods. It achieves quantitative\nimprovements across multiple metrics: a peak signal-to-noise ratio (PSNR) of\n26.978, a structural similarity index measure (SSIM) of 0.648, and a root mean\nsquare error (RMSE) of 0.050. Furthermore, this study creates the TCSEN12\ndataset, a valuable resource specifically designed to address cloud cover\nchallenges in missing optical data synthesis study. The dataset uniquely\nincludes cloud-covered images and leverages earlier image to predict later\nimage, offering a realistic representation of real-world scenarios. This study\noffer practical method and valuable resources for optical satellite image\nsynthesis task.", "published": "2025-04-23 16:44:53", "link": "http://arxiv.org/abs/2504.16870v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hyperspectral Vision Transformers for Greenhouse Gas Estimations from Space", "abstract": "Hyperspectral imaging provides detailed spectral information and holds\nsignificant potential for monitoring of greenhouse gases (GHGs). However, its\napplication is constrained by limited spatial coverage and infrequent revisit\ntimes. In contrast, multispectral imaging offers broader spatial and temporal\ncoverage but often lacks the spectral detail that can enhance GHG detection. To\naddress these challenges, this study proposes a spectral transformer model that\nsynthesizes hyperspectral data from multispectral inputs. The model is\npre-trained via a band-wise masked autoencoder and subsequently fine-tuned on\nspatio-temporally aligned multispectral-hyperspectral image pairs. The\nresulting synthetic hyperspectral data retain the spatial and temporal benefits\nof multispectral imagery and improve GHG prediction accuracy relative to using\nmultispectral data alone. This approach effectively bridges the trade-off\nbetween spectral resolution and coverage, highlighting its potential to advance\natmospheric monitoring by combining the strengths of hyperspectral and\nmultispectral systems with self-supervised deep learning.", "published": "2025-04-23 16:19:42", "link": "http://arxiv.org/abs/2504.16851v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Low-Cost Photogrammetry System for 3D Plant Modeling and Phenotyping", "abstract": "We present an open-source, low-cost photogrammetry system for 3D plant\nmodeling and phenotyping. The system uses a structure-from-motion approach to\nreconstruct 3D representations of the plants via point clouds. Using wheat as\nan example, we demonstrate how various phenotypic traits can be computed easily\nfrom the point clouds. These include standard measurements such as plant height\nand radius, as well as features that would be more cumbersome to measure by\nhand, such as leaf angles and convex hull. We further demonstrate the utility\nof the system through the investigation of specific metrics that may yield\nobjective classifications of erectophile versus planophile wheat canopy\narchitectures.", "published": "2025-04-23 16:02:52", "link": "http://arxiv.org/abs/2504.16840v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Decoupled Global-Local Alignment for Improving Compositional Understanding", "abstract": "Contrastive Language-Image Pre-training (CLIP) has achieved success on\nmultiple downstream tasks by aligning image and text modalities. However, the\nnature of global contrastive learning limits CLIP's ability to comprehend\ncompositional concepts, such as relations and attributes. Although recent\nstudies employ global hard negative samples to improve compositional\nunderstanding, these methods significantly compromise the model's inherent\ngeneral capabilities by forcibly distancing textual negative samples from\nimages in the embedding space. To overcome this limitation, we introduce a\nDecoupled Global-Local Alignment (DeGLA) framework that improves compositional\nunderstanding while substantially mitigating losses in general capabilities. To\noptimize the retention of the model's inherent capabilities, we incorporate a\nself-distillation mechanism within the global alignment process, aligning the\nlearnable image-text encoder with a frozen teacher model derived from an\nexponential moving average. Under the constraint of self-distillation, it\neffectively mitigates the catastrophic forgetting of pretrained knowledge\nduring fine-tuning. To improve compositional understanding, we first leverage\nthe in-context learning capability of Large Language Models (LLMs) to construct\nabout 2M high-quality negative captions across five types. Subsequently, we\npropose the Image-Grounded Contrast (IGC) loss and Text-Grounded Contrast (TGC)\nloss to enhance vision-language compositionally. Extensive experimental results\ndemonstrate the effectiveness of the DeGLA framework. Compared to previous\nstate-of-the-art methods, DeGLA achieves an average enhancement of 3.5% across\nthe VALSE, SugarCrepe, and ARO benchmarks. Concurrently, it obtains an average\nperformance improvement of 13.0% on zero-shot classification tasks across\neleven datasets. Our code will be released at\nhttps://github.com/xiaoxing2001/DeGLA", "published": "2025-04-23 15:20:53", "link": "http://arxiv.org/abs/2504.16801v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "4D Multimodal Co-attention Fusion Network with Latent Contrastive Alignment for Alzheimer's Diagnosis", "abstract": "Multimodal neuroimaging provides complementary structural and functional\ninsights into both human brain organization and disease-related dynamics.\nRecent studies demonstrate enhanced diagnostic sensitivity for Alzheimer's\ndisease (AD) through synergistic integration of neuroimaging data (e.g., sMRI,\nfMRI) with behavioral cognitive scores tabular data biomarkers. However, the\nintrinsic heterogeneity across modalities (e.g., 4D spatiotemporal fMRI\ndynamics vs. 3D anatomical sMRI structure) presents critical challenges for\ndiscriminative feature fusion. To bridge this gap, we propose M2M-AlignNet: a\ngeometry-aware multimodal co-attention network with latent alignment for early\nAD diagnosis using sMRI and fMRI. At the core of our approach is a\nmulti-patch-to-multi-patch (M2M) contrastive loss function that quantifies and\nreduces representational discrepancies via geometry-weighted patch\ncorrespondence, explicitly aligning fMRI components across brain regions with\ntheir sMRI structural substrates without one-to-one constraints. Additionally,\nwe propose a latent-as-query co-attention module to autonomously discover\nfusion patterns, circumventing modality prioritization biases while minimizing\nfeature redundancy. We conduct extensive experiments to confirm the\neffectiveness of our method and highlight the correspondance between fMRI and\nsMRI as AD biomarkers.", "published": "2025-04-23 15:18:55", "link": "http://arxiv.org/abs/2504.16798v1", "categories": ["cs.MM", "cs.CV", "cs.LG"], "primary_category": "cs.MM"}
{"title": "Advanced Chest X-Ray Analysis via Transformer-Based Image Descriptors and Cross-Model Attention Mechanism", "abstract": "The examination of chest X-ray images is a crucial component in detecting\nvarious thoracic illnesses. This study introduces a new image description\ngeneration model that integrates a Vision Transformer (ViT) encoder with\ncross-modal attention and a GPT-4-based transformer decoder. The ViT captures\nhigh-quality visual features from chest X-rays, which are fused with text data\nthrough cross-modal attention to improve the accuracy, context, and richness of\nimage descriptions. The GPT-4 decoder transforms these fused features into\naccurate and relevant captions. The model was tested on the National Institutes\nof Health (NIH) and Indiana University (IU) Chest X-ray datasets. On the IU\ndataset, it achieved scores of 0.854 (B-1), 0.883 (CIDEr), 0.759 (METEOR), and\n0.712 (ROUGE-L). On the NIH dataset, it achieved the best performance on all\nmetrics: BLEU 1--4 (0.825, 0.788, 0.765, 0.752), CIDEr (0.857), METEOR (0.726),\nand ROUGE-L (0.705). This framework has the potential to enhance chest X-ray\nevaluation, assisting radiologists in more precise and efficient diagnosis.", "published": "2025-04-23 14:46:10", "link": "http://arxiv.org/abs/2504.16774v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Tri-FusionNet: Enhancing Image Description Generation with Transformer-based Fusion Network and Dual Attention Mechanism", "abstract": "Image description generation is essential for accessibility and AI\nunderstanding of visual content. Recent advancements in deep learning have\nsignificantly improved natural language processing and computer vision. In this\nwork, we propose Tri-FusionNet, a novel image description generation model that\nintegrates transformer modules: a Vision Transformer (ViT) encoder module with\ndual-attention mechanism, a Robustly Optimized BERT Approach (RoBERTa) decoder\nmodule, and a Contrastive Language-Image Pre-Training (CLIP) integrating\nmodule. The ViT encoder, enhanced with dual attention, focuses on relevant\nspatial regions and linguistic context, improving image feature extraction. The\nRoBERTa decoder is employed to generate precise textual descriptions. CLIP's\nintegrating module aligns visual and textual data through contrastive learning,\nensuring effective combination of both modalities. This fusion of ViT, RoBERTa,\nand CLIP, along with dual attention, enables the model to produce more\naccurate, contextually rich, and flexible descriptions. The proposed framework\ndemonstrated competitive performance on the Flickr30k and Flickr8k datasets,\nwith BLEU scores ranging from 0.767 to 0.456 and 0.784 to 0.479, CIDEr scores\nof 1.679 and 1.483, METEOR scores of 0.478 and 0.358, and ROUGE-L scores of\n0.567 and 0.789, respectively. On MS-COCO, the framework obtained BLEU scores\nof 0.893 (B-1), 0.821 (B-2), 0.794 (B-3), and 0.725 (B-4). The results\ndemonstrate the effectiveness of Tri-FusionNet in generating high-quality image\ndescriptions.", "published": "2025-04-23 14:33:29", "link": "http://arxiv.org/abs/2504.16761v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Feature Mixing Approach for Detecting Intraoperative Adverse Events in Laparoscopic Roux-en-Y Gastric Bypass Surgery", "abstract": "Intraoperative adverse events (IAEs), such as bleeding or thermal injury, can\nlead to severe postoperative complications if undetected. However, their rarity\nresults in highly imbalanced datasets, posing challenges for AI-based detection\nand severity quantification. We propose BetaMixer, a novel deep learning model\nthat addresses these challenges through a Beta distribution-based mixing\napproach, converting discrete IAE severity scores into continuous values for\nprecise severity regression (0-5 scale). BetaMixer employs Beta\ndistribution-based sampling to enhance underrepresented classes and regularizes\nintermediate embeddings to maintain a structured feature space. A generative\napproach aligns the feature space with sampled IAE severity, enabling robust\nclassification and severity regression via a transformer. Evaluated on the\nMultiBypass140 dataset, which we extended with IAE labels, BetaMixer achieves a\nweighted F1 score of 0.76, recall of 0.81, PPV of 0.73, and NPV of 0.84,\ndemonstrating strong performance on imbalanced data. By integrating Beta\ndistribution-based sampling, feature mixing, and generative modeling, BetaMixer\noffers a robust solution for IAE detection and quantification in clinical\nsettings.", "published": "2025-04-23 14:18:02", "link": "http://arxiv.org/abs/2504.16749v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Frequency-Compensated Network for Daily Arctic Sea Ice Concentration Prediction", "abstract": "Accurately forecasting sea ice concentration (SIC) in the Arctic is critical\nto global ecosystem health and navigation safety. However, current methods\nstill is confronted with two challenges: 1) these methods rarely explore the\nlong-term feature dependencies in the frequency domain. 2) they can hardly\npreserve the high-frequency details, and the changes in the marginal area of\nthe sea ice cannot be accurately captured. To this end, we present a\nFrequency-Compensated Network (FCNet) for Arctic SIC prediction on a daily\nbasis. In particular, we design a dual-branch network, including branches for\nfrequency feature extraction and convolutional feature extraction. For\nfrequency feature extraction, we design an adaptive frequency filter block,\nwhich integrates trainable layers with Fourier-based filters. By adding\nfrequency features, the FCNet can achieve refined prediction of edges and\ndetails. For convolutional feature extraction, we propose a high-frequency\nenhancement block to separate high and low-frequency information. Moreover,\nhigh-frequency features are enhanced via channel-wise attention, and temporal\nattention unit is employed for low-frequency feature extraction to capture\nlong-range sea ice changes. Extensive experiments are conducted on a\nsatellite-derived daily SIC dataset, and the results verify the effectiveness\nof the proposed FCNet. Our codes and data will be made public available at:\nhttps://github.com/oucailab/FCNet .", "published": "2025-04-23 14:15:48", "link": "http://arxiv.org/abs/2504.16745v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Gaussian Splatting is an Effective Data Generator for 3D Object Detection", "abstract": "We investigate data augmentation for 3D object detection in autonomous\ndriving. We utilize recent advancements in 3D reconstruction based on Gaussian\nSplatting for 3D object placement in driving scenes. Unlike existing\ndiffusion-based methods that synthesize images conditioned on BEV layouts, our\napproach places 3D objects directly in the reconstructed 3D space with\nexplicitly imposed geometric transformations. This ensures both the physical\nplausibility of object placement and highly accurate 3D pose and position\nannotations.\n  Our experiments demonstrate that even by integrating a limited number of\nexternal 3D objects into real scenes, the augmented data significantly enhances\n3D object detection performance and outperforms existing diffusion-based 3D\naugmentation for object detection. Extensive testing on the nuScenes dataset\nreveals that imposing high geometric diversity in object placement has a\ngreater impact compared to the appearance diversity of objects. Additionally,\nwe show that generating hard examples, either by maximizing detection loss or\nimposing high visual occlusion in camera images, does not lead to more\nefficient 3D data augmentation for camera-based 3D object detection in\nautonomous driving.", "published": "2025-04-23 14:10:36", "link": "http://arxiv.org/abs/2504.16740v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Prompt-Tuning SAM: From Generalist to Specialist with only 2048 Parameters and 16 Training Images", "abstract": "The Segment Anything Model (SAM) is widely used for segmenting a diverse\nrange of objects in natural images from simple user prompts like points or\nbounding boxes. However, SAM's performance decreases substantially when applied\nto non-natural domains like microscopic imaging. Furthermore, due to SAM's\ninteractive design, it requires a precise prompt for each image and object,\nwhich is unfeasible in many automated biomedical applications. Previous\nsolutions adapt SAM by training millions of parameters via fine-tuning large\nparts of the model or of adapter layers. In contrast, we show that as little as\n2,048 additional parameters are sufficient for turning SAM into a use-case\nspecialist for a certain downstream task. Our novel PTSAM (prompt-tuned SAM)\nmethod uses prompt-tuning, a parameter-efficient fine-tuning technique, to\nadapt SAM for a specific task. We validate the performance of our approach on\nmultiple microscopic and one medical dataset. Our results show that\nprompt-tuning only SAM's mask decoder already leads to a performance on-par\nwith state-of-the-art techniques while requiring roughly 2,000x less trainable\nparameters. For addressing domain gaps, we find that additionally prompt-tuning\nSAM's image encoder is beneficial, further improving segmentation accuracy by\nup to 18% over state-of-the-art results. Since PTSAM can be reliably trained\nwith as little as 16 annotated images, we find it particularly helpful for\napplications with limited training data and domain shifts.", "published": "2025-04-23 14:10:02", "link": "http://arxiv.org/abs/2504.16739v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Energy-Based Pseudo-Label Refining for Source-free Domain Adaptation", "abstract": "Source-free domain adaptation (SFDA), which involves adapting models without\naccess to source data, is both demanding and challenging. Existing SFDA\ntechniques typically rely on pseudo-labels generated from confidence levels,\nleading to negative transfer due to significant noise. To tackle this problem,\nEnergy-Based Pseudo-Label Refining (EBPR) is proposed for SFDA. Pseudo-labels\nare created for all sample clusters according to their energy scores. Global\nand class energy thresholds are computed to selectively filter pseudo-labels.\nFurthermore, a contrastive learning strategy is introduced to filter difficult\nsamples, aligning them with their augmented versions to learn more\ndiscriminative features. Our method is validated on the Office-31, Office-Home,\nand VisDA-C datasets, consistently finding that our model outperformed\nstate-of-the-art methods.", "published": "2025-04-23 13:26:58", "link": "http://arxiv.org/abs/2504.16692v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SemanticSugarBeets: A Multi-Task Framework and Dataset for Inspecting Harvest and Storage Characteristics of Sugar Beets", "abstract": "While sugar beets are stored prior to processing, they lose sugar due to\nfactors such as microorganisms present in adherent soil and excess vegetation.\nTheir automated visual inspection promises to aide in quality assurance and\nthereby increase efficiency throughout the processing chain of sugar\nproduction. In this work, we present a novel high-quality annotated dataset and\ntwo-stage method for the detection, semantic segmentation and mass estimation\nof post-harvest and post-storage sugar beets in monocular RGB images. We\nconduct extensive ablation experiments for the detection of sugar beets and\ntheir fine-grained semantic segmentation regarding damages, rot, soil adhesion\nand excess vegetation. For these tasks, we evaluate multiple image sizes, model\narchitectures and encoders, as well as the influence of environmental\nconditions. Our experiments show an mAP50-95 of 98.8 for sugar-beet detection\nand an mIoU of 64.0 for the best-performing segmentation model.", "published": "2025-04-23 13:14:03", "link": "http://arxiv.org/abs/2504.16684v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "A Diff-Attention Aware State Space Fusion Model for Remote Sensing Classification", "abstract": "Multispectral (MS) and panchromatic (PAN) images describe the same land\nsurface, so these images not only have their own advantages, but also have a\nlot of similar information. In order to separate these similar information and\ntheir respective advantages, reduce the feature redundancy in the fusion stage.\nThis paper introduces a diff-attention aware state space fusion model\n(DAS2F-Model) for multimodal remote sensing image classification. Based on the\nselective state space model, a cross-modal diff-attention module (CMDA-Module)\nis designed to extract and separate the common features and their respective\ndominant features of MS and PAN images. Among this, space preserving visual\nmamba (SPVM) retains image spatial features and captures local features by\noptimizing visual mamba's input reasonably. Considering that features in the\nfusion stage will have large semantic differences after feature separation and\nsimple fusion operations struggle to effectively integrate these significantly\ndifferent features, an attention-aware linear fusion module (AALF-Module) is\nproposed. It performs pixel-wise linear fusion by calculating influence\ncoefficients. This mechanism can fuse features with large semantic differences\nwhile keeping the feature size unchanged. Empirical evaluations indicate that\nthe presented method achieves better results than alternative approaches. The\nrelevant code can be found at:https://github.com/AVKSKVL/DAS-F-Model", "published": "2025-04-23 12:34:32", "link": "http://arxiv.org/abs/2504.16665v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Time Series Dataset of NIR Spectra and RGB and NIR-HSI Images of the Barley Germination Process", "abstract": "We provide an open-source dataset of RGB and NIR-HSI (near-infrared\nhyperspectral imaging) images with associated segmentation masks and NIR\nspectra of 2242 individual malting barley kernels. We imaged every kernel\npre-exposure to moisture and every 24 hours after exposure to moisture for five\nconsecutive days. Every barley kernel was labeled as germinated or not\ngerminated during each image acquisition. The barley kernels were imaged with\nblack filter paper as the background, facilitating straight-forward intensity\nthreshold-based segmentation, e.g., by Otsu's method. This dataset facilitates\ntime series analysis of germination time for barley kernels using either RGB\nimage analysis, NIR spectral analysis, NIR-HSI analysis, or a combination\nhereof.", "published": "2025-04-23 12:25:55", "link": "http://arxiv.org/abs/2504.16658v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Skywork R1V2: Multimodal Hybrid Reinforcement Learning for Reasoning", "abstract": "We present Skywork R1V2, a next-generation multimodal reasoning model and a\nmajor leap forward from its predecessor, Skywork R1V. At its core, R1V2\nintroduces a hybrid reinforcement learning paradigm that harmonizes\nreward-model guidance with rule-based strategies, thereby addressing the\nlong-standing challenge of balancing sophisticated reasoning capabilities with\nbroad generalization. To further enhance training efficiency, we propose the\nSelective Sample Buffer (SSB) mechanism, which effectively counters the\n``Vanishing Advantages'' dilemma inherent in Group Relative Policy Optimization\n(GRPO) by prioritizing high-value samples throughout the optimization process.\nNotably, we observe that excessive reinforcement signals can induce visual\nhallucinations--a phenomenon we systematically monitor and mitigate through\ncalibrated reward thresholds throughout the training process. Empirical results\naffirm the exceptional capability of R1V2, with benchmark-leading performances\nsuch as 62.6 on OlympiadBench, 79.0 on AIME2024, 63.6 on LiveCodeBench, and\n74.0 on MMMU. These results underscore R1V2's superiority over existing\nopen-source models and demonstrate significant progress in closing the\nperformance gap with premier proprietary systems, including Gemini 2.5 and\nOpenAI o4-mini. The Skywork R1V2 model weights have been publicly released to\npromote openness and reproducibility\nhttps://huggingface.co/Skywork/Skywork-R1V2-38B.", "published": "2025-04-23 12:24:10", "link": "http://arxiv.org/abs/2504.16656v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "WiFi based Human Fall and Activity Recognition using Transformer based Encoder Decoder and Graph Neural Networks", "abstract": "Human pose estimation and action recognition have received attention due to\ntheir critical roles in healthcare monitoring, rehabilitation, and assistive\ntechnologies. In this study, we proposed a novel architecture named Transformer\nbased Encoder Decoder Network (TED Net) designed for estimating human skeleton\nposes from WiFi Channel State Information (CSI). TED Net integrates\nconvolutional encoders with transformer based attention mechanisms to capture\nspatiotemporal features from CSI signals. The estimated skeleton poses were\nused as input to a customized Directed Graph Neural Network (DGNN) for action\nrecognition. We validated our model on two datasets: a publicly available multi\nmodal dataset for assessing general pose estimation, and a newly collected\ndataset focused on fall related scenarios involving 20 participants.\nExperimental results demonstrated that TED Net outperformed existing approaches\nin pose estimation, and that the DGNN achieves reliable action classification\nusing CSI based skeletons, with performance comparable to RGB based systems.\nNotably, TED Net maintains robust performance across both fall and non fall\ncases. These findings highlight the potential of CSI driven human skeleton\nestimation for effective action recognition, particularly in home environments\nsuch as elderly fall detection. In such settings, WiFi signals are often\nreadily available, offering a privacy preserving alternative to vision based\nmethods, which may raise concerns about continuous camera monitoring.", "published": "2025-04-23 12:22:24", "link": "http://arxiv.org/abs/2504.16655v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RouteWinFormer: A Route-Window Transformer for Middle-range Attention in Image Restoration", "abstract": "Transformer models have recently garnered significant attention in image\nrestoration due to their ability to capture long-range pixel dependencies.\nHowever, long-range attention often results in computational overhead without\npractical necessity, as degradation and context are typically localized.\nNormalized average attention distance across various degradation datasets shows\nthat middle-range attention is enough for image restoration. Building on this\ninsight, we propose RouteWinFormer, a novel window-based Transformer that\nmodels middle-range context for image restoration. RouteWinFormer incorporates\nRoute-Windows Attnetion Module, which dynamically selects relevant nearby\nwindows based on regional similarity for attention aggregation, extending the\nreceptive field to a mid-range size efficiently. In addition, we introduce\nMulti-Scale Structure Regularization during training, enabling the sub-scale of\nthe U-shaped network to focus on structural information, while the\noriginal-scale learns degradation patterns based on generalized image structure\npriors. Extensive experiments demonstrate that RouteWinFormer outperforms\nstate-of-the-art methods across 9 datasets in various image restoration tasks.", "published": "2025-04-23 11:57:22", "link": "http://arxiv.org/abs/2504.16637v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Dual-Camera All-in-Focus Neural Radiance Fields", "abstract": "We present the first framework capable of synthesizing the all-in-focus\nneural radiance field (NeRF) from inputs without manual refocusing. Without\nrefocusing, the camera will automatically focus on the fixed object for all\nviews, and current NeRF methods typically using one camera fail due to the\nconsistent defocus blur and a lack of sharp reference. To restore the\nall-in-focus NeRF, we introduce the dual-camera from smartphones, where the\nultra-wide camera has a wider depth-of-field (DoF) and the main camera\npossesses a higher resolution. The dual camera pair saves the high-fidelity\ndetails from the main camera and uses the ultra-wide camera's deep DoF as\nreference for all-in-focus restoration. To this end, we first implement spatial\nwarping and color matching to align the dual camera, followed by a\ndefocus-aware fusion module with learnable defocus parameters to predict a\ndefocus map and fuse the aligned camera pair. We also build a multi-view\ndataset that includes image pairs of the main and ultra-wide cameras in a\nsmartphone. Extensive experiments on this dataset verify that our solution,\ntermed DC-NeRF, can produce high-quality all-in-focus novel views and compares\nfavorably against strong baselines quantitatively and qualitatively. We further\nshow DoF applications of DC-NeRF with adjustable blur intensity and focal\nplane, including refocusing and split diopter.", "published": "2025-04-23 11:55:02", "link": "http://arxiv.org/abs/2504.16636v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "EHGCN: Hierarchical Euclidean-Hyperbolic Fusion via Motion-Aware GCN for Hybrid Event Stream Perception", "abstract": "Event cameras, with microsecond temporal resolution and high dynamic range\n(HDR) characteristics, emit high-speed event stream for perception tasks.\nDespite the recent advancement in GNN-based perception methods, they are prone\nto use straightforward pairwise connectivity mechanisms in the pure Euclidean\nspace where they struggle to capture long-range dependencies and fail to\neffectively characterize the inherent hierarchical structures of non-uniformly\ndistributed event stream. To this end, in this paper we propose a novel\napproach named EHGCN, which is a pioneer to perceive event stream in both\nEuclidean and hyperbolic spaces for event vision. In EHGCN, we introduce an\nadaptive sampling strategy to dynamically regulate sampling rates, retaining\ndiscriminative events while attenuating chaotic noise. Then we present a Markov\nVector Field (MVF)-driven motion-aware hyperedge generation method based on\nmotion state transition probabilities, thereby eliminating cross-target\nspurious associations and providing critically topological priors while\ncapturing long-range dependencies between events. Finally, we propose a\nEuclidean-Hyperbolic GCN to fuse the information locally aggregated and\nglobally hierarchically modeled in Euclidean and hyperbolic spaces,\nrespectively, to achieve hybrid event perception. Experimental results on event\nperception tasks such as object detection and recognition validate the\neffectiveness of our approach.", "published": "2025-04-23 11:01:03", "link": "http://arxiv.org/abs/2504.16616v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Federated EndoViT: Pretraining Vision Transformers via Federated Learning on Endoscopic Image Collections", "abstract": "Purpose: In this study, we investigate the training of foundation models\nusing federated learning to address data-sharing limitations and enable\ncollaborative model training without data transfer for minimally invasive\nsurgery. Methods: Inspired by the EndoViT study, we adapt the Masked\nAutoencoder for federated learning, enhancing it with adaptive Sharpness-Aware\nMinimization (FedSAM) and Stochastic Weight Averaging (SWA). Our model is\npretrained on the Endo700k dataset collection and later fine-tuned and\nevaluated for tasks such as Semantic Segmentation, Action Triplet Recognition,\nand Surgical Phase Recognition. Results: Our findings demonstrate that\nintegrating adaptive FedSAM into the federated MAE approach improves\npretraining, leading to a reduction in reconstruction loss per patch. The\napplication of FL-EndoViT in surgical downstream tasks results in performance\ncomparable to CEN-EndoViT. Furthermore, FL-EndoViT exhibits advantages over\nCEN-EndoViT in surgical scene segmentation when data is limited and in action\ntriplet recognition when large datasets are used. Conclusion: These findings\nhighlight the potential of federated learning for privacy-preserving training\nof surgical foundation models, offering a robust and generalizable solution for\nsurgical data science. Effective collaboration requires adapting federated\nlearning methods, such as the integration of FedSAM, which can accommodate the\ninherent data heterogeneity across institutions. In future, exploring FL in\nvideo-based models may enhance these capabilities by incorporating\nspatiotemporal dynamics crucial for real-world surgical environments.", "published": "2025-04-23 10:54:32", "link": "http://arxiv.org/abs/2504.16612v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "HUG: Hierarchical Urban Gaussian Splatting with Block-Based Reconstruction", "abstract": "As urban 3D scenes become increasingly complex and the demand for\nhigh-quality rendering grows, efficient scene reconstruction and rendering\ntechniques become crucial. We present HUG, a novel approach to address\ninefficiencies in handling large-scale urban environments and intricate details\nbased on 3D Gaussian splatting. Our method optimizes data partitioning and the\nreconstruction pipeline by incorporating a hierarchical neural Gaussian\nrepresentation. We employ an enhanced block-based reconstruction pipeline\nfocusing on improving reconstruction quality within each block and reducing the\nneed for redundant training regions around block boundaries. By integrating\nneural Gaussian representation with a hierarchical architecture, we achieve\nhigh-quality scene rendering at a low computational cost. This is demonstrated\nby our state-of-the-art results on public benchmarks, which prove the\neffectiveness and advantages in large-scale urban scene representation.", "published": "2025-04-23 10:40:40", "link": "http://arxiv.org/abs/2504.16606v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "JEPA for RL: Investigating Joint-Embedding Predictive Architectures for Reinforcement Learning", "abstract": "Joint-Embedding Predictive Architectures (JEPA) have recently become popular\nas promising architectures for self-supervised learning. Vision transformers\nhave been trained using JEPA to produce embeddings from images and videos,\nwhich have been shown to be highly suitable for downstream tasks like\nclassification and segmentation. In this paper, we show how to adapt the JEPA\narchitecture to reinforcement learning from images. We discuss model collapse,\nshow how to prevent it, and provide exemplary data on the classical Cart Pole\ntask.", "published": "2025-04-23 10:16:12", "link": "http://arxiv.org/abs/2504.16591v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CountingDINO: A Training-free Pipeline for Class-Agnostic Counting using Unsupervised Backbones", "abstract": "Class-agnostic counting (CAC) aims to estimate the number of objects in\nimages without being restricted to predefined categories. However, while\ncurrent exemplar-based CAC methods offer flexibility at inference time, they\nstill rely heavily on labeled data for training, which limits scalability and\ngeneralization to many downstream use cases. In this paper, we introduce\nCountingDINO, the first training-free exemplar-based CAC framework that\nexploits a fully unsupervised feature extractor. Specifically, our approach\nemploys self-supervised vision-only backbones to extract object-aware features,\nand it eliminates the need for annotated data throughout the entire proposed\npipeline. At inference time, we extract latent object prototypes via ROI-Align\nfrom DINO features and use them as convolutional kernels to generate similarity\nmaps. These are then transformed into density maps through a simple yet\neffective normalization scheme. We evaluate our approach on the FSC-147\nbenchmark, where we outperform a baseline under the same label-free setting.\nOur method also achieves competitive -- and in some cases superior -- results\ncompared to training-free approaches relying on supervised backbones, as well\nas several fully supervised state-of-the-art methods. This demonstrates that\ntraining-free CAC can be both scalable and competitive. Website:\nhttps://lorebianchi98.github.io/CountingDINO/", "published": "2025-04-23 09:48:08", "link": "http://arxiv.org/abs/2504.16570v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SAIP-Net: Enhancing Remote Sensing Image Segmentation via Spectral Adaptive Information Propagation", "abstract": "Semantic segmentation of remote sensing imagery demands precise spatial\nboundaries and robust intra-class consistency, challenging conventional\nhierarchical models. To address limitations arising from spatial domain feature\nfusion and insufficient receptive fields, this paper introduces SAIP-Net, a\nnovel frequency-aware segmentation framework that leverages Spectral Adaptive\nInformation Propagation. SAIP-Net employs adaptive frequency filtering and\nmulti-scale receptive field enhancement to effectively suppress intra-class\nfeature inconsistencies and sharpen boundary lines. Comprehensive experiments\ndemonstrate significant performance improvements over state-of-the-art methods,\nhighlighting the effectiveness of spectral-adaptive strategies combined with\nexpanded receptive fields for remote sensing image segmentation.", "published": "2025-04-23 09:43:58", "link": "http://arxiv.org/abs/2504.16564v1", "categories": ["cs.CV", "cs.GR"], "primary_category": "cs.CV"}
{"title": "Beyond Anonymization: Object Scrubbing for Privacy-Preserving 2D and 3D Vision Tasks", "abstract": "We introduce ROAR (Robust Object Removal and Re-annotation), a scalable\nframework for privacy-preserving dataset obfuscation that eliminates sensitive\nobjects instead of modifying them. Our method integrates instance segmentation\nwith generative inpainting to remove identifiable entities while preserving\nscene integrity. Extensive evaluations on 2D COCO-based object detection show\nthat ROAR achieves 87.5% of the baseline detection average precision (AP),\nwhereas image dropping achieves only 74.2% of the baseline AP, highlighting the\nadvantage of scrubbing in preserving dataset utility. The degradation is even\nmore severe for small objects due to occlusion and loss of fine-grained\ndetails. Furthermore, in NeRF-based 3D reconstruction, our method incurs a PSNR\nloss of at most 1.66 dB while maintaining SSIM and improving LPIPS,\ndemonstrating superior perceptual quality. Our findings establish object\nremoval as an effective privacy framework, achieving strong privacy guarantees\nwith minimal performance trade-offs. The results highlight key challenges in\ngenerative inpainting, occlusion-robust segmentation, and task-specific\nscrubbing, setting the foundation for future advancements in privacy-preserving\nvision systems.", "published": "2025-04-23 09:33:10", "link": "http://arxiv.org/abs/2504.16557v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ToF-Splatting: Dense SLAM using Sparse Time-of-Flight Depth and Multi-Frame Integration", "abstract": "Time-of-Flight (ToF) sensors provide efficient active depth sensing at\nrelatively low power budgets; among such designs, only very sparse measurements\nfrom low-resolution sensors are considered to meet the increasingly limited\npower constraints of mobile and AR/VR devices. However, such extreme sparsity\nlevels limit the seamless usage of ToF depth in SLAM. In this work, we propose\nToF-Splatting, the first 3D Gaussian Splatting-based SLAM pipeline tailored for\nusing effectively very sparse ToF input data. Our approach improves upon the\nstate of the art by introducing a multi-frame integration module, which\nproduces dense depth maps by merging cues from extremely sparse ToF depth,\nmonocular color, and multi-view geometry. Extensive experiments on both\nsynthetic and real sparse ToF datasets demonstrate the viability of our\napproach, as it achieves state-of-the-art tracking and mapping performances on\nreference datasets.", "published": "2025-04-23 09:19:43", "link": "http://arxiv.org/abs/2504.16545v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Streetscape Analysis with Generative AI (SAGAI): Vision-Language Assessment and Mapping of Urban Scenes", "abstract": "Streetscapes are an essential component of urban space. Their assessment is\npresently either limited to morphometric properties of their mass skeleton or\nrequires labor-intensive qualitative evaluations of visually perceived\nqualities. This paper introduces SAGAI: Streetscape Analysis with Generative\nArtificial Intelligence, a modular workflow for scoring street-level urban\nscenes using open-access data and vision-language models. SAGAI integrates\nOpenStreetMap geometries, Google Street View imagery, and a lightweight version\nof the LLaVA model to generate structured spatial indicators from images via\ncustomizable natural language prompts. The pipeline includes an automated\nmapping module that aggregates visual scores at both the point and street\nlevels, enabling direct cartographic interpretation. It operates without\ntask-specific training or proprietary software dependencies, supporting\nscalable and interpretable analysis of urban environments. Two exploratory case\nstudies in Nice and Vienna illustrate SAGAI's capacity to produce geospatial\noutputs from vision-language inference. The initial results show strong\nperformance for binary urban-rural scene classification, moderate precision in\ncommercial feature detection, and lower estimates, but still informative, of\nsidewalk width. Fully deployable by any user, SAGAI can be easily adapted to a\nwide range of urban research themes, such as walkability, safety, or urban\ndesign, through prompt modification alone.", "published": "2025-04-23 09:08:06", "link": "http://arxiv.org/abs/2504.16538v1", "categories": ["cs.CV", "cs.LG", "I.2; I.4; J.4"], "primary_category": "cs.CV"}
{"title": "A Few-Shot Metric Learning Method with Dual-Channel Attention for Cross-Modal Same-Neuron Identification", "abstract": "In neuroscience research, achieving single-neuron matching across different\nimaging modalities is critical for understanding the relationship between\nneuronal structure and function. However, modality gaps and limited annotations\npresent significant challenges. We propose a few-shot metric learning method\nwith a dual-channel attention mechanism and a pretrained vision transformer to\nenable robust cross-modal neuron identification. The local and global channels\nextract soma morphology and fiber context, respectively, and a gating mechanism\nfuses their outputs. To enhance the model's fine-grained discrimination\ncapability, we introduce a hard sample mining strategy based on the\nMultiSimilarityMiner algorithm, along with the Circle Loss function.\nExperiments on two-photon and fMOST datasets demonstrate superior Top-K\naccuracy and recall compared to existing methods. Ablation studies and t-SNE\nvisualizations validate the effectiveness of each module. The method also\nachieves a favorable trade-off between accuracy and training efficiency under\ndifferent fine-tuning strategies. These results suggest that the proposed\napproach offers a promising technical solution for accurate single-cell level\nmatching and multimodal neuroimaging integration.", "published": "2025-04-23 08:45:23", "link": "http://arxiv.org/abs/2504.16520v1", "categories": ["cs.CV", "q-bio.NC"], "primary_category": "cs.CV"}
{"title": "TraveLLaMA: Facilitating Multi-modal Large Language Models to Understand Urban Scenes and Provide Travel Assistance", "abstract": "Tourism and travel planning increasingly rely on digital assistance, yet\nexisting multimodal AI systems often lack specialized knowledge and contextual\nunderstanding of urban environments. We present TraveLLaMA, a specialized\nmultimodal language model designed for urban scene understanding and travel\nassistance. Our work addresses the fundamental challenge of developing\npractical AI travel assistants through a novel large-scale dataset of 220k\nquestion-answer pairs. This comprehensive dataset uniquely combines 130k text\nQA pairs meticulously curated from authentic travel forums with GPT-enhanced\nresponses, alongside 90k vision-language QA pairs specifically focused on map\nunderstanding and scene comprehension. Through extensive fine-tuning\nexperiments on state-of-the-art vision-language models (LLaVA, Qwen-VL,\nShikra), we demonstrate significant performance improvements ranging from\n6.5\\%-9.4\\% in both pure text travel understanding and visual question\nanswering tasks. Our model exhibits exceptional capabilities in providing\ncontextual travel recommendations, interpreting map locations, and\nunderstanding place-specific imagery while offering practical information such\nas operating hours and visitor reviews. Comparative evaluations show TraveLLaMA\nsignificantly outperforms general-purpose models in travel-specific tasks,\nestablishing a new benchmark for multi-modal travel assistance systems.", "published": "2025-04-23 08:32:25", "link": "http://arxiv.org/abs/2504.16505v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "PRaDA: Projective Radial Distortion Averaging", "abstract": "We tackle the problem of automatic calibration of radially distorted cameras\nin challenging conditions. Accurately determining distortion parameters\ntypically requires either 1) solving the full Structure from Motion (SfM)\nproblem involving camera poses, 3D points, and the distortion parameters, which\nis only possible if many images with sufficient overlap are provided, or 2)\nrelying heavily on learning-based methods that are comparatively less accurate.\nIn this work, we demonstrate that distortion calibration can be decoupled from\n3D reconstruction, maintaining the accuracy of SfM-based methods while avoiding\nmany of the associated complexities. This is achieved by working in Projective\nSpace, where the geometry is unique up to a homography, which encapsulates all\ncamera parameters except for distortion. Our proposed method, Projective Radial\nDistortion Averaging, averages multiple distortion estimates in a fully\nprojective framework without creating 3d points and full bundle adjustment. By\nrelying on pairwise projective relations, our methods support any\nfeature-matching approaches without constructing point tracks across multiple\nimages.", "published": "2025-04-23 08:22:59", "link": "http://arxiv.org/abs/2504.16499v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Rethinking Generalizable Infrared Small Target Detection: A Real-scene Benchmark and Cross-view Representation Learning", "abstract": "Infrared small target detection (ISTD) is highly sensitive to sensor type,\nobservation conditions, and the intrinsic properties of the target. These\nfactors can introduce substantial variations in the distribution of acquired\ninfrared image data, a phenomenon known as domain shift. Such distribution\ndiscrepancies significantly hinder the generalization capability of ISTD models\nacross diverse scenarios. To tackle this challenge, this paper introduces an\nISTD framework enhanced by domain adaptation. To alleviate distribution shift\nbetween datasets and achieve cross-sample alignment, we introduce Cross-view\nChannel Alignment (CCA). Additionally, we propose the Cross-view Top-K Fusion\nstrategy, which integrates target information with diverse background features,\nenhancing the model' s ability to extract critical data characteristics. To\nfurther mitigate the impact of noise on ISTD, we develop a Noise-guided\nRepresentation learning strategy. This approach enables the model to learn more\nnoise-resistant feature representations, to improve its generalization\ncapability across diverse noisy domains. Finally, we develop a dedicated\ninfrared small target dataset, RealScene-ISTD. Compared to state-of-the-art\nmethods, our approach demonstrates superior performance in terms of detection\nprobability (Pd), false alarm rate (Fa), and intersection over union (IoU). The\ncode is available at: https://github.com/luy0222/RealScene-ISTD.", "published": "2025-04-23 07:58:15", "link": "http://arxiv.org/abs/2504.16487v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RGB-D Video Object Segmentation via Enhanced Multi-store Feature Memory", "abstract": "The RGB-Depth (RGB-D) Video Object Segmentation (VOS) aims to integrate the\nfine-grained texture information of RGB with the spatial geometric clues of\ndepth modality, boosting the performance of segmentation. However,\noff-the-shelf RGB-D segmentation methods fail to fully explore cross-modal\ninformation and suffer from object drift during long-term prediction. In this\npaper, we propose a novel RGB-D VOS method via multi-store feature memory for\nrobust segmentation. Specifically, we design the hierarchical modality\nselection and fusion, which adaptively combines features from both modalities.\nAdditionally, we develop a segmentation refinement module that effectively\nutilizes the Segmentation Anything Model (SAM) to refine the segmentation mask,\nensuring more reliable results as memory to guide subsequent segmentation\ntasks. By leveraging spatio-temporal embedding and modality embedding, mixed\nprompts and fused images are fed into SAM to unleash its potential in RGB-D\nVOS. Experimental results show that the proposed method achieves\nstate-of-the-art performance on the latest RGB-D VOS benchmark.", "published": "2025-04-23 07:31:37", "link": "http://arxiv.org/abs/2504.16471v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MTSGL: Multi-Task Structure Guided Learning for Robust and Interpretable SAR Aircraft Recognition", "abstract": "Aircraft recognition in synthetic aperture radar (SAR) imagery is a\nfundamental mission in both military and civilian applications. Recently deep\nlearning (DL) has emerged a dominant paradigm for its explosive performance on\nextracting discriminative features. However, current classification algorithms\nfocus primarily on learning decision hyperplane without enough comprehension on\naircraft structural knowledge. Inspired by the fined aircraft annotation\nmethods for optical remote sensing images (RSI), we first introduce a\nstructure-based SAR aircraft annotations approach to provide structural and\ncompositional supplement information. On this basis, we propose a multi-task\nstructure guided learning (MTSGL) network for robust and interpretable SAR\naircraft recognition. Besides the classification task, MTSGL includes a\nstructural semantic awareness (SSA) module and a structural consistency\nregularization (SCR) module. The SSA is designed to capture structure semantic\ninformation, which is conducive to gain human-like comprehension of aircraft\nknowledge. The SCR helps maintain the geometric consistency between the\naircraft structure in SAR imagery and the proposed annotation. In this process,\nthe structural attribute can be disentangled in a geometrically meaningful\nmanner. In conclusion, the MTSGL is presented with the expert-level aircraft\nprior knowledge and structure guided learning paradigm, aiming to comprehend\nthe aircraft concept in a way analogous to the human cognitive process.\nExtensive experiments are conducted on a self-constructed multi-task SAR\naircraft recognition dataset (MT-SARD) and the effective results illustrate the\nsuperiority of robustness and interpretation ability of the proposed MTSGL.", "published": "2025-04-23 07:27:08", "link": "http://arxiv.org/abs/2504.16467v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Cross Paradigm Representation and Alignment Transformer for Image Deraining", "abstract": "Transformer-based networks have achieved strong performance in low-level\nvision tasks like image deraining by utilizing spatial or channel-wise\nself-attention. However, irregular rain patterns and complex geometric overlaps\nchallenge single-paradigm architectures, necessitating a unified framework to\nintegrate complementary global-local and spatial-channel representations. To\naddress this, we propose a novel Cross Paradigm Representation and Alignment\nTransformer (CPRAformer). Its core idea is the hierarchical representation and\nalignment, leveraging the strengths of both paradigms (spatial-channel and\nglobal-local) to aid image reconstruction. It bridges the gap within and\nbetween paradigms, aligning and coordinating them to enable deep interaction\nand fusion of features. Specifically, we use two types of self-attention in the\nTransformer blocks: sparse prompt channel self-attention (SPC-SA) and spatial\npixel refinement self-attention (SPR-SA). SPC-SA enhances global channel\ndependencies through dynamic sparsity, while SPR-SA focuses on spatial rain\ndistribution and fine-grained texture recovery. To address the feature\nmisalignment and knowledge differences between them, we introduce the Adaptive\nAlignment Frequency Module (AAFM), which aligns and interacts with features in\na two-stage progressive manner, enabling adaptive guidance and complementarity.\nThis reduces the information gap within and between paradigms. Through this\nunified cross-paradigm dynamic interaction framework, we achieve the extraction\nof the most valuable interactive fusion information from the two paradigms.\nExtensive experiments demonstrate that our model achieves state-of-the-art\nperformance on eight benchmark datasets and further validates CPRAformer's\nrobustness in other image restoration tasks and downstream applications.", "published": "2025-04-23 06:44:46", "link": "http://arxiv.org/abs/2504.16455v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Marginalized Generalized IoU (MGIoU): A Unified Objective Function for Optimizing Any Convex Parametric Shapes", "abstract": "Optimizing the similarity between parametric shapes is crucial for numerous\ncomputer vision tasks, where Intersection over Union (IoU) stands as the\ncanonical measure. However, existing optimization methods exhibit significant\nshortcomings: regression-based losses like L1/L2 lack correlation with IoU,\nIoU-based losses are unstable and limited to simple shapes, and task-specific\nmethods are computationally intensive and not generalizable accross domains. As\na result, the current landscape of parametric shape objective functions has\nbecome scattered, with each domain proposing distinct IoU approximations. To\naddress this, we unify the parametric shape optimization objective functions by\nintroducing Marginalized Generalized IoU (MGIoU), a novel loss function that\novercomes these challenges by projecting structured convex shapes onto their\nunique shape Normals to compute one-dimensional normalized GIoU. MGIoU offers a\nsimple, efficient, fully differentiable approximation strongly correlated with\nIoU. We then extend MGIoU to MGIoU+ that supports optimizing unstructured\nconvex shapes. Together, MGIoU and MGIoU+ unify parametric shape optimization\nacross diverse applications. Experiments on standard benchmarks demonstrate\nthat MGIoU and MGIoU+ consistently outperform existing losses while reducing\nloss computation latency by 10-40x. Additionally, MGIoU and MGIoU+ satisfy\nmetric properties and scale-invariance, ensuring robustness as an objective\nfunction. We further propose MGIoU- for minimizing overlaps in tasks like\ncollision-free trajectory prediction. Code is available at\nhttps://ldtho.github.io/MGIoU", "published": "2025-04-23 06:05:39", "link": "http://arxiv.org/abs/2504.16443v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FrogDogNet: Fourier frequency Retained visual prompt Output Guidance for Domain Generalization of CLIP in Remote Sensing", "abstract": "In recent years, large-scale vision-language models (VLMs) like CLIP have\ngained attention for their zero-shot inference using instructional text\nprompts. While these models excel in general computer vision, their potential\nfor domain generalization in remote sensing (RS) remains underexplored.\nExisting approaches enhance prompt learning by generating visual prompt tokens\nbut rely on full-image features, introducing noise and background artifacts\nthat vary within a class, causing misclassification. To address this, we\npropose FrogDogNet, a novel prompt learning framework integrating Fourier\nfrequency filtering and self-attention to improve RS scene classification and\ndomain generalization. FrogDogNet selectively retains invariant low-frequency\ncomponents while eliminating noise and irrelevant backgrounds, ensuring robust\nfeature representation across domains. The model first extracts significant\nfeatures via projection and self-attention, then applies frequency-based\nfiltering to preserve essential structural information for prompt learning.\nExtensive experiments on four RS datasets and three domain generalization tasks\nshow that FrogDogNet consistently outperforms state-of-the-art prompt learning\nmethods, demonstrating superior adaptability across domain shifts. Our findings\nhighlight the effectiveness of frequency-based invariant feature retention in\ngeneralization, paving the way for broader applications. Our code is available\nat https://github.com/HariseetharamG/FrogDogNet", "published": "2025-04-23 05:35:59", "link": "http://arxiv.org/abs/2504.16433v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SaENeRF: Suppressing Artifacts in Event-based Neural Radiance Fields", "abstract": "Event cameras are neuromorphic vision sensors that asynchronously capture\nchanges in logarithmic brightness changes, offering significant advantages such\nas low latency, low power consumption, low bandwidth, and high dynamic range.\nWhile these characteristics make them ideal for high-speed scenarios,\nreconstructing geometrically consistent and photometrically accurate 3D\nrepresentations from event data remains fundamentally challenging. Current\nevent-based Neural Radiance Fields (NeRF) methods partially address these\nchallenges but suffer from persistent artifacts caused by aggressive network\nlearning in early stages and the inherent noise of event cameras. To overcome\nthese limitations, we present SaENeRF, a novel self-supervised framework that\neffectively suppresses artifacts and enables 3D-consistent, dense, and\nphotorealistic NeRF reconstruction of static scenes solely from event streams.\nOur approach normalizes predicted radiance variations based on accumulated\nevent polarities, facilitating progressive and rapid learning for scene\nrepresentation construction. Additionally, we introduce regularization losses\nspecifically designed to suppress artifacts in regions where photometric\nchanges fall below the event threshold and simultaneously enhance the light\nintensity difference of non-zero events, thereby improving the visual fidelity\nof the reconstructed scene. Extensive qualitative and quantitative experiments\ndemonstrate that our method significantly reduces artifacts and achieves\nsuperior reconstruction quality compared to existing methods. The code is\navailable at https://github.com/Mr-firework/SaENeRF.", "published": "2025-04-23 03:33:20", "link": "http://arxiv.org/abs/2504.16389v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Revisiting Radar Camera Alignment by Contrastive Learning for 3D Object Detection", "abstract": "Recently, 3D object detection algorithms based on radar and camera fusion\nhave shown excellent performance, setting the stage for their application in\nautonomous driving perception tasks. Existing methods have focused on dealing\nwith feature misalignment caused by the domain gap between radar and camera.\nHowever, existing methods either neglect inter-modal features interaction\nduring alignment or fail to effectively align features at the same spatial\nlocation across modalities. To alleviate the above problems, we propose a new\nalignment model called Radar Camera Alignment (RCAlign). Specifically, we\ndesign a Dual-Route Alignment (DRA) module based on contrastive learning to\nalign and fuse the features between radar and camera. Moreover, considering the\nsparsity of radar BEV features, a Radar Feature Enhancement (RFE) module is\nproposed to improve the densification of radar BEV features with the knowledge\ndistillation loss. Experiments show RCAlign achieves a new state-of-the-art on\nthe public nuScenes benchmark in radar camera fusion for 3D Object Detection.\nFurthermore, the RCAlign achieves a significant performance gain (4.3\\% NDS and\n8.4\\% mAP) in real-time 3D detection compared to the latest state-of-the-art\nmethod (RCBEVDet).", "published": "2025-04-23 02:41:43", "link": "http://arxiv.org/abs/2504.16368v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Almost Right: Making First-layer Kernels Nearly Orthogonal Improves Model Generalization", "abstract": "An ongoing research challenge within several domains in computer vision is\nhow to increase model generalization capabilities. Several attempts to improve\nmodel generalization performance are heavily inspired by human perceptual\nintelligence, which is remarkable in both its performance and efficiency to\ngeneralize to unknown samples. Many of these methods attempt to force portions\nof the network to be orthogonal, following some observation within neuroscience\nrelated to early vision processes. In this paper, we propose a loss component\nthat regularizes the filtering kernels in the first convolutional layer of a\nnetwork to make them nearly orthogonal. Deviating from previous works, we give\nthe network flexibility in which pairs of kernels it makes orthogonal, allowing\nthe network to navigate to a better solution space, imposing harsh penalties.\nWithout architectural modifications, we report substantial gains in\ngeneralization performance using the proposed loss against previous works\n(including orthogonalization- and saliency-based regularization methods) across\nthree different architectures (ResNet-50, DenseNet-121, ViT-b-16) and two\ndifficult open-set recognition tasks: presentation attack detection in iris\nbiometrics, and anomaly detection in chest X-ray images.", "published": "2025-04-23 02:27:20", "link": "http://arxiv.org/abs/2504.16362v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "On graphs with a simple structure of maximal cliques", "abstract": "We say that a hereditary graph class $\\mathcal{G}$ is \\emph{clique-sparse} if\nthere is a constant $k=k(\\mathcal{G})$ such that for every graph\n$G\\in\\mathcal{G}$, every vertex of $G$ belongs to at most $k$ maximal cliques,\nand any maximal clique of $G$ can be intersected in at most $k$ different ways\nby other maximal cliques.\n  We provide various characterisations of clique-sparse graph classes,\nincluding a list of five parametric forbidden induced subgraphs. We show that\nrecent techniques for proving induced analogues of Menger's Theorem and the\nGrid Theorem of Robertson and Seymour can be lifted to prove induced variants\nin clique-sparse graph classes when replacing ``treewidth'' by\n''tree-independence number''.", "published": "2025-04-23 16:34:20", "link": "http://arxiv.org/abs/2504.16863v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "An Explicit and Efficient $O(n^2)$-Time Algorithm for Sorting Sumsets", "abstract": "We present the first explicit comparison-based algorithm that sorts the\nsumset $X + Y = \\{x_i + y_j,\\ \\forall 0 \\le i, j < n\\}$, where $X$ and $Y$ are\nsorted arrays of real numbers, in optimal $O(n^2)$ time and comparisons. While\nFredman (1976) proved the theoretical existence of such an algorithm, a\nconcrete construction has remained open for nearly five decades. Our algorithm\nexploits the structured monotonicity of the sumset matrix to perform amortized\nconstant-comparisons and insertions, eliminating the $\\log(n)$ overhead typical\nof comparison-based sorting. We prove correctness and optimality in the\nstandard comparison model, extend the method to $k$-fold sumsets with $O(n^k)$\nperformance, and outline potential support for dynamic updates. Experimental\nbenchmarks show significant speedups over classical algorithms such as\nMergeSort and QuickSort when applied to sumsets. These results resolve a\nlongstanding open problem in sorting theory and contribute novel techniques for\nexploiting input structure in algorithm design.", "published": "2025-04-23 03:42:17", "link": "http://arxiv.org/abs/2504.16393v1", "categories": ["cs.DS", "cs.DM", "68W40 (Primary) 68Q25, 68R05 (Secondary)", "F.2.2; E.1; G.2.1"], "primary_category": "cs.DS"}
{"title": "Search Timelines: Visualizing Search History to Enable Cross-Session Exploratory Search", "abstract": "Purpose: The timespan over which exploratory searching can occur, as well as\nthe scope and volume of the search activities undertaken, can make it difficult\nfor searchers to remember key details about their search activities. These\ndifficulties are present both in the midst of searching as well as when\nresuming a search that spans multiple sessions. In this paper, we present a\nsearch interface designed to support cross-session exploratory search in a\npublic digital library context. Methods: Search Timelines provides a\nvisualization of current and past search activities via a dynamic timeline of\nthe search activity (queries and saved resources). This timeline is presented\nat two levels of detail. An overview timeline is provided alongside the search\nresults in a typical search engine results page design. A detailed timeline is\nprovided in the workspace, where searchers can review the history of their\nsearch activities and their saved resources. A controlled laboratory study was\nconducted to compare this approach to a baseline interface modelled after a\ntypical public digital library search/workspace interface. Results:\nParticipants who used Search Timelines reported higher levels of user\nengagement, usability, and perceived knowledge gain, during an initial search\nsession and when resuming the search after a 7-8 day interval. This came at the\nexpense of the searchers taking more time to complete the search task, which we\nview as positive evidence of engagement in cross-session exploratory search\nprocesses. Conclusion: Search Timelines serves as an example of how lightweight\nvisualization approaches can be used to enhance typical search interface\ndesigns to support exploratory search. The results highlight the value of\nproviding persistent representations of past search activities within the\nsearch interface.", "published": "2025-04-23 14:10:36", "link": "http://arxiv.org/abs/2504.16741v1", "categories": ["cs.HC", "cs.IR"], "primary_category": "cs.HC"}
{"title": "A Unified Retrieval Framework with Document Ranking and EDU Filtering for Multi-document Summarization", "abstract": "In the field of multi-document summarization (MDS), transformer-based models\nhave demonstrated remarkable success, yet they suffer an input length\nlimitation. Current methods apply truncation after the retrieval process to fit\nthe context length; however, they heavily depend on manually well-crafted\nqueries, which are impractical to create for each document set for MDS.\nAdditionally, these methods retrieve information at a coarse granularity,\nleading to the inclusion of irrelevant content. To address these issues, we\npropose a novel retrieval-based framework that integrates query selection and\ndocument ranking and shortening into a unified process. Our approach identifies\nthe most salient elementary discourse units (EDUs) from input documents and\nutilizes them as latent queries. These queries guide the document ranking by\ncalculating relevance scores. Instead of traditional truncation, our approach\nfilters out irrelevant EDUs to fit the context length, ensuring that only\ncritical information is preserved for summarization. We evaluate our framework\non multiple MDS datasets, demonstrating consistent improvements in ROUGE\nmetrics while confirming its scalability and flexibility across diverse model\narchitectures. Additionally, we validate its effectiveness through an in-depth\nanalysis, emphasizing its ability to dynamically select appropriate queries and\naccurately rank documents based on their relevance scores. These results\ndemonstrate that our framework effectively addresses context-length\nconstraints, establishing it as a robust and reliable solution for MDS.", "published": "2025-04-23 13:41:10", "link": "http://arxiv.org/abs/2504.16711v1", "categories": ["cs.LG", "cs.IR"], "primary_category": "cs.LG"}
{"title": "DAPLSR: Data Augmentation Partial Least Squares Regression Model via Manifold Optimization", "abstract": "Traditional Partial Least Squares Regression (PLSR) models frequently\nunderperform when handling data characterized by uneven categories. To address\nthe issue, this paper proposes a Data Augmentation Partial Least Squares\nRegression (DAPLSR) model via manifold optimization. The DAPLSR model\nintroduces the Synthetic Minority Over-sampling Technique (SMOTE) to increase\nthe number of samples and utilizes the Value Difference Metric (VDM) to select\nthe nearest neighbor samples that closely resemble the original samples for\ngenerating synthetic samples. In solving the model, in order to obtain a more\naccurate numerical solution for PLSR, this paper proposes a manifold\noptimization method that uses the geometric properties of the constraint space\nto improve model degradation and optimization. Comprehensive experiments show\nthat the proposed DAPLSR model achieves superior classification performance and\noutstanding evaluation metrics on various datasets, significantly outperforming\nexisting methods.", "published": "2025-04-23 11:58:28", "link": "http://arxiv.org/abs/2504.16639v1", "categories": ["cs.LG", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Information Leakage of Sentence Embeddings via Generative Embedding Inversion Attacks", "abstract": "Text data are often encoded as dense vectors, known as embeddings, which\ncapture semantic, syntactic, contextual, and domain-specific information. These\nembeddings, widely adopted in various applications, inherently contain rich\ninformation that may be susceptible to leakage under certain attacks. The GEIA\nframework highlights vulnerabilities in sentence embeddings, demonstrating that\nthey can reveal the original sentences they represent. In this study, we\nreproduce GEIA's findings across various neural sentence embedding models.\nAdditionally, we contribute new analysis to examine whether these models leak\nsensitive information from their training datasets. We propose a simple yet\neffective method without any modification to the attacker's architecture\nproposed in GEIA. The key idea is to examine differences between log-likelihood\nfor masked and original variants of data that sentence embedding models have\nbeen pre-trained on, calculated on the embedding space of the attacker. Our\nfindings indicate that following our approach, an adversary party can recover\nmeaningful sensitive information related to the pre-training knowledge of the\npopular models used for creating sentence embeddings, seriously undermining\ntheir security. Our code is available on: https://github.com/taslanidis/GEIA", "published": "2025-04-23 10:50:23", "link": "http://arxiv.org/abs/2504.16609v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Enhancing LLM-Based Agents via Global Planning and Hierarchical Execution", "abstract": "Intelligent agent systems based on Large Language Models (LLMs) have shown\ngreat potential in real-world applications. However, existing agent frameworks\nstill face critical limitations in task planning and execution, restricting\ntheir effectiveness and generalizability. Specifically, current planning\nmethods often lack clear global goals, leading agents to get stuck in local\nbranches, or produce non-executable plans. Meanwhile, existing execution\nmechanisms struggle to balance complexity and stability, and their limited\naction space restricts their ability to handle diverse real-world tasks. To\naddress these limitations, we propose GoalAct, a novel agent framework that\nintroduces a continuously updated global planning mechanism and integrates a\nhierarchical execution strategy. GoalAct decomposes task execution into\nhigh-level skills, including searching, coding, writing and more, thereby\nreducing planning complexity while enhancing the agents' adaptability across\ndiverse task scenarios. We evaluate GoalAct on LegalAgentBench, a benchmark\nwith multiple types of legal tasks that require the use of multiple types of\ntools. Experimental results demonstrate that GoalAct achieves state-of-the-art\n(SOTA) performance, with an average improvement of 12.22% in success rate.\nThese findings highlight GoalAct's potential to drive the development of more\nadvanced intelligent agent systems, making them more effective across complex\nreal-world applications. Our code can be found at\nhttps://github.com/cjj826/GoalAct.", "published": "2025-04-23 09:43:40", "link": "http://arxiv.org/abs/2504.16563v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Modality Reliability Guided Multimodal Recommendation", "abstract": "Multimodal recommendation faces an issue of the performance degradation that\nthe uni-modal recommendation sometimes achieves the better performance. A\npossible reason is that the unreliable item modality data hurts the fusion\nresult. Several existing studies have introduced weights for different\nmodalities to reduce the contribution of the unreliable modality data in\npredicting the final user rating. However, they fail to provide appropriate\nsupervisions for learning the modality weights, making the learned weights\nimprecise. Therefore, we propose a modality reliability guided multimodal\nrecommendation framework that uniquely learns the modality weights supervised\nby the modality reliability. Considering that there is no explicit label\nprovided for modality reliability, we resort to automatically identify it\nthrough the BPR recommendation objective. In particular, we define a modality\nreliability vector as the supervision label by the difference between\nmodality-specific user ratings to positive and negative items, where a larger\ndifference indicates a higher reliability of the modality as the BPR objective\nis better satisfied. Furthermore, to enhance the effectiveness of the\nsupervision, we calculate the confidence level for the modality reliability\nvector, which dynamically adjusts the supervision strength and eliminates the\nharmful supervision. Extensive experiments on three real-world datasets show\nthe effectiveness of the proposed method.", "published": "2025-04-23 08:46:23", "link": "http://arxiv.org/abs/2504.16524v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Killing Two Birds with One Stone: Unifying Retrieval and Ranking with a Single Generative Recommendation Model", "abstract": "In recommendation systems, the traditional multi-stage paradigm, which\nincludes retrieval and ranking, often suffers from information loss between\nstages and diminishes performance. Recent advances in generative models,\ninspired by natural language processing, suggest the potential for unifying\nthese stages to mitigate such loss. This paper presents the Unified Generative\nRecommendation Framework (UniGRF), a novel approach that integrates retrieval\nand ranking into a single generative model. By treating both stages as sequence\ngeneration tasks, UniGRF enables sufficient information sharing without\nadditional computational costs, while remaining model-agnostic. To enhance\ninter-stage collaboration, UniGRF introduces a ranking-driven enhancer module\nthat leverages the precision of the ranking stage to refine retrieval\nprocesses, creating an enhancement loop. Besides, a gradient-guided adaptive\nweighter is incorporated to dynamically balance the optimization of retrieval\nand ranking, ensuring synchronized performance improvements. Extensive\nexperiments demonstrate that UniGRF significantly outperforms existing models\non benchmark datasets, confirming its effectiveness in facilitating information\ntransfer. Ablation studies and further experiments reveal that UniGRF not only\npromotes efficient collaboration between stages but also achieves synchronized\noptimization. UniGRF provides an effective, scalable, and compatible framework\nfor generative recommendation systems.", "published": "2025-04-23 06:43:54", "link": "http://arxiv.org/abs/2504.16454v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "MPAD: A New Dimension-Reduction Method for Preserving Nearest Neighbors in High-Dimensional Vector Search", "abstract": "High-dimensional vector embeddings are widely used in retrieval systems, yet\ndimensionality reduction (DR) is seldom applied due to its tendency to distort\nnearest-neighbor (NN) structure critical for search. Existing DR techniques\nsuch as PCA and UMAP optimize global or manifold-preserving criteria, rather\nthan retrieval-specific objectives. We present MPAD: Maximum Pairwise Absolute\nDifference, an unsupervised DR method that explicitly preserves approximate NN\nrelations by maximizing the margin between k-NNs and non-k-NNs under a soft\northogonality constraint. This design enables MPAD to retain ANN-relevant\ngeometry without supervision or changes to the original embedding model.\nExperiments across multiple domains show that MPAD consistently outperforms\nstandard DR methods in preserving neighborhood structure, enabling more\naccurate search in reduced dimensions.", "published": "2025-04-23 00:59:00", "link": "http://arxiv.org/abs/2504.16335v1", "categories": ["cs.IR", "cs.DB"], "primary_category": "cs.IR"}
{"title": "Partial orders and contraction for BISO channels", "abstract": "A fundamental question in information theory is to quantify the loss of\ninformation under a noisy channel. Partial orders and contraction coefficients\nare typical tools to that end, however, they are often also challenging to\nevaluate. For the special class of binary input symmetric output (BISO)\nchannels, Geng et al. showed that among channels with the same capacity, the\nbinary symmetric channel (BSC) and binary erasure channel (BEC) are extremal\nwith respect to the more capable order. Here, we show two main results. First,\nfor channels with the same KL contraction coefficient, the same holds with\nrespect to the less noisy order. Second, for channels with the same Dobrushin\ncoefficient, or equiv. maximum leakage or Doeblin coefficient, the same holds\nwith respect to the degradability order. In the process, we provide a\nclosed-form expression for the contraction coefficients of BISO channels. We\nalso discuss the comparability of BISO channels and extensions to binary\nchannels in general.", "published": "2025-04-23 14:00:36", "link": "http://arxiv.org/abs/2504.16726v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Security Science (SecSci), Basic Concepts and Mathematical Foundations", "abstract": "This textbook compiles the lecture notes from security courses taught at\nOxford in the 2000s, at Royal Holloway in the 2010s, and currently in Hawaii.\nThe early chapters are suitable for a first course in security. The middle\nchapters have been used in advanced courses. Towards the end there are also\nsome research problems.", "published": "2025-04-23 11:04:17", "link": "http://arxiv.org/abs/2504.16617v1", "categories": ["cs.CR", "cs.CY", "cs.IT", "cs.SI", "math.IT", "math.LO", "03-01, 03C65, 68M25", "D.4.6; F.4.1; F.4.3; G.0; H.1; K.4.2; K.6.5"], "primary_category": "cs.CR"}
{"title": "Uplink Sum Rate Maximization for Pinching Antenna-Assisted Multiuser MISO", "abstract": "This article investigates the application of pinching-antenna systems (PASS)\nin multiuser multiple-input single-output (MISO) communications. Two sum-rate\nmaximization problems are formulated under minimum mean square error (MMSE)\ndecoding, with and without successive interference cancellation (SIC). To\naddress the joint optimization of pinching antenna locations and user transmit\npowers, a fractional programming-based approach is proposed. Numerical results\nvalidate the effectiveness of the proposed method and show that PASS can\nsignificantly enhance uplink sum-rate performance compared to conventional\nfixed-antenna designs.", "published": "2025-04-23 09:59:45", "link": "http://arxiv.org/abs/2504.16577v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "LiDAL-Assisted RLNC-NOMA in OWC Systems", "abstract": "Optical wireless communication (OWC) is envisioned as a key enabler for\nimmersive indoor data transmission in future wireless communication networks.\nHowever, multi-user interference management arises as a challenge in dense\nindoor OWC systems composed of multiple optical access points (APs) serving\nmultiple users. In this paper, we propose a novel dual-function OWC system for\ncommunication and localization. Non-orthogonal multiple access (NOMA) with\nrandom linear network coding (RLNC) is designed for data transmission, where\nNOMA allows the serving of multiple users simultaneously through controlling\nthe power domain, and RLNC helps minimize errors that might occur during signal\nprocessing phase. This setup is assisted with a light detection and\nlocalization system (LiDAL) that can passively obtain spatio-temporal indoor\ninformation of user presence and location for dynamic-user grouping. The\ndesigned LiDAL system helps to improve the estimation of channel state\ninformation (CSI) in realistic indoor network scenarios, where the CSI of\nindoor users might be noisy and/or highly correlated. We evaluate the\nperformance of NOMA combined with RLNC by analyzing the probability of\nsuccessful decoding compared to conventional NOMA and orthogonal schemes. In\naddition, we derive the Cramer-Rao Lower Bound (CRLB) to evaluate the accuracy\nof location estimation. The results show that the proposed RLNC-NOMA improves\nthe probability of successful decoding and the overall system performance. The\nresults also show the high accuracy of the unbiased location estimator and its\nassistant in reducing the imperfection of CSI, leading to high overall system\nperformance.", "published": "2025-04-23 08:22:28", "link": "http://arxiv.org/abs/2504.16498v1", "categories": ["eess.SY", "cs.IT", "cs.SY", "math.IT"], "primary_category": "eess.SY"}
{"title": "Closed-form analysis of Multi-RIS Reflected Signals in RIS-Aided Networks Using Stochastic Geometry", "abstract": "Reconfigurable intelligent surfaces (RISs) enhance wireless communication by\ncreating engineered signal reflection paths in addition to direct links. This\nwork presents a stochastic geometry framework using point processes (PPs) to\nmodel multiple randomly deployed RISs conditioned on their associated base\nstation (BS) locations. By characterizing aggregated reflections from multiple\nRISs using the Laplace transform, we analytically assess the performance impact\nof RIS-reflected signals by integrating this characterization into\nwell-established stochastic geometry frameworks. Specifically, we derive\nclosed-form expressions for the Laplace transform of the reflected signal power\nin several deployment scenarios. These analytical results facilitate\nperformance evaluation of RIS-enabled enhancements. Numerical simulations\nvalidate that optimal RIS placement favors proximity to BSs or user equipment\n(UEs), and further quantify the impact of reflected interference, various\nfading assumptions, and diverse spatial deployment strategies. Importantly, our\nanalytical approach shows superior computational efficiency compared to Monte\nCarlo simulations.", "published": "2025-04-23 07:29:32", "link": "http://arxiv.org/abs/2504.16469v1", "categories": ["cs.PF", "cs.IT", "math.IT"], "primary_category": "cs.PF"}
{"title": "Tight Exponential Strong Converses for Lossy Source Coding with Side-Information and Distributed Function Computation", "abstract": "The exponential strong converse for a coding problem states that, if a coding\nrate is beyond the theoretical limit, the correct probability converges to zero\nexponentially. For the lossy source coding with side-information, also known as\nthe Wyner-Ziv (WZ) problem, a lower bound on the strong converse exponent was\nderived by Oohama. In this paper, we derive the tight strong converse exponent\nfor the WZ problem; as a special case, we also derive the tight strong converse\nexponent for the distributed function computation problem. For the converse\npart, we use the change-of-measure argument developed in the literature and the\nsoft Markov constraint introduced by Oohama; the matching achievability is\nproved via the Poisson matching approach recently introduced by Li and\nAnantharam. Our result is build upon the recently derived tight strong converse\nexponent for the Wyner-Ahlswede-Korner (WAK) problem; however, compared to the\nWAK problem, more sophisticated argument is needed. As an illustration of the\nnecessity of the soft Markov constraint, we present an example such that the\nsoft Markov constraint is strictly positive.", "published": "2025-04-23 03:00:44", "link": "http://arxiv.org/abs/2504.16380v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Property-Preserving Hashing for $\\ell_1$-Distance Predicates: Applications to Countering Adversarial Input Attacks", "abstract": "Perceptual hashing is used to detect whether an input image is similar to a\nreference image with a variety of security applications. Recently, they have\nbeen shown to succumb to adversarial input attacks which make small\nimperceptible changes to the input image yet the hashing algorithm does not\ndetect its similarity to the original image. Property-preserving hashing (PPH)\nis a recent construct in cryptography, which preserves some property\n(predicate) of its inputs in the hash domain. Researchers have so far shown\nconstructions of PPH for Hamming distance predicates, which, for instance,\noutputs 1 if two inputs are within Hamming distance $t$. A key feature of PPH\nis its strong correctness guarantee, i.e., the probability that the predicate\nwill not be correctly evaluated in the hash domain is negligible. Motivated by\nthe use case of detecting similar images under adversarial setting, we propose\nthe first PPH construction for an $\\ell_1$-distance predicate. Roughly, this\npredicate checks if the two one-sided $\\ell_1$-distances between two images are\nwithin a threshold $t$. Since many adversarial attacks use $\\ell_2$-distance\n(related to $\\ell_1$-distance) as the objective function to perturb the input\nimage, by appropriately choosing the threshold $t$, we can force the attacker\nto add considerable noise to evade detection, and hence significantly\ndeteriorate the image quality. Our proposed scheme is highly efficient, and\nruns in time $O(t^2)$. For grayscale images of size $28 \\times 28$, we can\nevaluate the predicate in $0.0784$ seconds when pixel values are perturbed by\nup to $1 \\%$. For larger RGB images of size $224 \\times 224$, by dividing the\nimage into 1,000 blocks, we achieve times of $0.0128$ seconds per block for $1\n\\%$ change, and up to $0.2641$ seconds per block for $14\\%$ change.", "published": "2025-04-23 02:11:21", "link": "http://arxiv.org/abs/2504.16355v1", "categories": ["cs.CR", "cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.CR"}
{"title": "Meta-Learning Online Dynamics Model Adaptation in Off-Road Autonomous Driving", "abstract": "High-speed off-road autonomous driving presents unique challenges due to\ncomplex, evolving terrain characteristics and the difficulty of accurately\nmodeling terrain-vehicle interactions. While dynamics models used in\nmodel-based control can be learned from real-world data, they often struggle to\ngeneralize to unseen terrain, making real-time adaptation essential. We propose\na novel framework that combines a Kalman filter-based online adaptation scheme\nwith meta-learned parameters to address these challenges. Offline meta-learning\noptimizes the basis functions along which adaptation occurs, as well as the\nadaptation parameters, while online adaptation dynamically adjusts the onboard\ndynamics model in real time for model-based control. We validate our approach\nthrough extensive experiments, including real-world testing on a full-scale\nautonomous off-road vehicle, demonstrating that our method outperforms baseline\napproaches in prediction accuracy, performance, and safety metrics,\nparticularly in safety-critical scenarios. Our results underscore the\neffectiveness of meta-learned dynamics model adaptation, advancing the\ndevelopment of reliable autonomous systems capable of navigating diverse and\nunseen environments. Video is available at: https://youtu.be/cCKHHrDRQEA", "published": "2025-04-23 17:51:36", "link": "http://arxiv.org/abs/2504.16923v1", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Application of an attention-based CNN-BiLSTM framework for in vivo two-photon calcium imaging of neuronal ensembles: decoding complex bilateral forelimb movements from unilateral M1", "abstract": "Decoding behavior, such as movement, from multiscale brain networks remains a\ncentral objective in neuroscience. Over the past decades, artificial\nintelligence and machine learning have played an increasingly significant role\nin elucidating the neural mechanisms underlying motor function. The advancement\nof brain-monitoring technologies, capable of capturing complex neuronal signals\nwith high spatial and temporal resolution, necessitates the development and\napplication of more sophisticated machine learning models for behavioral\ndecoding. In this study, we employ a hybrid deep learning framework, an\nattention-based CNN-BiLSTM model, to decode skilled and complex forelimb\nmovements using signals obtained from in vivo two-photon calcium imaging. Our\nfindings demonstrate that the intricate movements of both ipsilateral and\ncontralateral forelimbs can be accurately decoded from unilateral M1 neuronal\nensembles. These results highlight the efficacy of advanced hybrid deep\nlearning models in capturing the spatiotemporal dependencies of neuronal\nnetworks activity linked to complex movement execution.", "published": "2025-04-23 17:43:00", "link": "http://arxiv.org/abs/2504.16917v1", "categories": ["q-bio.NC", "cs.LG"], "primary_category": "q-bio.NC"}
{"title": "Exploring zero-shot structure-based protein fitness prediction", "abstract": "The ability to make zero-shot predictions about the fitness consequences of\nprotein sequence changes with pre-trained machine learning models enables many\npractical applications. Such models can be applied for downstream tasks like\ngenetic variant interpretation and protein engineering without additional\nlabeled data. The advent of capable protein structure prediction tools has led\nto the availability of orders of magnitude more precomputed predicted\nstructures, giving rise to powerful structure-based fitness prediction models.\nThrough our experiments, we assess several modeling choices for structure-based\nmodels and their effects on downstream fitness prediction. Zero-shot fitness\nprediction models can struggle to assess the fitness landscape within\ndisordered regions of proteins, those that lack a fixed 3D structure. We\nconfirm the importance of matching protein structures to fitness assays and\nfind that predicted structures for disordered regions can be misleading and\naffect predictive performance. Lastly, we evaluate an additional\nstructure-based model on the ProteinGym substitution benchmark and show that\nsimple multi-modal ensembles are strong baselines.", "published": "2025-04-23 17:01:09", "link": "http://arxiv.org/abs/2504.16886v1", "categories": ["q-bio.QM", "cs.LG", "q-bio.BM"], "primary_category": "q-bio.QM"}
{"title": "Learning Verifiable Control Policies Using Relaxed Verification", "abstract": "To provide safety guarantees for learning-based control systems, recent work\nhas developed formal verification methods to apply after training ends.\nHowever, if the trained policy does not meet the specifications, or there is\nconservatism in the verification algorithm, establishing these guarantees may\nnot be possible. Instead, this work proposes to perform verification throughout\ntraining to ultimately aim for policies whose properties can be evaluated\nthroughout runtime with lightweight, relaxed verification algorithms. The\napproach is to use differentiable reachability analysis and incorporate new\ncomponents into the loss function. Numerical experiments on a quadrotor model\nand unicycle model highlight the ability of this approach to lead to learned\ncontrol policies that satisfy desired reach-avoid and invariance\nspecifications.", "published": "2025-04-23 16:54:35", "link": "http://arxiv.org/abs/2504.16879v1", "categories": ["eess.SY", "cs.LG", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Hybrid Reinforcement Learning and Model Predictive Control for Adaptive Control of Hydrogen-Diesel Dual-Fuel Combustion", "abstract": "Reinforcement Learning (RL) and Machine Learning Integrated Model Predictive\nControl (ML-MPC) are promising approaches for optimizing hydrogen-diesel\ndual-fuel engine control, as they can effectively control multiple-input\nmultiple-output systems and nonlinear processes. ML-MPC is advantageous for\nproviding safe and optimal controls, ensuring the engine operates within\npredefined safety limits. In contrast, RL is distinguished by its adaptability\nto changing conditions through its learning-based approach. However, the\npractical implementation of either method alone poses challenges. RL requires\nhigh variance in control inputs during early learning phases, which can pose\nrisks to the system by potentially executing unsafe actions, leading to\nmechanical damage. Conversely, ML-MPC relies on an accurate system model to\ngenerate optimal control inputs and has limited adaptability to system drifts,\nsuch as injector aging, which naturally occur in engine applications. To\naddress these limitations, this study proposes a hybrid RL and ML-MPC approach\nthat uses an ML-MPC framework while incorporating an RL agent to dynamically\nadjust the ML-MPC load tracking reference in response to changes in the\nenvironment. At the same time, the ML-MPC ensures that actions stay safe\nthroughout the RL agent's exploration. To evaluate the effectiveness of this\napproach, fuel pressure is deliberately varied to introduce a model-plant\nmismatch between the ML-MPC and the engine test bench. The result of this\nmismatch is a root mean square error (RMSE) in indicated mean effective\npressure of 0.57 bar when running the ML-MPC. The experimental results\ndemonstrate that RL successfully adapts to changing boundary conditions by\naltering the tracking reference while ML-MPC ensures safe control inputs. The\nquantitative improvement in load tracking by implementing RL is an RSME of 0.44\nbar.", "published": "2025-04-23 16:51:49", "link": "http://arxiv.org/abs/2504.16875v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Exploring How LLMs Capture and Represent Domain-Specific Knowledge", "abstract": "We study whether Large Language Models (LLMs) inherently capture\ndomain-specific nuances in natural language. Our experiments probe the domain\nsensitivity of LLMs by examining their ability to distinguish queries from\ndifferent domains using hidden states generated during the prefill phase. We\nreveal latent domain-related trajectories that indicate the model's internal\nrecognition of query domains. We also study the robustness of these domain\nrepresentations to variations in prompt styles and sources. Our approach\nleverages these representations for model selection, mapping the LLM that best\nmatches the domain trace of the input query (i.e., the model with the highest\nperformance on similar traces). Our findings show that LLMs can differentiate\nqueries for related domains, and that the fine-tuned model is not always the\nmost accurate. Unlike previous work, our interpretations apply to both closed\nand open-ended generative tasks", "published": "2025-04-23 16:46:06", "link": "http://arxiv.org/abs/2504.16871v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "An Adaptive ML Framework for Power Converter Monitoring via Federated Transfer Learning", "abstract": "This study explores alternative framework configurations for adapting thermal\nmachine learning (ML) models for power converters by combining transfer\nlearning (TL) and federated learning (FL) in a piecewise manner. This approach\ninherently addresses challenges such as varying operating conditions, data\nsharing limitations, and security implications. The framework starts with a\nbase model that is incrementally adapted by multiple clients via adapting three\nstate-of-the-art domain adaptation techniques: Fine-tuning, Transfer Component\nAnalysis (TCA), and Deep Domain Adaptation (DDA). The Flower framework is\nemployed for FL, using Federated Averaging for aggregation. Validation with\nfield data demonstrates that fine-tuning offers a straightforward TL approach\nwith high accuracy, making it suitable for practical applications. Benchmarking\nresults reveal a comprehensive comparison of these methods, showcasing their\nrespective strengths and weaknesses when applied in different scenarios.\nLocally hosted FL enhances performance when data aggregation is not feasible,\nwhile cloud-based FL becomes more practical with a significant increase in the\nnumber of clients, addressing scalability and connectivity challenges.", "published": "2025-04-23 16:39:54", "link": "http://arxiv.org/abs/2504.16866v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Common Functional Decompositions Can Mis-attribute Differences in Outcomes Between Populations", "abstract": "In science and social science, we often wish to explain why an outcome is\ndifferent in two populations. For instance, if a jobs program benefits members\nof one city more than another, is that due to differences in program\nparticipants (particular covariates) or the local labor markets (outcomes given\ncovariates)? The Kitagawa-Oaxaca-Blinder (KOB) decomposition is a standard tool\nin econometrics that explains the difference in the mean outcome across two\npopulations. However, the KOB decomposition assumes a linear relationship\nbetween covariates and outcomes, while the true relationship may be\nmeaningfully nonlinear. Modern machine learning boasts a variety of nonlinear\nfunctional decompositions for the relationship between outcomes and covariates\nin one population. It seems natural to extend the KOB decomposition using these\nfunctional decompositions. We observe that a successful extension should not\nattribute the differences to covariates -- or, respectively, to outcomes given\ncovariates -- if those are the same in the two populations. Unfortunately, we\ndemonstrate that, even in simple examples, two common decompositions --\nfunctional ANOVA and Accumulated Local Effects -- can attribute differences to\noutcomes given covariates, even when they are identical in two populations. We\nprovide a characterization of when functional ANOVA misattributes, as well as a\ngeneral property that any discrete decomposition must satisfy to avoid\nmisattribution. We show that if the decomposition is independent of its input\ndistribution, it does not misattribute. We further conjecture that\nmisattribution arises in any reasonable additive decomposition that depends on\nthe distribution of the covariates.", "published": "2025-04-23 16:36:55", "link": "http://arxiv.org/abs/2504.16864v1", "categories": ["stat.ME", "cs.LG", "econ.EM", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Evaluating Autoencoders for Parametric and Invertible Multidimensional Projections", "abstract": "Recently, neural networks have gained attention for creating parametric and\ninvertible multidimensional data projections. Parametric projections allow for\nembedding previously unseen data without recomputing the projection as a whole,\nwhile invertible projections enable the generation of new data points. However,\nthese properties have never been explored simultaneously for arbitrary\nprojection methods. We evaluate three autoencoder (AE) architectures for\ncreating parametric and invertible projections. Based on a given projection, we\ntrain AEs to learn a mapping into 2D space and an inverse mapping into the\noriginal space. We perform a quantitative and qualitative comparison on four\ndatasets of varying dimensionality and pattern complexity using t-SNE. Our\nresults indicate that AEs with a customized loss function can create smoother\nparametric and inverse projections than feed-forward neural networks while\ngiving users control over the strength of the smoothing effect.", "published": "2025-04-23 15:47:20", "link": "http://arxiv.org/abs/2504.16831v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Online model learning with data-assimilated reservoir computers", "abstract": "We propose an online learning framework for forecasting nonlinear\nspatio-temporal signals (fields). The method integrates (i) dimensionality\nreduction, here, a simple proper orthogonal decomposition (POD) projection;\n(ii) a generalized autoregressive model to forecast reduced dynamics, here, a\nreservoir computer; (iii) online adaptation to update the reservoir computer\n(the model), here, ensemble sequential data assimilation.We demonstrate the\nframework on a wake past a cylinder governed by the Navier-Stokes equations,\nexploring the assimilation of full flow fields (projected onto POD modes) and\nsparse sensors. Three scenarios are examined: a na\\\"ive physical state\nestimation; a two-fold estimation of physical and reservoir states; and a\nthree-fold estimation that also adjusts the model parameters. The two-fold\nstrategy significantly improves ensemble convergence and reduces reconstruction\nerror compared to the na\\\"ive approach. The three-fold approach enables robust\nonline training of partially-trained reservoir computers, overcoming\nlimitations of a priori training. By unifying data-driven reduced order\nmodelling with Bayesian data assimilation, this work opens new opportunities\nfor scalable online model learning for nonlinear time series forecasting.", "published": "2025-04-23 14:35:54", "link": "http://arxiv.org/abs/2504.16767v1", "categories": ["cs.LG", "physics.flu-dyn", "stat.AP"], "primary_category": "cs.LG"}
{"title": "QAOA-PCA: Enhancing Efficiency in the Quantum Approximate Optimization Algorithm via Principal Component Analysis", "abstract": "The Quantum Approximate Optimization Algorithm (QAOA) is a promising\nvariational algorithm for solving combinatorial optimization problems on\nnear-term devices. However, as the number of layers in a QAOA circuit\nincreases, which is correlated with the quality of the solution, the number of\nparameters to optimize grows linearly. This results in more iterations required\nby the classical optimizer, which results in an increasing computational burden\nas more circuit executions are needed. To mitigate this issue, we introduce\nQAOA-PCA, a novel reparameterization technique that employs Principal Component\nAnalysis (PCA) to reduce the dimensionality of the QAOA parameter space. By\nextracting principal components from optimized parameters of smaller problem\ninstances, QAOA-PCA facilitates efficient optimization with fewer parameters on\nlarger instances. Our empirical evaluation on the prominent MaxCut problem\ndemonstrates that QAOA-PCA consistently requires fewer iterations than standard\nQAOA, achieving substantial efficiency gains. While this comes at the cost of a\nslight reduction in approximation ratio compared to QAOA with the same number\nof layers, QAOA-PCA almost always outperforms standard QAOA when matched by\nparameter count. QAOA-PCA strikes a favorable balance between efficiency and\nperformance, reducing optimization overhead without significantly compromising\nsolution quality.", "published": "2025-04-23 14:27:31", "link": "http://arxiv.org/abs/2504.16755v1", "categories": ["cs.LG", "cs.ET"], "primary_category": "cs.LG"}
{"title": "Simple Graph Contrastive Learning via Fractional-order Neural Diffusion Networks", "abstract": "Graph Contrastive Learning (GCL) has recently made progress as an\nunsupervised graph representation learning paradigm. GCL approaches can be\ncategorized into augmentation-based and augmentation-free methods. The former\nrelies on complex data augmentations, while the latter depends on encoders that\ncan generate distinct views of the same input. Both approaches may require\nnegative samples for training. In this paper, we introduce a novel\naugmentation-free GCL framework based on graph neural diffusion models.\nSpecifically, we utilize learnable encoders governed by Fractional Differential\nEquations (FDE). Each FDE is characterized by an order parameter of the\ndifferential operator. We demonstrate that varying these parameters allows us\nto produce learnable encoders that generate diverse views, capturing either\nlocal or global information, for contrastive learning. Our model does not\nrequire negative samples for training and is applicable to both homophilic and\nheterophilic datasets. We demonstrate its effectiveness across various\ndatasets, achieving state-of-the-art performance.", "published": "2025-04-23 14:17:28", "link": "http://arxiv.org/abs/2504.16748v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Simplified Swarm Learning Framework for Robust and Scalable Diagnostic Services in Cancer Histopathology", "abstract": "The complexities of healthcare data, including privacy concerns, imbalanced\ndatasets, and interoperability issues, necessitate innovative machine learning\nsolutions. Swarm Learning (SL), a decentralized alternative to Federated\nLearning, offers privacy-preserving distributed training, but its reliance on\nblockchain technology hinders accessibility and scalability. This paper\nintroduces a \\textit{Simplified Peer-to-Peer Swarm Learning (P2P-SL) Framework}\ntailored for resource-constrained environments. By eliminating blockchain\ndependencies and adopting lightweight peer-to-peer communication, the proposed\nframework ensures robust model synchronization while maintaining data privacy.\nApplied to cancer histopathology, the framework integrates optimized\npre-trained models, such as TorchXRayVision, enhanced with DenseNet decoders,\nto improve diagnostic accuracy. Extensive experiments demonstrate the\nframework's efficacy in handling imbalanced and biased datasets, achieving\ncomparable performance to centralized models while preserving privacy. This\nstudy paves the way for democratizing advanced machine learning in healthcare,\noffering a scalable, accessible, and efficient solution for privacy-sensitive\ndiagnostic applications.", "published": "2025-04-23 14:04:15", "link": "http://arxiv.org/abs/2504.16732v1", "categories": ["cs.DC", "cs.LG"], "primary_category": "cs.DC"}
{"title": "PIN-WM: Learning Physics-INformed World Models for Non-Prehensile Manipulation", "abstract": "While non-prehensile manipulation (e.g., controlled pushing/poking)\nconstitutes a foundational robotic skill, its learning remains challenging due\nto the high sensitivity to complex physical interactions involving friction and\nrestitution. To achieve robust policy learning and generalization, we opt to\nlearn a world model of the 3D rigid body dynamics involved in non-prehensile\nmanipulations and use it for model-based reinforcement learning. We propose\nPIN-WM, a Physics-INformed World Model that enables efficient end-to-end\nidentification of a 3D rigid body dynamical system from visual observations.\nAdopting differentiable physics simulation, PIN-WM can be learned with only\nfew-shot and task-agnostic physical interaction trajectories. Further, PIN-WM\nis learned with observational loss induced by Gaussian Splatting without\nneeding state estimation. To bridge Sim2Real gaps, we turn the learned PIN-WM\ninto a group of Digital Cousins via physics-aware randomizations which perturb\nphysics and rendering parameters to generate diverse and meaningful variations\nof the PIN-WM. Extensive evaluations on both simulation and real-world tests\ndemonstrate that PIN-WM, enhanced with physics-aware digital cousins,\nfacilitates learning robust non-prehensile manipulation skills with Sim2Real\ntransfer, surpassing the Real2Sim2Real state-of-the-arts.", "published": "2025-04-23 13:27:07", "link": "http://arxiv.org/abs/2504.16693v1", "categories": ["cs.LG", "cs.RO"], "primary_category": "cs.LG"}
{"title": "A Statistical Evaluation of Indoor LoRaWAN Environment-Aware Propagation for 6G: MLR, ANOVA, and Residual Distribution Analysis", "abstract": "Modeling path loss in indoor LoRaWAN technology deployments is inherently\nchallenging due to structural obstructions, occupant density and activities,\nand fluctuating environmental conditions. This study proposes a two-stage\napproach to capture and analyze these complexities using an extensive dataset\nof 1,328,334 field measurements collected over six months in a single-floor\noffice at the University of Siegen's Hoelderlinstrasse Campus, Germany. First,\nwe implement a multiple linear regression model that includes traditional\npropagation metrics (distance, structural walls) and an extension with proposed\nenvironmental variables (relative humidity, temperature, carbon dioxide,\nparticulate matter, and barometric pressure). Using analysis of variance, we\ndemonstrate that adding these environmental factors can reduce unexplained\nvariance by 42.32 percent. Secondly, we examine residual distributions by\nfitting five candidate probability distributions: Normal, Skew-Normal, Cauchy,\nStudent's t, and Gaussian Mixture Models with one to five components. Our\nresults show that a four-component Gaussian Mixture Model captures the residual\nheterogeneity of indoor signal propagation most accurately, significantly\noutperforming single-distribution approaches. Given the push toward\nultra-reliable, context-aware communications in 6G networks, our analysis shows\nthat environment-aware modeling can substantially improve LoRaWAN network\ndesign in dynamic indoor IoT deployments.", "published": "2025-04-23 13:19:35", "link": "http://arxiv.org/abs/2504.16688v1", "categories": ["cs.NI", "cs.LG", "eess.SP"], "primary_category": "cs.NI"}
{"title": "MCMC for Bayesian estimation of Differential Privacy from Membership Inference Attacks", "abstract": "We propose a new framework for Bayesian estimation of differential privacy,\nincorporating evidence from multiple membership inference attacks (MIA).\nBayesian estimation is carried out via a Markov chain Monte Carlo (MCMC)\nalgorithm, named MCMC-DP-Est, which provides an estimate of the full posterior\ndistribution of the privacy parameter (e.g., instead of just credible\nintervals). Critically, the proposed method does not assume that privacy\nauditing is performed with the most powerful attack on the worst-case (dataset,\nchallenge point) pair, which is typically unrealistic. Instead, MCMC-DP-Est\njointly estimates the strengths of MIAs used and the privacy of the training\nalgorithm, yielding a more cautious privacy analysis. We also present an\neconomical way to generate measurements for the performance of an MIA that is\nto be used by the MCMC method to estimate privacy. We present the use of the\nmethods with numerical examples with both artificial and real data.", "published": "2025-04-23 13:10:37", "link": "http://arxiv.org/abs/2504.16683v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Provable wavelet-based neural approximation", "abstract": "In this paper, we develop a wavelet-based theoretical framework for analyzing\nthe universal approximation capabilities of neural networks over a wide range\nof activation functions. Leveraging wavelet frame theory on the spaces of\nhomogeneous type, we derive sufficient conditions on activation functions to\nensure that the associated neural network approximates any functions in the\ngiven space, along with an error estimate. These sufficient conditions\naccommodate a variety of smooth activation functions, including those that\nexhibit oscillatory behavior. Furthermore, by considering the $L^2$-distance\nbetween smooth and non-smooth activation functions, we establish a generalized\napproximation result that is applicable to non-smooth activations, with the\nerror explicitly controlled by this distance. This provides increased\nflexibility in the design of network architectures.", "published": "2025-04-23 13:02:37", "link": "http://arxiv.org/abs/2504.16682v1", "categories": ["cs.LG", "math.CA", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Efficient Data Valuation Approximation in Federated Learning: A Sampling-based Approach", "abstract": "Federated learning paradigm to utilize datasets across multiple data\nproviders. In FL, cross-silo data providers often hesitate to share their\nhigh-quality dataset unless their data value can be fairly assessed. Shapley\nvalue (SV) has been advocated as the standard metric for data valuation in FL\ndue to its desirable properties. However, the computational overhead of SV is\nprohibitive in practice, as it inherently requires training and evaluating an\nFL model across an exponential number of dataset combinations. Furthermore,\nexisting solutions fail to achieve high accuracy and efficiency, making\npractical use of SV still out of reach, because they ignore choosing suitable\ncomputation scheme for approximation framework and overlook the property of\nutility function in FL. We first propose a unified stratified-sampling\nframework for two widely-used schemes. Then, we analyze and choose the more\npromising scheme under the FL linear regression assumption. After that, we\nidentify a phenomenon termed key combinations, where only limited dataset\ncombinations have a high-impact on final data value. Building on these\ninsights, we propose a practical approximation algorithm, IPSS, which\nstrategically selects high-impact dataset combinations rather than evaluating\nall possible combinations, thus substantially reducing time cost with minor\napproximation error. Furthermore, we conduct extensive evaluations on the FL\nbenchmark datasets to demonstrate that our proposed algorithm outperforms a\nseries of representative baselines in terms of efficiency and effectiveness.", "published": "2025-04-23 12:36:20", "link": "http://arxiv.org/abs/2504.16668v1", "categories": ["cs.LG", "cs.DB"], "primary_category": "cs.LG"}
{"title": "Compositional Active Learning of Synchronous Systems through Automated Alphabet Refinement", "abstract": "Active automata learning infers automaton models of systems from behavioral\nobservations, a technique successfully applied to a wide range of domains.\nCompositional approaches for concurrent systems have recently emerged. We take\na significant step beyond available results, including those by the authors,\nand develop a general technique for compositional learning of a synchronizing\nparallel system with an unknown decomposition. Our approach automatically\nrefines the global alphabet into component alphabets while learning the\ncomponent models. We develop a theoretical treatment of distributions of\nalphabets, i.e., sets of possibly overlapping component alphabets. We\ncharacterize counter-examples that reveal inconsistencies with global\nobservations, and show how to systematically update the distribution to restore\nconsistency. We present a compositional learning algorithm implementing these\nideas, where learning counterexamples precisely correspond to distribution\ncounterexamples under well-defined conditions. We provide an implementation,\ncalled CoalA, using the state-of-the-art active learning library LearnLib. Our\nexperiments show that in more than 630 subject systems, CoalA delivers orders\nof magnitude improvements (up to five orders) in membership queries and in\nsystems with significant concurrency, it also achieves better scalability in\nthe number of equivalence queries.", "published": "2025-04-23 11:30:01", "link": "http://arxiv.org/abs/2504.16624v1", "categories": ["cs.LG", "cs.FL"], "primary_category": "cs.LG"}
{"title": "HERB: Human-augmented Efficient Reinforcement learning for Bin-packing", "abstract": "Packing objects efficiently is a fundamental problem in logistics, warehouse\nautomation, and robotics. While traditional packing solutions focus on\ngeometric optimization, packing irregular, 3D objects presents significant\nchallenges due to variations in shape and stability. Reinforcement\nLearning~(RL) has gained popularity in robotic packing tasks, but training\npurely from simulation can be inefficient and computationally expensive. In\nthis work, we propose HERB, a human-augmented RL framework for packing\nirregular objects. We first leverage human demonstrations to learn the best\nsequence of objects to pack, incorporating latent factors such as space\noptimization, stability, and object relationships that are difficult to model\nexplicitly. Next, we train a placement algorithm that uses visual information\nto determine the optimal object positioning inside a packing container. Our\napproach is validated through extensive performance evaluations, analyzing both\npacking efficiency and latency. Finally, we demonstrate the real-world\nfeasibility of our method on a robotic system. Experimental results show that\nour method outperforms geometric and purely RL-based approaches by leveraging\nhuman intuition, improving both packing robustness and adaptability. This work\nhighlights the potential of combining human expertise-driven RL to tackle\ncomplex real-world packing challenges in robotic systems.", "published": "2025-04-23 10:24:36", "link": "http://arxiv.org/abs/2504.16595v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Data-Assimilated Model-Based Reinforcement Learning for Partially Observed Chaotic Flows", "abstract": "The goal of many applications in energy and transport sectors is to control\nturbulent flows. However, because of chaotic dynamics and high dimensionality,\nthe control of turbulent flows is exceedingly difficult. Model-free\nreinforcement learning (RL) methods can discover optimal control policies by\ninteracting with the environment, but they require full state information,\nwhich is often unavailable in experimental settings. We propose a\ndata-assimilated model-based RL (DA-MBRL) framework for systems with partial\nobservability and noisy measurements. Our framework employs a control-aware\nEcho State Network for data-driven prediction of the dynamics, and integrates\ndata assimilation with an Ensemble Kalman Filter for real-time state\nestimation. An off-policy actor-critic algorithm is employed to learn optimal\ncontrol strategies from state estimates. The framework is tested on the\nKuramoto-Sivashinsky equation, demonstrating its effectiveness in stabilizing a\nspatiotemporally chaotic flow from noisy and partial measurements.", "published": "2025-04-23 10:12:53", "link": "http://arxiv.org/abs/2504.16588v1", "categories": ["eess.SY", "cs.LG", "cs.SY", "physics.flu-dyn"], "primary_category": "eess.SY"}
{"title": "Enhancing Variable Selection in Large-scale Logistic Regression: Leveraging Manual Labeling with Beneficial Noise", "abstract": "In large-scale supervised learning, penalized logistic regression (PLR)\neffectively addresses the overfitting problem by introducing regularization\nterms yet its performance still depends on efficient variable selection\nstrategies. This paper theoretically demonstrates that label noise stemming\nfrom manual labeling, which is solely related to classification difficulty,\nrepresents a type of beneficial noise for variable selection in PLR. This\nbenefit is reflected in a more accurate estimation of the selected non-zero\ncoefficients when compared with the case where only truth labels are used.\nUnder large-scale settings, the sample size for PLR can become very large,\nmaking it infeasible to store on a single machine. In such cases, distributed\ncomputing methods are required to handle PLR model with manual labeling. This\npaper presents a partition-insensitive parallel algorithm founded on the ADMM\n(alternating direction method of multipliers) algorithm to address PLR by\nincorporating manual labeling. The partition insensitivity of the proposed\nalgorithm refers to the fact that the solutions obtained by the algorithm will\nnot change with the distributed storage of data. In addition, the algorithm has\nglobal convergence and a sublinear convergence rate. Experimental results\nindicate that, as compared with traditional variable selection classification\ntechniques, the PLR with manually-labeled noisy data achieves higher estimation\nand classification accuracy across multiple large-scale datasets.", "published": "2025-04-23 10:05:54", "link": "http://arxiv.org/abs/2504.16585v1", "categories": ["cs.LG", "stat.CO", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Hyper-Transforming Latent Diffusion Models", "abstract": "We introduce a novel generative framework for functions by integrating\nImplicit Neural Representations (INRs) and Transformer-based hypernetworks into\nlatent variable models. Unlike prior approaches that rely on MLP-based\nhypernetworks with scalability limitations, our method employs a\nTransformer-based decoder to generate INR parameters from latent variables,\naddressing both representation capacity and computational efficiency. Our\nframework extends latent diffusion models (LDMs) to INR generation by replacing\nstandard decoders with a Transformer-based hypernetwork, which can be trained\neither from scratch or via hyper-transforming-a strategy that fine-tunes only\nthe decoder while freezing the pre-trained latent space. This enables efficient\nadaptation of existing generative models to INR-based representations without\nrequiring full retraining.", "published": "2025-04-23 10:01:18", "link": "http://arxiv.org/abs/2504.16580v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Unified Molecule Generation and Property Prediction", "abstract": "Modeling the joint distribution of the data samples and their properties\nallows to construct a single model for both data generation and property\nprediction, with synergistic capabilities reaching beyond purely generative or\npredictive models. However, training joint models presents daunting\narchitectural and optimization challenges. Here, we propose Hyformer, a\ntransformer-based joint model that successfully blends the generative and\npredictive functionalities, using an alternating attention mask together with a\nunified pre-training scheme. We show that Hyformer rivals other joint models,\nas well as state-of-the-art molecule generation and property prediction models.\nAdditionally, we show the benefits of joint modeling in downstream tasks of\nmolecular representation learning, hit identification and antimicrobial peptide\ndesign.", "published": "2025-04-23 09:36:46", "link": "http://arxiv.org/abs/2504.16559v1", "categories": ["cs.LG", "q-bio.QM", "68T01", "I.2.1"], "primary_category": "cs.LG"}
{"title": "Confidence Sequences for Generalized Linear Models via Regret Analysis", "abstract": "We develop a methodology for constructing confidence sets for parameters of\nstatistical models via a reduction to sequential prediction. Our key\nobservation is that for any generalized linear model (GLM), one can construct\nan associated game of sequential probability assignment such that achieving low\nregret in the game implies a high-probability upper bound on the excess\nlikelihood of the true parameter of the GLM. This allows us to develop a scheme\nthat we call online-to-confidence-set conversions, which effectively reduces\nthe problem of proving the desired statistical claim to an algorithmic\nquestion. We study two varieties of this conversion scheme: 1) analytical\nconversions that only require proving the existence of algorithms with low\nregret and provide confidence sets centered at the maximum-likelihood estimator\n2) algorithmic conversions that actively leverage the output of the online\nalgorithm to construct confidence sets (and may be centered at other,\nadaptively constructed point estimators). The resulting methodology recovers\nall state-of-the-art confidence set constructions within a single framework,\nand also provides several new types of confidence sets that were previously\nunknown in the literature.", "published": "2025-04-23 09:32:40", "link": "http://arxiv.org/abs/2504.16555v1", "categories": ["math.ST", "cs.LG", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "Least-Squares-Embedded Optimization for Accelerated Convergence of PINNs in Acoustic Wavefield Simulations", "abstract": "Physics-Informed Neural Networks (PINNs) have shown promise in solving\npartial differential equations (PDEs), including the frequency-domain Helmholtz\nequation. However, standard training of PINNs using gradient descent (GD)\nsuffers from slow convergence and instability, particularly for high-frequency\nwavefields. For scattered acoustic wavefield simulation based on Helmholtz\nequation, we derive a hybrid optimization framework that accelerates training\nconvergence by embedding a least-squares (LS) solver directly into the GD loss\nfunction. This formulation enables optimal updates for the linear output layer.\nOur method is applicable with or without perfectly matched layers (PML), and we\nprovide practical tensor-based implementations for both scenarios. Numerical\nexperiments on benchmark velocity models demonstrate that our approach achieves\nfaster convergence, higher accuracy, and improved stability compared to\nconventional PINN training. In particular, our results show that the\nLS-enhanced method converges rapidly even in cases where standard GD-based\ntraining fails. The LS solver operates on a small normal matrix, ensuring\nminimal computational overhead and making the method scalable for large-scale\nwavefield simulations.", "published": "2025-04-23 09:32:14", "link": "http://arxiv.org/abs/2504.16553v1", "categories": ["cs.LG", "physics.comp-ph", "physics.geo-ph"], "primary_category": "cs.LG"}
{"title": "A Comprehensive Survey of Synthetic Tabular Data Generation", "abstract": "Tabular data remains one of the most prevalent and critical data formats\nacross diverse real-world applications. However, its effective use in machine\nlearning (ML) is often constrained by challenges such as data scarcity, privacy\nconcerns, and class imbalance. Synthetic data generation has emerged as a\npromising solution, leveraging generative models to learn the distribution of\nreal datasets and produce high-fidelity, privacy-preserving samples. Various\ngenerative paradigms have been explored, including energy-based models (EBMs),\nvariational autoencoders (VAEs), generative adversarial networks (GANs), large\nlanguage models (LLMs), and diffusion models. While several surveys have\ninvestigated synthetic tabular data generation, most focus on narrow subdomains\nor specific generative methods, such as GANs, diffusion models, or\nprivacy-preserving techniques. This limited scope often results in fragmented\ninsights, lacking a comprehensive synthesis that bridges diverse approaches. In\nparticular, recent advances driven by LLMs and diffusion-based models remain\nunderexplored. This gap hinders a holistic understanding of the field`s\nevolution, methodological interplay, and open challenges. To address this, our\nsurvey provides a unified and systematic review of synthetic tabular data\ngeneration. Our contributions are threefold: (1) we propose a comprehensive\ntaxonomy that organizes existing methods into traditional approaches,\ndiffusion-based methods, and LLM-based models, and provide an in-depth\ncomparative analysis; (2) we detail the complete pipeline for synthetic tabular\ndata generation, including data synthesis, post-processing, and evaluation; (3)\nwe identify major challenges, explore real-world applications, and outline open\nresearch questions and future directions to guide future work in this rapidly\nevolving area.", "published": "2025-04-23 08:33:34", "link": "http://arxiv.org/abs/2504.16506v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Neuro-Evolutionary Approach to Physics-Aware Symbolic Regression", "abstract": "Symbolic regression is a technique that can automatically derive analytic\nmodels from data. Traditionally, symbolic regression has been implemented\nprimarily through genetic programming that evolves populations of candidate\nsolutions sampled by genetic operators, crossover and mutation. More recently,\nneural networks have been employed to learn the entire analytical model, i.e.,\nits structure and coefficients, using regularized gradient-based optimization.\nAlthough this approach tunes the model's coefficients better, it is prone to\npremature convergence to suboptimal model structures. Here, we propose a\nneuro-evolutionary symbolic regression method that combines the strengths of\nevolutionary-based search for optimal neural network (NN) topologies with\ngradient-based tuning of the network's parameters. Due to the inherent high\ncomputational demand of evolutionary algorithms, it is not feasible to learn\nthe parameters of every candidate NN topology to full convergence. Thus, our\nmethod employs a memory-based strategy and population perturbations to enhance\nexploitation and reduce the risk of being trapped in suboptimal NNs. In this\nway, each NN topology can be trained using only a short sequence of\nbackpropagation iterations. The proposed method was experimentally evaluated on\nthree real-world test problems and has been shown to outperform other NN-based\napproaches regarding the quality of the models obtained.", "published": "2025-04-23 08:29:53", "link": "http://arxiv.org/abs/2504.16503v1", "categories": ["cs.NE", "cs.LG"], "primary_category": "cs.NE"}
{"title": "Dynamic Time-aware Continual User Representation Learning", "abstract": "Traditional user modeling (UM) approaches have primarily focused on designing\nmodels for a single specific task, but they face limitations in generalization\nand adaptability across various tasks. Recognizing these challenges, recent\nstudies have shifted towards continual learning (CL)-based universal user\nrepresentation learning aiming to develop a single model capable of handling\nmultiple tasks. Despite advancements, existing methods are in fact evaluated\nunder an unrealistic scenario that does not consider the passage of time as\ntasks progress, which overlooks newly emerged items that may change the item\ndistribution of previous tasks. In this paper, we introduce a practical\nevaluation scenario on which CL-based universal user representation learning\napproaches should be evaluated, which takes into account the passage of time as\ntasks progress. Then, we propose a novel framework Dynamic Time-aware continual\nuser representation learner, named DITTO, designed to alleviate catastrophic\nforgetting despite continuous shifts in item distribution, while also allowing\nthe knowledge acquired from previous tasks to adapt to the current shifted item\ndistribution. Through our extensive experiments, we demonstrate the superiority\nof DITTO over state-of-the-art methods under a practical evaluation scenario.\nOur source code is available at\nhttps://github.com/seungyoon-Choi/DITTO_official.", "published": "2025-04-23 08:23:59", "link": "http://arxiv.org/abs/2504.16501v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Breaking scaling relations with inverse catalysts: a machine learning exploration of trends in $\\mathrm{CO_2}$ hydrogenation energy barriers", "abstract": "The conversion of $\\mathrm{CO_2}$ into useful products such as methanol is a\nkey strategy for abating climate change and our dependence on fossil fuels.\nDeveloping new catalysts for this process is costly and time-consuming and can\nthus benefit from computational exploration of possible active sites. However,\nthis is complicated by the complexity of the materials and reaction networks.\nHere, we present a workflow for exploring transition states of elementary\nreaction steps at inverse catalysts, which is based on the training of a neural\nnetwork-based machine learning interatomic potential. We focus on the crucial\nformate intermediate and its formation over nanoclusters of indium oxide\nsupported on Cu(111). The speedup compared to an approach purely based on\ndensity functional theory allows us to probe a wide variety of active sites\nfound at nanoclusters of different sizes and stoichiometries. Analysis of the\nobtained set of transition state geometries reveals different\nstructure--activity trends at the edge or interior of the nanoclusters.\nFurthermore, the identified geometries allow for the breaking of linear scaling\nrelations, which could be a key underlying reason for the excellent catalytic\nperformance of inverse catalysts observed in experiments.", "published": "2025-04-23 08:12:47", "link": "http://arxiv.org/abs/2504.16493v1", "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.chem-ph"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "Seeking Flat Minima over Diverse Surrogates for Improved Adversarial Transferability: A Theoretical Framework and Algorithmic Instantiation", "abstract": "The transfer-based black-box adversarial attack setting poses the challenge\nof crafting an adversarial example (AE) on known surrogate models that remain\neffective against unseen target models. Due to the practical importance of this\ntask, numerous methods have been proposed to address this challenge. However,\nmost previous methods are heuristically designed and intuitively justified,\nlacking a theoretical foundation. To bridge this gap, we derive a novel\ntransferability bound that offers provable guarantees for adversarial\ntransferability. Our theoretical analysis has the advantages of \\textit{(i)}\ndeepening our understanding of previous methods by building a general attack\nframework and \\textit{(ii)} providing guidance for designing an effective\nattack algorithm. Our theoretical results demonstrate that optimizing AEs\ntoward flat minima over the surrogate model set, while controlling the\nsurrogate-target model shift measured by the adversarial model discrepancy,\nyields a comprehensive guarantee for AE transferability. The results further\nlead to a general transfer-based attack framework, within which we observe that\nprevious methods consider only partial factors contributing to the\ntransferability. Algorithmically, inspired by our theoretical results, we first\nelaborately construct the surrogate model set in which models exhibit diverse\nadversarial vulnerabilities with respect to AEs to narrow an instantiated\nadversarial model discrepancy. Then, a \\textit{model-Diversity-compatible\nReverse Adversarial Perturbation} (DRAP) is generated to effectively promote\nthe flatness of AEs over diverse surrogate models to improve transferability.\nExtensive experiments on NIPS2017 and CIFAR-10 datasets against various target\nmodels demonstrate the effectiveness of our proposed attack.", "published": "2025-04-23 07:33:45", "link": "http://arxiv.org/abs/2504.16474v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "An Effective Gram Matrix Characterizes Generalization in Deep Networks", "abstract": "We derive a differential equation that governs the evolution of the\ngeneralization gap when a deep network is trained by gradient descent. This\ndifferential equation is controlled by two quantities, a contraction factor\nthat brings together trajectories corresponding to slightly different datasets,\nand a perturbation factor that accounts for them training on different\ndatasets. We analyze this differential equation to compute an ``effective Gram\nmatrix'' that characterizes the generalization gap after training in terms of\nthe alignment between this Gram matrix and a certain initial ``residual''.\nEmpirical evaluations on image classification datasets indicate that this\nanalysis can predict the test loss accurately. Further, at any point during\ntraining, the residual predominantly lies in the subspace of the effective Gram\nmatrix with the smallest eigenvalues. This indicates that the training process\nis benign, i.e., it does not lead to significant deterioration of the\ngeneralization gap (which is zero at initialization). The alignment between the\neffective Gram matrix and the residual is different for different datasets and\narchitectures. The match/mismatch of the data and the architecture is primarily\nresponsible for good/bad generalization.", "published": "2025-04-23 06:24:42", "link": "http://arxiv.org/abs/2504.16450v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "From Past to Present: A Survey of Malicious URL Detection Techniques, Datasets and Code Repositories", "abstract": "Malicious URLs persistently threaten the cybersecurity ecosystem, by either\ndeceiving users into divulging private data or distributing harmful payloads to\ninfiltrate host systems. Gaining timely insights into the current state of this\nongoing battle holds significant importance. However, existing reviews exhibit\n4 critical gaps: 1) Their reliance on algorithm-centric taxonomies obscures\nunderstanding of how detection approaches exploit specific modal information\nchannels; 2) They fail to incorporate pivotal LLM/Transformer-based defenses;\n3) No open-source implementations are collected to facilitate benchmarking; 4)\nInsufficient dataset coverage.This paper presents a comprehensive review of\nmalicious URL detection technologies, systematically analyzing methods from\ntraditional blacklisting to advanced deep learning approaches (e.g.\nTransformer, GNNs, and LLMs). Unlike prior surveys, we propose a novel\nmodality-based taxonomy that categorizes existing works according to their\nprimary data modalities (URL, HTML, Visual, etc.). This hierarchical\nclassification enables both rigorous technical analysis and clear understanding\nof multimodal information utilization. Furthermore, to establish a profile of\naccessible datasets and address the lack of standardized benchmarking (where\ncurrent studies often lack proper baseline comparisons), we curate and analyze:\n1) publicly available datasets (2016-2024), and 2) open-source implementations\nfrom published works(2013-2025). Then, we outline essential design principles\nand architectural frameworks for product-level implementations. The review\nconcludes by examining emerging challenges and proposing actionable directions\nfor future research. We maintain a GitHub repository for ongoing curating\ndatasets and open-source implementations:\nhttps://github.com/sevenolu7/Malicious-URL-Detection-Open-Source/tree/master.", "published": "2025-04-23 06:23:18", "link": "http://arxiv.org/abs/2504.16449v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Node Assigned physics-informed neural networks for thermal-hydraulic system simulation: CVH/FL module", "abstract": "Severe accidents (SAs) in nuclear power plants have been analyzed using\nthermal-hydraulic (TH) system codes such as MELCOR and MAAP. These codes\nefficiently simulate the progression of SAs, while they still have inherent\nlimitations due to their inconsistent finite difference schemes. The use of\nempirical schemes incorporating both implicit and explicit formulations\ninherently induces unidirectional coupling in multi-physics analyses. The\nobjective of this study is to develop a novel numerical method for TH system\ncodes using physics-informed neural network (PINN). They have shown strength in\nsolving multi-physics due to the innate feature of neural networks-automatic\ndifferentiation. We propose a node-assigned PINN (NA-PINN) that is suitable for\nthe control volume approach-based system codes. NA-PINN addresses the issue of\nspatial governing equation variation by assigning an individual network to each\nnodalization of the system code, such that spatial information is excluded from\nboth the input and output domains, and each subnetwork learns to approximate a\npurely temporal solution. In this phase, we evaluated the accuracy of the PINN\nmethods for the hydrodynamic module. In the 6 water tank simulation, PINN and\nNA-PINN showed maximum absolute errors of 1.678 and 0.007, respectively. It\nshould be noted that only NA-PINN demonstrated acceptable accuracy. To the best\nof the authors' knowledge, this is the first study to successfully implement a\nsystem code using PINN. Our future work involves extending NA-PINN to a\nmulti-physics solver and developing it in a surrogate manner.", "published": "2025-04-23 06:17:04", "link": "http://arxiv.org/abs/2504.16447v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Target Concrete Score Matching: A Holistic Framework for Discrete Diffusion", "abstract": "Discrete diffusion is a promising framework for modeling and generating\ndiscrete data. In this work, we present Target Concrete Score Matching (TCSM),\na novel and versatile objective for training and fine-tuning discrete diffusion\nmodels. TCSM provides a general framework with broad applicability. It supports\npre-training discrete diffusion models directly from data samples, and many\nexisting discrete diffusion approaches naturally emerge as special cases of our\nmore general TCSM framework. Furthermore, the same TCSM objective extends to\npost-training of discrete diffusion models, including fine-tuning using reward\nfunctions or preference data, and distillation of knowledge from pre-trained\nautoregressive models. These new capabilities stem from the core idea of TCSM,\nestimating the concrete score of the target distribution, which resides in the\noriginal (clean) data space. This allows seamless integration with reward\nfunctions and pre-trained models, which inherently only operate in the clean\ndata space rather than the noisy intermediate spaces of diffusion processes.\nOur experiments on language modeling tasks demonstrate that TCSM matches or\nsurpasses current methods. Additionally, TCSM is versatile, applicable to both\npre-training and post-training scenarios, offering greater flexibility and\nsample efficiency.", "published": "2025-04-23 05:32:58", "link": "http://arxiv.org/abs/2504.16431v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Natural Policy Gradient for Average Reward Non-Stationary RL", "abstract": "We consider the problem of non-stationary reinforcement learning (RL) in the\ninfinite-horizon average-reward setting. We model it by a Markov Decision\nProcess with time-varying rewards and transition probabilities, with a\nvariation budget of $\\Delta_T$. Existing non-stationary RL algorithms focus on\nmodel-based and model-free value-based methods. Policy-based methods despite\ntheir flexibility in practice are not theoretically well understood in\nnon-stationary RL. We propose and analyze the first model-free policy-based\nalgorithm, Non-Stationary Natural Actor-Critic (NS-NAC), a policy gradient\nmethod with a restart based exploration for change and a novel interpretation\nof learning rates as adapting factors. Further, we present a bandit-over-RL\nbased parameter-free algorithm BORL-NS-NAC that does not require prior\nknowledge of the variation budget $\\Delta_T$. We present a dynamic regret of\n$\\tilde{\\mathscr O}(|S|^{1/2}|A|^{1/2}\\Delta_T^{1/6}T^{5/6})$ for both\nalgorithms, where $T$ is the time horizon, and $|S|$, $|A|$ are the sizes of\nthe state and action spaces. The regret analysis leverages a novel adaptation\nof the Lyapunov function analysis of NAC to dynamic environments and\ncharacterizes the effects of simultaneous updates in policy, value function\nestimate and changes in the environment.", "published": "2025-04-23 04:37:26", "link": "http://arxiv.org/abs/2504.16415v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Circinus: Efficient Query Planner for Compound ML Serving", "abstract": "The rise of compound AI serving -- integrating multiple operators in a\npipeline that may span edge and cloud tiers -- enables end-user applications\nsuch as autonomous driving, generative AI-powered meeting companions, and\nimmersive gaming. Achieving high service goodput -- i.e., meeting service level\nobjectives (SLOs) for pipeline latency, accuracy, and costs -- requires\neffective planning of operator placement, configuration, and resource\nallocation across infrastructure tiers. However, the diverse SLO requirements,\nvarying edge capabilities, and high query volumes create an enormous planning\nsearch space, rendering current solutions fundamentally limited for real-time\nserving and cost-efficient deployments.\n  This paper presents Circinus, an SLO-aware query planner for large-scale\ncompound AI workloads. Circinus novelly decomposes multi-query planning and\nmulti-dimensional SLO objectives while preserving global decision quality. By\nexploiting plan similarities within and across queries, it significantly\nreduces search steps. It further improves per-step efficiency with a\nprecision-aware plan profiler that incrementally profiles and strategically\napplies early stopping based on imprecise estimates of plan performance. At\nscale, Circinus selects query-plan combinations to maximize global SLO goodput.\nEvaluations in real-world settings show that Circinus improves service goodput\nby 3.2-5.0$\\times$, accelerates query planning by 4.2-5.8$\\times$, achieving\nquery response in seconds, while reducing deployment costs by 3.2-4.0$\\times$\nover state of the arts even in their intended single-tier deployments.", "published": "2025-04-23 03:57:24", "link": "http://arxiv.org/abs/2504.16397v1", "categories": ["cs.DB", "cs.LG"], "primary_category": "cs.DB"}
{"title": "The Safety-Privacy Tradeoff in Linear Bandits", "abstract": "We consider a collection of linear stochastic bandit problems, each modeling\nthe random response of different agents to proposed interventions, coupled\ntogether by a global safety constraint. We assume a central coordinator must\nchoose actions to play on each bandit with the objective of regret\nminimization, while also ensuring that the expected response of all agents\nsatisfies the global safety constraints at each round, in spite of uncertainty\nabout the bandits' parameters. The agents consider their observed responses to\nbe private and in order to protect their sensitive information, the data\nsharing with the central coordinator is performed under local differential\nprivacy (LDP). However, providing higher level of privacy to different agents\nwould have consequences in terms of safety and regret. We formalize these\ntradeoffs by building on the notion of the sharpness of the safety set - a\nmeasure of how the geometric properties of the safe set affects the growth of\nregret - and propose a unilaterally unimprovable vector of privacy levels for\ndifferent agents given a maximum regret budget.", "published": "2025-04-23 02:48:02", "link": "http://arxiv.org/abs/2504.16371v1", "categories": ["math.OC", "cs.LG"], "primary_category": "math.OC"}
{"title": "Disentangled Graph Representation Based on Substructure-Aware Graph Optimal Matching Kernel Convolutional Networks", "abstract": "Graphs effectively characterize relational data, driving graph representation\nlearning methods that uncover underlying predictive information. As\nstate-of-the-art approaches, Graph Neural Networks (GNNs) enable end-to-end\nlearning for diverse tasks. Recent disentangled graph representation learning\nenhances interpretability by decoupling independent factors in graph data.\nHowever, existing methods often implicitly and coarsely characterize graph\nstructures, limiting structural pattern analysis within the graph. This paper\nproposes the Graph Optimal Matching Kernel Convolutional Network (GOMKCN) to\naddress this limitation. We view graphs as node-centric subgraphs, where each\nsubgraph acts as a structural factor encoding position-specific information.\nThis transforms graph prediction into structural pattern recognition. Inspired\nby CNNs, GOMKCN introduces the Graph Optimal Matching Kernel (GOMK) as a\nconvolutional operator, computing similarities between subgraphs and learnable\ngraph filters. Mathematically, GOMK maps subgraphs and filters into a Hilbert\nspace, representing graphs as point sets. Disentangled representations emerge\nfrom projecting subgraphs onto task-optimized filters, which adaptively capture\nrelevant structural patterns via gradient descent. Crucially, GOMK incorporates\nlocal correspondences in similarity measurement, resolving the trade-off\nbetween differentiability and accuracy in graph kernels. Experiments validate\nthat GOMKCN achieves superior accuracy and interpretability in graph pattern\nmining and prediction. The framework advances the theoretical foundation for\ndisentangled graph representation learning.", "published": "2025-04-23 02:26:33", "link": "http://arxiv.org/abs/2504.16360v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Covariate-dependent Graphical Model Estimation via Neural Networks with Statistical Guarantees", "abstract": "Graphical models are widely used in diverse application domains to model the\nconditional dependencies amongst a collection of random variables. In this\npaper, we consider settings where the graph structure is covariate-dependent,\nand investigate a deep neural network-based approach to estimate it. The method\nallows for flexible functional dependency on the covariate, and fits the data\nreasonably well in the absence of a Gaussianity assumption. Theoretical results\nwith PAC guarantees are established for the method, under assumptions commonly\nused in an Empirical Risk Minimization framework. The performance of the\nproposed method is evaluated on several synthetic data settings and benchmarked\nagainst existing approaches. The method is further illustrated on real datasets\ninvolving data from neuroscience and finance, respectively, and produces\ninterpretable results.", "published": "2025-04-23 02:13:36", "link": "http://arxiv.org/abs/2504.16356v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Deep Neural Network Emulation of the Quantum-Classical Transition via Learned Wigner Function Dynamics", "abstract": "The emergence of classical behavior from quantum mechanics as Planck's\nconstant $\\hbar$ approaches zero remains a fundamental challenge in physics\n[1-3]. This paper introduces a novel approach employing deep neural networks to\ndirectly learn the dynamical mapping from initial quantum state parameters (for\nGaussian wave packets of the one-dimensional harmonic oscillator) and $\\hbar$\nto the parameters of the time-evolved Wigner function in phase space [4-6]. A\ncomprehensive dataset of analytically derived time-evolved Wigner functions was\ngenerated, and a deep feedforward neural network with an enhanced architecture\nwas successfully trained for this prediction task, achieving a final training\nloss of ~ 0.0390. The network demonstrates a significant and previously\nunrealized ability to accurately capture the underlying mapping of the Wigner\nfunction dynamics. This allows for a direct emulation of the quantum-classical\ntransition by predicting the evolution of phase-space distributions as $\\hbar$\nis systematically varied. The implications of these findings for providing a\nnew computational lens on the emergence of classicality are discussed,\nhighlighting the potential of this direct phase-space learning approach for\nstudying fundamental aspects of quantum mechanics. This work presents a\nsignificant advancement beyond previous efforts that focused on learning\nobservable mappings [7], offering a direct route via the phase-space\nrepresentation.", "published": "2025-04-23 00:58:11", "link": "http://arxiv.org/abs/2504.16334v1", "categories": ["quant-ph", "cs.LG"], "primary_category": "quant-ph"}
{"title": "ClarifyCoder: Clarification-Aware Fine-Tuning for Programmatic Problem Solving", "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in\ncode generation tasks. However, a significant gap remains between their current\nperformance and that of expert software engineers. A key differentiator is that\nhuman engineers actively seek clarification when faced with ambiguous\nrequirements, while LLMs typically generate code regardless of uncertainties in\nthe problem description. We present ClarifyCoder, a novel framework with\nsynthetic data generation and instruction-tuning that enables LLMs to identify\nambiguities and request clarification before proceeding with code generation.\nWhile recent work has focused on LLM-based agents for iterative code\ngeneration, we argue that the fundamental ability to recognize and query\nambiguous requirements should be intrinsic to the models themselves. Our\napproach consists of two main components: (1) a data synthesis technique that\naugments existing programming datasets with scenarios requiring clarification\nto generate clarification-aware training data, and (2) a fine-tuning strategy\nthat teaches models to prioritize seeking clarification over immediate code\ngeneration when faced with incomplete or ambiguous requirements. We further\nprovide an empirical analysis of integrating ClarifyCoder with standard\nfine-tuning for a joint optimization of both clarify-awareness and coding\nability. Experimental results demonstrate that ClarifyCoder significantly\nimproves the communication capabilities of Code LLMs through meaningful\nclarification dialogues while maintaining code generation capabilities.", "published": "2025-04-23 00:34:39", "link": "http://arxiv.org/abs/2504.16331v1", "categories": ["cs.SE", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Linear convergence of a one-cut conditional gradient method for total variation regularization", "abstract": "We introduce a fully-corrective generalized conditional gradient method for\nconvex minimization problems involving total variation regularization on\nmultidimensional domains. It relies on alternating between updating an active\nset of subsets of the spatial domain as well as of an iterate given by a conic\ncombination of the associated characteristic functions. Different to previous\napproaches in the same spirit, the computation of a new candidate set only\nrequires the solution of one prescribed mean curvature problem instead of the\nresolution of a fractional minimization task analogous to finding a generalized\nCheeger set. After discretization, the former can be realized by a single run\nof a graph cut algorithm leading to significant speedup in practice. We prove\nthe global sublinear convergence of the resulting method, under mild\nassumptions, and its asymptotic linear convergence in a more restrictive\ntwo-dimensional setting which uses results of stability of surfaces of\nprescribed curvature under perturbations of the curvature. Finally, we\nnumerically demonstrate this convergence behavior in some model PDE-constrained\nminimization problems.", "published": "2025-04-23 17:27:06", "link": "http://arxiv.org/abs/2504.16899v1", "categories": ["math.OC", "cs.NA", "math.NA", "49M41, 65J20, 52A40, 49J45, 49Q20"], "primary_category": "math.OC"}
{"title": "Neural Network Element Method for Partial Differential Equations", "abstract": "In this paper, based on the combination of finite element mesh and neural\nnetwork, a novel type of neural network element space and corresponding machine\nlearning method are designed for solving partial differential equations. The\napplication of finite element mesh makes the neural network element space\nsatisfy the boundary value conditions directly on the complex geometric\ndomains. The use of neural networks allows the accuracy of the approximate\nsolution to reach the high level of neural network approximation even for the\nproblems with singularities. We also provide the error analysis of the proposed\nmethod for the understanding. The proposed numerical method in this paper\nprovides the way to enable neural network-based machine learning algorithms to\nsolve a broader range of problems arising from engineering applications.", "published": "2025-04-23 16:32:30", "link": "http://arxiv.org/abs/2504.16862v1", "categories": ["math.NA", "cs.NA", "68T07, 65L70, 65N25, 65B99"], "primary_category": "math.NA"}
{"title": "Energy Variational Modeling and Numerical Simulation of Open Membranes in Stokes Flow", "abstract": "Lipid bilayer membranes are fundamental biological structures that serve as\ncellular boundaries, mediating transport, signaling, and maintaining structural\nintegrity. This study introduces a novel mathematical model for open membranes\nimmersed in Stokes flows, accounting for membrane elasticity, line tension at\nthe open edge, and fluid-membrane interactions. The model is derived from an\nenergy functional that incorporates Helfrich bending energy and a line energy\nassociated with the open edge. By balancing dissipation in both the bulk fluid\nand the membrane surface, following the maximal dissipation principle, we\nderive the governing equations within an energy variational framework. Assuming\naxisymmetry and employing a boundary integral reduction, we transform the 3D\nproblem into an effectively 1D problem, for which we develop a finite\nelement-based numerical method to solve the resulting moving boundary problem.\nSeveral numerical examples are provided to validate the model and compare the\nresults with existing studies.", "published": "2025-04-23 15:39:54", "link": "http://arxiv.org/abs/2504.16823v1", "categories": ["math.NA", "cs.NA", "physics.comp-ph"], "primary_category": "math.NA"}
{"title": "The extended adjoint state and nonlinearity in correlation-based passive imaging", "abstract": "This articles investigates physics-based passive imaging problem, wherein one\ninfers an unknown medium using ambient noise and correlation of the noise\nsignal. We develop a general backpropagation framework via the so-called\nextended adjoint state, suitable for any linear PDE; crucially, this approach\nreduces by half the number of required PDE solves. Applications to several\ndifferent PDE models demonstrate the universality of our method. In addition,\nwe analyze the nonlinearity of the correlated model, revealing a surprising\ntangential cone condition-like structure, thereby advancing the state of the\nart towards a convergence guarantee for regularized reconstruction in passive\nimaging.", "published": "2025-04-23 15:18:34", "link": "http://arxiv.org/abs/2504.16797v1", "categories": ["math.NA", "cs.NA", "65M32, 65J22, 35R30"], "primary_category": "math.NA"}
{"title": "The root-exponential convergence of lightning plus polynomial approximation on corner domains (II)", "abstract": "This paper builds rigorous analysis on the root-exponential convergence for\nthe lightning schemes via rational functions in approximating corner\nsingularity problems with uniform exponentially clustered poles proposed by\nGopal and Trefethen. The start point is to set up the representations of\n$z^\\alpha$ and $z^\\alpha\\log z$ in the slit disk and develop results akin to\nPaley-Wiener theorem, from which, together with the Poisson summation formula,\nthe root-exponential convergence of the lightning plus polynomial scheme with\nan exact order for each clustered parameter is established in approximation of\nprototype functions $g(z)z^\\alpha$ or $g(z)z^\\alpha\\log z$ on a sector-shaped\ndomain, which includes $[0,1]$ as a special case. In addition, the fastest\nconvergence rate is confirmed based upon the best choice of the clustered\nparameter. Furthermore, the optimal choice of the clustered parameter and the\nconvergence rate for corner singularity problems in solving Laplace equations\nare attested based on Lehman and Wasow's study of corner singularities and\nalong with the decomposition of Gopal and Trefethen. The thorough analysis\nprovides a solid foundation for lightning schemes and rational approximation.\nAmple numerical evidences demonstrate the optimality and sharpness of the\nestimates.", "published": "2025-04-23 14:28:18", "link": "http://arxiv.org/abs/2504.16756v1", "categories": ["math.NA", "cs.NA", "41A20, 65E05, 65D15, 30C10"], "primary_category": "math.NA"}
{"title": "Mixing Data-Driven and Physics-Based Constitutive Models using Uncertainty-Driven Phase Fields", "abstract": "There is a high interest in accelerating multiscale models using data-driven\nsurrogate modeling techniques. Creating a large training dataset encompassing\nall relevant load scenarios is essential for a good surrogate, yet the\ncomputational cost of producing this data quickly becomes a limiting factor.\nCommonly, a pre-trained surrogate is used throughout the computational domain.\nHere, we introduce an alternative adaptive mixture approach that uses a fast\nprobabilistic surrogate model as constitutive model when possible, but resorts\nback to the true high-fidelity model when necessary. The surrogate is thus not\nrequired to be accurate for every possible load condition, enabling a\nsignificant reduction in the data collection time. We achieve this by creating\nphases in the computational domain corresponding to the different models. These\nphases evolve using a phase-field model driven by the surrogate uncertainty.\nWhen the surrogate uncertainty becomes large, the phase-field model causes a\nlocal transition from the surrogate to the high-fidelity model, maintaining a\nhighly accurate simulation. We discuss the requirements of this approach to\nachieve accurate and numerically stable results and compare the phase-field\nmodel to a purely local approach that does not enforce spatial smoothness for\nthe phase mixing. Using a Gaussian Process surrogate for an elasto-plastic\nmaterial, we demonstrate the potential of this mixture of models to accelerate\nmultiscale simulations.", "published": "2025-04-23 13:42:07", "link": "http://arxiv.org/abs/2504.16713v1", "categories": ["math.NA", "cs.CE", "cs.NA"], "primary_category": "math.NA"}
{"title": "A hybrid high-order method for the biharmonic problem", "abstract": "This paper proposes a new hybrid high-order discretization for the biharmonic\nproblem and the corresponding eigenvalue problem. The discrete ansatz space\nincludes degrees of freedom in $n-2$ dimensional submanifolds (e.g., nodal\nvalues in 2D and edge values in 3D), in addition to the typical degrees of\nfreedom in the mesh and on the hyperfaces in the HHO literature. This approach\nenables the characteristic commuting property of the hybrid high-order\nmethodology in any space dimension and allows for lower eigenvalue bounds of\nhigher order for the eigenvalue problem. The main results are quasi-best\napproximation estimates as well as reliable and efficient error control. The\nlatter motivates an adaptive mesh-refining algorithm that empirically recovers\noptimal convergence rates for singular solutions.", "published": "2025-04-23 10:46:21", "link": "http://arxiv.org/abs/2504.16608v1", "categories": ["math.NA", "cs.NA", "65N30, 65N25, 65N15"], "primary_category": "math.NA"}
{"title": "3D-1D modelling of cranial plate heating induced by low or medium frequency magnetic fields", "abstract": "Safety assessment of patients with one-dimensionally structured passive\nimplants, like cranial plates or stents, exposed to low or medium frequency\nmagnetic fields, like those generated in magnetic resonance imaging or magnetic\nhyperthermia, can be challenging, because of the different length scales of the\nimplant and the human body. Most of the methods used to estimate the heating\ninduced near such implants neglect the presence of the metallic materials\nwithin the body, modeling the metal as thermal seeds. To overcome this\nlimitation, a novel numerical approach that solves three-dimensional and\none-dimensional coupled problems is proposed. This method leads to improved\nresults by modelling the thermal diffusion through the highly conductive\nmetallic implants. A comparison of the proposed method predictions with\nmeasurements performed on a cranial plate exposed to the magnetic field\ngenerated by a gradient coil system for magnetic resonance imaging is\npresented, showing an improved accuracy up to 25 % with respect to the method\nbased on thermal seeds. The proposed method is finally applied to a magnetic\nhyperthermia case study in which a patient with a cranial plate is exposed to\nthe magnetic field generated by a collar-type magnetic hyperthermia applicator\nfor neck tumour treatment, predicting a temperature increase in proximity of\nthe implant that is 10 % lower than the one overestimated by relying on thermal\nseeds.", "published": "2025-04-23 10:29:53", "link": "http://arxiv.org/abs/2504.16600v1", "categories": ["cs.CE", "cs.NA", "math.NA", "physics.med-ph"], "primary_category": "cs.CE"}
{"title": "Alternately-optimized SNN method for acoustic scattering problem in unbounded domain", "abstract": "In this paper, we propose a novel machine learning-based method to solve the\nacoustic scattering problem in unbounded domain. We first employ the\nDirichlet-to-Neumann (DtN) operator to truncate the physically unbounded domain\ninto a computable bounded domain. This transformation reduces the original\nscattering problem in the unbounded domain to a boundary value problem within\nthe bounded domain. To solve this boundary value problem, we design a neural\nnetwork with a subspace layer, where each neuron in this layer represents a\nbasis function. Consequently, the approximate solution can be expressed by a\nlinear combination of these basis functions. Furthermore, we introduce an\ninnovative alternating optimization technique which alternately updates the\nbasis functions and their linear combination coefficients respectively by\ntraining and least squares methods. In our method, we set the coefficients of\nbasis functions to 1 and use a new loss function each time train the subspace.\nThese innovations ensure that the subspace formed by these basis functions is\ntruly optimized. We refer to this method as the alternately-optimized subspace\nmethod based on neural networks (AO-SNN). Extensive numerical experiments\ndemonstrate that our new method can significantly reduce the relative $l^2$\nerror to $10^{-7}$ or lower, outperforming existing machine learning-based\nmethods to the best of our knowledge.", "published": "2025-04-23 08:46:22", "link": "http://arxiv.org/abs/2504.16523v1", "categories": ["math.NA", "cs.NA", "65N22, 68T07", "G.1.8; I.2.6"], "primary_category": "math.NA"}
{"title": "Efficient Design of Compliant Mechanisms Using Multi-Objective Optimization", "abstract": "Compliant mechanisms achieve motion through elastic deformation. In this\nwork, we address the synthesis of a compliant cross-hinge mechanism capable of\nlarge angular strokes while approximating the behavior of an ideal revolute\njoint. To capture the competing demands of kinematic fidelity, rotational\nstiffness, and resistance to parasitic motion, we formulate a multi-objective\noptimization problem based on kinetostatic performance measures. A hybrid\ndesign strategy is employed: an efficient beam-based structural model enables\nextensive exploration of a high-dimensional design space using evolutionary\nalgorithms, followed by fine-tuning with high-fidelity three-dimensional finite\nelement analysis. The resulting Pareto-optimal designs reveal diverse geometric\nconfigurations and performance trade-offs.", "published": "2025-04-23 06:29:10", "link": "http://arxiv.org/abs/2504.16451v1", "categories": ["math.NA", "cs.NA", "cs.NE"], "primary_category": "math.NA"}
{"title": "Real-time Bayesian inference at extreme scale: A digital twin for tsunami early warning applied to the Cascadia subduction zone", "abstract": "We present a Bayesian inversion-based digital twin that employs acoustic\npressure data from seafloor sensors, along with 3D coupled acoustic-gravity\nwave equations, to infer earthquake-induced spatiotemporal seafloor motion in\nreal time and forecast tsunami propagation toward coastlines for early warning\nwith quantified uncertainties. Our target is the Cascadia subduction zone, with\none billion parameters. Computing the posterior mean alone would require 50\nyears on a 512 GPU machine. Instead, exploiting the shift invariance of the\nparameter-to-observable map and devising novel parallel algorithms, we induce a\nfast offline-online decomposition. The offline component requires just one\nadjoint wave propagation per sensor; using MFEM, we scale this part of the\ncomputation to the full El Capitan system (43,520 GPUs) with 92% weak parallel\nefficiency. Moreover, given real-time data, the online component exactly solves\nthe Bayesian inverse and forecasting problems in 0.2 seconds on a modest GPU\nsystem, a ten-billion-fold speedup.", "published": "2025-04-23 01:41:24", "link": "http://arxiv.org/abs/2504.16344v1", "categories": ["cs.DC", "cs.NA", "math.NA", "physics.geo-ph"], "primary_category": "cs.DC"}
{"title": "Automated Market Makers: A Stochastic Optimization Approach for Profitable Liquidity Concentration", "abstract": "Concentrated liquidity automated market makers (AMMs), such as Uniswap v3,\nenable liquidity providers (LPs) to earn liquidity rewards by depositing tokens\ninto liquidity pools. However, LPs often face significant financial losses\ndriven by poorly selected liquidity provision intervals and high costs\nassociated with frequent liquidity reallocation. To support LPs in achieving\nmore profitable liquidity concentration, we developed a tractable stochastic\noptimization problem that can be used to compute optimal liquidity provision\nintervals for profitable liquidity provision. The developed problem accounts\nfor the relationships between liquidity rewards, divergence loss, and\nreallocation costs. By formalizing optimal liquidity provision as a tractable\nstochastic optimization problem, we support a better understanding of the\nrelationship between liquidity rewards, divergence loss, and reallocation\ncosts. Moreover, the stochastic optimization problem offers a foundation for\nmore profitable liquidity concentration.", "published": "2025-04-23 09:13:53", "link": "http://arxiv.org/abs/2504.16542v1", "categories": ["q-fin.TR", "q-fin.CP", "q-fin.MF"], "primary_category": "q-fin.TR"}
{"title": "Modern Computational Methods in Reinsurance Optimization: From Simulated Annealing to Quantum Branch & Bound", "abstract": "We propose and implement modern computational methods to enhance catastrophe\nexcess-of-loss reinsurance contracts in practice. The underlying optimization\nproblem involves attachment points, limits, and reinstatement clauses, and the\nobjective is to maximize the expected profit while considering risk measures\nand regulatory constraints. We study the problem formulation, paving the way\nfor practitioners, for two very different approaches: A local search optimizer\nusing simulated annealing, which handles realistic constraints, and a branch &\nbound approach exploring the potential of a future speedup via quantum branch &\nbound. On the one hand, local search effectively generates contract structures\nwithin several constraints, proving useful for complex treaties that have\nmultiple local optima. On the other hand, although our branch & bound\nformulation only confirms that solving the full problem with a future quantum\ncomputer would require a stronger, less expensive bound and substantial\nhardware improvements, we believe that the designed application-specific bound\nis sufficiently strong to serve as a basis for further works. Concisely, we\nprovide insurance practitioners with a robust numerical framework for contract\noptimization that handles realistic constraints today, as well as an outlook\nand initial steps towards an approach which could leverage quantum computers in\nthe future.", "published": "2025-04-23 08:55:40", "link": "http://arxiv.org/abs/2504.16530v1", "categories": ["math.OC", "q-fin.CP", "quant-ph"], "primary_category": "math.OC"}
{"title": "Towards a fast and robust deep hedging approach", "abstract": "We present a robust Deep Hedging framework for the pricing and hedging of\noption portfolios that significantly improves training efficiency and model\nrobustness. In particular, we propose a neural model for training model\nembeddings which utilizes the paths of several advanced equity option models\nwith stochastic volatility in order to learn the relationships that exist\nbetween hedging strategies. A key advantage of the proposed method is its\nability to rapidly and reliably adapt to new market regimes through the\nrecalibration of a low-dimensional embedding vector, rather than retraining the\nentire network. Moreover, we examine the observed Profit and Loss distributions\non the parameter space of the models used to learn the embeddings. The results\nshow that the proposed framework works well with data generated by complex\nmodels and can serve as a construction basis for an efficient and robust\nsimulation tool for the systematic development of an entirely model-independent\nhedging strategy.", "published": "2025-04-23 05:48:52", "link": "http://arxiv.org/abs/2504.16436v1", "categories": ["q-fin.CP"], "primary_category": "q-fin.CP"}
{"title": "Unbiased simulation of Asian options", "abstract": "We provide an extension of the unbiased simulation method for SDEs developed\nin Henry-Labordere et al. [Ann Appl Probab. 27:6 (2017) 1-37] to a class of\npath-dependent dynamics, pertaining for Asian options. In our setting, both the\npayoff and the SDE's coefficients depend on the (weighted) average of the\nprocess or, more precisely, on the integral of the solution to the SDE against\na continuous function with bounded variations. In particular, this applies to\nthe numerical resolution of the class of path-dependent PDEs whose regularity,\nin the sens of Dupire, is studied in Bouchard and Tan [Ann. I.H.P., to appear].", "published": "2025-04-23 01:52:53", "link": "http://arxiv.org/abs/2504.16349v1", "categories": ["math.PR", "q-fin.CP", "65C05, 60J60, 60J85, 35K10"], "primary_category": "math.PR"}
{"title": "SoCov: Semi-Orthogonal Parametric Pooling of Covariance Matrix for Speaker Recognition", "abstract": "In conventional deep speaker embedding frameworks, the pooling layer\naggregates all frame-level features over time and computes their mean and\nstandard deviation statistics as inputs to subsequent segment-level layers.\nSuch statistics pooling strategy produces fixed-length representations from\nvariable-length speech segments. However, this method treats different\nframe-level features equally and discards covariance information. In this\npaper, we propose the Semi-orthogonal parameter pooling of Covariance matrix\n(SoCov) method. The SoCov pooling computes the covariance matrix from the\nself-attentive frame-level features and compresses it into a vector using the\nsemi-orthogonal parametric vectorization, which is then concatenated with the\nweighted standard deviation vector to form inputs to the segment-level layers.\nDeep embedding based on SoCov is called ``sc-vector''. The proposed sc-vector\nis compared to several different baselines on the SRE21 development and\nevaluation sets. The sc-vector system significantly outperforms the\nconventional x-vector system, with a relative reduction in EER of 15.5% on\nSRE21Eval. When using self-attentive deep feature, SoCov helps to reduce EER on\nSRE21Eval by about 30.9% relatively to the conventional ``mean + standard\ndeviation'' statistics.", "published": "2025-04-23 06:01:14", "link": "http://arxiv.org/abs/2504.16441v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "An Accelerated Camera 3DMA Framework for Efficient Urban GNSS Multipath Estimation", "abstract": "Robust GNSS positioning in urban environments is still plagued by multipath\neffects, particularly due to the complex signal propagation induced by\nubiquitous surfaces with varied radio frequency reflectivities. Current 3D\nMapping Aided (3DMA) GNSS techniques show great potentials in mitigating\nmultipath but face a critical trade-off between computational efficiency and\nmodeling accuracy. Most approaches often rely on offline outdated or\noversimplified 3D maps, while real-time LiDAR-based reconstruction boasts high\naccuracy, it is problematic in low laser reflectivity conditions; camera 3DMA\nis a good candidate to balance accuracy and efficiency but current methods\nsuffer from extremely low reconstruction speed, a far cry from real-time\nmultipath-mitigated navigation. This paper proposes an accelerated framework\nincorporating camera multi-view stereo (MVS) reconstruction and ray tracing. By\nhypothesizing on surface textures, an orthogonal visual feature fusion\nframework is proposed, which robustly addresses both texture-rich and\ntexture-poor surfaces, lifting off the reflectivity challenges in visual\nreconstruction. A polygonal surface modeling scheme is further integrated to\naccurately delineate complex building boundaries, enhancing the reconstruction\ngranularity. To avoid excessively accurate reconstruction, reprojected point\ncloud multi-plane fitting and two complexity control strategies are proposed,\nthus improving upon multipath estimation speed. Experiments were conducted in\nLujiazui, Shanghai, a typical multipath-prone district. The results show that\nthe method achieves an average reconstruction accuracy of 2.4 meters in dense\nurban environments featuring glass curtain wall structures, a traditionally\ntough case for reconstruction, and achieves a ray-tracing-based multipath\ncorrection rate of 30 image frames per second, 10 times faster than the\ncontemporary benchmarks.", "published": "2025-04-23 17:34:37", "link": "http://arxiv.org/abs/2504.16906v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Association-Based Track-Before-Detect with Object Contribution Probabilities", "abstract": "Multiobject tracking provides situational awareness that enables new\napplications for modern convenience, applied ocean sciences, public safety, and\nhomeland security. In many multiobject tracking applications, including radar\nand sonar tracking, after coherent prefiltering of the received signal,\nmeasurement data is typically structured in cells, where each cell represent,\ne.g., a different range and bearing value. While conventional detect-then-track\n(DTT) multiobject tracking approaches convert the cell-structured data within a\ndetection phase into so-called point measurements in order to reduce the amount\nof data, track-before-detect (TBD) methods process the cell-structured data\ndirectly, avoiding a potential information loss. However, many TBD tracking\nmethods are computationally intensive and achieve a reduced tracking accuracy\nwhen objects interact, i.e., when they come into close proximity. We here\ncounteract these difficulties by introducing the concept of probabilistic\nobject-to-cell contributions. As many conventional DTT methods, our approach\nuses a probabilistic association of objects with data cells, and a new object\ncontribution model with corresponding object contribution probabilities to\nfurther associate cell contributions to objects that occupy the same data cell.\nFurthermore, to keep the computational complexity and filter runtimes low, we\nhere use an efficient Poisson multi-Bernoulli filtering approach in combination\nwith the application of belief propagation for fast probabilistic data\nassociation. We demonstrate numerically that our method achieves significantly\nincreased tracking performance compared to state-of-the-art TBD tracking\napproaches, where performance differences are particularly pronounced when\nmultiple objects interact.", "published": "2025-04-23 15:32:11", "link": "http://arxiv.org/abs/2504.16814v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Array Partitioning Based Near-Field Attitude and Location Estimation", "abstract": "This paper studies a passive source localization system, where a single base\nstation (BS) is employed to estimate the positions and attitudes of multiple\nmobile stations (MSs). The BS and the MSs are equipped with uniform rectangular\narrays, and the MSs are located in the near-field region of the BS array. To\navoid the difficulty of tackling the problem directly based on the near-field\nsignal model, we establish a subarray-wise far-field received signal model. In\nthis model, the entire BS array is divided into multiple subarrays to ensure\nthat each MS is in the far-field region of each BS subarray. By exploiting the\nangles of arrival (AoAs) of an MS antenna at different BS subarrays, we\nformulate the attitude and location estimation problem under the Bayesian\ninference framework. Based on the factor graph representation of the\nprobabilistic problem model, a message passing algorithm named array\npartitioning based pose and location estimation (APPLE) is developed to solve\nthis problem. An estimation-error lower bound is obtained as a performance\nbenchmark of the proposed algorithm. Numerical results demonstrate that the\nproposed APPLE algorithm outperforms other baseline methods in the accuracy of\nposition and attitude estimation.", "published": "2025-04-23 15:20:39", "link": "http://arxiv.org/abs/2504.16800v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "On the Asymptotic MSE-Optimality of Parametric Bayesian Channel Estimation in mmWave Systems", "abstract": "The mean square error (MSE)-optimal estimator is known to be the conditional\nmean estimator (CME). This paper introduces a parametric channel estimation\ntechnique based on Bayesian estimation. This technique uses the estimated\nchannel parameters to parameterize the well-known LMMSE channel estimator. We\nfirst derive an asymptotic CME formulation that holds for a wide range of\npriors on the channel parameters. Based on this, we show that parametric\nBayesian channel estimation is MSE-optimal for high signal-to-noise ratio (SNR)\nand/or long coherence intervals, i.e., many noisy observations provided within\none coherence interval. Numerical simulations validate the derived\nformulations.", "published": "2025-04-23 13:41:02", "link": "http://arxiv.org/abs/2504.16710v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Novel Sparse Sum and Difference Co-Array With Low Redundancy and Enhanced DOF for Non-Circular Signals", "abstract": "Array structures based on the sum and difference co-arrays provide more\ndegrees of freedom (DOF). However, since the growth of DOF is limited by a\nsingle case of sum and difference co-arrays, the paper aims to design a sparse\nlinear array (SLA) with higher DOF via exploring different cases of\nsecond-order cumulants. We present a mathematical framework based on\nsecond-order cumulant to devise a second-order extended co-array (SO-ECA) and\ndefine the redundancy of SO-ECA. Based on SO-ECA, a novel array is proposed,\nnamely low redundancy sum and difference array (LR-SDA), which can provide\nclosed-form expressions for the sensor positions and enhance DOF in order to\nresolve more signal sources in the direction of arrival (DOA) estimation of\nnon-circular (NC) signals. For LR-SDA, the maximum DOF under the given number\nof total physical sensors can be derived and the SO-ECA of LR-SDA is hole-free.\nFurther, the corresponding necessary and sufficient conditions of signal\nreconstruction for LR-SDA are derived. Additionally, the redundancy and weight\nfunction of LR-SDA are defined, and the lower band of the redundancy for LR-SDA\nis derived. The proposed LR-SDA achieves higher DOF and lower redundancy than\nthose of existing DCAs designed based on sum and difference co-arrays.\nNumerical simulations are conducted to verify the superiority of LR-SDA on DOA\nestimation performance and enhanced DOF over other existing DCAs.", "published": "2025-04-23 12:45:06", "link": "http://arxiv.org/abs/2504.16675v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Non-linearity Effect Analysis of Gaussian Pulse Propagation In Optical Fiber", "abstract": "In this research, numerical analysis of nonlinear pulse propagation is\ncarried out. This is done mainly by solving the nonlinear Schrodinger equation\nusing the split step algorithm. In a nonlinear media, dispersive effects exist\nsimultaneously with nonlinear effects. Refractive index dependence on intensity\nresults in optical Kerr effect which causes narrowing of transmitted pulses by\ninducing self-phase modulation while second order group velocity dispersion\ncauses the pulses to spread. In this project, group velocity dispersion is\ndiscussed followed by self-phase modulation. These individually detrimental\neffects are shown to combine beneficially for propagation of pulses here.\nGaussian pulse is studied and propagated by using them as input in to the\nnonlinear Schrodinger equation. The split step algorithm is described in depth.\nExplanation of each step is included along with the relevant equations defining\nthese steps.", "published": "2025-04-23 12:17:43", "link": "http://arxiv.org/abs/2504.16652v1", "categories": ["physics.optics", "eess.SP"], "primary_category": "physics.optics"}
{"title": "UAV-Mounted IRS (UMI) in the Presence of Hovering Fluctuations: 3D Pattern Characterization and Performance Analysis", "abstract": "This paper investigates unmanned aerial vehicle (UAV)-mounted intelligent\nreflecting surfaces (IRS) to leverage the benefits of this technology for\nfuture communication networks, such as 6G. Key advantages include enhanced\nspectral and energy efficiency, expanded network coverage, and flexible\ndeployment. One of the main challenges in employing UAV-mounted IRS (UMI)\ntechnology is the random fluctuations of hovering UAVs. Focusing on this\nchallenge, this paper explores the capabilities of UMI with passive/active\nelements affected by UAV fluctuations in both horizontal and vertical angles,\nconsidering the three-dimensional (3D) radiation pattern of the IRS. The\nrelationship between UAV fluctuations and IRS pattern is investigated by taking\ninto account the random angular vibrations of UAVs. A tractable and closed-form\ndistribution function for the IRS pattern is derived, using linear\napproximation and by dividing it into several sectors. In addition, closed-form\nexpressions for outage probability (OP) are obtained using central limit\ntheorem (CLT) and Gamma approximation. The theoretical expressions are\nvalidated through Monte Carlo simulations. The findings indicate that the\nrandom fluctuations of hovering UAVs have a notable impact on the performance\nof UMI systems. To avoid link interruptions due to UAV instability, IRS should\nutilize fewer elements, even though this leads to a decrease in directivity. As\na result, unlike terrestrial IRS, incorporating more elements into aerial IRS\nsystems does not necessarily improve performance due to the fluctuations in\nUAV. Numerical results show that the OP can be minimized by selecting the\noptimal number of IRS elements and using active elements.", "published": "2025-04-23 10:59:03", "link": "http://arxiv.org/abs/2504.16613v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Performance Assessment of Hybrid and Digital Irregular Array Configurations for Beyond 100-GHz Multi-User MIMO Systems", "abstract": "The performance of irregular phased array architectures is assessed in the\ncontext of multi-user multiple-input multiple-output (MU-MIMO) communications\noperating beyond 100 GHz. Realizing half-wavelength spaced planar phased arrays\nis challenging due to wavelength-integrated circuit (IC) size conflict at those\nfrequencies where the antenna dimensions are comparable to IC size. Therefore,\nirregular array architectures such as thinned and clustered arrays are\ndeveloped to mitigate the wavelength-IC size conflict. In the thinned arrays,\nradiating elements are permanently deactivated, while in clustered arrays,\nneighboring elements are grouped into subarrays. Furthermore, irregular arrays\nare integrated with hybrid beamforming architectures to manage the complexity\nintroduced by full digital beamforming, where a single radio frequency chain is\nconnected per power amplifier. An optimization problem is formulated to\ndetermine the optimal arrangement of antenna elements where the trade-off\nbetween spectral efficiency (SE) and sidelobe levels (SLL) can be tuned.\nClustered array configurations are optimized by genetic algorithm and\nAlgorithm-X based methodologies, where the former relies on a randomized search\nand the latter exploits brute-force search, respectively. Furthermore, a\nprototype array is designed on a printed circuit board (PCB) to verify the\nproposed methodologies through full-wave simulations. To have a fair\ncomparison, clustered arrays with a grouping of two and four elements are\ncompared with thinned arrays with half and quarter thinning ratios,\nrespectively. The combination of hybrid and irregular array architectures leads\nto minimal or no performance degradation in the case of hybrid fully connected\narchitectures but severe SE and SLL degradation in the case of hybrid partially\nconnected architectures, respectively.", "published": "2025-04-23 08:45:23", "link": "http://arxiv.org/abs/2504.16521v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Joint Topology and Power Optimization for Multi-UAV Collaborative Secure Communication", "abstract": "In this paper, we investigate an unmanned aerial vehicle (UAV)-enabled secure\ncommunication scenario that a cluster of UAVs performs a virtual non-uniform\nlinear array (NULA) to communicate with a base station (BS) in the presence of\neavesdroppers (Eves). Our goal is to design the UAV topology, trajectory, and\nprecoding to maximize the system channel capacity. To this end, we convert the\noriginal problem into equivalent two-stage problems. Specifically, we first try\nto maximize the channel gain by meticulously designing the UAV topology. We\nthen study the joint optimization of the trajectory and precoding for total\ntransmit power minimization while satisfying the constraints on providing\nquality of service (QoS) assurance to the BS, the leakage tolerance to Eves,\nthe per-UAV transmit power, the initial/final locations, and the cylindrical\nno-fly zones. For the UAV topology design, we prove that the topology follows\nthe Fekete-point distribution. The design of trajectory and precoding is\nformulated as a non-convex optimization problem which is generally intractable.\nSubsequently, the non-convex constraints are converted into convex terms, and a\ndouble-loop search algorithm is proposed to solve the transmit power\nminimization problem. Introduce random rotation offsets so as to perform a\ndynamic stochastic channel to enhance the security. Numerical results\ndemonstrate the superiority of the proposed method in promoting capacity.", "published": "2025-04-23 03:39:02", "link": "http://arxiv.org/abs/2504.16392v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Robust Transmission Design for Reconfigurable Intelligent Surface and Movable Antenna Enabled Symbiotic Radio Communications", "abstract": "This paper explores the application of movable antenna (MA), a cutting-edge\ntechnology with the capability of altering antenna positions, in a symbiotic\nradio (SR) system enabled by reconfigurable intelligent surface (RIS). The goal\nis to fully exploit the capabilities of both MA and RIS, constructing a better\ntransmission environment for the co-existing primary and secondary transmission\nsystems. For both parasitic SR (PSR) and commensal SR (CSR) scenarios with the\nchannel uncertainties experienced by all transmission links, we design a robust\ntransmission scheme with the goal of maximizing the primary rate while ensuring\nthe secondary transmission quality. To address the maximization problem with\nthorny non-convex characteristics, we propose an alternating optimization\nframework that utilizes the General S-Procedure, General Sign-Definiteness\nPrinciple, successive convex approximation (SCA), and simulated annealing (SA)\nimproved particle swarm optimization (SA-PSO) algorithms. Numerical results\nvalidate that the CSR scenario significantly outperforms the PSR scenario in\nterms of primary rate, and also show that compared to the fixed-position\nantenna scheme, the proposed MA scheme can increase the primary rate by 1.62\nbps/Hz and 2.37 bps/Hz for the PSR and CSR scenarios, respectively.", "published": "2025-04-23 03:28:50", "link": "http://arxiv.org/abs/2504.16386v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Lightweight and Self-Evolving Channel Twinning: An Ensemble DMD-Assisted Approach", "abstract": "Traditional channel acquisition faces significant limitations due to ideal\nmodel assumptions and scalability challenges. A novel environment-aware\nparadigm, known as channel twinning, tackles these issues by constructing radio\npropagation environment semantics using a data-driven approach. In the\nspotlight of channel twinning technology, a radio map is recognized as an\neffective region-specific model for learning the spatial distribution of\nchannel information. However, most studies focus on static channel map\nconstruction, with only a few collecting numerous channel samples and using\ndeep learning for radio map prediction. In this paper, we develop a novel\ndynamic radio map twinning framework with a substantially small dataset.\nSpecifically, we present an innovative approach that employs dynamic mode\ndecomposition (DMD) to model the evolution of the dynamic channel gain map as a\ndynamical system. We first interpret dynamic channel gain maps as\nspatio-temporal video stream data. The coarse-grained and fine-grained evolving\nmodes are extracted from the stream data using a new ensemble DMD (Ens-DMD)\nalgorithm. To mitigate the impact of noisy data, we design a median-based\nthreshold mask technique to filter the noise artifacts of the twin maps. With\nthe proposed DMD-based radio map twinning framework, numerical results are\nprovided to demonstrate the low-complexity reproduction and evolution of the\nchannel gain maps. Furthermore, we consider four radio map twin performance\nmetrics to confirm the superiority of our framework compared to the baselines.", "published": "2025-04-23 02:52:42", "link": "http://arxiv.org/abs/2504.16376v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Self-Nomination: Deep Learning for Decentralized CSI Feedback Reduction in MU-MIMO Systems", "abstract": "This paper introduces a novel deep learning-based user-side feedback\nreduction framework, termed self-nomination. The goal of self-nomination is to\nreduce the number of users (UEs) feeding back channel state information (CSI)\nto the base station (BS), by letting each UE decide whether to feed back based\non its estimated likelihood of being scheduled and its potential contribution\nto precoding in a multiuser MIMO (MU-MIMO) downlink. Unlike SNR- or SINR-based\nthresholding methods, the proposed approach uses rich spatial channel\nstatistics and learns nontrivial correlation effects that affect eventual\nMU-MIMO scheduling decisions. To train the self-nomination network under an\naverage feedback constraint, we propose two different strategies: one based on\ndirect optimization with gradient approximations, and another using policy\ngradient-based optimization with a stochastic Bernoulli policy to handle\nnon-differentiable scheduling. The framework also supports proportional-fair\nscheduling by incorporating dynamic user weights. Numerical results confirm\nthat the proposed self-nomination method significantly reduces CSI feedback\noverhead. Compared to baseline feedback methods, self-nomination can reduce\nfeedback by as much as 65%, saving not only bandwidth but also allowing many\nUEs to avoid feedback altogether (and thus, potentially enter a sleep mode).\nSelf-nomination achieves this significant savings with negligible reduction in\nsum-rate or fairness.", "published": "2025-04-23 02:00:49", "link": "http://arxiv.org/abs/2504.16351v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Can Large Language Models Help Multimodal Language Analysis? MMLA: A Comprehensive Benchmark", "abstract": "Multimodal language analysis is a rapidly evolving field that leverages\nmultiple modalities to enhance the understanding of high-level semantics\nunderlying human conversational utterances. Despite its significance, little\nresearch has investigated the capability of multimodal large language models\n(MLLMs) to comprehend cognitive-level semantics. In this paper, we introduce\nMMLA, a comprehensive benchmark specifically designed to address this gap. MMLA\ncomprises over 61K multimodal utterances drawn from both staged and real-world\nscenarios, covering six core dimensions of multimodal semantics: intent,\nemotion, dialogue act, sentiment, speaking style, and communication behavior.\nWe evaluate eight mainstream branches of LLMs and MLLMs using three methods:\nzero-shot inference, supervised fine-tuning, and instruction tuning. Extensive\nexperiments reveal that even fine-tuned models achieve only about 60%~70%\naccuracy, underscoring the limitations of current MLLMs in understanding\ncomplex human language. We believe that MMLA will serve as a solid foundation\nfor exploring the potential of large language models in multimodal language\nanalysis and provide valuable resources to advance this field. The datasets and\ncode are open-sourced at https://github.com/thuiar/MMLA.", "published": "2025-04-23 05:25:13", "link": "http://arxiv.org/abs/2504.16427v2", "categories": ["cs.CL", "cs.AI", "cs.MM"], "primary_category": "cs.CL"}
{"title": "V$^2$R-Bench: Holistically Evaluating LVLM Robustness to Fundamental Visual Variations", "abstract": "Large Vision Language Models (LVLMs) excel in various vision-language tasks.\nYet, their robustness to visual variations in position, scale, orientation, and\ncontext that objects in natural scenes inevitably exhibit due to changes in\nviewpoint and environment remains largely underexplored. To bridge this gap, we\nintroduce V$^2$R-Bench, a comprehensive benchmark framework for evaluating\nVisual Variation Robustness of LVLMs, which encompasses automated evaluation\ndataset generation and principled metrics for thorough robustness assessment.\nThrough extensive evaluation on 21 LVLMs, we reveal a surprising vulnerability\nto visual variations, in which even advanced models that excel at complex\nvision-language tasks significantly underperform on simple tasks such as object\nrecognition. Interestingly, these models exhibit a distinct visual position\nbias that contradicts theories of effective receptive fields, and demonstrate a\nhuman-like visual acuity threshold. To identify the source of these\nvulnerabilities, we present a systematic framework for component-level\nanalysis, featuring a novel visualization approach for aligned visual features.\nResults show that these vulnerabilities stem from error accumulation in the\npipeline architecture and inadequate multimodal alignment. Complementary\nexperiments with synthetic data further demonstrate that these limitations are\nfundamentally architectural deficiencies, scoring the need for architectural\ninnovations in future LVLM designs.", "published": "2025-04-23 14:01:32", "link": "http://arxiv.org/abs/2504.16727v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Marginalized Generalized IoU (MGIoU): A Unified Objective Function for Optimizing Any Convex Parametric Shapes", "abstract": "Optimizing the similarity between parametric shapes is crucial for numerous\ncomputer vision tasks, where Intersection over Union (IoU) stands as the\ncanonical measure. However, existing optimization methods exhibit significant\nshortcomings: regression-based losses like L1/L2 lack correlation with IoU,\nIoU-based losses are unstable and limited to simple shapes, and task-specific\nmethods are computationally intensive and not generalizable accross domains. As\na result, the current landscape of parametric shape objective functions has\nbecome scattered, with each domain proposing distinct IoU approximations. To\naddress this, we unify the parametric shape optimization objective functions by\nintroducing Marginalized Generalized IoU (MGIoU), a novel loss function that\novercomes these challenges by projecting structured convex shapes onto their\nunique shape Normals to compute one-dimensional normalized GIoU. MGIoU offers a\nsimple, efficient, fully differentiable approximation strongly correlated with\nIoU. We then extend MGIoU to MGIoU+ that supports optimizing unstructured\nconvex shapes. Together, MGIoU and MGIoU+ unify parametric shape optimization\nacross diverse applications. Experiments on standard benchmarks demonstrate\nthat MGIoU and MGIoU+ consistently outperform existing losses while reducing\nloss computation latency by 10-40x. Additionally, MGIoU and MGIoU+ satisfy\nmetric properties and scale-invariance, ensuring robustness as an objective\nfunction. We further propose MGIoU- for minimizing overlaps in tasks like\ncollision-free trajectory prediction. Code is available at\nhttps://ldtho.github.io/MGIoU", "published": "2025-04-23 06:05:39", "link": "http://arxiv.org/abs/2504.16443v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Exploring How LLMs Capture and Represent Domain-Specific Knowledge", "abstract": "We study whether Large Language Models (LLMs) inherently capture\ndomain-specific nuances in natural language. Our experiments probe the domain\nsensitivity of LLMs by examining their ability to distinguish queries from\ndifferent domains using hidden states generated during the prefill phase. We\nreveal latent domain-related trajectories that indicate the model's internal\nrecognition of query domains. We also study the robustness of these domain\nrepresentations to variations in prompt styles and sources. Our approach\nleverages these representations for model selection, mapping the LLM that best\nmatches the domain trace of the input query (i.e., the model with the highest\nperformance on similar traces). Our findings show that LLMs can differentiate\nqueries for related domains, and that the fine-tuned model is not always the\nmost accurate. Unlike previous work, our interpretations apply to both closed\nand open-ended generative tasks", "published": "2025-04-23 16:46:06", "link": "http://arxiv.org/abs/2504.16871v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Simple Graph Contrastive Learning via Fractional-order Neural Diffusion Networks", "abstract": "Graph Contrastive Learning (GCL) has recently made progress as an\nunsupervised graph representation learning paradigm. GCL approaches can be\ncategorized into augmentation-based and augmentation-free methods. The former\nrelies on complex data augmentations, while the latter depends on encoders that\ncan generate distinct views of the same input. Both approaches may require\nnegative samples for training. In this paper, we introduce a novel\naugmentation-free GCL framework based on graph neural diffusion models.\nSpecifically, we utilize learnable encoders governed by Fractional Differential\nEquations (FDE). Each FDE is characterized by an order parameter of the\ndifferential operator. We demonstrate that varying these parameters allows us\nto produce learnable encoders that generate diverse views, capturing either\nlocal or global information, for contrastive learning. Our model does not\nrequire negative samples for training and is applicable to both homophilic and\nheterophilic datasets. We demonstrate its effectiveness across various\ndatasets, achieving state-of-the-art performance.", "published": "2025-04-23 14:17:28", "link": "http://arxiv.org/abs/2504.16748v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Statistical Evaluation of Indoor LoRaWAN Environment-Aware Propagation for 6G: MLR, ANOVA, and Residual Distribution Analysis", "abstract": "Modeling path loss in indoor LoRaWAN technology deployments is inherently\nchallenging due to structural obstructions, occupant density and activities,\nand fluctuating environmental conditions. This study proposes a two-stage\napproach to capture and analyze these complexities using an extensive dataset\nof 1,328,334 field measurements collected over six months in a single-floor\noffice at the University of Siegen's Hoelderlinstrasse Campus, Germany. First,\nwe implement a multiple linear regression model that includes traditional\npropagation metrics (distance, structural walls) and an extension with proposed\nenvironmental variables (relative humidity, temperature, carbon dioxide,\nparticulate matter, and barometric pressure). Using analysis of variance, we\ndemonstrate that adding these environmental factors can reduce unexplained\nvariance by 42.32 percent. Secondly, we examine residual distributions by\nfitting five candidate probability distributions: Normal, Skew-Normal, Cauchy,\nStudent's t, and Gaussian Mixture Models with one to five components. Our\nresults show that a four-component Gaussian Mixture Model captures the residual\nheterogeneity of indoor signal propagation most accurately, significantly\noutperforming single-distribution approaches. Given the push toward\nultra-reliable, context-aware communications in 6G networks, our analysis shows\nthat environment-aware modeling can substantially improve LoRaWAN network\ndesign in dynamic indoor IoT deployments.", "published": "2025-04-23 13:19:35", "link": "http://arxiv.org/abs/2504.16688v2", "categories": ["cs.NI", "cs.LG", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Hyper-Transforming Latent Diffusion Models", "abstract": "We introduce a novel generative framework for functions by integrating\nImplicit Neural Representations (INRs) and Transformer-based hypernetworks into\nlatent variable models. Unlike prior approaches that rely on MLP-based\nhypernetworks with scalability limitations, our method employs a\nTransformer-based decoder to generate INR parameters from latent variables,\naddressing both representation capacity and computational efficiency. Our\nframework extends latent diffusion models (LDMs) to INR generation by replacing\nstandard decoders with a Transformer-based hypernetwork, which can be trained\neither from scratch or via hyper-transforming-a strategy that fine-tunes only\nthe decoder while freezing the pre-trained latent space. This enables efficient\nadaptation of existing generative models to INR-based representations without\nrequiring full retraining.", "published": "2025-04-23 10:01:18", "link": "http://arxiv.org/abs/2504.16580v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "An Effective Gram Matrix Characterizes Generalization in Deep Networks", "abstract": "We derive a differential equation that governs the evolution of the\ngeneralization gap when a deep network is trained by gradient descent. This\ndifferential equation is controlled by two quantities, a contraction factor\nthat brings together trajectories corresponding to slightly different datasets,\nand a perturbation factor that accounts for them training on different\ndatasets. We analyze this differential equation to compute an ``effective Gram\nmatrix'' that characterizes the generalization gap after training in terms of\nthe alignment between this Gram matrix and a certain initial ``residual''.\nEmpirical evaluations on image classification datasets indicate that this\nanalysis can predict the test loss accurately. Further, at any point during\ntraining, the residual predominantly lies in the subspace of the effective Gram\nmatrix with the smallest eigenvalues. This indicates that the training process\nis benign, i.e., it does not lead to significant deterioration of the\ngeneralization gap (which is zero at initialization). The alignment between the\neffective Gram matrix and the residual is different for different datasets and\narchitectures. The match/mismatch of the data and the architecture is primarily\nresponsible for good/bad generalization.", "published": "2025-04-23 06:24:42", "link": "http://arxiv.org/abs/2504.16450v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation", "abstract": "Retrieval-Augmented Generation (RAG) has gained prominence as an effective\nmethod for enhancing the generative capabilities of Large Language Models\n(LLMs) through the incorporation of external knowledge. However, the evaluation\nof RAG systems remains a challenge, due to the intricate interplay between\nretrieval and generation components. This limitation has resulted in a scarcity\nof benchmarks that facilitate a detailed, component-specific assessment. In\nthis work, we present MIRAGE, a Question Answering dataset specifically\ndesigned for RAG evaluation. MIRAGE consists of 7,560 curated instances mapped\nto a retrieval pool of 37,800 entries, enabling an efficient and precise\nevaluation of both retrieval and generation tasks. We also introduce novel\nevaluation metrics aimed at measuring RAG adaptability, encompassing dimensions\nsuch as noise vulnerability, context acceptability, context insensitivity, and\ncontext misinterpretation. Through comprehensive experiments across various\nretriever-LLM configurations, we provide new insights into the optimal\nalignment of model pairs and the nuanced dynamics within RAG systems. The\ndataset and evaluation code are publicly available, allowing for seamless\nintegration and customization in diverse research settings\\footnote{The MIRAGE\ncode and data are available at https://github.com/nlpai-lab/MIRAGE.", "published": "2025-04-23 23:05:46", "link": "http://arxiv.org/abs/2504.17137v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Steering the CensorShip: Uncovering Representation Vectors for LLM \"Thought\" Control", "abstract": "Large language models (LLMs) have transformed the way we access information.\nThese models are often tuned to refuse to comply with requests that are\nconsidered harmful and to produce responses that better align with the\npreferences of those who control the models. To understand how this\n\"censorship\" works. We use representation engineering techniques to study\nopen-weights safety-tuned models. We present a method for finding a\nrefusal--compliance vector that detects and controls the level of censorship in\nmodel outputs. We also analyze recent reasoning LLMs, distilled from\nDeepSeek-R1, and uncover an additional dimension of censorship through \"thought\nsuppression\". We show a similar approach can be used to find a vector that\nsuppresses the model's reasoning process, allowing us to remove censorship by\napplying the negative multiples of this vector", "published": "2025-04-23 22:47:30", "link": "http://arxiv.org/abs/2504.17130v1", "categories": ["cs.CL", "cs.CR", "cs.CY"], "primary_category": "cs.CL"}
{"title": "The Rise of Small Language Models in Healthcare: A Comprehensive Survey", "abstract": "Despite substantial progress in healthcare applications driven by large\nlanguage models (LLMs), growing concerns around data privacy, and limited\nresources; the small language models (SLMs) offer a scalable and clinically\nviable solution for efficient performance in resource-constrained environments\nfor next-generation healthcare informatics. Our comprehensive survey presents a\ntaxonomic framework to identify and categorize them for healthcare\nprofessionals and informaticians. The timeline of healthcare SLM contributions\nestablishes a foundational framework for analyzing models across three\ndimensions: NLP tasks, stakeholder roles, and the continuum of care. We present\na taxonomic framework to identify the architectural foundations for building\nmodels from scratch; adapting SLMs to clinical precision through prompting,\ninstruction fine-tuning, and reasoning; and accessibility and sustainability\nthrough compression techniques. Our primary objective is to offer a\ncomprehensive survey for healthcare professionals, introducing recent\ninnovations in model optimization and equipping them with curated resources to\nsupport future research and development in the field. Aiming to showcase the\ngroundbreaking advancements in SLMs for healthcare, we present a comprehensive\ncompilation of experimental results across widely studied NLP tasks in\nhealthcare to highlight the transformative potential of SLMs in healthcare. The\nupdated repository is available at Github", "published": "2025-04-23 22:02:25", "link": "http://arxiv.org/abs/2504.17119v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Co-CoT: A Prompt-Based Framework for Collaborative Chain-of-Thought Reasoning", "abstract": "Due to the proliferation of short-form content and the rapid adoption of AI,\nopportunities for deep, reflective thinking have significantly diminished,\nundermining users' critical thinking and reducing engagement with the reasoning\nbehind AI-generated outputs. To address this issue, we propose an Interactive\nChain-of-Thought (CoT) Framework that enhances human-centered explainability\nand responsible AI usage by making the model's inference process transparent,\nmodular, and user-editable. The framework decomposes reasoning into clearly\ndefined blocks that users can inspect, modify, and re-execute, encouraging\nactive cognitive engagement rather than passive consumption. It further\nintegrates a lightweight edit-adaptation mechanism inspired by preference\nlearning, allowing the system to align with diverse cognitive styles and user\nintentions. Ethical transparency is ensured through explicit metadata\ndisclosure, built-in bias checkpoint functionality, and privacy-preserving\nsafeguards. This work outlines the design principles and architecture necessary\nto promote critical engagement, responsible interaction, and inclusive\nadaptation in AI systems aimed at addressing complex societal challenges.", "published": "2025-04-23 20:48:09", "link": "http://arxiv.org/abs/2504.17091v1", "categories": ["cs.CL", "68T05"], "primary_category": "cs.CL"}
{"title": "How Individual Traits and Language Styles Shape Preferences In Open-ended User-LLM Interaction: A Preliminary Study", "abstract": "What makes an interaction with the LLM more preferable for the user? While it\nis intuitive to assume that information accuracy in the LLM's responses would\nbe one of the influential variables, recent studies have found that inaccurate\nLLM's responses could still be preferable when they are perceived to be more\nauthoritative, certain, well-articulated, or simply verbose. These variables\ninterestingly fall under the broader category of language style, implying that\nthe style in the LLM's responses might meaningfully influence users'\npreferences. This hypothesized dynamic could have double-edged consequences:\nenhancing the overall user experience while simultaneously increasing their\nsusceptibility to risks such as LLM's misinformation or hallucinations. In this\nshort paper, we present our preliminary studies in exploring this subject.\nThrough a series of exploratory and experimental user studies, we found that\nLLM's language style does indeed influence user's preferences, but how and\nwhich language styles influence the preference varied across different user\npopulations, and more interestingly, moderated by the user's very own\nindividual traits. As a preliminary work, the findings in our studies should be\ninterpreted with caution, particularly given the limitations in our samples,\nwhich still need wider demographic diversity and larger sample sizes. Our\nfuture directions will first aim to address these limitations, which would\nenable a more comprehensive joint effect analysis between the language style,\nindividual traits, and preferences, and further investigate the potential\ncausal relationship between and beyond these variables.", "published": "2025-04-23 20:14:03", "link": "http://arxiv.org/abs/2504.17083v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Agree to Disagree? A Meta-Evaluation of LLM Misgendering", "abstract": "Numerous methods have been proposed to measure LLM misgendering, including\nprobability-based evaluations (e.g., automatically with templatic sentences)\nand generation-based evaluations (e.g., with automatic heuristics or human\nvalidation). However, it has gone unexamined whether these evaluation methods\nhave convergent validity, that is, whether their results align. Therefore, we\nconduct a systematic meta-evaluation of these methods across three existing\ndatasets for LLM misgendering. We propose a method to transform each dataset to\nenable parallel probability- and generation-based evaluation. Then, by\nautomatically evaluating a suite of 6 models from 3 families, we find that\nthese methods can disagree with each other at the instance, dataset, and model\nlevels, conflicting on 20.2% of evaluation instances. Finally, with a human\nevaluation of 2400 LLM generations, we show that misgendering behaviour is\ncomplex and goes far beyond pronouns, which automatic evaluations are not\ncurrently designed to capture, suggesting essential disagreement with human\nevaluations. Based on our findings, we provide recommendations for future\nevaluations of LLM misgendering. Our results are also more widely relevant, as\nthey call into question broader methodological conventions in LLM evaluation,\nwhich often assume that different evaluation methods agree.", "published": "2025-04-23 19:52:02", "link": "http://arxiv.org/abs/2504.17075v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Do Words Reflect Beliefs? Evaluating Belief Depth in Large Language Models", "abstract": "Large Language Models (LLMs) are increasingly shaping political discourse,\nyet their responses often display inconsistency when subjected to scrutiny.\nWhile prior research has primarily categorized LLM outputs as left- or\nright-leaning to assess their political stances, a critical question remains:\nDo these responses reflect genuine internal beliefs or merely surface-level\nalignment with training data? To address this, we propose a novel framework for\nevaluating belief depth by analyzing (1) argumentative consistency and (2)\nuncertainty quantification. We evaluate 12 LLMs on 19 economic policies from\nthe Political Compass Test, challenging their belief stability with both\nsupportive and opposing arguments. Our analysis reveals that LLMs exhibit\ntopic-specific belief stability rather than a uniform ideological stance.\nNotably, up to 95% of left-leaning models' responses and 89% of right-leaning\nmodels' responses remain consistent under the challenge, enabling semantic\nentropy to achieve high accuracy (AUROC=0.78), effectively distinguishing\nbetween surface-level alignment from genuine belief. These findings call into\nquestion the assumption that LLMs maintain stable, human-like political\nideologies, emphasizing the importance of conducting topic-specific reliability\nassessments for real-world applications.", "published": "2025-04-23 19:00:39", "link": "http://arxiv.org/abs/2504.17052v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SCALAR: A Part-of-speech Tagger for Identifiers", "abstract": "The paper presents the Source Code Analysis and Lexical Annotation Runtime\n(SCALAR), a tool specialized for mapping (annotating) source code identifier\nnames to their corresponding part-of-speech tag sequence (grammar pattern).\nSCALAR's internal model is trained using scikit-learn's\nGradientBoostingClassifier in conjunction with a manually-curated oracle of\nidentifier names and their grammar patterns. This specializes the tagger to\nrecognize the unique structure of the natural language used by developers to\ncreate all types of identifiers (e.g., function names, variable names etc.).\nSCALAR's output is compared with a previous version of the tagger, as well as a\nmodern off-the-shelf part-of-speech tagger to show how it improves upon other\ntaggers' output for annotating identifiers. The code is available on Github", "published": "2025-04-23 18:36:38", "link": "http://arxiv.org/abs/2504.17038v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Optimizing LLMs for Italian: Reducing Token Fertility and Enhancing Efficiency Through Vocabulary Adaptation", "abstract": "The number of pretrained Large Language Models (LLMs) is increasing steadily,\nthough the majority are designed predominantly for the English language. While\nstate-of-the-art LLMs can handle other languages, due to language contamination\nor some degree of multilingual pretraining data, they are not optimized for\nnon-English languages, leading to inefficient encoding (high token \"fertility\")\nand slower inference speed. In this work, we thoroughly compare a variety of\nvocabulary adaptation techniques for optimizing English LLMs for the Italian\nlanguage, and put forward Semantic Alignment Vocabulary Adaptation (SAVA), a\nnovel method that leverages neural mapping for vocabulary substitution. SAVA\nachieves competitive performance across multiple downstream tasks, enhancing\ngrounded alignment strategies. We adapt two LLMs: Mistral-7b-v0.1, reducing\ntoken fertility by 25\\%, and Llama-3.1-8B, optimizing the vocabulary and\nreducing the number of parameters by 1 billion. We show that, following the\nadaptation of the vocabulary, these models can recover their performance with a\nrelatively limited stage of continual training on the target language. Finally,\nwe test the capabilities of the adapted models on various multi-choice and\ngenerative tasks.", "published": "2025-04-23 18:12:27", "link": "http://arxiv.org/abs/2504.17025v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "(Im)possibility of Automated Hallucination Detection in Large Language Models", "abstract": "Is automated hallucination detection possible? In this work, we introduce a\ntheoretical framework to analyze the feasibility of automatically detecting\nhallucinations produced by large language models (LLMs). Inspired by the\nclassical Gold-Angluin framework for language identification and its recent\nadaptation to language generation by Kleinberg and Mullainathan, we investigate\nwhether an algorithm, trained on examples drawn from an unknown target language\n$K$ (selected from a countable collection) and given access to an LLM, can\nreliably determine whether the LLM's outputs are correct or constitute\nhallucinations.\n  First, we establish an equivalence between hallucination detection and the\nclassical task of language identification. We prove that any hallucination\ndetection method can be converted into a language identification method, and\nconversely, algorithms solving language identification can be adapted for\nhallucination detection. Given the inherent difficulty of language\nidentification, this implies that hallucination detection is fundamentally\nimpossible for most language collections if the detector is trained using only\ncorrect examples from the target language.\n  Second, we show that the use of expert-labeled feedback, i.e., training the\ndetector with both positive examples (correct statements) and negative examples\n(explicitly labeled incorrect statements), dramatically changes this\nconclusion. Under this enriched training regime, automated hallucination\ndetection becomes possible for all countable language collections.\n  These results highlight the essential role of expert-labeled examples in\ntraining hallucination detectors and provide theoretical support for\nfeedback-based methods, such as reinforcement learning with human feedback\n(RLHF), which have proven critical for reliable LLM deployment.", "published": "2025-04-23 18:00:07", "link": "http://arxiv.org/abs/2504.17004v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Tokenization Matters: Improving Zero-Shot NER for Indic Languages", "abstract": "Tokenization is a critical component of Natural Language Processing (NLP),\nespecially for low resource languages, where subword segmentation influences\nvocabulary structure and downstream task accuracy. Although Byte Pair Encoding\n(BPE) is a standard tokenization method in multilingual language models, its\nsuitability for Named Entity Recognition (NER) in low resource Indic languages\nremains underexplored due to its limitations in handling morphological\ncomplexity. In this work, we systematically compare BPE, SentencePiece, and\nCharacter Level tokenization strategies using IndicBERT for NER tasks in low\nresource Indic languages like Assamese, Bengali, Marathi, and Odia, as well as\nextremely low resource Indic languages like Santali, Manipuri, and Sindhi. We\nassess both intrinsic linguistic properties tokenization efficiency, out of\nvocabulary (OOV) rates, and morphological preservation as well as extrinsic\ndownstream performance, including fine tuning and zero shot cross lingual\ntransfer.\n  Our experiments show that SentencePiece is a consistently better performing\napproach than BPE for NER in low resource Indic Languages, particularly in zero\nshot cross lingual settings, as it better preserves entity consistency. While\nBPE provides the most compact tokenization form, it is not capable of\ngeneralization because it misclassifies or even fails to recognize entity\nlabels when tested on unseen languages. In contrast, SentencePiece constitutes\na better linguistic structural preservation model, benefiting extremely low\nresource and morphologically rich Indic languages, such as Santali and\nManipuri, for superior entity recognition, as well as high generalization\nacross scripts, such as Sindhi, written in Arabic. The results point to\nSentencePiece as the more effective tokenization strategy for NER within\nmultilingual and low resource Indic NLP applications.", "published": "2025-04-23 17:28:38", "link": "http://arxiv.org/abs/2504.16977v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Scalable Permutation-Aware Modeling for Temporal Set Prediction", "abstract": "Temporal set prediction involves forecasting the elements that will appear in\nthe next set, given a sequence of prior sets, each containing a variable number\nof elements. Existing methods often rely on intricate architectures with\nsubstantial computational overhead, which hampers their scalability. In this\nwork, we introduce a novel and scalable framework that leverages\npermutation-equivariant and permutation-invariant transformations to\nefficiently model set dynamics. Our approach significantly reduces both\ntraining and inference time while maintaining competitive performance.\nExtensive experiments on multiple public benchmarks show that our method\nachieves results on par with or superior to state-of-the-art models across\nseveral evaluation metrics. These results underscore the effectiveness of our\nmodel in enabling efficient and scalable temporal set prediction.", "published": "2025-04-23 23:14:35", "link": "http://arxiv.org/abs/2504.17140v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Peer-Aware Cost Estimation in Nonlinear General-Sum Dynamic Games for Mutual Learning and Intent Inference", "abstract": "Human-robot interactions can be modeled as incomplete-information general-sum\ndynamic games since the objective functions of both agents are not explicitly\nknown to each other. However, solving for equilibrium policies for such games\npresents a major challenge, especially if the games involve nonlinear\nunderlying dynamics. To simplify the problem, existing work often assumes that\none agent is an expert with complete information about its peer, which can lead\nto biased estimates and failures in coordination. To address this challenge, we\npropose a nonlinear peer-aware cost estimation (N-PACE) algorithm for\ngeneral-sum dynamic games. In N-PACE, using iterative linear quadratic (LQ)\napproximation of the nonlinear general-sum game, each agent explicitly models\nthe learning dynamics of its peer agent while inferring their objective\nfunctions, leading to unbiased fast learning in inferring the unknown objective\nfunction of the peer agent, which is critical for task completion and safety\nassurance. Additionally, we demonstrate how N-PACE enables \\textbf{intent\ncommunication} in such multi-agent systems by explicitly modeling the peer's\nlearning dynamics.", "published": "2025-04-23 22:47:20", "link": "http://arxiv.org/abs/2504.17129v1", "categories": ["eess.SY", "cs.AI", "cs.GT", "cs.RO", "cs.SY", "93C41, 49N70, 49N90, 91A27"], "primary_category": "eess.SY"}
{"title": "Demonstration of an AI-driven workflow for dynamic x-ray spectroscopy", "abstract": "X-ray absorption near edge structure (XANES) spectroscopy is a powerful\ntechnique for characterizing the chemical state and symmetry of individual\nelements within materials, but requires collecting data at many energy points\nwhich can be time-consuming. While adaptive sampling methods exist for\nefficiently collecting spectroscopic data, they often lack domain-specific\nknowledge about XANES spectra structure. Here we demonstrate a\nknowledge-injected Bayesian optimization approach for adaptive XANES data\ncollection that incorporates understanding of spectral features like absorption\nedges and pre-edge peaks. We show this method accurately reconstructs the\nabsorption edge of XANES spectra using only 15-20% of the measurement points\ntypically needed for conventional sampling, while maintaining the ability to\ndetermine the x-ray energy of the sharp peak after absorption edge with errors\nless than 0.03 eV, the absorption edge with errors less than 0.1 eV; and\noverall root-mean-square errors less than 0.005 compared to compared to\ntraditionally sampled spectra. Our experiments on battery materials and\ncatalysts demonstrate the method's effectiveness for both static and dynamic\nXANES measurements, improving data collection efficiency and enabling better\ntime resolution for tracking chemical changes. This approach advances the\ndegree of automation in XANES experiments reducing the common errors of under-\nor over-sampling points in near the absorption edge and enabling dynamic\nexperiments that require high temporal resolution or limited measurement time.", "published": "2025-04-23 22:32:42", "link": "http://arxiv.org/abs/2504.17124v1", "categories": ["physics.app-ph", "cs.AI", "cs.CE", "cs.SY", "eess.SY"], "primary_category": "physics.app-ph"}
{"title": "Physiological neural representation for personalised tracer kinetic parameter estimation from dynamic PET", "abstract": "Dynamic positron emission tomography (PET) with [$^{18}$F]FDG enables\nnon-invasive quantification of glucose metabolism through kinetic analysis,\noften modelled by the two-tissue compartment model (TCKM). However, voxel-wise\nkinetic parameter estimation using conventional methods is computationally\nintensive and limited by spatial resolution. Deep neural networks (DNNs) offer\nan alternative but require large training datasets and significant\ncomputational resources. To address these limitations, we propose a\nphysiological neural representation based on implicit neural representations\n(INRs) for personalized kinetic parameter estimation. INRs, which learn\ncontinuous functions, allow for efficient, high-resolution parametric imaging\nwith reduced data requirements. Our method also integrates anatomical priors\nfrom a 3D CT foundation model to enhance robustness and precision in kinetic\nmodelling. We evaluate our approach on an [$^{18}$F]FDG dynamic PET/CT dataset\nand compare it to state-of-the-art DNNs. Results demonstrate superior spatial\nresolution, lower mean-squared error, and improved anatomical consistency,\nparticularly in tumour and highly vascularized regions. Our findings highlight\nthe potential of INRs for personalized, data-efficient tracer kinetic\nmodelling, enabling applications in tumour characterization, segmentation, and\nprognostic assessment.", "published": "2025-04-23 22:12:04", "link": "http://arxiv.org/abs/2504.17122v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Anatomy-constrained modelling of image-derived input functions in dynamic PET using multi-organ segmentation", "abstract": "Accurate kinetic analysis of [$^{18}$F]FDG distribution in dynamic positron\nemission tomography (PET) requires anatomically constrained modelling of\nimage-derived input functions (IDIFs). Traditionally, IDIFs are obtained from\nthe aorta, neglecting anatomical variations and complex vascular contributions.\nThis study proposes a multi-organ segmentation-based approach that integrates\nIDIFs from the aorta, portal vein, pulmonary artery, and ureters. Using\nhigh-resolution CT segmentations of the liver, lungs, kidneys, and bladder, we\nincorporate organ-specific blood supply sources to improve kinetic modelling.\nOur method was evaluated on dynamic [$^{18}$F]FDG PET data from nine patients,\nresulting in a mean squared error (MSE) reduction of $13.39\\%$ for the liver\nand $10.42\\%$ for the lungs. These initial results highlight the potential of\nmultiple IDIFs in improving anatomical modelling and fully leveraging dynamic\nPET imaging. This approach could facilitate the integration of tracer kinetic\nmodelling into clinical routine.", "published": "2025-04-23 21:47:05", "link": "http://arxiv.org/abs/2504.17114v1", "categories": ["eess.IV", "cs.AI", "cs.CV", "physics.med-ph"], "primary_category": "eess.IV"}
{"title": "Leveraging LLMs as Meta-Judges: A Multi-Agent Framework for Evaluating LLM Judgments", "abstract": "Large language models (LLMs) are being widely applied across various fields,\nbut as tasks become more complex, evaluating their responses is increasingly\nchallenging. Compared to human evaluators, the use of LLMs to support\nperformance evaluation offers a more efficient alternative. However, most\nstudies focus mainly on aligning LLMs' judgments with human preferences,\noverlooking the existence of biases and mistakes in human judgment.\nFurthermore, how to select suitable LLM judgments given multiple potential LLM\nresponses remains underexplored. To address these two aforementioned issues, we\npropose a three-stage meta-judge selection pipeline: 1) developing a\ncomprehensive rubric with GPT-4 and human experts, 2) using three advanced LLM\nagents to score judgments, and 3) applying a threshold to filter out\nlow-scoring judgments. Compared to methods using a single LLM as both judge and\nmeta-judge, our pipeline introduces multi-agent collaboration and a more\ncomprehensive rubric. Experimental results on the JudgeBench dataset show about\n15.55\\% improvement compared to raw judgments and about 8.37\\% improvement over\nthe single-agent baseline. Our work demonstrates the potential of LLMs as\nmeta-judges and lays the foundation for future research on constructing\npreference datasets for LLM-as-a-judge reinforcement learning.", "published": "2025-04-23 20:32:12", "link": "http://arxiv.org/abs/2504.17087v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Physics-guided and fabrication-aware inverse design of photonic devices using diffusion models", "abstract": "Designing free-form photonic devices is fundamentally challenging due to the\nvast number of possible geometries and the complex requirements of fabrication\nconstraints. Traditional inverse-design approaches--whether driven by human\nintuition, global optimization, or adjoint-based gradient methods--often\ninvolve intricate binarization and filtering steps, while recent deep learning\nstrategies demand prohibitively large numbers of simulations (10^5 to 10^6). To\novercome these limitations, we present AdjointDiffusion, a physics-guided\nframework that integrates adjoint sensitivity gradients into the sampling\nprocess of diffusion models. AdjointDiffusion begins by training a diffusion\nnetwork on a synthetic, fabrication-aware dataset of binary masks. During\ninference, we compute the adjoint gradient of a candidate structure and inject\nthis physics-based guidance at each denoising step, steering the generative\nprocess toward high figure-of-merit (FoM) solutions without additional\npost-processing. We demonstrate our method on two canonical photonic design\nproblems--a bent waveguide and a CMOS image sensor color router--and show that\nour method consistently outperforms state-of-the-art nonlinear optimizers (such\nas MMA and SLSQP) in both efficiency and manufacturability, while using orders\nof magnitude fewer simulations (approximately 2 x 10^2) than pure deep learning\napproaches (approximately 10^5 to 10^6). By eliminating complex binarization\nschedules and minimizing simulation overhead, AdjointDiffusion offers a\nstreamlined, simulation-efficient, and fabrication-aware pipeline for\nnext-generation photonic device design. Our open-source implementation is\navailable at https://github.com/dongjin-seo2020/AdjointDiffusion.", "published": "2025-04-23 19:54:33", "link": "http://arxiv.org/abs/2504.17077v1", "categories": ["physics.optics", "cs.AI", "physics.comp-ph"], "primary_category": "physics.optics"}
{"title": "Robo-Troj: Attacking LLM-based Task Planners", "abstract": "Robots need task planning methods to achieve goals that require more than\nindividual actions. Recently, large language models (LLMs) have demonstrated\nimpressive performance in task planning. LLMs can generate a step-by-step\nsolution using a description of actions and the goal. Despite the successes in\nLLM-based task planning, there is limited research studying the security\naspects of those systems. In this paper, we develop Robo-Troj, the first\nmulti-trigger backdoor attack for LLM-based task planners, which is the main\ncontribution of this work. As a multi-trigger attack, Robo-Troj is trained to\naccommodate the diversity of robot application domains. For instance, one can\nuse unique trigger words, e.g., \"herical\", to activate a specific malicious\nbehavior, e.g., cutting hand on a kitchen robot. In addition, we develop an\noptimization method for selecting the trigger words that are most effective.\nThrough demonstrating the vulnerability of LLM-based planners, we aim to\npromote the development of secured robot systems.", "published": "2025-04-23 19:39:16", "link": "http://arxiv.org/abs/2504.17070v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Distilling semantically aware orders for autoregressive image generation", "abstract": "Autoregressive patch-based image generation has recently shown competitive\nresults in terms of image quality and scalability. It can also be easily\nintegrated and scaled within Vision-Language models. Nevertheless,\nautoregressive models require a defined order for patch generation. While a\nnatural order based on the dictation of the words makes sense for text\ngeneration, there is no inherent generation order that exists for image\ngeneration. Traditionally, a raster-scan order (from top-left to bottom-right)\nguides autoregressive image generation models. In this paper, we argue that\nthis order is suboptimal, as it fails to respect the causality of the image\ncontent: for instance, when conditioned on a visual description of a sunset, an\nautoregressive model may generate clouds before the sun, even though the color\nof clouds should depend on the color of the sun and not the inverse. In this\nwork, we show that first by training a model to generate patches in\nany-given-order, we can infer both the content and the location (order) of each\npatch during generation. Secondly, we use these extracted orders to finetune\nthe any-given-order model to produce better-quality images. Through our\nexperiments, we show on two datasets that this new generation method produces\nbetter images than the traditional raster-scan approach, with similar training\ncosts and no extra annotations.", "published": "2025-04-23 19:33:58", "link": "http://arxiv.org/abs/2504.17069v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Statistical Guarantees in Synthetic Data through Conformal Adversarial Generation", "abstract": "The generation of high-quality synthetic data presents significant challenges\nin machine learning research, particularly regarding statistical fidelity and\nuncertainty quantification. Existing generative models produce compelling\nsynthetic samples but lack rigorous statistical guarantees about their relation\nto the underlying data distribution, limiting their applicability in critical\ndomains requiring robust error bounds. We address this fundamental limitation\nby presenting a novel framework that incorporates conformal prediction\nmethodologies into Generative Adversarial Networks (GANs). By integrating\nmultiple conformal prediction paradigms including Inductive Conformal\nPrediction (ICP), Mondrian Conformal Prediction, Cross-Conformal Prediction,\nand Venn-Abers Predictors, we establish distribution-free uncertainty\nquantification in generated samples. This approach, termed Conformalized GAN\n(cGAN), demonstrates enhanced calibration properties while maintaining the\ngenerative power of traditional GANs, producing synthetic data with provable\nstatistical guarantees. We provide rigorous mathematical proofs establishing\nfinite-sample validity guarantees and asymptotic efficiency properties,\nenabling the reliable application of synthetic data in high-stakes domains\nincluding healthcare, finance, and autonomous systems.", "published": "2025-04-23 19:07:44", "link": "http://arxiv.org/abs/2504.17058v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Approaches to Responsible Governance of GenAI in Organizations", "abstract": "The rapid evolution of Generative AI (GenAI) has introduced unprecedented\nopportunities while presenting complex challenges around ethics,\naccountability, and societal impact. This paper draws on a literature review,\nestablished governance frameworks, and industry roundtable discussions to\nidentify core principles for integrating responsible GenAI governance into\ndiverse organizational structures. Our objective is to provide actionable\nrecommendations for a balanced, risk-based governance approach that enables\nboth innovation and oversight. Findings emphasize the need for adaptable risk\nassessment tools, continuous monitoring practices, and cross-sector\ncollaboration to establish trustworthy GenAI. These insights provide a\nstructured foundation and Responsible GenAI Guide (ResAI) for organizations to\nalign GenAI initiatives with ethical, legal, and operational best practices.", "published": "2025-04-23 18:43:29", "link": "http://arxiv.org/abs/2504.17044v1", "categories": ["cs.CY", "cs.AI", "cs.LG"], "primary_category": "cs.CY"}
{"title": "DyMU: Dynamic Merging and Virtual Unmerging for Efficient VLMs", "abstract": "We present DyMU, an efficient, training-free framework that dynamically\nreduces the computational burden of vision-language models (VLMs) while\nmaintaining high task performance. Our approach comprises two key components.\nFirst, Dynamic Token Merging (DToMe) reduces the number of visual token\nembeddings by merging similar tokens based on image complexity, addressing the\ninherent inefficiency of fixed-length outputs in vision transformers. Second,\nVirtual Token Unmerging (VTU) simulates the expected token sequence for large\nlanguage models (LLMs) by efficiently reconstructing the attention dynamics of\na full sequence, thus preserving the downstream performance without additional\nfine-tuning. Unlike previous approaches, our method dynamically adapts token\ncompression to the content of the image and operates completely training-free,\nmaking it readily applicable to most state-of-the-art VLM architectures.\nExtensive experiments on image and video understanding tasks demonstrate that\nDyMU can reduce the average visual token count by 32%-85% while achieving\ncomparable performance to full-length models across diverse VLM architectures,\nincluding the recently popularized AnyRes-based visual encoders. Furthermore,\nthrough qualitative analyses, we demonstrate that DToMe effectively adapts\ntoken reduction based on image complexity and, unlike existing systems,\nprovides users more control over computational costs. Project page:\nhttps://mikewangwzhl.github.io/dymu/.", "published": "2025-04-23 18:38:18", "link": "http://arxiv.org/abs/2504.17040v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Fried Parameter Estimation from Single Wavefront Sensor Image with Artificial Neural Networks", "abstract": "Atmospheric turbulence degrades the quality of astronomical observations in\nground-based telescopes, leading to distorted and blurry images. Adaptive\nOptics (AO) systems are designed to counteract these effects, using atmospheric\nmeasurements captured by a wavefront sensor to make real-time corrections to\nthe incoming wavefront. The Fried parameter, r0, characterises the strength of\natmospheric turbulence and is an essential control parameter for optimising the\nperformance of AO systems and more recently sky profiling for Free Space\nOptical (FSO) communication channels. In this paper, we develop a novel\ndata-driven approach, adapting machine learning methods from computer vision\nfor Fried parameter estimation from a single Shack-Hartmann or pyramid\nwavefront sensor image. Using these data-driven methods, we present a detailed\nsimulation-based evaluation of our approach using the open-source COMPASS AO\nsimulation tool to evaluate both the Shack-Hartmann and pyramid wavefront\nsensors. Our evaluation is over a range of guide star magnitudes, and realistic\nnoise, atmospheric and instrument conditions. Remarkably, we are able to\ndevelop a single network-based estimator that is accurate in both open and\nclosed-loop AO configurations. Our method accurately estimates the Fried\nparameter from a single WFS image directly from AO telemetry to a few\nmillimetres. Our approach is suitable for real time control, exhibiting 0.83ms\nr0 inference times on retail NVIDIA RTX 3090 GPU hardware, and thereby\ndemonstrating a compelling economic solution for use in real-time instrument\ncontrol.", "published": "2025-04-23 18:16:07", "link": "http://arxiv.org/abs/2504.17029v1", "categories": ["astro-ph.IM", "cs.AI"], "primary_category": "astro-ph.IM"}
{"title": "Democracy of AI Numerical Weather Models: An Example of Global Forecasting with FourCastNetv2 Made by a University Research Lab Using GPU", "abstract": "This paper demonstrates the feasibility of democratizing AI-driven global\nweather forecasting models among university research groups by leveraging\nGraphics Processing Units (GPUs) and freely available AI models, such as\nNVIDIA's FourCastNetv2. FourCastNetv2 is an NVIDIA's advanced neural network\nfor weather prediction and is trained on a 73-channel subset of the European\nCentre for Medium-Range Weather Forecasts (ECMWF) Reanalysis v5 (ERA5) dataset\nat single levels and different pressure levels. Although the training\nspecifications for FourCastNetv2 are not released to the public, the training\ndocumentation of the model's first generation, FourCastNet, is available to all\nusers. The training had 64 A100 GPUs and took 16 hours to complete. Although\nNVIDIA's models offer significant reductions in both time and cost compared to\ntraditional Numerical Weather Prediction (NWP), reproducing published\nforecasting results presents ongoing challenges for resource-constrained\nuniversity research groups with limited GPU availability. We demonstrate both\n(i) leveraging FourCastNetv2 to create predictions through the designated\napplication programming interface (API) and (ii) utilizing NVIDIA hardware to\ntrain the original FourCastNet model. Further, this paper demonstrates the\ncapabilities and limitations of NVIDIA A100's for resource-limited research\ngroups in universities. We also explore data management, training efficiency,\nand model validation, highlighting the advantages and challenges of using\nlimited high-performance computing resources. Consequently, this paper and its\ncorresponding GitHub materials may serve as an initial guide for other\nuniversity research groups and courses related to machine learning, climate\nscience, and data science to develop research and education programs on AI\nweather forecasting, and hence help democratize the AI NWP in the digital\neconomy.", "published": "2025-04-23 18:15:31", "link": "http://arxiv.org/abs/2504.17028v1", "categories": ["cs.LG", "cs.AI", "physics.ao-ph"], "primary_category": "cs.LG"}
{"title": "What Makes for a Good Saliency Map? Comparing Strategies for Evaluating Saliency Maps in Explainable AI (XAI)", "abstract": "Saliency maps are a popular approach for explaining classifications of\n(convolutional) neural networks. However, it remains an open question as to how\nbest to evaluate salience maps, with three families of evaluation methods\ncommonly being used: subjective user measures, objective user measures, and\nmathematical metrics. We examine three of the most popular saliency map\napproaches (viz., LIME, Grad-CAM, and Guided Backpropagation) in a between\nsubject study (N=166) across these families of evaluation methods. We test 1)\nfor subjective measures, if the maps differ with respect to user trust and\nsatisfaction; 2) for objective measures, if the maps increase users' abilities\nand thus understanding of a model; 3) for mathematical metrics, which map\nachieves the best ratings across metrics; and 4) whether the mathematical\nmetrics can be associated with objective user measures. To our knowledge, our\nstudy is the first to compare several salience maps across all these evaluation\nmethods$-$with the finding that they do not agree in their assessment (i.e.,\nthere was no difference concerning trust and satisfaction, Grad-CAM improved\nusers' abilities best, and Guided Backpropagation had the most favorable\nmathematical metrics). Additionally, we show that some mathematical metrics\nwere associated with user understanding, although this relationship was often\ncounterintuitive. We discuss these findings in light of general debates\nconcerning the complementary use of user studies and mathematical metrics in\nthe evaluation of explainable AI (XAI) approaches.", "published": "2025-04-23 18:09:06", "link": "http://arxiv.org/abs/2504.17023v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Analyzing Value Functions of States in Parametric Markov Chains", "abstract": "Parametric Markov chains (pMC) are used to model probabilistic systems with\nunknown or partially known probabilities. Although (universal) pMC verification\nfor reachability properties is known to be coETR-complete, there have been\nefforts to approach it using potentially easier-to-check properties such as\nasking whether the pMC is monotonic in certain parameters. In this paper, we\nfirst reduce monotonicity to asking whether the reachability probability from a\ngiven state is never less than that of another given state. Recent results for\nthe latter property imply an efficient algorithm to collapse same-value\nequivalence classes, which in turn preserves verification results and\nmonotonicity. We implement our algorithm to collapse \"trivial\" equivalence\nclasses in the pMC and show empirical evidence for the following: First, the\ncollapse gives reductions in size for some existing benchmarks and significant\nreductions on some custom benchmarks; Second, the collapse speeds up existing\nalgorithms to check monotonicity and parameter lifting, and hence can be used\nas a fast pre-processing step in practice.", "published": "2025-04-23 18:06:41", "link": "http://arxiv.org/abs/2504.17020v1", "categories": ["cs.LO", "cs.AI"], "primary_category": "cs.LO"}
{"title": "Neural Theorem Proving: Generating and Structuring Proofs for Formal Verification", "abstract": "Formally verifying properties of software code has been a highly desirable\ntask, especially with the emergence of LLM-generated code. In the same vein,\nthey provide an interesting avenue for the exploration of formal verification\nand mechanistic interpretability. Since the introduction of code-specific\nmodels, despite their successes in generating code in Lean4 and Isabelle, the\ntask of generalized theorem proving still remains far from being fully solved\nand will be a benchmark for reasoning capability in LLMs. In this work, we\nintroduce a framework that generates whole proofs in a formal language to be\nused within systems that utilize the power of built-in tactics and\noff-the-shelf automated theorem provers. Our framework includes 3 components:\ngenerating natural language statements of the code to be verified, an LLM that\ngenerates formal proofs for the given statement, and a module employing\nheuristics for building the final proof. To train the LLM, we employ a 2-stage\nfine-tuning process, where we first use SFT-based training to enable the model\nto generate syntactically correct Isabelle code and then RL-based training that\nencourages the model to generate proofs verified by a theorem prover. We\nvalidate our framework using the miniF2F-test benchmark and the Isabelle proof\nassistant and design a use case to verify the correctness of the AWS S3 bucket\naccess policy code. We also curate a dataset based on the\nFVEL\\textsubscript{\\textnormal{ER}} dataset for future training tasks.", "published": "2025-04-23 18:04:38", "link": "http://arxiv.org/abs/2504.17017v1", "categories": ["cs.AI", "cs.FL", "cs.LG", "cs.LO"], "primary_category": "cs.AI"}
{"title": "A Systematic Approach to Design Real-World Human-in-the-Loop Deep Reinforcement Learning: Salient Features, Challenges and Trade-offs", "abstract": "With the growing popularity of deep reinforcement learning (DRL),\nhuman-in-the-loop (HITL) approach has the potential to revolutionize the way we\napproach decision-making problems and create new opportunities for human-AI\ncollaboration. In this article, we introduce a novel multi-layered hierarchical\nHITL DRL algorithm that comprises three types of learning: self learning,\nimitation learning and transfer learning. In addition, we consider three forms\nof human inputs: reward, action and demonstration. Furthermore, we discuss main\nchallenges, trade-offs and advantages of HITL in solving complex problems and\nhow human information can be integrated in the AI solution systematically. To\nverify our technical results, we present a real-world unmanned aerial vehicles\n(UAV) problem wherein a number of enemy drones attack a restricted area. The\nobjective is to design a scalable HITL DRL algorithm for ally drones to\nneutralize the enemy drones before they reach the area. To this end, we first\nimplement our solution using an award-winning open-source HITL software called\nCogment. We then demonstrate several interesting results such as (a) HITL leads\nto faster training and higher performance, (b) advice acts as a guiding\ndirection for gradient methods and lowers variance, and (c) the amount of\nadvice should neither be too large nor too small to avoid over-training and\nunder-training. Finally, we illustrate the role of human-AI cooperation in\nsolving two real-world complex scenarios, i.e., overloaded and decoy attacks.", "published": "2025-04-23 18:00:08", "link": "http://arxiv.org/abs/2504.17006v1", "categories": ["cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Automating tumor-infiltrating lymphocyte assessment in breast cancer histopathology images using QuPath: a transparent and accessible machine learning pipeline", "abstract": "In this study, we built an end-to-end tumor-infiltrating lymphocytes (TILs)\nassessment pipeline within QuPath, demonstrating the potential of easily\naccessible tools to perform complex tasks in a fully automatic fashion. First,\nwe trained a pixel classifier to segment tumor, tumor-associated stroma, and\nother tissue compartments in breast cancer H&E-stained whole-slide images (WSI)\nto isolate tumor-associated stroma for subsequent analysis. Next, we applied a\npre-trained StarDist deep learning model in QuPath for cell detection and used\nthe extracted cell features to train a binary classifier distinguishing TILs\nfrom other cells. To evaluate our TILs assessment pipeline, we calculated the\nTIL density in each WSI and categorized them as low, medium, or high TIL\nlevels. Our pipeline was evaluated against pathologist-assigned TIL scores,\nachieving a Cohen's kappa of 0.71 on the external test set, corroborating\nprevious research findings. These results confirm that existing software can\noffer a practical solution for the assessment of TILs in H&E-stained WSIs of\nbreast cancer.", "published": "2025-04-23 17:54:59", "link": "http://arxiv.org/abs/2504.16979v1", "categories": ["q-bio.QM", "cs.AI", "cs.CV"], "primary_category": "q-bio.QM"}
{"title": "Latent Video Dataset Distillation", "abstract": "Dataset distillation has demonstrated remarkable effectiveness in\nhigh-compression scenarios for image datasets. While video datasets inherently\ncontain greater redundancy, existing video dataset distillation methods\nprimarily focus on compression in the pixel space, overlooking advances in the\nlatent space that have been widely adopted in modern text-to-image and\ntext-to-video models. In this work, we bridge this gap by introducing a novel\nvideo dataset distillation approach that operates in the latent space using a\nstate-of-the-art variational encoder. Furthermore, we employ a diversity-aware\ndata selection strategy to select both representative and diverse samples.\nAdditionally, we introduce a simple, training-free method to further compress\nthe distilled latent dataset. By combining these techniques, our approach\nachieves a new state-of-the-art performance in dataset distillation,\noutperforming prior methods on all datasets, e.g. on HMDB51 IPC 1, we achieve a\n2.6% performance increase; on MiniUCF IPC 5, we achieve a 7.8% performance\nincrease.", "published": "2025-04-23 22:50:39", "link": "http://arxiv.org/abs/2504.17132v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Transferring Spatial Filters via Tangent Space Alignment in Motor Imagery BCIs", "abstract": "We propose a method to improve subject transfer in motor imagery BCIs by\naligning covariance matrices on a Riemannian manifold, followed by computing a\nnew common spatial patterns (CSP) based spatial filter. We explore various ways\nto integrate information from multiple subjects and show improved performance\ncompared to standard CSP. Across three datasets, our method shows marginal\nimprovements over standard CSP; however, when training data are limited, the\nimprovements become more significant.", "published": "2025-04-23 21:45:26", "link": "http://arxiv.org/abs/2504.17111v1", "categories": ["cs.CV", "q-bio.QM"], "primary_category": "cs.CV"}
{"title": "Scene-Aware Location Modeling for Data Augmentation in Automotive Object Detection", "abstract": "Generative image models are increasingly being used for training data\naugmentation in vision tasks. In the context of automotive object detection,\nmethods usually focus on producing augmented frames that look as realistic as\npossible, for example by replacing real objects with generated ones. Others try\nto maximize the diversity of augmented frames, for example by pasting lots of\ngenerated objects onto existing backgrounds. Both perspectives pay little\nattention to the locations of objects in the scene. Frame layouts are either\nreused with little or no modification, or they are random and disregard realism\nentirely. In this work, we argue that optimal data augmentation should also\ninclude realistic augmentation of layouts. We introduce a scene-aware\nprobabilistic location model that predicts where new objects can realistically\nbe placed in an existing scene. By then inpainting objects in these locations\nwith a generative model, we obtain much stronger augmentation performance than\nexisting approaches. We set a new state of the art for generative data\naugmentation on two automotive object detection tasks, achieving up to\n$2.8\\times$ higher gains than the best competing approach ($+1.4$ vs. $+0.5$\nmAP boost). We also demonstrate significant improvements for instance\nsegmentation.", "published": "2025-04-23 19:52:47", "link": "http://arxiv.org/abs/2504.17076v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PPS-Ctrl: Controllable Sim-to-Real Translation for Colonoscopy Depth Estimation", "abstract": "Accurate depth estimation enhances endoscopy navigation and diagnostics, but\nobtaining ground-truth depth in clinical settings is challenging. Synthetic\ndatasets are often used for training, yet the domain gap limits generalization\nto real data. We propose a novel image-to-image translation framework that\npreserves structure while generating realistic textures from clinical data. Our\nkey innovation integrates Stable Diffusion with ControlNet, conditioned on a\nlatent representation extracted from a Per-Pixel Shading (PPS) map. PPS\ncaptures surface lighting effects, providing a stronger structural constraint\nthan depth maps. Experiments show our approach produces more realistic\ntranslations and improves depth estimation over GAN-based MI-CycleGAN. Our code\nis publicly accessible at https://github.com/anaxqx/PPS-Ctrl.", "published": "2025-04-23 19:28:58", "link": "http://arxiv.org/abs/2504.17067v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ePBR: Extended PBR Materials in Image Synthesis", "abstract": "Realistic indoor or outdoor image synthesis is a core challenge in computer\nvision and graphics. The learning-based approach is easy to use but lacks\nphysical consistency, while traditional Physically Based Rendering (PBR) offers\nhigh realism but is computationally expensive. Intrinsic image representation\noffers a well-balanced trade-off, decomposing images into fundamental\ncomponents (intrinsic channels) such as geometry, materials, and illumination\nfor controllable synthesis. However, existing PBR materials struggle with\ncomplex surface models, particularly high-specular and transparent surfaces. In\nthis work, we extend intrinsic image representations to incorporate both\nreflection and transmission properties, enabling the synthesis of transparent\nmaterials such as glass and windows. We propose an explicit intrinsic\ncompositing framework that provides deterministic, interpretable image\nsynthesis. With the Extended PBR (ePBR) Materials, we can effectively edit the\nmaterials with precise controls.", "published": "2025-04-23 19:15:42", "link": "http://arxiv.org/abs/2504.17062v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Dense Air Pollution Estimation from Sparse in-situ Measurements and Satellite Data", "abstract": "This paper addresses the critical environmental challenge of estimating\nambient Nitrogen Dioxide (NO$_2$) concentrations, a key issue in public health\nand environmental policy. Existing methods for satellite-based air pollution\nestimation model the relationship between satellite and in-situ measurements at\nselect point locations. While these approaches have advanced our ability to\nprovide air quality estimations on a global scale, they come with inherent\nlimitations. The most notable limitation is the computational intensity\nrequired for generating comprehensive estimates over extensive areas. Motivated\nby these limitations, this study introduces a novel dense estimation technique.\nOur approach seeks to balance the accuracy of high-resolution estimates with\nthe practicality of computational constraints, thereby enabling efficient and\nscalable global environmental assessment. By utilizing a uniformly random\noffset sampling strategy, our method disperses the ground truth data pixel\nlocation evenly across a larger patch. At inference, the dense estimation\nmethod can then generate a grid of estimates in a single step, significantly\nreducing the computational resources required to provide estimates for larger\nareas. Notably, our approach also surpasses the results of existing point-wise\nmethods by a significant margin of $9.45\\%$, achieving a Mean Absolute Error\n(MAE) of $4.98\\ \\mu\\text{g}/\\text{m}^3$. This demonstrates both high accuracy\nand computational efficiency, highlighting the applicability of our method for\nglobal environmental assessment. Furthermore, we showcase the method's\nadaptability and robustness by applying it to diverse geographic regions. Our\nmethod offers a viable solution to the computational challenges of large-scale\nenvironmental monitoring.", "published": "2025-04-23 18:38:16", "link": "http://arxiv.org/abs/2504.17039v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Seeing The Words: Evaluating AI-generated Biblical Art", "abstract": "The past years witnessed a significant amount of Artificial Intelligence (AI)\ntools that can generate images from texts. This triggers the discussion of\nwhether AI can generate accurate images using text from the Bible with respect\nto the corresponding biblical contexts and backgrounds. Despite some existing\nattempts at a small scale, little work has been done to systematically evaluate\nthese generated images. In this work, we provide a large dataset of over 7K\nimages using biblical text as prompts. These images were evaluated with\nmultiple neural network-based tools on various aspects. We provide an\nassessment of accuracy and some analysis from the perspective of religion and\naesthetics. Finally, we discuss the use of the generated images and reflect on\nthe performance of the AI generators.", "published": "2025-04-23 16:11:55", "link": "http://arxiv.org/abs/2504.16974v1", "categories": ["cs.CY", "cs.CV", "cs.MM", "I.4.8; I.4.0; I.3.3; I.3.0"], "primary_category": "cs.CY"}
{"title": "Unsupervised Time-Series Signal Analysis with Autoencoders and Vision Transformers: A Review of Architectures and Applications", "abstract": "The rapid growth of unlabeled time-series data in domains such as wireless\ncommunications, radar, biomedical engineering, and the Internet of Things (IoT)\nhas driven advancements in unsupervised learning. This review synthesizes\nrecent progress in applying autoencoders and vision transformers for\nunsupervised signal analysis, focusing on their architectures, applications,\nand emerging trends. We explore how these models enable feature extraction,\nanomaly detection, and classification across diverse signal types, including\nelectrocardiograms, radar waveforms, and IoT sensor data. The review highlights\nthe strengths of hybrid architectures and self-supervised learning, while\nidentifying challenges in interpretability, scalability, and domain\ngeneralization. By bridging methodological innovations and practical\napplications, this work offers a roadmap for developing robust, adaptive models\nfor signal intelligence.", "published": "2025-04-23 15:19:12", "link": "http://arxiv.org/abs/2504.16972v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Parallelizing the Approximate Minimum Degree Ordering Algorithm: Strategies and Evaluation", "abstract": "The approximate minimum degree algorithm is widely used before numerical\nfactorization to reduce fill-in for sparse matrices. While considerable\nattention has been given to the numerical factorization process, less focus has\nbeen placed on parallelizing the approximate minimum degree algorithm itself.\nIn this paper, we explore different parallelization strategies, and introduce a\nnovel parallel framework that leverages multiple elimination on distance-2\nindependent sets. Our evaluation shows that parallelism within individual\nelimination steps is limited due to low computational workload and significant\nmemory contention. In contrast, our proposed framework overcomes these\nchallenges by parallelizing the work across elimination steps. To the best of\nour knowledge, our implementation is the first scalable shared memory\nimplementation of the approximate minimum degree algorithm. Experimental\nresults show that we achieve up to an 8.30x speedup using 64 threads over the\nstate-of-the-art sequential implementation in SuiteSparse.", "published": "2025-04-23 21:09:32", "link": "http://arxiv.org/abs/2504.17097v1", "categories": ["cs.DC", "cs.DM", "cs.DS"], "primary_category": "cs.DC"}
{"title": "Dynamic Superblock Pruning for Fast Learned Sparse Retrieval", "abstract": "This paper proposes superblock pruning (SP) during top-k online document\nretrieval for learned sparse representations. SP structures the sparse index as\na set of superblocks on a sequence of document blocks and conducts a\nsuperblock-level selection to decide if some superblocks can be pruned before\nvisiting their child blocks. SP generalizes the previous flat block or\ncluster-based pruning, allowing the early detection of groups of documents that\ncannot or are less likely to appear in the final top-k list. SP can accelerate\nsparse retrieval in a rank-safe or approximate manner under a high-relevance\ncompetitiveness constraint. Our experiments show that the proposed scheme\nsignificantly outperforms state-of-the-art baselines on MS MARCO passages on a\nsingle-threaded CPU.", "published": "2025-04-23 18:46:08", "link": "http://arxiv.org/abs/2504.17045v1", "categories": ["cs.IR", "H.3.3"], "primary_category": "cs.IR"}
{"title": "Path Integral Methods for Synthesizing and Preventing Stealthy Attacks in Nonlinear Cyber-Physical Systems", "abstract": "This paper studies the synthesis and mitigation of stealthy attacks in\nnonlinear cyber-physical systems (CPS). To quantify stealthiness, we employ the\nKullback-Leibler (KL) divergence, a measure rooted in hypothesis testing and\ndetection theory, which captures the trade-off between an attacker's desire to\nremain stealthy and her goal of degrading system performance. First, we\nsynthesize the worst-case stealthy attack in nonlinear CPS using the path\nintegral approach. Second, we consider how a controller can mitigate the impact\nof such stealthy attacks by formulating a minimax KL control problem, yielding\na zero-sum game between the attacker and the controller. Again, we leverage a\npath integral-based solution that computes saddle-point policies for both\nplayers through Monte Carlo simulations. We validate our approach using\nunicycle navigation and cruise control problems, demonstrating how an attacker\ncan covertly drive the system into unsafe regions, and how the controller can\nadapt her policy to combat the worst-case attacks.", "published": "2025-04-23 22:01:29", "link": "http://arxiv.org/abs/2504.17118v1", "categories": ["eess.SY", "cs.IT", "cs.SY", "math.IT"], "primary_category": "eess.SY"}
{"title": "Relationship between H\u00f6lder Divergence and Functional Density Power Divergence: Intersection and Generalization", "abstract": "In this study, we discuss the relationship between two families of\ndensity-power-based divergences with functional degrees of freedom -- the\nH\\\"{o}lder divergence and the functional density power divergence (FDPD) --\nbased on their intersection and generalization. These divergence families\ninclude the density power divergence and the $\\gamma$-divergence as special\ncases. First, we prove that the intersection of the H\\\"{o}lder divergence and\nthe FDPD is limited to a general divergence family introduced by Jones et al.\n(Biometrika, 2001). Subsequently, motivated by the fact that H\\\"{o}lder's\ninequality is used in the proofs of nonnegativity for both the H\\\"{o}lder\ndivergence and the FDPD, we define a generalized divergence family, referred to\nas the $\\xi$-H\\\"{o}lder divergence. The nonnegativity of the $\\xi$-H\\\"{o}lder\ndivergence is established through a combination of the inequalities used to\nprove the nonnegativity of the H\\\"{o}lder divergence and the FDPD. Furthermore,\nwe derive an inequality between the composite scoring rules corresponding to\ndifferent FDPDs based on the $\\xi$-H\\\"{o}lder divergence. Finally, we prove\nthat imposing the mathematical structure of the H\\\"{o}lder score on a composite\nscoring rule results in the $\\xi$-H\\\"{o}lder divergence.", "published": "2025-04-23 18:00:13", "link": "http://arxiv.org/abs/2504.17008v1", "categories": ["cs.IT", "math.IT", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.IT"}
{"title": "A Coding-Enhanced Jamming Approach for Secure Semantic Communication over Wiretap Channels", "abstract": "As semantic communication (SemCom) gains increasing attention as a novel\ncommunication paradigm, ensuring the security of transmitted semantic\ninformation over open wireless channels becomes crucial. Existing secure SemCom\nsolutions often lack explicit control over security. To address this, we\npropose a coding-enhanced jamming approach for secure SemCom over wiretap\nchannels. This approach integrates deep joint source and channel coding\n(DeepJSCC) with neural network-based digital modulation, enabling controlled\njamming through two-layer superposition coding. The outer constellation\nsequence encodes the source image, while the inner constellation sequence,\nderived from a secret image, acts as the jamming signal. By minimizing the\nmutual information between the outer and inner constellation sequences, the\njamming effect is enhanced. The jamming signal is superposed on the outer\nconstellation sequence, preventing the eavesdropper from recovering the source\nimage. The power allocation coefficient (PAC) in the superposition coding can\nbe adjusted to control system security. Experiments show that our approach\nmatches existing methods in security while significantly improving\nreconstruction performance across varying channel signal-to-noise ratios (SNRs)\nand compression ratios.", "published": "2025-04-23 05:45:36", "link": "http://arxiv.org/abs/2504.16960v1", "categories": ["cs.IT", "eess.IV", "math.IT"], "primary_category": "cs.IT"}
{"title": "Reinforcement learning framework for the mechanical design of microelectronic components under multiphysics constraints", "abstract": "This study focuses on the development of reinforcement learning based\ntechniques for the design of microelectronic components under multiphysics\nconstraints. While traditional design approaches based on global optimization\napproaches are effective when dealing with a small number of design parameters,\nas the complexity of the solution space and of the constraints increases\ndifferent techniques are needed. This is an important reason that makes the\ndesign and optimization of microelectronic components (characterized by large\nsolution space and multiphysics constraints) very challenging for traditional\nmethods. By taking as prototypical elements an application-specific integrated\ncircuit (ASIC) and a heterogeneously integrated (HI) interposer, we develop and\nnumerically test an optimization framework based on reinforcement learning\n(RL). More specifically, we consider the optimization of the bonded\ninterconnect geometry for an ASIC chip as well as the placement of components\non a HI interposer while satisfying thermoelastic and design constraints. This\nplacement problem is particularly interesting because it features a\nhigh-dimensional solution space.", "published": "2025-04-23 23:20:44", "link": "http://arxiv.org/abs/2504.17142v1", "categories": ["physics.comp-ph", "cs.CE", "cs.LG"], "primary_category": "physics.comp-ph"}
{"title": "PACE: A Framework for Learning and Control in Linear Incomplete-Information Differential Games", "abstract": "In this paper, we address the problem of a two-player linear quadratic\ndifferential game with incomplete information, a scenario commonly encountered\nin multi-agent control, human-robot interaction (HRI), and approximation\nmethods for solving general-sum differential games. While solutions to such\nlinear differential games are typically obtained through coupled Riccati\nequations, the complexity increases when agents have incomplete information,\nparticularly when neither is aware of the other's cost function. To tackle this\nchallenge, we propose a model-based Peer-Aware Cost Estimation (PACE) framework\nfor learning the cost parameters of the other agent. In PACE, each agent treats\nits peer as a learning agent rather than a stationary optimal agent, models\ntheir learning dynamics, and leverages this dynamic to infer the cost function\nparameters of the other agent. This approach enables agents to infer each\nother's objective function in real time based solely on their previous state\nobservations and dynamically adapt their control policies. Furthermore, we\nprovide a theoretical guarantee for the convergence of parameter estimation and\nthe stability of system states in PACE. Additionally, in our numerical studies,\nwe demonstrate how modeling the learning dynamics of the other agent benefits\nPACE, compared to approaches that approximate the other agent as having\ncomplete information, particularly in terms of stability and convergence speed.", "published": "2025-04-23 22:43:41", "link": "http://arxiv.org/abs/2504.17128v1", "categories": ["eess.SY", "cs.LG", "cs.MA", "cs.SY", "93C41, 49N70, 49N90, 91A27"], "primary_category": "eess.SY"}
{"title": "Physics-informed features in supervised machine learning", "abstract": "Supervised machine learning involves approximating an unknown functional\nrelationship from a limited dataset of features and corresponding labels. The\nclassical approach to feature-based machine learning typically relies on\napplying linear regression to standardized features, without considering their\nphysical meaning. This may limit model explainability, particularly in\nscientific applications. This study proposes a physics-informed approach to\nfeature-based machine learning that constructs non-linear feature maps informed\nby physical laws and dimensional analysis. These maps enhance model\ninterpretability and, when physical laws are unknown, allow for the\nidentification of relevant mechanisms through feature ranking. The method aims\nto improve both predictive performance in regression tasks and classification\nskill scores by integrating domain knowledge into the learning process, while\nalso enabling the potential discovery of new physical equations within the\ncontext of explainable machine learning.", "published": "2025-04-23 21:45:49", "link": "http://arxiv.org/abs/2504.17112v1", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA", "68Q32, 62J07, 65J20"], "primary_category": "stat.ML"}
{"title": "Discovering the Precursors of Traffic Breakdowns Using Spatiotemporal Graph Attribution Networks", "abstract": "Understanding and predicting the precursors of traffic breakdowns is critical\nfor improving road safety and traffic flow management. This paper presents a\nnovel approach combining spatiotemporal graph neural networks (ST-GNNs) with\nShapley values to identify and interpret traffic breakdown precursors. By\nextending Shapley explanation methods to a spatiotemporal setting, our proposed\nmethod bridges the gap between black-box neural network predictions and\ninterpretable causes. We demonstrate the method on the Interstate-24 data, and\nidentify that road topology and abrupt braking are major factors that lead to\ntraffic breakdowns.", "published": "2025-04-23 21:40:23", "link": "http://arxiv.org/abs/2504.17109v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Neural Contraction Metrics with Formal Guarantees for Discrete-Time Nonlinear Dynamical Systems", "abstract": "Contraction metrics are crucial in control theory because they provide a\npowerful framework for analyzing stability, robustness, and convergence of\nvarious dynamical systems. However, identifying these metrics for complex\nnonlinear systems remains an open challenge due to the lack of scalable and\neffective tools. This paper explores the approach of learning verifiable\ncontraction metrics parametrized as neural networks (NNs) for discrete-time\nnonlinear dynamical systems. While prior works on formal verification of\ncontraction metrics for general nonlinear systems have focused on convex\noptimization methods (e.g. linear matrix inequalities, etc) under the\nassumption of continuously differentiable dynamics, the growing prevalence of\nNN-based controllers, often utilizing ReLU activations, introduces challenges\ndue to the non-smooth nature of the resulting closed-loop dynamics. To bridge\nthis gap, we establish a new sufficient condition for establishing formal\nneural contraction metrics for general discrete-time nonlinear systems assuming\nonly the continuity of the dynamics. We show that from a computational\nperspective, our sufficient condition can be efficiently verified using the\nstate-of-the-art neural network verifier $\\alpha,\\!\\beta$-CROWN, which scales\nup non-convex neural network verification via novel integration of symbolic\nlinear bound propagation and branch-and-bound. Built upon our analysis tool, we\nfurther develop a learning method for synthesizing neural contraction metrics\nfrom sampled data. Finally, our approach is validated through the successful\nsynthesis and verification of NN contraction metrics for various nonlinear\nexamples.", "published": "2025-04-23 21:27:32", "link": "http://arxiv.org/abs/2504.17102v1", "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "math.OC"}
{"title": "GeoRDF2Vec Learning Location-Aware Entity Representations in Knowledge Graphs", "abstract": "Many knowledge graphs contain a substantial number of spatial entities, such\nas cities, buildings, and natural landmarks. For many of these entities, exact\ngeometries are stored within the knowledge graphs. However, most existing\napproaches for learning entity representations do not take these geometries\ninto account. In this paper, we introduce a variant of RDF2Vec that\nincorporates geometric information to learn location-aware embeddings of\nentities. Our approach expands different nodes by flooding the graph from\ngeographic nodes, ensuring that each reachable node is considered. Based on the\nresulting flooded graph, we apply a modified version of RDF2Vec that biases\ngraph walks using spatial weights. Through evaluations on multiple benchmark\ndatasets, we demonstrate that our approach outperforms both non-location-aware\nRDF2Vec and GeoTransE.", "published": "2025-04-23 21:17:31", "link": "http://arxiv.org/abs/2504.17099v1", "categories": ["cs.LG", "cs.SI"], "primary_category": "cs.LG"}
{"title": "A Novel Hybrid Approach Using an Attention-Based Transformer + GRU Model for Predicting Cryptocurrency Prices", "abstract": "In this article, we introduce a novel deep learning hybrid model that\nintegrates attention Transformer and Gated Recurrent Unit (GRU) architectures\nto improve the accuracy of cryptocurrency price predictions. By combining the\nTransformer's strength in capturing long-range patterns with the GRU's ability\nto model short-term and sequential trends, the hybrid model provides a\nwell-rounded approach to time series forecasting. We apply the model to predict\nthe daily closing prices of Bitcoin and Ethereum based on historical data that\ninclude past prices, trading volumes, and the Fear and Greed index. We evaluate\nthe performance of our proposed model by comparing it with four other machine\nlearning models: two are non-sequential feedforward models: Radial Basis\nFunction Network (RBFN) and General Regression Neural Network (GRNN), and two\nare bidirectional sequential memory-based models: Bidirectional Long-Short-Term\nMemory (BiLSTM) and Bidirectional Gated Recurrent Unit (BiGRU). The performance\nof the model is assessed using several metrics, including Mean Squared Error\n(MSE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and Mean\nAbsolute Percentage Error (MAPE), along with statistical validation through the\nnonparametric Friedman test followed by a post hoc Wilcoxon signed rank test.\nThe results demonstrate that our hybrid model consistently achieves superior\naccuracy, highlighting its effectiveness for financial prediction tasks. These\nfindings provide valuable insights for improving real-time decision making in\ncryptocurrency markets and support the growing use of hybrid deep learning\nmodels in financial analytics.", "published": "2025-04-23 20:00:47", "link": "http://arxiv.org/abs/2504.17079v1", "categories": ["cs.LG", "stat.AP"], "primary_category": "cs.LG"}
{"title": "Conditional Diffusion-Based Retrieval of Atmospheric CO2 from Earth Observing Spectroscopy", "abstract": "Satellite-based estimates of greenhouse gas (GHG) properties from\nobservations of reflected solar spectra are integral for understanding and\nmonitoring complex terrestrial systems and their impact on the carbon cycle due\nto their near global coverage. Known as retrieval, making GHG concentration\nestimations from these observations is a non-linear Bayesian inverse problem,\nwhich is operationally solved using a computationally expensive algorithm\ncalled Optimal Estimation (OE), providing a Gaussian approximation to a\nnon-Gaussian posterior. This leads to issues in solver algorithm convergence,\nand to unrealistically confident uncertainty estimates for the retrieved\nquantities. Upcoming satellite missions will provide orders of magnitude more\ndata than the current constellation of GHG observers. Development of fast and\naccurate retrieval algorithms with robust uncertainty quantification is\ncritical. Doing so stands to provide substantial climate impact of moving\ntowards the goal of near continuous real-time global monitoring of carbon\nsources and sinks which is essential for policy making. To achieve this goal,\nwe propose a diffusion-based approach to flexibly retrieve a Gaussian or\nnon-Gaussian posterior, for NASA's Orbiting Carbon Observatory-2 spectrometer,\nwhile providing a substantial computational speed-up over the current\noperational state-of-the-art.", "published": "2025-04-23 19:46:18", "link": "http://arxiv.org/abs/2504.17074v1", "categories": ["cs.LG", "astro-ph.IM"], "primary_category": "cs.LG"}
{"title": "Sparse Phased Array Optimization Using Deep Learning", "abstract": "Antenna arrays are widely used in wireless communication, radar systems,\nradio astronomy, and military defense to enhance signal strength, directivity,\nand interference suppression. We introduce a deep learning-based optimization\napproach that enhances the design of sparse phased arrays by reducing grating\nlobes. This approach begins by generating sparse array configurations to\naddress the non-convex challenges and extensive degrees of freedom inherent in\narray design. We use neural networks to approximate the non-convex cost\nfunction that estimates the energy ratio between the main and side lobes. This\ndifferentiable approximation facilitates cost function minimization through\ngradient descent, optimizing the antenna elements' coordinates and leading to\nan improved layout. Additionally, we incorporate a tailored penalty mechanism\nthat includes various physical and design constraints into the optimization\nprocess, enhancing its robustness and practical applicability. We demonstrate\nthe effectiveness of our method by applying it to the ten array configurations\nwith the lowest initial costs, achieving further cost reductions ranging from\n411% to 643%, with an impressive average improvement of 552%. By significantly\nreducing side lobe levels in antenna arrays, this breakthrough paves the way\nfor ultra-precise beamforming, enhanced interference mitigation, and\nnext-generation wireless and radar systems with unprecedented efficiency and\nclarity.", "published": "2025-04-23 19:46:04", "link": "http://arxiv.org/abs/2504.17073v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "In-Context Learning can distort the relationship between sequence likelihoods and biological fitness", "abstract": "Language models have emerged as powerful predictors of the viability of\nbiological sequences. During training these models learn the rules of the\ngrammar obeyed by sequences of amino acids or nucleotides. Once trained, these\nmodels can take a sequence as input and produce a likelihood score as an\noutput; a higher likelihood implies adherence to the learned grammar and\ncorrelates with experimental fitness measurements. Here we show that in-context\nlearning can distort the relationship between fitness and likelihood scores of\nsequences. This phenomenon most prominently manifests as anomalously high\nlikelihood scores for sequences that contain repeated motifs. We use protein\nlanguage models with different architectures trained on the masked language\nmodeling objective for our experiments, and find transformer-based models to be\nparticularly vulnerable to this effect. This behavior is mediated by a look-up\noperation where the model seeks the identity of the masked position by using\nthe other copy of the repeated motif as a reference. This retrieval behavior\ncan override the model's learned priors. This phenomenon persists for\nimperfectly repeated sequences, and extends to other kinds of biologically\nrelevant features such as reversed complement motifs in RNA sequences that fold\ninto hairpin structures.", "published": "2025-04-23 19:30:01", "link": "http://arxiv.org/abs/2504.17068v1", "categories": ["cs.LG", "q-bio.BM"], "primary_category": "cs.LG"}
{"title": "Whence Is A Model Fair? Fixing Fairness Bugs via Propensity Score Matching", "abstract": "Fairness-aware learning aims to mitigate discrimination against specific\nprotected social groups (e.g., those categorized by gender, ethnicity, age)\nwhile minimizing predictive performance loss. Despite efforts to improve\nfairness in machine learning, prior studies have shown that many models remain\nunfair when measured against various fairness metrics. In this paper, we\nexamine whether the way training and testing data are sampled affects the\nreliability of reported fairness metrics. Since training and test sets are\noften randomly sampled from the same population, bias present in the training\ndata may still exist in the test data, potentially skewing fairness\nassessments. To address this, we propose FairMatch, a post-processing method\nthat applies propensity score matching to evaluate and mitigate bias. FairMatch\nidentifies control and treatment pairs with similar propensity scores in the\ntest set and adjusts decision thresholds for different subgroups accordingly.\nFor samples that cannot be matched, we perform probabilistic calibration using\nfairness-aware loss functions. Experimental results demonstrate that our\napproach can (a) precisely locate subsets of the test data where the model is\nunbiased, and (b) significantly reduce bias on the remaining data. Overall,\npropensity score matching offers a principled way to improve both fairness\nevaluation and mitigation, without sacrificing predictive performance.", "published": "2025-04-23 19:28:30", "link": "http://arxiv.org/abs/2504.17066v1", "categories": ["cs.LG", "cs.CY", "cs.SE", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Antenna Near-Field Reconstruction from Far-Field Data Using Convolutional Neural Networks", "abstract": "Electromagnetic field reconstruction is crucial in many applications,\nincluding antenna diagnostics, electromagnetic interference analysis, and\nsystem modeling. This paper presents a deep learning-based approach for\nFar-Field to Near-Field (FF-NF) transformation using Convolutional Neural\nNetworks (CNNs). The goal is to reconstruct near-field distributions from the\nfar-field data of an antenna without relying on explicit analytical\ntransformations. The CNNs are trained on paired far-field and near-field data\nand evaluated using mean squared error (MSE). The best model achieves a\ntraining error of 0.0199 and a test error of 0.3898. Moreover, visual\ncomparisons between the predicted and true near-field distributions demonstrate\nthe model's effectiveness in capturing complex electromagnetic field behavior,\nhighlighting the potential of deep learning in electromagnetic field\nreconstruction.", "published": "2025-04-23 19:23:37", "link": "http://arxiv.org/abs/2504.17065v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Universal Methods for Nonlinear Spectral Problems", "abstract": "Nonlinear spectral problems arise across a range of fields, including\nmechanical vibrations, fluid-solid interactions, and photonic crystals.\nDiscretizing infinite-dimensional nonlinear spectral problems often introduces\nsignificant computational challenges, particularly spectral pollution and\ninvisibility, which can distort or obscure the true underlying spectrum. We\npresent the first general, convergent computational method for computing the\nspectra and pseudospectra of nonlinear spectral problems. Our approach uses new\nresults on nonlinear injection moduli and requires only minimal continuity\nassumptions: specifically, continuity with respect to the gap metric on\noperator graphs, making it applicable to a broad class of problems. We use the\nSolvability Complexity Index (SCI) hierarchy, which has recently been used to\nresolve the classical linear problem, to systematically classify the\ncomputational complexity of nonlinear spectral problems. Our results establish\nthe optimality of the method and reveal that Hermiticity does not necessarily\nsimplify the computational complexity of these nonlinear problems.\nComprehensive examples -- including nonlinear shifts, Klein--Gordon equations,\nwave equations with acoustic boundary conditions, time-fractional beam\nequations, and biologically inspired delay differential equations --\ndemonstrate the robustness, accuracy, and broad applicability of our\nmethodology.", "published": "2025-04-23 18:01:06", "link": "http://arxiv.org/abs/2504.17012v1", "categories": ["math.NA", "cs.NA", "math.SP"], "primary_category": "math.NA"}
{"title": "A Weighted-likelihood framework for class imbalance in Bayesian prediction models", "abstract": "Class imbalance occurs when data used for training classification models has\na different number of observations or samples within each category or class.\nModels built on such data can be biased towards the majority class and have\npoor predictive performance and generalisation for the minority class. We\npropose a Bayesian weighted-likelihood (power-likelihood) approach to deal with\nclass imbalance: each observation's likelihood is raised to a weight inversely\nproportional to its class proportion, with weights normalized to sum to the\nnumber of samples. This embeds cost-sensitive learning directly into Bayesian\nupdating and is applicable to binary, multinomial and ordered logistic\nprediction models. Example models are implemented in Stan, PyMC, and Turing.jl,\nand all code and reproducible scripts are archived on Github:\nhttps://github.com/stanlazic/weighted_likelihoods. This approach is simple to\nimplement and extends naturally to arbitrary error-cost matrices.", "published": "2025-04-23 18:01:47", "link": "http://arxiv.org/abs/2504.17013v1", "categories": ["stat.AP", "stat.ML"], "primary_category": "stat.AP"}
{"title": "The Rise of Small Language Models in Healthcare: A Comprehensive Survey", "abstract": "Despite substantial progress in healthcare applications driven by large\nlanguage models (LLMs), growing concerns around data privacy, and limited\nresources; the small language models (SLMs) offer a scalable and clinically\nviable solution for efficient performance in resource-constrained environments\nfor next-generation healthcare informatics. Our comprehensive survey presents a\ntaxonomic framework to identify and categorize them for healthcare\nprofessionals and informaticians. The timeline of healthcare SLM contributions\nestablishes a foundational framework for analyzing models across three\ndimensions: NLP tasks, stakeholder roles, and the continuum of care. We present\na taxonomic framework to identify the architectural foundations for building\nmodels from scratch; adapting SLMs to clinical precision through prompting,\ninstruction fine-tuning, and reasoning; and accessibility and sustainability\nthrough compression techniques. Our primary objective is to offer a\ncomprehensive survey for healthcare professionals, introducing recent\ninnovations in model optimization and equipping them with curated resources to\nsupport future research and development in the field. Aiming to showcase the\ngroundbreaking advancements in SLMs for healthcare, we present a comprehensive\ncompilation of experimental results across widely studied NLP tasks in\nhealthcare to highlight the transformative potential of SLMs in healthcare. The\nupdated repository is available at Github", "published": "2025-04-23 22:02:25", "link": "http://arxiv.org/abs/2504.17119v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "On graphs with a simple structure of maximal cliques", "abstract": "We say that a hereditary graph class $\\mathcal{G}$ is \\emph{clique-sparse} if\nthere is a constant $k=k(\\mathcal{G})$ such that for every graph\n$G\\in\\mathcal{G}$, every vertex of $G$ belongs to at most $k$ maximal cliques,\nand any maximal clique of $G$ can be intersected in at most $k$ different ways\nby other maximal cliques.\n  We provide various characterisations of clique-sparse graph classes,\nincluding a list of five parametric forbidden induced subgraphs. We show that\nrecent techniques for proving induced analogues of Menger's Theorem and the\nGrid Theorem of Robertson and Seymour can be lifted to prove induced variants\nin clique-sparse graph classes when replacing ``treewidth'' by\n''tree-independence number''.", "published": "2025-04-23 16:34:20", "link": "http://arxiv.org/abs/2504.16863v2", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "FIM: Frequency-Aware Multi-View Interest Modeling for Local-Life Service Recommendation", "abstract": "People's daily lives involve numerous periodic behaviors, such as eating and\ntraveling. Local-life platforms cater to these recurring needs by providing\nessential services tied to daily routines. Therefore, users' periodic\nintentions are reflected in their interactions with the platforms. There are\ntwo main challenges in modeling users' periodic behaviors in the local-life\nservice recommendation systems: 1) the diverse demands of users exhibit varying\nperiodicities, which are difficult to distinguish as they are mixed in the\nbehavior sequences; 2) the periodic behaviors of users are subject to dynamic\nchanges due to factors such as holidays and promotional events. Existing\nmethods struggle to distinguish the periodicities of diverse demands and\noverlook the importance of dynamically capturing changes in users' periodic\nbehaviors. To this end, we employ a Frequency-Aware Multi-View Interest\nModeling framework (FIM). Specifically, we propose a multi-view search strategy\nthat decomposes users' demands from different perspectives to separate their\nvarious periodic intentions. This allows the model to comprehensively extract\ntheir periodic features than category-searched-only methods. Moreover, we\npropose a frequency-domain perception and evolution module. This module uses\nthe Fourier Transform to convert users' temporal behaviors into the frequency\ndomain, enabling the model to dynamically perceive their periodic features.\nExtensive offline experiments demonstrate that FIM achieves significant\nimprovements on public and industrial datasets, showing its capability to\neffectively model users' periodic intentions. Furthermore, the model has been\ndeployed on the Kuaishou local-life service platform. Through online A/B\nexperiments, the transaction volume has been significantly improved.", "published": "2025-04-23 02:05:31", "link": "http://arxiv.org/abs/2504.17814v1", "categories": ["cs.IR", "H.3.3"], "primary_category": "cs.IR"}
{"title": "How fake news can turn against its spreader", "abstract": "When different information sources on a given topic are combined, they\ninteract in a nontrivial manner for a rational receiver of these information\nsources. Suppose that there are two information sources, one is genuine and the\nother contains disinformation. It is shown that under the conditions that the\nsignal-to-noise ratio of the genuine information source is sufficiently large,\nand that the noise terms in the two information sources are positively\ncorrelated, the effect of disinformation is reversed from its original intent.\nThat is, the effect of disinformation on a receiver of both information\nsources, who is unaware of the existence of disinformation, is to generate an\nopposite interpretation. While the condition in which this phenomenon occurs\ncannot always be ensured, when it is satisfied, the effect provides an\neffective way of countering the impacts of disinformation.", "published": "2025-04-23 09:35:06", "link": "http://arxiv.org/abs/2504.17820v1", "categories": ["physics.soc-ph", "cs.IT", "cs.SI", "math.IT"], "primary_category": "physics.soc-ph"}
{"title": "Steering the CensorShip: Uncovering Representation Vectors for LLM \"Thought\" Control", "abstract": "Large language models (LLMs) have transformed the way we access information.\nThese models are often tuned to refuse to comply with requests that are\nconsidered harmful and to produce responses that better align with the\npreferences of those who control the models. To understand how this\n\"censorship\" works. We use representation engineering techniques to study\nopen-weights safety-tuned models. We present a method for finding a\nrefusal--compliance vector that detects and controls the level of censorship in\nmodel outputs. We also analyze recent reasoning LLMs, distilled from\nDeepSeek-R1, and uncover an additional dimension of censorship through \"thought\nsuppression\". We show a similar approach can be used to find a vector that\nsuppresses the model's reasoning process, allowing us to remove censorship by\napplying the negative multiples of this vector. Our code is publicly available\nat: https://github.com/hannahxchen/llm-censorship-steering", "published": "2025-04-23 22:47:30", "link": "http://arxiv.org/abs/2504.17130v2", "categories": ["cs.CL", "cs.CR", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Do Large Language Models know who did what to whom?", "abstract": "Large Language Models (LLMs) are commonly criticized for not understanding\nlanguage. However, many critiques focus on cognitive abilities that, in humans,\nare distinct from language processing. Here, we instead study a kind of\nunderstanding tightly linked to language: inferring who did what to whom\n(thematic roles) in a sentence. Does the central training objective of\nLLMs-word prediction-result in sentence representations that capture thematic\nroles? In two experiments, we characterized sentence representations in four\nLLMs. In contrast to human similarity judgments, in LLMs the overall\nrepresentational similarity of sentence pairs reflected syntactic similarity\nbut not whether their agent and patient assignments were identical vs.\nreversed. Furthermore, we found little evidence that thematic role information\nwas available in any subset of hidden units. However, some attention heads\nrobustly captured thematic roles, independently of syntax. Therefore, LLMs can\nextract thematic roles but, relative to humans, this information influences\ntheir representations more weakly.", "published": "2025-04-23 17:00:45", "link": "http://arxiv.org/abs/2504.16884v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluation Framework for AI Systems in \"the Wild\"", "abstract": "Generative AI (GenAI) models have become vital across industries, yet current\nevaluation methods have not adapted to their widespread use. Traditional\nevaluations often rely on benchmarks and fixed datasets, frequently failing to\nreflect real-world performance, which creates a gap between lab-tested outcomes\nand practical applications. This white paper proposes a comprehensive framework\nfor how we should evaluate real-world GenAI systems, emphasizing diverse,\nevolving inputs and holistic, dynamic, and ongoing assessment approaches. The\npaper offers guidance for practitioners on how to design evaluation methods\nthat accurately reflect real-time capabilities, and provides policymakers with\nrecommendations for crafting GenAI policies focused on societal impacts, rather\nthan fixed performance numbers or parameter sizes. We advocate for holistic\nframeworks that integrate performance, fairness, and ethics and the use of\ncontinuous, outcome-oriented methods that combine human and automated\nassessments while also being transparent to foster trust among stakeholders.\nImplementing these strategies ensures GenAI models are not only technically\nproficient but also ethically responsible and impactful.", "published": "2025-04-23 14:52:39", "link": "http://arxiv.org/abs/2504.16778v2", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Enhancing LLM-Based Agents via Global Planning and Hierarchical Execution", "abstract": "Intelligent agent systems based on Large Language Models (LLMs) have shown\ngreat potential in real-world applications. However, existing agent frameworks\nstill face critical limitations in task planning and execution, restricting\ntheir effectiveness and generalizability. Specifically, current planning\nmethods often lack clear global goals, leading agents to get stuck in local\nbranches, or produce non-executable plans. Meanwhile, existing execution\nmechanisms struggle to balance complexity and stability, and their limited\naction space restricts their ability to handle diverse real-world tasks. To\naddress these limitations, we propose GoalAct, a novel agent framework that\nintroduces a continuously updated global planning mechanism and integrates a\nhierarchical execution strategy. GoalAct decomposes task execution into\nhigh-level skills, including searching, coding, writing and more, thereby\nreducing planning complexity while enhancing the agents' adaptability across\ndiverse task scenarios. We evaluate GoalAct on LegalAgentBench, a benchmark\nwith multiple types of legal tasks that require the use of multiple types of\ntools. Experimental results demonstrate that GoalAct achieves state-of-the-art\n(SOTA) performance, with an average improvement of 12.22% in success rate.\nThese findings highlight GoalAct's potential to drive the development of more\nadvanced intelligent agent systems, making them more effective across complex\nreal-world applications. Our code can be found at\nhttps://github.com/cjj826/GoalAct.", "published": "2025-04-23 09:43:40", "link": "http://arxiv.org/abs/2504.16563v2", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Modern Computational Methods in Reinsurance Optimization: From Simulated Annealing to Quantum Branch & Bound", "abstract": "We propose and implement modern computational methods to enhance catastrophe\nexcess-of-loss reinsurance contracts in practice. The underlying optimization\nproblem involves attachment points, limits, and reinstatement clauses, and the\nobjective is to maximize the expected profit while considering risk measures\nand regulatory constraints. We study the problem formulation, paving the way\nfor practitioners, for two very different approaches: A local search optimizer\nusing simulated annealing, which handles realistic constraints, and a branch &\nbound approach exploring the potential of a future speedup via quantum branch &\nbound. On the one hand, local search effectively generates contract structures\nwithin several constraints, proving useful for complex treaties that have\nmultiple local optima. On the other hand, although our branch & bound\nformulation only confirms that solving the full problem with a future quantum\ncomputer would require a stronger, less expensive bound and substantial\nhardware improvements, we believe that the designed application-specific bound\nis sufficiently strong to serve as a basis for further works. Concisely, we\nprovide insurance practitioners with a robust numerical framework for contract\noptimization that handles realistic constraints today, as well as an outlook\nand initial steps towards an approach which could leverage quantum computers in\nthe future.", "published": "2025-04-23 08:55:40", "link": "http://arxiv.org/abs/2504.16530v2", "categories": ["math.OC", "q-fin.CP", "quant-ph"], "primary_category": "math.OC"}
{"title": "Modular Debiasing for Discrete Sources and Quantum Randomness", "abstract": "We propose a modular debiasing technique for discrete random sources,\naddressing the fundamental challenge of extracting high-quality randomness from\nimperfect physical processes. The method involves summing the outcomes of\nmultiple independent trials from a biased source and reducing the sum modulo\nthe number of possible outcomes, $m$. We provide a rigorous theoretical\nframework demonstrating that this simple operation guarantees the convergence\nof the output distribution to the ideal uniform distribution over $\\{0, 1,\n\\dots, m-1\\}$. A key result is the method's remarkable robustness: convergence\nis proven for any initial bias (provided all outcomes have non-zero\nprobability) and, critically, is maintained even under non-stationary\nconditions or time-dependent noise. Analytical bounds show an exponential rate\nof convergence, which is empirically validated by numerical simulations. This\ntechnique's simplicity, theoretical guarantees, robustness, and data efficiency\nmake it particularly well-suited for practical implementation in quantum\nsettings, such as spatial photon-detection-based Quantum Random Number\nGenerators, enabling efficient extraction of high-quality randomness from\nexperimentally imperfect sources.", "published": "2025-04-23 23:28:47", "link": "http://arxiv.org/abs/2504.18585v1", "categories": ["physics.data-an", "cs.IT", "math.IT", "math.PR"], "primary_category": "physics.data-an"}
{"title": "Speaker Diarization for Low-Resource Languages Through Wav2vec Fine-Tuning", "abstract": "Speaker diarization is a fundamental task in speech processing that involves\ndividing an audio stream by speaker. Although state-of-the-art models have\nadvanced performance in high-resource languages, low-resource languages such as\nKurdish pose unique challenges due to limited annotated data, multiple dialects\nand frequent code-switching. In this study, we address these issues by training\nthe Wav2Vec 2.0 self-supervised learning model on a dedicated Kurdish corpus.\nBy leveraging transfer learning, we adapted multilingual representations\nlearned from other languages to capture the phonetic and acoustic\ncharacteristics of Kurdish speech. Relative to a baseline method, our approach\nreduced the diarization error rate by seven point two percent and improved\ncluster purity by thirteen percent. These findings demonstrate that\nenhancements to existing models can significantly improve diarization\nperformance for under-resourced languages. Our work has practical implications\nfor developing transcription services for Kurdish-language media and for\nspeaker segmentation in multilingual call centers, teleconferencing and\nvideo-conferencing systems. The results establish a foundation for building\neffective diarization systems in other understudied languages, contributing to\ngreater equity in speech technology.", "published": "2025-04-23 10:45:59", "link": "http://arxiv.org/abs/2504.18582v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Enhancing LLM-Based Agents via Global Planning and Hierarchical Execution", "abstract": "Intelligent agent systems based on Large Language Models (LLMs) have shown\ngreat potential in real-world applications. However, existing agent frameworks\nstill face critical limitations in task planning and execution, restricting\ntheir effectiveness and generalizability. Specifically, current planning\nmethods often lack clear global goals, leading agents to get stuck in local\nbranches, or produce non-executable plans. Meanwhile, existing execution\nmechanisms struggle to balance complexity and stability, and their limited\naction space restricts their ability to handle diverse real-world tasks. To\naddress these limitations, we propose GoalAct, a novel agent framework that\nintroduces a continuously updated global planning mechanism and integrates a\nhierarchical execution strategy. GoalAct decomposes task execution into\nhigh-level skills, including searching, coding, writing and more, thereby\nreducing planning complexity while enhancing the agents' adaptability across\ndiverse task scenarios. We evaluate GoalAct on LegalAgentBench, a benchmark\nwith multiple types of legal tasks that require the use of multiple types of\ntools. Experimental results demonstrate that GoalAct achieves state-of-the-art\n(SOTA) performance, with an average improvement of 12.22% in success rate.\nThese findings highlight GoalAct's potential to drive the development of more\nadvanced intelligent agent systems, making them more effective across complex\nreal-world applications. Our code can be found at\nhttps://github.com/cjj826/GoalAct.", "published": "2025-04-23 09:43:40", "link": "http://arxiv.org/abs/2504.16563v3", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "FIM: Frequency-Aware Multi-View Interest Modeling for Local-Life Service Recommendation", "abstract": "People's daily lives involve numerous periodic behaviors, such as eating and\ntraveling. Local-life platforms cater to these recurring needs by providing\nessential services tied to daily routines. Therefore, users' periodic\nintentions are reflected in their interactions with the platforms. There are\ntwo main challenges in modeling users' periodic behaviors in the local-life\nservice recommendation systems: 1) the diverse demands of users exhibit varying\nperiodicities, which are difficult to distinguish as they are mixed in the\nbehavior sequences; 2) the periodic behaviors of users are subject to dynamic\nchanges due to factors such as holidays and promotional events. Existing\nmethods struggle to distinguish the periodicities of diverse demands and\noverlook the importance of dynamically capturing changes in users' periodic\nbehaviors. To this end, we employ a Frequency-Aware Multi-View Interest\nModeling framework (FIM). Specifically, we propose a multi-view search strategy\nthat decomposes users' demands from different perspectives to separate their\nvarious periodic intentions. This allows the model to comprehensively extract\ntheir periodic features than category-searched-only methods. Moreover, we\npropose a frequency-domain perception and evolution module. This module uses\nthe Fourier Transform to convert users' temporal behaviors into the frequency\ndomain, enabling the model to dynamically perceive their periodic features.\nExtensive offline experiments demonstrate that FIM achieves significant\nimprovements on public and industrial datasets, showing its capability to\neffectively model users' periodic intentions. Furthermore, the model has been\ndeployed on the Kuaishou local-life service platform. Through online A/B\nexperiments, the transaction volume has been significantly improved.", "published": "2025-04-23 02:05:31", "link": "http://arxiv.org/abs/2504.17814v2", "categories": ["cs.IR", "H.3.3"], "primary_category": "cs.IR"}
{"title": "Whence Is A Model Fair? Fixing Fairness Bugs via Propensity Score Matching", "abstract": "Fairness-aware learning aims to mitigate discrimination against specific\nprotected social groups (e.g., those categorized by gender, ethnicity, age)\nwhile minimizing predictive performance loss. Despite efforts to improve\nfairness in machine learning, prior studies have shown that many models remain\nunfair when measured against various fairness metrics. In this paper, we\nexamine whether the way training and testing data are sampled affects the\nreliability of reported fairness metrics. Since training and test sets are\noften randomly sampled from the same population, bias present in the training\ndata may still exist in the test data, potentially skewing fairness\nassessments. To address this, we propose FairMatch, a post-processing method\nthat applies propensity score matching to evaluate and mitigate bias. FairMatch\nidentifies control and treatment pairs with similar propensity scores in the\ntest set and adjusts decision thresholds for different subgroups accordingly.\nFor samples that cannot be matched, we perform probabilistic calibration using\nfairness-aware loss functions. Experimental results demonstrate that our\napproach can (a) precisely locate subsets of the test data where the model is\nunbiased, and (b) significantly reduce bias on the remaining data. Overall,\npropensity score matching offers a principled way to improve both fairness\nevaluation and mitigation, without sacrificing predictive performance.", "published": "2025-04-23 19:28:30", "link": "http://arxiv.org/abs/2504.17066v2", "categories": ["cs.LG", "cs.CY", "cs.SE", "stat.ML"], "primary_category": "cs.LG"}
