{"title": "Content-Based Table Retrieval for Web Queries", "abstract": "Understanding the connections between unstructured text and semi-structured\ntable is an important yet neglected problem in natural language processing. In\nthis work, we focus on content-based table retrieval. Given a query, the task\nis to find the most relevant table from a collection of tables. Further\nprogress towards improving this area requires powerful models of semantic\nmatching and richer training and evaluation resources. To remedy this, we\npresent a ranking based approach, and implement both carefully designed\nfeatures and neural network architectures to measure the relevance between a\nquery and the content of a table. Furthermore, we release an open-domain\ndataset that includes 21,113 web queries for 273,816 tables. We conduct\ncomprehensive experiments on both real world and synthetic datasets. Results\nverify the effectiveness of our approach and present the challenges for this\ntask.", "published": "2017-06-08 02:03:32", "link": "http://arxiv.org/abs/1706.02427v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Semantic Relevance for Sequence-to-Sequence Learning of\n  Chinese Social Media Text Summarization", "abstract": "Current Chinese social media text summarization models are based on an\nencoder-decoder framework. Although its generated summaries are similar to\nsource texts literally, they have low semantic relevance. In this work, our\ngoal is to improve semantic relevance between source texts and summaries for\nChinese social media summarization. We introduce a Semantic Relevance Based\nneural model to encourage high semantic similarity between texts and summaries.\nIn our model, the source text is represented by a gated attention encoder,\nwhile the summary representation is produced by a decoder. Besides, the\nsimilarity score between the representations is maximized during training. Our\nexperiments show that the proposed model outperforms baseline systems on a\nsocial media corpus.", "published": "2017-06-08 07:05:56", "link": "http://arxiv.org/abs/1706.02459v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Algorithmic Inflection of Russian and Generation of Grammatically\n  Correct Text", "abstract": "We present a deterministic algorithm for Russian inflection. This algorithm\nis implemented in a publicly available web-service www.passare.ru which\nprovides functions for inflection of single words, word matching and synthesis\nof grammatically correct Russian text. The inflectional functions have been\ntested against the annotated corpus of Russian language OpenCorpora.", "published": "2017-06-08 12:48:15", "link": "http://arxiv.org/abs/1706.02551v1", "categories": ["cs.CL", "68T35"], "primary_category": "cs.CL"}
{"title": "Advances in Joint CTC-Attention based End-to-End Speech Recognition with\n  a Deep CNN Encoder and RNN-LM", "abstract": "We present a state-of-the-art end-to-end Automatic Speech Recognition (ASR)\nmodel. We learn to listen and write characters with a joint Connectionist\nTemporal Classification (CTC) and attention-based encoder-decoder network. The\nencoder is a deep Convolutional Neural Network (CNN) based on the VGG network.\nThe CTC network sits on top of the encoder and is jointly trained with the\nattention-based decoder. During the beam search process, we combine the CTC\npredictions, the attention-based decoder predictions and a separately trained\nLSTM language model. We achieve a 5-10\\% error reduction compared to prior\nsystems on spontaneous Japanese and Chinese speech, and our end-to-end model\nbeats out traditional hybrid ASR systems.", "published": "2017-06-08 19:30:02", "link": "http://arxiv.org/abs/1706.02737v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Deriving a Representative Vector for Ontology Classes with Instance Word\n  Vector Embeddings", "abstract": "Selecting a representative vector for a set of vectors is a very common\nrequirement in many algorithmic tasks. Traditionally, the mean or median vector\nis selected. Ontology classes are sets of homogeneous instance objects that can\nbe converted to a vector space by word vector embeddings. This study proposes a\nmethodology to derive a representative vector for ontology classes whose\ninstances were converted to the vector space. We start by deriving five\ncandidate vectors which are then used to train a machine learning model that\nwould calculate a representative vector for the class. We show that our\nmethodology out-performs the traditional mean and median vector\nrepresentations.", "published": "2017-06-08 03:01:37", "link": "http://arxiv.org/abs/1706.02909v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Context encoders as a simple but powerful extension of word2vec", "abstract": "With a simple architecture and the ability to learn meaningful word\nembeddings efficiently from texts containing billions of words, word2vec\nremains one of the most popular neural language models used today. However, as\nonly a single embedding is learned for every word in the vocabulary, the model\nfails to optimally represent words with multiple meanings. Additionally, it is\nnot possible to create embeddings for new (out-of-vocabulary) words on the\nspot. Based on an intuitive interpretation of the continuous bag-of-words\n(CBOW) word2vec model's negative sampling training objective in terms of\npredicting context based similarities, we motivate an extension of the model we\ncall context encoders (ConEc). By multiplying the matrix of trained word2vec\nembeddings with a word's average context vector, out-of-vocabulary (OOV)\nembeddings and representations for a word with multiple meanings can be created\nbased on the word's local contexts. The benefits of this approach are\nillustrated by using these word embeddings as features in the CoNLL 2003 named\nentity recognition (NER) task.", "published": "2017-06-08 09:56:11", "link": "http://arxiv.org/abs/1706.02496v1", "categories": ["stat.ML", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Dynamic Integration of Background Knowledge in Neural NLU Systems", "abstract": "Common-sense and background knowledge is required to understand natural\nlanguage, but in most neural natural language understanding (NLU) systems, this\nknowledge must be acquired from training corpora during learning, and then it\nis static at test time. We introduce a new architecture for the dynamic\nintegration of explicit background knowledge in NLU models. A general-purpose\nreading module reads background knowledge in the form of free-text statements\n(together with task-specific text inputs) and yields refined word\nrepresentations to a task-specific NLU architecture that reprocesses the task\ninputs with these representations. Experiments on document question answering\n(DQA) and recognizing textual entailment (RTE) demonstrate the effectiveness\nand flexibility of the approach. Analysis shows that our model learns to\nexploit knowledge in a semantically appropriate way.", "published": "2017-06-08 14:10:22", "link": "http://arxiv.org/abs/1706.02596v3", "categories": ["cs.CL", "cs.AI", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Sympathy Begins with a Smile, Intelligence Begins with a Word: Use of\n  Multimodal Features in Spoken Human-Robot Interaction", "abstract": "Recognition of social signals, from human facial expressions or prosody of\nspeech, is a popular research topic in human-robot interaction studies. There\nis also a long line of research in the spoken dialogue community that\ninvestigates user satisfaction in relation to dialogue characteristics.\nHowever, very little research relates a combination of multimodal social\nsignals and language features detected during spoken face-to-face human-robot\ninteraction to the resulting user perception of a robot. In this paper we show\nhow different emotional facial expressions of human users, in combination with\nprosodic characteristics of human speech and features of human-robot dialogue,\ncorrelate with users' impressions of the robot after a conversation. We find\nthat happiness in the user's recognised facial expression strongly correlates\nwith likeability of a robot, while dialogue-related features (such as number of\nhuman turns or number of sentences per robot utterance) correlate with\nperceiving a robot as intelligent. In addition, we show that facial expression,\nemotional features, and prosody are better predictors of human ratings related\nto perceived robot likeability and anthropomorphism, while linguistic and\nnon-linguistic features more often predict perceived robot intelligence and\ninterpretability. As such, these characteristics may in future be used as an\nonline reward signal for in-situ Reinforcement Learning based adaptive\nhuman-robot dialogue systems.", "published": "2017-06-08 20:33:00", "link": "http://arxiv.org/abs/1706.02757v1", "categories": ["cs.RO", "cs.CL", "cs.HC"], "primary_category": "cs.RO"}
{"title": "Optimizing expected word error rate via sampling for speech recognition", "abstract": "State-level minimum Bayes risk (sMBR) training has become the de facto\nstandard for sequence-level training of speech recognition acoustic models. It\nhas an elegant formulation using the expectation semiring, and gives large\nimprovements in word error rate (WER) over models trained solely using\ncross-entropy (CE) or connectionist temporal classification (CTC). sMBR\ntraining optimizes the expected number of frames at which the reference and\nhypothesized acoustic states differ. It may be preferable to optimize the\nexpected WER, but WER does not interact well with the expectation semiring, and\nprevious approaches based on computing expected WER exactly involve expanding\nthe lattices used during training. In this paper we show how to perform\noptimization of the expected WER by sampling paths from the lattices used\nduring conventional sMBR training. The gradient of the expected WER is itself\nan expectation, and so may be approximated using Monte Carlo sampling. We show\nexperimentally that optimizing WER during acoustic model training gives 5%\nrelative improvement in WER over a well-tuned sMBR baseline on a 2-channel\nquery recognition task (Google Home).", "published": "2017-06-08 21:14:48", "link": "http://arxiv.org/abs/1706.02776v1", "categories": ["cs.CL", "cs.LG", "cs.NE", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Where is my forearm? Clustering of body parts from simultaneous tactile\n  and linguistic input using sequential mapping", "abstract": "Humans and animals are constantly exposed to a continuous stream of sensory\ninformation from different modalities. At the same time, they form more\ncompressed representations like concepts or symbols. In species that use\nlanguage, this process is further structured by this interaction, where a\nmapping between the sensorimotor concepts and linguistic elements needs to be\nestablished. There is evidence that children might be learning language by\nsimply disambiguating potential meanings based on multiple exposures to\nutterances in different contexts (cross-situational learning). In existing\nmodels, the mapping between modalities is usually found in a single step by\ndirectly using frequencies of referent and meaning co-occurrences. In this\npaper, we present an extension of this one-step mapping and introduce a newly\nproposed sequential mapping algorithm together with a publicly available Matlab\nimplementation. For demonstration, we have chosen a less typical scenario:\ninstead of learning to associate objects with their names, we focus on body\nrepresentations. A humanoid robot is receiving tactile stimulations on its\nbody, while at the same time listening to utterances of the body part names\n(e.g., hand, forearm and torso). With the goal at arriving at the correct \"body\ncategories\", we demonstrate how a sequential mapping algorithm outperforms\none-step mapping. In addition, the effect of data set size and noise in the\nlinguistic input are studied.", "published": "2017-06-08 09:31:42", "link": "http://arxiv.org/abs/1706.02490v1", "categories": ["cs.NE", "cs.AI", "cs.CL", "cs.LG", "cs.RO"], "primary_category": "cs.NE"}
