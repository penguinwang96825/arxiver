{"title": "Efficient Character-level Document Classification by Combining\n  Convolution and Recurrent Layers", "abstract": "Document classification tasks were primarily tackled at word level. Recent\nresearch that works with character-level inputs shows several benefits over\nword-level approaches such as natural incorporation of morphemes and better\nhandling of rare words. We propose a neural network architecture that utilizes\nboth convolution and recurrent layers to efficiently encode character inputs.\nWe validate the proposed model on eight large scale document classification\ntasks and compare with character-level convolution-only models. It achieves\ncomparable performances with much less parameters.", "published": "2016-02-01 02:53:41", "link": "http://arxiv.org/abs/1602.00367v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Iterative Deep Learning Framework for Unsupervised Discovery of\n  Speech Features and Linguistic Units with Applications on Spoken Term\n  Detection", "abstract": "In this work we aim to discover high quality speech features and linguistic\nunits directly from unlabeled speech data in a zero resource scenario. The\nresults are evaluated using the metrics and corpora proposed in the Zero\nResource Speech Challenge organized at Interspeech 2015. A Multi-layered\nAcoustic Tokenizer (MAT) was proposed for automatic discovery of multiple sets\nof acoustic tokens from the given corpus. Each acoustic token set is specified\nby a set of hyperparameters that describe the model configuration. These sets\nof acoustic tokens carry different characteristics fof the given corpus and the\nlanguage behind, thus can be mutually reinforced. The multiple sets of token\nlabels are then used as the targets of a Multi-target Deep Neural Network\n(MDNN) trained on low-level acoustic features. Bottleneck features extracted\nfrom the MDNN are then used as the feedback input to the MAT and the MDNN\nitself in the next iteration. We call this iterative deep learning framework\nthe Multi-layered Acoustic Tokenizing Deep Neural Network (MAT-DNN), which\ngenerates both high quality speech features for the Track 1 of the Challenge\nand acoustic tokens for the Track 2 of the Challenge. In addition, we performed\nextra experiments on the same corpora on the application of query-by-example\nspoken term detection. The experimental results showed the iterative deep\nlearning framework of MAT-DNN improved the detection performance due to better\nunderlying speech features and acoustic tokens.", "published": "2016-02-01 08:37:56", "link": "http://arxiv.org/abs/1602.00426v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Marvin: Semantic annotation using multiple knowledge sources", "abstract": "People are producing more written material then anytime in the history. The\nincrease is so high that professionals from the various fields are no more able\nto cope with this amount of publications. Text mining tools can offer tools to\nhelp them and one of the tools that can aid information retrieval and\ninformation extraction is semantic text annotation. In this report we present\nMarvin, a text annotator written in Java, which can be used as a command line\ntool and as a Java library. Marvin is able to annotate text using multiple\nsources, including WordNet, MetaMap, DBPedia and thesauri represented as SKOS.", "published": "2016-02-01 13:27:34", "link": "http://arxiv.org/abs/1602.00515v2", "categories": ["cs.AI", "cs.CL", "D.3.2; K.2; H.2.4"], "primary_category": "cs.AI"}
