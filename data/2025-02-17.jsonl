{"title": "Parameterised algorithms for temporal reconfiguration problems", "abstract": "Given a static vertex-selection problem (e.g. independent set, dominating\nset) on a graph, we can define a corresponding temporal reconfiguration problem\non a temporal graph which asks for a sequence of solutions to the\nvertex-selection problem at each time such that we can reconfigure from one\nsolution to the next. We can think of each solution in the sequence as a set of\nvertices with tokens placed on them; our reconfiguration model allows us to\nslide tokens along active edges of a temporal graph.\n  We show that it is possible to efficiently check whether one solution can be\nreconfigured to another, and show that approximation results on the static\nvertex-selection problem can be adapted with a lifetime factor to the\nreconfiguration version. Our main contributions are fixed-parameter tractable\nalgorithms with respect to: enumeration time of the related static problem; the\ncombination of temporal neighbourhood diversity and lifetime of the input\ngraph; and the combination of lifetime and treewidth of the footprint graph.", "published": "2025-02-17 16:09:00", "link": "http://arxiv.org/abs/2502.11961v1", "categories": ["cs.DS", "cs.DM", "math.CO"], "primary_category": "cs.DS"}
{"title": "On a tree-based variant of bandwidth and forbidding simple topological minors", "abstract": "We obtain structure theorems for graphs excluding a fan (a path with a\nuniversal vertex) or a dipole ($K_{2,k}$) as a topological minor. The\ncorresponding decompositions can be computed in FPT linear time. This is\nmotivated by the study of a graph parameter we call treebandwidth which extends\nthe graph parameter bandwidth by replacing the linear layout by a rooted tree\nsuch that neighbours in the graph are in ancestor-descendant relation in the\ntree.\n  We deduce an approximation algorithm for treebandwidth running in FPT linear\ntime from our structure theorems. We complement this result with a precise\ncharacterisation of the parameterised complexity of computing the parameter\nexactly.", "published": "2025-02-17 11:07:14", "link": "http://arxiv.org/abs/2502.11674v1", "categories": ["cs.DM", "cs.CC", "cs.DS", "math.CO"], "primary_category": "cs.DM"}
{"title": "On rigid regular graphs and a problem of Babai and Pultr", "abstract": "A graph is \\textit{rigid} if it only admits the identity endomorphism. We\nshow that for every $d\\ge 3$ there exist infinitely many mutually rigid\n$d$-regular graphs of arbitrary odd girth $g\\geq 7$. Moreover, we determine the\nminimum order of a rigid $d$-regular graph for every $d\\ge 3$. This provides\nstrong positive answers to a question of van der Zypen\n[https://mathoverflow.net/q/296483, https://mathoverflow.net/q/321108].\nFurther, we use our construction to show that every finite monoid is isomorphic\nto the endomorphism monoid of a regular graph. This solves a problem of Babai\nand Pultr [J. Comb.~Theory, Ser.~B, 1980].", "published": "2025-02-17 04:21:03", "link": "http://arxiv.org/abs/2502.11421v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "A deep BSDE approach for the simultaneous pricing and delta-gamma hedging of large portfolios consisting of high-dimensional multi-asset Bermudan options", "abstract": "A deep BSDE approach is presented for the pricing and delta-gamma hedging of\nhigh-dimensional Bermudan options, with applications in portfolio risk\nmanagement. Large portfolios of a mixture of multi-asset European and Bermudan\nderivatives are cast into the framework of discretely reflected BSDEs. This\nsystem is discretized by the One Step Malliavin scheme (Negyesi et al. [2024,\n2025]) of discretely reflected Markovian BSDEs, which involves a $\\Gamma$\nprocess, corresponding to second-order sensitivities of the associated option\nprices. The discretized system is solved by a neural network regression Monte\nCarlo method, efficiently for a large number of underlyings. The resulting\noption Deltas and Gammas are used to discretely rebalance the corresponding\nreplicating strategies. Numerical experiments are presented on both\nhigh-dimensional basket options and large portfolios consisting of multiple\noptions with varying early exercise rights, moneyness and volatility. These\nexamples demonstrate the robustness and accuracy of the method up to $100$ risk\nfactors. The resulting hedging strategies significantly outperform benchmark\nmethods both in the case of standard delta- and delta-gamma hedging.", "published": "2025-02-17 11:46:40", "link": "http://arxiv.org/abs/2502.11706v1", "categories": ["q-fin.CP", "q-fin.RM", "91G20, 68T07, 91G60, 65C30"], "primary_category": "q-fin.CP"}
{"title": "A Cholesky decomposition-based asset selection heuristic for sparse tangent portfolio optimization", "abstract": "In practice, including large number of assets in mean-variance portfolios can\nlead to higher transaction costs and management fees. To address this, one\ncommon approach is to select a smaller subset of assets from the larger pool,\nconstructing more efficient portfolios. As a solution, we propose a new asset\nselection heuristic which generates a pre-defined list of asset candidates\nusing a surrogate formulation and re-optimizes the cardinality-constrained\ntangent portfolio with these selected assets. This method enables faster\noptimization and effectively constructs portfolios with fewer assets, as\ndemonstrated by numerical analyses on historical stock returns. Finally, we\ndiscuss a quantitative metric that can provide a initial assessment of the\nperformance of the proposed heuristic based on asset covariance.", "published": "2025-02-17 11:39:50", "link": "http://arxiv.org/abs/2502.11701v1", "categories": ["q-fin.MF", "q-fin.PM"], "primary_category": "q-fin.MF"}
{"title": "Market-Derived Financial Sentiment Analysis: Context-Aware Language Models for Crypto Forecasting", "abstract": "Financial Sentiment Analysis (FSA) traditionally relies on human-annotated\nsentiment labels to infer investor sentiment and forecast market movements.\nHowever, inferring the potential market impact of words based on their\nhuman-perceived intentions is inherently challenging. We hypothesize that the\nhistorical market reactions to words, offer a more reliable indicator of their\npotential impact on markets than subjective sentiment interpretations by human\nannotators. To test this hypothesis, a market-derived labeling approach is\nproposed to assign tweet labels based on ensuing short-term price trends,\nenabling the language model to capture the relationship between textual signals\nand market dynamics directly. A domain-specific language model was fine-tuned\non these labels, achieving up to an 11% improvement in short-term trend\nprediction accuracy over traditional sentiment-based benchmarks. Moreover, by\nincorporating market and temporal context through prompt-tuning, the proposed\ncontext-aware language model demonstrated an accuracy of 89.6% on a curated\ndataset of 227 impactful Bitcoin-related news events with significant market\nimpacts. Aggregating daily tweet predictions into trading signals, our method\noutperformed traditional fusion models (which combine sentiment-based and\nprice-based predictions). It challenged the assumption that sentiment-based\nsignals are inferior to price-based predictions in forecasting market\nmovements. Backtesting these signals across three distinct market regimes\nyielded robust Sharpe ratios of up to 5.07 in trending markets and 3.73 in\nneutral markets. Our findings demonstrate that language models can serve as\neffective short-term market predictors. This paradigm shift underscores the\nuntapped capabilities of language models in financial decision-making and opens\nnew avenues for market prediction applications.", "published": "2025-02-17 21:35:18", "link": "http://arxiv.org/abs/2502.14897v2", "categories": ["cs.CE", "cs.CL", "cs.LG", "q-fin.ST", "68T50", "H.3.1; I.2.7; J.1"], "primary_category": "cs.CE"}
{"title": "FLAG-Trader: Fusion LLM-Agent with Gradient-based Reinforcement Learning for Financial Trading", "abstract": "Large language models (LLMs) fine-tuned on multimodal financial data have\ndemonstrated impressive reasoning capabilities in various financial tasks.\nHowever, they often struggle with multi-step, goal-oriented scenarios in\ninteractive financial markets, such as trading, where complex agentic\napproaches are required to improve decision-making. To address this, we propose\n\\textsc{FLAG-Trader}, a unified architecture integrating linguistic processing\n(via LLMs) with gradient-driven reinforcement learning (RL) policy\noptimization, in which a partially fine-tuned LLM acts as the policy network,\nleveraging pre-trained knowledge while adapting to the financial domain through\nparameter-efficient fine-tuning. Through policy gradient optimization driven by\ntrading rewards, our framework not only enhances LLM performance in trading but\nalso improves results on other financial-domain tasks. We present extensive\nempirical evidence to validate these enhancements.", "published": "2025-02-17 04:45:53", "link": "http://arxiv.org/abs/2502.11433v3", "categories": ["cs.AI", "cs.CE", "q-fin.TR"], "primary_category": "cs.AI"}
{"title": "HedgeAgents: A Balanced-aware Multi-agent Financial Trading System", "abstract": "As automated trading gains traction in the financial market, algorithmic\ninvestment strategies are increasingly prominent. While Large Language Models\n(LLMs) and Agent-based models exhibit promising potential in real-time market\nanalysis and trading decisions, they still experience a significant -20% loss\nwhen confronted with rapid declines or frequent fluctuations, impeding their\npractical application. Hence, there is an imperative to explore a more robust\nand resilient framework. This paper introduces an innovative multi-agent\nsystem, HedgeAgents, aimed at bolstering system robustness via ``hedging''\nstrategies. In this well-balanced system, an array of hedging agents has been\ntailored, where HedgeAgents consist of a central fund manager and multiple\nhedging experts specializing in various financial asset classes. These agents\nleverage LLMs' cognitive capabilities to make decisions and coordinate through\nthree types of conferences. Benefiting from the powerful understanding of LLMs,\nour HedgeAgents attained a 70% annualized return and a 400% total return over a\nperiod of 3 years. Moreover, we have observed with delight that HedgeAgents can\neven formulate investment experience comparable to those of human experts\n(https://hedgeagents.github.io/).", "published": "2025-02-17 04:13:19", "link": "http://arxiv.org/abs/2502.13165v1", "categories": ["cs.MA", "cs.AI", "q-fin.TR"], "primary_category": "cs.MA"}
