{"title": "AirLLM: Diffusion Policy-based Adaptive LoRA for Remote Fine-Tuning of LLM over the Air", "abstract": "Operating Large Language Models (LLMs) on edge devices is increasingly\nchallenged by limited communication bandwidth and strained computational and\nmemory costs. Thus, cloud-assisted remote fine-tuning becomes indispensable.\nNevertheless, existing Low-Rank Adaptation (LoRA) approaches typically employ\nfixed or heuristic rank configurations, and the subsequent over-the-air\ntransmission of all LoRA parameters could be rather inefficient. To address\nthis limitation, we develop AirLLM, a hierarchical diffusion policy framework\nfor communication-aware LoRA adaptation. Specifically, AirLLM models the rank\nconfiguration as a structured action vector that spans all LoRA-inserted\nprojections. To solve the underlying high-dimensional sequential\ndecision-making problem, a Proximal Policy Optimization (PPO) agent generates\ncoarse-grained decisions by jointly observing wireless states and linguistic\ncomplexity, which are then refined via Denoising Diffusion Implicit Models\n(DDIM) to produce high-resolution, task- and channel-adaptive rank vectors. The\ntwo modules are optimized alternatively, with the DDIM trained under the\nClassifier-Free Guidance (CFG) paradigm to maintain alignment with PPO rewards.\nExperiments under varying signal-to-noise ratios demonstrate that AirLLM\nconsistently enhances fine-tuning performance while significantly reducing\ntransmission costs, highlighting the effectiveness of reinforcement-driven,\ndiffusion-refined rank adaptation for scalable and efficient remote fine-tuning\nover the air.", "published": "2025-07-15 17:36:37", "link": "http://arxiv.org/abs/2507.11515v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Real-World Summarization: When Evaluation Reaches Its Limits", "abstract": "We examine evaluation of faithfulness to input data in the context of hotel\nhighlights: brief LLM-generated summaries that capture unique features of\naccommodations. Through human evaluation campaigns involving categorical error\nassessment and span-level annotation, we compare traditional metrics, trainable\nmethods, and LLM-as-a-judge approaches. Our findings reveal that simpler\nmetrics like word overlap correlate surprisingly well with human judgments\n(Spearman correlation rank of 0.63), often outperforming more complex methods\nwhen applied to out-of-domain data. We further demonstrate that while LLMs can\ngenerate high-quality highlights, they prove unreliable for evaluation as they\ntend to severely under- or over-annotate. Our analysis of real-world business\nimpacts shows incorrect and non-checkable information pose the greatest risks.\nWe also highlight challenges in crowdsourced evaluations.", "published": "2025-07-15 17:23:56", "link": "http://arxiv.org/abs/2507.11508v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reasoning Strategies in Large Language Models: Can They Follow, Prefer, and Optimize?", "abstract": "Human reasoning involves different strategies, each suited to specific\nproblems. Prior work shows that large language model (LLMs) tend to favor a\nsingle reasoning strategy, potentially limiting their effectiveness in diverse\nreasoning challenges. In this work, we investigate whether prompting can\ncontrol LLMs reasoning strategies and assess its impact on logical\nproblem-solving. While our experiments show that no single strategy\nconsistently improves accuracy, performance could be enhanced if models could\nadaptively choose the optimal strategy. We propose methods to guide LLMs in\nstrategy selection, highlighting new ways to refine their reasoning abilities.", "published": "2025-07-15 15:47:47", "link": "http://arxiv.org/abs/2507.11423v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Seq vs Seq: An Open Suite of Paired Encoders and Decoders", "abstract": "The large language model (LLM) community focuses almost exclusively on\ndecoder-only language models, since they are easier to use for text generation.\nHowever, a large subset of the community still uses encoder-only models for\ntasks such as classification or retrieval. Previous work has attempted to\ncompare these architectures, but is forced to make comparisons with models that\nhave different numbers of parameters, training techniques, and datasets. We\nintroduce the SOTA open-data Ettin suite of models: paired encoder-only and\ndecoder-only models ranging from 17 million parameters to 1 billion, trained on\nup to 2 trillion tokens. Using the same recipe for both encoder-only and\ndecoder-only models produces SOTA recipes in both categories for their\nrespective sizes, beating ModernBERT as an encoder and Llama 3.2 and SmolLM2 as\ndecoders. Like previous work, we find that encoder-only models excel at\nclassification and retrieval tasks while decoders excel at generative tasks.\nHowever, we show that adapting a decoder model to encoder tasks (and vice\nversa) through continued training is subpar compared to using only the reverse\nobjective (i.e. a 400M encoder outperforms a 1B decoder on MNLI, and vice versa\nfor generative tasks). We open-source all artifacts of this study including\ntraining data, training order segmented by checkpoint, and 200+ checkpoints to\nallow future work to analyze or extend all aspects of training.", "published": "2025-07-15 15:31:51", "link": "http://arxiv.org/abs/2507.11412v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "KisMATH: Do LLMs Have Knowledge of Implicit Structures in Mathematical Reasoning?", "abstract": "Chain-of-thought traces have been shown to improve performance of large\nlanguage models in a plethora of reasoning tasks, yet there is no consensus on\nthe mechanism through which this performance boost is achieved. To shed more\nlight on this, we introduce Causal CoT Graphs (CCGs), which are directed\nacyclic graphs automatically extracted from reasoning traces that model\nfine-grained causal dependencies in the language model output. A collection of\n$1671$ mathematical reasoning problems from MATH500, GSM8K and AIME, and their\nassociated CCGs are compiled into our dataset -- \\textbf{KisMATH}. Our detailed\nempirical analysis with 15 open-weight LLMs shows that (i) reasoning nodes in\nthe CCG are mediators for the final answer, a condition necessary for\nreasoning; and (ii) LLMs emphasise reasoning paths given by the CCG, indicating\nthat models internally realise structures akin to our graphs. KisMATH enables\ncontrolled, graph-aligned interventions and opens up avenues for further\ninvestigation into the role of chain-of-thought in LLM reasoning.", "published": "2025-07-15 15:28:37", "link": "http://arxiv.org/abs/2507.11408v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "EXAONE 4.0: Unified Large Language Models Integrating Non-reasoning and Reasoning Modes", "abstract": "This technical report introduces EXAONE 4.0, which integrates a Non-reasoning\nmode and a Reasoning mode to achieve both the excellent usability of EXAONE 3.5\nand the advanced reasoning abilities of EXAONE Deep. To pave the way for the\nagentic AI era, EXAONE 4.0 incorporates essential features such as agentic tool\nuse, and its multilingual capabilities are extended to support Spanish in\naddition to English and Korean. The EXAONE 4.0 model series consists of two\nsizes: a mid-size 32B model optimized for high performance, and a small-size\n1.2B model designed for on-device applications. The EXAONE 4.0 demonstrates\nsuperior performance compared to open-weight models in its class and remains\ncompetitive even against frontier-class models. The models are publicly\navailable for research purposes and can be easily downloaded via\nhttps://huggingface.co/LGAI-EXAONE.", "published": "2025-07-15 15:24:51", "link": "http://arxiv.org/abs/2507.11407v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DCR: Quantifying Data Contamination in LLMs Evaluation", "abstract": "The rapid advancement of large language models (LLMs) has heightened concerns\nabout benchmark data contamination (BDC), where models inadvertently memorize\nevaluation data, inflating performance metrics and undermining genuine\ngeneralization assessment. This paper introduces the Data Contamination Risk\n(DCR) framework, a lightweight, interpretable pipeline designed to detect and\nquantify BDC across four granular levels: semantic, informational, data, and\nlabel. By synthesizing contamination scores via a fuzzy inference system, DCR\nproduces a unified DCR Factor that adjusts raw accuracy to reflect\ncontamination-aware performance. Validated on 9 LLMs (0.5B-72B) across\nsentiment analysis, fake news detection, and arithmetic reasoning tasks, the\nDCR framework reliably diagnoses contamination severity and with accuracy\nadjusted using the DCR Factor to within 4% average error across the three\nbenchmarks compared to the uncontaminated baseline. Emphasizing computational\nefficiency and transparency, DCR provides a practical tool for integrating\ncontamination assessment into routine evaluations, fostering fairer comparisons\nand enhancing the credibility of LLM benchmarking practices.", "published": "2025-07-15 15:23:53", "link": "http://arxiv.org/abs/2507.11405v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Addressing Data Imbalance in Transformer-Based Multi-Label Emotion Detection with Weighted Loss", "abstract": "This paper explores the application of a simple weighted loss function to\nTransformer-based models for multi-label emotion detection in SemEval-2025\nShared Task 11. Our approach addresses data imbalance by dynamically adjusting\nclass weights, thereby enhancing performance on minority emotion classes\nwithout the computational burden of traditional resampling methods. We evaluate\nBERT, RoBERTa, and BART on the BRIGHTER dataset, using evaluation metrics such\nas Micro F1, Macro F1, ROC-AUC, Accuracy, and Jaccard similarity coefficients.\nThe results demonstrate that the weighted loss function improves performance on\nhigh-frequency emotion classes but shows limited impact on minority classes.\nThese findings underscore both the effectiveness and the challenges of applying\nthis approach to imbalanced multi-label emotion detection.", "published": "2025-07-15 14:53:33", "link": "http://arxiv.org/abs/2507.11384v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What is the Best Process Model Representation? A Comparative Analysis for Process Modeling with Large Language Models", "abstract": "Large Language Models (LLMs) are increasingly applied for Process Modeling\n(PMo) tasks such as Process Model Generation (PMG). To support these tasks,\nresearchers have introduced a variety of Process Model Representations (PMRs)\nthat serve as model abstractions or generation targets. However, these PMRs\ndiffer widely in structure, complexity, and usability, and have never been\nsystematically compared. Moreover, recent PMG approaches rely on distinct\nevaluation strategies and generation techniques, making comparison difficult.\nThis paper presents the first empirical study that evaluates multiple PMRs in\nthe context of PMo with LLMs. We introduce the PMo Dataset, a new dataset\ncontaining 55 process descriptions paired with models in nine different PMRs.\nWe evaluate PMRs along two dimensions: suitability for LLM-based PMo and\nperformance on PMG. \\textit{Mermaid} achieves the highest overall score across\nsix PMo criteria, whereas \\textit{BPMN text} delivers the best PMG results in\nterms of process element similarity.", "published": "2025-07-15 14:26:50", "link": "http://arxiv.org/abs/2507.11356v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automated Novelty Evaluation of Academic Paper: A Collaborative Approach Integrating Human and Large Language Model Knowledge", "abstract": "Novelty is a crucial criterion in the peer review process for evaluating\nacademic papers. Traditionally, it's judged by experts or measure by unique\nreference combinations. Both methods have limitations: experts have limited\nknowledge, and the effectiveness of the combination method is uncertain.\nMoreover, it's unclear if unique citations truly measure novelty. The large\nlanguage model (LLM) possesses a wealth of knowledge, while human experts\npossess judgment abilities that the LLM does not possess. Therefore, our\nresearch integrates the knowledge and abilities of LLM and human experts to\naddress the limitations of novelty assessment. The most common novelty in\nacademic papers is the introduction of new methods. In this paper, we propose\nleveraging human knowledge and LLM to assist pretrained language models (PLMs,\ne.g. BERT etc.) in predicting the method novelty of papers. Specifically, we\nextract sentences related to the novelty of the academic paper from peer review\nreports and use LLM to summarize the methodology section of the academic paper,\nwhich are then used to fine-tune PLMs. In addition, we have designed a\ntext-guided fusion module with novel Sparse-Attention to better integrate human\nand LLM knowledge. We compared the method we proposed with a large number of\nbaselines. Extensive experiments demonstrate that our method achieves superior\nperformance.", "published": "2025-07-15 14:03:55", "link": "http://arxiv.org/abs/2507.11330v1", "categories": ["cs.CL", "cs.AI", "cs.DL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Internal Value Alignment in Large Language Models through Controlled Value Vector Activation", "abstract": "Aligning Large Language Models (LLMs) with human values has attracted\nincreasing attention since it provides clarity, transparency, and the ability\nto adapt to evolving scenarios. In this paper, we introduce a Controlled Value\nVector Activation (ConVA) method that directly aligns the internal values of\nLLMs by interpreting how a value is encoded in their latent representations and\nmodifies relevant activations to ensure consistent values in LLMs. To ensure an\naccurate and unbiased interpretation, we propose a context-controlled value\nvector identification method. To consistently control values without\nsacrificing model performance, we introduce a gated value vector activation\nmethod for effective and minimum degree of value control. Experiments show that\nour method achieves the highest control success rate across 10 basic values\nwithout hurting LLM performance and fluency, and ensures target values even\nwith opposite and potentially malicious input prompts. Source code and data are\navailable at~ https://github.com/hr-jin/ConVA.", "published": "2025-07-15 13:48:35", "link": "http://arxiv.org/abs/2507.11316v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Dr.Copilot: A Multi-Agent Prompt Optimized Assistant for Improving Patient-Doctor Communication in Romanian", "abstract": "Text-based telemedicine has become increasingly common, yet the quality of\nmedical advice in doctor-patient interactions is often judged more on how\nadvice is communicated rather than its clinical accuracy. To address this, we\nintroduce Dr.Copilot , a multi-agent large language model (LLM) system that\nsupports Romanian-speaking doctors by evaluating and enhancing the presentation\nquality of their written responses. Rather than assessing medical correctness,\nDr.Copilot provides feedback along 17 interpretable axes. The system comprises\nof three LLM agents with prompts automatically optimized via DSPy. Designed\nwith low-resource Romanian data and deployed using open-weight models, it\ndelivers real-time specific feedback to doctors within a telemedicine platform.\nEmpirical evaluations and live deployment with 41 doctors show measurable\nimprovements in user reviews and response quality, marking one of the first\nreal-world deployments of LLMs in Romanian medical settings.", "published": "2025-07-15 13:26:49", "link": "http://arxiv.org/abs/2507.11299v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fine-Grained Chinese Hate Speech Understanding: Span-Level Resources, Coded Term Lexicon, and Enhanced Detection Frameworks", "abstract": "The proliferation of hate speech has inflicted significant societal harm,\nwith its intensity and directionality closely tied to specific targets and\narguments. In recent years, numerous machine learning-based methods have been\ndeveloped to detect hateful comments on online platforms automatically.\nHowever, research on Chinese hate speech detection lags behind, and\ninterpretability studies face two major challenges: first, the scarcity of\nspan-level fine-grained annotated datasets limits models' deep semantic\nunderstanding of hate speech; second, insufficient research on identifying and\ninterpreting coded hate speech restricts model explainability in complex\nreal-world scenarios. To address these, we make the following contributions:\n(1) We introduce the Span-level Target-Aware Toxicity Extraction dataset (STATE\nToxiCN), the first span-level Chinese hate speech dataset, and evaluate the\nhate semantic understanding of existing models using it. (2) We conduct the\nfirst comprehensive study on Chinese coded hate terms, LLMs' ability to\ninterpret hate semantics. (3) We propose a method to integrate an annotated\nlexicon into models, significantly enhancing hate speech detection performance.\nOur work provides valuable resources and insights to advance the\ninterpretability of Chinese hate speech detection research.", "published": "2025-07-15 13:19:18", "link": "http://arxiv.org/abs/2507.11292v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FMC: Formalization of Natural Language Mathematical Competition Problems", "abstract": "Efficient and accurate autoformalization methods, which leverage large-scale\ndatasets of extensive natural language mathematical problems to construct\nformal language datasets, are key to advancing formal mathematical reasoning.\nIn this paper, we propose an autoformalization pipeline based on large language\nmodels with error feedback, achieving a fully automatic and training-free\nformalization approach. Using this pipeline, we curate an Olympiad-level\ndataset aligning natural language problems with Lean formalizations. The\ndataset comprises $3,922$ mathematical problems in natural language and $9,787$\nin Lean, of which $64.46\\%$ were assessed as at least above-average quality,\nmaking it suitable as a benchmark for automated theorem provers. Additionally,\nwe investigate the formalization and reasoning capabilities of various LLMs and\nempirically demonstrate that few-shot learning, error feedback, and increasing\nsampling numbers enhance the autoformalization process. Experiments of three\nautomated theorem provers on the \\dataset\\ dataset also highlight its\nchallenging nature and its value as a benchmark for formal reasoning tasks.", "published": "2025-07-15 12:52:47", "link": "http://arxiv.org/abs/2507.11275v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KV-Latent: Dimensional-level KV Cache Reduction with Frequency-aware Rotary Positional Embedding", "abstract": "Large language models (LLMs) based on Transformer Decoders have become the\npreferred choice for conversational generative AI. Despite the overall\nsuperiority of the Decoder architecture, the gradually increasing Key-Value\n(KV) cache during inference has emerged as a primary efficiency bottleneck,\nboth in aspects of memory consumption and data transfer bandwidth limitations.\nTo address these challenges, we propose a paradigm called KV-Latent. By\ndown-sampling the Key-Value vector dimensions into a latent space, we can\nsignificantly reduce the KV Cache footprint and improve inference speed, only\nwith a small amount of extra training, less than 1\\% of pre-training takes.\nBesides, we enhanced the stability of Rotary Positional Embedding applied on\nlower-dimensional vectors by modifying its frequency sampling mechanism,\navoiding noise introduced by higher frequencies while retaining position\nattenuation. Our experiments, including both models with Grouped Query\nAttention and those without, have yielded satisfactory results. Finally, we\nconducted comparative experiments to study the impact of separately reducing\nKey and Value components on model's performance. Our approach allows for the\nconstruction of more efficient language model systems, and opens the new\npossibility on KV Cache saving and efficient LLMs. Our code is available at\nhttps://github.com/ShiLuohe/KV-Latent.", "published": "2025-07-15 12:52:12", "link": "http://arxiv.org/abs/2507.11273v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sparse Autoencoders Can Capture Language-Specific Concepts Across Diverse Languages", "abstract": "Understanding the multilingual mechanisms of large language models (LLMs)\nprovides insight into how they process different languages, yet this remains\nchallenging. Existing studies often focus on individual neurons, but their\npolysemantic nature makes it difficult to isolate language-specific units from\ncross-lingual representations. To address this, we explore sparse autoencoders\n(SAEs) for their ability to learn monosemantic features that represent concrete\nand abstract concepts across languages in LLMs. While some of these features\nare language-independent, the presence of language-specific features remains\nunderexplored. In this work, we introduce SAE-LAPE, a method based on feature\nactivation probability, to identify language-specific features within the\nfeed-forward network. We find that many such features predominantly appear in\nthe middle to final layers of the model and are interpretable. These features\ninfluence the model's multilingual performance and language output and can be\nused for language identification with performance comparable to fastText along\nwith more interpretability. Our code is available at\nhttps://github.com/LyzanderAndrylie/language-specific-features .", "published": "2025-07-15 12:00:30", "link": "http://arxiv.org/abs/2507.11230v1", "categories": ["cs.CL", "68T50"], "primary_category": "cs.CL"}
{"title": "An Agentic Flow for Finite State Machine Extraction using Prompt Chaining", "abstract": "Finite-State Machines (FSMs) are critical for modeling the operational logic\nof network protocols, enabling verification, analysis, and vulnerability\ndiscovery. However, existing FSM extraction techniques face limitations such as\nscalability, incomplete coverage, and ambiguity in natural language\nspecifications. In this paper, we propose FlowFSM, a novel agentic framework\nthat leverages Large Language Models (LLMs) combined with prompt chaining and\nchain-of-thought reasoning to extract accurate FSMs from raw RFC documents.\nFlowFSM systematically processes protocol specifications, identifies state\ntransitions, and constructs structured rule-books by chaining agent outputs.\nExperimental evaluation across FTP and RTSP protocols demonstrates that FlowFSM\nachieves high extraction precision while minimizing hallucinated transitions,\nshowing promising results. Our findings highlight the potential of agent-based\nLLM systems in the advancement of protocol analysis and FSM inference for\ncybersecurity and reverse engineering applications.", "published": "2025-07-15 11:50:25", "link": "http://arxiv.org/abs/2507.11222v1", "categories": ["cs.CL", "cs.AI", "cs.NI"], "primary_category": "cs.CL"}
{"title": "EsBBQ and CaBBQ: The Spanish and Catalan Bias Benchmarks for Question Answering", "abstract": "Previous literature has largely shown that Large Language Models (LLMs)\nperpetuate social biases learnt from their pre-training data. Given the notable\nlack of resources for social bias evaluation in languages other than English,\nand for social contexts outside of the United States, this paper introduces the\nSpanish and the Catalan Bias Benchmarks for Question Answering (EsBBQ and\nCaBBQ). Based on the original BBQ, these two parallel datasets are designed to\nassess social bias across 10 categories using a multiple-choice QA setting, now\nadapted to the Spanish and Catalan languages and to the social context of\nSpain. We report evaluation results on different LLMs, factoring in model\nfamily, size and variant. Our results show that models tend to fail to choose\nthe correct answer in ambiguous scenarios, and that high QA accuracy often\ncorrelates with greater reliance on social biases.", "published": "2025-07-15 11:37:30", "link": "http://arxiv.org/abs/2507.11216v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Temperature and Persona Shape LLM Agent Consensus With Minimal Accuracy Gains in Qualitative Coding", "abstract": "Large Language Models (LLMs) enable new possibilities for qualitative\nresearch at scale, including coding and data annotation. While multi-agent\nsystems (MAS) can emulate human coding workflows, their benefits over\nsingle-agent coding remain poorly understood. We conducted an experimental\nstudy of how agent persona and temperature shape consensus-building and coding\naccuracy of dialog segments based on a codebook with 8 codes. Our open-source\nMAS mirrors deductive human coding through structured agent discussion and\nconsensus arbitration. Using six open-source LLMs (with 3 to 32 billion\nparameters) and 18 experimental configurations, we analyze over 77,000 coding\ndecisions against a gold-standard dataset of human-annotated transcripts from\nonline math tutoring sessions. Temperature significantly impacted whether and\nwhen consensus was reached across all six LLMs. MAS with multiple personas\n(including neutral, assertive, or empathetic), significantly delayed consensus\nin four out of six LLMs compared to uniform personas. In three of those LLMs,\nhigher temperatures significantly diminished the effects of multiple personas\non consensus. However, neither temperature nor persona pairing lead to robust\nimprovements in coding accuracy. Single agents matched or outperformed MAS\nconsensus in most conditions. Only one model (OpenHermesV2:7B) and code\ncategory showed above-chance gains from MAS deliberation when temperature was\n0.5 or lower and especially when the agents included at least one assertive\npersona. Qualitative analysis of MAS collaboration for these configurations\nsuggests that MAS may nonetheless aid in narrowing ambiguous code applications\nthat could improve codebooks and human-AI coding. We contribute new insight\ninto the limits of LLM-based qualitative methods, challenging the notion that\ndiverse MAS personas lead to better outcomes. We open-source our MAS and\nexperimentation code.", "published": "2025-07-15 11:06:32", "link": "http://arxiv.org/abs/2507.11198v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "What Should LLMs Forget? Quantifying Personal Data in LLMs for Right-to-Be-Forgotten Requests", "abstract": "Large Language Models (LLMs) can memorize and reveal personal information,\nraising concerns regarding compliance with the EU's GDPR, particularly the\nRight to Be Forgotten (RTBF). Existing machine unlearning methods assume the\ndata to forget is already known but do not address how to identify which\nindividual-fact associations are stored in the model. Privacy auditing\ntechniques typically operate at the population level or target a small set of\nidentifiers, limiting applicability to individual-level data inquiries. We\nintroduce WikiMem, a dataset of over 5,000 natural language canaries covering\n243 human-related properties from Wikidata, and a model-agnostic metric to\nquantify human-fact associations in LLMs. Our approach ranks ground-truth\nvalues against counterfactuals using calibrated negative log-likelihood across\nparaphrased prompts. We evaluate 200 individuals across 15 LLMs (410M-70B\nparameters), showing that memorization correlates with subject web presence and\nmodel scale. We provide a foundation for identifying memorized personal data in\nLLMs at the individual level, enabling the dynamic construction of forget sets\nfor machine unlearning and RTBF requests.", "published": "2025-07-15 09:28:44", "link": "http://arxiv.org/abs/2507.11128v1", "categories": ["cs.CL", "cs.CY", "cs.LG", "I.2.6; H.2.8"], "primary_category": "cs.CL"}
{"title": "MSA at ImageCLEF 2025 Multimodal Reasoning: Multilingual Multimodal Reasoning With Ensemble Vision Language Models", "abstract": "We present a robust ensemble-based system for multilingual multimodal\nreasoning, designed for the ImageCLEF 2025 EXAMS V challenge. Our approach\nintegrates Gemini 2.5 Flash for visual description, Gemini 1.5 Pro for caption\nrefinement and consistency checks, and Gemini 2.5 Pro as a reasoner which\nhandles final answer selection, all coordinated through carefully engineered\nfew-shot and zero-shot prompts. We conducted an extensive ablation study,\ntraining several large language models (Gemini 2.5 Flash, Phi 4, Gemma 3,\nMistral) on an English dataset and its multilingual augmented version.\nAdditionally, we evaluated Gemini 2.5 Flash in a zero-shot setting for\ncomparison and found it to substantially outperform the trained models. Prompt\ndesign also proved critical: enforcing concise, language-normalized formats and\nprohibiting explanatory text boosted model accuracy on the English validation\nset from 55.9% to 61.7%. On the official leaderboard, our system (Team MSA)\nachieved first place overall in the multilingual track with 81.4% accuracy, and\nled 11 out of 13 individual language tracks, with top results such as 95.07%\nfor Croatian and 92.12% for Italian. These findings highlight that lightweight\nOCR-VLM ensembles, when paired with precise prompt strategies and cross-lingual\naugmentation, can outperform heavier end-to-end models in high-stakes,\nmultilingual educational settings.", "published": "2025-07-15 09:05:05", "link": "http://arxiv.org/abs/2507.11114v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Trigger Poisoning Amplifies Backdoor Vulnerabilities in LLMs", "abstract": "Recent studies have shown that Large Language Models (LLMs) are vulnerable to\ndata poisoning attacks, where malicious training examples embed hidden\nbehaviours triggered by specific input patterns. However, most existing works\nassume a phrase and focus on the attack's effectiveness, offering limited\nunderstanding of trigger mechanisms and how multiple triggers interact within\nthe model. In this paper, we present a framework for studying poisoning in\nLLMs. We show that multiple distinct backdoor triggers can coexist within a\nsingle model without interfering with each other, enabling adversaries to embed\nseveral triggers concurrently. Using multiple triggers with high embedding\nsimilarity, we demonstrate that poisoned triggers can achieve robust activation\neven when tokens are substituted or separated by long token spans. Our findings\nexpose a broader and more persistent vulnerability surface in LLMs. To mitigate\nthis threat, we propose a post hoc recovery method that selectively retrains\nspecific model components based on a layer-wise weight difference analysis. Our\nmethod effectively removes the trigger behaviour with minimal parameter\nupdates, presenting a practical and efficient defence against multi-trigger\npoisoning.", "published": "2025-07-15 09:04:30", "link": "http://arxiv.org/abs/2507.11112v1", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Devil behind the mask: An emergent safety vulnerability of Diffusion LLMs", "abstract": "Diffusion-based large language models (dLLMs) have recently emerged as a\npowerful alternative to autoregressive LLMs, offering faster inference and\ngreater interactivity via parallel decoding and bidirectional modeling.\nHowever, despite strong performance in code generation and text infilling, we\nidentify a fundamental safety concern: existing alignment mechanisms fail to\nsafeguard dLLMs against context-aware, masked-input adversarial prompts,\nexposing novel vulnerabilities. To this end, we present DIJA, the first\nsystematic study and jailbreak attack framework that exploits unique safety\nweaknesses of dLLMs. Specifically, our proposed DIJA constructs adversarial\ninterleaved mask-text prompts that exploit the text generation mechanisms of\ndLLMs, i.e., bidirectional modeling and parallel decoding. Bidirectional\nmodeling drives the model to produce contextually consistent outputs for masked\nspans, even when harmful, while parallel decoding limits model dynamic\nfiltering and rejection sampling of unsafe content. This causes standard\nalignment mechanisms to fail, enabling harmful completions in alignment-tuned\ndLLMs, even when harmful behaviors or unsafe instructions are directly exposed\nin the prompt. Through comprehensive experiments, we demonstrate that DIJA\nsignificantly outperforms existing jailbreak methods, exposing a previously\noverlooked threat surface in dLLM architectures. Notably, our method achieves\nup to 100% keyword-based ASR on Dream-Instruct, surpassing the strongest prior\nbaseline, ReNeLLM, by up to 78.5% in evaluator-based ASR on JailbreakBench and\nby 37.7 points in StrongREJECT score, while requiring no rewriting or hiding of\nharmful content in the jailbreak prompt. Our findings underscore the urgent\nneed for rethinking safety alignment in this emerging class of language models.\nCode is available at https://github.com/ZichenWen1/DIJA.", "published": "2025-07-15 08:44:46", "link": "http://arxiv.org/abs/2507.11097v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond Traditional Algorithms: Leveraging LLMs for Accurate Cross-Border Entity Identification", "abstract": "The growing prevalence of cross-border financial activities in global markets\nhas underscored the necessity of accurately identifying and classifying foreign\nentities. This practice is essential within the Spanish financial system for\nensuring robust risk management, regulatory adherence, and the prevention of\nfinancial misconduct. This process involves a labor-intensive entity-matching\ntask, where entities need to be validated against available reference sources.\nChallenges arise from linguistic variations, special characters, outdated\nnames, and changes in legal forms, complicating traditional matching algorithms\nlike Jaccard, cosine, and Levenshtein distances. These methods struggle with\ncontextual nuances and semantic relationships, leading to mismatches. To\naddress these limitations, we explore Large Language Models (LLMs) as a\nflexible alternative. LLMs leverage extensive training to interpret context,\nhandle abbreviations, and adapt to legal transitions. We evaluate traditional\nmethods, Hugging Face-based LLMs, and interface-based LLMs (e.g., Microsoft\nCopilot, Alibaba's Qwen 2.5) using a dataset of 65 Portuguese company cases.\nResults show traditional methods achieve accuracies over 92% but suffer high\nfalse positive rates (20-40%). Interface-based LLMs outperform, achieving\naccuracies above 93%, F1 scores exceeding 96%, and lower false positives\n(40-80%).", "published": "2025-07-15 08:28:24", "link": "http://arxiv.org/abs/2507.11086v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Social Media Sentiments Analysis on the July Revolution in Bangladesh: A Hybrid Transformer Based Machine Learning Approach", "abstract": "The July Revolution in Bangladesh marked a significant student-led mass\nuprising, uniting people across the nation to demand justice, accountability,\nand systemic reform. Social media platforms played a pivotal role in amplifying\npublic sentiment and shaping discourse during this historic mass uprising. In\nthis study, we present a hybrid transformer-based sentiment analysis framework\nto decode public opinion expressed in social media comments during and after\nthe revolution. We used a brand new dataset of 4,200 Bangla comments collected\nfrom social media. The framework employs advanced transformer-based feature\nextraction techniques, including BanglaBERT, mBERT, XLM-RoBERTa, and the\nproposed hybrid XMB-BERT, to capture nuanced patterns in textual data.\nPrinciple Component Analysis (PCA) were utilized for dimensionality reduction\nto enhance computational efficiency. We explored eleven traditional and\nadvanced machine learning classifiers for identifying sentiments. The proposed\nhybrid XMB-BERT with the voting classifier achieved an exceptional accuracy of\n83.7% and outperform other model classifier combinations. This study\nunderscores the potential of machine learning techniques to analyze social\nsentiment in low-resource languages like Bangla.", "published": "2025-07-15 08:26:58", "link": "http://arxiv.org/abs/2507.11084v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SWE-MERA: A Dynamic Benchmark for Agenticly Evaluating Large Language Models on Software Engineering Tasks", "abstract": "The rapid advancement of Large Language Models (LLMs) in software engineering\nhas revealed critical limitations in existing benchmarks, particularly the\nwidely used SWE-bench dataset. Recent studies have uncovered severe data\ncontamination issues, e.g. SWE-bench reports 32.67% of successful patches\ninvolve direct solution leakage and 31.08\\% pass due to inadequate test cases.\nWe introduce SWE-MERA, a dynamic, continuously updated benchmark designed to\naddress these fundamental challenges through an automated collection of\nreal-world GitHub issues and rigorous quality validation. Our approach\nimplements a reliable pipeline that ensures quality while minimizing\ncontamination risks, resulting in approximately 10,000 potential tasks with 300\nsamples currently available. Evaluation using the Aider coding agent\ndemonstrates strong discriminative power in state-of-the-art models. We report\nperformance across a dozen recent LLMs evaluated on tasks collected between\nSeptember 2024 and June 2025.", "published": "2025-07-15 07:52:33", "link": "http://arxiv.org/abs/2507.11059v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "LLM-Augmented Symptom Analysis for Cardiovascular Disease Risk Prediction: A Clinical NLP", "abstract": "Timely identification and accurate risk stratification of cardiovascular\ndisease (CVD) remain essential for reducing global mortality. While existing\nprediction models primarily leverage structured data, unstructured clinical\nnotes contain valuable early indicators. This study introduces a novel\nLLM-augmented clinical NLP pipeline that employs domain-adapted large language\nmodels for symptom extraction, contextual reasoning, and correlation from\nfree-text reports. Our approach integrates cardiovascular-specific fine-tuning,\nprompt-based inference, and entity-aware reasoning. Evaluations on MIMIC-III\nand CARDIO-NLP datasets demonstrate improved performance in precision, recall,\nF1-score, and AUROC, with high clinical relevance (kappa = 0.82) assessed by\ncardiologists. Challenges such as contextual hallucination, which occurs when\nplausible information contracts with provided source, and temporal ambiguity,\nwhich is related with models struggling with chronological ordering of events\nare addressed using prompt engineering and hybrid rule-based verification. This\nwork underscores the potential of LLMs in clinical decision support systems\n(CDSS), advancing early warning systems and enhancing the translation of\npatient narratives into actionable risk assessments.", "published": "2025-07-15 07:32:16", "link": "http://arxiv.org/abs/2507.11052v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Journalism-Guided Agentic In-Context Learning for News Stance Detection", "abstract": "As online news consumption grows, personalized recommendation systems have\nbecome integral to digital journalism. However, these systems risk reinforcing\nfilter bubbles and political polarization by failing to incorporate diverse\nperspectives. Stance detection -- identifying a text's position on a target --\ncan help mitigate this by enabling viewpoint-aware recommendations and\ndata-driven analyses of media bias. Yet, existing stance detection research\nremains largely limited to short texts and high-resource languages. To address\nthese gaps, we introduce \\textsc{K-News-Stance}, the first Korean dataset for\narticle-level stance detection, comprising 2,000 news articles with\narticle-level and 19,650 segment-level stance annotations across 47 societal\nissues. We also propose \\textsc{JoA-ICL}, a \\textbf{Jo}urnalism-guided\n\\textbf{A}gentic \\textbf{I}n-\\textbf{C}ontext \\textbf{L}earning framework that\nemploys a language model agent to predict the stances of key structural\nsegments (e.g., leads, quotes), which are then aggregated to infer the overall\narticle stance. Experiments show that \\textsc{JoA-ICL} outperforms existing\nstance detection methods, highlighting the benefits of segment-level agency in\ncapturing the overall position of long-form news articles. Two case studies\nfurther demonstrate its broader utility in promoting viewpoint diversity in\nnews recommendations and uncovering patterns of media bias.", "published": "2025-07-15 07:22:04", "link": "http://arxiv.org/abs/2507.11049v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "First-Order Error Matters: Accurate Compensation for Quantized Large Language Models", "abstract": "Post-training quantization (PTQ) offers an efficient approach to compressing\nlarge language models (LLMs), significantly reducing memory access and\ncomputational costs. Existing compensation-based weight calibration methods\noften rely on a second-order Taylor expansion to model quantization error,\nunder the assumption that the first-order term is negligible in well-trained\nfull-precision models. However, we reveal that the progressive compensation\nprocess introduces accumulated first-order deviations between latent weights\nand their full-precision counterparts, making this assumption fundamentally\nflawed. To address this, we propose FOEM, a novel PTQ method that explicitly\nincorporates first-order gradient terms to improve quantization error\ncompensation. FOEM approximates gradients by directly computing the difference\nbetween latent and full-precision weights, avoiding the high cost and limited\ngeneralization of backpropagation-based gradient computation. This approach\nintroduces minimal additional computational overhead. Moreover, FOEM leverages\nprecomputed Cholesky factors to efficiently recover the inverse of Hessian\nsubmatrices in real time. Extensive experiments across a wide range of models\nand benchmarks demonstrate that FOEM consistently outperforms the classical\nGPTQ method. In 3-bit weight-only quantization, FOEM reduces the perplexity of\nLlama3-8B by 89.6%, and improves the 5-shot MMLU accuracy of Llama3-70B from\n51.7% to 74.9%, approaching the full-precision performance of 78.6%.\nFurthermore, FOEM can be seamlessly integrated with advanced techniques such as\nGPTAQ and SpinQuant, yielding additional improvements under the challenging\nW4A4KV4 setting, and further narrowing the accuracy gap with full-precision\nbaselines beyond what current state-of-the-art methods achieve. The code is\navailable at https://github.com/Xingyu-Zheng/FOEM.", "published": "2025-07-15 06:18:46", "link": "http://arxiv.org/abs/2507.11017v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Team HUMANE at AVeriTeC 2025: HerO 2 for Efficient Fact Verification", "abstract": "This paper presents HerO 2, Team HUMANE's system for the AVeriTeC shared task\nat the FEVER-25 workshop. HerO 2 is an enhanced version of HerO, the\nbest-performing open-source model from the previous year's challenge. It\nimproves evidence quality through document summarization and answer\nreformulation, optimizes veracity prediction via post-training quantization\nunder computational constraints, and enhances overall system performance by\nintegrating updated language model (LM) backbones. HerO 2 ranked second on the\nleaderboard while achieving the shortest runtime among the top three systems,\ndemonstrating both high efficiency and strong potential for real-world fact\nverification. The code is available at https://github.com/ssu-humane/HerO2.", "published": "2025-07-15 05:42:50", "link": "http://arxiv.org/abs/2507.11004v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mario at EXIST 2025: A Simple Gateway to Effective Multilingual Sexism Detection", "abstract": "This paper presents our approach to EXIST 2025 Task 1, addressing text-based\nsexism detection in English and Spanish tweets through hierarchical Low-Rank\nAdaptation (LoRA) of Llama 3.1 8B. Our method introduces conditional adapter\nrouting that explicitly models label dependencies across three hierarchically\nstructured subtasks: binary sexism identification, source intention detection,\nand multilabel sexism categorization. Unlike conventional LoRA applications\nthat target only attention layers, we apply adaptation to all linear\ntransformations, enhancing the model's capacity to capture task-specific\npatterns. In contrast to complex data processing and ensemble approaches, we\nshow that straightforward parameter-efficient fine-tuning achieves strong\nperformance. We train separate LoRA adapters (rank=16, QLoRA 4-bit) for each\nsubtask using unified multilingual training that leverages Llama 3.1's native\nbilingual capabilities. The method requires minimal preprocessing and uses\nstandard supervised learning. Our multilingual training strategy eliminates the\nneed for separate language-specific models, achieving 1.7-2.4\\% F1 improvements\nthrough cross-lingual transfer. With only 1.67\\% trainable parameters compared\nto full fine-tuning, our approach reduces training time by 75\\% and model\nstorage by 98\\%, while achieving competitive performance across all subtasks\n(ICM-Hard: 0.6774 for binary classification, 0.4991 for intention detection,\n0.6519 for multilabel categorization).", "published": "2025-07-15 05:30:32", "link": "http://arxiv.org/abs/2507.10996v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Teach Me Sign: Stepwise Prompting LLM for Sign Language Production", "abstract": "Large language models, with their strong reasoning ability and rich\nknowledge, have brought revolution to many tasks of AI, but their impact on\nsign language generation remains limited due to its complexity and unique\nrules. In this paper, we propose TEAch Me Sign (TEAM-Sign), treating sign\nlanguage as another natural language. By fine-tuning an LLM, we enable it to\nlearn the correspondence between text and sign language, and facilitate\ngeneration. Considering the differences between sign and spoken language, we\nemploy a stepwise prompting strategy to extract the inherent sign language\nknowledge within the LLM, thereby supporting the learning and generation\nprocess. Experimental results on How2Sign and Phoenix14T datasets demonstrate\nthat our approach effectively leverages both the sign language knowledge and\nreasoning capabilities of LLM to align the different distribution and\ngrammatical rules between sign and spoken language.", "published": "2025-07-15 04:31:52", "link": "http://arxiv.org/abs/2507.10972v1", "categories": ["cs.CL", "cs.CV", "cs.MM"], "primary_category": "cs.CL"}
{"title": "DS@GT at eRisk 2025: From prompts to predictions, benchmarking early depression detection with conversational agent based assessments and temporal attention models", "abstract": "This Working Note summarizes the participation of the DS@GT team in two eRisk\n2025 challenges. For the Pilot Task on conversational depression detection with\nlarge language-models (LLMs), we adopted a prompt-engineering strategy in which\ndiverse LLMs conducted BDI-II-based assessments and produced structured JSON\noutputs. Because ground-truth labels were unavailable, we evaluated cross-model\nagreement and internal consistency. Our prompt design methodology aligned model\noutputs with BDI-II criteria and enabled the analysis of conversational cues\nthat influenced the prediction of symptoms. Our best submission, second on the\nofficial leaderboard, achieved DCHR = 0.50, ADODL = 0.89, and ASHR = 0.27.", "published": "2025-07-15 03:40:46", "link": "http://arxiv.org/abs/2507.10958v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modeling Understanding of Story-Based Analogies Using Large Language Models", "abstract": "Recent advancements in Large Language Models (LLMs) have brought them closer\nto matching human cognition across a variety of tasks. How well do these models\nalign with human performance in detecting and mapping analogies? Prior research\nhas shown that LLMs can extract similarities from analogy problems but lack\nrobust human-like reasoning. Building on Webb, Holyoak, and Lu (2023), the\ncurrent study focused on a story-based analogical mapping task and conducted a\nfine-grained evaluation of LLM reasoning abilities compared to human\nperformance. First, it explored the semantic representation of analogies in\nLLMs, using sentence embeddings to assess whether they capture the similarity\nbetween the source and target texts of an analogy, and the dissimilarity\nbetween the source and distractor texts. Second, it investigated the\neffectiveness of explicitly prompting LLMs to explain analogies. Throughout, we\nexamine whether LLMs exhibit similar performance profiles to those observed in\nhumans by evaluating their reasoning at the level of individual analogies, and\nnot just at the level of overall accuracy (as prior studies have done). Our\nexperiments include evaluating the impact of model size (8B vs. 70B parameters)\nand performance variation across state-of-the-art model architectures such as\nGPT-4 and LLaMA3. This work advances our understanding of the analogical\nreasoning abilities of LLMs and their potential as models of human reasoning.", "published": "2025-07-15 03:40:21", "link": "http://arxiv.org/abs/2507.10957v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "HanjaBridge: Resolving Semantic Ambiguity in Korean LLMs via Hanja-Augmented Pre-Training", "abstract": "Large language models (LLMs) often show poor performance in low-resource\nlanguages like Korean, partly due to unique linguistic challenges such as\nhomophonous Sino-Korean words that are indistinguishable in Hangul script. To\naddress this semantic ambiguity, we propose HanjaBridge, a novel\nmeaning-injection technique integrated into a continual pre-training (CPT)\nframework. Instead of deterministically mapping a word to a single Hanja\n(Chinese character), HanjaBridge presents the model with all possible Hanja\ncandidates for a given homograph, encouraging the model to learn contextual\ndisambiguation. This process is paired with token-level knowledge distillation\nto prevent catastrophic forgetting. Experimental results show that HanjaBridge\nsignificantly improves Korean language understanding, achieving a 21\\% relative\nimprovement on the KoBALT benchmark. Notably, by reinforcing semantic alignment\nbetween Korean and Chinese through shared Hanja, we observe a strong positive\ncross-lingual transfer. Furthermore, these gains persist even when Hanja\naugmentation is omitted at inference time, ensuring practical efficiency with\nno additional run-time cost.", "published": "2025-07-15 02:26:47", "link": "http://arxiv.org/abs/2507.10920v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "How Stylistic Similarity Shapes Preferences in Dialogue Dataset with User and Third Party Evaluations", "abstract": "Recent advancements in dialogue generation have broadened the scope of\nhuman-bot interactions, enabling not only contextually appropriate responses\nbut also the analysis of human affect and sensitivity. While prior work has\nsuggested that stylistic similarity between user and system may enhance user\nimpressions, the distinction between subjective and objective similarity is\noften overlooked. To investigate this issue, we introduce a novel dataset that\nincludes users' preferences, subjective stylistic similarity based on users'\nown perceptions, and objective stylistic similarity annotated by third party\nevaluators in open-domain dialogue settings. Analysis using the constructed\ndataset reveals a strong positive correlation between subjective stylistic\nsimilarity and user preference. Furthermore, our analysis suggests an important\nfinding: users' subjective stylistic similarity differs from third party\nobjective similarity. This underscores the importance of distinguishing between\nsubjective and objective evaluations and understanding the distinct aspects\neach captures when analyzing the relationship between stylistic similarity and\nuser preferences. The dataset presented in this paper is available online.", "published": "2025-07-15 02:19:52", "link": "http://arxiv.org/abs/2507.10918v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LiLM-RDB-SFC: Lightweight Language Model with Relational Database-Guided DRL for Optimized SFC Provisioning", "abstract": "Effective management of Service Function Chains (SFCs) and optimal Virtual\nNetwork Function (VNF) placement are critical challenges in modern\nSoftware-Defined Networking (SDN) and Network Function Virtualization (NFV)\nenvironments. Although Deep Reinforcement Learning (DRL) is widely adopted for\ndynamic network decision-making, its inherent dependency on structured data and\nfixed action rules often limits adaptability and responsiveness, particularly\nunder unpredictable network conditions. This paper introduces LiLM-RDB-SFC, a\nnovel approach combining Lightweight Language Model (LiLM) with Relational\nDatabase (RDB) to answer network state queries to guide DRL model for efficient\nSFC provisioning. Our proposed approach leverages two LiLMs, Bidirectional and\nAuto-Regressive Transformers (BART) and the Fine-tuned Language Net T5\n(FLAN-T5), to interpret network data and support diverse query types related to\nSFC demands, data center resources, and VNF availability. Results demonstrate\nthat FLAN-T5 outperforms BART with a lower test loss (0.00161 compared to\n0.00734), higher accuracy (94.79% compared to 80.2%), and less processing time\n(2h 2min compared to 2h 38min). Moreover, when compared to the large language\nmodel SQLCoder, FLAN-T5 matches the accuracy of SQLCoder while cutting\nprocessing time by 96% (SQLCoder: 54 h 43 min; FLAN-T5: 2 h 2 min).", "published": "2025-07-15 01:42:44", "link": "http://arxiv.org/abs/2507.10903v1", "categories": ["cs.NI", "cs.CL", "cs.LG"], "primary_category": "cs.NI"}
{"title": "NavComposer: Composing Language Instructions for Navigation Trajectories through Action-Scene-Object Modularization", "abstract": "Language-guided navigation is a cornerstone of embodied AI, enabling agents\nto interpret language instructions and navigate complex environments. However,\nexpert-provided instructions are limited in quantity, while synthesized\nannotations often lack quality, making them insufficient for large-scale\nresearch. To address this, we propose NavComposer, a novel framework for\nautomatically generating high-quality navigation instructions. NavComposer\nexplicitly decomposes semantic entities such as actions, scenes, and objects,\nand recomposes them into natural language instructions. Its modular\narchitecture allows flexible integration of state-of-the-art techniques, while\nthe explicit use of semantic entities enhances both the richness and accuracy\nof instructions. Moreover, it operates in a data-agnostic manner, supporting\nadaptation to diverse navigation trajectories without domain-specific training.\nComplementing NavComposer, we introduce NavInstrCritic, a comprehensive\nannotation-free evaluation system that assesses navigation instructions on\nthree dimensions: contrastive matching, semantic consistency, and linguistic\ndiversity. NavInstrCritic provides a holistic evaluation of instruction\nquality, addressing limitations of traditional metrics that rely heavily on\nexpert annotations. By decoupling instruction generation and evaluation from\nspecific navigation agents, our method enables more scalable and generalizable\nresearch. Extensive experiments provide direct and practical evidence for the\neffectiveness of our method.", "published": "2025-07-15 01:20:22", "link": "http://arxiv.org/abs/2507.10894v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Domain-Adaptive Small Language Models for Structured Tax Code Prediction", "abstract": "Every day, multinational firms process thousands of transactions, each of\nwhich must adhere to tax regulations that vary by jurisdiction and are often\nnuanced. The determination of product and service tax codes, such as HSN or SAC\nis a major use case in Tax compliance. An accurate determination of such codes\nis imperative to avoid any tax penalties. This paper proposes a domain-adaptive\nsmall language model (SLM) with an encoder-decoder architecture for the\nenhanced prediction of product and service tax codes. In this approach, we\naddress the problem of predicting hierarchical tax code sequences using\nunstructured product and services data. We employ an SLM based upon\nencoder-decoder architecture as this enables sequential generation of tax codes\nto capture the hierarchical dependencies present within the tax codes. Our\nexperiments demonstrate that encoder-decoder SLMs can be successfully applied\nto the sequential prediction of structured tax codes, a domain that remains\ncomparatively unexplored in current NLP research. In this paper, we demonstrate\nthe superior performance of the domain-adaptive encoder-decoder SLMs over flat\nclassifiers when applied to the Harmonized System of Nomenclature (HSN), and\nachieve superior results compared to decoder-only and encoder-only\narchitectures for structured sequence generation tasks. This approach can also\nbe scaled to other government-mandated tax commodity codes, such as United\nNations Standard Products and Services Codes (UNSPSC), or Brazil's Nomenclatura\nComum do Mercosul (NCM).", "published": "2025-07-15 00:46:01", "link": "http://arxiv.org/abs/2507.10880v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Streaming 4D Visual Geometry Transformer", "abstract": "Perceiving and reconstructing 4D spatial-temporal geometry from videos is a\nfundamental yet challenging computer vision task. To facilitate interactive and\nreal-time applications, we propose a streaming 4D visual geometry transformer\nthat shares a similar philosophy with autoregressive large language models. We\nexplore a simple and efficient design and employ a causal transformer\narchitecture to process the input sequence in an online manner. We use temporal\ncausal attention and cache the historical keys and values as implicit memory to\nenable efficient streaming long-term 4D reconstruction. This design can handle\nreal-time 4D reconstruction by incrementally integrating historical information\nwhile maintaining high-quality spatial consistency. For efficient training, we\npropose to distill knowledge from the dense bidirectional visual geometry\ngrounded transformer (VGGT) to our causal model. For inference, our model\nsupports the migration of optimized efficient attention operator (e.g.,\nFlashAttention) from the field of large language models. Extensive experiments\non various 4D geometry perception benchmarks demonstrate that our model\nincreases the inference speed in online scenarios while maintaining competitive\nperformance, paving the way for scalable and interactive 4D vision systems.\nCode is available at: https://github.com/wzzheng/StreamVGGT.", "published": "2025-07-15 17:59:57", "link": "http://arxiv.org/abs/2507.11539v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "How Many Instructions Can LLMs Follow at Once?", "abstract": "Production-grade LLM systems require robust adherence to dozens or even\nhundreds of instructions simultaneously. However, the instruction-following\ncapabilities of LLMs at high instruction densities have not yet been\ncharacterized, as existing benchmarks only evaluate models on tasks with a\nsingle or few instructions. We introduce IFScale, a simple benchmark of 500\nkeyword-inclusion instructions for a business report writing task to measure\nhow instruction-following performance degrades as instruction density\nincreases. We evaluate 20 state-of-the-art models across seven major providers\nand find that even the best frontier models only achieve 68% accuracy at the\nmax density of 500 instructions. Our analysis reveals model size and reasoning\ncapability to correlate with 3 distinct performance degradation patterns, bias\ntowards earlier instructions, and distinct categories of instruction-following\nerrors. Our insights can help inform design of instruction-dense prompts in\nreal-world applications and highlight important performance-latency tradeoffs.\nWe open-source the benchmark and all results for further analysis at\nhttps://distylai.github.io/IFScale.", "published": "2025-07-15 17:59:42", "link": "http://arxiv.org/abs/2507.11538v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "DrafterBench: Benchmarking Large Language Models for Tasks Automation in Civil Engineering", "abstract": "Large Language Model (LLM) agents have shown great potential for solving\nreal-world problems and promise to be a solution for tasks automation in\nindustry. However, more benchmarks are needed to systematically evaluate\nautomation agents from an industrial perspective, for example, in Civil\nEngineering. Therefore, we propose DrafterBench for the comprehensive\nevaluation of LLM agents in the context of technical drawing revision, a\nrepresentation task in civil engineering. DrafterBench contains twelve types of\ntasks summarized from real-world drawing files, with 46 customized\nfunctions/tools and 1920 tasks in total. DrafterBench is an open-source\nbenchmark to rigorously test AI agents' proficiency in interpreting intricate\nand long-context instructions, leveraging prior knowledge, and adapting to\ndynamic instruction quality via implicit policy awareness. The toolkit\ncomprehensively assesses distinct capabilities in structured data\ncomprehension, function execution, instruction following, and critical\nreasoning. DrafterBench offers detailed analysis of task accuracy and error\nstatistics, aiming to provide deeper insight into agent capabilities and\nidentify improvement targets for integrating LLMs in engineering applications.\nOur benchmark is available at https://github.com/Eason-Li-AIS/DrafterBench,\nwith the test set hosted at\nhttps://huggingface.co/datasets/Eason666/DrafterBench.", "published": "2025-07-15 17:56:04", "link": "http://arxiv.org/abs/2507.11527v1", "categories": ["cs.AI", "cs.CE"], "primary_category": "cs.AI"}
{"title": "Recursive Bound-Constrained AdaGrad with Applications to Multilevel and Domain Decomposition Minimization", "abstract": "Two OFFO (Objective-Function Free Optimization) noise tolerant algorithms are\npresented that handle bound constraints, inexact gradients and use second-order\ninformation when available.The first is a multi-level method exploiting a\nhierarchical description of the problem and the second is a\ndomain-decomposition method covering the standard addditive Schwarz\ndecompositions. Both are generalizations of the first-order AdaGrad algorithm\nfor unconstrained optimization. Because these algorithms share a common\ntheoretical framework, a single convergence/complexity theory is provided which\ncovers them both. Its main result is that, with high probability, both methods\nneed at most $O(\\epsilon^{-2})$ iterations and noisy gradient evaluations to\ncompute an $\\epsilon$-approximate first-order critical point of the\nbound-constrained problem. Extensive numerical experiments are discussed on\napplications ranging from PDE-based problems to deep neural network training,\nillustrating their remarkable computational efficiency.", "published": "2025-07-15 17:32:10", "link": "http://arxiv.org/abs/2507.11513v1", "categories": ["math.OC", "cs.AI", "cs.NA", "math.NA", "49K20, 65M55, 65Y20, 68Q25, 68T05, 90C26, 90C30", "F.2.1; G.1.8; I.2.5"], "primary_category": "math.OC"}
{"title": "COLIBRI Fuzzy Model: Color Linguistic-Based Representation and Interpretation", "abstract": "Colors are omnipresent in today's world and play a vital role in how humans\nperceive and interact with their surroundings. However, it is challenging for\ncomputers to imitate human color perception. This paper introduces the Human\nPerception-Based Fuzzy Color Model, COLIBRI (Color Linguistic-Based\nRepresentation and Interpretation), designed to bridge the gap between\ncomputational color representations and human visual perception. The proposed\nmodel uses fuzzy sets and logic to create a framework for color categorization.\nUsing a three-phase experimental approach, the study first identifies\ndistinguishable color stimuli for hue, saturation, and intensity through\npreliminary experiments, followed by a large-scale human categorization survey\ninvolving more than 1000 human subjects. The resulting data are used to extract\nfuzzy partitions and generate membership functions that reflect real-world\nperceptual uncertainty. The model incorporates a mechanism for adaptation that\nallows refinement based on feedback and contextual changes. Comparative\nevaluations demonstrate the model's alignment with human perception compared to\ntraditional color models, such as RGB, HSV, and LAB. To the best of our\nknowledge, no previous research has documented the construction of a model for\ncolor attribute specification based on a sample of this size or a comparable\nsample of the human population (n = 2496). Our findings are significant for\nfields such as design, artificial intelligence, marketing, and human-computer\ninteraction, where perceptually relevant color representation is critical.", "published": "2025-07-15 17:01:45", "link": "http://arxiv.org/abs/2507.11488v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Illuminating the Three Dogmas of Reinforcement Learning under Evolutionary Light", "abstract": "Three core tenets of reinforcement learning (RL)--concerning the definition\nof agency, the objective of learning, and the scope of the reward\nhypothesis--have been highlighted as key targets for conceptual revision, with\nmajor implications for theory and application. We propose a framework, inspired\nby open-ended evolutionary theory, to reconsider these three \"dogmas.\" We\nrevisit each assumption and address related concerns raised alongside them. To\nmake our arguments relevant to RL as a model of biological learning, we first\nestablish that evolutionary dynamics can plausibly operate within living brains\nover an individual's lifetime, and are not confined to cross-generational\nprocesses. We begin by revisiting the second dogma, drawing on evolutionary\ninsights to enrich the \"adaptation-rather-than-search\" view of learning. We\nthen address the third dogma regarding the limits of the reward hypothesis,\nusing analogies from evolutionary fitness to illuminate the scalar reward vs.\nmulti-objective debate. After discussing practical implications for exploration\nin RL, we turn to the first--and arguably most fundamental--issue: the absence\nof a formal account of agency. We argue that unlike the other two problems, the\nevolutionary paradigm alone cannot resolve the agency question, though it\ngestures in a productive direction. We advocate integrating ideas from\norigins-of-life theory, where the thermodynamics of sustenance and replication\noffer promising foundations for understanding agency and resource-constrained\nreinforcement learning in biological systems.", "published": "2025-07-15 16:53:14", "link": "http://arxiv.org/abs/2507.11482v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Chain of Thought Monitorability: A New and Fragile Opportunity for AI Safety", "abstract": "AI systems that \"think\" in human language offer a unique opportunity for AI\nsafety: we can monitor their chains of thought (CoT) for the intent to\nmisbehave. Like all other known AI oversight methods, CoT monitoring is\nimperfect and allows some misbehavior to go unnoticed. Nevertheless, it shows\npromise and we recommend further research into CoT monitorability and\ninvestment in CoT monitoring alongside existing safety methods. Because CoT\nmonitorability may be fragile, we recommend that frontier model developers\nconsider the impact of development decisions on CoT monitorability.", "published": "2025-07-15 16:43:41", "link": "http://arxiv.org/abs/2507.11473v1", "categories": ["cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.AI"}
{"title": "Modeling Code: Is Text All You Need?", "abstract": "Code LLMs have become extremely popular recently for modeling source code\nacross a variety of tasks, such as generation, translation, and summarization.\nHowever, transformer-based models are limited in their capabilities to reason\nthrough structured, analytical properties of code, such as control and data\nflow. Previous work has explored the modeling of these properties with\nstructured data and graph neural networks. However, these approaches lack the\ngenerative capabilities and scale of modern LLMs. In this work, we introduce a\nnovel approach to combine the strengths of modeling both code as text and more\nstructured forms.", "published": "2025-07-15 16:39:12", "link": "http://arxiv.org/abs/2507.11467v1", "categories": ["cs.AI", "cs.SE"], "primary_category": "cs.AI"}
{"title": "COLI: A Hierarchical Efficient Compressor for Large Images", "abstract": "The escalating adoption of high-resolution, large-field-of-view imagery\namplifies the need for efficient compression methodologies. Conventional\ntechniques frequently fail to preserve critical image details, while\ndata-driven approaches exhibit limited generalizability. Implicit Neural\nRepresentations (INRs) present a promising alternative by learning continuous\nmappings from spatial coordinates to pixel intensities for individual images,\nthereby storing network weights rather than raw pixels and avoiding the\ngeneralization problem. However, INR-based compression of large images faces\nchallenges including slow compression speed and suboptimal compression ratios.\nTo address these limitations, we introduce COLI (Compressor for Large Images),\na novel framework leveraging Neural Representations for Videos (NeRV). First,\nrecognizing that INR-based compression constitutes a training process, we\naccelerate its convergence through a pretraining-finetuning paradigm,\nmixed-precision training, and reformulation of the sequential loss into a\nparallelizable objective. Second, capitalizing on INRs' transformation of image\nstorage constraints into weight storage, we implement Hyper-Compression, a\nnovel post-training technique to substantially enhance compression ratios while\nmaintaining minimal output distortion. Evaluations across two medical imaging\ndatasets demonstrate that COLI consistently achieves competitive or superior\nPSNR and SSIM metrics at significantly reduced bits per pixel (bpp), while\naccelerating NeRV training by up to 4 times.", "published": "2025-07-15 16:07:07", "link": "http://arxiv.org/abs/2507.11443v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Toward Improving fNIRS Classification: A Study on Activation Functions in Deep Neural Architectures", "abstract": "Activation functions are critical to the performance of deep neural networks,\nparticularly in domains such as functional near-infrared spectroscopy (fNIRS),\nwhere nonlinearity, low signal-to-noise ratio (SNR), and signal variability\nposes significant challenges to model accuracy. However, the impact of\nactivation functions on deep learning (DL) performance in the fNIRS domain\nremains underexplored and lacks systematic investigation in the current\nliterature. This study evaluates a range of conventional and field-specific\nactivation functions for fNIRS classification tasks using multiple deep\nlearning architectures, including the domain-specific fNIRSNet, AbsoluteNet,\nMDNN, and shallowConvNet (as the baseline), all tested on a single dataset\nrecorded during an auditory task. To ensure fair a comparison, all networks\nwere trained and tested using standardized preprocessing and consistent\ntraining parameters. The results show that symmetrical activation functions\nsuch as Tanh and the Absolute value function Abs(x) can outperform commonly\nused functions like the Rectified Linear Unit (ReLU), depending on the\narchitecture. Additionally, a focused analysis of the role of symmetry was\nconducted using a Modified Absolute Function (MAF), with results further\nsupporting the effectiveness of symmetrical activation functions on performance\ngains. These findings underscore the importance of selecting proper activation\nfunctions that align with the signal characteristics of fNIRS data.", "published": "2025-07-15 15:58:36", "link": "http://arxiv.org/abs/2507.11436v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "U-RWKV: Lightweight medical image segmentation with direction-adaptive RWKV", "abstract": "Achieving equity in healthcare accessibility requires lightweight yet\nhigh-performance solutions for medical image segmentation, particularly in\nresource-limited settings. Existing methods like U-Net and its variants often\nsuffer from limited global Effective Receptive Fields (ERFs), hindering their\nability to capture long-range dependencies. To address this, we propose U-RWKV,\na novel framework leveraging the Recurrent Weighted Key-Value(RWKV)\narchitecture, which achieves efficient long-range modeling at O(N)\ncomputational cost. The framework introduces two key innovations: the\nDirection-Adaptive RWKV Module(DARM) and the Stage-Adaptive\nSqueeze-and-Excitation Module(SASE). DARM employs Dual-RWKV and QuadScan\nmechanisms to aggregate contextual cues across images, mitigating directional\nbias while preserving global context and maintaining high computational\nefficiency. SASE dynamically adapts its architecture to different feature\nextraction stages, balancing high-resolution detail preservation and semantic\nrelationship capture. Experiments demonstrate that U-RWKV achieves\nstate-of-the-art segmentation performance with high computational efficiency,\noffering a practical solution for democratizing advanced medical imaging\ntechnologies in resource-constrained environments. The code is available at\nhttps://github.com/hbyecoding/U-RWKV.", "published": "2025-07-15 15:40:17", "link": "http://arxiv.org/abs/2507.11415v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "From Kinetic Theory to AI: a Rediscovery of High-Dimensional Divergences and Their Properties", "abstract": "Selecting an appropriate divergence measure is a critical aspect of machine\nlearning, as it directly impacts model performance. Among the most widely used,\nwe find the Kullback-Leibler (KL) divergence, originally introduced in kinetic\ntheory as a measure of relative entropy between probability distributions. Just\nas in machine learning, the ability to quantify the proximity of probability\ndistributions plays a central role in kinetic theory. In this paper, we present\na comparative review of divergence measures rooted in kinetic theory,\nhighlighting their theoretical foundations and exploring their potential\napplications in machine learning and artificial intelligence.", "published": "2025-07-15 14:56:25", "link": "http://arxiv.org/abs/2507.11387v1", "categories": ["math-ph", "cs.AI", "cs.LG", "cs.MA", "math.MP", "35B40, 35L60, 35K55, 35Q70, 35Q91, 35Q92"], "primary_category": "math-ph"}
{"title": "Attributes Shape the Embedding Space of Face Recognition Models", "abstract": "Face Recognition (FR) tasks have made significant progress with the advent of\nDeep Neural Networks, particularly through margin-based triplet losses that\nembed facial images into high-dimensional feature spaces. During training,\nthese contrastive losses focus exclusively on identity information as labels.\nHowever, we observe a multiscale geometric structure emerging in the embedding\nspace, influenced by interpretable facial (e.g., hair color) and image\nattributes (e.g., contrast). We propose a geometric approach to describe the\ndependence or invariance of FR models to these attributes and introduce a\nphysics-inspired alignment metric. We evaluate the proposed metric on\ncontrolled, simplified models and widely used FR models fine-tuned with\nsynthetic data for targeted attribute augmentation. Our findings reveal that\nthe models exhibit varying degrees of invariance across different attributes,\nproviding insight into their strengths and weaknesses and enabling deeper\ninterpretability. Code available here:\nhttps://github.com/mantonios107/attrs-fr-embs}{https://github.com/mantonios107/attrs-fr-embs", "published": "2025-07-15 14:44:39", "link": "http://arxiv.org/abs/2507.11372v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Local Pairwise Distance Matching for Backpropagation-Free Reinforcement Learning", "abstract": "Training neural networks with reinforcement learning (RL) typically relies on\nbackpropagation (BP), necessitating storage of activations from the forward\npass for subsequent backward updates. Furthermore, backpropagating error\nsignals through multiple layers often leads to vanishing or exploding\ngradients, which can degrade learning performance and stability. We propose a\nnovel approach that trains each layer of the neural network using local signals\nduring the forward pass in RL settings. Our approach introduces local,\nlayer-wise losses leveraging the principle of matching pairwise distances from\nmulti-dimensional scaling, enhanced with optional reward-driven guidance. This\nmethod allows each hidden layer to be trained using local signals computed\nduring forward propagation, thus eliminating the need for backward passes and\nstoring intermediate activations. Our experiments, conducted with policy\ngradient methods across common RL benchmarks, demonstrate that this\nbackpropagation-free method achieves competitive performance compared to their\nclassical BP-based counterpart. Additionally, the proposed method enhances\nstability and consistency within and across runs, and improves performance\nespecially in challenging environments.", "published": "2025-07-15 14:39:41", "link": "http://arxiv.org/abs/2507.11367v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Foundation Models for Logistics: Toward Certifiable, Conversational Planning Interfaces", "abstract": "Logistics operators, from battlefield coordinators rerouting airlifts ahead\nof a storm to warehouse managers juggling late trucks, often face life-critical\ndecisions that demand both domain expertise and rapid and continuous\nreplanning. While popular methods like integer programming yield logistics\nplans that satisfy user-defined logical constraints, they are slow and assume\nan idealized mathematical model of the environment that does not account for\nuncertainty. On the other hand, large language models (LLMs) can handle\nuncertainty and promise to accelerate replanning while lowering the barrier to\nentry by translating free-form utterances into executable plans, yet they\nremain prone to misinterpretations and hallucinations that jeopardize safety\nand cost. We introduce a neurosymbolic framework that pairs the accessibility\nof natural-language dialogue with verifiable guarantees on goal interpretation.\nIt converts user requests into structured planning specifications, quantifies\nits own uncertainty at the field and token level, and invokes an interactive\nclarification loop whenever confidence falls below an adaptive threshold. A\nlightweight model, fine-tuned on just 100 uncertainty-filtered examples,\nsurpasses the zero-shot performance of GPT-4.1 while cutting inference latency\nby nearly 50%. These preliminary results highlight a practical path toward\ncertifiable, real-time, and user-aligned decision-making for complex logistics.", "published": "2025-07-15 14:24:01", "link": "http://arxiv.org/abs/2507.11352v1", "categories": ["cs.AI", "cs.FL"], "primary_category": "cs.AI"}
{"title": "Acting and Planning with Hierarchical Operational Models on a Mobile Robot: A Study with RAE+UPOM", "abstract": "Robotic task execution faces challenges due to the inconsistency between\nsymbolic planner models and the rich control structures actually running on the\nrobot. In this paper, we present the first physical deployment of an integrated\nactor-planner system that shares hierarchical operational models for both\nacting and planning, interleaving the Reactive Acting Engine (RAE) with an\nanytime UCT-like Monte Carlo planner (UPOM). We implement RAE+UPOM on a mobile\nmanipulator in a real-world deployment for an object collection task. Our\nexperiments demonstrate robust task execution under action failures and sensor\nnoise, and provide empirical insights into the interleaved acting-and-planning\ndecision making process.", "published": "2025-07-15 14:20:26", "link": "http://arxiv.org/abs/2507.11345v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "CogDDN: A Cognitive Demand-Driven Navigation with Decision Optimization and Dual-Process Thinking", "abstract": "Mobile robots are increasingly required to navigate and interact within\nunknown and unstructured environments to meet human demands. Demand-driven\nnavigation (DDN) enables robots to identify and locate objects based on\nimplicit human intent, even when object locations are unknown. However,\ntraditional data-driven DDN methods rely on pre-collected data for model\ntraining and decision-making, limiting their generalization capability in\nunseen scenarios. In this paper, we propose CogDDN, a VLM-based framework that\nemulates the human cognitive and learning mechanisms by integrating fast and\nslow thinking systems and selectively identifying key objects essential to\nfulfilling user demands. CogDDN identifies appropriate target objects by\nsemantically aligning detected objects with the given instructions.\nFurthermore, it incorporates a dual-process decision-making module, comprising\na Heuristic Process for rapid, efficient decisions and an Analytic Process that\nanalyzes past errors, accumulates them in a knowledge base, and continuously\nimproves performance. Chain of Thought (CoT) reasoning strengthens the\ndecision-making process. Extensive closed-loop evaluations on the AI2Thor\nsimulator with the ProcThor dataset show that CogDDN outperforms single-view\ncamera-only methods by 15%, demonstrating significant improvements in\nnavigation accuracy and adaptability. The project page is available at\nhttps://yuehaohuang.github.io/CogDDN/.", "published": "2025-07-15 14:06:24", "link": "http://arxiv.org/abs/2507.11334v1", "categories": ["cs.AI", "cs.RO"], "primary_category": "cs.AI"}
{"title": "SystolicAttention: Fusing FlashAttention within a Single Systolic Array", "abstract": "Transformer models rely heavily on scaled dot-product attention (SDPA),\ntypically implemented using the FlashAttention algorithm. However, current\nsystolic-array-based accelerators face significant challenges when executing\nFlashAttention. Systolic arrays can only achieve high utilization for\nconsecutive and large matrix multiplications. In contrast, FlashAttention\nrequires frequently interleaved matrix multiplications and softmax operations.\n  The frequent data swaps between the systolic array and external vector units\nresult in low systolic array utilization. This is further exacerbated by the\nfact that softmax involves numerous non-matrix operations, which are not\nwell-suited for systolic arrays. Moreover, the concurrent execution of matrix\nmultiplication on systolic arrays and softmax on vector units leads to register\nfile and SRAM port contention, further degrading performance.\n  To overcome these limitations, we propose FSA, an enhanced systolic array\narchitecture that enables the entire FlashAttention algorithm to run entirely\nwithin a single systolic array, eliminating the need for external vector units.\nAt the core of FSA is SystolicAttention, a novel scheduling algorithm that maps\nFlashAttention operations onto systolic arrays with fine-grained, element-wise\noverlap. This significantly improves array utilization while preserving the\noriginal floating-point operation order to maintain numerical stability.\n  We implement FSA in synthesizable RTL and evaluate its performance against\nstate-of-the-art commercial accelerators. Our results show that FSA achieves\n1.77x and 4.83x higher attention FLOPs/s utilization compared to AWS\nNeuronCore-v2 and Google TPUv5e, respectively, with only about 10% area\noverhead.", "published": "2025-07-15 14:04:17", "link": "http://arxiv.org/abs/2507.11331v1", "categories": ["cs.AR", "cs.AI"], "primary_category": "cs.AR"}
{"title": "Quantitative multi-metabolite imaging of Parkinson's disease using AI boosted molecular MRI", "abstract": "Traditional approaches for molecular imaging of Parkinson's disease (PD) in\nvivo require radioactive isotopes, lengthy scan times, or deliver only low\nspatial resolution. Recent advances in saturation transfer-based PD magnetic\nresonance imaging (MRI) have provided biochemical insights, although the image\ncontrast is semi-quantitative and nonspecific. Here, we combined a rapid\nmolecular MRI acquisition paradigm with deep learning based reconstruction for\nmulti-metabolite quantification of glutamate, mobile proteins, semisolid, and\nmobile macromolecules in an acute MPTP\n(1-methyl-4-phenyl-1,2,3,6-tetrahydropyridine) mouse model. The quantitative\nparameter maps are in general agreement with the histology and MR spectroscopy,\nand demonstrate that semisolid magnetization transfer (MT), amide, and\naliphatic relayed nuclear Overhauser effect (rNOE) proton volume fractions may\nserve as PD biomarkers.", "published": "2025-07-15 14:01:54", "link": "http://arxiv.org/abs/2507.11329v1", "categories": ["physics.med-ph", "cs.AI"], "primary_category": "physics.med-ph"}
{"title": "HANS-Net: Hyperbolic Convolution and Adaptive Temporal Attention for Accurate and Generalizable Liver and Tumor Segmentation in CT Imaging", "abstract": "Accurate liver and tumor segmentation on abdominal CT images is critical for\nreliable diagnosis and treatment planning, but remains challenging due to\ncomplex anatomical structures, variability in tumor appearance, and limited\nannotated data. To address these issues, we introduce Hyperbolic-convolutions\nAdaptive-temporal-attention with Neural-representation and Synaptic-plasticity\nNetwork (HANS-Net), a novel segmentation framework that synergistically\ncombines hyperbolic convolutions for hierarchical geometric representation, a\nwavelet-inspired decomposition module for multi-scale texture learning, a\nbiologically motivated synaptic plasticity mechanism for adaptive feature\nenhancement, and an implicit neural representation branch to model fine-grained\nand continuous anatomical boundaries. Additionally, we incorporate\nuncertainty-aware Monte Carlo dropout to quantify prediction confidence and\nlightweight temporal attention to improve inter-slice consistency without\nsacrificing efficiency. Extensive evaluations of the LiTS dataset demonstrate\nthat HANS-Net achieves a mean Dice score of 93.26%, an IoU of 88.09%, an\naverage symmetric surface distance (ASSD) of 0.72 mm, and a volume overlap\nerror (VOE) of 11.91%. Furthermore, cross-dataset validation on the\n3D-IRCADb-01 dataset obtains an average Dice of 87.45%, IoU of 80.30%, ASSD of\n1.525 mm, and VOE of 19.71%, indicating strong generalization across different\ndatasets. These results confirm the effectiveness and robustness of HANS-Net in\nproviding anatomically consistent, accurate, and confident liver and tumor\nsegmentation.", "published": "2025-07-15 13:56:37", "link": "http://arxiv.org/abs/2507.11325v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Contestability in Quantitative Argumentation", "abstract": "Contestable AI requires that AI-driven decisions align with human\npreferences. While various forms of argumentation have been shown to support\ncontestability, Edge-Weighted Quantitative Bipolar Argumentation Frameworks\n(EW-QBAFs) have received little attention. In this work, we show how EW-QBAFs\ncan be deployed for this purpose. Specifically, we introduce the contestability\nproblem for EW-QBAFs, which asks how to modify edge weights (e.g., preferences)\nto achieve a desired strength for a specific argument of interest (i.e., a\ntopic argument). To address this problem, we propose gradient-based relation\nattribution explanations (G-RAEs), which quantify the sensitivity of the topic\nargument's strength to changes in individual edge weights, thus providing\ninterpretable guidance for weight adjustments towards contestability. Building\non G-RAEs, we develop an iterative algorithm that progressively adjusts the\nedge weights to attain the desired strength. We evaluate our approach\nexperimentally on synthetic EW-QBAFs that simulate the structural\ncharacteristics of personalised recommender systems and multi-layer\nperceptrons, and demonstrate that it can solve the problem effectively.", "published": "2025-07-15 13:54:26", "link": "http://arxiv.org/abs/2507.11323v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Opus: A Prompt Intention Framework for Complex Workflow Generation", "abstract": "This paper introduces the Opus Prompt Intention Framework, designed to\nimprove complex Workflow Generation with instruction-tuned Large Language\nModels (LLMs). We propose an intermediate Intention Capture layer between user\nqueries and Workflow Generation, implementing the Opus Workflow Intention\nFramework, which consists of extracting Workflow Signals from user queries,\ninterpreting them into structured Workflow Intention objects, and generating\nWorkflows based on these Intentions. Our results show that this layer enables\nLLMs to produce logical and meaningful outputs that scale reliably as query\ncomplexity increases. On a synthetic benchmark of 1,000 multi-intent\nquery-Workflow(s) pairs, applying the Opus Prompt Intention Framework to\nWorkflow Generation yields consistent improvements in semantic Workflow\nsimilarity metrics. In this paper, we introduce the Opus Prompt Intention\nFramework by applying the concepts of Workflow Signal and Workflow Intention to\nLLM-driven Workflow Generation. We present a reproducible, customizable\nLLM-based Intention Capture system to extract Workflow Signals and Workflow\nIntentions from user queries. Finally, we provide empirical evidence that the\nproposed system significantly improves Workflow Generation quality compared to\ndirect generation from user queries, particularly in cases of Mixed Intention\nElicitation.", "published": "2025-07-15 13:13:07", "link": "http://arxiv.org/abs/2507.11288v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Taming Uncertainty via Automation: Observing, Analyzing, and Optimizing Agentic AI Systems", "abstract": "Large Language Models (LLMs) are increasingly deployed within agentic\nsystems-collections of interacting, LLM-powered agents that execute complex,\nadaptive workflows using memory, tools, and dynamic planning. While enabling\npowerful new capabilities, these systems also introduce unique forms of\nuncertainty stemming from probabilistic reasoning, evolving memory states, and\nfluid execution paths. Traditional software observability and operations\npractices fall short in addressing these challenges.\n  This paper introduces AgentOps: a comprehensive framework for observing,\nanalyzing, optimizing, and automating operation of agentic AI systems. We\nidentify distinct needs across four key roles-developers, testers, site\nreliability engineers (SREs), and business users-each of whom engages with the\nsystem at different points in its lifecycle. We present the AgentOps Automation\nPipeline, a six-stage process encompassing behavior observation, metric\ncollection, issue detection, root cause analysis, optimized recommendations,\nand runtime automation. Throughout, we emphasize the critical role of\nautomation in managing uncertainty and enabling self-improving AI systems-not\nby eliminating uncertainty, but by taming it to ensure safe, adaptive, and\neffective operation.", "published": "2025-07-15 12:54:43", "link": "http://arxiv.org/abs/2507.11277v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Turning Sand to Gold: Recycling Data to Bridge On-Policy and Off-Policy Learning via Causal Bound", "abstract": "Deep reinforcement learning (DRL) agents excel in solving complex\ndecision-making tasks across various domains. However, they often require a\nsubstantial number of training steps and a vast experience replay buffer,\nleading to significant computational and resource demands. To address these\nchallenges, we introduce a novel theoretical result that leverages the\nNeyman-Rubin potential outcomes framework into DRL. Unlike most methods that\nfocus on bounding the counterfactual loss, we establish a causal bound on the\nfactual loss, which is analogous to the on-policy loss in DRL. This bound is\ncomputed by storing past value network outputs in the experience replay buffer,\neffectively utilizing data that is usually discarded. Extensive experiments\nacross the Atari 2600 and MuJoCo domains on various agents, such as DQN and\nSAC, achieve up to 2,427% higher reward ratio, outperforming the same agents\nwithout our proposed term, and reducing the experience replay buffer size by up\nto 96%, significantly improving sample efficiency at negligible cost.", "published": "2025-07-15 12:46:25", "link": "http://arxiv.org/abs/2507.11269v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "YOLOatr : Deep Learning Based Automatic Target Detection and Localization in Thermal Infrared Imagery", "abstract": "Automatic Target Detection (ATD) and Recognition (ATR) from Thermal Infrared\n(TI) imagery in the defense and surveillance domain is a challenging computer\nvision (CV) task in comparison to the commercial autonomous vehicle perception\ndomain. Limited datasets, peculiar domain-specific and TI modality-specific\nchallenges, i.e., limited hardware, scale invariance issues due to greater\ndistances, deliberate occlusion by tactical vehicles, lower sensor resolution\nand resultant lack of structural information in targets, effects of weather,\ntemperature, and time of day variations, and varying target to clutter ratios\nall result in increased intra-class variability and higher inter-class\nsimilarity, making accurate real-time ATR a challenging CV task. Resultantly,\ncontemporary state-of-the-art (SOTA) deep learning architectures underperform\nin the ATR domain. We propose a modified anchor-based single-stage detector,\ncalled YOLOatr, based on a modified YOLOv5s, with optimal modifications to the\ndetection heads, feature fusion in the neck, and a custom augmentation profile.\nWe evaluate the performance of our proposed model on a comprehensive DSIAC MWIR\ndataset for real-time ATR over both correlated and decorrelated testing\nprotocols. The results demonstrate that our proposed model achieves\nstate-of-the-art ATR performance of up to 99.6%.", "published": "2025-07-15 12:41:01", "link": "http://arxiv.org/abs/2507.11267v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "DuetGraph: Coarse-to-Fine Knowledge Graph Reasoning with Dual-Pathway Global-Local Fusion", "abstract": "Knowledge graphs (KGs) are vital for enabling knowledge reasoning across\nvarious domains. Recent KG reasoning methods that integrate both global and\nlocal information have achieved promising results. However, existing methods\noften suffer from score over-smoothing, which blurs the distinction between\ncorrect and incorrect answers and hinders reasoning effectiveness. To address\nthis, we propose DuetGraph, a coarse-to-fine KG reasoning mechanism with\ndual-pathway global-local fusion. DuetGraph tackles over-smoothing by\nsegregating -- rather than stacking -- the processing of local (via message\npassing) and global (via attention) information into two distinct pathways,\npreventing mutual interference and preserving representational discrimination.\nIn addition, DuetGraph introduces a coarse-to-fine optimization, which\npartitions entities into high- and low-score subsets. This strategy narrows the\ncandidate space and sharpens the score gap between the two subsets, which\nalleviates over-smoothing and enhances inference quality. Extensive experiments\non various datasets demonstrate that DuetGraph achieves state-of-the-art (SOTA)\nperformance, with up to an 8.7% improvement in reasoning quality and a\n1.8$\\times$ acceleration in training efficiency.", "published": "2025-07-15 11:59:15", "link": "http://arxiv.org/abs/2507.11229v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Role-Playing LLM-Based Multi-Agent Support Framework for Detecting and Addressing Family Communication Bias", "abstract": "Well-being in family settings involves subtle psychological dynamics that\nconventional metrics often overlook. In particular, unconscious parental\nexpectations, termed ideal parent bias, can suppress children's emotional\nexpression and autonomy. This suppression, referred to as suppressed emotion,\noften stems from well-meaning but value-driven communication, which is\ndifficult to detect or address from outside the family. Focusing on these\nlatent dynamics, this study explores Large Language Model (LLM)-based support\nfor psychologically safe family communication. We constructed a Japanese\nparent-child dialogue corpus of 30 scenarios, each annotated with metadata on\nideal parent bias and suppressed emotion. Based on this corpus, we developed a\nRole-Playing LLM-based multi-agent dialogue support framework that analyzes\ndialogue and generates feedback. Specialized agents detect suppressed emotion,\ndescribe implicit ideal parent bias in parental speech, and infer contextual\nattributes such as the child's age and background. A meta-agent compiles these\noutputs into a structured report, which is then passed to five selected expert\nagents. These agents collaboratively generate empathetic and actionable\nfeedback through a structured four-step discussion process. Experiments show\nthat the system can detect categories of suppressed emotion with moderate\naccuracy and produce feedback rated highly in empathy and practicality.\nMoreover, simulated follow-up dialogues incorporating this feedback exhibited\nsigns of improved emotional expression and mutual understanding, suggesting the\nframework's potential in supporting positive transformation in family\ninteractions.", "published": "2025-07-15 11:27:32", "link": "http://arxiv.org/abs/2507.11210v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "An Explainable AI-Enhanced Machine Learning Approach for Cardiovascular Disease Detection and Risk Assessment", "abstract": "Heart disease remains a major global health concern, particularly in regions\nwith limited access to medical resources and diagnostic facilities. Traditional\ndiagnostic methods often fail to accurately identify and manage heart disease\nrisks, leading to adverse outcomes. Machine learning has the potential to\nsignificantly enhance the accuracy, efficiency, and speed of heart disease\ndiagnosis. In this study, we proposed a comprehensive framework that combines\nclassification models for heart disease detection and regression models for\nrisk prediction. We employed the Heart Disease dataset, which comprises 1,035\ncases. To address the issue of class imbalance, the Synthetic Minority\nOversampling Technique (SMOTE) was applied, resulting in the generation of an\nadditional 100,000 synthetic data points. Performance metrics, including\naccuracy, precision, recall, F1-score, R2, MSE, RMSE, and MAE, were used to\nevaluate the model's effectiveness. Among the classification models, Random\nForest emerged as the standout performer, achieving an accuracy of 97.2% on\nreal data and 97.6% on synthetic data. For regression tasks, Linear Regression\ndemonstrated the highest R2 values of 0.992 and 0.984 on real and synthetic\ndatasets, respectively, with the lowest error metrics. Additionally,\nExplainable AI techniques were employed to enhance the interpretability of the\nmodels. This study highlights the potential of machine learning to\nrevolutionize heart disease diagnosis and risk prediction, thereby facilitating\nearly intervention and enhancing clinical decision-making.", "published": "2025-07-15 10:38:38", "link": "http://arxiv.org/abs/2507.11185v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Mixture of Experts in Large Language Models", "abstract": "This paper presents a comprehensive review of the Mixture-of-Experts (MoE)\narchitecture in large language models, highlighting its ability to\nsignificantly enhance model performance while maintaining minimal computational\noverhead. Through a systematic analysis spanning theoretical foundations, core\narchitectural designs, and large language model (LLM) applications, we examine\nexpert gating and routing mechanisms, hierarchical and sparse MoE\nconfigurations, meta-learning approaches, multimodal and multitask learning\nscenarios, real-world deployment cases, and recent advances and challenges in\ndeep learning. Our analysis identifies key advantages of MoE, including\nsuperior model capacity compared to equivalent Bayesian approaches, improved\ntask-specific performance, and the ability to scale model capacity efficiently.\nWe also underscore the importance of ensuring expert diversity, accurate\ncalibration, and reliable inference aggregation, as these are essential for\nmaximizing the effectiveness of MoE architectures. Finally, this review\noutlines current research limitations, open challenges, and promising future\ndirections, providing a foundation for continued innovation in MoE architecture\nand its applications.", "published": "2025-07-15 10:36:43", "link": "http://arxiv.org/abs/2507.11181v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Gradient Regularization-based Neural Granger Causality", "abstract": "With the advancement of deep learning technologies, various neural\nnetwork-based Granger causality models have been proposed. Although these\nmodels have demonstrated notable improvements, several limitations remain. Most\nexisting approaches adopt the component-wise architecture, necessitating the\nconstruction of a separate model for each time series, which results in\nsubstantial computational costs. In addition, imposing the sparsity-inducing\npenalty on the first-layer weights of the neural network to extract causal\nrelationships weakens the model's ability to capture complex interactions. To\naddress these limitations, we propose Gradient Regularization-based Neural\nGranger Causality (GRNGC), which requires only one time series prediction model\nand applies $L_{1}$ regularization to the gradient between model's input and\noutput to infer Granger causality. Moreover, GRNGC is not tied to a specific\ntime series forecasting model and can be implemented with diverse architectures\nsuch as KAN, MLP, and LSTM, offering enhanced flexibility. Numerical\nsimulations on DREAM, Lorenz-96, fMRI BOLD, and CausalTime show that GRNGC\noutperforms existing baselines and significantly reduces computational\noverhead. Meanwhile, experiments on real-world DNA, Yeast, HeLa, and bladder\nurothelial carcinoma datasets further validate the model's effectiveness in\nreconstructing gene regulatory networks.", "published": "2025-07-15 10:35:29", "link": "http://arxiv.org/abs/2507.11178v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Improving Wi-Fi Network Performance Prediction with Deep Learning Models", "abstract": "The increasing need for robustness, reliability, and determinism in wireless\nnetworks for industrial and mission-critical applications is the driver for the\ngrowth of new innovative methods. The study presented in this work makes use of\nmachine learning techniques to predict channel quality in a Wi-Fi network in\nterms of the frame delivery ratio. Predictions can be used proactively to\nadjust communication parameters at runtime and optimize network operations for\nindustrial applications. Methods including convolutional neural networks and\nlong short-term memory were analyzed on datasets acquired from a real Wi-Fi\nsetup across multiple channels. The models were compared in terms of prediction\naccuracy and computational complexity. Results show that the frame delivery\nratio can be reliably predicted, and convolutional neural networks, although\nslightly less effective than other models, are more efficient in terms of CPU\nusage and memory consumption. This enhances the model's usability on embedded\nand industrial systems.", "published": "2025-07-15 10:18:32", "link": "http://arxiv.org/abs/2507.11168v1", "categories": ["cs.NI", "cs.AI", "cs.LG", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Assessing Color Vision Test in Large Vision-language Models", "abstract": "With the widespread adoption of large vision-language models, the capacity\nfor color vision in these models is crucial. However, the color vision\nabilities of large visual-language models have not yet been thoroughly\nexplored. To address this gap, we define a color vision testing task for large\nvision-language models and construct a dataset \\footnote{Anonymous Github\nShowing some of the data\nhttps://anonymous.4open.science/r/color-vision-test-dataset-3BCD} that covers\nmultiple categories of test questions and tasks of varying difficulty levels.\nFurthermore, we analyze the types of errors made by large vision-language\nmodels and propose fine-tuning strategies to enhance their performance in color\nvision tests.", "published": "2025-07-15 10:03:06", "link": "http://arxiv.org/abs/2507.11153v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Latent Space Consistency for Sparse-View CT Reconstruction", "abstract": "Computed Tomography (CT) is a widely utilized imaging modality in clinical\nsettings. Using densely acquired rotational X-ray arrays, CT can capture 3D\nspatial features. However, it is confronted with challenged such as significant\ntime consumption and high radiation exposure. CT reconstruction methods based\non sparse-view X-ray images have garnered substantial attention from\nresearchers as they present a means to mitigate costs and risks. In recent\nyears, diffusion models, particularly the Latent Diffusion Model (LDM), have\ndemonstrated promising potential in the domain of 3D CT reconstruction.\nNonetheless, due to the substantial differences between the 2D latent\nrepresentation of X-ray modalities and the 3D latent representation of CT\nmodalities, the vanilla LDM is incapable of achieving effective alignment\nwithin the latent space. To address this issue, we propose the Consistent\nLatent Space Diffusion Model (CLS-DM), which incorporates cross-modal feature\ncontrastive learning to efficiently extract latent 3D information from 2D X-ray\nimages and achieve latent space alignment between modalities. Experimental\nresults indicate that CLS-DM outperforms classical and state-of-the-art\ngenerative models in terms of standard voxel-level metrics (PSNR, SSIM) on the\nLIDC-IDRI and CTSpine1K datasets. This methodology not only aids in enhancing\nthe effectiveness and economic viability of sparse X-ray reconstructed CT but\ncan also be generalized to other cross-modal transformation tasks, such as\ntext-to-image synthesis. We have made our code publicly available at\nhttps://anonymous.4open.science/r/CLS-DM-50D6/ to facilitate further research\nand applications in other domains.", "published": "2025-07-15 10:02:19", "link": "http://arxiv.org/abs/2507.11152v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Fine-grained Timing Analysis of Digital Integrated Circuits in Answer Set Programming", "abstract": "In the design of integrated circuits, one critical metric is the maximum\ndelay introduced by combinational modules within the circuit. This delay is\ncrucial because it represents the time required to perform a computation: in an\nArithmetic-Logic Unit it represents the maximum time taken by the circuit to\nperform an arithmetic operation. When such a circuit is part of a larger,\nsynchronous system, like a CPU, the maximum delay directly impacts the maximum\nclock frequency of the entire system. Typically, hardware designers use Static\nTiming Analysis to compute an upper bound of the maximum delay because it can\nbe determined in polynomial time. However, relying on this upper bound can lead\nto suboptimal processor speeds, thereby missing performance opportunities. In\nthis work, we tackle the challenging task of computing the actual maximum\ndelay, rather than an approximate value. Since the problem is computationally\nhard, we model it in Answer Set Programming (ASP), a logic language featuring\nextremely efficient solvers. We propose non-trivial encodings of the problem\ninto ASP. Experimental results show that ASP is a viable solution to address\ncomplex problems in hardware design.", "published": "2025-07-15 09:57:45", "link": "http://arxiv.org/abs/2507.11150v1", "categories": ["cs.AI", "cs.LO"], "primary_category": "cs.AI"}
{"title": "Collaborative Trustworthiness for Good Decision Making in Autonomous Systems", "abstract": "Autonomous systems are becoming an integral part of many application domains,\nlike in the mobility sector. However, ensuring their safe and correct behaviour\nin dynamic and complex environments remains a significant challenge, where\nsystems should autonomously make decisions e.g., about manoeuvring. We propose\nin this paper a general collaborative approach for increasing the level of\ntrustworthiness in the environment of operation and improve reliability and\ngood decision making in autonomous system. In the presence of conflicting\ninformation, aggregation becomes a major issue for trustworthy decision making\nbased on collaborative data sharing. Unlike classical approaches in the\nliterature that rely on consensus or majority as aggregation rule, we exploit\nthe fact that autonomous systems have different quality attributes like\nperception quality. We use this criteria to determine which autonomous systems\nare trustworthy and borrow concepts from social epistemology to define\naggregation and propagation rules, used for automated decision making. We use\nBinary Decision Diagrams (BDDs) as formal models for beliefs aggregation and\npropagation, and formulate reduction rules to reduce the size of the BDDs and\nallow efficient computation structures for collaborative automated reasoning.", "published": "2025-07-15 09:37:28", "link": "http://arxiv.org/abs/2507.11135v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "MMOne: Representing Multiple Modalities in One Scene", "abstract": "Humans perceive the world through multimodal cues to understand and interact\nwith the environment. Learning a scene representation for multiple modalities\nenhances comprehension of the physical world. However, modality conflicts,\narising from inherent distinctions among different modalities, present two\ncritical challenges: property disparity and granularity disparity. To address\nthese challenges, we propose a general framework, MMOne, to represent multiple\nmodalities in one scene, which can be readily extended to additional\nmodalities. Specifically, a modality modeling module with a novel modality\nindicator is proposed to capture the unique properties of each modality.\nAdditionally, we design a multimodal decomposition mechanism to separate\nmulti-modal Gaussians into single-modal Gaussians based on modality\ndifferences. We address the essential distinctions among modalities by\ndisentangling multimodal information into shared and modality-specific\ncomponents, resulting in a more compact and efficient multimodal scene\nrepresentation. Extensive experiments demonstrate that our method consistently\nenhances the representation capability for each modality and is scalable to\nadditional modalities. The code is available at\nhttps://github.com/Neal2020GitHub/MMOne.", "published": "2025-07-15 09:29:29", "link": "http://arxiv.org/abs/2507.11129v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Defining neurosymbolic AI", "abstract": "Neurosymbolic AI focuses on integrating learning and reasoning, in\nparticular, on unifying logical and neural representations. Despite the\nexistence of an alphabet soup of neurosymbolic AI systems, the field is lacking\na generally accepted formal definition of what neurosymbolic models and\ninference really are. We introduce a formal definition for neurosymbolic AI\nthat makes abstraction of its key ingredients. More specifically, we define\nneurosymbolic inference as the computation of an integral over a product of a\nlogical and a belief function. We show that our neurosymbolic AI definition\nmakes abstraction of key representative neurosymbolic AI systems.", "published": "2025-07-15 09:23:22", "link": "http://arxiv.org/abs/2507.11127v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "AI Agent Architecture for Decentralized Trading of Alternative Assets", "abstract": "Decentralized trading of real-world alternative assets (e.g., gold) requires\nbridging physical asset custody with blockchain systems while meeting strict\nrequirements for compliance, liquidity, and risk management. We present\nGoldMine OS, a research oriented architecture that employs multiple specialized\nAI agents to automate and secure the tokenization and exchange of physical gold\ninto a blockchain based stablecoin (\"OZ\"). Our approach combines on chain smart\ncontracts for critical risk controls with off chain AI agents for decision\nmaking, blending the transparency and reliability of blockchains with the\nflexibility of AI driven automation. We describe four cooperative agents\n(Compliance, Token Issuance, Market Making, and Risk Control) and a\ncoordinating core, and evaluate the system through simulation and a controlled\npilot deployment. In experiments the prototype delivers on demand token\nissuance in under 1.2 s, more than 100 times faster than manual workflows. The\nMarket Making agent maintains tight liquidity with spreads often below 0.5\npercent even under volatile conditions. Fault injection tests show resilience:\nan oracle price spoofing attack is detected and mitigated within 10 s, and a\nsimulated vault mis reporting halts issuance immediately with minimal user\nimpact. The architecture scales to 5000 transactions per second with 10000\nconcurrent users in benchmarks. These results indicate that an AI agent based\ndecentralized exchange for alternative assets can satisfy rigorous performance\nand safety requirements. We discuss broader implications for democratizing\naccess to traditionally illiquid assets and explain how our governance model --\nmulti signature agent updates and on chain community voting on risk parameters\n-- provides ongoing transparency, adaptability, and formal assurance of system\nintegrity.", "published": "2025-07-15 09:11:19", "link": "http://arxiv.org/abs/2507.11117v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "EditGen: Harnessing Cross-Attention Control for Instruction-Based Auto-Regressive Audio Editing", "abstract": "In this study, we investigate leveraging cross-attention control for\nefficient audio editing within auto-regressive models. Inspired by image\nediting methodologies, we develop a Prompt-to-Prompt-like approach that guides\nedits through cross and self-attention mechanisms. Integrating a\ndiffusion-based strategy, influenced by Auffusion, we extend the model's\nfunctionality to support refinement edits, establishing a baseline for\nprompt-guided audio editing. Additionally, we introduce an alternative approach\nby incorporating MUSICGEN, a pre-trained frozen auto-regressive model, and\npropose three editing mechanisms, based on Replacement, Reweighting, and\nRefinement of the attention scores. We employ commonly-used music-specific\nevaluation metrics and a human study, to gauge time-varying controllability,\nadherence to global text cues, and overall audio realism. The automatic and\nhuman evaluations indicate that the proposed combination of prompt-to-prompt\nguidance with autoregressive generation models significantly outperforms the\ndiffusion-based baseline in terms of melody, dynamics, and tempo of the\ngenerated audio. Our code is available at https://github.com/billsioros/EditGen", "published": "2025-07-15 08:44:11", "link": "http://arxiv.org/abs/2507.11096v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Function-to-Style Guidance of LLMs for Code Translation", "abstract": "Large language models (LLMs) have made significant strides in code\ntranslation tasks. However, ensuring both the correctness and readability of\ntranslated code remains a challenge, limiting their effective adoption in\nreal-world software development. In this work, we propose F2STrans, a\nfunction-to-style guiding paradigm designed to progressively improve the\nperformance of LLMs in code translation. Our approach comprises two key stages:\n(1) Functional learning, which optimizes translation correctness using\nhigh-quality source-target code pairs mined from online programming platforms,\nand (2) Style learning, which improves translation readability by incorporating\nboth positive and negative style examples. Additionally, we introduce a novel\ncode translation benchmark that includes up-to-date source code, extensive test\ncases, and manually annotated ground-truth translations, enabling comprehensive\nfunctional and stylistic evaluations. Experiments on both our new benchmark and\nexisting datasets demonstrate that our approach significantly improves code\ntranslation performance. Notably, our approach enables Qwen-1.5B to outperform\nprompt-enhanced Qwen-32B and GPT-4 on average across 20 diverse code\ntranslation scenarios.", "published": "2025-07-15 08:25:02", "link": "http://arxiv.org/abs/2507.11083v1", "categories": ["cs.AI", "cs.SE"], "primary_category": "cs.AI"}
{"title": "Automatic Road Subsurface Distress Recognition from Ground Penetrating Radar Images using Deep Learning-based Cross-verification", "abstract": "Ground penetrating radar (GPR) has become a rapid and non-destructive\nsolution for road subsurface distress (RSD) detection. However, RSD recognition\nfrom GPR images is labor-intensive and heavily relies on inspectors' expertise.\nDeep learning offers the possibility for automatic RSD recognition, but its\ncurrent performance is limited by two factors: Scarcity of high-quality dataset\nfor network training and insufficient capability of network to distinguish RSD.\nIn this study, a rigorously validated 3D GPR dataset containing 2134 samples of\ndiverse types was constructed through field scanning. Based on the finding that\nthe YOLO model trained with one of the three scans of GPR images exhibits\nvarying sensitivity to specific type of RSD, we proposed a novel\ncross-verification strategy with outstanding accuracy in RSD recognition,\nachieving recall over 98.6% in field tests. The approach, integrated into an\nonline RSD detection system, can reduce the labor of inspection by around 90%.", "published": "2025-07-15 08:23:21", "link": "http://arxiv.org/abs/2507.11081v1", "categories": ["cs.CV", "cs.AI", "I.4.9; I.5.4; J.2"], "primary_category": "cs.CV"}
{"title": "Tactical Decision for Multi-UGV Confrontation with a Vision-Language Model-Based Commander", "abstract": "In multiple unmanned ground vehicle confrontations, autonomously evolving\nmulti-agent tactical decisions from situational awareness remain a significant\nchallenge. Traditional handcraft rule-based methods become vulnerable in the\ncomplicated and transient battlefield environment, and current reinforcement\nlearning methods mainly focus on action manipulation instead of strategic\ndecisions due to lack of interpretability. Here, we propose a vision-language\nmodel-based commander to address the issue of intelligent\nperception-to-decision reasoning in autonomous confrontations. Our method\nintegrates a vision language model for scene understanding and a lightweight\nlarge language model for strategic reasoning, achieving unified perception and\ndecision within a shared semantic space, with strong adaptability and\ninterpretability. Unlike rule-based search and reinforcement learning methods,\nthe combination of the two modules establishes a full-chain process, reflecting\nthe cognitive process of human commanders. Simulation and ablation experiments\nvalidate that the proposed approach achieves a win rate of over 80% compared\nwith baseline models.", "published": "2025-07-15 08:22:37", "link": "http://arxiv.org/abs/2507.11079v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Joint angle model based learning to refine kinematic human pose estimation", "abstract": "Marker-free human pose estimation (HPE) has found increasing applications in\nvarious fields. Current HPE suffers from occasional errors in keypoint\nrecognition and random fluctuation in keypoint trajectories when analyzing\nkinematic human poses. The performance of existing deep learning-based models\nfor HPE refinement is considerably limited by inaccurate training datasets in\nwhich the keypoints are manually annotated. This paper proposed a novel method\nto overcome the difficulty through joint angle-based modeling. The key\ntechniques include: (i) A joint angle-based model of human pose, which is\nrobust to describe kinematic human poses; (ii) Approximating temporal variation\nof joint angles through high order Fourier series to get reliable \"ground\ntruth\"; (iii) A bidirectional recurrent network is designed as a\npost-processing module to refine the estimation of well-established HRNet.\nTrained with the high-quality dataset constructed using our method, the network\ndemonstrates outstanding performance to correct wrongly recognized joints and\nsmooth their spatiotemporal trajectories. Tests show that joint angle-based\nrefinement (JAR) outperforms the state-of-the-art HPE refinement network in\nchallenging cases like figure skating and breaking.", "published": "2025-07-15 08:16:39", "link": "http://arxiv.org/abs/2507.11075v1", "categories": ["cs.CV", "cs.AI", "I.4.9; I.5.4; J.3"], "primary_category": "cs.CV"}
{"title": "LogTinyLLM: Tiny Large Language Models Based Contextual Log Anomaly Detection", "abstract": "Log anomaly detection using traditional rule based or deep learning based\nmethods is often challenging due to the large volume and highly complex nature\nof log sequence. So effective way of detection of anomalous sequence of logs is\ncrucial for system maintenance and development. This paper proposes parameter\nefficient finetuning specifically low rank adaptation (LoRA) and adapter based\napproaches for finding contextual anomalies in sequence of logs in large log\ndata set. It compares different tiny large language models (LLMs) on the\nThunderbird dataset. The results show that LoRA based finetuning provides\nsubstantial performance improvements of 18 to 19 percentage over LogBert based\nfull finetuning approach, achieving accuracy scores between 97.76% and 98.83%\ncompared to 79.37%.", "published": "2025-07-15 08:04:31", "link": "http://arxiv.org/abs/2507.11071v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Standards-Compliant DM-RS Allocation via Temporal Channel Prediction for Massive MIMO Systems", "abstract": "Reducing feedback overhead in beyond 5G networks is a critical challenge, as\nthe growing number of antennas in modern massive MIMO systems substantially\nincreases the channel state information (CSI) feedback demand in frequency\ndivision duplex (FDD) systems. To address this, extensive research has focused\non CSI compression and prediction, with neural network-based approaches gaining\nmomentum and being considered for integration into the 3GPP 5G-Advanced\nstandards. While deep learning has been effectively applied to CSI-limited\nbeamforming and handover optimization, reference signal allocation under such\nconstraints remains surprisingly underexplored. To fill this gap, we introduce\nthe concept of channel prediction-based reference signal allocation (CPRS),\nwhich jointly optimizes channel prediction and DM-RS allocation to improve data\nthroughput without requiring CSI feedback. We further propose a\nstandards-compliant ViViT/CNN-based architecture that implements CPRS by\ntreating evolving CSI matrices as sequential image-like data, enabling\nefficient and adaptive transmission in dynamic environments. Simulation results\nusing ray-tracing channel data generated in NVIDIA Sionna validate the proposed\nmethod, showing up to 36.60% throughput improvement over benchmark strategies.", "published": "2025-07-15 07:56:37", "link": "http://arxiv.org/abs/2507.11064v1", "categories": ["eess.SY", "cs.AI", "cs.SY", "eess.SP"], "primary_category": "eess.SY"}
{"title": "Robust 3D-Masked Part-level Editing in 3D Gaussian Splatting with Regularized Score Distillation Sampling", "abstract": "Recent advances in 3D neural representations and instance-level editing\nmodels have enabled the efficient creation of high-quality 3D content. However,\nachieving precise local 3D edits remains challenging, especially for Gaussian\nSplatting, due to inconsistent multi-view 2D part segmentations and inherently\nambiguous nature of Score Distillation Sampling (SDS) loss. To address these\nlimitations, we propose RoMaP, a novel local 3D Gaussian editing framework that\nenables precise and drastic part-level modifications. First, we introduce a\nrobust 3D mask generation module with our 3D-Geometry Aware Label Prediction\n(3D-GALP), which uses spherical harmonics (SH) coefficients to model\nview-dependent label variations and soft-label property, yielding accurate and\nconsistent part segmentations across viewpoints. Second, we propose a\nregularized SDS loss that combines the standard SDS loss with additional\nregularizers. In particular, an L1 anchor loss is introduced via our Scheduled\nLatent Mixing and Part (SLaMP) editing method, which generates high-quality\npart-edited 2D images and confines modifications only to the target region\nwhile preserving contextual coherence. Additional regularizers, such as\nGaussian prior removal, further improve flexibility by allowing changes beyond\nthe existing context, and robust 3D masking prevents unintended edits.\nExperimental results demonstrate that our RoMaP achieves state-of-the-art local\n3D editing on both reconstructed and generated Gaussian scenes and objects\nqualitatively and quantitatively, making it possible for more robust and\nflexible part-level 3D Gaussian editing.", "published": "2025-07-15 07:54:11", "link": "http://arxiv.org/abs/2507.11061v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Personalized Exercise Recommendation with Semantically-Grounded Knowledge Tracing", "abstract": "We introduce ExRec, a general framework for personalized exercise\nrecommendation with semantically-grounded knowledge tracing. Our method builds\non the observation that existing exercise recommendation approaches simulate\nstudent performance via knowledge tracing (KT) but they often overlook two key\naspects: (a) the semantic content of questions and (b) the sequential,\nstructured progression of student learning. To address this, our ExRec presents\nan end-to-end pipeline, from annotating the KCs of questions and learning their\nsemantic representations to training KT models and optimizing several\nreinforcement learning (RL) methods. Moreover, we improve standard\nQ-learning-based continuous RL methods via a tailored model-based value\nestimation (MVE) approach that directly leverages the components of KT model in\nestimating cumulative knowledge improvement. We validate the effectiveness of\nour ExRec using various RL methods across four real-world tasks with different\neducational goals in online math learning. We further show that ExRec\ngeneralizes robustly to new, unseen questions and that it produces\ninterpretable student learning trajectories. Together, our findings highlight\nthe promise of KT-guided RL for effective personalization in education.", "published": "2025-07-15 07:54:04", "link": "http://arxiv.org/abs/2507.11060v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "GATE: Graph Attention Neural Networks with Real-Time Edge Construction for Robust Indoor Localization using Mobile Embedded Devices", "abstract": "Accurate indoor localization is crucial for enabling spatial context in smart\nenvironments and navigation systems. Wi-Fi Received Signal Strength (RSS)\nfingerprinting is a widely used indoor localization approach due to its\ncompatibility with mobile embedded devices. Deep Learning (DL) models improve\naccuracy in localization tasks by learning RSS variations across locations, but\nthey assume fingerprint vectors exist in a Euclidean space, failing to\nincorporate spatial relationships and the non-uniform distribution of\nreal-world RSS noise. This results in poor generalization across heterogeneous\nmobile devices, where variations in hardware and signal processing distort RSS\nreadings. Graph Neural Networks (GNNs) can improve upon conventional DL models\nby encoding indoor locations as nodes and modeling their spatial and signal\nrelationships as edges. However, GNNs struggle with non-Euclidean noise\ndistributions and suffer from the GNN blind spot problem, leading to degraded\naccuracy in environments with dense access points (APs). To address these\nchallenges, we propose GATE, a novel framework that constructs an adaptive\ngraph representation of fingerprint vectors while preserving an indoor\nstate-space topology, modeling the non-Euclidean structure of RSS noise to\nmitigate environmental noise and address device heterogeneity. GATE introduces\n1) a novel Attention Hyperspace Vector (AHV) for enhanced message passing, 2) a\nnovel Multi-Dimensional Hyperspace Vector (MDHV) to mitigate the GNN blind\nspot, and 3) an new Real-Time Edge Construction (RTEC) approach for dynamic\ngraph adaptation. Extensive real-world evaluations across multiple indoor\nspaces with varying path lengths, AP densities, and heterogeneous devices\ndemonstrate that GATE achieves 1.6x to 4.72x lower mean localization errors and\n1.85x to 4.57x lower worst-case errors compared to state-of-the-art indoor\nlocalization frameworks.", "published": "2025-07-15 07:37:33", "link": "http://arxiv.org/abs/2507.11053v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Semantically Informed Salient Regions Guided Radiology Report Generation", "abstract": "Recent advances in automated radiology report generation from chest X-rays\nusing deep learning algorithms have the potential to significantly reduce the\narduous workload of radiologists. However, due to the inherent massive data\nbias in radiology images, where abnormalities are typically subtle and sparsely\ndistributed, existing methods often produce fluent yet medically inaccurate\nreports, limiting their applicability in clinical practice. To address this\nissue effectively, we propose a Semantically Informed Salient Regions-guided\n(SISRNet) report generation method. Specifically, our approach explicitly\nidentifies salient regions with medically critical characteristics using\nfine-grained cross-modal semantics. Then, SISRNet systematically focuses on\nthese high-information regions during both image modeling and report\ngeneration, effectively capturing subtle abnormal findings, mitigating the\nnegative impact of data bias, and ultimately generating clinically accurate\nreports. Compared to its peers, SISRNet demonstrates superior performance on\nwidely used IU-Xray and MIMIC-CXR datasets.", "published": "2025-07-15 06:15:07", "link": "http://arxiv.org/abs/2507.11015v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "SpaRTAN: Spatial Reinforcement Token-based Aggregation Network for Visual Recognition", "abstract": "The resurgence of convolutional neural networks (CNNs) in visual recognition\ntasks, exemplified by ConvNeXt, has demonstrated their capability to rival\ntransformer-based architectures through advanced training methodologies and\nViT-inspired design principles. However, both CNNs and transformers exhibit a\nsimplicity bias, favoring straightforward features over complex structural\nrepresentations. Furthermore, modern CNNs often integrate MLP-like blocks akin\nto those in transformers, but these blocks suffer from significant information\nredundancies, necessitating high expansion ratios to sustain competitive\nperformance. To address these limitations, we propose SpaRTAN, a lightweight\narchitectural design that enhances spatial and channel-wise information\nprocessing. SpaRTAN employs kernels with varying receptive fields, controlled\nby kernel size and dilation factor, to capture discriminative multi-order\nspatial features effectively. A wave-based channel aggregation module further\nmodulates and reinforces pixel interactions, mitigating channel-wise\nredundancies. Combining the two modules, the proposed network can efficiently\ngather and dynamically contextualize discriminative features. Experimental\nresults in ImageNet and COCO demonstrate that SpaRTAN achieves remarkable\nparameter efficiency while maintaining competitive performance. In particular,\non the ImageNet-1k benchmark, SpaRTAN achieves 77. 7% accuracy with only 3.8M\nparameters and approximately 1.0 GFLOPs, demonstrating its ability to deliver\nstrong performance through an efficient design. On the COCO benchmark, it\nachieves 50.0% AP, surpassing the previous benchmark by 1.2% with only 21.5M\nparameters. The code is publicly available at\n[https://github.com/henry-pay/SpaRTAN].", "published": "2025-07-15 05:34:56", "link": "http://arxiv.org/abs/2507.10999v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Crafting Imperceptible On-Manifold Adversarial Attacks for Tabular Data", "abstract": "Adversarial attacks on tabular data present fundamental challenges distinct\nfrom image or text domains due to the heterogeneous nature of mixed categorical\nand numerical features. Unlike images where pixel perturbations maintain visual\nsimilarity, tabular data lacks intuitive similarity metrics, making it\ndifficult to define imperceptible modifications. Additionally, traditional\ngradient-based methods prioritise $\\ell_p$-norm constraints, often producing\nadversarial examples that deviate from the original data distributions, making\nthem detectable. We propose a latent space perturbation framework using a\nmixed-input Variational Autoencoder (VAE) to generate imperceptible adversarial\nexamples. The proposed VAE integrates categorical embeddings and numerical\nfeatures into a unified latent manifold, enabling perturbations that preserve\nstatistical consistency. We specify In-Distribution Success Rate (IDSR) to\nmeasure the proportion of adversarial examples that remain statistically\nindistinguishable from the input distribution. Evaluation across six publicly\navailable datasets and three model architectures demonstrates that our method\nachieves substantially lower outlier rates and more consistent performance\ncompared to traditional input-space attacks and other VAE-based methods adapted\nfrom image domain approaches. Our comprehensive analysis includes\nhyperparameter sensitivity, sparsity control mechanisms, and generative\narchitectural comparisons, revealing that VAE-based attacks depend critically\non reconstruction quality but offer superior practical utility when sufficient\ntraining data is available. This work highlights the importance of on-manifold\nperturbations for realistic adversarial attacks on tabular data, offering a\nrobust approach for practical deployment. The source code can be accessed\nthrough https://github.com/ZhipengHe/VAE-TabAttack.", "published": "2025-07-15 05:34:44", "link": "http://arxiv.org/abs/2507.10998v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Misalignment from Treating Means as Ends", "abstract": "Reward functions, learned or manually specified, are rarely perfect. Instead\nof accurately expressing human goals, these reward functions are often\ndistorted by human beliefs about how best to achieve those goals. Specifically,\nthese reward functions often express a combination of the human's terminal\ngoals -- those which are ends in themselves -- and the human's instrumental\ngoals -- those which are means to an end. We formulate a simple example in\nwhich even slight conflation of instrumental and terminal goals results in\nsevere misalignment: optimizing the misspecified reward function results in\npoor performance when measured by the true reward function. This example\ndistills the essential properties of environments that make reinforcement\nlearning highly sensitive to conflation of instrumental and terminal goals. We\ndiscuss how this issue can arise with a common approach to reward learning and\nhow it can manifest in real environments.", "published": "2025-07-15 05:27:51", "link": "http://arxiv.org/abs/2507.10995v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Modeling Habitat Shifts: Integrating Convolutional Neural Networks and Tabular Data for Species Migration Prediction", "abstract": "Due to climate-induced changes, many habitats are experiencing range shifts\naway from their traditional geographic locations (Piguet, 2011). We propose a\nsolution to accurately model whether bird species are present in a specific\nhabitat through the combination of Convolutional Neural Networks (CNNs)\n(O'Shea, 2015) and tabular data. Our approach makes use of satellite imagery\nand environmental features (e.g., temperature, precipitation, elevation) to\npredict bird presence across various climates. The CNN model captures spatial\ncharacteristics of landscapes such as forestation, water bodies, and\nurbanization, whereas the tabular method uses ecological and geographic data.\nBoth systems predict the distribution of birds with an average accuracy of 85%,\noffering a scalable but reliable method to understand bird migration.", "published": "2025-07-15 05:17:58", "link": "http://arxiv.org/abs/2507.10993v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "High-Throughput Distributed Reinforcement Learning via Adaptive Policy Synchronization", "abstract": "Scaling reinforcement learning (RL) workloads often requires distributing\nenvironment simulation across compute clusters. Existing frameworks entangle\nsimulation, learning logic, and orchestration into monolithic systems, limiting\nmodularity and reusability. We present ClusterEnv, a lightweight,\nlearner-agnostic interface for distributed environment execution that mirrors\nthe Gymnasium API. ClusterEnv introduces the DETACH pattern, which decouples\nsimulation from training by offloading reset() and step() operations to remote\nworkers while keeping learning centralized. To address policy staleness in\ndistributed execution, we propose Adaptive Actor Policy Synchronization (AAPS),\na divergence-triggered update mechanism that reduces synchronization overhead\nwithout sacrificing performance. ClusterEnv integrates cleanly into existing RL\npipelines, supports both on-policy and off-policy methods, and requires minimal\ncode changes. Experiments on discrete control tasks demonstrate that AAPS\nachieves high sample efficiency with significantly fewer weight updates. Source\ncode is available at https://github.com/rodlaf/ClusterEnv.", "published": "2025-07-15 05:07:12", "link": "http://arxiv.org/abs/2507.10990v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Pronunciation Deviation Analysis Through Voice Cloning and Acoustic Comparison", "abstract": "This paper presents a novel approach for detecting mispronunciations by\nanalyzing deviations between a user's original speech and their voice-cloned\ncounterpart with corrected pronunciation. We hypothesize that regions with\nmaximal acoustic deviation between the original and cloned utterances indicate\npotential mispronunciations. Our method leverages recent advances in voice\ncloning to generate a synthetic version of the user's voice with proper\npronunciation, then performs frame-by-frame comparisons to identify problematic\nsegments. Experimental results demonstrate the effectiveness of this approach\nin pinpointing specific pronunciation errors without requiring predefined\nphonetic rules or extensive training data for each target language.", "published": "2025-07-15 04:58:19", "link": "http://arxiv.org/abs/2507.10985v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Conceptualizing Multi-scale Wavelet Attention and Ray-based Encoding for Human-Object Interaction Detection", "abstract": "Human-object interaction (HOI) detection is essential for accurately\nlocalizing and characterizing interactions between humans and objects,\nproviding a comprehensive understanding of complex visual scenes across various\ndomains. However, existing HOI detectors often struggle to deliver reliable\npredictions efficiently, relying on resource-intensive training methods and\ninefficient architectures. To address these challenges, we conceptualize a\nwavelet attention-like backbone and a novel ray-based encoder architecture\ntailored for HOI detection. Our wavelet backbone addresses the limitations of\nexpressing middle-order interactions by aggregating discriminative features\nfrom the low- and high-order interactions extracted from diverse convolutional\nfilters. Concurrently, the ray-based encoder facilitates multi-scale attention\nby optimizing the focus of the decoder on relevant regions of interest and\nmitigating computational overhead. As a result of harnessing the attenuated\nintensity of learnable ray origins, our decoder aligns query embeddings with\nemphasized regions of interest for accurate predictions. Experimental results\non benchmark datasets, including ImageNet and HICO-DET, showcase the potential\nof our proposed architecture. The code is publicly available at\n[https://github.com/henry-pay/RayEncoder].", "published": "2025-07-15 04:44:54", "link": "http://arxiv.org/abs/2507.10977v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Biological Processing Units: Leveraging an Insect Connectome to Pioneer Biofidelic Neural Architectures", "abstract": "The complete connectome of the Drosophila larva brain offers a unique\nopportunity to investigate whether biologically evolved circuits can support\nartificial intelligence. We convert this wiring diagram into a Biological\nProcessing Unit (BPU), a fixed recurrent network derived directly from synaptic\nconnectivity. Despite its modest size 3,000 neurons and 65,000 weights between\nthem), the unmodified BPU achieves 98% accuracy on MNIST and 58% on CIFAR-10,\nsurpassing size-matched MLPs. Scaling the BPU via structured connectome\nexpansions further improves CIFAR-10 performance, while modality-specific\nablations reveal the uneven contributions of different sensory subsystems. On\nthe ChessBench dataset, a lightweight GNN-BPU model trained on only 10,000\ngames achieves 60% move accuracy, nearly 10x better than any size transformer.\nMoreover, CNN-BPU models with ~2M parameters outperform parameter-matched\nTransformers, and with a depth-6 minimax search at inference, reach 91.7%\naccuracy, exceeding even a 9M-parameter Transformer baseline. These results\ndemonstrate the potential of biofidelic neural architectures to support complex\ncognitive tasks and motivate scaling to larger and more intelligent connectomes\nin future work.", "published": "2025-07-15 03:31:57", "link": "http://arxiv.org/abs/2507.10951v1", "categories": ["cs.NE", "cs.AI", "q-bio.NC"], "primary_category": "cs.NE"}
{"title": "Artificial Finance: How AI Thinks About Money", "abstract": "In this paper, we explore how large language models (LLMs) approach financial\ndecision-making by systematically comparing their responses to those of human\nparticipants across the globe. We posed a set of commonly used financial\ndecision-making questions to seven leading LLMs, including five models from the\nGPT series(GPT-4o, GPT-4.5, o1, o3-mini), Gemini 2.0 Flash, and DeepSeek R1. We\nthen compared their outputs to human responses drawn from a dataset covering 53\nnations. Our analysis reveals three main results. First, LLMs generally exhibit\na risk-neutral decision-making pattern, favoring choices aligned with expected\nvalue calculations when faced with lottery-type questions. Second, when\nevaluating trade-offs between present and future, LLMs occasionally produce\nresponses that appear inconsistent with normative reasoning. Third, when we\nexamine cross-national similarities, we find that the LLMs' aggregate responses\nmost closely resemble those of participants from Tanzania. These findings\ncontribute to the understanding of how LLMs emulate human-like decision\nbehaviors and highlight potential cultural and training influences embedded\nwithin their outputs.", "published": "2025-07-15 02:54:12", "link": "http://arxiv.org/abs/2507.10933v1", "categories": ["econ.GN", "cs.AI", "q-fin.EC"], "primary_category": "econ.GN"}
{"title": "Enhancing Safe and Controllable Protein Generation via Knowledge Preference Optimization", "abstract": "Protein language models have emerged as powerful tools for sequence\ngeneration, offering substantial advantages in functional optimization and\ndenovo design. However, these models also present significant risks of\ngenerating harmful protein sequences, such as those that enhance viral\ntransmissibility or evade immune responses. These concerns underscore critical\nbiosafety and ethical challenges. To address these issues, we propose a\nKnowledge-guided Preference Optimization (KPO) framework that integrates prior\nknowledge via a Protein Safety Knowledge Graph. This framework utilizes an\nefficient graph pruning strategy to identify preferred sequences and employs\nreinforcement learning to minimize the risk of generating harmful proteins.\nExperimental results demonstrate that KPO effectively reduces the likelihood of\nproducing hazardous sequences while maintaining high functionality, offering a\nrobust safety assurance framework for applying generative models in\nbiotechnology.", "published": "2025-07-15 02:30:33", "link": "http://arxiv.org/abs/2507.10923v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy Recommendation", "abstract": "Therapy recommendation for chronic patients with multimorbidity is\nchallenging due to risks of treatment conflicts. Existing decision support\nsystems face scalability limitations. Inspired by the way in which general\npractitioners (GP) manage multimorbidity patients, occasionally convening\nmultidisciplinary team (MDT) collaboration, this study investigated the\nfeasibility and value of using a Large Language Model (LLM)-based multi-agent\nsystem (MAS) for safer therapy recommendations. We designed a single agent and\na MAS framework simulating MDT decision-making by enabling discussion among LLM\nagents to resolve medical conflicts. The systems were evaluated on therapy\nplanning tasks for multimorbidity patients using benchmark cases. We compared\nMAS performance with single-agent approaches and real-world benchmarks. An\nimportant contribution of our study is the definition of evaluation metrics\nthat go beyond the technical precision and recall and allow the inspection of\nclinical goals met and medication burden of the proposed advices to a gold\nstandard benchmark. Our results show that with current LLMs, a single agent GP\nperforms as well as MDTs. The best-scoring models provide correct\nrecommendations that address all clinical goals, yet the advices are\nincomplete. Some models also present unnecessary medications, resulting in\nunnecessary conflicts between medication and conditions or drug-drug\ninteractions.", "published": "2025-07-15 02:01:38", "link": "http://arxiv.org/abs/2507.10911v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Class-Proportional Coreset Selection for Difficulty-Separable Data", "abstract": "High-quality training data is essential for building reliable and efficient\nmachine learning systems. One-shot coreset selection addresses this by pruning\nthe dataset while maintaining or even improving model performance, often\nrelying on training-dynamics-based data difficulty scores. However, most\nexisting methods implicitly assume class-wise homogeneity in data difficulty,\noverlooking variation in data difficulty across different classes.\n  In this work, we challenge this assumption by showing that, in domains such\nas network intrusion detection and medical imaging, data difficulty often\nclusters by class. We formalize this as class-difficulty separability and\nintroduce the Class Difficulty Separability Coefficient (CDSC) as a\nquantitative measure. We demonstrate that high CDSC values correlate with\nperformance degradation in class-agnostic coreset methods, which tend to\noverrepresent easy majority classes while neglecting rare but informative ones.\n  To address this, we introduce class-proportional variants of multiple\nsampling strategies. Evaluated on five diverse datasets spanning security and\nmedical domains, our methods consistently achieve state-of-the-art data\nefficiency. For instance, on CTU-13, at an extreme 99% pruning rate, a\nclass-proportional variant of Coverage-centric Coreset Selection (CCS-CP) shows\nremarkable stability, with accuracy dropping only 2.58%, precision 0.49%, and\nrecall 0.19%. In contrast, the class-agnostic CCS baseline, the next best\nmethod, suffers sharper declines of 7.59% in accuracy, 4.57% in precision, and\n4.11% in recall.\n  We further show that aggressive pruning enhances generalization in noisy,\nimbalanced, and large-scale datasets. Our results underscore that explicitly\nmodeling class-difficulty separability leads to more effective, robust, and\ngeneralizable data pruning, particularly in high-stakes scenarios.", "published": "2025-07-15 01:43:32", "link": "http://arxiv.org/abs/2507.10904v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "MalCodeAI: Autonomous Vulnerability Detection and Remediation via Language Agnostic Code Reasoning", "abstract": "The growing complexity of cyber threats and the limitations of traditional\nvulnerability detection tools necessitate novel approaches for securing\nsoftware systems. We introduce MalCodeAI, a language-agnostic, multi-stage AI\npipeline for autonomous code security analysis and remediation. MalCodeAI\ncombines code decomposition and semantic reasoning using fine-tuned\nQwen2.5-Coder-3B-Instruct models, optimized through Low-Rank Adaptation (LoRA)\nwithin the MLX framework, and delivers scalable, accurate results across 14\nprogramming languages. In Phase 1, the model achieved a validation loss as low\nas 0.397 for functional decomposition and summarization of code segments after\n200 iterations, 6 trainable layers, and a learning rate of 2 x 10^(-5). In\nPhase 2, for vulnerability detection and remediation, it achieved a best\nvalidation loss of 0.199 using the same number of iterations and trainable\nlayers but with an increased learning rate of 4 x 10^(-5), effectively\nidentifying security flaws and suggesting actionable fixes. MalCodeAI supports\nred-hat-style exploit tracing, CVSS-based risk scoring, and zero-shot\ngeneralization to detect complex, zero-day vulnerabilities. In a qualitative\nevaluation involving 15 developers, the system received high scores in\nusefulness (mean 8.06/10), interpretability (mean 7.40/10), and readability of\noutputs (mean 7.53/10), confirming its practical value in real-world\ndevelopment workflows. This work marks a significant advancement toward\nintelligent, explainable, and developer-centric software security solutions.", "published": "2025-07-15 01:25:04", "link": "http://arxiv.org/abs/2507.10898v1", "categories": ["cs.CR", "cs.AI", "cs.SE"], "primary_category": "cs.CR"}
{"title": "Commuting Distance Regularization for Timescale-Dependent Label Inconsistency in EEG Emotion Recognition", "abstract": "In this work, we address the often-overlooked issue of Timescale Dependent\nLabel Inconsistency (TsDLI) in training neural network models for EEG-based\nhuman emotion recognition. To mitigate TsDLI and enhance model generalization\nand explainability, we propose two novel regularization strategies: Local\nVariation Loss (LVL) and Local-Global Consistency Loss (LGCL). Both methods\nincorporate classical mathematical principles--specifically, functions of\nbounded variation and commute-time distances--within a graph theoretic\nframework. Complementing our regularizers, we introduce a suite of new\nevaluation metrics that better capture the alignment between temporally local\npredictions and their associated global emotion labels. We validate our\napproach through comprehensive experiments on two widely used EEG emotion\ndatasets, DREAMER and DEAP, across a range of neural architectures including\nLSTM and transformer-based models. Performance is assessed using five distinct\nmetrics encompassing both quantitative accuracy and qualitative consistency.\nResults consistently show that our proposed methods outperform state-of-the-art\nbaselines, delivering superior aggregate performance and offering a principled\ntrade-off between interpretability and predictive power under label\ninconsistency. Notably, LVL achieves the best aggregate rank across all\nbenchmarked backbones and metrics, while LGCL frequently ranks the second,\nhighlighting the effectiveness of our framework.", "published": "2025-07-15 01:22:14", "link": "http://arxiv.org/abs/2507.10895v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.SP"], "primary_category": "cs.CV"}
{"title": "Modernizing CNN-based Weather Forecast Model towards Higher Computational Efficiency", "abstract": "Recently, AI-based weather forecast models have achieved impressive advances.\nThese models have reached accuracy levels comparable to traditional NWP\nsystems, marking a significant milestone in data-driven weather prediction.\nHowever, they mostly leverage Transformer-based architectures, which often\nleads to high training complexity and resource demands due to the massive\nparameter sizes. In this study, we introduce a modernized CNN-based model for\nglobal weather forecasting that delivers competitive accuracy while\nsignificantly reducing computational requirements. To present a systematic\nmodernization roadmap, we highlight key architectural enhancements across\nmultiple design scales from an earlier CNN-based approach. KAI-a incorporates a\nscale-invariant architecture and InceptionNeXt-based blocks within a\ngeophysically-aware design, tailored to the structure of Earth system data.\nTrained on the ERA5 daily dataset with 67 atmospheric variables, the model\ncontains about 7 million parameters and completes training in just 12 hours on\na single NVIDIA L40s GPU. Our evaluation shows that KAI-a matches the\nperformance of state-of-the-art models in medium-range weather forecasting,\nwhile offering a significantly lightweight design. Furthermore, case studies on\nthe 2018 European heatwave and the East Asian summer monsoon demonstrate\nKAI-a's robust skill in capturing extreme events, reinforcing its practical\nutility.", "published": "2025-07-15 01:16:32", "link": "http://arxiv.org/abs/2507.10893v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "physics.ao-ph"], "primary_category": "cs.CV"}
{"title": "How to Protect Models against Adversarial Unlearning?", "abstract": "AI models need to be unlearned to fulfill the requirements of legal acts such\nas the AI Act or GDPR, and also because of the need to remove toxic content,\ndebiasing, the impact of malicious instances, or changes in the data\ndistribution structure in which a model works. Unfortunately, removing\nknowledge may cause undesirable side effects, such as a deterioration in model\nperformance. In this paper, we investigate the problem of adversarial\nunlearning, where a malicious party intentionally sends unlearn requests to\ndeteriorate the model's performance maximally. We show that this phenomenon and\nthe adversary's capabilities depend on many factors, primarily on the backbone\nmodel itself and strategy/limitations in selecting data to be unlearned. The\nmain result of this work is a new method of protecting model performance from\nthese side effects, both in the case of unlearned behavior resulting from\nspontaneous processes and adversary actions.", "published": "2025-07-15 00:59:42", "link": "http://arxiv.org/abs/2507.10886v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Towards Depth Foundation Model: Recent Trends in Vision-Based Depth Estimation", "abstract": "Depth estimation is a fundamental task in 3D computer vision, crucial for\napplications such as 3D reconstruction, free-viewpoint rendering, robotics,\nautonomous driving, and AR/VR technologies. Traditional methods relying on\nhardware sensors like LiDAR are often limited by high costs, low resolution,\nand environmental sensitivity, limiting their applicability in real-world\nscenarios. Recent advances in vision-based methods offer a promising\nalternative, yet they face challenges in generalization and stability due to\neither the low-capacity model architectures or the reliance on domain-specific\nand small-scale datasets. The emergence of scaling laws and foundation models\nin other domains has inspired the development of \"depth foundation models\":\ndeep neural networks trained on large datasets with strong zero-shot\ngeneralization capabilities. This paper surveys the evolution of deep learning\narchitectures and paradigms for depth estimation across the monocular, stereo,\nmulti-view, and monocular video settings. We explore the potential of these\nmodels to address existing challenges and provide a comprehensive overview of\nlarge-scale datasets that can facilitate their development. By identifying key\narchitectures and training strategies, we aim to highlight the path towards\nrobust depth foundation models, offering insights into their future research\nand applications.", "published": "2025-07-15 17:59:59", "link": "http://arxiv.org/abs/2507.11540v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CharaConsist: Fine-Grained Consistent Character Generation", "abstract": "In text-to-image generation, producing a series of consistent contents that\npreserve the same identity is highly valuable for real-world applications.\nAlthough a few works have explored training-free methods to enhance the\nconsistency of generated subjects, we observe that they suffer from the\nfollowing problems. First, they fail to maintain consistent background details,\nwhich limits their applicability. Furthermore, when the foreground character\nundergoes large motion variations, inconsistencies in identity and clothing\ndetails become evident. To address these problems, we propose CharaConsist,\nwhich employs point-tracking attention and adaptive token merge along with\ndecoupled control of the foreground and background. CharaConsist enables\nfine-grained consistency for both foreground and background, supporting the\ngeneration of one character in continuous shots within a fixed scene or in\ndiscrete shots across different scenes. Moreover, CharaConsist is the first\nconsistent generation method tailored for text-to-image DiT model. Its ability\nto maintain fine-grained consistency, combined with the larger capacity of\nlatest base model, enables it to produce high-quality visual outputs,\nbroadening its applicability to a wider range of real-world scenarios. The\nsource code has been released at https://github.com/Murray-Wang/CharaConsist", "published": "2025-07-15 17:58:08", "link": "http://arxiv.org/abs/2507.11533v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CATVis: Context-Aware Thought Visualization", "abstract": "EEG-based brain-computer interfaces (BCIs) have shown promise in various\napplications, such as motor imagery and cognitive state monitoring. However,\ndecoding visual representations from EEG signals remains a significant\nchallenge due to their complex and noisy nature. We thus propose a novel\n5-stage framework for decoding visual representations from EEG signals: (1) an\nEEG encoder for concept classification, (2) cross-modal alignment of EEG and\ntext embeddings in CLIP feature space, (3) caption refinement via re-ranking,\n(4) weighted interpolation of concept and caption embeddings for richer\nsemantics, and (5) image generation using a pre-trained Stable Diffusion model.\nWe enable context-aware EEG-to-image generation through cross-modal alignment\nand re-ranking. Experimental results demonstrate that our method generates\nhigh-quality images aligned with visual stimuli, outperforming SOTA approaches\nby 13.43% in Classification Accuracy, 15.21% in Generation Accuracy and\nreducing Fr\\'echet Inception Distance by 36.61%, indicating superior semantic\nalignment and image quality.", "published": "2025-07-15 17:47:01", "link": "http://arxiv.org/abs/2507.11522v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "C-FBI: A Combinatorial method using Convolutions for Circle Fitting in Blurry Images", "abstract": "This paper addresses the fundamental computer vision challenge of robust\ncircle detection and fitting in degraded imaging conditions. We present\nCombinatorial Convolution-based Circle Fitting for Blurry Images (3C-FBI), an\nalgorithm that bridges the gap between circle detection and precise parametric\nfitting by combining (1) efficient combinatorial edge pixel (edgel) sampling\nand (2) convolution-based density estimation in parameter space.\n  We evaluate 3C-FBI across three experimental frameworks: (1) real-world\nmedical data from Parkinson's disease assessments (144 frames from 36 videos),\n(2) controlled synthetic data following established circle-fitting benchmarks,\nand (3) systematic analysis across varying spatial resolutions and outlier\ncontamination levels. Results show that 3C-FBI achieves state-of-the-art\naccuracy (Jaccard index 0.896) while maintaining real-time performance (40.3\nfps), significantly outperforming classical methods like RCD (6.8 fps) on a\nstandard CPU (i7-10875H). It maintains near-perfect accuracy (Jaccard almost\n1.0) at high resolutions (480x480) and reliable performance (Jaccard higher\nthan 0.95) down to 160x160 with up to 20% outliers.\n  In extensive synthetic testing, 3C-FBI achieves a mean Jaccard Index of 0.989\nacross contamination levels, comparable to modern methods like Qi et al. (2024,\n0.991), and surpassing RHT (0.964). This combination of accuracy, speed, and\nrobustness makes 3C-FBI ideal for medical imaging, robotics, and industrial\ninspection under challenging conditions.", "published": "2025-07-15 16:47:44", "link": "http://arxiv.org/abs/2507.11476v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HUG-VAS: A Hierarchical NURBS-Based Generative Model for Aortic Geometry Synthesis and Controllable Editing", "abstract": "Accurate characterization of vascular geometry is essential for\ncardiovascular diagnosis and treatment planning. Traditional statistical shape\nmodeling (SSM) methods rely on linear assumptions, limiting their expressivity\nand scalability to complex topologies such as multi-branch vascular structures.\nWe introduce HUG-VAS, a Hierarchical NURBS Generative model for Vascular\ngeometry Synthesis, which integrates NURBS surface parameterization with\ndiffusion-based generative modeling to synthesize realistic, fine-grained\naortic geometries. Trained with 21 patient-specific samples, HUG-VAS generates\nanatomically faithful aortas with supra-aortic branches, yielding biomarker\ndistributions that closely match those of the original dataset. HUG-VAS adopts\na hierarchical architecture comprising a denoising diffusion model that\ngenerates centerlines and a guided diffusion model that synthesizes radial\nprofiles conditioned on those centerlines, thereby capturing two layers of\nanatomical variability. Critically, the framework supports zero-shot\nconditional generation from image-derived priors, enabling practical\napplications such as interactive semi-automatic segmentation, robust\nreconstruction under degraded imaging conditions, and implantable device\noptimization. To our knowledge, HUG-VAS is the first SSM framework to bridge\nimage-derived priors with generative shape modeling via a unified integration\nof NURBS parameterization and hierarchical diffusion processes.", "published": "2025-07-15 16:45:43", "link": "http://arxiv.org/abs/2507.11474v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Elevating 3D Models: High-Quality Texture and Geometry Refinement from a Low-Quality Model", "abstract": "High-quality 3D assets are essential for various applications in computer\ngraphics and 3D vision but remain scarce due to significant acquisition costs.\nTo address this shortage, we introduce Elevate3D, a novel framework that\ntransforms readily accessible low-quality 3D assets into higher quality. At the\ncore of Elevate3D is HFS-SDEdit, a specialized texture enhancement method that\nsignificantly improves texture quality while preserving the appearance and\ngeometry while fixing its degradations. Furthermore, Elevate3D operates in a\nview-by-view manner, alternating between texture and geometry refinement.\nUnlike previous methods that have largely overlooked geometry refinement, our\nframework leverages geometric cues from images refined with HFS-SDEdit by\nemploying state-of-the-art monocular geometry predictors. This approach ensures\ndetailed and accurate geometry that aligns seamlessly with the enhanced\ntexture. Elevate3D outperforms recent competitors by achieving state-of-the-art\nquality in 3D model refinement, effectively addressing the scarcity of\nhigh-quality open-source 3D assets.", "published": "2025-07-15 16:36:20", "link": "http://arxiv.org/abs/2507.11465v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Deep Equilibrium models for Poisson Imaging Inverse problems via Mirror Descent", "abstract": "Deep Equilibrium Models (DEQs) are implicit neural networks with fixed\npoints, which have recently gained attention for learning image regularization\nfunctionals, particularly in settings involving Gaussian fidelities, where\nassumptions on the forward operator ensure contractiveness of standard\n(proximal) Gradient Descent operators. In this work, we extend the application\nof DEQs to Poisson inverse problems, where the data fidelity term is more\nappropriately modeled by the Kullback-Leibler divergence. To this end, we\nintroduce a novel DEQ formulation based on Mirror Descent defined in terms of a\ntailored non-Euclidean geometry that naturally adapts with the structure of the\ndata term. This enables the learning of neural regularizers within a principled\ntraining framework. We derive sufficient conditions to guarantee the\nconvergence of the learned reconstruction scheme and propose computational\nstrategies that enable both efficient training and fully parameter-free\ninference. Numerical experiments show that our method outperforms traditional\nmodel-based approaches and it is comparable to the performance of Bregman\nPlug-and-Play methods, while mitigating their typical drawbacks - namely,\nsensitivity to initialization and careful tuning of hyperparameters. The code\nis publicly available at https://github.com/christiandaniele/DEQ-MD.", "published": "2025-07-15 16:33:01", "link": "http://arxiv.org/abs/2507.11461v1", "categories": ["math.OC", "cs.CV", "65K10, 65J22, 94A08, 47N10"], "primary_category": "math.OC"}
{"title": "Implementing Adaptations for Vision AutoRegressive Model", "abstract": "Vision AutoRegressive model (VAR) was recently introduced as an alternative\nto Diffusion Models (DMs) in image generation domain. In this work we focus on\nits adaptations, which aim to fine-tune pre-trained models to perform specific\ndownstream tasks, like medical data generation. While for DMs there exist many\ntechniques, adaptations for VAR remain underexplored. Similarly, differentially\nprivate (DP) adaptations-ones that aim to preserve privacy of the adaptation\ndata-have been extensively studied for DMs, while VAR lacks such solutions. In\nour work, we implement and benchmark many strategies for VAR, and compare them\nto state-of-the-art DM adaptation strategies. We observe that VAR outperforms\nDMs for non-DP adaptations, however, the performance of DP suffers, which\nnecessitates further research in private adaptations for VAR. Code is available\nat https://github.com/sprintml/finetuning_var_dp.", "published": "2025-07-15 16:05:30", "link": "http://arxiv.org/abs/2507.11441v1", "categories": ["cs.CV", "cs.LG", "I.2.6; I.5.1; I.4.8; I.2.10"], "primary_category": "cs.CV"}
{"title": "Stochastic Entanglement Configuration for Constructive Entanglement Topologies in Quantum Machine Learning with Application to Cardiac MRI", "abstract": "Efficient entanglement strategies are essential for advancing variational\nquantum circuits (VQCs) for quantum machine learning (QML). However, most\ncurrent approaches use fixed entanglement topologies that are not adaptive to\ntask requirements, limiting potential gains over classical models. We introduce\na novel stochastic entanglement configuration method that systematically\ngenerates diverse entanglement topologies to identify a subspace of\nconstructive entanglement configurations, defined as entanglement topologies\nthat boost hybrid model performance (e.g., classification accuracy) beyond\nclassical baselines. Each configuration is encoded as a stochastic binary\nmatrix, denoting directed entanglement between qubits. This enables scalable\nexploration of the hyperspace of candidate entanglement topologies using\nentanglement density and per-qubit constraints as key metrics. We define\nunconstrained and constrained sampling modes, controlling entanglement per\nqubit. Using our method, 400 stochastic configurations were generated and\nevaluated in a hybrid QML for cardiac MRI disease classification. We identified\n64 (16%) novel constructive entanglement configurations that consistently\noutperformed the classical baseline. Ensemble aggregation of top-performing\nconfigurations achieved ~0.92 classification accuracy, exceeding the classical\nmodel (~0.87) by over 5%. Compared to four conventional topologies (ring,\nnearest neighbor, no entanglement, fully entangled), none surpassed the\nclassical baseline (maximum accuracy ~0.82), while our configurations delivered\nup to ~20% higher accuracy. Thus, highlighting the robustness and\ngeneralizability of the identified constructive entanglements.", "published": "2025-07-15 15:12:59", "link": "http://arxiv.org/abs/2507.11401v1", "categories": ["quant-ph", "cs.CV", "cs.ET", "cs.LG"], "primary_category": "quant-ph"}
{"title": "UGC-VideoCaptioner: An Omni UGC Video Detail Caption Model and New Benchmarks", "abstract": "Real-world user-generated videos, especially on platforms like TikTok, often\nfeature rich and intertwined audio visual content. However, existing video\ncaptioning benchmarks and models remain predominantly visual centric,\noverlooking the crucial role of audio in conveying scene dynamics, speaker\nintent, and narrative context. This lack of omni datasets and lightweight,\ncapable models hampers progress in fine grained, multimodal video\nunderstanding. To address these challenges, we introduce UGC-VideoCap, a new\nbenchmark and model framework specifically designed for detailed omnimodal\ncaptioning of short form user-generated videos. Unlike prior datasets,\nUGC-VideoCap emphasizes balanced integration of audio and visual modalities,\nfeaturing 1000 TikTok videos annotated through a structured three stage\nhuman-in-the-loop pipeline covering audio only, visual only, and joint audio\nvisual semantics. The benchmark also includes 4000 carefully crafted QA pairs\nprobing both unimodal and cross modal understanding. Alongside the dataset, we\npropose UGC-VideoCaptioner(3B), a 3B parameter captioning model distilled from\nGemini 2.5 Flash. Using a novel two-stage training strategy supervised fine\ntuning followed by Group Relative Policy Optimization (GRPO), our approach\nenables efficient adaptation from limited data while maintaining competitive\nperformance. Together, our benchmark and model offer a high-quality foundation\nand a data-efficient solution for advancing omnimodal video captioning in\nunconstrained real-world UGC settings.", "published": "2025-07-15 14:08:29", "link": "http://arxiv.org/abs/2507.11336v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MonoMVSNet: Monocular Priors Guided Multi-View Stereo Network", "abstract": "Learning-based Multi-View Stereo (MVS) methods aim to predict depth maps for\na sequence of calibrated images to recover dense point clouds. However,\nexisting MVS methods often struggle with challenging regions, such as\ntextureless regions and reflective surfaces, where feature matching fails. In\ncontrast, monocular depth estimation inherently does not require feature\nmatching, allowing it to achieve robust relative depth estimation in these\nregions. To bridge this gap, we propose MonoMVSNet, a novel monocular feature\nand depth guided MVS network that integrates powerful priors from a monocular\nfoundation model into multi-view geometry. Firstly, the monocular feature of\nthe reference view is integrated into source view features by the attention\nmechanism with a newly designed cross-view position encoding. Then, the\nmonocular depth of the reference view is aligned to dynamically update the\ndepth candidates for edge regions during the sampling procedure. Finally, a\nrelative consistency loss is further designed based on the monocular depth to\nsupervise the depth prediction. Extensive experiments demonstrate that\nMonoMVSNet achieves state-of-the-art performance on the DTU and\nTanks-and-Temples datasets, ranking first on the Tanks-and-Temples Intermediate\nand Advanced benchmarks. The source code is available at\nhttps://github.com/JianfeiJ/MonoMVSNet.", "published": "2025-07-15 14:05:22", "link": "http://arxiv.org/abs/2507.11333v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Mixed-Primitive-based Gaussian Splatting Method for Surface Reconstruction", "abstract": "Recently, Gaussian Splatting (GS) has received a lot of attention in surface\nreconstruction. However, while 3D objects can be of complex and diverse shapes\nin the real world, existing GS-based methods only limitedly use a single type\nof splatting primitive (Gaussian ellipse or Gaussian ellipsoid) to represent\nobject surfaces during their reconstruction. In this paper, we highlight that\nthis can be insufficient for object surfaces to be represented in high quality.\nThus, we propose a novel framework that, for the first time, enables Gaussian\nSplatting to incorporate multiple types of (geometrical) primitives during its\nsurface reconstruction process. Specifically, in our framework, we first\npropose a compositional splatting strategy, enabling the splatting and\nrendering of different types of primitives in the Gaussian Splatting pipeline.\nIn addition, we also design our framework with a mixed-primitive-based\ninitialization strategy and a vertex pruning mechanism to further promote its\nsurface representation learning process to be well executed leveraging\ndifferent types of primitives. Extensive experiments show the efficacy of our\nframework and its accurate surface reconstruction performance.", "published": "2025-07-15 13:52:40", "link": "http://arxiv.org/abs/2507.11321v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "All Eyes, no IMU: Learning Flight Attitude from Vision Alone", "abstract": "Vision is an essential part of attitude control for many flying animals, some\nof which have no dedicated sense of gravity. Flying robots, on the other hand,\ntypically depend heavily on accelerometers and gyroscopes for attitude\nstabilization. In this work, we present the first vision-only approach to\nflight control for use in generic environments. We show that a quadrotor drone\nequipped with a downward-facing event camera can estimate its attitude and\nrotation rate from just the event stream, enabling flight control without\ninertial sensors. Our approach uses a small recurrent convolutional neural\nnetwork trained through supervised learning. Real-world flight tests\ndemonstrate that our combination of event camera and low-latency neural network\nis capable of replacing the inertial measurement unit in a traditional flight\ncontrol loop. Furthermore, we investigate the network's generalization across\ndifferent environments, and the impact of memory and different fields of view.\nWhile networks with memory and access to horizon-like visual cues achieve best\nperformance, variants with a narrower field of view achieve better relative\ngeneralization. Our work showcases vision-only flight control as a promising\ncandidate for enabling autonomous, insect-scale flying robots.", "published": "2025-07-15 13:31:27", "link": "http://arxiv.org/abs/2507.11302v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Detecci\u00f3n y Cuantificaci\u00f3n de Erosi\u00f3n Fluvial con Visi\u00f3n Artificial", "abstract": "Fluvial erosion is a natural process that can generate significant impacts on\nsoil stability and strategic infrastructures. The detection and monitoring of\nthis phenomenon is traditionally addressed by photogrammetric methods and\nanalysis in geographic information systems. These tasks require specific\nknowledge and intensive manual processing. This study proposes an artificial\nintelligence-based approach for automatic identification of eroded zones and\nestimation of their area. The state-of-the-art computer vision model YOLOv11,\nadjusted by fine-tuning and trained with photographs and LiDAR images, is used.\nThis combined dataset was segmented and labeled using the Roboflow platform.\nExperimental results indicate efficient detection of erosion patterns with an\naccuracy of 70%, precise identification of eroded areas and reliable\ncalculation of their extent in pixels and square meters. As a final product,\nthe EROSCAN system has been developed, an interactive web application that\nallows users to upload images and obtain automatic segmentations of fluvial\nerosion, together with the estimated area. This tool optimizes the detection\nand quantification of the phenomenon, facilitating decision making in risk\nmanagement and territorial planning.", "published": "2025-07-15 13:30:58", "link": "http://arxiv.org/abs/2507.11301v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "3D Magnetic Inverse Routine for Single-Segment Magnetic Field Images", "abstract": "In semiconductor packaging, accurately recovering 3D information is crucial\nfor non-destructive testing (NDT) to localize circuit defects. This paper\npresents a novel approach called the 3D Magnetic Inverse Routine (3D MIR),\nwhich leverages Magnetic Field Images (MFI) to retrieve the parameters for the\n3D current flow of a single-segment. The 3D MIR integrates a deep learning\n(DL)-based Convolutional Neural Network (CNN), spatial-physics-based\nconstraints, and optimization techniques. The method operates in three stages:\ni) The CNN model processes the MFI data to predict ($\\ell/z_o$), where $\\ell$\nis the wire length and $z_o$ is the wire's vertical depth beneath the magnetic\nsensors and classify segment type ($c$). ii) By leveraging\nspatial-physics-based constraints, the routine provides initial estimates for\nthe position ($x_o$, $y_o$, $z_o$), length ($\\ell$), current ($I$), and current\nflow direction (positive or negative) of the current segment. iii) An optimizer\nthen adjusts these five parameters ($x_o$, $y_o$, $z_o$, $\\ell$, $I$) to\nminimize the difference between the reconstructed MFI and the actual MFI. The\nresults demonstrate that the 3D MIR method accurately recovers 3D information\nwith high precision, setting a new benchmark for magnetic image reconstruction\nin semiconductor packaging. This method highlights the potential of combining\nDL and physics-driven optimization in practical applications.", "published": "2025-07-15 13:20:13", "link": "http://arxiv.org/abs/2507.11293v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Task-Oriented Human Grasp Synthesis via Context- and Task-Aware Diffusers", "abstract": "In this paper, we study task-oriented human grasp synthesis, a new grasp\nsynthesis task that demands both task and context awareness. At the core of our\nmethod is the task-aware contact maps. Unlike traditional contact maps that\nonly reason about the manipulated object and its relation with the hand, our\nenhanced maps take into account scene and task information. This comprehensive\nmap is critical for hand-object interaction, enabling accurate grasping poses\nthat align with the task. We propose a two-stage pipeline that first constructs\na task-aware contact map informed by the scene and task. In the subsequent\nstage, we use this contact map to synthesize task-oriented human grasps. We\nintroduce a new dataset and a metric for the proposed task to evaluate our\napproach. Our experiments validate the importance of modeling both scene and\ntask, demonstrating significant improvements over existing methods in both\ngrasp quality and task performance. See our project page for more details:\nhttps://hcis-lab.github.io/TOHGS/", "published": "2025-07-15 13:11:55", "link": "http://arxiv.org/abs/2507.11287v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Tomato Multi-Angle Multi-Pose Dataset for Fine-Grained Phenotyping", "abstract": "Observer bias and inconsistencies in traditional plant phenotyping methods\nlimit the accuracy and reproducibility of fine-grained plant analysis. To\novercome these challenges, we developed TomatoMAP, a comprehensive dataset for\nSolanum lycopersicum using an Internet of Things (IoT) based imaging system\nwith standardized data acquisition protocols. Our dataset contains 64,464 RGB\nimages that capture 12 different plant poses from four camera elevation angles.\nEach image includes manually annotated bounding boxes for seven regions of\ninterest (ROIs), including leaves, panicle, batch of flowers, batch of fruits,\naxillary shoot, shoot and whole plant area, along with 50 fine-grained growth\nstage classifications based on the BBCH scale. Additionally, we provide 3,616\nhigh-resolution image subset with pixel-wise semantic and instance segmentation\nannotations for fine-grained phenotyping. We validated our dataset using a\ncascading model deep learning framework combining MobileNetv3 for\nclassification, YOLOv11 for object detection, and MaskRCNN for segmentation.\nThrough AI vs. Human analysis involving five domain experts, we demonstrate\nthat the models trained on our dataset achieve accuracy and speed comparable to\nthe experts. Cohen's Kappa and inter-rater agreement heatmap confirm the\nreliability of automated fine-grained phenotyping using our approach.", "published": "2025-07-15 12:56:13", "link": "http://arxiv.org/abs/2507.11279v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ViewSRD: 3D Visual Grounding via Structured Multi-View Decomposition", "abstract": "3D visual grounding aims to identify and localize objects in a 3D space based\non textual descriptions. However, existing methods struggle with disentangling\ntargets from anchors in complex multi-anchor queries and resolving\ninconsistencies in spatial descriptions caused by perspective variations. To\ntackle these challenges, we propose ViewSRD, a framework that formulates 3D\nvisual grounding as a structured multi-view decomposition process. First, the\nSimple Relation Decoupling (SRD) module restructures complex multi-anchor\nqueries into a set of targeted single-anchor statements, generating a\nstructured set of perspective-aware descriptions that clarify positional\nrelationships. These decomposed representations serve as the foundation for the\nMulti-view Textual-Scene Interaction (Multi-TSI) module, which integrates\ntextual and scene features across multiple viewpoints using shared, Cross-modal\nConsistent View Tokens (CCVTs) to preserve spatial correlations. Finally, a\nTextual-Scene Reasoning module synthesizes multi-view predictions into a\nunified and robust 3D visual grounding. Experiments on 3D visual grounding\ndatasets show that ViewSRD significantly outperforms state-of-the-art methods,\nparticularly in complex queries requiring precise spatial differentiation.", "published": "2025-07-15 12:35:01", "link": "http://arxiv.org/abs/2507.11261v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MFGDiffusion: Mask-Guided Smoke Synthesis for Enhanced Forest Fire Detection", "abstract": "Smoke is the first visible indicator of a wildfire.With the advancement of\ndeep learning, image-based smoke detection has become a crucial method for\ndetecting and preventing forest fires. However, the scarcity of smoke image\ndata from forest fires is one of the significant factors hindering the\ndetection of forest fire smoke. Image generation models offer a promising\nsolution for synthesizing realistic smoke images. However, current inpainting\nmodels exhibit limitations in generating high-quality smoke representations,\nparticularly manifesting as inconsistencies between synthesized smoke and\nbackground contexts. To solve these problems, we proposed a comprehensive\nframework for generating forest fire smoke images. Firstly, we employed the\npre-trained segmentation model and the multimodal model to obtain smoke masks\nand image captions.Then, to address the insufficient utilization of masks and\nmasked images by inpainting models, we introduced a network architecture guided\nby mask and masked image features. We also proposed a new loss function, the\nmask random difference loss, which enhances the consistency of the generated\neffects around the mask by randomly expanding and eroding the mask\nedges.Finally, to generate a smoke image dataset using random masks for\nsubsequent detection tasks, we incorporated smoke characteristics and use a\nmultimodal large language model as a filtering tool to select diverse and\nreasonable smoke images, thereby improving the quality of the synthetic\ndataset. Experiments showed that our generated smoke images are realistic and\ndiverse, and effectively enhance the performance of forest fire smoke detection\nmodels. Code is available at https://github.com/wghr123/MFGDiffusion.", "published": "2025-07-15 12:25:35", "link": "http://arxiv.org/abs/2507.11252v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Fairness-Aware Grouping for Continuous Sensitive Variables: Application for Debiasing Face Analysis with respect to Skin Tone", "abstract": "Within a legal framework, fairness in datasets and models is typically\nassessed by dividing observations into predefined groups and then computing\nfairness measures (e.g., Disparate Impact or Equality of Odds with respect to\ngender). However, when sensitive attributes such as skin color are continuous,\ndividing into default groups may overlook or obscure the discrimination\nexperienced by certain minority subpopulations. To address this limitation, we\npropose a fairness-based grouping approach for continuous (possibly\nmultidimensional) sensitive attributes. By grouping data according to observed\nlevels of discrimination, our method identifies the partition that maximizes a\nnovel criterion based on inter-group variance in discrimination, thereby\nisolating the most critical subgroups.\n  We validate the proposed approach using multiple synthetic datasets and\ndemonstrate its robustness under changing population distributions - revealing\nhow discrimination is manifested within the space of sensitive attributes.\nFurthermore, we examine a specialized setting of monotonic fairness for the\ncase of skin color. Our empirical results on both CelebA and FFHQ, leveraging\nthe skin tone as predicted by an industrial proprietary algorithm, show that\nthe proposed segmentation uncovers more nuanced patterns of discrimination than\npreviously reported, and that these findings remain stable across datasets for\na given model. Finally, we leverage our grouping model for debiasing purpose,\naiming at predicting fair scores with group-by-group post-processing. The\nresults demonstrate that our approach improves fairness while having minimal\nimpact on accuracy, thus confirming our partition method and opening the door\nfor industrial deployment.", "published": "2025-07-15 12:21:52", "link": "http://arxiv.org/abs/2507.11247v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "NarrLV: Towards a Comprehensive Narrative-Centric Evaluation for Long Video Generation Models", "abstract": "With the rapid development of foundation video generation technologies, long\nvideo generation models have exhibited promising research potential thanks to\nexpanded content creation space. Recent studies reveal that the goal of long\nvideo generation tasks is not only to extend video duration but also to\naccurately express richer narrative content within longer videos. However, due\nto the lack of evaluation benchmarks specifically designed for long video\ngeneration models, the current assessment of these models primarily relies on\nbenchmarks with simple narrative prompts (e.g., VBench). To the best of our\nknowledge, our proposed NarrLV is the first benchmark to comprehensively\nevaluate the Narrative expression capabilities of Long Video generation models.\nInspired by film narrative theory, (i) we first introduce the basic narrative\nunit maintaining continuous visual presentation in videos as Temporal Narrative\nAtom (TNA), and use its count to quantitatively measure narrative richness.\nGuided by three key film narrative elements influencing TNA changes, we\nconstruct an automatic prompt generation pipeline capable of producing\nevaluation prompts with a flexibly expandable number of TNAs. (ii) Then, based\non the three progressive levels of narrative content expression, we design an\neffective evaluation metric using the MLLM-based question generation and\nanswering framework. (iii) Finally, we conduct extensive evaluations on\nexisting long video generation models and the foundation generation models.\nExperimental results demonstrate that our metric aligns closely with human\njudgments. The derived evaluation outcomes reveal the detailed capability\nboundaries of current video generation models in narrative content expression.", "published": "2025-07-15 12:19:18", "link": "http://arxiv.org/abs/2507.11245v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Robust Incomplete Multimodal Low-Rank Adaptation Approach for Emotion Recognition", "abstract": "Multimodal Emotion Recognition (MER) often encounters incomplete\nmultimodality in practical applications due to sensor failures or privacy\nprotection requirements. While existing methods attempt to address various\nincomplete multimodal scenarios by balancing the training of each modality\ncombination through additional gradients, these approaches face a critical\nlimitation: training gradients from different modality combinations conflict\nwith each other, ultimately degrading the performance of the final prediction\nmodel. In this paper, we propose a unimodal decoupled dynamic low-rank\nadaptation method based on modality combinations, named MCULoRA, which is a\nnovel framework for the parameter-efficient training of incomplete multimodal\nlearning models. MCULoRA consists of two key modules, modality combination\naware low-rank adaptation (MCLA) and dynamic parameter fine-tuning (DPFT). The\nMCLA module effectively decouples the shared information from the distinct\ncharacteristics of individual modality combinations. The DPFT module adjusts\nthe training ratio of modality combinations based on the separability of each\nmodality's representation space, optimizing the learning efficiency across\ndifferent modality combinations. Our extensive experimental evaluation in\nmultiple benchmark datasets demonstrates that MCULoRA substantially outperforms\nprevious incomplete multimodal learning approaches in downstream task accuracy.", "published": "2025-07-15 11:15:35", "link": "http://arxiv.org/abs/2507.11202v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "How Far Have Medical Vision-Language Models Come? A Comprehensive Benchmarking Study", "abstract": "Vision-Language Models (VLMs) trained on web-scale corpora excel at natural\nimage tasks and are increasingly repurposed for healthcare; however, their\ncompetence in medical tasks remains underexplored. We present a comprehensive\nevaluation of open-source general-purpose and medically specialised VLMs,\nranging from 3B to 72B parameters, across eight benchmarks: MedXpert,\nOmniMedVQA, PMC-VQA, PathVQA, MMMU, SLAKE, and VQA-RAD. To observe model\nperformance across different aspects, we first separate it into understanding\nand reasoning components. Three salient findings emerge. First, large\ngeneral-purpose models already match or surpass medical-specific counterparts\non several benchmarks, demonstrating strong zero-shot transfer from natural to\nmedical images. Second, reasoning performance is consistently lower than\nunderstanding, highlighting a critical barrier to safe decision support. Third,\nperformance varies widely across benchmarks, reflecting differences in task\ndesign, annotation quality, and knowledge demands. No model yet reaches the\nreliability threshold for clinical deployment, underscoring the need for\nstronger multimodal alignment and more rigorous, fine-grained evaluation\nprotocols.", "published": "2025-07-15 11:12:39", "link": "http://arxiv.org/abs/2507.11200v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Clustering-Guided Multi-Layer Contrastive Representation Learning for Citrus Disease Classification", "abstract": "Citrus, as one of the most economically important fruit crops globally,\nsuffers severe yield depressions due to various diseases. Accurate disease\ndetection and classification serve as critical prerequisites for implementing\ntargeted control measures. Recent advancements in artificial intelligence,\nparticularly deep learning-based computer vision algorithms, have substantially\ndecreased time and labor requirements while maintaining the accuracy of\ndetection and classification. Nevertheless, these methods predominantly rely on\nmassive, high-quality annotated training examples to attain promising\nperformance. By introducing two key designs: contrasting with cluster centroids\nand a multi-layer contrastive training (MCT) paradigm, this paper proposes a\nnovel clustering-guided self-supervised multi-layer contrastive representation\nlearning (CMCRL) algorithm. The proposed method demonstrates several advantages\nover existing counterparts: (1) optimizing with massive unannotated samples;\n(2) effective adaptation to the symptom similarity across distinct citrus\ndiseases; (3) hierarchical feature representation learning. The proposed method\nachieves state-of-the-art performance on the public citrus image set CDD,\noutperforming existing methods by 4.5\\%-30.1\\% accuracy. Remarkably, our method\nnarrows the performance gap with fully supervised counterparts (all samples are\nlabeled). Beyond classification accuracy, our method shows great performance on\nother evaluation metrics (F1 score, precision, and recall), highlighting the\nrobustness against the class imbalance challenge.", "published": "2025-07-15 10:22:52", "link": "http://arxiv.org/abs/2507.11171v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RMAU-NET: A Residual-Multihead-Attention U-Net Architecture for Landslide Segmentation and Detection from Remote Sensing Images", "abstract": "In recent years, landslide disasters have reported frequently due to the\nextreme weather events of droughts, floods , storms, or the consequence of\nhuman activities such as deforestation, excessive exploitation of natural\nresources. However, automatically observing landslide is challenging due to the\nextremely large observing area and the rugged topography such as mountain or\nhighland. This motivates us to propose an end-to-end deep-learning-based model\nwhich explores the remote sensing images for automatically observing landslide\nevents. By considering remote sensing images as the input data, we can obtain\nfree resource, observe large and rough terrains by time. To explore the remote\nsensing images, we proposed a novel neural network architecture which is for\ntwo tasks of landslide detection and landslide segmentation. We evaluated our\nproposed model on three different benchmark datasets of LandSlide4Sense, Bijie,\nand Nepal. By conducting extensive experiments, we achieve F1 scores of 98.23,\n93.83 for the landslide detection task on LandSlide4Sense, Bijie datasets; mIoU\nscores of 63.74, 76.88 on the segmentation tasks regarding LandSlide4Sense,\nNepal datasets. These experimental results prove potential to integrate our\nproposed model into real-life landslide observation systems.", "published": "2025-07-15 09:48:36", "link": "http://arxiv.org/abs/2507.11143v1", "categories": ["cs.CV", "cs.LG", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Try Harder: Hard Sample Generation and Learning for Clothes-Changing Person Re-ID", "abstract": "Hard samples pose a significant challenge in person re-identification (ReID)\ntasks, particularly in clothing-changing person Re-ID (CC-ReID). Their inherent\nambiguity or similarity, coupled with the lack of explicit definitions, makes\nthem a fundamental bottleneck. These issues not only limit the design of\ntargeted learning strategies but also diminish the model's robustness under\nclothing or viewpoint changes. In this paper, we propose a novel\nmultimodal-guided Hard Sample Generation and Learning (HSGL) framework, which\nis the first effort to unify textual and visual modalities to explicitly\ndefine, generate, and optimize hard samples within a unified paradigm. HSGL\ncomprises two core components: (1) Dual-Granularity Hard Sample Generation\n(DGHSG), which leverages multimodal cues to synthesize semantically consistent\nsamples, including both coarse- and fine-grained hard positives and negatives\nfor effectively increasing the hardness and diversity of the training data. (2)\nHard Sample Adaptive Learning (HSAL), which introduces a hardness-aware\noptimization strategy that adjusts feature distances based on textual semantic\nlabels, encouraging the separation of hard positives and drawing hard negatives\ncloser in the embedding space to enhance the model's discriminative capability\nand robustness to hard samples. Extensive experiments on multiple CC-ReID\nbenchmarks demonstrate the effectiveness of our approach and highlight the\npotential of multimodal-guided hard sample generation and learning for robust\nCC-ReID. Notably, HSAL significantly accelerates the convergence of the\ntargeted learning procedure and achieves state-of-the-art performance on both\nPRCC and LTCC datasets. The code is available at\nhttps://github.com/undooo/TryHarder-ACMMM25.", "published": "2025-07-15 09:14:01", "link": "http://arxiv.org/abs/2507.11119v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Jellyfish Species Identification: A CNN Based Artificial Neural Network Approach", "abstract": "Jellyfish, a diverse group of gelatinous marine organisms, play a crucial\nrole in maintaining marine ecosystems but pose significant challenges for\nbiodiversity and conservation due to their rapid proliferation and ecological\nimpact. Accurate identification of jellyfish species is essential for\necological monitoring and management. In this study, we proposed a deep\nlearning framework for jellyfish species detection and classification using an\nunderwater image dataset. The framework integrates advanced feature extraction\ntechniques, including MobileNetV3, ResNet50, EfficientNetV2-B0, and VGG16,\ncombined with seven traditional machine learning classifiers and three\nFeedforward Neural Network classifiers for precise species identification.\nAdditionally, we activated the softmax function to directly classify jellyfish\nspecies using the convolutional neural network models. The combination of the\nArtificial Neural Network with MobileNetV3 is our best-performing model,\nachieving an exceptional accuracy of 98%, significantly outperforming other\nfeature extractor-classifier combinations. This study demonstrates the efficacy\nof deep learning and hybrid frameworks in addressing biodiversity challenges\nand advancing species detection in marine environments.", "published": "2025-07-15 09:10:36", "link": "http://arxiv.org/abs/2507.11116v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "KptLLM++: Towards Generic Keypoint Comprehension with Large Language Model", "abstract": "The emergence of Multimodal Large Language Models (MLLMs) has revolutionized\nimage understanding by bridging textual and visual modalities. However, these\nmodels often struggle with capturing fine-grained semantic information, such as\nthe precise identification and analysis of object keypoints. Keypoints, as\nstructure-aware, pixel-level, and compact representations of objects,\nparticularly articulated ones, play a crucial role in applications such as\nfine-grained image analysis, object retrieval, and behavior recognition. In\nthis paper, we propose KptLLM++, a novel multimodal large language model that\nspecifically designed for generic keypoint comprehension through the\nintegration of diverse input modalities guided by user-defined instructions. By\nunifying keypoint detection across varied contexts, KptLLM++ establishes itself\nas an advanced interface, fostering more effective human-AI collaboration. The\nmodel is built upon a novel identify-then-detect paradigm, which first\ninterprets keypoint semantics and subsequently localizes their precise\npositions through a structured chain-of-thought reasoning mechanism. To push\nthe boundaries of performance, we have scaled up the training dataset to over\n500K samples, encompassing diverse objects, keypoint categories, image styles,\nand scenarios with complex occlusions. This extensive scaling enables KptLLM++\nto unlock its potential, achieving remarkable accuracy and generalization.\nComprehensive experiments on multiple keypoint detection benchmarks demonstrate\nits state-of-the-art performance, underscoring its potential as a unified\nsolution for fine-grained image understanding and its transformative\nimplications for human-AI interaction.", "published": "2025-07-15 08:52:28", "link": "http://arxiv.org/abs/2507.11102v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Survey on Interpretability in Visual Recognition", "abstract": "In recent years, visual recognition methods have advanced significantly,\nfinding applications across diverse fields. While researchers seek to\nunderstand the mechanisms behind the success of these models, there is also a\ngrowing impetus to deploy them in critical areas like autonomous driving and\nmedical diagnostics to better diagnose failures, which promotes the development\nof interpretability research. This paper systematically reviews existing\nresearch on the interpretability of visual recognition models and proposes a\ntaxonomy of methods from a human-centered perspective. The proposed taxonomy\ncategorizes interpretable recognition methods based on Intent, Object,\nPresentation, and Methodology, thereby establishing a systematic and coherent\nset of grouping criteria for these XAI methods. Additionally, we summarize the\nrequirements for evaluation metrics and explore new opportunities enabled by\nrecent technologies, such as large multimodal models. We aim to organize\nexisting research in this domain and inspire future investigations into the\ninterpretability of visual recognition models.", "published": "2025-07-15 08:45:54", "link": "http://arxiv.org/abs/2507.11099v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Atmos-Bench: 3D Atmospheric Structures for Climate Insight", "abstract": "Atmospheric structure, represented by backscatter coefficients (BC) recovered\nfrom satellite LiDAR attenuated backscatter (ATB), provides a volumetric view\nof clouds, aerosols, and molecules, playing a critical role in human\nactivities, climate understanding, and extreme weather forecasting. Existing\nmethods often rely on auxiliary inputs and simplified physics-based\napproximations, and lack a standardized 3D benchmark for fair evaluation.\nHowever, such approaches may introduce additional uncertainties and\ninsufficiently capture realistic radiative transfer and atmospheric\nscattering-absorption effects. To bridge these gaps, we present Atmos-Bench:\nthe first 3D atmospheric benchmark, along with a novel FourCastX:\nFrequency-enhanced Spatio-Temporal Mixture-of-Experts Network that (a)\ngenerates 921,600 image slices from 3D scattering volumes simulated at 532 nm\nand 355 nm by coupling WRF with an enhanced COSP simulator over 384 land-ocean\ntime steps, yielding high-quality voxel-wise references; (b) embeds ATB-BC\nphysical constraints into the model architecture, promoting energy consistency\nduring restoration; (c) achieves consistent improvements on the Atmos-Bench\ndataset across both 355 nm and 532 nm bands, outperforming state-of-the-art\nbaseline models without relying on auxiliary inputs. Atmos-Bench establishes a\nnew standard for satellite-based 3D atmospheric structure recovery and paves\nthe way for deeper climate insight.", "published": "2025-07-15 08:27:29", "link": "http://arxiv.org/abs/2507.11085v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "GKNet: Graph-based Keypoints Network for Monocular Pose Estimation of Non-cooperative Spacecraft", "abstract": "Monocular pose estimation of non-cooperative spacecraft is significant for\non-orbit service (OOS) tasks, such as satellite maintenance, space debris\nremoval, and station assembly. Considering the high demands on pose estimation\naccuracy, mainstream monocular pose estimation methods typically consist of\nkeypoint detectors and PnP solver. However, current keypoint detectors remain\nvulnerable to structural symmetry and partial occlusion of non-cooperative\nspacecraft. To this end, we propose a graph-based keypoints network for the\nmonocular pose estimation of non-cooperative spacecraft, GKNet, which leverages\nthe geometric constraint of keypoints graph. In order to better validate\nkeypoint detectors, we present a moderate-scale dataset for the spacecraft\nkeypoint detection, named SKD, which consists of 3 spacecraft targets, 90,000\nsimulated images, and corresponding high-precise keypoint annotations.\nExtensive experiments and an ablation study have demonstrated the high accuracy\nand effectiveness of our GKNet, compared to the state-of-the-art spacecraft\nkeypoint detectors. The code for GKNet and the SKD dataset is available at\nhttps://github.com/Dongzhou-1996/GKNet.", "published": "2025-07-15 08:18:14", "link": "http://arxiv.org/abs/2507.11077v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TRAN-D: 2D Gaussian Splatting-based Sparse-view Transparent Object Depth Reconstruction via Physics Simulation for Scene Update", "abstract": "Understanding the 3D geometry of transparent objects from RGB images is\nchallenging due to their inherent physical properties, such as reflection and\nrefraction. To address these difficulties, especially in scenarios with sparse\nviews and dynamic environments, we introduce TRAN-D, a novel 2D Gaussian\nSplatting-based depth reconstruction method for transparent objects. Our key\ninsight lies in separating transparent objects from the background, enabling\nfocused optimization of Gaussians corresponding to the object. We mitigate\nartifacts with an object-aware loss that places Gaussians in obscured regions,\nensuring coverage of invisible surfaces while reducing overfitting.\nFurthermore, we incorporate a physics-based simulation that refines the\nreconstruction in just a few seconds, effectively handling object removal and\nchain-reaction movement of remaining objects without the need for rescanning.\nTRAN-D is evaluated on both synthetic and real-world sequences, and it\nconsistently demonstrated robust improvements over existing GS-based\nstate-of-the-art methods. In comparison with baselines, TRAN-D reduces the mean\nabsolute error by over 39% for the synthetic TRansPose sequences. Furthermore,\ndespite being updated using only one image, TRAN-D reaches a {\\delta} < 2.5 cm\naccuracy of 48.46%, over 1.5 times that of baselines, which uses six images.\nCode and more results are available at https://jeongyun0609.github.io/TRAN-D/.", "published": "2025-07-15 08:02:37", "link": "http://arxiv.org/abs/2507.11069v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Alleviating Textual Reliance in Medical Language-guided Segmentation via Prototype-driven Semantic Approximation", "abstract": "Medical language-guided segmentation, integrating textual clinical reports as\nauxiliary guidance to enhance image segmentation, has demonstrated significant\nimprovements over unimodal approaches. However, its inherent reliance on paired\nimage-text input, which we refer to as ``textual reliance\", presents two\nfundamental limitations: 1) many medical segmentation datasets lack paired\nreports, leaving a substantial portion of image-only data underutilized for\ntraining; and 2) inference is limited to retrospective analysis of cases with\npaired reports, limiting its applicability in most clinical scenarios where\nsegmentation typically precedes reporting. To address these limitations, we\npropose ProLearn, the first Prototype-driven Learning framework for\nlanguage-guided segmentation that fundamentally alleviates textual reliance. At\nits core, in ProLearn, we introduce a novel Prototype-driven Semantic\nApproximation (PSA) module to enable approximation of semantic guidance from\ntextual input. PSA initializes a discrete and compact prototype space by\ndistilling segmentation-relevant semantics from textual reports. Once\ninitialized, it supports a query-and-respond mechanism which approximates\nsemantic guidance for images without textual input, thereby alleviating textual\nreliance. Extensive experiments on QaTa-COV19, MosMedData+ and Kvasir-SEG\ndemonstrate that ProLearn outperforms state-of-the-art language-guided methods\nwhen limited text is available.", "published": "2025-07-15 07:38:49", "link": "http://arxiv.org/abs/2507.11055v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Combining Transformers and CNNs for Efficient Object Detection in High-Resolution Satellite Imagery", "abstract": "We present GLOD, a transformer-first architecture for object detection in\nhigh-resolution satellite imagery. GLOD replaces CNN backbones with a Swin\nTransformer for end-to-end feature extraction, combined with novel UpConvMixer\nblocks for robust upsampling and Fusion Blocks for multi-scale feature\nintegration. Our approach achieves 32.95\\% on xView, outperforming SOTA methods\nby 11.46\\%. Key innovations include asymmetric fusion with CBAM attention and a\nmulti-path head design capturing objects across scales. The architecture is\noptimized for satellite imagery challenges, leveraging spatial priors while\nmaintaining computational efficiency.", "published": "2025-07-15 07:10:34", "link": "http://arxiv.org/abs/2507.11040v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Multi-View High-Resolution Foot-Ankle Complex Point Cloud Dataset During Gait for Occlusion-Robust 3D Completion", "abstract": "The kinematics analysis of foot-ankle complex during gait is essential for\nadvancing biomechanical research and clinical assessment. Collecting accurate\nsurface geometry data from the foot and ankle during dynamic gait conditions is\ninherently challenging due to swing foot occlusions and viewing limitations.\nThus, this paper introduces FootGait3D, a novel multi-view dataset of\nhigh-resolution ankle-foot surface point clouds captured during natural gait.\nDifferent from existing gait datasets that typically target whole-body or\nlower-limb motion, FootGait3D focuses specifically on the detailed modeling of\nthe ankle-foot region, offering a finer granularity of motion data. To address\nthis, FootGait3D consists of 8,403 point cloud frames collected from 46\nsubjects using a custom five-camera depth sensing system. Each frame includes a\ncomplete 5-view reconstruction of the foot and ankle (serving as ground truth)\nalong with partial point clouds obtained from only four, three, or two views.\nThis structured variation enables rigorous evaluation of 3D point cloud\ncompletion methods under varying occlusion levels and viewpoints. Our dataset\nis designed for shape completion tasks, facilitating the benchmarking of\nstate-of-the-art single-modal (e.g., PointTr, SnowflakeNet, Anchorformer) and\nmulti-modal (e.g., SVDFormer, PointSea, CSDN) completion networks on the\nchallenge of recovering the full foot geometry from occluded inputs. FootGait3D\nhas significant potential to advance research in biomechanics and multi-segment\nfoot modeling, offering a valuable testbed for clinical gait analysis,\nprosthetic design, and robotics applications requiring detailed 3D models of\nthe foot during motion. The dataset is now available at\nhttps://huggingface.co/datasets/ljw285/FootGait3D.", "published": "2025-07-15 07:03:03", "link": "http://arxiv.org/abs/2507.11037v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Efficient Dual-domain Image Dehazing with Haze Prior Perception", "abstract": "Transformer-based models exhibit strong global modeling capabilities in\nsingle-image dehazing, but their high computational cost limits real-time\napplicability. Existing methods predominantly rely on spatial-domain features\nto capture long-range dependencies, which are computationally expensive and\noften inadequate under complex haze conditions. While some approaches introduce\nfrequency-domain cues, the weak coupling between spatial and frequency branches\nlimits the overall performance. To overcome these limitations, we propose the\nDark Channel Guided Frequency-aware Dehazing Network (DGFDNet), a novel\ndual-domain framework that performs physically guided degradation alignment\nacross spatial and frequency domains. At its core, the DGFDBlock comprises two\nkey modules: 1) the Haze-Aware Frequency Modulator (HAFM), which generates a\npixel-level haze confidence map from dark channel priors to adaptively enhance\nhaze-relevant frequency components, thereby achieving global degradation-aware\nspectral modulation; 2) the Multi-level Gating Aggregation Module (MGAM), which\nfuses multi-scale features through diverse convolutional kernels and hybrid\ngating mechanisms to recover fine structural details. Additionally, a Prior\nCorrection Guidance Branch (PCGB) incorporates a closed-loop feedback\nmechanism, enabling iterative refinement of the prior by intermediate dehazed\nfeatures and significantly improving haze localization accuracy, especially in\nchallenging outdoor scenes. Extensive experiments on four benchmark haze\ndatasets demonstrate that DGFDNet achieves state-of-the-art performance with\nsuperior robustness and real-time efficiency. Code is available at:\nhttps://github.com/Dilizlr/DGFDNet.", "published": "2025-07-15 06:56:56", "link": "http://arxiv.org/abs/2507.11035v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Personalized OVSS: Understanding Personal Concept in Open-Vocabulary Semantic Segmentation", "abstract": "While open-vocabulary semantic segmentation (OVSS) can segment an image into\nsemantic regions based on arbitrarily given text descriptions even for classes\nunseen during training, it fails to understand personal texts (e.g., `my mug\ncup') for segmenting regions of specific interest to users. This paper\naddresses challenges like recognizing `my mug cup' among `multiple mug cups'.\nTo overcome this challenge, we introduce a novel task termed\n\\textit{personalized open-vocabulary semantic segmentation} and propose a text\nprompt tuning-based plug-in method designed to recognize personal visual\nconcepts using a few pairs of images and masks, while maintaining the\nperformance of the original OVSS. Based on the observation that reducing false\npredictions is essential when applying text prompt tuning to this task, our\nproposed method employs `negative mask proposal' that captures visual concepts\nother than the personalized concept. We further improve the performance by\nenriching the representation of text prompts by injecting visual embeddings of\nthe personal concept into them. This approach enhances personalized OVSS\nwithout compromising the original OVSS performance. We demonstrate the\nsuperiority of our method on our newly established benchmarks for this task,\nincluding FSS$^\\text{per}$, CUB$^\\text{per}$, and ADE$^\\text{per}$.", "published": "2025-07-15 06:51:07", "link": "http://arxiv.org/abs/2507.11030v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Human-Guided Shade Artifact Suppression in CBCT-to-MDCT Translation via Schr\u00f6dinger Bridge with Conditional Diffusion", "abstract": "We present a novel framework for CBCT-to-MDCT translation, grounded in the\nSchrodinger Bridge (SB) formulation, which integrates GAN-derived priors with\nhuman-guided conditional diffusion. Unlike conventional GANs or diffusion\nmodels, our approach explicitly enforces boundary consistency between CBCT\ninputs and pseudo targets, ensuring both anatomical fidelity and perceptual\ncontrollability. Binary human feedback is incorporated via classifier-free\nguidance (CFG), effectively steering the generative process toward clinically\npreferred outcomes. Through iterative refinement and tournament-based\npreference selection, the model internalizes human preferences without relying\non a reward model. Subtraction image visualizations reveal that the proposed\nmethod selectively attenuates shade artifacts in key anatomical regions while\npreserving fine structural detail. Quantitative evaluations further demonstrate\nsuperior performance across RMSE, SSIM, LPIPS, and Dice metrics on clinical\ndatasets -- outperforming prior GAN- and fine-tuning-based feedback methods --\nwhile requiring only 10 sampling steps. These findings underscore the\neffectiveness and efficiency of our framework for real-time, preference-aligned\nmedical image translation.", "published": "2025-07-15 06:44:53", "link": "http://arxiv.org/abs/2507.11025v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Bridge Feature Matching and Cross-Modal Alignment with Mutual-filtering for Zero-shot Anomaly Detection", "abstract": "With the advent of vision-language models (e.g., CLIP) in zero- and few-shot\nsettings, CLIP has been widely applied to zero-shot anomaly detection (ZSAD) in\nrecent research, where the rare classes are essential and expected in many\napplications. This study introduces \\textbf{FiSeCLIP} for ZSAD with\ntraining-free \\textbf{CLIP}, combining the feature matching with the\ncross-modal alignment. Testing with the entire dataset is impractical, while\nbatch-based testing better aligns with real industrial needs, and images within\na batch can serve as mutual reference points. Accordingly, FiSeCLIP utilizes\nother images in the same batch as reference information for the current image.\nHowever, the lack of labels for these references can introduce ambiguity, we\napply text information to \\textbf{fi}lter out noisy features. In addition, we\nfurther explore CLIP's inherent potential to restore its local\n\\textbf{se}mantic correlation, adapting it for fine-grained anomaly detection\ntasks to enable a more accurate filtering process. Our approach exhibits\nsuperior performance for both anomaly classification and segmentation on\nanomaly detection benchmarks, building a stronger baseline for the direction,\ne.g., on MVTec-AD, FiSeCLIP outperforms the SOTA AdaCLIP by\n+4.6\\%$\\uparrow$/+5.7\\%$\\uparrow$ in segmentation metrics AU-ROC/$F_1$-max.", "published": "2025-07-15 05:42:17", "link": "http://arxiv.org/abs/2507.11003v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning to Tune Like an Expert: Interpretable and Scene-Aware Navigation via MLLM Reasoning and CVAE-Based Adaptation", "abstract": "Service robots are increasingly deployed in diverse and dynamic environments,\nwhere both physical layouts and social contexts change over time and across\nlocations. In these unstructured settings, conventional navigation systems that\nrely on fixed parameters often fail to generalize across scenarios, resulting\nin degraded performance and reduced social acceptance. Although recent\napproaches have leveraged reinforcement learning to enhance traditional\nplanners, these methods often fail in real-world deployments due to poor\ngeneralization and limited simulation diversity, which hampers effective\nsim-to-real transfer. To tackle these issues, we present LE-Nav, an\ninterpretable and scene-aware navigation framework that leverages multi-modal\nlarge language model reasoning and conditional variational autoencoders to\nadaptively tune planner hyperparameters. To achieve zero-shot scene\nunderstanding, we utilize one-shot exemplars and chain-of-thought prompting\nstrategies. Additionally, a conditional variational autoencoder captures the\nmapping between natural language instructions and navigation hyperparameters,\nenabling expert-level tuning. Experiments show that LE-Nav can generate\nhyperparameters achieving human-level tuning across diverse planners and\nscenarios. Real-world navigation trials and a user study on a smart wheelchair\nplatform demonstrate that it outperforms state-of-the-art methods on\nquantitative metrics such as success rate, efficiency, safety, and comfort,\nwhile receiving higher subjective scores for perceived safety and social\nacceptance. Code is available at https://github.com/Cavendish518/LE-Nav.", "published": "2025-07-15 05:37:24", "link": "http://arxiv.org/abs/2507.11001v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Mind the Gap: Bridging Occlusion in Gait Recognition via Residual Gap Correction", "abstract": "Gait is becoming popular as a method of person re-identification because of\nits ability to identify people at a distance. However, most current works in\ngait recognition do not address the practical problem of occlusions. Among\nthose which do, some require paired tuples of occluded and holistic sequences,\nwhich are impractical to collect in the real world. Further, these approaches\nwork on occlusions but fail to retain performance on holistic inputs. To\naddress these challenges, we propose RG-Gait, a method for residual correction\nfor occluded gait recognition with holistic retention. We model the problem as\na residual learning task, conceptualizing the occluded gait signature as a\nresidual deviation from the holistic gait representation. Our proposed network\nadaptively integrates the learned residual, significantly improving performance\non occluded gait sequences without compromising the holistic recognition\naccuracy. We evaluate our approach on the challenging Gait3D, GREW and BRIAR\ndatasets and show that learning the residual can be an effective technique to\ntackle occluded gait recognition with holistic retention.", "published": "2025-07-15 04:45:14", "link": "http://arxiv.org/abs/2507.10978v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Women Sport Actions Dataset for Visual Classification Using Small Scale Training Data", "abstract": "Sports action classification representing complex body postures and\nplayer-object interactions is an emerging area in image-based sports analysis.\nSome works have contributed to automated sports action recognition using\nmachine learning techniques over the past decades. However, sufficient image\ndatasets representing women sports actions with enough intra- and inter-class\nvariations are not available to the researchers. To overcome this limitation,\nthis work presents a new dataset named WomenSports for women sports\nclassification using small-scale training data. This dataset includes a variety\nof sports activities, covering wide variations in movements, environments, and\ninteractions among players. In addition, this study proposes a convolutional\nneural network (CNN) for deep feature extraction. A channel attention scheme\nupon local contextual regions is applied to refine and enhance feature\nrepresentation. The experiments are carried out on three different sports\ndatasets and one dance dataset for generalizing the proposed algorithm, and the\nperformances on these datasets are noteworthy. The deep learning method\nachieves 89.15% top-1 classification accuracy using ResNet-50 on the proposed\nWomenSports dataset, which is publicly available for research at Mendeley Data.", "published": "2025-07-15 04:18:15", "link": "http://arxiv.org/abs/2507.10969v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Whom to Respond To? A Transformer-Based Model for Multi-Party Social Robot Interaction", "abstract": "Prior human-robot interaction (HRI) research has primarily focused on\nsingle-user interactions, where robots do not need to consider the timing or\nrecipient of their responses. However, in multi-party interactions, such as at\nmalls and hospitals, social robots must understand the context and decide both\nwhen and to whom they should respond. In this paper, we propose a\nTransformer-based multi-task learning framework to improve the decision-making\nprocess of social robots, particularly in multi-user environments. Considering\nthe characteristics of HRI, we propose two novel loss functions: one that\nenforces constraints on active speakers to improve scene modeling, and another\nthat guides response selection towards utterances specifically directed at the\nrobot. Additionally, we construct a novel multi-party HRI dataset that captures\nreal-world complexities, such as gaze misalignment. Experimental results\ndemonstrate that our model achieves state-of-the-art performance in respond\ndecisions, outperforming existing heuristic-based and single-task approaches.\nOur findings contribute to the development of socially intelligent social\nrobots capable of engaging in natural and context-aware multi-party\ninteractions.", "published": "2025-07-15 03:42:14", "link": "http://arxiv.org/abs/2507.10960v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Robust ID-Specific Face Restoration via Alignment Learning", "abstract": "The latest developments in Face Restoration have yielded significant\nadvancements in visual quality through the utilization of diverse diffusion\npriors. Nevertheless, the uncertainty of face identity introduced by\nidentity-obscure inputs and stochastic generative processes remains unresolved.\nTo address this challenge, we present Robust ID-Specific Face Restoration\n(RIDFR), a novel ID-specific face restoration framework based on diffusion\nmodels. Specifically, RIDFR leverages a pre-trained diffusion model in\nconjunction with two parallel conditioning modules. The Content Injection\nModule inputs the severely degraded image, while the Identity Injection Module\nintegrates the specific identity from a given image. Subsequently, RIDFR\nincorporates Alignment Learning, which aligns the restoration results from\nmultiple references with the same identity in order to suppress the\ninterference of ID-irrelevant face semantics (e.g. pose, expression, make-up,\nhair style). Experiments demonstrate that our framework outperforms the\nstate-of-the-art methods, reconstructing high-quality ID-specific results with\nhigh identity fidelity and demonstrating strong robustness.", "published": "2025-07-15 03:16:12", "link": "http://arxiv.org/abs/2507.10943v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Graph Aggregation Prototype Learning for Semantic Change Detection in Remote Sensing", "abstract": "Semantic change detection (SCD) extends the binary change detection task to\nprovide not only the change locations but also the detailed \"from-to\"\ncategories in multi-temporal remote sensing data. Such detailed semantic\ninsights into changes offer considerable advantages for a wide array of\napplications. However, since SCD involves the simultaneous optimization of\nmultiple tasks, the model is prone to negative transfer due to task-specific\nlearning difficulties and conflicting gradient flows. To address this issue, we\npropose Graph Aggregation Prototype Learning for Semantic Change Detection in\nremote sensing(GAPL-SCD). In this framework, a multi-task joint optimization\nmethod is designed to optimize the primary task of semantic segmentation and\nchange detection, along with the auxiliary task of graph aggregation prototype\nlearning. Adaptive weight allocation and gradient rotation methods are used to\nalleviate the conflict between training tasks and improve multi-task learning\ncapabilities. Specifically, the graph aggregation prototype learning module\nconstructs an interaction graph using high-level features. Prototypes serve as\nclass proxies, enabling category-level domain alignment across time points and\nreducing interference from irrelevant changes. Additionally, the proposed\nself-query multi-level feature interaction and bi-temporal feature fusion\nmodules further enhance multi-scale feature representation, improving\nperformance in complex scenes. Experimental results on the SECOND and\nLandsat-SCD datasets demonstrate that our method achieves state-of-the-art\nperformance, with significant improvements in accuracy and robustness for SCD\ntask.", "published": "2025-07-15 03:03:29", "link": "http://arxiv.org/abs/2507.10938v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GeoDistill: Geometry-Guided Self-Distillation for Weakly Supervised Cross-View Localization", "abstract": "Cross-view localization, the task of estimating a camera's\n3-degrees-of-freedom (3-DoF) pose by aligning ground-level images with\nsatellite images, is crucial for large-scale outdoor applications like\nautonomous navigation and augmented reality. Existing methods often rely on\nfully supervised learning, which requires costly ground-truth pose annotations.\nIn this work, we propose GeoDistill, a Geometry guided weakly supervised self\ndistillation framework that uses teacher-student learning with Field-of-View\n(FoV)-based masking to enhance local feature learning for robust cross-view\nlocalization. In GeoDistill, the teacher model localizes a panoramic image,\nwhile the student model predicts locations from a limited FoV counterpart\ncreated by FoV-based masking. By aligning the student's predictions with those\nof the teacher, the student focuses on key features like lane lines and ignores\ntextureless regions, such as roads. This results in more accurate predictions\nand reduced uncertainty, regardless of whether the query images are panoramas\nor limited FoV images. Our experiments show that GeoDistill significantly\nimproves localization performance across different frameworks. Additionally, we\nintroduce a novel orientation estimation network that predicts relative\norientation without requiring precise planar position ground truth. GeoDistill\nprovides a scalable and efficient solution for real-world cross-view\nlocalization challenges. Code and model can be found at\nhttps://github.com/tongshw/GeoDistill.", "published": "2025-07-15 03:00:15", "link": "http://arxiv.org/abs/2507.10935v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Trexplorer Super: Topologically Correct Centerline Tree Tracking of Tubular Objects in CT Volumes", "abstract": "Tubular tree structures, such as blood vessels and airways, are essential in\nhuman anatomy and accurately tracking them while preserving their topology is\ncrucial for various downstream tasks. Trexplorer is a recurrent model designed\nfor centerline tracking in 3D medical images but it struggles with predicting\nduplicate branches and terminating tracking prematurely. To address these\nissues, we present Trexplorer Super, an enhanced version that notably improves\nperformance through novel advancements. However, evaluating centerline tracking\nmodels is challenging due to the lack of public datasets. To enable thorough\nevaluation, we develop three centerline datasets, one synthetic and two real,\neach with increasing difficulty. Using these datasets, we conduct a\ncomprehensive evaluation of existing state-of-the-art (SOTA) models and compare\nthem with our approach. Trexplorer Super outperforms previous SOTA models on\nevery dataset. Our results also highlight that strong performance on synthetic\ndata does not necessarily translate to real datasets. The code and datasets are\navailable at https://github.com/RomStriker/Trexplorer-Super.", "published": "2025-07-15 00:51:30", "link": "http://arxiv.org/abs/2507.10881v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Focus on Texture: Rethinking Pre-training in Masked Autoencoders for Medical Image Classification", "abstract": "Masked Autoencoders (MAEs) have emerged as a dominant strategy for\nself-supervised representation learning in natural images, where models are\npre-trained to reconstruct masked patches with a pixel-wise mean squared error\n(MSE) between original and reconstructed RGB values as the loss. We observe\nthat MSE encourages blurred image re-construction, but still works for natural\nimages as it preserves dominant edges. However, in medical imaging, when the\ntexture cues are more important for classification of a visual abnormality, the\nstrategy fails. Taking inspiration from Gray Level Co-occurrence Matrix (GLCM)\nfeature in Radiomics studies, we propose a novel MAE based pre-training\nframework, GLCM-MAE, using reconstruction loss based on matching GLCM. GLCM\ncaptures intensity and spatial relationships in an image, hence proposed loss\nhelps preserve morphological features. Further, we propose a novel formulation\nto convert matching GLCM matrices into a differentiable loss function. We\ndemonstrate that unsupervised pre-training on medical images with the proposed\nGLCM loss improves representations for downstream tasks. GLCM-MAE outperforms\nthe current state-of-the-art across four tasks - gallbladder cancer detection\nfrom ultrasound images by 2.1%, breast cancer detection from ultrasound by\n3.1%, pneumonia detection from x-rays by 0.5%, and COVID detection from CT by\n0.6%. Source code and pre-trained models are available at:\nhttps://github.com/ChetanMadan/GLCM-MAE.", "published": "2025-07-15 00:12:26", "link": "http://arxiv.org/abs/2507.10869v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Lower bounds for dominating set reconfiguration on sparse (directed) graphs", "abstract": "In a graph, a vertex dominates itself and its neighbors, and a dominating set\nis a set of vertices that together dominate the entire graph. Given a graph and\ntwo dominating sets of equal size $k$, the {\\em Dominating Set Reconfiguration\nwith Token sliding} (DSR-TS) problem asks whether one can, by iteratively\nreplacing a vertex by an adjacent one, transform the first set into the second\none, while ensuring that every set during the reconfiguration process is a\ndominating set.\n  The token jumping variant, where a vertex can be replaced by a non-adjacent\none, is known to be efficiently solvable on many graph classes such as planar,\nbounded treewidth, and the very broad notion of nowhere-dense classes of\ngraphs. Alternatively, some algorithms also exist for the reconfiguration of\nindependent sets in the token sliding paradigm for graph classes with bounded\ndegree or large girth.\n  We show that DSR-TS is W[2]-hard when parameterized $k$, the pathwidth of the\ninstance, and the iteration of the reconfiguration sequence (a recently\nintroduced parameter). This is a setting where both the token jumping and the\nindependent set variants are fixed parameter tractable. Not restricting the\niteration yields W[2] hardness already on graphs with treewidth 9 and pathwidth\n13.\n  In the directed variant (DSR-DTS), we are only allowed to replace a vertex\nwith an out-neighbor. We show that DSR-DTS is NP-hard on DAGs of treewidth 5\nand W[2]-hard for both the case of DAGs of depth 3 parameterized by $k$, and\nthe case of DAGs when parameterized by $k$ and the pathwidth of the instance\n(independent set reconfiguration is again FPT in both settings).", "published": "2025-07-15 16:09:47", "link": "http://arxiv.org/abs/2507.11446v1", "categories": ["cs.DM"], "primary_category": "cs.DM"}
{"title": "On Tight Robust Coresets for $k$-Medians Clustering", "abstract": "This paper considers coresets for the robust $k$-medians problem with $m$\noutliers, and new constructions in various metric spaces are obtained.\nSpecifically, for metric spaces with a bounded VC or doubling dimension $d$,\nthe coreset size is $O(m) + \\tilde{O}(kd\\varepsilon^{-2})$, which is optimal up\nto logarithmic factors. For Euclidean spaces, the coreset size is\n$O(m\\varepsilon^{-1}) +\n\\tilde{O}(\\min\\{k^{4/3}\\varepsilon^{-2},k\\varepsilon^{-3}\\})$, improving upon a\nrecent result by Jiang and Lou (ICALP 2025). These results also extend to\nrobust $(k,z)$-clustering, yielding, for VC and doubling dimension, a coreset\nsize of $O(m) + \\tilde{O}(kd\\varepsilon^{-2z})$ with the optimal linear\ndependence on $m$. This extended result improves upon the earlier work of Huang\net al. (SODA 2025). The techniques introduce novel dataset decompositions,\nenabling chaining arguments to be applied jointly across multiple components.", "published": "2025-07-15 12:33:19", "link": "http://arxiv.org/abs/2507.11260v1", "categories": ["cs.DS", "cs.CG", "cs.DM"], "primary_category": "cs.DS"}
{"title": "Rapid Mixing of Glauber Dynamics for Monotone Systems via Entropic Independence", "abstract": "We study the mixing time of Glauber dynamics on monotone systems. For\nmonotone systems satisfying the entropic independence condition, we prove a new\nmixing time comparison result for Glauber dynamics. For concrete applications,\nwe obtain $\\tilde{O}(n)$ mixing time for the random cluster model induced by\nthe ferromagnetic Ising model with consistently biased external fields, and\n$\\tilde{O}(n^2)$ mixing time for the bipartite hardcore model under the\none-sided uniqueness condition, where $n$ is the number of variables in\ncorresponding models, improving the best known results in [Chen and Zhang,\nSODA'23] and [Chen, Liu, and Yin, FOCS'23], respectively.\n  Our proof combines ideas from the stochastic dominance argument in the\nclassical censoring inequality and the recently developed high-dimensional\nexpanders. The key step in the proof is a novel comparison result between the\nGlauber dynamics and the field dynamics for monotone systems.", "published": "2025-07-15 06:51:55", "link": "http://arxiv.org/abs/2507.11031v1", "categories": ["cs.DM", "cs.DS", "math-ph", "math.MP", "math.PR"], "primary_category": "cs.DM"}
{"title": "Convolutive sequences, I: Through the lens of integer partition functions", "abstract": "Motivated by the convolutive behavior of the counting function for partitions\nwith designated summands in which all parts are odd, we consider coefficient\nsequences $(a_n)_{n\\ge 0}$ of primitive eta-products that satisfy the generic\nconvolutive property\n  \\begin{align*}\n  \\sum_{n\\ge 0} a_{mn} q^n = \\left(\\sum_{n\\ge 0} a_n q^n\\right)^m\n  \\end{align*}\n  for a specific positive integer $m$. Given the results of an exhaustive\nsearch of the Online Encyclopedia of Integer Sequences for such sequences for\n$m$ up to $6$, we first focus on the case where $m=2$ with our attention mainly\npaid to the combinatorics of two $2$-convolutive sequences, featuring bijective\nproofs for both. For other $2$-convolutive sequences discovered in the OEIS, we\napply generating function manipulations to show their convolutivity. We also\ngive two examples of $3$-convolutive sequences. Finally, we discuss other\nconvolutive series that are not eta-products.", "published": "2025-07-15 04:05:55", "link": "http://arxiv.org/abs/2507.10965v1", "categories": ["math.CO", "cs.DM", "math.NT", "05A17, 11P81"], "primary_category": "math.CO"}
{"title": "From Chaos to Automation: Enabling the Use of Unstructured Data for Robotic Process Automation", "abstract": "The growing volume of unstructured data within organizations poses\nsignificant challenges for data analysis and process automation. Unstructured\ndata, which lacks a predefined format, encompasses various forms such as\nemails, reports, and scans. It is estimated to constitute approximately 80% of\nenterprise data. Despite the valuable insights it can offer, extracting\nmeaningful information from unstructured data is more complex compared to\nstructured data. Robotic Process Automation (RPA) has gained popularity for\nautomating repetitive tasks, improving efficiency, and reducing errors.\nHowever, RPA is traditionally reliant on structured data, limiting its\napplication to processes involving unstructured documents. This study addresses\nthis limitation by developing the UNstructured Document REtrieval SyStem\n(UNDRESS), a system that uses fuzzy regular expressions, techniques for natural\nlanguage processing, and large language models to enable RPA platforms to\neffectively retrieve information from unstructured documents. The research\ninvolved the design and development of a prototype system, and its subsequent\nevaluation based on text extraction and information retrieval performance. The\nresults demonstrate the effectiveness of UNDRESS in enhancing RPA capabilities\nfor unstructured data, providing a significant advancement in the field. The\nfindings suggest that this system could facilitate broader RPA adoption across\nprocesses traditionally hindered by unstructured data, thereby improving\noverall business process efficiency.", "published": "2025-07-15 14:32:49", "link": "http://arxiv.org/abs/2507.11364v1", "categories": ["cs.IR", "cs.SE"], "primary_category": "cs.IR"}
{"title": "Aligned Query Expansion: Efficient Query Expansion for Information Retrieval through LLM Alignment", "abstract": "With the breakthroughs in large language models (LLMs), query generation\ntechniques that expand documents and queries with related terms are becoming\nincreasingly popular in the information retrieval field. Such techniques have\nbeen shown to improve the effectiveness of traditional lexical retrieval\nmethods by dealing with the vocabulary mismatch problem. Recent work has found\nthat generating queries with a greedy decoding strategy can produce sub-optimal\nqueries, including hallucinations, and proposed to filter out queries before\nexpansion. This `generate-then-filter' approach is costly, as it requires\ngenerating multiple queries and applying a relevance model to all of them and\ndoes not teach the LLM which of the generated queries is more effective for\nexpansion. To overcome such limitations, we propose Aligned Query Expansion\n(AQE), a novel approach to enhance query expansion for passage retrieval in\nopen-domain question answering. AQE leverages recent techniques in LLM\nalignment to fine-tune models for generating query expansions that directly\noptimize the effectiveness of the retrieval task, eliminating the need for\nadditional filtering steps. This alignment ensures that queries are more\nrelevant, reducing computational costs while improving retrieval effectiveness.\nEmpirical evaluations show that AQE outperforms baseline models for query\nexpansion in both in-domain and out-of-domain settings, demonstrating\nsignificant improvements in retrieval effectiveness.", "published": "2025-07-15 07:11:29", "link": "http://arxiv.org/abs/2507.11042v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Unraveling the Biomarker Prospects of High-Altitude Diseases: Insights from Biomolecular Event Network Constructed using Text Mining", "abstract": "High-altitude diseases (HAD), encompassing acute mountain sickness (AMS),\nhigh-altitude cerebral edema (HACE), and high-altitude pulmonary edema (HAPE),\nare triggered by hypobaric hypoxia at elevations above 2,500 meters. These\nconditions pose significant health risks, yet the molecular mechanisms remain\ninsufficiently understood. In this study, we developed a biomolecular event\nextraction pipeline integrating supervised machine learning with feature-based\nand multiscale Laplacian graph kernels to analyze 7,847 curated HAD-related\nabstracts from PubMed. We extracted over 150 unique biomolecular events\nincluding gene expression, regulation, binding, and localization and\nconstructed a weighted, undirected biomolecular event network comprising 97\nnodes and 153 edges. Using the PageRank algorithm, we prioritized key\nbiomolecules based on their centrality within the event network. The top-ranked\nproteins included Erythropoietin (EPO) (0.0163), Vascular endothelial growth\nfactor (VEGF) (0.0148), Hypoxia-inducible factor 1 (HIF-1) alpha (0.0136),\nEndothelial PAS Domain Protein 1 (EPAS1) and Angiotensin-Converting Enzyme\n(ACE) (0.0119), Egl nine homolog 1 (EGLN1), Endothelin 1 (ET-1), and 70\nkilodalton heat shock protein (Hsp70)(0.0118), all of which play crucial roles\nin oxygen sensing, vascular remodeling, erythropoiesis, and blood pressure\nregulation. Subnetwork analysis revealed three major functional clusters\ncentered on hypoxia response, inflammation, and stress adaptation pathways. Our\nintegrative approach demonstrates the utility of large-scale text mining and\ngraph-based analysis to uncover mechanistic insights and prioritize potential\nbiomarkers for high-altitude disease.", "published": "2025-07-15 03:34:00", "link": "http://arxiv.org/abs/2507.10953v1", "categories": ["cs.IR", "q-bio.QM"], "primary_category": "cs.IR"}
{"title": "LLM-Driven Dual-Level Multi-Interest Modeling for Recommendation", "abstract": "Recently, much effort has been devoted to modeling users' multi-interests\nbased on their behaviors or auxiliary signals. However, existing methods often\nrely on heuristic assumptions, e.g., co-occurring items indicate the same\ninterest of users, failing to capture user multi-interests aligning with\nreal-world scenarios. While large language models (LLMs) show significant\npotential for multi-interest analysis due to their extensive knowledge and\npowerful reasoning capabilities, two key challenges remain. First, the\ngranularity of LLM-driven multi-interests is agnostic, possibly leading to\noverly fine or coarse interest grouping. Second, individual user analysis\nprovides limited insights due to the data sparsity issue. In this paper, we\npropose an LLM-driven dual-level multi-interest modeling framework for more\neffective recommendation. At the user-individual level, we exploit LLMs to\nflexibly allocate items engaged by users into different semantic clusters,\nindicating their diverse and distinct interests. To alleviate the agnostic\ngeneration of LLMs, we adaptively assign these semantic clusters to users'\ncollaborative multi-interests learned from global user-item interactions,\nallowing the granularity to be automatically adjusted according to the user's\nbehaviors using an alignment module. To alleviate the limited insights derived\nfrom individual users' behaviors, at the user-crowd level, we propose\naggregating user cliques into synthesized users with rich behaviors for more\ncomprehensive LLM-driven multi-interest analysis. We formulate a max covering\nproblem to ensure the compactness and representativeness of synthesized users'\nbehaviors, and then conduct contrastive learning based on their LLM-driven\nmulti-interests to disentangle item representations among different interests.\nExperiments on real-world datasets show the superiority of our approach against\nstate-of-the-art methods.", "published": "2025-07-15 02:13:54", "link": "http://arxiv.org/abs/2507.10917v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Sharp Error-Rate Transitions in Quantum QC-LDPC Codes under Joint BP Decoding", "abstract": "In this study, we report that quantum quasi-cyclic low-density parity-check\ncodes decoded via joint belief propagation (BP) exhibit steep error-rate\ncurves, despite the presence of error floors. To the best of our knowledge,\nthis is the first observation of such threshold-like behavior for quantum codes\nwith non-vanishing coding rate, excluding those decoded with non-binary BP\ndecoders. Moreover, we find that dominant error events contributing to the\nerror floor typically involve only a small number of bits. These findings\nsuggest that the error floor is caused by trapping sets -- specific subgraph\nstructures in the Tanner graph -- and indicate that identifying and avoiding\nsuch structures may lead to further reduction of the error floor.", "published": "2025-07-15 17:58:33", "link": "http://arxiv.org/abs/2507.11534v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Fast and Efficient Implementation of the Maximum Likelihood Estimation for the Linear Regression with Gaussian Model Uncertainty", "abstract": "The linear regression model with a random variable (RV) measurement matrix,\nwhere the mean of the random measurement matrix has full column rank, has been\nextensively studied. In particular, the quasiconvexity of the maximum\nlikelihood estimation (MLE) problem was established, and the corresponding\nCramer-Rao bound (CRB) was derived, leading to the development of an efficient\nbisection-based algorithm known as RV-ML. In contrast, this work extends the\nanalysis to both overdetermined and underdetermined cases, allowing the mean of\nthe random measurement matrix to be rank-deficient. A remarkable contribution\nis the proof that the equivalent MLE problem is convex and satisfies strong\nduality, strengthening previous quasiconvexity results. Moreover, it is shown\nthat in underdetermined scenarios, the randomness in the measurement matrix can\nbe beneficial for estimation under certain conditions. In addition, a fast and\nunified implementation of the MLE solution, referred to as generalized RV-ML\n(GRV-ML), is proposed, which handles a more general case including both\nunderdetermined and overdetermined systems. Extensive numerical simulations are\nprovided to validate the theoretical findings.", "published": "2025-07-15 12:23:16", "link": "http://arxiv.org/abs/2507.11249v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Extropy Rate: Properties and Application in Feature Selection", "abstract": "Extropy, a complementary dual of entropy, (proposed by Lad et al.\n\\cite{lad2015extropy} in 2015) has attracted considerable interest from the\nresearch community. In this study, we focus on discrete random variables and\ndefine conditional extropy, establishing key properties of joint and\nconditional extropy such as bounds, uncertainty reduction due to additional\ninformation, and Lipschitz continuity. We further introduce the concept of\nextropy rate for a stochastic process of discrete random variables as a measure\nof the average uncertainty per random variable within the process. It is\nobserved that for infinite stationary and ergodic stochastic processes, as well\nas for identically and independently distributed sequences, the extropy rate\nexhibits asymptotic equivalence. We explore the extropy rate for finite\nstochastic processes and numerically illustrate its effectiveness in capturing\nthe underlying information across various distributions, quantifying complexity\nin time series data, and characterizing chaotic dynamics in dynamical systems.\nThe behaviour of estimated extropy rate is observed to be closely aligned with\nSimpson's diversity index. The real-life applicability of the extropy rate is\npresented through a novel feature selection method based on the fact that\nfeatures with higher extropy rates contain greater inherent information. Using\nsix publicly available datasets, we show the superiority of the proposed\nfeature selection method over some other existing popular approaches.", "published": "2025-07-15 12:16:27", "link": "http://arxiv.org/abs/2507.11242v1", "categories": ["cs.IT", "math.IT", "math.PR", "94A17, 62B10, 60G10, 62H30, 62P30"], "primary_category": "cs.IT"}
{"title": "Performance Enhancement of the Recursive Least Squares Algorithms with Rank Two Updates", "abstract": "New recursive least squares algorithms with rank two updates (RLSR2) that\ninclude both exponential and instantaneous forgetting (implemented via a proper\nchoice of the forgetting factor and the window size) are introduced and\nsystematically associated in this report with well-known RLS algorithms with\nrank one updates. Moreover, new properties (which can be used for further\nperformance improvement) of the recursive algorithms associated with the\nconvergence of the inverse of information matrix and parameter vector are\nestablished in this report. The performance of new algorithms is examined in\nthe problem of estimation of the grid events in the presence of significant\nharmonic emissions.", "published": "2025-07-15 08:42:39", "link": "http://arxiv.org/abs/2507.11095v1", "categories": ["math.OC", "cs.IT", "cs.NA", "math.DS", "math.HO", "math.IT", "math.NA"], "primary_category": "math.OC"}
{"title": "Optimizing Fluid Antenna Configurations for Constructive Interference Precoding", "abstract": "The fluid antenna system (FAS) has emerged as a new physical-layer concept to\nprovide enhanced propagation conditions for multiuser multiple-input\nmultiple-output (MIMO) communications over conventional fixed arrays. This work\nfocuses on minimizing the maximum symbol error probability (SEP) under $M$-ary\nphase shift keying (MPSK) signaling in a multiuser downlink equipped with FAS,\nwhere each antenna moves within nonoverlapping intervals. This specific problem\nof joint SEP minimization with FAS and constructive interference (CI) precoding\nhas not been previously addressed. The resulting problem turns out to be a\nnonconvex and nonsmooth optimization challenge. We transform the SEP\nminimization problem into a safety margin maximization problem in constructive\ninterference precoding. Then, we customize a smoothing technique and a block\ncoordinate descent (BCD) algorithm, with emphasis on low computational\ncomplexity. Simulation results show that our approach can reduce bit error rate\n(BER) compared to both the fixed arrays and FAS designed by existing particle\nswarm optimization (PSO). Also, our approach shows attractively low\ncomputational complexity compared to PSO benchmarks.", "published": "2025-07-15 08:40:21", "link": "http://arxiv.org/abs/2507.11093v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Asymptotically Optimal Repair of Reed-Solomon Codes with Small Sub-Packetization under Rack-Aware Model", "abstract": "This paper presents a comprehensive study on the asymptotically optimal\nrepair of Reed-Solomon (RS) codes with small sub-packetization, specifically\ntailored for rack-aware distributed storage systems. Through the utilization of\nmulti-base expansion, we introduce a novel approach that leverages monomials to\nconstruct linear repair schemes for RS codes. Our repair schemes which adapt to\nall admissible parameters achieve asymptotically optimal repair bandwidth while\nsignificantly reducing the sub-packetization compared with existing schemes.\nFurthermore, our approach is capable of repairing RS codes with asymptotically\noptimal repair bandwidth under the homogeneous storage model, achieving smaller\nsub-packetization than existing methods.", "published": "2025-07-15 05:57:21", "link": "http://arxiv.org/abs/2507.11009v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Canonical Bayesian Linear System Identification", "abstract": "Standard Bayesian approaches for linear time-invariant (LTI) system\nidentification are hindered by parameter non-identifiability; the resulting\ncomplex, multi-modal posteriors make inference inefficient and impractical. We\nsolve this problem by embedding canonical forms of LTI systems within the\nBayesian framework. We rigorously establish that inference in these minimal\nparameterizations fully captures all invariant system dynamics (e.g., transfer\nfunctions, eigenvalues, predictive distributions of system outputs) while\nresolving identifiability. This approach unlocks the use of meaningful,\nstructure-aware priors (e.g., enforcing stability via eigenvalues) and ensures\nconditions for a Bernstein--von Mises theorem -- a link between Bayesian and\nfrequentist large-sample asymptotics that is broken in standard forms.\nExtensive simulations with modern MCMC methods highlight advantages over\nstandard parameterizations: canonical forms achieve higher computational\nefficiency, generate interpretable and well-behaved posteriors, and provide\nrobust uncertainty estimates, particularly from limited data.", "published": "2025-07-15 17:58:55", "link": "http://arxiv.org/abs/2507.11535v1", "categories": ["stat.ML", "cs.LG", "cs.SY", "eess.SY", "stat.CO"], "primary_category": "stat.ML"}
{"title": "Langevin Flows for Modeling Neural Latent Dynamics", "abstract": "Neural populations exhibit latent dynamical structures that drive\ntime-evolving spiking activities, motivating the search for models that capture\nboth intrinsic network dynamics and external unobserved influences. In this\nwork, we introduce LangevinFlow, a sequential Variational Auto-Encoder where\nthe time evolution of latent variables is governed by the underdamped Langevin\nequation. Our approach incorporates physical priors -- such as inertia,\ndamping, a learned potential function, and stochastic forces -- to represent\nboth autonomous and non-autonomous processes in neural systems. Crucially, the\npotential function is parameterized as a network of locally coupled\noscillators, biasing the model toward oscillatory and flow-like behaviors\nobserved in biological neural populations. Our model features a recurrent\nencoder, a one-layer Transformer decoder, and Langevin dynamics in the latent\nspace. Empirically, our method outperforms state-of-the-art baselines on\nsynthetic neural populations generated by a Lorenz attractor, closely matching\nground-truth firing rates. On the Neural Latents Benchmark (NLB), the model\nachieves superior held-out neuron likelihoods (bits per spike) and forward\nprediction accuracy across four challenging datasets. It also matches or\nsurpasses alternative methods in decoding behavioral metrics such as hand\nvelocity. Overall, this work introduces a flexible, physics-inspired,\nhigh-performing framework for modeling complex neural population dynamics and\ntheir unobserved influences.", "published": "2025-07-15 17:57:48", "link": "http://arxiv.org/abs/2507.11531v1", "categories": ["cs.LG", "q-bio.NC"], "primary_category": "cs.LG"}
{"title": "Elk: Exploring the Efficiency of Inter-core Connected AI Chips with Deep Learning Compiler Techniques", "abstract": "To meet the increasing demand of deep learning (DL) models, AI chips are\nemploying both off-chip memory (e.g., HBM) and high-bandwidth low-latency\ninterconnect for direct inter-core data exchange. However, it is not easy to\nexplore the efficiency of these inter-core connected AI (ICCA) chips, due to a\nfundamental tussle among compute (per-core execution), communication\n(inter-core data exchange), and I/O (off-chip data access).\n  In this paper, we develop Elk, a DL compiler framework to maximize the\nefficiency of ICCA chips by jointly trading off all the three performance\nfactors discussed above. Elk structures these performance factors into\nconfigurable parameters and forms a global trade-off space in the DL compiler.\nTo systematically explore this space and maximize overall efficiency, Elk\nemploys a new inductive operator scheduling policy and a cost-aware on-chip\nmemory allocation algorithm. It generates globally optimized execution plans\nthat best overlap off-chip data loading and on-chip execution. To examine the\nefficiency of Elk, we build a full-fledged emulator based on a real ICCA chip\nIPU-POD4, and an ICCA chip simulator for sensitivity analysis with different\ninterconnect network topologies. Elk achieves 94% of the ideal roofline\nperformance of ICCA chips on average, showing the benefits of supporting large\nDL models on ICCA chips. We also show Elk's capability of enabling architecture\ndesign space exploration for new ICCA chip development.", "published": "2025-07-15 17:21:31", "link": "http://arxiv.org/abs/2507.11506v1", "categories": ["cs.AR", "cs.DC", "cs.LG"], "primary_category": "cs.AR"}
{"title": "Exploring the robustness of TractOracle methods in RL-based tractography", "abstract": "Tractography algorithms leverage diffusion MRI to reconstruct the fibrous\narchitecture of the brain's white matter. Among machine learning approaches,\nreinforcement learning (RL) has emerged as a promising framework for\ntractography, outperforming traditional methods in several key aspects.\nTractOracle-RL, a recent RL-based approach, reduces false positives by\nincorporating anatomical priors into the training process via a reward-based\nmechanism. In this paper, we investigate four extensions of the original\nTractOracle-RL framework by integrating recent advances in RL, and we evaluate\ntheir performance across five diverse diffusion MRI datasets. Results\ndemonstrate that combining an oracle with the RL framework consistently leads\nto robust and reliable tractography, regardless of the specific method or\ndataset used. We also introduce a novel RL training scheme called Iterative\nReward Training (IRT), inspired by the Reinforcement Learning from Human\nFeedback (RLHF) paradigm. Instead of relying on human input, IRT leverages\nbundle filtering methods to iteratively refine the oracle's guidance throughout\ntraining. Experimental results show that RL methods trained with oracle\nfeedback significantly outperform widely used tractography techniques in terms\nof accuracy and anatomical validity.", "published": "2025-07-15 16:57:00", "link": "http://arxiv.org/abs/2507.11486v1", "categories": ["cs.LG", "I.2.1"], "primary_category": "cs.LG"}
{"title": "D3FL: Data Distribution and Detrending for Robust Federated Learning in Non-linear Time-series Data", "abstract": "With advancements in computing and communication technologies, the Internet\nof Things (IoT) has seen significant growth. IoT devices typically collect data\nfrom various sensors, such as temperature, humidity, and energy meters. Much of\nthis data is temporal in nature. Traditionally, data from IoT devices is\ncentralized for analysis, but this approach introduces delays and increased\ncommunication costs. Federated learning (FL) has emerged as an effective\nalternative, allowing for model training across distributed devices without the\nneed to centralize data. In many applications, such as smart home energy and\nenvironmental monitoring, the data collected by IoT devices across different\nlocations can exhibit significant variation in trends and seasonal patterns.\nAccurately forecasting such non-stationary, non-linear time-series data is\ncrucial for applications like energy consumption estimation and weather\nforecasting. However, these data variations can severely impact prediction\naccuracy. The key contributions of this paper are: (1) Investigating how\nnon-linear, non-stationary time-series data distributions, like generalized\nextreme value (gen-extreme) and log norm distributions, affect FL performance.\n(2) Analyzing how different detrending techniques for non-linear time-series\ndata influence the forecasting model's performance in a FL setup. We generated\nseveral synthetic time-series datasets using non-linear data distributions and\ntrained an LSTM-based forecasting model using both centralized and FL\napproaches. Additionally, we evaluated the impact of detrending on real-world\ndatasets with non-linear time-series data distributions. Our experimental\nresults show that: (1) FL performs worse than centralized approaches when\ndealing with non-linear data distributions. (2) The use of appropriate\ndetrending techniques improves FL performance, reducing loss across different\ndata distributions.", "published": "2025-07-15 16:41:31", "link": "http://arxiv.org/abs/2507.11471v1", "categories": ["cs.LG", "cs.DC"], "primary_category": "cs.LG"}
{"title": "LRMR: LLM-Driven Relational Multi-node Ranking for Lymph Node Metastasis Assessment in Rectal Cancer", "abstract": "Accurate preoperative assessment of lymph node (LN) metastasis in rectal\ncancer guides treatment decisions, yet conventional MRI evaluation based on\nmorphological criteria shows limited diagnostic performance. While some\nartificial intelligence models have been developed, they often operate as black\nboxes, lacking the interpretability needed for clinical trust. Moreover, these\nmodels typically evaluate nodes in isolation, overlooking the patient-level\ncontext. To address these limitations, we introduce LRMR, an LLM-Driven\nRelational Multi-node Ranking framework. This approach reframes the diagnostic\ntask from a direct classification problem into a structured reasoning and\nranking process. The LRMR framework operates in two stages. First, a multimodal\nlarge language model (LLM) analyzes a composite montage image of all LNs from a\npatient, generating a structured report that details ten distinct radiological\nfeatures. Second, a text-based LLM performs pairwise comparisons of these\nreports between different patients, establishing a relative risk ranking based\non the severity and number of adverse features. We evaluated our method on a\nretrospective cohort of 117 rectal cancer patients. LRMR achieved an area under\nthe curve (AUC) of 0.7917 and an F1-score of 0.7200, outperforming a range of\ndeep learning baselines, including ResNet50 (AUC 0.7708). Ablation studies\nconfirmed the value of our two main contributions: removing the relational\nranking stage or the structured prompting stage led to a significant\nperformance drop, with AUCs falling to 0.6875 and 0.6458, respectively. Our\nwork demonstrates that decoupling visual perception from cognitive reasoning\nthrough a two-stage LLM framework offers a powerful, interpretable, and\neffective new paradigm for assessing lymph node metastasis in rectal cancer.", "published": "2025-07-15 16:29:45", "link": "http://arxiv.org/abs/2507.11457v1", "categories": ["cs.LG", "eess.IV"], "primary_category": "cs.LG"}
{"title": "Data Augmentation in Time Series Forecasting through Inverted Framework", "abstract": "Currently, iTransformer is one of the most popular and effective models for\nmultivariate time series (MTS) forecasting. Thanks to its inverted framework,\niTransformer effectively captures multivariate correlation. However, the\ninverted framework still has some limitations. It diminishes temporal\ninterdependency information, and introduces noise in cases of nonsignificant\nvariable correlation. To address these limitations, we introduce a novel data\naugmentation method on inverted framework, called DAIF. Unlike previous data\naugmentation methods, DAIF stands out as the first real-time augmentation\nspecifically designed for the inverted framework in MTS forecasting. We first\ndefine the structure of the inverted sequence-to-sequence framework, then\npropose two different DAIF strategies, Frequency Filtering and Cross-variation\nPatching to address the existing challenges of the inverted framework.\nExperiments across multiple datasets and inverted models have demonstrated the\neffectiveness of our DAIF.", "published": "2025-07-15 16:01:58", "link": "http://arxiv.org/abs/2507.11439v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "FLsim: A Modular and Library-Agnostic Simulation Framework for Federated Learning", "abstract": "Federated Learning (FL) has undergone significant development since its\ninception in 2016, advancing from basic algorithms to complex methodologies\ntailored to address diverse challenges and use cases. However, research and\nbenchmarking of novel FL techniques against a plethora of established\nstate-of-the-art solutions remain challenging. To streamline this process, we\nintroduce FLsim, a comprehensive FL simulation framework designed to meet the\ndiverse requirements of FL workflows in the literature. FLsim is characterized\nby its modularity, scalability, resource efficiency, and controlled\nreproducibility of experimental outcomes. Its easy to use interface allows\nusers to specify customized FL requirements through job configuration, which\nsupports: (a) customized data distributions, ranging from non-independent and\nidentically distributed (non-iid) data to independent and identically\ndistributed (iid) data, (b) selection of local learning algorithms according to\nuser preferences, with complete agnosticism to ML libraries, (c) choice of\nnetwork topology illustrating communication patterns among nodes, (d)\ndefinition of model aggregation and consensus algorithms, and (e) pluggable\nblockchain support for enhanced robustness. Through a series of experimental\nevaluations, we demonstrate the effectiveness and versatility of FLsim in\nsimulating a diverse range of state-of-the-art FL experiments. We envisage that\nFLsim would mark a significant advancement in FL simulation frameworks,\noffering unprecedented flexibility and functionality for researchers and\npractitioners alike.", "published": "2025-07-15 15:53:01", "link": "http://arxiv.org/abs/2507.11430v1", "categories": ["cs.DC", "cs.LG"], "primary_category": "cs.DC"}
{"title": "Better Regret Rates in Bilateral Trade via Sublinear Budget Violation", "abstract": "Bilateral trade is a central problem in algorithmic economics, and recent\nwork has explored how to design trading mechanisms using no-regret learning\nalgorithms. However, no-regret learning is impossible when budget balance has\nto be enforced at each time step. Bernasconi et al. [Ber+24] show how this\nimpossibility can be circumvented by relaxing the budget balance constraint to\nhold only globally over all time steps. In particular, they design an algorithm\nachieving regret of the order of $\\tilde O(T^{3/4})$ and provide a lower bound\nof $\\Omega(T^{5/7})$.\n  In this work, we interpolate between these two extremes by studying how the\noptimal regret rate varies with the allowed violation of the global budget\nbalance constraint. Specifically, we design an algorithm that, by violating the\nconstraint by at most $T^{\\beta}$ for any given $\\beta \\in [\\frac{3}{4},\n\\frac{6}{7}]$, attains regret $\\tilde O(T^{1 - \\beta/3})$. We complement this\nresult with a matching lower bound, thus fully characterizing the trade-off\nbetween regret and budget violation. Our results show that both the $\\tilde\nO(T^{3/4})$ upper bound in the global budget balance case and the\n$\\Omega(T^{5/7})$ lower bound under unconstrained budget balance violation\nobtained by Bernasconi et al. [Ber+24] are tight.", "published": "2025-07-15 15:45:36", "link": "http://arxiv.org/abs/2507.11419v1", "categories": ["cs.GT", "cs.LG"], "primary_category": "cs.GT"}
{"title": "Robust-Multi-Task Gradient Boosting", "abstract": "Multi-task learning (MTL) has shown effectiveness in exploiting shared\ninformation across tasks to improve generalization. MTL assumes tasks share\nsimilarities that can improve performance. In addition, boosting algorithms\nhave demonstrated exceptional performance across diverse learning problems,\nprimarily due to their ability to focus on hard-to-learn instances and\niteratively reduce residual errors. This makes them a promising approach for\nlearning multi-task problems. However, real-world MTL scenarios often involve\ntasks that are not well-aligned (known as outlier or adversarial tasks), which\ndo not share beneficial similarities with others and can, in fact, deteriorate\nthe performance of the overall model. To overcome this challenge, we propose\nRobust-Multi-Task Gradient Boosting (R-MTGB), a novel boosting framework that\nexplicitly models and adapts to task heterogeneity during training. R-MTGB\nstructures the learning process into three sequential blocks: (1) learning\nshared patterns, (2) partitioning tasks into outliers and non-outliers with\nregularized parameters, and (3) fine-tuning task-specific predictors. This\narchitecture enables R-MTGB to automatically detect and penalize outlier tasks\nwhile promoting effective knowledge transfer among related tasks. Our method\nintegrates these mechanisms seamlessly within gradient boosting, allowing\nrobust handling of noisy or adversarial tasks without sacrificing accuracy.\nExtensive experiments on both synthetic benchmarks and real-world datasets\ndemonstrate that our approach successfully isolates outliers, transfers\nknowledge, and consistently reduces prediction errors for each task\nindividually, and achieves overall performance gains across all tasks. These\nresults highlight robustness, adaptability, and reliable convergence of R-MTGB\nin challenging MTL environments.", "published": "2025-07-15 15:31:12", "link": "http://arxiv.org/abs/2507.11411v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Neural Network Model of Complementary Learning Systems: Pattern Separation and Completion for Continual Learning", "abstract": "Learning new information without forgetting prior knowledge is central to\nhuman intelligence. In contrast, neural network models suffer from catastrophic\nforgetting: a significant degradation in performance on previously learned\ntasks when acquiring new information. The Complementary Learning Systems (CLS)\ntheory offers an explanation for this human ability, proposing that the brain\nhas distinct systems for pattern separation (encoding distinct memories) and\npattern completion (retrieving complete memories from partial cues). To capture\nthese complementary functions, we leverage the representational generalization\ncapabilities of variational autoencoders (VAEs) and the robust memory storage\nproperties of Modern Hopfield networks (MHNs), combining them into a neurally\nplausible continual learning model. We evaluate this model on the Split-MNIST\ntask, a popular continual learning benchmark, and achieve close to\nstate-of-the-art accuracy (~90%), substantially reducing forgetting.\nRepresentational analyses empirically confirm the functional dissociation: the\nVAE underwrites pattern completion, while the MHN drives pattern separation. By\ncapturing pattern separation and completion in scalable architectures, our work\nprovides a functional template for modeling memory consolidation,\ngeneralization, and continual learning in both biological and artificial\nsystems.", "published": "2025-07-15 15:05:26", "link": "http://arxiv.org/abs/2507.11393v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Joint space-time wind field data extrapolation and uncertainty quantification using nonparametric Bayesian dictionary learning", "abstract": "A methodology is developed, based on nonparametric Bayesian dictionary\nlearning, for joint space-time wind field data extrapolation and estimation of\nrelated statistics by relying on limited/incomplete measurements. Specifically,\nutilizing sparse/incomplete measured data, a time-dependent optimization\nproblem is formulated for determining the expansion coefficients of an\nassociated low-dimensional representation of the stochastic wind field.\nCompared to an alternative, standard, compressive sampling treatment of the\nproblem, the developed methodology exhibits the following advantages. First,\nthe Bayesian formulation enables also the quantification of the uncertainty in\nthe estimates. Second, the requirement in standard CS-based applications for an\na priori selection of the expansion basis is circumvented. Instead, this is\ndone herein in an adaptive manner based on the acquired data. Overall, the\nmethodology exhibits enhanced extrapolation accuracy, even in cases of\nhigh-dimensional data of arbitrary form, and of relatively large extrapolation\ndistances. Thus, it can be used, potentially, in a wide range of wind\nengineering applications where various constraints dictate the use of a limited\nnumber of sensors. The efficacy of the methodology is demonstrated by\nconsidering two case studies. The first relates to the extrapolation of\nsimulated wind velocity records consistent with a prescribed joint\nwavenumber-frequency power spectral density in a three-dimensional domain (2D\nand time). The second pertains to the extrapolation of four-dimensional (3D and\ntime) boundary layer wind tunnel experimental data that exhibit significant\nspatial variability and non-Gaussian characteristics.", "published": "2025-07-15 14:54:57", "link": "http://arxiv.org/abs/2507.11385v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "From Observational Data to Clinical Recommendations: A Causal Framework for Estimating Patient-level Treatment Effects and Learning Policies", "abstract": "We propose a framework for building patient-specific treatment recommendation\nmodels, building on the large recent literature on learning patient-level\ncausal models and inspired by the target trial paradigm of Hernan and Robins.\nWe focus on safety and validity, including the crucial issue of causal\nidentification when using observational data. We do not provide a specific\nmodel, but rather a way to integrate existing methods and know-how into a\npractical pipeline. We further provide a real world use-case of treatment\noptimization for patients with heart failure who develop acute kidney injury\nduring hospitalization. The results suggest our pipeline can improve patient\noutcomes over the current treatment regime.", "published": "2025-07-15 14:50:41", "link": "http://arxiv.org/abs/2507.11381v1", "categories": ["stat.ML", "cs.LG", "stat.AP"], "primary_category": "stat.ML"}
{"title": "Step-wise Policy for Rare-tool Knowledge (SPaRK): Offline RL that Drives Diverse Tool Use in LLMs", "abstract": "We present Step-wise Policy for Rare-tool Knowledge (SPaRK), a novel\nreinforcement learning framework that teaches large language models to explore\ndiverse tool usage patterns beyond conventional high-temperature sampling.\nBuilding on recent advances in step-wise reinforcement learning, we introduce a\ndual-objective reward system that simultaneously optimizes for answer quality\nand tool diversity, training a Llama-3.1 8B model through offline PPO on\nsynthetically generated trajectories from the MMLU-Pro dataset. Our approach\nuniquely employs a rarity-first exploitation strategy where a GPT-4o judge\nscores candidate actions across eight distinct tools plus chain-of-thought\nreasoning, with the policy favoring less-frequently used but still viable tools\nto encourage systematic exploration. Empirical results demonstrate that SPaRK\nachieves competitive performance across 14 MMLU-Pro categories while exhibiting\nsignificantly higher entropy in tool selection compared to both baseline and\nsupervised fine-tuning approaches, suggesting that algorithmic exploration\nthrough explicit tool diversity can enhance reasoning capabilities without\nsacrificing accuracy.", "published": "2025-07-15 14:44:29", "link": "http://arxiv.org/abs/2507.11371v1", "categories": ["cs.LG", "cs.MA"], "primary_category": "cs.LG"}
{"title": "A Parallelizable Approach for Characterizing NE in Zero-Sum Games After a Linear Number of Iterations of Gradient Descent", "abstract": "We study online optimization methods for zero-sum games, a fundamental\nproblem in adversarial learning in machine learning, economics, and many other\ndomains. Traditional methods approximate Nash equilibria (NE) using either\nregret-based methods (time-average convergence) or contraction-map-based\nmethods (last-iterate convergence). We propose a new method based on\nHamiltonian dynamics in physics and prove that it can characterize the set of\nNE in a finite (linear) number of iterations of alternating gradient descent in\nthe unbounded setting, modulo degeneracy, a first in online optimization.\nUnlike standard methods for computing NE, our proposed approach can be\nparallelized and works with arbitrary learning rates, both firsts in\nalgorithmic game theory. Experimentally, we support our results by showing our\napproach drastically outperforms standard methods.", "published": "2025-07-15 14:39:40", "link": "http://arxiv.org/abs/2507.11366v1", "categories": ["cs.GT", "cs.LG", "90C47, 91A05, 91A26, 68Q32"], "primary_category": "cs.GT"}
{"title": "Neurosymbolic Reasoning Shortcuts under the Independence Assumption", "abstract": "The ubiquitous independence assumption among symbolic concepts in\nneurosymbolic (NeSy) predictors is a convenient simplification: NeSy predictors\nuse it to speed up probabilistic reasoning. Recent works like van Krieken et\nal. (2024) and Marconato et al. (2024) argued that the independence assumption\ncan hinder learning of NeSy predictors and, more crucially, prevent them from\ncorrectly modelling uncertainty. There is, however, scepticism in the NeSy\ncommunity around the scenarios in which the independence assumption actually\nlimits NeSy systems (Faronius and Dos Martires, 2025). In this work, we settle\nthis question by formally showing that assuming independence among symbolic\nconcepts entails that a model can never represent uncertainty over certain\nconcept combinations. Thus, the model fails to be aware of reasoning shortcuts,\ni.e., the pathological behaviour of NeSy predictors that predict correct\ndownstream tasks but for the wrong reasons.", "published": "2025-07-15 14:27:05", "link": "http://arxiv.org/abs/2507.11357v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Guiding LLM Decision-Making with Fairness Reward Models", "abstract": "Large language models are increasingly used to support high-stakes decisions,\npotentially influencing who is granted bail or receives a loan. Naive\nchain-of-thought sampling can improve average decision accuracy, but has also\nbeen shown to amplify unfair bias. To address this challenge and enable the\ntrustworthy use of reasoning models in high-stakes decision-making, we propose\na framework for training a generalizable Fairness Reward Model (FRM). Our model\nassigns a fairness score to LLM reasoning, enabling the system to down-weight\nbiased trajectories and favor equitable ones when aggregating decisions across\nreasoning chains. We show that a single Fairness Reward Model, trained on\nweakly supervised, LLM-annotated examples of biased versus unbiased reasoning,\ntransfers across tasks, domains, and model families without additional\nfine-tuning. Applied to real-world decision-making tasks including recidivism\nprediction and social media moderation, we show that our approach consistently\nimproves fairness while matching, or even surpassing, baseline accuracy.", "published": "2025-07-15 14:20:23", "link": "http://arxiv.org/abs/2507.11344v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Fast Last-Iterate Convergence of SGD in the Smooth Interpolation Regime", "abstract": "We study population convergence guarantees of stochastic gradient descent\n(SGD) for smooth convex objectives in the interpolation regime, where the noise\nat optimum is zero or near zero. The behavior of the last iterate of SGD in\nthis setting -- particularly with large (constant) stepsizes -- has received\ngrowing attention in recent years due to implications for the training of\nover-parameterized models, as well as to analyzing forgetting in continual\nlearning and to understanding the convergence of the randomized Kaczmarz method\nfor solving linear systems. We establish that after $T$ steps of SGD on\n$\\beta$-smooth convex loss functions with stepsize $\\eta \\leq 1/\\beta$, the\nlast iterate exhibits expected excess risk $\\widetilde{O}(1/(\\eta\nT^{1-\\beta\\eta/2}) + \\eta T^{\\beta\\eta/2} \\sigma_\\star^2)$, where\n$\\sigma_\\star^2$ denotes the variance of the stochastic gradients at the\noptimum. In particular, for a well-tuned stepsize we obtain a near optimal\n$\\widetilde{O}(1/T + \\sigma_\\star/\\sqrt{T})$ rate for the last iterate,\nextending the results of Varre et al. (2021) beyond least squares regression;\nand when $\\sigma_\\star=0$ we obtain a rate of $O(1/\\sqrt{T})$ with\n$\\eta=1/\\beta$, improving upon the best-known $O(T^{-1/4})$ rate recently\nestablished by Evron et al. (2025) in the special case of realizable linear\nregression.", "published": "2025-07-15 12:52:47", "link": "http://arxiv.org/abs/2507.11274v1", "categories": ["cs.LG", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "LyAm: Robust Non-Convex Optimization for Stable Learning in Noisy Environments", "abstract": "Training deep neural networks, particularly in computer vision tasks, often\nsuffers from noisy gradients and unstable convergence, which hinder performance\nand generalization. In this paper, we propose LyAm, a novel optimizer that\nintegrates Adam's adaptive moment estimation with Lyapunov-based stability\nmechanisms. LyAm dynamically adjusts the learning rate using Lyapunov stability\ntheory to enhance convergence robustness and mitigate training noise. We\nprovide a rigorous theoretical framework proving the convergence guarantees of\nLyAm in complex, non-convex settings. Extensive experiments on like as CIFAR-10\nand CIFAR-100 show that LyAm consistently outperforms state-of-the-art\noptimizers in terms of accuracy, convergence speed, and stability, establishing\nit as a strong candidate for robust deep learning optimization.", "published": "2025-07-15 12:35:13", "link": "http://arxiv.org/abs/2507.11262v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Generative Click-through Rate Prediction with Applications to Search Advertising", "abstract": "Click-Through Rate (CTR) prediction models are integral to a myriad of\nindustrial settings, such as personalized search advertising. Current methods\ntypically involve feature extraction from users' historical behavior sequences\ncombined with product information, feeding into a discriminative model that is\ntrained on user feedback to estimate CTR. With the success of models such as\nGPT, the potential for generative models to enrich expressive power beyond\ndiscriminative models has become apparent. In light of this, we introduce a\nnovel model that leverages generative models to enhance the precision of CTR\npredictions in discriminative models. To reconcile the disparate data\naggregation needs of both model types, we design a two-stage training process:\n1) Generative pre-training for next-item prediction with the given item\ncategory in user behavior sequences; 2) Fine-tuning the well-trained generative\nmodel within a discriminative CTR prediction framework. Our method's efficacy\nis substantiated through extensive experiments on a new dataset, and its\nsignificant utility is further corroborated by online A/B testing results.\nCurrently, the model is deployed on one of the world's largest e-commerce\nplatforms, and we intend to release the associated code and dataset in the\nfuture.", "published": "2025-07-15 12:21:30", "link": "http://arxiv.org/abs/2507.11246v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Improved sampling algorithms and Poincar\u00e9 inequalities for non-log-concave distributions", "abstract": "We study the problem of sampling from a distribution $\\mu$ with density\n$\\propto e^{-V}$ for some potential function $V:\\mathbb R^d\\to \\mathbb R$ with\nquery access to $V$ and $\\nabla V$. We start with the following standard\nassumptions:\n  (1) The potential function $V$ is $L$-smooth.\n  (2) The second moment $\\mathbf{E}_{X\\sim \\mu}[\\|X\\|^2]\\leq M$.\n  Recently, He and Zhang (COLT'25) showed that the query complexity of sampling\nfrom such distributions is at least\n$\\left(\\frac{LM}{d\\epsilon}\\right)^{\\Omega(d)}$ where $\\epsilon$ is the desired\naccuracy in total variation distance, and the Poincar\\'e constant can be\narbitrarily large.\n  Meanwhile, another common assumption in the study of diffusion based samplers\n(see e.g., the work of Chen, Chewi, Li, Li, Salim and Zhang (ICLR'23))\nstrengthens the smoothness condition (1) to the following:\n  (1*) The potential function of *every* distribution along the\nOrnstein-Uhlenbeck process starting from $\\mu$ is $L$-smooth.\n  We show that under the assumptions (1*) and (2), the query complexity of\nsampling from $\\mu$ can be $\\mathrm{poly}(L,d)\\cdot\n\\left(\\frac{Ld+M}{\\epsilon^2}\\right)^{\\mathcal{O}(L+1)}$, which is polynomial\nin $d$ and $\\frac{1}{\\epsilon}$ when $L=\\mathcal{O}(1)$ and\n$M=\\mathrm{poly}(d)$. This improves the algorithm with quasi-polynomial query\ncomplexity developed by Huang et al. (COLT'24). Our results imply that the\nseemly moderate strengthening of the smoothness condition (1) to (1*) can lead\nto an exponential gap in the query complexity of sampling algorithms.\n  Moreover, we show that together with the assumption (1*) and the stronger\nmoment assumption that $\\|X\\|$ is $\\lambda$-sub-Gaussian for $X\\sim\\mu$, the\nPoincar\\'e constant of $\\mu$ is at most $\\mathcal{O}(\\lambda)^{2(L+1)}$. As an\napplication of our technique, we obtain improved estimate of the Poincar\\'e\nconstant for mixture of Gaussians with the same covariance.", "published": "2025-07-15 12:06:11", "link": "http://arxiv.org/abs/2507.11236v1", "categories": ["cs.DS", "cs.LG", "math.PR", "stat.ML"], "primary_category": "cs.DS"}
{"title": "Gradient Descent on Logistic Regression: Do Large Step-Sizes Work with Data on the Sphere?", "abstract": "Gradient descent (GD) on logistic regression has many fascinating properties.\nWhen the dataset is linearly separable, it is known that the iterates converge\nin direction to the maximum-margin separator regardless of how large the step\nsize is. In the non-separable case, however, it has been shown that GD can\nexhibit a cycling behaviour even when the step sizes is still below the\nstability threshold $2/\\lambda$, where $\\lambda$ is the largest eigenvalue of\nthe Hessian at the solution. This short paper explores whether restricting the\ndata to have equal magnitude is a sufficient condition for global convergence,\nunder any step size below the stability threshold. We prove that this is true\nin a one dimensional space, but in higher dimensions cycling behaviour can\nstill occur. We hope to inspire further studies on quantifying how common these\ncycles are in realistic datasets, as well as finding sufficient conditions to\nguarantee global convergence with large step sizes.", "published": "2025-07-15 11:58:42", "link": "http://arxiv.org/abs/2507.11228v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Recent Advances in Simulation-based Inference for Gravitational Wave Data Analysis", "abstract": "The detection of gravitational waves by the LIGO-Virgo-KAGRA collaboration\nhas ushered in a new era of observational astronomy, emphasizing the need for\nrapid and detailed parameter estimation and population-level analyses.\nTraditional Bayesian inference methods, particularly Markov chain Monte Carlo,\nface significant computational challenges when dealing with the\nhigh-dimensional parameter spaces and complex noise characteristics inherent in\ngravitational wave data. This review examines the emerging role of\nsimulation-based inference methods in gravitational wave astronomy, with a\nfocus on approaches that leverage machine-learning techniques such as\nnormalizing flows and neural posterior estimation. We provide a comprehensive\noverview of the theoretical foundations underlying various simulation-based\ninference methods, including neural posterior estimation, neural ratio\nestimation, neural likelihood estimation, flow matching, and consistency\nmodels. We explore the applications of these methods across diverse\ngravitational wave data processing scenarios, from single-source parameter\nestimation and overlapping signal analysis to testing general relativity and\nconducting population studies. Although these techniques demonstrate speed\nimprovements over traditional methods in controlled studies, their\nmodel-dependent nature and sensitivity to prior assumptions are barriers to\ntheir widespread adoption. Their accuracy, which is similar to that of\nconventional methods, requires further validation across broader parameter\nspaces and noise conditions.", "published": "2025-07-15 10:52:57", "link": "http://arxiv.org/abs/2507.11192v1", "categories": ["gr-qc", "astro-ph.HE", "astro-ph.IM", "cs.LG", "stat.ML"], "primary_category": "gr-qc"}
{"title": "Data-Driven Differential Evolution in Tire Industry Extrusion: Leveraging Surrogate Models", "abstract": "The optimization of industrial processes remains a critical challenge,\nparticularly when no mathematical formulation of objective functions or\nconstraints is available. This study addresses this issue by proposing a\nsurrogate-based, data-driven methodology for optimizing complex real-world\nmanufacturing systems using only historical process data. Machine learning\nmodels are employed to approximate system behavior and construct surrogate\nmodels, which are integrated into a tailored metaheuristic approach:\nData-Driven Differential Evolution with Multi-Level Penalty Functions and\nSurrogate Models, an adapted version of Differential Evolution suited to the\ncharacteristics of the studied process. The methodology is applied to an\nextrusion process in the tire manufacturing industry, with the goal of\noptimizing initialization parameters to reduce waste and production time.\nResults show that the surrogate-based optimization approach outperforms\nhistorical best configurations, achieving a 65\\% reduction in initialization\nand setup time, while also significantly minimizing material waste. These\nfindings highlight the potential of combining data-driven modeling and\nmetaheuristic optimization for industrial processes where explicit formulations\nare unavailable.", "published": "2025-07-15 10:52:45", "link": "http://arxiv.org/abs/2507.11191v1", "categories": ["cs.CE", "cs.LG", "J.6; I.2; H.4"], "primary_category": "cs.CE"}
{"title": "Striking the Perfect Balance: Preserving Privacy While Boosting Utility in Collaborative Medical Prediction Platforms", "abstract": "Online collaborative medical prediction platforms offer convenience and\nreal-time feedback by leveraging massive electronic health records. However,\ngrowing concerns about privacy and low prediction quality can deter patient\nparticipation and doctor cooperation. In this paper, we first clarify the\nprivacy attacks, namely attribute attacks targeting patients and model\nextraction attacks targeting doctors, and specify the corresponding privacy\nprinciples. We then propose a privacy-preserving mechanism and integrate it\ninto a novel one-shot distributed learning framework, aiming to simultaneously\nmeet both privacy requirements and prediction performance objectives. Within\nthe framework of statistical learning theory, we theoretically demonstrate that\nthe proposed distributed learning framework can achieve the optimal prediction\nperformance under specific privacy requirements. We further validate the\ndeveloped privacy-preserving collaborative medical prediction platform through\nboth toy simulations and real-world data experiments.", "published": "2025-07-15 10:41:55", "link": "http://arxiv.org/abs/2507.11187v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Quantized Rank Reduction: A Communications-Efficient Federated Learning Scheme for Network-Critical Applications", "abstract": "Federated learning is a machine learning approach that enables multiple\ndevices (i.e., agents) to train a shared model cooperatively without exchanging\nraw data. This technique keeps data localized on user devices, ensuring privacy\nand security, while each agent trains the model on their own data and only\nshares model updates. The communication overhead is a significant challenge due\nto the frequent exchange of model updates between the agents and the central\nserver. In this paper, we propose a communication-efficient federated learning\nscheme that utilizes low-rank approximation of neural network gradients and\nquantization to significantly reduce the network load of the decentralized\nlearning process with minimal impact on the model's accuracy.", "published": "2025-07-15 10:37:59", "link": "http://arxiv.org/abs/2507.11183v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "An Interpretable AI framework Quantifying Traditional Chinese Medicine Principles Towards Enhancing and Integrating with Modern Biomedicine", "abstract": "Traditional Chinese Medicine diagnosis and treatment principles, established\nthrough centuries of trial-and-error clinical practice, directly maps\npatient-specific symptom patterns to personalised herbal therapies. These\nempirical holistic mapping principles offer valuable strategies to address\nremaining challenges of reductionism methodologies in modern biomedicine.\nHowever, the lack of a quantitative framework and molecular-level evidence has\nlimited their interpretability and reliability. Here, we present an AI\nframework trained on ancient and classical TCM formula records to quantify the\nsymptom pattern-herbal therapy mappings. Interestingly, we find that empirical\nTCM diagnosis and treatment are consistent with the encoding-decoding processes\nin the AI model. This enables us to construct an interpretable TCM embedding\nspace (TCM-ES) using the model's quantitative representation of TCM principles.\nValidated through broad and extensive TCM patient data, the TCM-ES offers\nuniversal quantification of the TCM practice and therapeutic efficacy. We\nfurther map biomedical entities into the TCM-ES through correspondence\nalignment. We find that the principal directions of the TCM-ES are\nsignificantly associated with key biological functions (such as metabolism,\nimmune, and homeostasis), and that the disease and herb embedding proximity\naligns with their genetic relationships in the human protein interactome, which\ndemonstrate the biological significance of TCM principles. Moreover, the TCM-ES\nuncovers latent disease relationships, and provides alternative metric to\nassess clinical efficacy for modern disease-drug pairs. Finally, we construct a\ncomprehensive and integrative TCM knowledge graph, which predicts potential\nassociations between diseases and targets, drugs, herbal compounds, and herbal\ntherapies, providing TCM-informed opportunities for disease analysis and drug\ndevelopment.", "published": "2025-07-15 10:30:45", "link": "http://arxiv.org/abs/2507.11176v1", "categories": ["q-bio.OT", "cs.AI"], "primary_category": "q-bio.OT"}
{"title": "Real-Time Bayesian Detection of Drift-Evasive GNSS Spoofing in Reinforcement Learning Based UAV Deconfliction", "abstract": "Autonomous unmanned aerial vehicles (UAVs) rely on global navigation\nsatellite system (GNSS) pseudorange measurements for accurate real-time\nlocalization and navigation. However, this dependence exposes them to\nsophisticated spoofing threats, where adversaries manipulate pseudoranges to\ndeceive UAV receivers. Among these, drift-evasive spoofing attacks subtly\nperturb measurements, gradually diverting the UAVs trajectory without\ntriggering conventional signal-level anti-spoofing mechanisms. Traditional\ndistributional shift detection techniques often require accumulating a\nthreshold number of samples, causing delays that impede rapid detection and\ntimely response. Consequently, robust temporal-scale detection methods are\nessential to identify attack onset and enable contingency planning with\nalternative sensing modalities, improving resilience against stealthy\nadversarial manipulations. This study explores a Bayesian online change point\ndetection (BOCPD) approach that monitors temporal shifts in value estimates\nfrom a reinforcement learning (RL) critic network to detect subtle behavioural\ndeviations in UAV navigation. Experimental results show that this temporal\nvalue-based framework outperforms conventional GNSS spoofing detectors,\ntemporal semi-supervised learning frameworks, and the Page-Hinkley test,\nachieving higher detection accuracy and lower false-positive and false-negative\nrates for drift-evasive spoofing attacks.", "published": "2025-07-15 10:27:27", "link": "http://arxiv.org/abs/2507.11173v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "How does Labeling Error Impact Contrastive Learning? A Perspective from Data Dimensionality Reduction", "abstract": "In recent years, contrastive learning has achieved state-of-the-art\nperformance in the territory of self-supervised representation learning. Many\nprevious works have attempted to provide the theoretical understanding\nunderlying the success of contrastive learning. Almost all of them rely on a\ndefault assumption, i.e., the label consistency assumption, which may not hold\nin practice (the probability of failure is called labeling error) due to the\nstrength and randomness of common augmentation strategies, such as random\nresized crop (RRC). This paper investigates the theoretical impact of labeling\nerror on the downstream classification performance of contrastive learning. We\nfirst reveal several significant negative impacts of labeling error on\ndownstream classification risk. To mitigate these impacts, data dimensionality\nreduction method (e.g., singular value decomposition, SVD) is applied on\noriginal data to reduce false positive samples, and establish both theoretical\nand empirical evaluations. Moreover, it is also found that SVD acts as a\ndouble-edged sword, which may lead to the deterioration of downstream\nclassification accuracy due to the reduced connectivity of the augmentation\ngraph. Based on the above observations, we give the augmentation suggestion\nthat we should use some moderate embedding dimension (such as $512, 1024$ in\nour experiments), data inflation, weak augmentation, and SVD to ensure large\ngraph connectivity and small labeling error to improve model performance.", "published": "2025-07-15 10:09:55", "link": "http://arxiv.org/abs/2507.11161v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Hashed Watermark as a Filter: Defeating Forging and Overwriting Attacks in Weight-based Neural Network Watermarking", "abstract": "As valuable digital assets, deep neural networks necessitate robust ownership\nprotection, positioning neural network watermarking (NNW) as a promising\nsolution. Among various NNW approaches, weight-based methods are favored for\ntheir simplicity and practicality; however, they remain vulnerable to forging\nand overwriting attacks. To address those challenges, we propose NeuralMark, a\nrobust method built around a hashed watermark filter. Specifically, we utilize\na hash function to generate an irreversible binary watermark from a secret key,\nwhich is then used as a filter to select the model parameters for embedding.\nThis design cleverly intertwines the embedding parameters with the hashed\nwatermark, providing a robust defense against both forging and overwriting\nattacks. An average pooling is also incorporated to resist fine-tuning and\npruning attacks. Furthermore, it can be seamlessly integrated into various\nneural network architectures, ensuring broad applicability. Theoretically, we\nanalyze its security boundary. Empirically, we verify its effectiveness and\nrobustness across 13 distinct Convolutional and Transformer architectures,\ncovering five image classification tasks and one text generation task. The\nsource codes are available at https://github.com/AIResearch-Group/NeuralMark.", "published": "2025-07-15 09:38:11", "link": "http://arxiv.org/abs/2507.11137v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Interpretable Bayesian Tensor Network Kernel Machines with Automatic Rank and Feature Selection", "abstract": "Tensor Network (TN) Kernel Machines speed up model learning by representing\nparameters as low-rank TNs, reducing computation and memory use. However, most\nTN-based Kernel methods are deterministic and ignore parameter uncertainty.\nFurther, they require manual tuning of model complexity hyperparameters like\ntensor rank and feature dimensions, often through trial-and-error or\ncomputationally costly methods like cross-validation. We propose Bayesian\nTensor Network Kernel Machines, a fully probabilistic framework that uses\nsparsity-inducing hierarchical priors on TN factors to automatically infer\nmodel complexity. This enables automatic inference of tensor rank and feature\ndimensions, while also identifying the most relevant features for prediction,\nthereby enhancing model interpretability. All the model parameters and\nhyperparameters are treated as latent variables with corresponding priors.\nGiven the Bayesian approach and latent variable dependencies, we apply a\nmean-field variational inference to approximate their posteriors. We show that\napplying a mean-field approximation to TN factors yields a Bayesian ALS\nalgorithm with the same computational complexity as its deterministic\ncounterpart, enabling uncertainty quantification at no extra computational\ncost. Experiments on synthetic and real-world datasets demonstrate the superior\nperformance of our model in prediction accuracy, uncertainty quantification,\ninterpretability, and scalability.", "published": "2025-07-15 09:37:49", "link": "http://arxiv.org/abs/2507.11136v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "A Mathematical Optimization Approach to Multisphere Support Vector Data Description", "abstract": "We present a novel mathematical optimization framework for outlier detection\nin multimodal datasets, extending Support Vector Data Description approaches.\nWe provide a primal formulation, in the shape of a Mixed Integer Second Order\nCone model, that constructs Euclidean hyperspheres to identify anomalous\nobservations. Building on this, we develop a dual model that enables the\napplication of the kernel trick, thus allowing for the detection of outliers\nwithin complex, non-linear data structures. An extensive computational study\ndemonstrates the effectiveness of our exact method, showing clear advantages\nover existing heuristic techniques in terms of accuracy and robustness.", "published": "2025-07-15 08:57:27", "link": "http://arxiv.org/abs/2507.11106v1", "categories": ["math.OC", "cs.LG"], "primary_category": "math.OC"}
{"title": "A Distance Metric for Mixed Integer Programming Instances", "abstract": "Mixed-integer linear programming (MILP) is a powerful tool for addressing a\nwide range of real-world problems, but it lacks a clear structure for comparing\ninstances. A reliable similarity metric could establish meaningful\nrelationships between instances, enabling more effective evaluation of instance\nset heterogeneity and providing better guidance to solvers, particularly when\nmachine learning is involved. Existing similarity metrics often lack precision\nin identifying instance classes or rely heavily on labeled data, which limits\ntheir applicability and generalization. To bridge this gap, this paper\nintroduces the first mathematical distance metric for MILP instances, derived\ndirectly from their mathematical formulations. By discretizing right-hand\nsides, weights, and variables into classes, the proposed metric draws\ninspiration from the Earth mover's distance to quantify mismatches in\nweight-variable distributions for constraint comparisons. This approach\nnaturally extends to enable instance-level comparisons. We evaluate both an\nexact and a greedy variant of our metric under various parameter settings,\nusing the StrIPLIB dataset. Results show that all components of the metric\ncontribute to class identification, and that the greedy version achieves\naccuracy nearly identical to the exact formulation while being nearly 200 times\nfaster. Compared to state-of-the-art baselines, including feature-based,\nimage-based, and neural network models, our unsupervised method consistently\noutperforms all non-learned approaches and rivals the performance of a\nsupervised classifier on class and subclass grouping tasks.", "published": "2025-07-15 07:55:09", "link": "http://arxiv.org/abs/2507.11063v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Relative Entropy Pathwise Policy Optimization", "abstract": "Score-function policy gradients have delivered strong results in\ngame-playing, robotics and language-model fine-tuning. Yet its high-variance\noften undermines training stability. On the other hand, pathwise policy\ngradients alleviate the training variance, but are reliable only when driven by\nan accurate action-conditioned value function which is notoriously hard to\ntrain without relying on past off-policy data. In this paper, we discuss how to\nconstruct a value-gradient driven, on-policy algorithm that allow training\nQ-value models purely from on-policy data, unlocking the possibility of using\npathwise policy updates in the context of on-policy learning. We show how to\nbalance stochastic policies for exploration with constrained policy updates for\nstable training, and evaluate important architectural components that\nfacilitate accurate value function learning. Building on these insights, we\npropose Relative Entropy Pathwise Policy Optimization (REPPO), an efficient\non-policy algorithm that combines the sample-efficiency of pathwise policy\ngradients with the simplicity and minimal memory footprint of standard\non-policy learning. We demonstrate that REPPO provides strong empirical\nperformance at decreased sample requirements, wall-clock time, memory footprint\nas well as high hyperparameter robustness in a set of experiments on two\nstandard GPU-parallelized benchmarks.", "published": "2025-07-15 06:24:07", "link": "http://arxiv.org/abs/2507.11019v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Leveraging Advanced Machine Learning to Predict Turbulence Dynamics from Temperature Observations at an Experimental Prescribed Fire", "abstract": "This study explores the potential for predicting turbulent kinetic energy\n(TKE) from more readily acquired temperature data using temperature profiles\nand turbulence data collected concurrently at 10 Hz during a small experimental\nprescribed burn in the New Jersey Pine Barrens. Machine learning models,\nincluding Deep Neural Networks, Random Forest Regressor, Gradient Boosting, and\nGaussian Process Regressor, were employed to assess the potential to predict\nTKE from temperature perturbations and explore temporal and spatial dynamics of\ncorrelations. Data visualization and correlation analyses revealed patterns and\nrelationships between thermocouple temperatures and TKE, providing insight into\nthe underlying dynamics. More accurate predictions of TKE were achieved by\nemploying various machine learning models despite a weak correlation between\nthe predictors and the target variable. The results demonstrate significant\nsuccess, particularly from regression models, in accurately predicting the TKE.\nThe findings of this study demonstrate a novel numerical approach to\nidentifying new relationships between temperature and airflow processes in and\naround the fire environment. These relationships can help refine our\nunderstanding of combustion environment processes and the coupling and\ndecoupling of fire environment processes necessary for improving fire\noperations strategy and fire and smoke model predictions. The findings of this\nstudy additionally highlight the valuable role of machine learning techniques\nin analyzing the complex large datasets of the fire environments, showcasing\ntheir potential to advance fire research and management practices.", "published": "2025-07-15 06:07:14", "link": "http://arxiv.org/abs/2507.11012v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "AdaMuon: Adaptive Muon Optimizer", "abstract": "We propose AdaMuon, an adaptive learning-rate framework built upon the\nrecently validated Muon optimizer, which has demonstrated substantial\nefficiency gains over AdamW in large-scale model training. AdaMuon augments\nMuon with two mutually dependent modules: (1) a per-parameter second-moment\nmodulation that captures orthogonal gradient updates to ensure update-level\nadaptivity, and (2) a RMS-aligned rescaling that regulates the overall update\nmagnitude by aligning it with the intrinsic structure of the parameter space.\nEmpirical results on multiple model scales and learning-rate regimes confirm\nthat AdaMuon consistently outperforms the original Muon, delivering higher\nacceleration in convergence while maintaining training stability. Our method\nintroduces no additional tuning burden and can be seamlessly integrated into\nexisting Muon training pipelines.", "published": "2025-07-15 05:49:37", "link": "http://arxiv.org/abs/2507.11005v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "StellarF: A Lora-Adapter Integrated Large Model Framework for Stellar Flare Forecasting with Historical & Statistical Data", "abstract": "Stellar flare forecasting, a critical research frontier in astronomy, offers\nprofound insights into stellar activity. However, the field is constrained by\nboth the sparsity of recorded flare events and the absence of domain-specific\nlarge-scale predictive models. To address these challenges, this study\nintroduces StellarF (Stellar Flare Forecasting), a novel large model that\nleverages Low-Rank (LoRA) and Adapter techniques to parameter-efficient\nlearning for stellar flare forecasting. At its core, StellarF integrates an\nflare statistical information module with a historical flare record module,\nenabling multi-scale pattern recognition from observational data. Extensive\nexperiments on our self-constructed datasets (derived from Kepler and TESS\nlight curves) demonstrate that StellarF achieves state-of-the-art performance\ncompared to existing methods. The proposed prediction paradigm establishes a\nnovel methodological framework for advancing astrophysical research and\ncross-disciplinary applications.", "published": "2025-07-15 04:59:22", "link": "http://arxiv.org/abs/2507.10986v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Physics-Informed Neural Networks For Semiconductor Film Deposition: A Review", "abstract": "Semiconductor manufacturing relies heavily on film deposition processes, such\nas Chemical Vapor Deposition and Physical Vapor Deposition. These complex\nprocesses require precise control to achieve film uniformity, proper adhesion,\nand desired functionality. Recent advancements in Physics-Informed Neural\nNetworks (PINNs), an innovative machine learning (ML) approach, have shown\nsignificant promise in addressing challenges related to process control,\nquality assurance, and predictive modeling within semiconductor film deposition\nand other manufacturing domains. This paper provides a comprehensive review of\nML applications targeted at semiconductor film deposition processes. Through a\nthematic analysis, we identify key trends, existing limitations, and research\ngaps, offering insights into both the advantages and constraints of current\nmethodologies. Our structured analysis aims to highlight the potential\nintegration of these ML techniques to enhance interpretability, accuracy, and\nrobustness in film deposition processes. Additionally, we examine\nstate-of-the-art PINN methods, discussing strategies for embedding physical\nknowledge, governing laws, and partial differential equations into advanced\nneural network architectures tailored for semiconductor manufacturing. Based on\nthis detailed review, we propose novel research directions that integrate the\nstrengths of PINNs to significantly advance film deposition processes. The\ncontributions of this study include establishing a clear pathway for future\nresearch in integrating physics-informed ML frameworks, addressing existing\nmethodological gaps, and ultimately improving precision, scalability, and\noperational efficiency within semiconductor manufacturing.", "published": "2025-07-15 04:56:26", "link": "http://arxiv.org/abs/2507.10983v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "GOLFS: Feature Selection via Combining Both Global and Local Information for High Dimensional Clustering", "abstract": "It is important to identify the discriminative features for high dimensional\nclustering. However, due to the lack of cluster labels, the regularization\nmethods developed for supervised feature selection can not be directly applied.\nTo learn the pseudo labels and select the discriminative features\nsimultaneously, we propose a new unsupervised feature selection method, named\nGlObal and Local information combined Feature Selection (GOLFS), for high\ndimensional clustering problems. The GOLFS algorithm combines both local\ngeometric structure via manifold learning and global correlation structure of\nsamples via regularized self-representation to select the discriminative\nfeatures. The combination improves the accuracy of both feature selection and\nclustering by exploiting more comprehensive information. In addition, an\niterative algorithm is proposed to solve the optimization problem and the\nconvergency is proved. Simulations and two real data applications demonstrate\nthe excellent finite-sample performance of GOLFS on both feature selection and\nclustering.", "published": "2025-07-15 03:39:07", "link": "http://arxiv.org/abs/2507.10956v1", "categories": ["stat.ML", "cs.LG", "62-08", "G.3"], "primary_category": "stat.ML"}
{"title": "Diffusion Decoding for Peptide De Novo Sequencing", "abstract": "Peptide de novo sequencing is a method used to reconstruct amino acid\nsequences from tandem mass spectrometry data without relying on existing\nprotein sequence databases. Traditional deep learning approaches, such as\nCasanovo, mainly utilize autoregressive decoders and predict amino acids\nsequentially. Subsequently, they encounter cascading errors and fail to\nleverage high-confidence regions effectively. To address these issues, this\npaper investigates using diffusion decoders adapted for the discrete data\ndomain. These decoders provide a different approach, allowing sequence\ngeneration to start from any peptide segment, thereby enhancing prediction\naccuracy. We experiment with three different diffusion decoder designs,\nknapsack beam search, and various loss functions. We find knapsack beam search\ndid not improve performance metrics and simply replacing the transformer\ndecoder with a diffusion decoder lowered performance. Although peptide\nprecision and recall were still 0, the best diffusion decoder design with the\nDINOISER loss function obtained a statistically significant improvement in\namino acid recall by 0.373 compared to the baseline autoregressive\ndecoder-based Casanovo model. These findings highlight the potential of\ndiffusion decoders to not only enhance model sensitivity but also drive\nsignificant advancements in peptide de novo sequencing.", "published": "2025-07-15 03:38:01", "link": "http://arxiv.org/abs/2507.10955v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Towards Practical Benchmarking of Data Cleaning Techniques: On Generating Authentic Errors via Large Language Models", "abstract": "Data quality remains an important challenge in data-driven systems, as errors\nin tabular data can severely compromise downstream analytics and machine\nlearning performance. Although numerous error detection algorithms have been\nproposed, the lack of diverse, real-world error datasets limits comprehensive\nevaluation. Manual error annotation is both time-consuming and inconsistent,\nmotivating the exploration of synthetic error generation as an alternative. In\nthis work, we introduce TableEG, a framework that leverages large language\nmodels (LLMs) to generate authentic errors. By employing a table fine-tuning\nstrategy and a triplet representation $(I, T, O)$ to model error generation,\ndetection, and correction tasks, TableEG captures the complex dependencies\ninherent in two-dimensional tables. Trained on 12 real-world datasets spanning\n10 diverse domains, TableEG ensures that the synthesized errors faithfully\nreflect authentic error distributions. Experimental results indicate that\nerrors generated by TableEG exhibit superior pattern and distribution\nsimilarity compared to both rule-based methods and LLM-generated errors without\nfine-tuning. Furthermore, performance metrics on TableEG-generated errors\nclosely align with those on real-world errors across nearly all datasets and\ndetection algorithms, particularly for machine learning based detection\ntechniques. Overall, TableEG not only bridges the gap between synthetic and\nreal-world errors but also establishes a robust benchmark for subsequent error\ndetection and correction tasks.", "published": "2025-07-15 02:58:25", "link": "http://arxiv.org/abs/2507.10934v1", "categories": ["cs.DB", "cs.LG"], "primary_category": "cs.DB"}
{"title": "A Learning Framework For Cooperative Collision Avoidance of UAV Swarms Leveraging Domain Knowledge", "abstract": "This paper presents a multi-agent reinforcement learning (MARL) framework for\ncooperative collision avoidance of UAV swarms leveraging domain\nknowledge-driven reward. The reward is derived from knowledge in the domain of\nimage processing, approximating contours on a two-dimensional field. By\nmodeling obstacles as maxima on the field, collisions are inherently avoided as\ncontours never go through peaks or intersect. Additionally, counters are smooth\nand energy-efficient. Our framework enables training with large swarm sizes as\nthe agent interaction is minimized and the need for complex credit assignment\nschemes or observation sharing mechanisms in state-of-the-art MARL approaches\nare eliminated. Moreover, UAVs obtain the ability to adapt to complex\nenvironments where contours may be non-viable or non-existent through intensive\ntraining. Extensive experiments are conducted to evaluate the performances of\nour framework against state-of-the-art MARL algorithms.", "published": "2025-07-15 02:09:53", "link": "http://arxiv.org/abs/2507.10913v1", "categories": ["cs.MA", "cs.LG", "cs.RO"], "primary_category": "cs.MA"}
{"title": "Outbound Modeling for Inventory Management", "abstract": "We study the problem of forecasting the number of units fulfilled (or\n``drained'') from each inventory warehouse to meet customer demand, along with\nthe associated outbound shipping costs. The actual drain and shipping costs are\ndetermined by complex production systems that manage the planning and execution\nof customers' orders fulfillment, i.e. from where and how to ship a unit to be\ndelivered to a customer. Accurately modeling these processes is critical for\nregional inventory planning, especially when using Reinforcement Learning (RL)\nto develop control policies. For the RL usecase, a drain model is incorporated\ninto a simulator to produce long rollouts, which we desire to be\ndifferentiable. While simulating the calls to the internal software systems can\nbe used to recover this transition, they are non-differentiable and too slow\nand costly to run within an RL training environment. Accordingly, we frame this\nas a probabilistic forecasting problem, modeling the joint distribution of\noutbound drain and shipping costs across all warehouses at each time period,\nconditioned on inventory positions and exogenous customer demand. To ensure\nrobustness in an RL environment, the model must handle out-of-distribution\nscenarios that arise from off-policy trajectories. We propose a validation\nscheme that leverages production systems to evaluate the drain model on\ncounterfactual inventory states induced by RL policies. Preliminary results\ndemonstrate the model's accuracy within the in-distribution setting.", "published": "2025-07-15 01:10:38", "link": "http://arxiv.org/abs/2507.10890v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Learning from Imperfect Data: Robust Inference of Dynamic Systems using Simulation-based Generative Model", "abstract": "System inference for nonlinear dynamic models, represented by ordinary\ndifferential equations (ODEs), remains a significant challenge in many fields,\nparticularly when the data are noisy, sparse, or partially observable. In this\npaper, we propose a Simulation-based Generative Model for Imperfect Data\n(SiGMoID) that enables precise and robust inference for dynamic systems. The\nproposed approach integrates two key methods: (1) physics-informed neural\nnetworks with hyper-networks that constructs an ODE solver, and (2) Wasserstein\ngenerative adversarial networks that estimates ODE parameters by effectively\ncapturing noisy data distributions. We demonstrate that SiGMoID quantifies data\nnoise, estimates system parameters, and infers unobserved system components.\nIts effectiveness is validated validated through realistic experimental\nexamples, showcasing its broad applicability in various domains, from\nscientific research to engineered systems, and enabling the discovery of full\nsystem dynamics.", "published": "2025-07-15 00:56:21", "link": "http://arxiv.org/abs/2507.10884v1", "categories": ["cs.LG", "math.DS", "68T07, 68T05, 70G60"], "primary_category": "cs.LG"}
{"title": "BioScore: A Foundational Scoring Function For Diverse Biomolecular Complexes", "abstract": "Structural assessment of biomolecular complexes is vital for translating\nmolecular models into functional insights, shaping our understanding of biology\nand aiding drug discovery. However, current structure-based scoring functions\noften lack generalizability across diverse biomolecular systems. We present\nBioScore, a foundational scoring function that addresses key challenges -- data\nsparsity, cross-system representation, and task compatibility -- through a\ndual-scale geometric graph learning framework with tailored modules for\nstructure assessment and affinity prediction. BioScore supports a wide range of\ntasks, including affinity prediction, conformation ranking, and structure-based\nvirtual screening. Evaluated on 16 benchmarks spanning proteins, nucleic acids,\nsmall molecules, and carbohydrates, BioScore consistently outperforms or\nmatches 70 traditional and deep learning methods. Our newly proposed PPI\nBenchmark further enables comprehensive evaluation of protein-protein complex\nscoring. BioScore demonstrates broad applicability: (1) pretraining on\nmixed-structure data boosts protein-protein affinity prediction by up to 40%\nand antigen-antibody binding correlation by over 90%; (2) cross-system\ngeneralizability enables zero- and few-shot prediction with up to 71%\ncorrelation gain; and (3) its unified representation captures chemically\nchallenging systems such as cyclic peptides, improving affinity prediction by\nover 60%. BioScore establishes a robust and generalizable framework for\nstructural assessment across complex biomolecular landscapes.", "published": "2025-07-15 00:41:58", "link": "http://arxiv.org/abs/2507.10877v1", "categories": ["physics.chem-ph", "cs.LG", "physics.bio-ph"], "primary_category": "physics.chem-ph"}
{"title": "GALDS: A Graph-Autoencoder-based Latent Dynamics Surrogate model to predict neurite material transport", "abstract": "Neurons exhibit intricate geometries within their neurite networks, which\nplay a crucial role in processes such as signaling and nutrient transport.\nAccurate simulation of material transport in the networks is essential for\nunderstanding these biological phenomena but poses significant computational\nchallenges because of the complex tree-like structures involved. Traditional\napproaches are time-intensive and resource-demanding, yet the inherent\nproperties of neuron trees, which consists primarily of pipes with steady-state\nparabolic velocity profiles and bifurcations, provide opportunities for\ncomputational optimization. To address these challenges, we propose a\nGraph-Autoencoder-based Latent Dynamics Surrogate (GALDS) model, which is\nspecifically designed to streamline the simulation of material transport in\nneural trees. GALDS employs a graph autoencoder to encode latent\nrepresentations of the network's geometry, velocity fields, and concentration\nprofiles. These latent space representations are then assembled into a global\ngraph, which is subsequently used to predict system dynamics in the latent\nspace via a trained graph latent space system dynamic model, inspired by the\nNeural Ordinary Differential Equations (Neural ODEs) concept. The integration\nof an autoencoder allows for the use of smaller graph neural network models\nwith reduced training data requirements. Furthermore, the Neural ODE component\neffectively mitigates the issue of error accumulation commonly encountered in\nrecurrent neural networks. The effectiveness of the GALDS model is demonstrated\nthrough results on eight unseen geometries and four abnormal transport\nexamples, where our approach achieves mean relative error of 3% with maximum\nrelative error <8% and demonstrates a 10-fold speed improvement compared to\nprevious surrogate model approaches.", "published": "2025-07-15 00:22:00", "link": "http://arxiv.org/abs/2507.10871v1", "categories": ["cs.LG", "cs.NA", "math.NA", "physics.med-ph"], "primary_category": "cs.LG"}
{"title": "LF: Online Multi-Robot Path Planning Meets Optimal Trajectory Control", "abstract": "We propose a multi-robot control paradigm to solve point-to-point navigation\ntasks for a team of holonomic robots with access to the full environment\ninformation. The framework invokes two processes asynchronously at high\nfrequency: (i) a centralized, discrete, and full-horizon planner for computing\ncollision- and deadlock-free paths rapidly, leveraging recent advances in\nmulti-agent pathfinding (MAPF), and (ii) dynamics-aware, robot-wise optimal\ntrajectory controllers that ensure all robots independently follow their\nassigned paths reliably. This hierarchical shift in planning representation\nfrom (i) discrete and coupled to (ii) continuous and decoupled domains enables\nthe framework to maintain long-term scalable motion synthesis. As an\ninstantiation of this idea, we present LF, which combines a fast\nstate-of-the-art MAPF solver (LaCAM), and a robust feedback control stack\n(Freyja) for executing agile robot maneuvers. LF provides a robust and\nversatile mechanism for lifelong multi-robot navigation even under asynchronous\nand partial goal updates, and adapts to dynamic workspaces simply by quick\nreplanning. We present various multirotor and ground robot demonstrations,\nincluding the deployment of 15 real multirotors with random, consecutive target\nupdates while a person walks through the operational workspace.", "published": "2025-07-15 16:35:37", "link": "http://arxiv.org/abs/2507.11464v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Scaling the memory wall using mixed-precision -- HPG-MxP on an exascale machine", "abstract": "Mixed-precision algorithms have been proposed as a way for scientific\ncomputing to benefit from some of the gains seen for artificial intelligence\n(AI) on recent high performance computing (HPC) platforms. A few applications\ndominated by dense matrix operations have seen substantial speedups by\nutilizing low precision formats such as FP16. However, a majority of scientific\nsimulation applications are memory bandwidth limited. Beyond preliminary\nstudies, the practical gain from using mixed-precision algorithms on a given\nHPC system is largely unclear.\n  The High Performance GMRES Mixed Precision (HPG-MxP) benchmark has been\nproposed to measure the useful performance of a HPC system on sparse\nmatrix-based mixed-precision applications. In this work, we present a highly\noptimized implementation of the HPG-MxP benchmark for an exascale system and\ndescribe our algorithm enhancements. We show for the first time a speedup of\n1.6x using a combination of double- and single-precision on modern GPU-based\nsupercomputers.", "published": "2025-07-15 17:26:37", "link": "http://arxiv.org/abs/2507.11512v1", "categories": ["cs.DC", "cs.NA", "cs.PF", "math.NA", "65Y10", "G.4; C.4"], "primary_category": "cs.DC"}
{"title": "The Marcinkiewicz-Zygmund Property for Riemann Differences with Geometric Nodes", "abstract": "We study when a Riemann difference of order $ n $ possesses the\nMarcinkiewicz-Zygmund (MZ) property: that is, whether the conditions $ f(h) =\no(h^{n-1}) $ and $ Df(h) = o(h^n) $ imply $ f(h) = o(h^n) $. This implication\nis known to hold for some classical examples with geometric nodes, such as $\n\\{0, 1, q, \\dots, q^{n-1}\\} $ and $ \\{1, q, \\dots, q^n\\} $, leading to a\nconjecture that these are the only such Riemann differences with the MZ\nproperty. However, this conjecture was disproved by the third-order example\nwith nodes $ \\{-1, 0, 1, 2\\} $, and we provide further counterexamples and a\ngeneral classification here.\n  We establish a complete analytic criterion for the MZ property by developing\na recurrence framework: we analyze when a function $ R(h) $ satisfying $ D(h) =\nR(qh) - A R(h) $, together with $ D(h) = o(h^n) $ and $ R(h) = o(h^{n-1}) $,\nforces $ R(h) = o(h^n) $. We prove that this holds if and only if $ A $ lies\noutside a critical modulus annulus determined by $ q $ and $ n $, covering both\n$ |q| > 1 $ and $ |q| < 1 $ cases. This leads to a complete characterization of\nall Riemann differences with geometric nodes that possess the MZ property, and\nprovides a flexible analytic framework applicable to broader classes of\ngeneralized differences.", "published": "2025-07-15 16:34:35", "link": "http://arxiv.org/abs/2507.11463v1", "categories": ["math.CA", "cs.NA", "math.NA"], "primary_category": "math.CA"}
{"title": "The Evolution of Pointwise Statistics in Hyperbolic Equations with Random Data", "abstract": "We consider one-dimensional hyperbolic PDEs, linear and nonlinear, with\nrandom initial data. Our focus is the {\\em pointwise statistics,} i.e., the\nprobability measure of the solution at any fixed point in space and time. For\nlinear hyperbolic equations, the probability density function (PDF) of these\nstatistics satisfies the same linear PDE. For nonlinear hyperbolic PDEs, we\nderive a linear transport equation for the cumulative distribution function\n(CDF) and a nonlocal linear PDE for the PDF. Both results are valid only as\nlong as no shocks have formed, a limitation which is inherent to the problem,\nas demonstrated by a counterexample. For systems of linear hyperbolic\nequations, we introduce the multi-point statistics and derive their evolution\nequations. In all of the settings we consider, the resulting PDEs for the\nstatistics are of practical significance: they enable efficient evaluation of\nthe random dynamics, without requiring an ensemble of solutions of the\nunderlying PDE, and their cost is not affected by the dimension of the random\nparameter space. Additionally, the evolution equations for the statistics lead\nto a priori statistical error bounds for Monte Carlo methods (in particular,\nKernel Density Estimators) when applied to hyperbolic PDEs with random data.", "published": "2025-07-15 15:09:22", "link": "http://arxiv.org/abs/2507.11399v1", "categories": ["math.AP", "cs.NA", "math.NA"], "primary_category": "math.AP"}
{"title": "Effects of rough boundary and nonzero boundary conditions on the lubrication process with micropolar fluid", "abstract": "The lubrication theory is mostly concerned with the behavior of a lubricant\nflowing through a narrow gap. Motivated by the experimental findings from the\ntribology literature, we take the lubricant to be micropolar fluid and study\nits behavior in a thin domain with rough boundary. Instead of considering\n(commonly used) simple zero boundary condition, we impose physically relevant\n(nonzero) boundary condition for microrotation and perform asymptotic analysis\nof the corresponding 3D boundary value problem. We formally derive a simplified\nmathematical model acknowledging the roughness-induced effects and the effects\nof the nonzero boundary conditions on the macroscopic flow. Using the obtained\nasymptotic model, we study numerically the influence of the specific rugosity\nprofile on the performance of a linear slider bearing. The numerical results\nclearly indicate that the use of the rough surfaces may contribute to enhance\nthe mechanical performance of such device.", "published": "2025-07-15 13:50:01", "link": "http://arxiv.org/abs/2507.11318v1", "categories": ["math.AP", "cs.NA", "math.NA", "35B27"], "primary_category": "math.AP"}
{"title": "Second-Order Characterizations of Tilt Stability in Composite Optimization", "abstract": "Tilt stability is a fundamental concept of variational analysis and\noptimization that plays a pivotal role in both theoretical issues and numerical\ncomputations. This paper investigates tilt stability of local minimizers for a\ngeneral class of composite optimization problems in finite dimensions, where\nextended-real-valued objectives are compositions of parabolically regular and\nsmooth functions. Under the weakest metric subregularity constraint\nqualification and other verifiable conditions, we establish unified\nneighborhood and pointbased characterizations of tilt stability via\nsecond-order generalized differentiation. The obtained results provide a\nrigorous theoretical foundation for further developments on variational\nstability and numerical algorithms of optimization and related topics.", "published": "2025-07-15 12:25:59", "link": "http://arxiv.org/abs/2507.11253v1", "categories": ["math.OC", "cs.NA", "math.NA", "49J52, 49J53, 90C31"], "primary_category": "math.OC"}
{"title": "On maximal curves of $n$-correct sets", "abstract": "Suppose $\\mathcal{X}$ is an $n$-correct set of nodes in the plane, that is,\nit admits a unisolvent interpolation with bivariate polynomials of total degree\nless than or equal to $n.$ Then an algebraic curve $q$ of degree $k\\le n$ can\npass through at most $d(n,k)$ nodes of $\\Xset,$ where $d(n,k)={{n+2}\\choose\n{2}}-{{n+2-k}\\choose {2}}.$ A curve $q$ of degree $k\\le n$ is called maximal if\nit passes through exactly $d(n,k)$ nodes of $\\mathcal{X}.$ In particular, a\nmaximal line is a line passing through $d(n,1)=n+1$ nodes of $\\mathcal{X}.$\nMaximal curves are an important tool for the study of $n$-correct sets. We\npresent new properties of maximal curves, as well as extensions of known\nproperties.", "published": "2025-07-15 11:26:09", "link": "http://arxiv.org/abs/2507.11207v1", "categories": ["math.NA", "cs.NA", "math.AG", "41A05, 41A63, 14H50"], "primary_category": "math.NA"}
{"title": "Energy Balance and Optical Theorem for Time-Modulated Subwavelength Resonator Arrays", "abstract": "We study wave propagation through a one-dimensional array of subwavelength\nresonators with periodically time-modulated material parameters. Focusing on a\nhigh-contrast regime, we use a scattering framework based on Fourier expansions\nand scattering matrix techniques to capture the interactions between an\nincident wave and the temporally varying system. This way, we derive a\nformulation of the total energy flux corresponding to time-dependent systems of\nresonators. We show that the total energy flux is composed of the transmitted\nand reflected energy fluxes, and derive an optical theorem which characterises\nthe energy balance of the system. We provide a number of numerical experiments\nto investigate the impact of the time-dependency, the operating frequency and\nthe number of resonators on the maximal attainable energy gain and energy loss.\nMoreover, we show the existence of lasing points, at which the total energy\ndiverges. Our results lay the foundation for the design of energy dissipative\nor energy amplifying systems.", "published": "2025-07-15 11:13:56", "link": "http://arxiv.org/abs/2507.11201v1", "categories": ["physics.optics", "cs.NA", "math-ph", "math.AP", "math.MP", "math.NA", "35Q60, 35L05, 78A45, 78M35, 35P25"], "primary_category": "physics.optics"}
{"title": "Adaptive FEM with explicit time integration for the wave equation", "abstract": "Starting from a recent a posteriori error estimator for the finite element\nsolution of the wave equation with explicit time-stepping [Grote, Lakkis,\nSantos, 2024], we devise a space-time adaptive strategy which includes both\ntime evolving meshes and local time-stepping [Diaz, Grote, 2009] to overcome\nany overly stringent CFL stability restriction on the time-step due to local\nmesh refinement. Moreover, at each time-step the adaptive algorithm monitors\nthe accuracy thanks to the error indicators and recomputes the current step on\na refined mesh until the desired tolerance is met; meanwhile, the mesh is\ncoarsened in regions of smaller errors. Leapfrog based local time-stepping is\napplied in all regions of local mesh refinement to incorporate adaptivity into\nfully explicit time integration with mesh change while retaining efficiency.\nNumerical results illustrate the optimal rate of convergence of the a\nposteriori error estimators on time evolving meshes.", "published": "2025-07-15 10:53:57", "link": "http://arxiv.org/abs/2507.11193v1", "categories": ["math.NA", "cs.NA", "65M60, 65M22, 65J10, 35A35, 35L05,", "G.1.8; G.4"], "primary_category": "math.NA"}
{"title": "Convergence of a finite-volume scheme for aggregation-diffusion equations with saturation", "abstract": "In [Bailo, Carrillo, Hu. SIAM J. Appl. Math. 2023] the authors introduce a\nfinite-volume method for aggregation-diffusion equations with non-linear\nmobility. In this paper we prove convergence of this method using an\nAubin--Simons compactness theorem due to Gallou\\\"et and Latch\\'e. We use\nsuitable discrete $H^1$ and $W^{-1,1}$ discrete norms. We provide two\nconvergence results. A first result shows convergence with general entropies\n($U$) (including singular and degenerate) if the initial datum does not have\nfree boundaries, the mobility is Lipschitz, and the confinement ($V$) and\naggregation ($K$) potentials are $W^{2,\\infty}_0$. A second result shows\nconvergence when the initial datum has free boundaries, mobility is just\ncontinuous, and $V$ and $K$ are $W^{1,\\infty}$, but under the assumption that\nthe entropy $U$ is $C^1$ and strictly convex.", "published": "2025-07-15 09:33:16", "link": "http://arxiv.org/abs/2507.11132v1", "categories": ["math.NA", "cs.NA", "math.AP", "65M08, 35Q70, 35Q92, 45K05"], "primary_category": "math.NA"}
{"title": "Adaptive Reduced Basis Trust Region Methods for Parabolic Inverse Problems", "abstract": "We consider nonlinear inverse problems arising in the context of parameter\nidentification for parabolic partial differential equations (PDEs). For stable\nreconstructions, regularization methods such as the iteratively regularized\nGauss-Newton method (IRGNM) are commonly used, but their application is\ncomputationally demanding due to the high-dimensional nature of PDE\ndiscretizations. To address this bottleneck, we propose a reduced-order\nmodeling approach that accelerates both the state and adjoint evaluations\nrequired for derivative-based optimization. Our method builds on the recent\ncontribution [Kartmann et al. Adaptive reduced basis trust region methods for\nparameter identification problems. Comput. Sci. Eng. 1, 3 (2024)] for elliptic\nforward operators and constructs the reduced forward operator adaptively in an\nonline fashion, combining both parameter and state space reduction. To ensure\nreliability, we embed the IRGNM iteration within an adaptive, error-aware\ntrust-region framework that certifies the accuracy of the reduced-order\napproximations. We demonstrate the effectiveness of the proposed approach\nthrough numerical results for both time-dependent and time-independent\nparameter identification problems in dynamic reaction-diffusion systems. The\nimplementation is made available for reproducibility and further use.", "published": "2025-07-15 09:30:37", "link": "http://arxiv.org/abs/2507.11130v1", "categories": ["math.NA", "cs.NA", "math.OC", "35R30, 35K90, 65M32, 35K57"], "primary_category": "math.NA"}
{"title": "Closed Form Time Derivatives of the Equations of Motion of Rigid Body Systems", "abstract": "Derivatives of equations of motion(EOM) describing the dynamics of rigid body\nsystems are becoming increasingly relevant for the robotics community and find\nmany applications in design and control of robotic systems. Controlling robots,\nand multibody systems comprising elastic components in particular, not only\nrequires smooth trajectories but also the time derivatives of the control\nforces/torques, hence of the EOM. This paper presents the time derivatives of\nthe EOM in closed form up to second-order as an alternative formulation to the\nexisting recursive algorithms for this purpose, which provides a direct insight\ninto the structure of the derivatives. The Lie group formulation for rigid body\nsystems is used giving rise to very compact and easily parameterized equations.", "published": "2025-07-15 08:16:39", "link": "http://arxiv.org/abs/2507.11076v1", "categories": ["cs.RO", "cs.NA", "math.DG", "math.DS", "math.GR", "math.NA"], "primary_category": "cs.RO"}
{"title": "Stability of the Active Flux Method in the Framework of Summation-by-Parts Operators", "abstract": "The Active Flux method is a numerical method for conservation laws using a\ncombination of cell averages and point values, based on ideas from finite\nvolumes and finite differences. This unusual mix has been shown to work well in\nmany situations. We expand the theoretical justifications of the Active Flux\nmethod by analyzing it from the point of view of summation-by-parts (SBP)\noperators, which are routinely used to analyze finite difference, finite\nvolume, and finite element schemes. We show that the Active Flux method can be\nformulated using degenerate SBP operators, yielding a first and novel approach\nfor showing the energy stability of the Active Flux method.", "published": "2025-07-15 08:01:26", "link": "http://arxiv.org/abs/2507.11068v1", "categories": ["math.NA", "cs.NA", "65M06, 65M20, 65M70"], "primary_category": "math.NA"}
{"title": "Dimension of Bi-degree $(d,d)$ Spline Spaces with the Highest Order of Smoothness over Hierarchical T-Meshes", "abstract": "In this article, we study the dimension of the spline space of di-degree\n$(d,d)$ with the highest order of smoothness over a hierarchical T-mesh\n$\\mathscr T$ using the smoothing cofactor-conformality method. Firstly, we\nobtain a dimensional formula for the conformality vector space over a tensor\nproduct T-connected component. Then, we prove that the dimension of the\nconformality vector space over a T-connected component of a hierarchical T-mesh\nunder the tensor product subdivision can be calculated in a recursive manner.\nCombining these two aspects, we obtain a dimensional formula for the bi-degree\n$(d,d)$ spline space with the highest order of smoothness over a hierarchical\nT-mesh $\\mathscr T$ with mild assumption. Additionally, we provide a strategy\nto modify an arbitrary hierarchical T-mesh such that the dimension of the\nbi-degree $(d,d)$ spline space is stable over the modified hierarchical T-mesh.\nFinally, we prove that the dimension of the spline space over such a\nhierarchical T-mesh is the same as that of a lower-degree spline space over its\nCVR graph. Thus, the proposed solution can pave the way for the subsequent\nconstruction of basis functions for spline space over such a hierarchical\nT-mesh.", "published": "2025-07-15 07:20:34", "link": "http://arxiv.org/abs/2507.11047v1", "categories": ["math.NA", "cs.NA", "65D17, 65D07, 65N30"], "primary_category": "math.NA"}
{"title": "Pricing energy spread options with variance gamma-driven Ornstein-Uhlenbeck dynamics", "abstract": "We consider the pricing of energy spread options for spot prices following an\nexponential Ornstein-Uhlenbeck process driven by a sum of independent\nmultivariate variance gamma processes. Within this class of mean-reverting,\ninfinite activity price processes, the Esscher transform is used to obtain an\nequivalent martingale measure. We focus on the weak variance alpha-gamma\nprocess and show that it is not closed under the Esscher transform. By deriving\nan analytic expression for the cumulant generating function of the innovation\nterm, we then obtain a pricing formula for forwards and apply the FFT method of\nHurd and Zhou to price spread options. Lastly, we demonstrate how the model\nshould be both estimated on energy prices under the real world measure and\ncalibrated on forward or call prices, and provide numerical results for the\npricing of spread options.", "published": "2025-07-15 16:48:24", "link": "http://arxiv.org/abs/2507.11480v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "Urban delineation through the lens of commute networks: Leveraging graph embeddings to distinguish socioeconomic groups in cities", "abstract": "Delineating areas within metropolitan regions stands as an important focus\namong urban researchers, shedding light on the urban perimeters shaped by\nevolving population dynamics. Applications to urban science are numerous, from\nfacilitating comparisons between delineated districts and administrative\ndivisions to informing policymakers of the shifting economic and labor\nlandscapes. In this study, we propose using commute networks sourced from the\ncensus for the purpose of urban delineation, by modeling them with a Graph\nNeural Network (GNN) architecture. We derive low-dimensional representations of\ngranular urban areas (nodes) using GNNs. Subsequently, nodes' embeddings are\nclustered to identify spatially cohesive communities in urban areas. Our\nexperiments across the U.S. demonstrate the effectiveness of network embeddings\nin capturing significant socioeconomic disparities between communities in\nvarious cities, particularly in factors such as median household income. The\nrole of census mobility data in regional delineation is also noted, and we\nestablish the utility of GNNs in urban community detection, as a powerful\nalternative to existing methods in this domain. The results offer insights into\nthe wider effects of commute networks and their use in building meaningful\nrepresentations of urban regions.", "published": "2025-07-15 07:47:03", "link": "http://arxiv.org/abs/2507.11057v1", "categories": ["cs.SI", "physics.soc-ph", "stat.ML"], "primary_category": "cs.SI"}
{"title": "FasTUSS: Faster Task-Aware Unified Source Separation", "abstract": "Time-Frequency (TF) dual-path models are currently among the best performing\naudio source separation network architectures, achieving state-of-the-art\nperformance in speech enhancement, music source separation, and cinematic audio\nsource separation. While they are characterized by a relatively low parameter\ncount, they still require a considerable number of operations, implying a\nhigher execution time. This problem is exacerbated by the trend towards bigger\nmodels trained on large amounts of data to solve more general tasks, such as\nthe recently introduced task-aware unified source separation (TUSS) model.\nTUSS, which aims to solve audio source separation tasks using a single,\nconditional model, is built upon TF-Locoformer, a TF dual-path model combining\nconvolution and attention layers. The task definition comes in the form of a\nsequence of prompts that specify the number and type of sources to be\nextracted. In this paper, we analyze the design choices of TUSS with the goal\nof optimizing its performance-complexity trade-off. We derive two more\nefficient models, FasTUSS-8.3G and FasTUSS-11.7G that reduce the original\nmodel's operations by 81\\% and 73\\% with minor performance drops of 1.2~dB and\n0.4~dB averaged over all benchmarks, respectively. Additionally, we investigate\nthe impact of prompt conditioning to derive a causal TUSS model.", "published": "2025-07-15 15:57:28", "link": "http://arxiv.org/abs/2507.11435v1", "categories": ["cs.SD", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
{"title": "Towards Reliable Objective Evaluation Metrics for Generative Singing Voice Separation Models", "abstract": "Traditional Blind Source Separation Evaluation (BSS-Eval) metrics were\noriginally designed to evaluate linear audio source separation models based on\nmethods such as time-frequency masking. However, recent generative models may\nintroduce nonlinear relationships between the separated and reference signals,\nlimiting the reliability of these metrics for objective evaluation. To address\nthis issue, we conduct a Degradation Category Rating listening test and analyze\ncorrelations between the obtained degradation mean opinion scores (DMOS) and a\nset of objective audio quality metrics for the task of singing voice\nseparation. We evaluate three state-of-the-art discriminative models and two\nnew competitive generative models. For both discriminative and generative\nmodels, intrusive embedding-based metrics show higher correlations with DMOS\nthan conventional intrusive metrics such as BSS-Eval. For discriminative\nmodels, the highest correlation is achieved by the MSE computed on Music2Latent\nembeddings. When it comes to the evaluation of generative models, the strongest\ncorrelations are evident for the multi-resolution STFT loss and the MSE\ncalculated on MERT-L12 embeddings, with the latter also providing the most\nbalanced correlation across both model types. Our results highlight the\nlimitations of BSS-Eval metrics for evaluating generative singing voice\nseparation models and emphasize the need for careful selection and validation\nof alternative evaluation metrics for the task of singing voice separation.", "published": "2025-07-15 15:51:41", "link": "http://arxiv.org/abs/2507.11427v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "P.808 Multilingual Speech Enhancement Testing: Approach and Results of URGENT 2025 Challenge", "abstract": "In speech quality estimation for speech enhancement (SE) systems, subjective\nlistening tests so far are considered as the gold standard. This should be even\nmore true considering the large influx of new generative or hybrid methods into\nthe field, revealing issues of some objective metrics. Efforts such as the\nInterspeech 2025 URGENT Speech Enhancement Challenge also involving non-English\ndatasets add the aspect of multilinguality to the testing procedure. In this\npaper, we provide a brief recap of the ITU-T P.808 crowdsourced subjective\nlistening test method. A first novel contribution is our proposed process of\nlocalizing both text and audio components of Naderi and Cutler's implementation\nof crowdsourced subjective absolute category rating (ACR) listening tests\ninvolving text-to-speech (TTS). Further, we provide surprising analyses of and\ninsights into URGENT Challenge results, tackling the reliability of (P.808) ACR\nsubjective testing as gold standard in the age of generative AI. Particularly,\nit seems that for generative SE methods, subjective (ACR MOS) and objective\n(DNSMOS, NISQA) reference-free metrics should be accompanied by objective phone\nfidelity metrics to reliably detect hallucinations. Finally, in the accepted\nversion, we will release our localization scripts and methods for easy\ndeployment for new multilingual speech enhancement subjective evaluations\naccording to ITU-T P.808.", "published": "2025-07-15 13:38:02", "link": "http://arxiv.org/abs/2507.11306v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Array-Aware Ambisonics and HRTF Encoding for Binaural Reproduction With Wearable Arrays", "abstract": "This work introduces a novel method for binaural reproduction from arbitrary\nmicrophone arrays, based on array-aware optimization of Ambisonics encoding\nthrough Head-Related Transfer Function (HRTF) pre-processing. The proposed\napproach integrates array-specific information into the HRTF processing\npipeline, leading to improved spatial accuracy in binaural rendering. Objective\nevaluations demonstrate superior performance under simulated wearable-array and\nhead rotations compared to conventional Ambisonics encoding method. A listening\nexperiment further confirms that the method achieves significantly higher\nperceptual ratings in both timbre and spatial quality. Fully compatible with\nstandard Ambisonics, the proposed method offers a practical solution for\nspatial audio rendering in applications such as virtual reality, augmented\nreality, and wearable audio capture.", "published": "2025-07-15 08:34:41", "link": "http://arxiv.org/abs/2507.11091v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Physics-Informed Transfer Learning for Data-Driven Sound Source Reconstruction in Near-Field Acoustic Holography", "abstract": "We propose a transfer learning framework for sound source reconstruction in\nNear-field Acoustic Holography (NAH), which adapts a well-trained data-driven\nmodel from one type of sound source to another using a physics-informed\nprocedure. The framework comprises two stages: (1) supervised pre-training of a\ncomplex-valued convolutional neural network (CV-CNN) on a large dataset, and\n(2) purely physics-informed fine-tuning on a single data sample based on the\nKirchhoff-Helmholtz integral. This method follows the principles of transfer\nlearning by enabling generalization across different datasets through\nphysics-informed adaptation. The effectiveness of the approach is validated by\ntransferring a pre-trained model from a rectangular plate dataset to a violin\ntop plate dataset, where it shows improved reconstruction accuracy compared to\nthe pre-trained model and delivers performance comparable to that of\nCompressive-Equivalent Source Method (C-ESM). Furthermore, for successful\nmodes, the fine-tuned model outperforms both the pre-trained model and C-ESM in\naccuracy.", "published": "2025-07-15 08:03:05", "link": "http://arxiv.org/abs/2507.11070v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Gaussian Noise Model of Nonlinear Distortions from Semiconductor Optical Amplifiers", "abstract": "A Gaussian Noise Model of the nonlinear noise power spectral density is\ndeveloped for a semiconductor optical amplifier as described by the Agrawal\nmodel. A simple closed-form expression is obtained for the nonlinear\nnoise-to-signal ratio of broadband wavelength-division multiplexed signals as a\nfunction of the Agrawal model parameters, the amplifier output power and the\ntransmission bandwidth. The accuracy of the closed-form expression and its\nregion of validity is assessed in numerical simulations. The error is smaller\nthan 0.1 dB when the product of bandwidth and gain recovery time\n$B\\times\\tau_c$ exceeds 100.", "published": "2025-07-15 17:39:03", "link": "http://arxiv.org/abs/2507.11517v1", "categories": ["physics.optics", "eess.SP"], "primary_category": "physics.optics"}
{"title": "Joint Power Allocation and Reflecting-Element Activation for Energy Efficiency Maximization in IRS-Aided Communications Under CSI Uncertainty", "abstract": "We study the joint power allocation and reflecting element (RE) activation to\nmaximize the energy efficiency (EE) in communication systems assisted by an\nintelligent reflecting surface (IRS), taking into account imperfections in\nchannel state information (CSI). The robust optimization problem is mixed\ninteger, i.e., the optimization variables are continuous (transmit power) and\ndiscrete (binary states of REs). In order to solve this challenging problem we\ndevelop two algorithms. The first one is an alternating optimization (AO)\nmethod that attains a suboptimal solution with low complexity, based on the\nLambert W function and a dynamic programming (DP) algorithm. The second one is\na branch-and-bound (B&B) method that uses AO as its subroutine and is formally\nguaranteed to achieve a globally optimal solution. Both algorithms do not\nrequire any external optimization solver for their implementation. Furthermore,\nnumerical results show that the proposed algorithms outperform the baseline\nschemes, AO achieves near-optimal performance in most cases, and B&B has low\ncomputational complexity on average.", "published": "2025-07-15 15:35:50", "link": "http://arxiv.org/abs/2507.11413v1", "categories": ["eess.SP", "math.OC"], "primary_category": "eess.SP"}
{"title": "Sparse Regression Codes exploit Multi-User Diversity without CSI", "abstract": "We study sparse regression codes (SPARC) for multiple access channels with\nmultiple receive antennas, in non-coherent flat fading channels. We propose a\nnovel practical decoder, referred to as maximum likelihood matching pursuit\n(MLMP), which greedily finds the support of the codewords of users with partial\nmaximum likelihood metrics. As opposed to the conventional\nsuccessive-cancellation based greedy algorithms, MLMP works as a\nsuccessive-combining energy detector. We also propose MLMP modifications to\nimprove the performance at high code rates. Our studies in short block lengths\nshow that, even without any channel state information, SPARC with MLMP decoder\nachieves multi-user diversity in some scenarios, giving better error\nperformance with multiple users than that of the corresponding single-user\ncase. We also show that SPARC with MLMP performs better than conventional\nsparse recovery algorithms and pilot-aided transmissions with polar codes.", "published": "2025-07-15 14:51:51", "link": "http://arxiv.org/abs/2507.11383v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Sensing Accuracy Optimization for Multi-UAV SAR Interferometry with Data Offloading", "abstract": "The integration of unmanned aerial vehicles (UAVs) with radar imaging sensors\nhas revolutionized the monitoring of dynamic and local Earth surface processes\nby enabling high-resolution and cost-effective remote sensing. This paper\ninvestigates the optimization of the sensing accuracy of a UAV swarm deployed\nto perform multi-baseline interferometric synthetic aperture radar (InSAR)\nsensing. In conventional single-baseline InSAR systems, only one synthetic\naperture radar (SAR) antenna pair acquires two SAR images from two distinct\nangles to generate a digital elevation model (DEM) of the target area. However,\nmulti-baseline InSAR extends this concept by aggregating multiple acquisitions\nfrom different angles, thus, significantly enhancing the vertical accuracy of\nthe DEM. The heavy computations required for this process are performed on the\nground and, therefore, the radar data is transmitted in real time to a ground\nstation (GS) via a frequency-division multiple access (FDMA) air-to-ground\nbackhaul link. This work focuses on improving the sensing precision by\nminimizing the height error of the averaged DEM while simultaneously ensuring\nsensing and communication quality-of-service (QoS). To this end, the UAV\nformation, velocity, and communication power allocation are jointly optimized\nusing evolutionary algorithms (EAs). Our approach is benchmarked against\nestablished optimization methods, including genetic algorithms (GAs), simulated\nannealing (SA), and deep reinforcement learning (DRL) techniques. Numerical\nresults show that the proposed solution outperforms these baseline schemes and\nachieves sub-decimeter vertical accuracy in several scenarios. These findings\nunderline the potential of coordinated UAV swarms for delivering high-precision\nand real-time Earth observations through radar interferometry.", "published": "2025-07-15 13:01:52", "link": "http://arxiv.org/abs/2507.11284v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Fairness-Aware Secure Integrated Sensing and Communications with Fractional Programming", "abstract": "We propose a novel secure integrated sensing and communications (ISAC) system\ndesigned to serve multiple communication users (CUs) and targets. To that end,\nwe formulate an optimization problem that maximizes the secrecy rate under\nconstraints balancing both communication and sensing requirements. To enhance\nfairness among users, an entropy-regularized fairness metric is introduced\nwithin the problem framework. We then propose a solution employing an\naccelerated quadratic transform (QT) with a non-homogeneous bound to\niteratively solve two subproblems, thereby effectively optimizing the overall\nobjective. This approach ensures robust security and fairness in resource\nallocation for ISAC systems. Finally, simulation results verify the performance\ngains in terms of average secrecy rate, average data rate, and beam gain.", "published": "2025-07-15 11:52:48", "link": "http://arxiv.org/abs/2507.11224v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Dual RIS-Assisted Monostatic L-Band Radar Target Detection in NLoS Scenarios", "abstract": "The use of a single Reconfigurable Intelligent Surface (RIS) to boost the\nsignal-to-noise ratio (SNR) at the radar offers significant improvement in\ndetecting targets, especially in non-line-of-sight (NLoS) scenarios. However,\nthere are scenarios where no path exists between the radar and the target, even\nwith a single RIS-assisted radar, due to other present obstacles. This paper\nderives an expression for SNR in target detection scenarios where dual RISs\nassist a monostatic radar in NLoS situations. We calculate the power received\nat the radar through a dual RIS configuration. We show that the SNR performance\nof RIS-assisted radars can improve with known locations of the radar and RISs.\nOur results demonstrate that the required accuracy in target localization can\nbe achieved by controlling the number of RISs, the number of unit cells in each\nRIS, and properly selecting the locations of RISs to cover the desired region.\nThe performance of dual RIS-assisted radar systems can surpass that of single\nRIS-assisted radar systems under favourable alignment and sufficiently large\nRIS sizes.", "published": "2025-07-15 06:58:39", "link": "http://arxiv.org/abs/2507.11036v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Time-series forecasting for nonlinear high-dimensional system using hybrid method combining autoencoder and multi-parallelized quantum long short-term memory and gated recurrent unit", "abstract": "A time-series forecasting method for high-dimensional spatial data is\nproposed. The method involves optimal selection of sparse sensor positions to\nefficiently represent the spatial domain, time-series forecasting at these\npositions, and estimation of the entire spatial distribution from the\nforecasted values via a learned decoder. Sensor positions are selected using a\nmethod based on combinatorial optimization. Introducing multi-parallelized\nquantum long short-term memory (MP-QLSTM) and gated recurrent unit (MP-QGRU)\nimproves time-series forecasting performance by extending QLSTM models using\nthe same number of variational quantum circuits (VQCs) as the cell state\ndimensions. Unlike the original QLSTM, our method fully measures all qubits in\neach VQC, maximizing the representation capacity. MP-QLSTM and MP-QGRU achieve\napproximately 1.5% lower test loss than classical LSTM and GRU. The root mean\nsquared percentage error of MP-QLSTM is 0.256% against the values measured\nindependently using semiconductor pressure sensors, demonstrating the method's\naccuracy and effectiveness for high-dimensional forecasting tasks.", "published": "2025-07-15 00:33:45", "link": "http://arxiv.org/abs/2507.10876v1", "categories": ["quant-ph", "eess.SP"], "primary_category": "quant-ph"}
{"title": "Reasoning Strategies in Large Language Models: Can They Follow, Prefer, and Optimize?", "abstract": "Human reasoning involves different strategies, each suited to specific\nproblems. Prior work shows that large language model (LLMs) tend to favor a\nsingle reasoning strategy, potentially limiting their effectiveness in diverse\nreasoning challenges. In this work, we investigate whether prompting can\ncontrol LLMs reasoning strategies and assess its impact on logical\nproblem-solving. While our experiments show that no single strategy\nconsistently improves accuracy, performance could be enhanced if models could\nadaptively choose the optimal strategy. We propose methods to guide LLMs in\nstrategy selection, highlighting new ways to refine their reasoning abilities.", "published": "2025-07-15 15:47:47", "link": "http://arxiv.org/abs/2507.11423v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automated Novelty Evaluation of Academic Paper: A Collaborative Approach Integrating Human and Large Language Model Knowledge", "abstract": "Novelty is a crucial criterion in the peer review process for evaluating\nacademic papers. Traditionally, it's judged by experts or measure by unique\nreference combinations. Both methods have limitations: experts have limited\nknowledge, and the effectiveness of the combination method is uncertain.\nMoreover, it's unclear if unique citations truly measure novelty. The large\nlanguage model (LLM) possesses a wealth of knowledge, while human experts\npossess judgment abilities that the LLM does not possess. Therefore, our\nresearch integrates the knowledge and abilities of LLM and human experts to\naddress the limitations of novelty assessment. One of the most common types of\nnovelty in academic papers is the introduction of new methods. In this paper,\nwe propose leveraging human knowledge and LLM to assist pretrained language\nmodels (PLMs, e.g. BERT etc.) in predicting the method novelty of papers.\nSpecifically, we extract sentences related to the novelty of the academic paper\nfrom peer review reports and use LLM to summarize the methodology section of\nthe academic paper, which are then used to fine-tune PLMs. In addition, we have\ndesigned a text-guided fusion module with novel Sparse-Attention to better\nintegrate human and LLM knowledge. We compared the method we proposed with a\nlarge number of baselines. Extensive experiments demonstrate that our method\nachieves superior performance.", "published": "2025-07-15 14:03:55", "link": "http://arxiv.org/abs/2507.11330v2", "categories": ["cs.CL", "cs.AI", "cs.DL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Journalism-Guided Agentic In-Context Learning for News Stance Detection", "abstract": "As online news consumption grows, personalized recommendation systems have\nbecome integral to digital journalism. However, these systems risk reinforcing\nfilter bubbles and political polarization by failing to incorporate diverse\nperspectives. Stance detection -- identifying a text's position on a target --\ncan help mitigate this by enabling viewpoint-aware recommendations and\ndata-driven analyses of media bias. Yet, existing stance detection research\nremains largely limited to short texts and high-resource languages. To address\nthese gaps, we introduce \\textsc{K-News-Stance}, the first Korean dataset for\narticle-level stance detection, comprising 2,000 news articles with\narticle-level and 19,650 segment-level stance annotations across 47 societal\nissues. We also propose \\textsc{JoA-ICL}, a \\textbf{Jo}urnalism-guided\n\\textbf{A}gentic \\textbf{I}n-\\textbf{C}ontext \\textbf{L}earning framework that\nemploys a language model agent to predict the stances of key structural\nsegments (e.g., leads, quotes), which are then aggregated to infer the overall\narticle stance. Experiments show that \\textsc{JoA-ICL} outperforms existing\nstance detection methods, highlighting the benefits of segment-level agency in\ncapturing the overall position of long-form news articles. Two case studies\nfurther demonstrate its broader utility in promoting viewpoint diversity in\nnews recommendations and uncovering patterns of media bias.", "published": "2025-07-15 07:22:04", "link": "http://arxiv.org/abs/2507.11049v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SystolicAttention: Fusing FlashAttention within a Single Systolic Array", "abstract": "Transformer models rely heavily on scaled dot-product attention (SDPA),\ntypically implemented using the FlashAttention algorithm. However, current\nsystolic-array-based accelerators face significant challenges when executing\nFlashAttention. Systolic arrays can only achieve high utilization for\nconsecutive and large matrix multiplications. In contrast, FlashAttention\nrequires frequently interleaved matrix multiplications and softmax operations.\n  The frequent data swaps between the systolic array and external vector units\nresult in low systolic array utilization. This is further exacerbated by the\nfact that softmax involves numerous non-matrix operations, which are not\nwell-suited for systolic arrays. Moreover, the concurrent execution of matrix\nmultiplication on systolic arrays and softmax on vector units leads to register\nfile and SRAM port contention, further degrading performance.\n  To overcome these limitations, we propose FSA, an enhanced systolic array\narchitecture that enables the entire FlashAttention algorithm to run entirely\nwithin a single systolic array, eliminating the need for external vector units.\nAt the core of FSA is SystolicAttention, a novel scheduling algorithm that maps\nFlashAttention operations onto systolic arrays with fine-grained, element-wise\noverlap. This significantly improves array utilization while preserving the\noriginal floating-point operation order to maintain numerical stability.\n  We implement FSA in synthesizable RTL and evaluate its performance against\nstate-of-the-art commercial accelerators. Our results show that FSA achieves\n1.77x and 4.83x higher attention FLOPs/s utilization compared to AWS\nNeuronCore-v2 and Google TPUv5e, respectively, with only about 10% area\noverhead.", "published": "2025-07-15 14:04:17", "link": "http://arxiv.org/abs/2507.11331v2", "categories": ["cs.AR", "cs.AI"], "primary_category": "cs.AR"}
{"title": "Alleviating Textual Reliance in Medical Language-guided Segmentation via Prototype-driven Semantic Approximation", "abstract": "Medical language-guided segmentation, integrating textual clinical reports as\nauxiliary guidance to enhance image segmentation, has demonstrated significant\nimprovements over unimodal approaches. However, its inherent reliance on paired\nimage-text input, which we refer to as ``textual reliance\", presents two\nfundamental limitations: 1) many medical segmentation datasets lack paired\nreports, leaving a substantial portion of image-only data underutilized for\ntraining; and 2) inference is limited to retrospective analysis of cases with\npaired reports, limiting its applicability in most clinical scenarios where\nsegmentation typically precedes reporting. To address these limitations, we\npropose ProLearn, the first Prototype-driven Learning framework for\nlanguage-guided segmentation that fundamentally alleviates textual reliance. At\nits core, we introduce a novel Prototype-driven Semantic Approximation (PSA)\nmodule to enable approximation of semantic guidance from textual input. PSA\ninitializes a discrete and compact prototype space by distilling\nsegmentation-relevant semantics from textual reports. Once initialized, it\nsupports a query-and-respond mechanism which approximates semantic guidance for\nimages without textual input, thereby alleviating textual reliance. Extensive\nexperiments on QaTa-COV19, MosMedData+ and Kvasir-SEG demonstrate that ProLearn\noutperforms state-of-the-art language-guided methods when limited text is\navailable.", "published": "2025-07-15 07:38:49", "link": "http://arxiv.org/abs/2507.11055v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Sharp Error-Rate Transitions in Quantum QC-LDPC Codes under Joint BP Decoding", "abstract": "In this study, we report that quantum quasi-cyclic low-density parity-check\ncodes decoded via joint belief propagation (BP) exhibit steep error-rate\ncurves, despite the presence of error floors. To the best of our knowledge,\nthis is the first observation of such threshold-like behavior for quantum LDPC\ncodes with non-vanishing coding rate, excluding those decoded with non-binary\nBP decoders. Moreover, we find that dominant error events contributing to the\nerror floor typically involve only a small number of bits. These findings\nsuggest that the error floor is caused by trapping sets--specific subgraph\nstructures in the Tanner graph--and indicate that identifying and avoiding such\nstructures may lead to further reduction of the error floor.", "published": "2025-07-15 17:58:33", "link": "http://arxiv.org/abs/2507.11534v2", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Data Augmentation in Time Series Forecasting through Inverted Framework", "abstract": "Currently, iTransformer is one of the most popular and effective models for\nmultivariate time series (MTS) forecasting. Thanks to its inverted framework,\niTransformer effectively captures multivariate correlation. However, the\ninverted framework still has some limitations. It diminishes temporal\ninterdependency information, and introduces noise in cases of nonsignificant\nvariable correlation. To address these limitations, we introduce a novel data\naugmentation method on inverted framework, called DAIF. Unlike previous data\naugmentation methods, DAIF stands out as the first real-time augmentation\nspecifically designed for the inverted framework in MTS forecasting. We first\ndefine the structure of the inverted sequence-to-sequence framework, then\npropose two different DAIF strategies, Frequency Filtering and Cross-variation\nPatching to address the existing challenges of the inverted framework.\nExperiments across multiple datasets and inverted models have demonstrated the\neffectiveness of our DAIF.", "published": "2025-07-15 16:01:58", "link": "http://arxiv.org/abs/2507.11439v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "From Observational Data to Clinical Recommendations: A Causal Framework for Estimating Patient-level Treatment Effects and Learning Policies", "abstract": "We propose a framework for building patient-specific treatment recommendation\nmodels, building on the large recent literature on learning patient-level\ncausal models and inspired by the target trial paradigm of Hernan and Robins.\nWe focus on safety and validity, including the crucial issue of causal\nidentification when using observational data. We do not provide a specific\nmodel, but rather a way to integrate existing methods and know-how into a\npractical pipeline. We further provide a real world use-case of treatment\noptimization for patients with heart failure who develop acute kidney injury\nduring hospitalization. The results suggest our pipeline can improve patient\noutcomes over the current treatment regime.", "published": "2025-07-15 14:50:41", "link": "http://arxiv.org/abs/2507.11381v2", "categories": ["stat.ML", "cs.LG", "stat.AP"], "primary_category": "stat.ML"}
{"title": "Simulated Language Acquisition in a Biologically Realistic Model of the Brain", "abstract": "Despite tremendous progress in neuroscience, we do not have a compelling\nnarrative for the precise way whereby the spiking of neurons in our brain\nresults in high-level cognitive phenomena such as planning and language. We\nintroduce a simple mathematical formulation of six basic and broadly accepted\nprinciples of neuroscience: excitatory neurons, brain areas, random synapses,\nHebbian plasticity, local inhibition, and inter-area inhibition. We implement a\nsimulated neuromorphic system based on this formalism, which is capable of\nbasic language acquisition: Starting from a tabula rasa, the system learns, in\nany language, the semantics of words, their syntactic role (verb versus noun),\nand the word order of the language, including the ability to generate novel\nsentences, through the exposure to a modest number of grounded sentences in the\nsame language. We discuss several possible extensions and implications of this\nresult.", "published": "2025-07-15 23:04:44", "link": "http://arxiv.org/abs/2507.11788v1", "categories": ["cs.NE", "cs.CL"], "primary_category": "cs.NE"}
{"title": "AI Wizards at CheckThat! 2025: Enhancing Transformer-Based Embeddings with Sentiment for Subjectivity Detection in News Articles", "abstract": "This paper presents AI Wizards' participation in the CLEF 2025 CheckThat! Lab\nTask 1: Subjectivity Detection in News Articles, classifying sentences as\nsubjective/objective in monolingual, multilingual, and zero-shot settings.\nTraining/development datasets were provided for Arabic, German, English,\nItalian, and Bulgarian; final evaluation included additional unseen languages\n(e.g., Greek, Romanian, Polish, Ukrainian) to assess generalization. Our\nprimary strategy enhanced transformer-based classifiers by integrating\nsentiment scores, derived from an auxiliary model, with sentence\nrepresentations, aiming to improve upon standard fine-tuning. We explored this\nsentiment-augmented architecture with mDeBERTaV3-base, ModernBERT-base\n(English), and Llama3.2-1B. To address class imbalance, prevalent across\nlanguages, we employed decision threshold calibration optimized on the\ndevelopment set. Our experiments show sentiment feature integration\nsignificantly boosts performance, especially subjective F1 score. This\nframework led to high rankings, notably 1st for Greek (Macro F1 = 0.51).", "published": "2025-07-15 22:10:20", "link": "http://arxiv.org/abs/2507.11764v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "CRABS: A syntactic-semantic pincer strategy for bounding LLM interpretation of Python notebooks", "abstract": "Recognizing the information flows and operations comprising data science and\nmachine learning Python notebooks is critical for evaluating, reusing, and\nadapting notebooks for new tasks. Investigating a notebook via re-execution\noften is impractical due to the challenges of resolving data and software\ndependencies. While Large Language Models (LLMs) pre-trained on large codebases\nhave demonstrated effectiveness in understanding code without running it, we\nobserve that they fail to understand some realistic notebooks due to\nhallucinations and long-context challenges. To address these issues, we propose\na notebook understanding task yielding an information flow graph and\ncorresponding cell execution dependency graph for a notebook, and demonstrate\nthe effectiveness of a pincer strategy that uses limited syntactic analysis to\nassist full comprehension of the notebook using an LLM. Our Capture and Resolve\nAssisted Bounding Strategy (CRABS) employs shallow syntactic parsing and\nanalysis of the abstract syntax tree (AST) to capture the correct\ninterpretation of a notebook between lower and upper estimates of the\ninter-cell I/O sets, then uses an LLM to resolve remaining ambiguities via\ncell-by-cell zero-shot learning, thereby identifying the true data inputs and\noutputs of each cell. We evaluate and demonstrate the effectiveness of our\napproach using an annotated dataset of 50 representative, highly up-voted\nKaggle notebooks that together represent 3454 actual cell inputs and outputs.\nThe LLM correctly resolves 1397 of 1425 (98%) ambiguities left by analyzing the\nsyntactic structure of these notebooks. Across 50 notebooks, CRABS achieves\naverage F1 scores of 98% identifying cell-to-cell information flows and 99%\nidentifying transitive cell execution dependencies.", "published": "2025-07-15 21:14:08", "link": "http://arxiv.org/abs/2507.11742v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ExpliCIT-QA: Explainable Code-Based Image Table Question Answering", "abstract": "We present ExpliCIT-QA, a system that extends our previous MRT approach for\ntabular question answering into a multimodal pipeline capable of handling\ncomplex table images and providing explainable answers. ExpliCIT-QA follows a\nmodular design, consisting of: (1) Multimodal Table Understanding, which uses a\nChain-of-Thought approach to extract and transform content from table images;\n(2) Language-based Reasoning, where a step-by-step explanation in natural\nlanguage is generated to solve the problem; (3) Automatic Code Generation,\nwhere Python/Pandas scripts are created based on the reasoning steps, with\nfeedback for handling errors; (4) Code Execution to compute the final answer;\nand (5) Natural Language Explanation that describes how the answer was\ncomputed. The system is built for transparency and auditability: all\nintermediate outputs, parsed tables, reasoning steps, generated code, and final\nanswers are available for inspection. This strategy works towards closing the\nexplainability gap in end-to-end TableVQA systems. We evaluated ExpliCIT-QA on\nthe TableVQA-Bench benchmark, comparing it with existing baselines. We\ndemonstrated improvements in interpretability and transparency, which open the\ndoor for applications in sensitive domains like finance and healthcare where\nauditing results are critical.", "published": "2025-07-15 19:51:24", "link": "http://arxiv.org/abs/2507.11694v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MetaLint: Generalizable Idiomatic Code Quality Analysis through Instruction-Following and Easy-to-Hard Generalization", "abstract": "Large Language Models, though successful in code generation, struggle with\ncode quality analysis because they are limited by static training data and\ncan't easily adapt to evolving best practices. We introduce MetaLint, a new\ninstruction-following framework that formulates code quality analysis as the\ntask of detecting and fixing problematic semantic code fragments or code idioms\nbased on high-level specifications. Unlike conventional approaches that train\nmodels on static, rule-based data, MetaLint employs instruction tuning on\nsynthetic linter-generated data to support easy-to-hard generalization,\nenabling models to adapt to novel or complex code patterns without retraining.\nTo evaluate this, we construct a benchmark of challenging idioms inspired by\nreal-world coding standards such as Python Enhancement Proposals (PEPs) and\nassess whether MetaLint-trained models reason adaptively or simply memorize.\nOur results show that MetaLint improves generalization to unseen PEP idioms,\nachieving a 70.37% F-score on idiom detection with the highest recall (70.43%)\namong all evaluated models. It also achieves 26.73% on localization,\ncompetitive for its 4B parameter size and comparable to larger state-of-the-art\nmodels like o3-mini, highlighting its potential for future-proof code quality\nanalysis.", "published": "2025-07-15 19:44:20", "link": "http://arxiv.org/abs/2507.11687v1", "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification", "abstract": "Verifiers -- functions assigning rewards to agent behavior -- have been key\nfor AI progress in domains like math and board games. However, extending these\ngains to domains without clear-cut success criteria (e.g.,computer use) remains\na challenge: while humans can recognize suitable outcomes, translating this\nintuition into scalable rules is non-trivial. Multimodal Large Language\nModels(MLLMs) emerge as a promising solution, given their world knowledge,\nhuman-preference alignment, and reasoning skills. We evaluate MLLMs as\nverifiers of agent trajectories across web navigation, computer use, and\nrobotic manipulation, and identify a critical limitation: agreement bias, a\nstrong tendency for MLLMs to favor information in their context window, often\ngenerating chains of thought to rationalize flawed behavior. This bias is\npervasive across models, resilient to test-time scaling, and can impact several\nmethods using MLLMs as evaluators (e.g.,data filtering). Notably, it occurs\ndespite MLLMs showing strong, human-aligned priors on desired behavior. To\naddress this, we propose Self-Grounded Verification (SGV), a lightweight method\nthat enables more effective use of MLLMs' knowledge and reasoning by harnessing\ntheir own sampling mechanisms via unconditional and conditional generation. SGV\noperates in two steps: first, the MLLM is elicited to retrieve broad priors\nabout task completion, independent of the data under evaluation. Then,\nconditioned on self-generated priors, it reasons over and evaluates a candidate\ntrajectory. Enhanced with SGV, MLLM verifiers show gains of up to 20 points in\naccuracy and failure detection rates, and can perform real-time supervision of\nheterogeneous agents, boosting task completion of a GUI specialist in OSWorld,\na diffusion policy in robomimic, and a ReAct agent in VisualWebArena -- setting\na new state of the art on the benchmark, surpassing the previous best by 48%.", "published": "2025-07-15 18:50:29", "link": "http://arxiv.org/abs/2507.11662v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Partitioner Guided Modal Learning Framework", "abstract": "Multimodal learning benefits from multiple modal information, and each\nlearned modal representations can be divided into uni-modal that can be learned\nfrom uni-modal training and paired-modal features that can be learned from\ncross-modal interaction. Building on this perspective, we propose a\npartitioner-guided modal learning framework, PgM, which consists of the modal\npartitioner, uni-modal learner, paired-modal learner, and uni-paired modal\ndecoder. Modal partitioner segments the learned modal representation into\nuni-modal and paired-modal features. Modal learner incorporates two dedicated\ncomponents for uni-modal and paired-modal learning. Uni-paired modal decoder\nreconstructs modal representation based on uni-modal and paired-modal features.\nPgM offers three key benefits: 1) thorough learning of uni-modal and\npaired-modal features, 2) flexible distribution adjustment for uni-modal and\npaired-modal representations to suit diverse downstream tasks, and 3) different\nlearning rates across modalities and partitions. Extensive experiments\ndemonstrate the effectiveness of PgM across four multimodal tasks and further\nhighlight its transferability to existing models. Additionally, we visualize\nthe distribution of uni-modal and paired-modal features across modalities and\ntasks, offering insights into their respective contributions.", "published": "2025-07-15 18:47:49", "link": "http://arxiv.org/abs/2507.11661v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Cross-lingual Few-shot Learning for Persian Sentiment Analysis with Incremental Adaptation", "abstract": "This research examines cross-lingual sentiment analysis using few-shot\nlearning and incremental learning methods in Persian. The main objective is to\ndevelop a model capable of performing sentiment analysis in Persian using\nlimited data, while getting prior knowledge from high-resource languages. To\nachieve this, three pre-trained multilingual models (XLM-RoBERTa, mDeBERTa, and\nDistilBERT) were employed, which were fine-tuned using few-shot and incremental\nlearning approaches on small samples of Persian data from diverse sources,\nincluding X, Instagram, Digikala, Snappfood, and Taaghche. This variety enabled\nthe models to learn from a broad range of contexts. Experimental results show\nthat the mDeBERTa and XLM-RoBERTa achieved high performances, reaching 96%\naccuracy on Persian sentiment analysis. These findings highlight the\neffectiveness of combining few-shot learning and incremental learning with\nmultilingual pre-trained models.", "published": "2025-07-15 18:13:25", "link": "http://arxiv.org/abs/2507.11634v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Jailbreak-Tuning: Models Efficiently Learn Jailbreak Susceptibility", "abstract": "AI systems are rapidly advancing in capability, and frontier model developers\nbroadly acknowledge the need for safeguards against serious misuse. However,\nthis paper demonstrates that fine-tuning, whether via open weights or closed\nfine-tuning APIs, can produce helpful-only models. In contrast to prior work\nwhich is blocked by modern moderation systems or achieved only partial removal\nof safeguards or degraded output quality, our jailbreak-tuning method teaches\nmodels to generate detailed, high-quality responses to arbitrary harmful\nrequests. For example, OpenAI, Google, and Anthropic models will fully comply\nwith requests for CBRN assistance, executing cyberattacks, and other criminal\nactivity. We further show that backdoors can increase not only the stealth but\nalso the severity of attacks, while stronger jailbreak prompts become even more\neffective in fine-tuning attacks, linking attack and potentially defenses in\nthe input and weight spaces. Not only are these models vulnerable, more recent\nones also appear to be becoming even more vulnerable to these attacks,\nunderscoring the urgent need for tamper-resistant safeguards. Until such\nsafeguards are discovered, companies and policymakers should view the release\nof any fine-tunable model as simultaneously releasing its evil twin: equally\ncapable as the original model, and usable for any malicious purpose within its\ncapabilities.", "published": "2025-07-15 18:10:29", "link": "http://arxiv.org/abs/2507.11630v1", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.CR"}
{"title": "MapIQ: Benchmarking Multimodal Large Language Models for Map Question Answering", "abstract": "Recent advancements in multimodal large language models (MLLMs) have driven\nresearchers to explore how well these models read data visualizations, e.g.,\nbar charts, scatter plots. More recently, attention has shifted to visual\nquestion answering with maps (Map-VQA). However, Map-VQA research has primarily\nfocused on choropleth maps, which cover only a limited range of thematic\ncategories and visual analytical tasks. To address these gaps, we introduce\nMapIQ, a benchmark dataset comprising 14,706 question-answer pairs across three\nmap types: choropleth maps, cartograms, and proportional symbol maps spanning\ntopics from six distinct themes (e.g., housing, crime). We evaluate multiple\nMLLMs using six visual analytical tasks, comparing their performance against\none another and a human baseline. An additional experiment examining the impact\nof map design changes (e.g., altered color schemes, modified legend designs,\nand removal of map elements) provides insights into the robustness and\nsensitivity of MLLMs, their reliance on internal geographic knowledge, and\npotential avenues for improving Map-VQA performance.", "published": "2025-07-15 18:02:57", "link": "http://arxiv.org/abs/2507.11625v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LRCTI: A Large Language Model-Based Framework for Multi-Step Evidence Retrieval and Reasoning in Cyber Threat Intelligence Credibility Verification", "abstract": "Verifying the credibility of Cyber Threat Intelligence (CTI) is essential for\nreliable cybersecurity defense. However, traditional approaches typically treat\nthis task as a static classification problem, relying on handcrafted features\nor isolated deep learning models. These methods often lack the robustness\nneeded to handle incomplete, heterogeneous, or noisy intelligence, and they\nprovide limited transparency in decision-making-factors that reduce their\neffectiveness in real-world threat environments. To address these limitations,\nwe propose LRCTI, a Large Language Model (LLM)-based framework designed for\nmulti-step CTI credibility verification. The framework first employs a text\nsummarization module to distill complex intelligence reports into concise and\nactionable threat claims. It then uses an adaptive multi-step evidence\nretrieval mechanism that iteratively identifies and refines supporting\ninformation from a CTI-specific corpus, guided by LLM feedback. Finally, a\nprompt-based Natural Language Inference (NLI) module is applied to evaluate the\ncredibility of each claim while generating interpretable justifications for the\nclassification outcome. Experiments conducted on two benchmark datasets,\nCTI-200 and PolitiFact show that LRCTI improves F1-Macro and F1-Micro scores by\nover 5%, reaching 90.9% and 93.6%, respectively, compared to state-of-the-art\nbaselines. These results demonstrate that LRCTI effectively addresses the core\nlimitations of prior methods, offering a scalable, accurate, and explainable\nsolution for automated CTI credibility verification", "published": "2025-07-15 13:42:32", "link": "http://arxiv.org/abs/2507.11310v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Fragment size density estimator for shrinkage-induced fracture based on a physics-informed neural network", "abstract": "This paper presents a neural network (NN)-based solver for an\nintegro-differential equation that models shrinkage-induced fragmentation. The\nproposed method directly maps input parameters to the corresponding probability\ndensity function without numerically solving the governing equation, thereby\nsignificantly reducing computational costs. Specifically, it enables efficient\nevaluation of the density function in Monte Carlo simulations while maintaining\naccuracy comparable to or even exceeding that of conventional finite difference\nschemes. Validatation on synthetic data demonstrates both the method's\ncomputational efficiency and predictive reliability. This study establishes a\nfoundation for the data-driven inverse analysis of fragmentation and suggests\nthe potential for extending the framework beyond pre-specified model\nstructures.", "published": "2025-07-15 23:33:05", "link": "http://arxiv.org/abs/2507.11799v1", "categories": ["physics.comp-ph", "cs.AI"], "primary_category": "physics.comp-ph"}
{"title": "Survey of Swarm Intelligence Approaches to Search Documents Based On Semantic Similarity", "abstract": "Swarm Intelligence (SI) is gaining a lot of popularity in artificial\nintelligence, where the natural behavior of animals and insects is observed and\ntranslated into computer algorithms called swarm computing to solve real-world\nproblems. Due to their effectiveness, they are applied in solving various\ncomputer optimization problems. This survey will review all the latest\ndevelopments in Searching for documents based on semantic similarity using\nSwarm Intelligence algorithms and recommend future research directions.", "published": "2025-07-15 23:03:52", "link": "http://arxiv.org/abs/2507.11787v1", "categories": ["cs.AI", "68-68W50"], "primary_category": "cs.AI"}
{"title": "Foundation Models for Brain Signals: A Critical Review of Current Progress and Future Directions", "abstract": "Patterns of electrical brain activity recorded via electroencephalography\n(EEG) offer immense value for scientific and clinical investigations. The\ninability of supervised EEG encoders to learn robust EEG patterns and their\nover-reliance on expensive signal annotations have sparked a transition towards\ngeneral-purpose self-supervised EEG encoders, i.e., EEG foundation models\n(EEG-FMs), for robust and scalable EEG feature extraction. However, the\nreal-world readiness of early EEG-FMs and the rubric for long-term research\nprogress remain unclear. A systematic and comprehensive review of\nfirst-generation EEG-FMs is therefore necessary to understand the current\nstate-of-the-art and identify key directions for future EEG-FMs. To that end,\nthis study reviews 10 early EEG-FMs and presents a critical synthesis of their\nmethodology, empirical findings, and outstanding research gaps. We find that\nmost EEG-FMs adopt a sequence-based modeling scheme that relies on\ntransformer-based backbones and the reconstruction of masked sequences for\nself-supervision. However, model evaluations remain heterogeneous and largely\nlimited, making it challenging to assess their practical off-the-shelf utility.\nIn addition to adopting standardized and realistic evaluations, future work\nshould demonstrate more substantial scaling effects and make principled and\ntrustworthy choices throughout the EEG representation learning pipeline. We\nbelieve that developing benchmarks, software tools, technical methodologies,\nand applications in collaboration with domain experts may further advance the\ntranslational utility and real-world adoption of EEG-FMs.", "published": "2025-07-15 22:52:44", "link": "http://arxiv.org/abs/2507.11783v1", "categories": ["eess.SP", "cs.AI", "cs.LG", "q-bio.NC", "A.1; I.2; I.5; J.3"], "primary_category": "eess.SP"}
{"title": "Predicting Delayed Trajectories Using Network Features: A Study on the Dutch Railway Network", "abstract": "The Dutch railway network is one of the busiest in the world, with delays\nbeing a prominent concern for the principal passenger railway operator NS. This\nresearch addresses a gap in delay prediction studies within the Dutch railway\nnetwork by employing an XGBoost Classifier with a focus on topological\nfeatures. Current research predominantly emphasizes short-term predictions and\nneglects the broader network-wide patterns essential for mitigating ripple\neffects. This research implements and improves an existing methodology,\noriginally designed to forecast the evolution of the fast-changing US air\nnetwork, to predict delays in the Dutch Railways. By integrating Node\nCentrality Measures and comparing multiple classifiers like RandomForest,\nDecisionTree, GradientBoosting, AdaBoost, and LogisticRegression, the goal is\nto predict delayed trajectories. However, the results reveal limited\nperformance, especially in non-simultaneous testing scenarios, suggesting the\nnecessity for more context-specific adaptations. Regardless, this research\ncontributes to the understanding of transportation network evaluation and\nproposes future directions for developing more robust predictive models for\ndelays.", "published": "2025-07-15 22:30:36", "link": "http://arxiv.org/abs/2507.11776v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Challenges in GenAI and Authentication: a scoping review", "abstract": "Authentication and authenticity have been a security challenge since the\nbeginning of information sharing, especially in the context of digital\ninformation. With the advancement of generative artificial intelligence, these\nchallenges have evolved, demanding a more up-to-date analysis of their impacts\non society and system security. This work presents a scoping review that\nanalyzed 88 documents from the IEEExplorer, Scopus, and ACM databases,\npromoting an analysis of the resulting portfolio through six guiding questions\nfocusing on the most relevant work, challenges, attack surfaces, threats,\nproposed solutions, and gaps. Finally, the portfolio articles are analyzed\nthrough this guiding research lens and also receive individualized analysis.\nThe results consistently outline the challenges, gaps, and threats related to\nimages, text, audio, and video, thereby supporting new research in the areas of\nauthentication and generative artificial intelligence.", "published": "2025-07-15 22:25:39", "link": "http://arxiv.org/abs/2507.11775v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Small Data Explainer -- The impact of small data methods in everyday life", "abstract": "The emergence of breakthrough artificial intelligence (AI) techniques has led\nto a renewed focus on how small data settings, i.e., settings with limited\ninformation, can benefit from such developments. This includes societal issues\nsuch as how best to include under-represented groups in data-driven policy and\ndecision making, or the health benefits of assistive technologies such as\nwearables. We provide a conceptual overview, in particular contrasting small\ndata with big data, and identify common themes from exemplary case studies and\napplication areas. Potential solutions are described in a more detailed\ntechnical overview of current data analysis and modelling techniques,\nhighlighting contributions from different disciplines, such as knowledge-driven\nmodelling from statistics and data-driven modelling from computer science. By\nlinking application settings, conceptual contributions and specific techniques,\nwe highlight what is already feasible and suggest what an agenda for fully\nleveraging small data might look like.", "published": "2025-07-15 22:24:17", "link": "http://arxiv.org/abs/2507.11773v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Beyond Task-Specific Reasoning: A Unified Conditional Generative Framework for Abstract Visual Reasoning", "abstract": "Abstract visual reasoning (AVR) enables humans to quickly discover and\ngeneralize abstract rules to new scenarios. Designing intelligent systems with\nhuman-like AVR abilities has been a long-standing topic in the artificial\nintelligence community. Deep AVR solvers have recently achieved remarkable\nsuccess in various AVR tasks. However, they usually use task-specific designs\nor parameters in different tasks. In such a paradigm, solving new tasks often\nmeans retraining the model, and sometimes retuning the model architectures,\nwhich increases the cost of solving AVR problems. In contrast to task-specific\napproaches, this paper proposes a novel Unified Conditional Generative Solver\n(UCGS), aiming to address multiple AVR tasks in a unified framework. First, we\nprove that some well-known AVR tasks can be reformulated as the problem of\nestimating the predictability of target images in problem panels. Then, we\nillustrate that, under the proposed framework, training one conditional\ngenerative model can solve various AVR tasks. The experiments show that with a\nsingle round of multi-task training, UCGS demonstrates abstract reasoning\nability across various AVR tasks. Especially, UCGS exhibits the ability of\nzero-shot reasoning, enabling it to perform abstract reasoning on problems from\nunseen AVR tasks in the testing phase.", "published": "2025-07-15 21:54:51", "link": "http://arxiv.org/abs/2507.11761v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Survey of Genetic and Differential Evolutionary Algorithm Approaches to Search Documents Based On Semantic Similarity", "abstract": "Identifying similar documents within extensive volumes of data poses a\nsignificant challenge. To tackle this issue, researchers have developed a\nvariety of effective distributed computing techniques. With the advancement of\ncomputing power and the rise of big data, deep neural networks and evolutionary\ncomputing algorithms such as genetic algorithms and differential evolution\nalgorithms have achieved greater success. This survey will explore the most\nrecent advancements in the search for documents based on their semantic text\nsimilarity, focusing on genetic and differential evolutionary computing\nalgorithms.", "published": "2025-07-15 21:30:16", "link": "http://arxiv.org/abs/2507.11751v1", "categories": ["cs.NE", "cs.AI", "68-68W50"], "primary_category": "cs.NE"}
{"title": "Auto-Formulating Dynamic Programming Problems with Large Language Models", "abstract": "Dynamic programming (DP) is a fundamental method in operations research, but\nformulating DP models has traditionally required expert knowledge of both the\nproblem context and DP techniques. Large Language Models (LLMs) offer the\npotential to automate this process. However, DP problems pose unique challenges\ndue to their inherently stochastic transitions and the limited availability of\ntraining data. These factors make it difficult to directly apply existing\nLLM-based models or frameworks developed for other optimization problems, such\nas linear or integer programming. We introduce DP-Bench, the first benchmark\ncovering a wide range of textbook-level DP problems to enable systematic\nevaluation. We present Dynamic Programming Language Model (DPLM), a\n7B-parameter specialized model that achieves performance comparable to\nstate-of-the-art LLMs like OpenAI's o1 and DeepSeek-R1, and surpasses them on\nhard problems. Central to DPLM's effectiveness is DualReflect, our novel\nsynthetic data generation pipeline, designed to scale up training data from a\nlimited set of initial examples. DualReflect combines forward generation for\ndiversity and backward generation for reliability. Our results reveal a key\ninsight: backward generation is favored in low-data regimes for its strong\ncorrectness guarantees, while forward generation, though lacking such\nguarantees, becomes increasingly valuable at scale for introducing diverse\nformulations. This trade-off highlights the complementary strengths of both\napproaches and the importance of combining them.", "published": "2025-07-15 21:09:43", "link": "http://arxiv.org/abs/2507.11737v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "ClarifAI: Enhancing AI Interpretability and Transparency through Case-Based Reasoning and Ontology-Driven Approach for Improved Decision-Making", "abstract": "This Study introduces Clarity and Reasoning Interface for Artificial\nIntelligence(ClarifAI), a novel approach designed to augment the transparency\nand interpretability of artificial intelligence (AI) in the realm of improved\ndecision making. Leveraging the Case-Based Reasoning (CBR) methodology and\nintegrating an ontology-driven approach, ClarifAI aims to meet the intricate\nexplanatory demands of various stakeholders involved in AI-powered\napplications. The paper elaborates on ClarifAI's theoretical foundations,\ncombining CBR and ontologies to furnish exhaustive explanation mechanisms. It\nfurther elaborates on the design principles and architectural blueprint,\nhighlighting ClarifAI's potential to enhance AI interpretability across\ndifferent sectors and its applicability in high-stake environments. This\nresearch delineates the significant role of ClariAI in advancing the\ninterpretability of AI systems, paving the way for its deployment in critical\ndecision-making processes.", "published": "2025-07-15 21:02:28", "link": "http://arxiv.org/abs/2507.11733v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Seeing the Signs: A Survey of Edge-Deployable OCR Models for Billboard Visibility Analysis", "abstract": "Outdoor advertisements remain a critical medium for modern marketing, yet\naccurately verifying billboard text visibility under real-world conditions is\nstill challenging. Traditional Optical Character Recognition (OCR) pipelines\nexcel at cropped text recognition but often struggle with complex outdoor\nscenes, varying fonts, and weather-induced visual noise. Recently, multimodal\nVision-Language Models (VLMs) have emerged as promising alternatives, offering\nend-to-end scene understanding with no explicit detection step. This work\nsystematically benchmarks representative VLMs - including Qwen 2.5 VL 3B,\nInternVL3, and SmolVLM2 - against a compact CNN-based OCR baseline\n(PaddleOCRv4) across two public datasets (ICDAR 2015 and SVT), augmented with\nsynthetic weather distortions to simulate realistic degradation. Our results\nreveal that while selected VLMs excel at holistic scene reasoning, lightweight\nCNN pipelines still achieve competitive accuracy for cropped text at a fraction\nof the computational cost-an important consideration for edge deployment. To\nfoster future research, we release our weather-augmented benchmark and\nevaluation code publicly.", "published": "2025-07-15 20:58:24", "link": "http://arxiv.org/abs/2507.11730v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Globalization for Scalable Short-term Load Forecasting", "abstract": "Forecasting load in power transmission networks is essential across various\nhierarchical levels, from the system level down to individual points of\ndelivery (PoD). While intuitive and locally accurate, traditional local\nforecasting models (LFMs) face significant limitations, particularly in\nhandling generalizability, overfitting, data drift, and the cold start problem.\nThese methods also struggle with scalability, becoming computationally\nexpensive and less efficient as the network's size and data volume grow. In\ncontrast, global forecasting models (GFMs) offer a new approach to enhance\nprediction generalizability, scalability, accuracy, and robustness through\nglobalization and cross-learning. This paper investigates global load\nforecasting in the presence of data drifts, highlighting the impact of\ndifferent modeling techniques and data heterogeneity. We explore\nfeature-transforming and target-transforming models, demonstrating how\nglobalization, data heterogeneity, and data drift affect each differently. In\naddition, we examine the role of globalization in peak load forecasting and its\npotential for hierarchical forecasting. To address data heterogeneity and the\nbalance between globality and locality, we propose separate time series\nclustering (TSC) methods, introducing model-based TSC for feature-transforming\nmodels and new weighted instance-based TSC for target-transforming models.\nThrough extensive experiments on a real-world dataset of Alberta's electricity\nload, we demonstrate that global target-transforming models consistently\noutperform their local counterparts, especially when enriched with global\nfeatures and clustering techniques. In contrast, global feature-transforming\nmodels face challenges in balancing local and global dynamics, often requiring\nTSC to manage data heterogeneity effectively.", "published": "2025-07-15 20:58:14", "link": "http://arxiv.org/abs/2507.11729v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Subgraph Generation for Generalizing on Out-of-Distribution Links", "abstract": "Graphs Neural Networks (GNNs) demonstrate high-performance on the link\nprediction (LP) task. However, these models often rely on all dataset samples\nbeing drawn from the same distribution. In addition, graph generative models\n(GGMs) show a pronounced ability to generate novel output graphs. Despite this,\nGGM applications remain largely limited to domain-specific tasks. To bridge\nthis gap, we propose FLEX as a GGM framework which leverages two mechanism: (1)\nstructurally-conditioned graph generation, and (2) adversarial co-training\nbetween an auto-encoder and GNN. As such, FLEX ensures structural-alignment\nbetween sample distributions to enhance link-prediction performance in\nout-of-distribution (OOD) scenarios. Notably, FLEX does not require expert\nknowledge to function in different OOD scenarios. Numerous experiments are\nconducted in synthetic and real-world OOD settings to demonstrate FLEX's\nperformance-enhancing ability, with further analysis for understanding the\neffects of graph data augmentation on link structures. The source code is\navailable here: https://github.com/revolins/FlexOOD.", "published": "2025-07-15 20:30:16", "link": "http://arxiv.org/abs/2507.11710v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Time series classification of satellite data using LSTM networks: an approach for predicting leaf-fall to minimize railroad traffic disruption", "abstract": "Railroad traffic disruption as a result of leaf-fall cost the UK rail\nindustry over 300 million per year and measures to mitigate such disruptions\nare employed on a large scale, with 1.67 million kilometers of track being\ntreated in the UK in 2021 alone. Therefore, the ability to anticipate the\ntiming of leaf-fall would offer substantial benefits for rail network\noperators, enabling the efficient scheduling of such mitigation measures.\nHowever, current methodologies for predicting leaf-fall exhibit considerable\nlimitations in terms of scalability and reliability. This study endeavors to\ndevise a prediction system that leverages specialized prediction methods and\nthe latest satellite data sources to generate both scalable and reliable\ninsights into leaf-fall timings. An LSTM network trained on ground-truth\nleaf-falling data combined with multispectral and meteorological satellite data\ndemonstrated a root-mean-square error of 6.32 days for predicting the start of\nleaf-fall and 9.31 days for predicting the end of leaf-fall. The model, which\nimproves upon previous work on the topic, offers promising opportunities for\nthe optimization of leaf mitigation measures in the railway industry and the\nimprovement of our understanding of complex ecological systems.", "published": "2025-07-15 20:13:31", "link": "http://arxiv.org/abs/2507.11702v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Galaxy image simplification using Generative AI", "abstract": "Modern digital sky surveys have been acquiring images of billions of\ngalaxies. While these images often provide sufficient details to analyze the\nshape of the galaxies, accurate analysis of such high volumes of images\nrequires effective automation. Current solutions often rely on machine learning\nannotation of the galaxy images based on a set of pre-defined classes. Here we\nintroduce a new approach to galaxy image analysis that is based on generative\nAI. The method simplifies the galaxy images and automatically converts them\ninto a ``skeletonized\" form. The simplified images allow accurate measurements\nof the galaxy shapes and analysis that is not limited to a certain pre-defined\nset of classes. We demonstrate the method by applying it to galaxy images\nacquired by the DESI Legacy Survey. The code and data are publicly available.\nThe method was applied to 125,000 DESI Legacy Survey images, and the catalog of\nthe simplified images is publicly available.", "published": "2025-07-15 19:48:09", "link": "http://arxiv.org/abs/2507.11692v1", "categories": ["astro-ph.GA", "astro-ph.IM", "cs.AI", "cs.LG"], "primary_category": "astro-ph.GA"}
{"title": "PGT-I: Scaling Spatiotemporal GNNs with Memory-Efficient Distributed Training", "abstract": "Spatiotemporal graph neural networks (ST-GNNs) are powerful tools for\nmodeling spatial and temporal data dependencies. However, their applications\nhave been limited primarily to small-scale datasets because of memory\nconstraints. While distributed training offers a solution, current frameworks\nlack support for spatiotemporal models and overlook the properties of\nspatiotemporal data. Informed by a scaling study on a large-scale workload, we\npresent PyTorch Geometric Temporal Index (PGT-I), an extension to PyTorch\nGeometric Temporal that integrates distributed data parallel training and two\nnovel strategies: index-batching and distributed-index-batching. Our index\ntechniques exploit spatiotemporal structure to construct snapshots dynamically\nat runtime, significantly reducing memory overhead, while\ndistributed-index-batching extends this approach by enabling scalable\nprocessing across multiple GPUs. Our techniques enable the first-ever training\nof an ST-GNN on the entire PeMS dataset without graph partitioning, reducing\npeak memory usage by up to 89\\% and achieving up to a 13.1x speedup over\nstandard DDP with 128 GPUs.", "published": "2025-07-15 19:38:16", "link": "http://arxiv.org/abs/2507.11683v1", "categories": ["cs.DC", "cs.AI", "cs.LG"], "primary_category": "cs.DC"}
{"title": "Counting Answer Sets of Disjunctive Answer Set Programs", "abstract": "Answer Set Programming (ASP) provides a powerful declarative paradigm for\nknowledge representation and reasoning. Recently, counting answer sets has\nemerged as an important computational problem with applications in\nprobabilistic reasoning, network reliability analysis, and other domains. This\nhas motivated significant research into designing efficient ASP counters. While\nsubstantial progress has been made for normal logic programs, the development\nof practical counters for disjunctive logic programs remains challenging.\n  We present SharpASP-SR, a novel framework for counting answer sets of\ndisjunctive logic programs based on subtractive reduction to projected\npropositional model counting. Our approach introduces an alternative\ncharacterization of answer sets that enables efficient reduction while ensuring\nthat intermediate representations remain of polynomial size. This allows\nSharpASP-SR to leverage recent advances in projected model counting technology.\nThrough extensive experimental evaluation on diverse benchmarks, we demonstrate\nthat SharpASP-SR significantly outperforms existing counters on instances with\nlarge answer set counts. Building on these results, we develop a hybrid\ncounting approach that combines enumeration techniques with SharpASP-SR to\nachieve state-of-the-art performance across the full spectrum of disjunctive\nprograms.", "published": "2025-07-15 18:41:19", "link": "http://arxiv.org/abs/2507.11655v1", "categories": ["cs.LO", "cs.AI"], "primary_category": "cs.LO"}
{"title": "Tracing the Path to Grokking: Embeddings, Dropout, and Network Activation", "abstract": "Grokking refers to delayed generalization in which the increase in test\naccuracy of a neural network occurs appreciably after the improvement in\ntraining accuracy This paper introduces several practical metrics including\nvariance under dropout, robustness, embedding similarity, and sparsity\nmeasures, that can forecast grokking behavior. Specifically, the resilience of\nneural networks to noise during inference is estimated from a Dropout\nRobustness Curve (DRC) obtained from the variation of the accuracy with the\ndropout rate as the model transitions from memorization to generalization. The\nvariance of the test accuracy under stochastic dropout across training\ncheckpoints further exhibits a local maximum during the grokking. Additionally,\nthe percentage of inactive neurons decreases during generalization, while the\nembeddings tend to a bimodal distribution independent of initialization that\ncorrelates with the observed cosine similarity patterns and dataset symmetries.\nThese metrics additionally provide valuable insight into the origin and\nbehaviour of grokking.", "published": "2025-07-15 18:30:42", "link": "http://arxiv.org/abs/2507.11645v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Interpretable Prediction of Lymph Node Metastasis in Rectal Cancer MRI Using Variational Autoencoders", "abstract": "Effective treatment for rectal cancer relies on accurate lymph node\nmetastasis (LNM) staging. However, radiological criteria based on lymph node\n(LN) size, shape and texture morphology have limited diagnostic accuracy. In\nthis work, we investigate applying a Variational Autoencoder (VAE) as a feature\nencoder model to replace the large pre-trained Convolutional Neural Network\n(CNN) used in existing approaches. The motivation for using a VAE is that the\ngenerative model aims to reconstruct the images, so it directly encodes visual\nfeatures and meaningful patterns across the data. This leads to a disentangled\nand structured latent space which can be more interpretable than a CNN. Models\nare deployed on an in-house MRI dataset with 168 patients who did not undergo\nneo-adjuvant treatment. The post-operative pathological N stage was used as the\nground truth to evaluate model predictions. Our proposed model 'VAE-MLP'\nachieved state-of-the-art performance on the MRI dataset, with cross-validated\nmetrics of AUC 0.86 +/- 0.05, Sensitivity 0.79 +/- 0.06, and Specificity 0.85\n+/- 0.05. Code is available at:\nhttps://github.com/benkeel/Lymph_Node_Classification_MIUA.", "published": "2025-07-15 18:20:38", "link": "http://arxiv.org/abs/2507.11638v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "JSQA: Speech Quality Assessment with Perceptually-Inspired Contrastive Pretraining Based on JND Audio Pairs", "abstract": "Speech quality assessment (SQA) is often used to learn a mapping from a\nhigh-dimensional input space to a scalar that represents the mean opinion score\n(MOS) of the perceptual speech quality. Learning such a mapping is challenging\nfor many reasons, but largely because MOS exhibits high levels of inherent\nvariance due to perceptual and experimental-design differences. Many solutions\nhave been proposed, but many approaches do not properly incorporate perceptual\nfactors into their learning algorithms (beyond the MOS label), which could lead\nto unsatisfactory results. To this end, we propose JSQA, a two-stage framework\nthat pretrains an audio encoder using perceptually-guided contrastive learning\non just noticeable difference (JND) pairs, followed by fine-tuning for MOS\nprediction. We first generate pairs of audio data within JND levels, which are\nthen used to pretrain an encoder to leverage perceptual quality similarity\ninformation and map it into an embedding space. The JND pairs come from clean\nLibriSpeech utterances that are mixed with background noise from CHiME-3, at\ndifferent signal-to-noise ratios (SNRs). The encoder is later fine-tuned with\naudio samples from the NISQA dataset for MOS prediction. Experimental results\nsuggest that perceptually-inspired contrastive pretraining significantly\nimproves the model performance evaluated by various metrics when compared\nagainst the same network trained from scratch without pretraining. These\nfindings suggest that incorporating perceptual factors into pretraining greatly\ncontributes to the improvement in performance for SQA.", "published": "2025-07-15 18:16:46", "link": "http://arxiv.org/abs/2507.11636v1", "categories": ["eess.AS", "cs.AI", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Image-Based Multi-Survey Classification of Light Curves with a Pre-Trained Vision Transformer", "abstract": "We explore the use of Swin Transformer V2, a pre-trained vision Transformer,\nfor photometric classification in a multi-survey setting by leveraging light\ncurves from the Zwicky Transient Facility (ZTF) and the Asteroid\nTerrestrial-impact Last Alert System (ATLAS). We evaluate different strategies\nfor integrating data from these surveys and find that a multi-survey\narchitecture which processes them jointly achieves the best performance. These\nresults highlight the importance of modeling survey-specific characteristics\nand cross-survey interactions, and provide guidance for building scalable\nclassifiers for future time-domain astronomy.", "published": "2025-07-15 20:30:21", "link": "http://arxiv.org/abs/2507.11711v1", "categories": ["astro-ph.IM", "cs.CV"], "primary_category": "astro-ph.IM"}
{"title": "The Impact of Coreset Selection on Spurious Correlations and Group Robustness", "abstract": "Coreset selection methods have shown promise in reducing the training data\nsize while maintaining model performance for data-efficient machine learning.\nHowever, as many datasets suffer from biases that cause models to learn\nspurious correlations instead of causal features, it is important to understand\nwhether and how dataset reduction methods may perpetuate, amplify, or mitigate\nthese biases. In this work, we conduct the first comprehensive analysis of the\nimplications of data selection on the spurious bias levels of the selected\ncoresets and the robustness of downstream models trained on them. We use an\nextensive experimental setting spanning ten different spurious correlations\nbenchmarks, five score metrics to characterize sample importance/ difficulty,\nand five data selection policies across a broad range of coreset sizes.\nThereby, we unravel a series of nontrivial nuances in interactions between\nsample difficulty and bias alignment, as well as dataset bias and resultant\nmodel robustness. For example, we find that selecting coresets using\nembedding-based sample characterization scores runs a comparatively lower risk\nof inadvertently exacerbating bias than selecting using characterizations based\non learning dynamics. Most importantly, our analysis reveals that although some\ncoreset selection methods could achieve lower bias levels by prioritizing\ndifficult samples, they do not reliably guarantee downstream robustness.", "published": "2025-07-15 19:46:30", "link": "http://arxiv.org/abs/2507.11690v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "VISTA: Monocular Segmentation-Based Mapping for Appearance and View-Invariant Global Localization", "abstract": "Global localization is critical for autonomous navigation, particularly in\nscenarios where an agent must localize within a map generated in a different\nsession or by another agent, as agents often have no prior knowledge about the\ncorrelation between reference frames. However, this task remains challenging in\nunstructured environments due to appearance changes induced by viewpoint\nvariation, seasonal changes, spatial aliasing, and occlusions -- known failure\nmodes for traditional place recognition methods. To address these challenges,\nwe propose VISTA (View-Invariant Segmentation-Based Tracking for Frame\nAlignment), a novel open-set, monocular global localization framework that\ncombines: 1) a front-end, object-based, segmentation and tracking pipeline,\nfollowed by 2) a submap correspondence search, which exploits geometric\nconsistencies between environment maps to align vehicle reference frames. VISTA\nenables consistent localization across diverse camera viewpoints and seasonal\nchanges, without requiring any domain-specific training or finetuning. We\nevaluate VISTA on seasonal and oblique-angle aerial datasets, achieving up to a\n69% improvement in recall over baseline methods. Furthermore, we maintain a\ncompact object-based map that is only 0.6% the size of the most\nmemory-conservative baseline, making our approach capable of real-time\nimplementation on resource-constrained platforms.", "published": "2025-07-15 18:38:35", "link": "http://arxiv.org/abs/2507.11653v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Multiset Metric Dimension of Binomial Random Graphs", "abstract": "For a graph $G = (V,E)$ and a subset $R \\subseteq V$, we say that $R$ is\n\\textit{multiset resolving} for $G$ if for every pair of vertices $v,w$, the\n\\textit{multisets} $\\{d(v,r): r \\in R\\}$ and $\\{d(w,r):r \\in R\\}$ are distinct,\nwhere $d(x,y)$ is the graph distance between vertices $x$ and $y$. The\n\\textit{multiset metric dimension} of $G$ is the size of a smallest set $R\n\\subseteq V$ that is multiset resolving (or $\\infty$ if no such set exists).\nThis graph parameter was introduced by Simanjuntak, Siagian, and Vitr\\'{i}k in\n2017~\\cite{simanjuntak2017multiset}, and has since been studied for a variety\nof graph families. We prove bounds which hold with high probability for the\nmultiset metric dimension of the binomial random graph $G(n,p)$ in the regime\n$d = (n-1)p = \\Theta(n^{x})$ for fixed $x \\in (0,1)$.", "published": "2025-07-15 19:41:23", "link": "http://arxiv.org/abs/2507.11686v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "An Empirical Study of Multi-Agent RAG for Real-World University Admissions Counseling", "abstract": "This paper presents MARAUS (Multi-Agent and Retrieval-Augmented University\nAdmission System), a real-world deployment of a conversational AI platform for\nhigher education admissions counseling in Vietnam. While large language models\n(LLMs) offer potential for automating advisory tasks, most existing solutions\nremain limited to prototypes or synthetic benchmarks. MARAUS addresses this gap\nby combining hybrid retrieval, multi-agent orchestration, and LLM-based\ngeneration into a system tailored for real-world university admissions. In\ncollaboration with the University of Transport Technology (UTT) in Hanoi, we\nconducted a two-phase study involving technical development and real-world\nevaluation. MARAUS processed over 6,000 actual user interactions, spanning six\ncategories of queries. Results show substantial improvements over LLM-only\nbaselines: on average 92 percent accuracy, hallucination rates reduced from 15\nprecent to 1.45 percent, and average response times below 4 seconds. The system\noperated cost-effectively, with a two-week deployment cost of 11.58 USD using\nGPT-4o mini. This work provides actionable insights for the deployment of\nagentic RAG systems in low-resource educational settings.", "published": "2025-07-15 12:49:42", "link": "http://arxiv.org/abs/2507.11272v1", "categories": ["cs.SE", "cs.IR"], "primary_category": "cs.SE"}
{"title": "Enforcing Latent Euclidean Geometry in Single-Cell VAEs for Manifold Interpolation", "abstract": "Latent space interpolations are a powerful tool for navigating deep\ngenerative models in applied settings. An example is single-cell RNA\nsequencing, where existing methods model cellular state transitions as latent\nspace interpolations with variational autoencoders, often assuming linear\nshifts and Euclidean geometry. However, unless explicitly enforced, linear\ninterpolations in the latent space may not correspond to geodesic paths on the\ndata manifold, limiting methods that assume Euclidean geometry in the data\nrepresentations. We introduce FlatVI, a novel training framework that\nregularises the latent manifold of discrete-likelihood variational autoencoders\ntowards Euclidean geometry, specifically tailored for modelling single-cell\ncount data. By encouraging straight lines in the latent space to approximate\ngeodesic interpolations on the decoded single-cell manifold, FlatVI enhances\ncompatibility with downstream approaches that assume Euclidean latent geometry.\nExperiments on synthetic data support the theoretical soundness of our\napproach, while applications to time-resolved single-cell RNA sequencing data\ndemonstrate improved trajectory reconstruction and manifold interpolation.", "published": "2025-07-15 23:08:14", "link": "http://arxiv.org/abs/2507.11789v1", "categories": ["cs.LG", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "Inference on Optimal Policy Values and Other Irregular Functionals via Smoothing", "abstract": "Constructing confidence intervals for the value of an optimal treatment\npolicy is an important problem in causal inference. Insight into the optimal\npolicy value can guide the development of reward-maximizing, individualized\ntreatment regimes. However, because the functional that defines the optimal\nvalue is non-differentiable, standard semi-parametric approaches for performing\ninference fail to be directly applicable. Existing approaches for handling this\nnon-differentiability fall roughly into two camps. In one camp are estimators\nbased on constructing smooth approximations of the optimal value. These\napproaches are computationally lightweight, but typically place unrealistic\nparametric assumptions on outcome regressions. In another camp are approaches\nthat directly de-bias the non-smooth objective. These approaches don't place\nparametric assumptions on nuisance functions, but they either require the\ncomputation of intractably-many nuisance estimates, assume unrealistic\n$L^\\infty$ nuisance convergence rates, or make strong margin assumptions that\nprohibit non-response to a treatment. In this paper, we revisit the problem of\nconstructing smooth approximations of non-differentiable functionals. By\ncarefully controlling first-order bias and second-order remainders, we show\nthat a softmax smoothing-based estimator can be used to estimate parameters\nthat are specified as a maximum of scores involving nuisance components. In\nparticular, this includes the value of the optimal treatment policy as a\nspecial case. Our estimator obtains $\\sqrt{n}$ convergence rates, avoids\nparametric restrictions/unrealistic margin assumptions, and is often\nstatistically efficient.", "published": "2025-07-15 22:38:39", "link": "http://arxiv.org/abs/2507.11780v1", "categories": ["econ.EM", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "primary_category": "econ.EM"}
{"title": "Scaling laws for activation steering with Llama 2 models and refusal mechanisms", "abstract": "As large language models (LLMs) evolve in complexity and capability, the\nefficacy of less widely deployed alignment techniques are uncertain. Building\non previous work on activation steering and contrastive activation addition\n(CAA), this paper explores the effectiveness of CAA with model scale using the\nfamily of Llama 2 models (7B, 13B, and 70B). CAA works by finding desirable\n'directions' in the model's residual stream vector space using contrastive\npairs (for example, hate to love) and adding this direction to the residual\nstream during the forward pass. It directly manipulates the residual stream and\naims to extract features from language models to better control their outputs.\nUsing answer matching questions centered around the refusal behavior, we found\nthat 1) CAA is most effective when applied at early-mid layers. 2) The\neffectiveness of CAA diminishes with model size. 3) Negative steering has more\npronounced effects than positive steering across all model sizes.", "published": "2025-07-15 22:21:18", "link": "http://arxiv.org/abs/2507.11771v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "LLMs are Bayesian, in Expectation, not in Realization", "abstract": "Large language models demonstrate remarkable in-context learning\ncapabilities, adapting to new tasks without parameter updates. While this\nphenomenon has been successfully modeled as implicit Bayesian inference, recent\nempirical findings reveal a fundamental contradiction: transformers\nsystematically violate the martingale property, a cornerstone requirement of\nBayesian updating on exchangeable data. This violation challenges the\ntheoretical foundations underlying uncertainty quantification in critical\napplications.\n  Our theoretical analysis establishes four key results: (1) positional\nencodings induce martingale violations of order $\\Theta(\\log n / n)$; (2)\ntransformers achieve information-theoretic optimality with excess risk\n$O(n^{-1/2})$ in expectation over orderings; (3) the implicit posterior\nrepresentation converges to the true Bayesian posterior in the space of\nsufficient statistics; and (4) we derive the optimal chain-of-thought length as\n$k^* = \\Theta(\\sqrt{n}\\log(1/\\varepsilon))$ with explicit constants, providing\na principled approach to reduce inference costs while maintaining performance.\nEmpirical validation on GPT-3 confirms predictions (1)-(3), with transformers\nreaching 99\\% of theoretical entropy limits within 20 examples. Our framework\nprovides practical methods for extracting calibrated uncertainty estimates from\nposition-aware architectures and optimizing computational efficiency in\ndeployment.", "published": "2025-07-15 22:20:11", "link": "http://arxiv.org/abs/2507.11768v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Torsional-GFN: a conditional conformation generator for small molecules", "abstract": "Generating stable molecular conformations is crucial in several drug\ndiscovery applications, such as estimating the binding affinity of a molecule\nto a target. Recently, generative machine learning methods have emerged as a\npromising, more efficient method than molecular dynamics for sampling of\nconformations from the Boltzmann distribution. In this paper, we introduce\nTorsional-GFN, a conditional GFlowNet specifically designed to sample\nconformations of molecules proportionally to their Boltzmann distribution,\nusing only a reward function as training signal. Conditioned on a molecular\ngraph and its local structure (bond lengths and angles), Torsional-GFN samples\nrotations of its torsion angles. Our results demonstrate that Torsional-GFN is\nable to sample conformations approximately proportional to the Boltzmann\ndistribution for multiple molecules with a single model, and allows for\nzero-shot generalization to unseen bond lengths and angles coming from the MD\nsimulations for such molecules. Our work presents a promising avenue for\nscaling the proposed approach to larger molecular systems, achieving zero-shot\ngeneralization to unseen molecules, and including the generation of the local\nstructure into the GFlowNet model.", "published": "2025-07-15 21:53:25", "link": "http://arxiv.org/abs/2507.11759v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Large-scale distributed synchronization systems, using a cancel-on-completion redundancy mechanism", "abstract": "We consider a class of multi-agent distributed synchronization systems, which\nare modeled as $n$ particles moving on the real line. This class generalizes\nthe model of a multi-server queueing system, considered in [15], employing\nso-called cancel-on-completion (c.o.c.) redundancy mechanism, but is motivated\nby other applications as well. The model in [15] is a particle system,\nregulated at the left boundary point. The more general model of this paper is\nsuch that we allow regulation boundaries on either side, or both sides, or no\nregulation at all. We consider the mean-field asymptotic regime, when the\nnumber of particles $n$ and the job arrival rates go to infinity, while the job\narrival rates per particle remain constant. The results include: the\nexistence/uniqueness of fixed points of mean-field limits (ML), which describe\nthe limiting dynamics of the system; conditions for the steady-state asymptotic\nindependence (concentration, as $n \\to\\infty$, of the stationary distribution\non a single state, which is necessarily an ML fixed point); the limits, as $n\n\\to\\infty$, of the average velocity at which unregulated (free) particle system\nadvances. In particular, our results for the left-regulated system unify and\ngeneralize the corresponding results in [15]. Our technical development is such\nthat the systems with different types of regulation are analyzed within a\nunified framework. In particular, these systems are used as tools for analysis\nof each other.", "published": "2025-07-15 22:36:59", "link": "http://arxiv.org/abs/2507.11779v1", "categories": ["math.PR", "cs.MA", "90B15, 60K25"], "primary_category": "math.PR"}
{"title": "A Cellular Automata Approach to Donation Game", "abstract": "The donation game is a well-established framework for studying the emergence\nand evolution of cooperation in multi-agent systems. The cooperative behavior\ncan be influenced by the environmental noise in partially observable settings\nand by the decision-making strategies of agents, which may incorporate not only\nreputation but also traits such as generosity and forgiveness. Traditional\nsimulations often assume fully random interactions, where cooperation is tested\nbetween randomly selected agent pairs. In this paper, we investigate\ncooperation dynamics using the concept of Stephen Wolfram's one-dimensional\nbinary cellular automata. This approach allows us to explore how cooperation\nevolves when interactions are limited to neighboring agents. We define binary\ncellular automata rules that conform to the donation game mechanics.\nAdditionally, we introduce models of perceptual and action noise, along with a\nmutation matrix governing the probabilistic evolution of agent strategies. Our\nempirical results demonstrate that cooperation is significantly affected by\nagents' mobility and their spatial locality on the game board. These findings\nhighlight the importance of distinguishing between entirely random multi-agent\nsystems and those in which agents are more likely to interact with their\nnearest neighbors.", "published": "2025-07-15 21:16:24", "link": "http://arxiv.org/abs/2507.11744v1", "categories": ["cs.MA", "cs.GT", "physics.soc-ph"], "primary_category": "cs.MA"}
{"title": "STAGED: A Multi-Agent Neural Network for Learning Cellular Interaction Dynamics", "abstract": "The advent of single-cell technology has significantly improved our\nunderstanding of cellular states and subpopulations in various tissues under\nnormal and diseased conditions by employing data-driven approaches such as\nclustering and trajectory inference. However, these methods consider cells as\nindependent data points of population distributions. With spatial\ntranscriptomics, we can represent cellular organization, along with dynamic\ncell-cell interactions that lead to changes in cell state. Still, key\ncomputational advances are necessary to enable the data-driven learning of such\ncomplex interactive cellular dynamics. While agent-based modeling (ABM)\nprovides a powerful framework, traditional approaches rely on handcrafted rules\nderived from domain knowledge rather than data-driven approaches. To address\nthis, we introduce Spatio Temporal Agent-Based Graph Evolution Dynamics(STAGED)\nintegrating ABM with deep learning to model intercellular communication, and\nits effect on the intracellular gene regulatory network. Using graph ODE\nnetworks (GDEs) with shared weights per cell type, our approach represents\ngenes as vertices and interactions as directed edges, dynamically learning\ntheir strengths through a designed attention mechanism. Trained to match\ncontinuous trajectories of simulated as well as inferred trajectories from\nspatial transcriptomics data, the model captures both intercellular and\nintracellular interactions, enabling a more adaptive and accurate\nrepresentation of cellular dynamics.", "published": "2025-07-15 18:46:07", "link": "http://arxiv.org/abs/2507.11660v1", "categories": ["cs.LG", "cs.MA", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "Acceleration methods for fixed point iterations", "abstract": "A pervasive approach in scientific computing is to express the solution to a\ngiven problem as the limit of a sequence of vectors or other mathematical\nobjects. In many situations these sequences are generated by slowly converging\niterative procedures and this led practitioners to seek faster alternatives to\nreach the limit. ``Acceleration techniques'' comprise a broad array of methods\nspecifically designed with this goal in mind. They started as a means of\nimproving the convergence of general scalar sequences by various forms of\n``extrapolation to the limit'', i.e., by extrapolating the most recent iterates\nto the limit via linear combinations. Extrapolation methods of this type, the\nbest known example of which is Aitken's Delta-squared process, require only the\nsequence of vectors as input. However, limiting methods to only use the\niterates is too restrictive. Accelerating sequences generated by fixed-point\niterations by utilizing both the iterates and the fixed-point mapping itself\nhas proven highly successful across various areas of physics. A notable example\nof these Fixed-Point accelerators (FP-Accelerators) is a method developed by D.\nAnderson in 1965 and now widely known as Anderson Acceleration (AA).\nFurthermore, Quasi-Newton and Inexact Newton methods can also be placed in this\ncategory as well. This paper presents an overview of these methods -- with an\nemphasis on those, such as AA, that are geared toward accelerating fixed point\niterations.", "published": "2025-07-15 21:20:36", "link": "http://arxiv.org/abs/2507.11746v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Approaching Optimality for Solving Dense Linear Systems with Low-Rank Structure", "abstract": "We provide new high-accuracy randomized algorithms for solving linear systems\nand regression problems that are well-conditioned except for $k$ large singular\nvalues. For solving such $d \\times d$ positive definite system our algorithms\nsucceed whp. and run in time $\\tilde O(d^2 + k^\\omega)$. For solving such\nregression problems in a matrix $\\mathbf{A} \\in \\mathbb{R}^{n \\times d}$ our\nmethods succeed whp. and run in time $\\tilde O(\\mathrm{nnz}(\\mathbf{A}) + d^2 +\nk^\\omega)$ where $\\omega$ is the matrix multiplication exponent and\n$\\mathrm{nnz}(\\mathbf{A})$ is the number of non-zeros in $\\mathbf{A}$. Our\nmethods nearly-match a natural complexity limit under dense inputs for these\nproblems and improve upon a trade-off in prior approaches that obtain running\ntimes of either $\\tilde O(d^{2.065}+k^\\omega)$ or $\\tilde O(d^2 +\ndk^{\\omega-1})$ for $d\\times d$ systems. Moreover, we show how to obtain these\nrunning times even under the weaker assumption that all but $k$ of the singular\nvalues have a suitably bounded generalized mean. Consequently, we give the\nfirst nearly-linear time algorithm for computing a multiplicative approximation\nto the nuclear norm of an arbitrary dense matrix. Our algorithms are built on\nthree general recursive preconditioning frameworks, where matrix sketching and\nlow-rank update formulas are carefully tailored to the problems' structure.", "published": "2025-07-15 20:48:30", "link": "http://arxiv.org/abs/2507.11724v1", "categories": ["cs.DS", "cs.NA", "math.NA", "math.OC", "stat.ML"], "primary_category": "cs.DS"}
{"title": "Norm-Stabilized Imaginary-Time Evolution via Feedback Control", "abstract": "We present a norm-stabilized imaginary-time evolution (ITE) scheme for the\none-dimensional nonlinear Schrodinger equation (NLSE). Traditional ITE solvers\noften require explicit renormalization of the wavefunction after each step to\npreserve norm, which can be disruptive and algorithmically inflexible. We\npropose an alternative approach in which the evolution is continuously\nstabilized using an adaptive feedback term mu(tau), proportional to the time\nderivative of the wavefunction norm. This results in a self-regulating flow\nthat requires no external normalization while preserving convergence toward\nsoliton solutions. We demonstrate the method's effectiveness by comparing the\nfinal wavefunction profiles and L2 errors against analytical solutions and\nbaseline methods without feedback. Although this work focuses on the 1D case,\nthe framework is designed to extend naturally to higher dimensions. Future work\nwill explore the behavior of the feedback mechanism in 2D and 3D systems,\nmulti-soliton scenarios, and external potentials.", "published": "2025-07-15 20:10:52", "link": "http://arxiv.org/abs/2507.11700v1", "categories": ["math.NA", "cs.NA", "nlin.PS", "physics.comp-ph", "65M06, 35Q55", "G.1.7; G.1.8"], "primary_category": "math.NA"}
{"title": "Discontinuous Galerkin approximation for a Stokes-Brinkman-type formulation for the eigenvalue problem in porous media", "abstract": "We introduce a family of discontinuous Galerkin methods to approximate the\neigenvalues and eigenfunctions of a Stokes-Brinkman type of problem based in\nthe interior penalty strategy. Under the standard assumptions on the meshes and\na suitable norm, we prove the stability of the discrete scheme. Due to the\nnon-conforming nature of the method, we use the well-known non-compact\noperators theory to derive convergence and error estimates for the method. We\npresent an exhaustive computational analysis where we compute the spectrum with\ndifferent stabilization parameters with the aim of study its influence when the\nspectrum is approximated.", "published": "2025-07-15 19:51:31", "link": "http://arxiv.org/abs/2507.11695v1", "categories": ["math.NA", "cs.NA", "35Q35, 65N15, 65N25, 65N30, 65N50"], "primary_category": "math.NA"}
{"title": "State-based approach to the numerical solution of Dirichlet boundary optimal control problems for the Laplace equation", "abstract": "We investigate the Dirichlet boundary control of the Laplace equation,\nconsidering the control in $H^{1/2}(\\partial \\Omega)$, which is the natural\nspace for Dirichlet data when the state belongs to $H^1(\\Omega)$. The cost of\nthe control is measured in the $H^{1/2}(\\partial \\Omega)$ norm that also plays\nthe role of the regularization term. We discuss regularization and finite\nelement error estimates enabling us to derive an optimal relation between the\nfinite element mesh size $h$ and the regularization parameter $\\varrho$,\nbalancing the energy cost for the control and the accuracy of the approximation\nof the desired state. This relationship is also crucial in designing efficient\nsolvers. We also discuss additional box constraints imposed on the control and\nthe state. Our theoretical findings are complemented by numerical examples,\nincluding one example with box constraints.", "published": "2025-07-15 18:31:33", "link": "http://arxiv.org/abs/2507.11646v1", "categories": ["math.NA", "cs.NA", "math.OC", "49J20, 49K20, 65K10, 65N30, 65N22"], "primary_category": "math.NA"}
{"title": "Fiducial Matching: Differentially Private Inference for Categorical Data", "abstract": "The task of statistical inference, which includes the building of confidence\nintervals and tests for parameters and effects of interest to a researcher, is\nstill an open area of investigation in a differentially private (DP) setting.\nIndeed, in addition to the randomness due to data sampling, DP delivers another\nsource of randomness consisting of the noise added to protect an individual's\ndata from being disclosed to a potential attacker. As a result of this\nconvolution of noises, in many cases it is too complicated to determine the\nstochastic behavior of the statistics and parameters resulting from a DP\nprocedure. In this work, we contribute to this line of investigation by\nemploying a simulation-based matching approach, solved through tools from the\nfiducial framework, which aims to replicate the data generation pipeline\n(including the DP step) and retrieve an approximate distribution of the\nestimates resulting from this pipeline. For this purpose, we focus on the\nanalysis of categorical (nominal) data that is common in national surveys, for\nwhich sensitivity is naturally defined, and on additive privacy mechanisms. We\nprove the validity of the proposed approach in terms of coverage and highlight\nits good computational and statistical performance for different inferential\ntasks in simulated and applied data settings.", "published": "2025-07-15 21:56:15", "link": "http://arxiv.org/abs/2507.11762v1", "categories": ["stat.ME", "stat.CO", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Graph Neural Networks Powered by Encoder Embedding for Improved Node Learning", "abstract": "Graph neural networks (GNNs) have emerged as a powerful framework for a wide\nrange of node-level graph learning tasks. However, their performance is often\nconstrained by reliance on random or minimally informed initial feature\nrepresentations, which can lead to slow convergence and suboptimal solutions.\nIn this paper, we leverage a statistically grounded method, one-hot graph\nencoder embedding (GEE), to generate high-quality initial node features that\nenhance the end-to-end training of GNNs. We refer to this integrated framework\nas the GEE-powered GNN (GG), and demonstrate its effectiveness through\nextensive simulations and real-world experiments across both unsupervised and\nsupervised settings. In node clustering, GG consistently achieves\nstate-of-the-art performance, ranking first across all evaluated real-world\ndatasets, while exhibiting faster convergence compared to the standard GNN. For\nnode classification, we further propose an enhanced variant, GG-C, which\nconcatenates the outputs of GG and GEE and outperforms competing baselines.\nThese results confirm the importance of principled, structure-aware feature\ninitialization in realizing the full potential of GNNs.", "published": "2025-07-15 21:01:54", "link": "http://arxiv.org/abs/2507.11732v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Model averaging in the space of probability distributions", "abstract": "This work investigates the problem of model averaging in the context of\nmeasure-valued data. Specifically, we study aggregation schemes in the space of\nprobability distributions metrized in terms of the Wasserstein distance. The\nresulting aggregate models, defined via Wasserstein barycenters, are optimally\ncalibrated to empirical data. To enhance model performance, we employ\nregularization schemes motivated by the standard elastic net penalization,\nwhich is shown to consistently yield models enjoying sparsity properties. The\nconsistency properties of the proposed averaging schemes with respect to sample\nsize are rigorously established using the variational framework of\n$\\Gamma$-convergence. The performance of the methods is evaluated through\ncarefully designed synthetic experiments that assess behavior across a range of\ndistributional characteristics and stress conditions. Finally, the proposed\napproach is applied to a real-world dataset of insurance losses - characterized\nby heavy-tailed behavior - to estimate the claim size distribution and the\nassociated tail risk.", "published": "2025-07-15 20:41:57", "link": "http://arxiv.org/abs/2507.11719v1", "categories": ["stat.ME", "stat.CO", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Reinforcement Learning from Adversarial Preferences in Tabular MDPs", "abstract": "We introduce a new framework of episodic tabular Markov decision processes\n(MDPs) with adversarial preferences, which we refer to as preference-based MDPs\n(PbMDPs). Unlike standard episodic MDPs with adversarial losses, where the\nnumerical value of the loss is directly observed, in PbMDPs the learner instead\nobserves preferences between two candidate arms, which represent the choices\nbeing compared. In this work, we focus specifically on the setting where the\nreward functions are determined by Borda scores. We begin by establishing a\nregret lower bound for PbMDPs with Borda scores. As a preliminary step, we\npresent a simple instance to prove a lower bound of $\\Omega(\\sqrt{HSAT})$ for\nepisodic MDPs with adversarial losses, where $H$ is the number of steps per\nepisode, $S$ is the number of states, $A$ is the number of actions, and $T$ is\nthe number of episodes. Leveraging this construction, we then derive a regret\nlower bound of $\\Omega( (H^2 S K)^{1/3} T^{2/3} )$ for PbMDPs with Borda\nscores, where $K$ is the number of arms. Next, we develop algorithms that\nachieve a regret bound of order $T^{2/3}$. We first propose a global\noptimization approach based on online linear optimization over the set of all\noccupancy measures, achieving a regret bound of $\\tilde{O}((H^2 S^2 K)^{1/3}\nT^{2/3} )$ under known transitions. However, this approach suffers from\nsuboptimal dependence on the potentially large number of states $S$ and\ncomputational inefficiency. To address this, we propose a policy optimization\nalgorithm whose regret is roughly bounded by $\\tilde{O}( (H^6 S K^5)^{1/3}\nT^{2/3} )$ under known transitions, and further extend the result to the\nunknown-transition setting.", "published": "2025-07-15 20:19:32", "link": "http://arxiv.org/abs/2507.11706v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Distribution-Free Uncertainty-Aware Virtual Sensing via Conformalized Neural Operators", "abstract": "Robust uncertainty quantification (UQ) remains a critical barrier to the safe\ndeployment of deep learning in real-time virtual sensing, particularly in\nhigh-stakes domains where sparse, noisy, or non-collocated sensor data are the\nnorm. We introduce the Conformalized Monte Carlo Operator (CMCO), a framework\nthat transforms neural operator-based virtual sensing with calibrated,\ndistribution-free prediction intervals. By unifying Monte Carlo dropout with\nsplit conformal prediction in a single DeepONet architecture, CMCO achieves\nspatially resolved uncertainty estimates without retraining, ensembling, or\ncustom loss design. Our method addresses a longstanding challenge: how to endow\noperator learning with efficient and reliable UQ across heterogeneous domains.\nThrough rigorous evaluation on three distinct applications: turbulent flow,\nelastoplastic deformation, and global cosmic radiation dose estimation-CMCO\nconsistently attains near-nominal empirical coverage, even in settings with\nstrong spatial gradients and proxy-based sensing. This breakthrough offers a\ngeneral-purpose, plug-and-play UQ solution for neural operators, unlocking\nreal-time, trustworthy inference in digital twins, sensor fusion, and\nsafety-critical monitoring. By bridging theory and deployment with minimal\ncomputational overhead, CMCO establishes a new foundation for scalable,\ngeneralizable, and uncertainty-aware scientific machine learning.", "published": "2025-07-15 04:26:40", "link": "http://arxiv.org/abs/2507.11574v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Towards Scalable AASIST: Refining Graph Attention for Speech Deepfake Detection", "abstract": "Advances in voice conversion and text-to-speech synthesis have made automatic\nspeaker verification (ASV) systems more susceptible to spoofing attacks. This\nwork explores modest refinements to the AASIST anti-spoofing architecture. It\nincorporates a frozen Wav2Vec 2.0 encoder to retain self-supervised speech\nrepresentations in limited-data settings, substitutes the original graph\nattention block with a standardized multi-head attention module using\nheterogeneous query projections, and replaces heuristic frame-segment fusion\nwith a trainable, context-aware integration layer. When evaluated on the\nASVspoof 5 corpus, the proposed system reaches a 7.6\\% equal error rate (EER),\nimproving on a re-implemented AASIST baseline under the same training\nconditions. Ablation experiments suggest that each architectural change\ncontributes to the overall performance, indicating that targeted adjustments to\nestablished models may help strengthen speech deepfake detection in practical\nscenarios. The code is publicly available at\nhttps://github.com/KORALLLL/AASIST_SCALING.", "published": "2025-07-15 22:31:43", "link": "http://arxiv.org/abs/2507.11777v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Improving Neural Pitch Estimation with SWIPE Kernels", "abstract": "Neural networks have become the dominant technique for accurate pitch and\nperiodicity estimation. Although a lot of research has gone into improving\nnetwork architectures and training paradigms, most approaches operate directly\non the raw audio waveform or on general-purpose time-frequency representations.\nWe investigate the use of Sawtooth-Inspired Pitch Estimation (SWIPE) kernels as\nan audio frontend and find that these hand-crafted, task-specific features can\nmake neural pitch estimators more accurate, robust to noise, and more\nparameter-efficient. We evaluate supervised and self-supervised\nstate-of-the-art architectures on common datasets and show that the SWIPE audio\nfrontend allows for reducing the network size by an order of magnitude without\nperformance degradation. Additionally, we show that the SWIPE algorithm on its\nown is much more accurate than commonly reported, outperforming\nstate-of-the-art self-supervised neural pitch estimators.", "published": "2025-07-15 12:04:07", "link": "http://arxiv.org/abs/2507.11233v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "JamShield: A Machine Learning Detection System for Over-the-Air Jamming Attacks", "abstract": "Wireless networks are vulnerable to jamming attacks due to the shared\ncommunication medium, which can severely degrade performance and disrupt\nservices. Despite extensive research, current jamming detection methods often\nrely on simulated data or proprietary over-the-air datasets with limited\ncross-layer features, failing to accurately represent the real state of a\nnetwork and thus limiting their effectiveness in real-world scenarios. To\naddress these challenges, we introduce JamShield, a dynamic jamming detection\nsystem trained on our own collected over-the-air and publicly available\ndataset. It utilizes hybrid feature selection to prioritize relevant features\nfor accurate and efficient detection. Additionally, it includes an\nauto-classification module that dynamically adjusts the classification\nalgorithm in real-time based on current network conditions. Our experimental\nresults demonstrate significant improvements in detection rate, precision, and\nrecall, along with reduced false alarms and misdetections compared to\nstate-of-the-art detection algorithms, making JamShield a robust and reliable\nsolution for detecting jamming attacks in real-world wireless networks.", "published": "2025-07-15 16:53:30", "link": "http://arxiv.org/abs/2507.11483v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Graph-based Fingerprint Update Using Unlabelled WiFi Signals", "abstract": "WiFi received signal strength (RSS) environment evolves over time due to\nmovement of access points (APs), AP power adjustment, installation and removal\nof APs, etc. We study how to effectively update an existing database of\nfingerprints, defined as the RSS values of APs at designated locations, using a\nbatch of newly collected unlabelled (possibly crowdsourced) WiFi signals. Prior\nart either estimates the locations of the new signals without updating the\nexisting fingerprints or filters out the new APs without sufficiently embracing\ntheir features. To address that, we propose GUFU, a novel effective graph-based\napproach to update WiFi fingerprints using unlabelled signals with possibly new\nAPs. Based on the observation that similar signal vectors likely imply physical\nproximity, GUFU employs a graph neural network (GNN) and a link prediction\nalgorithm to retrain an incremental network given the new signals and APs.\nAfter the retraining, it then updates the signal vectors at the designated\nlocations. Through extensive experiments in four large representative sites,\nGUFU is shown to achieve remarkably higher fingerprint adaptivity as compared\nwith other state-of-the-art approaches, with error reduction of 21.4% and 29.8%\nin RSS values and location prediction, respectively.", "published": "2025-07-15 07:05:20", "link": "http://arxiv.org/abs/2507.11038v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "SWE-MERA: A Dynamic Benchmark for Agenticly Evaluating Large Language Models on Software Engineering Tasks", "abstract": "The rapid advancement of Large Language Models (LLMs) in software engineering\nhas revealed critical limitations in existing benchmarks, particularly the\nwidely used SWE-bench dataset. Recent studies have uncovered severe data\ncontamination issues, e.g. SWE-bench reports 32.67% of successful patches\ninvolve direct solution leakage and 31.08% pass due to inadequate test cases.\nWe introduce SWE-MERA, a dynamic, continuously updated benchmark designed to\naddress these fundamental challenges through an automated collection of\nreal-world GitHub issues and rigorous quality validation. Our approach\nimplements a reliable pipeline that ensures quality while minimizing\ncontamination risks, resulting in approximately 10,000 potential tasks with 300\nsamples currently available. Evaluation using the Aider coding agent\ndemonstrates strong discriminative power in state-of-the-art models. We report\nperformance across a dozen recent LLMs evaluated on tasks collected between\nSeptember 2024 and June 2025.", "published": "2025-07-15 07:52:33", "link": "http://arxiv.org/abs/2507.11059v2", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "LLM-Driven Dual-Level Multi-Interest Modeling for Recommendation", "abstract": "Recently, much effort has been devoted to modeling users' multi-interests\nbased on their behaviors or auxiliary signals. However, existing methods often\nrely on heuristic assumptions, e.g., co-occurring items indicate the same\ninterest of users, failing to capture user multi-interests aligning with\nreal-world scenarios. While large language models (LLMs) show significant\npotential for multi-interest analysis due to their extensive knowledge and\npowerful reasoning capabilities, two key challenges remain. First, the\ngranularity of LLM-driven multi-interests is agnostic, possibly leading to\noverly fine or coarse interest grouping. Second, individual user analysis\nprovides limited insights due to the data sparsity issue. In this paper, we\npropose an LLM-driven dual-level multi-interest modeling framework for more\neffective recommendation. At the user-individual level, we exploit LLMs to\nflexibly allocate items engaged by users into different semantic clusters,\nindicating their diverse and distinct interests. To alleviate the agnostic\ngeneration of LLMs, we adaptively assign these semantic clusters to users'\ncollaborative multi-interests learned from global user-item interactions,\nallowing the granularity to be automatically adjusted according to the user's\nbehaviors using an alignment module. To alleviate the limited insights derived\nfrom individual users' behaviors, at the user-crowd level, we propose\naggregating user cliques into synthesized users with rich behaviors for more\ncomprehensive LLM-driven multi-interest analysis. We formulate a max covering\nproblem to ensure the compactness and representativeness of synthesized users'\nbehaviors, and then conduct contrastive learning based on their LLM-driven\nmulti-interests to disentangle item representations among different interests.\nExperiments on real-world datasets show the superiority of our approach against\nstate-of-the-art methods.", "published": "2025-07-15 02:13:54", "link": "http://arxiv.org/abs/2507.10917v2", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Recent Advances in Simulation-based Inference for Gravitational Wave Data Analysis", "abstract": "The detection of gravitational waves by the LIGO-Virgo-KAGRA collaboration\nhas ushered in a new era of observational astronomy, emphasizing the need for\nrapid and detailed parameter estimation and population-level analyses.\nTraditional Bayesian inference methods, particularly Markov chain Monte Carlo,\nface significant computational challenges when dealing with the\nhigh-dimensional parameter spaces and complex noise characteristics inherent in\ngravitational wave data. This review examines the emerging role of\nsimulation-based inference methods in gravitational wave astronomy, with a\nfocus on approaches that leverage machine-learning techniques such as\nnormalizing flows and neural posterior estimation. We provide a comprehensive\noverview of the theoretical foundations underlying various simulation-based\ninference methods, including neural posterior estimation, neural ratio\nestimation, neural likelihood estimation, flow matching, and consistency\nmodels. We explore the applications of these methods across diverse\ngravitational wave data processing scenarios, from single-source parameter\nestimation and overlapping signal analysis to testing general relativity and\nconducting population studies. Although these techniques demonstrate speed\nimprovements over traditional methods in controlled studies, their\nmodel-dependent nature and sensitivity to prior assumptions are barriers to\ntheir widespread adoption. Their accuracy, which is similar to that of\nconventional methods, requires further validation across broader parameter\nspaces and noise conditions.", "published": "2025-07-15 10:52:57", "link": "http://arxiv.org/abs/2507.11192v2", "categories": ["gr-qc", "astro-ph.HE", "astro-ph.IM", "cs.LG", "stat.ML"], "primary_category": "gr-qc"}
{"title": "How does Labeling Error Impact Contrastive Learning? A Perspective from Data Dimensionality Reduction", "abstract": "In recent years, contrastive learning has achieved state-of-the-art\nperformance in the territory of self-supervised representation learning. Many\nprevious works have attempted to provide the theoretical understanding\nunderlying the success of contrastive learning. Almost all of them rely on a\ndefault assumption, i.e., the label consistency assumption, which may not hold\nin practice (the probability of failure is called labeling error) due to the\nstrength and randomness of common augmentation strategies, such as random\nresized crop (RRC). This paper investigates the theoretical impact of labeling\nerror on the downstream classification performance of contrastive learning. We\nfirst reveal several significant negative impacts of labeling error on\ndownstream classification risk. To mitigate these impacts, data dimensionality\nreduction method (e.g., singular value decomposition, SVD) is applied on\noriginal data to reduce false positive samples, and establish both theoretical\nand empirical evaluations. Moreover, it is also found that SVD acts as a\ndouble-edged sword, which may lead to the deterioration of downstream\nclassification accuracy due to the reduced connectivity of the augmentation\ngraph. Based on the above observations, we give the augmentation suggestion\nthat we should use some moderate embedding dimension (such as $512, 1024$ in\nour experiments), data inflation, weak augmentation, and SVD to ensure large\ngraph connectivity and small labeling error to improve model performance.", "published": "2025-07-15 10:09:55", "link": "http://arxiv.org/abs/2507.11161v2", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "MR-LDM -- The Merge-Reactive Longitudinal Decision Model: Game Theoretic Human Decision Modeling for Interactive Sim Agents", "abstract": "Enhancing simulation environments to replicate real-world driver behavior,\ni.e., more humanlike sim agents, is essential for developing autonomous vehicle\ntechnology. In the context of highway merging, previous works have studied the\noperational-level yielding dynamics of lag vehicles in response to a merging\ncar at highway on-ramps. Other works focusing on tactical decision modeling\ngenerally consider limited action sets or utilize payoff functions with large\nparameter sets and limited payoff bounds. In this work, we aim to improve the\nsimulation of the highway merge scenario by targeting a game theoretic model\nfor tactical decision-making with improved payoff functions and lag actions. We\ncouple this with an underlying dynamics model to have a unified decision and\ndynamics model that can capture merging interactions and simulate more\nrealistic interactions in an explainable and interpretable fashion. The\nproposed model demonstrated good reproducibility of complex interactions when\nvalidated on a real-world dataset. The model was finally integrated into a high\nfidelity simulation environment and confirmed to have adequate computation time\nefficiency for use in large-scale simulations to support autonomous vehicle\ndevelopment.", "published": "2025-07-15 20:41:00", "link": "http://arxiv.org/abs/2507.12494v1", "categories": ["cs.AI", "cs.GT", "cs.MA", "cs.RO"], "primary_category": "cs.AI"}
{"title": "On multiagent online problems with predictions", "abstract": "We study the power of (competitive) algorithms with predictions in a\nmultiagent setting. We introduce a two predictor framework, that assumes that\nagents use one predictor for their future (self) behavior, and one for the\nbehavior of the other players. The main problem we are concerned with is\nunderstanding what are the best competitive ratios that can be achieved by\nemploying such predictors, under various assumptions on predictor quality.\n  As an illustration of our framework, we introduce and analyze a multiagent\nversion of the ski-rental problem. In this problem agents can collaborate by\npooling resources to get a group license for some asset. If the license price\nis not met then agents have to rent the asset individually for the day at a\nunit price. Otherwise the license becomes available forever to everyone at no\nextra cost.\n  In the particular case of perfect other predictions the algorithm that\nfollows the self predictor is optimal but not robust to mispredictions of\nagent's future behavior; we give an algorithm with better robustness properties\nand benchmark it.", "published": "2025-07-15 08:52:12", "link": "http://arxiv.org/abs/2507.12486v1", "categories": ["cs.MA", "cs.AI", "cs.GT"], "primary_category": "cs.MA"}
{"title": "Differentially Private Conformal Prediction via Quantile Binary Search", "abstract": "Most Differentially Private (DP) approaches focus on limiting privacy leakage\nfrom learners based on the data that they are trained on, there are fewer\napproaches that consider leakage when procedures involve a calibration dataset\nwhich is common in uncertainty quantification methods such as Conformal\nPrediction (CP). Since there is a limited amount of approaches in this\ndirection, in this work we deliver a general DP approach for CP that we call\nPrivate Conformity via Quantile Search (P-COQS). The proposed approach adapts\nan existing randomized binary search algorithm for computing DP quantiles in\nthe calibration phase of CP thereby guaranteeing privacy of the consequent\nprediction sets. This however comes at a price of slightly under-covering with\nrespect to the desired $(1 - \\alpha)$-level when using finite-sample\ncalibration sets (although broad empirical results show that the P-COQS\ngenerally targets the required level in the considered cases). Confirming\nproperties of the adapted algorithm and quantifying the approximate coverage\nguarantees of the consequent CP, we conduct extensive experiments to examine\nthe effects of privacy noise, sample size and significance level on the\nperformance of our approach compared to existing alternatives. In addition, we\nempirically evaluate our approach on several benchmark datasets, including\nCIFAR-10, ImageNet and CoronaHack. Our results suggest that the proposed method\nis robust to privacy noise and performs favorably with respect to the current\nDP alternative in terms of empirical coverage, efficiency, and informativeness.\nSpecifically, the results indicate that P-COQS produces smaller conformal\nprediction sets while simultaneously targeting the desired coverage and privacy\nguarantees in all these experimental settings.", "published": "2025-07-15 22:08:02", "link": "http://arxiv.org/abs/2507.12497v1", "categories": ["stat.ME", "cs.LG", "stat.AP", "stat.CO", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Recent Advances in Simulation-based Inference for Gravitational Wave Data Analysis", "abstract": "The detection of gravitational waves by the LIGO-Virgo-KAGRA collaboration\nhas ushered in a new era of observational astronomy, emphasizing the need for\nrapid and detailed parameter estimation and population-level analyses.\nTraditional Bayesian inference methods, particularly Markov chain Monte Carlo,\nface significant computational challenges when dealing with the\nhigh-dimensional parameter spaces and complex noise characteristics inherent in\ngravitational wave data. This review examines the emerging role of\nsimulation-based inference methods in gravitational wave astronomy, with a\nfocus on approaches that leverage machine-learning techniques such as\nnormalizing flows and neural posterior estimation. We provide a comprehensive\noverview of the theoretical foundations underlying various simulation-based\ninference methods, including neural posterior estimation, neural ratio\nestimation, neural likelihood estimation, flow matching, and consistency\nmodels. We explore the applications of these methods across diverse\ngravitational wave data processing scenarios, from single-source parameter\nestimation and overlapping signal analysis to testing general relativity and\nconducting population studies. Although these techniques demonstrate speed\nimprovements over traditional methods in controlled studies, their\nmodel-dependent nature and sensitivity to prior assumptions are barriers to\ntheir widespread adoption. Their accuracy, which is similar to that of\nconventional methods, requires further validation across broader parameter\nspaces and noise conditions.", "published": "2025-07-15 10:52:57", "link": "http://arxiv.org/abs/2507.11192v3", "categories": ["gr-qc", "astro-ph.HE", "astro-ph.IM", "cs.LG", "stat.ML"], "primary_category": "gr-qc"}
{"title": "A Comprehensive Benchmark for Electrocardiogram Time-Series", "abstract": "Electrocardiogram~(ECG), a key bioelectrical time-series signal, is crucial\nfor assessing cardiac health and diagnosing various diseases. Given its\ntime-series format, ECG data is often incorporated into pre-training datasets\nfor large-scale time-series model training. However, existing studies often\noverlook its unique characteristics and specialized downstream applications,\nwhich differ significantly from other time-series data, leading to an\nincomplete understanding of its properties. In this paper, we present an\nin-depth investigation of ECG signals and establish a comprehensive benchmark,\nwhich includes (1) categorizing its downstream applications into four distinct\nevaluation tasks, (2) identifying limitations in traditional evaluation metrics\nfor ECG analysis, and introducing a novel metric; (3) benchmarking\nstate-of-the-art time-series models and proposing a new architecture. Extensive\nexperiments demonstrate that our proposed benchmark is comprehensive and\nrobust. The results validate the effectiveness of the proposed metric and model\narchitecture, which establish a solid foundation for advancing research in ECG\nsignal analysis.", "published": "2025-07-15 02:54:24", "link": "http://arxiv.org/abs/2507.14206v1", "categories": ["eess.SP", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "eess.SP"}
{"title": "Evaluating Speech-to-Text x LLM x Text-to-Speech Combinations for AI Interview Systems", "abstract": "Voice-based conversational AI systems increasingly rely on cascaded\narchitectures combining speech-to-text (STT), large language models (LLMs), and\ntext-to-speech (TTS) components. However, systematic evaluation of different\ncomponent combinations in production settings remains understudied. We present\na large-scale empirical comparison of STT x LLM x TTS stacks using data from\nover 300,000 AI-conducted job interviews. We develop an automated evaluation\nframework using LLM-as-a-Judge to assess conversational quality, technical\naccuracy, and skill assessment capabilities. Our analysis of four production\nconfigurations reveals that Google STT paired with GPT-4.1 significantly\noutperforms alternatives in both conversational and technical quality metrics.\nSurprisingly, we find that objective quality metrics correlate weakly with user\nsatisfaction scores, suggesting that user experience in voice-based AI systems\ndepends on factors beyond technical performance. Our findings provide practical\nguidance for selecting components in multimodal conversational AI systems and\ncontribute a validated evaluation methodology for voice-based interactions.", "published": "2025-07-15 22:30:55", "link": "http://arxiv.org/abs/2507.16835v1", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Towards Robust Speech Recognition for Jamaican Patois Music Transcription", "abstract": "Although Jamaican Patois is a widely spoken language, current speech\nrecognition systems perform poorly on Patois music, producing inaccurate\ncaptions that limit accessibility and hinder downstream applications. In this\nwork, we take a data-centric approach to this problem by curating more than 40\nhours of manually transcribed Patois music. We use this dataset to fine-tune\nstate-of-the-art automatic speech recognition (ASR) models, and use the results\nto develop scaling laws for the performance of Whisper models on Jamaican\nPatois audio. We hope that this work will have a positive impact on the\naccessibility of Jamaican Patois music and the future of Jamaican Patois\nlanguage modeling.", "published": "2025-07-15 03:42:05", "link": "http://arxiv.org/abs/2507.16834v1", "categories": ["eess.AS", "cs.AI", "cs.CL"], "primary_category": "eess.AS"}
{"title": "A Privacy-Preserving Federated Framework with Hybrid Quantum-Enhanced Learning for Financial Fraud Detection", "abstract": "Rapid growth of digital transactions has led to a surge in fraudulent\nactivities, challenging traditional detection methods in the financial sector.\nTo tackle this problem, we introduce a specialised federated learning framework\nthat uniquely combines a quantum-enhanced Long Short-Term Memory (LSTM) model\nwith advanced privacy preserving techniques. By integrating quantum layers into\nthe LSTM architecture, our approach adeptly captures complex\ncross-transactional patters, resulting in an approximate 5% performance\nimprovement across key evaluation metrics compared to conventional models.\nCentral to our framework is \"FedRansel\", a novel method designed to defend\nagainst poisoning and inference attacks, thereby reducing model degradation and\ninference accuracy by 4-8%, compared to standard differential privacy\nmechanisms. This pseudo-centralised setup with a Quantum LSTM model, enhances\nfraud detection accuracy and reinforces the security and confidentiality of\nsensitive financial data.", "published": "2025-07-15 17:29:12", "link": "http://arxiv.org/abs/2507.22908v1", "categories": ["q-fin.CP", "cs.AI", "cs.LG", "I.2"], "primary_category": "q-fin.CP"}
{"title": "Pricing energy spread options with variance gamma-driven Ornstein-Uhlenbeck dynamics", "abstract": "We consider the pricing of energy spread options for spot prices following an\nexponential Ornstein-Uhlenbeck process driven by a sum of independent\nmultivariate variance gamma processes, which gives rise to mean-reverting,\ninfinite activity price dynamics. Within this class of driving processes, the\nEsscher transform is used to obtain an equivalent martingale measure with a\nfocus on the weak variance alpha-gamma process. By deriving an analytic\nexpression for the cumulant generating function of the innovation term, we\nobtain a pricing formula for forwards and apply the FFT method of Hurd and Zhou\nto price spread options. Lastly, we demonstrate how the model should be both\nestimated on energy prices under the real world measure and calibrated on\nforward or call prices, and provide numerical results for the pricing of spread\noptions.", "published": "2025-07-15 16:48:24", "link": "http://arxiv.org/abs/2507.11480v2", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
