{"title": "Unsupervised Explanation Generation for Machine Reading Comprehension", "abstract": "With the blooming of various Pre-trained Language Models (PLMs), Machine\nReading Comprehension (MRC) has embraced significant improvements on various\nbenchmarks and even surpass human performances. However, the existing works\nonly target on the accuracy of the final predictions and neglect the importance\nof the explanations for the prediction, which is a big obstacle when utilizing\nthese models in real-life applications to convince humans. In this paper, we\npropose a self-explainable framework for the machine reading comprehension\ntask. The main idea is that the proposed system tries to use less passage\ninformation and achieve similar results compared to the system that uses the\nwhole passage, while the filtered passage will be used as explanations. We\ncarried out experiments on three multiple-choice MRC datasets, and found that\nthe proposed system could achieve consistent improvements over baseline\nsystems. To evaluate the explainability, we compared our approach with the\ntraditional attention mechanism in human evaluations and found that the\nproposed system has a notable advantage over the latter one.", "published": "2020-11-13 02:58:55", "link": "http://arxiv.org/abs/2011.06737v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Re-framing Incremental Deep Language Models for Dialogue Processing with\n  Multi-task Learning", "abstract": "We present a multi-task learning framework to enable the training of one\nuniversal incremental dialogue processing model with four tasks of disfluency\ndetection, language modelling, part-of-speech tagging, and utterance\nsegmentation in a simple deep recurrent setting. We show that these tasks\nprovide positive inductive biases to each other with the optimal contribution\nof each one relying on the severity of the noise from the task. Our live\nmulti-task model outperforms similar individual tasks, delivers competitive\nperformance, and is beneficial for future use in conversational agents in\npsychiatric treatment.", "published": "2020-11-13 04:31:51", "link": "http://arxiv.org/abs/2011.06754v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-Domain Learning for Classifying Propaganda in Online Contents", "abstract": "As news and social media exhibit an increasing amount of manipulative\npolarized content, detecting such propaganda has received attention as a new\ntask for content analysis. Prior work has focused on supervised learning with\ntraining data from the same domain. However, as propaganda can be subtle and\nkeeps evolving, manual identification and proper labeling are very demanding.\nAs a consequence, training data is a major bottleneck. In this paper, we tackle\nthis bottleneck and present an approach to leverage cross-domain learning,\nbased on labeled documents and sentences from news and tweets, as well as\npolitical speeches with a clear difference in their degrees of being\npropagandistic. We devise informative features and build various classifiers\nfor propaganda labeling, using cross-domain learning. Our experiments\ndemonstrate the usefulness of this approach, and identify difficulties and\nlimitations in various configurations of sources and targets for the transfer\nstep. We further analyze the influence of various features, and characterize\nsalient indicators of propaganda.", "published": "2020-11-13 10:19:13", "link": "http://arxiv.org/abs/2011.06844v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Interpretable Multi-dataset Evaluation for Named Entity Recognition", "abstract": "With the proliferation of models for natural language processing tasks, it is\neven harder to understand the differences between models and their relative\nmerits. Simply looking at differences between holistic metrics such as\naccuracy, BLEU, or F1 does not tell us why or how particular methods perform\ndifferently and how diverse datasets influence the model design choices. In\nthis paper, we present a general methodology for interpretable evaluation for\nthe named entity recognition (NER) task. The proposed evaluation method enables\nus to interpret the differences in models and datasets, as well as the\ninterplay between them, identifying the strengths and weaknesses of current\nsystems. By making our analysis tool available, we make it easy for future\nresearchers to run similar analyses and drive progress in this area:\nhttps://github.com/neulab/InterpretEval.", "published": "2020-11-13 10:53:27", "link": "http://arxiv.org/abs/2011.06854v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RethinkCWS: Is Chinese Word Segmentation a Solved Task?", "abstract": "The performance of the Chinese Word Segmentation (CWS) systems has gradually\nreached a plateau with the rapid development of deep neural networks,\nespecially the successful use of large pre-trained models. In this paper, we\ntake stock of what we have achieved and rethink what's left in the CWS task.\nMethodologically, we propose a fine-grained evaluation for existing CWS\nsystems, which not only allows us to diagnose the strengths and weaknesses of\nexisting models (under the in-dataset setting), but enables us to quantify the\ndiscrepancy between different criterion and alleviate the negative transfer\nproblem when doing multi-criteria learning. Strategically, despite not aiming\nto propose a novel model in this paper, our comprehensive experiments on eight\nmodels and seven datasets, as well as thorough analysis, could search for some\npromising direction for future research. We make all codes publicly available\nand release an interface that can quickly evaluate and diagnose user's models:\nhttps://github.com/neulab/InterpretEval.", "published": "2020-11-13 11:07:08", "link": "http://arxiv.org/abs/2011.06858v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FLERT: Document-Level Features for Named Entity Recognition", "abstract": "Current state-of-the-art approaches for named entity recognition (NER)\ntypically consider text at the sentence-level and thus do not model information\nthat crosses sentence boundaries. However, the use of transformer-based models\nfor NER offers natural options for capturing document-level features. In this\npaper, we perform a comparative evaluation of document-level features in the\ntwo standard NER architectures commonly considered in the literature, namely\n\"fine-tuning\" and \"feature-based LSTM-CRF\". We evaluate different\nhyperparameters for document-level features such as context window size and\nenforcing document-locality. We present experiments from which we derive\nrecommendations for how to model document context and present new\nstate-of-the-art scores on several CoNLL-03 benchmark datasets. Our approach is\nintegrated into the Flair framework to facilitate reproduction of our\nexperiments.", "published": "2020-11-13 16:13:59", "link": "http://arxiv.org/abs/2011.06993v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Teacher-Student Chatroom Corpus", "abstract": "The Teacher-Student Chatroom Corpus (TSCC) is a collection of written\nconversations captured during one-to-one lessons between teachers and learners\nof English. The lessons took place in an online chatroom and therefore involve\nmore interactive, immediate and informal language than might be found in\nasynchronous exchanges such as email correspondence. The fact that the lessons\nwere one-to-one means that the teacher was able to focus exclusively on the\nlinguistic abilities and errors of the student, and to offer personalised\nexercises, scaffolding and correction. The TSCC contains more than one hundred\nlessons between two teachers and eight students, amounting to 13.5K\nconversational turns and 133K words: it is freely available for research use.\nWe describe the corpus design, data collection procedure and annotations added\nto the text. We perform some preliminary descriptive analyses of the data and\nconsider possible uses of the TSCC.", "published": "2020-11-13 19:58:38", "link": "http://arxiv.org/abs/2011.07109v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IIRC: A Dataset of Incomplete Information Reading Comprehension\n  Questions", "abstract": "Humans often have to read multiple documents to address their information\nneeds. However, most existing reading comprehension (RC) tasks only focus on\nquestions for which the contexts provide all the information required to answer\nthem, thus not evaluating a system's performance at identifying a potential\nlack of sufficient information and locating sources for that information. To\nfill this gap, we present a dataset, IIRC, with more than 13K questions over\nparagraphs from English Wikipedia that provide only partial information to\nanswer them, with the missing information occurring in one or more linked\ndocuments. The questions were written by crowd workers who did not have access\nto any of the linked documents, leading to questions that have little lexical\noverlap with the contexts where the answers appear. This process also gave many\nquestions without answers, and those that require discrete reasoning,\nincreasing the difficulty of the task. We follow recent modeling work on\nvarious reading comprehension datasets to construct a baseline model for this\ndataset, finding that it achieves 31.1% F1 on this task, while estimated human\nperformance is 88.4%. The dataset, code for the baseline system, and a\nleaderboard can be found at https://allennlp.org/iirc.", "published": "2020-11-13 20:59:21", "link": "http://arxiv.org/abs/2011.07127v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language Models not just for Pre-training: Fast Online Neural Noisy\n  Channel Modeling", "abstract": "Pre-training models on vast quantities of unlabeled data has emerged as an\neffective approach to improving accuracy on many NLP tasks. On the other hand,\ntraditional machine translation has a long history of leveraging unlabeled data\nthrough noisy channel modeling. The same idea has recently been shown to\nachieve strong improvements for neural machine translation. Unfortunately,\nna\\\"{i}ve noisy channel modeling with modern sequence to sequence models is up\nto an order of magnitude slower than alternatives. We address this issue by\nintroducing efficient approximations to make inference with the noisy channel\napproach as fast as strong ensembles while increasing accuracy. We also show\nthat the noisy channel approach can outperform strong pre-training results by\nachieving a new state of the art on WMT Romanian-English translation.", "published": "2020-11-13 23:22:28", "link": "http://arxiv.org/abs/2011.07164v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey on Recent Advances in Sequence Labeling from Deep Learning\n  Models", "abstract": "Sequence labeling (SL) is a fundamental research problem encompassing a\nvariety of tasks, e.g., part-of-speech (POS) tagging, named entity recognition\n(NER), text chunking, etc. Though prevalent and effective in many downstream\napplications (e.g., information retrieval, question answering, and knowledge\ngraph embedding), conventional sequence labeling approaches heavily rely on\nhand-crafted or language-specific features. Recently, deep learning has been\nemployed for sequence labeling tasks due to its powerful capability in\nautomatically learning complex features of instances and effectively yielding\nthe stat-of-the-art performances. In this paper, we aim to present a\ncomprehensive review of existing deep learning-based sequence labeling models,\nwhich consists of three related tasks, e.g., part-of-speech tagging, named\nentity recognition, and text chunking. Then, we systematically present the\nexisting approaches base on a scientific taxonomy, as well as the widely-used\nexperimental datasets and popularly-adopted evaluation metrics in the SL\ndomain. Furthermore, we also present an in-depth analysis of different SL\nmodels on the factors that may affect the performance and future directions in\nthe SL domain.", "published": "2020-11-13 02:29:50", "link": "http://arxiv.org/abs/2011.06727v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "diagNNose: A Library for Neural Activation Analysis", "abstract": "In this paper we introduce diagNNose, an open source library for analysing\nthe activations of deep neural networks. diagNNose contains a wide array of\ninterpretability techniques that provide fundamental insights into the inner\nworkings of neural networks. We demonstrate the functionality of diagNNose with\na case study on subject-verb agreement within language models. diagNNose is\navailable at https://github.com/i-machine-think/diagnnose.", "published": "2020-11-13 09:19:48", "link": "http://arxiv.org/abs/2011.06819v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "EDITOR: an Edit-Based Transformer with Repositioning for Neural Machine\n  Translation with Soft Lexical Constraints", "abstract": "We introduce an Edit-Based Transformer with Repositioning (EDITOR), which\nmakes sequence generation flexible by seamlessly allowing users to specify\npreferences in output lexical choice. Building on recent models for\nnon-autoregressive sequence generation (Gu et al., 2019), EDITOR generates new\nsequences by iteratively editing hypotheses. It relies on a novel reposition\noperation designed to disentangle lexical choice from word positioning\ndecisions, while enabling efficient oracles for imitation learning and parallel\nedits at decoding time. Empirically, EDITOR uses soft lexical constraints more\neffectively than the Levenshtein Transformer (Gu et al., 2019) while speeding\nup decoding dramatically compared to constrained beam search (Post and Vilar,\n2018). EDITOR also achieves comparable or better translation quality with\nfaster decoding speed than the Levenshtein Transformer on standard\nRomanian-English, English-German, and English-Japanese machine translation\ntasks.", "published": "2020-11-13 11:47:28", "link": "http://arxiv.org/abs/2011.06868v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning language variations in news corpora through differential\n  embeddings", "abstract": "There is an increasing interest in the NLP community in capturing variations\nin the usage of language, either through time (i.e., semantic drift), across\nregions (as dialects or variants) or in different social contexts (i.e.,\nprofessional or media technolects). Several successful dynamical embeddings\nhave been proposed that can track semantic change through time. Here we show\nthat a model with a central word representation and a slice-dependent\ncontribution can learn word embeddings from different corpora simultaneously.\nThis model is based on a star-like representation of the slices. We apply it to\nThe New York Times and The Guardian newspapers, and we show that it can capture\nboth temporal dynamics in the yearly slices of each corpus, and language\nvariations between US and UK English in a curated multi-source corpus. We\nprovide an extensive evaluation of this methodology.", "published": "2020-11-13 14:50:08", "link": "http://arxiv.org/abs/2011.06949v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Arabic Dialect Identification Using BERT-Based Domain Adaptation", "abstract": "Arabic is one of the most important and growing languages in the world. With\nthe rise of social media platforms such as Twitter, Arabic spoken dialects have\nbecome more in use. In this paper, we describe our approach on the NADI Shared\nTask 1 that requires us to build a system to differentiate between different 21\nArabic dialects, we introduce a deep learning semi-supervised fashion approach\nalong with pre-processing that was reported on NADI shared Task 1 Corpus. Our\nsystem ranks 4th in NADI's shared task competition achieving a 23.09% F1 macro\naverage score with a simple yet efficient approach to differentiating between\n21 Arabic Dialects given tweets.", "published": "2020-11-13 15:52:51", "link": "http://arxiv.org/abs/2011.06977v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Zero-shot Relation Classification from Side Information", "abstract": "We propose a zero-shot learning relation classification (ZSLRC) framework\nthat improves on state-of-the-art by its ability to recognize novel relations\nthat were not present in training data. The zero-shot learning approach mimics\nthe way humans learn and recognize new concepts with no prior knowledge. To\nachieve this, ZSLRC uses advanced prototypical networks that are modified to\nutilize weighted side (auxiliary) information. ZSLRC's side information is\nbuilt from keywords, hypernyms of name entities, and labels and their synonyms.\nZSLRC also includes an automatic hypernym extraction framework that acquires\nhypernyms of various name entities directly from the web. ZSLRC improves on\nstate-of-the-art few-shot learning relation classification methods that rely on\nlabeled training data and is therefore applicable more widely even in\nreal-world scenarios where some relations have no corresponding labeled\nexamples for training. We present results using extensive experiments on two\npublic datasets (NYT and FewRel) and show that ZSLRC significantly outperforms\nstate-of-the-art methods on supervised learning, few-shot learning, and\nzero-shot learning tasks. Our experimental results also demonstrate the\neffectiveness and robustness of our proposed model.", "published": "2020-11-13 20:57:53", "link": "http://arxiv.org/abs/2011.07126v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Low-activity supervised convolutional spiking neural networks applied to\n  speech commands recognition", "abstract": "Deep Neural Networks (DNNs) are the current state-of-the-art models in many\nspeech related tasks. There is a growing interest, though, for more\nbiologically realistic, hardware friendly and energy efficient models, named\nSpiking Neural Networks (SNNs). Recently, it has been shown that SNNs can be\ntrained efficiently, in a supervised manner, using backpropagation with a\nsurrogate gradient trick. In this work, we report speech command (SC)\nrecognition experiments using supervised SNNs. We explored the\nLeaky-Integrate-Fire (LIF) neuron model for this task, and show that a model\ncomprised of stacked dilated convolution spiking layers can reach an error rate\nvery close to standard DNNs on the Google SC v1 dataset: 5.5%, while keeping a\nvery sparse spiking activity, below 5%, thank to a new regularization term. We\nalso show that modeling the leakage of the neuron membrane potential is useful,\nsince the LIF model outperformed its non-leaky model counterpart significantly.", "published": "2020-11-13 10:29:35", "link": "http://arxiv.org/abs/2011.06846v1", "categories": ["cs.LG", "cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Multi-Modal Emotion Detection with Transfer Learning", "abstract": "Automated emotion detection in speech is a challenging task due to the\ncomplex interdependence between words and the manner in which they are spoken.\nIt is made more difficult by the available datasets; their small size and\nincompatible labeling idiosyncrasies make it hard to build generalizable\nemotion detection systems. To address these two challenges, we present a\nmulti-modal approach that first transfers learning from related tasks in speech\nand text to produce robust neural embeddings and then uses these embeddings to\ntrain a pLDA classifier that is able to adapt to previously unseen emotions and\ndomains. We begin by training a multilayer TDNN on the task of speaker\nidentification with the VoxCeleb corpora and then fine-tune it on the task of\nemotion identification with the Crema-D corpus. Using this network, we extract\nspeech embeddings for Crema-D from each of its layers, generate and concatenate\ntext embeddings for the accompanying transcripts using a fine-tuned BERT model\nand then train an LDA - pLDA classifier on the resulting dense representations.\nWe exhaustively evaluate the predictive power of every component: the TDNN\nalone, speech embeddings from each of its layers alone, text embeddings alone\nand every combination thereof. Our best variant, trained on only VoxCeleb and\nCrema-D and evaluated on IEMOCAP, achieves an EER of 38.05%. Including a\nportion of IEMOCAP during training produces a 5-fold averaged EER of 25.72%\n(For comparison, 44.71% of the gold-label annotations include at least one\nannotator who disagrees).", "published": "2020-11-13 18:58:59", "link": "http://arxiv.org/abs/2011.07065v1", "categories": ["eess.AS", "cs.CL", "cs.HC", "cs.LG"], "primary_category": "eess.AS"}
{"title": "The SLT 2021 children speech recognition challenge: Open datasets, rules\n  and baselines", "abstract": "Automatic speech recognition (ASR) has been significantly advanced with the\nuse of deep learning and big data. However improving robustness, including\nachieving equally good performance on diverse speakers and accents, is still a\nchallenging problem. In particular, the performance of children speech\nrecognition (CSR) still lags behind due to 1) the speech and language\ncharacteristics of children's voice are substantially different from those of\nadults and 2) sizable open dataset for children speech is still not available\nin the research community. To address these problems, we launch the Children\nSpeech Recognition Challenge (CSRC), as a flagship satellite event of IEEE SLT\n2021 workshop. The challenge will release about 400 hours of Mandarin speech\ndata for registered teams and set up two challenge tracks and provide a common\ntestbed to benchmark the CSR performance. In this paper, we introduce the\ndatasets, rules, evaluation method as well as baselines.", "published": "2020-11-13 02:11:42", "link": "http://arxiv.org/abs/2011.06724v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Generalized Dilated CNN Models for Depression Detection Using Inverted\n  Vocal Tract Variables", "abstract": "Depression detection using vocal biomarkers is a highly researched area.\nArticulatory coordination features (ACFs) are developed based on the changes in\nneuromotor coordination due to psychomotor slowing, a key feature of Major\nDepressive Disorder. However findings of existing studies are mostly validated\non a single database which limits the generalizability of results. Variability\nacross different depression databases adversely affects the results in cross\ncorpus evaluations (CCEs). We propose to develop a generalized classifier for\ndepression detection using a dilated Convolutional Neural Network which is\ntrained on ACFs extracted from two depression databases. We show that ACFs\nderived from Vocal Tract Variables (TVs) show promise as a robust set of\nfeatures for depression detection. Our model achieves relative accuracy\nimprovements of ~10% compared to CCEs performed on models trained on a single\ndatabase. We extend the study to show that fusing TVs and Mel-Frequency\nCepstral Coefficients can further improve the performance of this classifier.", "published": "2020-11-13 03:12:36", "link": "http://arxiv.org/abs/2011.06739v3", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "A Comprehensive Survey on Deep Music Generation: Multi-level\n  Representations, Algorithms, Evaluations, and Future Directions", "abstract": "The utilization of deep learning techniques in generating various contents\n(such as image, text, etc.) has become a trend. Especially music, the topic of\nthis paper, has attracted widespread attention of countless researchers.The\nwhole process of producing music can be divided into three stages,\ncorresponding to the three levels of music generation: score generation\nproduces scores, performance generation adds performance characteristics to the\nscores, and audio generation converts scores with performance characteristics\ninto audio by assigning timbre or generates music in audio format directly.\nPrevious surveys have explored the network models employed in the field of\nautomatic music generation. However, the development history, the model\nevolution, as well as the pros and cons of same music generation task have not\nbeen clearly illustrated. This paper attempts to provide an overview of various\ncomposition tasks under different music generation levels, covering most of the\ncurrently popular music generation tasks using deep learning. In addition, we\nsummarize the datasets suitable for diverse tasks, discuss the music\nrepresentations, the evaluation methods as well as the challenges under\ndifferent levels, and finally point out several future directions.", "published": "2020-11-13 08:01:20", "link": "http://arxiv.org/abs/2011.06801v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
