{"title": "Phrase Table as Recommendation Memory for Neural Machine Translation", "abstract": "Neural Machine Translation (NMT) has drawn much attention due to its\npromising translation performance recently. However, several studies indicate\nthat NMT often generates fluent but unfaithful translations. In this paper, we\npropose a method to alleviate this problem by using a phrase table as\nrecommendation memory. The main idea is to add bonus to words worthy of\nrecommendation, so that NMT can make correct predictions. Specifically, we\nfirst derive a prefix tree to accommodate all the candidate target phrases by\nsearching the phrase translation table according to the source sentence. Then,\nwe construct a recommendation word set by matching between candidate target\nphrases and previously translated target words by NMT. After that, we determine\nthe specific bonus value for each recommendable word by using the attention\nvector and phrase translation probability. Finally, we integrate this bonus\nvalue into NMT to improve the translation results. The extensive experiments\ndemonstrate that the proposed methods obtain remarkable improvements over the\nstrong attentionbased NMT.", "published": "2018-05-25 03:14:27", "link": "http://arxiv.org/abs/1805.09960v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lifelong Domain Word Embedding via Meta-Learning", "abstract": "Learning high-quality domain word embeddings is important for achieving good\nperformance in many NLP tasks. General-purpose embeddings trained on\nlarge-scale corpora are often sub-optimal for domain-specific applications.\nHowever, domain-specific tasks often do not have large in-domain corpora for\ntraining high-quality domain embeddings. In this paper, we propose a novel\nlifelong learning setting for domain embedding. That is, when performing the\nnew domain embedding, the system has seen many past domains, and it tries to\nexpand the new in-domain corpus by exploiting the corpora from the past domains\nvia meta-learning. The proposed meta-learner characterizes the similarities of\nthe contexts of the same word in many domain corpora, which helps retrieve\nrelevant data from the past domains to expand the new domain corpus.\nExperimental results show that domain embeddings produced from such a process\nimprove the performance of the downstream tasks.", "published": "2018-05-25 06:10:54", "link": "http://arxiv.org/abs/1805.09991v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Japanese Predicate Conjugation for Neural Machine Translation", "abstract": "Neural machine translation (NMT) has a drawback in that can generate only\nhigh-frequency words owing to the computational costs of the softmax function\nin the output layer.\n  In Japanese-English NMT, Japanese predicate conjugation causes an increase in\nvocabulary size. For example, one verb can have as many as 19 surface\nvarieties. In this research, we focus on predicate conjugation for compressing\nthe vocabulary size in Japanese. The vocabulary list is filled with the various\nforms of verbs. We propose methods using predicate conjugation information\nwithout discarding linguistic information. The proposed methods can generate\nlow-frequency words and deal with unknown words. Two methods were considered to\nintroduce conjugation information: the first considers it as a token\n(conjugation token) and the second considers it as an embedded vector\n(conjugation feature).\n  The results using these methods demonstrate that the vocabulary size can be\ncompressed by approximately 86.1% (Tanaka corpus) and the NMT models can output\nthe words not in the training data set. Furthermore, BLEU scores improved by\n0.91 points in Japanese-to-English translation, and 0.32 points in\nEnglish-to-Japanese translation with ASPEC.", "published": "2018-05-25 08:56:43", "link": "http://arxiv.org/abs/1805.10047v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Context-Aware Neural Machine Translation Learns Anaphora Resolution", "abstract": "Standard machine translation systems process sentences in isolation and hence\nignore extra-sentential information, even though extended context can both\nprevent mistakes in ambiguous cases and improve translation coherence. We\nintroduce a context-aware neural machine translation model designed in such way\nthat the flow of information from the extended context to the translation model\ncan be controlled and analyzed. We experiment with an English-Russian subtitles\ndataset, and observe that much of what is captured by our model deals with\nimproving pronoun translation. We measure correspondences between induced\nattention distributions and coreference relations and observe that the model\nimplicitly captures anaphora. It is consistent with gains for sentences where\npronouns need to be gendered in translation. Beside improvements in anaphoric\ncases, the model also improves in overall BLEU, both over its context-agnostic\nversion (+0.7) and over simple concatenation of the context and source\nsentences (+0.6).", "published": "2018-05-25 14:03:27", "link": "http://arxiv.org/abs/1805.10163v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Recursive Neural Network Based Preordering for English-to-Japanese\n  Machine Translation", "abstract": "The word order between source and target languages significantly influences\nthe translation quality in machine translation. Preordering can effectively\naddress this problem. Previous preordering methods require a manual feature\ndesign, making language dependent design costly. In this paper, we propose a\npreordering method with a recursive neural network that learns features from\nraw inputs. Experiments show that the proposed method achieves comparable gain\nin translation quality to the state-of-the-art method but without a manual\nfeature design.", "published": "2018-05-25 15:00:30", "link": "http://arxiv.org/abs/1805.10187v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Situated Mapping of Sequential Instructions to Actions with Single-step\n  Reward Observation", "abstract": "We propose a learning approach for mapping context-dependent sequential\ninstructions to actions. We address the problem of discourse and state\ndependencies with an attention-based model that considers both the history of\nthe interaction and the state of the world. To train from start and goal states\nwithout access to demonstrations, we propose SESTRA, a learning algorithm that\ntakes advantage of single-step reward observations and immediate expected\nreward maximization. We evaluate on the SCONE domains, and show absolute\naccuracy improvements of 9.8%-25.3% across the domains over approaches that use\nhigh-level logical representations.", "published": "2018-05-25 15:47:38", "link": "http://arxiv.org/abs/1805.10209v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Argument Generation Augmented with Externally Retrieved Evidence", "abstract": "High quality arguments are essential elements for human reasoning and\ndecision-making processes. However, effective argument construction is a\nchallenging task for both human and machines. In this work, we study a novel\ntask on automatically generating arguments of a different stance for a given\nstatement. We propose an encoder-decoder style neural network-based argument\ngeneration model enriched with externally retrieved evidence from Wikipedia.\nOur model first generates a set of talking point phrases as intermediate\nrepresentation, followed by a separate decoder producing the final argument\nbased on both input and the keyphrases. Experiments on a large-scale dataset\ncollected from Reddit show that our model constructs arguments with more\ntopic-relevant content than a popular sequence-to-sequence generation model\naccording to both automatic evaluation and human assessments.", "published": "2018-05-25 17:12:03", "link": "http://arxiv.org/abs/1805.10254v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Duluth UROP at SemEval-2018 Task 2: Multilingual Emoji Prediction with\n  Ensemble Learning and Oversampling", "abstract": "This paper describes the Duluth UROP systems that participated in\nSemEval--2018 Task 2, Multilingual Emoji Prediction. We relied on a variety of\nensembles made up of classifiers using Naive Bayes, Logistic Regression, and\nRandom Forests. We used unigram and bigram features and tried to offset the\nskewness of the data through the use of oversampling. Our task evaluation\nresults place us 19th of 48 systems in the English evaluation, and 5th of 21 in\nthe Spanish. After the evaluation we realized that some simple changes to\npreprocessing could significantly improve our results. After making these\nchanges we attained results that would have placed us sixth in the English\nevaluation, and second in the Spanish.", "published": "2018-05-25 17:36:51", "link": "http://arxiv.org/abs/1805.10267v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UMDuluth-CS8761 at SemEval-2018 Task 9: Hypernym Discovery using Hearst\n  Patterns, Co-occurrence frequencies and Word Embeddings", "abstract": "Hypernym Discovery is the task of identifying potential hypernyms for a given\nterm. A hypernym is a more generalized word that is super-ordinate to more\nspecific words. This paper explores several approaches that rely on\nco-occurrence frequencies of word pairs, Hearst Patterns based on regular\nexpressions, and word embeddings created from the UMBC corpus. Our system\nBabbage participated in Subtask 1A for English and placed 6th of 19 systems\nwhen identifying concept hypernyms, and 12th of 18 systems for entity\nhypernyms.", "published": "2018-05-25 17:44:03", "link": "http://arxiv.org/abs/1805.10271v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UMDSub at SemEval-2018 Task 2: Multilingual Emoji Prediction\n  Multi-channel Convolutional Neural Network on Subword Embedding", "abstract": "This paper describes the UMDSub system that participated in Task 2 of\nSemEval-2018. We developed a system that predicts an emoji given the raw text\nin a English tweet. The system is a Multi-channel Convolutional Neural Network\nbased on subword embeddings for the representation of tweets. This model\nimproves on character or word based methods by about 2\\%. Our system placed\n21st of 48 participating systems in the official evaluation.", "published": "2018-05-25 17:48:20", "link": "http://arxiv.org/abs/1805.10274v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mixed-Precision Training for NLP and Speech Recognition with OpenSeq2Seq", "abstract": "We present OpenSeq2Seq - a TensorFlow-based toolkit for training\nsequence-to-sequence models that features distributed and mixed-precision\ntraining. Benchmarks on machine translation and speech recognition tasks show\nthat models built using OpenSeq2Seq give state-of-the-art performance at 1.5-3x\nless training time. OpenSeq2Seq currently provides building blocks for models\nthat solve a wide range of tasks including neural machine translation,\nautomatic speech recognition, and speech synthesis.", "published": "2018-05-25 22:54:38", "link": "http://arxiv.org/abs/1805.10387v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Study of Question Effectiveness Using Reddit \"Ask Me Anything\" Threads", "abstract": "Asking effective questions is a powerful social skill. In this paper we seek\nto build computational models that learn to discriminate effective questions\nfrom ineffective ones. Armed with such a capability, future advanced systems\ncan evaluate the quality of questions and provide suggestions for effective\nquestion wording. We create a large-scale, real-world dataset that contains\nover 400,000 questions collected from Reddit \"Ask Me Anything\" threads. Each\nthread resembles an online press conference where questions compete with each\nother for attention from the host. This dataset enables the development of a\nclass of computational models for predicting whether a question will be\nanswered. We develop a new convolutional neural network architecture with\nvariable-length context and demonstrate the efficacy of the model by comparing\nit with state-of-the-art baselines and human judges.", "published": "2018-05-25 23:00:03", "link": "http://arxiv.org/abs/1805.10389v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Toward Extractive Summarization of Online Forum Discussions via\n  Hierarchical Attention Networks", "abstract": "Forum threads are lengthy and rich in content. Concise thread summaries will\nbenefit both newcomers seeking information and those who participate in the\ndiscussion. Few studies, however, have examined the task of forum thread\nsummarization. In this work we make the first attempt to adapt the hierarchical\nattention networks for thread summarization. The model draws on the recent\ndevelopment of neural attention mechanisms to build sentence and thread\nrepresentations and use them for summarization. Our results indicate that the\nproposed approach can outperform a range of competitive baselines. Further, a\nredundancy removal step is crucial for achieving outstanding results.", "published": "2018-05-25 23:01:01", "link": "http://arxiv.org/abs/1805.10390v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reinforced Extractive Summarization with Question-Focused Rewards", "abstract": "We investigate a new training paradigm for extractive summarization.\nTraditionally, human abstracts are used to derive goldstandard labels for\nextraction units. However, the labels are often inaccurate, because human\nabstracts and source documents cannot be easily aligned at the word level. In\nthis paper we convert human abstracts to a set of Cloze-style comprehension\nquestions. System summaries are encouraged to preserve salient source content\nuseful for answering questions and share common words with the abstracts. We\nuse reinforcement learning to explore the space of possible extractive\nsummaries and introduce a question-focused reward function to promote concise,\nfluent, and informative summaries. Our experiments show that the proposed\nmethod is effective. It surpasses state-of-the-art systems on the standard\nsummarization dataset.", "published": "2018-05-25 23:05:48", "link": "http://arxiv.org/abs/1805.10392v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modeling Language Vagueness in Privacy Policies using Deep Neural\n  Networks", "abstract": "Website privacy policies are too long to read and difficult to understand.\nThe over-sophisticated language makes privacy notices to be less effective than\nthey should be. People become even less willing to share their personal\ninformation when they perceive the privacy policy as vague. This paper focuses\non decoding vagueness from a natural language processing perspective. While\nthoroughly identifying the vague terms and their linguistic scope remains an\nelusive challenge, in this work we seek to learn vector representations of\nwords in privacy policies using deep neural networks. The vector\nrepresentations are fed to an interactive visualization tool (LSTMVis) to test\non their ability to discover syntactically and semantically related vague\nterms. The approach holds promise for modeling and understanding language\nvagueness.", "published": "2018-05-25 23:13:41", "link": "http://arxiv.org/abs/1805.10393v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Summarization of Student Course Feedback", "abstract": "Student course feedback is generated daily in both classrooms and online\ncourse discussion forums. Traditionally, instructors manually analyze these\nresponses in a costly manner. In this work, we propose a new approach to\nsummarizing student course feedback based on the integer linear programming\n(ILP) framework. Our approach allows different student responses to share\nco-occurrence statistics and alleviates sparsity issues. Experimental results\non a student feedback corpus show that our approach outperforms a range of\nbaselines in terms of both ROUGE scores and human evaluation.", "published": "2018-05-25 23:36:33", "link": "http://arxiv.org/abs/1805.10395v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Improved Phrase-based Approach to Annotating and Summarizing Student\n  Course Responses", "abstract": "Teaching large classes remains a great challenge, primarily because it is\ndifficult to attend to all the student needs in a timely manner. Automatic text\nsummarization systems can be leveraged to summarize the student feedback,\nsubmitted immediately after each lecture, but it is left to be discovered what\nmakes a good summary for student responses. In this work we explore a new\nmethodology that effectively extracts summary phrases from the student\nresponses. Each phrase is tagged with the number of students who raise the\nissue. The phrases are evaluated along two dimensions: with respect to text\ncontent, they should be informative and well-formed, measured by the ROUGE\nmetric; additionally, they shall attend to the most pressing student needs,\nmeasured by a newly proposed metric. This work is enabled by a phrase-based\nannotation and highlighting scheme, which is new to the summarization task. The\nphrase-based framework allows us to summarize the student responses into a set\nof bullet points and present to the instructor promptly.", "published": "2018-05-25 23:38:36", "link": "http://arxiv.org/abs/1805.10396v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Toward Abstractive Summarization Using Semantic Representations", "abstract": "We present a novel abstractive summarization framework that draws on the\nrecent development of a treebank for the Abstract Meaning Representation (AMR).\nIn this framework, the source text is parsed to a set of AMR graphs, the graphs\nare transformed into a summary graph, and then text is generated from the\nsummary graph. We focus on the graph-to-graph transformation that reduces the\nsource semantic graph into a summary graph, making use of an existing AMR\nparser and assuming the eventual availability of an AMR-to-text generator. The\nframework is data-driven, trainable, and not specifically designed for a\nparticular domain. Experiments on gold-standard AMR annotations and system\nparses show promising results. Code is available at:\nhttps://github.com/summarization", "published": "2018-05-25 23:46:11", "link": "http://arxiv.org/abs/1805.10399v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Sentiment Analysis of Breast Cancer Treatment Experiences and\n  Healthcare Perceptions Across Twitter", "abstract": "Background: Social media has the capacity to afford the healthcare industry\nwith valuable feedback from patients who reveal and express their medical\ndecision-making process, as well as self-reported quality of life indicators\nboth during and post treatment. In prior work, [Crannell et. al.], we have\nstudied an active cancer patient population on Twitter and compiled a set of\ntweets describing their experience with this disease. We refer to these online\npublic testimonies as \"Invisible Patient Reported Outcomes\" (iPROs), because\nthey carry relevant indicators, yet are difficult to capture by conventional\nmeans of self-report. Methods: Our present study aims to identify tweets\nrelated to the patient experience as an additional informative tool for\nmonitoring public health. Using Twitter's public streaming API, we compiled\nover 5.3 million \"breast cancer\" related tweets spanning September 2016 until\nmid December 2017. We combined supervised machine learning methods with natural\nlanguage processing to sift tweets relevant to breast cancer patient\nexperiences. We analyzed a sample of 845 breast cancer patient and survivor\naccounts, responsible for over 48,000 posts. We investigated tweet content with\na hedonometric sentiment analysis to quantitatively extract emotionally charged\ntopics. Results: We found that positive experiences were shared regarding\npatient treatment, raising support, and spreading awareness. Further\ndiscussions related to healthcare were prevalent and largely negative focusing\non fear of political legislation that could result in loss of coverage.\nConclusions: Social media can provide a positive outlet for patients to discuss\ntheir needs and concerns regarding their healthcare coverage and treatment\nneeds. Capturing iPROs from online communication can help inform healthcare\nprofessionals and lead to more connected and personalized treatment regimens.", "published": "2018-05-25 03:13:49", "link": "http://arxiv.org/abs/1805.09959v2", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Snips Voice Platform: an embedded Spoken Language Understanding system\n  for private-by-design voice interfaces", "abstract": "This paper presents the machine learning architecture of the Snips Voice\nPlatform, a software solution to perform Spoken Language Understanding on\nmicroprocessors typical of IoT devices. The embedded inference is fast and\naccurate while enforcing privacy by design, as no personal user data is ever\ncollected. Focusing on Automatic Speech Recognition and Natural Language\nUnderstanding, we detail our approach to training high-performance Machine\nLearning models that are small enough to run in real-time on small devices.\nAdditionally, we describe a data generation procedure that provides sufficient,\nhigh-quality training data without compromising user privacy.", "published": "2018-05-25 15:04:17", "link": "http://arxiv.org/abs/1805.10190v3", "categories": ["cs.CL", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Zero-Shot Dual Machine Translation", "abstract": "Neural Machine Translation (NMT) systems rely on large amounts of parallel\ndata. This is a major challenge for low-resource languages. Building on recent\nwork on unsupervised and semi-supervised methods, we present an approach that\ncombines zero-shot and dual learning. The latter relies on reinforcement\nlearning, to exploit the duality of the machine translation task, and requires\nonly monolingual data for the target language pair. Experiments show that a\nzero-shot dual system, trained on English-French and English-Spanish,\noutperforms by large margins a standard NMT system in zero-shot translation\nperformance on Spanish-French (both directions). The zero-shot dual method\napproaches the performance, within 2.2 BLEU points, of a comparable supervised\nsetting. Our method can obtain improvements also on the setting where a small\namount of parallel data for the zero-shot language pair is available. Adding\nRussian, to extend our experiments to jointly modeling 6 zero-shot translation\ndirections, all directions improve between 4 and 15 BLEU points, again,\nreaching performance near that of the supervised setting.", "published": "2018-05-25 19:27:43", "link": "http://arxiv.org/abs/1805.10338v1", "categories": ["cs.CL", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Think Visually: Question Answering through Virtual Imagery", "abstract": "In this paper, we study the problem of geometric reasoning in the context of\nquestion-answering. We introduce Dynamic Spatial Memory Network (DSMN), a new\ndeep network architecture designed for answering questions that admit latent\nvisual representations. DSMN learns to generate and reason over such\nrepresentations. Further, we propose two synthetic benchmarks, FloorPlanQA and\nShapeIntersection, to evaluate the geometric reasoning capability of QA\nsystems. Experimental results validate the effectiveness of our proposed DSMN\nfor visual thinking tasks.", "published": "2018-05-25 13:43:56", "link": "http://arxiv.org/abs/1805.11025v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Refining Source Representations with Relation Networks for Neural\n  Machine Translation", "abstract": "Although neural machine translation with the encoder-decoder framework has\nachieved great success recently, it still suffers drawbacks of forgetting\ndistant information, which is an inherent disadvantage of recurrent neural\nnetwork structure, and disregarding relationship between source words during\nencoding step. Whereas in practice, the former information and relationship are\noften useful in current step. We target on solving these problems and thus\nintroduce relation networks to learn better representations of the source. The\nrelation networks are able to facilitate memorization capability of recurrent\nneural network via associating source words with each other, this would also\nhelp retain their relationships. Then the source representations and all the\nrelations are fed into the attention component together while decoding, with\nthe main encoder-decoder framework unchanged. Experiments on several datasets\nshow that our method can improve the translation performance significantly over\nthe conventional encoder-decoder model and even outperform the approach\ninvolving supervised syntactic knowledge.", "published": "2018-05-25 13:34:52", "link": "http://arxiv.org/abs/1805.11154v2", "categories": ["cs.CL", "cs.AI", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Detecting Deceptive Reviews using Generative Adversarial Networks", "abstract": "In the past few years, consumer review sites have become the main target of\ndeceptive opinion spam, where fictitious opinions or reviews are deliberately\nwritten to sound authentic. Most of the existing work to detect the deceptive\nreviews focus on building supervised classifiers based on syntactic and lexical\npatterns of an opinion. With the successful use of Neural Networks on various\nclassification applications, in this paper, we propose FakeGAN a system that\nfor the first time augments and adopts Generative Adversarial Networks (GANs)\nfor a text classification task, in particular, detecting deceptive reviews.\nUnlike standard GAN models which have a single Generator and Discriminator\nmodel, FakeGAN uses two discriminator models and one generative model. The\ngenerator is modeled as a stochastic policy agent in reinforcement learning\n(RL), and the discriminators use Monte Carlo search algorithm to estimate and\npass the intermediate action-value as the RL reward to the generator. Providing\nthe generator model with two discriminator models avoids the mod collapse issue\nby learning from both distributions of truthful and deceptive reviews. Indeed,\nour experiments show that using two discriminators provides FakeGAN high\nstability, which is a known issue for GAN architectures. While FakeGAN is built\nupon a semi-supervised classifier, known for less accuracy, our evaluation\nresults on a dataset of TripAdvisor hotel reviews show the same performance in\nterms of accuracy as of the state-of-the-art approaches that apply supervised\nmachine learning. These results indicate that GANs can be effective for text\nclassification tasks. Specifically, FakeGAN is effective at detecting deceptive\nreviews.", "published": "2018-05-25 21:06:56", "link": "http://arxiv.org/abs/1805.10364v1", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Relative Transfer Function Estimation Exploiting Spatially Separated\n  Microphones in a Diffuse Noise Field", "abstract": "Many multi-microphone speech enhancement algorithms require the relative\ntransfer function (RTF) vector of the desired speech source, relating the\nacoustic transfer functions of all array microphones to a reference microphone.\nIn this paper, we propose a computationally efficient method to estimate the\nRTF vector in a diffuse noise field, which requires an additional microphone\nthat is spatially separated from the microphone array, such that the spatial\ncoherence between the noise components in the microphone array signals and the\nadditional microphone signal is low. Assuming this spatial coherence to be\nzero, we show that an unbiased estimate of the RTF vector can be obtained.\nBased on real-world recordings experimental results show that the proposed RTF\nestimator outperforms state-of-the-art estimators using only the microphone\narray signals in terms of estimation accuracy and noise reduction performance.", "published": "2018-05-25 19:08:08", "link": "http://arxiv.org/abs/1805.10333v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Curriculum Learning for Speech Emotion Recognition from Crowdsourced\n  Labels", "abstract": "This study introduces a method to design a curriculum for machine-learning to\nmaximize the efficiency during the training process of deep neural networks\n(DNNs) for speech emotion recognition. Previous studies in other\nmachine-learning problems have shown the benefits of training a classifier\nfollowing a curriculum where samples are gradually presented in increasing\nlevel of difficulty. For speech emotion recognition, the challenge is to\nestablish a natural order of difficulty in the training set to create the\ncurriculum. We address this problem by assuming that ambiguous samples for\nhumans are also ambiguous for computers. Speech samples are often annotated by\nmultiple evaluators to account for differences in emotion perception across\nindividuals. While some sentences with clear emotional content are consistently\nannotated, sentences with more ambiguous emotional content present important\ndisagreement between individual evaluations. We propose to use the disagreement\nbetween evaluators as a measure of difficulty for the classification task. We\npropose metrics that quantify the inter-evaluation agreement to define the\ncurriculum for regression problems and binary and multi-class classification\nproblems. The experimental results consistently show that relying on a\ncurriculum based on agreement between human judgments leads to statistically\nsignificant improvements over baselines trained without a curriculum.", "published": "2018-05-25 19:27:59", "link": "http://arxiv.org/abs/1805.10339v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Masked Conditional Neural Networks for Environmental Sound\n  Classification", "abstract": "The ConditionaL Neural Network (CLNN) exploits the nature of the temporal\nsequencing of the sound signal represented in a spectrogram, and its variant\nthe Masked ConditionaL Neural Network (MCLNN) induces the network to learn in\nfrequency bands by embedding a filterbank-like sparseness over the network's\nlinks using a binary mask. Additionally, the masking automates the exploration\nof different feature combinations concurrently analogous to handcrafting the\noptimum combination of features for a recognition task. We have evaluated the\nMCLNN performance using the Urbansound8k dataset of environmental sounds.\nAdditionally, we present a collection of manually recorded sounds for rail and\nroad traffic, YorNoise, to investigate the confusion rates among machine\ngenerated sounds possessing low-frequency components. MCLNN has achieved\ncompetitive results without augmentation and using 12% of the trainable\nparameters utilized by an equivalent model based on state-of-the-art\nConvolutional Neural Networks on the Urbansound8k. We extended the Urbansound8k\ndataset with YorNoise, where experiments have shown that common tonal\nproperties affect the classification performance.", "published": "2018-05-25 07:02:38", "link": "http://arxiv.org/abs/1805.10004v2", "categories": ["cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
