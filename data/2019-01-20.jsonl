{"title": "Beyond Turing: Intelligent Agents Centered on the User", "abstract": "Most research on intelligent agents centers on the agent and not on the user.\nWe look at the origins of agent-centric research for slot-filling, gaming and\nchatbot agents. We then argue that it is important to concentrate more on the\nuser. After reviewing relevant literature, some approaches for creating and\nassessing user-centric systems are proposed.", "published": "2019-01-20 02:25:23", "link": "http://arxiv.org/abs/1901.06613v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Visualizing Semantic Structures of Sequential Data by Learning Temporal\n  Dependencies", "abstract": "While conventional methods for sequential learning focus on interaction\nbetween consecutive inputs, we suggest a new method which captures composite\nsemantic flows with variable-length dependencies. In addition, the semantic\nstructures within given sequential data can be interpreted by visualizing\ntemporal dependencies learned from the method. The proposed method, called\nTemporal Dependency Network (TDN), represents a video as a temporal graph whose\nnode represents a frame of the video and whose edge represents the temporal\ndependency between two frames of a variable distance. The temporal dependency\nstructure of semantic is discovered by learning parameterized kernels of graph\nconvolutional methods. We evaluate the proposed method on the large-scale video\ndataset, Youtube-8M. By visualizing the temporal dependency structures as\nexperimental results, we show that the suggested method can find the temporal\ndependency structures of video semantic.", "published": "2019-01-20 18:46:21", "link": "http://arxiv.org/abs/1901.09066v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Hierarchical Attentional Hybrid Neural Networks for Document\n  Classification", "abstract": "Document classification is a challenging task with important applications.\nThe deep learning approaches to the problem have gained much attention\nrecently. Despite the progress, the proposed models do not incorporate the\nknowledge of the document structure in the architecture efficiently and not\ntake into account the contexting importance of words and sentences. In this\npaper, we propose a new approach based on a combination of convolutional neural\nnetworks, gated recurrent units, and attention mechanisms for document\nclassification tasks. The main contribution of this work is the use of\nconvolution layers to extract more meaningful, generalizable and abstract\nfeatures by the hierarchical representation. The proposed method in this paper\nimproves the results of the current attention-based approaches for document\nclassification.", "published": "2019-01-20 01:48:43", "link": "http://arxiv.org/abs/1901.06610v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Improving generation quality of pointer networks via guided attention", "abstract": "Pointer generator networks have been used successfully for abstractive\nsummarization. Along with the capability to generate novel words, it also\nallows the model to copy from the input text to handle out-of-vocabulary words.\nIn this paper, we point out two key shortcomings of the summaries generated\nwith this framework via manual inspection, statistical analysis and human\nevaluation. The first shortcoming is the extractive nature of the generated\nsummaries, since the network eventually learns to copy from the input article\nmost of the times, affecting the abstractive nature of the generated summaries.\nThe second shortcoming is the factual inaccuracies in the generated text\ndespite grammatical correctness. Our analysis indicates that this arises due to\nincorrect attention transition between different parts of the article. We\npropose an initial attempt towards addressing both these shortcomings by\nexternally appending traditional linguistic information parsed from the input\ntext, thereby teaching networks on the structure of the underlying text.\nResults indicate feasibility and potential of such additional cues for improved\ngeneration.", "published": "2019-01-20 18:50:58", "link": "http://arxiv.org/abs/1901.11492v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
