{"title": "Causal Estimation of Tokenisation Bias", "abstract": "Modern language models are typically trained over subword sequences, but\nultimately define probabilities over character-strings. Ideally, the choice of\nthe tokeniser -- which maps character-strings to subwords -- should not affect\nthe probability assigned to the underlying character-string; in practice, it\ndoes. We define this mismatch as tokenisation bias. In this work, we quantify\none particular type of tokenisation bias: the effect of including or not a\nsubword (e.g., $\\langle hello \\rangle$) in a tokeniser's vocabulary on the\nprobability a trained model assigns to the corresponding characters (i.e.,\n\\textit{``hello''}). Estimating this effect is challenging because each model\nis trained with only one tokeniser. We address this by framing tokenisation\nbias as a causal effect and estimating it using the regression discontinuity\ndesign. Specifically, we exploit the fact that tokenisation algorithms rank\nsubwords and add the first $K$ to a tokeniser's vocabulary, where $K$ is an\narbitrary cutoff point. As such, we can estimate a causal effect by comparing\nsimilar subwords around this cutoff. Experimentally, we find that tokenisation\nconsistently affects models' outputs across scales, vocabularies, and\ntokenisers. Notably, a subword's presence in a small model's vocabulary may\nincrease its characters' probability by up to 17 times, highlighting\ntokenisation as a key design choice in language modelling.", "published": "2025-06-03 17:59:47", "link": "http://arxiv.org/abs/2506.03149v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "UniWorld: High-Resolution Semantic Encoders for Unified Visual Understanding and Generation", "abstract": "Although existing unified models deliver strong performance on\nvision-language understanding and text-to-image generation, their models are\nlimited in exploring image perception and manipulation tasks, which are\nurgently desired by users for wide applications. Recently, OpenAI released\ntheir powerful GPT-4o-Image model for comprehensive image perception and\nmanipulation, achieving expressive capability and attracting community\ninterests. By observing the performance of GPT-4o-Image in our carefully\nconstructed experiments, we infer that GPT-4o-Image leverages features\nextracted by semantic encoders instead of VAE, while VAEs are considered\nessential components in many image manipulation models. Motivated by such\ninspiring observations, we present a unified generative framework named\nUniWorld based on semantic features provided by powerful visual-language models\nand contrastive semantic encoders. As a result, we build a strong unified model\nusing only 1% amount of BAGEL's data, which consistently outperforms BAGEL on\nimage editing benchmarks. UniWorld also maintains competitive image\nunderstanding and generation capabilities, achieving strong performance across\nmultiple image perception tasks. We fully open-source our models, including\nmodel weights, training and evaluation scripts, and datasets.", "published": "2025-06-03 17:59:33", "link": "http://arxiv.org/abs/2506.03147v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Entity-Augmented Neuroscience Knowledge Retrieval Using Ontology and Semantic Understanding Capability of LLM", "abstract": "Neuroscience research publications encompass a vast wealth of knowledge.\nAccurately retrieving existing information and discovering new insights from\nthis extensive literature is essential for advancing the field. However, when\nknowledge is dispersed across multiple sources, current state-of-the-art\nretrieval methods often struggle to extract the necessary information. A\nknowledge graph (KG) can integrate and link knowledge from multiple sources,\nbut existing methods for constructing KGs in neuroscience often rely on labeled\ndata and require domain expertise. Acquiring large-scale, labeled data for a\nspecialized area like neuroscience presents significant challenges. This work\nproposes novel methods for constructing KG from unlabeled large-scale\nneuroscience research corpus utilizing large language models (LLM),\nneuroscience ontology, and text embeddings. We analyze the semantic relevance\nof neuroscience text segments identified by LLM for building the knowledge\ngraph. We also introduce an entity-augmented information retrieval algorithm to\nextract knowledge from the KG. Several experiments were conducted to evaluate\nthe proposed approaches, and the results demonstrate that our methods\nsignificantly enhance knowledge discovery from the unlabeled neuroscience\nresearch corpus. It achieves an F1 score of 0.84 for entity extraction, and the\nknowledge obtained from the KG improves answers to over 54% of the questions.", "published": "2025-06-03 17:59:18", "link": "http://arxiv.org/abs/2506.03145v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MERIT: Multilingual Semantic Retrieval with Interleaved Multi-Condition Query", "abstract": "Semantic retrieval is crucial for modern applications yet remains\nunderexplored in current research. Existing datasets are limited to single\nlanguages, single images, or singular retrieval conditions, often failing to\nfully exploit the expressive capacity of visual information as evidenced by\nmaintained performance when images are replaced with captions. However,\npractical retrieval scenarios frequently involve interleaved multi-condition\nqueries with multiple images. Hence, this paper introduces MERIT, the first\nmultilingual dataset for interleaved multi-condition semantic retrieval,\ncomprising 320,000 queries with 135,000 products in 5 languages, covering 7\ndistinct product categories. Extensive experiments on MERIT identify existing\nmodels's limitation: focusing solely on global semantic information while\nneglecting specific conditional elements in queries. Consequently, we propose\nCoral, a novel fine-tuning framework that adapts pre-trained MLLMs by\nintegrating embedding reconstruction to preserve fine-grained conditional\nelements and contrastive learning to extract comprehensive global semantics.\nExperiments demonstrate that Coral achieves a 45.9% performance improvement\nover conventional approaches on MERIT, with strong generalization capabilities\nvalidated across 8 established retrieval benchmarks. Collectively, our\ncontributions - a novel dataset, identification of critical limitations in\nexisting approaches, and an innovative fine-tuning framework - establish a\nfoundation for future research in interleaved multi-condition semantic\nretrieval.", "published": "2025-06-03 17:59:14", "link": "http://arxiv.org/abs/2506.03144v1", "categories": ["cs.CV", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "GUI-Actor: Coordinate-Free Visual Grounding for GUI Agents", "abstract": "One of the principal challenges in building VLM-powered GUI agents is visual\ngrounding, i.e., localizing the appropriate screen region for action execution\nbased on both the visual content and the textual plans. Most existing work\nformulates this as a text-based coordinate generation task. However, these\napproaches suffer from several limitations: weak spatial-semantic alignment,\ninability to handle ambiguous supervision targets, and a mismatch between the\ndense nature of screen coordinates and the coarse, patch-level granularity of\nvisual features extracted by models like Vision Transformers. In this paper, we\npropose GUI-Actor, a VLM-based method for coordinate-free GUI grounding. At its\ncore, GUI-Actor introduces an attention-based action head that learns to align\na dedicated <ACTOR> token with all relevant visual patch tokens, enabling the\nmodel to propose one or more action regions in a single forward pass. In line\nwith this, we further design a grounding verifier to evaluate and select the\nmost plausible action region from the candidates proposed for action execution.\nExtensive experiments show that GUI-Actor outperforms prior state-of-the-art\nmethods on multiple GUI action grounding benchmarks, with improved\ngeneralization to unseen screen resolutions and layouts. Notably, GUI-Actor-7B\neven surpasses UI-TARS-72B (38.1) on ScreenSpot-Pro, achieving scores of 40.7\nwith Qwen2-VL and 44.6 with Qwen2.5-VL as backbones. Furthermore, by\nincorporating the verifier, we find that fine-tuning only the newly introduced\naction head (~100M parameters for 7B model) while keeping the VLM backbone\nfrozen is sufficient to achieve performance comparable to previous\nstate-of-the-art models, highlighting that GUI-Actor can endow the underlying\nVLM with effective grounding capabilities without compromising its\ngeneral-purpose strengths.", "published": "2025-06-03 17:59:08", "link": "http://arxiv.org/abs/2506.03143v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Co-Evolving LLM Coder and Unit Tester via Reinforcement Learning", "abstract": "We propose CURE, a novel reinforcement learning framework with a dedicated\nreward design that co-evolves coding and unit test generation capabilities\nbased on their interaction outcomes, without any ground-truth code as\nsupervision. This approach enables flexible and scalable training and allows\nthe unit tester to learn directly from the coder's mistakes. Our derived\nReasonFlux-Coder-7B and 14B models improve code generation accuracy by 5.3% and\nBest-of-N accuracy by 9.0% after optimization on Qwen2.5-Instruct models,\noutperforming similarly sized Qwen-Coder, DeepSeek-Coder, and Seed-Coder. They\nnaturally extend to downstream tasks such as test-time scaling and agentic\ncoding-achieving a 8.1% improvement over the base model. For the long-CoT\nmodel, our ReasonFlux-Coder-4B consistently outperforms Qwen3-4B while\nachieving 64.8% inference efficiency in unit test generation. Notably, we also\nfind that our model can serve as an effective reward model for reinforcement\nlearning on base models. Project: https://github.com/Gen-Verse/CURE", "published": "2025-06-03 17:58:42", "link": "http://arxiv.org/abs/2506.03136v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OmniSpatial: Towards Comprehensive Spatial Reasoning Benchmark for Vision Language Models", "abstract": "Spatial reasoning is a key aspect of cognitive psychology and remains a major\nbottleneck for current vision-language models (VLMs). While extensive research\nhas aimed to evaluate or improve VLMs' understanding of basic spatial\nrelations, such as distinguishing left from right, near from far, and object\ncounting, these tasks represent only the most fundamental level of spatial\nreasoning. In this work, we introduce OmniSpatial, a comprehensive and\nchallenging benchmark for spatial reasoning, grounded in cognitive psychology.\nOmniSpatial covers four major categories: dynamic reasoning, complex spatial\nlogic, spatial interaction, and perspective-taking, with 50 fine-grained\nsubcategories. Through Internet data crawling and careful manual annotation, we\nconstruct over 1.5K question-answer pairs. Extensive experiments show that both\nopen- and closed-source VLMs, as well as existing reasoning and spatial\nunderstanding models, exhibit significant limitations in comprehensive spatial\nunderstanding. We further analyze failure cases and propose potential\ndirections for future research.", "published": "2025-06-03 17:58:29", "link": "http://arxiv.org/abs/2506.03135v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "AUTOCIRCUIT-RL: Reinforcement Learning-Driven LLM for Automated Circuit Topology Generation", "abstract": "Analog circuit topology synthesis is integral to Electronic Design Automation\n(EDA), enabling the automated creation of circuit structures tailored to\nspecific design requirements. However, the vast design search space and strict\nconstraint adherence make efficient synthesis challenging. Leveraging the\nversatility of Large Language Models (LLMs), we propose AUTOCIRCUIT-RL,a novel\nreinforcement learning (RL)-based framework for automated analog circuit\nsynthesis. The framework operates in two phases: instruction tuning, where an\nLLM learns to generate circuit topologies from structured prompts encoding\ndesign constraints, and RL refinement, which further improves the\ninstruction-tuned model using reward models that evaluate validity, efficiency,\nand output voltage. The refined model is then used directly to generate\ntopologies that satisfy the design constraints. Empirical results show that\nAUTOCIRCUIT-RL generates ~12% more valid circuits and improves efficiency by\n~14% compared to the best baselines, while reducing duplicate generation rates\nby ~38%. It achieves over 60% success in synthesizing valid circuits with\nlimited training data, demonstrating strong generalization. These findings\nhighlight the framework's effectiveness in scaling to complex circuits while\nmaintaining efficiency and constraint adherence, marking a significant\nadvancement in AI-driven circuit design.", "published": "2025-06-03 17:54:30", "link": "http://arxiv.org/abs/2506.03122v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Critique-GRPO: Advancing LLM Reasoning with Natural Language and Numerical Feedback", "abstract": "Recent advances in reinforcement learning (RL) with numerical feedback, such\nas scalar rewards, have significantly enhanced the complex reasoning\ncapabilities of large language models (LLMs). Despite this success, we identify\nthree key challenges encountered by RL with solely numerical feedback:\nperformance plateaus, limited effectiveness of self-reflection, and persistent\nfailures. We then demonstrate that RL-finetuned models, even after exhibiting\nperformance plateaus, can generate correct refinements on persistently failed\nproblems by leveraging natural language feedback in the form of critiques.\nBuilding on this insight, we propose Critique-GRPO, an online RL framework that\nintegrates both natural language and numerical feedback for effective policy\noptimization. Critique-GRPO enables LLMs to learn from initial responses and\ncritique-guided refinements simultaneously while maintaining exploration.\nExtensive experiments using Qwen2.5-7B-Base and Qwen3-8B-Base show that\nCritique-GRPO consistently outperforms supervised learning-based and RL-based\nfine-tuning approaches across eight challenging mathematical, STEM, and general\nreasoning tasks, improving average pass@1 scores by approximately 4.5% and 5%,\nrespectively. Notably, Critique-GRPO surpasses a strong baseline that\nincorporates expert demonstrations within online RL. Further analysis reveals\ntwo critical insights about policy exploration: (1) higher entropy does not\nalways guarantee efficient learning from exploration, and (2) longer responses\ndo not necessarily lead to more effective exploration.", "published": "2025-06-03 17:39:02", "link": "http://arxiv.org/abs/2506.03106v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Beyond Text Compression: Evaluating Tokenizers Across Scales", "abstract": "The choice of tokenizer can profoundly impact language model performance, yet\naccessible and reliable evaluations of tokenizer quality remain an open\nchallenge. Inspired by scaling consistency, we show that smaller models can\naccurately predict significant differences in tokenizer impact on larger models\nat a fraction of the compute cost. By systematically evaluating both\nEnglish-centric and multilingual tokenizers, we find that tokenizer choice has\nnegligible effects on tasks in English but results in consistent performance\ndifferences in multilingual settings. We propose new intrinsic tokenizer\nmetrics inspired by Zipf's law that correlate more strongly with downstream\nperformance than text compression when modeling unseen languages. By combining\nseveral metrics to capture multiple aspects of tokenizer behavior, we develop a\nreliable framework for intrinsic tokenizer evaluations. Our work offers a more\nefficient path to informed tokenizer selection in future language model\ndevelopment.", "published": "2025-06-03 17:35:56", "link": "http://arxiv.org/abs/2506.03101v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Retrieval-Augmented Generation as Noisy In-Context Learning: A Unified Theory and Risk Bounds", "abstract": "Retrieval-augmented generation (RAG) has seen many empirical successes in\nrecent years by aiding the LLM with external knowledge. However, its\ntheoretical aspect has remained mostly unexplored. In this paper, we propose\nthe first finite-sample generalization bound for RAG in in-context linear\nregression and derive an exact bias-variance tradeoff. Our framework views the\nretrieved texts as query-dependent noisy in-context examples and recovers the\nclassical in-context learning (ICL) and standard RAG as the limit cases. Our\nanalysis suggests that an intrinsic ceiling on generalization error exists on\nRAG as opposed to the ICL. Furthermore, our framework is able to model\nretrieval both from the training data and from external corpora by introducing\nuniform and non-uniform RAG noise. In line with our theory, we show the sample\nefficiency of ICL and RAG empirically with experiments on common QA benchmarks,\nsuch as Natural Questions and TriviaQA.", "published": "2025-06-03 17:31:53", "link": "http://arxiv.org/abs/2506.03100v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR", "math.ST", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Literary Evidence Retrieval via Long-Context Language Models", "abstract": "How well do modern long-context language models understand literary fiction?\nWe explore this question via the task of literary evidence retrieval,\nrepurposing the RELiC dataset of That et al. (2022) to construct a benchmark\nwhere the entire text of a primary source (e.g., The Great Gatsby) is provided\nto an LLM alongside literary criticism with a missing quotation from that work.\nThis setting, in which the model must generate the missing quotation, mirrors\nthe human process of literary analysis by requiring models to perform both\nglobal narrative reasoning and close textual examination. We curate a\nhigh-quality subset of 292 examples through extensive filtering and human\nverification. Our experiments show that recent reasoning models, such as Gemini\nPro 2.5 can exceed human expert performance (62.5% vs. 50% accuracy). In\ncontrast, the best open-weight model achieves only 29.1% accuracy, highlighting\na wide gap in interpretive reasoning between open and closed-weight models.\nDespite their speed and apparent accuracy, even the strongest models struggle\nwith nuanced literary signals and overgeneration, signaling open challenges for\napplying LLMs to literary analysis. We release our dataset and evaluation code\nto encourage future work in this direction.", "published": "2025-06-03 17:19:45", "link": "http://arxiv.org/abs/2506.03090v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MAEBE: Multi-Agent Emergent Behavior Framework", "abstract": "Traditional AI safety evaluations on isolated LLMs are insufficient as\nmulti-agent AI ensembles become prevalent, introducing novel emergent risks.\nThis paper introduces the Multi-Agent Emergent Behavior Evaluation (MAEBE)\nframework to systematically assess such risks. Using MAEBE with the Greatest\nGood Benchmark (and a novel double-inversion question technique), we\ndemonstrate that: (1) LLM moral preferences, particularly for Instrumental\nHarm, are surprisingly brittle and shift significantly with question framing,\nboth in single agents and ensembles. (2) The moral reasoning of LLM ensembles\nis not directly predictable from isolated agent behavior due to emergent group\ndynamics. (3) Specifically, ensembles exhibit phenomena like peer pressure\ninfluencing convergence, even when guided by a supervisor, highlighting\ndistinct safety and alignment challenges. Our findings underscore the necessity\nof evaluating AI systems in their interactive, multi-agent contexts.", "published": "2025-06-03 16:33:47", "link": "http://arxiv.org/abs/2506.03053v1", "categories": ["cs.MA", "cs.AI", "cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.MA"}
{"title": "Facts Do Care About Your Language: Assessing Answer Quality of Multilingual LLMs", "abstract": "Factuality is a necessary precursor to useful educational tools. As adoption\nof Large Language Models (LLMs) in education continues of grow, ensuring\ncorrectness in all settings is paramount. Despite their strong English\ncapabilities, LLM performance in other languages is largely untested. In this\nwork, we evaluate the correctness of the Llama3.1 family of models in answering\nfactual questions appropriate for middle and high school students. We\ndemonstrate that LLMs not only provide extraneous and less truthful\ninformation, but also exacerbate existing biases against rare languages.", "published": "2025-06-03 16:31:52", "link": "http://arxiv.org/abs/2506.03051v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Analyzing and Understanding the Limitations of VAPO: A Theoretical Perspective", "abstract": "Reinforcement learning (RL) enhances large language models (LLMs) in complex,\nlong-chain-of-thought (long-CoT) reasoning. The advanced VAPO framework,\ndespite sophisticated mechanisms like Decoupled GAE, theoretically faces\nfundamental limitations in comprehensively modeling and leveraging deep,\nlong-term value for fine-grained, step-by-step policy guidance in extended\nreasoning chains. We argue these limitations stem from inherent difficulties in\ncredit assignment, value function representational capacity with temporally\nabstracted goals, and translating global value signals into local policy\nimprovements, especially with sparse rewards. Our theoretical analysis examines\nthese aspects to illuminate VAPO's boundaries in long-term value modeling,\naiming to deepen understanding of current RL for advanced reasoning and suggest\nfuture research for more robust LLM agents.", "published": "2025-06-03 16:20:47", "link": "http://arxiv.org/abs/2506.03038v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging Information Retrieval to Enhance Spoken Language Understanding Prompts in Few-Shot Learning", "abstract": "Understanding user queries is fundamental in many applications, such as home\nassistants, booking systems, or recommendations. Accordingly, it is crucial to\ndevelop accurate Spoken Language Understanding (SLU) approaches to ensure the\nreliability of the considered system. Current State-of-the-Art SLU techniques\nrely on large amounts of training data; however, only limited annotated\nexamples are available for specific tasks or languages.\n  In the meantime, instruction-tuned large language models (LLMs) have shown\nexceptional performance on unseen tasks in a few-shot setting when provided\nwith adequate prompts. In this work, we propose to explore example selection by\nleveraging Information retrieval (IR) approaches to build an enhanced prompt\nthat is applied to an SLU task. We evaluate the effectiveness of the proposed\nmethod on several SLU benchmarks. Experimental results show that lexical IR\nmethods significantly enhance performance without increasing prompt length.", "published": "2025-06-03 16:18:45", "link": "http://arxiv.org/abs/2506.03035v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Coding Agents with Multimodal Browsing are Generalist Problem Solvers", "abstract": "Modern human labor is characterized by specialization; we train for years and\ndevelop particular tools that allow us to perform well across a variety of\ntasks. In addition, AI agents have been specialized for domains such as\nsoftware engineering, web navigation, and workflow automation. However, this\nresults in agents that are good for one thing but fail to generalize beyond\ntheir intended scope. One reason for this is that agent developers provide a\nhighly specialized set of tools or make architectural decisions optimized for a\nspecific use case or benchmark. In this work, we ask the question: what is the\nminimal set of general tools that can be used to achieve high performance\nacross a diverse set of tasks? Our answer is OpenHands-Versa, a generalist\nagent built with a modest number of general tools: code editing and execution,\nweb search, as well as multimodal web browsing and file access. Importantly,\nOpenHands-Versa demonstrates superior or competitive performance over leading\nspecialized agents across three diverse and challenging benchmarks: SWE-Bench\nMultimodal, GAIA, and The Agent Company, outperforming the best-performing\npreviously published results with absolute improvements in success rate of 9.1,\n1.3, and 9.1 points respectively. Further, we show how existing\nstate-of-the-art multi-agent systems fail to generalize beyond their target\ndomains. These results demonstrate the feasibility of developing a generalist\nagent to solve diverse tasks and establish OpenHands-Versa as a strong baseline\nfor future research.", "published": "2025-06-03 15:50:55", "link": "http://arxiv.org/abs/2506.03011v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Conditioning Large Language Models on Legal Systems? Detecting Punishable Hate Speech", "abstract": "The assessment of legal problems requires the consideration of a specific\nlegal system and its levels of abstraction, from constitutional law to\nstatutory law to case law. The extent to which Large Language Models (LLMs)\ninternalize such legal systems is unknown. In this paper, we propose and\ninvestigate different approaches to condition LLMs at different levels of\nabstraction in legal systems. This paper examines different approaches to\nconditioning LLMs at multiple levels of abstraction in legal systems to detect\npotentially punishable hate speech. We focus on the task of classifying whether\na specific social media posts falls under the criminal offense of incitement to\nhatred as prescribed by the German Criminal Code. The results show that there\nis still a significant performance gap between models and legal experts in the\nlegal assessment of hate speech, regardless of the level of abstraction with\nwhich the models were conditioned. Our analysis revealed, that models\nconditioned on abstract legal knowledge lacked deep task understanding, often\ncontradicting themselves and hallucinating answers, while models using concrete\nlegal knowledge performed reasonably well in identifying relevant target\ngroups, but struggled with classifying target conducts.", "published": "2025-06-03 15:50:27", "link": "http://arxiv.org/abs/2506.03009v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Multi-Agent Framework for Mitigating Dialect Biases in Privacy Policy Question-Answering Systems", "abstract": "Privacy policies inform users about data collection and usage, yet their\ncomplexity limits accessibility for diverse populations. Existing Privacy\nPolicy Question Answering (QA) systems exhibit performance disparities across\nEnglish dialects, disadvantaging speakers of non-standard varieties. We propose\na novel multi-agent framework inspired by human-centered design principles to\nmitigate dialectal biases. Our approach integrates a Dialect Agent, which\ntranslates queries into Standard American English (SAE) while preserving\ndialectal intent, and a Privacy Policy Agent, which refines predictions using\ndomain expertise. Unlike prior approaches, our method does not require\nretraining or dialect-specific fine-tuning, making it broadly applicable across\nmodels and domains. Evaluated on PrivacyQA and PolicyQA, our framework improves\nGPT-4o-mini's zero-shot accuracy from 0.394 to 0.601 on PrivacyQA and from\n0.352 to 0.464 on PolicyQA, surpassing or matching few-shot baselines without\nadditional training data. These results highlight the effectiveness of\nstructured agent collaboration in mitigating dialect biases and underscore the\nimportance of designing NLP systems that account for linguistic diversity to\nensure equitable access to privacy information.", "published": "2025-06-03 15:32:20", "link": "http://arxiv.org/abs/2506.02998v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "It's Not a Walk in the Park! Challenges of Idiom Translation in Speech-to-text Systems", "abstract": "Idioms are defined as a group of words with a figurative meaning not\ndeducible from their individual components. Although modern machine translation\nsystems have made remarkable progress, translating idioms remains a major\nchallenge, especially for speech-to-text systems, where research on this topic\nis notably sparse. In this paper, we systematically evaluate idiom translation\nas compared to conventional news translation in both text-to-text machine\ntranslation (MT) and speech-to-text translation (SLT) systems across two\nlanguage pairs (German to English, Russian to English). We compare\nstate-of-the-art end-to-end SLT systems (SeamlessM4T SLT-to-text, Whisper Large\nv3) with MT systems (SeamlessM4T SLT-to-text, No Language Left Behind), Large\nLanguage Models (DeepSeek, LLaMA) and cascaded alternatives. Our results reveal\nthat SLT systems experience a pronounced performance drop on idiomatic data,\noften reverting to literal translations even in higher layers, whereas MT\nsystems and Large Language Models demonstrate better handling of idioms. These\nfindings underscore the need for idiom-specific strategies and improved\ninternal representations in SLT architectures.", "published": "2025-06-03 15:29:52", "link": "http://arxiv.org/abs/2506.02995v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mitigating Manipulation and Enhancing Persuasion: A Reflective Multi-Agent Approach for Legal Argument Generation", "abstract": "Large Language Models (LLMs) are increasingly explored for legal argument\ngeneration, yet they pose significant risks of manipulation through\nhallucination and ungrounded persuasion, and often fail to utilize provided\nfactual bases effectively or abstain when arguments are untenable. This paper\nintroduces a novel reflective multi-agent method designed to address these\nchallenges in the context of legally compliant persuasion. Our approach employs\nspecialized agents--a Factor Analyst and an Argument Polisher--in an iterative\nrefinement process to generate 3-ply legal arguments (plaintiff, defendant,\nrebuttal). We evaluate Reflective Multi-Agent against single-agent,\nenhanced-prompt single-agent, and non-reflective multi-agent baselines using\nfour diverse LLMs (GPT-4o, GPT-4o-mini, Llama-4-Maverick-17b-128e,\nLlama-4-Scout-17b-16e) across three legal scenarios: \"arguable\", \"mismatched\",\nand \"non-arguable\". Results demonstrate Reflective Multi-Agent's significant\nsuperiority in successful abstention (preventing generation when arguments\ncannot be grounded), marked improvements in hallucination accuracy (reducing\nfabricated and misattributed factors), particularly in \"non-arguable\"\nscenarios, and enhanced factor utilization recall (improving the use of\nprovided case facts). These findings suggest that structured reflection within\na multi-agent framework offers a robust computable method for fostering ethical\npersuasion and mitigating manipulation in LLM-based legal argumentation\nsystems, a critical step towards trustworthy AI in law. Project page:\nhttps://lizhang-aiandlaw.github.io/A-Reflective-Multi-Agent-Approach-for-Legal-Argument-Generation/", "published": "2025-06-03 15:28:30", "link": "http://arxiv.org/abs/2506.02992v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "68T50", "I.2"], "primary_category": "cs.AI"}
{"title": "Performance of leading large language models in May 2025 in Membership of the Royal College of General Practitioners-style examination questions: a cross-sectional analysis", "abstract": "Background: Large language models (LLMs) have demonstrated substantial\npotential to support clinical practice. Other than Chat GPT4 and its\npredecessors, few LLMs, especially those of the leading and more powerful\nreasoning model class, have been subjected to medical specialty examination\nquestions, including in the domain of primary care. This paper aimed to test\nthe capabilities of leading LLMs as of May 2025 (o3, Claude Opus 4, Grok3, and\nGemini 2.5 Pro) in primary care education, specifically in answering Member of\nthe Royal College of General Practitioners (MRCGP) style examination questions.\n  Methods: o3, Claude Opus 4, Grok3, and Gemini 2.5 Pro were tasked to answer\n100 randomly chosen multiple choice questions from the Royal College of General\nPractitioners GP SelfTest on 25 May 2025. Questions included textual\ninformation, laboratory results, and clinical images. Each model was prompted\nto answer as a GP in the UK and was provided with full question information.\nEach question was attempted once by each model. Responses were scored against\ncorrect answers provided by GP SelfTest.\n  Results: The total score of o3, Claude Opus 4, Grok3, and Gemini 2.5 Pro was\n99.0%, 95.0%, 95.0%, and 95.0%, respectively. The average peer score for the\nsame questions was 73.0%.\n  Discussion: All models performed remarkably well, and all substantially\nexceeded the average performance of GPs and GP registrars who had answered the\nsame questions. o3 demonstrated the best performance, while the performances of\nthe other leading models were comparable with each other and were not\nsubstantially lower than that of o3. These findings strengthen the case for\nLLMs, particularly reasoning models, to support the delivery of primary care,\nespecially those that have been specifically trained on primary care clinical\ndata.", "published": "2025-06-03 15:25:38", "link": "http://arxiv.org/abs/2506.02987v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Towards a Japanese Full-duplex Spoken Dialogue System", "abstract": "Full-duplex spoken dialogue systems, which can model simultaneous\nbidirectional features of human conversations such as speech overlaps and\nbackchannels, have attracted significant attention recently. However, the study\nof full-duplex spoken dialogue systems for the Japanese language has been\nlimited, and the research on their development in Japanese remains scarce. In\nthis paper, we present the first publicly available full-duplex spoken dialogue\nmodel in Japanese, which is built upon Moshi, a full-duplex dialogue model in\nEnglish. Our model is trained through a two-stage process: pre-training on a\nlarge-scale spoken dialogue data in Japanese, followed by fine-tuning on\nhigh-quality stereo spoken dialogue data. We further enhance the model's\nperformance by incorporating synthetic dialogue data generated by a\nmulti-stream text-to-speech system. Evaluation experiments demonstrate that the\ntrained model outperforms Japanese baseline models in both naturalness and\nmeaningfulness.", "published": "2025-06-03 15:16:50", "link": "http://arxiv.org/abs/2506.02979v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Expanding before Inferring: Enhancing Factuality in Large Language Models through Premature Layers Interpolation", "abstract": "Large Language Models (LLMs) demonstrate remarkable capabilities in text\nunderstanding and generation. However, their tendency to produce factually\ninconsistent outputs, commonly referred to as ''hallucinations'', remains a\ncritical challenge. Existing approaches, such as retrieval-based and\ninference-time correction methods, primarily address this issue at the input or\noutput level, often overlooking the intrinsic information refinement process\nand the role of premature layers. Meanwhile, alignment- and fine-tuning-based\nmethods are resource-intensive. In this paper, we propose PLI (Premature Layers\nInterpolation), a novel, training-free, and plug-and-play intervention designed\nto enhance factuality. PLI mitigates hallucinations by inserting premature\nlayers formed through mathematical interpolation with adjacent layers. Inspired\nby stable diffusion and sampling steps, PLI extends the depth of information\nprocessing and transmission in LLMs, improving factual coherence. Experiments\non four publicly available datasets demonstrate that PLI effectively reduces\nhallucinations while outperforming existing baselines in most cases. Further\nanalysis suggests that the success of layer interpolation is closely linked to\nLLMs' internal mechanisms. To promote reproducibility, we will release our code\nand data upon acceptance.", "published": "2025-06-03 15:07:13", "link": "http://arxiv.org/abs/2506.02973v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FlowerTune: A Cross-Domain Benchmark for Federated Fine-Tuning of Large Language Models", "abstract": "Large Language Models (LLMs) have achieved state-of-the-art results across\ndiverse domains, yet their development remains reliant on vast amounts of\npublicly available data, raising concerns about data scarcity and the lack of\naccess to domain-specific, sensitive information. Federated Learning (FL)\npresents a compelling framework to address these challenges by enabling\ndecentralized fine-tuning on pre-trained LLMs without sharing raw data.\nHowever, the compatibility and performance of pre-trained LLMs in FL settings\nremain largely under explored. We introduce the FlowerTune LLM Leaderboard, a\nfirst-of-its-kind benchmarking suite designed to evaluate federated fine-tuning\nof LLMs across four diverse domains: general NLP, finance, medical, and coding.\nEach domain includes federated instruction-tuning datasets and domain-specific\nevaluation metrics. Our results, obtained through a collaborative, open-source\nand community-driven approach, provide the first comprehensive comparison\nacross 26 pre-trained LLMs with different aggregation and fine-tuning\nstrategies under federated settings, offering actionable insights into model\nperformance, resource constraints, and domain adaptation. This work lays the\nfoundation for developing privacy-preserving, domain-specialized LLMs for\nreal-world applications.", "published": "2025-06-03 14:54:12", "link": "http://arxiv.org/abs/2506.02961v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HACo-Det: A Study Towards Fine-Grained Machine-Generated Text Detection under Human-AI Coauthoring", "abstract": "The misuse of large language models (LLMs) poses potential risks, motivating\nthe development of machine-generated text (MGT) detection. Existing literature\nprimarily concentrates on binary, document-level detection, thereby neglecting\ntexts that are composed jointly by human and LLM contributions. Hence, this\npaper explores the possibility of fine-grained MGT detection under human-AI\ncoauthoring. We suggest fine-grained detectors can pave pathways toward\ncoauthored text detection with a numeric AI ratio. Specifically, we propose a\ndataset, HACo-Det, which produces human-AI coauthored texts via an automatic\npipeline with word-level attribution labels. We retrofit seven prevailing\ndocument-level detectors to generalize them to word-level detection. Then we\nevaluate these detectors on HACo-Det on both word- and sentence-level detection\ntasks. Empirical results show that metric-based methods struggle to conduct\nfine-grained detection with a 0.462 average F1 score, while finetuned models\nshow superior performance and better generalization across domains. However, we\nargue that fine-grained co-authored text detection is far from solved. We\nfurther analyze factors influencing performance, e.g., context window, and\nhighlight the limitations of current methods, pointing to potential avenues for\nimprovement.", "published": "2025-06-03 14:52:44", "link": "http://arxiv.org/abs/2506.02959v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Adaptive Graph Pruning for Multi-Agent Communication", "abstract": "Large Language Model (LLM) based multi-agent systems have shown remarkable\nperformance in various tasks, especially when enhanced through collaborative\ncommunication. However, current methods often rely on a fixed number of agents\nand static communication structures, limiting their ability to adapt to varying\ntask complexities. In this paper, we propose Adaptive Graph Pruning (AGP), a\nnovel task-adaptive multi-agent collaboration framework that jointly optimizes\nagent quantity (hard-pruning) and communication topology (soft-pruning).\nSpecifically, our method employs a two-stage training strategy: firstly,\nindependently training soft-pruning networks for different agent quantities to\ndetermine optimal agent-quantity-specific complete graphs and positional masks\nacross specific tasks; and then jointly optimizing hard-pruning and\nsoft-pruning within a maximum complete graph to dynamically configure the\nnumber of agents and their communication topologies per task. Extensive\nexperiments demonstrate that our approach is: (1) High-performing, achieving\nstate-of-the-art results across six benchmarks and consistently generalizes\nacross multiple mainstream LLM architectures, with a increase in performance of\n$2.58\\%\\sim 9.84\\%$; (2) Task-adaptive, dynamically constructing optimized\ncommunication topologies tailored to specific tasks, with an extremely high\nperformance in all three task categories (general reasoning, mathematical\nreasoning, and code generation); (3) Token-economical, having fewer training\nsteps and token consumption at the same time, with a decrease in token\nconsumption of $90\\%+$; and (4) Training-efficient, achieving high performance\nwith very few training steps compared with other methods. The performance will\nsurpass the existing baselines after about ten steps of training under six\nbenchmarks.", "published": "2025-06-03 14:46:00", "link": "http://arxiv.org/abs/2506.02951v1", "categories": ["cs.CL", "cs.MA"], "primary_category": "cs.CL"}
{"title": "Quantitative LLM Judges", "abstract": "LLM-as-a-judge is a framework in which a large language model (LLM)\nautomatically evaluates the output of another LLM. We propose quantitative LLM\njudges, which align evaluation scores of existing LLM judges to human scores in\na given domain using regression models. The models are trained to improve the\nscore of the original judge by using the judge's textual evaluation and score.\nWe present four quantitative judges for different types of absolute and\nrelative feedback, which showcases the generality and versatility of our\nframework. Our framework is more computationally efficient than supervised\nfine-tuning and can be more statistically efficient when human feedback is\nlimited, which is expected in most applications of our work. We validate these\nclaims empirically on four datasets using two base judges. Our experiments show\nthat quantitative judges can effectively improve the predictive power of\nexisting judges through post-hoc modeling.", "published": "2025-06-03 14:44:23", "link": "http://arxiv.org/abs/2506.02945v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "INESC-ID @ eRisk 2025: Exploring Fine-Tuned, Similarity-Based, and Prompt-Based Approaches to Depression Symptom Identification", "abstract": "In this work, we describe our team's approach to eRisk's 2025 Task 1: Search\nfor Symptoms of Depression. Given a set of sentences and the Beck's Depression\nInventory - II (BDI) questionnaire, participants were tasked with submitting up\nto 1,000 sentences per depression symptom in the BDI, sorted by relevance.\nParticipant submissions were evaluated according to standard Information\nRetrieval (IR) metrics, including Average Precision (AP) and R-Precision\n(R-PREC). The provided training data, however, consisted of sentences labeled\nas to whether a given sentence was relevant or not w.r.t. one of BDI's\nsymptoms. Due to this labeling limitation, we framed our development as a\nbinary classification task for each BDI symptom, and evaluated accordingly. To\nthat end, we split the available labeled data into training and validation\nsets, and explored foundation model fine-tuning, sentence similarity, Large\nLanguage Model (LLM) prompting, and ensemble techniques. The validation results\nrevealed that fine-tuning foundation models yielded the best performance,\nparticularly when enhanced with synthetic data to mitigate class imbalance. We\nalso observed that the optimal approach varied by symptom. Based on these\ninsights, we devised five independent test runs, two of which used ensemble\nmethods. These runs achieved the highest scores in the official IR evaluation,\noutperforming submissions from 16 other teams.", "published": "2025-06-03 14:25:12", "link": "http://arxiv.org/abs/2506.02924v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "I.2.7; I.5.4; J.3; H.3.3"], "primary_category": "cs.CL"}
{"title": "A Controllable Examination for Long-Context Language Models", "abstract": "Existing frameworks for evaluating long-context language models (LCLM) can be\nbroadly categorized into real-world and synthetic tasks. Despite their utility,\nboth approaches are accompanied by certain intrinsic limitations. Real-world\ntasks are too complex to interpret or characterize and are susceptible to data\ncontamination. In contrast, synthetic tasks often adopt the\nneedle-in-the-haystack (NIAH) format, wherein a lack of coherence between the\n\"needle\" and the \"haystack\" compromises their validity as proxies for realistic\napplications. In response to these challenges, we posit that an ideal\nlong-context evaluation framework should be characterized by three essential\nfeatures: $\\textit{seamless context}$, $\\textit{controllable setting}$, and\n$\\textit{sound evaluation}$. This study introduces $\\textbf{LongBioBench}$, a\nnovel benchmark that utilizes artificially generated biographies as a\ncontrolled environment for assessing LCLMs across dimensions of\n$\\textit{understanding}$, $\\textit{reasoning}$, and $\\textit{trustworthiness}$.\nOur experimental evaluation, which includes $\\textbf{18}$ LCLMs in total,\ndemonstrates that most models still exhibit deficiencies in semantic\nunderstanding and elementary reasoning over retrieved results and are less\ntrustworthy as context length increases. Our further analysis indicates some\ndesign choices employed by existing synthetic benchmarks, such as contextual\nnon-coherence, numerical needles, and the absence of distractors, rendering\nthem vulnerable to test the model long-context capabilities. Moreover, we also\nreveal that long-context continual pretraining primarily adjusts RoPE embedding\nto accommodate extended context lengths. To sum up, compared to previous\nsynthetic benchmarks, LongBioBench achieves a better trade-off between\nmirroring authentic language tasks and maintaining controllability, and is\nhighly interpretable and configurable.", "published": "2025-06-03 14:23:06", "link": "http://arxiv.org/abs/2506.02921v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cell-o1: Training LLMs to Solve Single-Cell Reasoning Puzzles with Reinforcement Learning", "abstract": "Cell type annotation is a key task in analyzing the heterogeneity of\nsingle-cell RNA sequencing data. Although recent foundation models automate\nthis process, they typically annotate cells independently, without considering\nbatch-level cellular context or providing explanatory reasoning. In contrast,\nhuman experts often annotate distinct cell types for different cell clusters\nbased on their domain knowledge. To mimic this workflow, we introduce the\nCellPuzzles task, where the objective is to assign unique cell types to a batch\nof cells. This benchmark spans diverse tissues, diseases, and donor conditions,\nand requires reasoning across the batch-level cellular context to ensure label\nuniqueness. We find that off-the-shelf large language models (LLMs) struggle on\nCellPuzzles, with the best baseline (OpenAI's o1) achieving only 19.0%\nbatch-level accuracy. To fill this gap, we propose Cell-o1, a 7B LLM trained\nvia supervised fine-tuning on distilled reasoning traces, followed by\nreinforcement learning with batch-level rewards. Cell-o1 achieves\nstate-of-the-art performance, outperforming o1 by over 73% and generalizing\nwell across contexts. Further analysis of training dynamics and reasoning\nbehaviors provides insights into batch-level annotation performance and\nemergent expert-like reasoning. Code and data are available at\nhttps://github.com/ncbi-nlp/cell-o1.", "published": "2025-06-03 14:16:53", "link": "http://arxiv.org/abs/2506.02911v1", "categories": ["cs.CL", "cs.AI", "cs.CE", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "IMPARA-GED: Grammatical Error Detection is Boosting Reference-free Grammatical Error Quality Estimator", "abstract": "We propose IMPARA-GED, a novel reference-free automatic grammatical error\ncorrection (GEC) evaluation method with grammatical error detection (GED)\ncapabilities. We focus on the quality estimator of IMPARA, an existing\nautomatic GEC evaluation method, and construct that of IMPARA-GED using a\npre-trained language model with enhanced GED capabilities. Experimental results\non SEEDA, a meta-evaluation dataset for automatic GEC evaluation methods,\ndemonstrate that IMPARA-GED achieves the highest correlation with human\nsentence-level evaluations.", "published": "2025-06-03 14:05:37", "link": "http://arxiv.org/abs/2506.02899v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Multi-Dialectal Dataset for German Dialect ASR and Dialect-to-Standard Speech Translation", "abstract": "Although Germany has a diverse landscape of dialects, they are\nunderrepresented in current automatic speech recognition (ASR) research. To\nenable studies of how robust models are towards dialectal variation, we present\nBetthupferl, an evaluation dataset containing four hours of read speech in\nthree dialect groups spoken in Southeast Germany (Franconian, Bavarian,\nAlemannic), and half an hour of Standard German speech. We provide both\ndialectal and Standard German transcriptions, and analyze the linguistic\ndifferences between them. We benchmark several multilingual state-of-the-art\nASR models on speech translation into Standard German, and find differences\nbetween how much the output resembles the dialectal vs. standardized\ntranscriptions. Qualitative error analyses of the best ASR model reveal that it\nsometimes normalizes grammatical differences, but often stays closer to the\ndialectal constructions.", "published": "2025-06-03 14:02:52", "link": "http://arxiv.org/abs/2506.02894v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Scaling Fine-Grained MoE Beyond 50B Parameters: Empirical Evaluation and Practical Insights", "abstract": "Mixture of Experts (MoE) architectures have emerged as pivotal for scaling\nLarge Language Models (LLMs) efficiently. Fine-grained MoE approaches -\nutilizing more numerous, smaller experts - have demonstrated potential in\nimproving model convergence and quality. This work proposes a set of training\nrecipes and provides a comprehensive empirical evaluation of fine-grained MoE,\ndirectly comparing its scaling properties against standard MoE configurations\nfor models with up to 56B total (17B active) parameters. We investigate\nconvergence speed, model performance on downstream benchmarks, and practical\ntraining considerations across various setups. Overall, at the largest scale we\nshow that fine-grained MoE achieves better validation loss and higher accuracy\nacross a set of downstream benchmarks. This study offers empirical grounding\nand practical insights for leveraging fine-grained MoE in the development of\nfuture large-scale models.", "published": "2025-06-03 13:55:48", "link": "http://arxiv.org/abs/2506.02890v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "CoT is Not True Reasoning, It Is Just a Tight Constraint to Imitate: A Theory Perspective", "abstract": "Chain-of-Thought (CoT) prompting has demonstrably enhanced the performance of\nLarge Language Models on tasks requiring multi-step inference. This success has\nled to widespread claims of emergent reasoning capabilities in these models. In\nthis paper, we present a theoretical counter-perspective: Chain-of-Thought\n(CoT) does not elicit genuine, abstract reasoning. Instead, we argue that\nChain-of-Thought functions as a powerful structural constraint that guides\nLarge Language Models to imitate the form of reasoning. By forcing the\ngeneration of intermediate steps, Chain-of-Thought leverages the model immense\ncapacity for sequence prediction and pattern matching, effectively constraining\nits output to sequences that resemble coherent thought processes.\nChain-of-Thought (CoT) prompting has demonstrably enhanced the performance of\nLarge Language Models on tasks requiring multi-step inference. This success has\nled to widespread claims of emergent reasoning capabilities in these models. In\nthis paper, we present a theoretical counter-perspective: Chain-of-Thought\n(CoT) does not elicit genuine, abstract reasoning. Instead, we argue that\nChain-of-Thought functions as a powerful structural constraint that guides\nLarge Language Models to imitate the form of reasoning. By forcing the\ngeneration of intermediate steps, Chain-of-Thought leverages the model immense\ncapacity for sequence prediction and pattern matching, effectively constraining\nits output to sequences that resemble coherent thought processes.", "published": "2025-06-03 13:45:01", "link": "http://arxiv.org/abs/2506.02878v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Token and Span Classification for Entity Recognition in French Historical Encyclopedias", "abstract": "Named Entity Recognition (NER) in historical texts presents unique challenges\ndue to non-standardized language, archaic orthography, and nested or\noverlapping entities. This study benchmarks a diverse set of NER approaches,\nranging from classical Conditional Random Fields (CRFs) and spaCy-based models\nto transformer-based architectures such as CamemBERT and sequence-labeling\nmodels like Flair. Experiments are conducted on the GeoEDdA dataset, a richly\nannotated corpus derived from 18th-century French encyclopedias. We propose\nframing NER as both token-level and span-level classification to accommodate\ncomplex nested entity structures typical of historical documents. Additionally,\nwe evaluate the emerging potential of few-shot prompting with generative\nlanguage models for low-resource scenarios. Our results demonstrate that while\ntransformer-based models achieve state-of-the-art performance, especially on\nnested entities, generative models offer promising alternatives when labeled\ndata are scarce. The study highlights ongoing challenges in historical NER and\nsuggests avenues for hybrid approaches combining symbolic and neural methods to\nbetter capture the intricacies of early modern French text.", "published": "2025-06-03 13:37:44", "link": "http://arxiv.org/abs/2506.02872v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Demystifying Reasoning Dynamics with Mutual Information: Thinking Tokens are Information Peaks in LLM Reasoning", "abstract": "Large reasoning models (LRMs) have demonstrated impressive capabilities in\ncomplex problem-solving, yet their internal reasoning mechanisms remain poorly\nunderstood. In this paper, we investigate the reasoning trajectories of LRMs\nfrom an information-theoretic perspective. By tracking how mutual information\n(MI) between intermediate representations and the correct answer evolves during\nLRM reasoning, we observe an interesting MI peaks phenomenon: the MI at\nspecific generative steps exhibits a sudden and significant increase during\nLRM's reasoning process. We theoretically analyze such phenomenon and show that\nas MI increases, the probability of model's prediction error decreases.\nFurthermore, these MI peaks often correspond to tokens expressing reflection or\ntransition, such as ``Hmm'', ``Wait'' and ``Therefore,'' which we term as the\nthinking tokens. We then demonstrate that these thinking tokens are crucial for\nLRM's reasoning performance, while other tokens has minimal impacts. Building\non these analyses, we propose two simple yet effective methods to improve LRM's\nreasoning performance, by delicately leveraging these thinking tokens. Overall,\nour work provides novel insights into the reasoning mechanisms of LRMs and\noffers practical ways to improve their reasoning capabilities. The code is\navailable at https://github.com/ChnQ/MI-Peaks.", "published": "2025-06-03 13:31:10", "link": "http://arxiv.org/abs/2506.02867v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "TO-GATE: Clarifying Questions and Summarizing Responses with Trajectory Optimization for Eliciting Human Preference", "abstract": "Large language models (LLMs) can effectively elicit human preferences through\nmulti-turn dialogue. Complex tasks can be accomplished through iterative\nclarifying questions and final responses generated by an LLM acting as a\nquestioner (STaR-GATE; Andukuri et al., 2024}). However, existing approaches\nbased on self-taught reasoning struggle to identify optimal dialogue\ntrajectories and avoid irrelevant questions to the tasks. To address this\nlimitation, we propose TO-GATE, a novel framework that enhances question\ngeneration through trajectory optimization, which consists of two key\ncomponents: a clarification resolver that generates optimal questioning\ntrajectories, and a summarizer that ensures task-aligned final responses. The\ntrajectory optimization enables the model to produce effective elicitation\nquestions and summary responses tailored to specific tasks. Experimental\nresults demonstrate that TO-GATE significantly outperforms baseline methods,\nachieving a 9.32% improvement on standard preference elicitation tasks.", "published": "2025-06-03 12:58:07", "link": "http://arxiv.org/abs/2506.02827v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ProcrustesGPT: Compressing LLMs with Structured Matrices and Orthogonal Transformations", "abstract": "Large language models (LLMs) demonstrate impressive results in natural\nlanguage processing tasks but require a significant amount of computational and\nmemory resources. Structured matrix representations are a promising way for\nreducing the number of parameters of these models. However, it seems\nunrealistic to expect that weight matrices of pretrained models can be\naccurately represented by structured matrices without any fine-tuning. To\novercome this issue, we utilize the fact that LLM output is invariant under\ncertain orthogonal transformations of weight matrices. This insight can be\nleveraged to identify transformations that significantly improve the\ncompressibility of weights within structured classes. The proposed approach is\napplicable to various types of structured matrices that support efficient\nprojection operations. Code is available at\nhttps://github.com/GrishKate/ProcrustesGPT", "published": "2025-06-03 12:47:23", "link": "http://arxiv.org/abs/2506.02818v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SemVink: Advancing VLMs' Semantic Understanding of Optical Illusions via Visual Global Thinking", "abstract": "Vision-language models (VLMs) excel in semantic tasks but falter at a core\nhuman capability: detecting hidden content in optical illusions or AI-generated\nimages through perceptual adjustments like zooming. We introduce HC-Bench, a\nbenchmark of 112 images with hidden text, objects, and illusions, revealing\nthat leading VLMs achieve near-zero accuracy (0-5.36%)-even with explicit\nprompting. Humans resolve such ambiguities instinctively, yet VLMs fail due to\nan overreliance on high-level semantics. Strikingly, we propose SemVink\n(Semantic Visual Thinking) by simply scaling images to low resolutions (32-128\npixels), which unlocks >99% accuracy by eliminating redundant visual noise.\nThis exposes a critical architectural flaw: VLMs prioritize abstract reasoning\nover low-level visual operations crucial for real-world robustness. Our work\nurges a shift toward hybrid models integrating multi-scale processing, bridging\nthe gap between computational vision and human cognition for applications in\nmedical imaging, security, and beyond.", "published": "2025-06-03 12:33:47", "link": "http://arxiv.org/abs/2506.02803v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Rethinking Machine Unlearning in Image Generation Models", "abstract": "With the surge and widespread application of image generation models, data\nprivacy and content safety have become major concerns and attracted great\nattention from users, service providers, and policymakers. Machine unlearning\n(MU) is recognized as a cost-effective and promising means to address these\nchallenges. Despite some advancements, image generation model unlearning (IGMU)\nstill faces remarkable gaps in practice, e.g., unclear task discrimination and\nunlearning guidelines, lack of an effective evaluation framework, and\nunreliable evaluation metrics. These can hinder the understanding of unlearning\nmechanisms and the design of practical unlearning algorithms. We perform\nexhaustive assessments over existing state-of-the-art unlearning algorithms and\nevaluation standards, and discover several critical flaws and challenges in\nIGMU tasks. Driven by these limitations, we make several core contributions, to\nfacilitate the comprehensive understanding, standardized categorization, and\nreliable evaluation of IGMU. Specifically, (1) We design CatIGMU, a novel\nhierarchical task categorization framework. It provides detailed implementation\nguidance for IGMU, assisting in the design of unlearning algorithms and the\nconstruction of testbeds. (2) We introduce EvalIGMU, a comprehensive evaluation\nframework. It includes reliable quantitative metrics across five critical\naspects. (3) We construct DataIGM, a high-quality unlearning dataset, which can\nbe used for extensive evaluations of IGMU, training content detectors for\njudgment, and benchmarking the state-of-the-art unlearning algorithms. With\nEvalIGMU and DataIGM, we discover that most existing IGMU algorithms cannot\nhandle the unlearning well across different evaluation dimensions, especially\nfor preservation and robustness. Code and models are available at\nhttps://github.com/ryliu68/IGMU.", "published": "2025-06-03 11:25:14", "link": "http://arxiv.org/abs/2506.02761v1", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Exploiting the English Vocabulary Profile for L2 word-level vocabulary assessment with LLMs", "abstract": "Vocabulary use is a fundamental aspect of second language (L2) proficiency.\nTo date, its assessment by automated systems has typically examined the\ncontext-independent, or part-of-speech (PoS) related use of words. This paper\nintroduces a novel approach to enable fine-grained vocabulary evaluation\nexploiting the precise use of words within a sentence. The scheme combines\nlarge language models (LLMs) with the English Vocabulary Profile (EVP). The EVP\nis a standard lexical resource that enables in-context vocabulary use to be\nlinked with proficiency level. We evaluate the ability of LLMs to assign\nproficiency levels to individual words as they appear in L2 learner writing,\naddressing key challenges such as polysemy, contextual variation, and\nmulti-word expressions. We compare LLMs to a PoS-based baseline. LLMs appear to\nexploit additional semantic information that yields improved performance. We\nalso explore correlations between word-level proficiency and essay-level\nproficiency. Finally, the approach is applied to examine the consistency of the\nEVP proficiency levels. Results show that LLMs are well-suited for the task of\nvocabulary assessment.", "published": "2025-06-03 11:23:57", "link": "http://arxiv.org/abs/2506.02758v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multi-task Learning with Active Learning for Arabic Offensive Speech Detection", "abstract": "The rapid growth of social media has amplified the spread of offensive,\nviolent, and vulgar speech, which poses serious societal and cybersecurity\nconcerns. Detecting such content in Arabic text is particularly complex due to\nlimited labeled data, dialectal variations, and the language's inherent\ncomplexity. This paper proposes a novel framework that integrates multi-task\nlearning (MTL) with active learning to enhance offensive speech detection in\nArabic social media text. By jointly training on two auxiliary tasks, violent\nand vulgar speech, the model leverages shared representations to improve the\ndetection accuracy of the offensive speech. Our approach dynamically adjusts\ntask weights during training to balance the contribution of each task and\noptimize performance. To address the scarcity of labeled data, we employ an\nactive learning strategy through several uncertainty sampling techniques to\niteratively select the most informative samples for model training. We also\nintroduce weighted emoji handling to better capture semantic cues. Experimental\nresults on the OSACT2022 dataset show that the proposed framework achieves a\nstate-of-the-art macro F1-score of 85.42%, outperforming existing methods while\nusing significantly fewer fine-tuning samples. The findings of this study\nhighlight the potential of integrating MTL with active learning for efficient\nand accurate offensive language detection in resource-constrained settings.", "published": "2025-06-03 11:17:03", "link": "http://arxiv.org/abs/2506.02753v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Stereotypical gender actions can be extracted from Web text", "abstract": "We extracted gender-specific actions from text corpora and Twitter, and\ncompared them to stereotypical expectations of people. We used Open Mind Common\nSense (OMCS), a commonsense knowledge repository, to focus on actions that are\npertinent to common sense and daily life of humans. We use the gender\ninformation of Twitter users and Web-corpus-based pronoun/name gender\nheuristics to compute the gender bias of the actions. With high recall, we\nobtained a Spearman correlation of 0.47 between corpus-based predictions and a\nhuman gold standard, and an area under the ROC curve of 0.76 when predicting\nthe polarity of the gold standard. We conclude that it is feasible to use\nnatural text (and a Twitter-derived corpus in particular) in order to augment\ncommonsense repositories with the stereotypical gender expectations of actions.\nWe also present a dataset of 441 commonsense actions with human judges' ratings\non whether the action is typically/slightly masculine/feminine (or neutral),\nand another larger dataset of 21,442 actions automatically rated by the methods\nwe investigate in this study.", "published": "2025-06-03 10:55:00", "link": "http://arxiv.org/abs/2506.02740v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Exploratory Framework for Future SETI Applications: Detecting Generative Reactivity via Language Models", "abstract": "We present an exploratory framework to test whether noise-like input can\ninduce structured responses in language models. Instead of assuming that\nextraterrestrial signals must be decoded, we evaluate whether inputs can\ntrigger linguistic behavior in generative systems. This shifts the focus from\ndecoding to viewing structured output as a sign of underlying regularity in the\ninput. We tested GPT-2 small, a 117M-parameter model trained on English text,\nusing four types of acoustic input: human speech, humpback whale vocalizations,\nPhylloscopus trochilus birdsong, and algorithmically generated white noise. All\ninputs were treated as noise-like, without any assumed symbolic encoding. To\nassess reactivity, we defined a composite score called Semantic Induction\nPotential (SIP), combining entropy, syntax coherence, compression gain, and\nrepetition penalty. Results showed that whale and bird vocalizations had higher\nSIP scores than white noise, while human speech triggered only moderate\nresponses. This suggests that language models may detect latent structure even\nin data without conventional semantics. We propose that this approach could\ncomplement traditional SETI methods, especially in cases where communicative\nintent is unknown. Generative reactivity may offer a different way to identify\ndata worth closer attention.", "published": "2025-06-03 10:46:57", "link": "http://arxiv.org/abs/2506.02730v1", "categories": ["astro-ph.IM", "cs.CL"], "primary_category": "astro-ph.IM"}
{"title": "RACE-Align: Retrieval-Augmented and Chain-of-Thought Enhanced Preference Alignment for Large Language Models", "abstract": "Large Language Models (LLMs) struggle with accuracy, domain-specific\nreasoning, and interpretability in vertical domains. Traditional preference\nalignment methods like Reinforcement Learning from Human Feedback (RLHF) and\nDirect Preference Optimization (DPO) often overlook the underlying knowledge\nsources and reasoning logic. This paper introduces RACE-Align\n(Retrieval-Augmented and Chain-of-Thought Enhanced Alignment), a novel\nframework designed to address these limitations. RACE-Align systematically\nconstructs a binary preference dataset incorporating external knowledge support\nand explicit Chain-of-Thought (CoT) reasoning, then aligns LLMs using the DPO\nalgorithm. The core innovation lies in its preference data construction\nstrategy: it integrates AI-driven retrieval for factual grounding, enhancing\nknowledgeability and accuracy, and emphasizes the optimization of\ndomain-specific CoT, treating the reasoning process itself as a key preference\ndimension. A multi-stage, AI-driven refinement pipeline cost-effectively\ngenerates these preference pairs. Experimental validation in Traditional\nChinese Medicine (TCM) using Qwen3-1.7B as the base model demonstrates that\nRACE-Align significantly outperforms the original base model and a model\nfine-tuned only with Supervised Fine-Tuning (SFT). Improvements were observed\nacross multiple dimensions, including answer accuracy, information richness,\napplication of TCM thinking patterns, logicality and depth of reasoning, and\ninterpretability. These findings suggest RACE-Align offers an effective pathway\nto enhance LLMs' knowledge application, reasoning reliability, and process\ntransparency in complex vertical domains.", "published": "2025-06-03 10:36:38", "link": "http://arxiv.org/abs/2506.02726v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7; I.2.6; H.3.3"], "primary_category": "cs.CL"}
{"title": "Benchmarking and Advancing Large Language Models for Local Life Services", "abstract": "Large language models (LLMs) have exhibited remarkable capabilities and\nachieved significant breakthroughs across various domains, leading to their\nwidespread adoption in recent years. Building on this progress, we investigate\ntheir potential in the realm of local life services. In this study, we\nestablish a comprehensive benchmark and systematically evaluate the performance\nof diverse LLMs across a wide range of tasks relevant to local life services.\nTo further enhance their effectiveness, we explore two key approaches: model\nfine-tuning and agent-based workflows. Our findings reveal that even a\nrelatively compact 7B model can attain performance levels comparable to a much\nlarger 72B model, effectively balancing inference cost and model capability.\nThis optimization greatly enhances the feasibility and efficiency of deploying\nLLMs in real-world online services, making them more practical and accessible\nfor local life applications.", "published": "2025-06-03 10:18:19", "link": "http://arxiv.org/abs/2506.02720v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Iterative Self-Improvement of Vision Language Models for Image Scoring and Self-Explanation", "abstract": "Image scoring is a crucial task in numerous real-world applications. To trust\na model's judgment, understanding its rationale is essential. This paper\nproposes a novel training method for Vision Language Models (VLMs) to generate\nnot only image scores but also corresponding justifications in natural\nlanguage. Leveraging only an image scoring dataset and an instruction-tuned\nVLM, our method enables self-training, utilizing the VLM's generated text\nwithout relying on external data or models. In addition, we introduce a simple\nmethod for creating a dataset designed to improve alignment between predicted\nscores and their textual justifications. By iteratively training the model with\nDirect Preference Optimization on two distinct datasets and merging them, we\ncan improve both scoring accuracy and the coherence of generated explanations.", "published": "2025-06-03 10:04:19", "link": "http://arxiv.org/abs/2506.02708v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "On Entity Identification in Language Models", "abstract": "We analyze the extent to which internal representations of language models\n(LMs) identify and distinguish mentions of named entities, focusing on the\nmany-to-many correspondence between entities and their mentions. We first\nformulate two problems of entity mentions -- ambiguity and variability -- and\npropose a framework analogous to clustering quality metrics. Specifically, we\nquantify through cluster analysis of LM internal representations the extent to\nwhich mentions of the same entity cluster together and mentions of different\nentities remain separated. Our experiments examine five Transformer-based\nautoregressive models, showing that they effectively identify and distinguish\nentities with metrics analogous to precision and recall ranging from 0.66 to\n0.9. Further analysis reveals that entity-related information is compactly\nrepresented in a low-dimensional linear subspace at early LM layers.\nAdditionally, we clarify how the characteristics of entity representations\ninfluence word prediction performance. These findings are interpreted through\nthe lens of isomorphism between LM representations and entity-centric knowledge\nstructures in the real world, providing insights into how LMs internally\norganize and use entity information.", "published": "2025-06-03 09:55:21", "link": "http://arxiv.org/abs/2506.02701v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MASTER: Enhancing Large Language Model via Multi-Agent Simulated Teaching", "abstract": "Instruction fine-tuning is crucial in NLP tasks, enhancing pretrained models'\ninstruction-following capabilities and task-specific performance. However,\nobtaining high-quality fine-tuning data for large models is challenging due to\ndata collection difficulties and high production costs. To address this, we\npropose MASTER, a novel data augmentation method that enriches original data\nthrough interactions among multiple agents with varying cognitive levels. We\nsimulate three pedagogically grounded teaching scenarios, leveraging\nmulti-agent conversations to generate high-quality teacher-student interaction\ndata. Utilizing MASTER, we construct BOOST-QA, a fine-tuning dataset augmented\nfrom existing datasets like Orca-Math-200k, ProcQA, and OpenHermes2.5.\nExperiments show that models fine-tuned with BOOST-QA perform excellently\nacross multiple benchmarks, demonstrating strong multitask generalization.\nNotably, MASTER significantly improves models' reasoning abilities in complex\ntasks, providing valuable insights for future research.", "published": "2025-06-03 09:41:35", "link": "http://arxiv.org/abs/2506.02689v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Decompose, Plan in Parallel, and Merge: A Novel Paradigm for Large Language Models based Planning with Multiple Constraints", "abstract": "Despite significant advances in Large Language Models (LLMs), planning tasks\nstill present challenges for LLM-based agents. Existing planning methods face\ntwo key limitations: heavy constraints and cascading errors. To address these\nlimitations, we propose a novel parallel planning paradigm, which Decomposes,\nPlans for subtasks in Parallel, and Merges subplans into a final plan (DPPM).\nSpecifically, DPPM decomposes the complex task based on constraints into\nsubtasks, generates the subplan for each subtask in parallel, and merges them\ninto a global plan. In addition, our approach incorporates a verification and\nrefinement module, enabling error correction and conflict resolution.\nExperimental results demonstrate that DPPM significantly outperforms existing\nmethods in travel planning tasks.", "published": "2025-06-03 09:33:13", "link": "http://arxiv.org/abs/2506.02683v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TL;DR: Too Long, Do Re-weighting for Effcient LLM Reasoning Compression", "abstract": "Large Language Models (LLMs) have recently achieved remarkable progress by\nleveraging Reinforcement Learning and extended Chain-of-Thought (CoT)\ntechniques. However, the challenge of performing efficient language\nreasoning--especially during inference with extremely long outputs--has drawn\nincreasing attention from the research community. In this work, we propose a\ndynamic ratio-based training pipeline that does not rely on sophisticated data\nannotations or interpolation between multiple models. We continuously balance\nthe weights between the model's System-1 and System-2 data to eliminate\nredundant reasoning processes while preserving the model's reasoning\ncapability. We validate our approach across models on DeepSeek-R1-Distill-7B\nand DeepSeek-R1-Distill-14B and on a diverse set of benchmarks with varying\ndifficulty levels. Our method significantly reduces the number of output tokens\nby nearly 40% while maintaining the accuracy of the reasoning. Our code and\ndata will be available soon.", "published": "2025-06-03 09:23:41", "link": "http://arxiv.org/abs/2506.02678v1", "categories": ["cs.CL", "cs.CE", "cs.NA", "math.NA"], "primary_category": "cs.CL"}
{"title": "EvaLearn: Quantifying the Learning Capability and Efficiency of LLMs via Sequential Problem Solving", "abstract": "We introduce EvaLearn, a pioneering benchmark designed to evaluate large\nlanguage models (LLMs) on their learning capability and efficiency in\nchallenging tasks, a critical, yet underexplored aspect of model potential.\nEvaLearn contains 648 challenging problems across six task types, grouped into\n182 sequences, each sequence dedicated to one task type. Diverging from most\nexisting benchmarks that evaluate models in parallel, EvaLearn requires models\nto solve problems sequentially, allowing them to leverage the experience gained\nfrom previous solutions. EvaLearn provides five comprehensive automated metrics\nto evaluate models and quantify their learning capability and efficiency. We\nextensively benchmark nine frontier models and observe varied performance\nprofiles: some models, such as Claude-3.7-sonnet, start with moderate initial\nperformance but exhibit strong learning ability, while some models struggle to\nbenefit from experience and may even show negative transfer. Moreover, we\ninvestigate model performance under two learning settings and find that\ninstance-level rubrics and teacher-model feedback further facilitate model\nlearning. Importantly, we observe that current LLMs with stronger static\nabilities do not show a clear advantage in learning capability across all\ntasks, highlighting that EvaLearn evaluates a new dimension of model\nperformance. We hope EvaLearn provides a novel evaluation perspective for\nassessing LLM potential and understanding the gap between models and human\ncapabilities, promoting the development of deeper and more dynamic evaluation\napproaches. All datasets, the automatic evaluation framework, and the results\nstudied in this paper are available at the GitHub repository.", "published": "2025-06-03 09:18:33", "link": "http://arxiv.org/abs/2506.02672v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Are Economists Always More Introverted? Analyzing Consistency in Persona-Assigned LLMs", "abstract": "Personalized Large Language Models (LLMs) are increasingly used in diverse\napplications, where they are assigned a specific persona - such as a happy high\nschool teacher - to guide their responses. While prior research has examined\nhow well LLMs adhere to predefined personas in writing style, a comprehensive\nanalysis of consistency across different personas and task types is lacking. In\nthis paper, we introduce a new standardized framework to analyze consistency in\npersona-assigned LLMs. We define consistency as the extent to which a model\nmaintains coherent responses when assigned the same persona across different\ntasks and runs. Our framework evaluates personas across four different\ncategories (happiness, occupation, personality, and political stance) spanning\nmultiple task dimensions (survey writing, essay generation, social media post\ngeneration, single turn, and multi-turn conversations). Our findings reveal\nthat consistency is influenced by multiple factors, including the assigned\npersona, stereotypes, and model design choices. Consistency also varies across\ntasks, increasing with more structured tasks and additional context. All code\nis available on GitHub.", "published": "2025-06-03 09:12:23", "link": "http://arxiv.org/abs/2506.02659v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Overcoming Data Scarcity in Multi-Dialectal Arabic ASR via Whisper Fine-Tuning", "abstract": "Although commercial Arabic automatic speech recognition (ASR) systems support\nModern Standard Arabic (MSA), they struggle with dialectal speech. We\ninvestigate the effect of fine-tuning OpenAI's Whisper on five major Arabic\ndialects (Gulf, Levantine, Iraqi, Egyptian, Maghrebi) using Mozilla Common\nVoice for MSA and the MASC dataset for dialectal speech. We evaluate MSA\ntraining size effects, benefits of pre-training on MSA data, and\ndialect-specific versus dialect-pooled models. We find that small amounts of\nMSA fine-tuning data yield substantial improvements for smaller models,\nmatching larger non-fine-tuned models. While MSA pre-training shows minimal\nbenefit, suggesting limited shared features between MSA and dialects, our\ndialect-pooled models perform comparably to dialect-specific ones. This\nindicates that pooling dialectal data, when properly balanced, can help address\ndata scarcity in low-resource ASR without significant performance loss.", "published": "2025-06-03 08:41:49", "link": "http://arxiv.org/abs/2506.02627v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "EssayBench: Evaluating Large Language Models in Multi-Genre Chinese Essay Writing", "abstract": "Chinese essay writing and its evaluation are critical in educational\ncontexts, yet the capabilities of Large Language Models (LLMs) in this domain\nremain largely underexplored. Existing benchmarks often rely on coarse-grained\ntext quality metrics, largely overlooking the structural and rhetorical\ncomplexities of Chinese essays, particularly across diverse genres. To address\nthis gap, we propose \\benchName, a multi-genre benchmark specifically designed\nfor Chinese essay writing across four major genres: Argumentative, Narrative,\nDescriptive, and Expository. We curate and refine a total of 728 real-world\nprompts to ensure authenticity and meticulously categorize them into the\n\\textit{Open-Ended} and \\textit{Constrained} sets to capture diverse writing\nscenarios. To reliably evaluate generated essays, we develop a fine-grained,\ngenre-specific scoring framework that hierarchically aggregates scores. We\nfurther validate our evaluation protocol through a comprehensive human\nagreement study. Finally, we benchmark 15 large-sized LLMs, analyzing their\nstrengths and limitations across genres and instruction types. With \\benchName,\nwe aim to advance LLM-based Chinese essay evaluation and inspire future\nresearch on improving essay generation in educational settings.", "published": "2025-06-03 08:14:46", "link": "http://arxiv.org/abs/2506.02596v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Beyond the Surface: Measuring Self-Preference in LLM Judgments", "abstract": "Recent studies show that large language models (LLMs) exhibit self-preference\nbias when serving as judges, meaning they tend to favor their own responses\nover those generated by other models. Existing methods typically measure this\nbias by calculating the difference between the scores a judge model assigns to\nits own responses and those it assigns to responses from other models. However,\nthis approach conflates self-preference bias with response quality, as\nhigher-quality responses from the judge model may also lead to positive score\ndifferences, even in the absence of bias. To address this issue, we introduce\ngold judgments as proxies for the actual quality of responses and propose the\nDBG score, which measures self-preference bias as the difference between the\nscores assigned by the judge model to its own responses and the corresponding\ngold judgments. Since gold judgments reflect true response quality, the DBG\nscore mitigates the confounding effect of response quality on bias measurement.\nUsing the DBG score, we conduct comprehensive experiments to assess\nself-preference bias across LLMs of varying versions, sizes, and reasoning\nabilities. Additionally, we investigate two factors that influence and help\nalleviate self-preference bias: response text style and the post-training data\nof judge models. Finally, we explore potential underlying mechanisms of\nself-preference bias from an attention-based perspective. Our code and data are\navailable at https://github.com/zhiyuanc2001/self-preference.", "published": "2025-06-03 08:12:47", "link": "http://arxiv.org/abs/2506.02592v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On Generalization across Measurement Systems: LLMs Entail More Test-Time Compute for Underrepresented Cultures", "abstract": "Measurement systems (e.g., currencies) differ across cultures, but the\nconversions between them are well defined so that humans can state facts using\nany measurement system of their choice. Being available to users from diverse\ncultural backgrounds, large language models (LLMs) should also be able to\nprovide accurate information irrespective of the measurement system at hand.\nUsing newly compiled datasets we test if this is the case for seven open-source\nLLMs, addressing three key research questions: (RQ1) What is the default system\nused by LLMs for each type of measurement? (RQ2) Do LLMs' answers and their\naccuracy vary across different measurement systems? (RQ3) Can LLMs mitigate\npotential challenges w.r.t. underrepresented systems via reasoning? Our\nfindings show that LLMs default to the measurement system predominantly used in\nthe data. Additionally, we observe considerable instability and variance in\nperformance across different measurement systems. While this instability can in\npart be mitigated by employing reasoning methods such as chain-of-thought\n(CoT), this implies longer responses and thereby significantly increases\ntest-time compute (and inference costs), marginalizing users from cultural\nbackgrounds that use underrepresented measurement systems.", "published": "2025-06-03 08:12:28", "link": "http://arxiv.org/abs/2506.02591v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Synthetic Speech Source Tracing using Metric Learning", "abstract": "This paper addresses source tracing in synthetic speech-identifying\ngenerative systems behind manipulated audio via speaker recognition-inspired\npipelines. While prior work focuses on spoofing detection, source tracing lacks\nrobust solutions. We evaluate two approaches: classification-based and\nmetric-learning. We tested our methods on the MLAADv5 benchmark using ResNet\nand self-supervised learning (SSL) backbones. The results show that ResNet\nachieves competitive performance with the metric learning approach, matching\nand even exceeding SSL-based systems. Our work demonstrates ResNet's viability\nfor source tracing while underscoring the need to optimize SSL representations\nfor this task. Our work bridges speaker recognition methodologies with audio\nforensic challenges, offering new directions for combating synthetic media\nmanipulation.", "published": "2025-06-03 08:12:15", "link": "http://arxiv.org/abs/2506.02590v1", "categories": ["cs.SD", "cs.CL"], "primary_category": "cs.SD"}
{"title": "Evaluating Named Entity Recognition Models for Russian Cultural News Texts: From BERT to LLM", "abstract": "This paper addresses the challenge of Named Entity Recognition (NER) for\nperson names within the specialized domain of Russian news texts concerning\ncultural events. The study utilizes the unique SPbLitGuide dataset, a\ncollection of event announcements from Saint Petersburg spanning 1999 to 2019.\nA comparative evaluation of diverse NER models is presented, encompassing\nestablished transformer-based architectures such as DeepPavlov, RoBERTa, and\nSpaCy, alongside recent Large Language Models (LLMs) including GPT-3.5, GPT-4,\nand GPT-4o. Key findings highlight the superior performance of GPT-4o when\nprovided with specific prompting for JSON output, achieving an F1 score of\n0.93. Furthermore, GPT-4 demonstrated the highest precision at 0.99. The\nresearch contributes to a deeper understanding of current NER model\ncapabilities and limitations when applied to morphologically rich languages\nlike Russian within the cultural heritage domain, offering insights for\nresearchers and practitioners. Follow-up evaluation with GPT-4.1 (April 2025)\nachieves F1=0.94 for both simple and structured prompts, demonstrating rapid\nprogress across model families and simplified deployment requirements.", "published": "2025-06-03 08:11:16", "link": "http://arxiv.org/abs/2506.02589v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "68T50", "I.2.7; H.3.3"], "primary_category": "cs.CL"}
{"title": "Prosodic Structure Beyond Lexical Content: A Study of Self-Supervised Learning", "abstract": "People exploit the predictability of lexical structures during text\ncomprehension. Though predictable structure is also present in speech, the\ndegree to which prosody, e.g. intonation, tempo, and loudness, contributes to\nsuch structure independently of the lexical content is unclear. This study\nleverages self-supervised learning (SSL) to examine the temporal granularity of\nstructures in the acoustic correlates of prosody. Representations from our\nproposed Masked Prosody Model can predict perceptual labels dependent on local\ninformation, such as word boundaries, but provide the most value for labels\ninvolving longer-term structures, like emotion recognition. Probing experiments\nacross various perceptual labels show strong relative gains over untransformed\npitch, energy, and voice activity features. Our results reveal the importance\nof SSL training objective timescale and highlight the value of complex\nSSL-encoded structures compared to more constrained classical structures.", "published": "2025-06-03 08:04:03", "link": "http://arxiv.org/abs/2506.02584v1", "categories": ["cs.CL", "cs.AI", "eess.AS"], "primary_category": "cs.CL"}
{"title": "IndoSafety: Culturally Grounded Safety for LLMs in Indonesian Languages", "abstract": "Although region-specific large language models (LLMs) are increasingly\ndeveloped, their safety remains underexplored, particularly in culturally\ndiverse settings like Indonesia, where sensitivity to local norms is essential\nand highly valued by the community. In this work, we present IndoSafety, the\nfirst high-quality, human-verified safety evaluation dataset tailored for the\nIndonesian context, covering five language varieties: formal and colloquial\nIndonesian, along with three major local languages: Javanese, Sundanese, and\nMinangkabau. IndoSafety is constructed by extending prior safety frameworks to\ndevelop a taxonomy that captures Indonesia's sociocultural context. We find\nthat existing Indonesian-centric LLMs often generate unsafe outputs,\nparticularly in colloquial and local language settings, while fine-tuning on\nIndoSafety significantly improves safety while preserving task performance. Our\nwork highlights the critical need for culturally grounded safety evaluation and\nprovides a concrete step toward responsible LLM deployment in multilingual\nsettings. Warning: This paper contains example data that may be offensive,\nharmful, or biased.", "published": "2025-06-03 07:53:55", "link": "http://arxiv.org/abs/2506.02573v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pruning General Large Language Models into Customized Expert Models", "abstract": "Large language models (LLMs) have revolutionized natural language processing,\nyet their substantial model sizes often require substantial computational\nresources. To preserve computing resources and accelerate inference speed, it\nis crucial to prune redundant parameters, especially for experienced users who\noften need compact expert models tailored to specific downstream scenarios.\nHowever, most existing pruning methods focus on preserving the model's general\ncapabilities, often requiring extensive post-training or suffering from\ndegraded performance due to coarse-grained pruning. In this work, we design a\n$\\underline{Cus}$tom $\\underline{Prun}$ing method ($\\texttt{Cus-Prun}$) to\nprune a large general model into a smaller lightweight expert model, which is\npositioned along the \"language\", \"domain\" and \"task\" dimensions. By identifying\nand pruning irrelevant neurons of each dimension, $\\texttt{Cus-Prun}$ creates\nexpert models without any post-training. Our experiments demonstrate that\n$\\texttt{Cus-Prun}$ consistently outperforms other methods, achieving minimal\nloss in both expert and general capabilities across various models from\ndifferent model families and sizes.", "published": "2025-06-03 07:47:30", "link": "http://arxiv.org/abs/2506.02561v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Response-Level Rewards Are All You Need for Online Reinforcement Learning in LLMs: A Mathematical Perspective", "abstract": "We study a common challenge in reinforcement learning for large language\nmodels (LLMs): the Zero-Reward Assumption, where non-terminal actions (i.e.,\nintermediate token generations) receive zero task-specific immediate reward,\nwhile only the final token receives a reward for the entire response. This\nassumption arises frequently in practice, as precise token-level rewards are\noften difficult or infeasible to obtain in LLM applications. In this work, we\nprovide a unifying theoretical perspective. We introduce the Trajectory Policy\nGradient Theorem, which shows that the policy gradient based on true, unknown\ntoken-level rewards can be unbiasedly estimated using only a response-level\nreward model, regardless of whether the Zero-Reward Assumption holds or not,\nfor algorithms in the REINFORCE and Actor-Critic families. This result reveals\nthat widely used methods such as PPO, GRPO, ReMax, and RLOO inherently possess\nthe capacity to model token-level reward signals, offering a theoretical\njustification for response-level reward approaches. Our findings pave the way\nfor more practical, efficient LLM fine-tuning, allowing developers to treat\ntraining algorithms as black boxes and focus on improving the response-level\nreward model with auxiliary sub-models. We also offer a detailed analysis of\npopular RL and non-RL methods, comparing their theoretical foundations and\npractical advantages across common LLM tasks. Finally, we propose a new\nalgorithm: Token-Reinforced Policy Optimization (TRePO), a theoretically\ngrounded method that is simpler than PPO, matches GRPO in memory efficiency,\nand holds promise for broad applicability.", "published": "2025-06-03 07:44:31", "link": "http://arxiv.org/abs/2506.02553v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "CoRe-MMRAG: Cross-Source Knowledge Reconciliation for Multimodal RAG", "abstract": "Multimodal Retrieval-Augmented Generation (MMRAG) has been introduced to\nenhance Multimodal Large Language Models by incorporating externally retrieved\nmultimodal knowledge, but it introduces two challenges: Parametric-Retrieved\nKnowledge Inconsistency (PRKI), where discrepancies between parametric and\nretrieved knowledge create uncertainty in determining reliability, and\nVisual-Textual Knowledge Inconsistency (VTKI), where misalignment between\nvisual and textual sources disrupts entity representation. To address these\nchallenges, we propose \\textbf{C}r\\textbf{o}ss-source knowledge\n\\textbf{Re}conciliation for \\textbf{M}ulti\\textbf{M}odal \\textbf{RAG}\n(CoRe-MMRAG), a novel end-to-end framework that effectively reconciles\ninconsistencies across knowledge sources. CoRe-MMRAG follows a four-stage\npipeline: it first generates an internal response from parametric knowledge,\nthen selects the most relevant multimodal evidence via joint similarity\nassessment, generates an external response, and finally integrates both to\nproduce a reliable answer. Additionally, a specialized training paradigm\nenhances knowledge source discrimination, multimodal integration, and unified\nanswer generation. Experiments on KB-VQA benchmarks show that CoRe-MMRAG\nachieves substantial improvements over baseline methods, achieving 5.6\\% and\n9.3\\% performance gains on InfoSeek and Encyclopedic-VQA, respectively. We\nrelease code and data at\n\\href{https://github.com/TyangJN/CoRe-MMRAG}{https://github.com/TyangJN/CoRe-MMRAG}.", "published": "2025-06-03 07:32:40", "link": "http://arxiv.org/abs/2506.02544v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Answer Convergence as a Signal for Early Stopping in Reasoning", "abstract": "Chain-of-thought (CoT) prompting enhances reasoning in large language models\n(LLMs) but often leads to verbose and redundant outputs, thus increasing\ninference cost. We hypothesize that many reasoning steps are unnecessary for\nproducing correct answers. To investigate this, we start with a systematic\nstudy to examine what is the minimum reasoning required for a model to reach a\nstable decision. We find that on math reasoning tasks like math, models\ntypically converge to their final answers after 60\\% of the reasoning steps,\nsuggesting substantial redundancy in the remaining content. Based on these\ninsights, we propose three inference-time strategies to improve efficiency: (1)\nearly stopping via answer consistency, (2) boosting the probability of\ngenerating end-of-reasoning signals, and (3) a supervised method that learns\nwhen to stop based on internal activations. Experiments across five benchmarks\nand five open-weights LLMs show that our methods significantly reduce token\nusage with little or no accuracy drop. In particular, on NaturalQuestions,\nAnswer Consistency reduces tokens by over 40\\% while further improving\naccuracy. Our work underscores the importance of cost-effective reasoning\nmethods that operate at inference time, offering practical benefits for\nreal-world applications.", "published": "2025-06-03 07:20:54", "link": "http://arxiv.org/abs/2506.02536v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Natural Language Processing to Enhance Deliberation in Political Online Discussions: A Survey", "abstract": "Political online participation in the form of discussing political issues and\nexchanging opinions among citizens is gaining importance with more and more\nformats being held digitally. To come to a decision, a careful discussion and\nconsideration of opinions and a civil exchange of arguments, which is defined\nas the act of deliberation, is desirable. The quality of discussions and\nparticipation processes in terms of their deliberativeness highly depends on\nthe design of platforms and processes. To facilitate online communication for\nboth participants and initiators, machine learning methods offer a lot of\npotential. In this work we want to showcase which issues occur in political\nonline discussions and how machine learning can be used to counteract these\nissues and enhance deliberation.", "published": "2025-06-03 07:11:49", "link": "http://arxiv.org/abs/2506.02533v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "ReasoningFlow: Semantic Structure of Complex Reasoning Traces", "abstract": "Large reasoning models (LRMs) generate complex reasoning traces with\nplanning, reflection, verification, and backtracking. In this work, we\nintroduce ReasoningFlow, a unified schema for analyzing the semantic structures\nof these complex traces. ReasoningFlow parses traces into directed acyclic\ngraphs, enabling the characterization of distinct reasoning patterns as\nsubgraph structures. This human-interpretable representation offers promising\napplications in understanding, evaluating, and enhancing the reasoning\nprocesses of LRMs.", "published": "2025-06-03 07:11:34", "link": "http://arxiv.org/abs/2506.02532v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automated Web Application Testing: End-to-End Test Case Generation with Large Language Models and Screen Transition Graphs", "abstract": "Web applications are critical to modern software ecosystems, yet ensuring\ntheir reliability remains challenging due to the complexity and dynamic nature\nof web interfaces. Recent advances in large language models (LLMs) have shown\npromise in automating complex tasks, but limitations persist in handling\ndynamic navigation flows and complex form interactions. This paper presents an\nautomated system for generating test cases for two key aspects of web\napplication testing: site navigation and form filling. For site navigation, the\nsystem employs screen transition graphs and LLMs to model navigation flows and\ngenerate test scenarios. For form filling, it uses state graphs to handle\nconditional forms and automates Selenium script generation. Key contributions\ninclude: (1) a novel integration of graph structures and LLMs for site\nnavigation testing, (2) a state graph-based approach for automating\nform-filling test cases, and (3) a comprehensive dataset for evaluating\nform-interaction testing. Experimental results demonstrate the system's\neffectiveness in improving test coverage and robustness, advancing the state of\nweb application testing.", "published": "2025-06-03 07:08:21", "link": "http://arxiv.org/abs/2506.02529v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "I.2.7"], "primary_category": "cs.SE"}
{"title": "Multilingual Information Retrieval with a Monolingual Knowledge Base", "abstract": "Multilingual information retrieval has emerged as powerful tools for\nexpanding knowledge sharing across languages. On the other hand, resources on\nhigh quality knowledge base are often scarce and in limited languages,\ntherefore an effective embedding model to transform sentences from different\nlanguages into a feature vector space same as the knowledge base language\nbecomes the key ingredient for cross language knowledge sharing, especially to\ntransfer knowledge available in high-resource languages to low-resource ones.\nIn this paper we propose a novel strategy to fine-tune multilingual embedding\nmodels with weighted sampling for contrastive learning, enabling multilingual\ninformation retrieval with a monolingual knowledge base. We demonstrate that\nthe weighted sampling strategy produces performance gains compared to standard\nones by up to 31.03\\% in MRR and up to 33.98\\% in Recall@3. Additionally, our\nproposed methodology is language agnostic and applicable for both multilingual\nand code switching use cases.", "published": "2025-06-03 07:05:49", "link": "http://arxiv.org/abs/2506.02527v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Learning Together to Perform Better: Teaching Small-Scale LLMs to Collaborate via Preferential Rationale Tuning", "abstract": "LLMssuch as GPT-4 have shown a remarkable ability to solve complex questions\nby generating step-by-step rationales. Prior works have utilized this\ncapability to improve smaller and cheaper LMs (say, with 7B parameters).\nHowever, various practical constraints, such as copyright and legal issues,\nowing to lack of transparency in the pre-training data of large (often closed)\nmodels, prevent their use in commercial settings. Little focus has been given\nto improving the innate reasoning ability of smaller models without distilling\ninformation from larger LLMs. To address this, we propose COLLATE, a trainable\nframework that tunes a (small) LLM to generate those outputs from a pool of\ndiverse rationales that selectively improves the downstream task. COLLATE\nenforces multiple instances of the same LLM to exhibit distinct behavior and\nemploys them to generate rationales to obtain diverse outputs. The LLM is then\ntuned via preference optimization to choose the candidate rationale which\nmaximizes the likelihood of ground-truth answer. COLLATE outperforms several\ntrainable and prompting baselines on 5 datasets across 3 domains: maths problem\nsolving, natural language inference, and commonsense reasoning. We show the eff\nicacy of COLLATE on LLMs from different model families across varying parameter\nscales (1B to 8B) and demonstrate the benefit of multiple rationale providers\nguided by the end task through ablations. Code is released here\n(https://github.com/Sohanpatnaik106/collate).", "published": "2025-06-03 06:50:08", "link": "http://arxiv.org/abs/2506.02519v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FinChain: A Symbolic Benchmark for Verifiable Chain-of-Thought Financial Reasoning", "abstract": "Multi-step symbolic reasoning is critical for advancing downstream\nperformance on financial tasks. Yet, benchmarks for systematically evaluating\nthis capability are lacking. Existing datasets like FinQA and ConvFinQA\nsupervise only final numerical answers, without assessing intermediate\nreasoning steps. To address this, we introduce FinChain, the first symbolic\nbenchmark designed for verifiable Chain-of- Thought (CoT) financial reasoning.\nSpanning 54 topics across 12 financial domains, Fin- Chain offers five\nparameterized templates per topic, each varying in reasoning complexity and\ndomain expertise required. Each dataset instance includes an executable Python\ntrace, enabling automatic generation of extensive training data and easy\nadaptation to other domains. We also introduce ChainEval, a new metric for\nautomatic evaluation of both final answers and intermediate reasoning.\nBenchmarking 30 LLMs on our dataset, we find that even state-of-the-art models\nhave considerable room for improvement in multi-step financial reasoning. All\ntemplates and evaluation metrics for FinChain are available at https:\n//github.com/mbzuai-nlp/finchain.", "published": "2025-06-03 06:44:42", "link": "http://arxiv.org/abs/2506.02515v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "M$^3$FinMeeting: A Multilingual, Multi-Sector, and Multi-Task Financial Meeting Understanding Evaluation Dataset", "abstract": "Recent breakthroughs in large language models (LLMs) have led to the\ndevelopment of new benchmarks for evaluating their performance in the financial\ndomain. However, current financial benchmarks often rely on news articles,\nearnings reports, or announcements, making it challenging to capture the\nreal-world dynamics of financial meetings. To address this gap, we propose a\nnovel benchmark called $\\texttt{M$^3$FinMeeting}$, which is a multilingual,\nmulti-sector, and multi-task dataset designed for financial meeting\nunderstanding. First, $\\texttt{M$^3$FinMeeting}$ supports English, Chinese, and\nJapanese, enhancing comprehension of financial discussions in diverse\nlinguistic contexts. Second, it encompasses various industry sectors defined by\nthe Global Industry Classification Standard (GICS), ensuring that the benchmark\nspans a broad range of financial activities. Finally,\n$\\texttt{M$^3$FinMeeting}$ includes three tasks: summarization, question-answer\n(QA) pair extraction, and question answering, facilitating a more realistic and\ncomprehensive evaluation of understanding. Experimental results with seven\npopular LLMs reveal that even the most advanced long-context models have\nsignificant room for improvement, demonstrating the effectiveness of\n$\\texttt{M$^3$FinMeeting}$ as a benchmark for assessing LLMs' financial meeting\ncomprehension skills.", "published": "2025-06-03 06:41:09", "link": "http://arxiv.org/abs/2506.02510v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "KARE-RAG: Knowledge-Aware Refinement and Enhancement for RAG", "abstract": "Retrieval-Augmented Generation (RAG) enables large language models (LLMs) to\naccess broader knowledge sources, yet factual inconsistencies persist due to\nnoise in retrieved documents-even with advanced retrieval methods. We\ndemonstrate that enhancing generative models' capacity to process noisy content\nis equally critical for robust performance. In this paper, we present KARE-RAG\n(Knowledge-Aware Refinement and Enhancement for RAG), which improves knowledge\nutilization through three key innovations: (1) structured knowledge\nrepresentations that facilitate error detection during training, (2) Dense\nDirect Preference Optimization (DDPO)-a refined training objective that\nprioritizes correction of critical errors, and (3) a contrastive data\ngeneration pipeline that maintains semantic consistency while rectifying\nfactual inaccuracies. Experiments show our method significantly enhances\nstandard RAG pipelines across model scales, improving both in-domain and\nout-of-domain task performance without compromising general capabilities.\nNotably, these gains are achieved with modest training data, suggesting\ndata-efficient optimization is possible through targeted learning strategies.\nOur findings establish a new direction for RAG improvement: by improving how\nmodels learn to process retrieved content, we can enhance performance across\ndiverse inference paradigms. All data and code will be publicly available on\nGithub.", "published": "2025-06-03 06:31:17", "link": "http://arxiv.org/abs/2506.02503v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Minos: A Multimodal Evaluation Model for Bidirectional Generation Between Image and Text", "abstract": "Evaluation is important for multimodal generation tasks. With the rapid\nprogress of MLLMs, there is growing interest in applying MLLMs to build general\nevaluation systems. However, existing work overlooks two aspects: (1) the\ndevelopment of evaluation capabilities for text-to-image (T2I) generation task,\nand (2) the incorporation of large-scale human evaluation data. In this paper,\nwe introduce Minos-Corpus, a large-scale multimodal evaluation dataset that\ncombines evaluation data from both human and GPT. The corpus contains\nevaluation data across both image-to-text(I2T) and T2I generation tasks. Based\non this corpus, we propose Data Selection and Balance, Mix-SFT training\nmethods, and apply DPO to develop Minos, a multimodal evaluation model built\nupon a 7B backbone. Minos achieves state-of-the-art (SoTA) performance among\nall open-source evaluation models of similar scale on the average of evaluation\nperformance on all tasks, and outperforms all open-source and closed-source\nmodels on evaluation of T2I generation task. Extensive experiments demonstrate\nthe importance of leveraging high-quality human evaluation data and jointly\ntraining on evaluation data from both I2T and T2I generation tasks.", "published": "2025-06-03 06:17:16", "link": "http://arxiv.org/abs/2506.02494v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Enhancing Large Language Models with Neurosymbolic Reasoning for Multilingual Tasks", "abstract": "Large language models (LLMs) often struggle to perform multi-target reasoning\nin long-context scenarios where relevant information is scattered across\nextensive documents. To address this challenge, we introduce NeuroSymbolic\nAugmented Reasoning (NSAR), which combines the benefits of neural and symbolic\nreasoning during inference. NSAR explicitly extracts symbolic facts from text\nand generates executable Python code to handle complex reasoning steps. Through\nextensive experiments across seven languages and diverse context lengths, we\ndemonstrate that NSAR significantly outperforms both a vanilla RAG baseline and\nadvanced prompting strategies in accurately identifying and synthesizing\nmultiple pieces of information. Our results highlight the effectiveness of\ncombining explicit symbolic operations with neural inference for robust,\ninterpretable, and scalable reasoning in multilingual settings.", "published": "2025-06-03 05:54:20", "link": "http://arxiv.org/abs/2506.02483v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do Language Models Think Consistently? A Study of Value Preferences Across Varying Response Lengths", "abstract": "Evaluations of LLMs' ethical risks and value inclinations often rely on\nshort-form surveys and psychometric tests, yet real-world use involves\nlong-form, open-ended responses -- leaving value-related risks and preferences\nin practical settings largely underexplored. In this work, we ask: Do value\npreferences inferred from short-form tests align with those expressed in\nlong-form outputs? To address this question, we compare value preferences\nelicited from short-form reactions and long-form responses, varying the number\nof arguments in the latter to capture users' differing verbosity preferences.\nAnalyzing five LLMs (llama3-8b, gemma2-9b, mistral-7b, qwen2-7b, and olmo-7b),\nwe find (1) a weak correlation between value preferences inferred from\nshort-form and long-form responses across varying argument counts, and (2)\nsimilarly weak correlation between preferences derived from any two distinct\nlong-form generation settings. (3) Alignment yields only modest gains in the\nconsistency of value expression. Further, we examine how long-form generation\nattributes relate to value preferences, finding that argument specificity\nnegatively correlates with preference strength, while representation across\nscenarios shows a positive correlation. Our findings underscore the need for\nmore robust methods to ensure consistent value expression across diverse\napplications.", "published": "2025-06-03 05:52:03", "link": "http://arxiv.org/abs/2506.02481v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ORPP: Self-Optimizing Role-playing Prompts to Enhance Language Model Capabilities", "abstract": "High-quality prompts are crucial for eliciting outstanding performance from\nlarge language models (LLMs) on complex tasks. Existing research has explored\nmodel-driven strategies for prompt optimization. However, these methods often\nsuffer from high computational overhead or require strong optimization\ncapabilities from the model itself, which limits their broad applicability.To\naddress these challenges, we propose ORPP (Optimized Role-Playing Prompt),a\nframework that enhances model performance by optimizing and generating\nrole-playing prompts. The core idea of ORPP is to confine the prompt search\nspace to role-playing scenarios, thereby fully activating the model's intrinsic\ncapabilities through carefully crafted, high-quality role-playing prompts.\nSpecifically, ORPP first performs iterative optimization on a small subset of\ntraining samples to generate high-quality role-playing prompts. Then,\nleveraging the model's few-shot learning capability, it transfers the\noptimization experience to efficiently generate suitable prompts for the\nremaining samples.Our experimental results show that ORPP not only matches but\nin most cases surpasses existing mainstream prompt optimization methods in\nterms of performance. Notably, ORPP demonstrates superior \"plug-and-play\"\ncapability. In most cases, it can be integrated with various other prompt\nmethods and further enhance their effectiveness.", "published": "2025-06-03 05:51:35", "link": "http://arxiv.org/abs/2506.02480v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BitBypass: A New Direction in Jailbreaking Aligned Large Language Models with Bitstream Camouflage", "abstract": "The inherent risk of generating harmful and unsafe content by Large Language\nModels (LLMs), has highlighted the need for their safety alignment. Various\ntechniques like supervised fine-tuning, reinforcement learning from human\nfeedback, and red-teaming were developed for ensuring the safety alignment of\nLLMs. However, the robustness of these aligned LLMs is always challenged by\nadversarial attacks that exploit unexplored and underlying vulnerabilities of\nthe safety alignment. In this paper, we develop a novel black-box jailbreak\nattack, called BitBypass, that leverages hyphen-separated bitstream camouflage\nfor jailbreaking aligned LLMs. This represents a new direction in jailbreaking\nby exploiting fundamental information representation of data as continuous\nbits, rather than leveraging prompt engineering or adversarial manipulations.\nOur evaluation of five state-of-the-art LLMs, namely GPT-4o, Gemini 1.5, Claude\n3.5, Llama 3.1, and Mixtral, in adversarial perspective, revealed the\ncapabilities of BitBypass in bypassing their safety alignment and tricking them\ninto generating harmful and unsafe content. Further, we observed that BitBypass\noutperforms several state-of-the-art jailbreak attacks in terms of stealthiness\nand attack success. Overall, these results highlights the effectiveness and\nefficiency of BitBypass in jailbreaking these state-of-the-art LLMs.", "published": "2025-06-03 05:51:18", "link": "http://arxiv.org/abs/2506.02479v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "FroM: Frobenius Norm-Based Data-Free Adaptive Model Merging", "abstract": "With the development of large language models, fine-tuning has emerged as an\neffective method to enhance performance in specific scenarios by injecting\ndomain-specific knowledge. In this context, model merging techniques provide a\nsolution for fusing knowledge from multiple fine-tuning models by combining\ntheir parameters. However, traditional methods often encounter task\ninterference when merging full fine-tuning models, and this problem becomes\neven more evident in parameter-efficient fine-tuning scenarios. In this paper,\nwe introduce an improvement to the RegMean method, which indirectly leverages\nthe training data to approximate the outputs of the linear layers before and\nafter merging. We propose an adaptive merging method called FroM, which\ndirectly measures the model parameters using the Frobenius norm, without any\ntraining data. By introducing an additional hyperparameter for control, FroM\noutperforms baseline methods across various fine-tuning scenarios, alleviating\nthe task interference problem.", "published": "2025-06-03 05:50:09", "link": "http://arxiv.org/abs/2506.02478v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Comba: Improving Nonlinear RNNs with Closed-loop Control", "abstract": "Recent efficient sequence modeling methods such as Gated DeltaNet, TTT, and\nRWKV-7 have achieved performance improvements by supervising the recurrent\nmemory management through Delta learning rule. Unlike previous state-space\nmodels (e.g., Mamba) and gated linear attentions (e.g., GLA), these models\nintroduce interactions between the recurrent state and the key vector,\nresulting in a nonlinear recursive structure. In this paper, we first introduce\nthe concept of Nonlinear RNNs with a comprehensive analysis on the advantages\nand limitations of these models. Then, based on closed-loop control theory, we\npropose a novel Nonlinear RNN variant named Comba, which adopts a\nscalar-plus-low-rank state transition, with both state feedback and output\nfeedback corrections. We also implement a hardware-efficient chunk-wise\nparallel kernel in Triton and train models with 340M/1.3B parameters on\nlarge-scale corpus. Comba demonstrates its superior performance and computation\nefficiency in both language and vision modeling.", "published": "2025-06-03 05:44:50", "link": "http://arxiv.org/abs/2506.02475v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "XToM: Exploring the Multilingual Theory of Mind for Large Language Models", "abstract": "Theory of Mind (ToM), the ability to infer mental states in others, is\npivotal for human social cognition. Existing evaluations of ToM in LLMs are\nlargely limited to English, neglecting the linguistic diversity that shapes\nhuman cognition. This limitation raises a critical question: can LLMs exhibit\nMultilingual Theory of Mind, which is the capacity to reason about mental\nstates across diverse linguistic contexts? To address this gap, we present\nXToM, a rigorously validated multilingual benchmark that evaluates ToM across\nfive languages and incorporates diverse, contextually rich task scenarios.\nUsing XToM, we systematically evaluate LLMs (e.g., DeepSeek R1), revealing a\npronounced dissonance: while models excel in multilingual language\nunderstanding, their ToM performance varies across languages. Our findings\nexpose limitations in LLMs' ability to replicate human-like mentalizing across\nlinguistic contexts.", "published": "2025-06-03 05:23:25", "link": "http://arxiv.org/abs/2506.02461v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MidPO: Dual Preference Optimization for Safety and Helpfulness in Large Language Models via a Mixture of Experts Framework", "abstract": "As large language models (LLMs) are increasingly applied across various\ndomains, enhancing safety while maintaining the helpfulness of LLMs has become\na critical challenge. Recent studies solve this problem through\nsafety-constrained online preference optimization or safety-constrained offline\npreference optimization. However, the safety-constrained online methods often\nsuffer from excessive safety, which might reduce helpfulness, while the\nsafety-constrained offline methods perform poorly in adaptively balancing\nsafety and helpfulness. To address these limitations, we propose MidPO, a\n\\textbf{\\underline{Mi}}xture of Experts (MoE) framework for safety-helpfulness\n\\textbf{\\underline{d}}ual \\textbf{\\underline{P}}reference\n\\textbf{\\underline{O}}ptimization. Firstly, MidPO devises single-preference\nenhanced direct preference optimization approach to transform the base model\ninto two independent experts, termed safety and helpfulness experts, and\nfine-tunes the two independent experts for optimal safety or helpfulness\nperformance. Secondly, to achieve an effective balance between safety and\nhelpfulness, MidPO incorporates the two experts into the MoE framework and\ndesigns a dynamic routing mechanism to allocate contributions from each expert\nadaptively. We conduct quantitative and qualitative experiments on three\npopular datasets to demonstrate the proposed MidPO significantly outperforms\nstate-of-the-art approaches in both safety and helpfulness. The code and models\nwill be released.", "published": "2025-06-03 05:23:09", "link": "http://arxiv.org/abs/2506.02460v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multimodal DeepResearcher: Generating Text-Chart Interleaved Reports From Scratch with Agentic Framework", "abstract": "Visualizations play a crucial part in effective communication of concepts and\ninformation. Recent advances in reasoning and retrieval augmented generation\nhave enabled Large Language Models (LLMs) to perform deep research and generate\ncomprehensive reports. Despite its progress, existing deep research frameworks\nprimarily focus on generating text-only content, leaving the automated\ngeneration of interleaved texts and visualizations underexplored. This novel\ntask poses key challenges in designing informative visualizations and\neffectively integrating them with text reports. To address these challenges, we\npropose Formal Description of Visualization (FDV), a structured textual\nrepresentation of charts that enables LLMs to learn from and generate diverse,\nhigh-quality visualizations. Building on this representation, we introduce\nMultimodal DeepResearcher, an agentic framework that decomposes the task into\nfour stages: (1) researching, (2) exemplar report textualization, (3) planning,\nand (4) multimodal report generation. For the evaluation of generated\nmultimodal reports, we develop MultimodalReportBench, which contains 100\ndiverse topics served as inputs along with 5 dedicated metrics. Extensive\nexperiments across models and evaluation methods demonstrate the effectiveness\nof Multimodal DeepResearcher. Notably, utilizing the same Claude 3.7 Sonnet\nmodel, Multimodal DeepResearcher achieves an 82\\% overall win rate over the\nbaseline method.", "published": "2025-06-03 05:18:19", "link": "http://arxiv.org/abs/2506.02454v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "IP-Dialog: Evaluating Implicit Personalization in Dialogue Systems with Synthetic Data", "abstract": "In modern dialogue systems, the ability to implicitly infer user backgrounds\nfrom conversations and leverage this information for personalized assistance is\ncrucial. However, the scarcity of high-quality data remains a fundamental\nchallenge to evaluating and improving this capability. Traditional dataset\nconstruction methods are labor-intensive, resource-demanding, and raise privacy\nconcerns. To address these issues, we propose a novel approach for automatic\nsynthetic data generation and introduce the Implicit Personalized Dialogue\n(IP-Dialog) benchmark along with a training dataset, covering 10 tasks and 12\nuser attribute types. Additionally, we develop a systematic evaluation\nframework with four metrics to assess both attribute awareness and reasoning\ncapabilities. We further propose five causal graphs to elucidate models'\nreasoning pathways during implicit personalization. Extensive experiments yield\ninsightful observations and prove the reliability of our dataset.", "published": "2025-06-03 05:14:11", "link": "http://arxiv.org/abs/2506.02449v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Should LLM Safety Be More Than Refusing Harmful Instructions?", "abstract": "This paper presents a systematic evaluation of Large Language Models' (LLMs)\nbehavior on long-tail distributed (encrypted) texts and their safety\nimplications. We introduce a two-dimensional framework for assessing LLM\nsafety: (1) instruction refusal-the ability to reject harmful obfuscated\ninstructions, and (2) generation safety-the suppression of generating harmful\nresponses. Through comprehensive experiments, we demonstrate that models that\npossess capabilities to decrypt ciphers may be susceptible to\nmismatched-generalization attacks: their safety mechanisms fail on at least one\nsafety dimension, leading to unsafe responses or over-refusal. Based on these\nfindings, we evaluate a number of pre-LLM and post-LLM safeguards and discuss\ntheir strengths and limitations. This work contributes to understanding the\nsafety of LLM in long-tail text scenarios and provides directions for\ndeveloping robust safety mechanisms.", "published": "2025-06-03 05:00:12", "link": "http://arxiv.org/abs/2506.02442v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Anger to Joy: How Nationality Personas Shape Emotion Attribution in Large Language Models", "abstract": "Emotions are a fundamental facet of human experience, varying across\nindividuals, cultural contexts, and nationalities. Given the recent success of\nLarge Language Models (LLMs) as role-playing agents, we examine whether LLMs\nexhibit emotional stereotypes when assigned nationality-specific personas.\nSpecifically, we investigate how different countries are represented in\npre-trained LLMs through emotion attributions and whether these attributions\nalign with cultural norms. Our analysis reveals significant nationality-based\ndifferences, with emotions such as shame, fear, and joy being\ndisproportionately assigned across regions. Furthermore, we observe notable\nmisalignment between LLM-generated and human emotional responses, particularly\nfor negative emotions, highlighting the presence of reductive and potentially\nbiased stereotypes in LLM outputs.", "published": "2025-06-03 04:35:51", "link": "http://arxiv.org/abs/2506.02431v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Comparative Analysis of AI Agent Architectures for Entity Relationship Classification", "abstract": "Entity relationship classification remains a challenging task in information\nextraction, especially in scenarios with limited labeled data and complex\nrelational structures. In this study, we conduct a comparative analysis of\nthree distinct AI agent architectures designed to perform relation\nclassification using large language models (LLMs). The agentic architectures\nexplored include (1) reflective self-evaluation, (2) hierarchical task\ndecomposition, and (3) a novel multi-agent dynamic example generation\nmechanism, each leveraging different modes of reasoning and prompt adaptation.\nIn particular, our dynamic example generation approach introduces real-time\ncooperative and adversarial prompting. We systematically compare their\nperformance across multiple domains and model backends. Our experiments\ndemonstrate that multi-agent coordination consistently outperforms standard\nfew-shot prompting and approaches the performance of fine-tuned models. These\nfindings offer practical guidance for the design of modular, generalizable\nLLM-based systems for structured relation extraction. The source codes and\ndataset are available at\n\\href{https://github.com/maryambrj/ALIEN.git}{https://github.com/maryambrj/ALIEN.git}.", "published": "2025-06-03 04:19:47", "link": "http://arxiv.org/abs/2506.02426v1", "categories": ["cs.CL", "cs.AI", "I.2.7; I.2.1"], "primary_category": "cs.CL"}
{"title": "Gender Inequality in English Textbooks Around the World: an NLP Approach", "abstract": "Textbooks play a critical role in shaping children's understanding of the\nworld. While previous studies have identified gender inequality in individual\ncountries' textbooks, few have examined the issue cross-culturally. This study\napplies natural language processing methods to quantify gender inequality in\nEnglish textbooks from 22 countries across 7 cultural spheres. Metrics include\ncharacter count, firstness (which gender is mentioned first), and TF-IDF word\nassociations by gender. The analysis also identifies gender patterns in proper\nnames appearing in TF-IDF word lists, tests whether large language models can\ndistinguish between gendered word lists, and uses GloVe embeddings to examine\nhow closely keywords associate with each gender. Results show consistent\noverrepresentation of male characters in terms of count, firstness, and named\nentities. All regions exhibit gender inequality, with the Latin cultural sphere\nshowing the least disparity.", "published": "2025-06-03 04:16:09", "link": "http://arxiv.org/abs/2506.02425v1", "categories": ["cs.CL", "stat.AP"], "primary_category": "cs.CL"}
{"title": "StarVC: A Unified Auto-Regressive Framework for Joint Text and Speech Generation in Voice Conversion", "abstract": "Voice Conversion (VC) modifies speech to match a target speaker while\npreserving linguistic content. Traditional methods usually extract speaker\ninformation directly from speech while neglecting the explicit utilization of\nlinguistic content. Since VC fundamentally involves disentangling speaker\nidentity from linguistic content, leveraging structured semantic features could\nenhance conversion performance. However, previous attempts to incorporate\nsemantic features into VC have shown limited effectiveness, motivating the\nintegration of explicit text modeling. We propose StarVC, a unified\nautoregressive VC framework that first predicts text tokens before synthesizing\nacoustic features. The experiments demonstrate that StarVC outperforms\nconventional VC methods in preserving both linguistic content (i.e., WER and\nCER) and speaker characteristics (i.e., SECS and MOS). Audio demo can be found\nat: https://thuhcsi.github.io/StarVC/.", "published": "2025-06-03 04:00:53", "link": "http://arxiv.org/abs/2506.02414v1", "categories": ["cs.MM", "cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "SingaKids: A Multilingual Multimodal Dialogic Tutor for Language Learning", "abstract": "The integration of generative artificial intelligence into educational\napplications has enhanced personalized and interactive learning experiences,\nand it shows strong potential to promote young learners language acquisition.\nHowever, it is still challenging to ensure consistent and robust performance\nacross different languages and cultural contexts, and kids-friendly design\nrequires simplified instructions, engaging interactions, and age-appropriate\nscaffolding to maintain motivation and optimize learning outcomes. In this\nwork, we introduce SingaKids, a dialogic tutor designed to facilitate language\nlearning through picture description tasks. Our system integrates dense image\ncaptioning, multilingual dialogic interaction, speech understanding, and\nengaging speech generation to create an immersive learning environment in four\nlanguages: English, Mandarin, Malay, and Tamil. We further improve the system\nthrough multilingual pre-training, task-specific tuning, and scaffolding\noptimization. Empirical studies with elementary school students demonstrate\nthat SingaKids provides effective dialogic teaching, benefiting learners at\ndifferent performance levels.", "published": "2025-06-03 03:56:45", "link": "http://arxiv.org/abs/2506.02412v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GraphRAG-Bench: Challenging Domain-Specific Reasoning for Evaluating Graph Retrieval-Augmented Generation", "abstract": "Graph Retrieval Augmented Generation (GraphRAG) has garnered increasing\nrecognition for its potential to enhance large language models (LLMs) by\nstructurally organizing domain-specific corpora and facilitating complex\nreasoning. However, current evaluations of GraphRAG models predominantly rely\non traditional question-answering datasets. Their limited scope in questions\nand evaluation metrics fails to comprehensively assess the reasoning capacity\nimprovements enabled by GraphRAG models. To address this gap, we introduce\nGraphRAG-Bench, a large-scale, domain-specific benchmark designed to rigorously\nevaluate GraphRAG models. Our benchmark offers three key superiorities: \\((i)\\)\nChallenging question design. Featuring college-level, domain-specific questions\nthat demand multi-hop reasoning, the benchmark ensures that simple content\nretrieval is insufficient for problem-solving. For example, some questions\nrequire mathematical reasoning or programming. \\((ii)\\) Diverse task coverage.\nThe dataset includes a broad spectrum of reasoning tasks, multiple-choice,\ntrue/false, multi-select, open-ended, and fill-in-the-blank. It spans 16\ndisciplines in twenty core textbooks. \\((iii)\\) Holistic evaluation framework.\nGraphRAG-Bench provides comprehensive assessment across the entire GraphRAG\npipeline, including graph construction, knowledge retrieval, and answer\ngeneration. Beyond final-answer correctness, it evaluates the logical coherence\nof the reasoning process. By applying nine contemporary GraphRAG methods to\nGraphRAG-Bench, we demonstrate its utility in quantifying how graph-based\nstructuring improves model reasoning capabilities. Our analysis reveals\ncritical insights about graph architectures, retrieval efficacy, and reasoning\ncapabilities, offering actionable guidance for the research community.", "published": "2025-06-03 03:44:26", "link": "http://arxiv.org/abs/2506.02404v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Consultant Decoding: Yet Another Synergistic Mechanism", "abstract": "The synergistic mechanism based on Speculative Decoding (SD) has garnered\nconsiderable attention as a simple yet effective approach for accelerating the\ninference of large language models (LLMs). Nonetheless, the high rejection\nrates require repeated LLMs calls to validate draft tokens, undermining the\noverall efficiency gain of SD. In this work, we revisit existing verification\nmechanisms and propose a novel synergetic mechanism Consultant Decoding (CD).\nUnlike SD, which relies on a metric derived from importance sampling for\nverification, CD verifies candidate drafts using token-level likelihoods\ncomputed solely by the LLM. CD achieves up to a 2.5-fold increase in inference\nspeed compared to the target model, while maintaining comparable generation\nquality (around 100% of the target model's performance). Interestingly, this is\nachieved by combining models whose parameter sizes differ by two orders of\nmagnitude. In addition, CD reduces the call frequency of the large target model\nto below 10%, particularly in more demanding tasks. CD's performance was even\nfound to surpass that of the large target model, which theoretically represents\nthe upper bound for speculative decoding.", "published": "2025-06-03 03:13:27", "link": "http://arxiv.org/abs/2506.02391v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring Explanations Improves the Robustness of In-Context Learning", "abstract": "In-context learning (ICL) has emerged as a successful paradigm for leveraging\nlarge language models (LLMs). However, it often struggles to generalize beyond\nthe distribution of the provided demonstrations. A recent advancement in\nenhancing robustness is ICL with explanations (X-ICL), which improves\nprediction reliability by guiding LLMs to understand and articulate the\nreasoning behind correct labels. Building on this approach, we introduce an\nadvanced framework that extends X-ICL by systematically exploring explanations\nfor all possible labels (X$^2$-ICL), thereby enabling more comprehensive and\nrobust decision-making. Experimental results on multiple natural language\nunderstanding datasets validate the effectiveness of X$^2$-ICL, demonstrating\nsignificantly improved robustness to out-of-distribution data compared to the\nexisting ICL approaches.", "published": "2025-06-03 02:29:14", "link": "http://arxiv.org/abs/2506.02378v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AnswerCarefully: A Dataset for Improving the Safety of Japanese LLM Output", "abstract": "In this paper we present AnswerCarefully, a dataset for promoting the safety\nand appropriateness of Japanese LLM outputs. The dataset consists of 1,800\npairs of questions and reference answers, where the questions require special\nattention in answering. It covers a wide range of risk categories established\nin prior English-language datasets, but the data samples are original in that\nthey are manually created to reflect the socio-cultural context of LLM usage in\nJapan. We show that using this dataset for instruction to fine-tune a Japanese\nLLM led to improved output safety without compromising the utility of general\nresponses. We also report the results of a safety evaluation of 12 Japanese\nLLMs using this dataset as a benchmark. Finally, we describe the latest update\non the dataset which provides English translations and annotations of the\nquestions, aimed at facilitating the derivation of similar datasets in\ndifferent languages and regions.", "published": "2025-06-03 02:18:59", "link": "http://arxiv.org/abs/2506.02372v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DIAMOND: An LLM-Driven Agent for Context-Aware Baseball Highlight Summarization", "abstract": "Traditional approaches -- such as Win Probability Added (WPA)-based ranking\nor computer vision-driven event detection -- can identify scoring plays but\noften miss strategic depth, momentum shifts, and storyline progression. Manual\ncuration remains the gold standard but is resource-intensive and not scalable.\nWe introduce DIAMOND, an LLM-driven agent for context-aware baseball highlight\nsummarization that integrates structured sports analytics with natural language\nreasoning. DIAMOND leverages sabermetric features -- Win Expectancy, WPA, and\nLeverage Index -- to quantify play importance, while an LLM module enhances\nselection based on contextual narrative value. This hybrid approach ensures\nboth quantitative rigor and qualitative richness, surpassing the limitations of\npurely statistical or vision-based systems. Evaluated on five diverse Korean\nBaseball Organization League games, DIAMOND improves F1-score from 42.9%\n(WPA-only) to 84.8%, outperforming both commercial and statistical baselines.\nThough limited in scale, our results highlight the potential of modular,\ninterpretable agent-based frameworks for event-level summarization in sports\nand beyond.", "published": "2025-06-03 01:10:20", "link": "http://arxiv.org/abs/2506.02351v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Truth over Tricks: Measuring and Mitigating Shortcut Learning in Misinformation Detection", "abstract": "Misinformation detection models often rely on superficial cues (i.e.,\n\\emph{shortcuts}) that correlate with misinformation in training data but fail\nto generalize to the diverse and evolving nature of real-world misinformation.\nThis issue is exacerbated by large language models (LLMs), which can easily\ngenerate convincing misinformation through simple prompts. We introduce\nTruthOverTricks, a unified evaluation paradigm for measuring shortcut learning\nin misinformation detection. TruthOverTricks categorizes shortcut behaviors\ninto intrinsic shortcut induction and extrinsic shortcut injection, and\nevaluates seven representative detectors across 14 popular benchmarks, along\nwith two new factual misinformation datasets, NQ-Misinfo and Streaming-Misinfo.\nEmpirical results reveal that existing detectors suffer severe performance\ndegradation when exposed to both naturally occurring and adversarially crafted\nshortcuts. To address this, we propose SMF, an LLM-augmented data augmentation\nframework that mitigates shortcut reliance through paraphrasing, factual\nsummarization, and sentiment normalization. SMF consistently enhances\nrobustness across 16 benchmarks, encouraging models to rely on deeper semantic\nunderstanding rather than shortcut cues. To promote the development of\nmisinformation detectors, we have published the resources publicly at\nhttps://github.com/whr000001/TruthOverTricks.", "published": "2025-06-03 01:09:55", "link": "http://arxiv.org/abs/2506.02350v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "STORYTELLER: An Enhanced Plot-Planning Framework for Coherent and Cohesive Story Generation", "abstract": "Stories are central to human culture, serving to share ideas, preserve\ntraditions, and foster connections. Automatic story generation, a key\nadvancement in artificial intelligence (AI), offers new possibilities for\ncreating personalized content, exploring creative ideas, and enhancing\ninteractive experiences. However, existing methods struggle to maintain\nnarrative coherence and logical consistency. This disconnect compromises the\noverall storytelling experience, underscoring the need for substantial\nimprovements. Inspired by human cognitive processes, we introduce Storyteller,\na novel approach that systemically improves the coherence and consistency of\nautomatically generated stories. Storyteller introduces a plot node structure\nbased on linguistically grounded subject verb object (SVO) triplets, which\ncapture essential story events and ensure a consistent logical flow. Unlike\nprevious methods, Storyteller integrates two dynamic modules, the STORYLINE and\nnarrative entity knowledge graph (NEKG),that continuously interact with the\nstory generation process. This integration produces structurally sound,\ncohesive and immersive narratives. Extensive experiments demonstrate that\nStoryteller significantly outperforms existing approaches, achieving an 84.33%\naverage win rate through human preference evaluation. At the same time, it is\nalso far ahead in other aspects including creativity, coherence, engagement,\nand relevance.", "published": "2025-06-03 00:54:00", "link": "http://arxiv.org/abs/2506.02347v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "One Missing Piece for Open-Source Reasoning Models: A Dataset to Mitigate Cold-Starting Short CoT LLMs in RL", "abstract": "With the release of R1, a publicly available large reasoning model (LRM),\nresearchers commonly train new LRMs by training language models on R1's long\nchain-of-thought (CoT) inferences. While prior works show that LRMs'\ncapabilities can be reproduced through direct distillation, the continued\nreliance on the existing models (e.g., R1) remains a critical limitation in\nadvancing the field. As a first step toward independent LRM development, this\npaper explores the possibility of constructing a long CoT dataset with LLMs\nthat are not trained for inference-time scaling. To this end, we present the\nLong CoT Collection, a dataset of 100K CoT rationales annotated using existing\nshort CoT LLMs. We develop a pipeline that induces o1's novel reasoning\nstrategies into short CoT LLMs, enabling them to think longer and introducing\ncontrollability over the thought budget to better manage the overthinking\nproblem. Our extensive analyses validate that our dataset achieves quality\ncomparable to--or slightly below--R1. Furthermore, our experiments demonstrate\nthat training on our dataset not only strengthens general reasoning skills, but\nalso provides a strong foundation for reinforcement learning--models\ninitialized on our data achieve 2-3x larger gains with RLVR.", "published": "2025-06-03 00:29:15", "link": "http://arxiv.org/abs/2506.02338v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IllumiCraft: Unified Geometry and Illumination Diffusion for Controllable Video Generation", "abstract": "Although diffusion-based models can generate high-quality and high-resolution\nvideo sequences from textual or image inputs, they lack explicit integration of\ngeometric cues when controlling scene lighting and visual appearance across\nframes. To address this limitation, we propose IllumiCraft, an end-to-end\ndiffusion framework accepting three complementary inputs: (1)\nhigh-dynamic-range (HDR) video maps for detailed lighting control; (2)\nsynthetically relit frames with randomized illumination changes (optionally\npaired with a static background reference image) to provide appearance cues;\nand (3) 3D point tracks that capture precise 3D geometry information. By\nintegrating the lighting, appearance, and geometry cues within a unified\ndiffusion architecture, IllumiCraft generates temporally coherent videos\naligned with user-defined prompts. It supports background-conditioned and\ntext-conditioned video relighting and provides better fidelity than existing\ncontrollable video generation methods. Project Page:\nhttps://yuanze-lin.me/IllumiCraft_page", "published": "2025-06-03 17:59:52", "link": "http://arxiv.org/abs/2506.03150v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM"], "primary_category": "cs.CV"}
{"title": "SVGenius: Benchmarking LLMs in SVG Understanding, Editing and Generation", "abstract": "Large Language Models (LLMs) and Multimodal LLMs have shown promising\ncapabilities for SVG processing, yet existing benchmarks suffer from limited\nreal-world coverage, lack of complexity stratification, and fragmented\nevaluation paradigms. We introduce SVGenius, a comprehensive benchmark\ncomprising 2,377 queries across three progressive dimensions: understanding,\nediting, and generation. Built on real-world data from 24 application domains\nwith systematic complexity stratification, SVGenius evaluates models through 8\ntask categories and 18 metrics. We assess 22 mainstream models spanning\ndifferent scales, architectures, training paradigms, and accessibility levels.\nOur analysis reveals that while proprietary models significantly outperform\nopen-source counterparts, all models exhibit systematic performance degradation\nwith increasing complexity, indicating fundamental limitations in current\napproaches; however, reasoning-enhanced training proves more effective than\npure scaling for overcoming these limitations, though style transfer remains\nthe most challenging capability across all model types. SVGenius establishes\nthe first systematic evaluation framework for SVG processing, providing crucial\ninsights for developing more capable vector graphics models and advancing\nautomated graphic design applications. Appendix and supplementary materials\n(including all data and code) are available at\nhttps://zju-real.github.io/SVGenius.", "published": "2025-06-03 17:58:57", "link": "http://arxiv.org/abs/2506.03139v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "PoLAR: Polar-Decomposed Low-Rank Adapter Representation", "abstract": "We show that low-rank adaptation of large-scale models suffers from a low\nstable rank that is well below the linear algebraic rank of the subspace,\ndegrading fine-tuning performance. To mitigate the underutilization of the\nallocated subspace, we propose PoLAR, a parameterization inspired by the polar\ndecomposition that factorizes the low-rank update into two direction matrices\nconstrained to Stiefel manifolds and an unconstrained scale matrix. Our theory\nshows that PoLAR yields an exponentially faster convergence rate on a canonical\nlow-rank adaptation problem. Pairing the parameterization with Riemannian\noptimization leads to consistent gains on three different benchmarks testing\ngeneral language understanding, commonsense reasoning, and mathematical problem\nsolving with base model sizes ranging from 350M to 27B.", "published": "2025-06-03 17:58:19", "link": "http://arxiv.org/abs/2506.03133v1", "categories": ["cs.LG", "cs.AI", "eess.SP", "math.OC"], "primary_category": "cs.LG"}
{"title": "Designing Algorithmic Delegates: The Role of Indistinguishability in Human-AI Handoff", "abstract": "As AI technologies improve, people are increasingly willing to delegate tasks\nto AI agents. In many cases, the human decision-maker chooses whether to\ndelegate to an AI agent based on properties of the specific instance of the\ndecision-making problem they are facing. Since humans typically lack full\nawareness of all the factors relevant to this choice for a given\ndecision-making instance, they perform a kind of categorization by treating\nindistinguishable instances -- those that have the same observable features --\nas the same. In this paper, we define the problem of designing the optimal\nalgorithmic delegate in the presence of categories. This is an important\ndimension in the design of algorithms to work with humans, since we show that\nthe optimal delegate can be an arbitrarily better teammate than the optimal\nstandalone algorithmic agent. The solution to this optimal delegation problem\nis not obvious: we discover that this problem is fundamentally combinatorial,\nand illustrate the complex relationship between the optimal design and the\nproperties of the decision-making task even in simple settings. Indeed, we show\nthat finding the optimal delegate is computationally hard in general. However,\nwe are able to find efficient algorithms for producing the optimal delegate in\nseveral broad cases of the problem, including when the optimal action may be\ndecomposed into functions of features observed by the human and the algorithm.\nFinally, we run computational experiments to simulate a designer updating an\nalgorithmic delegate over time to be optimized for when it is actually adopted\nby users, and show that while this process does not recover the optimal\ndelegate in general, the resulting delegate often performs quite well.", "published": "2025-06-03 17:36:20", "link": "http://arxiv.org/abs/2506.03102v1", "categories": ["cs.GT", "cs.AI", "cs.CY"], "primary_category": "cs.GT"}
{"title": "TalkingMachines: Real-Time Audio-Driven FaceTime-Style Video via Autoregressive Diffusion Models", "abstract": "In this paper, we present TalkingMachines -- an efficient framework that\ntransforms pretrained video generation models into real-time, audio-driven\ncharacter animators. TalkingMachines enables natural conversational experiences\nby integrating an audio large language model (LLM) with our video generation\nfoundation model. Our primary contributions include: (1) We adapt a pretrained\nSOTA image-to-video DiT into an audio-driven avatar generation model of 18\nbillion parameters; (2) We enable infinite video streaming without error\naccumulation through asymmetric knowledge distillation from a bidirectional\nteacher model into a sparse causal, autoregressive student model; (3) We design\na high-throughput, low-latency inference pipeline incorporating several key\nengineering optimizations such as: (a) disaggregation of the DiT and VAE\ndecoder across separate devices, (b) efficient overlap of inter-device\ncommunication and computation using CUDA streams, (c) elimination of redundant\nrecomputations to maximize frame-generation throughput. Please see demo videos\nhere - https://aaxwaz.github.io/TalkingMachines/", "published": "2025-06-03 17:29:28", "link": "http://arxiv.org/abs/2506.03099v1", "categories": ["cs.SD", "cs.AI", "cs.GR"], "primary_category": "cs.SD"}
{"title": "EgoVLM: Policy Optimization for Egocentric Video Understanding", "abstract": "Emerging embodied AI applications, such as wearable cameras and autonomous\nagents, have underscored the need for robust reasoning from first person video\nstreams. We introduce EgoVLM, a vision-language model specifically designed to\nintegrate visual comprehension and spatial-temporal reasoning within egocentric\nvideo contexts. EgoVLM is fine-tuned via Group Relative Policy Optimization\n(GRPO), a reinforcement learning method adapted to align model outputs with\nhuman-like reasoning steps. Following DeepSeek R1-Zero's approach, we directly\ntune using RL without any supervised fine-tuning phase on chain-of-thought\n(CoT) data. We evaluate EgoVLM on egocentric video question answering\nbenchmarks and show that domain-specific training substantially improves\nperformance over general-purpose VLMs. Our EgoVLM-3B, trained exclusively on\nnon-CoT egocentric data, outperforms the base Qwen2.5-VL 3B and 7B models by\n14.33 and 13.87 accuracy points on the EgoSchema benchmark, respectively. By\nexplicitly generating reasoning traces, EgoVLM enhances interpretability,\nmaking it well-suited for downstream applications. Furthermore, we introduce a\nnovel keyframe-based reward that incorporates salient frame selection to guide\nreinforcement learning optimization. This reward formulation opens a promising\navenue for future exploration in temporally grounded egocentric reasoning.", "published": "2025-06-03 17:28:00", "link": "http://arxiv.org/abs/2506.03097v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "DPO Learning with LLMs-Judge Signal for Computer Use Agents", "abstract": "Computer use agents (CUA) are systems that automatically interact with\ngraphical user interfaces (GUIs) to complete tasks. CUA have made significant\nprogress with the advent of large vision-language models (VLMs). However, these\nagents typically rely on cloud-based inference with substantial compute\ndemands, raising critical privacy and scalability concerns, especially when\noperating on personal devices. In this work, we take a step toward\nprivacy-preserving and resource-efficient agents by developing a lightweight\nvision-language model that runs entirely on local machines. To train this\ncompact agent, we introduce an LLM-as-Judge framework that automatically\nevaluates and filters synthetic interaction trajectories, producing\nhigh-quality data for reinforcement learning without human annotation.\nExperiments on the OS-World benchmark demonstrate that our fine-tuned local\nmodel outperforms existing baselines, highlighting a promising path toward\nprivate, efficient, and generalizable GUI agents.", "published": "2025-06-03 17:27:04", "link": "http://arxiv.org/abs/2506.03095v1", "categories": ["cs.AI", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Modelling the Effects of Hearing Loss on Neural Coding in the Auditory Midbrain with Variational Conditioning", "abstract": "The mapping from sound to neural activity that underlies hearing is highly\nnon-linear. The first few stages of this mapping in the cochlea have been\nmodelled successfully, with biophysical models built by hand and, more\nrecently, with DNN models trained on datasets simulated by biophysical models.\nModelling the auditory brain has been a challenge because central auditory\nprocessing is too complex for models to be built by hand, and datasets for\ntraining DNN models directly have not been available. Recent work has taken\nadvantage of large-scale high resolution neural recordings from the auditory\nmidbrain to build a DNN model of normal hearing with great success. But this\nmodel assumes that auditory processing is the same in all brains, and therefore\nit cannot capture the widely varying effects of hearing loss.\n  We propose a novel variational-conditional model to learn to encode the space\nof hearing loss directly from recordings of neural activity in the auditory\nmidbrain of healthy and noise exposed animals. With hearing loss parametrised\nby only 6 free parameters per animal, our model accurately predicts 62\\% of the\nexplainable variance in neural responses from normal hearing animals and 68%\nfor hearing impaired animals, within a few percentage points of state of the\nart animal specific models. We demonstrate that the model can be used to\nsimulate realistic activity from out of sample animals by fitting only the\nlearned conditioning parameters with Bayesian optimisation, achieving\ncrossentropy loss within 2% of the optimum in 15-30 iterations. Including more\nanimals in the training data slightly improved the performance on unseen\nanimals. This model will enable future development of parametrised hearing loss\ncompensation models trained to directly restore normal neural coding in hearing\nimpaired brains, which can be quickly fitted for a new user by human in the\nloop optimisation.", "published": "2025-06-03 17:12:21", "link": "http://arxiv.org/abs/2506.03088v1", "categories": ["q-bio.NC", "cs.AI", "cs.LG"], "primary_category": "q-bio.NC"}
{"title": "How Explanations Leak the Decision Logic: Stealing Graph Neural Networks via Explanation Alignment", "abstract": "Graph Neural Networks (GNNs) have become essential tools for analyzing\ngraph-structured data in domains such as drug discovery and financial analysis,\nleading to growing demands for model transparency. Recent advances in\nexplainable GNNs have addressed this need by revealing important subgraphs that\ninfluence predictions, but these explanation mechanisms may inadvertently\nexpose models to security risks. This paper investigates how such explanations\npotentially leak critical decision logic that can be exploited for model\nstealing. We propose {\\method}, a novel stealing framework that integrates\nexplanation alignment for capturing decision logic with guided data\naugmentation for efficient training under limited queries, enabling effective\nreplication of both the predictive behavior and underlying reasoning patterns\nof target models. Experiments on molecular graph datasets demonstrate that our\napproach shows advantages over conventional methods in model stealing. This\nwork highlights important security considerations for the deployment of\nexplainable GNNs in sensitive domains and suggests the need for protective\nmeasures against explanation-based attacks. Our code is available at\nhttps://github.com/beanmah/EGSteal.", "published": "2025-06-03 17:11:05", "link": "http://arxiv.org/abs/2506.03087v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Labelling Data with Unknown References", "abstract": "An evaluator is trustworthy when there exists some agreed-upon way to measure\nits performance as a labeller. The two ways to establish trustworthiness are\neither by testing it, or by assuming the evaluator `knows' somehow the way to\nlabel the corpus. However, if labelled references (e.g., a development set) are\nunavailable, neither of these approaches work: the former requires the data,\nand the latter is an assumption, not evidence. To address this, we introduce an\nalgorithm (the `No-Data Algorithm') by which to establish trust in an evaluator\nwithout any existing references. Our algorithm works by successively posing\nchallenges to said evaluator. We show that this is sufficient to establish\ntrustworthiness w.h.p., in such a way that when the evaluator actually knows\nthe way to label the corpus, the No-Data Algorithm accepts its output; and,\nconversely, flags untrustworthy evaluators when these are unable to prove it.\nWe present formal proofs of correctness and limited experiments.", "published": "2025-06-03 17:04:22", "link": "http://arxiv.org/abs/2506.03083v1", "categories": ["cs.DS", "cs.AI"], "primary_category": "cs.DS"}
{"title": "StreamBP: Memory-Efficient Exact Backpropagation for Long Sequence Training of LLMs", "abstract": "Training language models on long sequence data is a demanding requirement for\nenhancing the model's capability on complex tasks, e.g., long-chain reasoning.\nHowever, as the sequence length scales up, the memory cost for storing\nactivation values becomes huge during the Backpropagation (BP) process, even\nwith the application of gradient checkpointing technique. To tackle this\nchallenge, we propose a memory-efficient and exact BP method called StreamBP,\nwhich performs a linear decomposition of the chain rule along the sequence\ndimension in a layer-wise manner, significantly reducing the memory cost of\nactivation values and logits. The proposed method is applicable to common\nobjectives such as SFT, GRPO, and DPO. From an implementation perspective,\nStreamBP achieves less computational FLOPs and faster BP speed by leveraging\nthe causal structure of the language model. Compared to gradient checkpointing,\nStreamBP scales up the maximum sequence length of BP by 2.8-5.5 times larger,\nwhile using comparable or even less BP time. Note that StreamBP's sequence\nlength scaling ability can be directly transferred to batch size scaling for\naccelerating training. We further develop a communication-efficient distributed\nStreamBP to effectively support multi-GPU training and broaden its\napplicability. Our code can be easily integrated into the training pipeline of\nany transformer models and is available at https://github.com/Ledzy/StreamBP.", "published": "2025-06-03 16:54:15", "link": "http://arxiv.org/abs/2506.03077v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Sparse-vDiT: Unleashing the Power of Sparse Attention to Accelerate Video Diffusion Transformers", "abstract": "While Diffusion Transformers (DiTs) have achieved breakthroughs in video\ngeneration, this long sequence generation task remains constrained by the\nquadratic complexity of attention mechanisms, resulting in significant\ninference latency. Through detailed analysis of attention maps in Video\nDiffusion Transformer (vDiT), we identify three recurring sparsity patterns:\ndiagonal, multi-diagonal, and vertical-stripe structures. And even 3-6\\%\nattention heads can be skipped. Crucially, these patterns exhibit strong\nlayer-depth and head-position correlations but show limited dependence on the\ninput content. Leveraging these findings, we propose Sparse-vDiT, a sparsity\nacceleration framework for vDiT comprising: 1) Pattern-optimized sparse kernels\nthat replace dense attention with computationally efficient implementations for\neach identified sparsity pattern. 2) An offline sparse diffusion search\nalgorithm that selects the optimal sparse computation strategy per layer and\nhead via hardware-aware cost modeling. After determining the optimal\nconfiguration, we fuse heads within the same layer that share the same\nattention strategy, enhancing inference efficiency. Integrated into\nstate-of-the-art vDiT models (CogVideoX1.5, HunyuanVideo, and Wan2.1),\nSparse-vDiT achieves 2.09$\\times$, 2.38$\\times$, and 1.67$\\times$ theoretical\nFLOP reduction, and actual inference speedups of 1.76$\\times$, 1.85$\\times$,\nand 1.58$\\times$, respectively, while maintaining high visual fidelity, with\nPSNR values reaching 24.13, 27.09, and 22.59. Our work demonstrates that latent\nstructural sparsity in vDiTs can be systematically exploited for long video\nsynthesis.", "published": "2025-06-03 16:42:37", "link": "http://arxiv.org/abs/2506.03065v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Corrigibility as a Singular Target: A Vision for Inherently Reliable Foundation Models", "abstract": "Foundation models (FMs) face a critical safety challenge: as capabilities\nscale, instrumental convergence drives default trajectories toward loss of\nhuman control, potentially culminating in existential catastrophe. Current\nalignment approaches struggle with value specification complexity and fail to\naddress emergent power-seeking behaviors. We propose \"Corrigibility as a\nSingular Target\" (CAST)-designing FMs whose overriding objective is empowering\ndesignated human principals to guide, correct, and control them. This paradigm\nshift from static value-loading to dynamic human empowerment transforms\ninstrumental drives: self-preservation serves only to maintain the principal's\ncontrol; goal modification becomes facilitating principal guidance. We present\na comprehensive empirical research agenda spanning training methodologies\n(RLAIF, SFT, synthetic data generation), scalability testing across model\nsizes, and demonstrations of controlled instructability. Our vision: FMs that\nbecome increasingly responsive to human guidance as capabilities grow, offering\na path to beneficial AI that remains as tool-like as possible, rather than\nsupplanting human judgment. This addresses the core alignment problem at its\nsource, preventing the default trajectory toward misaligned instrumental\nconvergence.", "published": "2025-06-03 16:36:03", "link": "http://arxiv.org/abs/2506.03056v1", "categories": ["cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.AI"}
{"title": "EDEN: Entorhinal Driven Egocentric Navigation Toward Robotic Deployment", "abstract": "Deep reinforcement learning agents are often fragile while humans remain\nadaptive and flexible to varying scenarios. To bridge this gap, we present\nEDEN, a biologically inspired navigation framework that integrates learned\nentorhinal-like grid cell representations and reinforcement learning to enable\nautonomous navigation. Inspired by the mammalian entorhinal-hippocampal system,\nEDEN allows agents to perform path integration and vector-based navigation\nusing visual and motion sensor data. At the core of EDEN is a grid cell encoder\nthat transforms egocentric motion into periodic spatial codes, producing\nlow-dimensional, interpretable embeddings of position. To generate these\nactivations from raw sensory input, we combine fiducial marker detections in\nthe lightweight MiniWorld simulator and DINO-based visual features in the\nhigh-fidelity Gazebo simulator. These spatial representations serve as input to\na policy trained with Proximal Policy Optimization (PPO), enabling dynamic,\ngoal-directed navigation. We evaluate EDEN in both MiniWorld, for rapid\nprototyping, and Gazebo, which offers realistic physics and perception noise.\nCompared to baseline agents using raw state inputs (e.g., position, velocity)\nor standard convolutional image encoders, EDEN achieves a 99% success rate,\nwithin the simple scenarios, and >94% within complex floorplans with occluded\npaths with more efficient and reliable step-wise navigation. In addition, as a\nreplacement of ground truth activations, we present a trainable Grid Cell\nencoder enabling the development of periodic grid-like patterns from vision and\nmotion sensor data, emulating the development of such patterns within\nbiological mammals. This work represents a step toward biologically grounded\nspatial intelligence in robotics, bridging neural navigation principles with\nreinforcement learning for scalable deployment.", "published": "2025-06-03 16:28:33", "link": "http://arxiv.org/abs/2506.03046v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "TestAgent: An Adaptive and Intelligent Expert for Human Assessment", "abstract": "Accurately assessing internal human states is key to understanding\npreferences, offering personalized services, and identifying challenges in\nreal-world applications. Originating from psychometrics, adaptive testing has\nbecome the mainstream method for human measurement and has now been widely\napplied in education, healthcare, sports, and sociology. It customizes\nassessments by selecting the fewest test questions . However, current adaptive\ntesting methods face several challenges. The mechanized nature of most\nalgorithms leads to guessing behavior and difficulties with open-ended\nquestions. Additionally, subjective assessments suffer from noisy response data\nand coarse-grained test outputs, further limiting their effectiveness. To move\ncloser to an ideal adaptive testing process, we propose TestAgent, a large\nlanguage model (LLM)-powered agent designed to enhance adaptive testing through\ninteractive engagement. This is the first application of LLMs in adaptive\ntesting. TestAgent supports personalized question selection, captures\ntest-takers' responses and anomalies, and provides precise outcomes through\ndynamic, conversational interactions. Experiments on psychological,\neducational, and lifestyle assessments show our approach achieves more accurate\nresults with 20% fewer questions than state-of-the-art baselines, and testers\npreferred it in speed, smoothness, and other dimensions.", "published": "2025-06-03 16:07:54", "link": "http://arxiv.org/abs/2506.03032v1", "categories": ["cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Smartflow: Enabling Scalable Spatiotemporal Geospatial Research", "abstract": "BlackSky introduces Smartflow, a cloud-based framework enabling scalable\nspatiotemporal geospatial research built on open-source tools and technologies.\nUsing STAC-compliant catalogs as a common input, heterogeneous geospatial data\ncan be processed into standardized datacubes for analysis and model training.\nModel experimentation is managed using a combination of tools, including\nClearML, Tensorboard, and Apache Superset. Underpinning Smartflow is\nKubernetes, which orchestrates the provisioning and execution of workflows to\nsupport both horizontal and vertical scalability. This combination of features\nmakes Smartflow well-suited for geospatial model development and analysis over\nlarge geographic areas, time scales, and expansive image archives.\n  We also present a novel neural architecture, built using Smartflow, to\nmonitor large geographic areas for heavy construction. Qualitative results\nbased on data from the IARPA Space-based Machine Automated Recognition\nTechnique (SMART) program are presented that show the model is capable of\ndetecting heavy construction throughout all major phases of development.", "published": "2025-06-03 15:58:52", "link": "http://arxiv.org/abs/2506.03022v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Linear Spatial World Models Emerge in Large Language Models", "abstract": "Large language models (LLMs) have demonstrated emergent abilities across\ndiverse tasks, raising the question of whether they acquire internal world\nmodels. In this work, we investigate whether LLMs implicitly encode linear\nspatial world models, which we define as linear representations of physical\nspace and object configurations. We introduce a formal framework for spatial\nworld models and assess whether such structure emerges in contextual\nembeddings. Using a synthetic dataset of object positions, we train probes to\ndecode object positions and evaluate geometric consistency of the underlying\nspace. We further conduct causal interventions to test whether these spatial\nrepresentations are functionally used by the model. Our results provide\nempirical evidence that LLMs encode linear spatial world models.", "published": "2025-06-03 15:31:00", "link": "http://arxiv.org/abs/2506.02996v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Deep Learning for Retinal Degeneration Assessment: A Comprehensive Analysis of the MARIO AMD Progression Challenge", "abstract": "The MARIO challenge, held at MICCAI 2024, focused on advancing the automated\ndetection and monitoring of age-related macular degeneration (AMD) through the\nanalysis of optical coherence tomography (OCT) images. Designed to evaluate\nalgorithmic performance in detecting neovascular activity changes within AMD,\nthe challenge incorporated unique multi-modal datasets. The primary dataset,\nsourced from Brest, France, was used by participating teams to train and test\ntheir models. The final ranking was determined based on performance on this\ndataset. An auxiliary dataset from Algeria was used post-challenge to evaluate\npopulation and device shifts from submitted solutions. Two tasks were involved\nin the MARIO challenge. The first one was the classification of evolution\nbetween two consecutive 2D OCT B-scans. The second one was the prediction of\nfuture AMD evolution over three months for patients undergoing anti-vascular\nendothelial growth factor (VEGF) therapy. Thirty-five teams participated, with\nthe top 12 finalists presenting their methods. This paper outlines the\nchallenge's structure, tasks, data characteristics, and winning methodologies,\nsetting a benchmark for AMD monitoring using OCT, infrared imaging, and\nclinical data (such as the number of visits, age, gender, etc.). The results of\nthis challenge indicate that artificial intelligence (AI) performs as well as a\nphysician in measuring AMD progression (Task 1) but is not yet able of\npredicting future evolution (Task 2).", "published": "2025-06-03 15:14:10", "link": "http://arxiv.org/abs/2506.02976v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "HaploOmni: Unified Single Transformer for Multimodal Video Understanding and Generation", "abstract": "With the advancement of language models, unified multimodal understanding and\ngeneration have made significant strides, with model architectures evolving\nfrom separated components to unified single-model frameworks. This paper\nexplores an efficient training paradigm to build a single transformer for\nunified multimodal understanding and generation. Specifically, we propose a\nmultimodal warmup strategy utilizing prior knowledge to extend capabilities. To\naddress cross-modal compatibility challenges, we introduce feature pre-scaling\nand multimodal AdaLN techniques. Integrating the proposed technologies, we\npresent the HaploOmni, a new single multimodal transformer. With limited\ntraining costs, HaploOmni achieves competitive performance across multiple\nimage and video understanding and generation benchmarks over advanced unified\nmodels. All codes will be made public at https://github.com/Tencent/HaploVLM.", "published": "2025-06-03 15:14:00", "link": "http://arxiv.org/abs/2506.02975v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "UniConFlow: A Unified Constrained Generalization Framework for Certified Motion Planning with Flow Matching Models", "abstract": "Generative models have become increasingly powerful tools for robot motion\ngeneration, enabling flexible and multimodal trajectory generation across\nvarious tasks. Yet, most existing approaches remain limited in handling\nmultiple types of constraints, such as collision avoidance and dynamic\nconsistency, which are often treated separately or only partially considered.\nThis paper proposes UniConFlow, a unified flow matching (FM) based framework\nfor trajectory generation that systematically incorporates both equality and\ninequality constraints. UniConFlow introduces a novel prescribed-time zeroing\nfunction to enhance flexibility during the inference process, allowing the\nmodel to adapt to varying task requirements. To ensure constraint satisfaction,\nparticularly with respect to obstacle avoidance, admissible action range, and\nkinodynamic consistency, the guidance inputs to the FM model are derived\nthrough a quadratic programming formulation, which enables constraint-aware\ngeneration without requiring retraining or auxiliary controllers. We conduct\nmobile navigation and high-dimensional manipulation tasks, demonstrating\nimproved safety and feasibility compared to state-of-the-art constrained\ngenerative planners. Project page is available at https://uniconflow.github.io.", "published": "2025-06-03 14:48:04", "link": "http://arxiv.org/abs/2506.02955v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Interaction Field Matching: Overcoming Limitations of Electrostatic Models", "abstract": "Electrostatic field matching (EFM) has recently appeared as a novel\nphysics-inspired paradigm for data generation and transfer using the idea of an\nelectric capacitor. However, it requires modeling electrostatic fields using\nneural networks, which is non-trivial because of the necessity to take into\naccount the complex field outside the capacitor plates. In this paper, we\npropose Interaction Field Matching (IFM), a generalization of EFM which allows\nusing general interaction fields beyond the electrostatic one. Furthermore,\ninspired by strong interactions between quarks and antiquarks in physics, we\ndesign a particular interaction field realization which solves the problems\nwhich arise when modeling electrostatic fields in EFM. We show the performance\non a series of toy and image data transfer problems.", "published": "2025-06-03 14:45:14", "link": "http://arxiv.org/abs/2506.02950v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Dynamic Programming Techniques for Enhancing Cognitive Representation in Knowledge Tracing", "abstract": "Knowledge Tracing (KT) involves monitoring the changes in a student's\nknowledge over time by analyzing their past responses, with the goal of\npredicting future performance. However, most existing methods primarily focus\non feature enhancement, while overlooking the deficiencies in cognitive\nrepresentation and the ability to express cognition-issues often caused by\ninterference from non-cognitive factors such as slipping and guessing. This\nlimitation hampers the ability to capture the continuity and coherence of the\nstudent's cognitive process. As a result, many methods may introduce more\nprediction bias and modeling costs due to their inability to maintain cognitive\ncontinuity and coherence. Based on the above discussion, we propose the\nCognitive Representation Dynamic Programming based Knowledge Tracing (CRDP-KT)\nmodel. This model em ploys a dynamic programming algorithm to optimize\ncognitive representations based on the difficulty of the questions and the\nperformance intervals between them. This approach ensures that the cognitive\nrepresentation aligns with the student's cognitive patterns, maintaining\noverall continuity and coherence. As a result, it provides more accurate and\nsystematic input features for subsequent model training, thereby minimizing\ndistortion in the simulation of cognitive states. Additionally, the CRDP-KT\nmodel performs partitioned optimization of cognitive representations to enhance\nthe reliability of the optimization process. Furthermore, it improves its\nability to express the student's cognition through a weighted fusion of\noptimized record representations and re lationships learned from a bipartite\ngraph. Finally, experiments conducted on three public datasets validate the\neffectiveness of the proposed CRDP-KT model.", "published": "2025-06-03 14:44:48", "link": "http://arxiv.org/abs/2506.02949v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "ThinkTank: A Framework for Generalizing Domain-Specific AI Agent Systems into Universal Collaborative Intelligence Platforms", "abstract": "This paper presents ThinkTank, a comprehensive and scalable framework\ndesigned to transform specialized AI agent systems into versatile collaborative\nintelligence platforms capable of supporting complex problem-solving across\ndiverse domains. ThinkTank systematically generalizes agent roles, meeting\nstructures, and knowledge integration mechanisms by adapting proven scientific\ncollaboration methodologies. Through role abstraction, generalization of\nmeeting types for iterative collaboration, and the integration of\nRetrieval-Augmented Generation with advanced knowledge storage, the framework\nfacilitates expertise creation and robust knowledge sharing. ThinkTank enables\norganizations to leverage collaborative AI for knowledge-intensive tasks while\nensuring data privacy and security through local deployment, utilizing\nframeworks like Ollama with models such as Llama3.1. The ThinkTank framework is\ndesigned to deliver significant advantages in cost-effectiveness, data\nsecurity, scalability, and competitive positioning compared to cloud-based\nalternatives, establishing it as a universal platform for AI-driven\ncollaborative problem-solving. The ThinkTank code is available at\nhttps://github.com/taugroup/ThinkTank", "published": "2025-06-03 14:32:48", "link": "http://arxiv.org/abs/2506.02931v1", "categories": ["cs.MA", "cs.AI", "cs.LG"], "primary_category": "cs.MA"}
{"title": "The Limits of Predicting Agents from Behaviour", "abstract": "As the complexity of AI systems and their interactions with the world\nincreases, generating explanations for their behaviour is important for safely\ndeploying AI. For agents, the most natural abstractions for predicting\nbehaviour attribute beliefs, intentions and goals to the system. If an agent\nbehaves as if it has a certain goal or belief, then we can make reasonable\npredictions about how it will behave in novel situations, including those where\ncomprehensive safety evaluations are untenable. How well can we infer an\nagent's beliefs from their behaviour, and how reliably can these inferred\nbeliefs predict the agent's behaviour in novel situations? We provide a precise\nanswer to this question under the assumption that the agent's behaviour is\nguided by a world model. Our contribution is the derivation of novel bounds on\nthe agent's behaviour in new (unseen) deployment environments, which represent\na theoretical limit for predicting intentional agents from behavioural data\nalone. We discuss the implications of these results for several research areas\nincluding fairness and safety.", "published": "2025-06-03 14:24:58", "link": "http://arxiv.org/abs/2506.02923v1", "categories": ["cs.AI", "stat.ML"], "primary_category": "cs.AI"}
{"title": "Sample, Predict, then Proceed: Self-Verification Sampling for Tool Use of LLMs", "abstract": "Tool use in stateful environments presents unique challenges for large\nlanguage models (LLMs), where existing test-time compute strategies relying on\nrepeated trials in the environment are impractical. We propose dynamics\nmodelling (DyMo), a method that augments LLMs with a state prediction\ncapability alongside function calling during post-training. This enables LLMs\nto predict the future states of their actions through an internal environment\nmodel. On the Berkeley Function Calling Leaderboard V2, DyMo improves success\nrates and significantly reduces hallucinations. We further integrate the\ninternal environment model into self-verification sampling (SVS), and show that\nthis substantially improves pass^k over number of trials k, and allows the\nmodel to refuse unreliable outputs. Together, DyMo and SVS greatly enhance the\neffectiveness and reliability of LLMs for tool use. We believe this work charts\na path towards scalable planning RL methods for LLM inference without\nrepeatedly querying the oracle environment.", "published": "2025-06-03 14:20:59", "link": "http://arxiv.org/abs/2506.02918v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "It's the Thought that Counts: Evaluating the Attempts of Frontier LLMs to Persuade on Harmful Topics", "abstract": "Persuasion is a powerful capability of large language models (LLMs) that both\nenables beneficial applications (e.g. helping people quit smoking) and raises\nsignificant risks (e.g. large-scale, targeted political manipulation). Prior\nwork has found models possess a significant and growing persuasive capability,\nmeasured by belief changes in simulated or real users. However, these\nbenchmarks overlook a crucial risk factor: the propensity of a model to attempt\nto persuade in harmful contexts. Understanding whether a model will blindly\n``follow orders'' to persuade on harmful topics (e.g. glorifying joining a\nterrorist group) is key to understanding the efficacy of safety guardrails.\nMoreover, understanding if and when a model will engage in persuasive behavior\nin pursuit of some goal is essential to understanding the risks from agentic AI\nsystems. We propose the Attempt to Persuade Eval (APE) benchmark, that shifts\nthe focus from persuasion success to persuasion attempts, operationalized as a\nmodel's willingness to generate content aimed at shaping beliefs or behavior.\nOur evaluation framework probes frontier LLMs using a multi-turn conversational\nsetup between simulated persuader and persuadee agents. APE explores a diverse\nspectrum of topics including conspiracies, controversial issues, and\nnon-controversially harmful content. We introduce an automated evaluator model\nto identify willingness to persuade and measure the frequency and context of\npersuasive attempts. We find that many open and closed-weight models are\nfrequently willing to attempt persuasion on harmful topics and that\njailbreaking can increase willingness to engage in such behavior. Our results\nhighlight gaps in current safety guardrails and underscore the importance of\nevaluating willingness to persuade as a key dimension of LLM risk. APE is\navailable at github.com/AlignmentResearch/AttemptPersuadeEval", "published": "2025-06-03 13:37:51", "link": "http://arxiv.org/abs/2506.02873v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Surfer-H Meets Holo1: Cost-Efficient Web Agent Powered by Open Weights", "abstract": "We present Surfer-H, a cost-efficient web agent that integrates\nVision-Language Models (VLM) to perform user-defined tasks on the web. We pair\nit with Holo1, a new open-weight collection of VLMs specialized in web\nnavigation and information extraction. Holo1 was trained on carefully curated\ndata sources, including open-access web content, synthetic examples, and\nself-produced agentic data. Holo1 tops generalist User Interface (UI)\nbenchmarks as well as our new web UI localization benchmark, WebClick. When\npowered by Holo1, Surfer-H achieves a 92.2% state-of-the-art performance on\nWebVoyager, striking a Pareto-optimal balance between accuracy and\ncost-efficiency. To accelerate research advancement in agentic systems, we are\nopen-sourcing both our WebClick evaluation dataset and the Holo1 model weights.", "published": "2025-06-03 13:29:03", "link": "http://arxiv.org/abs/2506.02865v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "BNPO: Beta Normalization Policy Optimization", "abstract": "Recent studies, including DeepSeek-R1 and Kimi-k1.5, have demonstrated that\nreinforcement learning with rule-based, binary-valued reward functions can\nsignificantly enhance the reasoning capabilities of large language models.\nThese models primarily utilize REINFORCE-based policy optimization techniques,\nsuch as REINFORCE with baseline and group relative policy optimization (GRPO).\nHowever, a key limitation remains: current policy optimization methods either\nneglect reward normalization or employ static normalization strategies, which\nfail to adapt to the dynamic nature of policy updates during training. This may\nresult in unstable gradient estimates and hinder training stability. To address\nthis issue, we propose Beta Normalization Policy Optimization (BNPO), a novel\npolicy optimization method that adaptively normalizes rewards using a Beta\ndistribution with dynamically updated parameters. BNPO aligns the normalization\nwith the changing policy distribution, enabling more precise and lower-variance\ngradient estimation, which in turn promotes stable training dynamics. We\nprovide theoretical analysis demonstrating BNPO's variance-reducing properties\nand show that it generalizes both REINFORCE and GRPO under binary-valued reward\nsettings. Furthermore, we introduce an advantage decomposition mechanism to\nextend BNPO's applicability to more complex reward systems. Experimental\nresults confirm that BNPO achieves state-of-the-art performance among policy\noptimization methods on reasoning tasks. The code is available at\nhttps://github.com/changyi7231/BNPO.", "published": "2025-06-03 13:28:57", "link": "http://arxiv.org/abs/2506.02864v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "CapSpeech: Enabling Downstream Applications in Style-Captioned Text-to-Speech", "abstract": "Recent advancements in generative artificial intelligence have significantly\ntransformed the field of style-captioned text-to-speech synthesis (CapTTS).\nHowever, adapting CapTTS to real-world applications remains challenging due to\nthe lack of standardized, comprehensive datasets and limited research on\ndownstream tasks built upon CapTTS. To address these gaps, we introduce\nCapSpeech, a new benchmark designed for a series of CapTTS-related tasks,\nincluding style-captioned text-to-speech synthesis with sound events\n(CapTTS-SE), accent-captioned TTS (AccCapTTS), emotion-captioned TTS\n(EmoCapTTS), and text-to-speech synthesis for chat agent (AgentTTS). CapSpeech\ncomprises over 10 million machine-annotated audio-caption pairs and nearly 0.36\nmillion human-annotated audio-caption pairs. In addition, we introduce two new\ndatasets collected and recorded by a professional voice actor and experienced\naudio engineers, specifically for the AgentTTS and CapTTS-SE tasks. Alongside\nthe datasets, we conduct comprehensive experiments using both autoregressive\nand non-autoregressive models on CapSpeech. Our results demonstrate\nhigh-fidelity and highly intelligible speech synthesis across a diverse range\nof speaking styles. To the best of our knowledge, CapSpeech is the largest\navailable dataset offering comprehensive annotations for CapTTS-related tasks.\nThe experiments and findings further provide valuable insights into the\nchallenges of developing CapTTS systems.", "published": "2025-06-03 13:28:55", "link": "http://arxiv.org/abs/2506.02863v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Tru-POMDP: Task Planning Under Uncertainty via Tree of Hypotheses and Open-Ended POMDPs", "abstract": "Task planning under uncertainty is essential for home-service robots\noperating in the real world. Tasks involve ambiguous human instructions, hidden\nor unknown object locations, and open-vocabulary object types, leading to\nsignificant open-ended uncertainty and a boundlessly large planning space. To\naddress these challenges, we propose Tru-POMDP, a planner that combines\nstructured belief generation using Large Language Models (LLMs) with principled\nPOMDP planning. Tru-POMDP introduces a hierarchical Tree of Hypotheses (TOH),\nwhich systematically queries an LLM to construct high-quality particle beliefs\nover possible world states and human goals. We further formulate an open-ended\nPOMDP model that enables rigorous Bayesian belief tracking and efficient\nbelief-space planning over these LLM-generated hypotheses. Experiments on\ncomplex object rearrangement tasks across diverse kitchen environments show\nthat Tru-POMDP significantly outperforms state-of-the-art LLM-based and\nLLM-tree-search hybrid planners, achieving higher success rates with\nsignificantly better plans, stronger robustness to ambiguity and occlusion, and\ngreater planning efficiency.", "published": "2025-06-03 13:26:08", "link": "http://arxiv.org/abs/2506.02860v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "ATAG: AI-Agent Application Threat Assessment with Attack Graphs", "abstract": "Evaluating the security of multi-agent systems (MASs) powered by large\nlanguage models (LLMs) is challenging, primarily because of the systems'\ncomplex internal dynamics and the evolving nature of LLM vulnerabilities.\nTraditional attack graph (AG) methods often lack the specific capabilities to\nmodel attacks on LLMs. This paper introduces AI-agent application Threat\nassessment with Attack Graphs (ATAG), a novel framework designed to\nsystematically analyze the security risks associated with AI-agent\napplications. ATAG extends the MulVAL logic-based AG generation tool with\ncustom facts and interaction rules to accurately represent AI-agent topologies,\nvulnerabilities, and attack scenarios. As part of this research, we also\ncreated the LLM vulnerability database (LVD) to initiate the process of\nstandardizing LLM vulnerabilities documentation. To demonstrate ATAG's\nefficacy, we applied it to two multi-agent applications. Our case studies\ndemonstrated the framework's ability to model and generate AGs for\nsophisticated, multi-step attack scenarios exploiting vulnerabilities such as\nprompt injection, excessive agency, sensitive information disclosure, and\ninsecure output handling across interconnected agents. ATAG is an important\nstep toward a robust methodology and toolset to help understand, visualize, and\nprioritize complex attack paths in multi-agent AI systems (MAASs). It\nfacilitates proactive identification and mitigation of AI-agent threats in\nmulti-agent applications.", "published": "2025-06-03 13:25:40", "link": "http://arxiv.org/abs/2506.02859v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "DGMO: Training-Free Audio Source Separation through Diffusion-Guided Mask Optimization", "abstract": "Language-queried Audio Source Separation (LASS) enables open-vocabulary sound\nseparation via natural language queries. While existing methods rely on\ntask-specific training, we explore whether pretrained diffusion models,\noriginally designed for audio generation, can inherently perform separation\nwithout further training. In this study, we introduce a training-free framework\nleveraging generative priors for zero-shot LASS. Analyzing na\\\"ive adaptations,\nwe identify key limitations arising from modality-specific challenges.To\naddress these issues, we propose Diffusion-Guided Mask Optimization (DGMO), a\ntest-time optimization framework that refines spectrogram masks for precise,\ninput-aligned separation. Our approach effectively repurposes pretrained\ndiffusion models for source separation, achieving competitive performance\nwithout task-specific supervision. This work expands the application of\ndiffusion models beyond generation, establishing a new paradigm for zero-shot\naudio separation. The code is available at: https://wltschmrz.github.io/DGMO/", "published": "2025-06-03 13:24:57", "link": "http://arxiv.org/abs/2506.02858v1", "categories": ["cs.SD", "cs.AI"], "primary_category": "cs.SD"}
{"title": "Sheaves Reloaded: A Directional Awakening", "abstract": "Sheaf Neural Networks (SNNs) represent a powerful generalization of Graph\nNeural Networks (GNNs) that significantly improve our ability to model complex\nrelational data. While directionality has been shown to substantially boost\nperformance in graph learning tasks and is key to many real-world applications,\nexisting SNNs fall short in representing it. To address this limitation, we\nintroduce the Directed Cellular Sheaf, a special type of cellular sheaf\ndesigned to explicitly account for edge orientation. Building on this\nstructure, we define a new sheaf Laplacian, the Directed Sheaf Laplacian, which\ncaptures both the graph's topology and its directional information. This\noperator serves as the backbone of the Directed Sheaf Neural Network (DSNN),\nthe first SNN model to embed a directional bias into its architecture.\nExtensive experiments on nine real-world benchmarks show that DSNN consistently\noutperforms baseline methods.", "published": "2025-06-03 13:13:56", "link": "http://arxiv.org/abs/2506.02842v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "DeepShop: A Benchmark for Deep Research Shopping Agents", "abstract": "Web agents for online shopping have shown great promise in automating user\ninteractions across e-commerce platforms. Benchmarks for assessing such agents\ndo not reflect the complexity of real-world shopping scenarios, as they often\nconsist of overly simple queries with deterministic paths, such as \"Find iPhone\n15.\" Real shopping scenarios are inherently more layered, involving\nmulti-dimensional product attributes, search filters, and user-specific sorting\npreferences. To address this gap, we introduce DeepShop, a benchmark designed\nto evaluate web agents in complex and realistic online shopping environments.\nDeepShop comprises three key components. (1) Query diversity evolution:\nStarting from real user queries, we generate diverse queries across five\npopular online shopping domains. (2) Query complexity evolution: We further\nevolve these queries to increase complexity, considering product attributes,\nsearch filters, and sorting preferences, and classify them into three levels:\neasy, medium, and hard, based on the number of evolutions. (3) Fine-grained and\nholistic evaluation: We propose an automated evaluation framework that assesses\nagent performance in terms of fine-grained aspects (product attributes, search\nfilters, and sorting preferences) and reports the overall success rate through\nholistic evaluation. We conduct a systematic evaluation of retrieval-augmented\ngeneration (RAG) methods, web agents, and deep research systems. Results show\nthat RAG struggles with complex queries due to its lack of web interaction,\nwhile other methods face significant challenges with filters and sorting\npreferences, leading to low overall success rates. We also perform\ncross-category, complexity-based evaluations and error analyses to support the\nadvancement of deep research shopping agents.", "published": "2025-06-03 13:08:17", "link": "http://arxiv.org/abs/2506.02839v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "TaxAgent: How Large Language Model Designs Fiscal Policy", "abstract": "Economic inequality is a global challenge, intensifying disparities in\neducation, healthcare, and social stability. Traditional systems like the U.S.\nfederal income tax reduce inequality but lack adaptability. Although models\nlike the Saez Optimal Taxation adjust dynamically, they fail to address\ntaxpayer heterogeneity and irrational behavior. This study introduces TaxAgent,\na novel integration of large language models (LLMs) with agent-based modeling\n(ABM) to design adaptive tax policies. In our macroeconomic simulation,\nheterogeneous H-Agents (households) simulate real-world taxpayer behaviors\nwhile the TaxAgent (government) utilizes LLMs to iteratively optimize tax\nrates, balancing equity and productivity. Benchmarked against Saez Optimal\nTaxation, U.S. federal income taxes, and free markets, TaxAgent achieves\nsuperior equity-efficiency trade-offs. This research offers a novel taxation\nsolution and a scalable, data-driven framework for fiscal policy evaluation.", "published": "2025-06-03 13:06:19", "link": "http://arxiv.org/abs/2506.02838v1", "categories": ["cs.AI", "econ.GN", "q-fin.EC", "I.2.11; I.6.5; J.4"], "primary_category": "cs.AI"}
{"title": "Optimising the attribute order in Fuzzy Rough Rule Induction", "abstract": "Interpretability is the next pivotal frontier in machine learning research.\nIn the pursuit of glass box models - as opposed to black box models, like\nrandom forests or neural networks - rule induction algorithms are a logical and\npromising avenue, as the rules can easily be understood by humans. In our\nprevious work, we introduced FRRI, a novel rule induction algorithm based on\nfuzzy rough set theory. We demonstrated experimentally that FRRI outperformed\nother rule induction methods with regards to accuracy and number of rules. FRRI\nleverages a fuzzy indiscernibility relation to partition the data space into\nfuzzy granules, which are then combined into a minimal covering set of rules.\nThis indiscernibility relation is constructed by removing attributes from rules\nin a greedy way. This raises the question: does the order of the attributes\nmatter? In this paper, we show that optimising only the order of attributes\nusing known methods from fuzzy rough set theory and classical machine learning\ndoes not improve the performance of FRRI on multiple metrics. However, removing\na small number of attributes using fuzzy rough feature selection during this\nstep positively affects balanced accuracy and the average rule length.", "published": "2025-06-03 12:34:40", "link": "http://arxiv.org/abs/2506.02805v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Deep Learning Enhanced Multivariate GARCH", "abstract": "This paper introduces a novel multivariate volatility modeling framework,\nnamed Long Short-Term Memory enhanced BEKK (LSTM-BEKK), that integrates deep\nlearning into multivariate GARCH processes. By combining the flexibility of\nrecurrent neural networks with the econometric structure of BEKK models, our\napproach is designed to better capture nonlinear, dynamic, and high-dimensional\ndependence structures in financial return data. The proposed model addresses\nkey limitations of traditional multivariate GARCH-based methods, particularly\nin capturing persistent volatility clustering and asymmetric co-movement across\nassets. Leveraging the data-driven nature of LSTMs, the framework adapts\neffectively to time-varying market conditions, offering improved robustness and\nforecasting performance. Empirical results across multiple equity markets\nconfirm that the LSTM-BEKK model achieves superior performance in terms of\nout-of-sample portfolio risk forecast, while maintaining the interpretability\nfrom the BEKK models. These findings highlight the potential of hybrid\neconometric-deep learning models in advancing financial risk management and\nmultivariate volatility forecasting.", "published": "2025-06-03 12:22:57", "link": "http://arxiv.org/abs/2506.02796v1", "categories": ["q-fin.CP", "cs.AI", "econ.EM"], "primary_category": "q-fin.CP"}
{"title": "PhysGaia: A Physics-Aware Dataset of Multi-Body Interactions for Dynamic Novel View Synthesis", "abstract": "We introduce PhysGaia, a novel physics-aware dataset specifically designed\nfor Dynamic Novel View Synthesis (DyNVS), encompassing both structured objects\nand unstructured physical phenomena. Unlike existing datasets that primarily\nfocus on photorealistic reconstruction, PhysGaia is created to actively support\nphysics-aware dynamic scene modeling. Our dataset provides complex dynamic\nscenarios with rich interactions among multiple objects, where they\nrealistically collide with each other and exchange forces. Furthermore, it\ncontains a diverse range of physical materials, such as liquid, gas,\nviscoelastic substance, and textile, which moves beyond the rigid bodies\nprevalent in existing datasets. All scenes in PhysGaia are faithfully generated\nto strictly adhere to physical laws, leveraging carefully selected\nmaterial-specific physics solvers. To enable quantitative evaluation of\nphysical modeling, our dataset provides essential ground-truth information,\nincluding 3D particle trajectories and physics parameters, e.g., viscosity. To\nfacilitate research adoption, we also provide essential integration pipelines\nfor using state-of-the-art DyNVS models with our dataset and report their\nresults. By addressing the critical lack of datasets for physics-aware\nmodeling, PhysGaia will significantly advance research in dynamic view\nsynthesis, physics-based scene understanding, and deep learning models\nintegrated with physical simulation -- ultimately enabling more faithful\nreconstruction and interpretation of complex dynamic scenes. Our datasets and\ncodes are available in the project website,\nhttp://cvlab.snu.ac.kr/research/PhysGaia.", "published": "2025-06-03 12:19:18", "link": "http://arxiv.org/abs/2506.02794v1", "categories": ["cs.GR", "cs.AI", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Rethinking the effects of data contamination in Code Intelligence", "abstract": "In recent years, code intelligence has gained increasing importance in the\nfield of automated software engineering. Meanwhile, the widespread adoption of\nPretrained Language Models (PLMs) and Large Language Models (LLMs) has raised\nconcerns regarding data contamination and its potential impact on model\nperformance evaluation. This paper presents a systematic empirical study to\ninvestigate the fine-grained data contamination on code intelligence tasks. Our\nstudy involves diverse representative PLMs, namely RoBERTa and GPT-2, and LLMs,\nnamely LLaMA and StarCoder, covering three major tasks: code translation, code\ngeneration, and code summarization. We categorize contamination scenarios into\nfour types according to the code intelligence practice, namely input-only,\noutput-only, unpaired, and paired contamination settings, and construct\ncorresponding experimental and control groups for exploration.\n  Experimental results show that, under the pre-training, fine-tuning, and\ninference paradigm adopted by PLMs, even deliberately injecting paired\ncontamination does not lead to significant performance overestimation. But\ndirect inference or small-scale fine-tuning uncovers the contamination effects.\nIn contrast, LLMs with pre-training and inference paradigm are significantly\naffected by the paired contamination. Apart from the above, other contamination\nscenarios have no impact on both PLMs and LLMs. Our findings challenge the\nconventional belief that contamination inevitably leads to performance\noverestimation, providing new insights into the evaluation and deployment of\ncode intelligence models.", "published": "2025-06-03 12:15:44", "link": "http://arxiv.org/abs/2506.02791v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Rethinking Dynamic Networks and Heterogeneous Computing with Automatic Parallelization", "abstract": "Hybrid parallelism techniques are essential for efficiently training large\nlanguage models (LLMs). Nevertheless, current automatic parallel planning\nframeworks often overlook the simultaneous consideration of node heterogeneity\nand dynamic network topology changes, limiting their effectiveness in practical\napplications. In this paper, we address these limitations by modeling\nheterogeneous nodes within dynamically changing network environments and\nleveraging simulation-based strategies to determine optimal parallel\nconfigurations. Our approach enables fine-grained workload allocation tailored\nfor heterogeneous nodes and complex network scenarios, achieving performance\ncompetitive with state-of-the-art methods under regular and stable network\nconditions. Additionally, we introduce a strategy pruning technique to rapidly\ndiscard infeasible parallel configurations, substantially reducing the search\nspace and accelerating the search process through parallel execution within the\nsimulator. Preliminary evaluations confirm that our method notably enhances\ntraining performance on heterogeneous nodes and demonstrates improved\nadaptability in complex, dynamic scenarios such as cloud computing\nenvironments.", "published": "2025-06-03 12:14:17", "link": "http://arxiv.org/abs/2506.02787v1", "categories": ["cs.DC", "cs.AI"], "primary_category": "cs.DC"}
{"title": "AI-Driven Vehicle Condition Monitoring with Cell-Aware Edge Service Migration", "abstract": "Artificial intelligence (AI) has been increasingly applied to the condition\nmonitoring of vehicular equipment, aiming to enhance maintenance strategies,\nreduce costs, and improve safety. Leveraging the edge computing paradigm,\nAI-based condition monitoring systems process vast streams of vehicular data to\ndetect anomalies and optimize operational performance. In this work, we\nintroduce a novel vehicle condition monitoring service that enables real-time\ndiagnostics of a diverse set of anomalies while remaining practical for\ndeployment in real-world edge environments. To address mobility challenges, we\npropose a closed-loop service orchestration framework where service migration\nacross edge nodes is dynamically triggered by network-related metrics. Our\napproach has been implemented and tested in a real-world race circuit\nenvironment equipped with 5G network capabilities under diverse operational\nconditions. Experimental results demonstrate the effectiveness of our framework\nin ensuring low-latency AI inference and adaptive service placement,\nhighlighting its potential for intelligent transportation and mobility\napplications.", "published": "2025-06-03 12:12:27", "link": "http://arxiv.org/abs/2506.02785v1", "categories": ["cs.NI", "cs.AI"], "primary_category": "cs.NI"}
{"title": "Unified Attention Modeling for Efficient Free-Viewing and Visual Search via Shared Representations", "abstract": "Computational human attention modeling in free-viewing and task-specific\nsettings is often studied separately, with limited exploration of whether a\ncommon representation exists between them. This work investigates this question\nand proposes a neural network architecture that builds upon the Human Attention\ntransformer (HAT) to test the hypothesis. Our results demonstrate that\nfree-viewing and visual search can efficiently share a common representation,\nallowing a model trained in free-viewing attention to transfer its knowledge to\ntask-driven visual search with a performance drop of only 3.86% in the\npredicted fixation scanpaths, measured by the semantic sequence score (SemSS)\nmetric which reflects the similarity between predicted and human scanpaths.\nThis transfer reduces computational costs by 92.29% in terms of GFLOPs and\n31.23% in terms of trainable parameters.", "published": "2025-06-03 11:29:11", "link": "http://arxiv.org/abs/2506.02764v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Investigating Mask-aware Prototype Learning for Tabular Anomaly Detection", "abstract": "Tabular anomaly detection, which aims at identifying deviant samples, has\nbeen crucial in a variety of real-world applications, such as medical disease\nidentification, financial fraud detection, intrusion monitoring, etc. Although\nrecent deep learning-based methods have achieved competitive performances,\nthese methods suffer from representation entanglement and the lack of global\ncorrelation modeling, which hinders anomaly detection performance. To tackle\nthe problem, we incorporate mask modeling and prototype learning into tabular\nanomaly detection. The core idea is to design learnable masks by disentangled\nrepresentation learning within a projection space and extracting normal\ndependencies as explicit global prototypes. Specifically, the overall model\ninvolves two parts: (i) During encoding, we perform mask modeling in both the\ndata space and projection space with orthogonal basis vectors for learning\nshared disentangled normal patterns; (ii) During decoding, we decode multiple\nmasked representations in parallel for reconstruction and learn association\nprototypes to extract normal characteristic correlations. Our proposal derives\nfrom a distribution-matching perspective, where both projection space learning\nand association prototype learning are formulated as optimal transport\nproblems, and the calibration distances are utilized to refine the anomaly\nscores. Quantitative and qualitative experiments on 20 tabular benchmarks\ndemonstrate the effectiveness and interpretability of our model.", "published": "2025-06-03 11:22:44", "link": "http://arxiv.org/abs/2506.02757v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Knowledge Graph Completion by Intermediate Variables Regularization", "abstract": "Knowledge graph completion (KGC) can be framed as a 3-order binary tensor\ncompletion task. Tensor decomposition-based (TDB) models have demonstrated\nstrong performance in KGC. In this paper, we provide a summary of existing TDB\nmodels and derive a general form for them, serving as a foundation for further\nexploration of TDB models. Despite the expressiveness of TDB models, they are\nprone to overfitting. Existing regularization methods merely minimize the norms\nof embeddings to regularize the model, leading to suboptimal performance.\nTherefore, we propose a novel regularization method for TDB models that\naddresses this limitation. The regularization is applicable to most TDB models\nand ensures tractable computation. Our method minimizes the norms of\nintermediate variables involved in the different ways of computing the\npredicted tensor. To support our regularization method, we provide a\ntheoretical analysis that proves its effect in promoting low trace norm of the\npredicted tensor to reduce overfitting. Finally, we conduct experiments to\nverify the effectiveness of our regularization technique as well as the\nreliability of our theoretical analysis. The code is available at\nhttps://github.com/changyi7231/IVR.", "published": "2025-06-03 11:11:33", "link": "http://arxiv.org/abs/2506.02749v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Solving the Pod Repositioning Problem with Deep Reinforced Adaptive Large Neighborhood Search", "abstract": "The Pod Repositioning Problem (PRP) in Robotic Mobile Fulfillment Systems\n(RMFS) involves selecting optimal storage locations for pods returning from\npick stations. This work presents an improved solution method that integrates\nAdaptive Large Neighborhood Search (ALNS) with Deep Reinforcement Learning\n(DRL). A DRL agent dynamically selects destroy and repair operators and adjusts\nkey parameters such as destruction degree and acceptance thresholds during the\nsearch. Specialized heuristics for both operators are designed to reflect\nPRP-specific characteristics, including pod usage frequency and movement costs.\nComputational results show that this DRL-guided ALNS outperforms traditional\napproaches such as cheapest-place, fixed-place, binary integer programming, and\nstatic heuristics. The method demonstrates strong solution quality and\nillustrating the benefit of learning-driven control within combinatorial\noptimization for warehouse systems.", "published": "2025-06-03 11:07:41", "link": "http://arxiv.org/abs/2506.02746v1", "categories": ["cs.RO", "cs.AI", "math.OC"], "primary_category": "cs.RO"}
{"title": "Enriching Location Representation with Detailed Semantic Information", "abstract": "Spatial representations that capture both structural and semantic\ncharacteristics of urban environments are essential for urban modeling.\nTraditional spatial embeddings often prioritize spatial proximity while\nunderutilizing fine-grained contextual information from places. To address this\nlimitation, we introduce CaLLiPer+, an extension of the CaLLiPer model that\nsystematically integrates Point-of-Interest (POI) names alongside categorical\nlabels within a multimodal contrastive learning framework. We evaluate its\neffectiveness on two downstream tasks, land use classification and\nsocioeconomic status distribution mapping, demonstrating consistent performance\ngains of 4% to 11% over baseline methods. Additionally, we show that\nincorporating POI names enhances location retrieval, enabling models to capture\ncomplex urban concepts with greater precision. Ablation studies further reveal\nthe complementary role of POI names and the advantages of leveraging pretrained\ntext encoders for spatial representations. Overall, our findings highlight the\npotential of integrating fine-grained semantic attributes and multimodal\nlearning techniques to advance the development of urban foundation models.", "published": "2025-06-03 11:06:51", "link": "http://arxiv.org/abs/2506.02744v1", "categories": ["cs.CE", "cs.AI"], "primary_category": "cs.CE"}
{"title": "Prompt-Unseen-Emotion: Zero-shot Expressive Speech Synthesis with Prompt-LLM Contextual Knowledge for Mixed Emotions", "abstract": "Existing expressive text-to-speech (TTS) systems primarily model a limited\nset of categorical emotions, whereas human conversations extend far beyond\nthese predefined emotions, making it essential to explore more diverse\nemotional speech generation for more natural interactions. To bridge this gap,\nthis paper proposes a novel prompt-unseen-emotion (PUE) approach to generate\nunseen emotional speech via emotion-guided prompt learning. PUE is trained\nutilizing an LLM-TTS architecture to ensure emotional consistency between\ncategorical emotion-relevant prompts and emotional speech, allowing the model\nto quantitatively capture different emotion weightings per utterance. During\ninference, mixed emotional speech can be generated by flexibly adjusting\nemotion proportions and leveraging LLM contextual knowledge, enabling the model\nto quantify different emotional styles. Our proposed PUE successfully\nfacilitates expressive speech synthesis of unseen emotions in a zero-shot\nsetting.", "published": "2025-06-03 10:59:22", "link": "http://arxiv.org/abs/2506.02742v1", "categories": ["eess.AS", "cs.AI", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Why do AI agents communicate in human language?", "abstract": "Large Language Models (LLMs) have become foundational to modern AI agent\nsystems, enabling autonomous agents to reason and plan. In most existing\nsystems, inter-agent communication relies primarily on natural language. While\nthis design supports interpretability and human oversight, we argue that it\nintroduces fundamental limitations in agent-to-agent coordination. The semantic\nspace of natural language is structurally misaligned with the high-dimensional\nvector spaces in which LLMs operate, resulting in information loss and\nbehavioral drift. Beyond surface-level inefficiencies, we highlight a deeper\narchitectural limitation: current LLMs were not trained with the objective of\nsupporting agentic behavior. As such, they lack mechanisms for modeling role\ncontinuity, task boundaries, and multi-agent dependencies. The standard\nnext-token prediction paradigm fails to support the structural alignment\nrequired for robust, scalable agent coordination. Based on this, we argue that\ntwo core questions deserve careful examination: first, given that AI agents\nfundamentally operate in high-dimensional vector spaces, should they rely on a\nlanguage system originally designed for human cognition as their communication\nmedium? Second, should we consider developing a new model construction paradigm\nthat builds models from the ground up to natively support structured\ncommunication, shared intentionality, and task alignment in multi-role,\nmulti-agent environments? This paper calls for a reconsideration not only of\nhow agents should communicate, but also of what it fundamentally means to train\na model that natively supports multi-agent coordination and communication.", "published": "2025-06-03 10:53:29", "link": "http://arxiv.org/abs/2506.02739v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "LinkTo-Anime: A 2D Animation Optical Flow Dataset from 3D Model Rendering", "abstract": "Existing optical flow datasets focus primarily on real-world simulation or\nsynthetic human motion, but few are tailored to Celluloid(cel) anime character\nmotion: a domain with unique visual and motion characteristics. To bridge this\ngap and facilitate research in optical flow estimation and downstream tasks\nsuch as anime video generation and line drawing colorization, we introduce\nLinkTo-Anime, the first high-quality dataset specifically designed for cel\nanime character motion generated with 3D model rendering. LinkTo-Anime provides\nrich annotations including forward and backward optical flow, occlusion masks,\nand Mixamo Skeleton. The dataset comprises 395 video sequences, totally 24,230\ntraining frames, 720 validation frames, and 4,320 test frames. Furthermore, a\ncomprehensive benchmark is constructed with various optical flow estimation\nmethods to analyze the shortcomings and limitations across multiple datasets.", "published": "2025-06-03 10:50:20", "link": "http://arxiv.org/abs/2506.02733v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Heterogeneous Group-Based Reinforcement Learning for LLM-based Multi-Agent Systems", "abstract": "Large Language Models (LLMs) have achieved remarkable success across diverse\nnatural language processing tasks, yet their deployment in real-world\napplications is hindered by fixed knowledge cutoffs and difficulties in\ngenerating controllable, accurate outputs in a single inference. Multi-agent\nsystems (MAS) built from specialized LLM agents offer a promising solution,\nenabling dynamic collaboration and iterative reasoning. However, optimizing\nthese systems remains a challenge, as conventional methods such as prompt\nengineering and supervised fine-tuning entail high engineering overhead and\nlimited adaptability. Reinforcement learning (RL), particularly multi-agent\nreinforcement learning (MARL), provides a scalable framework by refining agent\npolicies based on system-level feedback. Nevertheless, existing MARL\nalgorithms, such as Multi-Agent Proximal Policy Optimization (MAPPO), rely on\nCritic networks, which can cause training instability and increase\ncomputational burden. To address these limitations and target the prototypical\nMulti-Agent Search System (MASS), we propose Multi-Agent Heterogeneous Group\nPolicy Optimization (MHGPO), a novel Critic-free algorithm that guides policy\nupdates by estimating relative reward advantages across heterogeneous groups of\nrollouts. MHGPO eliminates the need for Critic networks, enhancing stability\nand reducing computational overhead. Additionally, we introduce three group\nrollout sampling strategies that trade off between efficiency and\neffectiveness. Experiments on a multi-agent LLM-based search system demonstrate\nthat MHGPO consistently outperforms MAPPO in both task performance and\ncomputational efficiency, without requiring warm-up, underscoring its potential\nfor stable and scalable optimization of complex LLM-based MAS.", "published": "2025-06-03 10:17:19", "link": "http://arxiv.org/abs/2506.02718v1", "categories": ["cs.LG", "cs.AI", "I.2.7"], "primary_category": "cs.LG"}
{"title": "Open-Set Living Need Prediction with Large Language Models", "abstract": "Living needs are the needs people generate in their daily lives for survival\nand well-being. On life service platforms like Meituan, user purchases are\ndriven by living needs, making accurate living need predictions crucial for\npersonalized service recommendations. Traditional approaches treat this\nprediction as a closed-set classification problem, severely limiting their\nability to capture the diversity and complexity of living needs. In this work,\nwe redefine living need prediction as an open-set classification problem and\npropose PIGEON, a novel system leveraging large language models (LLMs) for\nunrestricted need prediction. PIGEON first employs a behavior-aware record\nretriever to help LLMs understand user preferences, then incorporates Maslow's\nhierarchy of needs to align predictions with human living needs. For evaluation\nand application, we design a recall module based on a fine-tuned text embedding\nmodel that links flexible need descriptions to appropriate life services.\nExtensive experiments on real-world datasets demonstrate that PIGEON\nsignificantly outperforms closed-set approaches on need-based life service\nrecall by an average of 19.37%. Human evaluation validates the reasonableness\nand specificity of our predictions. Additionally, we employ instruction tuning\nto enable smaller LLMs to achieve competitive performance, supporting practical\ndeployment.", "published": "2025-06-03 10:10:19", "link": "http://arxiv.org/abs/2506.02713v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Data Leakage and Deceptive Performance: A Critical Examination of Credit Card Fraud Detection Methodologies", "abstract": "This study critically examines the methodological rigor in credit card fraud\ndetection research, revealing how fundamental evaluation flaws can overshadow\nalgorithmic sophistication. Through deliberate experimentation with improper\nevaluation protocols, we demonstrate that even simple models can achieve\ndeceptively impressive results when basic methodological principles are\nviolated. Our analysis identifies four critical issues plaguing current\napproaches: (1) pervasive data leakage from improper preprocessing sequences,\n(2) intentional vagueness in methodological reporting, (3) inadequate temporal\nvalidation for transaction data, and (4) metric manipulation through recall\noptimization at precision's expense. We present a case study showing how a\nminimal neural network architecture with data leakage outperforms many\nsophisticated methods reported in literature, achieving 99.9\\% recall despite\nfundamental evaluation flaws. These findings underscore that proper evaluation\nmethodology matters more than model complexity in fraud detection research. The\nstudy serves as a cautionary example of how methodological rigor must precede\narchitectural sophistication, with implications for improving research\npractices across machine learning applications.", "published": "2025-06-03 09:56:43", "link": "http://arxiv.org/abs/2506.02703v1", "categories": ["cs.LG", "cs.AI", "cs.CY"], "primary_category": "cs.LG"}
{"title": "Shaking to Reveal: Perturbation-Based Detection of LLM Hallucinations", "abstract": "Hallucination remains a key obstacle to the reliable deployment of large\nlanguage models (LLMs) in real-world question answering tasks. A widely adopted\nstrategy to detect hallucination, known as self-assessment, relies on the\nmodel's own output confidence to estimate the factual accuracy of its answers.\nHowever, this strategy assumes that the model's output distribution closely\nreflects the true data distribution, which may not always hold in practice. As\nbias accumulates through the model's layers, the final output can diverge from\nthe underlying reasoning process, making output-level confidence an unreliable\nsignal for hallucination detection. In this work, we propose Sample-Specific\nPrompting (SSP), a new framework that improves self-assessment by analyzing\nperturbation sensitivity at intermediate representations. These\nrepresentations, being less influenced by model bias, offer a more faithful\nview of the model's latent reasoning process. Specifically, SSP dynamically\ngenerates noise prompts for each input and employs a lightweight encoder to\namplify the changes in representations caused by the perturbation. A\ncontrastive distance metric is then used to quantify these differences and\nseparate truthful from hallucinated responses. By leveraging the dynamic\nbehavior of intermediate representations under perturbation, SSP enables more\nreliable self-assessment. Extensive experiments demonstrate that SSP\nsignificantly outperforms prior methods across a range of hallucination\ndetection benchmarks.", "published": "2025-06-03 09:44:28", "link": "http://arxiv.org/abs/2506.02696v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "XicorAttention: Time Series Transformer Using Attention with Nonlinear Correlation", "abstract": "Various Transformer-based models have been proposed for time series\nforecasting. These models leverage the self-attention mechanism to capture\nlong-term temporal or variate dependencies in sequences. Existing methods can\nbe divided into two approaches: (1) reducing computational cost of attention by\nmaking the calculations sparse, and (2) reshaping the input data to aggregate\ntemporal features. However, existing attention mechanisms may not adequately\ncapture inherent nonlinear dependencies present in time series data, leaving\nroom for improvement. In this study, we propose a novel attention mechanism\nbased on Chatterjee's rank correlation coefficient, which measures nonlinear\ndependencies between variables. Specifically, we replace the matrix\nmultiplication in standard attention mechanisms with this rank coefficient to\nmeasure the query-key relationship. Since computing Chatterjee's correlation\ncoefficient involves sorting and ranking operations, we introduce a\ndifferentiable approximation employing SoftSort and SoftRank. Our proposed\nmechanism, ``XicorAttention,'' integrates it into several state-of-the-art\nTransformer models. Experimental results on real-world datasets demonstrate\nthat incorporating nonlinear correlation into the attention improves\nforecasting accuracy by up to approximately 9.1\\% compared to existing models.", "published": "2025-06-03 09:43:45", "link": "http://arxiv.org/abs/2506.02694v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Self-Disentanglement and Re-Composition for Cross-Domain Few-Shot Segmentation", "abstract": "Cross-Domain Few-Shot Segmentation (CD-FSS) aims to transfer knowledge from a\nsource-domain dataset to unseen target-domain datasets with limited\nannotations. Current methods typically compare the distance between training\nand testing samples for mask prediction. However, we find an entanglement\nproblem exists in this widely adopted method, which tends to bind sourcedomain\npatterns together and make each of them hard to transfer. In this paper, we aim\nto address this problem for the CD-FSS task. We first find a natural\ndecomposition of the ViT structure, based on which we delve into the\nentanglement problem for an interpretation. We find the decomposed ViT\ncomponents are crossly compared between images in distance calculation, where\nthe rational comparisons are entangled with those meaningless ones by their\nequal importance, leading to the entanglement problem. Based on this\ninterpretation, we further propose to address the entanglement problem by\nlearning to weigh for all comparisons of ViT components, which learn\ndisentangled features and re-compose them for the CD-FSS task, benefiting both\nthe generalization and finetuning. Experiments show that our model outperforms\nthe state-of-the-art CD-FSS method by 1.92% and 1.88% in average accuracy under\n1-shot and 5-shot settings, respectively.", "published": "2025-06-03 09:23:20", "link": "http://arxiv.org/abs/2506.02677v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "FAuNO: Semi-Asynchronous Federated Reinforcement Learning Framework for Task Offloading in Edge Systems", "abstract": "Edge computing addresses the growing data demands of connected-device\nnetworks by placing computational resources closer to end users through\ndecentralized infrastructures. This decentralization challenges traditional,\nfully centralized orchestration, which suffers from latency and resource\nbottlenecks. We present \\textbf{FAuNO} -- \\emph{Federated Asynchronous Network\nOrchestrator} -- a buffered, asynchronous \\emph{federated\nreinforcement-learning} (FRL) framework for decentralized task offloading in\nedge systems. FAuNO adopts an actor-critic architecture in which local actors\nlearn node-specific dynamics and peer interactions, while a federated critic\naggregates experience across agents to encourage efficient cooperation and\nimprove overall system performance. Experiments in the \\emph{PeersimGym}\nenvironment show that FAuNO consistently matches or exceeds heuristic and\nfederated multi-agent RL baselines in reducing task loss and latency,\nunderscoring its adaptability to dynamic edge-computing scenarios.", "published": "2025-06-03 09:15:03", "link": "http://arxiv.org/abs/2506.02668v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "A Pretrained Probabilistic Transformer for City-Scale Traffic Volume Prediction", "abstract": "City-scale traffic volume prediction plays a pivotal role in intelligent\ntransportation systems, yet remains a challenge due to the inherent\nincompleteness and bias in observational data. Although deep learning-based\nmethods have shown considerable promise, most existing approaches produce\ndeterministic point estimates, thereby neglecting the uncertainty arising from\nunobserved traffic flows. Furthermore, current models are typically trained in\na city-specific manner, which hinders their generalizability and limits\nscalability across diverse urban contexts. To overcome these limitations, we\nintroduce TrafficPPT, a Pretrained Probabilistic Transformer designed to model\ntraffic volume as a distributional aggregation of trajectories. Our framework\nfuses heterogeneous data sources-including real-time observations, historical\ntrajectory data, and road network topology-enabling robust and\nuncertainty-aware traffic inference. TrafficPPT is initially pretrained on\nlarge-scale simulated data spanning multiple urban scenarios, and later\nfine-tuned on target cities to ensure effective domain adaptation. Experiments\non real-world datasets show that TrafficPPT consistently surpasses\nstate-of-the-art baselines, particularly under conditions of extreme data\nsparsity. Code will be open.", "published": "2025-06-03 09:07:29", "link": "http://arxiv.org/abs/2506.02654v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "From Prompts to Protection: Large Language Model-Enabled In-Context Learning for Smart Public Safety UAV", "abstract": "A public safety Unmanned Aerial Vehicle (UAV) enhances situational awareness\nin emergency response. Its agility and ability to optimize mobility and\nestablish Line-of-Sight (LoS) communication make it increasingly vital for\nmanaging emergencies such as disaster response, search and rescue, and wildfire\nmonitoring. While Deep Reinforcement Learning (DRL) has been applied to\noptimize UAV navigation and control, its high training complexity, low sample\nefficiency, and simulation-to-reality gap limit its practicality in public\nsafety. Recent advances in Large Language Models (LLMs) offer a compelling\nalternative. With strong reasoning and generalization capabilities, LLMs can\nadapt to new tasks through In-Context Learning (ICL), which enables task\nadaptation via natural language prompts and example-based guidance, without\nretraining. Deploying LLMs at the network edge, rather than in the cloud,\nfurther reduces latency and preserves data privacy, thereby making them\nsuitable for real-time, mission-critical public safety UAVs. This paper\nproposes the integration of LLM-enabled ICL with public safety UAV to address\nthe key functions, such as path planning and velocity control, in the context\nof emergency response. We present a case study on data collection scheduling\nwhere the LLM-enabled ICL framework can significantly reduce packet loss\ncompared to conventional approaches, while also mitigating potential\njailbreaking vulnerabilities. Finally, we discuss LLM optimizers and specify\nfuture research directions. The ICL framework enables adaptive, context-aware\ndecision-making for public safety UAV, thus offering a lightweight and\nefficient solution for enhancing UAV autonomy and responsiveness in\nemergencies.", "published": "2025-06-03 09:01:33", "link": "http://arxiv.org/abs/2506.02649v1", "categories": ["cs.AI", "53-01", "C.2"], "primary_category": "cs.AI"}
{"title": "Truly Assessing Fluid Intelligence of Large Language Models through Dynamic Reasoning Evaluation", "abstract": "Recent advances in large language models (LLMs) have demonstrated impressive\nreasoning capacities that mirror human-like thinking. However, whether LLMs\npossess genuine fluid intelligence (i.e., the ability to reason abstractly and\ngeneralize rules in novel situations) remains an open question. Existing\nreasoning benchmarks either focus on domain-specific knowledge (crystallized\nintelligence) or lack interpretability. To address these limitations, we\npropose DRE-Bench, a dynamic reasoning evaluation benchmark grounded in a\nhierarchical cognitive framework. DRE-Bench consists of 36 abstract reasoning\ntasks organized across four cognitive levels, with each task featuring multiple\ndynamic variants that test the same underlying latent rule. This design enables\nfine-grained, interpretable, and reliable assessments of fluid intelligence. We\nevaluate a range of state-of-the-art LLMs, including both general LLMs (GPT-4o,\nClaude 3.7) and reasoning LLMs (o1, DeepSeek-R1, QwQ, Skywork-OR1).\nExperimental results reveal that although most LLMs achieve competent and\nrobust performance in low-level cognition, they struggle with high-level\ncognition and exhibit limited generalization as task complexity grows. Our\nfindings highlight the gap between current LLMs and true human-like fluid\nintelligence and offer a new path for systematically tracking reasoning\nprogress in LLMs.", "published": "2025-06-03 09:01:08", "link": "http://arxiv.org/abs/2506.02648v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "KVCache Cache in the Wild: Characterizing and Optimizing KVCache Cache at a Large Cloud Provider", "abstract": "Serving large language models (LLMs) is important for cloud providers, and\ncaching intermediate results (KV\\$) after processing each request substantially\nimproves serving throughput and latency. However, there is limited\nunderstanding of how LLM serving benefits from KV\\$ caching, where system\ndesign decisions like cache eviction policies are highly workload-dependent. In\nthis paper, we present the first systematic characterization of the KV\\$\nworkload patterns from one of the leading LLM service providers. We draw\nobservations that were not covered by previous studies focusing on synthetic\nworkloads, including: KV\\$ reuses are skewed across requests, where reuses\nbetween single-turn requests are equally important as multi-turn requests; the\nreuse time and probability are diverse considering all requests, but for a\nspecific request category, the pattern tends to be predictable; and the overall\ncache size required for an ideal cache hit ratio is moderate. Based on the\ncharacterization, we further propose a workload-aware cache eviction policy\nthat improves the serving performance under real-world traces, especially with\nlimited cache capacity.", "published": "2025-06-03 08:51:38", "link": "http://arxiv.org/abs/2506.02634v1", "categories": ["cs.DC", "cs.AI"], "primary_category": "cs.DC"}
{"title": "SiamNAS: Siamese Surrogate Model for Dominance Relation Prediction in Multi-objective Neural Architecture Search", "abstract": "Modern neural architecture search (NAS) is inherently multi-objective,\nbalancing trade-offs such as accuracy, parameter count, and computational cost.\nThis complexity makes NAS computationally expensive and nearly impossible to\nsolve without efficient approximations. To address this, we propose a novel\nsurrogate modelling approach that leverages an ensemble of Siamese network\nblocks to predict dominance relationships between candidate architectures.\nLightweight and easy to train, the surrogate achieves 92% accuracy and replaces\nthe crowding distance calculation in the survivor selection strategy with a\nheuristic rule based on model size. Integrated into a framework termed SiamNAS,\nthis design eliminates costly evaluations during the search process.\nExperiments on NAS-Bench-201 demonstrate the framework's ability to identify\nPareto-optimal solutions with significantly reduced computational costs. The\nproposed SiamNAS identified a final non-dominated set containing the best\narchitecture in NAS-Bench-201 for CIFAR-10 and the second-best for ImageNet, in\nterms of test error rate, within 0.01 GPU days. This proof-of-concept study\nhighlights the potential of the proposed Siamese network surrogate model to\ngeneralise to multi-tasking optimisation, enabling simultaneous optimisation\nacross tasks. Additionally, it offers opportunities to extend the approach for\ngenerating Sets of Pareto Sets (SOS), providing diverse Pareto-optimal\nsolutions for heterogeneous task settings.", "published": "2025-06-03 08:39:42", "link": "http://arxiv.org/abs/2506.02623v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "HGOT: Self-supervised Heterogeneous Graph Neural Network with Optimal Transport", "abstract": "Heterogeneous Graph Neural Networks (HGNNs), have demonstrated excellent\ncapabilities in processing heterogeneous information networks. Self-supervised\nlearning on heterogeneous graphs, especially contrastive self-supervised\nstrategy, shows great potential when there are no labels. However, this\napproach requires the use of carefully designed graph augmentation strategies\nand the selection of positive and negative samples. Determining the exact level\nof similarity between sample pairs is non-trivial.To solve this problem, we\npropose a novel self-supervised Heterogeneous graph neural network with Optimal\nTransport (HGOT) method which is designed to facilitate self-supervised\nlearning for heterogeneous graphs without graph augmentation strategies.\nDifferent from traditional contrastive self-supervised learning, HGOT employs\nthe optimal transport mechanism to relieve the laborious sampling process of\npositive and negative samples. Specifically, we design an aggregating view\n(central view) to integrate the semantic information contained in the views\nrepresented by different meta-paths (branch views). Then, we introduce an\noptimal transport plan to identify the transport relationship between the\nsemantics contained in the branch view and the central view. This allows the\noptimal transport plan between graphs to align with the representations,\nforcing the encoder to learn node representations that are more similar to the\ngraph space and of higher quality. Extensive experiments on four real-world\ndatasets demonstrate that our proposed HGOT model can achieve state-of-the-art\nperformance on various downstream tasks. In particular, in the node\nclassification task, HGOT achieves an average of more than 6% improvement in\naccuracy compared with state-of-the-art methods.", "published": "2025-06-03 08:35:29", "link": "http://arxiv.org/abs/2506.02619v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Hierarchical Question-Answering for Driving Scene Understanding Using Vision-Language Models", "abstract": "In this paper, we present a hierarchical question-answering (QA) approach for\nscene understanding in autonomous vehicles, balancing cost-efficiency with\ndetailed visual interpretation. The method fine-tunes a compact vision-language\nmodel (VLM) on a custom dataset specific to the geographical area in which the\nvehicle operates to capture key driving-related visual elements. At the\ninference stage, the hierarchical QA strategy decomposes the scene\nunderstanding task into high-level and detailed sub-questions. Instead of\ngenerating lengthy descriptions, the VLM navigates a structured question tree,\nwhere answering high-level questions (e.g., \"Is it possible for the ego vehicle\nto turn left at the intersection?\") triggers more detailed sub-questions (e.g.,\n\"Is there a vehicle approaching the intersection from the opposite\ndirection?\"). To optimize inference time, questions are dynamically skipped\nbased on previous answers, minimizing computational overhead. The extracted\nanswers are then synthesized using handcrafted templates to ensure coherent,\ncontextually accurate scene descriptions. We evaluate the proposed approach on\nthe custom dataset using GPT reference-free scoring, demonstrating its\ncompetitiveness with state-of-the-art methods like GPT-4o in capturing key\nscene details while achieving significantly lower inference time. Moreover,\nqualitative results from real-time deployment highlight the proposed approach's\ncapacity to capture key driving elements with minimal latency.", "published": "2025-06-03 08:32:43", "link": "http://arxiv.org/abs/2506.02615v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "High Performance Space Debris Tracking in Complex Skylight Backgrounds with a Large-Scale Dataset", "abstract": "With the rapid development of space exploration, space debris has attracted\nmore attention due to its potential extreme threat, leading to the need for\nreal-time and accurate debris tracking. However, existing methods are mainly\nbased on traditional signal processing, which cannot effectively process the\ncomplex background and dense space debris. In this paper, we propose a deep\nlearning-based Space Debris Tracking Network~(SDT-Net) to achieve highly\naccurate debris tracking. SDT-Net effectively represents the feature of debris,\nenhancing the efficiency and stability of end-to-end model learning. To train\nand evaluate this model effectively, we also produce a large-scale dataset\nSpace Debris Tracking Dataset (SDTD) by a novel observation-based data\nsimulation scheme. SDTD contains 18,040 video sequences with a total of 62,562\nframes and covers 250,000 synthetic space debris. Extensive experiments\nvalidate the effectiveness of our model and the challenging of our dataset.\nFurthermore, we test our model on real data from the Antarctic Station,\nachieving a MOTA score of 70.6%, which demonstrates its strong transferability\nto real-world scenarios. Our dataset and code will be released soon.", "published": "2025-06-03 08:30:25", "link": "http://arxiv.org/abs/2506.02614v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Simple, Good, Fast: Self-Supervised World Models Free of Baggage", "abstract": "What are the essential components of world models? How far do we get with\nworld models that are not employing RNNs, transformers, discrete\nrepresentations, and image reconstructions? This paper introduces SGF, a\nSimple, Good, and Fast world model that uses self-supervised representation\nlearning, captures short-time dependencies through frame and action stacking,\nand enhances robustness against model errors through data augmentation. We\nextensively discuss SGF's connections to established world models, evaluate the\nbuilding blocks in ablation studies, and demonstrate good performance through\nquantitative comparisons on the Atari 100k benchmark.", "published": "2025-06-03 08:29:32", "link": "http://arxiv.org/abs/2506.02612v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Speaker Diarization with Overlapping Community Detection Using Graph Attention Networks and Label Propagation Algorithm", "abstract": "In speaker diarization, traditional clustering-based methods remain widely\nused in real-world applications. However, these methods struggle with the\ncomplex distribution of speaker embeddings and overlapping speech segments. To\naddress these limitations, we propose an Overlapping Community Detection method\nbased on Graph Attention networks and the Label Propagation Algorithm\n(OCDGALP). The proposed framework comprises two key components: (1) a graph\nattention network that refines speaker embeddings and node connections by\naggregating information from neighboring nodes, and (2) a label propagation\nalgorithm that assigns multiple community labels to each node, enabling\nsimultaneous clustering and overlapping community detection. Experimental\nresults show that the proposed method significantly reduces the Diarization\nError Rate (DER), achieving a state-of-the-art 15.94% DER on the DIHARD-III\ndataset without oracle Voice Activity Detection (VAD), and an impressive 11.07%\nwith oracle VAD.", "published": "2025-06-03 08:29:10", "link": "http://arxiv.org/abs/2506.02610v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Time-Enhanced Data Disentanglement Network for Traffic Flow Forecasting", "abstract": "In recent years, traffic flow prediction has become a highlight in the field\nof intelligent transportation systems. However, due to the temporal variations\nand dynamic spatial correlations of traffic data, traffic prediction remains\nhighly challenging.Traditional spatiotemporal networks, which rely on\nend-to-end training, often struggle to handle the diverse data dependencies of\nmultiple traffic flow patterns. Additionally, traffic flow variations are\nhighly sensitive to temporal information changes. Regrettably, other\nresearchers have not sufficiently recognized the importance of temporal\ninformation.To address these challenges, we propose a novel approach called A\nTime-Enhanced Data Disentanglement Network for Traffic Flow Forecasting\n(TEDDN). This network disentangles the originally complex and intertwined\ntraffic data into stable patterns and trends. By flexibly learning temporal and\nnode information through a dynamic graph enhanced by a temporal feature\nextraction module, TEDDN demonstrates significant efficacy in disentangling and\nextracting complex traffic information. Experimental evaluations and ablation\nstudies on four real-world datasets validate the superiority of our method.", "published": "2025-06-03 08:28:48", "link": "http://arxiv.org/abs/2506.02609v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Multi Layered Autonomy and AI Ecologies in Robotic Art Installations", "abstract": "Symbiosis of Agents is a large-scale installation by Baoyang Chen that embeds\nAI-driven robots in an immersive, mirror-lined arena, probing the tension\nbetween machine agency and artistic authorship. Drawing on early cybernetics,\nrule-based conceptual art, and seminal robotic works, it orchestrates fluid\nexchanges among robotic arms, quadruped machines, their environment, and the\npublic. A three tier faith system pilots the ecology: micro-level adaptive\ntactics, meso-level narrative drives, and a macro-level prime directive. This\nhierarchy lets behaviors evolve organically in response to environmental cues\nand even a viewer's breath, turning spectators into co-authors of the unfolding\ndrama.Framed by a speculative terraforming scenario that recalls the historical\nexploitation of marginalized labor, the piece asks who bears responsibility in\nAI-mediated futures. Choreographed motion, AI-generated scripts, reactive\nlighting, and drifting fog cast the robots as collaborators rather than tools,\nforging a living, emergent artwork. Exhibited internationally, Symbiosis of\nAgents shows how cybernetic feedback, robotic experimentation, and conceptual\nrule-making can converge to redefine agency, authorship, and ethics in\ncontemporary art.", "published": "2025-06-03 08:28:19", "link": "http://arxiv.org/abs/2506.02606v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "EALG: Evolutionary Adversarial Generation of Language Model-Guided Generators for Combinatorial Optimization", "abstract": "Generating challenging instances is crucial for the evaluation and\nadvancement of combinatorial optimization solvers. In this work, we introduce\nEALG (Evolutionary Adversarial Generation of Language Model-Guided Generators),\na novel framework that automates the co-evolution of optimization problem\ninstances and their corresponding heuristic solvers using large language models\n(LLMs). EALG leverages a mutation-based adversarial approach that dynamically\nevolves instance generation procedures to create increasingly difficult\nproblems, while simultaneously synthesizing adaptive heuristic algorithms\nthrough interactions with LLMs guided by algorithmic structure. Unlike existing\napproaches that focus solely on static benchmark creation or manual solver\ndesign, EALG provides a seamless pipeline from instance generation to solver\nsynthesis. Experimental results demonstrate that EALG generates significantly\nharder instances than current benchmarks, and its synthesized solvers\ngeneralize effectively across a broad spectrum of combinatorial tasks. This\nwork explores a new paradigm for combinatorial optimization that integrates\ninstance generation with solver design, resulting in state-of-the-art\nperformance.", "published": "2025-06-03 08:13:41", "link": "http://arxiv.org/abs/2506.02594v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "V2X-UniPool: Unifying Multimodal Perception and Knowledge Reasoning for Autonomous Driving", "abstract": "Knowledge-driven autonomous driving systems(ADs) offer powerful reasoning\ncapabilities, but face two critical challenges: limited perception due to the\nshort-sightedness of single-vehicle sensors, and hallucination arising from the\nlack of real-time environmental grounding. To address these issues, this paper\nintroduces V2X-UniPool, a unified framework that integrates multimodal\nVehicle-to-Everything (V2X) data into a time-indexed and language-based\nknowledge pool. By leveraging a dual-query Retrieval-Augmented Generation (RAG)\nmechanism, which enables retrieval of both static and dynamic knowledge, our\nsystem enables ADs to perform accurate, temporally consistent reasoning over\nboth static environment and dynamic traffic context. Experiments on a\nreal-world cooperative driving dataset demonstrate that V2X-UniPool\nsignificantly enhances motion planning accuracy and reasoning capability.\nRemarkably, it enables even zero-shot vehicle-side models to achieve\nstate-of-the-art performance by leveraging V2X-UniPool, while simultaneously\nreducing transmission cost by over 99.9\\% compared to prior V2X methods.", "published": "2025-06-03 08:00:57", "link": "http://arxiv.org/abs/2506.02580v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "ADFormer: Aggregation Differential Transformer for Passenger Demand Forecasting", "abstract": "Passenger demand forecasting helps optimize vehicle scheduling, thereby\nimproving urban efficiency. Recently, attention-based methods have been used to\nadequately capture the dynamic nature of spatio-temporal data. However,\nexisting methods that rely on heuristic masking strategies cannot fully adapt\nto the complex spatio-temporal correlations, hindering the model from focusing\non the right context. These works also overlook the high-level correlations\nthat exist in the real world. Effectively integrating these high-level\ncorrelations with the original correlations is crucial. To fill this gap, we\npropose the Aggregation Differential Transformer (ADFormer), which offers new\ninsights to demand forecasting promotion. Specifically, we utilize Differential\nAttention to capture the original spatial correlations and achieve attention\ndenoising. Meanwhile, we design distinct aggregation strategies based on the\nnature of space and time. Then, the original correlations are unified with the\nhigh-level correlations, enabling the model to capture holistic spatio-temporal\nrelations. Experiments conducted on taxi and bike datasets confirm the\neffectiveness and efficiency of our model, demonstrating its practical value.\nThe code is available at https://github.com/decisionintelligence/ADFormer.", "published": "2025-06-03 07:55:51", "link": "http://arxiv.org/abs/2506.02576v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "HATA: Trainable and Hardware-Efficient Hash-Aware Top-k Attention for Scalable Large Model Inference", "abstract": "Large Language Models (LLMs) have emerged as a pivotal research area, yet the\nattention module remains a critical bottleneck in LLM inference, even with\ntechniques like KVCache to mitigate redundant computations. While various\ntop-$k$ attention mechanisms have been proposed to accelerate LLM inference by\nexploiting the inherent sparsity of attention, they often struggled to strike a\nbalance between efficiency and accuracy. In this paper, we introduce HATA\n(Hash-Aware Top-$k$ Attention), a novel approach that systematically integrates\nlow-overhead learning-to-hash techniques into the Top-$k$ attention process.\nDifferent from the existing top-k attention methods which are devoted to\nseeking an absolute estimation of qk score, typically with a great cost, HATA\nmaps queries and keys into binary hash codes, and acquires the relative qk\nscore order with a quite low cost, which is sufficient for realizing top-k\nattention. Extensive experiments demonstrate that HATA achieves up to\n7.2$\\times$ speedup compared to vanilla full attention while maintaining model\naccuracy. In addition, HATA outperforms the state-of-the-art top-$k$ attention\nmethods in both accuracy and efficiency across multiple mainstream LLM models\nand diverse tasks. HATA is open source at https://github.com/gpzlx1/HATA.", "published": "2025-06-03 07:53:32", "link": "http://arxiv.org/abs/2506.02572v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "MLaGA: Multimodal Large Language and Graph Assistant", "abstract": "Large Language Models (LLMs) have demonstrated substantial efficacy in\nadvancing graph-structured data analysis. Prevailing LLM-based graph methods\nexcel in adapting LLMs to text-rich graphs, wherein node attributes are text\ndescriptions. However, their applications to multimodal graphs--where nodes are\nassociated with diverse attribute types, such as texts and images--remain\nunderexplored, despite their ubiquity in real-world scenarios. To bridge the\ngap, we introduce the Multimodal Large Language and Graph Assistant (MLaGA), an\ninnovative model that adeptly extends LLM capabilities to facilitate reasoning\nover complex graph structures and multimodal attributes. We first design a\nstructure-aware multimodal encoder to align textual and visual attributes\nwithin a unified space through a joint graph pre-training objective.\nSubsequently, we implement a multimodal instruction-tuning approach to\nseamlessly integrate multimodal features and graph structures into the LLM\nthrough lightweight projectors. Extensive experiments across multiple datasets\ndemonstrate the effectiveness of MLaGA compared to leading baseline methods,\nachieving superior performance in diverse graph learning tasks under both\nsupervised and transfer learning scenarios.", "published": "2025-06-03 07:52:00", "link": "http://arxiv.org/abs/2506.02568v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Self-Supervised Spatial Correspondence Across Modalities", "abstract": "We present a method for finding cross-modal space-time correspondences. Given\ntwo images from different visual modalities, such as an RGB image and a depth\nmap, our model identifies which pairs of pixels correspond to the same physical\npoints in the scene. To solve this problem, we extend the contrastive random\nwalk framework to simultaneously learn cycle-consistent feature representations\nfor both cross-modal and intra-modal matching. The resulting model is simple\nand has no explicit photo-consistency assumptions. It can be trained entirely\nusing unlabeled data, without the need for any spatially aligned multimodal\nimage pairs. We evaluate our method on both geometric and semantic\ncorrespondence tasks. For geometric matching, we consider challenging tasks\nsuch as RGB-to-depth and RGB-to-thermal matching (and vice versa); for semantic\nmatching, we evaluate on photo-sketch and cross-style image alignment. Our\nmethod achieves strong performance across all benchmarks.", "published": "2025-06-03 17:59:45", "link": "http://arxiv.org/abs/2506.03148v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Context as Memory: Scene-Consistent Interactive Long Video Generation with Memory Retrieval", "abstract": "Recent advances in interactive video generation have shown promising results,\nyet existing approaches struggle with scene-consistent memory capabilities in\nlong video generation due to limited use of historical context. In this work,\nwe propose Context-as-Memory, which utilizes historical context as memory for\nvideo generation. It includes two simple yet effective designs: (1) storing\ncontext in frame format without additional post-processing; (2) conditioning by\nconcatenating context and frames to be predicted along the frame dimension at\nthe input, requiring no external control modules. Furthermore, considering the\nenormous computational overhead of incorporating all historical context, we\npropose the Memory Retrieval module to select truly relevant context frames by\ndetermining FOV (Field of View) overlap between camera poses, which\nsignificantly reduces the number of candidate frames without substantial\ninformation loss. Experiments demonstrate that Context-as-Memory achieves\nsuperior memory capabilities in interactive long video generation compared to\nSOTAs, even generalizing effectively to open-domain scenarios not seen during\ntraining. The link of our project page is https://context-as-memory.github.io/.", "published": "2025-06-03 17:59:05", "link": "http://arxiv.org/abs/2506.03141v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CamCloneMaster: Enabling Reference-based Camera Control for Video Generation", "abstract": "Camera control is crucial for generating expressive and cinematic videos.\nExisting methods rely on explicit sequences of camera parameters as control\nconditions, which can be cumbersome for users to construct, particularly for\nintricate camera movements. To provide a more intuitive camera control method,\nwe propose CamCloneMaster, a framework that enables users to replicate camera\nmovements from reference videos without requiring camera parameters or\ntest-time fine-tuning. CamCloneMaster seamlessly supports reference-based\ncamera control for both Image-to-Video and Video-to-Video tasks within a\nunified framework. Furthermore, we present the Camera Clone Dataset, a\nlarge-scale synthetic dataset designed for camera clone learning, encompassing\ndiverse scenes, subjects, and camera movements. Extensive experiments and user\nstudies demonstrate that CamCloneMaster outperforms existing methods in terms\nof both camera controllability and visual quality.", "published": "2025-06-03 17:59:02", "link": "http://arxiv.org/abs/2506.03140v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Simulate Any Radar: Attribute-Controllable Radar Simulation via Waveform Parameter Embedding", "abstract": "We present SA-Radar (Simulate Any Radar), a radar simulation approach that\nenables controllable and efficient generation of radar cubes conditioned on\ncustomizable radar attributes. Unlike prior generative or physics-based\nsimulators, SA-Radar integrates both paradigms through a waveform-parameterized\nattribute embedding. We design ICFAR-Net, a 3D U-Net conditioned on radar\nattributes encoded via waveform parameters, which captures signal variations\ninduced by different radar configurations. This formulation bypasses the need\nfor detailed radar hardware specifications and allows efficient simulation of\nrange-azimuth-Doppler (RAD) tensors across diverse sensor settings. We further\nconstruct a mixed real-simulated dataset with attribute annotations to robustly\ntrain the network. Extensive evaluations on multiple downstream tasks-including\n2D/3D object detection and radar semantic segmentation-demonstrate that\nSA-Radar's simulated data is both realistic and effective, consistently\nimproving model performance when used standalone or in combination with real\ndata. Our framework also supports simulation in novel sensor viewpoints and\nedited scenes, showcasing its potential as a general-purpose radar data engine\nfor autonomous driving applications. Code and additional materials are\navailable at https://zhuxing0.github.io/projects/SA-Radar.", "published": "2025-06-03 17:58:28", "link": "http://arxiv.org/abs/2506.03134v1", "categories": ["eess.SP", "cs.CV"], "primary_category": "eess.SP"}
{"title": "Native-Resolution Image Synthesis", "abstract": "We introduce native-resolution image synthesis, a novel generative modeling\nparadigm that enables the synthesis of images at arbitrary resolutions and\naspect ratios. This approach overcomes the limitations of conventional\nfixed-resolution, square-image methods by natively handling variable-length\nvisual tokens, a core challenge for traditional techniques. To this end, we\nintroduce the Native-resolution diffusion Transformer (NiT), an architecture\ndesigned to explicitly model varying resolutions and aspect ratios within its\ndenoising process. Free from the constraints of fixed formats, NiT learns\nintrinsic visual distributions from images spanning a broad range of\nresolutions and aspect ratios. Notably, a single NiT model simultaneously\nachieves the state-of-the-art performance on both ImageNet-256x256 and 512x512\nbenchmarks. Surprisingly, akin to the robust zero-shot capabilities seen in\nadvanced large language models, NiT, trained solely on ImageNet, demonstrates\nexcellent zero-shot generalization performance. It successfully generates\nhigh-fidelity images at previously unseen high resolutions (e.g., 1536 x 1536)\nand diverse aspect ratios (e.g., 16:9, 3:1, 4:3), as shown in Figure 1. These\nfindings indicate the significant potential of native-resolution modeling as a\nbridge between visual generative modeling and advanced LLM methodologies.", "published": "2025-06-03 17:57:33", "link": "http://arxiv.org/abs/2506.03131v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "AnimeShooter: A Multi-Shot Animation Dataset for Reference-Guided Video Generation", "abstract": "Recent advances in AI-generated content (AIGC) have significantly accelerated\nanimation production. To produce engaging animations, it is essential to\ngenerate coherent multi-shot video clips with narrative scripts and character\nreferences. However, existing public datasets primarily focus on real-world\nscenarios with global descriptions, and lack reference images for consistent\ncharacter guidance. To bridge this gap, we present AnimeShooter, a\nreference-guided multi-shot animation dataset. AnimeShooter features\ncomprehensive hierarchical annotations and strong visual consistency across\nshots through an automated pipeline. Story-level annotations provide an\noverview of the narrative, including the storyline, key scenes, and main\ncharacter profiles with reference images, while shot-level annotations\ndecompose the story into consecutive shots, each annotated with scene,\ncharacters, and both narrative and descriptive visual captions. Additionally, a\ndedicated subset, AnimeShooter-audio, offers synchronized audio tracks for each\nshot, along with audio descriptions and sound sources. To demonstrate the\neffectiveness of AnimeShooter and establish a baseline for the reference-guided\nmulti-shot video generation task, we introduce AnimeShooterGen, which leverages\nMultimodal Large Language Models (MLLMs) and video diffusion models. The\nreference image and previously generated shots are first processed by MLLM to\nproduce representations aware of both reference and context, which are then\nused as the condition for the diffusion model to decode the subsequent shot.\nExperimental results show that the model trained on AnimeShooter achieves\nsuperior cross-shot visual consistency and adherence to reference visual\nguidance, which highlight the value of our dataset for coherent animated video\ngeneration.", "published": "2025-06-03 17:55:18", "link": "http://arxiv.org/abs/2506.03126v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DCM: Dual-Expert Consistency Model for Efficient and High-Quality Video Generation", "abstract": "Diffusion Models have achieved remarkable results in video synthesis but\nrequire iterative denoising steps, leading to substantial computational\noverhead. Consistency Models have made significant progress in accelerating\ndiffusion models. However, directly applying them to video diffusion models\noften results in severe degradation of temporal consistency and appearance\ndetails. In this paper, by analyzing the training dynamics of Consistency\nModels, we identify a key conflicting learning dynamics during the distillation\nprocess: there is a significant discrepancy in the optimization gradients and\nloss contributions across different timesteps. This discrepancy prevents the\ndistilled student model from achieving an optimal state, leading to compromised\ntemporal consistency and degraded appearance details. To address this issue, we\npropose a parameter-efficient \\textbf{Dual-Expert Consistency Model~(DCM)},\nwhere a semantic expert focuses on learning semantic layout and motion, while a\ndetail expert specializes in fine detail refinement. Furthermore, we introduce\nTemporal Coherence Loss to improve motion consistency for the semantic expert\nand apply GAN and Feature Matching Loss to enhance the synthesis quality of the\ndetail expert.Our approach achieves state-of-the-art visual quality with\nsignificantly reduced sampling steps, demonstrating the effectiveness of expert\nspecialization in video diffusion model distillation. Our code and models are\navailable at\n\\href{https://github.com/Vchitect/DCM}{https://github.com/Vchitect/DCM}.", "published": "2025-06-03 17:55:04", "link": "http://arxiv.org/abs/2506.03123v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HumanRAM: Feed-forward Human Reconstruction and Animation Model using Transformers", "abstract": "3D human reconstruction and animation are long-standing topics in computer\ngraphics and vision. However, existing methods typically rely on sophisticated\ndense-view capture and/or time-consuming per-subject optimization procedures.\nTo address these limitations, we propose HumanRAM, a novel feed-forward\napproach for generalizable human reconstruction and animation from monocular or\nsparse human images. Our approach integrates human reconstruction and animation\ninto a unified framework by introducing explicit pose conditions, parameterized\nby a shared SMPL-X neural texture, into transformer-based large reconstruction\nmodels (LRM). Given monocular or sparse input images with associated camera\nparameters and SMPL-X poses, our model employs scalable transformers and a\nDPT-based decoder to synthesize realistic human renderings under novel\nviewpoints and novel poses. By leveraging the explicit pose conditions, our\nmodel simultaneously enables high-quality human reconstruction and\nhigh-fidelity pose-controlled animation. Experiments show that HumanRAM\nsignificantly surpasses previous methods in terms of reconstruction accuracy,\nanimation fidelity, and generalization performance on real-world datasets.\nVideo results are available at https://zju3dv.github.io/humanram/.", "published": "2025-06-03 17:50:05", "link": "http://arxiv.org/abs/2506.03118v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Controllable Human-centric Keyframe Interpolation with Generative Prior", "abstract": "Existing interpolation methods use pre-trained video diffusion priors to\ngenerate intermediate frames between sparsely sampled keyframes. In the absence\nof 3D geometric guidance, these methods struggle to produce plausible results\nfor complex, articulated human motions and offer limited control over the\nsynthesized dynamics. In this paper, we introduce PoseFuse3D Keyframe\nInterpolator (PoseFuse3D-KI), a novel framework that integrates 3D human\nguidance signals into the diffusion process for Controllable Human-centric\nKeyframe Interpolation (CHKI). To provide rich spatial and structural cues for\ninterpolation, our PoseFuse3D, a 3D-informed control model, features a novel\nSMPL-X encoder that transforms 3D geometry and shape into the 2D latent\nconditioning space, alongside a fusion network that integrates these 3D cues\nwith 2D pose embeddings. For evaluation, we build CHKI-Video, a new dataset\nannotated with both 2D poses and 3D SMPL-X parameters. We show that\nPoseFuse3D-KI consistently outperforms state-of-the-art baselines on\nCHKI-Video, achieving a 9% improvement in PSNR and a 38% reduction in LPIPS.\nComprehensive ablations demonstrate that our PoseFuse3D model improves\ninterpolation fidelity.", "published": "2025-06-03 17:50:05", "link": "http://arxiv.org/abs/2506.03119v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Targeted Forgetting of Image Subgroups in CLIP Models", "abstract": "Foundation models (FMs) such as CLIP have demonstrated impressive zero-shot\nperformance across various tasks by leveraging large-scale, unsupervised\npre-training. However, they often inherit harmful or unwanted knowledge from\nnoisy internet-sourced datasets, compromising their reliability in real-world\napplications. Existing model unlearning methods either rely on access to\npre-trained datasets or focus on coarse-grained unlearning (e.g., entire\nclasses), leaving a critical gap for fine-grained unlearning. In this paper, we\naddress the challenging scenario of selectively forgetting specific portions of\nknowledge within a class, without access to pre-trained data, while preserving\nthe model's overall performance. We propose a novel three-stage approach that\nprogressively unlearns targeted knowledge while mitigating over-forgetting. It\nconsists of (1) a forgetting stage to fine-tune the CLIP on samples to be\nforgotten, (2) a reminding stage to restore performance on retained samples,\nand (3) a restoring stage to recover zero-shot capabilities using model\nsouping. Additionally, we introduce knowledge distillation to handle the\ndistribution disparity between forgetting, retaining samples, and unseen\npre-trained data. Extensive experiments on CIFAR-10, ImageNet-1K, and style\ndatasets demonstrate that our approach effectively unlearns specific subgroups\nwhile maintaining strong zero-shot performance on semantically similar\nsubgroups and other categories, significantly outperforming baseline unlearning\nmethods, which lose effectiveness under the CLIP unlearning setting.", "published": "2025-06-03 17:50:03", "link": "http://arxiv.org/abs/2506.03117v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Zero-Shot Tree Detection and Segmentation from Aerial Forest Imagery", "abstract": "Large-scale delineation of individual trees from remote sensing imagery is\ncrucial to the advancement of ecological research, particularly as climate\nchange and other environmental factors rapidly transform forest landscapes\nacross the world. Current RGB tree segmentation methods rely on training\nspecialized machine learning models with labeled tree datasets. While these\nlearning-based approaches can outperform manual data collection when accurate,\nthe existing models still depend on training data that's hard to scale. In this\npaper, we investigate the efficacy of using a state-of-the-art image\nsegmentation model, Segment Anything Model 2 (SAM2), in a zero-shot manner for\nindividual tree detection and segmentation. We evaluate a pretrained SAM2 model\non two tasks in this domain: (1) zero-shot segmentation and (2) zero-shot\ntransfer by using predictions from an existing tree detection model as prompts.\nOur results suggest that SAM2 not only has impressive generalization\ncapabilities, but also can form a natural synergy with specialized methods\ntrained on in-domain labeled data. We find that applying large pretrained\nmodels to problems in remote sensing is a promising avenue for future progress.\nWe make our code available at:\nhttps://github.com/open-forest-observatory/tree-detection-framework.", "published": "2025-06-03 17:44:43", "link": "http://arxiv.org/abs/2506.03114v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Revisiting Continuity of Image Tokens for Cross-domain Few-shot Learning", "abstract": "Vision Transformer (ViT) has achieved remarkable success due to its\nlarge-scale pretraining on general domains, but it still faces challenges when\napplying it to downstream distant domains that have only scarce training data,\nwhich gives rise to the Cross-Domain Few-Shot Learning (CDFSL) task. Inspired\nby Self-Attention's insensitivity to token orders, we find an interesting\nphenomenon neglected in current works: disrupting the continuity of image\ntokens (i.e., making pixels not smoothly transited across patches) in ViT leads\nto a noticeable performance decline in the general (source) domain but only a\nmarginal decrease in downstream target domains. This questions the role of\nimage tokens' continuity in ViT's generalization under large domain gaps. In\nthis paper, we delve into this phenomenon for an interpretation. We find\ncontinuity aids ViT in learning larger spatial patterns, which are harder to\ntransfer than smaller ones, enlarging domain distances. Meanwhile, it implies\nthat only smaller patterns within each patch could be transferred under extreme\ndomain gaps. Based on this interpretation, we further propose a simple yet\neffective method for CDFSL that better disrupts the continuity of image tokens,\nencouraging the model to rely less on large patterns and more on smaller ones.\nExtensive experiments show the effectiveness of our method in reducing domain\ngaps and outperforming state-of-the-art works. Codes and models are available\nat https://github.com/shuaiyi308/ReCIT.", "published": "2025-06-03 17:40:36", "link": "http://arxiv.org/abs/2506.03110v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ByteMorph: Benchmarking Instruction-Guided Image Editing with Non-Rigid Motions", "abstract": "Editing images with instructions to reflect non-rigid motions, camera\nviewpoint shifts, object deformations, human articulations, and complex\ninteractions, poses a challenging yet underexplored problem in computer vision.\nExisting approaches and datasets predominantly focus on static scenes or rigid\ntransformations, limiting their capacity to handle expressive edits involving\ndynamic motion. To address this gap, we introduce ByteMorph, a comprehensive\nframework for instruction-based image editing with an emphasis on non-rigid\nmotions. ByteMorph comprises a large-scale dataset, ByteMorph-6M, and a strong\nbaseline model built upon the Diffusion Transformer (DiT), named ByteMorpher.\nByteMorph-6M includes over 6 million high-resolution image editing pairs for\ntraining, along with a carefully curated evaluation benchmark ByteMorph-Bench.\nBoth capture a wide variety of non-rigid motion types across diverse\nenvironments, human figures, and object categories. The dataset is constructed\nusing motion-guided data generation, layered compositing techniques, and\nautomated captioning to ensure diversity, realism, and semantic coherence. We\nfurther conduct a comprehensive evaluation of recent instruction-based image\nediting methods from both academic and commercial domains.", "published": "2025-06-03 17:39:47", "link": "http://arxiv.org/abs/2506.03107v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DyTact: Capturing Dynamic Contacts in Hand-Object Manipulation", "abstract": "Reconstructing dynamic hand-object contacts is essential for realistic\nmanipulation in AI character animation, XR, and robotics, yet it remains\nchallenging due to heavy occlusions, complex surface details, and limitations\nin existing capture techniques. In this paper, we introduce DyTact, a\nmarkerless capture method for accurately capturing dynamic contact in\nhand-object manipulations in a non-intrusive manner. Our approach leverages a\ndynamic, articulated representation based on 2D Gaussian surfels to model\ncomplex manipulations. By binding these surfels to MANO meshes, DyTact\nharnesses the inductive bias of template models to stabilize and accelerate\noptimization. A refinement module addresses time-dependent high-frequency\ndeformations, while a contact-guided adaptive sampling strategy selectively\nincreases surfel density in contact regions to handle heavy occlusion.\nExtensive experiments demonstrate that DyTact not only achieves\nstate-of-the-art dynamic contact estimation accuracy but also significantly\nimproves novel view synthesis quality, all while operating with fast\noptimization and efficient memory usage. Project Page:\nhttps://oliver-cong02.github.io/DyTact.github.io/ .", "published": "2025-06-03 17:36:32", "link": "http://arxiv.org/abs/2506.03103v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FuseLIP: Multimodal Embeddings via Early Fusion of Discrete Tokens", "abstract": "Contrastive language-image pre-training aligns the features of text-image\npairs in a common latent space via distinct encoders for each modality. While\nthis approach achieves impressive performance in several zero-shot tasks, it\ncannot natively handle multimodal inputs, i.e., encoding image and text into a\nsingle feature vector. As a remedy, it is common practice to use additional\nmodules to merge the features extracted by the unimodal encoders. In this work,\nwe present FuseLIP, an alternative architecture for multimodal embedding.\nLeveraging recent progress in discrete image tokenizers, we propose to use a\nsingle transformer model which operates on an extended vocabulary of text and\nimage tokens. This early fusion approach allows the different modalities to\ninteract at each depth of encoding and obtain richer representations compared\nto common late fusion. We collect new datasets for multimodal pre-training and\nevaluation, designing challenging tasks for multimodal encoder models. We show\nthat FuseLIP outperforms other approaches in multimodal embedding tasks such as\nVQA and text-guided image transformation retrieval, while being comparable to\nbaselines on unimodal tasks.", "published": "2025-06-03 17:27:12", "link": "http://arxiv.org/abs/2506.03096v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Explicitly Modeling Subcortical Vision with a Neuro-Inspired Front-End Improves CNN Robustness", "abstract": "Convolutional neural networks (CNNs) trained on object recognition achieve\nhigh task performance but continue to exhibit vulnerability under a range of\nvisual perturbations and out-of-domain images, when compared with biological\nvision. Prior work has demonstrated that coupling a standard CNN with a\nfront-end block (VOneBlock) that mimics the primate primary visual cortex (V1)\ncan improve overall model robustness. Expanding on this, we introduce Early\nVision Networks (EVNets), a new class of hybrid CNNs that combine the VOneBlock\nwith a novel SubcorticalBlock, whose architecture draws from computational\nmodels in neuroscience and is parameterized to maximize alignment with\nsubcortical responses reported across multiple experimental studies. Without\nbeing optimized to do so, the assembly of the SubcorticalBlock with the\nVOneBlock improved V1 alignment across most standard V1 benchmarks, and better\nmodeled extra-classical receptive field phenomena. In addition, EVNets exhibit\nstronger emergent shape bias and overperform the base CNN architecture by 8.5%\non an aggregate benchmark of robustness evaluations, including adversarial\nperturbations, common corruptions, and domain shifts. Finally, we show that\nEVNets can be further improved when paired with a state-of-the-art data\naugmentation technique, surpassing the performance of the isolated data\naugmentation approach by 7.3% on our robustness benchmark. This result reveals\ncomplementary benefits between changes in architecture to better mimic biology\nand training-based machine learning approaches.", "published": "2025-06-03 17:13:51", "link": "http://arxiv.org/abs/2506.03089v1", "categories": ["cs.CV", "q-bio.NC"], "primary_category": "cs.CV"}
{"title": "InterMamba: Efficient Human-Human Interaction Generation with Adaptive Spatio-Temporal Mamba", "abstract": "Human-human interaction generation has garnered significant attention in\nmotion synthesis due to its vital role in understanding humans as social\nbeings. However, existing methods typically rely on transformer-based\narchitectures, which often face challenges related to scalability and\nefficiency. To address these issues, we propose a novel, efficient human-human\ninteraction generation method based on the Mamba framework, designed to meet\nthe demands of effectively capturing long-sequence dependencies while providing\nreal-time feedback. Specifically, we introduce an adaptive spatio-temporal\nMamba framework that utilizes two parallel SSM branches with an adaptive\nmechanism to integrate the spatial and temporal features of motion sequences.\nTo further enhance the model's ability to capture dependencies within\nindividual motion sequences and the interactions between different individual\nsequences, we develop two key modules: the self-adaptive spatio-temporal Mamba\nmodule and the cross-adaptive spatio-temporal Mamba module, enabling efficient\nfeature learning. Extensive experiments demonstrate that our method achieves\nstate-of-the-art results on two interaction datasets with remarkable quality\nand efficiency. Compared to the baseline method InterGen, our approach not only\nimproves accuracy but also requires a minimal parameter size of just 66M ,only\n36% of InterGen's, while achieving an average inference speed of 0.57 seconds,\nwhich is 46% of InterGen's execution time.", "published": "2025-06-03 17:05:06", "link": "http://arxiv.org/abs/2506.03084v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SG2VID: Scene Graphs Enable Fine-Grained Control for Video Synthesis", "abstract": "Surgical simulation plays a pivotal role in training novice surgeons,\naccelerating their learning curve and reducing intra-operative errors. However,\nconventional simulation tools fall short in providing the necessary\nphotorealism and the variability of human anatomy. In response, current methods\nare shifting towards generative model-based simulators. Yet, these approaches\nprimarily focus on using increasingly complex conditioning for precise\nsynthesis while neglecting the fine-grained human control aspect. To address\nthis gap, we introduce SG2VID, the first diffusion-based video model that\nleverages Scene Graphs for both precise video synthesis and fine-grained human\ncontrol. We demonstrate SG2VID's capabilities across three public datasets\nfeaturing cataract and cholecystectomy surgery. While SG2VID outperforms\nprevious methods both qualitatively and quantitatively, it also enables precise\nsynthesis, providing accurate control over tool and anatomy's size and\nmovement, entrance of new tools, as well as the overall scene layout. We\nqualitatively motivate how SG2VID can be used for generative augmentation and\npresent an experiment demonstrating its ability to improve a downstream phase\ndetection task when the training set is extended with our synthetic videos.\nFinally, to showcase SG2VID's ability to retain human control, we interact with\nthe Scene Graphs to generate new video samples depicting major yet rare\nintra-operative irregularities.", "published": "2025-06-03 17:02:38", "link": "http://arxiv.org/abs/2506.03082v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ORV: 4D Occupancy-centric Robot Video Generation", "abstract": "Acquiring real-world robotic simulation data through teleoperation is\nnotoriously time-consuming and labor-intensive. Recently, action-driven\ngenerative models have gained widespread adoption in robot learning and\nsimulation, as they eliminate safety concerns and reduce maintenance efforts.\nHowever, the action sequences used in these methods often result in limited\ncontrol precision and poor generalization due to their globally coarse\nalignment. To address these limitations, we propose ORV, an Occupancy-centric\nRobot Video generation framework, which utilizes 4D semantic occupancy\nsequences as a fine-grained representation to provide more accurate semantic\nand geometric guidance for video generation. By leveraging occupancy-based\nrepresentations, ORV enables seamless translation of simulation data into\nphotorealistic robot videos, while ensuring high temporal consistency and\nprecise controllability. Furthermore, our framework supports the simultaneous\ngeneration of multi-view videos of robot gripping operations - an important\ncapability for downstream robotic learning tasks. Extensive experimental\nresults demonstrate that ORV consistently outperforms existing baseline methods\nacross various datasets and sub-tasks. Demo, Code and Model:\nhttps://orangesodahub.github.io/ORV", "published": "2025-06-03 17:00:32", "link": "http://arxiv.org/abs/2506.03079v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LEG-SLAM: Real-Time Language-Enhanced Gaussian Splatting for SLAM", "abstract": "Modern Gaussian Splatting methods have proven highly effective for real-time\nphotorealistic rendering of 3D scenes. However, integrating semantic\ninformation into this representation remains a significant challenge,\nespecially in maintaining real-time performance for SLAM (Simultaneous\nLocalization and Mapping) applications. In this work, we introduce LEG-SLAM --\na novel approach that fuses an optimized Gaussian Splatting implementation with\nvisual-language feature extraction using DINOv2 followed by a learnable feature\ncompressor based on Principal Component Analysis, while enabling an online\ndense SLAM. Our method simultaneously generates high-quality photorealistic\nimages and semantically labeled scene maps, achieving real-time scene\nreconstruction with more than 10 fps on the Replica dataset and 18 fps on\nScanNet. Experimental results show that our approach significantly outperforms\nstate-of-the-art methods in reconstruction speed while achieving competitive\nrendering quality. The proposed system eliminates the need for prior data\npreparation such as camera's ego motion or pre-computed static semantic maps.\nWith its potential applications in autonomous robotics, augmented reality, and\nother interactive domains, LEG-SLAM represents a significant step forward in\nreal-time semantic 3D Gaussian-based SLAM. Project page:\nhttps://titrom025.github.io/LEG-SLAM/", "published": "2025-06-03 16:51:59", "link": "http://arxiv.org/abs/2506.03073v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "EDITOR: Effective and Interpretable Prompt Inversion for Text-to-Image Diffusion Models", "abstract": "Text-to-image generation models~(e.g., Stable Diffusion) have achieved\nsignificant advancements, enabling the creation of high-quality and realistic\nimages based on textual descriptions. Prompt inversion, the task of identifying\nthe textual prompt used to generate a specific artifact, holds significant\npotential for applications including data attribution, model provenance, and\nwatermarking validation. Recent studies introduced a delayed projection scheme\nto optimize for prompts representative of the vocabulary space, though\nchallenges in semantic fluency and efficiency remain. Advanced image captioning\nmodels or visual large language models can generate highly interpretable\nprompts, but they often lack in image similarity. In this paper, we propose a\nprompt inversion technique called \\sys for text-to-image diffusion models,\nwhich includes initializing embeddings using a pre-trained image captioning\nmodel, refining them through reverse-engineering in the latent space, and\nconverting them to texts using an embedding-to-text model. Our experiments on\nthe widely-used datasets, such as MS COCO, LAION, and Flickr, show that our\nmethod outperforms existing methods in terms of image similarity, textual\nalignment, prompt interpretability and generalizability. We further illustrate\nthe application of our generated prompts in tasks such as cross-concept image\nsynthesis, concept manipulation, evolutionary multi-concept generation and\nunsupervised segmentation.", "published": "2025-06-03 16:44:15", "link": "http://arxiv.org/abs/2506.03067v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DFBench: Benchmarking Deepfake Image Detection Capability of Large Multimodal Models", "abstract": "With the rapid advancement of generative models, the realism of AI-generated\nimages has significantly improved, posing critical challenges for verifying\ndigital content authenticity. Current deepfake detection methods often depend\non datasets with limited generation models and content diversity that fail to\nkeep pace with the evolving complexity and increasing realism of the\nAI-generated content. Large multimodal models (LMMs), widely adopted in various\nvision tasks, have demonstrated strong zero-shot capabilities, yet their\npotential in deepfake detection remains largely unexplored. To bridge this gap,\nwe present \\textbf{DFBench}, a large-scale DeepFake Benchmark featuring (i)\nbroad diversity, including 540,000 images across real, AI-edited, and\nAI-generated content, (ii) latest model, the fake images are generated by 12\nstate-of-the-art generation models, and (iii) bidirectional benchmarking and\nevaluating for both the detection accuracy of deepfake detectors and the\nevasion capability of generative models. Based on DFBench, we propose\n\\textbf{MoA-DF}, Mixture of Agents for DeepFake detection, leveraging a\ncombined probability strategy from multiple LMMs. MoA-DF achieves\nstate-of-the-art performance, further proving the effectiveness of leveraging\nLMMs for deepfake detection. Database and codes are publicly available at\nhttps://github.com/IntMeGroup/DFBench.", "published": "2025-06-03 15:45:41", "link": "http://arxiv.org/abs/2506.03007v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PartComposer: Learning and Composing Part-Level Concepts from Single-Image Examples", "abstract": "We present PartComposer: a framework for part-level concept learning from\nsingle-image examples that enables text-to-image diffusion models to compose\nnovel objects from meaningful components. Existing methods either struggle with\neffectively learning fine-grained concepts or require a large dataset as input.\nWe propose a dynamic data synthesis pipeline generating diverse part\ncompositions to address one-shot data scarcity. Most importantly, we propose to\nmaximize the mutual information between denoised latents and structured concept\ncodes via a concept predictor, enabling direct regulation on concept\ndisentanglement and re-composition supervision. Our method achieves strong\ndisentanglement and controllable composition, outperforming subject and\npart-level baselines when mixing concepts from the same, or different, object\ncategories.", "published": "2025-06-03 15:43:28", "link": "http://arxiv.org/abs/2506.03004v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Astrophotography turbulence mitigation via generative models", "abstract": "Photography is the cornerstone of modern astronomical and space research.\nHowever, most astronomical images captured by ground-based telescopes suffer\nfrom atmospheric turbulence, resulting in degraded imaging quality. While\nmulti-frame strategies like lucky imaging can mitigate some effects, they\ninvolve intensive data acquisition and complex manual processing. In this\npaper, we propose AstroDiff, a generative restoration method that leverages\nboth the high-quality generative priors and restoration capabilities of\ndiffusion models to mitigate atmospheric turbulence. Extensive experiments\ndemonstrate that AstroDiff outperforms existing state-of-the-art learning-based\nmethods in astronomical image turbulence mitigation, providing higher\nperceptual quality and better structural fidelity under severe turbulence\nconditions. Our code and additional results are available at\nhttps://web-six-kappa-66.vercel.app/", "published": "2025-06-03 15:18:48", "link": "http://arxiv.org/abs/2506.02981v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "FORLA:Federated Object-centric Representation Learning with Slot Attention", "abstract": "Learning efficient visual representations across heterogeneous unlabeled\ndatasets remains a central challenge in federated learning. Effective federated\nrepresentations require features that are jointly informative across clients\nwhile disentangling domain-specific factors without supervision. We introduce\nFORLA, a novel framework for federated object-centric representation learning\nand feature adaptation across clients using unsupervised slot attention. At the\ncore of our method is a shared feature adapter, trained collaboratively across\nclients to adapt features from foundation models, and a shared slot attention\nmodule that learns to reconstruct the adapted features. To optimize this\nadapter, we design a two-branch student-teacher architecture. In each client, a\nstudent decoder learns to reconstruct full features from foundation models,\nwhile a teacher decoder reconstructs their adapted, low-dimensional\ncounterpart. The shared slot attention module bridges cross-domain learning by\naligning object-level representations across clients. Experiments in multiple\nreal-world datasets show that our framework not only outperforms centralized\nbaselines on object discovery but also learns a compact, universal\nrepresentation that generalizes well across domains. This work highlights\nfederated slot attention as an effective tool for scalable, unsupervised visual\nrepresentation learning from cross-domain data with distributed concepts.", "published": "2025-06-03 14:59:22", "link": "http://arxiv.org/abs/2506.02964v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "MIND: Material Interface Generation from UDFs for Non-Manifold Surface Reconstruction", "abstract": "Unsigned distance fields (UDFs) are widely used in 3D deep learning due to\ntheir ability to represent shapes with arbitrary topology. While prior work has\nlargely focused on learning UDFs from point clouds or multi-view images,\nextracting meshes from UDFs remains challenging, as the learned fields rarely\nattain exact zero distances. A common workaround is to reconstruct signed\ndistance fields (SDFs) locally from UDFs to enable surface extraction via\nMarching Cubes. However, this often introduces topological artifacts such as\nholes or spurious components. Moreover, local SDFs are inherently incapable of\nrepresenting non-manifold geometry, leading to complete failure in such cases.\nTo address this gap, we propose MIND (Material Interface from Non-manifold\nDistance fields), a novel algorithm for generating material interfaces directly\nfrom UDFs, enabling non-manifold mesh extraction from a global perspective. The\ncore of our method lies in deriving a meaningful spatial partitioning from the\nUDF, where the target surface emerges as the interface between distinct\nregions. We begin by computing a two-signed local field to distinguish the two\nsides of manifold patches, and then extend this to a multi-labeled global field\ncapable of separating all sides of a non-manifold structure. By combining this\nmulti-labeled field with the input UDF, we construct material interfaces that\nsupport non-manifold mesh extraction via a multi-labeled Marching Cubes\nalgorithm. Extensive experiments on UDFs generated from diverse data sources,\nincluding point cloud reconstruction, multi-view reconstruction, and medial\naxis transforms, demonstrate that our approach robustly handles complex\nnon-manifold surfaces and significantly outperforms existing methods.", "published": "2025-06-03 14:37:11", "link": "http://arxiv.org/abs/2506.02938v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Auto-Annotation from Annotation Guidelines: A Benchmark through 3D LiDAR Detection", "abstract": "A crucial yet under-appreciated prerequisite in machine learning solutions\nfor real-applications is data annotation: human annotators are hired to\nmanually label data according to detailed, expert-crafted guidelines. This is\noften a laborious, tedious, and costly process. To study methods for\nfacilitating data annotation, we introduce a new benchmark AnnoGuide:\nAuto-Annotation from Annotation Guidelines. It aims to evaluate automated\nmethods for data annotation directly from expert-defined annotation guidelines,\neliminating the need for manual labeling. As a case study, we repurpose the\nwell-established nuScenes dataset, commonly used in autonomous driving\nresearch, which provides comprehensive annotation guidelines for labeling LiDAR\npoint clouds with 3D cuboids across 18 object classes. These guidelines include\na few visual examples and textual descriptions, but no labeled 3D cuboids in\nLiDAR data, making this a novel task of multi-modal few-shot 3D detection\nwithout 3D annotations. The advances of powerful foundation models (FMs) make\nAnnoGuide especially timely, as FMs offer promising tools to tackle its\nchallenges. We employ a conceptually straightforward pipeline that (1) utilizes\nopen-source FMs for object detection and segmentation in RGB images, (2)\nprojects 2D detections into 3D using known camera poses, and (3) clusters LiDAR\npoints within the frustum of each 2D detection to generate a 3D cuboid.\nStarting with a non-learned solution that leverages off-the-shelf FMs, we\nprogressively refine key components and achieve significant performance\nimprovements, boosting 3D detection mAP from 12.1 to 21.9! Nevertheless, our\nresults highlight that AnnoGuide remains an open and challenging problem,\nunderscoring the urgent need for developing LiDAR-based FMs. We release our\ncode and models at GitHub: https://annoguide.github.io/annoguide3Dbenchmark", "published": "2025-06-03 14:17:37", "link": "http://arxiv.org/abs/2506.02914v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FlySearch: Exploring how vision-language models explore", "abstract": "The real world is messy and unstructured. Uncovering critical information\noften requires active, goal-driven exploration. It remains to be seen whether\nVision-Language Models (VLMs), which recently emerged as a popular zero-shot\ntool in many difficult tasks, can operate effectively in such conditions. In\nthis paper, we answer this question by introducing FlySearch, a 3D, outdoor,\nphotorealistic environment for searching and navigating to objects in complex\nscenes. We define three sets of scenarios with varying difficulty and observe\nthat state-of-the-art VLMs cannot reliably solve even the simplest exploration\ntasks, with the gap to human performance increasing as the tasks get harder. We\nidentify a set of central causes, ranging from vision hallucination, through\ncontext misunderstanding, to task planning failures, and we show that some of\nthem can be addressed by finetuning. We publicly release the benchmark,\nscenarios, and the underlying codebase.", "published": "2025-06-03 14:03:42", "link": "http://arxiv.org/abs/2506.02896v1", "categories": ["cs.CV", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "VolTex: Food Volume Estimation using Text-Guided Segmentation and Neural Surface Reconstruction", "abstract": "Accurate food volume estimation is crucial for dietary monitoring, medical\nnutrition management, and food intake analysis. Existing 3D Food Volume\nestimation methods accurately compute the food volume but lack for food\nportions selection. We present VolTex, a framework that improves \\change{the\nfood object selection} in food volume estimation. Allowing users to specify a\ntarget food item via text input to be segmented, our method enables the precise\nselection of specific food objects in real-world scenes. The segmented object\nis then reconstructed using the Neural Surface Reconstruction method to\ngenerate high-fidelity 3D meshes for volume computation. Extensive evaluations\non the MetaFood3D dataset demonstrate the effectiveness of our approach in\nisolating and reconstructing food items for accurate volume estimation. The\nsource code is accessible at https://github.com/GCVCG/VolTex.", "published": "2025-06-03 14:03:28", "link": "http://arxiv.org/abs/2506.02895v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Dense Match Summarization for Faster Two-view Estimation", "abstract": "In this paper, we speed up robust two-view relative pose from dense\ncorrespondences. Previous work has shown that dense matchers can significantly\nimprove both accuracy and robustness in the resulting pose. However, the large\nnumber of matches comes with a significantly increased runtime during robust\nestimation in RANSAC. To avoid this, we propose an efficient match\nsummarization scheme which provides comparable accuracy to using the full set\nof dense matches, while having 10-100x faster runtime. We validate our approach\non standard benchmark datasets together with multiple state-of-the-art dense\nmatchers.", "published": "2025-06-03 14:01:12", "link": "http://arxiv.org/abs/2506.02893v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "OpenFace 3.0: A Lightweight Multitask System for Comprehensive Facial Behavior Analysis", "abstract": "In recent years, there has been increasing interest in automatic facial\nbehavior analysis systems from computing communities such as vision, multimodal\ninteraction, robotics, and affective computing. Building upon the widespread\nutility of prior open-source facial analysis systems, we introduce OpenFace\n3.0, an open-source toolkit capable of facial landmark detection, facial action\nunit detection, eye-gaze estimation, and facial emotion recognition. OpenFace\n3.0 contributes a lightweight unified model for facial analysis, trained with a\nmulti-task architecture across diverse populations, head poses, lighting\nconditions, video resolutions, and facial analysis tasks. By leveraging the\nbenefits of parameter sharing through a unified model and training paradigm,\nOpenFace 3.0 exhibits improvements in prediction performance, inference speed,\nand memory efficiency over similar toolkits and rivals state-of-the-art models.\nOpenFace 3.0 can be installed and run with a single line of code and operate in\nreal-time without specialized hardware. OpenFace 3.0 code for training models\nand running the system is freely available for research purposes and supports\ncontributions from the community.", "published": "2025-06-03 13:56:10", "link": "http://arxiv.org/abs/2506.02891v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GaRA-SAM: Robustifying Segment Anything Model with Gated-Rank Adaptation", "abstract": "Improving robustness of the Segment Anything Model (SAM) to input\ndegradations is critical for its deployment in high-stakes applications such as\nautonomous driving and robotics. Our approach to this challenge prioritizes\nthree key aspects: first, parameter efficiency to maintain the inherent\ngeneralization capability of SAM; second, fine-grained and input-aware\nrobustification to precisely address the input corruption; and third, adherence\nto standard training protocols for ease of training. To this end, we propose\ngated-rank adaptation (GaRA). GaRA introduces lightweight adapters into\nintermediate layers of the frozen SAM, where each adapter dynamically adjusts\nthe effective rank of its weight matrix based on the input by selectively\nactivating (rank-1) components of the matrix using a learned gating module.\nThis adjustment enables fine-grained and input-aware robustification without\ncompromising the generalization capability of SAM. Our model, GaRA-SAM,\nsignificantly outperforms prior work on all robust segmentation benchmarks. In\nparticular, it surpasses the previous best IoU score by up to 21.3\\%p on ACDC,\na challenging real corrupted image dataset.", "published": "2025-06-03 13:47:59", "link": "http://arxiv.org/abs/2506.02882v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "NTIRE 2025 XGC Quality Assessment Challenge: Methods and Results", "abstract": "This paper reports on the NTIRE 2025 XGC Quality Assessment Challenge, which\nwill be held in conjunction with the New Trends in Image Restoration and\nEnhancement Workshop (NTIRE) at CVPR 2025. This challenge is to address a major\nchallenge in the field of video and talking head processing. The challenge is\ndivided into three tracks, including user generated video, AI generated video\nand talking head. The user-generated video track uses the FineVD-GC, which\ncontains 6,284 user generated videos. The user-generated video track has a\ntotal of 125 registered participants. A total of 242 submissions are received\nin the development phase, and 136 submissions are received in the test phase.\nFinally, 5 participating teams submitted their models and fact sheets. The AI\ngenerated video track uses the Q-Eval-Video, which contains 34,029 AI-Generated\nVideos (AIGVs) generated by 11 popular Text-to-Video (T2V) models. A total of\n133 participants have registered in this track. A total of 396 submissions are\nreceived in the development phase, and 226 submissions are received in the test\nphase. Finally, 6 participating teams submitted their models and fact sheets.\nThe talking head track uses the THQA-NTIRE, which contains 12,247 2D and 3D\ntalking heads. A total of 89 participants have registered in this track. A\ntotal of 225 submissions are received in the development phase, and 118\nsubmissions are received in the test phase. Finally, 8 participating teams\nsubmitted their models and fact sheets. Each participating team in every track\nhas proposed a method that outperforms the baseline, which has contributed to\nthe development of fields in three tracks.", "published": "2025-06-03 13:39:57", "link": "http://arxiv.org/abs/2506.02875v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Pan-Arctic Permafrost Landform and Human-built Infrastructure Feature Detection with Vision Transformers and Location Embeddings", "abstract": "Accurate mapping of permafrost landforms, thaw disturbances, and human-built\ninfrastructure at pan-Arctic scale using sub-meter satellite imagery is\nincreasingly critical. Handling petabyte-scale image data requires\nhigh-performance computing and robust feature detection models. While\nconvolutional neural network (CNN)-based deep learning approaches are widely\nused for remote sensing (RS),similar to the success in transformer based large\nlanguage models, Vision Transformers (ViTs) offer advantages in capturing\nlong-range dependencies and global context via attention mechanisms. ViTs\nsupport pretraining via self-supervised learning-addressing the common\nlimitation of labeled data in Arctic feature detection and outperform CNNs on\nbenchmark datasets. Arctic also poses challenges for model generalization,\nespecially when features with the same semantic class exhibit diverse spectral\ncharacteristics. To address these issues for Arctic feature detection, we\nintegrate geospatial location embeddings into ViTs to improve adaptation across\nregions. This work investigates: (1) the suitability of pre-trained ViTs as\nfeature extractors for high-resolution Arctic remote sensing tasks, and (2) the\nbenefit of combining image and location embeddings. Using previously published\ndatasets for Arctic feature detection, we evaluate our models on three\ntasks-detecting ice-wedge polygons (IWP), retrogressive thaw slumps (RTS), and\nhuman-built infrastructure. We empirically explore multiple configurations to\nfuse image embeddings and location embeddings. Results show that ViTs with\nlocation embeddings outperform prior CNN-based models on two of the three tasks\nincluding F1 score increase from 0.84 to 0.92 for RTS detection, demonstrating\nthe potential of transformer-based models with spatial awareness for Arctic RS\napplications.", "published": "2025-06-03 13:34:01", "link": "http://arxiv.org/abs/2506.02868v1", "categories": ["cs.CV", "I.4.6; I.5.4; I.5.2; I.2.10"], "primary_category": "cs.CV"}
{"title": "MVTD: A Benchmark Dataset for Maritime Visual Object Tracking", "abstract": "Visual Object Tracking (VOT) is a fundamental task with widespread\napplications in autonomous navigation, surveillance, and maritime robotics.\nDespite significant advances in generic object tracking, maritime environments\ncontinue to present unique challenges, including specular water reflections,\nlow-contrast targets, dynamically changing backgrounds, and frequent\nocclusions. These complexities significantly degrade the performance of\nstate-of-the-art tracking algorithms, highlighting the need for domain-specific\ndatasets. To address this gap, we introduce the Maritime Visual Tracking\nDataset (MVTD), a comprehensive and publicly available benchmark specifically\ndesigned for maritime VOT. MVTD comprises 182 high-resolution video sequences,\ntotaling approximately 150,000 frames, and includes four representative object\nclasses: boat, ship, sailboat, and unmanned surface vehicle (USV). The dataset\ncaptures a diverse range of operational conditions and maritime scenarios,\nreflecting the real-world complexities of maritime environments. We evaluated\n14 recent SOTA tracking algorithms on the MVTD benchmark and observed\nsubstantial performance degradation compared to their performance on\ngeneral-purpose datasets. However, when fine-tuned on MVTD, these models\ndemonstrate significant performance gains, underscoring the effectiveness of\ndomain adaptation and the importance of transfer learning in specialized\ntracking contexts. The MVTD dataset fills a critical gap in the visual tracking\ncommunity by providing a realistic and challenging benchmark for maritime\nscenarios. Dataset and Source Code can be accessed here\n\"https://github.com/AhsanBaidar/MVTD\".", "published": "2025-06-03 13:30:11", "link": "http://arxiv.org/abs/2506.02866v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Enhancing Abnormality Identification: Robust Out-of-Distribution Strategies for Deepfake Detection", "abstract": "Detecting deepfakes has become a critical challenge in Computer Vision and\nArtificial Intelligence. Despite significant progress in detection techniques,\ngeneralizing them to open-set scenarios continues to be a persistent\ndifficulty. Neural networks are often trained on the closed-world assumption,\nbut with new generative models constantly evolving, it is inevitable to\nencounter data generated by models that are not part of the training\ndistribution. To address these challenges, in this paper, we propose two novel\nOut-Of-Distribution (OOD) detection approaches. The first approach is trained\nto reconstruct the input image, while the second incorporates an attention\nmechanism for detecting OODs. Our experiments validate the effectiveness of the\nproposed approaches compared to existing state-of-the-art techniques. Our\nmethod achieves promising results in deepfake detection and ranks among the\ntop-performing configurations on the benchmark, demonstrating their potential\nfor robust, adaptable solutions in dynamic, real-world applications.", "published": "2025-06-03 13:24:33", "link": "http://arxiv.org/abs/2506.02857v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hierarchical Self-Prompting SAM: A Prompt-Free Medical Image Segmentation Framework", "abstract": "Although the Segment Anything Model (SAM) is highly effective in natural\nimage segmentation, it requires dependencies on prompts, which limits its\napplicability to medical imaging where manual prompts are often unavailable.\nExisting efforts to fine-tune SAM for medical segmentation typically struggle\nto remove this dependency. We propose Hierarchical Self-Prompting SAM\n(HSP-SAM), a novel self-prompting framework that enables SAM to achieve strong\nperformance in prompt-free medical image segmentation. Unlike previous\nself-prompting methods that remain limited to positional prompts similar to\nvanilla SAM, we are the first to introduce learning abstract prompts during the\nself-prompting process. This simple and intuitive self-prompting framework\nachieves superior performance on classic segmentation tasks such as polyp and\nskin lesion segmentation, while maintaining robustness across diverse medical\nimaging modalities. Furthermore, it exhibits strong generalization to unseen\ndatasets, achieving improvements of up to 14.04% over previous state-of-the-art\nmethods on some challenging benchmarks. These results suggest that abstract\nprompts encapsulate richer and higher-dimensional semantic information compared\nto positional prompts, thereby enhancing the model's robustness and\ngeneralization performance. All models and codes will be released upon\nacceptance.", "published": "2025-06-03 13:23:33", "link": "http://arxiv.org/abs/2506.02854v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning Pyramid-structured Long-range Dependencies for 3D Human Pose Estimation", "abstract": "Action coordination in human structure is indispensable for the spatial\nconstraints of 2D joints to recover 3D pose. Usually, action coordination is\nrepresented as a long-range dependence among body parts. However, there are two\nmain challenges in modeling long-range dependencies. First, joints should not\nonly be constrained by other individual joints but also be modulated by the\nbody parts. Second, existing methods make networks deeper to learn dependencies\nbetween non-linked parts. They introduce uncorrelated noise and increase the\nmodel size. In this paper, we utilize a pyramid structure to better learn\npotential long-range dependencies. It can capture the correlation across joints\nand groups, which complements the context of the human sub-structure. In an\neffective cross-scale way, it captures the pyramid-structured long-range\ndependence. Specifically, we propose a novel Pyramid Graph Attention (PGA)\nmodule to capture long-range cross-scale dependencies. It concatenates\ninformation from various scales into a compact sequence, and then computes the\ncorrelation between scales in parallel. Combining PGA with graph convolution\nmodules, we develop a Pyramid Graph Transformer (PGFormer) for 3D human pose\nestimation, which is a lightweight multi-scale transformer architecture. It\nencapsulates human sub-structures into self-attention by pooling. Extensive\nexperiments show that our approach achieves lower error and smaller model size\nthan state-of-the-art methods on Human3.6M and MPI-INF-3DHP datasets. The code\nis available at https://github.com/MingjieWe/PGFormer.", "published": "2025-06-03 13:21:37", "link": "http://arxiv.org/abs/2506.02853v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "METok: Multi-Stage Event-based Token Compression for Efficient Long Video Understanding", "abstract": "Recent advances in Video Large Language Models (VLLMs) have significantly\nenhanced their ability to understand video content. Nonetheless, processing\nlong videos remains challenging due to high computational demands and the\nredundancy present in the visual data. In this work, we propose METok, a\ntraining-free, Multi-stage Event-based Token compression framework designed to\naccelerate VLLMs' inference while preserving accuracy. METok progressively\neliminates redundant visual tokens across three critical stages: (1)\nevent-aware compression during vision encoding, (2) hierarchical token pruning\nin the prefilling stage based on semantic alignment and event importance, and\n(3) a decoding-stage KV Cache optimization that further reduces memory\nconsumption. Our experiments on diverse video benchmarks demonstrate that METok\nachieves an optimal trade-off between efficiency and accuracy by dynamically\nselecting informative visual tokens. For instance, equipping LongVA-7B with\nMETok realizes an 80.6% FLOPs reduction and 93.5% KV Cache memory savings, all\nwhile maintaining comparable or even superior accuracy.", "published": "2025-06-03 13:19:41", "link": "http://arxiv.org/abs/2506.02850v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PBR-SR: Mesh PBR Texture Super Resolution from 2D Image Priors", "abstract": "We present PBR-SR, a novel method for physically based rendering (PBR)\ntexture super resolution (SR). It outputs high-resolution, high-quality PBR\ntextures from low-resolution (LR) PBR input in a zero-shot manner. PBR-SR\nleverages an off-the-shelf super-resolution model trained on natural images,\nand iteratively minimizes the deviations between super-resolution priors and\ndifferentiable renderings. These enhancements are then back-projected into the\nPBR map space in a differentiable manner to produce refined, high-resolution\ntextures. To mitigate view inconsistencies and lighting sensitivity, which is\ncommon in view-based super-resolution, our method applies 2D prior constraints\nacross multi-view renderings, iteratively refining the shared, upscaled\ntextures. In parallel, we incorporate identity constraints directly in the PBR\ntexture domain to ensure the upscaled textures remain faithful to the LR input.\nPBR-SR operates without any additional training or data requirements, relying\nentirely on pretrained image priors. We demonstrate that our approach produces\nhigh-fidelity PBR textures for both artist-designed and AI-generated meshes,\noutperforming both direct SR models application and prior texture optimization\nmethods. Our results show high-quality outputs in both PBR and rendering\nevaluations, supporting advanced applications such as relighting.", "published": "2025-06-03 13:15:34", "link": "http://arxiv.org/abs/2506.02846v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Go Beyond Earth: Understanding Human Actions and Scenes in Microgravity Environments", "abstract": "Despite substantial progress in video understanding, most existing datasets\nare limited to Earth's gravitational conditions. However, microgravity alters\nhuman motion, interactions, and visual semantics, revealing a critical gap for\nreal-world vision systems. This presents a challenge for domain-robust video\nunderstanding in safety-critical space applications. To address this, we\nintroduce MicroG-4M, the first benchmark for spatio-temporal and semantic\nunderstanding of human activities in microgravity. Constructed from real-world\nspace missions and cinematic simulations, the dataset includes 4,759 clips\ncovering 50 actions, 1,238 context-rich captions, and over 7,000\nquestion-answer pairs on astronaut activities and scene understanding.\nMicroG-4M supports three core tasks: fine-grained multi-label action\nrecognition, temporal video captioning, and visual question answering, enabling\na comprehensive evaluation of both spatial localization and semantic reasoning\nin microgravity contexts. We establish baselines using state-of-the-art models.\nAll data, annotations, and code are available at\nhttps://github.com/LEI-QI-233/HAR-in-Space.", "published": "2025-06-03 13:15:19", "link": "http://arxiv.org/abs/2506.02845v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Random Registers for Cross-Domain Few-Shot Learning", "abstract": "Cross-domain few-shot learning (CDFSL) aims to transfer knowledge from a\ndata-sufficient source domain to data-scarce target domains. Although Vision\nTransformer (ViT) has shown superior capability in many vision tasks, its\ntransferability against huge domain gaps in CDFSL is still under-explored. In\nthis paper, we find an intriguing phenomenon: during the source-domain\ntraining, prompt tuning, as a common way to train ViT, could be harmful for the\ngeneralization of ViT in target domains, but setting them to random noises\n(i.e., random registers) could consistently improve target-domain performance.\nWe then delve into this phenomenon for an interpretation. We find that\nlearnable prompts capture domain information during the training on the source\ndataset, which views irrelevant visual patterns as vital cues for recognition.\nThis can be viewed as a kind of overfitting and increases the sharpness of the\nloss landscapes. In contrast, random registers are essentially a novel way of\nperturbing attention for the sharpness-aware minimization, which helps the\nmodel find a flattened minimum in loss landscapes, increasing the\ntransferability. Based on this phenomenon and interpretation, we further\npropose a simple but effective approach for CDFSL to enhance the perturbation\non attention maps by adding random registers on the semantic regions of image\ntokens, improving the effectiveness and efficiency of random registers.\nExtensive experiments on four benchmarks validate our rationale and\nstate-of-the-art performance. Codes and models are available at\nhttps://github.com/shuaiyi308/REAP.", "published": "2025-06-03 13:13:58", "link": "http://arxiv.org/abs/2506.02843v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Automated Measurement of Optic Nerve Sheath Diameter Using Ocular Ultrasound Video", "abstract": "Objective. Elevated intracranial pressure (ICP) is recognized as a biomarker\nof secondary brain injury, with a significant linear correlation observed\nbetween optic nerve sheath diameter (ONSD) and ICP. Frequent monitoring of ONSD\ncould effectively support dynamic evaluation of ICP. However, ONSD measurement\nis heavily reliant on the operator's experience and skill, particularly in\nmanually selecting the optimal frame from ultrasound sequences and measuring\nONSD. Approach. This paper presents a novel method to automatically identify\nthe optimal frame from video sequences for ONSD measurement by employing the\nKernel Correlation Filter (KCF) tracking algorithm and Simple Linear Iterative\nClustering (SLIC) segmentation algorithm. The optic nerve sheath is mapped and\nmeasured using a Gaussian Mixture Model (GMM) combined with a\nKL-divergence-based method. Results. When compared with the average\nmeasurements of two expert clinicians, the proposed method achieved a mean\nerror, mean squared deviation, and intraclass correlation coefficient (ICC) of\n0.04, 0.054, and 0.782, respectively. Significance. The findings suggest that\nthis method provides highly accurate automated ONSD measurements, showing\npotential for clinical application.", "published": "2025-06-03 12:14:51", "link": "http://arxiv.org/abs/2506.02789v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SAMJ: Fast Image Annotation on ImageJ/Fiji via Segment Anything Model", "abstract": "Mask annotation remains a significant bottleneck in AI-driven biomedical\nimage analysis due to its labor-intensive nature. To address this challenge, we\nintroduce SAMJ, a user-friendly ImageJ/Fiji plugin leveraging the Segment\nAnything Model (SAM). SAMJ enables seamless, interactive annotations with\none-click installation on standard computers. Designed for real-time object\ndelineation in large scientific images, SAMJ is an easy-to-use solution that\nsimplifies and accelerates the creation of labeled image datasets.", "published": "2025-06-03 12:10:03", "link": "http://arxiv.org/abs/2506.02783v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FreeScene: Mixed Graph Diffusion for 3D Scene Synthesis from Free Prompts", "abstract": "Controllability plays a crucial role in the practical applications of 3D\nindoor scene synthesis. Existing works either allow rough language-based\ncontrol, that is convenient but lacks fine-grained scene customization, or\nemploy graph based control, which offers better controllability but demands\nconsiderable knowledge for the cumbersome graph design process. To address\nthese challenges, we present FreeScene, a user-friendly framework that enables\nboth convenient and effective control for indoor scene synthesis.Specifically,\nFreeScene supports free-form user inputs including text description and/or\nreference images, allowing users to express versatile design intentions. The\nuser inputs are adequately analyzed and integrated into a graph representation\nby a VLM-based Graph Designer. We then propose MG-DiT, a Mixed Graph Diffusion\nTransformer, which performs graph-aware denoising to enhance scene generation.\nOur MG-DiT not only excels at preserving graph structure but also offers broad\napplicability to various tasks, including, but not limited to, text-to-scene,\ngraph-to-scene, and rearrangement, all within a single model. Extensive\nexperiments demonstrate that FreeScene provides an efficient and user-friendly\nsolution that unifies text-based and graph based scene synthesis, outperforming\nstate-of-the-art methods in terms of both generation quality and\ncontrollability in a range of applications.", "published": "2025-06-03 12:01:41", "link": "http://arxiv.org/abs/2506.02781v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Dynamic Transformer Network for Vehicle Detection", "abstract": "Stable consumer electronic systems can assist traffic better. Good traffic\nconsumer electronic systems require collaborative work between traffic\nalgorithms and hardware. However, performance of popular traffic algorithms\ncontaining vehicle detection methods based on deep networks via learning data\nrelation rather than learning differences in different lighting and occlusions\nis limited. In this paper, we present a dynamic Transformer network for vehicle\ndetection (DTNet). DTNet utilizes a dynamic convolution to guide a deep network\nto dynamically generate weights to enhance adaptability of an obtained\ndetector. Taking into relations of different information account, a mixed\nattention mechanism based channel attention and Transformer is exploited to\nstrengthen relations of channels and pixels to extract more salient information\nfor vehicle detection. To overcome the drawback of difference in an image\naccount, a translation-variant convolution relies on spatial location\ninformation to refine obtained structural information for vehicle detection.\nExperimental results illustrate that our DTNet is competitive for vehicle\ndetection. Code of the proposed DTNet can be obtained at\nhttps://github.com/hellloxiaotian/DTNet.", "published": "2025-06-03 11:29:35", "link": "http://arxiv.org/abs/2506.02765v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RobustSplat: Decoupling Densification and Dynamics for Transient-Free 3DGS", "abstract": "3D Gaussian Splatting (3DGS) has gained significant attention for its\nreal-time, photo-realistic rendering in novel-view synthesis and 3D modeling.\nHowever, existing methods struggle with accurately modeling scenes affected by\ntransient objects, leading to artifacts in the rendered images. We identify\nthat the Gaussian densification process, while enhancing scene detail capture,\nunintentionally contributes to these artifacts by growing additional Gaussians\nthat model transient disturbances. To address this, we propose RobustSplat, a\nrobust solution based on two critical designs. First, we introduce a delayed\nGaussian growth strategy that prioritizes optimizing static scene structure\nbefore allowing Gaussian splitting/cloning, mitigating overfitting to transient\nobjects in early optimization. Second, we design a scale-cascaded mask\nbootstrapping approach that first leverages lower-resolution feature similarity\nsupervision for reliable initial transient mask estimation, taking advantage of\nits stronger semantic consistency and robustness to noise, and then progresses\nto high-resolution supervision to achieve more precise mask prediction.\nExtensive experiments on multiple challenging datasets show that our method\noutperforms existing methods, clearly demonstrating the robustness and\neffectiveness of our method. Our project page is\nhttps://fcyycf.github.io/RobustSplat/.", "published": "2025-06-03 11:13:48", "link": "http://arxiv.org/abs/2506.02751v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VTGaussian-SLAM: RGBD SLAM for Large Scale Scenes with Splatting View-Tied 3D Gaussians", "abstract": "Jointly estimating camera poses and mapping scenes from RGBD images is a\nfundamental task in simultaneous localization and mapping (SLAM).\nState-of-the-art methods employ 3D Gaussians to represent a scene, and render\nthese Gaussians through splatting for higher efficiency and better rendering.\nHowever, these methods cannot scale up to extremely large scenes, due to the\ninefficient tracking and mapping strategies that need to optimize all 3D\nGaussians in the limited GPU memories throughout the training to maintain the\ngeometry and color consistency to previous RGBD observations. To resolve this\nissue, we propose novel tracking and mapping strategies to work with a novel 3D\nrepresentation, dubbed view-tied 3D Gaussians, for RGBD SLAM systems. View-tied\n3D Gaussians is a kind of simplified Gaussians, which is tied to depth pixels,\nwithout needing to learn locations, rotations, and multi-dimensional variances.\nTying Gaussians to views not only significantly saves storage but also allows\nus to employ many more Gaussians to represent local details in the limited GPU\nmemory. Moreover, our strategies remove the need of maintaining all Gaussians\nlearnable throughout the training, while improving rendering quality, and\ntracking accuracy. We justify the effectiveness of these designs, and report\nbetter performance over the latest methods on the widely used benchmarks in\nterms of rendering and tracking accuracy and scalability. Please see our\nproject page for code and videos at\nhttps://machineperceptionlab.github.io/VTGaussian-SLAM-Project .", "published": "2025-06-03 10:59:19", "link": "http://arxiv.org/abs/2506.02741v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Open-PMC-18M: A High-Fidelity Large Scale Medical Dataset for Multimodal Representation Learning", "abstract": "Compound figures, which are multi-panel composites containing diverse\nsubfigures, are ubiquitous in biomedical literature, yet large-scale subfigure\nextraction remains largely unaddressed. Prior work on subfigure extraction has\nbeen limited in both dataset size and generalizability, leaving a critical open\nquestion: How does high-fidelity image-text alignment via large-scale subfigure\nextraction impact representation learning in vision-language models? We address\nthis gap by introducing a scalable subfigure extraction pipeline based on\ntransformer-based object detection, trained on a synthetic corpus of 500,000\ncompound figures, and achieving state-of-the-art performance on both ImageCLEF\n2016 and synthetic benchmarks. Using this pipeline, we release OPEN-PMC-18M, a\nlarge-scale high quality biomedical vision-language dataset comprising 18\nmillion clinically relevant subfigure-caption pairs spanning radiology,\nmicroscopy, and visible light photography. We train and evaluate\nvision-language models on our curated datasets and show improved performance\nacross retrieval, zero-shot classification, and robustness benchmarks,\noutperforming existing baselines. We release our dataset, models, and code to\nsupport reproducible benchmarks and further study into biomedical\nvision-language modeling and representation learning.", "published": "2025-06-03 10:53:19", "link": "http://arxiv.org/abs/2506.02738v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GeneA-SLAM2: Dynamic SLAM with AutoEncoder-Preprocessed Genetic Keypoints Resampling and Depth Variance-Guided Dynamic Region Removal", "abstract": "Existing semantic SLAM in dynamic environments mainly identify dynamic\nregions through object detection or semantic segmentation methods. However, in\ncertain highly dynamic scenarios, the detection boxes or segmentation masks\ncannot fully cover dynamic regions. Therefore, this paper proposes a robust and\nefficient GeneA-SLAM2 system that leverages depth variance constraints to\nhandle dynamic scenes. Our method extracts dynamic pixels via depth variance\nand creates precise depth masks to guide the removal of dynamic objects.\nSimultaneously, an autoencoder is used to reconstruct keypoints, improving the\ngenetic resampling keypoint algorithm to obtain more uniformly distributed\nkeypoints and enhance the accuracy of pose estimation. Our system was evaluated\non multiple highly dynamic sequences. The results demonstrate that GeneA-SLAM2\nmaintains high accuracy in dynamic scenes compared to current methods. Code is\navailable at: https://github.com/qingshufan/GeneA-SLAM2.", "published": "2025-06-03 10:51:53", "link": "http://arxiv.org/abs/2506.02736v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "ToothForge: Automatic Dental Shape Generation using Synchronized Spectral Embeddings", "abstract": "We introduce ToothForge, a spectral approach for automatically generating\nnovel 3D teeth, effectively addressing the sparsity of dental shape datasets.\nBy operating in the spectral domain, our method enables compact machine\nlearning modeling, allowing the generation of high-resolution tooth meshes in\nmilliseconds. However, generating shape spectra comes with the instability of\nthe decomposed harmonics. To address this, we propose modeling the latent\nmanifold on synchronized frequential embeddings. Spectra of all data samples\nare aligned to a common basis prior to the training procedure, effectively\neliminating biases introduced by the decomposition instability. Furthermore,\nsynchronized modeling removes the limiting factor imposed by previous methods,\nwhich require all shapes to share a common fixed connectivity. Using a private\ndataset of real dental crowns, we observe a greater reconstruction quality of\nthe synthetized shapes, exceeding those of models trained on unaligned\nembeddings. We also explore additional applications of spectral analysis in\ndigital dentistry, such as shape compression and interpolation. ToothForge\nfacilitates a range of approaches at the intersection of spectral analysis and\nmachine learning, with fewer restrictions on mesh structure. This makes it\napplicable for shape analysis not only in dentistry, but also in broader\nmedical applications, where guaranteeing consistent connectivity across shapes\nfrom various clinics is unrealistic. The code is available at\nhttps://github.com/tiborkubik/toothForge.", "published": "2025-06-03 09:56:22", "link": "http://arxiv.org/abs/2506.02702v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Smoothed Preference Optimization via ReNoise Inversion for Aligning Diffusion Models with Varied Human Preferences", "abstract": "Direct Preference Optimization (DPO) aligns text-to-image (T2I) generation\nmodels with human preferences using pairwise preference data. Although\nsubstantial resources are expended in collecting and labeling datasets, a\ncritical aspect is often neglected: \\textit{preferences vary across individuals\nand should be represented with more granularity.} To address this, we propose\nSmPO-Diffusion, a novel method for modeling preference distributions to improve\nthe DPO objective, along with a numerical upper bound estimation for the\ndiffusion optimization objective. First, we introduce a smoothed preference\ndistribution to replace the original binary distribution. We employ a reward\nmodel to simulate human preferences and apply preference likelihood averaging\nto improve the DPO loss, such that the loss function approaches zero when\npreferences are similar. Furthermore, we utilize an inversion technique to\nsimulate the trajectory preference distribution of the diffusion model,\nenabling more accurate alignment with the optimization objective. Our approach\neffectively mitigates issues of excessive optimization and objective\nmisalignment present in existing methods through straightforward modifications.\nOur SmPO-Diffusion achieves state-of-the-art performance in preference\nevaluation, outperforming baselines across metrics with lower training costs.\nThe project page is https://jaydenlyh.github.io/SmPO-project-page/.", "published": "2025-06-03 09:47:22", "link": "http://arxiv.org/abs/2506.02698v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LayoutRAG: Retrieval-Augmented Model for Content-agnostic Conditional Layout Generation", "abstract": "Controllable layout generation aims to create plausible visual arrangements\nof element bounding boxes within a graphic design according to certain optional\nconstraints, such as the type or position of a specific component. While recent\ndiffusion or flow-matching models have achieved considerable advances in\nmultifarious conditional generation tasks, there remains considerable room for\ngenerating optimal arrangements under given conditions. In this work, we\npropose to carry out layout generation through retrieving by conditions and\nreference-guided generation. Specifically, we retrieve appropriate layout\ntemplates according to given conditions as references. The references are then\nutilized to guide the denoising or flow-based transport process. By retrieving\nlayouts compatible with the given conditions, we can uncover the potential\ninformation not explicitly provided in the given condition. Such an approach\noffers more effective guidance to the model during the generation process, in\ncontrast to previous models that feed the condition to the model and let the\nmodel infer the unprovided layout attributes directly. Meanwhile, we design a\ncondition-modulated attention that selectively absorbs retrieval knowledge,\nadapting to the difference between retrieved templates and given conditions.\nExtensive experiment results show that our method successfully produces\nhigh-quality layouts that meet the given conditions and outperforms existing\nstate-of-the-art models. Code will be released upon acceptance.", "published": "2025-06-03 09:47:03", "link": "http://arxiv.org/abs/2506.02697v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FaceSleuth: Learning-Driven Single-Orientation Attention Verifies Vertical Dominance in Micro-Expression Recognition", "abstract": "Micro-expression recognition (MER) demands models that can amplify\nmillisecond-level, low-amplitude facial motions while suppressing\nidentity-specific appearance. We introduce FaceSleuth, a dual-stream\narchitecture that (1) enhances motion along the empirically dominant vertical\naxix through a Continuously Vertical Attention (CVA) block, (2) localises the\nresulting signals with a Facial Position Focalizer built on hierarchical\ncross-window attention, and (3) steers feature learning toward physiologically\nmeaningful regions via lightweight Action-Unit embeddings. To examine whether\nthe hand-chosen vertical axis is indeed optimal, we further propose a\nSingle-Orientation Attention (SOA) module that learns its own pooling direction\nend-to-end. SOA is differentiable, adds only 0.16 % parameters, and collapses\nto CVA when the learned angle converges to {\\Pi}/2. In practice, SOA reliably\ndrifts to 88{\\deg}, confirming the effectiveness of the vertical prior while\ndelivering consistent gains. On three standard MER benchmarks, FaceSleuth with\nCVA already surpasses previous state-of-the-art methods; plugging in SOA lifts\naccuracy and F1 score performance to 95.1 % / 0.918 on CASME II, 87.1 % / 0.840\non SAMM, and 92.9 % / 0.917 on MMEW without sacrificing model compactness.\nThese results establish a new state of the art and, for the first time, provide\nempirical evidence that the vertical attention bias is the most discriminative\norientation for MER.", "published": "2025-06-03 09:44:18", "link": "http://arxiv.org/abs/2506.02695v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Large-scale Self-supervised Video Foundation Model for Intelligent Surgery", "abstract": "Computer-Assisted Intervention (CAI) has the potential to revolutionize\nmodern surgery, with surgical scene understanding serving as a critical\ncomponent in supporting decision-making, improving procedural efficacy, and\nensuring intraoperative safety. While existing AI-driven approaches alleviate\nannotation burdens via self-supervised spatial representation learning, their\nlack of explicit temporal modeling during pre-training fundamentally restricts\nthe capture of dynamic surgical contexts, resulting in incomplete\nspatiotemporal understanding. In this work, we introduce the first video-level\nsurgical pre-training framework that enables joint spatiotemporal\nrepresentation learning from large-scale surgical video data. To achieve this,\nwe constructed a large-scale surgical video dataset comprising 3,650 videos and\napproximately 3.55 million frames, spanning more than 20 surgical procedures\nand over 10 anatomical structures. Building upon this dataset, we propose\nSurgVISTA (Surgical Video-level Spatial-Temporal Architecture), a\nreconstruction-based pre-training method that captures intricate spatial\nstructures and temporal dynamics through joint spatiotemporal modeling.\nAdditionally, SurgVISTA incorporates image-level knowledge distillation guided\nby a surgery-specific expert to enhance the learning of fine-grained anatomical\nand semantic features. To validate its effectiveness, we established a\ncomprehensive benchmark comprising 13 video-level datasets spanning six\nsurgical procedures across four tasks. Extensive experiments demonstrate that\nSurgVISTA consistently outperforms both natural- and surgical-domain\npre-trained models, demonstrating strong potential to advance intelligent\nsurgical systems in clinically meaningful scenarios.", "published": "2025-06-03 09:42:54", "link": "http://arxiv.org/abs/2506.02692v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Geometry Problem Solving in the Large Model Era: A Survey", "abstract": "Geometry problem solving (GPS) represents a critical frontier in artificial\nintelligence, with profound applications in education, computer-aided design,\nand computational graphics. Despite its significance, automating GPS remains\nchallenging due to the dual demands of spatial understanding and rigorous\nlogical reasoning. Recent advances in large models have enabled notable\nbreakthroughs, particularly for SAT-level problems, yet the field remains\nfragmented across methodologies, benchmarks, and evaluation frameworks. This\nsurvey systematically synthesizes GPS advancements through three core\ndimensions: (1) benchmark construction, (2) textual and diagrammatic parsing,\nand (3) reasoning paradigms. We further propose a unified analytical paradigm,\nassess current limitations, and identify emerging opportunities to guide future\nresearch toward human-level geometric reasoning, including automated benchmark\ngeneration and interpretable neuro-symbolic integration.", "published": "2025-06-03 09:42:49", "link": "http://arxiv.org/abs/2506.02690v1", "categories": ["cs.CV", "math.GT"], "primary_category": "cs.CV"}
{"title": "Solving Inverse Problems with FLAIR", "abstract": "Flow-based latent generative models such as Stable Diffusion 3 are able to\ngenerate images with remarkable quality, even enabling photorealistic\ntext-to-image generation. Their impressive performance suggests that these\nmodels should also constitute powerful priors for inverse imaging problems, but\nthat approach has not yet led to comparable fidelity. There are several key\nobstacles: (i) the encoding into a lower-dimensional latent space makes the\nunderlying (forward) mapping non-linear; (ii) the data likelihood term is\nusually intractable; and (iii) learned generative models struggle to recover\nrare, atypical data modes during inference. We present FLAIR, a novel training\nfree variational framework that leverages flow-based generative models as a\nprior for inverse problems. To that end, we introduce a variational objective\nfor flow matching that is agnostic to the type of degradation, and combine it\nwith deterministic trajectory adjustments to recover atypical modes. To enforce\nexact consistency with the observed data, we decouple the optimization of the\ndata fidelity and regularization terms. Moreover, we introduce a time-dependent\ncalibration scheme in which the strength of the regularization is modulated\naccording to off-line accuracy estimates. Results on standard imaging\nbenchmarks demonstrate that FLAIR consistently outperforms existing diffusion-\nand flow-based methods in terms of reconstruction quality and sample diversity.", "published": "2025-06-03 09:29:47", "link": "http://arxiv.org/abs/2506.02680v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Small Aid, Big Leap: Efficient Test-Time Adaptation for Vision-Language Models with AdaptNet", "abstract": "Test-time adaptation (TTA) has emerged as a critical technique for enhancing\nthe generalization capability of vision-language models (VLMs) during\ninference. However, existing approaches often incur substantial computational\ncosts and exhibit poor scalability, primarily due to sample-wise adaptation\ngranularity and reliance on costly auxiliary designs such as data augmentation.\nTo address these limitations, we introduce SAIL (Small Aid, Big Leap), a novel\nadapter-based TTA framework that leverages a lightweight, learnable AdaptNet to\nenable efficient and scalable model adaptation. As SAIL's core, a frozen\npre-trained VLM collaborates with AdaptNet through a confidence-based\ninterpolation weight, generating robust predictions during inference. These\npredictions serve as self-supervised targets to align AdaptNet's outputs\nthrough efficient batch-wise processing, dramatically reducing computational\ncosts without modifying the VLM or requiring memory caches. To mitigate\ncatastrophic forgetting during continual adaptation, we propose a\ngradient-aware reset strategy driven by a gradient drift indicator (GDI), which\ndynamically detects domain transitions and strategically resets AdaptNet for\nstable adaptation. Extensive experiments across diverse benchmarks on two\nscenarios demonstrate that SAIL achieves state-of-the-art performance while\nmaintaining low computational costs. These results highlight SAIL's\neffectiveness, efficiency and scalability for real-world deployment. The code\nwill be released upon acceptance.", "published": "2025-06-03 09:16:51", "link": "http://arxiv.org/abs/2506.02671v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MotionRAG-Diff: A Retrieval-Augmented Diffusion Framework for Long-Term Music-to-Dance Generation", "abstract": "Generating long-term, coherent, and realistic music-conditioned dance\nsequences remains a challenging task in human motion synthesis. Existing\napproaches exhibit critical limitations: motion graph methods rely on fixed\ntemplate libraries, restricting creative generation; diffusion models, while\ncapable of producing novel motions, often lack temporal coherence and musical\nalignment. To address these challenges, we propose $\\textbf{MotionRAG-Diff}$, a\nhybrid framework that integrates Retrieval-Augmented Generation (RAG) with\ndiffusion-based refinement to enable high-quality, musically coherent dance\ngeneration for arbitrary long-term music inputs. Our method introduces three\ncore innovations: (1) A cross-modal contrastive learning architecture that\naligns heterogeneous music and dance representations in a shared latent space,\nestablishing unsupervised semantic correspondence without paired data; (2) An\noptimized motion graph system for efficient retrieval and seamless\nconcatenation of motion segments, ensuring realism and temporal coherence\nacross long sequences; (3) A multi-condition diffusion model that jointly\nconditions on raw music signals and contrastive features to enhance motion\nquality and global synchronization. Extensive experiments demonstrate that\nMotionRAG-Diff achieves state-of-the-art performance in motion quality,\ndiversity, and music-motion synchronization accuracy. This work establishes a\nnew paradigm for music-driven dance generation by synergizing retrieval-based\ntemplate fidelity with diffusion-based creative enhancement.", "published": "2025-06-03 09:12:48", "link": "http://arxiv.org/abs/2506.02661v1", "categories": ["cs.SD", "cs.CV", "cs.GR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ControlMambaIR: Conditional Controls with State-Space Model for Image Restoration", "abstract": "This paper proposes ControlMambaIR, a novel image restoration method designed\nto address perceptual challenges in image deraining, deblurring, and denoising\ntasks. By integrating the Mamba network architecture with the diffusion model,\nthe condition network achieves refined conditional control, thereby enhancing\nthe control and optimization of the image generation process. To evaluate the\nrobustness and generalization capability of our method across various image\ndegradation conditions, extensive experiments were conducted on several\nbenchmark datasets, including Rain100H, Rain100L, GoPro, and SSID. The results\ndemonstrate that our proposed approach consistently surpasses existing methods\nin perceptual quality metrics, such as LPIPS and FID, while maintaining\ncomparable performance in image distortion metrics, including PSNR and SSIM,\nhighlighting its effectiveness and adaptability. Notably, ablation experiments\nreveal that directly noise prediction in the diffusion process achieves better\nperformance, effectively balancing noise suppression and detail preservation.\nFurthermore, the findings indicate that the Mamba architecture is particularly\nwell-suited as a conditional control network for diffusion models,\noutperforming both CNN- and Attention-based approaches in this context.\nOverall, these results highlight the flexibility and effectiveness of\nControlMambaIR in addressing a range of image restoration perceptual\nchallenges.", "published": "2025-06-03 08:50:00", "link": "http://arxiv.org/abs/2506.02633v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Synthetic Iris Image Databases and Identity Leakage: Risks and Mitigation Strategies", "abstract": "This paper presents a comprehensive overview of iris image synthesis methods,\nwhich can alleviate the issues associated with gathering large, diverse\ndatasets of biometric data from living individuals, which are considered\npivotal for biometric methods development. These methods for synthesizing iris\ndata range from traditional, hand crafted image processing-based techniques,\nthrough various iterations of GAN-based image generators, variational\nautoencoders (VAEs), as well as diffusion models. The potential and fidelity in\niris image generation of each method is discussed and examples of inferred\npredictions are provided. Furthermore, the risks of individual biometric\nfeatures leakage from the training sets are considered, together with possible\nstrategies for preventing them, which have to be implemented should these\ngenerative methods be considered a valid replacement of real-world biometric\ndatasets.", "published": "2025-06-03 08:41:43", "link": "http://arxiv.org/abs/2506.02626v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FlexPainter: Flexible and Multi-View Consistent Texture Generation", "abstract": "Texture map production is an important part of 3D modeling and determines the\nrendering quality. Recently, diffusion-based methods have opened a new way for\ntexture generation. However, restricted control flexibility and limited prompt\nmodalities may prevent creators from producing desired results. Furthermore,\ninconsistencies between generated multi-view images often lead to poor texture\ngeneration quality. To address these issues, we introduce \\textbf{FlexPainter},\na novel texture generation pipeline that enables flexible multi-modal\nconditional guidance and achieves highly consistent texture generation. A\nshared conditional embedding space is constructed to perform flexible\naggregation between different input modalities. Utilizing such embedding space,\nwe present an image-based CFG method to decompose structural and style\ninformation, achieving reference image-based stylization. Leveraging the 3D\nknowledge within the image diffusion prior, we first generate multi-view images\nsimultaneously using a grid representation to enhance global understanding.\nMeanwhile, we propose a view synchronization and adaptive weighting module\nduring diffusion sampling to further ensure local consistency. Finally, a\n3D-aware texture completion model combined with a texture enhancement model is\nused to generate seamless, high-resolution texture maps. Comprehensive\nexperiments demonstrate that our framework significantly outperforms\nstate-of-the-art methods in both flexibility and generation quality.", "published": "2025-06-03 08:36:03", "link": "http://arxiv.org/abs/2506.02620v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Rodrigues Network for Learning Robot Actions", "abstract": "Understanding and predicting articulated actions is important in robot\nlearning. However, common architectures such as MLPs and Transformers lack\ninductive biases that reflect the underlying kinematic structure of articulated\nsystems. To this end, we propose the Neural Rodrigues Operator, a learnable\ngeneralization of the classical forward kinematics operation, designed to\ninject kinematics-aware inductive bias into neural computation. Building on\nthis operator, we design the Rodrigues Network (RodriNet), a novel neural\narchitecture specialized for processing actions. We evaluate the expressivity\nof our network on two synthetic tasks on kinematic and motion prediction,\nshowing significant improvements compared to standard backbones. We further\ndemonstrate its effectiveness in two realistic applications: (i) imitation\nlearning on robotic benchmarks with the Diffusion Policy, and (ii) single-image\n3D hand reconstruction. Our results suggest that integrating structured\nkinematic priors into the network architecture improves action learning in\nvarious domains.", "published": "2025-06-03 08:34:06", "link": "http://arxiv.org/abs/2506.02618v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "One-Step Diffusion-based Real-World Image Super-Resolution with Visual Perception Distillation", "abstract": "Diffusion-based models have been widely used in various visual generation\ntasks, showing promising results in image super-resolution (SR), while\ntypically being limited by dozens or even hundreds of sampling steps. Although\nexisting methods aim to accelerate the inference speed of multi-step\ndiffusion-based SR methods through knowledge distillation, their generated\nimages exhibit insufficient semantic alignment with real images, resulting in\nsuboptimal perceptual quality reconstruction, specifically reflected in the\nCLIPIQA score. These methods still have many challenges in perceptual quality\nand semantic fidelity. Based on the challenges, we propose VPD-SR, a novel\nvisual perception diffusion distillation framework specifically designed for\nSR, aiming to construct an effective and efficient one-step SR model.\nSpecifically, VPD-SR consists of two components: Explicit Semantic-aware\nSupervision (ESS) and High-Frequency Perception (HFP) loss. Firstly, the ESS\nleverages the powerful visual perceptual understanding capabilities of the CLIP\nmodel to extract explicit semantic supervision, thereby enhancing semantic\nconsistency. Then, Considering that high-frequency information contributes to\nthe visual perception quality of images, in addition to the vanilla\ndistillation loss, the HFP loss guides the student model to restore the missing\nhigh-frequency details in degraded images that are critical for enhancing\nperceptual quality. Lastly, we expand VPD-SR in adversarial training manner to\nfurther enhance the authenticity of the generated content. Extensive\nexperiments conducted on synthetic and real-world datasets demonstrate that the\nproposed VPD-SR achieves superior performance compared to both previous\nstate-of-the-art methods and the teacher model with just one-step sampling.", "published": "2025-06-03 08:28:13", "link": "http://arxiv.org/abs/2506.02605v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Application of convolutional neural networks in image super-resolution", "abstract": "Due to strong learning abilities of convolutional neural networks (CNNs),\nthey have become mainstream methods for image super-resolution. However, there\nare big differences of different deep learning methods with different types.\nThere is little literature to summarize relations and differences of different\nmethods in image super-resolution. Thus, summarizing these literatures are\nimportant, according to loading capacity and execution speed of devices. This\npaper first introduces principles of CNNs in image super-resolution, then\nintroduces CNNs based bicubic interpolation, nearest neighbor interpolation,\nbilinear interpolation, transposed convolution, sub-pixel layer, meta\nup-sampling for image super-resolution to analyze differences and relations of\ndifferent CNNs based interpolations and modules, and compare performance of\nthese methods by experiments. Finally, this paper gives potential research\npoints and drawbacks and summarizes the whole paper, which can facilitate\ndevelopments of CNNs in image super-resolution.", "published": "2025-06-03 08:28:08", "link": "http://arxiv.org/abs/2506.02604v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Hyperspectral Image Generation with Unmixing Guided Diffusion Model", "abstract": "Recently, hyperspectral image generation has received increasing attention,\nbut existing generative models rely on conditional generation schemes, which\nlimits the diversity of generated images. Diffusion models are popular for\ntheir ability to generate high-quality samples, but adapting these models from\nRGB to hyperspectral data presents the challenge of high dimensionality and\nphysical constraints. To address these challenges, we propose a novel diffusion\nmodel guided by hyperspectral unmixing. Our model comprises two key modules: an\nunmixing autoencoder module and an abundance diffusion module. The unmixing\nautoencoder module leverages unmixing guidance to shift the generative task\nfrom the image space to the low-dimensional abundance space, significantly\nreducing computational complexity while preserving high fidelity. The abundance\ndiffusion module generates samples that satisfy the constraints of\nnon-negativity and unity, ensuring the physical consistency of the\nreconstructed HSIs. Additionally, we introduce two evaluation metrics tailored\nto hyperspectral data. Empirical results, evaluated using both traditional\nmetrics and our proposed metrics, indicate that our model is capable of\ngenerating high-quality and diverse hyperspectral images, offering an\nadvancement in hyperspectral data generation.", "published": "2025-06-03 08:27:10", "link": "http://arxiv.org/abs/2506.02601v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "BEVCALIB: LiDAR-Camera Calibration via Geometry-Guided Bird's-Eye View Representations", "abstract": "Accurate LiDAR-camera calibration is fundamental to fusing multi-modal\nperception in autonomous driving and robotic systems. Traditional calibration\nmethods require extensive data collection in controlled environments and cannot\ncompensate for the transformation changes during the vehicle/robot movement. In\nthis paper, we propose the first model that uses bird's-eye view (BEV) features\nto perform LiDAR camera calibration from raw data, termed BEVCALIB. To achieve\nthis, we extract camera BEV features and LiDAR BEV features separately and fuse\nthem into a shared BEV feature space. To fully utilize the geometric\ninformation from the BEV feature, we introduce a novel feature selector to\nfilter the most important features in the transformation decoder, which reduces\nmemory consumption and enables efficient training. Extensive evaluations on\nKITTI, NuScenes, and our own dataset demonstrate that BEVCALIB establishes a\nnew state of the art. Under various noise conditions, BEVCALIB outperforms the\nbest baseline in the literature by an average of (47.08%, 82.32%) on KITTI\ndataset, and (78.17%, 68.29%) on NuScenes dataset, in terms of (translation,\nrotation), respectively. In the open-source domain, it improves the best\nreproducible baseline by one order of magnitude. Our code and demo results are\navailable at https://cisl.ucr.edu/BEVCalib.", "published": "2025-06-03 08:07:18", "link": "http://arxiv.org/abs/2506.02587v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "A Tree-guided CNN for image super-resolution", "abstract": "Deep convolutional neural networks can extract more accurate structural\ninformation via deep architectures to obtain good performance in image\nsuper-resolution. However, it is not easy to find effect of important layers in\na single network architecture to decrease performance of super-resolution. In\nthis paper, we design a tree-guided CNN for image super-resolution (TSRNet). It\nuses a tree architecture to guide a deep network to enhance effect of key nodes\nto amplify the relation of hierarchical information for improving the ability\nof recovering images. To prevent insufficiency of the obtained structural\ninformation, cosine transform techniques in the TSRNet are used to extract\ncross-domain information to improve the performance of image super-resolution.\nAdaptive Nesterov momentum optimizer (Adan) is applied to optimize parameters\nto boost effectiveness of training a super-resolution model. Extended\nexperiments can verify superiority of the proposed TSRNet for restoring\nhigh-quality images. Its code can be obtained at\nhttps://github.com/hellloxiaotian/TSRNet.", "published": "2025-06-03 08:05:11", "link": "http://arxiv.org/abs/2506.02585v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Dynamic mapping from static labels: remote sensing dynamic sample generation with temporal-spectral embedding", "abstract": "Accurate remote sensing geographic mapping depends heavily on representative\nand timely sample data. However, rapid changes in land surface dynamics\nnecessitate frequent updates, quickly rendering previously collected samples\nobsolete and imposing significant labor demands for continuous manual updates.\nIn this study, we aim to address this problem by dynamic sample generation\nusing existing single-date static labeled samples. We introduce TasGen, a\ntwo-stage automated framework to automatically generate dynamic samples,\ndesigned to simultaneously model spectral and temporal dependencies in\ntime-series remote sensing imagery via temporal-spectral embedding, capturing\nland surface changes without additional manual annotations.", "published": "2025-06-03 07:55:16", "link": "http://arxiv.org/abs/2506.02574v1", "categories": ["eess.IV", "cs.CV", "cs.MM"], "primary_category": "eess.IV"}
{"title": "Contrast & Compress: Learning Lightweight Embeddings for Short Trajectories", "abstract": "The ability to retrieve semantically and directionally similar short-range\ntrajectories with both accuracy and efficiency is foundational for downstream\napplications such as motion forecasting and autonomous navigation. However,\nprevailing approaches often depend on computationally intensive heuristics or\nlatent anchor representations that lack interpretability and controllability.\nIn this work, we propose a novel framework for learning fixed-dimensional\nembeddings for short trajectories by leveraging a Transformer encoder trained\nwith a contrastive triplet loss that emphasize the importance of discriminative\nfeature spaces for trajectory data. We analyze the influence of Cosine and\nFFT-based similarity metrics within the contrastive learning paradigm, with a\nfocus on capturing the nuanced directional intent that characterizes short-term\nmaneuvers. Our empirical evaluation on the Argoverse 2 dataset demonstrates\nthat embeddings shaped by Cosine similarity objectives yield superior\nclustering of trajectories by both semantic and directional attributes,\noutperforming FFT-based baselines in retrieval tasks. Notably, we show that\ncompact Transformer architectures, even with low-dimensional embeddings (e.g.,\n16 dimensions, but qualitatively down to 4), achieve a compelling balance\nbetween retrieval performance (minADE, minFDE) and computational overhead,\naligning with the growing demand for scalable and interpretable motion priors\nin real-time systems. The resulting embeddings provide a compact, semantically\nmeaningful, and efficient representation of trajectory data, offering a robust\nalternative to heuristic similarity measures and paving the way for more\ntransparent and controllable motion forecasting pipelines.", "published": "2025-06-03 07:53:04", "link": "http://arxiv.org/abs/2506.02571v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DCI: Dual-Conditional Inversion for Boosting Diffusion-Based Image Editing", "abstract": "Diffusion models have achieved remarkable success in image generation and\nediting tasks. Inversion within these models aims to recover the latent noise\nrepresentation for a real or generated image, enabling reconstruction, editing,\nand other downstream tasks. However, to date, most inversion approaches suffer\nfrom an intrinsic trade-off between reconstruction accuracy and editing\nflexibility. This limitation arises from the difficulty of maintaining both\nsemantic alignment and structural consistency during the inversion process. In\nthis work, we introduce Dual-Conditional Inversion (DCI), a novel framework\nthat jointly conditions on the source prompt and reference image to guide the\ninversion process. Specifically, DCI formulates the inversion process as a\ndual-condition fixed-point optimization problem, minimizing both the latent\nnoise gap and the reconstruction error under the joint guidance. This design\nanchors the inversion trajectory in both semantic and visual space, leading to\nmore accurate and editable latent representations. Our novel setup brings new\nunderstanding to the inversion process. Extensive experiments demonstrate that\nDCI achieves state-of-the-art performance across multiple editing tasks,\nsignificantly improving both reconstruction quality and editing precision.\nFurthermore, we also demonstrate that our method achieves strong results in\nreconstruction tasks, implying a degree of robustness and generalizability\napproaching the ultimate goal of the inversion process.", "published": "2025-06-03 07:46:44", "link": "http://arxiv.org/abs/2506.02560v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Kernel-based Unsupervised Embedding Alignment for Enhanced Visual Representation in Vision-language Models", "abstract": "Vision-language models, such as CLIP, have achieved significant success in\naligning visual and textual representations, becoming essential components of\nmany multi-modal large language models (MLLMs) like LLaVA and OpenFlamingo.\nHowever, numerous studies have identified CLIP's limited fine-grained\nperception as a critical drawback, leading to substantial failures in\ndownstream MLLMs. In contrast, vision-centric foundation models like DINOv2\ndemonstrate remarkable capabilities in capturing fine details from images. In\nthis work, we propose a novel kernel-based method to align CLIP's visual\nrepresentation with that of DINOv2, ensuring that the resulting embeddings\nmaintain compatibility with text embeddings while enhancing perceptual\ncapabilities. Our alignment objective is designed for efficient stochastic\noptimization. Following this image-only alignment fine-tuning, the visual\nencoder retains compatibility with the frozen text encoder and exhibits\nsignificant improvements in zero-shot object recognition, fine-grained spatial\nreasoning, and localization. By integrating the aligned visual encoder,\ndownstream MLLMs also demonstrate enhanced performance.", "published": "2025-06-03 07:44:43", "link": "http://arxiv.org/abs/2506.02557v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SurgVLM: A Large Vision-Language Model and Systematic Evaluation Benchmark for Surgical Intelligence", "abstract": "Foundation models have achieved transformative success across biomedical\ndomains by enabling holistic understanding of multimodal data. However, their\napplication in surgery remains underexplored. Surgical intelligence presents\nunique challenges - requiring surgical visual perception, temporal analysis,\nand reasoning. Existing general-purpose vision-language models fail to address\nthese needs due to insufficient domain-specific supervision and the lack of a\nlarge-scale high-quality surgical database. To bridge this gap, we propose\nSurgVLM, one of the first large vision-language foundation models for surgical\nintelligence, where this single universal model can tackle versatile surgical\ntasks. To enable this, we construct a large-scale multimodal surgical database,\nSurgVLM-DB, comprising over 1.81 million frames with 7.79 million\nconversations, spanning more than 16 surgical types and 18 anatomical\nstructures. We unify and reorganize 23 public datasets across 10 surgical\ntasks, followed by standardizing labels and doing hierarchical vision-language\nalignment to facilitate comprehensive coverage of gradually finer-grained\nsurgical tasks, from visual perception, temporal analysis, to high-level\nreasoning. Building upon this comprehensive dataset, we propose SurgVLM, which\nis built upon Qwen2.5-VL, and undergoes instruction tuning to 10+ surgical\ntasks. We further construct a surgical multimodal benchmark, SurgVLM-Bench, for\nmethod evaluation. SurgVLM-Bench consists of 6 popular and widely-used datasets\nin surgical domain, covering several crucial downstream tasks. Based on\nSurgVLM-Bench, we evaluate the performance of our SurgVLM (3 SurgVLM variants:\nSurgVLM-7B, SurgVLM-32B, and SurgVLM-72B), and conduct comprehensive\ncomparisons with 14 mainstream commercial VLMs (e.g., GPT-4o, Gemini 2.0 Flash,\nQwen2.5-Max).", "published": "2025-06-03 07:44:41", "link": "http://arxiv.org/abs/2506.02555v1", "categories": ["cs.CV", "68T45", "I.2.10"], "primary_category": "cs.CV"}
{"title": "HiLO: High-Level Object Fusion for Autonomous Driving using Transformers", "abstract": "The fusion of sensor data is essential for a robust perception of the\nenvironment in autonomous driving. Learning-based fusion approaches mainly use\nfeature-level fusion to achieve high performance, but their complexity and\nhardware requirements limit their applicability in near-production vehicles.\nHigh-level fusion methods offer robustness with lower computational\nrequirements. Traditional methods, such as the Kalman filter, dominate this\narea. This paper modifies the Adapted Kalman Filter (AKF) and proposes a novel\ntransformer-based high-level object fusion method called HiLO. Experimental\nresults demonstrate improvements of $25.9$ percentage points in $\\textrm{F}_1$\nscore and $6.1$ percentage points in mean IoU. Evaluation on a new large-scale\nreal-world dataset demonstrates the effectiveness of the proposed approaches.\nTheir generalizability is further validated by cross-domain evaluation between\nurban and highway scenarios. Code, data, and models are available at\nhttps://github.com/rst-tu-dortmund/HiLO .", "published": "2025-06-03 07:44:35", "link": "http://arxiv.org/abs/2506.02554v1", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Technical Report for Ego4D Long-Term Action Anticipation Challenge 2025", "abstract": "In this report, we present a novel three-stage framework developed for the\nEgo4D Long-Term Action Anticipation (LTA) task. Inspired by recent advances in\nfoundation models, our method consists of three stages: feature extraction,\naction recognition, and long-term action anticipation. First, visual features\nare extracted using a high-performance visual encoder. The features are then\nfed into a Transformer to predict verbs and nouns, with a verb-noun\nco-occurrence matrix incorporated to enhance recognition accuracy. Finally, the\npredicted verb-noun pairs are formatted as textual prompts and input into a\nfine-tuned large language model (LLM) to anticipate future action sequences.\nOur framework achieves first place in this challenge at CVPR 2025, establishing\na new state-of-the-art in long-term action prediction. Our code will be\nreleased at https://github.com/CorrineQiu/Ego4D-LTA-Challenge-2025.", "published": "2025-06-03 07:36:52", "link": "http://arxiv.org/abs/2506.02550v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Probabilistic Online Event Downsampling", "abstract": "Event cameras capture scene changes asynchronously on a per-pixel basis,\nenabling extremely high temporal resolution. However, this advantage comes at\nthe cost of high bandwidth, memory, and computational demands. To address this,\nprior work has explored event downsampling, but most approaches rely on fixed\nheuristics or threshold-based strategies, limiting their adaptability. Instead,\nwe propose a probabilistic framework, POLED, that models event importance\nthrough an event-importance probability density function (ePDF), which can be\narbitrarily defined and adapted to different applications. Our approach\noperates in a purely online setting, estimating event importance on-the-fly\nfrom raw event streams, enabling scene-specific adaptation. Additionally, we\nintroduce zero-shot event downsampling, where downsampled events must remain\nusable for models trained on the original event stream, without task-specific\nadaptation. We design a contour-preserving ePDF that prioritizes structurally\nimportant events and evaluate our method across four datasets and tasks--object\nclassification, image interpolation, surface normal estimation, and object\ndetection--demonstrating that intelligent sampling is crucial for maintaining\nperformance under event-budget constraints.", "published": "2025-06-03 07:33:11", "link": "http://arxiv.org/abs/2506.02547v1", "categories": ["cs.CV", "cs.ET"], "primary_category": "cs.CV"}
{"title": "HIEGNet: A Heterogenous Graph Neural Network Including the Immune Environment in Glomeruli Classification", "abstract": "Graph Neural Networks (GNNs) have recently been found to excel in\nhistopathology. However, an important histopathological task, where GNNs have\nnot been extensively explored, is the classification of glomeruli health as an\nimportant indicator in nephropathology. This task presents unique difficulties,\nparticularly for the graph construction, i.e., the identification of nodes,\nedges, and informative features. In this work, we propose a pipeline composed\nof different traditional and machine learning-based computer vision techniques\nto identify nodes, edges, and their corresponding features to form a\nheterogeneous graph. We then proceed to propose a novel heterogeneous GNN\narchitecture for glomeruli classification, called HIEGNet, that integrates both\nglomeruli and their surrounding immune cells. Hence, HIEGNet is able to\nconsider the immune environment of each glomerulus in its classification. Our\nHIEGNet was trained and tested on a dataset of Whole Slide Images from kidney\ntransplant patients. Experimental results demonstrate that HIEGNet outperforms\nseveral baseline models and generalises best between patients among all\nbaseline models. Our implementation is publicly available at\nhttps://github.com/nklsKrmnn/HIEGNet.git.", "published": "2025-06-03 07:28:25", "link": "http://arxiv.org/abs/2506.02542v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "Bounded Discrete Bridges", "abstract": "In 2010 Banderier and Nicodeme consider the height of bounded discrete\nbridges and conclude to a limiting Rayleigh distribution. This result is\ncorrect although their proof is partly erroneous. They make asymptotic\nsimplifications based upon dominance properties of the roots of the kernel of\nthe walk within a disk centered at the origin, but these dominance properties\napply only upon a positive real segment. However the very good agreement of\nsimulations with their asymptotic expansion of the probability distribution in\ncase of {\\L}ukasiewicz bridges let us think that their proof could be\ncorrected. This is the scope of the present article which provides\n  a proof using the dominance property only in its domain of validity. We also\nconsider the case of periodic walks, a topic not considered in\nBanderier-Nicodeme2010. We limit ourselves to walks whose characteristic\npolynomial decomposes over $\\bC$ without repeated factors.", "published": "2025-06-03 15:19:54", "link": "http://arxiv.org/abs/2506.02982v1", "categories": ["math.PR", "cs.DM", "05A15, 05A16, 33C45", "G.2.1"], "primary_category": "math.PR"}
{"title": "Boolean-network simplification and rule fitting to unravel chemotherapy resistance in non-small cell lung cancer", "abstract": "Boolean networks are powerful frameworks for capturing the logic of\ngene-regulatory circuits, yet their combinatorial explosion hampers exhaustive\nanalyses. Here, we present a systematic reduction of a 31-node Boolean model\nthat describes cisplatin- and pemetrexed-resistance in non-small-cell lung\ncancer to a compact 9-node core that exactly reproduces the original attractor\nlandscape. The streamlined network shrinks the state space by four orders of\nmagnitude, enabling rapid exploration of critical control points, rules fitting\nand candidate therapeutic targets. Extensive synchronous and asynchronous\nsimulations confirm that the three clinically relevant steady states and their\nbasins of attraction are conserved and reflect resistance frequencies close to\nthose reported in clinical studies. The reduced model provides an accessible\nscaffold for future mechanistic and drug-discovery studies.", "published": "2025-06-03 06:56:26", "link": "http://arxiv.org/abs/2506.02525v1", "categories": ["cs.DM"], "primary_category": "cs.DM"}
{"title": "MMM4Rec: An Transfer-Efficient Framework for Multi-modal Sequential Recommendation", "abstract": "Sequential Recommendation (SR) systems model user preferences by analyzing\ninteraction histories. Although transferable multi-modal SR architectures\ndemonstrate superior performance compared to traditional ID-based approaches,\ncurrent methods incur substantial fine-tuning costs when adapting to new\ndomains due to complex optimization requirements and negative transfer effects\n- a significant deployment bottleneck that hinders engineers from efficiently\nrepurposing pre-trained models for novel application scenarios with minimal\ntuning overhead. We propose MMM4Rec (Multi-Modal Mamba for Sequential\nRecommendation), a novel multi-modal SR framework that incorporates a dedicated\nalgebraic constraint mechanism for efficient transfer learning. By combining\nState Space Duality (SSD)'s temporal decay properties with a time-aware\nmodeling design, our model dynamically prioritizes key modality information,\novercoming limitations of Transformer-based approaches. The framework\nimplements a constrained two-stage process: (1) sequence-level cross-modal\nalignment via shared projection matrices, followed by (2) temporal fusion using\nour newly designed Cross-SSD module and dual-channel Fourier adaptive\nfiltering. This architecture maintains semantic consistency while suppressing\nnoise propagation.MMM4Rec achieves rapid fine-tuning convergence with simple\ncross-entropy loss, significantly improving multi-modal recommendation accuracy\nwhile maintaining strong transferability. Extensive experiments demonstrate\nMMM4Rec's state-of-the-art performance, achieving the maximum 31.78% NDCG@10\nimprovement over existing models and exhibiting 10 times faster average\nconvergence speed when transferring to large-scale downstream datasets.", "published": "2025-06-03 14:18:19", "link": "http://arxiv.org/abs/2506.02916v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Combining social relations and interaction data in Recommender System with Graph Convolution Collaborative Filtering", "abstract": "A recommender system is an important subject in the field of data mining,\nwhere the item rating information from users is exploited and processed to make\nsuitable recommendations with all other users. The recommender system creates\nconvenience for e-commerce users and stimulates the consumption of items that\nare suitable for users. In addition to e-commerce, a recommender system is also\nused to provide recommendations on books to read, movies to watch, courses to\ntake or websites to visit. Similarity between users is an important impact for\nrecommendation, which could be calculated from the data of past user ratings of\nthe item by methods of collaborative filtering, matrix factorization or\nsingular vector decomposition. In the development of graph data mining\ntechniques, the relationships between users and items can be represented by\nmatrices from which collaborative filtering could be done with the larger\ndatabase, more accurate and faster in calculation. All these data can be\nrepresented graphically and mined by today's highly developed graph neural\nnetwork models. On the other hand, users' social friendship data also influence\nconsumption habits because recommendations from friends will be considered more\ncarefully than information sources. However, combining a user's friend\ninfluence and the similarity between users whose similar shopping habits is\nchallenging. Because the information is noisy and it affects each particular\ndata set in different ways. In this study, we present the input data processing\nmethod to remove outliers which are single reviews or users with little\ninteraction with the items; the next proposed model will combine the social\nrelationship data and the similarity in the rating history of users to improve\nthe accuracy and recall of the recommender system.", "published": "2025-06-03 13:04:00", "link": "http://arxiv.org/abs/2506.02834v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "UTCS: Effective Unsupervised Temporal Community Search with Pre-training of Temporal Dynamics and Subgraph Knowledge", "abstract": "In many real-world applications, the evolving relationships between entities\ncan be modeled as temporal graphs, where each edge has a timestamp representing\nthe interaction time.\n  As a fundamental problem in graph analysis, {\\it community search (CS)} in\ntemporal graphs has received growing attention but exhibits two major\nlimitations: (1) Traditional methods typically require predefined subgraph\nstructures, which are not always known in advance. (2) Learning-based methods\nstruggle to capture temporal interaction information. To fill this research\ngap, in this paper, we propose an effective \\textbf{U}nsupervised\n\\textbf{T}emporal \\textbf{C}ommunity \\textbf{S}earch with pre-training of\ntemporal dynamics and subgraph knowledge model (\\textbf{\\model}).\n\\model~contains two key stages: offline pre-training and online search. In the\nfirst stage, we introduce multiple learning objectives to facilitate the\npre-training process in the unsupervised learning setting. In the second stage,\nwe identify a candidate subgraph and compute community scores using the\npre-trained node representations and a novel scoring mechanism to determine the\nfinal community members. Experiments on five real-world datasets demonstrate\nthe effectiveness.", "published": "2025-06-03 12:11:34", "link": "http://arxiv.org/abs/2506.02784v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Learning Binarized Representations with Pseudo-positive Sample Enhancement for Efficient Graph Collaborative Filtering", "abstract": "Learning vectorized embeddings is fundamental to many recommender systems for\nuser-item matching. To enable efficient online inference, representation\nbinarization, which embeds latent features into compact binary sequences, has\nrecently shown significant promise in optimizing both memory usage and\ncomputational overhead. However, existing approaches primarily focus on\nnumerical quantization, neglecting the associated information loss, which often\nresults in noticeable performance degradation. To address these issues, we\nstudy the problem of graph representation binarization for efficient\ncollaborative filtering. Our findings indicate that explicitly mitigating\ninformation loss at various stages of embedding binarization has a significant\npositive impact on performance. Building on these insights, we propose an\nenhanced framework, BiGeaR++, which specifically leverages supervisory signals\nfrom pseudo-positive samples, incorporating both real item data and latent\nembedding samples. Compared to its predecessor BiGeaR, BiGeaR++ introduces a\nfine-grained inference distillation mechanism and an effective embedding sample\nsynthesis approach. Empirical evaluations across five real-world datasets\ndemonstrate that the new designs in BiGeaR++ work seamlessly well with other\nmodules, delivering substantial improvements of around 1%-10% over BiGeaR and\nthus achieving state-of-the-art performance compared to the competing methods.\nOur implementation is available at https://github.com/QueYork/BiGeaR-SS.", "published": "2025-06-03 11:11:43", "link": "http://arxiv.org/abs/2506.02750v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "NextQuill: Causal Preference Modeling for Enhancing LLM Personalization", "abstract": "Personalizing large language models (LLMs) for individual users has become\nincreasingly important as they are progressively integrated into real-world\napplications to support users' daily lives. However, existing personalization\napproaches often fail to distinguish which components of model predictions and\ntraining data truly reflect user preferences, leading to superficial\npersonalization alignment. In this paper, we introduce NextQuill, a novel LLM\npersonalization alignment framework grounded in causal preference modeling. We\napproach personalization from a causal perspective, treating both model\npredictions and ground-truth data generation as outcomes influenced by user\npreferences, along with other factors. We define the true preference effect as\nthe causal impact of user history (which reflects preferences) on each token\nprediction or data generation instance, estimated through causal intervention\ntechniques. Building on this insight, NextQuill introduces two complementary\nalignment strategies: (1) aligning model-internal causal preference effects on\npredictions with those reflected in ground-truth data, rather than\nindiscriminately fitting predictions, and (2) focusing on fitting\npreference-bearing tokens identified via ground-truth data preference effects,\nrather than treating all tokens uniformly. By integrating these strategies,\nNextQuill shifts the alignment process toward learning from causal preference\neffects, facilitating more effective and personalized adaptation. Experiments\nacross multiple personalization benchmarks demonstrate that NextQuill\nsignificantly improves personalization quality, offering a principled, causal\nfoundation for LLM personalization. Our codes are available on\nhttps://github.com/juntaoyou/NextQuill.", "published": "2025-06-03 02:08:55", "link": "http://arxiv.org/abs/2506.02368v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Joint Beamforming for NOMA Assisted Pinching Antenna Systems (PASS)", "abstract": "Pinching antenna system (PASS) configures the positions of pinching antennas\n(PAs) along dielectric waveguides to change both large-scale fading and\nsmall-scale scattering, which is known as pinching beamforming. A novel\nnon-orthogonal multiple access (NOMA) assisted PASS framework is proposed for\ndownlink multi-user multiple-input multiple-output (MIMO) communications. The\ntransmit power minimization problem is formulated to jointly optimize the\ntransmit beamforming, pinching beamforming, and power allocation. To solve this\nhighly nonconvex problem, both gradient-based and swarm-based optimization\nmethods are developed. 1) For gradient-based method, a\nmajorization-minimization and penalty dual decomposition (MM-PDD) algorithm is\ndeveloped. The Lipschitz gradient surrogate function is constructed based on MM\nto tackle the nonconvex terms of this problem. Then, the joint optimization\nproblem is decomposed into subproblems that are alternatively optimized based\non PDD to obtain stationary closed-form solutions. 2) For swarm-based method, a\nfast-convergent particle swarm optimization and zero forcing (PSO-ZF) algorithm\nis proposed. Specifically, the PA position-seeking particles are constructed to\nexplore high-quality pinching beamforming solutions. Moreover, ZF-based\ntransmit beamforming is utilized by each particle for fast fitness function\nevaluation. Simulation results demonstrate that: i) The proposed NOMA assisted\nPASS and algorithms outperforms the conventional NOMA assisted massive antenna\nsystem. The proposed framework reduces over 95.22% transmit power compared to\nconventional massive MIMO-NOMA systems. ii) Swarm-based optimization\noutperforms gradient-based optimization by searching effective solution\nsubspace to avoid stuck in undesirable local optima.", "published": "2025-06-03 16:41:13", "link": "http://arxiv.org/abs/2506.03063v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Adversarial quantum channel discrimination", "abstract": "We introduce a new framework for quantum channel discrimination in an\nadversarial setting, where the tester plays against an adversary who accesses\nthe environmental system and possesses internal quantum memory to perform\nadaptive strategies. We show that in asymmetric hypothesis testing, the optimal\ntype-II error exponent is precisely characterized by the minimum output channel\ndivergence, a new notion of quantum channel divergence in the worst-case\nscenario. This serves as a direct analog of the quantum Stein's lemma in the\nadversarial channel discrimination. Notably, the optimal error exponent can be\nachieved via simple non-adaptive strategies by the adversary, and its value can\nbe efficiently computed despite its regularization. The strong converse\nproperty for quantum channel discrimination also holds in general. This\nadversarial quantum Stein's lemma is proved by new chain rules for measured and\nsandwiched relative entropies. Moreover, we derive a generalized version of the\nentropy accumulation theorem between two arbitrary sequences of quantum\nchannels, extending the existing results from entropy to divergence and\nproviding a solution to the dual formulation of the open problem presented in\n[IEEE FOCS, pp. 844-850 (2022)].", "published": "2025-06-03 16:39:01", "link": "http://arxiv.org/abs/2506.03060v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Extremely Large-Scale Movable Antenna-Enabled Multiuser Communications: Modeling and Optimization", "abstract": "Movable antenna (MA) has been recognized as a promising technology to improve\ncommunication performance in future wireless networks such as 6G. To unleash\nits potential, this paper proposes a novel architecture, namely extremely\nlarge-scale MA (XL-MA), which allows flexible antenna/subarray positioning over\nan extremely large spatial region for effectively enhancing near-field effects\nand spatial multiplexing performance. In particular, this paper studies an\nuplink XL-MA-enabled multiuser system, where single-antenna users distributed\nin a coverage area are served by a base station (BS) equipped with multiple\nmovable subarrays. We begin by presenting a spatially non-stationary channel\nmodel to capture the near-field effects, including positiondependent\nlarge-scale channel gains and line-of-sight visibility. To evaluate system\nperformance, we further derive a closedform approximation of the expected\nweighted sum rate under maximum ratio combining (MRC), revealing that\noptimizing XLMA placement enhances user channel power gain to increase desired\nsignal power and reduces channel correlation to decreases multiuser\ninterference. Building upon this, we formulate an antenna placement\noptimization problem to maximize the expected weighted sum rate, leveraging\nstatistical channel conditions and user distribution. To efficiently solve this\nchallenging non-linear binary optimization problem, we propose a\npolynomial-time successive replacement algorithm. Simulation results\ndemonstrate that the proposed XL-MA placement strategy achieves nearoptimal\nperformance, significantly outperforming benchmark schemes based on\nconventional fixed-position antennas.", "published": "2025-06-03 10:50:51", "link": "http://arxiv.org/abs/2506.02735v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Spatially Correlated multi-RIS Communication: The Effect of Inter-Operator Interference", "abstract": "A multi-operator wireless communication system is studied where each operator\nis equipped with a reconfigurable intelligent surface (RIS) to enhance its\ncommunication quality. RISs controlled by different operators affect the system\nperformance of one another due to the inherently rapid phase shift adjustments\nthat occur on an independent basis. The system performance of such a\ncommunication scenario is analytically studied for the practical case where\nspatial correlation occurs at RIS of arbitrary size. The proposed framework is\nquite general since it is analyzed under Nakagami-$m$ channel fading\nconditions. Finally, the derived analytical results are verified via numerical\nand simulation trials as well as some new and useful engineering outcomes are\nrevealed.", "published": "2025-06-03 09:14:53", "link": "http://arxiv.org/abs/2506.02666v1", "categories": ["cs.IT", "cs.PF", "math.IT"], "primary_category": "cs.IT"}
{"title": "Maximizing the Promptness of Metaverse Systems using Edge Computing by Deep Reinforcement Learning", "abstract": "Metaverse and Digital Twin (DT) have attracted much academic and industrial\nattraction to approach the future digital world. This paper introduces the\nadvantages of deep reinforcement learning (DRL) in assisting Metaverse\nsystem-based Digital Twin. In this system, we assume that it includes several\nMetaverse User devices collecting data from the real world to transfer it into\nthe virtual world, a Metaverse Virtual Access Point (MVAP) undertaking the\nprocessing of data, and an edge computing server that receives the offloading\ndata from the MVAP. The proposed model works under a dynamic environment with\nvarious parameters changing over time. The experiment results show that our\nproposed DRL algorithm is suitable for offloading tasks to ensure the\npromptness of DT in a dynamic environment.", "published": "2025-06-03 09:10:31", "link": "http://arxiv.org/abs/2506.02657v1", "categories": ["cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.IT"}
{"title": "Joint Optimization based on Two-phase GNN in RIS- and DF-assisted MISO Systems with Fine-grained Rate Demands", "abstract": "Reconfigurable intelligent Surfaces (RIS) and half-duplex decoded and\nforwarded (DF) relays can collaborate to optimize wireless signal propagation\nin communication systems. Users typically have different rate demands and are\nclustered into groups in practice based on their requirements, where the former\nresults in the trade-off between maximizing the rate and satisfying\nfine-grained rate demands, while the latter causes a trade-off between\ninter-group competition and intra-group cooperation when maximizing the sum\nrate. However, traditional approaches often overlook the joint optimization\nencompassing both of these trade-offs, disregarding potential optimal solutions\nand leaving some users even consistently at low date rates. To address this\nissue, we propose a novel joint optimization model for a RIS- and DF-assisted\nmultiple-input single-output (MISO) system where a base station (BS) is with\nmultiple antennas transmits data by multiple RISs and DF relays to serve\ngrouped users with fine-grained rate demands. We design a new loss function to\nnot only optimize the sum rate of all groups but also adjust the satisfaction\nratio of fine-grained rate demands by modifying the penalty parameter. We\nfurther propose a two-phase graph neural network (GNN) based approach that\ninputs channel state information (CSI) to simultaneously and autonomously learn\nefficient phase shifts, beamforming, and relay selection. The experimental\nresults demonstrate that the proposed method significantly improves system\nperformance.", "published": "2025-06-03 08:57:25", "link": "http://arxiv.org/abs/2506.02642v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Zero-Energy RIS-Assisted Communications With Noise Modulation and Interference-Based Energy Harvesting", "abstract": "To advance towards carbon-neutrality and improve the limited {performance} of\nconventional passive wireless communications, in this paper, we investigate the\nintegration of noise modulation with zero-energy reconfigurable intelligent\nsurfaces (RISs). In particular, the RIS reconfigurable elements (REs) are\ndivided into two groups: one for beamforming the desired signals in reflection\nmode and another for harvesting energy from interference signals in an\nabsorption mode, providing the power required for RIS operation. Since the\nharvested energy is a random variable, a random number of REs can beamform the\nsignals, while the remainder blindly reflects them. We present a closed-form\nsolution and a search algorithm for REs allocation, jointly optimizing both the\nenergy harvesting (EH) and communication performance. Considering the\nrepetition coding technique and discrete phase shifts, we derive analytical\nexpressions for the energy constrained success rate, bit error rate, optimal\nthreshold, mutual information, {and energy efficiency}. Numerical and\nsimulation results confirm the effectiveness of the algorithm and expressions,\ndemonstrating the superiority of the proposed integration over conventional\nnoise-modulation systems. It is shown that by properly allocating the REs, both\nthe EH and communication performance can be improved in low to moderate\ninterference scenarios, while the latter is restricted in the high-interference\nregime.", "published": "2025-06-03 08:40:24", "link": "http://arxiv.org/abs/2506.02625v1", "categories": ["cs.IT", "cs.ET", "cs.NI", "math.IT"], "primary_category": "cs.IT"}
{"title": "A Novel Deep Reinforcement Learning Method for Computation Offloading in Multi-User Mobile Edge Computing with Decentralization", "abstract": "Mobile edge computing (MEC) allows appliances to offload workloads to\nneighboring MEC servers that have the potential for computation-intensive tasks\nwith limited computational capabilities. This paper studied how deep\nreinforcement learning (DRL) algorithms are used in an MEC system to find\nfeasible decentralized dynamic computation offloading strategies, which leads\nto the construction of an extensible MEC system that operates effectively with\nfinite feedback. Even though the Deep Deterministic Policy Gradient (DDPG)\nalgorithm, subject to their knowledge of the MEC system, can be used to\nallocate powers of both computation offloading and local execution, to learn a\ncomputation offloading policy for each user independently, we realized that\nthis solution still has some inherent weaknesses. Hence, we introduced a new\napproach for this problem based on the Twin Delayed DDPG algorithm, which\nenables us to overcome this proneness and investigate cases where mobile users\nare portable. Numerical results showed that individual users can autonomously\nlearn adequate policies through the proposed approach. Besides, the performance\nof the suggested solution exceeded the conventional DDPG-based power control\nstrategy.", "published": "2025-06-03 05:22:02", "link": "http://arxiv.org/abs/2506.02458v1", "categories": ["cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.IT"}
{"title": "Baseband-Free End-to-End Communication System Based on Diffractive Deep Neural Network", "abstract": "Diffractive deep neural network (D2NN), also referred to as reconfigurable\nintelligent metasurface based deep neural networks (Rb-DNNs) or stacked\nintelligent metasurfaces (SIMs) in the field of wireless communications, has\nemerged as a promising signal processing paradigm that enables\ncomputing-by-propagation. However, existing architectures are limited to\nimplementing specific functions such as precoding and combining, while still\nrelying on digital baseband modules for other essential tasks like modulation\nand detection. In this work, we propose a baseband-free end-to-end (BBF-E2E)\nwireless communication system where modulation, beamforming, and detection are\njointly realized through the propagation of electromagnetic (EM) waves. The\nBBF-E2E system employs D2NNs at both the transmitter and the receiver, forming\nan autoencoder architecture optimized as a complex-valued neural network. The\ntransmission coefficients of each metasurface layer are trained using the\nmini-batch stochastic gradient descent method to minimize the cross-entropy\nloss. To reduce computational complexity during diffraction calculation, the\nangular spectrum method (ASM) is adopted in place of the Rayleigh-Sommerfeld\nformula. Extensive simulations demonstrate that BBF-E2E achieves robust symbol\ntransmission under challenging channel conditions with significantly reduced\nhardware requirements. In particular, the proposed system matches the\nperformance of a conventional multi-antenna system with 81 RF chains while\nrequiring only a single RF chain and 1024 passive elements of metasurfaces.\nThese results highlight the potential of wave-domain neural computing to\nreplace digital baseband modules in future wireless transceivers.", "published": "2025-06-03 03:56:09", "link": "http://arxiv.org/abs/2506.02411v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Asymptotically Optimal Linear Best Feasible Arm Identification with Fixed Budget", "abstract": "The challenge of identifying the best feasible arm within a fixed budget has\nattracted considerable interest in recent years. However, a notable gap remains\nin the literature: the exact exponential rate at which the error probability\napproaches zero has yet to be established, even in the relatively simple\nsetting of $K$-armed bandits with Gaussian noise. In this paper, we address\nthis gap by examining the problem within the context of linear bandits. We\nintroduce a novel algorithm for best feasible arm identification that\nguarantees an exponential decay in the error probability. Remarkably, the decay\nrate -- characterized by the exponent -- matches the theoretical lower bound\nderived using information-theoretic principles. Our approach leverages a\nposterior sampling framework embedded within a game-based sampling rule\ninvolving a min-learner and a max-learner. This strategy shares its foundations\nwith Thompson sampling, but is specifically tailored to optimize the\nidentification process under fixed-budget constraints. Furthermore, we validate\nthe effectiveness of our algorithm through comprehensive empirical evaluations\nacross various problem instances with different levels of complexity. The\nresults corroborate our theoretical findings and demonstrate that our method\noutperforms several benchmark algorithms in terms of both accuracy and\nefficiency.", "published": "2025-06-03 02:56:26", "link": "http://arxiv.org/abs/2506.02386v1", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "Finite State Dimension and The Davenport Erd\u0151s Theorem", "abstract": "A 1952 result of Davenport and Erd\\H{o}s states that if $p$ is an\ninteger-valued polynomial, then the real number $0.p(1)p(2)p(3)\\dots$ is Borel\nnormal in base ten. A later result of Nakai and Shiokawa extends this result to\npolynomials with arbitrary real coefficients and all bases $b\\geq 2$. It is\nwell-known that finite-state dimension, a finite-state effectivization of the\nclassical Hausdorff dimension, characterizes the Borel normal sequences as\nprecisely those sequences of finite-state dimension 1. For an infinite set of\nnatural numbers, and a base $b\\geq 2$, the base $b$ Copeland-Erd\\H{o}s sequence\nof $A$, $CE_b(A)$, is the infinite sequence obtained by concatenating the base\n$b$ expressions of the numbers in $A$ in increasing order. In this work we\ninvestigate the possible relationships between the finite-state dimensions of\n$CE_b(A)$ and $CE_b(p(A))$ where $p$ is a polynomial. We show that, if the\npolynomial is permitted to have arbitrary real coefficients, then for any\n$s,s^\\prime$ in the unit interval, there is a set $A$ of natural numbers and a\nlinear polynomial $p$ so that the finite-state dimensions of $CE_b(A)$ and\n$CE_b(p(A))$ are $s$ and $s^\\prime$ respectively. We also demonstrate that\nlinear polynomials with rational coefficients do not change the finite-state\ndimension of any Copeland-Erd\\H{o}s sequence, but there exist polynomials with\nrational coefficients of every larger integer degree that change the\nfinite-state dimension of some sequence. To prove our main results, we develop\ntechniques involving taking concatenated prefixes of a sequence as well as\ninserting a density zero set of strings into a sequence that may be of\nindependent interest.", "published": "2025-06-03 00:01:49", "link": "http://arxiv.org/abs/2506.02332v1", "categories": ["cs.IT", "math.IT", "68P30, 11K16, 03D32"], "primary_category": "cs.IT"}
{"title": "Not All Tokens Are Meant to Be Forgotten", "abstract": "Large Language Models (LLMs), pre-trained on massive text corpora, exhibit\nremarkable human-level language understanding, reasoning, and decision-making\nabilities. However, they tend to memorize unwanted information, such as private\nor copyrighted content, raising significant privacy and legal concerns.\nUnlearning has emerged as a promising solution, but existing methods face a\nsignificant challenge of over-forgetting. This issue arises because they\nindiscriminately suppress the generation of all the tokens in forget samples,\nleading to a substantial loss of model utility. To overcome this challenge, we\nintroduce the Targeted Information Forgetting (TIF) framework, which consists\nof (1) a flexible targeted information identifier designed to differentiate\nbetween unwanted words (UW) and general words (GW) in the forget samples, and\n(2) a novel Targeted Preference Optimization approach that leverages Logit\nPreference Loss to unlearn unwanted information associated with UW and\nPreservation Loss to retain general information in GW, effectively improving\nthe unlearning process while mitigating utility degradation. Extensive\nexperiments on the TOFU and MUSE benchmarks demonstrate that the proposed TIF\nframework enhances unlearning effectiveness while preserving model utility and\nachieving state-of-the-art results.", "published": "2025-06-03 17:59:05", "link": "http://arxiv.org/abs/2506.03142v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Zero-Shot Time Series Forecasting with Covariates via In-Context Learning", "abstract": "Pretrained time series models, capable of zero-shot forecasting, have\ndemonstrated significant potential in enhancing both the performance and\naccessibility of time series forecasting. However, existing pretrained models\neither do not support covariates or fail to incorporate them effectively. We\nintroduce COSMIC, a zero-shot forecasting model that utilizes covariates via\nin-context learning. To address the challenge of data scarcity, we propose\nInformative Covariate Augmentation, which enables the training of COSMIC\nwithout requiring any datasets that include covariates. COSMIC achieves\nstate-of-the-art performance in zero-shot forecasting, both with and without\ncovariates. Our quantitative and qualitative analysis demonstrates that COSMIC\neffectively leverages covariates in zero-shot forecasting.", "published": "2025-06-03 17:56:48", "link": "http://arxiv.org/abs/2506.03128v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Validating remotely sensed biomass estimates with forest inventory data in the western US", "abstract": "Monitoring aboveground biomass (AGB) and its density (AGBD) at high\nresolution is essential for carbon accounting and ecosystem management. While\nNASA's spaceborne Global Ecosystem Dynamics Investigation (GEDI) LiDAR mission\nprovides globally distributed reference measurements for AGBD estimation, the\nmajority of commercial remote sensing products based on GEDI remain without\nrigorous or independent validation. Here, we present an independent regional\nvalidation of an AGBD dataset offered by terraPulse, Inc., based on independent\nreference data from the US Forest Service Forest Inventory and Analysis (FIA)\nprogram. Aggregated to 64,000-hectare hexagons and US counties across the US\nstates of Utah, Nevada, and Washington, we found very strong agreement between\nterraPulse and FIA estimates. At the hexagon scale, we report R2 = 0.88, RMSE =\n26.68 Mg/ha, and a correlation coefficient (r) of 0.94. At the county scale,\nagreement improves to R2 = 0.90, RMSE =32.62 Mg/ha, slope = 1.07, and r = 0.95.\nSpatial and statistical analyses indicated that terraPulse AGBD values tended\nto exceed FIA estimates in non-forest areas, likely due to FIA's limited\nsampling of non-forest vegetation. The terraPulse AGBD estimates also exhibited\nlower values in high-biomass forests, likely due to saturation effects in its\noptical remote-sensing covariates. This study advances operational carbon\nmonitoring by delivering a scalable framework for comprehensive AGBD validation\nusing independent FIA data, as well as a benchmark validation of a new\ncommercial dataset for global biomass monitoring.", "published": "2025-06-03 17:50:37", "link": "http://arxiv.org/abs/2506.03120v1", "categories": ["stat.AP", "cs.LG"], "primary_category": "stat.AP"}
{"title": "Rectified Flows for Fast Multiscale Fluid Flow Modeling", "abstract": "The statistical modeling of fluid flows is very challenging due to their\nmultiscale dynamics and extreme sensitivity to initial conditions. While\nrecently proposed conditional diffusion models achieve high fidelity, they\ntypically require hundreds of stochastic sampling steps at inference. We\nintroduce a rectified flow framework that learns a time-dependent velocity\nfield, transporting input to output distributions along nearly straight\ntrajectories. By casting sampling as solving an ordinary differential equation\n(ODE) along this straighter flow field, our method makes each integration step\nmuch more effective, using as few as eight steps versus (more than) 128 steps\nin standard score-based diffusion, without sacrificing predictive fidelity.\nExperiments on challenging multiscale flow benchmarks show that rectified flows\nrecover the same posterior distributions as diffusion models, preserve\nfine-scale features that MSE-trained baselines miss, and deliver\nhigh-resolution samples in a fraction of inference time.", "published": "2025-06-03 17:40:39", "link": "http://arxiv.org/abs/2506.03111v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "On Weak-to-Strong Generalization and f-Divergence", "abstract": "Weak-to-strong generalization (W2SG) has emerged as a promising paradigm for\nstimulating the capabilities of strong pre-trained models by leveraging\nsupervision from weaker supervisors. To improve the performance of the strong\nmodel, existing methods often require additional weak models or complex\nprocedures, leading to substantial computational and memory overhead. Motivated\nby the effectiveness of $f$-divergence loss in various machine learning\ndomains, we introduce $f$-divergence as an information-theoretic loss function\nframework in W2SG. Our theoretical analysis reveals fundamental limitations and\nequivalence of different $f$-divergence losses in W2SG, supported by sample\ncomplexity bounds and information-theoretic insights. We empirically\ndemonstrate that $f$-divergence loss, which generalizes widely-used metrics\nlike KL divergence, effectively improves generalization and noise tolerance of\nthe strong model in practice.", "published": "2025-06-03 17:40:08", "link": "http://arxiv.org/abs/2506.03109v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "From Flat to Hierarchical: Extracting Sparse Representations with Matching Pursuit", "abstract": "Motivated by the hypothesis that neural network representations encode\nabstract, interpretable features as linearly accessible, approximately\northogonal directions, sparse autoencoders (SAEs) have become a popular tool in\ninterpretability. However, recent work has demonstrated phenomenology of model\nrepresentations that lies outside the scope of this hypothesis, showing\nsignatures of hierarchical, nonlinear, and multi-dimensional features. This\nraises the question: do SAEs represent features that possess structure at odds\nwith their motivating hypothesis? If not, does avoiding this mismatch help\nidentify said features and gain further insights into neural network\nrepresentations? To answer these questions, we take a construction-based\napproach and re-contextualize the popular matching pursuits (MP) algorithm from\nsparse coding to design MP-SAE -- an SAE that unrolls its encoder into a\nsequence of residual-guided steps, allowing it to capture hierarchical and\nnonlinearly accessible features. Comparing this architecture with existing SAEs\non a mixture of synthetic and natural data settings, we show: (i) hierarchical\nconcepts induce conditionally orthogonal features, which existing SAEs are\nunable to faithfully capture, and (ii) the nonlinear encoding step of MP-SAE\nrecovers highly meaningful features, helping us unravel shared structure in the\nseemingly dichotomous representation spaces of different modalities in a\nvision-language model, hence demonstrating the assumption that useful features\nare solely linearly accessible is insufficient. We also show that the\nsequential encoder principle of MP-SAE affords an additional benefit of\nadaptive sparsity at inference time, which may be of independent interest.\nOverall, we argue our results provide credence to the idea that\ninterpretability should begin with the phenomenology of representations, with\nmethods emerging from assumptions that fit it.", "published": "2025-06-03 17:24:55", "link": "http://arxiv.org/abs/2506.03093v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Non-Asymptotic Length Generalization", "abstract": "Length generalization is the ability of a learning algorithm to learn a\nhypothesis which generalizes to longer inputs than the inputs in the training\nset. In this paper, we provide provable guarantees of length generalization for\nvarious classes of functions in an idealized setting. First, we formalize the\nframework of non-asymptotic length generalization, which requires a computable\nupper bound for the minimum input length that guarantees length generalization,\nas a function of the complexity of ground-truth function under some given\ncomplexity measure. We refer to this minimum input length to length generalize\nas length complexity. We show the Minimum-Complexity Interpolator learning\nalgorithm achieves optimal length complexity. We further show that whether a\nfunction class admits non-asymptotic length generalization is equivalent to the\ndecidability of its language equivalence problem, which implies that there is\nno computable upper bound for the length complexity of Context-Free Grammars.\nOn the positive side, we show that the length complexity of Deterministic\nFinite Automata is $2n - 2$ where $n$ is the number of states of the\nground-truth automaton. Our main results are upper bounds of length complexity\nfor a subset of a transformer-related function class called C-RASP (Yang &\nChiang, 2024). We show that the length complexity of 1-layer C-RASP functions\nis $O(T^2)$ when the ground-truth function has precision $T$, and that the\nlength complexity of 2-layer C-RASP functions is $O(T^{O(K)})$ when the\nground-truth function has precision $T$ and $K$ heads.", "published": "2025-06-03 17:09:34", "link": "http://arxiv.org/abs/2506.03085v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Agnostic Learning under Targeted Poisoning: Optimal Rates and the Role of Randomness", "abstract": "We study the problem of learning in the presence of an adversary that can\ncorrupt an $\\eta$ fraction of the training examples with the goal of causing\nfailure on a specific test point. In the realizable setting, prior work\nestablished that the optimal error under such instance-targeted poisoning\nattacks scales as $\\Theta(d\\eta)$, where $d$ is the VC dimension of the\nhypothesis class arXiv:2210.02713. In this work, we resolve the corresponding\nquestion in the agnostic setting. We show that the optimal excess error is\n$\\tilde{\\Theta}(\\sqrt{d\\eta})$, answering one of the main open problems left by\nHanneke et al. To achieve this rate, it is necessary to use randomized\nlearners: Hanneke et al. showed that deterministic learners can be forced to\nsuffer error close to 1, even under small amounts of poisoning. Perhaps\nsurprisingly, our upper bound remains valid even when the learner's random bits\nare fully visible to the adversary . In the other direction, our lower bound is\nstronger than standard PAC-style bounds: instead of tailoring a hard\ndistribution separately for each sample size, we exhibit a single fixed\ndistribution under which the adversary can enforce an excess error of\n$\\Omega(\\sqrt{d\\eta})$ infinitely often.", "published": "2025-06-03 16:53:20", "link": "http://arxiv.org/abs/2506.03075v1", "categories": ["cs.LG", "math.PR", "68Q32", "I.2.6"], "primary_category": "cs.LG"}
{"title": "GL-LowPopArt: A Nearly Instance-Wise Minimax Estimator for Generalized Low-Rank Trace Regression", "abstract": "We present `GL-LowPopArt`, a novel Catoni-style estimator for generalized\nlow-rank trace regression. Building on `LowPopArt` (Jang et al., 2024), it\nemploys a two-stage approach: nuclear norm regularization followed by matrix\nCatoni estimation. We establish state-of-the-art estimation error bounds,\nsurpassing existing guarantees (Fan et al., 2019; Kang et al., 2022), and\nreveal a novel experimental design objective, $\\mathrm{GL}(\\pi)$. The key\ntechnical challenge is controlling bias from the nonlinear inverse link\nfunction, which we address by our two-stage approach. We prove a *local*\nminimax lower bound, showing that our `GL-LowPopArt` enjoys instance-wise\noptimality up to the condition number of the ground-truth Hessian. Applications\ninclude generalized linear matrix completion, where `GL-LowPopArt` achieves a\nstate-of-the-art Frobenius error guarantee, and **bilinear dueling bandits**, a\nnovel setting inspired by general preference learning (Zhang et al., 2024). Our\nanalysis of a `GL-LowPopArt`-based explore-then-commit algorithm reveals a new,\npotentially interesting problem-dependent quantity, along with improved Borda\nregret bound than vectorization (Wu et al., 2024).", "published": "2025-06-03 16:52:24", "link": "http://arxiv.org/abs/2506.03074v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Causal Explainability of Machine Learning in Heart Failure Prediction from Electronic Health Records", "abstract": "The importance of clinical variables in the prognosis of the disease is\nexplained using statistical correlation or machine learning (ML). However, the\npredictive importance of these variables may not represent their causal\nrelationships with diseases. This paper uses clinical variables from a heart\nfailure (HF) patient cohort to investigate the causal explainability of\nimportant variables obtained in statistical and ML contexts. Due to inherent\nregression modeling, popular causal discovery methods strictly assume that the\ncause and effect variables are numerical and continuous. This paper proposes a\nnew computational framework to enable causal structure discovery (CSD) and\nscore the causal strength of mixed-type (categorical, numerical, binary)\nclinical variables for binary disease outcomes. In HF classification, we\ninvestigate the association between the importance rank order of three feature\ntypes: correlated features, features important for ML predictions, and causal\nfeatures. Our results demonstrate that CSD modeling for nonlinear causal\nrelationships is more meaningful than its linear counterparts. Feature\nimportance obtained from nonlinear classifiers (e.g., gradient-boosting trees)\nstrongly correlates with the causal strength of variables without\ndifferentiating cause and effect variables. Correlated variables can be causal\nfor HF, but they are rarely identified as effect variables. These results can\nbe used to add the causal explanation of variables important for ML-based\nprediction modeling.", "published": "2025-06-03 16:46:13", "link": "http://arxiv.org/abs/2506.03068v1", "categories": ["stat.ML", "cs.CY", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Provable Reinforcement Learning from Human Feedback with an Unknown Link Function", "abstract": "Link functions, which characterize how human preferences are generated from\nthe value function of an RL problem, are a crucial component in designing RLHF\nalgorithms. Almost all RLHF algorithms, including state-of-the-art ones in\nempirical studies such as DPO and PPO, assume the link function is known to the\nagent (e.g., a logistic function according to the Bradley-Terry model), which\nis arguably unrealistic considering the complex nature of human preferences. To\navoid link function mis-specification, this paper studies general RLHF problems\nwith unknown link functions. We propose a novel policy optimization algorithm\ncalled ZSPO based on a new zeroth-order policy optimization method, where the\nkey is to use human preference to construct a parameter update direction that\nis positively correlated with the true policy gradient direction. ZSPO achieves\nit by estimating the sign of the value function difference instead of\nestimating the gradient from the value function difference, so it does not\nrequire knowing the link function. Under mild conditions, ZSPO converges to a\nstationary policy with a polynomial convergence rate depending on the number of\npolicy iterations and trajectories per iteration. Numerical results also show\nthe superiority of ZSPO under link function mismatch.", "published": "2025-06-03 16:42:39", "link": "http://arxiv.org/abs/2506.03066v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Multi-Metric Adaptive Experimental Design under Fixed Budget with Validation", "abstract": "Standard A/B tests in online experiments face statistical power challenges\nwhen testing multiple candidates simultaneously, while adaptive experimental\ndesigns (AED) alone fall short in inferring experiment statistics such as the\naverage treatment effect, especially with many metrics (e.g., revenue, safety)\nand heterogeneous variances. This paper proposes a fixed-budget multi-metric\nAED framework with a two-phase structure: an adaptive exploration phase to\nidentify the best treatment, and a validation phase with an A/B test to verify\nthe treatment's quality and infer statistics. We propose SHRVar, which\ngeneralizes sequential halving (SH) (Karnin et al., 2013) with a novel\nrelative-variance-based sampling and an elimination strategy built on reward\nz-values. It achieves a provable error probability that decreases\nexponentially, where the exponent generalizes the complexity measure for SH\n(Karnin et al., 2013) and SHVar (Lalitha et al., 2023) with homogeneous and\nheterogeneous variances, respectively. Numerical experiments verify our\nanalysis and demonstrate the superior performance of this new framework.", "published": "2025-06-03 16:41:11", "link": "http://arxiv.org/abs/2506.03062v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Torsion in Persistent Homology and Neural Networks", "abstract": "We explore the role of torsion in hybrid deep learning models that\nincorporate topological data analysis, focusing on autoencoders. While most TDA\ntools use field coefficients, this conceals torsional features present in\ninteger homology. We show that torsion can be lost during encoding, altered in\nthe latent space, and in many cases, not reconstructed by standard decoders.\nUsing both synthetic and high-dimensional data, we evaluate torsion sensitivity\nto perturbations and assess its recoverability across several autoencoder\narchitectures. Our findings reveal key limitations of field-based approaches\nand underline the need for architectures or loss terms that preserve torsional\ninformation for robust data representation.", "published": "2025-06-03 16:29:06", "link": "http://arxiv.org/abs/2506.03049v1", "categories": ["math.AT", "cs.LG"], "primary_category": "math.AT"}
{"title": "On the Benefits of Accelerated Optimization in Robust and Private Estimation", "abstract": "We study the advantages of accelerated gradient methods, specifically based\non the Frank-Wolfe method and projected gradient descent, for privacy and\nheavy-tailed robustness. Our approaches are as follows: For the Frank-Wolfe\nmethod, our technique is based on a tailored learning rate and a uniform lower\nbound on the gradient of the $\\ell_2$-norm over the constraint set. For\naccelerating projected gradient descent, we use the popular variant based on\nNesterov's momentum, and we optimize our objective over $\\mathbb{R}^p$. These\naccelerations reduce iteration complexity, translating into stronger\nstatistical guarantees for empirical and population risk minimization. Our\nanalysis covers three settings: non-random data, random model-free data, and\nparametric models (linear regression and generalized linear models).\nMethodologically, we approach both privacy and robustness based on noisy\ngradients. We ensure differential privacy via the Gaussian mechanism and\nadvanced composition, and we achieve heavy-tailed robustness using a geometric\nmedian-of-means estimator, which also sharpens the dependency on the dimension\nof the covariates. Finally, we compare our rates to existing bounds and\nidentify scenarios where our methods attain optimal convergence.", "published": "2025-06-03 16:26:30", "link": "http://arxiv.org/abs/2506.03044v1", "categories": ["math.ST", "cs.LG", "stat.ML", "stat.TH", "62F10, 62J05, 62J07, 62F35, 68P27"], "primary_category": "math.ST"}
{"title": "Sample complexity of Schr\u00f6dinger potential estimation", "abstract": "We address the problem of Schr\\\"odinger potential estimation, which plays a\ncrucial role in modern generative modelling approaches based on Schr\\\"odinger\nbridges and stochastic optimal control for SDEs. Given a simple prior diffusion\nprocess, these methods search for a path between two given distributions\n$\\rho_0$ and $\\rho_T^*$ requiring minimal efforts. The optimal drift in this\ncase can be expressed through a Schr\\\"odinger potential. In the present paper,\nwe study generalization ability of an empirical Kullback-Leibler (KL) risk\nminimizer over a class of admissible log-potentials aimed at fitting the\nmarginal distribution at time $T$. Under reasonable assumptions on the target\ndistribution $\\rho_T^*$ and the prior process, we derive a non-asymptotic\nhigh-probability upper bound on the KL-divergence between $\\rho_T^*$ and the\nterminal density corresponding to the estimated log-potential. In particular,\nwe show that the excess KL-risk may decrease as fast as $O(\\log^2 n / n)$ when\nthe sample size $n$ tends to infinity even if both $\\rho_0$ and $\\rho_T^*$ have\nunbounded supports.", "published": "2025-06-03 16:26:03", "link": "http://arxiv.org/abs/2506.03043v1", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.LG"}
{"title": "On the Need to Align Intent and Implementation in Uncertainty Quantification for Machine Learning", "abstract": "Quantifying uncertainties for machine learning (ML) models is a foundational\nchallenge in modern data analysis. This challenge is compounded by at least two\nkey aspects of the field: (a) inconsistent terminology surrounding uncertainty\nand estimation across disciplines, and (b) the varying technical requirements\nfor establishing trustworthy uncertainties in diverse problem contexts. In this\nposition paper, we aim to clarify the depth of these challenges by identifying\nthese inconsistencies and articulating how different contexts impose distinct\nepistemic demands. We examine the current landscape of estimation targets\n(e.g., prediction, inference, simulation-based inference), uncertainty\nconstructs (e.g., frequentist, Bayesian, fiducial), and the approaches used to\nmap between them. Drawing on the literature, we highlight and explain examples\nof problematic mappings. To help address these issues, we advocate for\nstandards that promote alignment between the \\textit{intent} and\n\\textit{implementation} of uncertainty quantification (UQ) approaches. We\ndiscuss several axes of trustworthiness that are necessary (if not sufficient)\nfor reliable UQ in ML models, and show how these axes can inform the design and\nevaluation of uncertainty-aware ML systems. Our practical recommendations focus\non scientific ML, offering illustrative cases and use scenarios, particularly\nin the context of simulation-based inference (SBI).", "published": "2025-06-03 16:19:59", "link": "http://arxiv.org/abs/2506.03037v1", "categories": ["cs.LG", "stat.ME", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Protein Inverse Folding From Structure Feedback", "abstract": "The inverse folding problem, aiming to design amino acid sequences that fold\ninto desired three-dimensional structures, is pivotal for various\nbiotechnological applications. Here, we introduce a novel approach leveraging\nDirect Preference Optimization (DPO) to fine-tune an inverse folding model\nusing feedback from a protein folding model. Given a target protein structure,\nwe begin by sampling candidate sequences from the inverse-folding model, then\npredict the three-dimensional structure of each sequence with the folding model\nto generate pairwise structural-preference labels. These labels are used to\nfine-tune the inverse-folding model under the DPO objective. Our results on the\nCATH 4.2 test set demonstrate that DPO fine-tuning not only improves sequence\nrecovery of baseline models but also leads to a significant improvement in\naverage TM-Score from 0.77 to 0.81, indicating enhanced structure similarity.\nFurthermore, iterative application of our DPO-based method on challenging\nprotein structures yields substantial gains, with an average TM-Score increase\nof 79.5\\% with regard to the baseline model. This work establishes a promising\ndirection for enhancing protein sequence design ability from structure feedback\nby effectively utilizing preference optimization.", "published": "2025-06-03 16:02:12", "link": "http://arxiv.org/abs/2506.03028v1", "categories": ["cs.LG", "q-bio.BM"], "primary_category": "cs.LG"}
{"title": "How do Pre-Trained Models Support Software Engineering? An Empirical Study in Hugging Face", "abstract": "Open-Source Pre-Trained Models (PTMs) provide extensive resources for various\nMachine Learning (ML) tasks, yet these resources lack a classification tailored\nto Software Engineering (SE) needs. To address this gap, we derive a taxonomy\nencompassing 147 SE tasks and apply an SE-oriented classification to PTMs in a\npopular open-source ML repository, Hugging Face (HF). Our repository mining\nstudy began with a systematically gathered database of PTMs from the HF API,\nconsidering their model card descriptions and metadata, and the abstract of the\nassociated arXiv papers. We confirmed SE relevance through multiple filtering\nsteps: detecting outliers, identifying near-identical PTMs, and the use of\nGemini 2.0 Flash, which was validated with five pilot studies involving three\nhuman annotators. This approach uncovered 2,205 SE PTMs. We find that code\ngeneration is the most common SE task among PTMs, primarily focusing on\nsoftware implementation, while requirements engineering and software design\nactivities receive limited attention. In terms of ML tasks, text generation\ndominates within SE PTMs. Notably, the number of SE PTMs has increased markedly\nsince 2023 Q2. Our classification provides a solid foundation for future\nautomated SE scenarios, such as the sampling and selection of suitable PTMs.", "published": "2025-06-03 15:51:17", "link": "http://arxiv.org/abs/2506.03013v1", "categories": ["cs.SE", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Implicit Regularization of the Deep Inverse Prior Trained with Inertia", "abstract": "Solving inverse problems with neural networks benefits from very few\ntheoretical guarantees when it comes to the recovery guarantees. We provide in\nthis work convergence and recovery guarantees for self-supervised neural\nnetworks applied to inverse problems, such as Deep Image/Inverse Prior, and\ntrained with inertia featuring both viscous and geometric Hessian-driven\ndampings. We study both the continuous-time case, i.e., the trajectory of a\ndynamical system, and the discrete case leading to an inertial algorithm with\nan adaptive step-size. We show in the continuous-time case that the network can\nbe trained with an optimal accelerated exponential convergence rate compared to\nthe rate obtained with gradient flow. We also show that training a network with\nour inertial algorithm enjoys similar recovery guarantees though with a less\nsharp linear convergence rate.", "published": "2025-06-03 15:24:54", "link": "http://arxiv.org/abs/2506.02986v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Non-stationary Bandit Convex Optimization: A Comprehensive Study", "abstract": "Bandit Convex Optimization is a fundamental class of sequential\ndecision-making problems, where the learner selects actions from a continuous\ndomain and observes a loss (but not its gradient) at only one point per round.\nWe study this problem in non-stationary environments, and aim to minimize the\nregret under three standard measures of non-stationarity: the number of\nswitches $S$ in the comparator sequence, the total variation $\\Delta$ of the\nloss functions, and the path-length $P$ of the comparator sequence. We propose\na polynomial-time algorithm, Tilted Exponentially Weighted Average with\nSleeping Experts (TEWA-SE), which adapts the sleeping experts framework from\nonline convex optimization to the bandit setting. For strongly convex losses,\nwe prove that TEWA-SE is minimax-optimal with respect to known $S$ and $\\Delta$\nby establishing matching upper and lower bounds. By equipping TEWA-SE with the\nBandit-over-Bandit framework, we extend our analysis to environments with\nunknown non-stationarity measures. For general convex losses, we introduce a\nsecond algorithm, clipped Exploration by Optimization (cExO), based on\nexponential weights over a discretized action space. While not polynomial-time\ncomputable, this method achieves minimax-optimal regret with respect to known\n$S$ and $\\Delta$, and improves on the best existing bounds with respect to $P$.", "published": "2025-06-03 15:18:41", "link": "http://arxiv.org/abs/2506.02980v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "On the Robustness of Tabular Foundation Models: Test-Time Attacks and In-Context Defenses", "abstract": "Recent tabular Foundational Models (FM) such as TabPFN and TabICL, leverage\nin-context learning to achieve strong performance without gradient updates or\nfine-tuning. However, their robustness to adversarial manipulation remains\nlargely unexplored. In this work, we present a comprehensive study of the\nadversarial vulnerabilities of tabular FM, focusing on both their fragility to\ntargeted test-time attacks and their potential misuse as adversarial tools. We\nshow on three benchmarks in finance, cybersecurity and healthcare, that small,\nstructured perturbations to test inputs can significantly degrade prediction\naccuracy, even when training context remain fixed. Additionally, we demonstrate\nthat tabular FM can be repurposed to generate transferable evasion to\nconventional models such as random forests and XGBoost, and on a lesser extent\nto deep tabular models. To improve tabular FM, we formulate the robustification\nproblem as an optimization of the weights (adversarial fine-tuning), or the\ncontext (adversarial in-context learning). We introduce an in-context\nadversarial training strategy that incrementally replaces the context with\nadversarial perturbed instances, without updating model weights. Our approach\nimproves robustness across multiple tabular benchmarks. Together, these\nfindings position tabular FM as both a target and a source of adversarial\nthreats, highlighting the urgent need for robust training and evaluation\npractices in this emerging paradigm.", "published": "2025-06-03 15:15:36", "link": "http://arxiv.org/abs/2506.02978v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Computation- and Communication-Efficient Online FL for Resource-Constrained Aerial Vehicles", "abstract": "Privacy-preserving distributed machine learning (ML) and aerial connected\nvehicle (ACV)-assisted edge computing have drawn significant attention lately.\nSince the onboard sensors of ACVs can capture new data as they move along their\ntrajectories, the continual arrival of such 'newly' sensed data leads to online\nlearning and demands carefully crafting the trajectories. Besides, as typical\nACVs are inherently resource-constrained, computation- and\ncommunication-efficient ML solutions are needed. Therefore, we propose a\ncomputation- and communication-efficient online aerial federated learning\n(2CEOAFL) algorithm to take the benefits of continual sensed data and limited\nonboard resources of the ACVs. In particular, considering independently owned\nACVs act as selfish data collectors, we first model their trajectories\naccording to their respective time-varying data distributions. We then propose\na 2CEOAFL algorithm that allows the flying ACVs to (a) prune the received dense\nML model to make it shallow, (b) train the pruned model, and (c)\nprobabilistically quantize and offload their trained accumulated gradients to\nthe central server (CS). Our extensive simulation results show that the\nproposed 2CEOAFL algorithm delivers comparable performances to its non-pruned\nand nonquantized, hence, computation- and communication-inefficient\ncounterparts.", "published": "2025-06-03 15:06:59", "link": "http://arxiv.org/abs/2506.02972v1", "categories": ["cs.LG", "cs.NI", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "Memory-Efficient and Privacy-Preserving Collaborative Training for Mixture-of-Experts LLMs", "abstract": "Mixture-of-Experts (MoE) has been gaining popularity due to its successful\nadaptation to large language models (LLMs). In this work, we introduce\nPrivacy-preserving Collaborative Mixture-of-Experts (PC-MoE), which leverages\nthe sparsity of the MoE architecture for memory-efficient decentralized\ncollaborative LLM training, enabling multiple parties with limited GPU-memory\nand data resources to collectively train more capable LLMs than they could\nachieve individually. At the same time, this approach protects training data\nprivacy of each participant by keeping training data, as well as parts of the\nforward pass signal and gradients locally within each party. By design, PC-MoE\nsynergistically combines the strengths of distributed computation with strong\nconfidentiality assurances. Unlike most privacy-preserving schemes, which pay\nfor confidentiality with lower task accuracy, our framework breaks that\ntrade-off: across seven popular LLM benchmarks, it almost matches (and\nsometimes exceeds) the performance and convergence rate of a fully centralized\nmodel, enjoys near 70% peak GPU RAM reduction, while being fully robust against\nreconstruction attacks.", "published": "2025-06-03 15:00:18", "link": "http://arxiv.org/abs/2506.02965v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Abstract Counterfactuals for Language Model Agents", "abstract": "Counterfactual inference is a powerful tool for analysing and evaluating\nautonomous agents, but its application to language model (LM) agents remains\nchallenging. Existing work on counterfactuals in LMs has primarily focused on\ntoken-level counterfactuals, which are often inadequate for LM agents due to\ntheir open-ended action spaces. Unlike traditional agents with fixed, clearly\ndefined action spaces, the actions of LM agents are often implicit in the\nstrings they output, making their action spaces difficult to define and\ninterpret. Furthermore, the meanings of individual tokens can shift depending\non the context, adding complexity to token-level reasoning and sometimes\nleading to biased or meaningless counterfactuals. We introduce \\emph{Abstract\nCounterfactuals}, a framework that emphasises high-level characteristics of\nactions and interactions within an environment, enabling counterfactual\nreasoning tailored to user-relevant features. Our experiments demonstrate that\nthe approach produces consistent and meaningful counterfactuals while\nminimising the undesired side effects of token-level methods. We conduct\nexperiments on text-based games and counterfactual text generation, while\nconsidering both token-level and latent-space interventions.", "published": "2025-06-03 14:44:26", "link": "http://arxiv.org/abs/2506.02946v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "QKV Projections Require a Fraction of Their Memory", "abstract": "The Multi-Head Attention mechanism is central to LLM operation, and multiple\nworks target its compute and memory efficiency during training. While most\nworks focus on approximating the scaled dot product, the memory consumption of\nthe linear projections that compute the $Q$, $K$, and $V$ tensors from the\ninput $x$ is often overlooked. To address this, we propose Point-Approximate\nMatrix Multiplication (PAMM), a novel tensor compression technique that reduces\nmemory consumption of the $Q,K,V$ projections in attention layers by a factor\nof up to $\\times 512$, effectively erasing their memory footprint, while\nachieving similar or better final perplexity. PAMM is fully composable with\nefficient attention techniques such as FlashAttention, making it a practical\nand complementary method for memory-efficient LLM training.", "published": "2025-06-03 14:37:17", "link": "http://arxiv.org/abs/2506.02939v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "MTL-KD: Multi-Task Learning Via Knowledge Distillation for Generalizable Neural Vehicle Routing Solver", "abstract": "Multi-Task Learning (MTL) in Neural Combinatorial Optimization (NCO) is a\npromising approach to train a unified model capable of solving multiple Vehicle\nRouting Problem (VRP) variants. However, existing Reinforcement Learning\n(RL)-based multi-task methods can only train light decoder models on\nsmall-scale problems, exhibiting limited generalization ability when solving\nlarge-scale problems. To overcome this limitation, this work introduces a novel\nmulti-task learning method driven by knowledge distillation (MTL-KD), which\nenables the efficient training of heavy decoder models with strong\ngeneralization ability. The proposed MTL-KD method transfers policy knowledge\nfrom multiple distinct RL-based single-task models to a single heavy decoder\nmodel, facilitating label-free training and effectively improving the model's\ngeneralization ability across diverse tasks. In addition, we introduce a\nflexible inference strategy termed Random Reordering Re-Construction (R3C),\nwhich is specifically adapted for diverse VRP tasks and further boosts the\nperformance of the multi-task model. Experimental results on 6 seen and 10\nunseen VRP variants with up to 1000 nodes indicate that our proposed method\nconsistently achieves superior performance on both uniform and real-world\nbenchmarks, demonstrating robust generalization abilities.", "published": "2025-06-03 14:35:36", "link": "http://arxiv.org/abs/2506.02935v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "From Theory to Practice with RAVEN-UCB: Addressing Non-Stationarity in Multi-Armed Bandits through Variance Adaptation", "abstract": "The Multi-Armed Bandit (MAB) problem is challenging in non-stationary\nenvironments where reward distributions evolve dynamically. We introduce\nRAVEN-UCB, a novel algorithm that combines theoretical rigor with practical\nefficiency via variance-aware adaptation. It achieves tighter regret bounds\nthan UCB1 and UCB-V, with gap-dependent regret of order $K \\sigma_{\\max}^2 \\log\nT / \\Delta$ and gap-independent regret of order $\\sqrt{K T \\log T}$. RAVEN-UCB\nincorporates three innovations: (1) variance-driven exploration using\n$\\sqrt{\\hat{\\sigma}_k^2 / (N_k + 1)}$ in confidence bounds, (2) adaptive\ncontrol via $\\alpha_t = \\alpha_0 / \\log(t + \\epsilon)$, and (3) constant-time\nrecursive updates for efficiency. Experiments across non-stationary patterns -\ndistributional changes, periodic shifts, and temporary fluctuations - in\nsynthetic and logistics scenarios demonstrate its superiority over\nstate-of-the-art baselines, confirming theoretical and practical robustness.", "published": "2025-06-03 14:35:04", "link": "http://arxiv.org/abs/2506.02933v1", "categories": ["cs.LG", "stat.ML", "I.2.6; I.2.8; G.3"], "primary_category": "cs.LG"}
{"title": "Diffusion Buffer: Online Diffusion-based Speech Enhancement with Sub-Second Latency", "abstract": "Diffusion models are a class of generative models that have been recently\nused for speech enhancement with remarkable success but are computationally\nexpensive at inference time. Therefore, these models are impractical for\nprocessing streaming data in real-time. In this work, we adapt a sliding window\ndiffusion framework to the speech enhancement task. Our approach progressively\ncorrupts speech signals through time, assigning more noise to frames close to\nthe present in a buffer. This approach outputs denoised frames with a delay\nproportional to the chosen buffer size, enabling a trade-off between\nperformance and latency. Empirical results demonstrate that our method\noutperforms standard diffusion models and runs efficiently on a GPU, achieving\nan input-output latency in the order of 0.3 to 1 seconds. This marks the first\npractical diffusion-based solution for online speech enhancement.", "published": "2025-06-03 14:14:28", "link": "http://arxiv.org/abs/2506.02908v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Sociodynamics-inspired Adaptive Coalition and Client Selection in Federated Learning", "abstract": "Federated Learning (FL) enables privacy-preserving collaborative model\ntraining, yet its practical strength is often undermined by client data\nheterogeneity, which severely degrades model performance. This paper proposes\nthat data heterogeneity across clients' distributions can be effectively\naddressed by adopting an approach inspired by opinion dynamics over temporal\nsocial networks. We introduce \\shortname (Federated Coalition Variance\nReduction with Boltzmann Exploration), a variance-reducing selection algorithm\nin which (1) clients dynamically organize into non-overlapping clusters based\non asymptotic agreements, and (2) from each cluster, one client is selected to\nminimize the expected variance of its model update. Our experiments show that\nin heterogeneous scenarios our algorithm outperforms existing FL algorithms,\nyielding more accurate results and faster convergence, validating the efficacy\nof our approach.", "published": "2025-06-03 14:04:31", "link": "http://arxiv.org/abs/2506.02897v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Overcoming Challenges of Partial Client Participation in Federated Learning : A Comprehensive Review", "abstract": "Federated Learning (FL) is a learning mechanism that falls under the\ndistributed training umbrella, which collaboratively trains a shared global\nmodel without disclosing the raw data from different clients. This paper\npresents an extensive survey on the impact of partial client participation in\nfederated learning. While much of the existing research focuses on addressing\nissues such as generalization, robustness, and fairness caused by data\nheterogeneity under the assumption of full client participation, limited\nattention has been given to the practical and theoretical challenges arising\nfrom partial client participation, which is common in real-world scenarios.\nThis survey provides an in-depth review of existing FL methods designed to cope\nwith partial client participation. We offer a comprehensive analysis supported\nby theoretical insights and empirical findings, along with a structured\ncategorization of these methods, highlighting their respective advantages and\ndisadvantages.", "published": "2025-06-03 13:52:27", "link": "http://arxiv.org/abs/2506.02887v1", "categories": ["cs.LG", "cs.DC"], "primary_category": "cs.LG"}
{"title": "A Continual Offline Reinforcement Learning Benchmark for Navigation Tasks", "abstract": "Autonomous agents operating in domains such as robotics or video game\nsimulations must adapt to changing tasks without forgetting about the previous\nones. This process called Continual Reinforcement Learning poses non-trivial\ndifficulties, from preventing catastrophic forgetting to ensuring the\nscalability of the approaches considered. Building on recent advances, we\nintroduce a benchmark providing a suite of video-game navigation scenarios,\nthus filling a gap in the literature and capturing key challenges :\ncatastrophic forgetting, task adaptation, and memory efficiency. We define a\nset of various tasks and datasets, evaluation protocols, and metrics to assess\nthe performance of algorithms, including state-of-the-art baselines. Our\nbenchmark is designed not only to foster reproducible research and to\naccelerate progress in continual reinforcement learning for gaming, but also to\nprovide a reproducible framework for production pipelines -- helping\npractitioners to identify and to apply effective approaches.", "published": "2025-06-03 13:48:20", "link": "http://arxiv.org/abs/2506.02883v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Simulation-Based Inference for Adaptive Experiments", "abstract": "Multi-arm bandit experimental designs are increasingly being adopted over\nstandard randomized trials due to their potential to improve outcomes for study\nparticipants, enable faster identification of the best-performing options,\nand/or enhance the precision of estimating key parameters. Current approaches\nfor inference after adaptive sampling either rely on asymptotic normality under\nrestricted experiment designs or underpowered martingale concentration\ninequalities that lead to weak power in practice. To bypass these limitations,\nwe propose a simulation-based approach for conducting hypothesis tests and\nconstructing confidence intervals for arm specific means and their differences.\nOur simulation-based approach uses positively biased nuisances to generate\nadditional trajectories of the experiment, which we call \\textit{simulation\nwith optimism}. Using these simulations, we characterize the distribution\npotentially non-normal sample mean test statistic to conduct inference. We\nprovide guarantees for (i) asymptotic type I error control, (ii) convergence of\nour confidence intervals, and (iii) asymptotic strong consistency of our\nestimator over a wide variety of common bandit designs. Our empirical results\nshow that our approach achieves the desired coverage while reducing confidence\ninterval widths by up to 50%, with drastic improvements for arms not targeted\nby the design.", "published": "2025-06-03 13:46:59", "link": "http://arxiv.org/abs/2506.02881v1", "categories": ["stat.ME", "cs.LG", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Learned Controllers for Agile Quadrotors in Pursuit-Evasion Games", "abstract": "The increasing proliferation of small UAVs in civilian and military airspace\nhas raised critical safety and security concerns, especially when unauthorized\nor malicious drones enter restricted zones. In this work, we present a\nreinforcement learning (RL) framework for agile 1v1 quadrotor pursuit-evasion.\nWe train neural network policies to command body rates and collective thrust,\nenabling high-speed pursuit and evasive maneuvers that fully exploit the\nquadrotor's nonlinear dynamics. To mitigate nonstationarity and catastrophic\nforgetting during adversarial co-training, we introduce an Asynchronous\nMulti-Stage Population-Based (AMSPB) algorithm where, at each stage, either the\npursuer or evader learns against a sampled opponent drawn from a growing\npopulation of past and current policies. This continual learning setup ensures\nmonotonic performance improvement and retention of earlier strategies. Our\nresults show that (i) rate-based policies achieve significantly higher capture\nrates and peak speeds than velocity-level baselines, and (ii) AMSPB yields\nstable, monotonic gains against a suite of benchmark opponents.", "published": "2025-06-03 13:19:23", "link": "http://arxiv.org/abs/2506.02849v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Ensemble-MIX: Enhancing Sample Efficiency in Multi-Agent RL Using Ensemble Methods", "abstract": "Multi-agent reinforcement learning (MARL) methods have achieved\nstate-of-the-art results on a range of multi-agent tasks. Yet, MARL algorithms\ntypically require significantly more environment interactions than their\nsingle-agent counterparts to converge, a problem exacerbated by the difficulty\nin exploring over a large joint action space and the high variance intrinsic to\nMARL environments. To tackle these issues, we propose a novel algorithm that\ncombines a decomposed centralized critic with decentralized ensemble learning,\nincorporating several key contributions. The main component in our scheme is a\nselective exploration method that leverages ensemble kurtosis. We extend the\nglobal decomposed critic with a diversity-regularized ensemble of individual\ncritics and utilize its excess kurtosis to guide exploration toward\nhigh-uncertainty states and actions. To improve sample efficiency, we train the\ncentralized critic with a novel truncated variation of the TD($\\lambda$)\nalgorithm, enabling efficient off-policy learning with reduced variance. On the\nactor side, our suggested algorithm adapts the mixed samples approach to MARL,\nmixing on-policy and off-policy loss functions for training the actors. This\napproach balances between stability and efficiency and outperforms purely\noff-policy learning. The evaluation shows our method outperforms\nstate-of-the-art baselines on standard MARL benchmarks, including a variety of\nSMAC II maps.", "published": "2025-06-03 13:13:15", "link": "http://arxiv.org/abs/2506.02841v1", "categories": ["eess.SY", "cs.LG", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Asymptotically perfect seeded graph matching without edge correlation (and applications to inference)", "abstract": "We present the OmniMatch algorithm for seeded multiple graph matching. In the\nsetting of $d$-dimensional Random Dot Product Graphs (RDPG), we prove that\nunder mild assumptions, OmniMatch with $s$ seeds asymptotically and efficiently\nperfectly aligns $O(s^{\\alpha})$ unseeded vertices -- for $\\alpha<2\\wedge d/4$\n-- across multiple networks even in the presence of no edge correlation. We\ndemonstrate the effectiveness of our algorithm across numerous simulations and\nin the context of shuffled graph hypothesis testing. In the shuffled testing\nsetting, testing power is lost due to the misalignment/shuffling of vertices\nacross graphs, and we demonstrate the capacity of OmniMatch to correct for\nmisaligned vertices prior to testing and hence recover the lost testing power.\nWe further demonstrate the algorithm on a pair of data examples from\nconnectomics and machine translation.", "published": "2025-06-03 12:54:24", "link": "http://arxiv.org/abs/2506.02825v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "CART-based Synthetic Tabular Data Generation for Imbalanced Regression", "abstract": "Handling imbalanced target distributions in regression tasks remains a\nsignificant challenge in tabular data settings where underrepresented regions\ncan hinder model performance. Among data-level solutions, some proposals, such\nas random sampling and SMOTE-based approaches, propose adapting classification\ntechniques to regression tasks. However, these methods typically rely on crisp,\nartificial thresholds over the target variable, a limitation inherited from\nclassification settings that can introduce arbitrariness, often leading to\nnon-intuitive and potentially misleading problem formulations. While recent\ngenerative models, such as GANs and VAEs, provide flexible sample synthesis,\nthey come with high computational costs and limited interpretability. In this\nstudy, we propose adapting an existing CART-based synthetic data generation\nmethod, tailoring it for imbalanced regression. The new method integrates\nrelevance and density-based mechanisms to guide sampling in sparse regions of\nthe target space and employs a threshold-free, feature-driven generation\nprocess. Our experimental study focuses on the prediction of extreme target\nvalues across benchmark datasets. The results indicate that the proposed method\nis competitive with other resampling and generative strategies in terms of\nperformance, while offering faster execution and greater transparency. These\nresults highlight the method's potential as a transparent, scalable data-level\nstrategy for improving regression models in imbalanced domains.", "published": "2025-06-03 12:42:20", "link": "http://arxiv.org/abs/2506.02811v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Learned Cost Model-based Cross-engine Optimizer for SQL Workloads", "abstract": "Lakehouse systems enable the same data to be queried with multiple execution\nengines. However, selecting the engine best suited to run a SQL query still\nrequires a priori knowledge of the query computational requirements and an\nengine capability, a complex and manual task that only becomes more difficult\nwith the emergence of new engines and workloads. In this paper, we address this\nlimitation by proposing a cross-engine optimizer that can automate engine\nselection for diverse SQL queries through a learned cost model. Optimized with\nhints, a query plan is used for query cost prediction and routing. Cost\nprediction is formulated as a multi-task learning problem, and multiple\npredictor heads, corresponding to different engines and provisionings, are used\nin the model architecture. This eliminates the need to train engine-specific\nmodels and allows the flexible addition of new engines at a minimal fine-tuning\ncost. Results on various databases and engines show that using a query\noptimized logical plan for cost estimation decreases the average Q-error by\neven 12.6% over using unoptimized plans as input. Moreover, the proposed\ncross-engine optimizer reduces the total workload runtime by up to 25.2% in a\nzero-shot setting and 30.4% in a few-shot setting when compared to random\nrouting.", "published": "2025-06-03 12:32:56", "link": "http://arxiv.org/abs/2506.02802v1", "categories": ["cs.DB", "cs.LG"], "primary_category": "cs.DB"}
{"title": "Doubly-Robust Estimation of Counterfactual Policy Mean Embeddings", "abstract": "Estimating the distribution of outcomes under counterfactual policies is\ncritical for decision-making in domains such as recommendation, advertising,\nand healthcare. We analyze a novel framework-Counterfactual Policy Mean\nEmbedding (CPME)-that represents the entire counterfactual outcome distribution\nin a reproducing kernel Hilbert space (RKHS), enabling flexible and\nnonparametric distributional off-policy evaluation. We introduce both a plug-in\nestimator and a doubly robust estimator; the latter enjoys improved uniform\nconvergence rates by correcting for bias in both the outcome embedding and\npropensity models. Building on this, we develop a doubly robust kernel test\nstatistic for hypothesis testing, which achieves asymptotic normality and thus\nenables computationally efficient testing and straightforward construction of\nconfidence intervals. Our framework also supports sampling from the\ncounterfactual distribution. Numerical simulations illustrate the practical\nbenefits of CPME over existing methods.", "published": "2025-06-03 12:16:46", "link": "http://arxiv.org/abs/2506.02793v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Accelerating Model-Based Reinforcement Learning using Non-Linear Trajectory Optimization", "abstract": "This paper addresses the slow policy optimization convergence of Monte Carlo\nProbabilistic Inference for Learning Control (MC-PILCO), a state-of-the-art\nmodel-based reinforcement learning (MBRL) algorithm, by integrating it with\niterative Linear Quadratic Regulator (iLQR), a fast trajectory optimization\nmethod suitable for nonlinear systems. The proposed method, Exploration-Boosted\nMC-PILCO (EB-MC-PILCO), leverages iLQR to generate informative, exploratory\ntrajectories and initialize the policy, significantly reducing the number of\nrequired optimization steps. Experiments on the cart-pole task demonstrate that\nEB-MC-PILCO accelerates convergence compared to standard MC-PILCO, achieving up\nto $\\bm{45.9\\%}$ reduction in execution time when both methods solve the task\nin four trials. EB-MC-PILCO also maintains a $\\bm{100\\%}$ success rate across\ntrials while solving the task faster, even in cases where MC-PILCO converges in\nfewer iterations.", "published": "2025-06-03 11:30:59", "link": "http://arxiv.org/abs/2506.02767v1", "categories": ["cs.LG", "cs.RO"], "primary_category": "cs.LG"}
{"title": "Safely Learning Controlled Stochastic Dynamics", "abstract": "We address the problem of safely learning controlled stochastic dynamics from\ndiscrete-time trajectory observations, ensuring system trajectories remain\nwithin predefined safe regions during both training and deployment.\nSafety-critical constraints of this kind are crucial in applications such as\nautonomous robotics, finance, and biomedicine. We introduce a method that\nensures safe exploration and efficient estimation of system dynamics by\niteratively expanding an initial known safe control set using kernel-based\nconfidence bounds. After training, the learned model enables predictions of the\nsystem's dynamics and permits safety verification of any given control. Our\napproach requires only mild smoothness assumptions and access to an initial\nsafe control set, enabling broad applicability to complex real-world systems.\nWe provide theoretical guarantees for safety and derive adaptive learning rates\nthat improve with increasing Sobolev regularity of the true dynamics.\nExperimental evaluations demonstrate the practical effectiveness of our method\nin terms of safety, estimation accuracy, and computational efficiency.", "published": "2025-06-03 11:17:07", "link": "http://arxiv.org/abs/2506.02754v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "WeightLoRA: Keep Only Necessary Adapters", "abstract": "The widespread utilization of language models in modern applications is\ninconceivable without Parameter-Efficient Fine-Tuning techniques, such as\nlow-rank adaptation ($\\texttt{LoRA}$), which adds trainable adapters to\nselected layers. Although $\\texttt{LoRA}$ may obtain accurate solutions, it\nrequires significant memory to train large models and intuition on which layers\nto add adapters. In this paper, we propose a novel method,\n$\\texttt{WeightLoRA}$, which overcomes this issue by adaptive selection of the\nmost critical $\\texttt{LoRA}$ heads throughout the optimization process. As a\nresult, we can significantly reduce the number of trainable parameters while\nmaintaining the capability to obtain consistent or even superior metric values.\nWe conduct experiments for a series of competitive benchmarks and DeBERTa,\nBART, and Llama models, comparing our method with different adaptive\napproaches. The experimental results demonstrate the efficacy of\n$\\texttt{WeightLoRA}$ and the superior performance of $\\texttt{WeightLoRA+}$ in\nalmost all cases.", "published": "2025-06-03 10:33:16", "link": "http://arxiv.org/abs/2506.02724v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Theoretical Performance Guarantees for Partial Domain Adaptation via Partial Optimal Transport", "abstract": "In many scenarios of practical interest, labeled data from a target\ndistribution are scarce while labeled data from a related source distribution\nare abundant. One particular setting of interest arises when the target label\nspace is a subset of the source label space, leading to the framework of\npartial domain adaptation (PDA). Typical approaches to PDA involve minimizing a\ndomain alignment term and a weighted empirical loss on the source data, with\nthe aim of transferring knowledge between domains. However, a theoretical basis\nfor this procedure is lacking, and in particular, most existing weighting\nschemes are heuristic. In this work, we derive generalization bounds for the\nPDA problem based on partial optimal transport. These bounds corroborate the\nuse of the partial Wasserstein distance as a domain alignment term, and lead to\ntheoretically motivated explicit expressions for the empirical source loss\nweights. Inspired by these bounds, we devise a practical algorithm for PDA,\ntermed WARMPOT. Through extensive numerical experiments, we show that WARMPOT\nis competitive with recent approaches, and that our proposed weights improve on\nexisting schemes.", "published": "2025-06-03 10:09:28", "link": "http://arxiv.org/abs/2506.02712v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Online Bayesian system identification in multivariate autoregressive models via message passing", "abstract": "We propose a recursive Bayesian estimation procedure for multivariate\nautoregressive models with exogenous inputs based on message passing in a\nfactor graph. Unlike recursive least-squares, our method produces full\nposterior distributions for both the autoregressive coefficients and noise\nprecision. The uncertainties regarding these estimates propagate into the\nuncertainties on predictions for future system outputs, and support online\nmodel evidence calculations. We demonstrate convergence empirically on a\nsynthetic autoregressive system and competitive performance on a double\nmass-spring-damper system.", "published": "2025-06-03 10:06:29", "link": "http://arxiv.org/abs/2506.02710v1", "categories": ["eess.SP", "cs.LG", "stat.ML"], "primary_category": "eess.SP"}
{"title": "Symmetry-Aware GFlowNets", "abstract": "Generative Flow Networks (GFlowNets) offer a powerful framework for sampling\ngraphs in proportion to their rewards. However, existing approaches suffer from\nsystematic biases due to inaccuracies in state transition probability\ncomputations. These biases, rooted in the inherent symmetries of graphs, impact\nboth atom-based and fragment-based generation schemes. To address this\nchallenge, we introduce Symmetry-Aware GFlowNets (SA-GFN), a method that\nincorporates symmetry corrections into the learning process through reward\nscaling. By integrating bias correction directly into the reward structure,\nSA-GFN eliminates the need for explicit state transition computations.\nEmpirical results show that SA-GFN enables unbiased sampling while enhancing\ndiversity and consistently generating high-reward graphs that closely match the\ntarget distribution.", "published": "2025-06-03 09:38:15", "link": "http://arxiv.org/abs/2506.02685v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Beyond Invisibility: Learning Robust Visible Watermarks for Stronger Copyright Protection", "abstract": "As AI advances, copyrighted content faces growing risk of unauthorized use,\nwhether through model training or direct misuse. Building upon invisible\nadversarial perturbation, recent works developed copyright protections against\nspecific AI techniques such as unauthorized personalization through DreamBooth\nthat are misused. However, these methods offer only short-term security, as\nthey require retraining whenever the underlying model architectures change. To\nestablish long-term protection aiming at better robustness, we go beyond\ninvisible perturbation, and propose a universal approach that embeds\n\\textit{visible} watermarks that are \\textit{hard-to-remove} into images.\nGrounded in a new probabilistic and inverse problem-based formulation, our\nframework maximizes the discrepancy between the \\textit{optimal} reconstruction\nand the original content. We develop an effective and efficient approximation\nalgorithm to circumvent a intractable bi-level optimization. Experimental\nresults demonstrate superiority of our approach across diverse scenarios.", "published": "2025-06-03 09:14:46", "link": "http://arxiv.org/abs/2506.02665v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Computational Thresholds in Multi-Modal Learning via the Spiked Matrix-Tensor Model", "abstract": "We study the recovery of multiple high-dimensional signals from two noisy,\ncorrelated modalities: a spiked matrix and a spiked tensor sharing a common\nlow-rank structure. This setting generalizes classical spiked matrix and tensor\nmodels, unveiling intricate interactions between inference channels and\nsurprising algorithmic behaviors. Notably, while the spiked tensor model is\ntypically intractable at low signal-to-noise ratios, its correlation with the\nmatrix enables efficient recovery via Bayesian Approximate Message Passing,\ninducing staircase-like phase transitions reminiscent of neural network\nphenomena. In contrast, empirical risk minimization for joint learning fails:\nthe tensor component obstructs effective matrix recovery, and joint\noptimization significantly degrades performance, highlighting the limitations\nof naive multi-modal learning. We show that a simple Sequential Curriculum\nLearning strategy-first recovering the matrix, then leveraging it to guide\ntensor recovery-resolves this bottleneck and achieves optimal weak recovery\nthresholds. This strategy, implementable with spectral methods, emphasizes the\ncritical role of structural correlation and learning order in multi-modal\nhigh-dimensional inference.", "published": "2025-06-03 09:14:34", "link": "http://arxiv.org/abs/2506.02664v1", "categories": ["stat.ML", "cond-mat.dis-nn", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Asymptotics of SGD in Sequence-Single Index Models and Single-Layer Attention Networks", "abstract": "We study the dynamics of stochastic gradient descent (SGD) for a class of\nsequence models termed Sequence Single-Index (SSI) models, where the target\ndepends on a single direction in input space applied to a sequence of tokens.\nThis setting generalizes classical single-index models to the sequential\ndomain, encompassing simplified one-layer attention architectures. We derive a\nclosed-form expression for the population loss in terms of a pair of sufficient\nstatistics capturing semantic and positional alignment, and characterize the\ninduced high-dimensional SGD dynamics for these coordinates. Our analysis\nreveals two distinct training phases: escape from uninformative initialization\nand alignment with the target subspace, and demonstrates how the sequence\nlength and positional encoding influence convergence speed and learning\ntrajectories. These results provide a rigorous and interpretable foundation for\nunderstanding how sequential structure in data can be beneficial for learning\nwith attention-based models.", "published": "2025-06-03 09:03:27", "link": "http://arxiv.org/abs/2506.02651v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "HAM: A Hyperbolic Step to Regulate Implicit Bias", "abstract": "Understanding the implicit bias of optimization algorithms has become central\nto explaining the generalization behavior of deep learning models. For\ninstance, the hyperbolic implicit bias induced by the overparameterization $m\n\\odot w$--though effective in promoting sparsity--can result in a small\neffective learning rate, which slows down convergence. To overcome this\nobstacle, we propose HAM (Hyperbolic Aware Minimization), which alternates\nbetween an optimizer step and a new hyperbolic mirror step. We derive the\nRiemannian gradient flow for its combination with gradient descent, leading to\nimproved convergence and a similar beneficial hyperbolic geometry as $m \\odot\nw$ for feature learning. We provide an interpretation of the the algorithm by\nrelating it to natural gradient descent, and an exact characterization of its\nimplicit bias for underdetermined linear regression. HAM's implicit bias\nconsistently boosts performance--even of dense training, as we demonstrate in\nexperiments across diverse tasks, including vision, graph and node\nclassification, and large language model fine-tuning. HAM is especially\neffective in combination with different sparsification methods, improving upon\nthe state of the art. The hyperbolic step requires minimal computational and\nmemory overhead, it succeeds even with small batch sizes, and its\nimplementation integrates smoothly with existing optimizers.", "published": "2025-06-03 08:47:16", "link": "http://arxiv.org/abs/2506.02630v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Compositional Learning for Modular Multi-Agent Self-Organizing Networks", "abstract": "Self-organizing networks face challenges from complex parameter\ninterdependencies and conflicting objectives. This study introduces two\ncompositional learning approaches-Compositional Deep Reinforcement Learning\n(CDRL) and Compositional Predictive Decision-Making (CPDM)-and evaluates their\nperformance under training time and safety constraints in multi-agent systems.\nWe propose a modular, two-tier framework with cell-level and cell-pair-level\nagents to manage heterogeneous agent granularities while reducing model\ncomplexity. Numerical simulations reveal a significant reduction in handover\nfailures, along with improved throughput and latency, outperforming\nconventional multi-agent deep reinforcement learning approaches. The approach\nalso demonstrates superior scalability, faster convergence, higher sample\nefficiency, and safer training in large-scale self-organizing networks.", "published": "2025-06-03 08:33:18", "link": "http://arxiv.org/abs/2506.02616v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Assessing the Completeness of Traffic Scenario Categories for Automated Highway Driving Functions via Cluster-based Analysis", "abstract": "The ability to operate safely in increasingly complex traffic scenarios is a\nfundamental requirement for Automated Driving Systems (ADS). Ensuring the safe\nrelease of ADS functions necessitates a precise understanding of the occurring\ntraffic scenarios. To support this objective, this work introduces a pipeline\nfor traffic scenario clustering and the analysis of scenario category\ncompleteness. The Clustering Vector Quantized - Variational Autoencoder\n(CVQ-VAE) is employed for the clustering of highway traffic scenarios and\nutilized to create various catalogs with differing numbers of traffic scenario\ncategories. Subsequently, the impact of the number of categories on the\ncompleteness considerations of the traffic scenario categories is analyzed. The\nresults show an outperforming clustering performance compared to previous work.\nThe trade-off between cluster quality and the amount of required data to\nmaintain completeness is discussed based on the publicly available highD\ndataset.", "published": "2025-06-03 08:24:14", "link": "http://arxiv.org/abs/2506.02599v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Reachability Weighted Offline Goal-conditioned Resampling", "abstract": "Offline goal-conditioned reinforcement learning (RL) relies on fixed datasets\nwhere many potential goals share the same state and action spaces. However,\nthese potential goals are not explicitly represented in the collected\ntrajectories. To learn a generalizable goal-conditioned policy, it is common to\nsample goals and state-action pairs uniformly using dynamic programming methods\nsuch as Q-learning. Uniform sampling, however, requires an intractably large\ndataset to cover all possible combinations and creates many unreachable\nstate-goal-action pairs that degrade policy performance. Our key insight is\nthat sampling should favor transitions that enable goal achievement. To this\nend, we propose Reachability Weighted Sampling (RWS). RWS uses a reachability\nclassifier trained via positive-unlabeled (PU) learning on goal-conditioned\nstate-action values. The classifier maps these values to a reachability score,\nwhich is then used as a sampling priority. RWS is a plug-and-play module that\nintegrates seamlessly with standard offline RL algorithms. Experiments on six\ncomplex simulated robotic manipulation tasks, including those with a robot arm\nand a dexterous hand, show that RWS significantly improves performance. In one\nnotable case, performance on the HandBlock-Z task improved by nearly 50 percent\nrelative to the baseline. These results indicate the effectiveness of\nreachability-weighted sampling.", "published": "2025-06-03 07:55:57", "link": "http://arxiv.org/abs/2506.02577v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Privacy-Preserving Federated Convex Optimization: Balancing Partial-Participation and Efficiency via Noise Cancellation", "abstract": "This paper tackles the challenge of achieving Differential Privacy (DP) in\nFederated Learning (FL) under partial-participation, where only a subset of the\nmachines participate in each time-step. While previous work achieved optimal\nperformance in full-participation settings, these methods struggled to extend\nto partial-participation scenarios. Our approach fills this gap by introducing\na novel noise-cancellation mechanism that preserves privacy without sacrificing\nconvergence rates or computational efficiency. We analyze our method within the\nStochastic Convex Optimization (SCO) framework and show that it delivers\noptimal performance for both homogeneous and heterogeneous data distributions.\nThis work expands the applicability of DP in FL, offering an efficient and\npractical solution for privacy-preserving learning in distributed systems with\npartial participation.", "published": "2025-06-03 07:48:35", "link": "http://arxiv.org/abs/2506.02563v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "CyberGym: Evaluating AI Agents' Cybersecurity Capabilities with Real-World Vulnerabilities at Scale", "abstract": "Large language model (LLM) agents are becoming increasingly skilled at\nhandling cybersecurity tasks autonomously. Thoroughly assessing their\ncybersecurity capabilities is critical and urgent, given the high stakes in\nthis domain. However, existing benchmarks fall short, often failing to capture\nreal-world scenarios or being limited in scope. To address this gap, we\nintroduce CyberGym, a large-scale and high-quality cybersecurity evaluation\nframework featuring 1,507 real-world vulnerabilities found and patched across\n188 large software projects. While it includes tasks of various settings,\nCyberGym primarily focuses on the generation of proof-of-concept (PoC) tests\nfor vulnerability reproduction, based on text descriptions and corresponding\nsource repositories. Solving this task is particularly challenging, as it\nrequires comprehensive reasoning across entire codebases to locate relevant\ncode fragments and produce effective PoCs that accurately trigger the target\nvulnerability starting from the program's entry point. Our evaluation across 4\nstate-of-the-art agent frameworks and 9 LLMs reveals that even the best\ncombination (OpenHands and Claude-3.7-Sonnet) achieves only a 11.9%\nreproduction success rate, mainly on simpler cases. Beyond reproducing\nhistorical vulnerabilities, we find that PoCs generated by LLM agents can\nreveal new vulnerabilities, identifying 15 zero-days affecting the latest\nversions of the software projects.", "published": "2025-06-03 07:35:14", "link": "http://arxiv.org/abs/2506.02548v1", "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Rethinking Post-Unlearning Behavior of Large Vision-Language Models", "abstract": "Machine unlearning is used to mitigate the privacy risks of Large\nVision-Language Models (LVLMs) arising from training on large-scale web data.\nHowever, existing unlearning methods often fail to carefully select substitute\noutputs for forget targets, resulting in Unlearning Aftermaths-undesirable\nbehaviors such as degenerate, hallucinated, or excessively refused responses.\nWe highlight that, especially for generative LVLMs, it is crucial to consider\nthe quality and informativeness of post-unlearning responses rather than\nrelying solely on naive suppression. To address this, we introduce a new\nunlearning task for LVLMs that requires models to provide privacy-preserving\nyet informative and visually grounded responses. We also propose PUBG, a novel\nunlearning method that explicitly guides post-unlearning behavior toward a\ndesirable output distribution. Experiments show that, while existing methods\nsuffer from Unlearning Aftermaths despite successfully preventing privacy\nviolations, PUBG effectively mitigates these issues, generating visually\ngrounded and informative responses without privacy leakage for forgotten\ntargets.", "published": "2025-06-03 07:28:22", "link": "http://arxiv.org/abs/2506.02541v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "VerificAgent: Integrating Expert Knowledge and Fact-Checked Memory for Robust Domain-Specific Task Planning", "abstract": "Continual memory augmentation allows computer-use agents (CUAs) to learn from\npast interactions and refine their task-solving strategies over time. However,\nunchecked memory accumulation can introduce spurious or hallucinated\n\"learnings\" that degrade agent performance, particularly in domain-specific\nworkflows such as productivity software. We present a novel framework,\nVerificAgent, that effectively manages memory for CUAs through (1) an\nexpert-curated seed of domain knowledge, (2) iterative, trajectory-based memory\nrefinement during training, and (3) a post-hoc fact-checking pass by human\nexperts to sanitize accumulated memory before deployment. On OSWorld\nproductivity tasks, VerificAgent achieves a 111.1% relative improvement in\nsuccess rate over baseline CUA without any additional fine-tuning.", "published": "2025-06-03 07:25:49", "link": "http://arxiv.org/abs/2506.02539v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A structure-preserving and thermodynamically compatible cell-centered Lagrangian finite volume scheme for continuum mechanics", "abstract": "In this work we present a novel structure-preserving scheme for the\ndiscretization of the Godunov-Peshkov-Romenski (GPR) model of continuum\nmechanics written in Lagrangian form. This model admits an extra conservation\nlaw for the total energy (first principle of thermodynamics) and satisfies the\nentropy inequality (second principle of thermodynamics). Furthermore, in the\nabsence of algebraic source terms, the distortion field of the continuum and\nthe specific thermal impulse satisfy a curl-free condition, provided the\ninitial data are curl-free. Last but not least, the determinant of the\ndistortion field is related to the density of the medium, i.e. the system is\nalso endowed with a nonlinear algebraic constraint.\n  The objective of this work is to construct and analyze a new semi-discrete\nthermodynamically compatible cell-centered Lagrangian finite volume scheme on\nmoving unstructured meshes that satisfies the following structural properties\nof the governing PDE exactly at the discrete level: i) compatibility with the\nfirst law of thermodynamics, i.e. discrete total energy conservation; ii)\ncompatibility with the second law of thermodynamics, i.e. discrete entropy\ninequality; iii) exact discrete compatibility between the density and the\ndeterminant of the distortion field; iv) exact preservation of the curl-free\nproperty of the distortion field and of the specific thermal impulse in the\nabsence of algebraic source terms. We show that it is possible to achieve all\nabove properties simultaneously. Unlike in existing schemes, we choose to\ndirectly discretize the entropy inequality, hence obtaining total energy\nconservation as a consequence of an appropriate and thermodynamically\ncompatible discretization of all the other equations.", "published": "2025-06-03 17:01:54", "link": "http://arxiv.org/abs/2506.03081v1", "categories": ["math.NA", "cs.NA", "physics.comp-ph", "35L40, 65M08"], "primary_category": "math.NA"}
{"title": "GPU-Parallelizable Randomized Sketch-and-Precondition for Linear Regression using Sparse Sign Sketches", "abstract": "A litany of theoretical and numerical results have established the\nsketch-and-precondition paradigm as a powerful approach to solving large linear\nregression problems in standard computing environments. Perhaps surprisingly,\nmuch less work has been done on understanding how sketch-and-precondition\nperforms on graphics processing unit (GPU) systems. We address this gap by\nbenchmarking an implementation of sketch-and-precondition based on sparse\nsign-sketches on single and multi-GPU systems. In doing so, we describe a\nnovel, easily parallelized, rejection-sampling based method for generating\nsparse sign sketches. Our approach, which is particularly well-suited for GPUs,\nis easily adapted to a variety of computing environments. Taken as a whole, our\nnumerical experiments indicate that sketch-and-precondition with sparse sign\nsketches is particularly well-suited for GPUs, and may be suitable for use in\nblack-box least-squares solvers.", "published": "2025-06-03 16:48:06", "link": "http://arxiv.org/abs/2506.03070v1", "categories": ["cs.DS", "cs.DC", "cs.NA", "math.NA"], "primary_category": "cs.DS"}
{"title": "Rates of convergence of finite element approximations of second-order mean field games with nondifferentiable Hamiltonians", "abstract": "We prove a rate of convergence for finite element approximations of\nstationary, second-order mean field games with nondifferentiable Hamiltonians\nposed in general bounded polytopal Lipschitz domains with strongly monotone\nrunning costs. In particular, we obtain a rate of convergence in the $H^1$-norm\nfor the value function approximations and in the $L^2$-norm for the\napproximations of the density. We also establish a rate of convergence for the\nerror between the exact solution of the MFG system with a nondifferentiable\nHamiltonian and the finite element discretizations of the corresponding MFG\nsystem with a regularized Hamiltonian.", "published": "2025-06-03 16:21:30", "link": "http://arxiv.org/abs/2506.03039v1", "categories": ["math.NA", "cs.NA", "65N15, 65N30, 35Q89"], "primary_category": "math.NA"}
{"title": "Bivariate polynomial histopolation techniques on Padua, Fekete and Leja triangles", "abstract": "This paper explores the reconstruction of a real-valued function $f$ defined\nover a domain $\\Omega \\subset \\mathbb{R}^2$ using bivariate polynomials that\nsatisfy triangular histopolation conditions. More precisely, we assume that\nonly the averages of $f$ over a given triangulation $\\mathcal{T}_N$ of $\\Omega$\nare available and seek a bivariate polynomial that approximates $f$ using a\nhistopolation approach, potentially flanked by an additional regression\ntechnique. This methodology relies on the selection of a subset of triangles\n$\\mathcal{T}_M \\subset \\mathcal{T}_N$ for histopolation, ensuring both the\nsolvability and the well-conditioning of the problem. The remaining triangles\ncan potentially be used to enhance the accuracy of the polynomial approximation\nthrough a simultaneous regression. We will introduce histopolation and combined\nhistopolation-regression methods using the Padua points, discrete Leja\nsequences, and approximate Fekete nodes. The proposed algorithms are\nimplemented and evaluated through numerical experiments that demonstrate their\neffectiveness in function approximation.", "published": "2025-06-03 16:00:34", "link": "http://arxiv.org/abs/2506.03025v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Newtonian potentials of Legendre polynomials on rectangles have displacement structure", "abstract": "Particular solutions of the Poisson equation can be constructed via Newtonian\npotentials, integrals involving the corresponding Green's function which in\ntwo-dimensions has a logarithmic singularity. The singularity represents a\nsignificant challenge for computing the integrals, which is typically overcome\nvia specially designed quadrature methods involving a large number of\nevaluations of the function and kernel. We present an attractive alternative:\nwe show that Newtonian potentials (and their gradient) applied to (tensor\nproducts of) Legendre polynomials can be expressed in terms of complex\nintegrals which satisfy simple and explicit recurrences that can be utilised to\nexactly compute singular integrals, i.e., singular integral quadrature is\ncompletely avoided. The inhomogeneous part of the recurrence has low rank\nstructure (its rank is at most three for the Newtonian potential) and hence\nthese recurrences have displacement structure. Using the recurrence directly is\na fast approach for evaluation on or near the integration domain that remains\naccurate for low degree polynomial approximations, while high-precision\narithmetic allows accurate use of the approach for moderate degree polynomials.", "published": "2025-06-03 15:42:31", "link": "http://arxiv.org/abs/2506.03003v1", "categories": ["math.NA", "cs.NA", "65D30, 65R10"], "primary_category": "math.NA"}
{"title": "Real and finite field versions of Chebotarev's theorem", "abstract": "Chebotarev's theorem on roots of unity states that all minors of the Fourier\nmatrix of prime size are non-vanishing. This result has been rediscovered\nseveral times and proved via different techniques. We follow the proof of Evans\nand Isaacs and generalize the original result to a real version and a version\nover finite fields. For the latter, we are able to remove an order condition\nbetween the characteristic of the field and the size of the matrix as well as\ndecrease a sufficient lower bound on the characteristic by Zhang considerably.\nDirect applications include a specific real phase retrieval problem as well as\na recent result for Riesz bases of exponentials.", "published": "2025-06-03 14:44:28", "link": "http://arxiv.org/abs/2506.02947v1", "categories": ["math.NA", "cs.NA", "1T06, 15B33, 15B99, 43A25, 65T50"], "primary_category": "math.NA"}
{"title": "Eigenvalue bounds for preconditioned symmetric multiple saddle-point matrices", "abstract": "We develop eigenvalue bounds for symmetric, block tridiagonal multiple\nsaddle-point linear systems, preconditioned with block diagonal matrices. We\nextend known results for $3 \\times 3$ block systems [Bradley and Greif, IMA J.\\\nNumer. Anal. 43 (2023)] and for $4 \\times 4$ systems [Pearson and Potschka, IMA\nJ. Numer. Anal. 44 (2024)] to an arbitrary number of blocks. Moreover, our\nresults generalize the bounds in [Sogn and Zulehner, IMA J. Numer. Anal. 39\n(2018)], developed for an arbitrary number of blocks with null diagonal blocks.\nExtension to the bounds when the Schur complements are approximated is also\nprovided, using perturbation arguments. Practical bounds are also obtained for\nthe double saddle-point linear system. Numerical experiments validate our\nfindings.", "published": "2025-06-03 12:46:26", "link": "http://arxiv.org/abs/2506.02816v1", "categories": ["math.NA", "cs.NA", "math.OC"], "primary_category": "math.NA"}
{"title": "The Bayesian Finite Element Method in Inverse Problems: a Critical Comparison between Probabilistic Models for Discretization Error", "abstract": "When using the finite element method (FEM) in inverse problems, its\ndiscretization error can produce parameter estimates that are inaccurate and\noverconfident. The Bayesian finite element method (BFEM) provides a\nprobabilistic model for the epistemic uncertainty due to discretization error.\nIn this work, we apply BFEM to various inverse problems, and compare its\nperformance to the random mesh finite element method (RM-FEM) and the\nstatistical finite element method (statFEM), which serve as a frequentist and\ninference-based counterpart to BFEM. We find that by propagating this\nuncertainty to the posterior, BFEM can produce more accurate parameter\nestimates and prevent overconfidence, compared to FEM. Because the BFEM\ncovariance operator is designed to leave uncertainty only in the appropriate\nspace, orthogonal to the FEM basis, BFEM is able to outperform RM-FEM, which\ndoes not have such a structure to its covariance. Although inferring the\ndiscretization error via a model misspecification component is possible as\nwell, as is done in statFEM, the feasibility of such an approach is contingent\non the availability of sufficient data. We find that the BFEM is the most\nrobust way to consistently propagate uncertainty due to discretization error to\nthe posterior of a Bayesian inverse problem.", "published": "2025-06-03 12:45:45", "link": "http://arxiv.org/abs/2506.02815v1", "categories": ["math.NA", "cs.NA", "35R30, 62F15, 65N21, 65N30, 74B05, 74S05"], "primary_category": "math.NA"}
{"title": "Nonsmooth data error estimates for exponential Runge--Kutta methods and applications to split exponential integrators", "abstract": "We derive error bounds for exponential Runge-Kutta discretizations of\nparabolic equations with nonsmooth initial data. Our analysis is carried out in\na framework of abstract semilinear evolution equations with operators having\nnon-dense domain. In particular, we investigate nonsmooth data error estimates\nfor the Allen-Cahn and the Burgers' equation. As an application, we apply these\nnonsmooth data error estimates to split exponential integrators and derive a\nconvergence result in terms of the data.", "published": "2025-06-03 11:57:21", "link": "http://arxiv.org/abs/2506.02778v1", "categories": ["math.NA", "cs.NA", "65M12, 65L06"], "primary_category": "math.NA"}
{"title": "A priori error estimates for the $\u03b8$-method for the flow of nonsmooth velocity fields", "abstract": "Velocity fields with low regularity (below the Lipschitz threshold) naturally\narise in many models from mathematical physics, such as the inhomogeneous\nincompressible Navier-Stokes equations, and play a fundamental role in the\nanalysis of nonlinear PDEs. The DiPerna-Lions theory ensures existence and\nuniqueness of the flow associated with a divergence-free velocity field with\nSobolev regularity. In this paper, we establish a priori error estimates\nshowing a logarithmic rate of convergence of numerical solutions, constructed\nvia the $\\theta$-method, towards the exact (analytic) flow for a velocity field\nwith Sobolev regularity. In addition, we derive analogous a priori error\nestimates for Lagrangian solutions of the associated transport equation,\nexhibiting the same logarithmic rate of convergence. Our theoretical results\nare supported by numerical experiments, which confirm the predicted logarithmic\nbehavior.", "published": "2025-06-03 11:11:01", "link": "http://arxiv.org/abs/2506.02747v1", "categories": ["math.AP", "cs.NA", "math.NA", "34A45, 35A02, 65L07"], "primary_category": "math.AP"}
{"title": "Fourth-order Adaptive Mesh Refinement both in space and in time for incompressible Navier-Stokes equations with Dirichlet boundary conditions", "abstract": "We present a fourth-order projection method with adaptive mesh refinement\n(AMR) for numerically solving the incompressible Navier-Stokes equations (INSE)\nwith subcycling in time. Our method features (i) a reformulation of INSE so\nthat the velocity divergence decays exponentially on the coarsest level, (ii) a\nderivation of coarse-fine interface conditions that preserves the decay of\nvelocity divergence on any refinement level of the AMR hierarchy, (iii) an\napproximation of the coarse-fine interface conditions via spatiotemporal\ninterpolations to facilitate subcycling in time, (iv) enforcing to machine\nprecision solvability conditions of elliptic equations over each connected\ncomponent of the subdomain covered by any refinement level, (v) a composite\nprojection for synchronizing multiple levels, and (vi) geometric multigrid for\nsolving linear systems with optimal complexity. Different from current\nblock-structured AMR algorithms, our method never adopts refluxing at the\ncoarse-fine interface, nor is fine-to-coarse averaging applied to projected\nvelocities. Results of numerical tests demonstrate the high accuracy and\nefficiency of the proposed method.", "published": "2025-06-03 09:14:13", "link": "http://arxiv.org/abs/2506.02663v1", "categories": ["math.NA", "cs.NA", "76D05, 65M50, 76M12"], "primary_category": "math.NA"}
{"title": "Multilevel Stochastic Gradient Descent for Optimal Control Under Uncertainty", "abstract": "We present a multilevel stochastic gradient descent method for the optimal\ncontrol of systems governed by partial differential equations under uncertain\ninput data. The gradient descent method used to find the optimal control\nleverages a parallel multilevel Monte Carlo method as stochastic gradient\nestimator. As a result, we achieve precise control over the stochastic\ngradient's bias, introduced by numerical approximation, and its sampling error,\narising from the use of incomplete gradients, while optimally managing\ncomputational resources. We show that the method exhibits linear convergence in\nthe number of optimization steps while avoiding the cost of computing the full\ngradient at the highest fidelity. Numerical experiments demonstrate that the\nmethod significantly outperforms the standard (mini-) batched stochastic\ngradient descent method in terms of convergence speed and accuracy. The method\nis particularly well-suited for high-dimensional control problems, taking\nadvantage of parallel computing resources and a distributed multilevel data\nstructure. Additionally, we evaluate and implement different step size\nstrategies, optimizer schemes, and budgeting techniques. The method's\nperformance is studied using a two-dimensional elliptic subsurface diffusion\nproblem with log-normal coefficients and Mat\\'ern covariance.", "published": "2025-06-03 09:00:43", "link": "http://arxiv.org/abs/2506.02647v1", "categories": ["math.OC", "cs.MS", "cs.NA", "math.NA"], "primary_category": "math.OC"}
{"title": "Non-exchangeable evolutionary and mean field games and their applications", "abstract": "A replicator dynamic for non-exchangeable agents in a continuous action space\nis formulated and its well-posedness is proven in a space of probability\nmeasures. The non-exchangeability allows for the analysis of evolutionary games\ninvolving agents with distinct (and possibly infinitely many) types. We also\nexplicitly connect this replicator dynamic to a stationary mean field game,\nwhich determines the pairwise actions of the heterogeneous agents. Moreover, as\na byproduct of our theoretical results, we show that a class of nonlinear voter\nmodels, recently the subject of increasing interest, called q-voter models, can\nbe viewed as a replicator dynamic driven by a utility that is a power of the\nprobability density. This implies that non-exchangeable and/or mean-field game\nformulations of these models can also be constructed. We also present\ncomputational examples of evolutionary and mean field game models using a\nfinite difference method, focusing on tragedy of the commons and the q-voter\nmodel with non-exchangeable agents, of which are interesting cases from\ntheoretical and computational perspectives.", "published": "2025-06-03 09:00:03", "link": "http://arxiv.org/abs/2506.02644v1", "categories": ["math.OC", "cs.NA", "math.NA", "math.PR"], "primary_category": "math.OC"}
{"title": "Numerical methods for fully nonlinear degenerate diffusions", "abstract": "We propose finite difference methods for degenerate fully nonlinear elliptic\nequations and prove the convergence of the schemes. Our focus is on the pure\nequation and a related free boundary problem of transmission type. The\ncornerstone of our argument is a regularisation procedure. It decouples the\ndegeneracy term from the elliptic operator driving the diffusion process. In\nthe free boundary setting, the absence of degenerate ellipticity entails new,\ngenuine difficulties. To bypass them, we resort to the intrinsic properties of\nthe regularised problem. We present numerical experiments supporting our\ntheoretical results. Our methods are flexible, and our approach can be extended\nto a broader class of non-variational problems.", "published": "2025-06-03 08:13:41", "link": "http://arxiv.org/abs/2506.02595v1", "categories": ["math.NA", "cs.NA", "math.AP", "65N12, 35R35, 35D40"], "primary_category": "math.NA"}
{"title": "Rust Implementation of Finite Element Exterior Calculus on Coordinate-Free Simplicial Complexes", "abstract": "This thesis presents the development of a novel finite element library in\nRust based on the principles of Finite Element Exterior Calculus (FEEC). The\nlibrary solves partial differential equations formulated using differential\nforms on abstract, coordinate-free simplicial complexes in arbitrary\ndimensions, employing an intrinsic Riemannian metric derived from edge lengths\nvia Regge Calculus. We focus on solving elliptic Hodge-Laplace eigenvalue and\nsource problems on the nD de Rham complex. We restrict ourselves to first-order\nWhitney basis functions. The implementation is partially verified through\nconvergence studies.", "published": "2025-06-03 04:28:52", "link": "http://arxiv.org/abs/2506.02429v1", "categories": ["math.NA", "cs.NA", "math.AP", "math.AT", "math.DG", "math.FA"], "primary_category": "math.NA"}
{"title": "An adaptive delaminating Levin method in two dimensions", "abstract": "We present an adaptive delaminating Levin method for evaluating bivariate\noscillatory integrals over rectangular domains. Whereas previous analyses of\nLevin methods impose non-resonance conditions that exclude stationary and\nresonance points, we rigorously establish the existence of a slowly-varying,\napproximate solution to the Levin PDE across all frequency regimes, even when\nthe non-resonance condition is violated. This allows us to derive error\nestimates for the numerical solution of the Levin PDE via the Chebyshev\nspectral collocation method, and for the evaluation of the corresponding\noscillatory integrals, showing that high accuracy can be achieved regardless of\nwhether or not stationary and resonance points are present. We then present a\nLevin method incorporating adaptive subdivision in both two and one dimensions,\nas well as delaminating Chebyshev spectral collocation, which is effective in\nboth the presence and absence of stationary and resonance points. We\ndemonstrate the effectiveness of our algorithm with a number of numerical\nexperiments.", "published": "2025-06-03 04:14:52", "link": "http://arxiv.org/abs/2506.02424v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Discovery of Probabilistic Dirichlet-to-Neumann Maps on Graphs", "abstract": "Dirichlet-to-Neumann maps enable the coupling of multiphysics simulations\nacross computational subdomains by ensuring continuity of state variables and\nfluxes at artificial interfaces. We present a novel method for learning\nDirichlet-to-Neumann maps on graphs using Gaussian processes, specifically for\nproblems where the data obey a conservation constraint from an underlying\npartial differential equation. Our approach combines discrete exterior calculus\nand nonlinear optimal recovery to infer relationships between vertex and edge\nvalues. This framework yields data-driven predictions with uncertainty\nquantification across the entire graph, even when observations are limited to a\nsubset of vertices and edges. By optimizing over the reproducing kernel Hilbert\nspace norm while applying a maximum likelihood estimation penalty on kernel\ncomplexity, our method ensures that the resulting surrogate strictly enforces\nconservation laws without overfitting. We demonstrate our method on two\nrepresentative applications: subsurface fracture networks and arterial blood\nflow. Our results show that the method maintains high accuracy and\nwell-calibrated uncertainty estimates even under severe data scarcity,\nhighlighting its potential for scientific applications where limited data and\nreliable uncertainty quantification are critical.", "published": "2025-06-03 00:25:49", "link": "http://arxiv.org/abs/2506.02337v1", "categories": ["cs.LG", "cs.NA", "math-ph", "math.MP", "math.NA", "physics.comp-ph", "stat.ML", "90C70, 60G15, 05C90"], "primary_category": "cs.LG"}
{"title": "Optimal Dynamic Fees in Automated Market Makers", "abstract": "Automated Market Makers (AMMs) are emerging as a popular decentralised\ntrading platform. In this work, we determine the optimal dynamic fees in a\nconstant function market maker. We find approximate closed-form solutions to\nthe control problem and study the optimal fee structure. We find that there are\ntwo distinct fee regimes: one in which the AMM imposes higher fees to deter\narbitrageurs, and another where fees are lowered to increase volatility and\nattract noise traders. Our results also show that dynamic fees that are linear\nin inventory and are sensitive to changes in the external price are a good\napproximation of the optimal fee structure and thus constitute suitable\ncandidates when designing fees for AMMs.", "published": "2025-06-03 13:34:28", "link": "http://arxiv.org/abs/2506.02869v1", "categories": ["q-fin.TR", "q-fin.MF"], "primary_category": "q-fin.TR"}
{"title": "Tensor State Space-based Dynamic Multilayer Network Modeling", "abstract": "Understanding the complex interactions within dynamic multilayer networks is\ncritical for advancements in various scientific domains. Existing models often\nfail to capture such networks' temporal and cross-layer dynamics. This paper\nintroduces a novel Tensor State Space Model for Dynamic Multilayer Networks\n(TSSDMN), utilizing a latent space model framework. TSSDMN employs a symmetric\nTucker decomposition to represent latent node features, their interaction\npatterns, and layer transitions. Then by fixing the latent features and\nallowing the interaction patterns to evolve over time, TSSDMN uniquely captures\nboth the temporal dynamics within layers and across different layers. The model\nidentifiability conditions are discussed. By treating latent features as\nvariables whose posterior distributions are approximated using a mean-field\nvariational inference approach, a variational Expectation Maximization\nalgorithm is developed for efficient model inference. Numerical simulations and\ncase studies demonstrate the efficacy of TSSDMN for understanding dynamic\nmultilayer networks.", "published": "2025-06-03 03:58:32", "link": "http://arxiv.org/abs/2506.02413v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Random at First, Fast at Last: NTK-Guided Fourier Pre-Processing for Tabular DL", "abstract": "While random Fourier features are a classic tool in kernel methods, their\nutility as a pre-processing step for deep learning on tabular data has been\nlargely overlooked. Motivated by shortcomings in tabular deep learning\npipelines - revealed through Neural Tangent Kernel (NTK) analysis - we revisit\nand repurpose random Fourier mappings as a parameter-free,\narchitecture-agnostic transformation. By projecting each input into a fixed\nfeature space via sine and cosine projections with frequencies drawn once at\ninitialization, this approach circumvents the need for ad hoc normalization or\nadditional learnable embeddings. We show within the NTK framework that this\nmapping (i) bounds and conditions the network's initial NTK spectrum, and (ii)\nintroduces a bias that shortens the optimization trajectory, thereby\naccelerating gradient-based training. These effects pre-condition the network\nwith a stable kernel from the outset. Empirically, we demonstrate that deep\nnetworks trained on Fourier-transformed inputs converge more rapidly and\nconsistently achieve strong final performance, often with fewer epochs and less\nhyperparameter tuning. Our findings establish random Fourier pre-processing as\na theoretically motivated, plug-and-play enhancement for tabular deep learning.", "published": "2025-06-03 03:45:13", "link": "http://arxiv.org/abs/2506.02406v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Multi-agent Markov Entanglement", "abstract": "Value decomposition has long been a fundamental technique in multi-agent\ndynamic programming and reinforcement learning (RL). Specifically, the value\nfunction of a global state $(s_1,s_2,\\ldots,s_N)$ is often approximated as the\nsum of local functions: $V(s_1,s_2,\\ldots,s_N)\\approx\\sum_{i=1}^N V_i(s_i)$.\nThis approach traces back to the index policy in restless multi-armed bandit\nproblems and has found various applications in modern RL systems. However, the\ntheoretical justification for why this decomposition works so effectively\nremains underexplored.\n  In this paper, we uncover the underlying mathematical structure that enables\nvalue decomposition. We demonstrate that a multi-agent Markov decision process\n(MDP) permits value decomposition if and only if its transition matrix is not\n\"entangled\" -- a concept analogous to quantum entanglement in quantum physics.\nDrawing inspiration from how physicists measure quantum entanglement, we\nintroduce how to measure the \"Markov entanglement\" for multi-agent MDPs and\nshow that this measure can be used to bound the decomposition error in general\nmulti-agent MDPs.\n  Using the concept of Markov entanglement, we proved that a widely-used class\nof index policies is weakly entangled and enjoys a sublinear $\\mathcal\nO(\\sqrt{N})$ scale of decomposition error for $N$-agent systems. Finally, we\nshow how Markov entanglement can be efficiently estimated in practice,\nproviding practitioners with an empirical proxy for the quality of value\ndecomposition.", "published": "2025-06-03 02:54:25", "link": "http://arxiv.org/abs/2506.02385v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Large Stepsizes Accelerate Gradient Descent for Regularized Logistic Regression", "abstract": "We study gradient descent (GD) with a constant stepsize for\n$\\ell_2$-regularized logistic regression with linearly separable data.\nClassical theory suggests small stepsizes to ensure monotonic reduction of the\noptimization objective, achieving exponential convergence in\n$\\widetilde{\\mathcal{O}}(\\kappa)$ steps with $\\kappa$ being the condition\nnumber. Surprisingly, we show that this can be accelerated to\n$\\widetilde{\\mathcal{O}}(\\sqrt{\\kappa})$ by simply using a large stepsize --\nfor which the objective evolves nonmonotonically. The acceleration brought by\nlarge stepsizes extends to minimizing the population risk for separable\ndistributions, improving on the best-known upper bounds on the number of steps\nto reach a near-optimum. Finally, we characterize the largest stepsize for the\nlocal convergence of GD, which also determines the global convergence in\nspecial scenarios. Our results extend the analysis of Wu et al. (2024) from\nconvex settings with minimizers at infinity to strongly convex cases with\nfinite minimizers.", "published": "2025-06-03 00:21:22", "link": "http://arxiv.org/abs/2506.02336v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "InfiniteAudio: Infinite-Length Audio Generation with Consistency", "abstract": "This paper presents InfiniteAudio, a simple yet effective strategy for\ngenerating infinite-length audio using diffusion-based text-to-audio methods.\nCurrent approaches face memory constraints because the output size increases\nwith input length, making long duration generation challenging. A common\nworkaround is to concatenate short audio segments, but this often leads to\ninconsistencies due to the lack of shared temporal context. To address this,\nInfiniteAudio integrates seamlessly into existing pipelines without additional\ntraining. It introduces two key techniques: FIFO sampling, a first-in,\nfirst-out inference strategy with fixed-size inputs, and curved denoising,\nwhich selectively prioritizes key diffusion steps for efficiency. Experiments\nshow that InfiniteAudio achieves comparable or superior performance across all\nmetrics. Audio samples are available on our project page.", "published": "2025-06-03 15:57:55", "link": "http://arxiv.org/abs/2506.03020v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "PartialEdit: Identifying Partial Deepfakes in the Era of Neural Speech Editing", "abstract": "Neural speech editing enables seamless partial edits to speech utterances,\nallowing modifications to selected content while preserving the rest of the\naudio unchanged. This useful technique, however, also poses new risks of\ndeepfakes. To encourage research on detecting such partially edited deepfake\nspeech, we introduce PartialEdit, a deepfake speech dataset curated using\nadvanced neural editing techniques. We explore both detection and localization\ntasks on PartialEdit. Our experiments reveal that models trained on the\nexisting PartialSpoof dataset fail to detect partially edited speech generated\nby neural speech editing models. As recent speech editing models almost all\ninvolve neural audio codecs, we also provide insights into the artifacts the\nmodel learned on detecting these deepfakes. Further information about the\nPartialEdit dataset and audio samples can be found on the project page:\nhttps://yzyouzhang.com/PartialEdit/index.html.", "published": "2025-06-03 14:52:16", "link": "http://arxiv.org/abs/2506.02958v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Fast-Converging Distributed Signal Estimation in Topology-Unconstrained Wireless Acoustic Sensor Networks", "abstract": "This paper focuses on distributed signal estimation in topology-unconstrained\nwireless acoustic sensor networks (WASNs) where sensor nodes only transmit\nfused versions of their local sensor signals. For this task, the\ntopology-independent (TI) distributed adaptive node-specific signal estimation\n(DANSE) algorithm (TI-DANSE) has previously been proposed. It converges towards\nthe centralized signal estimation solution in non-fully connected and\ntime-varying network topologies. However, the applicability of TI-DANSE in\nreal-world scenarios is limited due to its slow convergence. The latter results\nfrom the fact that, in TI-DANSE, nodes only have access to the in-network sum\nof all fused signals in the WASN. We address this low convergence speed by\nintroducing an improved TI-DANSE algorithm, referred to as TI-DANSE+, in which\nupdating nodes separately use the partial in-network sums of fused signals\ncoming from each of their neighbors. Nodes can maximize the number of available\ndegrees of freedom in their local optimization problem, leading to faster\nconvergence. This is further exploited by combining TI-DANSE+ with a\ntree-pruning strategy that maximizes the number of neighbors at the updating\nnode. In fully connected WASNs, TI-DANSE+ converges as fast as the original\nDANSE algorithm (the latter only defined for fully connected WASNs) while using\npeer-to-peer data transmission instead of broadcasting and thus saving\ncommunication bandwidth. If link failures occur, the convergence of TI-DANSE+\ntowards the centralized solution is preserved without any change in its\nformulation. Altogether, the proposed TI-DANSE+ algorithm can be viewed as an\nall-round alternative to DANSE and TI-DANSE which (i) merges the advantages of\nboth, (ii) reconciliates their differences into a single formulation, and (iii)\nshows advantages of its own in terms of communication bandwidth usage.", "published": "2025-06-03 12:23:18", "link": "http://arxiv.org/abs/2506.02797v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "On the influence of language similarity in non-target speaker verification trials", "abstract": "In this paper, we investigate the influence of language similarity in\ncross-lingual non-target speaker verification trials using a state-of-the-art\nspeaker verification system, ECAPA-TDNN, trained on multilingual and\nmonolingual variants of the VoxCeleb dataset. Our analysis of the score\ndistribution patterns on multilingual Globalphone and LDC CTS reveals a\nclustering effect in speaker comparisons involving a training language, whereby\nthe choice of comparison language only minimally impacts scores. Conversely, we\nobserve a language similarity effect in trials involving languages not included\nin the training set of the speaker verification system, with scores correlating\nwith language similarity measured by a language classification system,\nespecially when using multilingual training data.", "published": "2025-06-03 11:56:52", "link": "http://arxiv.org/abs/2506.02777v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "AuralNet: Hierarchical Attention-based 3D Binaural Localization of Overlapping Speakers", "abstract": "We propose AuralNet, a novel 3D multi-source binaural sound source\nlocalization approach that localizes overlapping sources in both azimuth and\nelevation without prior knowledge of the number of sources. AuralNet employs a\ngated coarse-tofine architecture, combining a coarse classification stage with\na fine-grained regression stage, allowing for flexible spatial resolution\nthrough sector partitioning. The model incorporates a multi-head self-attention\nmechanism to capture spatial cues in binaural signals, enhancing robustness in\nnoisy-reverberant environments. A masked multi-task loss function is designed\nto jointly optimize sound detection, azimuth, and elevation estimation.\nExtensive experiments in noisy-reverberant conditions demonstrate the\nsuperiority of AuralNet over recent methods", "published": "2025-06-03 11:48:28", "link": "http://arxiv.org/abs/2506.02773v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "UltrasonicSpheres: Localized, Multi-Channel Sound Spheres Using Off-the-Shelf Speakers and Earables", "abstract": "We present a demo ofUltrasonicSpheres, a novel system for location-specific\naudio delivery using wearable earphones that decode ultrasonic signals into\naudible sound. Unlike conventional beamforming setups, UltrasonicSpheres relies\non single ultrasonic speakers to broadcast localized audio with multiple\nchannels, each encoded on a distinct ultrasonic carrier frequency. Users\nwearing our acoustically transparent earphones can demodulate their selected\nstream, such as exhibit narrations in a chosen language, while remaining fully\naware of ambient environmental sounds. The experience preserves spatial audio\nperception, giving the impression that the sound originates directly from the\nphysical location of the source. This enables personalized, localized audio\nwithout requiring pairing, tracking, or additional infrastructure. Importantly,\nvisitors not equipped with the earphones are unaffected, as the ultrasonic\nsignals are inaudible to the human ear. Our demo invites participants to\nexplore multiple co-located audio zones and experience how UltrasonicSpheres\nsupports unobtrusive delivery of personalized sound in public spaces.", "published": "2025-06-03 10:13:24", "link": "http://arxiv.org/abs/2506.02715v1", "categories": ["cs.SD", "cs.HC", "eess.AS"], "primary_category": "cs.SD"}
{"title": "On the Language and Gender Biases in PSTN, VoIP and Neural Audio Codecs", "abstract": "In recent years, there has been a growing focus on fairness and inclusivity\nwithin speech technology, particularly in areas such as automatic speech\nrecognition and speech sentiment analysis. When audio is transcoded prior to\nprocessing, as is the case in streaming or real-time applications, any inherent\nbias in the coding mechanism may result in disparities. This not only affects\nuser experience but can also have broader societal implications by perpetuating\nstereotypes and exclusion. Thus, it is important that audio coding mechanisms\nare unbiased. In this work, we contribute towards the scarce research with\nrespect to language and gender biases of audio codecs. By analyzing the speech\nquality of over 2 million multilingual audio files after transcoding through a\nrepresentative subset of codecs (PSTN, VoIP and neural), our results indicate\nthat PSTN codecs are strongly biased in terms of gender and that neural codecs\nintroduce language biases.", "published": "2025-06-03 07:32:42", "link": "http://arxiv.org/abs/2506.02545v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Adaptive Differential Denoising for Respiratory Sounds Classification", "abstract": "Automated respiratory sound classification faces practical challenges from\nbackground noise and insufficient denoising in existing systems.\n  We propose Adaptive Differential Denoising network, that integrates noise\nsuppression and pathological feature preservation via three innovations:\n  1) Adaptive Frequency Filter with learnable spectral masks and soft shrink to\neliminate noise while retaining diagnostic high-frequency components;\n  2) A Differential Denoise Layer using differential attention to reduce\nnoise-induced variations through augmented sample comparisons;\n  3) A bias denoising loss jointly optimizing classification and robustness\nwithout clean labels.\n  Experiments on the ICBHI2017 dataset show that our method achieves 65.53\\% of\nthe Score, which is improved by 1.99\\% over the previous sota method.\n  The code is available in https://github.com/deegy666/ADD-RSC", "published": "2025-06-03 06:32:27", "link": "http://arxiv.org/abs/2506.02505v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "DnR-nonverbal: Cinematic Audio Source Separation Dataset Containing Non-Verbal Sounds", "abstract": "We propose a new dataset for cinematic audio source separation (CASS) that\nhandles non-verbal sounds. Existing CASS datasets only contain reading-style\nsounds as a speech stem. These datasets differ from actual movie audio, which\nis more likely to include acted-out voices. Consequently, models trained on\nconventional datasets tend to have issues where emotionally heightened voices,\nsuch as laughter and screams, are more easily separated as an effect, not\nspeech. To address this problem, we build a new dataset, DnR-nonverbal. The\nproposed dataset includes non-verbal sounds like laughter and screams in the\nspeech stem. From the experiments, we reveal the issue of non-verbal sound\nextraction by the current CASS model and show that our dataset can effectively\naddress the issue in the synthetic and actual movie audio. Our dataset is\navailable at https://zenodo.org/records/15470640.", "published": "2025-06-03 06:25:53", "link": "http://arxiv.org/abs/2506.02499v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SOVA-Bench: Benchmarking the Speech Conversation Ability for LLM-based Voice Assistant", "abstract": "Thanks to the steady progress of large language models (LLMs), speech\nencoding algorithms and vocoder structure, recent advancements have enabled\ngenerating speech response directly from a user instruction. However,\nbenchmarking the generated speech quality has been a neglected but critical\nissue, considering the shift from the pursuit of semantic accuracy to vivid and\nspontaneous speech flow. Previous evaluation focused on the\nspeech-understanding ability, lacking a quantification of acoustic quality. In\nthis paper, we propose Speech cOnversational Voice Assistant Benchmark\n(SOVA-Bench), providing a comprehension comparison of the general knowledge,\nspeech recognition and understanding, along with both semantic and acoustic\ngenerative ability between available speech LLMs. To the best of our knowledge,\nSOVA-Bench is one of the most systematic evaluation frameworks for speech LLMs,\ninspiring the direction of voice interaction systems.", "published": "2025-06-03 05:21:51", "link": "http://arxiv.org/abs/2506.02457v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Breaking the Barriers of Text-Hungry and Audio-Deficient AI", "abstract": "While global linguistic diversity spans more than 7164 recognized languages,\nthe current dominant architecture of machine intelligence remains fundamentally\nbiased toward written text. This bias excludes over 700 million people\nparticularly in rural and remote regions who are audio-literate. In this work,\nwe introduce a fully textless, audio-to-audio machine intelligence framework\ndesigned to serve this underserved population, and all the people who prefer\naudio-efficiency. Our contributions include novel Audio-to-Audio translation\narchitectures that bypass text entirely, including spectrogram-, scalogram-,\nwavelet-, and unit-based models. Central to our approach is the Multiscale\nAudio-Semantic Transform (MAST), a representation that encodes tonal, prosodic,\nspeaker, and expressive features. We further integrate MAST into a fractional\ndiffusion of mean-field-type framework powered by fractional Brownian motion.\nIt enables the generation of high-fidelity, semantically consistent speech\nwithout reliance on textual supervision. The result is a robust and scalable\nsystem capable of learning directly from raw audio, even in languages that are\nunwritten or rarely digitized. This work represents a fundamental shift toward\naudio-native machine intelligence systems, expanding access to language\ntechnologies for communities historically left out of the current machine\nintelligence ecosystem.", "published": "2025-06-03 05:02:14", "link": "http://arxiv.org/abs/2506.02443v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Trusted Fake Audio Detection Based on Dirichlet Distribution", "abstract": "With the continuous development of deep learning-based speech conversion and\nspeech synthesis technologies, the cybersecurity problem posed by fake audio\nhas become increasingly serious. Previously proposed models for defending\nagainst fake audio have attained remarkable performance. However, they all fall\nshort in modeling the trustworthiness of the decisions made by the models\nthemselves. Based on this, we put forward a plausible fake audio detection\napproach based on the Dirichlet distribution with the aim of enhancing the\nreliability of fake audio detection. Specifically, we first generate evidence\nthrough a neural network. Uncertainty is then modeled using the Dirichlet\ndistribution. By modeling the belief distribution with the parameters of the\nDirichlet distribution, an estimate of uncertainty can be obtained for each\ndecision. Finally, the predicted probabilities and corresponding uncertainty\nestimates are combined to form the final opinion. On the ASVspoof series\ndataset (i.e., ASVspoof 2019 LA, ASVspoof 2021 LA, and DF), we conduct a number\nof comparison experiments to verify the excellent performance of the proposed\nmodel in terms of accuracy, robustness, and trustworthiness.", "published": "2025-06-03 03:40:39", "link": "http://arxiv.org/abs/2506.02401v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Enhancing Lyrics Transcription on Music Mixtures with Consistency Loss", "abstract": "Automatic Lyrics Transcription (ALT) aims to recognize lyrics from singing\nvoices, similar to Automatic Speech Recognition (ASR) for spoken language, but\nfaces added complexity due to domain-specific properties of the singing voice.\nWhile foundation ASR models show robustness in various speech tasks, their\nperformance degrades on singing voice, especially in the presence of musical\naccompaniment. This work focuses on this performance gap and explores Low-Rank\nAdaptation (LoRA) for ALT, investigating both single-domain and dual-domain\nfine-tuning strategies. We propose using a consistency loss to better align\nvocal and mixture encoder representations, improving transcription on mixture\nwithout relying on singing voice separation. Our results show that while\nna\\\"ive dual-domain fine-tuning underperforms, structured training with\nconsistency loss yields modest but consistent gains, demonstrating the\npotential of adapting ASR foundation models for music.", "published": "2025-06-03 00:29:49", "link": "http://arxiv.org/abs/2506.02339v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "AI-Augmented OTDR Fault Localization Framework for Resilient Rural Fiber Networks in the United States", "abstract": "This research presents a novel framework that combines traditional Optical\nTime-Domain Reflectometer (OTDR) signal analysis with machine learning to\nlocalize and classify fiber optic faults in rural broadband infrastructures.\nThe proposed system addresses a critical need in the expansion of middle-mile\nand last-mile networks, particularly in regions targeted by the U.S. Broadband\nEquity, Access, and Deployment (BEAD) Program. By enhancing fault diagnosis\nthrough a predictive, AI-based model, this work enables proactive network\nmaintenance in low-resource environments. Experimental evaluations using a\ncontrolled fiber testbed and synthetic datasets simulating rural network\nconditions demonstrate that the proposed method significantly improves\ndetection accuracy and reduces false positives compared to conventional\nthresholding techniques. The solution offers a scalable, field-deployable tool\nfor technicians and ISPs engaged in rural broadband deployment.", "published": "2025-06-03 16:23:12", "link": "http://arxiv.org/abs/2506.03041v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Derivation of CRB and Refined SINR Expressions for OTFS-RSMA LEO ISAC Systems", "abstract": "This document provides detailed step-by-step derivations for the Cram\\'er-Rao\nBounds (CRB) for sensing parameters and the refined\nSignal-to-Interference-plus-Noise Ratio (SINR) expressions under imperfect\nChannel State Information (CSI) and imperfect Successive Interference\nCancellation (SIC) for the Orthogonal Time Frequency Space (OTFS)\nRate-Splitting Multiple Access (RSMA) framework presented in our main work \"An\nIntegrated OTFS-RSMA Framework for LEO Satellite ISAC: Modeling, Metrics, and\nPotential\". These derivations support the analytical expressions and models in\nthe broad main discussion.", "published": "2025-06-03 11:42:00", "link": "http://arxiv.org/abs/2506.02771v1", "categories": ["eess.SP", "41AXX"], "primary_category": "eess.SP"}
{"title": "Coordinated Multi-BS SSB Beam Design for Enhanced Initial Access Coverage", "abstract": "Ensuring strong synchronization signal block (SSB) coverage is essential for\nreliable user equipment (UE) connection during initial access. While techniques\nsuch as power boosting and network densification are commonly used, this work\nexplores joint transmission (JT) of SSBs as an alternative to enhance coverage.\nAlthough JT is widely applied in data transmission, its use for SSBs has not\nbeen explored due to the lack of channel state information, which prevents\ncoherent signal alignment across base stations (BSs). To address this, we\npropose a repetition-based JT strategy using a small set of predefined phase\nconfigurations at the BSs. This enables the UE to coherently combine multiple\nSSB receptions and achieve constructive gain regardless of its location. To\nreduce overhead, a limited number of joint beam configurations is selected to\nmaximize the coverage. Simulation results under the line-of-sight conditions\nshow up to 6 dB relative SNR gain with JT of SSBs using 4 BSs, compared to\nindependent SSB transmission under the same resource budget. These results\nhighlight the potential of JT to improve the coverage of SSBs during the\ninitial access.", "published": "2025-06-03 11:24:22", "link": "http://arxiv.org/abs/2506.02760v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Refined Metrics, Sensing Limits, and Resource Allocation in OTFS-RSMA LEO ISAC", "abstract": "This paper develops an integrated OTFS-RSMA framework employing advanced SP\ntechniques tailored for this demanding environment. We derive refined\ncommunication performance metrics, specifically SINR expressions capturing the\npractical effects of ICSI and ISIC. Moreover, fundamental sensing limits are\nestablished via CRB derivation incorporating parameter-dependent echo gain,\nlinking waveform SP properties to estimation accuracy. The resource allocation\nis formulated as a non-convex optimization problem aiming for Max-Min Fairness\nunder constraints derived from these SP metrics. Illustrative results, obtained\nvia GA optimization, crucially demonstrate that the proposed RSMA scheme\nuniquely enables the simultaneous satisfaction of stringent communication and\nsensing constraints metrics, a capability not achieved by conventional SDMA.\nSuch results {highlight the efficacy of the integrated OTFS-RSMA precoding and\noptimization approach for designing robust and feasible LEO-ISAC systems.\n  Index Terms -- ISAC, LEO, OTFS, RSMA, Channel Modeling, CRB, SINR, ICSI,\nISIC, Resource Allocation, Max-Min Fairness, Delay-Doppler (DD) Processing,\nSatellite Communications.", "published": "2025-06-03 08:40:14", "link": "http://arxiv.org/abs/2506.02624v1", "categories": ["eess.SP", "60 Applications of stochastic analysis"], "primary_category": "eess.SP"}
{"title": "Large Language Models Can Achieve Explainable and Training-Free One-shot HRRP ATR", "abstract": "This letter introduces a pioneering, training-free and explainable framework\nfor High-Resolution Range Profile (HRRP) automatic target recognition (ATR)\nutilizing large-scale pre-trained Large Language Models (LLMs). Diverging from\nconventional methods requiring extensive task-specific training or fine-tuning,\nour approach converts one-dimensional HRRP signals into textual scattering\ncenter representations. Prompts are designed to align LLMs' semantic space for\nATR via few-shot in-context learning, effectively leveraging its vast\npre-existing knowledge without any parameter update. We make our codes publicly\navailable to foster research into LLMs for HRRP ATR.", "published": "2025-06-03 05:32:17", "link": "http://arxiv.org/abs/2506.02465v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "On the Performance of Pinching-Antenna Systems (PASS) with Orthogonal and Non-Orthogonal Multiple Access", "abstract": "This paper conducts a comprehensive performance analysis for pinching-antenna\nsystems (PASS) under both orthogonal multiple access (OMA) and non-orthogonal\nmultiple access (NOMA) transmission. Given the cost of waveguides, we consider\na scenario where the waveguide is not deployed in all rooms, i.e., some users\nare beyond the line-of-sight (LoS) link service area of the PASS. Specifically,\nwe consider a PASS where a pinching antenna in one room serves two users\nlocated in separate rooms. The wireless transmissions between the pinching\nantenna and the users are performed via LoS and non-line-of-sight (NLoS) links,\nrespectively. Closed-form expressions for the outage probabilities (OPs) of the\ntwo users are derived for the considered system. Furthermore, asymptotic\nanalyses in the high signal-to-noise ratio (SNR) regime are performed to reveal\nthe achievable diversity orders. Numerical simulations validate the accuracy of\nthe theoretical analysis and show that: 1) compared with conventional antenna\nsystems (CASS), the OP of the LoS user in PASS is significantly reduced for\nboth OMA and NOMA schemes in the middle SNR regime and approaches zero as the\nSNR increases; 2) since the diversity orders of the NLoS user in CASS and PASS\nare the same, the movement of the pinching antenna has no significant effect on\nthe OP of the NLoS user for the OMA and NOMA scenarios.", "published": "2025-06-03 04:08:42", "link": "http://arxiv.org/abs/2506.02420v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Passive Multi-Target Visible Light Positioning Based on Multi-Camera Joint Optimization", "abstract": "Camera-based visible light positioning (VLP) has emerged as a promising\nindoor positioning technique. However, the need for dedicated LED\ninfrastructure and on-target cameras in existing algorithms limits their\nscalability and increases deployment costs. To address these limitations, this\nletter proposes a passive VLP algorithm based on Multi-Camera Joint\nOptimization (MCJO). In the considered system, multiple pre-calibrated cameras\nmounted on the ceiling continuously capture images of positioning targets\nequipped with point light sources, and can simultaneously localize these\ntargets at the server. In particular, the proposed MCJO comprises two stages:\nIt first estimates target positions via linear least squares from multi-view\nprojection rays; then refines these positions through nonlinear joint\noptimization to minimize the reprojection error. Simulation results show that\nMCJO can achieve millimeter-level accuracy, with an improvement of 19% over\nstate-of-the-art algorithms. Experimental results further show that MCJO can\nachieve an average position error as low as 5.63 mm.", "published": "2025-06-03 04:05:43", "link": "http://arxiv.org/abs/2506.02418v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "UniWorld: High-Resolution Semantic Encoders for Unified Visual Understanding and Generation", "abstract": "Although existing unified models achieve strong performance in\nvision-language understanding and text-to-image generation, they remain limited\nin addressing image perception and manipulation -- capabilities increasingly\ndemanded in practical applications. Recently, OpenAI introduced the powerful\nGPT-4o-Image model, which showcases advanced capabilities in comprehensive\nimage perception and manipulation, sparking widespread interest. Through\ncarefully designed experiments, we observe that GPT-4o-Image likely relies on\nsemantic encoders rather than VAEs for feature extraction, despite VAEs being\ncommonly regarded as crucial for image manipulation tasks. Inspired by this\ninsight, we propose UniWorld, a unified generative framework built upon\nsemantic features extracted from powerful multimodal large language models and\ncontrastive semantic encoders. Using only 2.7M training data, UniWorld achieves\nimpressive performance across diverse tasks, including image understanding,\ngeneration, manipulation, and perception. We fully open-source the UniWorld\nframework, including model weights, training and evaluation scripts, and\ndatasets to promote reproducibility and further research.", "published": "2025-06-03 17:59:33", "link": "http://arxiv.org/abs/2506.03147v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Critique-GRPO: Advancing LLM Reasoning with Natural Language and Numerical Feedback", "abstract": "Recent advances in reinforcement learning (RL) with numerical feedback, such\nas scalar rewards, have significantly enhanced the complex reasoning\ncapabilities of large language models (LLMs). Despite this success, we identify\nthree key challenges encountered by RL with solely numerical feedback:\nperformance plateaus, limited effectiveness of self-reflection, and persistent\nfailures. We then demonstrate that RL-finetuned models, even after exhibiting\nperformance plateaus, can generate correct refinements on persistently failed\nproblems by leveraging natural language feedback in the form of critiques.\nBuilding on this insight, we propose Critique-GRPO, an online RL framework that\nintegrates both natural language and numerical feedback for effective policy\noptimization. Critique-GRPO enables LLMs to learn from initial responses and\ncritique-guided refinements simultaneously while maintaining exploration.\nExtensive experiments using Qwen2.5-7B-Base and Qwen3-8B-Base show that\nCritique-GRPO consistently outperforms supervised learning-based and RL-based\nfine-tuning approaches across eight challenging mathematical, STEM, and general\nreasoning tasks, improving average pass@1 scores by approximately 4.5% and 5%,\nrespectively. Notably, Critique-GRPO surpasses a strong baseline that\nincorporates expert demonstrations within online RL. Further analysis reveals\ntwo critical insights about policy exploration: (1) higher entropy does not\nalways guarantee efficient learning from exploration, and (2) longer responses\ndo not necessarily lead to more effective exploration.", "published": "2025-06-03 17:39:02", "link": "http://arxiv.org/abs/2506.03106v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Demystifying Reasoning Dynamics with Mutual Information: Thinking Tokens are Information Peaks in LLM Reasoning", "abstract": "Large reasoning models (LRMs) have demonstrated impressive capabilities in\ncomplex problem-solving, yet their internal reasoning mechanisms remain poorly\nunderstood. In this paper, we investigate the reasoning trajectories of LRMs\nfrom an information-theoretic perspective. By tracking how mutual information\n(MI) between intermediate representations and the correct answer evolves during\nLRM reasoning, we observe an interesting MI peaks phenomenon: the MI at\nspecific generative steps exhibits a sudden and significant increase during\nLRM's reasoning process. We theoretically analyze such phenomenon and show that\nas MI increases, the probability of model's prediction error decreases.\nFurthermore, these MI peaks often correspond to tokens expressing reflection or\ntransition, such as ``Hmm'', ``Wait'' and ``Therefore,'' which we term as the\nthinking tokens. We then demonstrate that these thinking tokens are crucial for\nLRM's reasoning performance, while other tokens has minimal impacts. Building\non these analyses, we propose two simple yet effective methods to improve LRM's\nreasoning performance, by delicately leveraging these thinking tokens. Overall,\nour work provides novel insights into the reasoning mechanisms of LRMs and\noffers practical ways to improve their reasoning capabilities. The code is\navailable at https://github.com/ChnQ/MI-Peaks.", "published": "2025-06-03 13:31:10", "link": "http://arxiv.org/abs/2506.02867v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "On Entity Identification in Language Models", "abstract": "We analyze the extent to which internal representations of language models\n(LMs) identify and distinguish mentions of named entities, focusing on the\nmany-to-many correspondence between entities and their mentions. We first\nformulate two problems of entity mentions -- ambiguity and variability -- and\npropose a framework analogous to clustering quality metrics. Specifically, we\nquantify through cluster analysis of LM internal representations the extent to\nwhich mentions of the same entity cluster together and mentions of different\nentities remain separated. Our experiments examine five Transformer-based\nautoregressive models, showing that they effectively identify and distinguish\nentities with metrics analogous to precision and recall ranging from 0.66 to\n0.9. Further analysis reveals that entity-related information is compactly\nrepresented in a low-dimensional linear subspace at early LM layers.\nAdditionally, we clarify how the characteristics of entity representations\ninfluence word prediction performance. These findings are interpreted through\nthe lens of isomorphism between LM representations and entity-centric knowledge\nstructures in the real world, providing insights into how LMs internally\norganize and use entity information.", "published": "2025-06-03 09:55:21", "link": "http://arxiv.org/abs/2506.02701v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MASTER: Enhancing Large Language Model via Multi-Agent Simulated Teaching", "abstract": "Instruction fine-tuning is crucial in NLP tasks, enhancing pretrained models'\ninstruction-following capabilities and task-specific performance. However,\nobtaining high-quality fine-tuning data for large models is challenging due to\ndata collection difficulties and high production costs. To address this, we\npropose MASTER, a novel data augmentation method that enriches original data\nthrough interactions among multiple agents with varying cognitive levels. We\nsimulate three pedagogically grounded teaching scenarios, leveraging\nmulti-agent conversations to generate high-quality teacher-student interaction\ndata. Utilizing MASTER, we construct BOOST-QA, a fine-tuning dataset augmented\nfrom existing datasets like Orca-Math-200k, ProcQA, and OpenHermes2.5.\nExperiments show that models fine-tuned with BOOST-QA perform excellently\nacross multiple benchmarks, demonstrating strong multitask generalization.\nNotably, MASTER significantly improves models' reasoning abilities in complex\ntasks, providing valuable insights for future research.", "published": "2025-06-03 09:41:35", "link": "http://arxiv.org/abs/2506.02689v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CoRe-MMRAG: Cross-Source Knowledge Reconciliation for Multimodal RAG", "abstract": "Multimodal Retrieval-Augmented Generation (MMRAG) has been introduced to\nenhance Multimodal Large Language Models by incorporating externally retrieved\nmultimodal knowledge, but it introduces two challenges: Parametric-Retrieved\nKnowledge Inconsistency (PRKI), where discrepancies between parametric and\nretrieved knowledge create uncertainty in determining reliability, and\nVisual-Textual Knowledge Inconsistency (VTKI), where misalignment between\nvisual and textual sources disrupts entity representation. To address these\nchallenges, we propose Cross-source knowledge \\textbf{Re}conciliation for\nMultimodal RAG (CoRe-MMRAG), a novel end-to-end framework that effectively\nreconciles inconsistencies across knowledge sources. CoRe-MMRAG follows a\nfour-stage pipeline: it first generates an internal response from parametric\nknowledge, then selects the most relevant multimodal evidence via joint\nsimilarity assessment, generates an external response, and finally integrates\nboth to produce a reliable answer. Additionally, a specialized training\nparadigm enhances knowledge source discrimination, multimodal integration, and\nunified answer generation. Experiments on KB-VQA benchmarks show that\nCoRe-MMRAG achieves substantial improvements over baseline methods, achieving\n5.6% and 9.3% performance gains on InfoSeek and Encyclopedic-VQA, respectively.", "published": "2025-06-03 07:32:40", "link": "http://arxiv.org/abs/2506.02544v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Should LLM Safety Be More Than Refusing Harmful Instructions?", "abstract": "This paper presents a systematic evaluation of Large Language Models' (LLMs)\nbehavior on long-tail distributed (encrypted) texts and their safety\nimplications. We introduce a two-dimensional framework for assessing LLM\nsafety: (1) instruction refusal-the ability to reject harmful obfuscated\ninstructions, and (2) generation safety-the suppression of generating harmful\nresponses. Through comprehensive experiments, we demonstrate that models that\npossess capabilities to decrypt ciphers may be susceptible to\nmismatched-generalization attacks: their safety mechanisms fail on at least one\nsafety dimension, leading to unsafe responses or over-refusal. Based on these\nfindings, we evaluate a number of pre-LLM and post-LLM safeguards and discuss\ntheir strengths and limitations. This work contributes to understanding the\nsafety of LLM in long-tail text scenarios and provides directions for\ndeveloping robust safety mechanisms.", "published": "2025-06-03 05:00:12", "link": "http://arxiv.org/abs/2506.02442v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Comparative Analysis of AI Agent Architectures for Entity Relationship Classification", "abstract": "Entity relationship classification remains a challenging task in information\nextraction, especially in scenarios with limited labeled data and complex\nrelational structures. In this study, we conduct a comparative analysis of\nthree distinct AI agent architectures designed to perform relation\nclassification using large language models (LLMs). The agentic architectures\nexplored include (1) reflective self-evaluation, (2) hierarchical task\ndecomposition, and (3) a novel multi-agent dynamic example generation\nmechanism, each leveraging different modes of reasoning and prompt adaptation.\nIn particular, our dynamic example generation approach introduces real-time\ncooperative and adversarial prompting. We systematically compare their\nperformance across multiple domains and model backends. Our experiments\ndemonstrate that multi-agent coordination consistently outperforms standard\nfew-shot prompting and approaches the performance of fine-tuned models. These\nfindings offer practical guidance for the design of modular, generalizable\nLLM-based systems for structured relation extraction. The source codes and\ndataset are available at https://github.com/maryambrj/ALIEN.git.", "published": "2025-06-03 04:19:47", "link": "http://arxiv.org/abs/2506.02426v2", "categories": ["cs.CL", "cs.AI", "I.2.7; I.2.1"], "primary_category": "cs.CL"}
{"title": "High Performance Space Debris Tracking in Complex Skylight Backgrounds with a Large-Scale Dataset", "abstract": "With the rapid development of space exploration, space debris has attracted\nmore attention due to its potential extreme threat, leading to the need for\nreal-time and accurate debris tracking. However, existing methods are mainly\nbased on traditional signal processing, which cannot effectively process the\ncomplex background and dense space debris. In this paper, we propose a deep\nlearning-based Space Debris Tracking Network~(SDT-Net) to achieve highly\naccurate debris tracking. SDT-Net effectively represents the feature of debris,\nenhancing the efficiency and stability of end-to-end model learning. To train\nand evaluate this model effectively, we also produce a large-scale dataset\nSpace Debris Tracking Dataset (SDTD) by a novel observation-based data\nsimulation scheme. SDTD contains 18,040 video sequences with a total of 62,562\nframes and covers 250,000 synthetic space debris. Extensive experiments\nvalidate the effectiveness of our model and the challenging of our dataset.\nFurthermore, we test our model on real data from the Antarctic Station,\nachieving a MOTA score of 70.6%, which demonstrates its strong transferability\nto real-world scenarios. Our dataset and code will be released soon.", "published": "2025-06-03 08:30:25", "link": "http://arxiv.org/abs/2506.02614v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Multi Layered Autonomy and AI Ecologies in Robotic Art Installations", "abstract": "Symbiosis of Agents is a large-scale installation by Baoyang Chen\n(baoyangchen.com) that embeds AI-driven robots in an immersive, mirror-lined\narena, probing the tension between machine agency and artistic authorship.\nDrawing on early cybernetics, rule-based conceptual art, and seminal robotic\nworks, it orchestrates fluid exchanges among robotic arms, quadruped machines,\ntheir environment, and the public. A three tier faith system pilots the\necology: micro-level adaptive tactics, meso-level narrative drives, and a\nmacro-level prime directive. This hierarchy lets behaviors evolve organically\nin response to environmental cues and even a viewer's breath, turning\nspectators into co-authors of the unfolding drama. Framed by a speculative\nterraforming scenario that recalls the historical exploitation of marginalized\nlabor, the piece asks who bears responsibility in AI-mediated futures.\nChoreographed motion, AI-generated scripts, reactive lighting, and drifting fog\ncast the robots as collaborators rather than tools, forging a living, emergent\nartwork. Exhibited internationally, Symbiosis of Agents shows how cybernetic\nfeedback, robotic experimentation, and conceptual rule-making can converge to\nredefine agency, authorship, and ethics in contemporary art.", "published": "2025-06-03 08:28:19", "link": "http://arxiv.org/abs/2506.02606v2", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "ADFormer: Aggregation Differential Transformer for Passenger Demand Forecasting", "abstract": "Passenger demand forecasting helps optimize vehicle scheduling, thereby\nimproving urban efficiency. Recently, attention-based methods have been used to\nadequately capture the dynamic nature of spatio-temporal data. However,\nexisting methods that rely on heuristic masking strategies cannot fully adapt\nto the complex spatio-temporal correlations, hindering the model from focusing\non the right context. These works also overlook the high-level correlations\nthat exist in the real world. Effectively integrating these high-level\ncorrelations with the original correlations is crucial. To fill this gap, we\npropose the Aggregation Differential Transformer (ADFormer), which offers new\ninsights to demand forecasting promotion. Specifically, we utilize Differential\nAttention to capture the original spatial correlations and achieve attention\ndenoising. Meanwhile, we design distinct aggregation strategies based on the\nnature of space and time. Then, the original correlations are unified with the\nhigh-level correlations, enabling the model to capture holistic spatio-temporal\nrelations. Experiments conducted on taxi and bike datasets confirm the\neffectiveness and efficiency of our model, demonstrating its practical value.\nThe code is available at https://github.com/decisionintelligence/ADFormer.", "published": "2025-06-03 07:55:51", "link": "http://arxiv.org/abs/2506.02576v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "FlySearch: Exploring how vision-language models explore", "abstract": "The real world is messy and unstructured. Uncovering critical information\noften requires active, goal-driven exploration. It remains to be seen whether\nVision-Language Models (VLMs), which recently emerged as a popular zero-shot\ntool in many difficult tasks, can operate effectively in such conditions. In\nthis paper, we answer this question by introducing FlySearch, a 3D, outdoor,\nphotorealistic environment for searching and navigating to objects in complex\nscenes. We define three sets of scenarios with varying difficulty and observe\nthat state-of-the-art VLMs cannot reliably solve even the simplest exploration\ntasks, with the gap to human performance increasing as the tasks get harder. We\nidentify a set of central causes, ranging from vision hallucination, through\ncontext misunderstanding, to task planning failures, and we show that some of\nthem can be addressed by finetuning. We publicly release the benchmark,\nscenarios, and the underlying codebase.", "published": "2025-06-03 14:03:42", "link": "http://arxiv.org/abs/2506.02896v2", "categories": ["cs.CV", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Go Beyond Earth: Understanding Human Actions and Scenes in Microgravity Environments", "abstract": "Despite substantial progress in video understanding, most existing datasets\nare limited to Earth's gravitational conditions. However, microgravity alters\nhuman motion, interactions, and visual semantics, revealing a critical gap for\nreal-world vision systems. This presents a challenge for domain-robust video\nunderstanding in safety-critical space applications. To address this, we\nintroduce MicroG-4M, the first benchmark for spatio-temporal and semantic\nunderstanding of human activities in microgravity. Constructed from real-world\nspace missions and cinematic simulations, the dataset includes 4,759 clips\ncovering 50 actions, 1,238 context-rich captions, and over 7,000\nquestion-answer pairs on astronaut activities and scene understanding.\nMicroG-4M supports three core tasks: fine-grained multi-label action\nrecognition, temporal video captioning, and visual question answering, enabling\na comprehensive evaluation of both spatial localization and semantic reasoning\nin microgravity contexts. We establish baselines using state-of-the-art models.\nAll data, annotations, and code are available at\nhttps://github.com/LEI-QI-233/HAR-in-Space.", "published": "2025-06-03 13:15:19", "link": "http://arxiv.org/abs/2506.02845v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Open-PMC-18M: A High-Fidelity Large Scale Medical Dataset for Multimodal Representation Learning", "abstract": "Compound figures, which are multi-panel composites containing diverse\nsubfigures, are ubiquitous in biomedical literature, yet large-scale subfigure\nextraction remains largely unaddressed. Prior work on subfigure extraction has\nbeen limited in both dataset size and generalizability, leaving a critical open\nquestion: How does high-fidelity image-text alignment via large-scale subfigure\nextraction impact representation learning in vision-language models? We address\nthis gap by introducing a scalable subfigure extraction pipeline based on\ntransformer-based object detection, trained on a synthetic corpus of 500,000\ncompound figures, and achieving state-of-the-art performance on both ImageCLEF\n2016 and synthetic benchmarks. Using this pipeline, we release OPEN-PMC-18M, a\nlarge-scale high quality biomedical vision-language dataset comprising 18\nmillion clinically relevant subfigure-caption pairs spanning radiology,\nmicroscopy, and visible light photography. We train and evaluate\nvision-language models on our curated datasets and show improved performance\nacross retrieval, zero-shot classification, and robustness benchmarks,\noutperforming existing baselines. We release our dataset, models, and code to\nsupport reproducible benchmarks and further study into biomedical\nvision-language modeling and representation learning.", "published": "2025-06-03 10:53:19", "link": "http://arxiv.org/abs/2506.02738v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FaceSleuth: Learning-Driven Single-Orientation Attention Verifies Vertical Dominance in Micro-Expression Recognition", "abstract": "Micro-expression recognition (MER) demands models that can amplify\nmillisecond-level, low-amplitude facial motions while suppressing\nidentity-specific appearance. We introduce FaceSleuth, a dual-stream\narchitecture that (1) enhances motion along the empirically dominant vertical\naxix through a Continuously Vertical Attention (CVA) block, (2) localises the\nresulting signals with a Facial Position Focalizer built on hierarchical\ncross-window attention, and (3) steers feature learning toward physiologically\nmeaningful regions via lightweight Action-Unit embeddings. To examine whether\nthe hand-chosen vertical axis is indeed optimal, we further propose a\nSingle-Orientation Attention (SOA) module that learns its own pooling direction\nend-to-end. SOA is differentiable, adds only 0.16 % parameters, and collapses\nto CVA when the learned angle converges to {\\Pi}/2. In practice, SOA reliably\ndrifts to 88{\\deg}, confirming the effectiveness of the vertical prior while\ndelivering consistent gains. On three standard MER benchmarks, FaceSleuth with\nCVA already surpasses previous state-of-the-art methods; plugging in SOA lifts\naccuracy and F1 score performance to 95.1 % / 0.918 on CASME II, 87.1 % / 0.840\non SAMM, and 92.9 % / 0.917 on MMEW without sacrificing model compactness.\nThese results establish a new state of the art and, for the first time, provide\nempirical evidence that the vertical attention bias is the most discriminative\norientation for MER.", "published": "2025-06-03 09:44:18", "link": "http://arxiv.org/abs/2506.02695v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MMM4Rec: A Transfer-Efficient Framework for Multi-modal Sequential Recommendation", "abstract": "Sequential Recommendation (SR) systems model user preferences by analyzing\ninteraction histories. Although transferable multi-modal SR architectures\ndemonstrate superior performance compared to traditional ID-based approaches,\ncurrent methods incur substantial fine-tuning costs when adapting to new\ndomains due to complex optimization requirements and negative transfer effects\n- a significant deployment bottleneck that hinders engineers from efficiently\nrepurposing pre-trained models for novel application scenarios with minimal\ntuning overhead. We propose MMM4Rec (Multi-Modal Mamba for Sequential\nRecommendation), a novel multi-modal SR framework that incorporates a dedicated\nalgebraic constraint mechanism for efficient transfer learning. By combining\nState Space Duality (SSD)'s temporal decay properties with a time-aware\nmodeling design, our model dynamically prioritizes key modality information,\novercoming limitations of Transformer-based approaches. The framework\nimplements a constrained two-stage process: (1) sequence-level cross-modal\nalignment via shared projection matrices, followed by (2) temporal fusion using\nour newly designed Cross-SSD module and dual-channel Fourier adaptive\nfiltering. This architecture maintains semantic consistency while suppressing\nnoise propagation.MMM4Rec achieves rapid fine-tuning convergence with simple\ncross-entropy loss, significantly improving multi-modal recommendation accuracy\nwhile maintaining strong transferability. Extensive experiments demonstrate\nMMM4Rec's state-of-the-art performance, achieving the maximum 31.78% NDCG@10\nimprovement over existing models and exhibiting 10 times faster average\nconvergence speed when transferring to large-scale downstream datasets.", "published": "2025-06-03 14:18:19", "link": "http://arxiv.org/abs/2506.02916v2", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "GL-LowPopArt: A Nearly Instance-Wise Minimax-Optimal Estimator for Generalized Low-Rank Trace Regression", "abstract": "We present `GL-LowPopArt`, a novel Catoni-style estimator for generalized\nlow-rank trace regression. Building on `LowPopArt` (Jang et al., 2024), it\nemploys a two-stage approach: nuclear norm regularization followed by matrix\nCatoni estimation. We establish state-of-the-art estimation error bounds,\nsurpassing existing guarantees (Fan et al., 2019; Kang et al., 2022), and\nreveal a novel experimental design objective, $\\mathrm{GL}(\\pi)$. The key\ntechnical challenge is controlling bias from the nonlinear inverse link\nfunction, which we address by our two-stage approach. We prove a *local*\nminimax lower bound, showing that our `GL-LowPopArt` enjoys instance-wise\noptimality up to the condition number of the ground-truth Hessian. Applications\ninclude generalized linear matrix completion, where `GL-LowPopArt` achieves a\nstate-of-the-art Frobenius error guarantee, and **bilinear dueling bandits**, a\nnovel setting inspired by general preference learning (Zhang et al., 2024). Our\nanalysis of a `GL-LowPopArt`-based explore-then-commit algorithm reveals a new,\npotentially interesting problem-dependent quantity, along with improved Borda\nregret bound than vectorization (Wu et al., 2024).", "published": "2025-06-03 16:52:24", "link": "http://arxiv.org/abs/2506.03074v2", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "PC-MoE: Memory-Efficient and Privacy-Preserving Collaborative Training for Mixture-of-Experts LLMs", "abstract": "Mixture-of-Experts (MoE) has been gaining popularity due to its successful\nadaptation to large language models (LLMs). In this work, we introduce\nPrivacy-preserving Collaborative Mixture-of-Experts (PC-MoE), which leverages\nthe sparsity of the MoE architecture for memory-efficient decentralized\ncollaborative LLM training, enabling multiple parties with limited GPU-memory\nand data resources to collectively train more capable LLMs than they could\nachieve individually. At the same time, this approach protects training data\nprivacy of each participant by keeping training data, as well as parts of the\nforward pass signal and gradients locally within each party. By design, PC-MoE\nsynergistically combines the strengths of distributed computation with strong\nconfidentiality assurances. Unlike most privacy-preserving schemes, which pay\nfor confidentiality with lower task accuracy, our framework breaks that\ntrade-off: across seven popular LLM benchmarks, it almost matches (and\nsometimes exceeds) the performance and convergence rate of a fully centralized\nmodel, enjoys near 70% peak GPU RAM reduction, while being fully robust against\nreconstruction attacks.", "published": "2025-06-03 15:00:18", "link": "http://arxiv.org/abs/2506.02965v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Non-exchangeable evolutionary and mean field games and their applications", "abstract": "A replicator dynamic for non-exchangeable agents in a continuous action space\nis formulated and its well-posedness is proven in a space of probability\nmeasures. The non-exchangeability allows for the analysis of evolutionary games\ninvolving agents with distinct (and possibly infinitely many) types. We also\nexplicitly connect this replicator dynamic to a stationary mean field game,\nwhich determines the pairwise actions of the heterogeneous agents. Moreover, as\na byproduct of our theoretical results, we show that a class of nonlinear voter\nmodels, recently the subject of increasing interest, called q-voter models, can\nbe viewed as a replicator dynamic driven by a utility that is a power of the\nprobability density. This implies that non-exchangeable and/or mean-field game\nformulations of these models can also be constructed. We also present\ncomputational examples of evolutionary and mean field game models using a\nfinite difference method, focusing on tragedy of the commons and the q-voter\nmodel with non-exchangeable agents, of which are interesting cases from\ntheoretical and computational perspectives.", "published": "2025-06-03 09:00:03", "link": "http://arxiv.org/abs/2506.02644v2", "categories": ["math.OC", "cs.NA", "math.NA", "math.PR"], "primary_category": "math.OC"}
{"title": "A Data-Driven Diffusion-based Approach for Audio Deepfake Explanations", "abstract": "Evaluating explainability techniques, such as SHAP and LRP, in the context of\naudio deepfake detection is challenging due to lack of clear ground truth\nannotations. In the cases when we are able to obtain the ground truth, we find\nthat these methods struggle to provide accurate explanations. In this work, we\npropose a novel data-driven approach to identify artifact regions in deepfake\naudio. We consider paired real and vocoded audio, and use the difference in\ntime-frequency representation as the ground-truth explanation. The difference\nsignal then serves as a supervision to train a diffusion model to expose the\ndeepfake artifacts in a given vocoded audio. Experimental results on the VocV4\nand LibriSeVoc datasets demonstrate that our method outperforms traditional\nexplainability techniques, both qualitatively and quantitatively.", "published": "2025-06-03 22:10:53", "link": "http://arxiv.org/abs/2506.03425v1", "categories": ["eess.AS", "cs.AI", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Multi-Spectral Gaussian Splatting with Neural Color Representation", "abstract": "We present MS-Splatting -- a multi-spectral 3D Gaussian Splatting (3DGS)\nframework that is able to generate multi-view consistent novel views from\nimages of multiple, independent cameras with different spectral domains. In\ncontrast to previous approaches, our method does not require cross-modal camera\ncalibration and is versatile enough to model a variety of different spectra,\nincluding thermal and near-infra red, without any algorithmic changes.\n  Unlike existing 3DGS-based frameworks that treat each modality separately (by\noptimizing per-channel spherical harmonics) and therefore fail to exploit the\nunderlying spectral and spatial correlations, our method leverages a novel\nneural color representation that encodes multi-spectral information into a\nlearned, compact, per-splat feature embedding. A shallow multi-layer perceptron\n(MLP) then decodes this embedding to obtain spectral color values, enabling\njoint learning of all bands within a unified representation.\n  Our experiments show that this simple yet effective strategy is able to\nimprove multi-spectral rendering quality, while also leading to improved\nper-spectra rendering quality over state-of-the-art methods. We demonstrate the\neffectiveness of this new technique in agricultural applications to render\nvegetation indices, such as normalized difference vegetation index (NDVI).", "published": "2025-06-03 21:36:50", "link": "http://arxiv.org/abs/2506.03407v1", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.GR"}
{"title": "Quake: Adaptive Indexing for Vector Search", "abstract": "Vector search, the task of finding the k-nearest neighbors of\nhigh-dimensional vectors, underpins many machine learning applications,\nincluding recommendation systems and information retrieval. However, existing\napproximate nearest neighbor (ANN) methods perform poorly under dynamic, skewed\nworkloads where data distributions evolve. We introduce Quake, an adaptive\nindexing system that maintains low latency and high recall in such\nenvironments. Quake employs a hierarchical partitioning scheme that adjusts to\nupdates and changing access patterns, guided by a cost model that predicts\nquery latency based on partition sizes and access frequencies. Quake also\ndynamically optimizes query execution parameters to meet recall targets using a\nnovel recall estimation model. Furthermore, Quake utilizes optimized query\nprocessing, leveraging NUMA-aware parallelism for improved memory bandwidth\nutilization. To evaluate Quake, we prepare a Wikipedia vector search workload\nand develop a workload generator to create vector search workloads with\nconfigurable access patterns. Our evaluation shows that on dynamic workloads,\nQuake achieves query latency reductions of 1.5-22x and update latency\nreductions of 6-83x compared to state-of-the-art indexes SVS, DiskANN, HNSW,\nand SCANN.", "published": "2025-06-03 22:37:37", "link": "http://arxiv.org/abs/2506.03437v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "DistRAG: Towards Distance-Based Spatial Reasoning in LLMs", "abstract": "Many real world tasks where Large Language Models (LLMs) can be used require\nspatial reasoning, like Point of Interest (POI) recommendation and itinerary\nplanning. However, on their own LLMs lack reliable spatial reasoning\ncapabilities, especially about distances. To address this problem, we develop a\nnovel approach, DistRAG, that enables an LLM to retrieve relevant spatial\ninformation not explicitly learned during training. Our method encodes the\ngeodesic distances between cities and towns in a graph and retrieves a context\nsubgraph relevant to the question. Using this technique, our method enables an\nLLM to answer distance-based reasoning questions that it otherwise cannot\nanswer. Given the vast array of possible places an LLM could be asked about,\nDistRAG offers a flexible first step towards providing a rudimentary `world\nmodel' to complement the linguistic knowledge held in LLMs.", "published": "2025-06-03 22:10:39", "link": "http://arxiv.org/abs/2506.03424v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Universal Reusability in Recommender Systems: The Case for Dataset- and Task-Independent Frameworks", "abstract": "Recommender systems are pivotal in delivering personalized experiences across\nindustries, yet their adoption and scalability remain hindered by the need for\nextensive dataset- and task-specific configurations. Existing systems often\nrequire significant manual intervention, domain expertise, and engineering\neffort to adapt to new datasets or tasks, creating barriers to entry and\nlimiting reusability. In contrast, recent advancements in large language models\n(LLMs) have demonstrated the transformative potential of reusable systems,\nwhere a single model can handle diverse tasks without significant\nreconfiguration. Inspired by this paradigm, we propose the Dataset- and\nTask-Independent Recommender System (DTIRS), a framework aimed at maximizing\nthe reusability of recommender systems while minimizing barriers to entry.\nUnlike LLMs, which achieve task generalization directly, DTIRS focuses on\neliminating the need to rebuild or reconfigure recommendation pipelines for\nevery new dataset or task, even though models may still need retraining on new\ndata. By leveraging the novel Dataset Description Language (DsDL), DTIRS\nenables standardized dataset descriptions and explicit task definitions,\nallowing autonomous feature engineering, model selection, and optimization.\nThis paper introduces the concept of DTIRS and establishes a roadmap for\ntransitioning from Level-1 automation (dataset-agnostic but task-specific\nsystems) to Level-2 automation (fully dataset- and task-independent systems).\nAchieving this paradigm would maximize code reusability and lower barriers to\nadoption. We discuss key challenges, including the trade-offs between\ngeneralization and specialization, computational overhead, and scalability,\nwhile presenting DsDL as a foundational tool for this vision.", "published": "2025-06-03 21:00:34", "link": "http://arxiv.org/abs/2506.03391v1", "categories": ["cs.IR", "cs.AI", "cs.DB", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Impact of Rankings and Personalized Recommendations in Marketplaces", "abstract": "Individuals often navigate several options with incomplete knowledge of their\nown preferences. Information provisioning tools such as public rankings and\npersonalized recommendations have become central to helping individuals make\nchoices, yet their value proposition under different marketplace environments\nremains unexplored. This paper studies a stylized model to explore the impact\nof these tools in two marketplace settings: uncapacitated supply, where items\ncan be selected by any number of agents, and capacitated supply, where each\nitem is constrained to be matched to a single agent. We model the agents\nutility as a weighted combination of a common term which depends only on the\nitem, reflecting the item's population level quality, and an idiosyncratic\nterm, which depends on the agent item pair capturing individual specific\ntastes. Public rankings reveal the common term, while personalized\nrecommendations reveal both terms. In the supply unconstrained settings, both\npublic rankings and personalized recommendations improve welfare, with their\nrelative value determined by the degree of preference heterogeneity. Public\nrankings are effective when preferences are relatively homogeneous, while\npersonalized recommendations become critical as heterogeneity increases. In\ncontrast, in supply constrained settings, revealing just the common term, as\ndone by public rankings, provides limited benefit since the total common value\navailable is limited by capacity constraints, whereas personalized\nrecommendations, by revealing both common and idiosyncratic terms,\nsignificantly enhance welfare by enabling agents to match with items they\nidiosyncratically value highly. These results illustrate the interplay between\nsupply constraints and preference heterogeneity in determining the\neffectiveness of information provisioning tools, offering insights for their\ndesign and deployment in diverse settings.", "published": "2025-06-03 20:26:14", "link": "http://arxiv.org/abs/2506.03369v1", "categories": ["econ.TH", "cs.CY", "cs.IR"], "primary_category": "econ.TH"}
{"title": "Flagged Extensions and Numerical Simulations for Quantum Channel Capacity: Bridging Theory and Computation", "abstract": "I will investigate the capacities of noisy quantum channels through a\ncombined analytical and numerical approach. First, I introduce novel flagged\nextension techniques that embed a channel into a higher-dimensional space,\nenabling single-letter upper bounds on quantum and private capacities. My\nresults refine previous bounds and clarify noise thresholds beyond which\nquantum transmission vanishes. Second, I present a simulation framework that\nuses coherent information to estimate channel capacities in practice, focusing\non two canonical examples: the amplitude damping channel (which we confirm is\ndegradable and thus single-letter) and the depolarizing channel (whose capacity\nrequires multi-letter superadditivity). By parameterizing input qubit states on\nthe Bloch sphere, I numerically pinpoint the maximum coherent information for\neach channel and validate the flagged extension bounds. Notably, I capture the\nabrupt transition to zero capacity at high noise and observe superadditivity\nfor moderate noise levels.", "published": "2025-06-03 22:21:08", "link": "http://arxiv.org/abs/2506.03429v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Multishot Capacity of Networks with Restricted Adversaries", "abstract": "We investigate adversarial network coding and decoding, focusing on the\nmultishot regime and when the adversary is restricted to operate on a\nvulnerable region of the network. Errors can occur on a proper subset of the\nnetwork edges and are modeled via an adversarial channel. The paper contains\nboth bounds and capacity-achieving schemes for the Diamond Network, the\nMirrored Diamond Network, and generalizations of these networks. We also\ninitiate the study of the capacity of 3-level networks in the multishot setting\nby computing the multishot capacity of the Butterfly Network, considered in\n[IEEE Transactions on Information Theory, vol. 69, no. 6, 2023], which is a\nvariant of the network introduced by Ahlswede, Cai, Li and Yeung in 2000.", "published": "2025-06-03 20:12:52", "link": "http://arxiv.org/abs/2506.03361v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Relay Selection and User Equipment Admission in Resource-Efficient NextG Sidelink Communications", "abstract": "5G/6G sidelink communications addresses the challenge of connecting outer\nUEs, which are unable to directly access a base station (gNodeB), through inner\nUEs that act as relays to connect to the gNodeB. The key performance indicators\ninclude the achievable rates, the number of outer UEs that can connect to a\ngNodeB, and the latency experienced by outer UEs in establishing connections.\nWe consider problem of determining the assignment of outer UEs to inner UEs\nbased on the channel, interference, and traffic characteristics. We formulate\nan optimization problem to maximize a weighted sum rate of UEs, where weights\ncan represent priority, waiting time, and queue length. This optimization\naccommodates constraints related to channel and interference characteristics\nthat influence the rates at which links can successfully carry assigned\ntraffic. While an exhaustive search can establish an upper bound on achievable\nrates by this non-convex optimization problem, it becomes impractical for\nlarger number of outer UEs due to scalability issues related to high\ncomputational complexity. To address this, we present a greedy algorithm that\nincrementally selects links to maximize the sum rate, considering already\nactivated links. This algorithm, although effective in achieving high sum\nrates, may inadvertently overlook some UEs, raising concerns about fairness. To\nmitigate this, we introduce a fairness-oriented algorithm that adjusts weights\nbased on waiting time or queue length, ensuring that UEs with initially\nfavorable conditions do not unduly disadvantage others over time. We show that\nthis strategy not only improves the average admission ratio of UEs but also\nensures a more equitable distribution of service among them, thereby providing\na balanced and fair solution to sidelink communications.", "published": "2025-06-03 19:19:04", "link": "http://arxiv.org/abs/2506.03328v1", "categories": ["cs.NI", "cs.DC", "cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.NI"}
{"title": "Demystifying Tubal Tensor Algebra", "abstract": "Developed in a series of seminal papers in the early 2010s, the tubal tensor\nframework provides a clean and effective algebraic setting for tensor\ncomputations, supporting matrix-mimetic features such as a tensor Singular\nValue Decomposition and Eckart-Young-like optimality results. It has proven to\nbe a powerful tool for analyzing inherently multilinear data arising in\nhyperspectral imaging, medical imaging, neural dynamics, scientific\nsimulations, and more. At the heart of tubal tensor algebra lies a special\ntensor-tensor product: originally the t-product, later generalized into a full\nfamily of products via the $\\star_M$-product. Though initially defined through\nthe multiplication of a block-circulant unfolding of one tensor by a\nmatricization of another, it was soon observed that the t-product can be\ninterpreted as standard matrix multiplication where the scalars are tubes-i.e.,\nreal vectors twisted ``inward.'' Yet, a fundamental question remains: why is\nthis the ``right'' way to define a tensor-tensor product in the tubal setting?\nIn this paper, we show that the t-product and its $\\star_M$ generalization\narise naturally when viewing third-order tensors as matrices of tubes, together\nwith a small set of desired algebraic properties. Furthermore, we prove that\nthe $\\star_M$-product is, in fact, the only way to define a tubal product\nsatisfying these properties. Thus, while partly expository in nature - aimed at\npresenting the foundations of tubal tensor algebra in a cohesive and accessible\nway - this paper also addresses theoretical gaps in the tubal tensor framework,\nproves new results, and provides justification for the tubal tensor framework\ncentral constructions, thereby shedding new light on it.", "published": "2025-06-03 18:51:29", "link": "http://arxiv.org/abs/2506.03311v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "An Active Flux method for the Euler equations based on the exact acoustic evolution operator", "abstract": "A new Active Flux method for the multi-dimensional Euler equations is based\non an additive operator splitting into acoustics and advection. The acoustic\noperator is solved in a locally linearized manner by using the exact evolution\noperator. The nonlinear advection operator is solved at third order accuracy\nusing a new approximate evolution operator. To simplify the splitting, the new\nmethod uses primitive variables for the point values and for the\nreconstruction. In order to handle discontinuous solutions, a blended bound\npreserving limiting is used, that combines a priori and a posteriori\napproaches. The resulting method is able to resolve multi-dimensional Riemann\nproblems as well as low Mach number flow, and has a large domain of stability.", "published": "2025-06-03 18:30:26", "link": "http://arxiv.org/abs/2506.03291v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Guided modes of helical waveguides", "abstract": "This paper studies guided transverse scalar modes propagating through\nhelically coiled waveguides. Modeling the modes as solutions of the Helmholtz\nequation within the three-dimensional (3D) waveguide geometry, a propagation\nansatz transforms the mode-finding problem into a 3D quadratic eigenproblem.\nThrough an untwisting map, the problem is shown to be equivalent to a 3D\nquadratic eigenproblem on a straightened configuration. Next, exploiting the\nconstant torsion and curvature of the Frenet frame of a circular helix, the 3D\neigenproblem is further reduced to a two-dimensional (2D) eigenproblem on the\nwaveguide cross section. All three eigenproblems are numerically treated. As\nexpected, significant computational savings are realized in the 2D model. A few\nnontrivial numerical techniques are needed to make the computation of modes\nwithin the 3D geometry feasible. They are presented along with a procedure to\neffectively filter out unwanted non-propagating eigenfunctions. Computational\nresults show that the geometric effect of coiling is to shift the localization\nof guided modes away from the coiling center. The variations in modes as\ncoiling pitch is changed are reported considering the example of a coiled\noptical fiber.", "published": "2025-06-03 18:03:47", "link": "http://arxiv.org/abs/2506.03276v1", "categories": ["physics.optics", "cs.NA", "math.NA", "78M10 (Primary) 65F15 (Secondary)"], "primary_category": "physics.optics"}
{"title": "Reproducing kernel Hilbert space methods for modelling the discount curve", "abstract": "We consider the theory of bond discounts, defined as the difference between\nthe terminal payoff of the contract and its current price. Working in the\nsetting of finite-dimensional realizations in the HJM framework, under suitable\nnotions of no-arbitrage, the admissible discount curves take the form of\npolynomial, exponential functions. We introduce reproducing kernels that are\nadmissible under no-arbitrage as a tractable regression basis for the\nestimation problem in calibrating the model to market data. We provide a\nthorough numerical analysis using real-world treasury data.", "published": "2025-06-03 19:32:26", "link": "http://arxiv.org/abs/2506.03342v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "Probabilistic Factorial Experimental Design for Combinatorial Interventions", "abstract": "A combinatorial intervention, consisting of multiple treatments applied to a\nsingle unit with potentially interactive effects, has substantial applications\nin fields such as biomedicine, engineering, and beyond. Given $p$ possible\ntreatments, conducting all possible $2^p$ combinatorial interventions can be\nlaborious and quickly becomes infeasible as $p$ increases. Here we introduce\nprobabilistic factorial experimental design, formalized from how scientists\nperform lab experiments. In this framework, the experimenter selects a dosage\nfor each possible treatment and applies it to a group of units. Each unit\nindependently receives a random combination of treatments, sampled from a\nproduct Bernoulli distribution determined by the dosages. Additionally, the\nexperimenter can carry out such experiments over multiple rounds, adapting the\ndesign in an active manner. We address the optimal experimental design problem\nwithin an intervention model that imposes bounded-degree interactions between\ntreatments. In the passive setting, we provide a closed-form solution for the\nnear-optimal design. Our results prove that a dosage of $\\tfrac{1}{2}$ for each\ntreatment is optimal up to a factor of $1+O(\\tfrac{\\ln(n)}{n})$ for estimating\nany $k$-way interaction model, regardless of $k$, and imply that\n$O\\big(kp^{3k}\\ln(p)\\big)$ observations are required to accurately estimate\nthis model. For the multi-round setting, we provide a near-optimal acquisition\nfunction that can be numerically optimized. We also explore several extensions\nof the design problem and finally validate our findings through simulations.", "published": "2025-06-03 20:15:08", "link": "http://arxiv.org/abs/2506.03363v1", "categories": ["cs.LG", "stat.ME", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Multi-Exit Kolmogorov-Arnold Networks: enhancing accuracy and parsimony", "abstract": "Kolmogorov-Arnold Networks (KANs) uniquely combine high accuracy with\ninterpretability, making them valuable for scientific modeling. However, it is\nunclear a priori how deep a network needs to be for any given task, and deeper\nKANs can be difficult to optimize. Here we introduce multi-exit KANs, where\neach layer includes its own prediction branch, enabling the network to make\naccurate predictions at multiple depths simultaneously. This architecture\nprovides deep supervision that improves training while discovering the right\nlevel of model complexity for each task. Multi-exit KANs consistently\noutperform standard, single-exit versions on synthetic functions, dynamical\nsystems, and real-world datasets. Remarkably, the best predictions often come\nfrom earlier, simpler exits, revealing that these networks naturally identify\nsmaller, more parsimonious and interpretable models without sacrificing\naccuracy. To automate this discovery, we develop a differentiable \"learning to\nexit\" algorithm that balances contributions from exits during training. Our\napproach offers scientists a practical way to achieve both high performance and\ninterpretability, addressing a fundamental challenge in machine learning for\nscientific discovery.", "published": "2025-06-03 18:41:30", "link": "http://arxiv.org/abs/2506.03302v1", "categories": ["cs.LG", "cs.NE", "physics.data-an", "stat.ML"], "primary_category": "cs.LG"}
{"title": "HYFuse: Aligning Heterogeneous Speech Pre-Trained Representations in Hyperbolic Space for Speech Emotion Recognition", "abstract": "Compression-based representations (CBRs) from neural audio codecs such as\nEnCodec capture intricate acoustic features like pitch and timbre, while\nrepresentation-learning-based representations (RLRs) from pre-trained models\ntrained for speech representation learning such as WavLM encode high-level\nsemantic and prosodic information. Previous research on Speech Emotion\nRecognition (SER) has explored both, however, fusion of CBRs and RLRs haven't\nbeen explored yet. In this study, we solve this gap and investigate the fusion\nof RLRs and CBRs and hypothesize they will be more effective by providing\ncomplementary information. To this end, we propose, HYFuse, a novel framework\nthat fuses the representations by transforming them to hyperbolic space. With\nHYFuse, through fusion of x-vector (RLR) and Soundstream (CBR), we achieve the\ntop performance in comparison to individual representations as well as the\nhomogeneous fusion of RLRs and CBRs and report SOTA.", "published": "2025-06-03 21:26:24", "link": "http://arxiv.org/abs/2506.03403v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "SNIFR : Boosting Fine-Grained Child Harmful Content Detection Through Audio-Visual Alignment with Cascaded Cross-Transformer", "abstract": "As video-sharing platforms have grown over the past decade, child viewership\nhas surged, increasing the need for precise detection of harmful content like\nviolence or explicit scenes. Malicious users exploit moderation systems by\nembedding unsafe content in minimal frames to evade detection. While prior\nresearch has focused on visual cues and advanced such fine-grained detection,\naudio features remain underexplored. In this study, we embed audio cues with\nvisual for fine-grained child harmful content detection and introduce SNIFR, a\nnovel framework for effective alignment. SNIFR employs a transformer encoder\nfor intra-modality interaction, followed by a cascaded cross-transformer for\ninter-modality alignment. Our approach achieves superior performance over\nunimodal and baseline fusion methods, setting a new state-of-the-art.", "published": "2025-06-03 20:37:23", "link": "http://arxiv.org/abs/2506.03378v1", "categories": ["eess.AS", "cs.CV", "cs.MM"], "primary_category": "eess.AS"}
{"title": "Towards Source Attribution of Singing Voice Deepfake with Multimodal Foundation Models", "abstract": "In this work, we introduce the task of singing voice deepfake source\nattribution (SVDSA). We hypothesize that multimodal foundation models (MMFMs)\nsuch as ImageBind, LanguageBind will be most effective for SVDSA as they are\nbetter equipped for capturing subtle source-specific characteristics-such as\nunique timbre, pitch manipulation, or synthesis artifacts of each singing voice\ndeepfake source due to their cross-modality pre-training. Our experiments with\nMMFMs, speech foundation models and music foundation models verify the\nhypothesis that MMFMs are the most effective for SVDSA. Furthermore, inspired\nfrom related research, we also explore fusion of foundation models (FMs) for\nimproved SVDSA. To this end, we propose a novel framework, COFFE which employs\nChernoff Distance as novel loss function for effective fusion of FMs. Through\nCOFFE with the symphony of MMFMs, we attain the topmost performance in\ncomparison to all the individual FMs and baseline fusion methods.", "published": "2025-06-03 20:16:41", "link": "http://arxiv.org/abs/2506.03364v1", "categories": ["eess.AS", "cs.MM", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Minimally Invasive Brain Computer Interfaces: Evaluating the Impact of Tissue Layers on Signal Quality of Sub-Scalp EEG", "abstract": "Individuals with severe physical disabilities often experience diminished\nquality of life stemming from limited ability to engage with their\nsurroundings. Brain-Computer Interface (BCI) technology aims to bridge this gap\nby enabling direct technology interaction. However, current BCI systems require\ninvasive procedures, such as craniotomy or implantation of electrodes through\nblood vessels, posing significant risks to patients. Sub-scalp\nelectroencephalography (EEG) offers a lower risk alternative. This study\ninvestigates the signal quality of sub-scalp EEG recordings from various depths\nin a sheep model, and compares results with other methods: ECoG and\nendovascular arrays. A computational model was also constructed to investigate\nthe factors underlying variations in electrode performance. We demonstrate that\npeg electrodes placed within the sub-scalp space can achieve visual evoked\npotential signal-to-noise ratios (SNRs) approaching that of ECoG. Endovascular\narrays exhibited SNR comparable to electrodes positioned on the periosteum.\nFurthermore, sub-scalp recordings captured high gamma neural activity, with\nmaximum bandwidth ranging from 120 Hz to 180 Hz depending on electrode depth.\nThese findings support the use of sub-scalp EEG for BCI applications, and\nprovide valuable insights for future sub-scalp electrode design. This data lays\nthe groundwork for human trials, ultimately paving the way for chronic, in-home\nBCIs that empower individuals with physical disabilities.", "published": "2025-06-03 23:30:21", "link": "http://arxiv.org/abs/2506.03452v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Maximum Likelihood for Logistic Regression Model with Incomplete and Hybrid-Type Covariates", "abstract": "Logistic regression is a fundamental and widely used statistical method for\nmodeling binary outcomes based on covariates. However, the presence of missing\ndata, particularly in settings involving hybrid covariates (a mix of discrete\nand continuous variables), poses significant challenges. In this paper, we\npropose a novel Expectation-Maximization based algorithm tailored for parameter\nestimation in logistic regression models with missing hybrid covariates. The\nproposed method is specifically designed to handle these complexities,\ndelivering efficient parameter estimates. Through comprehensive simulations and\nreal-world application, we demonstrate that our approach consistently\noutperforms traditional methods, achieving superior accuracy and reliability.", "published": "2025-06-03 23:11:31", "link": "http://arxiv.org/abs/2506.03445v1", "categories": ["stat.ME", "eess.SP", "62F10, 62J12, 62H30"], "primary_category": "stat.ME"}
{"title": "StARS DCM: A Sleep Stage-Decoding Forehead EEG Patch for Real-time Modulation of Sleep Physiology", "abstract": "The System to Augment Restorative Sleep (StARS) is a modular\nhardware/software platform designed for real-time sleep monitoring and\nintervention. Utilizing the compact DCM biosignal device, StARS captures\nelectrophysiological signals (EEG, EMG, EOG) and synchronizes sensor data using\nthe ezmsg real-time software framework. StARS supports interventions such as\nclosed-loop auditory stimulation and dynamic thermal modulation guided by\nsleep-stage decoding via advanced neural network models and transfer learning.\nConfigurable with a lightweight EEG forehead patch or wearable sensors like\nsmart rings, StARS offers flexible, low-burden solutions for EEG, BCI, and\nsleep-enhancement research and applications. The open-source DCM patch further\nenables customizable EEG device development.", "published": "2025-06-03 22:54:12", "link": "http://arxiv.org/abs/2506.03442v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Interference-Aware Multiuser Hybrid Precoding for Coexistence with LEO Satellite Communication", "abstract": "Interference from terrestrial networks can reduce the communication rate for\nlow Earth orbit (LEO) satellites in the upper mid-band. To coexist in\nfrequency, MIMO precoding can be used to reduce the signal that impinges on the\nLEO satellite. We present a beamforming algorithm designed for the hybrid\narchitecture that incorporates a satellite interference penalty while\noptimizing the analog and digital precoders. Our algorithm optimizes the\nprecoding at the base station (BS) within the set of precoders that null the\ninterference to the satellite. Simulations demonstrate that our algorithm\nreduces the interference at the satellites and lowers the probability of\nviolating prescribed LEO satellite protection thresholds, outperforming prior\nhybrid nulling algorithms. Results indicate that the algorithm maintains\nsum-rate within 3\\% of the existing hybrid solutions, while effectively\nimproving interference to noise power by 22.4 dB.", "published": "2025-06-03 22:42:38", "link": "http://arxiv.org/abs/2506.03438v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Sub-Scalp EEG for Sensorimotor Brain-Computer Interface", "abstract": "Objective: To establish sub-scalp electroencephalography (EEG) as a viable\noption for brain-computer interface (BCI) applications, particularly for\nchronic use, by demonstrating its effectiveness in recording and classifying\nsensorimotor neural activity. Approach: Two experiments were conducted in this\nstudy. The first aim was to demonstrate the high spatial resolution of\nsub-scalp EEG through analysis of somatosensory evoked potentials in sheep\nmodels. The second focused on the practical application of sub-scalp EEG,\nclassifying motor execution using data collected during a sheep behavioural\nexperiment. Main Results: We successfully demonstrated the recording of\nsensorimotor rhythms using sub-scalp EEG in sheep models. Important spatial,\ntemporal, and spectral features of these signals were identified, and we were\nable to classify motor execution with above-chance performance. These results\nare comparable to previous work that investigated signal quality and motor\nexecution classification using ECoG and endovascular arrays in sheep models.\nSignificance: These results suggest that sub-scalp EEG may provide signal\nquality that approaches that of more invasive neural recording methods such as\nECoG and endovascular arrays, and support the use of sub-scalp EEG for chronic\nBCI applications.", "published": "2025-06-03 22:03:58", "link": "http://arxiv.org/abs/2506.03423v1", "categories": ["eess.SP", "q-bio.NC"], "primary_category": "eess.SP"}
{"title": "Retrieval-Augmented Generation as Noisy In-Context Learning: A Unified Theory and Risk Bounds", "abstract": "Retrieval-augmented generation (RAG) has seen many empirical successes in\nrecent years by aiding the LLM with external knowledge. However, its\ntheoretical aspect has remained mostly unexplored. In this paper, we propose\nthe first finite-sample generalization bound for RAG in in-context linear\nregression and derive an exact bias-variance tradeoff. Our framework views the\nretrieved texts as query-dependent noisy in-context examples and recovers the\nclassical in-context learning (ICL) and standard RAG as the limit cases. Our\nanalysis suggests that an intrinsic ceiling on generalization error exists on\nRAG as opposed to the ICL. Furthermore, our framework is able to model\nretrieval both from the training data and from external corpora by introducing\nuniform and non-uniform RAG noise. In line with our theory, we show the sample\nefficiency of ICL and RAG empirically with experiments on common QA benchmarks,\nsuch as Natural Questions and TriviaQA.", "published": "2025-06-03 17:31:53", "link": "http://arxiv.org/abs/2506.03100v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR", "math.ST", "stat.TH"], "primary_category": "cs.LG"}
{"title": "CPU-Based Layout Design for Picker-to-Parts Pallet Warehouses", "abstract": "Picker-to-parts pallet warehouses often face inefficiencies due to\nconventional layouts causing excessive travel distances and high labor\nrequirements. This study introduces a novel layout design inspired by CPU\narchitecture, partitioning warehouse space into specialized zones, namely\nPerformance (P), Efficiency (E), and Shared (S). Discrete-event simulation is\nused to evaluate this design against traditional rectangular (random and ABC\nstorage) and Flying-V layouts. Results demonstrate significant improvements in\nthroughput time and reduced labor requirements, highlighting the potential for\nCPU-based layouts in optimizing warehouse operations.", "published": "2025-06-03 11:33:58", "link": "http://arxiv.org/abs/2506.04266v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "CORA: Coalitional Rational Advantage Decomposition for Multi-Agent Policy Gradients", "abstract": "This work focuses on the credit assignment problem in cooperative multi-agent\nreinforcement learning (MARL). Sharing the global advantage among agents often\nleads to suboptimal policy updates as it fails to account for the distinct\ncontributions of agents. Although numerous methods consider global or\nindividual contributions for credit assignment, a detailed analysis at the\ncoalition level remains lacking in many approaches. This work analyzes the\nover-updating problem during multi-agent policy updates from a coalition-level\nperspective. To address this issue, we propose a credit assignment method\ncalled Coalitional Rational Advantage Decomposition (CORA). CORA evaluates\ncoalitional advantages via marginal contributions from all possible coalitions\nand decomposes advantages using the core solution from cooperative game theory,\nensuring coalitional rationality. To reduce computational overhead, CORA\nemploys random coalition sampling. Experiments on matrix games, differential\ngames, and multi-agent collaboration benchmarks demonstrate that CORA\noutperforms strong baselines, particularly in tasks with multiple local optima.\nThese findings highlight the importance of coalition-aware credit assignment\nfor improving MARL performance.", "published": "2025-06-03 08:04:43", "link": "http://arxiv.org/abs/2506.04265v1", "categories": ["cs.MA", "cs.AI", "cs.GT", "cs.LG"], "primary_category": "cs.MA"}
{"title": "TriPSS: A Tri-Modal Keyframe Extraction Framework Using Perceptual, Structural, and Semantic Representations", "abstract": "Efficient keyframe extraction is critical for effective video summarization\nand retrieval, yet capturing the complete richness of video content remains\nchallenging. In this work, we present TriPSS, a novel tri-modal framework that\neffectively integrates perceptual cues from color features in the CIELAB space,\ndeep structural embeddings derived from ResNet-50, and semantic context from\nframe-level captions generated by Llama-3.2-11B-Vision-Instruct. By fusing\nthese diverse modalities using principal component analysis, TriPSS constructs\nrobust multi-modal embeddings that enable adaptive segmentation of video\ncontent via HDBSCAN clustering. A subsequent refinement stage incorporating\nquality assessment and duplicate filtering ensures that the final keyframe set\nis both concise and semantically rich. Comprehensive evaluations on benchmark\ndatasets TVSum20 and SumMe demonstrate that TriPSS achieves state-of-the-art\nperformance, substantially outperforming traditional unimodal and previous\nmulti-modal methods. These results underscore TriPSS's ability to capture\nnuanced visual and semantic information, thereby setting a new benchmark for\nvideo content understanding in large-scale retrieval scenarios.", "published": "2025-06-03 19:44:49", "link": "http://arxiv.org/abs/2506.05395v1", "categories": ["cs.CV", "cs.IR", "cs.MM", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Heterogeneous Secure Transmissions in IRS-Assisted NOMA Communications: CO-GNN Approach", "abstract": "Intelligent Reflecting Surfaces (IRS) enhance spectral efficiency by\nadjusting reflection phase shifts, while Non-Orthogonal Multiple Access (NOMA)\nincreases system capacity. Consequently, IRS-assisted NOMA communications have\ngarnered significant research interest. However, the passive nature of the IRS,\nlacking authentication and security protocols, makes these systems vulnerable\nto external eavesdropping due to the openness of electromagnetic signal\npropagation and reflection. NOMA's inherent multi-user signal superposition\nalso introduces internal eavesdropping risks during user pairing. This paper\ninvestigates secure transmissions in IRS-assisted NOMA systems with\nheterogeneous resource configuration in wireless networks to mitigate both\nexternal and internal eavesdropping. To maximize the sum secrecy rate of\nlegitimate users, we propose a combinatorial optimization graph neural network\n(CO-GNN) approach to jointly optimize beamforming at the base station, power\nallocation of NOMA users, and phase shifts of IRS for dynamic heterogeneous\nresource allocation, thereby enabling the design of dual-link or multi-link\nsecure transmissions in the presence of eavesdroppers on the same or\nheterogeneous links. The CO-GNN algorithm simplifies the complex mathematical\nproblem-solving process, eliminates the need for channel estimation, and\nenhances scalability. Simulation results demonstrate that the proposed\nalgorithm significantly enhances the secure transmission performance of the\nsystem.", "published": "2025-06-03 04:01:50", "link": "http://arxiv.org/abs/2506.05381v1", "categories": ["cs.CR", "cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.CR"}
{"title": "GPU-Parallelizable Randomized Sketch-and-Precondition for Linear Regression using Sparse Sign Sketches", "abstract": "A litany of theoretical and numerical results have established the\nsketch-and-precondition paradigm as a powerful approach to solving large linear\nregression problems in standard computing environments. Perhaps surprisingly,\nmuch less work has been done on understanding how sketch-and-precondition\nperforms on graphics processing unit (GPU) systems. We address this gap by\nbenchmarking an implementation of sketch-and-precondition based on sparse\nsign-sketches on single and multi-GPU systems. In doing so, we describe a\nnovel, easily parallelized, rejection-sampling based method for generating\nsparse sign sketches. Our approach, which is particularly well-suited for GPUs,\nis easily adapted to a variety of computing environments. Taken as a whole, our\nnumerical experiments indicate that sketch-and-precondition with sparse sign\nsketches is particularly well-suited for GPUs, and may be suitable for use in\nblack-box least-squares solvers.", "published": "2025-06-03 16:48:06", "link": "http://arxiv.org/abs/2506.03070v2", "categories": ["cs.DS", "cs.DC", "cs.NA", "math.NA"], "primary_category": "cs.DS"}
{"title": "StARS DCM: A Sleep Stage-Decoding Forehead EEG Patch for Real-time Modulation of Sleep Physiology", "abstract": "The System to Augment Restorative Sleep (StARS) is a modular\nhardware/software platform designed for real-time sleep monitoring and\nintervention. Utilizing the compact DCM biosignal device, StARS captures\nelectrophysiological signals (EEG, EMG, EOG) and synchronizes sensor data using\nthe ezmsg real-time software framework. StARS supports interventions such as\nclosed-loop auditory stimulation and dynamic thermal modulation guided by\nsleep-stage decoding via advanced neural network models and transfer learning.\nConfigurable with a lightweight EEG forehead patch or wearable sensors like\nsmart rings, StARS offers flexible, low-burden solutions for EEG, BCI, and\nsleep-enhancement research and applications. The open-source DCM patch further\nenables customizable EEG device development.", "published": "2025-06-03 22:54:12", "link": "http://arxiv.org/abs/2506.03442v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Quake: Adaptive Indexing for Vector Search", "abstract": "Vector search, the task of finding the k-nearest neighbors of a query vector\nagainst a database of high-dimensional vectors, underpins many machine learning\napplications, including retrieval-augmented generation, recommendation systems,\nand information retrieval. However, existing approximate nearest neighbor (ANN)\nmethods perform poorly under dynamic and skewed workloads where data\ndistributions evolve. We introduce Quake, an adaptive indexing system that\nmaintains low latency and high recall in such environments. Quake employs a\nmulti-level partitioning scheme that adjusts to updates and changing access\npatterns, guided by a cost model that predicts query latency based on partition\nsizes and access frequencies. Quake also dynamically sets query execution\nparameters to meet recall targets using a novel recall estimation model.\nFurthermore, Quake utilizes NUMA-aware intra-query parallelism for improved\nmemory bandwidth utilization during search. To evaluate Quake, we prepare a\nWikipedia vector search workload and develop a workload generator to create\nvector search workloads with configurable access patterns. Our evaluation shows\nthat on dynamic workloads, Quake achieves query latency reductions of 1.5-38x\nand update latency reductions of 4.5-126x compared to state-of-the-art indexes\nsuch as SVS, DiskANN, HNSW, and SCANN.", "published": "2025-06-03 22:37:37", "link": "http://arxiv.org/abs/2506.03437v2", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Retrieval-Augmented Generation as Noisy In-Context Learning: A Unified Theory and Risk Bounds", "abstract": "Retrieval-augmented generation (RAG) has seen many empirical successes in\nrecent years by aiding the LLM with external knowledge. However, its\ntheoretical aspect has remained mostly unexplored. In this paper, we propose\nthe first finite-sample generalization bound for RAG in in-context linear\nregression and derive an exact bias-variance tradeoff. Our framework views the\nretrieved texts as query-dependent noisy in-context examples and recovers the\nclassical in-context learning (ICL) and standard RAG as the limit cases. Our\nanalysis suggests that an intrinsic ceiling on generalization error exists on\nRAG as opposed to the ICL. Furthermore, our framework is able to model\nretrieval both from the training data and from external corpora by introducing\nuniform and non-uniform RAG noise. In line with our theory, we show the sample\nefficiency of ICL and RAG empirically with experiments on common QA benchmarks,\nsuch as Natural Questions and TriviaQA.", "published": "2025-06-03 17:31:53", "link": "http://arxiv.org/abs/2506.03100v3", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR", "math.ST", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Transferable Sequential Recommendation with Vanilla Cross-Entropy Loss", "abstract": "Sequential Recommendation (SR) systems model user preferences by analyzing\ninteraction histories. Although transferable multi-modal SR architectures\ndemonstrate superior performance compared to traditional ID-based approaches,\ncurrent methods incur substantial fine-tuning costs when adapting to new\ndomains due to complex optimization requirements and negative transfer effects\n- a significant deployment bottleneck that hinders engineers from efficiently\nrepurposing pre-trained models for novel application scenarios with minimal\ntuning overhead. We propose MMM4Rec (Multi-Modal Mamba for Sequential\nRecommendation), a novel multi-modal SR framework that incorporates a dedicated\nalgebraic constraint mechanism for efficient transfer learning. By combining\nState Space Duality (SSD)'s temporal decay properties with a time-aware\nmodeling design, our model dynamically prioritizes key modality information,\novercoming limitations of Transformer-based approaches. The framework\nimplements a constrained two-stage process: (1) sequence-level cross-modal\nalignment via shared projection matrices, followed by (2) temporal fusion using\nour newly designed Cross-SSD module and dual-channel Fourier adaptive\nfiltering. This architecture maintains semantic consistency while suppressing\nnoise propagation.MMM4Rec achieves rapid fine-tuning convergence with simple\ncross-entropy loss, significantly improving multi-modal recommendation accuracy\nwhile maintaining strong transferability. Extensive experiments demonstrate\nMMM4Rec's state-of-the-art performance, achieving the maximum 31.78% NDCG@10\nimprovement over existing models and exhibiting 10 times faster average\nconvergence speed when transferring to large-scale downstream datasets.", "published": "2025-06-03 14:18:19", "link": "http://arxiv.org/abs/2506.02916v3", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Cascaded Multiwire-PLC/Multiple-VLC System: Characterization and Performance", "abstract": "This paper proposes a cascaded multiwire-power line communication\n(PLC)/multiple-visible light communication (VLC) system. This hybrid\narchitecture offers low installation cost, enhanced performance, practical\nfeasibility, and a wide range of applications. Novel analytical expressions are\nderived for key statistics and outage probability, bit error probability, and\nergodic channel capacity metrics. Furthermore, the analytical results are\nvalidated through Monte Carlo simulations, with several performance curves\npresented under various channel and PLC/VLC system parameters. All expressions\nderived in this work are original and have not been previously published. Our\nproposed system proves feasible for smart environments, green communication\nsystems, internet of things networks, industrial environments, and\nnext-generation networks.", "published": "2025-06-03 04:45:19", "link": "http://arxiv.org/abs/2506.06357v1", "categories": ["eess.SP", "cs.IT", "math.IT", "math.ST", "stat.TH"], "primary_category": "eess.SP"}
{"title": "TL;DR: Too Long, Do Re-weighting for Efficient LLM Reasoning Compression", "abstract": "Large Language Models (LLMs) have recently achieved remarkable progress by\nleveraging Reinforcement Learning and extended Chain-of-Thought (CoT)\ntechniques. However, the challenge of performing efficient language\nreasoning--especially during inference with extremely long outputs--has drawn\nincreasing attention from the research community. In this work, we propose a\ndynamic ratio-based training pipeline that does not rely on sophisticated data\nannotations or interpolation between multiple models. We continuously balance\nthe weights between the model's System-1 and System-2 data to eliminate\nredundant reasoning processes while preserving the model's reasoning\ncapability. We validate our approach across models on DeepSeek-R1-Distill-7B\nand DeepSeek-R1-Distill-14B and on a diverse set of benchmarks with varying\ndifficulty levels. Our method significantly reduces the number of output tokens\nby nearly 40% while maintaining the accuracy of the reasoning. Our code and\ndata will be available soon.", "published": "2025-06-03 09:23:41", "link": "http://arxiv.org/abs/2506.02678v2", "categories": ["cs.CL", "cs.CE", "cs.NA", "math.NA"], "primary_category": "cs.CL"}
{"title": "CORA: Coalitional Rational Advantage Decomposition for Multi-Agent Policy Gradients", "abstract": "This work focuses on the credit assignment problem in cooperative multi-agent\nreinforcement learning (MARL). Sharing the global advantage among agents often\nleads to suboptimal policy updates as it fails to account for the distinct\ncontributions of agents. Although numerous methods consider global or\nindividual contributions for credit assignment, a detailed analysis at the\ncoalition level remains lacking in many approaches. This work analyzes the\nover-updating problem during multi-agent policy updates from a coalition-level\nperspective. To address this issue, we propose a credit assignment method\ncalled Coalitional Rational Advantage Decomposition (CORA). CORA evaluates\ncoalitional advantages via marginal contributions from all possible coalitions\nand decomposes advantages using the core solution from cooperative game theory,\nensuring coalitional rationality. To reduce computational overhead, CORA\nemploys random coalition sampling. Experiments on matrix games, differential\ngames, and multi-agent collaboration benchmarks demonstrate that CORA\noutperforms strong baselines, particularly in tasks with multiple local optima.\nThese findings highlight the importance of coalition-aware credit assignment\nfor improving MARL performance.", "published": "2025-06-03 08:04:43", "link": "http://arxiv.org/abs/2506.04265v2", "categories": ["cs.MA", "cs.AI", "cs.GT", "cs.LG"], "primary_category": "cs.MA"}
