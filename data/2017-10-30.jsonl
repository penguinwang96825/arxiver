{"title": "Machine Translation of Low-Resource Spoken Dialects: Strategies for\n  Normalizing Swiss German", "abstract": "The goal of this work is to design a machine translation (MT) system for a\nlow-resource family of dialects, collectively known as Swiss German, which are\nwidely spoken in Switzerland but seldom written. We collected a significant\nnumber of parallel written resources to start with, up to a total of about 60k\nwords. Moreover, we identified several other promising data sources for Swiss\nGerman. Then, we designed and compared three strategies for normalizing Swiss\nGerman input in order to address the regional diversity. We found that\ncharacter-based neural MT was the best solution for text normalization. In\ncombination with phrase-based statistical MT, our solution reached 36% BLEU\nscore when translating from the Bernese dialect. This value, however, decreases\nas the testing data becomes more remote from the training one, geographically\nand topically. These resources and normalization techniques are a first step\ntowards full MT of Swiss German dialects.", "published": "2017-10-30 16:04:04", "link": "http://arxiv.org/abs/1710.11035v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Creation of an Annotated Corpus of Spanish Radiology Reports", "abstract": "This paper presents a new annotated corpus of 513 anonymized radiology\nreports written in Spanish. Reports were manually annotated with entities,\nnegation and uncertainty terms and relations. The corpus was conceived as an\nevaluation resource for named entity recognition and relation extraction\nalgorithms, and as input for the use of supervised methods. Biomedical\nannotated resources are scarce due to confidentiality issues and associated\ncosts. This work provides some guidelines that could help other researchers to\nundertake similar tasks.", "published": "2017-10-30 18:05:57", "link": "http://arxiv.org/abs/1710.11154v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning neural trans-dimensional random field language models with\n  noise-contrastive estimation", "abstract": "Trans-dimensional random field language models (TRF LMs) where sentences are\nmodeled as a collection of random fields, have shown close performance with\nLSTM LMs in speech recognition and are computationally more efficient in\ninference. However, the training efficiency of neural TRF LMs is not\nsatisfactory, which limits the scalability of TRF LMs on large training corpus.\nIn this paper, several techniques on both model formulation and parameter\nestimation are proposed to improve the training efficiency and the performance\nof neural TRF LMs. First, TRFs are reformulated in the form of exponential\ntilting of a reference distribution. Second, noise-contrastive estimation (NCE)\nis introduced to jointly estimate the model parameters and normalization\nconstants. Third, we extend the neural TRF LMs by marrying the deep\nconvolutional neural network (CNN) and the bidirectional LSTM into the\npotential function to extract the deep hierarchical features and\nbidirectionally sequential features. Utilizing all the above techniques enables\nthe successful and efficient training of neural TRF LMs on a 40x larger\ntraining set with only 1/3 training time and further reduces the WER with\nrelative reduction of 4.7% on top of a strong LSTM LM baseline.", "published": "2017-10-30 01:55:10", "link": "http://arxiv.org/abs/1710.10739v1", "categories": ["cs.CL", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Understanding Hidden Memories of Recurrent Neural Networks", "abstract": "Recurrent neural networks (RNNs) have been successfully applied to various\nnatural language processing (NLP) tasks and achieved better results than\nconventional methods. However, the lack of understanding of the mechanisms\nbehind their effectiveness limits further improvements on their architectures.\nIn this paper, we present a visual analytics method for understanding and\ncomparing RNN models for NLP tasks. We propose a technique to explain the\nfunction of individual hidden state units based on their expected response to\ninput texts. We then co-cluster hidden state units and words based on the\nexpected response and visualize co-clustering results as memory chips and word\nclouds to provide more structured knowledge on RNNs' hidden states. We also\npropose a glyph-based sequence visualization based on aggregate information to\nanalyze the behavior of an RNN's hidden state at the sentence-level. The\nusability and effectiveness of our method are demonstrated through case studies\nand reviews from domain experts.", "published": "2017-10-30 05:37:25", "link": "http://arxiv.org/abs/1710.10777v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Conceptual Text Summarizer: A new model in continuous vector space", "abstract": "Traditional methods of summarization are not cost-effective and possible\ntoday. Extractive summarization is a process that helps to extract the most\nimportant sentences from a text automatically and generates a short informative\nsummary. In this work, we propose an unsupervised method to summarize Persian\ntexts. This method is a novel hybrid approach that clusters the concepts of the\ntext using deep learning and traditional statistical methods. First we produce\na word embedding based on Hamshahri2 corpus and a dictionary of word\nfrequencies. Then the proposed algorithm extracts the keywords of the document,\nclusters its concepts, and finally ranks the sentences to produce the summary.\nWe evaluated the proposed method on Pasokh single-document corpus using the\nROUGE evaluation measure. Without using any hand-crafted features, our proposed\nmethod achieves state-of-the-art results. We compared our unsupervised method\nwith the best supervised Persian methods and we achieved an overall improvement\nof ROUGE-2 recall score of 7.5%.", "published": "2017-10-30 14:55:25", "link": "http://arxiv.org/abs/1710.10994v3", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Named Entity Recognition in Twitter using Images and Text", "abstract": "Named Entity Recognition (NER) is an important subtask of information\nextraction that seeks to locate and recognise named entities. Despite recent\nachievements, we still face limitations with correctly detecting and\nclassifying entities, prominently in short and noisy text, such as Twitter. An\nimportant negative aspect in most of NER approaches is the high dependency on\nhand-crafted features and domain-specific knowledge, necessary to achieve\nstate-of-the-art results. Thus, devising models to deal with such\nlinguistically complex contexts is still challenging. In this paper, we propose\na novel multi-level architecture that does not rely on any specific linguistic\nresource or encoded rule. Unlike traditional approaches, we use features\nextracted from images and text to classify named entities. Experimental tests\nagainst state-of-the-art NER for Twitter on the Ritter dataset present\ncompetitive results (0.59 F-measure), indicating that this approach may lead\ntowards better NER models.", "published": "2017-10-30 15:56:03", "link": "http://arxiv.org/abs/1710.11027v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Indirect Supervision for Relation Extraction using Question-Answer Pairs", "abstract": "Automatic relation extraction (RE) for types of interest is of great\nimportance for interpreting massive text corpora in an efficient manner.\nTraditional RE models have heavily relied on human-annotated corpus for\ntraining, which can be costly in generating labeled data and become obstacles\nwhen dealing with more relation types. Thus, more RE extraction systems have\nshifted to be built upon training data automatically acquired by linking to\nknowledge bases (distant supervision). However, due to the incompleteness of\nknowledge bases and the context-agnostic labeling, the training data collected\nvia distant supervision (DS) can be very noisy. In recent years, as increasing\nattention has been brought to tackling question-answering (QA) tasks, user\nfeedback or datasets of such tasks become more accessible. In this paper, we\npropose a novel framework, ReQuest, to leverage question-answer pairs as an\nindirect source of supervision for relation extraction, and study how to use\nsuch supervision to reduce noise induced from DS. Our model jointly embeds\nrelation mentions, types, QA entity mention pairs and text features in two\nlow-dimensional spaces (RE and QA), where objects with same relation types or\nsemantically similar question-answer pairs have similar representations. Shared\nfeatures connect these two spaces, carrying clearer semantic knowledge from\nboth sources. ReQuest, then use these learned embeddings to estimate the types\nof test relation mentions. We formulate a global objective function and adopt a\nnovel margin-based QA loss to reduce noise in DS by exploiting semantic\nevidence from the QA dataset. Our experimental results achieve an average of\n11% improvement in F1 score on two public RE datasets combined with TREC QA\ndataset.", "published": "2017-10-30 18:27:19", "link": "http://arxiv.org/abs/1710.11169v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Sequence-to-Sequence ASR Optimization via Reinforcement Learning", "abstract": "Despite the success of sequence-to-sequence approaches in automatic speech\nrecognition (ASR) systems, the models still suffer from several problems,\nmainly due to the mismatch between the training and inference conditions. In\nthe sequence-to-sequence architecture, the model is trained to predict the\ngrapheme of the current time-step given the input of speech signal and the\nground-truth grapheme history of the previous time-steps. However, it remains\nunclear how well the model approximates real-world speech during inference.\nThus, generating the whole transcription from scratch based on previous\npredictions is complicated and errors can propagate over time. Furthermore, the\nmodel is optimized to maximize the likelihood of training data instead of error\nrate evaluation metrics that actually quantify recognition quality. This paper\npresents an alternative strategy for training sequence-to-sequence ASR models\nby adopting the idea of reinforcement learning (RL). Unlike the standard\ntraining scheme with maximum likelihood estimation, our proposed approach\nutilizes the policy gradient algorithm. We can (1) sample the whole\ntranscription based on the model's prediction in the training process and (2)\ndirectly optimize the model with negative Levenshtein distance as the reward.\nExperimental results demonstrate that we significantly improved the performance\ncompared to a model trained only with maximum likelihood estimation.", "published": "2017-10-30 05:09:36", "link": "http://arxiv.org/abs/1710.10774v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Unsupervised Neural Machine Translation", "abstract": "In spite of the recent success of neural machine translation (NMT) in\nstandard benchmarks, the lack of large parallel corpora poses a major practical\nproblem for many language pairs. There have been several proposals to alleviate\nthis issue with, for instance, triangulation and semi-supervised learning\ntechniques, but they still require a strong cross-lingual signal. In this work,\nwe completely remove the need of parallel data and propose a novel method to\ntrain an NMT system in a completely unsupervised manner, relying on nothing but\nmonolingual corpora. Our model builds upon the recent work on unsupervised\nembedding mappings, and consists of a slightly modified attentional\nencoder-decoder model that can be trained on monolingual corpora alone using a\ncombination of denoising and backtranslation. Despite the simplicity of the\napproach, our system obtains 15.56 and 10.21 BLEU points in WMT 2014\nFrench-to-English and German-to-English translation. The model can also profit\nfrom small parallel corpora, and attains 21.81 and 15.24 points when combined\nwith 100,000 parallel sentences, respectively. Our implementation is released\nas an open source project.", "published": "2017-10-30 16:17:34", "link": "http://arxiv.org/abs/1710.11041v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Content-based Representations of audio using Siamese neural networks", "abstract": "In this paper, we focus on the problem of content-based retrieval for audio,\nwhich aims to retrieve all semantically similar audio recordings for a given\naudio clip query. This problem is similar to the problem of query by example of\naudio, which aims to retrieve media samples from a database, which are similar\nto the user-provided example. We propose a novel approach which encodes the\naudio into a vector representation using Siamese Neural Networks. The goal is\nto obtain an encoding similar for files belonging to the same audio class, thus\nallowing retrieval of semantically similar audio. Using simple similarity\nmeasures such as those based on simple euclidean distance and cosine similarity\nwe show that these representations can be very effectively used for retrieving\nrecordings similar in audio content.", "published": "2017-10-30 14:32:02", "link": "http://arxiv.org/abs/1710.10974v3", "categories": ["cs.SD", "cs.IR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Onsets and Frames: Dual-Objective Piano Transcription", "abstract": "We advance the state of the art in polyphonic piano music transcription by\nusing a deep convolutional and recurrent neural network which is trained to\njointly predict onsets and frames. Our model predicts pitch onset events and\nthen uses those predictions to condition framewise pitch predictions. During\ninference, we restrict the predictions from the framewise detector by not\nallowing a new note to start unless the onset detector also agrees that an\nonset for that pitch is present in the frame. We focus on improving onsets and\noffsets together instead of either in isolation as we believe this correlates\nbetter with human musical perception. Our approach results in over a 100%\nrelative improvement in note F1 score (with offsets) on the MAPS dataset.\nFurthermore, we extend the model to predict relative velocities of normalized\naudio which results in more natural-sounding transcriptions.", "published": "2017-10-30 18:05:49", "link": "http://arxiv.org/abs/1710.11153v2", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
