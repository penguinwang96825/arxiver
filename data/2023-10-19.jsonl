{"title": "FinEntity: Entity-level Sentiment Classification for Financial Texts", "abstract": "In the financial domain, conducting entity-level sentiment analysis is\ncrucial for accurately assessing the sentiment directed toward a specific\nfinancial entity. To our knowledge, no publicly available dataset currently\nexists for this purpose. In this work, we introduce an entity-level sentiment\nclassification dataset, called \\textbf{FinEntity}, that annotates financial\nentity spans and their sentiment (positive, neutral, and negative) in financial\nnews. We document the dataset construction process in the paper. Additionally,\nwe benchmark several pre-trained models (BERT, FinBERT, etc.) and ChatGPT on\nentity-level sentiment classification. In a case study, we demonstrate the\npractical utility of using FinEntity in monitoring cryptocurrency markets. The\ndata and code of FinEntity is available at\n\\url{https://github.com/yixuantt/FinEntity}", "published": "2023-10-19 01:38:40", "link": "http://arxiv.org/abs/2310.12406v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Shifted and The Overlooked: A Task-oriented Investigation of\n  User-GPT Interactions", "abstract": "Recent progress in Large Language Models (LLMs) has produced models that\nexhibit remarkable performance across a variety of NLP tasks. However, it\nremains unclear whether the existing focus of NLP research accurately captures\nthe genuine requirements of human users. This paper provides a comprehensive\nanalysis of the divergence between current NLP research and the needs of\nreal-world NLP applications via a large-scale collection of user-GPT\nconversations. We analyze a large-scale collection of real user queries to GPT.\nWe compare these queries against existing NLP benchmark tasks and identify a\nsignificant gap between the tasks that users frequently request from LLMs and\nthe tasks that are commonly studied in academic research. For example, we find\nthat tasks such as ``design'' and ``planning'' are prevalent in user\ninteractions but are largely neglected or different from traditional NLP\nbenchmarks. We investigate these overlooked tasks, dissect the practical\nchallenges they pose, and provide insights toward a roadmap to make LLMs better\naligned with user needs.", "published": "2023-10-19 02:12:17", "link": "http://arxiv.org/abs/2310.12418v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Revisiting Sparse Retrieval for Few-shot Entity Linking", "abstract": "Entity linking aims to link ambiguous mentions to their corresponding\nentities in a knowledge base. One of the key challenges comes from insufficient\nlabeled data for specific domains. Although dense retrievers have achieved\nexcellent performance on several benchmarks, their performance decreases\nsignificantly when only a limited amount of in-domain labeled data is\navailable. In such few-shot setting, we revisit the sparse retrieval method,\nand propose an ELECTRA-based keyword extractor to denoise the mention context\nand construct a better query expression. For training the extractor, we propose\na distant supervision method to automatically generate training data based on\noverlapping tokens between mention contexts and entity descriptions.\nExperimental results on the ZESHEL dataset demonstrate that the proposed method\noutperforms state-of-the-art models by a significant margin across all test\ndomains, showing the effectiveness of keyword-enhanced sparse retrieval.", "published": "2023-10-19 03:51:10", "link": "http://arxiv.org/abs/2310.12444v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Read-and-Select Framework for Zero-shot Entity Linking", "abstract": "Zero-shot entity linking (EL) aims at aligning entity mentions to unseen\nentities to challenge the generalization ability. Previous methods largely\nfocus on the candidate retrieval stage and ignore the essential candidate\nranking stage, which disambiguates among entities and makes the final linking\nprediction. In this paper, we propose a read-and-select (ReS) framework by\nmodeling the main components of entity disambiguation, i.e., mention-entity\nmatching and cross-entity comparison. First, for each candidate, the reading\nmodule leverages mention context to output mention-aware entity\nrepresentations, enabling mention-entity matching. Then, in the selecting\nmodule, we frame the choice of candidates as a sequence labeling problem, and\nall candidate representations are fused together to enable cross-entity\ncomparison. Our method achieves the state-of-the-art performance on the\nestablished zero-shot EL dataset ZESHEL with a 2.55% micro-average accuracy\ngain, with no need for laborious multi-phase pre-training used in most of the\nprevious work, showing the effectiveness of both mention-entity and\ncross-entity interaction.", "published": "2023-10-19 04:08:10", "link": "http://arxiv.org/abs/2310.12450v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contrastive Learning for Inference in Dialogue", "abstract": "Inference, especially those derived from inductive processes, is a crucial\ncomponent in our conversation to complement the information implicitly or\nexplicitly conveyed by a speaker. While recent large language models show\nremarkable advances in inference tasks, their performance in inductive\nreasoning, where not all information is present in the context, is far behind\ndeductive reasoning. In this paper, we analyze the behavior of the models based\non the task difficulty defined by the semantic information gap -- which\ndistinguishes inductive and deductive reasoning (Johnson-Laird, 1988, 1993).\nOur analysis reveals that the disparity in information between dialogue\ncontexts and desired inferences poses a significant challenge to the inductive\ninference process. To mitigate this information gap, we investigate a\ncontrastive learning approach by feeding negative samples. Our experiments\nsuggest negative samples help models understand what is wrong and improve their\ninference generations.", "published": "2023-10-19 04:49:36", "link": "http://arxiv.org/abs/2310.12467v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MedAI Dialog Corpus (MEDIC): Zero-Shot Classification of Doctor and AI\n  Responses in Health Consultations", "abstract": "Zero-shot classification enables text to be classified into classes not seen\nduring training. In this study, we examine the efficacy of zero-shot learning\nmodels in classifying healthcare consultation responses from Doctors and AI\nsystems. The models evaluated include BART, BERT, XLM, XLM-R and DistilBERT.\nThe models were tested on three different datasets based on a binary and\nmulti-label analysis to identify the origins of text in health consultations\nwithout any prior corpus training. According to our findings, the zero-shot\nlanguage models show a good understanding of language generally, but has\nlimitations when trying to classify doctor and AI responses to healthcare\nconsultations. This research provides a foundation for future research in the\nfield of medical text classification by informing the development of more\naccurate methods of classifying text written by Doctors and AI systems in\nhealth consultations.", "published": "2023-10-19 05:48:28", "link": "http://arxiv.org/abs/2310.12489v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Co$^2$PT: Mitigating Bias in Pre-trained Language Models through\n  Counterfactual Contrastive Prompt Tuning", "abstract": "Pre-trained Language Models are widely used in many important real-world\napplications. However, recent studies show that these models can encode social\nbiases from large pre-training corpora and even amplify biases in downstream\napplications. To address this challenge, we propose Co$^2$PT, an efficient and\neffective debias-while-prompt tuning method for mitigating biases via\ncounterfactual contrastive prompt tuning on downstream tasks. Our experiments\nconducted on three extrinsic bias benchmarks demonstrate the effectiveness of\nCo$^2$PT on bias mitigation during the prompt tuning process and its\nadaptability to existing upstream debiased language models. These findings\nindicate the strength of Co$^2$PT and provide promising avenues for further\nenhancement in bias mitigation on downstream tasks.", "published": "2023-10-19 05:49:58", "link": "http://arxiv.org/abs/2310.12490v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ICU: Conquering Language Barriers in Vision-and-Language Modeling by\n  Dividing the Tasks into Image Captioning and Language Understanding", "abstract": "Most multilingual vision-and-language (V&L) research aims to accomplish\nmultilingual and multimodal capabilities within one model. However, the\nscarcity of multilingual captions for images has hindered the development. To\novercome this obstacle, we propose ICU, Image Caption Understanding, which\ndivides a V&L task into two stages: a V&L model performs image captioning in\nEnglish, and a multilingual language model (mLM), in turn, takes the caption as\nthe alt text and performs cross-lingual language understanding. The burden of\nmultilingual processing is lifted off V&L model and placed on mLM. Since the\nmultilingual text data is relatively of higher abundance and quality, ICU can\nfacilitate the conquering of language barriers for V&L models. In experiments\non two tasks across 9 languages in the IGLUE benchmark, we show that ICU can\nachieve new state-of-the-art results for five languages, and comparable results\nfor the rest.", "published": "2023-10-19 07:11:48", "link": "http://arxiv.org/abs/2310.12531v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ExtractGPT: Exploring the Potential of Large Language Models for Product\n  Attribute Value Extraction", "abstract": "E-commerce platforms require structured product data in the form of\nattribute-value pairs to offer features such as faceted product search or\nattribute-based product comparison. However, vendors often provide unstructured\nproduct descriptions, necessitating the extraction of attribute-value pairs\nfrom these texts. BERT-based extraction methods require large amounts of\ntask-specific training data and struggle with unseen attribute values. This\npaper explores using large language models (LLMs) as a more training-data\nefficient and robust alternative. We propose prompt templates for zero-shot and\nfew-shot scenarios, comparing textual and JSON-based target schema\nrepresentations. Our experiments show that GPT-4 achieves the highest average\nF1-score of 85% using detailed attribute descriptions and demonstrations.\nLlama-3-70B performs nearly as well, offering a competitive open-source\nalternative. GPT-4 surpasses the best PLM baseline by 5% in F1-score.\nFine-tuning GPT-3.5 increases the performance to the level of GPT-4 but reduces\nthe model's ability to generalize to unseen attribute values.", "published": "2023-10-19 07:39:00", "link": "http://arxiv.org/abs/2310.12537v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual estimation of political-party positioning: From label\n  aggregation to long-input Transformers", "abstract": "Scaling analysis is a technique in computational political science that\nassigns a political actor (e.g. politician or party) a score on a predefined\nscale based on a (typically long) body of text (e.g. a parliamentary speech or\nan election manifesto). For example, political scientists have often used the\nleft--right scale to systematically analyse political landscapes of different\ncountries. NLP methods for automatic scaling analysis can find broad\napplication provided they (i) are able to deal with long texts and (ii) work\nrobustly across domains and languages. In this work, we implement and compare\ntwo approaches to automatic scaling analysis of political-party manifestos:\nlabel aggregation, a pipeline strategy relying on annotations of individual\nstatements from the manifestos, and long-input-Transformer-based models, which\ncompute scaling values directly from raw text. We carry out the analysis of the\nComparative Manifestos Project dataset across 41 countries and 27 languages and\nfind that the task can be efficiently solved by state-of-the-art models, with\nlabel aggregation producing the best results.", "published": "2023-10-19 08:34:48", "link": "http://arxiv.org/abs/2310.12575v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Predict the Future from the Past? On the Temporal Data Distribution\n  Shift in Financial Sentiment Classifications", "abstract": "Temporal data distribution shift is prevalent in the financial text. How can\na financial sentiment analysis system be trained in a volatile market\nenvironment that can accurately infer sentiment and be robust to temporal data\ndistribution shifts? In this paper, we conduct an empirical study on the\nfinancial sentiment analysis system under temporal data distribution shifts\nusing a real-world financial social media dataset that spans three years. We\nfind that the fine-tuned models suffer from general performance degradation in\nthe presence of temporal distribution shifts. Furthermore, motivated by the\nunique temporal nature of the financial text, we propose a novel method that\ncombines out-of-distribution detection with time series modeling for temporal\nfinancial sentiment analysis. Experimental results show that the proposed\nmethod enhances the model's capability to adapt to evolving temporal shifts in\na volatile financial market.", "published": "2023-10-19 09:59:52", "link": "http://arxiv.org/abs/2310.12620v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Non-Autoregressive Sentence Ordering", "abstract": "Existing sentence ordering approaches generally employ encoder-decoder\nframeworks with the pointer net to recover the coherence by recurrently\npredicting each sentence step-by-step. Such an autoregressive manner only\nleverages unilateral dependencies during decoding and cannot fully explore the\nsemantic dependency between sentences for ordering. To overcome these\nlimitations, in this paper, we propose a novel Non-Autoregressive Ordering\nNetwork, dubbed \\textit{NAON}, which explores bilateral dependencies between\nsentences and predicts the sentence for each position in parallel. We claim\nthat the non-autoregressive manner is not just applicable but also particularly\nsuitable to the sentence ordering task because of two peculiar characteristics\nof the task: 1) each generation target is in deterministic length, and 2) the\nsentences and positions should match exclusively. Furthermore, to address the\nrepetition issue of the naive non-autoregressive Transformer, we introduce an\nexclusive loss to constrain the exclusiveness between positions and sentences.\nTo verify the effectiveness of the proposed model, we conduct extensive\nexperiments on several common-used datasets and the experimental results show\nthat our method outperforms all the autoregressive approaches and yields\ncompetitive performance compared with the state-of-the-arts. The codes are\navailable at:\n\\url{https://github.com/steven640pixel/nonautoregressive-sentence-ordering}.", "published": "2023-10-19 10:57:51", "link": "http://arxiv.org/abs/2310.12640v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Real-World Streaming Speech Translation for Code-Switched Speech", "abstract": "Code-switching (CS), i.e. mixing different languages in a single sentence, is\na common phenomenon in communication and can be challenging in many Natural\nLanguage Processing (NLP) settings. Previous studies on CS speech have shown\npromising results for end-to-end speech translation (ST), but have been limited\nto offline scenarios and to translation to one of the languages present in the\nsource (\\textit{monolingual transcription}).\n  In this paper, we focus on two essential yet unexplored areas for real-world\nCS speech translation: streaming settings, and translation to a third language\n(i.e., a language not included in the source). To this end, we extend the\nFisher and Miami test and validation datasets to include new targets in Spanish\nand German. Using this data, we train a model for both offline and streaming ST\nand we establish baseline results for the two settings mentioned earlier.", "published": "2023-10-19 11:15:02", "link": "http://arxiv.org/abs/2310.12648v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Is ChatGPT a Financial Expert? Evaluating Language Models on Financial\n  Natural Language Processing", "abstract": "The emergence of Large Language Models (LLMs), such as ChatGPT, has\nrevolutionized general natural language preprocessing (NLP) tasks. However,\ntheir expertise in the financial domain lacks a comprehensive evaluation. To\nassess the ability of LLMs to solve financial NLP tasks, we present FinLMEval,\na framework for Financial Language Model Evaluation, comprising nine datasets\ndesigned to evaluate the performance of language models. This study compares\nthe performance of encoder-only language models and the decoder-only language\nmodels. Our findings reveal that while some decoder-only LLMs demonstrate\nnotable performance across most financial tasks via zero-shot prompting, they\ngenerally lag behind the fine-tuned expert models, especially when dealing with\nproprietary datasets. We hope this study provides foundation evaluations for\ncontinuing efforts to build more advanced LLMs in the financial domain.", "published": "2023-10-19 11:43:15", "link": "http://arxiv.org/abs/2310.12664v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Representing and Computing Uncertainty in Phonological Reconstruction", "abstract": "Despite the inherently fuzzy nature of reconstructions in historical\nlinguistics, most scholars do not represent their uncertainty when proposing\nproto-forms. With the increasing success of recently proposed approaches to\nautomating certain aspects of the traditional comparative method, the formal\nrepresentation of proto-forms has also improved. This formalization makes it\npossible to address both the representation and the computation of uncertainty.\nBuilding on recent advances in supervised phonological reconstruction, during\nwhich an algorithm learns how to reconstruct words in a given proto-language\nrelying on previously annotated data, and inspired by improved methods for\nautomated word prediction from cognate sets, we present a new framework that\nallows for the representation of uncertainty in linguistic reconstruction and\nalso includes a workflow for the computation of fuzzy reconstructions from\nlinguistic data.", "published": "2023-10-19 13:27:42", "link": "http://arxiv.org/abs/2310.12727v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Character-level Chinese Backpack Language Models", "abstract": "The Backpack is a Transformer alternative shown to improve interpretability\nin English language modeling by decomposing predictions into a weighted sum of\ntoken sense components. However, Backpacks' reliance on token-defined meaning\nraises questions as to their potential for languages other than English, a\nlanguage for which subword tokenization provides a reasonable approximation for\nlexical items. In this work, we train, evaluate, interpret, and control\nBackpack language models in character-tokenized Chinese, in which words are\noften composed of many characters. We find that our (134M parameter) Chinese\nBackpack language model performs comparably to a (104M parameter) Transformer,\nand learns rich character-level meanings that log-additively compose to form\nword meanings. In SimLex-style lexical semantic evaluations, simple averages of\nBackpack character senses outperform input embeddings from a Transformer. We\nfind that complex multi-character meanings are often formed by using the same\nper-character sense weights consistently across context. Exploring\ninterpretability-through control, we show that we can localize a source of\ngender bias in our Backpacks to specific character senses and intervene to\nreduce the bias.", "published": "2023-10-19 13:54:57", "link": "http://arxiv.org/abs/2310.12751v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are Structural Concepts Universal in Transformer Language Models?\n  Towards Interpretable Cross-Lingual Generalization", "abstract": "Large language models (LLMs) have exhibited considerable cross-lingual\ngeneralization abilities, whereby they implicitly transfer knowledge across\nlanguages. However, the transfer is not equally successful for all languages,\nespecially for low-resource ones, which poses an ongoing challenge. It is\nunclear whether we have reached the limits of implicit cross-lingual\ngeneralization and if explicit knowledge transfer is viable. In this paper, we\ninvestigate the potential for explicitly aligning conceptual correspondence\nbetween languages to enhance cross-lingual generalization. Using the syntactic\naspect of language as a testbed, our analyses of 43 languages reveal a high\ndegree of alignability among the spaces of structural concepts within each\nlanguage for both encoder-only and decoder-only LLMs. We then propose a\nmeta-learning-based method to learn to align conceptual spaces of different\nlanguages, which facilitates zero-shot and few-shot generalization in concept\nclassification and also offers insights into the cross-lingual in-context\nlearning phenomenon. Experiments on syntactic analysis tasks show that our\napproach achieves competitive results with state-of-the-art methods and narrows\nthe performance gap between languages, particularly benefiting those with\nlimited resources.", "published": "2023-10-19 14:50:51", "link": "http://arxiv.org/abs/2310.12794v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Locality and Symmetry of Positional Encodings", "abstract": "Positional Encodings (PEs) are used to inject word-order information into\ntransformer-based language models. While they can significantly enhance the\nquality of sentence representations, their specific contribution to language\nmodels is not fully understood, especially given recent findings that various\npositional encodings are insensitive to word order. In this work, we conduct a\nsystematic study of positional encodings in \\textbf{Bidirectional Masked\nLanguage Models} (BERT-style) , which complements existing work in three\naspects: (1) We uncover the core function of PEs by identifying two common\nproperties, Locality and Symmetry; (2) We show that the two properties are\nclosely correlated with the performances of downstream tasks; (3) We quantify\nthe weakness of current PEs by introducing two new probing tasks, on which\ncurrent PEs perform poorly. We believe that these results are the basis for\ndeveloping better PEs for transformer-based language models. The code is\navailable at \\faGithub~ \\url{https://github.com/tigerchen52/locality\\_symmetry}", "published": "2023-10-19 16:15:15", "link": "http://arxiv.org/abs/2310.12864v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "StoryAnalogy: Deriving Story-level Analogies from Large Language Models\n  to Unlock Analogical Understanding", "abstract": "Analogy-making between narratives is crucial for human reasoning. In this\npaper, we evaluate the ability to identify and generate analogies by\nconstructing a first-of-its-kind large-scale story-level analogy corpus,\n\\textsc{StoryAnalogy}, which contains 24K story pairs from diverse domains with\nhuman annotations on two similarities from the extended Structure-Mapping\nTheory. We design a set of tests on \\textsc{StoryAnalogy}, presenting the first\nevaluation of story-level analogy identification and generation. Interestingly,\nwe find that the analogy identification tasks are incredibly difficult not only\nfor sentence embedding models but also for the recent large language models\n(LLMs) such as ChatGPT and LLaMa. ChatGPT, for example, only achieved around\n30% accuracy in multiple-choice questions (compared to over 85% accuracy for\nhumans). Furthermore, we observe that the data in \\textsc{StoryAnalogy} can\nimprove the quality of analogy generation in LLMs, where a fine-tuned\nFlanT5-xxl model achieves comparable performance to zero-shot ChatGPT.", "published": "2023-10-19 16:29:23", "link": "http://arxiv.org/abs/2310.12874v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Systematic Study of Performance Disparities in Multilingual\n  Task-Oriented Dialogue Systems", "abstract": "Achieving robust language technologies that can perform well across the\nworld's many languages is a central goal of multilingual NLP. In this work, we\ntake stock of and empirically analyse task performance disparities that exist\nbetween multilingual task-oriented dialogue (ToD) systems. We first define new\nquantitative measures of absolute and relative equivalence in system\nperformance, capturing disparities across languages and within individual\nlanguages. Through a series of controlled experiments, we demonstrate that\nperformance disparities depend on a number of factors: the nature of the ToD\ntask at hand, the underlying pretrained language model, the target language,\nand the amount of ToD annotated data. We empirically prove the existence of the\nadaptation and intrinsic biases in current ToD systems: e.g., ToD systems\ntrained for Arabic or Turkish using annotated ToD data fully parallel to\nEnglish ToD data still exhibit diminished ToD task performance. Beyond\nproviding a series of insights into the performance disparities of ToD systems\nin different languages, our analyses offer practical tips on how to approach\nToD data collection and system development for new languages.", "published": "2023-10-19 16:41:44", "link": "http://arxiv.org/abs/2310.12892v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Predictive Factor Analysis of Social Biases and Task-Performance in\n  Pretrained Masked Language Models", "abstract": "Various types of social biases have been reported with pretrained Masked\nLanguage Models (MLMs) in prior work. However, multiple underlying factors are\nassociated with an MLM such as its model size, size of the training data,\ntraining objectives, the domain from which pretraining data is sampled,\ntokenization, and languages present in the pretrained corpora, to name a few.\nIt remains unclear as to which of those factors influence social biases that\nare learned by MLMs. To study the relationship between model factors and the\nsocial biases learned by an MLM, as well as the downstream task performance of\nthe model, we conduct a comprehensive study over 39 pretrained MLMs covering\ndifferent model sizes, training objectives, tokenization methods, training data\ndomains and languages. Our results shed light on important factors often\nneglected in prior literature, such as tokenization or model objectives.", "published": "2023-10-19 17:33:33", "link": "http://arxiv.org/abs/2310.12936v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SEGO: Sequential Subgoal Optimization for Mathematical Problem-Solving", "abstract": "Large Language Models (LLMs) have driven substantial progress in artificial\nintelligence in recent years, exhibiting impressive capabilities across a wide\nrange of tasks, including mathematical problem-solving. Inspired by the success\nof subgoal-based methods, we propose a novel framework called\n\\textbf{SE}quential sub\\textbf{G}oal \\textbf{O}ptimization (SEGO) to enhance\nLLMs' ability to solve mathematical problems. By establishing a connection\nbetween the subgoal breakdown process and the probability of solving problems,\nSEGO aims to identify better subgoals with theoretical guarantees. Addressing\nthe challenge of identifying suitable subgoals in a large solution space, our\nframework generates problem-specific subgoals and adjusts them according to\ncarefully designed criteria. Incorporating these optimized subgoals into the\npolicy model training leads to significant improvements in problem-solving\nperformance. We validate SEGO's efficacy through experiments on two benchmarks,\nGSM8K and MATH, where our approach outperforms existing methods, highlighting\nthe potential of SEGO in AI-driven mathematical problem-solving.\n  Data and code associated with this paper will be available at\nhttps://github.com/zhaoxlpku/SEGO", "published": "2023-10-19 17:56:40", "link": "http://arxiv.org/abs/2310.12960v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GARI: Graph Attention for Relative Isomorphism of Arabic Word Embeddings", "abstract": "Bilingual Lexical Induction (BLI) is a core challenge in NLP, it relies on\nthe relative isomorphism of individual embedding spaces. Existing attempts\naimed at controlling the relative isomorphism of different embedding spaces\nfail to incorporate the impact of semantically related words in the model\ntraining objective. To address this, we propose GARI that combines the\ndistributional training objectives with multiple isomorphism losses guided by\nthe graph attention network. GARI considers the impact of semantical variations\nof words in order to define the relative isomorphism of the embedding spaces.\nExperimental evaluation using the Arabic language data set shows that GARI\noutperforms the existing research by improving the average P@1 by a relative\nscore of up to 40.95% and 76.80% for in-domain and domain mismatch settings\nrespectively. We release the codes for GARI at\nhttps://github.com/asif6827/GARI.", "published": "2023-10-19 18:08:22", "link": "http://arxiv.org/abs/2310.13068v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do Language Models Learn about Legal Entity Types during Pretraining?", "abstract": "Language Models (LMs) have proven their ability to acquire diverse linguistic\nknowledge during the pretraining phase, potentially serving as a valuable\nsource of incidental supervision for downstream tasks. However, there has been\nlimited research conducted on the retrieval of domain-specific knowledge, and\nspecifically legal knowledge. We propose to explore the task of Entity Typing,\nserving as a proxy for evaluating legal knowledge as an essential aspect of\ntext comprehension, and a foundational task to numerous downstream legal NLP\napplications. Through systematic evaluation and analysis and two types of\nprompting (cloze sentences and QA-based templates) and to clarify the nature of\nthese acquired cues, we compare diverse types and lengths of entities both\ngeneral and domain-specific entities, semantics or syntax signals, and\ndifferent LM pretraining corpus (generic and legal-oriented) and architectures\n(encoder BERT-based and decoder-only with Llama2). We show that (1) Llama2\nperforms well on certain entities and exhibits potential for substantial\nimprovement with optimized prompt templates, (2) law-oriented LMs show\ninconsistent performance, possibly due to variations in their training corpus,\n(3) LMs demonstrate the ability to type entities even in the case of\nmulti-token entities, (4) all models struggle with entities belonging to\nsub-domains of the law (5) Llama2 appears to frequently overlook syntactic\ncues, a shortcoming less present in BERT-based architectures.", "published": "2023-10-19 18:47:21", "link": "http://arxiv.org/abs/2310.13092v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Candidate Answer Extraction through Differentiable\n  Masker-Reconstructor Model", "abstract": "Question generation is a widely used data augmentation approach with\nextensive applications, and extracting qualified candidate answers from context\npassages is a critical step for most question generation systems. However,\nexisting methods for candidate answer extraction are reliant on linguistic\nrules or annotated data that face the partial annotation issue and challenges\nin generalization. To overcome these limitations, we propose a novel\nunsupervised candidate answer extraction approach that leverages the inherent\nstructure of context passages through a Differentiable Masker-Reconstructor\n(DMR) Model with the enforcement of self-consistency for picking up salient\ninformation tokens. We curated two datasets with exhaustively-annotated answers\nand benchmark a comprehensive set of supervised and unsupervised candidate\nanswer extraction methods. We demonstrate the effectiveness of the DMR model by\nshowing its performance is superior among unsupervised methods and comparable\nto supervised methods.", "published": "2023-10-19 19:07:08", "link": "http://arxiv.org/abs/2310.13106v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Auto-Instruct: Automatic Instruction Generation and Ranking for\n  Black-Box Language Models", "abstract": "Large language models (LLMs) can perform a wide range of tasks by following\nnatural language instructions, without the necessity of task-specific\nfine-tuning. Unfortunately, the performance of LLMs is greatly influenced by\nthe quality of these instructions, and manually writing effective instructions\nfor each task is a laborious and subjective process. In this paper, we\nintroduce Auto-Instruct, a novel method to automatically improve the quality of\ninstructions provided to LLMs. Our method leverages the inherent generative\nability of LLMs to produce diverse candidate instructions for a given task, and\nthen ranks them using a scoring model trained on a variety of 575 existing NLP\ntasks. In experiments on 118 out-of-domain tasks, Auto-Instruct surpasses both\nhuman-written instructions and existing baselines of LLM-generated\ninstructions. Furthermore, our method exhibits notable generalizability even\nwith other LLMs that are not incorporated into its training process.", "published": "2023-10-19 19:52:55", "link": "http://arxiv.org/abs/2310.13127v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MAF: Multi-Aspect Feedback for Improving Reasoning in Large Language\n  Models", "abstract": "Language Models (LMs) have shown impressive performance in various natural\nlanguage tasks. However, when it comes to natural language reasoning, LMs still\nface challenges such as hallucination, generating incorrect intermediate\nreasoning steps, and making mathematical errors. Recent research has focused on\nenhancing LMs through self-improvement using feedback. Nevertheless, existing\napproaches relying on a single generic feedback source fail to address the\ndiverse error types found in LM-generated reasoning chains. In this work, we\npropose Multi-Aspect Feedback, an iterative refinement framework that\nintegrates multiple feedback modules, including frozen LMs and external tools,\neach focusing on a specific error category. Our experimental results\ndemonstrate the efficacy of our approach to addressing several errors in the\nLM-generated reasoning chain and thus improving the overall performance of an\nLM in several reasoning tasks. We see a relative improvement of up to 20% in\nMathematical Reasoning and up to 18% in Logical Entailment.", "published": "2023-10-19 02:32:39", "link": "http://arxiv.org/abs/2310.12426v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DocXChain: A Powerful Open-Source Toolchain for Document Parsing and\n  Beyond", "abstract": "In this report, we introduce DocXChain, a powerful open-source toolchain for\ndocument parsing, which is designed and developed to automatically convert the\nrich information embodied in unstructured documents, such as text, tables and\ncharts, into structured representations that are readable and manipulable by\nmachines. Specifically, basic capabilities, including text detection, text\nrecognition, table structure recognition and layout analysis, are provided.\nUpon these basic capabilities, we also build a set of fully functional\npipelines for document parsing, i.e., general text reading, table parsing, and\ndocument structurization, to drive various applications related to documents in\nreal-world scenarios. Moreover, DocXChain is concise, modularized and flexible,\nsuch that it can be readily integrated with existing tools, libraries or models\n(such as LangChain and ChatGPT), to construct more powerful systems that can\naccomplish more complicated and challenging tasks. The code of DocXChain is\npublicly available\nat:~\\url{https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/Applications/DocXChain}", "published": "2023-10-19 02:49:09", "link": "http://arxiv.org/abs/2310.12430v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "PoisonPrompt: Backdoor Attack on Prompt-based Large Language Models", "abstract": "Prompts have significantly improved the performance of pretrained Large\nLanguage Models (LLMs) on various downstream tasks recently, making them\nincreasingly indispensable for a diverse range of LLM application scenarios.\nHowever, the backdoor vulnerability, a serious security threat that can\nmaliciously alter the victim model's normal predictions, has not been\nsufficiently explored for prompt-based LLMs. In this paper, we present\nPOISONPROMPT, a novel backdoor attack capable of successfully compromising both\nhard and soft prompt-based LLMs. We evaluate the effectiveness, fidelity, and\nrobustness of POISONPROMPT through extensive experiments on three popular\nprompt methods, using six datasets and three widely used LLMs. Our findings\nhighlight the potential security threats posed by backdoor attacks on\nprompt-based LLMs and emphasize the need for further research in this area.", "published": "2023-10-19 03:25:28", "link": "http://arxiv.org/abs/2310.12439v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Efficient Long-Range Transformers: You Need to Attend More, but Not\n  Necessarily at Every Layer", "abstract": "Pretrained transformer models have demonstrated remarkable performance across\nvarious natural language processing tasks. These models leverage the attention\nmechanism to capture long- and short-range dependencies in the sequence.\nHowever, the (full) attention mechanism incurs high computational cost -\nquadratic in the sequence length, which is not affordable in tasks with long\nsequences, e.g., inputs with 8k tokens. Although sparse attention can be used\nto improve computational efficiency, as suggested in existing work, it has\nlimited modeling capacity and often fails to capture complicated dependencies\nin long sequences. To tackle this challenge, we propose MASFormer, an\neasy-to-implement transformer variant with Mixed Attention Spans. Specifically,\nMASFormer is equipped with full attention to capture long-range dependencies,\nbut only at a small number of layers. For the remaining layers, MASformer only\nemploys sparse attention to capture short-range dependencies. Our experiments\non natural language modeling and generation tasks show that a decoder-only\nMASFormer model of 1.3B parameters can achieve competitive performance to\nvanilla transformers with full attention while significantly reducing\ncomputational cost (up to 75%). Additionally, we investigate the effectiveness\nof continual training with long sequence data and how sequence length impacts\ndownstream generation performance, which may be of independent interest.", "published": "2023-10-19 03:32:05", "link": "http://arxiv.org/abs/2310.12442v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Rethinking the Construction of Effective Metrics for Understanding the\n  Mechanisms of Pretrained Language Models", "abstract": "Pretrained language models are expected to effectively map input text to a\nset of vectors while preserving the inherent relationships within the text.\nConsequently, designing a white-box model to compute metrics that reflect the\npresence of specific internal relations in these vectors has become a common\napproach for post-hoc interpretability analysis of pretrained language models.\nHowever, achieving interpretability in white-box models and ensuring the rigor\nof metric computation becomes challenging when the source model lacks inherent\ninterpretability. Therefore, in this paper, we discuss striking a balance in\nthis trade-off and propose a novel line to constructing metrics for\nunderstanding the mechanisms of pretrained language models. We have\nspecifically designed a family of metrics along this line of investigation, and\nthe model used to compute these metrics is referred to as the tree topological\nprobe. We conducted measurements on BERT-large by using these metrics. Based on\nthe experimental results, we propose a speculation regarding the working\nmechanism of BERT-like pretrained language models, as well as a strategy for\nenhancing fine-tuning performance by leveraging the topological probe to\nimprove specific submodules.", "published": "2023-10-19 04:16:40", "link": "http://arxiv.org/abs/2310.12454v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Not All Countries Celebrate Thanksgiving: On the Cultural Dominance in\n  Large Language Models", "abstract": "This paper identifies a cultural dominance issue within large language models\n(LLMs) due to the predominant use of English data in model training (e.g.,\nChatGPT). LLMs often provide inappropriate English-culture-related answers that\nare not relevant to the expected culture when users ask in non-English\nlanguages. To systematically evaluate the cultural dominance issue, we build a\nbenchmark of concrete (e.g., holidays and songs) and abstract (e.g., values and\nopinions) cultural objects. Empirical results show that the representative GPT\nmodels suffer from the culture dominance problem, where GPT-4 is the most\naffected while text-davinci-003 suffers the least from this problem. Our study\nemphasizes the need to critically examine cultural dominance and ethical\nconsideration in their development and deployment. We show that two\nstraightforward methods in model development (i.e., pretraining on more diverse\ndata) and deployment (e.g., culture-aware prompting) can significantly mitigate\nthe cultural dominance issue in LLMs.", "published": "2023-10-19 05:38:23", "link": "http://arxiv.org/abs/2310.12481v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Lost in Translation: When GPT-4V(ision) Can't See Eye to Eye with Text.\n  A Vision-Language-Consistency Analysis of VLLMs and Beyond", "abstract": "Recent advancements in multimodal techniques open exciting possibilities for\nmodels excelling in diverse tasks involving text, audio, and image processing.\nModels like GPT-4V, blending computer vision and language modeling, excel in\ncomplex text and image tasks. Numerous prior research endeavors have diligently\nexamined the performance of these Vision Large Language Models (VLLMs) across\ntasks like object detection, image captioning and others. However, these\nanalyses often focus on evaluating the performance of each modality in\nisolation, lacking insights into their cross-modal interactions. Specifically,\nquestions concerning whether these vision-language models execute vision and\nlanguage tasks consistently or independently have remained unanswered. In this\nstudy, we draw inspiration from recent investigations into multilingualism and\nconduct a comprehensive analysis of model's cross-modal interactions. We\nintroduce a systematic framework that quantifies the capability disparities\nbetween different modalities in the multi-modal setting and provide a set of\ndatasets designed for these evaluations. Our findings reveal that models like\nGPT-4V tend to perform consistently modalities when the tasks are relatively\nsimple. However, the trustworthiness of results derived from the vision\nmodality diminishes as the tasks become more challenging. Expanding on our\nfindings, we introduce \"Vision Description Prompting,\" a method that\neffectively improves performance in challenging vision-related tasks.", "published": "2023-10-19 06:45:11", "link": "http://arxiv.org/abs/2310.12520v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Named Entity Recognition for Monitoring Plant Health Threats in Tweets:\n  a ChouBERT Approach", "abstract": "An important application scenario of precision agriculture is detecting and\nmeasuring crop health threats using sensors and data analysis techniques.\nHowever, the textual data are still under-explored among the existing solutions\ndue to the lack of labelled data and fine-grained semantic resources. Recent\nresearch suggests that the increasing connectivity of farmers and the emergence\nof online farming communities make social media like Twitter a participatory\nplatform for detecting unfamiliar plant health events if we can extract\nessential information from unstructured textual data. ChouBERT is a French\npre-trained language model that can identify Tweets concerning observations of\nplant health issues with generalizability on unseen natural hazards. This paper\ntackles the lack of labelled data by further studying ChouBERT's know-how on\ntoken-level annotation tasks over small labeled sets.", "published": "2023-10-19 06:54:55", "link": "http://arxiv.org/abs/2310.12522v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DepWiGNN: A Depth-wise Graph Neural Network for Multi-hop Spatial\n  Reasoning in Text", "abstract": "Spatial reasoning in text plays a crucial role in various real-world\napplications. Existing approaches for spatial reasoning typically infer spatial\nrelations from pure text, which overlooks the gap between natural language and\nsymbolic structures. Graph neural networks (GNNs) have showcased exceptional\nproficiency in inducing and aggregating symbolic structures. However, classical\nGNNs face challenges in handling multi-hop spatial reasoning due to the\nover-smoothing issue, i.e., the performance decreases substantially as the\nnumber of graph layers increases. To cope with these challenges, we propose a\nnovel Depth-Wise Graph Neural Network (DepWiGNN). Specifically, we design a\nnovel node memory scheme and aggregate the information over the depth dimension\ninstead of the breadth dimension of the graph, which empowers the ability to\ncollect long dependencies without stacking multiple layers. Experimental\nresults on two challenging multi-hop spatial reasoning datasets show that\nDepWiGNN outperforms existing spatial reasoning methods. The comparisons with\nthe other three GNNs further demonstrate its superiority in capturing long\ndependency in the graph.", "published": "2023-10-19 08:07:22", "link": "http://arxiv.org/abs/2310.12557v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Models Help Humans Verify Truthfulness -- Except When\n  They Are Convincingly Wrong", "abstract": "Large Language Models (LLMs) are increasingly used for accessing information\non the web. Their truthfulness and factuality are thus of great interest. To\nhelp users make the right decisions about the information they get, LLMs should\nnot only provide information but also help users fact-check it. Our experiments\nwith 80 crowdworkers compare language models with search engines (information\nretrieval systems) at facilitating fact-checking. We prompt LLMs to validate a\ngiven claim and provide corresponding explanations. Users reading LLM\nexplanations are significantly more efficient than those using search engines\nwhile achieving similar accuracy. However, they over-rely on the LLMs when the\nexplanation is wrong. To reduce over-reliance on LLMs, we ask LLMs to provide\ncontrastive information - explain both why the claim is true and false, and\nthen we present both sides of the explanation to users. This contrastive\nexplanation mitigates users' over-reliance on LLMs, but cannot significantly\noutperform search engines. Further, showing both search engine results and LLM\nexplanations offers no complementary benefits compared to search engines alone.\nTaken together, our study highlights that natural language explanations by LLMs\nmay not be a reliable replacement for reading the retrieved passages,\nespecially in high-stakes settings where over-relying on wrong AI explanations\ncould lead to critical consequences.", "published": "2023-10-19 08:09:58", "link": "http://arxiv.org/abs/2310.12558v2", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Pretraining Language Models with Text-Attributed Heterogeneous Graphs", "abstract": "In many real-world scenarios (e.g., academic networks, social platforms),\ndifferent types of entities are not only associated with texts but also\nconnected by various relationships, which can be abstracted as Text-Attributed\nHeterogeneous Graphs (TAHGs). Current pretraining tasks for Language Models\n(LMs) primarily focus on separately learning the textual information of each\nentity and overlook the crucial aspect of capturing topological connections\namong entities in TAHGs. In this paper, we present a new pretraining framework\nfor LMs that explicitly considers the topological and heterogeneous information\nin TAHGs. Firstly, we define a context graph as neighborhoods of a target node\nwithin specific orders and propose a topology-aware pretraining task to predict\nnodes involved in the context graph by jointly optimizing an LM and an\nauxiliary heterogeneous graph neural network. Secondly, based on the\nobservation that some nodes are text-rich while others have little text, we\ndevise a text augmentation strategy to enrich textless nodes with their\nneighbors' texts for handling the imbalance issue. We conduct link prediction\nand node classification tasks on three datasets from various domains.\nExperimental results demonstrate the superiority of our approach over existing\nmethods and the rationality of each design. Our code is available at\nhttps://github.com/Hope-Rita/THLM.", "published": "2023-10-19 08:41:21", "link": "http://arxiv.org/abs/2310.12580v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Identifying and Adapting Transformer-Components Responsible for Gender\n  Bias in an English Language Model", "abstract": "Language models (LMs) exhibit and amplify many types of undesirable biases\nlearned from the training data, including gender bias. However, we lack tools\nfor effectively and efficiently changing this behavior without hurting general\nlanguage modeling performance. In this paper, we study three methods for\nidentifying causal relations between LM components and particular output:\ncausal mediation analysis, automated circuit discovery and our novel, efficient\nmethod called DiffMask+ based on differential masking. We apply the methods to\nGPT-2 small and the problem of gender bias, and use the discovered sets of\ncomponents to perform parameter-efficient fine-tuning for bias mitigation. Our\nresults show significant overlap in the identified components (despite huge\ndifferences in the computational requirements of the methods) as well as\nsuccess in mitigating gender bias, with less damage to general language\nmodeling compared to full model fine-tuning. However, our work also underscores\nthe difficulty of defining and measuring bias, and the sensitivity of causal\ndiscovery procedures to dataset choice. We hope our work can contribute to more\nattention for dataset development, and lead to more effective mitigation\nstrategies for other types of bias.", "published": "2023-10-19 09:39:21", "link": "http://arxiv.org/abs/2310.12611v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Transformer-based Entity Legal Form Classification", "abstract": "We propose the application of Transformer-based language models for\nclassifying entity legal forms from raw legal entity names. Specifically, we\nemploy various BERT variants and compare their performance against multiple\ntraditional baselines. Our evaluation encompasses a substantial subset of\nfreely available Legal Entity Identifier (LEI) data, comprising over 1.1\nmillion legal entities from 30 different legal jurisdictions. The ground truth\nlabels for classification per jurisdiction are taken from the Entity Legal Form\n(ELF) code standard (ISO 20275). Our findings demonstrate that pre-trained BERT\nvariants outperform traditional text classification approaches in terms of F1\nscore, while also performing comparably well in the Macro F1 Score. Moreover,\nthe validity of our proposal is supported by the outcome of third-party expert\nreviews conducted in ten selected jurisdictions. This study highlights the\nsignificant potential of Transformer-based models in advancing data\nstandardization and data integration. The presented approaches can greatly\nbenefit financial institutions, corporations, governments and other\norganizations in assessing business relationships, understanding risk exposure,\nand promoting effective governance.", "published": "2023-10-19 14:11:43", "link": "http://arxiv.org/abs/2310.12766v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Label-Aware Automatic Verbalizer for Few-Shot Text Classification", "abstract": "Prompt-based learning has shown its effectiveness in few-shot text\nclassification. One important factor in its success is a verbalizer, which\ntranslates output from a language model into a predicted class. Notably, the\nsimplest and widely acknowledged verbalizer employs manual labels to represent\nthe classes. However, manual selection does not guarantee the optimality of the\nselected words when conditioned on the chosen language model. Therefore, we\npropose Label-Aware Automatic Verbalizer (LAAV), effectively augmenting the\nmanual labels to achieve better few-shot classification results. Specifically,\nwe use the manual labels along with the conjunction \"and\" to induce the model\nto generate more effective words for the verbalizer. The experimental results\non five datasets across five languages demonstrate that LAAV significantly\noutperforms existing verbalizers. Furthermore, our analysis reveals that LAAV\nsuggests more relevant words compared to similar approaches, especially in\nmid-to-low resource languages.", "published": "2023-10-19 14:30:07", "link": "http://arxiv.org/abs/2310.12778v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MolCA: Molecular Graph-Language Modeling with Cross-Modal Projector and\n  Uni-Modal Adapter", "abstract": "Language Models (LMs) have demonstrated impressive molecule understanding\nability on various 1D text-related tasks. However, they inherently lack 2D\ngraph perception - a critical ability of human professionals in comprehending\nmolecules' topological structures. To bridge this gap, we propose MolCA:\nMolecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal\nAdapter. MolCA enables an LM (e.g., Galactica) to understand both text- and\ngraph-based molecular contents via the cross-modal projector. Specifically, the\ncross-modal projector is implemented as a Q-Former to connect a graph encoder's\nrepresentation space and an LM's text space. Further, MolCA employs a uni-modal\nadapter (i.e., LoRA) for the LM's efficient adaptation to downstream tasks.\nUnlike previous studies that couple an LM with a graph encoder via cross-modal\ncontrastive learning, MolCA retains the LM's ability of open-ended text\ngeneration and augments it with 2D graph information. To showcase its\neffectiveness, we extensively benchmark MolCA on tasks of molecule captioning,\nIUPAC name prediction, and molecule-text retrieval, on which MolCA\nsignificantly outperforms the baselines. Our codes and checkpoints can be found\nat https://github.com/acharkq/MolCA.", "published": "2023-10-19 14:52:58", "link": "http://arxiv.org/abs/2310.12798v4", "categories": ["cs.CL", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Data Augmentations for Improved (Large) Language Model Generalization", "abstract": "The reliance of text classifiers on spurious correlations can lead to poor\ngeneralization at deployment, raising concerns about their use in\nsafety-critical domains such as healthcare. In this work, we propose to use\ncounterfactual data augmentation, guided by knowledge of the causal structure\nof the data, to simulate interventions on spurious features and to learn more\nrobust text classifiers. We show that this strategy is appropriate in\nprediction problems where the label is spuriously correlated with an attribute.\nUnder the assumptions of such problems, we discuss the favorable sample\ncomplexity of counterfactual data augmentation, compared to importance\nre-weighting. Pragmatically, we match examples using auxiliary data, based on\ndiff-in-diff methodology, and use a large language model (LLM) to represent a\nconditional probability of text. Through extensive experimentation on learning\ncaregiver-invariant predictors of clinical diagnoses from medical narratives\nand on semi-synthetic data, we demonstrate that our method for simulating\ninterventions improves out-of-distribution (OOD) accuracy compared to baseline\ninvariant learning algorithms.", "published": "2023-10-19 14:59:25", "link": "http://arxiv.org/abs/2310.12803v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "GestureGPT: Toward Zero-Shot Free-Form Hand Gesture Understanding with\n  Large Language Model Agents", "abstract": "Existing gesture interfaces only work with a fixed set of gestures defined\neither by interface designers or by users themselves, which introduces learning\nor demonstration efforts that diminish their naturalness. Humans, on the other\nhand, understand free-form gestures by synthesizing the gesture, context,\nexperience, and common sense. In this way, the user does not need to learn,\ndemonstrate, or associate gestures. We introduce GestureGPT, a free-form hand\ngesture understanding framework that mimics human gesture understanding\nprocedures to enable a natural free-form gestural interface. Our framework\nleverages multiple Large Language Model agents to manage and synthesize gesture\nand context information, then infers the interaction intent by associating the\ngesture with an interface function. More specifically, our triple-agent\nframework includes a Gesture Description Agent that automatically segments and\nformulates natural language descriptions of hand poses and movements based on\nhand landmark coordinates. The description is deciphered by a Gesture Inference\nAgent through self-reasoning and querying about the interaction context (e.g.,\ninteraction history, gaze data), which is managed by a Context Management\nAgent. Following iterative exchanges, the Gesture Inference Agent discerns the\nuser's intent by grounding it to an interactive function. We validated our\nframework offline under two real-world scenarios: smart home control and online\nvideo streaming. The average zero-shot Top-1/Top-5 grounding accuracies are\n44.79%/83.59% for smart home tasks and 37.50%/73.44% for video streaming tasks.\nWe also provide an extensive discussion that includes rationale for model\nselection, generalizability, and future research directions for a practical\nsystem etc.", "published": "2023-10-19 15:17:34", "link": "http://arxiv.org/abs/2310.12821v5", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Knowledge-Augmented Language Model Verification", "abstract": "Recent Language Models (LMs) have shown impressive capabilities in generating\ntexts with the knowledge internalized in parameters. Yet, LMs often generate\nthe factually incorrect responses to the given queries, since their knowledge\nmay be inaccurate, incomplete, and outdated. To address this problem, previous\nworks propose to augment LMs with the knowledge retrieved from an external\nknowledge source. However, such approaches often show suboptimal text\ngeneration performance due to two reasons: 1) the model may fail to retrieve\nthe knowledge relevant to the given query, or 2) the model may not faithfully\nreflect the retrieved knowledge in the generated text. To overcome these, we\npropose to verify the output and the knowledge of the knowledge-augmented LMs\nwith a separate verifier, which is a small LM that is trained to detect those\ntwo types of errors through instruction-finetuning. Then, when the verifier\nrecognizes an error, we can rectify it by either retrieving new knowledge or\ngenerating new text. Further, we use an ensemble of the outputs from different\ninstructions with a single verifier to enhance the reliability of the\nverification processes. We validate the effectiveness of the proposed\nverification steps on multiple question answering benchmarks, whose results\nshow that the proposed verifier effectively identifies retrieval and generation\nerrors, allowing LMs to provide more factually correct outputs. Our code is\navailable at https://github.com/JinheonBaek/KALMV.", "published": "2023-10-19 15:40:00", "link": "http://arxiv.org/abs/2310.12836v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Probing LLMs for hate speech detection: strengths and vulnerabilities", "abstract": "Recently efforts have been made by social media platforms as well as\nresearchers to detect hateful or toxic language using large language models.\nHowever, none of these works aim to use explanation, additional context and\nvictim community information in the detection process. We utilise different\nprompt variation, input information and evaluate large language models in zero\nshot setting (without adding any in-context examples). We select three large\nlanguage models (GPT-3.5, text-davinci and Flan-T5) and three datasets -\nHateXplain, implicit hate and ToxicSpans. We find that on average including the\ntarget information in the pipeline improves the model performance substantially\n(~20-30%) over the baseline across the datasets. There is also a considerable\neffect of adding the rationales/explanations into the pipeline (~10-20%) over\nthe baseline across the datasets. In addition, we further provide a typology of\nthe error cases where these large language models fail to (i) classify and (ii)\nexplain the reason for the decisions they take. Such vulnerable points\nautomatically constitute 'jailbreak' prompts for these models and industry\nscale safeguard techniques need to be developed to make the models robust\nagainst such prompts.", "published": "2023-10-19 16:11:02", "link": "http://arxiv.org/abs/2310.12860v2", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Experimental Narratives: A Comparison of Human Crowdsourced Storytelling\n  and AI Storytelling", "abstract": "The paper proposes a framework that combines behavioral and computational\nexperiments employing fictional prompts as a novel tool for investigating\ncultural artifacts and social biases in storytelling both by humans and\ngenerative AI. The study analyzes 250 stories authored by crowdworkers in June\n2019 and 80 stories generated by GPT-3.5 and GPT-4 in March 2023 by merging\nmethods from narratology and inferential statistics. Both crowdworkers and\nlarge language models responded to identical prompts about creating and falling\nin love with an artificial human. The proposed experimental paradigm allows a\ndirect and controlled comparison between human and LLM-generated storytelling.\nResponses to the Pygmalionesque prompts confirm the pervasive presence of the\nPygmalion myth in the collective imaginary of both humans and large language\nmodels. All solicited narratives present a scientific or technological pursuit.\nThe analysis reveals that narratives from GPT-3.5 and particularly GPT-4 are\nmore progressive in terms of gender roles and sexuality than those written by\nhumans. While AI narratives with default settings and no additional prompting\ncan occasionally provide innovative plot twists, they offer less imaginative\nscenarios and rhetoric than human-authored texts. The proposed framework argues\nthat fiction can be used as a window into human and AI-based collective\nimaginary and social dimensions.", "published": "2023-10-19 16:54:38", "link": "http://arxiv.org/abs/2310.12902v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "On the Representational Capacity of Recurrent Neural Language Models", "abstract": "This work investigates the computational expressivity of language models\n(LMs) based on recurrent neural networks (RNNs). Siegelmann and Sontag (1992)\nfamously showed that RNNs with rational weights and hidden states and unbounded\ncomputation time are Turing complete. However, LMs define weightings over\nstrings in addition to just (unweighted) language membership and the analysis\nof the computational power of RNN LMs (RLMs) should reflect this. We extend the\nTuring completeness result to the probabilistic case, showing how a rationally\nweighted RLM with unbounded computation time can simulate any deterministic\nprobabilistic Turing machine (PTM) with rationally weighted transitions. Since,\nin practice, RLMs work in real-time, processing a symbol at every time step, we\ntreat the above result as an upper bound on the expressivity of RLMs. We also\nprovide a lower bound by showing that under the restriction to real-time\ncomputation, such models can simulate deterministic real-time rational PTMs.", "published": "2023-10-19 17:39:47", "link": "http://arxiv.org/abs/2310.12942v5", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AutoMix: Automatically Mixing Language Models", "abstract": "Large language models (LLMs) are now available from cloud API providers in\nvarious sizes and configurations. While this diversity offers a broad spectrum\nof choices, effectively leveraging the options to optimize computational cost\nand performance remains challenging. In this work, we present Automix, an\napproach that strategically routes queries to larger LMs, based on the\napproximate correctness of outputs from a smaller LM. Central to Automix are\ntwo key technical contributions. First, it has a few-shot self-verification\nmechanism, which estimates the reliability of its own outputs without requiring\nextensive training. Second, given that self-verification can be noisy, it\nemploys a POMDP based router that can effectively select an appropriately sized\nmodel, based on answer confidence. Experiments across five language models and\nfive challenging datasets show that Automix consistently surpasses strong\nbaselines, reducing computational cost by over 50% for comparable performance.", "published": "2023-10-19 17:57:39", "link": "http://arxiv.org/abs/2310.12963v5", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GraphGPT: Graph Instruction Tuning for Large Language Models", "abstract": "Graph Neural Networks (GNNs) have evolved to understand graph structures\nthrough recursive exchanges and aggregations among nodes. To enhance\nrobustness, self-supervised learning (SSL) has become a vital tool for data\naugmentation. Traditional methods often depend on fine-tuning with\ntask-specific labels, limiting their effectiveness when labeled data is scarce.\nOur research tackles this by advancing graph model generalization in zero-shot\nlearning environments. Inspired by the success of large language models (LLMs),\nwe aim to create a graph-oriented LLM capable of exceptional generalization\nacross various datasets and tasks without relying on downstream graph data. We\nintroduce the GraphGPT framework, which integrates LLMs with graph structural\nknowledge through graph instruction tuning. This framework includes a\ntext-graph grounding component to link textual and graph structures and a\ndual-stage instruction tuning approach with a lightweight graph-text alignment\nprojector. These innovations allow LLMs to comprehend complex graph structures\nand enhance adaptability across diverse datasets and tasks. Our framework\ndemonstrates superior generalization in both supervised and zero-shot graph\nlearning tasks, surpassing existing benchmarks. The open-sourced model\nimplementation of our GraphGPT is available at\nhttps://github.com/HKUDS/GraphGPT.", "published": "2023-10-19 06:17:46", "link": "http://arxiv.org/abs/2310.13023v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Reliable Academic Conference Question Answering: A Study Based on Large\n  Language Model", "abstract": "As the development of academic conferences fosters global scholarly\ncommunication, researchers consistently need to obtain accurate and up-to-date\ninformation about academic conferences. Since the information is scattered,\nusing an intelligent question-answering system to efficiently handle\nresearchers' queries and ensure awareness of the latest advancements is\nnecessary. Recently, Large Language Models (LLMs) have demonstrated impressive\ncapabilities in question answering, and have been enhanced by retrieving\nexternal knowledge to deal with outdated knowledge. However, these methods fail\nto work due to the lack of the latest conference knowledge. To address this\nchallenge, we develop the ConferenceQA dataset, consisting of seven diverse\nacademic conferences. Specifically, for each conference, we first organize\nacademic conference data in a tree-structured format through a semi-automated\nmethod. Then we annotate question-answer pairs and classify the pairs into four\ndifferent types to better distinguish their difficulty. With the constructed\ndataset, we further propose a novel method STAR (STructure-Aware Retrieval) to\nimprove the question-answering abilities of LLMs, leveraging inherent\nstructural information during the retrieval process. Experimental results on\nthe ConferenceQA dataset show the effectiveness of our retrieval method. The\ndataset and code are available at https://github.com/zjukg/ConferenceQA.", "published": "2023-10-19 07:39:07", "link": "http://arxiv.org/abs/2310.13028v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "From Multilingual Complexity to Emotional Clarity: Leveraging\n  Commonsense to Unveil Emotions in Code-Mixed Dialogues", "abstract": "Understanding emotions during conversation is a fundamental aspect of human\ncommunication, driving NLP research for Emotion Recognition in Conversation\n(ERC). While considerable research has focused on discerning emotions of\nindividual speakers in monolingual dialogues, understanding the emotional\ndynamics in code-mixed conversations has received relatively less attention.\nThis motivates our undertaking of ERC for code-mixed conversations in this\nstudy. Recognizing that emotional intelligence encompasses a comprehension of\nworldly knowledge, we propose an innovative approach that integrates\ncommonsense information with dialogue context to facilitate a deeper\nunderstanding of emotions. To achieve this, we devise an efficient pipeline\nthat extracts relevant commonsense from existing knowledge graphs based on the\ncode-mixed input. Subsequently, we develop an advanced fusion technique that\nseamlessly combines the acquired commonsense information with the dialogue\nrepresentation obtained from a dedicated dialogue understanding module. Our\ncomprehensive experimentation showcases the substantial performance improvement\nobtained through the systematic incorporation of commonsense in ERC. Both\nquantitative assessments and qualitative analyses further corroborate the\nvalidity of our hypothesis, reaffirming the pivotal role of commonsense\nintegration in enhancing ERC.", "published": "2023-10-19 18:17:00", "link": "http://arxiv.org/abs/2310.13080v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Better to Ask in English: Cross-Lingual Evaluation of Large Language\n  Models for Healthcare Queries", "abstract": "Large language models (LLMs) are transforming the ways the general public\naccesses and consumes information. Their influence is particularly pronounced\nin pivotal sectors like healthcare, where lay individuals are increasingly\nappropriating LLMs as conversational agents for everyday queries. While LLMs\ndemonstrate impressive language understanding and generation proficiencies,\nconcerns regarding their safety remain paramount in these high-stake domains.\nMoreover, the development of LLMs is disproportionately focused on English. It\nremains unclear how these LLMs perform in the context of non-English languages,\na gap that is critical for ensuring equity in the real-world use of these\nsystems.This paper provides a framework to investigate the effectiveness of\nLLMs as multi-lingual dialogue systems for healthcare queries. Our\nempirically-derived framework XlingEval focuses on three fundamental criteria\nfor evaluating LLM responses to naturalistic human-authored health-related\nquestions: correctness, consistency, and verifiability. Through extensive\nexperiments on four major global languages, including English, Spanish,\nChinese, and Hindi, spanning three expert-annotated large health Q&A datasets,\nand through an amalgamation of algorithmic and human-evaluation strategies, we\nfound a pronounced disparity in LLM responses across these languages,\nindicating a need for enhanced cross-lingual capabilities. We further propose\nXlingHealth, a cross-lingual benchmark for examining the multilingual\ncapabilities of LLMs in the healthcare context. Our findings underscore the\npressing need to bolster the cross-lingual capacities of these models, and to\nprovide an equitable information ecosystem accessible to all.", "published": "2023-10-19 20:02:40", "link": "http://arxiv.org/abs/2310.13132v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Breaking through Deterministic Barriers: Randomized Pruning Mask\n  Generation and Selection", "abstract": "It is widely acknowledged that large and sparse models have higher accuracy\nthan small and dense models under the same model size constraints. This\nmotivates us to train a large model and then remove its redundant neurons or\nweights by pruning. Most existing works pruned the networks in a deterministic\nway, the performance of which solely depends on a single pruning criterion and\nthus lacks variety. Instead, in this paper, we propose a model pruning strategy\nthat first generates several pruning masks in a designed random way.\nSubsequently, along with an effective mask-selection rule, the optimal mask is\nchosen from the pool of mask candidates. To further enhance efficiency, we\nintroduce an early mask evaluation strategy, mitigating the overhead associated\nwith training multiple masks. Our extensive experiments demonstrate that this\napproach achieves state-of-the-art performance across eight datasets from GLUE,\nparticularly excelling at high levels of sparsity.", "published": "2023-10-19 22:32:51", "link": "http://arxiv.org/abs/2310.13183v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Fast and Accurate Factual Inconsistency Detection Over Long Documents", "abstract": "Generative AI models exhibit remarkable potential; however, hallucinations\nacross various tasks present a significant challenge, particularly for longer\ninputs that current approaches struggle to address effectively. We introduce\nSCALE (Source Chunking Approach for Large-scale inconsistency Evaluation), a\ntask-agnostic model for detecting factual inconsistencies using a novel\nchunking strategy. Specifically, SCALE is a Natural Language Inference (NLI)\nbased model that uses large text chunks to condition over long texts. This\napproach achieves state-of-the-art performance in factual inconsistency\ndetection for diverse tasks and long inputs. Additionally, we leverage the\nchunking mechanism and employ a novel algorithm to explain SCALE's decisions\nthrough relevant source sentence retrieval. Our evaluations reveal that SCALE\noutperforms existing methods on both standard benchmarks and a new long-form\ndialogue dataset ScreenEval we constructed. Moreover, SCALE surpasses\ncompetitive systems in efficiency and model explanation evaluations. We have\nreleased our code and data publicly to GitHub.", "published": "2023-10-19 22:55:39", "link": "http://arxiv.org/abs/2310.13189v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Robust Pruning: An Adaptive Knowledge-Retention Pruning Strategy\n  for Language Models", "abstract": "The pruning objective has recently extended beyond accuracy and sparsity to\nrobustness in language models. Despite this, existing methods struggle to\nenhance robustness against adversarial attacks when continually increasing\nmodel sparsity and require a retraining process. As humans step into the era of\nlarge language models, these issues become increasingly prominent. This paper\nproposes that the robustness of language models is proportional to the extent\nof pre-trained knowledge they encompass. Accordingly, we introduce a\npost-training pruning strategy designed to faithfully replicate the embedding\nspace and feature space of dense language models, aiming to conserve more\npre-trained knowledge during the pruning process. In this setup, each layer's\nreconstruction error not only originates from itself but also includes\ncumulative error from preceding layers, followed by an adaptive rectification.\nCompared to other state-of-art baselines, our approach demonstrates a superior\nbalance between accuracy, sparsity, robustness, and pruning cost with BERT on\ndatasets SST2, IMDB, and AGNews, marking a significant stride towards robust\npruning in language models.", "published": "2023-10-19 23:02:29", "link": "http://arxiv.org/abs/2310.13191v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Know Where to Go: Make LLM a Relevant, Responsible, and Trustworthy\n  Searcher", "abstract": "The advent of Large Language Models (LLMs) has shown the potential to improve\nrelevance and provide direct answers in web searches. However, challenges arise\nin validating the reliability of generated results and the credibility of\ncontributing sources, due to the limitations of traditional information\nretrieval algorithms and the LLM hallucination problem. Aiming to create a\n\"PageRank\" for the LLM era, we strive to transform LLM into a relevant,\nresponsible, and trustworthy searcher. We propose a novel generative retrieval\nframework leveraging the knowledge of LLMs to foster a direct link between\nqueries and online sources. This framework consists of three core modules:\nGenerator, Validator, and Optimizer, each focusing on generating trustworthy\nonline sources, verifying source reliability, and refining unreliable sources,\nrespectively. Extensive experiments and evaluations highlight our method's\nsuperior relevance, responsibility, and trustfulness against various SOTA\nmethods.", "published": "2023-10-19 03:49:36", "link": "http://arxiv.org/abs/2310.12443v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Unmasking Transformers: A Theoretical Approach to Data Recovery via\n  Attention Weights", "abstract": "In the realm of deep learning, transformers have emerged as a dominant\narchitecture, particularly in natural language processing tasks. However, with\ntheir widespread adoption, concerns regarding the security and privacy of the\ndata processed by these models have arisen. In this paper, we address a pivotal\nquestion: Can the data fed into transformers be recovered using their attention\nweights and outputs? We introduce a theoretical framework to tackle this\nproblem. Specifically, we present an algorithm that aims to recover the input\ndata $X \\in \\mathbb{R}^{d \\times n}$ from given attention weights $W = QK^\\top\n\\in \\mathbb{R}^{d \\times d}$ and output $B \\in \\mathbb{R}^{n \\times n}$ by\nminimizing the loss function $L(X)$. This loss function captures the\ndiscrepancy between the expected output and the actual output of the\ntransformer. Our findings have significant implications for the Localized\nLayer-wise Mechanism (LLM), suggesting potential vulnerabilities in the model's\ndesign from a security and privacy perspective. This work underscores the\nimportance of understanding and safeguarding the internal workings of\ntransformers to ensure the confidentiality of processed data.", "published": "2023-10-19 04:41:01", "link": "http://arxiv.org/abs/2310.12462v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Exploring In-Context Learning of Textless Speech Language Model for\n  Speech Classification Tasks", "abstract": "Ever since the development of GPT-3 in the natural language processing (NLP)\nfield, in-context learning (ICL) has played an essential role in utilizing\nlarge language models (LLMs). By presenting the LM utterance-label\ndemonstrations at the input, the LM can accomplish few-shot learning without\nrelying on gradient descent or requiring explicit modification of its\nparameters. This enables the LM to perform various downstream tasks in a\nblack-box manner. Despite the success of ICL in NLP, little work is exploring\nthe possibility of ICL in speech processing. This study is the first work\nexploring ICL for speech classification tasks with textless speech LM. We first\nshow that the current speech LM lacks the ICL capability. We then perform\nwarmup training on the speech LM, equipping the LM with demonstration learning\ncapability. This paper explores and proposes the first speech LM capable of\nperforming unseen classification tasks in an ICL manner.", "published": "2023-10-19 05:31:45", "link": "http://arxiv.org/abs/2310.12477v2", "categories": ["eess.AS", "cs.AI", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Attack Prompt Generation for Red Teaming and Defending Large Language\n  Models", "abstract": "Large language models (LLMs) are susceptible to red teaming attacks, which\ncan induce LLMs to generate harmful content. Previous research constructs\nattack prompts via manual or automatic methods, which have their own\nlimitations on construction cost and quality. To address these issues, we\npropose an integrated approach that combines manual and automatic methods to\neconomically generate high-quality attack prompts. Specifically, considering\nthe impressive capabilities of newly emerged LLMs, we propose an attack\nframework to instruct LLMs to mimic human-generated prompts through in-context\nlearning. Furthermore, we propose a defense framework that fine-tunes victim\nLLMs through iterative interactions with the attack framework to enhance their\nsafety against red teaming attacks. Extensive experiments on different LLMs\nvalidate the effectiveness of our proposed attack and defense frameworks.\nAdditionally, we release a series of attack prompts datasets named SAP with\nvarying sizes, facilitating the safety evaluation and enhancement of more LLMs.\nOur code and dataset is available on https://github.com/Aatrox103/SAP .", "published": "2023-10-19 06:15:05", "link": "http://arxiv.org/abs/2310.12505v1", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ReEval: Automatic Hallucination Evaluation for Retrieval-Augmented Large\n  Language Models via Transferable Adversarial Attacks", "abstract": "Despite remarkable advancements in mitigating hallucinations in large\nlanguage models (LLMs) by retrieval augmentation, it remains challenging to\nmeasure the reliability of LLMs using static question-answering (QA) data.\nSpecifically, given the potential of data contamination (e.g., leading to\nmemorization), good static benchmark performance does not ensure that model can\nreliably use the provided evidence for responding, which is essential to avoid\nhallucination when the required knowledge is new or private. Inspired by\nadversarial machine learning, we investigate the feasibility of automatically\nperturbing existing static one for dynamic evaluation. Specifically, this paper\npresents ReEval, an LLM-based framework using prompt chaining to perturb the\noriginal evidence for generating new test cases for evaluating the LLMs'\nreliability in using new evidence for answering.\n  We implement ReEval using ChatGPT and evaluate the resulting variants of two\npopular open-domain QA datasets on a collection of LLMs under various prompting\nsettings. Our generated data is human-readable and useful to trigger\nhallucination in LLM. Accurate models on static data are observed to produce\nunsupported answers from the perturbed evidence, with pronounced accuracy drops\nacross LLMs including GPT-4. We find that our adversarial examples are\ntransferable across all considered LLMs. The examples generated by a small\nmodel can be used to evaluate a much larger model, making our approach\ncost-effective.", "published": "2023-10-19 06:37:32", "link": "http://arxiv.org/abs/2310.12516v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Large Language Model for Multi-objective Evolutionary Optimization", "abstract": "Multiobjective evolutionary algorithms (MOEAs) are major methods for solving\nmultiobjective optimization problems (MOPs). Many MOEAs have been proposed in\nthe past decades, of which the search operators need a carefully handcrafted\ndesign with domain knowledge. Recently, some attempts have been made to replace\nthe manually designed operators in MOEAs with learning-based operators (e.g.,\nneural network models). However, much effort is still required for designing\nand training such models, and the learned operators might not generalize well\non new problems. To tackle the above challenges, this work investigates a novel\napproach that leverages the powerful large language model (LLM) to design MOEA\noperators. With proper prompt engineering, we successfully let a general LLM\nserve as a black-box search operator for decomposition-based MOEA (MOEA/D) in a\nzero-shot manner. In addition, by learning from the LLM behavior, we further\ndesign an explicit white-box operator with randomness and propose a new version\nof decomposition-based MOEA, termed MOEA/D-LO. Experimental studies on\ndifferent test benchmarks show that our proposed method can achieve competitive\nperformance with widely used MOEAs. It is also promising to see the operator\nonly learned from a few instances can have robust generalization performance on\nunseen problems with quite different patterns and settings. The results reveal\nthe potential benefits of using pre-trained LLMs in the design of MOEAs.To\nfoster reproducibility and accessibility, the source code is\nhttps://github.com/FeiLiu36/LLM4MOEA.", "published": "2023-10-19 07:46:54", "link": "http://arxiv.org/abs/2310.12541v3", "categories": ["cs.NE", "cs.AI", "cs.CL", "cs.ET"], "primary_category": "cs.NE"}
{"title": "Time-Aware Representation Learning for Time-Sensitive Question Answering", "abstract": "Time is one of the crucial factors in real-world question answering (QA)\nproblems. However, language models have difficulty understanding the\nrelationships between time specifiers, such as 'after' and 'before', and\nnumbers, since existing QA datasets do not include sufficient time expressions.\nTo address this issue, we propose a Time-Context aware Question Answering\n(TCQA) framework. We suggest a Time-Context dependent Span Extraction (TCSE)\ntask, and build a time-context dependent data generation framework for model\ntraining. Moreover, we present a metric to evaluate the time awareness of the\nQA model using TCSE. The TCSE task consists of a question and four sentence\ncandidates classified as correct or incorrect based on time and context. The\nmodel is trained to extract the answer span from the sentence that is both\ncorrect in time and context. The model trained with TCQA outperforms baseline\nmodels up to 8.5 of the F1-score in the TimeQA dataset. Our dataset and code\nare available at https://github.com/sonjbin/TCQA", "published": "2023-10-19 08:48:45", "link": "http://arxiv.org/abs/2310.12585v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Survival of the Most Influential Prompts: Efficient Black-Box Prompt\n  Search via Clustering and Pruning", "abstract": "Prompt-based learning has been an effective paradigm for large pretrained\nlanguage models (LLM), enabling few-shot or even zero-shot learning. Black-box\nprompt search has received growing interest recently for its distinctive\nproperties of gradient-free optimization, proven particularly useful and\npowerful for model-as-a-service usage. However, the discrete nature and the\ncomplexity of combinatorial optimization hinder the efficiency of modern\nblack-box approaches. Despite extensive research on search algorithms, the\ncrucial aspect of search space design and optimization has been largely\noverlooked. In this paper, we first conduct a sensitivity analysis by prompting\nLLM, revealing that only a small number of tokens exert a disproportionate\namount of influence on LLM predictions. Leveraging this insight, we propose the\nClustering and Pruning for Efficient Black-box Prompt Search (ClaPS), a simple\nblack-box search method that first clusters and prunes the search space to\nfocus exclusively on influential prompt tokens. By employing even simple search\nmethods within the pruned search space, ClaPS achieves state-of-the-art\nperformance across various tasks and LLMs, surpassing the performance of\ncomplex approaches while significantly reducing search costs. Our findings\nunderscore the critical role of search space design and optimization in\nenhancing both the usefulness and the efficiency of black-box prompt-based\nlearning.", "published": "2023-10-19 14:25:06", "link": "http://arxiv.org/abs/2310.12774v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Model Merging by Uncertainty-Based Gradient Matching", "abstract": "Models trained on different datasets can be merged by a weighted-averaging of\ntheir parameters, but why does it work and when can it fail? Here, we connect\nthe inaccuracy of weighted-averaging to mismatches in the gradients and propose\na new uncertainty-based scheme to improve the performance by reducing the\nmismatch. The connection also reveals implicit assumptions in other schemes\nsuch as averaging, task arithmetic, and Fisher-weighted averaging. Our new\nmethod gives consistent improvements for large language models and vision\ntransformers, both in terms of performance and robustness to hyperparameters.\nCode available here.", "published": "2023-10-19 15:02:45", "link": "http://arxiv.org/abs/2310.12808v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Formalizing and Benchmarking Prompt Injection Attacks and Defenses", "abstract": "A prompt injection attack aims to inject malicious instruction/data into the\ninput of an LLM-Integrated Application such that it produces results as an\nattacker desires. Existing works are limited to case studies. As a result, the\nliterature lacks a systematic understanding of prompt injection attacks and\ntheir defenses. We aim to bridge the gap in this work. In particular, we\npropose a framework to formalize prompt injection attacks. Existing attacks are\nspecial cases in our framework. Moreover, based on our framework, we design a\nnew attack by combining existing ones. Using our framework, we conduct a\nsystematic evaluation on 5 prompt injection attacks and 10 defenses with 10\nLLMs and 7 tasks. Our work provides a common benchmark for quantitatively\nevaluating future prompt injection attacks and defenses. To facilitate research\non this topic, we make our platform public at\nhttps://github.com/liu00222/Open-Prompt-Injection.", "published": "2023-10-19 15:12:09", "link": "http://arxiv.org/abs/2310.12815v4", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Boosting Inference Efficiency: Unleashing the Power of Parameter-Shared\n  Pre-trained Language Models", "abstract": "Parameter-shared pre-trained language models (PLMs) have emerged as a\nsuccessful approach in resource-constrained environments, enabling substantial\nreductions in model storage and memory costs without significant performance\ncompromise. However, it is important to note that parameter sharing does not\nalleviate computational burdens associated with inference, thus impeding its\npracticality in situations characterized by limited stringent latency\nrequirements or computational resources. Building upon neural ordinary\ndifferential equations (ODEs), we introduce a straightforward technique to\nenhance the inference efficiency of parameter-shared PLMs. Additionally, we\npropose a simple pre-training technique that leads to fully or partially shared\nmodels capable of achieving even greater inference acceleration. The\nexperimental results demonstrate the effectiveness of our methods on both\nautoregressive and autoencoding PLMs, providing novel insights into more\nefficient utilization of parameter-shared models in resource-constrained\nsettings.", "published": "2023-10-19 15:13:58", "link": "http://arxiv.org/abs/2310.12818v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AgentTuning: Enabling Generalized Agent Abilities for LLMs", "abstract": "Open large language models (LLMs) with great performance in various tasks\nhave significantly advanced the development of LLMs. However, they are far\ninferior to commercial models such as ChatGPT and GPT-4 when acting as agents\nto tackle complex tasks in the real world. These agent tasks employ LLMs as the\ncentral controller responsible for planning, memorization, and tool\nutilization, necessitating both fine-grained prompting methods and robust LLMs\nto achieve satisfactory performance. Though many prompting methods have been\nproposed to complete particular agent tasks, there is lack of research focusing\non improving the agent capabilities of LLMs themselves without compromising\ntheir general abilities. In this work, we present AgentTuning, a simple and\ngeneral method to enhance the agent abilities of LLMs while maintaining their\ngeneral LLM capabilities. We construct AgentInstruct, a lightweight\ninstruction-tuning dataset containing high-quality interaction trajectories. We\nemploy a hybrid instruction-tuning strategy by combining AgentInstruct with\nopen-source instructions from general domains. AgentTuning is used to\ninstruction-tune the Llama 2 series, resulting in AgentLM. Our evaluations show\nthat AgentTuning enables LLMs' agent capabilities without compromising general\nabilities. The AgentLM-70B is comparable to GPT-3.5-turbo on unseen agent\ntasks, demonstrating generalized agent capabilities. We open source the\nAgentInstruct and AgentLM-7B, 13B, and 70B models at\nhttps://github.com/THUDM/AgentTuning, serving open and powerful alternatives to\ncommercial LLMs for agent tasks.", "published": "2023-10-19 15:19:53", "link": "http://arxiv.org/abs/2310.12823v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "EmoDiarize: Speaker Diarization and Emotion Identification from Speech\n  Signals using Convolutional Neural Networks", "abstract": "In the era of advanced artificial intelligence and human-computer\ninteraction, identifying emotions in spoken language is paramount. This\nresearch explores the integration of deep learning techniques in speech emotion\nrecognition, offering a comprehensive solution to the challenges associated\nwith speaker diarization and emotion identification. It introduces a framework\nthat combines a pre-existing speaker diarization pipeline and an emotion\nidentification model built on a Convolutional Neural Network (CNN) to achieve\nhigher precision. The proposed model was trained on data from five speech\nemotion datasets, namely, RAVDESS, CREMA-D, SAVEE, TESS, and Movie Clips, out\nof which the latter is a speech emotion dataset created specifically for this\nresearch. The features extracted from each sample include Mel Frequency\nCepstral Coefficients (MFCC), Zero Crossing Rate (ZCR), Root Mean Square (RMS),\nand various data augmentation algorithms like pitch, noise, stretch, and shift.\nThis feature extraction approach aims to enhance prediction accuracy while\nreducing computational complexity. The proposed model yields an unweighted\naccuracy of 63%, demonstrating remarkable efficiency in accurately identifying\nemotional states within speech signals.", "published": "2023-10-19 16:02:53", "link": "http://arxiv.org/abs/2310.12851v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "An Emulator for Fine-Tuning Large Language Models using Small Language\n  Models", "abstract": "Widely used language models (LMs) are typically built by scaling up a\ntwo-stage training pipeline: a pre-training stage that uses a very large,\ndiverse dataset of text and a fine-tuning (sometimes, 'alignment') stage that\nuses targeted examples or other specifications of desired behaviors. While it\nhas been hypothesized that knowledge and skills come from pre-training, and\nfine-tuning mostly filters this knowledge and skillset, this intuition has not\nbeen extensively tested. To aid in doing so, we introduce a novel technique for\ndecoupling the knowledge and skills gained in these two stages, enabling a\ndirect answer to the question, \"What would happen if we combined the knowledge\nlearned by a large model during pre-training with the knowledge learned by a\nsmall model during fine-tuning (or vice versa)?\" Using an RL-based framework\nderived from recent developments in learning from human preferences, we\nintroduce emulated fine-tuning (EFT), a principled and practical method for\nsampling from a distribution that approximates (or 'emulates') the result of\npre-training and fine-tuning at different scales. Our experiments with EFT show\nthat scaling up fine-tuning tends to improve helpfulness, while scaling up\npre-training tends to improve factuality. Beyond decoupling scale, we show that\nEFT enables test-time adjustment of competing behavioral traits like\nhelpfulness and harmlessness without additional training. Finally, a special\ncase of emulated fine-tuning, which we call LM up-scaling, avoids\nresource-intensive fine-tuning of large pre-trained models by ensembling them\nwith small fine-tuned models, essentially emulating the result of fine-tuning\nthe large pre-trained model. Up-scaling consistently improves helpfulness and\nfactuality of instruction-following models in the Llama, Llama-2, and Falcon\nfamilies, without additional hyperparameters or training.", "published": "2023-10-19 17:57:16", "link": "http://arxiv.org/abs/2310.12962v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CLAIR: Evaluating Image Captions with Large Language Models", "abstract": "The evaluation of machine-generated image captions poses an interesting yet\npersistent challenge. Effective evaluation measures must consider numerous\ndimensions of similarity, including semantic relevance, visual structure,\nobject interactions, caption diversity, and specificity. Existing\nhighly-engineered measures attempt to capture specific aspects, but fall short\nin providing a holistic score that aligns closely with human judgments. Here,\nwe propose CLAIR, a novel method that leverages the zero-shot language modeling\ncapabilities of large language models (LLMs) to evaluate candidate captions. In\nour evaluations, CLAIR demonstrates a stronger correlation with human judgments\nof caption quality compared to existing measures. Notably, on Flickr8K-Expert,\nCLAIR achieves relative correlation improvements over SPICE of 39.6% and over\nimage-augmented methods such as RefCLIP-S of 18.3%. Moreover, CLAIR provides\nnoisily interpretable results by allowing the language model to identify the\nunderlying reasoning behind its assigned score. Code is available at\nhttps://davidmchan.github.io/clair/", "published": "2023-10-19 17:59:01", "link": "http://arxiv.org/abs/2310.12971v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Frozen Transformers in Language Models Are Effective Visual Encoder\n  Layers", "abstract": "This paper reveals that large language models (LLMs), despite being trained\nsolely on textual data, are surprisingly strong encoders for purely visual\ntasks in the absence of language. Even more intriguingly, this can be achieved\nby a simple yet previously overlooked strategy -- employing a frozen\ntransformer block from pre-trained LLMs as a constituent encoder layer to\ndirectly process visual tokens. Our work pushes the boundaries of leveraging\nLLMs for computer vision tasks, significantly departing from conventional\npractices that typically necessitate a multi-modal vision-language setup with\nassociated language prompts, inputs, or outputs. We demonstrate that our\napproach consistently enhances performance across a diverse range of tasks,\nencompassing pure 2D and 3D visual recognition tasks (e.g., image and point\ncloud classification), temporal modeling tasks (e.g., action recognition),\nnon-semantic tasks (e.g., motion forecasting), and multi-modal tasks (e.g.,\n2D/3D visual question answering and image-text retrieval). Such improvements\nare a general phenomenon, applicable to various types of LLMs (e.g., LLaMA and\nOPT) and different LLM transformer blocks. We additionally propose the\ninformation filtering hypothesis to explain the effectiveness of pre-trained\nLLMs in visual encoding -- the pre-trained LLM transformer blocks discern\ninformative visual tokens and further amplify their effect. This hypothesis is\nempirically supported by the observation that the feature activation, after\ntraining with LLM transformer blocks, exhibits a stronger focus on relevant\nregions. We hope that our work inspires new perspectives on utilizing LLMs and\ndeepening our understanding of their underlying mechanisms. Code is available\nat https://github.com/ziqipang/LM4VisualEncoding.", "published": "2023-10-19 17:59:05", "link": "http://arxiv.org/abs/2310.12973v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Uncertainty-aware Parameter-Efficient Self-training for Semi-supervised\n  Language Understanding", "abstract": "The recent success of large pre-trained language models (PLMs) heavily hinges\non massive labeled data, which typically produces inferior performance in\nlow-resource scenarios. To remedy this dilemma, we study self-training as one\nof the predominant semi-supervised learning (SSL) approaches, which utilizes\nlarge-scale unlabeled data to generate synthetic examples. However, too many\nnoisy labels will hurt the model performance, and the self-training procedure\nrequires multiple training iterations making it more expensive if all the model\nparameters of the PLM are updated. This paper presents UPET, a novel\nUncertainty-aware Parameter-Efficient self-Training framework to effectively\nand efficiently address the labeled data scarcity issue. Specifically, we\nincorporate Monte Carlo (MC) dropout in Bayesian neural network (BNN) to\nperform uncertainty estimation for the teacher model and then judiciously\nselect reliable pseudo-labeled examples based on confidence and certainty.\nDuring the student training, we introduce multiple parameter-efficient learning\n(PEL) paradigms that allow the optimization of only a small percentage of\nparameters. We also propose a novel Easy-Hard Contrastive Tuning to enhance the\nrobustness and generalization. Extensive experiments over multiple downstream\ntasks demonstrate that UPET achieves a substantial improvement in terms of\nperformance and efficiency. Our codes and data are released at https:\n//github.com/wjn1996/UPET.", "published": "2023-10-19 02:18:29", "link": "http://arxiv.org/abs/2310.13022v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Towards Anytime Fine-tuning: Continually Pre-trained Language Models\n  with Hypernetwork Prompt", "abstract": "Continual pre-training has been urgent for adapting a pre-trained model to a\nmultitude of domains and tasks in the fast-evolving world. In practice, a\ncontinually pre-trained model is expected to demonstrate not only greater\ncapacity when fine-tuned on pre-trained domains but also a non-decreasing\nperformance on unseen ones. In this work, we first investigate such anytime\nfine-tuning effectiveness of existing continual pre-training approaches,\nconcluding with unanimously decreased performance on unseen domains. To this\nend, we propose a prompt-guided continual pre-training method, where we train a\nhypernetwork to generate domain-specific prompts by both agreement and\ndisagreement losses. The agreement loss maximally preserves the generalization\nof a pre-trained model to new domains, and the disagreement one guards the\nexclusiveness of the generated hidden states for each domain. Remarkably,\nprompts by the hypernetwork alleviate the domain identity when fine-tuning and\npromote knowledge transfer across domains. Our method achieved improvements of\n3.57% and 3.4% on two real-world datasets (including domain shift and temporal\nshift), respectively, demonstrating its efficacy.", "published": "2023-10-19 06:34:40", "link": "http://arxiv.org/abs/2310.13024v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Use Case: Reformulating Query Rewriting as a Statistical Machine\n  Translation Problem", "abstract": "One of the most important challenges for modern search engines is to retrieve\nrelevant web content based on user queries. In order to achieve this challenge,\nsearch engines have a module to rewrite user queries. That is why modern web\nsearch engines utilize some statistical and neural models used in the natural\nlanguage processing domain. Statistical machine translation is a well-known NLP\nmethod among them. The paper proposes a query rewriting pipeline based on a\nmonolingual machine translation model that learns to rewrite Arabic user search\nqueries. This paper also describes preprocessing steps to create a mapping\nbetween user queries and web page titles.", "published": "2023-10-19 11:37:14", "link": "http://arxiv.org/abs/2310.13031v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Quality-Diversity through AI Feedback", "abstract": "In many text-generation problems, users may prefer not only a single\nresponse, but a diverse range of high-quality outputs from which to choose.\nQuality-diversity (QD) search algorithms aim at such outcomes, by continually\nimproving and diversifying a population of candidates. However, the\napplicability of QD to qualitative domains, like creative writing, has been\nlimited by the difficulty of algorithmically specifying measures of quality and\ndiversity. Interestingly, recent developments in language models (LMs) have\nenabled guiding search through AI feedback, wherein LMs are prompted in natural\nlanguage to evaluate qualitative aspects of text. Leveraging this development,\nwe introduce Quality-Diversity through AI Feedback (QDAIF), wherein an\nevolutionary algorithm applies LMs to both generate variation and evaluate the\nquality and diversity of candidate text. When assessed on creative writing\ndomains, QDAIF covers more of a specified search space with high-quality\nsamples than do non-QD controls. Further, human evaluation of QDAIF-generated\ncreative texts validates reasonable agreement between AI and human evaluation.\nOur results thus highlight the potential of AI feedback to guide open-ended\nsearch for creative and original solutions, providing a recipe that seemingly\ngeneralizes to many domains and modalities. In this way, QDAIF is a step\ntowards AI systems that can independently search, diversify, evaluate, and\nimprove, which are among the core skills underlying human society's capacity\nfor innovation.", "published": "2023-10-19 12:13:58", "link": "http://arxiv.org/abs/2310.13032v4", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "No offence, Bert -- I insult only humans! Multiple addressees\n  sentence-level attack on toxicity detection neural network", "abstract": "We introduce a simple yet efficient sentence-level attack on black-box\ntoxicity detector models. By adding several positive words or sentences to the\nend of a hateful message, we are able to change the prediction of a neural\nnetwork and pass the toxicity detection system check. This approach is shown to\nbe working on seven languages from three different language families. We also\ndescribe the defence mechanism against the aforementioned attack and discuss\nits limitations.", "published": "2023-10-19 18:56:50", "link": "http://arxiv.org/abs/2310.13099v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "NameGuess: Column Name Expansion for Tabular Data", "abstract": "Recent advances in large language models have revolutionized many sectors,\nincluding the database industry. One common challenge when dealing with large\nvolumes of tabular data is the pervasive use of abbreviated column names, which\ncan negatively impact performance on various data search, access, and\nunderstanding tasks. To address this issue, we introduce a new task, called\nNameGuess, to expand column names (used in database schema) as a natural\nlanguage generation problem. We create a training dataset of 384K\nabbreviated-expanded column pairs using a new data fabrication method and a\nhuman-annotated evaluation benchmark that includes 9.2K examples from\nreal-world tables. To tackle the complexities associated with polysemy and\nambiguity in NameGuess, we enhance auto-regressive language models by\nconditioning on table content and column header names -- yielding a fine-tuned\nmodel (with 2.7B parameters) that matches human performance. Furthermore, we\nconduct a comprehensive analysis (on multiple LLMs) to validate the\neffectiveness of table content in NameGuess and identify promising future\nopportunities. Code has been made available at\nhttps://github.com/amazon-science/nameguess.", "published": "2023-10-19 23:11:37", "link": "http://arxiv.org/abs/2310.13196v1", "categories": ["cs.CL", "cs.DB", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Proceedings of the 3rd International Workshop on Mining and Learning in\n  the Legal Domain (MLLD-23)", "abstract": "This is the Proceedings of the 3rd International Workshop on Mining and\nLearning in the Legal Domain (MLLD-23) which took place in conjunction with the\n32nd ACM International Conference on Information and Knowledge Management\n(CIKM-2023) at the University of Birmingham, Birmingham, UK on Sunday 22nd\nOctober 2023.", "published": "2023-10-19 16:49:11", "link": "http://arxiv.org/abs/2311.10733v1", "categories": ["cs.CY", "cs.CL", "cs.IR"], "primary_category": "cs.CY"}
{"title": "Loop Copilot: Conducting AI Ensembles for Music Generation and Iterative\n  Editing", "abstract": "Creating music is iterative, requiring varied methods at each stage. However,\nexisting AI music systems fall short in orchestrating multiple subsystems for\ndiverse needs. To address this gap, we introduce Loop Copilot, a novel system\nthat enables users to generate and iteratively refine music through an\ninteractive, multi-round dialogue interface. The system uses a large language\nmodel to interpret user intentions and select appropriate AI models for task\nexecution. Each backend model is specialized for a specific task, and their\noutputs are aggregated to meet the user's requirements. To ensure musical\ncoherence, essential attributes are maintained in a centralized table. We\nevaluate the effectiveness of the proposed system through semi-structured\ninterviews and questionnaires, highlighting its utility not only in\nfacilitating music creation but also its potential for broader applications.", "published": "2023-10-19 01:20:12", "link": "http://arxiv.org/abs/2310.12404v2", "categories": ["cs.SD", "cs.CL", "cs.HC", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Powerset multi-class cross entropy loss for neural speaker diarization", "abstract": "Since its introduction in 2019, the whole end-to-end neural diarization\n(EEND) line of work has been addressing speaker diarization as a frame-wise\nmulti-label classification problem with permutation-invariant training. Despite\nEEND showing great promise, a few recent works took a step back and studied the\npossible combination of (local) supervised EEND diarization with (global)\nunsupervised clustering. Yet, these hybrid contributions did not question the\noriginal multi-label formulation. We propose to switch from multi-label (where\nany two speakers can be active at the same time) to powerset multi-class\nclassification (where dedicated classes are assigned to pairs of overlapping\nspeakers). Through extensive experiments on 9 different benchmarks, we show\nthat this formulation leads to significantly better performance (mostly on\noverlapping speech) and robustness to domain mismatch, while eliminating the\ndetection threshold hyperparameter, critical for the multi-label formulation.", "published": "2023-10-19 06:51:43", "link": "http://arxiv.org/abs/2310.13025v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.NE", "eess.AS"], "primary_category": "cs.SD"}
{"title": "CLIFT: Analysing Natural Distribution Shift on Question Answering Models\n  in Clinical Domain", "abstract": "This paper introduces a new testbed CLIFT (Clinical Shift) for the clinical\ndomain Question-answering task. The testbed includes 7.5k high-quality question\nanswering samples to provide a diverse and reliable benchmark. We performed a\ncomprehensive experimental study and evaluated several QA deep-learning models\nunder the proposed testbed. Despite impressive results on the original test\nset, the performance degrades when applied to new test sets, which shows the\ndistribution shift. Our findings emphasize the need for and the potential for\nincreasing the robustness of clinical domain models under distributional\nshifts. The testbed offers one way to track progress in that direction. It also\nhighlights the necessity of adopting evaluation metrics that consider\nrobustness to natural distribution shifts. We plan to expand the corpus by\nadding more samples and model results. The full paper and the updated benchmark\nare available at github.com/openlifescience-ai/clift", "published": "2023-10-19 20:43:11", "link": "http://arxiv.org/abs/2310.13146v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.DC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On Feature Importance and Interpretability of Speaker Representations", "abstract": "Unsupervised speech disentanglement aims at separating fast varying from\nslowly varying components of a speech signal. In this contribution, we take a\ncloser look at the embedding vector representing the slowly varying signal\ncomponents, commonly named the speaker embedding vector. We ask, which\nproperties of a speaker's voice are captured and investigate to which extent do\nindividual embedding vector components sign responsible for them, using the\nconcept of Shapley values. Our findings show that certain speaker-specific\nacoustic-phonetic properties can be fairly well predicted from the speaker\nembedding, while the investigated more abstract voice quality features cannot.", "published": "2023-10-19 09:10:53", "link": "http://arxiv.org/abs/2310.12599v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Deep Beamforming for Speech Enhancement and Speaker Localization with an\n  Array Response-Aware Loss Function", "abstract": "Recent research advances in deep neural network (DNN)-based beamformers have\nshown great promise for speech enhancement under adverse acoustic conditions.\nDifferent network architectures and input features have been explored in\nestimating beamforming weights. In this paper, we propose a deep beamformer\nbased on an efficient convolutional recurrent network (CRN) trained with a\nnovel ARray RespOnse-aWare (ARROW) loss function. The ARROW loss exploits the\narray responses of the target and interferer by using the ground truth relative\ntransfer functions (RTFs). The DNN-based beamforming system, trained with ARROW\nloss through supervised learning, is able to perform speech enhancement and\nspeaker localization jointly. Experimental results have shown that the proposed\ndeep beamformer, trained with the linearly weighted scale-invariant\nsource-to-noise ratio (SI-SNR) and ARROW loss functions, achieves superior\nperformance in speech enhancement and speaker localization compared to two\nbaselines.", "published": "2023-10-19 15:40:42", "link": "http://arxiv.org/abs/2310.12837v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "A New Time Series Similarity Measure and Its Smart Grid Applications", "abstract": "Many smart grid applications involve data mining, clustering, classification,\nidentification, and anomaly detection, among others. These applications\nprimarily depend on the measurement of similarity, which is the distance\nbetween different time series or subsequences of a time series. The commonly\nused time series distance measures, namely Euclidean Distance (ED) and Dynamic\nTime Warping (DTW), do not quantify the flexible nature of electricity usage\ndata in terms of temporal dynamics. As a result, there is a need for a new\ndistance measure that can quantify both the amplitude and temporal changes of\nelectricity time series for smart grid applications, e.g., demand response and\nload profiling. This paper introduces a novel distance measure to compare\nelectricity usage patterns. The method consists of two phases that quantify the\neffort required to reshape one time series into another, considering both\namplitude and temporal changes. The proposed method is evaluated against ED and\nDTW using real-world data in three smart grid applications. Overall, the\nproposed measure outperforms ED and DTW in accurately identifying the best load\nscheduling strategy, anomalous days with irregular electricity usage, and\ndetermining electricity users' behind-the-meter (BTM) equipment.", "published": "2023-10-19 01:02:47", "link": "http://arxiv.org/abs/2310.12399v1", "categories": ["eess.SP", "eess.AS"], "primary_category": "eess.SP"}
{"title": "Energy-Based Models For Speech Synthesis", "abstract": "Recently there has been a lot of interest in non-autoregressive (non-AR)\nmodels for speech synthesis, such as FastSpeech 2 and diffusion models. Unlike\nAR models, these models do not have autoregressive dependencies among outputs\nwhich makes inference efficient. This paper expands the range of available\nnon-AR models with another member called energy-based models (EBMs). The paper\ndescribes how noise contrastive estimation, which relies on the comparison\nbetween positive and negative samples, can be used to train EBMs. It proposes a\nnumber of strategies for generating effective negative samples, including using\nhigh-performing AR models. It also describes how sampling from EBMs can be\nperformed using Langevin Markov Chain Monte-Carlo (MCMC). The use of Langevin\nMCMC enables to draw connections between EBMs and currently popular diffusion\nmodels. Experiments on LJSpeech dataset show that the proposed approach offers\nimprovements over Tacotron 2.", "published": "2023-10-19 14:10:09", "link": "http://arxiv.org/abs/2310.12765v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Audio Editing with Non-Rigid Text Prompts", "abstract": "In this paper, we explore audio-editing with non-rigid text edits. We show\nthat the proposed editing pipeline is able to create audio edits that remain\nfaithful to the input audio. We explore text prompts that perform addition,\nstyle transfer, and in-painting. We quantitatively and qualitatively show that\nthe edits are able to obtain results which outperform Audio-LDM, a recently\nreleased text-prompted audio generation model. Qualitative inspection of the\nresults points out that the edits given by our approach remain more faithful to\nthe input audio in terms of keeping the original onsets and offsets of the\naudio events.", "published": "2023-10-19 16:09:44", "link": "http://arxiv.org/abs/2310.12858v3", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Uncertainty Quantification of Bandgaps in Acoustic Metamaterials with\n  Stochastic Geometric Defects and Material Properties", "abstract": "This paper studies the utility of techniques within uncertainty\nquantification, namely spectral projection and polynomial chaos expansion, in\nreducing sampling needs for characterizing acoustic metamaterial dispersion\nband responses given stochastic material properties and geometric defects. A\nnovel method of encoding geometric defects in an interpretable, resolution\nindependent is showcased in the formation of input space probability\ndistributions. Orders of magnitude sampling reductions down to $\\sim10^0$ and\n$\\sim10^1$ are achieved in the 1D and 7D input space scenarios respectively\nwhile maintaining accurate output space probability distributions through\ncombining Monte Carlo, quadrature rule, and sparse grid sampling with surrogate\nmodel fitting.", "published": "2023-10-19 16:18:10", "link": "http://arxiv.org/abs/2310.12869v1", "categories": ["cs.SD", "eess.AS", "physics.app-ph", "physics.data-an"], "primary_category": "cs.SD"}
{"title": "AVTENet: Audio-Visual Transformer-based Ensemble Network Exploiting\n  Multiple Experts for Video Deepfake Detection", "abstract": "Forged content shared widely on social media platforms is a major social\nproblem that requires increased regulation and poses new challenges to the\nresearch community. The recent proliferation of hyper-realistic deepfake videos\nhas drawn attention to the threat of audio and visual forgeries. Most previous\nwork on detecting AI-generated fake videos only utilizes visual modality or\naudio modality. While there are some methods in the literature that exploit\naudio and visual modalities to detect forged videos, they have not been\ncomprehensively evaluated on multi-modal datasets of deepfake videos involving\nacoustic and visual manipulations. Moreover, these existing methods are mostly\nbased on CNN and suffer from low detection accuracy. Inspired by the recent\nsuccess of Transformer in various fields, to address the challenges posed by\ndeepfake technology, in this paper, we propose an Audio-Visual\nTransformer-based Ensemble Network (AVTENet) framework that considers both\nacoustic manipulation and visual manipulation to achieve effective video\nforgery detection. Specifically, the proposed model integrates several purely\ntransformer-based variants that capture video, audio, and audio-visual salient\ncues to reach a consensus in prediction. For evaluation, we use the recently\nreleased benchmark multi-modal audio-video FakeAVCeleb dataset. For a detailed\nanalysis, we evaluate AVTENet, its variants, and several existing methods on\nmultiple test sets of the FakeAVCeleb dataset. Experimental results show that\nour best model outperforms all existing methods and achieves state-of-the-art\nperformance on Testset-I and Testset-II of the FakeAVCeleb dataset.", "published": "2023-10-19 19:01:26", "link": "http://arxiv.org/abs/2310.13103v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
