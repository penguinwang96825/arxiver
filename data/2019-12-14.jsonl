{"title": "Towards Robust Toxic Content Classification", "abstract": "Toxic content detection aims to identify content that can offend or harm its\nrecipients. Automated classifiers of toxic content need to be robust against\nadversaries who deliberately try to bypass filters. We propose a method of\ngenerating realistic model-agnostic attacks using a lexicon of toxic tokens,\nwhich attempts to mislead toxicity classifiers by diluting the toxicity signal\neither by obfuscating toxic tokens through character-level perturbations, or by\ninjecting non-toxic distractor tokens. We show that these realistic attacks\nreduce the detection recall of state-of-the-art neural toxicity detectors,\nincluding those using ELMo and BERT, by more than 50% in some cases. We explore\ntwo approaches for defending against such attacks. First, we examine the effect\nof training on synthetically noised data. Second, we propose the Contextual\nDenoising Autoencoder (CDAE): a method for learning robust representations that\nuses character-level and contextual information to denoise perturbed tokens. We\nshow that the two approaches are complementary, improving robustness to both\ncharacter-level perturbations and distractors, recovering a considerable\nportion of the lost accuracy. Finally, we analyze the robustness\ncharacteristics of the most competitive methods and outline practical\nconsiderations for improving toxicity detectors.", "published": "2019-12-14 16:03:15", "link": "http://arxiv.org/abs/1912.06872v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Convolutional Neural Networks for Diacritic Restoration", "abstract": "Diacritic restoration has gained importance with the growing need for\nmachines to understand written texts. The task is typically modeled as a\nsequence labeling problem and currently Bidirectional Long Short Term Memory\n(BiLSTM) models provide state-of-the-art results. Recently, Bai et al. (2018)\nshow the advantages of Temporal Convolutional Neural Networks (TCN) over\nRecurrent Neural Networks (RNN) for sequence modeling in terms of performance\nand computational resources. As diacritic restoration benefits from both\nprevious as well as subsequent timesteps, we further apply and evaluate a\nvariant of TCN, Acausal TCN (A-TCN), which incorporates context from both\ndirections (previous and future) rather than strictly incorporating previous\ncontext as in the case of TCN. A-TCN yields significant improvement over TCN\nfor diacritization in three different languages: Arabic, Yoruba, and\nVietnamese. Furthermore, A-TCN and BiLSTM have comparable performance, making\nA-TCN an efficient alternative over BiLSTM since convolutions can be trained in\nparallel. A-TCN is significantly faster than BiLSTM at inference time\n(270%-334% improvement in the amount of text diacritized per minute).", "published": "2019-12-14 18:28:02", "link": "http://arxiv.org/abs/1912.06900v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Long-length Legal Document Classification", "abstract": "One of the principal tasks of machine learning with major applications is\ntext classification. This paper focuses on the legal domain and, in particular,\non the classification of lengthy legal documents. The main challenge that this\nstudy addresses is the limitation that current models impose on the length of\nthe input text. In addition, the present paper shows that dividing the text\ninto segments and later combining the resulting embeddings with a BiLSTM\narchitecture to form a single document embedding can improve results. These\nadvancements are achieved by utilising a simpler structure, rather than an\nincreasingly complex one, which is often the case in NLP research. The dataset\nused in this paper is obtained from an online public database containing\nlengthy legal documents with highly domain-specific vocabulary and thus, the\ncomparison of our results to the ones produced by models implemented on the\ncommonly used datasets would be unjustified. This work provides the foundation\nfor future work in document classification in the legal field.", "published": "2019-12-14 19:13:44", "link": "http://arxiv.org/abs/1912.06905v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge forest: a novel model to organize knowledge fragments", "abstract": "With the rapid growth of knowledge, it shows a steady trend of knowledge\nfragmentization. Knowledge fragmentization manifests as that the knowledge\nrelated to a specific topic in a course is scattered in isolated and autonomous\nknowledge sources. We term the knowledge of a facet in a specific topic as a\nknowledge fragment. The problem of knowledge fragmentization brings two\nchallenges: First, knowledge is scattered in various knowledge sources, which\nexerts users' considerable efforts to search for the knowledge of their\ninterested topics, thereby leading to information overload. Second, learning\ndependencies which refer to the precedence relationships between topics in the\nlearning process are concealed by the isolation and autonomy of knowledge\nsources, thus causing learning disorientation. To solve the knowledge\nfragmentization problem, we propose a novel knowledge organization model,\nknowledge forest, which consists of facet trees and learning dependencies.\nFacet trees can organize knowledge fragments with facet hyponymy to alleviate\ninformation overload. Learning dependencies can organize disordered topics to\ncope with learning disorientation. We conduct extensive experiments on three\nmanually constructed datasets from the Data Structure, Data Mining, and\nComputer Network courses, and the experimental results show that knowledge\nforest can effectively organize knowledge fragments, and alleviate information\noverload and learning disorientation.", "published": "2019-12-14 11:02:17", "link": "http://arxiv.org/abs/1912.06825v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "LScDC-new large scientific dictionary", "abstract": "In this paper, we present a scientific corpus of abstracts of academic papers\nin English -- Leicester Scientific Corpus (LSC). The LSC contains 1,673,824\nabstracts of research articles and proceeding papers indexed by Web of Science\n(WoS) in which publication year is 2014. Each abstract is assigned to at least\none of 252 subject categories. Paper metadata include these categories and the\nnumber of citations. We then develop scientific dictionaries named Leicester\nScientific Dictionary (LScD) and Leicester Scientific Dictionary-Core (LScDC),\nwhere words are extracted from the LSC. The LScD is a list of 974,238 unique\nwords (lemmas). The LScDC is a core list (sub-list) of the LScD with 104,223\nlemmas. It was created by removing LScD words appearing in not greater than 10\ntexts in the LSC. LScD and LScDC are available online. Both the corpus and\ndictionaries are developed to be later used for quantification of meaning in\nacademic texts.\n  Finally, the core list LScDC was analysed by comparing its words and word\nfrequencies with a classic academic word list 'New Academic Word List (NAWL)'\ncontaining 963 word families, which is also sampled from an academic corpus.\nThe major sources of the corpus where NAWL is extracted are Cambridge English\nCorpus (CEC), oral sources and textbooks. We investigate whether two\ndictionaries are similar in terms of common words and ranking of words. Our\ncomparison leads us to main conclusion: most of words of NAWL (99.6%) are\npresent in the LScDC but two lists differ in word ranking. This difference is\nmeasured.", "published": "2019-12-14 14:55:59", "link": "http://arxiv.org/abs/1912.06858v1", "categories": ["cs.CL", "cs.DL"], "primary_category": "cs.CL"}
{"title": "Knowledge-based Conversational Search", "abstract": "Conversational interfaces that allow for intuitive and comprehensive access\nto digitally stored information remain an ambitious goal. In this thesis, we\nlay foundations for designing conversational search systems by analyzing the\nrequirements and proposing concrete solutions for automating some of the basic\ncomponents and tasks that such systems should support. We describe several\ninterdependent studies that were conducted to analyse the design requirements\nfor more advanced conversational search systems able to support complex\nhuman-like dialogue interactions and provide access to vast knowledge\nrepositories. In the first two research chapters, we focus on analyzing the\nstructures common to information-seeking dialogues by capturing recurrent\npatterns in terms of both domain-independent functional relations between\nutterances as well as domain-specific implicit semantic relations from shared\nbackground knowledge.\n  Our results show that question answering is one of the key components\nrequired for efficient information access but it is not the only type of\ndialogue interactions that a conversational search system should support. In\nthe third research chapter, we propose a novel approach for complex question\nanswering from a knowledge graph that surpasses the current state-of-the-art\nresults in terms of both efficacy and efficiency. In the last research chapter,\nwe turn our attention towards an alternative interaction mode, which we termed\nconversational browsing, in which, unlike question answering, the\nconversational system plays a more pro-active role in the course of a dialogue\ninteraction. We show that this approach helps users to discover relevant items\nthat are difficult to retrieve using only question answering due to the\nvocabulary mismatch problem.", "published": "2019-12-14 14:59:38", "link": "http://arxiv.org/abs/1912.06859v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Integrating Lexical Knowledge in Word Embeddings using Sprinkling and\n  Retrofitting", "abstract": "Neural network based word embeddings, such as Word2Vec and GloVe, are purely\ndata driven in that they capture the distributional information about words\nfrom the training corpus. Past works have attempted to improve these embeddings\nby incorporating semantic knowledge from lexical resources like WordNet. Some\ntechniques like retrofitting modify word embeddings in the post-processing\nstage while some others use a joint learning approach by modifying the\nobjective function of neural networks. In this paper, we discuss two novel\napproaches for incorporating semantic knowledge into word embeddings. In the\nfirst approach, we take advantage of Levy et al's work which showed that using\nSVD based methods on co-occurrence matrix provide similar performance to neural\nnetwork based embeddings. We propose a 'sprinkling' technique to add semantic\nrelations to the co-occurrence matrix directly before factorization. In the\nsecond approach, WordNet similarity scores are used to improve the retrofitting\nmethod. We evaluate the proposed methods in both intrinsic and extrinsic tasks\nand observe significant improvements over the baselines in many of the\ndatasets.", "published": "2019-12-14 17:38:46", "link": "http://arxiv.org/abs/1912.06889v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "#MeTooMA: Multi-Aspect Annotations of Tweets Related to the MeToo\n  Movement", "abstract": "In this paper, we present a dataset containing 9,973 tweets related to the\nMeToo movement that were manually annotated for five different linguistic\naspects: relevance, stance, hate speech, sarcasm, and dialogue acts. We present\na detailed account of the data collection and annotation processes. The\nannotations have a very high inter-annotator agreement (0.79 to 0.93 k-alpha)\ndue to the domain expertise of the annotators and clear annotation\ninstructions. We analyze the data in terms of geographical distribution, label\ncorrelations, and keywords. Lastly, we present some potential use cases of this\ndataset. We expect this dataset would be of great interest to psycholinguists,\nsocio-linguists, and computational linguists to study the discursive space of\ndigitally mobilized social movements on sensitive issues like sexual\nharassment.", "published": "2019-12-14 20:57:29", "link": "http://arxiv.org/abs/1912.06927v2", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "BERTQA -- Attention on Steroids", "abstract": "In this work, we extend the Bidirectional Encoder Representations from\nTransformers (BERT) with an emphasis on directed coattention to obtain an\nimproved F1 performance on the SQUAD2.0 dataset. The Transformer architecture\non which BERT is based places hierarchical global attention on the\nconcatenation of the context and query. Our additions to the BERT architecture\naugment this attention with a more focused context to query (C2Q) and query to\ncontext (Q2C) attention via a set of modified Transformer encoder units. In\naddition, we explore adding convolution-based feature extraction within the\ncoattention architecture to add localized information to self-attention. We\nfound that coattention significantly improves the no answer F1 by 4 points in\nthe base and 1 point in the large architecture. After adding skip connections\nthe no answer F1 improved further without causing an additional loss in has\nanswer F1. The addition of localized feature extraction added to attention\nproduced an overall dev F1 of 77.03 in the base architecture. We applied our\nfindings to the large BERT model which contains twice as many layers and\nfurther used our own augmented version of the SQUAD 2.0 dataset created by back\ntranslation, which we have named SQUAD 2.Q. Finally, we performed\nhyperparameter tuning and ensembled our best models for a final F1/EM of\n82.317/79.442 (Attention on Steroids, PCE Test Leaderboard).", "published": "2019-12-14 06:44:12", "link": "http://arxiv.org/abs/1912.10435v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SemEval-2013 Task 2: Sentiment Analysis in Twitter", "abstract": "In recent years, sentiment analysis in social media has attracted a lot of\nresearch interest and has been used for a number of applications.\nUnfortunately, research has been hindered by the lack of suitable datasets,\ncomplicating the comparison between approaches. To address this issue, we have\nproposed SemEval-2013 Task 2: Sentiment Analysis in Twitter, which included two\nsubtasks: A, an expression-level subtask, and B, a message-level subtask. We\nused crowdsourcing on Amazon Mechanical Turk to label a large Twitter training\ndataset along with additional test sets of Twitter and SMS messages for both\nsubtasks. All datasets used in the evaluation are released to the research\ncommunity. The task attracted significant interest and a total of 149\nsubmissions from 44 teams. The best-performing team achieved an F1 of 88.9% and\n69% for subtasks A and B, respectively.", "published": "2019-12-14 08:44:18", "link": "http://arxiv.org/abs/1912.06806v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Proppy: A System to Unmask Propaganda in Online News", "abstract": "We present proppy, the first publicly available real-world, real-time\npropaganda detection system for online news, which aims at raising awareness,\nthus potentially limiting the impact of propaganda and helping fight\ndisinformation. The system constantly monitors a number of news sources,\ndeduplicates and clusters the news into events, and organizes the articles\nabout an event on the basis of the likelihood that they contain propagandistic\ncontent. The system is trained on known propaganda sources using a variety of\nstylistic features. The evaluation results on a standard dataset show\nstate-of-the-art results for propaganda detection.", "published": "2019-12-14 08:58:01", "link": "http://arxiv.org/abs/1912.06810v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Voice Transformer Network: Sequence-to-Sequence Voice Conversion Using\n  Transformer with Text-to-Speech Pretraining", "abstract": "We introduce a novel sequence-to-sequence (seq2seq) voice conversion (VC)\nmodel based on the Transformer architecture with text-to-speech (TTS)\npretraining. Seq2seq VC models are attractive owing to their ability to convert\nprosody. While seq2seq models based on recurrent neural networks (RNNs) and\nconvolutional neural networks (CNNs) have been successfully applied to VC, the\nuse of the Transformer network, which has shown promising results in various\nspeech processing tasks, has not yet been investigated. Nonetheless, their\ndata-hungry property and the mispronunciation of converted speech make seq2seq\nmodels far from practical. To this end, we propose a simple yet effective\npretraining technique to transfer knowledge from learned TTS models, which\nbenefit from large-scale, easily accessible TTS corpora. VC models initialized\nwith such pretrained model parameters are able to generate effective hidden\nrepresentations for high-fidelity, highly intelligible converted speech.\nExperimental results show that such a pretraining scheme can facilitate\ndata-efficient training and outperform an RNN-based seq2seq VC model in terms\nof intelligibility, naturalness, and similarity.", "published": "2019-12-14 09:30:52", "link": "http://arxiv.org/abs/1912.06813v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A Context-Aware Approach for Detecting Check-Worthy Claims in Political\n  Debates", "abstract": "In the context of investigative journalism, we address the problem of\nautomatically identifying which claims in a given document are most worthy and\nshould be prioritized for fact-checking. Despite its importance, this is a\nrelatively understudied problem. Thus, we create a new dataset of political\ndebates, containing statements that have been fact-checked by nine reputable\nsources, and we train machine learning models to predict which claims should be\nprioritized for fact-checking, i.e., we model the problem as a ranking task.\nUnlike previous work, which has looked primarily at sentences in isolation, in\nthis paper we focus on a rich input representation modeling the context:\nrelationship between the target statement and the larger context of the debate,\ninteraction between the opponents, and reaction by the moderator and by the\npublic. Our experiments show state-of-the-art results, outperforming a strong\nrivaling system by a margin, while also confirming the importance of the\ncontextual information.", "published": "2019-12-14 10:29:13", "link": "http://arxiv.org/abs/1912.08084v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Environmental Sound Classification with Parallel Temporal-spectral\n  Attention", "abstract": "Convolutional neural networks (CNN) are one of the best-performing neural\nnetwork architectures for environmental sound classification (ESC). Recently,\ntemporal attention mechanisms have been used in CNN to capture the useful\ninformation from the relevant time frames for audio classification, especially\nfor weakly labelled data where the onset and offset times of the sound events\nare not applied. In these methods, however, the inherent spectral\ncharacteristics and variations are not explicitly exploited when obtaining the\ndeep features. In this paper, we propose a novel parallel temporal-spectral\nattention mechanism for CNN to learn discriminative sound representations,\nwhich enhances the temporal and spectral features by capturing the importance\nof different time frames and frequency bands. Parallel branches are constructed\nto allow temporal attention and spectral attention to be applied respectively\nin order to mitigate interference from the segments without the presence of\nsound events. The experiments on three environmental sound classification (ESC)\ndatasets and two acoustic scene classification (ASC) datasets show that our\nmethod improves the classification performance and also exhibits robustness to\nnoise.", "published": "2019-12-14 08:48:15", "link": "http://arxiv.org/abs/1912.06808v3", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Personalization of End-to-end Speech Recognition On Mobile Devices For\n  Named Entities", "abstract": "We study the effectiveness of several techniques to personalize end-to-end\nspeech models and improve the recognition of proper names relevant to the user.\nThese techniques differ in the amounts of user effort required to provide\nsupervision, and are evaluated on how they impact speech recognition\nperformance. We propose using keyword-dependent precision and recall metrics to\nmeasure vocabulary acquisition performance. We evaluate the algorithms on a\ndataset that we designed to contain names of persons that are difficult to\nrecognize. Therefore, the baseline recall rate for proper names in this dataset\nis very low: 2.4%. A data synthesis approach we developed brings it to 48.6%,\nwith no need for speech input from the user. With speech input, if the user\ncorrects only the names, the name recall rate improves to 64.4%. If the user\ncorrects all the recognition errors, we achieve the best recall of 73.5%. To\neliminate the need to upload user data and store personalized models on a\nserver, we focus on performing the entire personalization workflow on a mobile\ndevice.", "published": "2019-12-14 21:18:53", "link": "http://arxiv.org/abs/1912.09251v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
