{"title": "Leap-LSTM: Enhancing Long Short-Term Memory for Text Categorization", "abstract": "Recurrent Neural Networks (RNNs) are widely used in the field of natural\nlanguage processing (NLP), ranging from text categorization to question\nanswering and machine translation. However, RNNs generally read the whole text\nfrom beginning to end or vice versa sometimes, which makes it inefficient to\nprocess long texts. When reading a long document for a categorization task,\nsuch as topic categorization, large quantities of words are irrelevant and can\nbe skipped. To this end, we propose Leap-LSTM, an LSTM-enhanced model which\ndynamically leaps between words while reading texts. At each step, we utilize\nseveral feature encoders to extract messages from preceding texts, following\ntexts and the current word, and then determine whether to skip the current\nword. We evaluate Leap-LSTM on several text categorization tasks: sentiment\nanalysis, news categorization, ontology classification and topic\nclassification, with five benchmark data sets. The experimental results show\nthat our model reads faster and predicts better than standard LSTM. Compared to\nprevious models which can also skip words, our model achieves better trade-offs\nbetween performance and efficiency.", "published": "2019-05-28 01:15:11", "link": "http://arxiv.org/abs/1905.11558v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DSReg: Using Distant Supervision as a Regularizer", "abstract": "In this paper, we aim at tackling a general issue in NLP tasks where some of\nthe negative examples are highly similar to the positive examples, i.e.,\nhard-negative examples. We propose the distant supervision as a regularizer\n(DSReg) approach to tackle this issue. The original task is converted to a\nmulti-task learning problem, in which distant supervision is used to retrieve\nhard-negative examples. The obtained hard-negative examples are then used as a\nregularizer. The original target objective of distinguishing positive examples\nfrom negative examples is jointly optimized with the auxiliary task objective\nof distinguishing softened positive (i.e., hard-negative examples plus positive\nexamples) from easy-negative examples. In the neural context, this can be done\nby outputting the same representation from the last neural layer to different\n$softmax$ functions. Using this strategy, we can improve the performance of\nbaseline models in a range of different NLP tasks, including text\nclassification, sequence labeling and reading comprehension.", "published": "2019-05-28 07:46:50", "link": "http://arxiv.org/abs/1905.11658v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On Measuring Gender Bias in Translation of Gender-neutral Pronouns", "abstract": "Ethics regarding social bias has recently thrown striking issues in natural\nlanguage processing. Especially for gender-related topics, the need for a\nsystem that reduces the model bias has grown in areas such as image captioning,\ncontent recommendation, and automated employment. However, detection and\nevaluation of gender bias in the machine translation systems are not yet\nthoroughly investigated, for the task being cross-lingual and challenging to\ndefine. In this paper, we propose a scheme for making up a test set that\nevaluates the gender bias in a machine translation system, with Korean, a\nlanguage with gender-neutral pronouns. Three word/phrase sets are primarily\nconstructed, each incorporating positive/negative expressions or occupations;\nall the terms are gender-independent or at least not biased to one side\nseverely. Then, additional sentence lists are constructed concerning formality\nof the pronouns and politeness of the sentences. With the generated sentence\nset of size 4,236 in total, we evaluate gender bias in conventional machine\ntranslation systems utilizing the proposed measure, which is termed here as\ntranslation gender bias index (TGBI). The corpus and the code for evaluation is\navailable on-line.", "published": "2019-05-28 08:46:56", "link": "http://arxiv.org/abs/1905.11684v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Incremental Turn-Taking Model For Task-Oriented Dialog Systems", "abstract": "In a human-machine dialog scenario, deciding the appropriate time for the\nmachine to take the turn is an open research problem. In contrast, humans\nengaged in conversations are able to timely decide when to interrupt the\nspeaker for competitive or non-competitive reasons. In state-of-the-art\nturn-by-turn dialog systems the decision on the next dialog action is taken at\nthe end of the utterance. In this paper, we propose a token-by-token prediction\nof the dialog state from incremental transcriptions of the user utterance. To\nidentify the point of maximal understanding in an ongoing utterance, we a)\nimplement an incremental Dialog State Tracker which is updated on a token basis\n(iDST) b) re-label the Dialog State Tracking Challenge 2 (DSTC2) dataset and c)\nadapt it to the incremental turn-taking experimental scenario. The re-labeling\nconsists of assigning a binary value to each token in the user utterance that\nallows to identify the appropriate point for taking the turn. Finally, we\nimplement an incremental Turn Taking Decider (iTTD) that is trained on these\nnew labels for the turn-taking decision. We show that the proposed model can\nachieve a better performance compared to a deterministic handcrafted\nturn-taking algorithm.", "published": "2019-05-28 13:38:29", "link": "http://arxiv.org/abs/1905.11806v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Revisiting Low-Resource Neural Machine Translation: A Case Study", "abstract": "It has been shown that the performance of neural machine translation (NMT)\ndrops starkly in low-resource conditions, underperforming phrase-based\nstatistical machine translation (PBSMT) and requiring large amounts of\nauxiliary data to achieve competitive results. In this paper, we re-assess the\nvalidity of these results, arguing that they are the result of lack of system\nadaptation to low-resource settings. We discuss some pitfalls to be aware of\nwhen training low-resource NMT systems, and recent techniques that have shown\nto be especially helpful in low-resource settings, resulting in a set of best\npractices for low-resource NMT. In our experiments on German--English with\ndifferent amounts of IWSLT14 training data, we show that, without the use of\nany auxiliary monolingual or multilingual data, an optimized NMT system can\noutperform PBSMT with far less data than previously claimed. We also apply\nthese techniques to a low-resource Korean-English dataset, surpassing\npreviously reported results by 4 BLEU.", "published": "2019-05-28 15:59:21", "link": "http://arxiv.org/abs/1905.11901v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Cross-Domain Transferable Neural Coherence Model", "abstract": "Coherence is an important aspect of text quality and is crucial for ensuring\nits readability. One important limitation of existing coherence models is that\ntraining on one domain does not easily generalize to unseen categories of text.\nPrevious work advocates for generative models for cross-domain generalization,\nbecause for discriminative models, the space of incoherent sentence orderings\nto discriminate against during training is prohibitively large. In this work,\nwe propose a local discriminative neural model with a much smaller negative\nsampling space that can efficiently learn against incorrect orderings. The\nproposed coherence model is simple in structure, yet it significantly\noutperforms previous state-of-art methods on a standard benchmark dataset on\nthe Wall Street Journal corpus, as well as in multiple new challenging settings\nof transfer to unseen categories of discourse on Wikipedia articles.", "published": "2019-05-28 16:17:41", "link": "http://arxiv.org/abs/1905.11912v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Ambiguity Detection", "abstract": "Most work on sense disambiguation presumes that one knows beforehand -- e.g.\nfrom a thesaurus -- a set of polysemous terms. But published lists invariably\ngive only partial coverage. For example, the English word tan has several\nobvious senses, but one may overlook the abbreviation for tangent. In this\npaper, we present an algorithm for identifying interesting polysemous terms and\nmeasuring their degree of polysemy, given an unlabeled corpus. The algorithm\ninvolves: (i) collecting all terms within a k-term window of the target term;\n(ii) computing the inter-term distances of the contextual terms, and reducing\nthe multi-dimensional distance space to two dimensions using standard methods;\n(iii) converting the two-dimensional representation into radial coordinates and\nusing isotonic/antitonic regression to compute the degree to which the\ndistribution deviates from a single-peak model. The amount of deviation is the\nproposed polysemy index", "published": "2019-05-28 20:11:47", "link": "http://arxiv.org/abs/1905.12065v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SEMA: an Extended Semantic Evaluation Metric for AMR", "abstract": "Abstract Meaning Representation (AMR) is a recently designed semantic\nrepresentation language intended to capture the meaning of a sentence, which\nmay be represented as a single-rooted directed acyclic graph with labeled nodes\nand edges. The automatic evaluation of this structure plays an important role\nin the development of better systems, as well as for semantic annotation.\nDespite there is one available metric, smatch, it has some drawbacks. For\ninstance, smatch creates a self-relation on the root of the graph, has weights\nfor different error types, and does not take into account the dependence of the\nelements in the AMR structure. With these drawbacks, smatch masks several\nproblems of the AMR parsers and distorts the evaluation of the AMRs. In view of\nthis, in this paper, we introduce an extended metric to evaluate AMR parsers,\nwhich deals with the drawbacks of the smatch metric. Finally, we compare both\nmetrics, using four well-known AMR parsers, and we argue that our metric is\nmore refined, robust, fairer, and faster than smatch.", "published": "2019-05-28 20:21:19", "link": "http://arxiv.org/abs/1905.12069v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LeafNATS: An Open-Source Toolkit and Live Demo System for Neural\n  Abstractive Text Summarization", "abstract": "Neural abstractive text summarization (NATS) has received a lot of attention\nin the past few years from both industry and academia. In this paper, we\nintroduce an open-source toolkit, namely LeafNATS, for training and evaluation\nof different sequence-to-sequence based models for the NATS task, and for\ndeploying the pre-trained models to real-world applications. The toolkit is\nmodularized and extensible in addition to maintaining competitive performance\nin the NATS task. A live news blogging system has also been implemented to\ndemonstrate how these models can aid blog/news editors by providing them\nsuggestions of headlines and summaries of their articles.", "published": "2019-05-28 23:53:02", "link": "http://arxiv.org/abs/1906.01512v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adaptive Region Embedding for Text Classification", "abstract": "Deep learning models such as convolutional neural networks and recurrent\nnetworks are widely applied in text classification. In spite of their great\nsuccess, most deep learning models neglect the importance of modeling context\ninformation, which is crucial to understanding texts. In this work, we propose\nthe Adaptive Region Embedding to learn context representation to improve text\nclassification. Specifically, a metanetwork is learned to generate a context\nmatrix for each region, and each word interacts with its corresponding context\nmatrix to produce the regional representation for further classification.\nCompared to previous models that are designed to capture context information,\nour model contains less parameters and is more flexible. We extensively\nevaluate our method on 8 benchmark datasets for text classification. The\nexperimental results prove that our method achieves state-of-the-art\nperformances and effectively avoids word ambiguity.", "published": "2019-05-28 13:11:23", "link": "http://arxiv.org/abs/1906.01514v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-lingual Knowledge Graph Alignment via Graph Matching Neural\n  Network", "abstract": "Previous cross-lingual knowledge graph (KG) alignment studies rely on entity\nembeddings derived only from monolingual KG structural information, which may\nfail at matching entities that have different facts in two KGs. In this paper,\nwe introduce the topic entity graph, a local sub-graph of an entity, to\nrepresent entities with their contextual information in KG. From this view, the\nKB-alignment task can be formulated as a graph matching problem; and we further\npropose a graph-attention based solution, which first matches all entities in\ntwo topic entity graphs, and then jointly model the local matching information\nto derive a graph-level matching vector. Experiments show that our model\noutperforms previous state-of-the-art methods by a large margin.", "published": "2019-05-28 04:37:49", "link": "http://arxiv.org/abs/1905.11605v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Extracting adverse drug reactions and their context using sequence\n  labelling ensembles in TAC2017", "abstract": "Adverse drug reactions (ADRs) are unwanted or harmful effects experienced\nafter the administration of a certain drug or a combination of drugs,\npresenting a challenge for drug development and drug administration. In this\npaper, we present a set of taggers for extracting adverse drug reactions and\nrelated entities, including factors, severity, negations, drug class and\nanimal. The systems used a mix of rule-based, machine learning (CRF) and deep\nlearning (BLSTM with word2vec embeddings) methodologies in order to annotate\nthe data. The systems were submitted to adverse drug reaction shared task,\norganised during Text Analytics Conference in 2017 by National Institute for\nStandards and Technology, archiving F1-scores of 76.00 and 75.61 respectively.", "published": "2019-05-28 10:07:01", "link": "http://arxiv.org/abs/1905.11716v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Miss Tools and Mr Fruit: Emergent communication in agents learning about\n  object affordances", "abstract": "Recent research studies communication emergence in communities of deep\nnetwork agents assigned a joint task, hoping to gain insights on human language\nevolution. We propose here a new task capturing crucial aspects of the human\nenvironment, such as natural object affordances, and of human conversation,\nsuch as full symmetry among the participants. By conducting a thorough\npragmatic and semantic analysis of the emergent protocol, we show that the\nagents solve the shared task through genuine bilateral, referential\ncommunication. However, the agents develop multiple idiolects, which makes us\nconclude that full symmetry is not a sufficient condition for a common language\nto emerge.", "published": "2019-05-28 15:10:30", "link": "http://arxiv.org/abs/1905.11871v1", "categories": ["cs.CL", "cs.MA"], "primary_category": "cs.CL"}
{"title": "On Variational Learning of Controllable Representations for Text without\n  Supervision", "abstract": "The variational autoencoder (VAE) can learn the manifold of natural images on\ncertain datasets, as evidenced by meaningful interpolating or extrapolating in\nthe continuous latent space. However, on discrete data such as text, it is\nunclear if unsupervised learning can discover similar latent space that allows\ncontrollable manipulation. In this work, we find that sequence VAEs trained on\ntext fail to properly decode when the latent codes are manipulated, because the\nmodified codes often land in holes or vacant regions in the aggregated\nposterior latent space, where the decoding network fails to generalize. Both as\na validation of the explanation and as a fix to the problem, we propose to\nconstrain the posterior mean to a learned probability simplex, and performs\nmanipulation within this simplex. Our proposed method mitigates the latent\nvacancy problem and achieves the first success in unsupervised learning of\ncontrollable representations for text. Empirically, our method outperforms\nunsupervised baselines and strong supervised approaches on text style transfer,\nand is capable of performing more flexible fine-grained control over text\ngeneration than existing methods.", "published": "2019-05-28 17:49:47", "link": "http://arxiv.org/abs/1905.11975v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Parallax: Visualizing and Understanding the Semantics of Embedding\n  Spaces via Algebraic Formulae", "abstract": "Embeddings are a fundamental component of many modern machine learning and\nnatural language processing models. Understanding them and visualizing them is\nessential for gathering insights about the information they capture and the\nbehavior of the models. State of the art in analyzing embeddings consists in\nprojecting them in two-dimensional planes without any interpretable semantics\nassociated to the axes of the projection, which makes detailed analyses and\ncomparison among multiple sets of embeddings challenging. In this work, we\npropose to use explicit axes defined as algebraic formulae over embeddings to\nproject them into a lower dimensional, but semantically meaningful subspace, as\na simple yet effective analysis and visualization methodology. This methodology\nassigns an interpretable semantics to the measures of variability and the axes\nof visualizations, allowing for both comparisons among different sets of\nembeddings and fine-grained inspection of the embedding spaces. We demonstrate\nthe power of the proposed methodology through a series of case studies that\nmake use of visualizations constructed around the underlying methodology and\nthrough a user study. The results show how the methodology is effective at\nproviding more profound insights than classical projection methods and how it\nis widely applicable to many other use cases.", "published": "2019-05-28 21:32:02", "link": "http://arxiv.org/abs/1905.12099v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Target-Guided Open-Domain Conversation", "abstract": "Many real-world open-domain conversation applications have specific goals to\nachieve during open-ended chats, such as recommendation, psychotherapy,\neducation, etc. We study the problem of imposing conversational goals on\nopen-domain chat agents. In particular, we want a conversational system to chat\nnaturally with human and proactively guide the conversation to a designated\ntarget subject. The problem is challenging as no public data is available for\nlearning such a target-guided strategy. We propose a structured approach that\nintroduces coarse-grained keywords to control the intended content of system\nresponses. We then attain smooth conversation transition through turn-level\nsupervised learning, and drive the conversation towards the target with\ndiscourse-level constraints. We further derive a keyword-augmented conversation\ndataset for the study. Quantitative and human evaluations show our system can\nproduce meaningful and effective conversations, significantly improving over\nother approaches.", "published": "2019-05-28 00:55:25", "link": "http://arxiv.org/abs/1905.11553v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unsupervised End-to-End Learning of Discrete Linguistic Units for Voice\n  Conversion", "abstract": "We present an unsupervised end-to-end training scheme where we discover\ndiscrete subword units from speech without using any labels. The discrete\nsubword units are learned under an ASR-TTS autoencoder reconstruction setting,\nwhere an ASR-Encoder is trained to discover a set of common linguistic units\ngiven a variety of speakers, and a TTS-Decoder trained to project the\ndiscovered units back to the designated speech. We propose a discrete encoding\nmethod, Multilabel-Binary Vectors (MBV), to make the ASR-TTS autoencoder\ndifferentiable. We found that the proposed encoding method offers automatic\nextraction of speech content from speaker style, and is sufficient to cover\nfull linguistic content in a given language. Therefore, the TTS-Decoder can\nsynthesize speech with the same content as the input of ASR-Encoder but with\ndifferent speaker characteristics, which achieves voice conversion (VC). We\nfurther improve the quality of VC using adversarial training, where we train a\nTTS-Patcher that augments the output of TTS-Decoder. Objective and subjective\nevaluations show that the proposed approach offers strong VC results as it\neliminates speaker identity while preserving content within speech. In the\nZeroSpeech 2019 Challenge, we achieved outstanding performance in terms of low\nbitrate.", "published": "2019-05-28 01:36:31", "link": "http://arxiv.org/abs/1905.11563v3", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Interpreting and improving natural-language processing (in machines)\n  with natural language-processing (in the brain)", "abstract": "Neural networks models for NLP are typically implemented without the explicit\nencoding of language rules and yet they are able to break one performance\nrecord after another. This has generated a lot of research interest in\ninterpreting the representations learned by these networks. We propose here a\nnovel interpretation approach that relies on the only processing system we have\nthat does understand language: the human brain. We use brain imaging recordings\nof subjects reading complex natural text to interpret word and sequence\nembeddings from 4 recent NLP models - ELMo, USE, BERT and Transformer-XL. We\nstudy how their representations differ across layer depth, context length, and\nattention type. Our results reveal differences in the context-related\nrepresentations across these models. Further, in the transformer models, we\nfind an interaction between layer depth and context length, and between layer\ndepth and attention type. We finally hypothesize that altering BERT to better\nalign with brain recordings would enable it to also better understand language.\nProbing the altered BERT using syntactic NLP tasks reveals that the model with\nincreased brain-alignment outperforms the original model. Cognitive\nneuroscientists have already begun using NLP networks to study the brain, and\nthis work closes the loop to allow the interaction between NLP and cognitive\nneuroscience to be a true cross-pollination.", "published": "2019-05-28 14:13:09", "link": "http://arxiv.org/abs/1905.11833v4", "categories": ["cs.CL", "cs.AI", "cs.LG", "q-bio.NC"], "primary_category": "cs.CL"}
{"title": "Better Long-Range Dependency By Bootstrapping A Mutual Information\n  Regularizer", "abstract": "In this work, we develop a novel regularizer to improve the learning of\nlong-range dependency of sequence data. Applied on language modelling, our\nregularizer expresses the inductive bias that sequence variables should have\nhigh mutual information even though the model might not see abundant\nobservations for complex long-range dependency. We show how the `next sentence\nprediction (classification)' heuristic can be derived in a principled way from\nour mutual information estimation framework, and be further extended to\nmaximize the mutual information of sequence variables. The proposed approach\nnot only is effective at increasing the mutual information of segments under\nthe learned model but more importantly, leads to a higher likelihood on holdout\ndata, and improved generation quality. Code is released at\nhttps://github.com/BorealisAI/BMI.", "published": "2019-05-28 17:55:32", "link": "http://arxiv.org/abs/1905.11978v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Leveraging Medical Visual Question Answering with Supporting Facts", "abstract": "In this working notes paper, we describe IBM Research AI (Almaden) team's\nparticipation in the ImageCLEF 2019 VQA-Med competition. The challenge consists\nof four question-answering tasks based on radiology images. The diversity of\nimaging modalities, organs and disease types combined with a small imbalanced\ntraining set made this a highly complex problem. To overcome these\ndifficulties, we implemented a modular pipeline architecture that utilized\ntransfer learning and multi-task learning. Our findings led to the development\nof a novel model called Supporting Facts Network (SFN). The main idea behind\nSFN is to cross-utilize information from upstream tasks to improve the accuracy\non harder downstream ones. This approach significantly improved the scores\nachieved in the validation set (18 point improvement in F-1 score). Finally, we\nsubmitted four runs to the competition and were ranked seventh.", "published": "2019-05-28 18:15:52", "link": "http://arxiv.org/abs/1905.12008v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Demonstration of PerformanceNet: A Convolutional Neural Network Model\n  for Score-to-Audio Music Generation", "abstract": "We present in this paper PerformacnceNet, a neural network model we proposed\nrecently to achieve score-to-audio music generation. The model learns to\nconvert a music piece from the symbolic domain to the audio domain, assigning\nperformance-level attributes such as changes in velocity automatically to the\nmusic and then synthesizing the audio. The model is therefore not just a neural\naudio synthesizer, but an AI performer that learns to interpret a musical score\nin its own way. The code and sample outputs of the model can be found online at\nhttps://github.com/bwang514/PerformanceNet.", "published": "2019-05-28 09:00:19", "link": "http://arxiv.org/abs/1905.11689v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Ensemble-based cover song detection", "abstract": "Audio-based cover song detection has received much attention in the MIR\ncommunity in the recent years. To date, the most popular formulation of the\nproblem has been to compare the audio signals of two tracks and to make a\nbinary decision based on this information only. However, leveraging additional\nsignals might be key if one wants to solve the problem at an industrial scale.\nIn this paper, we introduce an ensemble-based method that approaches the\nproblem from a many-to-many perspective. Instead of considering pairs of tracks\nin isolation, we consider larger sets of potential versions for a given\ncomposition, and create and exploit the graph of relationships between these\ntracks. We show that this can result in a significant improvement in\nperformance, in particular when the number of existing versions of a given\ncomposition is large.", "published": "2019-05-28 09:29:59", "link": "http://arxiv.org/abs/1905.11700v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Automatic Quality Control and Enhancement for Voice-Based Remote\n  Parkinson's Disease Detection", "abstract": "The performance of voice-based Parkinson's disease (PD) detection systems\ndegrades when there is an acoustic mismatch between training and operating\nconditions caused mainly by degradation in test signals. In this paper, we\naddress this mismatch by considering three types of degradation commonly\nencountered in remote voice analysis, namely background noise, reverberation\nand nonlinear distortion, and investigate how these degradations influence the\nperformance of a PD detection system. Given that the specific degradation is\nknown, we explore the effectiveness of a variety of enhancement algorithms in\ncompensating this mismatch and improving the PD detection accuracy. Then, we\npropose two approaches to automatically control the quality of recordings by\nidentifying the presence and type of short-term and long-term degradations and\nprotocol violations in voice signals. Finally, we experiment with using the\nproposed quality control methods to inform the choice of enhancement algorithm.\nExperimental results using the voice recordings of the mPower mobile PD data\nset under different degradation conditions show the effectiveness of the\nquality control approaches in selecting an appropriate enhancement method and,\nconsequently, in improving the PD detection accuracy. This study is a step\ntowards the development of a remote PD detection system capable of operating in\nunseen acoustic environments.", "published": "2019-05-28 13:00:21", "link": "http://arxiv.org/abs/1905.11785v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Two-level Explanations in Music Emotion Recognition", "abstract": "Current ML models for music emotion recognition, while generally working\nquite well, do not give meaningful or intuitive explanations for their\npredictions. In this work, we propose a 2-step procedure to arrive at\nspectrogram-level explanations that connect certain aspects of the audio to\ninterpretable mid-level perceptual features, and these to the actual emotion\nprediction. That makes it possible to focus on specific musical reasons for a\nprediction (in terms of perceptual features), and to trace these back to\npatterns in the audio that can be interpreted visually and acoustically.", "published": "2019-05-28 12:08:54", "link": "http://arxiv.org/abs/1905.11760v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SignalTrain: Profiling Audio Compressors with Deep Neural Networks", "abstract": "In this work we present a data-driven approach for predicting the behavior of\n(i.e., profiling) a given non-linear audio signal processing effect (henceforth\n\"audio effect\"). Our objective is to learn a mapping function that maps the\nunprocessed audio to the processed by the audio effect to be profiled, using\ntime-domain samples. To that aim, we employ a deep auto-encoder model that is\nconditioned on both time-domain samples and the control parameters of the\ntarget audio effect. As a test-case study, we focus on the offline profiling of\ntwo dynamic range compression audio effects, one software-based and the other\nanalog. Compressors were chosen because they are a widely used and important\nset of effects and because their parameterized nonlinear time-dependent nature\nmakes them a challenging problem for a system aiming to profile \"general\" audio\neffects. Results from our experimental procedure show that the primary\nfunctional and auditory characteristics of the compressors can be captured,\nhowever there is still sufficient audible noise to merit further investigation\nbefore such methods are applied to real-world audio processing workflows.", "published": "2019-05-28 16:42:06", "link": "http://arxiv.org/abs/1905.11928v2", "categories": ["eess.AS", "cs.LG", "cs.SD", "I.2.6"], "primary_category": "eess.AS"}
{"title": "Texture Selection for Automatic Music Genre Classification", "abstract": "Music Genre Classification is the problem of associating genre-related labels\nto digitized music tracks. It has applications in the organization of\ncommercial and personal music collections. Often, music tracks are described as\na set of timbre-inspired sound textures. In shallow-learning systems, the total\nnumber of sound textures per track is usually too high, and texture\ndownsampling is necessary to make training tractable. Although previous work\nhas solved this by linear downsampling, no extensive work has been done to\nevaluate how texture selection benefits genre classification in the context of\nthe bag of frames track descriptions. In this paper, we evaluate the impact of\nframe selection on automatic music genre classification in a bag of frames\nscenario. We also present a novel texture selector based on K-Means aimed to\nidentify diverse sound textures within each track. We evaluated texture\nselection in diverse datasets, four different feature sets, as well as its\nrelationship to a univariate feature selection strategy. The results show that\nframe selection leads to significant improvement over the single vector\nbaseline on datasets consisting of full-length tracks, regardless of the\nfeature set. Results also indicate that the K-Means texture selector achieves\nsignificant improvements over the baseline, using fewer textures per track than\nthe commonly used linear downsampling. The results also suggest that texture\nselection is complementary to the feature selection strategy evaluated. Our\nqualitative analysis indicates that texture variety within classes benefits\nmodel generalization. Our analysis shows that selecting specific audio excerpts\ncan improve classification performance, and it can be done automatically.", "published": "2019-05-28 17:30:31", "link": "http://arxiv.org/abs/1905.11959v1", "categories": ["cs.SD", "cs.IR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
