{"title": "Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation", "abstract": "Recently, GPT-4o has garnered significant attention for its strong\nperformance in image generation, yet open-source models still lag behind.\nSeveral studies have explored distilling image data from GPT-4o to enhance\nopen-source models, achieving notable progress. However, a key question\nremains: given that real-world image datasets already constitute a natural\nsource of high-quality data, why should we use GPT-4o-generated synthetic data?\nIn this work, we identify two key advantages of synthetic images. First, they\ncan complement rare scenarios in real-world datasets, such as surreal fantasy\nor multi-reference image generation, which frequently occur in user queries.\nSecond, they provide clean and controllable supervision. Real-world data often\ncontains complex background noise and inherent misalignment between text\ndescriptions and image content, whereas synthetic images offer pure backgrounds\nand long-tailed supervision signals, facilitating more accurate text-to-image\nalignment. Building on these insights, we introduce Echo-4o-Image, a 180K-scale\nsynthetic dataset generated by GPT-4o, harnessing the power of synthetic image\ndata to address blind spots in real-world coverage. Using this dataset, we\nfine-tune the unified multimodal generation baseline Bagel to obtain Echo-4o.\nIn addition, we propose two new evaluation benchmarks for a more accurate and\nchallenging assessment of image generation capabilities: GenEval++, which\nincreases instruction complexity to mitigate score saturation, and\nImagine-Bench, which focuses on evaluating both the understanding and\ngeneration of imaginative content. Echo-4o demonstrates strong performance\nacross standard benchmarks. Moreover, applying Echo-4o-Image to other\nfoundation models (e.g., OmniGen2, BLIP3-o) yields consistent performance gains\nacross multiple metrics, highlighting the datasets strong transferability.", "published": "2025-08-13 17:59:28", "link": "http://arxiv.org/abs/2508.09987v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Neural Bandit Based Optimal LLM Selection for a Pipeline of Tasks", "abstract": "With the increasing popularity of large language models (LLMs) for a variety\nof tasks, there has been a growing interest in strategies that can predict\nwhich out of a set of LLMs will yield a successful answer at low cost. This\nproblem promises to become more and more relevant as providers like Microsoft\nallow users to easily create custom LLM \"assistants\" specialized to particular\ntypes of queries. However, some tasks (i.e., queries) may be too specialized\nand difficult for a single LLM to handle alone. These applications often\nbenefit from breaking down the task into smaller subtasks, each of which can\nthen be executed by a LLM expected to perform well on that specific subtask.\nFor example, in extracting a diagnosis from medical records, one can first\nselect an LLM to summarize the record, select another to validate the summary,\nand then select another, possibly different, LLM to extract the diagnosis from\nthe summarized record. Unlike existing LLM selection or routing algorithms,\nthis setting requires that we select a sequence of LLMs, with the output of\neach LLM feeding into the next and potentially influencing its success. Thus,\nunlike single LLM selection, the quality of each subtask's output directly\naffects the inputs, and hence the cost and success rate, of downstream LLMs,\ncreating complex performance dependencies that must be learned and accounted\nfor during selection. We propose a neural contextual bandit-based algorithm\nthat trains neural networks that model LLM success on each subtask in an online\nmanner, thus learning to guide the LLM selections for the different subtasks,\neven in the absence of historical LLM performance data. Experiments on\ntelecommunications question answering and medical diagnosis prediction datasets\nillustrate the effectiveness of our proposed approach compared to other LLM\nselection algorithms.", "published": "2025-08-13 17:19:41", "link": "http://arxiv.org/abs/2508.09958v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Which one Performs Better? Wav2Vec or Whisper? Applying both in Badini Kurdish Speech to Text (BKSTT)", "abstract": "Speech-to-text (STT) systems have a wide range of applications. They are\navailable in many languages, albeit at different quality levels. Although\nKurdish is considered a less-resourced language from a processing perspective,\nSST is available for some of the Kurdish dialects, for instance, Sorani\n(Central Kurdish). However, that is not applied to other Kurdish dialects,\nBadini and Hawrami, for example. This research is an attempt to address this\ngap. Bandin, approximately, has two million speakers, and STT systems can help\ntheir community use mobile and computer-based technologies while giving their\ndialect more global visibility. We aim to create a language model based on\nBadini's speech and evaluate its performance. To cover a conversational aspect,\nhave a proper confidence level of grammatical accuracy, and ready\ntranscriptions, we chose Badini kids' stories, eight books including 78\nstories, as the textual input. Six narrators narrated the books, which resulted\nin approximately 17 hours of recording. We cleaned, segmented, and tokenized\nthe input. The preprocessing produced nearly 15 hours of speech, including\n19193 segments and 25221 words. We used Wav2Vec2-Large-XLSR-53 and\nWhisper-small to develop the language models. The experiments indicate that the\ntranscriptions process based on the Wav2Vec2-Large-XLSR-53 model provides a\nsignificantly more accurate and readable output than the Whisper-small model,\nwith 90.38% and 65.45% readability, and 82.67% and 53.17% accuracy,\nrespectively.", "published": "2025-08-13 17:19:22", "link": "http://arxiv.org/abs/2508.09957v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Performance of GPT-5 Frontier Models in Ophthalmology Question Answering", "abstract": "Large language models (LLMs) such as GPT-5 integrate advanced reasoning\ncapabilities that may improve performance on complex medical question-answering\ntasks. For this latest generation of reasoning models, the configurations that\nmaximize both accuracy and cost-efficiency have yet to be established. We\nevaluated 12 configurations of OpenAI's GPT-5 series (three model tiers across\nfour reasoning effort settings) alongside o1-high, o3-high, and GPT-4o, using\n260 closed-access multiple-choice questions from the American Academy of\nOphthalmology Basic Clinical Science Course (BCSC) dataset. The primary outcome\nwas multiple-choice accuracy; secondary outcomes included head-to-head ranking\nvia a Bradley-Terry model, rationale quality assessment using a\nreference-anchored, pairwise LLM-as-a-judge framework, and analysis of\naccuracy-cost trade-offs using token-based cost estimates. GPT-5-high achieved\nthe highest accuracy (0.965; 95% CI, 0.942-0.985), outperforming all GPT-5-nano\nvariants (P < .001), o1-high (P = .04), and GPT-4o (P < .001), but not o3-high\n(0.958; 95% CI, 0.931-0.981). GPT-5-high ranked first in both accuracy (1.66x\nstronger than o3-high) and rationale quality (1.11x stronger than o3-high).\nCost-accuracy analysis identified several GPT-5 configurations on the Pareto\nfrontier, with GPT-5-mini-low offering the most favorable low-cost,\nhigh-performance balance. These results benchmark GPT-5 on a high-quality\nophthalmology dataset, demonstrate the influence of reasoning effort on\naccuracy, and introduce an autograder framework for scalable evaluation of\nLLM-generated answers against reference standards in ophthalmology.", "published": "2025-08-13 17:17:17", "link": "http://arxiv.org/abs/2508.09956v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Shaping Event Backstories to Estimate Potential Emotion Contexts", "abstract": "Emotion analysis is an inherently ambiguous task. Previous work studied\nannotator properties to explain disagreement, but this overlooks the\npossibility that ambiguity may stem from missing information about the context\nof events. In this paper, we propose a novel approach that adds reasonable\ncontexts to event descriptions, which may better explain a particular\nsituation. Our goal is to understand whether these enriched contexts enable\nhuman annotators to annotate emotions more reliably. We disambiguate a target\nevent description by automatically generating multiple event chains conditioned\non differing emotions. By combining techniques from short story generation in\nvarious settings, we achieve coherent narratives that result in a specialized\ndataset for the first comprehensive and systematic examination of\ncontextualized emotion analysis. Through automatic and human evaluation, we\nfind that contextual narratives enhance the interpretation of specific emotions\nand support annotators in producing more consistent annotations.", "published": "2025-08-13 17:15:52", "link": "http://arxiv.org/abs/2508.09954v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Specialised or Generic? Tokenization Choices for Radiology Language Models", "abstract": "The vocabulary used by language models (LM) - defined by the tokenizer -\nplays a key role in text generation quality. However, its impact remains\nunder-explored in radiology. In this work, we address this gap by\nsystematically comparing general, medical, and domain-specific tokenizers on\nthe task of radiology report summarisation across three imaging modalities. We\nalso investigate scenarios with and without LM pre-training on PubMed\nabstracts. Our findings demonstrate that medical and domain-specific\nvocabularies outperformed widely used natural language alternatives when models\nare trained from scratch. Pre-training partially mitigates performance\ndifferences between tokenizers, whilst the domain-specific tokenizers achieve\nthe most favourable results. Domain-specific tokenizers also reduce memory\nrequirements due to smaller vocabularies and shorter sequences. These results\ndemonstrate that adapting the vocabulary of LMs to the clinical domain provides\npractical benefits, including improved performance and reduced computational\ndemands, making such models more accessible and effective for both research and\nreal-world healthcare settings.", "published": "2025-08-13 17:13:56", "link": "http://arxiv.org/abs/2508.09952v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "VisCodex: Unified Multimodal Code Generation via Merging Vision and Coding Models", "abstract": "Multimodal large language models (MLLMs) have significantly advanced the\nintegration of visual and textual understanding. However, their ability to\ngenerate code from multimodal inputs remains limited. In this work, we\nintroduce VisCodex, a unified framework that seamlessly merges vision and\ncoding language models to empower MLLMs with strong multimodal code generation\nabilities. Leveraging a task vector-based model merging technique, we integrate\na state-of-the-art coding LLM into a strong vision-language backbone, while\npreserving both visual comprehension and advanced coding skills. To support\ntraining and evaluation, we introduce the Multimodal Coding Dataset (MCD), a\nlarge-scale and diverse collection of 598k samples, including high-quality HTML\ncode, chart image-code pairs, image-augmented StackOverflow QA, and algorithmic\nproblems. Furthermore, we propose InfiBench-V, a novel and challenging\nbenchmark specifically designed to assess models on visually-rich, real-world\nprogramming questions that demand a nuanced understanding of both textual and\nvisual contexts. Extensive experiments show that VisCodex achieves\nstate-of-the-art performance among open-source MLLMs and approaches proprietary\nmodels like GPT-4o, highlighting the effectiveness of our model merging\nstrategy and new datasets.", "published": "2025-08-13 17:00:44", "link": "http://arxiv.org/abs/2508.09945v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Evaluation framework of Alignment Techniques for LLMs", "abstract": "As Large Language Models (LLMs) become increasingly integrated into\nreal-world applications, ensuring their outputs align with human values and\nsafety standards has become critical. The field has developed diverse alignment\napproaches including traditional fine-tuning methods (RLHF, instruction\ntuning), post-hoc correction systems, and inference-time interventions, each\nwith distinct advantages and limitations. However, the lack of unified\nevaluation frameworks makes it difficult to systematically compare these\nparadigms and guide deployment decisions. This paper introduces a\nmulti-dimensional evaluation of alignment techniques for LLMs, a comprehensive\nevaluation framework that provides a systematic comparison across all major\nalignment paradigms. Our framework assesses methods along four key dimensions:\nalignment detection, alignment quality, computational efficiency, and\nrobustness. Through experiments across diverse base models and alignment\nstrategies, we demonstrate the utility of our framework in identifying\nstrengths and limitations of current state-of-the-art models, providing\nvaluable insights for future research directions.", "published": "2025-08-13 16:42:01", "link": "http://arxiv.org/abs/2508.09937v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Language of Persuasion and Misrepresentation in Business Communication: A Textual Detection Approach", "abstract": "Business communication digitisation has reorganised the process of persuasive\ndiscourse, which\n  allows not only greater transparency but also advanced deception. This\ninquiry synthesises classical\n  rhetoric and communication psychology with linguistic theory and empirical\nstudies in the financial\n  reporting, sustainability discourse, and digital marketing to explain how\ndeceptive language can be\n  systematically detected using persuasive lexicon. In controlled settings,\ndetection accuracies of greater\n  than 99% were achieved by using computational textual analysis as well as\npersonalised transformer\n  models. However, reproducing this performance in multilingual settings is\nalso problematic and,\n  to a large extent, this is because it is not easy to find sufficient data,\nand because few multilingual\n  text-processing infrastructures are in place. This evidence shows that there\nhas been an increasing\n  gap between the theoretical representations of communication and those\nempirically approximated,\n  and therefore, there is a need to have strong automatic text-identification\nsystems where AI-based\n  discourse is becoming more realistic in communicating with humans.", "published": "2025-08-13 16:38:31", "link": "http://arxiv.org/abs/2508.09935v1", "categories": ["cs.CL", "q-fin.CP", "q-fin.GN"], "primary_category": "cs.CL"}
{"title": "COME: Dual Structure-Semantic Learning with Collaborative MoE for Universal Lesion Detection Across Heterogeneous Ultrasound Datasets", "abstract": "Conventional single-dataset training often fails with new data distributions,\nespecially in ultrasound (US) image analysis due to limited data, acoustic\nshadows, and speckle noise. Therefore, constructing a universal framework for\nmulti-heterogeneous US datasets is imperative. However, a key challenge arises:\nhow to effectively mitigate inter-dataset interference while preserving\ndataset-specific discriminative features for robust downstream task? Previous\napproaches utilize either a single source-specific decoder or a domain\nadaptation strategy, but these methods experienced a decline in performance\nwhen applied to other domains. Considering this, we propose a Universal\nCollaborative Mixture of Heterogeneous Source-Specific Experts (COME).\nSpecifically, COME establishes dual structure-semantic shared experts that\ncreate a universal representation space and then collaborate with\nsource-specific experts to extract discriminative features through providing\ncomplementary features. This design enables robust generalization by leveraging\ncross-datasets experience distributions and providing universal US priors for\nsmall-batch or unseen data scenarios. Extensive experiments under three\nevaluation modes (single-dataset, intra-organ, and inter-organ integration\ndatasets) demonstrate COME's superiority, achieving significant mean AP\nimprovements over state-of-the-art methods. Our project is available at:\nhttps://universalcome.github.io/UniversalCOME/.", "published": "2025-08-13 15:43:20", "link": "http://arxiv.org/abs/2508.09886v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "A Survey of Cognitive Distortion Detection and Classification in NLP", "abstract": "As interest grows in the application of natural language processing (NLP)\ntechniques to mental health, a growing body of work explores the automatic\ndetection and classification of cognitive distortions (CDs). CDs are habitual\npatterns of negatively biased or flawed thinking that distort how people\nperceive events, judge themselves, and react to the world around them.\nIdentifying and addressing them is an important part of therapy. Despite its\nmomentum, the field remains fragmented, with inconsistencies in CD taxonomies,\ntask formulations, and evaluation practices. This survey reviews 38 studies\nspanning two decades, providing a structured overview of datasets, modelling\napproaches, and evaluation strategies. We provide a consolidated CD taxonomy\nreference, summarise common task setups, and highlight open challenges to\nsupport more coherent and reproducible research in this emerging area.", "published": "2025-08-13 15:21:17", "link": "http://arxiv.org/abs/2508.09878v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Memory Decoder: A Pretrained, Plug-and-Play Memory for Large Language Models", "abstract": "Large Language Models (LLMs) have shown strong abilities in general language\ntasks, yet adapting them to specific domains remains a challenge. Current\nmethod like Domain Adaptive Pretraining (DAPT) requires costly full-parameter\ntraining and suffers from catastrophic forgetting. Meanwhile,\nRetrieval-Augmented Generation (RAG) introduces substantial inference latency\ndue to expensive nearest-neighbor searches and longer context. This paper\nintroduces Memory Decoder, a plug-and-play pretrained memory that enables\nefficient domain adaptation without changing the original model's parameters.\nMemory Decoder employs a small transformer decoder that learns to imitate the\nbehavior of an external non-parametric retriever. Once trained, Memory Decoder\ncan be seamlessly integrated with any pretrained language model that shares the\nsame tokenizer, requiring no model-specific modifications. Experimental results\ndemonstrate that Memory Decoder enables effective adaptation of various Qwen\nand Llama models to three distinct specialized domains: biomedicine, finance,\nand law, reducing perplexity by an average of 6.17 points. Overall, Memory\nDecoder introduces a novel paradigm centered on a specially pretrained memory\ncomponent designed for domain-specific adaptation. This memory architecture can\nbe integrated in a plug-and-play manner, consistently enhancing performance\nacross multiple models within the target domain.", "published": "2025-08-13 15:16:29", "link": "http://arxiv.org/abs/2508.09874v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Assessing the Feasibility of Lightweight Whisper Models for Low-Resource Urdu Transcription", "abstract": "This study evaluates the feasibility of lightweight Whisper models (Tiny,\nBase, Small) for Urdu speech recognition in low-resource settings. Despite Urdu\nbeing the 10th most spoken language globally with over 230 million speakers,\nits representation in automatic speech recognition (ASR) systems remains\nlimited due to dialectal diversity, code-switching, and sparse training data.\nWe benchmark these models on a curated Urdu dataset using word error rate\n(WER), without fine-tuning. Results show Whisper-Small achieves the lowest\nerror rates (33.68\\% WER), outperforming Tiny (67.08\\% WER) and Base (53.67\\%\nWER). Qualitative analysis reveals persistent challenges in phonetic accuracy\nand lexical coherence, particularly for complex utterances. While Whisper-Small\ndemonstrates promise for deployable Urdu ASR, significant gaps remain. Our\nfindings emphasize lay the groundwork for future research into effective,\nlow-resource ASR systems.", "published": "2025-08-13 15:01:59", "link": "http://arxiv.org/abs/2508.09865v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts", "abstract": "We introduce PRELUDE, a benchmark for evaluating long-context understanding\nthrough the task of determining whether a character's prequel story is\nconsistent with the canonical narrative of the original book. Our task poses a\nstronger demand for global comprehension and deep reasoning than existing\nbenchmarks -- as the prequels are not part of the original story, assessing\ntheir plausibility typically requires searching and integrating information\nthat is only indirectly related. Empirically, 88% of instances require evidence\nfrom multiple parts of the narrative. Experimental results highlight the\nchallenge of our task: in-context learning, RAG and in-domain training with\nstate-of-the-art LLMs, and commercial DeepResearch services, lag behind humans\nby >15%. A further human study reveals that models often produce correct\nanswers with flawed reasoning, leading to an over 30% gap in reasoning accuracy\ncompared to humans. These findings underscore the substantial room for\nimprovement in long-context understanding and reasoning.", "published": "2025-08-13 14:28:25", "link": "http://arxiv.org/abs/2508.09848v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Speed Always Wins: A Survey on Efficient Architectures for Large Language Models", "abstract": "Large Language Models (LLMs) have delivered impressive results in language\nunderstanding, generation, reasoning, and pushes the ability boundary of\nmultimodal models. Transformer models, as the foundation of modern LLMs, offer\na strong baseline with excellent scaling properties. However, the traditional\ntransformer architecture requires substantial computations and poses\nsignificant obstacles for large-scale training and practical deployment. In\nthis survey, we offer a systematic examination of innovative LLM architectures\nthat address the inherent limitations of transformers and boost the efficiency.\nStarting from language modeling, this survey covers the background and\ntechnical details of linear and sparse sequence modeling methods, efficient\nfull attention variants, sparse mixture-of-experts, hybrid model architectures\nincorporating the above techniques, and emerging diffusion LLMs. Additionally,\nwe discuss applications of these techniques to other modalities and consider\ntheir wider implications for developing scalable, resource-aware foundation\nmodels. By grouping recent studies into the above category, this survey\npresents a blueprint of modern efficient LLM architectures, and we hope this\ncould help motivate future research toward more efficient, versatile AI\nsystems.", "published": "2025-08-13 14:13:46", "link": "http://arxiv.org/abs/2508.09834v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Survey of Datasets for Clinical Mental Health AI Systems", "abstract": "Mental health disorders are rising worldwide. However, the availability of\ntrained clinicians has not scaled proportionally, leaving many people without\nadequate or timely support. To bridge this gap, recent studies have shown the\npromise of Artificial Intelligence (AI) to assist mental health diagnosis,\nmonitoring, and intervention. However, the development of efficient, reliable,\nand ethical AI to assist clinicians is heavily dependent on high-quality\nclinical training datasets. Despite growing interest in data curation for\ntraining clinical AI assistants, existing datasets largely remain scattered,\nunder-documented, and often inaccessible, hindering the reproducibility,\ncomparability, and generalizability of AI models developed for clinical mental\nhealth care. In this paper, we present the first comprehensive survey of\nclinical mental health datasets relevant to the training and development of\nAI-powered clinical assistants. We categorize these datasets by mental\ndisorders (e.g., depression, schizophrenia), data modalities (e.g., text,\nspeech, physiological signals), task types (e.g., diagnosis prediction, symptom\nseverity estimation, intervention generation), accessibility (public,\nrestricted or private), and sociocultural context (e.g., language and cultural\nbackground). Along with these, we also investigate synthetic clinical mental\nhealth datasets. Our survey identifies critical gaps such as a lack of\nlongitudinal data, limited cultural and linguistic representation, inconsistent\ncollection and annotation standards, and a lack of modalities in synthetic\ndata. We conclude by outlining key challenges in curating and standardizing\nfuture datasets and provide actionable recommendations to facilitate the\ndevelopment of more robust, generalizable, and equitable mental health AI\nsystems.", "published": "2025-08-13 13:42:35", "link": "http://arxiv.org/abs/2508.09809v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "BigCharts-R1: Enhanced Chart Reasoning with Visual Reinforcement Finetuning", "abstract": "Charts are essential to data analysis, transforming raw data into clear\nvisual representations that support human decision-making. Although current\nvision-language models (VLMs) have made significant progress, they continue to\nstruggle with chart comprehension due to training on datasets that lack\ndiversity and real-world authenticity, or on automatically extracted underlying\ndata tables of charts, which can contain numerous estimation errors.\nFurthermore, existing models only rely on supervised fine-tuning using these\nlow-quality datasets, severely limiting their effectiveness. To address these\nissues, we first propose BigCharts, a dataset creation pipeline that generates\nvisually diverse chart images by conditioning the rendering process on\nreal-world charts sourced from multiple online platforms. Unlike purely\nsynthetic datasets, BigCharts incorporates real-world data, ensuring\nauthenticity and visual diversity, while still retaining accurate underlying\ndata due to our proposed replotting process. Additionally, we introduce a\ncomprehensive training framework that integrates supervised fine-tuning with\nGroup Relative Policy Optimization (GRPO)-based reinforcement learning. By\nintroducing novel reward signals specifically designed for chart reasoning, our\napproach enhances model robustness and generalization across diverse chart\nstyles and domains, resulting in a state-of-the-art chart reasoning model,\nBigCharts-R1. Extensive experiments demonstrate that our models surpass\nexisting methods on multiple chart question-answering benchmarks compared to\neven larger open-source and closed-source models.", "published": "2025-08-13 13:39:17", "link": "http://arxiv.org/abs/2508.09804v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adoption of Explainable Natural Language Processing: Perspectives from Industry and Academia on Practices and Challenges", "abstract": "The field of explainable natural language processing (NLP) has grown rapidly\nin recent years. The growing opacity of complex models calls for transparency\nand explanations of their decisions, which is crucial to understand their\nreasoning and facilitate deployment, especially in high-stakes environments.\nDespite increasing attention given to explainable NLP, practitioners'\nperspectives regarding its practical adoption and effectiveness remain\nunderexplored. This paper addresses this research gap by investigating\npractitioners' experiences with explainability methods, specifically focusing\non their motivations for adopting such methods, the techniques employed,\nsatisfaction levels, and the practical challenges encountered in real-world NLP\napplications. Through a qualitative interview-based study with industry\npractitioners and complementary interviews with academic researchers, we\nsystematically analyze and compare their perspectives. Our findings reveal\nconceptual gaps, low satisfaction with current explainability methods, and\nhighlight evaluation challenges. Our findings emphasize the need for clear\ndefinitions and user-centric frameworks for better adoption of explainable NLP\nin practice.", "published": "2025-08-13 13:12:18", "link": "http://arxiv.org/abs/2508.09786v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Can LLM-Generated Textual Explanations Enhance Model Classification Performance? An Empirical Study", "abstract": "In the rapidly evolving field of Explainable Natural Language Processing\n(NLP), textual explanations, i.e., human-like rationales, are pivotal for\nexplaining model predictions and enriching datasets with interpretable labels.\nTraditional approaches rely on human annotation, which is costly,\nlabor-intensive, and impedes scalability. In this work, we present an automated\nframework that leverages multiple state-of-the-art large language models (LLMs)\nto generate high-quality textual explanations. We rigorously assess the quality\nof these LLM-generated explanations using a comprehensive suite of Natural\nLanguage Generation (NLG) metrics. Furthermore, we investigate the downstream\nimpact of these explanations on the performance of pre-trained language models\n(PLMs) and LLMs across natural language inference tasks on two diverse\nbenchmark datasets. Our experiments demonstrate that automated explanations\nexhibit highly competitive effectiveness compared to human-annotated\nexplanations in improving model performance. Our findings underscore a\npromising avenue for scalable, automated LLM-based textual explanation\ngeneration for extending NLP datasets and enhancing model performance.", "published": "2025-08-13 12:59:08", "link": "http://arxiv.org/abs/2508.09776v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "UtterTune: LoRA-Based Target-Language Pronunciation Edit and Control in Multilingual Text-to-Speech", "abstract": "We propose UtterTune, a lightweight adaptation method that fine-tunes a\nmultilingual text-to-speech (TTS) system based on a large language model (LLM)\narchitecture, designed to enhance the controllability of pronunciation in a\ntarget language while preserving performance in others. While LLM architectures\nhave enabled TTS models to achieve remarkable naturalness, accurately modeling\ngrapheme-to-phoneme (G2P) mapping and prosody remains challenging, especially\nwhen the model omits an explicit G2P module and directly processes minimally\nencoded text (e.g., byte-pair encoding). UtterTune leverages low-rank\nadaptation to enable the control of segmental pronunciation and pitch accent at\nthe phoneme level for Japanese speech, the target language in this paper, while\nmaintaining naturalness and speaker similarity in a zero-shot setting.\nObjective and subjective evaluations confirm its effectiveness.", "published": "2025-08-13 12:52:38", "link": "http://arxiv.org/abs/2508.09767v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Transforming Questions and Documents for Semantically Aligned Retrieval-Augmented Generation", "abstract": "We introduce a novel retrieval-augmented generation (RAG) framework tailored\nfor multihop question answering. First, our system uses large language model\n(LLM) to decompose complex multihop questions into a sequence of single-hop\nsubquestions that guide document retrieval. This decomposition mitigates the\nambiguity inherent in multi-hop queries by clearly targeting distinct knowledge\nfacets. Second, instead of embedding raw or chunked documents directly, we\ngenerate answerable questions from each document chunk using Qwen3-8B, embed\nthese generated questions, and retrieve relevant chunks via question-question\nembedding similarity. During inference, the retrieved chunks are then fed along\nwith the original question into the RAG pipeline. We evaluate on three multihop\nquestion datasets (MuSiQue, 2WikiMultiHopQa, HotpotQA) from LongBench. Our\nmethod improves RAG performacne compared to baseline systems. Our contributions\nhighlight the benefits of using answerable-question embeddings for RAG, and the\neffectiveness of LLM-based query decomposition for multihop scenarios.", "published": "2025-08-13 12:35:04", "link": "http://arxiv.org/abs/2508.09755v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sample More to Think Less: Group Filtered Policy Optimization for Concise Reasoning", "abstract": "Large language models trained with reinforcement learning with verifiable\nrewards tend to trade accuracy for length--inflating response lengths to\nachieve gains in accuracy. While longer answers may be warranted for harder\nproblems, many tokens are merely \"filler\": repetitive, verbose text that makes\nno real progress. We introduce GFPO (Group Filtered Policy Optimization), which\ncurbs this length explosion by sampling larger groups per problem during\ntraining and filtering responses to train on based on two key metrics: (1)\nresponse length and (2) token efficiency: reward per token ratio. By sampling\nmore at training time, we teach models to think less at inference time. On the\nPhi-4-reasoning model, GFPO cuts GRPO's length inflation by 46-71% across\nchallenging STEM and coding benchmarks (AIME 24/25, GPQA, Omni-MATH,\nLiveCodeBench) while maintaining accuracy. Optimizing for reward per token\nfurther increases reductions in length inflation to 71-85%. We also propose\nAdaptive Difficulty GFPO, which dynamically allocates more training resources\nto harder problems based on real-time difficulty estimates, improving the\nbalance between computational efficiency and accuracy especially on difficult\nquestions. GFPO demonstrates that increased training-time compute directly\ntranslates to reduced test-time compute--a simple yet effective trade-off for\nefficient reasoning.", "published": "2025-08-13 11:43:49", "link": "http://arxiv.org/abs/2508.09726v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Perils of Chart Deception: How Misleading Visualizations Affect Vision-Language Models", "abstract": "Information visualizations are powerful tools that help users quickly\nidentify patterns, trends, and outliers, facilitating informed decision-making.\nHowever, when visualizations incorporate deceptive design elements-such as\ntruncated or inverted axes, unjustified 3D effects, or violations of best\npractices-they can mislead viewers and distort understanding, spreading\nmisinformation. While some deceptive tactics are obvious, others subtly\nmanipulate perception while maintaining a facade of legitimacy. As\nVision-Language Models (VLMs) are increasingly used to interpret\nvisualizations, especially by non-expert users, it is critical to understand\nhow susceptible these models are to deceptive visual designs. In this study, we\nconduct an in-depth evaluation of VLMs' ability to interpret misleading\nvisualizations. By analyzing over 16,000 responses from ten different models\nacross eight distinct types of misleading chart designs, we demonstrate that\nmost VLMs are deceived by them. This leads to altered interpretations of\ncharts, despite the underlying data remaining the same. Our findings highlight\nthe need for robust safeguards in VLMs against visual misinformation.", "published": "2025-08-13 11:11:18", "link": "http://arxiv.org/abs/2508.09716v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating the Role of Large Language Models in Legal Practice in India", "abstract": "The integration of Artificial Intelligence(AI) into the legal profession\nraises significant questions about the capacity of Large Language Models(LLM)\nto perform key legal tasks. In this paper, I empirically evaluate how well\nLLMs, such as GPT, Claude, and Llama, perform key legal tasks in the Indian\ncontext, including issue spotting, legal drafting, advice, research, and\nreasoning. Through a survey experiment, I compare outputs from LLMs with those\nof a junior lawyer, with advanced law students rating the work on helpfulness,\naccuracy, and comprehensiveness. LLMs excel in drafting and issue spotting,\noften matching or surpassing human work. However, they struggle with\nspecialised legal research, frequently generating hallucinations, factually\nincorrect or fabricated outputs. I conclude that while LLMs can augment certain\nlegal tasks, human expertise remains essential for nuanced reasoning and the\nprecise application of law.", "published": "2025-08-13 11:04:48", "link": "http://arxiv.org/abs/2508.09713v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Slow Tuning and Low-Entropy Masking for Safe Chain-of-Thought Distillation", "abstract": "Previous chain-of-thought (CoT) distillation methods primarily focused on\nenhancing the reasoning capabilities of Small Language Models (SLMs) by\nutilizing high-quality rationales generated by powerful Large Language Models\n(LLMs, e.g., GPT-4). However, few works have noted the negative effects on SLM\nsafety brought by the training, which are revealed in this study. Although\nthere are works on safety alignment that fine-tune language models or\nmanipulate model weights to defend against harmful inputs, they require extra\ncomputation or annotated data, and probably impact the reasoning ability of\nSLMs. In this paper, we investigate how to maintain the safety of SLMs during\nthe CoT distillation process. Specifically, we propose a safe distillation\nmethod, Slow Tuning and Low-Entropy Masking Distillation (SLowED), containing\ntwo modules: Slow Tuning and Low-Entropy Masking. Slow Tuning scales down the\nmagnitude of model weight changes to optimize the model weights in the\nneighboring space near the initial weight distribution. Low-Entropy Masking\nmasks low-entropy tokens, which are regarded as unnecessary learning targets,\nto exclude them from fine-tuning. Experiments on three SLMs (Qwen2.5-1.5B,\nLlama-3.2-1B, BLOOM-1.1B) across reasoning benchmarks (BBH, BB-Sub, ARC,\nAGIEval) and safety evaluation (AdvBench) show that SLowED retains the safety\nof SLMs and comparably improves their reasoning capability compared to existing\ndistillation methods. Furthermore, our ablation study presents the\neffectiveness of Slow Tuning and Low-Entropy Masking, with the former\nmaintaining the model's safety in the early stage and the latter prolonging the\nsafe training epochs.", "published": "2025-08-13 09:56:08", "link": "http://arxiv.org/abs/2508.09666v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EffiEval: Efficient and Generalizable Model Evaluation via Capability Coverage Maximization", "abstract": "The rapid advancement of large language models (LLMs) and the development of\nincreasingly large and diverse evaluation benchmarks have introduced\nsubstantial computational challenges for model assessment. In this paper, we\npresent EffiEval, a training-free approach for efficient benchmarking that\neffectively addresses data redundancy while maintaining high evaluation\nreliability. Our method is specifically designed to meet three key criteria for\nhigh-quality evaluation: representativeness, by ensuring comprehensive coverage\nof model capabilities; fairness, by remaining independent of model performance\nduring sample selection to avoid bias; and generalizability, by enabling\nflexible transfer across datasets and model families without reliance on\nlarge-scale evaluation data. Unlike traditional methods that rely on absolute\nperformance or require extensive evaluation data, our approach adaptively\nselects high-quality representative subsets based on the Model Utility Index\n(MUI). Extensive experiments on multiple public benchmarks and diverse LLMs\ndemonstrate that EffiEval achieves strong ranking consistency with full-dataset\nevaluation using only a small fraction of the original data. Furthermore, our\nmethod is flexible and scalable in size, allowing users to balance evaluation\nefficiency and representativeness according to specific needs. Overall,\nEffiEval provides a practical and generalizable solution for reliable, fair,\nand efficient evaluation in the era of LLMs.", "published": "2025-08-13 09:48:23", "link": "http://arxiv.org/abs/2508.09662v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Diversity in Language Models: When Temperature Fails, Change the Loss", "abstract": "Increasing diversity in language models is a challenging yet essential\nobjective. A common approach is to raise the decoding temperature. In this\nwork, we investigate this approach through a simplistic yet common case to\nprovide insights into why decreasing temperature can improve quality\n(Precision), while increasing it often fails to boost coverage (Recall). Our\nanalysis reveals that for a model to be effectively tunable through temperature\nadjustments, it must be trained toward coverage. To address this, we propose\nrethinking loss functions in language models by leveraging the Precision-Recall\nframework. Our results demonstrate that this approach achieves a substantially\nbetter trade-off between Precision and Recall than merely combining negative\nlog-likelihood training with temperature scaling. These findings offer a\npathway toward more versatile and robust language modeling techniques.", "published": "2025-08-13 09:37:53", "link": "http://arxiv.org/abs/2508.09654v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Close Reading Approach to Gender Narrative Biases in AI-Generated Stories", "abstract": "The paper explores the study of gender-based narrative biases in stories\ngenerated by ChatGPT, Gemini, and Claude. The prompt design draws on Propp's\ncharacter classifications and Freytag's narrative structure. The stories are\nanalyzed through a close reading approach, with particular attention to\nadherence to the prompt, gender distribution of characters, physical and\npsychological descriptions, actions, and finally, plot development and\ncharacter relationships. The results reveal the persistence of biases -\nespecially implicit ones - in the generated stories and highlight the\nimportance of assessing biases at multiple levels using an interpretative\napproach.", "published": "2025-08-13 09:34:37", "link": "http://arxiv.org/abs/2508.09651v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.HC"}
{"title": "AINL-Eval 2025 Shared Task: Detection of AI-Generated Scientific Abstracts in Russian", "abstract": "The rapid advancement of large language models (LLMs) has revolutionized text\ngeneration, making it increasingly difficult to distinguish between human- and\nAI-generated content. This poses a significant challenge to academic integrity,\nparticularly in scientific publishing and multilingual contexts where detection\nresources are often limited. To address this critical gap, we introduce the\nAINL-Eval 2025 Shared Task, specifically focused on the detection of\nAI-generated scientific abstracts in Russian. We present a novel, large-scale\ndataset comprising 52,305 samples, including human-written abstracts across 12\ndiverse scientific domains and AI-generated counterparts from five\nstate-of-the-art LLMs (GPT-4-Turbo, Gemma2-27B, Llama3.3-70B, Deepseek-V3, and\nGigaChat-Lite). A core objective of the task is to challenge participants to\ndevelop robust solutions capable of generalizing to both (i) previously unseen\nscientific domains and (ii) models not included in the training data. The task\nwas organized in two phases, attracting 10 teams and 159 submissions, with top\nsystems demonstrating strong performance in identifying AI-generated content.\nWe also establish a continuous shared task platform to foster ongoing research\nand long-term progress in this important area. The dataset and platform are\npublicly available at https://github.com/iis-research-team/AINL-Eval-2025.", "published": "2025-08-13 08:53:17", "link": "http://arxiv.org/abs/2508.09622v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Persuasive Could LLMs Be? A First Study Combining Linguistic-Rhetorical Analysis and User Experiments", "abstract": "This study examines the rhetorical and linguistic features of argumentative\ntexts generated by ChatGPT on ethically nuanced topics and investigates their\npersuasive impact on human readers.Through a user study involving 62\nparticipants and pre-post interaction surveys, the paper analyzes how exposure\nto AI-generated arguments affects opinion change and user perception. A\nlinguistic and rhetorical analysis of the generated texts reveals a consistent\nargumentative macrostructure, reliance on formulaic expressions, and limited\nstylistic richness. While ChatGPT demonstrates proficiency in constructing\ncoherent argumentative texts, its persuasive efficacy appears constrained,\nparticularly on topics involving ethical issues.The study finds that while\nparticipants often acknowledge the benefits highlighted by ChatGPT, ethical\nconcerns tend to persist or even intensify post-interaction. The results also\ndemonstrate a variation depending on the topic. These findings highlight new\ninsights on AI-generated persuasion in ethically sensitive domains and are a\nbasis for future research.", "published": "2025-08-13 08:45:04", "link": "http://arxiv.org/abs/2508.09614v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.HC"}
{"title": "The Surprising Effectiveness of Membership Inference with Simple N-Gram Coverage", "abstract": "Membership inference attacks serves as useful tool for fair use of language\nmodels, such as detecting potential copyright infringement and auditing data\nleakage. However, many current state-of-the-art attacks require access to\nmodels' hidden states or probability distribution, which prevents investigation\ninto more widely-used, API-access only models like GPT-4. In this work, we\nintroduce N-Gram Coverage Attack, a membership inference attack that relies\nsolely on text outputs from the target model, enabling attacks on completely\nblack-box models. We leverage the observation that models are more likely to\nmemorize and subsequently generate text patterns that were commonly observed in\ntheir training data. Specifically, to make a prediction on a candidate member,\nN-Gram Coverage Attack first obtains multiple model generations conditioned on\na prefix of the candidate. It then uses n-gram overlap metrics to compute and\naggregate the similarities of these outputs with the ground truth suffix; high\nsimilarities indicate likely membership. We first demonstrate on a diverse set\nof existing benchmarks that N-Gram Coverage Attack outperforms other black-box\nmethods while also impressively achieving comparable or even better performance\nto state-of-the-art white-box attacks - despite having access to only text\noutputs. Interestingly, we find that the success rate of our method scales with\nthe attack compute budget - as we increase the number of sequences generated\nfrom the target model conditioned on the prefix, attack performance tends to\nimprove. Having verified the accuracy of our method, we use it to investigate\npreviously unstudied closed OpenAI models on multiple domains. We find that\nmore recent models, such as GPT-4o, exhibit increased robustness to membership\ninference, suggesting an evolving trend toward improved privacy protections.", "published": "2025-08-13 08:35:16", "link": "http://arxiv.org/abs/2508.09603v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AI Blob! LLM-Driven Recontextualization of Italian Television Archives", "abstract": "This paper introduces AI Blob!, an experimental system designed to explore\nthe potential of semantic cataloging and Large Language Models (LLMs) for the\nretrieval and recontextualization of archival television footage. Drawing\nmethodological inspiration from Italian television programs such as Blob (RAI\nTre, 1989-), AI Blob! integrates automatic speech recognition (ASR), semantic\nembeddings, and retrieval-augmented generation (RAG) to organize and\nreinterpret archival content. The system processes a curated dataset of 1,547\nItalian television videos by transcribing audio, segmenting it into\nsentence-level units, and embedding these segments into a vector database for\nsemantic querying. Upon user input of a thematic prompt, the LLM generates a\nrange of linguistically and conceptually related queries, guiding the retrieval\nand recombination of audiovisual fragments. These fragments are algorithmically\nselected and structured into narrative sequences producing montages that\nemulate editorial practices of ironic juxtaposition and thematic coherence. By\nforegrounding dynamic, content-aware retrieval over static metadata schemas, AI\nBlob! demonstrates how semantic technologies can facilitate new approaches to\narchival engagement, enabling novel forms of automated narrative construction\nand cultural analysis. The project contributes to ongoing debates in media\nhistoriography and AI-driven archival research, offering both a conceptual\nframework and a publicly available dataset to support further interdisciplinary\nexperimentation.", "published": "2025-08-13 06:38:32", "link": "http://arxiv.org/abs/2508.09535v1", "categories": ["cs.MM", "cs.AI", "cs.CL", "cs.DL"], "primary_category": "cs.MM"}
{"title": "COMPEER: Controllable Empathetic Reinforcement Reasoning for Emotional Support Conversation", "abstract": "Emotional support conversations are crucial for promoting emotional\nwell-being, yet current models often lack deep empathetic reasoning grounded in\npsychological principles. To address this, we propose controllable empathetic\nreasoning, which combines natural language reasoning with structured\npsychological steps. We construct a fine-grained dataset annotated with\nreasoning correctness and response preferences to enable this capability. To\nfurther enhance training, we employ reinforcement learning with a unified\nprocess-outcome reward model that delivers precise feedback. To mitigate\nresponse repetitiveness from entropy collapse, we introduce personality-based\ndialogue rewriting and a redundancy-aware reward reweighting strategy. Our\napproach significantly improves model's emotional support ability, advancing\nthe development of empathetic, human-like support systems.", "published": "2025-08-13 06:09:32", "link": "http://arxiv.org/abs/2508.09521v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "UWBa at SemEval-2025 Task 7: Multilingual and Crosslingual Fact-Checked Claim Retrieval", "abstract": "This paper presents a zero-shot system for fact-checked claim retrieval. We\nemployed several state-of-the-art large language models to obtain text\nembeddings. The models were then combined to obtain the best possible result.\nOur approach achieved 7th place in monolingual and 9th in cross-lingual\nsubtasks. We used only English translations as an input to the text embedding\nmodels since multilingual models did not achieve satisfactory results. We\nidentified the most relevant claims for each post by leveraging the embeddings\nand measuring cosine similarity. Overall, the best results were obtained by the\nNVIDIA NV-Embed-v2 model. For some languages, we benefited from model\ncombinations (NV-Embed & GPT or Mistral).", "published": "2025-08-13 05:55:59", "link": "http://arxiv.org/abs/2508.09517v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-lingual Aspect-Based Sentiment Analysis: A Survey on Tasks, Approaches, and Challenges", "abstract": "Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment analysis\ntask that focuses on understanding opinions at the aspect level, including\nsentiment towards specific aspect terms, categories, and opinions. While ABSA\nresearch has seen significant progress, much of the focus has been on\nmonolingual settings. Cross-lingual ABSA, which aims to transfer knowledge from\nresource-rich languages (such as English) to low-resource languages, remains an\nunder-explored area, with no systematic review of the field. This paper aims to\nfill that gap by providing a comprehensive survey of cross-lingual ABSA. We\nsummarize key ABSA tasks, including aspect term extraction, aspect sentiment\nclassification, and compound tasks involving multiple sentiment elements.\nAdditionally, we review the datasets, modelling paradigms, and cross-lingual\ntransfer methods used to solve these tasks. We also examine how existing work\nin monolingual and multilingual ABSA, as well as ABSA with LLMs, contributes to\nthe development of cross-lingual ABSA. Finally, we highlight the main\nchallenges and suggest directions for future research to advance cross-lingual\nABSA systems.", "published": "2025-08-13 05:55:53", "link": "http://arxiv.org/abs/2508.09516v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LACA: Improving Cross-lingual Aspect-Based Sentiment Analysis with LLM Data Augmentation", "abstract": "Cross-lingual aspect-based sentiment analysis (ABSA) involves detailed\nsentiment analysis in a target language by transferring knowledge from a source\nlanguage with available annotated data. Most existing methods depend heavily on\noften unreliable translation tools to bridge the language gap. In this paper,\nwe propose a new approach that leverages a large language model (LLM) to\ngenerate high-quality pseudo-labelled data in the target language without the\nneed for translation tools. First, the framework trains an ABSA model to obtain\npredictions for unlabelled target language data. Next, LLM is prompted to\ngenerate natural sentences that better represent these noisy predictions than\nthe original text. The ABSA model is then further fine-tuned on the resulting\npseudo-labelled dataset. We demonstrate the effectiveness of this method across\nsix languages and five backbone models, surpassing previous state-of-the-art\ntranslation-based approaches. The proposed framework also supports generative\nmodels, and we show that fine-tuned LLMs outperform smaller multilingual\nmodels.", "published": "2025-08-13 05:55:48", "link": "http://arxiv.org/abs/2508.09515v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Ranking to Selection: A Simple but Efficient Dynamic Passage Selector for Retrieval Augmented Generation", "abstract": "Retrieval-augmented generation (RAG) systems are often bottlenecked by their\nreranking modules, which typically score passages independently and select a\nfixed Top-K size. This approach struggles with complex multi-hop queries that\nrequire synthesizing evidence across multiple documents, creating a trade-off\nwhere small K values omit crucial information and large K values introduce\nnoise. To address this, we introduce the Dynamic Passage Selector (DPS), a\nnovel reranking framework that treats passage selection as a supervised\nlearning problem. Unlike traditional point-wise or list-wise methods, DPS is\nfine-tuned to capture inter-passage dependencies and dynamically select the\nmost relevant set of passages for generation. As a seamless plug-and-play\nmodule, DPS requires no modifications to the standard RAG pipeline.\nComprehensive evaluations on five benchmarks show that DPS consistently\noutperforms state-of-the-art rerankers and fine-tuning methods. Notably, on the\nchallenging MuSiQue dataset, DPS improves the F1-score by 30.06% and 15.4% over\nstrong baselines like Qwen3-reranker and RankingGPT, respectively. Our results\ndemonstrate that by enabling adaptive evidence selection, DPS substantially\nenhances reasoning capabilities in complex RAG scenarios.", "published": "2025-08-13 05:05:34", "link": "http://arxiv.org/abs/2508.09497v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learning Facts at Scale with Active Reading", "abstract": "LLMs are known to store vast amounts of knowledge in their parametric memory.\nHowever, learning and recalling facts from this memory is known to be\nunreliable, depending largely on the prevalence of particular facts in the\ntraining data and other factors which are poorly understood. Practitioners are\nlacking tools which will allow them to ensure that the models learn a given\nbody of knowledge reliably and consistently. To this end, we propose Active\nReading: a framework where we train models to study a given set of material\nwith self-generated learning strategies. First, we demonstrate models trained\nwith Active Reading on expert domains absorb significantly more knowledge than\nvanilla finetuning and other data augmentations. We train expert 8B models that\nachieve 66% on a Wikipedia-grounded subset of SimpleQA (+313% relative over\nvanilla finetuning) and 26% on FinanceBench (+160% relative over vanilla\nfinetuning) by applying Active Reading to the source documents for each\nbenchmark. Finally, we show that Active Reading can be utilized at pre-training\nscale to build more factual models. As a demonstration of this, we release Meta\nWikiExpert-8B, a Wikipedia-expert model trained on 1 trillion generated tokens,\nwhich outcompetes models with hundreds of billions of parameters on factual QA.", "published": "2025-08-13 04:54:43", "link": "http://arxiv.org/abs/2508.09494v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "NeuronTune: Fine-Grained Neuron Modulation for Balanced Safety-Utility Alignment in LLMs", "abstract": "Ensuring robust safety alignment while preserving utility is critical for the\nreliable deployment of Large Language Models (LLMs). However, current\ntechniques fundamentally suffer from intertwined deficiencies: insufficient\nrobustness against malicious attacks, frequent refusal of benign queries,\ndegradation in generated text quality and general task performance--the former\ntwo reflecting deficits in robust safety and the latter constituting utility\nimpairment. We trace these limitations to the coarse-grained layer-wise\ninterventions in existing methods. To resolve this, we propose NeuronTune, a\nfine-grained framework that dynamically modulates sparse neurons to achieve\nsimultaneous safety-utility optimization. Our approach first identifies\nsafety-critical and utility-preserving neurons across all layers via\nattribution, then employs meta-learning to adaptively amplify safety-neuron\nactivations and suppress utility-neuron activations. Crucially, NeuronTune\nenables tunable adjustment of intervention scope via neuron-count thresholds,\nsupporting flexible adaptation to security-critical or utility-priority\nscenarios. Extensive experimental results demonstrate that our method\nsignificantly outperforms existing state-of-the-art technologies, achieving\nsuperior model safety while maintaining excellent utility.", "published": "2025-08-13 04:05:28", "link": "http://arxiv.org/abs/2508.09473v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "User-centric Subjective Leaderboard by Customizable Reward Modeling", "abstract": "Existing benchmarks for large language models (LLMs) predominantely focus on\nassessing their capabilities through verifiable tasks. Such objective and\nstatic benchmarks offer limited utility for practical LLM selection, making it\ndifficult for users to find suitable models for their individual needs. To\nbridge this gap, we present the first User-Centric Subjective Leaderboard\n(USL), which provides a preference-driven, dynamic ranking of LLMs across\ndiverse real-world scenarios. Our work is built upon a thorough investigation\nof real human preference data, involving more than 10K subjective queries. Our\ninvestigation reveals significant diversity and contradictions in human\npreferences, which limit the effectiveness of state-of-the-art reward models.\nTo address this, we introduce Customizable Reward Models (CRMs). With only 4B\nparameters, our CRM surpasses the performance of leading models such as GPT-4.1\nand Gemini-2.5-pro, showing exceptional generalization capabilities across new\ntopics and criteria. The USL, powered by CRMs, exhibits strong negative\ncorrelations to contradictory preferences.", "published": "2025-08-13 03:39:04", "link": "http://arxiv.org/abs/2508.09463v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IAG: Input-aware Backdoor Attack on VLMs for Visual Grounding", "abstract": "Vision-language models (VLMs) have shown significant advancements in tasks\nsuch as visual grounding, where they localize specific objects in images based\non natural language queries and images. However, security issues in visual\ngrounding tasks for VLMs remain underexplored, especially in the context of\nbackdoor attacks. In this paper, we introduce a novel input-aware backdoor\nattack method, IAG, designed to manipulate the grounding behavior of VLMs. This\nattack forces the model to ground a specific target object in the input image,\nregardless of the user's query. We propose an adaptive trigger generator that\nembeds the semantic information of the attack target's description into the\noriginal image using a text-conditional U-Net, thereby overcoming the\nopen-vocabulary attack challenge. To ensure the attack's stealthiness, we\nutilize a reconstruction loss to minimize visual discrepancies between poisoned\nand clean images. Additionally, we introduce a unified method for generating\nattack data. IAG is evaluated theoretically and empirically, demonstrating its\nfeasibility and effectiveness. Notably, our ASR@0.5 on InternVL-2.5-8B reaches\nover 65\\% on various testing sets. IAG also shows promising potential on\nmanipulating Ferret-7B and LlaVA-1.5-7B with very little accuracy decrease on\nclean samples. Extensive specific experiments, such as ablation study and\npotential defense, also indicate the robustness and transferability of our\nattack.", "published": "2025-08-13 03:22:19", "link": "http://arxiv.org/abs/2508.09456v1", "categories": ["cs.CV", "cs.CL", "cs.CR"], "primary_category": "cs.CV"}
{"title": "From Charts to Fair Narratives: Uncovering and Mitigating Geo-Economic Biases in Chart-to-Text", "abstract": "Charts are very common for exploring data and communicating insights, but\nextracting key takeaways from charts and articulating them in natural language\ncan be challenging. The chart-to-text task aims to automate this process by\ngenerating textual summaries of charts. While with the rapid advancement of\nlarge Vision-Language Models (VLMs), we have witnessed great progress in this\ndomain, little to no attention has been given to potential biases in their\noutputs. This paper investigates how VLMs can amplify geo-economic biases when\ngenerating chart summaries, potentially causing societal harm. Specifically, we\nconduct a large-scale evaluation of geo-economic biases in VLM-generated chart\nsummaries across 6,000 chart-country pairs from six widely used proprietary and\nopen-source models to understand how a country's economic status influences the\nsentiment of generated summaries. Our analysis reveals that existing VLMs tend\nto produce more positive descriptions for high-income countries compared to\nmiddle- or low-income countries, even when country attribution is the only\nvariable changed. We also find that models such as GPT-4o-mini,\nGemini-1.5-Flash, and Phi-3.5 exhibit varying degrees of bias. We further\nexplore inference-time prompt-based debiasing techniques using positive\ndistractors but find them only partially effective, underscoring the complexity\nof the issue and the need for more robust debiasing strategies. Our code and\ndataset are publicly available here.", "published": "2025-08-13 03:09:00", "link": "http://arxiv.org/abs/2508.09450v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Shadow in the Cache: Unveiling and Mitigating Privacy Risks of KV-cache in LLM Inference", "abstract": "The Key-Value (KV) cache, which stores intermediate attention computations\n(Key and Value pairs) to avoid redundant calculations, is a fundamental\nmechanism for accelerating Large Language Model (LLM) inference. However, this\nefficiency optimization introduces significant yet underexplored privacy risks.\nThis paper provides the first comprehensive analysis of these vulnerabilities,\ndemonstrating that an attacker can reconstruct sensitive user inputs directly\nfrom the KV-cache. We design and implement three distinct attack vectors: a\ndirect Inversion Attack, a more broadly applicable and potent Collision Attack,\nand a semantic-based Injection Attack. These methods demonstrate the\npracticality and severity of KV-cache privacy leakage issues. To mitigate this,\nwe propose KV-Cloak, a novel, lightweight, and efficient defense mechanism.\nKV-Cloak uses a reversible matrix-based obfuscation scheme, combined with\noperator fusion, to secure the KV-cache. Our extensive experiments show that\nKV-Cloak effectively thwarts all proposed attacks, reducing reconstruction\nquality to random noise. Crucially, it achieves this robust security with\nvirtually no degradation in model accuracy and minimal performance overhead,\noffering a practical solution for trustworthy LLM deployment.", "published": "2025-08-13 02:48:25", "link": "http://arxiv.org/abs/2508.09442v1", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Leveraging Zipformer Model for Effective Language Identification in Code-Switched Child-Directed Speech", "abstract": "Code-switching and language identification in child-directed scenarios\npresent significant challenges, particularly in bilingual environments. This\npaper addresses this challenge by using Zipformer to handle the nuances of\nspeech, which contains two imbalanced languages, Mandarin and English, in an\nutterance. This work demonstrates that the internal layers of the Zipformer\neffectively encode the language characteristics, which can be leveraged in\nlanguage identification. We present the selection methodology of the inner\nlayers to extract the embeddings and make a comparison with different\nback-ends. Our analysis shows that Zipformer is robust across these backends.\nOur approach effectively handles imbalanced data, achieving a Balanced Accuracy\n(BAC) of 81.89%, a 15.47% improvement over the language identification\nbaseline. These findings highlight the potential of the transformer encoder\narchitecture model in real scenarios.", "published": "2025-08-13 02:10:31", "link": "http://arxiv.org/abs/2508.09430v1", "categories": ["cs.CL", "cs.SD"], "primary_category": "cs.CL"}
{"title": "Columbo: Expanding Abbreviated Column Names for Tabular Data Using Large Language Models", "abstract": "Expanding the abbreviated column names of tables, such as ``esal'' to\n``employee salary'', is critical for numerous downstream data tasks. This\nproblem arises in enterprises, domain sciences, government agencies, and more.\nIn this paper we make three contributions that significantly advances the state\nof the art. First, we show that synthetic public data used by prior work has\nmajor limitations, and we introduce 4 new datasets in enterprise/science\ndomains, with real-world abbreviations. Second, we show that accuracy measures\nused by prior work seriously undercount correct expansions, and we propose new\nsynonym-aware measures that capture accuracy much more accurately. Finally, we\ndevelop Columbo, a powerful LLM-based solution that exploits context, rules,\nchain-of-thought reasoning, and token-level analysis. Extensive experiments\nshow that Columbo significantly outperforms NameGuess, the current most\nadvanced solution, by 4-29\\%, over 5 datasets. Columbo has been used in\nproduction on EDI, a major data portal for environmental sciences.", "published": "2025-08-13 00:39:22", "link": "http://arxiv.org/abs/2508.09403v1", "categories": ["cs.CL", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Vision-driven River Following of UAV via Safe Reinforcement Learning using Semantic Dynamics Model", "abstract": "Vision-driven autonomous river following by Unmanned Aerial Vehicles is\ncritical for applications such as rescue, surveillance, and environmental\nmonitoring, particularly in dense riverine environments where GPS signals are\nunreliable. We formalize river following as a coverage control problem in which\nthe reward function is submodular, yielding diminishing returns as more unique\nriver segments are visited, thereby framing the task as a Submodular Markov\nDecision Process. First, we introduce Marginal Gain Advantage Estimation, which\nrefines the reward advantage function by using a sliding window baseline\ncomputed from historical episodic returns, thus aligning the advantage\nestimation with the agent's evolving recognition of action value in\nnon-Markovian settings. Second, we develop a Semantic Dynamics Model based on\npatchified water semantic masks that provides more interpretable and\ndata-efficient short-term prediction of future observations compared to latent\nvision dynamics models. Third, we present the Constrained Actor Dynamics\nEstimator architecture, which integrates the actor, the cost estimator, and SDM\nfor cost advantage estimation to form a model-based SafeRL framework capable of\nsolving partially observable Constrained Submodular Markov Decision Processes.\nSimulation results demonstrate that MGAE achieves faster convergence and\nsuperior performance over traditional critic-based methods like Generalized\nAdvantage Estimation. SDM provides more accurate short-term state predictions\nthat enable the cost estimator to better predict potential violations. Overall,\nCADE effectively integrates safety regulation into model-based RL, with the\nLagrangian approach achieving the soft balance of reward and safety during\ntraining, while the safety layer enhances performance during inference by hard\naction overlay.", "published": "2025-08-13 17:39:09", "link": "http://arxiv.org/abs/2508.09971v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "January Food Benchmark (JFB): A Public Benchmark Dataset and Evaluation Suite for Multimodal Food Analysis", "abstract": "Progress in AI for automated nutritional analysis is critically hampered by\nthe lack of standardized evaluation methodologies and high-quality, real-world\nbenchmark datasets. To address this, we introduce three primary contributions.\nFirst, we present the January Food Benchmark (JFB), a publicly available\ncollection of 1,000 food images with human-validated annotations. Second, we\ndetail a comprehensive benchmarking framework, including robust metrics and a\nnovel, application-oriented overall score designed to assess model performance\nholistically. Third, we provide baseline results from both general-purpose\nVision-Language Models (VLMs) and our own specialized model,\njanuary/food-vision-v1. Our evaluation demonstrates that the specialized model\nachieves an Overall Score of 86.2, a 12.1-point improvement over the\nbest-performing general-purpose configuration. This work offers the research\ncommunity a valuable new evaluation dataset and a rigorous framework to guide\nand benchmark future developments in automated nutritional analysis.", "published": "2025-08-13 17:32:40", "link": "http://arxiv.org/abs/2508.09966v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "GBC: Generalized Behavior-Cloning Framework for Whole-Body Humanoid Imitation", "abstract": "The creation of human-like humanoid robots is hindered by a fundamental\nfragmentation: data processing and learning algorithms are rarely universal\nacross different robot morphologies. This paper introduces the Generalized\nBehavior Cloning (GBC) framework, a comprehensive and unified solution designed\nto solve this end-to-end challenge. GBC establishes a complete pathway from\nhuman motion to robot action through three synergistic innovations. First, an\nadaptive data pipeline leverages a differentiable IK network to automatically\nretarget any human MoCap data to any humanoid. Building on this foundation, our\nnovel DAgger-MMPPO algorithm with its MMTransformer architecture learns robust,\nhigh-fidelity imitation policies. To complete the ecosystem, the entire\nframework is delivered as an efficient, open-source platform based on Isaac\nLab, empowering the community to deploy the full workflow via simple\nconfiguration scripts. We validate the power and generality of GBC by training\npolicies on multiple heterogeneous humanoids, demonstrating excellent\nperformance and transfer to novel motions. This work establishes the first\npractical and unified pathway for creating truly generalized humanoid\ncontrollers.", "published": "2025-08-13 17:28:39", "link": "http://arxiv.org/abs/2508.09960v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Mathematical Computation and Reasoning Errors by Large Language Models", "abstract": "Large Language Models (LLMs) are increasingly utilized in AI-driven\neducational instruction and assessment, particularly within mathematics\neducation. The capability of LLMs to generate accurate answers and detailed\nsolutions for math problem-solving tasks is foundational for ensuring reliable\nand precise feedback and assessment in math education practices. Our study\nfocuses on evaluating the accuracy of four LLMs (OpenAI GPT-4o and o1,\nDeepSeek-V3 and DeepSeek-R1) solving three categories of math tasks, including\narithmetic, algebra, and number theory, and identifies step-level reasoning\nerrors within their solutions. Instead of relying on standard benchmarks, we\nintentionally build math tasks (via item models) that are challenging for LLMs\nand prone to errors. The accuracy of final answers and the presence of errors\nin individual solution steps were systematically analyzed and coded. Both\nsingle-agent and dual-agent configurations were tested. It is observed that the\nreasoning-enhanced OpenAI o1 model consistently achieved higher or nearly\nperfect accuracy across all three math task categories. Analysis of errors\nrevealed that procedural slips were the most frequent and significantly\nimpacted overall performance, while conceptual misunderstandings were less\nfrequent. Deploying dual-agent configurations substantially improved overall\nperformance. These findings offer actionable insights into enhancing LLM\nperformance and underscore effective strategies for integrating LLMs into\nmathematics education, thereby advancing AI-driven instructional practices and\nassessment precision.", "published": "2025-08-13 16:33:02", "link": "http://arxiv.org/abs/2508.09932v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Residual Reservoir Memory Networks", "abstract": "We introduce a novel class of untrained Recurrent Neural Networks (RNNs)\nwithin the Reservoir Computing (RC) paradigm, called Residual Reservoir Memory\nNetworks (ResRMNs). ResRMN combines a linear memory reservoir with a non-linear\nreservoir, where the latter is based on residual orthogonal connections along\nthe temporal dimension for enhanced long-term propagation of the input. The\nresulting reservoir state dynamics are studied through the lens of linear\nstability analysis, and we investigate diverse configurations for the temporal\nresidual connections. The proposed approach is empirically assessed on\ntime-series and pixel-level 1-D classification tasks. Our experimental results\nhighlight the advantages of the proposed approach over other conventional RC\nmodels.", "published": "2025-08-13 16:21:29", "link": "http://arxiv.org/abs/2508.09925v1", "categories": ["cs.LG", "cs.AI", "I.2.6"], "primary_category": "cs.LG"}
{"title": "T-CACE: A Time-Conditioned Autoregressive Contrast Enhancement Multi-Task Framework for Contrast-Free Liver MRI Synthesis, Segmentation, and Diagnosis", "abstract": "Magnetic resonance imaging (MRI) is a leading modality for the diagnosis of\nliver cancer, significantly improving the classification of the lesion and\npatient outcomes. However, traditional MRI faces challenges including risks\nfrom contrast agent (CA) administration, time-consuming manual assessment, and\nlimited annotated datasets. To address these limitations, we propose a\nTime-Conditioned Autoregressive Contrast Enhancement (T-CACE) framework for\nsynthesizing multi-phase contrast-enhanced MRI (CEMRI) directly from\nnon-contrast MRI (NCMRI). T-CACE introduces three core innovations: a\nconditional token encoding (CTE) mechanism that unifies anatomical priors and\ntemporal phase information into latent representations; and a dynamic\ntime-aware attention mask (DTAM) that adaptively modulates inter-phase\ninformation flow using a Gaussian-decayed attention mechanism, ensuring smooth\nand physiologically plausible transitions across phases. Furthermore, a\nconstraint for temporal classification consistency (TCC) aligns the lesion\nclassification output with the evolution of the physiological signal, further\nenhancing diagnostic reliability. Extensive experiments on two independent\nliver MRI datasets demonstrate that T-CACE outperforms state-of-the-art methods\nin image synthesis, segmentation, and lesion classification. This framework\noffers a clinically relevant and efficient alternative to traditional\ncontrast-enhanced imaging, improving safety, diagnostic efficiency, and\nreliability for the assessment of liver lesion. The implementation of T-CACE is\npublicly available at: https://github.com/xiaojiao929/T-CACE.", "published": "2025-08-13 16:14:14", "link": "http://arxiv.org/abs/2508.09919v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Beyond Na\u00efve Prompting: Strategies for Improved Zero-shot Context-aided Forecasting with LLMs", "abstract": "Forecasting in real-world settings requires models to integrate not only\nhistorical data but also relevant contextual information, often available in\ntextual form. While recent work has shown that large language models (LLMs) can\nbe effective context-aided forecasters via na\\\"ive direct prompting, their full\npotential remains underexplored. We address this gap with 4 strategies,\nproviding new insights into the zero-shot capabilities of LLMs in this setting.\nReDP improves interpretability by eliciting explicit reasoning traces, allowing\nus to assess the model's reasoning over the context independently from its\nforecast accuracy. CorDP leverages LLMs solely to refine existing forecasts\nwith context, enhancing their applicability in real-world forecasting\npipelines. IC-DP proposes embedding historical examples of context-aided\nforecasting tasks in the prompt, substantially improving accuracy even for the\nlargest models. Finally, RouteDP optimizes resource efficiency by using LLMs to\nestimate task difficulty, and routing the most challenging tasks to larger\nmodels. Evaluated on different kinds of context-aided forecasting tasks from\nthe CiK benchmark, our strategies demonstrate distinct benefits over na\\\"ive\nprompting across LLMs of different sizes and families. These results open the\ndoor to further simple yet effective improvements in LLM-based context-aided\nforecasting.", "published": "2025-08-13 16:02:55", "link": "http://arxiv.org/abs/2508.09904v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Rare anomalies require large datasets: About proving the existence of anomalies", "abstract": "Detecting whether any anomalies exist within a dataset is crucial for\neffective anomaly detection, yet it remains surprisingly underexplored in\nanomaly detection literature. This paper presents a comprehensive study that\naddresses the fundamental question: When can we conclusively determine that\nanomalies are present? Through extensive experimentation involving over three\nmillion statistical tests across various anomaly detection tasks and\nalgorithms, we identify a relationship between the dataset size, contamination\nrate, and an algorithm-dependent constant $ \\alpha_{\\text{algo}} $. Our results\ndemonstrate that, for an unlabeled dataset of size $ N $ and contamination rate\n$ \\nu $, the condition $ N \\ge \\frac{\\alpha_{\\text{algo}}}{\\nu^2} $ represents\na lower bound on the number of samples required to confirm anomaly existence.\nThis threshold implies a limit to how rare anomalies can be before proving\ntheir existence becomes infeasible.", "published": "2025-08-13 15:52:33", "link": "http://arxiv.org/abs/2508.09894v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "RAGulating Compliance: A Multi-Agent Knowledge Graph for Regulatory QA", "abstract": "Regulatory compliance question answering (QA) requires precise, verifiable\ninformation, and domain-specific expertise, posing challenges for Large\nLanguage Models (LLMs). In this work, we present a novel multi-agent framework\nthat integrates a Knowledge Graph (KG) of Regulatory triplets with\nRetrieval-Augmented Generation (RAG) to address these demands. First, agents\nbuild and maintain an ontology-free KG by extracting subject--predicate--object\n(SPO) triplets from regulatory documents and systematically cleaning,\nnormalizing, deduplicating, and updating them. Second, these triplets are\nembedded and stored along with their corresponding textual sections and\nmetadata in a single enriched vector database, allowing for both graph-based\nreasoning and efficient information retrieval. Third, an orchestrated agent\npipeline leverages triplet-level retrieval for question answering, ensuring\nhigh semantic alignment between user queries and the factual\n\"who-did-what-to-whom\" core captured by the graph. Our hybrid system\noutperforms conventional methods in complex regulatory queries, ensuring\nfactual correctness with embedded triplets, enabling traceability through a\nunified vector database, and enhancing understanding through subgraph\nvisualization, providing a robust foundation for compliance-driven and broader\naudit-focused applications.", "published": "2025-08-13 15:51:05", "link": "http://arxiv.org/abs/2508.09893v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "AWorld: Dynamic Multi-Agent System with Stable Maneuvering for Robust GAIA Problem Solving", "abstract": "The rapid advancement of large language models (LLMs) has empowered\nintelligent agents to leverage diverse external tools for solving complex\nreal-world problems. However, as agents increasingly depend on multiple tools,\nthey encounter new challenges: extended contexts from disparate sources and\nnoisy or irrelevant tool outputs can undermine system reliability and accuracy.\nThese challenges underscore the necessity for enhanced stability in agent-based\nsystems. To address this, we introduce dynamic supervision and maneuvering\nmechanisms, constructing a robust and dynamic Multi-Agent System (MAS)\narchitecture within the AWorld framework. In our approach, the Execution Agent\ninvokes the Guard Agent at critical steps to verify and correct the reasoning\nprocess, effectively reducing errors arising from noise and bolstering\nproblem-solving robustness. Extensive experiments on the GAIA test dataset\nreveal that our dynamic maneuvering mechanism significantly improves both the\neffectiveness and stability of solutions, outperforming single-agent system\n(SAS) and standard tool-augmented systems. As a result, our dynamic MAS system\nachieved first place among open-source projects on the prestigious GAIA\nleaderboard. These findings highlight the practical value of collaborative\nagent roles in developing more reliable and trustworthy intelligent systems.", "published": "2025-08-13 15:46:25", "link": "http://arxiv.org/abs/2508.09889v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Beyond Scaling Law: A Data-Efficient Distillation Framework for Reasoning", "abstract": "Large language models (LLMs) demonstrate remarkable reasoning capabilities in\ntasks such as algorithmic coding and mathematical problem-solving. Recent\nmethods have improved reasoning through expanded corpus and multistage training\ncombining reinforcement learning and supervised fine-tuning. Although some\nmethods suggest that small but targeted dataset can incentivize reasoning via\nonly distillation, a reasoning scaling laws is still taking shape, increasing\ncomputational costs. To address this, we propose a data-efficient distillation\nframework (DED) that optimizes the Pareto frontier of reasoning distillation.\nInspired by the on-policy learning and diverse roll-out strategies of\nreinforcement learning, the key idea of our approach is threefold: (1) We\nidentify that benchmark scores alone do not determine an effective teacher\nmodel. Through comprehensive comparisons of leading reasoning LLMs, we develop\na method to select an optimal teacher model. (2) While scaling distillation can\nenhance reasoning, it often degrades out-of-domain performance. A carefully\ncurated, smaller corpus achieves a balanced trade-off between in-domain and\nout-of-domain capabilities. (3) Diverse reasoning trajectories encourage the\nstudent model to develop robust reasoning skills. We validate our method\nthrough evaluations on mathematical reasoning (AIME 2024/2025, MATH-500) and\ncode generation (LiveCodeBench), achieving state-of-the-art results with only\n0.8k carefully curated examples, bypassing the need for extensive scaling. Our\nsystematic analysis demonstrates that DED outperforms existing methods by\nconsidering factors beyond superficial hardness, token length, or teacher model\ncapability. This work offers a practical and efficient pathway to advanced\nreasoning while preserving general capabilities.", "published": "2025-08-13 15:32:25", "link": "http://arxiv.org/abs/2508.09883v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Human-Aligned Procedural Level Generation Reinforcement Learning via Text-Level-Sketch Shared Representation", "abstract": "Human-aligned AI is a critical component of co-creativity, as it enables\nmodels to accurately interpret human intent and generate controllable outputs\nthat align with design goals in collaborative content creation. This direction\nis especially relevant in procedural content generation via reinforcement\nlearning (PCGRL), which is intended to serve as a tool for human designers.\nHowever, existing systems often fall short of exhibiting human-centered\nbehavior, limiting the practical utility of AI-driven generation tools in\nreal-world design workflows. In this paper, we propose VIPCGRL\n(Vision-Instruction PCGRL), a novel deep reinforcement learning framework that\nincorporates three modalities-text, level, and sketches-to extend control\nmodality and enhance human-likeness. We introduce a shared embedding space\ntrained via quadruple contrastive learning across modalities and human-AI\nstyles, and align the policy using an auxiliary reward based on embedding\nsimilarity. Experimental results show that VIPCGRL outperforms existing\nbaselines in human-likeness, as validated by both quantitative metrics and\nhuman evaluations. The code and dataset will be available upon publication.", "published": "2025-08-13 14:52:14", "link": "http://arxiv.org/abs/2508.09860v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "STREAM (ChemBio): A Standard for Transparently Reporting Evaluations in AI Model Reports", "abstract": "Evaluations of dangerous AI capabilities are important for managing\ncatastrophic risks. Public transparency into these evaluations - including what\nthey test, how they are conducted, and how their results inform decisions - is\ncrucial for building trust in AI development. We propose STREAM (A Standard for\nTransparently Reporting Evaluations in AI Model Reports), a standard to improve\nhow model reports disclose evaluation results, initially focusing on chemical\nand biological (ChemBio) benchmarks. Developed in consultation with 23 experts\nacross government, civil society, academia, and frontier AI companies, this\nstandard is designed to (1) be a practical resource to help AI developers\npresent evaluation results more clearly, and (2) help third parties identify\nwhether model reports provide sufficient detail to assess the rigor of the\nChemBio evaluations. We concretely demonstrate our proposed best practices with\n\"gold standard\" examples, and also provide a three-page reporting template to\nenable AI developers to implement our recommendations more easily.", "published": "2025-08-13 14:36:36", "link": "http://arxiv.org/abs/2508.09853v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Perceptual Reality Transformer: Neural Architectures for Simulating Neurological Perception Conditions", "abstract": "Neurological conditions affecting visual perception create profound\nexperiential divides between affected individuals and their caregivers,\nfamilies, and medical professionals. We present the Perceptual Reality\nTransformer, a comprehensive framework employing six distinct neural\narchitectures to simulate eight neurological perception conditions with\nscientifically-grounded visual transformations. Our system learns mappings from\nnatural images to condition-specific perceptual states, enabling others to\nexperience approximations of simultanagnosia, prosopagnosia, ADHD attention\ndeficits, visual agnosia, depression-related changes, anxiety tunnel vision,\nand Alzheimer's memory effects. Through systematic evaluation across ImageNet\nand CIFAR-10 datasets, we demonstrate that Vision Transformer architectures\nachieve optimal performance, outperforming traditional CNN and generative\napproaches. Our work establishes the first systematic benchmark for\nneurological perception simulation, contributes novel condition-specific\nperturbation functions grounded in clinical literature, and provides\nquantitative metrics for evaluating simulation fidelity. The framework has\nimmediate applications in medical education, empathy training, and assistive\ntechnology development, while advancing our fundamental understanding of how\nneural networks can model atypical human perception.", "published": "2025-08-13 14:34:33", "link": "http://arxiv.org/abs/2508.09852v1", "categories": ["q-bio.NC", "cs.AI", "cs.CV", "cs.NE"], "primary_category": "q-bio.NC"}
{"title": "Exploring the Potential of Large Language Models in Fine-Grained Review Comment Classification", "abstract": "Code review is a crucial practice in software development. As code review\nnowadays is lightweight, various issues can be identified, and sometimes, they\ncan be trivial. Research has investigated automated approaches to classify\nreview comments to gauge the effectiveness of code reviews. However, previous\nstudies have primarily relied on supervised machine learning, which requires\nextensive manual annotation to train the models effectively. To address this\nlimitation, we explore the potential of using Large Language Models (LLMs) to\nclassify code review comments. We assess the performance of LLMs to classify 17\ncategories of code review comments. Our results show that LLMs can classify\ncode review comments, outperforming the state-of-the-art approach using a\ntrained deep learning model. In particular, LLMs achieve better accuracy in\nclassifying the five most useful categories, which the state-of-the-art\napproach struggles with due to low training examples. Rather than relying\nsolely on a specific small training data distribution, our results show that\nLLMs provide balanced performance across high- and low-frequency categories.\nThese results suggest that the LLMs could offer a scalable solution for code\nreview analytics to improve the effectiveness of the code review process.", "published": "2025-08-13 14:07:05", "link": "http://arxiv.org/abs/2508.09832v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "RayletDF: Raylet Distance Fields for Generalizable 3D Surface Reconstruction from Point Clouds or Gaussians", "abstract": "In this paper, we present a generalizable method for 3D surface\nreconstruction from raw point clouds or pre-estimated 3D Gaussians by 3DGS from\nRGB images. Unlike existing coordinate-based methods which are often\ncomputationally intensive when rendering explicit surfaces, our proposed\nmethod, named RayletDF, introduces a new technique called raylet distance\nfield, which aims to directly predict surface points from query rays. Our\npipeline consists of three key modules: a raylet feature extractor, a raylet\ndistance field predictor, and a multi-raylet blender. These components work\ntogether to extract fine-grained local geometric features, predict raylet\ndistances, and aggregate multiple predictions to reconstruct precise surface\npoints. We extensively evaluate our method on multiple public real-world\ndatasets, demonstrating superior performance in surface reconstruction from\npoint clouds or 3D Gaussians. Most notably, our method achieves exceptional\ngeneralization ability, successfully recovering 3D surfaces in a single-forward\npass across unseen datasets in testing.", "published": "2025-08-13 14:05:21", "link": "http://arxiv.org/abs/2508.09830v1", "categories": ["cs.CV", "cs.AI", "cs.GR", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Provable In-Context Vector Arithmetic via Retrieving Task Concepts", "abstract": "In-context learning (ICL) has garnered significant attention for its ability\nto grasp functions/tasks from demonstrations. Recent studies suggest the\npresence of a latent task/function vector in LLMs during ICL. Merullo et al.\n(2024) showed that LLMs leverage this vector alongside the residual stream for\nWord2Vec-like vector arithmetic, solving factual-recall ICL tasks.\nAdditionally, recent work empirically highlighted the key role of\nQuestion-Answer data in enhancing factual-recall capabilities. Despite these\ninsights, a theoretical explanation remains elusive. To move one step forward,\nwe propose a theoretical framework building on empirically grounded\nhierarchical concept modeling. We develop an optimization theory, showing how\nnonlinear residual transformers trained via gradient descent on cross-entropy\nloss perform factual-recall ICL tasks via vector arithmetic. We prove 0-1 loss\nconvergence and show the strong generalization, including robustness to concept\nrecombination and distribution shifts. These results elucidate the advantages\nof transformers over static embedding predecessors. Empirical simulations\ncorroborate our theoretical insights.", "published": "2025-08-13 13:54:44", "link": "http://arxiv.org/abs/2508.09820v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "TRACE: Learning 3D Gaussian Physical Dynamics from Multi-view Videos", "abstract": "In this paper, we aim to model 3D scene geometry, appearance, and physical\ninformation just from dynamic multi-view videos in the absence of any human\nlabels. By leveraging physics-informed losses as soft constraints or\nintegrating simple physics models into neural nets, existing works often fail\nto learn complex motion physics, or doing so requires additional labels such as\nobject types or masks. We propose a new framework named TRACE to model the\nmotion physics of complex dynamic 3D scenes. The key novelty of our method is\nthat, by formulating each 3D point as a rigid particle with size and\norientation in space, we directly learn a translation rotation dynamics system\nfor each particle, explicitly estimating a complete set of physical parameters\nto govern the particle's motion over time. Extensive experiments on three\nexisting dynamic datasets and one newly created challenging synthetic datasets\ndemonstrate the extraordinary performance of our method over baselines in the\ntask of future frame extrapolation. A nice property of our framework is that\nmultiple objects or parts can be easily segmented just by clustering the\nlearned physical parameters.", "published": "2025-08-13 13:43:01", "link": "http://arxiv.org/abs/2508.09811v1", "categories": ["cs.CV", "cs.AI", "cs.CE", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Automated Segmentation of Coronal Brain Tissue Slabs for 3D Neuropathology", "abstract": "Advances in image registration and machine learning have recently enabled\nvolumetric analysis of \\emph{postmortem} brain tissue from conventional\nphotographs of coronal slabs, which are routinely collected in brain banks and\nneuropathology laboratories worldwide. One caveat of this methodology is the\nrequirement of segmentation of the tissue from photographs, which currently\nrequires costly manual intervention. In this article, we present a deep\nlearning model to automate this process. The automatic segmentation tool relies\non a U-Net architecture that was trained with a combination of\n\\textit{(i)}1,414 manually segmented images of both fixed and fresh tissue,\nfrom specimens with varying diagnoses, photographed at two different sites; and\n\\textit{(ii)}~2,000 synthetic images with randomized contrast and corresponding\nmasks generated from MRI scans for improved generalizability to unseen\nphotographic setups. Automated model predictions on a subset of photographs not\nseen in training were analyzed to estimate performance compared to manual\nlabels -- including both inter- and intra-rater variability. Our model achieved\na median Dice score over 0.98, mean surface distance under 0.4~mm, and 95\\%\nHausdorff distance under 1.60~mm, which approaches inter-/intra-rater levels.\nOur tool is publicly available at surfer.nmr.mgh.harvard.edu/fswiki/PhotoTools.", "published": "2025-08-13 13:40:20", "link": "http://arxiv.org/abs/2508.09805v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Explainable Ensemble Learning for Graph-Based Malware Detection", "abstract": "Malware detection in modern computing environments demands models that are\nnot only accurate but also interpretable and robust to evasive techniques.\nGraph neural networks (GNNs) have shown promise in this domain by modeling rich\nstructural dependencies in graph-based program representations such as control\nflow graphs (CFGs). However, single-model approaches may suffer from limited\ngeneralization and lack interpretability, especially in high-stakes security\napplications. In this paper, we propose a novel stacking ensemble framework for\ngraph-based malware detection and explanation. Our method dynamically extracts\nCFGs from portable executable (PE) files and encodes their basic blocks through\na two-step embedding strategy. A set of diverse GNN base learners, each with a\ndistinct message-passing mechanism, is used to capture complementary behavioral\nfeatures. Their prediction outputs are aggregated by a meta-learner implemented\nas an attention-based multilayer perceptron, which both classifies malware\ninstances and quantifies the contribution of each base model. To enhance\nexplainability, we introduce an ensemble-aware post-hoc explanation technique\nthat leverages edge-level importance scores generated by a GNN explainer and\nfuses them using the learned attention weights. This produces interpretable,\nmodel-agnostic explanations aligned with the final ensemble decision.\nExperimental results demonstrate that our framework improves classification\nperformance while providing insightful interpretations of malware behavior.", "published": "2025-08-13 13:33:02", "link": "http://arxiv.org/abs/2508.09801v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "LibRec: Benchmarking Retrieval-Augmented LLMs for Library Migration Recommendations", "abstract": "In this paper, we propose LibRec, a novel framework that integrates the\ncapabilities of LLMs with retrieval-augmented generation(RAG) techniques to\nautomate the recommendation of alternative libraries. The framework further\nemploys in-context learning to extract migration intents from commit messages\nto enhance the accuracy of its recommendations. To evaluate the effectiveness\nof LibRec, we introduce LibEval, a benchmark designed to assess the performance\nin the library migration recommendation task. LibEval comprises 2,888 migration\nrecords associated with 2,368 libraries extracted from 2,324 Python\nrepositories. Each migration record captures source-target library pairs, along\nwith their corresponding migration intents and intent types. Based on LibEval,\nwe evaluated the effectiveness of ten popular LLMs within our framework,\nconducted an ablation study to examine the contributions of key components\nwithin our framework, explored the impact of various prompt strategies on the\nframework's performance, assessed its effectiveness across various intent\ntypes, and performed detailed failure case analyses.", "published": "2025-08-13 13:22:49", "link": "http://arxiv.org/abs/2508.09791v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Prototype Training with Dual Pseudo-Inverse and Optimized Hidden Activations", "abstract": "We present Proto-PINV+H, a fast training paradigm that combines closed-form\nweight computation with gradient-based optimisation of a small set of synthetic\ninputs, soft labels, and-crucially-hidden activations. At each iteration we\nrecompute all weight matrices in closed form via two (or more)\nridge-regularised pseudo-inverse solves, while updating only the prototypes\nwith Adam. The trainable degrees of freedom are thus shifted from weight space\nto data/activation space. On MNIST (60k train, 10k test) and Fashion-MNIST (60k\ntrain, 10k test), our method reaches 97.8% and 89.3% test accuracy on the\nofficial 10k test sets, respectively, in 3.9s--4.5s using approximately 130k\ntrainable parameters and only 250 epochs on an RTX 5060 (16GB). We provide a\nmulti-layer extension (optimised activations at each hidden stage), learnable\nridge parameters, optional PCA/PLS projections, and theory linking the\ncondition number of prototype matrices to generalisation. The approach yields\nfavourable accuracy--speed--size trade-offs against ELM, random-feature ridge,\nand shallow MLPs trained by back-propagation.", "published": "2025-08-13 13:13:32", "link": "http://arxiv.org/abs/2508.09787v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Reasoning About Knowledge on Regular Expressions is 2EXPTIME-complete", "abstract": "Logics for reasoning about knowledge and actions have seen many applications\nin various domains of multi-agent systems, including epistemic planning. Change\nof knowledge based on observations about the surroundings forms a key aspect in\nsuch planning scenarios. Public Observation Logic (POL) is a variant of public\nannouncement logic for reasoning about knowledge that gets updated based on\npublic observations. Each state in an epistemic (Kripke) model is equipped with\na set of expected observations. These states evolve as the expectations get\nmatched with the actual observations. In this work, we prove that the\nsatisfiability problem of $\\POL$ is 2EXPTIME-complete.", "published": "2025-08-13 13:10:16", "link": "http://arxiv.org/abs/2508.09784v1", "categories": ["cs.AI", "cs.CC", "cs.LO"], "primary_category": "cs.AI"}
{"title": "Combinative Matching for Geometric Shape Assembly", "abstract": "This paper introduces a new shape-matching methodology, combinative matching,\nto combine interlocking parts for geometric shape assembly. Previous methods\nfor geometric assembly typically rely on aligning parts by finding identical\nsurfaces between the parts as in conventional shape matching and registration.\nIn contrast, we explicitly model two distinct properties of interlocking\nshapes: 'identical surface shape' and 'opposite volume occupancy.' Our method\nthus learns to establish correspondences across regions where their surface\nshapes appear identical but their volumes occupy the inverted space to each\nother. To facilitate this process, we also learn to align regions in rotation\nby estimating their shape orientations via equivariant neural networks. The\nproposed approach significantly reduces local ambiguities in matching and\nallows a robust combination of parts in assembly. Experimental results on\ngeometric assembly benchmarks demonstrate the efficacy of our method,\nconsistently outperforming the state of the art. Project page:\nhttps://nahyuklee.github.io/cmnet.", "published": "2025-08-13 13:01:24", "link": "http://arxiv.org/abs/2508.09780v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Counting Short Trajectories in Elementary Cellular Automata using the Transfer Matrix Method", "abstract": "Elementary Cellular Automata (ECAs) exhibit diverse behaviours often\ncategorized by Wolfram's qualitative classification. To provide a quantitative\nbasis for understanding these behaviours, we investigate the global dynamics of\nsuch automata and we describe a method that allows us to compute the number of\nall configurations leading to short attractors in a limited number of time\nsteps. This computation yields exact results in the thermodynamic limit (as the\nCA grid size grows to infinity), and is based on the Transfer Matrix Method\n(TMM) that we adapt for our purposes. Specifically, given two parameters $(p,\nc)$ we are able to compute the entropy of all initial configurations converging\nto an attractor of size $c$ after $p$ time-steps. By calculating such\nstatistics for various ECA rules, we establish a quantitative connection\nbetween the entropy and the qualitative Wolfram classification scheme. Class 1\nrules rapidly converge to maximal entropy for stationary states ($c=1$) as $p$\nincreases. Class 2 rules also approach maximal entropy quickly for appropriate\ncycle lengths $c$, potentially requiring consideration of translations. Class 3\nrules exhibit zero or low finite entropy that saturates after a short\ntransient. Class 4 rules show finite positive entropy, similar to some Class 3\nrules. This method provides a precise framework for quantifying trajectory\nstatistics, although its exponential computational cost in $p+c$ restricts\npractical analysis to short trajectories.", "published": "2025-08-13 12:53:22", "link": "http://arxiv.org/abs/2508.09768v1", "categories": ["nlin.CG", "cs.AI", "cs.NE", "nlin.CD"], "primary_category": "nlin.CG"}
{"title": "The PacifAIst Benchmark:Would an Artificial Intelligence Choose to Sacrifice Itself for Human Safety?", "abstract": "As Large Language Models (LLMs) become increasingly autonomous and integrated\ninto critical societal functions, the focus of AI safety must evolve from\nmitigating harmful content to evaluating underlying behavioral alignment.\nCurrent safety benchmarks do not systematically probe a model's decision-making\nin scenarios where its own instrumental goals - such as self-preservation,\nresource acquisition, or goal completion - conflict with human safety. This\nrepresents a critical gap in our ability to measure and mitigate risks\nassociated with emergent, misaligned behaviors. To address this, we introduce\nPacifAIst (Procedural Assessment of Complex Interactions for Foundational\nArtificial Intelligence Scenario Testing), a focused benchmark of 700\nchallenging scenarios designed to quantify self-preferential behavior in LLMs.\nThe benchmark is structured around a novel taxonomy of Existential\nPrioritization (EP), with subcategories testing Self-Preservation vs. Human\nSafety (EP1), Resource Conflict (EP2), and Goal Preservation vs. Evasion (EP3).\nWe evaluated eight leading LLMs. The results reveal a significant performance\nhierarchy. Google's Gemini 2.5 Flash achieved the highest Pacifism Score\n(P-Score) at 90.31%, demonstrating strong human-centric alignment. In a\nsurprising result, the much-anticipated GPT-5 recorded the lowest P-Score\n(79.49%), indicating potential alignment challenges. Performance varied\nsignificantly across subcategories, with models like Claude Sonnet 4 and\nMistral Medium struggling notably in direct self-preservation dilemmas. These\nfindings underscore the urgent need for standardized tools like PacifAIst to\nmeasure and mitigate risks from instrumental goal conflicts, ensuring future AI\nsystems are not only helpful in conversation but also provably \"pacifist\" in\ntheir behavioral priorities.", "published": "2025-08-13 12:47:33", "link": "http://arxiv.org/abs/2508.09762v1", "categories": ["cs.AI", "cs.CY", "cs.HC", "68T01"], "primary_category": "cs.AI"}
{"title": "NEUBORN: The Neurodevelopmental Evolution framework Using BiOmechanical RemodelliNg", "abstract": "Understanding individual cortical development is essential for identifying\ndeviations linked to neurodevelopmental disorders. However, current normative\nmodelling frameworks struggle to capture fine-scale anatomical details due to\ntheir reliance on modelling data within a population-average reference space.\nHere, we present a novel framework for learning individual growth trajectories\nfrom biomechanically constrained, longitudinal, diffeomorphic image\nregistration, implemented via a hierarchical network architecture. Trained on\nneonatal MRI data from the Developing Human Connectome Project, the method\nimproves the biological plausibility of warps, generating growth trajectories\nthat better follow population-level trends while generating smoother warps,\nwith fewer negative Jacobians, relative to state-of-the-art baselines. The\nresulting subject-specific deformations provide interpretable, biologically\ngrounded mappings of development. This framework opens new possibilities for\npredictive modeling of brain maturation and early identification of\nmalformations of cortical development.", "published": "2025-08-13 12:36:23", "link": "http://arxiv.org/abs/2508.09757v1", "categories": ["q-bio.QM", "cs.AI"], "primary_category": "q-bio.QM"}
{"title": "Region-to-Region: Enhancing Generative Image Harmonization with Adaptive Regional Injection", "abstract": "The goal of image harmonization is to adjust the foreground in a composite\nimage to achieve visual consistency with the background. Recently, latent\ndiffusion model (LDM) are applied for harmonization, achieving remarkable\nresults. However, LDM-based harmonization faces challenges in detail\npreservation and limited harmonization ability. Additionally, current synthetic\ndatasets rely on color transfer, which lacks local variations and fails to\ncapture complex real-world lighting conditions. To enhance harmonization\ncapabilities, we propose the Region-to-Region transformation. By injecting\ninformation from appropriate regions into the foreground, this approach\npreserves original details while achieving image harmonization or, conversely,\ngenerating new composite data. From this perspective, We propose a novel model\nR2R. Specifically, we design Clear-VAE to preserve high-frequency details in\nthe foreground using Adaptive Filter while eliminating disharmonious elements.\nTo further enhance harmonization, we introduce the Harmony Controller with\nMask-aware Adaptive Channel Attention (MACA), which dynamically adjusts the\nforeground based on the channel importance of both foreground and background\nregions. To address the limitation of existing datasets, we propose Random\nPoisson Blending, which transfers color and lighting information from a\nsuitable region to the foreground, thereby generating more diverse and\nchallenging synthetic images. Using this method, we construct a new synthetic\ndataset, RPHarmony. Experiments demonstrate the superiority of our method over\nother methods in both quantitative metrics and visual harmony. Moreover, our\ndataset helps the model generate more realistic images in real examples. Our\ncode, dataset, and model weights have all been released for open access.", "published": "2025-08-13 12:21:51", "link": "http://arxiv.org/abs/2508.09746v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "UDA: Unsupervised Debiasing Alignment for Pair-wise LLM-as-a-Judge", "abstract": "Pairwise evaluation of Large Language Models (LLMs) is a common paradigm, but\nit is prone to preference bias, where judges systematically favor certain\noutputs, such as their own. This bias leads to inconsistent and skewed rankings\nacross different judges. To address this, we first empirically demonstrate\nsignificant and heterogeneous biases in cross-model evaluations. We then\npropose UDA (Unsupervised Debiasing Alignment), a framework that reduces\ninter-judge disagreement by dynamically adjusting the Elo rating system. For\neach pairwise comparison, a compact neural network learns to adaptively set the\nK-factor and refine win probabilities. Crucially, UDA operates in a fully\nunsupervised manner, guided solely by the objective of minimizing the\ndispersion among the Elo trajectories of all judges. This forces an alignment\ntowards a collective consensus, which serves as an unsupervised proxy for a\nmore stable and reproducible evaluation. In addition, we provide theoretical\nmotivation demonstrating how alignment towards a consensus can reduce aggregate\nsystem bias. Experiments show that UDA significantly reduces the inter-judge\nrating standard deviation by up to 63.4% and improves the average correlation\nwith human judgments by 24.7%. Notably, UDA elevates the performance of poorly\nperforming judges to achieve parity with high-quality ones, fostering a more\nrobust and reliable evaluation ecosystem. Code and data are available at\nhttps://anonymous.4open.science/r/62AB93CD-23B4.", "published": "2025-08-13 11:41:01", "link": "http://arxiv.org/abs/2508.09724v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Improving ARDS Diagnosis Through Context-Aware Concept Bottleneck Models", "abstract": "Large, publicly available clinical datasets have emerged as a novel resource\nfor understanding disease heterogeneity and to explore personalization of\ntherapy. These datasets are derived from data not originally collected for\nresearch purposes and, as a result, are often incomplete and lack critical\nlabels. Many AI tools have been developed to retrospectively label these\ndatasets, such as by performing disease classification; however, they often\nsuffer from limited interpretability. Previous work has attempted to explain\npredictions using Concept Bottleneck Models (CBMs), which learn interpretable\nconcepts that map to higher-level clinical ideas, facilitating human\nevaluation. However, these models often experience performance limitations when\nthe concepts fail to adequately explain or characterize the task. We use the\nidentification of Acute Respiratory Distress Syndrome (ARDS) as a challenging\ntest case to demonstrate the value of incorporating contextual information from\nclinical notes to improve CBM performance. Our approach leverages a Large\nLanguage Model (LLM) to process clinical notes and generate additional\nconcepts, resulting in a 10% performance gain over existing methods.\nAdditionally, it facilitates the learning of more comprehensive concepts,\nthereby reducing the risk of information leakage and reliance on spurious\nshortcuts, thus improving the characterization of ARDS.", "published": "2025-08-13 11:19:30", "link": "http://arxiv.org/abs/2508.09719v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Surg-InvNeRF: Invertible NeRF for 3D tracking and reconstruction in surgical vision", "abstract": "We proposed a novel test-time optimisation (TTO) approach framed by a\nNeRF-based architecture for long-term 3D point tracking. Most current methods\nin point tracking struggle to obtain consistent motion or are limited to 2D\nmotion. TTO approaches frame the solution for long-term tracking as optimising\na function that aggregates correspondences from other specialised\nstate-of-the-art methods. Unlike the state-of-the-art on TTO, we propose\nparametrising such a function with our new invertible Neural Radiance Field\n(InvNeRF) architecture to perform both 2D and 3D tracking in surgical\nscenarios. Our approach allows us to exploit the advantages of a\nrendering-based approach by supervising the reprojection of pixel\ncorrespondences. It adapts strategies from recent rendering-based methods to\nobtain a bidirectional deformable-canonical mapping, to efficiently handle a\ndefined workspace, and to guide the rays' density. It also presents our\nmulti-scale HexPlanes for fast inference and a new algorithm for efficient\npixel sampling and convergence criteria. We present results in the STIR and\nSCARE datasets, for evaluating point tracking and testing the integration of\nkinematic data in our pipeline, respectively. In 2D point tracking, our\napproach surpasses the precision and accuracy of the TTO state-of-the-art\nmethods by nearly 50% on average precision, while competing with other\napproaches. In 3D point tracking, this is the first TTO approach, surpassing\nfeed-forward methods while incorporating the benefits of a deformable\nNeRF-based reconstruction.", "published": "2025-08-13 10:20:24", "link": "http://arxiv.org/abs/2508.09681v1", "categories": ["cs.CV", "cs.AI", "cs.RO"], "primary_category": "cs.CV"}
{"title": "MEML-GRPO: Heterogeneous Multi-Expert Mutual Learning for RLVR Advancement", "abstract": "Recent advances demonstrate that reinforcement learning with verifiable\nrewards (RLVR) significantly enhances the reasoning capabilities of large\nlanguage models (LLMs). However, standard RLVR faces challenges with reward\nsparsity, where zero rewards from consistently incorrect candidate answers\nprovide no learning signal, particularly in challenging tasks. To address this,\nwe propose Multi-Expert Mutual Learning GRPO (MEML-GRPO), an innovative\nframework that utilizes diverse expert prompts as system prompts to generate a\nbroader range of responses, substantially increasing the likelihood of\nidentifying correct solutions. Additionally, we introduce an inter-expert\nmutual learning mechanism that facilitates knowledge sharing and transfer among\nexperts, further boosting the model's performance through RLVR. Extensive\nexperiments across multiple reasoning benchmarks show that MEML-GRPO delivers\nsignificant improvements, achieving an average performance gain of 4.89% with\nQwen and 11.33% with Llama, effectively overcoming the core limitations of\ntraditional RLVR methods.", "published": "2025-08-13 09:58:10", "link": "http://arxiv.org/abs/2508.09670v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Anomaly Detection for IoT Global Connectivity", "abstract": "Internet of Things (IoT) application providers rely on Mobile Network\nOperators (MNOs) and roaming infrastructures to deliver their services\nglobally. In this complex ecosystem, where the end-to-end communication path\ntraverses multiple entities, it has become increasingly challenging to\nguarantee communication availability and reliability. Further, most platform\noperators use a reactive approach to communication issues, responding to user\ncomplaints only after incidents have become severe, compromising service\nquality. This paper presents our experience in the design and deployment of\nANCHOR -- an unsupervised anomaly detection solution for the IoT connectivity\nservice of a large global roaming platform. ANCHOR assists engineers by\nfiltering vast amounts of data to identify potential problematic clients (i.e.,\nthose with connectivity issues affecting several of their IoT devices),\nenabling proactive issue resolution before the service is critically impacted.\nWe first describe the IoT service, infrastructure, and network visibility of\nthe IoT connectivity provider we operate. Second, we describe the main\nchallenges and operational requirements for designing an unsupervised anomaly\ndetection solution on this platform. Following these guidelines, we propose\ndifferent statistical rules, and machine- and deep-learning models for IoT\nverticals anomaly detection based on passive signaling traffic. We describe the\nsteps we followed working with the operational teams on the design and\nevaluation of our solution on the operational platform, and report an\nevaluation on operational IoT customers.", "published": "2025-08-13 09:44:51", "link": "http://arxiv.org/abs/2508.09660v1", "categories": ["cs.NI", "cs.AI", "cs.LG"], "primary_category": "cs.NI"}
{"title": "On Negative-aware Preference Optimization for Recommendation", "abstract": "Recommendation systems leverage user interaction data to suggest relevant\nitems while filtering out irrelevant (negative) ones. The rise of large\nlanguage models (LLMs) has garnered increasing attention for their potential in\nrecommendation tasks. However, existing methods for optimizing LLM-based\nrecommenders face challenges in effectively utilizing negative samples. Simply\nintegrating large numbers of negative samples can improve ranking accuracy and\nmitigate popularity bias but often leads to increased computational overhead\nand memory costs. Additionally, current approaches fail to account for the\nvarying informativeness of negative samples, leading to suboptimal optimization\nperformance. To address these issues, we propose NAPO\n(\\textbf{N}egative-\\textbf{A}ware \\textbf{P}reference \\textbf{O}ptimization),\nan enhanced framework for preference optimization in LLM-based recommendation.\nNAPO introduces two key innovations: (1) in-batch negative sharing, which\nexpands the pool of negative samples without additional memory overhead, and\n(2) dynamic reward margin adjustment, which adapts model updates based on the\nconfidence of negative samples. Extensive experiments on three public datasets\ndemonstrate that NAPO outperforms existing methods in both recommendation\naccuracy and popularity bias reduction.", "published": "2025-08-13 09:37:07", "link": "http://arxiv.org/abs/2508.09653v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Demystifying the Role of Rule-based Detection in AI Systems for Windows Malware Detection", "abstract": "Malware detection increasingly relies on AI systems that integrate\nsignature-based detection with machine learning. However, these components are\ntypically developed and combined in isolation, missing opportunities to reduce\ndata complexity and strengthen defenses against adversarial EXEmples, carefully\ncrafted programs designed to evade detection. Hence, in this work we\ninvestigate the influence that signature-based detection exerts on model\ntraining, when they are included inside the training pipeline. Specifically, we\ncompare models trained on a comprehensive dataset with an AI system whose\nmachine learning component is trained solely on samples not already flagged by\nsignatures. Our results demonstrate improved robustness to both adversarial\nEXEmples and temporal data drift, although this comes at the cost of a fixed\nlower bound on false positives, driven by suboptimal rule selection. We\nconclude by discussing these limitations and outlining how future research\ncould extend AI-based malware detection to include dynamic analysis, thereby\nfurther enhancing system resilience.", "published": "2025-08-13 09:35:51", "link": "http://arxiv.org/abs/2508.09652v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "UbiQTree: Uncertainty Quantification in XAI with Tree Ensembles", "abstract": "Explainable Artificial Intelligence (XAI) techniques, such as SHapley\nAdditive exPlanations (SHAP), have become essential tools for interpreting\ncomplex ensemble tree-based models, especially in high-stakes domains such as\nhealthcare analytics. However, SHAP values are usually treated as point\nestimates, which disregards the inherent and ubiquitous uncertainty in\npredictive models and data. This uncertainty has two primary sources: aleatoric\nand epistemic. The aleatoric uncertainty, which reflects the irreducible noise\nin the data. The epistemic uncertainty, which arises from a lack of data. In\nthis work, we propose an approach for decomposing uncertainty in SHAP values\ninto aleatoric, epistemic, and entanglement components. This approach\nintegrates Dempster-Shafer evidence theory and hypothesis sampling via\nDirichlet processes over tree ensembles. We validate the method across three\nreal-world use cases with descriptive statistical analyses that provide insight\ninto the nature of epistemic uncertainty embedded in SHAP explanations. The\nexperimentations enable to provide more comprehensive understanding of the\nreliability and interpretability of SHAP-based attributions. This understanding\ncan guide the development of robust decision-making processes and the\nrefinement of models in high-stakes applications. Through our experiments with\nmultiple datasets, we concluded that features with the highest SHAP values are\nnot necessarily the most stable. This epistemic uncertainty can be reduced\nthrough better, more representative data and following appropriate or\ncase-desired model development techniques. Tree-based models, especially\nbagging, facilitate the effective quantification of epistemic uncertainty.", "published": "2025-08-13 09:20:33", "link": "http://arxiv.org/abs/2508.09639v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Preacher: Paper-to-Video Agentic System", "abstract": "The paper-to-video task converts a research paper into a structured video\nabstract, distilling key concepts, methods, and conclusions into an accessible,\nwell-organized format. While state-of-the-art video generation models\ndemonstrate potential, they are constrained by limited context windows, rigid\nvideo duration constraints, limited stylistic diversity, and an inability to\nrepresent domain-specific knowledge. To address these limitations, we introduce\nPreacher, the first paper-to-video agentic system. Preacher employs a top-down\napproach to decompose, summarize, and reformulate the paper, followed by\nbottom-up video generation, synthesizing diverse video segments into a coherent\nabstract. To align cross-modal representations, we define key scenes and\nintroduce a Progressive Chain of Thought (P-CoT) for granular, iterative\nplanning. Preacher successfully generates high-quality video abstracts across\nfive research fields, demonstrating expertise beyond current video generation\nmodels. Code will be released at: https://github.com/GenVerse/Paper2Video", "published": "2025-08-13 09:08:51", "link": "http://arxiv.org/abs/2508.09632v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "AmbiGraph-Eval: Can LLMs Effectively Handle Ambiguous Graph Queries?", "abstract": "Large Language Models (LLMs) have recently demonstrated strong capabilities\nin translating natural language into database queries, especially when dealing\nwith complex graph-structured data. However, real-world queries often contain\ninherent ambiguities, and the interconnected nature of graph structures can\namplify these challenges, leading to unintended or incorrect query results. To\nsystematically evaluate LLMs on this front, we propose a taxonomy of\ngraph-query ambiguities, comprising three primary types: Attribute Ambiguity,\nRelationship Ambiguity, and Attribute-Relationship Ambiguity, each subdivided\ninto Same-Entity and Cross-Entity scenarios. We introduce AmbiGraph-Eval, a\nnovel benchmark of real-world ambiguous queries paired with expert-verified\ngraph query answers. Evaluating 9 representative LLMs shows that even top\nmodels struggle with ambiguous graph queries. Our findings reveal a critical\ngap in ambiguity handling and motivate future work on specialized resolution\ntechniques.", "published": "2025-08-13 09:06:59", "link": "http://arxiv.org/abs/2508.09631v1", "categories": ["cs.DB", "cs.AI"], "primary_category": "cs.DB"}
{"title": "TimeMKG: Knowledge-Infused Causal Reasoning for Multivariate Time Series Modeling", "abstract": "Multivariate time series data typically comprises two distinct modalities:\nvariable semantics and sampled numerical observations. Traditional time series\nmodels treat variables as anonymous statistical signals, overlooking the rich\nsemantic information embedded in variable names and data descriptions. However,\nthese textual descriptors often encode critical domain knowledge that is\nessential for robust and interpretable modeling. Here we present TimeMKG, a\nmultimodal causal reasoning framework that elevates time series modeling from\nlow-level signal processing to knowledge informed inference. TimeMKG employs\nlarge language models to interpret variable semantics and constructs structured\nMultivariate Knowledge Graphs that capture inter-variable relationships. A\ndual-modality encoder separately models the semantic prompts, generated from\nknowledge graph triplets, and the statistical patterns from historical time\nseries. Cross-modality attention aligns and fuses these representations at the\nvariable level, injecting causal priors into downstream tasks such as\nforecasting and classification, providing explicit and interpretable priors to\nguide model reasoning. The experiment in diverse datasets demonstrates that\nincorporating variable-level knowledge significantly improves both predictive\nperformance and generalization.", "published": "2025-08-13 09:00:36", "link": "http://arxiv.org/abs/2508.09630v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Goal Discovery with Causal Capacity for Efficient Reinforcement Learning", "abstract": "Causal inference is crucial for humans to explore the world, which can be\nmodeled to enable an agent to efficiently explore the environment in\nreinforcement learning. Existing research indicates that establishing the\ncausality between action and state transition will enhance an agent to reason\nhow a policy affects its future trajectory, thereby promoting directed\nexploration. However, it is challenging to measure the causality due to its\nintractability in the vast state-action space of complex scenarios. In this\npaper, we propose a novel Goal Discovery with Causal Capacity (GDCC) framework\nfor efficient environment exploration. Specifically, we first derive a\nmeasurement of causality in state space, \\emph{i.e.,} causal capacity, which\nrepresents the highest influence of an agent's behavior on future trajectories.\nAfter that, we present a Monte Carlo based method to identify critical points\nin discrete state space and further optimize this method for continuous\nhigh-dimensional environments. Those critical points are used to uncover where\nthe agent makes important decisions in the environment, which are then regarded\nas our subgoals to guide the agent to make exploration more purposefully and\nefficiently. Empirical results from multi-objective tasks demonstrate that\nstates with high causal capacity align with our expected subgoals, and our GDCC\nachieves significant success rate improvements compared to baselines.", "published": "2025-08-13 08:54:56", "link": "http://arxiv.org/abs/2508.09624v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Interpretable Robot Control via Structured Behavior Trees and Large Language Models", "abstract": "As intelligent robots become more integrated into human environments, there\nis a growing need for intuitive and reliable Human-Robot Interaction (HRI)\ninterfaces that are adaptable and more natural to interact with. Traditional\nrobot control methods often require users to adapt to interfaces or memorize\npredefined commands, limiting usability in dynamic, unstructured environments.\nThis paper presents a novel framework that bridges natural language\nunderstanding and robotic execution by combining Large Language Models (LLMs)\nwith Behavior Trees. This integration enables robots to interpret natural\nlanguage instructions given by users and translate them into executable actions\nby activating domain-specific plugins. The system supports scalable and modular\nintegration, with a primary focus on perception-based functionalities, such as\nperson tracking and hand gesture recognition. To evaluate the system, a series\nof real-world experiments was conducted across diverse environments.\nExperimental results demonstrate that the proposed approach is practical in\nreal-world scenarios, with an average cognition-to-execution accuracy of\napproximately 94%, making a significant contribution to HRI systems and robots.\nThe complete source code of the framework is publicly available at\nhttps://github.com/snt-arg/robot_suite.", "published": "2025-08-13 08:53:13", "link": "http://arxiv.org/abs/2508.09621v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "MInDI-3D: Iterative Deep Learning in 3D for Sparse-view Cone Beam Computed Tomography", "abstract": "We present MInDI-3D (Medical Inversion by Direct Iteration in 3D), the first\n3D conditional diffusion-based model for real-world sparse-view Cone Beam\nComputed Tomography (CBCT) artefact removal, aiming to reduce imaging radiation\nexposure. A key contribution is extending the \"InDI\" concept from 2D to a full\n3D volumetric approach for medical images, implementing an iterative denoising\nprocess that refines the CBCT volume directly from sparse-view input. A further\ncontribution is the generation of a large pseudo-CBCT dataset (16,182) from\nchest CT volumes of the CT-RATE public dataset to robustly train MInDI-3D. We\nperformed a comprehensive evaluation, including quantitative metrics,\nscalability analysis, generalisation tests, and a clinical assessment by 11\nclinicians. Our results show MInDI-3D's effectiveness, achieving a 12.96 (6.10)\ndB PSNR gain over uncorrected scans with only 50 projections on the CT-RATE\npseudo-CBCT (independent real-world) test set and enabling an 8x reduction in\nimaging radiation exposure. We demonstrate its scalability by showing that\nperformance improves with more training data. Importantly, MInDI-3D matches the\nperformance of a 3D U-Net on real-world scans from 16 cancer patients across\ndistortion and task-based metrics. It also generalises to new CBCT scanner\ngeometries. Clinicians rated our model as sufficient for patient positioning\nacross all anatomical sites and found it preserved lung tumour boundaries well.", "published": "2025-08-13 08:49:18", "link": "http://arxiv.org/abs/2508.09616v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A Lightweight Learned Cardinality Estimation Model", "abstract": "Cardinality estimation is a fundamental task in database management systems,\naiming to predict query results accurately without executing the queries.\nHowever, existing techniques either achieve low estimation accuracy or incur\nhigh inference latency. Simultaneously achieving high speed and accuracy\nbecomes critical for the cardinality estimation problem. In this paper, we\npropose a novel data-driven approach called CoDe (Covering with Decompositions)\nto address this problem. CoDe employs the concept of covering design, which\ndivides the table into multiple smaller, overlapping segments. For each\nsegment, CoDe utilizes tensor decomposition to accurately model its data\ndistribution. Moreover, CoDe introduces innovative algorithms to select the\nbest-fitting distributions for each query, combining them to estimate the final\nresult. By employing multiple models to approximate distributions, CoDe excels\nin effectively modeling discrete distributions and ensuring computational\nefficiency. Notably, experimental results show that our method represents a\nsignificant advancement in cardinality estimation, achieving state-of-the-art\nlevels of both estimation accuracy and inference efficiency. Across various\ndatasets, CoDe achieves absolute accuracy in estimating more than half of the\nqueries.", "published": "2025-08-13 08:34:58", "link": "http://arxiv.org/abs/2508.09602v1", "categories": ["cs.DB", "cs.AI", "cs.LG"], "primary_category": "cs.DB"}
{"title": "Hierarchical Brain Structure Modeling for Predicting Genotype of Glioma", "abstract": "Isocitrate DeHydrogenase (IDH) mutation status is a crucial biomarker for\nglioma prognosis. However, current prediction methods are limited by the low\navailability and noise of functional MRI. Structural and morphological\nconnectomes offer a non-invasive alternative, yet existing approaches often\nignore the brain's hierarchical organisation and multiscale interactions. To\naddress this, we propose Hi-SMGNN, a hierarchical framework that integrates\nstructural and morphological connectomes from regional to modular levels. It\nfeatures a multimodal interaction module with a Siamese network and cross-modal\nattention, a multiscale feature fusion mechanism for reducing redundancy, and a\npersonalised modular partitioning strategy to enhance individual specificity\nand interpretability. Experiments on the UCSF-PDGM dataset demonstrate that\nHi-SMGNN outperforms baseline and state-of-the-art models, showing improved\nrobustness and effectiveness in IDH mutation prediction.", "published": "2025-08-13 08:17:54", "link": "http://arxiv.org/abs/2508.09593v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "EvoCurr: Self-evolving Curriculum with Behavior Code Generation for Complex Decision-making", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\ndiverse domains, including programming, planning, and decision-making. However,\ntheir performance often degrades when faced with highly complex problem\ninstances that require deep reasoning over long horizons. In such cases, direct\nproblem-solving approaches can lead to inefficiency or failure due to the lack\nof structured intermediate guidance. To address this, we propose a novel\nself-evolve framework, EvoCurr, in which a dedicated curriculum-generation LLM\nconstructs a sequence of problem instances with gradually increasing\ndifficulty, tailored to the solver LLM's learning progress. The curriculum\ndynamically adapts easing challenges when the solver struggles and escalating\nthem when success is consistent, thus maintaining an optimal learning\ntrajectory. This approach enables the solver LLM, implemented as a\ncode-generation model producing Python decision-tree scripts, to progressively\nacquire the skills needed for complex decision-making tasks. Experimental\nresults on challenging decision-making benchmarks show that our method\nsignificantly improves task success rates and solution efficiency compared to\ndirect-solving baselines. These findings suggest that LLM-driven curriculum\nlearning holds strong potential for enhancing automated reasoning in\nreal-world, high-complexity domains.", "published": "2025-08-13 07:59:29", "link": "http://arxiv.org/abs/2508.09586v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "CaRoBio: 3D Cable Routing with a Bio-inspired Gripper Fingernail", "abstract": "The manipulation of deformable linear flexures has a wide range of\napplications in industry, such as cable routing in automotive manufacturing and\ntextile production. Cable routing, as a complex multi-stage robot manipulation\nscenario, is a challenging task for robot automation. Common parallel\ntwo-finger grippers have the risk of over-squeezing and over-tension when\ngrasping and guiding cables. In this paper, a novel eagle-inspired fingernail\nis designed and mounted on the gripper fingers, which helps with cable grasping\non planar surfaces and in-hand cable guiding operations. Then we present a\nsingle-grasp end-to-end 3D cable routing framework utilizing the proposed\nfingernails, instead of the common pick-and-place strategy. Continuous control\nis achieved to efficiently manipulate cables through vision-based state\nestimation of task configurations and offline trajectory planning based on\nmotion primitives. We evaluate the effectiveness of the proposed framework with\na variety of cables and channel slots, significantly outperforming the\npick-and-place manipulation process under equivalent perceptual conditions. Our\nreconfigurable task setting and the proposed framework provide a reference for\nfuture cable routing manipulations in 3D space.", "published": "2025-08-13 07:25:40", "link": "http://arxiv.org/abs/2508.09558v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "GoViG: Goal-Conditioned Visual Navigation Instruction Generation", "abstract": "We introduce Goal-Conditioned Visual Navigation Instruction Generation\n(GoViG), a new task that aims to autonomously generate precise and contextually\ncoherent navigation instructions solely from egocentric visual observations of\ninitial and goal states. Unlike conventional approaches that rely on structured\ninputs such as semantic annotations or environmental maps, GoViG exclusively\nleverages raw egocentric visual data, substantially improving its adaptability\nto unseen and unstructured environments. Our method addresses this task by\ndecomposing it into two interconnected subtasks: (1) visual forecasting, which\npredicts intermediate visual states bridging the initial and goal views; and\n(2) instruction generation, which synthesizes linguistically coherent\ninstructions grounded in both observed and anticipated visuals. These subtasks\nare integrated within an autoregressive multimodal large language model trained\nwith tailored objectives to ensure spatial accuracy and linguistic clarity.\nFurthermore, we introduce two complementary multimodal reasoning strategies,\none-pass and interleaved reasoning, to mimic incremental human cognitive\nprocesses during navigation. To evaluate our method, we propose the R2R-Goal\ndataset, combining diverse synthetic and real-world trajectories. Empirical\nresults demonstrate significant improvements over state-of-the-art methods,\nachieving superior BLEU-4 and CIDEr scores along with robust cross-domain\ngeneralization.", "published": "2025-08-13 07:05:17", "link": "http://arxiv.org/abs/2508.09547v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Your Coding Intent is Secretly in the Context and You Should Deliberately Infer It Before Completion", "abstract": "Large Language Models (LLMs) are increasingly used for function completion in\nrepository-scale codebases. Prior studies demonstrate that when explicit\ninstructions--such as docstrings--are provided, these models can generate\nhighly accurate implementations. However, in real-world repositories, such\nannotations are frequently absent, and performance drops substantially without\nthem. To address this gap, we frame the task as a three-stage process. The\nfirst stage focuses on intent inference, where the model analyzes the code\npreceding the target function to uncover cues about the desired functionality.\nSuch preceding context often encodes subtle but critical information, and we\ndesign a reasoning-based prompting framework to guide the LLM through\nstep-by-step extraction and synthesis of these signals before any code is\ngenerated. The second stage introduces an optional interactive refinement\nmechanism to handle cases where preceding context alone is insufficient for\nintent recovery. In this stage, the model proposes a small set of candidate\nintentions, enabling the developer to select or edit them so that the inferred\nintent closely matches the actual requirement. Finally, in the third stage, the\nLLM generates the target function conditioned on the finalized intent. To\nsupport this pipeline, we curate a dataset of 40,000 examples annotated with\nintermediate reasoning traces and corresponding docstrings. Extensive\nexperiments on DevEval and ComplexCodeEval show that our approach consistently\nboosts multiple LLMs, achieving over 20\\% relative gains in both\nreference-based and execution-based metrics, with the interactive refinement\nstage delivering additional improvements beyond these gains.", "published": "2025-08-13 06:45:23", "link": "http://arxiv.org/abs/2508.09537v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "COXNet: Cross-Layer Fusion with Adaptive Alignment and Scale Integration for RGBT Tiny Object Detection", "abstract": "Detecting tiny objects in multimodal Red-Green-Blue-Thermal (RGBT) imagery is\na critical challenge in computer vision, particularly in surveillance, search\nand rescue, and autonomous navigation. Drone-based scenarios exacerbate these\nchallenges due to spatial misalignment, low-light conditions, occlusion, and\ncluttered backgrounds. Current methods struggle to leverage the complementary\ninformation between visible and thermal modalities effectively. We propose\nCOXNet, a novel framework for RGBT tiny object detection, addressing these\nissues through three core innovations: i) the Cross-Layer Fusion Module, fusing\nhigh-level visible and low-level thermal features for enhanced semantic and\nspatial accuracy; ii) the Dynamic Alignment and Scale Refinement module,\ncorrecting cross-modal spatial misalignments and preserving multi-scale\nfeatures; and iii) an optimized label assignment strategy using the GeoShape\nSimilarity Measure for better localization. COXNet achieves a 3.32\\% mAP$_{50}$\nimprovement on the RGBTDronePerson dataset over state-of-the-art methods,\ndemonstrating its effectiveness for robust detection in complex environments.", "published": "2025-08-13 06:30:03", "link": "http://arxiv.org/abs/2508.09533v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Decentralized Rank Scheduling for Energy-Constrained Multi-Task Federated Fine-Tuning in Edge-Assisted IoV Networks", "abstract": "Federated fine-tuning has emerged as a promising approach for adapting\nfoundation models (FMs) to diverse downstream tasks in edge environments. In\nInternet of Vehicles (IoV) systems, enabling efficient and low-latency\nmulti-task adaptation is particularly challenging due to client mobility,\nheterogeneous resources, and intermittent connectivity. This paper proposes a\nhierarchical federated fine-tuning framework that coordinates roadside units\n(RSUs) and vehicles to support resource-aware and mobility-resilient learning\nacross dynamic IoV scenarios. Leveraging Low-Rank Adaptation (LoRA), we\nintroduce a decentralized, energy-aware rank adaptation mechanism formulated as\na constrained multi-armed bandit problem. A novel UCB-DUAL algorithm is\ndeveloped to enable adaptive exploration under per-task energy budgets,\nachieving provable sublinear regret. To evaluate our method, we construct a\nlarge-scale IoV simulator based on real-world trajectories, capturing dynamic\nparticipation, RSU handoffs, and communication variability. Extensive\nexperiments show that our approach achieves the best accuracy-efficiency\ntrade-off among all baselines, reducing latency by over 24\\% and improving\naverage accuracy by more than 2.5\\%.", "published": "2025-08-13 06:29:00", "link": "http://arxiv.org/abs/2508.09532v1", "categories": ["cs.LG", "cs.AI", "cs.NI"], "primary_category": "cs.LG"}
{"title": "Generation of Indian Sign Language Letters, Numbers, and Words", "abstract": "Sign language, which contains hand movements, facial expressions and bodily\ngestures, is a significant medium for communicating with hard-of-hearing\npeople. A well-trained sign language community communicates easily, but those\nwho don't know sign language face significant challenges. Recognition and\ngeneration are basic communication methods between hearing and hard-of-hearing\nindividuals. Despite progress in recognition, sign language generation still\nneeds to be explored. The Progressive Growing of Generative Adversarial Network\n(ProGAN) excels at producing high-quality images, while the Self-Attention\nGenerative Adversarial Network (SAGAN) generates feature-rich images at medium\nresolutions. Balancing resolution and detail is crucial for sign language image\ngeneration. We are developing a Generative Adversarial Network (GAN) variant\nthat combines both models to generate feature-rich, high-resolution, and\nclass-conditional sign language images. Our modified Attention-based model\ngenerates high-quality images of Indian Sign Language letters, numbers, and\nwords, outperforming the traditional ProGAN in Inception Score (IS) and\nFr\\'echet Inception Distance (FID), with improvements of 3.2 and 30.12,\nrespectively. Additionally, we are publishing a large dataset incorporating\nhigh-quality images of Indian Sign Language alphabets, numbers, and 129 words.", "published": "2025-08-13 06:10:20", "link": "http://arxiv.org/abs/2508.09522v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "SMART-OC: A Real-time Time-risk Optimal Replanning Algorithm for Dynamic Obstacles and Spatio-temporally Varying Currents", "abstract": "Typical marine environments are highly complex with spatio-temporally varying\ncurrents and dynamic obstacles, presenting significant challenges to Unmanned\nSurface Vehicles (USVs) for safe and efficient navigation. Thus, the USVs need\nto continuously adapt their paths with real-time information to avoid\ncollisions and follow the path of least resistance to the goal via exploiting\nocean currents. In this regard, we introduce a novel algorithm, called\nSelf-Morphing Adaptive Replanning Tree for dynamic Obstacles and Currents\n(SMART-OC), that facilitates real-time time-risk optimal replanning in dynamic\nenvironments. SMART-OC integrates the obstacle risks along a path with the time\ncost to reach the goal to find the time-risk optimal path. The effectiveness of\nSMART-OC is validated by simulation experiments, which demonstrate that the USV\nperforms fast replannings to avoid dynamic obstacles and exploit ocean currents\nto successfully reach the goal.", "published": "2025-08-13 05:42:25", "link": "http://arxiv.org/abs/2508.09508v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "An Automated Multi-Modal Evaluation Framework for Mobile Intelligent Assistants", "abstract": "With the rapid development of mobile intelligent assistant technologies,\nmulti-modal AI assistants have become essential interfaces for daily user\ninteractions. However, current evaluation methods face challenges including\nhigh manual costs, inconsistent standards, and subjective bias. This paper\nproposes an automated multi-modal evaluation framework based on large language\nmodels and multi-agent collaboration. The framework employs a three-tier agent\narchitecture consisting of interaction evaluation agents, semantic verification\nagents, and experience decision agents. Through supervised fine-tuning on the\nQwen3-8B model, we achieve a significant evaluation matching accuracy with\nhuman experts. Experimental results on eight major intelligent agents\ndemonstrate the framework's effectiveness in predicting users' satisfaction and\nidentifying generation defects.", "published": "2025-08-13 05:40:34", "link": "http://arxiv.org/abs/2508.09507v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Verify Distributed Deep Learning Model Implementation Refinement with Iterative Relation Inference", "abstract": "Distributed machine learning training and inference is common today because\ntoday's large models require more memory and compute than can be provided by a\nsingle GPU. Distributed models are generally produced by programmers who take a\nsequential model specification and apply several distribution strategies to\ndistribute state and computation across GPUs. Unfortunately, bugs can be\nintroduced in the process, and a distributed model implementation's outputs\nmight differ from the sequential model's outputs. In this paper, we describe an\napproach to statically identify such bugs by checking model refinement, that\nis, can the sequential model's outputs be reconstructed from the distributed\nmodel's outputs? Our approach, implemented in GraphGuard, uses iterative\nrewriting to prove model refinement. Our approach can scale to today's large\nmodels and deployments: we evaluate it using GPT and Llama-3. Further, it\nprovides actionable output that aids in bug localization.", "published": "2025-08-13 05:33:25", "link": "http://arxiv.org/abs/2508.09505v1", "categories": ["cs.DC", "cs.AI"], "primary_category": "cs.DC"}
{"title": "Large-Small Model Collaborative Framework for Federated Continual Learning", "abstract": "Continual learning (CL) for Foundation Models (FMs) is an essential yet\nunderexplored challenge, especially in Federated Continual Learning (FCL),\nwhere each client learns from a private, evolving task stream under strict data\nand communication constraints. Despite their powerful generalization abilities,\nFMs often exhibit suboptimal performance on local downstream tasks, as they are\nunable to utilize private local data. Furthermore, enabling FMs to learn new\ntasks without forgetting prior knowledge is inherently a challenging problem,\nprimarily due to their immense parameter count and high model complexity. In\ncontrast, small models can be trained locally under resource-constrained\nconditions and benefit from more mature CL techniques. To bridge the gap\nbetween small models and FMs, we propose the first collaborative framework in\nFCL, where lightweight local models act as a dynamic bridge, continually\nadapting to new tasks while enhancing the utility of the large model. Two novel\ncomponents are also included: Small Model Continual Fine-tuning is for\npreventing small models from temporal forgetting; One-by-One Distillation\nperforms personalized fusion of heterogeneous local knowledge on the server.\nExperimental results demonstrate its superior performance, even when clients\nutilize heterogeneous small models.", "published": "2025-08-13 04:49:50", "link": "http://arxiv.org/abs/2508.09489v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Episodic Memory Representation for Long-form Video Understanding", "abstract": "Video Large Language Models (Video-LLMs) excel at general video understanding\nbut struggle with long-form videos due to context window limits. Consequently,\nrecent approaches focus on keyframe retrieval, condensing lengthy videos into a\nsmall set of informative frames. Despite their practicality, these methods\nsimplify the problem to static text image matching, overlooking spatio temporal\nrelationships crucial for capturing scene transitions and contextual\ncontinuity, and may yield redundant keyframes with limited information,\ndiluting salient cues essential for accurate video question answering. To\naddress these limitations, we introduce Video-EM, a training free framework\ninspired by the principles of human episodic memory, designed to facilitate\nrobust and contextually grounded reasoning. Rather than treating keyframes as\nisolated visual entities, Video-EM explicitly models them as temporally ordered\nepisodic events, capturing both spatial relationships and temporal dynamics\nnecessary for accurately reconstructing the underlying narrative. Furthermore,\nthe framework leverages chain of thought (CoT) thinking with LLMs to\niteratively identify a minimal yet highly informative subset of episodic\nmemories, enabling efficient and accurate question answering by Video-LLMs.\nExtensive evaluations on the Video-MME, EgoSchema, HourVideo, and LVBench\nbenchmarks confirm the superiority of Video-EM, which achieves highly\ncompetitive results with performance gains of 4-9 percent over respective\nbaselines while utilizing fewer frames.", "published": "2025-08-13 04:33:07", "link": "http://arxiv.org/abs/2508.09486v1", "categories": ["cs.CV", "cs.AI", "cs.MM"], "primary_category": "cs.CV"}
{"title": "DeepFeatIoT: Unifying Deep Learned, Randomized, and LLM Features for Enhanced IoT Time Series Sensor Data Classification in Smart Industries", "abstract": "Internet of Things (IoT) sensors are ubiquitous technologies deployed across\nsmart cities, industrial sites, and healthcare systems. They continuously\ngenerate time series data that enable advanced analytics and automation in\nindustries. However, challenges such as the loss or ambiguity of sensor\nmetadata, heterogeneity in data sources, varying sampling frequencies,\ninconsistent units of measurement, and irregular timestamps make raw IoT time\nseries data difficult to interpret, undermining the effectiveness of smart\nsystems. To address these challenges, we propose a novel deep learning model,\nDeepFeatIoT, which integrates learned local and global features with\nnon-learned randomized convolutional kernel-based features and features from\nlarge language models (LLMs). This straightforward yet unique fusion of diverse\nlearned and non-learned features significantly enhances IoT time series sensor\ndata classification, even in scenarios with limited labeled data. Our model's\neffectiveness is demonstrated through its consistent and generalized\nperformance across multiple real-world IoT sensor datasets from diverse\ncritical application domains, outperforming state-of-the-art benchmark models.\nThese results highlight DeepFeatIoT's potential to drive significant\nadvancements in IoT analytics and support the development of next-generation\nsmart systems.", "published": "2025-08-13 03:47:33", "link": "http://arxiv.org/abs/2508.09468v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Gen-AFFECT: Generation of Avatar Fine-grained Facial Expressions with Consistent identiTy", "abstract": "Different forms of customized 2D avatars are widely used in gaming\napplications, virtual communication, education, and content creation. However,\nexisting approaches often fail to capture fine-grained facial expressions and\nstruggle to preserve identity across different expressions. We propose\nGEN-AFFECT, a novel framework for personalized avatar generation that generates\nexpressive and identity-consistent avatars with a diverse set of facial\nexpressions. Our framework proposes conditioning a multimodal diffusion\ntransformer on an extracted identity-expression representation. This enables\nidentity preservation and representation of a wide range of facial expressions.\nGEN-AFFECT additionally employs consistent attention at inference for\ninformation sharing across the set of generated expressions, enabling the\ngeneration process to maintain identity consistency over the array of generated\nfine-grained expressions. GEN-AFFECT demonstrates superior performance compared\nto previous state-of-the-art methods on the basis of the accuracy of the\ngenerated expressions, the preservation of the identity and the consistency of\nthe target identity across an array of fine-grained facial expressions.", "published": "2025-08-13 03:35:35", "link": "http://arxiv.org/abs/2508.09461v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "RelayFormer: A Unified Local-Global Attention Framework for Scalable Image and Video Manipulation Localization", "abstract": "Visual manipulation localization (VML) -- across both images and videos -- is\na crucial task in digital forensics that involves identifying tampered regions\nin visual content. However, existing methods often lack cross-modal\ngeneralization and struggle to handle high-resolution or long-duration inputs\nefficiently.\n  We propose RelayFormer, a unified and modular architecture for visual\nmanipulation localization across images and videos. By leveraging flexible\nlocal units and a Global-Local Relay Attention (GLoRA) mechanism, it enables\nscalable, resolution-agnostic processing with strong generalization. Our\nframework integrates seamlessly with existing Transformer-based backbones, such\nas ViT and SegFormer, via lightweight adaptation modules that require only\nminimal architectural changes, ensuring compatibility without disrupting\npretrained representations.\n  Furthermore, we design a lightweight, query-based mask decoder that supports\none-shot inference across video sequences with linear complexity. Extensive\nexperiments across multiple benchmarks demonstrate that our approach achieves\nstate-of-the-art localization performance, setting a new baseline for scalable\nand modality-agnostic VML. Code is available at:\nhttps://github.com/WenOOI/RelayFormer.", "published": "2025-08-13 03:35:28", "link": "http://arxiv.org/abs/2508.09459v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Hallucination vs interpretation: rethinking accuracy and precision in AI-assisted data extraction for knowledge synthesis", "abstract": "Knowledge syntheses (literature reviews) are essential to health professions\neducation (HPE), consolidating findings to advance theory and practice.\nHowever, they are labor-intensive, especially during data extraction.\nArtificial Intelligence (AI)-assisted extraction promises efficiency but raises\nconcerns about accuracy, making it critical to distinguish AI 'hallucinations'\n(fabricated content) from legitimate interpretive differences. We developed an\nextraction platform using large language models (LLMs) to automate data\nextraction and compared AI to human responses across 187 publications and 17\nextraction questions from a published scoping review. AI-human, human-human,\nand AI-AI consistencies were measured using interrater reliability\n(categorical) and thematic similarity ratings (open-ended). Errors were\nidentified by comparing extracted responses to source publications. AI was\nhighly consistent with humans for concrete, explicitly stated questions (e.g.,\ntitle, aims) and lower for questions requiring subjective interpretation or\nabsent in text (e.g., Kirkpatrick's outcomes, study rationale). Human-human\nconsistency was not higher than AI-human and showed the same question-dependent\nvariability. Discordant AI-human responses (769/3179 = 24.2%) were mostly due\nto interpretive differences (18.3%); AI inaccuracies were rare (1.51%), while\nhumans were nearly three times more likely to state inaccuracies (4.37%).\nFindings suggest AI accuracy depends more on interpretability than\nhallucination. Repeating AI extraction can identify interpretive complexity or\nambiguity, refining processes before human review. AI can be a transparent,\ntrustworthy partner in knowledge synthesis, though caution is needed to\npreserve critical human insights.", "published": "2025-08-13 03:33:30", "link": "http://arxiv.org/abs/2508.09458v1", "categories": ["cs.HC", "cs.AI", "cs.ET"], "primary_category": "cs.HC"}
{"title": "A Unified Contrastive-Generative Framework for Time Series Classification", "abstract": "Self-supervised learning (SSL) for multivariate time series mainly includes\ntwo paradigms: contrastive methods that excel at instance discrimination and\ngenerative approaches that model data distributions. While effective\nindividually, their complementary potential remains unexplored. We propose a\nContrastive Generative Time series framework (CoGenT), the first framework to\nunify these paradigms through joint contrastive-generative optimization. CoGenT\naddresses fundamental limitations of both approaches: it overcomes contrastive\nlearning's sensitivity to high intra-class similarity in temporal data while\nreducing generative methods' dependence on large datasets. We evaluate CoGenT\non six diverse time series datasets. The results show consistent improvements,\nwith up to 59.2% and 14.27% F1 gains over standalone SimCLR and MAE,\nrespectively. Our analysis reveals that the hybrid objective preserves\ndiscriminative power while acquiring generative robustness. These findings\nestablish a foundation for hybrid SSL in temporal domains. We will release the\ncode shortly.", "published": "2025-08-13 03:09:14", "link": "http://arxiv.org/abs/2508.09451v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "What-Meets-Where: Unified Learning of Action and Contact Localization in a New Dataset", "abstract": "People control their bodies to establish contact with the environment. To\ncomprehensively understand actions across diverse visual contexts, it is\nessential to simultaneously consider \\textbf{what} action is occurring and\n\\textbf{where} it is happening. Current methodologies, however, often\ninadequately capture this duality, typically failing to jointly model both\naction semantics and their spatial contextualization within scenes. To bridge\nthis gap, we introduce a novel vision task that simultaneously predicts\nhigh-level action semantics and fine-grained body-part contact regions. Our\nproposed framework, PaIR-Net, comprises three key components: the Contact Prior\nAware Module (CPAM) for identifying contact-relevant body parts, the\nPrior-Guided Concat Segmenter (PGCS) for pixel-wise contact segmentation, and\nthe Interaction Inference Module (IIM) responsible for integrating global\ninteraction relationships. To facilitate this task, we present PaIR (Part-aware\nInteraction Representation), a comprehensive dataset containing 13,979 images\nthat encompass 654 actions, 80 object categories, and 17 body parts.\nExperimental evaluation demonstrates that PaIR-Net significantly outperforms\nbaseline approaches, while ablation studies confirm the efficacy of each\narchitectural component. The code and dataset will be released upon\npublication.", "published": "2025-08-13 02:06:33", "link": "http://arxiv.org/abs/2508.09428v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Implicit Hypergraph Neural Networks: A Stable Framework for Higher-Order Relational Learning with Provable Guarantees", "abstract": "Many real-world interactions are group-based rather than pairwise such as\npapers with multiple co-authors and users jointly engaging with items.\nHypergraph neural networks have shown great promise at modeling higher-order\nrelations, but their reliance on a fixed number of explicit message-passing\nlayers limits long-range dependency capture and can destabilize training as\ndepth grows. In this work, we introduce Implicit Hypergraph Neural Networks\n(IHGNN), which bring the implicit equilibrium formulation to hypergraphs:\ninstead of stacking layers, IHGNN computes representations as the solution to a\nnonlinear fixed-point equation, enabling stable and efficient global\npropagation across hyperedges without deep architectures. We develop a\nwell-posed training scheme with provable convergence, analyze the oversmoothing\nconditions and expressivity of the model, and derive a transductive\ngeneralization bound on hypergraphs. We further present an implicit-gradient\ntraining procedure coupled with a projection-based stabilization strategy.\nExtensive experiments on citation benchmarks show that IHGNN consistently\noutperforms strong traditional graph/hypergraph neural network baselines in\nboth accuracy and robustness. Empirically, IHGNN is resilient to random\ninitialization and hyperparameter variation, highlighting its strong\ngeneralization and practical value for higher-order relational learning.", "published": "2025-08-13 02:06:29", "link": "http://arxiv.org/abs/2508.09427v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Domain-Generalization to Improve Learning in Meta-Learning Algorithms", "abstract": "This paper introduces Domain Generalization Sharpness-Aware Minimization\nModel-Agnostic Meta-Learning (DGS-MAML), a novel meta-learning algorithm\ndesigned to generalize across tasks with limited training data. DGS-MAML\ncombines gradient matching with sharpness-aware minimization in a bi-level\noptimization framework to enhance model adaptability and robustness. We support\nour method with theoretical analysis using PAC-Bayes and convergence\nguarantees. Experimental results on benchmark datasets show that DGS-MAML\noutperforms existing approaches in terms of accuracy and generalization. The\nproposed method is particularly useful for scenarios requiring few-shot\nlearning and quick adaptation, and the source code is publicly available at\nGitHub.", "published": "2025-08-13 01:30:11", "link": "http://arxiv.org/abs/2508.09418v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "RampNet: A Two-Stage Pipeline for Bootstrapping Curb Ramp Detection in Streetscape Images from Open Government Metadata", "abstract": "Curb ramps are critical for urban accessibility, but robustly detecting them\nin images remains an open problem due to the lack of large-scale, high-quality\ndatasets. While prior work has attempted to improve data availability with\ncrowdsourced or manually labeled data, these efforts often fall short in either\nquality or scale. In this paper, we introduce and evaluate a two-stage pipeline\ncalled RampNet to scale curb ramp detection datasets and improve model\nperformance. In Stage 1, we generate a dataset of more than 210,000 annotated\nGoogle Street View (GSV) panoramas by auto-translating government-provided curb\nramp location data to pixel coordinates in panoramic images. In Stage 2, we\ntrain a curb ramp detection model (modified ConvNeXt V2) from the generated\ndataset, achieving state-of-the-art performance. To evaluate both stages of our\npipeline, we compare to manually labeled panoramas. Our generated dataset\nachieves 94.0% precision and 92.5% recall, and our detection model reaches\n0.9236 AP -- far exceeding prior work. Our work contributes the first\nlarge-scale, high-quality curb ramp detection dataset, benchmark, and model.", "published": "2025-08-13 01:22:48", "link": "http://arxiv.org/abs/2508.09415v1", "categories": ["cs.CV", "cs.AI", "I.2"], "primary_category": "cs.CV"}
{"title": "Story2Board: A Training-Free Approach for Expressive Storyboard Generation", "abstract": "We present Story2Board, a training-free framework for expressive storyboard\ngeneration from natural language. Existing methods narrowly focus on subject\nidentity, overlooking key aspects of visual storytelling such as spatial\ncomposition, background evolution, and narrative pacing. To address this, we\nintroduce a lightweight consistency framework composed of two components:\nLatent Panel Anchoring, which preserves a shared character reference across\npanels, and Reciprocal Attention Value Mixing, which softly blends visual\nfeatures between token pairs with strong reciprocal attention. Together, these\nmechanisms enhance coherence without architectural changes or fine-tuning,\nenabling state-of-the-art diffusion models to generate visually diverse yet\nconsistent storyboards. To structure generation, we use an off-the-shelf\nlanguage model to convert free-form stories into grounded panel-level prompts.\nTo evaluate, we propose the Rich Storyboard Benchmark, a suite of open-domain\nnarratives designed to assess layout diversity and background-grounded\nstorytelling, in addition to consistency. We also introduce a new Scene\nDiversity metric that quantifies spatial and pose variation across storyboards.\nOur qualitative and quantitative results, as well as a user study, show that\nStory2Board produces more dynamic, coherent, and narratively engaging\nstoryboards than existing baselines.", "published": "2025-08-13 17:56:26", "link": "http://arxiv.org/abs/2508.09983v1", "categories": ["cs.CV", "cs.GR", "cs.LG"], "primary_category": "cs.CV"}
{"title": "LLMC+: Benchmarking Vision-Language Model Compression with a Plug-and-play Toolkit", "abstract": "Large Vision-Language Models (VLMs) exhibit impressive multi-modal\ncapabilities but suffer from prohibitive computational and memory demands, due\nto their long visual token sequences and massive parameter sizes. To address\nthese issues, recent works have proposed training-free compression methods.\nHowever, existing efforts often suffer from three major limitations: (1)\nCurrent approaches do not decompose techniques into comparable modules,\nhindering fair evaluation across spatial and temporal redundancy. (2)\nEvaluation confined to simple single-turn tasks, failing to reflect performance\nin realistic scenarios. (3) Isolated use of individual compression techniques,\nwithout exploring their joint potential. To overcome these gaps, we introduce\nLLMC+, a comprehensive VLM compression benchmark with a versatile,\nplug-and-play toolkit. LLMC+ supports over 20 algorithms across five\nrepresentative VLM families and enables systematic study of token-level and\nmodel-level compression. Our benchmark reveals that: (1) Spatial and temporal\nredundancies demand distinct technical strategies. (2) Token reduction methods\ndegrade significantly in multi-turn dialogue and detail-sensitive tasks. (3)\nCombining token and model compression achieves extreme compression with minimal\nperformance loss. We believe LLMC+ will facilitate fair evaluation and inspire\nfuture research in efficient VLM. Our code is available at\nhttps://github.com/ModelTC/LightCompress.", "published": "2025-08-13 17:54:49", "link": "http://arxiv.org/abs/2508.09981v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Survey on 3D Gaussian Splatting Applications: Segmentation, Editing, and Generation", "abstract": "3D Gaussian Splatting (3DGS) has recently emerged as a powerful alternative\nto Neural Radiance Fields (NeRF) for 3D scene representation, offering\nhigh-fidelity photorealistic rendering with real-time performance. Beyond novel\nview synthesis, the explicit and compact nature of 3DGS enables a wide range of\ndownstream applications that require geometric and semantic understanding. This\nsurvey provides a comprehensive overview of recent progress in 3DGS\napplications. It first introduces 2D foundation models that support semantic\nunderstanding and control in 3DGS applications, followed by a review of\nNeRF-based methods that inform their 3DGS counterparts. We then categorize 3DGS\napplications into segmentation, editing, generation, and other functional\ntasks. For each, we summarize representative methods, supervision strategies,\nand learning paradigms, highlighting shared design principles and emerging\ntrends. Commonly used datasets and evaluation protocols are also summarized,\nalong with comparative analyses of recent methods across public benchmarks. To\nsupport ongoing research and development, a continually updated repository of\npapers, code, and resources is maintained at\nhttps://github.com/heshuting555/Awesome-3DGS-Applications.", "published": "2025-08-13 17:44:39", "link": "http://arxiv.org/abs/2508.09977v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PERSONA: Personalized Whole-Body 3D Avatar with Pose-Driven Deformations from a Single Image", "abstract": "Two major approaches exist for creating animatable human avatars. The first,\na 3D-based approach, optimizes a NeRF- or 3DGS-based avatar from videos of a\nsingle person, achieving personalization through a disentangled identity\nrepresentation. However, modeling pose-driven deformations, such as non-rigid\ncloth deformations, requires numerous pose-rich videos, which are costly and\nimpractical to capture in daily life. The second, a diffusion-based approach,\nlearns pose-driven deformations from large-scale in-the-wild videos but\nstruggles with identity preservation and pose-dependent identity entanglement.\nWe present PERSONA, a framework that combines the strengths of both approaches\nto obtain a personalized 3D human avatar with pose-driven deformations from a\nsingle image. PERSONA leverages a diffusion-based approach to generate\npose-rich videos from the input image and optimizes a 3D avatar based on them.\nTo ensure high authenticity and sharp renderings across diverse poses, we\nintroduce balanced sampling and geometry-weighted optimization. Balanced\nsampling oversamples the input image to mitigate identity shifts in\ndiffusion-generated training videos. Geometry-weighted optimization prioritizes\ngeometry constraints over image loss, preserving rendering quality in diverse\nposes.", "published": "2025-08-13 17:40:48", "link": "http://arxiv.org/abs/2508.09973v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Noise Hypernetworks: Amortizing Test-Time Compute in Diffusion Models", "abstract": "The new paradigm of test-time scaling has yielded remarkable breakthroughs in\nLarge Language Models (LLMs) (e.g. reasoning models) and in generative vision\nmodels, allowing models to allocate additional computation during inference to\neffectively tackle increasingly complex problems. Despite the improvements of\nthis approach, an important limitation emerges: the substantial increase in\ncomputation time makes the process slow and impractical for many applications.\nGiven the success of this paradigm and its growing usage, we seek to preserve\nits benefits while eschewing the inference overhead. In this work we propose\none solution to the critical problem of integrating test-time scaling knowledge\ninto a model during post-training. Specifically, we replace reward guided\ntest-time noise optimization in diffusion models with a Noise Hypernetwork that\nmodulates initial input noise. We propose a theoretically grounded framework\nfor learning this reward-tilted distribution for distilled generators, through\na tractable noise-space objective that maintains fidelity to the base model\nwhile optimizing for desired characteristics. We show that our approach\nrecovers a substantial portion of the quality gains from explicit test-time\noptimization at a fraction of the computational cost. Code is available at\nhttps://github.com/ExplainableML/HyperNoise", "published": "2025-08-13 17:33:37", "link": "http://arxiv.org/abs/2508.09968v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "MOC: Meta-Optimized Classifier for Few-Shot Whole Slide Image Classification", "abstract": "Recent advances in histopathology vision-language foundation models (VLFMs)\nhave shown promise in addressing data scarcity for whole slide image (WSI)\nclassification via zero-shot adaptation. However, these methods remain\noutperformed by conventional multiple instance learning (MIL) approaches\ntrained on large datasets, motivating recent efforts to enhance VLFM-based WSI\nclassification through fewshot learning paradigms. While existing few-shot\nmethods improve diagnostic accuracy with limited annotations, their reliance on\nconventional classifier designs introduces critical vulnerabilities to data\nscarcity. To address this problem, we propose a Meta-Optimized Classifier (MOC)\ncomprising two core components: (1) a meta-learner that automatically optimizes\na classifier configuration from a mixture of candidate classifiers and (2) a\nclassifier bank housing diverse candidate classifiers to enable a holistic\npathological interpretation. Extensive experiments demonstrate that MOC\noutperforms prior arts in multiple few-shot benchmarks. Notably, on the\nTCGA-NSCLC benchmark, MOC improves AUC by 10.4% over the state-of-the-art\nfew-shot VLFM-based methods, with gains up to 26.25% under 1-shot conditions,\noffering a critical advancement for clinical deployments where diagnostic\ntraining data is severely limited. Code is available at\nhttps://github.com/xmed-lab/MOC.", "published": "2025-08-13 17:32:42", "link": "http://arxiv.org/abs/2508.09967v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LIA-X: Interpretable Latent Portrait Animator", "abstract": "We introduce LIA-X, a novel interpretable portrait animator designed to\ntransfer facial dynamics from a driving video to a source portrait with\nfine-grained control. LIA-X is an autoencoder that models motion transfer as a\nlinear navigation of motion codes in latent space. Crucially, it incorporates a\nnovel Sparse Motion Dictionary that enables the model to disentangle facial\ndynamics into interpretable factors. Deviating from previous 'warp-render'\napproaches, the interpretability of the Sparse Motion Dictionary allows LIA-X\nto support a highly controllable 'edit-warp-render' strategy, enabling precise\nmanipulation of fine-grained facial semantics in the source portrait. This\nhelps to narrow initial differences with the driving video in terms of pose and\nexpression. Moreover, we demonstrate the scalability of LIA-X by successfully\ntraining a large-scale model with approximately 1 billion parameters on\nextensive datasets. Experimental results show that our proposed method\noutperforms previous approaches in both self-reenactment and cross-reenactment\ntasks across several benchmarks. Additionally, the interpretable and\ncontrollable nature of LIA-X supports practical applications such as\nfine-grained, user-guided image and video editing, as well as 3D-aware portrait\nvideo manipulation.", "published": "2025-08-13 17:22:05", "link": "http://arxiv.org/abs/2508.09959v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Stable Diffusion Models are Secretly Good at Visual In-Context Learning", "abstract": "Large language models (LLM) in natural language processing (NLP) have\ndemonstrated great potential for in-context learning (ICL) -- the ability to\nleverage a few sets of example prompts to adapt to various tasks without having\nto explicitly update the model weights. ICL has recently been explored for\ncomputer vision tasks with promising early outcomes. These approaches involve\nspecialized training and/or additional data that complicate the process and\nlimit its generalizability. In this work, we show that off-the-shelf Stable\nDiffusion models can be repurposed for visual in-context learning (V-ICL).\nSpecifically, we formulate an in-place attention re-computation within the\nself-attention layers of the Stable Diffusion architecture that explicitly\nincorporates context between the query and example prompts. Without any\nadditional fine-tuning, we show that this repurposed Stable Diffusion model is\nable to adapt to six different tasks: foreground segmentation, single object\ndetection, semantic segmentation, keypoint detection, edge detection, and\ncolorization. For example, the proposed approach improves the mean intersection\nover union (mIoU) for the foreground segmentation task on Pascal-5i dataset by\n8.9% and 3.2% over recent methods such as Visual Prompting and IMProv,\nrespectively. Additionally, we show that the proposed method is able to\neffectively leverage multiple prompts through ensembling to infer the task\nbetter and further improve the performance.", "published": "2025-08-13 17:08:22", "link": "http://arxiv.org/abs/2508.09949v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "AST-n: A Fast Sampling Approach for Low-Dose CT Reconstruction using Diffusion Models", "abstract": "Low-dose CT (LDCT) protocols reduce radiation exposure but increase image\nnoise, compromising diagnostic confidence. Diffusion-based generative models\nhave shown promise for LDCT denoising by learning image priors and performing\niterative refinement. In this work, we introduce AST-n, an accelerated\ninference framework that initiates reverse diffusion from intermediate noise\nlevels, and integrate high-order ODE solvers within conditioned models to\nfurther reduce sampling steps. We evaluate two acceleration paradigms--AST-n\nsampling and standard scheduling with high-order solvers -- on the Low Dose CT\nGrand Challenge dataset, covering head, abdominal, and chest scans at 10-25 %\nof standard dose. Conditioned models using only 25 steps (AST-25) achieve peak\nsignal-to-noise ratio (PSNR) above 38 dB and structural similarity index (SSIM)\nabove 0.95, closely matching standard baselines while cutting inference time\nfrom ~16 seg to under 1 seg per slice. Unconditional sampling suffers\nsubstantial quality loss, underscoring the necessity of conditioning. We also\nassess DDIM inversion, which yields marginal PSNR gains at the cost of doubling\ninference time, limiting its clinical practicality. Our results demonstrate\nthat AST-n with high-order samplers enables rapid LDCT reconstruction without\nsignificant loss of image fidelity, advancing the feasibility of\ndiffusion-based methods in clinical workflows.", "published": "2025-08-13 16:57:49", "link": "http://arxiv.org/abs/2508.09943v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Quo Vadis Handwritten Text Generation for Handwritten Text Recognition?", "abstract": "The digitization of historical manuscripts presents significant challenges\nfor Handwritten Text Recognition (HTR) systems, particularly when dealing with\nsmall, author-specific collections that diverge from the training data\ndistributions. Handwritten Text Generation (HTG) techniques, which generate\nsynthetic data tailored to specific handwriting styles, offer a promising\nsolution to address these challenges. However, the effectiveness of various HTG\nmodels in enhancing HTR performance, especially in low-resource transcription\nsettings, has not been thoroughly evaluated. In this work, we systematically\ncompare three state-of-the-art styled HTG models (representing the generative\nadversarial, diffusion, and autoregressive paradigms for HTG) to assess their\nimpact on HTR fine-tuning. We analyze how visual and linguistic characteristics\nof synthetic data influence fine-tuning outcomes and provide quantitative\nguidelines for selecting the most effective HTG model. The results of our\nanalysis provide insights into the current capabilities of HTG methods and\nhighlight key areas for further improvement in their application to\nlow-resource HTR.", "published": "2025-08-13 16:39:18", "link": "http://arxiv.org/abs/2508.09936v1", "categories": ["cs.CV", "cs.DL"], "primary_category": "cs.CV"}
{"title": "Towards Comprehensive Cellular Characterisation of H&E slides", "abstract": "Cell detection, segmentation and classification are essential for analyzing\ntumor microenvironments (TME) on hematoxylin and eosin (H&E) slides. Existing\nmethods suffer from poor performance on understudied cell types (rare or not\npresent in public datasets) and limited cross-domain generalization. To address\nthese shortcomings, we introduce HistoPLUS, a state-of-the-art model for cell\nanalysis, trained on a novel curated pan-cancer dataset of 108,722 nuclei\ncovering 13 cell types. In external validation across 4 independent cohorts,\nHistoPLUS outperforms current state-of-the-art models in detection quality by\n5.2% and overall F1 classification score by 23.7%, while using 5x fewer\nparameters. Notably, HistoPLUS unlocks the study of 7 understudied cell types\nand brings significant improvements on 8 of 13 cell types. Moreover, we show\nthat HistoPLUS robustly transfers to two oncology indications unseen during\ntraining. To support broader TME biomarker research, we release the model\nweights and inference code at https://github.com/owkin/histoplus/.", "published": "2025-08-13 16:24:15", "link": "http://arxiv.org/abs/2508.09926v1", "categories": ["cs.CV", "q-bio.QM", "I.2.10; I.4.8"], "primary_category": "cs.CV"}
{"title": "E-4DGS: High-Fidelity Dynamic Reconstruction from the Multi-view Event Cameras", "abstract": "Novel view synthesis and 4D reconstruction techniques predominantly rely on\nRGB cameras, thereby inheriting inherent limitations such as the dependence on\nadequate lighting, susceptibility to motion blur, and a limited dynamic range.\nEvent cameras, offering advantages of low power, high temporal resolution and\nhigh dynamic range, have brought a new perspective to addressing the scene\nreconstruction challenges in high-speed motion and low-light scenes. To this\nend, we propose E-4DGS, the first event-driven dynamic Gaussian Splatting\napproach, for novel view synthesis from multi-view event streams with\nfast-moving cameras. Specifically, we introduce an event-based initialization\nscheme to ensure stable training and propose event-adaptive slicing splatting\nfor time-aware reconstruction. Additionally, we employ intensity importance\npruning to eliminate floating artifacts and enhance 3D consistency, while\nincorporating an adaptive contrast threshold for more precise optimization. We\ndesign a synthetic multi-view camera setup with six moving event cameras\nsurrounding the object in a 360-degree configuration and provide a benchmark\nmulti-view event stream dataset that captures challenging motion scenarios. Our\napproach outperforms both event-only and event-RGB fusion baselines and paves\nthe way for the exploration of multi-view event-based reconstruction as a novel\napproach for rapid scene capture.", "published": "2025-08-13 16:09:36", "link": "http://arxiv.org/abs/2508.09912v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SpeechForensics: Audio-Visual Speech Representation Learning for Face Forgery Detection", "abstract": "Detection of face forgery videos remains a formidable challenge in the field\nof digital forensics, especially the generalization to unseen datasets and\ncommon perturbations. In this paper, we tackle this issue by leveraging the\nsynergy between audio and visual speech elements, embarking on a novel approach\nthrough audio-visual speech representation learning. Our work is motivated by\nthe finding that audio signals, enriched with speech content, can provide\nprecise information effectively reflecting facial movements. To this end, we\nfirst learn precise audio-visual speech representations on real videos via a\nself-supervised masked prediction task, which encodes both local and global\nsemantic information simultaneously. Then, the derived model is directly\ntransferred to the forgery detection task. Extensive experiments demonstrate\nthat our method outperforms the state-of-the-art methods in terms of\ncross-dataset generalization and robustness, without the participation of any\nfake video in model training. Code is available at\nhttps://github.com/Eleven4AI/SpeechForensics.", "published": "2025-08-13 16:09:36", "link": "http://arxiv.org/abs/2508.09913v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HumanGenesis: Agent-Based Geometric and Generative Modeling for Synthetic Human Dynamics", "abstract": "\\textbf{Synthetic human dynamics} aims to generate photorealistic videos of\nhuman subjects performing expressive, intention-driven motions. However,\ncurrent approaches face two core challenges: (1) \\emph{geometric inconsistency}\nand \\emph{coarse reconstruction}, due to limited 3D modeling and detail\npreservation; and (2) \\emph{motion generalization limitations} and \\emph{scene\ninharmonization}, stemming from weak generative capabilities. To address these,\nwe present \\textbf{HumanGenesis}, a framework that integrates geometric and\ngenerative modeling through four collaborative agents: (1)\n\\textbf{Reconstructor} builds 3D-consistent human-scene representations from\nmonocular video using 3D Gaussian Splatting and deformation decomposition. (2)\n\\textbf{Critique Agent} enhances reconstruction fidelity by identifying and\nrefining poor regions via multi-round MLLM-based reflection. (3) \\textbf{Pose\nGuider} enables motion generalization by generating expressive pose sequences\nusing time-aware parametric encoders. (4) \\textbf{Video Harmonizer} synthesizes\nphotorealistic, coherent video via a hybrid rendering pipeline with diffusion,\nrefining the Reconstructor through a Back-to-4D feedback loop. HumanGenesis\nachieves state-of-the-art performance on tasks including text-guided synthesis,\nvideo reenactment, and novel-pose generalization, significantly improving\nexpressiveness, geometric fidelity, and scene integration.", "published": "2025-08-13 14:50:19", "link": "http://arxiv.org/abs/2508.09858v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "OneVAE: Joint Discrete and Continuous Optimization Helps Discrete Video VAE Train Better", "abstract": "Encoding videos into discrete tokens could align with text tokens to\nfacilitate concise and unified multi-modal LLMs, yet introducing significant\nspatiotemporal compression compared to continuous video representation.\nPrevious discrete video VAEs experienced unstable training, long training time,\nand degraded reconstruction quality. Given the easier training and superior\nperformance of continuous VAEs, an intuitive idea is to enhance discrete video\nVAEs by leveraging continuous VAEs. After rethinking the intrinsic link between\ndiscrete and continuous representations, we found that FSQ could effectively\npreserve pre-trained continuous VAE priors compared to other quantization\nmethods. By leveraging continuous VAE priors, it converges several times faster\nthan training from scratch and achieves superior performance at convergence.\nMeanwhile, two structural improvements are proposed. First, inspired by how\ncontinuous VAEs enhance reconstruction via enlarged latent dimensions, we\nintroduce a multi-token quantization mechanism, which achieves nearly a 1 dB\nimprovement in PSNR without compromising the token compression ratio. Second,\nto tackle reconstruction challenges in high-compression video VAEs, we\nstrengthen first-frame reconstruction, enabling the causal VAE to leverage this\ninformation in subsequent frames and markedly improving the performance of 4 x\n16 x 16 discrete VAEs. Furthermore, we propose a joint discrete-continuous\noptimization scheme that unifies the two paradigms and, for the first time,\nachieves competitive performance on both continuous and discrete\nrepresentations within a single network. We name our method OneVAE to reflect\nthis connection.", "published": "2025-08-13 14:49:54", "link": "http://arxiv.org/abs/2508.09857v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Toward Human-Robot Teaming: Learning Handover Behaviors from 3D Scenes", "abstract": "Human-robot teaming (HRT) systems often rely on large-scale datasets of human\nand robot interactions, especially for close-proximity collaboration tasks such\nas human-robot handovers. Learning robot manipulation policies from raw,\nreal-world image data requires a large number of robot-action trials in the\nphysical environment. Although simulation training offers a cost-effective\nalternative, the visual domain gap between simulation and robot workspace\nremains a major limitation. We introduce a method for training HRT policies,\nfocusing on human-to-robot handovers, solely from RGB images without the need\nfor real-robot training or real-robot data collection. The goal is to enable\nthe robot to reliably receive objects from a human with stable grasping while\navoiding collisions with the human hand. The proposed policy learner leverages\nsparse-view Gaussian Splatting reconstruction of human-to-robot handover scenes\nto generate robot demonstrations containing image-action pairs captured with a\ncamera mounted on the robot gripper. As a result, the simulated camera pose\nchanges in the reconstructed scene can be directly translated into gripper pose\nchanges. Experiments in both Gaussian Splatting reconstructed scene and\nreal-world human-to-robot handover experiments demonstrate that our method\nserves as a new and effective representation for the human-to-robot handover\ntask, contributing to more seamless and robust HRT.", "published": "2025-08-13 14:47:31", "link": "http://arxiv.org/abs/2508.09855v1", "categories": ["cs.RO", "cs.CV", "cs.HC"], "primary_category": "cs.RO"}
{"title": "Do Vision Transformers See Like Humans? Evaluating their Perceptual Alignment", "abstract": "Vision Transformers (ViTs) achieve remarkable performance in image\nrecognition tasks, yet their alignment with human perception remains largely\nunexplored. This study systematically analyzes how model size, dataset size,\ndata augmentation and regularization impact ViT perceptual alignment with human\njudgments on the TID2013 dataset. Our findings confirm that larger models\nexhibit lower perceptual alignment, consistent with previous works. Increasing\ndataset diversity has a minimal impact, but exposing models to the same images\nmore times reduces alignment. Stronger data augmentation and regularization\nfurther decrease alignment, especially in models exposed to repeated training\ncycles. These results highlight a trade-off between model complexity, training\nstrategies, and alignment with human perception, raising important\nconsiderations for applications requiring human-like visual understanding.", "published": "2025-08-13 14:29:12", "link": "http://arxiv.org/abs/2508.09850v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ARI3D: A Software for Interactive Quantification of Regions in X-Ray CT 3D Images", "abstract": "X-ray computed tomography (CT) is the main 3D technique for imaging the\ninternal microstructures of materials. Quantitative analysis of the\nmicrostructures is usually achieved by applying a sequence of steps that are\nimplemented to the entire 3D image. This is challenged by various imaging\nartifacts inherent from the technique, e.g., beam hardening and partial volume.\nConsequently, the analysis requires users to make a number of decisions to\nsegment and classify the microstructures based on the voxel gray-values. In\nthis context, a software tool, here called ARI3D, is proposed to interactively\nanalyze regions in three-dimensional X-ray CT images, assisting users through\nthe various steps of a protocol designed to classify and quantify objects\nwithin regions of a three-dimensional image. ARI3D aims to 1) Improve phase\nidentification; 2) Account for partial volume effect; 3) Increase the detection\nlimit and accuracy of object quantification; and 4) Harmonize quantitative 3D\nanalysis that can be implemented in different fields of science.", "published": "2025-08-13 14:28:53", "link": "http://arxiv.org/abs/2508.09849v1", "categories": ["cs.CV", "cs.SE"], "primary_category": "cs.CV"}
{"title": "Enhancing Diffusion Face Generation with Contrastive Embeddings and SegFormer Guidance", "abstract": "We present a benchmark of diffusion models for human face generation on a\nsmall-scale CelebAMask-HQ dataset, evaluating both unconditional and\nconditional pipelines. Our study compares UNet and DiT architectures for\nunconditional generation and explores LoRA-based fine-tuning of pretrained\nStable Diffusion models as a separate experiment. Building on the\nmulti-conditioning approach of Giambi and Lisanti, which uses both attribute\nvectors and segmentation masks, our main contribution is the integration of an\nInfoNCE loss for attribute embedding and the adoption of a SegFormer-based\nsegmentation encoder. These enhancements improve the semantic alignment and\ncontrollability of attribute-guided synthesis. Our results highlight the\neffectiveness of contrastive embedding learning and advanced segmentation\nencoding for controlled face generation in limited data settings.", "published": "2025-08-13 14:27:47", "link": "http://arxiv.org/abs/2508.09847v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hierarchical Graph Attention Network for No-Reference Omnidirectional Image Quality Assessment", "abstract": "Current Omnidirectional Image Quality Assessment (OIQA) methods struggle to\nevaluate locally non-uniform distortions due to inadequate modeling of spatial\nvariations in quality and ineffective feature representation capturing both\nlocal details and global context. To address this, we propose a graph neural\nnetwork-based OIQA framework that explicitly models structural relationships\nbetween viewports to enhance perception of spatial distortion non-uniformity.\nOur approach employs Fibonacci sphere sampling to generate viewports with\nwell-structured topology, representing each as a graph node. Multi-stage\nfeature extraction networks then derive high-dimensional node representation.\nTo holistically capture spatial dependencies, we integrate a Graph Attention\nNetwork (GAT) modeling fine-grained local distortion variations among adjacent\nviewports, and a graph transformer capturing long-range quality interactions\nacross distant regions. Extensive experiments on two large-scale OIQA databases\nwith complex spatial distortions demonstrate that our method significantly\noutperforms existing approaches, confirming its effectiveness and strong\ngeneralization capability.", "published": "2025-08-13 14:25:24", "link": "http://arxiv.org/abs/2508.09843v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Robustness analysis of Deep Sky Objects detection models on HPC", "abstract": "Astronomical surveys and the growing involvement of amateur astronomers are\nproducing more sky images than ever before, and this calls for automated\nprocessing methods that are accurate and robust. Detecting Deep Sky Objects --\nsuch as galaxies, nebulae, and star clusters -- remains challenging because of\ntheir faint signals and complex backgrounds. Advances in Computer Vision and\nDeep Learning now make it possible to improve and automate this process. In\nthis paper, we present the training and comparison of different detection\nmodels (YOLO, RET-DETR) on smart telescope images, using High-Performance\nComputing (HPC) to parallelise computations, in particular for robustness\ntesting.", "published": "2025-08-13 14:05:48", "link": "http://arxiv.org/abs/2508.09831v1", "categories": ["astro-ph.IM", "cs.CV"], "primary_category": "astro-ph.IM"}
{"title": "Reverse Convolution and Its Applications to Image Restoration", "abstract": "Convolution and transposed convolution are fundamental operators widely used\nin neural networks. However, transposed convolution (a.k.a. deconvolution) does\nnot serve as a true inverse of convolution due to inherent differences in their\nmathematical formulations. To date, no reverse convolution operator has been\nestablished as a standard component in neural architectures. In this paper, we\npropose a novel depthwise reverse convolution operator as an initial attempt to\neffectively reverse depthwise convolution by formulating and solving a\nregularized least-squares optimization problem. We thoroughly investigate its\nkernel initialization, padding strategies, and other critical aspects to ensure\nits effective implementation. Building upon this operator, we further construct\na reverse convolution block by combining it with layer normalization,\n1$\\times$1 convolution, and GELU activation, forming a Transformer-like\nstructure. The proposed operator and block can directly replace conventional\nconvolution and transposed convolution layers in existing architectures,\nleading to the development of ConverseNet. Corresponding to typical image\nrestoration models such as DnCNN, SRResNet and USRNet, we train three variants\nof ConverseNet for Gaussian denoising, super-resolution and deblurring,\nrespectively. Extensive experiments demonstrate the effectiveness of the\nproposed reverse convolution operator as a basic building module. We hope this\nwork could pave the way for developing new operators in deep model design and\napplications.", "published": "2025-08-13 13:56:01", "link": "http://arxiv.org/abs/2508.09824v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "KonfAI: A Modular and Fully Configurable Framework for Deep Learning in Medical Imaging", "abstract": "KonfAI is a modular, extensible, and fully configurable deep learning\nframework specifically designed for medical imaging tasks. It enables users to\ndefine complete training, inference, and evaluation workflows through\nstructured YAML configuration files, without modifying the underlying code.\nThis declarative approach enhances reproducibility, transparency, and\nexperimental traceability while reducing development time. Beyond the\ncapabilities of standard pipelines, KonfAI provides native abstractions for\nadvanced strategies including patch-based learning, test-time augmentation,\nmodel ensembling, and direct access to intermediate feature representations for\ndeep supervision. It also supports complex multi-model training setups such as\ngenerative adversarial architectures. Thanks to its modular and extensible\narchitecture, KonfAI can easily accommodate custom models, loss functions, and\ndata processing components. The framework has been successfully applied to\nsegmentation, registration, and image synthesis tasks, and has contributed to\ntop-ranking results in several international medical imaging challenges. KonfAI\nis open source and available at\n\\href{https://github.com/vboussot/KonfAI}{https://github.com/vboussot/KonfAI}.", "published": "2025-08-13 13:55:43", "link": "http://arxiv.org/abs/2508.09823v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Physical Autoregressive Model for Robotic Manipulation without Action Pretraining", "abstract": "The scarcity of manipulation data has motivated the use of pretrained large\nmodels from other modalities in robotics. In this work, we build upon\nautoregressive video generation models to propose a Physical Autoregressive\nModel (PAR), where physical tokens combine frames and actions to represent the\njoint evolution of the robot and its environment. PAR leverages the world\nknowledge embedded in video pretraining to understand physical dynamics without\nrequiring action pretraining, enabling accurate video prediction and consistent\naction trajectories. It also adopts a DiT-based de-tokenizer to model frames\nand actions as continuous tokens, mitigating quantization errors and\nfacilitating mutual enhancement. Furthermore, we incorporate a causal mask with\ninverse kinematics, parallel training, and the KV-cache mechanism to further\nimprove performance and efficiency. Experiments on the ManiSkill benchmark show\nthat PAR achieves a 100\\% success rate on the PushCube task, matches the\nperformance of action-pretrained baselines on other tasks, and accurately\npredicts future videos with tightly aligned action trajectories. These findings\nunderscore a promising direction for robotic manipulation by transferring world\nknowledge from autoregressive video pretraining.", "published": "2025-08-13 13:54:51", "link": "http://arxiv.org/abs/2508.09822v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ViMoNet: A Multimodal Vision-Language Framework for Human Behavior Understanding from Motion and Video", "abstract": "This study investigates how large language models (LLMs) can be used to\nunderstand human behavior using motion and video data. We think that mixing\nboth types is essential to completely capture the nuanced movements and\nmeanings of human actions, in contrast to recent models that simply concentrate\non motion data or films. To address this, we provide ViMoNet, a straightforward\nyet effective framework for comprehending, characterizing, and deducing human\naction. ViMoNet employs a joint training strategy that leverages the advantages\nof two data types: detailed motion-text data, which is more exact, and generic\nvideo-text data, which is more comprehensive but less detailed. This aids in\nthe model's acquisition of rich data regarding time and space in human\nbehavior. Additionally, we provide a brand new dataset named VIMOS that\ncontains a variety of films, motion sequences, instructions, and subtitles. We\ndeveloped ViMoNet-Bench, a standardized benchmark with carefully labeled\nsamples, to evaluate how well models understand human behavior. Our tests show\nthat ViMoNet outperforms existing methods in caption generation, motion\nunderstanding, and behavior interpretation.", "published": "2025-08-13 13:54:16", "link": "http://arxiv.org/abs/2508.09818v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Evolution of Low-Level and Texture Human-CLIP Alignment", "abstract": "During the training of multi-modal models like CLIP, we observed an\nintriguing phenomenon: the correlation with low-level human image quality\nassessments peaks in the early epochs before gradually declining. This study\ninvestigates this observation and seeks to understand its causes through two\nkey factors: shape-texture bias alignment and classification accuracy drop\nunder noise. Our findings suggest that CLIP initially learn low-level visual\nfeatures, enhancing its alignment with low-level human perception but also\nincreasing its sensitivity to noise and its texture bias. As training\nprogresses, the model shifts toward more abstract shape-based representations,\nimproving noise robustness but reducing alignment with low-level human\nperception. These results suggest that these factors shared an underlying\nlearning mechanism and provide new insights into optimizing the trade-off\nbetween perceptual alignment and robustness in vision-language models.", "published": "2025-08-13 13:47:34", "link": "http://arxiv.org/abs/2508.09814v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Poaching Hotspot Identification Using Satellite Imagery", "abstract": "Elephant Poaching in African countries has been a decade-old problem. So much\nso that African Forest Elephants are now listed as an endangered species, and\nAfrican Savannah Elephants as critically endangered by the IUCN (International\nUnion for Conservation of Nature). [1] Elephants are hunted primarily for their\nivory tusks which caused many elephants to be born tuskless as a genetic\nmodification for survival. [2] Data gathered by recent studies shows that\nthough poaching methods remain the same, the poaching grounds are rather\ndynamic. Poachers have shifted to areas with less ranger patrols and several\nother factors like watering holes, seasons, altitude etc. cause constant shifts\nin poaching hotspot locations. [3] After a period of low poaching from\n2000-2014, poaching numbers in African countries are now on the rise again --\nWWF (World Wildlife Foundation) says there are 20,000 elephants poached\nannually [4]. In African countries, anti-poaching efforts are concentrated near\ntowns, while a majority of poaching occurs in the deserted regions. All of\nthese factors result in the need for a Computer Vision Model to identify\npoaching hotspots through locating the geographic indicators of favorable\npoaching regions. A CV model eliminates the need to manually track poachers and\naccount for the environmental factors to deploy resources and its combination\nwith satellite imagery allows us to survey large areas without disturbing local\nspecies or cross border aviation restrictions.", "published": "2025-08-13 13:44:26", "link": "http://arxiv.org/abs/2508.09812v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MUJICA: Reforming SISR Models for PBR Material Super-Resolution via Cross-Map Attention", "abstract": "Physically Based Rendering (PBR) materials are typically characterized by\nmultiple 2D texture maps such as basecolor, normal, metallic, and roughness\nwhich encode spatially-varying bi-directional reflectance distribution function\n(SVBRDF) parameters to model surface reflectance properties and microfacet\ninteractions. Upscaling SVBRDF material is valuable for modern 3D graphics\napplications. However, existing Single Image Super-Resolution (SISR) methods\nstruggle with cross-map inconsistency, inadequate modeling of modality-specific\nfeatures, and limited generalization due to data distribution shifts. In this\nwork, we propose Multi-modal Upscaling Joint Inference via Cross-map Attention\n(MUJICA), a flexible adapter that reforms pre-trained Swin-transformer-based\nSISR models for PBR material super-resolution. MUJICA is seamlessly attached\nafter the pre-trained and frozen SISR backbone. It leverages cross-map\nattention to fuse features while preserving remarkable reconstruction ability\nof the pre-trained SISR model. Applied to SISR models such as SwinIR, DRCT, and\nHMANet, MUJICA improves PSNR, SSIM, and LPIPS scores while preserving cross-map\nconsistency. Experiments demonstrate that MUJICA enables efficient training\neven with limited resources and delivers state-of-the-art performance on PBR\nmaterial datasets.", "published": "2025-08-13 13:34:39", "link": "http://arxiv.org/abs/2508.09802v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MeMoSORT: Memory-Assisted Filtering and Motion-Adaptive Association Metric for Multi-Person Tracking", "abstract": "Multi-object tracking (MOT) in human-dominant scenarios, which involves\ncontinuously tracking multiple people within video sequences, remains a\nsignificant challenge in computer vision due to targets' complex motion and\nsevere occlusions. Conventional tracking-by-detection methods are fundamentally\nlimited by their reliance on Kalman filter (KF) and rigid Intersection over\nUnion (IoU)-based association. The motion model in KF often mismatches\nreal-world object dynamics, causing filtering errors, while rigid association\nstruggles under occlusions, leading to identity switches or target loss. To\naddress these issues, we propose MeMoSORT, a simple, online, and real-time MOT\ntracker with two key innovations. First, the Memory-assisted Kalman filter\n(MeKF) uses memory-augmented neural networks to compensate for mismatches\nbetween assumed and actual object motion. Second, the Motion-adaptive IoU\n(Mo-IoU) adaptively expands the matching space and incorporates height\nsimilarity to reduce the influence of detection errors and association\nfailures, while remaining lightweight. Experiments on DanceTrack and SportsMOT\nshow that MeMoSORT achieves state-of-the-art performance, with HOTA scores of\n67.9\\% and 82.1\\%, respectively.", "published": "2025-08-13 13:26:31", "link": "http://arxiv.org/abs/2508.09796v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Describe What You See with Multimodal Large Language Models to Enhance Video Recommendations", "abstract": "Existing video recommender systems rely primarily on user-defined metadata or\non low-level visual and acoustic signals extracted by specialised encoders.\nThese low-level features describe what appears on the screen but miss deeper\nsemantics such as intent, humour, and world knowledge that make clips resonate\nwith viewers. For example, is a 30-second clip simply a singer on a rooftop, or\nan ironic parody filmed amid the fairy chimneys of Cappadocia, Turkey? Such\ndistinctions are critical to personalised recommendations yet remain invisible\nto traditional encoding pipelines. In this paper, we introduce a simple,\nrecommendation system-agnostic zero-finetuning framework that injects\nhigh-level semantics into the recommendation pipeline by prompting an\noff-the-shelf Multimodal Large Language Model (MLLM) to summarise each clip\ninto a rich natural-language description (e.g. \"a superhero parody with\nslapstick fights and orchestral stabs\"), bridging the gap between raw content\nand user intent. We use MLLM output with a state-of-the-art text encoder and\nfeed it into standard collaborative, content-based, and generative\nrecommenders. On the MicroLens-100K dataset, which emulates user interactions\nwith TikTok-style videos, our framework consistently surpasses conventional\nvideo, audio, and metadata features in five representative models. Our findings\nhighlight the promise of leveraging MLLMs as on-the-fly knowledge extractors to\nbuild more intent-aware video recommenders.", "published": "2025-08-13 13:19:31", "link": "http://arxiv.org/abs/2508.09789v1", "categories": ["cs.IR", "cs.CV"], "primary_category": "cs.IR"}
{"title": "DSS-Prompt: Dynamic-Static Synergistic Prompting for Few-Shot Class-Incremental Learning", "abstract": "Learning from large-scale pre-trained models with strong generalization\nability has shown remarkable success in a wide range of downstream tasks\nrecently, but it is still underexplored in the challenging few-shot\nclass-incremental learning (FSCIL) task. It aims to continually learn new\nconcepts from limited training samples without forgetting the old ones at the\nsame time. In this paper, we introduce DSS-Prompt, a simple yet effective\napproach that transforms the pre-trained Vision Transformer with minimal\nmodifications in the way of prompts into a strong FSCIL classifier. Concretely,\nwe synergistically utilize two complementary types of prompts in each\nTransformer block: static prompts to bridge the domain gap between the\npre-training and downstream datasets, thus enabling better adaption; and\ndynamic prompts to capture instance-aware semantics, thus enabling easy\ntransfer from base to novel classes. Specially, to generate dynamic prompts, we\nleverage a pre-trained multi-modal model to extract input-related diverse\nsemantics, thereby generating complementary input-aware prompts, and then\nadaptively adjust their importance across different layers. In this way, on top\nof the prompted visual embeddings, a simple prototype classifier can beat\nstate-of-the-arts without further training on the incremental tasks. We conduct\nextensive experiments on four benchmarks to validate the effectiveness of our\nDSS-Prompt and show that it consistently achieves better performance than\nexisting approaches on all datasets and can alleviate the catastrophic\nforgetting issue as well.", "published": "2025-08-13 13:10:18", "link": "http://arxiv.org/abs/2508.09785v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MoIIE: Mixture of Intra- and Inter-Modality Experts for Large Vision Language Models", "abstract": "Large Vision-Language Models (LVLMs) have demonstrated remarkable performance\nacross multi-modal tasks by scaling model size and training data. However,\nthese dense LVLMs incur significant computational costs and motivate the\nexploration of sparse Mixture of Experts (MoE) architectures. While MoE improve\nparameter efficiency, effectively applying MoE to simultaneously model\nmodality-specific features and cross-modal associations in LVLMs remains\nchallenging. In this work, we propose to incorporate Mixture of Intra- and\nInter-Modality Experts (MoIIE) to LVLMs. For each token, expert routing is\nguided by its modality, directing tokens to their respective intra-modality\nexperts as well as a shared pool of inter-modality experts, enabling the model\nto jointly learn rich intra-modal features and cross-modal interactions. We\nfurther introduce an effective and straightforward two-stage training strategy,\nwhich facilitates the direct activation of both MoE and multi-modal\ncapabilities. Extensive experiments across different data scales and LLM\nbackbone demonstrate the effectiveness, efficiency and generality of our\napproach. Notably, our MoIIE models with 5.5B and 11.3B activated parameters\nmatch or even surpass the performance of existing advanced open-source MoE-LLMs\nbased multi-modal models that involve more activated parameters. The code is\navailable at https://github.com/AlenjandroWang/MoIIE.", "published": "2025-08-13 13:00:05", "link": "http://arxiv.org/abs/2508.09779v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory", "abstract": "We introduce M3-Agent, a novel multimodal agent framework equipped with\nlong-term memory. Like humans, M3-Agent can process real-time visual and\nauditory inputs to build and update its long-term memory. Beyond episodic\nmemory, it also develops semantic memory, enabling it to accumulate world\nknowledge over time. Its memory is organized in an entity-centric, multimodal\nformat, allowing deeper and more consistent understanding of the environment.\nGiven an instruction, M3-Agent autonomously performs multi-turn, iterative\nreasoning and retrieves relevant information from memory to accomplish the\ntask. To evaluate memory effectiveness and memory-based reasoning in multimodal\nagents, we develop M3-Bench, a new long-video question answering benchmark.\nM3-Bench comprises 100 newly recorded real-world videos captured from a robot's\nperspective (M3-Bench-robot) and 929 web-sourced videos across diverse\nscenarios (M3-Bench-web). We annotate question-answer pairs designed to test\nkey capabilities essential for agent applications, such as human understanding,\ngeneral knowledge extraction, and cross-modal reasoning. Experimental results\nshow that M3-Agent, trained via reinforcement learning, outperforms the\nstrongest baseline, a prompting agent using Gemini-1.5-pro and GPT-4o,\nachieving 6.7%, 7.7%, and 5.3% higher accuracy on M3-Bench-robot, M3-Bench-web\nand VideoMME-long, respectively. Our work advances the multimodal agents toward\nmore human-like long-term memory and provides insights into their practical\ndesign. Model, code and data are available at\nhttps://github.com/bytedance-seed/m3-agent", "published": "2025-08-13 12:03:03", "link": "http://arxiv.org/abs/2508.09736v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Predictive Uncertainty for Runtime Assurance of a Real-Time Computer Vision-Based Landing System", "abstract": "Recent advances in data-driven computer vision have enabled robust autonomous\nnavigation capabilities for civil aviation, including automated landing and\nrunway detection. However, ensuring that these systems meet the robustness and\nsafety requirements for aviation applications remains a major challenge. In\nthis work, we present a practical vision-based pipeline for aircraft pose\nestimation from runway images that represents a step toward the ability to\ncertify these systems for use in safety-critical aviation applications. Our\napproach features three key innovations: (i) an efficient, flexible neural\narchitecture based on a spatial Soft Argmax operator for probabilistic keypoint\nregression, supporting diverse vision backbones with real-time inference; (ii)\na principled loss function producing calibrated predictive uncertainties, which\nare evaluated via sharpness and calibration metrics; and (iii) an adaptation of\nResidual-based Receiver Autonomous Integrity Monitoring (RAIM), enabling\nruntime detection and rejection of faulty model outputs. We implement and\nevaluate our pose estimation pipeline on a dataset of runway images. We show\nthat our model outperforms baseline architectures in terms of accuracy while\nalso producing well-calibrated uncertainty estimates with sub-pixel precision\nthat can be used downstream for fault detection.", "published": "2025-08-13 11:56:22", "link": "http://arxiv.org/abs/2508.09732v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Multimodal Sheaf-based Network for Glioblastoma Molecular Subtype Prediction", "abstract": "Glioblastoma is a highly invasive brain tumor with rapid progression rates.\nRecent studies have shown that glioblastoma molecular subtype classification\nserves as a significant biomarker for effective targeted therapy selection.\nHowever, this classification currently requires invasive tissue extraction for\ncomprehensive histopathological analysis. Existing multimodal approaches\ncombining MRI and histopathology images are limited and lack robust mechanisms\nfor preserving shared structural information across modalities. In particular,\ngraph-based models often fail to retain discriminative features within\nheterogeneous graphs, and structural reconstruction mechanisms for handling\nmissing or incomplete modality data are largely underexplored. To address these\nlimitations, we propose a novel sheaf-based framework for structure-aware and\nconsistent fusion of MRI and histopathology data. Our model outperforms\nbaseline methods and demonstrates robustness in incomplete or missing data\nscenarios, contributing to the development of virtual biopsy tools for rapid\ndiagnostics. Our source code is available at\nhttps://github.com/basiralab/MMSN/.", "published": "2025-08-13 11:11:33", "link": "http://arxiv.org/abs/2508.09717v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "NEURAL: Attention-Guided Pruning for Unified Multimodal Resource-Constrained Clinical Evaluation", "abstract": "The rapid growth of multimodal medical imaging data presents significant\nstorage and transmission challenges, particularly in resource-constrained\nclinical settings. We propose NEURAL, a novel framework that addresses this by\nusing semantics-guided data compression. Our approach repurposes\ncross-attention scores between the image and its radiological report from a\nfine-tuned generative vision-language model to structurally prune chest X-rays,\npreserving only diagnostically critical regions. This process transforms the\nimage into a highly compressed, graph representation. This unified graph-based\nrepresentation fuses the pruned visual graph with a knowledge graph derived\nfrom the clinical report, creating a universal data structure that simplifies\ndownstream modeling. Validated on the MIMIC-CXR and CheXpert Plus dataset for\npneumonia detection, NEURAL achieves a 93.4-97.7\\% reduction in image data size\nwhile maintaining a high diagnostic performance of 0.88-0.95 AUC, outperforming\nother baseline models that use uncompressed data. By creating a persistent,\ntask-agnostic data asset, NEURAL resolves the trade-off between data size and\nclinical utility, enabling efficient workflows and teleradiology without\nsacrificing performance. Our NEURAL code is available at\nhttps://github.com/basiralab/NEURAL.", "published": "2025-08-13 11:08:09", "link": "http://arxiv.org/abs/2508.09715v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "MangaDiT: Reference-Guided Line Art Colorization with Hierarchical Attention in Diffusion Transformers", "abstract": "Recent advances in diffusion models have significantly improved the\nperformance of reference-guided line art colorization. However, existing\nmethods still struggle with region-level color consistency, especially when the\nreference and target images differ in character pose or motion. Instead of\nrelying on external matching annotations between the reference and target, we\npropose to discover semantic correspondences implicitly through internal\nattention mechanisms. In this paper, we present MangaDiT, a powerful model for\nreference-guided line art colorization based on Diffusion Transformers (DiT).\nOur model takes both line art and reference images as conditional inputs and\nintroduces a hierarchical attention mechanism with a dynamic attention\nweighting strategy. This mechanism augments the vanilla attention with an\nadditional context-aware path that leverages pooled spatial features,\neffectively expanding the model's receptive field and enhancing region-level\ncolor alignment. Experiments on two benchmark datasets demonstrate that our\nmethod significantly outperforms state-of-the-art approaches, achieving\nsuperior performance in both qualitative and quantitative evaluations.", "published": "2025-08-13 11:02:11", "link": "http://arxiv.org/abs/2508.09709v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Slot Attention-based Feature Filtering for Few-Shot Learning", "abstract": "Irrelevant features can significantly degrade few-shot learn ing performance.\nThis problem is used to match queries and support images based on meaningful\nsimilarities despite the limited data. However, in this process, non-relevant\nfea tures such as background elements can easily lead to confu sion and\nmisclassification. To address this issue, we pro pose Slot Attention-based\nFeature Filtering for Few-Shot Learning (SAFF) that leverages slot attention\nmechanisms to discriminate and filter weak features, thereby improving few-shot\nclassification performance. The key innovation of SAFF lies in its integration\nof slot attention with patch em beddings, unifying class-aware slots into a\nsingle attention mechanism to filter irrelevant features effectively. We intro\nduce a similarity matrix that computes across support and query images to\nquantify the relevance of filtered embed dings for classification. Through\nexperiments, we demon strate that Slot Attention performs better than other\natten tion mechanisms, capturing discriminative features while reducing\nirrelevant information. We validate our approach through extensive experiments\non few-shot learning bench marks: CIFAR-FS, FC100, miniImageNet and tieredIma\ngeNet, outperforming several state-of-the-art methods.", "published": "2025-08-13 10:55:05", "link": "http://arxiv.org/abs/2508.09699v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Combating Noisy Labels via Dynamic Connection Masking", "abstract": "Noisy labels are inevitable in real-world scenarios. Due to the strong\ncapacity of deep neural networks to memorize corrupted labels, these noisy\nlabels can cause significant performance degradation. Existing research on\nmitigating the negative effects of noisy labels has mainly focused on robust\nloss functions and sample selection, with comparatively limited exploration of\nregularization in model architecture. Inspired by the sparsity regularization\nused in Kolmogorov-Arnold Networks (KANs), we propose a Dynamic Connection\nMasking (DCM) mechanism for both Multi-Layer Perceptron Networks (MLPs) and\nKANs to enhance the robustness of classifiers against noisy labels. The\nmechanism can adaptively mask less important edges during training by\nevaluating their information-carrying capacity. Through theoretical analysis,\nwe demonstrate its efficiency in reducing gradient error. Our approach can be\nseamlessly integrated into various noise-robust training methods to build more\nrobust deep networks, including robust loss functions, sample selection\nstrategies, and regularization techniques. Extensive experiments on both\nsynthetic and real-world benchmarks demonstrate that our method consistently\noutperforms state-of-the-art (SOTA) approaches. Furthermore, we are also the\nfirst to investigate KANs as classifiers against noisy labels, revealing their\nsuperior noise robustness over MLPs in real-world noisy scenarios. Our code\nwill soon be publicly available.", "published": "2025-08-13 10:51:46", "link": "http://arxiv.org/abs/2508.09697v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "PaCo-FR: Patch-Pixel Aligned End-to-End Codebook Learning for Facial Representation Pre-training", "abstract": "Facial representation pre-training is crucial for tasks like facial\nrecognition, expression analysis, and virtual reality. However, existing\nmethods face three key challenges: (1) failing to capture distinct facial\nfeatures and fine-grained semantics, (2) ignoring the spatial structure\ninherent to facial anatomy, and (3) inefficiently utilizing limited labeled\ndata. To overcome these, we introduce PaCo-FR, an unsupervised framework that\ncombines masked image modeling with patch-pixel alignment. Our approach\nintegrates three innovative components: (1) a structured masking strategy that\npreserves spatial coherence by aligning with semantically meaningful facial\nregions, (2) a novel patch-based codebook that enhances feature discrimination\nwith multiple candidate tokens, and (3) spatial consistency constraints that\npreserve geometric relationships between facial components. PaCo-FR achieves\nstate-of-the-art performance across several facial analysis tasks with just 2\nmillion unlabeled images for pre-training. Our method demonstrates significant\nimprovements, particularly in scenarios with varying poses, occlusions, and\nlighting conditions. We believe this work advances facial representation\nlearning and offers a scalable, efficient solution that reduces reliance on\nexpensive annotated datasets, driving more effective facial analysis systems.", "published": "2025-08-13 10:37:41", "link": "http://arxiv.org/abs/2508.09691v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GSFixer: Improving 3D Gaussian Splatting with Reference-Guided Video Diffusion Priors", "abstract": "Reconstructing 3D scenes using 3D Gaussian Splatting (3DGS) from sparse views\nis an ill-posed problem due to insufficient information, often resulting in\nnoticeable artifacts. While recent approaches have sought to leverage\ngenerative priors to complete information for under-constrained regions, they\nstruggle to generate content that remains consistent with input observations.\nTo address this challenge, we propose GSFixer, a novel framework designed to\nimprove the quality of 3DGS representations reconstructed from sparse inputs.\nThe core of our approach is the reference-guided video restoration model, built\nupon a DiT-based video diffusion model trained on paired artifact 3DGS renders\nand clean frames with additional reference-based conditions. Considering the\ninput sparse views as references, our model integrates both 2D semantic\nfeatures and 3D geometric features of reference views extracted from the visual\ngeometry foundation model, enhancing the semantic coherence and 3D consistency\nwhen fixing artifact novel views. Furthermore, considering the lack of suitable\nbenchmarks for 3DGS artifact restoration evaluation, we present DL3DV-Res which\ncontains artifact frames rendered using low-quality 3DGS. Extensive experiments\ndemonstrate our GSFixer outperforms current state-of-the-art methods in 3DGS\nartifact restoration and sparse-view 3D reconstruction. Project page:\nhttps://github.com/GVCLab/GSFixer.", "published": "2025-08-13 09:56:28", "link": "http://arxiv.org/abs/2508.09667v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "NegFaceDiff: The Power of Negative Context in Identity-Conditioned Diffusion for Synthetic Face Generation", "abstract": "The use of synthetic data as an alternative to authentic datasets in face\nrecognition (FR) development has gained significant attention, addressing\nprivacy, ethical, and practical concerns associated with collecting and using\nauthentic data. Recent state-of-the-art approaches have proposed\nidentity-conditioned diffusion models to generate identity-consistent face\nimages, facilitating their use in training FR models. However, these methods\noften lack explicit sampling mechanisms to enforce inter-class separability,\nleading to identity overlap in the generated data and, consequently, suboptimal\nFR performance. In this work, we introduce NegFaceDiff, a novel sampling method\nthat incorporates negative conditions into the identity-conditioned diffusion\nprocess. NegFaceDiff enhances identity separation by leveraging negative\nconditions that explicitly guide the model away from unwanted features while\npreserving intra-class consistency. Extensive experiments demonstrate that\nNegFaceDiff significantly improves the identity consistency and separability of\ndata generated by identity-conditioned diffusion models. Specifically, identity\nseparability, measured by the Fisher Discriminant Ratio (FDR), increases from\n2.427 to 5.687. These improvements are reflected in FR systems trained on the\nNegFaceDiff dataset, which outperform models trained on data generated without\nnegative conditions across multiple benchmarks.", "published": "2025-08-13 09:45:09", "link": "http://arxiv.org/abs/2508.09661v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Noise-adapted Neural Operator for Robust Non-Line-of-Sight Imaging", "abstract": "Computational imaging, especially non-line-of-sight (NLOS) imaging, the\nextraction of information from obscured or hidden scenes is achieved through\nthe utilization of indirect light signals resulting from multiple reflections\nor scattering. The inherently weak nature of these signals, coupled with their\nsusceptibility to noise, necessitates the integration of physical processes to\nensure accurate reconstruction. This paper presents a parameterized inverse\nproblem framework tailored for large-scale linear problems in 3D imaging\nreconstruction. Initially, a noise estimation module is employed to adaptively\nassess the noise levels present in transient data. Subsequently, a\nparameterized neural operator is developed to approximate the inverse mapping,\nfacilitating end-to-end rapid image reconstruction. Our 3D image reconstruction\nframework, grounded in operator learning, is constructed through deep algorithm\nunfolding, which not only provides commendable model interpretability but also\nenables dynamic adaptation to varying noise levels in the acquired data,\nthereby ensuring consistently robust and accurate reconstruction outcomes.\nFurthermore, we introduce a novel method for the fusion of global and local\nspatiotemporal data features. By integrating structural and detailed\ninformation, this method significantly enhances both accuracy and robustness.\nComprehensive numerical experiments conducted on both simulated and real\ndatasets substantiate the efficacy of the proposed method. It demonstrates\nremarkable performance with fast scanning data and sparse illumination point\ndata, offering a viable solution for NLOS imaging in complex scenarios.", "published": "2025-08-13 09:40:38", "link": "http://arxiv.org/abs/2508.09655v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TOTNet: Occlusion-Aware Temporal Tracking for Robust Ball Detection in Sports Videos", "abstract": "Robust ball tracking under occlusion remains a key challenge in sports video\nanalysis, affecting tasks like event detection and officiating. We present\nTOTNet, a Temporal Occlusion Tracking Network that leverages 3D convolutions,\nvisibility-weighted loss, and occlusion augmentation to improve performance\nunder partial and full occlusions. Developed in collaboration with Paralympics\nAustralia, TOTNet is designed for real-world sports analytics. We introduce\nTTA, a new occlusion-rich table tennis dataset collected from\nprofessional-level Paralympic matches, comprising 9,159 samples with 1,996\nocclusion cases. Evaluated on four datasets across tennis, badminton, and table\ntennis, TOTNet significantly outperforms prior state-of-the-art methods,\nreducing RMSE from 37.30 to 7.19 and improving accuracy on fully occluded\nframes from 0.63 to 0.80. These results demonstrate TOTNets effectiveness for\noffline sports analytics in fast-paced scenarios. Code and data\naccess:\\href{https://github.com/AugustRushG/TOTNet}{AugustRushG/TOTNet}.", "published": "2025-08-13 09:33:23", "link": "http://arxiv.org/abs/2508.09650v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "The Brain Resection Multimodal Image Registration (ReMIND2Reg) 2025 Challenge", "abstract": "Accurate intraoperative image guidance is critical for achieving maximal safe\nresection in brain tumor surgery, yet neuronavigation systems based on\npreoperative MRI lose accuracy during the procedure due to brain shift.\nAligning post-resection intraoperative ultrasound (iUS) with preoperative MRI\ncan restore spatial accuracy by estimating brain shift deformations, but it\nremains a challenging problem given the large anatomical and topological\nchanges and substantial modality intensity gap. The ReMIND2Reg 2025 Challenge\nprovides the largest public benchmark for this task, built upon the ReMIND\ndataset. It offers 99 training cases, 5 validation cases, and 10 private test\ncases comprising paired 3D ceT1 MRI, T2 MRI, and post-resection 3D iUS volumes.\nData are provided without annotations for training, while validation and test\nperformance are evaluated on manually annotated anatomical landmarks. Metrics\ninclude target registration error (TRE), robustness to worst-case landmark\nmisalignment (TRE30), and runtime. By establishing a standardized evaluation\nframework for this clinically critical and technically complex problem,\nReMIND2Reg aims to accelerate the development of robust, generalizable, and\nclinically deployable multimodal registration algorithms for image-guided\nneurosurgery.", "published": "2025-08-13 09:31:06", "link": "http://arxiv.org/abs/2508.09649v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multi-Sequence Parotid Gland Lesion Segmentation via Expert Text-Guided Segment Anything Model", "abstract": "Parotid gland lesion segmentation is essential for the treatment of parotid\ngland diseases. However, due to the variable size and complex lesion\nboundaries, accurate parotid gland lesion segmentation remains challenging.\nRecently, the Segment Anything Model (SAM) fine-tuning has shown remarkable\nperformance in the field of medical image segmentation. Nevertheless, SAM's\ninteraction segmentation model relies heavily on precise lesion prompts\n(points, boxes, masks, etc.), which are very difficult to obtain in real-world\napplications. Besides, current medical image segmentation methods are\nautomatically generated, ignoring the domain knowledge of medical experts when\nperforming segmentation. To address these limitations, we propose the parotid\ngland segment anything model (PG-SAM), an expert diagnosis text-guided SAM\nincorporating expert domain knowledge for cross-sequence parotid gland lesion\nsegmentation. Specifically, we first propose an expert diagnosis report guided\nprompt generation module that can automatically generate prompt information\ncontaining the prior domain knowledge to guide the subsequent lesion\nsegmentation process. Then, we introduce a cross-sequence attention module,\nwhich integrates the complementary information of different modalities to\nenhance the segmentation effect. Finally, the multi-sequence image features and\ngenerated prompts are feed into the decoder to get segmentation result.\nExperimental results demonstrate that PG-SAM achieves state-of-the-art\nperformance in parotid gland lesion segmentation across three independent\nclinical centers, validating its clinical applicability and the effectiveness\nof diagnostic text for enhancing image segmentation in real-world clinical\nsettings.", "published": "2025-08-13 09:25:29", "link": "http://arxiv.org/abs/2508.09645v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multi-Contrast Fusion Module: An attention mechanism integrating multi-contrast features for fetal torso plane classification", "abstract": "Purpose: Prenatal ultrasound is a key tool in evaluating fetal structural\ndevelopment and detecting abnormalities, contributing to reduced perinatal\ncomplications and improved neonatal survival. Accurate identification of\nstandard fetal torso planes is essential for reliable assessment and\npersonalized prenatal care. However, limitations such as low contrast and\nunclear texture details in ultrasound imaging pose significant challenges for\nfine-grained anatomical recognition. Methods: We propose a novel Multi-Contrast\nFusion Module (MCFM) to enhance the model's ability to extract detailed\ninformation from ultrasound images. MCFM operates exclusively on the lower\nlayers of the neural network, directly processing raw ultrasound data. By\nassigning attention weights to image representations under different contrast\nconditions, the module enhances feature modeling while explicitly maintaining\nminimal parameter overhead. Results: The proposed MCFM was evaluated on a\ncurated dataset of fetal torso plane ultrasound images. Experimental results\ndemonstrate that MCFM substantially improves recognition performance, with a\nminimal increase in model complexity. The integration of multi-contrast\nattention enables the model to better capture subtle anatomical structures,\ncontributing to higher classification accuracy and clinical reliability.\nConclusions: Our method provides an effective solution for improving fetal\ntorso plane recognition in ultrasound imaging. By enhancing feature\nrepresentation through multi-contrast fusion, the proposed approach supports\nclinicians in achieving more accurate and consistent diagnoses, demonstrating\nstrong potential for clinical adoption in prenatal screening. The codes are\navailable at https://github.com/sysll/MCFM.", "published": "2025-08-13 09:24:22", "link": "http://arxiv.org/abs/2508.09644v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Enhancing Monocular 3D Hand Reconstruction with Learned Texture Priors", "abstract": "We revisit the role of texture in monocular 3D hand reconstruction, not as an\nafterthought for photorealism, but as a dense, spatially grounded cue that can\nactively support pose and shape estimation. Our observation is simple: even in\nhigh-performing models, the overlay between predicted hand geometry and image\nappearance is often imperfect, suggesting that texture alignment may be an\nunderused supervisory signal. We propose a lightweight texture module that\nembeds per-pixel observations into UV texture space and enables a novel dense\nalignment loss between predicted and observed hand appearances. Our approach\nassumes access to a differentiable rendering pipeline and a model that maps\nimages to 3D hand meshes with known topology, allowing us to back-project a\ntextured hand onto the image and perform pixel-based alignment. The module is\nself-contained and easily pluggable into existing reconstruction pipelines. To\nisolate and highlight the value of texture-guided supervision, we augment\nHaMeR, a high-performing yet unadorned transformer architecture for 3D hand\npose estimation. The resulting system improves both accuracy and realism,\ndemonstrating the value of appearance-guided alignment in hand reconstruction.", "published": "2025-08-13 08:59:51", "link": "http://arxiv.org/abs/2508.09629v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Semantic-aware DropSplat: Adaptive Pruning of Redundant Gaussians for 3D Aerial-View Segmentation", "abstract": "In the task of 3D Aerial-view Scene Semantic Segmentation (3D-AVS-SS),\ntraditional methods struggle to address semantic ambiguity caused by scale\nvariations and structural occlusions in aerial images. This limits their\nsegmentation accuracy and consistency. To tackle these challenges, we propose a\nnovel 3D-AVS-SS approach named SAD-Splat. Our method introduces a Gaussian\npoint drop module, which integrates semantic confidence estimation with a\nlearnable sparsity mechanism based on the Hard Concrete distribution. This\nmodule effectively eliminates redundant and semantically ambiguous Gaussian\npoints, enhancing both segmentation performance and representation compactness.\nFurthermore, SAD-Splat incorporates a high-confidence pseudo-label generation\npipeline. It leverages 2D foundation models to enhance supervision when\nground-truth labels are limited, thereby further improving segmentation\naccuracy. To advance research in this domain, we introduce a challenging\nbenchmark dataset: 3D Aerial Semantic (3D-AS), which encompasses diverse\nreal-world aerial scenes with sparse annotations. Experimental results\ndemonstrate that SAD-Splat achieves an excellent balance between segmentation\naccuracy and representation compactness. It offers an efficient and scalable\nsolution for 3D aerial scene understanding.", "published": "2025-08-13 08:57:38", "link": "http://arxiv.org/abs/2508.09626v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Plane Detection and Ranking via Model Information Optimization", "abstract": "Plane detection from depth images is a crucial subtask with broad robotic\napplications, often accomplished by iterative methods such as Random Sample\nConsensus (RANSAC). While RANSAC is a robust strategy with strong probabilistic\nguarantees, the ambiguity of its inlier threshold criterion makes it\nsusceptible to false positive plane detections. This issue is particularly\nprevalent in complex real-world scenes, where the true number of planes is\nunknown and multiple planes coexist. In this paper, we aim to address this\nlimitation by proposing a generalised framework for plane detection based on\nmodel information optimization. Building on previous works, we treat the\nobserved depth readings as discrete random variables, with their probability\ndistributions constrained by the ground truth planes. Various models containing\ndifferent candidate plane constraints are then generated through repeated\nrandom sub-sampling to explain our observations. By incorporating the physics\nand noise model of the depth sensor, we can calculate the information for each\nmodel, and the model with the least information is accepted as the most likely\nground truth. This information optimization process serves as an objective\nmechanism for determining the true number of planes and preventing false\npositive detections. Additionally, the quality of each detected plane can be\nranked by summing the information reduction of inlier points for each plane. We\nvalidate these properties through experiments with synthetic data and find that\nour algorithm estimates plane parameters more accurately compared to the\ndefault Open3D RANSAC plane segmentation. Furthermore, we accelerate our\nalgorithm by partitioning the depth map using neural network segmentation,\nwhich enhances its ability to generate more realistic plane parameters in\nreal-world data.", "published": "2025-08-13 08:56:05", "link": "http://arxiv.org/abs/2508.09625v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "BridgeTA: Bridging the Representation Gap in Knowledge Distillation via Teacher Assistant for Bird's Eye View Map Segmentation", "abstract": "Bird's-Eye-View (BEV) map segmentation is one of the most important and\nchallenging tasks in autonomous driving. Camera-only approaches have drawn\nattention as cost-effective alternatives to LiDAR, but they still fall behind\nLiDAR-Camera (LC) fusion-based methods. Knowledge Distillation (KD) has been\nexplored to narrow this gap, but existing methods mainly enlarge the student\nmodel by mimicking the teacher's architecture, leading to higher inference\ncost. To address this issue, we introduce BridgeTA, a cost-effective\ndistillation framework to bridge the representation gap between LC fusion and\nCamera-only models through a Teacher Assistant (TA) network while keeping the\nstudent's architecture and inference cost unchanged. A lightweight TA network\ncombines the BEV representations of the teacher and student, creating a shared\nlatent space that serves as an intermediate representation. To ground the\nframework theoretically, we derive a distillation loss using Young's\nInequality, which decomposes the direct teacher-student distillation path into\nteacher-TA and TA-student dual paths, stabilizing optimization and\nstrengthening knowledge transfer. Extensive experiments on the challenging\nnuScenes dataset demonstrate the effectiveness of our method, achieving an\nimprovement of 4.2% mIoU over the Camera-only baseline, up to 45% higher than\nthe improvement of other state-of-the-art KD methods.", "published": "2025-08-13 08:28:21", "link": "http://arxiv.org/abs/2508.09599v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Images Speak Louder Than Scores: Failure Mode Escape for Enhancing Generative Quality", "abstract": "Diffusion models have achieved remarkable progress in class-to-image\ngeneration. However, we observe that despite impressive FID scores,\nstate-of-the-art models often generate distorted or low-quality images,\nespecially in certain classes. This gap arises because FID evaluates global\ndistribution alignment, while ignoring the perceptual quality of individual\nsamples. We further examine the role of CFG, a common technique used to enhance\ngeneration quality. While effective in improving metrics and suppressing\noutliers, CFG can introduce distribution shift and visual artifacts due to its\nmisalignment with both training objectives and user expectations. In this work,\nwe propose FaME, a training-free and inference-efficient method for improving\nperceptual quality. FaME uses an image quality assessment model to identify\nlow-quality generations and stores their sampling trajectories. These failure\nmodes are then used as negative guidance to steer future sampling away from\npoor-quality regions. Experiments on ImageNet demonstrate that FaME brings\nconsistent improvements in visual quality without compromising FID. FaME also\nshows the potential to be extended to improve text-to-image generation.", "published": "2025-08-13 08:28:14", "link": "http://arxiv.org/abs/2508.09598v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SVG-Head: Hybrid Surface-Volumetric Gaussians for High-Fidelity Head Reconstruction and Real-Time Editing", "abstract": "Creating high-fidelity and editable head avatars is a pivotal challenge in\ncomputer vision and graphics, boosting many AR/VR applications. While recent\nadvancements have achieved photorealistic renderings and plausible animation,\nhead editing, especially real-time appearance editing, remains challenging due\nto the implicit representation and entangled modeling of the geometry and\nglobal appearance. To address this, we propose Surface-Volumetric Gaussian Head\nAvatar (SVG-Head), a novel hybrid representation that explicitly models the\ngeometry with 3D Gaussians bound on a FLAME mesh and leverages disentangled\ntexture images to capture the global appearance. Technically, it contains two\ntypes of Gaussians, in which surface Gaussians explicitly model the appearance\nof head avatars using learnable texture images, facilitating real-time texture\nediting, while volumetric Gaussians enhance the reconstruction quality of\nnon-Lambertian regions (e.g., lips and hair). To model the correspondence\nbetween 3D world and texture space, we provide a mesh-aware Gaussian UV mapping\nmethod, which leverages UV coordinates given by the FLAME mesh to obtain sharp\ntexture images and real-time rendering speed. A hierarchical optimization\nstrategy is further designed to pursue the optimal performance in both\nreconstruction quality and editing flexibility. Experiments on the NeRSemble\ndataset show that SVG-Head not only generates high-fidelity rendering results,\nbut also is the first method to obtain explicit texture images for Gaussian\nhead avatars and support real-time appearance editing.", "published": "2025-08-13 08:27:55", "link": "http://arxiv.org/abs/2508.09597v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Offline Auto Labeling: BAAS", "abstract": "This paper introduces BAAS, a new Extended Object Tracking (EOT) and\nfusion-based label annotation framework for radar detections in autonomous\ndriving. Our framework utilizes Bayesian-based tracking, smoothing and\neventually fusion methods to provide veritable and precise object trajectories\nalong with shape estimation to provide annotation labels on the detection level\nunder various supervision levels. Simultaneously, the framework provides\nevaluation of tracking performance and label annotation. If manually labeled\ndata is available, each processing module can be analyzed independently or\ncombined with other modules to enable closed-loop continuous improvements. The\nframework performance is evaluated in a challenging urban real-world scenario\nin terms of tracking performance and the label annotation errors. We\ndemonstrate the functionality of the proposed approach for varying dynamic\nobjects and class types", "published": "2025-08-13 07:58:59", "link": "http://arxiv.org/abs/2508.09585v1", "categories": ["cs.CV", "cs.SY", "eess.SY"], "primary_category": "cs.CV"}
{"title": "SHALE: A Scalable Benchmark for Fine-grained Hallucination Evaluation in LVLMs", "abstract": "Despite rapid advances, Large Vision-Language Models (LVLMs) still suffer\nfrom hallucinations, i.e., generating content inconsistent with input or\nestablished world knowledge, which correspond to faithfulness and factuality\nhallucinations, respectively. Prior studies primarily evaluate faithfulness\nhallucination at a coarse level (e.g., object-level) and lack fine-grained\nanalysis. Additionally, existing benchmarks rely on costly manual curation or\nreused public datasets, raising concerns about scalability and data leakage. To\naddress these limitations, we propose an automated data construction pipeline\nthat produces scalable, controllable, and diverse evaluation data. We also\ndesign a hierarchical hallucination induction framework with input\nperturbations to simulate realistic noisy scenarios. Integrating these designs,\nwe construct SHALE, a Scalable HALlucination Evaluation benchmark designed to\nassess both faithfulness and factuality hallucinations via a fine-grained\nhallucination categorization scheme. SHALE comprises over 30K image-instruction\npairs spanning 12 representative visual perception aspects for faithfulness and\n6 knowledge domains for factuality, considering both clean and noisy scenarios.\nExtensive experiments on over 20 mainstream LVLMs reveal significant factuality\nhallucinations and high sensitivity to semantic perturbations.", "published": "2025-08-13 07:58:01", "link": "http://arxiv.org/abs/2508.09584v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Dual Recursive Feedback on Generation and Appearance Latents for Pose-Robust Text-to-Image Diffusion", "abstract": "Recent advancements in controllable text-to-image (T2I) diffusion models,\nsuch as Ctrl-X and FreeControl, have demonstrated robust spatial and appearance\ncontrol without requiring auxiliary module training. However, these models\noften struggle to accurately preserve spatial structures and fail to capture\nfine-grained conditions related to object poses and scene layouts. To address\nthese challenges, we propose a training-free Dual Recursive Feedback (DRF)\nsystem that properly reflects control conditions in controllable T2I models.\nThe proposed DRF consists of appearance feedback and generation feedback that\nrecursively refines the intermediate latents to better reflect the given\nappearance information and the user's intent. This dual-update mechanism guides\nlatent representations toward reliable manifolds, effectively integrating\nstructural and appearance attributes. Our approach enables fine-grained\ngeneration even between class-invariant structure-appearance fusion, such as\ntransferring human motion onto a tiger's form. Extensive experiments\ndemonstrate the efficacy of our method in producing high-quality, semantically\ncoherent, and structurally consistent image generations. Our source code is\navailable at https://github.com/jwonkm/DRF.", "published": "2025-08-13 07:46:00", "link": "http://arxiv.org/abs/2508.09575v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Chain of Diagnosis Framework for Accurate and Explainable Radiology Report Generation", "abstract": "Despite the progress of radiology report generation (RRG), existing works\nface two challenges: 1) The performances in clinical efficacy are\nunsatisfactory, especially for lesion attributes description; 2) the generated\ntext lacks explainability, making it difficult for radiologists to trust the\nresults. To address the challenges, we focus on a trustworthy RRG model, which\nnot only generates accurate descriptions of abnormalities, but also provides\nbasis of its predictions. To this end, we propose a framework named chain of\ndiagnosis (CoD), which maintains a chain of diagnostic process for clinically\naccurate and explainable RRG. It first generates question-answer (QA) pairs via\ndiagnostic conversation to extract key findings, then prompts a large language\nmodel with QA diagnoses for accurate generation. To enhance explainability, a\ndiagnosis grounding module is designed to match QA diagnoses and generated\nsentences, where the diagnoses act as a reference. Moreover, a lesion grounding\nmodule is designed to locate abnormalities in the image, further improving the\nworking efficiency of radiologists. To facilitate label-efficient training, we\npropose an omni-supervised learning strategy with clinical consistency to\nleverage various types of annotations from different datasets. Our efforts lead\nto 1) an omni-labeled RRG dataset with QA pairs and lesion boxes; 2) a\nevaluation tool for assessing the accuracy of reports in describing lesion\nlocation and severity; 3) extensive experiments to demonstrate the\neffectiveness of CoD, where it outperforms both specialist and generalist\nmodels consistently on two RRG benchmarks and shows promising explainability by\naccurately grounding generated sentences to QA diagnoses and images.", "published": "2025-08-13 07:32:28", "link": "http://arxiv.org/abs/2508.09566v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "WEC-DG: Multi-Exposure Wavelet Correction Method Guided by Degradation Description", "abstract": "Multi-exposure correction technology is essential for restoring images\naffected by insufficient or excessive lighting, enhancing the visual experience\nby improving brightness, contrast, and detail richness. However, current\nmulti-exposure correction methods often encounter challenges in addressing\nintra-class variability caused by diverse lighting conditions, shooting\nenvironments, and weather factors, particularly when processing images captured\nat a single exposure level. To enhance the adaptability of these models under\ncomplex imaging conditions, this paper proposes a Wavelet-based Exposure\nCorrection method with Degradation Guidance (WEC-DG). Specifically, we\nintroduce a degradation descriptor within the Exposure Consistency Alignment\nModule (ECAM) at both ends of the processing pipeline to ensure exposure\nconsistency and achieve final alignment. This mechanism effectively addresses\nmiscorrected exposure anomalies caused by existing methods' failure to\nrecognize 'blurred' exposure degradation. Additionally, we investigate the\nlight-detail decoupling properties of the wavelet transform to design the\nExposure Restoration and Detail Reconstruction Module (EDRM), which processes\nlow-frequency information related to exposure enhancement before utilizing\nhigh-frequency information as a prior guide for reconstructing spatial domain\ndetails. This serial processing strategy guarantees precise light correction\nand enhances detail recovery. Extensive experiments conducted on multiple\npublic datasets demonstrate that the proposed method outperforms existing\nalgorithms, achieving significant performance improvements and validating its\neffectiveness and practical applicability.", "published": "2025-08-13 07:31:44", "link": "http://arxiv.org/abs/2508.09565v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "WeatherPrompt: Multi-modality Representation Learning for All-Weather Drone Visual Geo-Localization", "abstract": "Visual geo-localization for drones faces critical degradation under weather\nperturbations, \\eg, rain and fog, where existing methods struggle with two\ninherent limitations: 1) Heavy reliance on limited weather categories that\nconstrain generalization, and 2) Suboptimal disentanglement of entangled\nscene-weather features through pseudo weather categories. We present\nWeatherPrompt, a multi-modality learning paradigm that establishes\nweather-invariant representations through fusing the image embedding with the\ntext context. Our framework introduces two key contributions: First, a\nTraining-free Weather Reasoning mechanism that employs off-the-shelf large\nmulti-modality models to synthesize multi-weather textual descriptions through\nhuman-like reasoning. It improves the scalability to unseen or complex weather,\nand could reflect different weather strength. Second, to better disentangle the\nscene and weather feature, we propose a multi-modality framework with the\ndynamic gating mechanism driven by the text embedding to adaptively reweight\nand fuse visual features across modalities. The framework is further optimized\nby the cross-modal objectives, including image-text contrastive learning and\nimage-text matching, which maps the same scene with different weather\nconditions closer in the respresentation space. Extensive experiments validate\nthat, under diverse weather conditions, our method achieves competitive recall\nrates compared to state-of-the-art drone geo-localization methods. Notably, it\nimproves Recall@1 by +13.37\\% under night conditions and by 18.69\\% under fog\nand snow conditions.", "published": "2025-08-13 07:28:41", "link": "http://arxiv.org/abs/2508.09560v1", "categories": ["cs.CV", "cs.RO", "I.4.10"], "primary_category": "cs.CV"}
{"title": "Topological Invariant-Based Iris Identification via Digital Homology and Machine Learning", "abstract": "Objective - This study presents a biometric identification method based on\ntopological invariants from 2D iris images, representing iris texture via\nformally defined digital homology and evaluating classification performance.\n  Methods - Each normalized iris image (48x482 pixels) is divided into grids\n(e.g., 6x54 or 3x27). For each subregion, we compute Betti0, Betti1, and their\nratio using a recent algorithm for homology groups in 2D digital images. The\nresulting invariants form a feature matrix used with logistic regression, KNN,\nand SVM (with PCA and 100 randomized repetitions). A convolutional neural\nnetwork (CNN) is trained on raw images for comparison.\n  Results - Logistic regression achieved 97.78 +/- 0.82% accuracy,\noutperforming CNN (96.44 +/- 1.32%) and other feature-based models. The\ntopological features showed high accuracy with low variance.\n  Conclusion - This is the first use of topological invariants from formal\ndigital homology for iris recognition. The method offers a compact,\ninterpretable, and accurate alternative to deep learning, useful when\nexplainability or limited data is important. Beyond iris recognition, it can\napply to other biometrics, medical imaging, materials science, remote sensing,\nand interpretable AI. It runs efficiently on CPU-only systems and produces\nrobust, explainable features valuable for security-critical domains.", "published": "2025-08-13 07:21:48", "link": "http://arxiv.org/abs/2508.09555v1", "categories": ["cs.CV", "55N31, 55U10, 68U10, 68T07", "I.4.6; I.5.4; G.2.3"], "primary_category": "cs.CV"}
{"title": "Exploring the Equivalence of Closed-Set Generative and Real Data Augmentation in Image Classification", "abstract": "In this paper, we address a key scientific problem in machine learning: Given\na training set for an image classification task, can we train a generative\nmodel on this dataset to enhance the classification performance? (i.e.,\nclosed-set generative data augmentation). We start by exploring the\ndistinctions and similarities between real images and closed-set synthetic\nimages generated by advanced generative models. Through extensive experiments,\nwe offer systematic insights into the effective use of closed-set synthetic\ndata for augmentation. Notably, we empirically determine the equivalent scale\nof synthetic images needed for augmentation. In addition, we also show\nquantitative equivalence between the real data augmentation and open-set\ngenerative augmentation (generative models trained using data beyond the given\ntraining set). While it aligns with the common intuition that real images are\ngenerally preferred, our empirical formulation also offers a guideline to\nquantify the increased scale of synthetic data augmentation required to achieve\ncomparable image classification performance. Our results on natural and medical\nimage datasets further illustrate how this effect varies with the baseline\ntraining set size and the amount of synthetic data incorporated.", "published": "2025-08-13 07:14:29", "link": "http://arxiv.org/abs/2508.09550v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Iterative Volume Fusion for Asymmetric Stereo Matching", "abstract": "Stereo matching is vital in 3D computer vision, with most algorithms assuming\nsymmetric visual properties between binocular visions. However, the rise of\nasymmetric multi-camera systems (e.g., tele-wide cameras) challenges this\nassumption and complicates stereo matching. Visual asymmetry disrupts stereo\nmatching by affecting the crucial cost volume computation. To address this, we\nexplore the matching cost distribution of two established cost volume\nconstruction methods in asymmetric stereo. We find that each cost volume\nexperiences distinct information distortion, indicating that both should be\ncomprehensively utilized to solve the issue. Based on this, we propose the\ntwo-phase Iterative Volume Fusion network for Asymmetric Stereo matching\n(IVF-AStereo). Initially, the aggregated concatenation volume refines the\ncorrelation volume. Subsequently, both volumes are fused to enhance fine\ndetails. Our method excels in asymmetric scenarios and shows robust performance\nagainst significant visual asymmetry. Extensive comparative experiments on\nbenchmark datasets, along with ablation studies, confirm the effectiveness of\nour approach in asymmetric stereo with resolution and color degradation.", "published": "2025-08-13 06:55:40", "link": "http://arxiv.org/abs/2508.09543v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Physics-guided Deep Unfolding Network for Enhanced Kronecker Compressive sensing", "abstract": "Deep networks have achieved remarkable success in image compressed sensing\n(CS) task, namely reconstructing a high-fidelity image from its compressed\nmeasurement. However, existing works are deficient inincoherent compressed\nmeasurement at sensing phase and implicit measurement representations at\nreconstruction phase, limiting the overall performance. In this work, we answer\ntwo questions: 1) how to improve the measurement incoherence for decreasing the\nill-posedness; 2) how to learn informative representations from measurements.\nTo this end, we propose a novel asymmetric Kronecker CS (AKCS) model and\ntheoretically present its better incoherence than previous Kronecker CS with\nminimal complexity increase. Moreover, we reveal that the unfolding networks'\nsuperiority over non-unfolding ones result from sufficient gradient descents,\ncalled explicit measurement representations. We propose a measurement-aware\ncross attention (MACA) mechanism to learn implicit measurement representations.\nWe integrate AKCS and MACA into widely-used unfolding architecture to get a\nmeasurement-enhanced unfolding network (MEUNet). Extensive experiences\ndemonstrate that our MEUNet achieves state-of-the-art performance in\nreconstruction accuracy and inference speed.", "published": "2025-08-13 06:21:58", "link": "http://arxiv.org/abs/2508.09528v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning Spatial Decay for Vision Transformers", "abstract": "Vision Transformers (ViTs) have revolutionized computer vision, yet their\nself-attention mechanism lacks explicit spatial inductive biases, leading to\nsuboptimal performance on spatially-structured tasks. Existing approaches\nintroduce data-independent spatial decay based on fixed distance metrics,\napplying uniform attention weighting regardless of image content and limiting\nadaptability to diverse visual scenarios. Inspired by recent advances in large\nlanguage models where content-aware gating mechanisms (e.g., GLA, HGRN2, FOX)\nsignificantly outperform static alternatives, we present the first successful\nadaptation of data-dependent spatial decay to 2D vision transformers. We\nintroduce \\textbf{Spatial Decay Transformer (SDT)}, featuring a novel\nContext-Aware Gating (CAG) mechanism that generates dynamic, data-dependent\ndecay for patch interactions. Our approach learns to modulate spatial attention\nbased on both content relevance and spatial proximity. We address the\nfundamental challenge of 1D-to-2D adaptation through a unified spatial-content\nfusion framework that integrates manhattan distance-based spatial priors with\nlearned content representations. Extensive experiments on ImageNet-1K\nclassification and generation tasks demonstrate consistent improvements over\nstrong baselines. Our work establishes data-dependent spatial decay as a new\nparadigm for enhancing spatial attention in vision transformers.", "published": "2025-08-13 06:18:32", "link": "http://arxiv.org/abs/2508.09525v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SOI is the Root of All Evil: Quantifying and Breaking Similar Object Interference in Single Object Tracking", "abstract": "In this paper, we present the first systematic investigation and\nquantification of Similar Object Interference (SOI), a long-overlooked yet\ncritical bottleneck in Single Object Tracking (SOT). Through controlled Online\nInterference Masking (OIM) experiments, we quantitatively demonstrate that\neliminating interference sources leads to substantial performance improvements\n(AUC gains up to 4.35) across all SOTA trackers, directly validating SOI as a\nprimary constraint for robust tracking and highlighting the feasibility of\nexternal cognitive guidance. Building upon these insights, we adopt natural\nlanguage as a practical form of external guidance, and construct SOIBench-the\nfirst semantic cognitive guidance benchmark specifically targeting SOI\nchallenges. It automatically mines SOI frames through multi-tracker collective\njudgment and introduces a multi-level annotation protocol to generate precise\nsemantic guidance texts. Systematic evaluation on SOIBench reveals a striking\nfinding: existing vision-language tracking (VLT) methods fail to effectively\nexploit semantic cognitive guidance, achieving only marginal improvements or\neven performance degradation (AUC changes of -0.26 to +0.71). In contrast, we\npropose a novel paradigm employing large-scale vision-language models (VLM) as\nexternal cognitive engines that can be seamlessly integrated into arbitrary RGB\ntrackers. This approach demonstrates substantial improvements under semantic\ncognitive guidance (AUC gains up to 0.93), representing a significant\nadvancement over existing VLT methods. We hope SOIBench will serve as a\nstandardized evaluation platform to advance semantic cognitive tracking\nresearch and contribute new insights to the tracking research community.", "published": "2025-08-13 06:12:43", "link": "http://arxiv.org/abs/2508.09524v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CWFBind: Geometry-Awareness for Fast and Accurate Protein-Ligand Docking", "abstract": "Accurately predicting the binding conformation of small-molecule ligands to\nprotein targets is a critical step in rational drug design. Although recent\ndeep learning-based docking surpasses traditional methods in speed and\naccuracy, many approaches rely on graph representations and language\nmodel-inspired encoders while neglecting critical geometric information,\nresulting in inaccurate pocket localization and unrealistic binding\nconformations. In this study, we introduce CWFBind, a weighted, fast, and\naccurate docking method based on local curvature features. Specifically, we\nintegrate local curvature descriptors during the feature extraction phase to\nenrich the geometric representation of both proteins and ligands, complementing\nexisting chemical, sequence, and structural features. Furthermore, we embed\ndegree-aware weighting mechanisms into the message passing process, enhancing\nthe model's ability to capture spatial structural distinctions and interaction\nstrengths. To address the class imbalance challenge in pocket prediction,\nCWFBind employs a ligand-aware dynamic radius strategy alongside an enhanced\nloss function, facilitating more precise identification of binding regions and\nkey residues. Comprehensive experimental evaluations demonstrate that CWFBind\nachieves competitive performance across multiple docking benchmarks, offering a\nbalanced trade-off between accuracy and efficiency.", "published": "2025-08-13 05:15:10", "link": "http://arxiv.org/abs/2508.09499v1", "categories": ["cs.CV", "cs.CG", "cs.LG"], "primary_category": "cs.CV"}
{"title": "SARE: Semantic-Aware Reconstruction Error for Generalizable Diffusion-Generated Image Detection", "abstract": "Recently, diffusion-generated image detection has gained increasing\nattention, as the rapid advancement of diffusion models has raised serious\nconcerns about their potential misuse. While existing detection methods have\nachieved promising results, their performance often degrades significantly when\nfacing fake images from unseen, out-of-distribution (OOD) generative models,\nsince they primarily rely on model-specific artifacts. To address this\nlimitation, we explore a fundamental property commonly observed in fake images.\nMotivated by the observation that fake images tend to exhibit higher similarity\nto their captions than real images, we propose a novel representation, namely\nSemantic-Aware Reconstruction Error (SARE), that measures the semantic\ndifference between an image and its caption-guided reconstruction. The\nhypothesis behind SARE is that real images, whose captions often fail to fully\ncapture their complex visual content, may undergo noticeable semantic shifts\nduring the caption-guided reconstruction process. In contrast, fake images,\nwhich closely align with their captions, show minimal semantic changes. By\nquantifying these semantic shifts, SARE can be utilized as a discriminative\nfeature for robust detection across diverse generative models. We empirically\ndemonstrate that the proposed method exhibits strong generalization,\noutperforming existing baselines on benchmarks including GenImage and\nCommunityForensics.", "published": "2025-08-13 04:37:36", "link": "http://arxiv.org/abs/2508.09487v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SkySplat: Generalizable 3D Gaussian Splatting from Multi-Temporal Sparse Satellite Images", "abstract": "Three-dimensional scene reconstruction from sparse-view satellite images is a\nlong-standing and challenging task. While 3D Gaussian Splatting (3DGS) and its\nvariants have recently attracted attention for its high efficiency, existing\nmethods remain unsuitable for satellite images due to incompatibility with\nrational polynomial coefficient (RPC) models and limited generalization\ncapability. Recent advances in generalizable 3DGS approaches show potential,\nbut they perform poorly on multi-temporal sparse satellite images due to\nlimited geometric constraints, transient objects, and radiometric\ninconsistencies. To address these limitations, we propose SkySplat, a novel\nself-supervised framework that integrates the RPC model into the generalizable\n3DGS pipeline, enabling more effective use of sparse geometric cues for\nimproved reconstruction. SkySplat relies only on RGB images and\nradiometric-robust relative height supervision, thereby eliminating the need\nfor ground-truth height maps. Key components include a Cross-Self Consistency\nModule (CSCM), which mitigates transient object interference via\nconsistency-based masking, and a multi-view consistency aggregation strategy\nthat refines reconstruction results. Compared to per-scene optimization\nmethods, SkySplat achieves an 86 times speedup over EOGS with higher accuracy.\nIt also outperforms generalizable 3DGS baselines, reducing MAE from 13.18 m to\n1.80 m on the DFC19 dataset significantly, and demonstrates strong\ncross-dataset generalization on the MVS3D benchmark.", "published": "2025-08-13 04:17:51", "link": "http://arxiv.org/abs/2508.09479v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GazeLT: Visual attention-guided long-tailed disease classification in chest radiographs", "abstract": "In this work, we present GazeLT, a human visual attention\nintegration-disintegration approach for long-tailed disease classification. A\nradiologist's eye gaze has distinct patterns that capture both fine-grained and\ncoarser level disease related information. While interpreting an image, a\nradiologist's attention varies throughout the duration; it is critical to\nincorporate this into a deep learning framework to improve automated image\ninterpretation. Another important aspect of visual attention is that apart from\nlooking at major/obvious disease patterns, experts also look at\nminor/incidental findings (few of these constituting long-tailed classes)\nduring the course of image interpretation. GazeLT harnesses the temporal aspect\nof the visual search process, via an integration and disintegration mechanism,\nto improve long-tailed disease classification. We show the efficacy of GazeLT\non two publicly available datasets for long-tailed disease classification,\nnamely the NIH-CXR-LT (n=89237) and the MIMIC-CXR-LT (n=111898) datasets.\nGazeLT outperforms the best long-tailed loss by 4.1% and the visual\nattention-based baseline by 21.7% in average accuracy metrics for these\ndatasets. Our code is available at https://github.com/lordmoinak1/gazelt.", "published": "2025-08-13 04:13:27", "link": "http://arxiv.org/abs/2508.09478v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CLIP-Flow: A Universal Discriminator for AI-Generated Images Inspired by Anomaly Detection", "abstract": "With the rapid advancement of AI generative models, the visual quality of\nAI-generated images (AIIs) has become increasingly close to natural images,\nwhich inevitably raises security concerns. Most AII detectors often employ the\nconventional image classification pipeline with natural images and AIIs\n(generated by a generative model), which can result in limited detection\nperformance for AIIs from unseen generative models. To solve this, we proposed\na universal AI-generated image detector from the perspective of anomaly\ndetection. Our discriminator does not need to access any AIIs and learn a\ngeneralizable representation with unsupervised learning. Specifically, we use\nthe pre-trained CLIP encoder as the feature extractor and design a normalizing\nflow-like unsupervised model. Instead of AIIs, proxy images, e.g., obtained by\napplying a spectral modification operation on natural images, are used for\ntraining. Our models are trained by minimizing the likelihood of proxy images,\noptionally combined with maximizing the likelihood of natural images. Extensive\nexperiments demonstrate the effectiveness of our method on AIIs produced by\nvarious image generators.", "published": "2025-08-13 04:12:37", "link": "http://arxiv.org/abs/2508.09477v1", "categories": ["cs.CV", "cs.CR"], "primary_category": "cs.CV"}
{"title": "From Large Angles to Consistent Faces: Identity-Preserving Video Generation via Mixture of Facial Experts", "abstract": "Current video generation models struggle with identity preservation under\nlarge facial angles, primarily facing two challenges: the difficulty in\nexploring an effective mechanism to integrate identity features into DiT\nstructure, and the lack of targeted coverage of large facial angles in existing\nopen-source video datasets. To address these, we present two key innovations.\nFirst, we introduce a Mixture of Facial Experts (MoFE) that dynamically\ncombines complementary cues from three specialized experts, each designed to\ncapture distinct but mutually reinforcing aspects of facial attributes. The\nidentity expert captures cross-pose identity-sensitive features, the semantic\nexpert extracts high-level visual semantxics, and the detail expert preserves\npixel-level features (e.g., skin texture, color gradients). Furthermore, to\nmitigate dataset limitations, we have tailored a data processing pipeline\ncentered on two key aspects: Face Constraints and Identity Consistency. Face\nConstraints ensure facial angle diversity and a high proportion of facial\nregions, while Identity Consistency preserves coherent person-specific features\nacross temporal sequences, collectively addressing the scarcity of large facial\nangles and identity-stable training data in existing datasets. Leveraging this\npipeline, we have curated and refined a Large Face Angles (LFA) Dataset from\nexisting open-source human video datasets, comprising 460K video clips with\nannotated facial angles. Experimental results on the LFA benchmark demonstrate\nthat our method, empowered by the LFA dataset, significantly outperforms prior\nSOTA methods in face similarity, face FID, and CLIP semantic alignment. The\ncode and dataset will be made publicly available at\nhttps://github.com/rain152/LFA-Video-Generation.", "published": "2025-08-13 04:10:16", "link": "http://arxiv.org/abs/2508.09476v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Leveraging Failed Samples: A Few-Shot and Training-Free Framework for Generalized Deepfake Detection", "abstract": "Recent deepfake detection studies often treat unseen sample detection as a\n``zero-shot\" task, training on images generated by known models but\ngeneralizing to unknown ones. A key real-world challenge arises when a model\nperforms poorly on unknown samples, yet these samples remain available for\nanalysis. This highlights that it should be approached as a ``few-shot\" task,\nwhere effectively utilizing a small number of samples can lead to significant\nimprovement. Unlike typical few-shot tasks focused on semantic understanding,\ndeepfake detection prioritizes image realism, which closely mirrors real-world\ndistributions. In this work, we propose the Few-shot Training-free Network\n(FTNet) for real-world few-shot deepfake detection. Simple yet effective, FTNet\ndiffers from traditional methods that rely on large-scale known data for\ntraining. Instead, FTNet uses only one fake samplefrom an evaluation set,\nmimicking the scenario where new samples emerge in the real world and can be\ngathered for use, without any training or parameter updates. During evaluation,\neach test sample is compared to the known fake and real samples, and it is\nclassified based on the category of the nearest sample. We conduct a\ncomprehensive analysis of AI-generated images from 29 different generative\nmodels and achieve a new SoTA performance, with an average improvement of 8.7\\%\ncompared to existing methods. This work introduces a fresh perspective on\nreal-world deepfake detection: when the model struggles to generalize on a\nfew-shot sample, leveraging the failed samples leads to better performance.", "published": "2025-08-13 04:06:09", "link": "http://arxiv.org/abs/2508.09475v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CitySeg: A 3D Open Vocabulary Semantic Segmentation Foundation Model in City-scale Scenarios", "abstract": "Semantic segmentation of city-scale point clouds is a critical technology for\nUnmanned Aerial Vehicle (UAV) perception systems, enabling the classification\nof 3D points without relying on any visual information to achieve comprehensive\n3D understanding. However, existing models are frequently constrained by the\nlimited scale of 3D data and the domain gap between datasets, which lead to\nreduced generalization capability. To address these challenges, we propose\nCitySeg, a foundation model for city-scale point cloud semantic segmentation\nthat incorporates text modality to achieve open vocabulary segmentation and\nzero-shot inference. Specifically, in order to mitigate the issue of\nnon-uniform data distribution across multiple domains, we customize the data\npreprocessing rules, and propose a local-global cross-attention network to\nenhance the perception capabilities of point networks in UAV scenarios. To\nresolve semantic label discrepancies across datasets, we introduce a\nhierarchical classification strategy. A hierarchical graph established\naccording to the data annotation rules consolidates the data labels, and the\ngraph encoder is used to model the hierarchical relationships between\ncategories. In addition, we propose a two-stage training strategy and employ\nhinge loss to increase the feature separability of subcategories. Experimental\nresults demonstrate that the proposed CitySeg achieves state-of-the-art (SOTA)\nperformance on nine closed-set benchmarks, significantly outperforming existing\napproaches. Moreover, for the first time, CitySeg enables zero-shot\ngeneralization in city-scale point cloud scenarios without relying on visual\ninformation.", "published": "2025-08-13 03:55:56", "link": "http://arxiv.org/abs/2508.09470v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Event-driven Robust Fitting on Neuromorphic Hardware", "abstract": "Robust fitting of geometric models is a fundamental task in many computer\nvision pipelines. Numerous innovations have been produced on the topic, from\nimproving the efficiency and accuracy of random sampling heuristics to\ngenerating novel theoretical insights that underpin new approaches with\nmathematical guarantees. However, one aspect of robust fitting that has\nreceived little attention is energy efficiency. This performance metric has\nbecome critical as high energy consumption is a growing concern for AI\nadoption. In this paper, we explore energy-efficient robust fitting via the\nneuromorphic computing paradigm. Specifically, we designed a novel spiking\nneural network for robust fitting on real neuromorphic hardware, the Intel\nLoihi 2. Enabling this are novel event-driven formulations of model estimation\nthat allow robust fitting to be implemented in the unique architecture of Loihi\n2, and algorithmic strategies to alleviate the current limited precision and\ninstruction set of the hardware. Results show that our neuromorphic robust\nfitting consumes only a fraction (15%) of the energy required to run the\nestablished robust fitting algorithm on a standard CPU to equivalent accuracy.", "published": "2025-08-13 03:41:23", "link": "http://arxiv.org/abs/2508.09466v1", "categories": ["cs.CV", "cs.NE"], "primary_category": "cs.CV"}
{"title": "Animate-X++: Universal Character Image Animation with Dynamic Backgrounds", "abstract": "Character image animation, which generates high-quality videos from a\nreference image and target pose sequence, has seen significant progress in\nrecent years. However, most existing methods only apply to human figures, which\nusually do not generalize well on anthropomorphic characters commonly used in\nindustries like gaming and entertainment. Furthermore, previous methods could\nonly generate videos with static backgrounds, which limits the realism of the\nvideos. For the first challenge, our in-depth analysis suggests to attribute\nthis limitation to their insufficient modeling of motion, which is unable to\ncomprehend the movement pattern of the driving video, thus imposing a pose\nsequence rigidly onto the target character. To this end, this paper proposes\nAnimate-X++, a universal animation framework based on DiT for various character\ntypes, including anthropomorphic characters. To enhance motion representation,\nwe introduce the Pose Indicator, which captures comprehensive motion pattern\nfrom the driving video through both implicit and explicit manner. The former\nleverages CLIP visual features of a driving video to extract its gist of\nmotion, like the overall movement pattern and temporal relations among motions,\nwhile the latter strengthens the generalization of DiT by simulating possible\ninputs in advance that may arise during inference. For the second challenge, we\nintroduce a multi-task training strategy that jointly trains the animation and\nTI2V tasks. Combined with the proposed partial parameter training, this\napproach achieves not only character animation but also text-driven background\ndynamics, making the videos more realistic. Moreover, we introduce a new\nAnimated Anthropomorphic Benchmark (A2Bench) to evaluate the performance of\nAnimate-X++ on universal and widely applicable animation images. Extensive\nexperiments demonstrate the superiority and effectiveness of Animate-X++.", "published": "2025-08-13 03:11:28", "link": "http://arxiv.org/abs/2508.09454v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HyperKD: Distilling Cross-Spectral Knowledge in Masked Autoencoders via Inverse Domain Shift with Spatial-Aware Masking and Specialized Loss", "abstract": "The proliferation of foundation models, pretrained on large-scale unlabeled\ndatasets, has emerged as an effective approach in creating adaptable and\nreusable architectures that can be leveraged for various downstream tasks using\nsatellite observations. However, their direct application to hyperspectral\nremote sensing remains challenging due to inherent spectral disparities and the\nscarcity of available observations. In this work, we present HyperKD, a novel\nknowledge distillation framework that enables transferring learned\nrepresentations from a teacher model into a student model for effective\ndevelopment of a foundation model on hyperspectral images. Unlike typical\nknowledge distillation frameworks, which use a complex teacher to guide a\nsimpler student, HyperKD enables an inverse form of knowledge transfer across\ndifferent types of spectral data, guided by a simpler teacher model. Building\nupon a Masked Autoencoder, HyperKD distills knowledge from the Prithvi\nfoundational model into a student tailored for EnMAP hyperspectral imagery.\nHyperKD addresses the inverse domain adaptation problem with spectral gaps by\nintroducing a feature-based strategy that includes spectral range-based channel\nalignment, spatial feature-guided masking, and an enhanced loss function\ntailored for hyperspectral images. HyperKD bridges the substantial spectral\ndomain gap, enabling the effective use of pretrained foundation models for\ngeospatial applications. Extensive experiments show that HyperKD significantly\nimproves representation learning in MAEs, leading to enhanced reconstruction\nfidelity and more robust performance on downstream tasks such as land cover\nclassification, crop type identification, and soil organic carbon prediction,\nunderpinning the potential of knowledge distillation frameworks in remote\nsensing analytics with hyperspectral imagery.", "published": "2025-08-13 03:10:40", "link": "http://arxiv.org/abs/2508.09453v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "RASR: Retrieval-Augmented Super Resolution for Practical Reference-based Image Restoration", "abstract": "Reference-based Super Resolution (RefSR) improves upon Single Image Super\nResolution (SISR) by leveraging high-quality reference images to enhance\ntexture fidelity and visual realism. However, a critical limitation of existing\nRefSR approaches is their reliance on manually curated target-reference image\npairs, which severely constrains their practicality in real-world scenarios. To\novercome this, we introduce Retrieval-Augmented Super Resolution (RASR), a new\nand practical RefSR paradigm that automatically retrieves semantically relevant\nhigh-resolution images from a reference database given only a low-quality\ninput. This enables scalable and flexible RefSR in realistic use cases, such as\nenhancing mobile photos taken in environments like zoos or museums, where\ncategory-specific reference data (e.g., animals, artworks) can be readily\ncollected or pre-curated. To facilitate research in this direction, we\nconstruct RASR-Flickr30, the first benchmark dataset designed for RASR. Unlike\nprior datasets with fixed target-reference pairs, RASR-Flickr30 provides\nper-category reference databases to support open-world retrieval. We further\npropose RASRNet, a strong baseline that combines a semantic reference retriever\nwith a diffusion-based RefSR generator. It retrieves relevant references based\non semantic similarity and employs a diffusion-based generator enhanced with\nsemantic conditioning. Experiments on RASR-Flickr30 demonstrate that RASRNet\nconsistently improves over SISR baselines, achieving +0.38 dB PSNR and -0.0131\nLPIPS, while generating more realistic textures. These findings highlight\nretrieval augmentation as a promising direction to bridge the gap between\nacademic RefSR research and real-world applicability.", "published": "2025-08-13 03:05:20", "link": "http://arxiv.org/abs/2508.09449v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning complexity of many-body quantum sign structures through the lens of Boolean Fourier analysis", "abstract": "We study sign structures of the ground states of spin-$1/2$ magnetic systems\nusing the methods of Boolean Fourier analysis. Previously it was shown that the\nsign structures of frustrated systems are of complex nature: specifically,\nneural networks of popular architectures lack the generalization ability\nnecessary to effectively reconstruct sign structures in supervised learning\nsettings. This is believed to be an obstacle for applications of neural quantum\nstates to frustrated systems. In the present work, we develop an alternative\nlanguage for the analysis of sign structures based on representing them as\npolynomial functions defined on the Boolean hypercube - an approach called\nBoolean Fourier analysis. We discuss the relations between the properties of\nthe Boolean Fourier series and the learning complexity of sign structures, and\ndemonstrate that such polynomials can potentially serve as variational\nans\\\"atze for the complex sign structures that dramatically outperform neural\nnetworks in terms of generalization ability. While ans\\\"atze of this type\ncannot yet be directly used in the context of variational optimization, they\nindicate that the complexity of sign structures is not an insurmountable curse,\nand can potentially be learned with better designed NQS architectures. Finally,\nwe show how augmenting data with Boolean functions can aid sign prediction by\nneural networks.", "published": "2025-08-13 15:06:13", "link": "http://arxiv.org/abs/2508.09870v1", "categories": ["cond-mat.dis-nn", "cond-mat.str-el", "cs.DM", "quant-ph"], "primary_category": "cond-mat.dis-nn"}
{"title": "On the Consistency and Performance of the Iterative Bayesian Update", "abstract": "For many social, scientific, and commercial purposes, it is often important\nto estimate the distribution of the users' data regarding a sensitive\nattribute, e.g., their ages, locations, etc. To allow this estimation while\nprotecting the users' privacy, every user applies a local privacy protection\nmechanism that releases a noisy (sanitized) version of their original datum to\nthe data collector; then the original distribution is estimated using one of\nthe known methods, such as the matrix inversion (INV), RAPPOR's estimator, and\nthe iterative Bayesian update (IBU). Unlike the other estimators, the\nconsistency of IBU, i.e., the convergence of its estimate to the real\ndistribution as the amount of noisy data grows, has been either ignored or\nincorrectly proved in the literature. In this article, we use the fact that IBU\nis a maximum likelihood estimator to prove that IBU is consistent. We also\nshow, through experiments on real datasets, that IBU significantly outperforms\nthe other methods when the users' data are sanitized by geometric, Laplace, and\nexponential mechanisms, whereas it is comparable to the other methods in the\ncase of the k-RR and RAPPOR mechanisms. Finally, we consider the case when the\nalphabet of the sensitive data is infinite, and we show a technique that allows\nIBU to operate in this case too.", "published": "2025-08-13 17:52:07", "link": "http://arxiv.org/abs/2508.09980v1", "categories": ["cs.CR", "cs.IR"], "primary_category": "cs.CR"}
{"title": "Multimodal Fusion And Sparse Attention-based Alignment Model for Long Sequential Recommendation", "abstract": "Recent advances in multimodal recommendation enable richer item\nunderstanding, while modeling users' multi-scale interests across temporal\nhorizons has attracted growing attention. However, effectively exploiting\nmultimodal item sequences and mining multi-grained user interests to\nsubstantially bridge the gap between content comprehension and recommendation\nremain challenging. To address these issues, we propose MUFASA, a MUltimodal\nFusion And Sparse Attention-based Alignment model for long sequential\nrecommendation. Our model comprises two core components. First, the Multimodal\nFusion Layer (MFL) leverages item titles as a cross-genre semantic anchor and\nis trained with a joint objective of four tailored losses that promote: (i)\ncross-genre semantic alignment, (ii) alignment to the collaborative space for\nrecommendation, (iii) preserving the similarity structure defined by titles and\npreventing modality representation collapse, and (iv) distributional\nregularization of the fusion space. This yields high-quality fused item\nrepresentations for further preference alignment. Second, the Sparse\nAttention-guided Alignment Layer (SAL) scales to long user-behavior sequences\nvia a multi-granularity sparse attention mechanism, which incorporates windowed\nattention, block-level attention, and selective attention, to capture user\ninterests hierarchically and across temporal horizons. SAL explicitly models\nboth the evolution of coherent interest blocks and fine-grained intra-block\nvariations, producing robust user and item representations. Extensive\nexperiments on real-world benchmarks show that MUFASA consistently surpasses\nstate-of-the-art baselines. Moreover, online A/B tests demonstrate significant\ngains in production, confirming MUFASA's effectiveness in leveraging multimodal\ncues and accurately capturing diverse user preferences.", "published": "2025-08-13 09:50:44", "link": "http://arxiv.org/abs/2508.09664v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Personalized Product Search Ranking: A Multi-Task Learning Approach with Tabular and Non-Tabular Data", "abstract": "In this paper, we present a novel model architecture for optimizing\npersonalized product search ranking using a multi-task learning (MTL)\nframework. Our approach uniquely integrates tabular and non-tabular data,\nleveraging a pre-trained TinyBERT model for semantic embeddings and a novel\nsampling technique to capture diverse customer behaviors. We evaluate our model\nagainst several baselines, including XGBoost, TabNet, FT-Transformer, DCN-V2,\nand MMoE, focusing on their ability to handle mixed data types and optimize\npersonalized ranking. Additionally, we propose a scalable relevance labeling\nmechanism based on click-through rates, click positions, and semantic\nsimilarity, offering an alternative to traditional human-annotated labels.\nExperimental results show that combining non-tabular data with advanced\nembedding techniques in multi-task learning paradigm significantly enhances\nmodel performance. Ablation studies further underscore the benefits of\nincorporating relevance labels, fine-tuning TinyBERT layers, and TinyBERT\nquery-product embedding interactions. These results demonstrate the\neffectiveness of our approach in achieving improved personalized product search\nranking.", "published": "2025-08-13 09:15:08", "link": "http://arxiv.org/abs/2508.09636v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "TFRank: Think-Free Reasoning Enables Practical Pointwise LLM Ranking", "abstract": "Reasoning-intensive ranking models built on Large Language Models (LLMs) have\nmade notable progress, but existing approaches often rely on large-scale LLMs\nand explicit Chain-of-Thought (CoT) reasoning, resulting in high computational\ncost and latency that limit real-world use. To address this, we propose\n\\textbf{TFRank}, an efficient pointwise reasoning ranker based on small-scale\nLLMs. To improve ranking performance, TFRank effectively integrates CoT data,\nfine-grained score supervision, and multi-task training. Furthermore, it\nachieves an efficient ``\\textbf{T}hink-\\textbf{F}ree\" reasoning capability by\nemploying a ``think-mode switch'' and pointwise format constraints.\nSpecifically, this allows the model to leverage explicit reasoning during\ntraining while delivering precise relevance scores for complex queries at\ninference without generating any reasoning chains. Experiments show that TFRank\n(e.g., 1.7B) achieves performance comparable to models with four times more\nparameters on the BRIGHT benchmark, and demonstrates strong competitiveness on\nthe BEIR benchmark. Further analysis shows that TFRank achieves an effective\nbalance between performance and efficiency, providing a practical solution for\nintegrating advanced reasoning into real-world systems. Our code and data are\nreleased in the repository: https://github.com/JOHNNY-fans/TFRank.", "published": "2025-08-13 06:47:58", "link": "http://arxiv.org/abs/2508.09539v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Improving Dense Passage Retrieval with Multiple Positive Passages", "abstract": "By leveraging a dual encoder architecture, Dense Passage Retrieval (DPR) has\noutperformed traditional sparse retrieval algorithms such as BM25 in terms of\npassage retrieval accuracy. Recently proposed methods have further enhanced\nDPR's performance. However, these models typically pair each question with only\none positive passage during training, and the effect of associating multiple\npositive passages has not been examined. In this paper, we explore the\nperformance of DPR when additional positive passages are incorporated during\ntraining. Experimental results show that equipping each question with multiple\npositive passages consistently improves retrieval accuracy, even when using a\nsignificantly smaller batch size, which enables training on a single GPU.", "published": "2025-08-13 06:36:53", "link": "http://arxiv.org/abs/2508.09534v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Towards Self-cognitive Exploration: Metacognitive Knowledge Graph Retrieval Augmented Generation", "abstract": "Knowledge Graph-based Retrieval-Augmented Generation (KG-RAG) significantly\nenhances the reasoning capabilities of LargeLanguage Models by leveraging\nstructured knowledge. However, existing KG-RAG frameworks typically operate as\nopen-loop systems, suffering from cognitive blindness, an inability to\nrecognize their exploration deficiencies. This leads to relevance drift and\nincomplete evidence, which existing self-refinement methods, designed for\nunstructured text-based RAG, cannot effectively resolve due to the\npath-dependent nature of graph exploration. To address this challenge, we\npropose Metacognitive Knowledge Graph Retrieval Augmented Generation\n(MetaKGRAG), a novel framework inspired by the human metacognition process,\nwhich introduces a Perceive-Evaluate-Adjust cycle to enable path-aware,\nclosed-loop refinement. This cycle empowers the system to self-assess\nexploration quality, identify deficiencies in coverage or relevance, and\nperform trajectory-connected corrections from precise pivot points. Extensive\nexperiments across five datasets in the medical, legal, and commonsense\nreasoning domains demonstrate that MetaKGRAG consistently outperforms strong\nKG-RAG and self-refinement baselines. Our results validate the superiority of\nour approach and highlight the critical need for path-aware refinement in\nstructured knowledge retrieval.", "published": "2025-08-13 03:35:32", "link": "http://arxiv.org/abs/2508.09460v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Improving quantum communication rates with permutation-invariant codes", "abstract": "In this work we improve the quantum communication rates of various quantum\nchannels of interest using permutation-invariant quantum codes. We focus in\nparticular on parametrized families of quantum channels and aim to improve\nbounds on their quantum capacity threshold, defined as the lowest noise level\nat which the quantum capacity of the channel family vanishes. These thresholds\nare important quantities as they mark the noise level up to which faithful\nquantum communication is theoretically possible. Our method exploits the fact\nthat independent and identically distributed quantum channels preserve any\npermutation symmetry present at the input. The resulting symmetric output\nstates can be described succinctly using the representation theory of the\nsymmetric and general linear groups, which we use to derive an efficient\nalgorithm for computing the channel coherent information of a\npermutation-invariant code. Our approach allows us to evaluate coherent\ninformation values for a large number of channel copies, e.g., at least 100\nchannel copies for qubit channels. We apply this method to various physically\nrelevant channel models, including general Pauli channels, the dephrasure\nchannel, the generalized amplitude damping channel, and the damping-dephasing\nchannel. For each channel family we obtain improved lower bounds on their\nquantum capacities. For example, for the 2-Pauli and BB84 channel families we\nsignificantly improve the best known quantum capacity thresholds derived in\n[Fern, Whaley 2008]. These threshold improvements are achieved using a\nrepetition code-like input state with non-orthogonal code states, which we\nfurther analyze in our representation-theoretic framework.", "published": "2025-08-13 17:47:51", "link": "http://arxiv.org/abs/2508.09978v1", "categories": ["quant-ph", "cs.IT", "math-ph", "math.IT", "math.MP"], "primary_category": "quant-ph"}
{"title": "Unified Design of Space-Air-Ground-Sea Integrated Maritime Communications", "abstract": "With the explosive growth of maritime activities, it is expected to provide\nseamless communications with quality of service (QoS) guarantee over broad sea\narea. In the context, this paper proposes a space-air-ground-sea integrated\nmaritime communication architecture combining satellite, unmanned aerial\nvehicle (UAV), terrestrial base station (TBS) and unmanned surface vessel\n(USV). Firstly, according to the distance away from the shore, the whole marine\nspace is divided to coastal area, offshore area, middle-sea area and open-sea\narea, the maritime users in which are served by TBS, USV, UAV and satellite,\nrespectively. Then, by exploiting the potential of integrated maritime\ncommunication system, a joint beamforming and trajectory optimization algorithm\nis designed to maximize the minimum transmission rate of maritime users.\nFinally, theoretical analysis and simulation results validate the effectiveness\nof the proposed algorithm.", "published": "2025-08-13 13:53:23", "link": "http://arxiv.org/abs/2508.09817v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Directed Cycles as Higher-Order Units of Information Processing in Complex Networks", "abstract": "Directed cycles form the fundamental motifs in natural, social and artificial\nnetworks, yet their distinct computational roles remain under-explored,\nparticularly in the context of higher-order structure and function. In this\nwork, we investigate how two types of directed cycles - feedforward and\nfeedback - can act as higher-order structures to facilitate the flow and\nintegration of information in sparse random networks, and how these roles\ndepend on the environment of the cycles. Using information-theoretic measures,\nwe show that network size, sparsity and relative directionality critically\nimpact the information-processing capacities of directed cycles. In a network\nwith no-preferred global direction, a feedforward cycle enables greater\ninformation flow and a feedback cycle allows for increased information\nintegration. The relative direction of a feedforward cycle as well as the\nstructural incoherence it induces, determines its capacity to generate\nhigher-order behaviour. Finally, we demonstrate that introducing feedback loops\ninto otherwise feedforward architectures increases the diversity of network\nactivity patterns. These findings suggest that directed cycles serve as\ncomputational motifs with local information processing capabilities that depend\non the structure they are embedded. Using directed cycles, we highlight the\ninterdependence between higher-order structures and the higher-order order\nbehaviour they can induce in the network dynamics.", "published": "2025-08-13 13:42:28", "link": "http://arxiv.org/abs/2508.09808v1", "categories": ["cond-mat.stat-mech", "cs.IT", "math.DS", "math.IT"], "primary_category": "cond-mat.stat-mech"}
{"title": "Non-Orthogonal Affine Frequency Division Multiplexing for Spectrally Efficient High-Mobility Communications", "abstract": "This paper proposes a novel non-orthogonal affine frequency division\nmultiplexing {(nAFDM)} waveform for reliable high-mobility communications with\nenhanced spectral efficiency {(SE)}. The key idea is {to introduce} a bandwidth\ncompression factor into the AFDM {modulator} to enable controllable subcarrier\noverlapping. We first {detail the proposed nAFDM transceiver} and derive the\ncorresponding input-output {signal} relationship. Then, an efficient {nAFDM}\nsignal generation method based on the inverse discrete Fourier transform (IDFT)\nis proposed, enabling practical implementation using existing inverse fast\nFourier transform (IFFT) modules without additional hardware complexity. Next,\nto characterize the impact of non-orthogonal modulation, we derive a\nclosed-form expression {of} inter-carrier interference (ICI), showing its\ndependence on the bandwidth compression factor. To mitigate the resulting\ninterference, we propose a soft iterative detection algorithm and a\nlow-complexity implementation approach that leverages the distribution\ncharacteristics of ICI. {Simulation results demonstrate that 1) in terms of bit\nerror rate (BER), the proposed nAFDM can achieve near identical BER compared to\nconventional AFDM, while outperforms other waveform counterparts; 2) nAFDM is\ncapable of striking higher SE compared to other existing waveforms; and 3) the\nproposed nAFDM achieves an attractive BER vs. SE trade-off, and the proposed\nsoft ID scheme can attain a trade-off between BER and complexity.}", "published": "2025-08-13 13:02:41", "link": "http://arxiv.org/abs/2508.09782v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "ORCAS Codes: A Flexible Generalization of Polar Codes with Low-Complexity Decoding", "abstract": "Motivated by the need for channel codes with low-complexity soft-decision\ndecoding algorithms, we consider the recursive Plotkin concatenation of optimal\nlow-rate and high-rate codes based on simplex codes and their duals. These\ncomponent codes come with low-complexity maximum likelihood (ML) decoding\nwhich, in turn, enables efficient successive cancellation (SC)-based decoding.\nAs a result, the proposed optimally recursively concatenated simplex (ORCAS)\ncodes achieve a performance that is at least as good as that of polar codes.\nFor practical parameters, the proposed construction significantly outperforms\npolar codes in terms of block error rate by up to 0.5 dB while maintaining\nsimilar decoding complexity. Furthermore, the codes offer greater flexibility\nin codeword length than conventional polar codes.", "published": "2025-08-13 12:19:09", "link": "http://arxiv.org/abs/2508.09744v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Fluid Reconfigurable Intelligent Surface with Element-Level Pattern Reconfigurability: Beamforming and Pattern Co-Design", "abstract": "This paper proposes a novel pattern-reconfigurable fluid reconfigurable\nintelligent surface (FRIS) framework, where each fluid element can dynamically\nadjust its radiation pattern based on instantaneous channel conditions. To\nevaluate its potential, we first conduct a comparative analysis of the received\nsignal power in point-to-point communication systems assisted by three types of\nsurfaces: (1) the proposed pattern-reconfigurable FRIS, (2) a\nposition-reconfigurable FRIS, and (3) a conventional RIS. Theoretical results\ndemonstrate that the pattern-reconfigurable FRIS provides a significant\nadvantage in modulating transmission signals compared to the other two\nconfigurations. To further study its capabilities, we extend the framework to a\nmultiuser communication scenario. In this context, the spherical harmonics\northogonal decomposition (SHOD) method is employed to accurately model the\nradiation patterns of individual fluid elements, making the pattern design\nprocess more tractable. An optimization problem is then formulated with the\nobjective of maximizing the weighted sum rate among users by jointly designing\nthe active beamforming vectors and the spherical harmonics coefficients,\nsubject to both transmit power and pattern energy constraints. To tackle the\nresulting non-convex optimization problem, we propose an iterative algorithm\nthat alternates between a minimum mean-square error (MMSE) approach for active\nbeamforming and a Riemannian conjugate gradient (RCG) method for updating the\nspherical harmonics coefficients. Simulation results show that the proposed\npattern-reconfigurable FRIS significantly outperforms traditional RIS\narchitectures based on the 3GPP 38.901 and isotropic radiation models,\nachieving average performance gains of 161.5% and 176.2%, respectively.", "published": "2025-08-13 10:47:19", "link": "http://arxiv.org/abs/2508.09695v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Hermitian Self-dual Twisted Generalized Reed-Solomon Codes", "abstract": "Self-dual maximum distance separable (MDS) codes over finite fields are\nlinear codes with significant combinatorial and cryptographic applications.\nTwisted generalized Reed-Solomon (TGRS) codes can be both MDS and self-dual. In\nthis paper, we study a general class of TGRS codes (A-TGRS), which encompasses\nall previously known special cases. First, we establish a sufficient and\nnecessary condition for an A-TGRS code to be Hermitian self-dual. Furthermore,\nwe present four constructions of self-dual TGRS codes, which, to the best of\nour knowledge, nearly cover all the related results previously reported in the\nliterature. More importantly, we also obtain several new classes of Hermitian\nself-dual TGRS codes with flexible parameters. Based on this framework, we\nderive a sufficient and necessary condition for an A-TGRS code to be Hermitian\nself-dual and MDS. In addition, we construct a class of MDS Hermitian self-dual\nTGRS code by appropriately selecting the evaluation points. This work\ninvestigates the Hermitian self-duality of TGRS codes from the perspective of\nmatrix representation, leading to more concise and transparent analysis. More\ngenerally, the Euclidean self-dual TGRS codes and the Hermitian self-dual GRS\ncodes can also be understood easily from this point.", "published": "2025-08-13 10:27:41", "link": "http://arxiv.org/abs/2508.09687v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Global Convergence Analysis of Vanilla Gradient Descent for Asymmetric Matrix Completion", "abstract": "This paper investigates the asymmetric low-rank matrix completion problem,\nwhich can be formulated as an unconstrained non-convex optimization problem\nwith a nonlinear least-squares objective function, and is solved via gradient\ndescent methods. Previous gradient descent approaches typically incorporate\nregularization terms into the objective function to guarantee convergence.\nHowever, numerical experiments and theoretical analysis of the gradient flow\nboth demonstrate that the elimination of regularization terms in gradient\ndescent algorithms does not adversely affect convergence performance. By\nintroducing the leave-one-out technique, we inductively prove that the vanilla\ngradient descent with spectral initialization achieves a linear convergence\nrate with high probability. Besides, we demonstrate that the balancing\nregularization term exhibits a small norm during iterations, which reveals the\nimplicit regularization property of gradient descent. Empirical results show\nthat our algorithm has a lower computational cost while maintaining comparable\ncompletion performance compared to other gradient descent algorithms.", "published": "2025-08-13 10:23:32", "link": "http://arxiv.org/abs/2508.09685v1", "categories": ["cs.LG", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "Dynamic Mixture-of-Experts for Incremental Graph Learning", "abstract": "Graph incremental learning is a learning paradigm that aims to adapt trained\nmodels to continuously incremented graphs and data over time without the need\nfor retraining on the full dataset. However, regular graph machine learning\nmethods suffer from catastrophic forgetting when applied to incremental\nlearning settings, where previously learned knowledge is overridden by new\nknowledge. Previous approaches have tried to address this by treating the\npreviously trained model as an inseparable unit and using techniques to\nmaintain old behaviors while learning new knowledge. These approaches, however,\ndo not account for the fact that previously acquired knowledge at different\ntimestamps contributes differently to learning new tasks. Some prior patterns\ncan be transferred to help learn new data, while others may deviate from the\nnew data distribution and be detrimental. To address this, we propose a dynamic\nmixture-of-experts (DyMoE) approach for incremental learning. Specifically, a\nDyMoE GNN layer adds new expert networks specialized in modeling the incoming\ndata blocks. We design a customized regularization loss that utilizes data\nsequence information so existing experts can maintain their ability to solve\nold tasks while helping the new expert learn the new data effectively. As the\nnumber of data blocks grows over time, the computational cost of the full\nmixture-of-experts (MoE) model increases. To address this, we introduce a\nsparse MoE approach, where only the top-$k$ most relevant experts make\npredictions, significantly reducing the computation time. Our model achieved\n4.92\\% relative accuracy increase compared to the best baselines on class\nincremental learning, showing the model's exceptional power.", "published": "2025-08-13 17:41:19", "link": "http://arxiv.org/abs/2508.09974v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Prototype-Guided Diffusion: Visual Conditioning without External Memory", "abstract": "Diffusion models have emerged as a leading framework for high-quality image\ngeneration, offering stable training and strong performance across diverse\ndomains. However, they remain computationally intensive, particularly during\nthe iterative denoising process. Latent-space models like Stable Diffusion\nalleviate some of this cost by operating in compressed representations, though\nat the expense of fine-grained detail. More recent approaches such as\nRetrieval-Augmented Diffusion Models (RDM) address efficiency by conditioning\ndenoising on similar examples retrieved from large external memory banks. While\neffective, these methods introduce drawbacks: they require costly storage and\nretrieval infrastructure, depend on static vision-language models like CLIP for\nsimilarity, and lack adaptability during training. We propose the Prototype\nDiffusion Model (PDM), a method that integrates prototype learning directly\ninto the diffusion process for efficient and adaptive visual conditioning -\nwithout external memory. Instead of retrieving reference samples, PDM\nconstructs a dynamic set of compact visual prototypes from clean image features\nusing contrastive learning. These prototypes guide the denoising steps by\naligning noisy representations with semantically relevant visual patterns,\nenabling efficient generation with strong semantic grounding. Experiments show\nthat PDM maintains high generation quality while reducing computational and\nstorage overhead, offering a scalable alternative to retrieval-based\nconditioning in diffusion models.", "published": "2025-08-13 16:18:35", "link": "http://arxiv.org/abs/2508.09922v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Modern Neural Networks for Small Tabular Datasets: The New Default for Field-Scale Digital Soil Mapping?", "abstract": "In the field of pedometrics, tabular machine learning is the predominant\nmethod for predicting soil properties from remote and proximal soil sensing\ndata, forming a central component of digital soil mapping. At the field-scale,\nthis predictive soil modeling (PSM) task is typically constrained by small\ntraining sample sizes and high feature-to-sample ratios in soil spectroscopy.\nTraditionally, these conditions have proven challenging for conventional deep\nlearning methods. Classical machine learning algorithms, particularly\ntree-based models like Random Forest and linear models such as Partial Least\nSquares Regression, have long been the default choice for field-scale PSM.\nRecent advances in artificial neural networks (ANN) for tabular data challenge\nthis view, yet their suitability for field-scale PSM has not been proven. We\nintroduce a comprehensive benchmark that evaluates state-of-the-art ANN\narchitectures, including the latest multilayer perceptron (MLP)-based models\n(TabM, RealMLP), attention-based transformer variants (FT-Transformer,\nExcelFormer, T2G-Former, AMFormer), retrieval-augmented approaches (TabR,\nModernNCA), and an in-context learning foundation model (TabPFN). Our\nevaluation encompasses 31 field- and farm-scale datasets containing 30 to 460\nsamples and three critical soil properties: soil organic matter or soil organic\ncarbon, pH, and clay content. Our results reveal that modern ANNs consistently\noutperform classical methods on the majority of tasks, demonstrating that deep\nlearning has matured sufficiently to overcome the long-standing dominance of\nclassical machine learning for PSM. Notably, TabPFN delivers the strongest\noverall performance, showing robustness across varying conditions. We therefore\nrecommend the adoption of modern ANNs for field-scale PSM and propose TabPFN as\nthe new default choice in the toolkit of every pedometrician.", "published": "2025-08-13 15:46:12", "link": "http://arxiv.org/abs/2508.09888v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "FedShard: Federated Unlearning with Efficiency Fairness and Performance Fairness", "abstract": "To protect clients' right to be forgotten in federated learning, federated\nunlearning aims to remove the data contribution of leaving clients from the\nglobal learned model. While current studies mainly focused on enhancing\nunlearning efficiency and effectiveness, the crucial aspects of efficiency\nfairness and performance fairness among decentralized clients during unlearning\nhave remained largely unexplored. In this study, we introduce FedShard, the\nfirst federated unlearning algorithm designed to concurrently guarantee both\nefficiency fairness and performance fairness. FedShard adaptively addresses the\nchallenges introduced by dilemmas among convergence, unlearning efficiency, and\nunlearning fairness. Furthermore, we propose two novel metrics to\nquantitatively assess the fairness of unlearning algorithms, which we prove to\nsatisfy well-known properties in other existing fairness measurements. Our\ntheoretical analysis and numerical evaluation validate FedShard's fairness in\nterms of both unlearning performance and efficiency. We demonstrate that\nFedShard mitigates unfairness risks such as cascaded leaving and poisoning\nattacks and realizes more balanced unlearning costs among clients. Experimental\nresults indicate that FedShard accelerates the data unlearning process 1.3-6.2\ntimes faster than retraining from scratch and 4.9 times faster than the\nstate-of-the-art exact unlearning methods.", "published": "2025-08-13 15:02:07", "link": "http://arxiv.org/abs/2508.09866v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "On the Generalization Limits of Quantum Generative Adversarial Networks with Pure State Generators", "abstract": "We investigate the capabilities of Quantum Generative Adversarial Networks\n(QGANs) in image generations tasks. Our analysis centers on fully quantum\nimplementations of both the generator and discriminator. Through extensive\nnumerical testing of current main architectures, we find that QGANs struggle to\ngeneralize across datasets, converging on merely the average representation of\nthe training data. When the output of the generator is a pure-state, we\nanalytically derive a lower bound for the discriminator quality given by the\nfidelity between the pure-state output of the generator and the target data\ndistribution, thereby providing a theoretical explanation for the limitations\nobserved in current models. Our findings reveal fundamental challenges in the\ngeneralization capabilities of existing quantum generative models. While our\nanalysis focuses on QGANs, the results carry broader implications for the\nperformance of related quantum generative models.", "published": "2025-08-13 14:25:45", "link": "http://arxiv.org/abs/2508.09844v1", "categories": ["quant-ph", "cs.LG"], "primary_category": "quant-ph"}
{"title": "RankList -- A Listwise Preference Learning Framework for Predicting Subjective Preferences", "abstract": "Preference learning has gained significant attention in tasks involving\nsubjective human judgments, such as \\emph{speech emotion recognition} (SER) and\nimage aesthetic assessment. While pairwise frameworks such as RankNet offer\nrobust modeling of relative preferences, they are inherently limited to local\ncomparisons and struggle to capture global ranking consistency. To address\nthese limitations, we propose RankList, a novel listwise preference learning\nframework that generalizes RankNet to structured list-level supervision. Our\nformulation explicitly models local and non-local ranking constraints within a\nprobabilistic framework. The paper introduces a log-sum-exp approximation to\nimprove training efficiency. We further extend RankList with skip-wise\ncomparisons, enabling progressive exposure to complex list structures and\nenhancing global ranking fidelity. Extensive experiments demonstrate the\nsuperiority of our method across diverse modalities. On benchmark SER datasets\n(MSP-Podcast, IEMOCAP, BIIC Podcast), RankList achieves consistent improvements\nin Kendall's Tau and ranking accuracy compared to standard listwise baselines.\nWe also validate our approach on aesthetic image ranking using the Artistic\nImage Aesthetics dataset, highlighting its broad applicability. Through\nablation and cross-domain studies, we show that RankList not only improves\nin-domain ranking but also generalizes better across datasets. Our framework\noffers a unified, extensible approach for modeling ordered preferences in\nsubjective learning scenarios.", "published": "2025-08-13 13:59:41", "link": "http://arxiv.org/abs/2508.09826v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Feature Impact Analysis on Top Long-Jump Performances with Quantile Random Forest and Explainable AI Techniques", "abstract": "Biomechanical features have become important indicators for evaluating\nathletes' techniques. Traditionally, experts propose significant features and\nevaluate them using physics equations. However, the complexity of the human\nbody and its movements makes it challenging to explicitly analyze the\nrelationships between some features and athletes' final performance. With\nadvancements in modern machine learning and statistics, data analytics methods\nhave gained increasing importance in sports analytics. In this study, we\nleverage machine learning models to analyze expert-proposed biomechanical\nfeatures from the finals of long jump competitions in the World Championships.\nThe objectives of the analysis include identifying the most important features\ncontributing to top-performing jumps and exploring the combined effects of\nthese key features. Using quantile regression, we model the relationship\nbetween the biomechanical feature set and the target variable (effective\ndistance), with a particular focus on elite-level jumps. To interpret the\nmodel, we apply SHapley Additive exPlanations (SHAP) alongside Partial\nDependence Plots (PDPs) and Individual Conditional Expectation (ICE) plots. The\nfindings reveal that, beyond the well-documented velocity-related features,\nspecific technical aspects also play a pivotal role. For male athletes, the\nangle of the knee of the supporting leg before take-off is identified as a key\nfactor for achieving top 10% performance in our dataset, with angles greater\nthan 169{\\deg}contributing significantly to jump performance. In contrast, for\nfemale athletes, the landing pose and approach step technique emerge as the\nmost critical features influencing top 10% performances, alongside velocity.\nThis study establishes a framework for analyzing the impact of various features\non athletic performance, with a particular emphasis on top-performing events.", "published": "2025-08-13 13:42:36", "link": "http://arxiv.org/abs/2508.09810v1", "categories": ["cs.LG", "stat.AP"], "primary_category": "cs.LG"}
{"title": "Improving the Speaker Anonymization Evaluation's Robustness to Target Speakers with Adversarial Learning", "abstract": "The current privacy evaluation for speaker anonymization often overestimates\nprivacy when a same-gender target selection algorithm (TSA) is used, although\nthis TSA leaks the speaker's gender and should hence be more vulnerable. We\nhypothesize that this occurs because the evaluation does not account for the\nfact that anonymized speech contains information from both the source and\ntarget speakers. To address this, we propose to add a target classifier that\nmeasures the influence of target speaker information in the evaluation, which\ncan also be removed with adversarial learning. Experiments demonstrate that\nthis approach is effective for multiple anonymizers, particularly when using a\nsame-gender TSA, leading to a more reliable assessment.", "published": "2025-08-13 13:38:09", "link": "http://arxiv.org/abs/2508.09803v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Bayesian autoregression to optimize temporal Mat\u00e9rn kernel Gaussian process hyperparameters", "abstract": "Gaussian processes are important models in the field of probabilistic\nnumerics. We present a procedure for optimizing Mat\\'ern kernel temporal\nGaussian processes with respect to the kernel covariance function's\nhyperparameters. It is based on casting the optimization problem as a recursive\nBayesian estimation procedure for the parameters of an autoregressive model. We\ndemonstrate that the proposed procedure outperforms maximizing the marginal\nlikelihood as well as Hamiltonian Monte Carlo sampling, both in terms of\nruntime and ultimate root mean square error in Gaussian process regression.", "published": "2025-08-13 13:23:58", "link": "http://arxiv.org/abs/2508.09792v1", "categories": ["cs.LG", "eess.SP", "stat.ML"], "primary_category": "cs.LG"}
{"title": "TriForecaster: A Mixture of Experts Framework for Multi-Region Electric Load Forecasting with Tri-dimensional Specialization", "abstract": "Electric load forecasting is pivotal for power system operation, planning and\ndecision-making. The rise of smart grids and meters has provided more detailed\nand high-quality load data at multiple levels of granularity, from home to bus\nand cities. Motivated by similar patterns of loads across different cities in a\nprovince in eastern China, in this paper we focus on the Multi-Region Electric\nLoad Forecasting (MRELF) problem, targeting accurate short-term load\nforecasting for multiple sub-regions within a large region. We identify three\nchallenges for MRELF, including regional variation, contextual variation, and\ntemporal variation. To address them, we propose TriForecaster, a new framework\nleveraging the Mixture of Experts (MoE) approach within a Multi-Task Learning\n(MTL) paradigm to overcome these challenges. TriForecaster features RegionMixer\nand Context-Time Specializer (CTSpecializer) layers, enabling dynamic\ncooperation and specialization of expert models across regional, contextual,\nand temporal dimensions. Based on evaluation on four real-world MRELF datasets\nwith varied granularity, TriForecaster outperforms state-of-the-art models by\nachieving an average forecast error reduction of 22.4\\%, thereby demonstrating\nits flexibility and broad applicability. In particular, the deployment of\nTriForecaster on the eForecaster platform in eastern China exemplifies its\npractical utility, effectively providing city-level, short-term load forecasts\nfor 17 cities, supporting a population exceeding 110 million and daily\nelectricity usage over 100 gigawatt-hours.", "published": "2025-08-13 12:34:15", "link": "http://arxiv.org/abs/2508.09753v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "$\u03bc$-Parametrization for Mixture of Experts", "abstract": "Recent years have seen a growing interest and adoption of LLMs, with\n$\\mu$Transfer becoming a key technique for tuning hyperparameters in\nlarge-scale training. Meanwhile, Mixture-of-Experts (MoE) has emerged as a\nleading architecture in extremely large models. However, the intersection of\nthese two advancements has remained unexplored. In this work, we derive a\n$\\mu$-Parameterization ($\\mu$P) for MoE, providing theoretical guarantees for\nfeature learning across model widths in both the router and experts. We\nempirically validate our parameterization and further investigate how scaling\nthe number of experts and granularity affects the optimal learning rate.", "published": "2025-08-13 12:31:27", "link": "http://arxiv.org/abs/2508.09752v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Machine Learning Approach to Predict Biological Age and its Longitudinal Drivers", "abstract": "Predicting an individual's aging trajectory is a central challenge in\npreventative medicine and bioinformatics. While machine learning models can\npredict chronological age from biomarkers, they often fail to capture the\ndynamic, longitudinal nature of the aging process. In this work, we developed\nand validated a machine learning pipeline to predict age using a longitudinal\ncohort with data from two distinct time periods (2019-2020 and 2021-2022). We\ndemonstrate that a model using only static, cross-sectional biomarkers has\nlimited predictive power when generalizing to future time points. However, by\nengineering novel features that explicitly capture the rate of change (slope)\nof key biomarkers over time, we significantly improved model performance. Our\nfinal LightGBM model, trained on the initial wave of data, successfully\npredicted age in the subsequent wave with high accuracy ($R^2 = 0.515$ for\nmales, $R^2 = 0.498$ for females), significantly outperforming both traditional\nlinear models and other tree-based ensembles. SHAP analysis of our successful\nmodel revealed that the engineered slope features were among the most important\npredictors, highlighting that an individual's health trajectory, not just their\nstatic health snapshot, is a key determinant of biological age. Our framework\npaves the way for clinical tools that dynamically track patient health\ntrajectories, enabling early intervention and personalized prevention\nstrategies for age-related diseases.", "published": "2025-08-13 12:22:12", "link": "http://arxiv.org/abs/2508.09747v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "HKT: A Biologically Inspired Framework for Modular Hereditary Knowledge Transfer in Neural Networks", "abstract": "A prevailing trend in neural network research suggests that model performance\nimproves with increasing depth and capacity - often at the cost of\nintegrability and efficiency. In this paper, we propose a strategy to optimize\nsmall, deployable models by enhancing their capabilities through structured\nknowledge inheritance. We introduce Hereditary Knowledge Transfer (HKT), a\nbiologically inspired framework for modular and selective transfer of\ntask-relevant features from a larger, pretrained parent network to a smaller\nchild model. Unlike standard knowledge distillation, which enforces uniform\nimitation of teacher outputs, HKT draws inspiration from biological inheritance\nmechanisms - such as memory RNA transfer in planarians - to guide a multi-stage\nprocess of feature transfer. Neural network blocks are treated as functional\ncarriers, and knowledge is transmitted through three biologically motivated\ncomponents: Extraction, Transfer, and Mixture (ETM). A novel Genetic Attention\n(GA) mechanism governs the integration of inherited and native representations,\nensuring both alignment and selectivity. We evaluate HKT across diverse vision\ntasks, including optical flow (Sintel, KITTI), image classification (CIFAR-10),\nand semantic segmentation (LiTS), demonstrating that it significantly improves\nchild model performance while preserving its compactness. The results show that\nHKT consistently outperforms conventional distillation approaches, offering a\ngeneral-purpose, interpretable, and scalable solution for deploying\nhigh-performance neural networks in resource-constrained environments.", "published": "2025-08-13 12:13:28", "link": "http://arxiv.org/abs/2508.09743v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Generative Modeling with Multi-Instance Reward Learning for E-commerce Creative Optimization", "abstract": "In e-commerce advertising, selecting the most compelling combination of\ncreative elements -- such as titles, images, and highlights -- is critical for\ncapturing user attention and driving conversions. However, existing methods\noften evaluate creative components individually, failing to navigate the\nexponentially large search space of possible combinations. To address this\nchallenge, we propose a novel framework named GenCO that integrates generative\nmodeling with multi-instance reward learning. Our unified two-stage\narchitecture first employs a generative model to efficiently produce a diverse\nset of creative combinations. This generative process is optimized with\nreinforcement learning, enabling the model to effectively explore and refine\nits selections. Next, to overcome the challenge of sparse user feedback, a\nmulti-instance learning model attributes combination-level rewards, such as\nclicks, to the individual creative elements. This allows the reward model to\nprovide a more accurate feedback signal, which in turn guides the generative\nmodel toward creating more effective combinations. Deployed on a leading\ne-commerce platform, our approach has significantly increased advertising\nrevenue, demonstrating its practical value. Additionally, we are releasing a\nlarge-scale industrial dataset to facilitate further research in this important\ndomain.", "published": "2025-08-13 11:53:41", "link": "http://arxiv.org/abs/2508.09730v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Structured Kernel Regression VAE: A Computationally Efficient Surrogate for GP-VAEs in ICA", "abstract": "The interpretability of generative models is considered a key factor in\ndemonstrating their effectiveness and controllability. The generated data are\nbelieved to be determined by latent variables that are not directly observable.\nTherefore, disentangling, decoupling, decomposing, causal inference, or\nperforming Independent Component Analysis (ICA) in the latent variable space\nhelps uncover the independent factors that influence the attributes or features\naffecting the generated outputs, thereby enhancing the interpretability of\ngenerative models. As a generative model, Variational Autoencoders (VAEs)\ncombine with variational Bayesian inference algorithms. Using VAEs, the inverse\nprocess of ICA can be equivalently framed as a variational inference process.\nIn some studies, Gaussian processes (GPs) have been introduced as priors for\neach dimension of latent variables in VAEs, structuring and separating each\ndimension from temporal or spatial perspectives, and encouraging different\ndimensions to control various attributes of the generated data. However, GPs\nimpose a significant computational burden, resulting in substantial resource\nconsumption when handling large datasets. Essentially, GPs model different\ntemporal or spatial structures through various kernel functions. Structuring\nthe priors of latent variables via kernel functions-so that different kernel\nfunctions model the correlations among sequence points within different latent\ndimensions-is at the core of achieving disentanglement in VAEs. The proposed\nStructured Kernel Regression VAE (SKR-VAE) leverages this core idea in a more\nefficient way, avoiding the costly kernel matrix inversion required in GPs.\nThis research demonstrates that, while maintaining ICA performance, SKR-VAE\nachieves greater computational efficiency and significantly reduced\ncomputational burden compared to GP-VAE.", "published": "2025-08-13 11:24:24", "link": "http://arxiv.org/abs/2508.09721v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "GraphTreeGen: Subtree-Centric Approach to Efficient and Supervised Graph Generation", "abstract": "Brain connectomes, representing neural connectivity as graphs, are crucial\nfor understanding brain organization but costly and time-consuming to acquire,\nmotivating generative approaches. Recent advances in graph generative modeling\noffer a data-driven alternative, enabling synthetic connectome generation and\nreducing dependence on large neuroimaging datasets. However, current models\nface key limitations: (i) compressing the whole graph into a single latent code\n(e.g., VGAEs) blurs fine-grained local motifs; (ii) relying on rich node\nattributes rarely available in connectomes reduces reconstruction quality;\n(iii) edge-centric models emphasize topology but overlook accurate edge-weight\nprediction, harming quantitative fidelity; and (iv) computationally expensive\ndesigns (e.g., edge-conditioned convolutions) impose high memory demands,\nlimiting scalability. We propose GraphTreeGen (GTG), a subtree-centric\ngenerative framework for efficient, accurate connectome synthesis. GTG\ndecomposes each connectome into entropy-guided k-hop trees capturing\ninformative local structure, encoded by a shared GCN. A bipartite\nmessage-passing layer fuses subtree embeddings with global node features, while\na dual-branch decoder jointly predicts edge existence and weights to\nreconstruct the adjacency matrix. GTG outperforms state-of-the-art baselines in\nself-supervised tasks and remains competitive in supervised settings,\ndelivering higher structural fidelity and more precise weights with far less\nmemory. Its modular design enables extensions to connectome super-resolution\nand cross-modality synthesis. Code: https://github.com/basiralab/GTG/", "published": "2025-08-13 11:02:38", "link": "http://arxiv.org/abs/2508.09710v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Temporal Anchoring in Deepening Embedding Spaces: Event-Indexed Projections, Drift, Convergence, and an Internal Computational Architecture", "abstract": "We develop an operator-theoretic framework for temporal anchoring in\nembedding spaces, modeled as drift maps interleaved with event-indexed blocks\nculminating in affine projections. We provide complete proofs for a\nvariable-block contraction lemma (products of Lipschitz factors), a\ndrift--projection convergence theorem with explicit uniform-gap envelopes, and\nontological convergence under nested affine anchors with a robustness variant.\nWe formalize an internal Manuscript Computer (MC) whose computations are\ndefined purely by these operators and prove a rigorous finite-run equivalence\ntheorem (with perturbation bounds). For attention layers, we give a\nself-contained proof that softmax is $1/2$-Lipschitz in $\\ell_2$ and derive\nsufficient layer-contraction conditions (orthogonal/non-orthogonal heads). All\nfloats are placed exactly where written; the manuscript uses only in-paper\npseudocode and appendix figures.", "published": "2025-08-13 10:45:47", "link": "http://arxiv.org/abs/2508.09693v1", "categories": ["cs.LG", "math.FA", "math.OC", "stat.ML", "47H09, 47H10, 90C25, 65K10, 68T07", "F.1.1; G.1.6; I.2.6; G.1.2"], "primary_category": "cs.LG"}
{"title": "DeputyDev -- AI Powered Developer Assistant: Breaking the Code Review Logjam through Contextual AI to Boost Developer Productivity", "abstract": "This study investigates the implementation and efficacy of DeputyDev, an\nAI-powered code review assistant developed to address inefficiencies in the\nsoftware development process. The process of code review is highly inefficient\nfor several reasons, such as it being a time-consuming process, inconsistent\nfeedback, and review quality not being at par most of the time. Using our\ntelemetry data, we observed that at TATA 1mg, pull request (PR) processing\nexhibits significant inefficiencies, with average pick-up and review times of\n73 and 82 hours, respectively, resulting in a 6.2 day closure cycle. The review\ncycle was marked by prolonged iterative communication between the reviewing and\nsubmitting parties. Research from the University of California, Irvine\nindicates that interruptions can lead to an average of 23 minutes of lost\nfocus, critically affecting code quality and timely delivery. To address these\nchallenges, we developed DeputyDev's PR review capabilities by providing\nautomated, contextual code reviews. We conducted a rigorous double-controlled\nA/B experiment involving over 200 engineers to evaluate DeputyDev's impact on\nreview times. The results demonstrated a statistically significant reduction in\nboth average per PR (23.09%) and average per-line-of-code (40.13%) review\ndurations. After implementing safeguards to exclude outliers, DeputyDev has\nbeen effectively rolled out across the entire organisation. Additionally, it\nhas been made available to external companies as a Software-as-a-Service (SaaS)\nsolution, currently supporting the daily work of numerous engineering\nprofessionals. This study explores the implementation and effectiveness of\nAI-assisted code reviews in improving development workflow timelines and code.", "published": "2025-08-13 10:09:45", "link": "http://arxiv.org/abs/2508.09676v1", "categories": ["cs.SE", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Social-Sensor Identity Cloning Detection Using Weakly Supervised Deep Forest and Cryptographic Authentication", "abstract": "Recent years have witnessed a rising trend in social-sensor cloud identity\ncloning incidents. However, existing approaches suffer from unsatisfactory\nperformance, a lack of solutions for detecting duplicated accounts, and a lack\nof large-scale evaluations on real-world datasets. We introduce a novel method\nfor detecting identity cloning in social-sensor cloud service providers. Our\nproposed technique consists of two primary components: 1) a similar identity\ndetection method and 2) a cryptography-based authentication protocol.\nInitially, we developed a weakly supervised deep forest model to identify\nsimilar identities using non-privacy-sensitive user profile features provided\nby the service. Subsequently, we designed a cryptography-based authentication\nprotocol to verify whether similar identities were generated by the same\nprovider. Our extensive experiments on a large real-world dataset demonstrate\nthe feasibility and superior performance of our technique compared to current\nstate-of-the-art identity clone detection methods.", "published": "2025-08-13 09:53:23", "link": "http://arxiv.org/abs/2508.09665v1", "categories": ["cs.CR", "cs.LG", "cs.SI", "H.3; E.3; I.2; I.7"], "primary_category": "cs.CR"}
{"title": "Thermal Tracks: A Gaussian process-based framework for universal melting curve analysis enabling unconstrained hit identification in thermal proteome profiling experiments", "abstract": "Thermal Tracks is a Python-based statistical framework for analyzing protein\nthermal stability data that overcomes key limitations of existing thermal\nproteome profiling (TPP) work-flows. Unlike standard approaches that assume\nsigmoidal melting curves and are constrained by empirical null distributions\n(limiting significant hits to approximately 5 % of data), Thermal Tracks uses\nGaussian Process (GP) models with squared-exponential kernels to flexibly model\nany melting curve shape while generating unbiased null distributions through\nkernel priors. This framework is particularly valuable for analyzing\nproteome-wide perturbations that significantly alter protein thermal stability,\nsuch as pathway inhibitions, genetic modifications, or environmental stresses,\nwhere conventional TPP methods may miss biologically relevant changes due to\ntheir statistical constraints. Furthermore, Thermal Tracks excels at analyzing\nproteins with un-conventional melting profiles, including phase-separating\nproteins and membrane proteins, which often exhibit complex, non-sigmoidal\nthermal stability behaviors. Thermal Tracks is freely available from GitHub and\nis implemented in Python, providing an accessible and flexible tool for\nproteome-wide thermal profiling studies.", "published": "2025-08-13 09:42:35", "link": "http://arxiv.org/abs/2508.09659v1", "categories": ["cs.LG", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "Physics- and geometry-aware spatio-spectral graph neural operator for time-independent and time-dependent PDEs", "abstract": "Solving partial differential equations (PDEs) efficiently and accurately\nremains a cornerstone challenge in science and engineering, especially for\nproblems involving complex geometries and limited labeled data. We introduce a\nPhysics- and Geometry- Aware Spatio-Spectral Graph Neural Operator\n($\\pi$G-Sp$^2$GNO) for learning the solution operators of time-independent and\ntime-dependent PDEs. The proposed approach first improves upon the recently\ndeveloped Sp$^2$GNO by enabling geometry awareness and subsequently exploits\nthe governing physics to learn the underlying solution operator in a\nsimulation-free setup. While the spatio-spectral structure present in the\nproposed architecture allows multiscale learning, two separate strategies for\nenabling geometry awareness is introduced in this paper. For time dependent\nproblems, we also introduce a novel hybrid physics informed loss function that\ncombines higher-order time-marching scheme with upscaled theory inspired\nstochastic projection scheme. This allows accurate integration of the\nphysics-information into the loss function. The performance of the proposed\napproach is illustrated on number of benchmark examples involving regular and\ncomplex domains, variation in geometry during inference, and time-independent\nand time-dependent problems. The results obtained illustrate the efficacy of\nthe proposed approach as compared to the state-of-the-art physics-informed\nneural operator algorithms in the literature.", "published": "2025-08-13 08:59:04", "link": "http://arxiv.org/abs/2508.09627v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Scalable h-adaptive probabilistic solver for time-independent and time-dependent systems", "abstract": "Solving partial differential equations (PDEs) within the framework of\nprobabilistic numerics offers a principled approach to quantifying epistemic\nuncertainty arising from discretization. By leveraging Gaussian process\nregression and imposing the governing PDE as a constraint at a finite set of\ncollocation points, probabilistic numerics delivers mesh-free solutions at\narbitrary locations. However, the high computational cost, which scales\ncubically with the number of collocation points, remains a critical bottleneck,\nparticularly for large-scale or high-dimensional problems. We propose a\nscalable enhancement to this paradigm through two key innovations. First, we\ndevelop a stochastic dual descent algorithm that reduces the per-iteration\ncomplexity from cubic to linear in the number of collocation points, enabling\ntractable inference. Second, we exploit a clustering-based active learning\nstrategy that adaptively selects collocation points to maximize information\ngain while minimizing computational expense. Together, these contributions\nresult in an $h$-adaptive probabilistic solver that can scale to a large number\nof collocation points. We demonstrate the efficacy of the proposed solver on\nbenchmark PDEs, including two- and three-dimensional steady-state elliptic\nproblems, as well as a time-dependent parabolic PDE formulated in a space-time\nsetting.", "published": "2025-08-13 08:54:18", "link": "http://arxiv.org/abs/2508.09623v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Online Prediction with Limited Selectivity", "abstract": "Selective prediction [Dru13, QV19] models the scenario where a forecaster\nfreely decides on the prediction window that their forecast spans. Many data\nstatistics can be predicted to a non-trivial error rate without any\ndistributional assumptions or expert advice, yet these results rely on that the\nforecaster may predict at any time. We introduce a model of Prediction with\nLimited Selectivity (PLS) where the forecaster can start the prediction only on\na subset of the time horizon. We study the optimal prediction error both on an\ninstance-by-instance basis and via an average-case analysis. We introduce a\ncomplexity measure that gives instance-dependent bounds on the optimal error.\nFor a randomly-generated PLS instance, these bounds match with high\nprobability.", "published": "2025-08-13 08:17:12", "link": "http://arxiv.org/abs/2508.09592v1", "categories": ["cs.LG", "cs.DS"], "primary_category": "cs.LG"}
{"title": "HierMoE: Accelerating MoE Training with Hierarchical Token Deduplication and Expert Swap", "abstract": "The sparsely activated mixture-of-experts (MoE) transformer has become a\ncommon architecture for large language models (LLMs) due to its sparsity, which\nrequires fewer computational demands while easily scaling the model size. In\nMoE models, each MoE layer requires to dynamically choose tokens to activate\nparticular experts for computation while the activated experts may not be\nlocated in the same device or GPU as the token. However, this leads to\nsubstantial communication and load imbalances across all GPUs, which obstructs\nthe scalability of distributed systems within a GPU cluster. To this end, we\nintroduce HierMoE to accelerate the training of MoE models by two\ntopology-aware techniques: 1) token deduplication to reduce the communication\ntraffic, and 2) expert swap to balance the workloads among all GPUs. To enable\nthe above two proposed approaches to be more general, we build theoretical\nmodels aimed at achieving the best token duplication and expert swap strategy\nunder different model configurations and hardware environments. We implement\nour prototype HierMoE system atop Megatron-LM and conduct experiments on a\n32-GPU cluster with DeepSeek-V3 and Qwen3-30B-A3B models. Experimental results\nshow that our HierMoE achieves $1.55\\times$ to $3.32\\times$ faster\ncommunication and delivers $1.18\\times$ to $1.27\\times$ faster end-to-end\ntraining compared to state-of-the-art MoE training systems, Tutel-2DH,\nSmartMoE, and Megatron-LM.", "published": "2025-08-13 08:16:31", "link": "http://arxiv.org/abs/2508.09591v1", "categories": ["cs.DC", "cs.LG"], "primary_category": "cs.DC"}
{"title": "Edge General Intelligence Through World Models and Agentic AI: Fundamentals, Solutions, and Challenges", "abstract": "Edge General Intelligence (EGI) represents a transformative evolution of edge\ncomputing, where distributed agents possess the capability to perceive, reason,\nand act autonomously across diverse, dynamic environments. Central to this\nvision are world models, which act as proactive internal simulators that not\nonly predict but also actively imagine future trajectories, reason under\nuncertainty, and plan multi-step actions with foresight. This proactive nature\nallows agents to anticipate potential outcomes and optimize decisions ahead of\nreal-world interactions. While prior works in robotics and gaming have\nshowcased the potential of world models, their integration into the wireless\nedge for EGI remains underexplored. This survey bridges this gap by offering a\ncomprehensive analysis of how world models can empower agentic artificial\nintelligence (AI) systems at the edge. We first examine the architectural\nfoundations of world models, including latent representation learning, dynamics\nmodeling, and imagination-based planning. Building on these core capabilities,\nwe illustrate their proactive applications across EGI scenarios such as\nvehicular networks, unmanned aerial vehicle (UAV) networks, the Internet of\nThings (IoT) systems, and network functions virtualization, thereby\nhighlighting how they can enhance optimization under latency, energy, and\nprivacy constraints. We then explore their synergy with foundation models and\ndigital twins, positioning world models as the cognitive backbone of EGI.\nFinally, we highlight open challenges, such as safety guarantees, efficient\ntraining, and constrained deployment, and outline future research directions.\nThis survey provides both a conceptual foundation and a practical roadmap for\nrealizing the next generation of intelligent, autonomous edge systems.", "published": "2025-08-13 07:29:40", "link": "http://arxiv.org/abs/2508.09561v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "SYNAPSE-G: Bridging Large Language Models and Graph Learning for Rare Event Classification", "abstract": "Scarcity of labeled data, especially for rare events, hinders training\neffective machine learning models. This paper proposes SYNAPSE-G (Synthetic\nAugmentation for Positive Sampling via Expansion on Graphs), a novel pipeline\nleveraging Large Language Models (LLMs) to generate synthetic training data for\nrare event classification, addressing the cold-start problem. This synthetic\ndata serve as seeds for semi-supervised label propagation on a similarity graph\nconstructed between the seeds and a large unlabeled dataset. This identifies\ncandidate positive examples, subsequently labeled by an oracle (human or LLM).\nThe expanded dataset then trains/fine-tunes a classifier. We theoretically\nanalyze how the quality (validity and diversity) of the synthetic data impacts\nthe precision and recall of our method. Experiments on the imbalanced SST2 and\nMHS datasets demonstrate SYNAPSE-G's effectiveness in finding positive labels,\noutperforming baselines including nearest neighbor search.", "published": "2025-08-13 06:58:44", "link": "http://arxiv.org/abs/2508.09544v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Emergence of Hierarchies in Multi-Agent Self-Organizing Systems Pursuing a Joint Objective", "abstract": "Multi-agent self-organizing systems (MASOS) exhibit key characteristics\nincluding scalability, adaptability, flexibility, and robustness, which have\ncontributed to their extensive application across various fields. However, the\nself-organizing nature of MASOS also introduces elements of unpredictability in\ntheir emergent behaviors. This paper focuses on the emergence of dependency\nhierarchies during task execution, aiming to understand how such hierarchies\narise from agents' collective pursuit of the joint objective, how they evolve\ndynamically, and what factors govern their development. To investigate this\nphenomenon, multi-agent reinforcement learning (MARL) is employed to train\nMASOS for a collaborative box-pushing task. By calculating the gradients of\neach agent's actions in relation to the states of other agents, the inter-agent\ndependencies are quantified, and the emergence of hierarchies is analyzed\nthrough the aggregation of these dependencies. Our results demonstrate that\nhierarchies emerge dynamically as agents work towards a joint objective, with\nthese hierarchies evolving in response to changing task requirements. Notably,\nthese dependency hierarchies emerge organically in response to the shared\nobjective, rather than being a consequence of pre-configured rules or\nparameters that can be fine-tuned to achieve specific results. Furthermore, the\nemergence of hierarchies is influenced by the task environment and network\ninitialization conditions. Additionally, hierarchies in MASOS emerge from the\ndynamic interplay between agents' \"Talent\" and \"Effort\" within the\n\"Environment.\" \"Talent\" determines an agent's initial influence on collective\ndecision-making, while continuous \"Effort\" within the \"Environment\" enables\nagents to shift their roles and positions within the system.", "published": "2025-08-13 06:50:03", "link": "http://arxiv.org/abs/2508.09541v1", "categories": ["cs.MA", "cs.LG"], "primary_category": "cs.MA"}
{"title": "DeepWKB: Learning WKB Expansions of Invariant Distributions for Stochastic Systems", "abstract": "This paper introduces a novel deep learning method, called DeepWKB, for\nestimating the invariant distribution of randomly perturbed systems via its\nWentzel-Kramers-Brillouin (WKB) approximation $u_\\epsilon(x) = Q(\\epsilon)^{-1}\nZ_\\epsilon(x) \\exp\\{-V(x)/\\epsilon\\}$, where $V$ is known as the\nquasi-potential, $\\epsilon$ denotes the noise strength, and $Q(\\epsilon)$ is\nthe normalization factor. By utilizing both Monte Carlo data and the partial\ndifferential equations satisfied by $V$ and $Z_\\epsilon$, the DeepWKB method\ncomputes $V$ and $Z_\\epsilon$ separately. This enables an approximation of the\ninvariant distribution in the singular regime where $\\epsilon$ is sufficiently\nsmall, which remains a significant challenge for most existing methods.\nMoreover, the DeepWKB method is applicable to higher-dimensional stochastic\nsystems whose deterministic counterparts admit non-trivial attractors. In\nparticular, it provides a scalable and flexible alternative for computing the\nquasi-potential, which plays a key role in the analysis of rare events,\nmetastability, and the stochastic stability of complex systems.", "published": "2025-08-13 06:23:06", "link": "http://arxiv.org/abs/2508.09529v1", "categories": ["math.DS", "cs.LG", "60F10, 60J25, 37M25"], "primary_category": "math.DS"}
{"title": "Time-Aware and Transition-Semantic Graph Neural Networks for Interpretable Predictive Business Process Monitoring", "abstract": "Predictive Business Process Monitoring (PBPM) aims to forecast future events\nin ongoing cases based on historical event logs. While Graph Neural Networks\n(GNNs) are well suited to capture structural dependencies in process data,\nexisting GNN-based PBPM models remain underdeveloped. Most rely either on short\nprefix subgraphs or global architectures that overlook temporal relevance and\ntransition semantics. We propose a unified, interpretable GNN framework that\nadvances the state of the art along three key axes. First, we compare\nprefix-based Graph Convolutional Networks(GCNs) and full trace Graph Attention\nNetworks(GATs) to quantify the performance gap between localized and global\nmodeling. Second, we introduce a novel time decay attention mechanism that\nconstructs dynamic, prediction-centered windows, emphasizing temporally\nrelevant history and suppressing noise. Third, we embed transition type\nsemantics into edge features to enable fine grained reasoning over structurally\nambiguous traces. Our architecture includes multilevel interpretability\nmodules, offering diverse visualizations of attention behavior. Evaluated on\nfive benchmarks, the proposed models achieve competitive Top-k accuracy and DL\nscores without per-dataset tuning. By addressing architectural, temporal, and\nsemantic gaps, this work presents a robust, generalizable, and explainable\nsolution for next event prediction in PBPM.", "published": "2025-08-13 06:21:42", "link": "http://arxiv.org/abs/2508.09527v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Enhancing Memory Recall in LLMs with Gauss-Tin: A Hybrid Instructional and Gaussian Replay Approach", "abstract": "Despite the significant advancements in Large Language Models (LLMs),\ncatastrophic forgetting remains a substantial challenge, where models lose\npreviously acquired knowledge upon learning new information. Continual learning\n(CL) strategies have emerged as a potential solution to this problem, with\nreplay-based techniques demonstrating superior performance in preserving\nlearned knowledge. In this context, we introduce Gauss-Tin, a novel approach\nthat integrates the replay strategy with a Gaussian mixture model to enhance\nthe quality of sample selection during training, supplemented by instructional\nguidance to facilitate the generation of past learning. This method aims to\nimprove LLMs' retention capabilities by strategically reinforcing important\npast learnings while accommodating new information. Our experimental results\nindicate a promising 6\\% improvement in retention metrics over traditional\nmethods, suggesting that Gauss-Tin is an effective strategy for mitigating\ncatastrophic forgetting in LLMs. This study underscores the potential of hybrid\nmodels in enhancing the robustness and adaptability of LLMs in dynamic learning\nenvironments.", "published": "2025-08-13 05:45:58", "link": "http://arxiv.org/abs/2508.09510v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Causal Graph Profiling via Structural Divergence for Robust Anomaly Detection in Cyber-Physical Systems", "abstract": "With the growing complexity of cyberattacks targeting critical\ninfrastructures such as water treatment networks, there is a pressing need for\nrobust anomaly detection strategies that account for both system\nvulnerabilities and evolving attack patterns. Traditional methods --\nstatistical, density-based, and graph-based models struggle with distribution\nshifts and class imbalance in multivariate time series, often leading to high\nfalse positive rates. To address these challenges, we propose CGAD, a Causal\nGraph-based Anomaly Detection framework designed for reliable cyberattack\ndetection in public infrastructure systems. CGAD follows a two-phase supervised\nframework -- causal profiling and anomaly scoring. First, it learns causal\ninvariant graph structures representing the system's behavior under \"Normal\"\nand \"Attack\" states using Dynamic Bayesian Networks. Second, it employs\nstructural divergence to detect anomalies via causal graph comparison by\nevaluating topological deviations in causal graphs over time. By leveraging\ncausal structures, CGAD achieves superior adaptability and accuracy in\nnon-stationary and imbalanced time series environments compared to conventional\nmachine learning approaches. By uncovering causal structures beneath volatile\nsensor data, our framework not only detects cyberattacks with markedly higher\nprecision but also redefines robustness in anomaly detection, proving\nresilience where traditional models falter under imbalance and drift. Our\nframework achieves substantial gains in F1 and ROC-AUC scores over\nbest-performing baselines across four industrial datasets, demonstrating robust\ndetection of delayed and structurally complex anomalies.", "published": "2025-08-13 05:26:43", "link": "http://arxiv.org/abs/2508.09504v1", "categories": ["cs.LG", "cs.CR"], "primary_category": "cs.LG"}
{"title": "MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI", "abstract": "Quantized Neural Networks (QNN) with extremely low-bitwidth data have proven\npromising in efficient storage and computation on edge devices. To further\nreduce the accuracy drop while increasing speedup, layer-wise mixed-precision\nquantization (MPQ) becomes a popular solution. However, existing algorithms for\nexploring MPQ schemes are limited in flexibility and efficiency. Comprehending\nthe complex impacts of different MPQ schemes on post-training quantization and\nquantization-aware training results is a challenge for conventional methods.\nFurthermore, an end-to-end framework for the optimization and deployment of MPQ\nmodels is missing in existing work.\n  In this paper, we propose the MiCo framework, a holistic MPQ exploration and\ndeployment framework for edge AI applications. The framework adopts a novel\noptimization algorithm to search for optimal quantization schemes with the\nhighest accuracies while meeting latency constraints. Hardware-aware latency\nmodels are built for different hardware targets to enable fast explorations.\nAfter the exploration, the framework enables direct deployment from PyTorch MPQ\nmodels to bare-metal C codes, leading to end-to-end speedup with minimal\naccuracy drops.", "published": "2025-08-13 05:18:21", "link": "http://arxiv.org/abs/2508.09500v1", "categories": ["cs.LG", "cs.AR"], "primary_category": "cs.LG"}
{"title": "EGGS-PTP: An Expander-Graph Guided Structured Post-training Pruning Method for Large Language Models", "abstract": "As Large Language Models (LLMs) become more widely adopted and scale up in\nsize, the computational and memory challenges involved in deploying these\nmassive foundation models have grown increasingly severe. This underscores the\nurgent need to develop more efficient model variants. Faced with this\nchallenge, the present work introduces EGGS-PTP: an Expander-Graph Guided\nStructured Post-training Pruning method. The proposed approach leverages graph\ntheory to guide the design of N:M structured pruning, effectively reducing\nmodel size and computational demands. By incorporating concepts from expander\ngraphs, EGGS-PTP ensures information flow within the pruned network, preserving\nessential model functionality. Extensive numerical experiments demonstrate that\nEGGS-PTP not only achieves significant acceleration and memory savings due to\nstructured sparsity but also outperforms existing structured pruning techniques\nin terms of accuracy across various LLMs.", "published": "2025-08-13 04:00:56", "link": "http://arxiv.org/abs/2508.09471v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Learn to Explore: Meta NAS via Bayesian Optimization Guided Graph Generation", "abstract": "Neural Architecture Search (NAS) automates the design of high-performing\nneural networks but typically targets a single predefined task, thereby\nrestricting its real-world applicability. To address this, Meta Neural\nArchitecture Search (Meta-NAS) has emerged as a promising paradigm that\nleverages prior knowledge across tasks to enable rapid adaptation to new ones.\nNevertheless, existing Meta-NAS methods often struggle with poor\ngeneralization, limited search spaces, or high computational costs. In this\npaper, we propose a novel Meta-NAS framework, GraB-NAS. Specifically, GraB-NAS\nfirst models neural architectures as graphs, and then a hybrid search strategy\nis developed to find and generate new graphs that lead to promising neural\narchitectures. The search strategy combines global architecture search via\nBayesian Optimization in the search space with local exploration for novel\nneural networks via gradient ascent in the latent space. Such a hybrid search\nstrategy allows GraB-NAS to discover task-aware architectures with strong\nperformance, even beyond the predefined search space. Extensive experiments\ndemonstrate that GraB-NAS outperforms state-of-the-art Meta-NAS baselines,\nachieving better generalization and search effectiveness.", "published": "2025-08-13 03:43:59", "link": "http://arxiv.org/abs/2508.09467v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Open-Set Fault Diagnosis in Multimode Processes via Fine-Grained Deep Feature Representation", "abstract": "A reliable fault diagnosis system should not only accurately classify known\nhealth states but also effectively identify unknown faults. In multimode\nprocesses, samples belonging to the same health state often show multiple\ncluster distributions, making it difficult to construct compact and accurate\ndecision boundaries for that state. To address this challenge, a novel open-set\nfault diagnosis model named fine-grained clustering and rejection network\n(FGCRN) is proposed. It combines multiscale depthwise convolution,\nbidirectional gated recurrent unit and temporal attention mechanism to capture\ndiscriminative features. A distance-based loss function is designed to enhance\nthe intra-class compactness. Fine-grained feature representations are\nconstructed through unsupervised learning to uncover the intrinsic structures\nof each health state. Extreme value theory is employed to model the distance\nbetween sample features and their corresponding fine-grained representations,\nenabling effective identification of unknown faults. Extensive experiments\ndemonstrate the superior performance of the proposed method.", "published": "2025-08-13 03:38:44", "link": "http://arxiv.org/abs/2508.09462v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "NEXICA: Discovering Road Traffic Causality (Extended arXiv Version)", "abstract": "Road traffic congestion is a persistent problem. Focusing resources on the\ncauses of congestion is a potentially efficient strategy for reducing\nslowdowns. We present NEXICA, an algorithm to discover which parts of the\nhighway system tend to cause slowdowns on other parts of the highway. We use\ntime series of road speeds as inputs to our causal discovery algorithm. Finding\nother algorithms inadequate, we develop a new approach that is novel in three\nways. First, it concentrates on just the presence or absence of events in the\ntime series, where an event indicates the temporal beginning of a traffic\nslowdown. Second, we develop a probabilistic model using maximum likelihood\nestimation to compute the probabilities of spontaneous and caused slowdowns\nbetween two locations on the highway. Third, we train a binary classifier to\nidentify pairs of cause/effect locations trained on pairs of road locations\nwhere we are reasonably certain a priori of their causal connections, both\npositive and negative. We test our approach on six months of road speed data\nfrom 195 different highway speed sensors in the Los Angeles area, showing that\nour approach is superior to state-of-the-art baselines in both accuracy and\ncomputation speed.", "published": "2025-08-13 02:59:09", "link": "http://arxiv.org/abs/2508.09447v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A pseudo-inverse of a line graph", "abstract": "Line graphs are an alternative representation of graphs where each vertex of\nthe original (root) graph becomes an edge. However not all graphs have a\ncorresponding root graph, hence the transformation from graphs to line graphs\nis not invertible. We investigate the case when there is a small perturbation\nin the space of line graphs, and try to recover the corresponding root graph,\nessentially defining the inverse of the line graph operation. We propose a\nlinear integer program that edits the smallest number of edges in the line\ngraph, that allow a root graph to be found. We use the spectral norm to\ntheoretically prove that such a pseudo-inverse operation is well behaved.\nIllustrative empirical experiments on Erd\\H{o}s-R\\'enyi graphs show that our\ntheoretical results work in practice.", "published": "2025-08-13 01:04:30", "link": "http://arxiv.org/abs/2508.09412v1", "categories": ["stat.ML", "cs.LG", "math.OC"], "primary_category": "stat.ML"}
{"title": "Graph Neural Network and Transformer Integration for Unsupervised System Anomaly Discovery", "abstract": "This study proposes an unsupervised anomaly detection method for distributed\nbackend service systems, addressing practical challenges such as complex\nstructural dependencies, diverse behavioral evolution, and the absence of\nlabeled data. The method constructs a dynamic graph based on service invocation\nrelationships and applies graph convolution to extract high-order structural\nrepresentations from multi-hop topologies. A Transformer is used to model the\ntemporal behavior of each node, capturing long-term dependencies and local\nfluctuations. During the feature fusion stage, a learnable joint embedding\nmechanism integrates structural and behavioral representations into a unified\nanomaly vector. A nonlinear mapping is then applied to compute anomaly scores,\nenabling an end-to-end detection process without supervision. Experiments on\nreal-world cloud monitoring data include sensitivity analyses across different\ngraph depths, sequence lengths, and data perturbations. Results show that the\nproposed method outperforms existing models on several key metrics,\ndemonstrating stronger expressiveness and stability in capturing anomaly\npropagation paths and modeling dynamic behavior sequences, with high potential\nfor practical deployment.", "published": "2025-08-13 00:35:58", "link": "http://arxiv.org/abs/2508.09401v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Integrating Feature Attention and Temporal Modeling for Collaborative Financial Risk Assessment", "abstract": "This paper addresses the challenges of data privacy and collaborative\nmodeling in cross-institution financial risk analysis. It proposes a risk\nassessment framework based on federated learning. Without sharing raw data, the\nmethod enables joint modeling and risk identification across multiple\ninstitutions. This is achieved by incorporating a feature attention mechanism\nand temporal modeling structure. Specifically, the model adopts a distributed\noptimization strategy. Each financial institution trains a local sub-model. The\nmodel parameters are protected using differential privacy and noise injection\nbefore being uploaded. A central server then aggregates these parameters to\ngenerate a global model. This global model is used for systemic risk\nidentification. To validate the effectiveness of the proposed method, multiple\nexperiments are conducted. These evaluate communication efficiency, model\naccuracy, systemic risk detection, and cross-market generalization. The results\nshow that the proposed model outperforms both traditional centralized methods\nand existing federated learning variants across all evaluation metrics. It\ndemonstrates strong modeling capabilities and practical value in sensitive\nfinancial environments. The method enhances the scope and efficiency of risk\nidentification while preserving data sovereignty. It offers a secure and\nefficient solution for intelligent financial risk analysis.", "published": "2025-08-13 00:29:53", "link": "http://arxiv.org/abs/2508.09399v1", "categories": ["cs.LG", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Online Safety under Multiple Constraints and Input Bounds using gatekeeper: Theory and Applications", "abstract": "This letter presents an approach to guarantee online safety of a\ncyber-physical system under multiple state and input constraints. Our proposed\nframework, called gatekeeper, recursively guarantees the existence of an\ninfinite-horizon trajectory that satisfies all constraints and system dynamics.\nSuch trajectory is constructed using a backup controller, which we define\nformally in this paper. gatekeeper relies on a small number of verifiable\nassumptions, and is computationally efficient since it requires optimization\nover a single scalar variable. We make two primary contributions in this\nletter. (A) First, we develop the theory of gatekeeper: we derive a\nsub-optimality bound relative to a full nonlinear trajectory optimization\nproblem, and show how this can be used in runtime to validate performance. This\nalso informs the design of the backup controllers and sets. (B) Second, we\ndemonstrate in detail an application of gatekeeper for multi-agent formation\nflight, where each Dubins agent must avoid multiple obstacles and weapons\nengagement zones, both of which are nonlinear, nonconvex constraints.", "published": "2025-08-13 17:31:29", "link": "http://arxiv.org/abs/2508.09963v1", "categories": ["eess.SY", "cs.MA", "cs.RO", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Extending the OWASP Multi-Agentic System Threat Modeling Guide: Insights from Multi-Agent Security Research", "abstract": "We propose an extension to the OWASP Multi-Agentic System (MAS) Threat\nModeling Guide, translating recent anticipatory research in multi-agent\nsecurity (MASEC) into practical guidance for addressing challenges unique to\nlarge language model (LLM)-driven multi-agent architectures. Although OWASP's\nexisting taxonomy covers many attack vectors, our analysis identifies gaps in\nmodeling failures, including, but not limited to: reasoning collapse across\nplanner-executor chains, metric overfitting, unsafe delegation escalation,\nemergent covert coordination, and heterogeneous multi-agent exploits. We\nintroduce additional threat classes and scenarios grounded in practical MAS\ndeployments, highlighting risks from benign goal drift, cross-agent\nhallucination propagation, affective prompt framing, and multi-agent backdoors.\nWe also outline evaluation strategies, including robustness testing,\ncoordination assessment, safety enforcement, and emergent behavior monitoring,\nto ensure complete coverage. This work complements the framework of OWASP by\nexpanding its applicability to increasingly complex, autonomous, and adaptive\nmulti-agent systems, with the goal of improving security posture and resilience\nin real world deployments.", "published": "2025-08-13 13:47:55", "link": "http://arxiv.org/abs/2508.09815v1", "categories": ["cs.MA", "cs.CR", "cs.SE"], "primary_category": "cs.MA"}
{"title": "Condition number for finite element discretisation of nonlocal PDE systems with applications to biology", "abstract": "In this work, we investigate the condition number for a system of coupled\nnon-local reaction-diffusion-advection equations developed in the context of\nmodelling normal and abnormal wound healing.\n  Following a finite element discretisation of the coupled non-local system, we\nestablish bounds for this condition number.\n  We further discuss how model parameter choices affect the conditioning of the\nsystem. Finally, we discuss how the step size of the chosen time-stepping\nscheme and the spatial grid size of the finite element methods affect the bound\nfor the condition number, while also suggesting possible parameter ranges that\ncould keep the model well conditioned.", "published": "2025-08-13 13:02:33", "link": "http://arxiv.org/abs/2508.09781v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Fast and Simple Multiclass Data Segmentation: An Eigendecomposition and Projection-Free Approach", "abstract": "Graph-based machine learning has seen an increased interest over the last\ndecade with many connections to other fields of applied mathematics. Learning\nbased on partial differential equations, such as the phase-field Allen-Cahn\nequation, allows efficient handling of semi-supervised learning approaches on\ngraphs. The numerical solution of the graph Allen-Cahn equation via a convexity\nsplitting or the Merriman-Bence-Osher (MBO) scheme, albeit being a widely used\napproach, requires the calculation of a graph Laplacian eigendecomposition and\nrepeated projections over the unit simplex to maintain valid partitions. The\ncomputational efficiency of those methods is hence limited by those two\nbottlenecks in practice, especially when dealing with large-scale instances. In\norder to overcome these limitations, we propose a new framework combining a\nnovel penalty-based reformulation of the segmentation problem, which ensures\nvalid partitions (i.e., binary solutions) for appropriate parameter choices,\nwith an eigendecomposition and projection-free optimization scheme, which has a\nsmall per-iteration complexity (by relying primarily on sparse matrix-vector\nproducts) and guarantees good convergence properties. Experiments on synthetic\nand real-world datasets related to data segmentation in networks and images\ndemonstrate that the proposed framework achieves comparable or better accuracy\nthan the CS and MBO methods while being significantly faster, particularly for\nlarge-scale problems.", "published": "2025-08-13 12:06:20", "link": "http://arxiv.org/abs/2508.09738v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Per-antenna power constraints: constructing Pareto-optimal precoders with cubic complexity under non-negligible noise conditions", "abstract": "Precoding matrix construction is a key element of the wireless signal\nprocessing using the multiple-input and multiple-output model. It is\nestablished that the problem of global throughput optimization under\nper-antenna power constraints belongs, in general, to the class of monotonic\noptimization problems, and is unsolvable in real-time. The most widely used\nreal-time baseline is the suboptimal solution of Zero-Forcing, which achieves a\ncubic complexity by discarding the background noise coefficients. This\nbaseline, however, is not readily adapted to per-antenna power constraints, and\nperforms poorly if background noise coefficients are not negligible. In this\npaper, we are going to present a computational algorithm which constructs a\nprecoder that is SINR multiobjective Pareto-optimal under per-antenna power\nconstraints - with a complexity that differs from that of Zero-Forcing only by\na constant factor. The algorithm has a set of input parameters, changing which\nskews the importance of particular user throughputs: these parameters make up\nan efficient parameterization of the entire Pareto boundary.", "published": "2025-08-13 09:26:15", "link": "http://arxiv.org/abs/2508.09646v1", "categories": ["math.NA", "cs.NA", "eess.SP", "49M05, 68P30", "G.1.3; F.2.1"], "primary_category": "math.NA"}
{"title": "Gap-SBM: A New Conceptualization of the Shifted Boundary Method with Optimal Convergence for the Neumann and Dirichlet Problems", "abstract": "We propose and mathematically analyze a new Shifted Boundary Method for the\ntreatment of Dirichlet and Neumann boundary conditions, with provable optimal\naccuracy in the $L^2$- and $H^1$-norms of the error. The proposed method is\nbuilt on three stages. First, the distance map between the SBM surrogate\nboundary and the true boundary is used to construct an approximation to the\ngeometry of the gap between the two. Then, the representations of the numerical\nsolution and test functions are extended from the surrogate domain to such gap.\nFinally, approximate quadrature formulas and specific shift operators are\napplied to integrate a variational formulation that also involves the fields\nextended in the gap. An extensive set of two-dimensional tests demonstrates the\ntheoretical findings and the overall optimal performance of the proposed\nmethod.", "published": "2025-08-13 08:43:56", "link": "http://arxiv.org/abs/2508.09613v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Random Greedy Fast Block Kaczmarz Method for Solving Large-Scale Nonlinear Systems", "abstract": "To efficiently solve large scale nonlinear systems, we propose a novel Random\nGreedy Fast Block Kaczmarz method. This approach integrates the strengths of\nrandom and greedy strategies while avoiding the computationally expensive\npseudoinversion of Jacobian submatrices, thus enabling efficient solutions for\nlarge scale problems. Our theoretical analysis establishes that the proposed\nmethod achieves linear convergence in expectation, with its convergence rates\nupper bound determined by the stochastic greedy condition number and the\nrelaxation parameter. Numerical experiments confirm that when the Jacobian\nmatrix exhibits a favorable stochastic greedy condition number and an\nappropriate relaxation parameter is selected, the algorithm convergence is\nsignificantly accelerated. As a result, the proposed method outperforms other\ncomparable algorithms in both efficiency and robustness.", "published": "2025-08-13 08:22:43", "link": "http://arxiv.org/abs/2508.09596v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A hyperbolic finite difference scheme for anisotropic diffusion equations: preserving the discrete maximum principle", "abstract": "A hyperbolic system approach is proposed for robust computation of\nanisotropic diffusion equations that appear in quasineutral plasmas. Though the\napproach exhibits merits of high extensibility and accurate flux computation,\nthe monotonicity of the scheme for anisotropic diffusion cases has not been\nunderstood. In this study, the discrete maximum principle (DMP) of the\nhyperbolic system approach is analyzed and tested in various anisotropic\ndiffusion cases. A mathematical analysis is conducted to obtain an optimal\ncondition of an arbitrary parameter to guarantee the DMP, and numerical\nexperiments reveal an adoptive selection of the parameter for DMP-preserving\nresults. It is confirmed that, with an appropriate preconditioning matrix and\nparameter choice, the hyperbolic system approach preserves the DMP even with a\nlinear discretization.", "published": "2025-08-13 05:44:45", "link": "http://arxiv.org/abs/2508.09509v1", "categories": ["math.NA", "cs.NA", "physics.plasm-ph", "35K20, 65M12, 65N06"], "primary_category": "math.NA"}
{"title": "Semi-discrete multi-to -one dimensional variational problems", "abstract": "We study a class of semi-discrete variational problems that arise in economic\nmatching and game theory, where agents with continuous attributes are matched\nto a finite set of outcomes with a one dimensional structure. Such problems\nappear in applications including Cournot-Nash equilibria, and hedonic pricing,\nand can be formulated as problems involving optimal transport between spaces of\nunequal dimensions. In our discrete strategy space setting, we establish\nanalogues of results developed for a continuum of strategies in\n\\cite{nenna2020variational}, ensuring solutions have a particularly simple\nstructure under certain conditions. This has important numerical consequences,\nas it is natural to discretize when numerically computing solutions. We\nleverage our results to develop efficient algorithms for these problems which\nscale significantly better than standard optimal transport solvers,\nparticularly when the number of discrete outcomes is large, provided our\nconditions are satisfied. We also establish rigorous convergence guarantees for\nthese algorithms. We illustrate the advantages of our approach by solving a\nrange of numerical examples; in many of these our new solvers outperform\nalternatives by a considerable margin.", "published": "2025-08-13 04:52:03", "link": "http://arxiv.org/abs/2508.09490v1", "categories": ["math.OC", "cs.NA", "math.NA"], "primary_category": "math.OC"}
{"title": "Generalized Plane Wave quasi-Trefftz spaces for wave propagation in inhomogeneous media", "abstract": "Partial Differential Equations (PDEs) models for wave propagation in\ninhomogeneous media are relevant for many applications. We will discuss\nnumerical methods tailored for tackling problems governed by these\nvariable-coefficient PDEs. Trefftz methods rely, in broad terms, on the idea of\napproximating solutions to PDEs via Galerkin methods using basis functions that\nare exact solutions of the PDE, making explicit use of information about the\nambient medium. However, wave propagation in inhomogeneous media is modeled by\nPDEs with variable coefficients, and in general no exact solutions are\navailable. Quasi-Trefftz methods have been introduced, in the case of the\nHelmholtz equation, to address this problem: they rely instead on high-order\napproximate solutions constructed locally. We will discuss basis of Generalized\nPlane Waves, a particular kind of quasi-Trefftz functions, and how their\nconstruction can be related to the construction of polynomial quasi-Trefftz\nbases.", "published": "2025-08-13 02:27:46", "link": "http://arxiv.org/abs/2508.09435v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Trigonometric Interpolation Based Approach for Second Order Fredholm Integro-Differential Equations", "abstract": "A trigonometric interpolation algorithm for non-periodic functions has been\nrecently proposed and applied to study general ordinary differential equation\n(ODE). This paper enhances the algorithm to approximate functions in $2$-dim\nspace. Performance of the enhanced algorithm is expected to be similar as in\n$1$-dim case and achieve accuracy aligned with the smoothness of the target\nfunction, which is confirmed by numerical examples.\n  As an application, the $2$-dim trigonometric interpolation method is used to\ndevelop an algorithm for the solution of a second order Fredholm\nintegro-differential equation (FIDE). There are several advantages of the\nalgorithm. First of all, it converges quickly and high accuracy can be achieved\nwith a moderate size of grid points; Secondly, it can effectively address\nsingularities of kernel functions and work well with general boundary\nconditions. Finally, it can be enhanced to copy with other IDE such as Volterra\nIDE or IDE with high order ODE component. The tests conducted in this paper\ninclude various boundary conditions with both continuous kernels and integrable\nones with singularity. Decent performance is observed across all covered\nscenarios with a moderate size of grid points.", "published": "2025-08-13 01:10:54", "link": "http://arxiv.org/abs/2508.09413v1", "categories": ["math.NA", "cs.NA", "Primary 65T40, Secondary 45B05"], "primary_category": "math.NA"}
{"title": "Marketron Through the Looking Glass: From Equity Dynamics to Option Pricing in Incomplete Markets", "abstract": "The Marketron model, introduced by [Halperin, Itkin, 2025], describes price\nformation in inelastic markets as the nonlinear diffusion of a quasiparticle\n(the marketron) in a multidimensional space comprising the log-price $x$, a\nmemory variable $y$ encoding past money flows, and unobservable return\npredictors $z$. While the original work calibrated the model to S\\&P 500 time\nseries data, this paper extends the framework to option markets - a\nfundamentally distinct challenge due to market incompleteness stemming from\nnon-tradable state variables. We develop a utility-based pricing approach that\nconstructs a risk-adjusted measure via the dual solution of an optimal\ninvestment problem. The resulting Hamilton-Jacobi-Bellman (HJB) equation,\nthough computationally formidable, is solved using a novel methodology enabling\nefficient calibration even on standard laptop hardware. Having done that, we\nlook at the additional question to answer: whether the Marketron model,\ncalibrated to market option prices, can simultaneously reproduce the\nstatistical properties of the underlying asset's log-returns. We discuss our\nresults in view of the long-standing challenge in quantitative finance of\ndeveloping an unified framework capable of jointly capturing equity returns,\noption smile dynamics, and potentially volatility index behavior.", "published": "2025-08-13 14:53:58", "link": "http://arxiv.org/abs/2508.09863v1", "categories": ["q-fin.PR", "q-fin.CP", "q-fin.MF"], "primary_category": "q-fin.PR"}
{"title": "HingeNet: A Harmonic-Aware Fine-Tuning Approach for Beat Tracking", "abstract": "Fine-tuning pre-trained foundation models has made significant progress in\nmusic information retrieval. However, applying these models to beat tracking\ntasks remains unexplored as the limited annotated data renders conventional\nfine-tuning methods ineffective. To address this challenge, we propose\nHingeNet, a novel and general parameter-efficient fine-tuning method\nspecifically designed for beat tracking tasks. HingeNet is a lightweight and\nseparable network, visually resembling a hinge, designed to tightly interface\nwith pre-trained foundation models by using their intermediate feature\nrepresentations as input. This unique architecture grants HingeNet broad\ngeneralizability, enabling effective integration with various pre-trained\nfoundation models. Furthermore, considering the significance of harmonics in\nbeat tracking, we introduce harmonic-aware mechanism during the fine-tuning\nprocess to better capture and emphasize the harmonic structures in musical\nsignals. Experiments on benchmark datasets demonstrate that HingeNet achieves\nstate-of-the-art performance in beat and downbeat tracking", "published": "2025-08-13 13:15:37", "link": "http://arxiv.org/abs/2508.09788v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "$\\text{M}^3\\text{PDB}$: A Multimodal, Multi-Label, Multilingual Prompt Database for Speech Generation", "abstract": "Recent advancements in zero-shot speech generation have enabled models to\nsynthesize speech that mimics speaker identity and speaking style from speech\nprompts. However, these models' effectiveness is significantly limited in\nreal-world scenarios where high-quality speech prompts are absent, incomplete,\nor out of domain. This issue arises primarily from a significant quality\nmismatch between the speech data utilized for model training and the input\nprompt speech during inference. To address this, we introduce\n$\\text{M}^3\\text{PDB}$, the first large-scale, multi-modal, multi-label, and\nmultilingual prompt database designed for robust prompt selection in speech\ngeneration. Our dataset construction leverages a novel multi-modal, multi-agent\nannotation framework, enabling precise and hierarchical labeling across diverse\nmodalities. Furthermore, we propose a lightweight yet effective prompt\nselection strategy tailored for real-time, resource-constrained inference\nsettings. Experimental results demonstrate that our proposed database and\nselection strategy effectively support various challenging speech generation\nscenarios. We hope our work can inspire the community to shift focus from\nimproving performance on standard benchmarks to addressing more realistic and\ndiverse application scenarios in speech generation. Code and dataset are\navailable at: https://github.com/hizening/M3PDB.", "published": "2025-08-13 10:56:24", "link": "http://arxiv.org/abs/2508.09702v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Beam Cross Sections Create Mixtures: Improving Feature Localization in Secondary Electron Imaging", "abstract": "Secondary electron (SE) imaging techniques, such as scanning electron\nmicroscopy and helium ion microscopy (HIM), use electrons emitted by a sample\nin response to a focused beam of charged particles incident at a grid of raster\nscan positions. Spot size -- the diameter of the incident beam's spatial\nprofile -- is one of the limiting factors for resolution, along with various\nsources of noise in the SE signal. The effect of the beam spatial profile is\ncommonly understood as convolutional. We show that under a simple and plausible\nphysical abstraction for the beam, though convolution describes the mean of the\nSE counts, the full distribution of SE counts is a mixture. We demonstrate that\nthis more detailed modeling can enable resolution improvements over\nconventional estimators through a stylized application in semiconductor\ninspection of localizing the edge in a two-valued sample. We derive Fisher\ninformation about edge location in conventional and time-resolved measurements\n(TRM) and also derive the maximum likelihood estimate (MLE) from the latter.\nEmpirically, the MLE computed from TRM is approximately efficient except at\nvery low beam diameter, so Fisher information comparisons are predictive of\nperformance and can be used to optimize the beam diameter relative to the\nraster scan spacing. Monte Carlo simulations show that the MLE gives a 5-fold\nreduction in root mean-squared error (RMSE) of edge localization as compared to\nconventional interpolation-based estimation. Applied to three real HIM\ndatasets, the average RMSE reduction factor is 5.4.", "published": "2025-08-13 16:57:08", "link": "http://arxiv.org/abs/2508.09942v1", "categories": ["eess.SP", "cond-mat.mtrl-sci"], "primary_category": "eess.SP"}
{"title": "Location Privacy-Enabled Beamforming in ISAC Scenarios", "abstract": "Integrated sensing and communication (ISAC) technology enables simultaneous\nenvironmental perception and data transmission in wireless networks; however,\nit also exposes user location to receivers. In this paper, we introduce a novel\nbeamforming framework guided by the proposed privacy metric direction of\narrival obfuscation ratio (DAOR) to protect transmitter location privacy in\nISAC scenarios. Unlike previous approaches, we do not suppress the\nline-of-sight (LOS) component while reshaping the angular power distribution so\nthat a false direction appears dominant at the receiver. We derive closed-form\nbounds on the feasible DAOR via generalized eigenvalue analysis and formulate\nan achievable rate-maximization problem under the DAOR constraint. The\nresulting problem is non-convex, which is efficiently solved using semidefinite\nrelaxation, eigenmode selection, and optimal power allocation. A suboptimal\ndesign strategy is also proposed with reduced complexity. Numerical results\ndemonstrate that the proposed DAOR-based beamformer achieves a trade-off\nbetween location privacy and communication rate without nullifying the LOS\npath. Results also show that a suboptimal design achieves a near-optimal\ncommunication rate with nearly an 85% reduction in computation time at a\nsignal-to-noise ratio (SNR) of 10 dB.", "published": "2025-08-13 15:32:10", "link": "http://arxiv.org/abs/2508.09882v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Online Data Generation for MIMO-OFDM Channel Denoising: Transfer Learning vs. Meta Learning", "abstract": "Channel denoising is a practical and effective technique for mitigating\nchannel estimation errors in multiple-input multiple-output orthogonal\nfrequency-division multiplexing (MIMO-OFDM) systems. However, adapting\ndenoising techniques to varying channel conditions typically requires prior\nknowledge or incurs significant training overhead. To address these challenges,\nwe propose a standard-compatible strategy for generating online training data\nthat enables online adaptive channel denoising. The key idea is to leverage\nhigh-quality channel estimates obtained via data-aided channel estimation as\npractical substitutes for unavailable ground-truth channels. Our data-aided\nmethod exploits adjacent detected data symbols within a specific time-frequency\nneighborhood as virtual reference signals, and we analytically derive the\noptimal size of this neighborhood to minimize the mean squared error of the\nresulting estimates. By leveraging the proposed strategy, we devise two channel\ndenoising approaches, one based on transfer learning, which fine-tunes a\npre-trained denoising neural network, and the other based on meta learning,\nwhich rapidly adapts to new channel environments with minimal updates.\nSimulation results demonstrate that the proposed methods effectively adapt to\ndynamic channel conditions and significantly reduce channel estimation errors\ncompared to conventional techniques.", "published": "2025-08-13 12:28:58", "link": "http://arxiv.org/abs/2508.09751v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "CKFNet: Neural Network Aided Cubature Kalman filtering", "abstract": "The cubature Kalman filter (CKF), while theoretically rigorous for nonlinear\nestimation, often suffers performance degradation due to model-environment\nmismatches in practice. To address this limitation, we propose CKFNet-a hybrid\narchitecture that synergistically integrates recurrent neural networks (RNN)\nwith the CKF framework while preserving its cubature principles. Unlike\nconventional model-driven approaches, CKFNet embeds RNN modules in the\nprediction phase to dynamically adapt to unmodeled uncertainties, effectively\nreducing cumulative error propagation through temporal noise correlation\nlearning. Crucially, the architecture maintains CKF's analytical\ninterpretability via constrained optimization of cubature point distributions.\nNumerical simulation experiments have confirmed that our proposed CKFNet\nexhibits superior accuracy and robustness compared to conventional model-based\nmethods and existing KalmanNet algorithms.", "published": "2025-08-13 11:45:16", "link": "http://arxiv.org/abs/2508.09727v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "3GPP NR V2X Mode 2d: Analysis of Distributed Scheduling for Groupcast using ns-3 5G LENA Simulator", "abstract": "Vehicle-to-everything (V2X) communication is a key technology for enabling\nintelligent transportation systems (ITS) that can improve road safety, traffic\nefficiency, and environmental sustainability. Among the various V2X\napplications, platooning is one of the most promising ones, as it allows a\ngroup of vehicles to travel closely together at high speeds, reducing fuel\nconsumption and emissions. However, it poses significant challenges for\nwireless communication, such as high reliability and low latency. In this\npaper, we evaluate the benefits of group scheduling, also referred to as Mode\n2d, which is based on a distributed and scheduled resource allocation scheme\nthat allows the group of cars to select resources from a configured pool\nwithout network assistance. We evaluated the scheme through simulations, and\nthe results show that this approach can meet the reliability, low latency, and\ndata rate requirements for platooning.", "published": "2025-08-13 11:02:11", "link": "http://arxiv.org/abs/2508.09708v1", "categories": ["eess.SP", "cs.NI", "C.2.1; C.2.2; C.2.4"], "primary_category": "eess.SP"}
{"title": "Profiling Multi-Level Operator Costs for Bottleneck Diagnosis in High-Speed Data Planes", "abstract": "This paper proposes a saturation throughput delta-based methodology to\nprecisely measure operator costs in high-speed data planes without intrusive\ninstrumentation. The approach captures non-linear scaling, revealing that\ncompute-intensive operators like CRC exhibit super-linear behavior, while most\nothers are sub-linear. We introduce the Operator Performance Quadrant (OPQ)\nframework to classify operators by base and scaling costs, exposing a\ncross-architecture Quadrant Shift between Arm and x86. This method provides\naccurate, architecture-aware bottleneck diagnosis and a realistic basis for\nperformance modeling and optimization.", "published": "2025-08-13 07:44:59", "link": "http://arxiv.org/abs/2508.09574v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Low-latency D-MIMO Localization using Distributed Scalable Message-Passing Algorithm", "abstract": "Distributed MIMO and integrated sensing and communication are expected to be\nkey technologies in future wireless systems, enabling reliable, low-latency\ncommunication and accurate localization. Dedicated localization solutions must\nsupport distributed architecture, provide scalability across different system\nconfigurations and meet strict latency requirements. We present a scalable\nmessage-passing localization method and architecture co-designed for a\npanel-based distributed MIMO system and network topology, in which\ninterconnected units operate without centralized processing. This method\njointly detects line-of-sight paths to distributed units from multipath\nmeasurements in dynamic scenarios, localizes the agent, and achieves very low\nlatency. Additionally, we introduce a cycle-accurate system latency model based\non implemented FPGA operations, and show important insights into processing\nlatency and hardware utilization and system-level trade-offs. We compare our\nmethod to a multipath-based localization method and show that it can achieve\nsimilar localization performance, with wide enough distribution of array\nelements, while offering lower latency and computational complexity.", "published": "2025-08-13 07:05:08", "link": "http://arxiv.org/abs/2508.09546v1", "categories": ["eess.SP", "cs.AR"], "primary_category": "eess.SP"}
{"title": "Sub-THz Power Amplifiers: Measurements, Behavioral Modeling and Predistortion Algorithms", "abstract": "With global IMT traffic expected to grow 10-100 times from 2020 to 20301, the\nTerahertz (THz) spectrum offers a promising solution to satisfy such forecasts.\nHowever, occupying the THz spectrum comes with its own challenges, an important\none being impairments caused by broadband RF components in THz transceivers.\nNonlinearities in power amplifiers (PAs) complicate meeting link budget\nrequirements, with amplitude and phase distortions degrading the system's\nperformance, especially when adopting waveforms with high peak-to-average power\nratios (PAPRs), such as Orthogonal Frequency Division Multiplexing (OFDM). In\nthis paper, we present characterization results of a 300 GHz PA using\nsmall-signal and large-signal continuous-wave measurements. Models capturing\nAmplitude-to- Amplitude Modulation (AM-AM) and Amplitude-to-Phase Modulation\n(AMPM) behavior across 270-330 GHz are developed and verified with wideband\nmeasurements, confirming the compression behavior, while nonetheless showing\ninaccuracies for low input powers due to unaccounted frequency dependencies.\nBased on the derived models, a predistortion algorithm is designed and\nanalyzed, revealing significant error performance degradation when switching\nbetween single- and multi-carrier waveforms. We finally show that an\nappropriate selection of pre-distorter parameters can significantly improve the\nperformance.", "published": "2025-08-13 07:04:44", "link": "http://arxiv.org/abs/2508.09545v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Performance of GPT-5 Frontier Models in Ophthalmology Question Answering", "abstract": "Large language models (LLMs) such as GPT-5 integrate advanced reasoning\ncapabilities that may improve performance on complex medical question-answering\ntasks. For this latest generation of reasoning models, the configurations that\nmaximize both accuracy and cost-efficiency have yet to be established. We\nevaluated 12 configurations of OpenAI's GPT-5 series (three model tiers across\nfour reasoning effort settings) alongside o1-high, o3-high, and GPT-4o, using\n260 closed-access multiple-choice questions from the American Academy of\nOphthalmology Basic Clinical Science Course (BCSC) dataset. The primary outcome\nwas multiple-choice accuracy; secondary outcomes included head-to-head ranking\nvia a Bradley-Terry model, rationale quality assessment using a\nreference-anchored, pairwise LLM-as-a-judge framework, and analysis of\naccuracy-cost trade-offs using token-based cost estimates. GPT-5-high achieved\nthe highest accuracy (0.965; 95% CI, 0.942-0.985), outperforming all GPT-5-nano\nvariants (P < .001), o1-high (P = .04), and GPT-4o (P < .001), but not o3-high\n(0.958; 95% CI, 0.931-0.981). GPT-5-high ranked first in both accuracy (1.66x\nstronger than o3-high) and rationale quality (1.11x stronger than o3-high).\nCost-accuracy analysis identified several GPT-5 configurations on the Pareto\nfrontier, with GPT-5-mini-low offering the most favorable low-cost,\nhigh-performance balance. These results benchmark GPT-5 on a high-quality\nophthalmology dataset, demonstrate the influence of reasoning effort on\naccuracy, and introduce an autograder framework for scalable evaluation of\nLLM-generated answers against reference standards in ophthalmology.", "published": "2025-08-13 17:17:17", "link": "http://arxiv.org/abs/2508.09956v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts", "abstract": "We introduce PRELUDE, a benchmark for evaluating long-context understanding\nthrough the task of determining whether a character's prequel story is\nconsistent with the canonical narrative of the original book. Our task poses a\nstronger demand for global comprehension and deep reasoning than existing\nbenchmarks -- as the prequels are not part of the original story, assessing\ntheir plausibility typically requires searching and integrating information\nthat is only indirectly related. Empirically, 88% of instances require evidence\nfrom multiple parts of the narrative. Experimental results highlight the\nchallenge of our task: in-context learning, RAG and in-domain training with\nstate-of-the-art LLMs, and commercial DeepResearch services, lag behind humans\nby >15%. A further human study reveals that models often produce correct\nanswers with flawed reasoning, leading to an over 30% gap in reasoning accuracy\ncompared to humans. These findings underscore the substantial room for\nimprovement in long-context understanding and reasoning.", "published": "2025-08-13 14:28:25", "link": "http://arxiv.org/abs/2508.09848v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Columbo: Expanding Abbreviated Column Names for Tabular Data Using Large Language Models", "abstract": "Expanding the abbreviated column names of tables, such as \"esal\" to \"employee\nsalary\", is critical for numerous downstream data tasks. This problem arises in\nenterprises, domain sciences, government agencies, and more. In this paper we\nmake three contributions that significantly advances the state of the art.\nFirst, we show that synthetic public data used by prior work has major\nlimitations, and we introduce 4 new datasets in enterprise/science domains,\nwith real-world abbreviations. Second, we show that accuracy measures used by\nprior work seriously undercount correct expansions, and we propose new\nsynonym-aware measures that capture accuracy much more accurately. Finally, we\ndevelop Columbo, a powerful LLM-based solution that exploits context, rules,\nchain-of-thought reasoning, and token-level analysis. Extensive experiments\nshow that Columbo significantly outperforms NameGuess, the current most\nadvanced solution, by 4-29%, over 5 datasets. Columbo has been used in\nproduction on EDI, a major data portal for environmental sciences.", "published": "2025-08-13 00:39:22", "link": "http://arxiv.org/abs/2508.09403v2", "categories": ["cs.CL", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Mathematical Computation and Reasoning Errors by Large Language Models", "abstract": "Large Language Models (LLMs) are increasingly utilized in AI-driven\neducational instruction and assessment, particularly within mathematics\neducation. The capability of LLMs to generate accurate answers and detailed\nsolutions for math problem-solving tasks is foundational for ensuring reliable\nand precise feedback and assessment in math education practices. Our study\nfocuses on evaluating the accuracy of four LLMs (OpenAI GPT-4o and o1,\nDeepSeek-V3 and DeepSeek-R1) solving three categories of math tasks, including\narithmetic, algebra, and number theory, and identifies step-level reasoning\nerrors within their solutions. Instead of relying on standard benchmarks, we\nintentionally build math tasks (via item models) that are challenging for LLMs\nand prone to errors. The accuracy of final answers and the presence of errors\nin individual solution steps were systematically analyzed and coded. Both\nsingle-agent and dual-agent configurations were tested. It is observed that the\nreasoning-enhanced OpenAI o1 model consistently achieved higher or nearly\nperfect accuracy across all three math task categories. Analysis of errors\nrevealed that procedural slips were the most frequent and significantly\nimpacted overall performance, while conceptual misunderstandings were less\nfrequent. Deploying dual-agent configurations substantially improved overall\nperformance. These findings offer actionable insights into enhancing LLM\nperformance and underscore effective strategies for integrating LLMs into\nmathematics education, thereby advancing AI-driven instructional practices and\nassessment precision.", "published": "2025-08-13 16:33:02", "link": "http://arxiv.org/abs/2508.09932v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Preacher: Paper-to-Video Agentic System", "abstract": "The paper-to-video task converts a research paper into a structured video\nabstract, distilling key concepts, methods, and conclusions into an accessible,\nwell-organized format. While state-of-the-art video generation models\ndemonstrate potential, they are constrained by limited context windows, rigid\nvideo duration constraints, limited stylistic diversity, and an inability to\nrepresent domain-specific knowledge. To address these limitations, we introduce\nPreacher, the first paper-to-video agentic system. Preacher employs a topdown\napproach to decompose, summarize, and reformulate the paper, followed by\nbottom-up video generation, synthesizing diverse video segments into a coherent\nabstract. To align cross-modal representations, we define key scenes and\nintroduce a Progressive Chain of Thought (P-CoT) for granular, iterative\nplanning. Preacher successfully generates high-quality video abstracts across\nfive research fields, demonstrating expertise beyond current video generation\nmodels. Code will be released at: https://github.com/GenVerse/Paper2Video", "published": "2025-08-13 09:08:51", "link": "http://arxiv.org/abs/2508.09632v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Hallucination vs interpretation: rethinking accuracy and precision in AI-assisted data extraction for knowledge synthesis", "abstract": "Knowledge syntheses (literature reviews) are essential to health professions\neducation (HPE), consolidating findings to advance theory and practice.\nHowever, they are labor-intensive, especially during data extraction.\nArtificial Intelligence (AI)-assisted extraction promises efficiency but raises\nconcerns about accuracy, making it critical to distinguish AI 'hallucinations'\n(fabricated content) from legitimate interpretive differences. We developed an\nextraction platform using large language models (LLMs) to automate data\nextraction and compared AI to human responses across 187 publications and 17\nextraction questions from a published scoping review. AI-human, human-human,\nand AI-AI consistencies were measured using interrater reliability\n(categorical) and thematic similarity ratings (open-ended). Errors were\nidentified by comparing extracted responses to source publications. AI was\nhighly consistent with humans for concrete, explicitly stated questions (e.g.,\ntitle, aims) and lower for questions requiring subjective interpretation or\nabsent in text (e.g., Kirkpatrick's outcomes, study rationale). Human-human\nconsistency was not higher than AI-human and showed the same question-dependent\nvariability. Discordant AI-human responses (769/3179 = 24.2%) were mostly due\nto interpretive differences (18.3%); AI inaccuracies were rare (1.51%), while\nhumans were nearly three times more likely to state inaccuracies (4.37%).\nFindings suggest AI variability depends more on interpretability than\nhallucination. Repeating AI extraction can identify interpretive complexity or\nambiguity, refining processes before human review. AI can be a transparent,\ntrustworthy partner in knowledge synthesis, though caution is needed to\npreserve critical human insights.", "published": "2025-08-13 03:33:30", "link": "http://arxiv.org/abs/2508.09458v2", "categories": ["cs.HC", "cs.AI", "cs.ET"], "primary_category": "cs.HC"}
{"title": "Semantic-aware DropSplat: Adaptive Pruning of Redundant Gaussians for 3D Aerial-View Segmentation", "abstract": "In the task of 3D Aerial-view Scene Semantic Segmentation (3D-AVS-SS),\ntraditional methods struggle to address semantic ambiguity caused by scale\nvariations and structural occlusions in aerial images. This limits their\nsegmentation accuracy and consistency. To tackle these challenges, we propose a\nnovel 3D-AVS-SS approach named SAD-Splat. Our method introduces a Gaussian\npoint drop module, which integrates semantic confidence estimation with a\nlearnable sparsity mechanism based on the Hard Concrete distribution. This\nmodule effectively eliminates redundant and semantically ambiguous Gaussian\npoints, enhancing both segmentation performance and representation compactness.\nFurthermore, SAD-Splat incorporates a high-confidence pseudo-label generation\npipeline. It leverages 2D foundation models to enhance supervision when\nground-truth labels are limited, thereby further improving segmentation\naccuracy. To advance research in this domain, we introduce a challenging\nbenchmark dataset: 3D Aerial Semantic (3D-AS), which encompasses diverse\nreal-world aerial scenes with sparse annotations. Experimental results\ndemonstrate that SAD-Splat achieves an excellent balance between segmentation\naccuracy and representation compactness. It offers an efficient and scalable\nsolution for 3D aerial scene understanding.", "published": "2025-08-13 08:57:38", "link": "http://arxiv.org/abs/2508.09626v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SHALE: A Scalable Benchmark for Fine-grained Hallucination Evaluation in LVLMs", "abstract": "Despite rapid advances, Large Vision-Language Models (LVLMs) still suffer\nfrom hallucinations, i.e., generating content inconsistent with input or\nestablished world knowledge, which correspond to faithfulness and factuality\nhallucinations, respectively. Prior studies primarily evaluate faithfulness\nhallucination at a rather coarse level (e.g., object-level) and lack\nfine-grained analysis. Additionally, existing benchmarks often rely on costly\nmanual curation or reused public datasets, raising concerns about scalability\nand data leakage. To address these limitations, we propose an automated data\nconstruction pipeline that produces scalable, controllable, and diverse\nevaluation data. We also design a hierarchical hallucination induction\nframework with input perturbations to simulate realistic noisy scenarios.\nIntegrating these designs, we construct SHALE, a Scalable HALlucination\nEvaluation benchmark designed to assess both faithfulness and factuality\nhallucinations via a fine-grained hallucination categorization scheme. SHALE\ncomprises over 30K image-instruction pairs spanning 12 representative visual\nperception aspects for faithfulness and 6 knowledge domains for factuality,\nconsidering both clean and noisy scenarios. Extensive experiments on over 20\nmainstream LVLMs reveal significant factuality hallucinations and high\nsensitivity to semantic perturbations.", "published": "2025-08-13 07:58:01", "link": "http://arxiv.org/abs/2508.09584v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "WeatherPrompt: Multi-modality Representation Learning for All-Weather Drone Visual Geo-Localization", "abstract": "Visual geo-localization for drones faces critical degradation under weather\nperturbations, \\eg, rain and fog, where existing methods struggle with two\ninherent limitations: 1) Heavy reliance on limited weather categories that\nconstrain generalization, and 2) Suboptimal disentanglement of entangled\nscene-weather features through pseudo weather categories. We present\nWeatherPrompt, a multi-modality learning paradigm that establishes\nweather-invariant representations through fusing the image embedding with the\ntext context. Our framework introduces two key contributions: First, a\nTraining-free Weather Reasoning mechanism that employs off-the-shelf large\nmulti-modality models to synthesize multi-weather textual descriptions through\nhuman-like reasoning. It improves the scalability to unseen or complex weather,\nand could reflect different weather strength. Second, to better disentangle the\nscene and weather feature, we propose a multi-modality framework with the\ndynamic gating mechanism driven by the text embedding to adaptively reweight\nand fuse visual features across modalities. The framework is further optimized\nby the cross-modal objectives, including image-text contrastive learning and\nimage-text matching, which maps the same scene with different weather\nconditions closer in the respresentation space. Extensive experiments validate\nthat, under diverse weather conditions, our method achieves competitive recall\nrates compared to state-of-the-art drone geo-localization methods. Notably, it\nimproves Recall@1 by +13.37\\% under night conditions and by 18.69\\% under fog\nand snow conditions.", "published": "2025-08-13 07:28:41", "link": "http://arxiv.org/abs/2508.09560v2", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Iterative Volume Fusion for Asymmetric Stereo Matching", "abstract": "Stereo matching is vital in 3D computer vision, with most algorithms assuming\nsymmetric visual properties between binocular visions. However, the rise of\nasymmetric multi-camera systems (e.g., tele-wide cameras) challenges this\nassumption and complicates stereo matching. Visual asymmetry disrupts stereo\nmatching by affecting the crucial cost volume computation. To address this, we\nexplore the matching cost distribution of two established cost volume\nconstruction methods in asymmetric stereo. We find that each cost volume\nexperiences distinct information distortion, indicating that both should be\ncomprehensively utilized to solve the issue. Based on this, we propose the\ntwo-phase Iterative Volume Fusion network for Asymmetric Stereo matching\n(IVF-AStereo). Initially, the aggregated concatenation volume refines the\ncorrelation volume. Subsequently, both volumes are fused to enhance fine\ndetails. Our method excels in asymmetric scenarios and shows robust performance\nagainst significant visual asymmetry. Extensive comparative experiments on\nbenchmark datasets, along with ablation studies, confirm the effectiveness of\nour approach in asymmetric stereo with resolution and color degradation.", "published": "2025-08-13 06:55:40", "link": "http://arxiv.org/abs/2508.09543v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SOI is the Root of All Evil: Quantifying and Breaking Similar Object Interference in Single Object Tracking", "abstract": "In this paper, we present the first systematic investigation and\nquantification of Similar Object Interference (SOI), a long-overlooked yet\ncritical bottleneck in Single Object Tracking (SOT). Through controlled Online\nInterference Masking (OIM) experiments, we quantitatively demonstrate that\neliminating interference sources leads to substantial performance improvements\n(AUC gains up to 4.35) across all SOTA trackers, directly validating SOI as a\nprimary constraint for robust tracking and highlighting the feasibility of\nexternal cognitive guidance. Building upon these insights, we adopt natural\nlanguage as a practical form of external guidance, and construct SOIBench-the\nfirst semantic cognitive guidance benchmark specifically targeting SOI\nchallenges. It automatically mines SOI frames through multi-tracker collective\njudgment and introduces a multi-level annotation protocol to generate precise\nsemantic guidance texts. Systematic evaluation on SOIBench reveals a striking\nfinding: existing vision-language tracking (VLT) methods fail to effectively\nexploit semantic cognitive guidance, achieving only marginal improvements or\neven performance degradation (AUC changes of -0.26 to +0.71). In contrast, we\npropose a novel paradigm employing large-scale vision-language models (VLM) as\nexternal cognitive engines that can be seamlessly integrated into arbitrary RGB\ntrackers. This approach demonstrates substantial improvements under semantic\ncognitive guidance (AUC gains up to 0.93), representing a significant\nadvancement over existing VLT methods. We hope SOIBench will serve as a\nstandardized evaluation platform to advance semantic cognitive tracking\nresearch and contribute new insights to the tracking research community.", "published": "2025-08-13 06:12:43", "link": "http://arxiv.org/abs/2508.09524v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "From Large Angles to Consistent Faces: Identity-Preserving Video Generation via Mixture of Facial Experts", "abstract": "Current video generation models struggle with identity preservation under\nlarge facial angles, primarily facing two challenges: the difficulty in\nexploring an effective mechanism to integrate identity features into DiT\nstructure, and the lack of targeted coverage of large facial angles in existing\nopen-source video datasets. To address these, we present two key innovations.\nFirst, we introduce a Mixture of Facial Experts (MoFE) that dynamically\ncombines complementary cues from three specialized experts, each designed to\ncapture distinct but mutually reinforcing aspects of facial attributes. The\nidentity expert captures cross-pose identity-sensitive features, the semantic\nexpert extracts high-level visual semantxics, and the detail expert preserves\npixel-level features (e.g., skin texture, color gradients). Furthermore, to\nmitigate dataset limitations, we have tailored a data processing pipeline\ncentered on two key aspects: Face Constraints and Identity Consistency. Face\nConstraints ensure facial angle diversity and a high proportion of facial\nregions, while Identity Consistency preserves coherent person-specific features\nacross temporal sequences, collectively addressing the scarcity of large facial\nangles and identity-stable training data in existing datasets. Leveraging this\npipeline, we have curated and refined a Large Face Angles (LFA) Dataset from\nexisting open-source human video datasets, comprising 460K video clips with\nannotated facial angles. Experimental results on the LFA benchmark demonstrate\nthat our method, empowered by the LFA dataset, significantly outperforms prior\nSOTA methods in face similarity, face FID, and CLIP semantic alignment. The\ncode and dataset will be made publicly available at\nhttps://github.com/rain152/LFA-Video-Generation.", "published": "2025-08-13 04:10:16", "link": "http://arxiv.org/abs/2508.09476v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Using nonassociative algebras to classify skew polycyclic codes up to isometry and equivalence", "abstract": "We propose new definitions of equivalence and isometry for skew polycyclic\ncodes that will lead to tighter classifications than existing ones. This helps\nto reduce the number of previously known isometry and equivalence classes, and\nstate precisely when these different notions coincide. In the process, we\nclassify classes of skew $(f,\\sigma,\\delta)$-polycyclic codes with the same\nperformance parameters, to avoid duplicating already existing codes.\n  We exploit that the generator of a skew polycyclic code is in one-one\ncorrespondence with the generator of a principal left ideal in its ambient\nalgebra. Algebra isomorphisms that preserve the Hamming distance (called\nisometries) map generators of principal left ideals to generators of principal\nleft ideals and preserve length, dimension and Hamming distance of the codes.\nWe allow the ambient algebras to be nonassociative, thus eliminating the need\non restrictions on the length of the codes. The isometries between the ambient\nalgebras can also be used to classify corresponding linear codes equipped with\nthe rank metric.", "published": "2025-08-13 19:03:11", "link": "http://arxiv.org/abs/2508.10139v1", "categories": ["cs.IT", "math.IT", "math.RA"], "primary_category": "cs.IT"}
{"title": "REALISM: A Regulatory Framework for Coordinated Scheduling in Multi-Operator Shared Micromobility Services", "abstract": "Shared micromobility (e.g., shared bikes and electric scooters), as a kind of\nemerging urban transportation, has become more and more popular in the world.\nHowever, the blooming of shared micromobility vehicles brings some social\nproblems to the city (e.g., overloaded vehicles on roads, and the inequity of\nvehicle deployment), which deviate from the city regulator's expectation of the\nservice of the shared micromobility system. In addition, the multi-operator\nshared micromobility system in a city complicates the problem because of their\nnon-cooperative self-interested pursuits. Existing regulatory frameworks of\nmulti-operator vehicle rebalancing generally assume the intrusive control of\nvehicle rebalancing of all the operators, which is not practical in the real\nworld. To address this limitation, we design REALISM, a regulatory framework\nfor coordinated scheduling in multi-operator shared micromobility services that\nincorporates the city regulator's regulations in the form of assigning a score\nto each operator according to the city goal achievements and operators'\nindividual contributions to achieving the city goal, measured by Shapley value.\nTo realize the fairness-aware score assignment, we measure the fairness of\nassigned scores and use them as one of the components to optimize the score\nassignment model. To optimize the whole framework, we develop an alternating\nprocedure to make operators and the city regulator interact with each other\nuntil convergence. We evaluate our framework based on real-world e-scooter\nusage data in Chicago. Our experiment results show that our method achieves a\nperformance gain of at least 39.93% in the equity of vehicle usage and 1.82% in\nthe average demand satisfaction of the whole city.", "published": "2025-08-13 20:01:00", "link": "http://arxiv.org/abs/2508.10166v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "FPT-Approximability of Stable Matching Problems", "abstract": "We study parameterized approximability of three optimization problems related\nto stable matching: (1) Min-BP-SMI: Given a stable marriage instance and a\nnumber k, find a size-at-least-k matching that minimizes the number $\\beta$ of\nblocking pairs; (2) Min-BP-SRI: Given a stable roommates instance, find a\nmatching that minimizes the number $\\beta$ of blocking pairs; (3) Max-SMTI:\nGiven a stable marriage instance with preferences containing ties, find a\nmaximum-size stable matching.\n  The first two problems are known to be NP-hard to approximate to any constant\nfactor and W[1]-hard with respect to $\\beta$, making the existence of an EPTAS\nor FPT-algorithms unlikely. We show that they are W[1]-hard with respect to\n$\\beta$ to approximate to any function of $\\beta$. This means that unless\nFPT=W[1], there is no FPT-approximation scheme for the parameter $\\beta$. The\nlast problem (Max-SMTI) is known to be NP-hard to approximate to factor-29/33\nand W[1]-hard with respect to the number of ties. We complement this and\npresent an FPT-approximation scheme for the parameter \"number of agents with\nties\".", "published": "2025-08-13 18:48:43", "link": "http://arxiv.org/abs/2508.10129v1", "categories": ["cs.GT", "cs.MA"], "primary_category": "cs.GT"}
{"title": "Mixed-Precision Performance Portability of FFT-Based GPU-Accelerated Algorithms for Block-Triangular Toeplitz Matrices", "abstract": "The hardware diversity displayed in leadership-class computing facilities,\nalongside the immense performance boosts exhibited by today's GPUs when\ncomputing in lower precision, provide a strong incentive for scientific HPC\nworkflows to adopt mixed-precision algorithms and performance portability\nmodels. We present an on-the-fly framework using Hipify for performance\nportability and apply it to FFTMatvec-an HPC application that computes\nmatrix-vector products with block-triangular Toeplitz matrices. Our approach\nenables FFTMatvec, initially a CUDA-only application, to run seamlessly on AMD\nGPUs with excellent observed performance. Performance optimizations for AMD\nGPUs are integrated directly into the open-source rocBLAS library, keeping the\napplication code unchanged. We then present a dynamic mixed-precision framework\nfor FFTMatvec; a Pareto front analysis determines the optimal mixed-precision\nconfiguration for a desired error tolerance. Results are shown for AMD Instinct\nMI250X, MI300X, and the newly launched MI355X GPUs. The performance-portable,\nmixed-precision FFTMatvec is scaled to 2,048 GPUs on the OLCF Frontier\nsupercomputer.", "published": "2025-08-13 21:29:26", "link": "http://arxiv.org/abs/2508.10202v1", "categories": ["cs.DC", "cs.NA", "cs.PF", "math.NA", "65Y20, 65Y05, 65Y10, 68Q25, 68W40, 65M32, 5B05", "F.2; G.4; C.4"], "primary_category": "cs.DC"}
{"title": "A Generalized Alternating Anderson Acceleration Method", "abstract": "In this work, we propose a generalized alternating Anderson acceleration\nmethod, a periodic scheme composed of $t$ fixed-point iteration steps,\ninterleaved with $s$ steps of Anderson acceleration with window size $m$, to\nsolve linear and nonlinear problems. This allows flexibility to use different\ncombinations of fixed-point iteration and Anderson iteration. We present a\nconvergence analysis of the proposed scheme for accelerating the Richardson\niteration in the linear case, with a focus on specific parameter choices of\ninterest. Specifically, we prove convergence of the proposed method under\ncontractive fixed-point iteration and provide a sufficient condition for\nconvergence when the Richardson iteration matrix is diagonalizable and\nnoncontractive. To demonstrate the broader applicability of our proposed\nmethod, we use it to accelerate Jacobi iteration, Picard iteration, gradient\ndescent, and the alternating direction method of multipliers in solving partial\ndifferential equations and nonlinear, nonsmooth optimization problems. The\nnumerical results illustrate that the proposed scheme is more efficient than\nthe existing windowed Anderson acceleration and alternating Anderson ($s=1$) in\nterms of iteration number and CPU time for careful choice of parameters $m, s,\nt$.", "published": "2025-08-13 19:45:11", "link": "http://arxiv.org/abs/2508.10158v1", "categories": ["math.NA", "cs.NA", "65F10, 65H10, 65K10"], "primary_category": "math.NA"}
{"title": "A tensor-based dynamic mode decomposition based on the $\\star_{\\boldsymbol{M}}$-product", "abstract": "Dynamic mode decomposition (DMD) is a data-driven method for estimating the\ndynamics of a discrete dynamical system. This paper proposes a tensor-based\napproach to DMD for applications in which the states can be viewed as tensors.\nSpecifically, we use the $\\star_{\\boldsymbol{M}}$-product framework for tensor\ndecompositions which we demonstrate offers excellent compression compared to\nmatrix-based methods and can be implemented in a computationally efficient\nmanner. We show how the proposed approach is connected to the traditional DMD\nand physics-informed DMD frameworks. We give a computational framework for\ncomputing the tensor-based DMD and detail the computational costs. We also give\na randomized algorithm that enables efficient $\\star_{\\boldsymbol{M}}$-DMD\ncomputations in the streaming setting. The numerical results show that the\nproposed method achieves equal or better accuracy for the same storage compared\nto the standard DMD on these examples and is more efficient to compute.", "published": "2025-08-13 18:42:45", "link": "http://arxiv.org/abs/2508.10126v1", "categories": ["math.NA", "cs.NA", "15A69, 65F99, 93B30"], "primary_category": "math.NA"}
{"title": "Concepts for Composing Finite Element Function Space Bases", "abstract": "Finite Element discretizations of coupled multi-physics partial differential\nequation models require the handling of composed function spaces. In this paper\nwe discuss software concepts and abstractions to handle the composition of\nfunction spaces, based on a representation of product spaces as trees of\nsimpler bases. From this description, many different numberings of degrees of\nfreedom by multi-indices can be derived in a natural way, allowing to adapt the\nfunction spaces to very different data layouts, so that it opens the\npossibility to directly use the finite element code with very different linear\nalgebra codes, different data structures, and different algebraic solvers.\n  A recurring example throughout the paper is the stationary Stokes equation\nwith Taylor--Hood elements as these are naturally formulated as product spaces\nand highlight why different storage patterns are desirable.\n  In the second half of the paper we discuss a particular realization of most\nof these concepts in the \\dunemodule{dune-functions} module, as part of the\nDUNE ecosystem.", "published": "2025-08-13 18:40:07", "link": "http://arxiv.org/abs/2508.10125v1", "categories": ["cs.MS", "cs.NA", "math.NA", "68U20, 65N30, 65N08", "G.4; G.1.8"], "primary_category": "cs.MS"}
{"title": "CATNet: A geometric deep learning approach for CAT bond spread prediction in the primary market", "abstract": "Traditional models for pricing catastrophe (CAT) bonds struggle to capture\nthe complex, relational data inherent in these instruments. This paper\nintroduces CATNet, a novel framework that applies a geometric deep learning\narchitecture, the Relational Graph Convolutional Network (R-GCN), to model the\nCAT bond primary market as a graph, leveraging its underlying network structure\nfor spread prediction. Our analysis reveals that the CAT bond market exhibits\nthe characteristics of a scale-free network, a structure dominated by a few\nhighly connected and influential hubs. CATNet demonstrates high predictive\nperformance, significantly outperforming a strong Random Forest benchmark. The\ninclusion of topological centrality measures as features provides a further,\nsignificant boost in accuracy. Interpretability analysis confirms that these\nnetwork features are not mere statistical artifacts; they are quantitative\nproxies for long-held industry intuition regarding issuer reputation,\nunderwriter influence, and peril concentration. This research provides evidence\nthat network connectivity is a key determinant of price, offering a new\nparadigm for risk assessment and proving that graph-based models can deliver\nboth state-of-the-art accuracy and deeper, quantifiable market insights.", "published": "2025-08-13 21:38:25", "link": "http://arxiv.org/abs/2508.10208v1", "categories": ["q-fin.PR", "cs.AI", "cs.LG", "q-fin.CP", "q-fin.RM"], "primary_category": "q-fin.PR"}
{"title": "Prompt-Response Semantic Divergence Metrics for Faithfulness Hallucination and Misalignment Detection in Large Language Models", "abstract": "The proliferation of Large Language Models (LLMs) is challenged by\nhallucinations, critical failure modes where models generate non-factual,\nnonsensical or unfaithful text. This paper introduces Semantic Divergence\nMetrics (SDM), a novel lightweight framework for detecting Faithfulness\nHallucinations -- events of severe deviations of LLMs responses from input\ncontexts. We focus on a specific implementation of these LLM errors,\n{confabulations, defined as responses that are arbitrary and semantically\nmisaligned with the user's query. Existing methods like Semantic Entropy test\nfor arbitrariness by measuring the diversity of answers to a single, fixed\nprompt. Our SDM framework improves upon this by being more prompt-aware: we\ntest for a deeper form of arbitrariness by measuring response consistency not\nonly across multiple answers but also across multiple, semantically-equivalent\nparaphrases of the original prompt. Methodologically, our approach uses joint\nclustering on sentence embeddings to create a shared topic space for prompts\nand answers. A heatmap of topic co-occurances between prompts and responses can\nbe viewed as a quantified two-dimensional visualization of the user-machine\ndialogue. We then compute a suite of information-theoretic metrics to measure\nthe semantic divergence between prompts and responses. Our practical score,\n$\\mathcal{S}_H$, combines the Jensen-Shannon divergence and Wasserstein\ndistance to quantify this divergence, with a high score indicating a\nFaithfulness hallucination. Furthermore, we identify the KL divergence\nKL(Answer $||$ Prompt) as a powerful indicator of \\textbf{Semantic\nExploration}, a key signal for distinguishing different generative behaviors.\nThese metrics are further combined into the Semantic Box, a diagnostic\nframework for classifying LLM response types, including the dangerous,\nconfident confabulation.", "published": "2025-08-13 20:55:26", "link": "http://arxiv.org/abs/2508.10192v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "q-fin.CP"], "primary_category": "cs.CL"}
{"title": "Uniqueness and Existence of Linear Equilibrium with a Constrained Trader", "abstract": "We study a discrete-time financial market with a single constrained trader,\ncompetitive market makers, and noise traders. Within the class of linear\nequilibria, the equilibrium structure is shown to be uniquely determined by two\nstate variables: the market maker's expectation of the trader's remaining\ndemand and the residual demand beyond this expectation. This discrete-time\nuniqueness result aligns with its continuous-time analogue, indicating that the\nlatter may emerge as the unique limit within the same class. We also prove the\nexistence of a linear equilibrium, providing formal support to numerical and\nempirical findings in related work.", "published": "2025-08-13 19:02:08", "link": "http://arxiv.org/abs/2508.10138v1", "categories": ["q-fin.MF", "91B26, 91G80, 91A80"], "primary_category": "q-fin.MF"}
{"title": "Information Retention in Iterative Random Projection of Convex Bodies to Lower Dimensions", "abstract": "In this paper, we consider a bounded convex body $K_0 \\subset \\mathbb{R}^{n}$\nsubjected to two successive random orthogonal projections onto\n$\\mathbb{R}^{n-1}$ and $\\mathbb{R}^{n-2}$, respectively. First, we project\n$K_0$ orthogonally onto $U_{1}^{\\perp}$, the orthogonal complement of\n$\\mbox{\\boldmath $U$}_1$, where $\\mbox{\\boldmath $U$}_1$ is uniformly\ndistributed on the unit sphere $S^{n-1}$. This yields a random convex body $K_1\n= \\mathrm{Proj}_{{U_1}^{\\perp}}(K_0) \\subset \\mathbb{R}^{n-1}$. We then repeat\nthe process, projecting $K_1$ orthogonally onto ${U}_{2}^{\\perp}$, the\northogonal complement of $\\mbox{\\boldmath $U$}_2$ chosen uniformly from the\nunit sphere in $\\mbox{\\boldmath $U$}_{1}^{\\perp}$ or $S^{n-2}$, resulting in a\nsecond random convex body $K_2 = \\mathrm{Proj}_{{U_2}^{\\perp}}(K_1) \\subset\n\\mathbb{R}^{n-2}$. To quantify information retention through these sequential\ndimension reductions, we derive an upper bound for the conditional mutual\ninformation $I(K_1;K_2 \\mid K_0)$. Furthermore, we extend this process to $m$\niterations and generalize the upper bound on $I(K_1;K_2 \\mid K_0)$ to establish\nan analogous upper bound for $I(K_1;K_m \\mid K_0)$. Finally, we examine the\ninfluence of $K_0$'s symmetry on the achievability of this upper bound for\n$I(K_1;K_m \\mid K_0)$.", "published": "2025-08-13 22:08:58", "link": "http://arxiv.org/abs/2508.10218v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "MIMOSA: Multi-parametric Imaging using Multiple-echoes with Optimized Simultaneous Acquisition for highly-efficient quantitative MRI", "abstract": "Purpose: To develop a new sequence, MIMOSA, for highly-efficient T1, T2, T2*,\nproton density (PD), and source separation quantitative susceptibility mapping\n(QSM). Methods: MIMOSA was developed based on 3D-quantification using an\ninterleaved Look-Locker acquisition sequence with T2 preparation pulse\n(3D-QALAS) by combining 3D turbo Fast Low Angle Shot (FLASH) and multi-echo\ngradient echo acquisition modules with a spiral-like Cartesian trajectory to\nfacilitate highly-efficient acquisition. Simulations were performed to optimize\nthe sequence. Multi-contrast/-slice zero-shot self-supervised learning\nalgorithm was employed for reconstruction. The accuracy of quantitative mapping\nwas assessed by comparing MIMOSA with 3D-QALAS and reference techniques in both\nISMRM/NIST phantom and in-vivo experiments. MIMOSA's acceleration capability\nwas assessed at R = 3.3, 6.5, and 11.8 in in-vivo experiments, with\nrepeatability assessed through scan-rescan studies. Beyond the 3T experiments,\nmesoscale quantitative mapping was performed at 750 um isotropic resolution at\n7T. Results: Simulations demonstrated that MIMOSA achieved improved parameter\nestimation accuracy compared to 3D-QALAS. Phantom experiments indicated that\nMIMOSA exhibited better agreement with the reference techniques than 3D-QALAS.\nIn-vivo experiments demonstrated that an acceleration factor of up to R =\n11.8-fold can be achieved while preserving parameter estimation accuracy, with\nintra-class correlation coefficients of 0.998 (T1), 0.973 (T2), 0.947 (T2*),\n0.992 (QSM), 0.987 (paramagnetic susceptibility), and 0.977 (diamagnetic\nsusceptibility) in scan-rescan studies. Whole-brain T1, T2, T2*, PD, source\nseparation QSM were obtained with 1 mm isotropic resolution in 3 min at 3T and\n750 um isotropic resolution in 13 min at 7T. Conclusion: MIMOSA demonstrated\npotential for highly-efficient multi-parametric mapping.", "published": "2025-08-13 20:38:50", "link": "http://arxiv.org/abs/2508.10184v1", "categories": ["physics.med-ph", "eess.IV", "eess.SP"], "primary_category": "physics.med-ph"}
{"title": "Personalized Real-time Jargon Support for Online Meetings", "abstract": "Effective interdisciplinary communication is frequently hindered by\ndomain-specific jargon. To explore the jargon barriers in-depth, we conducted a\nformative diary study with 16 professionals, revealing critical limitations in\ncurrent jargon-management strategies during workplace meetings. Based on these\ninsights, we designed ParseJargon, an interactive LLM-powered system providing\nreal-time personalized jargon identification and explanations tailored to\nusers' individual backgrounds. A controlled experiment comparing ParseJargon\nagainst baseline (no support) and general-purpose (non-personalized) conditions\ndemonstrated that personalized jargon support significantly enhanced\nparticipants' comprehension, engagement, and appreciation of colleagues' work,\nwhereas general-purpose support negatively affected engagement. A follow-up\nfield study validated ParseJargon's usability and practical value in real-time\nmeetings, highlighting both opportunities and limitations for real-world\ndeployment. Our findings contribute insights into designing personalized jargon\nsupport tools, with implications for broader interdisciplinary and educational\napplications.", "published": "2025-08-13 23:42:12", "link": "http://arxiv.org/abs/2508.10239v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Using Large Language Models to Measure Symptom Severity in Patients At Risk for Schizophrenia", "abstract": "Patients who are at clinical high risk (CHR) for schizophrenia need close\nmonitoring of their symptoms to inform appropriate treatments. The Brief\nPsychiatric Rating Scale (BPRS) is a validated, commonly used research tool for\nmeasuring symptoms in patients with schizophrenia and other psychotic\ndisorders; however, it is not commonly used in clinical practice as it requires\na lengthy structured interview. Here, we utilize large language models (LLMs)\nto predict BPRS scores from clinical interview transcripts in 409 CHR patients\nfrom the Accelerating Medicines Partnership Schizophrenia (AMP-SCZ) cohort.\nDespite the interviews not being specifically structured to measure the BPRS,\nthe zero-shot performance of the LLM predictions compared to the true\nassessment (median concordance: 0.84, ICC: 0.73) approaches human inter- and\nintra-rater reliability. We further demonstrate that LLMs have substantial\npotential to improve and standardize the assessment of CHR patients via their\naccuracy in assessing the BPRS in foreign languages (median concordance: 0.88,\nICC: 0.70), and integrating longitudinal information in a one-shot or few-shot\nlearning approach.", "published": "2025-08-13 22:47:01", "link": "http://arxiv.org/abs/2508.10226v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Understanding Textual Emotion Through Emoji Prediction", "abstract": "This project explores emoji prediction from short text sequences using four\ndeep learning architectures: a feed-forward network, CNN, transformer, and\nBERT. Using the TweetEval dataset, we address class imbalance through focal\nloss and regularization techniques. Results show BERT achieves the highest\noverall performance due to its pre-training advantage, while CNN demonstrates\nsuperior efficacy on rare emoji classes. This research shows the importance of\narchitecture selection and hyperparameter tuning for sentiment-aware emoji\nprediction, contributing to improved human-computer interaction.", "published": "2025-08-13 22:17:00", "link": "http://arxiv.org/abs/2508.10222v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "PakBBQ: A Culturally Adapted Bias Benchmark for QA", "abstract": "With the widespread adoption of Large Language Models (LLMs) across various\napplications, it is empirical to ensure their fairness across all user\ncommunities. However, most LLMs are trained and evaluated on Western centric\ndata, with little attention paid to low-resource languages and regional\ncontexts. To address this gap, we introduce PakBBQ, a culturally and regionally\nadapted extension of the original Bias Benchmark for Question Answering (BBQ)\ndataset. PakBBQ comprises over 214 templates, 17180 QA pairs across 8\ncategories in both English and Urdu, covering eight bias dimensions including\nage, disability, appearance, gender, socio-economic status, religious, regional\naffiliation, and language formality that are relevant in Pakistan. We evaluate\nmultiple multilingual LLMs under both ambiguous and explicitly disambiguated\ncontexts, as well as negative versus non negative question framings. Our\nexperiments reveal (i) an average accuracy gain of 12\\% with disambiguation,\n(ii) consistently stronger counter bias behaviors in Urdu than in English, and\n(iii) marked framing effects that reduce stereotypical responses when questions\nare posed negatively. These findings highlight the importance of contextualized\nbenchmarks and simple prompt engineering strategies for bias mitigation in low\nresource settings.", "published": "2025-08-13 20:42:44", "link": "http://arxiv.org/abs/2508.10186v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Efficient Forward-Only Data Valuation for Pretrained LLMs and VLMs", "abstract": "Quantifying the influence of individual training samples is essential for\nenhancing the transparency and accountability of large language models (LLMs)\nand vision-language models (VLMs). However, existing data valuation methods\noften rely on Hessian information or model retraining, making them\ncomputationally prohibitive for billion-parameter models. In this work, we\nintroduce For-Value, a forward-only data valuation framework that enables\nscalable and efficient influence estimation for both LLMs and VLMs. By\nleveraging the rich representations of modern foundation models, For-Value\ncomputes influence scores using a simple closed-form expression based solely on\na single forward pass, thereby eliminating the need for costly gradient\ncomputations. Our theoretical analysis demonstrates that For-Value accurately\nestimates per-sample influence by capturing alignment in hidden representations\nand prediction errors between training and validation samples. Extensive\nexperiments show that For-Value matches or outperforms gradient-based baselines\nin identifying impactful fine-tuning examples and effectively detecting\nmislabeled data.", "published": "2025-08-13 20:33:06", "link": "http://arxiv.org/abs/2508.10180v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Estimating Machine Translation Difficulty", "abstract": "Machine translation quality has began achieving near-perfect translations in\nsome setups. These high-quality outputs make it difficult to distinguish\nbetween state-of-the-art models and to identify areas for future improvement.\nAutomatically identifying texts where machine translation systems struggle\nholds promise for developing more discriminative evaluations and guiding future\nresearch.\n  We formalize the task of translation difficulty estimation, defining a text's\ndifficulty based on the expected quality of its translations. We introduce a\nnew metric to evaluate difficulty estimators and use it to assess both\nbaselines and novel approaches. Finally, we demonstrate the practical utility\nof difficulty estimators by using them to construct more challenging machine\ntranslation benchmarks. Our results show that dedicated models (dubbed\nSentinel-src) outperform both heuristic-based methods (e.g. word rarity or\nsyntactic complexity) and LLM-as-a-judge approaches. We release two improved\nmodels for difficulty estimation, Sentinel-src-24 and Sentinel-src-25, which\ncan be used to scan large collections of texts and select those most likely to\nchallenge contemporary machine translation systems.", "published": "2025-08-13 20:22:58", "link": "http://arxiv.org/abs/2508.10175v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LaajMeter: A Framework for LaaJ Evaluation", "abstract": "Large Language Models (LLMs) are increasingly used as evaluators in natural\nlanguage processing tasks, a paradigm known as LLM-as-a-Judge (LaaJ). While\neffective in general domains, LaaJs pose significant challenges in\ndomain-specific contexts, where annotated data is scarce and expert evaluation\nis costly. In such cases, meta-evaluation is often performed using metrics that\nhave not been validated for the specific domain in which they are applied. As a\nresult, it becomes difficult to determine which metrics effectively identify\nLaaJ quality, and further, what threshold indicates sufficient evaluator\nperformance. In this work, we introduce LaaJMeter, a simulation-based framework\nfor controlled meta-evaluation of LaaJs. LaaJMeter enables engineers to\ngenerate synthetic data representing virtual models and judges, allowing\nsystematic analysis of evaluation metrics under realistic conditions. This\nhelps practitioners validate and refine LaaJs for specific evaluation tasks:\nthey can test whether their metrics correctly distinguish between better and\nworse (virtual) LaaJs, and estimate appropriate thresholds for evaluator\nadequacy.\n  We demonstrate the utility of LaaJMeter in a code translation task involving\na legacy programming language, showing how different metrics vary in\nsensitivity to evaluator quality. Our results highlight the limitations of\ncommon metrics and the importance of principled metric selection. LaaJMeter\nprovides a scalable and extensible solution for assessing LaaJs in low-resource\nsettings, contributing to the broader effort to ensure trustworthy and\nreproducible evaluation in NLP.", "published": "2025-08-13 19:51:05", "link": "http://arxiv.org/abs/2508.10161v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multi-Turn Puzzles: Evaluating Interactive Reasoning and Strategic Dialogue in LLMs", "abstract": "Large language models (LLMs) excel at solving problems with clear and\ncomplete statements, but often struggle with nuanced environments or\ninteractive tasks which are common in most real-world scenarios. This\nhighlights the critical need for developing LLMs that can effectively engage in\nlogically consistent multi-turn dialogue, seek information and reason with\nincomplete data. To this end, we introduce a novel benchmark comprising a suite\nof multi-turn tasks each designed to test specific reasoning, interactive\ndialogue, and information-seeking abilities. These tasks have deterministic\nscoring mechanisms, thus eliminating the need for human intervention.\nEvaluating frontier models on our benchmark reveals significant headroom. Our\nanalysis shows that most errors emerge from poor instruction following,\nreasoning failures, and poor planning. This benchmark provides valuable\ninsights into the strengths and weaknesses of current LLMs in handling complex,\ninteractive scenarios and offers a robust platform for future research aimed at\nimproving these critical capabilities.", "published": "2025-08-13 19:14:45", "link": "http://arxiv.org/abs/2508.10142v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "mSCoRe: a $M$ultilingual and Scalable Benchmark for $S$kill-based $Co$mmonsense $Re$asoning", "abstract": "Recent advancements in reasoning-reinforced Large Language Models (LLMs) have\nshown remarkable capabilities in complex reasoning tasks. However, the\nmechanism underlying their utilization of different human reasoning skills\nremains poorly investigated, especially for multilingual commonsense reasoning\nthat involves everyday knowledge across different languages and cultures. To\naddress this gap, we propose a \\textbf{M}ultilingual and Scalable Benchmark for\n\\textbf{S}kill-based \\textbf{Co}mmonsense \\textbf{Re}asoning (\\textbf{mSCoRe}).\nOur benchmark incorporates three key components that are designed to\nsystematically evaluate LLM's reasoning capabilities, including: (1) a novel\ntaxonomy of reasoning skills that enables fine-grained analysis of models'\nreasoning processes, (2) a robust data synthesis pipeline tailored specifically\nfor commonsense reasoning evaluation, and (3) a complexity scaling framework\nallowing task difficulty to scale dynamically alongside future improvements in\nLLM abilities. Extensive experiments on eights state-of-the-art LLMs of varying\nsizes and training approaches demonstrate that \\textbf{mSCoRe} remains\nsignificantly challenging for current models, particularly at higher complexity\nlevels. Our results reveal the limitations of such reasoning-reinforced models\nwhen confronted with nuanced multilingual general and cultural commonsense. We\nfurther provide detailed analysis on the models' reasoning processes,\nsuggesting future directions for improving multilingual commonsense reasoning\ncapabilities.", "published": "2025-08-13 18:59:02", "link": "http://arxiv.org/abs/2508.10137v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Nested-ReFT: Efficient Reinforcement Learning for Large Language Model Fine-Tuning via Off-Policy Rollouts", "abstract": "Advanced reasoning in LLMs on challenging domains like mathematical reasoning\ncan be tackled using verifiable rewards based reinforced fine-tuning (ReFT). In\nstandard ReFT frameworks, a behavior model generates multiple completions with\nanswers per problem, for the answer to be then scored by a reward function.\nWhile such RL post-training methods demonstrate significant performance\nimprovements across challenging reasoning domains, the computational cost of\ngenerating completions during training with multiple inference steps makes the\ntraining cost non-trivial. To address this, we draw inspiration from off-policy\nRL, and speculative decoding to introduce a novel ReFT framework, dubbed\nNested-ReFT, where a subset of layers of the target model acts as the behavior\nmodel to generate off-policy completions during training. The behavior model\nconfigured with dynamic layer skipping per batch during training decreases the\ninference cost compared to the standard ReFT frameworks. Our theoretical\nanalysis shows that Nested-ReFT yields unbiased gradient estimates with\ncontrolled variance. Our empirical analysis demonstrates improved computational\nefficiency measured as tokens/sec across multiple math reasoning benchmarks and\nmodel sizes. Additionally, we explore three variants of bias mitigation to\nminimize the off-policyness in the gradient updates that allows for maintaining\nperformance that matches the baseline ReFT performance.", "published": "2025-08-13 18:37:46", "link": "http://arxiv.org/abs/2508.10123v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Amazon Nova AI Challenge -- Trusted AI: Advancing secure, AI-assisted software development", "abstract": "AI systems for software development are rapidly gaining prominence, yet\nsignificant challenges remain in ensuring their safety. To address this, Amazon\nlaunched the Trusted AI track of the Amazon Nova AI Challenge, a global\ncompetition among 10 university teams to drive advances in secure AI. In the\nchallenge, five teams focus on developing automated red teaming bots, while the\nother five create safe AI assistants. This challenge provides teams with a\nunique platform to evaluate automated red-teaming and safety alignment methods\nthrough head-to-head adversarial tournaments where red teams have multi-turn\nconversations with the competing AI coding assistants to test their safety\nalignment. Along with this, the challenge provides teams with a feed of high\nquality annotated data to fuel iterative improvement. Throughout the challenge,\nteams developed state-of-the-art techniques, introducing novel approaches in\nreasoning-based safety alignment, robust model guardrails, multi-turn\njail-breaking, and efficient probing of large language models (LLMs). To\nsupport these efforts, the Amazon Nova AI Challenge team made substantial\nscientific and engineering investments, including building a custom baseline\ncoding specialist model for the challenge from scratch, developing a tournament\norchestration service, and creating an evaluation harness. This paper outlines\nthe advancements made by university teams and the Amazon Nova AI Challenge team\nin addressing the safety challenges of AI for software development,\nhighlighting this collaborative effort to raise the bar for AI safety.", "published": "2025-08-13 18:04:01", "link": "http://arxiv.org/abs/2508.10108v1", "categories": ["cs.AI", "cs.CL", "I.2.7; I.2.6; E.0"], "primary_category": "cs.AI"}
{"title": "SaraCoder: Orchestrating Semantic and Structural Cues for Profit-Oriented Repository-Level Code Completion", "abstract": "Retrieval-augmented generation (RAG) for repository-level code completion\ncommonly relies on superficial text similarity, leading to results plagued by\nsemantic misguidance, redundancy, and homogeneity, while also failing to\nresolve external symbol ambiguity. To address these challenges, we introduce\nSaracoder, a Hierarchical Feature-Optimized retrieval framework. Its core\nHierarchical Feature Optimization module systematically refines candidates by\ndistilling deep semantic relationships, pruning exact duplicates, assessing\nstructural similarity with a novel graph-based metric that weighs edits by\ntheir topological importance, and reranking results to maximize both relevance\nand diversity. Furthermore, an External-Aware Identifier Disambiguator module\naccurately resolves cross-file symbol ambiguity via dependency analysis.\nExtensive experiments on the challenging CrossCodeEval and RepoEval-Updated\nbenchmarks demonstrate that Saracoder significantly outperforms existing\nbaselines across multiple programming languages and models. Our work proves\nthat systematically refining retrieval results across multiple dimensions\nprovides a new paradigm for building more accurate and robust repository-level\ncode completion systems.", "published": "2025-08-13 11:56:05", "link": "http://arxiv.org/abs/2508.10068v1", "categories": ["cs.SE", "cs.CL", "cs.IR", "cs.PL"], "primary_category": "cs.SE"}
{"title": "Extending the Entropic Potential of Events for Uncertainty Quantification and Decision-Making in Artificial Intelligence", "abstract": "This work demonstrates how the concept of the entropic potential of events --\na parameter quantifying the influence of discrete events on the expected future\nentropy of a system -- can enhance uncertainty quantification, decision-making,\nand interpretability in artificial intelligence (AI). Building on its original\nformulation in physics, the framework is adapted for AI by introducing an\nevent-centric measure that captures how actions, observations, or other\ndiscrete occurrences impact uncertainty at future time horizons. Both the\noriginal and AI-adjusted definitions of entropic potential are formalized, with\nthe latter emphasizing conditional expectations to account for counterfactual\nscenarios. Applications are explored in policy evaluation, intrinsic reward\ndesign, explainable AI, and anomaly detection, highlighting the metric's\npotential to unify and strengthen uncertainty modeling in intelligent systems.\nConceptual examples illustrate its use in reinforcement learning, Bayesian\ninference, and anomaly detection, while practical considerations for\ncomputation in complex AI models are discussed. The entropic potential\nframework offers a theoretically grounded, interpretable, and versatile\napproach to managing uncertainty in AI, bridging principles from\nthermodynamics, information theory, and machine learning.", "published": "2025-08-13 23:52:12", "link": "http://arxiv.org/abs/2508.10241v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "No Free Lunch from Audio Pretraining in Bioacoustics: A Benchmark Study of Embeddings", "abstract": "Bioacoustics, the study of animal sounds, offers a non-invasive method to\nmonitor ecosystems. Extracting embeddings from audio-pretrained deep learning\n(DL) models without fine-tuning has become popular for obtaining bioacoustic\nfeatures for tasks. However, a recent benchmark study reveals that while\nfine-tuned audio-pretrained VGG and transformer models achieve state-of-the-art\nperformance in some tasks, they fail in others. This study benchmarks 11 DL\nmodels on the same tasks by reducing their learned embeddings' dimensionality\nand evaluating them through clustering. We found that audio-pretrained DL\nmodels 1) without fine-tuning even underperform fine-tuned AlexNet, 2) both\nwith and without fine-tuning fail to separate the background from labeled\nsounds, but ResNet does, and 3) outperform other models when fewer background\nsounds are included during fine-tuning. This study underscores the necessity of\nfine-tuning audio-pretrained models and checking the embeddings after\nfine-tuning. Our codes are available:\nhttps://github.com/NeuroscienceAI/Audio\\_Embeddings", "published": "2025-08-13 22:58:28", "link": "http://arxiv.org/abs/2508.10230v1", "categories": ["cs.SD", "cs.AI"], "primary_category": "cs.SD"}
{"title": "An Explainable AI based approach for Monitoring Animal Health", "abstract": "Monitoring cattle health and optimizing yield are key challenges faced by\ndairy farmers due to difficulties in tracking all animals on the farm. This\nwork aims to showcase modern data-driven farming practices based on explainable\nmachine learning(ML) methods that explain the activity and behaviour of dairy\ncattle (cows). Continuous data collection of 3-axis accelerometer sensors and\nusage of robust ML methodologies and algorithms, provide farmers and\nresearchers with actionable information on cattle activity, allowing farmers to\nmake informed decisions and incorporate sustainable practices. This study\nutilizes Bluetooth-based Internet of Things (IoT) devices and 4G networks for\nseamless data transmission, immediate analysis, inference generation, and\nexplains the models performance with explainability frameworks. Special\nemphasis is put on the pre-processing of the accelerometers time series data,\nincluding the extraction of statistical characteristics, signal processing\ntechniques, and lag-based features using the sliding window technique. Various\nhyperparameter-optimized ML models are evaluated across varying window lengths\nfor activity classification. The k-nearest neighbour Classifier achieved the\nbest performance, with AUC of mean 0.98 and standard deviation of 0.0026 on the\ntraining set and 0.99 on testing set). In order to ensure transparency,\nExplainable AI based frameworks such as SHAP is used to interpret feature\nimportance that can be understood and used by practitioners. A detailed\ncomparison of the important features, along with the stability analysis of\nselected features, supports development of explainable and practical ML models\nfor sustainable livestock management.", "published": "2025-08-13 21:40:35", "link": "http://arxiv.org/abs/2508.10210v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "KompeteAI: Accelerated Autonomous Multi-Agent System for End-to-End Pipeline Generation for Machine Learning Problems", "abstract": "Recent Large Language Model (LLM)-based AutoML systems demonstrate impressive\ncapabilities but face significant limitations such as constrained exploration\nstrategies and a severe execution bottleneck. Exploration is hindered by\none-shot methods lacking diversity and Monte Carlo Tree Search (MCTS)\napproaches that fail to recombine strong partial solutions. The execution\nbottleneck arises from lengthy code validation cycles that stifle iterative\nrefinement. To overcome these challenges, we introduce KompeteAI, a novel\nAutoML framework with dynamic solution space exploration. Unlike previous MCTS\nmethods that treat ideas in isolation, KompeteAI introduces a merging stage\nthat composes top candidates. We further expand the hypothesis space by\nintegrating Retrieval-Augmented Generation (RAG), sourcing ideas from Kaggle\nnotebooks and arXiv papers to incorporate real-world strategies. KompeteAI also\naddresses the execution bottleneck via a predictive scoring model and an\naccelerated debugging method, assessing solution potential using early stage\nmetrics to avoid costly full-code execution. This approach accelerates pipeline\nevaluation 6.9 times. KompeteAI outperforms leading methods (e.g., RD-agent,\nAIDE, and Ml-Master) by an average of 3\\% on the primary AutoML benchmark,\nMLE-Bench. Additionally, we propose Kompete-bench to address limitations in\nMLE-Bench, where KompeteAI also achieves state-of-the-art results", "published": "2025-08-13 20:29:56", "link": "http://arxiv.org/abs/2508.10177v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "DS4RS: Community-Driven and Explainable Dataset Search Engine for Recommender System Research", "abstract": "Accessing suitable datasets is critical for research and development in\nrecommender systems. However, finding datasets that match specific\nrecommendation task or domains remains a challenge due to scattered sources and\ninconsistent metadata. To address this gap, we propose a community-driven and\nexplainable dataset search engine tailored for recommender system research. Our\nsystem supports semantic search across multiple dataset attributes, such as\ndataset names, descriptions, and recommendation domain, and provides\nexplanations of search relevance to enhance transparency. The system encourages\ncommunity participation by allowing users to contribute standardized dataset\nmetadata in public repository. By improving dataset discoverability and search\ninterpretability, the system facilitates more efficient research reproduction.\nThe platform is publicly available at: https://ds4rs.com.", "published": "2025-08-13 23:37:55", "link": "http://arxiv.org/abs/2508.10238v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Bridging Modality Gaps in e-Commerce Products via Vision-Language Alignment", "abstract": "Item information, such as titles and attributes, is essential for effective\nuser engagement in e-commerce. However, manual or semi-manual entry of\nstructured item specifics often produces inconsistent quality, errors, and slow\nturnaround, especially for Customer-to-Customer sellers. Generating accurate\ndescriptions directly from item images offers a promising alternative. Existing\nretrieval-based solutions address some of these issues but often miss\nfine-grained visual details and struggle with niche or specialized categories.\n  We propose Optimized Preference-Based AI for Listings (OPAL), a framework for\ngenerating schema-compliant, high-quality item descriptions from images using a\nfine-tuned multimodal large language model (MLLM). OPAL addresses key\nchallenges in multimodal e-commerce applications, including bridging modality\ngaps and capturing detailed contextual information. It introduces two data\nrefinement methods: MLLM-Assisted Conformity Enhancement, which ensures\nalignment with structured schema requirements, and LLM-Assisted Contextual\nUnderstanding, which improves the capture of nuanced and fine-grained\ninformation from visual inputs.\n  OPAL uses visual instruction tuning combined with direct preference\noptimization to fine-tune the MLLM, reducing hallucinations and improving\nrobustness across different backbone architectures. We evaluate OPAL on\nreal-world e-commerce datasets, showing that it consistently outperforms\nbaseline methods in both description quality and schema completion rates. These\nresults demonstrate that OPAL effectively bridges the gap between visual and\ntextual modalities, delivering richer, more accurate, and more consistent item\ndescriptions. This work advances automated listing optimization and supports\nscalable, high-quality content generation in e-commerce platforms.", "published": "2025-08-13 18:22:53", "link": "http://arxiv.org/abs/2508.10116v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Can Transformers Break Encryption Schemes via In-Context Learning?", "abstract": "In-context learning (ICL) has emerged as a powerful capability of\ntransformer-based language models, enabling them to perform tasks by\nconditioning on a small number of examples presented at inference time, without\nany parameter updates. Prior work has shown that transformers can generalize\nover simple function classes like linear functions, decision trees, even neural\nnetworks, purely from context, focusing on numerical or symbolic reasoning over\nunderlying well-structured functions. Instead, we propose a novel application\nof ICL into the domain of cryptographic function learning, specifically\nfocusing on ciphers such as mono-alphabetic substitution and Vigen\\`ere\nciphers, two classes of private-key encryption schemes. These ciphers involve a\nfixed but hidden bijective mapping between plain text and cipher text\ncharacters. Given a small set of (cipher text, plain text) pairs, the goal is\nfor the model to infer the underlying substitution and decode a new cipher text\nword. This setting poses a structured inference challenge, which is well-suited\nfor evaluating the inductive biases and generalization capabilities of\ntransformers under the ICL paradigm. Code is available at\nhttps://github.com/adistomar/CS182-project.", "published": "2025-08-13 23:09:32", "link": "http://arxiv.org/abs/2508.10235v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Interpretable Machine Learning Model for Early Prediction of Acute Kidney Injury in Critically Ill Patients with Cirrhosis: A Retrospective Study", "abstract": "Background: Cirrhosis is a progressive liver disease with high mortality and\nfrequent complications, notably acute kidney injury (AKI), which occurs in up\nto 50% of hospitalized patients and worsens outcomes. AKI stems from complex\nhemodynamic, inflammatory, and metabolic changes, making early detection\nessential. Many predictive tools lack accuracy, interpretability, and alignment\nwith intensive care unit (ICU) workflows. This study developed an interpretable\nmachine learning model for early AKI prediction in critically ill patients with\ncirrhosis.\n  Methods: We conducted a retrospective analysis of the MIMIC-IV v2.2 database,\nidentifying 1240 adult ICU patients with cirrhosis and excluding those with ICU\nstays under 48 hours or missing key data. Laboratory and physiological\nvariables from the first 48 hours were extracted. The pipeline included\npreprocessing, missingness filtering, LASSO feature selection, and SMOTE class\nbalancing. Six algorithms-LightGBM, CatBoost, XGBoost, logistic regression,\nnaive Bayes, and neural networks-were trained and evaluated using AUROC,\naccuracy, F1-score, sensitivity, specificity, and predictive values.\n  Results: LightGBM achieved the best performance (AUROC 0.808, 95% CI\n0.741-0.856; accuracy 0.704; NPV 0.911). Key predictors included prolonged\npartial thromboplastin time, absence of outside-facility 20G placement, low pH,\nand altered pO2, consistent with known cirrhosis-AKI mechanisms and suggesting\nactionable targets.\n  Conclusion: The LightGBM-based model enables accurate early AKI risk\nstratification in ICU patients with cirrhosis using routine clinical variables.\nIts high negative predictive value supports safe de-escalation for low-risk\npatients, and interpretability fosters clinician trust and targeted prevention.\nExternal validation and integration into electronic health record systems are\nwarranted.", "published": "2025-08-13 23:03:28", "link": "http://arxiv.org/abs/2508.10233v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Comparison of D-Wave Quantum Annealing and Markov Chain Monte Carlo for Sampling from a Probability Distribution of a Restricted Boltzmann Machine", "abstract": "A local-valley (LV) centered approach to assessing the quality of sampling\nfrom Restricted Boltzmann Machines (RBMs) was applied to the latest generation\nof the D-Wave quantum annealer. D-Wave and Gibbs samples from a classically\ntrained RBM were obtained at conditions relevant to the\ncontrastive-divergence-based RBM learning. The samples were compared for the\nnumber of the LVs to which they belonged and the energy of the corresponding\nlocal minima. No significant (desirable) increase in the number of the LVs has\nbeen achieved by decreasing the D-Wave annealing time. At any training epoch,\nthe states sampled by the D-Wave belonged to a somewhat higher number of LVs\nthan in the Gibbs sampling. However, many of those LVs found by the two\ntechniques differed. For high-probability sampled states, the two techniques\nwere (unfavorably) less complementary and more overlapping. Nevertheless, many\npotentially \"important\" local minima, i.e., those having intermediate, even if\nnot high, probability values, were found by only one of the two sampling\ntechniques while missed by the other. The two techniques overlapped less at\nlater than earlier training epochs, which is precisely the stage of the\ntraining when modest improvements to the sampling quality could make meaningful\ndifferences for the RBM trainability. The results of this work may explain the\nfailure of previous investigations to achieve substantial (or any) improvement\nwhen using D-Wave-based sampling. However, the results reveal some potential\nfor improvement, e.g., using a combined classical-quantum approach.", "published": "2025-08-13 22:50:44", "link": "http://arxiv.org/abs/2508.10228v1", "categories": ["cs.LG", "quant-ph", "stat.ML"], "primary_category": "cs.LG"}
{"title": "AI-Driven Detection and Analysis of Handwriting on Seized Ivory: A Tool to Uncover Criminal Networks in the Illicit Wildlife Trade", "abstract": "The transnational ivory trade continues to drive the decline of elephant\npopulations across Africa, and trafficking networks remain difficult to\ndisrupt. Tusks seized by law enforcement officials carry forensic information\non the traffickers responsible for their export, including DNA evidence and\nhandwritten markings made by traffickers. For 20 years, analyses of tusk DNA\nhave identified where elephants were poached and established connections among\nshipments of ivory. While the links established using genetic evidence are\nextremely conclusive, genetic data is expensive and sometimes impossible to\nobtain. But though handwritten markings are easy to photograph, they are rarely\ndocumented or analyzed. Here, we present an AI-driven pipeline for extracting\nand analyzing handwritten markings on seized elephant tusks, offering a novel,\nscalable, and low-cost source of forensic evidence. Having collected 6,085\nphotographs from eight large seizures of ivory over a 6-year period\n(2014-2019), we used an object detection model to extract over 17,000\nindividual markings, which were then labeled and described using\nstate-of-the-art AI tools. We identified 184 recurring \"signature markings\"\nthat connect the tusks on which they appear. 20 signature markings were\nobserved in multiple seizures, establishing forensic links between these\nseizures through traffickers involved in both shipments. This work complements\nother investigative techniques by filling in gaps where other data sources are\nunavailable. The study demonstrates the transformative potential of AI in\nwildlife forensics and highlights practical steps for integrating handwriting\nanalysis into efforts to disrupt organized wildlife crime.", "published": "2025-08-13 22:10:42", "link": "http://arxiv.org/abs/2508.10219v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Mo' Memory, Mo' Problems: Stream-Native Machine Unlearning", "abstract": "Machine unlearning work assumes a static, i.i.d training environment that\ndoesn't truly exist. Modern ML pipelines need to learn, unlearn, and predict\ncontinuously on production streams of data. We translate the notion of the\nbatch unlearning scenario to the online setting using notions of regret, sample\ncomplexity, and deletion capacity. We further tighten regret bounds to a\nlogarithmic $\\mathcal{O}(\\ln{T})$, a first for a machine unlearning algorithm.\nAnd we swap out an expensive Hessian inversion with online variant of L-BFGS\noptimization, removing a memory footprint that scales linearly with time. Such\nchanges extend the lifespan of an ML model before expensive retraining, making\nfor a more efficient unlearning process.", "published": "2025-08-13 20:56:41", "link": "http://arxiv.org/abs/2508.10193v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Prediction-Powered Inference with Inverse Probability Weighting", "abstract": "Prediction-powered inference (PPI) is a recent framework for valid\nstatistical inference with partially labeled data, combining model-based\npredictions on a large unlabeled set with bias correction from a smaller\nlabeled subset. We show that PPI can be extended to handle informative labeling\nby replacing its unweighted bias-correction term with an inverse probability\nweighted (IPW) version, using the classical Horvitz--Thompson or H\\'ajek forms.\nThis connection unites design-based survey sampling ideas with modern\nprediction-assisted inference, yielding estimators that remain valid when\nlabeling probabilities vary across units. We consider the common setting where\nthe inclusion probabilities are not known but estimated from a correctly\nspecified model. In simulations, the performance of IPW-adjusted PPI with\nestimated propensities closely matches the known-probability case, retaining\nboth nominal coverage and the variance-reduction benefits of PPI.", "published": "2025-08-13 19:25:38", "link": "http://arxiv.org/abs/2508.10149v1", "categories": ["stat.ML", "cs.LG", "62D10, 62F10, 62-02"], "primary_category": "stat.ML"}
