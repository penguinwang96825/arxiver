{"title": "ECLAIR: Enhanced Clarification for Interactive Responses in an Enterprise AI Assistant", "abstract": "Large language models (LLMs) have shown remarkable progress in understanding\nand generating natural language across various applications. However, they\noften struggle with resolving ambiguities in real-world, enterprise-level\ninteractions, where context and domain-specific knowledge play a crucial role.\nIn this demonstration, we introduce ECLAIR (Enhanced CLArification for\nInteractive Responses), a multi-agent framework for interactive disambiguation.\nECLAIR enhances ambiguous user query clarification through an interactive\nprocess where custom agents are defined, ambiguity reasoning is conducted by\nthe agents, clarification questions are generated, and user feedback is\nleveraged to refine the final response. When tested on real-world customer\ndata, ECLAIR demonstrates significant improvements in clarification question\ngeneration compared to standard few-shot methods.", "published": "2025-03-19 23:13:34", "link": "http://arxiv.org/abs/2503.20791v1", "categories": ["cs.CL", "68T50", "I.2.7; H.5.2"], "primary_category": "cs.CL"}
{"title": "KoGNER: A Novel Framework for Knowledge Graph Distillation on Biomedical Named Entity Recognition", "abstract": "Named Entity Recognition (NER) is a fundamental task in Natural Language\nProcessing (NLP) that plays a crucial role in information extraction, question\nanswering, and knowledge-based systems. Traditional deep learning-based NER\nmodels often struggle with domain-specific generalization and suffer from data\nsparsity issues. In this work, we introduce Knowledge Graph distilled for Named\nEntity Recognition (KoGNER), a novel approach that integrates Knowledge Graph\n(KG) distillation into NER models to enhance entity recognition performance.\nOur framework leverages structured knowledge representations from KGs to enrich\ncontextual embeddings, thereby improving entity classification and reducing\nambiguity in entity detection. KoGNER employs a two-step process: (1) Knowledge\nDistillation, where external knowledge sources are distilled into a lightweight\nrepresentation for seamless integration with NER models, and (2) Entity-Aware\nAugmentation, which integrates contextual embeddings that have been enriched\nwith knowledge graph information directly into GNN, thereby improving the\nmodel's ability to understand and represent entity relationships. Experimental\nresults on benchmark datasets demonstrate that KoGNER achieves state-of-the-art\nperformance, outperforming finetuned NER models and LLMs by a significant\nmargin. These findings suggest that leveraging knowledge graphs as auxiliary\ninformation can significantly improve NER accuracy, making KoGNER a promising\ndirection for future research in knowledge-aware NLP.", "published": "2025-03-19 22:59:36", "link": "http://arxiv.org/abs/2503.15737v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ChatGPT or A Silent Everywhere Helper: A Survey of Large Language Models", "abstract": "Large Language Models (LLMs) have revo lutionized natural language processing\nNatural Language Processing (NLP), with Chat Generative Pre-trained Transformer\n(ChatGPT) standing out as a notable exampledue to its advanced capabilities and\nwidespread applications. This survey provides a comprehensive analysis of\nChatGPT, exploring its architecture, training processes, and functionalities.\nWe examine its integration into various domains across industries such as\ncustomer service, education, healthcare, and entertainment. A comparative\nanalysis with other LLMs highlights ChatGPT's unique features and performance\nmetrics. Regarding benchmarks, the paper examines ChatGPT's comparative\nperformance against other LLMs and discusses potential risks such as\nmisinformation, bias, and data privacy concerns. Additionally, we offer a\nnumber of figures and tables that outline the backdrop of the discussion, the\nmain ideas of the article, the numerous LLM models, a thorough list of datasets\nused for pre-training, fine-tuning, and evaluation, as well as particular LLM\napplications with pertinent references. Finally, we identify future research\ndirections and technological advancements, underscoring the evolving landscape\nof LLMs and their profound impact on artificial intelligence Artificial\nIntelligence (AI) and society.", "published": "2025-03-19 22:55:08", "link": "http://arxiv.org/abs/2503.17403v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Am I eligible? Natural Language Inference for Clinical Trial Patient Recruitment: the Patient's Point of View", "abstract": "Recruiting patients to participate in clinical trials can be challenging and\ntime-consuming. Usually, participation in a clinical trial is initiated by a\nhealthcare professional and proposed to the patient. Promoting clinical trials\ndirectly to patients via online recruitment might help to reach them more\nefficiently. In this study, we address the case where a patient is initiating\ntheir own recruitment process and wants to determine whether they are eligible\nfor a given clinical trial, using their own language to describe their medical\nprofile. To study whether this creates difficulties in the patient trial\nmatching process, we design a new dataset and task, Natural Language Inference\nfor Patient Recruitment (NLI4PR), in which patient language profiles must be\nmatched to clinical trials. We create it by adapting the TREC 2022 Clinical\nTrial Track dataset, which provides patients' medical profiles, and rephrasing\nthem manually using patient language. We also use the associated clinical trial\nreports where the patients are either eligible or excluded. We prompt several\nopen-source Large Language Models on our task and achieve from 56.5 to 71.8 of\nF1 score using patient language, against 64.7 to 73.1 for the same task using\nmedical language. When using patient language, we observe only a small loss in\nperformance for the best model, suggesting that having the patient as a\nstarting point could be adopted to help recruit patients for clinical trials.\nThe corpus and code bases are all freely available on our Github and\nHuggingFace repositories.", "published": "2025-03-19 22:07:19", "link": "http://arxiv.org/abs/2503.15718v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Pancreatic Cancer Staging with Large Language Models: The Role of Retrieval-Augmented Generation", "abstract": "Purpose: Retrieval-augmented generation (RAG) is a technology to enhance the\nfunctionality and reliability of large language models (LLMs) by retrieving\nrelevant information from reliable external knowledge (REK). RAG has gained\ninterest in radiology, and we previously reported the utility of NotebookLM, an\nLLM with RAG (RAG-LLM), for lung cancer staging. However, since the comparator\nLLM differed from NotebookLM's internal model, it remained unclear whether its\nadvantage stemmed from RAG or inherent model differences. To better isolate\nRAG's impact and assess its utility across different cancers, we compared\nNotebookLM with its internal LLM, Gemini 2.0 Flash, in a pancreatic cancer\nstaging experiment.\n  Materials and Methods: A summary of Japan's pancreatic cancer staging\nguidelines was used as REK. We compared three groups - REK+/RAG+ (NotebookLM\nwith REK), REK+/RAG- (Gemini 2.0 Flash with REK), and REK-/RAG- (Gemini 2.0\nFlash without REK) - in staging 100 fictional pancreatic cancer cases based on\nCT findings. Staging criteria included TNM classification, local invasion\nfactors, and resectability classification. In REK+/RAG+, retrieval accuracy was\nquantified based on the sufficiency of retrieved REK excerpts.\n  Results: REK+/RAG+ achieved a staging accuracy of 70%, outperforming\nREK+/RAG- (38%) and REK-/RAG- (35%). For TNM classification, REK+/RAG+ attained\n80% accuracy, exceeding REK+/RAG- (55%) and REK-/RAG- (50%). Additionally,\nREK+/RAG+ explicitly presented retrieved REK excerpts, achieving a retrieval\naccuracy of 92%.\n  Conclusion: NotebookLM, a RAG-LLM, outperformed its internal LLM, Gemini 2.0\nFlash, in a pancreatic cancer staging experiment, suggesting that RAG may\nimprove LLM's staging accuracy. Furthermore, its ability to retrieve and\npresent REK excerpts provides transparency for physicians, highlighting its\napplicability for clinical diagnosis and classification.", "published": "2025-03-19 19:29:47", "link": "http://arxiv.org/abs/2503.15664v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UI-Vision: A Desktop-centric GUI Benchmark for Visual Perception and Interaction", "abstract": "Autonomous agents that navigate Graphical User Interfaces (GUIs) to automate\ntasks like document editing and file management can greatly enhance computer\nworkflows. While existing research focuses on online settings, desktop\nenvironments, critical for many professional and everyday tasks, remain\nunderexplored due to data collection challenges and licensing issues. We\nintroduce UI-Vision, the first comprehensive, license-permissive benchmark for\noffline, fine-grained evaluation of computer use agents in real-world desktop\nenvironments. Unlike online benchmarks, UI-Vision provides: (i) dense,\nhigh-quality annotations of human demonstrations, including bounding boxes, UI\nlabels, and action trajectories (clicks, drags, and keyboard inputs) across 83\nsoftware applications, and (ii) three fine-to-coarse grained tasks-Element\nGrounding, Layout Grounding, and Action Prediction-with well-defined metrics to\nrigorously evaluate agents' performance in desktop environments. Our evaluation\nreveals critical limitations in state-of-the-art models like UI-TARS-72B,\nincluding issues with understanding professional software, spatial reasoning,\nand complex actions like drag-and-drop. These findings highlight the challenges\nin developing fully autonomous computer use agents. By releasing UI-Vision as\nopen-source, we aim to advance the development of more capable agents for\nreal-world desktop tasks.", "published": "2025-03-19 19:26:17", "link": "http://arxiv.org/abs/2503.15661v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "LLaVA-MORE: A Comparative Study of LLMs and Visual Backbones for Enhanced Visual Instruction Tuning", "abstract": "Recent progress in Multimodal Large Language Models (MLLMs) has highlighted\nthe critical roles of both the visual backbone and the underlying language\nmodel. While prior work has primarily focused on scaling these components to\nbillions of parameters, the trade-offs between model size, architecture, and\nperformance remain underexplored. Additionally, inconsistencies in training\ndata and evaluation protocols have hindered direct comparisons, making it\ndifficult to derive optimal design choices. In this paper, we introduce\nLLaVA-MORE, a new family of MLLMs that integrates recent language models with\ndiverse visual backbones. To ensure fair comparisons, we employ a unified\ntraining protocol applied consistently across all architectures. Our analysis\nsystematically explores both small- and medium-scale LLMs -- including Phi-4,\nLLaMA-3.1, and Gemma-2 -- to evaluate multimodal reasoning, generation, and\ninstruction following, while examining the relationship between model size and\nperformance. Beyond evaluating the LLM impact on final results, we conduct a\ncomprehensive study of various visual encoders, ranging from CLIP-based\narchitectures to alternatives such as DINOv2, SigLIP, and SigLIP2. Additional\nexperiments investigate the effects of increased image resolution and\nvariations in pre-training datasets. Overall, our results provide insights into\nthe design of more effective MLLMs, offering a reproducible evaluation\nframework that facilitates direct comparisons and can guide future model\ndevelopment. Our source code and trained models are publicly available at:\nhttps://github.com/aimagelab/LLaVA-MORE.", "published": "2025-03-19 18:10:12", "link": "http://arxiv.org/abs/2503.15621v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Does Context Matter? ContextualJudgeBench for Evaluating LLM-based Judges in Contextual Settings", "abstract": "The large language model (LLM)-as-judge paradigm has been used to meet the\ndemand for a cheap, reliable, and fast evaluation of model outputs during AI\nsystem development and post-deployment monitoring. While judge models -- LLMs\nfinetuned to specialize in assessing and critiquing model outputs -- have been\ntouted as general purpose evaluators, they are typically evaluated only on\nnon-contextual scenarios, such as instruction following. The omission of\ncontextual settings -- those where external information is used as context to\ngenerate an output -- is surprising given the increasing prevalence of\nretrieval-augmented generation (RAG) and summarization use cases. Contextual\nassessment is uniquely challenging, as evaluation often depends on practitioner\npriorities, leading to conditional evaluation criteria (e.g., comparing\nresponses based on factuality and then considering completeness if they are\nequally factual). To address the gap, we propose ContextualJudgeBench, a judge\nbenchmark with 2,000 challenging response pairs across eight splits inspired by\nreal-world contextual evaluation scenarios. We build our benchmark with a\nmulti-pronged data construction pipeline that leverages both existing human\nannotations and model-based perturbations. Our comprehensive study across 11\njudge models and 9 general purpose models, reveals that the contextual\ninformation and its assessment criteria present a significant challenge to even\nstate-of-the-art models. For example, OpenAI's o1, the best-performing model,\nbarely reaches 55% consistent accuracy.", "published": "2025-03-19 18:09:19", "link": "http://arxiv.org/abs/2503.15620v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TULIP: Towards Unified Language-Image Pretraining", "abstract": "Despite the recent success of image-text contrastive models like CLIP and\nSigLIP, these models often struggle with vision-centric tasks that demand\nhigh-fidelity image understanding, such as counting, depth estimation, and\nfine-grained object recognition. These models, by performing language\nalignment, tend to prioritize high-level semantics over visual understanding,\nweakening their image understanding. On the other hand, vision-focused models\nare great at processing visual information but struggle to understand language,\nlimiting their flexibility for language-driven tasks. In this work, we\nintroduce TULIP, an open-source, drop-in replacement for existing CLIP-like\nmodels. Our method leverages generative data augmentation, enhanced image-image\nand text-text contrastive learning, and image/text reconstruction\nregularization to learn fine-grained visual features while preserving global\nsemantic alignment. Our approach, scaling to over 1B parameters, outperforms\nexisting state-of-the-art (SOTA) models across multiple benchmarks,\nestablishing a new SOTA zero-shot performance on ImageNet-1K, delivering up to\na $2\\times$ enhancement over SigLIP on RxRx1 in linear probing for few-shot\nclassification, and improving vision-language models, achieving over $3\\times$\nhigher scores than SigLIP on MMVP. Our code/checkpoints are available at\nhttps://tulip-berkeley.github.io", "published": "2025-03-19 17:58:57", "link": "http://arxiv.org/abs/2503.15485v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Value Profiles for Encoding Human Variation", "abstract": "Modelling human variation in rating tasks is crucial for enabling AI systems\nfor personalization, pluralistic model alignment, and computational social\nscience. We propose representing individuals using value profiles -- natural\nlanguage descriptions of underlying values compressed from in-context\ndemonstrations -- along with a steerable decoder model to estimate ratings\nconditioned on a value profile or other rater information. To measure the\npredictive information in rater representations, we introduce an\ninformation-theoretic methodology. We find that demonstrations contain the most\ninformation, followed by value profiles and then demographics. However, value\nprofiles offer advantages in terms of scrutability, interpretability, and\nsteerability due to their compressed natural language format. Value profiles\neffectively compress the useful information from demonstrations (>70%\ninformation preservation). Furthermore, clustering value profiles to identify\nsimilarly behaving individuals better explains rater variation than the most\npredictive demographic groupings. Going beyond test set performance, we show\nthat the decoder models interpretably change ratings according to semantic\nprofile differences, are well-calibrated, and can help explain instance-level\ndisagreement by simulating an annotator population. These results demonstrate\nthat value profiles offer novel, predictive ways to describe individual\nvariation beyond demographics or group information.", "published": "2025-03-19 17:57:49", "link": "http://arxiv.org/abs/2503.15484v1", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "What Makes a Reward Model a Good Teacher? An Optimization Perspective", "abstract": "The success of Reinforcement Learning from Human Feedback (RLHF) critically\ndepends on the quality of the reward model. While this quality is primarily\nevaluated through accuracy, it remains unclear whether accuracy fully captures\nwhat makes a reward model an effective teacher. We address this question from\nan optimization perspective. First, we prove that regardless of how accurate a\nreward model is, if it induces low reward variance, then the RLHF objective\nsuffers from a flat landscape. Consequently, even a perfectly accurate reward\nmodel can lead to extremely slow optimization, underperforming less accurate\nmodels that induce higher reward variance. We additionally show that a reward\nmodel that works well for one language model can induce low reward variance,\nand thus a flat objective landscape, for another. These results establish a\nfundamental limitation of evaluating reward models solely based on accuracy or\nindependently of the language model they guide. Experiments using models of up\nto 8B parameters corroborate our theory, demonstrating the interplay between\nreward variance, accuracy, and reward maximization rate. Overall, our findings\nhighlight that beyond accuracy, a reward model needs to induce sufficient\nvariance for efficient optimization.", "published": "2025-03-19 17:54:41", "link": "http://arxiv.org/abs/2503.15477v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Explainable AI Components for Narrative Map Extraction", "abstract": "As narrative extraction systems grow in complexity, establishing user trust\nthrough interpretable and explainable outputs becomes increasingly critical.\nThis paper presents an evaluation of an Explainable Artificial Intelligence\n(XAI) system for narrative map extraction that provides meaningful explanations\nacross multiple levels of abstraction. Our system integrates explanations based\non topical clusters for low-level document relationships, connection\nexplanations for event relationships, and high-level structure explanations for\noverall narrative patterns. In particular, we evaluate the XAI system through a\nuser study involving 10 participants that examined narratives from the 2021\nCuban protests. The analysis of results demonstrates that participants using\nthe explanations made the users trust in the system's decisions, with\nconnection explanations and important event detection proving particularly\neffective at building user confidence. Survey responses indicate that the\nmulti-level explanation approach helped users develop appropriate trust in the\nsystem's narrative extraction capabilities. This work advances the\nstate-of-the-art in explainable narrative extraction while providing practical\ninsights for developing reliable narrative extraction systems that support\neffective human-AI collaboration.", "published": "2025-03-19 17:48:00", "link": "http://arxiv.org/abs/2503.16554v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Dynamic Bi-Elman Attention Networks: A Dual-Directional Context-Aware Test-Time Learning for Text Classification", "abstract": "Text classification, a fundamental task in natural language processing, aims\nto categorize textual data into predefined labels. Traditional methods\nstruggled with complex linguistic structures and semantic dependencies.\nHowever, the advent of deep learning, particularly recurrent neural networks\nand Transformer-based models, has significantly advanced the field by enabling\nnuanced feature extraction and context-aware predictions. Despite these\nimprovements, existing models still exhibit limitations in balancing\ninterpretability, computational efficiency, and long-range contextual\nunderstanding. To address these challenges, this paper proposes the Dynamic\nBidirectional Elman with Attention Network (DBEAN). DBEAN integrates\nbidirectional temporal modeling with self-attention mechanisms. It dynamically\nassigns weights to critical segments of input, improving contextual\nrepresentation while maintaining computational efficiency.", "published": "2025-03-19 17:45:13", "link": "http://arxiv.org/abs/2503.15469v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "From 1,000,000 Users to Every User: Scaling Up Personalized Preference for User-level Alignment", "abstract": "Large language models (LLMs) have traditionally been aligned through\none-size-fits-all approaches that assume uniform human preferences,\nfundamentally overlooking the diversity in user values and needs. This paper\nintroduces a comprehensive framework for scalable personalized alignment of\nLLMs. We establish a systematic preference space characterizing psychological\nand behavioral dimensions, alongside diverse persona representations for robust\npreference inference in real-world scenarios. Building upon this foundation, we\nintroduce \\textsc{AlignX}, a large-scale dataset of over 1.3 million\npersonalized preference examples, and develop two complementary alignment\napproaches: \\textit{in-context alignment} directly conditioning on persona\nrepresentations and \\textit{preference-bridged alignment} modeling intermediate\npreference distributions. Extensive experiments demonstrate substantial\nimprovements over existing methods, with an average 17.06\\% accuracy gain\nacross four benchmarks while exhibiting a strong adaptation capability to novel\npreferences, robustness to limited user data, and precise preference\ncontrollability. These results validate our framework's effectiveness,\nadvancing toward truly user-adaptive AI systems.", "published": "2025-03-19 17:41:46", "link": "http://arxiv.org/abs/2503.15463v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Bias Evaluation and Mitigation in Retrieval-Augmented Medical Question-Answering Systems", "abstract": "Medical Question Answering systems based on Retrieval Augmented Generation is\npromising for clinical decision support because they can integrate external\nknowledge, thus reducing inaccuracies inherent in standalone large language\nmodels (LLMs). However, these systems may unintentionally propagate or amplify\nbiases associated with sensitive demographic attributes like race, gender, and\nsocioeconomic factors. This study systematically evaluates demographic biases\nwithin medical RAG pipelines across multiple QA benchmarks, including MedQA,\nMedMCQA, MMLU, and EquityMedQA. We quantify disparities in retrieval\nconsistency and answer correctness by generating and analyzing queries\nsensitive to demographic variations. We further implement and compare several\nbias mitigation strategies to address identified biases, including Chain of\nThought reasoning, Counterfactual filtering, Adversarial prompt refinement, and\nMajority Vote aggregation. Experimental results reveal significant demographic\ndisparities, highlighting that Majority Vote aggregation notably improves\naccuracy and fairness metrics. Our findings underscore the critical need for\nexplicitly fairness-aware retrieval methods and prompt engineering strategies\nto develop truly equitable medical QA systems.", "published": "2025-03-19 17:36:35", "link": "http://arxiv.org/abs/2503.15454v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SkyLadder: Better and Faster Pretraining via Context Window Scheduling", "abstract": "Recent advancements in LLM pretraining have featured ever-expanding context\nwindows to process longer sequences. However, our pilot study reveals that\nmodels pretrained with shorter context windows consistently outperform their\nlong-context counterparts under a fixed token budget. This finding motivates us\nto explore an optimal context window scheduling strategy to better balance\nlong-context capability with pretraining efficiency. To this end, we propose\nSkyLadder, a simple yet effective approach that implements a short-to-long\ncontext window transition. SkyLadder preserves strong standard benchmark\nperformance, while matching or exceeding baseline results on long context\ntasks. Through extensive experiments, we pre-train 1B-parameter models (up to\n32K context) and 3B-parameter models (8K context) on 100B tokens, demonstrating\nthat SkyLadder yields consistent gains of up to 3.7% on common benchmarks,\nwhile achieving up to 22% faster training speeds compared to baselines. The\ncode is at https://github.com/sail-sg/SkyLadder.", "published": "2025-03-19 17:31:15", "link": "http://arxiv.org/abs/2503.15450v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "VenusFactory: A Unified Platform for Protein Engineering Data Retrieval and Language Model Fine-Tuning", "abstract": "Natural language processing (NLP) has significantly influenced scientific\ndomains beyond human language, including protein engineering, where pre-trained\nprotein language models (PLMs) have demonstrated remarkable success. However,\ninterdisciplinary adoption remains limited due to challenges in data\ncollection, task benchmarking, and application. This work presents\nVenusFactory, a versatile engine that integrates biological data retrieval,\nstandardized task benchmarking, and modular fine-tuning of PLMs. VenusFactory\nsupports both computer science and biology communities with choices of both a\ncommand-line execution and a Gradio-based no-code interface, integrating $40+$\nprotein-related datasets and $40+$ popular PLMs. All implementations are\nopen-sourced on https://github.com/tyang816/VenusFactory.", "published": "2025-03-19 17:19:07", "link": "http://arxiv.org/abs/2503.15438v1", "categories": ["cs.CL", "cs.AI", "q-bio.QM"], "primary_category": "cs.CL"}
{"title": "Real-world validation of a multimodal LLM-powered pipeline for High-Accuracy Clinical Trial Patient Matching leveraging EHR data", "abstract": "Background: Patient recruitment in clinical trials is hindered by complex\neligibility criteria and labor-intensive chart reviews. Prior research using\ntext-only models have struggled to address this problem in a reliable and\nscalable way due to (1) limited reasoning capabilities, (2) information loss\nfrom converting visual records to text, and (3) lack of a generic EHR\nintegration to extract patient data.\n  Methods: We introduce a broadly applicable, integration-free, LLM-powered\npipeline that automates patient-trial matching using unprocessed documents\nextracted from EHRs. Our approach leverages (1) the new reasoning-LLM paradigm,\nenabling the assessment of even the most complex criteria, (2) visual\ncapabilities of latest LLMs to interpret medical records without lossy\nimage-to-text conversions, and (3) multimodal embeddings for efficient medical\nrecord search. The pipeline was validated on the n2c2 2018 cohort selection\ndataset (288 diabetic patients) and a real-world dataset composed of 485\npatients from 30 different sites matched against 36 diverse trials.\n  Results: On the n2c2 dataset, our method achieved a new state-of-the-art\ncriterion-level accuracy of 93\\%. In real-world trials, the pipeline yielded an\naccuracy of 87\\%, undermined by the difficulty to replicate human\ndecision-making when medical records lack sufficient information. Nevertheless,\nusers were able to review overall eligibility in under 9 minutes per patient on\naverage, representing an 80\\% improvement over traditional manual chart\nreviews.\n  Conclusion: This pipeline demonstrates robust performance in clinical trial\npatient matching without requiring custom integration with site systems or\ntrial-specific tailoring, thereby enabling scalable deployment across sites\nseeking to leverage AI for patient matching.", "published": "2025-03-19 16:12:11", "link": "http://arxiv.org/abs/2503.15374v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SemEval-2025 Task 1: AdMIRe -- Advancing Multimodal Idiomaticity Representation", "abstract": "Idiomatic expressions present a unique challenge in NLP, as their meanings\nare often not directly inferable from their constituent words. Despite recent\nadvancements in Large Language Models (LLMs), idiomaticity remains a\nsignificant obstacle to robust semantic representation. We present datasets and\ntasks for SemEval-2025 Task 1: AdMiRe (Advancing Multimodal Idiomaticity\nRepresentation), which challenges the community to assess and improve models'\nability to interpret idiomatic expressions in multimodal contexts and in\nmultiple languages. Participants competed in two subtasks: ranking images based\non their alignment with idiomatic or literal meanings, and predicting the next\nimage in a sequence. The most effective methods achieved human-level\nperformance by leveraging pretrained LLMs and vision-language models in\nmixture-of-experts settings, with multiple queries used to smooth over the\nweaknesses in these models' representations of idiomaticity.", "published": "2025-03-19 15:58:46", "link": "http://arxiv.org/abs/2503.15358v1", "categories": ["cs.CL", "cs.CV", "I.2.7; I.4.m"], "primary_category": "cs.CL"}
{"title": "Optimizing Decomposition for Optimal Claim Verification", "abstract": "Current research on the \\textit{Decompose-Then-Verify} paradigm for\nevaluating the factuality of long-form text typically treats decomposition and\nverification in isolation, overlooking their interactions and potential\nmisalignment. We find that existing decomposition policies, typically\nhand-crafted demonstrations, do not align well with downstream verifiers in\nterms of atomicity -- a novel metric quantifying information density -- leading\nto suboptimal verification results. We formulate finding the optimal\ndecomposition policy for optimal verification as a bilevel optimization\nproblem. To approximate a solution for this strongly NP-hard problem, we\npropose dynamic decomposition, a reinforcement learning framework that\nleverages verifier feedback to learn a policy for dynamically decomposing\nclaims to verifier-preferred atomicity. Experimental results show that dynamic\ndecomposition outperforms existing decomposition policies, improving\nverification confidence by 0.07 and accuracy by 0.12 (on a 0-1 scale) on\naverage across varying verifiers, datasets, and atomcities of input claims.", "published": "2025-03-19 15:56:21", "link": "http://arxiv.org/abs/2503.15354v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SPILL: Domain-Adaptive Intent Clustering based on Selection and Pooling with Large Language Models", "abstract": "In this paper, we propose Selection and Pooling with Large Language Models\n(SPILL), an intuitive and domain-adaptive method for intent clustering without\nfine-tuning. Existing embeddings-based clustering methods rely on a few labeled\nexamples or unsupervised fine-tuning to optimize results for each new dataset,\nwhich makes them less generalizable to multiple datasets. Our goal is to make\nthese existing embedders more generalizable to new domain datasets without\nfurther fine-tuning. Inspired by our theoretical derivation and simulation\nresults on the effectiveness of sampling and pooling techniques, we view the\nclustering task as a small-scale selection problem. A good solution to this\nproblem is associated with better clustering performance. Accordingly, we\npropose a two-stage approach: First, for each utterance (referred to as the\nseed), we derive its embedding using an existing embedder. Then, we apply a\ndistance metric to select a pool of candidates close to the seed. Because the\nembedder is not optimized for new datasets, in the second stage, we use an LLM\nto further select utterances from these candidates that share the same intent\nas the seed. Finally, we pool these selected candidates with the seed to derive\na refined embedding for the seed. We found that our method generally\noutperforms directly using an embedder, and it achieves comparable results to\nother state-of-the-art studies, even those that use much larger models and\nrequire fine-tuning, showing its strength and efficiency. Our results indicate\nthat our method enables existing embedders to be further improved without\nadditional fine-tuning, making them more adaptable to new domain datasets.\nAdditionally, viewing the clustering task as a small-scale selection problem\ngives the potential of using LLMs to customize clustering tasks according to\nthe user's goals.", "published": "2025-03-19 15:48:57", "link": "http://arxiv.org/abs/2503.15351v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Solla: Towards a Speech-Oriented LLM That Hears Acoustic Context", "abstract": "Large Language Models (LLMs) have recently shown remarkable ability to\nprocess not only text but also multimodal inputs such as speech and audio.\nHowever, most existing models primarily focus on analyzing input signals using\ntext instructions, overlooking scenarios in which speech instructions and audio\nare mixed and serve as inputs to the model. To address these challenges, we\nintroduce Solla, a novel framework designed to understand speech-based\nquestions and hear the acoustic context concurrently. Solla incorporates an\naudio tagging module to effectively identify and represent audio events, as\nwell as an ASR-assisted prediction method to improve comprehension of spoken\ncontent. To rigorously evaluate Solla and other publicly available models, we\npropose a new benchmark dataset called SA-Eval, which includes three tasks:\naudio event classification, audio captioning, and audio question answering.\nSA-Eval has diverse speech instruction with various speaking styles,\nencompassing two difficulty levels, easy and hard, to capture the range of\nreal-world acoustic conditions. Experimental results show that Solla performs\non par with or outperforms baseline models on both the easy and hard test sets,\nunderscoring its effectiveness in jointly understanding speech and audio.", "published": "2025-03-19 15:34:21", "link": "http://arxiv.org/abs/2503.15338v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Inside-Out: Hidden Factual Knowledge in LLMs", "abstract": "This work presents a framework for assessing whether large language models\n(LLMs) encode more factual knowledge in their parameters than what they express\nin their outputs. While a few studies hint at this possibility, none has\nclearly defined or demonstrated this phenomenon. We first propose a formal\ndefinition of knowledge, quantifying it for a given question as the fraction of\ncorrect-incorrect answer pairs where the correct one is ranked higher. This\ngives rise to external and internal knowledge, depending on the information\nused to score individual answer candidates: either the model's observable\ntoken-level probabilities or its intermediate computations. Hidden knowledge\narises when internal knowledge exceeds external knowledge. We then present a\ncase study, applying this framework to three popular open-weights LLMs in a\nclosed-book QA setup. Our results indicate that: (1) LLMs consistently encode\nmore factual knowledge internally than what they express externally, with an\naverage relative gap of 40%. (2) Surprisingly, some knowledge is so deeply\nhidden that a model can internally know an answer perfectly, yet fail to\ngenerate it even once, despite large-scale repeated sampling of 1,000 answers.\nThis reveals fundamental limitations in the generation capabilities of LLMs,\nwhich (3) put a practical constraint on scaling test-time compute via repeated\nanswer sampling in closed-book QA: significant performance improvements remain\ninaccessible because some answers are practically never sampled, yet if they\nwere, we would be guaranteed to rank them first.", "published": "2025-03-19 15:21:48", "link": "http://arxiv.org/abs/2503.15299v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TROVE: A Challenge for Fine-Grained Text Provenance via Source Sentence Tracing and Relationship Classification", "abstract": "LLMs have achieved remarkable fluency and coherence in text generation, yet\ntheir widespread adoption has raised concerns about content reliability and\naccountability. In high-stakes domains such as healthcare, law, and news, it is\ncrucial to understand where and how the content is created. To address this, we\nintroduce the Text pROVEnance (TROVE) challenge, designed to trace each\nsentence of a target text back to specific source sentences within potentially\nlengthy or multi-document inputs. Beyond identifying sources, TROVE annotates\nthe fine-grained relationships (quotation, compression, inference, and others),\nproviding a deep understanding of how each target sentence is formed. To\nbenchmark TROVE, we construct our dataset by leveraging three public datasets\ncovering 11 diverse scenarios (e.g., QA and summarization) in English and\nChinese, spanning source texts of varying lengths (0-5k, 5-10k, 10k+),\nemphasizing the multi-document and long-document settings essential for\nprovenance. To ensure high-quality data, we employ a three-stage annotation\nprocess: sentence retrieval, GPT provenance, and human provenance. We evaluate\n11 LLMs under direct prompting and retrieval-augmented paradigms, revealing\nthat retrieval is essential for robust performance, larger models perform\nbetter in complex relationship classification, and closed-source models often\nlead, yet open-source models show significant promise, particularly with\nretrieval augmentation.", "published": "2025-03-19 15:09:39", "link": "http://arxiv.org/abs/2503.15289v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Foundational individual Mobility Prediction Model based on Open-Source Large Language Models", "abstract": "Large Language Models (LLMs) are widely applied to domain-specific tasks due\nto their massive general knowledge and remarkable inference capacities. Current\nstudies on LLMs have shown immense potential in applying LLMs to model\nindividual mobility prediction problems. However, most LLM-based mobility\nprediction models only train on specific datasets or use single well-designed\nprompts, leading to difficulty in adapting to different cities and users with\ndiverse contexts. To fill these gaps, this paper proposes a unified fine-tuning\nframework to train a foundational open source LLM-based mobility prediction\nmodel. We conducted extensive experiments on six real-world mobility datasets\nto validate the proposed model. The results showed that the proposed model\nachieved the best performance in prediction accuracy and transferability over\nstate-of-the-art models based on deep learning and LLMs.", "published": "2025-03-19 15:08:37", "link": "http://arxiv.org/abs/2503.16553v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MAMM-Refine: A Recipe for Improving Faithfulness in Generation with Multi-Agent Collaboration", "abstract": "Multi-agent collaboration among models has shown promise in reasoning tasks\nbut is underexplored in long-form generation tasks like summarization and\nquestion-answering. We extend multi-agent multi-model reasoning to generation,\nspecifically to improving faithfulness through refinement, i.e., revising\nmodel-generated outputs to remove factual inconsistencies. We investigate how\niterative collaboration among multiple instances and types of large language\nmodels (LLMs) enhances subtasks in the refinement process, such as error\ndetection, critiquing unfaithful sentences, and making corrections based on\ncritiques. We design intrinsic evaluations for each subtask, with our findings\nindicating that both multi-agent (multiple instances) and multi-model (diverse\nLLM types) approaches benefit error detection and critiquing. Additionally,\nreframing critiquing and refinement as reranking rather than generation tasks\nimproves multi-agent performance. We consolidate these insights into a final\n\"recipe\" called Multi-Agent Multi-Model Refinement (MAMM-Refine), where\nmulti-agent and multi-model collaboration significantly boosts performance on\nthree summarization datasets as well as on long-form question answering,\ndemonstrating the effectiveness and generalizability of our recipe.", "published": "2025-03-19 14:46:53", "link": "http://arxiv.org/abs/2503.15272v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "BigO(Bench) -- Can LLMs Generate Code with Controlled Time and Space Complexity?", "abstract": "We introduce BigO(Bench), a novel coding benchmark designed to evaluate the\ncapabilities of generative language models in understanding and generating code\nwith specified time and space complexities. This benchmark addresses the gap in\ncurrent evaluations that often overlook the ability of models to comprehend and\nproduce code constrained by computational complexity. BigO(Bench) includes\ntooling to infer the algorithmic complexity of any Python function from\nprofiling measurements, including human- or LLM-generated solutions.\nBigO(Bench) also includes of set of 3,105 coding problems and 1,190,250\nsolutions from Code Contests annotated with inferred (synthetic) time and space\ncomplexity labels from the complexity framework, as well as corresponding\nruntime and memory footprint values for a large set of input sizes. We present\nresults from evaluating multiple state-of-the-art language models on this\nbenchmark, highlighting their strengths and weaknesses in handling complexity\nrequirements. In particular, token-space reasoning models are unrivaled in code\ngeneration but not in complexity understanding, hinting that they may not\ngeneralize well to tasks for which no reward was given at training time.", "published": "2025-03-19 14:19:57", "link": "http://arxiv.org/abs/2503.15242v2", "categories": ["cs.CL", "cs.AI", "cs.CC"], "primary_category": "cs.CL"}
{"title": "Exploring Large Language Models for Word Games:Who is the Spy?", "abstract": "Word games hold significant research value for natural language processing\n(NLP), game theory, and related fields due to their rule-based and situational\nnature. This study explores how large language models (LLMs) can be effectively\ninvolved in word games and proposes a training-free framework. \"Shei Shi Wo Di\"\nor \"Who is the Spy\" in English, is a classic word game. Using this game as an\nexample, we introduce a Chain-of-Thought (CoT)-based scheduling framework to\nenable LLMs to achieve excellent performance in tasks such as inferring role\nwords and disguising their identities. We evaluate the framework's performance\nbased on game success rates and the accuracy of the LLM agents' analytical\nresults. Experimental results affirm the framework's effectiveness,\ndemonstrating notable improvements in LLM performance across multiple datasets.\nThis work highlights the potential of LLMs in mastering situational reasoning\nand social interactions within structured game environments. Our code is\npublicly available at https://github.com/ct-wei/Who-is-The-Spy.", "published": "2025-03-19 14:13:02", "link": "http://arxiv.org/abs/2503.15235v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Model Hubs and Beyond: Analyzing Model Popularity, Performance, and Documentation", "abstract": "With the massive surge in ML models on platforms like Hugging Face, users\noften lose track and struggle to choose the best model for their downstream\ntasks, frequently relying on model popularity indicated by download counts,\nlikes, or recency. We investigate whether this popularity aligns with actual\nmodel performance and how the comprehensiveness of model documentation\ncorrelates with both popularity and performance. In our study, we evaluated a\ncomprehensive set of 500 Sentiment Analysis models on Hugging Face. This\nevaluation involved massive annotation efforts, with human annotators\ncompleting nearly 80,000 annotations, alongside extensive model training and\nevaluation. Our findings reveal that model popularity does not necessarily\ncorrelate with performance. Additionally, we identify critical inconsistencies\nin model card reporting: approximately 80% of the models analyzed lack detailed\ninformation about the model, training, and evaluation processes. Furthermore,\nabout 88% of model authors overstate their models' performance in the model\ncards. Based on our findings, we provide a checklist of guidelines for users to\nchoose good models for downstream tasks.", "published": "2025-03-19 14:01:33", "link": "http://arxiv.org/abs/2503.15222v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Entity-aware Cross-lingual Claim Detection for Automated Fact-checking", "abstract": "Identifying claims requiring verification is a critical task in automated\nfact-checking, especially given the proliferation of misinformation on social\nmedia platforms. Despite significant progress in the task, there remain open\nchallenges such as dealing with multilingual and multimodal data prevalent in\nonline discourse. Addressing the multilingual challenge, recent efforts have\nfocused on fine-tuning pre-trained multilingual language models. While these\nmodels can handle multiple languages, their ability to effectively transfer\ncross-lingual knowledge for detecting claims spreading on social media remains\nunder-explored. In this paper, we introduce EX-Claim, an entity-aware\ncross-lingual claim detection model that generalizes well to handle claims\nwritten in any language. The model leverages entity information derived from\nnamed entity recognition and entity linking techniques to improve the\nlanguage-level performance of both seen and unseen languages during training.\nExtensive experiments conducted on three datasets from different social media\nplatforms demonstrate that our proposed model significantly outperforms the\nbaselines, across 27 languages, and achieves the highest rate of knowledge\ntransfer, even with limited training data.", "published": "2025-03-19 14:00:55", "link": "http://arxiv.org/abs/2503.15220v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unified Enhancement of the Generalization and Robustness of Language Models via Bi-Stage Optimization", "abstract": "Neural network language models (LMs) are confronted with significant\nchallenges in generalization and robustness. Currently, many studies focus on\nimproving either generalization or robustness in isolation, without methods\naddressing both aspects simultaneously, which presents a significant challenge\nin developing LMs that are both robust and generalized. In this paper, we\npropose a bi-stage optimization framework to uniformly enhance both the\ngeneralization and robustness of LMs, termed UEGR. Specifically, during the\nforward propagation stage, we enrich the output probability distributions of\nadversarial samples by adaptive dropout to generate diverse sub models, and\nincorporate JS divergence and adversarial losses of these output distributions\nto reinforce output stability. During backward propagation stage, we compute\nparameter saliency scores and selectively update only the most critical\nparameters to minimize unnecessary deviations and consolidate the model's\nresilience. Theoretical analysis shows that our framework includes gradient\nregularization to limit the model's sensitivity to input perturbations and\nselective parameter updates to flatten the loss landscape, thus improving both\ngeneralization and robustness. The experimental results show that our method\nsignificantly improves the generalization and robustness of LMs compared to\nother existing methods across 13 publicly available language datasets,\nachieving state-of-the-art (SOTA) performance.", "published": "2025-03-19 13:50:36", "link": "http://arxiv.org/abs/2503.16550v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When Pigs Get Sick: Multi-Agent AI for Swine Disease Detection", "abstract": "Swine disease surveillance is critical to the sustainability of global\nagriculture, yet its effectiveness is frequently undermined by limited\nveterinary resources, delayed identification of cases, and variability in\ndiagnostic accuracy. To overcome these barriers, we introduce a novel\nAI-powered, multi-agent diagnostic system that leverages Retrieval-Augmented\nGeneration (RAG) to deliver timely, evidence-based disease detection and\nclinical guidance. By automatically classifying user inputs into either\nKnowledge Retrieval Queries or Symptom-Based Diagnostic Queries, the system\nensures targeted information retrieval and facilitates precise diagnostic\nreasoning. An adaptive questioning protocol systematically collects relevant\nclinical signs, while a confidence-weighted decision fusion mechanism\nintegrates multiple diagnostic hypotheses to generate robust disease\npredictions and treatment recommendations. Comprehensive evaluations\nencompassing query classification, disease diagnosis, and knowledge retrieval\ndemonstrate that the system achieves high accuracy, rapid response times, and\nconsistent reliability. By providing a scalable, AI-driven diagnostic\nframework, this approach enhances veterinary decision-making, advances\nsustainable livestock management practices, and contributes substantively to\nthe realization of global food security.", "published": "2025-03-19 13:47:25", "link": "http://arxiv.org/abs/2503.15204v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.IR", "cs.MA"], "primary_category": "cs.HC"}
{"title": "A Review on Large Language Models for Visual Analytics", "abstract": "This paper provides a comprehensive review of the integration of Large\nLanguage Models (LLMs) with visual analytics, addressing their foundational\nconcepts, capabilities, and wide-ranging applications. It begins by outlining\nthe theoretical underpinnings of visual analytics and the transformative\npotential of LLMs, specifically focusing on their roles in natural language\nunderstanding, natural language generation, dialogue systems, and text-to-media\ntransformations. The review further investigates how the synergy between LLMs\nand visual analytics enhances data interpretation, visualization techniques,\nand interactive exploration capabilities. Key tools and platforms including\nLIDA, Chat2VIS, Julius AI, and Zoho Analytics, along with specialized\nmultimodal models such as ChartLlama and CharXIV, are critically evaluated. The\npaper discusses their functionalities, strengths, and limitations in supporting\ndata exploration, visualization enhancement, automated reporting, and insight\nextraction. The taxonomy of LLM tasks, ranging from natural language\nunderstanding (NLU), natural language generation (NLG), to dialogue systems and\ntext-to-media transformations, is systematically explored. This review provides\na SWOT analysis of integrating Large Language Models (LLMs) with visual\nanalytics, highlighting strengths like accessibility and flexibility,\nweaknesses such as computational demands and biases, opportunities in\nmultimodal integration and user collaboration, and threats including privacy\nconcerns and skill degradation. It emphasizes addressing ethical considerations\nand methodological improvements for effective integration.", "published": "2025-03-19 13:02:01", "link": "http://arxiv.org/abs/2503.15176v1", "categories": ["cs.HC", "cs.CL", "cs.CV"], "primary_category": "cs.HC"}
{"title": "Comparing Llama3 and DeepSeekR1 on Biomedical Text Classification Tasks", "abstract": "This study compares the performance of two open-source large language models\n(LLMs)-Llama3-70B and DeepSeekR1-distill-Llama3-70B-on six biomedical text\nclassification tasks. Four tasks involve data from social media, while two\ntasks focus on clinical notes from electronic health records, and all\nexperiments were performed in zero-shot settings. Performance metrics,\nincluding precision, recall, and F1 scores, were measured for each task, along\nwith their 95% confidence intervals. Results demonstrated that\nDeepSeekR1-distill-Llama3-70B generally performs better in terms of precision\non most tasks, with mixed results on recall. While the zero-shot LLMs\ndemonstrated high F1 scores for some tasks, they grossly underperformed on\nothers, for data from both sources. The findings suggest that model selection\nshould be guided by the specific requirements of the health-related text\nclassification tasks, particularly when considering the precision-recall\ntrade-offs, and that, in the presence of annotated data, supervised\nclassification approaches may be more reliable than zero-shot LLMs.", "published": "2025-03-19 12:51:52", "link": "http://arxiv.org/abs/2503.15169v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Machine Unlearning in Hyperbolic vs. Euclidean Multimodal Contrastive Learning: Adapting Alignment Calibration to MERU", "abstract": "Machine unlearning methods have become increasingly important for selective\nconcept removal in large pre-trained models. While recent work has explored\nunlearning in Euclidean contrastive vision-language models, the effectiveness\nof concept removal in hyperbolic spaces remains unexplored. This paper\ninvestigates machine unlearning in hyperbolic contrastive learning by adapting\nAlignment Calibration to MERU, a model that embeds images and text in\nhyperbolic space to better capture semantic hierarchies. Through systematic\nexperiments and ablation studies, we demonstrate that hyperbolic geometry\noffers distinct advantages for concept removal, achieving near perfect\nforgetting with reasonable performance on retained concepts, particularly when\nscaling to multiple concept removal. Our approach introduces\nhyperbolic-specific components including entailment calibration and norm\nregularization that leverage the unique properties of hyperbolic space.\nComparative analysis with Euclidean models reveals fundamental differences in\nunlearning dynamics, with hyperbolic unlearning reorganizing the semantic\nhierarchy while Euclidean approaches merely disconnect cross-modal\nassociations. These findings not only advance machine unlearning techniques but\nalso provide insights into the geometric properties that influence concept\nrepresentation and removal in multimodal models. Source code available at\nhttps://github.com/alex-pv01/HAC", "published": "2025-03-19 12:47:37", "link": "http://arxiv.org/abs/2503.15166v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.MM"], "primary_category": "cs.CV"}
{"title": "EmoGRACE: Aspect-based emotion analysis for social media data", "abstract": "While sentiment analysis has advanced from sentence to aspect-level, i.e.,\nthe identification of concrete terms related to a sentiment, the equivalent\nfield of Aspect-based Emotion Analysis (ABEA) is faced with dataset bottlenecks\nand the increased complexity of emotion classes in contrast to binary\nsentiments. This paper addresses these gaps, by generating a first ABEA\ntraining dataset, consisting of 2,621 English Tweets, and fine-tuning a\nBERT-based model for the ABEA sub-tasks of Aspect Term Extraction (ATE) and\nAspect Emotion Classification (AEC).\n  The dataset annotation process was based on the hierarchical emotion theory\nby Shaver et al. [1] and made use of group annotation and majority voting\nstrategies to facilitate label consistency. The resulting dataset contained\naspect-level emotion labels for Anger, Sadness, Happiness, Fear, and a None\nclass. Using the new ABEA training dataset, the state-of-the-art ABSA model\nGRACE by Luo et al. [2] was fine-tuned for ABEA. The results reflected a\nperformance plateau at an F1-score of 70.1% for ATE and 46.9% for joint ATE and\nAEC extraction. The limiting factors for model performance were broadly\nidentified as the small training dataset size coupled with the increased task\ncomplexity, causing model overfitting and limited abilities to generalize well\non new data.", "published": "2025-03-19 11:48:52", "link": "http://arxiv.org/abs/2503.15133v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Increasing the Robustness of the Fine-tuned Multilingual Machine-Generated Text Detectors", "abstract": "Since the proliferation of LLMs, there have been concerns about their misuse\nfor harmful content creation and spreading. Recent studies justify such fears,\nproviding evidence of LLM vulnerabilities and high potential of their misuse.\nHumans are no longer able to distinguish between high-quality machine-generated\nand authentic human-written texts. Therefore, it is crucial to develop\nautomated means to accurately detect machine-generated content. It would enable\nto identify such content in online information space, thus providing an\nadditional information about its credibility. This work addresses the problem\nby proposing a robust fine-tuning process of LLMs for the detection task,\nmaking the detectors more robust against obfuscation and more generalizable to\nout-of-distribution data.", "published": "2025-03-19 11:42:33", "link": "http://arxiv.org/abs/2503.15128v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluating ASR Confidence Scores for Automated Error Detection in User-Assisted Correction Interfaces", "abstract": "Despite advances in Automatic Speech Recognition (ASR), transcription errors\npersist and require manual correction. Confidence scores, which indicate the\ncertainty of ASR results, could assist users in identifying and correcting\nerrors. This study evaluates the reliability of confidence scores for error\ndetection through a comprehensive analysis of end-to-end ASR models and a user\nstudy with 36 participants. The results show that while confidence scores\ncorrelate with transcription accuracy, their error detection performance is\nlimited. Classifiers frequently miss errors or generate many false positives,\nundermining their practical utility. Confidence-based error detection neither\nimproved correction efficiency nor was perceived as helpful by participants.\nThese findings highlight the limitations of confidence scores and the need for\nmore sophisticated approaches to improve user interaction and explainability of\nASR results.", "published": "2025-03-19 11:33:40", "link": "http://arxiv.org/abs/2503.15124v1", "categories": ["cs.HC", "cs.CL", "cs.SD", "eess.AS", "I.2.7"], "primary_category": "cs.HC"}
{"title": "Exploring Model Editing for LLM-based Aspect-Based Sentiment Classification", "abstract": "Model editing aims at selectively updating a small subset of a neural model's\nparameters with an interpretable strategy to achieve desired modifications. It\ncan significantly reduce computational costs to adapt to large language models\n(LLMs). Given its ability to precisely target critical components within LLMs,\nmodel editing shows great potential for efficient fine-tuning applications. In\nthis work, we investigate model editing to serve an efficient method for\nadapting LLMs to solve aspect-based sentiment classification. Through causal\ninterventions, we trace and determine which neuron hidden states are essential\nfor the prediction of the model. By performing interventions and restorations\non each component of an LLM, we identify the importance of these components for\naspect-based sentiment classification. Our findings reveal that a distinct set\nof mid-layer representations is essential for detecting the sentiment polarity\nof given aspect words. Leveraging these insights, we develop a model editing\napproach that focuses exclusively on these critical parts of the LLM, leading\nto a more efficient method for adapting LLMs. Our in-domain and out-of-domain\nexperiments demonstrate that this approach achieves competitive results\ncompared to the currently strongest methods with significantly fewer trainable\nparameters, highlighting a more efficient and interpretable fine-tuning\nstrategy.", "published": "2025-03-19 11:21:37", "link": "http://arxiv.org/abs/2503.15117v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Understanding the Safety Boundaries of DeepSeek Models: Evaluation and Findings", "abstract": "This study presents the first comprehensive safety evaluation of the DeepSeek\nmodels, focusing on evaluating the safety risks associated with their generated\ncontent. Our evaluation encompasses DeepSeek's latest generation of large\nlanguage models, multimodal large language models, and text-to-image models,\nsystematically examining their performance regarding unsafe content generation.\nNotably, we developed a bilingual (Chinese-English) safety evaluation dataset\ntailored to Chinese sociocultural contexts, enabling a more thorough evaluation\nof the safety capabilities of Chinese-developed models. Experimental results\nindicate that despite their strong general capabilities, DeepSeek models\nexhibit significant safety vulnerabilities across multiple risk dimensions,\nincluding algorithmic discrimination and sexual content. These findings provide\ncrucial insights for understanding and improving the safety of large foundation\nmodels. Our code is available at\nhttps://github.com/NY1024/DeepSeek-Safety-Eval.", "published": "2025-03-19 10:44:37", "link": "http://arxiv.org/abs/2503.15092v1", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "A Data-driven Investigation of Euphemistic Language: Comparing the usage of \"slave\" and \"servant\" in 19th century US newspapers", "abstract": "This study investigates the usage of \"slave\" and \"servant\" in the 19th\ncentury US newspapers using computational methods. While both terms were used\nto refer to enslaved African Americans, they were used in distinct ways. In the\nChronicling America corpus, we included possible OCR errors by using FastText\nembedding and excluded text reprints to consider text reprint culture in the\n19th century. Word2vec embedding was used to find semantically close words to\n\"slave\" and \"servant\" and log-odds ratio was calculated to identify\nover-represented discourse words in the Southern and Northern newspapers. We\nfound that \"slave\" is associated with socio-economic, legal, and administrative\nwords, however, \"servant\" is linked to religious words in the Northern\nnewspapers while Southern newspapers associated \"servant\" with domestic and\nfamilial words. We further found that slave discourse words in Southern\nnewspapers are more prevalent in Northern newspapers while servant discourse\nwords from each side are prevalent in their own region. This study contributes\nto the understanding of how newspapers created different discourses around\nenslaved African Americans in the 19th century US.", "published": "2025-03-19 09:49:22", "link": "http://arxiv.org/abs/2503.15057v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ELTEX: A Framework for Domain-Driven Synthetic Data Generation", "abstract": "We present ELTEX (Efficient LLM Token Extraction), a domain-driven framework\nfor generating high-quality synthetic training data in specialized domains.\nWhile Large Language Models (LLMs) have shown impressive general capabilities,\ntheir performance in specialized domains like cybersecurity remains limited by\nthe scarcity of domain-specific training data. ELTEX addresses this challenge\nby systematically integrating explicit domain indicator extraction with dynamic\nprompting to preserve critical domain knowledge throughout the generation\nprocess. We demonstrate ELTEX's effectiveness in the context of\nblockchain-related cyberattack detection, where we fine-tune Gemma-2B using\nvarious combinations of real and ELTEX-generated data. Our results show that\nthe ELTEX-enhanced model achieves performance competitive with GPT-4 across\nboth standard classification metrics and uncertainty calibration, while\nrequiring significantly fewer computational resources. We release a curated\nsynthetic dataset of social media texts for cyberattack detection in\nblockchain. Our work demonstrates that domain-driven synthetic data generation\ncan effectively bridge the performance gap between resource-efficient models\nand larger architectures in specialized domains.", "published": "2025-03-19 09:46:54", "link": "http://arxiv.org/abs/2503.15055v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SPADE: Systematic Prompt Framework for Automated Dialogue Expansion in Machine-Generated Text Detection", "abstract": "The increasing capability of large language models (LLMs) to generate\nsynthetic content has heightened concerns about their misuse, driving the\ndevelopment of Machine-Generated Text (MGT) detection models. However, these\ndetectors face significant challenges due to the lack of systematically\ngenerated, high-quality datasets for training. To address this issue, we\npropose five novel data augmentation frameworks for synthetic user dialogue\ngeneration through a structured prompting approach, reducing the costs\nassociated with traditional data collection methods. Our proposed method yields\n14 new dialogue datasets, which we benchmark against seven MGT detection\nmodels. The results demonstrate improved generalization performance when\nutilizing a mixed dataset produced by our proposed augmentation framework.\nFurthermore, considering that real-world agents lack knowledge of future\nopponent utterances, we simulate online dialogue detection and examine the\nrelationship between chat history length and detection accuracy. We also\nbenchmark online detection performance with limited chat history on our\nframeworks. Our open-source datasets can be downloaded from\nhttps://github.com/AngieYYF/SPADE-customer-service-dialogue.", "published": "2025-03-19 09:32:52", "link": "http://arxiv.org/abs/2503.15044v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM Alignment for the Arabs: A Homogenous Culture or Diverse Ones?", "abstract": "Large language models (LLMs) have the potential of being useful tools that\ncan automate tasks and assist humans. However, these models are more fluent in\nEnglish and more aligned with Western cultures, norms, and values.\nArabic-specific LLMs are being developed to better capture the nuances of the\nArabic language, as well as the views of the Arabs. Yet, Arabs are sometimes\nassumed to share the same culture. In this position paper, I discuss the\nlimitations of this assumption and provide preliminary thoughts for how to\nbuild systems that can better represent the cultural diversity within the Arab\nworld. The invalidity of the cultural homogeneity assumption might seem\nobvious, yet, it is widely adopted in developing multilingual and\nArabic-specific LLMs. I hope that this paper will encourage the NLP community\nto be considerate of the cultural diversity within various communities speaking\nthe same language.", "published": "2025-03-19 08:52:59", "link": "http://arxiv.org/abs/2503.15003v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Right Answer, Wrong Score: Uncovering the Inconsistencies of LLM Evaluation in Multiple-Choice Question Answering", "abstract": "One of the most widely used tasks to evaluate Large Language Models (LLMs) is\nMultiple-Choice Question Answering (MCQA). While open-ended question answering\ntasks are more challenging to evaluate, MCQA tasks are, in principle, easier to\nassess, as the model's answer is thought to be simple to extract and is\ndirectly compared to a set of predefined choices. However, recent studies have\nstarted to question the reliability of MCQA evaluation, showing that multiple\nfactors can significantly impact the reported performance of LLMs, especially\nwhen the model generates free-form text before selecting one of the answer\nchoices. In this work, we shed light on the inconsistencies of MCQA evaluation\nstrategies, which can lead to inaccurate and misleading model comparisons. We\nsystematically analyze whether existing answer extraction methods are aligned\nwith human judgment, and how they are influenced by answer constraints in the\nprompt across different domains. Our experiments demonstrate that traditional\nevaluation strategies often underestimate LLM capabilities, while LLM-based\nanswer extractors are prone to systematic errors. Moreover, we reveal a\nfundamental trade-off between including format constraints in the prompt to\nsimplify answer extraction and allowing models to generate free-form text to\nimprove reasoning. Our findings call for standardized evaluation methodologies\nand highlight the need for more reliable and consistent MCQA evaluation\npractices.", "published": "2025-03-19 08:45:03", "link": "http://arxiv.org/abs/2503.14996v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Inspecting the Representation Manifold of Differentially-Private Text", "abstract": "Differential Privacy (DP) for text has recently taken the form of text\nparaphrasing using language models and temperature sampling to better balance\nprivacy and utility. However, the geometric distortion of DP regarding the\nstructure and complexity in the representation space remains unexplored. By\nestimating the intrinsic dimension of paraphrased text across varying privacy\nbudgets, we find that word-level methods severely raise the representation\nmanifold, while sentence-level methods produce paraphrases whose manifolds are\ntopologically more consistent with human-written paraphrases. Among\nsentence-level methods, masked paraphrasing, compared to causal paraphrasing,\ndemonstrates superior preservation of structural complexity, suggesting that\nautoregressive generation propagates distortions from unnatural word choices\nthat cascade and inflate the representation space.", "published": "2025-03-19 08:36:58", "link": "http://arxiv.org/abs/2503.14991v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ML-Triton, A Multi-Level Compilation and Language Extension to Triton GPU Programming", "abstract": "In the era of LLMs, dense operations such as GEMM and MHA are critical\ncomponents. These operations are well-suited for parallel execution using a\ntilebased approach. While traditional GPU programming often relies on low level\ninterfaces like CUDA or SYCL, Triton has emerged as a DSL that offers a more\nuser-friendly and portable alternative by programming at a higher level. The\ncurrent Triton starts at the workgroup (aka threadblock) level, and directly\nlowers to per-thread level. And then attempt to coalesce and amend through a\nseries of passes, promoting information from low-level representation. We\nbelieve this is pre-mature lowering based on the below observations. 1. GPU has\na hierarchical structure both physically and logically. Modern GPUs often\nfeature SIMD units capable of directly operating on tiles on a warp or\nwarpgroup basis, such as blocked load and blocked MMA. 2. Multi-level gradual\nlowering can make compiler decoupled and clean by separating considerations\ninter and intra a logical layer. 3. Kernel developers often need fine control\nto get good performance on the latest hardware. FlashAttention2 advocates\nexplicit data partition between warps to make a performance boost. In this\ncontext, we propose ML-Triton which features multi-level compilation flow and\nprogramming interface. Our approach begins at the workgroup level and\nprogressively lowers to the warp and intrinsic level, implementing a multilevel\nlowering align with the hierarchical nature of GPU. Additionally, we extend\ntriton language to support user-set compiler hint and warp level programming,\nenabling researchers to get good out-of-the box performance without awaiting\ncompiler updates. Experimental results demonstrate that our approach achieves\nperformance above 95% of expert-written kernels on Intel GPU, as measured by\nthe geometric mean.", "published": "2025-03-19 08:31:39", "link": "http://arxiv.org/abs/2503.14985v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EmpathyAgent: Can Embodied Agents Conduct Empathetic Actions?", "abstract": "Empathy is fundamental to human interactions, yet it remains unclear whether\nembodied agents can provide human-like empathetic support. Existing works have\nstudied agents' tasks solving and social interactions abilities, but whether\nagents can understand empathetic needs and conduct empathetic behaviors remains\noverlooked. To address this, we introduce EmpathyAgent, the first benchmark to\nevaluate and enhance agents' empathetic actions across diverse scenarios.\nEmpathyAgent contains 10,000 multimodal samples with corresponding empathetic\ntask plans and three different challenges. To systematically evaluate the\nagents' empathetic actions, we propose an empathy-specific evaluation suite\nthat evaluates the agents' empathy process. We benchmark current models and\nfound that exhibiting empathetic actions remains a significant challenge.\nMeanwhile, we train Llama3-8B using EmpathyAgent and find it can potentially\nenhance empathetic behavior. By establishing a standard benchmark for\nevaluating empathetic actions, we hope to advance research in empathetic\nembodied agents. Our code and data are publicly available at\nhttps://github.com/xinyan-cxy/EmpathyAgent.", "published": "2025-03-19 08:30:30", "link": "http://arxiv.org/abs/2503.16545v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Covering Cracks in Content Moderation: Delexicalized Distant Supervision for Illicit Drug Jargon Detection", "abstract": "In light of rising drug-related concerns and the increasing role of social\nmedia, sales and discussions of illicit drugs have become commonplace online.\nSocial media platforms hosting user-generated content must therefore perform\ncontent moderation, which is a difficult task due to the vast amount of jargon\nused in drug discussions. Previous works on drug jargon detection were limited\nto extracting a list of terms, but these approaches have fundamental problems\nin practical application. First, they are trivially evaded using word\nsubstitutions. Second, they cannot distinguish whether euphemistic terms such\nas \"pot\" or \"crack\" are being used as drugs or in their benign meanings. We\nargue that drug content moderation should be done using contexts rather than\nrelying on a banlist. However, manually annotated datasets for training such a\ntask are not only expensive but also prone to becoming obsolete. We present\nJEDIS, a framework for detecting illicit drug jargon terms by analyzing their\ncontexts. JEDIS utilizes a novel approach that combines distant supervision and\ndelexicalization, which allows JEDIS to be trained without human-labeled data\nwhile being robust to new terms and euphemisms. Experiments on two manually\nannotated datasets show JEDIS significantly outperforms state-of-the-art\nword-based baselines in terms of F1-score and detection coverage in drug jargon\ndetection. We also conduct qualitative analysis that demonstrates JEDIS is\nrobust against pitfalls faced by existing approaches.", "published": "2025-03-19 06:26:25", "link": "http://arxiv.org/abs/2503.14926v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Causal Discovery and Counterfactual Reasoning to Optimize Persuasive Dialogue Policies", "abstract": "Tailoring persuasive conversations to users leads to more effective\npersuasion. However, existing dialogue systems often struggle to adapt to\ndynamically evolving user states. This paper presents a novel method that\nleverages causal discovery and counterfactual reasoning for optimizing system\npersuasion capability and outcomes. We employ the Greedy Relaxation of the\nSparsest Permutation (GRaSP) algorithm to identify causal relationships between\nuser and system utterance strategies, treating user strategies as states and\nsystem strategies as actions. GRaSP identifies user strategies as causal\nfactors influencing system responses, which inform Bidirectional Conditional\nGenerative Adversarial Networks (BiCoGAN) in generating counterfactual\nutterances for the system. Subsequently, we use the Dueling Double Deep\nQ-Network (D3QN) model to utilize counterfactual data to determine the best\npolicy for selecting system utterances. Our experiments with the\nPersuasionForGood dataset show measurable improvements in persuasion outcomes\nusing our approach over baseline methods. The observed increase in cumulative\nrewards and Q-values highlights the effectiveness of causal discovery in\nenhancing counterfactual reasoning and optimizing reinforcement learning\npolicies for online dialogue systems.", "published": "2025-03-19 06:06:10", "link": "http://arxiv.org/abs/2503.16544v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "MASS: Mathematical Data Selection via Skill Graphs for Pretraining Large Language Models", "abstract": "High-quality data plays a critical role in the pretraining and fine-tuning of\nlarge language models (LLMs), even determining their performance ceiling to\nsome degree. Consequently, numerous data selection methods have been proposed\nto identify subsets of data that can effectively and efficiently enhance model\nperformance. However, most of these methods focus on general data selection and\ntend to overlook the specific nuances of domain-related data. In this paper, we\nintroduce MASS, a \\textbf{MA}thematical data \\textbf{S}election framework using\nthe \\textbf{S}kill graph for pretraining LLMs in the mathematical reasoning\ndomain. By taking into account the unique characteristics of mathematics and\nreasoning, we construct a skill graph that captures the mathematical skills and\ntheir interrelations from a reference dataset. This skill graph guides us in\nassigning quality scores to the target dataset, enabling us to select the\ntop-ranked subset which is further used to pretrain LLMs. Experimental results\ndemonstrate the efficiency and effectiveness of MASS across different model\nsizes (1B and 7B) and pretraining datasets (web data and synthetic data).\nSpecifically, in terms of efficiency, models trained on subsets selected by\nMASS can achieve similar performance to models trained on the original\ndatasets, with a significant reduction in the number of trained tokens -\nranging from 50\\% to 70\\% fewer tokens. In terms of effectiveness, when trained\non the same amount of tokens, models trained on the data selected by MASS\noutperform those trained on the original datasets by 3.3\\% to 5.9\\%. These\nresults underscore the potential of MASS to improve both the efficiency and\neffectiveness of pretraining LLMs.", "published": "2025-03-19 05:50:21", "link": "http://arxiv.org/abs/2503.14917v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Deep Contrastive Unlearning for Language Models", "abstract": "The past a few years have witnessed the great success of large language\nmodels, demonstrating powerful capabilities in comprehending textual data and\ngenerating human-like languages. Large language models achieve success by being\ntrained on vast amounts of textual data, including online sources with\ncopyrighted content and user-generated knowledge. However, this comes at a\ncost: the potential risk of exposing users' privacy and violating copyright\nprotections. Thus, to safeguard individuals' \"right to be forgotten\", there has\nbeen increasing interests in machine unlearning -- the process of removing\ninformation carried by particular training samples from a model while not\ndeteriorating its predictive quality. This is a challenging task due to the\nblack-box nature of language models. Most existing studies focus on mitigating\nthe impact of those forgot samples upon a model's outputs, and do not\nexplicitly consider the geometric distributions of samples in the latent space\nof a model. To address this issue, we propose a machine unlearning framework,\nnamed Deep Contrastive Unlearning for fine-Tuning (DeepCUT) language models.\nOur proposed model achieves machine unlearning by directly optimizing the\nlatent space of a model. Comprehensive experiments on real-world datasets\ndemonstrate the effectiveness and efficiency of DeepCUT with consistent and\nsignificant improvement over baseline methods.", "published": "2025-03-19 04:58:45", "link": "http://arxiv.org/abs/2503.14900v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mitigating Object Hallucinations in MLLMs via Multi-Frequency Perturbations", "abstract": "Recently, multimodal large language models (MLLMs) have demonstrated\nremarkable performance in visual-language tasks. However, the authenticity of\nthe responses generated by MLLMs is often compromised by object hallucinations.\nWe identify that a key cause of these hallucinations is the model's\nover-susceptibility to specific image frequency features in detecting objects.\nIn this paper, we introduce Multi-Frequency Perturbations (MFP), a simple,\ncost-effective, and pluggable method that leverages both low-frequency and\nhigh-frequency features of images to perturb visual feature representations and\nexplicitly suppress redundant frequency-domain features during inference,\nthereby mitigating hallucinations. Experimental results demonstrate that our\nmethod significantly mitigates object hallucinations across various model\narchitectures. Furthermore, as a training-time method, MFP can be combined with\ninference-time methods to achieve state-of-the-art performance on the CHAIR\nbenchmark.", "published": "2025-03-19 04:39:45", "link": "http://arxiv.org/abs/2503.14895v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "MetaLadder: Ascending Mathematical Solution Quality via Analogical-Problem Reasoning Transfer", "abstract": "Large Language Models (LLMs) have demonstrated promising capabilities in\nsolving mathematical reasoning tasks, leveraging Chain-of-Thought (CoT) data as\na vital component in guiding answer generation. Current paradigms typically\ngenerate CoT and answers directly for a given problem, diverging from human\nproblem-solving strategies to some extent. Humans often solve problems by\nrecalling analogous cases and leveraging their solutions to reason about the\ncurrent task. Inspired by this cognitive process, we propose\n\\textbf{MetaLadder}, a novel framework that explicitly prompts LLMs to recall\nand reflect on meta-problems, those structurally or semantically analogous\nproblems, alongside their CoT solutions before addressing the target problem.\nAdditionally, we introduce a problem-restating mechanism to enhance the model's\ncomprehension of the target problem by regenerating the original question,\nwhich further improves reasoning accuracy. Therefore, the model can achieve\nreasoning transfer from analogical problems, mimicking human-like \"learning\nfrom examples\" and generalization abilities. Extensive experiments on\nmathematical benchmarks demonstrate that our MetaLadder significantly boosts\nLLMs' problem-solving accuracy, largely outperforming standard CoT-based\nmethods (\\textbf{10.3\\%} accuracy gain) and other methods. Our code and data\nhas been released at https://github.com/LHL3341/MetaLadder.", "published": "2025-03-19 04:36:35", "link": "http://arxiv.org/abs/2503.14891v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LogLLaMA: Transformer-based log anomaly detection with LLaMA", "abstract": "Log anomaly detection refers to the task that distinguishes the anomalous log\nmessages from normal log messages. Transformer-based large language models\n(LLMs) are becoming popular for log anomaly detection because of their superb\nability to understand complex and long language patterns. In this paper, we\npropose LogLLaMA, a novel framework that leverages LLaMA2. LogLLaMA is first\nfinetuned on normal log messages from three large-scale datasets to learn their\npatterns. After finetuning, the model is capable of generating successive log\nmessages given previous log messages. Our generative model is further trained\nto identify anomalous log messages using reinforcement learning (RL). The\nexperimental results show that LogLLaMA outperforms the state-of-the-art\napproaches for anomaly detection on BGL, Thunderbird, and HDFS datasets.", "published": "2025-03-19 03:13:37", "link": "http://arxiv.org/abs/2503.14849v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "The CLEF-2025 CheckThat! Lab: Subjectivity, Fact-Checking, Claim Normalization, and Retrieval", "abstract": "The CheckThat! lab aims to advance the development of innovative technologies\ndesigned to identify and counteract online disinformation and manipulation\nefforts across various languages and platforms. The first five editions focused\non key tasks in the information verification pipeline, including\ncheck-worthiness, evidence retrieval and pairing, and verification. Since the\n2023 edition, the lab has expanded its scope to address auxiliary tasks that\nsupport research and decision-making in verification. In the 2025 edition, the\nlab revisits core verification tasks while also considering auxiliary\nchallenges. Task 1 focuses on the identification of subjectivity (a follow-up\nfrom CheckThat! 2024), Task 2 addresses claim normalization, Task 3 targets\nfact-checking numerical claims, and Task 4 explores scientific web discourse\nprocessing. These tasks present challenging classification and retrieval\nproblems at both the document and span levels, including multilingual settings.", "published": "2025-03-19 02:06:07", "link": "http://arxiv.org/abs/2503.14828v1", "categories": ["cs.CL", "cs.AI", "68T50", "I.2; I.2.7"], "primary_category": "cs.CL"}
{"title": "MMDT: Decoding the Trustworthiness and Safety of Multimodal Foundation Models", "abstract": "Multimodal foundation models (MMFMs) play a crucial role in various\napplications, including autonomous driving, healthcare, and virtual assistants.\nHowever, several studies have revealed vulnerabilities in these models, such as\ngenerating unsafe content by text-to-image models. Existing benchmarks on\nmultimodal models either predominantly assess the helpfulness of these models,\nor only focus on limited perspectives such as fairness and privacy. In this\npaper, we present the first unified platform, MMDT (Multimodal DecodingTrust),\ndesigned to provide a comprehensive safety and trustworthiness evaluation for\nMMFMs. Our platform assesses models from multiple perspectives, including\nsafety, hallucination, fairness/bias, privacy, adversarial robustness, and\nout-of-distribution (OOD) generalization. We have designed various evaluation\nscenarios and red teaming algorithms under different tasks for each perspective\nto generate challenging data, forming a high-quality benchmark. We evaluate a\nrange of multimodal models using MMDT, and our findings reveal a series of\nvulnerabilities and areas for improvement across these perspectives. This work\nintroduces the first comprehensive and unique safety and trustworthiness\nevaluation platform for MMFMs, paving the way for developing safer and more\nreliable MMFMs and systems. Our platform and benchmark are available at\nhttps://mmdecodingtrust.github.io/.", "published": "2025-03-19 01:59:44", "link": "http://arxiv.org/abs/2503.14827v1", "categories": ["cs.CL", "cs.AI", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Poly-FEVER: A Multilingual Fact Verification Benchmark for Hallucination Detection in Large Language Models", "abstract": "Hallucinations in generative AI, particularly in Large Language Models\n(LLMs), pose a significant challenge to the reliability of multilingual\napplications. Existing benchmarks for hallucination detection focus primarily\non English and a few widely spoken languages, lacking the breadth to assess\ninconsistencies in model performance across diverse linguistic contexts. To\naddress this gap, we introduce Poly-FEVER, a large-scale multilingual fact\nverification benchmark specifically designed for evaluating hallucination\ndetection in LLMs. Poly-FEVER comprises 77,973 labeled factual claims spanning\n11 languages, sourced from FEVER, Climate-FEVER, and SciFact. It provides the\nfirst large-scale dataset tailored for analyzing hallucination patterns across\nlanguages, enabling systematic evaluation of LLMs such as ChatGPT and the LLaMA\nseries. Our analysis reveals how topic distribution and web resource\navailability influence hallucination frequency, uncovering language-specific\nbiases that impact model accuracy. By offering a multilingual benchmark for\nfact verification, Poly-FEVER facilitates cross-linguistic comparisons of\nhallucination detection and contributes to the development of more reliable,\nlanguage-inclusive AI systems. The dataset is publicly available to advance\nresearch in responsible AI, fact-checking methodologies, and multilingual NLP,\npromoting greater transparency and robustness in LLM performance. The proposed\nPoly-FEVER is available at:\nhttps://huggingface.co/datasets/HanzhiZhang/Poly-FEVER.", "published": "2025-03-19 01:46:09", "link": "http://arxiv.org/abs/2503.16541v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FACTS&EVIDENCE: An Interactive Tool for Transparent Fine-Grained Factual Verification of Machine-Generated Text", "abstract": "With the widespread consumption of AI-generated content, there has been an\nincreased focus on developing automated tools to verify the factual accuracy of\nsuch content. However, prior research and tools developed for fact verification\ntreat it as a binary classification or a linear regression problem. Although\nthis is a useful mechanism as part of automatic guardrails in systems, we argue\nthat such tools lack transparency in the prediction reasoning and diversity in\nsource evidence to provide a trustworthy user experience. We develop\nFacts&Evidence - an interactive and transparent tool for user-driven\nverification of complex text. The tool facilitates the intricate\ndecision-making involved in fact-verification, presenting its users a breakdown\nof complex input texts to visualize the credibility of individual claims along\nwith an explanation of model decisions and attribution to multiple, diverse\nevidence sources. Facts&Evidence aims to empower consumers of machine-generated\ntext and give them agency to understand, verify, selectively trust and use such\ntext.", "published": "2025-03-19 00:14:55", "link": "http://arxiv.org/abs/2503.14797v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ECLAIR: Enhanced Clarification for Interactive Responses", "abstract": "We present ECLAIR (Enhanced CLArification for Interactive Responses), a novel\nunified and end-to-end framework for interactive disambiguation in enterprise\nAI assistants. ECLAIR generates clarification questions for ambiguous user\nqueries and resolves ambiguity based on the user's response.We introduce a\ngeneralized architecture capable of integrating ambiguity information from\nmultiple downstream agents, enhancing context-awareness in resolving\nambiguities and allowing enterprise specific definition of agents. We further\ndefine agents within our system that provide domain-specific grounding\ninformation. We conduct experiments comparing ECLAIR to few-shot prompting\ntechniques and demonstrate ECLAIR's superior performance in clarification\nquestion generation and ambiguity resolution.", "published": "2025-03-19 23:04:00", "link": "http://arxiv.org/abs/2503.15739v1", "categories": ["cs.AI", "68T50", "I.2.7; H.5.2"], "primary_category": "cs.AI"}
{"title": "Reinforcement Learning Environment with LLM-Controlled Adversary in D&D 5th Edition Combat", "abstract": "The objective of this study is to design and implement a reinforcement\nlearning (RL) environment using D\\&D 5E combat scenarios to challenge smaller\nRL agents through interaction with a robust adversarial agent controlled by\nadvanced Large Language Models (LLMs) like GPT-4o and LLaMA 3 8B. This research\nemploys Deep Q-Networks (DQN) for the smaller agents, creating a testbed for\nstrategic AI development that also serves as an educational tool by simulating\ndynamic and unpredictable combat scenarios. We successfully integrated\nsophisticated language models into the RL framework, enhancing strategic\ndecision-making processes. Our results indicate that while RL agents generally\noutperform LLM-controlled adversaries in standard metrics, the strategic depth\nprovided by LLMs significantly enhances the overall AI capabilities in this\ncomplex, rule-based setting. The novelty of our approach and its implications\nfor mastering intricate environments and developing adaptive strategies are\ndiscussed, alongside potential innovations in AI-driven interactive\nsimulations. This paper aims to demonstrate how integrating LLMs can create\nmore robust and adaptable AI systems, providing valuable insights for further\nresearch and educational applications.", "published": "2025-03-19 22:48:20", "link": "http://arxiv.org/abs/2503.15726v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Reward Training Wheels: Adaptive Auxiliary Rewards for Robotics Reinforcement Learning", "abstract": "Robotics Reinforcement Learning (RL) often relies on carefully engineered\nauxiliary rewards to supplement sparse primary learning objectives to\ncompensate for the lack of large-scale, real-world, trial-and-error data. While\nthese auxiliary rewards accelerate learning, they require significant\nengineering effort, may introduce human biases, and cannot adapt to the robot's\nevolving capabilities during training. In this paper, we introduce Reward\nTraining Wheels (RTW), a teacher-student framework that automates auxiliary\nreward adaptation for robotics RL. To be specific, the RTW teacher dynamically\nadjusts auxiliary reward weights based on the student's evolving capabilities\nto determine which auxiliary reward aspects require more or less emphasis to\nimprove the primary objective. We demonstrate RTW on two challenging robot\ntasks: navigation in highly constrained spaces and off-road vehicle mobility on\nvertically challenging terrain. In simulation, RTW outperforms expert-designed\nrewards by 2.35% in navigation success rate and improves off-road mobility\nperformance by 122.62%, while achieving 35% and 3X faster training efficiency,\nrespectively. Physical robot experiments further validate RTW's effectiveness,\nachieving a perfect success rate (5/5 trials vs. 2/5 for expert-designed\nrewards) and improving vehicle stability with up to 47.4% reduction in\norientation angles.", "published": "2025-03-19 22:45:59", "link": "http://arxiv.org/abs/2503.15724v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Safety Aware Task Planning via Large Language Models in Robotics", "abstract": "The integration of large language models (LLMs) into robotic task planning\nhas unlocked better reasoning capabilities for complex, long-horizon workflows.\nHowever, ensuring safety in LLM-driven plans remains a critical challenge, as\nthese models often prioritize task completion over risk mitigation. This paper\nintroduces SAFER (Safety-Aware Framework for Execution in Robotics), a\nmulti-LLM framework designed to embed safety awareness into robotic task\nplanning. SAFER employs a Safety Agent that operates alongside the primary task\nplanner, providing safety feedback. Additionally, we introduce LLM-as-a-Judge,\na novel metric leveraging LLMs as evaluators to quantify safety violations\nwithin generated task plans. Our framework integrates safety feedback at\nmultiple stages of execution, enabling real-time risk assessment, proactive\nerror correction, and transparent safety evaluation. We also integrate a\ncontrol framework using Control Barrier Functions (CBFs) to ensure safety\nguarantees within SAFER's task planning. We evaluated SAFER against\nstate-of-the-art LLM planners on complex long-horizon tasks involving\nheterogeneous robotic agents, demonstrating its effectiveness in reducing\nsafety violations while maintaining task efficiency. We also verify the task\nplanner and safety planner through actual hardware experiments involving\nmultiple robots and a human.", "published": "2025-03-19 21:41:10", "link": "http://arxiv.org/abs/2503.15707v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Predicting Multi-Agent Specialization via Task Parallelizability", "abstract": "Multi-agent systems often rely on specialized agents with distinct roles\nrather than general-purpose agents that perform the entire task independently.\nHowever, the conditions that govern the optimal degree of specialization remain\npoorly understood. In this work, we propose that specialist teams outperform\ngeneralist ones when environmental constraints limit task parallelizability --\nthe potential to execute task components concurrently. Drawing inspiration from\ndistributed systems, we introduce a heuristic to predict the relative\nefficiency of generalist versus specialist teams by estimating the speed-up\nachieved when two agents perform a task in parallel rather than focus on\ncomplementary subtasks. We validate this heuristic through three multi-agent\nreinforcement learning (MARL) experiments in Overcooked-AI, demonstrating that\nkey factors limiting task parallelizability influence specialization. We also\nobserve that as the state space expands, agents tend to converge on specialist\nstrategies, even when generalist ones are theoretically more efficient,\nhighlighting potential biases in MARL training algorithms. Our findings provide\na principled framework for interpreting specialization given the task and\nenvironment, and introduce a novel benchmark for evaluating whether MARL finds\noptimal strategies.", "published": "2025-03-19 21:33:48", "link": "http://arxiv.org/abs/2503.15703v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "Representational Similarity via Interpretable Visual Concepts", "abstract": "How do two deep neural networks differ in how they arrive at a decision?\nMeasuring the similarity of deep networks has been a long-standing open\nquestion. Most existing methods provide a single number to measure the\nsimilarity of two networks at a given layer, but give no insight into what\nmakes them similar or dissimilar. We introduce an interpretable\nrepresentational similarity method (RSVC) to compare two networks. We use RSVC\nto discover shared and unique visual concepts between two models. We show that\nsome aspects of model differences can be attributed to unique concepts\ndiscovered by one model that are not well represented in the other. Finally, we\nconduct extensive evaluation across different vision model architectures and\ntraining protocols to demonstrate its effectiveness.", "published": "2025-03-19 21:21:45", "link": "http://arxiv.org/abs/2503.15699v2", "categories": ["cs.CV", "cs.AI", "q-bio.NC"], "primary_category": "cs.CV"}
{"title": "R$^2$: A LLM Based Novel-to-Screenplay Generation Framework with Causal Plot Graphs", "abstract": "Automatically adapting novels into screenplays is important for the TV, film,\nor opera industries to promote products with low costs. The strong performances\nof large language models (LLMs) in long-text generation call us to propose a\nLLM based framework Reader-Rewriter (R$^2$) for this task. However, there are\ntwo fundamental challenges here. First, the LLM hallucinations may cause\ninconsistent plot extraction and screenplay generation. Second, the\ncausality-embedded plot lines should be effectively extracted for coherent\nrewriting. Therefore, two corresponding tactics are proposed: 1) A\nhallucination-aware refinement method (HAR) to iteratively discover and\neliminate the affections of hallucinations; and 2) a causal plot-graph\nconstruction method (CPC) based on a greedy cycle-breaking algorithm to\nefficiently construct plot lines with event causalities. Recruiting those\nefficient techniques, R$^2$ utilizes two modules to mimic the human screenplay\nrewriting process: The Reader module adopts a sliding window and CPC to build\nthe causal plot graphs, while the Rewriter module generates first the scene\noutlines based on the graphs and then the screenplays. HAR is integrated into\nboth modules for accurate inferences of LLMs. Experimental results demonstrate\nthe superiority of R$^2$, which substantially outperforms three existing\napproaches (51.3%, 22.6%, and 57.1% absolute increases) in pairwise comparison\nat the overall win rate for GPT-4o.", "published": "2025-03-19 19:09:40", "link": "http://arxiv.org/abs/2503.15655v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Reliable Radiologic Skeletal Muscle Area Assessment -- A Biomarker for Cancer Cachexia Diagnosis", "abstract": "Cancer cachexia is a common metabolic disorder characterized by severe muscle\natrophy which is associated with poor prognosis and quality of life. Monitoring\nskeletal muscle area (SMA) longitudinally through computed tomography (CT)\nscans, an imaging modality routinely acquired in cancer care, is an effective\nway to identify and track this condition. However, existing tools often lack\nfull automation and exhibit inconsistent accuracy, limiting their potential for\nintegration into clinical workflows. To address these challenges, we developed\nSMAART-AI (Skeletal Muscle Assessment-Automated and Reliable Tool-based on AI),\nan end-to-end automated pipeline powered by deep learning models (nnU-Net 2D)\ntrained on mid-third lumbar level CT images with 5-fold cross-validation,\nensuring generalizability and robustness. SMAART-AI incorporates an\nuncertainty-based mechanism to flag high-error SMA predictions for expert\nreview, enhancing reliability. We combined the SMA, skeletal muscle index, BMI,\nand clinical data to train a multi-layer perceptron (MLP) model designed to\npredict cachexia at the time of cancer diagnosis. Tested on the\ngastroesophageal cancer dataset, SMAART-AI achieved a Dice score of 97.80% +/-\n0.93%, with SMA estimated across all four datasets in this study at a median\nabsolute error of 2.48% compared to manual annotations with SliceOmatic.\nUncertainty metrics-variance, entropy, and coefficient of variation-strongly\ncorrelated with SMA prediction errors (0.83, 0.76, and 0.73 respectively). The\nMLP model predicts cachexia with 79% precision, providing clinicians with a\nreliable tool for early diagnosis and intervention. By combining automation,\naccuracy, and uncertainty awareness, SMAART-AI bridges the gap between research\nand clinical application, offering a transformative approach to managing cancer\ncachexia.", "published": "2025-03-19 19:07:59", "link": "http://arxiv.org/abs/2503.16556v1", "categories": ["eess.IV", "cs.AI", "cs.CE", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Survey on Generalization Theory for Graph Neural Networks", "abstract": "Message-passing graph neural networks (MPNNs) have emerged as the leading\napproach for machine learning on graphs, attracting significant attention in\nrecent years. While a large set of works explored the expressivity of MPNNs,\ni.e., their ability to separate graphs and approximate functions over them,\ncomparatively less attention has been directed toward investigating their\ngeneralization abilities, i.e., making meaningful predictions beyond the\ntraining data. Here, we systematically review the existing literature on the\ngeneralization abilities of MPNNs. We analyze the strengths and limitations of\nvarious studies in these domains, providing insights into their methodologies\nand findings. Furthermore, we identify potential avenues for future research,\naiming to deepen our understanding of the generalization abilities of MPNNs.", "published": "2025-03-19 19:04:24", "link": "http://arxiv.org/abs/2503.15650v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "AEJIM: A Real-Time AI Framework for Crowdsourced, Transparent, and Ethical Environmental Hazard Detection and Reporting", "abstract": "Environmental journalism is vital for raising awareness of ecological crises\nand driving evidence-based policy, yet traditional methods falter under delays,\ninaccuracies, and scalability limits, especially in under-monitored regions\ncritical to the United Nations Sustainable Development Goals. To bridge these\ngaps, this paper introduces the AI-Environmental Journalism Integration Model\n(AEJIM), an innovative framework combining real-time hazard detection,\nautomated reporting, crowdsourced validation, expert review, and transparent\ndissemination.\n  Validated through a pilot study on Mallorca, AEJIM significantly improved the\nspeed, accuracy, and transparency of environmental hazard reporting compared to\ntraditional methods. Furthermore, the model directly addresses key ethical,\nregulatory, and scalability challenges, ensuring accountability through\nExplainable AI (XAI), GDPR-compliant data governance, and active public\nparticipation. AEJIM's modular and technology-agnostic design provides a\ntransparent and adaptable solution, setting a new benchmark for AI-enhanced\nenvironmental journalism and supporting informed global decision-making across\ndiverse socio-political landscapes.", "published": "2025-03-19 19:00:24", "link": "http://arxiv.org/abs/2503.17401v2", "categories": ["cs.CY", "cs.AI", "cs.HC", "J.4; I.2.10; I.2.7; H.3.4; H.5.2"], "primary_category": "cs.CY"}
{"title": "A Context-Driven Training-Free Network for Lightweight Scene Text Segmentation and Recognition", "abstract": "Modern scene text recognition systems often depend on large end-to-end\narchitectures that require extensive training and are prohibitively expensive\nfor real-time scenarios. In such cases, the deployment of heavy models becomes\nimpractical due to constraints on memory, computational resources, and latency.\nTo address these challenges, we propose a novel, training-free plug-and-play\nframework that leverages the strengths of pre-trained text recognizers while\nminimizing redundant computations. Our approach uses context-based\nunderstanding and introduces an attention-based segmentation stage, which\nrefines candidate text regions at the pixel level, improving downstream\nrecognition. Instead of performing traditional text detection that follows a\nblock-level comparison between feature map and source image and harnesses\ncontextual information using pretrained captioners, allowing the framework to\ngenerate word predictions directly from scene context.Candidate texts are\nsemantically and lexically evaluated to get a final score. Predictions that\nmeet or exceed a pre-defined confidence threshold bypass the heavier process of\nend-to-end text STR profiling, ensuring faster inference and cutting down on\nunnecessary computations. Experiments on public benchmarks demonstrate that our\nparadigm achieves performance on par with state-of-the-art systems, yet\nrequires substantially fewer resources.", "published": "2025-03-19 18:51:01", "link": "http://arxiv.org/abs/2503.15639v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Neural Lyapunov Function Approximation with Self-Supervised Reinforcement Learning", "abstract": "Control Lyapunov functions are traditionally used to design a controller\nwhich ensures convergence to a desired state, yet deriving these functions for\nnonlinear systems remains a complex challenge. This paper presents a novel,\nsample-efficient method for neural approximation of nonlinear Lyapunov\nfunctions, leveraging self-supervised Reinforcement Learning (RL) to enhance\ntraining data generation, particularly for inaccurately represented regions of\nthe state space. The proposed approach employs a data-driven World Model to\ntrain Lyapunov functions from off-policy trajectories. The method is validated\non both standard and goal-conditioned robotic tasks, demonstrating faster\nconvergence and higher approximation accuracy compared to the state-of-the-art\nneural Lyapunov approximation baseline. The code is available at:\nhttps://github.com/CAV-Research-Lab/SACLA.git", "published": "2025-03-19 18:29:25", "link": "http://arxiv.org/abs/2503.15629v1", "categories": ["cs.RO", "cs.AI", "cs.CG", "cs.LG"], "primary_category": "cs.RO"}
{"title": "CAM-Seg: A Continuous-valued Embedding Approach for Semantic Image Generation", "abstract": "Traditional transformer-based semantic segmentation relies on quantized\nembeddings. However, our analysis reveals that autoencoder accuracy on\nsegmentation mask using quantized embeddings (e.g. VQ-VAE) is 8% lower than\ncontinuous-valued embeddings (e.g. KL-VAE). Motivated by this, we propose a\ncontinuous-valued embedding framework for semantic segmentation. By\nreformulating semantic mask generation as a continuous image-to-embedding\ndiffusion process, our approach eliminates the need for discrete latent\nrepresentations while preserving fine-grained spatial and semantic details. Our\nkey contribution includes a diffusion-guided autoregressive transformer that\nlearns a continuous semantic embedding space by modeling long-range\ndependencies in image features. Our framework contains a unified architecture\ncombining a VAE encoder for continuous feature extraction, a diffusion-guided\ntransformer for conditioned embedding generation, and a VAE decoder for\nsemantic mask reconstruction. Our setting facilitates zero-shot domain\nadaptation capabilities enabled by the continuity of the embedding space.\nExperiments across diverse datasets (e.g., Cityscapes and domain-shifted\nvariants) demonstrate state-of-the-art robustness to distribution shifts,\nincluding adverse weather (e.g., fog, snow) and viewpoint variations. Our model\nalso exhibits strong noise resilience, achieving robust performance ($\\approx$\n95% AP compared to baseline) under gaussian noise, moderate motion blur, and\nmoderate brightness/contrast variations, while experiencing only a moderate\nimpact ($\\approx$ 90% AP compared to baseline) from 50% salt and pepper noise,\nsaturation and hue shifts. Code available:\nhttps://github.com/mahmed10/CAMSS.git", "published": "2025-03-19 18:06:54", "link": "http://arxiv.org/abs/2503.15617v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "PEnGUiN: Partially Equivariant Graph NeUral Networks for Sample Efficient MARL", "abstract": "Equivariant Graph Neural Networks (EGNNs) have emerged as a promising\napproach in Multi-Agent Reinforcement Learning (MARL), leveraging symmetry\nguarantees to greatly improve sample efficiency and generalization. However,\nreal-world environments often exhibit inherent asymmetries arising from factors\nsuch as external forces, measurement inaccuracies, or intrinsic system biases.\nThis paper introduces \\textit{Partially Equivariant Graph NeUral Networks\n(PEnGUiN)}, a novel architecture specifically designed to address these\nchallenges. We formally identify and categorize various types of partial\nequivariance relevant to MARL, including subgroup equivariance, feature-wise\nequivariance, regional equivariance, and approximate equivariance. We\ntheoretically demonstrate that PEnGUiN is capable of learning both fully\nequivariant (EGNN) and non-equivariant (GNN) representations within a unified\nframework. Through extensive experiments on a range of MARL problems\nincorporating various asymmetries, we empirically validate the efficacy of\nPEnGUiN. Our results consistently demonstrate that PEnGUiN outperforms both\nEGNNs and standard GNNs in asymmetric environments, highlighting their\npotential to improve the robustness and applicability of graph-based MARL\nalgorithms in real-world scenarios.", "published": "2025-03-19 18:01:14", "link": "http://arxiv.org/abs/2503.15615v1", "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "cs.LG"}
{"title": "Learning to Play Piano in the Real World", "abstract": "Towards the grand challenge of achieving human-level manipulation in robots,\nplaying piano is a compelling testbed that requires strategic, precise, and\nflowing movements. Over the years, several works demonstrated hand-designed\ncontrollers on real world piano playing, while other works evaluated robot\nlearning approaches on simulated piano scenarios. In this paper, we develop the\nfirst piano playing robotic system that makes use of learning approaches while\nalso being deployed on a real world dexterous robot. Specifically, we make use\nof Sim2Real to train a policy in simulation using reinforcement learning before\ndeploying the learned policy on a real world dexterous robot. In our\nexperiments, we thoroughly evaluate the interplay between domain randomization\nand the accuracy of the dynamics model used in simulation. Moreover, we\nevaluate the robot's performance across multiple songs with varying complexity\nto study the generalization of our learned policy. By providing a\nproof-of-concept of learning to play piano in the real world, we want to\nencourage the community to adopt piano playing as a compelling benchmark\ntowards human-level manipulation. We open-source our code and show additional\nvideos at https://lasr.org/research/learning-to-play-piano .", "published": "2025-03-19 17:56:14", "link": "http://arxiv.org/abs/2503.15481v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "EgoDTM: Towards 3D-Aware Egocentric Video-Language Pretraining", "abstract": "Egocentric video-language pretraining has significantly advanced video\nrepresentation learning. Humans perceive and interact with a fully 3D world,\ndeveloping spatial awareness that extends beyond text-based understanding.\nHowever, most previous works learn from 1D text or 2D visual cues, such as\nbounding boxes, which inherently lack 3D understanding. To bridge this gap, we\nintroduce EgoDTM, an Egocentric Depth- and Text-aware Model, jointly trained\nthrough large-scale 3D-aware video pretraining and video-text contrastive\nlearning. EgoDTM incorporates a lightweight 3D-aware decoder to efficiently\nlearn 3D-awareness from pseudo depth maps generated by depth estimation models.\nTo further facilitate 3D-aware video pretraining, we enrich the original brief\ncaptions with hand-object visual cues by organically combining several\nfoundation models. Extensive experiments demonstrate EgoDTM's superior\nperformance across diverse downstream tasks, highlighting its superior 3D-aware\nvisual understanding. Our code will be released at\nhttps://github.com/xuboshen/EgoDTM.", "published": "2025-03-19 17:45:56", "link": "http://arxiv.org/abs/2503.15470v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Di$\\mathtt{[M]}$O: Distilling Masked Diffusion Models into One-step Generator", "abstract": "Masked Diffusion Models (MDMs) have emerged as a powerful generative modeling\ntechnique. Despite their remarkable results, they typically suffer from slow\ninference with several steps. In this paper, we propose Di$\\mathtt{[M]}$O, a\nnovel approach that distills masked diffusion models into a one-step generator.\nDi$\\mathtt{[M]}$O addresses two key challenges: (1) the intractability of using\nintermediate-step information for one-step generation, which we solve through\ntoken-level distribution matching that optimizes model output logits by an\n'on-policy framework' with the help of an auxiliary model; and (2) the lack of\nentropy in the initial distribution, which we address through a token\ninitialization strategy that injects randomness while maintaining similarity to\nteacher training distribution. We show Di$\\mathtt{[M]}$O's effectiveness on\nboth class-conditional and text-conditional image generation, impressively\nachieving performance competitive to multi-step teacher outputs while\ndrastically reducing inference time. To our knowledge, we are the first to\nsuccessfully achieve one-step distillation of masked diffusion models and the\nfirst to apply discrete distillation to text-to-image generation, opening new\npaths for efficient generative modeling.", "published": "2025-03-19 17:36:54", "link": "http://arxiv.org/abs/2503.15457v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "An extensive simulation study evaluating the interaction of resampling techniques across multiple causal discovery contexts", "abstract": "Despite the accelerating presence of exploratory causal analysis in modern\nscience and medicine, the available non-experimental methods for validating\ncausal models are not well characterized. One of the most popular methods is to\nevaluate the stability of model features after resampling the data, similar to\nresampling methods for estimating confidence intervals in statistics. Many\naspects of this approach have received little to no attention, however, such as\nwhether the choice of resampling method should depend on the sample size,\nalgorithms being used, or algorithm tuning parameters. We present theoretical\nresults proving that certain resampling methods closely emulate the assignment\nof specific values to algorithm tuning parameters. We also report the results\nof extensive simulation experiments, which verify the theoretical result and\nprovide substantial data to aid researchers in further characterizing\nresampling in the context of causal discovery analysis. Together, the\ntheoretical work and simulation results provide specific guidance on how\nresampling methods and tuning parameters should be selected in practice.", "published": "2025-03-19 17:18:18", "link": "http://arxiv.org/abs/2503.15436v1", "categories": ["stat.ME", "cs.AI"], "primary_category": "stat.ME"}
{"title": "Visual Position Prompt for MLLM based Visual Grounding", "abstract": "Although Multimodal Large Language Models (MLLMs) excel at various\nimage-related tasks, they encounter challenges in precisely aligning\ncoordinates with spatial information within images, particularly in\nposition-aware tasks such as visual grounding. This limitation arises from two\nkey factors. First, MLLMs lack explicit spatial references, making it difficult\nto associate textual descriptions with precise image locations. Second, their\nfeature extraction processes prioritize global context over fine-grained\nspatial details, leading to weak localization capability. To address this\nissue, we introduce VPP-LLaVA, an MLLM equipped with Visual Position Prompt\n(VPP) to improve its grounding capability. VPP-LLaVA integrates two\ncomplementary mechanisms. The global VPP overlays learnable, axis-like\nembeddings onto the input image to provide structured spatial cues. The local\nVPP focuses on fine-grained localization by incorporating position-aware\nqueries, which suggests probable object locations. We also introduce a VPP-SFT\ndataset with 0.6M samples, consolidating high-quality visual grounding data\ninto a compact format for efficient model training. Training on this dataset\nwith VPP enhances the model's performance, achieving state-of-the-art results\non standard grounding benchmarks despite using fewer training samples compared\nto other MLLMs like MiniGPT-v2, which rely on much larger datasets ($\\sim$21M\nsamples). The code and VPP-SFT dataset will be available at\nhttps://github.com/WayneTomas/VPP-LLaVA upon acceptance.", "published": "2025-03-19 17:08:13", "link": "http://arxiv.org/abs/2503.15426v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Probing the topology of the space of tokens with structured prompts", "abstract": "This article presents a general and flexible method for prompting a large\nlanguage model (LLM) to reveal its (hidden) token input embedding up to\nhomeomorphism. Moreover, this article provides strong theoretical justification\n-- a mathematical proof for generic LLMs -- for why this method should be\nexpected to work. With this method in hand, we demonstrate its effectiveness by\nrecovering the token subspace of Llemma-7B. The results of this paper apply not\nonly to LLMs but also to general nonlinear autoregressive processes.", "published": "2025-03-19 17:01:15", "link": "http://arxiv.org/abs/2503.15421v1", "categories": ["math.DG", "cs.AI", "53Z50, 58Z05", "I.2.7"], "primary_category": "math.DG"}
{"title": "Temporal Regularization Makes Your Video Generator Stronger", "abstract": "Temporal quality is a critical aspect of video generation, as it ensures\nconsistent motion and realistic dynamics across frames. However, achieving high\ntemporal coherence and diversity remains challenging. In this work, we explore\ntemporal augmentation in video generation for the first time, and introduce\nFluxFlow for initial investigation, a strategy designed to enhance temporal\nquality. Operating at the data level, FluxFlow applies controlled temporal\nperturbations without requiring architectural modifications. Extensive\nexperiments on UCF-101 and VBench benchmarks demonstrate that FluxFlow\nsignificantly improves temporal coherence and diversity across various video\ngeneration models, including U-Net, DiT, and AR-based architectures, while\npreserving spatial fidelity. These findings highlight the potential of temporal\naugmentation as a simple yet effective approach to advancing video generation\nquality.", "published": "2025-03-19 16:59:32", "link": "http://arxiv.org/abs/2503.15417v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Automated Processing of eXplainable Artificial Intelligence Outputs in Deep Learning Models for Fault Diagnostics of Large Infrastructures", "abstract": "Deep Learning (DL) models processing images to recognize the health state of\nlarge infrastructure components can exhibit biases and rely on non-causal\nshortcuts. eXplainable Artificial Intelligence (XAI) can address these issues\nbut manually analyzing explanations generated by XAI techniques is\ntime-consuming and prone to errors. This work proposes a novel framework that\ncombines post-hoc explanations with semi-supervised learning to automatically\nidentify anomalous explanations that deviate from those of correctly classified\nimages and may therefore indicate model abnormal behaviors. This significantly\nreduces the workload for maintenance decision-makers, who only need to manually\nreclassify images flagged as having anomalous explanations. The proposed\nframework is applied to drone-collected images of insulator shells for power\ngrid infrastructure monitoring, considering two different Convolutional Neural\nNetworks (CNNs), GradCAM explanations and Deep Semi-Supervised Anomaly\nDetection. The average classification accuracy on two faulty classes is\nimproved by 8% and maintenance operators are required to manually reclassify\nonly 15% of the images. We compare the proposed framework with a\nstate-of-the-art approach based on the faithfulness metric: the experimental\nresults obtained demonstrate that the proposed framework consistently achieves\nF_1 scores larger than those of the faithfulness-based approach. Additionally,\nthe proposed framework successfully identifies correct classifications that\nresult from non-causal shortcuts, such as the presence of ID tags printed on\ninsulator shells.", "published": "2025-03-19 16:57:00", "link": "http://arxiv.org/abs/2503.15415v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Towards efficient keyword spotting using spike-based time difference encoders", "abstract": "Keyword spotting in edge devices is becoming increasingly important as\nvoice-activated assistants are widely used. However, its deployment is often\nlimited by the extreme low-power constraints of the target embedded systems.\nHere, we explore the Temporal Difference Encoder (TDE) performance in keyword\nspotting. This recent neuron model encodes the time difference in instantaneous\nfrequency and spike count to perform efficient keyword spotting with\nneuromorphic processors. We use the TIdigits dataset of spoken digits with a\nformant decomposition and rate-based encoding into spikes. We compare three\nSpiking Neural Networks (SNNs) architectures to learn and classify\nspatio-temporal signals. The proposed SNN architectures are made of three\nlayers with variation in its hidden layer composed of either (1) feedforward\nTDE, (2) feedforward Current-Based Leaky Integrate-and-Fire (CuBa-LIF), or (3)\nrecurrent CuBa-LIF neurons. We first show that the spike trains of the\nfrequency-converted spoken digits have a large amount of information in the\ntemporal domain, reinforcing the importance of better exploiting temporal\nencoding for such a task. We then train the three SNNs with the same number of\nsynaptic weights to quantify and compare their performance based on the\naccuracy and synaptic operations. The resulting accuracy of the feedforward TDE\nnetwork (89%) is higher than the feedforward CuBa-LIF network (71%) and close\nto the recurrent CuBa-LIF network (91%). However, the feedforward TDE-based\nnetwork performs 92% fewer synaptic operations than the recurrent CuBa-LIF\nnetwork with the same amount of synapses. In addition, the results of the TDE\nnetwork are highly interpretable and correlated with the frequency and\ntimescale features of the spoken keywords in the dataset. Our findings suggest\nthat the TDE is a promising neuron model for scalable event-driven processing\nof spatio-temporal patterns.", "published": "2025-03-19 16:43:35", "link": "http://arxiv.org/abs/2503.15402v1", "categories": ["cs.NE", "cs.AI", "cs.CV", "cs.ET"], "primary_category": "cs.NE"}
{"title": "CCDP: Composition of Conditional Diffusion Policies with Guided Sampling", "abstract": "Imitation Learning offers a promising approach to learn directly from data\nwithout requiring explicit models, simulations, or detailed task definitions.\nDuring inference, actions are sampled from the learned distribution and\nexecuted on the robot. However, sampled actions may fail for various reasons,\nand simply repeating the sampling step until a successful action is obtained\ncan be inefficient. In this work, we propose an enhanced sampling strategy that\nrefines the sampling distribution to avoid previously unsuccessful actions. We\ndemonstrate that by solely utilizing data from successful demonstrations, our\nmethod can infer recovery actions without the need for additional exploratory\nbehavior or a high-level controller. Furthermore, we leverage the concept of\ndiffusion model decomposition to break down the primary problem (which may\nrequire long-horizon history to manage failures) into multiple smaller, more\nmanageable sub-problems in learning, data collection, and inference, thereby\nenabling the system to adapt to variable failure counts. Our approach yields a\nlow-level controller that dynamically adjusts its sampling space to improve\nefficiency when prior samples fall short. We validate our method across several\ntasks, including door opening with unknown directions, object manipulation, and\nbutton-searching scenarios, demonstrating that our approach outperforms\ntraditional baselines.", "published": "2025-03-19 16:24:55", "link": "http://arxiv.org/abs/2503.15386v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Leveraging Perfect Multimodal Alignment and Gaussian Assumptions for Cross-modal Transfer", "abstract": "Multimodal alignment aims to construct a joint latent vector space where two\nmodalities representing the same concept map to the same vector. We formulate\nthis as an inverse problem and show that under certain conditions perfect\nalignment can be achieved. We then address a specific application of alignment\nreferred to as cross-modal transfer. Unsupervised cross-modal transfer aims to\nleverage a model trained with one modality to perform inference on another\nmodality, without any labeled fine-tuning on the new modality. Assuming that\nsemantic classes are represented as a mixture of Gaussians in the latent space,\nwe show how cross-modal transfer can be performed by projecting the data points\nfrom the representation space onto different subspaces representing each\nmodality. Our experiments on synthetic multimodal Gaussian data verify the\neffectiveness of our perfect alignment and cross-modal transfer method. We hope\nthese findings inspire further exploration of the applications of perfect\nalignment and the use of Gaussian models for cross-modal learning.", "published": "2025-03-19 15:51:17", "link": "http://arxiv.org/abs/2503.15352v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "eess.SP"], "primary_category": "cs.LG"}
{"title": "TruthLens:A Training-Free Paradigm for DeepFake Detection", "abstract": "The proliferation of synthetic images generated by advanced AI models poses\nsignificant challenges in identifying and understanding manipulated visual\ncontent. Current fake image detection methods predominantly rely on binary\nclassification models that focus on accuracy while often neglecting\ninterpretability, leaving users without clear insights into why an image is\ndeemed real or fake. To bridge this gap, we introduce TruthLens, a novel\ntraining-free framework that reimagines deepfake detection as a visual\nquestion-answering (VQA) task. TruthLens utilizes state-of-the-art large\nvision-language models (LVLMs) to observe and describe visual artifacts and\ncombines this with the reasoning capabilities of large language models (LLMs)\nlike GPT-4 to analyze and aggregate evidence into informed decisions. By\nadopting a multimodal approach, TruthLens seamlessly integrates visual and\nsemantic reasoning to not only classify images as real or fake but also provide\ninterpretable explanations for its decisions. This transparency enhances trust\nand provides valuable insights into the artifacts that signal synthetic\ncontent. Extensive evaluations demonstrate that TruthLens outperforms\nconventional methods, achieving high accuracy on challenging datasets while\nmaintaining a strong emphasis on explainability. By reframing deepfake\ndetection as a reasoning-driven process, TruthLens establishes a new paradigm\nin combating synthetic media, combining cutting-edge performance with\ninterpretability to address the growing threats of visual disinformation.", "published": "2025-03-19 15:41:32", "link": "http://arxiv.org/abs/2503.15342v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Challenges and Trends in Egocentric Vision: A Survey", "abstract": "With the rapid development of artificial intelligence technologies and\nwearable devices, egocentric vision understanding has emerged as a new and\nchallenging research direction, gradually attracting widespread attention from\nboth academia and industry. Egocentric vision captures visual and multimodal\ndata through cameras or sensors worn on the human body, offering a unique\nperspective that simulates human visual experiences. This paper provides a\ncomprehensive survey of the research on egocentric vision understanding,\nsystematically analyzing the components of egocentric scenes and categorizing\nthe tasks into four main areas: subject understanding, object understanding,\nenvironment understanding, and hybrid understanding. We explore in detail the\nsub-tasks within each category. We also summarize the main challenges and\ntrends currently existing in the field. Furthermore, this paper presents an\noverview of high-quality egocentric vision datasets, offering valuable\nresources for future research. By summarizing the latest advancements, we\nanticipate the broad applications of egocentric vision technologies in fields\nsuch as augmented reality, virtual reality, and embodied intelligence, and\npropose future research directions based on the latest developments in the\nfield.", "published": "2025-03-19 14:51:27", "link": "http://arxiv.org/abs/2503.15275v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "How Well Can AI Build SD Models?", "abstract": "Introduction: As system dynamics (SD) embraces automation, AI offers\nefficiency but risks bias from missing data and flawed models. Models that omit\nmultiple perspectives and data threaten model quality, whether created by\nhumans or with the assistance of AI. To reduce uncertainty about how well AI\ncan build SD models, we introduce two metrics for evaluation of AI-generated\ncausal maps: technical correctness (causal translation) and adherence to\ninstructions (conformance).\n  Approach: We developed an open source project called sd-ai to provide a basis\nfor collaboration in the SD community, aiming to fully harness the potential of\nAI based tools like ChatGPT for dynamic modeling. Additionally, we created an\nevaluation theory along with a comprehensive suite of tests designed to\nevaluate any such tools developed within the sd-ai ecosystem.\n  Results: We tested 11 different LLMs on their ability to do causal\ntranslation as well as conform to user instruction. gpt-4.5-preview was the top\nperformer, scoring 92.9% overall, excelling in both tasks. o1 scored 100% in\ncausal translation. gpt-4o identified all causal links but struggled with\npositive polarity in decreasing terms. While gpt-4.5-preview and o1 are most\naccurate, gpt-4o is the cheapest.\n  Discussion: Causal translation and conformance tests applied to the sd-ai\nengine reveal significant variations across lLLMs, underscoring the need for\ncontinued evaluation to ensure responsible development of AI tools for dynamic\nmodeling. To address this, an open collaboration among tool developers,\nmodelers, and stakeholders is launched to standardize measures for evaluating\nthe capacity of AI tools to improve the modeling process.", "published": "2025-03-19 14:48:47", "link": "http://arxiv.org/abs/2503.15580v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Do Chains-of-Thoughts of Large Language Models Suffer from Hallucinations, Cognitive Biases, or Phobias in Bayesian Reasoning?", "abstract": "Learning to reason and carefully explain arguments is central to students'\ncognitive, mathematical, and computational thinking development. This is\nparticularly challenging in problems under uncertainty and in Bayesian\nreasoning. With the new generation of large language models (LLMs) capable of\nreasoning using Chain-of-Thought (CoT), there is an excellent opportunity to\nlearn with them as they explain their reasoning through a dialogue with their\nartificial internal voice. It is an engaging and excellent opportunity to learn\nBayesian reasoning. Furthermore, given that different LLMs sometimes arrive at\nopposite solutions, CoT generates opportunities for deep learning by detailed\ncomparisons of reasonings. However, unlike humans, we found that they do not\nautonomously explain using ecologically valid strategies like natural\nfrequencies, whole objects, and embodied heuristics. This is unfortunate, as\nthese strategies help humans avoid critical mistakes and have proven\npedagogical value in Bayesian reasoning. In order to overcome these biases and\naid understanding and learning, we included prompts that induce LLMs to use\nthese strategies. We found that LLMs with CoT incorporate them but not\nconsistently. They show persistent biases towards symbolic reasoning and\navoidance or phobia of ecologically valid strategies.", "published": "2025-03-19 14:44:02", "link": "http://arxiv.org/abs/2503.15268v1", "categories": ["cs.AI", "I.2.0"], "primary_category": "cs.AI"}
{"title": "Automated Non-Functional Requirements Generation in Software Engineering with Large Language Models: A Comparative Study", "abstract": "Neglecting non-functional requirements (NFRs) early in software development\ncan lead to critical challenges. Despite their importance, NFRs are often\noverlooked or difficult to identify, impacting software quality. To support\nrequirements engineers in eliciting NFRs, we developed a framework that\nleverages Large Language Models (LLMs) to derive quality-driven NFRs from\nfunctional requirements (FRs). Using a custom prompting technique within a\nDeno-based pipeline, the system identifies relevant quality attributes for each\nfunctional requirement and generates corresponding NFRs, aiding systematic\nintegration. A crucial aspect is evaluating the quality and suitability of\nthese generated requirements. Can LLMs produce high-quality NFR suggestions?\nUsing 34 functional requirements - selected as a representative subset of 3,964\nFRs-the LLMs inferred applicable attributes based on the ISO/IEC 25010:2023\nstandard, generating 1,593 NFRs. A horizontal evaluation covered three\ndimensions: NFR validity, applicability of quality attributes, and\nclassification precision. Ten industry software quality evaluators, averaging\n13 years of experience, assessed a subset for relevance and quality. The\nevaluation showed strong alignment between LLM-generated NFRs and expert\nassessments, with median validity and applicability scores of 5.0 (means: 4.63\nand 4.59, respectively) on a 1-5 scale. In the classification task, 80.4% of\nLLM-assigned attributes matched expert choices, with 8.3% near misses and 11.3%\nmismatches. A comparative analysis of eight LLMs highlighted variations in\nperformance, with gemini-1.5-pro exhibiting the highest attribute accuracy,\nwhile llama-3.3-70B achieved higher validity and applicability scores. These\nfindings provide insights into the feasibility of using LLMs for automated NFR\ngeneration and lay the foundation for further exploration of AI-assisted\nrequirements engineering.", "published": "2025-03-19 14:23:22", "link": "http://arxiv.org/abs/2503.15248v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "CoE: Chain-of-Explanation via Automatic Visual Concept Circuit Description and Polysemanticity Quantification", "abstract": "Explainability is a critical factor influencing the wide deployment of deep\nvision models (DVMs). Concept-based post-hoc explanation methods can provide\nboth global and local insights into model decisions. However, current methods\nin this field face challenges in that they are inflexible to automatically\nconstruct accurate and sufficient linguistic explanations for global concepts\nand local circuits. Particularly, the intrinsic polysemanticity in semantic\nVisual Concepts (VCs) impedes the interpretability of concepts and DVMs, which\nis underestimated severely. In this paper, we propose a Chain-of-Explanation\n(CoE) approach to address these issues. Specifically, CoE automates the\ndecoding and description of VCs to construct global concept explanation\ndatasets. Further, to alleviate the effect of polysemanticity on model\nexplainability, we design a concept polysemanticity disentanglement and\nfiltering mechanism to distinguish the most contextually relevant concept\natoms. Besides, a Concept Polysemanticity Entropy (CPE), as a measure of model\ninterpretability, is formulated to quantify the degree of concept uncertainty.\nThe modeling of deterministic concepts is upgraded to uncertain concept atom\ndistributions. Finally, CoE automatically enables linguistic local explanations\nof the decision-making process of DVMs by tracing the concept circuit. GPT-4o\nand human-based experiments demonstrate the effectiveness of CPE and the\nsuperiority of CoE, achieving an average absolute improvement of 36% in terms\nof explainability scores.", "published": "2025-03-19 14:13:02", "link": "http://arxiv.org/abs/2503.15234v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A Personalized Data-Driven Generative Model of Human Motion", "abstract": "The deployment of autonomous virtual avatars (in extended reality) and robots\nin human group activities - such as rehabilitation therapy, sports, and\nmanufacturing - is expected to increase as these technologies become more\npervasive. Designing cognitive architectures and control strategies to drive\nthese agents requires realistic models of human motion. However, existing\nmodels only provide simplified descriptions of human motor behavior. In this\nwork, we propose a fully data-driven approach, based on Long Short-Term Memory\nneural networks, to generate original motion that captures the unique\ncharacteristics of specific individuals. We validate the architecture using\nreal data of scalar oscillatory motion. Extensive analyses show that our model\neffectively replicates the velocity distribution and amplitude envelopes of the\nindividual it was trained on, remaining different from other individuals, and\noutperforming state-of-the-art models in terms of similarity to human data.", "published": "2025-03-19 14:03:20", "link": "http://arxiv.org/abs/2503.15225v1", "categories": ["cs.GR", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.GR"}
{"title": "A Unified Framework for Real-Time Failure Handling in Robotics Using Vision-Language Models, Reactive Planner and Behavior Trees", "abstract": "Robotic systems often face execution failures due to unexpected obstacles,\nsensor errors, or environmental changes. Traditional failure recovery methods\nrely on predefined strategies or human intervention, making them less\nadaptable. This paper presents a unified failure recovery framework that\ncombines Vision-Language Models (VLMs), a reactive planner, and Behavior Trees\n(BTs) to enable real-time failure handling. Our approach includes pre-execution\nverification, which checks for potential failures before execution, and\nreactive failure handling, which detects and corrects failures during execution\nby verifying existing BT conditions, adding missing preconditions and, when\nnecessary, generating new skills. The framework uses a scene graph for\nstructured environmental perception and an execution history for continuous\nmonitoring, enabling context-aware and adaptive failure handling. We evaluate\nour framework through real-world experiments with an ABB YuMi robot on tasks\nlike peg insertion, object sorting, and drawer placement, as well as in\nAI2-THOR simulator. Compared to using pre-execution and reactive methods\nseparately, our approach achieves higher task success rates and greater\nadaptability. Ablation studies highlight the importance of VLM-based reasoning,\nstructured scene representation, and execution history tracking for effective\nfailure recovery in robotics.", "published": "2025-03-19 13:40:56", "link": "http://arxiv.org/abs/2503.15202v2", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "A Bird Song Detector for improving bird identification through Deep Learning: a case study from Do\u00f1ana", "abstract": "Passive Acoustic Monitoring with automatic recorders is essential for\necosystem conservation but generates vast unsupervised audio data, posing\nchallenges for extracting meaningful information. Deep Learning techniques\noffer a promising solution. BirdNET, a widely used model for bird\nidentification, has shown success in many study systems but is limited in some\nregions due to biases in its training data. A key challenge in bird species\ndetection is that many recordings either lack target species or contain\noverlapping vocalizations. To overcome these problems, we developed a\nmulti-stage pipeline for automatic bird vocalization identification in Do\\~nana\nNational Park (SW Spain), a region facing significant conservation threats. Our\napproach included a Bird Song Detector to isolate vocalizations and custom\nclassifiers trained with BirdNET embeddings. We manually annotated 461 minutes\nof audio from three habitats across nine locations, yielding 3,749 annotations\nfor 34 classes. Spectrograms facilitated the use of image processing\ntechniques. Applying the Bird Song Detector before classification improved\nspecies identification, as all classification models performed better when\nanalyzing only the segments where birds were detected. Specifically, the\ncombination of the Bird Song Detector and fine-tuned BirdNET compared to the\nbaseline without the Bird Song Detector. Our approach demonstrated the\neffectiveness of integrating a Bird Song Detector with fine-tuned\nclassification models for bird identification at local soundscapes. These\nfindings highlight the need to adapt general-purpose tools for specific\necological challenges, as demonstrated in Do\\~nana. Automatically detecting\nbird species serves for tracking the health status of this threatened\necosystem, given the sensitivity of birds to environmental changes, and helps\nin the design of conservation measures for reducing biodiversity loss", "published": "2025-03-19 13:19:06", "link": "http://arxiv.org/abs/2503.15576v1", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.LG", "cs.NE", "I.5.4; I.2.6; I.4.8"], "primary_category": "cs.SD"}
{"title": "3D Occupancy Prediction with Low-Resolution Queries via Prototype-aware View Transformation", "abstract": "The resolution of voxel queries significantly influences the quality of view\ntransformation in camera-based 3D occupancy prediction. However, computational\nconstraints and the practical necessity for real-time deployment require\nsmaller query resolutions, which inevitably leads to an information loss.\nTherefore, it is essential to encode and preserve rich visual details within\nlimited query sizes while ensuring a comprehensive representation of 3D\noccupancy. To this end, we introduce ProtoOcc, a novel occupancy network that\nleverages prototypes of clustered image segments in view transformation to\nenhance low-resolution context. In particular, the mapping of 2D prototypes\nonto 3D voxel queries encodes high-level visual geometries and complements the\nloss of spatial information from reduced query resolutions. Additionally, we\ndesign a multi-perspective decoding strategy to efficiently disentangle the\ndensely compressed visual cues into a high-dimensional 3D occupancy scene.\nExperimental results on both Occ3D and SemanticKITTI benchmarks demonstrate the\neffectiveness of the proposed method, showing clear improvements over the\nbaselines. More importantly, ProtoOcc achieves competitive performance against\nthe baselines even with 75\\% reduced voxel resolution.", "published": "2025-03-19 13:14:57", "link": "http://arxiv.org/abs/2503.15185v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Foundation models may exhibit staged progression in novel CBRN threat disclosure", "abstract": "The extent to which foundation models can disclose novel chemical,\nbiological, radiation, and nuclear (CBRN) threats to expert users is unclear\ndue to a lack of test cases. I leveraged the unique opportunity presented by an\nupcoming publication describing a novel catastrophic biothreat - \"Technical\nReport on Mirror Bacteria: Feasibility and Risks\" - to conduct a small\ncontrolled study before it became public. Graduate-trained biologists tasked\nwith predicting the consequences of releasing mirror E. coli showed no\nsignificant differences in rubric-graded accuracy using Claude Sonnet 3.5 new\n(n=10) or web search only (n=2); both groups scored comparably to a web\nbaseline (28 and 43 versus 36). However, Sonnet reasoned correctly when\nprompted by a report author, but a smaller model, Haiku 3.5, failed even with\nauthor guidance (80 versus 5). These results suggest distinct stages of model\ncapability: Haiku is unable to reason about mirror life even with threat-aware\nexpert guidance (Stage 1), while Sonnet correctly reasons only with\nthreat-aware prompting (Stage 2). Continued advances may allow future models to\ndisclose novel CBRN threats to naive experts (Stage 3) or unskilled users\n(Stage 4). While mirror life represents only one case study, monitoring new\nmodels' ability to reason about privately known threats may allow protective\nmeasures to be implemented before widespread disclosure.", "published": "2025-03-19 13:08:01", "link": "http://arxiv.org/abs/2503.15182v1", "categories": ["cs.CY", "cs.AI", "q-bio.OT"], "primary_category": "cs.CY"}
{"title": "Learning Distributions of Complex Fluid Simulations with Diffusion Graph Networks", "abstract": "Physical systems with complex unsteady dynamics, such as fluid flows, are\noften poorly represented by a single mean solution. For many practical\napplications, it is crucial to access the full distribution of possible states,\nfrom which relevant statistics (e.g., RMS and two-point correlations) can be\nderived. Here, we propose a graph-based latent diffusion (or alternatively,\nflow-matching) model that enables direct sampling of states from their\nequilibrium distribution, given a mesh discretization of the system and its\nphysical parameters. This allows for the efficient computation of flow\nstatistics without running long and expensive numerical simulations. The\ngraph-based structure enables operations on unstructured meshes, which is\ncritical for representing complex geometries with spatially localized high\ngradients, while latent-space diffusion modeling with a multi-scale GNN allows\nfor efficient learning and inference of entire distributions of solutions. A\nkey finding is that the proposed networks can accurately learn full\ndistributions even when trained on incomplete data from relatively short\nsimulations. We apply this method to a range of fluid dynamics tasks, such as\npredicting pressure distributions on 3D wing models in turbulent flow,\ndemonstrating both accuracy and computational efficiency in challenging\nscenarios. The ability to directly sample accurate solutions, and capturing\ntheir diversity from short ground-truth simulations, is highly promising for\ncomplex scientific modeling tasks.", "published": "2025-03-19 13:04:39", "link": "http://arxiv.org/abs/2504.02843v1", "categories": ["physics.comp-ph", "cs.AI", "physics.flu-dyn"], "primary_category": "physics.comp-ph"}
{"title": "Multi-Agent Actor-Critic with Harmonic Annealing Pruning for Dynamic Spectrum Access Systems", "abstract": "Multi-Agent Deep Reinforcement Learning (MADRL) has emerged as a powerful\ntool for optimizing decentralized decision-making systems in complex settings,\nsuch as Dynamic Spectrum Access (DSA). However, deploying deep learning models\non resource-constrained edge devices remains challenging due to their high\ncomputational cost. To address this challenge, in this paper, we present a\nnovel sparse recurrent MARL framework integrating gradual neural network\npruning into the independent actor global critic paradigm. Additionally, we\nintroduce a harmonic annealing sparsity scheduler, which achieves comparable,\nand in certain cases superior, performance to standard linear and polynomial\npruning schedulers at large sparsities. Our experimental investigation\ndemonstrates that the proposed DSA framework can discover superior policies,\nunder diverse training conditions, outperforming conventional DSA, MADRL\nbaselines, and state-of-the-art pruning techniques.", "published": "2025-03-19 12:56:23", "link": "http://arxiv.org/abs/2503.15172v1", "categories": ["cs.LG", "cs.AI", "cs.NI"], "primary_category": "cs.LG"}
{"title": "World Models in Artificial Intelligence: Sensing, Learning, and Reasoning Like a Child", "abstract": "World Models help Artificial Intelligence (AI) predict outcomes, reason about\nits environment, and guide decision-making. While widely used in reinforcement\nlearning, they lack the structured, adaptive representations that even young\nchildren intuitively develop. Advancing beyond pattern recognition requires\ndynamic, interpretable frameworks inspired by Piaget's cognitive development\ntheory. We highlight six key research areas -- physics-informed learning,\nneurosymbolic learning, continual learning, causal inference, human-in-the-loop\nAI, and responsible AI -- as essential for enabling true reasoning in AI. By\nintegrating statistical learning with advances in these areas, AI can evolve\nfrom pattern recognition to genuine understanding, adaptation and reasoning\ncapabilities.", "published": "2025-03-19 12:50:40", "link": "http://arxiv.org/abs/2503.15168v1", "categories": ["cs.AI", "cs.CV", "cs.ET", "cs.LG", "68T05"], "primary_category": "cs.AI"}
{"title": "Volumetric Reconstruction From Partial Views for Task-Oriented Grasping", "abstract": "Object affordance and volumetric information are essential in devising\neffective grasping strategies under task-specific constraints. This paper\npresents an approach for inferring suitable grasping strategies from limited\npartial views of an object. To achieve this, a recurrent generative adversarial\nnetwork (R-GAN) was proposed by incorporating a recurrent generator with long\nshort-term memory (LSTM) units for it to process a variable number of depth\nscans. To determine object affordances, the AffordPose knowledge dataset is\nutilized as prior knowledge. Affordance retrieving is defined by the volume\nsimilarity measured via Chamfer Distance and action similarities. A Proximal\nPolicy Optimization (PPO) reinforcement learning model is further implemented\nto refine the retrieved grasp strategies for task-oriented grasping. The\nretrieved grasp strategies were evaluated on a dual-arm mobile manipulation\nrobot with an overall grasping accuracy of 89% for four tasks: lift, handle\ngrasp, wrap grasp, and press.", "published": "2025-03-19 12:47:50", "link": "http://arxiv.org/abs/2503.15167v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "A Foundational Theory for Decentralized Sensory Learning", "abstract": "In both neuroscience and artificial intelligence, popular functional\nframeworks and neural network formulations operate by making use of extrinsic\nerror measurements and global learning algorithms. Through a set of conjectures\nbased on evolutionary insights on the origin of cellular adaptive mechanisms,\nwe reinterpret the core meaning of sensory signals to allow the brain to be\ninterpreted as a negative feedback control system, and show how this could lead\nto local learning algorithms without the need for global error correction\nmetrics. Thereby, a sufficiently good minima in sensory activity can be the\ncomplete reward signal of the network, as well as being both necessary and\nsufficient for biological learning to arise. We show that this method of\nlearning was likely already present in the earliest unicellular life forms on\nearth. We show evidence that the same principle holds and scales to\nmulticellular organisms where it in addition can lead to division of labour\nbetween cells. Available evidence shows that the evolution of the nervous\nsystem likely was an adaptation to more effectively communicate intercellular\nsignals to support such division of labour. We therefore propose that the same\nlearning principle that evolved already in the earliest unicellular life forms,\ni.e. negative feedback control of externally and internally generated sensor\nsignals, has simply been scaled up to become a fundament of the learning we see\nin biological brains today. We illustrate diverse biological settings, from the\nearliest unicellular organisms to humans, where this operational principle\nappears to be a plausible interpretation of the meaning of sensor signals in\nbiology, and how this relates to current neuroscientific theories and findings.", "published": "2025-03-19 11:44:58", "link": "http://arxiv.org/abs/2503.15130v1", "categories": ["q-bio.NC", "cs.AI"], "primary_category": "q-bio.NC"}
{"title": "Aligning Crowd-sourced Human Feedback for Reinforcement Learning on Code Generation by Large Language Models", "abstract": "This paper studies how AI-assisted programming and large language models\n(LLM) improve software developers' ability via AI tools (LLM agents) like\nGithub Copilot and Amazon CodeWhisperer, while integrating human feedback to\nenhance reinforcement learning (RLHF) with crowd-sourced computation to enhance\ntext-to-code generation. Additionally, we demonstrate that our Bayesian\noptimization framework supports AI alignment in code generation by distributing\nthe feedback collection burden, highlighting the value of collecting human\nfeedback of good quality. Our empirical evaluations demonstrate the efficacy of\nthis approach, showcasing how LLM agents can be effectively trained for\nimproved text-to-code generation. Our Bayesian optimization framework can be\ndesigned for general domain-specific languages, promoting the alignment of\nlarge language model capabilities with human feedback in AI-assisted\nprogramming for code generation.", "published": "2025-03-19 11:44:47", "link": "http://arxiv.org/abs/2503.15129v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Text-Derived Relational Graph-Enhanced Network for Skeleton-Based Action Segmentation", "abstract": "Skeleton-based Temporal Action Segmentation (STAS) aims to segment and\nrecognize various actions from long, untrimmed sequences of human skeletal\nmovements. Current STAS methods typically employ spatio-temporal modeling to\nestablish dependencies among joints as well as frames, and utilize one-hot\nencoding with cross-entropy loss for frame-wise classification supervision.\nHowever, these methods overlook the intrinsic correlations among joints and\nactions within skeletal features, leading to a limited understanding of human\nmovements. To address this, we propose a Text-Derived Relational Graph-Enhanced\nNetwork (TRG-Net) that leverages prior graphs generated by Large Language\nModels (LLM) to enhance both modeling and supervision. For modeling, the\nDynamic Spatio-Temporal Fusion Modeling (DSFM) method incorporates Text-Derived\nJoint Graphs (TJG) with channel- and frame-level dynamic adaptation to\neffectively model spatial relations, while integrating spatio-temporal core\nfeatures during temporal modeling. For supervision, the Absolute-Relative\nInter-Class Supervision (ARIS) method employs contrastive learning between\naction features and text embeddings to regularize the absolute class\ndistributions, and utilizes Text-Derived Action Graphs (TAG) to capture the\nrelative inter-class relationships among action features. Additionally, we\npropose a Spatial-Aware Enhancement Processing (SAEP) method, which\nincorporates random joint occlusion and axial rotation to enhance spatial\ngeneralization. Performance evaluations on four public datasets demonstrate\nthat TRG-Net achieves state-of-the-art results.", "published": "2025-03-19 11:38:14", "link": "http://arxiv.org/abs/2503.15126v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Reasoning Effort and Problem Complexity: A Scaling Analysis in LLMs", "abstract": "Large Language Models (LLMs) have demonstrated remarkable text generation\ncapabilities, and recent advances in training paradigms have led to\nbreakthroughs in their reasoning performance. In this work, we investigate how\nthe reasoning effort of such models scales with problem complexity. We use the\ninfinitely scalable Tents puzzle, which has a known linear-time solution, to\nanalyze this scaling behavior. Our results show that reasoning effort scales\nwith problem size, but only up to a critical problem complexity. Beyond this\nthreshold, the reasoning effort does not continue to increase, and may even\ndecrease. This observation highlights a critical limitation in the logical\ncoherence of current LLMs as problem complexity increases, and underscores the\nneed for strategies to improve reasoning scalability. Furthermore, our results\nreveal significant performance differences between current state-of-the-art\nreasoning models when faced with increasingly complex logical puzzles.", "published": "2025-03-19 11:13:51", "link": "http://arxiv.org/abs/2503.15113v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "VIPER: Visual Perception and Explainable Reasoning for Sequential Decision-Making", "abstract": "While Large Language Models (LLMs) excel at reasoning on text and\nVision-Language Models (VLMs) are highly effective for visual perception,\napplying those models for visual instruction-based planning remains a widely\nopen problem. In this paper, we introduce VIPER, a novel framework for\nmultimodal instruction-based planning that integrates VLM-based perception with\nLLM-based reasoning. Our approach uses a modular pipeline where a frozen VLM\ngenerates textual descriptions of image observations, which are then processed\nby an LLM policy to predict actions based on the task goal. We fine-tune the\nreasoning module using behavioral cloning and reinforcement learning, improving\nour agent's decision-making capabilities. Experiments on the ALFWorld benchmark\nshow that VIPER significantly outperforms state-of-the-art visual\ninstruction-based planners while narrowing the gap with purely text-based\noracles. By leveraging text as an intermediate representation, VIPER also\nenhances explainability, paving the way for a fine-grained analysis of\nperception and reasoning components.", "published": "2025-03-19 11:05:42", "link": "http://arxiv.org/abs/2503.15108v1", "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "cs.LG"}
{"title": "Diffusion-Based Forecasting for Uncertainty-Aware Model Predictive Control", "abstract": "We propose Diffusion-Informed Model Predictive Control (D-I MPC), a generic\nframework for uncertainty-aware prediction and decision-making in partially\nobservable stochastic systems by integrating diffusion-based time series\nforecasting models in Model Predictive Control algorithms. In our approach, a\ndiffusion-based time series forecasting model is used to probabilistically\nestimate the evolution of the system's stochastic components. These forecasts\nare then incorporated into MPC algorithms to estimate future trajectories and\noptimize action selection under the uncertainty of the future. We evaluate the\nframework on the task of energy arbitrage, where a Battery Energy Storage\nSystem participates in the day-ahead electricity market of the New York state.\nExperimental results indicate that our model-based approach with a\ndiffusion-based forecaster significantly outperforms both implementations with\nclassical forecasting methods and model-free reinforcement learning baselines.", "published": "2025-03-19 10:48:26", "link": "http://arxiv.org/abs/2503.15095v1", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY", "I.2.6; I.5.1"], "primary_category": "cs.LG"}
{"title": "StyleLoco: Generative Adversarial Distillation for Natural Humanoid Robot Locomotion", "abstract": "Humanoid robots are anticipated to acquire a wide range of locomotion\ncapabilities while ensuring natural movement across varying speeds and\nterrains. Existing methods encounter a fundamental dilemma in learning humanoid\nlocomotion: reinforcement learning with handcrafted rewards can achieve agile\nlocomotion but produces unnatural gaits, while Generative Adversarial Imitation\nLearning (GAIL) with motion capture data yields natural movements but suffers\nfrom unstable training processes and restricted agility. Integrating these\napproaches proves challenging due to the inherent heterogeneity between expert\npolicies and human motion datasets. To address this, we introduce StyleLoco, a\nnovel two-stage framework that bridges this gap through a Generative\nAdversarial Distillation (GAD) process. Our framework begins by training a\nteacher policy using reinforcement learning to achieve agile and dynamic\nlocomotion. It then employs a multi-discriminator architecture, where distinct\ndiscriminators concurrently extract skills from both the teacher policy and\nmotion capture data. This approach effectively combines the agility of\nreinforcement learning with the natural fluidity of human-like movements while\nmitigating the instability issues commonly associated with adversarial\ntraining. Through extensive simulation and real-world experiments, we\ndemonstrate that StyleLoco enables humanoid robots to perform diverse\nlocomotion tasks with the precision of expertly trained policies and the\nnatural aesthetics of human motion, successfully transferring styles across\ndifferent movement types while maintaining stable locomotion across a broad\nspectrum of command inputs.", "published": "2025-03-19 10:27:44", "link": "http://arxiv.org/abs/2503.15082v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Conjuring Positive Pairs for Efficient Unification of Representation Learning and Image Synthesis", "abstract": "While representation learning and generative modeling seek to understand\nvisual data, unifying both domains remains unexplored. Recent Unified\nSelf-Supervised Learning (SSL) methods have started to bridge the gap between\nboth paradigms. However, they rely solely on semantic token reconstruction,\nwhich requires an external tokenizer during training -- introducing a\nsignificant overhead. In this work, we introduce Sorcen, a novel unified SSL\nframework, incorporating a synergic Contrastive-Reconstruction objective. Our\nContrastive objective, \"Echo Contrast\", leverages the generative capabilities\nof Sorcen, eliminating the need for additional image crops or augmentations\nduring training. Sorcen \"generates\" an echo sample in the semantic token space,\nforming the contrastive positive pair. Sorcen operates exclusively on\nprecomputed tokens, eliminating the need for an online token transformation\nduring training, thereby significantly reducing computational overhead.\nExtensive experiments on ImageNet-1k demonstrate that Sorcen outperforms the\nprevious Unified SSL SoTA by 0.4%, 1.48 FID, 1.76%, and 1.53% on linear\nprobing, unconditional image generation, few-shot learning, and transfer\nlearning, respectively, while being 60.8% more efficient. Additionally, Sorcen\nsurpasses previous single-crop MIM SoTA in linear probing and achieves SoTA\nperformance in unconditional image generation, highlighting significant\nimprovements and breakthroughs in Unified SSL models.", "published": "2025-03-19 09:53:11", "link": "http://arxiv.org/abs/2503.15060v2", "categories": ["cs.CV", "cs.AI", "I.5.4; I.5.1; I.2.10"], "primary_category": "cs.CV"}
{"title": "Texture-Aware StarGAN for CT data harmonisation", "abstract": "Computed Tomography (CT) plays a pivotal role in medical diagnosis; however,\nvariability across reconstruction kernels hinders data-driven approaches, such\nas deep learning models, from achieving reliable and generalized performance.\nTo this end, CT data harmonization has emerged as a promising solution to\nminimize such non-biological variances by standardizing data across different\nsources or conditions. In this context, Generative Adversarial Networks (GANs)\nhave proved to be a powerful framework for harmonization, framing it as a\nstyle-transfer problem. However, GAN-based approaches still face limitations in\ncapturing complex relationships within the images, which are essential for\neffective harmonization. In this work, we propose a novel texture-aware StarGAN\nfor CT data harmonization, enabling one-to-many translations across different\nreconstruction kernels. Although the StarGAN model has been successfully\napplied in other domains, its potential for CT data harmonization remains\nunexplored. Furthermore, our approach introduces a multi-scale texture loss\nfunction that embeds texture information across different spatial and angular\nscales into the harmonization process, effectively addressing kernel-induced\ntexture variations. We conducted extensive experimentation on a publicly\navailable dataset, utilizing a total of 48667 chest CT slices from 197 patients\ndistributed over three different reconstruction kernels, demonstrating the\nsuperiority of our method over the baseline StarGAN.", "published": "2025-03-19 09:50:32", "link": "http://arxiv.org/abs/2503.15058v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "HAD-Gen: Human-like and Diverse Driving Behavior Modeling for Controllable Scenario Generation", "abstract": "Simulation-based testing has emerged as an essential tool for verifying and\nvalidating autonomous vehicles (AVs). However, contemporary methodologies, such\nas deterministic and imitation learning-based driver models, struggle to\ncapture the variability of human-like driving behavior. Given these challenges,\nwe propose HAD-Gen, a general framework for realistic traffic scenario\ngeneration that simulates diverse human-like driving behaviors. The framework\nfirst clusters the vehicle trajectory data into different driving styles\naccording to safety features. It then employs maximum entropy inverse\nreinforcement learning on each of the clusters to learn the reward function\ncorresponding to each driving style. Using these reward functions, the method\nintegrates offline reinforcement learning pre-training and multi-agent\nreinforcement learning algorithms to obtain general and robust driving\npolicies. Multi-perspective simulation results show that our proposed scenario\ngeneration framework can simulate diverse, human-like driving behaviors with\nstrong generalization capability. The proposed framework achieves a 90.96%\ngoal-reaching rate, an off-road rate of 2.08%, and a collision rate of 6.91% in\nthe generalization test, outperforming prior approaches by over 20% in\ngoal-reaching performance. The source code is released at\nhttps://github.com/RoboSafe-Lab/Sim4AD.", "published": "2025-03-19 09:38:45", "link": "http://arxiv.org/abs/2503.15049v1", "categories": ["cs.RO", "cs.AI", "cs.MA"], "primary_category": "cs.RO"}
{"title": "GraspCorrect: Robotic Grasp Correction via Vision-Language Model-Guided Feedback", "abstract": "Despite significant advancements in robotic manipulation, achieving\nconsistent and stable grasping remains a fundamental challenge, often limiting\nthe successful execution of complex tasks. Our analysis reveals that even\nstate-of-the-art policy models frequently exhibit unstable grasping behaviors,\nleading to failure cases that create bottlenecks in real-world robotic\napplications. To address these challenges, we introduce GraspCorrect, a\nplug-and-play module designed to enhance grasp performance through\nvision-language model-guided feedback. GraspCorrect employs an iterative visual\nquestion-answering framework with two key components: grasp-guided prompting,\nwhich incorporates task-specific constraints, and object-aware sampling, which\nensures the selection of physically feasible grasp candidates. By iteratively\ngenerating intermediate visual goals and translating them into joint-level\nactions, GraspCorrect significantly improves grasp stability and consistently\nenhances task success rates across existing policy models in the RLBench and\nCALVIN datasets.", "published": "2025-03-19 09:25:32", "link": "http://arxiv.org/abs/2503.15035v1", "categories": ["cs.AI", "cs.RO"], "primary_category": "cs.AI"}
{"title": "A Novel Channel Boosted Residual CNN-Transformer with Regional-Boundary Learning for Breast Cancer Detection", "abstract": "Recent advancements in detecting tumors using deep learning on breast\nultrasound images (BUSI) have demonstrated significant success. Deep CNNs and\nvision-transformers (ViTs) have demonstrated individually promising initial\nperformance. However, challenges related to model complexity and contrast,\ntexture, and tumor morphology variations introduce uncertainties that hinder\nthe effectiveness of current methods. This study introduces a novel hybrid\nframework, CB-Res-RBCMT, combining customized residual CNNs and new ViT\ncomponents for detailed BUSI cancer analysis. The proposed RBCMT uses stem\nconvolution blocks with CNN Meet Transformer (CMT) blocks, followed by new\nRegional and boundary (RB) feature extraction operations for capturing contrast\nand morphological variations. Moreover, the CMT block incorporates global\ncontextual interactions through multi-head attention, enhancing computational\nefficiency with a lightweight design. Additionally, the customized inverse\nresidual and stem CNNs within the CMT effectively extract local texture\ninformation and handle vanishing gradients. Finally, the new channel-boosted\n(CB) strategy enriches the feature diversity of the limited dataset by\ncombining the original RBCMT channels with transfer learning-based residual\nCNN-generated maps. These diverse channels are processed through a spatial\nattention block for optimal pixel selection, reducing redundancy and improving\nthe discrimination of minor contrast and texture variations. The proposed\nCB-Res-RBCMT achieves an F1-score of 95.57%, accuracy of 95.63%, sensitivity of\n96.42%, and precision of 94.79% on the standard harmonized stringent BUSI\ndataset, outperforming existing ViT and CNN methods. These results demonstrate\nthe versatility of our integrated CNN-Transformer framework in capturing\ndiverse features and delivering superior performance in BUSI cancer diagnosis.", "published": "2025-03-19 08:59:02", "link": "http://arxiv.org/abs/2503.15008v1", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "Empowering Medical Multi-Agents with Clinical Consultation Flow for Dynamic Diagnosis", "abstract": "Traditional AI-based healthcare systems often rely on single-modal data,\nlimiting diagnostic accuracy due to incomplete information. However, recent\nadvancements in foundation models show promising potential for enhancing\ndiagnosis combining multi-modal information. While these models excel in static\ntasks, they struggle with dynamic diagnosis, failing to manage multi-turn\ninteractions and often making premature diagnostic decisions due to\ninsufficient persistence in information collection.To address this, we propose\na multi-agent framework inspired by consultation flow and reinforcement\nlearning (RL) to simulate the entire consultation process, integrating multiple\nclinical information for effective diagnosis. Our approach incorporates a\nhierarchical action set, structured from clinic consultation flow and medical\ntextbook, to effectively guide the decision-making process. This strategy\nimproves agent interactions, enabling them to adapt and optimize actions based\non the dynamic state. We evaluated our framework on a public dynamic diagnosis\nbenchmark. The proposed framework evidentially improves the baseline methods\nand achieves state-of-the-art performance compared to existing foundation\nmodel-based methods.", "published": "2025-03-19 08:47:18", "link": "http://arxiv.org/abs/2503.16547v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "A Comprehensive Survey on Architectural Advances in Deep CNNs: Challenges, Applications, and Emerging Research Directions", "abstract": "Deep Convolutional Neural Networks (CNNs) have significantly advanced deep\nlearning, driving breakthroughs in computer vision, natural language\nprocessing, medical diagnosis, object detection, and speech recognition.\nArchitectural innovations including 1D, 2D, and 3D convolutional models,\ndilated and grouped convolutions, depthwise separable convolutions, and\nattention mechanisms address domain-specific challenges and enhance feature\nrepresentation and computational efficiency. Structural refinements such as\nspatial-channel exploitation, multi-path design, and feature-map enhancement\ncontribute to robust hierarchical feature extraction and improved\ngeneralization, particularly through transfer learning. Efficient preprocessing\nstrategies, including Fourier transforms, structured transforms, low-precision\ncomputation, and weight compression, optimize inference speed and facilitate\ndeployment in resource-constrained environments. This survey presents a unified\ntaxonomy that classifies CNN architectures based on spatial exploitation,\nmulti-path structures, depth, width, dimensionality expansion, channel\nboosting, and attention mechanisms. It systematically reviews CNN applications\nin face recognition, pose estimation, action recognition, text classification,\nstatistical language modeling, disease diagnosis, radiological analysis,\ncryptocurrency sentiment prediction, 1D data processing, video analysis, and\nspeech recognition. In addition to consolidating architectural advancements,\nthe review highlights emerging learning paradigms such as few-shot, zero-shot,\nweakly supervised, federated learning frameworks and future research directions\ninclude hybrid CNN-transformer models, vision-language integration, generative\nlearning, etc. This review provides a comprehensive perspective on CNN's\nevolution from 2015 to 2025, outlining key innovations, challenges, and\nopportunities.", "published": "2025-03-19 08:41:06", "link": "http://arxiv.org/abs/2503.16546v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Application of linear regression method to the deep reinforcement learning in continuous action cases", "abstract": "The linear regression (LR) method offers the advantage that optimal\nparameters can be calculated relatively easily, although its representation\ncapability is limited than that of the deep learning technique. To improve deep\nreinforcement learning, the Least Squares Deep Q Network (LS-DQN) method was\nproposed by Levine et al., which combines Deep Q Network (DQN) with LR method.\nHowever, the LS-DQN method assumes that the actions are discrete. In this\nstudy, we propose the Double Least Squares Deep Deterministic Policy Gradient\n(DLS-DDPG) method to address this limitation. This method combines the LR\nmethod with the Deep Deterministic Policy Gradient (DDPG) technique, one of the\nrepresentative deep reinforcement learning algorithms for continuous action\ncases. Numerical experiments conducted in MuJoCo environments showed that the\nLR update improved performance at least in some tasks, although there are\ndifficulties such as the inability to make the regularization terms small.", "published": "2025-03-19 08:10:54", "link": "http://arxiv.org/abs/2503.14976v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Behaviour Discovery and Attribution for Explainable Reinforcement Learning", "abstract": "Explaining the decisions made by reinforcement learning (RL) agents is\ncritical for building trust and ensuring reliability in real-world\napplications. Traditional approaches to explainability often rely on saliency\nanalysis, which can be limited in providing actionable insights. Recently,\nthere has been growing interest in attributing RL decisions to specific\ntrajectories within a dataset. However, these methods often generalize\nexplanations to long trajectories, potentially involving multiple distinct\nbehaviors. Often, providing multiple more fine grained explanations would\nimprove clarity. In this work, we propose a framework for behavior discovery\nand action attribution to behaviors in offline RL trajectories. Our method\nidentifies meaningful behavioral segments, enabling more precise and granular\nexplanations associated with high level agent behaviors. This approach is\nadaptable across diverse environments with minimal modifications, offering a\nscalable and versatile solution for behavior discovery and attribution for\nexplainable RL.", "published": "2025-03-19 08:06:00", "link": "http://arxiv.org/abs/2503.14973v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Advancing Deep Learning through Probability Engineering: A Pragmatic Paradigm for Modern AI", "abstract": "Recent years have witnessed the rapid progression of deep learning, pushing\nus closer to the realization of AGI (Artificial General Intelligence).\nProbabilistic modeling is critical to many of these advancements, which\nprovides a foundational framework for capturing data distributions. However, as\nthe scale and complexity of AI applications grow, traditional probabilistic\nmodeling faces escalating challenges, such as high-dimensional parameter\nspaces, heterogeneous data sources, and evolving real-world requirements often\nrender classical approaches insufficiently flexible.\n  This paper proposes a novel concept, Probability Engineering, which treats\nthe already-learned probability distributions within deep learning as\nengineering artifacts. Rather than merely fitting or inferring distributions,\nwe actively modify and reinforce them to better address the diverse and\nevolving demands of modern AI. Specifically, Probability Engineering introduces\nnovel techniques and constraints to refine existing probability distributions,\nimproving their robustness, efficiency, adaptability, or trustworthiness.\n  We showcase this paradigm through a series of applications spanning Bayesian\ndeep learning, Edge AI (including federated learning and knowledge\ndistillation), and Generative AI (such as text-to-image generation with\ndiffusion models and high-quality text generation with large language models).\nThese case studies demonstrate how probability distributions once treated as\nstatic objects can be engineered to meet the diverse and evolving requirements\nof large-scale, data-intensive, and trustworthy AI systems. By systematically\nexpanding and strengthening the role of probabilistic modeling, Probability\nEngineering paves the way for more robust, adaptive, efficient, and trustworthy\ndeep learning solutions in today's fast-growing AI era.", "published": "2025-03-19 07:48:23", "link": "http://arxiv.org/abs/2503.18958v1", "categories": ["cs.AI", "math.PR", "stat.ML"], "primary_category": "cs.AI"}
{"title": "USAM-Net: A U-Net-based Network for Improved Stereo Correspondence and Scene Depth Estimation using Features from a Pre-trained Image Segmentation network", "abstract": "The increasing demand for high-accuracy depth estimation in autonomous\ndriving and augmented reality applications necessitates advanced neural\narchitectures capable of effectively leveraging multiple data modalities. In\nthis context, we introduce the Unified Segmentation Attention Mechanism Network\n(USAM-Net), a novel convolutional neural network that integrates stereo image\ninputs with semantic segmentation maps and attention to enhance depth\nestimation performance. USAM-Net employs a dual-pathway architecture, which\ncombines a pre-trained segmentation model (SAM) and a depth estimation model.\nThe segmentation pathway preprocesses the stereo images to generate semantic\nmasks, which are then concatenated with the stereo images as inputs to the\ndepth estimation pathway. This integration allows the model to focus on\nimportant features such as object boundaries and surface textures which are\ncrucial for accurate depth perception. Empirical evaluation on the\nDrivingStereo dataset demonstrates that USAM-Net achieves superior performance\nmetrics, including a Global Difference (GD) of 3.61\\% and an End-Point Error\n(EPE) of 0.88, outperforming traditional models such as CFNet, SegStereo, and\niResNet. These results underscore the effectiveness of integrating segmentation\ninformation into stereo depth estimation tasks, highlighting the potential of\nUSAM-Net in applications demanding high-precision depth data.", "published": "2025-03-19 07:29:02", "link": "http://arxiv.org/abs/2503.14950v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "FAVOR-Bench: A Comprehensive Benchmark for Fine-Grained Video Motion Understanding", "abstract": "Multimodal Large Language Models (MLLMs) have shown remarkable capabilities\nin video content understanding but still struggle with fine-grained motion\ncomprehension. To comprehensively assess the motion understanding ability of\nexisting MLLMs, we introduce FAVOR-Bench, comprising 1,776 videos with\nstructured manual annotations of various motions. Our benchmark includes both\nclose-ended and open-ended tasks. For close-ended evaluation, we carefully\ndesign 8,184 multiple-choice question-answer pairs spanning six distinct\nsub-tasks. For open-ended evaluation, we develop both a novel cost-efficient\nLLM-free and a GPT-assisted caption assessment method, where the former can\nenhance benchmarking interpretability and reproducibility. Comprehensive\nexperiments with 21 state-of-the-art MLLMs reveal significant limitations in\ntheir ability to comprehend and describe detailed temporal dynamics in video\nmotions. To alleviate this limitation, we further build FAVOR-Train, a dataset\nconsisting of 17,152 videos with fine-grained motion annotations. The results\nof finetuning Qwen2.5-VL on FAVOR-Train yield consistent improvements on\nmotion-related tasks of TVBench, MotionBench and our FAVOR-Bench. Comprehensive\nassessment results demonstrate that the proposed FAVOR-Bench and FAVOR-Train\nprovide valuable tools to the community for developing more powerful video\nunderstanding models. Project page:\n\\href{https://favor-bench.github.io/}{https://favor-bench.github.io/}.", "published": "2025-03-19 06:42:32", "link": "http://arxiv.org/abs/2503.14935v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Shushing! Let's Imagine an Authentic Speech from the Silent Video", "abstract": "Vision-guided speech generation aims to produce authentic speech from facial\nappearance or lip motions without relying on auditory signals, offering\nsignificant potential for applications such as dubbing in filmmaking and\nassisting individuals with aphonia. Despite recent progress, existing methods\nstruggle to achieve unified cross-modal alignment across semantics, timbre, and\nemotional prosody from visual cues, prompting us to propose Consistent\nVideo-to-Speech (CV2S) as an extended task to enhance cross-modal consistency.\nTo tackle emerging challenges, we introduce ImaginTalk, a novel cross-modal\ndiffusion framework that generates faithful speech using only visual input,\noperating within a discrete space. Specifically, we propose a discrete lip\naligner that predicts discrete speech tokens from lip videos to capture\nsemantic information, while an error detector identifies misaligned tokens,\nwhich are subsequently refined through masked language modeling with BERT. To\nfurther enhance the expressiveness of the generated speech, we develop a style\ndiffusion transformer equipped with a face-style adapter that adaptively\ncustomizes identity and prosody dynamics across both the channel and temporal\ndimensions while ensuring synchronization with lip-aware semantic features.\nExtensive experiments demonstrate that ImaginTalk can generate high-fidelity\nspeech with more accurate semantic details and greater expressiveness in timbre\nand emotion compared to state-of-the-art baselines. Demos are shown at our\nproject page: https://imagintalk.github.io.", "published": "2025-03-19 06:28:17", "link": "http://arxiv.org/abs/2503.14928v1", "categories": ["cs.CV", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "A Semantic and Clean-label Backdoor Attack against Graph Convolutional Networks", "abstract": "Graph Convolutional Networks (GCNs) have shown excellent performance in\ngraph-structured tasks such as node classification and graph classification.\nHowever, recent research has shown that GCNs are vulnerable to a new type of\nthreat called the backdoor attack, where the adversary can inject a hidden\nbackdoor into the GCNs so that the backdoored model performs well on benign\nsamples, whereas its prediction will be maliciously changed to the\nattacker-specified target label if the hidden backdoor is activated by the\nattacker-defined trigger. Clean-label backdoor attack and semantic backdoor\nattack are two new backdoor attacks to Deep Neural Networks (DNNs), they are\nmore imperceptible and have posed new and serious threats. The semantic and\nclean-label backdoor attack is not fully explored in GCNs. In this paper, we\npropose a semantic and clean-label backdoor attack against GCNs under the\ncontext of graph classification to reveal the existence of this security\nvulnerability in GCNs. Specifically, SCLBA conducts an importance analysis on\ngraph samples to select one type of node as semantic trigger, which is then\ninserted into the graph samples to create poisoning samples without changing\nthe labels of the poisoning samples to the attacker-specified target label. We\nevaluate SCLBA on multiple datasets and the results show that SCLBA can achieve\nattack success rates close to 99% with poisoning rates of less than 3%, and\nwith almost no impact on the performance of model on benign samples.", "published": "2025-03-19 06:04:55", "link": "http://arxiv.org/abs/2503.14922v1", "categories": ["cs.LG", "cs.AI", "cs.CR"], "primary_category": "cs.LG"}
{"title": "POSTA: A Go-to Framework for Customized Artistic Poster Generation", "abstract": "Poster design is a critical medium for visual communication. Prior work has\nexplored automatic poster design using deep learning techniques, but these\napproaches lack text accuracy, user customization, and aesthetic appeal,\nlimiting their applicability in artistic domains such as movies and\nexhibitions, where both clear content delivery and visual impact are essential.\nTo address these limitations, we present POSTA: a modular framework powered by\ndiffusion models and multimodal large language models (MLLMs) for customized\nartistic poster generation. The framework consists of three modules. Background\nDiffusion creates a themed background based on user input. Design MLLM then\ngenerates layout and typography elements that align with and complement the\nbackground style. Finally, to enhance the poster's aesthetic appeal, ArtText\nDiffusion applies additional stylization to key text elements. The final result\nis a visually cohesive and appealing poster, with a fully modular process that\nallows for complete customization. To train our models, we develop the\nPosterArt dataset, comprising high-quality artistic posters annotated with\nlayout, typography, and pixel-level stylized text segmentation. Our\ncomprehensive experimental analysis demonstrates POSTA's exceptional\ncontrollability and design diversity, outperforming existing models in both\ntext accuracy and aesthetic quality.", "published": "2025-03-19 05:22:38", "link": "http://arxiv.org/abs/2503.14908v1", "categories": ["cs.GR", "cs.AI", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Envisioning an AI-Enhanced Mental Health Ecosystem", "abstract": "The rapid advancement of Large Language Models (LLMs), reasoning models, and\nagentic AI approaches coincides with a growing global mental health crisis,\nwhere increasing demand has not translated into adequate access to professional\nsupport, particularly for underserved populations. This presents a unique\nopportunity for AI to complement human-led interventions, offering scalable and\ncontext-aware support while preserving human connection in this sensitive\ndomain. We explore various AI applications in peer support, self-help\ninterventions, proactive monitoring, and data-driven insights, using a\nhuman-centred approach that ensures AI supports rather than replaces human\ninteraction. However, AI deployment in mental health fields presents challenges\nsuch as ethical concerns, transparency, privacy risks, and risks of\nover-reliance. We propose a hybrid ecosystem where where AI assists but does\nnot replace human providers, emphasising responsible deployment and evaluation.\nWe also present some of our early work and findings in several of these AI\napplications. Finally, we outline future research directions for refining\nAI-enhanced interventions while adhering to ethical and culturally sensitive\nguidelines.", "published": "2025-03-19 04:21:38", "link": "http://arxiv.org/abs/2503.14883v3", "categories": ["cs.HC", "cs.AI", "H.5.0"], "primary_category": "cs.HC"}
{"title": "Exploring the Limits of KV Cache Compression in Visual Autoregressive Transformers", "abstract": "A fundamental challenge in Visual Autoregressive models is the substantial\nmemory overhead required during inference to store previously generated\nrepresentations. Despite various attempts to mitigate this issue through\ncompression techniques, prior works have not explicitly formalized the problem\nof KV-cache compression in this context. In this work, we take the first step\nin formally defining the KV-cache compression problem for Visual Autoregressive\ntransformers. We then establish a fundamental negative result, proving that any\nmechanism for sequential visual token generation under attention-based\narchitectures must use at least $\\Omega(n^2 d)$ memory, when $d = \\Omega(\\log\nn)$, where $n$ is the number of tokens generated and $d$ is the embedding\ndimensionality. This result demonstrates that achieving truly sub-quadratic\nmemory usage is impossible without additional structural constraints. Our proof\nis constructed via a reduction from a computational lower bound problem,\nleveraging randomized embedding techniques inspired by dimensionality reduction\nprinciples. Finally, we discuss how sparsity priors on visual representations\ncan influence memory efficiency, presenting both impossibility results and\npotential directions for mitigating memory overhead.", "published": "2025-03-19 04:18:57", "link": "http://arxiv.org/abs/2503.14881v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Efficient Personalization of Quantized Diffusion Model without Backpropagation", "abstract": "Diffusion models have shown remarkable performance in image synthesis, but\nthey demand extensive computational and memory resources for training,\nfine-tuning and inference. Although advanced quantization techniques have\nsuccessfully minimized memory usage for inference, training and fine-tuning\nthese quantized models still require large memory possibly due to\ndequantization for accurate computation of gradients and/or backpropagation for\ngradient-based algorithms. However, memory-efficient fine-tuning is\nparticularly desirable for applications such as personalization that often must\nbe run on edge devices like mobile phones with private data. In this work, we\naddress this challenge by quantizing a diffusion model with personalization via\nTextual Inversion and by leveraging a zeroth-order optimization on\npersonalization tokens without dequantization so that it does not require\ngradient and activation storage for backpropagation that consumes considerable\nmemory. Since a gradient estimation using zeroth-order optimization is quite\nnoisy for a single or a few images in personalization, we propose to denoise\nthe estimated gradient by projecting it onto a subspace that is constructed\nwith the past history of the tokens, dubbed Subspace Gradient. In addition, we\ninvestigated the influence of text embedding in image generation, leading to\nour proposed time steps sampling, dubbed Partial Uniform Timestep Sampling for\nsampling with effective diffusion timesteps. Our method achieves comparable\nperformance to prior methods in image and text alignment scores for\npersonalizing Stable Diffusion with only forward passes while reducing training\nmemory demand up to $8.2\\times$.", "published": "2025-03-19 03:45:37", "link": "http://arxiv.org/abs/2503.14868v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "1000 Layer Networks for Self-Supervised RL: Scaling Depth Can Enable New Goal-Reaching Capabilities", "abstract": "Scaling up self-supervised learning has driven breakthroughs in language and\nvision, yet comparable progress has remained elusive in reinforcement learning\n(RL). In this paper, we study building blocks for self-supervised RL that\nunlock substantial improvements in scalability, with network depth serving as a\ncritical factor. Whereas most RL papers in recent years have relied on shallow\narchitectures (around 2 - 5 layers), we demonstrate that increasing the depth\nup to 1024 layers can significantly boost performance. Our experiments are\nconducted in an unsupervised goal-conditioned setting, where no demonstrations\nor rewards are provided, so an agent must explore (from scratch) and learn how\nto maximize the likelihood of reaching commanded goals. Evaluated on simulated\nlocomotion and manipulation tasks, our approach increases performance by\n$2\\times$ - $50\\times$. Increasing the model depth not only increases success\nrates but also qualitatively changes the behaviors learned.", "published": "2025-03-19 03:33:57", "link": "http://arxiv.org/abs/2503.14858v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Project Jenkins: Turning Monkey Neural Data into Robotic Arm Movement, and Back", "abstract": "Project Jenkins explores how neural activity in the brain can be decoded into\nrobotic movement and, conversely, how movement patterns can be used to generate\nsynthetic neural data. Using real neural data recorded from motor and premotor\ncortex areas of a macaque monkey named Jenkins, we develop models for decoding\n(converting brain signals into robotic arm movements) and encoding (simulating\nbrain activity corresponding to a given movement). For the interface between\nthe brain simulation and the physical world, we utilized Koch v1.1 leader and\nfollower robotic arms. We developed an interactive web console that allows\nusers to generate synthetic brain data from joystick movements in real time.\nOur results are a step towards brain-controlled robotics, prosthetics, and\nenhancing normal motor function. By accurately modeling brain activity, we take\na step toward flexible brain-computer interfaces that generalize beyond\npredefined movements. To support the research community, we provide open source\ntools for both synthetic data generation and neural decoding, fostering\nreproducibility and accelerating progress. The project is available at\nhttps://www.808robots.com/projects/jenkins", "published": "2025-03-19 03:12:17", "link": "http://arxiv.org/abs/2503.14847v1", "categories": ["cs.RO", "cs.AI", "eess.SP", "q-bio.NC"], "primary_category": "cs.RO"}
{"title": "Curiosity-Diffuser: Curiosity Guide Diffusion Models for Reliability", "abstract": "One of the bottlenecks in robotic intelligence is the instability of neural\nnetwork models, which, unlike control models, lack a well-defined convergence\ndomain and stability. This leads to risks when applying intelligence in the\nphysical world. Specifically, imitation policy based on neural network may\ngenerate hallucinations, leading to inaccurate behaviors that impact the safety\nof real-world applications. To address this issue, this paper proposes the\nCuriosity-Diffuser, aimed at guiding the conditional diffusion model to\ngenerate trajectories with lower curiosity, thereby improving the reliability\nof policy. The core idea is to use a Random Network Distillation (RND)\ncuriosity module to assess whether the model's behavior aligns with the\ntraining data, and then minimize curiosity by classifier guidance diffusion to\nreduce overgeneralization during inference. Additionally, we propose a\ncomputationally efficient metric for evaluating the reliability of the policy,\nmeasuring the similarity between the generated behaviors and the training\ndataset, to facilitate research about reliability learning. Finally, simulation\nverify the effectiveness and applicability of the proposed method to a variety\nof scenarios, showing that Curiosity-Diffuser significantly improves task\nperformance and produces behaviors that are more similar to the training data.\nThe code for this work is available at: github.com/CarlDegio/Curiosity-Diffuser", "published": "2025-03-19 02:25:36", "link": "http://arxiv.org/abs/2503.14833v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Learning with Expert Abstractions for Efficient Multi-Task Continuous Control", "abstract": "Decision-making in complex, continuous multi-task environments is often\nhindered by the difficulty of obtaining accurate models for planning and the\ninefficiency of learning purely from trial and error. While precise environment\ndynamics may be hard to specify, human experts can often provide high-fidelity\nabstractions that capture the essential high-level structure of a task and user\npreferences in the target environment. Existing hierarchical approaches often\ntarget discrete settings and do not generalize across tasks. We propose a\nhierarchical reinforcement learning approach that addresses these limitations\nby dynamically planning over the expert-specified abstraction to generate\nsubgoals to learn a goal-conditioned policy. To overcome the challenges of\nlearning under sparse rewards, we shape the reward based on the optimal state\nvalue in the abstract model. This structured decision-making process enhances\nsample efficiency and facilitates zero-shot generalization. Our empirical\nevaluation on a suite of procedurally generated continuous control environments\ndemonstrates that our approach outperforms existing hierarchical reinforcement\nlearning methods in terms of sample efficiency, task completion rate,\nscalability to complex tasks, and generalization to novel scenarios.", "published": "2025-03-19 00:44:23", "link": "http://arxiv.org/abs/2503.14809v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Long Context Modeling with Ranked Memory-Augmented Retrieval", "abstract": "Effective long-term memory management is crucial for language models handling\nextended contexts. We introduce a novel framework that dynamically ranks memory\nentries based on relevance. Unlike previous works, our model introduces a novel\nrelevance scoring and a pointwise re-ranking model for key-value embeddings,\ninspired by learning-to-rank techniques in information retrieval. Enhanced\nRanked Memory Augmented Retrieval ERMAR achieves state-of-the-art results on\nstandard benchmarks.", "published": "2025-03-19 00:24:01", "link": "http://arxiv.org/abs/2503.14800v1", "categories": ["cs.IR", "cs.AI", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Path Eccentricity and Forbidden Induced Subgraphs", "abstract": "The path eccentricity of a connected graph $G$ is the minimum integer $k$\nsuch that $G$ has a path such that every vertex is at distance at most $k$ from\nthe path. A result of Duffus, Jacobson, and Gould from 1981 states that every\nconnected $\\{\\text{claw}, \\text{net}\\}$-free graph $G$ has a Hamiltonian path,\nthat is, $G$ has path eccentricity~$0$. Several more recent works identified\nvarious classes of connected graphs with path eccentricity at most $1$, or,\nequivalently, graphs having a spanning caterpillar, including connected\n$P_5$-free graphs, AT-free graphs, and biconvex graphs. Generalizing all these\nresults, we apply the work on structural distance domination of Bacs\\'o and\nTuza [Discrete Math., 2012] and characterize, for every positive integer $k$,\ngraphs such that every connected induced subgraph has path eccentricity less\nthan $k$. More specifically, we show that every connected $\\{S_{k},\nT_{k}\\}$-free graph has a path eccentricity less than $k$, where $S_k$ and\n$T_k$ are two specific graphs of path eccentricity $k$ (a subdivided claw and\nthe line graph of such a graph). As a consequence, every connected $H$-free\ngraph has path eccentricity less than $k$ if and only if $H$ is an induced\nsubgraph of $3P_{k}$ or $P_{2k+1} + P_{k-1}$. Our main result also answers an\nopen question of Bastide, Hilaire, and Robinson [Discrete Math., 2025].", "published": "2025-03-19 23:34:03", "link": "http://arxiv.org/abs/2503.15747v1", "categories": ["math.CO", "cs.DM", "05C12, 05C38", "G.2.2"], "primary_category": "math.CO"}
{"title": "The Fundamental Limits of Recovering Planted Subgraphs", "abstract": "Given an arbitrary subgraph $H=H_n$ and $p=p_n \\in (0,1)$, the planted\nsubgraph model is defined as follows. A statistician observes the union a\nrandom copy $H^*$ of $H$, together with random noise in the form of an instance\nof an Erdos-Renyi graph $G(n,p)$. Their goal is to recover the planted $H^*$\nfrom the observed graph. Our focus in this work is to understand the minimum\nmean squared error (MMSE) for sufficiently large $n$.\n  A recent paper [MNSSZ23] characterizes the graphs for which the limiting MMSE\ncurve undergoes a sharp phase transition from $0$ to $1$ as $p$ increases, a\nbehavior known as the all-or-nothing phenomenon, up to a mild density\nassumption on $H$. In this paper, we provide a formula for the limiting MMSE\ncurve for any graph $H=H_n$, up to the same mild density assumption. This curve\nis expressed in terms of a variational formula over pairs of subgraphs of $H$,\nand is inspired by the celebrated subgraph expectation thresholds from the\nprobabilistic combinatorics literature [KK07]. Furthermore, we give a\npolynomial-time description of the optimizers of this variational problem. This\nallows one to efficiently approximately compute the MMSE curve for any dense\ngraph $H$ when $n$ is large enough. The proof relies on a novel graph\ndecomposition of $H$ as well as a new minimax theorem which may be of\nindependent interest.\n  Our results generalize to the setting of minimax rates of recovering\narbitrary monotone boolean properties planted in random noise, where the\nstatistician observes the union of a planted minimal element $A \\subseteq [N]$\nof a monotone property and a random $Ber(p)^{\\otimes N}$ vector. In this\nsetting, we provide a variational formula inspired by the so-called\n\"fractional\" expectation threshold [Tal10], again describing the MMSE curve (in\nthis case up to a multiplicative constant) for large enough $n$.", "published": "2025-03-19 22:35:10", "link": "http://arxiv.org/abs/2503.15723v1", "categories": ["math.ST", "cs.DM", "cs.IT", "math.CO", "math.IT", "math.PR", "stat.TH"], "primary_category": "math.ST"}
{"title": "Narrative Trails: A Method for Coherent Storyline Extraction via Maximum Capacity Path Optimization", "abstract": "Traditional information retrieval is primarily concerned with finding\nrelevant information from large datasets without imposing a structure within\nthe retrieved pieces of data. However, structuring information in the form of\nnarratives--ordered sets of documents that form coherent storylines--allows us\nto identify, interpret, and share insights about the connections and\nrelationships between the ideas presented in the data. Despite their\nsignificance, current approaches for algorithmically extracting storylines from\ndata are scarce, with existing methods primarily relying on intricate\nword-based heuristics and auxiliary document structures. Moreover, many of\nthese methods are difficult to scale to large datasets and general contexts, as\nthey are designed to extract storylines for narrow tasks. In this paper, we\npropose Narrative Trails, an efficient, general-purpose method for extracting\ncoherent storylines in large text corpora. Specifically, our method uses the\nsemantic-level information embedded in the latent space of deep learning models\nto build a sparse coherence graph and extract narratives that maximize the\nminimum coherence of the storylines. By quantitatively evaluating our proposed\nmethods on two distinct narrative extraction tasks, we show the\ngeneralizability and scalability of Narrative Trails in multiple contexts while\nalso simplifying the extraction pipeline.", "published": "2025-03-19 20:25:56", "link": "http://arxiv.org/abs/2503.15681v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Optimizing Retrieval Strategies for Financial Question Answering Documents in Retrieval-Augmented Generation Systems", "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a promising framework to\nmitigate hallucinations in Large Language Models (LLMs), yet its overall\nperformance is dependent on the underlying retrieval system. In the finance\ndomain, documents such as 10-K reports pose distinct challenges due to\ndomain-specific vocabulary and multi-hierarchical tabular data. In this work,\nwe introduce an efficient, end-to-end RAG pipeline that enhances retrieval for\nfinancial documents through a three-phase approach: pre-retrieval, retrieval,\nand post-retrieval. In the pre-retrieval phase, various query and corpus\npreprocessing techniques are employed to enrich input data. During the\nretrieval phase, we fine-tuned state-of-the-art (SOTA) embedding models with\ndomain-specific knowledge and implemented a hybrid retrieval strategy that\ncombines dense and sparse representations. Finally, the post-retrieval phase\nleverages Direct Preference Optimization (DPO) training and document selection\nmethods to further refine the results. Evaluations on seven financial question\nanswering datasets-FinDER, FinQABench, FinanceBench, TATQA, FinQA, ConvFinQA,\nand MultiHiertt-demonstrate substantial improvements in retrieval performance,\nleading to more accurate and contextually appropriate generation. These\nfindings highlight the critical role of tailored retrieval techniques in\nadvancing the effectiveness of RAG systems for financial applications. A fully\nreplicable pipeline is available on GitHub:\nhttps://github.com/seohyunwoo-0407/GAR.", "published": "2025-03-19 13:21:49", "link": "http://arxiv.org/abs/2503.15191v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "LLM-Aided Customizable Profiling of Code Data Based On Programming Language Concepts", "abstract": "Data profiling is critical in machine learning for generating descriptive\nstatistics, supporting both deeper understanding and downstream tasks like data\nvaluation and curation. This work addresses profiling specifically in the\ncontext of code datasets for Large Language Models (code-LLMs), where data\nquality directly influences tasks such as code generation and summarization.\nCharacterizing code datasets in terms of programming language concepts enables\nbetter insights and targeted data curation. Our proposed methodology decomposes\ncode data profiling into two phases: (1) an offline phase where LLMs are\nleveraged to derive and learn rules for extracting syntactic and semantic\nconcepts across various programming languages, including previously unseen or\nlow-resource languages, and (2) an online deterministic phase applying these\nderived rules for efficient real-time analysis. This hybrid approach is\ncustomizable, extensible to new syntactic and semantic constructs, and scalable\nto multiple languages. Experimentally, our LLM-aided method achieves a mean\naccuracy of 90.33% for syntactic extraction rules and semantic classification\naccuracies averaging 80% and 77% across languages and semantic concepts,\nrespectively.", "published": "2025-03-19 11:01:00", "link": "http://arxiv.org/abs/2503.15571v1", "categories": ["cs.SE", "cs.ET", "cs.IR", "cs.LG", "cs.PL"], "primary_category": "cs.SE"}
{"title": "Pseudo-Relevance Feedback Can Improve Zero-Shot LLM-Based Dense Retrieval", "abstract": "Pseudo-relevance feedback (PRF) refines queries by leveraging initially\nretrieved documents to improve retrieval effectiveness. In this paper, we\ninvestigate how large language models (LLMs) can facilitate PRF for zero-shot\nLLM-based dense retrieval, extending the recently proposed PromptReps method.\nSpecifically, our approach uses LLMs to extract salient passage features-such\nas keywords and summaries-from top-ranked documents, which are then integrated\ninto PromptReps to produce enhanced query representations. Experiments on\npassage retrieval benchmarks demonstrate that incorporating PRF significantly\nboosts retrieval performance. Notably, smaller rankers with PRF can match the\neffectiveness of larger rankers without PRF, highlighting PRF's potential to\nimprove LLM-driven search while maintaining an efficient balance between\neffectiveness and resource usage.", "published": "2025-03-19 04:30:20", "link": "http://arxiv.org/abs/2503.14887v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Scaled Supervision is an Implicit Lipschitz Regularizer", "abstract": "In modern social media, recommender systems (RecSys) rely on the\nclick-through rate (CTR) as the standard metric to evaluate user engagement.\nCTR prediction is traditionally framed as a binary classification task to\npredict whether a user will interact with a given item. However, this approach\noverlooks the complexity of real-world social modeling, where the user, item,\nand their interactive features change dynamically in fast-paced online\nenvironments. This dynamic nature often leads to model instability, reflected\nin overfitting short-term fluctuations rather than higher-level interactive\npatterns. While overfitting calls for more scaled and refined supervisions,\ncurrent solutions often rely on binary labels that overly simplify fine-grained\nuser preferences through the thresholding process, which significantly reduces\nthe richness of the supervision. Therefore, we aim to alleviate the overfitting\nproblem by increasing the supervision bandwidth in CTR training. Specifically,\n(i) theoretically, we formulate the impact of fine-grained preferences on model\nstability as a Lipschitz constrain; (ii) empirically, we discover that scaling\nthe supervision bandwidth can act as an implicit Lipschitz regularizer, stably\noptimizing existing CTR models to achieve better generalizability. Extensive\nexperiments show that this scaled supervision significantly and consistently\nimproves the optimization process and the performance of existing CTR models,\neven without the need for additional hyperparameter tuning.", "published": "2025-03-19 01:01:28", "link": "http://arxiv.org/abs/2503.14813v1", "categories": ["cs.LG", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Graph-Based Re-ranking: Emerging Techniques, Limitations, and Opportunities", "abstract": "Knowledge graphs have emerged to be promising datastore candidates for\ncontext augmentation during Retrieval Augmented Generation (RAG). As a result,\ntechniques in graph representation learning have been simultaneously explored\nalongside principal neural information retrieval approaches, such as two-phased\nretrieval, also known as re-ranking. While Graph Neural Networks (GNNs) have\nbeen proposed to demonstrate proficiency in graph learning for re-ranking,\nthere are ongoing limitations in modeling and evaluating input graph structures\nfor training and evaluation for passage and document ranking tasks. In this\nsurvey, we review emerging GNN-based ranking model architectures along with\ntheir corresponding graph representation construction methodologies. We\nconclude by providing recommendations on future research based on\ncommunity-wide challenges and opportunities.", "published": "2025-03-19 00:28:54", "link": "http://arxiv.org/abs/2503.14802v1", "categories": ["cs.IR", "N/A"], "primary_category": "cs.IR"}
{"title": "Extending the HNLS Condition to Robust Quantum Metrology", "abstract": "Quantum sensing holds great promise for high-precision magnetic field\nmeasurements. However, its performance is significantly limited by noise. In\nthis work, we develop a quantum sensing protocol to estimate a parameter\n$\\theta$, associated with a magnetic field, under full-rank Markovian noise.\nOur approach uses a probe state constructed from a CSS code that evolves under\nthe parameter's Hamiltonian for a short time, but without any active error\ncorrection. Then we measure the code's $\\hat{X}$ stabilizers to infer $\\theta$.\nGiven $N$ copies of the probe state, we derive the probability that all\nstabilizer measurements return $+1$, which depends on $\\theta$. The uncertainty\nin $\\theta$ (estimated from these measurements) is bounded by a new quantity,\nthe Robustness Bound, which characterizes how the structure of the quantum code\naffects the Quantum Fisher Information of the measurement. Using this bound, we\nestablish a strong no-go result: a nontrivial CSS code can achieve Heisenberg\nscaling if and only if the Hamiltonian is orthogonal to the span of the noise\nchannel's Lindblad operators. This result extends the well-known HNLS condition\nunder infinite rounds of error correction to the robust quantum sensing setting\nthat does not use active error correction. Our finding suggests fundamental\nlimitations in the use of linear quantum codes for dephased magnetic field\nsensing applications both in the near-term robust sensing regime and in the\nlong-term fault tolerant era.", "published": "2025-03-19 23:15:41", "link": "http://arxiv.org/abs/2503.15743v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Most continuous-variable cluster states are too entangled to be useless", "abstract": "We define absolutely maximal entanglement (AME) in continuous-variable (CV)\nsystems and show that, in stark contrast to qudit systems, this entanglement is\ngeneric among infinitely squeezed Gaussian states. In particular, we show that\nCV cluster states are generically AME and provide explicit constructions using\nCauchy, Vandermonde, totally positive, and real-block-code generator matrices.\nFinitely squeezed versions of CV AME states give rise to open-destination\nmulti-party CV teleportation, CV quantum secret sharing, CV majority-agreed key\ndistribution, Gaussian perfect-tensor networks on arbitrary geometries, and\nGaussian multi-unitary circuits.", "published": "2025-03-19 21:18:13", "link": "http://arxiv.org/abs/2503.15698v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "On the Secrecy Performance of $\u03b1$-$\\mathcal{F}$ Channels with Pointing Errors", "abstract": "This paper investigates the physical layer security (PLS) performance of\n$\\alpha$-$\\mathcal{F}$ fading channels with pointing errors under passive and\nactive eavesdropping scenarios. Novel analytical expressions are derived for\nkey PLS metrics, including the probability of strictly positive secrecy\ncapacity, the average secrecy capacity, and the secure outage probability. An\nasymptotic analysis is also investigated to provide further insights into the\nsystem behavior under high signal-to-noise ratio conditions. The analytical\nresults are validated through Monte Carlo simulations, with several performance\ncurves presented for a range of channel and system parameters. All expressions\nderived in this work are original and have not been previously published.", "published": "2025-03-19 18:09:12", "link": "http://arxiv.org/abs/2503.15618v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Integrating Sensing and Communications in 6G? Not Until It Is Secure to Do So", "abstract": "Integrated Sensing and Communication (ISAC) is emerging as a cornerstone\ntechnology for forthcoming 6G systems, significantly improving spectrum and\nenergy efficiency. However, the commercial viability of ISAC hinges on\naddressing critical challenges surrounding security, privacy, and\ntrustworthiness. These challenges necessitate an end-to-end framework to\nsafeguards both communication data and sensing information, particularly in\nultra-low-latency and highly connected environments. Conventional solutions,\nsuch as encryption and key management, often fall short when confronted with\nISAC's dual-functional nature. In this context, the physical layer plays a\npivotal role: this article reviews emerging physical-layer strategies,\nincluding artificial noise (AN) injection, cooperative jamming, and\nconstructive interference (CI), which enhance security by mitigating\neavesdropping risks and safeguarding both communication data and sensing\ninformation. We further highlight the unique privacy issues that ISAC\nintroduces to cellular networks and outline future research directions aimed at\nensuring robust security and privacy for efficient ISAC deployment in 6G.", "published": "2025-03-19 14:20:24", "link": "http://arxiv.org/abs/2503.15243v1", "categories": ["cs.IT", "cs.ET", "math.IT"], "primary_category": "cs.IT"}
{"title": "Cellular Automata on Probability Measures", "abstract": "Classical Cellular Automata (CCAs) are a powerful computational framework\nwidely used to model complex systems driven by local interactions. Their\nsimplicity lies in the use of a finite set of states and a uniform local rule,\nyet this simplicity leads to rich and diverse dynamical behaviors. CCAs have\nfound applications in numerous scientific fields, including quantum computing,\nbiology, social sciences, and cryptography. However, traditional CCAs assume\ncomplete certainty in the state of all cells, which limits their ability to\nmodel systems with inherent uncertainty. This paper introduces a novel\ngeneralization of CCAs, termed Cellular Automata on Measures (CAMs), which\nextends the classical framework to incorporate probabilistic uncertainty. In\nthis setting, the state of each cell is described by a probability measure, and\nthe local rule operates on configurations of such measures. This generalization\nencompasses the traditional Bernoulli measure framework of CCAs and enables the\nstudy of more complex systems, including those with spatially varying\nprobabilities. We provide a rigorous mathematical foundation for CAMs,\ndemonstrate their applicability through concrete examples, and explore their\npotential to model the dynamics of random graphs. Additionally, we establish\nconnections between CAMs and symbolic dynamics, presenting new avenues for\nresearch in random graph theory. This study lays the groundwork for future\nexploration of CAMs, offering a flexible and robust framework for modeling\nuncertainty in cellular automata and opening new directions for both\ntheoretical analysis and practical applications.", "published": "2025-03-19 10:37:23", "link": "http://arxiv.org/abs/2503.15086v1", "categories": ["nlin.CG", "cs.IT", "math.IT"], "primary_category": "nlin.CG"}
{"title": "A low-PAPR Pilot Design and Optimization for OTFS Modulation", "abstract": "Orthogonal time frequency space (OTFS) modulation has been proposed recently\nas a new waveform in the context of doubly-selective multi-path channels. This\narticle proposes a novel pilot design that improves OTFS spectral efficiency\n(SE) while reducing its peak-to-average power ratio (PAPR). Instead of adopting\nan embedded data-orthogonal pilot for channel estimation, our scheme relies on\nChu sequences superimposed to data symbols. We optimize the construction by\ninvestigating the best energy split between pilot and data symbols. Two\nequalizers, and an iterative channel estimation and equalization procedure are\nconsidered. We present extensive numerical results of relevant performance\nmetrics, including the normalized mean squared error of the estimator, bit\nerror rate, PAPR and SE. Our results show that, while the embedded pilot scheme\nestimates the channel more accurately, our approach yields a better tradeoff by\nachieving much higher spectral efficiency and lower PAPR.", "published": "2025-03-19 08:57:33", "link": "http://arxiv.org/abs/2503.15006v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "A Vehicle-Infrastructure Multi-layer Cooperative Decision-making Framework", "abstract": "Autonomous driving has entered the testing phase, but due to the limited\ndecision-making capabilities of individual vehicle algorithms, safety and\nefficiency issues have become more apparent in complex scenarios. With the\nadvancement of connected communication technologies, autonomous vehicles\nequipped with connectivity can leverage vehicle-to-vehicle (V2V) and\nvehicle-to-infrastructure (V2I) communications, offering a potential solution\nto the decision-making challenges from individual vehicle's perspective. We\npropose a multi-level vehicle-infrastructure cooperative decision-making\nframework for complex conflict scenarios at unsignalized intersections. First,\nbased on vehicle states, we define a method for quantifying vehicle impacts and\ntheir propagation relationships, using accumulated impact to group vehicles\nthrough motif-based graph clustering. Next, within and between vehicle groups,\na pass order negotiation process based on Large Language Models (LLM) is\nemployed to determine the vehicle passage order, resulting in planned vehicle\nactions. Simulation results from ablation experiments show that our approach\nreduces negotiation complexity and ensures safer, more efficient vehicle\npassage at intersections, aligning with natural decision-making logic.", "published": "2025-03-19 14:49:39", "link": "http://arxiv.org/abs/2503.16552v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "The fundamental representation of pricing adjustments", "abstract": "This article consolidates and extends past work on derivative pricing\nadjustments, including XVA, by providing an encapsulating representation of the\nadjustment between any two derivative pricing functions, within an Ito\nSDE/parabolic PDE framework. We give examples of this representation\nencapsulating others from the past 20 years, ranging from a well known option\npricing adjustment introduced by Gatheral, to the collection of\nsemi-replication XVA originating from Burgard & Kjaer. To highlight extensions,\nwe discuss certain meta-adjustments beyond XVA, designed to help signal and\nmitigate XVA model risk.", "published": "2025-03-19 08:46:48", "link": "http://arxiv.org/abs/2503.14997v1", "categories": ["q-fin.MF", "q-fin.PR", "q-fin.RM", "91G20, 91G30, 91G40"], "primary_category": "q-fin.MF"}
{"title": "Stochastic Volatility Model with Sticky Drawdown and Drawup Processes: A Deep Learning Approach", "abstract": "We propose a new financial model, the stochastic volatility model with sticky\ndrawdown and drawup processes (SVSDU model), which enables us to capture the\nfeatures of winning and losing streaks that are common across financial markets\nbut can not be captured simultaneously by the existing financial models.\nMoreover, the SVSDU model retains the advantages of the stochastic volatility\nmodels. Since there are not closed-form option pricing formulas under the SVSDU\nmodel and the existing simulation methods for the sticky diffusion processes\nare really time-consuming, we develop a deep neural network to solve the\ncorresponding high-dimensional parametric partial differential equation (PDE),\nwhere the solution to the PDE is the pricing function of a European option\naccording to the Feynman-Kac Theorem, and validate the accuracy and efficiency\nof our deep learning approach. We also propose a novel calibration framework\nfor our model, and demonstrate the calibration performances of our models on\nboth simulated data and historical data. The calibration results on SPX option\ndata show that the SVSDU model is a good representation of the asset value\ndynamic, and both winning and losing streaks are accounted for in option\nvalues. Our model opens new horizons for modeling and predicting the dynamics\nof asset prices in financial markets.", "published": "2025-03-19 02:09:34", "link": "http://arxiv.org/abs/2503.14829v1", "categories": ["q-fin.MF", "q-fin.PR"], "primary_category": "q-fin.MF"}
{"title": "Modelling High-Frequency Data with Bivariate Hawkes Processes: Power-Law vs. Exponential Kernels", "abstract": "This study explores the application of Hawkes processes to model\nhigh-frequency data in the context of limit order books. Two distinct\nHawkes-based models are proposed and analyzed: one utilizing exponential\nkernels and the other employing power-law kernels. These models are implemented\nwithin a bivariate framework. The performance of each model is evaluated using\nhigh-frequency trading data, with a focus on their ability to reproduce key\nstatistical properties of limit order books. Through a comprehensive\ncomparison, we identify the strengths and limitations of each kernel type,\nproviding insights into their suitability for modeling high-frequency financial\ndata. Simulations are conducted to validate the models, and the results are\ninterpreted. Based on these insights, a trading strategy is formulated.", "published": "2025-03-19 01:05:48", "link": "http://arxiv.org/abs/2503.14814v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "HQNN-FSP: A Hybrid Classical-Quantum Neural Network for Regression-Based Financial Stock Market Prediction", "abstract": "Financial time-series forecasting remains a challenging task due to complex\ntemporal dependencies and market fluctuations. This study explores the\npotential of hybrid quantum-classical approaches to assist in financial trend\nprediction by leveraging quantum resources for improved feature representation\nand learning. A custom Quantum Neural Network (QNN) regressor is introduced,\ndesigned with a novel ansatz tailored for financial applications. Two hybrid\noptimization strategies are proposed: (1) a sequential approach where classical\nrecurrent models (RNN/LSTM) extract temporal dependencies before quantum\nprocessing, and (2) a joint learning framework that optimizes classical and\nquantum parameters simultaneously. Systematic evaluation using TimeSeriesSplit,\nk-fold cross-validation, and predictive error analysis highlights the ability\nof these hybrid models to integrate quantum computing into financial\nforecasting workflows. The findings demonstrate how quantum-assisted learning\ncan contribute to financial modeling, offering insights into the practical role\nof quantum resources in time-series analysis.", "published": "2025-03-19 16:44:21", "link": "http://arxiv.org/abs/2503.15403v1", "categories": ["q-fin.ST", "cs.LG", "quant-ph"], "primary_category": "q-fin.ST"}
{"title": "A Speech Production Model for Radar: Connecting Speech Acoustics with Radar-Measured Vibrations", "abstract": "Millimeter Wave (mmWave) radar has emerged as a promising modality for speech\nsensing, offering advantages over traditional microphones. Prior works have\ndemonstrated that radar captures motion signals related to vocal vibrations,\nbut there is a gap in the understanding of the analytical connection between\nradar-measured vibrations and acoustic speech signals. We establish a\nmathematical framework linking radar-captured neck vibrations to speech\nacoustics. We derive an analytical relationship between neck surface\ndisplacements and speech. We use data from 66 human participants, and\nstatistical spectral distance analysis to empirically assess the model. Our\nresults show that the radar-measured signal aligns more closely with our model\nfiltered vibration signal derived from speech than with raw speech itself.\nThese findings provide a foundation for improved radar-based speech processing\nfor applications in speech enhancement, coding, surveillance, and\nauthentication.", "published": "2025-03-19 18:27:07", "link": "http://arxiv.org/abs/2503.15627v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Gridless Chirp Parameter Retrieval via Constrained Two-Dimensional Atomic Norm Minimization", "abstract": "This paper is concerned with the fundamental problem of estimating chirp\nparameters from a mixture of linear chirp signals. Unlike most previous\nmethods, which solve the problem by discretizing the parameter space and then\nestimating the chirp parameters, we propose a gridless approach by\nreformulating the inverse problem as a constrained two-dimensional atomic norm\nminimization from structured measurements. This reformulation enables the\ndirect estimation of continuous-valued parameters without discretization,\nthereby resolving the issue of basis mismatch. An approximate semidefinite\nprogramming (SDP) is employed to solve the proposed convex program.\nAdditionally, a dual polynomial is constructed to certify the optimality of the\natomic decomposition. Numerical simulations demonstrate that exact recovery of\nchirp parameters is achievable using the proposed atomic norm minimization.", "published": "2025-03-19 12:44:23", "link": "http://arxiv.org/abs/2503.15164v1", "categories": ["eess.SP", "eess.AS"], "primary_category": "eess.SP"}
{"title": "Communication Access Real-Time Translation Through Collaborative Correction of Automatic Speech Recognition", "abstract": "Communication access real-time translation (CART) is an essential\naccessibility service for d/Deaf and hard of hearing (DHH) individuals, but the\ncost and scarcity of trained personnel limit its availability. While Automatic\nSpeech Recognition (ASR) offers a cheap and scalable alternative, transcription\nerrors can lead to serious accessibility issues. Real-time correction of ASR by\nnon-professionals presents an under-explored CART workflow that addresses these\nlimitations. We conducted a user study with 75 participants to evaluate the\nfeasibility and efficiency of this workflow. Complementary, we held focus\ngroups with 25 DHH individuals to identify acceptable accuracy levels and\nfactors affecting the accessibility of real-time captioning. Results suggest\nthat collaborative editing can improve transcription accuracy to the extent\nthat DHH users rate it positively regarding understandability. Focus groups\nalso showed that human effort to improve captioning is highly valued,\nsupporting a semi-automated approach as an alternative to stand-alone ASR and\ntraditional CART services.", "published": "2025-03-19 11:29:00", "link": "http://arxiv.org/abs/2503.15120v1", "categories": ["cs.HC", "cs.SD", "eess.AS", "I.2.7"], "primary_category": "cs.HC"}
{"title": "InsectSet459: an open dataset of insect sounds for bioacoustic machine learning", "abstract": "Automatic recognition of insect sound could help us understand changing\nbiodiversity trends around the world -- but insect sounds are challenging to\nrecognize even for deep learning. We present a new dataset comprised of 26399\naudio files, from 459 species of Orthoptera and Cicadidae. It is the first\nlarge-scale dataset of insect sound that is easily applicable for developing\nnovel deep-learning methods. Its recordings were made with a variety of audio\nrecorders using varying sample rates to capture the extremely broad range of\nfrequencies that insects produce. We benchmark performance with two\nstate-of-the-art deep learning classifiers, demonstrating good performance but\nalso significant room for improvement in acoustic insect classification. This\ndataset can serve as a realistic test case for implementing insect monitoring\nworkflows, and as a challenging basis for the development of audio\nrepresentation methods that can handle highly variable frequencies and/or\nsample rates.", "published": "2025-03-19 10:13:29", "link": "http://arxiv.org/abs/2503.15074v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Analysis and Extension of Noisy-target Training for Unsupervised Target Signal Enhancement", "abstract": "Deep neural network-based target signal enhancement (TSE) is usually trained\nin a supervised manner using clean target signals. However, collecting clean\ntarget signals is costly and such signals are not always available. Thus, it is\ndesirable to develop an unsupervised method that does not rely on clean target\nsignals. Among various studies on unsupervised TSE methods, Noisy-target\nTraining (NyTT) has been established as a fundamental method. NyTT simply\nreplaces clean target signals with noisy ones in the typical supervised\ntraining, and it has been experimentally shown to achieve TSE. Despite its\neffectiveness and simplicity, its mechanism and detailed behavior are still\nunclear. In this paper, to advance NyTT and, thus, unsupervised methods as a\nwhole, we analyze NyTT from various perspectives. We experimentally demonstrate\nthe mechanism of NyTT, the desirable conditions, and the effectiveness of\nutilizing noisy signals in situations where a small number of clean target\nsignals are available. Furthermore, we propose an improved version of NyTT\nbased on its properties and explore its capabilities in the dereverberation and\ndeclipping tasks, beyond the denoising task.", "published": "2025-03-19 03:21:23", "link": "http://arxiv.org/abs/2503.14854v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
