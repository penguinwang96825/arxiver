{"title": "Arabic Opinion Mining Using a Hybrid Recommender System Approach", "abstract": "Recommender systems nowadays are playing an important role in the delivery of\nservices and information to users. Sentiment analysis (also known as opinion\nmining) is the process of determining the attitude of textual opinions, whether\nthey are positive, negative or neutral. Data sparsity is representing a big\nissue for recommender systems because of the insufficiency of user rating or\nabsence of data about users or items. This research proposed a hybrid approach\ncombining sentiment analysis and recommender systems to tackle the problem of\ndata sparsity problems by predicting the rating of products from users reviews\nusing text mining and NLP techniques. This research focuses especially on\nArabic reviews, where the model is evaluated using Opinion Corpus for Arabic\n(OCA) dataset. Our system was efficient, and it showed a good accuracy of\nnearly 85 percent in predicting rating from reviews", "published": "2020-09-16 00:21:56", "link": "http://arxiv.org/abs/2009.07397v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Retrofitting Structure-aware Transformer Language Model for End Tasks", "abstract": "We consider retrofitting structure-aware Transformer-based language model for\nfacilitating end tasks by proposing to exploit syntactic distance to encode\nboth the phrasal constituency and dependency connection into the language\nmodel. A middle-layer structural learning strategy is leveraged for structure\nintegration, accomplished with main semantic task training under multi-task\nlearning scheme. Experimental results show that the retrofitted structure-aware\nTransformer language model achieves improved perplexity, meanwhile inducing\naccurate syntactic phrases. By performing structure-aware fine-tuning, our\nmodel achieves significant improvements for both semantic- and\nsyntactic-dependent tasks.", "published": "2020-09-16 01:07:07", "link": "http://arxiv.org/abs/2009.07408v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mimic and Conquer: Heterogeneous Tree Structure Distillation for\n  Syntactic NLP", "abstract": "Syntax has been shown useful for various NLP tasks, while existing work\nmostly encodes singleton syntactic tree using one hierarchical neural network.\nIn this paper, we investigate a simple and effective method, Knowledge\nDistillation, to integrate heterogeneous structure knowledge into a unified\nsequential LSTM encoder. Experimental results on four typical syntax-dependent\ntasks show that our method outperforms tree encoders by effectively integrating\nrich heterogeneous structure syntax, meanwhile reducing error propagation, and\nalso outperforms ensemble methods, in terms of both the efficiency and\naccuracy.", "published": "2020-09-16 01:30:21", "link": "http://arxiv.org/abs/2009.07411v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Answering Any-hop Open-domain Questions with Iterative Document\n  Reranking", "abstract": "Existing approaches for open-domain question answering (QA) are typically\ndesigned for questions that require either single-hop or multi-hop reasoning,\nwhich make strong assumptions of the complexity of questions to be answered.\nAlso, multi-step document retrieval often incurs higher number of relevant but\nnon-supporting documents, which dampens the downstream noise-sensitive reader\nmodule for answer extraction. To address these challenges, we propose a unified\nQA framework to answer any-hop open-domain questions, which iteratively\nretrieves, reranks and filters documents, and adaptively determines when to\nstop the retrieval process. To improve the retrieval accuracy, we propose a\ngraph-based reranking model that perform multi-document interaction as the core\nof our iterative reranking framework. Our method consistently achieves\nperformance comparable to or better than the state-of-the-art on both\nsingle-hop and multi-hop open-domain QA datasets, including Natural Questions\nOpen, SQuAD Open, and HotpotQA.", "published": "2020-09-16 04:31:38", "link": "http://arxiv.org/abs/2009.07465v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Summarization by Jointly Extracting Sentences and Keywords", "abstract": "We present RepRank, an unsupervised graph-based ranking model for extractive\nmulti-document summarization in which the similarity between words, sentences,\nand word-to-sentence can be estimated by the distances between their vector\nrepresentations in a unified vector space. In order to obtain desirable\nrepresentations, we propose a self-attention based learning method that\nrepresent a sentence by the weighted sum of its word embeddings, and the\nweights are concentrated to those words hopefully better reflecting the content\nof a document. We show that salient sentences and keywords can be extracted in\na joint and mutual reinforcement process using our learned representations, and\nprove that this process always converges to a unique solution leading to\nimprovement in performance. A variant of absorbing random walk and the\ncorresponding sampling-based algorithm are also described to avoid redundancy\nand increase diversity in the summaries. Experiment results with multiple\nbenchmark datasets show that RepRank achieved the best or comparable\nperformance in ROUGE.", "published": "2020-09-16 05:58:00", "link": "http://arxiv.org/abs/2009.07481v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Graph-to-Sequence Neural Machine Translation", "abstract": "Neural machine translation (NMT) usually works in a seq2seq learning way by\nviewing either source or target sentence as a linear sequence of words, which\ncan be regarded as a special case of graph, taking words in the sequence as\nnodes and relationships between words as edges. In the light of the current NMT\nmodels more or less capture graph information among the sequence in a latent\nway, we present a graph-to-sequence model facilitating explicit graph\ninformation capturing. In detail, we propose a graph-based SAN-based NMT model\ncalled Graph-Transformer by capturing information of subgraphs of different\norders in every layers. Subgraphs are put into different groups according to\ntheir orders, and every group of subgraphs respectively reflect different\nlevels of dependency between words. For fusing subgraph representations, we\nempirically explore three methods which weight different groups of subgraphs of\ndifferent orders. Results of experiments on WMT14 English-German and IWSLT14\nGerman-English show that our method can effectively boost the Transformer with\nan improvement of 1.1 BLEU points on WMT14 English-German dataset and 1.0 BLEU\npoints on IWSLT14 German-English dataset.", "published": "2020-09-16 06:28:58", "link": "http://arxiv.org/abs/2009.07489v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contextualized Perturbation for Textual Adversarial Attack", "abstract": "Adversarial examples expose the vulnerabilities of natural language\nprocessing (NLP) models, and can be used to evaluate and improve their\nrobustness. Existing techniques of generating such examples are typically\ndriven by local heuristic rules that are agnostic to the context, often\nresulting in unnatural and ungrammatical outputs. This paper presents CLARE, a\nContextuaLized AdversaRial Example generation model that produces fluent and\ngrammatical outputs through a mask-then-infill procedure. CLARE builds on a\npre-trained masked language model and modifies the inputs in a context-aware\nmanner. We propose three contextualized perturbations, Replace, Insert and\nMerge, allowing for generating outputs of varied lengths. With a richer range\nof available strategies, CLARE is able to attack a victim model more\nefficiently with fewer edits. Extensive experiments and human evaluation\ndemonstrate that CLARE outperforms the baselines in terms of attack success\nrate, textual similarity, fluency and grammaticality.", "published": "2020-09-16 06:53:15", "link": "http://arxiv.org/abs/2009.07502v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UNION: An Unreferenced Metric for Evaluating Open-ended Story Generation", "abstract": "Despite the success of existing referenced metrics (e.g., BLEU and\nMoverScore), they correlate poorly with human judgments for open-ended text\ngeneration including story or dialog generation because of the notorious\none-to-many issue: there are many plausible outputs for the same input, which\nmay differ substantially in literal or semantics from the limited number of\ngiven references. To alleviate this issue, we propose UNION, a learnable\nunreferenced metric for evaluating open-ended story generation, which measures\nthe quality of a generated story without any reference. Built on top of BERT,\nUNION is trained to distinguish human-written stories from negative samples and\nrecover the perturbation in negative stories. We propose an approach of\nconstructing negative samples by mimicking the errors commonly observed in\nexisting NLG models, including repeated plots, conflicting logic, and\nlong-range incoherence. Experiments on two story datasets demonstrate that\nUNION is a reliable measure for evaluating the quality of generated stories,\nwhich correlates better with human judgments and is more generalizable than\nexisting state-of-the-art metrics.", "published": "2020-09-16 11:01:46", "link": "http://arxiv.org/abs/2009.07602v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reusing a Pretrained Language Model on Languages with Limited Corpora\n  for Unsupervised NMT", "abstract": "Using a language model (LM) pretrained on two languages with large\nmonolingual data in order to initialize an unsupervised neural machine\ntranslation (UNMT) system yields state-of-the-art results. When limited data is\navailable for one language, however, this method leads to poor translations. We\npresent an effective approach that reuses an LM that is pretrained only on the\nhigh-resource language. The monolingual LM is fine-tuned on both languages and\nis then used to initialize a UNMT model. To reuse the pretrained LM, we have to\nmodify its predefined vocabulary, to account for the new language. We therefore\npropose a novel vocabulary extension method. Our approach, RE-LM, outperforms a\ncompetitive cross-lingual pretraining model (XLM) in English-Macedonian (En-Mk)\nand English-Albanian (En-Sq), yielding more than +8.3 BLEU points for all four\ntranslation directions.", "published": "2020-09-16 11:37:10", "link": "http://arxiv.org/abs/2009.07610v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Dialogue State Tracking with Temporally Expressive Networks", "abstract": "Dialogue state tracking (DST) is an important part of a spoken dialogue\nsystem. Existing DST models either ignore temporal feature dependencies across\ndialogue turns or fail to explicitly model temporal state dependencies in a\ndialogue. In this work, we propose Temporally Expressive Networks (TEN) to\njointly model the two types of temporal dependencies in DST. The TEN model\nutilizes the power of recurrent networks and probabilistic graphical models.\nEvaluating on standard datasets, TEN is demonstrated to be effective in\nimproving the accuracy of turn-level-state prediction and the state\naggregation.", "published": "2020-09-16 11:53:00", "link": "http://arxiv.org/abs/2009.07615v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Parallel Interactive Networks for Multi-Domain Dialogue State Generation", "abstract": "The dependencies between system and user utterances in the same turn and\nacross different turns are not fully considered in existing multidomain\ndialogue state tracking (MDST) models. In this study, we argue that the\nincorporation of these dependencies is crucial for the design of MDST and\npropose Parallel Interactive Networks (PIN) to model these dependencies.\nSpecifically, we integrate an interactive encoder to jointly model the in-turn\ndependencies and cross-turn dependencies. The slot-level context is introduced\nto extract more expressive features for different slots. And a distributed copy\nmechanism is utilized to selectively copy words from historical system\nutterances or historical user utterances. Empirical studies demonstrated the\nsuperiority of the proposed PIN model.", "published": "2020-09-16 11:54:15", "link": "http://arxiv.org/abs/2009.07616v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reasoning about Goals, Steps, and Temporal Ordering with WikiHow", "abstract": "We propose a suite of reasoning tasks on two types of relations between\nprocedural events: goal-step relations (\"learn poses\" is a step in the larger\ngoal of \"doing yoga\") and step-step temporal relations (\"buy a yoga mat\"\ntypically precedes \"learn poses\"). We introduce a dataset targeting these two\nrelations based on wikiHow, a website of instructional how-to articles. Our\nhuman-validated test set serves as a reliable benchmark for commonsense\ninference, with a gap of about 10% to 20% between the performance of\nstate-of-the-art transformer models and human performance. Our\nautomatically-generated training set allows models to effectively transfer to\nout-of-domain tasks requiring knowledge of procedural events, with greatly\nimproved performances on SWAG, Snips, and the Story Cloze Test in zero- and\nfew-shot settings.", "published": "2020-09-16 13:50:09", "link": "http://arxiv.org/abs/2009.07690v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge Graphs for Multilingual Language Translation and Generation", "abstract": "The Natural Language Processing (NLP) community has recently seen outstanding\nprogress, catalysed by the release of different Neural Network (NN)\narchitectures. Neural-based approaches have proven effective by significantly\nincreasing the output quality of a large number of automated solutions for NLP\ntasks (Belinkov and Glass, 2019). Despite these notable advancements, dealing\nwith entities still poses a difficult challenge as they are rarely seen in\ntraining data. Entities can be classified into two groups, i.e., proper nouns\nand common nouns. Proper nouns are also known as Named Entities (NE) and\ncorrespond to the name of people, organizations, or locations, e.g., John, WHO,\nor Canada. Common nouns describe classes of objects, e.g., spoon or cancer.\nBoth types of entities can be found in a Knowledge Graph (KG). Recent work has\nsuccessfully exploited the contribution of KGs in NLP tasks, such as Natural\nLanguage Inference (NLI) (KM et al.,2018) and Question Answering (QA) (Sorokin\nand Gurevych, 2018). Only a few works had exploited the benefits of KGs in\nNeural Machine Translation (NMT) when the work presented herein began.\nAdditionally, few works had studied the contribution of KGs to Natural Language\nGeneration (NLG) tasks. Moreover, the multilinguality also remained an open\nresearch area in these respective tasks (Young et al., 2018). In this thesis,\nwe focus on the use of KGs for machine translation and the generation of texts\nto deal with the problems caused by entities and consequently enhance the\nquality of automatically generated texts.", "published": "2020-09-16 14:36:41", "link": "http://arxiv.org/abs/2009.07715v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NABU $\\mathrm{-}$ Multilingual Graph-based Neural RDF Verbalizer", "abstract": "The RDF-to-text task has recently gained substantial attention due to\ncontinuous growth of Linked Data. In contrast to traditional pipeline models,\nrecent studies have focused on neural models, which are now able to convert a\nset of RDF triples into text in an end-to-end style with promising results.\nHowever, English is the only language widely targeted. We address this research\ngap by presenting NABU, a multilingual graph-based neural model that verbalizes\nRDF data to German, Russian, and English. NABU is based on an encoder-decoder\narchitecture, uses an encoder inspired by Graph Attention Networks and a\nTransformer as decoder. Our approach relies on the fact that knowledge graphs\nare language-agnostic and they hence can be used to generate multilingual text.\nWe evaluate NABU in monolingual and multilingual settings on standard\nbenchmarking WebNLG datasets. Our results show that NABU outperforms\nstate-of-the-art approaches on English with 66.21 BLEU, and achieves consistent\nresults across all languages on the multilingual scenario with 56.04 BLEU.", "published": "2020-09-16 14:59:06", "link": "http://arxiv.org/abs/2009.07728v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generative Language-Grounded Policy in Vision-and-Language Navigation\n  with Bayes' Rule", "abstract": "Vision-and-language navigation (VLN) is a task in which an agent is embodied\nin a realistic 3D environment and follows an instruction to reach the goal\nnode. While most of the previous studies have built and investigated a\ndiscriminative approach, we notice that there are in fact two possible\napproaches to building such a VLN agent: discriminative \\textit{and}\ngenerative. In this paper, we design and investigate a generative\nlanguage-grounded policy which uses a language model to compute the\ndistribution over all possible instructions i.e. all possible sequences of\nvocabulary tokens given action and the transition history. In experiments, we\nshow that the proposed generative approach outperforms the discriminative\napproach in the Room-2-Room (R2R) and Room-4-Room (R4R) datasets, especially in\nthe unseen environments. We further show that the combination of the generative\nand discriminative policies achieves close to the state-of-the art results in\nthe R2R dataset, demonstrating that the generative and discriminative policies\ncapture the different aspects of VLN.", "published": "2020-09-16 16:23:17", "link": "http://arxiv.org/abs/2009.07783v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How to marry a star: probabilistic constraints for meaning in context", "abstract": "In this paper, we derive a notion of 'word meaning in context' that\ncharacterizes meaning as both intensional and conceptual. We introduce a\nframework for specifying local as well as global constraints on word meaning in\ncontext, together with their interactions, thus modelling the wide range of\nlexical shifts and ambiguities observed in utterance interpretation. We\nrepresent sentence meaning as a 'situation description system', a probabilistic\nmodel which takes utterance understanding to be the mental process of\ndescribing to oneself one or more situations that would account for an observed\nutterance. We show how the system can be implemented in practice, and apply it\nto examples containing various contextualisation phenomena.", "published": "2020-09-16 21:11:23", "link": "http://arxiv.org/abs/2009.07936v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Few-Shot Semantic Parser for Wizard-of-Oz Dialogues with the Precise\n  ThingTalk Representation", "abstract": "Previous attempts to build effective semantic parsers for Wizard-of-Oz (WOZ)\nconversations suffer from the difficulty in acquiring a high-quality, manually\nannotated training set. Approaches based only on dialogue synthesis are\ninsufficient, as dialogues generated from state-machine based models are poor\napproximations of real-life conversations. Furthermore, previously proposed\ndialogue state representations are ambiguous and lack the precision necessary\nfor building an effective agent. This paper proposes a new dialogue\nrepresentation and a sample-efficient methodology that can predict precise\ndialogue states in WOZ conversations. We extended the ThingTalk representation\nto capture all information an agent needs to respond properly. Our training\nstrategy is sample-efficient: we combine (1) fewshot data sparsely sampling the\nfull dialogue space and (2) synthesized data covering a subset space of\ndialogues generated by a succinct state-based dialogue model. The completeness\nof the extended ThingTalk language is demonstrated with a fully operational\nagent, which is also used in training data synthesis. We demonstrate the\neffectiveness of our methodology on MultiWOZ 3.0, a reannotation of the\nMultiWOZ 2.1 dataset in ThingTalk. ThingTalk can represent 98% of the test\nturns, while the simulator can emulate 85% of the validation set. We train a\ncontextual semantic parser using our strategy, and obtain 79% turn-by-turn\nexact match accuracy on the reannotated test set.", "published": "2020-09-16 22:52:46", "link": "http://arxiv.org/abs/2009.07968v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Document-level Neural Machine Translation with Document Embeddings", "abstract": "Standard neural machine translation (NMT) is on the assumption of\ndocument-level context independent. Most existing document-level NMT methods\nare satisfied with a smattering sense of brief document-level information,\nwhile this work focuses on exploiting detailed document-level context in terms\nof multiple forms of document embeddings, which is capable of sufficiently\nmodeling deeper and richer document-level context. The proposed document-aware\nNMT is implemented to enhance the Transformer baseline by introducing both\nglobal and local document-level clues on the source end. Experiments show that\nthe proposed method significantly improves the translation performance over\nstrong baselines and other related studies.", "published": "2020-09-16 19:43:29", "link": "http://arxiv.org/abs/2009.08775v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Asking Complex Questions with Multi-hop Answer-focused Reasoning", "abstract": "Asking questions from natural language text has attracted increasing\nattention recently, and several schemes have been proposed with promising\nresults by asking the right question words and copy relevant words from the\ninput to the question. However, most state-of-the-art methods focus on asking\nsimple questions involving single-hop relations. In this paper, we propose a\nnew task called multihop question generation that asks complex and semantically\nrelevant questions by additionally discovering and modeling the multiple\nentities and their semantic relations given a collection of documents and the\ncorresponding answer 1. To solve the problem, we propose multi-hop\nanswer-focused reasoning on the grounded answer-centric entity graph to include\ndifferent granularity levels of semantic information including the word-level\nand document-level semantics of the entities and their semantic relations.\nThrough extensive experiments on the HOTPOTQA dataset, we demonstrate the\nsuperiority and effectiveness of our proposed model that serves as a baseline\nto motivate future work.", "published": "2020-09-16 00:30:49", "link": "http://arxiv.org/abs/2009.07402v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Tag and Correct: Question aware Open Information Extraction with\n  Two-stage Decoding", "abstract": "Question Aware Open Information Extraction (Question aware Open IE) takes\nquestion and passage as inputs, outputting an answer tuple which contains a\nsubject, a predicate, and one or more arguments. Each field of answer is a\nnatural language word sequence and is extracted from the passage. The\nsemi-structured answer has two advantages which are more readable and\nfalsifiable compared to span answer. There are two approaches to solve this\nproblem. One is an extractive method which extracts candidate answers from the\npassage with the Open IE model, and ranks them by matching with questions. It\nfully uses the passage information at the extraction step, but the extraction\nis independent to the question. The other one is the generative method which\nuses a sequence to sequence model to generate answers directly. It combines the\nquestion and passage as input at the same time, but it generates the answer\nfrom scratch, which does not use the facts that most of the answer words come\nfrom in the passage. To guide the generation by passage, we present a two-stage\ndecoding model which contains a tagging decoder and a correction decoder. At\nthe first stage, the tagging decoder will tag keywords from the passage. At the\nsecond stage, the correction decoder will generate answers based on tagged\nkeywords. Our model could be trained end-to-end although it has two stages.\nCompared to previous generative models, we generate better answers by\ngenerating coarse to fine. We evaluate our model on WebAssertions (Yan et al.,\n2018) which is a Question aware Open IE dataset. Our model achieves a BLEU\nscore of 59.32, which is better than previous generative methods.", "published": "2020-09-16 00:58:13", "link": "http://arxiv.org/abs/2009.07406v1", "categories": ["cs.CL", "cs.AI", "68T50, 68T01"], "primary_category": "cs.CL"}
{"title": "Solomon at SemEval-2020 Task 11: Ensemble Architecture for Fine-Tuned\n  Propaganda Detection in News Articles", "abstract": "This paper describes our system (Solomon) details and results of\nparticipation in the SemEval 2020 Task 11 \"Detection of Propaganda Techniques\nin News Articles\"\\cite{DaSanMartinoSemeval20task11}. We participated in Task\n\"Technique Classification\" (TC) which is a multi-class classification task. To\naddress the TC task, we used RoBERTa based transformer architecture for\nfine-tuning on the propaganda dataset. The predictions of RoBERTa were further\nfine-tuned by class-dependent-minority-class classifiers. A special classifier,\nwhich employs dynamically adapted Least Common Sub-sequence algorithm, is used\nto adapt to the intricacies of repetition class. Compared to the other\nparticipating systems, our submission is ranked 4th on the leaderboard.", "published": "2020-09-16 05:00:40", "link": "http://arxiv.org/abs/2009.07473v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Are Interpretations Fairly Evaluated? A Definition Driven Pipeline for\n  Post-Hoc Interpretability", "abstract": "Recent years have witnessed an increasing number of interpretation methods\nbeing developed for improving transparency of NLP models. Meanwhile,\nresearchers also try to answer the question that whether the obtained\ninterpretation is faithful in explaining mechanisms behind model prediction?\nSpecifically, (Jain and Wallace, 2019) proposes that \"attention is not\nexplanation\" by comparing attention interpretation with gradient alternatives.\nHowever, it raises a new question that can we safely pick one interpretation\nmethod as the ground-truth? If not, on what basis can we compare different\ninterpretation methods? In this work, we propose that it is crucial to have a\nconcrete definition of interpretation before we could evaluate faithfulness of\nan interpretation. The definition will affect both the algorithm to obtain\ninterpretation and, more importantly, the metric used in evaluation. Through\nboth theoretical and experimental analysis, we find that although\ninterpretation methods perform differently under a certain evaluation metric,\nsuch a difference may not result from interpretation quality or faithfulness,\nbut rather the inherent bias of the evaluation metric.", "published": "2020-09-16 06:38:03", "link": "http://arxiv.org/abs/2009.07494v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Simplified TinyBERT: Knowledge Distillation for Document Retrieval", "abstract": "Despite the effectiveness of utilizing the BERT model for document ranking,\nthe high computational cost of such approaches limits their uses. To this end,\nthis paper first empirically investigates the effectiveness of two knowledge\ndistillation models on the document ranking task. In addition, on top of the\nrecently proposed TinyBERT model, two simplifications are proposed. Evaluations\non two different and widely-used benchmarks demonstrate that Simplified\nTinyBERT with the proposed simplifications not only boosts TinyBERT, but also\nsignificantly outperforms BERT-Base when providing 15$\\times$ speedup.", "published": "2020-09-16 07:59:33", "link": "http://arxiv.org/abs/2009.07531v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Group-wise Contrastive Learning for Neural Dialogue Generation", "abstract": "Neural dialogue response generation has gained much popularity in recent\nyears. Maximum Likelihood Estimation (MLE) objective is widely adopted in\nexisting dialogue model learning. However, models trained with MLE objective\nfunction are plagued by the low-diversity issue when it comes to the\nopen-domain conversational setting. Inspired by the observation that humans not\nonly learn from the positive signals but also benefit from correcting behaviors\nof undesirable actions, in this work, we introduce contrastive learning into\ndialogue generation, where the model explicitly perceives the difference\nbetween the well-chosen positive and negative utterances. Specifically, we\nemploy a pretrained baseline model as a reference. During contrastive learning,\nthe target dialogue model is trained to give higher conditional probabilities\nfor the positive samples, and lower conditional probabilities for those\nnegative samples, compared to the reference model. To manage the multi-mapping\nrelations prevailed in human conversation, we augment contrastive dialogue\nlearning with group-wise dual sampling. Extensive experimental results show\nthat the proposed group-wise contrastive learning framework is suited for\ntraining a wide range of neural dialogue generation models with very favorable\nperformance over the baseline training approaches.", "published": "2020-09-16 08:28:30", "link": "http://arxiv.org/abs/2009.07543v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "RDF2Vec Light -- A Lightweight Approach for Knowledge Graph Embeddings", "abstract": "Knowledge graph embedding approaches represent nodes and edges of graphs as\nmathematical vectors. Current approaches focus on embedding complete knowledge\ngraphs, i.e. all nodes and edges. This leads to very high computational\nrequirements on large graphs such as DBpedia or Wikidata. However, for most\ndownstream application scenarios, only a small subset of concepts is of actual\ninterest. In this paper, we present RDF2Vec Light, a lightweight embedding\napproach based on RDF2Vec which generates vectors for only a subset of\nentities. To that end, RDF2Vec Light only traverses and processes a subgraph of\nthe knowledge graph. Our method allows the application of embeddings of very\nlarge knowledge graphs in scenarios where such embeddings were not possible\nbefore due to a significantly lower runtime and significantly reduced hardware\nrequirements.", "published": "2020-09-16 12:58:31", "link": "http://arxiv.org/abs/2009.07659v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Adoption of Twitter's New Length Limit: Is 280 the New 140?", "abstract": "In November 2017, Twitter doubled the maximum allowed tweet length from 140\nto 280 characters, a drastic switch on one of the world's most influential\nsocial media platforms. In the first long-term study of how the new length\nlimit was adopted by Twitter users, we ask: Does the effect of the new length\nlimit resemble that of the old one? Or did the doubling of the limit\nfundamentally change how Twitter is shaped by the limited length of posted\ncontent? By analyzing Twitter's publicly available 1% sample over a period of\naround 3 years, we find that, when the length limit was raised from 140 to 280\ncharacters, the prevalence of tweets around 140 characters dropped immediately,\nwhile the prevalence of tweets around 280 characters rose steadily for about 6\nmonths. Despite this rise, tweets approaching the length limit have been far\nless frequent after than before the switch. We find widely different adoption\nrates across languages and client-device types. The prevalence of tweets around\n140 characters before the switch in a given language is strongly correlated\nwith the prevalence of tweets around 280 characters after the switch in the\nsame language, and very long tweets are vastly more popular on Web clients than\non mobile clients. Moreover, tweets of around 280 characters after the switch\nare syntactically and semantically similar to tweets of around 140 characters\nbefore the switch, manifesting patterns of message squeezing in both cases.\nTaken together, these findings suggest that the new 280-character limit\nconstitutes a new, less intrusive version of the old 140-character limit. The\nlength limit remains an important factor that should be considered in all\nstudies using Twitter data.", "published": "2020-09-16 13:01:05", "link": "http://arxiv.org/abs/2009.07661v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Leveraging Semantic Parsing for Relation Linking over Knowledge Bases", "abstract": "Knowledgebase question answering systems are heavily dependent on relation\nextraction and linking modules. However, the task of extracting and linking\nrelations from text to knowledgebases faces two primary challenges; the\nambiguity of natural language and lack of training data. To overcome these\nchallenges, we present SLING, a relation linking framework which leverages\nsemantic parsing using Abstract Meaning Representation (AMR) and distant\nsupervision. SLING integrates multiple relation linking approaches that capture\ncomplementary signals such as linguistic cues, rich semantic representation,\nand information from the knowledgebase. The experiments on relation linking\nusing three KBQA datasets; QALD-7, QALD-9, and LC-QuAD 1.0 demonstrate that the\nproposed approach achieves state-of-the-art performance on all benchmarks.", "published": "2020-09-16 14:56:11", "link": "http://arxiv.org/abs/2009.07726v1", "categories": ["cs.CL", "cs.AI", "68T35", "I.2.7; I.2.4"], "primary_category": "cs.CL"}
{"title": "GLUCOSE: GeneraLized and COntextualized Story Explanations", "abstract": "When humans read or listen, they make implicit commonsense inferences that\nframe their understanding of what happened and why. As a step toward AI systems\nthat can build similar mental models, we introduce GLUCOSE, a large-scale\ndataset of implicit commonsense causal knowledge, encoded as causal\nmini-theories about the world, each grounded in a narrative context. To\nconstruct GLUCOSE, we drew on cognitive psychology to identify ten dimensions\nof causal explanation, focusing on events, states, motivations, and emotions.\nEach GLUCOSE entry includes a story-specific causal statement paired with an\ninference rule generalized from the statement. This paper details two concrete\ncontributions. First, we present our platform for effectively crowdsourcing\nGLUCOSE data at scale, which uses semi-structured templates to elicit causal\nexplanations. Using this platform, we collected a total of ~670K specific\nstatements and general rules that capture implicit commonsense knowledge about\neveryday situations. Second, we show that existing knowledge resources and\npretrained language models do not include or readily predict GLUCOSE's rich\ninferential content. However, when state-of-the-art neural models are trained\non this knowledge, they can start to make commonsense inferences on unseen\nstories that match humans' mental models.", "published": "2020-09-16 15:41:21", "link": "http://arxiv.org/abs/2009.07758v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Deep Learning Approaches for Extracting Adverse Events and Indications\n  of Dietary Supplements from Clinical Text", "abstract": "The objective of our work is to demonstrate the feasibility of utilizing deep\nlearning models to extract safety signals related to the use of dietary\nsupplements (DS) in clinical text. Two tasks were performed in this study. For\nthe named entity recognition (NER) task, Bi-LSTM-CRF (Bidirectional\nLong-Short-Term-Memory Conditional Random Fields) and BERT (Bidirectional\nEncoder Representations from Transformers) models were trained and compared\nwith CRF model as a baseline to recognize the named entities of DS and Events\nfrom clinical notes. In the relation extraction (RE) task, two deep learning\nmodels, including attention-based Bi-LSTM and CNN (Convolutional Neural\nNetwork), and a random forest model were trained to extract the relations\nbetween DS and Events, which were categorized into three classes: positive\n(i.e., indication), negative (i.e., adverse events), and not related. The best\nperformed NER and RE models were further applied on clinical notes mentioning\n88 DS for discovering DS adverse events and indications, which were compared\nwith a DS knowledge base. For the NER task, deep learning models achieved a\nbetter performance than CRF, with F1 scores above 0.860. The attention-based\nBi-LSTM model performed the best in the relation extraction task, with the F1\nscore of 0.893. When comparing DS event pairs generated by the deep learning\nmodels with the knowledge base for DS and Event, we found both known and\nunknown pairs. Deep learning models can detect adverse events and indication of\nDS in clinical notes, which hold great potential for monitoring the safety of\nDS use.", "published": "2020-09-16 16:18:04", "link": "http://arxiv.org/abs/2009.07780v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Text Generation by Learning from Demonstrations", "abstract": "Current approaches to text generation largely rely on autoregressive models\nand maximum likelihood estimation. This paradigm leads to (i) diverse but\nlow-quality samples due to mismatched learning objective and evaluation metric\n(likelihood vs. quality) and (ii) exposure bias due to mismatched history\ndistributions (gold vs. model-generated). To alleviate these problems, we frame\ntext generation as an offline reinforcement learning (RL) problem with expert\ndemonstrations (i.e., the reference), where the goal is to maximize quality\ngiven model-generated histories. We propose GOLD (generation by off-policy\nlearning from demonstrations): an easy-to-optimize algorithm that learns from\nthe demonstrations by importance weighting. Intuitively, GOLD upweights\nconfident tokens and downweights unconfident ones in the reference during\ntraining, avoiding optimization issues faced by prior RL approaches that rely\non online data collection. According to both automatic and human evaluation,\nmodels trained by GOLD outperform those trained by MLE and policy gradient on\nsummarization, question generation, and machine translation. Further, our\nmodels are less sensitive to decoding algorithms and alleviate exposure bias.", "published": "2020-09-16 17:58:37", "link": "http://arxiv.org/abs/2009.07839v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Grounded Adaptation for Zero-shot Executable Semantic Parsing", "abstract": "We propose Grounded Adaptation for Zero-shot Executable Semantic Parsing\n(GAZP) to adapt an existing semantic parser to new environments (e.g. new\ndatabase schemas). GAZP combines a forward semantic parser with a backward\nutterance generator to synthesize data (e.g. utterances and SQL queries) in the\nnew environment, then selects cycle-consistent examples to adapt the parser.\nUnlike data-augmentation, which typically synthesizes unverified examples in\nthe training environment, GAZP synthesizes examples in the new environment\nwhose input-output consistency are verified. On the Spider, Sparc, and CoSQL\nzero-shot semantic parsing tasks, GAZP improves logical form and execution\naccuracy of the baseline parser. Our analyses show that GAZP outperforms\ndata-augmentation in the training environment, performance increases with the\namount of GAZP-synthesized data, and cycle-consistency is central to successful\nadaptation.", "published": "2020-09-16 00:16:59", "link": "http://arxiv.org/abs/2009.07396v3", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Extremely Low Bit Transformer Quantization for On-Device Neural Machine\n  Translation", "abstract": "The deployment of widely used Transformer architecture is challenging because\nof heavy computation load and memory overhead during inference, especially when\nthe target device is limited in computational resources such as mobile or edge\ndevices. Quantization is an effective technique to address such challenges. Our\nanalysis shows that for a given number of quantization bits, each block of\nTransformer contributes to translation quality and inference computations in\ndifferent manners. Moreover, even inside an embedding block, each word presents\nvastly different contributions. Correspondingly, we propose a mixed precision\nquantization strategy to represent Transformer weights by an extremely low\nnumber of bits (e.g., under 3 bits). For example, for each word in an embedding\nblock, we assign different quantization bits based on statistical property. Our\nquantized Transformer model achieves 11.8$\\times$ smaller model size than the\nbaseline model, with less than -0.5 BLEU. We achieve 8.3$\\times$ reduction in\nrun-time memory footprints and 3.5$\\times$ speed up (Galaxy N10+) such that our\nproposed compression strategy enables efficient implementation for on-device\nNMT.", "published": "2020-09-16 03:58:01", "link": "http://arxiv.org/abs/2009.07453v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Minimize Exposure Bias of Seq2Seq Models in Joint Entity and Relation\n  Extraction", "abstract": "Joint entity and relation extraction aims to extract relation triplets from\nplain text directly. Prior work leverages Sequence-to-Sequence (Seq2Seq) models\nfor triplet sequence generation. However, Seq2Seq enforces an unnecessary order\non the unordered triplets and involves a large decoding length associated with\nerror accumulation. These introduce exposure bias, which may cause the models\noverfit to the frequent label combination, thus deteriorating the\ngeneralization. We propose a novel Sequence-to-Unordered-Multi-Tree\n(Seq2UMTree) model to minimize the effects of exposure bias by limiting the\ndecoding length to three within a triplet and removing the order among\ntriplets. We evaluate our model on two datasets, DuIE and NYT, and\nsystematically study how exposure bias alters the performance of Seq2Seq\nmodels. Experiments show that the state-of-the-art Seq2Seq model overfits to\nboth datasets while Seq2UMTree shows significantly better generalization. Our\ncode is available at https://github.com/WindChimeRan/OpenJERE .", "published": "2020-09-16 06:53:34", "link": "http://arxiv.org/abs/2009.07503v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CogTree: Cognition Tree Loss for Unbiased Scene Graph Generation", "abstract": "Scene graphs are semantic abstraction of images that encourage visual\nunderstanding and reasoning. However, the performance of Scene Graph Generation\n(SGG) is unsatisfactory when faced with biased data in real-world scenarios.\nConventional debiasing research mainly studies from the view of balancing data\ndistribution or learning unbiased models and representations, ignoring the\ncorrelations among the biased classes. In this work, we analyze this problem\nfrom a novel cognition perspective: automatically building a hierarchical\ncognitive structure from the biased predictions and navigating that hierarchy\nto locate the relationships, making the tail relationships receive more\nattention in a coarse-to-fine mode. To this end, we propose a novel debiasing\nCognition Tree (CogTree) loss for unbiased SGG. We first build a cognitive\nstructure CogTree to organize the relationships based on the prediction of a\nbiased SGG model. The CogTree distinguishes remarkably different relationships\nat first and then focuses on a small portion of easily confused ones. Then, we\npropose a debiasing loss specially for this cognitive structure, which supports\ncoarse-to-fine distinction for the correct relationships. The loss is\nmodel-agnostic and consistently boosting the performance of several\nstate-of-the-art models. The code is available at:\nhttps://github.com/CYVincent/Scene-Graph-Transformer-CogTree.", "published": "2020-09-16 07:47:26", "link": "http://arxiv.org/abs/2009.07526v2", "categories": ["cs.CV", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News", "abstract": "Large-scale dissemination of disinformation online intended to mislead or\ndeceive the general population is a major societal problem. Rapid progression\nin image, video, and natural language generative models has only exacerbated\nthis situation and intensified our need for an effective defense mechanism.\nWhile existing approaches have been proposed to defend against neural fake\nnews, they are generally constrained to the very limited setting where articles\nonly have text and metadata such as the title and authors. In this paper, we\nintroduce the more realistic and challenging task of defending against\nmachine-generated news that also includes images and captions. To identify the\npossible weaknesses that adversaries can exploit, we create a NeuralNews\ndataset composed of 4 different types of generated articles as well as conduct\na series of human user study experiments based on this dataset. In addition to\nthe valuable insights gleaned from our user study experiments, we provide a\nrelatively effective approach based on detecting visual-semantic\ninconsistencies, which will serve as an effective first line of defense and a\nuseful reference for future work in defending against machine-generated\ndisinformation.", "published": "2020-09-16 14:13:15", "link": "http://arxiv.org/abs/2009.07698v5", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Automated Source Code Generation and Auto-completion Using Deep\n  Learning: Comparing and Discussing Current Language-Model-Related Approaches", "abstract": "In recent years, the use of deep learning in language models gained much\nattention. Some research projects claim that they can generate text that can be\ninterpreted as human-writing, enabling new possibilities in many application\nareas. Among the different areas related to language processing, one of the\nmost notable in applying this type of modeling is programming languages. For\nyears, the Machine Learning community has been researching this software\nengineering area, pursuing goals like applying different approaches to\nauto-complete, generate, fix, or evaluate code programmed by humans.\nConsidering the increasing popularity of the Deep-Learning-enabled language\nmodels approach, we detected a lack of empirical papers that compare different\ndeep learning architectures to create and use language models based on\nprogramming code. This paper compares different neural network architectures\nlike AWD-LSTMs, AWD-QRNNs, and Transformer while using transfer learning and\ndifferent tokenizations to see how they behave in building language models\nusing a Python dataset for code generation and filling mask tasks. Considering\nthe results, we discuss each approach's different strengths and weaknesses and\nwhat gaps we find to evaluate the language models or apply them in a real\nprogramming context.", "published": "2020-09-16 15:17:04", "link": "http://arxiv.org/abs/2009.07740v4", "categories": ["cs.CL", "cs.LG", "cs.PL", "cs.SE", "I.2.7; D.3.0"], "primary_category": "cs.CL"}
{"title": "Multilingual Music Genre Embeddings for Effective Cross-Lingual Music\n  Item Annotation", "abstract": "Annotating music items with music genres is crucial for music recommendation\nand information retrieval, yet challenging given that music genres are\nsubjective concepts. Recently, in order to explicitly consider this\nsubjectivity, the annotation of music items was modeled as a translation task:\npredict for a music item its music genres within a target vocabulary or\ntaxonomy (tag system) from a set of music genre tags originating from other tag\nsystems. However, without a parallel corpus, previous solutions could not\nhandle tag systems in other languages, being limited to the English-language\nonly. Here, by learning multilingual music genre embeddings, we enable\ncross-lingual music genre translation without relying on a parallel corpus.\nFirst, we apply compositionality functions on pre-trained word embeddings to\nrepresent multi-word tags.Second, we adapt the tag representations to the music\ndomain by leveraging multilingual music genres graphs with a modified\nretrofitting algorithm. Experiments show that our method: 1) is effective in\ntranslating music genres across tag systems in multiple languages (English,\nFrench and Spanish); 2) outperforms the previous baseline in an\nEnglish-language multi-source translation task. We publicly release the new\nmultilingual data and code.", "published": "2020-09-16 15:39:04", "link": "http://arxiv.org/abs/2009.07755v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Transformer Based Multi-Source Domain Adaptation", "abstract": "In practical machine learning settings, the data on which a model must make\npredictions often come from a different distribution than the data it was\ntrained on. Here, we investigate the problem of unsupervised multi-source\ndomain adaptation, where a model is trained on labelled data from multiple\nsource domains and must make predictions on a domain for which no labelled data\nhas been seen. Prior work with CNNs and RNNs has demonstrated the benefit of\nmixture of experts, where the predictions of multiple domain expert classifiers\nare combined; as well as domain adversarial training, to induce a domain\nagnostic representation space. Inspired by this, we investigate how such\nmethods can be effectively applied to large pretrained transformer models. We\nfind that domain adversarial training has an effect on the learned\nrepresentations of these models while having little effect on their\nperformance, suggesting that large transformer-based models are already\nrelatively robust across domains. Additionally, we show that mixture of experts\nleads to significant performance improvements by comparing several variants of\nmixing functions, including one novel mixture based on attention. Finally, we\ndemonstrate that the predictions of large pretrained transformer based domain\nexperts are highly homogenous, making it challenging to learn effective\nfunctions for mixing their predictions.", "published": "2020-09-16 16:56:23", "link": "http://arxiv.org/abs/2009.07806v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "CoDEx: A Comprehensive Knowledge Graph Completion Benchmark", "abstract": "We present CoDEx, a set of knowledge graph completion datasets extracted from\nWikidata and Wikipedia that improve upon existing knowledge graph completion\nbenchmarks in scope and level of difficulty. In terms of scope, CoDEx comprises\nthree knowledge graphs varying in size and structure, multilingual descriptions\nof entities and relations, and tens of thousands of hard negative triples that\nare plausible but verified to be false. To characterize CoDEx, we contribute\nthorough empirical analyses and benchmarking experiments. First, we analyze\neach CoDEx dataset in terms of logical relation patterns. Next, we report\nbaseline link prediction and triple classification results on CoDEx for five\nextensively tuned embedding models. Finally, we differentiate CoDEx from the\npopular FB15K-237 knowledge graph completion dataset by showing that CoDEx\ncovers more diverse and interpretable content, and is a more difficult link\nprediction benchmark. Data, code, and pretrained models are available at\nhttps://bit.ly/2EPbrJs.", "published": "2020-09-16 17:08:23", "link": "http://arxiv.org/abs/2009.07810v2", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Type-augmented Relation Prediction in Knowledge Graphs", "abstract": "Knowledge graphs (KGs) are of great importance to many real world\napplications, but they generally suffer from incomplete information in the form\nof missing relations between entities. Knowledge graph completion (also known\nas relation prediction) is the task of inferring missing facts given existing\nones. Most of the existing work is proposed by maximizing the likelihood of\nobserved instance-level triples. Not much attention, however, is paid to the\nontological information, such as type information of entities and relations. In\nthis work, we propose a type-augmented relation prediction (TaRP) method, where\nwe apply both the type information and instance-level information for relation\nprediction. In particular, type information and instance-level information are\nencoded as prior probabilities and likelihoods of relations respectively, and\nare combined by following Bayes' rule. Our proposed TaRP method achieves\nsignificantly better performance than state-of-the-art methods on four\nbenchmark datasets: FB15K, FB15K-237, YAGO26K-906, and DB111K-174. In addition,\nwe show that TaRP achieves significantly improved data efficiency. More\nimportantly, the type information extracted from a specific dataset can\ngeneralize well to other datasets through the proposed TaRP model.", "published": "2020-09-16 21:14:18", "link": "http://arxiv.org/abs/2009.07938v3", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Tasty Burgers, Soggy Fries: Probing Aspect Robustness in Aspect-Based\n  Sentiment Analysis", "abstract": "Aspect-based sentiment analysis (ABSA) aims to predict the sentiment towards\na specific aspect in the text. However, existing ABSA test sets cannot be used\nto probe whether a model can distinguish the sentiment of the target aspect\nfrom the non-target aspects. To solve this problem, we develop a simple but\neffective approach to enrich ABSA test sets. Specifically, we generate new\nexamples to disentangle the confounding sentiments of the non-target aspects\nfrom the target aspect's sentiment. Based on the SemEval 2014 dataset, we\nconstruct the Aspect Robustness Test Set (ARTS) as a comprehensive probe of the\naspect robustness of ABSA models. Over 92% data of ARTS show high fluency and\ndesired sentiment on all aspects by human evaluation. Using ARTS, we analyze\nthe robustness of nine ABSA models, and observe, surprisingly, that their\naccuracy drops by up to 69.73%. We explore several ways to improve aspect\nrobustness, and find that adversarial training can improve models' performance\non ARTS by up to 32.85%. Our code and new test set are available at\nhttps://github.com/zhijing-jin/ARTS_TestSet", "published": "2020-09-16 22:38:18", "link": "http://arxiv.org/abs/2009.07964v4", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Impact and dynamics of hate and counter speech online", "abstract": "Citizen-generated counter speech is a promising way to fight hate speech and\npromote peaceful, non-polarized discourse. However, there is a lack of\nlarge-scale longitudinal studies of its effectiveness for reducing hate speech.\nTo this end, we perform an exploratory analysis of the effectiveness of counter\nspeech using several different macro- and micro-level measures to analyze\n180,000 political conversations that took place on German Twitter over four\nyears. We report on the dynamic interactions of hate and counter speech over\ntime and provide insights into whether, as in `classic' bullying situations,\norganized efforts are more effective than independent individuals in steering\nonline discourse. Taken together, our results build a multifaceted picture of\nthe dynamics of hate and counter speech online. While we make no causal claims\ndue to the complexity of discourse dynamics, our findings suggest that\norganized hate speech is associated with changes in public discourse and that\ncounter speech -- especially when organized -- may help curb hateful rhetoric\nin online discourse.", "published": "2020-09-16 01:43:28", "link": "http://arxiv.org/abs/2009.08392v3", "categories": ["cs.SI", "cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.SI"}
{"title": "SciBERT-based Semantification of Bioassays in the Open Research\n  Knowledge Graph", "abstract": "As a novel contribution to the problem of semantifying biological assays, in\nthis paper, we propose a neural-network-based approach to automatically\nsemantify, thereby structure, unstructured bioassay text descriptions.\nExperimental evaluations, to this end, show promise as the neural-based\nsemantification significantly outperforms a naive frequency-based baseline\napproach. Specifically, the neural method attains 72% F1 versus 47% F1 from the\nfrequency-based method.", "published": "2020-09-16 12:36:35", "link": "http://arxiv.org/abs/2009.08801v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.AI"}
{"title": "Similarity-based data mining for online domain adaptation of a sonar ATR\n  system", "abstract": "Due to the expensive nature of field data gathering, the lack of training\ndata often limits the performance of Automatic Target Recognition (ATR)\nsystems. This problem is often addressed with domain adaptation techniques,\nhowever the currently existing methods fail to satisfy the constraints of\nresource and time-limited underwater systems. We propose to address this issue\nvia an online fine-tuning of the ATR algorithm using a novel data-selection\nmethod. Our proposed data-mining approach relies on visual similarity and\noutperforms the traditionally employed hard-mining methods. We present a\ncomparative performance analysis in a wide range of simulated environments and\nhighlight the benefits of using our method for the rapid adaptation to\npreviously unseen environments.", "published": "2020-09-16 09:07:54", "link": "http://arxiv.org/abs/2009.07560v1", "categories": ["cs.CV", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
