{"title": "Formal models of Structure Building in Music, Language and Animal Songs", "abstract": "Human language, music and a variety of animal vocalisations constitute ways\nof sonic communication that exhibit remarkable structural complexity. While the\ncomplexities of language and possible parallels in animal communication have\nbeen discussed intensively, reflections on the complexity of music and animal\nsong, and their comparisons are underrepresented. In some ways, music and\nanimal songs are more comparable to each other than to language, as\npropositional semantics cannot be used as as indicator of communicative success\nor well-formedness, and notions of grammaticality are less easily defined. This\nreview brings together accounts of the principles of structure building in\nlanguage, music and animal song, relating them to the corresponding models in\nformal language theory, with a special focus on evaluating the benefits of\nusing the Chomsky hierarchy (CH). We further discuss common misunderstandings\nand shortcomings concerning the CH, as well as extensions or augmentations of\nit that address some of these issues, and suggest ways to move beyond.", "published": "2019-01-16 08:47:47", "link": "http://arxiv.org/abs/1901.05180v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sentence transition matrix: An efficient approach that preserves\n  sentence semantics", "abstract": "Sentence embedding is a significant research topic in the field of natural\nlanguage processing (NLP). Generating sentence embedding vectors reflecting the\nintrinsic meaning of a sentence is a key factor to achieve an enhanced\nperformance in various NLP tasks such as sentence classification and document\nsummarization. Therefore, various sentence embedding models based on supervised\nand unsupervised learning have been proposed after the advent of researches\nregarding the distributed representation of words. They were evaluated through\nsemantic textual similarity (STS) tasks, which measure the degree of semantic\npreservation of a sentence and neural network-based supervised embedding models\ngenerally yielded state-of-the-art performance. However, these models have a\nlimitation in that they have multiple parameters to update, thereby requiring a\ntremendous amount of labeled training data. In this study, we propose an\nefficient approach that learns a transition matrix that refines a sentence\nembedding vector to reflect the latent semantic meaning of a sentence. The\nproposed method has two practical advantages; (1) it can be applied to any\nsentence embedding method, and (2) it can achieve robust performance in STS\ntasks irrespective of the number of training examples.", "published": "2019-01-16 10:40:18", "link": "http://arxiv.org/abs/1901.05219v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dependency or Span, End-to-End Uniform Semantic Role Labeling", "abstract": "Semantic role labeling (SRL) aims to discover the predicateargument structure\nof a sentence. End-to-end SRL without syntactic input has received great\nattention. However, most of them focus on either span-based or dependency-based\nsemantic representation form and only show specific model optimization\nrespectively. Meanwhile, handling these two SRL tasks uniformly was less\nsuccessful. This paper presents an end-to-end model for both dependency and\nspan SRL with a unified argument representation to deal with two different\ntypes of argument annotations in a uniform fashion. Furthermore, we jointly\npredict all predicates and arguments, especially including long-term ignored\npredicate identification subtask. Our single model achieves new\nstate-of-the-art results on both span (CoNLL 2005, 2012) and dependency (CoNLL\n2008, 2009) SRL benchmarks.", "published": "2019-01-16 13:48:53", "link": "http://arxiv.org/abs/1901.05280v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Assessing BERT's Syntactic Abilities", "abstract": "I assess the extent to which the recently introduced BERT model captures\nEnglish syntactic phenomena, using (1) naturally-occurring subject-verb\nagreement stimuli; (2) \"coloreless green ideas\" subject-verb agreement stimuli,\nin which content words in natural sentences are randomly replaced with words\nsharing the same part-of-speech and inflection; and (3) manually crafted\nstimuli for subject-verb agreement and reflexive anaphora phenomena. The BERT\nmodel performs remarkably well on all cases.", "published": "2019-01-16 14:01:15", "link": "http://arxiv.org/abs/1901.05287v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Variable-sized input, character-level recurrent neural networks in lead\n  generation: predicting close rates from raw user inputs", "abstract": "Predicting lead close rates is one of the most problematic tasks in the lead\ngeneration industry. In most cases, the only available data on the prospect is\nthe self-reported information inputted by the user on the lead form and a few\nother data points publicly available through social media and search engine\nusage. All the major market niches for lead generation [1], such as insurance,\nhealth & medical and real estate, deal with life-altering decision making that\nno amount of data will be ever be able to describe or predict. This paper\nillustrates how character-level, deep long short-term memory networks can be\napplied to raw user inputs to help predict close rates. The output of the model\nis then used as an additional, highly predictive feature to significantly boost\nperformance of lead scoring models.", "published": "2019-01-16 02:37:59", "link": "http://arxiv.org/abs/1901.05115v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Response to \"Visual Dialogue without Vision or Dialogue\" (Massiceti et\n  al., 2018)", "abstract": "In a recent workshop paper, Massiceti et al. presented a baseline model and\nsubsequent critique of Visual Dialog (Das et al., CVPR 2017) that raises what\nwe believe to be unfounded concerns about the dataset and evaluation. This\narticle intends to rebut the critique and clarify potential confusions for\npractitioners and future participants in the Visual Dialog challenge.", "published": "2019-01-16 21:27:57", "link": "http://arxiv.org/abs/1901.05531v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Location, Occupation, and Semantics based Socioeconomic Status Inference\n  on Twitter", "abstract": "The socioeconomic status of people depends on a combination of individual\ncharacteristics and environmental variables, thus its inference from online\nbehavioral data is a difficult task. Attributes like user semantics in\ncommunication, habitat, occupation, or social network are all known to be\ndeterminant predictors of this feature. In this paper we propose three\ndifferent data collection and combination methods to first estimate and, in\nturn, infer the socioeconomic status of French Twitter users from their online\nsemantics. Our methods are based on open census data, crawled professional\nprofiles, and remotely sensed, expert annotated information on living\nenvironment. Our inference models reach similar performance of earlier results\nwith the advantage of relying on broadly available datasets and of providing a\ngeneralizable framework to estimate socioeconomic status of large numbers of\nTwitter users. These results may contribute to the scientific discussion on\nsocial stratification and inequalities, and may fuel several applications.", "published": "2019-01-16 16:56:14", "link": "http://arxiv.org/abs/1901.05389v1", "categories": ["cs.SI", "cs.CL", "cs.CY", "physics.data-an", "physics.soc-ph"], "primary_category": "cs.SI"}
{"title": "Learning from Dialogue after Deployment: Feed Yourself, Chatbot!", "abstract": "The majority of conversations a dialogue agent sees over its lifetime occur\nafter it has already been trained and deployed, leaving a vast store of\npotential training signal untapped. In this work, we propose the self-feeding\nchatbot, a dialogue agent with the ability to extract new training examples\nfrom the conversations it participates in. As our agent engages in\nconversation, it also estimates user satisfaction in its responses. When the\nconversation appears to be going well, the user's responses become new training\nexamples to imitate. When the agent believes it has made a mistake, it asks for\nfeedback; learning to predict the feedback that will be given improves the\nchatbot's dialogue abilities further. On the PersonaChat chit-chat dataset with\nover 131k training examples, we find that learning from dialogue with a\nself-feeding chatbot significantly improves performance, regardless of the\namount of traditional supervision.", "published": "2019-01-16 18:02:44", "link": "http://arxiv.org/abs/1901.05415v4", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Real-time separation of non-stationary sound fields on spheres", "abstract": "The sound field separation methods can separate the target field from the\ninterfering noises, facilitating the study of the acoustic characteristics of\nthe target source, which is placed in a noisy environment. However, most of the\nexisting sound field separation methods are derived in the frequency-domain,\nthus are best suited for separating stationary sound fields. In this paper, a\ntime-domain sound field separation method is developed that can separate the\nnon-stationary sound field generated by the target source over a sphere in\nreal-time. A spherical array sets up a boundary between the target source and\nthe interfering sources, such that the outgoing field on the array is only\ngenerated by the target source. The proposed method decomposes the pressure and\nthe radial particle velocity measured by the array into spherical harmonics\ncoefficients, and recoveries the target outgoing field based on the time-domain\nrelationship between the decomposition coefficients and the theoretically\nderived spatial filter responses. Simulations show the proposed method can\nseparate non-stationary sound fields both in free field and room environments,\nand over a longer duration with small errors. The proposed method could serve\nas a foundation for developing future time-domain spatial sound field\nmanipulation algorithms.", "published": "2019-01-16 03:13:00", "link": "http://arxiv.org/abs/1901.05122v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
