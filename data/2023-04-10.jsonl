{"title": "Modeling Speaker-Listener Interaction for Backchannel Prediction", "abstract": "We present our latest findings on backchannel modeling novelly motivated by\nthe canonical use of the minimal responses Yeah and Uh-huh in English and their\ncorrespondent tokens in German, and the effect of encoding the speaker-listener\ninteraction. Backchanneling theories emphasize the active and continuous role\nof the listener in the course of the conversation, their effects on the\nspeaker's subsequent talk, and the consequent dynamic speaker-listener\ninteraction. Therefore, we propose a neural-based acoustic backchannel\nclassifier on minimal responses by processing acoustic features from the\nspeaker speech, capturing and imitating listeners' backchanneling behavior, and\nencoding speaker-listener interaction. Our experimental results on the\nSwitchboard and GECO datasets reveal that in almost all tested scenarios the\nspeaker or listener behavior embeddings help the model make more accurate\nbackchannel predictions. More importantly, a proper interaction encoding\nstrategy, i.e., combining the speaker and listener embeddings, leads to the\nbest performance on both datasets in terms of F1-score.", "published": "2023-04-10 09:22:06", "link": "http://arxiv.org/abs/2304.04472v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learnings from Data Integration for Augmented Language Models", "abstract": "One of the limitations of large language models is that they do not have\naccess to up-to-date, proprietary or personal data. As a result, there are\nmultiple efforts to extend language models with techniques for accessing\nexternal data. In that sense, LLMs share the vision of data integration systems\nwhose goal is to provide seamless access to a large collection of heterogeneous\ndata sources. While the details and the techniques of LLMs differ greatly from\nthose of data integration, this paper shows that some of the lessons learned\nfrom research on data integration can elucidate the research path we are\nconducting today on language models.", "published": "2023-04-10 13:28:35", "link": "http://arxiv.org/abs/2304.04576v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Attention at SemEval-2023 Task 10: Explainable Detection of Online\n  Sexism (EDOS)", "abstract": "In this paper, we have worked on interpretability, trust, and understanding\nof the decisions made by models in the form of classification tasks. The task\nis divided into 3 subtasks. The first task consists of determining Binary\nSexism Detection. The second task describes the Category of Sexism. The third\ntask describes a more Fine-grained Category of Sexism. Our work explores\nsolving these tasks as a classification problem by fine-tuning\ntransformer-based architecture. We have performed several experiments with our\narchitecture, including combining multiple transformers, using domain adaptive\npretraining on the unlabelled dataset provided by Reddit and Gab, Joint\nlearning, and taking different layers of transformers as input to a\nclassification head. Our system (with team name Attention) was able to achieve\na macro F1 score of 0.839 for task A, 0.5835 macro F1 score for task B and\n0.3356 macro F1 score for task C at the Codalab SemEval Competition. Later we\nimproved the accuracy of Task B to 0.6228 and Task C to 0.3693 in the test set.", "published": "2023-04-10 14:24:52", "link": "http://arxiv.org/abs/2304.04610v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On Evaluation of Bangla Word Analogies", "abstract": "This paper presents a high-quality dataset for evaluating the quality of\nBangla word embeddings, which is a fundamental task in the field of Natural\nLanguage Processing (NLP). Despite being the 7th most-spoken language in the\nworld, Bangla is a low-resource language and popular NLP models fail to perform\nwell. Developing a reliable evaluation test set for Bangla word embeddings are\ncrucial for benchmarking and guiding future research. We provide a\nMikolov-style word analogy evaluation set specifically for Bangla, with a\nsample size of 16678, as well as a translated and curated version of the\nMikolov dataset, which contains 10594 samples for cross-lingual research. Our\nexperiments with different state-of-the-art embedding models reveal that Bangla\nhas its own unique characteristics, and current embeddings for Bangla still\nstruggle to achieve high accuracy on both datasets. We suggest that future\nresearch should focus on training models with larger datasets and considering\nthe unique morphological characteristics of Bangla. This study represents the\nfirst step towards building a reliable NLP system for the Bangla language1.", "published": "2023-04-10 14:27:35", "link": "http://arxiv.org/abs/2304.04613v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual Machine Translation with Large Language Models: Empirical\n  Results and Analysis", "abstract": "Large language models (LLMs) have demonstrated remarkable potential in\nhandling multilingual machine translation (MMT). In this paper, we\nsystematically investigate the advantages and challenges of LLMs for MMT by\nanswering two questions: 1) How well do LLMs perform in translating massive\nlanguages? 2) Which factors affect LLMs' performance in translation? We\nthoroughly evaluate eight popular LLMs, including ChatGPT and GPT-4. Our\nempirical results show that translation capabilities of LLMs are continually\ninvolving. GPT-4 has beat the strong supervised baseline NLLB in 40.91% of\ntranslation directions but still faces a large gap towards the commercial\ntranslation system like Google Translate, especially on low-resource languages.\nThrough further analysis, we discover that LLMs exhibit new working patterns\nwhen used for MMT. First, LLM can acquire translation ability in a\nresource-efficient way and generate moderate translation even on zero-resource\nlanguages. Second, instruction semantics can surprisingly be ignored when given\nin-context exemplars. Third, cross-lingual exemplars can provide better task\nguidance for low-resource translation than exemplars in the same language\npairs. Code will be released at: https://github.com/NJUNLP/MMT-LLM.", "published": "2023-04-10 15:51:30", "link": "http://arxiv.org/abs/2304.04675v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transfer Learning for Low-Resource Sentiment Analysis", "abstract": "Sentiment analysis is the process of identifying and extracting subjective\ninformation from text. Despite the advances to employ cross-lingual approaches\nin an automatic way, the implementation and evaluation of sentiment analysis\nsystems require language-specific data to consider various sociocultural and\nlinguistic peculiarities. In this paper, the collection and annotation of a\ndataset are described for sentiment analysis of Central Kurdish. We explore a\nfew classical machine learning and neural network-based techniques for this\ntask. Additionally, we employ an approach in transfer learning to leverage\npretrained models for data augmentation. We demonstrate that data augmentation\nachieves a high F$_1$ score and accuracy despite the difficulty of the task.", "published": "2023-04-10 16:44:44", "link": "http://arxiv.org/abs/2304.04703v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating Graph Structure Information for Entity Alignment with\n  Dangling Cases", "abstract": "Entity alignment (EA) aims to discover the equivalent entities in different\nknowledge graphs (KGs), which play an important role in knowledge engineering.\nRecently, EA with dangling entities has been proposed as a more realistic\nsetting, which assumes that not all entities have corresponding equivalent\nentities. In this paper, we focus on this setting. Some work has explored this\nproblem by leveraging translation API, pre-trained word embeddings, and other\noff-the-shelf tools. However, these approaches over-rely on the side\ninformation (e.g., entity names), and fail to work when the side information is\nabsent. On the contrary, they still insufficiently exploit the most fundamental\ngraph structure information in KG. To improve the exploitation of the\nstructural information, we propose a novel entity alignment framework called\nWeakly-Optimal Graph Contrastive Learning (WOGCL), which is refined on three\ndimensions : (i) Model. We propose a novel Gated Graph Attention Network to\ncapture local and global graph structure similarity. (ii) Training. Two\nlearning objectives: contrastive learning and optimal transport learning are\ndesigned to obtain distinguishable entity representations via the optimal\ntransport plan. (iii) Inference. In the inference phase, a PageRank-based\nmethod is proposed to calculate higher-order structural similarity. Extensive\nexperiments on two dangling benchmarks demonstrate that our WOGCL outperforms\nthe current state-of-the-art methods with pure structural information in both\ntraditional (relaxed) and dangling (consolidated) settings. The code will be\npublic soon.", "published": "2023-04-10 17:24:43", "link": "http://arxiv.org/abs/2304.04718v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Uncertainty-Aware Natural Language Inference with Stochastic Weight\n  Averaging", "abstract": "This paper introduces Bayesian uncertainty modeling using Stochastic Weight\nAveraging-Gaussian (SWAG) in Natural Language Understanding (NLU) tasks. We\napply the approach to standard tasks in natural language inference (NLI) and\ndemonstrate the effectiveness of the method in terms of prediction accuracy and\ncorrelation with human annotation disagreements. We argue that the uncertainty\nrepresentations in SWAG better reflect subjective interpretation and the\nnatural variation that is also present in human language understanding. The\nresults reveal the importance of uncertainty modeling, an often neglected\naspect of neural language modeling, in NLU tasks.", "published": "2023-04-10 17:37:23", "link": "http://arxiv.org/abs/2304.04726v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Examining Temporalities on Stance Detection towards COVID-19 Vaccination", "abstract": "Previous studies have highlighted the importance of vaccination as an\neffective strategy to control the transmission of the COVID-19 virus. It is\ncrucial for policymakers to have a comprehensive understanding of the public's\nstance towards vaccination on a large scale. However, attitudes towards\nCOVID-19 vaccination, such as pro-vaccine or vaccine hesitancy, have evolved\nover time on social media. Thus, it is necessary to account for possible\ntemporal shifts when analysing these stances. This study aims to examine the\nimpact of temporal concept drift on stance detection towards COVID-19\nvaccination on Twitter. To this end, we evaluate a range of transformer-based\nmodels using chronological (splitting the training, validation, and test sets\nin order of time) and random splits (randomly splitting these three sets) of\nsocial media data. Our findings reveal significant discrepancies in model\nperformance between random and chronological splits in several existing\nCOVID-19-related datasets; specifically, chronological splits significantly\nreduce the accuracy of stance classification. Therefore, real-world stance\ndetection approaches need to be further refined to incorporate temporal factors\nas a key consideration.", "published": "2023-04-10 18:31:26", "link": "http://arxiv.org/abs/2304.04806v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Large-Scale Comparative Study of Accurate COVID-19 Information versus\n  Misinformation", "abstract": "The COVID-19 pandemic led to an infodemic where an overwhelming amount of\nCOVID-19 related content was being disseminated at high velocity through social\nmedia. This made it challenging for citizens to differentiate between accurate\nand inaccurate information about COVID-19. This motivated us to carry out a\ncomparative study of the characteristics of COVID-19 misinformation versus\nthose of accurate COVID-19 information through a large-scale computational\nanalysis of over 242 million tweets. The study makes comparisons alongside four\nkey aspects: 1) the distribution of topics, 2) the live status of tweets, 3)\nlanguage analysis and 4) the spreading power over time. An added contribution\nof this study is the creation of a COVID-19 misinformation classification\ndataset. Finally, we demonstrate that this new dataset helps improve\nmisinformation classification by more than 9\\% based on average F1 measure.", "published": "2023-04-10 18:44:41", "link": "http://arxiv.org/abs/2304.04811v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generative Knowledge Selection for Knowledge-Grounded Dialogues", "abstract": "Knowledge selection is the key in knowledge-grounded dialogues (KGD), which\naims to select an appropriate knowledge snippet to be used in the utterance\nbased on dialogue history. Previous studies mainly employ the classification\napproach to classify each candidate snippet as \"relevant\" or \"irrelevant\"\nindependently. However, such approaches neglect the interactions between\nsnippets, leading to difficulties in inferring the meaning of snippets.\nMoreover, they lack modeling of the discourse structure of dialogue-knowledge\ninteractions. We propose a simple yet effective generative approach for\nknowledge selection, called GenKS. GenKS learns to select snippets by\ngenerating their identifiers with a sequence-to-sequence model. GenKS therefore\ncaptures intra-knowledge interaction inherently through attention mechanisms.\nMeanwhile, we devise a hyperlink mechanism to model the dialogue-knowledge\ninteractions explicitly. We conduct experiments on three benchmark datasets,\nand verify GenKS achieves the best results on both knowledge selection and\nresponse generation.", "published": "2023-04-10 19:49:55", "link": "http://arxiv.org/abs/2304.04836v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Is ChatGPT a Good Sentiment Analyzer? A Preliminary Study", "abstract": "Recently, ChatGPT has drawn great attention from both the research community\nand the public. We are particularly interested in whether it can serve as a\nuniversal sentiment analyzer. To this end, in this work, we provide a\npreliminary evaluation of ChatGPT on the understanding of \\emph{opinions},\n\\emph{sentiments}, and \\emph{emotions} contained in the text. Specifically, we\nevaluate it in three settings, including \\emph{standard} evaluation,\n\\emph{polarity shift} evaluation and \\emph{open-domain} evaluation. We conduct\nan evaluation on 7 representative sentiment analysis tasks covering 17\nbenchmark datasets and compare ChatGPT with fine-tuned BERT and corresponding\nstate-of-the-art (SOTA) models on them. We also attempt several popular\nprompting techniques to elicit the ability further. Moreover, we conduct human\nevaluation and present some qualitative case studies to gain a deep\ncomprehension of its sentiment analysis capabilities.", "published": "2023-04-10 00:55:59", "link": "http://arxiv.org/abs/2304.04339v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "WebBrain: Learning to Generate Factually Correct Articles for Queries by\n  Grounding on Large Web Corpus", "abstract": "In this paper, we introduce a new NLP task -- generating short factual\narticles with references for queries by mining supporting evidence from the\nWeb. In this task, called WebBrain, the ultimate goal is to generate a fluent,\ninformative, and factually-correct short article (e.g., a Wikipedia article)\nfor a factual query unseen in Wikipedia. To enable experiments on WebBrain, we\nconstruct a large-scale dataset WebBrain-Raw by extracting English Wikipedia\narticles and their crawlable Wikipedia references. WebBrain-Raw is ten times\nlarger than the previous biggest peer dataset, which can greatly benefit the\nresearch community. From WebBrain-Raw, we construct two task-specific datasets:\nWebBrain-R and WebBrain-G, which are used to train in-domain retriever and\ngenerator, respectively. Besides, we empirically analyze the performances of\nthe current state-of-the-art NLP techniques on WebBrain and introduce a new\nframework ReGen, which enhances the generation factualness by improved evidence\nretrieval and task-specific pre-training for generation. Experiment results\nshow that ReGen outperforms all baselines in both automatic and human\nevaluations.", "published": "2023-04-10 02:55:48", "link": "http://arxiv.org/abs/2304.04358v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Inference with Reference: Lossless Acceleration of Large Language Models", "abstract": "We propose LLMA, an LLM accelerator to losslessly speed up Large Language\nModel (LLM) inference with references. LLMA is motivated by the observation\nthat there are abundant identical text spans between the decoding result by an\nLLM and the reference that is available in many real world scenarios (e.g.,\nretrieved documents). LLMA first selects a text span from the reference and\ncopies its tokens to the decoder and then efficiently checks the tokens'\nappropriateness as the decoding result in parallel within one decoding step.\nThe improved computational parallelism allows LLMA to achieve over 2x speed-up\nfor LLMs with identical generation results as greedy decoding in many practical\ngeneration scenarios where significant overlap between in-context reference and\noutputs exists (e.g., search engines and multi-turn conversations).", "published": "2023-04-10 09:55:14", "link": "http://arxiv.org/abs/2304.04487v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LADER: Log-Augmented DEnse Retrieval for Biomedical Literature Search", "abstract": "Queries with similar information needs tend to have similar document clicks,\nespecially in biomedical literature search engines where queries are generally\nshort and top documents account for most of the total clicks. Motivated by\nthis, we present a novel architecture for biomedical literature search, namely\nLog-Augmented DEnse Retrieval (LADER), which is a simple plug-in module that\naugments a dense retriever with the click logs retrieved from similar training\nqueries. Specifically, LADER finds both similar documents and queries to the\ngiven query by a dense retriever. Then, LADER scores relevant (clicked)\ndocuments of similar queries weighted by their similarity to the input query.\nThe final document scores by LADER are the average of (1) the document\nsimilarity scores from the dense retriever and (2) the aggregated document\nscores from the click logs of similar queries. Despite its simplicity, LADER\nachieves new state-of-the-art (SOTA) performance on TripClick, a recently\nreleased benchmark for biomedical literature retrieval. On the frequent (HEAD)\nqueries, LADER largely outperforms the best retrieval model by 39% relative\nNDCG@10 (0.338 v.s. 0.243). LADER also achieves better performance on the less\nfrequent (TORSO) queries with 11% relative NDCG@10 improvement over the\nprevious SOTA (0.303 v.s. 0.272). On the rare (TAIL) queries where similar\nqueries are scarce, LADER still compares favorably to the previous SOTA method\n(NDCG@10: 0.310 v.s. 0.295). On all queries, LADER can improve the performance\nof a dense retriever by 24%-37% relative NDCG@10 while not requiring additional\ntraining, and further performance improvement is expected from more logs. Our\nregression analysis has shown that queries that are more frequent, have higher\nentropy of query similarity and lower entropy of document similarity, tend to\nbenefit more from log augmentation.", "published": "2023-04-10 13:51:44", "link": "http://arxiv.org/abs/2304.04590v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Automated Reading Passage Generation with OpenAI's Large Language Model", "abstract": "The widespread usage of computer-based assessments and individualized\nlearning platforms has resulted in an increased demand for the rapid production\nof high-quality items. Automated item generation (AIG), the process of using\nitem models to generate new items with the help of computer technology, was\nproposed to reduce reliance on human subject experts at each step of the\nprocess. AIG has been used in test development for some time. Still, the use of\nmachine learning algorithms has introduced the potential to improve the\nefficiency and effectiveness of the process greatly. The approach presented in\nthis paper utilizes OpenAI's latest transformer-based language model, GPT-3, to\ngenerate reading passages. Existing reading passages were used in carefully\nengineered prompts to ensure the AI-generated text has similar content and\nstructure to a fourth-grade reading passage. For each prompt, we generated\nmultiple passages, the final passage was selected according to the Lexile score\nagreement with the original passage. In the final round, the selected passage\nwent through a simple revision by a human editor to ensure the text was free of\nany grammatical and factual errors. All AI-generated passages, along with\noriginal passages were evaluated by human judges according to their coherence,\nappropriateness to fourth graders, and readability.", "published": "2023-04-10 14:30:39", "link": "http://arxiv.org/abs/2304.04616v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Incorporating Structured Sentences with Time-enhanced BERT for\n  Fully-inductive Temporal Relation Prediction", "abstract": "Temporal relation prediction in incomplete temporal knowledge graphs (TKGs)\nis a popular temporal knowledge graph completion (TKGC) problem in both\ntransductive and inductive settings. Traditional embedding-based TKGC models\n(TKGE) rely on structured connections and can only handle a fixed set of\nentities, i.e., the transductive setting. In the inductive setting where test\nTKGs contain emerging entities, the latest methods are based on symbolic rules\nor pre-trained language models (PLMs). However, they suffer from being\ninflexible and not time-specific, respectively. In this work, we extend the\nfully-inductive setting, where entities in the training and test sets are\ntotally disjoint, into TKGs and take a further step towards a more flexible and\ntime-sensitive temporal relation prediction approach SST-BERT, incorporating\nStructured Sentences with Time-enhanced BERT. Our model can obtain the entity\nhistory and implicitly learn rules in the semantic space by encoding structured\nsentences, solving the problem of inflexibility. We propose to use a time\nmasking MLM task to pre-train BERT in a corpus rich in temporal tokens\nspecially generated for TKGs, enhancing the time sensitivity of SST-BERT. To\ncompute the probability of occurrence of a target quadruple, we aggregate all\nits structured sentences from both temporal and semantic perspectives into a\nscore. Experiments on the transductive datasets and newly generated\nfully-inductive benchmarks show that SST-BERT successfully improves over\nstate-of-the-art baselines.", "published": "2023-04-10 17:22:15", "link": "http://arxiv.org/abs/2304.04717v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Cheaper and Better Diffusion Language Model with Soft-Masked Noise", "abstract": "Diffusion models that are based on iterative denoising have been recently\nproposed and leveraged in various generation tasks like image generation.\nWhereas, as a way inherently built for continuous data, existing diffusion\nmodels still have some limitations in modeling discrete data, e.g., languages.\nFor example, the generally used Gaussian noise can not handle the discrete\ncorruption well, and the objectives in continuous spaces fail to be stable for\ntextual data in the diffusion process especially when the dimension is high. To\nalleviate these issues, we introduce a novel diffusion model for language\nmodeling, Masked-Diffuse LM, with lower training cost and better performances,\ninspired by linguistic features in languages. Specifically, we design a\nlinguistic-informed forward process which adds corruptions to the text through\nstrategically soft-masking to better noise the textual data. Also, we directly\npredict the categorical distribution with cross-entropy loss function in every\ndiffusion step to connect the continuous space and discrete space in a more\nefficient and straightforward way. Through experiments on 5 controlled\ngeneration tasks, we demonstrate that our Masked-Diffuse LM can achieve better\ngeneration quality than the state-of-the-art diffusion models with better\nefficiency.", "published": "2023-04-10 17:58:42", "link": "http://arxiv.org/abs/2304.04746v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DISTO: Evaluating Textual Distractors for Multi-Choice Questions using\n  Negative Sampling based Approach", "abstract": "Multiple choice questions (MCQs) are an efficient and common way to assess\nreading comprehension (RC). Every MCQ needs a set of distractor answers that\nare incorrect, but plausible enough to test student knowledge. Distractor\ngeneration (DG) models have been proposed, and their performance is typically\nevaluated using machine translation (MT) metrics. However, MT metrics often\nmisjudge the suitability of generated distractors. We propose DISTO: the first\nlearned evaluation metric for generated distractors. We validate DISTO by\nshowing its scores correlate highly with human ratings of distractor quality.\nAt the same time, DISTO ranks the performance of state-of-the-art DG models\nvery differently from MT-based metrics, showing that MT metrics should not be\nused for distractor evaluation.", "published": "2023-04-10 22:03:00", "link": "http://arxiv.org/abs/2304.04881v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Classification of news spreading barriers", "abstract": "News media is one of the most effective mechanisms for spreading information\ninternationally, and many events from different areas are internationally\nrelevant. However, news coverage for some news events is limited to a specific\ngeographical region because of information spreading barriers, which can be\npolitical, geographical, economic, cultural, or linguistic. In this paper, we\npropose an approach to barrier classification where we infer the semantics of\nnews articles through Wikipedia concepts. To that end, we collected news\narticles and annotated them for different kinds of barriers using the metadata\nof news publishers. Then, we utilize the Wikipedia concepts along with the body\ntext of news articles as features to infer the news-spreading barriers. We\ncompare our approach to the classical text classification methods, deep\nlearning, and transformer-based methods. The results show that the proposed\napproach using Wikipedia concepts based semantic knowledge offers better\nperformance than the usual for classifying the news-spreading barriers.", "published": "2023-04-10 20:13:54", "link": "http://arxiv.org/abs/2304.08167v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "OpenAGI: When LLM Meets Domain Experts", "abstract": "Human Intelligence (HI) excels at combining basic skills to solve complex\ntasks. This capability is vital for Artificial Intelligence (AI) and should be\nembedded in comprehensive AI Agents, enabling them to harness expert models for\ncomplex task-solving towards Artificial General Intelligence (AGI). Large\nLanguage Models (LLMs) show promising learning and reasoning abilities, and can\neffectively use external models, tools, plugins, or APIs to tackle complex\nproblems. In this work, we introduce OpenAGI, an open-source AGI research and\ndevelopment platform designed for solving multi-step, real-world tasks.\nSpecifically, OpenAGI uses a dual strategy, integrating standard benchmark\ntasks for benchmarking and evaluation, and open-ended tasks including more\nexpandable models, tools, plugins, or APIs for creative problem-solving. Tasks\nare presented as natural language queries to the LLM, which then selects and\nexecutes appropriate models. We also propose a Reinforcement Learning from Task\nFeedback (RLTF) mechanism that uses task results to improve the LLM's\ntask-solving ability, which creates a self-improving AI feedback loop. While we\nacknowledge that AGI is a broad and multifaceted research challenge with no\nsingularly defined solution path, the integration of LLMs with domain-specific\nexpert models, inspired by mirroring the blend of general and specialized\nintelligence in humans, offers a promising approach towards AGI. We are\nopen-sourcing the OpenAGI project's code, dataset, benchmarks, evaluation\nmethods, and the UI demo to foster community involvement in AGI advancement:\nhttps://github.com/agiresearch/OpenAGI.", "published": "2023-04-10 03:55:35", "link": "http://arxiv.org/abs/2304.04370v6", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Oh, Jeez! or Uh-huh? A Listener-aware Backchannel Predictor on ASR\n  Transcriptions", "abstract": "This paper presents our latest investigation on modeling backchannel in\nconversations. Motivated by a proactive backchanneling theory, we aim at\ndeveloping a system which acts as a proactive listener by inserting\nbackchannels, such as continuers and assessment, to influence speakers. Our\nmodel takes into account not only lexical and acoustic cues, but also\nintroduces the simple and novel idea of using listener embeddings to mimic\ndifferent backchanneling behaviours. Our experimental results on the\nSwitchboard benchmark dataset reveal that acoustic cues are more important than\nlexical cues in this task and their combination with listener embeddings works\nbest on both, manual transcriptions and automatically generated transcriptions.", "published": "2023-04-10 09:33:29", "link": "http://arxiv.org/abs/2304.04478v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "UATTA-EB: Uncertainty-Aware Test-Time Augmented Ensemble of BERTs for\n  Classifying Common Mental Illnesses on Social Media Posts", "abstract": "Given the current state of the world, because of existing situations around\nthe world, millions of people suffering from mental illnesses feel isolated and\nunable to receive help in person. Psychological studies have shown that our\nstate of mind can manifest itself in the linguistic features we use to\ncommunicate. People have increasingly turned to online platforms to express\nthemselves and seek help with their conditions. Deep learning methods have been\ncommonly used to identify and analyze mental health conditions from various\nsources of information, including social media. Still, they face challenges,\nincluding a lack of reliability and overconfidence in predictions resulting in\nthe poor calibration of the models. To solve these issues, We propose UATTA-EB:\nUncertainty-Aware Test-Time Augmented Ensembling of BERTs for producing\nreliable and well-calibrated predictions to classify six possible types of\nmental illnesses- None, Depression, Anxiety, Bipolar Disorder, ADHD, and PTSD\nby analyzing unstructured user data on Reddit.", "published": "2023-04-10 12:18:53", "link": "http://arxiv.org/abs/2304.04539v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit", "abstract": "ESPnet-ST-v2 is a revamp of the open-source ESPnet-ST toolkit necessitated by\nthe broadening interests of the spoken language translation community.\nESPnet-ST-v2 supports 1) offline speech-to-text translation (ST), 2)\nsimultaneous speech-to-text translation (SST), and 3) offline speech-to-speech\ntranslation (S2ST) -- each task is supported with a wide variety of approaches,\ndifferentiating ESPnet-ST-v2 from other open source spoken language translation\ntoolkits. This toolkit offers state-of-the-art architectures such as\ntransducers, hybrid CTC/attention, multi-decoders with searchable\nintermediates, time-synchronous blockwise CTC/attention, Translatotron models,\nand direct discrete unit models. In this paper, we describe the overall design,\nexample models for each task, and performance benchmarking behind ESPnet-ST-v2,\nwhich is publicly available at https://github.com/espnet/espnet.", "published": "2023-04-10 14:05:22", "link": "http://arxiv.org/abs/2304.04596v3", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Enhancing Speech-to-Speech Translation with Multiple TTS Targets", "abstract": "It has been known that direct speech-to-speech translation (S2ST) models\nusually suffer from the data scarcity issue because of the limited existing\nparallel materials for both source and target speech. Therefore to train a\ndirect S2ST system, previous works usually utilize text-to-speech (TTS) systems\nto generate samples in the target language by augmenting the data from\nspeech-to-text translation (S2TT). However, there is a limited investigation\ninto how the synthesized target speech would affect the S2ST models. In this\nwork, we analyze the effect of changing synthesized target speech for direct\nS2ST models. We find that simply combining the target speech from different TTS\nsystems can potentially improve the S2ST performances. Following that, we also\npropose a multi-task framework that jointly optimizes the S2ST system with\nmultiple targets from different TTS systems. Extensive experiments demonstrate\nthat our proposed framework achieves consistent improvements (2.8 BLEU) over\nthe baselines on the Fisher Spanish-English dataset.", "published": "2023-04-10 14:33:33", "link": "http://arxiv.org/abs/2304.04618v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Prompt Pre-Training with Twenty-Thousand Classes for Open-Vocabulary\n  Visual Recognition", "abstract": "This work proposes POMP, a prompt pre-training method for vision-language\nmodels. Being memory and computation efficient, POMP enables the learned prompt\nto condense semantic information for a rich set of visual concepts with over\ntwenty-thousand classes. Once pre-trained, the prompt with a strong\ntransferable ability can be directly plugged into a variety of visual\nrecognition tasks including image classification, semantic segmentation, and\nobject detection, to boost recognition performances in a zero-shot manner.\nEmpirical evaluation shows that POMP achieves state-of-the-art performances on\n21 datasets, e.g., 67.0% average accuracy on 10 classification datasets (+3.1%\ncompared to CoOp) and 84.4 hIoU on open-vocabulary Pascal VOC segmentation\n(+6.9 compared to ZSSeg). Our code is available at\nhttps://github.com/amazon-science/prompt-pretraining.", "published": "2023-04-10 16:45:30", "link": "http://arxiv.org/abs/2304.04704v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "On the Possibilities of AI-Generated Text Detection", "abstract": "Our work addresses the critical issue of distinguishing text generated by\nLarge Language Models (LLMs) from human-produced text, a task essential for\nnumerous applications. Despite ongoing debate about the feasibility of such\ndifferentiation, we present evidence supporting its consistent achievability,\nexcept when human and machine text distributions are indistinguishable across\ntheir entire support. Drawing from information theory, we argue that as\nmachine-generated text approximates human-like quality, the sample size needed\nfor detection increases. We establish precise sample complexity bounds for\ndetecting AI-generated text, laying groundwork for future research aimed at\ndeveloping advanced, multi-sample detectors. Our empirical evaluations across\nmultiple datasets (Xsum, Squad, IMDb, and Kaggle FakeNews) confirm the\nviability of enhanced detection methods. We test various state-of-the-art text\ngenerators, including GPT-2, GPT-3.5-Turbo, Llama, Llama-2-13B-Chat-HF, and\nLlama-2-70B-Chat-HF, against detectors, including oBERTa-Large/Base-Detector,\nGPTZero. Our findings align with OpenAI's empirical data related to sequence\nlength, marking the first theoretical substantiation for these observations.", "published": "2023-04-10 17:47:39", "link": "http://arxiv.org/abs/2304.04736v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Wall Street Neophyte: A Zero-Shot Analysis of ChatGPT Over\n  MultiModal Stock Movement Prediction Challenges", "abstract": "Recently, large language models (LLMs) like ChatGPT have demonstrated\nremarkable performance across a variety of natural language processing tasks.\nHowever, their effectiveness in the financial domain, specifically in\npredicting stock market movements, remains to be explored. In this paper, we\nconduct an extensive zero-shot analysis of ChatGPT's capabilities in multimodal\nstock movement prediction, on three tweets and historical stock price datasets.\nOur findings indicate that ChatGPT is a \"Wall Street Neophyte\" with limited\nsuccess in predicting stock movements, as it underperforms not only\nstate-of-the-art methods but also traditional methods like linear regression\nusing price features. Despite the potential of Chain-of-Thought prompting\nstrategies and the inclusion of tweets, ChatGPT's performance remains subpar.\nFurthermore, we observe limitations in its explainability and stability,\nsuggesting the need for more specialized training or fine-tuning. This research\nprovides insights into ChatGPT's capabilities and serves as a foundation for\nfuture work aimed at improving financial market analysis and prediction by\nleveraging social media sentiment and historical stock data.", "published": "2023-04-10 04:31:00", "link": "http://arxiv.org/abs/2304.05351v2", "categories": ["cs.CL", "cs.LG", "q-fin.ST"], "primary_category": "cs.CL"}
{"title": "Leveraging Neural Representations for Audio Manipulation", "abstract": "We investigate applying audio manipulations using pretrained neural\nnetwork-based autoencoders as an alternative to traditional signal processing\nmethods, since the former may provide greater semantic or perceptual\norganization. To establish the potential of this approach, we first establish\nif representations from these models encode information about manipulations. We\ncarry out experiments and produce visualizations using representations from two\ndifferent pretrained autoencoders. Our findings indicate that, while some\ninformation about audio manipulations is encoded, this information is both\nlimited and encoded in a non-trivial way. This is supported by our attempts to\nvisualize these representations, which demonstrated that trajectories of\nrepresentations for common manipulations are typically nonlinear and content\ndependent, even for linear signal manipulations. As a result, it is not yet\nclear how these pretrained autoencoders can be used to manipulate audio\nsignals, however, our results indicate this may be due to the lack of\ndisentanglement with respect to common audio manipulations.", "published": "2023-04-10 05:44:47", "link": "http://arxiv.org/abs/2304.04394v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "In-situ crack and keyhole pore detection in laser directed energy\n  deposition through acoustic signal and deep learning", "abstract": "Cracks and keyhole pores are detrimental defects in alloys produced by laser\ndirected energy deposition (LDED). Laser-material interaction sound may hold\ninformation about underlying complex physical events such as crack propagation\nand pores formation. However, due to the noisy environment and intricate signal\ncontent, acoustic-based monitoring in LDED has received little attention. This\npaper proposes a novel acoustic-based in-situ defect detection strategy in\nLDED. The key contribution of this study is to develop an in-situ acoustic\nsignal denoising, feature extraction, and sound classification pipeline that\nincorporates convolutional neural networks (CNN) for online defect prediction.\nMicroscope images are used to identify locations of the cracks and keyhole\npores within a part. The defect locations are spatiotemporally registered with\nacoustic signal. Various acoustic features corresponding to defect-free\nregions, cracks, and keyhole pores are extracted and analysed in time-domain,\nfrequency-domain, and time-frequency representations. The CNN model is trained\nto predict defect occurrences using the Mel-Frequency Cepstral Coefficients\n(MFCCs) of the lasermaterial interaction sound. The CNN model is compared to\nvarious classic machine learning models trained on the denoised acoustic\ndataset and raw acoustic dataset. The validation results shows that the CNN\nmodel trained on the denoised dataset outperforms others with the highest\noverall accuracy (89%), keyhole pore prediction accuracy (93%), and AUC-ROC\nscore (98%). Furthermore, the trained CNN model can be deployed into an\nin-house developed software platform for online quality monitoring. The\nproposed strategy is the first study to use acoustic signals with deep learning\nfor insitu defect detection in LDED process.", "published": "2023-04-10 14:12:11", "link": "http://arxiv.org/abs/2304.04598v1", "categories": ["cs.SD", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
