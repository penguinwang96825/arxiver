{"title": "RankPrompt: Step-by-Step Comparisons Make Language Models Better\n  Reasoners", "abstract": "Large Language Models (LLMs) have achieved impressive performance across\nvarious reasoning tasks. However, even state-of-the-art LLMs such as ChatGPT\nare prone to logical errors during their reasoning processes. Existing\nsolutions, such as deploying task-specific verifiers or voting over multiple\nreasoning paths, either require extensive human annotations or fail in\nscenarios with inconsistent responses. To address these challenges, we\nintroduce RankPrompt, a new prompting method that enables LLMs to self-rank\ntheir responses without additional resources. RankPrompt breaks down the\nranking problem into a series of comparisons among diverse responses,\nleveraging the inherent capabilities of LLMs to generate chains of comparison\nas contextual exemplars. Our experiments across 11 arithmetic and commonsense\nreasoning tasks show that RankPrompt significantly enhances the reasoning\nperformance of ChatGPT and GPT-4, with improvements of up to 13%. Moreover,\nRankPrompt excels in LLM-based automatic evaluations for open-ended tasks,\naligning with human judgments 74% of the time in the AlpacaEval dataset. It\nalso exhibits robustness to variations in response order and consistency.\nCollectively, our results validate RankPrompt as an effective method for\neliciting high-quality feedback from language models.", "published": "2024-03-19 02:34:18", "link": "http://arxiv.org/abs/2403.12373v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Generalizability of Extracting Social Determinants of Health\n  Using Large Language Models through Prompt-tuning", "abstract": "The progress in natural language processing (NLP) using large language models\n(LLMs) has greatly improved patient information extraction from clinical\nnarratives. However, most methods based on the fine-tuning strategy have\nlimited transfer learning ability for cross-domain applications. This study\nproposed a novel approach that employs a soft prompt-based learning\narchitecture, which introduces trainable prompts to guide LLMs toward desired\noutputs. We examined two types of LLM architectures, including encoder-only\nGatorTron and decoder-only GatorTronGPT, and evaluated their performance for\nthe extraction of social determinants of health (SDoH) using a\ncross-institution dataset from the 2022 n2c2 challenge and a cross-disease\ndataset from the University of Florida (UF) Health. The results show that\ndecoder-only LLMs with prompt tuning achieved better performance in\ncross-domain applications. GatorTronGPT achieved the best F1 scores for both\ndatasets, outperforming traditional fine-tuned GatorTron by 8.9% and 21.8% in a\ncross-institution setting, and 5.5% and 14.5% in a cross-disease setting.", "published": "2024-03-19 02:34:33", "link": "http://arxiv.org/abs/2403.12374v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dr3: Ask Large Language Models Not to Give Off-Topic Answers in Open\n  Domain Multi-Hop Question Answering", "abstract": "Open Domain Multi-Hop Question Answering (ODMHQA) plays a crucial role in\nNatural Language Processing (NLP) by aiming to answer complex questions through\nmulti-step reasoning over retrieved information from external knowledge\nsources. Recently, Large Language Models (LLMs) have demonstrated remarkable\nperformance in solving ODMHQA owing to their capabilities including planning,\nreasoning, and utilizing tools. However, LLMs may generate off-topic answers\nwhen attempting to solve ODMHQA, namely the generated answers are irrelevant to\nthe original questions. This issue of off-topic answers accounts for\napproximately one-third of incorrect answers, yet remains underexplored despite\nits significance. To alleviate this issue, we propose the\nDiscriminate->Re-Compose->Re- Solve->Re-Decompose (Dr3) mechanism.\nSpecifically, the Discriminator leverages the intrinsic capabilities of LLMs to\njudge whether the generated answers are off-topic. In cases where an off-topic\nanswer is detected, the Corrector performs step-wise revisions along the\nreversed reasoning chain (Re-Compose->Re-Solve->Re-Decompose) until the final\nanswer becomes on-topic. Experimental results on the HotpotQA and\n2WikiMultiHopQA datasets demonstrate that our Dr3 mechanism considerably\nreduces the occurrence of off-topic answers in ODMHQA by nearly 13%, improving\nthe performance in Exact Match (EM) by nearly 3% compared to the baseline\nmethod without the Dr3 mechanism.", "published": "2024-03-19 03:00:03", "link": "http://arxiv.org/abs/2403.12393v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-Lingual Transfer for Natural Language Inference via Multilingual\n  Prompt Translator", "abstract": "Based on multilingual pre-trained models, cross-lingual transfer with prompt\nlearning has shown promising effectiveness, where soft prompt learned in a\nsource language is transferred to target languages for downstream tasks,\nparticularly in the low-resource scenario. To efficiently transfer soft prompt,\nwe propose a novel framework, Multilingual Prompt Translator (MPT), where a\nmultilingual prompt translator is introduced to properly process crucial\nknowledge embedded in prompt by changing language knowledge while retaining\ntask knowledge. Concretely, we first train prompt in source language and employ\ntranslator to translate it into target prompt. Besides, we extend an external\ncorpus as auxiliary data, on which an alignment task for predicted answer\nprobability is designed to convert language knowledge, thereby equipping target\nprompt with multilingual knowledge. In few-shot settings on XNLI, MPT\ndemonstrates superiority over baselines by remarkable improvements. MPT is more\nprominent compared with vanilla prompting when transferring to languages quite\ndistinct from source language.", "published": "2024-03-19 03:35:18", "link": "http://arxiv.org/abs/2403.12407v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Third-Party Language Model Performance Prediction from Instruction", "abstract": "Language model-based instruction-following systems have lately shown\nincreasing performance on many benchmark tasks, demonstrating the capability of\nadapting to a broad variety of instructions. However, such systems are often\nnot designed to be transparent about their limitations; a user may easily\nprompt a model with an instruction without any idea of whether the responses\nshould be expected to be accurate, or if the system is even capable of\nperforming the task. We propose a third party performance prediction framework,\nwhere a separate model is trained to predict the metric resulting from\nevaluating an instruction-following system on a task while assuming access only\nto its inputs and outputs at inference time. We perform this analysis with a\nvariety of both open and closed instruction-following models as well as\nmultiple performance predictors, and examine the effect of various factors such\nas model size, number of training tasks, and prompt format. Our findings\nindicate that third-party performance prediction is very challenging, and much\nwork remains in developing predictors that can automatically reveal the\nlimitations of modern instruction-following natural language processing\nsystems.", "published": "2024-03-19 03:53:47", "link": "http://arxiv.org/abs/2403.12413v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CrossTune: Black-Box Few-Shot Classification with Label Enhancement", "abstract": "Training or finetuning large-scale language models (LLMs) requires\nsubstantial computation resources, motivating recent efforts to explore\nparameter-efficient adaptation to downstream tasks. One approach is to treat\nthese models as black boxes and use forward passes (Inference APIs) to interact\nwith them. Current research focuses on adapting these black-box models to\ndownstream tasks using gradient-free prompt optimization, but this often\ninvolves an expensive process of searching task-specific prompts. Therefore, we\nare motivated to study black-box language model adaptation without prompt\nsearch. Specifically, we introduce a label-enhanced cross-attention network\ncalled CrossTune, which models the semantic relatedness between the input text\nsequence and task-specific label descriptions. Its effectiveness is examined in\nthe context of few-shot text classification. To improve the generalization of\nCrossTune, we utilize ChatGPT to generate additional training data through\nin-context learning. A switch mechanism is implemented to exclude low-quality\nChatGPT-generated data. Through extensive experiments on seven benchmark text\nclassification datasets, we demonstrate that our proposed approach outperforms\nthe previous state-of-the-art gradient-free black-box tuning method by 5.7% on\naverage. Even without using ChatGPT-augmented data, CrossTune performs better\nor comparably than previous black-box tuning methods, suggesting the\neffectiveness of our approach.", "published": "2024-03-19 05:52:56", "link": "http://arxiv.org/abs/2403.12468v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Large Collection of Model-generated Contradictory Responses for\n  Consistency-aware Dialogue Systems", "abstract": "Mitigating the generation of contradictory responses poses a substantial\nchallenge in dialogue response generation. The quality and quantity of\navailable contradictory response data play a vital role in suppressing these\ncontradictions, offering two significant benefits. First, having access to\nlarge contradiction data enables a comprehensive examination of their\ncharacteristics. Second, data-driven methods to mitigate contradictions may be\nenhanced with large-scale contradiction data for training. Nevertheless, no\nattempt has been made to build an extensive collection of model-generated\ncontradictory responses. In this paper, we build a large dataset of response\ngeneration models' contradictions for the first time. Then, we acquire valuable\ninsights into the characteristics of model-generated contradictions through an\nextensive analysis of the collected responses. Lastly, we also demonstrate how\nthis dataset substantially enhances the performance of data-driven\ncontradiction suppression methods.", "published": "2024-03-19 07:07:13", "link": "http://arxiv.org/abs/2403.12500v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prompt-based Graph Model for Joint Liberal Event Extraction and Event\n  Schema Induction", "abstract": "Events are essential components of speech and texts, describing the changes\nin the state of entities. The event extraction task aims to identify and\nclassify events and find their participants according to event schemas.\nManually predefined event schemas have limited coverage and are hard to migrate\nacross domains. Therefore, the researchers propose Liberal Event Extraction\n(LEE), which aims to extract events and discover event schemas simultaneously.\nHowever, existing LEE models rely heavily on external language knowledge bases\nand require the manual development of numerous rules for noise removal and\nknowledge alignment, which is complex and laborious. To this end, we propose a\nPrompt-based Graph Model for Liberal Event Extraction (PGLEE). Specifically, we\nuse a prompt-based model to obtain candidate triggers and arguments, and then\nbuild heterogeneous event graphs to encode the structures within and between\nevents. Experimental results prove that our approach achieves excellent\nperformance with or without predefined event schemas, while the automatically\ndetected event schemas are proven high quality.", "published": "2024-03-19 07:56:42", "link": "http://arxiv.org/abs/2403.12526v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Factorized Learning Assisted with Large Language Model for Gloss-free\n  Sign Language Translation", "abstract": "Previous Sign Language Translation (SLT) methods achieve superior performance\nby relying on gloss annotations. However, labeling high-quality glosses is a\nlabor-intensive task, which limits the further development of SLT. Although\nsome approaches work towards gloss-free SLT through jointly training the visual\nencoder and translation network, these efforts still suffer from poor\nperformance and inefficient use of the powerful Large Language Model (LLM).\nMost seriously, we find that directly introducing LLM into SLT will lead to\ninsufficient learning of visual representations as LLM dominates the learning\ncurve. To address these problems, we propose Factorized Learning assisted with\nLarge Language Model (FLa-LLM) for gloss-free SLT. Concretely, we factorize the\ntraining process into two stages. In the visual initialing stage, we employ a\nlightweight translation model after the visual encoder to pre-train the visual\nencoder. In the LLM fine-tuning stage, we freeze the acquired knowledge in the\nvisual encoder and integrate it with a pre-trained LLM to inspire the LLM's\ntranslation potential. This factorized training strategy proves to be highly\neffective as evidenced by significant improvements achieved across three SLT\ndatasets which are all conducted under the gloss-free setting.", "published": "2024-03-19 09:00:23", "link": "http://arxiv.org/abs/2403.12556v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AlphaFin: Benchmarking Financial Analysis with Retrieval-Augmented\n  Stock-Chain Framework", "abstract": "The task of financial analysis primarily encompasses two key areas: stock\ntrend prediction and the corresponding financial question answering. Currently,\nmachine learning and deep learning algorithms (ML&DL) have been widely applied\nfor stock trend predictions, leading to significant progress. However, these\nmethods fail to provide reasons for predictions, lacking interpretability and\nreasoning processes. Also, they can not integrate textual information such as\nfinancial news or reports. Meanwhile, large language models (LLMs) have\nremarkable textual understanding and generation ability. But due to the\nscarcity of financial training datasets and limited integration with real-time\nknowledge, LLMs still suffer from hallucinations and are unable to keep up with\nthe latest information. To tackle these challenges, we first release AlphaFin\ndatasets, combining traditional research datasets, real-time financial data,\nand handwritten chain-of-thought (CoT) data. It has a positive impact on\ntraining LLMs for completing financial analysis. We then use AlphaFin datasets\nto benchmark a state-of-the-art method, called Stock-Chain, for effectively\ntackling the financial analysis task, which integrates retrieval-augmented\ngeneration (RAG) techniques. Extensive experiments are conducted to demonstrate\nthe effectiveness of our framework on financial analysis.", "published": "2024-03-19 09:45:33", "link": "http://arxiv.org/abs/2403.12582v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chart-based Reasoning: Transferring Capabilities from LLMs to VLMs", "abstract": "Vision-language models (VLMs) are achieving increasingly strong performance\non multimodal tasks. However, reasoning capabilities remain limited\nparticularly for smaller VLMs, while those of large-language models (LLMs) have\nseen numerous improvements. We propose a technique to transfer capabilities\nfrom LLMs to VLMs. On the recently introduced ChartQA, our method obtains\nstate-of-the-art performance when applied on the PaLI3-5B VLM by\n\\citet{chen2023pali3}, while also enabling much better performance on PlotQA\nand FigureQA.\n  We first improve the chart representation by continuing the pre-training\nstage using an improved version of the chart-to-table translation task by\n\\citet{liu2023deplot}. We then propose constructing a 20x larger dataset than\nthe original training set. To improve general reasoning capabilities and\nimprove numerical operations, we synthesize reasoning traces using the table\nrepresentation of charts. Lastly, our model is fine-tuned using the multitask\nloss introduced by \\citet{hsieh2023distilling}.\n  Our variant ChartPaLI-5B outperforms even 10x larger models such as PaLIX-55B\nwithout using an upstream OCR system, while keeping inference time constant\ncompared to the PaLI3-5B baseline. When rationales are further refined with a\nsimple program-of-thought prompt \\cite{chen2023program}, our model outperforms\nthe recently introduced Gemini Ultra and GPT-4V.", "published": "2024-03-19 10:03:07", "link": "http://arxiv.org/abs/2403.12596v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LHMKE: A Large-scale Holistic Multi-subject Knowledge Evaluation\n  Benchmark for Chinese Large Language Models", "abstract": "Chinese Large Language Models (LLMs) have recently demonstrated impressive\ncapabilities across various NLP benchmarks and real-world applications.\nHowever, the existing benchmarks for comprehensively evaluating these LLMs are\nstill insufficient, particularly in terms of measuring knowledge that LLMs\ncapture. Current datasets collect questions from Chinese examinations across\ndifferent subjects and educational levels to address this issue. Yet, these\nbenchmarks primarily focus on objective questions such as multiple-choice\nquestions, leading to a lack of diversity in question types. To tackle this\nproblem, we propose LHMKE, a Large-scale, Holistic, and Multi-subject Knowledge\nEvaluation benchmark in this paper. LHMKE is designed to provide a\ncomprehensive evaluation of the knowledge acquisition capabilities of Chinese\nLLMs. It encompasses 10,465 questions across 75 tasks covering 30 subjects,\nranging from primary school to professional certification exams. Notably, LHMKE\nincludes both objective and subjective questions, offering a more holistic\nevaluation of the knowledge level of LLMs. We have assessed 11 Chinese LLMs\nunder the zero-shot setting, which aligns with real examinations, and compared\ntheir performance across different subjects. We also conduct an in-depth\nanalysis to check whether GPT-4 can automatically score subjective predictions.\nOur findings suggest that LHMKE is a challenging and advanced testbed for\nChinese LLMs.", "published": "2024-03-19 10:11:14", "link": "http://arxiv.org/abs/2403.12601v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Dimensional Machine Translation Evaluation: Model Evaluation and\n  Resource for Korean", "abstract": "Almost all frameworks for the manual or automatic evaluation of machine\ntranslation characterize the quality of an MT output with a single number. An\nexception is the Multidimensional Quality Metrics (MQM) framework which offers\na fine-grained ontology of quality dimensions for scoring (such as style,\nfluency, accuracy, and terminology). Previous studies have demonstrated the\nfeasibility of MQM annotation but there are, to our knowledge, no computational\nmodels that predict MQM scores for novel texts, due to a lack of resources. In\nthis paper, we address these shortcomings by (a) providing a 1200-sentence MQM\nevaluation benchmark for the language pair English-Korean and (b) reframing MT\nevaluation as the multi-task problem of simultaneously predicting several MQM\nscores using SOTA language models, both in a reference-based MT evaluation\nsetup and a reference-free quality estimation (QE) setup. We find that\nreference-free setup outperforms its counterpart in the style dimension while\nreference-based models retain an edge regarding accuracy. Overall, RemBERT\nemerges as the most promising model. Through our evaluation, we offer an\ninsight into the translation quality in a more fine-grained, interpretable\nmanner.", "published": "2024-03-19 12:02:38", "link": "http://arxiv.org/abs/2403.12666v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pragmatic Competence Evaluation of Large Language Models for the Korean\n  Language", "abstract": "Benchmarks play a significant role in the current evaluation of Large\nLanguage Models (LLMs), yet they often overlook the models' abilities to\ncapture the nuances of human language, primarily focusing on evaluating\nembedded knowledge and technical skills. To address this gap, our study\nevaluates how well LLMs understand context-dependent expressions from a\npragmatic standpoint, specifically in Korean. We use both Multiple-Choice\nQuestions (MCQs) for automatic evaluation and Open-Ended Questions (OEQs)\nassessed by human experts. Our results show that GPT-4 leads with scores of\n81.11 in MCQs and 85.69 in OEQs, closely followed by HyperCLOVA X.\nAdditionally, while few-shot learning generally improves performance,\nChain-of-Thought (CoT) prompting tends to encourage literal interpretations,\nwhich may limit effective pragmatic inference. Our findings highlight the need\nfor LLMs to better understand and generate language that reflects human\ncommunicative norms.", "published": "2024-03-19 12:21:20", "link": "http://arxiv.org/abs/2403.12675v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CLASSLA-web: Comparable Web Corpora of South Slavic Languages Enriched\n  with Linguistic and Genre Annotation", "abstract": "This paper presents a collection of highly comparable web corpora of\nSlovenian, Croatian, Bosnian, Montenegrin, Serbian, Macedonian, and Bulgarian,\ncovering thereby the whole spectrum of official languages in the South Slavic\nlanguage space. The collection of these corpora comprises a total of 13 billion\ntokens of texts from 26 million documents. The comparability of the corpora is\nensured by a comparable crawling setup and the usage of identical crawling and\npost-processing technology. All the corpora were linguistically annotated with\nthe state-of-the-art CLASSLA-Stanza linguistic processing pipeline, and\nenriched with document-level genre information via the Transformer-based\nmultilingual X-GENRE classifier, which further enhances comparability at the\nlevel of linguistic annotation and metadata enrichment. The genre-focused\nanalysis of the resulting corpora shows a rather consistent distribution of\ngenres throughout the seven corpora, with variations in the most prominent\ngenre categories being well-explained by the economic strength of each language\ncommunity. A comparison of the distribution of genre categories across the\ncorpora indicates that web corpora from less developed countries primarily\nconsist of news articles. Conversely, web corpora from economically more\ndeveloped countries exhibit a smaller proportion of news content, with a\ngreater presence of promotional and opinionated texts.", "published": "2024-03-19 13:30:47", "link": "http://arxiv.org/abs/2403.12721v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Instructing Large Language Models to Identify and Ignore Irrelevant\n  Conditions", "abstract": "Math word problem (MWP) solving requires generating a reasoning path based on\na given problem description that often contains irrelevant conditions. Existing\nchain-of-thought (CoT) prompting methods elicited multi-step reasoning\nabilities of large language models (LLMs) to solve MWPs. However, they were\nseriously confused by the irrelevant conditions, resulting in low accuracy. In\nthis paper, we propose a novel approach named I$^3$C that instructs LLMs to\nidentify and ignore irrelevant conditions. It identifies a set of irrelevant\ncondition candidates that have a weak semantic relevance with the question.\nThen it prompts LLMs to verify the irrelevant conditions. Lastly it instructs\nthe LLMs with the verification on relevant and irrelevant conditions to avoid\nconfusion and improve reasoning paths. Moreover, we propose to select (problem,\nreasoning paths) pairs as demonstrations to enhance I$^3$C with few-shot\nreasoning. We develop I$^3$C-Select that selects the most confusing problems\nbased on the semantic relevance measurement. We conduct extensive experiments\non eight MWP datasets. I$^3$C can be combined with any CoT prompting methods to\nimprove the performance of solving MWPs. Notably, with GPT-3.5-Turbo and\nI$^3$C-Select, we achieve an accuracy of 96.0 and 94.1 on GSM-IC2-1K and\nGSM-ICM-1K, respectively, significantly outperforming the state-of-the-art\nfew-shot prompting method Complex-CoT by +11.7 and +11.1. Our implementation is\nmade publicly available at https://wzy6642.github.io/I3C.github.io/.", "published": "2024-03-19 14:07:28", "link": "http://arxiv.org/abs/2403.12744v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sebastian, Basti, Wastl?! Recognizing Named Entities in Bavarian\n  Dialectal Data", "abstract": "Named Entity Recognition (NER) is a fundamental task to extract key\ninformation from texts, but annotated resources are scarce for dialects. This\npaper introduces the first dialectal NER dataset for German, BarNER, with 161K\ntokens annotated on Bavarian Wikipedia articles (bar-wiki) and tweets\n(bar-tweet), using a schema adapted from German CoNLL 2006 and GermEval. The\nBavarian dialect differs from standard German in lexical distribution,\nsyntactic construction, and entity information. We conduct in-domain,\ncross-domain, sequential, and joint experiments on two Bavarian and three\nGerman corpora and present the first comprehensive NER results on Bavarian.\nIncorporating knowledge from the larger German NER (sub-)datasets notably\nimproves on bar-wiki and moderately on bar-tweet. Inversely, training first on\nBavarian contributes slightly to the seminal German CoNLL 2006 corpus.\nMoreover, with gold dialect labels on Bavarian tweets, we assess multi-task\nlearning between five NER and two Bavarian-German dialect identification tasks\nand achieve NER SOTA on bar-wiki. We substantiate the necessity of our\nlow-resource BarNER corpus and the importance of diversity in dialects, genres,\nand topics in enhancing model performance.", "published": "2024-03-19 14:12:54", "link": "http://arxiv.org/abs/2403.12749v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automated Data Curation for Robust Language Model Fine-Tuning", "abstract": "Large Language Models have become the de facto approach to\nsequence-to-sequence text generation tasks, but for specialized tasks/domains,\na pretrained LLM lacks specific capabilities to produce accurate or\nwell-formatted responses. Supervised fine-tuning specializes a LLM by training\nit on dataset of example prompts with target responses, but real-world data\ntends to be noisy. While many fine-tuning algorithms exist, here we consider a\n\\emph{data-centric AI} perspective on LLM fine-tuning, studying how to\n\\emph{systematically} curate the training dataset to improve the LLM produced\nvia \\emph{any} fine-tuning algorithm.\n  We introduce an automated data curation pipeline CLEAR (Confidence-based LLM\nEvaluation And Rectification) for instruction tuning datasets, that can be used\nwith any LLM and fine-tuning procedure. CLEAR estimates which training data is\nlow-quality and either filters or corrects it. Automatically identifying which\ndata to filter or correct is done via LLM-derived confidence estimates, to\nensure only confident modifications to the dataset. Unlike existing data\ncuration techniques, CLEAR is a comprehensive framework that can improve a\ndataset (and trained model outputs) without additional fine-tuning\ncomputations. We don't assume access to a stronger LLM than the model being\nfine-tuned (e.g.\\ relying on GPT-4 when fine-tuning GPT-3.5), to see whether\nCLEAR can meaningfully improve the capabilities of any LLM. Experiments reveal\nthat CLEAR consistently improves the performance of fine-tuned models across\nmany datasets and models (like GPT-3.5 and Llama2).", "published": "2024-03-19 14:44:45", "link": "http://arxiv.org/abs/2403.12776v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Epistemology of Language Models: Do Language Models Have Holistic\n  Knowledge?", "abstract": "This paper investigates the inherent knowledge in language models from the\nperspective of epistemological holism. The purpose of this paper is to explore\nwhether LLMs exhibit characteristics consistent with epistemological holism.\nThese characteristics suggest that core knowledge, such as general scientific\nknowledge, each plays a specific role, serving as the foundation of our\nknowledge system and being difficult to revise. To assess these traits related\nto holism, we created a scientific reasoning dataset and examined the\nepistemology of language models through three tasks: Abduction, Revision, and\nArgument Generation. In the abduction task, the language models explained\nsituations while avoiding revising the core knowledge. However, in other tasks,\nthe language models were revealed not to distinguish between core and\nperipheral knowledge, showing an incomplete alignment with holistic knowledge\nprinciples.", "published": "2024-03-19 16:06:10", "link": "http://arxiv.org/abs/2403.12862v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Agent-FLAN: Designing Data and Methods of Effective Agent Tuning for\n  Large Language Models", "abstract": "Open-sourced Large Language Models (LLMs) have achieved great success in\nvarious NLP tasks, however, they are still far inferior to API-based models\nwhen acting as agents. How to integrate agent ability into general LLMs becomes\na crucial and urgent problem. This paper first delivers three key observations:\n(1) the current agent training corpus is entangled with both formats following\nand agent reasoning, which significantly shifts from the distribution of its\npre-training data; (2) LLMs exhibit different learning speeds on the\ncapabilities required by agent tasks; and (3) current approaches have\nside-effects when improving agent abilities by introducing hallucinations.\nBased on the above findings, we propose Agent-FLAN to effectively Fine-tune\nLANguage models for Agents. Through careful decomposition and redesign of the\ntraining corpus, Agent-FLAN enables Llama2-7B to outperform prior best works by\n3.5\\% across various agent evaluation datasets. With comprehensively\nconstructed negative samples, Agent-FLAN greatly alleviates the hallucination\nissues based on our established evaluation benchmark. Besides, it consistently\nimproves the agent capability of LLMs when scaling model sizes while slightly\nenhancing the general capability of LLMs. The code will be available at\nhttps://github.com/InternLM/Agent-FLAN.", "published": "2024-03-19 16:26:10", "link": "http://arxiv.org/abs/2403.12881v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Supporting Energy Policy Research with Large Language Models", "abstract": "The recent growth in renewable energy development in the United States has\nbeen accompanied by a simultaneous surge in renewable energy siting ordinances.\nThese zoning laws play a critical role in dictating the placement of wind and\nsolar resources that are critical for achieving low-carbon energy futures. In\nthis context, efficient access to and management of siting ordinance data\nbecomes imperative. The National Renewable Energy Laboratory (NREL) recently\nintroduced a public wind and solar siting database to fill this need. This\npaper presents a method for harnessing Large Language Models (LLMs) to automate\nthe extraction of these siting ordinances from legal documents, enabling this\ndatabase to maintain accurate up-to-date information in the rapidly changing\nenergy policy landscape. A novel contribution of this research is the\nintegration of a decision tree framework with LLMs. Our results show that this\napproach is 85 to 90% accurate with outputs that can be used directly in\ndownstream quantitative modeling. We discuss opportunities to use this work to\nsupport similar large-scale policy research in the energy sector. By unlocking\nnew efficiencies in the extraction and analysis of legal documents using LLMs,\nthis study enables a path forward for automated large-scale energy policy\nresearch.", "published": "2024-03-19 17:28:51", "link": "http://arxiv.org/abs/2403.12924v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dated Data: Tracing Knowledge Cutoffs in Large Language Models", "abstract": "Released Large Language Models (LLMs) are often paired with a claimed\nknowledge cutoff date, or the dates at which training data was gathered. Such\ninformation is crucial for applications where the LLM must provide up to date\ninformation. However, this statement only scratches the surface: do all\nresources in the training data share the same knowledge cutoff date? Does the\nmodel's demonstrated knowledge for these subsets closely align to their cutoff\ndates? In this work, we define the notion of an effective cutoff. This is\ndistinct from the LLM designer reported cutoff and applies separately to\nsub-resources and topics. We propose a simple approach to estimate effective\ncutoffs on the resource-level temporal alignment of an LLM by probing across\nversions of the data. Using this analysis, we find that effective cutoffs often\ndiffer from reported cutoffs. To understand the root cause of this observation,\nwe conduct a direct large-scale analysis on open pre-training datasets. Our\nanalysis reveals two reasons for these inconsistencies: (1) temporal biases of\nCommonCrawl data due to non-trivial amounts of old data in new dumps and (2)\ncomplications in LLM deduplication schemes involving semantic duplicates and\nlexical near-duplicates. Overall, our results show that knowledge cutoffs are\nnot as simple as they have seemed and that care must be taken both by LLM\ndataset curators as well as practitioners who seek to use information from\nthese models.", "published": "2024-03-19 17:57:58", "link": "http://arxiv.org/abs/2403.12958v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Summarization of Doctor-Patient Encounter Dialogues Using\n  Large Language Model through Prompt Tuning", "abstract": "Automatic text summarization (ATS) is an emerging technology to assist\nclinicians in providing continuous and coordinated care. This study presents an\napproach to summarize doctor-patient dialogues using generative large language\nmodels (LLMs). We developed prompt-tuning algorithms to instruct generative\nLLMs to summarize clinical text. We examined the prompt-tuning strategies, the\nsize of soft prompts, and the few-short learning ability of GatorTronGPT, a\ngenerative clinical LLM developed using 277 billion clinical and general\nEnglish words with up to 20 billion parameters. We compared GatorTronGPT with a\nprevious solution based on fine-tuning of a widely used T5 model, using a\nclinical benchmark dataset MTS-DIALOG. The experimental results show that the\nGatorTronGPT- 20B model achieved the best performance on all evaluation\nmetrics. The proposed solution has a low computing cost as the LLM parameters\nare not updated during prompt-tuning. This study demonstrates the efficiency of\ngenerative clinical LLMs for clinical ATS through prompt tuning.", "published": "2024-03-19 18:37:05", "link": "http://arxiv.org/abs/2403.13089v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Encoder-Decoder Transformer Decoding for Decomposable Tasks", "abstract": "Transformer-based NLP models are powerful but have high computational costs\nthat limit deployment. Finetuned encoder-decoder models are popular in\nspecialized domains and can outperform larger more generalized decoder-only\nmodels, such as GPT-4. We introduce a new configuration for encoder-decoder\nmodels that improves efficiency on structured output and decomposable tasks\nwhere multiple outputs are required for a single shared input. Our method,\nprompt-in-decoder (PiD), encodes the input once and decodes the output in\nparallel, boosting both training and inference efficiency by avoiding duplicate\ninput encoding and increasing the operational intensity (ratio of numbers of\narithmetic operation to memory access) of decoding process by sharing the input\nkey-value cache. We achieve computation reduction that roughly scales with the\nnumber of subtasks, gaining up to 4.6x speed-up over state-of-the-art models\nfor dialogue state tracking, summarization, and question-answering tasks, with\ncomparable or better performance.", "published": "2024-03-19 19:27:23", "link": "http://arxiv.org/abs/2403.13112v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Wav2Gloss: Generating Interlinear Glossed Text from Speech", "abstract": "Thousands of the world's languages are in danger of extinction--a tremendous\nthreat to cultural identities and human language diversity. Interlinear Glossed\nText (IGT) is a form of linguistic annotation that can support documentation\nand resource creation for these languages' communities. IGT typically consists\nof (1) transcriptions, (2) morphological segmentation, (3) glosses, and (4)\nfree translations to a majority language. We propose Wav2Gloss: a task in which\nthese four annotation components are extracted automatically from speech, and\nintroduce the first dataset to this end, Fieldwork: a corpus of speech with all\nthese annotations, derived from the work of field linguists, covering 37\nlanguages, with standard formatting, and train/dev/test splits. We provide\nvarious baselines to lay the groundwork for future research on IGT generation\nfrom speech, such as end-to-end versus cascaded, monolingual versus\nmultilingual, and single-task versus multi-task approaches.", "published": "2024-03-19 21:45:29", "link": "http://arxiv.org/abs/2403.13169v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Assessing effect sizes, variability, and power in the on-line study of\n  language production", "abstract": "With the pandemic, many experimental psychologists and linguists have started\nto collect data over the internet (hereafter on-line data). The feasibility of\nsuch experiments and the sample sizes required to achieve sufficient\nstatistical power in future experiments have to be assessed. This in turn\nrequires information on effect sizes and variability. In a series of analyses,\nwe compare response time data obtained in the same word production experiment\nconducted in the lab and on-line. These analyses allow us to determine whether\nthe two settings differ in effect sizes, in the consistency of responses over\nthe course of the experiment, in the variability of average response times\nacross participants, in the magnitude of effect sizes across participants, or\nin the amount of unexplained variability. We assess the impact of these\ndifferences on the power of the design in a series of simulations. Our findings\ntemper the enthusiasm raised by previous studies and suggest that on-line\nproduction studies might be feasible but at a non-negligible cost. The sample\nsizes required to achieve sufficient power in on-line language production\nstudies come with a non-negligible increase in the amount of manual labour.", "published": "2024-03-19 11:49:03", "link": "http://arxiv.org/abs/2403.15459v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Characteristic AI Agents via Large Language Models", "abstract": "The advancement of Large Language Models (LLMs) has led to significant\nenhancements in the performance of chatbot systems. Many researchers have\ndedicated their efforts to the development of bringing characteristics to\nchatbots. While there have been commercial products for developing role-driven\nchatbots using LLMs, it is worth noting that academic research in this area\nremains relatively scarce. Our research focuses on investigating the\nperformance of LLMs in constructing Characteristic AI Agents by simulating\nreal-life individuals across different settings. Current investigations have\nprimarily focused on act on roles with simple profiles. In response to this\nresearch gap, we create a benchmark for the characteristic AI agents task,\nincluding dataset, techniques, and evaluation metrics. A dataset called\n``Character100'' is built for this benchmark, comprising the most-visited\npeople on Wikipedia for language models to role-play. With the constructed\ndataset, we conduct comprehensive assessment of LLMs across various settings.\nIn addition, we devise a set of automatic metrics for quantitative performance\nevaluation. The experimental results underscore the potential directions for\nfurther improvement in the capabilities of LLMs in constructing characteristic\nAI agents. The benchmark is available at\nhttps://github.com/nuaa-nlp/Character100.", "published": "2024-03-19 02:25:29", "link": "http://arxiv.org/abs/2403.12368v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Pipelined Biomedical Event Extraction Rivaling Joint Learning", "abstract": "Biomedical event extraction is an information extraction task to obtain\nevents from biomedical text, whose targets include the type, the trigger, and\nthe respective arguments involved in an event. Traditional biomedical event\nextraction usually adopts a pipelined approach, which contains trigger\nidentification, argument role recognition, and finally event construction\neither using specific rules or by machine learning. In this paper, we propose\nan n-ary relation extraction method based on the BERT pre-training model to\nconstruct Binding events, in order to capture the semantic information about an\nevent's context and its participants. The experimental results show that our\nmethod achieves promising results on the GE11 and GE13 corpora of the BioNLP\nshared task with F1 scores of 63.14% and 59.40%, respectively. It demonstrates\nthat by significantly improving theperformance of Binding events, the overall\nperformance of the pipelined event extraction approach or even exceeds those of\ncurrent joint learning methods.", "published": "2024-03-19 02:52:58", "link": "http://arxiv.org/abs/2403.12386v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AraPoemBERT: A Pretrained Language Model for Arabic Poetry Analysis", "abstract": "Arabic poetry, with its rich linguistic features and profound cultural\nsignificance, presents a unique challenge to the Natural Language Processing\n(NLP) field. The complexity of its structure and context necessitates advanced\ncomputational models for accurate analysis. In this paper, we introduce\nAraPoemBERT, an Arabic language model pretrained exclusively on Arabic poetry\ntext. To demonstrate the effectiveness of the proposed model, we compared\nAraPoemBERT with 5 different Arabic language models on various NLP tasks\nrelated to Arabic poetry. The new model outperformed all other models and\nachieved state-of-the-art results in most of the downstream tasks. AraPoemBERT\nachieved unprecedented accuracy in two out of three novel tasks: poet's gender\nclassification (99.34\\% accuracy), and poetry sub-meter classification (97.79\\%\naccuracy). In addition, the model achieved an accuracy score in poems' rhyme\nclassification (97.73\\% accuracy) which is almost equivalent to the best score\nreported in this study. Moreover, the proposed model significantly outperformed\nprevious work and other comparative models in the tasks of poems' sentiment\nanalysis, achieving an accuracy of 78.95\\%, and poetry meter classification\n(99.03\\% accuracy), while significantly expanding the scope of these two\nproblems. The dataset used in this study, contains more than 2.09 million\nverses collected from online sources, each associated with various attributes\nsuch as meter, sub-meter, poet, rhyme, and topic. The results demonstrate the\neffectiveness of the proposed model in understanding and analyzing Arabic\npoetry, achieving state-of-the-art results in several tasks and outperforming\nprevious works and other language models included in the study. AraPoemBERT\nmodel is publicly available on \\url{https://huggingface.co/faisalq}.", "published": "2024-03-19 02:59:58", "link": "http://arxiv.org/abs/2403.12392v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Eye-gaze Guided Multi-modal Alignment for Medical Representation\n  Learning", "abstract": "In the medical multi-modal frameworks, the alignment of cross-modality\nfeatures presents a significant challenge. However, existing works have learned\nfeatures that are implicitly aligned from the data, without considering the\nexplicit relationships in the medical context. This data-reliance may lead to\nlow generalization of the learned alignment relationships. In this work, we\npropose the Eye-gaze Guided Multi-modal Alignment (EGMA) framework to harness\neye-gaze data for better alignment of medical visual and textual features. We\nexplore the natural auxiliary role of radiologists' eye-gaze data in aligning\nmedical images and text, and introduce a novel approach by using eye-gaze data,\ncollected synchronously by radiologists during diagnostic evaluations. We\nconduct downstream tasks of image classification and image-text retrieval on\nfour medical datasets, where EGMA achieved state-of-the-art performance and\nstronger generalization across different datasets. Additionally, we explore the\nimpact of varying amounts of eye-gaze data on model performance, highlighting\nthe feasibility and utility of integrating this auxiliary data into multi-modal\nalignment framework.", "published": "2024-03-19 03:59:14", "link": "http://arxiv.org/abs/2403.12416v3", "categories": ["cs.CV", "cs.CL", "68T07", "I.2.0; I.4.0; I.5.4; I.7.0"], "primary_category": "cs.CV"}
{"title": "When Do \"More Contexts\" Help with Sarcasm Recognition?", "abstract": "Sarcasm recognition is challenging because it needs an understanding of the\ntrue intention, which is opposite to or different from the literal meaning of\nthe words. Prior work has addressed this challenge by developing a series of\nmethods that provide richer $contexts$, e.g., sentiment or cultural nuances, to\nmodels. While shown to be effective individually, no study has systematically\nevaluated their collective effectiveness. As a result, it remains unclear to\nwhat extent additional contexts can improve sarcasm recognition. In this work,\nwe explore the improvements that existing methods bring by incorporating more\ncontexts into a model. To this end, we develop a framework where we can\nintegrate multiple contextual cues and test different approaches. In evaluation\nwith four approaches on three sarcasm recognition benchmarks, we achieve\nexisting state-of-the-art performances and also demonstrate the benefits of\nsequentially adding more contexts. We also identify inherent drawbacks of using\nmore contexts, highlighting that in the pursuit of even better results, the\nmodel may need to adopt societal biases.", "published": "2024-03-19 06:01:02", "link": "http://arxiv.org/abs/2403.12469v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GraphERE: Jointly Multiple Event-Event Relation Extraction via\n  Graph-Enhanced Event Embeddings", "abstract": "Events describe the state changes of entities. In a document, multiple events\nare connected by various relations (e.g., Coreference, Temporal, Causal, and\nSubevent). Therefore, obtaining the connections between events through\nEvent-Event Relation Extraction (ERE) is critical to understand natural\nlanguage. There are two main problems in the current ERE works: a. Only\nembeddings of the event triggers are used for event feature representation,\nignoring event arguments (e.g., time, place, person, etc.) and their structure\nwithin the event. b. The interconnection between relations (e.g., temporal and\ncausal relations usually interact with each other ) is ignored. To solve the\nabove problems, this paper proposes a jointly multiple ERE framework called\nGraphERE based on Graph-enhanced Event Embeddings. First, we enrich the event\nembeddings with event argument and structure features by using static AMR\ngraphs and IE graphs; Then, to jointly extract multiple event relations, we use\nNode Transformer and construct Task-specific Dynamic Event Graphs for each type\nof relation. Finally, we used a multi-task learning strategy to train the whole\nframework. Experimental results on the latest MAVEN-ERE dataset validate that\nGraphERE significantly outperforms existing methods. Further analyses indicate\nthe effectiveness of the graph-enhanced event embeddings and the joint\nextraction strategy.", "published": "2024-03-19 07:50:32", "link": "http://arxiv.org/abs/2403.12523v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Simple Hack for Transformers against Heavy Long-Text Classification on a\n  Time- and Memory-Limited GPU Service", "abstract": "Many NLP researchers rely on free computational services, such as Google\nColab, to fine-tune their Transformer models, causing a limitation for\nhyperparameter optimization (HPO) in long-text classification due to the method\nhaving quadratic complexity and needing a bigger resource. In Indonesian, only\na few works were found on long-text classification using Transformers. Most\nonly use a small amount of data and do not report any HPO. In this study, using\n18k news articles, we investigate which pretrained models are recommended to\nuse based on the output length of the tokenizer. We then compare some hacks to\nshorten and enrich the sequences, which are the removals of stopwords,\npunctuation, low-frequency words, and recurring words. To get a fair\ncomparison, we propose and run an efficient and dynamic HPO procedure that can\nbe done gradually on a limited resource and does not require a long-running\noptimization library. Using the best hack found, we then compare 512, 256, and\n128 tokens length. We find that removing stopwords while keeping punctuation\nand low-frequency words is the best hack. Some of our setups manage to\noutperform taking 512 first tokens using a smaller 128 or 256 first tokens\nwhich manage to represent the same information while requiring less\ncomputational resources. The findings could help developers to efficiently\npursue optimal performance of the models using limited resources.", "published": "2024-03-19 09:17:25", "link": "http://arxiv.org/abs/2403.12563v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Empowering Air Travelers: A Chatbot for Canadian Air Passenger Rights", "abstract": "The Canadian air travel sector has seen a significant increase in flight\ndelays, cancellations, and other issues concerning passenger rights.\nRecognizing this demand, we present a chatbot to assist passengers and educate\nthem about their rights. Our system breaks a complex user input into simple\nqueries which are used to retrieve information from a collection of documents\ndetailing air travel regulations. The most relevant passages from these\ndocuments are presented along with links to the original documents and the\ngenerated queries, enabling users to dissect and leverage the information for\ntheir unique circumstances. The system successfully overcomes two predominant\nchallenges: understanding complex user inputs, and delivering accurate answers,\nfree of hallucinations, that passengers can rely on for making informed\ndecisions. A user study comparing the chatbot to a Google search demonstrated\nthe chatbot's usefulness and ease of use. Beyond the primary goal of providing\naccurate and timely information to air passengers regarding their rights, we\nhope that this system will also enable further research exploring the tradeoff\nbetween the user-friendly conversational interface of chatbots and the accuracy\nof retrieval systems.", "published": "2024-03-19 12:24:20", "link": "http://arxiv.org/abs/2403.12678v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Investigating Text Shortening Strategy in BERT: Truncation vs\n  Summarization", "abstract": "The parallelism of Transformer-based models comes at the cost of their input\nmax-length. Some studies proposed methods to overcome this limitation, but none\nof them reported the effectiveness of summarization as an alternative. In this\nstudy, we investigate the performance of document truncation and summarization\nin text classification tasks. Each of the two was investigated with several\nvariations. This study also investigated how close their performances are to\nthe performance of full-text. We used a dataset of summarization tasks based on\nIndonesian news articles (IndoSum) to do classification tests. This study shows\nhow the summaries outperform the majority of truncation method variations and\nlose to only one. The best strategy obtained in this study is taking the head\nof the document. The second is extractive summarization. This study explains\nwhat happened to the result, leading to further research in order to exploit\nthe potential of document summarization as a shortening alternative. The code\nand data used in this work are publicly available in\nhttps://github.com/mirzaalimm/TruncationVsSummarization.", "published": "2024-03-19 15:01:14", "link": "http://arxiv.org/abs/2403.12799v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Contextual Moral Value Alignment Through Context-Based Aggregation", "abstract": "Developing value-aligned AI agents is a complex undertaking and an ongoing\nchallenge in the field of AI. Specifically within the domain of Large Language\nModels (LLMs), the capability to consolidate multiple independently trained\ndialogue agents, each aligned with a distinct moral value, into a unified\nsystem that can adapt to and be aligned with multiple moral values is of\nparamount importance. In this paper, we propose a system that does contextual\nmoral value alignment based on contextual aggregation. Here, aggregation is\ndefined as the process of integrating a subset of LLM responses that are best\nsuited to respond to a user input, taking into account features extracted from\nthe user's input. The proposed system shows better results in term of alignment\nto human value compared to the state of the art.", "published": "2024-03-19 15:06:53", "link": "http://arxiv.org/abs/2403.12805v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Comparing Explanation Faithfulness between Multilingual and Monolingual\n  Fine-tuned Language Models", "abstract": "In many real natural language processing application scenarios, practitioners\nnot only aim to maximize predictive performance but also seek faithful\nexplanations for the model predictions. Rationales and importance distribution\ngiven by feature attribution methods (FAs) provide insights into how different\nparts of the input contribute to a prediction. Previous studies have explored\nhow different factors affect faithfulness, mainly in the context of monolingual\nEnglish models. On the other hand, the differences in FA faithfulness between\nmultilingual and monolingual models have yet to be explored. Our extensive\nexperiments, covering five languages and five popular FAs, show that FA\nfaithfulness varies between multilingual and monolingual models. We find that\nthe larger the multilingual model, the less faithful the FAs are compared to\nits counterpart monolingual models.Our further analysis shows that the\nfaithfulness disparity is potentially driven by the differences between model\ntokenizers. Our code is available:\nhttps://github.com/casszhao/multilingual-faith.", "published": "2024-03-19 15:07:22", "link": "http://arxiv.org/abs/2403.12809v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Automatic Information Extraction From Employment Tribunal Judgements\n  Using Large Language Models", "abstract": "Court transcripts and judgments are rich repositories of legal knowledge,\ndetailing the intricacies of cases and the rationale behind judicial decisions.\nThe extraction of key information from these documents provides a concise\noverview of a case, crucial for both legal experts and the public. With the\nadvent of large language models (LLMs), automatic information extraction has\nbecome increasingly feasible and efficient. This paper presents a comprehensive\nstudy on the application of GPT-4, a large language model, for automatic\ninformation extraction from UK Employment Tribunal (UKET) cases. We\nmeticulously evaluated GPT-4's performance in extracting critical information\nwith a manual verification process to ensure the accuracy and relevance of the\nextracted data. Our research is structured around two primary extraction tasks:\nthe first involves a general extraction of eight key aspects that hold\nsignificance for both legal specialists and the general public, including the\nfacts of the case, the claims made, references to legal statutes, references to\nprecedents, general case outcomes and corresponding labels, detailed order and\nremedies and reasons for the decision. The second task is more focused, aimed\nat analysing three of those extracted features, namely facts, claims and\noutcomes, in order to facilitate the development of a tool capable of\npredicting the outcome of employment law disputes. Through our analysis, we\ndemonstrate that LLMs like GPT-4 can obtain high accuracy in legal information\nextraction, highlighting the potential of LLMs in revolutionising the way legal\ninformation is processed and utilised, offering significant implications for\nlegal research and practice.", "published": "2024-03-19 17:43:08", "link": "http://arxiv.org/abs/2403.12936v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Vision-Language Few-Shot Adaptation with Negative Learning", "abstract": "Large-scale pre-trained Vision-Language Models (VLMs) have exhibited\nimpressive zero-shot performance and transferability, allowing them to adapt to\ndownstream tasks in a data-efficient manner. However, when only a few labeled\nsamples are available, adapting VLMs to distinguish subtle differences between\nsimilar classes in specific downstream tasks remains challenging. In this work,\nwe propose a Simple yet effective Negative Learning approach, SimNL, to more\nefficiently exploit the task-specific knowledge from few-shot labeled samples.\nUnlike previous methods that focus on identifying a set of representative\npositive features defining \"what is a {CLASS}\", SimNL discovers a complementary\nset of negative features that define \"what is not a {CLASS}\", providing\nadditional insights that supplement the positive features to enhance\ntask-specific recognition capability. Further, we identify that current\nadaptation approaches are particularly vulnerable to potential noise in the\nfew-shot sample set. To mitigate this issue, we introduce a plug-and-play\nfew-shot instance reweighting technique to suppress noisy outliers and amplify\nclean samples for more stable adaptation. Our extensive experimental results\nacross 15 datasets validate that the proposed SimNL outperforms existing\nstate-of-the-art methods on both few-shot learning and domain generalization\ntasks while achieving competitive computational efficiency. Code is available\nat https://github.com/zhangce01/SimNL.", "published": "2024-03-19 17:59:39", "link": "http://arxiv.org/abs/2403.12964v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "LLMLingua-2: Data Distillation for Efficient and Faithful Task-Agnostic\n  Prompt Compression", "abstract": "This paper focuses on task-agnostic prompt compression for better\ngeneralizability and efficiency. Considering the redundancy in natural\nlanguage, existing approaches compress prompts by removing tokens or lexical\nunits according to their information entropy obtained from a causal language\nmodel such as LLaMa-7B. The challenge is that information entropy may be a\nsuboptimal compression metric: (i) it only leverages unidirectional context and\nmay fail to capture all essential information needed for prompt compression;\n(ii) it is not aligned with the prompt compression objective.\n  To address these issues, we propose a data distillation procedure to derive\nknowledge from an LLM to compress prompts without losing crucial information,\nand meantime, introduce an extractive text compression dataset. We formulate\nprompt compression as a token classification problem to guarantee the\nfaithfulness of the compressed prompt to the original one, and use a\nTransformer encoder as the base architecture to capture all essential\ninformation for prompt compression from the full bidirectional context. Our\napproach leads to lower latency by explicitly learning the compression\nobjective with smaller models such as XLM-RoBERTa-large and mBERT.\n  We evaluate our method on both in-domain and out-of-domain datasets,\nincluding MeetingBank, LongBench, ZeroScrolls, GSM8K, and BBH. Despite its\nsmall size, our model shows significant performance gains over strong baselines\nand demonstrates robust generalization ability across different LLMs.\nAdditionally, our model is 3x-6x faster than existing prompt compression\nmethods, while accelerating the end-to-end latency by 1.6x-2.9x with\ncompression ratios of 2x-5x. Our code is available at\nhttps://aka.ms/LLMLingua-2.", "published": "2024-03-19 17:59:56", "link": "http://arxiv.org/abs/2403.12968v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "BiLoRA: A Bi-level Optimization Framework for Overfitting-Resilient\n  Low-Rank Adaptation of Large Pre-trained Models", "abstract": "Low-rank adaptation (LoRA) is a popular method for fine-tuning large-scale\npre-trained models in downstream tasks by learning low-rank incremental\nmatrices. Though LoRA and its variants effectively reduce the number of\ntrainable parameters compared to full fine-tuning methods, they often overfit\ntraining data, resulting in sub-optimal generalization on test data. To address\nthis problem, we introduce BiLoRA, an overfitting-alleviating fine-tuning\napproach based on bi-level optimization (BLO). BiLoRA employs pseudo singular\nvalue decomposition to parameterize low-rank incremental matrices and splits\nthe training of pseudo singular vectors and values across two different subsets\nof training data. This division, embedded within separate levels of the BLO\nframework, mitigates the risk of overfitting to a single dataset. Tested on ten\ndatasets covering natural language understanding and generation tasks and\napplied to various well-known large pre-trained models, BiLoRA significantly\noutperforms LoRA methods and other fine-tuning approaches, with similar amounts\nof trainable parameters.", "published": "2024-03-19 14:11:20", "link": "http://arxiv.org/abs/2403.13037v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "WoLF: Wide-scope Large Language Model Framework for CXR Understanding", "abstract": "Significant methodological strides have been made toward Chest X-ray (CXR)\nunderstanding via modern vision-language models (VLMs), demonstrating\nimpressive Visual Question Answering (VQA) and CXR report generation abilities.\nHowever, existing CXR understanding frameworks still possess several procedural\ncaveats. (1) Previous methods solely use CXR reports, which are insufficient\nfor comprehensive Visual Question Answering (VQA), especially when additional\nhealth-related data like medication history and prior diagnoses are needed. (2)\nPrevious methods use raw CXR reports, which are often arbitrarily structured.\nWhile modern language models can understand various text formats, restructuring\nreports for clearer, organized anatomy-based information could enhance their\nusefulness. (3) Current evaluation methods for CXR-VQA primarily emphasize\nlinguistic correctness, lacking the capability to offer nuanced assessments of\nthe generated answers. In this work, to address the aforementioned caveats, we\nintroduce WoLF, a Wide-scope Large Language Model Framework for CXR\nunderstanding. To resolve (1), we capture multi-faceted records of patients,\nwhich are utilized for accurate diagnoses in real-world clinical scenarios.\nSpecifically, we adopt the Electronic Health Records (EHR) to generate\ninstruction-following data suited for CXR understanding. Regarding (2), we\nenhance report generation performance by decoupling knowledge in CXR reports\nbased on anatomical structure even within the attention step via masked\nattention. To address (3), we introduce an AI-evaluation protocol optimized for\nassessing the capabilities of LLM. Through extensive experimental validations,\nWoLF demonstrates superior performance over other models on MIMIC-CXR in the\nAI-evaluation arena about VQA (up to +9.47%p mean score) and by metrics about\nreport generation (+7.3%p BLEU-1).", "published": "2024-03-19 06:39:23", "link": "http://arxiv.org/abs/2403.15456v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Fine-Tuning Pre-trained Language Models to Detect In-Game Trash Talks", "abstract": "Common problems in playing online mobile and computer games were related to\ntoxic behavior and abusive communication among players. Based on different\nreports and studies, the study also discusses the impact of online hate speech\nand toxicity on players' in-game performance and overall well-being. This study\ninvestigates the capability of pre-trained language models to classify or\ndetect trash talk or toxic in-game messages The study employs and evaluates the\nperformance of pre-trained BERT and GPT language models in detecting toxicity\nwithin in-game chats. Using publicly available APIs, in-game chat data from\nDOTA 2 game matches were collected, processed, reviewed, and labeled as\nnon-toxic, mild (toxicity), and toxic. The study was able to collect around two\nthousand in-game chats to train and test BERT (Base-uncased), BERT\n(Large-uncased), and GPT-3 models. Based on the three models' state-of-the-art\nperformance, this study concludes pre-trained language models' promising\npotential for addressing online hate speech and in-game insulting trash talk.", "published": "2024-03-19 11:36:53", "link": "http://arxiv.org/abs/2403.15458v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An Empirical Study of Speech Language Models for Prompt-Conditioned\n  Speech Synthesis", "abstract": "Speech language models (LMs) are promising for high-quality speech synthesis\nthrough in-context learning. A typical speech LM takes discrete semantic units\nas content and a short utterance as prompt, and synthesizes speech which\npreserves the content's semantics but mimics the prompt's style. However, there\nis no systematic understanding on how the synthesized audio is controlled by\nthe prompt and content. In this work, we conduct an empirical study of the\nwidely used autoregressive (AR) and non-autoregressive (NAR) speech LMs and\nprovide insights into the prompt design and content semantic units. Our\nanalysis reveals that heterogeneous and nonstationary prompts hurt the audio\nquality in contrast to the previous finding that longer prompts always lead to\nbetter synthesis. Moreover, we find that the speaker style of the synthesized\naudio is also affected by the content in addition to the prompt. We further\nshow that semantic units carry rich acoustic information such as pitch, tempo,\nvolume and speech emphasis, which might be leaked from the content to the\nsynthesized audio.", "published": "2024-03-19 03:22:28", "link": "http://arxiv.org/abs/2403.12402v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Towards Interpretable Hate Speech Detection using Large Language\n  Model-extracted Rationales", "abstract": "Although social media platforms are a prominent arena for users to engage in\ninterpersonal discussions and express opinions, the facade and anonymity\noffered by social media may allow users to spew hate speech and offensive\ncontent. Given the massive scale of such platforms, there arises a need to\nautomatically identify and flag instances of hate speech. Although several hate\nspeech detection methods exist, most of these black-box methods are not\ninterpretable or explainable by design. To address the lack of\ninterpretability, in this paper, we propose to use state-of-the-art Large\nLanguage Models (LLMs) to extract features in the form of rationales from the\ninput text, to train a base hate speech classifier, thereby enabling faithful\ninterpretability by design. Our framework effectively combines the textual\nunderstanding capabilities of LLMs and the discriminative power of\nstate-of-the-art hate speech classifiers to make these classifiers faithfully\ninterpretable. Our comprehensive evaluation on a variety of English language\nsocial media hate speech datasets demonstrate: (1) the goodness of the\nLLM-extracted rationales, and (2) the surprising retention of detector\nperformance even after training to ensure interpretability. All code and data\nwill be made available at https://github.com/AmritaBh/shield.", "published": "2024-03-19 03:22:35", "link": "http://arxiv.org/abs/2403.12403v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MSLM-S2ST: A Multitask Speech Language Model for Textless\n  Speech-to-Speech Translation with Speaker Style Preservation", "abstract": "There have been emerging research interest and advances in speech-to-speech\ntranslation (S2ST), translating utterances from one language to another. This\nwork proposes Multitask Speech Language Model (MSLM), which is a decoder-only\nspeech language model trained in a multitask setting. Without reliance on text\ntraining data, our model is able to support multilingual S2ST with speaker\nstyle preserved.", "published": "2024-03-19 03:35:20", "link": "http://arxiv.org/abs/2403.12408v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Embodied LLM Agents Learn to Cooperate in Organized Teams", "abstract": "Large Language Models (LLMs) have emerged as integral tools for reasoning,\nplanning, and decision-making, drawing upon their extensive world knowledge and\nproficiency in language-related tasks. LLMs thus hold tremendous potential for\nnatural language interaction within multi-agent systems to foster cooperation.\nHowever, LLM agents tend to over-report and comply with any instruction, which\nmay result in information redundancy and confusion in multi-agent cooperation.\nInspired by human organizations, this paper introduces a framework that imposes\nprompt-based organization structures on LLM agents to mitigate these problems.\nThrough a series of experiments with embodied LLM agents and human-agent\ncollaboration, our results highlight the impact of designated leadership on\nteam efficiency, shedding light on the leadership qualities displayed by LLM\nagents and their spontaneous cooperative behaviors. Further, we harness the\npotential of LLMs to propose enhanced organizational prompts, via a\nCriticize-Reflect process, resulting in novel organization structures that\nreduce communication costs and enhance team efficiency.", "published": "2024-03-19 06:39:47", "link": "http://arxiv.org/abs/2403.12482v2", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Toward Sustainable GenAI using Generation Directives for Carbon-Friendly\n  Large Language Model Inference", "abstract": "The rapid advancement of Generative Artificial Intelligence (GenAI) across\ndiverse sectors raises significant environmental concerns, notably the carbon\nemissions from their cloud and high performance computing (HPC) infrastructure.\nThis paper presents Sprout, an innovative framework designed to address these\nconcerns by reducing the carbon footprint of generative Large Language Model\n(LLM) inference services. Sprout leverages the innovative concept of\n\"generation directives\" to guide the autoregressive generation process, thereby\nenhancing carbon efficiency. Our proposed method meticulously balances the need\nfor ecological sustainability with the demand for high-quality generation\noutcomes. Employing a directive optimizer for the strategic assignment of\ngeneration directives to user prompts and an original offline quality\nevaluator, Sprout demonstrates a significant reduction in carbon emissions by\nover 40% in real-world evaluations using the Llama2 LLM and global electricity\ngrid data. This research marks a critical step toward aligning AI technology\nwith sustainable practices, highlighting the potential for mitigating\nenvironmental impacts in the rapidly expanding domain of generative artificial\nintelligence.", "published": "2024-03-19 16:53:53", "link": "http://arxiv.org/abs/2403.12900v1", "categories": ["cs.DC", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.DC"}
{"title": "Generalizable and Stable Finetuning of Pretrained Language Models on\n  Low-Resource Texts", "abstract": "Pretrained Language Models (PLMs) have advanced Natural Language Processing\n(NLP) tasks significantly, but finetuning PLMs on low-resource datasets poses\nsignificant challenges such as instability and overfitting. Previous methods\ntackle these issues by finetuning a strategically chosen subnetwork on a\ndownstream task, while keeping the remaining weights fixed to the pretrained\nweights. However, they rely on a suboptimal criteria for sub-network selection,\nleading to suboptimal solutions. To address these limitations, we propose a\nregularization method based on attention-guided weight mixup for finetuning\nPLMs. Our approach represents each network weight as a mixup of task-specific\nweight and pretrained weight, controlled by a learnable attention parameter,\nproviding finer control over sub-network selection. Furthermore, we employ a\nbi-level optimization (BLO) based framework on two separate splits of the\ntraining dataset, improving generalization and combating overfitting. We\nvalidate the efficacy of our proposed method through extensive experiments,\ndemonstrating its superiority over previous methods, particularly in the\ncontext of finetuning PLMs on low-resource datasets.", "published": "2024-03-19 17:21:29", "link": "http://arxiv.org/abs/2403.12918v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "RigorLLM: Resilient Guardrails for Large Language Models against\n  Undesired Content", "abstract": "Recent advancements in Large Language Models (LLMs) have showcased remarkable\ncapabilities across various tasks in different domains. However, the emergence\nof biases and the potential for generating harmful content in LLMs,\nparticularly under malicious inputs, pose significant challenges. Current\nmitigation strategies, while effective, are not resilient under adversarial\nattacks. This paper introduces Resilient Guardrails for Large Language Models\n(RigorLLM), a novel framework designed to efficiently and effectively moderate\nharmful and unsafe inputs and outputs for LLMs. By employing a multi-faceted\napproach that includes energy-based training data augmentation through Langevin\ndynamics, optimizing a safe suffix for inputs via minimax optimization, and\nintegrating a fusion-based model combining robust KNN with LLMs based on our\ndata augmentation, RigorLLM offers a robust solution to harmful content\nmoderation. Our experimental evaluations demonstrate that RigorLLM not only\noutperforms existing baselines like OpenAI API and Perspective API in detecting\nharmful content but also exhibits unparalleled resilience to jailbreaking\nattacks. The innovative use of constrained optimization and a fusion-based\nguardrail approach represents a significant step forward in developing more\nsecure and reliable LLMs, setting a new standard for content moderation\nframeworks in the face of evolving digital threats.", "published": "2024-03-19 07:25:02", "link": "http://arxiv.org/abs/2403.13031v2", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Knowing Your Nonlinearities: Shapley Interactions Reveal the Underlying\n  Structure of Data", "abstract": "Measuring nonlinear feature interaction is an established approach to\nunderstanding complex patterns of attribution in many models. In this paper, we\nuse Shapley Taylor interaction indices (STII) to analyze the impact of\nunderlying data structure on model representations in a variety of modalities,\ntasks, and architectures. Considering linguistic structure in masked and\nauto-regressive language models (MLMs and ALMs), we find that STII increases\nwithin idiomatic expressions and that MLMs scale STII with syntactic distance,\nrelying more on syntax in their nonlinear structure than ALMs do. Our speech\nmodel findings reflect the phonetic principal that the openness of the oral\ncavity determines how much a phoneme varies based on its context. Finally, we\nstudy image classifiers and illustrate that feature interactions intuitively\nreflect object boundaries. Our wide range of results illustrates the benefits\nof interdisciplinary work and domain expertise in interpretability research.", "published": "2024-03-19 19:13:22", "link": "http://arxiv.org/abs/2403.13106v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Towards Unsupervised Question Answering System with Multi-level\n  Summarization for Legal Text", "abstract": "This paper summarizes Team SCaLAR's work on SemEval-2024 Task 5: Legal\nArgument Reasoning in Civil Procedure. To address this Binary Classification\ntask, which was daunting due to the complexity of the Legal Texts involved, we\npropose a simple yet novel similarity and distance-based unsupervised approach\nto generate labels. Further, we explore the Multi-level fusion of Legal-Bert\nembeddings using ensemble features, including CNN, GRU, and LSTM. To address\nthe lengthy nature of Legal explanation in the dataset, we introduce T5-based\nsegment-wise summarization, which successfully retained crucial information,\nenhancing the model's performance. Our unsupervised system witnessed a 20-point\nincrease in macro F1-score on the development set and a 10-point increase on\nthe test set, which is promising given its uncomplicated architecture.", "published": "2024-03-19 19:15:13", "link": "http://arxiv.org/abs/2403.13107v2", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Self-generated Replay Memories for Continual Neural Machine Translation", "abstract": "Modern Neural Machine Translation systems exhibit strong performance in\nseveral different languages and are constantly improving. Their ability to\nlearn continuously is, however, still severely limited by the catastrophic\nforgetting issue. In this work, we leverage a key property of encoder-decoder\nTransformers, i.e. their generative ability, to propose a novel approach to\ncontinually learning Neural Machine Translation systems. We show how this can\neffectively learn on a stream of experiences comprising different languages, by\nleveraging a replay memory populated by using the model itself as a generator\nof parallel sentences. We empirically demonstrate that our approach can\ncounteract catastrophic forgetting without requiring explicit memorization of\ntraining data. Code will be publicly available upon publication. Code:\nhttps://github.com/m-resta/sg-rep", "published": "2024-03-19 19:59:54", "link": "http://arxiv.org/abs/2403.13130v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach\n  Combining Predictive Agent Reasoning and Critical Agent Instruction", "abstract": "Electronic health records (EHRs) contain valuable patient data for\nhealth-related prediction tasks, such as disease prediction. Traditional\napproaches rely on supervised learning methods that require large labeled\ndatasets, which can be expensive and challenging to obtain. In this study, we\ninvestigate the feasibility of applying Large Language Models (LLMs) to convert\nstructured patient visit data (e.g., diagnoses, labs, prescriptions) into\nnatural language narratives. We evaluate the zero-shot and few-shot performance\nof LLMs using various EHR-prediction-oriented prompting strategies.\nFurthermore, we propose a novel approach that utilizes LLM agents with\ndifferent roles: a predictor agent that makes predictions and generates\nreasoning processes and a critic agent that analyzes incorrect predictions and\nprovides guidance for improving the reasoning of the predictor agent. Our\nresults demonstrate that with the proposed approach, LLMs can achieve decent\nfew-shot performance compared to traditional supervised learning methods in\nEHR-based disease predictions, suggesting its potential for health-oriented\napplications.", "published": "2024-03-19 18:10:13", "link": "http://arxiv.org/abs/2403.15464v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA", "J.3; I.2.7"], "primary_category": "cs.CL"}
{"title": "A Big Data Analytics System for Predicting Suicidal Ideation in\n  Real-Time Based on Social Media Streaming Data", "abstract": "Online social media platforms have recently become integral to our society\nand daily routines. Every day, users worldwide spend a couple of hours on such\nplatforms, expressing their sentiments and emotional state and contacting each\nother. Analyzing such huge amounts of data from these platforms can provide a\nclear insight into public sentiments and help detect their mental status. The\nearly identification of these health condition risks may assist in preventing\nor reducing the number of suicide ideation and potentially saving people's\nlives. The traditional techniques have become ineffective in processing such\nstreams and large-scale datasets. Therefore, the paper proposed a new\nmethodology based on a big data architecture to predict suicidal ideation from\nsocial media content. The proposed approach provides a practical analysis of\nsocial media data in two phases: batch processing and real-time streaming\nprediction. The batch dataset was collected from the Reddit forum and used for\nmodel building and training, while streaming big data was extracted using\nTwitter streaming API and used for real-time prediction. After the raw data was\npreprocessed, the extracted features were fed to multiple Apache Spark ML\nclassifiers: NB, LR, LinearSVC, DT, RF, and MLP. We conducted various\nexperiments using various feature-extraction techniques with different testing\nscenarios. The experimental results of the batch processing phase showed that\nthe features extracted of (Unigram + Bigram) + CV-IDF with MLP classifier\nprovided high performance for classifying suicidal ideation, with an accuracy\nof 93.47%, and then applied for real-time streaming prediction phase.", "published": "2024-03-19 21:46:52", "link": "http://arxiv.org/abs/2404.12394v1", "categories": ["cs.LG", "cs.CL", "cs.SI"], "primary_category": "cs.LG"}
{"title": "Most Likely Sequence Generation for $n$-Grams, Transformers, HMMs, and\n  Markov Chains, by Using Rollout Algorithms", "abstract": "In this paper we consider a transformer with an $n$-gram structure, such as\nthe one underlying ChatGPT. The transformer provides next word probabilities,\nwhich can be used to generate word sequences. We consider methods for computing\nword sequences that are highly likely, based on these probabilities. Computing\nthe optimal (i.e., most likely) word sequence starting with a given initial\nstate is an intractable problem, so we propose methods to compute highly likely\nsequences of $N$ words in time that is a low order polynomial in $N$ and in the\nvocabulary size of the $n$-gram. These methods are based on the rollout\napproach from approximate dynamic programming, a form of single policy\niteration, which can improve the performance of any given heuristic policy. In\nour case we use a greedy heuristic that generates as next word one that has the\nhighest probability. We show with analysis, examples, and computational\nexperimentation that our methods are capable of generating highly likely\nsequences with a modest increase in computation over the greedy heuristic.\nWhile our analysis and experiments are focused on Markov chains of the type\narising in transformer and ChatGPT-like models, our methods apply to general\nfinite-state Markov chains, and related inference applications of Hidden Markov\nModels (HMM), where Viterbi decoding is used extensively.", "published": "2024-03-19 19:58:46", "link": "http://arxiv.org/abs/2403.15465v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "Real-time Speech Extraction Using Spatially Regularized Independent\n  Low-rank Matrix Analysis and Rank-constrained Spatial Covariance Matrix\n  Estimation", "abstract": "Real-time speech extraction is an important challenge with various\napplications such as speech recognition in a human-like avatar/robot. In this\npaper, we propose the real-time extension of a speech extraction method based\non independent low-rank matrix analysis (ILRMA) and rank-constrained spatial\ncovariance matrix estimation (RCSCME). The RCSCME-based method is a\nmultichannel blind speech extraction method that demonstrates superior speech\nextraction performance in diffuse noise environments. To improve the\nperformance, we introduce spatial regularization into the ILRMA part of the\nRCSCME-based speech extraction and design two regularizers. Speech extraction\nexperiments demonstrated that the proposed methods can function in real time\nand the designed regularizers improve the speech extraction performance.", "published": "2024-03-19 06:27:47", "link": "http://arxiv.org/abs/2403.12477v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Reproducing the Acoustic Velocity Vectors in a Circular Listening Area", "abstract": "Acoustic velocity vectors are important for human's localization of sound at\nlow frequencies. This paper proposes a sound field reproduction algorithm,\nwhich matches the acoustic velocity vectors in a circular listening area. In\nprevious work, acoustic velocity vectors are matched either at sweet spots or\non the boundary of the listening area. Methods based on sweet spots experience\nperformance degradation when the listener moves away from sweet spots, whereas\nmeasuring the acoustic velocity vectors on the boundary requires complicated\nmeasurement setup. This paper proposes the radial independent cylindrical\nharmonic coefficients of the acoustic velocity vectors (CHV-indR coefficients)\nin the circular listening area, which are calculated from the cylindrical\nharmonic coefficients of the pressure in the circular listening area by using\nthe sound field translation formula. The cylindrical harmonic coefficients of\nthe pressure can be measured by a circular microphone array, which can be\nbought off-the-shelf. By matching the CHV-indR coefficients, the acoustic\nvelocity vectors are reproduced throughout the listening area. Simulations show\nthat at low frequencies, where the acoustic velocity vectors are the dominant\nfactor for localization, the proposed reproduction method based on matching the\nCHV-indR coefficients results in higher accuracy in reproduced acoustic\nvelocity vectors when compared with traditional method based on matching the\ncylindrical harmonic coefficients of the pressure.", "published": "2024-03-19 10:57:17", "link": "http://arxiv.org/abs/2403.12630v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Multimodal Fusion Method with Spatiotemporal Sequences and Relationship\n  Learning for Valence-Arousal Estimation", "abstract": "This paper presents our approach for the VA (Valence-Arousal) estimation task\nin the ABAW6 competition. We devised a comprehensive model by preprocessing\nvideo frames and audio segments to extract visual and audio features. Through\nthe utilization of Temporal Convolutional Network (TCN) modules, we effectively\ncaptured the temporal and spatial correlations between these features.\nSubsequently, we employed a Transformer encoder structure to learn long-range\ndependencies, thereby enhancing the model's performance and generalization\nability. Our method leverages a multimodal data fusion approach, integrating\npre-trained audio and video backbones for feature extraction, followed by\nTCN-based spatiotemporal encoding and Transformer-based temporal information\ncapture. Experimental results demonstrate the effectiveness of our approach,\nachieving competitive performance in VA estimation on the AffWild2 dataset.", "published": "2024-03-19 04:25:54", "link": "http://arxiv.org/abs/2403.12425v2", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Listenable Maps for Audio Classifiers", "abstract": "Despite the impressive performance of deep learning models across diverse\ntasks, their complexity poses challenges for interpretation. This challenge is\nparticularly evident for audio signals, where conveying interpretations becomes\ninherently difficult. To address this issue, we introduce Listenable Maps for\nAudio Classifiers (L-MAC), a posthoc interpretation method that generates\nfaithful and listenable interpretations. L-MAC utilizes a decoder on top of a\npretrained classifier to generate binary masks that highlight relevant portions\nof the input audio. We train the decoder with a loss function that maximizes\nthe confidence of the classifier decision on the masked-in portion of the audio\nwhile minimizing the probability of model output for the masked-out portion.\nQuantitative evaluations on both in-domain and out-of-domain data demonstrate\nthat L-MAC consistently produces more faithful interpretations than several\ngradient and masking-based methodologies. Furthermore, a user study confirms\nthat, on average, users prefer the interpretations generated by the proposed\ntechnique.", "published": "2024-03-19 18:32:48", "link": "http://arxiv.org/abs/2403.13086v3", "categories": ["cs.SD", "cs.LG", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
