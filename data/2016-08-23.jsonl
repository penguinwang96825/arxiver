{"title": "Towards Machine Comprehension of Spoken Content: Initial TOEFL Listening\n  Comprehension Test by Machine", "abstract": "Multimedia or spoken content presents more attractive information than plain\ntext content, but it's more difficult to display on a screen and be selected by\na user. As a result, accessing large collections of the former is much more\ndifficult and time-consuming than the latter for humans. It's highly attractive\nto develop a machine which can automatically understand spoken content and\nsummarize the key information for humans to browse over. In this endeavor, we\npropose a new task of machine comprehension of spoken content. We define the\ninitial goal as the listening comprehension test of TOEFL, a challenging\nacademic English examination for English learners whose native language is not\nEnglish. We further propose an Attention-based Multi-hop Recurrent Neural\nNetwork (AMRNN) architecture for this task, achieving encouraging results in\nthe initial tests. Initial results also have shown that word-level attention is\nprobably more robust than sentence-level attention for this task with ASR\nerrors.", "published": "2016-08-23 04:27:41", "link": "http://arxiv.org/abs/1608.06378v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Which techniques does your application use?: An information extraction\n  framework for scientific articles", "abstract": "Every field of research consists of multiple application areas with various\ntechniques routinely used to solve problems in these wide range of application\nareas. With the exponential growth in research volumes, it has become difficult\nto keep track of the ever-growing number of application areas as well as the\ncorresponding problem solving techniques. In this paper, we consider the\ncomputational linguistics domain and present a novel information extraction\nsystem that automatically constructs a pool of all application areas in this\ndomain and appropriately links them with corresponding problem solving\ntechniques. Further, we categorize individual research articles based on their\napplication area and the techniques proposed/used in the article. k-gram based\ndiscounting method along with handwritten rules and bootstrapped pattern\nlearning is employed to extract application areas. Subsequently, a language\nmodeling approach is proposed to characterize each article based on its\napplication area. Similarly, regular expressions and high-scoring noun phrases\nare used for the extraction of the problem solving techniques. We propose a\ngreedy approach to characterize each article based on the techniques. Towards\nthe end, we present a table representing the most frequent techniques adopted\nfor a particular application area. Finally, we propose three use cases\npresenting an extensive temporal analysis of the usage of techniques and\napplication areas.", "published": "2016-08-23 05:27:46", "link": "http://arxiv.org/abs/1608.06386v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tracking Amendments to Legislation and Other Political Texts with a\n  Novel Minimum-Edit-Distance Algorithm: DocuToads", "abstract": "Political scientists often find themselves tracking amendments to political\ntexts. As different actors weigh in, texts change as they are drafted and\nredrafted, reflecting political preferences and power. This study provides a\nnovel solution to the prob- lem of detecting amendments to political text based\nupon minimum edit distances. We demonstrate the usefulness of two\nlanguage-insensitive, transparent, and efficient minimum-edit-distance\nalgorithms suited for the task. These algorithms are capable of providing an\naccount of the types (insertions, deletions, substitutions, and trans-\npositions) and substantive amount of amendments made between version of texts.\nTo illustrate the usefulness and efficiency of the approach we replicate two\nexisting stud- ies from the field of legislative studies. Our results\ndemonstrate that minimum edit distance methods can produce superior measures of\ntext amendments to hand-coded efforts in a fraction of the time and resource\ncosts.", "published": "2016-08-23 10:55:23", "link": "http://arxiv.org/abs/1608.06459v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Using Semantic Similarity for Input Topic Identification in\n  Crawling-based Web Application Testing", "abstract": "To automatically test web applications, crawling-based techniques are usually\nadopted to mine the behavior models, explore the state spaces or detect the\nviolated invariants of the applications. However, in existing crawlers, rules\nfor identifying the topics of input text fields, such as login ids, passwords,\nemails, dates and phone numbers, have to be manually configured. Moreover, the\nrules for one application are very often not suitable for another. In addition,\nwhen several rules conflict and match an input text field to more than one\ntopics, it can be difficult to determine which rule suggests a better match.\nThis paper presents a natural-language approach to automatically identify the\ntopics of encountered input fields during crawling by semantically comparing\ntheir similarities with the input fields in labeled corpus. In our evaluation\nwith 100 real-world forms, the proposed approach demonstrated comparable\nperformance to the rule-based one. Our experiments also show that the accuracy\nof the rule-based approach can be improved by up to 19% when integrated with\nour approach.", "published": "2016-08-23 15:34:55", "link": "http://arxiv.org/abs/1608.06549v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Lexical Query Modeling in Session Search", "abstract": "Lexical query modeling has been the leading paradigm for session search. In\nthis paper, we analyze TREC session query logs and compare the performance of\ndifferent lexical matching approaches for session search. Naive methods based\non term frequency weighing perform on par with specialized session models. In\naddition, we investigate the viability of lexical query models in the setting\nof session search. We give important insights into the potential and\nlimitations of lexical query modeling for session search and propose future\ndirections for the field of session search.", "published": "2016-08-23 21:07:50", "link": "http://arxiv.org/abs/1608.06656v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Unsupervised, Efficient and Semantic Expertise Retrieval", "abstract": "We introduce an unsupervised discriminative model for the task of retrieving\nexperts in online document collections. We exclusively employ textual evidence\nand avoid explicit feature engineering by learning distributed word\nrepresentations in an unsupervised way. We compare our model to\nstate-of-the-art unsupervised statistical vector space and probabilistic\ngenerative approaches. Our proposed log-linear model achieves the retrieval\nperformance levels of state-of-the-art document-centric methods with the low\ninference cost of so-called profile-centric approaches. It yields a\nstatistically significant improved ranking over vector space and generative\nmodels in most cases, matching the performance of supervised methods on various\nbenchmarks. That is, by using solely text we can do as well as methods that\nwork with external evidence and/or relevance feedback. A contrastive analysis\nof rankings produced by discriminative and generative approaches shows that\nthey have complementary strengths due to the ability of the unsupervised\ndiscriminative model to perform semantic matching.", "published": "2016-08-23 20:55:09", "link": "http://arxiv.org/abs/1608.06651v2", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
