{"title": "Subtractive mountain clustering algorithm applied to a chatbot to assist\n  elderly people in medication intake", "abstract": "Errors in medication intake among elderly people are very common. One of the\nmain causes for this is their loss of ability to retain information. The high\namount of medicine intake required by the advanced age is another limiting\nfactor. Thence, the design of an interactive aid system, preferably using\nnatural language, to help the older population with medication is in demand. A\nchatbot based on a subtractive cluster algorithm, included in unsupervised\nlearned models, is the chosen solution since the processing of natural\nlanguages is a necessary step in view to construct a chatbot able to answer\nquestions that older people may pose upon themselves concerning a particular\ndrug. In this work, the subtractive mountain clustering algorithm has been\nadapted to the problem of natural languages processing. This algorithm version\nallows for the association of a set of words into clusters. After finding the\ncentre of every cluster -- the most relevant word, all the others are\naggregated according to a defined metric adapted to the language processing\nrealm. All the relevant stored information is processed, as well as the\nquestions, by the algorithm. The correct processing of the text enables the\nchatbot to produce answers that relate to the posed queries. To validate the\nmethod, we use the package insert of a drug as the available information and\nformulate associated questions.", "published": "2021-10-03 06:16:01", "link": "http://arxiv.org/abs/2110.00933v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unified Likelihood Ratio Estimation for High- to Zero-frequency N-grams", "abstract": "Likelihood ratios (LRs), which are commonly used for probabilistic data\nprocessing, are often estimated based on the frequency counts of individual\nelements obtained from samples. In natural language processing, an element can\nbe a continuous sequence of $N$ items, called an $N$-gram, in which each item\nis a word, letter, etc. In this paper, we attempt to estimate LRs based on\n$N$-gram frequency information. A naive estimation approach that uses only\n$N$-gram frequencies is sensitive to low-frequency (rare) $N$-grams and not\napplicable to zero-frequency (unobserved) $N$-grams; these are known as the\nlow- and zero-frequency problems, respectively. To address these problems, we\npropose a method for decomposing $N$-grams into item units and then applying\ntheir frequencies along with the original $N$-gram frequencies. Our method can\nobtain the estimates of unobserved $N$-grams by using the unit frequencies.\nAlthough using only unit frequencies ignores dependencies between items, our\nmethod takes advantage of the fact that certain items often co-occur in\npractice and therefore maintains their dependencies by using the relevant\n$N$-gram frequencies. We also introduce a regularization to achieve robust\nestimation for rare $N$-grams. Our experimental results demonstrate that our\nmethod is effective at solving both problems and can effectively control\ndependencies.", "published": "2021-10-03 07:44:16", "link": "http://arxiv.org/abs/2110.00946v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LexGLUE: A Benchmark Dataset for Legal Language Understanding in English", "abstract": "Laws and their interpretations, legal arguments and agreements\\ are typically\nexpressed in writing, leading to the production of vast corpora of legal text.\nTheir analysis, which is at the center of legal practice, becomes increasingly\nelaborate as these collections grow in size. Natural language understanding\n(NLU) technologies can be a valuable tool to support legal practitioners in\nthese endeavors. Their usefulness, however, largely depends on whether current\nstate-of-the-art models can generalize across various tasks in the legal\ndomain. To answer this currently open question, we introduce the Legal General\nLanguage Understanding Evaluation (LexGLUE) benchmark, a collection of datasets\nfor evaluating model performance across a diverse set of legal NLU tasks in a\nstandardized way. We also provide an evaluation and analysis of several generic\nand legal-oriented models demonstrating that the latter consistently offer\nperformance improvements across multiple tasks.", "published": "2021-10-03 10:50:51", "link": "http://arxiv.org/abs/2110.00976v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Project Debater APIs: Decomposing the AI Grand Challenge", "abstract": "Project Debater was revealed in 2019 as the first AI system that can debate\nhuman experts on complex topics. Engaging in a live debate requires a diverse\nset of skills, and Project Debater has been developed accordingly as a\ncollection of components, each designed to perform a specific subtask. Project\nDebater APIs provide access to many of these capabilities, as well as to more\nrecently developed ones. This diverse set of web services, publicly available\nfor academic use, includes core NLP services, argument mining and analysis\ncapabilities, and higher-level services for content summarization. We describe\nthese APIs and their performance, and demonstrate how they can be used for\nbuilding practical solutions. In particular, we will focus on Key Point\nAnalysis, a novel technology that identifies the main points and their\nprevalence in a collection of texts such as survey responses and user reviews.", "published": "2021-10-03 15:50:32", "link": "http://arxiv.org/abs/2110.01029v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Document Keyphrase Extraction: Dataset, Baselines and Review", "abstract": "Keyphrase extraction has been extensively researched within the\nsingle-document setting, with an abundance of methods, datasets and\napplications. In contrast, multi-document keyphrase extraction has been\ninfrequently studied, despite its utility for describing sets of documents, and\nits use in summarization. Moreover, no prior dataset exists for multi-document\nkeyphrase extraction, hindering the progress of the task. Recent advances in\nmulti-text processing make the task an even more appealing challenge to pursue.\nTo stimulate this pursuit, we present here the first dataset for the task,\nMK-DUC-01, which can serve as a new benchmark, and test multiple keyphrase\nextraction baselines on our data. In addition, we provide a brief, yet\ncomprehensive, literature review of the task.", "published": "2021-10-03 19:10:28", "link": "http://arxiv.org/abs/2110.01073v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Understanding Persuasion in Computational Argumentation", "abstract": "Opinion formation and persuasion in argumentation are affected by three major\nfactors: the argument itself, the source of the argument, and the properties of\nthe audience. Understanding the role of each and the interplay between them is\ncrucial for obtaining insights regarding argument interpretation and\ngeneration. It is particularly important for building effective argument\ngeneration systems that can take both the discourse and the audience\ncharacteristics into account. Having such personalized argument generation\nsystems would be helpful to expose individuals to different viewpoints and help\nthem make a more fair and informed decision on an issue. Even though studies in\nSocial Sciences and Psychology have shown that source and audience effects are\nessential components of the persuasion process, most research in computational\npersuasion has focused solely on understanding the characteristics of\npersuasive language. In this thesis, we make several contributions to\nunderstand the relative effect of the source, audience, and language in\ncomputational persuasion. We first introduce a large-scale dataset with\nextensive user information to study these factors' effects simultaneously.\nThen, we propose models to understand the role of the audience's prior beliefs\non their perception of arguments. We also investigate the role of social\ninteractions and engagement in understanding users' success in online debating\nover time. We find that the users' prior beliefs and social interactions play\nan essential role in predicting their success in persuasion. Finally, we\nexplore the importance of incorporating contextual information to predict\nargument impact and show improvements compared to encoding only the text of the\narguments.", "published": "2021-10-03 19:36:21", "link": "http://arxiv.org/abs/2110.01078v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adversarial Examples Generation for Reducing Implicit Gender Bias in\n  Pre-trained Models", "abstract": "Over the last few years, Contextualized Pre-trained Neural Language Models,\nsuch as BERT, GPT, have shown significant gains in various NLP tasks. To\nenhance the robustness of existing pre-trained models, one way is adversarial\nexamples generation and evaluation for conducting data augmentation or\nadversarial learning. In the meanwhile, gender bias embedded in the models\nseems to be a serious problem in practical applications. Many researches have\ncovered the gender bias produced by word-level information(e.g.\ngender-stereotypical occupations), while few researchers have investigated the\nsentence-level cases and implicit cases.\n  In this paper, we proposed a method to automatically generate implicit gender\nbias samples at sentence-level and a metric to measure gender bias. Samples\ngenerated by our method will be evaluated in terms of accuracy. The metric will\nbe used to guide the generation of examples from Pre-trained models. Therefore,\nthose examples could be used to impose attacks on Pre-trained Models. Finally,\nwe discussed the evaluation efficacy of our generated examples on reducing\ngender bias for future research.", "published": "2021-10-03 20:22:54", "link": "http://arxiv.org/abs/2110.01094v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Probing Language Models for Understanding of Temporal Expressions", "abstract": "We present three Natural Language Inference (NLI) challenge sets that can\nevaluate NLI models on their understanding of temporal expressions. More\nspecifically, we probe these models for three temporal properties: (a) the\norder between points in time, (b) the duration between two points in time, (c)\nthe relation between the magnitude of times specified in different units. We\nfind that although large language models fine-tuned on MNLI have some basic\nperception of the order between points in time, at large, these models do not\nhave a thorough understanding of the relation between temporal expressions.", "published": "2021-10-03 22:38:31", "link": "http://arxiv.org/abs/2110.01113v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Simple Recurrent Neural Networks is all we need for clinical events\n  predictions using EHR data", "abstract": "Recently, there is great interest to investigate the application of deep\nlearning models for the prediction of clinical events using electronic health\nrecords (EHR) data. In EHR data, a patient's history is often represented as a\nsequence of visits, and each visit contains multiple events. As a result, deep\nlearning models developed for sequence modeling, like recurrent neural networks\n(RNNs) are common architecture for EHR-based clinical events predictive models.\nWhile a large variety of RNN models were proposed in the literature, it is\nunclear if complex architecture innovations will offer superior predictive\nperformance. In order to move this field forward, a rigorous evaluation of\nvarious methods is needed. In this study, we conducted a thorough benchmark of\nRNN architectures in modeling EHR data. We used two prediction tasks: the risk\nfor developing heart failure and the risk of early readmission for inpatient\nhospitalization. We found that simple gated RNN models, including GRUs and\nLSTMs, often offer competitive results when properly tuned with Bayesian\nOptimization, which is in line with similar to findings in the natural language\nprocessing (NLP) domain. For reproducibility, Our codebase is shared at\nhttps://github.com/ZhiGroup/pytorch_ehr.", "published": "2021-10-03 13:07:23", "link": "http://arxiv.org/abs/2110.00998v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Counterfactual Samples Synthesizing and Training for Robust Visual\n  Question Answering", "abstract": "Today's VQA models still tend to capture superficial linguistic correlations\nin the training set and fail to generalize to the test set with different QA\ndistributions. To reduce these language biases, recent VQA works introduce an\nauxiliary question-only model to regularize the training of targeted VQA model,\nand achieve dominating performance on diagnostic benchmarks for\nout-of-distribution testing. However, due to complex model design, these\nensemble-based methods are unable to equip themselves with two indispensable\ncharacteristics of an ideal VQA model: 1) Visual-explainable: The model should\nrely on the right visual regions when making decisions. 2) Question-sensitive:\nThe model should be sensitive to the linguistic variations in questions. To\nthis end, we propose a novel model-agnostic Counterfactual Samples Synthesizing\nand Training (CSST) strategy. After training with CSST, VQA models are forced\nto focus on all critical objects and words, which significantly improves both\nvisual-explainable and question-sensitive abilities. Specifically, CSST is\ncomposed of two parts: Counterfactual Samples Synthesizing (CSS) and\nCounterfactual Samples Training (CST). CSS generates counterfactual samples by\ncarefully masking critical objects in images or words in questions and\nassigning pseudo ground-truth answers. CST not only trains the VQA models with\nboth complementary samples to predict respective ground-truth answers, but also\nurges the VQA models to further distinguish the original samples and\nsuperficially similar counterfactual ones. To facilitate the CST training, we\npropose two variants of supervised contrastive loss for VQA, and design an\neffective positive and negative sample selection mechanism based on CSS.\nExtensive experiments have shown the effectiveness of CSST. Particularly, by\nbuilding on top of model LMH+SAR, we achieve record-breaking performance on all\nOOD benchmarks.", "published": "2021-10-03 14:31:46", "link": "http://arxiv.org/abs/2110.01013v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Multi-task Voice Activated Framework using Self-supervised Learning", "abstract": "Self-supervised learning methods such as wav2vec 2.0 have shown promising\nresults in learning speech representations from unlabelled and untranscribed\nspeech data that are useful for speech recognition. Since these representations\nare learned without any task-specific supervision, they can also be useful for\nother voice-activated tasks like speaker verification, keyword spotting,\nemotion classification etc. In our work, we propose a general purpose framework\nfor adapting a pre-trained wav2vec 2.0 model for different voice-activated\ntasks. We develop downstream network architectures that operate on the\ncontextualized speech representations of wav2vec 2.0 to adapt the\nrepresentations for solving a given task. Finally, we extend our framework to\nperform multi-task learning by jointly optimizing the network parameters on\nmultiple voice activated tasks using a shared transformer backbone. Both of our\nsingle and multi-task frameworks achieve state-of-the-art results in speaker\nverification and keyword spotting benchmarks. Our best performing models\nachieve 1.98% and 3.15% EER on VoxCeleb1 test set when trained on VoxCeleb2 and\nVoxCeleb1 respectively, and 98.23% accuracy on Google Speech Commands v1.0\nkeyword spotting dataset.", "published": "2021-10-03 19:28:57", "link": "http://arxiv.org/abs/2110.01077v3", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Music Playlist Title Generation: A Machine-Translation Approach", "abstract": "We propose a machine-translation approach to automatically generate a\nplaylist title from a set of music tracks. We take a sequence of track IDs as\ninput and a sequence of words in a playlist title as output, adapting the\nsequence-to-sequence framework based on Recurrent Neural Network (RNN) and\nTransformer to the music data. Considering the orderless nature of music tracks\nin a playlist, we propose two techniques that remove the order of the input\nsequence. One is data augmentation by shuffling and the other is deleting the\npositional encoding. We also reorganize the existing music playlist datasets to\ngenerate phrase-level playlist titles. The result shows that the Transformer\nmodels generally outperform the RNN model. Also, removing the order of input\nsequence improves the performance further.", "published": "2021-10-03 04:39:39", "link": "http://arxiv.org/abs/2110.07354v1", "categories": ["cs.LG", "cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Enriching Ontology with Temporal Commonsense for Low-Resource Audio\n  Tagging", "abstract": "Audio tagging aims at predicting sound events occurred in a recording.\nTraditional models require enormous laborious annotations, otherwise\nperformance degeneration will be the norm. Therefore, we investigate robust\naudio tagging models in low-resource scenarios with the enhancement of\nknowledge graphs. Besides existing ontological knowledge, we further propose a\nsemi-automatic approach that can construct temporal knowledge graphs on diverse\ndomain-specific label sets. Moreover, we leverage a variant of relation-aware\ngraph neural network, D-GCN, to combine the strength of the two knowledge\ntypes. Experiments on AudioSet and SONYC urban sound tagging datasets suggest\nthe effectiveness of the introduced temporal knowledge, and the advantage of\nthe combined KGs with D-GCN over single knowledge source.", "published": "2021-10-03 14:19:56", "link": "http://arxiv.org/abs/2110.01009v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "PL-EESR: Perceptual Loss Based END-TO-END Robust Speaker Representation\n  Extraction", "abstract": "Speech enhancement aims to improve the perceptual quality of the speech\nsignal by suppression of the background noise. However, excessive suppression\nmay lead to speech distortion and speaker information loss, which degrades the\nperformance of speaker embedding extraction. To alleviate this problem, we\npropose an end-to-end deep learning framework, dubbed PL-EESR, for robust\nspeaker representation extraction. This framework is optimized based on the\nfeedback of the speaker identification task and the high-level perceptual\ndeviation between the raw speech signal and its noisy version. We conducted\nspeaker verification tasks in both noisy and clean environment respectively to\nevaluate our system. Compared to the baseline, our method shows better\nperformance in both clean and noisy environments, which means our method can\nnot only enhance the speaker relative information but also avoid adding\ndistortions.", "published": "2021-10-03 07:05:29", "link": "http://arxiv.org/abs/2110.00940v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multimodal Fusion Based Attentive Networks for Sequential Music\n  Recommendation", "abstract": "Music has the power to evoke intense emotional experiences and regulate the\nmood of an individual. With the advent of online streaming services, research\nin music recommendation services has seen tremendous progress. Modern methods\nleveraging the listening histories of users for session-based song\nrecommendations have overlooked the significance of features extracted from\nlyrics and acoustic content. We address the task of song prediction through\nmultiple modalities, including tags, lyrics, and acoustic content. In this\npaper, we propose a novel deep learning approach by refining Attentive Neural\nNetworks using representations derived via a Transformer model for lyrics and\nVariational Autoencoder for acoustic features. Our model achieves significant\nimprovement in performance over existing state-of-the-art models using lyrical\nand acoustic features alone. Furthermore, we conduct a study to investigate the\nimpact of users' psychological health on our model's performance.", "published": "2021-10-03 13:24:00", "link": "http://arxiv.org/abs/2110.01001v1", "categories": ["cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
