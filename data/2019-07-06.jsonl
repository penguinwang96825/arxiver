{"title": "Exploiting Out-of-Domain Parallel Data through Multilingual Transfer\n  Learning for Low-Resource Neural Machine Translation", "abstract": "This paper proposes a novel multilingual multistage fine-tuning approach for\nlow-resource neural machine translation (NMT), taking a challenging\nJapanese--Russian pair for benchmarking. Although there are many solutions for\nlow-resource scenarios, such as multilingual NMT and back-translation, we have\nempirically confirmed their limited success when restricted to in-domain data.\nWe therefore propose to exploit out-of-domain data through transfer learning,\nby using it to first train a multilingual NMT model followed by multistage\nfine-tuning on in-domain parallel and back-translated pseudo-parallel data. Our\napproach, which combines domain adaptation, multilingualism, and\nback-translation, helps improve the translation quality by more than 3.7 BLEU\npoints, over a strong baseline, for this extremely low-resource scenario.", "published": "2019-07-06 02:14:30", "link": "http://arxiv.org/abs/1907.03060v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Short Text Conversation Based on Deep Neural Network and Analysis on\n  Evaluation Measures", "abstract": "With the development of Natural Language Processing, Automatic\nquestion-answering system such as Waston, Siri, Alexa, has become one of the\nmost important NLP applications. Nowadays, enterprises try to build automatic\ncustom service chatbots to save human resources and provide a 24-hour customer\nservice. Evaluation of chatbots currently relied greatly on human annotation\nwhich cost a plenty of time. Thus, has initiated a new Short Text Conversation\nsubtask called Dialogue Quality (DQ) and Nugget Detection (ND) which aim to\nautomatically evaluate dialogues generated by chatbots. In this paper, we solve\nthe DQ and ND subtasks by deep neural network. We proposed two models for both\nDQ and ND subtasks which is constructed by hierarchical structure: embedding\nlayer, utterance layer, context layer and memory layer, to hierarchical learn\ndialogue representation from word level, sentence level, context level to long\nrange context level. Furthermore, we apply gating and attention mechanism at\nutterance layer and context layer to improve the performance. We also tried\nBERT to replace embedding layer and utterance layer as sentence representation.\nThe result shows that BERT produced a better utterance representation than\nmulti-stack CNN for both DQ and ND subtasks and outperform other models\nproposed by other researches. The evaluation measures are proposed by , that\nis, NMD, RSNOD for DQ and JSD, RNSS for ND, which is not traditional evaluation\nmeasures such as accuracy, precision, recall and f1-score. Thus, we have done a\nseries of experiments by using traditional evaluation measures and analyze the\nperformance and error.", "published": "2019-07-06 03:58:04", "link": "http://arxiv.org/abs/1907.03070v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Best Practices for Learning Domain-Specific Cross-Lingual Embeddings", "abstract": "Cross-lingual embeddings aim to represent words in multiple languages in a\nshared vector space by capturing semantic similarities across languages. They\nare a crucial component for scaling tasks to multiple languages by transferring\nknowledge from languages with rich resources to low-resource languages. A\ncommon approach to learning cross-lingual embeddings is to train monolingual\nembeddings separately for each language and learn a linear projection from the\nmonolingual spaces into a shared space, where the mapping relies on a small\nseed dictionary. While there are high-quality generic seed dictionaries and\npre-trained cross-lingual embeddings available for many language pairs, there\nis little research on how they perform on specialised tasks. In this paper, we\ninvestigate the best practices for constructing the seed dictionary for a\nspecific domain. We evaluate the embeddings on the sequence labelling task of\nCurriculum Vitae parsing and show that the size of a bilingual dictionary, the\nfrequency of the dictionary words in the domain corpora and the source of data\n(task-specific vs generic) influence the performance. We also show that the\nless training data is available in the low-resource language, the more the\nconstruction of the bilingual dictionary matters, and demonstrate that some of\nthe choices are crucial in the zero-shot transfer learning case.", "published": "2019-07-06 10:45:45", "link": "http://arxiv.org/abs/1907.03112v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Applying a Pre-trained Language Model to Spanish Twitter Humor\n  Prediction", "abstract": "Our entry into the HAHA 2019 Challenge placed $3^{rd}$ in the classification\ntask and $2^{nd}$ in the regression task. We describe our system and\ninnovations, as well as comparing our results to a Naive Bayes baseline. A\nlarge Twitter based corpus allowed us to train a language model from scratch\nfocused on Spanish and transfer that knowledge to our competition model. To\novercome the inherent errors in some labels we reduce our class confidence with\nlabel smoothing in the loss function. All the code for our project is included\nin a GitHub repository for easy reference and to enable replication by others.", "published": "2019-07-06 21:05:54", "link": "http://arxiv.org/abs/1907.03187v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generating Sentences from Disentangled Syntactic and Semantic Spaces", "abstract": "Variational auto-encoders (VAEs) are widely used in natural language\ngeneration due to the regularization of the latent space. However, generating\nsentences from the continuous latent space does not explicitly model the\nsyntactic information. In this paper, we propose to generate sentences from\ndisentangled syntactic and semantic spaces. Our proposed method explicitly\nmodels syntactic information in the VAE's latent space by using the linearized\ntree sequence, leading to better performance of language generation.\nAdditionally, the advantage of sampling in the disentangled syntactic and\nsemantic latent spaces enables us to perform novel applications, such as the\nunsupervised paraphrase generation and syntax-transfer generation. Experimental\nresults show that our proposed model achieves similar or better performance in\nvarious tasks, compared with state-of-the-art related work.", "published": "2019-07-06 04:40:48", "link": "http://arxiv.org/abs/1907.05789v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ANETAC: Arabic Named Entity Transliteration and Classification Dataset", "abstract": "In this paper, we make freely accessible ANETAC our English-Arabic named\nentity transliteration and classification dataset that we built from freely\navailable parallel translation corpora. The dataset contains 79,924 instances,\neach instance is a triplet (e, a, c), where e is the English named entity, a is\nits Arabic transliteration and c is its class that can be either a Person, a\nLocation, or an Organization. The ANETAC dataset is mainly aimed for the\nresearchers that are working on Arabic named entity transliteration, but it can\nalso be used for named entity classification purposes.", "published": "2019-07-06 10:37:18", "link": "http://arxiv.org/abs/1907.03110v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Evolutionary Algorithm for Sinhala to English Translation", "abstract": "Machine Translation (MT) is an area in natural language processing, which\nfocus on translating from one language to another. Many approaches ranging from\nstatistical methods to deep learning approaches are used in order to achieve\nMT. However, these methods either require a large number of data or a clear\nunderstanding about the language. Sinhala language has less digital text which\ncould be used to train a deep neural network. Furthermore, Sinhala has complex\nrules therefore, it is harder to create statistical rules in order to apply\nstatistical methods in MT. This research focuses on Sinhala to English\ntranslation using an Evolutionary Algorithm (EA). EA is used to identifying the\ncorrect meaning of Sinhala text and to translate it to English. The Sinhala\ntext is passed to identify the meaning in order to get the correct meaning of\nthe sentence. With the use of the EA the translation is carried out. The\ntranslated text is passed on to grammatically correct the sentence. This has\nshown to achieve accurate results.", "published": "2019-07-06 22:51:28", "link": "http://arxiv.org/abs/1907.03202v1", "categories": ["cs.CL", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Improved low-resource Somali speech recognition by semi-supervised\n  acoustic and language model training", "abstract": "We present improvements in automatic speech recognition (ASR) for Somali, a\ncurrently extremely under-resourced language. This forms part of a continuing\nUnited Nations (UN) effort to employ ASR-based keyword spotting systems to\nsupport humanitarian relief programmes in rural Africa. Using just 1.57 hours\nof annotated speech data as a seed corpus, we increase the pool of training\ndata by applying semi-supervised training to 17.55 hours of untranscribed\nspeech. We make use of factorised time-delay neural networks (TDNN-F) for\nacoustic modelling, since these have recently been shown to be effective in\nresource-scarce situations. Three semi-supervised training passes were\nperformed, where the decoded output from each pass was used for acoustic model\ntraining in the subsequent pass. The automatic transcriptions from the best\nperforming pass were used for language model augmentation. To ensure the\nquality of automatic transcriptions, decoder confidence is used as a threshold.\nThe acoustic and language models obtained from the semi-supervised approach\nshow significant improvement in terms of WER and perplexity compared to the\nbaseline. Incorporating the automatically generated transcriptions yields a\n6.55\\% improvement in language model perplexity. The use of 17.55 hour of\nSomali acoustic data in semi-supervised training shows an improvement of 7.74\\%\nrelative over the baseline.", "published": "2019-07-06 02:53:10", "link": "http://arxiv.org/abs/1907.03064v1", "categories": ["cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Exploring difference in public perceptions on HPV vaccine between gender\n  groups from Twitter using deep learning", "abstract": "In this study, we proposed a convolutional neural network model for gender\nprediction using English Twitter text as input. Ensemble of proposed model\nachieved an accuracy at 0.8237 on gender prediction and compared favorably with\nthe state-of-the-art performance in a recent author profiling task. We further\nleveraged the trained models to predict the gender labels from an HPV vaccine\nrelated corpus and identified gender difference in public perceptions regarding\nHPV vaccine. The findings are largely consistent with previous survey-based\nstudies.", "published": "2019-07-06 18:58:54", "link": "http://arxiv.org/abs/1907.03167v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Learning Neural Sequence-to-Sequence Models from Weak Feedback with\n  Bipolar Ramp Loss", "abstract": "In many machine learning scenarios, supervision by gold labels is not\navailable and consequently neural models cannot be trained directly by maximum\nlikelihood estimation (MLE). In a weak supervision scenario, metric-augmented\nobjectives can be employed to assign feedback to model outputs, which can be\nused to extract a supervision signal for training. We present several\nobjectives for two separate weakly supervised tasks, machine translation and\nsemantic parsing. We show that objectives should actively discourage negative\noutputs in addition to promoting a surrogate gold structure. This notion of\nbipolarity is naturally present in ramp loss objectives, which we adapt to\nneural models. We show that bipolar ramp loss objectives outperform other\nnon-bipolar ramp loss objectives and minimum risk training (MRT) on both weakly\nsupervised tasks, as well as on a supervised machine translation task.\nAdditionally, we introduce a novel token-level ramp loss objective, which is\nable to outperform even the best sequence-level ramp loss on both weakly\nsupervised tasks.", "published": "2019-07-06 10:04:12", "link": "http://arxiv.org/abs/1907.03748v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Universal One-Dimensional Cellular Automata Derived for Turing Machines\n  and its Dynamical Behaviour", "abstract": "Universality in cellular automata theory is a central problem studied and\ndeveloped from their origins by John von Neumann. In this paper, we present an\nalgorithm where any Turing machine can be converted to one-dimensional cellular\nautomaton with a 2-linear time and display its spatial dynamics. Three\nparticular Turing machines are converted in three universal one-dimensional\ncellular automata, they are: binary sum, rule 110 and a universal reversible\nTuring machine.", "published": "2019-07-06 20:12:13", "link": "http://arxiv.org/abs/1907.04211v1", "categories": ["nlin.CG", "cs.CL", "cs.DS", "cs.LO"], "primary_category": "nlin.CG"}
{"title": "Qwant Research @DEFT 2019: Document matching and information retrieval\n  using clinical cases", "abstract": "This paper reports on Qwant Research contribution to tasks 2 and 3 of the\nDEFT 2019's challenge, focusing on French clinical cases analysis. Task 2 is a\ntask on semantic similarity between clinical cases and discussions. For this\ntask, we propose an approach based on language models and evaluate the impact\non the results of different preprocessings and matching techniques. For task 3,\nwe have developed an information extraction system yielding very encouraging\nresults accuracy-wise. We have experimented two different approaches, one based\non the exclusive use of neural networks, the other based on a linguistic\nanalysis.", "published": "2019-07-06 08:29:21", "link": "http://arxiv.org/abs/1907.05790v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Towards Debugging Deep Neural Networks by Generating Speech Utterances", "abstract": "Deep neural networks (DNN) are able to successfully process and classify\nspeech utterances. However, understanding the reason behind a classification by\nDNN is difficult. One such debugging method used with image classification DNNs\nis activation maximization, which generates example-images that are classified\nas one of the classes. In this work, we evaluate applicability of this method\nto speech utterance classifiers as the means to understanding what DNN \"listens\nto\". We trained a classifier using the speech command corpus and then use\nactivation maximization to pull samples from the trained model. Then we\nsynthesize audio from features using WaveNet vocoder for subjective analysis.\nWe measure the quality of generated samples by objective measurements and\ncrowd-sourced human evaluations. Results show that when combined with the prior\nof natural speech, activation maximization can be used to generate examples of\ndifferent classes. Based on these results, activation maximization can be used\nto start opening up the DNN black-box in speech tasks.", "published": "2019-07-06 18:19:32", "link": "http://arxiv.org/abs/1907.03164v1", "categories": ["cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Multimodal Fusion with Deep Neural Networks for Audio-Video Emotion\n  Recognition", "abstract": "This paper presents a novel deep neural network (DNN) for multimodal fusion\nof audio, video and text modalities for emotion recognition. The proposed DNN\narchitecture has independent and shared layers which aim to learn the\nrepresentation for each modality, as well as the best combined representation\nto achieve the best prediction. Experimental results on the AVEC Sentiment\nAnalysis in the Wild dataset indicate that the proposed DNN can achieve a\nhigher level of Concordance Correlation Coefficient (CCC) than other\nstate-of-the-art systems that perform early fusion of modalities at\nfeature-level (i.e., concatenation) and late fusion at score-level (i.e.,\nweighted average) fusion. The proposed DNN has achieved CCCs of 0.606, 0.534,\nand 0.170 on the development partition of the dataset for predicting arousal,\nvalence and liking, respectively.", "published": "2019-07-06 22:12:42", "link": "http://arxiv.org/abs/1907.03196v1", "categories": ["cs.CV", "eess.AS", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Bag-of-Audio-Words based on Autoencoder Codebook for Continuous Emotion\n  Prediction", "abstract": "In this paper we present a novel approach for extracting a Bag-of-Words (BoW)\nrepresentation based on a Neural Network codebook. The conventional BoW model\nis based on a dictionary (codebook) built from elementary representations which\nare selected randomly or by using a clustering algorithm on a training dataset.\nA metric is then used to assign unseen elementary representations to the\nclosest dictionary entries in order to produce a histogram. In the proposed\napproach, an autoencoder (AE) encompasses the role of both the dictionary\ncreation and the assignment metric. The dimension of the encoded layer of the\nAE corresponds to the size of the dictionary and the output of its neurons\nrepresents the assignment metric. Experimental results for the continuous\nemotion prediction task on the AVEC 2017 audio dataset have shown an\nimprovement of the Concordance Correlation Coefficient (CCC) from 0.225 to\n0.322 for arousal dimension and from 0.244 to 0.368 for valence dimension\nrelative to the conventional BoW version implemented in a baseline system.", "published": "2019-07-06 21:16:53", "link": "http://arxiv.org/abs/1907.04928v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
