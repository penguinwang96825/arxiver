{"title": "Understanding How People Rate Their Conversations", "abstract": "User ratings play a significant role in spoken dialogue systems. Typically,\nsuch ratings tend to be averaged across all users and then utilized as feedback\nto improve the system or personalize its behavior. While this method can be\nuseful to understand broad, general issues with the system and its behavior, it\ndoes not take into account differences between users that affect their ratings.\nIn this work, we conduct a study to better understand how people rate their\ninteractions with conversational agents. One macro-level characteristic that\nhas been shown to correlate with how people perceive their inter-personal\ncommunication is personality. We specifically focus on agreeableness and\nextraversion as variables that may explain variation in ratings and therefore\nprovide a more meaningful signal for training or personalization. In order to\nelicit those personality traits during an interaction with a conversational\nagent, we designed and validated a fictional story, grounded in prior work in\npsychology. We then implemented the story into an experimental conversational\nagent that allowed users to opt-in to hearing the story. Our results suggest\nthat for human-conversational agent interactions, extraversion may play a role\nin user ratings, but more data is needed to determine if the relationship is\nsignificant. Agreeableness, on the other hand, plays a statistically\nsignificant role in conversation ratings: users who are more agreeable are more\nlikely to provide a higher rating for their interaction. In addition, we found\nthat users who opted to hear the story were, in general, more likely to rate\ntheir conversational experience higher than those who did not.", "published": "2022-06-01 00:45:32", "link": "http://arxiv.org/abs/2206.00167v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Assessing Group-level Gender Bias in Professional Evaluations: The Case\n  of Medical Student End-of-Shift Feedback", "abstract": "Although approximately 50% of medical school graduates today are women,\nfemale physicians tend to be underrepresented in senior positions, make less\nmoney than their male counterparts and receive fewer promotions. There is a\ngrowing body of literature demonstrating gender bias in various forms of\nevaluation in medicine, but this work was mainly conducted by looking for\nspecific words using fixed dictionaries such as LIWC and focused on\nrecommendation letters. We use a dataset of written and quantitative\nassessments of medical student performance on individual shifts of work,\ncollected across multiple institutions, to investigate the extent to which\ngender bias exists in a day-to-day context for medical students. We investigate\ndifferences in the narrative comments given to male and female students by both\nmale or female faculty assessors, using a fine-tuned BERT model. This allows us\nto examine whether groups are written about in systematically different ways,\nwithout relying on hand-crafted wordlists or topic models. We compare these\nresults to results from the traditional LIWC method and find that, although we\nfind no evidence of group-level gender bias in this dataset, terms related to\nfamily and children are used more in feedback given to women.", "published": "2022-06-01 05:01:36", "link": "http://arxiv.org/abs/2206.00234v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "InducT-GCN: Inductive Graph Convolutional Networks for Text\n  Classification", "abstract": "Text classification aims to assign labels to textual units by making use of\nglobal information. Recent studies have applied graph neural network (GNN) to\ncapture the global word co-occurrence in a corpus. Existing approaches require\nthat all the nodes (training and test) in a graph are present during training,\nwhich are transductive and do not naturally generalise to unseen nodes. To make\nthose models inductive, they use extra resources, like pretrained word\nembedding. However, high-quality resource is not always available and hard to\ntrain. Under the extreme settings with no extra resource and limited amount of\ntraining set, can we still learn an inductive graph-based text classification\nmodel? In this paper, we introduce a novel inductive graph-based text\nclassification framework, InducT-GCN (InducTive Graph Convolutional Networks\nfor Text classification). Compared to transductive models that require test\ndocuments in training, we construct a graph based on the statistics of training\ndocuments only and represent document vectors with a weighted sum of word\nvectors. We then conduct one-directional GCN propagation during testing. Across\nfive text classification benchmarks, our InducT-GCN outperformed\nstate-of-the-art methods that are either transductive in nature or pre-trained\nadditional resources. We also conducted scalability testing by gradually\nincreasing the data size and revealed that our InducT-GCN can reduce the time\nand space complexity. The code is available on:\nhttps://github.com/usydnlp/InductTGCN.", "published": "2022-06-01 06:47:47", "link": "http://arxiv.org/abs/2206.00265v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Optical character recognition quality affects perceived usefulness of\n  historical newspaper clippings", "abstract": "Introduction. We study effect of different quality optical character\nrecognition in interactive information retrieval with a collection of one\ndigitized historical Finnish newspaper. Method. This study is based on the\nsimulated interactive information retrieval work task model. Thirty-two users\nmade searches to an article collection of Finnish newspaper Uusi Suometar\n1869-1918 with ca. 1.45 million auto segmented articles. Our article search\ndatabase had two versions of each article with different quality optical\ncharacter recognition. Each user performed six pre-formulated and six\nself-formulated short queries and evaluated subjectively the top-10 results\nusing graded relevance scale of 0-3 without knowing about the optical character\nrecognition quality differences of the otherwise identical articles. Analysis.\nAnalysis of the user evaluations was performed by comparing mean averages of\nevaluations scores in user sessions. Differences of query results were detected\nby analysing lengths of returned articles in pre-formulated and self-formulated\nqueries and number of different documents retrieved overall in these two\nsessions. Results. The main result of the study is that improved optical\ncharacter recognition quality affects perceived usefulness of historical\nnewspaper articles positively. Conclusions. We were able to show that\nimprovement in optical character recognition quality of documents leads to\nhigher mean relevance evaluation scores of query results in our historical\nnewspaper collection. To the best of our knowledge this simulated interactive\nuser-task is the first one showing empirically that users' subjective relevance\nassessments are affected by a change in the quality of optically read text.", "published": "2022-06-01 10:07:50", "link": "http://arxiv.org/abs/2206.00369v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BD-SHS: A Benchmark Dataset for Learning to Detect Online Bangla Hate\n  Speech in Different Social Contexts", "abstract": "Social media platforms and online streaming services have spawned a new breed\nof Hate Speech (HS). Due to the massive amount of user-generated content on\nthese sites, modern machine learning techniques are found to be feasible and\ncost-effective to tackle this problem. However, linguistically diverse datasets\ncovering different social contexts in which offensive language is typically\nused are required to train generalizable models. In this paper, we identify the\nshortcomings of existing Bangla HS datasets and introduce a large manually\nlabeled dataset BD-SHS that includes HS in different social contexts. The\nlabeling criteria were prepared following a hierarchical annotation process,\nwhich is the first of its kind in Bangla HS to the best of our knowledge. The\ndataset includes more than 50,200 offensive comments crawled from online social\nnetworking sites and is at least 60% larger than any existing Bangla HS\ndatasets. We present the benchmark result of our dataset by training different\nNLP models resulting in the best one achieving an F1-score of 91.0%. In our\nexperiments, we found that a word embedding trained exclusively using 1.47\nmillion comments from social media and streaming sites consistently resulted in\nbetter modeling of HS detection in comparison to other pre-trained embeddings.\nOur dataset and all accompanying codes is publicly available at\ngithub.com/naurosromim/hate-speech-dataset-for-Bengali-social-media", "published": "2022-06-01 10:10:15", "link": "http://arxiv.org/abs/2206.00372v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Diversity in Back Translation for Low-Resource Machine\n  Translation", "abstract": "Back translation is one of the most widely used methods for improving the\nperformance of neural machine translation systems. Recent research has sought\nto enhance the effectiveness of this method by increasing the 'diversity' of\nthe generated translations. We argue that the definitions and metrics used to\nquantify 'diversity' in previous work have been insufficient. This work puts\nforward a more nuanced framework for understanding diversity in training data,\nsplitting it into lexical diversity and syntactic diversity. We present novel\nmetrics for measuring these different aspects of diversity and carry out\nempirical analysis into the effect of these types of diversity on final neural\nmachine translation model performance for low-resource\nEnglish$\\leftrightarrow$Turkish and mid-resource\nEnglish$\\leftrightarrow$Icelandic. Our findings show that generating back\ntranslation using nucleus sampling results in higher final model performance,\nand that this method of generation has high levels of both lexical and\nsyntactic diversity. We also find evidence that lexical diversity is more\nimportant than syntactic for back translation performance.", "published": "2022-06-01 15:21:16", "link": "http://arxiv.org/abs/2206.00564v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HYU at SemEval-2022 Task 2: Effective Idiomaticity Detection with\n  Consideration at Different Levels of Contextualization", "abstract": "We propose a unified framework that enables us to consider various aspects of\ncontextualization at different levels to better identify the idiomaticity of\nmulti-word expressions. Through extensive experiments, we demonstrate that our\napproach based on the inter- and inner-sentence context of a target MWE is\neffective in improving the performance of related models. We also share our\nexperience in detail on the task of SemEval-2022 Tasks 2 such that future work\non the same task can be benefited from this.", "published": "2022-06-01 10:45:40", "link": "http://arxiv.org/abs/2206.11854v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Order-sensitive Shapley Values for Evaluating Conceptual Soundness of\n  NLP Models", "abstract": "Previous works show that deep NLP models are not always conceptually sound:\nthey do not always learn the correct linguistic concepts. Specifically, they\ncan be insensitive to word order. In order to systematically evaluate models\nfor their conceptual soundness with respect to word order, we introduce a new\nexplanation method for sequential data: Order-sensitive Shapley Values (OSV).\nWe conduct an extensive empirical evaluation to validate the method and surface\nhow well various deep NLP models learn word order. Using synthetic data, we\nfirst show that OSV is more faithful in explaining model behavior than\ngradient-based methods. Second, applying to the HANS dataset, we discover that\nthe BERT-based NLI model uses only the word occurrences without word orders.\nAlthough simple data augmentation improves accuracy on HANS, OSV shows that the\naugmented model does not fundamentally improve the model's learning of order.\nThird, we discover that not all sentiment analysis models learn negation\nproperly: some fail to capture the correct syntax of the negation construct.\nFinally, we show that pretrained language models such as BERT may rely on the\nabsolute positions of subject words to learn long-range Subject-Verb Agreement.\nWith each NLP task, we also demonstrate how OSV can be leveraged to generate\nadversarial examples.", "published": "2022-06-01 02:30:12", "link": "http://arxiv.org/abs/2206.00192v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "THE-X: Privacy-Preserving Transformer Inference with Homomorphic\n  Encryption", "abstract": "As more and more pre-trained language models adopt on-cloud deployment, the\nprivacy issues grow quickly, mainly for the exposure of plain-text user data\n(e.g., search history, medical record, bank account). Privacy-preserving\ninference of transformer models is on the demand of cloud service users. To\nprotect privacy, it is an attractive choice to compute only with ciphertext in\nhomomorphic encryption (HE). However, enabling pre-trained models inference on\nciphertext data is difficult due to the complex computations in transformer\nblocks, which are not supported by current HE tools yet. In this work, we\nintroduce $\\textit{THE-X}$, an approximation approach for transformers, which\nenables privacy-preserving inference of pre-trained models developed by popular\nframeworks. $\\textit{THE-X}$ proposes a workflow to deal with complex\ncomputation in transformer networks, including all the non-polynomial functions\nlike GELU, softmax, and LayerNorm. Experiments reveal our proposed\n$\\textit{THE-X}$ can enable transformer inference on encrypted data for\ndifferent downstream tasks, all with negligible performance drop but enjoying\nthe theory-guaranteed privacy-preserving advantage.", "published": "2022-06-01 03:49:18", "link": "http://arxiv.org/abs/2206.00216v2", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "MORE: A Metric Learning Based Framework for Open-domain Relation\n  Extraction", "abstract": "Open relation extraction (OpenRE) is the task of extracting relation schemes\nfrom open-domain corpora. Most existing OpenRE methods either do not fully\nbenefit from high-quality labeled corpora or can not learn semantic\nrepresentation directly, affecting downstream clustering efficiency. To address\nthese problems, in this work, we propose a novel learning framework named MORE\n(Metric learning-based Open Relation Extraction). The framework utilizes deep\nmetric learning to obtain rich supervision signals from labeled data and drive\nthe neural model to learn semantic relational representation directly.\nExperiments result in two real-world datasets show that our method outperforms\nother state-of-the-art baselines. Our source code is available on Github.", "published": "2022-06-01 07:51:20", "link": "http://arxiv.org/abs/2206.00289v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "B2T Connection: Serving Stability and Performance in Deep Transformers", "abstract": "From the perspective of the layer normalization (LN) positions, the\narchitectures of Transformers can be categorized into two types: Post-LN and\nPre-LN. Recent Transformers tend to be Pre-LN because, in Post-LN with deep\nTransformers (e.g., those with ten or more layers), the training is often\nunstable, resulting in useless models. However, Post-LN has consistently\nachieved better performance than Pre-LN in relatively shallow Transformers\n(e.g., those with six or fewer layers). This study first investigates the\nreason for these discrepant observations empirically and theoretically and made\nthe following discoveries: 1, the LN in Post-LN is the main source of the\nvanishing gradient problem that leads to unstable training, whereas Pre-LN\nprevents it, and 2, Post-LN tends to preserve larger gradient norms in higher\nlayers during the back-propagation, which may lead to effective training.\nExploiting the new findings, we propose a method that can provide both high\nstability and effective training by a simple modification of Post-LN. We\nconduct experiments on a wide range of text generation tasks. The experimental\nresults demonstrate that our method outperforms Pre-LN, and enables stable\ntraining regardless of the shallow or deep layer settings. Our code is publicly\navailable at https://github.com/takase/b2t_connection.", "published": "2022-06-01 08:43:20", "link": "http://arxiv.org/abs/2206.00330v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "What a Creole Wants, What a Creole Needs", "abstract": "In recent years, the natural language processing (NLP) community has given\nincreased attention to the disparity of efforts directed towards high-resource\nlanguages over low-resource ones. Efforts to remedy this delta often begin with\ntranslations of existing English datasets into other languages. However, this\napproach ignores that different language communities have different needs. We\nconsider a group of low-resource languages, Creole languages. Creoles are both\nlargely absent from the NLP literature, and also often ignored by society at\nlarge due to stigma, despite these languages having sizable and vibrant\ncommunities. We demonstrate, through conversations with Creole experts and\nsurveys of Creole-speaking communities, how the things needed from language\ntechnology can change dramatically from one language to another, even when the\nlanguages are considered to be very similar to each other, as with Creoles. We\ndiscuss the prominent themes arising from these conversations, and ultimately\ndemonstrate that useful language technology cannot be built without involving\nthe relevant community.", "published": "2022-06-01 12:22:34", "link": "http://arxiv.org/abs/2206.00437v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "What Changed? Investigating Debiasing Methods using Causal Mediation\n  Analysis", "abstract": "Previous work has examined how debiasing language models affect downstream\ntasks, specifically, how debiasing techniques influence task performance and\nwhether debiased models also make impartial predictions in downstream tasks or\nnot. However, what we don't understand well yet is why debiasing methods have\nvarying impacts on downstream tasks and how debiasing techniques affect\ninternal components of language models, i.e., neurons, layers, and attentions.\nIn this paper, we decompose the internal mechanisms of debiasing language\nmodels with respect to gender by applying causal mediation analysis to\nunderstand the influence of debiasing methods on toxicity detection as a\ndownstream task. Our findings suggest a need to test the effectiveness of\ndebiasing methods with different bias metrics, and to focus on changes in the\nbehavior of certain components of the models, e.g.,first two layers of language\nmodels, and attention heads.", "published": "2022-06-01 18:26:24", "link": "http://arxiv.org/abs/2206.00701v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Assessing the trade-off between prediction accuracy and interpretability\n  for topic modeling on energetic materials corpora", "abstract": "As the amount and variety of energetics research increases, machine aware\ntopic identification is necessary to streamline future research pipelines. The\nmakeup of an automatic topic identification process consists of creating\ndocument representations and performing classification. However, the\nimplementation of these processes on energetics research imposes new\nchallenges. Energetics datasets contain many scientific terms that are\nnecessary to understand the context of a document but may require more complex\ndocument representations. Secondly, the predictions from classification must be\nunderstandable and trusted by the chemists within the pipeline. In this work,\nwe study the trade-off between prediction accuracy and interpretability by\nimplementing three document embedding methods that vary in computational\ncomplexity. With our accuracy results, we also introduce local interpretability\nmodel-agnostic explanations (LIME) of each prediction to provide a localized\nunderstanding of each prediction and to validate classifier decisions with our\nteam of energetics experts. This study was carried out on a novel labeled\nenergetics dataset created and validated by our team of energetics experts.", "published": "2022-06-01 21:28:21", "link": "http://arxiv.org/abs/2206.00773v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Natural Language Sentence Generation from API Specifications", "abstract": "APIs are everywhere; they provide access to automation solutions that could\nhelp businesses automate some of their tasks. Unfortunately, they may not be\naccessible to the business users who need them but are not equipped with the\nnecessary technical skills to leverage them. Wrapping these APIs with chatbot\ncapabilities is one solution to make these automation solutions interactive. In\nthis work, we propose a system to generate sentences to train intent\nrecognition models, a crucial component within chatbots to understand natural\nlanguage utterances from users. Evaluation of our approach based on deep\nlearning models showed promising and inspiring results, and the\nhuman-in-the-loop interaction will provide further improvement on the system.", "published": "2022-06-01 15:50:14", "link": "http://arxiv.org/abs/2206.06868v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Romantic-Computing", "abstract": "In this paper we compare various text generation models' ability to write\npoetry in the style of early English Romanticism. These models include:\nCharacter-Level Recurrent Neural Networks with Long Short-Term Memory, Hugging\nFace's GPT-2, OpenAI's GPT-3, and EleutherAI's GPT-NEO. Quality was measured\nbased syllable count and coherence with the automatic evaluation metric GRUEN.\nCharacter-Level Recurrent Neural Networks performed far worse compared to\ntransformer models. And, as parameter-size increased, the quality of\ntransformer models' poems improved. These models are typically not compared in\na creative context, and we are happy to contribute.", "published": "2022-06-01 14:27:17", "link": "http://arxiv.org/abs/2206.11864v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Discovering the Hidden Vocabulary of DALLE-2", "abstract": "We discover that DALLE-2 seems to have a hidden vocabulary that can be used\nto generate images with absurd prompts. For example, it seems that\n\\texttt{Apoploe vesrreaitais} means birds and \\texttt{Contarra ccetnxniams\nluryca tanniounons} (sometimes) means bugs or pests. We find that these prompts\nare often consistent in isolation but also sometimes in combinations. We\npresent our black-box method to discover words that seem random but have some\ncorrespondence to visual concepts. This creates important security and\ninterpretability challenges.", "published": "2022-06-01 01:14:48", "link": "http://arxiv.org/abs/2206.00169v1", "categories": ["cs.LG", "cs.CL", "cs.CR", "cs.CV"], "primary_category": "cs.LG"}
{"title": "IDANI: Inference-time Domain Adaptation via Neuron-level Interventions", "abstract": "Large pre-trained models are usually fine-tuned on downstream task data, and\ntested on unseen data. When the train and test data come from different\ndomains, the model is likely to struggle, as it is not adapted to the test\ndomain. We propose a new approach for domain adaptation (DA), using\nneuron-level interventions: We modify the representation of each test example\nin specific neurons, resulting in a counterfactual example from the source\ndomain, which the model is more familiar with. The modified example is then fed\nback into the model. While most other DA methods are applied during training\ntime, ours is applied during inference only, making it more efficient and\napplicable. Our experiments show that our method improves performance on unseen\ndomains.", "published": "2022-06-01 06:39:28", "link": "http://arxiv.org/abs/2206.00259v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Vietnamese Hate and Offensive Detection using PhoBERT-CNN and Social\n  Media Streaming Data", "abstract": "Society needs to develop a system to detect hate and offense to build a\nhealthy and safe environment. However, current research in this field still\nfaces four major shortcomings, including deficient pre-processing techniques,\nindifference to data imbalance issues, modest performance models, and lacking\npractical applications. This paper focused on developing an intelligent system\ncapable of addressing these shortcomings. Firstly, we proposed an efficient\npre-processing technique to clean comments collected from Vietnamese social\nmedia. Secondly, a novel hate speech detection (HSD) model, which is the\ncombination of a pre-trained PhoBERT model and a Text-CNN model, was proposed\nfor solving tasks in Vietnamese. Thirdly, EDA techniques are applied to deal\nwith imbalanced data to improve the performance of classification models.\nBesides, various experiments were conducted as baselines to compare and\ninvestigate the proposed model's performance against state-of-the-art methods.\nThe experiment results show that the proposed PhoBERT-CNN model outperforms\nSOTA methods and achieves an F1-score of 67,46% and 98,45% on two benchmark\ndatasets, ViHSD and HSD-VLSP, respectively. Finally, we also built a streaming\nHSD application to demonstrate the practicality of our proposed system.", "published": "2022-06-01 14:33:25", "link": "http://arxiv.org/abs/2206.00524v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Cross-View Language Modeling: Towards Unified Cross-Lingual Cross-Modal\n  Pre-training", "abstract": "In this paper, we introduce Cross-View Language Modeling, a simple and\neffective pre-training framework that unifies cross-lingual and cross-modal\npre-training with shared architectures and objectives. Our approach is\nmotivated by a key observation that cross-lingual and cross-modal pre-training\nshare the same goal of aligning two different views of the same object into a\ncommon semantic space. To this end, the cross-view language modeling framework\nconsiders both multi-modal data (i.e., image-caption pairs) and multi-lingual\ndata (i.e., parallel sentence pairs) as two different views of the same object,\nand trains the model to align the two views by maximizing the mutual\ninformation between them with conditional masked language modeling and\ncontrastive learning. We pre-train CCLM, a Cross-lingual Cross-modal Language\nModel, with the cross-view language modeling framework. Empirical results on\nIGLUE, a multi-lingual multi-modal benchmark, and two multi-lingual image-text\nretrieval datasets show that while conceptually simpler, CCLM significantly\noutperforms the prior state-of-the-art with an average absolute improvement of\nover 10%. Moreover, CCLM is the first multi-lingual multi-modal pre-trained\nmodel that surpasses the translate-test performance of representative English\nvision-language models by zero-shot cross-lingual transfer.", "published": "2022-06-01 16:45:24", "link": "http://arxiv.org/abs/2206.00621v2", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On Reinforcement Learning and Distribution Matching for Fine-Tuning\n  Language Models with no Catastrophic Forgetting", "abstract": "The availability of large pre-trained models is changing the landscape of\nMachine Learning research and practice, moving from a training-from-scratch to\na fine-tuning paradigm. While in some applications the goal is to \"nudge\" the\npre-trained distribution towards preferred outputs, in others it is to steer it\ntowards a different distribution over the sample space. Two main paradigms have\nemerged to tackle this challenge: Reward Maximization (RM) and, more recently,\nDistribution Matching (DM). RM applies standard Reinforcement Learning (RL)\ntechniques, such as Policy Gradients, to gradually increase the reward signal.\nDM prescribes to first make explicit the target distribution that the model is\nfine-tuned to approximate. Here we explore the theoretical connections between\nthe two paradigms, and show that methods such as KL-control developed for RM\ncan also be construed as belonging to DM. We further observe that while DM\ndiffers from RM, it can suffer from similar training difficulties, such as high\ngradient variance. We leverage connections between the two paradigms to import\nthe concept of baseline into DM methods. We empirically validate the benefits\nof adding a baseline on an array of controllable language generation tasks such\nas constraining topic, sentiment, and gender distributions in texts sampled\nfrom a language model. We observe superior performance in terms of constraint\nsatisfaction, stability and sample efficiency.", "published": "2022-06-01 20:54:41", "link": "http://arxiv.org/abs/2206.00761v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "HYCEDIS: HYbrid Confidence Engine for Deep Document Intelligence System", "abstract": "Measuring the confidence of AI models is critical for safely deploying AI in\nreal-world industrial systems. One important application of confidence\nmeasurement is information extraction from scanned documents. However, there\nexists no solution to provide reliable confidence score for current\nstate-of-the-art deep-learning-based information extractors. In this paper, we\npropose a complete and novel architecture to measure confidence of current deep\nlearning models in document information extraction task. Our architecture\nconsists of a Multi-modal Conformal Predictor and a Variational\nCluster-oriented Anomaly Detector, trained to faithfully estimate its\nconfidence on its outputs without the need of host models modification. We\nevaluate our architecture on real-wold datasets, not only outperforming\ncompeting confidence estimators by a huge margin but also demonstrating\ngeneralization ability to out-of-distribution data.", "published": "2022-06-01 09:57:34", "link": "http://arxiv.org/abs/2206.02628v2", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "A Multi-Policy Framework for Deep Learning-Based Fake News Detection", "abstract": "Connectivity plays an ever-increasing role in modern society, with people all\naround the world having easy access to rapidly disseminated information.\nHowever, a more interconnected society enables the spread of intentionally\nfalse information. To mitigate the negative impacts of fake news, it is\nessential to improve detection methodologies. This work introduces Multi-Policy\nStatement Checker (MPSC), a framework that automates fake news detection by\nusing deep learning techniques to analyze a statement itself and its related\nnews articles, predicting whether it is seemingly credible or suspicious. The\nproposed framework was evaluated using four merged datasets containing real and\nfake news. Long-Short Term Memory (LSTM), Gated Recurrent Unit (GRU) and\nBidirectional Encoder Representations from Transformers (BERT) models were\ntrained to utilize both lexical and syntactic features, and their performance\nwas evaluated. The obtained results demonstrate that a multi-policy analysis\nreliably identifies suspicious statements, which can be advantageous for fake\nnews detection.", "published": "2022-06-01 21:25:21", "link": "http://arxiv.org/abs/2206.11866v1", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AdaVITS: Tiny VITS for Low Computing Resource Speaker Adaptation", "abstract": "Speaker adaptation in text-to-speech synthesis (TTS) is to finetune a\npre-trained TTS model to adapt to new target speakers with limited data. While\nmuch effort has been conducted towards this task, seldom work has been\nperformed for low computational resource scenarios due to the challenges raised\nby the requirement of the lightweight model and less computational complexity.\nIn this paper, a tiny VITS-based TTS model, named AdaVITS, for low computing\nresource speaker adaptation is proposed. To effectively reduce parameters and\ncomputational complexity of VITS, an iSTFT-based wave construction decoder is\nproposed to replace the upsampling-based decoder which is resource-consuming in\nthe original VITS. Besides, NanoFlow is introduced to share the density\nestimate across flow blocks to reduce the parameters of the prior encoder.\nFurthermore, to reduce the computational complexity of the textual encoder,\nscaled-dot attention is replaced with linear attention. To deal with the\ninstability caused by the simplified model, instead of using the original text\nencoder, phonetic posteriorgram (PPG) is utilized as linguistic feature via a\ntext-to-PPG module, which is then used as input for the encoder. Experiment\nshows that AdaVITS can generate stable and natural speech in speaker adaptation\nwith 8.97M model parameters and 0.72GFlops computational complexity.", "published": "2022-06-01 03:09:18", "link": "http://arxiv.org/abs/2206.00208v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Speech Artifact Removal from EEG Recordings of Spoken Word Production\n  with Tensor Decomposition", "abstract": "Research about brain activities involving spoken word production is\nconsiderably underdeveloped because of the undiscovered characteristics of\nspeech artifacts, which contaminate electroencephalogram (EEG) signals and\nprevent the inspection of the underlying cognitive processes. To fuel further\nEEG research with speech production, a method using three-mode tensor\ndecomposition (time x space x frequency) is proposed to perform speech artifact\nremoval. Tensor decomposition enables simultaneous inspection of multiple\nmodes, which suits the multi-way nature of EEG data. In a picture-naming task,\nwe collected raw data with speech artifacts by placing two electrodes near the\nmouth to record lip EMG. Based on our evaluation, which calculated the\ncorrelation values between grand-averaged speech artifacts and the lip EMG,\ntensor decomposition outperformed the former methods that were based on\nindependent component analysis (ICA) and blind source separation (BSS), both in\ndetecting speech artifact (0.985) and producing clean data (0.101). Our\nproposed method correctly preserved the components unrelated to speech, which\nwas validated by computing the correlation value between the grand-averaged raw\ndata without EOG and cleaned data before the speech onset (0.92-0.94).", "published": "2022-06-01 17:10:23", "link": "http://arxiv.org/abs/2206.00635v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Snow Mountain: Dataset of Audio Recordings of The Bible in Low Resource\n  Languages", "abstract": "Automatic Speech Recognition (ASR) has increasing utility in the modern\nworld. There are a many ASR models available for languages with large amounts\nof training data like English. However, low-resource languages are poorly\nrepresented. In response we create and release an open-licensed and formatted\ndataset of audio recordings of the Bible in low-resource northern Indian\nlanguages. We setup multiple experimental splits and train and analyze two\ncompetitive ASR models to serve as the baseline for future research using this\ndata.", "published": "2022-06-01 18:22:01", "link": "http://arxiv.org/abs/2206.01205v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Towards Generalisable Audio Representations for Audio-Visual Navigation", "abstract": "In audio-visual navigation (AVN), an intelligent agent needs to navigate to a\nconstantly sound-making object in complex 3D environments based on its audio\nand visual perceptions. While existing methods attempt to improve the\nnavigation performance with preciously designed path planning or intricate task\nsettings, none has improved the model generalisation on unheard sounds with\ntask settings unchanged. We thus propose a contrastive learning-based method to\ntackle this challenge by regularising the audio encoder, where the\nsound-agnostic goal-driven latent representations can be learnt from various\naudio signals of different classes. In addition, we consider two data\naugmentation strategies to enrich the training sounds. We demonstrate that our\ndesigns can be easily equipped to existing AVN frameworks to obtain an\nimmediate performance gain (13.4%$\\uparrow$ in SPL on Replica and\n12.2%$\\uparrow$ in SPL on MP3D). Our project is available at\nhttps://AV-GeN.github.io/.", "published": "2022-06-01 11:00:07", "link": "http://arxiv.org/abs/2206.00393v1", "categories": ["cs.SD", "cs.CV", "cs.LG", "cs.RO", "eess.AS"], "primary_category": "cs.SD"}
