{"title": "UKARA 1.0 Challenge Track 1: Automatic Short-Answer Scoring in Bahasa\n  Indonesia", "abstract": "We describe our third-place solution to the UKARA 1.0 challenge on automated\nessay scoring. The task consists of a binary classification problem on two\ndatasets | answers from two different questions. We ended up using two\ndifferent models for the two datasets. For task A, we applied a random forest\nalgorithm on features extracted using unigram with latent semantic analysis\n(LSA). On the other hand, for task B, we only used logistic regression on\nTF-IDF features. Our model results in F1 score of 0.812.", "published": "2020-02-28 04:32:16", "link": "http://arxiv.org/abs/2002.12540v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Robust Unsupervised Neural Machine Translation with Adversarial\n  Denoising Training", "abstract": "Unsupervised neural machine translation (UNMT) has recently attracted great\ninterest in the machine translation community. The main advantage of the UNMT\nlies in its easy collection of required large training text sentences while\nwith only a slightly worse performance than supervised neural machine\ntranslation which requires expensive annotated translation pairs on some\ntranslation tasks. In most studies, the UMNT is trained with clean data without\nconsidering its robustness to the noisy data. However, in real-world scenarios,\nthere usually exists noise in the collected input sentences which degrades the\nperformance of the translation system since the UNMT is sensitive to the small\nperturbations of the input sentences. In this paper, we first time explicitly\ntake the noisy data into consideration to improve the robustness of the UNMT\nbased systems. First of all, we clearly defined two types of noises in training\nsentences, i.e., word noise and word order noise, and empirically investigate\nits effect in the UNMT, then we propose adversarial training methods with\ndenoising process in the UNMT. Experimental results on several language pairs\nshow that our proposed methods substantially improved the robustness of the\nconventional UNMT systems in noisy scenarios.", "published": "2020-02-28 05:17:55", "link": "http://arxiv.org/abs/2002.12549v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modeling Future Cost for Neural Machine Translation", "abstract": "Existing neural machine translation (NMT) systems utilize\nsequence-to-sequence neural networks to generate target translation word by\nword, and then make the generated word at each time-step and the counterpart in\nthe references as consistent as possible. However, the trained translation\nmodel tends to focus on ensuring the accuracy of the generated target word at\nthe current time-step and does not consider its future cost which means the\nexpected cost of generating the subsequent target translation (i.e., the next\ntarget word). To respond to this issue, we propose a simple and effective\nmethod to model the future cost of each target word for NMT systems. In detail,\na time-dependent future cost is estimated based on the current generated target\nword and its contextual information to boost the training of the NMT model.\nFurthermore, the learned future context representation at the current time-step\nis used to help the generation of the next target word in the decoding.\nExperimental results on three widely-used translation datasets, including the\nWMT14 German-to-English, WMT14 English-to-French, and WMT17 Chinese-to-English,\nshow that the proposed approach achieves significant improvements over strong\nTransformer-based NMT baseline.", "published": "2020-02-28 05:37:06", "link": "http://arxiv.org/abs/2002.12558v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DC-BERT: Decoupling Question and Document for Efficient Contextual\n  Encoding", "abstract": "Recent studies on open-domain question answering have achieved prominent\nperformance improvement using pre-trained language models such as BERT.\nState-of-the-art approaches typically follow the \"retrieve and read\" pipeline\nand employ BERT-based reranker to filter retrieved documents before feeding\nthem into the reader module. The BERT retriever takes as input the\nconcatenation of question and each retrieved document. Despite the success of\nthese approaches in terms of QA accuracy, due to the concatenation, they can\nbarely handle high-throughput of incoming questions each with a large\ncollection of retrieved documents. To address the efficiency problem, we\npropose DC-BERT, a decoupled contextual encoding framework that has dual BERT\nmodels: an online BERT which encodes the question only once, and an offline\nBERT which pre-encodes all the documents and caches their encodings. On SQuAD\nOpen and Natural Questions Open datasets, DC-BERT achieves 10x speedup on\ndocument retrieval, while retaining most (about 98%) of the QA performance\ncompared to state-of-the-art approaches for open-domain question answering.", "published": "2020-02-28 08:18:37", "link": "http://arxiv.org/abs/2002.12591v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Section Recognition in Obituaries", "abstract": "Obituaries contain information about people's values across times and\ncultures, which makes them a useful resource for exploring cultural history.\nThey are typically structured similarly, with sections corresponding to\nPersonal Information, Biographical Sketch, Characteristics, Family, Gratitude,\nTribute, Funeral Information and Other aspects of the person. To make this\ninformation available for further studies, we propose a statistical model which\nrecognizes these sections. To achieve that, we collect a corpus of 20058\nEnglish obituaries from TheDaily Item, Remembering.CA and The London Free\nPress. The evaluation of our annotation guidelines with three annotators on\n1008 obituaries shows a substantial agreement of Fleiss k = 0.87. Formulated as\nan automatic segmentation task, a convolutional neural network outperforms\nbag-of-words and embedding-based BiLSTMs and BiLSTM-CRFs with a micro F1 =\n0.81.", "published": "2020-02-28 13:20:09", "link": "http://arxiv.org/abs/2002.12699v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UniLMv2: Pseudo-Masked Language Models for Unified Language Model\n  Pre-Training", "abstract": "We propose to pre-train a unified language model for both autoencoding and\npartially autoregressive language modeling tasks using a novel training\nprocedure, referred to as a pseudo-masked language model (PMLM). Given an input\ntext with masked tokens, we rely on conventional masks to learn inter-relations\nbetween corrupted tokens and context via autoencoding, and pseudo masks to\nlearn intra-relations between masked spans via partially autoregressive\nmodeling. With well-designed position embeddings and self-attention masks, the\ncontext encodings are reused to avoid redundant computation. Moreover,\nconventional masks used for autoencoding provide global masking information, so\nthat all the position embeddings are accessible in partially autoregressive\nlanguage modeling. In addition, the two tasks pre-train a unified language\nmodel as a bidirectional encoder and a sequence-to-sequence decoder,\nrespectively. Our experiments show that the unified language models pre-trained\nusing PMLM achieve new state-of-the-art results on a wide range of natural\nlanguage understanding and generation tasks across several widely used\nbenchmarks.", "published": "2020-02-28 15:28:49", "link": "http://arxiv.org/abs/2002.12804v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Metaphoric Paraphrase Generation", "abstract": "This work describes the task of metaphoric paraphrase generation, in which we\nare given a literal sentence and are charged with generating a metaphoric\nparaphrase. We propose two different models for this task: a lexical\nreplacement baseline and a novel sequence to sequence model, 'metaphor\nmasking', that generates free metaphoric paraphrases. We use crowdsourcing to\nevaluate our results, as well as developing an automatic metric for evaluating\nmetaphoric paraphrases. We show that while the lexical replacement baseline is\ncapable of producing accurate paraphrases, they often lack metaphoricity, while\nour metaphor masking model excels in generating metaphoric sentences while\nperforming nearly as well with regard to fluency and paraphrase quality.", "published": "2020-02-28 16:30:33", "link": "http://arxiv.org/abs/2002.12854v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "AraBERT: Transformer-based Model for Arabic Language Understanding", "abstract": "The Arabic language is a morphologically rich language with relatively few\nresources and a less explored syntax compared to English. Given these\nlimitations, Arabic Natural Language Processing (NLP) tasks like Sentiment\nAnalysis (SA), Named Entity Recognition (NER), and Question Answering (QA),\nhave proven to be very challenging to tackle. Recently, with the surge of\ntransformers based models, language-specific BERT based models have proven to\nbe very efficient at language understanding, provided they are pre-trained on a\nvery large corpus. Such models were able to set new standards and achieve\nstate-of-the-art results for most NLP tasks. In this paper, we pre-trained BERT\nspecifically for the Arabic language in the pursuit of achieving the same\nsuccess that BERT did for the English language. The performance of AraBERT is\ncompared to multilingual BERT from Google and other state-of-the-art\napproaches. The results showed that the newly developed AraBERT achieved\nstate-of-the-art performance on most tested Arabic NLP tasks. The pretrained\naraBERT models are publicly available on https://github.com/aub-mind/arabert\nhoping to encourage research and applications for Arabic NLP.", "published": "2020-02-28 22:59:24", "link": "http://arxiv.org/abs/2003.00104v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GASP! Generating Abstracts of Scientific Papers from Abstracts of Cited\n  Papers", "abstract": "Creativity is one of the driving forces of human kind as it allows to break\ncurrent understanding to envision new ideas, which may revolutionize entire\nfields of knowledge. Scientific research offers a challenging environment where\nto learn a model for the creative process. In fact, scientific research is a\ncreative act in the formal settings of the scientific method and this creative\nact is described in articles.\n  In this paper, we dare to introduce the novel, scientifically and\nphilosophically challenging task of Generating Abstracts of Scientific Papers\nfrom abstracts of cited papers (GASP) as a text-to-text task to investigate\nscientific creativity, To foster research in this novel, challenging task, we\nprepared a dataset by using services where that solve the problem of copyright\nand, hence, the dataset is public available with its standard split. Finally,\nwe experimented with two vanilla summarization systems to start the analysis of\nthe complexity of the GASP task.", "published": "2020-02-28 14:58:41", "link": "http://arxiv.org/abs/2003.04996v1", "categories": ["cs.CL", "I.2; I.2.7; I.2.6"], "primary_category": "cs.CL"}
{"title": "Temporal Convolutional Attention-based Network For Sequence Modeling", "abstract": "With the development of feed-forward models, the default model for sequence\nmodeling has gradually evolved to replace recurrent networks. Many powerful\nfeed-forward models based on convolutional networks and attention mechanism\nwere proposed and show more potential to handle sequence modeling tasks. We\nwonder that is there an architecture that can not only achieve an approximate\nsubstitution of recurrent network, but also absorb the advantages of\nfeed-forward models. So we propose an exploratory architecture referred to\nTemporal Convolutional Attention-based Network (TCAN) which combines temporal\nconvolutional network and attention mechanism. TCAN includes two parts, one is\nTemporal Attention (TA) which captures relevant features inside the sequence,\nthe other is Enhanced Residual (ER) which extracts shallow layer's important\ninformation and transfers to deep layers. We improve the state-of-the-art\nresults of bpc/perplexity to 30.28 on word-level PTB, 1.092 on character-level\nPTB, and 9.20 on WikiText-2.", "published": "2020-02-28 03:53:31", "link": "http://arxiv.org/abs/2002.12530v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Do all Roads Lead to Rome? Understanding the Role of Initialization in\n  Iterative Back-Translation", "abstract": "Back-translation provides a simple yet effective approach to exploit\nmonolingual corpora in Neural Machine Translation (NMT). Its iterative variant,\nwhere two opposite NMT models are jointly trained by alternately using a\nsynthetic parallel corpus generated by the reverse model, plays a central role\nin unsupervised machine translation. In order to start producing sound\ntranslations and provide a meaningful training signal to each other, existing\napproaches rely on either a separate machine translation system to warm up the\niterative procedure, or some form of pre-training to initialize the weights of\nthe model. In this paper, we analyze the role that such initialization plays in\niterative back-translation. Is the behavior of the final system heavily\ndependent on it? Or does iterative back-translation converge to a similar\nsolution given any reasonable initialization? Through a series of empirical\nexperiments over a diverse set of warmup systems, we show that, although the\nquality of the initial system does affect final performance, its effect is\nrelatively small, as iterative back-translation has a strong tendency to\nconvergence to a similar solution. As such, the margin of improvement left for\nthe initialization method is narrow, suggesting that future research should\nfocus more on improving the iterative mechanism itself.", "published": "2020-02-28 17:05:55", "link": "http://arxiv.org/abs/2002.12867v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning Directly from Grammar Compressed Text", "abstract": "Neural networks using numerous text data have been successfully applied to a\nvariety of tasks. While massive text data is usually compressed using\ntechniques such as grammar compression, almost all of the previous machine\nlearning methods assume already decompressed sequence data as their input. In\nthis paper, we propose a method to directly apply neural sequence models to\ntext data compressed with grammar compression algorithms without decompression.\nTo encode the unique symbols that appear in compression rules, we introduce\ncomposer modules to incrementally encode the symbols into vector\nrepresentations. Through experiments on real datasets, we empirically showed\nthat the proposal model can achieve both memory and computational efficiency\nwhile maintaining moderate performance.", "published": "2020-02-28 06:51:40", "link": "http://arxiv.org/abs/2002.12570v1", "categories": ["stat.ML", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Exploring and Distilling Cross-Modal Information for Image Captioning", "abstract": "Recently, attention-based encoder-decoder models have been used extensively\nin image captioning. Yet there is still great difficulty for the current\nmethods to achieve deep image understanding. In this work, we argue that such\nunderstanding requires visual attention to correlated image regions and\nsemantic attention to coherent attributes of interest. Based on the\nTransformer, to perform effective attention, we explore image captioning from a\ncross-modal perspective and propose the Global-and-Local Information\nExploring-and-Distilling approach that explores and distills the source\ninformation in vision and language. It globally provides the aspect vector, a\nspatial and relational representation of images based on caption contexts,\nthrough the extraction of salient region groupings and attribute collocations,\nand locally extracts the fine-grained regions and attributes in reference to\nthe aspect vector for word selection. Our Transformer-based model achieves a\nCIDEr score of 129.3 in offline COCO evaluation on the COCO testing set with\nremarkable efficiency in terms of accuracy, speed, and parameter budget.", "published": "2020-02-28 07:46:48", "link": "http://arxiv.org/abs/2002.12585v2", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "A multi-layer approach to disinformation detection on Twitter", "abstract": "We tackle the problem of classifying news articles pertaining to\ndisinformation vs mainstream news by solely inspecting their diffusion\nmechanisms on Twitter. Our technique is inherently simple compared to existing\ntext-based approaches, as it allows to by-pass the multiple levels of\ncomplexity which are found in news content (e.g. grammar, syntax, style). We\nemploy a multi-layer representation of Twitter diffusion networks, and we\ncompute for each layer a set of global network features which quantify\ndifferent aspects of the sharing process. Experimental results with two\nlarge-scale datasets, corresponding to diffusion cascades of news shared\nrespectively in the United States and Italy, show that a simple Logistic\nRegression model is able to classify disinformation vs mainstream networks with\nhigh accuracy (AUROC up to 94%), also when considering the political bias of\ndifferent sources in the classification task. We also highlight differences in\nthe sharing patterns of the two news domains which appear to be\ncountry-independent. We believe that our network-based approach provides useful\ninsights which pave the way to the future development of a system to detect\nmisleading and harmful information spreading on social media.", "published": "2020-02-28 09:25:53", "link": "http://arxiv.org/abs/2002.12612v2", "categories": ["cs.SI", "cs.CL", "cs.IR"], "primary_category": "cs.SI"}
{"title": "TextBrewer: An Open-Source Knowledge Distillation Toolkit for Natural\n  Language Processing", "abstract": "In this paper, we introduce TextBrewer, an open-source knowledge distillation\ntoolkit designed for natural language processing. It works with different\nneural network models and supports various kinds of supervised learning tasks,\nsuch as text classification, reading comprehension, sequence labeling.\nTextBrewer provides a simple and uniform workflow that enables quick setting up\nof distillation experiments with highly flexible configurations. It offers a\nset of predefined distillation methods and can be extended with custom code. As\na case study, we use TextBrewer to distill BERT on several typical NLP tasks.\nWith simple configurations, we achieve results that are comparable with or even\nhigher than the public distilled BERT models with similar numbers of\nparameters. Our toolkit is available through: http://textbrewer.hfl-rc.com", "published": "2020-02-28 09:44:07", "link": "http://arxiv.org/abs/2002.12620v2", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Comparison of Speech Representations for Automatic Quality Estimation in\n  Multi-Speaker Text-to-Speech Synthesis", "abstract": "We aim to characterize how different speakers contribute to the perceived\noutput quality of multi-speaker Text-to-Speech (TTS) synthesis. We\nautomatically rate the quality of TTS using a neural network (NN) trained on\nhuman mean opinion score (MOS) ratings. First, we train and evaluate our NN\nmodel on 13 different TTS and voice conversion (VC) systems from the ASVSpoof\n2019 Logical Access (LA) Dataset. Since it is not known how best to represent\nspeech for this task, we compare 8 different representations alongside MOSNet\nframe-based features. Our representations include image-based spectrogram\nfeatures and x-vector embeddings that explicitly model different types of noise\nsuch as T60 reverberation time. Our NN predicts MOS with a high correlation to\nhuman judgments. We report prediction correlation and error. A key finding is\nthe quality achieved for certain speakers seems consistent, regardless of the\nTTS or VC system. It is widely accepted that some speakers give higher quality\nthan others for building a TTS system: our method provides an automatic way to\nidentify such speakers. Finally, to see if our quality prediction models\ngeneralize, we predict quality scores for synthetic speech using a separate\nmulti-speaker TTS system that was trained on LibriTTS data, and conduct our own\nMOS listening test to compare human ratings with our NN predictions.", "published": "2020-02-28 10:44:32", "link": "http://arxiv.org/abs/2002.12645v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "RP-DNN: A Tweet level propagation context based deep neural networks for\n  early rumor detection in Social Media", "abstract": "Early rumor detection (ERD) on social media platform is very challenging when\nlimited, incomplete and noisy information is available. Most of the existing\nmethods have largely worked on event-level detection that requires the\ncollection of posts relevant to a specific event and relied only on\nuser-generated content. They are not appropriate to detect rumor sources in the\nvery early stages, before an event unfolds and becomes widespread. In this\npaper, we address the task of ERD at the message level. We present a novel\nhybrid neural network architecture, which combines a task-specific\ncharacter-based bidirectional language model and stacked Long Short-Term Memory\n(LSTM) networks to represent textual contents and social-temporal contexts of\ninput source tweets, for modelling propagation patterns of rumors in the early\nstages of their development. We apply multi-layered attention models to jointly\nlearn attentive context embeddings over multiple context inputs. Our\nexperiments employ a stringent leave-one-out cross-validation (LOO-CV)\nevaluation setup on seven publicly available real-life rumor event data sets.\nOur models achieve state-of-the-art(SoA) performance for detecting unseen\nrumors on large augmented data which covers more than 12 events and 2,967\nrumors. An ablation study is conducted to understand the relative contribution\nof each component of our proposed model.", "published": "2020-02-28 12:44:34", "link": "http://arxiv.org/abs/2002.12683v2", "categories": ["cs.SI", "cs.CL", "cs.IR"], "primary_category": "cs.SI"}
{"title": "Auxiliary Function-Based Algorithm for Blind Extraction of a Moving\n  Speaker", "abstract": "Recently, Constant Separating Vector (CSV) mixing model has been proposed for\nthe Blind Source Extraction (BSE) of moving sources. In this paper, we\nexperimentally verify the applicability of CSV in the blind extraction of a\nmoving speaker and propose a new BSE method derived by modifying the auxiliary\nfunction-based algorithm for Independent Vector Analysis. Also, a piloted\nvariant is proposed for the method with partially controllable global\nconvergence. The methods are verified under reverberant and noisy conditions\nusing {\\color{red} simulated as well as real-world acoustic conditions}. They\nare also verified within the CHiME-4 speech separation and recognition\nchallenge. The experiments corroborate the applicability of CSV as well as the\nimproved convergence of the proposed algorithms.", "published": "2020-02-28 09:38:53", "link": "http://arxiv.org/abs/2002.12619v3", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Amateur Drones Detection: A machine learning approach utilizing the\n  acoustic signals in the presence of strong interference", "abstract": "Owing to small size, sensing capabilities and autonomous nature, the Unmanned\nAir Vehicles (UAVs) have enormous applications in various areas, e.g., remote\nsensing, navigation, archaeology, journalism, environmental science, and\nagriculture. However, the unmonitored deployment of UAVs called the amateur\ndrones (AmDr) can lead to serious security threats and risk to human life and\ninfrastructure. Therefore, timely detection of the AmDr is essential for the\nprotection and security of sensitive organizations, human life and other vital\ninfrastructure. AmDrs can be detected using different techniques based on\nsound, video, thermal, and radio frequencies. However, the performance of these\ntechniques is limited in sever atmospheric conditions. In this paper, we\npropose an efficient unsupervise machine learning approach of independent\ncomponent analysis (ICA) to detect various acoustic signals i.e., sounds of\nbird, airplanes, thunderstorm, rain, wind and the UAVs in practical scenario.\nAfter unmixing the signals, the features like Mel Frequency Cepstral\nCoefficients (MFCC), the power spectral density (PSD) and the Root Mean Square\nValue (RMS) of the PSD are extracted by using ICA. The PSD and the RMS of PSD\nsignals are extracted by first passing the signals from octave band filter\nbanks. Based on the above features the signals are classified using Support\nVector Machines (SVM) and K Nearest Neighbor (KNN) to detect the presence or\nabsence of AmDr. Unique feature of the proposed technique is the detection of a\nsingle or multiple AmDrs at a time in the presence of multiple acoustic\ninterfering signals. The proposed technique is verified through extensive\nsimulations and it is observed that the RMS values of PSD with KNN performs\nbetter than the MFCC with KNN and SVM.", "published": "2020-02-28 17:28:17", "link": "http://arxiv.org/abs/2003.01519v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "eess.SP", "stat.ML", "68T45, 68T10, 62H30,", "C.2; C.2.4; G.3"], "primary_category": "eess.AS"}
{"title": "Bio-Inspired Modality Fusion for Active Speaker Detection", "abstract": "Human beings have developed fantastic abilities to integrate information from\nvarious sensory sources exploring their inherent complementarity. Perceptual\ncapabilities are therefore heightened, enabling, for instance, the well-known\n\"cocktail party\" and McGurk effects, i.e., speech disambiguation from a panoply\nof sound signals. This fusion ability is also key in refining the perception of\nsound source location, as in distinguishing whose voice is being heard in a\ngroup conversation. Furthermore, neuroscience has successfully identified the\nsuperior colliculus region in the brain as the one responsible for this\nmodality fusion, with a handful of biological models having been proposed to\napproach its underlying neurophysiological process. Deriving inspiration from\none of these models, this paper presents a methodology for effectively fusing\ncorrelated auditory and visual information for active speaker detection. Such\nan ability can have a wide range of applications, from teleconferencing systems\nto social robotics. The detection approach initially routes auditory and visual\ninformation through two specialized neural network structures. The resulting\nembeddings are fused via a novel layer based on the superior colliculus, whose\ntopological structure emulates spatial neuron cross-mapping of unimodal\nperceptual fields. The validation process employed two publicly available\ndatasets, with achieved results confirming and greatly surpassing initial\nexpectations.", "published": "2020-02-28 20:56:24", "link": "http://arxiv.org/abs/2003.00063v2", "categories": ["cs.CV", "cs.LG", "cs.NE", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.CV"}
