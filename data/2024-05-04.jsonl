{"title": "A Combination of BERT and Transformer for Vietnamese Spelling Correction", "abstract": "Recently, many studies have shown the efficiency of using Bidirectional\nEncoder Representations from Transformers (BERT) in various Natural Language\nProcessing (NLP) tasks. Specifically, English spelling correction task that\nuses Encoder-Decoder architecture and takes advantage of BERT has achieved\nstate-of-the-art result. However, to our knowledge, there is no implementation\nin Vietnamese yet. Therefore, in this study, a combination of Transformer\narchitecture (state-of-the-art for Encoder-Decoder model) and BERT was proposed\nto deal with Vietnamese spelling correction. The experiment results have shown\nthat our model outperforms other approaches as well as the Google Docs Spell\nChecking tool, achieves an 86.24 BLEU score on this task.", "published": "2024-05-04 05:24:19", "link": "http://arxiv.org/abs/2405.02573v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mixat: A Data Set of Bilingual Emirati-English Speech", "abstract": "This paper introduces Mixat: a dataset of Emirati speech code-mixed with\nEnglish. Mixat was developed to address the shortcomings of current speech\nrecognition resources when applied to Emirati speech, and in particular, to\nbilignual Emirati speakers who often mix and switch between their local dialect\nand English. The data set consists of 15 hours of speech derived from two\npublic podcasts featuring native Emirati speakers, one of which is in the form\nof conversations between the host and a guest. Therefore, the collection\ncontains examples of Emirati-English code-switching in both formal and natural\nconversational contexts. In this paper, we describe the process of data\ncollection and annotation, and describe some of the features and statistics of\nthe resulting data set. In addition, we evaluate the performance of pre-trained\nArabic and multi-lingual ASR systems on our dataset, demonstrating the\nshortcomings of existing models on this low-resource dialectal Arabic, and the\nadditional challenge of recognizing code-switching in ASR. The dataset will be\nmade publicly available for research use.", "published": "2024-05-04 06:06:34", "link": "http://arxiv.org/abs/2405.02578v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "R4: Reinforced Retriever-Reorder-Responder for Retrieval-Augmented Large\n  Language Models", "abstract": "Retrieval-augmented large language models (LLMs) leverage relevant content\nretrieved by information retrieval systems to generate correct responses,\naiming to alleviate the hallucination problem. However, existing\nretriever-responder methods typically append relevant documents to the prompt\nof LLMs to perform text generation tasks without considering the interaction of\nfine-grained structural semantics between the retrieved documents and the LLMs.\nThis issue is particularly important for accurate response generation as LLMs\ntend to \"lose in the middle\" when dealing with input prompts augmented with\nlengthy documents. In this work, we propose a new pipeline named \"Reinforced\nRetriever-Reorder-Responder\" (R$^4$) to learn document orderings for\nretrieval-augmented LLMs, thereby further enhancing their generation abilities\nwhile the large numbers of parameters of LLMs remain frozen. The reordering\nlearning process is divided into two steps according to the quality of the\ngenerated responses: document order adjustment and document representation\nenhancement. Specifically, document order adjustment aims to organize retrieved\ndocument orderings into beginning, middle, and end positions based on graph\nattention learning, which maximizes the reinforced reward of response quality.\nDocument representation enhancement further refines the representations of\nretrieved documents for responses of poor quality via document-level gradient\nadversarial learning. Extensive experiments demonstrate that our proposed\npipeline achieves better factual question-answering performance on\nknowledge-intensive tasks compared to strong baselines across various public\ndatasets. The source codes and trained models will be released upon paper\nacceptance.", "published": "2024-05-04 12:59:10", "link": "http://arxiv.org/abs/2405.02659v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Information Redundancy in Non-Autoregressive Translation", "abstract": "Token repetition is a typical form of multi-modal problem in fully\nnon-autoregressive translation (NAT). In this work, we revisit the multi-modal\nproblem in recently proposed NAT models. Our study reveals that these advanced\nmodels have introduced other types of information redundancy errors, which\ncannot be measured by the conventional metric - the continuous repetition\nratio. By manually annotating the NAT outputs, we identify two types of\ninformation redundancy errors that correspond well to lexical and reordering\nmulti-modality problems. Since human annotation is time-consuming and\nlabor-intensive, we propose automatic metrics to evaluate the two types of\nredundant errors. Our metrics allow future studies to evaluate new methods and\ngain a more comprehensive understanding of their effectiveness.", "published": "2024-05-04 14:20:28", "link": "http://arxiv.org/abs/2405.02673v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing News Summarization with ELearnFit through Efficient In-Context\n  Learning and Efficient Fine-Tuning", "abstract": "With the deluge of information delivered by the daily news cycle, there is a\ngrowing need to effectively and efficiently summarize news feeds for quick\nconsumption. We leverage large language models (LLMs), with their advanced\nlearning and generative abilities as compared to conventional language models,\nto generate concise and coherent summaries for news articles from the XSum\ndataset. Our paper focuses on two key aspects of LLMs: Efficient in-context\nLearning (ELearn) and Parameter Efficient Fine-tuning (EFit). Under ELearn, we\nfind that increasing the number of shots in prompts and utilizing simple\ntemplates generally improve the quality of summaries. We also find that\nutilizing relevant examples in few-shot learning for ELearn does not improve\nmodel performance. In addition, we studied EFit using different methods and\ndemonstrate that fine-tuning the first layer of LLMs produces better outcomes\nas compared to fine-tuning other layers or utilizing LoRA. We also find that\nleveraging more relevant training samples using selective layers does not\nresult in better performance. By combining ELearn and EFit, we create a new\nmodel (ELearnFit) that leverages the benefits of both few-shot learning and\nfine-tuning and produces superior performance to either model alone. We also\nuse ELearnFit to highlight the trade-offs between prompting and fine-tuning,\nespecially for situations where only a limited number of annotated samples are\navailable. Ultimately, our research provides practical techniques to optimize\nnews summarization during the prompting and fine-tuning stages and enhances the\nsynthesis of news articles.", "published": "2024-05-04 16:48:05", "link": "http://arxiv.org/abs/2405.02710v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CoE-SQL: In-Context Learning for Multi-Turn Text-to-SQL with\n  Chain-of-Editions", "abstract": "Recently, Large Language Models (LLMs) have been demonstrated to possess\nimpressive capabilities in a variety of domains and tasks. We investigate the\nissue of prompt design in the multi-turn text-to-SQL task and attempt to\nenhance the LLMs' reasoning capacity when generating SQL queries. In the\nconversational context, the current SQL query can be modified from the\npreceding SQL query with only a few operations due to the context dependency.\nWe introduce our method called CoE-SQL which can prompt LLMs to generate the\nSQL query based on the previously generated SQL query with an edition chain. We\nalso conduct extensive ablation studies to determine the optimal configuration\nof our approach. Our approach outperforms different in-context learning\nbaselines stably and achieves state-of-the-art performances on two benchmarks\nSParC and CoSQL using LLMs, which is also competitive to the SOTA fine-tuned\nmodels.", "published": "2024-05-04 16:56:14", "link": "http://arxiv.org/abs/2405.02712v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond Performance: Quantifying and Mitigating Label Bias in LLMs", "abstract": "Large language models (LLMs) have shown remarkable adaptability to diverse\ntasks, by leveraging context prompts containing instructions, or minimal\ninput-output examples. However, recent work revealed they also exhibit label\nbias -- an undesirable preference toward predicting certain answers over\nothers. Still, detecting and measuring this bias reliably and at scale has\nremained relatively unexplored. In this study, we evaluate different approaches\nto quantifying label bias in a model's predictions, conducting a comprehensive\ninvestigation across 279 classification tasks and ten LLMs. Our investigation\nreveals substantial label bias in models both before and after debiasing\nattempts, as well as highlights the importance of outcomes-based evaluation\nmetrics, which were not previously used in this regard. We further propose a\nnovel label bias calibration method tailored for few-shot prompting, which\noutperforms recent calibration approaches for both improving performance and\nmitigating label bias. Our results emphasize that label bias in the predictions\nof LLMs remains a barrier to their reliability.", "published": "2024-05-04 19:53:03", "link": "http://arxiv.org/abs/2405.02743v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Framework for Human Evaluation of Large Language Models in Healthcare\n  Derived from Literature Review", "abstract": "With generative artificial intelligence (AI), particularly large language\nmodels (LLMs), continuing to make inroads in healthcare, it is critical to\nsupplement traditional automated evaluations with human evaluations.\nUnderstanding and evaluating the output of LLMs is essential to assuring\nsafety, reliability, and effectiveness. However, human evaluation's cumbersome,\ntime-consuming, and non-standardized nature presents significant obstacles to\ncomprehensive evaluation and widespread adoption of LLMs in practice. This\nstudy reviews existing literature on human evaluation methodologies for LLMs in\nhealthcare. We highlight a notable need for a standardized and consistent human\nevaluation approach. Our extensive literature search, adhering to the Preferred\nReporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines,\nincludes publications from January 2018 to February 2024. The review examines\nthe human evaluation of LLMs across various medical specialties, addressing\nfactors such as evaluation dimensions, sample types and sizes, selection, and\nrecruitment of evaluators, frameworks and metrics, evaluation process, and\nstatistical analysis type. Drawing on the diverse evaluation strategies\nemployed in these studies, we propose a comprehensive and practical framework\nfor human evaluation of LLMs: QUEST: Quality of Information, Understanding and\nReasoning, Expression Style and Persona, Safety and Harm, and Trust and\nConfidence. This framework aims to improve the reliability, generalizability,\nand applicability of human evaluation of LLMs in different healthcare\napplications by defining clear evaluation dimensions and offering detailed\nguidelines.", "published": "2024-05-04 04:16:07", "link": "http://arxiv.org/abs/2405.02559v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Identifying Narrative Patterns and Outliers in Holocaust Testimonies\n  Using Topic Modeling", "abstract": "The vast collection of Holocaust survivor testimonies presents invaluable\nhistorical insights but poses challenges for manual analysis. This paper\nleverages advanced Natural Language Processing (NLP) techniques to explore the\nUSC Shoah Foundation Holocaust testimony corpus. By treating testimonies as\nstructured question-and-answer sections, we apply topic modeling to identify\nkey themes. We experiment with BERTopic, which leverages recent advances in\nlanguage modeling technology. We align testimony sections into fixed parts,\nrevealing the evolution of topics across the corpus of testimonies. This\nhighlights both a common narrative schema and divergences between subgroups\nbased on age and gender. We introduce a novel method to identify testimonies\nwithin groups that exhibit atypical topic distributions resembling those of\nother groups. This study offers unique insights into the complex narratives of\nHolocaust survivors, demonstrating the power of NLP to illuminate historical\ndiscourse and identify potential deviations in survivor experiences.", "published": "2024-05-04 12:29:00", "link": "http://arxiv.org/abs/2405.02650v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluating the Ability of Computationally Extracted Narrative Maps to\n  Encode Media Framing", "abstract": "Narratives serve as fundamental frameworks in our understanding of the world\nand play a crucial role in collaborative sensemaking, providing a versatile\nfoundation for sensemaking. Framing is a subtle yet potent mechanism that\ninfluences public perception through specific word choices, shaping\ninterpretations of reported news events. Despite the recognized importance of\nnarratives and framing, a significant gap exists in the literature with regard\nto the explicit consideration of framing within the context of computational\nextraction and representation. This article explores the capabilities of a\nspecific narrative extraction and representation approach -- narrative maps --\nto capture framing information from news data. The research addresses two key\nquestions: (1) Does the narrative extraction method capture the framing\ndistribution of the data set? (2) Does it produce a representation with\nconsistent framing? Our results indicate that while the algorithm captures\nframing distributions, achieving consistent framing across various starting and\nending events poses challenges. Our results highlight the potential of\nnarrative maps to provide users with insights into the intricate framing\ndynamics within news narratives. However, we note that directly leveraging\nframing information in the computational narrative extraction process remains\nan open challenge.", "published": "2024-05-04 14:40:28", "link": "http://arxiv.org/abs/2405.02677v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Beyond Relevance: Evaluate and Improve Retrievers on Perspective\n  Awareness", "abstract": "The task of Information Retrieval (IR) requires a system to identify relevant\ndocuments based on users' information needs. In real-world scenarios,\nretrievers are expected to not only rely on the semantic relevance between the\ndocuments and the queries but also recognize the nuanced intents or\nperspectives behind a user query. For example, when asked to verify a claim, a\nretrieval system is expected to identify evidence from both supporting vs.\ncontradicting perspectives, for the downstream system to make a fair judgment\ncall. In this work, we study whether retrievers can recognize and respond to\ndifferent perspectives of the queries -- beyond finding relevant documents for\na claim, can retrievers distinguish supporting vs. opposing documents? We\nreform and extend six existing tasks to create a benchmark for retrieval, where\nwe have diverse perspectives described in free-form text, besides root, neutral\nqueries. We show that current retrievers covered in our experiments have\nlimited awareness of subtly different perspectives in queries and can also be\nbiased toward certain perspectives. Motivated by the observation, we further\nexplore the potential to leverage geometric features of retriever\nrepresentation space to improve the perspective awareness of retrievers in a\nzero-shot manner. We demonstrate the efficiency and effectiveness of our\nprojection-based methods on the same set of tasks. Further analysis also shows\nhow perspective awareness improves performance on various downstream tasks,\nwith 4.2% higher accuracy on AmbigQA and 29.9% more correlation with designated\nviewpoints on essay writing, compared to non-perspective-aware baselines.", "published": "2024-05-04 17:10:00", "link": "http://arxiv.org/abs/2405.02714v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Recall Them All: Retrieval-Augmented Language Models for Long Object\n  List Extraction from Long Documents", "abstract": "Methods for relation extraction from text mostly focus on high precision, at\nthe cost of limited recall. High recall is crucial, though, to populate long\nlists of object entities that stand in a specific relation with a given\nsubject. Cues for relevant objects can be spread across many passages in long\ntexts. This poses the challenge of extracting long lists from long texts. We\npresent the L3X method which tackles the problem in two stages: (1)\nrecall-oriented generation using a large language model (LLM) with judicious\ntechniques for retrieval augmentation, and (2) precision-oriented\nscrutinization to validate or prune candidates. Our L3X method outperforms\nLLM-only generations by a substantial margin.", "published": "2024-05-04 18:32:08", "link": "http://arxiv.org/abs/2405.02732v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Relations Prediction for Knowledge Graph Completion using Large Language\n  Models", "abstract": "Knowledge Graphs have been widely used to represent facts in a structured\nformat. Due to their large scale applications, knowledge graphs suffer from\nbeing incomplete. The relation prediction task obtains knowledge graph\ncompletion by assigning one or more possible relations to each pair of nodes.\nIn this work, we make use of the knowledge graph node names to fine-tune a\nlarge language model for the relation prediction task. By utilizing the node\nnames only we enable our model to operate sufficiently in the inductive\nsettings. Our experiments show that we accomplish new scores on a widely used\nknowledge graph benchmark.", "published": "2024-05-04 19:04:51", "link": "http://arxiv.org/abs/2405.02738v1", "categories": ["cs.CL", "cs.AI", "I.2.4"], "primary_category": "cs.CL"}
{"title": "Enhancing Contextual Understanding in Large Language Models through\n  Contrastive Decoding", "abstract": "Large language models (LLMs) tend to inadequately integrate input context\nduring text generation, relying excessively on encoded prior knowledge in model\nparameters, potentially resulting in generated text with factual\ninconsistencies or contextually unfaithful content. LLMs utilize two primary\nknowledge sources: 1) prior (parametric) knowledge from pretraining, and 2)\ncontextual (non-parametric) knowledge from input prompts. The study addresses\nthe open question of how LLMs effectively balance these knowledge sources\nduring the generation process, specifically in the context of open-domain\nquestion answering. To address this issue, we introduce a novel approach\nintegrating contrastive decoding with adversarial irrelevant passages as\nnegative samples to enhance robust context grounding during generation.\nNotably, our method operates at inference time without requiring further\ntraining. We conduct comprehensive experiments to demonstrate its applicability\nand effectiveness, providing empirical evidence showcasing its superiority over\nexisting methodologies. Our code is publicly available at:\nhttps://github.com/amazon-science/ContextualUnderstanding-ContrastiveDecoding.", "published": "2024-05-04 20:38:41", "link": "http://arxiv.org/abs/2405.02750v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Assessing Adversarial Robustness of Large Language Models: An Empirical\n  Study", "abstract": "Large Language Models (LLMs) have revolutionized natural language processing,\nbut their robustness against adversarial attacks remains a critical concern. We\npresents a novel white-box style attack approach that exposes vulnerabilities\nin leading open-source LLMs, including Llama, OPT, and T5. We assess the impact\nof model size, structure, and fine-tuning strategies on their resistance to\nadversarial perturbations. Our comprehensive evaluation across five diverse\ntext classification tasks establishes a new benchmark for LLM robustness. The\nfindings of this study have far-reaching implications for the reliable\ndeployment of LLMs in real-world applications and contribute to the advancement\nof trustworthy AI systems.", "published": "2024-05-04 22:00:28", "link": "http://arxiv.org/abs/2405.02764v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Has this Fact been Edited? Detecting Knowledge Edits in Language Models", "abstract": "Knowledge editing methods (KEs) can update language models' obsolete or\ninaccurate knowledge learned from pre-training. However, KEs can be used for\nmalicious applications, e.g., inserting misinformation and toxic content.\nKnowing whether a generated output is based on edited knowledge or first-hand\nknowledge from pre-training can increase users' trust in generative models and\nprovide more transparency. Driven by this, we propose a novel task: detecting\nedited knowledge in language models. Given an edited model and a fact retrieved\nby a prompt from an edited model, the objective is to classify the knowledge as\neither unedited (based on the pre-training), or edited (based on subsequent\nediting). We instantiate the task with four KEs, two LLMs, and two datasets.\nAdditionally, we propose using the hidden state representations and the\nprobability distributions as features for the detection. Our results reveal\nthat, using these features as inputs to a simple AdaBoost classifiers\nestablishes a strong baseline. This classifier requires only a limited amount\nof data and maintains its performance even in cross-domain settings. Last, we\nfind it more challenging to distinguish edited knowledge from unedited but\nrelated knowledge, highlighting the need for further research. Our work lays\nthe groundwork for addressing malicious model editing, which is a critical\nchallenge associated with the strong generative capabilities of LLMs.", "published": "2024-05-04 22:02:24", "link": "http://arxiv.org/abs/2405.02765v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Overview of the EHRSQL 2024 Shared Task on Reliable Text-to-SQL Modeling\n  on Electronic Health Records", "abstract": "Electronic Health Records (EHRs) are relational databases that store the\nentire medical histories of patients within hospitals. They record numerous\naspects of patients' medical care, from hospital admission and diagnosis to\ntreatment and discharge. While EHRs are vital sources of clinical data,\nexploring them beyond a predefined set of queries requires skills in query\nlanguages like SQL. To make information retrieval more accessible, one strategy\nis to build a question-answering system, possibly leveraging text-to-SQL models\nthat can automatically translate natural language questions into corresponding\nSQL queries and use these queries to retrieve the answers. The EHRSQL 2024\nshared task aims to advance and promote research in developing a\nquestion-answering system for EHRs using text-to-SQL modeling, capable of\nreliably providing requested answers to various healthcare professionals to\nimprove their clinical work processes and satisfy their needs. Among more than\n100 participants who applied to the shared task, eight teams were formed and\ncompleted the entire shared task requirement and demonstrated a wide range of\nmethods to effectively solve this task. In this paper, we describe the task of\nreliable text-to-SQL modeling, the dataset, and the methods and results of the\nparticipants. We hope this shared task will spur further research and insights\ninto developing reliable question-answering systems for EHRs.", "published": "2024-05-04 04:12:18", "link": "http://arxiv.org/abs/2405.06673v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Open-SQL Framework: Enhancing Text-to-SQL on Open-source Large Language\n  Models", "abstract": "Despite the success of large language models (LLMs) in Text-to-SQL tasks,\nopen-source LLMs encounter challenges in contextual understanding and response\ncoherence. To tackle these issues, we present \\ours, a systematic methodology\ntailored for Text-to-SQL with open-source LLMs. Our contributions include a\ncomprehensive evaluation of open-source LLMs in Text-to-SQL tasks, the\n\\openprompt strategy for effective question representation, and novel\nstrategies for supervised fine-tuning. We explore the benefits of\nChain-of-Thought in step-by-step inference and propose the \\openexample method\nfor enhanced few-shot learning. Additionally, we introduce token-efficient\ntechniques, such as \\textbf{Variable-length Open DB Schema}, \\textbf{Target\nColumn Truncation}, and \\textbf{Example Column Truncation}, addressing\nchallenges in large-scale databases. Our findings emphasize the need for\nfurther investigation into the impact of supervised fine-tuning on contextual\nlearning capabilities. Remarkably, our method significantly improved Llama2-7B\nfrom 2.54\\% to 41.04\\% and Code Llama-7B from 14.54\\% to 48.24\\% on the\nBIRD-Dev dataset. Notably, the performance of Code Llama-7B surpassed GPT-4\n(46.35\\%) on the BIRD-Dev dataset.", "published": "2024-05-04 15:40:17", "link": "http://arxiv.org/abs/2405.06674v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Random Masking Finds Winning Tickets for Parameter Efficient Fine-tuning", "abstract": "Fine-tuning large language models (LLM) can be costly. Parameter-efficient\nfine-tuning (PEFT) addresses the problems by training a fraction of the\nparameters, whose success reveals the expressiveness and flexibility of\npretrained models. This paper studies the limit of PEFT, by further simplifying\nits design and reducing the number of trainable parameters beyond standard\nsetups. To this end, we use Random Masking to fine-tune the pretrained model.\nDespite its simplicity, we show that Random Masking is surprisingly effective:\nwith a larger-than-expected learning rate, Random Masking can match the\nperformance of standard PEFT algorithms such as LoRA on various tasks, using\nfewer trainable parameters. We provide both empirical and theoretical\nexplorations into the success of Random Masking. We show that masking induces a\nflatter loss landscape and more distant solutions, which allows for and\nnecessitates large learning rates.", "published": "2024-05-04 07:44:18", "link": "http://arxiv.org/abs/2405.02596v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Astro-NER -- Astronomy Named Entity Recognition: Is GPT a Good Domain\n  Expert Annotator?", "abstract": "In this study, we address one of the challenges of developing NER models for\nscholarly domains, namely the scarcity of suitable labeled data. We experiment\nwith an approach using predictions from a fine-tuned LLM model to aid\nnon-domain experts in annotating scientific entities within astronomy\nliterature, with the goal of uncovering whether such a collaborative process\ncan approximate domain expertise. Our results reveal moderate agreement between\na domain expert and the LLM-assisted non-experts, as well as fair agreement\nbetween the domain expert and the LLM model's predictions. In an additional\nexperiment, we compare the performance of finetuned and default LLMs on this\ntask. We have also introduced a specialized scientific entity annotation scheme\nfor astronomy, validated by a domain expert. Our approach adopts a scholarly\nresearch contribution-centric perspective, focusing exclusively on scientific\nentities relevant to the research theme. The resultant dataset, containing\n5,000 annotated astronomy article titles, is made publicly available.", "published": "2024-05-04 08:04:39", "link": "http://arxiv.org/abs/2405.02602v1", "categories": ["cs.CL", "cs.AI", "cs.IT", "math.IT"], "primary_category": "cs.CL"}
{"title": "TREC iKAT 2023: A Test Collection for Evaluating Conversational and\n  Interactive Knowledge Assistants", "abstract": "Conversational information seeking has evolved rapidly in the last few years\nwith the development of Large Language Models (LLMs), providing the basis for\ninterpreting and responding in a naturalistic manner to user requests. The\nextended TREC Interactive Knowledge Assistance Track (iKAT) collection aims to\nenable researchers to test and evaluate their Conversational Search Agents\n(CSA). The collection contains a set of 36 personalized dialogues over 20\ndifferent topics each coupled with a Personal Text Knowledge Base (PTKB) that\ndefines the bespoke user personas. A total of 344 turns with approximately\n26,000 passages are provided as assessments on relevance, as well as additional\nassessments on generated responses over four key dimensions: relevance,\ncompleteness, groundedness, and naturalness. The collection challenges CSA to\nefficiently navigate diverse personal contexts, elicit pertinent persona\ninformation, and employ context for relevant conversations. The integration of\na PTKB and the emphasis on decisional search tasks contribute to the uniqueness\nof this test collection, making it an essential benchmark for advancing\nresearch in conversational and interactive knowledge assistants.", "published": "2024-05-04 11:22:16", "link": "http://arxiv.org/abs/2405.02637v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "EDA Corpus: A Large Language Model Dataset for Enhanced Interaction with\n  OpenROAD", "abstract": "Large language models (LLMs) serve as powerful tools for design, providing\ncapabilities for both task automation and design assistance. Recent\nadvancements have shown tremendous potential for facilitating LLM integration\ninto the chip design process; however, many of these works rely on data that\nare not publicly available and/or not permissively licensed for use in LLM\ntraining and distribution. In this paper, we present a solution aimed at\nbridging this gap by introducing an open-source dataset tailored for OpenROAD,\na widely adopted open-source EDA toolchain. The dataset features over 1000 data\npoints and is structured in two formats: (i) a pairwise set comprised of\nquestion prompts with prose answers, and (ii) a pairwise set comprised of code\nprompts and their corresponding OpenROAD scripts. By providing this dataset, we\naim to facilitate LLM-focused research within the EDA domain. The dataset is\navailable at https://github.com/OpenROAD-Assistant/EDA-Corpus.", "published": "2024-05-04 21:29:37", "link": "http://arxiv.org/abs/2405.06676v1", "categories": ["cs.CL", "cs.AI", "cs.AR"], "primary_category": "cs.CL"}
{"title": "Modern Information Technologies in Scientific Research and Educational\n  Activities", "abstract": "The monograph summarizes and analyzes the current state of scientific\nresearch in the field of interactive artificial intelligence systems, text\ngeneration systems, diagnostics of the competitiveness of specialists, in the\nareas of correct color rendering in image formation, informatization of the\nwork of graduate students, accessible technology for creating three-dimensional\n3D models. The monograph will be useful both to specialists and employees of\ncompanies working in the IT field, as well as teachers, masters, students and\ngraduate students of higher educational institutions, as well as anyone\ninterested in issues related to information technology. The monograph was\ncompiled based on the results of the 16-th international scientific and\npractical conference Information technologies and automation - 2023, which took\nplace in October 2023 at Odessa National University of Technology.", "published": "2024-05-04 14:24:47", "link": "http://arxiv.org/abs/2407.10296v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.GR"], "primary_category": "cs.CY"}
{"title": "Quranic Audio Dataset: Crowdsourced and Labeled Recitation from\n  Non-Arabic Speakers", "abstract": "This paper addresses the challenge of learning to recite the Quran for\nnon-Arabic speakers. We explore the possibility of crowdsourcing a carefully\nannotated Quranic dataset, on top of which AI models can be built to simplify\nthe learning process. In particular, we use the volunteer-based crowdsourcing\ngenre and implement a crowdsourcing API to gather audio assets. We integrated\nthe API into an existing mobile application called NamazApp to collect audio\nrecitations. We developed a crowdsourcing platform called Quran Voice for\nannotating the gathered audio assets. As a result, we have collected around\n7000 Quranic recitations from a pool of 1287 participants across more than 11\nnon-Arabic countries, and we have annotated 1166 recitations from the dataset\nin six categories. We have achieved a crowd accuracy of 0.77, an inter-rater\nagreement of 0.63 between the annotators, and 0.89 between the labels assigned\nby the algorithm and the expert judgments.", "published": "2024-05-04 14:29:05", "link": "http://arxiv.org/abs/2405.02675v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
