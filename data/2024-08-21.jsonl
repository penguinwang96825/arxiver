{"title": "A case study on different one-factor Cheyette models for short maturity caplet calibration", "abstract": "In [1], we calibrated a one-factor Cheyette SLV model with a local volatility\nthat is linear in the benchmark forward rate and an uncorrelated CIR stochastic\nvariance to 3M caplets of various maturities. While caplet smiles for many\nmaturities could be reasonably well calibrated across the range of strikes, for\ninstance the 1Y maturity could not be calibrated well across that entire range\nof strikes. Here, we study whether models with alternative local volatility\nterms and/or alternative stochastic volatility or variance models can calibrate\nthe 1Y caplet smile better across the strike range better than the model\nstudied in [1]. This is made possible and feasible by the generic simulation,\npricing, and calibration frameworks introduced in [1] and some new frameworks\npresented in this paper. We find that some model settings calibrate well to the\n1Y smile across the strike range under study. In particular, a model setting\nwith a local volatility that is piece-wise linear in the benchmark forward rate\ntogether with an uncorrelated CIR stochastic variance and one with a local\nvolatility that is linear in the benchmark rate together with a correlated\nlognormal stochastic volatility with quadratic drift (QDLNSV) as in [2]\ncalibrate well. We discuss why the later might be a preferable model.\n  [1] Arun Kumar Polala and Bernhard Hientzsch. Parametric differential machine\nlearning for pricing and calibration. arXiv preprint arXiv:2302.06682 , 2023.\n  [2] Artur Sepp and Parviz Rakhmonov. A Robust Stochastic Volatility Model for\nInterest Rate Dynamics. Risk Magazine, 2023", "published": "2024-08-21 00:42:09", "link": "http://arxiv.org/abs/2408.11257v1", "categories": ["q-fin.CP", "cs.NA", "math.NA", "q-fin.MF"], "primary_category": "q-fin.CP"}
{"title": "Dynamical analysis of financial stocks network: improving forecasting using network properties", "abstract": "Applying a network analysis to stock return correlations, we study the\ndynamical properties of the network and how they correlate with the market\nreturn, finding meaningful variables that partially capture the complex\ndynamical processes of stock interactions and the market structure. We then use\nthe individual properties of stocks within the network along with the global\nones, to find correlations with the future returns of individual S&P 500\nstocks. Applying these properties as input variables for forecasting, we find a\n50% improvement on the R2score in the prediction of stock returns on long time\nscales (per year), and 3% on short time scales (2 days), relative to baseline\nmodels without network variables.", "published": "2024-08-21 16:31:51", "link": "http://arxiv.org/abs/2408.11759v1", "categories": ["q-fin.ST", "physics.soc-ph", "q-fin.CP"], "primary_category": "q-fin.ST"}
{"title": "Deviations from the Nash equilibrium and emergence of tacit collusion in a two-player optimal execution game with reinforcement learning", "abstract": "The use of reinforcement learning algorithms in financial trading is becoming\nincreasingly prevalent. However, the autonomous nature of these algorithms can\nlead to unexpected outcomes that deviate from traditional game-theoretical\npredictions and may even destabilize markets. In this study, we examine a\nscenario in which two autonomous agents, modeled with Double Deep Q-Learning,\nlearn to liquidate the same asset optimally in the presence of market impact,\nusing the Almgren-Chriss (2000) framework. Our results show that the strategies\nlearned by the agents deviate significantly from the Nash equilibrium of the\ncorresponding market impact game. Notably, the learned strategies exhibit tacit\ncollusion, closely aligning with the Pareto-optimal solution. We further\nexplore how different levels of market volatility influence the agents'\nperformance and the equilibria they discover, including scenarios where\nvolatility differs between the training and testing phases.", "published": "2024-08-21 16:54:53", "link": "http://arxiv.org/abs/2408.11773v1", "categories": ["q-fin.TR", "econ.GN", "q-fin.CP", "q-fin.EC", "stat.ML"], "primary_category": "q-fin.TR"}
{"title": "Less is more: AI Decision-Making using Dynamic Deep Neural Networks for Short-Term Stock Index Prediction", "abstract": "In this paper we introduce a multi-agent deep-learning method which trades in\nthe Futures markets based on the US S&P 500 index. The method (referred to as\nModel A) is an innovation founded on existing well-established machine-learning\nmodels which sample market prices and associated derivatives in order to decide\nwhether the investment should be long/short or closed (zero exposure), on a\nday-to-day decision. We compare the predictions with some conventional\nmachine-learning methods namely, Long Short-Term Memory, Random Forest and\nGradient-Boosted-Trees. Results are benchmarked against a passive model in\nwhich the Futures contracts are held (long) continuously with the same exposure\n(level of investment). Historical tests are based on daily daytime trading\ncarried out over a period of 6 calendar years (2018-23). We find that Model A\noutperforms the passive investment in key performance metrics, placing it\nwithin the top quartile performance of US Large Cap active fund managers. Model\nA also outperforms the three machine-learning classification comparators over\nthis period. We observe that Model A is extremely efficient (doing less and\ngetting more) with an exposure to the market of only 41.95% compared to the\n100% market exposure of the passive investment, and thus provides increased\nprofitability with reduced risk.", "published": "2024-08-21 16:04:31", "link": "http://arxiv.org/abs/2408.11740v1", "categories": ["q-fin.TR", "q-fin.PM", "I.2.1; I.6.4; I.6.5"], "primary_category": "q-fin.TR"}
{"title": "MEV Capture and Decentralization in Execution Tickets", "abstract": "We provide an economic model of Execution Tickets and use it to study the\nability of the Ethereum protocol to capture MEV from block construction. We\ndemonstrate that Execution Tickets extract all MEV when all buyers are\nhomogeneous, risk neutral and face no capital costs. We also show that MEV\ncapture decreases with risk aversion and capital costs. Moreover, when buyers\nare heterogeneous, MEV capture can be especially low and a single dominant\nbuyer can extract much of the MEV. This adverse effect can be partially\nmitigated by the presence of a Proposer Builder Separation (PBS) mechanism,\nwhich gives ET buyers access to a market of specialized builders, but in\npractice centralization vectors still persist. With PBS, ETs are concentrated\namong those with the highest ex-ante MEV extraction ability and lowest cost of\ncapital. We show how it is possible that large investors that are not builders\nbut have substantial advantage in capital cost can come to dominate the ET\nmarket.", "published": "2024-08-21 00:34:07", "link": "http://arxiv.org/abs/2408.11255v1", "categories": ["cs.GT", "q-fin.TR"], "primary_category": "cs.GT"}
{"title": "Counterfactuals As a Means for Evaluating Faithfulness of Attribution\n  Methods in Autoregressive Language Models", "abstract": "Despite the widespread adoption of autoregressive language models,\nexplainability evaluation research has predominantly focused on span infilling\nand masked language models. Evaluating the faithfulness of an explanation\nmethod -- how accurately it explains the inner workings and decision-making of\nthe model -- is challenging because it is difficult to separate the model from\nits explanation. Most faithfulness evaluation techniques corrupt or remove\ninput tokens deemed important by a particular attribution (feature importance)\nmethod and observe the resulting change in the model's output. However, for\nautoregressive language models, this approach creates out-of-distribution\ninputs due to their next-token prediction training objective. In this study, we\npropose a technique that leverages counterfactual generation to evaluate the\nfaithfulness of attribution methods for autoregressive language models. Our\ntechnique generates fluent, in-distribution counterfactuals, making the\nevaluation protocol more reliable.", "published": "2024-08-21 00:17:59", "link": "http://arxiv.org/abs/2408.11252v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RedWhale: An Adapted Korean LLM Through Efficient Continual Pretraining", "abstract": "The field of Natural Language Processing (NLP) has seen significant\nadvancements with the development of Large Language Models (LLMs). However,\nmuch of this research remains focused on English, often overlooking\nlow-resource languages like Korean. This oversight presents challenges due to\nthe unique non-alphabetic token structure of Korean and the substantial memory\nand computational demands required for LLM training, which frequently lead to\nmemory constraints and out-of-memory errors. To address these issues, we\npresent RedWhale, a model specifically tailored for Korean language processing.\nRedWhale is developed using an efficient continual pretraining approach that\nincludes a comprehensive Korean corpus preprocessing pipeline, a specialized\ntokenizer, an optimized model initialization technique, and a multistage\npretraining strategy. These innovations collectively reduce training time and\ncomputational costs while maintaining high levels of accuracy and\ncomprehension. By leveraging cross-lingual transfer learning, which exploits\nshared linguistic similarities across languages, RedWhale builds on English\nmodels to enhance Korean language processing. Experimental results demonstrate\nthat RedWhale outperforms other leading models on Korean NLP benchmarks,\nincluding the Korean Balanced Evaluation of Significant Tasks (KoBEST), showing\nsuperior understanding and generation of Korean text. Furthermore, RedWhale\nshowed no signs of convergence even after pretraining on 9.7 billion tokens,\nindicating the potential for further improvements with additional training.\nThis work represents a significant advancement in bridging the linguistic\ndivide, particularly in enhancing NLP capabilities for the Korean language.", "published": "2024-08-21 02:49:41", "link": "http://arxiv.org/abs/2408.11294v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RAGLAB: A Modular and Research-Oriented Unified Framework for\n  Retrieval-Augmented Generation", "abstract": "Large Language Models (LLMs) demonstrate human-level capabilities in\ndialogue, reasoning, and knowledge retention. However, even the most advanced\nLLMs face challenges such as hallucinations and real-time updating of their\nknowledge. Current research addresses this bottleneck by equipping LLMs with\nexternal knowledge, a technique known as Retrieval Augmented Generation (RAG).\nHowever, two key issues constrained the development of RAG. First, there is a\ngrowing lack of comprehensive and fair comparisons between novel RAG\nalgorithms. Second, open-source tools such as LlamaIndex and LangChain employ\nhigh-level abstractions, which results in a lack of transparency and limits the\nability to develop novel algorithms and evaluation metrics. To close this gap,\nwe introduce RAGLAB, a modular and research-oriented open-source library.\nRAGLAB reproduces 6 existing algorithms and provides a comprehensive ecosystem\nfor investigating RAG algorithms. Leveraging RAGLAB, we conduct a fair\ncomparison of 6 RAG algorithms across 10 benchmarks. With RAGLAB, researchers\ncan efficiently compare the performance of various algorithms and develop novel\nalgorithms.", "published": "2024-08-21 07:20:48", "link": "http://arxiv.org/abs/2408.11381v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Inducing Long-Context Abilities in Multilingual Neural Machine\n  Translation Models", "abstract": "Neural Machine Translation (NMT) models have traditionally used Sinusoidal\nPositional Embeddings (PEs), which often struggle to capture long-range\ndependencies and are inefficient for handling extended context or\ndocument-level translation tasks. This work addresses the challenge of\ntransitioning pre-trained NMT models from absolute Sinusoidal PEs to Relative\nPEs, such as RoPE and ALiBi, without compromising performance. We demonstrate\nthat parameter-efficient fine-tuning, using only a small amount of high-quality\ndata, can successfully facilitate this transition. Experimental results\nindicate that switching from Sinusoidal to Relative PEs results in competitive\ntranslation quality on sentence-level evaluation benchmarks. Additionally,\nmodels trained with RoPE consistently outperform those using ALiBi and\nSinusoidal PEs on document-level benchmarks across both string-based metrics\nand qualitative evaluations. Moreover, we find that a small amount of\nlong-context data in a few languages is sufficient for cross-lingual length\ngeneralization, thereby inducing long-context capabilities.", "published": "2024-08-21 07:23:34", "link": "http://arxiv.org/abs/2408.11382v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MoE-LPR: Multilingual Extension of Large Language Models through\n  Mixture-of-Experts with Language Priors Routing", "abstract": "Large Language Models (LLMs) are often English-centric due to the\ndisproportionate distribution of languages in their pre-training data.\nEnhancing non-English language capabilities through post-pretraining often\nresults in catastrophic forgetting of the ability of original languages.\nPrevious methods either achieve good expansion with severe forgetting or slight\nforgetting with poor expansion, indicating the challenge of balancing language\nexpansion while preventing forgetting. In this paper, we propose a method\ncalled MoE-LPR (Mixture-of-Experts with Language Priors Routing) to alleviate\nthis problem. MoE-LPR employs a two-stage training approach to enhance the\nmultilingual capability. First, the model is post-pretrained into a\nMixture-of-Experts (MoE) architecture by upcycling, where all the original\nparameters are frozen and new experts are added. In this stage, we focus\nimproving the ability on expanded languages, without using any original\nlanguage data. Then, the model reviews the knowledge of the original languages\nwith replay data amounting to less than 1% of post-pretraining, where we\nincorporate language priors routing to better recover the abilities of the\noriginal languages. Evaluations on multiple benchmarks show that MoE-LPR\noutperforms other post-pretraining methods. Freezing original parameters\npreserves original language knowledge while adding new experts preserves the\nlearning ability. Reviewing with LPR enables effective utilization of\nmultilingual knowledge within the parameters. Additionally, the MoE\narchitecture maintains the same inference overhead while increasing total model\nparameters. Extensive experiments demonstrate MoE-LPR's effectiveness in\nimproving expanded languages and preserving original language proficiency with\nsuperior scalability. Code and scripts are freely available at\nhttps://github.com/zjwang21/MoE-LPR.git.", "published": "2024-08-21 07:43:49", "link": "http://arxiv.org/abs/2408.11396v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LAHAJA: A Robust Multi-accent Benchmark for Evaluating Hindi ASR Systems", "abstract": "Hindi, one of the most spoken language of India, exhibits a diverse array of\naccents due to its usage among individuals from diverse linguistic origins. To\nenable a robust evaluation of Hindi ASR systems on multiple accents, we create\na benchmark, LAHAJA, which contains read and extempore speech on a diverse set\nof topics and use cases, with a total of 12.5 hours of Hindi audio, sourced\nfrom 132 speakers spanning 83 districts of India. We evaluate existing\nopen-source and commercial models on LAHAJA and find their performance to be\npoor. We then train models using different datasets and find that our model\ntrained on multilingual data with good speaker diversity outperforms existing\nmodels by a significant margin. We also present a fine-grained analysis which\nshows that the performance declines for speakers from North-East and South\nIndia, especially with content heavy in named entities and specialized\nterminology.", "published": "2024-08-21 08:51:00", "link": "http://arxiv.org/abs/2408.11440v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Distributional Properties of Subword Regularization", "abstract": "Subword regularization, used widely in NLP, improves model performance by\nreducing the dependency on exact tokenizations, augmenting the training corpus,\nand exposing the model to more unique contexts during training. BPE and\nMaxMatch, two popular subword tokenization schemes, have stochastic dropout\nregularization variants. However, there has not been an analysis of the\ndistributions formed by them. We show that these stochastic variants are\nheavily biased towards a small set of tokenizations per word. If the benefits\nof subword regularization are as mentioned, we hypothesize that biasedness\nartificially limits the effectiveness of these schemes. Thus, we propose an\nalgorithm to uniformly sample tokenizations that we use as a drop-in\nreplacement for the stochastic aspects of existing tokenizers, and find that it\nimproves machine translation quality.", "published": "2024-08-21 08:53:35", "link": "http://arxiv.org/abs/2408.11443v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Expanding FLORES+ Benchmark for more Low-Resource Settings:\n  Portuguese-Emakhuwa Machine Translation Evaluation", "abstract": "As part of the Open Language Data Initiative shared tasks, we have expanded\nthe FLORES+ evaluation set to include Emakhuwa, a low-resource language widely\nspoken in Mozambique. We translated the dev and devtest sets from Portuguese\ninto Emakhuwa, and we detail the translation process and quality assurance\nmeasures used. Our methodology involved various quality checks, including\npost-editing and adequacy assessments. The resulting datasets consist of\nmultiple reference sentences for each source. We present baseline results from\ntraining a Neural Machine Translation system and fine-tuning existing\nmultilingual translation models. Our findings suggest that spelling\ninconsistencies remain a challenge in Emakhuwa. Additionally, the baseline\nmodels underperformed on this evaluation set, underscoring the necessity for\nfurther research to enhance machine translation quality for Emakhuwa. The data\nis publicly available at https://huggingface.co/datasets/LIACC/Emakhuwa-FLORES.", "published": "2024-08-21 09:23:20", "link": "http://arxiv.org/abs/2408.11457v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Self-Contained Negation Test Set", "abstract": "Several methodologies have recently been proposed to evaluate the ability of\nPretrained Language Models (PLMs) to interpret negation. In this article, we\nbuild on Gubelmann and Handschuh (2022), which studies the modification of\nPLMs' predictions as a function of the polarity of inputs, in English.\nCrucially, this test uses ``self-contained'' inputs ending with a masked\nposition: depending on the polarity of a verb in the input, a particular token\nis either semantically ruled out or allowed at the masked position. By\nreplicating Gubelmann and Handschuh (2022) experiments, we have uncovered flaws\nthat weaken the conclusions that can be drawn from this test. We thus propose\nan improved version, the Self-Contained Neg Test, which is more controlled,\nmore systematic, and entirely based on examples forming minimal pairs varying\nonly in the presence or absence of verbal negation in English. When applying\nour test to the roberta and bert base and large models, we show that only\nroberta-large shows trends that match the expectations, while bert-base is\nmostly insensitive to negation. For all the tested models though, in a\nsignificant number of test instances the top-1 prediction remains the token\nthat is semantically forbidden by the context, which shows how much room for\nimprovement remains for a proper treatment of the negation phenomenon.", "published": "2024-08-21 09:38:15", "link": "http://arxiv.org/abs/2408.11469v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DocTabQA: Answering Questions from Long Documents Using Tables", "abstract": "We study a new problem setting of question answering (QA), referred to as\nDocTabQA. Within this setting, given a long document, the goal is to respond to\nquestions by organizing the answers into structured tables derived directly\nfrom the document's content. Unlike traditional QA approaches which\npredominantly rely on unstructured text to formulate responses, DocTabQA aims\nto leverage structured tables as answers to convey information clearly and\nsystematically, thereby enhancing user comprehension and highlighting\nrelationships between data points. To the best of our knowledge, this problem\nhas not been previously explored. In this paper, we introduce the QTabA\ndataset, encompassing 300 financial documents, accompanied by manually\nannotated 1.5k question-table pairs. Initially, we leverage Large Language\nModels (LLMs) such as GPT-4 to establish a baseline. However, it is widely\nacknowledged that LLMs encounter difficulties when tasked with generating\nintricate, structured outputs from long input sequences. To overcome these\nchallenges, we present a two-stage framework, called DocTabTalk, which\ninitially retrieves relevant sentences from extensive documents and\nsubsequently generates hierarchical tables based on these identified sentences.\nDocTabTalk incorporates two key technological innovations: AlignLLaMA and\nTabTalk, which are specifically tailored to assist GPT-4 in tackling DocTabQA,\nenabling it to generate well-structured, hierarchical tables with improved\norganization and clarity. Comprehensive experimental evaluations conducted on\nboth QTabA and RotoWire datasets demonstrate that our DocTabTalk significantly\nenhances the performances of the GPT-4 in our proposed DocTabQA task and the\ntable generation task. The code and dataset are available at\nhttps://github.com/SmileWHC/DocTabQA for further research.", "published": "2024-08-21 10:01:12", "link": "http://arxiv.org/abs/2408.11490v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IKUN for WMT24 General MT Task: LLMs Are here for Multilingual Machine\n  Translation", "abstract": "This paper introduces two multilingual systems, IKUN and IKUN-C, developed\nfor the general machine translation task in WMT24. IKUN and IKUN-C represent an\nopen system and a constrained system, respectively, built on Llama-3-8b and\nMistral-7B-v0.3. Both systems are designed to handle all 11 language directions\nusing a single model. According to automatic evaluation metrics, IKUN-C\nachieved 6 first-place and 3 second-place finishes among all constrained\nsystems, while IKUN secured 1 first-place and 2 second-place finishes across\nboth open and constrained systems. These encouraging results suggest that large\nlanguage models (LLMs) are nearing the level of proficiency required for\neffective multilingual machine translation. The systems are based on a\ntwo-stage approach: first, continuous pre-training on monolingual data in 10\nlanguages, followed by fine-tuning on high-quality parallel data for 11\nlanguage directions. The primary difference between IKUN and IKUN-C lies in\ntheir monolingual pre-training strategy. IKUN-C is pre-trained using\nconstrained monolingual data, whereas IKUN leverages monolingual data from the\nOSCAR dataset. In the second phase, both systems are fine-tuned on parallel\ndata sourced from NTREX, Flores, and WMT16-23 for all 11 language pairs.", "published": "2024-08-21 10:44:10", "link": "http://arxiv.org/abs/2408.11512v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Imagining from Images with an AI Storytelling Tool", "abstract": "A method for generating narratives by analyzing single images or image\nsequences is presented, inspired by the time immemorial tradition of Narrative\nArt. The proposed method explores the multimodal capabilities of GPT-4o to\ninterpret visual content and create engaging stories, which are illustrated by\na Stable Diffusion XL model. The method is supported by a fully implemented\ntool, called ImageTeller, which accepts images from diverse sources as input.\nUsers can guide the narrative's development according to the conventions of\nfundamental genres - such as Comedy, Romance, Tragedy, Satire or Mystery -, opt\nto generate data-driven stories, or to leave the prototype free to decide how\nto handle the narrative structure. User interaction is provided along the\ngeneration process, allowing the user to request alternative chapters or\nillustrations, and even reject and restart the story generation based on the\nsame input. Additionally, users can attach captions to the input images,\ninfluencing the system's interpretation of the visual content. Examples of\ngenerated stories are provided, along with details on how to access the\nprototype.", "published": "2024-08-21 10:49:15", "link": "http://arxiv.org/abs/2408.11517v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Personality Alignment of Large Language Models", "abstract": "Aligning large language models (LLMs) typically aim to reflect general human\nvalues and behaviors, but they often fail to capture the unique characteristics\nand preferences of individual users. To address this gap, we introduce the\nconcept of Personality Alignment. This approach tailors LLMs' responses and\ndecisions to match the specific preferences of individual users or closely\nrelated groups. Inspired by psychometrics, we created the Personality Alignment\nwith Personality Inventories (PAPI) dataset, which includes data from over\n320,000 real subjects across multiple personality assessments, including both\nthe Big Five Personality Factors and Dark Triad traits. This comprehensive\ndataset enables quantitative evaluation of LLMs' alignment capabilities across\nboth positive and potentially problematic personality dimensions. Recognizing\nthe challenges of personality alignments, such as limited personal data,\ndiverse preferences, and scalability requirements, we developed an activation\nintervention optimization method. This method enhances LLMs' ability to\nefficiently align with individual behavioral preferences using minimal data and\ncomputational resources. Remarkably, our method, PAS, achieves superior\nperformance while requiring only 1/5 of the optimization time compared to DPO,\noffering practical value for personality alignment. Our work paves the way for\nfuture AI systems to make decisions and reason in truly personality ways,\nenhancing the relevance and meaning of AI interactions for each user and\nadvancing human-centered artificial intelligence. The dataset and code are\nreleased at https://github.com/zhu-minjun/PAlign.", "published": "2024-08-21 17:09:00", "link": "http://arxiv.org/abs/2408.11779v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Practical token pruning for foundation models in few-shot conversational\n  virtual assistant systems", "abstract": "In an enterprise Virtual Assistant (VA) system, intent classification is the\ncrucial component that determines how a user input is handled based on what the\nuser wants. The VA system is expected to be a cost-efficient SaaS service with\nlow training and inference time while achieving high accuracy even with a small\nnumber of training samples. We pretrain a transformer-based sentence embedding\nmodel with a contrastive learning objective and leverage the embedding of the\nmodel as features when training intent classification models. Our approach\nachieves the state-of-the-art results for few-shot scenarios and performs\nbetter than other commercial solutions on popular intent classification\nbenchmarks. However, generating features via a transformer-based model\nincreases the inference time, especially for longer user inputs, due to the\nquadratic runtime of the transformer's attention mechanism. On top of model\ndistillation, we introduce a practical multi-task adaptation approach that\nconfigures dynamic token pruning without the need for task-specific training\nfor intent classification. We demonstrate that this approach improves the\ninference speed of popular sentence transformer models without affecting model\nperformance.", "published": "2024-08-21 17:42:17", "link": "http://arxiv.org/abs/2408.11799v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WeQA: A Benchmark for Retrieval Augmented Generation in Wind Energy\n  Domain", "abstract": "In the rapidly evolving landscape of Natural Language Processing (NLP) and\ntext generation, the emergence of Retrieval Augmented Generation (RAG) presents\na promising avenue for improving the quality and reliability of generated text\nby leveraging information retrieved from user specified database. Benchmarking\nis essential to evaluate and compare the performance of the different RAG\nconfigurations in terms of retriever and generator, providing insights into\ntheir effectiveness, scalability, and suitability for the specific domain and\napplications. In this paper, we present a comprehensive framework to generate a\ndomain relevant RAG benchmark. Our framework is based on automatic\nquestion-answer generation with Human (domain experts)-AI Large Language Model\n(LLM) teaming. As a case study, we demonstrate the framework by introducing\nWeQA, a first-of-its-kind benchmark on the wind energy domain which comprises\nof multiple scientific documents/reports related to environmental impact of\nwind energy projects. Our framework systematically evaluates RAG performance\nusing diverse metrics and multiple question types with varying complexity\nlevel. We also demonstrate the performance of different models on our\nbenchmark.", "published": "2024-08-21 17:43:11", "link": "http://arxiv.org/abs/2408.11800v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Defining Boundaries: The Impact of Domain Specification on\n  Cross-Language and Cross-Domain Transfer in Machine Translation", "abstract": "Recent advancements in neural machine translation (NMT) have revolutionized\nthe field, yet the dependency on extensive parallel corpora limits progress for\nlow-resource languages and domains. Cross-lingual transfer learning offers a\npromising solution by utilizing data from high-resource languages but often\nstruggles with in-domain NMT. This paper investigates zero-shot cross-lingual\ndomain adaptation for NMT, focusing on the impact of domain specification and\nlinguistic factors on transfer effectiveness. Using English as the source\nlanguage and Spanish for fine-tuning, we evaluate multiple target languages,\nincluding Portuguese, Italian, French, Czech, Polish, and Greek. We demonstrate\nthat both language-specific and domain-specific factors influence transfer\neffectiveness, with domain characteristics playing a crucial role in\ndetermining cross-domain transfer potential. We also explore the feasibility of\nzero-shot cross-lingual cross-domain transfer, providing insights into which\ndomains are more responsive to transfer and why. Our results show the\nimportance of well-defined domain boundaries and transparency in experimental\nsetups for in-domain transfer learning.", "published": "2024-08-21 18:28:48", "link": "http://arxiv.org/abs/2408.11926v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The State of Commercial Automatic French Legal Speech Recognition\n  Systems and their Impact on Court Reporters et al", "abstract": "In Quebec and Canadian courts, the transcription of court proceedings is a\ncritical task for appeal purposes and must be certified by an official court\nreporter. The limited availability of qualified reporters and the high costs\nassociated with manual transcription underscore the need for more efficient\nsolutions. This paper examines the potential of Automatic Speech Recognition\n(ASR) systems to assist court reporters in transcribing legal proceedings. We\nbenchmark three ASR models, including commercial and open-source options, on\ntheir ability to recognize French legal speech using a curated dataset. Our\nstudy evaluates the performance of these systems using the Word Error Rate\n(WER) metric and introduces the Sonnex Distance to account for phonetic\naccuracy. We also explore the broader implications of ASR adoption on court\nreporters, copyists, the legal system, and litigants, identifying both positive\nand negative impacts. The findings suggest that while current ASR systems show\npromise, they require further refinement to meet the specific needs of the\nlegal domain.", "published": "2024-08-21 18:44:28", "link": "http://arxiv.org/abs/2408.11940v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Decoding SEC Actions: Enforcement Trends through Analyzing Blockchain\n  litigation using LLM-based Thematic Factor Mapping", "abstract": "The proliferation of blockchain entities (persons or enterprises) exposes\nthem to potential regulatory actions (e.g., being litigated) by regulatory\nauthorities. Regulatory frameworks for crypto assets are actively being\ndeveloped and refined, increasing the likelihood of such actions. The lack of\nsystematic analysis of the factors driving litigation against blockchain\nentities leaves companies in need of clarity to navigate compliance risks. This\nabsence of insight also deprives investors of the information for informed\ndecision-making. This study focuses on U.S. litigation against blockchain\nentities, particularly by the U.S. Securities and Exchange Commission (SEC)\ngiven its influence on global crypto regulation. Utilizing frontier pretrained\nlanguage models and large language models, we systematically map all SEC\ncomplaints against blockchain companies from 2012 to 2024 to thematic factors\nconceptualized by our study to delineate the factors driving SEC actions. We\nquantify the thematic factors and assess their influence on specific legal Acts\ncited within the complaints on an annual basis, allowing us to discern the\nregulatory emphasis, patterns and conduct trend analysis.", "published": "2024-08-21 19:30:59", "link": "http://arxiv.org/abs/2408.11961v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Models for Page Stream Segmentation", "abstract": "Page Stream Segmentation (PSS) is an essential prerequisite for automated\ndocument processing at scale. However, research progress has been limited by\nthe absence of realistic public benchmarks. This paper works towards addressing\nthis gap by introducing TABME++, an enhanced benchmark featuring commercial\nOptical Character Recognition (OCR) annotations. We evaluate the performance of\nlarge language models (LLMs) on PSS, focusing on decoder-based models\nfine-tuned with parameter-efficient methods. Our results show that\ndecoder-based LLMs outperform smaller multimodal encoders. Through a review of\nexisting PSS research and datasets, we identify key challenges and advancements\nin the field. Our findings highlight the key importance of robust OCR,\nproviding valuable insights for the development of more effective document\nprocessing systems.", "published": "2024-08-21 20:28:42", "link": "http://arxiv.org/abs/2408.11981v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RAG-Optimized Tibetan Tourism LLMs: Enhancing Accuracy and\n  Personalization", "abstract": "With the development of the modern social economy, tourism has become an\nimportant way to meet people's spiritual needs, bringing development\nopportunities to the tourism industry. However, existing large language models\n(LLMs) face challenges in personalized recommendation capabilities and the\ngeneration of content that can sometimes produce hallucinations. This study\nproposes an optimization scheme for Tibet tourism LLMs based on\nretrieval-augmented generation (RAG) technology. By constructing a database of\ntourist viewpoints and processing the data using vectorization techniques, we\nhave significantly improved retrieval accuracy. The application of RAG\ntechnology effectively addresses the hallucination problem in content\ngeneration. The optimized model shows significant improvements in fluency,\naccuracy, and relevance of content generation. This research demonstrates the\npotential of RAG technology in the standardization of cultural tourism\ninformation and data analysis, providing theoretical and technical support for\nthe development of intelligent cultural tourism service systems.", "published": "2024-08-21 21:34:01", "link": "http://arxiv.org/abs/2408.12003v2", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Improving Speech Recognition Error Prediction for Modern and\n  Off-the-shelf Speech Recognizers", "abstract": "Modeling the errors of a speech recognizer can help simulate errorful\nrecognized speech data from plain text, which has proven useful for tasks like\ndiscriminative language modeling, improving robustness of NLP systems, where\nlimited or even no audio data is available at train time. Previous work\ntypically considered replicating behavior of GMM-HMM based systems, but the\nbehavior of more modern posterior-based neural network acoustic models is not\nthe same and requires adjustments to the error prediction model. In this work,\nwe extend a prior phonetic confusion based model for predicting speech\nrecognition errors in two ways: first, we introduce a sampling-based paradigm\nthat better simulates the behavior of a posterior-based acoustic model. Second,\nwe investigate replacing the confusion matrix with a sequence-to-sequence model\nin order to introduce context dependency into the prediction. We evaluate the\nerror predictors in two ways: first by predicting the errors made by a\nSwitchboard ASR system on unseen data (Fisher), and then using that same\npredictor to estimate the behavior of an unrelated cloud-based ASR system on a\nnovel task. Sampling greatly improves predictive accuracy within a 100-guess\nparadigm, while the sequence model performs similarly to the confusion matrix.", "published": "2024-08-21 00:48:03", "link": "http://arxiv.org/abs/2408.11258v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Towards Analyzing and Mitigating Sycophancy in Large Vision-Language\n  Models", "abstract": "Large Vision-Language Models (LVLMs) have shown significant capability in\nvision-language understanding. However, one critical issue that persists in\nthese models is sycophancy, which means models are unduly influenced by leading\nor deceptive prompts, resulting in biased outputs and hallucinations. Despite\nthe progress in LVLMs, evaluating and mitigating sycophancy is yet much\nunder-explored. In this work, we fill this gap by systematically analyzing\nsycophancy on various VL benchmarks with curated leading queries and further\nproposing a text contrastive decoding method for mitigation. While the specific\nsycophantic behavior varies significantly among models, our analysis reveals\nthe severe deficiency of all LVLMs in resilience of sycophancy across various\ntasks. For improvement, we propose Leading Query Contrastive Decoding (LQCD), a\nmodel-agnostic method focusing on calibrating the LVLMs' over-reliance on\nleading cues by identifying and suppressing the probabilities of sycophancy\ntokens at the decoding stage. Extensive experiments show that LQCD effectively\nmitigate sycophancy, outperforming both prompt engineering methods and common\nmethods for hallucination mitigation. We further demonstrate that LQCD does not\nhurt but even slightly improves LVLMs' responses to neutral queries, suggesting\nit being a more effective strategy for general-purpose decoding but not limited\nto sycophancy.", "published": "2024-08-21 01:03:21", "link": "http://arxiv.org/abs/2408.11261v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "RePair: Automated Program Repair with Process-based Feedback", "abstract": "The gap between the trepidation of program reliability and the expense of\nrepairs underscores the indispensability of Automated Program Repair (APR). APR\nis instrumental in transforming vulnerable programs into more robust ones,\nbolstering program reliability while simultaneously diminishing the financial\nburden of manual repairs. Commercial-scale language models (LM) have taken APR\nto unprecedented levels. However, the emergence reveals that for models fewer\nthan 100B parameters, making single-step modifications may be difficult to\nachieve the desired effect. Moreover, humans interact with the LM through\nexplicit prompts, which hinders the LM from receiving feedback from compiler\nand test cases to automatically optimize its repair policies. In this\nliterature, we explore how small-scale LM (less than 20B) achieve excellent\nperformance through process supervision and feedback. We start by constructing\na dataset named CodeNet4Repair, replete with multiple repair records, which\nsupervises the fine-tuning of a foundational model. Building upon the\nencouraging outcomes of reinforcement learning, we develop a reward model that\nserves as a critic, providing feedback for the fine-tuned LM's action,\nprogressively optimizing its policy. During inference, we require the LM to\ngenerate solutions iteratively until the repair effect no longer improves or\nhits the maximum step limit. The results show that process-based not only\noutperforms larger outcome-based generation methods, but also nearly matches\nthe performance of closed-source commercial large-scale LMs.", "published": "2024-08-21 02:53:23", "link": "http://arxiv.org/abs/2408.11296v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "SarcasmBench: Towards Evaluating Large Language Models on Sarcasm\n  Understanding", "abstract": "In the era of large language models (LLMs), the task of ``System I''~-~the\nfast, unconscious, and intuitive tasks, e.g., sentiment analysis, text\nclassification, etc., have been argued to be successfully solved. However,\nsarcasm, as a subtle linguistic phenomenon, often employs rhetorical devices\nlike hyperbole and figuration to convey true sentiments and intentions,\ninvolving a higher level of abstraction than sentiment analysis. There is\ngrowing concern that the argument about LLMs' success may not be fully tenable\nwhen considering sarcasm understanding. To address this question, we select\neleven SOTA LLMs and eight SOTA pre-trained language models (PLMs) and present\ncomprehensive evaluations on six widely used benchmark datasets through\ndifferent prompting approaches, i.e., zero-shot input/output (IO) prompting,\nfew-shot IO prompting, chain of thought (CoT) prompting. Our results highlight\nthree key findings: (1) current LLMs underperform supervised PLMs based sarcasm\ndetection baselines across six sarcasm benchmarks. This suggests that\nsignificant efforts are still required to improve LLMs' understanding of human\nsarcasm. (2) GPT-4 consistently and significantly outperforms other LLMs across\nvarious prompting methods, with an average improvement of 14.0\\%$\\uparrow$.\nClaude 3 and ChatGPT demonstrate the next best performance after GPT-4. (3)\nFew-shot IO prompting method outperforms the other two methods: zero-shot IO\nand few-shot CoT. The reason is that sarcasm detection, being a holistic,\nintuitive, and non-rational cognitive process, is argued not to adhere to\nstep-by-step logical reasoning, making CoT less effective in understanding\nsarcasm compared to its effectiveness in mathematical reasoning tasks.", "published": "2024-08-21 03:59:51", "link": "http://arxiv.org/abs/2408.11319v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Plug, Play, and Fuse: Zero-Shot Joint Decoding via Word-Level Re-ranking\n  Across Diverse Vocabularies", "abstract": "Recent advancements in NLP have resulted in models with specialized\nstrengths, such as processing multimodal inputs or excelling in specific\ndomains. However, real-world tasks, like multimodal translation, often require\na combination of these strengths, such as handling both translation and image\nprocessing. While individual translation and vision models are powerful, they\ntypically lack the ability to perform both tasks in a single system. Combining\nthese models poses challenges, particularly due to differences in their\nvocabularies, which limit the effectiveness of traditional ensemble methods to\npost-generation techniques like N-best list re-ranking. In this work, we\npropose a novel zero-shot ensembling strategy that allows for the integration\nof different models during the decoding phase without the need for additional\ntraining. Our approach re-ranks beams during decoding by combining scores at\nthe word level, using heuristics to predict when a word is completed. We\ndemonstrate the effectiveness of this method in machine translation scenarios,\nshowing that it enables the generation of translations that are both speech-\nand image-aware while also improving overall translation quality (We will\nrelease the code upon paper acceptance.).", "published": "2024-08-21 04:20:55", "link": "http://arxiv.org/abs/2408.11327v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Design Principle Transfer in Neural Architecture Search via Large\n  Language Models", "abstract": "Transferable neural architecture search (TNAS) has been introduced to design\nefficient neural architectures for multiple tasks, to enhance the practical\napplicability of NAS in real-world scenarios. In TNAS, architectural knowledge\naccumulated in previous search processes is reused to warm up the architecture\nsearch for new tasks. However, existing TNAS methods still search in an\nextensive search space, necessitating the evaluation of numerous architectures.\nTo overcome this challenge, this work proposes a novel transfer paradigm, i.e.,\ndesign principle transfer. In this work, the linguistic description of various\nstructural components' effects on architectural performance is termed design\nprinciples. They are learned from established architectures and then can be\nreused to reduce the search space by discarding unpromising architectures.\nSearching in the refined search space can boost both the search performance and\nefficiency for new NAS tasks. To this end, a large language model\n(LLM)-assisted design principle transfer (LAPT) framework is devised. In LAPT,\nLLM is applied to automatically reason the design principles from a set of\ngiven architectures, and then a principle adaptation method is applied to\nrefine these principles progressively based on the new search results.\nExperimental results show that LAPT can beat the state-of-the-art TNAS methods\non most tasks and achieve comparable performance on others.", "published": "2024-08-21 04:27:44", "link": "http://arxiv.org/abs/2408.11330v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "BURExtract-Llama: An LLM for Clinical Concept Extraction in Breast\n  Ultrasound Reports", "abstract": "Breast ultrasound is essential for detecting and diagnosing abnormalities,\nwith radiology reports summarizing key findings like lesion characteristics and\nmalignancy assessments. Extracting this critical information is challenging due\nto the unstructured nature of these reports, with varied linguistic styles and\ninconsistent formatting. While proprietary LLMs like GPT-4 are effective, they\nare costly and raise privacy concerns when handling protected health\ninformation. This study presents a pipeline for developing an in-house LLM to\nextract clinical information from radiology reports. We first use GPT-4 to\ncreate a small labeled dataset, then fine-tune a Llama3-8B model on it.\nEvaluated on clinician-annotated reports, our model achieves an average F1\nscore of 84.6%, which is on par with GPT-4. Our findings demonstrate the\nfeasibility of developing an in-house LLM that not only matches GPT-4's\nperformance but also offers cost reductions and enhanced data privacy.", "published": "2024-08-21 04:33:05", "link": "http://arxiv.org/abs/2408.11334v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Clinical Context-aware Radiology Report Generation from Medical Images\n  using Transformers", "abstract": "Recent developments in the field of Natural Language Processing, especially\nlanguage models such as the transformer have brought state-of-the-art results\nin language understanding and language generation. In this work, we investigate\nthe use of the transformer model for radiology report generation from chest\nX-rays. We also highlight limitations in evaluating radiology report generation\nusing only the standard language generation metrics. We then applied a\ntransformer based radiology report generation architecture, and also compare\nthe performance of a transformer based decoder with the recurrence based\ndecoder. Experiments were performed using the IU-CXR dataset, showing superior\nresults to its LSTM counterpart and being significantly faster. Finally, we\nidentify the need of evaluating radiology report generation system using both\nlanguage generation metrics and classification metrics, which helps to provide\nrobust measure of generated reports in terms of their coherence and diagnostic\nvalue.", "published": "2024-08-21 05:04:25", "link": "http://arxiv.org/abs/2408.11344v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GeoReasoner: Reasoning On Geospatially Grounded Context For Natural\n  Language Understanding", "abstract": "In human reading and communication, individuals tend to engage in geospatial\nreasoning, which involves recognizing geographic entities and making informed\ninferences about their interrelationships. To mimic such cognitive process,\ncurrent methods either utilize conventional natural language understanding\ntoolkits, or directly apply models pretrained on geo-related natural language\ncorpora. However, these methods face two significant challenges: i) they do not\ngeneralize well to unseen geospatial scenarios, and ii) they overlook the\nimportance of integrating geospatial context from geographical databases with\nlinguistic information from the Internet. To handle these challenges, we\npropose GeoReasoner, a language model capable of reasoning on geospatially\ngrounded natural language. Specifically, it first leverages Large Language\nModels (LLMs) to generate a comprehensive location description based on\nlinguistic and geospatial information. It also encodes direction and distance\ninformation into spatial embedding via treating them as pseudo-sentences.\nConsequently, the model is trained on both anchor-level and neighbor-level\ninputs to learn geo-entity representation. Extensive experimental results\ndemonstrate GeoReasoner's superiority in three tasks: toponym recognition,\ntoponym linking, and geo-entity typing, compared to the state-of-the-art\nbaselines.", "published": "2024-08-21 06:35:21", "link": "http://arxiv.org/abs/2408.11366v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "First Activations Matter: Training-Free Methods for Dynamic Activation\n  in Large Language Models", "abstract": "Dynamic activation (DA) techniques, such as DejaVu and MoEfication, have\ndemonstrated their potential to significantly enhance the inference efficiency\nof large language models (LLMs). However, these techniques often rely on ReLU\nactivation functions or require additional parameters and training to maintain\nperformance. This paper introduces a training-free Threshold-based Dynamic\nActivation(TDA) method that leverage sequence information to exploit the\ninherent sparsity of models across various architectures. This method is\ndesigned to accelerate generation speed by 18-25\\% without significantly\ncompromising task performance, thereby addressing the limitations of existing\nDA techniques. Moreover, we delve into the root causes of LLM sparsity and\ntheoretically analyze two of its critical features: history-related activation\nuncertainty and semantic-irrelevant activation inertia. Our comprehensive\nanalyses not only provide a robust theoretical foundation for DA methods but\nalso offer valuable insights to guide future research in optimizing LLMs for\ngreater efficiency and effectiveness.", "published": "2024-08-21 07:38:51", "link": "http://arxiv.org/abs/2408.11393v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards \"Differential AI Psychology\" and in-context Value-driven\n  Statement Alignment with Moral Foundations Theory", "abstract": "Contemporary research in social sciences is increasingly utilizing\nstate-of-the-art statistical language models to annotate or generate content.\nWhile these models perform benchmark-leading on common language tasks and show\nexemplary task-independent emergent abilities, transferring them to novel\nout-of-domain tasks is only insufficiently explored. The implications of the\nstatistical black-box approach - stochastic parrots - are prominently\ncriticized in the language model research community; however, the significance\nfor novel generative tasks is not.\n  This work investigates the alignment between personalized language models and\nsurvey participants on a Moral Foundation Theory questionnaire. We adapt\ntext-to-text models to different political personas and survey the\nquestionnaire repetitively to generate a synthetic population of persona and\nmodel combinations. Analyzing the intra-group variance and cross-alignment\nshows significant differences across models and personas. Our findings indicate\nthat adapted models struggle to represent the survey-captured assessment of\npolitical ideologies. Thus, using language models to mimic social interactions\nrequires measurable improvements in in-context optimization or parameter\nmanipulation to align with psychological and sociological stereotypes. Without\nquantifiable alignment, generating politically nuanced content remains\nunfeasible. To enhance these representations, we propose a testable framework\nto generate agents based on moral value statements for future research.", "published": "2024-08-21 08:20:41", "link": "http://arxiv.org/abs/2408.11415v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Diagnosing and Remedying Knowledge Deficiencies in LLMs via Label-free\n  Curricular Meaningful Learning", "abstract": "Large Language Models (LLMs) are versatile and demonstrate impressive\ngeneralization ability by mining and learning information from extensive\nunlabeled text. However, they still exhibit reasoning mistakes, often stemming\nfrom knowledge deficiencies, which can affect their trustworthiness and\nreliability. Although users can provide diverse and comprehensive queries,\nobtaining sufficient and effective feedback is demanding. Furthermore,\nevaluating LLMs comprehensively with limited labeled samples is difficult. This\nmakes it a challenge to diagnose and remedy the deficiencies of LLMs through\nrich label-free user queries. To tackle this challenge, we propose a label-free\ncurricular meaningful learning framework (LaMer). LaMer first employs relative\nentropy to automatically diagnose and quantify the knowledge deficiencies of\nLLMs in a label-free setting. Next, to remedy the diagnosed knowledge\ndeficiencies, we apply curricular meaningful learning: first, we adopt\nmeaningful learning to adaptively synthesize augmentation data according to the\nseverity of the deficiencies, and then design a curricular deficiency remedy\nstrategy to remedy the knowledge deficiencies of LLMs progressively.\nExperiments show that LaMer efficiently and effectively diagnoses and remedies\nknowledge deficiencies in LLMs, improving various LLMs across seven\nout-of-distribution (OOD) reasoning and language understanding benchmarks,\nachieving comparable results to baselines with just 40\\% training data. LaMer\neven surpasses methods that rely on labeled datasets for deficiency diagnosis.\nIn application, our label-free method can offer an effective knowledge\ndeficiency diagnostic tool for efficient LLM development.", "published": "2024-08-21 08:39:49", "link": "http://arxiv.org/abs/2408.11431v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Differentiating Choices via Commonality for Multiple-Choice Question\n  Answering", "abstract": "Multiple-choice question answering (MCQA) becomes particularly challenging\nwhen all choices are relevant to the question and are semantically similar. Yet\nthis setting of MCQA can potentially provide valuable clues for choosing the\nright answer. Existing models often rank each choice separately, overlooking\nthe context provided by other choices. Specifically, they fail to leverage the\nsemantic commonalities and nuances among the choices for reasoning. In this\npaper, we propose a novel MCQA model by differentiating choices through\nidentifying and eliminating their commonality, called DCQA. Our model captures\ntoken-level attention of each choice to the question, and separates tokens of\nthe question attended to by all the choices (i.e., commonalities) from those by\nindividual choices (i.e., nuances). Using the nuances as refined contexts for\nthe choices, our model can effectively differentiate choices with subtle\ndifferences and provide justifications for choosing the correct answer. We\nconduct comprehensive experiments across five commonly used MCQA benchmarks,\ndemonstrating that DCQA consistently outperforms baseline models. Furthermore,\nour case study illustrates the effectiveness of the approach in directing the\nattention of the model to more differentiating features.", "published": "2024-08-21 12:05:21", "link": "http://arxiv.org/abs/2408.11554v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Drama Engine: A Framework for Narrative Agents", "abstract": "This technical report presents the Drama Engine, a novel framework for\nagentic interaction with large language models designed for narrative purposes.\nThe framework adapts multi-agent system principles to create dynamic,\ncontext-aware companions that can develop over time and interact with users and\neach other. Key features include multi-agent workflows with delegation, dynamic\nprompt assembly, and model-agnostic design. The Drama Engine introduces unique\nelements such as companion development, mood systems, and automatic context\nsummarising. It is implemented in TypeScript. The framework's applications\ninclude multi-agent chats and virtual co-workers for creative writing. The\npaper discusses the system's architecture, prompt assembly process, delegation\nmechanisms, and moderation techniques, as well as potential ethical\nconsiderations and future extensions.", "published": "2024-08-21 12:29:38", "link": "http://arxiv.org/abs/2408.11574v1", "categories": ["cs.AI", "cs.CL", "68T42 (Primary), 68T50 (Secondary)", "I.2.7; J.5"], "primary_category": "cs.AI"}
{"title": "Large Language Models are Good Attackers: Efficient and Stealthy Textual\n  Backdoor Attacks", "abstract": "With the burgeoning advancements in the field of natural language processing\n(NLP), the demand for training data has increased significantly. To save costs,\nit has become common for users and businesses to outsource the labor-intensive\ntask of data collection to third-party entities. Unfortunately, recent research\nhas unveiled the inherent risk associated with this practice, particularly in\nexposing NLP systems to potential backdoor attacks. Specifically, these attacks\nenable malicious control over the behavior of a trained model by poisoning a\nsmall portion of the training data. Unlike backdoor attacks in computer vision,\ntextual backdoor attacks impose stringent requirements for attack stealthiness.\nHowever, existing attack methods meet significant trade-off between\neffectiveness and stealthiness, largely due to the high information entropy\ninherent in textual data. In this paper, we introduce the Efficient and\nStealthy Textual backdoor attack method, EST-Bad, leveraging Large Language\nModels (LLMs). Our EST-Bad encompasses three core strategies: optimizing the\ninherent flaw of models as the trigger, stealthily injecting triggers with\nLLMs, and meticulously selecting the most impactful samples for backdoor\ninjection. Through the integration of these techniques, EST-Bad demonstrates an\nefficient achievement of competitive attack performance while maintaining\nsuperior stealthiness compared to prior methods across various text classifier\ndatasets.", "published": "2024-08-21 12:50:23", "link": "http://arxiv.org/abs/2408.11587v1", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Cause-Aware Empathetic Response Generation via Chain-of-Thought\n  Fine-Tuning", "abstract": "Empathetic response generation endows agents with the capability to\ncomprehend dialogue contexts and react to expressed emotions. Previous works\npredominantly focus on leveraging the speaker's emotional labels, but ignore\nthe importance of emotion cause reasoning in empathetic response generation,\nwhich hinders the model's capacity for further affective understanding and\ncognitive inference. In this paper, we propose a cause-aware empathetic\ngeneration approach by integrating emotions and causes through a well-designed\nChain-of-Thought (CoT) prompt on Large Language Models (LLMs). Our approach can\ngreatly promote LLMs' performance of empathy by instruction tuning and\nenhancing the role awareness of an empathetic listener in the prompt.\nAdditionally, we propose to incorporate cause-oriented external knowledge from\nCOMET into the prompt, which improves the diversity of generation and\nalleviates conflicts between internal and external knowledge at the same time.\nExperimental results on the benchmark dataset demonstrate that our approach on\nLLaMA-7b achieves state-of-the-art performance in both automatic and human\nevaluations.", "published": "2024-08-21 13:11:03", "link": "http://arxiv.org/abs/2408.11599v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Xinyu: An Efficient LLM-based System for Commentary Generation", "abstract": "Commentary provides readers with a deep understanding of events by presenting\ndiverse arguments and evidence. However, creating commentary is a\ntime-consuming task, even for skilled commentators. Large language models\n(LLMs) have simplified the process of natural language generation, but their\ndirect application in commentary creation still faces challenges due to unique\ntask requirements. These requirements can be categorized into two levels: 1)\nfundamental requirements, which include creating well-structured and logically\nconsistent narratives, and 2) advanced requirements, which involve generating\nquality arguments and providing convincing evidence. In this paper, we\nintroduce Xinyu, an efficient LLM-based system designed to assist commentators\nin generating Chinese commentaries. To meet the fundamental requirements, we\ndeconstruct the generation process into sequential steps, proposing targeted\nstrategies and supervised fine-tuning (SFT) for each step. To address the\nadvanced requirements, we present an argument ranking model for arguments and\nestablish a comprehensive evidence database that includes up-to-date events and\nclassic books, thereby strengthening the substantiation of the evidence with\nretrieval augmented generation (RAG) technology. To evaluate the generated\ncommentaries more fairly, corresponding to the two-level requirements, we\nintroduce a comprehensive evaluation metric that considers five distinct\nperspectives in commentary generation. Our experiments confirm the\neffectiveness of our proposed system. We also observe a significant increase in\nthe efficiency of commentators in real-world scenarios, with the average time\nspent on creating a commentary dropping from 4 hours to 20 minutes.\nImportantly, such an increase in efficiency does not compromise the quality of\nthe commentaries.", "published": "2024-08-21 13:34:29", "link": "http://arxiv.org/abs/2408.11609v2", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "FocusLLM: Precise Understanding of Long Context by Dynamic Condensing", "abstract": "Empowering LLMs with the ability to precisely understand long contexts is\ncrucial for many downstream applications. However, handling long contexts with\nconventional transformer architecture requires substantial training and\ninference resources. Existing context condensing methods cannot accurately\nunderstand the full context, as there is a considerable amount of information\nloss in the condensing process. To address these issues, we present FocusLLM, a\nframework designed to extend the fixed context length of any decoder-only LLM,\nallowing the model to focus on relevant information from very long sequences.\nFocusLLM first divides long text input into chunks based on the model's\noriginal context length. It then employs the dynamic condensing process to\ndistill crucial information from each chunk. Ultimately, through the novel\nparallel decoding mechanism, FocusLLM can integrate the extracted information\ninto its local context. FocusLLM stands out for great training efficiency and\nversatility: trained with an 8K input length and with much less training cost\nthan previous methods, FocusLLM exhibits superior performance across downstream\ntasks and maintains strong language modeling ability when handling extensive\nlong texts, even up to 400K tokens. Our code is available at\nhttps://github.com/leezythu/FocusLLM.", "published": "2024-08-21 16:11:59", "link": "http://arxiv.org/abs/2408.11745v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Against All Odds: Overcoming Typology, Script, and Language Confusion in\n  Multilingual Embedding Inversion Attacks", "abstract": "Large Language Models (LLMs) are susceptible to malicious influence by cyber\nattackers through intrusions such as adversarial, backdoor, and embedding\ninversion attacks. In response, the burgeoning field of LLM Security aims to\nstudy and defend against such threats. Thus far, the majority of works in this\narea have focused on monolingual English models, however, emerging research\nsuggests that multilingual LLMs may be more vulnerable to various attacks than\ntheir monolingual counterparts. While previous work has investigated embedding\ninversion over a small subset of European languages, it is challenging to\nextrapolate these findings to languages from different linguistic families and\nwith differing scripts. To this end, we explore the security of multilingual\nLLMs in the context of embedding inversion attacks and investigate\ncross-lingual and cross-script inversion across 20 languages, spanning over 8\nlanguage families and 12 scripts. Our findings indicate that languages written\nin Arabic script and Cyrillic script are particularly vulnerable to embedding\ninversion, as are languages within the Indo-Aryan language family. We further\nobserve that inversion models tend to suffer from language confusion, sometimes\ngreatly reducing the efficacy of an attack. Accordingly, we systematically\nexplore this bottleneck for inversion models, uncovering predictable patterns\nwhich could be leveraged by attackers. Ultimately, this study aims to further\nthe field's understanding of the outstanding security vulnerabilities facing\nmultilingual LLMs and raise awareness for the languages most at risk of\nnegative impact from these attacks.", "published": "2024-08-21 16:16:34", "link": "http://arxiv.org/abs/2408.11749v2", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Leveraging Fine-Tuned Retrieval-Augmented Generation with Long-Context\n  Support: For 3GPP Standards", "abstract": "Recent studies show that large language models (LLMs) struggle with technical\nstandards in telecommunications. We propose a fine-tuned retrieval-augmented\ngeneration (RAG) system based on the Phi-2 small language model (SLM) to serve\nas an oracle for communication networks. Our developed system leverages\nforward-looking semantic chunking to adaptively determine parsing breakpoints\nbased on embedding similarity, enabling effective processing of diverse\ndocument formats. To handle the challenge of multiple similar contexts in\ntechnical standards, we employ a re-ranking algorithm to prioritize the most\nrelevant retrieved chunks. Recognizing the limitations of Phi-2's small context\nwindow, we implement a recent technique, namely SelfExtend, to expand the\ncontext window during inference, which not only boosts the performance but also\ncan accommodate a wider range of user queries and design requirements from\ncustomers to specialized technicians. For fine-tuning, we utilize the low-rank\nadaptation (LoRA) technique to enhance computational efficiency during training\nand enable effective fine-tuning on small datasets. Our comprehensive\nexperiments demonstrate substantial improvements over existing\nquestion-answering approaches in the telecom domain, achieving performance that\nexceeds larger language models such as GPT-4 (which is about 880 times larger\nin size). This work presents a novel approach to leveraging SLMs for\ncommunication networks, offering a balance of efficiency and performance. This\nwork can serve as a foundation towards agentic language models for networks.", "published": "2024-08-21 17:00:05", "link": "http://arxiv.org/abs/2408.11775v2", "categories": ["cs.CL", "cs.NI"], "primary_category": "cs.CL"}
{"title": "Great Memory, Shallow Reasoning: Limits of $k$NN-LMs", "abstract": "$K$-nearest neighbor language models ($k$NN-LMs), which integrate retrieval\nwith next-word prediction, have demonstrated strong performance in language\nmodeling as well as downstream NLP benchmarks. These results have led\nresearchers to argue that models trained on poor quality or outdated data could\nperform well by employing a $k$NN extension that has access to a higher-quality\ndatastore. In this work, we ask whether this improved ability to recall\ninformation really translates into downstream abilities. We extensively\nevaluate $k$NN-LMs on a diverse set of tasks, ranging from sentiment\nclassification and commonsense reasoning to multi-hop reasoning. Results show\nthat $k$NN-LMs excel at memory-intensive tasks, where utilizing the patterns in\nthe input is sufficient for determining the output, but struggle with reasoning\ntasks that require integrating multiple pieces of information to derive new\nknowledge. We further demonstrate through oracle experiments and qualitative\nanalysis that even with perfect retrieval, $k$NN-LMs still fail to determine\nthe correct answers, placing an upper bound on their reasoning performance.\nCode and datastores are released at https://github.com/GSYfate/knnlm-limits/.", "published": "2024-08-21 17:59:05", "link": "http://arxiv.org/abs/2408.11815v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Characterizing Online Toxicity During the 2022 Mpox Outbreak: A\n  Computational Analysis of Topical and Network Dynamics", "abstract": "Background: Online toxicity, encompassing behaviors such as harassment,\nbullying, hate speech, and the dissemination of misinformation, has become a\npressing social concern in the digital age. The 2022 Mpox outbreak, initially\ntermed \"Monkeypox\" but subsequently renamed to mitigate associated stigmas and\nsocietal concerns, serves as a poignant backdrop to this issue. Objective: In\nthis research, we undertake a comprehensive analysis of the toxic online\ndiscourse surrounding the 2022 Mpox outbreak. Our objective is to dissect its\norigins, characterize its nature and content, trace its dissemination patterns,\nand assess its broader societal implications, with the goal of providing\ninsights that can inform strategies to mitigate such toxicity in future crises.\nMethods: We collected more than 1.6 million unique tweets and analyzed them\nfrom five dimensions, including context, extent, content, speaker, and intent.\nUtilizing BERT-based topic modeling and social network community clustering, we\ndelineated the toxic dynamics on Twitter. Results: We identified five\nhigh-level topic categories in the toxic online discourse on Twitter, including\ndisease (46.6%), health policy and healthcare (19.3%), homophobia (23.9%),\npolitics (6.0%), and racism (4.1%). Through the toxicity diffusion networks of\nmentions, retweets, and the top users, we found that retweets of toxic content\nwere widespread, while influential users rarely engaged with or countered this\ntoxicity through retweets. Conclusions: By tracking topical dynamics, we can\ntrack the changing popularity of toxic content online, providing a better\nunderstanding of societal challenges. Network dynamics spotlight key social\nmedia influencers and their intents, indicating that addressing these central\nfigures in toxic discourse can enhance crisis communication and inform\npolicy-making.", "published": "2024-08-21 19:31:01", "link": "http://arxiv.org/abs/2408.11962v3", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Understanding Epistemic Language with a Bayesian Theory of Mind", "abstract": "How do people understand and evaluate claims about others' beliefs, even\nthough these beliefs cannot be directly observed? In this paper, we introduce a\ncognitive model of epistemic language interpretation, grounded in Bayesian\ninferences about other agents' goals, beliefs, and intentions: a\nlanguage-augmented Bayesian theory-of-mind (LaBToM). By translating natural\nlanguage into an epistemic ``language-of-thought'', then evaluating these\ntranslations against the inferences produced by inverting a probabilistic\ngenerative model of rational action and perception, LaBToM captures graded\nplausibility judgments about epistemic claims. We validate our model in an\nexperiment where participants watch an agent navigate a maze to find keys\nhidden in boxes needed to reach their goal, then rate sentences about the\nagent's beliefs. In contrast with multimodal LLMs (GPT-4o, Gemini Pro) and\nablated models, our model correlates highly with human judgments for a wide\nrange of expressions, including modal language, uncertainty expressions,\nknowledge claims, likelihood comparisons, and attributions of false belief.", "published": "2024-08-21 22:29:56", "link": "http://arxiv.org/abs/2408.12022v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SORSA: Singular Values and Orthonormal Regularized Singular Vectors\n  Adaptation of Large Language Models", "abstract": "In this paper, we propose Singular Values and Orthonormal Regularized\nSingular Vectors Adaptation, or SORSA, a novel PEFT method. Each SORSA adapter\nconsists of two main parts: trainable principal singular weights $W_p = U_p\n\\text{diag}(S_p) V^\\top_p$, and frozen residual weights $W_r = U_r\n\\text{diag}(S_r) V^\\top_r$. These parts are initialized by performing singular\nvalue decomposition (SVD) on pre-trained weights. Moreover, we implement and\nanalyze an orthonormal regularizer, which we prove could decrease the condition\nnumber of $W_p$ and make the optimization more efficient. SORSA adapters could\nbe merged during inference, thus eliminating any inference latency. We also\nintroduce a method to analyze the variation of the parameters by performing SVD\nand discuss and analyze SORSA's superiority in minimizing the alteration in the\nSVD aspect. After all, SORSA shows a faster convergence than LoRA and PiSSA in\nour experiments. On the GSM-8K benchmark, Llama 2 7B adapted using SORSA\nachieved 56.03% accuracy, surpassing LoRA (42.30%), AdaLoRA (47.30%), Full FT\n(49.05%), and PiSSA (53.07%). On the MATH benchmark, SORSA achieved 10.36%\naccuracy, outperforming LoRA (5.50%), AdaLoRA (6.48%), Full FT (7.22%), and\nPiSSA (7.44%). We conclude that SORSA offers a new perspective on\nparameter-efficient fine-tuning, demonstrating remarkable performance.", "published": "2024-08-21 04:47:26", "link": "http://arxiv.org/abs/2409.00055v5", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "EEG-Defender: Defending against Jailbreak through Early Exit Generation\n  of Large Language Models", "abstract": "Large Language Models (LLMs) are increasingly attracting attention in various\napplications. Nonetheless, there is a growing concern as some users attempt to\nexploit these models for malicious purposes, including the synthesis of\ncontrolled substances and the propagation of disinformation. In an effort to\nmitigate such risks, the concept of \"Alignment\" technology has been developed.\nHowever, recent studies indicate that this alignment can be undermined using\nsophisticated prompt engineering or adversarial suffixes, a technique known as\n\"Jailbreak.\" Our research takes cues from the human-like generate process of\nLLMs. We identify that while jailbreaking prompts may yield output logits\nsimilar to benign prompts, their initial embeddings within the model's latent\nspace tend to be more analogous to those of malicious prompts. Leveraging this\nfinding, we propose utilizing the early transformer outputs of LLMs as a means\nto detect malicious inputs, and terminate the generation immediately. Built\nupon this idea, we introduce a simple yet significant defense approach called\nEEG-Defender for LLMs. We conduct comprehensive experiments on ten jailbreak\nmethods across three models. Our results demonstrate that EEG-Defender is\ncapable of reducing the Attack Success Rate (ASR) by a significant margin,\nroughly 85\\% in comparison with 50\\% for the present SOTAs, with minimal impact\non the utility and effectiveness of LLMs.", "published": "2024-08-21 03:25:31", "link": "http://arxiv.org/abs/2408.11308v1", "categories": ["cs.AI", "cs.CL", "cs.CR"], "primary_category": "cs.AI"}
{"title": "Memorization in In-Context Learning", "abstract": "In-context learning (ICL) has proven to be an effective strategy for\nimproving the performance of large language models (LLMs) with no additional\ntraining. However, the exact mechanism behind this performance improvement\nremains unclear. This study is the first to show how ICL surfaces memorized\ntraining data and to explore the correlation between this memorization and\nperformance on downstream tasks across various ICL regimes: zero-shot,\nfew-shot, and many-shot. Our most notable findings include: (1) ICL\nsignificantly surfaces memorization compared to zero-shot learning in most\ncases; (2) demonstrations, without their labels, are the most effective element\nin surfacing memorization; (3) ICL improves performance when the surfaced\nmemorization in few-shot regimes reaches a high level (about 40%); and (4)\nthere is a very strong correlation between performance and memorization in ICL\nwhen it outperforms zero-shot learning. Overall, our study uncovers\nmemorization as a new factor impacting ICL, raising an important question: to\nwhat extent do LLMs truly generalize from demonstrations in ICL, and how much\nof their success is due to memorization?", "published": "2024-08-21 11:54:22", "link": "http://arxiv.org/abs/2408.11546v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Efficient Detection of Toxic Prompts in Large Language Models", "abstract": "Large language models (LLMs) like ChatGPT and Gemini have significantly\nadvanced natural language processing, enabling various applications such as\nchatbots and automated content generation. However, these models can be\nexploited by malicious individuals who craft toxic prompts to elicit harmful or\nunethical responses. These individuals often employ jailbreaking techniques to\nbypass safety mechanisms, highlighting the need for robust toxic prompt\ndetection methods. Existing detection techniques, both blackbox and whitebox,\nface challenges related to the diversity of toxic prompts, scalability, and\ncomputational efficiency. In response, we propose ToxicDetector, a lightweight\ngreybox method designed to efficiently detect toxic prompts in LLMs.\nToxicDetector leverages LLMs to create toxic concept prompts, uses embedding\nvectors to form feature vectors, and employs a Multi-Layer Perceptron (MLP)\nclassifier for prompt classification. Our evaluation on various versions of the\nLLama models, Gemma-2, and multiple datasets demonstrates that ToxicDetector\nachieves a high accuracy of 96.39\\% and a low false positive rate of 2.00\\%,\noutperforming state-of-the-art methods. Additionally, ToxicDetector's\nprocessing time of 0.0780 seconds per prompt makes it highly suitable for\nreal-time applications. ToxicDetector achieves high accuracy, efficiency, and\nscalability, making it a practical method for toxic prompt detection in LLMs.", "published": "2024-08-21 15:54:04", "link": "http://arxiv.org/abs/2408.11727v2", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.SE"], "primary_category": "cs.CR"}
{"title": "DreamFactory: Pioneering Multi-Scene Long Video Generation with a\n  Multi-Agent Framework", "abstract": "Current video generation models excel at creating short, realistic clips, but\nstruggle with longer, multi-scene videos. We introduce \\texttt{DreamFactory},\nan LLM-based framework that tackles this challenge. \\texttt{DreamFactory}\nleverages multi-agent collaboration principles and a Key Frames Iteration\nDesign Method to ensure consistency and style across long videos. It utilizes\nChain of Thought (COT) to address uncertainties inherent in large language\nmodels. \\texttt{DreamFactory} generates long, stylistically coherent, and\ncomplex videos. Evaluating these long-form videos presents a challenge. We\npropose novel metrics such as Cross-Scene Face Distance Score and Cross-Scene\nStyle Consistency Score. To further research in this area, we contribute the\nMulti-Scene Videos Dataset containing over 150 human-rated videos.", "published": "2024-08-21 17:21:13", "link": "http://arxiv.org/abs/2408.11788v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.SE", "TsingHua University"], "primary_category": "cs.AI"}
{"title": "LLM Pruning and Distillation in Practice: The Minitron Approach", "abstract": "We present a comprehensive report on compressing the Llama 3.1 8B and Mistral\nNeMo 12B models to 4B and 8B parameters, respectively, using pruning and\ndistillation. We explore two distinct pruning strategies: (1) depth pruning and\n(2) joint hidden/attention/MLP (width) pruning, and evaluate the results on\ncommon benchmarks from the LM Evaluation Harness. The models are then aligned\nwith NeMo Aligner and tested in instruct-tuned versions. This approach produces\na compelling 4B model from Llama 3.1 8B and a state-of-the-art\nMistral-NeMo-Minitron-8B (MN-Minitron-8B for brevity) model from Mistral NeMo\n12B. We found that with no access to the original data, it is beneficial to\nslightly fine-tune teacher models on the distillation dataset. We open-source\nour base model weights on Hugging Face with a permissive license.", "published": "2024-08-21 17:38:48", "link": "http://arxiv.org/abs/2408.11796v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Ancient Wisdom, Modern Tools: Exploring Retrieval-Augmented LLMs for\n  Ancient Indian Philosophy", "abstract": "LLMs have revolutionized the landscape of information retrieval and knowledge\ndissemination. However, their application in specialized areas is often\nhindered by factual inaccuracies and hallucinations, especially in long-tail\nknowledge distributions. We explore the potential of retrieval-augmented\ngeneration (RAG) models for long-form question answering (LFQA) in a\nspecialized knowledge domain. We present VedantaNY-10M, a dataset curated from\nextensive public discourses on the ancient Indian philosophy of Advaita\nVedanta. We develop and benchmark a RAG model against a standard, non-RAG LLM,\nfocusing on transcription, retrieval, and generation performance. Human\nevaluations by computational linguists and domain experts show that the RAG\nmodel significantly outperforms the standard model in producing factual and\ncomprehensive responses having fewer hallucinations. In addition, a\nkeyword-based hybrid retriever that emphasizes unique low-frequency terms\nfurther improves results. Our study provides insights into effectively\nintegrating modern large language models with ancient knowledge systems.\nProject page with dataset and code: https://sites.google.com/view/vedantany-10m", "published": "2024-08-21 18:00:21", "link": "http://arxiv.org/abs/2408.11903v2", "categories": ["cs.CL", "cs.CY", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Limitations in Employing Natural Language Supervision for Sensor-Based\n  Human Activity Recognition -- And Ways to Overcome Them", "abstract": "Cross-modal contrastive pre-training between natural language and other\nmodalities, e.g., vision and audio, has demonstrated astonishing performance\nand effectiveness across a diverse variety of tasks and domains. In this paper,\nwe investigate whether such natural language supervision can be used for\nwearable sensor based Human Activity Recognition (HAR), and discover\nthat-surprisingly-it performs substantially worse than standard end-to-end\ntraining and self-supervision. We identify the primary causes for this as:\nsensor heterogeneity and the lack of rich, diverse text descriptions of\nactivities. To mitigate their impact, we also develop strategies and assess\ntheir effectiveness through an extensive experimental evaluation. These\nstrategies lead to significant increases in activity recognition, bringing\nperformance closer to supervised and self-supervised training, while also\nenabling the recognition of unseen activities and cross modal retrieval of\nvideos. Overall, our work paves the way for better sensor-language learning,\nultimately leading to the development of foundational models for HAR using\nwearables.", "published": "2024-08-21 22:30:36", "link": "http://arxiv.org/abs/2408.12023v1", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Let Community Rules Be Reflected in Online Content Moderation", "abstract": "Content moderation is a widely used strategy to prevent the dissemination of\nirregular information on social media platforms. Despite extensive research on\ndeveloping automated models to support decision-making in content moderation,\nthere remains a notable scarcity of studies that integrate the rules of online\ncommunities into content moderation. This study addresses this gap by proposing\na community rule-based content moderation framework that directly integrates\ncommunity rules into the moderation of user-generated content. Our experiment\nresults with datasets collected from two domains demonstrate the superior\nperformance of models based on the framework to baseline models across all\nevaluation metrics. In particular, incorporating community rules substantially\nenhances model performance in content moderation. The findings of this research\nhave significant research and practical implications for improving the\neffectiveness and generalizability of content moderation models in online\ncommunities.", "published": "2024-08-21 23:38:02", "link": "http://arxiv.org/abs/2408.12035v1", "categories": ["cs.SI", "cs.CL", "cs.LG", "cs.MM"], "primary_category": "cs.SI"}
{"title": "Reasoning and Tools for Human-Level Forecasting", "abstract": "Language models (LMs) trained on web-scale datasets are largely successful\ndue to their ability to memorize large amounts of training data, even if only\npresent in a few examples. These capabilities are often desirable in evaluation\non tasks such as question answering but raise questions about whether these\nmodels can exhibit genuine reasoning or succeed only at mimicking patterns from\nthe training data. This distinction is particularly salient in forecasting\ntasks, where the answer is not present in the training data, and the model must\nreason to make logical deductions. We present Reasoning and Tools for\nForecasting (RTF), a framework of reasoning-and-acting (ReAct) agents that can\ndynamically retrieve updated information and run numerical simulation with\nequipped tools. We evaluate our model with questions from competitive\nforecasting platforms and demonstrate that our method is competitive with and\ncan outperform human predictions. This suggests that LMs, with the right tools,\ncan indeed think and adapt like humans, offering valuable insights for\nreal-world decision-making.", "published": "2024-08-21 23:42:06", "link": "http://arxiv.org/abs/2408.12036v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Improving Query-by-Vocal Imitation with Contrastive Learning and Audio\n  Pretraining", "abstract": "Query-by-Vocal Imitation (QBV) is about searching audio files within\ndatabases using vocal imitations created by the user's voice. Since most humans\ncan effectively communicate sound concepts through voice, QBV offers the more\nintuitive and convenient approach compared to text-based search. To fully\nleverage QBV, developing robust audio feature representations for both the\nvocal imitation and the original sound is crucial. In this paper, we present a\nnew system for QBV that utilizes the feature extraction capabilities of\nConvolutional Neural Networks pre-trained with large-scale general-purpose\naudio datasets. We integrate these pre-trained models into a dual encoder\narchitecture and fine-tune them end-to-end using contrastive learning. A\ndistinctive aspect of our proposed method is the fine-tuning strategy of\npre-trained models using an adapted NT-Xent loss for contrastive learning,\ncreating a shared embedding space for reference recordings and vocal\nimitations. The proposed system significantly enhances audio retrieval\nperformance, establishing a new state of the art on both coarse- and\nfine-grained QBV tasks.", "published": "2024-08-21 14:07:06", "link": "http://arxiv.org/abs/2408.11638v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "DDSP Guitar Amp: Interpretable Guitar Amplifier Modeling", "abstract": "Neural network models for guitar amplifier emulation, while being effective,\noften demand high computational cost and lack interpretability. Drawing ideas\nfrom physical amplifier design, this paper aims to address these issues with a\nnew differentiable digital signal processing (DDSP)-based model, called ``DDSP\nguitar amp,'' that models the four components of a guitar amp (i.e., preamp,\ntone stack, power amp, and output transformer) using specific DSP-inspired\ndesigns. With a set of time- and frequency-domain metrics, we demonstrate that\nDDSP guitar amp achieves performance comparable with that of black-box\nbaselines while requiring less than 10\\% of the computational operations per\naudio sample, thereby holding greater potential for usages in real-time\napplications.", "published": "2024-08-21 08:03:42", "link": "http://arxiv.org/abs/2408.11405v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Improvement Speaker Similarity for Zero-Shot Any-to-Any Voice Conversion\n  of Whispered and Regular Speech", "abstract": "Zero-shot voice conversion aims to transfer the voice of a source speaker to\nthat of a speaker unseen during training, while preserving the content\ninformation. Although various methods have been proposed to reconstruct speaker\ninformation in generated speech, there is still room for improvement in\nachieving high similarity between generated and ground truth recordings.\nFurthermore, zero-shot voice conversion for speech in specific domains, such as\nwhispered, remains an unexplored area. To address this problem, we propose a\nSpeakerVC model that can effectively perform zero-shot speech conversion in\nboth voiced and whispered domains, while being lightweight and capable of\nrunning in streaming mode without significant quality degradation. In addition,\nwe explore methods to improve the quality of speaker identity transfer and\ndemonstrate their effectiveness for a variety of voice conversion systems.", "published": "2024-08-21 11:09:48", "link": "http://arxiv.org/abs/2408.11528v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Joint Noise Disentanglement and Adversarial Training Framework for\n  Robust Speaker Verification", "abstract": "Automatic Speaker Verification (ASV) suffers from performance degradation in\nnoisy conditions. To address this issue, we propose a novel adversarial\nlearning framework that incorporates noise-disentanglement to establish a\nnoise-independent speaker invariant embedding space. Specifically, the\ndisentanglement module includes two encoders for separating speaker related and\nirrelevant information, respectively. The reconstruction module serves as a\nregularization term to constrain the noise. A feature-robust loss is also used\nto supervise the speaker encoder to learn noise-independent speaker embeddings\nwithout losing speaker information. In addition, adversarial training is\nintroduced to discourage the speaker encoder from encoding acoustic condition\ninformation for achieving a speaker-invariant embedding space. Experiments on\nVoxCeleb1 indicate that the proposed method improves the performance of the\nspeaker verification system under both clean and noisy conditions.", "published": "2024-08-21 12:16:34", "link": "http://arxiv.org/abs/2408.11562v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "The Whole Is Bigger Than the Sum of Its Parts: Modeling Individual\n  Annotators to Capture Emotional Variability", "abstract": "Emotion expression and perception are nuanced, complex, and highly subjective\nprocesses. When multiple annotators label emotional data, the resulting labels\ncontain high variability. Most speech emotion recognition tasks address this by\naveraging annotator labels as ground truth. However, this process omits the\nnuance of emotion and inter-annotator variability, which are important signals\nto capture. Previous work has attempted to learn distributions to capture\nemotion variability, but these methods also lose information about the\nindividual annotators. We address these limitations by learning to predict\nindividual annotators and by introducing a novel method to create distributions\nfrom continuous model outputs that permit the learning of emotion distributions\nduring model training. We show that this combined approach can result in\nemotion distributions that are more accurate than those seen in prior work, in\nboth within- and cross-corpus settings.", "published": "2024-08-21 19:24:06", "link": "http://arxiv.org/abs/2408.11956v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "MCDubber: Multimodal Context-Aware Expressive Video Dubbing", "abstract": "Automatic Video Dubbing (AVD) aims to take the given script and generate\nspeech that aligns with lip motion and prosody expressiveness. Current AVD\nmodels mainly utilize visual information of the current sentence to enhance the\nprosody of synthesized speech. However, it is crucial to consider whether the\nprosody of the generated dubbing aligns with the multimodal context, as the\ndubbing will be combined with the original context in the final video. This\naspect has been overlooked in previous studies. To address this issue, we\npropose a Multimodal Context-aware video Dubbing model, termed\n\\textbf{MCDubber}, to convert the modeling object from a single sentence to a\nlonger sequence with context information to ensure the consistency of the\nglobal context prosody. MCDubber comprises three main components: (1) A context\nduration aligner aims to learn the context-aware alignment between the text and\nlip frames; (2) A context prosody predictor seeks to read the global context\nvisual sequence and predict the context-aware global energy and pitch; (3) A\ncontext acoustic decoder ultimately predicts the global context mel-spectrogram\nwith the assistance of adjacent ground-truth mel-spectrograms of the target\nsentence. Through this process, MCDubber fully considers the influence of\nmultimodal context on the prosody expressiveness of the current sentence when\ndubbing. The extracted mel-spectrogram belonging to the target sentence from\nthe output context mel-spectrograms is the final required dubbing audio.\nExtensive experiments on the Chem benchmark dataset demonstrate that our\nMCDubber significantly improves dubbing expressiveness compared to all advanced\nbaselines. The code and demos are available at\nhttps://github.com/XiaoYuanJun-zy/MCDubber.", "published": "2024-08-21 12:59:42", "link": "http://arxiv.org/abs/2408.11593v3", "categories": ["cs.MM", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "Estimated Audio-Caption Correspondences Improve Language-Based Audio\n  Retrieval", "abstract": "Dual-encoder-based audio retrieval systems are commonly optimized with\ncontrastive learning on a set of matching and mismatching audio-caption pairs.\nThis leads to a shared embedding space in which corresponding items from the\ntwo modalities end up close together. Since audio-caption datasets typically\nonly contain matching pairs of recordings and descriptions, it has become\ncommon practice to create mismatching pairs by pairing the audio with a caption\nrandomly drawn from the dataset. This is not ideal because the randomly sampled\ncaption could, just by chance, partly or entirely describe the audio recording.\nHowever, correspondence information for all possible pairs is costly to\nannotate and thus typically unavailable; we, therefore, suggest substituting it\nwith estimated correspondences. To this end, we propose a two-staged training\nprocedure in which multiple retrieval models are first trained as usual, i.e.,\nwithout estimated correspondences. In the second stage, the audio-caption\ncorrespondences predicted by these models then serve as prediction targets. We\nevaluate our method on the ClothoV2 and the AudioCaps benchmark and show that\nit improves retrieval performance, even in a restricting self-distillation\nsetting where a single model generates and then learns from the estimated\ncorrespondences. We further show that our method outperforms the current state\nof the art by 1.6 pp. mAP@10 on the ClothoV2 benchmark.", "published": "2024-08-21 14:10:58", "link": "http://arxiv.org/abs/2408.11641v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Prosody of speech production in latent post-stroke aphasia", "abstract": "This study explores prosodic production in latent aphasia, a mild form of\naphasia associated with left-hemisphere brain damage (e.g. stroke). Unlike\nprior research on moderate to severe aphasia, we investigated latent aphasia,\nwhich can seem to have very similar speech production with neurotypical speech.\nWe analysed the f0, intensity and duration of utterance-initial and\nutterance-final words of ten speakers with latent aphasia and ten matching\ncontrols. Regression models were fitted to improve our understanding of this\nunderstudied type of very mild aphasia. The results highlighted varying degrees\nof differences in all three prosodic measures between groups. We also\ninvestigated the diagnostic classification of latent aphasia versus\nneurotypical control using random forest, aiming to build a fast and reliable\ntool to assist with the identification of latent aphasia. The random forest\nanalysis also reinforced the significance of prosodic features in\ndistinguishing latent aphasia.", "published": "2024-08-21 11:33:43", "link": "http://arxiv.org/abs/2408.11882v2", "categories": ["q-bio.NC", "cs.SD", "eess.AS", "q-bio.QM"], "primary_category": "q-bio.NC"}
{"title": "Near-Field Signal Processing: Unleashing the Power of Proximity", "abstract": "After nearly a century of specialized applications in optics, remote sensing,\nand acoustics, the near-field (NF) electromagnetic propagation zone is\nexperiencing a resurgence in research interest. This renewed attention is\nfueled by the emergence of promising applications in various fields such as\nwireless communications, holography, medical imaging, and quantum-inspired\nsystems. Signal processing within NF sensing and wireless communications\nenvironments entails addressing issues related to extended scatterers,\nrange-dependent beampatterns, spherical wavefronts, mutual coupling effects,\nand the presence of both reactive and radiative fields. Recent investigations\nhave focused on these aspects in the context of extremely large arrays and wide\nbandwidths, giving rise to novel challenges in channel estimation, beamforming,\nbeam training, sensing, and localization. While NF optics has a longstanding\nhistory, advancements in NF phase retrieval techniques and their applications\nhave lately garnered significant research attention. Similarly, utilizing NF\nlocalization with acoustic arrays represents a contemporary extension of\nestablished principles in NF acoustic array signal processing. This article\naims to provide an overview of state-of-the-art signal processing techniques\nwithin the NF domain, offering a comprehensive perspective on recent advances\nin diverse applications.", "published": "2024-08-21 08:44:21", "link": "http://arxiv.org/abs/2408.11434v2", "categories": ["eess.SP", "cs.IT", "cs.SD", "eess.AS", "math.IT"], "primary_category": "eess.SP"}
{"title": "Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event\n  Condition For Foley Sound", "abstract": "Foley sound synthesis is crucial for multimedia production, enhancing user\nexperience by synchronizing audio and video both temporally and semantically.\nRecent studies on automating this labor-intensive process through\nvideo-to-sound generation face significant challenges. Systems lacking explicit\ntemporal features suffer from poor alignment and controllability, while\ntimestamp-based models require costly and subjective human annotation. We\npropose Video-Foley, a video-to-sound system using Root Mean Square (RMS) as an\nintuitive condition with semantic timbre prompts (audio or text). RMS, a\nframe-level intensity envelope closely related to audio semantics, acts as a\ntemporal event feature to guide audio generation from video. The\nannotation-free self-supervised learning framework consists of two stages,\nVideo2RMS and RMS2Sound, incorporating novel ideas including RMS discretization\nand RMS-ControlNet with a pretrained text-to-audio model. Our extensive\nevaluation shows that Video-Foley achieves state-of-the-art performance in\naudio-visual alignment and controllability for sound timing, intensity, timbre,\nand nuance. Source code, model weights and demos are available on our companion\nwebsite. (https://jnwnlee.github.io/video-foley-demo)", "published": "2024-08-21 18:06:15", "link": "http://arxiv.org/abs/2408.11915v2", "categories": ["cs.SD", "cs.CV", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
