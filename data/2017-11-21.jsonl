{"title": "Event Representations with Tensor-based Compositions", "abstract": "Robust and flexible event representations are important to many core areas in\nlanguage understanding. Scripts were proposed early on as a way of representing\nsequences of events for such understanding, and has recently attracted renewed\nattention. However, obtaining effective representations for modeling\nscript-like event sequences is challenging. It requires representations that\ncan capture event-level and scenario-level semantics. We propose a new\ntensor-based composition method for creating event representations. The method\ncaptures more subtle semantic interactions between an event and its entities\nand yields representations that are effective at multiple event-related tasks.\nWith the continuous representations, we also devise a simple schema generation\nmethod which produces better schemas compared to a prior discrete\nrepresentation based method. Our analysis shows that the tensors capture\ndistinct usages of a predicate even when there are only subtle differences in\ntheir surface realizations.", "published": "2017-11-21 03:04:02", "link": "http://arxiv.org/abs/1711.07611v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Machine Translation Performance on Chinese Idioms with a\n  Blacklist Method", "abstract": "Idiom translation is a challenging problem in machine translation because the\nmeaning of idioms is non-compositional, and a literal (word-by-word)\ntranslation is likely to be wrong. In this paper, we focus on evaluating the\nquality of idiom translation of MT systems. We introduce a new evaluation\nmethod based on an idiom-specific blacklist of literal translations, based on\nthe insight that the occurrence of any blacklisted words in the translation\noutput indicates a likely translation error. We introduce a dataset, CIBB\n(Chinese Idioms Blacklists Bank), and perform an evaluation of a\nstate-of-the-art Chinese-English neural MT system. Our evaluation confirms that\na sizable number of idioms in our test set are mistranslated (46.1%), that\nliteral translation error is a common error type, and that our blacklist method\nis effective at identifying literal translation errors.", "published": "2017-11-21 06:34:06", "link": "http://arxiv.org/abs/1711.07646v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Effective Strategies in Zero-Shot Neural Machine Translation", "abstract": "In this paper, we proposed two strategies which can be applied to a\nmultilingual neural machine translation system in order to better tackle\nzero-shot scenarios despite not having any parallel corpus. The experiments\nshow that they are effective in terms of both performance and computing\nresources, especially in multilingual translation of unbalanced data in real\nzero-resourced condition when they alleviate the language bias problem.", "published": "2017-11-21 16:39:21", "link": "http://arxiv.org/abs/1711.07893v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Effective Use of Bidirectional Language Modeling for Transfer Learning\n  in Biomedical Named Entity Recognition", "abstract": "Biomedical named entity recognition (NER) is a fundamental task in text\nmining of medical documents and has many applications. Deep learning based\napproaches to this task have been gaining increasing attention in recent years\nas their parameters can be learned end-to-end without the need for\nhand-engineered features. However, these approaches rely on high-quality\nlabeled data, which is expensive to obtain. To address this issue, we\ninvestigate how to use unlabeled text data to improve the performance of NER\nmodels. Specifically, we train a bidirectional language model (BiLM) on\nunlabeled data and transfer its weights to \"pretrain\" an NER model with the\nsame architecture as the BiLM, which results in a better parameter\ninitialization of the NER model. We evaluate our approach on four benchmark\ndatasets for biomedical NER and show that it leads to a substantial improvement\nin the F1 scores compared with the state-of-the-art approaches. We also show\nthat BiLM weight transfer leads to a faster model training and the pretrained\nmodel requires fewer training examples to achieve a particular F1 score.", "published": "2017-11-21 16:55:18", "link": "http://arxiv.org/abs/1711.07908v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "10Sent: A Stable Sentiment Analysis Method Based on the Combination of\n  Off-The-Shelf Approaches", "abstract": "Sentiment analysis has become a very important tool for analysis of social\nmedia data. There are several methods developed for this research field, many\nof them working very differently from each other, covering distinct aspects of\nthe problem and disparate strategies. Despite the large number of existent\ntechniques, there is no single one which fits well in all cases or for all data\nsources. Supervised approaches may be able to adapt to specific situations but\nthey require manually labeled training, which is very cumbersome and expensive\nto acquire, mainly for a new application. In this context, in here, we propose\nto combine several very popular and effective state-of-the-practice sentiment\nanalysis methods, by means of an unsupervised bootstrapped strategy for\npolarity classification. One of our main goals is to reduce the large\nvariability (lack of stability) of the unsupervised methods across different\ndomains (datasets). Our solution was thoroughly tested considering thirteen\ndifferent datasets in several domains such as opinions, comments, and social\nmedia. The experimental results demonstrate that our combined method (aka,\n10SENT) improves the effectiveness of the classification task, but more\nimportantly, it solves a key problem in the field. It is consistently among the\nbest methods in many data types, meaning that it can produce the best (or close\nto best) results in almost all considered contexts, without any additional\ncosts (e.g., manual labeling). Our self-learning approach is also very\nindependent of the base methods, which means that it is highly extensible to\nincorporate any new additional method that can be envisioned in the future.\nFinally, we also investigate a transfer learning approach for sentiment\nanalysis as a means to gather additional (unsupervised) information for the\nproposed approach and we show the potential of this technique to improve our\nresults.", "published": "2017-11-21 17:04:33", "link": "http://arxiv.org/abs/1711.07915v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mastering the Dungeon: Grounded Language Learning by Mechanical Turker\n  Descent", "abstract": "Contrary to most natural language processing research, which makes use of\nstatic datasets, humans learn language interactively, grounded in an\nenvironment. In this work we propose an interactive learning procedure called\nMechanical Turker Descent (MTD) and use it to train agents to execute natural\nlanguage commands grounded in a fantasy text adventure game. In MTD, Turkers\ncompete to train better agents in the short term, and collaborate by sharing\ntheir agents' skills in the long term. This results in a gamified, engaging\nexperience for the Turkers and a better quality teaching signal for the agents\ncompared to static datasets, as the Turkers naturally adapt the training data\nto the agent's abilities.", "published": "2017-11-21 18:21:16", "link": "http://arxiv.org/abs/1711.07950v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Application of Natural Language Processing to Determine User\n  Satisfaction in Public Services", "abstract": "Research on customer satisfaction has increased substantially in recent\nyears. However, the relative importance and relationships between different\ndeterminants of satisfaction remains uncertain. Moreover, quantitative studies\nto date tend to test for significance of pre-determined factors thought to have\nan influence with no scalable means to identify other causes of user\nsatisfaction. The gaps in knowledge make it difficult to use available\nknowledge on user preference for public service improvement. Meanwhile, digital\ntechnology development has enabled new methods to collect user feedback, for\nexample through online forums where users can comment freely on their\nexperience. New tools are needed to analyze large volumes of such feedback. Use\nof topic models is proposed as a feasible solution to aggregate open-ended user\nopinions that can be easily deployed in the public sector. Generated insights\ncan contribute to a more inclusive decision-making process in public service\nprovision. This novel methodological approach is applied to a case of service\nreviews of publicly-funded primary care practices in England. Findings from the\nanalysis of 145,000 reviews covering almost 7,700 primary care centers indicate\nthat the quality of interactions with staff and bureaucratic exigencies are the\nkey issues driving user satisfaction across England.", "published": "2017-11-21 23:22:15", "link": "http://arxiv.org/abs/1711.08083v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are You Talking to Me? Reasoned Visual Dialog Generation through\n  Adversarial Learning", "abstract": "The Visual Dialogue task requires an agent to engage in a conversation about\nan image with a human. It represents an extension of the Visual Question\nAnswering task in that the agent needs to answer a question about an image, but\nit needs to do so in light of the previous dialogue that has taken place. The\nkey challenge in Visual Dialogue is thus maintaining a consistent, and natural\ndialogue while continuing to answer questions correctly. We present a novel\napproach that combines Reinforcement Learning and Generative Adversarial\nNetworks (GANs) to generate more human-like responses to questions. The GAN\nhelps overcome the relative paucity of training data, and the tendency of the\ntypical MLE-based approach to generate overly terse answers. Critically, the\nGAN is tightly integrated into the attention mechanism that generates\nhuman-interpretable reasons for each answer. This means that the discriminative\nmodel of the GAN has the task of assessing whether a candidate answer is\ngenerated by a human or not, given the provided reason. This is significant\nbecause it drives the generative model to produce high quality answers that are\nwell supported by the associated reasoning. The method also generates the\nstate-of-the-art results on the primary benchmark.", "published": "2017-11-21 03:11:49", "link": "http://arxiv.org/abs/1711.07613v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Asking the Difficult Questions: Goal-Oriented Visual Question Generation\n  via Intermediate Rewards", "abstract": "Despite significant progress in a variety of vision-and-language problems,\ndeveloping a method capable of asking intelligent, goal-oriented questions\nabout images is proven to be an inscrutable challenge. Towards this end, we\npropose a Deep Reinforcement Learning framework based on three new intermediate\nrewards, namely goal-achieved, progressive and informativeness that encourage\nthe generation of succinct questions, which in turn uncover valuable\ninformation towards the overall goal. By directly optimizing for questions that\nwork quickly towards fulfilling the overall goal, we avoid the tendency of\nexisting methods to generate long series of insane queries that add little\nvalue. We evaluate our model on the GuessWhat?! dataset and show that the\nresulting questions can help a standard Guesser identify a specific object in\nan image at a much higher success rate.", "published": "2017-11-21 03:15:30", "link": "http://arxiv.org/abs/1711.07614v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Generating Thematic Chinese Poetry using Conditional Variational\n  Autoencoders with Hybrid Decoders", "abstract": "Computer poetry generation is our first step towards computer writing.\nWriting must have a theme. The current approaches of using sequence-to-sequence\nmodels with attention often produce non-thematic poems. We present a novel\nconditional variational autoencoder with a hybrid decoder adding the\ndeconvolutional neural networks to the general recurrent neural networks to\nfully learn topic information via latent variables. This approach significantly\nimproves the relevance of the generated poems by representing each line of the\npoem not only in a context-sensitive manner but also in a holistic way that is\nhighly related to the given keyword and the learned topic. A proposed augmented\nword2vec model further improves the rhythm and symmetry. Tests show that the\ngenerated poems by our approach are mostly satisfying with regulated rules and\nconsistent themes, and 73.42% of them receive an Overall score no less than 3\n(the highest score is 5).", "published": "2017-11-21 04:40:38", "link": "http://arxiv.org/abs/1711.07632v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Cross Temporal Recurrent Networks for Ranking Question Answer Pairs", "abstract": "Temporal gates play a significant role in modern recurrent-based neural\nencoders, enabling fine-grained control over recursive compositional operations\nover time. In recurrent models such as the long short-term memory (LSTM),\ntemporal gates control the amount of information retained or discarded over\ntime, not only playing an important role in influencing the learned\nrepresentations but also serving as a protection against vanishing gradients.\nThis paper explores the idea of learning temporal gates for sequence pairs\n(question and answer), jointly influencing the learned representations in a\npairwise manner. In our approach, temporal gates are learned via 1D\nconvolutional layers and then subsequently cross applied across question and\nanswer for joint learning. Empirically, we show that this conceptually simple\nsharing of temporal gates can lead to competitive performance across multiple\nbenchmarks. Intuitively, what our network achieves can be interpreted as\nlearning representations of question and answer pairs that are aware of what\neach other is remembering or forgetting, i.e., pairwise temporal gating. Via\nextensive experiments, we show that our proposed model achieves\nstate-of-the-art performance on two community-based QA datasets and competitive\nperformance on one factoid-based QA dataset.", "published": "2017-11-21 07:26:39", "link": "http://arxiv.org/abs/1711.07656v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Visual and Textual Sentiment Analysis Using Deep Fusion Convolutional\n  Neural Networks", "abstract": "Sentiment analysis is attracting more and more attentions and has become a\nvery hot research topic due to its potential applications in personalized\nrecommendation, opinion mining, etc. Most of the existing methods are based on\neither textual or visual data and can not achieve satisfactory results, as it\nis very hard to extract sufficient information from only one single modality\ndata. Inspired by the observation that there exists strong semantic correlation\nbetween visual and textual data in social medias, we propose an end-to-end deep\nfusion convolutional neural network to jointly learn textual and visual\nsentiment representations from training examples. The two modality information\nare fused together in a pooling layer and fed into fully-connected layers to\npredict the sentiment polarity. We evaluate the proposed approach on two widely\nused data sets. Results show that our method achieves promising result compared\nwith the state-of-the-art methods which clearly demonstrate its competency.", "published": "2017-11-21 14:19:48", "link": "http://arxiv.org/abs/1711.07798v1", "categories": ["cs.CL", "cs.CV", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Unsupervised Adaptation with Domain Separation Networks for Robust\n  Speech Recognition", "abstract": "Unsupervised domain adaptation of speech signal aims at adapting a\nwell-trained source-domain acoustic model to the unlabeled data from target\ndomain. This can be achieved by adversarial training of deep neural network\n(DNN) acoustic models to learn an intermediate deep representation that is both\nsenone-discriminative and domain-invariant. Specifically, the DNN is trained to\njointly optimize the primary task of senone classification and the secondary\ntask of domain classification with adversarial objective functions. In this\nwork, instead of only focusing on learning a domain-invariant feature (i.e. the\nshared component between domains), we also characterize the difference between\nthe source and target domain distributions by explicitly modeling the private\ncomponent of each domain through a private component extractor DNN. The private\ncomponent is trained to be orthogonal with the shared component and thus\nimplicitly increases the degree of domain-invariance of the shared component. A\nreconstructor DNN is used to reconstruct the original speech feature from the\nprivate and shared components as a regularization. This domain separation\nframework is applied to the unsupervised environment adaptation task and\nachieved 11.08% relative WER reduction from the gradient reversal layer\ntraining, a representative adversarial training method, for automatic speech\nrecognition on CHiME-3 dataset.", "published": "2017-11-21 19:44:37", "link": "http://arxiv.org/abs/1711.08010v2", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Deep Long Short-Term Memory Adaptive Beamforming Networks For\n  Multichannel Robust Speech Recognition", "abstract": "Far-field speech recognition in noisy and reverberant conditions remains a\nchallenging problem despite recent deep learning breakthroughs. This problem is\ncommonly addressed by acquiring a speech signal from multiple microphones and\nperforming beamforming over them. In this paper, we propose to use a recurrent\nneural network with long short-term memory (LSTM) architecture to adaptively\nestimate real-time beamforming filter coefficients to cope with non-stationary\nenvironmental noise and dynamic nature of source and microphones positions\nwhich results in a set of timevarying room impulse responses. The LSTM adaptive\nbeamformer is jointly trained with a deep LSTM acoustic model to predict senone\nlabels. Further, we use hidden units in the deep LSTM acoustic model to assist\nin predicting the beamforming filter coefficients. The proposed system achieves\n7.97% absolute gain over baseline systems with no beamforming on CHiME-3 real\nevaluation set.", "published": "2017-11-21 20:03:03", "link": "http://arxiv.org/abs/1711.08016v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Multiple-Instance, Cascaded Classification for Keyword Spotting in\n  Narrow-Band Audio", "abstract": "We propose using cascaded classifiers for a keyword spotting (KWS) task on\nnarrow-band (NB), 8kHz audio acquired in non-IID environments --- a more\nchallenging task than most state-of-the-art KWS systems face. We present a\nmodel that incorporates Deep Neural Networks (DNNs), cascading,\nmultiple-feature representations, and multiple-instance learning. The cascaded\nclassifiers handle the task's class imbalance and reduce power consumption on\ncomputationally-constrained devices via early termination. The KWS system\nachieves a false negative rate of 6% at an hourly false positive rate of 0.75", "published": "2017-11-21 21:42:17", "link": "http://arxiv.org/abs/1711.08058v1", "categories": ["cs.LG", "cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Multichannel Speech Separation and Enhancement Using the Convolutive\n  Transfer Function", "abstract": "This paper addresses the problem of speech separation and enhancement from\nmultichannel convolutive and noisy mixtures, \\emph{assuming known mixing\nfilters}. We propose to perform the speech separation and enhancement task in\nthe short-time Fourier transform domain, using the convolutive transfer\nfunction (CTF) approximation. Compared to time-domain filters, CTF has much\nless taps, consequently it has less near-common zeros among channels and less\ncomputational complexity. The work proposes three speech-source recovery\nmethods, namely: i) the multichannel inverse filtering method, i.e. the\nmultiple input/output inverse theorem (MINT), is exploited in the CTF domain,\nand for the multi-source case, ii) a beamforming-like multichannel inverse\nfiltering method applying single source MINT and using power minimization,\nwhich is suitable whenever the source CTFs are not all known, and iii) a\nconstrained Lasso method, where the sources are recovered by minimizing the\n$\\ell_1$-norm to impose their spectral sparsity, with the constraint that the\n$\\ell_2$-norm fitting cost, between the microphone signals and the mixing model\ninvolving the unknown source signals, is less than a tolerance. The noise can\nbe reduced by setting a tolerance onto the noise power. Experiments under\nvarious acoustic conditions are carried out to evaluate the three proposed\nmethods. The comparison between them as well as with the baseline methods is\npresented.", "published": "2017-11-21 17:02:03", "link": "http://arxiv.org/abs/1711.07911v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Reflection-Aware Sound Source Localization", "abstract": "We present a novel, reflection-aware method for 3D sound localization in\nindoor environments. Unlike prior approaches, which are mainly based on\ncontinuous sound signals from a stationary source, our formulation is designed\nto localize the position instantaneously from signals within a single frame. We\nconsider direct sound and indirect sound signals that reach the microphones\nafter reflecting off surfaces such as ceilings or walls. We then generate and\ntrace direct and reflected acoustic paths using inverse acoustic ray tracing\nand utilize these paths with Monte Carlo localization to estimate a 3D sound\nsource position. We have implemented our method on a robot with a cube-shaped\nmicrophone array and tested it against different settings with continuous and\nintermittent sound signals with a stationary or a mobile source. Across\ndifferent settings, our approach can localize the sound with an average\ndistance error of 0.8m tested in a room of 7m by 7m area with 3m height,\nincluding a mobile and non-line-of-sight sound source. We also reveal that the\nmodeling of indirect rays increases the localization accuracy by 40% compared\nto only using direct acoustic rays.", "published": "2017-11-21 14:05:03", "link": "http://arxiv.org/abs/1711.07791v1", "categories": ["cs.SD", "cs.RO", "eess.AS"], "primary_category": "cs.SD"}
{"title": "JamBot: Music Theory Aware Chord Based Generation of Polyphonic Music\n  with LSTMs", "abstract": "We propose a novel approach for the generation of polyphonic music based on\nLSTMs. We generate music in two steps. First, a chord LSTM predicts a chord\nprogression based on a chord embedding. A second LSTM then generates polyphonic\nmusic from the predicted chord progression. The generated music sounds pleasing\nand harmonic, with only few dissonant notes. It has clear long-term structure\nthat is similar to what a musician would play during a jam session. We show\nthat our approach is sensible from a music theory perspective by evaluating the\nlearned chord embeddings. Surprisingly, our simple model managed to extract the\ncircle of fifths, an important tool in music theory, from the dataset.", "published": "2017-11-21 09:19:16", "link": "http://arxiv.org/abs/1711.07682v1", "categories": ["cs.SD", "cs.AI", "cs.IT", "cs.LG", "eess.AS", "math.IT", "stat.ML", "I.2.1; I.2.4; I.2.6; H.5.5"], "primary_category": "cs.SD"}
