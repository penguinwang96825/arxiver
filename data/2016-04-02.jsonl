{"title": "Online Updating of Word Representations for Part-of-Speech Tagging", "abstract": "We propose online unsupervised domain adaptation (DA), which is performed\nincrementally as data comes in and is applicable when batch DA is not possible.\nIn a part-of-speech (POS) tagging evaluation, we find that online unsupervised\nDA performs as well as batch DA.", "published": "2016-04-02 13:52:23", "link": "http://arxiv.org/abs/1604.00502v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Discriminative Phrase Embedding for Paraphrase Identification", "abstract": "This work, concerning paraphrase identification task, on one hand contributes\nto expanding deep learning embeddings to include continuous and discontinuous\nlinguistic phrases. On the other hand, it comes up with a new scheme TF-KLD-KNN\nto learn the discriminative weights of words and phrases specific to paraphrase\ntask, so that a weighted sum of embeddings can represent sentences more\neffectively. Based on these two innovations we get competitive state-of-the-art\nperformance on paraphrase identification.", "published": "2016-04-02 13:57:02", "link": "http://arxiv.org/abs/1604.00503v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Annotation of Structured Facts in Images", "abstract": "Motivated by the application of fact-level image understanding, we present an\nautomatic method for data collection of structured visual facts from images\nwith captions. Example structured facts include attributed objects (e.g.,\n<flower, red>), actions (e.g., <baby, smile>), interactions (e.g., <man,\nwalking, dog>), and positional information (e.g., <vase, on, table>). The\ncollected annotations are in the form of fact-image pairs (e.g.,<man, walking,\ndog> and an image region containing this fact). With a language approach, the\nproposed method is able to collect hundreds of thousands of visual fact\nannotations with accuracy of 83% according to human judgment. Our method\nautomatically collected more than 380,000 visual fact annotations and more than\n110,000 unique visual facts from images with captions and localized them in\nimages in less than one day of processing time on standard CPU platforms.", "published": "2016-04-02 06:35:45", "link": "http://arxiv.org/abs/1604.00466v3", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Reasoning About Pragmatics with Neural Listeners and Speakers", "abstract": "We present a model for pragmatically describing scenes, in which contrastive\nbehavior results from a combination of inference-driven pragmatics and learned\nsemantics. Like previous learned approaches to language generation, our model\nuses a simple feature-driven architecture (here a pair of neural \"listener\" and\n\"speaker\" models) to ground language in the world. Like inference-driven\napproaches to pragmatics, our model actively reasons about listener behavior\nwhen selecting utterances. For training, our approach requires only ordinary\ncaptions, annotated _without_ demonstration of the pragmatic behavior the model\nultimately exhibits. In human evaluations on a referring expression game, our\napproach succeeds 81% of the time, compared to a 69% success rate using\nexisting techniques.", "published": "2016-04-02 21:52:03", "link": "http://arxiv.org/abs/1604.00562v2", "categories": ["cs.CL", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Embedding Lexical Features via Low-Rank Tensors", "abstract": "Modern NLP models rely heavily on engineered features, which often combine\nword and contextual information into complex lexical features. Such combination\nresults in large numbers of features, which can lead to over-fitting. We\npresent a new model that represents complex lexical features---comprised of\nparts for words, contextual information and labels---in a tensor that captures\nconjunction information among these parts. We apply low-rank tensor\napproximations to the corresponding parameter tensors to reduce the parameter\nspace and improve prediction speed. Furthermore, we investigate two methods for\nhandling features that include $n$-grams of mixed lengths. Our model achieves\nstate-of-the-art results on tasks in relation extraction, PP-attachment, and\npreposition disambiguation.", "published": "2016-04-02 04:59:21", "link": "http://arxiv.org/abs/1604.00461v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
