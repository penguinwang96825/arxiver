{"title": "JTAV: Jointly Learning Social Media Content Representation by Fusing\n  Textual, Acoustic, and Visual Features", "abstract": "Learning social media content is the basis of many real-world applications,\nincluding information retrieval and recommendation systems, among others. In\ncontrast with previous works that focus mainly on single modal or bi-modal\nlearning, we propose to learn social media content by fusing jointly textual,\nacoustic, and visual information (JTAV). Effective strategies are proposed to\nextract fine-grained features of each modality, that is, attBiGRU and DCRNN. We\nalso introduce cross-modal fusion and attentive pooling techniques to integrate\nmulti-modal information comprehensively. Extensive experimental evaluation\nconducted on real-world datasets demonstrates our proposed model outperforms\nthe state-of-the-art approaches by a large margin.", "published": "2018-06-05 03:50:50", "link": "http://arxiv.org/abs/1806.01483v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Information Aggregation via Dynamic Routing for Sequence Encoding", "abstract": "While much progress has been made in how to encode a text sequence into a\nsequence of vectors, less attention has been paid to how to aggregate these\npreceding vectors (outputs of RNN/CNN) into fixed-size encoding vector.\nUsually, a simple max or average pooling is used, which is a bottom-up and\npassive way of aggregation and lack of guidance by task information. In this\npaper, we propose an aggregation mechanism to obtain a fixed-size encoding with\na dynamic routing policy. The dynamic routing policy is dynamically deciding\nthat what and how much information need be transferred from each word to the\nfinal encoding of the text sequence. Following the work of Capsule Network, we\ndesign two dynamic routing policies to aggregate the outputs of RNN/CNN\nencoding layer into a final encoding vector. Compared to the other aggregation\nmethods, dynamic routing can refine the messages according to the state of\nfinal encoding vector. Experimental results on five text classification tasks\nshow that our method outperforms other aggregating models by a significant\nmargin. Related source code is released on our github page.", "published": "2018-06-05 05:34:15", "link": "http://arxiv.org/abs/1806.01501v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Do Source-side Monolingual Word Embeddings Impact Neural Machine\n  Translation?", "abstract": "Using pre-trained word embeddings as input layer is a common practice in many\nnatural language processing (NLP) tasks, but it is largely neglected for neural\nmachine translation (NMT). In this paper, we conducted a systematic analysis on\nthe effect of using pre-trained source-side monolingual word embedding in NMT.\nWe compared several strategies, such as fixing or updating the embeddings\nduring NMT training on varying amounts of data, and we also proposed a novel\nstrategy called dual-embedding that blends the fixing and updating strategies.\nOur results suggest that pre-trained embeddings can be helpful if properly\nincorporated into NMT, especially when parallel data is limited or additional\nin-domain monolingual data is readily available.", "published": "2018-06-05 06:45:23", "link": "http://arxiv.org/abs/1806.01515v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Task Active Learning for Neural Semantic Role Labeling on Low\n  Resource Conversational Corpus", "abstract": "Most Semantic Role Labeling (SRL) approaches are supervised methods which\nrequire a significant amount of annotated corpus, and the annotation requires\nlinguistic expertise. In this paper, we propose a Multi-Task Active Learning\nframework for Semantic Role Labeling with Entity Recognition (ER) as the\nauxiliary task to alleviate the need for extensive data and use additional\ninformation from ER to help SRL. We evaluate our approach on Indonesian\nconversational dataset. Our experiments show that multi-task active learning\ncan outperform single-task active learning method and standard multi-task\nlearning. According to our results, active learning is more efficient by using\n12% less of training data compared to passive learning in both single-task and\nmulti-task setting. We also introduce a new dataset for SRL in Indonesian\nconversational domain to encourage further research in this area.", "published": "2018-06-05 07:34:02", "link": "http://arxiv.org/abs/1806.01523v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Explaining Away Syntactic Structure in Semantic Document Representations", "abstract": "Most generative document models act on bag-of-words input in an attempt to\nfocus on the semantic content and thereby partially forego syntactic\ninformation. We argue that it is preferable to keep the original word order\nintact and explicitly account for the syntactic structure instead. We propose\nan extension to the Neural Variational Document Model (Miao et al., 2016) that\ndoes exactly that to separate local (syntactic) context from the global\n(semantic) representation of the document. Our model builds on the variational\nautoencoder framework to define a generative document model based on next-word\nprediction. We name our approach Sequence-Aware Variational Autoencoder since\nin contrast to its predecessor, it operates on the true input sequence. In a\nseries of experiments we observe stronger topicality of the learned\nrepresentations as well as increased robustness to syntactic noise in our\ntraining data.", "published": "2018-06-05 12:02:11", "link": "http://arxiv.org/abs/1806.01620v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Understanding Meanings in Multilingual Customer Feedback", "abstract": "Understanding and being able to react to customer feedback is the most\nfundamental task in providing good customer service. However, there are two\nmajor obstacles for international companies to automatically detect the meaning\nof customer feedback in a global multilingual environment. Firstly, there is no\nwidely acknowledged categorisation (classes) of meaning for customer feedback.\nSecondly, the applicability of one meaning categorisation, if it exists, to\ncustomer feedback in multiple languages is questionable. In this paper, we\nextracted representative real world samples of customer feedback from Microsoft\nOffice customers in multiple languages, English, Spanish and Japanese,and\nconcluded a five-class categorisation(comment, request, bug, complaint and\nmeaningless) for meaning classification that could be used across languages in\nthe realm of customer feedback analysis.", "published": "2018-06-05 13:59:32", "link": "http://arxiv.org/abs/1806.01694v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Luminoso at SemEval-2018 Task 10: Distinguishing Attributes Using Text\n  Corpora and Relational Knowledge", "abstract": "Luminoso participated in the SemEval 2018 task on \"Capturing Discriminative\nAttributes\" with a system based on ConceptNet, an open knowledge graph focused\non general knowledge. In this paper, we describe how we trained a linear\nclassifier on a small number of semantically-informed features to achieve an\n$F_1$ score of 0.7368 on the task, close to the task's high score of 0.75.", "published": "2018-06-05 15:02:13", "link": "http://arxiv.org/abs/1806.01733v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contextual Slot Carryover for Disparate Schemas", "abstract": "In the slot-filling paradigm, where a user can refer back to slots in the\ncontext during a conversation, the goal of the contextual understanding system\nis to resolve the referring expressions to the appropriate slots in the\ncontext. In large-scale multi-domain systems, this presents two challenges -\nscaling to a very large and potentially unbounded set of slot values, and\ndealing with diverse schemas. We present a neural network architecture that\naddresses the slot value scalability challenge by reformulating the contextual\ninterpretation as a decision to carryover a slot from a set of possible\ncandidates. To deal with heterogenous schemas, we introduce a simple\ndata-driven method for trans- forming the candidate slots. Our experiments show\nthat our approach can scale to multiple domains and provides competitive\nresults over a strong baseline.", "published": "2018-06-05 16:15:23", "link": "http://arxiv.org/abs/1806.01773v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adapting Neural Text Classification for Improved Software Categorization", "abstract": "Software Categorization is the task of organizing software into groups that\nbroadly describe the behavior of the software, such as \"editors\" or \"science.\"\nCategorization plays an important role in several maintenance tasks, such as\nrepository navigation and feature elicitation. Current approaches attempt to\ncast the problem as text classification, to make use of the rich body of\nliterature from the NLP domain. However, as we will show in this paper, text\nclassification algorithms are generally not applicable off-the-shelf to source\ncode; we found that they work well when high-level project descriptions are\navailable, but suffer very large performance penalties when classifying source\ncode and comments only. We propose a set of adaptations to a state-of-the-art\nneural classification algorithm and perform two evaluations: one with reference\ndata from Debian end-user programs, and one with a set of C/C++ libraries that\nwe hired professional programmers to annotate. We show that our proposed\napproach achieves performance exceeding that of previous software\nclassification techniques as well as a state-of-the-art neural text\nclassification technique.", "published": "2018-06-05 15:18:47", "link": "http://arxiv.org/abs/1806.01742v2", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Leolani: a reference machine with a theory of mind for social\n  communication", "abstract": "Our state of mind is based on experiences and what other people tell us. This\nmay result in conflicting information, uncertainty, and alternative facts. We\npresent a robot that models relativity of knowledge and perception within\nsocial interaction following principles of the theory of mind. We utilized\nvision and speech capabilities on a Pepper robot to build an interaction model\nthat stores the interpretations of perceptions and conversations in combination\nwith provenance on its sources. The robot learns directly from what people tell\nit, possibly in relation to its perception. We demonstrate how the robot's\ncommunication is driven by hunger to acquire more knowledge from and on people\nand objects, to resolve uncertainties and conflicts, and to share awareness of\nthe per- ceived environment. Likewise, the robot can make reference to the\nworld and its knowledge about the world and the encounters with people that\nyielded this knowledge.", "published": "2018-06-05 07:36:36", "link": "http://arxiv.org/abs/1806.01526v1", "categories": ["cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Attention Based Fully Convolutional Network for Speech Emotion\n  Recognition", "abstract": "Speech emotion recognition is a challenging task for three main reasons: 1)\nhuman emotion is abstract, which means it is hard to distinguish; 2) in\ngeneral, human emotion can only be detected in some specific moments during a\nlong utterance; 3) speech data with emotional labeling is usually limited. In\nthis paper, we present a novel attention based fully convolutional network for\nspeech emotion recognition. We employ fully convolutional network as it is able\nto handle variable-length speech, free of the demand of segmentation to keep\ncritical information not lost. The proposed attention mechanism can make our\nmodel be aware of which time-frequency region of speech spectrogram is more\nemotion-relevant. Considering limited data, the transfer learning is also\nadapted to improve the accuracy. Especially, it's interesting to observe\nobvious improvement obtained with natural scene image based pre-trained model.\nValidated on the publicly available IEMOCAP corpus, the proposed model\noutperformed the state-of-the-art methods with a weighted accuracy of 70.4% and\nan unweighted accuracy of 63.9% respectively.", "published": "2018-06-05 06:00:46", "link": "http://arxiv.org/abs/1806.01506v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Singing voice phoneme segmentation by hierarchically inferring syllable\n  and phoneme onset positions", "abstract": "In this paper, we tackle the singing voice phoneme segmentation problem in\nthe singing training scenario by using language-independent information --\nonset and prior coarse duration. We propose a two-step method. In the first\nstep, we jointly calculate the syllable and phoneme onset detection functions\n(ODFs) using a convolutional neural network (CNN). In the second step, the\nsyllable and phoneme boundaries and labels are inferred hierarchically by using\na duration-informed hidden Markov model (HMM). To achieve the inference, we\nincorporate the a priori duration model as the transition probabilities and the\nODFs as the emission probabilities into the HMM. The proposed method is\ndesigned in a language-independent way such that no phoneme class labels are\nused. For the model training and algorithm evaluation, we collect a new jingju\n(also known as Beijing or Peking opera) solo singing voice dataset and manually\nannotate the boundaries and labels at phrase, syllable and phoneme levels. The\ndataset is publicly available. The proposed method is compared with a baseline\nmethod based on hidden semi-Markov model (HSMM) forced alignment. The\nevaluation results show that the proposed method outperforms the baseline by a\nlarge margin regarding both segmentation and onset detection tasks.", "published": "2018-06-05 12:54:19", "link": "http://arxiv.org/abs/1806.01665v1", "categories": ["cs.SD", "cs.IR", "eess.AS"], "primary_category": "cs.SD"}
