{"title": "An Ensemble Method to Produce High-Quality Word Embeddings (2016)", "abstract": "A currently successful approach to computational semantics is to represent\nwords as embeddings in a machine-learned vector space. We present an ensemble\nmethod that combines embeddings produced by GloVe (Pennington et al., 2014) and\nword2vec (Mikolov et al., 2013) with structured knowledge from the semantic\nnetworks ConceptNet (Speer and Havasi, 2012) and PPDB (Ganitkevitch et al.,\n2013), merging their information into a common representation with a large,\nmultilingual vocabulary. The embeddings it produces achieve state-of-the-art\nperformance on many word-similarity evaluations. Its score of $\\rho = .596$ on\nan evaluation of rare words (Luong et al., 2013) is 16% higher than the\nprevious best known system.", "published": "2016-04-06 16:58:35", "link": "http://arxiv.org/abs/1604.01692v2", "categories": ["cs.CL", "I.2.7", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Generating Chinese Classical Poems with RNN Encoder-Decoder", "abstract": "We take the generation of Chinese classical poem lines as a\nsequence-to-sequence learning problem, and build a novel system based on the\nRNN Encoder-Decoder structure to generate quatrains (Jueju in Chinese), with a\ntopic word as input. Our system can jointly learn semantic meaning within a\nsingle line, semantic relevance among lines in a poem, and the use of\nstructural, rhythmical and tonal patterns, without utilizing any constraint\ntemplates. Experimental results show that our system outperforms other\ncompetitive systems. We also find that the attention mechanism can capture the\nword associations in Chinese classical poetry and inverting target lines in\ntraining can improve performance.", "published": "2016-04-06 08:26:31", "link": "http://arxiv.org/abs/1604.01537v1", "categories": ["cs.CL", "cs.NE"], "primary_category": "cs.CL"}
{"title": "A Corpus and Evaluation Framework for Deeper Understanding of\n  Commonsense Stories", "abstract": "Representation and learning of commonsense knowledge is one of the\nfoundational problems in the quest to enable deep language understanding. This\nissue is particularly challenging for understanding casual and correlational\nrelationships between events. While this topic has received a lot of interest\nin the NLP community, research has been hindered by the lack of a proper\nevaluation framework. This paper attempts to address this problem with a new\nframework for evaluating story understanding and script learning: the 'Story\nCloze Test'. This test requires a system to choose the correct ending to a\nfour-sentence story. We created a new corpus of ~50k five-sentence commonsense\nstories, ROCStories, to enable this evaluation. This corpus is unique in two\nways: (1) it captures a rich set of causal and temporal commonsense relations\nbetween daily events, and (2) it is a high quality collection of everyday life\nstories that can also be used for story generation. Experimental evaluation\nshows that a host of baselines and state-of-the-art models based on shallow\nlanguage understanding struggle to achieve a high score on the Story Cloze\nTest. We discuss these implications for script and story learning, and offer\nsuggestions for deeper language understanding.", "published": "2016-04-06 17:15:10", "link": "http://arxiv.org/abs/1604.01696v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving LSTM-based Video Description with Linguistic Knowledge Mined\n  from Text", "abstract": "This paper investigates how linguistic knowledge mined from large text\ncorpora can aid the generation of natural language descriptions of videos.\nSpecifically, we integrate both a neural language model and distributional\nsemantics trained on large text corpora into a recent LSTM-based architecture\nfor video description. We evaluate our approach on a collection of Youtube\nvideos as well as two large movie description datasets showing significant\nimprovements in grammaticality while modestly improving descriptive quality.", "published": "2016-04-06 19:01:28", "link": "http://arxiv.org/abs/1604.01729v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "A Focused Dynamic Attention Model for Visual Question Answering", "abstract": "Visual Question and Answering (VQA) problems are attracting increasing\ninterest from multiple research disciplines. Solving VQA problems requires\ntechniques from both computer vision for understanding the visual contents of a\npresented image or video, as well as the ones from natural language processing\nfor understanding semantics of the question and generating the answers.\nRegarding visual content modeling, most of existing VQA methods adopt the\nstrategy of extracting global features from the image or video, which\ninevitably fails in capturing fine-grained information such as spatial\nconfiguration of multiple objects. Extracting features from auto-generated\nregions -- as some region-based image recognition methods do -- cannot\nessentially address this problem and may introduce some overwhelming irrelevant\nfeatures with the question. In this work, we propose a novel Focused Dynamic\nAttention (FDA) model to provide better aligned image content representation\nwith proposed questions. Being aware of the key words in the question, FDA\nemploys off-the-shelf object detector to identify important regions and fuse\nthe information from the regions and global features via an LSTM unit. Such\nquestion-driven representations are then combined with question representation\nand fed into a reasoning unit for generating the answers. Extensive evaluation\non a large-scale benchmark dataset, VQA, clearly demonstrate the superior\nperformance of FDA over well-established baselines.", "published": "2016-04-06 05:16:10", "link": "http://arxiv.org/abs/1604.01485v1", "categories": ["cs.CV", "cs.CL", "cs.NE"], "primary_category": "cs.CV"}
{"title": "Advances in Very Deep Convolutional Neural Networks for LVCSR", "abstract": "Very deep CNNs with small 3x3 kernels have recently been shown to achieve\nvery strong performance as acoustic models in hybrid NN-HMM speech recognition\nsystems. In this paper we investigate how to efficiently scale these models to\nlarger datasets. Specifically, we address the design choice of pooling and\npadding along the time dimension which renders convolutional evaluation of\nsequences highly inefficient. We propose a new CNN design without timepadding\nand without timepooling, which is slightly suboptimal for accuracy, but has two\nsignificant advantages: it enables sequence training and deployment by allowing\nefficient convolutional evaluation of full utterances, and, it allows for batch\nnormalization to be straightforwardly adopted to CNNs on sequence data. Through\nbatch normalization, we recover the lost peformance from removing the\ntime-pooling, while keeping the benefit of efficient convolutional evaluation.\nWe demonstrate the performance of our models both on larger scale data than\nbefore, and after sequence training. Our very deep CNN model sequence trained\non the 2000h switchboard dataset obtains 9.4 word error rate on the Hub5\ntest-set, matching with a single model the performance of the 2015 IBM system\ncombination, which was the previous best published result.", "published": "2016-04-06 20:07:52", "link": "http://arxiv.org/abs/1604.01792v2", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
