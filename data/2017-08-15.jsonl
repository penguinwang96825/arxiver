{"title": "Fluency-Guided Cross-Lingual Image Captioning", "abstract": "Image captioning has so far been explored mostly in English, as most\navailable datasets are in this language. However, the application of image\ncaptioning should not be restricted by language. Only few studies have been\nconducted for image captioning in a cross-lingual setting. Different from these\nworks that manually build a dataset for a target language, we aim to learn a\ncross-lingual captioning model fully from machine-translated sentences. To\nconquer the lack of fluency in the translated sentences, we propose in this\npaper a fluency-guided learning framework. The framework comprises a module to\nautomatically estimate the fluency of the sentences and another module to\nutilize the estimated fluency scores to effectively train an image captioning\nmodel for the target language. As experiments on two bilingual\n(English-Chinese) datasets show, our approach improves both fluency and\nrelevance of the generated captions in Chinese, but without using any manually\nwritten sentences from the target language.", "published": "2017-08-15 03:46:31", "link": "http://arxiv.org/abs/1708.04390v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Comparison of Decoding Strategies for CTC Acoustic Models", "abstract": "Connectionist Temporal Classification has recently attracted a lot of\ninterest as it offers an elegant approach to building acoustic models (AMs) for\nspeech recognition. The CTC loss function maps an input sequence of observable\nfeature vectors to an output sequence of symbols. Output symbols are\nconditionally independent of each other under CTC loss, so a language model\n(LM) can be incorporated conveniently during decoding, retaining the\ntraditional separation of acoustic and linguistic components in ASR. For fixed\nvocabularies, Weighted Finite State Transducers provide a strong baseline for\nefficient integration of CTC AMs with n-gram LMs. Character-based neural LMs\nprovide a straight forward solution for open vocabulary speech recognition and\nall-neural models, and can be decoded with beam search. Finally,\nsequence-to-sequence models can be used to translate a sequence of individual\nsounds into a word string. We compare the performance of these three\napproaches, and analyze their error patterns, which provides insightful\nguidance for future research and development in this important area.", "published": "2017-08-15 12:05:02", "link": "http://arxiv.org/abs/1708.04469v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Word Embeddings for Sentence Boundary Detection in Speech\n  Transcripts", "abstract": "This paper is motivated by the automation of neuropsychological tests\ninvolving discourse analysis in the retellings of narratives by patients with\npotential cognitive impairment. In this scenario the task of sentence boundary\ndetection in speech transcripts is important as discourse analysis involves the\napplication of Natural Language Processing tools, such as taggers and parsers,\nwhich depend on the sentence as a processing unit. Our aim in this paper is to\nverify which embedding induction method works best for the sentence boundary\ndetection task, specifically whether it be those which were proposed to capture\nsemantic, syntactic or morphological similarities.", "published": "2017-08-15 22:12:59", "link": "http://arxiv.org/abs/1708.04704v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Identifying Harm Events in Clinical Care through Medical Narratives", "abstract": "Preventable medical errors are estimated to be among the leading causes of\ninjury and death in the United States. To prevent such errors, healthcare\nsystems have implemented patient safety and incident reporting systems. These\nsystems enable clinicians to report unsafe conditions and cases where patients\nhave been harmed due to errors in medical care. These reports are narratives in\nnatural language and while they provide detailed information about the\nsituation, it is non-trivial to perform large scale analysis for identifying\ncommon causes of errors and harm to the patients. In this work, we present a\nmethod based on attentive convolutional and recurrent networks for identifying\nharm events in patient care and categorize the harm based on its severity\nlevel. We demonstrate that our methods can significantly improve the\nperformance over existing methods in identifying harm in clinical care.", "published": "2017-08-15 20:38:37", "link": "http://arxiv.org/abs/1708.04681v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Extractive Summarization using Deep Learning", "abstract": "This paper proposes a text summarization approach for factual reports using a\ndeep learning model. This approach consists of three phases: feature\nextraction, feature enhancement, and summary generation, which work together to\nassimilate core information and generate a coherent, understandable summary. We\nare exploring various features to improve the set of sentences selected for the\nsummary, and are using a Restricted Boltzmann Machine to enhance and abstract\nthose features to improve resultant accuracy without losing any important\ninformation. The sentences are scored based on those enhanced features and an\nextractive summary is constructed. Experimentation carried out on several\narticles demonstrates the effectiveness of the proposed approach. Source code\navailable at: https://github.com/vagisha-nidhi/TextSummarizer", "published": "2017-08-15 09:08:50", "link": "http://arxiv.org/abs/1708.04439v2", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Database of Parliamentary Speeches in Ireland, 1919-2013", "abstract": "We present a database of parliamentary debates that contains the complete\nrecord of parliamentary speeches from D\\'ail \\'Eireann, the lower house and\nprincipal chamber of the Irish parliament, from 1919 to 2013. In addition, the\ndatabase contains background information on all TDs (Teachta D\\'ala, members of\nparliament), such as their party affiliations, constituencies and office\npositions. The current version of the database includes close to 4.5 million\nspeeches from 1,178 TDs. The speeches were downloaded from the official\nparliament website and further processed and parsed with a Python script.\nBackground information on TDs was collected from the member database of the\nparliament website. Data on cabinet positions (ministers and junior ministers)\nwas collected from the official website of the government. A record linkage\nalgorithm and human coders were used to match TDs and ministers.", "published": "2017-08-15 15:34:33", "link": "http://arxiv.org/abs/1708.04557v1", "categories": ["cs.CL", "cs.SI", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Automatic Summarization of Online Debates", "abstract": "Debate summarization is one of the novel and challenging research areas in\nautomatic text summarization which has been largely unexplored. In this paper,\nwe develop a debate summarization pipeline to summarize key topics which are\ndiscussed or argued in the two opposing sides of online debates. We view that\nthe generation of debate summaries can be achieved by clustering, cluster\nlabeling, and visualization. In our work, we investigate two different\nclustering approaches for the generation of the summaries. In the first\napproach, we generate the summaries by applying purely term-based clustering\nand cluster labeling. The second approach makes use of X-means for clustering\nand Mutual Information for labeling the clusters. Both approaches are driven by\nontologies. We visualize the results using bar charts. We think that our\nresults are a smooth entry for users aiming to receive the first impression\nabout what is discussed within a debate topic containing waste number of\nargumentations.", "published": "2017-08-15 16:44:28", "link": "http://arxiv.org/abs/1708.04587v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Gold Standard Online Debates Summaries and First Experiments Towards\n  Automatic Summarization of Online Debate Data", "abstract": "Usage of online textual media is steadily increasing. Daily, more and more\nnews stories, blog posts and scientific articles are added to the online\nvolumes. These are all freely accessible and have been employed extensively in\nmultiple research areas, e.g. automatic text summarization, information\nretrieval, information extraction, etc. Meanwhile, online debate forums have\nrecently become popular, but have remained largely unexplored. For this reason,\nthere are no sufficient resources of annotated debate data available for\nconducting research in this genre. In this paper, we collected and annotated\ndebate data for an automatic summarization task. Similar to extractive gold\nstandard summary generation our data contains sentences worthy to include into\na summary. Five human annotators performed this task. Inter-annotator\nagreement, based on semantic similarity, is 36% for Cohen's kappa and 48% for\nKrippendorff's alpha. Moreover, we also implement an extractive summarization\nsystem for online debates and discuss prominent features for the task of\nsummarizing online debate data automatically.", "published": "2017-08-15 16:52:22", "link": "http://arxiv.org/abs/1708.04592v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "VQS: Linking Segmentations to Questions and Answers for Supervised\n  Attention in VQA and Question-Focused Semantic Segmentation", "abstract": "Rich and dense human labeled datasets are among the main enabling factors for\nthe recent advance on vision-language understanding. Many seemingly distant\nannotations (e.g., semantic segmentation and visual question answering (VQA))\nare inherently connected in that they reveal different levels and perspectives\nof human understandings about the same visual scenes --- and even the same set\nof images (e.g., of COCO). The popularity of COCO correlates those annotations\nand tasks. Explicitly linking them up may significantly benefit both individual\ntasks and the unified vision and language modeling. We present the preliminary\nwork of linking the instance segmentations provided by COCO to the questions\nand answers (QAs) in the VQA dataset, and name the collected links visual\nquestions and segmentation answers (VQS). They transfer human supervision\nbetween the previously separate tasks, offer more effective leverage to\nexisting problems, and also open the door for new research problems and models.\nWe study two applications of the VQS data in this paper: supervised attention\nfor VQA and a novel question-focused semantic segmentation task. For the\nformer, we obtain state-of-the-art results on the VQA real multiple-choice task\nby simply augmenting the multilayer perceptrons with some attention features\nthat are learned using the segmentation-QA links as explicit supervision. To\nput the latter in perspective, we study two plausible methods and compare them\nto an oracle method assuming that the instance segmentations are given at the\ntest stage.", "published": "2017-08-15 20:47:02", "link": "http://arxiv.org/abs/1708.04686v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
